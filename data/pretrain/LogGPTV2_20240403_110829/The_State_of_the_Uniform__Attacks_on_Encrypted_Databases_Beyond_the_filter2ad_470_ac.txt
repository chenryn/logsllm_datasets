choose the estimator (cid:9)NJ(i(cid:2)) such that Hi(cid:2)
is the ﬁrst null
hypothesis not rejected. We denote the above method for order
selection as JACKKNIFE-SELFTUNE.
The Valiant-Valiant Estimator. The work by Valiant and
Valiant [44] introduced a framework for rigorously estimating
the histogram of a discrete probability distribution from a
sample. Since we are using the estimator from [44] as is,
we limit our exposition into a high-level description of the
estimator and its guarantees and we refer the reader to the
original manuscript [44] for the detailed description. The
VALIANT-VALIANT estimator takes as an input a sample
from an unknown distribution, creates the ﬁngerprint and then
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:12:16 UTC from IEEE Xplore.  Restrictions apply. 
1228
0.2
r
o
r
r
E
e
v
i
t
l
a
e
R
0.15
0.1
0.05
Beta( 1 , 2.5 ), N=105
Jackknife Estimator
Valiant-Valiant-Estimator
0.45
0.4
0.35
0.3
0.25
0.2
0.15
r
o
r
r
E
e
v
i
t
a
e
R
l
Beta( 1 , 5 ), N=105
Jackknife Estimator
Valiant-Valiant Estimator
0.65
0.6
r
o
r
r
0.55
Beta( 1 , 10 ), N=105
Jackknife Estimator
Valiant-Valiant Estimator
E
e
v
i
t
l
a
e
R
0.5
0.45
0.4
Beta( 1 , 17 ), N=105
Jackknife Estimator
Valiant-Valiant Estimator
0.8
0.75
0.7
0.65
0.6
0.55
r
o
r
r
E
e
v
i
t
a
e
R
l
0
5 104 105
5 105 106
5 106
0.1
5 104 105
5 105 106
5 106
Number of Queries (Log Scale)
Number of Queries (Log Scale)
0.35
5 104 105
5 105 106
5 106
Number of Queries (Log Scale)
0.5
5 104 105
5 105 106
5 106
Number of Queries (Log Scale)
Fig. 6. Comparison of estimators JACKKNIFE-SELFTUNE and VALIANT-VALIANT with respect to their relative error in support size estimation.
computes a plausible histogram that might have produced the
observed ﬁngerprint. Because there are numerous histograms
that explain equally well the observed ﬁngerprint the authors
propose a method that picks the “simplest” among them.
Theorem 1. (Corollary 1.12 [44]) There exist absolute positive
constants ζ, γ such that for any 0  N, given a sample of search tokens D of size
m > γ
log N sampled from any query distribution π over the
domain of pT|R of size |pT|R| = N, the VALIANT-VALIANT
2
estimator outputs a ˆN such that
N
Pr(|N − ˆN| ≤ N ) ≥ 1 − e−N ζ ,
provided none of the probabilities in π lie in (0, 1
N ).
N ).
It is worth noting that the above guarantees are bounds
on the convergence rate and not essential parameters for the
VALIANT-VALIANT estimator. The algorithm itself does not
depend on any of the above parameters and its only input is
a sample D of any size. An alternative way to interpret the
requirement that none of the probabilities in π lie in (0, 1
N )
is: the approximation guarantees only hold for all the search
tokens with probabilities that are larger than 1
N and as a result
there is no rigorous guarantee for detecting the tokens with
probabilities within (0, 1
Evaluation of the Estimators. We conduct experiments to
evaluate the performance of the estimators VALIANT-VALIANT
and JACKKNIFE-SELFTUNE. The only input that the two non-
parametric estimators take is a sample form an unknown query
distribution and based on the frequency of the search tokens
they estimate the support size. We compute the relative error
of the support size estimation under different settings:
• Query distribution. We deploy a discretized Beta probability
distribution Beta(α, β) deﬁned under parameterizations that
take values α = 1 and β = {1, 2.5, 5, 10, 17}.
• Scale of support size. Chosen to be N = 105.
• Number of observed search tokens. Varying sample size.
We differentiate in our text between the α, β that denote the
boundaries of the universe of values, see Section II, from the
α, β used for the Beta probability distribution by characterizing
the latter as parameters of the distribution. Figure 7 shows
the tested parameterizations of the Beta distribution. Beta is
deﬁned under continuous interval [0, 1] which we discretized
into N segments of equal length. Parameter β = 1 gives the
uniform distribution, parameter β = 2.5 gives an almost linear
n
o
i
t
u
b
i
r
t
s
D
y
t
i
l
i
i
b
a
b
o
r
P
y
r
e
u
Q
0.15
0.1
0.05
0.025
0.01
0
1
Beta Distributions, Support Size N=100
Parametrizations
=1,  =1
=1,  =2.5
=1,  =5
=1,  =10
=1,  =17
20
40
60
Search Tokens 
80
100
Fig. 7. Evaluation of the estimators is conducted under various query
distributions parameterized as a Beta probability mass function.
decay. For parameter β = 10, we have roughly a power law,
i.e., the Pareto principle, where roughly 80% of the mass is
distributed among 20% percent of the search tokens. This
behavior has been recorded in a lot of real-world phenomena.
To give some more concrete statistics, for parameters β =
2.5, 5, 10, 17 the percentages of search tokens that: (a) have
probability less than 1/N are 54%, 67%, 77%, 84% and (b)
have probability less than 1/N 2 are 0.5%, 12%, 36%, 54%,
respectively. For each parametrization we tested 5·103 instances
and in Figures 6 and 8 we report the average absolute relative
error. We recall that even though our experiments are conducted
over a ﬁxed family of distributions, e.g., the beta distribution,
by Remark 4 our observations apply to any permutation of
the probability mass “towers” and thus cover a wide range of
query distributions. Speciﬁcally a single benchmark covers all
the N ! possible assignments of probabilities to labels/queries.
As it can be seen in Figure 6 estimator JACKKNIFE-SELFTUNE
is more accurate than VALIANT-VALIANT in the majority of
the tested settings. The above measurements experimentally
conﬁrm the guarantees of Theorem 1 since a sublinear number
of queries is enough to predict the existence of unobserved
search tokens except the ones that have probability less than
1/N. Another observation is that the maximum tested number
of observed search tokens, i.e., 500N, resulted in a relative
error that is close to the percentage of search tokens with
probability less than 1/N 2.
Interestingly, for the case of uniform query distribution the
VALIANT-VALIANT estimator is signiﬁcantly more accurate
when the number of samples is sublinear. Based on this
observation we propose a “modular-estimator” to achieve the
best of both worlds, an agnostic non-parametric estimator that
deploys (1) the VALIANT-VALIANT when the query distribution
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:12:16 UTC from IEEE Xplore.  Restrictions apply. 
1229
r
o
r
r
E
e
v
i
t
l
a
e
R
0.5
0.4
0.3
0.2
0.1
0.05
0
Beta( 1 , 1 ), N=103
Jackknife Estimator
Valiant-Valiant Estimator
102
5 102
103
5 103
104
Number of Queries (Log Scale)
1
0.8
0.6
0.4
0.2
r
o
r
r
E
e
v
i
t
l
a
e
R
0.05
103
Beta( 1 , 1 ), N=105
Jackknife Estimator
Valiant-Valiant Estimator
104
5 104 105
5 105 106
Number of Queries (Log Scale)
Fig. 8. Comparison of estimators under uniform query distribution.
is uniform and (2) the JACKKNIFE-SELFTUNE otherwise.
√
Modularity via Property Testing. Our estimator is Algo-
rithm 1 (MODULAR-ESTIMATOR). The work of Goldreich
and Ron [26] introduced a property testing [25] technique
called collision-probability tester that given a sample from an
unknown distribution it tests whether the sample originated
from a distribution that is -afar from the uniform over [1, N ].
Diakonikolas et al. [19] showed a tight upper bound on
the sample complexity of O(
N /2) which proves sample-
optimality. The collision-probability tester takes as parameters
the desired error  the sample D and the support size N as an
input. Unfortunately, in our setup we do not know N therefore
in our algorithm we use the output of VALIANT-VALIANT
as an approximation ˆN to perform the collision-probability
tester. Our approach is modular in the sense that different
modules, i.e., estimators, are used for different “shapes” of
query distributions. For concreteness we chose 0.1 as the
threshold of the signiﬁcance level of hypothesis testing, per
recommendation of [7], and a ﬁxed error  for the collision-
probability tester but these quantities can be tuned differently.
Algorithm 1: MODULAR-ESTIMATOR
Input: Multiset of m search tokens D sampled according to pT|R
Output: Estimation of the support size ˆN
1 Deploy VALIANT-VALIANT estimator with input D and get ˆNV ;
2 Compute number of collisions c← |{j < k : k ∈ [2, m], tj = tk}|;
3 Set the error parameter for the tester  ← 1/ ˆNV ;
4 if c/
5
6 end
(cid:3) ≤ (1 + 22)/ ˆNV then // collision prob. tester
7 Set number of unique tokens based on ﬁngerprint d ←(cid:4)m
// Deploy JA C K K N I F E-SE L FTU N E;
8 for i ← 1 to 9 do
return ˆNV since it passed the tester
(cid:2)m
i=1 fi;
2
k
− α(i)
k , where α(i)
k is the k-th coefﬁcient of the
(cid:7)
Set bk ← α(i+1)
ˆNJ(i+1) − ˆNJ(i) ←(cid:4)m
jackknife estimator of order i, see Equation (1);
(cid:6)(cid:4)m
(cid:5)var( ˆNJ(i+1) − ˆNJ(i)|d) ← d
k=1(bk)2fk − ( ˆNJ(i+1)− ˆNJ(i))2