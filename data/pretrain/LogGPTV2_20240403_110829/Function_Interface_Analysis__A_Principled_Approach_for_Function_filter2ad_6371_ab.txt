entry checks are described in the next section. For function
exits, our checks relate to the stack discipline. Speciﬁcally,
the stack pointer value at the jump shouldn’t be lower than
its initial value on function entry. Otherwise, local storage
allocated in the function wouldn’t have been freed, suggesting
an intra-procedural jump.
In addition to determining function ends, tail call identiﬁca-
tion serves a second important purpose: enumerating function
starts that are reached only through jumps.
VI. INTERFACE PROPERTY CHECKING
For potential functions reached only via jumps or indirect
calls, we identify a set of checks to determine if the targets
are indeed functions. These checks can relate to control-ﬂow
or data-ﬂow properties, as described further below.
VI-A. Control Flow Properties
These properties are designed to identify control transfers
into (or out of) a function body that do not conform to a
function interface. A function candidate is ﬂagged as spurious
when such non-conformant control transfers are discovered.
Function entries. We rule out known intra-procedural control
transfer targets from being function starts. In particular, table
jumps are intra-procedural control ﬂow transfers as they result
from switch-case statements. Hence, table jump targets are
ruled out as possible function starts. Since our jump table
analysis is designed to identify deﬁnite table jump targets, it is
safe to remove them from the list of possible function starts.
Function exits. Our second control ﬂow check examines each
return instruction to determine if it will transfer control to the
address stored on top of the stack at the function entry point.
In most cases, our static analysis can accurately reason
about stack pointer value at function exits. Even functions
that change their stack pointer by an unbounded amount (e.g.,
due to alloca) typically pass the check: they contain an
instruction to move esp to ebp near their start, and another
to move ebp back to esp near their end. Our static analysis
can hence conclude that the return address will be read from
the same location where it would have been stored by the
805ce70 :
805ce70:
805ce71:
805ce72:
805ce73:
...
805d900:
805d901:
805d902:
805d903:
805d904:
push
push
push
push
...
pop
pop
pop
pop
ret
%ebp ; real func start
%edi
%esi
%ebx
%ebx ; +4 ; spurious func start
%esi ; +8
%edi ; +12
%ebp ; +16
Fig. 3.
Incorrect return address is used for a spurious function
8081130 :
...
8081136:
...
8081a10:
8081a14:
8081a1b:
...
...
sub
...
mov
mov
call
...
$0x533c,%esp
%edi,0x4(%esp) ; spurious func start
$0x80e6718,(%esp)
807c8d0
Fig. 4. “Return address” is overwritten for a spurious function
call instruction used to enter the function. Coupled with an
analysis of stores on stack, it is possible to determine if this
location was preserved during function execution.
The main purpose of function exit check is to ﬂag spurious
functions, i.e., our focus is on detecting violations of this
property. To illustrate its use, consider the code snippet in
Fig. 3. In this snippet, 0x805ce70 is a real function start,
while 0x805d900 isn’t. They are both enumerated as potential
function starts. However, function [0x805d900, 0x805d904]
is detected as spurious by our analysis, as its return address
comes from a location 16 bytes above the correct stack slot.
Fig. 4 shows our second example. In this code, address
0x8081a10 is enumerated as a potential function start. How-
ever, since its “return address” is overwritten at 0x801a14,
the “function” can never return to the intended return address.
Hence 0x8081a10 is ﬂagged as spurious function start. Note
that in the context of the real function starting at 0x8081130,
the instruction at 0x801a14 does not modify the return slot,
so 0x8081130 isn’t ﬂagged spurious.
Internal Instructions. A function’s internal
instructions
should not be targeted by control ﬂows from outside. An
exception arises in the case of multi-entry functions, but
even then, these alternate entry points must be targeted by
inter-procedural control transfers. In contrast, if an internal
instruction of a function f is targeted by an intra-procedural
transfer from another function g, that provides strong evidence
that f is likely spurious.
Recall that when we perform interface veriﬁcation for a
function beginning at location f, we start with a traversal of
its body at f. The instructions uncovered by this traversal
constitute the body of f, and any control transfers using intra-
procedural control ﬂow constructs (e.g., table jumps) from
outside this body indicate that f is spurious.
205
Registers
Allowed
argument
Callee-
save
x86-32
Windows
(See
Fig. 6
ebx, esi,
edi, ebp
x86-32
UNIX-like
(See
Fig. 6)
ebx, esi,
edi, ebp
x86-64
Windows
rcx, rdx,
r8, r9
rbx, rsi, rdi,
rbp, r12-r15
x86-64
UNIX-like
rdi, rsi, rdx,
rcx, r8, r9
rbx, rbp
r12-r15
Fig. 5. Register usage summary for calling conventions on different platforms
x86-32 calling convention Argument passing
cdecl, stdcall, pascal
fastcall (Microsoft, GNU)
fastcall (Borland)
thiscall (Microsoft)
Fig. 6. Arguments passing for x86-32 calling conventions
stack
ecx, edx then stack
eax, edx, ecx then stack
ecx then stack
VI-B. Data Flow Properties
Function calling conventions [20] govern the ﬂow of data
between callers and callees of legitimate functions; in contrast,
spurious functions are likely to violate these conventions.
While calling convention checks could be applied to dataﬂows
that take place via registers as well as the stack, our imple-
mentation only targets register-based ﬂows.
Calling conventions on the most common platforms are
summarized in Fig. 5. In this ﬁgure, allowed argument reg-
isters are registers that can be used for passing arguments to
a function, therefore used for inwards data ﬂow. On the other
hand, callee-save registers are those registers whose values
need to be saved before being used in a function, and restored
before the function returns.
Note that on x86-32 allowed argument registers are calling
convention speciﬁc, and the details are presented in Fig. 6.
To compute a reference set, we take the union of all calling
conventions. Therefore, the resultant allowed argument regis-
ters are eax, edx, and ecx. Any dataﬂow from a caller to a
callee via other registers would be in violation of all calling
conventions, thus indicating a spurious function.
Static Analysis for Argument Registers.
If a register is live at a “function” start, it is potentially
an argument register. This is because a live register indicates
its use is before its deﬁnition in the “function” body. Conse-
quently, it must have been deﬁned before the function being
called and information is passed through it. However, there
is an exception: callee-save instructions at function beginning
“use” callee-save registers with the purpose of preserving them
to stack. Since this does not represent information passing,
they should not be considered as real uses. Our analysis adopts
a simple strategy by not considering register saves on the stack
as a use of the register. Speciﬁcally, if a register is saved to
an address less than the value of the stack pointer at function
entry, then it is not treated as a use of that register.
Note that a special case for argument register checking is
that EFLAGS are not used for passing information. Therefore,
a live ﬂag also suggests a spurious function.
A concrete example for argument register checking is shown
in Fig. 4. For the entry point 0x8081a10, a non-permitted
805ce70 :
805ce70:
805ce71:
805ce72:
805ce73:
...
805d900:
805d901:
805d902:
805d903:
805d904:
push
push
push
push
...
pop
pop
pop
pop
ret
%ebp ; real func start
%edi
%esi
%ebx
%ebx ; +4 ; spurious func start
%esi ; +8
%edi ; +12
%ebp ; +16
End state (for “function”
[0x805d900, 0x805d904]
Initial
state
ebx = EBX ebx = *(ESP)
esi = ESI
edi = EDI
ebp = EBP
...
esi = *(ESP + 4)
edi = *(ESP + 8)
ebp = *(ESP + 12)
...
ret addr = *(ESP + 16)
End state (for “function”
[0x805ce70, 0x805d904]
ebx = EBX
esi = ESI
edi = EDI
ebp = EBP
...
ret addr = *(ESP)
Fig. 7. The analysis states of example code
argument register (edi) is live, thus ﬂagging it as spurious.
Static Analysis for Callee-saves. To check value preservation
for callee-save registers, we keep track of register and memory
values by performing an abstract
interpretation [14]. Our
abstract domain is similar to the one described by Saxena et
al [32]. In short, each domain element is a sum of a symbolic
base which denotes the original register value on function
entry, and a constant. The analysis produces at the function
end the abstract value of each register and memory location,
and how it has changed against the initial value.
Fig. 7 shows the initial and end states from our analysis of
an example snippet. In this ﬁgure, the capitalized REG is the
symbolic value denoting the initial value of reg upon function
entry. The right two columns show the end states for “func-
tion” [0x805d900, 0x805d904] and [0x805ce70, 0x805d904],
respectively. For “function” [0x805d900, 0x805d904], since
registers ebx, esi, edi, ebp do not preserve their values but
instead get new values from “return address” (location [ESP
+ 0]) and “stack argument” region (location [ESP + 4] to
[ESP + 12]) , it is recognized as spurious. On the other hand,
“function” [0x805ce70, 0x805d904] passes callee-save register
usage checking. Note that in case register values end up with
TOP, our analysis conservatively concludes no violations.
Note that
in above two examples (Fig. 3 and Fig. 4),
spurious functions violate both control ﬂow and data ﬂow
properties. This is not always the case — sometimes only
a single interface checking technique is effective. Thus, by
combining these checks, we signiﬁcantly decrease the odds of
spurious functions passing all checks.
VII. EVALUATION
VII-A. Data Set
We used three data sets for evaluating our system.
Data Set 1. The ﬁrst data set is the same as that used by
machine learning based approaches, namely, ByteWeight [7]
206
x86-32
Function start
x86-64
overall
F1
x86-32
Function boundary
x86-64
P
R
F1
Tool
0.9841 0.9794 0.9817 0.9914 0.9847 0.9880 0.9849 0.9278 0.9229 0.9253 0.9322 0.9252 0.9287 0.9270
ByteWeight
0.9956 0.9906 0.9931 0.9880 0.9780 0.9830 0.9881 0.9775 0.9534 0.9653 0.9485 0.8991 0.9232 0.9443
Neural
0.9978 0.9920 0.9948 0.9960 0.9948 0.9954 0.9951 0.9865 0.9809 0.9837 0.9912 0.9900 0.9906 0.9871
Ours
Error ratio 2.0000 1.1750 1.3269 2.1500 2.9423 2.6086 2.4286 1.6667 2.4398 2.1288 5.8523 7.4800 7.5851 4.3178
F1
F1
F1
R
R
R
P
P
P
overall
F1
Fig. 8. Function start and boundary identiﬁcation results from different tools
and the work of Shin et al [35]. Since our current imple-
mentation is limited to Linux ELF binaries, the comparison
focuses on the subset of the results for this platform. Note
that
the vast majority (2064 of 2200) of the binaries in
this data set were on Linux, so our results do cover over
90% of the data used in these works. These 2064 binaries
correspond to binutils, coreutils and findutils. They
are compiled with GNU (gcc) or Intel (icc) compilers, from
no optimization to the highest optimization level for both x86-
32 and x86-64 architectures. These binaries include around
600,000 functions in total, with a total size over 280MB.
Despite its size, this data set is found to be skewed by a
recent work [5]. Speciﬁcally, since many binaries are from the
same package, they share a signiﬁcant number of functions.
This gives machine learning techniques advantages because
functions used for learning and testing signiﬁcantly overlap.
Nevertheless, we use this data set in order to provide a direct
comparison with machine learning approaches.
Data Set 2. Our second data set is the set of SPEC 2006
programs. As compared to the ﬁrst data set, which are mostly
operating system utilities written in C, SPEC programs are
more diverse in terms of their applications, as well as the
programming languages used (C, C++, Fortran). Moreover,
unlike the ﬁrst data set, SPEC programs rarely share functions
with each other. To compile these programs, we used the GCC
compiler suite (gcc, g++, and gfortran) and LLVM (clang,
clang++), and compiled with all optimization levels (O0-O3).
Data Set 3. Our third data set
is the GNU C library,
which is a suite of functionally related shared libraries (24
in total), including libc.so, libm.so, libpthread.so, etc.
This is a more challenging data set for two reasons. First, the
code is low-level and contains many instances of hand-written
assembly. Second, the binaries are in the form of position
independent code (PIC). We used GCC -O2 to compile for
both x86-32 and x86-64 architectures.
VII-B. Metrics
We use the same metrics, precision, recall, and F1-score
as in previous work [7, 35]. Their deﬁnitions are as follows.
In these equations, TP denotes the number of true positives
for identiﬁed functions, FP denotes false positive, while FN
denotes false negatives.
Recall =
T P
T P + F N
(1)
207
Note that recall captures the fraction of functions in the
binary that are correctly identiﬁed by an approach.
P recision =
T P
T P + F P
(2)
Note that precision represents the conditional probability
that a true function has been identiﬁed whenever our approach
reports a function.
Typically, these two metrics are combined using a harmonic
mean into a quantity called F1-score:
F 1 =
2 · P recision · Recall
P recision + Recall
(3)
VII-C. Implementation
Our main analysis framework is implemented in Python, and
consists of about 4100 lines of code. For the disassembler, we
used objdump and reimplemented the error correction algo-
rithm from BinCFI [45]. The main framework also includes all
major components described, including function start identiﬁ-
cation, function body traversal, and part of interface checking.
Our current analysis engine is based on angr [36].
We used angr mainly because it is a comprehensive binary
analysis platform, and supports both x86-32 and x86-64. We
built our customized analysis on top of angr, but not using
any of its built-in function recovery algorithms. In fact, their
accuracy is well under the best published results from machine
learning systems [7, 35] and Nucleus [5] (which we compare
in the following sections), probably because the primary goal
of angr is for offensive binary analysis [36], rather than robust
recovery of program constructs in benign binaries.
VII-D. Summary of Results
Fig. 8 summarizes function start and boundary identiﬁcation
results for the ﬁrst data set. Since for this data set the two
machine learning works [7, 35] have best published results
and outperformed previous tools (such as IDA and Dyninst
Tool
Ours
Nucleus
F1
0.92
R
0.89
x86-64 binaries
x86-32 binaries
Dataset &
compiler
SPEC
(GCC)
SPEC
(LLVM)
GLIBC
0.9846 0.9914 0.9879 0.9804 0.9840 0.9817
(GCC)
Fig. 9. Function boundary identiﬁcation results for SPEC 2006 and GLIBC.
F1
P
0.97
0.93
0.9988 0.9869 0.9927 0.9952 0.9861 0.9905
0.95
0.90
0.9978 0.9933 0.9955 0.9934 0.9902 0.9918
P