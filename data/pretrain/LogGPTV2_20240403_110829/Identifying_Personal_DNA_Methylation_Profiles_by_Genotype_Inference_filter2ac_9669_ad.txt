edges of each interior node partition the node’s input domain
into two distinct sets. Each leaf node of the tree is labeled with
a class yj. It is worth noting that a single class may occur at
more than one leaf.
In order to classify an input using a classiﬁcation tree, one
starts at the root node and walks down the tree until a leaf
node is reached. At each interior node, the decision which
edge to select is determined by the partition to which the
corresponding input value belongs. Finally, the class label
of the leaf node determines the result of the classiﬁcation
task. In the following, we will focus on the most common
form of classiﬁcation trees as implemented in many libraries:
binary classiﬁcation trees in which the partitioning at each
interior node is given by a comparison of the input value
with a threshold wi. The model of such a classiﬁcation tree
is completely described by the structure of the tree, the input
values vi corresponding to each node, as well as the thresholds
wi applied at each node.
2) Random Forests: Classiﬁcation trees usually suffer from
a high prediction variance and can easily suffer from overﬁt-
ting to their training set. In order to reduce the prediction
variance, random forests put
together multiple noisy, but
approximately unbiased classiﬁcation trees.
In general, a random forest consists of B classiﬁcation
trees, where the number B is subject to tuning. The training
of a random forest is performed on a training dataset T =
{((cid:2)x1, y1), . . . , ((cid:2)xn, yn)}, consisting of n samples together with
their corresponding class label. During the training, each tree
is grown on n randomly chosen (with replacement) training
samples using only a randomly chosen set of input predictors
(components of the training samples) K ⊆ {1, . . . , len((cid:2)x)}.
This random subset of input predictors is what distinguishes
random forest from simple tree bagging and ensures the trees
to be de-correlated so that the same input predictors are not
used in all of the trees. This step is important to reduce the
correlation of the trees, which then enables further reduction
of the prediction variance [33].
Given a random forest model and an input (cid:2)v, the classiﬁca-
tion algorithm evaluates each of the model’s trees individually.
Then, depending on the application, implementation or pref-
erence, the resulting class can be determined by plurality vote
(or majority vote for binary classiﬁcation), averaging the class
predictions or providing class probabilities in terms of relative
vote counts.
B. Private Classiﬁcation with Random Forests
Next, we introduce our construction that enables to securely
evaluate random forests between a third party and a querier.
More speciﬁcally, we do not want the querier (referred to as
client) to learn the structure of the trees, nor should the third
party (referred to as server) learn anything about the input
sample or the result of the classiﬁcation.
We build our construction on top of the work of Bost et
al. [23] and extend it to work with random forests. In their
work,
they introduced three major classiﬁcation protocols,
namely for hyperplane decision, Na¨ıve Bayes, and classiﬁ-
cation trees, all satisfying the constraint to keep both the
classiﬁer model and the data conﬁdential. Since classiﬁcation
trees are an important component of random forests, we ﬁrst
recap the details of the classiﬁcation tree protocol, before
extending it to random forests.
It is important to note that the classiﬁer is trained upfront
on data in the clear, whereas only the actual classiﬁcation of
new samples is performed securely on encrypted data.
1) Cryptosystem and Notation: In the following, we will
rely on three different additively homomorphic public-key
cryptosystems. An additively homomorphic public-key en-
cryption scheme allows, given the two encrypted messages
Enc(a) and Enc(b), to compute Enc(a + b) using a public-
key operation on the encrypted messages. Moreover, one of
our cryptosystems is a leveled fully homomorphic encryption,
which also allows to perform a bounded number of multi-
plications in sequence, i.e., to compute Enc(a · b) on the
encrypted messages. Bounded means that the cryptographic
scheme allows to evaluate polynomials only up to a certain
multiplicative depth L. Below, we list the cryptosystems we
use and also mention the corresponding plaintext spaces M:
cryptosystem of
1) the QR (Quadratic Residuosity)
Goldwasser-Micali [36] (M = F2, bits),
965
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:45 UTC from IEEE Xplore.  Restrictions apply. 
2) the Paillier cryptosystem [37] (M = ZN with N being
the public modulus of Paillier),
3) a leveled fully homomorphic encryption (FHE) scheme
based on the Brakerski-Gentry-Vaikuntanathan [38]
scheme as implemented by HELib [39] (M = F2).
We denote the client in our protocols by C and the server
by S. [b]A denotes a bit b encrypted by the QR scheme under
party A’s key (so only A can decrypt the message using her
secret key). Similarly, [[m]]A denotes an integer m encrypted
by the Paillier scheme, and [[[b]]]A denotes a bit b encrypted by
the leveled FHE scheme. SKs
A is used for party A’s secret key
for the encryption scheme Paillier (s = P ), QR (s = QR) or
leveled FHE (s = F HE), and PKs
A is the respective public
key. For a distribution D, a ← D means that we assign a a
random sample from that distribution.
2) Cryptographic Assumptions and Adversarial Model:
The security of our protocol relies on the semantic secu-
rity [40] of the cryptosystems we use and, hence, also on the
well-studied assumptions underlying those systems, namely
the Quadratic Residuosity assumption, the Decisional Com-
posite Residuosity assumption, and the Ring Learning With
Errors (RLWE) assumption.
We prove our protocol
to be secure in the two-party
computation framework for passive adversaries (or honest-but-
curious [40]), by relying on modular sequential composition
of smaller protocols as described below.
3) Building Blocks: Speciﬁcally, we will reuse existing
building blocks from the work of Bost et al. and also design a
new one that is needed for our protocol: changing encryption
ownership. Their work already introduced several smaller
building blocks, such as different comparison protocols on
encrypted data, or a protocol to evaluate the arg max function
on encrypted data. Those building blocks necessary for our
own construction are brieﬂy reviewed hereunder, before we
introduce our own building blocks as well as the full con-
struction.
a) Comparison Protocols: Bost et al.
introduce ﬁve
slightly different comparison protocols,
two of which we
will need in our construction. Let A, B be two parties. A
has PKP
B and B has the corresponding secret keys
SKP
B, PKQR
B, SKQR
B .
The ﬁrst comparison protocol (referred to as (1) later)
assumes that A has two values [[a]]B, [[b]]B. This protocol then
allows to compare a and b, such that A learns [a ≤ b]B and
B learns nothing about the comparison.
the only difference being that B also learns a ≤ b.
The second comparison protocol, (2), works the same way,
More details as well as the other comparison protocols can
be found in [23].
b) arg max on Encrypted Data: Based on their compar-
ison protocol (2), Bost et al. develop a protocol to compute
the arg max on encrypted data. Let A, B be two parties. A
has k encrypted values ([[a1]]B, . . . , [[ak]]B) (where k is also
known to B) and wants to know the arg max over unencrypted
values (i.e., the index i of the largest value ai), but neither
party should learn anything else.
Hence, this protocol allows to compute arg max1≤i≤k ai
given only the values encrypted under B’s key. In particular,
during the computation, B should neither learn the values ai,
nor should B learn the order relations between the ai’s. The
full details of this protocol are described in [23].
c) Changing the Encryption Scheme: In order to convert
ciphertexts from one of the cryptosystems to another, Bost
et al. rely on a simple protocol to change the encryption
scheme. Since this protocol is crucial for essential parts of
our construction, we will provide a more detailed description
of the protocol.
B , SKs2
B , PKs2
First, we consider the case, for which Ms1 = Ms2 = F2,
i.e., the two cryptosystems have the same message space:
Let A, B be two parties, A having PKs1
B and a ci-
phertext c = Encs1 (x). B has the corresponding secret keys
SKs1
B . The goal is to re-encrypt x using the cryptosystem
s2, without B learning x.
Intuitively, the protocol works as follows. First, A uniformly
picks a random noise r ← Ms1, encrypts it using PKs1
B and
adds it to the ciphertext c, before sending the result to B. B
then decrypts the ciphertext to x + r ∈ Ms1, re-encrypts it
using SKs2
B and sends Encs2 (x + r) to A, who can strip off r
using the homomorphic property of s2. B only obtains x + r,
which hides x information-theoretically (this can be seen as a
one-time pad).
(cid:4)= Ms2, we only require the
transformation from Ms1 = F2 to Ms2 = ZN , i.e., from FHE
to Paillier. Here, the beginning of the protocol remains the
same and A obtains [[x ⊕ r]]B with x, r ∈ F2. The important
difference to the previous case now arises when A wants to
strip off r ∈ Ms1 = F2 from the encryption. Since the additive
operation on F2 is ⊕ and on ZN is +, we have to emulate
⊕ in Paillier’s message space. This can be easily done by
computing:
For the second case, when Ms1
(cid:4)
[[x]]B =
[[x ⊕ r]]B
g([[x ⊕ r]]
−1
B ) mod N 2
if r = 0
if r = 1
Before giving the result to an adversary, who knows [[x ⊕
r]]B, but not SKP
B, the obtained result has to be refreshed to
preserve semantic security. A pseudocode implementation as
well as the security and correctness proofs of this protocol can
be found in [23].
d) Private Evaluation of Classiﬁcation Trees: The most
useful protocol is the one for privately evaluating a classiﬁca-
tion tree. Here, the main idea is to represent the classiﬁcation
tree as a polynomial P , whose output is the result of the
classiﬁcation.
Let bi be the boolean outcome of a comparison between the
ith node’s input value vj and the corresponding threshold wi,
i.e., wi < vj. Then, given the class labels Y = {y0, . . . , yk},
one can express a classiﬁcation tree by a polynomial. The
polynomial is constructed recursively by a procedure F(T ).
If T is a leaf node, F(T ) = y, where y is the class label at
the leaf T . If T is an internal node, and T1 is the child tree
in case the corresponding b is true, and T2 is the child tree in
966
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:45 UTC from IEEE Xplore.  Restrictions apply. 
case b is false, then F(T ) = bF(T1) + (1 − b)F(T2) is the
polynomial that evaluates T1 if b and T2 otherwise.
Using this polynomial, Bost et al. then introduce a protocol
to evaluate the tree, while revealing only the outcome and the
number of comparisons. Let S and C denote the server and
client respectively. First, S and C make use of the comparison
protocol (1), so that S learns the bits [bi]C for every node.
Then, they interact in the protocol to change the encryption
scheme from QR to FHE, obtaining [[[bi]]]C.
The server S can then evaluate the polynomial P using
the homomorphic properties of the FHE scheme. However,
since the plaintext space is only F2 and the class labels
potentially take more than one bit, we would have to evaluate
the polynomial for each bit individually. Fortunately, the so-
called SIMD slots of the FHE scheme (described in details
in [41]) allow the scheme to encrypt a vector of bits in one
ciphertext and evaluate the polynomial on the whole vector
at once, in parallel. Hence, for each class label yi, the server
encrypts its bit representation yi0, . . . , yil using these SIMD
slots to [[[yi0, . . . , yil]]]C and can evaluate the polynomial for
each bit in parallel.
The client can later decrypt the resulting class label and
convert it back to the normal integer representation. A more
detailed explanation, as well as proofs of correctness can be
found in [23].
e) Changing Encryption Owner: Next, we will introduce
our protocol to change the ownership of an encryption, which
we will need in order to apply the arg max protocol in a way
that only the client learns the result of the plurality vote.
Given two parties A and B, out of which A holds the en-
crypted message [[x]]B, we want B to hold the same encrypted
message, but this time under A’s key. However, neither A nor
B should learn the message x itself. In the following, we
design a protocol to meet this goal and provide the proof in
the appendix.
B, SKP
B, PKP
Let A have PKP
A, [[x]]B and B have SKP
A. Then
A ﬁrst blinds the encrypted message by uniformly sampling
a random noise r from the plaintext space, encrypting it and
adding it to the ciphertext. Then, A also encrypts r using his
own secret key and sends both [[x + r]]B and [[r]]A to B. B
then decrypts the ﬁrst ciphertext to x + r, which hides x in
an information-theoretic way and encrypts it again using PKP
A.
Then B strips off r using the sent encryptions without learning
r itself and obtains [[x]]A.
The complete protocol is shown in Protocol 1.
967
A, PKP
Protocol 1 Changing Encryption Owner
Input: A : ([[x]]B, SKP
B), B : (PKP
Output: B : [[x]]A
1: A: uniformly pick a random noise r ← MP = ZN
B and
(Paillier’s message space), encrypt
compute [[x + r]]B
it using PKP
A, SKP
B)
2: A: encrypt r using SKP
A to [[r]]A
3: A: send ([[x + r]]B, [[r]]A) to B
4: B: decrypt [[x+r]]B to get x+r and encrypt it using PKP
A
5: B: compute [[x]]A = [[x + r]]A · [[r]]
−1
A using the homomor-
to [[x + r]]A
phic property
Theorem 1. Protocol 1 is secure in the honest-but-curious
model.
The proof of the theorem is provided in the appendix.
4) Private Random Forests: Now that we introduced all
building blocks necessary to privately evaluate a random for-
est, we ﬁrst give an intuition of our protocol before presenting
its pseudocode in Protocol 2.
Intuitively, one could just evaluate each tree of a random
forest individually, given the protocol introduced by Bost et
al., and return the outcomes to the client. The client is then able
to compute the plurality vote or any metric she is interested
in. This, however, will not only leak the number of trees, but
most likely also the number of nodes within each tree to the
client. Indeed, the scheme of Bost et al. reveals the number
of comparisons, thus the number of inner nodes to the client.