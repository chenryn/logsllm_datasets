title:Policing congestion response in an internetwork using re-feedback
author:Bob Briscoe and
Arnaud Jacquet and
Carla Di Cairano-Gilfedder and
Alessandro Salvatori and
Andrea Soppera and
Martin Koyabe
Policing Congestion Response in an Internetwork using
Re-feedback
Bob Briscoe
BT Research & UCL
Arnaud Jacquet
BT Research
Carla Di Cairano-Gilfedder
BT Research
PI:EMAIL
PI:EMAIL
carla.dicairano-
PI:EMAIL
Martin Koyabe
BT Research
Alessandro Salvatori
Eur´ecom & BT Research
PI:EMAIL
Andrea Soppera
BT Research
PI:EMAIL
PI:EMAIL
ABSTRACT
This paper introduces a novel feedback arrangement, termed
re-feedback. It ensures metrics in data headers such as time
to live and congestion notiﬁcation will arrive at each relay
carrying a truthful prediction of the remainder of their path.
We propose mechanisms at the network edge that ensure the
dominant selﬁsh strategy of both network domains and end-
points will be to set these headers honestly and to respond
correctly to path congestion and delay, despite conﬂicting
interests. Although these mechanisms inﬂuence incentives,
they don’t involve tampering with end-user pricing. We de-
scribe a TCP rate policer as a speciﬁc example of this new
capability. We show it can be generalised to police various
qualities of service. We also sketch how a limited form of
re-feedback could be deployed incrementally around unmod-
iﬁed routers without changing IP.
Categories and Subject Descriptors
C.2.0 [Computer-communication networks]: Security
and protection; C.2.1 [Computer-communication net-
works]: Network Architecture and Design
General Terms
Economics, Security
Keywords
Policing, congestion, QoS, characterisation, incentives
1.
INTRODUCTION
The current Internet architecture trusts hosts to respond
voluntarily to congestion; a feature commonly put down to
the environment of mutual trust in which these algorithms
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’05, August  22–26,  2005,  Philadelphia,  Pennsylvania,  USA.
Copyright 2005 ACM 1-59593-009-4/05/0008 ...$5.00.
emerged. Limited evidence shows that the large majority
of end-points on the Internet comply with a TCP-friendly
response to congestion. But if they didn’t, it would be hard
to force them to, given path congestion is only known at the
last egress of an internetwork, but policing is most useful at
the ﬁrst ingress.
Without knowing what makes the current co-operative
consensus stable, we may unwittingly destabilise it. At the
most alarmist, if this were to lead to congestion collapse [7]
there would be no obvious way back. But even now, ap-
plications that need to be unresponsive to congestion can
eﬀectively steal whatever share of bottleneck resources they
want from responsive ﬂows. Whether or not such free-riding
is common, inability to prevent it increases the risk of poor
returns, leading to under-investment in capacity.
In 2000, these capacity allocation and accountability prob-
lems helped to motivate a overhaul of the Internet archi-
tecture [1], but they remain unresolved. We believe their
solution lies in a realignment of the feedback architecture.
Changing the Internet’s feedback architecture seems to
imply considerable upheaval. But, perhaps surprisingly, we
believe a limited form of the new arrangement could be de-
ployed incrementally at the transport layer, around unmod-
iﬁed routers using the existing ﬁelds in IP (v4 or v6). Pro-
tocol engineering isn’t the focus of the present paper—an
idealised numeric scheme is all that is necessary to explain
the concepts. However, to satisfy doubters, we sketch our
engineering and deployment ideas at the end.
Conceptually, the solution could hardly be simpler. We
propose collecting path information in packet header ﬁelds
as data traverses a path, just as can already be done with
time to live (TTL) or congestion notiﬁcation (ECN [19]).
But previously, as each node added characterisation of its
local hop, the header values accumulated upstream path
knowledge. By a simple realignment, we arrange each ﬁeld
to characterise the remaining downstream path. We aim to
reach a target for the metric at the destination, rather than
aligning the datum at the source. For example, TTL cur-
rently always starts at the datum 255. Instead we propose it
should arrive at the destination set to an agreed datum (say
16). To achieve this, each receiver will need to occasionally
feed back the TTL values arriving in packets, so the sender
can adjust the next attempt in order to continue to hit 16.
§2 expands on this basic explanation with more precision.
277We term this pattern ‘re-feedback’, short for either receiver-
aligned or re-inserted feedback, although it is actually simi-
lar to the ordinary feedback found in other disciplines (elec-
tronics, hydraulics, etc.). Once re-feedback is in place, each
packet arrives at each network element carrying a view of
its own downstream path, albeit a round trip ago. So full
path congestion becomes visible at the ﬁrst ingress, where a
rate policer is most useful.
But we still don’t seem to have solved the problem.
It
seems na¨ıve to police traﬃc by trusting ﬁelds that depend
on the honesty of both the sender and receiver—those with
most to gain from lying. However, in §3 we explain why
re-aligning feedback allows us to arrange for honesty to be
everyone’s dominant strategy—not only end-users, but also
networks. Building on the resulting trustworthiness of path
metrics, we describe how to build a rate equation policer,
using TCP as a concrete example. We generalise to any
rate equation, in particular Kelly’s [14], showing that we can
synthesise the same eﬀect as quality of service mechanisms,
but only using an ingress policer. We also describe a passive
policer for inter-domain boundaries.
In §4 we sketch our incremental deployment ideas. Then
we end the body of the paper (§5) with the results of simu-
lations conducted to test whether the incentive mechanism
really is responsive enough to ensure truthful congestion re-
porting. We wrap up with related work and conclusions.
2. RE-FEEDBACK
Characterising paths through networks requires more than
one metric. We have chosen to explain how re-feedback
works using two: congestion and delay (that is, unloaded de-
lay not congestion delay). Re-feedback of just these two met-
rics helps solve a surprisingly large set of networking prob-
lems. But additional metrics might be useful in practice,
e.g. hop count, unloaded loss rate etc. Delay re-feedback is
a useful starting point because it is trivially simple to ex-
plain. Then we use congestion to highlight the similarities
and diﬀerences that are encountered between metrics.
A pre-requisite for re-feedback is the explicit declaration of
path metrics and their maintenance along the path. Setting
aside protocol details for now, it will suﬃce to consider a
multi-bit ﬁeld for delay and another for congestion carried
in future network layer packet headers1. Also equivalent
ﬁelds will be necessary in the end-to-end back-channel from
receiver to sender—sent frequently enough to control the
most volatile metric (congestion). For instance, in future
TCP acks (or RTCP receiver reports, etc.)
Network layer headers will also need a ‘certain’ ﬂag, which
the sender should clear at the start of a ﬂow, when no feed-
back is yet available. Metric(s) carried in uncertain pack-
ets should not contribute to any bulk averaging at network
equipment (e.g. see §3.2.1), but the ﬂag is not intended to
aﬀect forwarding of the packet itself.
Fig 1 introduces our notation. Each path across the net-
0 ≤ ir < nr
work consists of a sequence of resources, ir;
indexed in the context of each path r from the sender S with
resource ir = 0 to resource ir = (nr − 1) just before the re-
ceiver R. Whenever a single path context makes it obvious,
we will drop the suﬃx r.
1We believe it is possible to apply re-feedback in a separate
control plane, or even where control information is analogue,
but for clarity we stick to one IP-based scenario.
S m0
h0(t)
hn(t)
h0( t) 
h0( t+T) 
N mi
hi( t) 
hi+1( t) 
N mn-1
R
hn( t) 
m1,i
m2,i…
N
delay
congestion
…
h1,i 
h2,i…
h1,i+1 
h2,i+1…
Figure 1: Notation for path characterisation metrics
m and headers h.
242
S1
0
a)
– 242
+   255 + 16
S1
0
b)
255
250
249
N1
5
N2
1
0
242
R1
245
7
N5
252
S2
0
245
N3
1
255
29
N1
5
24
N2
1
0
2
N4
3
254
23
S2
0
+   255 + 16
26
– 245
15
N3
2
26
27
2
N4
3
24
25
R2
16
R1
15
16
R2
7
N5
22
23
Figure 2: Network ﬂows carrying unloaded delay in
packet headers. a) With classic feedback, sources
initialise headers to 255. b) With re-feedback over
the same network, sources set headers so as to reach
16 at the destination.
The unloaded delay header, h1, is carried in packets from
resource to resource. Each relay N characterises its local
resource’s contribution to the delay—perhaps by echo tests
with the downstream neighbour. It contributes to the whole
path delay by combining its local contribution m1,i with the
incoming header value, h1,i, and forwarding the updated
result, h1,i+1 (Fig 1). The choice of combining function
depends on the metric in question. As unloaded delay is
additive, subtraction is an appropriate combining function
(like TTL processing), h1,i+1 = h1,i − m1,i.
Other packet header ﬁelds will require combining func-
tions appropriate to the metrics they represent. The inset
in Fig 1 shows packets carrying header ﬁelds for both delay
and congestion being combined with the local metrics for
each, as parallel, independent operations. Where the con-
text is obvious, we drop the suﬃx that distinguishes between
delay and congestion.
If we introduce feedback of unloaded delay, the receiver
will report the header values it receives back to the sender.
With classic feedback, the sender always initialises the un-
loaded delay header to a well-known value, say h0 = 255,
as shown in Fig 2a). The header will arrive at node j
with a value accumulated over all the upstream resources
i=0 mi. We call the composition of all the local
hj = h0 −(cid:1)j−1
metrics mi experienced by a packet the path metric
So, with classic feedback for delay, the path metric up-
combining function at resource i,
hi+1 = g(hi, mi)
header initialisation function at source,
h0(t+T ) = f (h0(t), hn(t))
downstream path metric at resource j,
ρj(hj(t+T ))
unloaded delay
hi − mi
h0(t) − hn(t) + hz
hj(t+T ) − hz
congestion
1 − (1 − hi)(1 − mi)
1 − (1−hz )(1−h0(t))
(cid:3)
(cid:2)
1−hn(t)
1 − 1−hz
1−hj(t+T )
s
Eqn
(6)
(9)
(10)
Table 1: The functions g(·) & f (·) required to implement re-feedback and ρ(·) to exploit it, summarising results
from §2 & Appendix A, where notation is formally deﬁned.
As with delay, the combining function for each relay to
accumulate local congestion into headers (ﬁrst row) must
be chosen to reﬂect the way congestion accumulates. In Ap-
pendix A.1 we deﬁne congestion as a probability, using ax-
iomatic deﬁnitions2. So, as shown, we must use the function
for combinatorial probability to combine congestion headers.
For either delay or congestion, the combining function at
relays can be the same as for classic feedback, as the pur-
pose is still to accumulate a path metric from local metrics.
By avoiding arbitrary changes to the classic combining func-
tions, re-feedback can be introduced incrementally, solely by
arrangement between corresponding endpoints.
Each initialisation function (second row) ensures the header
reaches hz at the destination, given the way it accumulates
along the path. Each function in the third row was derived
from the previous two in order to predict the downstream
path metric (DPM) from any node.
Note that neither prediction of DPM requires path state,
only the state arriving in the packet itself. Further note
that, for congestion, the DPM ρj also depends on the ef-
fective packet size s. For bit-congestible resources like links
s = actual packet size. For packet-congestible resources like
forwarding look-ups s = 1.
Fig 2 also illustrates how a change on a path aﬀects the
predictions in packets traversing it. The increase in delay at
resource N3 between Figs 2a) & b) (highlighted as a star-
burst) causes packets in ﬂight upstream to underestimate
their remaining downstream delay. Packets in ﬂight down-
stream still correctly predict their downstream delay, but
when feedback from them releases further packets, these un-