title:Kal\(ε\)ido: Real-Time Privacy Control for Eye-Tracking Systems
author:Jingjie Li and
Amrita Roy Chowdhury and
Kassem Fawaz and
Younghyun Kim
Kaleido: Real-Time Privacy Control for Eye-Tracking Systems
Jingjie Li, Amrita Roy Chowdhury, Kassem Fawaz, and Younghyun Kim
University of Wisconsin–Madison
{jingjie.li, roychowdhur2, kfawaz, younghyun.kim}@wisc.edu
Abstract
Recent advances in sensing and computing technologies have
led to the rise of eye-tracking platforms. Ranging from mo-
biles to high-end mixed reality headsets, a wide spectrum
of interactive systems now employs eye-tracking. However,
eye gaze data is a rich source of sensitive information that
can reveal an individual’s physiological and psychological
traits. Prior approaches to protecting eye-tracking data suf-
fer from two major drawbacks: they are either incompatible
with the current eye-tracking ecosystem or provide no formal
privacy guarantee. In this paper, we propose Kaleido, an eye-
tracking data processing system that (1) provides a formal
privacy guarantee, (2) integrates seamlessly with existing eye-
tracking ecosystems, and (3) operates in real-time. Kaleido
acts as an intermediary protection layer in the software stack
of eye-tracking systems. We conduct a comprehensive user
study and trace-based analysis to evaluate Kaleido. Our user
study shows that the users enjoy a satisfactory level of utility
from Kaleido. Additionally, we present empirical evidence
of Kaleido’s effectiveness in thwarting real-world attacks on
eye-tracking data.
1 Introduction
Recent advances in sensing and computing technologies have
facilitated the rapid adoption of eye tracking as a hands-free
interface in augmented, virtual, and mixed reality settings. It
offers users control over virtual components [84], events [51],
and digital avatars [80], especially in settings where hand-
based control is either impractical or infeasible [89]. In-
teractive systems are now capable of performing continu-
ous eye tracking using off-the-shelf webcams [66], smart-
phones [61], tablets [32], desktops [62], wearable glasses [93],
and mixed reality headsets such as the HTC VIVE and Mi-
crosoft HoloLens.
From a stream of eye gaze positions in a scene, eye-tracking
applications precisely estimate what the user is viewing to
trigger events, prefetch scenes, or perform actions in the vir-
No privacy (ε=∞) 
(a) Raw data 
Low privacy (ε=3) 
High privacy (ε=0.5) 
(b) Noisy data from Kalεido
Figure 1: Eye gaze heatmaps from an individual user with
and without Kaleido’s noising effect on a web page.
tual environment. One’s eye gaze streams, however, are vul-
nerable to potential privacy threats. Previous research has
demonstrated that psychological and physiological factors
direct the formation of unique patterns in the user’s eye gazes.
For instance, researchers were able to infer insights about
the user’s behavioral traits [49, 75, 77], diagnose Alzheimer’s
disease and autism spectrum disorder [30, 41], understand
the user’s familiarity of a scene [78], infer mental status dur-
ing social interaction [76], detect personality traits [10], and
deliver personalized advertisements [16, 24, 92].
Third-party applications that use eye gaze streams can ex-
tract information beyond their intended core functionality,
posing signiﬁcant privacy threats to the users. For example,
Figure 1(a) shows the heatmap of eye gazes on a web page
from an individual user. While an application can help the
user scroll up/down the web page, the aggregated eye gaze
positions can reveal the user’s interest. Unfortunately, the
eye-tracking platforms do not offer users the ability to con-
trol their privacy. They relay the raw eye gaze streams to the
applications without much regard to the embedded sensitive
information.
Researchers have developed privacy-preserving mecha-
nisms for eye gaze streams [12, 13, 29, 53, 79] to alleviate
these concerns. These mechanisms share a similar working
principle: allowing access to only some high-level “features”
of the eye gaze streams, possibly with some added noise, in-
stead of the raw gaze streams. While some of them provide
formal privacy guarantees [12,53,79], they are mostly imprac-
tical to deploy due to multiple limitations. First, they require
modiﬁcation of the eye-tracking application programming
interfaces (APIs) since the applications expect to receive a
sequence of raw eye gaze positions, not just features. Second,
processing eye gaze streams to extract features does not hap-
pen in real-time, affecting the user experience. Third, they
require the user to control a set of parameters that are hard to
understand for most users. In short, the question of how to pro-
vide a backward-compatible, easy-to-use privacy-preserving
system for real-time eye tracking is still an open one.
In this paper, we design, implement, and evaluate Kaleido
as an afﬁrmative answer to the above question. Kaleido pro-
vides a formal privacy guarantee based on differential privacy
(DP) [21], the de-facto standard for achieving data privacy. To
the best of our knowledge, Kaleido is the ﬁrst system to (1)
provide a privacy guarantee on raw eye gazes, (2) seamlessly
integrate with the existing eye-tracking ecosystem, and (3)
operate in real-time. Kaleido offers the following advantages:
• Formal privacy guarantee. Kaleido uses a differentially
private algorithm to release noisy eye gaze streams to the
applications, which protects the spatial distribution of a gaze
trajectory that is formed within any window of a speciﬁc
duration (as determined by the users). Kaleido achieves this
objective by bringing the privacy semantics from two distinct
contexts, absolute location data and streaming event data,
into the domain of eye gaze data (Section 4.3.3). Figure 1(b)
shows Kaleido’s privacy protection in action.
• Seamless integration with the eye-tracking ecosystem.
As Kaleido operates on raw eye gaze streams, it ﬁts within
the existing ecosystem of eye-tracking applications. It is also
platform- and application-agnostic; it operates on popular
eye-tracking platforms and requires no modiﬁcation of the
applications, making it more practical to deploy.
• Ease of use. As the parameters of Kaleido’s privacy guar-
antee are a function of the visual feed semantics, it reduces
the burden of complex privacy conﬁguration on the user.
We integrate Kaleido as a Unity [26] plugin; it acts as a pro-
tection layer between untrusted applications and trusted plat-
forms. Unity is the mainstream engine for gaming and mixed
reality applications; it supports various peripherals such as
eye-tracking sensors. Kaleido’s architecture comprises four
major components: (1) context processing core, which extracts
scene semantics from keyframes of dynamic visual feed; (2)
conﬁguration manager, which automatically conﬁgures the
parameters of the DP guarantee based on scene semantics
and user preferences; (3) noisy gaze generator which gener-
ates noisy gaze streams; and (4) noisy gaze processor, which
performs local post-processing on the noisy gaze streams.
The Kaleido plugin leverages off-the-shelf APIs and comput-
ing blocks, providing backward compatibility across a broad
spectrum of applications and platforms.
We conduct a user study and trace-based analysis to eval-
uate Kaleido. To understand perceived utility, we investigate
ROI
Saccade
Fixation
Figure 2: Example of ﬁxations, saccades, and ROIs in a
scene [52], where the blue dots represent individual gazes and
purple (grey) dashed circles represent ﬁxations (saccades).
the user experience of a real-time eye-tracking game with
Kaleido. The quantitative and qualitative feedback indicates
a minor impact on users’ game performance and satisfac-
tion. The users show a high incentive to adopt Kaleido and
its control knob for eye-tracking privacy. Furthermore, we
validate that Kaleido can successfully thwart various adver-
sarial analytics, aiming to identify unique traits from users’
eye gazes. Even with modest privacy levels, Kaleido can drive
the attacker’s accuracy close to random baselines.
2 Background on Eye Tracking
2.1 Properties of Eye Gaze
Eye gaze data, commonly represented as a stream of gaze
positions projected onto a visual scene, reﬂects how people
explore and process the visual content. Typically, eye gaze
data is abstracted as a scanpath, which captures the character-
istics of the user’s visual attention [68]. A scanpath is a time
sequence of ﬁxations that are separated by saccades [8, 82].
Fixations represent clusters of gazes concentrated around spe-
ciﬁc regions in the scene (such as an object). Saccades denote
gazes traveling rapidly from one ﬁxation to another. A re-
gion in the scene space that attracts human attention [58] is
referred to as a region of interest (ROI). Figure 2 illustrates
ﬁxations, saccades, and ROIs in a scene.
2.2 Eye-Tracking Platform
Two of the most popular techniques for acquiring real-time
eye gaze [56] are: vision-based tracking and infrared pupil-
corneal reﬂection tracking. The former estimates gaze posi-
tions from the captured images of the eyes; the latter projects
infrared light onto the eyes and estimates the point of gaze
from the pupil and corneal reﬂections. The raw measurement
data is represented as a stream of tuples hx,y,ti, where x and
y represent the 2D coordinates of its location on the visual
scene (corresponding to a pixel of the image), and t is the
associated timestamp [47, 83, 86].
Eye-tracking platforms [37, 45] incorporate eye-tracking
with development engines, such as Unity. The platform ex-
poses eye gaze streams to user applications through prede-
ﬁned APIs. An application session is the duration of user
interaction with the platform to perform a task, such as play-
ing a game or browsing a document. Each session is a series of
scenes where the visual content remains relatively unchanged
(e.g., part of the same panoramic view).
Each application deﬁnes its interaction semantics based on
the eye gaze streams. Examples include eye gaze-based input
and selection [84], active event triggering by eye gaze ges-
tures [51], automatic scene switching during browsing [46],
foveated rendering [6,67], and virtual social interaction using
digital avatars [80].
2.3 Privacy Threats
Eye gaze patterns inherently reﬂect human traits and carry
sensitive information about the user. While the applications
would primarily process eye gaze streams for user interaction
purposes, accumulating the data over multiple sessions can
result in privacy threats. Below, we discuss some examples of
possible psychological and physiological inferences that can
be drawn from eye gaze streams.
Absolute gaze distribution on a scene. The spatial distri-
bution of absolute gaze positions on a scene can reveal in-
sights about the individual’s cognitive process of exploring
speciﬁc visual content. Fixations and saccades within and
between ROIs reﬂect how an individual’s attention moves
within a scene – revealing cues about one’s interest. For ex-
ample, gaze patterns on merchandise can enable precision
marketing and personalized recommendations in consumer
research [16, 24, 92]. Other researchers have attributed indi-
viduals’ ﬁxation patterns to their psychological state, such
as lying about recognizing a face [60, 78]. Further, individ-
uals with different physiological and cultural backgrounds
demonstrate distinguishing characteristics depending on the
ROI features such as color, texture, and semantics [3, 70].
Aggregate statistics on gaze distribution over time. The
statistical characteristics or features of scanpaths computed
over a period of time, such as ﬁxation duration/rate and
saccade speed/acceleration, can reveal sensitive informa-
tion about an individual. For example, the length of sac-
cades can help in categorizing ﬁxations into different func-
tional groups, including “locating,” “guiding,” “directing,”
and “checking,” which reveal one’s behavioral traits while
performing daily tasks, such as interpersonal communica-
tion [49, 75, 77]. Diseases such as autism spectrum disor-
der [30] and Alzheimer’s [41] can also be diagnosed from
ﬁxation features. Additionally, ﬁxation and saccade features
can be utilized as biometrics for user identiﬁcation and authen-
tication [23, 33] because of their uniqueness to individuals.
These features can also reveal information about a user’s phys-
iological conditions, such as vision correction conditions [63].
3 Related Work
In this section, we provide a summary of the related work.
One line of work proposes “recognizer” systems that process
a sensor stream, such as a video, to “recognize” predeﬁned
objects or features [38,69,73]. The principle underlying these
systems is to send only abstract features from the data stream
(possibly after obfuscation) to the untrusted applications in
place of the raw stream. However, this approach suffers from
a set of shortcomings when applied in the context of real-time
eye tracking. First, APIs of current user applications expect,
as inputs, raw eye gaze streams directly or basic gaze events
such as ﬁxations. Second, this approach does not provide a
formal privacy guarantee and cannot defend against attacks
that consume only coarse-grained measurements (that can
be computed from the features)
[53]. Last, such systems
introduce complications for permission control for both users
and application developers.
Another line of work uses adversarial machine learning-
based approaches to protect the raw eye gaze data [29]. How-
ever, such techniques operate on predetermined data streams
and require training. Hence, these solutions are not practi-
cally feasible for real-time interactions. Additionally, they
do not offer any formal privacy guarantee. In another work,
Bozkir et al. [13] use randomized encoding to privately train
an SVR model for gaze estimation. However, this method
would require signiﬁcant changes, such as communication
with a third-party server, to existing eye-tracking ecosystems.
Differential privacy has been proposed in the context of eye
tracking [12, 53, 79]. However, the major problem with the
existing works is that they release noisy high-level features,
such as heatmap [53] and ratio of saccades [12,79]. Moreover,
their workﬂow involves collecting the dataset of eye gaze
streams from a group of users and then performing noisy fea-
ture extraction from it – the data release cannot be performed
in real-time. Also, the computation of the sensitivity [21] of
the features in two of the works [12, 79] is dependent on the
dataset, leading to additional privacy leakage [64]. Further,
Bozkir et al. [12] adopt the central differential privacy set-
ting that requires the presence of a trusted data aggregator, an
infeasible proposition for most eye-tracking applications.
Thus, the solutions above are not directly comparable to
Kaleido, aiming to provide a formal privacy guarantee for raw
gaze streams in real-time interactions.
4 Privacy Model
As discussed in Section 2.3, we observe that the privacy
threats to eye-tracking data arise either from the analysis of
the absolute spatial distribution or the aggregate statistics of
gaze positions over time. Thus, the spatial information of the
gaze positions is the primary source of sensitive information.
Hence, in Kaleido, we choose to provide our formal guaran-
tee (Deﬁnition 4.5) on the spatial information of the gaze
positions. In what follows, we start with some background
on differential privacy, followed by the privacy deﬁnition for
Kaleido and its implications.
4.1 Differential Privacy Preliminaries
For Kaleido’s formal privacy guarantee, we leverage two
variants of differential privacy: geo-indistinguishability [5]
and w-event differential privacy [42].
Geo-indistinguishability. Geo-indistinguishability is a spe-
cialization of differential privacy that provides privacy guaran-
tees for geographical information in 2D space. It is formally
deﬁned as follows:
Deﬁnition 4.1 ((((eee,,,rrr)))-geo-indistinguishability). A mecha-
nism M : X 7! Z is deﬁned to be (e,r) - geo-indistinguishable
iff for all pairs of inputs (x,x0) 2 X ⇥X such that d(x,x0)  r,
(1)
8S ⇢ Z,Pr[M (x) 2 S]  eePr[M (x0) 2 S]
where d(·,·) denotes the Euclidean metric.
We refer to the pair (x,x0) in the above deﬁnition as the
r-Euclidean neighboring. Intuitively, the above deﬁnition
protects all pairs of r-Euclidean neighbors1.
www-event differential privacy. As discussed above, eye gaze
data in real-world interaction interfaces is obtained in the
form of streaming data. Hence, we also use a variant of the w-
event differential privacy guarantee [42], which is deﬁned in
the context streaming data. In this context, the user’s behavior
breaks into a set of “events,” corresponding to data updates
in the stream due to user actions. Intuitively, this privacy
guarantee protects all event sequences of length w in a stream.
Let S be a stream of an inﬁnite tuple S = (D1,D2,··· )
where every data point Di at time stamp i is a database with
d columns and arbitrary rows (each row corresponds to an
unique user). Let St denote a stream preﬁx of S up till time
stamp t, St = (D1,D2,··· ,Dt), and St[i],i 2 [t] denote the i-th