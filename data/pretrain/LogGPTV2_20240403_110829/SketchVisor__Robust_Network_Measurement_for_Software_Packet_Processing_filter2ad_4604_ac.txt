Remove ❕ from H
E = E + ˆe
We also keep two global counters for the hash table, which we
later use to recover the aggregate statistics of small flows in the
control plane (§5).
• E : the sum of all decremented byte counts.
• V : the total byte count of packets in the fast path.
Algorithm: Algorithm 1 shows our fast path algorithm. Its idea
is to keep the top-k flows in H, and remove from H any flow that
is below some threshold if H is full. Specifically, upon receiving
a packet of size v for flow f , we first update the total byte count
V (line 6). If f is already in the hash table H, we increase the
residual byte rf (lines 7-8); if H is not full (i.e., it has fewer than k
flows), we insert f with (E, v, 0) to H (lines 9-10); otherwise, we
use ComputeThresh to compute a decremented value ˆe (line 12).
For each flow ❕ in H, we decrease r❕ by ˆe and increase d❕ by ˆe
(line 14). We kick out flows with residual byte counts no larger
than 0 (lines 15-16). We add f to H if its remaining byte count is
larger than ˆe (lines 17-18). Finally, we update the total decremented
byte count E (line 19).
The function ComputeThresh selects a threshold ˆe with respect
to k +1 values, i.e., the values of the top-k flows in H and the value of
the new flow f . It fits the input values to a power-law distribution
and estimates the power-law exponent θ (line 3) and threshold ˆe
(line 4), as in PLC [15]. Lemma 4.1 states that Algorithm 1 provides
tight lower and upper bounds of each top-k flow tracked by H. In
Appendix, we explain how θ and ˆe are derived, and present the
proof of Lemma 4.1.
Lemma 4.1. Algorithm 1 has the following properties:
• If flow f has size vf > E, it must be tracked in H.
• If f ∈ H, rf + df ≤ vf ≤ rf + df + ef .
• For any flow, its maximum possible error is bounded by O( V
k ).
Discussion: Lemma 4.1 does not assume any statistical distribu-
tion. It implies that the per-flow error, which is bounded by O( V
k ),
decreases with k. On the other hand, tracking more large flows
SIGCOMM ’17, August 21−25, 2017, Los Angeles, CA, USA
Huang et al.
The fast path is volume-based and tracks byte counts, yet we
can also use it to track connectivity-based statistics (e.g., DDoS,
superspreader, and cardinality) by converting connectivity-based
sketches in the normal path into volume-based sketches, similar
to the approach in Counting Bloom Filter [4, 34]. Specifically,
connectivity-based sketches typically maintain bit arrays and set a
bit to one if any observed flow/host is hashed to the bit. We now
replace bits by counters and update the counters by byte counts.
5 NETWORK-WIDE RECOVERY
5.1 Key Idea
The control plane provides network-wide measurement by peri-
odically collecting local measurement results from all hosts and
operating on the global views of the normal path and the fast path.
Specifically, it aggregates all sketches via matrix additions into a
single sketch N (i.e., the sketch counters at the same position are
added together), merges all top-k flows and their respective esti-
1, and adds all recorded
mated byte counts into a single hash table H
total byte counts into V . Note that the fast path loses information,
as it only holds approximate counters for top-k flows and does
not keep track of specific small flows. Thus, given N , H, and V ,
the goal of the control plane is to accurately recover the missing
information and hence the true sketch T , as if all traffic were only
recorded in T .
Solution overview: We first formulate the recovery of T as a ma-
trix interpolation problem (§5.2). Our formulation also demonstrates
the hardness of the recovery problem. To this end, we leverage
compressive sensing [6, 7, 9, 61] to solve the recovery problem by
incorporating domain knowledge into optimization.
5.2 Problem Formulation
Interpolation refers to reconstructing missing values based on in-
complete and/or indirect observations. In our case, we formulate
a matrix interpolation problem that recovers the true sketch T by
filling the missing values in N based on H and V . We first derive
problem constraints that need to be satisfied by T .
Constraints: We decompose the traffic (in bytes) in the fast path
into two 2104 × 1 vectors indexed by 5-tuple flow header space,
namely x and y, where x denotes the vector of the actual byte
counts of the tracked flows (i.e., flows in H) and y denotes the
vector of the actual byte counts of other flows. If a flow does not
exist, its vector element has value zero. Thus, the vector x + y
describes the per-flow traffic counts in the fast path.
To recover T , conceivably, we could inject all traffic of the fast
path back to the normal path. This in essence applies the sketch
function to x + y, denoted by sk(x + y), and adds sk(x + y) to N to
obtain T :
(1)
However, both x and y are unknown in practice, as the fast path
does not track the actual byte counts of individual flows. Neverthe-
less, we can specify their constraints. First, the fast path tracks the
total byte count V . We can relate x and y to V via their l1-norms
(resp. (cid:107)x(cid:107)1 and (cid:107)y(cid:107)1) as:
T = N + sk(x + y).
(cid:107)x(cid:107)1 + (cid:107)y(cid:107)1 = V .
(2)
1To simplify notation, we overload H to denote the global hash table in this section.
Figure 4: Example of fast path.
needs more memory and time to traverse the hash table for kick-out
operations. Thus, the value of k trades between performance and
accuracy. Nevertheless, a small hash table suffices in practice since
the fast path is activated only when necessary (§7.5).
Example: We use an example (Figure 4) to illustrate how Algo-
rithm 1 works and how the counters bound the flow sizes. Suppose
that we have a stream of five packets and the hash table H has
three buckets. For the first three packets (i.e., p0, p1, p2), we insert
three flows (i.e., f0, f1, f2) into H, and V represents their total byte
count so far (Figure 4(b)). For the fourth packet p3, since H is full,
we want to kick out small flows and check if we can insert the
new flow f3. To do this, we invoke ComputeThresh to compute a
decrement for each flow (which is 2 in this case), and update their
r and d (Figure 4(c)). We kick out f2 because its r becomes 0, and
insert the new flow f3 (Figure 4(d)). Finally, we see a packet p4
from f2 again. We still use ComputeThresh to kick out a small
flow, which is f3 in this case (Figure 4(e)), and insert f2 (Figure 4(f)).
Note that we set the e of f2 to be 2 because we have decremented 2
bytes in total before f2 is inserted. This e represents the maximum
possible byte count that is not included for f2 when f2 is not in the
table yet. Thus, the upper bound of f2 is e + r + d = 7. The lower
bound is r + d = 5 because we count every byte after the flow is
inserted. We emphasize that in this example, we kick out one flow
each time for brevity, but in general, ComputeThresh computes a
threshold that can kick out multiple flows at a time, which is our
main improvement over Misra-Gries’s algorithm [33].
Generality: Our fast path design is applicable for general traf-
fic statistics listed in §2.1. The fast path monitors 5-tuple flows
and clearly supports flow-based statistics. It can also extract IP
addresses from 5-tuples for host-based statistics. To track more
fine-grained flows, we only need to extend the flow definition with
more fields (e.g., MAC addresses).
ferdf0090f1070f2020V=18,  E=0(a)  A  stream  of  packets(b)  Receive  p0,  p1,  p2ferdf0072f1052f2002V=21,  E=0(c)  Receive  p3(before  kick-­out)ferdf0072f1052f3012V=21,  E=2(d)  Receive  p3(after  kick-­out)ferdf0063f1043f3003V=26,  E=2(e)  Receive  p4(before  kick-­out)ferdf0063f1043f2241V=26,  E=3(f)  Receive  p4(after  kick-­out)f09p0f17p1f22p2f33p3f25p4SketchVisor: Robust Network Measurement for So(cid:129)ware Packet Processing
SIGCOMM ’17, August 21−25, 2017, Los Angeles, CA, USA
Also, while the merged hash table H does not track x, it gives
the lower and upper bounds for each flow due to Lemma 4.1:
rf + df ≤ xf ≤ rf + df + ef .
(3)
Hardness: Our problem is to find T that satisfies the constraints
Equations (1)-(3), in which Equations (1) and (2) characterize the
aggregate properties of the traffic in the fast path, while Equa-
tion (3) quantifies the errors of individual flows. Unfortunately,
the fast path only provides incomplete information, and the above
constraints are insufficient to unambiguously determine T ; instead,
there exist multiple feasible solutions. This so-called undercon-
strained problem is commonly found in many matrix interpolation
problems [24, 60]. Thus, instead of finding a closed form of T , we
find the ‘‘best’’ estimate of T .
5.3 Compressive Sensing
We leverage compressive sensing [6, 7, 9, 61] to solve our under-
constrained matrix interpolation problem. Compressive sensing
provides a framework to integrate domain knowledge about matrix
structures, so as to eliminate feasible but irrelevant solutions and
form a solvable optimization problem [9, 61]. In our case, we incor-
porate our knowledge about the properties of network traffic and
sketches to form an appropriate optimization objective function.
Properties: We first identify the properties for T , x, and y.
• T is approximated as a low-rank matrix: As network traffic
is dominated by large flows [54, 59], few counters in T have
much different values from other counters that are only accessed
by small flows. Thus, we can approximate T as a low-rank matrix
(see justifications later).
• Both x and sk(x) are sparse: Since x only includes the top
flows in H and the entire flow space has a very large size (e.g.,
2104 for 5-tuple flows), we can treat x as a sparse vector. Also,
each flow in x touches a limited number of counters in a sketch,
so sk(x) is also sparse.
• Both y and sk(y) are of small noise: Network traffic is often
dominated by few large flows that are recorded in x. The remain-
ing flows in y are all very small and their sizes have low variance.
Thus, we can treat y as a small-noise vector. In addition, a sketch
maps such small-noise flows uniformly to its counters, so sk(y)
is also of small noise.
Before describing how we incorporate the above properties into
an optimization objective, we conduct rank analysis to validate the
low-rank approximation of T . We apply singular value decomposi-
tion to generate low rank approximations [18] for several sketch
matrices, using the same configurations in §7. Figure 5 shows the
relative errors (measured by Frobenius norm) of the low rank ap-
proximations. Reversible Sketch [46], Deltoid [13], and TwoLevel
[56] take only around 50%, 32%, and 15% of singular values to
achieve low rank approximations with less than 10% of errors, re-
spectively (i.e., they can capture more than 90% of information). On
the other hand, the relative error of Count-Min Sketch [14] drops
linearly with the ratio of top singular values. The reason is that it
typically has few rows (less than 10) with thousands of counters
each. Such a simple matrix has a rank equal to its number of rows
and shows no low rank approximation. Nevertheless, we can still
leverage the optimizations of x and y to accurately recover T .
1
2γ
• (cid:107)T (cid:107)∗ = 
• (cid:107)x(cid:107)1 =
=
• (cid:107)y(cid:107)2
F
Figure 5: Error of low rank approximation for sketch-based
solutions.
Objective function: We now encode the above properties into
the objective function, and leverage the compressive sensing frame-
work LENS [9] to recover T . LENS works by decomposing a traffic
matrix into low-rank, sparse, and small-noise components and
forming an objective function that characterizes the components.
Note that LENS mainly addresses traffic matrices that specify traffic
volume between all source and destination pairs, while we focus on
sketches that map flows to counters and have completely different
structures from traffic matrices. Nevertheless, our components T ,
x, and y actually share similar properties to LENS as argued above.
Thus, we follow LENS and derive the following objective function:
(4)
where α, β, and γ are weighting parameters that are configurable
(see details below). The three terms in the objective function have
the following meanings:
minimize: α(cid:107)T (cid:107)∗ + β(cid:107)x(cid:107)1 +
(cid:107)y(cid:107)2
F ,
i σi, where σi’s are singular values of T .
It is the
nuclear norm [44] of T and penalizes against the high rank of T .
i |xi|. It is the l1-norm of x and penalizes against the
. It is the squared Frobenius norm of y and penal-
lack of sparsity in x.
izes against large elements in y.
Our objective function provides a general framework for the
recovery of all sketches, even though some terms may not be nec-
essary. For example, the term y has limited impact on sketches for
heavy hitter detection, since heavy hitter detection mainly focuses
on large flows in x and a sub-optimal y is also acceptable. Also, for
sketches that do not have low-rank approximations (e.g., Count-
Min Sketch in Figure 5), the nuclear norm of T is nearly a constant,
so we can discard the term (cid:107)T (cid:107)∗ in the optimization objective.
Problem solving and parameter settings: The optimization
problem minimizes the objective function Equation (4) subject to
the constraints Equations (1)-(3). This is a convex optimization
problem, which is computationally tractable. We use the Alterna-
tive Direction Method to efficiently solve this problem [9]. Our
optimization formulation has three parameters, i.e., α, β, and γ.
Following the guidelines of LENS [9], we set parameters as follows.
2
i
i y
γ = 10 · γy .

First, we consider α. The constants mT and nT are the numbers of
rows and columns of matrix T , while η(N) is the probability density
of matrix N and is set as
. Next, we consider β. The
i, j N[i][j]
mT ·nT
nT )(cid:112)
β =(cid:112)2 log(mx · nx) =
α = (√
mT +
√
η(N).
√