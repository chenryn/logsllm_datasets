tions such as session clustering, HMM model building,
online initial/midstream throughput prediction, on the
server. The learning of the HMM model is implemented
using the Probabilistic Modeling Toolkit (PMTK) [35]
in Octave. As model training is a time-consuming pro-
cess, we do it on a per-day basis with the log collected
on each day.9 The server responds to the POST requests
from video clients and returns the throughput prediction
results.
9Since the model learning for different clusters are indepen-
dent, this process can be easily parallelized.
We believe that our implementation can be easily trans-
lated to the client-side solution (i.e., each client makes
throughput prediction by itself), as we only require less than
600 additional lines of JavaScript over open-source play-
ers [3, 47].
7 Evaluation
In this section, we show that:
• CS2P reduces median prediction error by 40% for ini-
tial throughput and 50% for midstream throughput com-
paring to state-of-art predictors, achieving 6% 1-epoch-
ahead and 90% of the
ofﬂine-optimal QoE respectively for initial and midstream
chunks, while these numbers for the next best solutions are
only 42% and 73%. This result conﬁrms that the improved
prediction accuracy of CS2P leads to concrete QoE gain
when combined with prediction-based bitrate adaptation al-
gorithms.
In Figure 10a we also compare CS2P against CFA [29],
which selects the initial video bitrate based on the QoE pre-
diction via cross-session methodology. We see that CS2P
signiﬁcantly outperforms CFA. The reason is that CFA re-
lies on QoE prediction, and QoE heavily depends on video-
speciﬁc features (e.g., videos with different bitrate levels
have different QoE). In our dataset we do not record these
video-speciﬁc features, making it difﬁcult to predict QoE ac-
curately. However, CS2P relies on throughput prediction us-
ing only network-speciﬁc features, and our dataset enables it
to have good enough predictions.
Detailed QoE: Next, we zoom in and focus on two key QoE
factors, AvgBitrate and GoodRatio. As shown in Table 3,
CS2P leads to both higher AvgBitrate and GoodRatio for
initial and midstream chunks.
Figure 11 shows the Pareto frontier of QoE factors for
midstream chunks achieved by MPC+different predictors,
Figure 11: Tradeoff between AvgBitrate and GoodRatio.
i.e., the set of achievable AvgBitrate and GoodRatio by ad-
justing weight on QoE factors. The more to the top right,
the better QoE is achieved. We observe that CS2P-based
bitrate selection strikes a better tradeoff of higher AvgBi-
trate and higher GoodRatio. Overall, CS2P + MPC achieves
better QoE than other predictors, once again conﬁrming the
claim that higher prediction accuracy leads to QoE improve-
ment [48].
7.4 Sensitivity Analysis
We also conduct sensitivity analysis of the performance of
CS2P w.r.t. key design parameters.
HMM states: While a sufﬁcient number of states is nec-
essary to fully capture the behavior of the network, having
too many states lead to increased model complexity and po-
tential overﬁtting. Figure 12a shows the prediction error
vs. number of HMM states. We see that while the error de-
creases with more states, there is a natural diminishing return
property as the performance gain after 6 states is much less.
This conﬁrms our choice of 6-state HMM based on cross
validation.
Group size: As discussed in Section 5.1, if the number of
training sessions in a cluster is too small, the data will be
 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1CDFAbsolute Normalized ErrorCS2PSVRGBRLM-ClientLM-Server 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1CDFAbsolute Normalized ErrorARLSHMGHMSVRGBRCS2P 0 0.1 0.2 0.3 0.4 0.5 1 2 3 4 5 6 7 8 9 10Absolute Percentage ErrorNumber of Lookahead StepsARLSHMGHMSVRGBRCS2P 0 0.2 0.4 0.6 0.8 1 0.7 0.8 0.9CDFNormalized QoESVRGBRCFACS2P 0 0.2 0.4 0.6 0.8 1 0.8 0.85 0.9 0.95CDFNormalized QoEARLSHMGHMSVRGBRCS2P 0 1 2 3 4 5 6 0.8 0.9 1Avg. Bitrate (Mbps)Good RatioCS2PGBRARSVRLSHM(a) Error vs. HMM states
(b) Error vs. Group size
(c) Error vs. Measurement frequency
Figure 12: Sensitivity analysis of CS2P parameters.
insufﬁcient to yield reliable prediction results. Figure 12b
shows the error vs. the threshold of group size in the train-
ing dataset. We observe that while the error decreases with
more training sessions, the prediction error converges after
the group size grows to 100. Again, this conﬁrms our choice
of group size 100 using cross validation.
Measurement granularity: We also investigate how per-
formance of CS2P changes w.r.t. throughput measurement
granularity. We merge the original per-6-second traces to
more coarse-grained traces (18s, 30s, 42s) by taking the av-
erage of multiple consecutive epochs. Figure 12c shows that
the prediction error is generally independent of measurement
granularity.
7.5 Pilot Deployment
Finally, we conduct two deployment studies to evaluate the