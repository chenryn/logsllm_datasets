  Meta options: timestamp-format=%H%B%S timeout=50s
  Recipients:
   Recipient: my-alert-recipient (value=my-other-recipient)
```
以下命令修改报警 `my-alert`{.literal} 和接收者
`my-alert-recipient`{.literal} 的报警值。
``` literallayout
# pcs alert update my-alert options option1=newvalue1 meta timestamp-format="%H%M%S"
# pcs alert recipient update my-alert-recipient options option1=new meta timeout=60s
# pcs alert
Alerts:
 Alert: alert (path=/my/path)
  Recipients:
   Recipient: alert-recipient (value=rec_value)
   Recipient: my-recipient (value=rec_value2)
 Alert: my-alert (path=/path/to/script)
  Description: alert_description
  Options: opt=val option1=newvalue1
  Meta options: timestamp-format=%H%M%S timeout=50s
  Recipients:
   Recipient: my-alert-recipient (value=my-other-recipient)
    Options: option1=new
    Meta options: timeout=60s
```
以下命令从 `alert`{.literal} 中删除接收者
`my-alert-recipient`{.literal}。
``` literallayout
# pcs alert recipient remove my-recipient
# pcs alert
Alerts:
 Alert: alert (path=/my/path)
  Recipients:
   Recipient: alert-recipient (value=rec_value)
 Alert: my-alert (path=/path/to/script)
  Description: alert_description
  Options: opt=val option1=newvalue1
  Meta options: timestamp-format="%M%B%S" timeout=50s
  Recipients:
   Recipient: my-alert-recipient (value=my-other-recipient)
    Options: option1=new
    Meta options: timeout=60s
```
以下命令将从配置中删除 `myalert`{.literal}。
``` literallayout
# pcs alert remove myalert
# pcs alert
Alerts:
 Alert: alert (path=/my/path)
  Recipients:
   Recipient: alert-recipient (value=rec_value)
```
:::
::: section
::: titlepage
# []{#assembly_configuring-pacemaker-alert-agents_configuring-and-managing-high-availability-clusters.html#writing-cluster-alert-agent-configuring-pacemaker-alert-agents}编写集群警报代理 {.title}
:::
Pacemaker
群集警报有三种类型：节点警报、隔离警报和资源警报。传递给报警代理的环境变量可能会由于报警类型而有所不同。下表描述了传递给警报代理的环境变量，并指定环境变量何时与特定警报类型关联。
::: table
[]{#assembly_configuring-pacemaker-alert-agents_configuring-and-managing-high-availability-clusters.html#tb-alert-environmentvariables-HAAR}
**表 27.2. 传递给报警代理的环境变量**
::: table-contents
  环境变量                              描述
  ------------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  `CRM_alert_kind`{.literal}            报警类型（节点、隔离或资源）
  `CRM_alert_version`{.literal}         发送报警的 Pacemaker 版本
  `CRM_alert_recipient`{.literal}       配置的接收者
  `CRM_alert_node_sequence`{.literal}   每当在本地节点上发出报警时，序列号就会增加，它可以用来参考 Pacemaker 所发出报警的顺序。发生时间较晚的事件的报警序列号比发生时间较早的事件的报警序列号要高。请注意，这个数字没有集群范围的含义。
  `CRM_alert_timestamp`{.literal}       执行代理前创建的时间戳，使用由 `timestamp-format`{.literal} meta 选项指定的格式。这可以确保在事件发生时代理有一个可靠、高度准确的时间，无论代理本身何时被调用（这可能会因为系统负载或其他情况而延迟）。
  `CRM_alert_node`{.literal}            受影响节点的名称
  `CRM_alert_desc`{.literal}            有关事件的详情。对于节点报警，这是节点的当前状态（成员或丢失）。对于隔离报警，这是请求的隔离操作的总结，其中包括起源、目标以及隔离操作错误代码（若有的话）。对于资源报警，这是等同于 `CRM_alert_status`{.literal} 的可读字符串。
  `CRM_alert_nodeid`{.literal}          状态更改了的节点 ID（仅由节点报警提供）
  `CRM_alert_task`{.literal}            请求的隔离或资源操作（仅由隔离和资源报警提供）
  `CRM_alert_rc`{.literal}              保护或资源操作的数字返回代码（仅由隔离和资源警告提供）
  `CRM_alert_rsc`{.literal}             受影响的资源的名称（仅限资源报警）
  `CRM_alert_interval`{.literal}        资源操作的时间间隔（仅限资源报警）
  `CRM_alert_target_rc`{.literal}       操作的预期数字返回码（仅用于资源报警）
  `CRM_alert_status`{.literal}          Pacemaker 用来表示操作结果的数字码（仅用于资源报警）
:::
:::
在编写报警代理时，您必须考虑以下问题。
::: itemizedlist
-   警告代理可以在没有接收者的情况下被调用（如果没有配置任何接收者），因此代理必须能够处理这种情况，即使它只在那种情况下才会退出。用户可以修改配置阶段，并在以后添加一个接收者。
-   如果为报警配置了多个接收者，则会为每个接收者调用一次报警代理。如果代理无法同时运行，则应该只使用单个的接收者进行配置。不过，代理可以自由地将接收者解析为一个列表。
-   当发生集群事件时，所有报警作为单独的进程同时被触发。根据配置了多少报警和接收方以及报警代理中的操作，可能会发生严重的负载突发。可以编写代理来考虑这一点，例如将资源密集型操作排队到其他实例中，而不是直接执行。
-   报警代理以
    `hacluster 用户身份运行`{.literal}，该用户具有最小权限集。如果代理需要额外的特权，建议配置
    `sudo`{.literal}
    以允许代理以具有适当特权的另一用户身份运行必要的命令。
-   请小心地验证和清理用户配置的参数，如 `CRM_alert_timestamp`{.literal}
    （其内容由用户配置的 `timestamp-format`{.literal}
    指定）、`CRM_alert_recipient`{.literal}
    和所有报警选项。这是防止配置错误所必需的。此外，如果某些用户可以在不具有
    `hacluster`{.literal} 级别权限访问集群节点的情况下修改了
    CIB，则这也是一个潜在的安全问题，您应该避免注入代码的可能性。
-   如果集群包含资源，而对资源操作的 `on-fail`{.literal} 参数设为
    `fence`{.literal}
    ，则失败时会有多个隔离通知，每个设置了此参数的资源都有一个通知，另外还有一个通知。`pacemaker-fenced`{.literal}
    和 `pacemaker-controld`{.literal} 都将发送通知。pacemaker
    在这种情况下只能执行一个实际隔离操作，无论发送了多少条通知。
:::
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
报警接口设计为与 `ocf:pacemaker:ClusterMon`{.literal}
资源使用的外部脚本接口向后兼容。为了保持这种兼容性，传递给报警代理的环境变量会带有
`CRM_notify_`{.literal} 和 `CRM_alert_`{.literal}
前缀。兼容性方面的一个问题是 `ClusterMon`{.literal} 资源以 root
用户身份运行外部脚本，而报警代理则以 `hacluster`{.literal}
用户身份运行。
:::
:::
:::
[]{#assembly_configuring-multisite-cluster-configuring-and-managing-high-availability-clusters.html}
::: chapter
::: titlepage
# []{#assembly_configuring-multisite-cluster-configuring-and-managing-high-availability-clusters.html#assembly_configuring-multisite-cluster-configuring-and-managing-high-availability-clusters}第 28 章 多站点 Pacemaker 集群 {.title}
:::
当集群跨越多个站点时，站点间网络连接的问题可能会导致崩溃问题。当连接断开时，某个位置的节点无法判断位于另一个站点中的某个节点是否失败，或者仍然能够使用失败的站点间连接。此外，在两个站点间提供高可用性服务可能会有问题。为解决这些问题，Pacemaker
完全支持通过使用 Booth 集群票据管理器配置跨多个站点的高可用性集群。
::: section
::: titlepage
# []{#assembly_configuring-multisite-cluster-configuring-and-managing-high-availability-clusters.html#con_booth-cluster-ticket-manager-configuring-multisite-cluster}Booth 集群票据管理器概述 {.title}
:::
Booth [*票据管理器（ticket manager）*]{.emphasis}
是一个分布式服务，它应该在与在特定站点连接集群节点的网络不同的物理网络中运行。它会产生另一个松散集群，一个
[*Booth
空间*]{.emphasis}，它位于站点的常规集群之上。这可整合沟通层，为独立的
Booth ticket 采用基于认可的决策流程。
Booth [*ticket*]{.emphasis} 是 Boothship
中的单例，代表一个对时间敏感、可移动的授权单元。资源可以被配置为需要运行某个
ticket。这样可保证资源一次只在一个站点运行，并为其提供 ticket。
您可以将 Booth
看成一个覆盖集群，由在不同站点中运行的集群组成，所有原始集群相互独立。这是与集群沟通的
Booth 服务，它是否获得一个 ticket，而 Pacemaker 会根据 Pacemaker ticket
约束决定是否在集群中运行资源。这意味着，在使用 ticket
管理器时，每个集群都可以运行自己的资源和共享资源。例如，在一个集群中只能运行资源
A、B 和 C，资源 D、E 和 F
仅在另一个集群中运行，且在这两个集群中之一运行的资源 G 和 H 由 ticket
决定。也可以按照一个单独的 ticket 来决定在两个集群中运行的额外资源 J。
:::
::: section
::: titlepage
# []{#assembly_configuring-multisite-cluster-configuring-and-managing-high-availability-clusters.html#proc-configuring-multisite-with-booth-configuring-multisite-cluster}使用 Pacemaker 配置多站点集群 {.title}
:::
以下流程概述了配置使用 Booth ticket 管理器的多站点配置的步骤。
这些示例命令使用以下协议：
::: itemizedlist
-   集群 1 由节点 `cluster1-node1`{.literal} 和
    `cluster1-node2`{.literal} 组成
-   集群 1 具有为其分配的浮动 IP 地址 192.168.11.100
-   集群 2 由 `cluster2-node1`{.literal} 和 `cluster2-node2`{.literal}
    组成
-   集群 2 具有为其分配的浮动 IP 地址 192.168.22.100
-   仲裁节点是 `arbitrator-node`{.literal} ，其 IP 地址为 192.168.99.100
-   此配置使用的 Booth ticket 的名称是 `apacheticket`{.literal}
:::
这些示例命令假定已将 Apache 服务的集群资源配置为每个集群的资源组
`apachegroup`{.literal}
的一部分。不需要每个集群上的资源和资源组为这些资源配置一个 ticket
约束，因为每个集群的 Pacemaker
实例都是独立的，但这是一个常见故障转移的场景。
请注意，您可以随时输入 `pcs booth config 命令来显示当前`{.literal}
节点或集群的 booth 配置，或使用 `pcs booth status`{.literal}
命令在本地节点上显示 booth 的当前状态。
::: orderedlist
**流程**
1.  在两个集群的每个节点上都安装 `booth-site`{.literal} Booth ticket
    manager 软件包。
    ``` literallayout
    [root@cluster1-node1 ~]# yum install -y booth-site
    [root@cluster1-node2 ~]# yum install -y booth-site
    [root@cluster2-node1 ~]# yum install -y booth-site
    [root@cluster2-node2 ~]# yum install -y booth-site
    ```
2.  在仲裁节点上安装 `pcs`{.literal}、`booth-core`{.literal} 和
    `booth-arbitrator`{.literal} 软件包。
    ``` literallayout
    [root@arbitrator-node ~]# yum install -y pcs booth-core booth-arbitrator
    ```
3.  如果您正在运行 `firewalld`{.literal}
    守护进程，请在两个集群的所有节点上和临时节点上执行以下命令，以启用红帽高可用性附加组件所需的端口。
    ``` literallayout
    # firewall-cmd --permanent --add-service=high-availability
    # firewall-cmd --add-service=high-availability
    ```
    您可能需要修改开放端口以适合本地条件。有关红帽高可用性附加组件所需端口的更多信息，[请参阅启用高可用性附加组件的端口](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_high_availability_clusters/assembly_creating-high-availability-cluster-configuring-and-managing-high-availability-clusters#proc_enabling-ports-for-high-availability-creating-high-availability-cluster){.link}。
4.  在一个集群的一个节点上创建 Booth
    配置。您为每个集群和地区指定的地址必须是 IP
    地址。对于每个集群，您可以指定一个浮动 IP 地址。
    ``` literallayout
    [cluster1-node1 ~] # pcs booth setup sites 192.168.11.100 192.168.22.100 arbitrators 192.168.99.100
    ```
    这个命令会在运行它的节点上创建配置文件
    `/etc/booth /booth.conf`{.literal} 和
    /etc/booth/booth.key``{=html}。
5.  为 Booth 配置创建
    ticket。这是您要用来定义资源约束的票据，允许仅在向集群授予这个票据时运行资源。
    这个基本故障转移配置过程只使用一个
    ticket，但您可以为每个复杂情况创建额外的 ticket，因为每个 ticket
    都与不同的资源或资源关联。
    ``` literallayout
    [cluster1-node1 ~] # pcs booth ticket add apacheticket
    ```
6.  将 Booth 配置同步至当前集群中的所有节点。
    ``` literallayout
    [cluster1-node1 ~] # pcs booth sync
    ```
7.  在仲裁机构（arbitrator）节点中，将 Booth
    配置拉取到仲裁机构中。如果您之前还没有这样做，则必须首先向要提取配置的节点验证
    `pcs`{.literal}。
    ``` literallayout
    [arbitrator-node ~] # pcs host auth cluster1-node1
    [arbitrator-node ~] # pcs booth pull cluster1-node1
    ```
8.  将 Booth
    配置拉取到其他集群，并同步到该集群的所有节点。与仲裁节点一样，如果您之前还没有这样做，您必须首先向要提取配置的节点验证
    `pcs`{.literal}。
    ``` literallayout
    [cluster2-node1 ~] # pcs host auth cluster1-node1
    [cluster2-node1 ~] # pcs booth pull cluster1-node1
    [cluster2-node1 ~] # pcs booth sync
    ```
9.  在仲裁机构中开启并启动 Booth。
    ::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
    ### 注意 {.title}
    您不能在集群的任何节点上手动启动或启用 Booth，因为 Booth
    作为这些集群中的 Pacemaker 资源运行。
    :::
    ``` literallayout
    [arbitrator-node ~] # pcs booth start
    [arbitrator-node ~] # pcs booth enable
    ```
10. 将 Booth
    配置为作为集群资源在这两个集群站点运行。这将创建一个资源组，并将
    `booth-ip`{.literal} 和 `booth-service`{.literal} 作为该组的成员。
    ``` literallayout
    [cluster1-node1 ~] # pcs booth create ip 192.168.11.100
    [cluster2-node1 ~] # pcs booth create ip 192.168.22.100
    ```
11. 为您为每个集群定义的资源组添加一个 ticket 约束。
    ``` literallayout
    [cluster1-node1 ~] # pcs constraint ticket add apacheticket apachegroup
    [cluster2-node1 ~] # pcs constraint ticket add apacheticket apachegroup
    ```
    您可以输入以下命令来显示当前配置的 ticket 约束。
    ``` literallayout
    pcs constraint ticket [show]