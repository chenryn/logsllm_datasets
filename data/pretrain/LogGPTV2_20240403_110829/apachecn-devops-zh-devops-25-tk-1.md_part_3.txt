```
...
Events:
... Message
... -------
... New size: 3; reason: Current number of replicas below Spec.MinReplicas
... missing request for memory on container db-sidecar in pod go-demo-5/db-0
... failed to get memory utilization: missing request for memory on container db-sidecar in pod go-demo-5/db-0
```
Please note that your output could have only one event, or even none of those. If that's the case, please wait for a few minutes and repeat the previous command.
如果我们专注于第一条信息，我们可以看到它开始得很好。HPA 检测到当前副本数量低于限制，并将它们增加到三个。这是预期的行为，所以让我们转到另外两条消息。
HPA 无法计算百分比，因为我们没有指定我们为`db-sidecar`容器请求了多少内存。没有`requests`，HPA 无法计算实际内存使用的百分比。换句话说，我们错过了为`db-sidecar`容器指定资源，HPA 无法完成其工作。我们将通过应用`go-demo-5-no-hpa.yml`来解决这个问题。
让我们快速了解一下新的定义。
```
 1  cat scaling/go-demo-5-no-hpa.yml
```
输出限于相关部分，如下所示。
```
...
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: db
  namespace: go-demo-5
spec:
  ...
  template:
    ...
    spec:
      ...
      - name: db-sidecar
        ...
        resources:
          limits:
            memory: "100Mi"
            cpu: 0.2
          requests:
            memory: "50Mi"
            cpu: 0.1
...
```
与最初的定义相比，唯一值得注意的区别是，这次我们为`db-sidecar`容器定义了资源。让我们应用它。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-no-hpa.yml \
 3      --record
```
接下来，我们将等待一段时间，等待更改生效，然后再重新检索 HPA。
```
 1  kubectl -n go-demo-5 get hpa
```
这一次，产量更有希望。
```
NAME REFERENCE      TARGETS          MINPODS MAXPODS REPLICAS AGE
api  Deployment/api 66%/80%, 10%/80% 2       5       2        16m
db   StatefulSet/db 60%/80%, 4%/80%  3       5       3        10m
```
两个 HPA 都显示当前和目标资源使用情况。两者都没有达到目标值，因此 HPA 保持了最小数量的副本。我们可以通过列出`go-demo-5`命名空间中的所有 Pods 来确认这一点。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME    READY STATUS  RESTARTS AGE
api-... 1/1   Running 0        42m
api-... 1/1   Running 0        46m
db-0    2/2   Running 0        33m
db-1    2/2   Running 0        33m
db-2    2/2   Running 0        33m
```
我们可以看到`api`部署有两个 Pods，而`db`状态集有三个副本。这些数字相当于住房津贴定义中的`spec.minReplicas`条目。
让我们看看当实际内存使用量高于目标值时会发生什么。
我们将修改其中一个 HPA 的定义，降低其中一个目标，以此来重现 Pods 消耗的资源超出预期的情况。
让我们看一下修改后的 HPA 定义。
```
 1  cat scaling/go-demo-5-api-hpa-low-mem.yml
```
输出限于相关部分，如下所示。
```
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: api
  namespace: go-demo-5
spec:
  ...
  metrics:
  ...
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 10
```
我们将`targetAverageUtilization`降低到`10`。这肯定会低于当前的内存利用率，我们将能够见证 HPA 的运行。让我们应用新的定义。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-api-hpa-low-mem.yml \
 3      --record
```
请稍等片刻，以进行下一轮数据收集，并检索 HPA。
```
 1  kubectl -n go-demo-5 get hpa
```
输出如下。
```
NAME REFERENCE      TARGETS          MINPODS MAXPODS REPLICAS AGE
api  Deployment/api 49%/10%, 10%/80% 2       5       2        44m
db   StatefulSet/db 64%/80%, 5%/80%  3       5       3        39m
```
我们可以看到`api` HPA ( `49%`)的实际记忆远远高于阈值(`10%`)。然而，副本的数量仍然相同(`2`)。我们必须再等几分钟才能再次取回 HPA。
```
 1  kubectl -n go-demo-5 get hpa
```
这一次，输出略有不同。
```
NAME REFERENCE      TARGETS          MINPODS MAXPODS REPLICAS AGE
api  Deployment/api 49%/10%, 10%/80% 2       5       4        44m
db   StatefulSet/db 64%/80%, 5%/80%  3       5       3        39m
```
我们可以看到副本数量增加到`4`。HPA 改变了部署，产生了级联效应，导致吊舱数量增加。
我们来描述一下`api` HPA。
```
 1  kubectl -n go-demo-5 describe hpa api
```
输出仅限于事件消息，如下所示。
```
...
Events:
... Message
... -------
... New size: 2; reason: Current number of replicas below Spec.MinReplicas
... New size: 4; reason: memory resource utilization (percentage of request) above target
```
我们可以看到 HPA 把尺寸改成了`4`，因为`memory resource utilization (percentage of request)`是`above target`。
因为在这种情况下，增加副本数量并没有将内存消耗降低到 HPA 目标以下，所以我们应该预计 HPA 将继续扩大部署，直到达到`5`的限制。我们将等待几分钟，再次描述 HPA，以此来证实这一假设。
```
 1  kubectl -n go-demo-5 describe hpa api
```
输出仅限于事件消息，如下所示。
```
...
Events:
... Message
... -------
... New size: 2; reason: Current number of replicas below Spec.MinReplicas
... New size: 4; reason: memory resource utilization (percentage of request) above target
... New size: 5; reason: memory resource utilization (percentage of request) above target
```
我们收到消息称新的大小现在是`5`，从而证明 HPA 将继续扩展，直到资源低于目标，或者像我们的情况一样，达到最大副本数量。
我们可以通过列出`go-demo-5`命名空间中的所有 Pods 来确认缩放确实有效。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME    READY STATUS  RESTARTS AGE
api-... 1/1   Running 0        47m
api-... 1/1   Running 0        51m
api-... 1/1   Running 0        4m
api-... 1/1   Running 0        4m
api-... 1/1   Running 0        24s
db-0    2/2   Running 0        38m
db-1    2/2   Running 0        38m
db-2    2/2   Running 0        38m
```
我们可以看到，`api`部署确实有五个副本。
HPA 从度量服务器检索数据，得出实际资源使用高于阈值的结论，并使用新数量的副本操作部署。
![](img/1176f620-4e31-44e3-8eb0-5c8a4ef9b2e6.png)
Figure 1-5: HPA scaling through manipulation of the Deployment
接下来，我们将验证缩减是否也有效。我们将通过重新应用初始定义来做到这一点，该定义将内存和 CPU 都设置为 80%。由于实际内存使用低于该值，HPA 应该开始缩减，直到达到最小副本数。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-api-hpa.yml \
 3      --record
```
和以前一样，我们会等几分钟再描述 HPA。
```
 1  kubectl -n go-demo-5 describe hpa api
```
输出仅限于事件消息，如下所示。
```
...
Events:
... Message
... -------
... New size: 2; reason: Current number of replicas below Spec.MinReplicas
... New size: 4; reason: memory resource utilization (percentage of request) above target
... New size: 5; reason: memory resource utilization (percentage of request) above target
... New size: 3; reason: All metrics below target
```
如我们所见，由于所有的`metrics`都是`below target`，所以它将尺寸改为`3`。
一段时间后，它将再次缩小到两个副本并停止，因为这是我们在 HPA 定义中设置的限制。
# 在部署和状态集中是复制副本还是不复制副本？
知道 horizontalpodocautoscaler(HPA)管理我们的应用的自动扩展后，可能会出现关于副本的问题。我们是应该在我们的部署和状态集中定义它们，还是应该仅依靠 HPA 来管理它们？我们将探索不同的组合，并根据结果定义策略，而不是直接回答这个问题。
首先，让我们看看我们的集群中现在有多少 Pods。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME    READY STATUS  RESTARTS AGE
api-... 1/1   Running 0        27m