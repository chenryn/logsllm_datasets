He
such that
p(x) = h(x) · t(x)), and computes the proof πy as:
(the polynomial
for h(x)
, gw0(s)
, gy0(s)
solves
).
w
v
y
( gvmid (s)
,
v
gαvvmid (s)
v
gβw(s)
gβv(s)
w
v
gw(s)
w ,
, gαww(s)
w
gβy(s)
y
gy(s)
,
y
, gαyy(s)
y
gh(s),
),
where vmid(x) = ∑k∈Imid ck·vk(x), v(x) = ∑k∈[m] ck·vk(x)
w(x) = ∑k∈[m] ck · wk(x), and y(x) = ∑k∈[m] ck · yk(x).
• {0,1} ← Verify(V KF ,u,y,πy): The veriﬁcation of an al-
leged proof with elements gVmid , gW , gY , gH, gV(cid:48)
mid , gW(cid:48)
,
gY(cid:48)
, and gZ uses the public veriﬁcation key V KF and the
pairing function e to perform the following checks.
• Divisibility check for the QAP: using elements from
V KF compute gvio(s)
e(gv0(s)
gY
y ,g).
• Check that the linear combinations computed over V ,
W and Y are in their appropriate spans:
e(gV(cid:48)
midv
(cid:17)ck and check:
w ) = e(gt(s)
gW
y
,gH )e(gy0(s)
w ,g) = e(gW
w ,gαw ),
= ∏k∈[N]
e(gW(cid:48)
,gw0(s)
gvio(s)
v
,gαv),
gvk(s)
v
gVmid
v
(cid:16)
w
v
v
y
v
,g) = e(gVmid
e(gY(cid:48)
y ,g) = e(gY
y ,gαy).
• Check that the same coefﬁcients were used in each of
the linear combinations over V , W and Y :
y ,gβγ).
e(gZ,gγ) = e(gvio(s)
gW
w gY
gVmid
v
v
The correctness of the VC scheme follows from the prop-
erties of the QAP. Regarding security, we have the following:
Theorem 1 Let d be an upper bound on the degree of the
QAP used in the VC scheme, and let q = 4d + 4. The VC
scheme is sound under the d-PKE, q-PDH and 2q-SDH as-
sumptions (see Appendix A).
The proof of Theorem 1 is in Appendix B.
242
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
1 ), (g2,gα
Security Intuition. As intuition for why the VC scheme is
sound, note that it seems hard for an adversary who does
not know α to construct any pair of group elements h,hα ex-
cept in the obvious way: by taking pairs (g1,gα
2 ), . . .
that he is given, and applying the same linear combination
(in the exponent) to the left and right elements of the pairs.
This hardness is formalized in the d-PKE assumption, a sort
of “knowledge-of-exponent” assumption [41], that says that
the adversary must “know” such a linear combination, in the
sense that this linear combination can be extracted from him.
Roughly, this means that, in the security proof, we can extract
polynomials Vmid(x), W (x), Y (x) such that Vmid (from the
proof) equals Vmid(s), W =W (s) and Y =Y (s), and that more-
over these polynomials are in the linear spans of the vk(x)’s,
wk(x)’s, and yk(x)’s respectively. If the adversary manages to
provide a proof of a false statement that veriﬁes, then these
polynomials must not actually correspond to a QAP solution.
So, either p(x) is not actually divisible by t(x) (in this case we
break 2q-SDH) or V (x) = vio(x) +Vmid(x), W (x) and Y (x) do
not use the same linear combination (in this case we break
q-PDH because in the proof we choose β in a clever way).
Zero Knowledge. We can apply GGPR’s rerandomization
technique [30] (§2.3) to provide zero-knowledge for our new
veriﬁable computation construction. The worker chooses
R← F and in his proof, instead of the polynomials
δv,δw,δy
vmid(x), v(x), w(x) and y(x), he uses the following random-
ized versions vmid(x) + δvt(x), v(x) + δvt(x), w(x) + δwt(x)
and y(x) + δyt(x). In order to facilitate the randomization of
the proof we add the following terms to the evaluation key:
gαvt(s)
v
Performance. Our main improvement is that our VC scheme
only requires a regular QAP, rather than a strong QAP, which
improves performance by more than a factor of 3. Moreover,
the scheme itself is simpler, leading to fewer group elements
in the keys and proof, fewer bilinear maps for Verify, etc.
, gαwt(s)
, gαyt(s)
, gβt(s)
, gβt(s)
w
The scheme above assumes a symmetric bilinear map. In
practice, for performance reasons, we use an asymmetric bi-
linear map e : G1 × G2 → GT where G1 is an elliptic curve
group called the “base” curve, and G2 is the “twist” curve.
Operations over the base curve are about 3 times faster than
over the twist curve (§5.1). Due to our optimizations, while
the worker must compute the gw(s)
term over the twist curve,
all of the other proof terms can be over the base curve.
3.2 Expressive Circuit Constructions
The QAP that we use in our VC scheme is deﬁned over Fp,
where p is a large prime. We can, as explained above, de-
rive a QAP over Fp that efﬁciently computes any function F
that can be expressed in terms of addition and multiplication
modulo p. This provides no obvious way to express some op-
erations, such as a ≥ b using mod-p arithmetic. On the other
hand, given a and b as bits, comparison is easy. Hence, one
might infer that Boolean circuits are more general and thus
QSPs superior to QAPs.
, gβt(s)
v
y
.
w
y
w
However, we design an arithmetic split gate to translate an
arithmetic wire a ∈ Fp, known to be in [0,2k − 1], into k bi-
nary output wires. Given such binary values, we can compute
Boolean functions using arithmetic gates: NAND(a,b) =
1−ab, AND(a,b) = ab, OR(a,b) = 1− (1−a)(1−b). Each
embedded Boolean gate costs only one multiply.
Furthermore, the expression ∑k
Surprisingly, even though QSPs are “designed for”
Boolean circuits, the arithmetic embedding gives a more efﬁ-
cient VC scheme. With a QSP, each gate increases the degree
of t(x) by 9 and the QSP size by 12. Embedding introduces
an expensive initial gate that constrains each input to {0,1},
but henceforth, each embedded gate preserves the {0,1} in-
variant, adding only 1 to the degree and size of the QAP. 3
i=1 2i−1ai combines a bit-
wise representation of a back into a single wire. Because the
sum consists of additions and multiplications by constants,
recombination is free; it doesn’t increase the size of the QAP.
Below, we deﬁne a split gate as a standalone QAP which
can be composed [30, Thm.11] with other gates. In our full
paper [40], we design a gate that enforces wire equality and a
gate that checks whether a wire value is equal to zero.
Split Gate. Given input a ∈ Fp known to be in [0,2k − 1], the
split gate outputs k wires holding the binary digits a1, . . . ,ak
i=1 2i−1ai = a, and that
of a. Thus, the QAP ensures that ∑k
each ai is either 0 or 1. For convenience, we number the
output wires 1, . . . ,k and the input wire k + 1.
In our mini-QAP, let t(x) = (x − r)∏k
i=1(x − ri) where
for 1 ≤ i ≤ k, vk+1(r) = 0,
for 1 ≤ i ≤ k, wk+1(r) = 0,
for 1 ≤ i ≤ k, yk+1(r) = 1;
v0(r) = 0,
•
w0(r) = 1, wi(r) = 0
y0(r) = 0,
yi(r) = 0
• For 1 ≤ j ≤ k: v j(r j) = 1, vi(r j) = 0 for all i (cid:54)= j,
w0(r j) = 1, w j(r j) = −1, wi(r j) = 0 for all i (cid:54)= 0, j,
and yi(r j) = 0 for all i.
r,r1, . . . ,rk are distinct roots. We set:
k=1 ak · vk(x)) · (w0(x) + ∑m
k=1 ak · wk(x)) −
If (v0(x) + ∑m
k=1 ak · yk(x)) is divisible by t(x), it must evaluate
(y0(x) + ∑m
to 0 at r, and therefore the ﬁrst set of equations guarantee that
i=1 2i−1ai − a = 0. This guarantees that if all a1, . . . ,ak are
∑k
binary, then they are the binary digits of a. The second set of
equations guarantees that each ai is either 0 or 1. In particu-
lar, for each 1 ≤ j ≤ k, the above polynomial evaluates to 0 at
r j if and only if a j · (1− a j) = 0.
4 Implementation
We implemented a compiler that takes a subset of C to an
equivalent arithmetic circuit (§4.1). Our veriﬁable compu-
tation suite then compiles the circuit representation to the
equivalent QAP, and generates code to run the VC protocol,
including key generation, proof computation, and proof ver-
iﬁcation (§4.2). The toolchain compiles a large collection of
applications and runs them with veriﬁcation (§4.3). Source
code for the toolchain is available [40].
vi(r) = 2i−1
3QSPs still have smaller proofs, since they require only two sets of poly-
nomials (V ,W ) vs. three (V ,W ,Y ).
243
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
int mat[SIZE*SIZE] = { 0x12, ... };
struct In { int vector[SIZE]; };
struct Out { int result[SIZE]; };
void compute(struct In *input, struct Out *output){
int i, j, k, t;
for (i=0; i[i*SIZE+k] * input->vector[k];
}
output->result[i] = t;
}
}
Figure 3: Fixed-Matrix Multiplication. The qcc compiler unrolls
the loops and decodes the struct and array references to generate an
arithmetic expression for Out in terms of In.
4.1 Compiler Toolchain
The applications described below (§4.3) and evaluated in §5
are each compiled using qcc, our C-to-arithmetic-expression
compiler, a 3,525-line Python program [42]. They are also
compiled with gcc to produce the Native timings in Figures 7
and 8. A unit test validates that the gcc and 32-bit qcc exe-
cutables produce matching output on varying inputs.
The compiler understands a substantial subset of C, in-
cluding global, function and block-scoped variables; arrays,
structs, and pointers; function calls, conditionals, loops; and
static initializers (Fig. 3). It also understands arithmetic and
bitwise Boolean operators and preprocessor syntax. The pro-
gram’s entry point is a function
void compute(struct In *in, struct Out *out)
whose parameters identify the set of input and output values.
Since the “target machine” (arithmetic circuits) supports
only expressions, not mutable state and iteration, we re-
strict the C program’s semantics accordingly. For example,
pointers and array dereferences must be compile-time con-
stants; otherwise, each dynamic reference would produce
conditional expressions of size proportional to the address-
able memory. Function calls are inlined, while preserving C
variable scope and pointer semantics.
Imperative conditionals compile to conditional expressions
that encode the imperative side effects. Static conditions are
collapsed at compile time. Similarly, loops with statically-
evaluatable termination conditions are automatically unrolled
completely. A loop with dynamic termination—depending
on an input value—requires a pragma unroll to inform
the compiler how far it should unroll.
The only scalar type presently supported is int; a compiler
ﬂag selects the integer size. The compiler inserts masking
expressions to ensure that a k-bit int behaves exactly as the
corresponding C type, including overﬂow. As described be-
low, our arithmetic circuits operate over a 254-bit ﬁeld; if the
program’s computation is known not to overﬂow 254 bits, the
programmer can disable masking with a compiler ﬂag. We
plan to extend our compiler to support ﬂoating point values
via standard techniques [28, 43].
These features (and limitations) are similar to a parallel ef-
fort [44] to compile C for the purposes of secure multiparty
computation, though they compile only to Boolean circuits.
Details. The compiler front-end tracks scopes and variable
values (as expressions), and unrolls imperative execution into
a ﬁnal program state that provides expressions for each output
value. The intermediate language is a set of expressions of C-
like operators, such as +, *, <=, ?:, &, and ˆ.
The compiler back-end expands each expression into the
arithmetic gate language of mul, add, const-mul, wire-split,
etc., eliminating common subexpressions. It carefully bounds
the bit-width of each wire value:
bit width 4);
• inputs have the compiler-speciﬁed int width;
• each constant has a known width (e.g. 13 = 11012 has
• a bitwise op produces the max of its arguments’ widths;
• add can produce max+1 bits (for a carry); and
• mul can produce 2· max bits.
When the width nears the available bits in the crypto ﬁeld
(254), the compiler generates a split operation to truncate the