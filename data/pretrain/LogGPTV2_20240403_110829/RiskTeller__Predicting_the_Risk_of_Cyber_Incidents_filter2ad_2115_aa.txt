title:RiskTeller: Predicting the Risk of Cyber Incidents
author:Leyla Bilge and
Yufei Han and
Matteo Dell'Amico
RiskTeller: Predicting the Risk of Cyber Incidents
Leyla Bilge
Yufei Han
Matteo Dell’Amico
Symantec Research Labs
PI:EMAIL
Symantec Research Labs
PI:EMAIL
Symantec Research Labs
PI:EMAIL
ABSTRACT
The current evolution of the cyber-threat ecosystem shows that no
system can be considered invulnerable. It is therefore important
to quantify the risk level within a system and devise risk predic-
tion methods such that proactive measures can be taken to reduce
the damage of cyber attacks. We present RiskTeller, a system that
analyzes binary file appearance logs of machines to predict which
machines are at risk of infection months in advance. Risk prediction
models are built by creating, for each machine, a comprehensive
profile capturing its usage patterns, and then associating each pro-
file to a risk level through both fully and semi-supervised learning
methods. We evaluate RiskTeller on a year-long dataset containing
information about all the binaries appearing on machines of 18
enterprises. We show that RiskTeller can use the machine profile
computed for a given machine to predict subsequent infections
with the highest prediction precision achieved to date.
1 INTRODUCTION
Over the last two decades, the cyber-threat ecosystem faced dra-
matic changes. On the one hand, attackers now use sophisticated
tools and techniques to breach systems [32]; on the other hand,
the stakes at risk become larger every year. Experian reports that
almost half of business organizations suffer at least one security
incident per year [8]; despite the efforts in developing and defend-
ing secure systems, hardly anybody in the industry – especially in
large organizations – can feel that their infrastructure is invulnera-
ble. Rather than wondering if they would be victims of malicious
actions, IT administrators are shifting towards trying to understand
when it will happen, and what the consequences will be.
Since malware infections may be unavoidable, the problem of
predicting the risk becomes fundamental: understanding which are
the most risky parts of a given system allows to act proactively, and
focus on hardening them; estimating the infection risk is funda-
mental in the rapidly growing area of cyber-insurance [27]. Cyber-
insurance ensures that organizations and private users alike can
mitigate the cost of otherwise potentially devastating attacks, but
an efficient cyber-insurance market is only feasible if effective ways
of estimating and predicting risk exist.
To date, the research community extensively studied various
aspects of the malware problem mainly focusing on three topics:
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS 2017, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3134022
analysis, detection and prevention. However, only a few works
presented prediction models [4, 16, 19, 30, 37, 38] that could allow
proactive measures to be adopted to avoid the damage. These works
analyzed the users’ demographics [16, 38], network connectivity
behavior [38], web browsing behavior [4, 38], website features [30],
network mismanagement details [19] and historical incident reports
of organizations [19, 37] to predict cyber incidents. We instead
employ a dataset that provides fine graned information about the
security posture of each enteprise machine and allows us to achieve
higher prediction accuracy than previous works.
We present RiskTeller, a system that analyzes per-machine file
appearance logs to predict which machines are at risk of getting
infected by malware. The data is collected from 600K machines
belonging to 18 enterprises. During our analysis, these machines re-
ported a total of 4.4 billion binary file appearance events, resulting
in the largest dataset used for risk prediction to date. We use this
data to generate, for each machine, a profile of 89 features. Features
are based on the volume of events, their temporal patterns, applica-
tion categories, rarity of files, patching behavior, and past threat
history. These features give us a comprehensive synthesis of each
machine’s usage patterns, and a good sense of the security aware-
ness of its users. All together, these features play a fundamental
role for the quality of the results produced by RiskTeller.
Our ground truth is based on observing malicious files and infec-
tion records according to the end point protection software installed
in the period that follows feature extraction: we built it carefully,
avoiding to create labels due to mislabeled files. In an ideal scenario
where the labeled data is sufficiently comprehensive to capture
all clean and risky machine profiles in the wild, supervised ma-
chine learning algorithms can achieve the best accuracy assuming
that the features are selected appropriately. However, such an ideal
ground truth is nearly impossible to obtain as no malware detection
solution can attain perfection due to the known arms-race with the
cyber attackers. Our ground truth leverages a large set of labeled
files (to our knowledge the largest ground truth used so far with
over 1B labeled files) which gives us the confidence that our results
are reliable; we nevertheless question the quality of our ground
truth and investigate whether there is still room for improvement.
To address this problem, in addition to a traditional supervised
machine learning algorithm, we devise a semi-supervised algorithm
that attributes fuzzy labels to unknown user profiles based on their
similarity to the labeled ones; this choice allows us to leverage on
full information available in the dataset and enrich the ground truth
when it is imbalanced or limited in size.
In summary, the contributions of our paper are as follows:
(1) We propose RiskTeller, a system that leverages both su-
pervised and semi-supervised learning methodologies to
predict which machines are at risk with highest accuracy
achived to date.
Session F2:  Insights from Log(in)sCCS’17, October 30-November 3, 2017, Dallas, TX, USA1299(2) We design 89 features that are extracted from per-machine
file appearance logs to produce machine profiles, which cap-
ture the machine’s patterns of usage and security aware-
ness of enterprise users.
(3) We design a semi-supervised machine learning algorithm,
which leverages on profile similarity to infer fuzzy labels
for unlabeled machines based on similar labeled machines
to enrich the ground truth.
(4) We perform a comprehensive evaluation that shows how
RiskTeller can predict which machines will get infected
with high precision, and that the former two steps are
fundamental in getting high-quality results.
2 WHY CYBER RISK PREDICTION?
For around a decade, the security community has been warning
about an imminent “cyber crime era”; the constant stream of news
about cyber security incidents, often reaching the front pages of
mainstream media, shows that the cyber crime era finally arrived.
Unfortunately, facing cyber attacks is now the norm rather than an
exception, and it is hence necessary to set up proactive defenses.
Businesses need to be prepared to minimize damage when attacks
eventually strike; to this end, they need to deploy multiple layers
of security including managed security services, trusted security
advisors, employee training programs etc. in addition to traditional
cyber threat defense mechanisms. Since this can be very expensive,
businesses may need to prioritize; predicting the entities that are
more likely to get attacked and ultimately infected is an important
element on the prioritization step. For example, a special security
training could be provided to the employees that are at higher risk
of cyber attacks through malware sent via email, such that when
they receive mail from attackers they do not open the attachment.
Recently, several security companies started to incorporate cyber
insurance into their multi-layer cyber security approach, to ensure
that the recovery after cyber attacks is less painful. Due to the high
demand for cyber insurance, the market has been steadily grow-
ing and putting the insurance companies in a great competition to
assess and predict the risk the most accurately. Typically [2], risk as-
sessment for cyber insurance uses underwriting tools whose main
goal is to assess the risk of a company through questionnaires with
the least possible questions, or via publicly available data (obtained,
e.g., through active scanning or by looking for the IP addresses
of a company in blacklists). In both cases, the information avail-
able to accurately assess a company’s security posture is limited;
hence, insurance companies have a significantly lower accuracy
than what can be achieved using internal security telemetry. Simi-
larly, in other insurance fields the accuracy of risk assessment that
has been widely adopted is quite low [7, 10, 28] (around 70% predic-
tion accuracy); this is why insurance companies have been seeking
for better risk prediction methodologies that leverage private infor-
mation obtained from the insured entities (e.g., fitness tracking data
for health insurance, driving habits data collected through special
hardware for car insurance, etc.). In our work, we analyze internal
telemetry collected from companies to predict which computers are
most at risk, and thanks to the profiles we build for each computer,
we are able to achieve high prediction accuracy.
We need to emphasize that predicting future events is a different
and more difficult problem than detecting current malicious events.
For detection, false positives can be very expensive (e.g., a user
may not be able to perform their job if an essential software is
erroneously recognized as malware); the goal is hence maximising
the true positive ratio while keeping the false positives very low. On
the other hand, for prediction the main goal is quite the opposite:
an enterprise would want to know all the machines that could
be infected, to apply appropriate hardening measures or provide
security training to users; compared to the detection domain, false
positives are more difficult to avoid, but the cost of false positives is
lower. Previous works in the prediction field produced more than
20% false positives to predict over 95% of the incidents correctly [19];
these numbers are perfectly acceptable for insurance companies.
However, the competition in the market raises the bar and asks for
lower false positives. Our work aims at meeting this expectation.
3 DATASET
Our work builds its foundations by mining large-scale data that
helped us discover interesting behavioral differences between clean
machines and those that are more likely to get infected by malware.
The first dataset we employ consists of reports for the appearance
of new binary files (e.g., due to file downloads or in-house file
creations after compilation), generated by enterprise customers of
a large antivirus company who opted in to share their data, such
that through large-scale data analysis new methodologies can be
developed to increase the existing malware detection capabilities.
To protect customer identities, all sensitive information such as
customer id, IP addresses, and enterprise names are anonymized.
The binary file appearance logs are collected from more than
100K enterprises. Every day, the data centers receive reports about
around 100M file appearances of 14M distinct binaries. We were able
to obtain only a subset of this data, covering 4.4B binary appearance
logs of 600K machines belonging to 18 enterprises: even if its size
is considerably smaller than the full dataset processed by the AV
company, our results show that it is sufficient to model the file
appearance patterns of Internet users and to accurately predict
cyber threats several months in advance.
The fields we are particularly interested in from the binary file
appearance logs are: (a) (anonymized) enterprise and machine iden-
tifiers, (b) SHA2 file hash, (c) file name and directory, (d) file version,
(e) timestamps for the first appearance of the file on the machine
(local timezone) and for the time when it was reported to the data
centers (PST), and (f) file signer subject in the certificate.
3.1 Data Preprocessing
As discussed earlier, the data fields we include in our analysis are
enterprise and machine identifiers, file hash, name, directory, and
version, timestamps for file appearance and report, reputation and
name of the file signer. To extract better value from this information,
we perform some data normalization and cleaning.
We normalize file and directory names to identify those likely to
perform the same functions. We remove version numbers through
simple regular expressions (version numbers in general appear
in filenames as groups of numerical characters separated by dots
with occasional alphabetical characters, e.g., “v2.45.7r5”), and
Session F2:  Insights from Log(in)sCCS’17, October 30-November 3, 2017, Dallas, TX, USA1300also remove suffixes generally appended to duplicate files, such as
numbers wrapped inside brackets (“()”, “[]”, and “{}”).
Unfortunately, our datasets do not include specific information
about which applications binary files belong to: we therefore resort
to directory name to infer them. In Windows systems, applications
use the CSIDL (Constant Special Item Id List)1 to identify the name
of special folders in each Windows installation, and our datasets in
a majority of the cases include normalized directory names (we nor-
malize the remaining following the guidelines of CSIDL) rather than
the full path including variable information such as drive identifiers,
usernames, and OS-specific strings. Applications are installed in
the CSIDL_PROGRAM_FILES directory, and our heuristic to identify
an application is to use depth-3 paths starting from that directory
to identify applications; for example, the directory corresponding
to Google Chrome is \CSIDL_PROGRAM_FILES\google\chrome.
This is the string that we use to recognize applications.
3.2 Ground Truth
We split our datasets in two consecutive periods: a first feature
extraction period from which we compute features that will be fed
to our classifier, and a labeling period from which we identify a
ground truth of “clean” and “infected” machines. Riskteller performs
prediction in a temporal sense, meaning that the classifier only uses
features from the feature extraction period to predict labels that
are based on events happening in the successive labeling period.
In addition to the binary appearance logs dataset, we leverage
three more datasets that we use to build our ground truth. As we
discuss in Section 5, our predictive model leverages supervised and
semi-supervised machine learning techniques to differentiate the
clean machines from those that are likely to encounter malware
infections. As the quality of machine learning techniques strongly
depends on the quality of the ground truth, we endeavor to de-
fine clean and risky machine profiles in a way that minimizes the
probability of errors.
We build our ground truth using three different datasets:
(1) A labeled dataset we obtained from the AV company at the
end of 2015, consisting of 16M known benign and 214M
known malware file hashes; note that this dataset is up-
dated continuously whenever new labels are acquired.
(2) A dataset of file hashes that were identified as malware
according to the AV product, and that has never been man-
ually exonerated (i.e., marked as false positive) by users.
By the end of 2015 the AV telemetry dataset, which con-
sists of detailed reports about the type of malware the files
are associated with, contained 800M hashes. The fact that
these files were never marked as false positives gives us
confidence that very few of these files are actually benign.
(3) A dataset of malware infections detected through the net-
work activity of machines. For example, if the machine
initiates a command-and-control activity with known Zeus
C&C servers, the machine is flagged as infected. We ob-
tain the network-based infection data from the telemetry
dataset generated by the IPS product of the company.
1https://msdn.microsoft.com/en-us/library/windows/desktop/bb762494(v=
vs.85).aspx
In Section 6.1.2 we describe in more detail how we define thresh-
olds to identify clean and risky profiles; here we limit ourselves to a
brief summary. We define as “clean” a machine with a very limited
number of unknown files, zero files known to be malware, and no
infection record. On the other hand, we consider “risky” a machine
that, during the labeling period, has multiple known malware files
in its file appearance logs and/or records of infections according to
the IPS telemetry dataset.
4 BUILDING THE MACHINE PROFILES
As the main goal of our work is to be able to predict which machines
are most likely to get infected, we perform an in-depth investigation