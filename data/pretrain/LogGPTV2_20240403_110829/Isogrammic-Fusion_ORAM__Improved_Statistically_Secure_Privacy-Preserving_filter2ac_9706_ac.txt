to-leaf path has the same length, which is O (log n/ log w ). Note that
each leaf can be viewed as having an address of O (log(n/ logc n))
bits in a standard numbering of the leaves, so that each root-to-leaf
path can be determined by the bits from this address, where going
from any node to the appropriate child is performed by “reading
off” the next O (log w ) bits from this address, which determine the
appropriate next node in the fusion tree, and then reading that
next node. This allows us to perform a root-to-leaf search in H by
visiting the O (log n/ log w ) nodes in such a root-to-leaf path, each
of which is represented using O (1) words. That is, we can perform
such a search using a thin client. Moreover, the tree, H, is static, so
we don’t need to add or remove nodes from H.
We use H as our primary “outer loop” data structure, then, for
our simulation of an isogrammic access sequence. For any item,
(k, v), belonging to our current set of items, the key, k, is mapped
to a specific root-to-leaf path in H, which is determined by the
first O (log(n/ logc n)) bits in the random part of k. During our OS
simulation, we maintain the invariant that each key-value pair,
(k, v), is stored in the bucket, bu, for exactly one node, u, on the
root-to-leaf path in H for the random part of k. With this in mind, let
us describe our algorithms for processing get and put operations,
then, using H. We describe the functioning of these operations
from the perspective of the client, Alice. From the perspective of
the server, Bob, the functioning of these operations will look the
same. Thus, Bob cannot even distinguish whether an operation is a
put or a get.
Each put(k, v) operation begins by inserting the item, (k, v), in
the bucket, br , for the root, r, of H, using the fusion-tree OS method
described in Section 3. Note that this satisfies our invariant for
storing items in H; we will describe later what we do when the
root bucket becomes full so as to continue satisfying our invariant.
Then, for the sake of obliviousness (so Bob cannot tell whether this
operation is a get or put), we uniformly and independently choose
a random key, k′, and traverse the root-to-leaf path in H for k′,
performing a search for k′ in the bucket, bu, for each node u on this
path, using the fusion-tree OS method described in Section 3. Alice
just “throws away” the results of these searches, but, of course, Bob
doesn’t know this.
For any given get(k ) operation, we begin, for the sake of oblivi-
ousness, by inserting a dummy item, (k′, e), in the bucket, br , for the
root, r, of H, where e is a special “empty” value and k′ is a random
key, using the fusion-tree OS method described in Section 3. So
as to distinguish this type of dummy item from others, we refer
to each such dummy item as an original dummy item. We then
traverse the root-to-leaf path, π, for (the random part of) k in H,
and, for each node, u, in π, we search in the bucket, bu, for u to see
if the key-vaue pair for k is in this bucket, using the fusion-tree OS
scheme described above in Section 3. By our invariant, the item,
(k, v), must be stored in the bucket for one of the nodes in the path
π. Note that we search in the bucket for every node in π, even after
we have found and removed the key-value pair, (k, v). Because we
are simulating an isogrammic access sequence, there will be one
bucket with this item, but we search all the buckets for the sake of
obliviousness.
An important consequence of the above methods and the fact
that we are simulating an isogrammic access sequence is that each
traversal of a path in H is determined by a random index that
is chosen uniformly at random and is independent of every other
index used to do a search in H. Thus, the server, Bob, learns nothing
about Alice’s access pattern from these searches. In addition, as
we will see shortly, the server cannot determine where any item,
(k, v), is actually stored, because the random part of the key k is
only revealed when we do a get(k ) operation and put operations
never reveal the locations of their keys. Moreover, we maintain the
fact that the server doesn’t know the actual location of any item,
along with our invariant, even as bucket for a node, u, becomes full
and needs to have its items distributed to its children.
Periodically, so as to avoid overflowing buckets, we move items
from a bucket, bu, stored at a node u in H to u’s children, in a process
we call a flush operation. In particular, we flush the root node, r,
every L put or get operations. We flush each internal node, u, after u
has receivedW flushes from its parent, which each involve inserting
exactly 4L/W real and dummy items (including new dummy items)
into the bucket for u. Because of this functionality, and the fact that
we are moving items based on random keys, the number of real
and original dummy items in the bucket, bu, at a time when we are
flusing a node u at depth i is expected to be L, and it is at most 4L
with high probability. Also, note that we will periodically perform
flush operations across all the nodes on a given level of H at any
given time when flush operations occur, which is the main reason
why our I/O overhead bounds are amortized. We don’t flush the leaf
nodes in H, however. Instead, after every leaf, u, in H has received
W flushes, we perform an oblivious compression to compress out
a sufficient number of dummy items so that the number of real
and dummy items in u’s bucket is 4L. Thus, the bucket for a leaf
never grows to have more than 8L real and dummy items. If, at
the time we are compressing the contents of a leaf bucket, we
determine that there are more than 4L real items being stored in
such a bucket, which, as we show, is an event that occurs with
low probability, then we restart the entire OS simulation. Such an
event doesn’t compromise privacy, since it depends only on random
keys, not Alice’s data or access sequence. Thus, doing a restart just
Session 16: Applied Crypto 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea703impacts performance, but because restarts are so improbable, our
I/O bounds still hold with high probability. Our method for doing a
flush operation at a node, u, in H is as follows:
(1) We obliviously shuffle the real and original dummy items of
bu into an array, A, of size 4L, stored at the server. This step
will never overflow A (because of how we perform the rest
of the steps in a flush operation). This step can be done using
known oblivious shuffling methods (e.g., see [1, 6, 10, 12]).
(2) For each child, xi, i = 1, 2, . . . ,W , of u, we create an array,
Ai, of size 4L/W .
(3) We obliviously sort the real and original dummy items from
A into the arrays, A1, . . . , Aℓ, according the keys for these
items, so that the item, (k, v), goes to the array Ai if the
next O (log w ) bits of the key k would direct a search for k to
the child xi. We perform this oblivious sorting step so that
if there are fewer than 4L/W items destined for any array,
Ai, we pad the array with (new) dummy items to bring the
number of items destined to each array, Ai, to be exactly
4L/W . However, if we determine from this oblivious sorting
step that there are more than 4L/W real and original dummy
items destined for any array, Ai, which (as we show) is an
event that occurs with low probability, then we restart the
entire OS simulation. Because this step is done obliviously
and keys are random (hence, they never depend on Alice’s
data values or access pattern), even if we restart, Bob learns
nothing about Alice’s access sequence during this step. So,
let us assume that we don’t restart. This step can be done
using known oblivious sorting, padding, and partitioning
methods (e.g., see [1, 6, 10, 12]).
(4) For each real and dummy item (including both original and
new dummy items), (k, v), in each Ai, we insert (k, v) into
the bucket bxi
using the fusion-tree OS method of Section 3.
The first important thing to note about a flush operation is that
it is guaranteed to preserve our invariant that each item, (k, v),
is stored in the bucket of a node in H on the root-to-leaf path
determined by the random part of k. Moreover, because we move
real and original dummy items to children nodes obliviously, in
spite of our invariant, the server never knows where an item,
(k, v), is stored; hence, the server can never differentiate two access
sequences more than random.
Since we flush the root every L steps, and we flush every other
node, u, at depth i, after it has received W flushes, and both real
and original dummy items are mapped to u only if the first i logW
bits of each of their random keys matches u’s address, the expected
number of real and original dummy items stored in the bucket
for u is at most L at the time we flush u. In fact, this is a rather
conservative estimate, since it assumes that none of these items
were removed as a result of get operations.
Lemma 3. The number, f , of real and original dummy items
flushed from a node, u, to one of its children, xi , is never more than
4L/W , with high probability. Likewise, a leaf in H will never receive
more than 4L real items, with high probability.
Theorem 4. We can obliviously simulate an isogrammic sequence
of a polynomial number of put(k, v) and get(k ) operations, for a data
set of size n, with an I/O overhead of O (log n log log n), for constant-
sized client-sized memory, or O (log n) with client-side memory of
size O (logϵ n), for a fixed constant 0 < ϵ ≤ 1/2. This simulation
achieves statistical security and has the claimed I/O overhead bounds
with high probability.
Putting the above pieces together, then, gives us the following:
Theorem 5. Given a RAM algorithm, A, with memory size, n,
where n is a power of 2, we can simulate the memory accesses of A
in an oblivious fashion that achieves statistical security, such that,
with high probability, the I/O overhead is O (log2
n log log n) for a
constant-size client-side private memory and is O (log2
n) for a client-
side private memory of size O (logϵ n), for a constant 0 < ϵ ≤ 1/2. In
either case, messages are of size O (1).
ACKNOWLEDGMENTS
This research was supported by the NSF under grant 1228639, and
DARPA under agreement no. AFRL FA8750-15-2-0092. The views
expressed are those of the author and do not reflect the official policy
or position of the Department of Defense or the U.S. Government.
We thank Eli Upfal and Marina Blanton for helpful discussions.
REFERENCES
[1] M. Ajtai, J. Komlós, and E. Szemerédi. 1983. Sorting in c log n Parallel Steps.
[2] Arne Andersson, Peter Bro Miltersen, and Mikkel Thorup. 1999. Fusion trees
Combinatorica 3, 1 (1983), 1–19.
can be implemented with AC0 instructions only. Theoretical Computer
Science 215, 1-2 (1999), 337–344.
[3] Kai-Min Chung, Zhenming Liu, and Rafael Pass. 2014. Statistically-secure
ORAM with ˜O (log2 n) Overhead. In 20th ASIACRYPT. 62–81.
Archive, Report 2013/243. (2013). https://eprint.iacr.org/2013/243.
[4] Kai-Min Chung and Rafael Pass. 2013. A Simple ORAM. Cryptology ePrint
[5] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein.
[8] Michael L. Fredman and Dan E. Willard. 1993. Surpassing the information
[6] Ivan Damgård, Sigurd Meldgaard, and Jesper Buus Nielsen. 2011. Perfectly
[11] Michael T. Goodrich. 2017. BIOS ORAM: Improved Privacy-Preserving Data
[10] Michael T. Goodrich. 2014. Zig-zag Sort: A Simple Deterministic Data-oblivious
2009. Introduction to Algorithms (3rd ed.). The MIT Press.
Secure Oblivious RAM without Random Oracles. In 8th Theory of
Cryptography Conference (TCC). LNCS, Vol. 6597. 144–163.
[7] Christopher W. Fletcher, Muhammad Naveed, Ling Ren, Elaine Shi, and Emil
Stefanov. 2015. Bucket ORAM: Single Online Roundtrip, Constant Bandwidth
Oblivious RAM. IACR Cryptology ePrint Archive 2015 (2015), 1065.
theoretic bound with fusion trees. J. Comput. System Sci. 47, 3 (1993), 424–436.
[9] Oded Goldreich and Rafail Ostrovsky. 1996. Software Protection and Simulation
on Oblivious RAMs. J. ACM 43, 3 (May 1996), 431–473.
Sorting Algorithm Running in O (n log n) Time. In STOC. 684–693.
Access for Parameterized Outsourced Storage. In WPES. 41–50.
[12] Michael T. Goodrich and Michael Mitzenmacher. 2011. Privacy-Preserving
Access of Outsourced Data via Oblivious RAM Simulation. In 28th ICALP
(LNCS), Vol. 6756. 576–587.
[13] Michael T. Goodrich, Michael Mitzenmacher, Olga Ohrimenko, and Roberto
Tamassia. 2012. Practical Oblivious Storage. In CODASPY. 13–24.
[14] Eyal Kushilevitz, Steve Lu, and Rafail Ostrovsky. 2012. On the (in)Security of
Hash-based Oblivious RAM and a New Balancing Scheme. In SODA. 143–156.
[15] Michael Mitzenmacher and Eli Upfal. 2005. Probability and computing:
Randomized algorithms and probabilistic analysis. Cambridge Univ.
[16] Olga Ohrimenko, Michael T. Goodrich, Roberto Tamassia, and Eli Upfal. 2014.
The Melbourne Shuffle: Improving Oblivious Storage in the Cloud. In ICALP
(LNCS), Vol. 8573. 556–567.
[17] Emil Stefanov and Elaine Shi. 2013. Multi-cloud Oblivious Storage. In CCS.
247–258.
[18] E. Stefanov and E. Shi. 2013. ObliviStore: High Performance Oblivious Cloud
[19] Emil Stefanov, Marten van Dijk, Elaine Shi, Christopher Fletcher, Ling Ren,
Storage. In IEEE Symp. on Security and Privacy (SP). 253–267.
Xiangyao Yu, and Srinivas Devadas. 2013. Path ORAM: An Extremely Simple
Oblivious RAM Protocol. In CCS. 299–310.
the Goldreich-Ostrovsky Lower Bound. In CCS. 850–861.
Stefanov, and Yan Huang. 2014. Oblivious Data Structures. In CCS. 215–226.
[20] Xiao Wang, Hubert Chan, and Elaine Shi. 2015. Circuit ORAM: On Tightness of
[21] Xiao Shaun Wang, Kartik Nayak, Chang Liu, T-H. Hubert Chan, Elaine Shi, Emil
Session 16: Applied Crypto 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea704Method
Thin Client?
Statistically Secure?
Goldreich-Ostrofky [9]
Damgård et al. [6]
Goodrich-Mitzenmacher [12]
Kushilevitz et al. [14]
Melbourne shuffle [16]
Path ORAM [19]
Supermarket ORAM [3]
BIOS ORAM [11]
Isogrammic-fusion ORAM 1
Isogrammic-fusion ORAM 2
Yes
Yes
No
Yes
No
No
No
No
Yes
Yes
No
Yes