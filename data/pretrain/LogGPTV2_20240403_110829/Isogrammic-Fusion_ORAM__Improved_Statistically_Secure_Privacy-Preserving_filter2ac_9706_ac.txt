### Optimized Text

In a fusion tree, every root-to-leaf path has the same length, which is \( O(\log n / \log w) \). Each leaf can be considered to have an address of \( O(\log(n / \log_c n)) \) bits in a standard numbering of the leaves. This means that each root-to-leaf path can be determined by the bits from this address. Moving from any node to its appropriate child involves "reading off" the next \( O(\log w) \) bits from the address, which determine the next node in the fusion tree. This allows us to perform a root-to-leaf search in the tree \( H \) by visiting the \( O(\log n / \log w) \) nodes along such a path, each of which is represented using \( O(1) \) words. Thus, we can perform such a search using a thin client. Additionally, the tree \( H \) is static, so no nodes need to be added or removed.

We use \( H \) as our primary "outer loop" data structure for simulating an isogrammic access sequence. For any item \((k, v)\) in our current set of items, the key \( k \) is mapped to a specific root-to-leaf path in \( H \), determined by the first \( O(\log(n / \log_c n)) \) bits of the random part of \( k \). During the simulation, we maintain the invariant that each key-value pair \((k, v)\) is stored in the bucket \( b_u \) for exactly one node \( u \) on the root-to-leaf path in \( H \) for the random part of \( k \).

### Algorithms for get and put Operations

#### put(k, v) Operation
1. Insert the item \((k, v)\) into the bucket \( b_r \) for the root \( r \) of \( H \) using the fusion-tree OS method described in Section 3. This satisfies our invariant for storing items in \( H \).
2. To ensure obliviousness (so Bob cannot tell whether this operation is a get or put), uniformly and independently choose a random key \( k' \) and traverse the root-to-leaf path in \( H \) for \( k' \). Perform a search for \( k' \) in the bucket \( b_u \) for each node \( u \) on this path using the fusion-tree OS method. Alice discards the results of these searches, but Bob remains unaware of this.

#### get(k) Operation
1. For the sake of obliviousness, insert a dummy item \((k', e)\) into the bucket \( b_r \) for the root \( r \) of \( H \), where \( e \) is a special "empty" value and \( k' \) is a random key, using the fusion-tree OS method.
2. Traverse the root-to-leaf path \( \pi \) for the random part of \( k \) in \( H \). For each node \( u \) in \( \pi \), search in the bucket \( b_u \) to see if the key-value pair for \( k \) is present, using the fusion-tree OS scheme. By our invariant, the item \((k, v)\) must be stored in the bucket for one of the nodes in the path \( \pi \). We search in the bucket for every node in \( \pi \), even after finding and removing the key-value pair, to maintain obliviousness.

### Consequences and Privacy
The above methods, combined with the fact that we are simulating an isogrammic access sequence, ensure that each traversal of a path in \( H \) is determined by a random index chosen uniformly at random and independently of other indices used for searches in \( H \). This means that the server, Bob, learns nothing about Alice's access pattern from these searches. Furthermore, since the random part of the key \( k \) is only revealed during a get operation and put operations never reveal the locations of their keys, the server cannot determine where any item \((k, v)\) is actually stored.

### Flush Operations
To avoid overflowing buckets, we periodically move items from a bucket \( b_u \) stored at a node \( u \) in \( H \) to \( u \)'s children in a process called a flush operation. Specifically:
- Flush the root node \( r \) every \( L \) put or get operations.
- Flush each internal node \( u \) after it has received \( W \) flushes from its parent, each involving inserting exactly \( 4L/W \) real and dummy items (including new dummy items) into the bucket for \( u \).

Due to this functionality and the randomness of the keys, the number of real and original dummy items in the bucket \( b_u \) at the time of flushing a node \( u \) at depth \( i \) is expected to be \( L \) and is at most \( 4L \) with high probability. We also periodically perform flush operations across all nodes on a given level of \( H \) when flush operations occur, which amortizes our I/O overhead bounds.

We do not flush the leaf nodes in \( H \). Instead, after every leaf \( u \) in \( H \) has received \( W \) flushes, we perform an oblivious compression to compress out a sufficient number of dummy items so that the number of real and dummy items in \( u \)'s bucket is \( 4L \). This ensures that the bucket for a leaf never grows to have more than \( 8L \) real and dummy items. If, during the compression of a leaf bucket, we determine that there are more than \( 4L \) real items, we restart the entire OS simulation. Such an event does not compromise privacy and only impacts performance, but because restarts are improbable, our I/O bounds still hold with high probability.

### Theorem and Lemma
**Lemma 3.** The number \( f \) of real and original dummy items flushed from a node \( u \) to one of its children \( x_i \) is never more than \( 4L/W \), with high probability. Likewise, a leaf in \( H \) will never receive more than \( 4L \) real items, with high probability.

**Theorem 4.** We can obliviously simulate an isogrammic sequence of a polynomial number of put\((k, v)\) and get\((k)\) operations for a data set of size \( n \) with an I/O overhead of \( O(\log n \log \log n) \) for constant-sized client memory, or \( O(\log n) \) with client-side memory of size \( O(\log^\epsilon n) \), for a fixed constant \( 0 < \epsilon \leq 1/2 \). This simulation achieves statistical security and has the claimed I/O overhead bounds with high probability.

**Theorem 5.** Given a RAM algorithm \( A \) with memory size \( n \) (where \( n \) is a power of 2), we can simulate the memory accesses of \( A \) in an oblivious fashion that achieves statistical security. With high probability, the I/O overhead is \( O(\log^2 n \log \log n) \) for a constant-size client-side private memory and is \( O(\log^2 n) \) for a client-side private memory of size \( O(\log^\epsilon n) \), for a constant \( 0 < \epsilon \leq 1/2 \). In either case, messages are of size \( O(1) \).

### Acknowledgments
This research was supported by the NSF under grant 1228639 and DARPA under agreement no. AFRL FA8750-15-2-0092. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. We thank Eli Upfal and Marina Blanton for helpful discussions.

### References
[References section remains unchanged]