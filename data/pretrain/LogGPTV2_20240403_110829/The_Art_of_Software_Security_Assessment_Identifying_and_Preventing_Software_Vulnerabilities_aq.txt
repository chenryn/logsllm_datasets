discussed in the CP1 strategy. This strategy has gotten a lot of press in the past few 
years, as software companies scramble to find simpler and less expensive methods of 
securing their applications. The result has been an explosion in the number and 
variety of source analysis tools. 
Table 4-10. CP2: Automated Source Analysis Tool 
Start point 
Potential vulnerabilities 
End point 
Any form of user-malleable input 
Tracing method 
Backward, control-flow sensitive, data-flow sensitive 
Goal 
Identify vulnerabilities based on a list of candidate points and 
code paths obtained from automated analysis tools. 
Difficulty 
Easy to moderate 
Speed 
Fast to very slow (depending on false-positive rate) 
Comprehension 
impact 
Very low 
Abstraction 
Basic implementation through complex implementation 
Strengths 
Good coverage for easily identified vulnerabilities 
Isn't mentally taxing 
Hard to go off track 
Weaknesses 
Biases the reviewer to confirming only a limited set of potential 
issues Comprehension impact is much lower than with code 
comprehension strategies 
The results are only as good as your search method 
Early source-code analysis systems were just simple lexical analyzers; they searched 
for patterns matching potentially vulnerable source strings. Newer systems can 
actually perform a fairly detailed analysis of an application's data flow and identify 
several classes of vulnerabilities. These tools can be helpful in identifying candidate 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
134 
points and even offer some level of analysis to speed up manual review of identified 
candidates. 
The downside of automated source analysis tools is that they are in their infancy. The 
current batch of tools require a high time and cost investment and have inconsistent 
performance. Most tools require extensive configuration and have serious issues with 
identifying excessive false-positive candidate points. This problem is so severe that 
the results of the tool are often ignored because of time required to trace all the 
false-positive results. 
Finally, as a candidate point strategy, automated source analysis tools focus only on 
a specific set of potentially vulnerable idioms. Therefore, they are limited in the 
classes of vulnerabilities they can detect. Even the best automated source analysis 
tools fail to identify simple vulnerabilities outside their parameters or complex 
vulnerabilities that lack an easily defined direct relationship. These complex 
vulnerabilities include most design and logic vulnerabilities in addition to many of the 
more complex implementation vulnerabilities. 
Taking all the preceding points into account, there is still a lot of potential for 
automated source analysis tools. The technology will certainly improve, and the 
long-term benefits will eventually outweigh the downsides. In fact, many 
development groups are already using automated analysis to augment manual code 
review and internal quality control. This practice can be expected to grow as tools 
become more flexible and can be integrated into the complete review process more 
effectively. 
Simple Lexical Candidate Points 
A wide range of vulnerabilities lend themselves to identification based on simple 
pattern-matching schemes (the CP3 strategy shown in Table 4-11). Format string 
vulnerabilities and SQL injection are two obvious examples. In identifying these 
vulnerabilities, the reviewer uses a utility such as grep or findstr to generate a list of 
candidate points from across a codebase. This list is then paired down based on what 
the reviewer knows about the application design. For instance, you should be able to 
eliminate the majority of these candidate points by simply identifying whether they 
are in a module that handles any potentially malicious input. After the list has been 
paired down, you use the general candidate point approach (CP1) to identify any 
exploitable paths to this location. 
Table 4-11. CP3: Simple Lexical Candidate Points 
Start point 
Potential vulnerabilities 
End point 
Any form of user-malleable input 
Tracing method 
Backward, control-flow sensitive, data-flow sensitive 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
135 
Table 4-11. CP3: Simple Lexical Candidate Points 
Start point 
Potential vulnerabilities 
Goal 
Identify potential vulnerabilities based on simple pattern 
matching, and then trace to entry points for confirmation. 
Difficulty 
Easy to moderate 
Speed 
Fast to medium (depending on the number of points) 
Comprehension 
impact 
Low 
Abstraction 
Basic implementation through complex implementation 
Strengths 
Good coverage for known vulnerability classes 
Isn't too mentally taxing 
Hard to go off track 
Weaknesses 
Capable of confirming only a limited set of potential issues 
Comprehension impact is almost nonexistent 
The results are only as good as the search pattern 
Simple Binary Candidate Points 
As with source analysis, a range of candidate points can be identified fairly easily in an 
application's binary code (the CP4 strategy shown in Table 4-12). For example, you 
can identify a starting list of candidate points for sign extension vulnerabilities by 
listing the occurrences of the MOVSX instruction on an Intel binary executable. You 
can also search for many equivalent source patterns in the binary; this method is 
essential when you don't have access to the application's source code. You can then 
pair down the list and trace in essentially the same manner you would for the lexical 
candidate point strategy (CP3). 
Table 4-12. CP4: Simple Binary Candidate Points 
Start point 
Potential vulnerabilities 
End point 
Any form of user-malleable input 
Tracing method 
Backward, control-flow sensitive, data-flow sensitive 
Goal 
Identify potential vulnerabilities based on patterns in the 
application's binary code and then trace to entry points for 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
136 
Table 4-12. CP4: Simple Binary Candidate Points 
Start point 
Potential vulnerabilities 
confirmation. 
Difficulty 
Easy to moderate 
Speed 
Fast to medium (depending on the number of points) 
Comprehension 
impact 
Low 
Abstraction 
Basic implementation through complex implementation 
Strengths 
Good coverage for known vulnerability classes 
Isn't too mentally taxing 
Hard to go off track 
Weaknesses 
Capable of confirming only a limited set of potential issues 
Comprehension impact is almost nonexistent 
The results are only as good as the search pattern 
Black Box-Generated Candidate Points 
When black box testing returns results indicating software bugs, you need to work 
backward from the fault point to find the cause. This strategy (CP5) is summarized in 
Table 4-13. 
Table 4-13. CP5: Black Box-Generated Candidate Points 
Start point 
Potential vulnerabilities 
End point 
Any form of user-malleable input 
Tracing method 
Backward, control-flow sensitive, data-flow sensitive 
Goal 
Identify potential vulnerabilities based on patterns in the 
application binary and then trace to entry points for 
confirmation. 
Difficulty 
Easy to moderate 
Speed 
Fast to medium (depending on the number of points) 
Comprehension 
impact 
Low 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
137 
Table 4-13. CP5: Black Box-Generated Candidate Points 
Start point 
Potential vulnerabilities 
Abstraction 
Basic implementation through complex implementation 
Strengths 
Good coverage for known vulnerability classes 
Is not overly taxing mentally 
Hard to go off track 
Weaknesses 
Only capable of confirming a limited set of potential issues 
Comprehension impact is almost nonexistent 
The results are only as good as the tool 
Most of the time, the black box method involves performing some level of crash 
analysis. To perform this step, you probably need to be familiar with assembly code. 
Many debuggers can correlate source code with assembly code to some degree, so if 
you have source code available, you might not need to be as familiar with assembly 
code. Sooner or later, however, a good auditor should be competent at reading and 
interpreting assembly code. Fortunately, it's something that you will almost certainly 
pick up with experience, and you can take advantage of a lot of available literature on 
assembly code for a variety of architectures. Because most popular software is 
compiled for Intel platforms, you will probably want to learn this platform first. In 
addition to books and online tutorials, you can find a comprehensive manual of the 
Intel instruction set and programming guides from Intel at 
www.intel.com/design/pentium4/manuals/index_new.htm. 
Now you have the challenge of tracing backward from a memory dump of where the 
crash occurred to where in the code something went wrong. This topic could warrant 
an entire chapter or more, but because it's not the focus of this chapter (or the book), 
just the basics are covered. First, some crash dumps are easy to find because they 
crash precisely at the location where the bug is triggered. Consider this following code, 
for example: 
text:76F3F707            movzx   ecx, word ptr [eax+0Ah] 
text:76F3F70B            dec     ecx 
text:76F3F70C            mov     edx, ecx 
text:76F3F70E            shr     ecx, 2 
text:76F3F711            lea     edi, [eax+19h] 
text:76F3F714            rep movsd 
text:76F3F716            mov     ecx, edx 
text:76F3F718            and     ecx, 3 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
138 
text:76F3F71B            rep movsb 
text:76F3F71D            pop     edi 
text:76F3F71E            pop     esi 
A huge memory copy will occur, assuming you can control the short integer located at 
[eax+0Ah] and set that integer to 0. If it's set to 0, the dec ecx instruction causes an 
integer underflow, which results in a large memory copy. 
Note 
This type of bug is discussed in more detail in Chapter 6(? [????.]), "C Language 
Issues." Don't worry if you don't understand it now. Just be aware that a huge 
memory copy occurs as a result, thus corrupting large amounts of program data. 
If you had fuzz-tested this bug, it would crash on the rep movsd instruction. This bug 
is fairly straightforward to analyze via back-tracing because you know instantly where 
the crash occurs. 
The remaining work is to figure out where [eax+0Ah] is populated. Usually you search 
the immediate function where the application has crashed; failing that, you might 
need to do more investigative work. In this case, you need to see where the eax 
register was set and trace back to find where it was allocated. In object-oriented code, 
references like this might refer to an object instantiation of a class, which makes 
things more difficult (if you have only the binary to work with) because you can't see 
a direct path from the population of that memory location to a place where it's 
referenced and used. Thankfully, othersin particular, Halvar Flakehave done work on 
dealing with object recognition in binaries and weeding out unwanted code paths to 
help isolate activity in a certain part of the application. (Flake's BinNavi tool and 
objrec IDA plug-in are described in "Binary Navigation Tools(? [????.])," later in this 
chapter.) In this situation, a crash is analyzed with this basic procedure: 
1.  Examine the instruction where the program crashed to see why the fault was 
generated. Was an invalid source operand read? Was an invalid destination 
operation written to? Was an index to a memory location too large or too small? 
Was a loop counter not a sane value? 
2.  Work backward to determine where the invalid operand came from. Look back in 
the local function to see where the relevant register was populated. Was it 
populated by a structure member? Was it set locally? Is it an argument? For 
structure or object members, this step might involve quite a bit of work. 
3.  Connect the invalid operand with some data fed into the program at the entry 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
139 
point you were fuzz-testing. Determine what part of the data caused the 
exception to occur. 
The second example of dealing with faults happens when the application crashes at a 
seemingly random location. This can happen when memory corruption occurs at 
some point in the program but the corrupted memory region isn't accessed (or 
accessed in such a way that a fault is generated) until much later in the code. In fact, 
in the previous assembly example, imagine that you traced it back and determined 
that [eax+0Ah] was set to 10 when a class was initialized and is never changed. This 
crash then becomes mystifying because you have determined that [eax+0Ah] is never 
set to 0, yet here it is crashing because it was set to 0! In this case, what has likely 
happened is one of two things: 
You corrupted memory somewhere early in the structure that eax points to. 
You corrupted another buffer on the heap, and it has overwritten the structure 
eax points to. 
If the first case is true, when you fuzz the application again with the same input, an 
identical crash will probably occur, but if the second case is true, the application might 
crash somewhere totally different or not at all. 
So how do you find out what's going on? Several tools are available to help you 
discover the cause of a fault, depending on the nature of the vulnerability. The easiest 
one to discover is when a buffer that's not part of any sort of structure has been 
allocated on the heap and overflowed. Although the random crashes seem like a 
problem at first, you can isolate problems such as this one fairly quickly. Microsoft has 
a tool named gflags that's part of the Microsoft Debugging Tools for Windows 
(available at www.microsoft.com/whdc/devtools/debugging/debugstart.mspx), 
which is useful in this situation. In particular, you can use it to enable "heap paging" 
functionality in the process you're debugging. Essentially, heap paging causes each 
request for memory to be allocated at the end of a page so that a guard page 
immediately follows the memory allocated. So when a buffer overflow occurs, an 
attempt is made during the copy operation to write data to the guard page, thus 
triggering an exception. Therefore, you can cause an exception to occur immediately 
when the bug is triggered. 
Custom memory allocators might be more difficult, however. One approach is to 
intercept calls to the custom memory allocation routines and redirect them to system 
allocation routines. The difficulty of this approach depends on the OS, whether 
memory allocators are in a separate shared library, and whether they are externally 
accessible symbols. Other solutions might include patching binary code to make the 
custom memory allocators do nothing except call the real allocation routines. Some of 
these methods can become messy and programming intensive, but your choice 
depends on the testing environment and what tools you have available. For example, 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
140 
in a UNIX environment, hijacking function calls to a shared library is quite simple 
using the LD_PRELOAD functionality that UNIX linkers provide. You can set this 
environment variable to direct the linker to load a library of your choosing instead of 
the library function that's intended to be called. 
Note 
The LD_PRELOAD linker functionality has been a target of security bugs in the past, 
and it's discussed in more detail in the coverage of UNIX vulnerabilities in Chapter 10(? 
[????.]), "Unix II: Processes." 
Another quick-and-dirty hack involves using a debugger to manually redirect calls 
from one location to another to cause different allocation routines to be called. For 
example, you could set a breakpoint in a debugger on a custom application, and then 
set the instruction pointer to point to the system's memory allocator whenever the 
breakpoint is triggered. This method is tedious because allocations probably occur 
hundreds of times in the application you're examining; however, many debuggers 
enable you to create scripts or carry out tasks automatically when a breakpoint is 
triggered. For example, in the SoftICE debugger, you could issue the following 
command: 
bpx 12345678 DO "r eip malloc" 
This command sets a breakpoint on memory location 0x12345678 (assuming the 
custom memory allocator is at that location). When the breakpoint is triggered, the 
instruction pointer is changed to point to the malloc() routine instead. 
If you have corrupted a structure, you need to examine the effects of that corruption 
to understand how it occurred. Look for the offset of the lowest corrupted structure 
member to get a more accurate location. Once you know the location, you should be 
able to determine that the corruption occurred in one of the following two ways: 
A buffer in the structure was the target of an unsafe copy. 
An array of some other data type (integers or pointers, perhaps) has been 
copied into unsafely because of an invalid index into that array or because it 
simply copied too many elements into the array. 
So you need to identify where the corrupted elements exist in the structure you are 
examining. Doing this can cut down on time spent examining how the structure is 
manipulated, as fixed-size data types being modified aren't a concern. The way 
certain offsets of the structure are accessed gives you a clear indication of what kind 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
141 
of data is being stored there. Code indicating data buffers in a structure might look 