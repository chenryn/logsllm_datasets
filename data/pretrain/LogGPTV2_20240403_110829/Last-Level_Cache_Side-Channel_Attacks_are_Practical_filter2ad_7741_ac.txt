without interferences from non-participating memory
accesses). The sender picks from its allocated buffer
two memory lines, line 0 and line 1, that map to the
two agreed cache set indices. To send a “1”, the sender
continuously accesses line 1 for an amount of time,
Tmark. Similarly, the sender continuously accesses line 0
for a time equal to Tmark to send a “0”. The RZ encoding
scheme makes sure there is enough time between two
consecutive bits by busy waiting for an amount of time,
Tpause.
Before monitoring the sender, the receiver ﬁrst uses
Algorithm 1 to create eviction sets set 1 and set 0
for line 1 and line 0. It then uses PRIME+PROBE to
continuously monitor the two sets. To maximize channel
capacity, we set the idle interval between successive
probes to zero.
We construct the covert channel on a Dell server
platform with the Xen VMM, and a HP desktop plat-
form with VMware ESXi, Table I shows their conﬁgura-
tions. We use the default conﬁgurations for the VMMs,
which have large page support to transparently back up
the large pages in the guest physical memory with large
frames in the host physical memory. The only special
conﬁguration is that for Xen, we need to use native
mode for the “rdtsc” instruction to avoid being emulated
by the VMM.
Figure 4 shows a sample sequence of the receiver’s
measurements when interleaved bits of ones and zeros
are transmitted. The ﬁgure clearly shows that the peaks
of set 0 occur during the troughs of set 1 and vice versa,
corresponding to the “101010...” sequence. The receiver
can get more than one sample for each mark, and the
pause duration is long enough to avoid overlapping
between “1” and “0”. The experiment indicates that the
threshold value should be 700 cycles. Note that the mark
duration seen by the receiver is much longer than Tmark
of the sender (100 cycles), since the receiver’s probe
takes much longer time than 100 cycles.
Algorithm 2: Covert channel protocol
line 1: cache line accessed by the sender to send “1”.
line 0: cache line accessed by the sender to send “0”.
set 1: eviction set conﬂicting with line 1.
set 0: eviction set conﬂicting with line 0.
Dsend[N]: N bits data to transmit by the sender.
Sender Operations:
for i ← 0 to N − 1 do
if Dsend[i] = 1 then
for an amount of time Tmark do
access line 1;
end
busy loop for an amount of time Tpause;
for an amount of time Tmark do
access line 0;
end
busy loop for an amount of time Tpause;
else
end
end
Receiver Operations:
for an amount of time Tmonitor do
probe set 1 in forward direction;
probe set 0 in forward direction;
probe set 1 in backward direction;
probe set 0 in backward direction;
end
TABLE I: Experimental platform speciﬁcations.
Processor Model
Microarchitecture
Clock Frequency
# of Cores (slices)
LLC
Cache line size
VMM
Guest OS
Dell R720 (server)
Intel Xeon E5 2690
Sandy Bridge
2.9 GHz
8
20-way 20 MiB
64 B
Xen 4.4 (HVM)
Ubuntu 14.04.1 LTS
HP Elite 8300 (desktop)
Intel Core i5-3470
Sandy Bridge
3.2 GHz
4
12-way 6 MiB
64 B
VMware ESXi 5.1
CentOS 6.5
The covert channel suffers from various transmission
errors, including bit loss, insertion of extra bits or bit
ﬂips. We conduct an experiment to measure the effect
of the pause duration on channel capacity and error
rate. The sender generates a long pseudo-random bit
sequence (PRBS) with a period of 215−1 using a linear
feedback shift register (LFSR) with a width of 15 [29].
The LFSR can exhaust all the 215 states except the all-
zero state in one period, therefore the maximum number
of consecutive ones and consecutive zeros is 15 and 14,
respectively. To decode the signal, the receiver probes
both set 0 and set 1. It produces a “1” for each sequence
of consecutive probes in set 1 that take longer than a
threshold value (e.g., 700 cycles for the server and 400
cycles for the desktop), and a “0” for each sequence of
consecutive probes in set 0 that are above the threshold.
611
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:03 UTC from IEEE Xplore.  Restrictions apply. 
l
)
s
e
c
y
C
(
i
e
m
T
e
b
o
r
P
i
e
m
T
e
b
o
r
P
1000
800
600
400
0
1000
800
600
400
0
(a)
10
20
30
40
50
(b)
10
20
30
Prime−Probe Sequence
40
50
Fig. 4: Sample sequence of receiver’s access time on
server platform, (a) set 1, (b) set 0. The sender transmits
the sequence “101010...”. Tmark = 100 and Tpause = 3000
cycles.
To estimate the error rate, we ﬁrst identify a com-
plete period of the received PRBS to synchronize the
received signals with the sent PRBS, and then calculate
the edit distance [25] of one complete period of the sent
PRBS and the received data. The edit distance calculates
the number of insertion, deletion, or substitution opera-
tions required to transform a string to another string. In
the measurement, we ﬁx Tmark as 100 cycles and vary
Tpause.
Server Channel Capacity
Desktop Channel Capacity
Server Error Rate
Desktop Error Rate
0.3
0.25
0.2
0.15
0.1
e
t
a
R
r
o
r
r
E
about 0.5% and 3%, respectively, where insertion and
ﬂip errors dominate the bit-loss errors.
The desktop shows a higher error rate than the
server, and larger variance. This is a result of the
desktop’s lower LLC associativity, as the interaction
with higher-level caches tends to be stronger when the
associativity of the caches is similar. Perhaps counter-
intuitively, the ﬁgure also shows that the channel capac-
ity on the generally more powerful server is about 20%
less than that of the desktop, also a result of the server’s
higher LLC associativity (and thus higher probe time)
as well as a slightly lower clock rate.
The key takeaway from Figure 5 is the high overall
bandwidth, on the desktop 1.2 Mb/s with an error rate
of 22%. Although the probe time for the LLC is much
longer than that of the L1 cache, this is balanced by the
efﬁciency gain from the concurrent execution of sender
and receiver. Our observed bandwidth of 1.2 Mb/s is
about 6 times that of the highest previously reported
channel capacity [42] for an LLC-based covert channel.
For an apples-to-apples comparison of channel band-
width, we need to know the error rate in the experiments
of Wu et al. [42]. Unfortunately, this error rate is not
mentioned, and the test conditions are not compatible
with ours. Nevertheless, note that
if we reduce the
channel bandwidth to 600 Kb/s the error rate on the
server platform drops to below 1%. Thus,
the data
transfer rate of our method is three times faster than
the raw transfer rate reported in [42].
We have also experimented with longer mark du-
rations, where the receiver can collect more than one
sample per mark. This can further reduce the error rate,
but the effects are not as pronounced as for changing
the pause duration, so we do not pursue this further.
VI. ATTACKING THE SQUARE-AND-MULTIPLY
EXPONENTIATION ALGORITHM
1400
1200
1000
800
600
400
200
0
/
)
s
b
K
(
e
t
a
R
t
i
B
2000                3000               4000                 5000             6000
Pause Duration (Cycles)
0.05
0
We now show how our approach can be used to
leak a secret by recovering a secret-dependent execution
path. We use as a case study the square-and-multiply
implementation of modular exponentiation.
Fig. 5: Channel capacity and error rate of the covert
channel.
Figure 5 shows the resulting channel capacity and
error rate. As can be expected, increasing the pause
duration reduces the error rate, but also the channel
capacity. With a small pause time, synchronization may
be lost during long sequences of the same bit value.
Consequently, it is hard to determine the number of
consecutive bits of the same value, resulting in many
bit-loss errors. As Tpause increases, the error rate drops
for both the server and the desktop, until leveling out at
A. Square-and-multiply exponentiation
Modular exponentiation is the operation of raising a
number b to the power e modulo m. In both RSA [33]
and ElGamal [11] decryptions, leaking the exponent e
may lead to the recovery of the private key.
The square-and-multiply algorithm [15] computes
r = be mod m by scanning the bits of the binary repre-
sentation of the exponent e. Given a binary representa-
tion of e as (en−1···e0)2, square-and-multiply calculates
a sequence of intermediate values rn−1, . . . ,r0 such that
612
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:03 UTC from IEEE Xplore.  Restrictions apply. 
r
e
b
m
u
n
t
e
s
e
h
c
a
C
 60
 50
 40
 30
 20
 10
 0
 0
 200
 400
 600
 800
 1000
Time slot number
Fig. 6: Traces of activity in cache sets. The highlighted trace at cache set 43 is for the code of the squaring operation.
(cid:5)e/2i(cid:6) mod m using the formula ri−1 = ri
2bei−1.
ri = b
Algorithm 3 shows a pseudo-code implementation of
square-and-multiply.
Algorithm 3: Square-and-Multiply exponentiation
input : base b, modulo m, exponent e = (en−1 ···e0)2
output: be mod m
r ← 1
for i from n− 1 downto 0 do
r ← r2 mod m
if ei = 1 then
r ← r· b mod m
end
end
return r
The multiplications and modulo reductions directly
correspond to the bits of the exponent: each occurrence
of square-reduce-multiply-reduce corresponds to a one
bit, while each occurrence of square-reduce not fol-
lowed by a multiply corresponds to a zero bit. Conse-
quently, an attacker process that can trace the execution
of the square-and-multiply exponentiation algorithm can
recover the exponent [2, 45, 47]. We now show how we
can attack this algorithm using the technique developed
in Section IV. The main challenge is ﬁnding the cache
sets that hold the relevant victim code.
By their nature, side-channel attacks are very spe-
ciﬁc to the details of what is being attacked. Here we
develop an attack against the implementation of square-
and-multiply found in GnuPG version 1.4.13. For the
victim we use the default build, which compiles the
code with a high level of optimization (-O2), but leaves
the debugging information in the binary. The debugging
information is not loaded during run time, and does
not affect the performance of the optimized code. The
victim repeatedly executes the GnuPG binary to decrypt
613