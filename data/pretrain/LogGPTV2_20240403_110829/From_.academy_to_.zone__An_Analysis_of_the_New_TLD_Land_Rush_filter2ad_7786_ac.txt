### Domain Classification and Content Categorization

To classify the technical data returned by domains when queried through our DNS or HTTP infrastructure, we use a combination of features from both crawls. These features include DNS CNAME records, Web headers, Web contents, and NS records in zone files. 

#### Identification and Classification
- **Invalid DNS or HTTP Errors**: Domains with invalid DNS or HTTP errors are easily identifiable.
- **Textual Content Analysis**: For many domains, classification is based on the textual content they return to HTTP queries. We employ a combination of automated machine learning techniques and manual inspection of web pages.

#### Domain Categories
We categorize each domain into one of seven categories:

1. **No DNS**: Domains that do not successfully resolve DNS queries.
2. **HTTP Error**: Domains with valid DNS but do not return an HTTP 200 status code.
3. **Parked**: Domains owned by ad networks or for sale, typically returning web pages dominated by ads.
4. **Unused**: Domains returning HTTP content that is not consumer-ready, such as empty pages, default web server templates, or PHP errors.
5. **Free**: Domains given out as part of promotions, still using the original template, or with registry-owned web templates.
6. **Defensive Redirect**: Domains that redirect through various technical mechanisms to a different domain name.
7. **Content**: Domains hosting valid web content for users to visit.

#### Content Summary
To provide context for the new TLD results, we present domain classifications for three datasets:
1. All domains in the new TLDs as of February 3, 2015.
2. 3 million domains from old TLDs chosen uniformly at random.
3. All domains in the same set of old TLDs newly registered during December 2014.

| Content Category | Results (New TLDs) | Percentage |
|------------------|--------------------|------------|
| No DNS           | 567,390            | 15.6%      |
| HTTP Error       | 362,727            | 10.0%      |
| Parked           | 1,161,892          | 31.9%      |
| Unused           | 504,928            | 13.9%      |
| Free             | 432,323            | 11.9%      |
| Defensive Redirect| 236,380         | 6.5%       |
| Content          | 372,569            | 10.2%      |
| Total            | 3,638,209          | 100.0%     |

Figure 2 summarizes these datasets. This paper focuses on the new TLDs, and Table 3 shows exact values for the 290 public English TLDs, excluding `quebec`, `scot`, and `gal`.

#### Comparison and Insights
- **Erroneous Domains**: No DNS and HTTP Error account for about a quarter of all domains.
- **Domain Parking**: Another quarter utilizes domain parking.
- **Unused or Redirects**: Roughly 20% of domains are either unused or redirect elsewhere.
- **Content and Promotional Domains**: New TLDs show a lack of content but have a high volume of free domains.

Figure 3 illustrates the content classification for the 20 largest TLDs allowing public registrations, showing typical splits between major content categories and differences in registration types, especially for free domains.

### Content Clustering Methodology

#### Objective
Our goal is to cluster web pages hosted at domains into one of the content categories. Key challenges include the large dataset size and the lack of labeled data for training a classifier.

#### Clustering Process
1. **Initial Clustering**:
   - **Step 1**: Cluster web pages with highly similar content using a "bag-of-words" approach to extract HTML features.
   - **Step 2**: Use k-means clustering with \( k = 400 \) to organize web pages into groups of high similarity.
   - **Step 3**: Manually inspect clusters using a custom visualization tool to identify cohesive clusters of replicated web pages.

2. **Manual Inspection and Labeling**:
   - **Step 1**: Place domains into three broad categories: parked, content-free, and meaningful content.
   - **Step 2**: Focus on bulk labeling of clearly homogeneous clusters of parked or content-free web pages.

3. **Nearest Neighbor Classification**:
   - **Step 1**: Extract HTML features from remaining web pages and map them into the same feature space as the initial subset.
   - **Step 2**: Use nearest neighbor classification to label more candidate web pages, focusing on parked and content-free pages.
   - **Step 3**: Iterate this process until no more obviously cohesive clusters remain.

4. **Final Manual Inspection**:
   - **Step 1**: Manually inspect a random sample of the remaining unlabeled web pages to ensure they contain legitimate content.

### Final Classification
We combine the cluster labels with page metadata (e.g., DNS errors, HTTP status codes, redirect chains) to make a final classification. For domains that might fall into multiple categories, we prioritize categories in the order listed in Table 3.

This comprehensive approach ensures accurate and detailed classification of domain content, providing valuable insights into the usage and characteristics of new and old TLDs.