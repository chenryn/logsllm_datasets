b− a and d − c). While this deﬁnition and model for loss episodes
is somewhat simplistic and dependent on well behaved TCP ﬂows,
it is important for any measurement method to be robust to ﬂows
that do not react to congestion in a TCP-friendly fashion.
This deﬁnition of loss episodes can be considered a “router-centric”
view since it says nothing about when any one end-to-end ﬂow ac-
tually loses a packet or senses a lost packet. This contrasts with
most of the prior work discussed in Section 2 which consider only
losses of individual or groups of probe packets. In other words,
in our methodology, a loss episode begins when the probability of
some packet loss becomes positive. During the episode, there might
be transient periods during which packet loss ceases to occur, fol-
lowed by resumption of some packet loss. The episode ends when
the probability of packet loss stays at 0 for a sufﬁcient period of
time (longer than typical RTT). Thus, we offer two deﬁnitions for
packet loss rate:
• Router-centric loss rate. With L the number of dropped
packets on a given output link on router R during a given
period of time, and S the number all successfully transmitted
packets through the same link over the same period of time,
we deﬁne the router-centric loss rate as L/(S + L).
• End-to-end loss rate. We deﬁne end-to-end loss rate in ex-
actly the same manner as router-centric loss-rate, with the
caveat that we only count packets that belong to a speciﬁc
ﬂow on interest.
It is important to distinguish between these two notions of loss
rates since packets are transmitted at the maximum rate Bout during
loss episodes. The result is that during a period where the router-
centric loss rate is non-zero, there may be ﬂows that do not lose any
packets and therefore have end-to-end loss rates of zero. This ob-
servation is central to our study and bears directly on the design and
implementation of active measurement methods for packet loss.
4. SIMPLE POISSON PROBING FOR
PACKET LOSS
We begin by evaluating the capabilities of simple Poisson-modulated
loss probe measurements using the ZING tool [2, 20]. We tested
ZING in a series of experiments conducted in a laboratory environ-
ment consisting of commodity workstation end hosts and a series of
IP routers. We consider this to be an environment ideally suited to
understanding and calibrating end-to-end loss measurement tools.
Laboratory environments do not have the weaknesses typically as-
sociated with ns-type simulation (e.g., abstractions of measurement
tools, protocols and systems) [13], nor do they have the weaknesses
of wide area in situ experiments (e.g., lack of control, repeatability,
and complete, high ﬁdelity end-to-end instrumentation). We ad-
dress the important issue of testing the tool under “representative”
trafﬁc conditions by using a combination of the Harpoon IP trafﬁc
generator [31] and Iperf [33] to evaluate the tool over a range of
cross trafﬁc and loss conditions.
4.1 Testbed Setup
The laboratory testbed used in our experiments is shown in Fig-
ure 3. It consisted of commodity end hosts connected to a dumbbell-
like topology comprised of Cisco GSR 12000 routers. Both probe
and background trafﬁc was generated and received by the end hosts.
Trafﬁc ﬂowed from the sending hosts on separate paths via Giga-
bit Ethernet to separate Cisco GSRs (hop B in the ﬁgure) where it
transitioned to OC12 (622 Mb/s) links. This conﬁguration was cre-
ated in order to accommodate our measurement system, described
below. Probe and background trafﬁc was then multiplexed onto a
single OC3 (155 Mb/s) link (hop C in the ﬁgure) which formed the
bottleneck where loss episodes took place. We used a hardware-
based propagation delay emulator on the OC3 link to add 50 mil-
liseconds delay in each direction for all experiments, and conﬁg-
ured the bottleneck queue to hold approximately 100 milliseconds
BBoutinRQNFigure 2: Example of the evolution of the length of a queue over time. The queue length grows when aggregate demand exceeds the
capacity of the output link. Loss episodes begin (points a and c) when the maximum buffer size Q is exceeded. Loss episodes end
(points b and d) when aggregate demand falls below the capacity of the output link and the queue drains to zero.
Figure 3: Experimental testbed. Cross trafﬁc scenarios consisted of constant bit-rate trafﬁc, long-lived TCP ﬂows, and Harpoon
web-like trafﬁc. Cross trafﬁc ﬂowed across one of two routers at hop B, while probe trafﬁc ﬂowed through the other. Optical splitters
connected Endace DAG 3.5 and 3.8 passive packet capture cards to the testbed between hops B and C, and hops C and D. Probe
trafﬁc ﬂowed from left to right and the loss episodes occurred at hop C.
Users specify the mean probe rate λ, the probe packet size, and the
number of packets in a “ﬂight.”
of packets. Packets exited the OC3 link via another Cisco GSR
12000 (hop D in the ﬁgure) and passed to receiving hosts via Giga-
bit Ethernet.
The probe and trafﬁc generator hosts consisted of identically
conﬁgured workstations running Linux 2.4. The workstations had
2 GHz Intel Pentium 4 processors with 2 GB of RAM and Intel
Pro/1000 network cards. They were also dual-homed, so that all
management trafﬁc was on a separate network than depicted in Fig-
ure 3.
One of the most important aspects of our testbed was the mea-
surement system we used to establish “ground truth” for our ex-
periments. Optical splitters were attached to both the ingress and
egress links at hop C and Endace DAG 3.5 and 3.8 passive monitor-
ing cards were used to capture traces of packets entering and leav-
ing the bottleneck node. DAG cards have been used extensively in
many other studies to capture high ﬁdelity packet traces in live en-
vironments (e.g., they are deployed in Sprint’s backbone [14] and in
the NLANR infrastructure [23]). By comparing packet header in-
formation, we were able to identify exactly which packets were lost
at the congested output queue during experiments. Furthermore,
the fact that the measurements of packets entering and leaving hop
C were time-synchronized on the order of a single microsecond en-
abled us to easily infer the queue length and how the queue was
affected by probe trafﬁc during all tests.
4.2 Performance of Poisson Probes
ZING is a tool for measuring packet delay and loss in one di-
rection on an end-to-end path. The ZING sender emits UDP probe
packets at Poisson-modulated intervals with timestamps and unique
sequence numbers and the receiver logs the probe packet arrivals.
To evaluate simple Poisson probing, we conﬁgured ZING using
the same parameters as in [39]. Namely, we ran two tests, one
with λ = 100ms (10 Hz) and 256 byte payloads and another with
λ = 50ms (20Hz) and 64 byte payloads. To determine the duration
of our experiments below, we selected a period of time that should
limit the variance of the loss rate estimator ¯X where Var( ¯Xn) ≈ p
n
for loss rate p and number of probes n.
We conducted three separate experiments in our evaluation of
simple Poisson probing.
In each test we measured both the fre-
quency and duration of packet loss episodes. Again, we used the
deﬁnition in [39] for loss episode, namely, “a series of consecutive
packets (possibly only of length one) that were lost.” The ﬁrst ex-
periment uses 40 inﬁnite TCP sources with receive windows set to
256 full size (1500 bytes) packets. Figure 4 shows the time series of
the queue occupancy for a portion of the experiment; the expected
synchronization behavior of TCP sources in congestion avoidance
is clear. The experiment was run for a period of 15 minutes which
should have enabled ZING to measure loss rate with standard devi-
ation within 10% of the mean.
Results from the experiment with inﬁnite TCP sources are shown
in Table 1. The table shows that ZING performs poorly in measuring
both loss frequency and duration in this scenario. For both probe
rates, there were no instances of consecutive lost packets, which
explains the inability to estimate loss episode duration.
In the second set of experiments, we used Iperf to create a series
of (approximately) constant duration (about 68 milliseconds) loss
episodes that were spaced randomly at exponential intervals with
mean of 10 seconds over a 15 minute period. The time series of the
QtimecapacitybufferlengthqueuecdbaGEtraffic generator hostGEGEbadabing receiverAdtech SX−14GEbadabing senderGEtraffic generator hostDAG monitor hostSiCisco 6500Cisco 12000Cisco 12000Cisco 6500propagation delayemulatoreach direction)(50 millisecondsCisco 12000OC12OC12OC3OC3SihopidentifierABCDEqueue length for a portion of the test period is shown in Figure 5.
Results from the experiment with randomly spaced, constant du-
ration loss episodes are shown in Table 2. The table shows that
ZING measures loss frequencies and durations that are closer to the
true values.
In the ﬁnal set of experiments, we used Harpoon to create a se-
ries of loss episodes that approximate loss resulting from web-like
trafﬁc. Harpoon was conﬁgured to brieﬂy increase its load in order
to induce packet loss, on average, every 20 seconds. The variabil-
ity of trafﬁc produced by Harpoon complicates delineation of loss
episodes. To establish baseline loss episodes to compare against,
we found trace segments where the ﬁrst and last events were packet
losses, and queuing delays of all packets between those losses were
above 90 milliseconds (within 10 milliseconds of the maximum).
We ran this test for 15 minutes and a portion of the time series for
the queue length is shown in Figure 6.
Results from the experiment with Harpoon web-like trafﬁc are
shown in Table 3. For measuring loss frequency, neither probe rate
results in a close match to the true frequency. For loss episode
duration, the results are also poor. For the 10 Hz probe rate, there
were no consecutive losses measured, and for the 20 Hz probe rate,
there were only two instances of consecutive losses, each of exactly
two lost packets.
Figure 4: Queue length time series for a portion of the experi-
ment with 40 inﬁnite TCP sources.
Table 1: Results from ZING experiments with inﬁnite TCP
sources.
frequency
true values
ZING (10Hz)
ZING (20Hz)
0.0265
0.0005
0.0002
duration µ (σ)
(seconds)
0.136 (0.009)
0 (0)
0 (0)
Table 2: Results from ZING experiments with randomly spaced,
constant duration loss episodes.
frequency
true values
ZING (10Hz)
ZING (20Hz)
0.0069
0.0036
0.0031
duration µ (σ)
(seconds)
0.068 (0.000)
0.043 (0.001)
0.050 (0.002)
Table 3: Results from ZING experiments with Harpoon web-
like trafﬁc.
frequency
duration µ (σ)
(seconds)
Figure 5: Queue length time series for a portion of the experi-
ment with randomly spaced, constant duration loss episodes.
5.1 General Setup
Our methodology involves dispatching a sequence of probes,
each of which contains one or more very closely spaced packets.
The aim of a probe is to get a snapshot of the congestion state of
the network at the instant of probing. To this end, the record for
each probe indicates whether or not it encountered congestion, as
indicated by either the loss or sufﬁcient delay of any of the packets
within a probe, as described in § 6. The reason for using multi-
packet probes is that not all packets passing through a congested
link are subject to loss; using multiple packets enables a more ac-
curate determination to be made.
The probes themselves are organized into what we term basic
experiments, each of which comprises a number of probes sent in
true values
ZING (10Hz)
ZING (20Hz)
0.0093
0.0014
0.0012
0.136 (0.009)
0 (0)
0.022 (0.001)
5. PROBE PROCESS MODEL
The results from our experiments described in the previous sec-
tion show that simple Poisson probing is generally poor for mea-
suring loss episode frequency and loss episode duration. These
results, along with deeper investigation of the reasons for partic-
ular deﬁciencies in loss episode duration measurement, form the
foundation for a new measurement process.
Figure 6: Queue length time series for a portion of the exper-
iment with Harpoon web-like trafﬁc. Time segments in grey
indicate loss episodes.
1012141618200.000.020.040.060.080.10time (seconds)queue length (seconds)3032343638400.000.020.040.060.080.10time (seconds)queue length (seconds)3436384042440.000.020.040.060.080.10time (seconds)queue length (seconds)rapid succession. The aim of the basic experiment is to determine
the dynamics of transitions between the congested and uncongested
state of the network. Below we show how this enables us to esti-
mate the duration of congestion periods.
A full experiment comprises a sequence of basic experiments
generated according to some rule. The sequence may be termi-
nated after some speciﬁed number of basic experiments, or after
a given duration, or in an open-ended adaptive fashion, e.g., until
estimates of desired accuracy for a congestion characteristic have
been obtained, or until such accuracy is determined impossible.
We formulate the probe process as a discrete-time process. This
decision is not a fundamental limitation: since we are concerned
with measuring congestion dynamics, we need only ensure that
the interval between the discrete time slots is smaller than the time
scales of the congested episodes. A congested slot is simply a time
slot during which congestion occurs. A congestion episode is a
maximal set of consecutive slots that are congested.
There are three steps in the explanation of our loss measurement
method (i.e., the experimental design and the subsequent estima-
tion). First, we present the basic algorithm version of our design.
This model is designed to provide estimators of the frequency of
congested slots and the duration of congestion episodes. The fre-
quency estimator is unbiased, and under relatively weak statistical
assumptions, both estimators are consistent in the sense they con-
verges to their respective true values as the number of measure-
ments grows.
Second, we describe the improved algorithm version of our de-
sign which provides loss episode estimators under weaker assump-
tions, and requires that we employ a more sophisticated experi-
mental design. In this version of the model, we insert a mechanism
to estimate, and thereby correct the possible bias of the estimators
from the basic design.
Third, we describe simple validation techniques that can be used
to assign a level of conﬁdence to loss episode estimates. This en-
ables open-ended experimentation with a stopping criterion based
on estimators reaching a requisite level of conﬁdence.
5.2 Basic Algorithm
For each time slot i we decide whether or not to commence a
basic experiment; this decision is made independently with some
ﬁxed probability p over all slots. We indicate this series of de-
cisions through random variables {xi} that takes the value 1 (if a
basic experiment is started in slot i) and 0 otherwise.
If xi = 1, we dispatch two probes to measure congestion in slots i
and i+1. The random variable yi records the reports obtained from
the probes as a 2-digit binary number, i.e., yi = 00 means “both
probes did not observe congestion”, while yi = 10 means “the ﬁrst
probe observed congestion while the second one did not”, and so
on. Our methodology is based on the following fundamental as-
sumptions, which, in view of the probe and its reporting design (as
described in § 6) are very likely to be valid ones. These assumptions
are required in both algorithmic versions. The basic algorithm re-
quires a stronger version of these assumptions, as we detail later.
5.2.1 Assumptions
We do not assume that the probes accurately report congestion: