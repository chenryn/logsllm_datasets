title:Temporal System Call Specialization for Attack Surface Reduction
author:Seyedhamed Ghavamnia and
Tapti Palit and
Shachee Mishra and
Michalis Polychronakis
Temporal System Call Specialization for 
Attack Surface Reduction
Seyedhamed Ghavamnia, Tapti Palit, Shachee Mishra, and 
Michalis Polychronakis, Stony Brook University
https://www.usenix.org/conference/usenixsecurity20/presentation/ghavamnia
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Temporal System Call Specialization
for Attack Surface Reduction
Seyedhamed Ghavamnia, Tapti Palit, Shachee Mishra, Michalis Polychronakis
Stony Brook University
Abstract
Attack surface reduction through the removal of unnecessary
application features and code is a promising technique for
improving security without incurring any additional overhead.
Recent software debloating techniques consider an applica-
tion’s entire lifetime when extracting its code requirements,
and reduce the attack surface accordingly.
In this paper, we present temporal specialization, a novel
approach for limiting the set of system calls available to a
process depending on its phase of execution. Our approach
is tailored to server applications, which exhibit distinct ini-
tialization and serving phases with different system call re-
quirements. We present novel static analysis techniques for
improving the precision of extracting the application’s call
graph for each execution phase, which is then used to pinpoint
the system calls used in each phase. We show that require-
ments change throughout the lifetime of servers, and many
dangerous system calls (such as execve) can be disabled
after the completion of the initialization phase. We have im-
plemented a prototype of temporal specialization on top of the
LLVM compiler, and evaluated its effectiveness with six pop-
ular server applications. Our results show that it disables 51%
more security-critical system calls compared to existing li-
brary specialization approaches, while offering the additional
beneﬁt of neutralizing 13 more Linux kernel vulnerabilities
that could lead to privilege escalation.
1 Introduction
Modern software is complex. Applications typically support
a wide range of functionalities for different use cases [28, 49],
as evidenced by the existence of multiple features, options,
and conﬁguration settings. To support these different features,
programs typically require access to a vast range of privileged
operations from the OS kernel (e.g., allocating memory, creat-
ing new processes, and accessing ﬁles or the network), which
are made available through the system call interface.
Some of these capabilities, however, are used by the ap-
plication only once during startup, and are never used again
during the lifetime of the program. This is especially true for
server applications, which once launched, remain running and
serving requests for a long period of time. This means that
all kernel capabilities (i.e., system calls) remain available to
a potentially vulnerable process, and can thus be used as part
of exploitation attempts.
Software debloating and specialization has recently gained
popularity as a technique for removing or constraining un-
used parts of applications, with the goal of reducing the
code and features available to attackers. While some ap-
proaches use static analysis to identify unused parts of shared
libraries [12, 51], others rely on dynamic analysis and train-
ing to identify unneeded parts of the application [13, 21, 48].
Similar techniques have also been applied on containers to
constrain the set of system calls available to the hosted pro-
grams [22, 38, 59]. A key shared characteristic of the above
approaches is that they consider the entire lifetime of a pro-
gram as part of the scope of their analysis.
In this paper, we explore software specialization from a
different perspective, and present temporal system call spe-
cialization, a novel attack surface reduction approach for lim-
iting even further the set of system calls that are available
to a process, depending on its phase of execution. Instead of
treating each application as a single, monolithic entity with
an unchanging set of requirements, temporal specialization
takes into consideration the changes in an application’s re-
quirements throughout its execution lifetime. In particular,
we focus on server applications, which typically exhibit two
distinct initialization and serving phases.
Our main motivation is that many dangerous system calls,
such as execve, which are frequently used as part of exploit
code, are often not removed by existing code debloating and
specialization techniques, because they are required by the
application for legitimate purposes. Crucially, however, oper-
ations such as spawning new processes or creating listening
sockets are typically only performed during the very ﬁrst
moments of a server’s lifetime—the initialization phase. Tem-
poral specialization automatically derives the set of system
calls required by each execution phase, and restricts the set of
USENIX Association
29th USENIX Security Symposium    1749
available system calls once the server enters its stable serv-
ing phase. This signiﬁcantly reduces the set of system calls
available to an attacker.
A crucial requirement for pinpointing the system calls
required in each phase is to construct a sound and precise
call graph. As most server applications are developed using
C/C++, which support indirect function invocations, we must
rely on static code analysis to resolve the possible targets
of indirect call sites. Unfortunately, the state-of-the-art im-
plementations of points-to analysis algorithms suffer from
severe imprecision and overapproximation, which eventually
results in the inclusion of many spurious system calls that
are not actually used. To address this challenge, we propose
two pruning mechanisms that remove spurious edges from
the derived call graph, signiﬁcantly improving its precision
while retaining its soundness. After identifying the system
calls needed in each phase, we use Seccomp BPF to block any
system calls that are not needed anymore after the completion
of the initialization phase, thereby removing them from the
process’ attack surface.
We implemented a prototype of temporal specialization
for Linux on top of LLVM, and evaluated it with six popular
applications (Nginx, Apache Httpd, Lighttpd, Bind, Mem-
cached, and Redis). We show that many dangerous system
calls, such as execve, can be disabled after the application
enters its serving phase, i.e., when the server application starts
handling client requests and becomes susceptible to attacks.
Our results show that temporal specialization disables 51%
more security-critical system calls compared to existing li-
brary specialization approaches [12, 51], while in many cases
it does not leave room for evasion using alternative system
call combinations. As an added beneﬁt, 53 Linux kernel vul-
nerabilities are neutralized by removing system calls which
serve as entry points for triggering them, 13 of which are not
preventable by library specialization.
Our work makes the following main contributions:
1. We propose a novel temporal system call specialization
approach that considers the different operational charac-
teristics of server applications throughout their different
execution phases.
2. We present type-based and address-taken-based pruning
mechanisms to improve the precision of static analysis
techniques for call graph construction.
3. We evaluate our prototype implementation with six pop-
ular applications and a diverse set of 567 shellcode and
17 ROP payload samples, demonstrating its effective-
ness in blocking exploit code, as well as in reducing the
exposed attack surface of the underlying kernel.
Our prototype implementation is publicly available as an
open-source project at https://github.com/shamedgh/
temporal-specialization.
2 Background and Motivation
User-space applications rely on the system call API to inter-
act with the OS. The Linux kernel v4.15 used in this work
provides 333 system calls, while its latest version 5.6 (as of
June 2020) provides 349. Applications, however, typically
rely only on a subset of these system calls for their opera-
tion. Moreover, their requirements change according to the
phase of execution, e.g., whether the application is being ini-
tialized or serving requests. From a security perspective, this
overabundance of system calls allows an attacker to i) use
the additional system calls to carry out malicious operations
as part of exploiting a vulnerability, and ii) exploit underly-
ing kernel vulnerabilities triggered through system calls and
achieve privilege escalation [22, 31, 32].
2.1 Static vs. Temporal API Specialization
Previous works in attack surface reduction [21, 26, 34, 48, 50]
consider the entire application lifetime, and remove function-
ality that will never be used at any point. When considering
the execution phases of typical server applications, however,
we observe that further specialization can be achieved.
In particular, servers typically start handling client requests
after performing a series of one-time operations for setting up
the process. This initialization phase mainly consists of op-
erations such as parsing conﬁguration ﬁles, binding network
ports, and forking worker processes. After the completion
of these tasks, the server enters its main long-term serving
phase for handling client requests. In this stable state, the
server typically performs operations such as reading from and
writing to sockets or ﬁles, managing memory, and allocating
tasks to the worker processes. Nginx [7] is an example of a
server which exhibits this behavior. Depending on whether it
is started in “single-process” or “multi-process” mode, Nginx
either executes the function ngx_single_process_cycle,
or forks the conﬁgured number of worker processes, each
of which invokes the function ngx_worker_process_cycle.
Both functions mark the beginning of the serving phase by
entering an inﬁnite loop that processes client requests.
The operations performed in these two phases are distinc-
tively different, and thus the required system calls for carrying
them out are also different. For example, if a server only cre-
ates a ﬁxed set of long-lived worker processes during the
initialization phase, it will not need access to system calls
such as fork and execve during the serving phase.
Figure 1 shows a simpliﬁed view of the call graph for
Apache httpd [15], one of the most popular open source
web servers. The different shapes correspond to application
functions, library functions, and system calls. The initializa-
tion phase begins with main, and this phase performs oper-
ations such as binding and listening to sockets, and spawn-
ing the worker processes through calls to fork and execve.
The forked worker processes begin execution at the func-
1750    29th USENIX Security Symposium
USENIX Association
Figure 1: Library debloating [12,51] can only remove system calls that are never used during the entire lifetime of the application
(top left). Temporal specialization removes additional system calls that are never used after the initialization phase (top right).
tion child_main, which denotes the beginning of the serving
phase. During this phase, the application performs tasks such
as allocating buffers and handling I/O operations.
Library debloating techniques [12, 51] analyze the code
of a given application to identify and remove parts of the
linked libraries that are not needed by the application, thereby
creating specialized versions of each library. However, they
consider the entire lifetime of the application, and therefore,
in the example of Figure 1, are unable to prevent access to
system calls such as fork and execve—crucial for attackers’
exploit code—as they are used during the initialization phase.
2.2 Seccomp BPF
Seccomp BPF [8] is a mechanism provided by the Linux ker-
nel for restricting the set of system calls that are accessible
by user-space programs. Speciﬁcally, Seccomp BPF uses the
Berkeley Packet Filter language [40] for allowing develop-
ers to write programs that act as system call ﬁlters, i.e., BPF
programs that inspect the system call number (as well as argu-
ment values, if needed) and allow, log, or deny the execution
of the respective system call. Applications can apply Sec-
comp BFP ﬁlters by invoking either the prctl or seccomp
system call from within their own process. After doing so, all
system call invocations from within the process itself or any
forked child processes will be checked against the installed
ﬁlters to grant or reject permission. We use this mechanism
to reduce the set of system calls available to programs after
the completion of their initialization phase.
3 Threat Model
be used along with other code specialization techniques. Our
technique limits the set of system calls an attacker can in-
voke. Therefore, any exploit code (e.g., shellcode or ROP
payload) will have limited capabilities, and will not be able to
invoke system calls that are not needed by the server after its
initialization phase. These typically include security-critical
system calls that can be used to spawn additional services, ex-
ecute shell commands, and so on. Preventing access to these
system calls also effectively neutralizes the corresponding
kernel code, which may contain vulnerabilities that can lead
to privilege escalation [39]—an attacker cannot trigger those
vulnerabilities to compromise the kernel, as the respective
system calls cannot be invoked in the ﬁrst place.
Time-of-check to time-of-use (TOCTTOU) [60] and other
race condition attacks are out of the scope of this work.
4 Design
Our goal is to reduce the number of system calls available
to attackers once a server application has ﬁnished its initial-
ization phase, and thus reduce the exposed attack surface.
Disabling system calls that remain unused during the serving
phase requires the identiﬁcation of those system calls that the
application uses during the initialization phase, and does not
need afterwards. To achieve this, our approach performs the
following steps, illustrated in Figure 2.
• Build a sound call graph of the application, and derive
the list of imported functions from external libraries.
• Map the application call graph, as well as the imported
external library functions, to system calls.
We consider remote adversaries armed with a vulnerability
that allows arbitrary code execution. Temporal system call
specialization does not rely on any other exploit mitigations,
but as an attack surface reduction technique, it is meant to
• Use programmer-supplied information about the func-
tions that mark the beginning of the initialization and
serving phases, respectively, to derive the call graph of
each of these phases of execution.
USENIX Association
29th USENIX Security Symposium    1751
mainsock_bindp_listnchild_mainreadbindwritevexecvemallocbindlistenexecvewritevmmapreadApache Process Address SpaceSyscallLib. Func.App. Func.forkpre_configmk_childproc_forkapr_pallocfile_writevsock_recvprctlprctlmkdirmknodbrctlbrctlsetnssetnsfcntlfcntlUnused libcfunctionsbindlistenexecvewritevmmapforkreadprctlmknodbrctlsetnsfcntlbindlistenexecvewritevmmapforkreadprctlmknodbrctlsetnsfcntlInitializationServingFigure 2: Overview of the process for generating a sound call graph to identify the system calls required by each execution phase.
• Based on these call graphs, identify the list of system
calls required by each phase.
• Create Seccomp ﬁlters to restrict the use of unneeded
system calls, and apply them right after the end of the
initialization phase.
Identifying the Transition Point
4.1
We require an expert to identify the boundary where the pro-
gram transitions from the initialization phase to the serving
phase, and pass it to our toolchain through a conﬁguration ﬁle.
This is the point where the server begins its main operation
and its system call requirements change. As discussed in Sec-
tion 2.1, in many applications, such as Apache Httpd [15] and
Nginx [7], the transition takes place after the server’s main
process forks, and child processes are created. In others, such
as Memcached [4], which use an event-driven model, this
transition takes place at the beginning of the event loop that
handles client requests. In case of Apache Httpd, as shown in
Figure 1, this transition boundary is deﬁned by the function
child_main, and once execution reaches this function, many
system calls are no longer needed.
Although identifying this transition boundary could per-
haps be automated based on heuristics or dynamic analysis,
we did not invest the effort to develop such a capability, as
this needs to be done only once per application. Manually
pinpointing the entry point to the serving phase is relatively
easy even if one is not familiar with a given code base. This
is the only step where manual intervention is required.
4.2 Call Graph Construction
Applications and libraries written in C/C++ often use indirect
function calls via function pointers. For example, the libapr
and libapr-util libraries used by Apache Httpd, use func-
tion pointers to register custom memory allocation functions,
to register callbacks, and to provide other functionalities that
allow the programmer to customize the library. Resolving
these indirect function calls in a sound and precise manner is
therefore critical for identifying the system calls needed by
the application.
Points-to analysis is a static code analysis technique for
deriving the possible targets of pointers in a program, and is
necessary to soundly identify the target functions of indirect
function calls. We use the well-known Andersen’s points-to
analysis algorithm [14] for this purpose.
Applying Andersen’s algorithm to the source code of an
application generates a sound call graph, in which all indi-
rect call sites are resolved. However, like all static analy-
sis techniques, points-to analysis suffers from imprecision
and overapproximation. For example, Apache’s function
ap_run_pre_config contains an indirect function call. An-
dersen’s points-to analysis reports 136 targets for this function
pointer. We manually veriﬁed that only seven targets can ac-
tually be executed, and the rest 129 are spurious targets that
were included due to the imprecision of the analysis.
Previous works [14, 27] have extensively discussed the
challenges of scalable and accurate points-to analysis, and
an in-depth discussion of these issues is out of the scope of
this paper. However, we brieﬂy describe the different sources
of overapproximation we faced in our problem space, along
with how we mitigated them.
4.2.1 Points-to Analysis Overapproximation
Points-to analysis can be modeled with multiple types of sen-
sitivity, which reﬂect how objects in memory are modeled.
These include ﬁeld sensitivity, context sensitivity, and path
sensitivity. An analysis algorithm employing a higher degree
of sensitivity will provide more precise results, and in turn
will allow us to gain a more ﬁne-grained view into the system
calls required by each execution phase. However, using higher
degrees of sensitivity has the fundamental problem of increas-
ing the analysis time, while it requires signiﬁcant effort to
implement such a capability. For example, the popular imple-
mentation of Andersen’s algorithm, SVF [55], supports ﬁeld
sensitivity (it models every ﬁeld of a struct type uniquely),
but not context sensitivity or path sensitivity. This results in
imprecision in the results of the points-to analysis.
Context-sensitive analysis considers the calling context
when analyzing the target of a function call. When the same
function is invoked from different call sites, each function call
gets its own “context” and is analyzed independently of the
1752    29th USENIX Security Symposium
USENIX Association
LLVM IRProgrammer-provided Function ListSVF Andersen’s AnalysisType-based PruningAddress-taken Based PruningSeccompFilter Generationfilter(SYS_execve)filter(SYS_setuid)filter(SYS_setsid)filter(SYS_bind)filter(SYS_listen)Imprecise Call GraphPrecise Call GraphCall Graph with Type-based Pruningother function calls. This prevents return values of the called
function from propagating into unintended call sites, leading
to imprecision. This is critical for functions that allocate or
reassign objects referenced by their arguments, or functions
that return pointers. Lack of context sensitivity in such cases
causes the propagation of analysis results to all call sites and
all return sites of these functions. For example, to allocate
memory, Nginx uses a wrapper around memory allocation
routines (e.g., malloc), called ngx_alloc. Because the anal-
ysis used by SVF is not context sensitive, its results contain
signiﬁcant overapproximation.
Similarly to context sensitivity, the lack of path sensitivity
also causes overapproximation in the results of the points-
to analysis. Path-sensitive points-to analysis takes into ac-
count the predicates of the branch conditions in the control
ﬂow graph of the program when solving pointer constraints.
Without path sensitivity, the analysis cannot reason about the
predicate conditions of a branch.
During our analysis of popular servers, we observed that it
was common for libraries (e.g., libapr) to provide an option
to insert optional callback functions at various stages of the
life cycle of the library. These callbacks are implemented as
indirect function calls, and their call sites are guarded by NULL
checks on the callback function pointer. We call these guarded
indirect call sites, and discuss them further in Section 4.2.3.
Due to the lack of context sensitivity, even if no callback
function is registered, the points-to analysis can return spuri-
ous targets for the guarded indirect call site. Due to the lack of
path sensitivity, the analysis cannot detect that the call site is
in fact guarded, and will be skipped at runtime. Figure 3 shows
an example of a guarded indirect call site. The imprecise call
graph contains a spurious edge to piped_log_maintenance
from a guarded indirect call site accessible in the serving