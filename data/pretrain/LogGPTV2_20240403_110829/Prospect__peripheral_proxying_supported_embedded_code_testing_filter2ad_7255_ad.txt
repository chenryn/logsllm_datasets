warded when PROSPECT is used. The results are visible
in Table 5 in Section 6.1.
5.2 Case Study: Security Audit of a Propri-
etary Fire Alarm System
Under a legally binding non-disclosure agreement, we were
able to employ PROSPECT to conduct a full-scale security
audit of a widely used ﬁre alarm system over a time frame
of more than 6 months. A schematic overview of the overall
ﬁre alarm system is visible in Figure 5. On the lower side
of the picture there is the ﬁre alarm system that has a ﬁeld
level bus with a number of sensors (such as smoke detec-
tors) and actuators (such as alarm lights or sirens) attached
to it. Typically, there is one ﬁre alarm system in a building
and the sensors/actuators are situated in the rooms or on
the outside of each building. Each ﬁre alarm system is con-
nected over a network connection (i.e. via TCP/IP) to one
central building management server that is responsible for
all ﬁre alarm systems in multiple buildings. Thus, the server
can manage the ﬁre alarm systems and necessary steps can
be taken in case there is a ﬁre alarm. From the security
perspective, the TCP/IP connection between the ﬁre alarm
systems and the building management server is interesting.
After all, if an attacker could get access to the ﬁre alarm
systems over the building network or even the Internet, it
might be possible to trigger false alarms or to disable ﬁre
alarms which would lead to a dangerous situation for the
persons in the building.
On a technical level, the ﬁre alarm system we analyzed is
a customized embedded Linux system with custom drivers,
custom peripheral hardware components and several propri-
etary userspace programs that make up the overall ﬁre alarm
336Figure 6: Security Analysis Environment
6. RESULTS AND DISCUSSION
6.1 Performance Impact
Table 5 shows the average performance impact of our sys-
tem (Section 5.1). The values are arithmetic means over all
recorded system calls. More speciﬁcally, the average number
of read() accesses is the average of all read accesses from
166, 972 native and 196, 075 forwarded system calls, respec-
tively. It clearly shows that for system calls that can be for-
warded without further consideration (i.e. lseek(), read(),
write() and _newselect()), the slowdown is practically in-
signiﬁcant as the main use of PROSPECT is program de-
bugging (i.e. single stepping) and dynamic code analysis.
Our results show that with PROSPECT the _newselect()
call was slightly faster than on the native system. This is
due to the nature of the system call. It blocks as long as
either the given timeout is reached or one of the monitored
ﬁle descriptors is ready. As this is closely related to the
behavior of peripheral hardware (e.g. sleep modes), small
variances in the recorded values are unavoidable.
In contrast, the ioctl() and open() calls cause a signif-
icant slowdown. The ioctl() slowdown is caused by the
dynamic memory tunneling mechanism described in Section
4.3 whereas the open() slowdown is due to the connection
establishment between the PROSPECT client and server.
On the virtual analysis environment, we were unable to cap-
ture close() calls on virtual character devices which is why
we can not provide a performance comparison. However, as
close() also works on an existing PROSPECT connection
and no special considerations are necessary for the call, we
believe that the performance impact is comparable to the
lseek(), read(), write() and _newselect() calls. Fur-
thermore, Table 5 also lists the frequency of each speciﬁc
system call. It shows that the most frequently used calls are
also the fastest. For instance, write(), read(), seek() and
_newselect() account for 95,71% of all forwarded system
calls. The distribution between system calls for native and
forwarded execution slightly varied between analysis runs
due to the internal state of the peripheral hardware.
6.2 Proprietary Fire Alarm System Security
Audit
During our ﬁre alarm security analysis (Section 5.2), we
conducted extensive fuzz testing with the setup shown in
Figure 6. During analysis, PROSPECT successfully for-
warded more than 500, 000 system calls per analysis run
to the target system without issues. Likewise, we were able
to manually debug and single-step through the ﬁre alarm
application code. Our fuzz tests revealed a previously un-
known zero-day vulnerability that was reported to the man-
ufacturer. Our case study shows that even under demanding
real-life requirements (29 multi-threaded processes that con-
currently access 5 diﬀerent hardware peripherals), our sys-
tem performed well and enabled us to conduct both dynamic
analysis and extensive fuzz testing to discover vulnerabili-
ties.
7. LIMITATIONS AND FUTURE WORK
Due to the nature of PROSPECT, it has a number of
limitations that need to be considered. At the moment,
our system uses TCP/IP over a network connection between
the virtual analysis system and the embedded target system.
However, if the userspace application under analysis changes
the network conﬁguration, this would also bring down the
PROSPECT connection. Similarly, if the target system has
no network interface, PROSPECT can not be used. We
plan to add support for diﬀerent communication interfaces
(such as serial links) to PROSPECT so that it is usable in
these cases as well. Another limitation is that PROSPECT
requires pthreads on the target system and only runs on
Linux right now. Another limitation is the missing mmap
support for character devices due to the missing support in
FUSE. Since mmap calls can be forwarded just the same (i.e.
by using a similar approach as described in Section 4.3), we
plan to implement full mmap support in future versions.
As PROSPECT requires only very little supported func-
tionality on the target system and FUSE has been ported
to a number of operating systems (Section 3), our system
could be easily ported to diﬀerent architectures and operat-
ing systems as well. At least for some implementations, the
considerable slowdown caused by PROSPECT might lead
to issues. However, this situation also occurs when single-
stepping through programs and solutions, such as altering
the information returned by timing related system calls, ex-
ist. Also, our system does not provide any security features
at the moment.
Another consideration was brieﬂy discussed in Section 3.
When accessing devices on UNIX systems, their access rights
are determined by the device’s permissions. The client im-
plementation needs to create virtual character devices and
337Syscall
write()
lseek()
ioctl()
_newselect()
read()
close()
poll()
open()
Native [%] Native [ms] Fwd. [%] Fwd. [ms] Diﬀ. [ms]
19.32
2.2
116.26
-2.41
2.26
N/A
N/A
683.72
25.39
2.31
117.15
40.85
3.29
N/A
N/A
684.62
21.27
28.14
1.6
14.8
34.16
0.01
0.0
0.02
6.07
0.12
0.89
43.27
1.03
0.1
N/A
0.9
22.79
18.88
4.27
17.14
36.9
0.0
0.0
0.02
Slowdown [x]
3.18
18.65
130.37
-0.06
2.19
N/A
N/A
757.37
Table 5: PROSPECT Slowdown
therefore requires root privileges.
In contrast, the PRO-
SPECT server can be run as any user on the target system.
It is however recommended to run it as root, simply to en-
sure that all devices are accessible. Through PROSPECT,
the investigated process inherits the device access permis-
sions from the server. As a result, it could be possible for
an investigated process to access devices even though that
would not be possible under normal circumstances. This
property is not necessarily a limitation per se, as it consti-
tutes an additional possibility to inﬂuence system behavior
during analysis.
With regard to the high slowdown for unrestricted ioctl()
calls, our implementation still provides room for improve-
ment. For instance in future implementations, instead of
querying the /proc ﬁle system, we could implement a more
eﬃcient mechanism to minimize execution time.
8. RELATED WORK
When dealing with security analysis on embedded sys-
tems, most research approaches use static analysis to achieve
their goal. For instance, Khare et al. presented some of the
key problems that need to be faced when using static anal-
ysis techniques on a large embedded code base [9]. In their
work they focus on the static analysis of source code to im-
prove the overall security of embedded systems.
In contrast, Ramakrishnan and Gopal do not require ac-
cess to source code as their static program analysis tech-
niques run on embedded binaries [22]. However, they do
not focus on embedded security or vulnerability discovery.
In [18], Zili Shao et al.
introduce a mixed hardware/-
software system to check for and protect embedded systems
from buﬀer overﬂow attacks. Their system works during
program execution, but is more focused on vulnerability pro-
tection than on vulnerability discovery.
In [21], Sumpf and Brakensiek introduced device driver
isolation within virtualized embedded platforms. The ap-
proach presented here can be considered the most closely re-
lated system compared to PROSPECT. The authors created
device drivers with a generalized interface to provide homo-
geneous access for virtual machines.
In contrast to PRO-
SPECT, however, the implementation of the driver must be
known. Furthermore their system is limited to L4 microker-
nels and not suitable for unknown peripheral devices.
9. CONCLUSION
PROSPECT turned out to be a valuable tool that en-
abled us to conduct a full-scale dynamic security analysis
of a widely used ﬁre alarm system. Without PROSPECT,
dynamic analysis would have been infeasible due to the lim-
itations of the ﬁre alarm embedded system. We believe that
PROSPECT’s approach has a high practical impact. It al-
lows to overcome the limitations of static analysis that are
common for embedded vulnerability discovery. The general
concept is applicable to a wide range of embedded systems,
including smart phones or ﬁeld level SCADA components.
10. ACKNOWLEDGEMENTS
The research leading to these results has received fund-
ing from the Austrian Research Promotion Agency (FFG)
under grants 836276 (SG2), 834005 (Fire-IP) and the Eu-
ropean Union Seventh Framework Programme under grant
agreement n. 257007 (SysSec). We would like to thank
the anonymous reviewers for their helpful feedback and im-
provement suggestions. We would like to thank Trustworks
[12] for providing valuable insights and tools that made this
research possible.
11. REFERENCES
[1] A. Austin and L. Williams. One technique is not
enough: A comparison of vulnerability discovery
techniques. In Empirical Software Engineering and
Measurement (ESEM), 2011 International Symposium
on, pages 97–106, 2011.
[2] S. Bekrar, C. Bekrar, R. Groz, and L. Mounier.
Finding software vulnerabilities by smart fuzzing. In
Software Testing, Veriﬁcation and Validation (ICST),
2011 IEEE Fourth International Conference on, pages
427–430, 2011.
[3] D. Brylow, N. Damgaard, and J. Palsberg. Static
checking of interrupt-driven software. In Proceedings
of the 23rd International Conference on Software
Engineering, ICSE ’01, pages 47–56, Washington, DC,
USA, 2001. IEEE Computer Society.
[4] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley.
Unleashing mayhem on binary code. In Security and
Privacy (SP), 2012 IEEE Symposium on, pages
380–394, 2012.
[5] W. Drewry and T. Ormandy. Flayer: Exposing
application internals, 2007.
[6] T. Garﬁnkel and M. Rosenblum. A virtual machine
introspection based architecture for intrusion
detection. In In Proc. Network and Distributed
Systems Security Symposium, pages 191–206, 2003.
[7] S. Karnouskos. Stuxnet worm impact on industrial
cyber-physical system security. In IECON 2011 - 37th
Annual Conference on IEEE Industrial Electronics
Society, pages 4490–4494, 2011.
338[8] M. Kermani, M. Zhang, A. Raghunathan, and N. Jha.
[17] K. Serebryany, D. Bruening, A. Potapenko, and
Emerging frontiers in embedded security. In VLSI
Design and 2013 12th International Conference on
Embedded Systems (VLSID), 2013 26th International
Conference on, pages 203–208, 2013.
[9] S. Khare, S. Saraswat, and S. Kumar. Static program
analysis of large embedded code base: an experience.
In Proceedings of the 4th India Software Engineering
Conference, ISEC ’11, pages 99–102, New York, NY,
USA, 2011. ACM.
[10] P. Koopman. Embedded system security. Computer,
37(7):95–97, July 2004.
[11] B. Liu, L. Shi, Z. Cai, and M. Li. Software
vulnerability discovery techniques: A survey. In
Multimedia Information Networking and Security
(MINES), 2012 Fourth International Conference on,
pages 152–156, 2012.
[12] Trustworks KG. http://www.trustworks.at (retrieved
2013-04-17), 2013.
[13] A. Moser, C. Kruegel, and E. Kirda. Exploring
multiple execution paths for malware analysis. In
Proceedings of the 2007 IEEE Symposium on Security
and Privacy, SP ’07, pages 231–245, Washington, DC,
USA, 2007. IEEE Computer Society.
D. Vyukov. Addresssanitizer: a fast address sanity
checker. In Proceedings of the 2012 USENIX
conference on Annual Technical Conference, USENIX
ATC’12, pages 28–28, Berkeley, CA, USA, 2012.
USENIX Association.
[18] Z. Shao, C. Xue, Q. Zhuge, M. Qiu, B. Xiao, and
E. H.-M. Sha. Security protection and checking for
embedded system integration against buﬀer overﬂow
attacks via hardware/software. IEEE Transactions on
Computers, 55(4):443–453, 2006.
[19] K. V. Shibu. Introduction To Embedded Systems.
McGraw-Hill Education, 2009.
[20] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert,
M. Szydlowski, R. Kemmerer, C. Kruegel, and
G. Vigna. Your botnet is my botnet: analysis of a
botnet takeover. In Proceedings of the 16th ACM
conference on Computer and communications security,
CCS ’09, pages 635–647, New York, NY, USA, 2009.
ACM.
[21] S. Sumpf and J. Brakensiek. Device driver isolation
within virtualized embedded platforms. In Consumer
Communications and Networking Conference, 2009.
CCNC 2009. 6th IEEE, pages 1–5, 2009.
[14] S. Parameswaran and T. Wolf. Embedded systems
[22] R. Venkitaraman and G. Gupta. Static program
security-an overview. Design Automation for
Embedded Systems, 12(3):173–183, 2008.
[15] F. Project. Filesystem in userspace.
http://fuse.sourceforge.net/ (retrieved 2013-04-17),
2013.
[16] E. Schwartz, T. Avgerinos, and D. Brumley. All you
ever wanted to know about dynamic taint analysis and
forward symbolic execution (but might have been
afraid to ask). In Security and Privacy (SP), 2010
IEEE Symposium on, pages 317–331, 2010.
analysis of embedded executable assembly code. In
Proceedings of the 2004 international conference on
Compilers, architecture, and synthesis for embedded
systems, CASES ’04, pages 157–166, New York, NY,
USA, 2004. ACM.
[23] J. Viega and H. Thompson. The state of
embedded-device security (spoiler alert: It’s bad).
Security Privacy, IEEE, 10(5):68–70, 2012.
[24] C. Willems, T. Holz, and F. Freiling. Toward
automated dynamic malware analysis using
cwsandbox. Security Privacy, IEEE, 5(2):32–39, 2007.
339