2/7015 15/492 85/698 184/786
100
In the full SPIT experiment, we request the hundred bots to register with
the proxy. Spitter hits all the bots in four successive campaigns with increas-
ing intensity. Results are slightly better than in the partial SPIT experiment
(Table 9). Partial SPIT generates an abnormal traﬃc at the same level as full
SPIT does.
7 Related Works
VoIP security is a recent research domain that emerged over the last few years
with the increasing use of this technology by enterprises and individuals. Com-
bating SPIT and DoS is the subject of many research proceedings. Quittek
Monitoring SIP Traﬃc Using Support Vector Machines
327
et al. [10] apply hidden Turing tests and compare the resulting patterns with
typical human communication patterns. Passing these tests causes signiﬁcant
resource consumption in the SPIT generation side. The authors of [11] pro-
pose a call rank mechanism based on call duration, social networks and global
reputation to ﬁlter SPIT calls. Other ideas include a progressive and multi
(short term -long term) grey level algorithm [12] and incorporating active stack
ﬁngerprinting [13].
The authors of [14] design application and transport sensors to protect en-
terprise networks from VoIP DoS attacks based on previous works on TCP DoS
protection and study diﬀerent recovery algorithms. The authors of [15] modify
the original state machine of SIP transactions to detect transaction anomalies
and apply diﬀerent thresholds to detect ﬂooding attacks. More adaptive to such
attacks is the work of Sengar et al. [16] where the Hellinger distance between
learning and testing periods is used to detect TCP SYN, SIP INVITE and RTP
ﬂoods. Their approach shows good performances. There have many papers in
the community on generic intrusion detection methods [17,18,19] without to ex-
tend to the ﬁne tuned session, dialog, transaction related parameters found in
SIP. Over the past, many security related applications have leveraged machine
learning techniques and the reader is referred to [20] and [21] for an overview.
The closest work to ours is the study of [22] where the authors have presented
a traﬃc behavior proﬁling methodology and demonstrated its applications in
problem diagnosis and anomaly detection. Our work is more oriented towards
attack detection and classiﬁcation rather than proposing a global and multi level
proﬁling methodology. We have addressed the VoIP speciﬁc event correlation and
honeypots in previous published work [23] and [24], which did not cover SIP-level
monitoring.
8 Conclusion and Future Works
As attacks on VoIP are popping-up in diﬀerent forms with increasing impact on
both the users and infrastructure, more monitoring and security management is
needed. In this paper, we proposed an online monitoring methodology based on
support vector machines. Our idea is to cut the ongoing signalling (SIP) traﬃc
into small slices and to extract a vector of deﬁned features characterizing each
slice. Vectors are then pushed into a SVM for classiﬁcation based on a learning
model. We then use a deterministic event correlator to raise an alarm when
suspicious and abnormal situations occur.
We validated our approach by oﬄine tests over a set of real world traces and
attacks which are generated in our customized testbed and inserted in the normal
traﬃc traces. Results showed a real time performance and a high accuracy of
detecting ﬂooding and SPIT attacks especially when coupled with eﬃcient event
correlation rules. Detection of other types of attacks are future work.
Unsupervised learning techniques are appealing because they don’t need a
priori knowledge of the traﬃc and can detect new and previously unknown at-
tacks. We consider currently to redeﬁne and reorder our set of features based
328
M. Nassar, R. State, and O. Festor
on diﬀerent features selection algorithms. We will extend the current event cor-
relation and ﬁltering algorithm in order to reveal attack strategies and improve
intrusion prevention/detection accuracy.
Acknowledgment. We would like to thank Mr Dorgham Sisalem and Mr. Sven
Ehlert, both from Fraunhofer Institute in Berlin for their comments and feedback
on discussing the analysis of SIP traces.
References
1. VoIPSA: VoIP security and privacy threat taxonomy. Public Realease 1.0 (October
2005), http://www.voipsa.org/Activities/VOIPSA Threat Taxonomy 0.1.pdf
2. Endler, D., Collier, M.: Hacking Exposed VoIP: Voice Over IP Security Secrets and
Solutions. McGraw-Hill Professional Publishing, New York (2007)
3. Vapnik, V.N.: The nature of statistical learning theory. Springer, New York (1995)
4. Vapnik, V.: Statistical Learning Theory, New York (1998)
5. Guyon, I., Weston, J., Barnhill, S., Vapnik, V.: Gene selection for cancer classiﬁ-
cation using support vector machines. Mach. Learn. 46(1-3), 389–422 (2002)
6. Romano, R.A., Aragon, C.R., Ding, C.: Supernova recognition using support vec-
tor machines. In: ICMLA 2006: Proceedings of the 5th International Conference
on Machine Learning and Applications, Washington, DC, USA, pp. 77–82. IEEE
Computer Society, Los Alamitos (2006)
7. Mukkamala, S., Janoski, G., Sung, A.: Intrusion detection: Support vector machines
and neural networks. The IEEE Computer Society Student Magazine 10(2) (2002)
8. Chang, C.C., Lin, C.J.: LIBSVM: a library for support vector machines (2001),
http://www.csie.ntu.edu.tw/∼cjlin/libsvm
9. Abdelnur, H.J., State, R., Festor, O.: KiF: a stateful SIP fuzzer. In: IPTComm
2007: Proceedings of the 1st international conference on Principles, systems and
applications of IP telecommunications, pp. 47–56. ACM, New York (2007)
10. Quittek, J., Niccolini, S., Tartarelli, S., Stiemerling, M., Brunner, M., Ewald, T.:
Detecting SPIT calls by checking communication patterns. In: IEEE International
Conference on Communications (ICC 2007) (June 2007)
11. Balasubramaniyan, V.A., Ahamad, M., Park, H.: CallRank: Combating SPIT using
call duration, social networks and global reputation. In: Fourth Conference on
Email and Anti-Spam (CEAS 2007). Mountain View, California (2007)
12. Shin, D., Shim, C.: Progressive multi gray-leveling: A voice Spam protection algo-
rithm. IEEE Network 20
13. Yan, H., Sripanidkulchai, K., Zhang, H., Shae, Z.Y., Saha, D.: Incorporating active
ﬁngerprinting into SPIT prevention systems. In: Third annual security workshop
(VSW 2006), June 2006, ACM Press, New York (2006)
14. Reynolds, B., Ghosal, D.: Secure IP Telephony using Multi-layered Protection.
In: Proceedings of The 10th Annual Network and Distributed System Security
Symposium, San Diego, CA, USA (February 2003)
15. Chen, E.: Detecting DoS attacks on SIP systems. In: Proceedings of 1st IEEE
Workshop on VoIP Management and Security, San Diego, CA, USA, April 2006,
pp. 53–58 (2006)
16. Sengar, H., Wang, H., Wijesekera, D., Jajodia, S.: Detecting VoIP Floods using
the Hellinger Distance. Transactions on Parallel and Distributed Systems (acepted
for future publication, September 2007)
Monitoring SIP Traﬃc Using Support Vector Machines
329
17. Valdes, A., Skinner, K.: Adaptive, model-based monitoring for cyber attack de-
tection. In: Debar, H., M´e, L., Wu, S.F. (eds.) RAID 2000. LNCS, vol. 1907, pp.
80–92. Springer, Heidelberg (2000)
18. Denning, D.E.: An intrusion-detection model. In: IEEE Symposium on Security
and Privacy, April 1986, pp. 118–133. IEEE Computer Society Press, Los Alamitos
(1986)
19. Kr¨ugel, C., Toth, T., Kirda, E.: Service speciﬁc anomaly detection for network
intrusion detection. In: SAC 2002: Proceedings of the 2002 ACM symposium on
Applied computing, pp. 201–208. ACM Press, New York (2002)
20. Ning, P., Jajodia, S.: Intrusion Detection in Distributed Systems: An Abstraction-
Based Approach. Springer, Heidelberg (2003)
21. Maloof, M.: Machine Learning and Data Mining for Computer Security: Methods
and Applications. Springer, Heidelberg (2005)
22. Kang, H.J., Zhang, Z.L., Ranjan, S., Nucci, A.: Sip-based voip traﬃc behavior
proﬁling and its applications. In: MineNet 2007: Proceedings of the 3rd annual
ACM workshop on Mining network data, pp. 39–44. ACM, New York (2007)
23. Nassar, M., State, R., Festor, O.: Intrusion detections mechanisms for VoIP appli-
cations. In: Third annual security workshop (VSW 2006), June 2006. ACM Press,
New York (2006)
24. Nassar, M., State, R., Festor, O.: VoIP honeypot architecture. In: Proc. of 10 th.
IEEE/IFIP Symposium on Integrated Management. (June 2007)
330
M. Nassar, R. State, and O. Festor
Table 10. Appendix: List of features
Number Name
Description
Group 1 - General Statistics
Duration
NbReq
NbResp
NbSdp
AvInterReq
AvInterResp
AvInterSdp
Total time of the slice
# of requests / Total # of messages
# of responses / Total # of messages
# of messages carrying SDP / Total # of messages
Average inter arrival of requests
Average inter arrival of responses
Average inter arrival of messages carrying SDP bodies
Group 2 - Call-ID Based Statistics
NbSess
AvDuration
NbSenders
NbReceivers
AvMsg
# of diﬀerent Call-IDs
Average duration of a Call-ID
# of diﬀerent senders / Total # of Call-IDs
# of diﬀerent receivers / Total # of Call-IDs
Average # of messages per Call-ID
# of CALLSET/ Total # of Call-ID
Group 3 - Dialogs Final State Distribution
NbNOTACALL # of NOTACALL/ Total # of Call-ID
NbCALLSET
NbCANCELED # of CANCELED/ Total # of Call-ID
NbREJECTED # of REJECTED/ Total # of Call-ID
NbINCALL
NbCOMPLETED # of COMPLETED/ Total # of Call-ID
NbRESIDUE
# of INCALL/ Total # of Call-ID
# of RESIDUE/ Total # of Call-ID
NbInv
NbReg
NbBye
NbAck
NbCan
NbOpt
Nb Ref
NbSub
NbNot
NbMes
NbInf
NbPra
NbUpd
Nb1xx
Nb2xx
Nb3xx
Nb4xx
Nb5xx
Nb6xx
Group 4 - Requests Distribution
# of INVITE / Total # of requests
# of REGISTER/ Total # of requests
# of BYE/ Total # of requests
# of ACK/ Total # of requests
# of CANCEL/ Total # of requests
# of OPTIONS / Total # of requests
# of REFER/ Total # of requests
# of SUBSCRIBE/ Total # of requests
# of NOTIFY/ Total # of requests
# of MESSAGE/ Total # of requests
# of INFO/ Total # of requests
# of PRACK/ Total # of requests
# of UPDATE/ Total # of requests
Group 5 - Responses Distribution
# of Informational responses / Total # of responses
# of Success responses / Total # of responses
# of Redirection responses / Total # of responses
# of Client error responses / Total # of responses
# of Server error responses / Total # of responses
# of Global error responses / Total # of responses
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38