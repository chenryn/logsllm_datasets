### Table V: Anomaly Detection Performance on the BGL Dataset

| Method        | Precision (P) | Recall (R) | F1 Score (F) | Specificity (S) |
|---------------|---------------|------------|--------------|-----------------|
| LogBERT       | 28.82         | 94.92      | 44.22        | 37.18           |
| LogFiT (ours) | 95.249        | 84.2       | 89.38        | 99.16           |

**Note:** The evaluation data was modified to replace the top 10 verbs with their WordNet lemmas.

### Evaluation and Results

To test the LogFiT model's ability to handle log sentence variability, the evaluation set was dynamically modified during inference. Specifically, the top 10 occurring action words (that can be mapped to synonyms in WordNet) were replaced with their WordNet lemmas. Table V shows the results of feeding this modified BGL evaluation set to the unmodified LogFiT models.

The results indicate that the LogFiT model is robust to changes in the log sentences, as the reduction in F1 score is only around 2% (from 91.22 to 89.38). In contrast, the F1 score for LogBERT drops significantly from 88.63 to 44.22, highlighting LogFiT's superior performance in handling variations in log content.

### Conclusion

This paper introduces LogFiT, a novel log anomaly detection model that leverages the general linguistic knowledge embedded within a pre-trained BERT-based language model (LM). LogFiT is trained in a self-supervised manner using only normal system logs to predict masked tokens in log sequences. This approach enables LogFiT to recognize the linguistic structure of normal system logs and flag anomalies when it fails to reconstruct an input log sequence.

Critically, LogFiT's use of a BERT-based LM allows it to handle variability in the content of system logs. The performance of LogFiT was evaluated on the HDFS, BGL, and Thunderbird datasets, and it outperformed baseline models in terms of F1 score. Additionally, LogFiT's specificity exceeded that of the baselines on the HDFS and BGL datasets and was comparable to LogBERT on the Thunderbird dataset.

In experiments testing for variations in the content of input log paragraphs, LogFiT demonstrated superior performance over LogBERT, attributed to its ability to handle out-of-vocabulary tokens. LogFiT integrates with the popular HuggingFace ecosystem, making it easy to adapt in future work.

Overall, LogFiT presents a flexible and future-proof approach to detecting abnormal behavior in computer systems through language modeling.

### Future Work

While LogFiT is intended to be used as a threshold-based anomaly detector trained in a self-supervised manner, it can easily be converted to a classifier. If, after deployment, operators are able to collect and label anomaly log samples, the model can be converted to a classifier by replacing its language modeling head with a classification head.

Additionally, the LogFiT LM can be pre-trained on diverse log datasets, allowing it to serve as a foundation for downstream NLP and log anomaly detection tasks. This flexibility and adaptability make LogFiT a robust and transferable solution for anomaly detection in log data.

### References

1. Lun Pin Yuan, Peng Liu, and Sencun Zhu, "Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs."
2. Dan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic, Rishabh Krishnan, and Dawn Song, "Pretrained Transformers Improve Out-of-Distribution Robustness," Association for Computational Linguistics (ACL), Apr. 2020, pp. 2744â€“2751. DOI: 10.18653/v1/2020.acl-main.244. arXiv: 2004.06100. Available: https://arxiv.org/abs/2004.06100v2.
3. Harold Ott, Jasmin Bogatinovski, Alexander Acker, Sasho Nedelkoski, and Odej Kao, "Robust and Transferable Anomaly Detection in Log Data Using Pre-trained Language Models," in 2021 IEEE/ACM International Conference on Software Engineering (ICSE).

This optimized version provides a clear and professional presentation of the results, conclusions, and future work, while also ensuring that the references are properly formatted and cited.