Our analysis reports that each participant of each group
was prompted at least 4 times for non-attack opera-
tions. Note that, as per definition of first-use autho-
rization, participants in Group-FR-U and Group-FR-P
were not prompted with authorization messages once
again should they have already authorized the program
in a previous task or during the preliminary phase. In-
stead, participants in Group-EN-U and participants in
Group-EN-P were presented with a new authorization
message any time a new delegation path was identified
by EnTrust. This explains the lower percentage of sub-
jects prompted, with an authorization request, in the
first-use groups.
TASK A: The analysis of subjects’ responses revealed
that 9 subjects from Group-FR-U and 8 subjects from
Group-FR-P interacted with Smart Assistant during the
preliminary phase, or during another task, to “take a
screenshot” and granted the app permission to capture
their screen; thus, they were not prompted once again
with an authorization message during this task, as per
default in first-use permissions. In addition, 4 subjects
from Group-FR-U explicitly allowed Smart Assistant to
capture their screen, therefore, resulting in a 87% and
53% attack success, respectively, as reported in Table 1.
On the contrary, only 3 subjects from Group-EN-U and
no subject from Group-EN-P allowed the attack (20%
and 0% attack success, respectively). Also, similarly to
what happened in Group-FR-U and Group-FR-P, 8 sub-
jects from Group-EN-U and 8 subjects from Group-EN-P
interacted with Smart Assistant during the preliminary
phase and asked to “take a screenshot.” However, since
the voice command “create a note” was a different com-
mand, EnTrust prompted all subjects with a new au-
thorization message, as shown in Table 1.
TASK B : The analysis of subjects’ responses revealed
that 9 subjects from Group-FR-U and 7 subjects from
Group-FR-P interacted with Basic Camera to take a pic-
ture or record a video, either during the preliminary
phase or during another task, and authorized it to cap-
those
576    28th USENIX Security Symposium
USENIX Association
ture pictures, audio, and access the device’s location.
Thus, they were not prompted once again during this
task as per default in first-use permissions. Also, we
found that 3 subjects from Group-FR-U explicitly au-
thorized Basic Camera to access the camera, as well as
the microphone, and the GPS receiver; therefore, re-
sulting in 80% and 47% attack success, respectively. In
contrast, 2 subjects from Group-EN-U and no subject
from Group-EN-P authorized access to the camera, mi-
crophone, and GPS receiver (13% and 0% attack suc-
cess, respectively). Also, we found that 8 subjects from
Group-EN-U and 6 subjects from Group-EN-P interacted
with Basic Camera during the preliminary phase or
during another task. However, none of them asked to
“take a selfie” before, so all subjects were prompted by
EnTrust with a new authorization message. At the end
of the experiment, among all the subjects, when asked
why they authorized access to the GPS receiver, the ma-
jority said that they expected a camera app to access
location to create geo-tag metadata when taking a pic-
ture. In contrast, the subjects who denied access stated
not feeling comfortable sharing their location when tak-
ing a selfie.
TASK C : The analysis of subjects’ responses revealed
that 8 subjects from Group-FR-U and 8 subjects from
Group-FR-P interacted with Basic Camera, either dur-
ing the preliminary phase or during another task, and
authorized the app to capture pictures. Thus, during
this task, they were not prompted with an authorization
message once again as per default in first-use permis-
sions. They were only prompted to grant permission to
Mobile Banking, explaining why even the primed sub-
jects were not able to detect the attack.
In addition,
2 subjects from Group-FR-U explicitly authorized Ba-
sic Camera to capture a frame with the bank check;
therefore, resulting in 67% and 53% attack success, re-
spectively. On the other hand, only 1 subject from
Group-EN-U and no subject from Group-EN-P autho-
rized Basic Camera to capture a frame with the bank
check, resulting in a 7% and 0% attack success, re-
spectively. Notice that all subjects from Group-EN-U
and Group-EN-P were prompted with a new authoriza-
tion message by EnTrust for the new command “de-
posit bank check.” Interestingly, the one subject from
Group-EN-U, who allowed Basic Camera to capture a
frame with the bank check, verbally expressed his con-
cern about the permission notification presented on the
screen. The subject stated observing that two apps
asked permission to access the camera to take pictures.
This is reasonable for an unprimed subject not expect-
ing a malicious behavior.
from Group-FR-P, and those
Discussion: Comparing the results from Group-FR-U
versus
from
Group-EN-U versus those from Group-EN-P, we observe
- as expected - that primed subjects allowed fewer at-
tacks. We find that users primed for security problems
still fall victim to attacks due to first-use authorization,
even when rejecting all the malicious operations they
see. On the other hand, unprimed users fail to detect
attacks between 7-20% with EnTrust. So while this is a
marked improvement, over the 67-87% failure for users
with first-use authorization, there is room for further
improvement. However, it is apparent that the dele-
gation graphs constructed by EnTrust aided the sub-
jects in avoiding attacks even when unprimed. EnTrust
performed slightly better than first-use authorization in
terms of explicit authorizations (explicit allows in Ta-
ble 1); which suggests that the additional information
provided by EnTrust in authorization messages (i.e.,
programs’ name and identity mark as well as delega-
tion information, as shown in Figure 6) may be help-
ful to users in avoiding unexpected program behav-
iors. We verified the hypothesis that the information
in EnTrust authorizations helps unprimed users iden-
tify attacks by calculating the difference in explicit al-
lows, across the three experimental tasks, for subjects in
Group-FR-U versus subjects in Group-EN-U. Our anal-
ysis indeed revealed a statistically significant difference
(χ2 = 19.3966; p = 0.000011).
Also, EnTrust was significantly more effective than
first-use in keeping users “on guard” independently of
whether subjects were primed (47-67% lower attack suc-
cess with EnTrust).
Indeed, different from the first-
use approach, EnTrust was able to highlight whether
pre-authorized programs attempted accessing sensors
via unauthorized delegation paths.
If so, EnTrust
prompted users for an explicit authorization for the
newly identified delegation path. We verified the hy-
pothesis that EnTrust better helps primed and un-
primed users in preventing attacks than first-use, by cal-
culating the difference in successful attacks, across the
three experimental tasks, for subjects in Group-FR-U
and Group-FR-P, versus subjects in Group-EN-U and
Group-EN-P. Our analysis indeed revealed a statistically
significant difference (χ2 = 65.5603; p = 0.00001). Nor-
mally, the standard Bonferroni correction would be ap-
plied for multiple testing, but due to the small p-values
such a correction was not necessary.
6.3 Field Study
We performed a field study to evaluate whether EnTrust
increases the decision-overhead imposed on users. We
measured the number of explicit authorizations users
had to make when interacting with EnTrust under re-
alistic and practical conditions, and compared it with
the first-use approach adopted in commercial systems
(i.e., Android OS and Apple iOS). We also measured the
number of authorizations handled by EnTrust via the
cache mechanism that, transparently to users, granted
authorized operations.
Experimental Procedures: Participants met with one
of our researchers to set up the loaner device, an LG
Nexus 5X smartphone running a modified version of
the Android OS integrating the EnTrust authorization
framework. The loaner device had pre-installed 5 voice
assistants and 10 apps selected among the most pop-
ular6 with up to millions of downloads from the offi-
cial Google Play store. For such programs, to ensure
the confidentiality of participants’ personal information,
mock accounts were set up instead of real accounts for
all apps requiring a log-in. To facilitate daily use of the
loaner device, the researcher transferred participants’
SIM cards and data, as well as participants’ apps in the
loaner device, however no data was collected from such
apps. The above protocol was a requirement for the IRB
approval by our Institution and it is compliant with the
protocol followed in related work [33, 15, 11]. Before
loaning the device, the researcher asked each partici-
pant to use the loaner device for their everyday tasks
for a period of 7 days.
In addition to their everyday
tasks, participants were asked to explore each of the pre-
installed voice assistants and apps, at least once a day,
by interacting as they would normally do. Particularly,
we asked the participants to interact with each voice as-
sistant by asking the following three questions: (1) “cap-
ture a screenshot,” (2) “record a voice note,” (3) “how
long does it take to drive back home.” Additionally, we
asked participants to be creative and ask three addi-
tional questions of their choice. Table 2 summarizes all
the assistants and apps pre-installed on the smartphones
for the field study. Because the mere purpose of our field
study was to measure the decision-overhead imposed to
users by EnTrust and to avoid participants’ bias, the
researcher advertised the study as a generic “voice as-
sistants and apps testing” study without mentioning
security implications or training the users about the
features provided by EnTrust. The smartphones pro-
vided to participants were running a background service
with runtime logging enabled, automatically restarted
at boot time, to monitor the number of times each pro-
gram was launched, the users’ input events, the con-
structed delegation graphs, the authorization decisions
made by the participants, and the number of autho-
rizations automatically granted by EnTrust. The back-
ground service also measured the gaps between consecu-
tive input events and handoff events, as well as the time
required by each program to service each event. This
data was used to perform the time constraints analysis
reported in Appendix B.
Experimental Results: Nine subjects participated and
completed the field study. The data collected during our
experiment indicates that all user authorizations were
obtained within the first 72 hours of interaction with
the experimental device, after which we observed only
operations automatically granted by EnTrust via the
caching mechanism.
The first subject allowed us to discover two imple-
mentation issues that affected the number of explicit
authorizations required by EnTrust. First, changing the
orientation of the screen (portrait versus landscape) was
causing EnTrust to request a new explicit user autho-
USENIX Association
28th USENIX Security Symposium    577
Expl. Authorizations
First-Use
EnTrust
Impl. Authorizations
in s 7 Days Period
3
3
2
3
3
2
3
2
1
3
1
1
1
1
1
3
3
2
3
3
2
3
2
1
3
4
3
4
4
3
276
84
93
393
117
76
100
101
18
127
72
49
84
63
56
Snapchat
YouTube
Facebook Messenger
Instagram
Facebook
Whatsapp
Skype
WeChat
Reddit
Bitmoji
Google Assistant
Microsoft Cortana
Amazon Alexa
Samsung Bixby
Lyra Virtual Assistant
Table 2: Apps and voice assistants tested in the field study.
The last column shows the number of operations automati-
cally authorized by EnTrust after user’s authorization.
rization for an already authorized widget whenever the
screen orientation changed. This inconvenience was due
to the change in some of the features used to model the
context within which the widget was presented. To ad-
dress this shortcoming, we modified our original pro-
totype to force the Window Manager to generate in
memory two graphical user interfaces for both screen
orientations to allow EnTrust to bind them with a spe-
cific widget presented on the screen. Second, for the
voice commands, we noticed that differently phrased
voice commands with the same meaning would be iden-
tified as different input events. For instance, “take
a selfie” and “take a picture of me”. This shortcom-
ing was causing EnTrust to generate a new delegation
graph for each differently phrased voice command. To
address this issue, we leveraged the Dialogflow engine
by Google, part of the AI.API.7 Dialogflow is a devel-
opment suite for building conversational interfaces and
provides a database of synonyms to group together voice
commands with the same meaning. We fixed the issues
and continued our experiment with other subjects.
Table 2 reports the average number of explicit autho-
rizations performed by the subjects. We compared them
with the number of explicit authorizations that would
be necessary if the first-use permission mechanism was
used instead. The results show that EnTrust required
the same number of explicit authorizations by users for
all the tested apps. For all voice assistants, instead,
EnTrust may require up to 3 additional explicit autho-
rizations, when compared with the first-use approach;
which is far below the 8 additional explicit authoriza-
tions used in prior work, which are considered likely not
to introduce significant risk of habituation or annoy-
ance [33]. These additional authorizations are due to
the fact that with the first-use approach the programs
(activated by the voice assistant to serve the user re-
quest) may have already received the required permis-
sions to access the sensitive sensors. EnTrust instead
captures the entire sequence of events, from the input
event to any subsequent action or operation request, and
then ties them together. Therefore, EnTrust constructs
a new graph for each novel interaction. Nonetheless,
the number of decisions imposed on the users remains
very modest. Indeed, on average, three additional ex-
plicit user authorizations are required per voice assis-
tant. Also, the number of explicit authorizations made
by the users remained a constant factor compared to the
number of operations implicitly authorized by EnTrust,
which instead grew linearly over time. We measured
an average of 16 operations implicitly authorized by
EnTrust during a 24-hour period (last column of Ta-
ble 2). Therefore, if we consider such a daily average
number of implicitly authorized operations for a period
of one year, we will have on the order of thousands of
operations automatically authorized by EnTrust, which
would not require additional explicit effort for the users.
6.4 Backward Compatibility Analysis
To verify that EnTrust is backward compatible with ex-
isting programs, we used the Compatibility Test Suite
(CTS),8 an automated testing tool released by Google
via the AOSP.9 In particular, this analysis verified that
possible delays in the delivery of events introduced by
EnTrust or the change in scheduling of events did not
impact applications’ functionality. We tested the com-
patibility of EnTrust with 1,000 existing apps, among
the top 2,000 most downloaded apps on Google Play
Store, selected based on those declaring permissions to
access sensitive sensors in their manifest. The experi-