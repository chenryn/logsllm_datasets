20
3
3 –
1
1 –
4
3 –
1 –
8
2
1 –
1 –
4
2 –
2 –
6
3
1 –
2 –
3
1 –
2 –
2
2 –
8
Environment Setup. For our evaluation, we use a machine
with i7-9700k 3.6Ghz and 16GB RAM, running 64-bit Linux
Ubuntu 16.04 (for A1, A3, and A4) and Windows 10 (for A2).
B. Effectiveness in Finding Logic Flaws
Table III presents the number of executions exhibiting logic
ﬂaws identiﬁed by SWARMFLAWFINDER for each algorithm.
In total, we ﬁnd 4,684 executions leading to mission failures
for the four algorithms: 1,554 from A1, 755 from A2, 287 from
A3, and 2,088 from A4 (in the third column). After pruning
out similar executions, we ﬁnd 42 distinct mission failures,
that are attributed to 15 different root causes (C1-1∼C4-3)2.
The unique number of failures are presented in the fourth
column and the last column shows whether it is conﬁrmed by
the developers of the algorithms. – indicates that developers
have conﬁrmed the logic ﬂaws. We further analyze the mission
failures and categorize them into four different types as follows
(in the gray shaded rows):
1. Crash between victim drones: A victim drone is crashed
into another victim drone.
2. Crash into external objects: A victim drone is crashed
into an external object (not a victim drone).
3. Suspended progress: A swarm could not make meaning-
ful progress, failing to complete the mission.
4. Slow progress: A swarm’s progress is exceptionally slow,
eventually failing to complete the mission in time. This is
less severe than the suspended progress since the swarm
may ﬁnish the mission if given a longer time.
Root Causes and Potential Fixes. We identify root causes of
the mission failures and potential ﬁxes via manual analysis.
Note that all the ﬁxes we present below resolved the prob-
lem in the tested scenarios. We also communicate with the
developers to conﬁrm the ﬁxes. Fixes with ‘(Conﬁrmed)’ are
the ones that are conﬁrmed. We present a few cases in this
section, and the remainings are in § IX-F.
C1-1. Missing collision detection: In A1, a leader drone
does not have logic for avoiding other drones in a swarm. The
algorithm developers conﬁrmed that they thought that leader
drones always move ahead of other drones, believing the logic
is unnecessary. Details are in § V-E1.
Fix (Conﬁrmed): We reuse code snippets from a follower
drone that detects other victim drones for the leader drone.
C1-2. Naive multi-force handling: A1 uses the artiﬁcial
potential ﬁeld (APF) to implement the drones’ collision avoid-
ance mechanism. Unfortunately,
it has difﬁculty handling
multiple forces are involved, as shown in § III’s Fig. 3.
Fix (Conﬁrmed): We ﬁnd that this is a fundamental weak-
ness of the APF. One may reconﬁgure the algorithm to
make the drone sense external objects earlier by changing
the value of influence radius (from 0.15 to 0.3). This
will avoid a drone surrounded by external objects.
2CX-Y means “the root cause Y of a logic ﬂaw in algorithm X (AX)”
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
91816
(a) Adaptive Swarm (Navigation)(c) Sciadro(Distributed search)(b) SocraticSwarm(Coordinated search)(d) Pietro’s (Search and rescue)C1-4. Excessive force in APF: A1 uses the artiﬁcial potential
ﬁeld (APF) to make drones’ decisions at runtime. If a drone is
at a location that is very far from the other drones in a swarm,
a force to move toward the swarm becomes excessively strong,
making the detached drone ﬂy directly to the swarm without
considering external objects on the path (e.g., wall). In other
words, the drone decides to ﬂy toward the wall because the
force for rejoining the swarm becomes bigger than the force
preventing the drone from crashing into the wall.
Fix (Conﬁrmed): We deﬁne a maximum value for all
forces and assign a much larger value than the maximum
value for the force related to obstacles (e.g., the wall). It
requires changing 6 SLOC. This prevents the drone from
crashing into obstacles but often causing the swarm stuck
as described in C1-5, requiring the ﬁx from C1-5 as well.
C1-5. Naive swarm’s pose measurement: A1 measures the
current pose of the entire swarm by computing the centroid
of all drones. Unfortunately, this often neglects drones to fall
behind signiﬁcantly, eventually making the swarm unable to
progress. Details are shown in § V-E2.
Fix (Conﬁrmed): We add code snippets (2 SLOC) to con-
sider the drone’s distances from the centroid, and if a drone
is signiﬁcantly far behind than others (e.g., more than two
times), we make the leader wait for the other drones.
C2-1. Overly-sensitive object detection: Drones are conﬁg-
ured to be overly sensitive in avoiding external objects, leading
to crashes to other victim drones to avoid objects.
Fix (Conﬁrmed): We relax the object detection by changing
DEFAULT WEIGHT COSTS to 0.219 (from 0.319) in A2.
C2-2. Indeﬁnite wait for crashed drones: A2 uses a bid-
ding algorithm to distribute tasks to individual drones. The
algorithm has a bug that it does not exclude crashed drones
(hence unusable) from the bidding process. After assigning a
task to an inactive crashed drone, the algorithm waits for the
task completion indeﬁnitely, suspending progress.
Fix (Conﬁrmed): We change the bidding algorithm (10
SLOC) to reclaim tasks from crashed drones.
C2-3. Long deadline for an assigned task: A2’s bidding
algorithm has an internal deadline for each task assigned to
a drone. However, the deadline is too long. When an attack
drone successfully prevents victim drones from completing
tasks, the algorithm keeps waiting for the task.
Fix (Conﬁrmed): We change the deadline (SEARCH
TIMEOUT TIME) shorter in A2. This effectively mitigates
the delays caused by the adversarial drones in our scenario.
C2-4. Drones detaching from a swarm: We observe that
malfunctioning drones are moving outside of the map, de-
taching themselves from the swarm. This is because drones
do not have any tasks to bid (i.e., ﬁnished all the tasks) have
no incentive to stay in the swarm. This signiﬁcantly delays the
swarm’s progress since the algorithm still waits for the task
completion by the malfunctioning drone.
Fix (Conﬁrmed): We increase the individual drone’s incen-
tive value for being a part of the swarm.
C3-1 and C4-1. Naive detouring method: In A3, when a
drone encounters an obstacle, it tries to detour the obstacle
by randomly selecting the alternative direction (i.e., angle) to
ﬂy. Unfortunately, if objects are approaching the drone from
the randomly decided direction, the drone crashes. Moreover,
this method also performs poorly for drones escaping from a
complex structure, delaying the progress signiﬁcantly.
Fix : For A3, we add more randomness in choosing a
direction for detouring by changing 8 SLOC. For A4, we
ﬁnd that the randomness in the detouring process overly
affects the decision. Hence, we remove the random values
involved in the process by changing 2 SLOC.
C4-2. Detouring without sensing: In A4, when a drone
avoids an obstacle, it selects an alternative path. Unfortunately,
it does not consider whether there is an obstacle in the
alternative path. If there is an object in the path, the drone
crashes. We present a detailed case study in § V-E3.
Fix : We add 10 SLOC to make a drone sense the surround-
ings when it calculates an alternative path.
Quality of Fixes. To understand the quality of our ﬁxes,
we have applied them to the algorithms, and run SWARM-
FLAWFINDER on the ﬁxed algorithms (for 24 hours per
algorithm). The results show that the logic ﬂaw targeted by
the ﬁx is no longer observed after applying each ﬁx. Hence,
we consider each ﬁx successfully resolves its targeted logic
ﬂaw. Further, we apply all the ﬁxes together (i.e., an integrated
ﬁx) and run SWARMFLAWFINDER to understand whether the
integrated ﬁx can eliminate all the logic ﬂaws. We ﬁnd that
for A1, the integrated ﬁx fails to resolve C1-2 and C1-6,
because the ﬁxes for C1-2 and C1-6 are conﬂicting. To solve
this, we manually tune the conﬁguration values (i.e., changing
influence radius to 0.225 and repulsive coef to 300
in the ﬁxes; the original ﬁxes; the original ﬁxes are changing
them to 0.3 and 400), and the tuned integrated ﬁx resolved all
the logic ﬂaws. Details can be found in § IX-D.
Side Effects of Fixes. While the ﬁxes make the algorithms
more robust, they may also cause overhead. We observe 3.9%,
2.5%, 1.2%, and 1.5% average overhead for A1, A2, A3, and
A4, respectively. For the integrated ﬁxes, we observe 11.4%,
9.0%, 2.2%, and 4.7% overhead for A1, A2, A3, and A4,
respectively. Details can be found in [8]. Note that we do not
observe ﬁxes introducing additional logic ﬂaws.
Impact of Flaws. In A1, C1-1∼C1-4 are the most critical bugs
since they will result in crashed drones. C1-5∼C1-6 lead to
mission delays, and the victim drones are intact; hence their
impact is limited. In A2, A3, and A4, the crashes between
drones are less critical than crashes in A1 since there are many
victim drones, and crashing a few drones may not immediately
lead to mission failures. However, since a crash in A2 (C2-
2) can suspend the search progress, it is more critical than
the crashes in A3 and A4. Slow progress type bugs in all
algorithms are less impactful than other types of bugs.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
101817
is because, in part, SWARMFLAWFINDER can run more test
cases exhaustively in the focused area, guided by DCC, without
any domain knowledge in ﬁnding the area. The random
testing approach does not have such a particular focused area
observed. Second, SWARMFLAWFINDER found on average
25.75% more failures than random testing (red and orange
dots in Fig. 8), when we run both for the same period (i.e.,
24 hours). We present details of the statistics in the Appendix
(Fig. 16). Third, the random testing seems to ﬁnd some unique
DCC values from the places that SWARMFLAWFINDER did not
test (the large red and blue dots outside the shade). However,
we manually check them and ﬁnd that they are variants of the
tests generated by SWARMFLAWFINDER, meaning that they
are all subsets of SWARMFLAWFINDER’s tests.
3) Impact of Searching Space on Random Testing: Observe
that the random testing approach’s test cases are spread over
the wide area in Fig. 8. This is because the random testing
approach lacks the guidance metric which is DCC in SWARM-
FLAWFINDER. To further understand the effectiveness of DCC
and the impact of searching space, we conduct additional
experiments with different searching spaces restrictions on
random testing approach. Speciﬁcally, we run the random
testing with the explored space (e.g., the gray shaded area
in Fig. 8-(b)) obtained by SWARMFLAWFINDER. We also run
two more experiments with 2x and 3x Base searching spaces
(as shown in Fig. 17). The results show that the random testing
performs better when given the searching space. However,
it still misses three logic ﬂaws C1-2, C1-3, and C2-1, that
are dependent on the subtle timing. Details including all the
experiment results (in Table IV) can be found in § IX-C2.
D. Coverage based on DCC
We measure the coverage of DCC values by SWARM-
FLAWFINDER. Speciﬁcally, we ﬁrst collect an almost com-
plete range of the DCC values by running tests with attack
drones on every 0.2 meters in the 3D space. Then, we run
SWARMFLAWFINDER for 24 hours to understand how many
DCC values (out of the collected values) are covered. We
also run the random testing version of SWARMFLAWFINDER
(without the DCC guidance) and measure the coverage of DCC
values. As shown in Fig. 9, SWARMFLAWFINDER covers two
times more DCC values (avg. 63.5%) than the random testing
version (avg. 28.5%). Details can be found in § IX-B.
E. Case Studies
1) Missing Collision Detection in Adaptive Swarm: Fig. 10
shows three screenshots of a failed mission which we repro-
duced in the lab with real world drones. The failed mission
represents the ‘C1-1’ in Table III. In Fig. 10-(a), the attack
drone (red circled) approaches the leader drone (L), making
it to move closer to another drone near the wall (F3). In (b),
the attack drone pushes the leader drone further. Interestingly,
we ﬁnd that the leader does not consider the fact that there
is F3, pushing it to the wall until F3 crashes. In (c), after the
crash, the attack drone still is alive.
Fig. 8.
FLAWFINDER and (b) the random testing approach.
Spatial Distribution of Test cases generated by (a) SWARM-
Fig. 9. Coverage of Unique DCC Values.
C. Effectiveness of DCC in Fuzz Testing
1) Creating Random Testing Approach: To understand the
effectiveness of DCC based guidance during the fuzz testing,
we create a random testing approach by removing DCC based
guidance from SWARMFLAWFINDER. The random testing
version only leverages the result of the execution (whether
the mission is failed or not). If a test run resulted in a mission
failure, it prioritizes similar tests by perturbing the test case
with a small delta. If a test did not lead to a mission failure,
it tries to mutate the test case with a larger random value, as
SWARMFLAWFINDER does when it observes a similar DCC
value described in § IV-C.
2) Spatial Distribution of Test-cases: We run the random
testing approach and SWARMFLAWFINDER on our evaluated
algorithms for 24 hours to measure the spatial distribution
of the test cases generated by the two techniques. Fig. 8
shows the results of A1 (Results for A2, A3, and A4 are
presented in [8]). Speciﬁcally, Fig. 8-(a) is the results from
SWARMFLAWFINDER while (b) is from the random testing
approach. The silver round dotted circles approximately show
the size of the area explored during the testing. Each dot in
the ﬁgure represents a test case. Large dots indicate they result
in new unique DCC values, where small dots are not. Red and
orange dots are the test cases that caused mission failures (i.e.,
discovering logic ﬂaws). Silver and blue dots are the test cases
that do not cause mission failures. Note that we do not limit
searching space for both SWARMFLAWFINDER and random
approach, and the results show that SWARMFLAWFINDER
does more focused searching. The shaded area in Fig. 8-(b)
represents the explored area by SWARMFLAWFINDER in (a).
Observations. First, SWARMFLAWFINDER is able to focus
on testing a smaller but more promising area, as shown in
the shaded area. Moreover, while it
tests a smaller area,
SWARMFLAWFINDER’s test cases result in more new unique
DCC values (represented by the large red and blue dots). This
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
111818
(a) Visualized test cases generated for A1by SWARMFLAWFINDER(b) Visualized test cases generated for A1 by the random testing approachVictimSwarm69.2%59.8%67.0%57.9%30.8%27.8%29.5%25.8%0%10%20%30%40%50%60%70%80%A4A3A2A1RandomFlawFinderSwarmFlawFinderFig. 10. Attack drone causing a victim drone (F3) to crash into the wall.
Fig. 11. Attack drone pushes a victim drone F2 to suspend the swarm’s progress.
Analysis. We manually analyze the algorithm to understand
why the leader drone keeps moving forward while F3 stays
behind the wall. It turns out that the algorithm computes the
centroid of all drones to measure the current position of the
swarm. As long as the centroid is not falling behind, the leader
keeps moving forward. Hence, even if F3 cannot progress,
the other drones’ progress makes the centroid move toward
the destination, giving the leader a wrong perception that the
swarm is progressing. A possible ﬁx is to consider the distance
between the centroid and individual drones.
3) Detouring without Sensing: Fig. 12 shows the failed
mission (C4-2 in A4): (a) the attack drone (red drone) pushes
two victim drones into the corner. (b) The victim drones sense
the corner and try to ﬂy in the opposite direction. Then, both
drones ﬂy to the same location, causing a crash.
Analysis. This crash happens when an attack drone pushes
multiple drones into the corner, making both of them try to
escape from the corner. From our manual analysis, we ﬁnd that
the algorithm does not have code for detecting obstacles when
detouring. As a result, when it computes a ﬂight path to detour,
it does not consider any obstacles in the path. We believe this is
a mistake, and we resolved this issue by implementing sensing
during detouring by reusing the existing code.
VI. DISCUSSION
Additional Attack Strategies. We acknowledge that there can
be more sophisticated attack strategies, which may improve
the SWARMFLAWFINDER’s performance. Adding new attack
strategies is straightforward. One can deﬁne a new attack
behavior relative to a victim drone. The essence of this
research is to show the feasibility of DCC based fuzz testing.
DCC and Behavior Abstraction. While it turns out DCC is
highly effective in guiding the SWARMFLAWFINDER’s testing
Fig. 12. Drones crashing while detouring due to obstacles.
Analysis. We inspect the DCC values of the leader drone
before the crash. Interestingly, its DCC values do not include
other victim drones, even if they are very close. This means
that the leader drone does not recognize and try to avoid other
victim drones. We inspect the source code of A1 and ﬁnd
that it does not have the logic to detect other victim drones
as external objects. The algorithm’s developer conﬁrms that
the logic is omitted, because the leader drone will mostly ﬂy
ahead of other drones, making the mission failure difﬁcult to
be revealed without SWARMFLAWFINDER. We ran SWARM-
FLAWFINDER without the DCC guided feedback (i.e., random
testing approach) for 24 hours and did not ﬁnd the error.
2) Suspended Swarm Mission due to a Logic Flaw: We ﬁnd
another logic ﬂaw (C1-5 in Table III) in A1. Fig. 11 shows
the mission failure reproduced with the real-world drones. In
(a), the attack drone (red circled) chases the victim drone F2,
making it go faster. This results in F2 blocking the path of F3.
As shown in (b), F3 is stalled because F2 is going faster than
expected. In (c), F3 is completely behind the wall, while L
and F1 make progress toward the destination. Finally, in (d),
due to the F3, the other drones cannot make progress while
F3 cannot proceed due to the F2 blocking its path.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
121819
(a) Attack drone pushes the leader drone(b) Leader drone moves backwithoutconsideringtheF3,makingF3 crashing into the wall(c) Missionfailedwithacrash(The attack drone still alive)LF2F3F1LF2F3F1LF2F3F1(a) Attack drone chases a victim drone(b) The chased victim drone blocks the other drone’s way, making it stuck behind the wall(c) Other drones make progress(d) The entire swarm cannot make progress due to the drone stuck behind the wallLF2F3F1LF2F3F1LF2F3F1LF2F3F1(a) Victim drones approaching the corner(b) Victim drones try to detour without considering the surroundingprocess, we do not argue that DCC is a direct abstraction of
the swarm behavior. Instead, it is an approximation of the
abstraction. However, we argue that it captures the behavior
differences of swarm algorithms effectively.
VII. RELATED WORK
Testing for Robotics. While systematic testing for robotics
systems helps improve the overall quality and safety of the
systems signiﬁcantly, testing robots in real-world conditions
is often expensive and unsafe. As a result, simulation-based
approaches have been widely adopted in robotics testing [39]–
[46], and shown to be effective [47]. [44] proposes coverage-
driven veriﬁcation (CDV) for evaluating the testing progress of
the system under test. CDV and DCC in SWARMFLAWFINDER
share the same goal while CDV is coarse-grained and requires
deﬁnitions from developers. [48], [49] apply combinatorial
interaction testing to detect ﬂaws triggered by interactions
of parameters, while they also require deﬁnitions of systems’
conﬁguration space. Cal`o [50] proposes using search-based