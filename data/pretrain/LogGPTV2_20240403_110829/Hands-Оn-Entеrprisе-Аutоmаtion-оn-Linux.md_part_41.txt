dynamic inventory. This type of Ansible command is known as an ad hoc command, and it
is typically used to run a single Ansible module against an inventory, with a set of
parameters.
Throughout this book, we have encouraged the use of full playbooks and roles for all
Ansible tasks—and for good reason! If you frequently run commands without storing the
code in some shape or form, it will soon become very difficult, if not impossible, to know
who ran what and when they ran it. Indeed, if you have looked into AWX/Ansible Tower,
you will see that it does not even support ad hoc Ansible commands—running them is not
aligned with the principles of auditability and role-based access control that underpin this
product.
The example ping command we have looked at is the same as writing a playbook that
looks like this:
---
- hosts: webservers
gather_facts: no
tasks:
- ping:
The question is, then, why would you want to learn about ad hoc commands in Ansible?
The answer often comes about for one-off maintenance tasks. The beauty of Ansible is that
once you have implemented it throughout your infrastructure (and set up authentication,
inventories, and so on), it has access to all of your servers.
[ 452 ]
Tips and Tricks Chapter 16
For example, suppose you need to distribute an emergency patch to a set of systems by
copying a file across. There are several ways you could solve this problem, including these:
Write an Ansible playbook (and/or reusable role) to copy the file
Copy across the file manually using scp or a similar tool
Execute an ad hoc Ansible command
Of these three options, the first is almost certainly going to be inefficient in an emergency
scenario. The manual copying using scp is perfectly valid but is inefficient, especially when
you have gone to the trouble of setting up Ansible.
In an ad hoc command, you can use any module that you can use in a playbook or role.
You can specify the same arguments too, only they are formatted a little differently as we
specify them on the command line rather than in a YAML file.
Let's suppose an error has been found on the front page of our web server, and we urgently
need to copy across a new version that has the fix in it. The ad hoc command to run this
might look like this:
$ ansible webservers -i inventory -m copy -a "src=frontpage.html
dest=/var/www/html/frontpage.html" --become
Let's break that command down—the group and inventory script are specified just as
before, but this time, we have the following:
Tells Ansible to use the copy module for the ad
-m copy
hoc command
Provides the parameters or arguments for the
-a "..."
module
The src parameter, which tells the copy
src=frontpage.html module where to obtain the file from on the
Ansible server
The dest parameter, which tells the copy
dest=/var/www/html/frontpage.htmlmodule where to write the file on the
destination server
--become Tells Ansible to become root (that is, sudo)
When you run this command, you will note that the output is quite different from the
ansible-playbook command. Nonetheless, the files are faithfully copied to all specified
hosts in the inventory without you needing to write an entire playbook. The following
screenshot shows an example of the output from this command:
[ 453 ]
Tips and Tricks Chapter 16
What is doubly useful about these ad hoc commands is that not only is the file copied to all
hosts specified without writing an entire playbook, but that the output from the command
shows all of the return values from the module that you launched—copy, in this case. This
is incredibly useful in playbook and role development as you might want to register the
output of a particular task into a variable, and using an ad hoc command such as this shows
you what this variable would contain.
For example, say that you wanted to actually perform the preceding task in a role instead of
an ad hoc command, and register the results of this task in a variable called filecopy. The
main.yml file in the role tasks/ directory might look like this:
---
- name: Copy across new web server front page
copy:
src: "frontpage.html"
dest: "/var/www/html/frontpage.html"
register: filecopy
[ 454 ]
Tips and Tricks Chapter 16
We know from our ad hoc command that filecopy will be a dictionary containing several
useful items, including changed and size. Hence, we could easily perform some
conditional processing on these in a later task—for example, perhaps running another
related task with the following clause:
when: filecopy.changed == true
Of course, if you needed to just run a raw shell command, you could do that too using the
shell command—a simple example is shown as follows:
$ ansible webservers -i inventory -m shell -a "echo test > /tmp/test"
This, of course, is a contrived example, but it demonstrates to you how you could run an
identical shell command across all of the servers in an Ansible inventory with relative ease.
You can even inject variables into the module arguments using the format now familiar to
you from your role and playbook development, as in this example:
$ ansible webservers -i inventory -m shell -a "echo Hello from {{
inventory_hostname }} > /tmp/test && cat /tmp/test"
The output of this specific command should look something like the following
screenshot—see how the shell module returns the output from the command within the
Ansible output—this is incredibly powerful and would, for example, enable you to gather
information from all of the machines in an inventory with ease:
Hence, you could use Ansible ad hoc commands to perform a quick audit of your systems
or to check the value of a specific setting across a set of servers.
Another place where ad hoc commands are valuable is in testing Jinja2 expressions. We
have come across these a few times in the book, and when developing a playbook or role,
the last thing you want to do is run through an entire play, only to discover that one of your
Jinja2 expressions was wrong. Ad hoc commands enable you to easily and rapidly test
these on the command line.
[ 455 ]
Tips and Tricks Chapter 16
Say, for example, you want to develop a Jinja2 expression to put into a playbook that
returns the uppercase value of a variable called vmname if it is defined, and otherwise,
return the keyword all in lowercase. This would be useful in defining a host pattern for
use in a playbook workflow, for example. This is not a trivial Jinja2 expression, and so
rather than testing it within a playbook, let's figure it out on the command line. What we
would do is print the Jinja2 expression using a debug msg, and then set the vmname
variable using the -e flag. Hence, we might run this:
$ ansible localhost -m debug -a "msg={% if vmname is defined %}{{ vmname |
upper }}{% else %}all{% endif %}" -e vmname=test
$ ansible localhost -m debug -a "msg={% if vmname is defined %}{{ vmname |
upper }}{% else %}all{% endif %}"
The following screenshot shows this in action:
As you can see from the preceding screenshot, the commands produce the desired output
when vmname is set and undefined, and so we can copy this into our playbook or role and
proceed with confidence!
That concludes our chapter on tips and tricks—it is hoped that these final words will help
you with implementing a highly reliable and scalable Linux automation infrastructure
based upon Ansible in your enterprise.
[ 456 ]
Tips and Tricks Chapter 16
Summary
Effective automation in an enterprise setting goes beyond writing Ansible playbooks and
roles—it is all about maintaining single sources of truth so that you can always have
confidence in your automation processes. It is also about leveraging your chosen tool for as
many purposes as possible, including assisting you with playbook and role development,
and in helping you with one-off tasks that do not necessarily warrant a playbook (although
this is discouraged as it removes some of the auditing capability offered by playbook
development and effective use of AWX/Ansible Tower).
In this chapter, you learned how to make effective use of version control to maintain a
history of your Linux environment. You then gained hands-on experience in using dynamic
inventories for Ansible to prevent discrepancies in deployments and to ensure that both
your inventories and playbooks can be trusted. Finally, you learned how to handle one-off
tasks using Ansible and even assist your own playbook development.
That concludes our book on Linux automation in the enterprise—I hope that you have
found it valuable and that it will assist you on your own journey of effective automation in
a large scale setting.
Questions
1. What is Ansible Galaxy?
2. Why is it important to use version control for your playbooks and especially your
roles?
3. List two ways in which you can include role code from a separate Git repository
within your own Git project.
4. Why is it important to use dynamic inventories where possible?
5. What language(s) should you write your dynamic inventory scripts in if writing
your own?
6. Where would you find the documentation on requirements and configuration
examples for the dynamic inventory scripts shipped with Ansible?
7. What is an ad hoc Ansible command?
8. List two ways in which ad hoc commands can help you with playbook and role
development.
9. How can you run an arbitrary shell command across a group of Linux servers
using an Ansible ad hoc command?
[ 457 ]
Tips and Tricks Chapter 16
Further reading
To explore the effective use of Git for version control of your playbooks,
especially when it comes to branching and merging, please refer to Git Best
Practices Guide by Eric Pidoux (https:/​/​www.​packtpub.​com/​gb/​application-
development/​git-​best-​practices-​guide)
For an in-depth understanding of Ansible, please refer to Mastering Ansible, 3rd
Edition by James Freeman and Jesse Keating (https:/​/​www.​packtpub.​com/​gb/
virtualization-​and-​cloud/​mastering-​ansible-​third-​edition)
[ 458 ]
Assessments
Chapter 1 - Building a Standard Operating
Environment on Linux
1. Standard Operating Environment.
2. There are many reasons, but commonly enterprises will have Linux machines in
service for many years (often whether they originally planned to or not!). An
operation system falling out of support and not having security patches available
is a big problem for most enterprises, and so Linux distributions should be
chosen accordingly.
3. Yes, absolutely—the standards are there to serve as a guideline and to prevent
things from getting chaotic, but they are not intended to be so rigid that they
hamper progress or innovation.
4. Possible answers might include the following:
The speed at which new machines can be brought up for scaling
purposes
Confidence in those machines that they will work the same as the
current ones
The reliability of the machines brought into service
5. Possible answers might include the following:
High levels of confidence in the environment amongst all staff
members
Supports automation of tasks
Consistency reduces the possibility of an application working in one
environment and failing in another
6. As all the machines across the enterprise are the same (or at least broadly
similar), staff can manage a large environment with a relatively small amount of
knowledge, as all machines should be built the same way, to the same standards,
and all applications should be deployed in the same way.
7. SOEs ensure the consistency of machine builds, which will include security
hardening—the environment will also be built to known standards, which
should have redundant services disabled (reducing the attack surface) and a
well-understood patching strategy.
Assessments
Chapter 2 - Automating Your IT
Infrastructure with Ansible
1. Ansible is an open source automation platform used for running tasks across an
inventory of servers. It differs from a simple shell script in that it will (when
using native modules) only attempt to make changes when they are required
(hence resulting in a consistent state), and it offers native support for remote
connections to other machines (using SSH on Linux) and encryption of sensitive
data and makes use of highly readable, self-documenting code.
2. An Ansible inventory is simply a list of servers against which an Ansible
playbook is to be run.
3. Ansible has built-in features to make it easy to reuse roles—hence, a single role
might find application in several playbooks. Conversely, if the code is written in
a single large playbook, the only way to reuse the code in a different playbook is
to copy and paste, which is both cumbersome and difficult to keep track of
(especially when the code is changed in one place).
4. Jinja2.
5. Yes—Ansible has a strict and well-documented variable precedence order.
6. Employing templates will always result in a deployed file that looks the same on
all machines. Using search and replace can be tricky, and simple changes to the
target file on one machine can break the search pattern in all but the most
meticulously designed regular expressions.
7. Ansible facts can be used to tell Ansible useful information, such as which
operating system it is running on—hence, playbooks can be coded to perform
different actions on a CentOS and Ubuntu host (for example, using yum on
CentOS and apt on Ubuntu).
Chapter 3 - Streamlining Infrastructure
Management with AWX
1. AWX stores credentials in a manner that is not easily reversible, even to
administrators—as a result, it prevents those running automation tasks from
accessing secure credentials and making use of them in another context.
[ 460 ]
Assessments
2. If two people are working from a set of playbooks, how can you ensure they are
consistent? Equally, how can you ensure that you understand the changes that
have been made in your playbooks, especially when issues arise? Good version
control strategies address these and many more challenges.
3. AWX has all of the dynamic inventory scripts provided as part of the Ansible
project built in, along with all supporting libraries. They can be configured
through the AWX user interface, and so can be considered to work out of the box,
whereas additional work is required to use them on the command line.
4. A project is a logical grouping of playbooks—it might be a single directory on a
filesystem or a repository in a version control system such as Git.
5. A template is analogous to the ansible-playbook command, along with all its
switches and parameters, which you might run on the command line.
6. This is visible in the Job History pane for each job in the user interface—every
job has the Git commit hash stored along with other valuable information about
the task that was run.
7. The AWX server itself houses some very sensitive data, including the database,
which contains reversibly encrypted credentials. Also, it is possible to run
playbooks from a known path on the local filesystem of the AWX host and so, to
enforce version control usage, it is important that as few people as possible have
access to this server.
8. AWX has a built-in scheduler that can run playbooks at a time of your choosing
(either as a one-off or regularly).
Chapter 4 - Deployment Methodologies
1. A Docker container is built from code—commonly a Dockerfile—and as a
result, you can be confident of what a Docker container will look like when it is
built. An SOE is also built programmatically, and so all builds in the SOE should
look the same (perhaps allowing for minor differences when deploying on
different platforms).
2. The MariaDB service takes up disk space, which although seemingly small,
would waste a lot of storage if deployed hundreds of times. It also means you
need to ensure it is disabled when it is not needed, which is not a necessary check
if it is not installed at all.
3. Build the image off the most minimal set of packages possible. Don't include
anything that isn't needed across all (or at least 90% of) machines. Clean up the
image (for example, sysprep) before completing the build process.
[ 461 ]
Assessments
4. If a password gets compromised, you will have to change it across all deployed
machines as the password will be replicated from the original image. This may
require an audit to ensure all machines that were deployed with this password
are found and addressed.
5. Create the standard operating system image with a syslog file that includes the
correct parameters to send logging information to a centralized logging server.
Check and enforce this configuration regularly with Ansible.
6. If your requirements are highly specialized (perhaps a very specific set of
package versions is required for one of your applications), you might choose to
build your own. You would also do this if you had special security requirements,
or perhaps for some reason, you don't have confidence/trust in the publicly
available image.
7. Deploy the SSH configuration file with Ansible using a Jinja2 template to ensure
consistency across all machines.
Chapter 5 - Using Ansible to Build Virtual
Machine Templates for Deployment
1. Sysprep removes all redundant information from the image so it is clean when it
is deployed. This might include system logs, bash history files, SSH host
identification keys, MAC addresses in udev rules—anything that should not be
deployed a hundred times across the enterprise.
2. Whenever you need to know something about the underlying system—perhaps
the IP address, the operating system, or the disk geometry.
3. Ideally, create a Jinja2 template and deploy it with Ansible using the template
module.
4. get_url.
5. You would write two tasks, one that uses the apt module, and one that uses the
yum module. Each task should have a when clause and check the Ansible Facts to
ensure it runs the correct task on the corresponding operating system.
6. To ensure it was not corrupted when you downloaded it and to ensure it has not
been tampered with (for example, malicious software injected).
7. The roles can be reused to audit, validate, and enforce configuration across the
enterprise once the template has been deployed.
[ 462 ]
Assessments