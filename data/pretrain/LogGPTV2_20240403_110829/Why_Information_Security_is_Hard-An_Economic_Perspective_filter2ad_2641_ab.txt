[I]t is not because of the few thousand
francs which would have to be spent to put a
roof over the third-class carriage or to uphol-
ster the third-class seats that some company
or other has open carriages with wooden
benches .
. What the company is try-
ing to do is prevent the passengers who can
pay the second-class fare from traveling third
class; it hits the poor, not because it wants
to hurt them, but to frighten the rich .
.
. And it is again for the same reason that
the companies, having proved almost cruel to
the third-class passengers and mean to the
second-class ones, become lavish in dealing
with ﬁrst-class customers. Having refused
the poor what is necessary, they give the rich
what is superﬂuous. [10]
This is a also common business model in the soft-
ware and online services sectors. A basic program or
service may be available free; a much better one for a
subscription; and a ‘Gold’ service at a ridiculous price.
In many cases, the program is the same except that
some features are disabled for the budget user. Many
cryptographic and other technical protection mecha-
nisms have as their real function the maintenance of
this diﬀerential.
Another business strategy is to manipulate switch-
ing costs.
Incumbents try to increase the cost of
switching, whether by indirect methods such as con-
trolling marketing channels and building industries of
complementary suppliers, or, increasingly, by direct
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:04:10 UTC from IEEE Xplore.  Restrictions apply. 
methods such as making systems incompatible and
hard to reverse engineer. Meanwhile competitors try
to do the reverse: they look for ways to reuse the
base of complementary products and services, and to
reverse engineer whatever protection the incumbent
builds in. This extends to the control of complemen-
tary vendors, sometimes using technical mechanisms.
Sometime, security mechanisms have both product
diﬀerentiation and higher switching costs as goals. An
example which may become politicized is ‘accessory
control’. According to one company that sells au-
thentication chips into the automative market, some
printer companies have begun to embed cryptographic
authentication protocols in laser printers to ensure
that genuine toner cartridges are used. If a competi-
tor’s cartridge is loaded instead, the printer will qui-
etly downgrade from 1200 dpi to 300 dpi. In mobile
phones, much of the proﬁt is made on batteries, and
authentication can be used to spot competitors’ prod-
ucts so they can be drained more quickly [3].
Another example comes from Microsoft Passport.
This is a system whose ostensible purpose is single
signon: a Passport user doesn’t have to think up sep-
arate passwords for each participating web site, with
all the attendant hassle and risk. Instead, sites that
use Passport share a central authentication server run
by Microsoft to which users log on. They use web
redirection to connect their Passport-carrying visitors
to this server; authentication requests and responses
are passed back and forth by the user’s browser in
encrypted cookies. So far, so good.
But the real functions of Passport are somewhat
more subtle [18]. First, by patching itself into all the
web transactions of participating sites, Microsoft can
collect a huge amount of data about online shopping
habits and enable participants to swap it.
If every
site can exchange data with every other site, then the
value of the network to each participating web site
grows with the number of sites, and there is a strong
network externality. So one such network may come
to dominate, and Microsoft hopes to own it. Second,
the authentication protocols used between the mer-
chant servers and the Passport server are proprietary
variants of Kerberos, so the web server must use Mi-
crosoft software rather than Apache or Netscape (this
has supposedly been ‘ﬁxed’ with the latest release, but
participating sites still cannot use their own authen-
tication server, and so remain in various ways at Mi-
crosoft’s mercy).
So Passport isn’t so much a security product, as a
play for control of both the web server and purchasing
information markets. It comes bundled with services
such as Hotmail, is already used by 40 million people,
and does 400 authentications per second on average.
Its known ﬂaws include that Microsoft keeps all the
users’ credit card details, creating a huge target; var-
ious possible middleperson attacks; and that you can
be impersonated by someone who steals your cookie
ﬁle. (Passport has a ‘logout’ facility that’s supposed
to delete the cookies for a particular merchant, so you
can use a shared PC with less risk, but this feature
didn’t work properly for Netscape users when it was
ﬁrst deployed [13].)
The constant struggles to entrench or undermine
monopolies and to segment and control markets de-
termine many of the environmental conditions that
make the security engineer’s work harder. They make
it likely that, over time, government interference in
information security standards will be motivated by
broader competition issues, as well as by narrow is-
sues of the eﬀectiveness of infosec product markets
(and law enforcement access to data).
So much for commercial information security. But
what about the government sector? As information at-
tack and defense become ever more important tools of
national policy, what broader eﬀects might they have?
4 Information Warfare – Oﬀense and
Defense
One of the most important aspects of a new technol-
ogy package is whether it favours oﬀense or defense in
warfare. The balance has repeatedly swung back and
forth, with the machine gun giving an advantage to
the defense in World War 1, and the tank handing it
back to the oﬀense by World War 2.
The diﬃculties of developing secure systems using
a penetrate-and-patch methodology have been known
to the security community since at least the Anderson
report in the early 1970s [2]; however, a new insight
on this can be gained by using an essentially economic
argument, that enables us to deal with vulnerabilities
in a quantitative way [6].
To simplify matters, let us suppose a large, complex
product such as Windows 2000 has 1,000,000 bugs,
each with an MTBF of 1,000,000,000 hours. Suppose
that Paddy works for the Irish Republican Army, and
his job is to break into the British Army’s computer
to get the list of informers in Belfast; while Brian is
the army assurance guy whose job is to stop Paddy.
So he must learn of the bugs before Paddy does.
Paddy has a day job so he can only do 1000 hours
of testing a year. Brian has full Windows source code,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:04:10 UTC from IEEE Xplore.  Restrictions apply. 
dozens of PhDs, control of the commercial evalua-
tion labs, an inside track on CERT, an information
sharing deal with other UKUSA member states – and
he also runs the government’s scheme to send round
consultants to critical industries such as power and
telecomms to advise them how to protect their sys-
tems. Suppose that Brian beneﬁts from 10,000,000
hours a year worth of testing.
After a year, Paddy ﬁnds a bug, while Brian has
found 100,000. But the probability that Brian has
found Paddy’s bug is only 10%. After ten years he
will ﬁnd it – but by then Paddy will have found nine
more, and it’s unlikely that Brian will know of all of
them. Worse, Brian’s bug reports will have become
such a ﬁrehose that Microsoft will have killﬁled him.
In other words, Paddy has thermodynamics on his
side. Even a very moderately resourced attacker can
break anything that’s at all large and complex. There
is nothing that can be done to stop this, so long as
there are enough diﬀerent security vulnerabilities to
do statistics: diﬀerent testers ﬁnd diﬀerent bugs. (The
actual statistics are somewhat more complicated, in-
volving lots of exponential sums; keen readers can ﬁnd
the details at [6].)
There are various ways in which one might hope to
escape this statistical trap.
(cid:127) First, although it’s
reasonable to expect a
35,000,000 line program like Windows 2000 to
have 1,000,000 bugs, perhaps only 1% of them are
security-critical. This changes the game slightly,
but not much; Paddy now needs to recruit 100
volunteers to help him (or, more realistically,
swap information in a grey market with other sub-
versive elements). Still, the eﬀort required of the
attacker is still much less than that needed for
eﬀective defense.
(cid:127) Second, there may be a single ﬁx for a large num-
ber of the security critical bugs. For example,
if half of them are stack overﬂows, then perhaps
these can all be removed by a new compiler.
(cid:127) Third, you can make the security critical part of
the system small enough that the bugs can be
found. This was understood, in an empirical way,
by the early 1970s. However, the discussion in the
above section should have made clear that a mini-
mal TCB is unlikely to be available anytime soon,
as it would make applications harder to develop
and thus impair the platform vendors’ appeal to
developers.
So information warfare looks rather like air war-
fare looked in the 1920s and 1930s. Attack is sim-
ply easier than defense. Defending a modern infor-
mation system could also be likened to defending a
large, thinly-populated territory like the nineteenth
century Wild West: the men in black hats can strike
anywhere, while the men in white hats have to defend
everywhere. Another possible relevant analogy is the
use of piracy on the high seas as an instrument of state
policy by many European powers in the sixteenth and
seveteenth centuries. Until the great powers agreed to
deny pirates safe haven, piracy was just too easy.
The technical bias in favour of attack is made even
worse by asymmetric information. Suppose that you
head up a U.S. agency with an economic intelligence
mission, and a computer scientist working for you has
just discovered a beautiful new exploit on Windows
2000. If you report this to Microsoft, you will protect
250 million Americans; if you keep quiet, you will be
able to conduct operations against 400 million Euro-
peans and 100 million Japanese. What’s more, you
will get credit for operations you conduct successfully
against foreigners, while the odds are that any op-
erations that they conduct successfully against U.S.
targets will remain unknown to your superiors. This
further emphasizes the motive for attack rather than
defense. Finally – and this appears to be less widely
realized – the balance in favour of attack rather than
defense is still more pronounced in smaller countries.
They have proportionally fewer citizens to defend, and
more foreigners to attack.
In other words, the increasing politicization of in-
formation attack and defense may even be a destabi-
lizing factor in international aﬀairs.
5 Distinguishing Good from Bad
Since Auguste Kerckhoﬀs wrote his two seminal pa-
pers on security engineering in 1883 [12], people have
discussed the dangers of ‘security-by-obscurity’, that
is, relying on the attacker’s being ignorant of the de-
sign of a system. Economics can give us a fresh insight
into this. We have already seen that obscure designs
are often used deliberately as a means of entrenching
monopolies; but why is it that, even in relatively com-
petitive security product markets, the bad products
tend to drive out the good?
The theory of asymmetric information gives us an
explanation of one of the mechanisms. Consider a used
car market, on which there are 100 good cars (the
‘plums’), worth $3000 each, and 100 rather trouble-
some ones (the ‘lemons’), each of which is worth only
$1000. The vendors know which is which, but the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:04:10 UTC from IEEE Xplore.  Restrictions apply. 
buyers don’t. So what will be the equilibrium price of
used cars?
If customers start oﬀ believing that the probability
they will get a plum is equal to the probability they
will get a lemon, then the market price will start oﬀ
at $2000. However, at that price only lemons will be
oﬀered for sale, and once the buyers observe this, the
price will drop rapidly to $1000 with no plums being
sold at all. In other words, when buyers don’t have as
much information about the quality of the products
as sellers do, there will be severe downward pressure
on both price and quality. Infosec people frequently
complain about this in many markets for the prod-
ucts and components we use; the above insight, due
to Akerlof [1], explains why it happens.
The problem of bad products driving out good ones
can be made even worse when the people evaluat-