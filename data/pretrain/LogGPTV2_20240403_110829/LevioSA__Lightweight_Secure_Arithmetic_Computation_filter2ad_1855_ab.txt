ters, and providing an implementation with benchmarks. Indeed,
our outer protocol has a similar high-level structure to the one
implicit in Ligero [1]. However, the compilation from (information-
theoretic) MPC to 2PC is quite different from the one required for
zero-knowledge and requires a different analysis. In the case of
zero-knowledge, soundness (for NO instances) and privacy (for YES
instances) do not have to hold at the same time. When compiling
for 2PC, we need soundness and privacy to hold simultaneously.
This affects the concrete analysis as well as the proof of security.
Following the IPS compiler, we rely on two building blocks: (1)
an outer MPC protocol Π with 2 clients (providing the inputs) and
n servers (performing the computation) secure against an active
corruption of a minority of the servers and at most one client (cf.
Section 4.1), and (2) an inner 2PC protocol secure against passive
corruptions. In the compiled protocol, the desired arithmetic func-
tionality is realized by the outer protocol, and the inner protocol
is used to emulate the server’s computation in the outer protocol.
The two parties in the computation participate as clients in the
outer protocol and use the inner protocol to securely emulate the
computation and communication in the outer protocol. A major
technical part of our protocol involves designing and optimizing a
new outer protocol. For the inner protocol, we simply rely on the
classic [26] protocol.
Optimizing the outer MPC protocol (Section 4.1). In the IPS
compiler, the outer protocol begins with the clients distributing its
inputs via secret-sharing to the servers. The servers then compute
the desired the functionality on the shared inputs and deliver the
shares of the outputs back to the clients. In our optimized protocol,
we rely on “share packing” (a.k.a packed secret-sharing) due to
[19]. Packed secret sharing extends Shamir’s secret sharing and
allows sharing a block of w secrets within a single set of shares.
We will assume that the circuit is arranged in layers that contain
each all addition or all multiplication gates. In each phase of the
protocol, the gates in a layer of the circuit are computed. At the
beginning of each layer, the parties arrange (pack) the shared secrets
corresponding to the input wire values of that layer into “left”
and “right” blocks so that the left and right wire values of the
gates are aligned in their corresponding blocks. Next, the protocol
proceeds layer by layer. For layers comprising of only addition
gates, the shares corresponding to their input blocks can be locally
added by the servers. For multiplication gates, these shares can
be locally multiplied by the servers, which doubles the degree
size of the encoding polynomial. Therefore, a “degree reduction”
step must be performed after each multiplication. Furthermore, the
encoded values of every computation layer must be rearranged
between layers. In typical honest majority MPC protocols, degree
reduction and layer rearrangement with packed shares involve
pairwise communication between the servers using verifiable secret
sharing. We will instead have the servers send the shares (after
masking the secret) to the two clients and have them perform the
degree reduction / repacking. This reduces the communication from
quadratic to linear in the number of servers. Furthermore, this will
result in an outer protocol with no server-to-server communication
which significantly simplifies the watchlist mechanism.
The IPS compiler requires the outer protocol to be secure against
active corruptions. This means the servers need to make sure that
the degree reduction and repacking are done correctly in each layer,
and that the shares are valid. This is typically achieved through
verifiable secret sharing that is expensive. Note that it is sufficient
for the IPS compiler to rely on an outer protocol that is secure with
abort. To protect against active adversaries in the outer protocol,
we introduce three tests that need to be performed at the end before
the outputs are revealed. The first “degree test” (because the shares
lie on some k-degree polynomial) ensures that all the shares from
all the layers are valid secret shares. The second “permutation test”
Session 2C: Secure Computing ICCS ’19, November 11–15, 2019, London, United Kingdom329ensures that repacking in each step is performed correctly and
finally, the third “degree reduction test” ensures that the degree
reduction step was performed correctly. These tests and ensuing
analyses are inspired by analogous tests from the work of [1].
Next, applying the IPS compiler, we combine our outer protocol
with an inner protocol that is realized here by the passive GMW [26]
protocol. This combination, yielding protocol Φ, is carried out by
having the parties of the inner protocol emulate the corresponding
roles of the clients from Π as well as emulating the virtual servers.
As mentioned above, one of the simplifications of our outer proto-
col, which greatly improves its description, implies that the servers
do not need to communicate via private channels and only commu-
nicate with the clients. Consequently, ensuring correctness via the
watchlist mechanism is much simpler, where the goal of using this
mechanism is to enforce correctness by allowing each party Pi to
monitor the actions of the other party P1−i, making sure that P1−i
follows the instructions of the outer protocol Π.
Note that the overhead of the inner protocol is dominated by
the number of servers and the numbers of OLE calls, as these calls
require interaction. By carefully optimizing the number of servers,
we show that for sufficiently wide circuits, our protocol only re-
quires 4 amortized passively secure OLE calls per multiplication
gate.
Using imperfect OLE (Section 6). Another feature of our com-
piler is that it can tolerate an imperfect passive OLE, namely one
that has a non-negligible statistical privacy or correctness error.
This security feature can be turned into an efficiency advantage.
For example, imperfect OLE can be implemented more efficiently
by aggressively setting the parameters in existing LWE-based OLE
constructions.
Previous related privacy amplification results from the litera-
ture [16, 28, 45] relied on a so-called “statistical-to-perfect lemma”
to reduce a general leaky functionality to a simple one that leaks ev-
erything with small probability but otherwise leaks nothing. (This
is akin to the notion of covert security in secure computation.) This
simple kind of “zero-one” leakage is clearly tolerated by our com-
piler if the leakage probability is low. Unfortunately, the leakage
probability promised by the statistical-to-perfect lemma grows lin-
early with the domain size of the functionality. In particular, when
considering OLE protocols over large fields, the lemma can only
provide a meaningful security guarantee when the statistical error
is smaller than the inverse of the field size.
Towards better statistical error tolerance, we formulate a simple
leaky OLE functionality that allows the adversary to choose a subset
of field elements called an exclusion set. The functionality leaks to
the adversary one bit of information specifying whether the honest
party’s secret input belongs to this set. For this model, we are able to
prove that if the exclusion set is sufficiently small compared to the
field size, the imperfection is indeed tolerated by our compiler. To
this end, we extend the work of Benhamouda et al. [6] and establish
a new result on the leakage resilience of Shamir’s secret sharing
scheme in the exclusion set regime, where less than one bit is leaked
from each share. We conjecture that our analysis for the simplified
“exclusion set” model can be extended to general statistical leakage,
in the sense that an arbitrary ϵ-secure passive OLE is no worse (for
our compiler) than leaky OLE with exclusion set of fractional size
O(ϵ). Proving or refuting this conjecture is left as an interesting
question for future work.
Implementation. We implemented our main compiler and show-
case its strength by benchmarking the applications described next.
Our implementation relies on a recent lightweight passive OLE
implementation due to de Castro et al. [14, 32] that is based on
the LWE assumption. We implemented the authenticated triples
functionality and compared it with the recent work of Keller et al.
[36], which is considered the state-of-the-art. We then give bench-
marks for generating active OLE from passive OLE, as well as for
randomly generated circuits designed to showcase our end-to-end
performance. The final benchmark is a concrete use case that im-
plements a simple secure neural network inference problem.
1.3 Applications
The protocol we design can be adapted and optimized for several
use cases, which we present below.
Arithmetic 2PC with active security (Section 5.2). First, our
protocol can be efficiently instantiated to compute any functions
expressed as an arithmetic circuit. Given an arbitrary passive OLE
protocol, we provide two instantiations:
(1) For sufficiently “wide” circuits, our protocol can be used directly,
requiring only 4 passive OLE per multiplication gate in the com-
puted circuit (in an amortized sense), where the OLE are used in a
black-box way.
(2) To compute arbitrary circuits, our protocol can be used (and fur-
ther optimized) to realize the “authenticated triples” functionality
from [15] (whose circuit is itself wide). These triples can then be
“consumed” by the “online phase” of [15] to compute the original
circuit. This combined protocol requires an amortized 16 passive
OLE per multiplication gate.
Black-Box active OLE from passive OLE (Section 5.3). Our sec-
ond application is a concretely efficient protocol for achieving OLE
with active security from actively secure oblivious-transfer and
passively secure OLE in a black-box way where the computational
and communication overheads are roughly twice of the passive
OLE instantiation in the amortized setting.
Privacy-preserving secure neural network inference (Section
5.4). In a concrete use case, we consider a scenario where a party
PCL wishes to classify private data based on a private machine learn-
ing model trained by another party PML in an outsourced setting,
with an untrusted set of cloud nodes performing the computation.
More formally, we consider the two-server model in which a party
PML distributes its trained model via additive secret sharing to two
cloud nodes s1, s2. In the next classification phase, the servers ob-
tain a shared input from PCL and securely compute the result of the
classification algorithm. The security of the protocol is required
to hold against any active adversary that corrupts at most one
party and one server. This model (or similar variants) is popular for
outsourcing privacy-preserving machine learning computations
[43, 48]. Our work is the first to demonstrate a protocol for privacy-
preserving machine learning computation which achieves active
security.
Providing security against active adversaries in this setting presents
its own challenges beyond utilizing an active secure protocol for
the underlying functionality. In more details, party PML needs to be
Session 2C: Secure Computing ICCS ’19, November 11–15, 2019, London, United Kingdom330ensured that the servers use the “right” inputs and do not abuse the
valid input provided by PCL by adding to it a carefully chosen small
adversarial perturbation with the aim to change the prediction
[38, 57].2 These types of attacks can be devastating when correct-
ness of computation is crucial to the application, such as in medical
diagnosis and image classification for defense applications, and only
arise in the presence of active adversaries. To prevent them, we
must incorporate an authentication mechanism that will guarantee
that the classification was obtained on the “right” inputs. To ensure
this, we combine ideas originating from [13, 21] to obtain a proto-
col that guarantees that either the answer is correct or indicates
that one of the servers behaved maliciously. We demonstrate the
practicality of our implementation by implementing a CNN with 3
layers with quadratic activation function as described in [33].
Another challenge induced in such a scenario is the abuse on
PCL’s side, which may choose its input in some “bad format” that
may allow to infer information about the model. We note that
our protocol does not provide this type of input certification and
an additional mechanism must be provided. Furthermore, input
certification is a different task from input authentication. Where
the former is performed with respect to the input inserted by party
PCL, whereas the later is performed with respect to the clouds’
computations.
Recently, there has been extensive literature showcasing ma-
chine learning computation with passive security. For example, in
[48] the authors introduce SecureML, a system for several privacy
preserving machine learning training and classifications algorithms
in the two-server model that run 2PC for arithmetic computation. In
[43], the authors develop MiniONN, a framework for transforming
an existing neural network to an oblivious neural network which
protects the privacy of the model (held by a cloud) and the client’s in-
put in the predication phase. In [53], Riazi et al. present Chameleon,
a system that supports hybrid secure computation in the two-party
setting, which combines arithmetic computation over rings for lin-
ear operations and Yao’s garbled circuits [61] for the non-linear
computation. Chameleon provides training and classification for
deep and convolutional neural networks. Juvekar et al. [33] extends
this paradigm in GAZELLE for classifying private images using a
convolutional neural network, protecting the classification phase,
and using homomorphic encryption scheme for carrying out the
linear computation. Finally, in a recent work by Elsloo et al. [58]
the authors introduce SEALion, which is an improved framework
for privacy preserving machine learning based on homomorphic
encryption. In the setting with more than two parties, Wagh et al.
[59] introduced SecureNN, a tool for training and predication in
the three-party and four-party settings with honest majority. We
summarize some of the recent implementations in the two-party
setting in Table 1.
2 PRELIMINARIES
Basic notations. We denote a security parameter by κ. We say that
a function µ : N → N is negligible if for every positive polynomial
p(·) and all sufficiently large κ’s it holds that µ(κ) <
1
p(κ). We use
2We emphasize that relying on general secure two-party computation does not prevent
such an attack. Even if one of the servers is honest, the other server could perturb the
input supplied by PCL.
construction
security
level
Chameleon
passive
Gazelle
passive
mixed
mixed
SEALion
passive
arithmetic
LevioSA
active
arithmetic
model of
computation methodology
activation
function
non-linear
non-linear
& square
non-linear
square
GC+GMW
additive SS
FHE+GC
FHE
MPC
in-the-head
Table 1: Recent 2PC secure ML implementations.
the abbreviation PPT to denote probabilistic polynomial-time and
denote by [n] the set of elements {1, . . . , n} for some n ∈ N. We