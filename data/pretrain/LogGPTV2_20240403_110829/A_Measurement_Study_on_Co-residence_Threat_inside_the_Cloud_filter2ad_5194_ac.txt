300 to 400 instances, which will take 15 to 20 rounds
with each round launching 20 instances from one ac-
count. However, achieving co-residence with a particular
target does not cost more time than achieving a random
co-residence pair. The reason for this is simple: To get
a random pair, we need to check 400 candidate pairs in
each round, but to get a co-residence pair with a target,
we only need to check 20 candidates in one round.
It is also possible that an attacker is unable to achieve
co-residence with a certain target due to various rea-
sons, e.g., the target physical machine reaches full capac-
ity. During our study, we failed to achieve co-residence
with two targets, one is m1.medium type and the other
is m3.medium type. By failing to achieve co-residence
we mean that after trying with more than 1,000 probing
instances in two different days, we still cannot achieve
co-residence with these two targets.
Overall, it is still very feasible to achieve co-residence
in EC2 nowadays. However, an attacker needs to launch
hundreds of instances to reach that goal, which may in-
troduce considerable cost. In Section 4.4, we will com-
pare our results to previous studies, demonstrating that
achieving machine-level co-residence has become much
more difﬁcult than before, due to the change in cloud en-
vironments and VM placement policies.
4.3 Quantifying rack level co-residence
While covert channel and side channel attacks require
an attacker to obtain an instance located exactly on the
same physical machine with the victim, some malicious
activities only need coarse-grained co-residence. Xu et
al. [23] proposed a new attack called power attack. In
their threat model, the attacker attempts to signiﬁcantly
increase power consumption of multiple machines con-
nected by the same power facility simultaneously to trip
the circuit breaker (CB). Since these machines located
in the same rack are likely to be connected by the same
CB, in a power attack the attack instances are not re-
quired to be placed on a same physical machine. Instead
the attacker should place many instances within the same
rack as the victim, i.e., achieving as much rack-level co-
residence as possible. We performed measurement on
how much effort is required to place a certain number of
934  24th USENIX Security Symposium 
USENIX Association
6
Table 1: The number of co-residence pairs achieved by one round of
probing in 2008 [14].
Account A
Account B
Co-residence
Zone 1
Zone 2
Zone 3
1
10
20
1
10
20
1
10
20
20
20
20
20
20
20
20
20
20
1
5
7
0
3
8
1
2
8
instances under the same rack.
We ﬁrst use one account to launch 20 instances, and
then we check whether there are any instances in this
batch that are located within the same rack. If there are
no instances located in the same rack, we just randomly
pick an instance and set its hosting rack as the target rack.
Thanks to the Top of Rack(ToR) switch topology, verify-
ing whether two instances are in the same rack is simple.
Through a simple trace-routing, we can verify whether an
instance has the same ToR switch with our target rack.
This rack level co-residence can be further veriﬁed by
performing trace-route from the candidate instance to the
target instance. If the two instances are in the same rack,
there should be only one hop in the trace, i.e., they are
one hop away.
Figure 9 shows our measurement results.
It is clear
that an attacker can easily have multiple instances lo-
cated within the same rack. The information of ToR
switch helps the attacker quickly verify the rack-level
co-residence. Since the malicious attack based on the
rack-level co-residence is newly proposed [23], EC2 is
unlikely to take any action to suppress rack-level co-
residence.
4.4 Battle in VM placement
Table 1 lists the data from the original work on co-
residence [14]. We can see that it was extremely easy
to achieve co-residence in 2008. With two accounts each
launching 20 instances, there were 7 or 8 co-residence
pairs observed. In the 2012 work [19], the cost of achiev-
ing a co-residence instance pair is also brieﬂy reported: A
co-residence pair (micro) is achieved with 160 instances
booted.
As we can see, nowadays it is much more difﬁcult to
achieve co-residence than in 2008 and 2012. EC2 could
have adjusted its VM placement policies to suppress co-
residence.
4.4.1 A larger pool
The business of EC2 is scaling fast, and thus it is intuitive
that Amazon keeps deploying more servers into EC2.
The measurement in 2008 [14] shows that there were
three availability zones in the US east region. At present,
the availability zones are expanded to four. Such expan-
sion in availability zones also indicates that the business
scale of EC2 is growing rapidly.
The measurement in 2008 [14] also shows 78 unique
Domain0 IP addresses with 1785 m1.small instances,
which means it only observed 78 physical machines that
host m1.small service. Due to the evolution in EC2 man-
agement, we are no longer able to identify Dom0. How-
ever, we have identiﬁed at least 59 racks of servers that
host m1.small instances. This suggests that the number
of physical machines hosting m1.small instances is sig-
niﬁcantly larger than that in 2008. The enlarged pool pro-
vides EC2 with more ﬂexibility to place incoming VMs,
which is one of the reasons that it is now much more dif-
ﬁcult to achieve co-residence than before.
4.4.2 Time locality
Time locality can help to achieve co-residence. Time lo-
cality means if two accounts launch instances simultane-
ously, it is more likely that some of these instances with
time locality will be assigned to the same physical ma-
chine.
To verify whether such time locality exists in the cur-
rent EC2, we performed another measurement. We set
up four groups of experiments. In the ﬁrst group, the two
accounts always launch 20 VMs simultaneously. In the
second group, the second account launches 20 VMs 10
minutes after the ﬁrst account launches 20 VMs. In the
third group, the launching time of the second account is
one hour apart from that of the ﬁrst account. In the fourth
group, the second account launches VMs four hours af-
ter the ﬁrst account. All instances are t1.micro type. In
each group, the measurement terminates whenever a co-
residence pair is observed and the number of instances
required to achieve co-residence is recorded. All the ex-
periments are repeated 5 times and the average is noted.
Figure 10 illustrates the number of instances required
to achieve co-residence in each case. We can see that
the efforts required to achieve co-residence do not vary
signiﬁcantly with the change of instance launching in-
tervals. This implies that time locality seems to be very
weak in the current EC2, which increases co-residence
cost.
4.4.3 Dynamic assignment
In 2008, the IP addresses and instances in EC2 were as-
signed in a relatively static manner [14]. However, as we
have demonstrated before, there are considerable map-
ping changes in our measurement, which indicates that
the IP assignment has introduced a certain dynamism.
Meanwhile, in 2008, the instances were placed strictly
based on the instance type, i.e., one physical machine
can only host one type of instance [14]. In contrast, our
measurement results show that such an assumption may
not hold anymore. First, some small instances use in-
ternal IP addresses that were used by micro instances
USENIX Association  
24th USENIX Security Symposium  935
7
d
e
h
c
n
u
a
L
s
e
c
n
a
t
s
n
I
600
500
400
300
200
100
0
d
e
h
c
n
u
a
L
s
e
c
n
a
t
s
n
I
300
250
200
150
100
50
0
2
4
6
8
10
12
14
16
18
20
0 minute
10 minutes
1 hour
4 hours
Number of Instances in a Rack
Interval
Figure 9: Instances launched to place certain number of instances
within the same rack.
Figure 10: Effort to achieve co-residence with different time lo-
cality.
before. Second, during our measurement, by accident
we observed that one live small instance has very close
IP to a medium instance. We then attempted to build
a covert channel between them.
It turned out that the
covert channel did work, which veriﬁes that these two in-
stances with different types are indeed located on a same
physical machine. Following such an observation, in the
rest of our rest measurement we also kept checking co-
residence between different types of instances. Overall,
ﬁve pairs of different-type co-residence instances are ob-
served throughout our study. Our results indicate that in
certain cases current VM placement policies in EC2 can
mix different types of instances on one physical machine,
potentially to reduce fragmentation. Such a policy also
increases the difﬁculty of achieving co-residence.
5 The Impact of Network Management
upon Co-residence
As network management plays a critical role in data
center management, it has a signiﬁcant impact on co-
residence. On one hand, an attacker attempts to obtain
as much networking information inside the cloud as pos-
sible to ease the gaining process of co-residence. On the
other hand, the cloud vendors try to protect sensitive in-
formation while not degrading regular networking man-
agement and performance. In this section, we introduce
the adjustments made by EC2 in network management
during recent years to mitigate co-residence threat and
the effectiveness of these approaches.
5.1 Methodology
To study the adjustment made by EC2 in network man-
agement, we performed large scale trace-routing. First,
for the instances we booted, we performed “neighbor-
hood trace-routing” from our instances to their “neigh-
bors.” Here we deﬁne neighbors as all those instances
that share the /23 preﬁx of their private IP addresses with
our source instances. Such trace-routing can inform us of
the routing paths between an instance and other instances
in the same rack and neighboring racks.
We next performed trace-routing from several of our
instances (i.e., the instances we booted) to all the in-
stances in a target list. We use the live host list from our
scanning measurement (see Section 3.5 and Appendix A)
as the target list. Trace-routing from our instances to over
650,000 target instances takes more than 8 days, but it
can help us to understand network management in EC2
in a more comprehensive manner.
5.2 The evolution in routing conﬁguration
The routing information has been leveraged to perform
cloud cartography [14], which can further be used to
launch co-residence-based attacks. However, our trace-
routing results demonstrate that, as a response to cloud
cartography, EC2 has adjusted its routing conﬁgurations
to enhance security in the past few years. The adjust-
ments we found are listed as follows.
5.2.1 Hidden Domain0
EC2 uses XEN as the virtualization technique in the
cloud. According to the networking I/O mechanism of
XEN [6], all the network trafﬁc of guest VMs (instances)
should travel through the privileged instance: Domain-
0 (i.e, Dom0). Thus, Dom0 acts as the gateway of all
instances on the physical machine, and all instances on
this physical machine should have the same ﬁrst-hop in
their routing paths. Such Dom0 information provides an
attacker with a very efﬁcient probing technique: by sim-
ply checking the Dom0’s IP addresses of two instances,
one can know whether they are co-resident. Therefore,