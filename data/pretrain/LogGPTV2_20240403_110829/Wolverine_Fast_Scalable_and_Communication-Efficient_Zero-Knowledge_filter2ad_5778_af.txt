G
Theorem 4. If the LPN
k,n,t,p assumption holds, then Πp,r
UC-realizes F p,r
sVOLE
spsVOLE)-hybrid model.
A proof of the above can be found in Appendix E, where
sVOLE in the (F p,r
spsVOLE from the
sVOLE,F p,r
spsVOLE.
we also describe further optimizations for protocol Πp,r
sVOLE.
V. PERFORMANCE EVALUATION
In this section, we report on the performance of our sVOLE
protocol and our overall ZK protocol for both boolean and
arithmetic circuits. All our protocols were implemented in the
EMP toolkit [57], and we will release an open-source version
of our code. In all our experiments, we use two Amazon EC2
instances of type m5.4xlarge with 16 vCPUs and 64 GB
of RAM, using 5 threads. We artiﬁcially limit the network
bandwidth as indicated in each experiment. All implementa-
tions achieve the statistical security parameter ρ ≥ 40 and
computational security parameter κ = 128.
We focus here on the performance of protocol Πp,r
A. (Subﬁeld) Vector Oblivious Linear Evaluation
sVOLE over
large ﬁelds; speciﬁcally, we ﬁx the Mersenne prime p = 261−1
and set r = 1. (sVOLE is equivalent to VOLE in this case.)
Parameter selection. As suggested in prior work [13], [53],
[60], we choose the public LPN matrix A as a generator
of a 10-local linear code, which means that each column
of A contains exactly 10 (uniform) nonzero entries. This is
advantageous since it means that computing each entry of u·A
involves reading only 10 positions of u ∈ Fk
p. To ensure that
reading those positions can be done quickly, we set k so that
u ﬁts in the L1 CPU cache (i.e., the size of u is less than
8 MB). With k ﬁxed, for any choice of n > k we can take the
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:45 UTC from IEEE Xplore.  Restrictions apply. 
1083
One-time setup
Extend execution
k0
n0
t0
k
n
t
642,048
19,870
1,319
TABLE II: LPN parameters used in our VOLE protocol.
10,805,248
589,760
2,508
20 Mbps 50 Mbps 100 Mbps 500 Mbps 1 Gbps
Init. (ms)
Extend (ns/VOLE)
1343
101
640
87
478
85
451
85
438
85
TABLE III: Efﬁciency of our VOLE protocol as a function of
network bandwidth. The communication per VOLE correlation is
0.42 bits; the overall communication of the one-time setup is 1.1 MB.
smallest t for which all known attacks on the LPN problem
require at least 2128 operations [13], [14]. When we apply
the optimizations described at the end of the previous section
to our protocol, we see that using LPN parameters (n, k, t)
means that each invocation of the extend procedure results in
n−k−t−1 usable VOLE correlations. We perform exhaustive
search to ﬁnd the smallest n so that n − k − t − 1 ≥ 107. For
the parameters of the setup phase, we follow the same step as
above, except that we will ensure that n0 − k0 − t0 − 1 ≥ k.
This results in the LPN parameters shown in Table II.
Performance. We evaluate the efﬁciency of protocol Πp,r
sVOLE
in Table III. The extend procedure requires very little com-
munication (less than half a bit per usable VOLE correlation),
and its execution time is largely unaffected by the network
bandwidth above 100 Mbps. The one-time initialization only
communicates 1.1 MB and takes roughly 478 milliseconds
under a 100 Mbps network.
In Table IV, we compare our VOLE protocol with the
best known protocols that have been implemented [53], [27].
Since our protocol needs an one-time setup,
that can be
amortized over multiple executions, we report our performance
both without one-time setup (in case multiple extensions are
executed), and the one with one-time setup (in case only
one extension is executed). We ﬁx the network bandwidth
to 500 Mbps to match the experiments of Castro et al. [27].
Our protocol outperforms prior work even though prior work
is secure only against semi-honest adversaries, whereas our
protocol is secure in the malicious setting. Note in particular
that the communication complexity of our protocol is orders
of magnitude lower than prior work. Boyle et al. [14] also
proposed a maliciously secure sVOLE protocol but only im-
plemented their protocol for the special case p = 2, r = 128.
Based on their implementation in that case, we estimate that
[53]
[27]
Ours
(w/o setup)
Ours
(w/ setup)
Communication (bits)
Execution time (ns)
960
2000
160
400
0.42
85
1.32
130
TABLE IV: Our VOLE protocol vs. prior protocols. We ﬁx the
network bandwidth to 500 Mbps and report the marginal cost per
VOLE correlation. Running time for the protocol of Schoppmann et
al. [53] is the time for communication alone; numbers for the protocol
of Castro et al. [27] are taken from their paper and are based on the
same network and CPU conﬁguration but using 8 threads.
for our choice of p their protocol would communicate roughly
0.14 bits per sVOLE; however their computation is much
heavier than ours and would take time at least 900 ns per
VOLE correlation. Therefore, we believe that our protocol is
still more efﬁcient for most network bandwidth settings.
B. Zero-Knowledge Proofs
We report on the performance of our ZK protocol for
boolean and arithmetic circuits. In both cases, we use pipelin-
ing [43] to streamline the protocol execution. This signiﬁcantly
reduces the memory usage (from linear in the circuit size
to linear in the memory needed to evaluate the circuit non-
cryptographically) and allows us to scale to very large circuits.
To further reduce the memory usage for large circuits, we
changed the protocol so that rather than checking the correct-
ness of all C multiplication gates at the end, we check blocks
of C(cid:48)  2ρ. Setting c = B, we have
(cid:18) B
(cid:19)
B−1(cid:89)
(cid:18)C(cid:48)B + B
(cid:19)
B
· C
(cid:48) + 1
≥ C
(cid:48)B
,
B
=
i=0
B − i
and so we need C(cid:48) ≥ 2ρ/B. For the best efﬁciency, we set
B = 2 when possible. For batched opening of authenticated
values, we use the second approach described in Section II-A
along with the Fiat-Shamir heuristic to make it non-interactive.
We instantiate F p,r
sVOLE using Ferret [60] with p = 2 and r =
128.
Performance. The execution of our protocol can be split
into two stages: input processing, whose cost is proportional
to the witness length, and circuit processing, whose cost is
proportional
to the number of AND gates. Therefore, we
measure the scalability of our ZK protocol by increasing
either the witness length or the circuit size while artiﬁcially
keeping the other value ﬁxed. The experimental results in
Figure 9 show that the execution time is indeed linear in
both the witness length and the circuit size, with very small
marginal cost for each bit of the witness or each AND gate.
For example, under a 50 Mbps network, the marginal time of
our protocol is 3.35 µs per bit of the witness and 0.5 µs per
AND gate of the circuit.
The ZKGC approach [47], [42] is the only previous ap-
proach for efﬁcient ZK proofs that scales to large circuits
while using less than 10 GB of memory. The communication
complexity of our protocol is roughly 15× lower than the
ZKGC approach. For this reason, our protocol is particularly
well-suited for settings involving a low-bandwidth network.
Example 1: Merkle trees. As a representative example
highlighting the efﬁciency and scalability of our protocol,
we consider proving knowledge of the n = 2d leaves in
a complete Merkle tree of depth d using SHA-256 as the
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:45 UTC from IEEE Xplore.  Restrictions apply. 
1084
Fig. 9: Scalability of Wolverine for boolean circuits.
Fig. 10: Running time and memory usage of Wolverine when
proving knowledge of all leaves in a Merkle tree of a given depth.
internal hash function, where the root digest is known to both
parties. In Figure 10, we report on the running time and overall
memory usage of our protocol for d ranging from 6 to 19
(totaling 63–524,287 calls to SHA-256). Since the boolean
circuit for SHA-256 has 22,573 AND gates, the largest circuit
in these experiments contains more than 11 billion gates.
The overall memory consumption of our protocol is about
400 MB; this is dominated by the initial generation of 107
sVOLE correlations during the ofﬂine phase of the execu-
tion. During the online phase, the Merkle-tree computation
is implemented in a post-order, depth-ﬁrst fashion so that the
additional memory usage at any point corresponds only to
authenticated values for O(d) tree nodes (at most 150 KB).
Since this is dominated by the memory usage during the
online phase, the memory usage plotted in Figure 10 is nearly
constant even as d increases.
In Table I, we compare the performance of our protocol to
that of the state-of-the-art protocols for the same problem, in
a 200 Mbps network. (There, we report on the performance
of our protocol using only one thread.) We benchmarked all
prior work except for Ligero [1], for which we obtained
performance estimates from the authors. Spartan [54] uses
the R1CS representation, so we conservatively assume that
each SHA-256 hash requires 22,573 constraints. Virgo [63]
does not support free-XOR, and thus for each SHA-256 hash
it uses roughly 218 gates. (For this reason, the running time
of Virgo for the Merkle-tree example is close to its running
time for the matrix-multiplication example.) Compared to
the ZKGC approach, Wolverine achieves better running time
and about 15× lower communication, which means that it
will be up to 15× faster when running in a low-bandwidth
network. Compared to other protocols, we achieve at least a
5× improvement in execution time while using less memory.
Example 2: Proving existence of a bug in programs. We
also apply our system to prove the existence of a bug in one
out of a set of n program snippets in zero knowledge (in par-
ticular, without revealing which snippet contains the bug). This
Number of snippets
Stacked garbling (s)
Our protocol (s)
4
22
0.42
10 Mbps
50
22.1
5.2
200
22.2
20.8
100 Mbps
4
2.3
0.15
50
2.5
1.8
200
3.18
7.2
TABLE V: Wolverine vs. ZKGC with stacked garbling for
proving the existence of a bug in one of multiple code snippets.
DECO [62]
Blind CA [56]
Protocol
Execution time
Communication
DECO Wolverine
12.6 s
1.7 KB
0.28 s
184 KB
Blind CA Wolverine
71 s
85.1 MB
3.3 s
2.8 MB
TABLE VI: Using our protocol Wolverine in ZK-enabled appli-
cations. All benchmarks are based on a 10 Mbps network and reﬂect
the ZK component only.
problem was recently studied by Heath and Kolesnikov [42],
who showed how to adapt the ZKGC approach using a tech-
nique called stacked garbling so as to obtain communication
proportional to the size (cid:96) of the largest program snippet, rather
than the total size O(n · (cid:96)) of all programs snippets.
We performed experiments using the same programs as in
the work of Heath and Kolesnikov. These result in boolean
circuits whose sizes range from 70,869–90,772 AND gates
and whose largest input length is 112 bits. We show the
results in Table V. Wolverine does not use the stacked garbling
optimization,2 and so has communication complexity O(n· (cid:96)).
Nevertheless, for moderate values of n, Wolverine is still
noticeably faster than ZKGC with stacked garbling. The effect
is more pronounced in lower-bandwidth networks.
Example 3: Accelerating ZK-enabled applications. Here we
discuss the use of Wolverine in two recent applications that
rely on ZK proofs. Both applications require interaction any-
way, and so there is no real disadvantage to using an interactive
ZK proof in these cases. We describe the applications below,
and present the relevant benchmarking results in Table VI.