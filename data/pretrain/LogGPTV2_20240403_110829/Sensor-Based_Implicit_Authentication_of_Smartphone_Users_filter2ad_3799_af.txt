enables us to detect the context of the current user prior to
authenticating her. For the Random Forest algorithm, we use
10-fold cross-validation to get the results in Table V.
F. User Authentication Algorithms
1) Features: We now ask whether such simple, fast and
user-agnostic contexts (stationary versus moving) can signiﬁ-
cantly improve the accuracy of user authentication? If so, to
what extent? For this, we did different experiments, where the
users could use their smartphones and smartwatches as they
normally do in their daily lives, without any constraints on
the contexts under which they used their devices. Users were
invited to take our smartphone and smartwatch for one to two
weeks, and use them under free-form, real-use conditions.
We evaluate the accuracy of user authentication when
only the smartphone’s sensor features from the accelerometer
and gyroscope were used, and when both the smartphone
and smartwatch’s sensor features were used. The former had
feature vectors with 7 × 2 = 14 elements, while the latter had
feature vectors with 7 × 2 × 2 = 28 elements.
2) Kernel Ridge Regression algorithm: Here we tried diffe-
rent machine learning algorithms, and found the Kernel Ridge
Regression (KRR) machine learning algorithm to give the
best results. Table VI shows user authentication results for a
sample of state-of-the-art machine learning techniques: KRR,
Support Vector Machines (SVM), linear regression, and naive
Bayes. We see that KRR achieves the best accuracy. SVM
also achieves high accuracy but the computational complexity
is much higher than KRR (shown in Section V-H). Linear
regression and naive Bayes have signiﬁcantly lower accuracy
compared to KRR and SVM.
316
(cid:3)
(cid:20)(cid:19)(cid:19)
(cid:3)
TABLE VII.
THE FRR,FAR AND ACCURACY UNDER TWO CONTEXTS
WITH DIFFERENT DEVICES.
(cid:12)
(cid:8)
(cid:11)
(cid:3)
(cid:92)
(cid:70)
(cid:68)
(cid:85)
(cid:88)
(cid:70)
(cid:70)
(cid:36)
(cid:20)(cid:19)(cid:19)
(cid:28)(cid:24)
(cid:28)(cid:19)
(cid:27)(cid:24)
(cid:27)(cid:19)
(cid:26)(cid:24)
(cid:3)
(cid:19)
(cid:21)(cid:19)(cid:19)
(cid:12)
(cid:8)
(cid:11)
(cid:3)
(cid:92)
(cid:70)
(cid:68)
(cid:85)
(cid:88)
(cid:70)
(cid:70)
(cid:36)
(cid:28)(cid:24)
(cid:28)(cid:19)
(cid:27)(cid:24)
(cid:27)(cid:19)
(cid:26)(cid:24)
(cid:3)
(cid:19)
(cid:21)(cid:19)(cid:19)
(cid:38)(cid:82)(cid:80)(cid:69)(cid:76)(cid:81)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:54)(cid:80)(cid:68)(cid:85)(cid:87)(cid:83)(cid:75)(cid:82)(cid:81)(cid:72)
(cid:54)(cid:80)(cid:68)(cid:85)(cid:87)(cid:90)(cid:68)(cid:87)(cid:70)(cid:75)
(cid:20)(cid:19)(cid:19)(cid:19)
(cid:20)(cid:21)(cid:19)(cid:19)
(cid:23)(cid:19)(cid:19)
(cid:25)(cid:19)(cid:19)
(cid:39)(cid:68)(cid:87)(cid:68)(cid:3)(cid:54)(cid:76)(cid:93)(cid:72)(cid:3)(cid:11)(cid:86)(cid:72)(cid:70)(cid:82)(cid:81)(cid:71)(cid:86)(cid:12)
(cid:27)(cid:19)(cid:19)
(cid:38)(cid:82)(cid:80)(cid:69)(cid:76)(cid:81)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:54)(cid:80)(cid:68)(cid:85)(cid:87)(cid:83)(cid:75)(cid:82)(cid:81)(cid:72)
(cid:54)(cid:80)(cid:68)(cid:85)(cid:87)(cid:90)(cid:68)(cid:87)(cid:70)(cid:75)
(cid:20)(cid:19)(cid:19)(cid:19)
(cid:20)(cid:21)(cid:19)(cid:19)
Context
w/o context
w/ context
Device
Smartphone
Combination
Smartphone
Combination
FRR
FAR
15.4% 17.4%
9.3%
7.3%
8.3%
5.1%
0.9%
2.8%
Accuracy
83.6%
91.7%
93.3%
98.1%
(cid:23)(cid:19)(cid:19)
(cid:25)(cid:19)(cid:19)
(cid:39)(cid:68)(cid:87)(cid:68)(cid:3)(cid:54)(cid:76)(cid:93)(cid:72)(cid:3)(cid:11)(cid:86)(cid:72)(cid:70)(cid:82)(cid:81)(cid:71)(cid:86)(cid:12)
(cid:27)(cid:19)(cid:19)
(a) Stationary
(b) Moving
Fig. 5. Accuracy with different data sizes under the two contexts. We observe
that the best accuracy happens when the data size is around 800. The accuracy
decreases after the training set size is larger than 800 because a large training
data set is likely to cause over-ﬁtting in the machine learning algorithms.
Kernel ridge regressions (KRR) have been widely used for
classiﬁcation analysis [30], [42], [43], [44]. The advantage of
KRR is that the computational complexity is much less than
other machine learning methods, e.g., SVM. The goal of KRR
is to learn a model that assigns the correct label to an unseen
testing sample. This can be thought of as learning a function
f : X → Y which maps each data x to a label y. The optimal
classiﬁer can be obtained analytically according to
w∗
= argminw∈Rd ρ(cid:3)w(cid:3)2
+
N(cid:3)
(wT xk − yk)
2
(5)
k=1
k
where N is the data size and xM×1
represents the transpose
of Authenticate(k), the authentication feature vector, and M
is the dimension of the authentication feature vector. Let X
denote a M × N training data matrix X = [x1, x2,··· , xN ].
Let y = [y1, y2,··· , yN ]. (cid:2)φ(xi) denotes the kernel function,
which maps the original data xi into a higher-dimensional (J)
space. In addition, we deﬁne Φ = [(cid:2)φ(x1)(cid:2)φ(x2)··· (cid:2)φ(xN )]
and K = ΦT Φ. This objective function in Eq. 5 has an
analytic optimal solution [30] where
w∗
= Φ[K + ρIN ]
−1y
(6)
By utilizing certain matrix transformation properties, the com-
putational complexity for computing the optimal w∗ in Eq. 6
can be largely reduced from O(N 2.373) to O(M 2.373), which
we will carefully discuss in Section V-H. This is a huge
reduction since N=800 data points in our experiments, and
M = 28 features in our authentication feature vector.
3) System Parameters: We need to decide on two important
parameters in the system, the window size and the size of the
dataset. We empirically derive the “optimal” values for these
parameters.
Window Size.
The window size is an important system parameter, which
determines the time that our system needs to perform an au-
thentication, i.e., window size directly determines our system’s
authentication frequency.
For each context, we vary the window size from 1 second
to 16 seconds. Given a window size and a detected context, for
each target user, we utilize 10-fold cross-validation for training
and testing. Here, we utilize the false reject rate (FRR) and
false accept rate (FAR) as metrics to evaluate the authentication
accuracy of our system. FRR is the fraction of the legitimate
user’s data that are misclassiﬁed as other users’ data. FAR
is the fraction of other users’ data that are misclassiﬁed as
317
the legitimate user’s. For security protection, a large FAR is
more harmful than a large FRR. However, a large FRR would
degrade the usage convenience. Therefore, we investigate the
inﬂuence of the window size on FRR and FAR, in choosing a
proper window size.
Figure 4 shows that the FRR and FAR for each context
become stable when the window size is greater than 6 seconds.
The smartphone has better (lower) FRR and FAR than the
smartwatch. The combination of the smartphone and smart-
watch has the lowest FRR and FAR, and achieves the best
authentication performance than using each alone.
Data Size.
Another important system parameter is the size of the
data set, which also affects the overall authentication accuracy
because a larger training data set provides the system more
information. According to our observations above, we set
the window size as 6 seconds. We ranged the training set
sizes, from 100 to 1200 and show the experimental results
in Figure 5. We see that as the training set size increases,
the accuracy ﬁrst increases, approaching a maximum accuracy
point, and then decreases. The maximum accuracy happens
when the data size is around 800. The accuracy decreases after
the training set size is larger than 800 because a large training
data set is likely to cause over-ﬁtting in the machine learning
algorithms so that the constructed training model would in-
troduce more errors than expected. Comparing the three lines
in each ﬁgure, we also ﬁnd that using more devices provides
extra information that improves authentication accuracy.
4) User Authentication Evaluation with KRR: We now
show the overall authentication performance of our system in
Table VII by setting the window size as 6 seconds and the
data size as 800 (from Section V-F3 results).
From Table VII, we have the following interesting observa-
tions: (1) SmarterYou works well with just the smartphone,
even without contexts: by using only the smartphone without
considering any context, our system can achieve authentication
accuracy up to 83.6%. (2) Auxiliary devices are helpful: by
combining sensor data from the smartwatch with the smartp-
hone sensor data, the authentication performance increases
signiﬁcantly over that of the smartphone alone, reaching 91.7%
accuracy, with better FRR and FAR. (3) Context detection is
beneﬁcial for authentication: the authentication accuracy is
further improved, when we take the ﬁner-grained context dif-
ferences into consideration, reaching 93.3% accuracy with the
smartphone alone, and 98.1% accuracy with the combination
of smartphone and smartwatch data.
the overall
time for implementing
context detection followed by user authentication is less than
21 milliseconds. This is a fast user authentication testing time,
with excellent authentication accuracy of 98%, making our
system efﬁcient and applicable in real world scenarios.
We also found that
G. Masquerading attacks
Our third set of experiments was designed to analyze our
system’s performance in defending against some real world
attacks (e.g., masquerading or mimicry attacks). We consider
the worst case situation where we assume the attacker is
able to monitor and record the victim’s behavior. Thus the
attacker can try his best to learn the victim’s behavior. In
these experiments, we asked each subject to be a malicious
adversary whose goal was to mimic the victim user’s behavior
to the best of his/her ability. One user’s data was recorded and
his/her model was built as the legitimate user. The other users
tried to mimic the legitimate user and cheat the system to let
them be authenticated as the victim user. The victim user was
recorded by a VCR. Subjects were asked to watch the video
and mimic the behavior. Both the adversary and the legitimate
user performed the same tasks, and the user’s behavior is
clearly visible to the adversary. Such an attack is repeated 20
times for each legitimate user and his/her ‘adversaries’.
Recall that the goal of an attacker is to get access to
the sensitive information stored in the smartphone, or in the
cloud accessed through the smartphone. As we have shown in
Figure 4 and Table VII, SmarterYou achieves very low FARs
when attackers attempt to use the smartphone with their own
behavioral patterns.
Now, we show that SmarterYou is even secure against the
masquerading attacks where an adversary tries to mimic the
user’s behavior. Here, ‘secure’ means that the attacker cannot
cheat the system via performing these spooﬁng attacks and the
system should detect these attacks in a short time. To evaluate
this, we design a masquerading attack where the adversary
not only knows the password but also observes and mimics
the user’s behavioral patterns. If the adversary succeeds in
mimicking the user’s behavioral pattern, then SmarterYou will
misidentify the adversary as the legitimate user and he/she can
thus use the victim user’s smartphone.
In order to show the ability of SmarterYou to defend against
these mimicry attacks, we counted the percentage of people
(attackers) who were still using the smartphone without being
de-authenticated by the system as the attack time progresses.
Figure 6 shows the fraction of adversaries that are recognized
as legitimate users by SmarterYou at time t, from which we
can see how quickly SmarterYou can recognize an adversary
and terminate his access to the smartphone. At t = 0, all the
adversaries have access to the smartphone, but within 6s, only
10% of adversaries have access. That is, SmarterYou identiﬁed
on average 90% of adversaries as unauthorized users within
6s. By t = 18s, SmarterYou identiﬁed all the adversaries.
Therefore, SmarterYou performed well
in recognizing the
adversary who is launching the masquerading attack.
These experimental results also match with analysis from
a theoretical point of view. We assume the FAR in each time
window is p, then the chance that the attacker can escape from
detection in n time windows is pn. Based on our experimental
results in Section V-F, our system can achieve 2.8% FAR
in a time window of 6 seconds. Thus, within only three
windows, the probability for the attacker escaping detection
is (2.8%)3 = 0.002%, which is very small. Therefore, our
SmarterYou system shows good performance in defending
against masquerading attacks.
(cid:20)
(cid:19)(cid:17)(cid:27)
(cid:19)(cid:17)(cid:25)
(cid:19)(cid:17)(cid:23)
(cid:19)(cid:17)(cid:21)
(cid:86)
(cid:72)
(cid:76)
(cid:85)
(cid:68)
(cid:86)
(cid:85)
(cid:72)
(cid:89)
(cid:71)
(cid:36)
(cid:3)
(cid:3)
(cid:73)
(cid:82)
(cid:81)
(cid:82)
(cid:76)
(cid:87)
(cid:70)
(cid:68)
(cid:85)
(cid:41)
(cid:19)
(cid:19)
(cid:20)(cid:19)
(cid:21)(cid:19)
(cid:22)(cid:19)
(cid:55)(cid:76)(cid:80)(cid:72)(cid:3)(cid:11)(cid:86)(cid:72)(cid:70)(cid:82)(cid:81)(cid:71)(cid:86)(cid:12)
(cid:23)(cid:19)
(cid:24)(cid:19)
(cid:25)(cid:19)
Fig. 6.
smartphone at time t.
Fraction of adversaries that have access to the legitimate user’s
(cid:38)(cid:79)(cid:68)(cid:86)(cid:86)(cid:76)(cid:73)(cid:76)(cid:72)(cid:85)
(cid:47)(cid:72)(cid:74)(cid:76)(cid:87)(cid:76)(cid:80)(cid:68)(cid:87)(cid:72)(cid:3)(cid:88)(cid:86)(cid:72)(cid:85)
(cid:38)(cid:54) (cid:78) (cid:32) (cid:91) (cid:90)
(cid:55)
(cid:78)
(cid:11)
(cid:12)
(cid:38) (cid:54)(cid:72)
(cid:36)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)(cid:72)(cid:85)
(cid:13)
(cid:72)
(cid:85)