title:PhishTime: Continuous Longitudinal Measurement of the Effectiveness
of Anti-phishing Blacklists
author:Adam Oest and
Yeganeh Safaei and
Penghui Zhang and
Brad Wardman and
Kevin Tyers and
Yan Shoshitaishvili and
Adam Doup&apos;e
PhishTime: Continuous Longitudinal Measurement 
of the Effectiveness of Anti-phishing Blacklists
Adam Oest, Yeganeh Safaei, and Penghui Zhang, Arizona State University; 
Brad Wardman and Kevin Tyers, PayPal; Yan Shoshitaishvili and Adam Doupé, 
Arizona State University; Gail-Joon Ahn, Arizona State University, Samsung Research
https://www.usenix.org/conference/usenixsecurity20/presentation/oest-phishtime
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Continuous Longitudinal Measurement of the E(cid:29)ectiveness of Anti-phishing Blacklists
PhishTime:
Brad Wardman†, Kevin Tyers†, Yan Shoshitaishvili*, Adam Doupé*, Gail-Joon Ahn*,§
Adam Oest*, Yeganeh Safaei*, Penghui Zhang*
*Arizona State University, †PayPal, Inc., §Samsung Research
*{aoest, ysafaeis, pzhang57,yans, doupe, gahn}@asu.edu, †{bwardman, ktyers}@paypal.com
Abstract
Due to their ubiquity in modern web browsers, anti-
phishing blacklists are a key defense against large-scale
phishing attacks. However, sophistication in phishing
websites—such as evasion techniques that seek to defeat
these blacklists—continues to grow. Yet, the e(cid:29)ectiveness of
blacklists against evasive websites is di(cid:28)cult to measure, and
there have been no methodical e(cid:29)orts to make and track such
measurements, at the ecosystem level, over time.
We propose a framework for continuously identifying un-
mitigated phishing websites in the wild, replicating key as-
pectsoftheircon(cid:27)gurationinacontrolledsetting,andgenerat-
ing longitudinal experiments to measure the ecosystem’s pro-
tection. In six experiment deployments over nine months, we
systematicallylaunchandreport2,862new(innocuous)phish-
ing websites to evaluate the performance (speed and coverage)
and consistency of blacklists,with the goal of improving them.
We show that methodical long-term empirical measure-
ments are an e(cid:29)ective strategy for proactively detecting weak-
nesses in the anti-phishing ecosystem. Through our exper-
iments, we identify and disclose several such weaknesses,
including a class of behavior-based JavaScript evasion that
blacklists were unable to detect. We (cid:27)nd that enhanced protec-
tions on mobile devices and the expansion of evidence-based
reporting protocols are critical ecosystem improvements that
could better protect users against modern phishing attacks,
which routinely seek to evade detection infrastructure.
1 Introduction
Phishing attacks represent a signi(cid:27)cant threat to millions
of Internet users [62]. Beyond stealing victims’ account
credentials, modern phishing websites have evolved to
collect extensive (cid:27)nancial and personal information to fuel
identify theft, fraud, and other cybercrime [29, 57]. Simul-
taneously, phishing in(cid:30)icts collateral damage by harming the
reputation of impersonated brands, compromising legitimate
infrastructure, and necessitating e(cid:29)ort to mitigate abuse [45].
The anti-phishing ecosystem has long been involved in
a cat-and-mouse game with attackers (phishers). Despite the
ecosystem’s evolving defenses, the volume of phishing web-
siteshascontinuedtogrowovertimeandhasrecentlyreached
record-high levels [2,25]. Phishing remains popular among
criminals due to its scalability and low barrier to entry—even
for sophisticated and highly evasive attacks—thanks to the
support of illicit underground services [9,28].
Robust yet scalable ecosystem-level defenses are thus
needed to protect users from the modern barrage of phishing.
Anti-phishing blacklists, which alert users whenever they
try to visit a known malicious website, and are enabled by
default in major desktop and mobile web browsers, are a key
defense [52]. Blacklists are supportedby extensive backendin-
frastructure that seeks to detect and mitigate phishing attacks.
Despite the importance of blacklists, and even attention
from security researchers [44,50,52,63], there have been no
systematic, long-term, real-world studies of the anti-phishing
blacklist ecosystem. Evasive phishing attacks that attempt to
circumvent blacklists are not only becoming more common,
but have recently been shown to be responsible for the
majority of real-world impact due to large-scale phishing [46].
Thus, the blacklisting of such attacks warrants close scrutiny.
In this paper, we propose PhishTime: a framework for
continuously identifying sophisticated phishing attacks in
the wild and continuously monitoring—in an empirical, con-
trolled manner—the response of the anti-phishing ecosystem
to blacklist evasion techniques, with the goal of automatically
identifying gaps within the ecosystem. PhishTime can thus be
used to ensure that the ecosystem—or speci(cid:27)c entities within
it—deliver a consistent degree of protection to users. In the
(cid:27)rst longitudinal study of its kind, we deploy the framework
over the course of one year to measure the performance of
three blacklists—Google Safe Browsing, Microsoft SmartScreen,
and Opera—across majordesktop and mobile browsers (which
collectively have an overwhelming global market share [8]).
PhishTime operates in two stages: (cid:27)rst, it collects phishing
URL reports in real time and monitors the blacklisting status
of live phishing websites (run by actual criminals). Criminal
phishing websites that evade prompt blacklisting are manu-
ally analyzed for insight into evasion techniques successful
against blacklists. Second, PhishTime leverages these insights
to generate experiments that deploy large batches of arti(cid:27)-
cial (realistic, yet innocuous) phishing websites with evasion
techniques representative of those observed in the criminal
USENIX Association
29th USENIX Security Symposium    379
websites. Then, PhishTime adapts and enhances a previously
proposed,automatedtestbed[44]tohostthearti(cid:27)cialphishing
websites, report them to blacklists, and measure the blacklists’
response (while implementing numerous controls to min-
imize confounding factors). Unlike prior empirical studies,
PhishTime’sexperimentalmethodologyuniquelyenablesitto
evaluate and contextualize the response time of blacklists [44].
Our experiments involved the deployment, reporting (to
blacklists), and monitoring of 2,862 new, previously unseen,
arti(cid:27)cial, evasive PayPal-branded phishing websites over
a period of nine months. This yielded several interesting
(cid:27)ndings, which we promptly disclosed to the a(cid:29)ected entities.
1. Blacklists exhibited an average response time of as little
as 55 minutes against unsophisticated phishing websites,
but phishing websites with evasion commonly used in
the wild—even trivial techniques such as redirection via
URL shorteners—delayed blacklisting up to an average
of 2 hours and 58 minutes1, and were up to 19% less
likely to be detected. We also found that blacklists
allow phishers to reuse domains for multiple attacks:
with evasion, phishing websites reusing domains were
still blacklisted up to 1 hour and 20 minutes slower
than unevasive ones. Moreover, certain sophisticated
JavaScript evasion could entirely avoid blacklisting.
2. PhishTime’s continuous measurements enabled us
to identify emerging issues over time. We detected
a decrease in blacklisting seemingly due to a failure
in PayPal’s crawler-based phishing detection system
(this (cid:27)nding led directly to remediation of this issue
by PayPal). We also found a regression in the blocking
of malicious redirections by bit.ly (but, unfortunately,
received no response from that company). Lastly, mobile
Chrome,Safari,and Opera consistently exhibited a lesser
degree of blacklisting than their desktop counterparts.
3. New evidence-based phishing reporting protocols (i.e.,
that allow the submission of evidence such as a screen-
shot [11]) can expedite the blacklisting of evasive phish-
ing websites. We perform the (cid:27)rst comparison of such a
protocol alongside traditional URL-only reporting [24].
To help identify other ecosystem gaps by continuously eval-
uating attack con(cid:27)gurations beyond those considered in our
experiments, we are collaborating with the Anti-Phishing
Working Group (APWG) to integrate PhishTime as a perma-
nentecosystem service. Ourcontributionsarethusasfollows:
• A framework for the continuous long-term empirical
measurement of the anti-phishing ecosystem.
• Deployment of the framework for a longitudinal
evaluation of the performance of browser blacklists,
with a focus on evasive phishing.
• Identi(cid:27)cation, disclosure, and remediation of several
ecosystem vulnerabilities exploitable by phishers.
1Even such a seemingly short delay can cause up to 20% more victims [46].
2 Background
Phishing is a type of social engineering attack [32] through
which attackers (known as phishers) seek to trick victims into
disclosing sensitive information [15]. This stolen information
allows phishers to compromise user accounts and identities,
whichisasigni(cid:27)cantthreatbothtothevictimsandthesecurity
of online services [9,19]. Within the current ecosystem, there
existtwomaincategoriesofphishing: spearphishing,whichen-
tailsaconcentratede(cid:29)orttotrickspeci(cid:27)chigh-valuegroupsor
individuals [27],and large-scale phishing,whichtargets a wide
range ofpossible victims andallows phishers to pro(cid:27)tthrough
volume [52]. We primarily focus on the latter in this work.
2.1 Phishing Attacks
In a typical phishing attack, phishers (cid:27)rst con(cid:27)gure and
deploy a deceptive phishing website to mimic the appearance
of a legitimate website (e.g., of a bank or e-mail provider)
that is likely to appear familiar to potential victims. Phishers
then start distributing messages to their victims (e.g., via
e-mail or SMS spam campaigns) to lure them to the phishing
website [10, 28]. Such messages will often contain a call to
action that suggests a degree of urgency (e.g., correcting a
billing error or securing an account) [61]. Victims who are
successfully lured will then visit the phishing website and
follow its prompts, which may ask for account credentials,
(cid:27)nancial information, or biographical data. Finally, the data
harvested by the phishing website is ex(cid:27)ltrated back to the
phishers and can then be used to commit fraud [57].
Phishing attacks have a low barrier to entry and are easy
to scale due to the existence of myriad illicit services in
underground communities. To deploy phishing websites,
many attackers purchase or obtain phishing kits, which are
all-in-one packages with all the necessary software to create
a phishing website [6,13]. Additional services allow phishers
to orchestrate attacks with minimal e(cid:29)ort [54,55,58].
Although phishing kits vary in quality, the recent growth
in phishing volume—which coincides with a decline in
malware and drive-by-downloads—has been accompanied by
a general increase in sophistication [2,18,62]. For example,
advanced kits venture beyond stealing account credentials
and may ask their victims to provide detailed (cid:27)nancial and
personal information [46]. Additionally, such kits incorporate
features to evade detection by automated anti-phishing
systems [44] and may even attempt to intercept two-factor
authentication in real time [60]. The threat that phishing
poses to victims, organizations, and Internet infrastructure
has given rise to an anti-phishing ecosystem that has matured
over time—in response to the evolution of phishing—to
provide multiple layers of defense [45].
2.2 Anti-phishing Blacklists
Browser blacklists are a key anti-phishing defense that
protects users transparently and is enabled by default in
most major web browsers across both desktop and mobile
380    29th USENIX Security Symposium
USENIX Association
devices [44]. Thus, blacklists are capable of protecting users
on the same scale at which phishing occurs.
When a user attempts to visit a phishing website whose
URL is known to the browser’s blacklist, the browser will
display a prominent warning in place of the phishing con-
tent [52]. Moreover, blacklists can be integrated with e-mail
spam (cid:27)lters to outright prevent users from being exposed to
e-mails withthe same malicious URL. Blacklists are supported
by extensive backend infrastructure that collects suspected
phishing URLs and veri(cid:27)es malicious content prior to adding
them to the blacklist (to avoid false positives). Some blacklists
are also supplemented by in-browser heuristic classi(cid:27)ers [35].
Evasion Techniques. A notable weakness of blacklists
is that they are inherently reactive. Phishers capitalize on
the time gap between a phishing website’s deployment
and its subsequent blacklisting, and may increase their
return-on-investment (ROI) by prolonging this gap [26,41].
Because blacklist detection relies on content veri(cid:27)cation,
blacklists are vulnerable to evasion techniques which, when
successful, may delay or entirely prevent blacklisting [44].
In Section 6, we describe our approach to testing evasion
techniques commonly used in the wild.
Cloaking is an evasion technique that seeks to hide phish-
ing content from blacklist infrastructure (i.e., web crawlers)
while keeping it visible to human victims [30]. When a
phishing website with cloaking suspects that a request is from
a crawler, it will replace the phishing content with a benign-
looking page or an error message. Cloaking has become
standard in phishing kits, and it is commonly implemented on
both the server side and client side by applying (cid:27)lters based
on HTTP request attributes and device characteristics [45].
Redirection links make it more di(cid:28)cult for anti-phishing
systems (e.g., e-mail spam (cid:27)lters or blacklists) to correlate
a link in a lure with a known phishing URL [10]. Because
blacklists block phishing websites based on their URLs,
phishers typically distribute lures with di(cid:29)erent URLs that
then redirect [20] to the (cid:27)nal phishing URL. The HTTP
redirection chain itself may implement cloaking to further
evade detection, and a many-to-one mapping may exist
between redirection links and phishing websites to dilute
each link’s perceived maliciousness [65]. Phishers commonly
abuse URL shortening services to create redirection links [10].
Compromised infrastructure is regularly used by phishers
to host phishing kits [1, 31]. Such infrastructure—which
otherwise contains legitimate websites—poses a particular
challenge to blacklists, as the blacklists must ensure that the
legitimate content is not blocked alongside the phishing con-
tent (e.g., it might only di(cid:29)er in the path of a URL on the same
domain [3]). Some phishing kits exploit this phenomenon by
generating many sub-folders under one domain, all of which
must then be individually blacklisted [46].
Reporting Protocols. Just as individual users rely on
browser blacklists to stay safe from phishing, the organiza-
tions impersonated by phishing websites rely on blacklists to
protect their customers. These organizations typically obtain
phishing reports from their customers or internal systems,
and then forward the identi(cid:27)ed URLs to blacklists, either
directly or through the help of third-party vendors [48].
Blacklists predominantly accept reports of phishing web-
sites in the form of a bare URL [22,23,42,53]. However, such
reports can prove ine(cid:29)ective if the website successfully uses
evasion, as the blacklist may mistake the website as benign
and thus fail to act appropriately on the report. Reporting
protocols that facilitate the submission of additional evidence
(e.g., screenshots or page source) are currently available on
a limited scale [11]; we test one such protocol in Section 8.6.
3 Blacklist Evaluation Metrics
In this section, we explain the metrics that we use to evaluate
blacklists and describe the speci(cid:27)c blacklists that we consider
throughout the rest of this paper.
3.1 Blacklist Performance
Discovery refers to a blacklist’s ability to identify new URLs
in the wild that are suspected of hosting phishing content.
A blacklist with ideal discovery would know of every URL
within the population of live phishing URLs. Discovery
can result from direct phishing reports or other ecosystem
sources, such as monitoring of e-mail spam, web tra(cid:28)c,
website content, or server con(cid:27)guration [5,17,35,43,46].
Detection refers to a blacklist’s ability to correctly classify
the discovered URLs,such that URLs with phishing content are
added to the blacklist. A blacklist with ideal detection would
notonly(cid:30)ag everytrue-positive phishing URL,butitwoulddo
so promptly at the time of discovery to minimize the potential
damage caused by each attack. Thus, we can split detection
into two sub-metrics: For any set of phishing URLs discovered
by a blacklist, coverage is the proportion of these URLs that
are blacklisted at any point while they host phishing content.
Speed is the time delay between discovery and blacklisting,
which assesses how quickly blacklists respond. It is thus de-
sirable for blacklists to deliver high coverage and high speed2.
3.2 Selection of Blacklists
Several di(cid:29)erent service providers maintain anti-phishing
blacklists that are natively included in modern web browsers.
Google Safe Browsing (GSB) protects Chrome, Safari, Firefox,
and Chromium [25]; by global browser market share as of
December 2019, GSB is the most impactful blacklist as it
protects approximately 80.30% of desktop users and 92.22%
of mobile users [8]. Microsoft SmartScreen protects Internet
Explorer (IE) and Edge [38] and accounts for approximately
12.96% of desktop users. Opera’s fraud and malware protection
leverages undisclosed third-party providers [47,50] to protect
the Opera browser, which has a market share of approxi-
mately 1.50% on desktops and 1.27% on mobile. We focus
2Perfect detection is nontrivial in part because blacklists must maintain
a very low false-positive rate to avoid disrupting legitimate websites [64].
USENIX Association
29th USENIX Security Symposium    381
to take a proactive approach to mitigate the expansion of
sophisticated developments in phishing.
The system work(cid:30)ow is described in Figure 1, and proceeds
as follows. PhishTime begins by collecting a number of
real, live phishing websites (i.e., operated by criminals) for
analysis, with Section 5 covering the following steps:
Monitor Blacklisting of Live Phishing Websites. First,
we build a sample of live phishing URLs ( 1 ) and con-
tinuously monitor their status on blacklists of interest.
In our deployment, in real time, we collected PayPal
phishing URLs from the APWG eCrime Exchange [2]
and URLs from phishing e-mails reported directly to
PayPal. Using multiple data sources helps increase the