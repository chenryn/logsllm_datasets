# Managing Compute Resources for Containers（管理容器的计算资源）
> 译者按：本节中，笔者将request翻译成最小需求，limit翻译成最大限制。由于出现的次数太多，故而绝大多数地方直接不翻译了，大家可以当做术语来阅读。
指定 [Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod/) 时，可选择指定每个容器需要多少CPU和内存（RAM）。当容器指定了最小资源需求时，Scheduler可对Pod调度到哪个Node上进行更好的决策。当容器具有指定的资源限制时，可以指定的方式，处理Node上资源的争抢。有关资源的最小需求和最大限制之间的差异的更多信息，请参阅 [Resource QoS](https://git.k8s.io/community/contributors/design-proposals/node/resource-qos.md) 。
## Resource types（资源类型）
*CPU*和*内存*都是*资源类型* 。资源类型有基本单元。CPU以核心为单位指定，内存以字节为单位指定。
CPU和内存统称为*计算资源* ，也可称为*资源* 。 计算资源是可以请求、分配和消费的，可测量的数量。它们与 [API resources](https://kubernetes.io/docs/concepts/overview/kubernetes-api/) 。 API资源（如Pods和 [Services](https://kubernetes.io/docs/concepts/services-networking/service/) 是可通过Kubernetes API Server读取和修改的对象。
## Resource requests and limits of Pod and Container（Pod和容器资源的最小需求与最大限制）
Pod的每个容器可指定以下一个或多个：
- `spec.containers[].resources.limits.cpu`
- `spec.containers[].resources.limits.memory`
- `spec.containers[].resources.requests.cpu`
- `spec.containers[].resources.requests.memory`
尽管只能在每个容器上指定request和limit，但这样既可方便地算出Pod资源的request和limit。特定资源类型的Pod resource request/limit是Pod中每个容器该类型资源的request/limit的总和。
## Meaning of CPU（CPU的含义）
CPU资源的request和limit以*cpu为*单位。在Kubernetes中，一个cpu相当于：
- 1 AWS vCPU
- 1 GCP Core
- 1 Azure vCore
- 1 *Hyperthread* on a bare-metal Intel processor with Hyperthreading
允许小数。具有 `spec.containers[].resources.requests.cpu=0.5` 的容器，保证其所需的CPU资源是需要`1cpu` 容器资源的一半。表达式 `0.1` 等价于表达式 `100m` ，可看作“100millicpu”。有些人说“100 millicore”，表达的也是一个意思。具有小数点的请求（如 `0.1` ，会由API转换为 `100m` ，精度不超过 `1m` 。
CPU始终被要求作为绝对数量，从不作为相对数量；0.1在单核、双核或48核机器中，表示的是相同数量的CPU。
## Meaning of memory（内存的含义）
`memory` 的request和limit以字节为单位。可使用整数或定点整数来表示内存，并使用如下后缀之一：E、P、T、G、M、K；也可使用：Ei，Pi，Ti ，Gi，Mi，Ki。 例如，以下代表大致相同的值：
```
128974848, 129e6, 129M, 123Mi
```
如下是一个例子。如下Pod有两个容器。每个容器都有0.25 cpu和64MiB（226字节）内存的request。 每个容器的内存限制为0.5 cpu和128MiB。你可以说Pod有0.5 cpu和128 MiB内存的request，有1 cpu和256MiB内存的limit。
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: frontend
spec:
  containers:
  - name: db
    image: mysql
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
  - name: wp
    image: wordpress
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```
## How Pods with resource requests are scheduled（如何调度带有request的Pods）
当您创建一个Pod时，Kubernetes Scheduler将为Pod选择一个Node。对于各种资源类型，每个Node都有最大容量：可为Pod提供的CPU和内存量。Scheduler确保对于每种资源类型，调度到该Node的所有容器的request之和小于该Node的容量。请注意，尽管Node上的实际内存或CPU资源使用量非常低，但如果容量检查失败，那么Scheduler仍会拒绝在该Node上放置一个Pod。这样可在资源使用稍后增加时，例如在请求的高峰期，防止Node上的资源短缺。
## How Pods with resource limits are run（带有资源limit的Pod是如何运行的）
当kubelet启动Pod的容器时，它将CPU和内存限制传递到容器运行时。
使用Docker时：
-  `spec.containers[].resources.requests.cpu` 转换为其核心值，该值可能是小数，乘以1024。该数字中的较大值或2用作 `docker run` 命令中 [`--cpu-shares`](https://docs.docker.com/engine/reference/run/#/cpu-share-constraint) 的值。
-  `spec.containers[].resources.limits.cpu` 转换为其millicore值并乘以100。结果值是容器每100ms可以使用的CPU时间总量。 在此间隔期间，容器不能占用超过其CPU时间的份额。
  > **注意** ：默认配额期限为100ms。 CPU配额的最小分辨率为1ms。
-  `spec.containers[].resources.limits.memory` 会被转换为一个整数，并用作 `docker run`命令中 [`--memory`](https://docs.docker.com/engine/reference/run/#/user-memory-constraints) 标志的值。
如果容器超出其内存limit，则可能会被终止。如果容器能够重新启动，则与所有其他类型的运行时故障一样，kubelet将重新启动它。
如果一个容器超出其内存request，那么当Node内存不满足要求时，Pod可能会被逐出。
容器可能被允许或不允许长时间超过其CPU limit。 然而，即使CPU使用量过大，容器也不会被杀死。
要确定容器是否由于资源limit而无法调度或被杀死，请参阅 [Troubleshooting](https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#troubleshooting) 部分。
## 监控计算资源使用情况（Monitoring compute resource usage）
Pod的资源使用情况被报告为Pod status的一部分。
如果为集群配置了 [optional monitoring](http://releases.k8s.io/master/cluster/addons/cluster-monitoring/README.md) ，那么即可从监控系统查询Pod资源的使用情况。
## Troubleshooting（故障排查）
### My Pods are pending with event message failedScheduling
如果Scheduler找不到任何Pod能够匹配的Node，则Pod将保持unscheduled状态。每当调度程序找不到地方调度Pod时，会产生一个事件，如下所示：
```shell
$ kubectl describe pod frontend | grep -A 3 Events
Events:
  FirstSeen LastSeen   Count  From          Subobject   PathReason      Message
  36s   5s     6      {scheduler }              FailedScheduling  Failed for reason PodExceedsFreeCPU and possibly others
```
在上述示例中，由于Node上的CPU资源不足，名为“frontend”的Pod无法调度。 如果内存不足，也可能会导致失败，并提示类似的错误消息（PodExceedsFreeMemory）。一般来说，如果一个Pod处于pending状态，并带有这种类型的消息，有几件事情要尝试：
- 向集群添加更多Node。
- 终止不需要的Pod，为处于pending的Pod腾出空间。
- 检查Pod是否不大于所有Node。例如，如果所有Node的容量为 `cpu: 1` ，那么request = `cpu: 1.1` 的Pod将永远不会被调度。
可使用 `kubectl describe nodes` 命令检查Node的容量和数量。 例如：
```shell
$ kubectl describe nodes e2e-test-minion-group-4lw4
Name:            e2e-test-minion-group-4lw4
[ ... lines removed for clarity ...]
Capacity:
 alpha.kubernetes.io/nvidia-gpu:    0
 cpu:                               2
 memory:                            7679792Ki
 pods:                              110
Allocatable:
 alpha.kubernetes.io/nvidia-gpu:    0
 cpu:                               1800m
 memory:                            7474992Ki
 pods:                              110
[ ... lines removed for clarity ...]
Non-terminated Pods:        (5 in total)
  Namespace    Name                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits
  ---------    ----                                  ------------  ----------  ---------------  -------------
  kube-system  fluentd-gcp-v1.38-28bv1               100m (5%)     0 (0%)      200Mi (2%)       200Mi (2%)
  kube-system  kube-dns-3297075139-61lj3             260m (13%)    0 (0%)      100Mi (1%)       170Mi (2%)
  kube-system  kube-proxy-e2e-test-...               100m (5%)     0 (0%)      0 (0%)           0 (0%)
  kube-system  monitoring-influxdb-grafana-v4-z1m12  200m (10%)    200m (10%)  600Mi (8%)       600Mi (8%)
  kube-system  node-problem-detector-v0.1-fj7m3      20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests    CPU Limits    Memory Requests    Memory Limits
  ------------    ----------    ---------------    -------------
  680m (34%)      400m (20%)    920Mi (12%)        1070Mi (14%)
```
由如上输出可知，如果一个Pod的request超过1120mCPU或6.23Gi内存，它将不适合该Node。
通过查看 `Pods` 部分，可查看哪些Pod占用Node上的空间。
> 译者按：CPU 1120m是这么算的：1800m（Allocatable） - 680m（Allocated）。同理，内存是7474992Ki - 1070Mi
Pods所用的资源量必须小于Node容量，因为系统守护程序需要使用一部分资源。 `allocatable` 字段 [NodeStatus](https://kubernetes.io/docs/resources-reference/v1.8/#nodestatus-v1-core) 给出了Pod可用的资源量。有关更多信息，请参阅 [Node Allocatable Resources](https://git.k8s.io/community/contributors/design-proposals/node/node-allocatable.md) 。
可配置 [resource quota](https://kubernetes.io/docs/concepts/policy/resource-quotas/) 功能，从而限制能够使用的资源总量。 如果与Namespace一起使用，则可防止一个团队占用所有资源。
### My Container is terminated
由于资源不足，容器可能会被终止。要查看容器是否因为资源限制而被杀死，请在感兴趣的Pod上调用 `kubectl describe pod` ：
```shell
[12:54:41] $ kubectl describe pod simmemleak-hra99
Name:                           simmemleak-hra99
Namespace:                      default
Image(s):                       saadali/simmemleak
Node:                           kubernetes-node-tf0f/10.240.216.66
Labels:                         name=simmemleak
Status:                         Running
Reason: