pp0 ← Setup(1λ);
pp1, st S ← S1(1λ);
b(cid:48) ← AKEYGEN,PROVE(1λ, ppb)
A wins if b = b(cid:48)
KEYGEN(R)
if EK(R) exists, return ⊥
EK0, VK0 ← KeyGen(pp, R)
EK1, VK1, st S ← S2(st S, R)
EK(R) := EKb
return (EKb, VKb)
PROVE(R, u, w)
if EK(R) undeﬁned, return ⊥
Π0 ← Prove(EK(R), u, w)
Π1, st S ← S3(st S, R, u)
return Πb
C Designated Veriﬁer HP Scheme from Weak PRFs (XP2)
In this section we present a more abstract deﬁnition of the scheme XP2 given in Section 4.3. We
recall that XP2 supports the class of multi-exponentiation computations and works in the designated
veriﬁer setting.
The main building block of XP2 is a cryptographic primitive, called homomorphic weak pseudo-
random functions, that we recall below.
Homomorphic Weak Pseudo-random Functions. A homomorphic weak pseudorandom func-
tion [23] WPRF consists of algorithms KeyGen and PRF. The key generation KeyGen takes as input
the security parameter 1λ and outputs a secret key k and some public parameters pp that specify
domain X and range Y of the function. On input X ∈ X , PRFk(X) returns Y ∈ Y . Homomorphic
weak pseudorandom function have two properties: weak pseudorandomness and homomorphism.
• WPRF is weakly pseudorandom if, for any p.p.t. adversary A and any polynomial t = t(λ),
we have
Pr[A(1λ, pp,{Xi, Yi}t
i=1)] − Pr[A(1λ, pp,{Xi, Zi}t
where k, pp ← KeyGen(1λ); Xi ∈ X ; Yi = PRFk(Xi); and Zi
i=1)] ≈ 0
$←− Y for i = 1..t.
• WPRF is homomorphic if, for any inputs X1, X2 ∈ X and any integer coeﬃcients c1, c2 ∈ Z,
it holds that PRF(X c1
1 X c2
2 ) = PRF(X1)c1PRF(X2)c2.
We instantiate WPRF for X = Y = G1 as PRFk(h) = hk. This scheme is weakly pseudorandom in
any cyclic prime order group under the DDH assumption.
In presence of asymmetric bilinear groups G1 and G2, this function can be instantiated in G1
and G2 and proven secure under the SXDH assumption [23].
The XP2 construction. XP2 is described in terms of a weak homomorphic PRF as deﬁned above.
The scheme XP2 works as follows:
$←− G1 for i ∈ [1, n] and returns pp = (G1, p, g1, H) where H = (H1, . . . , Hn).
Setup(1λ) samples Hi
Hash(pp, (x1, . . . , xn)) returns σx ←(cid:81)
i∈[1,n] Hi
xi.
28
KeyGen(pp, F ) generates δ, k $←− Z∗
(F, T ), VKF = (δ, k) where T = (T1, . . . , Tn).
Prove(EKF , (x1, . . . , xn), cx) computes Φx ←(cid:81)
p; computes Ti ← Fi
that cx =(cid:81)
the proof.)
xi; and returns Φx. (Implicitly we require
xi, though the cx part of the instance is not used in the computation of
i∈[1,n] Ti
i∈[1,n] Fi
δPRFk(Hi) for i ∈ [1, n]; and returns EKF =
Verify(VKF , σx, cx, Φx) returns Φx
?= cx
δPRFk(σx).
Theorem C.1 (Adaptive Soundness of XP2). Assuming the weak pseudorandomness of PRF, the
XP2 construction above is adaptively sound (Deﬁnition 3.1 for multiple relations and a designated
veriﬁer).
We prove that XP2 construction is adaptively sound for a single relation, then apply Theorem 3.1
to extend it to multiple relations. We outline below the games that we use for the proof.
Game 0: This game is the same as the adaptive forgery game.
Game 1: This game is the same as Game 0 except for the following change in the way the veriﬁ-
cation queries are answered by the challenger.
Instead of computing PRFk(σx), the challenger computes σ(cid:48) as(cid:81)
Let (x, cx, Φx) be the query made by the adversary to the VERIFY oracle. Let σx = Hash(pp, x).
i∈[1,n] PRFk(Hi)xi Then, it
veriﬁes by checking if Φx = cδ
xσ(cid:48) holds.
δ(cid:81)
Game 2: During KeyGen, instead of generating a key k for the weak PRF, the challenger sets each
Ti to Fi
δZi, where Zi
$←− G1, and sets VK = (δ, Z1, . . . , Zn).
Accordingly, for veriﬁcation queries (σx, cx, Φx), where σx exists in the challenger’s table with
σx = Hash(pp, x), the challenger checks Φx = cx
xi.
i∈[1,n] Zi
Let Gi(A) be the output of Game i run with adversary A. We prove the following claims:
1. Pr[G0(A) = 1] = Pr[G1(A) = 1].
2. Pr[G1(A) = 1] ≈ Pr[G2(A) = 1].
3. Pr[G2 = 1] ≈ 0.
Claim C.1. Pr[G0(A) = 1] = Pr[G1(A) = 1].
Proof. By the homomorphic property of the weak PRF, the computation in the veriﬁcation oracle
for Game 1 is equivalent to Game 0 and it does not aﬀect the distribution of the outcome of
veriﬁcation.
Claim C.2. Pr[G1(A) = 1] ≈ Pr[G2(A) = 1].
Proof. The diﬀerence between Games 1 and 2 is the substitution of a random element with an
$←− G1 by a
element generated by a weak homomorphic PRF. Since values Hi are chosen as Hi
trusted Setup algorithm, one can write a distinguisher for WPRF given a distinguisher of the two
games in the claim.
29
Claim C.3. Pr[G2(A) = 1] ≤ q/p for a (computationally unbounded) adversary A that makes at
most q queries to the veriﬁcation oracle.
Proof. We ﬁrst rewrite Game 2 as follows.
Game 2 :
(F1, . . . , Fn) ← A(1λ) where Fi ∈ Gp;
The challenger chooses δ $←− Zp and computes Ti ← Fi
Deﬁne O(Φ, x, cx) to return 1 iﬀ Φ = cδ
Given oracle access to O,A(stateA) returns 1 if O returns 1,and 0 otherwise.
i grixi ∧ cx (cid:54)=(cid:81)
Wlog we assume that A never outputs (Φ, (xi)i, cx) such that cx =(cid:81)
xi as such outputs do not
help the adversary and can be avoided. Therefore, the probability that the experiment outputs 1
is:
δgri where ri
$←− Zp;
(cid:81)
i Fi
i Fi
xi;
x
Pr[output is 1] = Pr
Forgeryj
(cid:91)
δ(cid:81)
j
 ≤(cid:88)
Pr(cid:2)Forgeryj
x (cid:54)=(cid:81)
i ∧ cj
i Fi
j
(cid:3)
where the event Forgeryj is deﬁned as Φj = cj
x
query to O.
i grixj
xj
i and corresponds to the jth
T1, . . . , Tn, and show that no matter what these values are, the probability is at most 1/p.
Now we will bound the probability inside the sum conditioned on a particular value of F1, . . . , Fn,
Since the adversary is unbounded, wlog we assume A is deterministic. Now, ﬁx such a value
for Fi’s and Ti’s that happens in the experiment with non-zero probability. Notice that, once the
value of δ is ﬁxed, there is a unique value for r1 that results in the answer T1 for F1. Similarly,
there is a unique value of r2 that makes answer to F2, T2 and so on. In other words, there are
exactly p possible values of δ, r1, r2, . . . , rn that result in these queries and answers, precisely one
for each possible choice of δ.
i grixi ∧ cx (cid:54)=(cid:81)
δ(cid:81)
(cid:18) cx(cid:81)
(cid:19)δ (cid:54)= 1
xi and B = Φ(cid:81)
Therefore, δ = logA(B) mod p where A = cx(cid:81)
xi . There is exactly one δ that
satisﬁes this equation. So, out of the p possible settings of δ, r1, . . . , rn, at most one will result in
A’s success. Therefore, we can bound the probability as:
Wlog we omit superscript j below. Since Φ = cx
xi, we have the following:
Φ(cid:81)
i Fi
i Fi
i Ti
i Fi
i Ti
=
xi
xi
Pr[output is 1] ≤(cid:88)
(cid:88)
(cid:88)
j
Pr[Forgeryj] =
Pr[F1, .., Fn, T1, .., Tn] Pr[Forgeryj | F1, .., Fn, T1, .., Tn] ≤ q/p
j
Fl,Tl
Though the distribution over diﬀerent values of Fl and Tl is not known, the above bound holds for
value of these variables.
D Security Proofs
D.1 Proof of Theorem 3.1
Theorem 3.1. A HP scheme that is -secure as per Deﬁnition 3.1 for a single relation is q-secure
for multiple relations, where q bounds the number of calls to KEYGEN made by the adversary.
30
Proof. Assume there is an adversary A that can win the adaptive forgery in the multiple relations
case game with non-negligible probability  against HP . We construct an adversary B that can
break HP while querying key generation only for a single relation. We ﬁrst consider the designated
veriﬁer option and then show that the proof extends to the public veriﬁability option as well.
B uses his pp as pp for A and initializes a tape T to store a mapping between R’s queried by
A and EKR, VKR. (T is stored in B’s state.) A makes a forgery on one of the q relations that he
queries KEYGEN for. Since B does not know which one, he chooses an index i ∈ [1, q] at random.
B answers A’s KEYGEN(R) queries as follows. If R is in T, return ⊥. If B chooses R as his
forgery, i.e., R is the ith relation queried by A, he sets R(cid:48) to R and sends R(cid:48) to his challenger, and
gets EKR(cid:48) back. He stores R(cid:48) and EKR(cid:48),⊥ in T and returns EKR(cid:48) to A. If A queries for any other R
not in T, B runs HP.KeyGen himself, stores R and corresponding EKR, VKR in T and returns EKR
to A.
B answers A’s VERIFY(R, x, v, Π) queries as follows. If R is not in T, he returns 0. If R(cid:48) = R,
B queries his own VERIFY oracle and returns the reply to A. For all other relations, he ﬁrst
runs σx ← HP.Hash(pp, x), looks up R’s veriﬁcation key VKR in T and returns the result of
HP.Verify(VKR, σx, v, Π).
Once A outputs a forgery R∗, x∗, v∗, ΠR∗, B checks if R∗ = R(cid:48). If yes, he returns x∗, v∗, ΠR∗ as
Let q be the number of KeyGen queries A requested. Then, B wins with probability /q which
is non-negligible if q is polynomial in the security parameter.
The proof extends to the public veriﬁability option as follows. During KEYGEN queries, B as
before queries his own challenger on R(cid:48) and receives back EKR(cid:48) as well as VKR(cid:48). He forwards both
of them to A. Similarly for other R’s he sends both EKR and VKR to A. The VERIFY oracle
disappears as a consequence.
his forgery, Otherwise he aborts.
D.2 Proof of Theorem 3.2
Theorem 3.2. If VC is knowledge-sound and hash is collision-resistant, then HPinn is adaptively
sound (Deﬁnition 3.1 for multiple relations).
Proof outline. The proof of adaptive soundness proceeds in a sequence of game transformations.
Game 1 This is the original adaptive soundness game.
Game 2 Let AVC be the adversary obtained from A by taking pp and the randomness used by
A and the challenger up to the point where it queries KeyGen as auxiliary input. It receives
EKR, VKR as input and reruns A and the experiment from the beginning to restore the state
of A at the time of the query. It then runs A and returns its proof. We conjecture that the
auxiliary input used by AVC to reproduce the state of A is benign as it consists of a random
hash key and a random tape.
Game 2 is the same as Game 1, except that for each adversary we execute the challenger
together with the knowledge extractor EVC that is guaranteed to exist for every AVC under
the knowledge soundness of VC. The game aborts without A winning if EVC fails to extract
a valid witness (x(cid:48), w) for R(cid:48).
Game 3 The same as Game 2, except that we abort if the x output by A is diﬀerent from the x(cid:48)
extracted by EVC.
In Game 3, the success probability of A is negligible as otherwise we break the collision
resistance property of hash.
31
D.3 Proof of Theorem 4.1
Theorem 4.1. If XP is adaptively sound in the publicly veriﬁable (resp. designated veriﬁer) setting,
and VC is sound, then the HPgen construction in Section 4.1 is adaptively sound in the publicly
veriﬁable (resp. designated veriﬁer) setting.
To prove Theorem 4.1 we show that if there exists an adversary A that breaks the security
of HPgen, then using A, we can either build an adversary AXP that breaks the security of the XP
scheme or an adversary AVC that breaks the security of VC construction. Our proof considers the