The eight beliefs are:
1. Genome privacy is hopeless, because all of us leave biological cells (hair, skin,
droplets of saliva,...) wherever we go.
2. Genomic data is not special and should be treated as any other sensitive health
data e.g. health record or mental health notes.
3. Genome privacy is irrelevant, because genetics is non-deterministic
4. Genome privacy should be left to bioinformaticians, they can provide better
privacy solutions than computer security, privacy and cryptography community
can.
5. Genome privacy will be fully guaranteed by legislation
6. Privacy Enhancing Technologies are a nuisance in the case of genetics: genetic
data should be made available online to everyone to facilitate research, as done
e.g. in the case of the Personal Genome Project
7. Encrypting genomic data is superﬂuous because it is hard to identify a person
from her variants
8. Advantages of genomic based healthcare justify the harm that genome privacy
breach can cause.
Figure 2: Beleifs about genomic privacy
Figure 3: Expertise of the survey respondents.
The participants were also asked to report their expertise in genomics/genetics
and security/privacy. We show these results in Figure 3.
We now comment on our ﬁndings from the survey. The importance of
genome privacy has been advertised in several research papers and articles
(e.g., [Ayday et al., 2013a]). We asked respondents whether they would share
their genomes on the Web (Figure 4). We ﬁnd that 48% of the respondents are
not in favor of doing so, while 8% would and would go so far as to reveal their
identities. 30% of the respondents think that anonymization (or pseudonymiza-
tion) is suﬃcient to hide their identity. Recently, Humbert et. al. [Humbert
et al., 2013] showed that the privacy loss of an individual due to publicly avail-
able genomes of his family members is not negligible (discussed in detail in
Section VI). Nevertheless, we observe that 39% support the right to publish
one’s genome (Figure 5).
12
Figure 4: Response to the question: Would you publicly share your genome on the
Web?
Figure 5: Response to the question: Assuming that one’s genomic data leaks lot of
private information about his or her relatives, do you think one should have the right
to share his or her genomic data?
As discussed in Section IV, there is a tension between the desire for genome
privacy and biomedical research. Thus, we asked the survey respondents what
they would trade for privacy. As expected, the results (shown in Figure 6)
indicate that the respondents are willing to trade money and test time (duration)
to protect privacy, but they usually do not accept trading accuracy or utility.
Figure 6: Response to the question: What can we compromise to improve privacy of
genomic data? (Multiple options can be checked)
We also asked the respondents to evaluate the importance of existing and
ongoing research directions on genomic privacy (as discussed in detail in Sec-
tion VII), considering the types of problems they are trying to solve (Figure 7).
The respondents all agree that privacy is important in all domains (i.e., health-
care, research, recreational genomics, legal and forensics) and think that privacy
13
Figure 7: Relevance of genome privacy research done by computer science community.
is the most important when genomic data is delegated to a third party (e.g.,
storage in a commercial cloud or outsourcing computation of genomic data to a
cloud). The respondents think that privacy is the least important when genomic
data is used for research or healthcare issues.
Finally, we asked whether the respondents agree with the beliefs we intro-
duced earlier in this section. We comment on a few important results (Figure 8).
First, we observe that 20% of the respondents believe that genome privacy is a
Figure 8: Response to the question: Do you believe that: (Multiple options can be
checked). “None” means the respondent does not agree with any of the beliefs.
lost cause (Belief 1), while almost half of the respondents consider genomic data
to be no diﬀerent than electronic health data (Belief 2). Even though genomic
information is, in most instances, non-deterministic, all respondents agree that
this fact does not reduce the importance of genome privacy (in contrast with
Belief 3). Only 7% of our respondents think that genome privacy should be left
to bioinformaticians (Belief 4). Furthermore, we observe that only 20% of the
respondents believe that genome privacy can be fully guaranteed by legislation
(Belief 5). Notably, only 7% of the respondents think that privacy enhancing
technologies are a nuisance in the case of genetics (Belief 6). According to 11%
of the respondents, the conﬁdentiality of genomic data is superﬂuous because
14
it is hard to identify a person from her variants (Belief 7). And, ﬁnally, only
28% of the respondents think that advantages that will be brought by genomics
in healthcare will justify the harm that might be caused by privacy issues (Be-
lief 8). Overall we conclude that the eight beliefs we informally collected do not
reﬂect the opinion of the biomedical community.
VI Known Privacy Risks
In this section, we survey a wide spectrum of privacy threats to human genomic
data, as reported by prior research.
VI.A Re-identiﬁcation Threats
Re-identiﬁcation is probably the most extensively studied privacy risk in dissem-
ination and analysis of human genomic data. In such an attack, an unauthorized
party looks at the published human genomes that are already under certain pro-
tection to hide the identity information of their donors (e.g., patients), and tries
to recover the identities of the individuals involved. Such an attack, once it
succeeds, can cause serious damage to those donors, e.g., discrimination and
ﬁnancial loss. In this section, we review the weaknesses within existing privacy
protection techniques that make this type of attack possible.
Pseudo-anonymized Data. A widely used method for protecting health in-
formation is the removal of explicit and quasi-identifying attributes (e.g., name
and date of birth). Such redaction meets legal requirements to protect privacy
(e.g., de-identiﬁcation under the U.S. Health Insurance Portability and Account-
ability Act) for traditional health records. However, genomic data cannot be
anonymized by just removing the identifying information. There is always a risk
for the adversary to infer the phenotype of a DNA-material donor (that is, the
person’s observable characteristics like eye/hair/skin colors), which will lead to
her identiﬁcation, from her genotypes (her genetic makeup). Even though the
techniques for this purpose are still not there yet, the rapid progress in genomic
research and technologies is quickly moving us toward that end. Moreover, re-
identiﬁcation can be achieved through inspecting the background information
that comes with publicized DNA sequences [Gitschier, 2009; Gymrek et al., 2013;
Hayden, 2013]. As an example, genomic variants on the Y chromosome have
been correlated with surnames (for males), which can be found out using pub-
lic geneology databases. Other instances include identifying Personal Genome
Project (PGP) participants through public demographic data [Sweeney et al.,
2013], recovering the identities of family members from the data released by
the 1000 Genome Project using public information (e.g. death notices)[Malin,
2006], and other correlation attacks [Malin and Sweeney, 2004].
It has been
shown that even cryptographically secure protocols leaks a lot of information
when used for genomic data [Goodrich, 2009].
Aggregate Genomic Data. In addition to the aforementioned re-identiﬁcation
15
threat, which comes from the possible correlation between an individual’s ge-
nomic data and other public information, the identity of a participant of a
genomic study can also be revealed by a “second sample”, that is, part of the
DNA information from the individual. This happens, for example, when one
obtains a small amount of genomic data from another individual, such as a small
set of her single nucleotide polymorphisms (SNPs), and attempts to determine
her presence in a clinic study on HIV, based on anonymized patient DNA data
published online. This turns out to be rather straightforward, given the unique-
ness of individual’s genome. Particularly, in 2004, research shows that as few
as 100 SNPs are enough to uniquely distinguish one individual from others [Lin
et al., 2004]. Based on this observation, the genomic researchers generally agree
that such DNA raw data are too sensitive to release through online repositories
(such as the NIH’s PopSet resources), without proper agreements in place. An
alternative is to publish “pooled” data, in which summary statistics are disclosed
for the case and control groups of individuals in a study.
Yet, in 2008, Homer and colleagues [Homer et al., 2008] showed that when
an adversary had access to a known participant’s genome sequence, they could
determine if the participant was in a certain group. Speciﬁcally, the researchers
compared one individual’s DNA sample to the rates at which her variants show
up in various study populations (and a reference population that does not in-
clude the individual) and applied a statistical hypothesis test to determine the
likelihood of which group she is in (i.e., case or reference). The ﬁndings of the
work compelled the NIH, as well as the Wellcome Trust in the UK, to remove
all publicly available aggregate genomic data from their websites. Ever since, re-
searchers are required to sign a data use agreement (prohibiting re-identiﬁcation)
to access such data [Zerhouni and Nabel, 2008], the process of which could take
several months. At the same time, such attacks were enhanced. First, Homer’s
test statistic was improved through exploitation of genotype frequencies [Jacobs
et al., 2009], while an alternative, based on linear regression was developed to
facilitate more robust inference attacks [Masca et al., 2011]. Wang et. al. [Wang
et al., 2009a] demonstrated, perhaps, an even more powerful attack by showing
that an individual can be identiﬁed even from the aggregate statistical data (co-
eﬃcient of determination –r2– values) published in research papers. While the
methodology introduced in [Homer et al., 2008] requires on the order of 10,000
pieces of genome (of the target individual), this new attack required only on
the order of 200. Their approach even shows the possibility of recovering part
of the DNA raw sequences for the participants of biomedical studies, using the
statistics including p-values and the r2.
Quantiﬁcation of information content in aggregate statistics obtained as an
output of genome-wide association studies (GWAS) shows that an individual’s
participation in the study and her phenotype can be inferred with high ac-
curacy [Im et al., 2012; Craig et al., 2011]. Beyond these works, it has been
shown that a Bayesian network could be leveraged to incorporate additional
background information, and thus improve predictive power [Clayton, 2010]. It
was recently shown that RNA expression data can be linked to the identity of
an individual through the inference of SNPs [Schadt et al., 2012].
16
Yet, there is debate over the practicality of such attacks. Some researchers
believe that individual identiﬁcation from pooled data is hard in practice [Braun
et al., 2009; Sankararaman et al., 2009; Visscher and Hill, 2009; Gilbert, 2008].
In particular, it has been shown that the assumptions required to accurately
identify individuals from aggregate genomic data rarely hold in practice [Braun
et al., 2009]. Such inference attacks depend upon the ancestry of the partici-
pants, the absolute and relative number of people in case and control groups,
and the number of SNPs [Masca et al., 2011] and the availability of the second
sample. Thus, the false positive rates are much higher in practice. Still, others
believe that publication of complete genome wide aggregate results are danger-
ous for privacy of the participants [Lumley and Rice, 2010; Church et al., 2009].
Furthermore, the NIH continues to adhere to its policy of data use agreements.
Beyond the sharing of aggregate data processing, it should be recognized that
millions of people are sequence or genotyped for state of the art GWAS studies.
This sequenced data is shared among diﬀerent institutions with inconsistent
security and privacy procedures [Brenner, 2013]. On the one hand, this could
lead to serious backlash and fear to participate in such studies. On the other
hand, not sharing this data could severely impede biomedical research. Thus,
measures should be taken to mitigate the negative outcomes of genomic data
sharing [Brenner, 2013].
VI.B Phenotype Inference
Another critical privacy threat to human genome data is inference of sensitive
phenotype information from the DNA sequence. Here we summarize related
prior studies.
Correlation of Genomic Data. Partially available genomic data can be used
to infer the unpublished genomic data due to linkage disequilibrium (LD), a cor-
relation between regions of the genome [Halperin and Stephan, 2009; Marchini
and Howie, 2010]. For example, Jim Watson (the discoverer of DNA) donated
his genome for research but concealed his ApoE gene, because it reveals suscep-
tibility to Alzheimer’s disease. Yet, it was shown that the ApoE gene variant
can be inferred from the published genome [Nyholt et al., 2008]. Such comple-
tion attacks are quite relevant in DTC environments, where customers have the
option to hide some of the variants related to a particular disease.
Kin Privacy Breach. A signiﬁcant part of the population does not want
to publicly release their genomic data [McGuire et al., 2011]. Disclosures of
their relatives can thus threaten the privacy of such people, who never release
their genomic data. The haplotypes of the individuals not sequenced or geno-
typed can be obtained using LD-based completion attacks [Kong et al., 2008].
For instance, if both parents are genotyped, then most of the variants for their
oﬀsprings can be inferred. The genomic data of family members can also be in-
ferred using data that has been publicly shared by blood relatives and domain-
speciﬁc knowledge about genomics [Humbert et al., 2013]. Such reconstruction
17
attacks can be carried out using (i) (partial) genomic data of a subset of fam-
ily members, and (ii) publicly-known genomic background information (linkage
disequilibrium and minor allele frequencies (MAFs) This attack aﬀects individ-
uals whose relatives publicly share genomic data (obtained using DTC services)
on the Internet (e.g. on OpenSNP.org). The family members of the individuals
who publish their genomic data on OpenSNP.org can be found on social media
sites, such as Facebook [Humbert et al., 2013].
VI.C Other Threats
In addition to the above threats, there are a few other genome-related privacy
issues, as follows:
Anonymous Paternity Breach. As mentioned above, the Y chromosome
is inherited from father to son virtually intact and genealogy databases link
this chromosome to the surname to model ancestry. Beyond the case discussed
above, this information has been used to identify sperm donors in several cases.
For example, a 15 year boy who was conceived using donor sperm, successfully
found his biological father by sending his cheek swab to a genealogy service
and doing Internet search [Motluk, 2005; Stein, 2005]. Similarly, an adopted
child was able to ﬁnd his real father with the help of a genealogy database
(and substantial manual eﬀort) [Naik, 2009]. In short, DNA testing have made
tracing anonymous sperm donors easy and theoretically sperm donors can no
more be anonymous [Lehmann-Haupt, 2010].
Legal and Forensic. DNA is collected for legal and forensic purposes from
criminals8 and victims9. On the one hand, forensic techniques are becoming
more promising with the evolving technology [Kayser and de Knijﬀ, 2011; Pak-
stis et al., 2010]. On the other hand, abuse of DNA (e.g., to stage crime scenes)
have already baﬄed people and law enforcement agencies [Bobellan, 2010]. Some
people like Madonna (the singer) are paranoid enough about the misuse of their
DNA that they hire DNA sterilization teams to clean up their leftover DNA
(e.g., stray hairs or saliva) [Villalva, 2012]. We are not aware of any privacy risk
assessment studies done primarily in legal and forensic context, in part because
law enforcement agencies store a very limited amount of genetic markers. Yet, in
the future, it could well happen that law enforcement agencies will have access