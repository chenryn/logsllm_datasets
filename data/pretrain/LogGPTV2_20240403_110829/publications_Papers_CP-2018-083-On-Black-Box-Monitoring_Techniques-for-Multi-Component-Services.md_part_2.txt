the total capacity of each layer. It should be noted however 1000 (4)
that this does not reduce the generality of the solution. The η i =H(λ,µ ,iδ), i=1,...,1000
same approach could be applied under different distributions  =ecdf(iδ), i=1,...,1000
i
and loads, as long as some conditions are met (the resulting
λ>0, λ∈R
distributionhavingenoughinformationtoextrapolatetheorig-
inalprocesses).Furthermore,thetwoprocessesunderstudydo µ >0, µ ∈R
not necessarily have to be tandem, they may, for example, be
interleaved, as long as the sum of the components follows the Attheendofthisstep,weareleftwithaλandµ ,whichare
previously described assumptions. A good example of where estimators of the service rate of Layers 1 and 2 respectively.
interleaving is the more adequate model, would be resource Giventhattheloadunderwhichthemeasurementsweretaken,
time-slicing. which we denote as W, as well as the parallelism levels,
denoted c and c , the occupation of each layer, ρ and ρ
To define it more precisely, given f(x) and g(y), which 1 2 1 2
can be determined as shown in Equation 5 where S denotes
are the density functions of the service times of two layers,
the service rate of a layer (λ or µ ).
known to be approximately exponentially distributed, of rates
λandµ,weknowthatthetotalservicetimewillbedescribed
W
by the sum of two random variables, h(z), obtained from the ρ= (5)
c·S
convolution of the two, as shown in Equation 1.
The assumption that the parallelism level c is known might
 +∞ seem limiting, however, in practice this parameter is easy
h(z)=(f ∗g)(z)= f(z−y)g(y) dy (1) to monitor using classical tools, and even if not directly
−∞
measurable, heuristics can be used to estimate it. One such
example is exploiting the relationships between maximum
By substituting for the particular case of the exponential
throughput T and parallelism given by Equation 6.
distribution, we get the result for h(z) in Equation 2, which
weintegrateinEquation3toobtainthecumulativedistribution
function H(z). T =c·S (6)
TABLE II: Machine Learning Decomposition
III. EVALUATION
We validated and benchmarked the two methods with total Range Layer1-MSE Layer2-MSE
0.1 0.12 0.12
service time samples extracted from a simulated service with
0.2 0.07 0.08
two layers. The described system was simulated as two se- 0.3 0.04 0.03
quentialsingleserverqueuesystems(M/M/1)inRusingthe 0.4 0.03 0.02
0.5 0.02 0.02
qcomputer [11] package (shown in Figure 2).
0.6 0.03 0.02
0.7 0.03 0.03
0.8 0.03 0.03
W L1 L2 0.9 0.03 0.03
Fig. 2: Two sequential single server queue systems. TABLE III: Exponential Decomposition
To simulate different occupation rates, we used a fixed Range Layer1-MSE Layer2-MSE
0.1 0.08 0.08
global request arrival rate W of 30 requests per unit of time
0.2 0.12 0.26
and varied the service rates S of each layer according to 0.3 0.25 0.51
Equation 5. A set of 30 samples of 2000 observations each 0.4 0.40 0.68
0.5 0.93 0.74
was then obtained for all the permutations of the two layers
0.6 1.79 1.76
with occupations in the range [0.1,0.9] in 0.1 increments 0.7 3.76 4.95
(e.g. (0.1,0.1),(0.1,0.2),...). Each sample, a line in a CSV, 0.8 11.38 11.43
contains 2000 features and the 2 targets, in this case the 0.9 66.48 74.87
occupation parameters.
Using cross-validation we trained the machine learn- The SVR algorithm attained an average of 0.05 MSE (with
ing algorithms and evaluate the quality of the predictions. 0.04 standard deviation) for Layer 1 and 0.05 (with 0.03
For the exponential variable sum algorithm we used the standard deviation) for Layer 2. On a [0,1] range this is a
proposedoptimizationapproachtopredictthetargetsforeach good result.
sample.
SVR algorithm outperforms SLR and Decision tree model,
To compare the two general approaches we calculated
forbothlayers.Therefore,wecomparedSVRalgorithmwitha
the Mean Square Error (MSE) for each layer grouped by
non-linear kernel with theexponential decomposition method.
occupation range in 0.1 increments. Additionally, as we tried
Todothis,wetrainedthesameSVRalgorithmforbothLayer
multiplemachinelearningapproaches,thesemetricswerealso
1 and Layer 2. We submitted to the fitted model only values
used to pick the best algorithm.
for a specific range (e.g. 0.1, 0.2) and registered the MSE for
the predicted values. In Table II we can evaluate the machine
IV. RESULTS
learning accuracy for distinct Layer levels. We can observe
As we referred in Section II, we collected a set of 2000
that for low occupied layers the algorithm have a worst MSE,
total response time for the clients invocations. We analyze the
compared with a more occupied Layer.
resultsobtainedwiththemachinelearningalgorithmsandalso
In Table III we can observe the algorithm to split the
with the exponential decomposition.
two layers with the exponential decomposition method. We
TABLE I: Regression model results for Layer 1 and Layer 2 evaluated the MSE for each Layer 1 and Layer 2 occupation
occupation level. One could notice that this algorithm outperforms SVR
on lower occupations levels. However, for high occupation
Layer1 Layer2
levels, the exponential algorithm, does not predict correctly,
Method MSE MSE
DecisionTree 0.12±0.08 0.09±0.06 being outperformed by the machine learning approach.
SLR 0.81±0.61 0.93±0.44 Another difference is that the Machine Learning algorithm
SVR 0.05±0.04 0.05±0.03
requiressupervisedtrainingandtheexponentialdecomposition
does not. On the other hand, the latter can only be used when
The results obtained for the Layer 1 and 2 occupation
the system load during the sampling period is known. Given
models are summarized in Table I, Table II and Table III.
their complementary properties and ranges of effectiveness,
We report average results for the mean square error (MSE),
they are obvious candidates for hybrid application.
between the predicted and actual values. Since we performed
20 repetitions of 10-fold cross-validation, we present average
V. RELATEDWORK
and standard deviation results.
Table I presents the results for three distinct classifiers: The monitoring research field is active with several contri-
decisiontreeregressor,SLRandSVRalgorithms.Asexpected, butions in the academy as well as in the industry. Hence, we
SVR outperforms the others algorithms, since it uses a non- present several works from both fields.
linearkernelthatfitsbettertherawdatathatishandledinthis In the industry, companies such as New Relic [12], Dyna-
use case scenario. Trace [3] or distributed tracing system such as ZipKin [13],
aim to give frameworks or tools to administrators, to create system. Secondly, we want to test our method in more setups
dashboards or notifications. Our work focus on increasing to ensure its robustness. Finally, since our ultimate goal is
trustworthiness and reliability of the overall system with improvingmonitoringtechniquesandprovidingbetterinsights
autonomous prediction of system occupation. to administrators, we would like to implement this method in
In academic research, [14] uses an approach with a ar- a real world scenario.
chitecture where each microservice makes self-management
ACKNOWLEDGMENT
concerningmonitoringandscaling.Thisapproachmayleadto
thediscardoftheimportanceofcallpaths,andthe“waterfall” This work was partially carried out under the project
effect that a microservice may have in others components. PTDC/EEI-ESS/1189/2014 — Data Science for Non-
In[15],atoolbasedintheglobalentropyofadistributedsys- Programmers, supported by COMPETE 2020, Portugal 2020-
tem is presented to automatically detect anomalies. However, POCI, UE-FEDER and FCT.
due to the fact that do not rely on response time and other
performance metrics it may lead to false positives. In [16], REFERENCES
[17],Malkowskietal.studiedbottlenecksinN-tiersystems,to
[1] “Pingdom,”https://www.pingdom.com/,retrieved:Jun,2017.
analyzemulti-bottlenecks,duetosaturation.Theymanagedto [2] “Bucky,”http://github.hubspot.com/bucky/,retrieved:Jun,2017.
conclude that lightly loaded resources may be responsible for [3] “Dynatrace,”https://www.dynatrace.com/platform/,retrievedMay,2017.
[4] R. Filipe and F. Araujo, “Client-side monitoring techniques for web
that phenomenon. In [18], authors try to discover bottlenecks
sites,” in 2016 IEEE 15th International Symposium on Network Com-
in data flow programs running in the cloud. They focus more putingandApplications(NCA),Oct2016,pp.363–366.
on CPU and I/O bottlenecks, and not predicting occupation. [5] R.Filipe,R.P.Paiva,andF.Araujo,“Client-sideblack-boxmonitoring
forwebsites,”in2017IEEE16thInternationalSymposiumonNetwork
In [19] the goal is to model web servers as single server ComputingandApplications(NCA),Oct2017,pp.1–5.
queues in terms of response time and overall system perfor- [6] “Nagios,”https://www.nagios.org/,retrievedSeptember,2018.
[7] “Zabbix,”https://www.zabbix.com/,retrievedSeptember,2018.
mance.[20]usesasimilarapproachforanApacheWebServer.
[8] A. Sen and M. Srivastava, Regression analysis: theory, methods, and
In[21],layeredqueueingnetworksareusedtomodelasystem applications. SpringerScience&BusinessMedia,2012.
withtwolayers–frontendandbackend. [22]presentsamodel [9] I.H.Witten,E.Frank,M.A.Hall,andC.J.Pal,DataMining:Practical
Machine Learning Tools and Techniques, 4th ed. Burlington, MA:
for Multi-tiered Web Applications using queues for individual
MorganKaufmann,2016.
componentssuchasCPU,I/OorNetwork.However,thereare [10] “Scikitlearn,”http://scikit-learn.org,retrievedJun,2018.
multiple points ofobservability, being this way asolution that [11] A. Ebert, P. Wu, K. Mengersen, and F. Ruggeri, “Computationally
Efficient Simulation of Queues: The R Package queuecomputer,” mar
although functional is more intrusive than ours. Our premise
2017.
is simplicity. We aim to automatically determine the overall [12] “NewRelic,”https://newrelic.com,retrievedMay,2017.
occupation of the system layers from exterior observations, [13] “Zipkin,”http://zipkin.io/,retrievedOct,2017.
[14] G. Toffetti, S. Brunner, M. Blo¨chlinger, F. Dudouet, and A. Edmonds,
meaningthemethodrequiresnoadditionalinstrumentationnor
“An architecture for self-managing microservices,” in Proceedings of
complex measurements. the1st International WorkshoponAutomated IncidentManagementin
Cloud,ser.AIMC’15. NewYork,NY,USA:ACM,2015,pp.19–24.
VI. CONCLUSIONSANDFUTUREWORK [15] H. Malik and E. M. Shakshuki, “Towards identifying performance
anomalies,” Procedia Computer Science, vol. 83, no. Supplement C,
Monitoring and observability of systems is a challenge pp.621–627,2016,the7thInternationalConferenceonAmbientSys-
tems, Networks and Technologies (ANT 2016) / The 6th International
for administrators, due to increased application elasticity,
ConferenceonSustainableEnergyInformationTechnology(SEIT-2016)
complexity, granularity and dynamics. The current tools put /AffiliatedWorkshops.
the burden of analysis, such as detecting bottlenecks and [16] S.Malkowski,M.Hedwig,J.Parekh,C.Pu,andA.Sahai,“Bottleneck
detection using statistical intervention analysis,” in Managing Virtual-
performanceissuesontheoperators.Asthenumberofservices
izationofNetworksandServices. Springer,2007,pp.122–134.
andtechnologiesinasystemincreases,sodoesthecomplexity [17] S.Malkowski,M.Hedwig,andC.Pu,“ExperimentalEvaluationofN-
andtimespentinoperationaltasks,suchasrootcauseanalysis. tier Systems: Observation and Analysis of Multi-Bottlenecks,” IISWC
’09: Proceedings of the 2009 IEEE 12th International Symposium on
Our goal is to identify the occupation of each component WorkloadCharacterization,2009.
on a two layer system. The evidence collected shows that it [18] “DetectingbottlenecksinparallelDAG-baseddataflowprograms,”2010
3rdWorkshoponMany-TaskComputingonGridsandSupercomputers,
is possible to identify the capacity and occupation of each
pp.1–10,2010.
layer, solely from the overall response time, as measured by [19] J. Cao, M. Andersson, C. Nyberg, and M. Kihl, “Web Server Perfor-
a client. Since the proposed method is not coupled to any mance Modeling using an M/G/1/K*PS Queue,” in 10th International
ConferenceonTelecommunications,ICT2003,vol.2,no.2,2003,pp.
infrastructureorlanguage,itcanbeusedinanykindofsystem
1501–1506.
where observability is a major concern. The two methods – [20] T. Van Do, U. R. Krieger, and R. Chakka, “Performance modeling
supervised machine learning and exponential decomposition of an apache web server with a dynamic pool of service processes,”
TelecommunicationSystems,vol.39,no.2,pp.117–129,2008.
– combined can complement each other’s shortcoming and
[21] Y. Shoaib and O. Das, “Web application performance modeling
provide insight about overall system performance. using layered queueing networks,” Electron. Notes Theor. Comput.
Sci., vol. 275, pp. 123–142, Sep. 2011. [Online]. Available:
As future work, there are several directions we want to
http://dx.doi.org/10.1016/j.entcs.2011.09.009
explore.Sincethetotalrequesttimedistributioncarriesenough [22] A. Kattepur and M. Nambiar, “Performance modeling of multi-tiered
information to infer the capacity of each system component, webapplicationswithvaryingservicedemands,”in2015IEEEInterna-
tional Parallel and Distributed Processing Symposium Workshop, May
we want to generalize our model, to more than a two layer
2015,pp.415–424.