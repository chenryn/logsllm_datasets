provide the result to be compared with the next com-
pleted instruction in introspection mode. The results
are read from the backlog buffer only during intro-
spection mode.
In our experiments, we assume that
the backlog buffer can store the results of 2K instruc-
tions. Section 5.2 analyzes the impact of varying the
size of the backlog buffer and Section 5.3 analyzes the
hardware cost of the backlog buffer.
3. Selection mechanism for load instructions: Because
store instructions update the D-cache in performance
mode, load instructions read their memory values from
the backlog buffer in introspection mode. A newly
added mux selects between the D-cache output and the
backlog buffer output, based on the mode of the pro-
cessor.
4. Comparator: A comparator is required to compare the
results of redundant execution with the results stored in
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:11 UTC from IEEE Xplore.  Restrictions apply. 
the backlog buffer. The comparator logic is accessed
after the retirement stage of the pipeline. If the inputs
to the comparator are different, an error is signaled in
introspection mode.
In addition, depending on the error handling policy, logic
for handling errors may be required.
3.2. Operation
A processor implementing MBI can be in performance
mode, introspection mode, or switching from one mode to
another. We describe the operation for all these cases.
• Operation in performance mode
In performance mode, the processor performs its nor-
mal operation without checking for errors resulting
from transient faults. When an instruction retires, it
updates the PERF ARF register ﬁle and its results are
also copied into the backlog buffer. Store instructions
update the D-cache and load instructions read their val-
ues from the D-cache.
• Operation in introspection mode
Instruction processing in introspection mode begins
with the oldest instruction that was retired in perfor-
mance mode but has not yet been processed in intro-
spection mode. In introspection mode, the processor
fetches the instructions from the I-cache and processes
them in the normal manner with four exceptions. First,
retired instructions update the ISPEC ARF register ﬁle.
Second, a load instruction reads its memory value from
the backlog buffer. Third, a store instruction does not
update the D-cache (memory system is not updated in
introspection mode). Finally, the prediction for a con-
ditional branch instruction is provided by the resolved
branch direction stored in the backlog buffer.
In in-
trospection mode, the processor does not update the
branch predictor. This allows the branch predictor to
retain its history information for performance mode.
When an instruction retires in introspection mode, its
result is compared with the result stored in the backlog
buffer. A match denotes correct operation, whereas a
mismatch is signaled as an error. We discuss error han-
dling policies in Section 6.
• Switching from performance mode to introspection
mode
A processor in performance mode can switch to intro-
spection mode due to any of the following reasons:
1. Long-latency L2 cache miss
When there is a long-latency L2 cache miss, the
instruction causing the cache miss will reach the
head of the reorder-buffer and stall retirement un-
til the cache miss gets serviced. When the in-
struction causing the cache miss reaches the head
of the reorder-buffer, the processor waits for 30
cycles and switches to introspection mode. The
30 cycle wait allows the in-ﬂight instructions to
execute and to possibly generate additional L2
misses.
2. Backlog buffer full
When the backlog buffer is full, the processor is
forced to enter introspection mode. This is done
to guarantee redundant execution, and, therefore,
transient fault coverage, for all instructions.
3. System call
Instructions retired in performance mode need to
go through redundant execution before the pro-
cessor executes a system call.4 This prevents ex-
ternal devices from accessing the possibly incor-
rect results of the instructions that have not been
verified through redundant execution. As system
calls are infrequent, entering introspection mode
before them does not cause a significant perfor-
mance degradation. For SPEC CPU2000 bench-
marks, only 0.0004% of the introspection mode
episodes were caused by system calls.
4. Self-modifying code
When self-modifying code is detected, the pro-
cessor is forced to enter introspection mode be-
fore modifying any of the instructions. Other-
wise, the two executions of the same instruc-
tion will likely give different results in perfor-
mance mode and introspection mode, even if
there is no transient fault. We do not have any
self-modifying code in our experiments because
we model the Alpha ISA, which disallows self-
modifying code.
If the processor switches from performance mode to
introspection mode because of a long-latency cache
miss,
the entry into introspection mode is called
normal-introspection. Entry into introspection mode
for any other reason is called forced-introspection. The
process of switching to introspection mode comprises
two activities. First, the mode bit is switched to indi-
cate introspection mode so that subsequent writes to
the ARF update the ISPEC ARF. Second, the pipeline
is ﬂushed and the PC from the ISPEC ARF is copied
into the PC of the fetch unit so that the processor be-
gins fetching the redundant instructions from the I-
cache.
4For critical system calls, such as the machine check exception, the
processor can transfer control without completing redundant execution of
all retired instructions.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:11 UTC from IEEE Xplore.  Restrictions apply. 
• Switching from introspection mode to performance
5. Results and Analysis
mode.
For normal-introspection, the processor returns to per-
formance mode when the long-latency cache miss gets
serviced or when the backlog buffer becomes empty,
whichever is earlier. On the other hand, for forced-
introspection,
the processor returns to performance
mode only when the backlog buffer becomes empty.
The process of returning to performance mode com-
prises two activities. First, the mode bit is switched to
indicate performance mode so that subsequent writes
to the ARF update the PERF ARF. Second, the pipeline
is ﬂushed and the PC of the PERF ARF is copied into
the PC of the fetch unit.
4. Experimental Methodology
The experiments were performed with SPEC CPU2000
benchmarks compiled for the Alpha ISA with the -fast
optimizations and profiling feedback enabled. We perform
our studies with the reference input set by fast-forwarding
up to 15 billion instructions and simulating up to 200M in-
structions.
We evaluate MBI by modeling it in an execution-driven
performance simulator. Our baseline processor is an ag-
gressive eight-wide out-of-order superscalar processor that
implements the Alpha ISA. Table 1 describes the baseline
configuration. Because MBI is primarily targeted towards
utilizing the idle cycles during long-latency cache misses,
we model the memory system in detail. We faithfully model
port contention, bank conﬂicts, bandwidth, and queuing de-
lays. The cache hierarchy includes a relatively large, 1MB,
L2 cache. Because some of the cache misses can be easily
prefetched using a prefetcher, our baseline also contains a
state-of-the-art streaming prefetcher [18].
Table 1. Baseline configuration.
Instruction cache
Branch Predictor
Decode/Issue
Execution units
Data Cache
Unified L2 cache
Memory
Bus
Prefetcher
16KB, 64B line-size, 4-way with LRU replacement;
8-wide fetch with 2 cycle access latency.
64K-entry gshare/64K-entry PAs hybrid with
64K-entry selector; 4K-entry, 4-way BTB;
minimum branch misprediction penalty is 24 cycles.
8-wide; reservation station contains 128 entries.
8 general purpose functional units;
All INT instructions, except multiply, take 1 cycle;
INT multiply takes 8 cycles.
All FP operations, except FP divide, take 4 cycles;
FP divide takes 16 cycles.
16KB, 64B line-size, 4-way with LRU replacement,
2-cycle hit latency, 128-entry MSHR.
1MB, 64B line-size, 8-way with LRU replacement,
15-cycle hit latency, 128-entry MSHR.
400-cycle minimum access latency; 32 banks.
16B-wide split-transaction bus at 4:1 speed ratio.
Stream-based prefetcher with 32 stream buffers.
5.1. Performance Overhead
MBI has two sources of performance overhead. The first
source is the latency involved in filling the pipeline after
switching from one mode to another. We call this over-
head the pipeline-fill penalty. The second source is forced-
introspection, which forces the processor to perform re-
dundant execution at the expense of performing its normal
operation. We call this overhead the forced-introspection
penalty.
Figure 4 shows the decrease in IPC of the baseline pro-
cessor when MBI is incorporated. To measure IPC, we only
count the instructions retired in performance mode. We
measure the IPC overhead for a suite by first calculating the
harmonic mean IPC of the baseline for the suite, then cal-
culating the harmonic mean IPC for the suite when MBI is
incorporated, and taking the percentage difference between
the two harmonic means.
C
P
I
n
i
n
o
i
t
c
u
d
e
R
%
50
45
40
35
30
25
20
15
10
5
0
 mcf
 am m p
 lucas
 art
 wupwise
 twolf
 apsi
 facerec
 swim
 vpr
 vortex
 galgel
 bzip2
 gcc
 m grid
 equake
 parser
 applu
 mesa
 perlbm k
 sixtrack
 crafty
 gzip
 gap
 fma3d
 eon
HIGH-MEM CATEGORY
LOW-MEM CATEGORY
-
L
L
A
G
V
A
-
M
E
M
H
G
H
G
V
A
-
I
Figure 4. IPC reduction due to the MBI mechanism.
For benchmarks in the HIGH-MEM category, the IPC
overhead due to MBI is fairly low, averaging only 7.1%.
The average IPC overhead for all the 26 benchmarks is
14.5%. For mcf, art, twolf, vpr and swim, the IPC reduc-
tion is well below 5%. These benchmarks are memory in-
tensive and have frequent stalls due to long-latency cache
misses. For lucas, ammp, and wupwise, the IPC reduction
ranges from 12% to 16%. The bursty L2 cache miss be-
havior of these three benchmarks results in a high IPC over-
head even though these benchmarks spend more than half of
their execution time waiting for memory. In some of these
benchmarks, the program passes through two phases, P1
and P2, each phase containing many more instructions than
the size of the backlog buffer. Phase P1 causes a lot of long-
latency cache misses and therefore results in a lot of spare
processing bandwidth, whereas phase P2 does not contain
any long-latency cache misses. Phases P1 and P2 repeat
in an alternating pattern. Even though there is significant
spare processing bandwidth during P1, instructions in P2
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:11 UTC from IEEE Xplore.  Restrictions apply. 
cannot utilize it for redundant execution and the processor
is frequently forced to enter forced-introspection during P2,
which causes the reduction in IPC.
For benchmarks in the LOW-MEM category, the perfor-
mance overhead is high. All benchmarks, with the excep-
tion of vortex and parser, incur an IPC reduction of more
than 30%. For the LOW-MEM benchmarks when the pro-
cessor enters introspection mode, it is almost always be-
cause the backlog buffer is full. This results in frequent
incurrence of the forced-introspection penalty.
5.2. Impact of the Size of the Backlog Buffer
In the previous section, we assumed that the backlog
buffer can store the results of 2K instructions. In this sec-
tion, we analyze the sensitivity of the IPC overhead of MBI
to the capacity of the backlog buffer. We vary the size of the
backlog buffer from 1K entries to 4K entries and measure
the IPC overhead. Figure 5 shows the IPC variations when
the size of the backlog buffer is changed.
C
P
I
n
i
n
o
i
t
c
u
d
e
R
%
25
20
15
10
5
0
gcc
average
ammp
art
1K
2K
4K
Figure 5. Sensitivity of the IPC overhead to the size of the back-
log buffer. Y-axis represents the IPC overhead and X-axis rep-
resents the number of entries in the backlog buffer.
The IPC-overhead for ammp decreases from 14.9% to
9.2% as the backlog buffer size is increased from 1K-entry
to 4K-entry because a larger backlog buffer can reduce the
number of costly forced-introspection episodes. Bench-
mark art has a steady IPC overhead of 3.6% for all three
sizes of the backlog buffer. Art has frequent long-latency
cache misses, which obviates the need for a large backlog
buffer. Benchmark gcc has a large instruction working-set
size, and therefore it shows a slight increase in the IPC over-
head when the size of the backlog buffer is increased. A
large backlog buffer can increase the I-cache miss rate in
introspection mode, which in turn can increase the I-cache