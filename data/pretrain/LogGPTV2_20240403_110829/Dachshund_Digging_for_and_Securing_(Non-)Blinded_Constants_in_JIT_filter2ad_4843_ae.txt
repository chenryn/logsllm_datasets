7
1
7
5
7
,
2
1
0
1
3
,
1
7
8
2
,
4
4
1
8
2
,
5
3
7
4
1
,
7
4
8
5
5
,
9
3
2
2
6
,
8
3
3
0
0
,
9
0
5
5
,
9
0
2
2
,
9
7
3
3
,
1
3
0
3
,
3
7
9
1
,
4
2
0
7
,
2
8
8
5
,
3
2
7
6
6
,
3
2
6
6
3
,
1
1
Richards
DeltaBlue
Crypto
RayTrace
EarleyBoyer
RegExp
Splay
NavierStokes
PdfJS
Mandreel
Gameboy
CodeLoad
Box2D
zlib
Typescript
Fig. 7. Octane results in Chrome (Original vs Proxy vs Not-Optimized)
VI. DISCUSSION
In this section, we revisit the two proposed frameworks,
and discuss their implications and possible limitations.
A. Implications of Dachshund
DACHSHUND has revealed several ways attackers can inject
arbitrary long gadgets into JIT-compiled code. We will now
discuss how this is relevant from a security perspective.
How bad is attacker-induced shellcode, really?
One could argue that additional defense schemes in browsers
will protect against control-ﬂow diversion attacks, regardless
of whether an attacker can inject shellcode or not. While
is not wrong per se, we believe that our
this argument
ﬁndings have important implications anyway. First, constant
blinding is part of the two most popular browsers, and—as we
ﬁnd—a security feature that can be easily circumvented by
attackers. Relying on such schemes is only helpful if they are
also implemented correctly. Otherwise, as we ﬁnd, they give
security guarantees that do not hold in practice. Second, attacks
in the past have demonstrated that even additional security
mechanisms such as CFI or sandboxing cannot protect against
successful browser exploitation. We thus argue that it is not
an “either-or” question which security mechanisms to use; we
see the need for complementary techniques to defend against
browser threats. Finally, predictable gadgets may also have
severe security implications on even stronger threat models.
For example, assuming that the location of gadgets can be
identiﬁed, schemes that propose non-readable code (such as
Execute-no-Read proposals [3], [12], [13]) can potentially be
evaded. We will perform such an evaluation in future work.
Does it matter that you found four-byte constants?
DACHSHUND is not the ﬁrst work to target constant blinding
schemes. Athanasakis et al. [2] had already proven that two-
byte constants are sufﬁcient to assemble suitable ROP chains.
However, we looked at the problem from a different angle.
Instead of using constants that are excluded from the blinding
process (because they are too short), we inspected whether
constants actually survive constant blinding. Indeed, four-byte
gadgets give an adversary more ﬂexibility in the types of
gadgets to use and make building a ROP chain signiﬁcantly
easier. But the more fundamental observation is the fact that
we found that constants that should have been blinded were,
in fact, not successfully blinded.
B. Limitations of Dachshund
DACHSHUND uses code fuzzing, which is known to be
incomplete in terms of code coverage and cases that it explores.
We have shown that our technique is quite successful for
discovering leftover constants in JIT-compiled code. However,
similar to other fuzzing techniques, DACHSHUND cannot be
used to prove that JIT engines do not emit attacker-controlled
constants. DACHSHUND could be combined with static code
analysis to fulﬁll this higher goal.
Furthermore, DACHSHUND leverages immediate constants
in JavaScript code to evade constant blinding. It may also be
possible to ﬁnd other types of attacker-controllable constants,
such as values embedded in control-ﬂow statements (e.g.,
constants encoded in relative offsets). However, our ﬁndings
show that an attacker does not even need to search for other
types of constants, given plenty of immediate ones.
C. Limitations of the Defense
Our proposal to defend against constants has certain lim-
itations, which we address next. As already mentioned, our
proxy-based solution requires that HTTPS-secured content can
also be rewritten. This means that certiﬁcate validation will be
done by the proxy and the client needs to trust certiﬁcates
handed out by the proxy. However, in corporate settings, such
HTTPS-enabled proxies are quite common and serve to inspect
client communication for multiple purposes (e.g., caching,
protecting against information leakage, identifying HTTPS-
based malware communication, etc.) Our rewriting logic can
easily be integrated into existing proxies.
An alternative to a proxy implementation would be to
embed our method as a browser extension. This way users
will have more control over the rewriter, e.g., they can request
on-demand rewriting of certain pages or whitelist
trusted
pages. Also, HTTPS-based content will be no problem for
an extension-based rewriter, as rewriting happens after a page
is already loaded. However, the extension will face a race
11
condition with the running JavaScript, i.e., JavaScript on the
page may be executed before the extension ﬁnishes rewriting.
This problem can be solved by disabling JavaScript execution
for all pages until the rewriter terminates.
A technical challenge for our solution is potential deﬁ-
ciencies in the HTML/JavaScript parser. We might face cases
in which the parser fails to parse the code. There are two
possibilities for dealing with unparsable scripts: (i) we block
the script, or (ii) we allow the script without modiﬁcation.
Solution (ii) lowers the security, because an adversary may
ﬁnd out a way to create a script that is unparsable but is still
tolerated (and executed) in browsers. However, using (i) may
block scripts that come from legitimate sources, thus modify-
ing the semantics of the page. A solution to the aforementioned
problem could be to extract all immediate constants by alter-
native means (e.g., using regular expressions) from unparsable
scripts and replace them with the safe alternatives. However, in
summary, non-parseable scripts are not a fundamental problem
of our approach, but more a technical challenge for parser
implementations.
One weakness of our defense technique is that future JIT
compilers might convert global objects into integers as part
of the JIT code optimization. The basic idea why we replace
integer constants with global objects is that the global variables
in JavaScript are volatile and can be modiﬁed by every function
running in the same context, e.g., by a JavaScript function
running at some time intervals. Therefore, these global vari-
ables, even though they encode integer values, will not be
inlined. However, if a global variable is ﬁrst moved into a local
variable, then the local variable can be inlined if necessary. We
manually tested multiple such cases in Chrome and found out
that the JIT compiler of Chrome does not inline such variables.
However, in the future, if the compiler is extended to also inline
these variables, our rewriter has to be adapted accordingly.
Furthermore, we unfortunately have no way to prove the
completeness of the rewriter. For example, our current proto-
type implementation does not cover all border cases of implicit
conversions. In our JavaScript rewriter, we account for implicit
conversions between a string and a number, e.g., from the
string ’123’ to the number 123. JavaScript, however, allows
more cases of allowed implicit conversions. For example, using
Boolean constants true and false as numbers 1 and 0
respectively (true+true is 2, true*100 is 100). Similarly,
unary operators can be applied to various types of JavaScript
objects to convert them to integers. For example, +[] equals
to 0, and +!![] equals to 1. These types of conversions are
used by JavaScript obfuscators to hide the source code [32]. As
Edge only caches (i.e., emits in JIT-code) integer constants that
are directly encoded as immediate values in JavaScript, these
implicit conversions will not be a problem for it. However, they
can still be emitted by the optimizing compiler of Chrome.
By manual veriﬁcation, we found out that these cases are not
optimized by Chrome’s current JIT compiler and therefore can
be ignored by our defense altogether. In the future, if these
values get inlined into the executable code, our defense can
be easily extended to also cover them.
Apart from immediate constants, an attacker might encode
implicit constants in JITted code. She can do so by abusing
other parts of the JavaScript code that indirectly inﬂuence
values encoded in JIT-compiled code. For example, parameters
on the stack are referenced by adding their offset to rbp. The
offset is encoded as a part of the instruction, and thus is emitted
to the code. By varying the number of function parameters,
the attacker might generate useful gadgets. However,
this
attack is limited by the number of possible arguments that
a function can have, limiting the attacker to incomplete two
bytes. Alternatively, Maisuradze et al. [36] demonstrated that
an adversary can use relative offsets encoded in control ﬂow
instructions (e.g., conditional jumps or calls). By carefully
choosing certain code sizes, attackers can change the values en-
coded in these instructions, such as relative offsets of branches
(e.g., if/else) or calls (e.g., between caller and callee).
Complementary techniques, such as code randomization (e.g.,
NOP insertions) or control-ﬂow-changing code rewriting might
help to defend against such cases as a probabilistic defense.
We leave these ideas open for future work.
The discussion above has shown that we are not aware
of any obfuscation technique that evades our defense. That
said, it might be possible that JIT compilers change, or simply
that attackers may ﬁnd novel evasion tricks that we have not
discussed. In any case, this is not a fundamental limitation of
our defense, but (as the examples above show) we can likely
further improve code rewriting to gain complete coverage over
any attacker-controlled constant that we might have missed in
the current prototype implementation.
VII. RELATED WORK
In the following, we survey related work, including an evo-
lution of attack techniques and their corresponding defenses.
A. ASLR vs. Code-Reuse Attacks
ASLR continues to be the most-widely deployed defense
against code-reuse attacks [50]. However, apart from being in-
complete [46] (i.e., not being applied to all memory segments)
or having low entropy due to a 32-bit systems [48], ASLR
is also vulnerable to code-reuse attacks utilizing information
leakage [31], [17], [5]. To make up for ASLR’s weaknesses,
ﬁne-grained randomization schemes complement ASLR by
randomizing the code within memory segments reordered by
ASLR. Therefore,
leaking a code pointer does not reveal
any information about the remaining code in that page. For
example, Pappas et al. [43] randomize instructions inside basic
blocks by code rewriting. ASLP, by Kil et al. [33], shufﬂes the
addresses of functions along with important data structures
by statically rewriting an executable. STIR, by Wartell et
al. [51], permutes basic blocks of the program at startup. Lu et
al. advance these schemes by providing a practical runtime re-
randomization solution [35].
However, scripting environments enabled attackers to lever-
age information leak to bypass ASLR. In JIT-ROP [49], Snow
et al. demonstrated that by repeatedly exploiting a memory
disclosure vulnerability, the attacker can read code pages of a
program and generate a gadget chain on the ﬂy.
Closest related to our work, Athanasakis et al. [2] em-
powered JIT-ROP by utilizing the code output from the JIT
compilers to inject
their own gadgets. Knowing that JIT
engines do not blind smaller constants, they show that an
attacker may be able to carefully align two-byte gadgets to
mount successful attacks. We follow the same motivation,
12
but show that the deﬁciencies of constant blinding are far
more fundamental than ignoring small constants. DACHSHUND
has proven that constant blinding implementations in modern
browsers are inherently incomplete, irrespective of the size of
the constants. In addition, we propose and implement a viable
defense against attacker-induced gadgets in JavaScript code.
B. Defenses against Code Reuse
Researchers have proposed various defenses against code-
reuse attacks, as summarized in the following.
Non-Readable Code: Backes et al. [3] and Crane et
al. [12] proposed tackling JIT-ROP attacks by forbidding
the attacker to read executable pages of the program. XnR
(Execute-no-Read) marks executable pages as non-present and
utilizes a page-fault handler to allow only valid accesses (i.e.,
instruction fetches). Similarly, Readactor uses Extended Page
Tables (EPT) to mark all executable pages as non-readable
and applies ﬁne-grained randomization to all executable pages.
Some remaining weaknesses of Readactor (e.g., function point-
ers in import tables and vtables) have been resolved in its
successor Readactor++ [13]. Targeting ARM, also Braden et
al. [8] suggest to leverage execute-only memory to protect
against code-reuse attacks. Finally, Gionta et al. suggest to
hide code via a split TLB [24].
Although the idea of non-readable code is promising,
withdrawing read privileges alone does not sufﬁce to protect
against attacker-induced gadgets, in particular if gadgets are
deterministic and their locations predictable. This is also the
reason why the schemes are typically combined with ﬁne-
grained randomization schemes, and hence,
their security
against our attack heavily depends on the randomization.
Control Flow Integrity: CFI schemes restrict the control
ﬂow to valid code paths. CFI implementations range from
coarse-grained to ﬁne-grained schemes [55], [56], [14], [37],
[55], following the typical compromise between efﬁciency and
security [15], [25]. Shying the complexity of JIT engines, few
CFI schemes have been tested on JIT compilers. One of the
notable exceptions is NaCl SFI [1], which provides a coarse-
grained CFI implementation for JIT engines, but faces an over-
head of 51% on x64 systems. Similarly, RockJIT instruments
JIT-compiled code with coarse-grained checks, verifying the
control ﬂow instruction targets at runtime. Forcing the jump