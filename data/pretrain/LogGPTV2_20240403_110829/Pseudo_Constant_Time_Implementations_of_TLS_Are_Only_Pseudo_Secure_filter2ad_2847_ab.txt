scribes our synchronized probe PRIME+PROBE attack on Amazon’s s2n implementa-
tion and Section 5 provides details on how to optimize the full byte plaintext recovery.
Section 6 describes our synchronized prime PRIME+PROBE attack on mbed TLS,
GnuTLS and wolfSSL. In Section 7 we introduce our novel “PostFetch” attack on the
mbed TLS implementation. Finally, Section 8 discusses the results and raises some
open questions.
2 Further Background
2.1 TLS Record Processing and the Lucky 13 Attack
For a detailed account of how TLS is processing records in CBC-mode cipher suites
and how this enables the Lucky 13 attack, see [3,2]. We present here a highly com-
pressed version of this information heavily based on [2] in order to make the paper
self-contained.
A TLS record R (viewed as a byte sequence) is processed as follows. The sender
has an 8-byte per-record sequence number SQN, and forms a 5-byte ﬁeld HDR consisting
of a 2-byte version ﬁeld, a 1-byte type ﬁeld, and a 2-byte length ﬁeld. The sender then
calculates a MAC over the bytes SQN||HDR||R; let T denote the resulting MAC tag. The
size t of the MAC tag depends on the hash function speciﬁed for use in HMAC in the
cipher suite.
The record is encoded by setting P = R||T||pad. Here pad is a sequence of padding
bytes chosen such that the length of P in bytes is a multiple of the block-size b of the
selected block cipher (b = 16 for AES). In TLS, the padding must consist of p+1 copies
of some byte value p, where 0 ≤ p ≤ 255. Implementations typically use the last byte
of pad as an indicator of the padding length to determine how many padding bytes
should be present in a record and what values those bytes should take.
In the encryption step, the encoded record P is encrypted using CBC-mode of
the selected block cipher. TLS 1.1 and 1.2 mandate an explicit IV, which should be
randomly generated. TLS 1.0 (and SSL) use a chained IV. Thus, the ciphertext blocks
are computed as:
Cj = EKe (Pj ⊕ Cj−1)
where Pi are the blocks of P , C0 is the IV, and Ke is the key for the block cipher E.
The ﬁnal ciphertext data has the form:
HDR||C
where C is the concatenation of the blocks Ci (including or excluding the IV depending
on the particular SSL or TLS version). Note that the sequence number is not trans-
mitted as part of the message.
At a high level, the decryption process reverses this sequence of steps: ﬁrst the
ciphertext is decrypted block by block to recover the plaintext blocks:
Pj = DKe (Cj) ⊕ Cj−1,
where D denotes the decryption algorithm of the block cipher. Then the padding is
checked and removed, and ﬁnally, the MAC is checked. However, these operations must
be performed without leaking any information about what the make-up of the plaintext
Pseudo Constant Time Implementations of TLS Are Only Pseudo Secure
7
blocks is in terms of message, MAC ﬁeld and padding, and whether the format is valid.
Prior literature including [9,3,5,2,4] illustrates the diﬃculties of doing this securely.
As a ﬂavour of what can go wrong, consider an attacker that wishes to decrypt a
target ciphertext block C∗; let C∗
−1 denote the preceding block in the sequence of ci-
phertext blocks. The attacker intercepts a ciphertext HDR||C and injects HDR(cid:48)||C||C∗
−1⊕
∆||C∗ so that it is received in the sequence of TLS records. Here HDR(cid:48) is a modiﬁed
header containing the correct length ﬁeld and ∆ is a block-size mask. A naive imple-
mentation might treat the last block of this ciphertext as containing padding, check its
validity, and then either send a padding error message or extract and verify the MAC.
By construction, the last block is equal to P ∗ ⊕ ∆, where P ∗ is the (unknown) target
plaintext block. Whether or not the padding is valid therefore leaks information about
P ∗ ⊕ ∆, and thence about P ∗. By varying the value of ∆ across diﬀerent injected TLS
records, the attacker can gradually build up information about P ∗, possibly recovering
it in its entirety.
In reality, attacks against CBC-mode in TLS are more complex than this:
– First, all errors are fatal, meaning that the connection is terminated and the key
is thrown away. However, an attacker can aim to recover plaintext blocks that
are repeated in predictable locations over many connections, e.g. HTTP cookies,
with client-side malicious JavaScript being used to initiate the required connections
and the cookies being automatically injected into connections by the victim’s web
browser.
– Second, the error messages are encrypted, so the attacker cannot directly learn
whether or not the padding is valid. Instead, the leakage typically comes from timing
information. For example, in the above discussion, we assumed that the MAC was
only checked if the padding is good; of course the MAC veriﬁcation will fail with
overwhelming probability, and the error condition will then leak through the timing
of the error message, which can be measured by an attacker located on the network.
– Third, such large timing diﬀerences are no longer present in implementations, due
to patching. In particular, in view of the attacks of [33,9], the TLS 1.1 and 1.2
speciﬁcations recommend checking the MAC even if the padding is bad, and doing
so on a synthetic message whose length is equal to that of the plaintext (i.e. as if
the padding had zero length). This reduces, but does not completely eliminate the
timing diﬀerences; the remaining timing variation was exploited in Lucky 13 [3].
– Fourth, as the timing diﬀerences have become smaller through patching, so network
noise has made mounting the attacks remotely progressively harder. This in part
motivates cache-based attacks with a co-located attacker, like those in [5] and here.
2.2 Cache attacks
Cache attacks have become one of the most proliﬁc types of attack against crypto-
graphic primitives, using diﬀerent techniques for measuring leakage of secret values
(e.g. [30,38,23,16]). Those diﬀerent techniques were used to break real world crypto-
graphic implementations (e.g. [17,39,37,6,8,19,15]). The assumption that the attacker
can run code on the same platform as the target’s process is now widely accepted and
used, including in the recent Meltdown [22] and Spectre [20] attacks.
Some cache attacks (e.g. [38] required shared memory between the attacker and
target processes. Memory might be shared between diﬀerent processes or even VMs
8
Eyal Ronen, Kenneth G. Paterson, and Adi Shamir
due to memory deduplication. Memory deduplication optimizations (e.g. KSM), allow
two or more processes or VMs to share identical memory pages (e.g. shared library
code or constants). However, due to the discovered security implications, today they are
disabled between diﬀerent VMs by IaaS providers [23]. Using more advanced techniques
such as those in [23,16,21] cross-VM attacks are now practical even when memory
deduplication is disabled.
Our cache attack techniques are based on the PRIME+PROBE [30] attack vari-
ant of Liu et al. [23] that allows cross-VM attacks. The Mastik [36] toolkit contains
an implementation of this attack. We will give a short description of the general
PRIME+PROBE attack (for a detailed account of the techniques see [23]). The main
idea is that the access time to data that is stored in the cache is much smaller than
for data that is stored in main memory. In the ﬁrst PRIME phase of the attack, the
attacker ﬁlls the part of the cache that will hold the target’s data by accessing its own
data in speciﬁc memory locations. In the second PROBE phase, the attacker tests if
part of its data was evicted from the cache by measuring the access time to its own
data. If all of the data is still in the cache, the target’s data was not accessed. Oth-
erwise, either the target’s data was accessed, or some other code forced the eviction
of the attacker’s data. If the target’s code access pattern to its data is determined by
some secret value, the attacker can learn this value.
3
Implementation Bugs in Lucky13 Countermeasures
Pseudo constant time countermeasures are very hard to get right and maintain over
time. This is due both to the possibility of ﬁnding novel variants of the original at-
tacks, and the need to manually check the timing implications of adding new features.
In contrast, real constant time implementations are more robust against novel attack
variants, and bugs created by supporting new features will likely be found by unit-
testing. TLS 1.2 [12] added new ciphers suites based on CBC-mode for encryption and
HMAC-SHA-384 for integrity. The SHA-384 hash function is considered more secure,
and also has better performance on 64-bit processors, than the previously supported
SHA-1 and SHA-256 algorithms. We tested if TLS implementations supporting HMAC-
SHA-384 are vulnerable to timing attacks similar to the one described in [2]. All of
the constant-time implementations that we checked (OpenSSL, BoringSSL, NSS) were
secure. However, all of the ”pseudo” constant time implementations (i.e. those only
ensuring a constant number of compression function calls) had bugs making them vul-
nerable to attack. The reason for the bugs is that, although the SHA-384 cipher suites
were added, the code responsible for adding dummy compression function calls was not
updated correctly. Speciﬁcally, SHA-384 has a 128-byte block size (compared to the
64-byte blocks of SHA-256), and encodes the message length using 16 bytes (compared
to 8 bytes in SHA-256). All of the extra compression function call calculations have
hard-coded values appropriate for SHA-256 but not SHA-384, resulting in them using
a non-constant number of calls to the SHA-384 compression function. We explain in
more detail below for each of the four ”pseudo” constant time implementations we
studied; since the bugs are easily ﬁxed, we do not go into great detail on how each bug
leads to a plaintext recovery attack.
Pseudo Constant Time Implementations of TLS Are Only Pseudo Secure
9
3.1 GnuTLS Implementation
Although the function dummy_wait (see Listing 1.3 in Appendix A) uses the correct
hash block size, it also uses the hard-coded number ”9”. This comes from at least 1 byte
for the the hash function padding and the 8 bytes used to encode the hashed message
length for SHA-256. However, in SHA-384, the message length is encoded using 16
bytes, and so the correct value should be ”17” rather than ”9”. The code includes a
comment warning that this is a hash-speciﬁc ﬁx, but it was apparently not corrected
when the SHA-384 cipher suites were added.
Even more surprisingly, we discovered that the GnuTLS Implementation is vul-
nerable to a timing attack when SHA-256 is selected as the hash algorithm in HMAC,
despite this having been patched in response to Lucky 13 [27]. The function dummy_wait
can add at most one call to the hash compression function. However, the attack de-
scribed in Section 6.3 creates a padding oracle that distinguishes between a valid pad
of a large length (PadLen > 240) and an invalid padding (PadLen = 0). In that case,
for GnuTLS, there will be a timing diﬀerence of 3 calls to the compression function
of SHA-256, that is 3 times larger than the timing diﬀerence in the original Lucky 13
attack [3].
3.2 mbed TLS Implementation
The function ssl_decrypt_buf (see Listing 1.8 in Appendix A) uses the hard-coded
value ”64” (for block size) and ”8” (for message length encoding). These should be ”128”
and ”16”, respectively, for SHA-384. For example, HMAC veriﬁcation of a decrypted
TLS record of length 512 and valid padding of length in the range PadLen = 229 will
result in 3 more compression functions call than same length TLS record with invalid
padding (PadLen = 0). Again we can use the attack described in Section 6.3 to create
a padding oracle to distinguish between the two cases, resulting in a timing diﬀerence
much larger than the one in the original Lucky 13 attack [3].
3.3 WolfSSL Implementation
The function GetRounds (see Listing 1.5 in Appendix A) uses the hard-coded numbers
”64” and ”55” (64-8-1). These should be ”128” and ”111”, respectively, for SHA-384.
The same attack described in Appendix 3.2 can also be used against the WolfSSL
implementation.
3.4 Amazon’s s2n Implementation
The s2n_hmac_digest_two_compression_rounds function (see Listing 1.1) can add
one dummy compression function call. The calculation of the condition uses the hard-
coded number 9 as the minimal number of bytes to add, whereas 17 would be appro-
priate for SHA-384. This bug was not detected during the formal veriﬁcation of the
HMAC code carried out by Galois [13]. However, unlike our new cache attack for s2n
presented in Section 4, the attack arising from this bug (modeled on that in [2]) is likely
to be impractical due to the random delay protection in s2n.
10
Eyal Ronen, Kenneth G. Paterson, and Adi Shamir
4 A Cache-based Padding Oracle in Amazon’s s2n
Implementation
Amazon’s s2n TLS implementation is responsible for protecting all of the traﬃc to
Amazon’s S3 cloud storage service [31]. This implementation was previously analysed by
Albrecht and Paterson [2] and found vulnerable to a variant of the Lucky 13 attack. The
current protection includes a pseudo constant time implementation, and the inclusion
of a very high resolution and large random delay after detecting any error in TLS
decryption. This causes previous timing attacks to become impractical. Moreover, the
correctness of s2n’s patched HMAC implementation was formally veriﬁed [13].
However, as we will see, the memory access pattern in s2n depends on the padding
length byte (i.e. the last byte of the decrypted TLS record). We will use a PRIME+PROBE [30]
cache attack to build a new padding oracle for s2n. We assume a cache side-channel as
in Liu et al. [23], and describe two versions of our attack on s2n: In a simpliﬁed version,
we target the speciﬁc code written to block the attack in [2]. However, this attack is not
practical due to an ad hoc programming decision in s2n. In our full synchronized probe
PRIME+PROBE attack, we exploit the same programming decision, but using the
probability of cache hits and misses as an indicator of padding length. Our full attack
works on HMAC using both SHA-384 and SHA-256, even if the simple bug described
in Appendix 3.4 is ﬁxed.
4.1 Attack Preliminaries
In both attacks the cache side-channel arises from the access pattern to a dynamically
allocated memory location, more speciﬁcally a buﬀer used to store part of the key in
the HMAC calculation. We ﬁrst have to ﬁnd the mapping of this location to the right
cache set, by exploiting a design decision of the s2n developers: All the structures and
memory buﬀers required for a speciﬁc connection in s2n are allocated in the handshake
phase and are reused for all messages. We can then ﬁnd the right cache set in the
same manner as in [23]. For each handshake, we trace the cache set while processing
valid messages, and ﬁnd the cache set exhibiting the activity pattern we expect for the
HMAC code.
4.2 Simpliﬁed Attack
The attack described in [2] is based on the following fact: If we split a message
into two parts, and hash each of them separately, the number of calls to the inter-
nal hash compression function might vary depending on the split point. This is due
to the padding and length bytes added internally by the hash function. A new func-
tion s2n_hmac_digest_two_compression_rounds (see Listing 1.1 in Appendix A) was
added to the HMAC API in s2n to block this attack vector. This function makes two
calls to the internal hash compression function, even if the hash padding doesn’t neces-
sitate it. The function checks if the hash padding will require another compression call.
If not, it will reset the hash context and call another update function. In that case, the
buﬀer that is sent to the update function is the HMAC state buﬀer called xor_pad.
The only other place this buﬀer is used is in the HMAC initialization function, and
that is called only once, in the TLS handshake.
Pseudo Constant Time Implementations of TLS Are Only Pseudo Secure
11
xor pad ← FindXorPadCache(valid msg)
Prime(xor pad)
Send attacker’s TLS record to target
Algorithm 1 s2n Simpliﬁed Attack
1: function SimplifiedS2NPadOracle(valid msg,attack msg)
2:
3:
4:
5: Wait for veriﬁcation error
6:
7: