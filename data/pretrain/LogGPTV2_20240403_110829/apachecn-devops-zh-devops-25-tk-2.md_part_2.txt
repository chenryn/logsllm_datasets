 6      --set sslCertPath=/etc/kubernetes/pki/ca.crt \
 7      --set rbac.create=true
 8
9  kubectl -n kube-system \
10      rollout status \
11      deployment aws-cluster-autoscaler
```
部署推出后，自动缩放器应该可以完全运行。
# 在 AKS 中设置集群自动缩放器
在撰写本文时(2018 年 10 月)，Cluster Autoscaler 不在 AKS 工作。至少，不总是。目前还在测试阶段，暂时还不能推荐。希望它将很快全面投入运行并保持稳定。当这种情况发生时，我将使用特定于 AKS 的说明更新这一章。如果您觉得有冒险精神或者您致力于 Azure，请按照 Azure Kubernetes 服务(AKS) -预览([https://docs . Microsoft . com/en-in/Azure/AKS/Cluster-Autoscaler](https://docs.microsoft.com/en-in/azure/aks/cluster-autoscaler))文章中的说明进行操作。如果它有效，你应该能够遵循本章的其余部分。
# 扩大集群规模
目标是扩展我们集群的节点，以满足我们 Pods 的需求。我们不仅希望在需要额外容量时增加工作节点的数量，还希望在未充分利用时将其删除。现在，我们将专注于前者，然后探索后者。
让我们先来看看集群中有多少节点。
```
 1  kubectl get nodes
```
来自 GKE 的输出如下。
```
NAME             STATUS ROLES  AGE   VERSION
gke-devops25-... Ready   5m27s v1.9.7-gke.6
gke-devops25-... Ready   5m28s v1.9.7-gke.6
gke-devops25-... Ready   5m24s v1.9.7-gke.6
```
在您的情况下，节点的数量可能不同。那不重要。重要的是记住你现在有多少，因为这个数字很快就会改变。
在推出`go-demo-5`应用之前，让我们先看看它的定义。
```
 1  cat scaling/go-demo-5-many.yml
```
输出限于相关部分，如下所示。
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
  namespace: go-demo-5
spec:
  ...
  template:
    ...
    spec:
      containers:
      - name: api
        ...
        resources:
          limits:
            memory: 1Gi
            cpu: 0.1
          requests:
            memory: 500Mi
            cpu: 0.01
...
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: api
  namespace: go-demo-5
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 15
  maxReplicas: 30
  ...
```
在这种情况下，我们即将应用的定义中唯一重要的部分是与`api`部署相关联的 HPA。其最小副本数为`15`。假设每个`api`容器请求 500 兆内存，假设它是使用其中一个 Gists 创建的，那么 15 个副本(7.5 千兆内存)应该超过我们的集群所能承受的。否则，您可能需要增加副本的最小数量。
让我们应用这个定义，看看住房公积金。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-many.yml \
 3      --record
 4
 5  kubectl -n go-demo-5 get hpa
```
后一个命令的输出如下。
```
NAME   REFERENCE        TARGETS                        MINPODS   MAXPODS   REPLICAS   AGE
api    Deployment/api   /80%, /80%   15        30        1          38s
db     StatefulSet/db   /80%, /80%   3         5         1          40s
```
目标是否还是`unknown`不重要。他们很快就会被计算出来，但是我们现在不关心他们。重要的是`api` HPA 将至少将部署扩展到`15`副本。
接下来，我们需要等待几秒钟，然后才能查看`go-demo-5`名称空间中的 Pods。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME    READY STATUS            RESTARTS AGE
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   Pending           0        2s
api-... 0/1   Pending           0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 1        32s
api-... 0/1   Pending           0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   Pending           0        2s
api-... 0/1   ContainerCreating 0        2s
api-... 0/1   ContainerCreating 0        2s
db-0    2/2   Running           0        34s
db-1    0/2   ContainerCreating 0        34s
```
我们可以看到一些`api`吊舱正在被创建，而其他的正在等待。Pod 进入挂起状态的原因有很多。
在我们的例子中，没有足够的可用资源来托管所有的 Pods。
![](img/a1c839db-c439-4994-a113-8b0a27c59e84.png)
Figure 2-1: Unschedulable (pending) Pods waiting for the cluster capacity to increase
让我们看看集群自动缩放器是否对我们的容量不足有所帮助。我们将探索包含集群自动缩放器状态的配置映射。
```
 1  kubectl -n kube-system get cm \
 2      cluster-autoscaler-status \
 3      -o yaml
```
输出太大，无法完整呈现，因此我们将重点关注重要的部分。
```
apiVersion: v1
data:
  status: |+
    Cluster-autoscaler status at 2018-10-03 ...
    Cluster-wide:
      ...
      ScaleUp: InProgress (ready=3 registered=3)
    ... 
    NodeGroups:
      Name:    ...gke-devops25-default-pool-ce277413-grp
      ...
      ScaleUp: InProgress (ready=1 cloudProviderTarget=2)
               ...
```