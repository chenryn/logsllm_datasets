### System Performance and Scalability

The system performance is stable, with a consumption rate maintained within 90%. The CPU utilization rate is approximately 6%, with occasional spikes. These metrics indicate that Xede is scalable for parallel exploit detection.

### Figures

**Figure 6.** Increased CPU consumption by Xede compared with QEMU.
- **Y-Axis:** CPU Utilization (%)
- **X-Axis:** Time (s)

**Figure 7.** CPU cycles and memory consumed by Xede.
- **Y-Axis:** Resource Utilization (%)
- **X-Axis:** Time (s)

**Figure 8.** Increased CPU and memory consumption by Xede compared with QEMU.
- **Y-Axis:** Resource Utilization (%)
- **X-Axis:** Time (s)

**Figure 9.** CPU and memory consumption with 80 Xede instances.
- **Y-Axis:** CPU and Memory Utilization (%)
- **X-Axis:** Time (s)

### Discussion

#### Detecting Exploits without ROP and Code Injection

Xede can detect exploits that leverage Return-Oriented Programming (ROP) or code injection. However, it may not detect exploits that hijack control flows without using ROP. For example, an exploit could use legitimate software code to copy shellcode into a legal code region and then redirect the control flow to this shellcode. Constructing such exploits is challenging due to strict requirements, such as a writable code segment and evasion of Data Execution Prevention (DEP). In practice, we have not observed any such exploits. Xede can be extended to detect these types of exploits, for instance, by computing checksums for different memory regions to detect unauthorized modifications.

#### Accuracy of ROP Detection

Xede does not count gadgets where the source and destination addresses of a jump are the same, which significantly reduces the miscounted gadgets and false positives in detecting Jump-Oriented Programming (JOP). However, it is theoretically possible to evade Xede by constructing gadget chains with the same intermediate gadgets, e.g., `gadget 1 -> gadget x -> gadget 2 -> gadget x -> ...`. To perform control flow hijacking from intermediate gadgets to different gadgets, a large number of gadgets are required to build these chains. This makes it difficult to construct such gadget chains, and we have not observed any such attacks in practice. Therefore, we do not consider these attacks in this paper.

### Related Work

#### Malicious Code Detection

Malicious code detection primarily relies on behavior analysis [2,3,19,27,45,46]. This technique monitors the APIs called by the target process and checks if the process behaves properly by analyzing the API sequence. Behavior analysis is widely used in current anti-virus software like FireEye [19] and WildFire [45]. However, this approach has limitations, including the need to configure behavior policies for different sample types and the difficulty in accurately defining benign and malicious behaviors [25]. Additionally, exploits are sensitive to the system environment; if the victim software version does not match the expected environment, the exploit will fail, and the malicious behavior will not be identified.

#### Shellcode Detection

Recent research focuses on detecting exploits by identifying shellcode [31,35,44]. Shellcode detection approaches scan the content of the sample file before execution to determine if it contains shellcode characteristics. For example, Polychronakis et al. [31] use runtime heuristics to identify machine-level operations common in shellcode, such as reading from FS:[0x30] and writing to FS:[0]. Wang et al. [44] disassemble each network request to generate a control flow graph and use static taint and initialization analysis to detect self-modifying and indirect jump code obfuscation. These approaches face challenges because the content in data files differs from the actual layout in process memory, making it difficult to accurately identify shellcode. Moreover, shellcode structures can be similar to benign payloads, leading to high false positive rates [28].

#### Control Flow Integrity (CFI)

Exploit detection through CFI involves generating a complete control flow graph (CFG) of samples by performing static pre-analysis [1,21,47]. It monitors the execution of the target process, analyzes each instruction, and verifies the legitimacy of each control flow transfer by checking the CFG. Zhang et al. [47] classify the destination addresses of indirect control flow transfers and verify them based on static analysis results. However, CFI approaches are not practical for real systems due to the need for source code or debug information, the inability to verify dynamic code, and inefficiency and complexity [21].

#### Taint Analysis

Taint analysis uses dynamic tracing to detect exploits [11–13,29,33,41]. It marks input data from tainted samples, monitors program execution, and tracks how the tainted attribute propagates. However, existing taint analysis engines do not fully support the entire Intel instruction set, affecting accuracy. Additionally, the computational complexity and overhead make it impractical for real-world use [36].

#### Prevention Mechanisms

Mechanisms like Address Space Layout Randomization (ASLR) [26] and DEP [17] protect against malicious code. ROP techniques are used to evade these mechanisms. Last Branch Recording (LBR) [23] is a recent technique that analyzes executed indirect branch instructions but has limitations, such as a small LBR stack size and the inability to observe the actual path of instruction execution [9,30]. Shadow stack and speculative code execution, similar to Xede, are also used to detect ROP. For example, Davi et al. [16] used shadow stack, but their system cannot instrument kernel code. Polychronakis et al. [32] used speculative code execution but cannot detect exploits leveraging randomized modules.

### Summary

In this paper, we present Xede, an exploit detection system designed to comprehensively detect various types of exploits, including those generated by pure code injections, ROP, and hybrid techniques. We implemented a prototype of Xede using QEMU. Our evaluation demonstrates that Xede effectively detects different exploits, both in controlled experiments and in real-world deployments. Xede has detected numerous exploits that mainstream anti-virus software fails to capture, including those that raise abnormal execution exceptions due to mismatched execution environments.

### Acknowledgements

We thank our shepherd Christopher Kruegel and the anonymous reviewers for their insightful comments. This work is partially supported by the National Basic Research Program of China (973 Program) (Grant No. 2012CB315804) and the National Natural Science Foundation of China (Grant No. 91418206).

### References

1. Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J.: Control-Flow Integrity. In: Proceedings of the 12th ACM Conference on Computer and Communications Security, pp. 340–353. ACM (2005).
2. Amnpardaz. http://jevereg.amnpardaz.com/
3. Anubis. https://anubis.iseclab.org/
4. Flame Malware. http://en.wikipedia.org/wiki/Flame_malware
5. Sony Pictures Entertainment hack. http://en.wikipedia.org/wiki/Sony_Pictures_Entertainment_hack
6. Stuxnet. http://en.wikipedia.org/wiki/Stuxnet
7. Carlini, N., Wagner, D.: ROP is Still Dangerous: Breaking Modern Defenses. In: USENIX Security Symposium (2014).
8. Checkoway, S., Davi, L., Dmitrienko, A., Sadeghi, A.R., Shacham, H., Winandy, M.: Return-Oriented Programming Without Returns. In: Proceedings of the 17th ACM Conference on Computer and Communications Security, pp. 559–572. ACM (2010).
9. Cheng, Y., Zhou, Z., Yu, M., Ding, X., Deng, R.H.: Ropecker: A Generic and Practical Approach for Defending Against ROP Attacks. In: Symposium on Network and Distributed System Security (NDSS) (2014).
10. contagiodump. http://contagiodump.blogspot.com/
11. Costa, M., Crowcroft, J., Castro, M., Rowstron, A., Zhou, L., Zhang, L., Barham, P.: Vigilante: End-to-End Containment of Internet Worms. ACM SIGOPS Oper. Syst. Rev. 39, 133–147 (2005). ACM.
12. Crandall, J.R., Chong, F.: Minos: Architectural Support for Software Security Through Control Data Integrity. In: International Symposium on Microarchitecture (2004).
13. Crandall, J.R., Su, Z., Wu, S.F., Chong, F.T.: On Deriving Unknown Vulnerabilities from Zero-Day Polymorphic and Metamorphic Worm Exploits. In: Proceedings of the 12th ACM Conference on Computer and Communications Security, pp. 235–248. ACM (2005).
14. CVE-2012-0158. http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2012-0158
15. CVE-2014-1761. http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-1761
16. Davi, L., Sadeghi, A.R., Winandy, M.: RopDefender: A Detection Tool to Defend Against Return-Oriented Programming Attacks. In: Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security, pp. 40–51. ACM (2011).
17. Data Execution Prevention. http://en.wikipedia.org/wiki/Data_Execution_Prevention
18. exploit-db. http://www.exploit-db.com/
19. FireEye. http://www.fireeye.com/
20. Garfinkel, T., Rosenblum, M.: A Virtual Machine Introspection Based Architecture for Intrusion Detection. In: Proceedings of the 10th Network and Distributed System Security Symposium, February 2003.
21. Goktas, E., Athanasopoulos, E., Bos, H., Portokalidis, G.: Out of Control: Overcoming Control-Flow Integrity. In: 2014 IEEE Symposium on Security and Privacy (SP), pp. 575–589. IEEE (2014).
22. IDA Pro. https://www.hex-rays.com/products/ida/
23. Intel: Intel 64 and IA-32 Architectures Software Developer's Manual, February 2014.
24. Jiang, X., Wang, X., Xu, D.: Stealthy Malware Detection Through VMM-Based "Out-Of-the-Box" Semantic View Reconstruction. In: Proceedings of the 14th ACM Conference on Computer and Communications Security, October 2007.
25. Lanzi, A., Balzarotti, D., Kruegel, C., Christodorescu, M., Kirda, E.: AccessMiner: Using System-Centric Models for Malware Protection. In: Proceedings of the 17th ACM Conference on Computer and Communications Security, pp. 399–412. ACM (2010).
26. Larsen, P., Homescu, A., Brunthaler, S., Franz, M.: SoK: Automated Software Diversity. In: Proceedings of the 2014 IEEE Symposium on Security and Privacy, SP 2014 (2014).
27. LastLine. https://www.lastline.com/
28. Mason, J., Small, S., Monrose, F., MacManus, G.: English Shellcode. In: Proceedings of the 16th ACM Conference on Computer and Communications Security, pp. 524–533. ACM (2009).
29. Newsome, J., Song, D.: Dynamic Taint Analysis for Automatic Detection, Analysis, and Signature Generation of Exploits on Commodity Software (2005).
30. Pappas, V., Polychronakis, M., Keromytis, A.D.: Transparent ROP Exploit Mitigation Using Indirect Branch Tracing. In: USENIX Security, pp. 447–462 (2013).
31. Polychronakis, M., Anagnostakis, K.G., Markatos, E.P.: Comprehensive Shellcode Detection Using Runtime Heuristics. In: Proceedings of the 26th Annual Computer Security Applications Conference, pp. 287–296. ACM (2010).
32. Polychronakis, M., Keromytis, A.D.: ROP Payload Detection Using Speculative Code Execution. In: 2011 6th International Conference on Malicious and Unwanted Software (MALWARE), pp. 58–65. IEEE (2011).
33. Portokalidis, G., Slowinska, A., Bos, H.: Argos: An Emulator for Fingerprinting Zero-Day Attacks for Advertised Honeypots with Automatic Signature Generation. ACM SIGOPS Oper. Syst. Rev. 40, 15–27 (2006). ACM.
34. Rabek, J.C., Khazan, R.I., Lewandowski, S.M., Cunningham, R.K.: Detection of Injected, Dynamically Generated, and Obfuscated Malicious Code. In: Proceedings of the 2003 ACM Workshop on Rapid Malcode, pp. 76–82. ACM (2003).
35. Ratanaworabhan, P., Livshits, V.B., Zorn, B.G.: Nozzle: A Defense Against Heap-Spraying Code Injection Attacks. In: USENIX Security Symposium, pp. 169–186 (2009).
36. Schwartz, E.J., Avgerinos, T., Brumley, D.: All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution (But Might Have Been Afraid to Ask). In: 2010 IEEE Symposium on Security and Privacy (SP), pp. 317–331. IEEE (2010).
37. Secunia: Secunia Vulnerability Review 2015. Technical report, Secunia (2014). http://secunia.com/vulnerability-review/
38. securityfocus. http://www.securityfocus.com/
39. Shacham, H.: The Geometry of Innocent Flesh on the Bone: Return-Into-LIBC Without Function Calls (on the x86). In: Proceedings of the 14th ACM Conference on Computer and Communications Security, October 2007.
40. Snow, K.Z., Monrose, F.: Automatic Hooking for Forensic Analysis of Document-Based Code Injection Attacks (2012).
41. Suh, G.E., Lee, J.W., Zhang, D., Devadas, S.: Secure Program Execution Via Dynamic Information Flow Tracking. ACM Sigplan Not. 39, 85–96 (2004). ACM.
42. TCA Malware Analysis Platform. http://www.tcasoft.com/
43. VirusTotal. https://www.virustotal.com/
44. Wang, X., Jhi, Y.C., Zhu, S., Liu, P.: STILL: Exploit Code Detection via Static Taint and Initialization Analyses. In: 2008 Annual Computer Security Applications Conference, ACSAC 2008, pp. 289–298. IEEE (2008).
45. WildFire. https://www.paloaltonetworks.com/products/technologies/wildfire.html
46. XecScan. http://scan.xecure-lab.com/
47. Zhang, M., Sekar, R.: Control Flow Integrity for COTS Binaries. In: Usenix Security, pp. 337–352 (2013).