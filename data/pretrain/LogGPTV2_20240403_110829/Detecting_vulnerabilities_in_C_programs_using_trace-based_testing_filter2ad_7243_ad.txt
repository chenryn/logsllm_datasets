Remark
1 new bug
1 new bug
1 new bug
1 new bug
2 new bugs
2 new bug
4 new bugs
1 new bug
* According to the BAD marks in the program, there are 6 bugs in the trace. However, we found that one of them is not a bug.
Table 3. Experimental Results. “LOC” represents the number of lines of the code; “Input” represents
the program input we use; “LOT” represents the number of lines in the execution trace exercised by
the test case; “Time” represents the time that our tool used; “#KnownBugs” is the number of previ-
ously reported vulnerabilities in the execution trace; “#FoundBugs” is the number of vulnerabilities
found by SecTAC; and “#FP” is the number of false positives.
provided in [28] default in the table.
For http server programs, we randomly generate 50 nor-
mal http requests. For the ftp server program, we manually
generate 10 test cases that include basic ftp commands such
as “ls”, “get”, and “put”. We use the GCC bounds check-
ing extension to monitor the program execution. These test
cases do not trigger any out-of-bounds operation. Next we
describe the test input to every benchmark program tested
in the experiment.
In the Bind 1 program, buffer overﬂow occurs when a
negative value is passed as the third argument of memcpy.
In [28], a constant string “sls.lcs.mit.edu” is hard-coded
as the second argument of strcpy to achieve this. We
use “www.cnn.com” instead as the normal test data under
which the program runs normally, and SecTAC can detect
this vulnerability. Similarly, for the Bind 2 program, we
use string “cnn.com” as the normal test input instead of the
original hard-coded input “sls.lcs.mit.edu” that crashes
the program. The Bind 3 program does not check the buffer
space when calling memcpy. The provided test case is a
ﬁle s3.in whose content is “9283721”. However, we no-
tice that as long as its content is not “0”, the vulnerability
always occurs. Thus we just use the original test case. The
Bind 4 program uses sprintf without boundary check-
ing. A string of 1072 bytes long is provided in [28] as the
input to trigger the vulnerability. We do not use this input;
instead, we use a normal test input as given in Table 3.
Most of the vulnerabilities in the Sendmail programs are
caused by out-of-bounds pointer operations. These opera-
tions are usually in a loop where the pointer is increased
by 1 for each iteration. As a result, in the execution trace,
the out-of-bounds operation of a pointer only occurs when
a test case can actually trigger the vulnerability. In other
words, the execution trace under a normal test case does not
contain the vulnerability. Thus, we use test cases provided
by the benchmark programs in our experiments.
The test input to each Wu-ftp program is a string that
represents a path. For the Wu-ftp 1 program, the original
test case in [28] is “/tmp/” followed by 24 ’a’s. This is
carefully designed to trigger the buffer overﬂow caused by
strcpy. For the Wu-ftp 2 program, the original test case
is also a speciﬁc complex path with 9 subdirectories, which
triggers the vulnerability caused by strcat. For the Wu-
ftp 3 program, the length of the input path is made more
than 47 to trigger the vulnerability caused by strcpy. In
our experiments, we use normal test inputs. Speciﬁcally, for
Wu-ftp 1 and Wu-ftp 3, we use a normal input “/tmp/aa”
that does not trigger the vulnerability. For Wu-ftp 2, we
use “/tmp/test.c”, which is the path of an existing ﬁle and
does not trigger the vulnerability.
Performance: We did the experiments on a 2GHz Core
2 Desktop running Ubuntu-8.10 Linux operating system.
We let the Java use a maximum of 1G heap memory dur-
ing our experiments. The ﬁfth column of Table 3 shows the
execution time of SecTAC for analyzing all traces for each
program. The execution time is the sum of the times needed
for trace-based symbolic execution and satisﬁability analy-
sis, which increases nearly linearly with the trace size in our
experiments. We can see that SecTAC can quickly analyze
C programs for vulnerability.
In addition to the known bugs,
SecTAC also detected six new vulnerabilities in the 14
benchmark programs as shown in Table 4. Test cases
that trigger these vulnerabilities can be directly derived
New vulnerabilities:
Program
Bind 4
Sendmail 1
Sendmail 3
Wu-ftp 2
Wu-ftp 3
Wu-ftp 3
Test Input that Triggers the New Vulnerability
www.cnn.com; www.nbc.com
default
default
a 200 bytes long string for argv[1]
/a...a (48 a’s)/aa
/a...a (48 a’s)/aa
Location of the New Vulnerability
ns-lookup-bad.c:277
crackaddr-bad.c:460
mime1-bad.c:212
call fb realpath.c:94
realpath-2.4.2-bad.c:269
realpath-2.4.2-bad.c:257
Remarks
nsp out-of-bound
buﬂim out-of-bound
inﬁle out-of-bound
strcpy buffer overﬂow
where out-of-bound
strcpy buffer overﬂow
Table 4. New Vulnerabilities in the benchmark programs
from the solutions given by the satisﬁability checker Yices
[7] in SecTAC. Notably, we detected a vulnerability in
code that was previously considered to be safe. The au-
thors of [28] explicitly commented the line 257 of ﬁle
realpath-2.4.2-bad.c in the Wu-ftp 3 program as
a safe call. However, our experiment shows that it is not.
As shown in Table 4, when the length of a directory name is
long enough, the strcpy function at line 257 will overﬂow
the destination buffer whose size is only 46 bytes.
For nullhttpd-0.5.1, SecTAC found three buffer
overﬂow vulnerabilities at line 143 of ﬁle “http.c”. The at-
tacker can overﬂow three different buffers in this line of
code. In addition, it also found a new vulnerability at line
58 of ﬁle “conﬁg.c”, where the program uses snprintf
to copy a string variable config.server_base_dir
and a constant string “/bin” to buffer server_bin_dir.
However, the space allocated to server_bin_dir is
255. If the string length of config.server_base_dir
is 255, the buffer is not null terminated and the string “/bin”
cannot be copied to the buffer, causing a conﬁguration error.
Lines 59 to 61 in the same ﬁle have the same vulnerability.
For the lancer program, SecTAC found four buffer over-
ﬂow problems in “handler.c” and “host.c”. These problems
have the same pattern: the author declared a buffer with the
size of n, and used strncpy to copy at most n-1 non-
zero characters to the buffer. However, the value at position
n-1, which does not belong to this buffer, could be a non-
zero value. Thus, it is possible that the string in the buffer is
not properly null-terminated, which may cause buffer over-
ﬂow. For the bftpd-2.3 program, SecTAC detected that
the buffer “bu host” (whose content is from an external in-
put) may be not properly null-terminated. We have reported
this vulnerability to the author of the program and a new
version was subsequently released to ﬁx this bug.
6 Related Work
The method in [14] detects buffer overﬂow using exist-
ing test cases. They do not perform symbolic analysis and
ignore branch conditions, causing many false alarms. The
predictive testing in [16] inserts assertions into the source
program and uses a combination of concrete and symbolic
execution on the given test inputs to discover assertion vi-
olations. DART [11, 10] and CUTE [22] can automatically
generate test cases. However, they use concrete values for
complex constraints that they cannot handle. They may
miss many paths that are covered by the test cases carefully
designed in traditional testing. SecTAC takes advantage of
previous test effort. In addition, DART and CUTE over-
look useful information about variables and functions such
as pointer dependency and function return type. SPLAT
[26] improves DART by introducing a length attribute in
each buffer. It also represents a ﬁxed-length preﬁx of the
buffer elements symbolically. Other buffer elements are
represented using concrete values during execution. The
limitation is that when the program visits a buffer element
beyond the preﬁx, their symbolic execution becomes con-
crete. SecTAC generatesnew objectsonly when a buffer el-
ement is visited, which improves the precision and reduces
the cost. EXE [6] and KLEE [4] were developed to achieve
high branch coverage. They can detect memory overﬂow
vulnerabilities. SAGE [12] also employs trace-based sym-
bolic execution with satisﬁability analysis. However, SAGE
works on the binary level; a lot of useful information in the
source code is no longer available for analysis.
7 Limitations and Suggestions
SecTAC has a number of limitations. First, we must
have the test cases ready before doing the security testing.
The effectiveness of SecTAC depends on the completeness
of the existing test cases. In fact, the branch coverage of the
test cases determines the number of paths that our method
can check. Second, the size of an execution trace for large
complex programs may be huge. Analyzing a large execu-
tion trace can cause many problems. For example, it may be
the case that a large number of statements in the trace gen-
erate security constraints. As a result, SecTAC may invoke
the SMT solver very frequently, which can slow down se-
curity testing signiﬁcantly. We plan to improve SecTAC by
managingprogram and security constraints more efﬁciently,
e.g., by using BDDs [2, 3].
8 Conclusion and Future Work
In this paper, we proposed an approach for testing the
security of C programs using trace-based symbolic execu-
tion and satisﬁability analysis. We developed a tool named
SecTAC to demonstrate the effectiveness of our approach.
We evaluated this tool on 14 benchmark programs and 3
open source programs. The result shows that our tool
quickly identiﬁed every reported vulnerability in the traces
and also found 13 new vulnerabilities. In conclusion, our
tool is effective and efﬁcient in testing the security of cur-
rent software systems.
We are interested in the following directions. First, al-
though our approach can handle multi-threaded programs
as long as the test cases are available, it only analyzes a
speciﬁc combination of the traces generated by different
threads. We proposeto identify the trace for each thread and
seek effective ways to combine them to improve the detec-
tion of security vulnerabilities in multi-threaded programs.
Second, we will also seek solutions to further improve the
efﬁciency of SecTAC and conduct more experiments on
large and complex programs to evaluate our approach.
Acknowledgment
The authors would like to thank the anonymous review-
ers for their valuable comments.
References
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-
ﬂow integrity.
In Proceedings of the ACM Conference on
Computer and Communications Security (CCS), pages 340–
353, 2005.
[2] S. B. Akers. Binary decision diagrams. IEEE Transaction
on Computers, C-27(6):509 – 516, June 1978.
[3] R. E. Bryant. Graph-based algorithms for boolean func-
tion manipulation.
IEEE Transaction on Computers, C-
35(8):677–691, 1986.
[4] C. Cadar, D. Dunbar, and D. Engler. KLEE: Unassisted
and automatic generation of high-coverage tests for com-
plex system programs. In Proceedings of the USENIX Sym-
posium on Operating Systems Design and Implementation
(OSDI), 2008.
[5] C. Cadar and D. Engler. Execution generated test cases:
How to make systems code crash itself.
In Proceedings
of the International SPIN Workshop on Model Checking of
Software, 2005.
[6] C. Cadar, V. Ganesh, P. Pawlowski, D. Dill, and D. Engler.
EXE: automatically generating inputs of death. In Proceed-
ings of the ACM Conference on Computer and Communica-
tions Security (CCS), pages 322–335, 2006.
[7] B. Dutertre and L. de Moura. A fast linear-arithmetic solver
for DPLL(T). In Proceedings of the Computer-Aided Veriﬁ-
cation Conference (CAV), pages 81–94, 2006.
Towards
a property-based testing environment with applications to
security-critical software. In Proceedings of the 4th Irvine
Software Symposium, pages 39–48, 1994.
[9] A. Ghosh, T. O’Connor, and G. McGraw. An automated ap-
proach for identifying potential vulnerabilities in software.
In Proceedings of the IEEE Symposium on Security and Pri-
vacy, pages 104–114, 1998.
In
Proceedings of the Symposium on Principles of Program-
ming Languages (POPL), 2007.
[11] P. Godefroid, N. Klarlund, and K. Sen. DART: directed au-
tomated random testing. In Proceedings of the ACM SIG-
PLAN conference on Programming Language Design and
Implementation, pages 213–223, 2005.
[12] P. Godefroid, M. Y. Levin, and D. Molnar. Automated white-
box fuzz testing.
In Proceedings of the Network and Dis-
tributed Systems Security (NDSS), pages 151–166, 2008.
[13] R. Hastings and B. Joyce. Purify: Fast detection of mem-
ory leaks and access errors.
In Proceedings of the Winter
USENIX Conference, pages 125–136, 1992.
[10] P. Godefroid. Compositional dynamic test generation.
[8] G. Fink, C. Ko, M. Archer, and K. Levitt.
[14] E. Haugh and M. Bishop. Testing C programs for buffer
overﬂow vulnerabilities. In Proceedings of the Network and
Distributed System Security Symposium (NDSS), pages 123–
130, 2003.
[15] R. Jones and P. Kelly. Backwards-compatible bounds check-
ing for arrays and pointers in C programs. In Proceedings of
the International Workshop on Automated Debugging, 1997.
[16] P. Joshi, K. Sen, and M. Shlimovich. Predictive testing: am-
plifying the effectiveness of software testing.
In Proceed-
ings of the Joint Meeting of the European Software Engi-
neering Conference and the ACM SIGSOFT Symposium on
the Foundations of Software Engineering, pages 561–564,
2007.
[17] P. Marinescu and G. Candea. LFI: A practical and gen-
eral library-level fault injector. In Proceedings of the Inter-
national Conference on Dependable Systems and Networks
(DSN), 2009.
[18] G. C. Necula, S. McPeak, S. Rahul, and W. Weimer. CIL:
Intermediate language and tools for analysis and transforma-
tion of C programs. In Proceedings of the International Con-
ference on Compiler Construction, pages 213–228, 2002.
[19] S. Ranise and C. Tinelli. The satisﬁability modulo theories
library(smt-lib). www.SMT-LIB.org, 2006.
[20] M. Ringenburg and D. Grossman. Preventing format-string
attacks via automatic and efﬁcient dynamic checking.
In
Proceedings of the ACM Conference on Computer and Com-
munications Security (CCS), pages 354–363, 2005.
[21] K. Sen. Concolic testing. In Proceedings of the IEEE/ACM
nternational Conference on Automated Software Engineer-
ing (ASE), 2007.
[22] K. Sen, D. Marinov, and G. Agha. CUTE: a concolic unit
testing engine for C.
In Proceedings of the joint Meeting
of the European Software Engineering Conference and the
ACM SIGSOFT International Symposium on Foundations of
Software Engineering, pages 263–272, 2005.
[23] E. C. Sezer, P. Ning, C. Kil, and J. Xu. Memsherlock: an au-
tomated debugger for unknown memory corruption vulner-
abilities. In Proceedings of the ACM Conference on Com-
puter and Communications Security (CCS), pages 562–572,
2007.
[24] J. Viega, J. T. Bloch, Y. Kohno, and G. McGraw. ITS4: A
static vulnerability scanner for C and C++ code. In Proceed-
ings of the Annual Computer Security Applications Confer-
ence (ACSAC), page 257, 2000.
[25] D. Wagner, J. Foster, E. Brewer, and A. Aiken. A ﬁrst step
towards automated detection of buffer overrun vulnerabili-
ties. In Proceedings of the Network and Distributed System
Security Symposium (NDSS), pages 3–17, 2000.
[26] R. Xu, P. Godefroid, and R. Majumdar. Testing for buffer
overﬂows with length abstractions.
In Proceedings of the
International Symposium on Software Testing and Analysis
(ISSTA), pages 27–38, 2008.
[27] M. Zhivich, T.Leek, and R. Lippmann. Dynamic buffer over-
ﬂow detection. In Proceedings of the Workshop on the Eval-
uation of Software Defect Detection Tools, 2005.
[28] M. Zitser, R. Lippmann, and T. Leek. Testing static analysis
tools using exploitable buffer overﬂows from open source
In Proceedings of the ACM SIGSOFT International
code.
Symposium on Foundations of Software Engineering, pages
97–106, 2004.