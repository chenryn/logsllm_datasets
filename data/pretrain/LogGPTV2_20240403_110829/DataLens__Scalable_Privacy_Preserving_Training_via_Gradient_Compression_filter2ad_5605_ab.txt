design of the underlying algorithm and imposes novel challenges
in theoretical understandings, which is the focus of this work.
3 THREAT MODEL & METHOD OVERVIEW
In this section, we will first introduce the threat model that we
consider in this paper, then provide an overview of the proposed
DataLens framework as a differentially private data generative
model. We also provide an overview of the proposed noisy gradient
compression and aggregation method TopAgg, which serves as one
of the key building blocks in DataLens.
3.1 Threat Model and Goal
In practice, the machine learning models are usually trained by data
containing a large amount of privacy sensitive information. Thus,
given a trained model, an attacker is able to train some shadow
models with partial data or leverage other strategies to infer the
‚Äúmembership‚Äù of a training instance [51], which leads to the leakage
of sensitive information. For instance, if a person is known to have
participated in a heart disease test, her privacy of having heart
disease would be revealed. An attacker is also able to recover the
training information via data recovery attacks [10, 11].
Differential privacy (DP) can protect against membership infer-
ence attacks and training-data memorization [11, 61]. Intuitively,
differential privacy guarantees that when the input dataset differs
by one record, the output distribution of a differentially private
algorithm does not change by much. This definition reduces the
risk of membership inference attacks and data recovery attacks
given that it prevents the algorithm from memorizing individual
record in the input training dataset.
In this paper, our goal is to ensure the differential privacy guar-
antees for training machine learning models, and therefore protect
the privacy of training data. There has been a line of research fo-
cusing on providing differential privacy guarantees for the trained
machine learning models by adding DP noise during training [2].
Here we mainly consider a more flexible case, where we will design
a differentially private data generative model, which ensures that
the generated data instead of the model‚Äôs parameters are differen-
tially private as proved in Theorem 3. Thus, as long as the data
are generated, they can be used for training arbitrary down-stream
learning tasks with differential privacy guarantees.
Note that besides privacy-preserving, it is also critical to make
sure that the generated data is of high utility, and therefore we
evaluate the prediction accuracy of models trained on the DP gen-
erated data and test their accuracy on real testset. Different with
existing data generative models, ‚Äúvisual" quality of the generated
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2148DP data is not the main goal of this paper, and we will provide eval-
uation on the visual quality of the generated data for understanding
purpose in Section 5.2 and Table 3. We believe it is interesting fu-
ture research to integrate other losses to further improve the visual
quality of the generated data if it is part of the goal.
a tighter privacy bound. We have also provide a theoretical anal-
ysis for the convergence of TopAgg in Section 4.3, which to our
best knowledge is the first convergence analysis considering the
coordinate-wise gradient clipping together with gradient compres-
sion and DP noise mechanism.
3.2 Method Overview
Here we briefly illustrate the proposed DataLens framework, as
well as the novel noisy gradient compression and aggregation ap-
proach TopAgg which serves as a key building block in DataLens.
The goal of DataLens is to generate high-dimensional data which
will not leak private information in the training data. In terms of
privacy preserving ML training, PATE [44] so far has achieved the
state of the art performance, which motivates our privacy analysis.
Figure 1 presents an overview for the structure of DataLens. This
framework combines the algorithm TopAgg for high dimensional
differentially private (DP) gradient compression and aggregation
with GAN and the PATE framework. DataLens consists of an
ensemble of teacher discriminators and a student generator. The
teacher discriminators have access to randomly partitioned non-
overlapping sensitive training data. In each training iteration, each
teacher model produces a gradient vector to guide the student gen-
erator in updating its synthetic records. These gradient vectors
from different teachers are compressed and aggregated using the
proposed DP gradient aggregation algorithm TopAgg before they
are sent to the student generator.
In DataLens, we propose a novel algorithm TopAgg for high
dimensional DP gradient compression and aggregation. Our main
insight hinges on gradient sparsification as indicated in recent work
on communication-efficient distributed learning [4, 5]: we can ap-
ply aggressive lossy compression on the gradient vectors without
slowing down SGD convergence. In this paper, we identify a spe-
cific lossy compression scheme under which we can leverage more
efficient DP mechanism, thus increasing the utility significantly.
In particular, the proposed gradient compression and aggrega-
tion algorithm TopAgg takes the top-ùëò entries in a gradient vector
and compresses them via stochastic sign gradient quantization [24].
This step significantly reduces the dimensionality of a gradient
vector while preserving the most valuable gradient direction infor-
mation. After the compression, we perform DP gradient aggregation
over the sign gradient vectors with a corresponding noise injection
mechanism. Since the gradient vectors have been compressed, the
aggregation algorithm has a much lower sensitivity, which leads to
The DP gradient compression and aggregation step is crucial
for the privacy protection and utility of the generator. Yet, it is
challenging for the algorithm to both preserve high data utility and
achieve a strong privacy guarantee. To achieve high data utility,
the algorithm needs to preserve the correct gradient directions of
the teacher models. As for the privacy guarantee, privacy composi-
tion over a high dimensional gradient vector often consumes high
privacy budget, resulting in a weaker privacy guarantee.
To address this problem, prior work uses random projection to
project the gradient vector onto lower dimensions [37]. However,
this approach introduces excessive noise to the gradient directions
and greatly undermines the utility of the model, making it hard to
analyze the convergence.
4 DATALENS: SCALABLE PRIVACY
PRESERVING GENERATIVE MODEL
We first present our privacy preserving data generative model
DataLens, then perform a rigorous analysis on its privacy guaran-
tee and convergence, and demonstrate the privacy-utility trade-off
controlled by the proposed gradient compression method. We also
briefly discussion how to adapt the proposed noisy gradient com-
pression and aggregation algorithm TopAgg from DataLens to
standard SGD training.
4.1 DataLens Training
We now present the main algorithms used in DataLens. It consists
of three parts: an ensemble of teacher discriminators, a student
generator, and a DP gradient aggregator. First, we introduce the
algorithm for training the student generator and teacher discrimi-
nators. Then, we introduce the novel high-dimensional DP gradient
compression and aggregation algorithm TopAgg (Algorithm 3).
This algorithm consists of two parts: a top-ùëò gradient compression
algorithm (TopkStoSignGrad, Algorithm 2) that compresses the
gradient vectors while preserving the important gradient directions;
and a DP gradient aggregation algorithm that aggregates teacher
gradient vectors with differential privacy guarantees.
Training DP Generator via Teacher Discriminator Aggre-
gation. On the high level, as shown in Figure 1 the teacher discrim-
inators are trained on non-overlapping sensitive data partitions
to distinguish between real and synthetic data. The student gen-
erator produces synthetic records, sends them to the teachers for
label querying, and uses the aggregated gradient from the teacher
discriminators to improve its generated synthetic records. The DP
gradient aggregator ensembles the teachers‚Äô gradient vectors and
adds DP noise for privacy guarantees. The detailed algorithm for
this process is included in the Algorithm 1.
To begin with, we randomly partition the sensitive training
dataset into non-overlapping subsets of the same size. Each partition
is associated with one teacher discriminator. Then, we iteratively
update the student generator and the teacher discriminators. Each
iteration consists of the following four steps:
Step 1: Training teacher discriminators. The student gener-
ator Œ® produces a batch of synthetic records. Each teacher discrim-
inator Œìùëñ updates the weights based on standard discriminator loss
LŒìùëñ to reduce its loss on distinguishing the synthetic records from
real records in its training data partition.
Step 2: Generating and compressing teacher gradient vec-
tors. Each teacher discriminator Œìùëñ computes a gradient vector ùëî(ùëñ)
of the discriminator loss LŒìùëñ with regard to the synthetic records.
Such gradient vector contains the information that could guide
the student generator to improve its synthetic records aiming to
increase the generated data utility (i.e., classification accuracy of
trained models).
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2149Figure 1: Overview of DataLens. DataLens consists of an ensemble of teacher discriminators and a student generator. DataLens provides
a novel algorithm TopAgg for high dimensional DP gradient compression and aggregation. TopAgg consists of two parts: (1) top-ùëò and sign
gradient compression that selects the top ùëò gradient dimensions, and (2) DP gradient aggregation for high-dimensional sparse gradients. The
solid arrows denote the data flow, while the dash arrows denote the gradient flow.
Algorithm 1 - Training the Student Generator.
1: Input: batch size ùëö, number of teacher models ùëÅ , number of training
iterationsùëá , gradient clipping constant ùëê, top-ùëò, noise parameters ùúé, vot-
ing threshold ùõΩ, disjoint subsets of private sensitive data ùëë1, ùëë2, . . . , ùëëùëÅ ,
learning rate ùõæ
2: for number of training iterations ‚àà [ùëá ] do
3:
4:
5:
6:
7:
8:
9:
10:
‚ä≤ Phase I: Pre-Processing
Sample ùëö noise samples z = (z1, z2, . . . , zùëö)
Generate fake samples Œ®(z1), Œ®(z2), . . . , Œ®(zùëö)
for each synthetic image Œ®(zùëó) do
‚ä≤ Phase II: Private Computation and Aggregation
for each teacher model Œìùëñ do
Sample ùëö data samples (x1, x2, . . . , xùëö) from ùëëùëñ
Update the teacher discriminator Œìùëñ by descending its sto-
chastic gradient on LŒìùëñ on both fake samples and real samples
= ‚àí ùúï log Œìùëñ (ùëé)
teacher discriminator loss LŒìùëñ w.r.t. the sample Œ®(zùëó).
Calculate the gradient g
(ùëñ)
ùëó
ùúïùëé
(cid:12)(cid:12)(cid:12)ùëé=Œ®(zùëó ) of the
11:
12:
13:
14:
15:
16:
17:
18:
end for
gùëó ‚Üê (g
¬Øgùëó ‚Üê DPTopkAgg(cid:0)ùëá , gùëó , ùëê, ùëò, ùúé, ùõΩ(cid:1)
, . . . , g
(ùëÅ )
ùëó
(1)
ùëó
(2)
ùëó
, g
)
‚ä≤ Phase III: Post-Processing
ÀÜxùëó ‚Üê Œ®(zùëó) + ùõæ ¬Øgùëó
end for
Update the student generator Œ® by descending its stochastic gradi-
ent on ÀÜLŒ®(z, ÀÜx) = 1
ùëö
ùëó=1(Œ®(zùëó) ‚àí ÀÜxùëó)2 on ÀÜx = ( ÀÜx1, ÀÜx2, . . . , ÀÜxùëö)
ùëö
19: end for
Step 3: DP gradient compression and aggregation. In order
to perform efficient DP mechanism for the teacher gradient vectors,
we propose TopAgg to compress the teacher gradient vectors first
and then aggregate them. We perform gradient aggregation over
the teachers‚Äô gradient vectors with a corresponding noise injection
algorithm that guarantees differential privacy. The final aggregated
noisy gradient vector is then passed to the student generator. Details
will be discussed in the next subsection.
Step 4: Training the student generator. The student gener-
ator learns to improve its synthetic records by back-propagating
ùëö
ùëö
ùúïÀÜx
= 2ùõæ
ùëö
ùëö
the aggregated DP gradient vectors produced by the teacher en-
semble. We define the loss function for the student generator as
ùëó=1(Œ®(zùëó) ‚àí ÀÜxùëó)2, where zùëó is the noise sample,
ÀÜLŒ®(z, ÀÜx) = 1
Œ®(zùëó) is the synthetic data, and ÀÜxùëó = Œ®(zùëó) + ùõæ ¬Øgùëó is the synthetic
data plus the aggregated DP gradient vectors from the teacher
discriminators. Since ‚àí ùúï ÀÜLŒ®(z,ÀÜx)
ùëó=1 ¬Øgùëó, descending the sto-
chastic gradient on ÀÜLŒ®(z, ÀÜx) would propagate the aggregated DP
gradient vectors from the teacher discriminators to the student
generator.
Top-ùëò Gradient Compression via Stochastic Sign Gradient.
In the Step 3. gradient compression and aggregation, each teacher
model compresses its dense, real-valued gradient vector into a
sparse sign vector with ùëò nonzero entries. We first present and dis-
cuss the gradient compression function: TopkStoSignGrad(g, ùëê, ùëò)
(Algorithm 2).
Inspired by the recent results on signSGD [7] and gradient com-
pression in communication efficient distributed learning [5, 57],
we design a gradient compression algorithm that reduces a gra-
dient vector in two steps. First, we select the top-ùëò dimensions
in each teacher gradient g and set the remaining dimensions to
zero. This step reduces the dimensionality of the gradient vector
and allows us to achieve a tighter privacy bound during DP gra-
dient aggregation. Then, we clip the gradient at each dimension
with threshold ùëê, normalize the top-ùëò gradient vector, and perform
stochastic gradient sign quantization. Specifically, we first select
the top-ùëò dimensions of the gradient. Let ÀÜùëîùëó be the j-th dimension
selected from the gradient vector g, we then clip each selected
dimension as ÀÜùëîùëó = min(max( ÀÜùëîùëó ,‚àíùëê), ùëê). After normalization, we
assign the stochastic gradient sign Àúùëîùëó based on the following rule:
with probability 1+ ÀÜùëîùëó
1,
2
‚àí1, with probability 1‚àí ÀÜùëîùëó
2
;
.
(1)
We can see that Àúùëîùëó is an unbiased estimator of ÀÜùëîùëó. As a result, we
transform a dense, real-valued gradient vector into a sparsified
{‚àí1, 0, 1}-valued vector, which allows more effective differentially
private gradient aggregation.
High Dimensional DP Gradient Aggregation. In the gradi-
ent aggregation step, we perform differentially private aggregation
(cid:40)
Àúùëîùëó =
Session 7A: Privacy Attacks and Defenses for ML CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2150Algorithm 2 - Gradient Compression on Top-ùëò Dimensions
via Stochastic Sign Gradient (TopkStoSignGrad). This algo-
rithm takes in a gradient vector of a teacher model g(ùëñ) and returns
the compressed gradient vector Àúg(ùëñ).
1: Input: Gradient vector g(ùëñ) , gradient clipping constant ùëê, top-ùëò
2: h(ùëñ) ‚Üê arg-topk(|g(ùëñ) |, ùëò)
‚ä≤ the top-ùëò indices of the absolute value of gradient ÀÜg(ùëñ)
,‚àíùëê), ùëê) for each dimension ùëó in g(ùëñ)
(ùëñ)
ùëó