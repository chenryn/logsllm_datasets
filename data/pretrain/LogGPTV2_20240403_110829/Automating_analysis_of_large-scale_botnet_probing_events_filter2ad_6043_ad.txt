number approaches work similarly, here we discuss only the for-
mer. We proceed by identifying the top sources originating in at
least four sets of scanning. We test whether (after over(cid:3)ow recov-
ery) the IPIDs increases linearly with respect to time, as follows.
First, for two consecutive scans, if the IPID of the second is smaller
than the (cid:2)rst, we adjust it by 64K. We then try to (cid:2)t the corrected
IPIDi and its corresponding arrival time ti, along with previous
points, to a line. If they (cid:2)t with correlation coef(cid:2)cient r > 0:99, it
re(cid:3)ects consistency with a near-constant scan speed, and the sender
is a single host rather than multiple hosts behind a NAT. When this
happens, we estimate the global speed from the slope.
It is possible that multiple over(cid:3)ows might occur, in which case
the simple over(cid:3)ow recovery approach will fail. However, in this
case the chance that we can still (cid:2)t the IPIDs to a line is very small,
so in general we will discard such cases. This will create a bias
when estimating very large global scopes, because they will more
often exhibit multiple over(cid:3)ows.
Sources that happen to engage in activity in addition to scan-
ning can lead to overestimation of their global scan speed, since
they will consume IPID or possibly ephemeral port numbers more
quickly than those that might be simply due to the scanning. To
offset this bias, when we have both IPID and ephemeral port esti-
mates, we use the lesser of the two. Furthermore, in our evaluation,
for the cases where we can get both estimates, we check the consis-
tency between them, and found that IPID estimates usually produce
larger results, but more than 95% of the time within a factor of two
of the ephemeral port estimate. (Clearly, IPID can sometimes ad-
vance more quickly if the scanner receives a SYN-ACK in response
to a probe, and thus returns an ACK to complete the 3-way hand-
shake.)
Global scan scope extrapolation. With the ability to estimate
the global scan speed, we (cid:2)nally estimate the global scan scope.
Since we know the local scope, the problem is equivalent to es-
timate the local over global ratio (cid:26). Suppose in a probing event
there are m senders seen by the sensor, for which we can estimate
the global scan speeds RGi of a subset of size m0. For sender i
(i 2 [m0]), we know Ti (duration during which we observe the
sender in the Honeynet) and ni (number of observed scans). We
use the linear regression with correlation coef(cid:2)cient r > 0:99 (as
we discussed before) to estimate the RGi which is also quite ac-
curate. The main estimation error comes from variation of the
observed ni from its expectation. De(cid:2)ne ^(cid:26)i = ni
for each
sender. Sender i’s global scan speed is RGi. Globally during Ti, it
sends out RGi (cid:1) Ti scans. ni is the number of scans we see if we
sample from RGi (cid:1) Ti total scans with probability (cid:26). Therefore, ^(cid:26)i
is an estimator of (cid:26). If we aggregate over all the m0 senders, we get
RGi (cid:1)Ti
i ni
^(cid:26) = Pm0
Pm0
i RGi (cid:1) Ti
(2)
As show in Appendix C, we formally prove that ^(cid:26) is an unbiased
estimator of (cid:26), and it is more accurate than ^(cid:26)i, which only re(cid:3)ects
a single sender. We then can use ^(cid:26) to estimate the global scope a
probe targeted.
Average Scan Speed Per Bot. After extrapolating (cid:26) and M, we
estimate the average scan speed per bot using:
Q
R (cid:1) T (cid:1) M
= (cid:26)
(3)
Here Q is the number of scans received by the sensor in time T ,
which should re(cid:3)ect a portion (cid:26) of the total scans. We estimate the
total scans by R (cid:1) T (cid:1) M, where R is the average scan speed per bot.
This formulation assumes that each bot participates in the entire
duration of the event, which is more likely to hold for short-lived
events.
Limitations. Note that both of the above techniques can fail if
attackers either craft raw IP packets or explicitly bind the source
)
c
e
s
/
s
e
b
o
r
p
(
d
e
e
p
S
l
l
a
b
o
G
e
a
m
t
0
4
0
3
0
2
0
1
i
t
s
E
0
0
5
10
Figure 6: Top 30 estimate speeds of Event VNC-060729.
15
Rank
20
25
30
port used for TCP probes. Thus, the schemes may lose power in
the future. However, crafting raw IP packets and simulating a TCP
stack is a somewhat time consuming process, especially given most
bots (85+%) we observed run Windows, and in modern Windows
systems the raw socket interface has been disabled. Empirically, in
our datasets we did not (cid:2)nd any case for which the techniques did
not appear to apply.
4.4 Extrapolating from Interarrival Times
For Approach II, we estimate global scanning speed (and hence
global scope, via estimating (cid:26) from an estimate of R using Equa-
tion 3) in a quite different fashion, as follows. Clearly, a sender’s
global scan speed s provides an upper bound on the local speed we
might observe for the sender. Furthermore, if we happen to observe
two consecutive scans from that sender, then they should arrive
about (cid:1)t = 1=s apart. Accordingly, the minimum observed (cid:1)t
gives us a lower bound on s, but with two important considerations:
(i) the lower bound might be too conservative, if the global scope
is large, and we never observe two consecutive scans, and (ii) noise
perturbing network timing will introduce potentially considerable
inaccuracies in the assumption that the observed (cid:1)T matches the
interarrival spacing present at the source.
We proceed by considering all m senders we observe, other than
those that sent only a single scan. We rank these by the estimated
global scan rate they imply via ^s = 1= ^(cid:1)t, where ^(cid:1)t is the min-
imum observed interarrival time for the sender. Naturally, fast
senders should tend to re(cid:3)ect larger estimated speeds, which we
veri(cid:2)ed by comparing ^(cid:1)t of each sender with how many scans we
observed from it. We (cid:2)nd that generally the correlation is clear
though with considerable deviations.
Using the fast senders’ speeds to form an estimate of the aver-
age scanning speed may of course overestimate the average speed.
On the other hand, our technique aims at estimating a lower bound.
Thus, it is crucial to (cid:2)nd a balanced point among the possible esti-
mates. We do so by presenting the different sorted estimates from
which the analyst chooses the (cid:147)knee(cid:148) of the resulting curve, i.e., the
point with smallest rank k for which an increase in k yields little
change in s. Figure 6 shows an example, plotting the top 30 maxi-
mum estimated speeds of Event VNC-060729. From the (cid:2)gure we
would likely select k = 6 as the knee, giving an estimated speed
8.26.
5. EVALUATION
We evaluate our techniques using the honeynet traf(cid:2)c described
in Section 2.1. The total data spans 24 months and 293 GB of
packet traces. Since the extrapolation algorithms we use are linear
in the number of scans in the events, we (cid:2)nd that our system takes
less than one minute to analyze the scan properties and perform
the extrapolation analysis for a given event. We use SNR= 50 and
a tail parameter ! = 5 for event extraction (ranging ! from 3 to
8 yields identical results). We extract 203 botnet scan events and
504 miscon(cid:2)guration events. There were a few moderate worm
outbreaks observed during the period, such as the Allaple worm [4].
Targeted
# of kinds of
Service
vul./probes
NetBIOS/SMB/RPC 7
VNC
1
1
Symantec
1
MS SQL
2
HTTP
Telnet
1
MySQL
1
Others
4
total
18
Events
81
39
34
14
13
12
6
4
203
Table 5: The summary of the events
The miscon(cid:2)guration events are mainly caused by P2P traf(cid:2)c. In
this paper, we focus on the botnet scan events.
We (cid:2)rst present characteristics of the botnet scanning events.
Then we present the botnet event correlation study. Next we dis-
cuss results for the four botnet scan pattern checking techniques
and their validation. We (cid:2)nish with the presentation of global ex-
trapolation results and their validation using DShield, a world-wide
scan repository.
5.1 Basic Characteristics of the Botnet Events
In Table 5, we break down 203 events according to their targeted
services. We (cid:2)nd that most of the events target popular services
that have large install-base. We also (cid:2)nd that 30 (14.8%) events are
purely port reconnaissance without any payloads. Another three
events check whether the HTTP service is open by requesting the
homepage. The remaining (83.7%) events target certain vulnera-
bilities. Therefore, these botnet scans likely re(cid:3)ect attempted ex-
ploitations.
Figure 7 shows the CDF of event duration. A botnet event can
last from a few minutes to a few days. There are 36 events that
last very close to half an hour, leading to the spike in the Figure 7.
As we will discuss in Section 5.2, it is a cluster of events which
scan the same vulnerability every half hour over and over again, for
days on end. Most likely these botnet events are driven by a single
botmaster. From Figure 8, we also (cid:2)nd that the number of sources
involved in a botnet event is quite heterogeneous. In Figure 9, we
show the CDF of unique number of ASes per event. Most of the
bots (62.7%) come from more than 100 ASes. Only 3% of events
re(cid:3)ect fewer than 20 ASes. This implies that cleaning the botnets
from some part of the world (some of ASes) will not improve the
situation. Also blocking them based on AS number is very hard due
to large number of ASes involved. We also (cid:2)nd that the number of
destinations a bot scans differs signi(cid:2)cantly for different events, as
show in Figure 10.
We further study the OS, AS and IP distribution of the events.
Table 4 in Section 4 shows the aggregated OS distribution. We see
that Microsoft Windows is the most popular OS, with more than
83% of bots using Windows 2000/XP. (We see similar results when
analyzing individual events.) For AS and IP address distribution,
we (cid:2)nd that the aggregated results (203 events together) are close
to those seen in previous work [25]. However, we (cid:2)nd very large
variation across individual events; thus, address blacklists derived
from one event might not be effective when defending against other
events.
0
.
1
0
.
1
y
t
i
l
i
b
a
b
o
r
p
l
e
v
i
t
a
u
m
u
c
8
.
0
6
.
0
4
.
0
2
.
0
8
.
0
6
.
0
y
t
i
l
i
b
a
b
o
r
p
e
v
i
t
a
u
m
u
c
l
4
.
0
2
.
0
0
.
0
1e+01
1e−01
1e+00
1e+02
event duration (hours)
1e+03
Figure 7: Event Duration.
0
.
0
500
100 200
5000
Figure 8: # of Sources.
# of sources per event
2000
0
.
1
0
.
1
y
t
i
l
i
b
a