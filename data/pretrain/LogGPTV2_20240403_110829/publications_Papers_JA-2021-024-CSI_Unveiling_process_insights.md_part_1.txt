Unveiling process insights from refactoring practices
Joa˜o Caldeira a, Fernando Brito e Abreu a, Jorge Cardoso b,c, Jos´e
Pereira dos Reis a
aIscte - Instituto Universit´ario de Lisboa, ISTAR-Iscte, Lisboa, Portugal
bCISUC, Dept. of Informatics Engineering
University of Coimbra, Portugal
cHuawei Munich Research Center, Germany
0202
Abstract
tcO
Context: Softwarecomprehensionandmaintenanceactivities, suchasrefac-
toring, are said to be negatively impacted by software complexity. The meth-
92
ods used to measure software product and processes complexity have been
thoroughly debated in the literature. However, the discernment about the
possible links between these two dimensions, particularly on the benefits of ]ES.sc[
using the process perspective, has a long journey ahead.
Objective: To improve the understanding of the liaison of developers’ activ-
ities and software complexity within a refactoring task, namely by evaluating
if process metrics gathered from the IDE, using process mining methods and
1v29651.0102:viXra
tools, are suitable to accurately classify different refactoring practices and
the resulting software complexity.
Method: We mined source code metrics from a software product after a
quality improvement task was given in parallel to (117) software developers,
organized in (71) teams. Simultaneously, we collected events from their IDE
work sessions (320) and used process mining to model their processes and
extract the correspondent metrics.
Results: Most teams using a plugin for refactoring (JDeodorant) reduced
softwarecomplexitymoreeffectivelyandwithsimplerprocessesthantheones
that performed refactoring using only Eclipse native features. We were able
tofindmoderatecorrelations(≈43%)betweensoftwarecyclomaticcomplex-
ity and process cyclomatic complexity. Using only process driven metrics, we
computed ≈30,000 models aiming to predict the type of refactoring method
Email addresses: PI:EMAIL (Jo˜ao Caldeira ), PI:EMAIL
(Fernando Brito e Abreu ), PI:EMAIL (Jorge Cardoso ),
PI:EMAIL (Jos´e Pereira dos Reis )
Preprint submitted to Computer Standards and Interfaces October 30, 2020
(automatic or manual) teams had used and the expected level of software
cyclomatic complexity reduction after their work sessions. The best models
foundfortherefactoringmethodandcyclomaticcomplexitylevelpredictions,
had an accuracy of 92.95% and 94.36%, respectively.
Conclusions: We have demonstrated the feasibility of an approach that al-
lowsbuildingcross-cuttinganalyticalmodelsinsoftwareprojects, suchasthe
one we used for detecting manual or automatic refactoring practices. Events
from the development tools and support activities can be collected, trans-
formed, aggregated, and analyzed with fewer privacy concerns or technical
constraintsthansourcecode-drivenmetrics. Thismakesourapproachagnos-
tictoprogramminglanguages, geographiclocation, ordevelopmentpractices,
making it suitable for challenging contexts such as in modern global software
development projects. Initial findings are encouraging, and lead us to sug-
gest practitioners may use our method in other development tasks, such as,
defect analysis and unit or integration tests.
Keywords: Software Complexity, Software Process Complexity, Software
Development Process Mining, Refactoring Practices
1. Introduction
“...All things - from the tiniest virus to the greatest galaxy - are, in
reality, not things at all, but processes...”1
—Alvin Toffler(1928-2016)2
A process3 is ”a series of actions taken in order to achieve a result”. In
many business areas, either on delivering products and/or services, the qual-
ity of the outcome is very often related with the process followed to build
it [1, 2, 3]. This is expected to be no different in the software development
domain. Therefore, to fully comprehend how software quality and improved
maintainability are achieved, one should look carefully to the process per-
spective to complement any code related analysis [4].
Software development is intrinsically a process and, accordingly, it is a
blend of activities performed by developers, often working from different
1In ”Future Shock”, Penguin Random House, New York, 1970.
2American writer, futurist, and businessman known for his works discussing modern
technologies, including the digital and the communication revolutions, with emphasis on
their effects on cultures worldwide.
3Adapted from https://dictionary.cambridge.org/dictionary/english/process
2
locations and using a multitude of languages, tools and methodologies in
order to create a new product or maintain an existing one [4]. Since the
early days of software development, it was understood that programming is
an inherently complex and error-prone process, and to fully understand it,
we should mine, in a timely and proper manner, all facets of that process
[5]. Any relevant insights one may obtain should therefore originate from
the activities and/or artifacts recorded in software repositories during the
development life cycle.
Studies on estimating the effort to develop a certain artifact, the identifi-
cation of software defects, the prediction of time to solve bugs or on software
comprehension, and the detection of refactoring opportunities, are amongst
the most common use cases for those repositories [6, 7, 8, 9, 10, 11, 12].
Refactoring on its own is still a very challenging activity. The iden-
tification of components to refactor and the forecast of which methods to
embrace continue to be relevant topics for research [13, 14, 15, 16]. These
challenges emerge partially due to the significant functionality limitations
software repositories contain and the type of data they use [17].
Some authors confirm that developers perform refactoring tasks manually
more frequently than automatically [12]. Furthermore, it has been observed,
in a real-life scenario, that refactoring can be harmful when done manually,
using only IDE native features or simply driven by developers’ skills, as it
may introduce non-expected defects in the code [18].
Ontryingtocomprehendsoftwaredevelopmentprocesses,includingrefac-
toring practices, many data sources, methods, and tools have been used with
validated outcomes, but some others are yet to be fully exploited [19]. For
example, since Version Control Systems (VCS) are widely used by develop-
ers, researchers get easy access to historical data of many projects and use
file-based VCSs as the primary source of code evolution data [20]. Although
it is often convenient to use such repositories, research-based on VCS data is
imprecise and incomplete [17].
As such, answering questions that correlate code changes with other ac-
tivities (e.g., test runs, refactoring) is often unfeasible. Several reasons may
contribute to it, as for instance:
• developers may not commit all their tests and/or refactorings;
• there are many ways to refactor one version of the code, therefore
it is important to determine the refactoring activities sequences and
frequencies;
• often we cannot distinguish if a refactoring was done manually or
through a tool, just by comparing source code snapshots [21].
3
1.1. Code vs. Process Analysis
Most published work on software quality-related issues is based on source
code metrics, especially on Java systems [22, 23, 24]. Tools for collecting
those metrics upon other frequently used languages, such as JavaScript or
Python, are often not available, which expose well the difficulties to repro-
duce the same research on projects having diverse languages. In case those
metric collection tools exist, they often require to share the source code with
third-party organizations [25], particularly on cloud-based platforms. Such
scenarios raise privacy and ownership issues on sensitive data. Source code
obfuscation does not mitigate this problem because developers need to keep
code semantics for interpreting the metrics in context.
Instead, mining the developers’ activities and behaviors, the same is to
say, to mine their development process fragments, may be a more feasible
approach since it is not specific to any programming language, geographic
location or development methodology followed.
Event data can be obfuscated without losing the process structure and
coherence, therefore, whoever is responsible to analyze the logs can apply
algorithms to discover process models in very similar ways as if the logs were
not obfuscated [26]. In other words, events from the development tools and
support activities can be collected, transformed and aggregated with fewer
privacy concerns and technical hurdles. As such, it has been pointed out that
software development event logs can be used to complement, or even replace,
source code data in software development analytics-related tasks [27].
1.2. Contributions
It is frequent to find software prediction models using source code and
ownershipmetrics[16]. However,periodicallythisdataisnoteasilyaccessible
or has imprecisions. Nowadays, development teams use a diversity of lan-
guages, methodologies and tools, therefore, the collection and aggregation of
data from software projects remains a challenge. Additionally, process met-
ricshavebeenfoundtobegoodpredictorsformodelingsoftwaredevelopment
tasks [28].
Thus, we proposed earlier [29] and are now evaluating deeper the use of
process metrics gathered from the IDE (Integrated Development Environ-
ment), as a way to enhance existing models or eventually, build new ones.
Software product and process metrics have long been proposed, as well as
techniques for their collection [30, 31, 32, 19, 33, 34, 35]. However, the asso-
ciation between product and process dimensions is only marginally discussed
in the literature [36]. In order to improve our understanding on the liaison
between the type of development activities executed and the resulting soft-
ware product characteristics, namely to ascertain if developers’ behavior has
4
an impact on software product quality, we collected data during a software
quality improvement task (application of refactoring operations) given to 71
development teams. Regarding developers’ behavior, we recorded all events
corresponding to the activities/tasks/operations team members performed
within their IDE and used those events to mine the underlying process and
extract their metrics. Regarding software quality, we collected complexity
metrics before and after the refactoring actions took place. The main objec-
tives for this work are, therefore:
• to assess the use of software process metrics to facilitate and improve
the analysis and predictions on refactoring tasks and/or other generic
software activities;
• to evaluate a possible association between the complexity of the pro-
duced code and developers’ practices in different refactoring tasks;
• tobuildclassificationmodelsforrefactoringpracticesusingonlyprocess
metrics and assess the prediction accuracy of such approach.
The rest of this paper is organized as follows: section 2 provides back-
ground related to the research area and emphasizes the need for the fol-
lowed approach; subsequent section 3 outlines the related work; the research
methodology and the study setup are presented in section 4; the results,
the corresponding analysis and implications can be found in section 5 and
threats to validity are discussed in section 6; the concluding comments and
the outline for future work are produced in section 7.
2. Background
Empirical software engineering and software analytics are now mature re-
search areas with substantial contributions to the software development best
practices [37]. The knowledge base created to support those achievements
took a great advantage from the experience gathered on analyzing past soft-
ware projects. Based on the maturity obtained, it was possible to derive
several models to measure software complexity, effort and relationships.
2.1. Early models
Lines of Code(LOC). The identification and quantification of software
size/defect relationship did not happen overnight. The first known “size”
law, saying the number of defects D was a function of the number of LOC;
specifically, D = 4.86 + 0.018 * i, was the result of decades of experience and
was presented by Fumio Akiyama [38].
5
Cyclomatic Complexity. One of the most relevant propositions to as-
sess the difficulty to maintain software was introduced by Thomas McCabe
when he stated that the complexity of the code was more important than the
number of LOC. He argued that when his “cyclomatic complexity” metric
was over 10, the code is more likely to be defective [39]. This metric, un-
derpinned by graph theory, went through thorough validation scrutiny and
then became the first software metric recognized by a standardization body,
theNIST[31],whatmakesitevenmorerelevantinthecontextofthisjournal.
Halstead Complexity. On trying to establish an empirical science of soft-
ware development, Maurice Howard Halstead, introduced the Halstead com-
plexity measures [40]. These metrics, which are computed statically from
the code, assume that software measurement should reflect the implementa-
tion or expression of algorithms in different languages, but be independent of
their execution on a specific platform. Halstead’s metrics were used, among
other things, to assess programmers’ performance in software maintenance
activities (measured by the time to locate and successfully correct the bug)
[41].
Effort Estimators. Later, Barry Boehm proposed an estimator for devel-
opment effort that was exponential on program size: effort = a∗KLOCb ∗
EffortMultipliers, where 2.4 ≤ a ≤ 3 and 1.05 ≤ b ≤ 1.2 [42].
Henry and Kafura Metrics. These two authors defined and validated a
setofsoftwaremetricsbasedonthemeasurementofinformationflowbetween
system components. Specific metrics are defined for procedure complexity,
software modules complexity, and module coupling [43].
The above models were the foundation knowledge for what is nowadays
often categorized as Software Development Analytics [44]. However, current
development methods, tools and data repositories are very different from the
past. Backinthoseyears, softwaredevelopersweremainlyusingatexteditor
and a compiler. Software projects were essentially built employing a single
programming language, following a fairly simple development methodology
and the developers were rarely located in different geographies or across
multiple time zones. These workspace conditions have changed.
6
2.2. Modern Days
In 2019, JetBrains4 polled almost 7000 developers about their develop-
ment ecosystem. Results show that more than 30 different programming
languages are being used and confirmed that web back-end, web front-end
and mobile applications are the type of applications mostly developed, with
figures of 60%, 46% and 23%, respectively. It was unanimous the adherence
of cross-platform development frameworks and 80% said they use any type
of source code collaboration tool, 75% use a standalone IDE and 71% use
a lightweight desktop editor. Almost 50% said they use continuous integra-
tion/delivery (CI/CD) and issue tracking tools. Less than 15% responded
that they use any sort of static analysis, code review and in-cloud IDE tools.
Table 1 presents the key takeaways from the mentioned survey.
Insummary, currently, asoftwaredevelopmentecosystemhastodealwith
at least the following facets:
• Multi-Language Ecosystem. According to a recent work about
multi-languagesoftwaredevelopment[45],theauthorspresentevidences
that non-trivial enterprise software systems are written in at least 7
programming languages and, a previous work showed that in the open
source world alone, the average is 5 languages per project. Among
these, one may find general-purpose languages(GPL) such as Java or
C# and also domain-specific languages(DSL) like SQL and HTML,
and cross-language links are also quite common, meaning some code
artifacts are shared between languages. As a result, developers con-
firm they find more problems in activities such as implementing new
requirements (78%) and in refactoring (71%).
• IDE Evolution. A substantial change was carried in the Integrated
DevelopmentEnvironments(IDEs). Softwaredevelopmentmovedaway
from the early days of the code editor. As confirmed by the Jetbrains
poll, developers now use powerful platforms and frameworks which al-
low them to be more productive on their jobs. This results from the
combination of different software development life cycle activities, such
as: requirementselicitation,producinganalysisanddesignmodels,pro-
gramming, testing, configuration management, dependencies manage-
ment or continuous integration into one single tool such as Eclipse,
IntelliJ IDEA, Netbeans or Visual Studio Code. These tools sup-
port the needs of different stakeholders, as they embed a myriad of
4https://www.jetbrains.com/lp/devecosystem-2019/
7
Table 1: Survey Key Takeaways*