    ScriptTransformer: It is possible to write transformers in Javascript or any other scripting language supported by Java
    DateFormatTransformer: It is useful for parsing date/time strings into java.util.Date instances
    NumberFormatTransformer: Can be used to parse a number from a String
    TemplateTransformer: Can be used to overwrite or modify any existing Solr field or to create new Solr fields
    HTMLStripTransformer: Can be used to strip HTML out of a string field 
    ClobTransformer: Can be used to create a String out of a Clob type in database
    LogTransformer: Can be used to Log data to console/logs
    EntityProcessor: Each entity is handled by a default Entity processor called SqlEntityProcessor. This works well for systems which use RDBMS as a datasource 
    SqlEntityProcessor: This is the defaut. The DataSource must be of type DataSource>> . JdbcDataSource can be used with this
    XPathEntityProcessor: Used when indexing XML type data
    FileListEntityProcessor: A simple entity processor which can be used to enumerate the list of files from a File System based on some criteria. It does not use a DataSource
    CachedSqlEntityProcessor: This is an extension of the SqlEntityProcessor. This EntityProcessor helps reduce the no: of DB queries executed by caching the rows. It does not help to use it in the root most entity because only one sql is run for the entity
    PlainTextEntityProcessor: This EntityProcessor reads all content from the data source into an single implicit field called 'plainText'. The content is not parsed in any way, however you may add transformers to manipulate the data within 'plainText' as needed or to create other additional fields
    LineEntityProcessor: This EntityProcessor reads all content from the data source on a line by line basis, a field called 'rawLine' is returned for each line read. The content is not parsed in any way, however you may add transformers to manipulate the data within 'rawLine' or to create other additional fields
    SolrEntityProcessor: This EntityProcessor imports data from different Solr instances and cores
    DataSource:A class can extend org.apache.solr.handler.dataimport.DataSource and can be used as a DataSource. 
    JdbcDataSource: This is the default. 
    URLDataSource: This datasource is often used with XPathEntityProcessor to fetch content from an underlying file:// or http:// location
    HttpDataSource: is being deprecated in favour of URLDataSource in Solr1.4. There is no change in functionality between URLDataSource and HttpDataSource, only a name change.
    FileDataSource: This can be used like an URLDataSource but used to fetch content from files on disk. The only difference from URLDataSource, when accessing disk files, is how a pathname is specified 
    FieldReaderDataSource: This can be used like an URLDataSource  
    ContentStreamDataSource: Use this to use the POST data as the DataSource. This can be used with any EntityProcessor that uses a DataSource 
    The entity for an xml/http data source can have the following attributes over and above the default attributes
    processor (required) : The value must be "XPathEntityProcessor"
    url (required) : The url used to invoke the REST API. (Can be templatized). if the data souce is file this must be the file location
    stream (optional) : set this to true , if the xml is really big
    forEach(required) : The xpath expression which demarcates a record. If there are multiple types of record separate them with " | " (pipe) . If useSolrAddSchema is set to 'true' this can be omitted
    xsl(optional): This will be used as a preprocessor for applying the XSL transformation. Provide the full path in the filesystem or a url
    useSolrAddSchema(optional): Set it's value to 'true' if the xml that is fed into this processor has the same schema as that of the solr add xml. No need to mention any fields if it is set to true
    flatten (optional) : If this is set to true, text from under all the tags are extracted into one field , irrespective of the tag name.
    The entity fields can have the following attributes (over and above the default attributes):
    xpath (optional) : The xpath expression of the field to be mapped as a column in the record . It can be omitted if the column does not come from an xml attribute (is a synthetic field created by a transformer). If a field is marked as multivalued in the schema and in a given row of the xpath finds multiple values it is handled automatically by the XPathEntityProcessor. No extra configuration is required 
    commonField : can be (true| false) . If true, this field once encountered in a record will be copied to other records before creating a Solr document 
### PoC Evolution
#### The first phase -- database driver + external connection + no echo
According to the official [vulnerability warning
description](https://issues.apache.org/jira/browse/SOLR-13669), a DIH config
can contain scripts. There is an example of a ScriptTransformer I found in
[Documents]
():
We can see that the java code can be executed in the script. Construct PoC
(see the related error message through logs to view the problem of the PoC
structure). This database can be externally connected, so the related
information of the database can be controlled by itself.
In the example of ScriptTransformer, you can see the word row.put. Maybe we
can get the echo. Test it:
Here we can see the id field but cannot see the name field. There is no error
in logs. I tried to put the data into the id:
We can see the information that is echoed. At first I didn't know why putting
to name failed, but when I saw the PoC in the third stage and then went back
to find information, I realized that dataConfig and schema should be used
together. The name field is not configured in the schema, but the fileid id is
defined by default, so solr does not put the name field data into the Document
but it will put the id field. In the third phase of PoC, the name attribute in
each Field has "_s". I searched to find that dynamicField can be configured in
the schema configuration file. The following is the default configured
dynamicField:
In the above related concepts, this field is introduced. And it passed the
test:
As long as the dynamicField can match the name attribute of the field in the
dataConfig, Solr will be automatically added to the document. If the schema is
configured with the corresponding field, the configured field will take
precedence. If there is no configuration, it will match according to the
dynamicField.
#### The second phase -- external connection + no echo
In the documentation, JdbcDataSource can use JNDI,
Test if we can do the injection:
There is a malicious [demo](https://github.com/kxcode/JNDI-Exploit-Bypass-Demo) of JNDI+LDAP and it does not require the goal CLASSPATH to have a
database driver.
#### The third phase -- no external connection + echo
@fnmsd made this PoC by using [ContentStreamDataSource]
(https://cwiki.apache.org/confluence/display/SOLR/DataImportHandler#), which
is not described in the documentation. I found an example in
[stackoverflower]()
The ContentStreamDataSource can receive Post data as a data source. We can get
a echo by combining it with the dynamicField mentioned in the first stage.
And here is the result.
After going back to look at other types of DataSources, you can also use
URLDataSource/HttpDataSource. An example is provided in the documentationï¼š
Constructing a test is also possible, you can use protocols such as http, ftp,
etc.
### Reference link
  * 
  * 
  * 
  * 
# About Knownsec & 404 Team
Beijing Knownsec Information Technology Co., Ltd. was established by a group
of high-profile international security experts. It has over a hundred frontier
security talents nationwide as the core security research team to provide
long-term internationally advanced network security solutions for the
government and enterprises.
Knownsec's specialties include network attack and defense integrated
technologies and product R&D under new situations. It provides visualization
solutions that meet the world-class security technology standards and enhances
the security monitoring, alarm and defense abilities of customer networks with
its industry-leading capabilities in cloud computing and big data processing.
The company's technical strength is strongly recognized by the State Ministry
of Public Security, the Central Government Procurement Center, the Ministry of
Industry and Information Technology (MIIT), China National Vulnerability
Database of Information Security (CNNVD), the Central Bank, the Hong Kong
Jockey Club, Microsoft, Zhejiang Satellite TV and other well-known clients.
404 Team, the core security team of Knownsec, is dedicated to the research of
security vulnerability and offensive and defensive technology in the fields of
Web, IoT, industrial control, blockchain, etc. 404 team has submitted
vulnerability research to many well-known vendors such as Microsoft, Apple,
Adobe, Tencent, Alibaba, Baidu, etc. And has received a high reputation in the
industry.
The most well-known sharing of Knownsec 404 Team includes: [KCon Hacking
Conference](http://kcon.knownsec.com/#/ "KCon Hacking Conference"), [Seebug
Vulnerability Database](https://www.seebug.org/ "Seebug Vulnerability
Database") and [ZoomEye Cyberspace Search Engine](https://www.zoomeye.org/
"ZoomEye Cyberspace Search Engine").
* * *