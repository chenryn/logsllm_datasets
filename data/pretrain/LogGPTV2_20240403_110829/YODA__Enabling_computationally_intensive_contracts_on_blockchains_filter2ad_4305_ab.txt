a version which does. Studying other possible MIRACLE
algorithms is part of our future work.
Naive Solution 1 (NS1): Suppose we use a single subset ES
from SP to compute Ψ(x). If more than 50% of nodes in
the ES publish the same execution result then this is chosen
as Ψ(x). One shortcoming of this scheme is that for lower
β (more security), the size of ES must be a large fraction of SP.
A second shortcoming is that if the actual fraction of Byzantine
nodes f is much smaller than fmax then we end up using an
ES much larger than required. For example, with β = 10−20
as the error, starting with |SP| = 1600 and fmax = 0.35, NS1
will always pick |ES| ≈ 900 independent of f.
Naive Solution 2 (NS2): In this solution we relax the require-
ment of achieving consensus in one round. If in an ES, the
fraction of nodes submitting a particular solution exceeds some
threshold then we terminate with that solution. This threshold
should be high enough to ensure the correct solution w.h.p. In
NS1 for example, the threshold is 1/2. In general, the smaller q
is the larger will the threshold be. If we do not reach consensus
then a new round is triggered.
The advantage is that we can use an ES in each round of size
smaller than the ES used in NS1. In NS2, in certain instances
such as when f = 0, a single round may still be sufﬁcient to
reach consensus. One shortcoming is that the number of rounds
to terminate can be large because NS2 does not optimally
combine the results of all rounds in order to reach consensus.
Results of one round are forgotten in future rounds.
B. Design and Algorithm
In MIRACLE, we employ the multi-round strategy of NS2
to achieve gains in case f (cid:28) fmax. In contrast to NS2, each
round uses all hitherto published results to decide whether to
terminate or not. For a given Ψ(x), let d1, d2, ..., dm be the
m unique digest values broadcast up to and including the ith
round. Let ck,i denote the number of times dk is repeated in
the ith round. Let Ci denote the total number of submissions
(ES nodes) in the ith round, i.e. Ci =(cid:80)m
k=1 ck,i.
The problem we are addressing is to decide among one of
may solutions broadcast. We present a novel model of this
problem as a multiple hypothesis testing problem where we
have one hypothesis for each solution submitted and the test
must decide which hypothesis is true.
Primer on Hypothesis Testing. For the reader unfamiliar
with Hypothesis testing, we now describe a standard example.
Consider a communication system in which a source is trans-
mitting one symbol selected from a known small master set to
a receiver over a noisy channel. In the simplest case, only two
symbols are allowed, one each for communicating bit 0 and
bit 1. The receiver’s task is to decide which symbol (and hence
which corresponding bit(s)) was transmitted given the observa-
tion. To solve the problem, one proposes a hypothesis for each
potential symbol which claims that the corresponding symbol
was transmitted. The goal is to determine which hypothesis is
true. To do so, the receiver computes the probability of the
observation conditioned on every hypothesis being true. Only
if one of these probabilities is much larger than the others can
one say with conﬁdence that the corresponding hypothesis is
true with high probability.
One of our novel contributions in MIRACLE is to formulate
the problem of determining the true Ψ(x) as a hypothesis
testing problem. This is not obvious because traditional hy-
pothesis tests are designed to handle real-world phenomena
such as signals in noise. In our problem we have an intelligent
adversary which is hard to model as there is no restriction on
what solution it can submit. It can submit any of 2n digests
if the digest is n bits long. Hence unlike the communication
problem described above,
there is no small master set of
potential correct solutions known a priori to YODA.
However, in the worst case when the fraction of Byzantine
nodes is maximum, i.e. f = fmax, we do have a probability
distribution on the total number of Byzantine nodes in an
ES. Similarly we have a probability distribution of the total
number of quasi-honest nodes in an ES. These probability
distributions are sufﬁcient for us to compute a likelihood and
perform a hypothesis test. In the case the adversary submits
only a single incorrect solution, MIRACLE is optimal in
the number of rounds it takes to converge. However, if it
submits many solutions then our assumed distributions for
different hypotheses are not exact. Fortunately, if the adversary
submits more than one solution, it is to his own detriment as
MIRACLE will converge to the correct solution with higher
probability than if it submitted only a single solution.
MIRACLE uses multiple parallel Sequential Probability
Ratio Tests (SPRT) to choose the correct solution [28] whose
details are given next.
MIRACLE as Parallel SPRT: We model the problem as
m simultaneous two-hypotheses Sequential Probability Ratio
Tests (SPRT) [28]. The kth SPRT is given by:
• Null Hypothesis, Hk : dk is the solution.
• Alternative Hypothesis, H∗
k : dk is not the solution.
The log-likelihood ratio is deﬁned as the log of the ratio of
probabilities of the observations (ck,i) conditioned on the two
hypotheses. We approximate this log-likelihood ratio after i
rounds by a quantity we loosely call the likelihood. We denote
it by Lk,i, and proceed as follows. We give a formula for the
likelihood subsequently. For appropriately chosen threshold T,
in round i we perform
• If Lk,i ≤ T, make no decision.
• If Lk,i > T, decide in favor of Hk.
When any one SPRT, say the kth, terminates in favor of
its Null Hypothesis Hk, we halt all other SPRTs and declare
dk as the digest. If no SPRT terminates, we proceed to the
next round. Algorithm 1 demonstrates the general MIRACLE
algorithm for any given Lk,i and T.
MIRACLE and YODA. We now present our speciﬁc choices
for the likelihood Lk,i and threshold T which we use in
YODA. MIRACLE can in general use other choices for the
same quantities, and such generalisations are part of future
work.
Recall that nodes are selected randomly and with the same
4
Algorithm 1 MIRACLE
1: i ← 1
2: while Lk,i ≤ T ∀k do
3:
4:
5: end while
6: declare dk(cid:48) to be correct where Lk(cid:48),i > T
i ← i + 1
Pick next ES to execute Ψ(x)
Lk,i =
probability q for any ES. We set
i(cid:88)
k,j − (Cj − ck,j)2(cid:1) =
(cid:0)c2
(cid:18)
j=1
and the threshold to:
1 − β
β
T =
ln
i(cid:88)
((2ck,j − Cj)Cj)
j=1
(cid:19) 2q(1 − q)M (1 − fmax)fmax
(1 − fmax) − fmax
(1)
.
(2)
The above choice of Lk,i is indeed the log-likelihood ratio
when the adversary submits a single incorrect solution in all
rounds, assuming a Gaussian distribution for the number of
quasi-honest and Byzantine nodes in any ES. Under the same
assumptions, in Section VII-A we describe how this choice
of threshold gives an optimal solution in terms of number of
rounds to terminate along with required security.
IV. RICE: RANDOMNESS INSERTED CONTRACT
EXECUTION
MIRACLE by itself does not force quasi-honest nodes
to behave honestly. In fact, a free-loading attack by quasi-
honest node is a real possibility. Here quasi-honest nodes
in an ES of one round may simply replay the digest with
highest likelihood of previous submissions in earlier rounds.
Even though this enables a quasi-honest node to save on
heavy CIC computation, this attack can make increase the
probability of accepting an incorrect solution to larger than
β. Speciﬁcally, in scenarios where the corresponding digest is
an incorrect solution, as an adversary can sometime dominate
a large fraction in ES, free-loading can lead to acceptance of
an incorrect solution.
To address this in this section we describe Randomness
Inserted Contract Execution (RICE), a procedure to pseudo-
randomly change the digest of Ψ(x) from one round to the
next to mitigate the free-loading problem. Other attacks, such
as collusion of quasi-honest nodes within the same ES and
copying digests submitted by nodes in the same round are
addressed in §VI.
So far we have looked at Ψ as a very abstract function
without describing any of its details. We now formally deﬁne
the semantics of Ψ required to understand RICE.
A. Design of RICE
Setup. We assume Ψ to be a stateful function similar to a
smart contract. Let σ be the state on which Ψ operates by
taking an input x. The output of Ψ(σ, x) is the modiﬁed state
σ∗. Call root(σ) (or simply root) a unique digest of σ. For
example, root can represent the root of a Merkle tree where
leaves of the tree correspond to the contents of σ.
Let j (≥ 1) be the MIRACLE round number. We wish to
generate a pseudorandom digest in each round. At the same
time, to compute likelihoods, we must be able to map digests
across different rounds to each other. To solve the paradox,
we generate a digest (seed(j,.), root), where seed(j,.) is a
pseudorandom number which changes from one round to the
next. The seed is initialized as:
seed(j,0) ←
if j = 1
RandomGen()
hash(seed(j−1,0)) otherwise
(3)
(cid:40)
Array Model for RICE. Consider an execution model in
which all machine level instructions that Ψ(σ, x) executes
are stored in an imaginary “instruction array”, that is the ith
instruction executed is stored in the ith array position. RICE
then interrupts execution6 of Ψ(σ, x) at certain intermediate
indices of the array where state of the CIC is σ(cid:48) and updates
the seed as follows:
seed(j,l+1) ← hash(seed(j,l)||root(σ(cid:48)))
(4)
By choosing these different indices pseudorandomly in differ-
ent rounds, RICE produces a different digest every round. ES
nodes then submits (seed(j,φ), root(σ∗)) as the digest after
executing Ψ(σ, x), where φ is the total number of times the
seed has been updated.
Due to the deterministic nature of the Ψ, all nodes computing
Ψ(σ, x) correctly will have the same root across rounds. The
seed values of all honest nodes will be identical within any
round, but will differ from one round to the next. Malicious
nodes may submit the correct root but the wrong digest, an
attack we guard against in §VI
Details. Let t denote the indices in the instruction array where
t ∈ [1 : T ] where T is the total number of instructions
executed as a part of Ψ(σ, x). Note that T is unknown a
priori, but assumed to be bounded. Speciﬁcally, for systems
such as Ethereum where CIC transactions have a gas limit,
T is guaranteed to be bounded (refer §VI). Thus to update
digest, instead of executing the entire Ψ array in a single run,
RICE progressively executes a subarray of Ψ array between
two index ti (initial) and tf (ﬁnal), updates the seed, and
repeats the process with the next sub-array and so on until
it reaches T .
Formally, let Ψ[ti : tf ] denote an arbitrary subarray from
Ψ with ti and tf its initial and ﬁnal index. RICE consists of
a new deterministic contract execution function Ψ(cid:48) with the
following semantics. Inputs to Ψ(cid:48) are two indices ti, tf , an
intermediate CIC state σ(cid:48) and x. Given input (ti, tf , σ(cid:48), x), Ψ(cid:48)
executes subarray Ψ[ti : tf ] (both ti, tf inclusive) with state
σ(cid:48) and data x. After execution, Ψ(cid:48) returns a modiﬁed state
and the last successfully executed index. In the special case
where T < tf for some (ti, tf ), Ψ(cid:48)(ti, tf , σ(cid:48), x) runs only till
Ψ[ti : T ] and returns σ∗, T as its output. Formally,
(σ(cid:48), tf ), if tf < T
(σ∗, T ), if tf ≥ T
After executing (l + 1)th subarray of Ψ(σ, x), RICE updates
the seed via (4).
← Ψ(cid:48)(ti, tf , σ(cid:48), x), where σ∗ = Ψ(σ, x)
(cid:27)
Algorithm 2 gives the pseducode of RICE.
6Blockchains such as Ethereum count gas used after each instruction. Hence
additional interrupts are not required for Ethereum-like blockchains.
5
(cid:46) Next subarray indices
σ(cid:48), tl ← Ψ(cid:48)(σ(cid:48), ti, tf , x)
if tl is T then
return (seed(j,l), root(σ(cid:48)))
Algorithm 2 RICE
1: input seed(j,0), σ, x
2: σ(cid:48) ← σ, l ← 0
3: ti, tf ← NEXT
4: while true do
5:
6:
7:
8:
9:
10:
11:
12: end while
end if
seed(j,l+1) ← hash(seed(j,l)||root(σ(cid:48)))
l ← l + 1
ti, tf ← NEXT
B. Choosing the indices.
A naive strategy is to choose indices tf as multiples of a
ﬁxed number, say ∆. Note that ∆ cannot be a function of T
which is not known prior to computing Ψ. This strategy leads
to overheads of O(T ).
Another problem arises because indices do not change from
one round to the next. Suppose a quasi-honest node of the
current wants to free-load the root values at these indices
from an earlier round. It can ask any node from an earlier
ES to provide these root values and use (4) to verify that they
indeed corresponded to the digest submitted by that node,
thereby giving it conﬁdence that these root values are correct.
It can then reuse these root values to create its own digest
without performing the computation. In case the ES node
queried is malicious, the quasi-honest node will submit an
incorrect solution.
A second naive strategy is to choose the sub-array sizes
randomly but with mean size exponentially increasing as
Ψ progresses. For example, choose tf − ti randomly from
[2k : 2k+1] where k increments by 1 from one sub-array to
the next. On the positive side, this will lead to O(log2T ) seed
updates (and consequently overheads of that order) and also
will produce a different set of indices from one round to the
next with large probability.
However, there remains the problem of skipping computing
the last sub-array of the instruction array. Suppose a quasi-
honest node in the current round’s ES has learned the value of
T from ES nodes of earlier rounds. It can perform computation
of Ψ for all sub-arrays except for the last one. Then it can
use a value of root submitted in an earlier round in (4) to
obtain the ﬁnal seed value, without computing the last sub-
array. For this strategy the last sub-array can be as large as T /2,
leading to nodes skipping as much as half of the computation.
Hence although overheads have reduced to O(log2T ),
the
computation skipped at the end is O(T ). We seek to ﬁnd a
sweet spot between the two with our choice of indices for
RICE.
Our Approach. RICE uses a hybrid of
the two index
locating procedures described above. The idea is to di-
vide the array Ψ(cid:48)
into sub-arrays of size 2k where k =
1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, . . .. In other words, every value of
k repeats k times. Thus,
like the second naive scheme
the sub-array size increase, but much more gradually (sub-
exponentially) so that
the last sub-array which might be
skipped is smaller. More precisely, for a sub-array of size 2k
6
Algorithm 3 Next subarray indices
1: Let K = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, . . .]
2: procedure NEXT(seed, σ, index, tf )
k ← K[index]
3:
pivot ← tf − int(seed[1 : k]) + 2k
4:
nextSeed ← hash(seed||root(σ(cid:48)))
5:
ti ← tf + 1
6:
tf ← pivot + int(nextSeed[1 : k])
7:
return ti, tf
8:
9: end procedure
we choose the index to update the seed as int(seed[1 : k])
away from the beginning of the sub-array, where int(seed[1 :
k]) denotes the integer whose binary representation is identical
to the ﬁrst k bits of seed. Algorithm 3 demonstrates our
approach.
V. CIC PRELIMINARIES
Smart Contracts and its Execution. A smart contract in
YODA is denoted by its state σ = (cid, code, storage).
Here cid denotes its immutable globally unique cryptographic
identity, and code represents its immutable program logic
consisting of functions. The state can be modiﬁed by a
transaction invoking its code and its execution can only begin
at a function. Functions may accept data from sources external
to the blockchain which must be included in the transactions
invoking them. In YODA smart contracts are stateful and state
is maintained as (key, value) pairs which together we refer to
as storage.
A transaction τ in YODA is the tuple (tid, f unId, data, ξ).
Here tid is a globally unique transaction identity and f unId
is the function it invokes. All external inputs required for the
function are part of data and ξ consists of meta-information
about the account that generated the transactions along with
a cryptographic proof of its authenticity. Hereafter we assume
all transactions are validated using ξ before being included in
a block and hence we drop ξ.