✓
✓
32
✓
✓
✓
9
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
20
40
27 / 54 ✓
4 / 52 ✓
28 / 54 ✓
33 / 54 ✓
32 / 54 ✓
0 / 54
8 / 47 ✓
20 / 54 ✓
39 / 54 ✓
13 / 54 ✓
16 / 54 ✓
19 / 53 ✓
22 / 52 ✓
34 / 54 ✓
6 / 54 ✓
34 / 54 ✓
23 / 54 ✓
29 / 52 ✓
20 / 52 ✓
24 / 54 ✓
35 / 53 ✓
0 / 54
0 / 54
0 / 53
0 / 54
0 / 54
0 / 54
0 / 53
0 / 53
0 / 54
0 / 54
50
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
57
✓
✓
Table 2: Malware detection results over the malware benchmark. Shaded ids (i.e., m1∼m53 and sm1∼sm5) are malware. sb1∼sb5
are benign samples. Red cells and dark gray cells represent false positives and false negatives respectively.
files were not detected by VT and our manual inspection result
shows that they are false positive (Fig. 6- 4 - A ).
Figure 7: Types of Malware Reported by VirusTotal.
VT also recognized 2,406 of PhpMalScan’s 3,891 (3,748 + 143)
detected samples as malware, while not recognizing 1,485 of them
(Fig. 6- 4 - B ). Out of the 2,406 recognized samples, 741 were de-
tected by only 1 engine, while 797 were detected by exactly two
engines. 836 were detected by less than 5 engines, leaving only 32
samples that were discovered by several engines. 65 samples recog-
nized by both maldet and VT were not detected by PhpMalScan.
Our manual inspection on these cases shows that they are malicious
code that either use deprecated PHP features, or are dead code, and
thus are no longer harmful (as they cannot be executed anymore).
Fig. 6- 5 depicts the result of our manual sub-sampling and inves-
tigation of malware samples detected by maldet and PhpMalScan,
to obtain false positive rates. We used standard sub-sampling tech-
niques to obtain the number of sub-samples which gives us 95%
confidence with 10% margin of error. Out of the 69 sub-samples
randomly selected and investigated from 238 maldet detections, 11
(16%) were false positives while 58 (84%) were true positives. Out
of the 94 sub-samples randomly selected from 3,891 PhpMalScan
detections, 2 (2.13%) were false positives and 92 (97.87%) were true
positives. The 2 false positives were a program that loads several
external modules from the Internet and run them, and a program
that generates PDF files outside the program directory, respectively.
Malware Types and Distribution: To better understand the samples
detected by VT, we categorize them by their types inferred from
the detected names. Fig. 7 shows the result. Webshell takes the
largest portion (40.45%). The second largest portion is obfuscation
(30.80%) where VT detects the samples because they are obfuscated.
However, as discussed in Section 4.3, benign programs are also
obfuscated in practice, resulting in false positives. Backdoor and
Agent malware (e.g., lurking in the system for a long time and
delivering future malware or payload) are 14.55% and 10.86% re-
spectively. Others include Spammer (0.91%), Downloader/Uploader
(0.78%), Phishing Webpages (0.57%) and Packed programs (0.41%).
Note that benign programs can be packed, leading to false positives.
4.3 Scanning Malware Samples (Dataset B)
In Section 4.2, we showed that MalMax is highly effective in
analyzing and discovering real-world (unknown) malware in the
wild. However, as we do not have ground-truth on the dataset A,
our experiment does not provide the precision of MalMax (and
PhpMalScan). In this section, we used dataset B, for which we had
ground-truth, to understand the precision of our technique.
4.3.1 Detection Precision. We ran PhpMalScan as well as several
state-of-the-art malware detection tools on our real-world and
synthesized malware benchmark suite. Table 2 provides the results
of evaluating different tools on the benchmark suite. For each tool,
✓ in a light gray cell means malicious behaviors were detected,
where a dark gray cell represents a false negative case (i.e., failed to
detect a malware sample). The table lists all 63 samples including
WebShell40.45%Obfuscation30.80%Backdoor14.55%Malware	(Agent)10.86%Spammer0.91%Downloader/Uploader0.78%Phishing	Webpages0.57%Packed0.41%Others0.67%53 diverse real-world PHP malware (from m1 to m53) and 5 benign
and 5 malicious synthesized samples (from sb1 to sb5 and from sm1
to sm5 respectively). The filenames of samples are omitted due to
the space and can be found on the project website [4]. A perfect
tool would be able to identify the 58 malware in this set. Results
from existing tools are as follows:
• Linux Malware Detector (maldet) flags 31 (53% TP) malware
samples and one benign sample as malicious (red cell, sb1)
which is an obfuscated benign program.
• BackdoorMan only detects 9 programs as malware where 2
of them are false positives (sb1 and sb3). sb3 uses a PHP func-
tion create_function() to create dynamic code and then
execute it, although the dynamic code is not from untrusted
sources (e.g., external inputs), hence not malicious. Back-
doorMan detects dynamically generated code as malicious,
regardless of the internal behavior.
• PHP Malware Finder (phpmaldet) only detects 20 (34% TP)
• ClamAV detects 40 instances recognized as malware, one
of which is a false positive (sb1), resulting in 39 (67% TP)
correct detections. It also flags sb1 as malicious due to the
obfuscation applied to the sample.
• VirusTotal detects 50 (86% TP) of the malware in the set, but
fails to detect one real-world malware (m38) which is a recent
malware we collected from the wild and any of the synthetic
samples as they are not included in virus databases, showing
that signature-based antivirus solutions are less effective in
detecting unknown malware.
of the malware in the benchmark.
PhpMalScan. We detected 57 of the 58 malware in the benchmark,
with no false positives, in under 20 seconds. There is one malware
(m36) that was not recognized by PhpMalScan. This malware
uses features in the set of weaknesses of our technique, MalMax,
using counterfactually executed branches’ invariants in control flow
decisions dynamically, thereby preventing counterfactual execution
to reach and analyze the malicious behavior within a predefined
timeout. Increasing the timeout can solve the issue, meaning that
it is a limitation of PhpMalScan, not of MalMax.
Observations. First, many malware detectors consider obfusca-
tions as malicious, regardless of the internal behaviors of programs.
Note that obfuscating benign programs is common in practice, used
in thousands of popular PHP libraries as a means of protecting
them against reverse engineering and license tampering [30, 42].
Second, existing tools (particularly signature-based tools) are
not effective at detecting new and/or unknown malware samples.
Specifically, only BackdoorMan detects one synthesized malware
sample as malicious. However, the tool also marked two benign
synthesized samples as malicious, motivating us to develop and
include techniques in MalMax that can precisely detect malware
with sophisticated obfuscation.
4.4 Scanning Benign Applications
We ran various malware detection tools on real-world benign ap-
plications to understand the precision of the tools. Table 3 lists the
statistical features of the applications used in this experiment. Note
that these applications are diverse. Joomla has only 446 include
statements, but has more than 2400 files. To include the 2400 files
using 446 statements, several include statements should be dy-
namic, i.e., they should evaluate an expression and then include it as
a file. Our manual inspection confirms such behavior—the majority
of Joomla files are included using PHP autoloaders [54]. (Although
Joomla has the most Lines of Code (LOC), it has fewer expres-
sions than phpMyAdmin, which has about two thirds of Joomla’s
LOC. Expressions can be a better proxy for functionality in PHP
applications compared to LOC. As for the number of statements,
Wordpress, despite having the least LOC among the four, has the
second most statement count.For the sake of our analysis, which
aims to cover as many execution paths as possible, the number
of branches is of interest. In this regard, Joomla and Wordpress
outweigh the other two by a factor of two.
Results. PhpMalScan does not flag any files as malware when
scanning these benign applications, meaning that it has no false
positives. BackdoorMan and PHP Malware Detector emit hundreds
of false warnings (categorized as suspicious) when scanning these
applications. Specifically, BackdoorMan generates 393, 514, 263, and
688 warnings and PHP Malware Detector emits 251, 1141, 36, and
36 warnings for Wordpress, Joomla, phpMyAdmin, and CakePHP
respectively. Note that those warnings are false positives as those ap-
plications are all benign. Moreover, PHP Malware Detector reports
4 malware in Joomla and 2 malware phpMyAdmin respectively.
Name
Includes
Wordpress
Joomla
phpMyAdmin
CakePHP
678
446
1,217
121
Table 3: Statistical features of applications evaluated.
Version LOC Files Statements Expressions Branches
469K
641K
724K
625K
17K
20K
10K
7K
4.2.2
3.5.1
4.6.1
3.0.18
262K 480
472K 2,477
303K 869
351K 1,805
58K
95K
38K
53K
4.5 Overhead
Runtime Performance. Scanning large real-world applications
such as the ones listed in the tables reveals the performance and
limitations of different tools. Linux Malware Detector spends sig-
nificant time scanning these applications, up to 333 seconds for
Joomla. BackdoorMan also spends significant time scanning these
applications, up to 291 seconds for Joomla. ClamAV, PHP Malware
Finder, and our tool spend less than 30 seconds analyzing Joomla.
maldet backdoorman phpmaldet ClamAV PhpMalScan
Wordpress
Joomla
phpMyAdmin
CakePHP
88.7
332.9
177.7
157.2
64.4
291.6
111.0
214.1
8.1
24.7
15.9
13.9
21.0
30.2
25.0
19.7
14.8
12.2
3.0
5.0
Table 4: Runtime performance of scanning the popular web
applications. All times are in seconds.
As shown in Table 4, PhpMalScan outperforms all other tools
except for PHP Malware Finder on Wordpress, which is about 7
seconds faster. We analyzed that case and discovered that it is
because Wordpress uses several loops that load its framework based
on the database data, and our tool needs to unwrap most of these
loops while actually fetching new functionality from the database,
which results in a significant slowdown. However, unwrapping
loops is essential in revealing malicious behaviors in real-world
malware, hence, we believe this slowdown is acceptable.
Memory Consumption. Our prototype typically uses about 200MB
of memory, although at times it can run up to 1 GB due to nesting
isolations caused by the counterfactual execution (Section 3.1). The
other tools typically consume less than 200MB of memory, except
for some antivirus tools that load signature databases into memory
before execution (e.g., ClamAV), which take up to 1 GB. We believe
PhpMalScan (and its underlying infrastructure MalMax) incurs a
reasonable memory overhead in modern computing environments.
4.6 Case Study
We present investigation of two malware samples that are not
detected by VirusTotal.
Sample I: Delivering Payload through Benign Website. Fig. 8-
(a) shows the malware in its original form (i.e., obfuscated). Due
to the obfuscation, most AVs in VT fail to detect it. We leverage
MalMax to deobfuscate the malware and the result is shown in
Fig. 8-(b). We use VT to scan the deobfuscated code and 2 AVs detect