title:Scout: A Point of Presence Recommendation System Using Real User
Monitoring Data
author:Yang Yang and
Liang Zhang and
Ritesh Maheshwari and
Zaid Ali Kahn and
Deepak Agarwal and
Sanjay Dubey
Scout: A Point of Presence Recommendation
System Using Real User Monitoring Data
Yang Yang(B), Liang Zhang, Ritesh Maheshwari, Zaid Ali Kahn,
Deepak Agarwal, and Sanjay Dubey
LinkedIn, 2029 Stierlin Court, Mountain View, CA 94043, USA
{yyang,lizhang,rmaheshw,zali,dagarwal,sdubey}@linkedin.com
Abstract. This paper describes, Scout, a statistical modeling driven
approach to automatically recommend new Point of Presence (PoP) cen-
ters for web sites. PoPs help reduce a website’s page download time
dramatically. However, where to build the new PoP centers given the
current assets of existing ones is a problem that has rarely been studied
in a quantitative and principled way before; it was mainly done through
empirical studies or through applying industry experience and intuitions.
In this paper, we propose a novel approach that estimates the impact of
the PoP centers by building a statistical model using the real user mon-
itoring data collected by the web sites and recommend the next PoPs to
build. We also consider the problem of recommending PoPs using other
metrics such as user’s number of page views. We show empirically that
our approach works well, by experiments that use real data collected
from millions of user visits in a major social network site.
1 Introduction
Most websites serve dynamic content (e.g. HTML and JSON) from their data
centers and utilize Content Delivery Networks (CDN) for serving cacheable assets
such as Cascading Style Sheets (CSS), JavaScripts, images etc. Reducing the
download time of dynamic content is important to improve the experience of a
typical user visiting the site. One commonly adopted strategy by web companies
to accomplish this is to terminate user’s TCP connection closer to the user by
using Point of Presence centers (PoP).1
Point of Presence Centers, or PoPs, are “small scale data centers” usually
with only a few racks. They act as TCP termination point of client requests
for dynamic content. As shown in Fig. 1, data transfer over PoP to data center
link happens in single round trip time (RTT) due to large congestion control
windows between them. But the data transfer between clients and PoP can take
multiple RTTs since that TCP connection is likely new with a small congestion
control window and the dynamic content size is larger than what can ﬁt in the
smaller congestion window. For users with high RTTs to the data centers, early
1 Another strategy is to use CDNs to deliver dynamic content, but it is less common
due to security, privacy and cost concerns.
c(cid:2) Springer International Publishing Switzerland 2016
T. Karagiannis and X. Dimitropoulos (Eds.): PAM 2016, LNCS 9631, pp. 205–217, 2016.
DOI: 10.1007/978-3-319-30505-9 16
206
Y. Yang et al.
Fig. 1. An example illustration of how PoPs help in performance. In this paper, we
focus on optimizing PoP location for page download time, which is deﬁned as sum of
ﬁrst byte time and content download time.
TCP termination at PoPs help improve the overall download time by reducing
the RTT between users and PoPs.
Our estimates (using historical costs from a major social network) show that
building a PoP can be a costly aﬀair: an initial investment of over 1 Million US
dollars and a recurring cost of about US $720000 per year. An important question
then arises: where should the next PoP be built? Note that the ideal location of
the next PoP is dependent on many factors such as: (a) feasibility and cost of
building a PoP in a given location; (b) potential performance improvement for
end-users that will get impacted by the PoP; and (c) other business beneﬁts to
the company for the impacted regions like increased page views, engagement etc.
Traditionally, the selection of PoP locations is based on experience or intu-
ition: web companies often follow their predecessor’s paths to expand their PoP
footprints, or study the network connection for the regions in which they want to
expand businesses to propose new PoP locations. To the best of our knowledge,
the problem of where to build the next PoPs has not been systematically studied
in a quantitative and principled way before.
In this paper we propose Scout, a general purpose PoP recommendation
system for web companies utilizing PoPs as end-user connection termination
points. At a high level, Scout works as follows:
1. Scout takes as input a set of existing PoPs, a set of potential PoP candi-
dates, passively collected real user monitoring (RUM) data from user visits
to the website, and other relevant features such as user’s geographical region,
browser type, the size of the packets to be downloaded etc.
Scout: A PoP Recommendation System Using RUM Data
207
2. Scout uses the RUM data to train a statistical model to predict page download
time using features such as distance between current PoP and end-user, end-
user’s network characteristics, PoP’s network characteristics etc.
3. For each potential PoP in the candidate list, Scout then predicts page down-
load time improvement for end-users who see a net positive gain if assigned
to that PoP.
4. Scout calculates “impact score” for each candidate PoP, and outputs a sorted
list of PoP candidate locations by the score. The impact score is deﬁned to
be either the improvement to the overall site performance, or the impact to
some other business metrics such as total number of page views.
Real User Monitoring (RUM) Data. For the past few years, web companies
have been able to collect client-side performance data for their end-users to ana-
lyze and detect performance issues using the Navigation timing API, which was
recommended by the Web Performance working group of the World Wide Web
Consortium (W3C) in 2012 and implemented by most of the major browsers.
This technique of client-side monitoring is called Real User Monitoring, or RUM.
In this paper, we use client IP address and page download time metrics from
RUM to build our statistical models.
Related Work. We believe Scout is a novel approach to an age old problem faced
by most web companies. Scout’s design was motivated by a singular focus on using
only readily available passive measurement data to deliver an end-to-end solution
to PoP selection problem. This sets it apart from previous works [3,5,6,11] in the
literature since most of them have used active measurement techniques and have
tried to solve a piece of puzzle by only trying to estimate RTT. The essential met-
ric for performance of a website is the total page download time. Our work esti-
mates impact of building a PoP using metrics that impact the end-users’ page
download time which albeit includes RTT, but also includes many other impor-
tant features, e.g. size of the webpage (which varies on a per-user basis), the poten-
tial PoP’s peering density, concentration of the website’s end-users around a given
location, improvement in performance for end-users in a given location etc. Most
works in literature have also evaluated their approaches in simulations or a small
set of experimental data. In contrast, our approach uses millions of data samples
from real users of a major social network site with > 400 million members and
billions of page views per month. Finally, active measurement techniques require
signiﬁcant eﬀort to collect data, whereas we use RUM data which is likely being
already collected by most web companies. Other interesting works in this ﬁeld that
are orthogonal to our work but related are those (a) optimize how to assign users
to PoPs (once built) [10,12], (b) use statistical modeling to correlate user request
patterns with web server performance [8,15] and (c) study impact of web perfor-
mance on user behavior [1,4,13,14].
2 Scout: A System for Recommending New PoP Centers
Assume a web company already has T number of existing PoP centers, denoted as
p1, ..., pT . We would like to ﬁnd the optimal location to build the next PoP pT +1
208
Y. Yang et al.
from candidate set P , given p1, ..., pT . Since sometimes a fast-growing company
may want to build multiple new PoPs at the same time, the problem can also
be extended to ﬁnding an optimal set of PoP locations with pre-determined size
L, pT +1, ..., pT +L from candidate set P , given p1, ..., pT .
PoP candidate set P is derived using the following constraints: availability
of real estate to house a high density of power and proximity to metro region
ﬁber, neutrality of PoP/data center operator, and closeness to Internet Exchange
Points (IXP’s) and interconnections. We start our list with the PeeringDB data
[2] that contains about 1400 potential locations worldwide; we remove all IXP
locations where number of ASNs peering at the IXP is below a certain threshold
(e.g. 30). These locations are less desirable since they do not have as many poten-
tial peering partners. At the end our candidate list includes around 400 facilities
where PoPs can be built for better performance. Others may use diﬀerent selec-
tion criteria for PoP candidate list selection but our PoP recommendation system
should still work in general.
At a high-level, our approach works as follows: (a) We build a statistical
model to predict site speed when a user is allocated to a new candidate PoP
center. (b) For a new candidate PoP center location, we measure the overall
predicted improvement to site speed (impact score) obtained by hypothetically
allocating a set of user visits to the new PoP. Note that only the user visits
which are projected to beneﬁt from the new PoP will be routed to it. We also
assume that new PoPs are built with enough capacity so that load is not a factor.
(c) When we have to recommend multiple PoP center locations simultaneously,
we consider two strategies: a greedy strategy that computes impact score for
each candidate PoP incrementally one at a time; a more computationally inten-
sive strategy computes the impact score obtained by evaluating multiple PoPs
simultaneously. We scale the computation for the latter by using Map-Reduce.
2.1 Site Speed Prediction Model Using RUM
We ﬁrst describe our probabilistic statistical modeling approach of using a set
of features to predict the total page download time, which equals the sum of
connect time, ﬁrst-byte time and content download time. The model is learned
from the RUM data collected from user visits connecting to the current PoP cen-
ters. We consider three types of features here: (a) Context features of the user
visit, e.g. time of the day, day of the week, the webpage that the users are visit-
ing, through Secure Sockets Layer (SSL) or not, and so forth; (b) User-speciﬁc
features, including user’s geographical locations inferred from their IP addresses,
operating systems, web browser types (e.g. Internet Explorer, or Mozilla Firefox,
or Google Chrome) and versions, the size of packets to be downloaded from the
server (or equivalent features), number of social network connections the user
has, etc.; (c) PoP-speciﬁc features, including both the user distance to the PoP
centers and the PoP center distance to the data centers. In this paper we use both
the geographical distance and the network distance (which captures the number
of hops it takes to connect from a user’s original IP address to the PoP cen-
ters). The geographical distance between a user and the PoP center is obtained
Scout: A PoP Recommendation System Using RUM Data
209
by calculating the straight line distance between the user’s inferred geographical
location (from their IP address) and the location of the PoP center. In order to
calculate network distance between user’s origin AS and PoP center, we obtained
route server data for 70 IXP’s globally from Packet Clearing House (PCH), which
consist of all the possible routes from user’s origin ASNs to the peering ASNs;
an ASN connection map can be built such that given any potential PoP center
location with a list of peered ASNs, the minimum number of hops it takes from
the user’s origin AS to connect to the PoP is obtained as the network distance
to the PoP feature. For example, assume a user’s origin ASN is 56203, and the
ASN path to route to the current PoP is “56203 => 7545 => 174 => 10912”.
Then, the network distance feature is 3, since it takes 3 ASN hops to connect
to the PoP’s peering ASN 10912. Based on the data results, we ﬁnd that the
geographical distance makes the biggest contribution to the ﬁnal prediction, but
other features are also contributing.
Our Notations. For each user page view i and the PoP center p that the user is
routed to, let yi,p be the observed total page download time, which is the sum of
connection time, ﬁrst byte time, and content download time. We also denote the
corresponding feature set for observation i and PoP center p as xi,p, a m-dim
column vector. These features including context, user-speciﬁc and PoP-speciﬁc
features, are used to predict site speed yi,p through a statistical model. Note
that both the total page download time yi,p and the feature set xi,p depend on
the location of the PoP center p. Hence, if the user visit i is routed to a new
PoP center p(cid:3) instead of p, the feature set would become xi,p(cid:2), and the impact
to the total page download time would be yi,p(cid:2) instead of yi,p.
The Model of Total Page Download Time. Given the feature set xi,p,
one simplest model to predict yi,p is linear regression upon the logarithm of the
response log(yi,p) ∼ N(x(cid:3)
i,pβ
and σ2 are respectively the mean and the variance of the Gaussian distribution.
The logarithm transformation of yi,p is needed since the distribution of total
page download time has a long tail towards the right. Here, we care about the
estimate of β, which can be obtained by using the ordinary least square (OLS)
method as
i,pβ, σ2), where β is a m-dim column vector, and x(cid:3)
ˆβOLS = arg min
β
N(cid:2)
i=1
(log(yi,pobs) − x(cid:3)
β)2,
(1)
i,pobs
i,p ˆβOLS.
where pobs means the PoP center that the users are routed to in the observed
sample i, and N is the sample size. For feature vector xi,p where p can be any
PoP center location, the expected total page download time can be predicted as
E[log(yi,p)|xi,p] = x(cid:3)
Quantile Regression. Since the RUM data often include outliers and do not
ﬁt standard parametric distributions, it is customary to measure metrics such as
total page download time through quantiles instead of the arithmetic mean. In
such scenarios, since the model needs to be robust to outliers and the interest is
to measure performance through quantiles such as median rather than the mean,
210
Y. Yang et al.
using quantile regression (QR) [9] is a better approach. Assume the τ-th quantile
of the total page download time yi,p is yi,p(τ), i.e. yi,p(τ) = inf
(P [yi,p =
t
τ). The corresponding coeﬃcient vector can be solved by the loss function
ˆβQR(τ) = arg min
β
i=1
N(cid:2)
ρτ (log(yi,pobs) − x(cid:3)
i,pobs
β),
(2)
i,p ˆβQR(τ)).
where ρτ (z) = |z(τ − I(z  0, and 0 when x <= 0.
2.2 Recommend One PoP
In this section, we consider the problem of selecting the next PoP center can-
didate from the candidate set P , assuming we already have K number of PoP
centers running. Our approach can be illustrated as follows:
1. Build a total page download time prediction model M based on the observed
, yi,pobs), i = 1, . . . , N}. Note that M can be either linear
dataset {(xi,pobs
regression or quantile regression. For linear regression with logarithm trans-
formation of the response, M(xi,p) = exp(x(cid:3)
i,p ˆβOLS), and for quantile regres-
sion with logarithm transformation of the response, M(xi,p) = exp(x(cid:3)
i,p ˆβQR).
2. We predict the impact to the total page download time for record i if it is
routed to PoP p ∈ P instead of the current PoP center pobs, by changing the
feature set from xi,pobs to xi,p. The improvement of the total page download
time can be calculated as Δi(p) = M(xi,p) − M(xi,pobs).
3. Since it may not be feasible to have personalized PoP center routing in prac-
tice, we group the users to segments by certain attributes, and route all users
who belong to the same segment to the same PoP. The attributes to do such
segmentation can be geographical regions or origin ASNs. For segment I , we
deﬁne
Δ(p, I ) = Median{M(xi,p), i ∈ I } − Median{M(xi,pobs), i ∈ I },
(3)
and this is considered as the predicted impact on the median of the total page
download time by routing to future PoP p for segment I .
4. Calculate the impact score for each candidate PoP. Denote the probabil-
qI = 1.
ity of a page view request coming from segment I as qI , and
(cid:3)
I
Scout: A PoP Recommendation System Using RUM Data
211
For each segment I , if we route the traﬃc to PoP p, the predicted impact of
site speed is Δ(p, I ). However, if Δ(p, I ) < 0, we would choose not to route
to this new PoP given the projected gain is negative. Hence, the impact score
S(p) for PoP p can be deﬁned as
(cid:2)
S(p) =
max(0, Δ(p, I ))qI .
(4)
And the best PoP candidate popt is popt = arg maxp∈P S(p).
I
2.3 Recommend Multiple PoPs Simultaneously
Often we would like to have multiple new PoP recommendations at the same
time, given the existing K number of PoPs. We can certainly run the approach
described in Sect. 2.2 iteratively to obtain the list. However, this greedy app-
roach may not be optimal; jointly considering the combinations of multiple PoP
candidates at the same time can potentially give better impact scores overall.
Assume we want to recommend L new PoPs out of the candidate set P , the