title:Network Anomography
author:Yin Zhang and
Zihui Ge and
Albert G. Greenberg and
Matthew Roughan
Network Anomography
Yin Zhang†, Zihui Ge‡, Albert Greenberg‡, and Matthew Roughan§
†Department of Computer Sciences, University of Texas at Austin, Austin, TX 78712, USA
‡AT&T Labs – Research, Florham Park, NJ 07932, USA
§School of Mathematical Science, University of Adelaide, SA 5005, Australia
Abstract
Anomaly detection is a ﬁrst and important step needed
to respond to unexpected problems and to assure high per-
formance and security in IP networks. We introduce a
framework and a powerful class of algorithms for net-
work anomography, the problem of inferring network-level
anomalies from widely available data aggregates. The
framework contains novel algorithms, as well as a recently
published approach based on Principal Component Analy-
sis (PCA). Moreover, owing to its clear separation of infer-
ence and anomaly detection, the framework opens the door
to the creation of whole families of new algorithms. We
introduce several such algorithms here, based on ARIMA
modeling, the Fourier transform, Wavelets, and Princi-
pal Component Analysis. We introduce a new dynamic
anomography algorithm, which effectively tracks routing
and trafﬁc change, so as to alert with high ﬁdelity on intrin-
sic changes in network-level trafﬁc, yet not on internal rout-
ing changes. An additional beneﬁt of dynamic anomogra-
phy is that it is robust to missing data, an important opera-
tional reality. To the best of our knowledge, this is the ﬁrst
anomography algorithm that can handle routing changes
and missing data. To evaluate these algorithms, we used
several months of trafﬁc data collected from the Abilene
network and from a large Tier-1 ISP network. To compare
performance, we use the methodology put forward earlier
for the Abilene data set. The ﬁndings are encouraging.
Among the new algorithms introduced here, we see: high
accuracy in detection (few false negatives and few false
positives), and high robustness (little performance degra-
dation in the presence of measurement noise, missing data
and routing changes).
1 Introduction
The ﬁrst step in ﬁxing a problem is knowing it exists. This
is no less true in networking than anywhere else – we need
to know about a problem before we can repair it. Network-
ing vendors typically build alarms into network equipment
to facilitate fast, accurate detection and diagnosis of prob-
lems. However, in practice, there are many problems for
which explicit alarms are either absent (for new or uncom-
mon problems), or intrinsically hard to produce. In these
cases we must infer the problem from other data sources.
For instance, many types of network problems cause abnor-
mal patterns to appear in the network trafﬁc. Such trafﬁc
anomalies may be caused by problems ranging from secu-
rity threats such as Distributed Denial of Service (DDoS)
attacks and network worms, to unusual trafﬁc events such
as ﬂash crowds, to vendor implementation bugs, to network
misconﬁgurations. We refer to the problem of inferring
anomalies from indirect measurement as network anomog-
raphy (combining “anomalous” with “tomography,” a gen-
eral approach to such inference problems).
Network tomography [31] bears some resemblance, in
that both involve the solution of a linear inverse prob-
lem. Examples include inference of individual link per-
formance characteristics from path performance character-
istics, and inference of trafﬁc matrices from individual link
load measurements. For example, the trafﬁc matrix estima-
tion problem arises because the obvious source of data for
direct measurement (ﬂow-level data) can be hard to obtain
network-wide [5, 14, 22, 23, 28, 31, 34, 35]. On the other
hand, Simple Network Management Protocol (SNMP) data
on individual link loads is available almost ubiquitously.
Fortunately, the link loads and trafﬁc matrices are simply
related by a linear equation
b = Ax
(1)
The vector b contains the link measurements, and A is the
routing matrix (deﬁned formally below). We wish to in-
fer x, which contains the unknown trafﬁc matrix elements
written as a vector. Tomographic inference techniques seek
to invert this relationship to ﬁnd x.
The anomography problem is different and somewhat
more complex. First, note that anomaly detection is per-
formed on a series of measurements over a period of time,
rather than from a single snapshot. In addition to changes in
the trafﬁc, the solution must build in the ability to deal with
changes in routing. Second, note that the anomalies that
we wish to infer may have dramatically different properties
from a trafﬁc matrix, and so different methods than those
used for network tomography may be called for. Indeed, we
ﬁnd that simple extensions to network tomography meth-
ods perform fair poorly here. Techniques that transform
the measurements prior to attempting to solve the inverse
problem are preferable.
As a simple example, imagine trying to detect an anoma-
lous trafﬁc pattern caused by a ﬂash crowd or DDoS attack
on a web site. This type of event will cause increases in
trafﬁc ﬂows headed towards a particular set of destinations.
It may be hard to rapidly identify which of the tens of thou-
sands of ingress links on a large network might be primar-
ily responsible, as large surges at a network egress link may
arise from small surges on several ingress links. We must
USENIX Association
Internet Measurement Conference 2005  
317
infer the change in the pattern of trafﬁc to the particular
site from the complete set of link data, considered together,
rather than as individual time series. This illustrates an im-
portant feature of anomography – it extends anomaly de-
tection to network-level problems (automatically building
in correlation across the network) where link-level anomaly
detection might be inadequate or unreliable.
Many approaches to anomography are possible. In pio-
neering work, Lakhina et al. introduced a novel approach
based on Principal Component Analysis (PCA) [19]. Our
paper makes three major contributions to understanding
and solving anomography problems:
1. We present a simple and powerful framework that
encompasses a wide class of methods for network
anomography. We will see that the method of [19] is
a member of this class. The framework clearly decou-
ples the inference and anomaly detection steps, and so
immediately opens the door to the development of new
algorithms where one makes different choices for each
step. Accordingly, we introduce several such new al-
gorithms here, based on ARIMA modeling, the Fourier
transform, Wavelets, and Principal Component Analy-
sis. Moreover, the framework is not restricted to the
analysis of link trafﬁc data, and in particular also applies
to the dual problem of inferring performance anomalies
from end-to-end performance measurements.
2. We introduce a new algorithm for dynamic anomogra-
phy, which identiﬁes network level trafﬁc anomalies and
works in the presence of routing changes. That is, dy-
namic anomography tracks routing and trafﬁc change
– signaling trafﬁc anomalies, but not internal network
routing changes (which may dramatically change inter-
nal trafﬁc patterns but may leave the trafﬁc matrix, de-
scribing how trafﬁc enters and exits the network, stable).
In IP networks, routing changes occur as part of the nor-
mal “self-healing” behavior of the network, and so iso-
lating these from trafﬁc anomalies is advantageous. An
additional beneﬁt of dynamic anomography is that it is
robust to missing link load measurements, an important
operational reality (see Section 4 for why missing data
may result in changes in the routing matrix). To the best
of our knowledge, this is the ﬁrst anomography algo-
rithm that can handle routing changes and missing data.
3. Using data sets collected from a large Tier-1 ISP and
from Internet2’s Abilene network, we report on the re-
sults of an extensive and thorough evaluation of a set
of anomography methods. To understand the ﬁdelity
of the methods and to compare different methods, we
apply the methodology introduced in [19]. Under this
methodology, we ﬁnd that in general the new temporal
anomography methods introduced here exhibit consis-
tently high ﬁdelity. In particular, we ﬁnd that the most
successful method (of those examined) is a variation of
dynamic anomography, combining Box-Jenkins model-
ing (ARIMA) with `1 norm minimization. Further eval-
uation suggests that this algorithm can cope well with
measurement noise, and degrade gracefully in the pres-
ence of missing or corrupted data.
The paper is organized as follows. Section 2 summarizes
background and related work. In Section 3 we describe our
framework, and the anomography algorithms examined in
this paper, in the context of ﬁxed routing.
In Section 4
we extend the Box-Jenkins anomography to the case where
routing may change over time. In Section 5 we describe our
evaluation methodology, and Section 6 presents the results.
Section 7 provides ﬁnal remarks.
2 Background
2.1 Network Tomography
Network tomography describes several problems:
infer-
ring link performance of a network from end-to-end mea-
surements, or inferring Origin-Destination (OD) trafﬁc de-
mands from link load measurements. These problems can
be written as linear inverse problems where one seeks to
ﬁnd unknowns x from measurements b given a linear rela-
tionship (1), where A is the routing matrix. For a network
with n links, and m OD ﬂows, we deﬁne the routing matrix
to be the n × m matrix A = [aij ] where aij indicates the
fraction of trafﬁc from ﬂow j to appear on link i.
SNMP provides link measurements of trafﬁc volumes
(bytes and packets), typically at 5 minute intervals (this
data is described in more detail in, for example [34]). We
shall assume data of this type is the input to our algorithms,
and we wish to infer anomalous trafﬁc matrix elements, but
note that anomography is not limited to this problem, and
could equally be applied to inferring anomalous link per-
formance from end-to-end measurements. An additional
source of data used here comes from the routing protocols
used to build the forwarding tables within each router. We
use routing data (e.g., gathered from a route monitor as in
[27]) along with a route simulator (as in [10]) to predict the
results of these distributed computations, and determine the
network routing.
The problem of inferring the OD trafﬁc-matrix has been
much studied recently (e.g., [5, 14, 22, 23, 28, 31, 34, 35]).
The problem’s key characteristic is that it is massively un-
derconstrained: there will be approximately N 2 OD ﬂows
to estimate and only O(N ) link measurements. Hence to-
mography methods seek to introduce additional informa-
tion, often in the form of some kind of trafﬁc model (for in-
stance a Poisson model in [31, 28], a Gaussian model in [5],
or a gravity model in [34, 35]). Anomography problems are
also highly underconstrained, but the models used to de-
scribe trafﬁc are inappropriate for anomalies — by deﬁni-
tion these events are generated by completely different pro-
cesses from normal network trafﬁc. Moreover, in anomog-
raphy we combine detection with inference, whereas in
standard network tomography we seek only to infer a set
of trafﬁc matrix elements. Hence there are important dif-
ferences between this paper and network tomography.
318
Internet Measurement Conference 2005 
USENIX Association
It is also important to note that routing matrices change
In much previous work, routing matrices are
over time.
taken to be constant (an exception being [23], where the
trafﬁc is assumed to be somewhat constant, while the rout-
ing varies), but it is important (see [29]) to allow for the
fact that routing is not constant, and neither is the trafﬁc.
In order to allow for variable routing, we index not just the
trafﬁc measurements over time, but also the routing matrix.
Given these, we may write the relationship between the link
trafﬁc, and OD trafﬁc matrix as
bj = Aj xj,
(2)
where Aj is an n×m routing matrix, xj is a length-n vector
of unknown OD ﬂow trafﬁc volumes, and bj is a length-m
vector of link loads1, at time interval j.
2.2 Related Work
Lakhina et al. carried out the pioneering work in the area
of inference of anomalies at network level, [19, 18, 20],
and adapted Principal Components Analysis (PCA) to this
setting. Donoho [8, 9] introduced a powerful mathemati-
cal treatment for tomography-like problems, wherein one
seeks solutions that maximize sparsity (intuitively, solu-
tions with fewest explanations). These papers inspired our
development of the new methods introduced here, and our
development of a framework in which a very wide class of
methods all ﬁt.
Anomaly detection is a burgeoning ﬁeld. A great deal
of research in network anomaly detection relies on some
type of inference step, taking a set of alarms [13, 15, 16,
25, 30] as input. While anomography includes methods
of this type, our results indicate that it is better to delay
alarm generation until after the inference step. In that way,
a single constructive alarm may be generated, rather than
a storm of redundant alarms. Moreover, in delaying the
alarm generation until after the inference step, we can in
some cases greatly improve the sensitivity of detection, as
was demonstrated in [19].
We approach the network anomaly detection problem
from the point of detecting unknown anomalous behavior,
rather than looking for particular signatures in the data, the
focus of much work in the security community. A large
component of the work on machine learning, signal pro-
cessing and time-series analysis is devoted to detecting out-
liers or anomalies in time-series. This literature has been
applied to networks in a number of cases; for examples
see [1, 4, 15, 17, 30, 32]. These methods range in sophis-
tication from [4], which suggests the use of the standard
Holt-Winters forecasting technique for network anomaly
detection, to [1], which uses a sophisticated wavelet based
method with great potential. These methods focus on sin-
gle time series rather than the multi-dimensional time series
that arise in anomography.
Most earlier work ignores noise or provides weak tests of
robustness to noise (which can destroy utility). A strength
of the work presented here is that we provide tests of effec-
tiveness of the methods in the presence of noise, always a
factor in practice.
3 Network Anomography
In this section, we shall assume that the routing matrices
Aj are time-invariant and are denoted by A. (We will ex-
tend our work to time-varying Aj in Section 4.) Under this
assumption, we can combine all t linear systems (2) into a
single equation using matrix notation:
B = AX,
(3)
where B = [b1 b2 · · · bt] is the matrix formed by having
bj as its column vectors, and similarly X = [x1 x2 · · · xt].
3.1 A General Anomography Framework
We identify two basic solution strategies to network
anomography: (i) early inverse, and (ii) late inverse. Early-
inverse approaches may appear more intuitive. The early-
inverse approach tackles the problem in two steps. The
ﬁrst is the network tomography step, where OD ﬂow data
at each interval j are inferred from the link load mea-
surements by solving the ill-posed linear inverse problem
(2). Given the estimated OD ﬂow data xj at different time
points j, in the second step, anomaly detection can then be
applied to the xj. For this step, there are many widely used
spatial and temporal analysis techniques, which we will de-
scribe later in this section.
Early-inverse methods, although conceptually simple,
have an obvious drawback — errors in the ﬁrst step, which
are unavoidable due to the ill-posed nature of the infer-
ence problem, can contaminate the second step, sabotaging
overall performance. Another disadvantage is that early-
inverse methods apply a potentially computationally ex-
pensive anomaly detection step to high-dimensional data:
on a network of N nodes, one must perform this step on
all N 2 OD pairs. As we will see, late-inverse performs
anomaly detection on only O(N ) dimensional data. We fo-
cus on late-inverse methods in this paper for these reasons,
though we shall provide some comparisons between early-
and late-inverse methods.
The idea of the late-inverse method is to defer “lossy”
inference to the last step. Speciﬁcally, late inverse ap-
proaches extract the anomalous trafﬁc from the link load
observation, then form and solve a new set of inference
problems:
˜B = A ˜X,
(4)
where ˜B = [˜b1 ˜b2 · · · ˜bt] is the matrix of anomalous trafﬁc
in the observables, and ˜X = [˜x1 ˜x2 · · · ˜xt] is the matrix of
OD ﬂow anomalies to be diagnosed, over t time intervals.
While the new inference problems (4) share the same
linear-inverse structure as in network tomography (3), the
characteristics of the unknowns are very different, and so is
the solution strategy, which we will explore in Section 3.4.
We now introduce a simple framework for late-inverse
anomography methods. In this framework, ˜B is formed by
USENIX Association
Internet Measurement Conference 2005  
319
multiplying B with a transformation matrix T . Depending
on whether we use a left or right multiplying transforma-
tion matrix, we can further divide the framework into the
following two classes:
• spatial anomography, where a left multiplying transfor-
mation matrix T is used to form ˜B, i.e., ˜B = T B;
• temporal anomography, where a right multiplying
transformation matrix T is used to form ˜B, i.e., ˜B =
BT .
Our framework encompasses a number of analysis tech-
niques for extracting anomalous trafﬁc ˜B from link load
observations B, as we next illustrate.