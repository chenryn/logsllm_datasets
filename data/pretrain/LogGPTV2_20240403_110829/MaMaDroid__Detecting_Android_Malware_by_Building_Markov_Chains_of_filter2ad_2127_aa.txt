title:MaMaDroid: Detecting Android Malware by Building Markov Chains of
Behavioral Models
author:Enrico Mariconti and
Lucky Onwuzurike and
Panagiotis Andriotis and
Emiliano De Cristofaro and
Gordon J. Ross and
Gianluca Stringhini
MAMADROID: Detecting Android Malware by
Building Markov Chains of Behavioral Models
Enrico Mariconti†, Lucky Onwuzurike†, Panagiotis Andriotis‡,
Emiliano De Cristofaro†, Gordon Ross†, and Gianluca Stringhini†
†University College London, ‡University of the West of England
{enrico.mariconti.14,lucky.onwuzurike.13,e.decristofaro,g.ross,g.stringhini}@ucl.ac.uk,
PI:EMAIL
Abstract—The rise in popularity of the Android platform
has resulted in an explosion of malware threats targeting it. As
both Android malware and the operating system itself constantly
evolve, it is very challenging to design robust malware mitigation
techniques that can operate for long periods of time without
the need for modiﬁcations or costly re-training. In this paper,
we present MAMADROID, an Android malware detection system
that relies on app behavior. MAMADROID builds a behavioral
model, in the form of a Markov chain, from the sequence of
abstracted API calls performed by an app, and uses it to extract
features and perform classiﬁcation. By abstracting calls to their
packages or families, MAMADROID maintains resilience to API
changes and keeps the feature set size manageable. We evaluate
its accuracy on a dataset of 8.5K benign and 35.5K malicious
apps collected over a period of six years, showing that it not
only effectively detects malware (with up to 99% F-measure),
but also that the model built by the system keeps its detection
capabilities for long periods of time (on average, 86% and 75%
F-measure, respectively, one and two years after training). Finally,
we compare against DROIDAPIMINER, a state-of-the-art system
that relies on the frequency of API calls performed by apps,
showing that MAMADROID signiﬁcantly outperforms it.
I.
INTRODUCTION
In the ﬁrst quarter of 2016, 85% of smartphone sales were
devices running Android [49]. Due to its popularity, cyber-
criminals have increasingly targeted this ecosystem [17], as
malware running on mobile devices can be particularly lucrative
– e.g., allowing attackers to defeat two factor authentication [51],
[53] or trigger leakage of sensitive information [27]. Detecting
malware on mobile devices presents additional challenges com-
pared to desktop/laptop computers: smartphones have limited
battery life, making it infeasible to use traditional approaches
requiring constant scanning and complex computation [43].
Therefore, Android malware detection is typically performed
by Google in a centralized fashion, i.e., by analyzing apps
submitted to the Play Store using a tool called Bouncer [40].
However, many malicious apps manage to avoid detection [1],
and anyway Android’s openness enables manufacturers and
Permission  to  freely  reproduce  all  or  part  of  this  paper  for  noncommercial 
purposes  is  granted  provided  that  copies  bear  this  notice  and  the  full  citation 
on  the  ﬁrst  page.  Reproduction  for  commercial  purposes  is  strictly  prohibited 
without the prior written consent of the Internet Society, the ﬁrst-named author 
(for  reproduction  of  an  entire  paper  only),  and  the  author’s  employer  if  the 
paper  was  prepared  within  the  scope  of  employment.
NDSS  ’17,  26  February  -  1  March  2017,  San  Diego,  CA,  USA
Copyright  2017  Internet  Society,  ISBN  1-891562-46-0
http://dx.doi.org/10.14722/ndss.2017.23353
users to install apps that come from third-party market places,
which might not perform any malware checks at all, or anyway
not as accurately [67].
As a result, the research community has devoted signiﬁcant
attention to malware detection on Android. Previous work
has often relied on the permissions requested by apps [20],
[46], using models built from malware samples. This strategy,
however, is prone to false positives, since there are often
legitimate reasons for benign apps to request permissions
classiﬁed as dangerous [20]. Another approach, used by
DROIDAPIMINER [2], is to perform classiﬁcation based on
API calls frequently used by malware. However, relying on
the most common calls observed during training prompts the
need for constant retraining, due to the evolution of malware
and the Android API alike. For instance, “old” calls are often
deprecated with new API releases, so malware developers may
switch to different calls to perform similar actions, which affects
DROIDAPIMINER’s effectiveness due to its use of speciﬁc calls.
In this paper, we present a novel malware detection system
for Android that instead relies on the sequence of abstracted
API calls performed by an app rather than their use or frequency,
aiming to capture the behavioral model of the app. Our system,
which we call MAMADROID, abstracts API calls to either
the package name of the call (e.g., java.lang) or its source
(e.g., java, android, google), which we refer to as family.
Abstraction provides resilience to API changes in the Android
framework as families and packages are added and removed
less frequently than single API calls. At the same time, this does
not abstract away the behavior of an app: for instance, packages
include classes and interfaces used to perform similar operations
on similar objects, so we can model the types of operations from
the package name, independently of the underlying classes and
interfaces. For example, we know that the java.io package
is used for system I/O and access to the ﬁle system, even
though there are different classes and interfaces provided by
the package for such operations.
After abstracting the calls, MAMADROID analyzes the
sequence of API calls performed by an app, aiming to model
the app’s behavior. Our intuition is that malware may use calls
for different operations, and in a different order, than benign
apps. For example, android.media.MediaRecorder can be used
by any app that has permission to record audio, but the call
sequence may reveal that malware only uses calls from this
class after calls to getRunningTasks(), which allows recording
conversations [65], as opposed to benign apps where calls from
the class may appear in any order. Relying on the sequence
of abstracted calls allows us to model behavior in a more
complex way than previous work, which only looked at the
presence or absence of certain API calls or permissions [2], [5],
while still keeping the problem tractable [33]. MAMADROID
builds a statistical model to represent the transitions between
the API calls performed by an app, speciﬁcally, we model
these transitions as Markov chains, and use them to extract
features and perform classiﬁcation (i.e., labeling apps as benign
or malicious). Calls are abstracted to either their package or
their family, i.e., MAMADROID operates in one of two modes,
depending on the abstraction granularity.
We present a detailed evaluation of both classiﬁcation
accuracy (using F-measure, precision, and recall) and runtime
performance of MAMADROID, using a dataset of almost 44K
apps (8.5K benign and 35.5K malware samples). We include
a mix of older and newer apps, from October 2010 to May
2016, verifying that our model is robust to changes in Android
malware samples and APIs. To the best of our knowledge,
this is the largest malware dataset used to evaluate an Android
malware detection system in a research paper. Our experimental
analysis shows that MAMADROID can effectively model both
benign and malicious Android apps, and perform an efﬁcient
classiﬁcation on them. Compared to other systems such as
DROIDAPIMINER [2], our approach allows us to account for
changes in the Android API, without the need to frequently
retrain the classiﬁer.
We show that MAMADROID is able to effectively detect
unknown malware samples not only in the “present,” (with
F-measure up to 99%) but also consistently over the years (i.e.,
when the system is trained on older samples and classiﬁcation
performed over newer ones), as it keeps an average detection
accuracy, evaluated in terms of F-measure, of 86% after one
year and 75% after two years (as opposed to 46% and 42%
achieved by DROIDAPIMINER [2]). We also highlight that
when the system is not efﬁcient anymore (when the test set is
newer than the training set by more than two years), it is as a
result of MAMADROID having low recall, but maintaining
high precision. We also do the opposite, i.e., training on
newer samples and verifying that the system can still detect
old malware. This is particularly important as it shows that
MAMADROID can detect newer threats, while still identifying
malware samples that have been in the wild for some time.
Summary of Contributions. First, we introduce a novel
approach, implemented in a tool called MAMADROID, to detect
Android malware by abstracting API calls to their package
and family, and using Markov chains to model the behavior
of the apps through the sequences of API calls. Second, we
can detect unknown samples on the same year of training
with an F-measure of 99%, but also years after training the
system, meaning that MAMADROID does not need continuous
re-training. Our system is scalable as we model every single
app independently from the others and can easily append app
features in a new training set. Finally, compared to previous
work [2], MAMADROID achieves signiﬁcantly higher accuracy
with reasonably fast running times, while also being more
robust to evolution in malware development and changes in
the Android API.
Paper Organization. The rest of the paper is organized as
follows. The next section presents the MAMADROID system,
Fig. 1: Overview of MAMADROID operation. In (1), it extracts the
call graph from an Android app, next, it builds the sequences of
(abstracted) API calls from the call graph (2). In (3), the sequences
of calls are used to build a Markov chain and a feature vector for
that app. Finally, classiﬁcation is performed in (4), labeling the app
as benign or malicious.
then, Section III introduces the datasets used in our evaluation
(Section IV), while Section V further discusses our results
as well as its limitations. After reviewing related work in
Section VI, the paper concludes in Section VII.
II. THE MAMADROID SYSTEM
A. Overview
We now introduce MAMADROID, a novel system for
Android malware detection. MAMADROID characterizes the
transitions between different API calls performed by Android
apps – i.e., the sequence of API calls. It then models these
transitions as Markov chains, which are in turn used to extract
features for machine learning algorithms to classify apps as
benign or malicious. MAMADROID does not actually use the
sequence of raw API calls, but abstracts each call to either its
package or its family. For instance, the API call getMessage()
is parsed as:
.lang.Throwable: String getMessage()
(cid:123)
package
(cid:122)
(cid:125)(cid:124)
java(cid:124)(cid:123)(cid:122)(cid:125)
(cid:124)
family
(cid:123)(cid:122)
API call
(cid:125)
Given these two different types of abstractions, we have
two modes of operation for MAMADROID, each using one
of the types of abstraction. We test both, highlighting their
advantages and disadvantages — in a nutshell, the abstraction
to family is more lightweight, while that to package is more
ﬁne-grained.
MAMADROID’s operation goes through four phases, as
depicted in Fig. 1. First, we extract the call graph from each
app by using static analysis (1), next we obtain the sequences
of API calls for the app using all unique nodes in the call
graph and associating, to each node, all its child nodes (2). As
mentioned, we abstract a call to either its package or family.
Finally, by building on the sequences, MAMADROID constructs
a Markov chain model (3), with the transition probabilities used
as the feature vector to classify the app as either benign or
malware using a machine learning classiﬁer (4). In the rest of
this section, we discuss each of these steps in detail.
B. Call Graph Extraction
The ﬁrst step in MAMADROID is to extract the app’s call
graph. We do so by performing static analysis on the app’s
2
Call Graph Extraction (1)SequenceExtraction (2)Markov Chain Modeling (3)Classification (4)?package com.fa.c;
import android.content.Context;
import android.os.Environment;
import android.util.Log;
import com.stericson.RootShell.execution.Command;
import com.stericson.RootShell.execution.Shell;
import com.stericson.RootTools.RootTools;
import java.io.File;
public class RootCommandExecutor {
public static boolean Execute(Context paramContext) {
paramContext = new Command(0, new String[] { "cat " + Environment.
getExternalStorageDirectory().getAbsolutePath() + File.separator + Utilities
.GetWatchDogName(paramContext) + " > /data/" + Utilities.GetWatchDogName(
paramContext), "cat " + Environment.getExternalStorageDirectory().
getAbsolutePath() + File.separator + Utilities.GetExecName(paramContext) + "
> /data/" + Utilities.GetExecName(paramContext), "rm " + Environment.
getExternalStorageDirectory().getAbsolutePath() + File.separator + Utilities
.GetWatchDogName(paramContext), "rm " + Environment.
getExternalStorageDirectory().getAbsolutePath() + File.separator + Utilities
.GetExecName(paramContext), "chmod 777 /data/" + Utilities.GetWatchDogName(
paramContext), "chmod 777 /data/" + Utilities.GetExecName(paramContext), "/
data/" + Utilities.GetWatchDogName(paramContext) + " " + Utilities.
GetDeviceInfoCommandLineArgs(paramContext) + " /data/" + Utilities.
GetExecName(paramContext) + " " + Environment.getExternalStorageDirectory().
getAbsolutePath() + File.separator + Utilities.GetExchangeFileName(
paramContext) + " " + Environment.getExternalStorageDirectory().
getAbsolutePath() + File.separator + " " + Utilities.GetPhoneNumber(
paramContext) });
try {
RootTools.getShell(true).add(paramContext);
return true;
}
catch (Exception paramContext) {
Log.d("CPS", paramContext.getMessage());
}
return false;
}
}
Fig. 2: Code snippet from a malicious app (com.g.o.speed.memboost)
executing commands as root.
apk.1 Speciﬁcally, we use a Java optimization and analysis
framework, Soot [52], to extract call graphs and FlowDroid [6]
to ensure contexts and ﬂows are preserved.
To better clarify the different steps involved in our system,
we employ a “running example,” using a real-world malware
sample. Speciﬁcally, Fig. 2 lists a class extracted from the
decompiled apk of malware disguised as a memory booster app
(with package name com.g.o.speed.memboost), which executes
commands (rm, chmod, etc.) as root.2 To ease presentation, we
focus on the portion of the code executed in the try/catch block.
The resulting call graph of the try/catch block is shown in Fig. 3.
Note that, for simplicity, we omit calls for object initialization,
return types and parameters, as well as implicit calls in a
method. Additional calls that are invoked when getShell(true)
is called are not shown, except for the add() method that is
directly called by the program code, as shown in Fig. 2.
C. Sequence Extraction
Next, we extract the sequences of API calls from the call
graph. Since MAMADROID uses static analysis, the graph
obtained from Soot represents the sequence of functions that
are potentially called by the program. However, each execution
of the app could take a speciﬁc branch of the graph and only
execute a subset of the calls. For instance, when running the
code in Fig. 2 multiple times, the Execute method could be
followed by different calls, e.g., getShell() in the try block only
or getShell() and then getMessage() in the catch block.
com.fa.c.RootCommandExecutor:
Execute()
android.util.Log:
d()
com.stericson.RootTools.RootTools:
getShell()
java.lang.Throwable:
getMessage()
com.stericson.RootShell.execution.Shell:
add()
Fig. 3: Call graph of the API calls in the try/catch block of Fig. 2.
(Return types and parameters are omitted to ease presentation).
In this phase, MAMADROID operates as follows. First, it
identiﬁes a set of entry nodes in the call graph, i.e., nodes with