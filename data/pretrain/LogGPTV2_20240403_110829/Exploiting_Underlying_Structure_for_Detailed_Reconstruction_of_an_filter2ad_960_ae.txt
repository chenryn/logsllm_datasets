contributed enough packets to allow us to use our mech-
anism for estimating the seed. Since the counter used by
Witty to reseed its PRNG is only 32 bits wide, it will wrap-
around every 232 milliseconds, which is approximately
49.7 days. The results could potentially be distorted due
to this effect (but see below).
There is a clear domination of short-lived machines, with
approximately 47% having uptimes of less than ﬁ ve days.
On the other hand, there are just ﬁ ve machines that had an
uptime of more than 40 days. The sharp drop-off above
40 days leads us to conclude that the effects due to the
wrapping-around of the counter are negligible.
The highest number of machines were booted on the
same day as the spread of the worm. There are prominent
troughs during the weekends — recall that the worm was
released on a Friday evening Paciﬁc Time, so the nearest
weekend had passed 5 days previously — and heightened
activity during the working days.
One feature that stands out is the presence of two modes,
one at 29 days and the second at 36/37 days. On further in-
vestigation, we found that the machines in the ﬁrst mode
all belonged to a set of 135 infectees from the same /16
address block, and traceroutes revealed they were situated
at a single US military installation. Similarly, machines in
the second mode belonged to a group of 81 infectees from
another /16 address block, belonging to an educational in-
stitution. However, while machines in the second group ap-
peared at the telescope one-by-one throughout the infection
period, 110 of the 135 machines in the ﬁrst group appeared
at the telescope within 10 seconds of Witty’s onset. Since
such a fast spread is not feasible by random scanning of the
address space, the authors of [18] concluded that these ma-
chines were either part of a hit-list or were already compro-
mised and under the control of the attacker. Because we can
ﬁt the actions of these infectees with running the full Witty
code, including PRNG reseeding patterns that match the
process of overwriting disk blocks, this provides evidence
that these machines were not specially controlled by the at-
tacker (unlike the Patient Zero machine), and thus we con-
clude that they likely constitute a hit-list. (We investigated
an alternate explanation that instead these machines were
passively monitoring large address regions and hence were
infected much more quickly, but can discount this possi-
bility because a “lineage”analysis reveals that a signiﬁcant
number of the machines did not receive any infection pack-
ets on even their entire local /16 prior to their own scanning
activity arriving at the telescope. Additionally, these sys-
tems’ IP addresses also suggest local monitors, rather than
a collection of global monitors on a large address space.)
Returning then to the fact that these machines were all re-
booted exactly 29 days before the onset of the worm, we
speculate that the reboot was due to a facility-wide system
upgrade; perhaps the installation of system software such
as Microsoft updates (a critical update had been released
on Feb. 10, about 10 days before the simultaneous system
reboots), or perhaps the installation of the vulnerable ISS
products themselves. We might then speculate that the at-
tacker knew about the ISS installation at the site (thus en-
abling them to construct a hit-list), which, along with the
attacker’s rapid construction of the worm indicating they
likely knew about the vulnerability in advance [21], sug-
gests that the attacker was an ISS “insider.”
Number of disks. Once we can recover the seed used at
USENIX Association
Internet Measurement Conference 2005  
361
Number of Disks
Number of Infectees
1
52
2
32
3
12
4
2
5
2
6
0
7
0
Table 2: Disk counts of 100 infectees.
the beginning of a sequence of packets, we can use its value
as an anchor to mark off the precise subsequent actions of
the worm. Recall from Fig. 2 that the worm generates ex-
actly 20,000 packets in its inner loop, using 80,000 random
numbers in the process. After exiting the inner loop, the
worm uses three bits from the next random number to de-
cide which physical disk it will attempt to open. Starting
from the seed, this is exactly the 80,001th number in the
sequence generated by the PRNG. Thus, knowledge of the
seed tells us exactly which disk the worm attempts to open.
Furthermore, as discussed above we can tell whether this
attempt succeeded based on whether the worm reseeds af-
ter the attempt. We can therefore estimate the number of
disks on the infectee, based on which of the attempts for
drives in the range 0 to 7 lead to a successful return from
the open system call. Table 2 shows the number of disks
for 100 infectees, calculated using this approach. The ma-
jority of infectees had just one or two disks, while we ﬁnd
a few with up to ﬁ ve disks. Since the installation of end-
system ﬁre wall software was a prerequisite for infection by
Witty, the infectee population is more likely to contain pro-
duction servers with multiple disks.
Exploration of infection graph. Knowledge of the pre-
cise seeds allows us to reconstruct the complete list of pack-
ets sent by each infectee. Additionally, the large size of our
telescope allows us to detect an infectee within the ﬁrst few
seconds (few hundred packets) of its infection. Therefore
if an infectee is ﬁrst seen at a time T , we can inspect the list
of packets sent by all other infectees active within a short
preceding interval, say (T − 10 sec, T ), to see which sent a
packet to the new infectee, and thus is the infectee’s likely
“infector.” to select the most likely “infector”.
The probability of more than one infectee sending a
worm packet to the same new infectee at the time of its
infection is quite low. With about 11,000 pkts/sec seen at
a telescope with 1/256 of the entire Internet address space,
and suffering 30% losses due to congestion (§ 5), the ag-
gregate scanning rate of the worm comes out to around
256 · 11, 000/0.7 ≈ 4 · 106 pkts/sec. With more than 4 · 109
addresses to scan, the probability that more than one in-
fectee scans the same address within the same 10 second
interval is around 1%.
Figure 12 shows scan packets from infected sources that
targeted other infectees seen at the telescope. The x-
coordinate gives tscan, the packet’s estimated sending time,
and the y-coordinate gives the difference between tinfection,
the time when the target infectee ﬁrst appeared at the tele-
scope, and tscan. A small positive value of tinfection − tscan
raises strong suspicions that the given scan packet is re-
)
.
c
e
s
(
n
a
c
s
t
-
n
o
i
t
c
e
f
n
i
t
1000
100
10
0
-10
-100
-1000
 0
 500  1000  1500  2000  2500  3000  3500  4000  4500  5000
tscan (sec.)
Figure 12: Scans from infectees, targeted to other victims.
 500
 450
 400
 350
 300
 250
 200
 150
 100
 50
s
n
a
c
s
f
o
r
e
b
m
u
N
 0
-5000 -4000 -3000 -2000 -1000
 0
 1000  2000  3000  4000  5000
tinfection-tscan (sec.)
Figure 13: Number of scans in 10 second buckets.
sponsible for infecting the given target. Negative values
mean the target was already infected, while larger positive
values imply the scan failed to infect the target for some
reason — it was lost,8 or blocked due to the random desti-
nation port it used, or simply the target was not connected
to the Internet at that time. (Note that the asymptotic curves
at the top and bottom correspond to truncation effects re-
ﬂecting the upper and lower bounds on infection times.)
The clusters at extreme values of tinfection − tscan in Fig-
ure 12 mask a very sharp additional cluster, even using the
log-scaling. This lies in the region 0 < tinfection−tscan ≤ 10.
In Figure 13, we plot the number of scans in 10 second
buckets against tinfection − tscan. The very central sharp peak
corresponds to the interval 0-to-10 seconds — a clear mark
of the dispatch of a successful scan closely followed by
the appearance of the victim at the telescope. We plan
to continue our investigation of infector-infectee relation-
ships, hoping to produce an extensive “lineage”of infection
chains for use in models of worm propagation.
362
Internet Measurement Conference 2005 
USENIX Association
7 Discussion
While we have focused on the Witty worm in this pa-
per, the key idea is much broader. Our analysis demon-
strates the potential richness of information embedded in
network telescope observations, ready to be revealed if we
can frame a precise model of the underlying processes gen-
erating the observations. Here we discuss the breadth and
limitations of our analysis, and examine general insights
beyond the speciﬁc instance of the Witty worm.
Candidates for similar analysis. The binary code of
all Internet worms is available by deﬁnition, making them
candidates for disassembly and analysis. Similarly, copies
of many scanning and ﬂooding tools have been captured by
white hat researchers, and traces observed at telescopes of
probing or attack trafﬁc (or backscatter) from the operation
of such tools provide candidates for similar analysis. A pre-
liminary assessment we performed of ten well-known DoS
attack tools revealed that six of them use simple PRNGs
with unsophisticated seeds, while the other four use no ran-
dom number generation at all. Even with limited knowl-
edge of the operation of such tools, we should in principle
be able to analyze logs of their attack trafﬁc or backscat-
ter with a similar intent of reconstructing the sequence of
events in the automation of the attack, potentially leading
to information about the attacking hosts, their interaction
with the network, and other forensic clues.
Diversity of PRNGs. Our analysis was greatly facili-
tated by the use of a linear congruential PRNG by Witty’s
author. Reverse-engineering the state of a more complex
PRNG could be much more difﬁcult.
In the extreme, a
worm using a cryptographically strong hash function with
a well-chosen key as its PRNG would greatly resist such
reverse engineering. However, there are several practical
reasons that support the likelihood of many attackers using
simpler PRNGs.
Implementing good PRNGs is a complicated task [8],
especially when constrained by limits on code size and the
difﬁculty of incorporating linkable libraries. Large-scale
worms beneﬁt greatly from as self-contained a design as
possible, with few dependencies on platform support, to
maximize the set of potential victims. Worms have also
proven difﬁcult to fully debug — virtually all large-scale
worms have exhibited signiﬁcant bugs — which likewise
argues for keeping components as simple as possible. His-
torically, worm authors have struggled to implement even
the LC PRNG correctly. The initial version of Code Red
failed to seed the PRNG with any entropy, leading to all
copies of the worm scanning exactly the same sequence of
addresses [2]. Slammer’s PRNG implementation had three
serious errors, one where the author used a value of the pa-
rameter b in the LC equation (Eqn. 1) that was larger than
the correct value by 1 due to an incorrect 2’s complement
conversion, another where this value was subtracted from
instead of added to the term aXi in Eqn 1, and ﬁnally the
(mis)use of an OR instruction rather than XOR to clear a
key register [11]. In addition, sources of local entropy at
hosts are often limited to a few system variables, compli-
cating the task of seeding the PRNG in a fashion strong
enough to resist analysis. Thus it is conceivable that worm
authors will have difﬁculty implementing bug-free, com-
pact versions of sophisticated PRNGs.
In addition, today’s worm authors have little incentive
to implement a complex PRNG. As long as their goals are
conﬁned to effectively scanning the IP address space and
maximizing the worm’s infection rate, simple PRNGs suf-
ﬁce. Hiding one’s tracks while releasing a worm can al-
ready be accomplished by using a chain of compromised
victims as stepping stones. Indeed, the fact that Witty’s au-
thor left Patient Zero running with a separate program for
spreading the worm was purely a mistake on his/her part.
As discussed earlier, the code it ran scanned a very small
subset of the IP address space, and did not manage to pro-
duce even one infection during scanning.
Thus, there are signiﬁcant factors that may lead to the
continued use by worms of simple PRNGs such as LC,
which, along with the availability of disassembled code,
will facilitate the development of structural models of
worm behavior to use in conjunction with telescope obser-
vations for detailed reconstructions.
General observations from this work. Our study has
leveraged the special conditions produced by a worm’s re-
lease to measure numerous features of its victim population
and the network over which it spread. While speciﬁc esti-
mation tricks developed in this paper might not apply to
other telescope observations in a “cookbook”manner, the
insight that telescope observations carry rich information
that can be heavily mined armed with a sufﬁciently detailed
model of the underlying source processes is of major sig-
niﬁcance for the future study of such data.
Understanding the structure of the scanning techniques
used by worms (and empirical data on hitherto unmeasured
quantities such as distribution of access bandwidth) can be
crucial for developing correct models of their spread — a
case made for example by our observation of the doubly-
scanned and never-scanned portions of the address space,
and their multi-factored impact on the worm’s growth.
Finally, we would emphasize that the extraction of the
features we have assessed was a labor-intensive process.
Indeed, for many of them we did not initially apprehend
even the possibility of analyzing them. This highlights not
only the difﬁculty of such a forensic undertaking, but also
its serendipitous nature. The latter holds promise that ob-
servations of other Internet-scale events in the future, even
those of signiﬁcantly different details or nature, will likely
remain open to the possibility of such analysis.
USENIX Association
Internet Measurement Conference 2005  
363
364
Internet Measurement Conference 2005 
USENIX Association