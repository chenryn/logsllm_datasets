"fieldName": "visit_count"
"name"：
"type":
"fields":[
"type": "or"
"dimension":"corpuin"
"type":“selector"
"value":1
"dimension": "is_ad",
"type":“selector",
"value":“www.mejia.wang"
"value":“2852199351"
"hyperUnique"
"visitor_count",
"hyperUnique",
"value":"2"
"dimension":"device_type",
"type":"selector",
"value": "1"
"dimension": "device_type",
"type":“selector",
145
---
## Page 170
146
"postAggregations":
"fields":
"fn": "/",
"fn":"/"
"fieldName":"click_count"
"name":"click_visitor_count",
"fieldName":"new_visit_count"
"name"：
"type":
"fields":
"name"
"type"
"type":
:"click_rate"
"hyperUnique"
"fieldName":"visitor_count"
"type":"hyperUniqueCardinality",
"fieldName":"click_visitor_count"
"type":"hyperUniqueCardinality",
"arithmetic"
"fieldName":"visitor_count"
"type": "hyperUniqueCardinality",
"fieldName":"new_visitor_count"
"type": "hyperUniqueCardinality"
"new_visitor_rate",
"arithmetic",
Druid实时大数据分析原理与实践
---
## Page 171
第6章
context
intervals
postAggregations
aggregations
filter
granularity
having
limitSpec
dimensions
dataSource
queryType
字段名
其中columns是一个数组，可以指定多个排序字段，排序字段可以是demension或metric，
"columns":[list of OrderByColumnSpec],
"limit"
"type"
指定排序规则和 limit 的行数。JSON示例如下：
GroupBy特有的字段为 limitSpec 和 having。
GroupBy查询包含如下部分。
（1）limitSpec
"intervals":[
数据查询
"2016-08-29T00:00:00+08:00/2016-09-04T23:59:59+08:00"
,
"default"
指定一些查询参数，如结果是否进缓存等
查询时间区间范围，ISO-8601格式
后聚合器
聚合器
过滤器
查询结果进行聚合的时间粒度
对统计结果进行筛选
对统计结果进行排序，取limit的行数
进行GroupBy查询的维度集合
要查询数据集dataSource名字
对于GroupBy查询，该字段的值必须是groupBy
描述
否
是
否
是
否
是
否
否
是
是
是
是否必需
147
---
## Page 172
selector、and、or和not等操作。JSON示例如下：
"limitSpec":{
指定排序规则的拼写方式：
148
"value":
"aggregation":"",
"type": "equalTo",
"value":
"aggregation":"",
类似于 SQL 中的having 操作，对GroupBy 的结果进行筛选。支持大于、等于、小于、
"columns":[
"limit":1000,
"type": "default",
"type":"greaterThan",
示例如下：
"direction"
"dimension"：""
（2）having
人
"direction":"ascending"
"dimension":"click_visitor_count"
"direction":"descending"
"dimension":
"：
:"visitor_count",
Druid实时大数据分析原理与实践
---
## Page 173
定过滤器和时间段查看指定维度和Metric。能通过descending字段指定排序顺序，并支持分
6.7
第6章数据查询
Select类似于SQL中的 select操作，Select用来查看Druid中存储的数据，并支持按照指
如果不指定，默认使用vl。
在最新发布的0.9.2版本中，GroupBy可以在context中指定使用新算法，指定方式为：
"havingSpec": 
"type": "not",
"havingSpecs": [, , ..]
"type": "or",
"havingSpecs": [, , ...]
"type":"and"
"value":
"dimension":""
"type":"dimSelector",
"value":
"aggregation":"",
"type": "lessThan",
Select
149
---
## Page 174
JSON示例如下：
150
"pagingSpec":{"pagingIdentifiers":{,"threshold":5,“fromNext":true}
在 pagingSpec中指定分页拉取的offset 和条目数，在结果中会返回下次拉取的offset。
"queryType":"select"
"metrics":
"descending":
"dataSource":"visitor_statistics",
pagingSpec":{
'intervals":[
'dimensions":
"pagingIdentifiers":{},
"visit_count",
"2016-08-29/2016-08-31"
"threshold":5
"click_visit_count"
"count"
"device_type",
"tid",
'new_visit_count"
"ad_campaign
ad_media",
ad_source"
'is_new",
'host",
"corpuin"
"false",
Druid实时大数据分析原理与实践
---
## Page 175
6.8
第6章
"pattern":“some_pattern"
"type"
"case_sensitive":true,
"type"
"case_sensitive":false,
"type”:“fragment",
"value"
"type"
Search查询返回匹配中的维度，类似于 SQL中的like 操作，但是支持更多的匹配操作。
"searchDimensions":[
"queryType":
"query":
"intervals":[
"granularity":
"dataSource":
一个Search查询的JSON示例如下：
"value":"some_value"
Search
数据查询
"value":
"type":
"2013-01-01T00:00:00.000/2013-01-03T00:00:00.000"
"dim2"
"dim1"
:"regex",
："contains",
"some_value"
"insensitive_contains"
"search"
"Ke"
"insensitive_contains"
"sample_datasource"
"day"
151
---
## Page 176
返回结果如下：
"sort":{
"type": "lexicographic"
"timestamp":"2012-01-02T00:00:00.000Z"
"result":[
"timestamp":"2012-01-01T00:00:00.000Z"
"result":
"value":"SomethingElseThatContainske"
"dimension":"dim2"
"count":2,
"value":"SomethingThatContainsKe"
"dimension":"dim1"
"count":1,
"value":"Ke$haForPresident""
"dimension":“dim2",
"count":1
"value": “Ke$ha"
"dimension":"dim1",
"count":3，
Druid实时大数据分析原理与实践
---
## Page 177
1.timeBoundary
最近一次摄入数据的时间戳。查询JSON示例分别如下：
column、metric、aggregator和查询粒度等信息；通过dataSourceMetadata查询DataSource的
Source的最早和最晚的时间点；通过segmentMetadata查询Segment的元信息，如有哪些
6.9
方式。ilter字段也支持正则匹配。
为查询条件进行TopN、GroupBy或Timeseries 等操作，则可以在filter字段中指定各种过滤
第6章数据查询
"intervals":["2013-01-01/2014-01-01"]
segmentMetadata
"dataSource":"sample_datasource",
"queryType":"segmentMetadata",
返回结果如下：
"dataSource":"sample_datasource",
"queryType"：
Druid支持对DataSource的基础元数据进行查询。可以通过timeBoundary查询Data-
需要注意的是，Search只是返回匹配中维度，不支持其他聚合操作。如果要将Search作
'bound"
元数据查询
"timestamp":"2013-05-09T18:24:00.000Z"
"result":[
"minTime":
"maxTime":"2013-05-09T18:37:00.000Z"
:"timeBoundary",
"2013-05-09T18:24:00.000Z"
153
---
## Page 178
154
返回结果如下：
"columns":{
"aggregat.ors":
"dim1":{
"__time”：{
"metric1":{
"metric1":{
"dim2":
"hasMultipleValues":false,
"cardinality":null,
"type":"STRING"
"size":100000,
"hasMultipleValues": true,
"cardinality":1504,
"type":
"hasMultiplevalues":false,
"cardinality":
"type":"LONG"
"hasMultipleValues":false,
"cardinality":null,
"type": "longSu"
"name":“metric1"，
"fieldName":“metric1",
"size":100000,
"errorMessage":null,
"errorMessage":null,
"size":100000,
"errorMessage":null,
"size":407240380,
"errorMessage":null,
“STRING"
1944
Druid实时大数据分析原理与实践
---
## Page 179
gators.
"toInclude":["type":
第6章数据查询
"toInclude":["type":
context
lenientAggregatorMerge
analysisTypes
merge
tolnclude
字段名
toInclude的使用方式如下：
segmentMetadata支持更多的查询字段，