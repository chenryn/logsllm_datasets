Theproposedmodel,whichshowsthebestperformancefigures,achieves32%precisionand95%
recall,demonstratinghighsensitivitytoclearfault-signalingmessages,butlowprecision(andthus
highfalsealarmrate)overall.
Zheng et al. [165] propose a method based on RNN to estimate the Remaining Useful Life of
systemcomponents.Theyarguethatthetemporalnatureofsensordatajustifiestheuseof long
short-termmemory(LSTM)-basedRNNs,duetotheirabilitytomodellongterm-dependencies.
TheyexperimentwiththreeRULpublicdatasetsandcomparetheirmethodwithotherMachine
Learning approaches in terms of Root Mean-squared Error (RMSE), showing how their ap-
proach obtains the best RUL prediction performance (RMSE = 2.80, 54.47% improvement over
CNNs).
4.2.2 SystemFailurePrediction. Insteadofinvestigatingtheoccurrenceofphysicalcomponent
failures,futuresystemavailabilitycanalsobeestimatedthroughsymptomaticevidenceanddepen-
dencymodelingassumptionsatthesoftwarelevel.Pastapproachesforsystemfailureprediction
aremostlybasedontheobservationoflogs,whichconstitutethemostfrequentdatasource,KPIs
andhardwaremetrics,whicharetypicallyusedinshorterpredictionwindowsandaremorefre-
quentlyassociatedwiththefailuredetectionproblemaswell.Systemfailurepredictionareapplied
on different abstraction levels depending on the target software component under investigation
(job,task,container,VM,ornode).
SomeearlycontributionsareassociatedwithfailurepredictionintheIBMsupercomputerBlue-
Geneproject.Liangetal.[81],forinstance,applydifferentclassificationalgorithmsforBlueGene,
ACMTransactionsonIntelligentSystemsandTechnology,Vol.12,No.6,Article81.Publicationdate:November2021.
ASurveyofAIOpsMethodsforFailureManagement 81:21
usingrealeventlogstopredictfatalfailuresinsidefixedtimewindowsofobservation.Inputfea-
tures are parsed from structured logs based on the severity, total count, and distribution of log
events inside an observation window. Features obtained from the previous window are used to
predictfailureinthenextone.Intheevaluationphase,fourclassificationalgorithms(SVM,RIP-
PER,BMNN,k-NN)arecomparedusingprecision,recall,andF-score.Thesizeoftheprediction
windowappearstohavealargeimpactonthefinaldetectionperformance.Fromtheexperiments,
theidealwindowsizeisestimatedbetween6and12htobalanceutilityeffectivenessandaccuracy.
TheBi-modalnearestneighborapproachproposedinthepaperprovidesthebestresultsoverall,
leadingtoanF-measureof70%(and50%)with12-h(and6-h)predictionwindows,respectively.
Cohen et al. [31] investigate an approach based on Tree-augmented Bayesian Networks
(TANs)toassociateobservedvariableswithabstractservicestates,forecastanddetectSLOvio-
lations and failures in three-tiered Web services. The system is based on the observation of sys-
temmetrics,suchCPUtime,diskreads,swapspace,andKPI-relatedmeasures,likethenumberof
servedrequests,allinterdependentlymodeled(inadditiontothedependentvariable,thepredicted
state).Theoptimalgraphstructure,includingtheidealsubsetofinputmetrics,isselectedutilizing
agreedystrategy.Theapproach,originallydevelopedfordetection,canalsobeusedtodiagnose
failuresthankstotheinterpretabilitypropertiesofTANs(seeSection4.4.2).Twoseparateexperi-
mentsareusedforvalidation,amulti-tieredJavaserverapplication,andanApacheservertestbed,
bothinjectedwithsyntheticworkloadsvaryinginconnections,requestrate,andtype.Theresults
forforecasting,applied1or5mininadvanceoffailures,showhighdetectionrates(83–93%)and
false-alarmratesvaryingbetween9.1%and24%dependingontheexperiments.
Salfner et al. [123] train HSMM for online prediction of failures in event sequences collected
fromerrorlogs.OneHSMMistrainedonfailingsequences,asecondoneonnon-failingsequences.
Then,thesequencelikelihoodofthemodelsdetermineswhichofthetwoscenariosismorelikelyto
occur.Theapproachisevaluatedonlogsofacommercialtelecommunicationsystemandcompared
withotherpredictiontechniques,achievinganF-measureof0.7419(precision0.852,recall0.657).
Theobservedfalse-positiverateis0.0145.
Chalermarrewongetal.[23]proposeasystemavailabilitypredictionframeworkfordatacenters,
basedonautoregressivemodelsandfault-treeanalysis.Theirautoregressiveintegratedmovingav-
erage(ARIMA)modelworksontimeseriesofworkloadandhardwaremetrics,wherethresholds
arefixedtodetectcomponent-levelsymptoms(suchashighCPUtemperature,baddisksectors,
memoryexhaustion),whichalsoconstitutetheleavesofthefaulttree.Usingthesesymptomsand
thetreestructure,amodelofdependenciesincombinationallogicdeterminestheavailabilitystate
deterministically.Anadvantageoftheseapproachesthatitimplicitlyprovidesgranularinforma-
tionfordiagnosis.Theexperimentalresultsshowhighpredictionaccuracy(97%)butahighrate
offalsealarmsaswell(precisionis53%).
TheHORApredictionsystem[119]adoptsaholisticapproach,wherearchitecturalknowledgeis
usedwithonlinetime-seriesdatatopredictQoSviolationsandservicefailuresindistributedsoft-
ware systems. Component dependency and failure propagation models, in the form of Bayesian
Networks,areusedtoassociatecomponentfailures,predictedfromsystemmetricswithautore-
gressivepredictors,tosystem-wideproblems.Testedonamicroservice-basedapplication,thenew
approach is compared to a monolithic approach (not using architectural knowledge) by inject-
ing memory leaks, node crashes, and system overloads during execution. The HORA approach
achievesahigherrecall(83.3%versus69.2%)andAUCROC(0.920versus0.837,+9.9%)compared
tothemonolithicapproach.Theproposedapproachisalsomoreviablewhenahighfalsealarm
rate(≥10%)isacceptable,whilethemonolithicapproachismoreadequateforpredictionsinthe
0–10%falsealarmrange.
ACMTransactionsonIntelligentSystemsandTechnology,Vol.12,No.6,Article81.Publicationdate:November2021.
81:22 P.Notaroetal.
Fronzaetal.[44]describeafailurepredictionapproachbasedontext-analysisofsystemlogsand
SVMs.First,logfilesareparsedandencodedusingatechniquecalledRandomIndexing,wherefor
eachoperationinsidealogline,indexvectorsareassignedtoobtainalatentrepresentationofthe
text.Then,byscanningthroughthelogcorpus,contextvectorsforeachoperationarecomputed,
so that co-occurrence of operations can be taken into account. Finally, sequences of operations
arerepresentedastheweightedsumofcontextvectorscorrespondingtotheoperationsencoded
inside.TheserepresentationsofsequencesconstitutetheinputofaweightedSVM,trainedwiththe
objectiveofminimizingfalsenegatives.Resultsshowhowaweightedapproachcancompensate
foradecreaseinspecificity(alwaysgreaterthan80%)toimproverecall(50%).
Similarly,inReference[160]RNNsareappliedforfailurepredictionfromlogs.Theapproachis
composedofaclusteringalgorithmusedtogroupsimilarlogs,apatternmatcherusedtoidentify
commontemplatesinsidesimilarlogs,alogfeatureextractorbasedonnaturallanguageprocess-
ing,andasequentialneuralnetworkarchitecturebasedonLSTMcells,usedtopredictthefailure
statuswithinthepredictiveperiod.TheuseofLSTMsisalsomotivatedbytheirsequentialmod-
elingabilitiesandtherarityoffailures.Theapproachiscompared,usingrealdatacollectedfrom
two enterprise server clusters, with other Machine Learning methods (SVM, logistic regression,
randomforest)intermsofprecision-recallAUC.At70%precision,theLSTMmethodshowsthe
highest failure sensitivity with a recall value of 0.909. LSTMs are able to detect signs of failures
earlierthanothermethods(73minonaverage).
LSTM networks are also used by Islam et al. in Reference [61], a large characterization study
ofjobfailuresconductedonaworkloadtracedatasetbyGoogle.Failuresarepredictedatthejob
andtasklevel,whereajobisacollectionoftasksandeachtaskisasingle-machinecommandor
program.Failuresarepredictedfromresourceusagemeasures,performancedata,andtaskinfor-
mation(completionstatus,user/node/jobattributes).Fortaskfailureprediction,thefinalF1-score
ofthesystemis0.87(precision=0.89,recall=0.85,FPR=0.11).Forjobfailureprediction,theap-
proachachievesaF1-scoreof0.81(precision=0.80,recall=0.83,FPR=0.20).Thepredictionalgo-
rithmcanbeusedtoreduceresourcewaste(downby12–20%intheexperiments)byre-submission
oflikely-to-failjobsandtasks.
4.3 FailureDetection
Inthissection,westartdiscussingreactivefailuremanagementmethods,whichoperatetolimit
theconsequencesoffailuresaftertheyhaveoccurred.Theyaremotivatedbythefactthat,even
withthemostadvancedpreventionandpredictiontechniques,theoccurrencerateoffailurescan
neverbefullyreducedto0.Somereactiveapproaches,forexampleinroot-causeanalysisoranom-
alydetection,canalsobeusedtogetabetterunderstandingofhowfailuresarecausallyrelated
andpropagateovertime,ortocomprehendwithwhichtemporalcharacteristics(variance,burst
frequency,periodicity,seasonality)failuresareassociated.
Thedetectionoffailuresviamonitoringoperationscanbeacomplexandtedioustaskforhu-
manoperators.Chenetal.[26]reporthowintheadministrationofacommercialwebsite,75%of
the recovery time was spent on average for detection. The automatic discovery of performance
problems and errors allows operators to dedicate less time identifying service-related problems
whileprovidinginsightsonwhichfailuresmustbeprioritizedinthediagnosisstepbasedonthe
frequency observed in the detection phase. Automated failure detection is based on a variety of
monitoring tools, ranging from simple print statements (which constitute the fundamental unit
ofsystemlogs)tomorecomplexinstrumentationtechniquesorentireframeworks.Wedivideour
discussionoffailuredetectioninanomalydetection,Internettrafficclassification,andlogenhance-
menttechniques.
ACMTransactionsonIntelligentSystemsandTechnology,Vol.12,No.6,Article81.Publicationdate:November2021.
ASurveyofAIOpsMethodsforFailureManagement 81:23
4.3.1 Anomaly Detection. According to our quantitative results [113], failure detection is
treatedasananomalydetectionprobleminthelargemajorityofcontributionsrelatedtoITsystem
management.Anomalydetectionisamultidisciplinarytaskthatdealswithfindingpatternsindata
thatdonotconformtotheexpectedbehavior[24].Theinterestinanomalydetectionismotivated
bythepossibilitytoobtainactionableinformationtodealwithdiseases,frauds,cyber-attacks,sys-
temoutages,andfaults,dependingonthetargetdomain.Anomalydetectionoperatesbyderiving
amodelofnormalbehavior,andbytestingnewobservationsagainstthismodel.AnomalyDetec-
tionisappliedintheAIOpscontextundertheassumptionthatfailuresgenerateirregularbehavior
inITsystems(errors)acrossasetofmeasurableentities(orsymptoms),suchasKPIs,metrics,logs,
orexecutiontraces.Anomalydetectionisalsousedtodetectcyber-attacks,congestion,andsub-
optimalresourceutilization,whichcanallbecausesoffuturefailures.Becauseobtaininglabeled
examplesistime-consuming,anomalydetectionsystemstypicallyrelyonunsupervisedlearning.
Threearethemostprominenttechniquesusedinsuchcontext:clustering[11,127],dimensionality
reduction[72,151]andneuralnetworkautoencoders[7,131,150,159].Oneoftheearliestexam-
plesofunsupervisedlearningforsystemworkloadcharacterizationisMagpie[11],abehavioral
modelingtoolchainfordistributedsystems.Magpie’sinstrumentationisbasedonfine-grained,in-
kerneleventloggingtoolsavailableunderWindows,abletomeasureresourceconsumptionand
executiontimesaccurately.Theeventsregisteredwiththistoolareusedtoreconstructrequests
andapplybehavioralclusteringtoobtainasmallsetofuniquerequesttypes,eachassociatedwith
aspecificworkloadmodel.Inthepaper,behavioralclusteringallowsonetomodelrealisticwork-
loadsmorepreciselythanbygroupingrequestsbyURL.Arealisticworkloadmodelisbeneficialto
identifyanomalousresourceconsumption,besidesenhancingcapacityplanningandperformance
testing.
At the network level, Lakhina et al. [72] monitor network links via SNMP data to detect and
diagnoseanomaliesinnetworktraffic.TheapplyPCAonlinkflowmeasurementscollectedover
timetoseparatetrafficinnormalandanomaloussubspaces.Theyclassifyprincipalcomponents
innormalandabnormal(settingathresholdontheexplainedvariance),thenidentifyanomalies
byreconstructingthenewobservationsusingabnormalcomponents.Ifthereconstructionerror
exceedsapredefinedthreshold,thenthenewdatapointisconsideredanomalous.Theirapproach
isvalidatedusingsyntheticandrealvolumeanomalies,thelatterdetectedwithtraditionalclass
forecastingalgorithms.Inafollow-upwork[73],asimilarapproachbasedontrafficfeaturedistri-
butionentropyisproposed.Thepapershowshowthesamesubspacemethodcanexploitpacket
information,suchassourceandtargetdestinationaddressorport,todetectsecuritythreatsand
serviceoutages,aswellastoprovidepreliminarydiagnosticinformation.
SeveralapproachesapplyunsupervisedlearningonunivariatetimeseriesconstructedfromKPI
and metric observations [127, 150]. Sharma et al. [127] propose CloudPD, an end-to-end failure
tolerance system performing failure detection, diagnosis, and classification in virtualized cloud
environments(seealsoSection4.4.2).Thepaperproposestocollectavarietyofmeasuresatthe
VM and physical machine level, including resource utilization, operating system variables, and
applicationperformancemetrics.ThepaperthenproposesthreedifferentunsupervisedMachine
Learningapproachesforanomalydetection:k-nearestneighbors(k-NN),HMMs,andk-means
clustering. The k-NN detection approach is evaluated on three different benchmarks, where it
beatsfourproposedbaselineswithanaveragehigherrecall(83–87%)andalowerfalsealarmrate
(12–17%).Donut[150]performsanomalydetectiononseasonalKPItimeseriesusingdeepVaria-
tionalAutoencoders(VAE)andwindowsampling.Theapproachiscomparedonthreedifferent
datasetsof18KPIstoOpprentice[86]andabaselineVAEperformanceintermsofF-score(ranging
from0.75to0.9),AUC(0.7–0.9)andaveragealertdelay(4to12min).Oneoftheconclusionsofthe
ACMTransactionsonIntelligentSystemsandTechnology,Vol.12,No.6,Article81.Publicationdate:November2021.
81:24 P.Notaroetal.
authorsisthatautoencoderapproachesrequireabnormalsamplesinadditiontonormalbehavior
samples.
Themostrecenttime-seriesapproachesfocusonmultivariateanomalydetectionusingautoen-
coders[7,131,159].Twoadvantagesofamulti-dimensionalanalysisaretheabilitytomodelthe
inter-correlationsbetweendifferentmetrics/components,andtoprovideinterpretableresultsfor
root-cause analysis, by attributing the detected anomaly to a specific metric or component. MS-
CRED[159]usesaconvolutional-recurrent(ConvLSTM)autoencoderarchitecturetocapturetem-
poral patterns at different scales and thus identify abnormal time steps. In the evaluation study,
MSCRED outperforms the baselines (SVM, ARMA, GMM, CNN) with an F1-score of 0.82–0.89,
whilebeingabletoidentifyanomaliesonscalesw =10,30,60s.Bycomputingthereconstruction
errorsonindividualtimesequences,MSCREDcanalsoidentifyrootcausesmoreeffectively(top-3
recall=0.75–0.80).OmnyAnomaly[131]proposesarecurrentVAEmodelusingstochasticvariable
connectionandplanarnormalizingflow.AsforMSCRED,thereconstructionerrorcanbeusedto
interpret anomalies and connect back to individual time series. OmniAnomaly achieves a detec-
tionF1-scoreof0.8599onthreerealdatasets,includingservermetricdata(SMD[108])collected
fromalarge-scaleInternetcompany.SMDisalsousedforevaluationinUSAD[7],whichapplies
adversarial-basedtechniquestotheautoencoderarchitectureforfasterandmorestabletraining.
In USAD, the anomaly score is parametrized so that the sensitivity can be adjusted rapidly and
on multiple levels for real industrial applications. On five real datasets, USAD achieves results
comparabletoOmniAnomaly(F1=0.791forboth),whilereducingtrainingtimeby547timeson
average.