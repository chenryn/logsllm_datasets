title:On the effectiveness of anonymizing networks for web search privacy
author:Sai Teja Peddinti and
Nitesh Saxena
On the effectiveness of Anonymizing Networks for Web
Search Privacy
Sai Teja Peddinti
Computer Science and Engineering
Polytechnic Institute of New York University
PI:EMAIL
Nitesh Saxena
Computer Science and Engineering
Polytechnic Institute of New York University
PI:EMAIL
ABSTRACT
Web search has emerged as one of the most important applications
on the internet, with several search engines available to the users.
There is a common practice among these search engines to log and
analyse the user queries, which leads to serious privacy implica-
tions. One well known solution to search privacy involves issuing
the queries via an anonymizing network, such as Tor, thereby hid-
ing one’s identity from the search engine. A fundamental problem
with this solution, however, is that user queries are still obviously
revealed to the search engine, although they are “mixed” among the
queries issued by other users of the same anonymization service.
In this paper, we consider the problem of identifying the queries
of a user of interest (UOI) within a pool of queries received by a
search engine over an anonymizing network. We demonstrate that
an adversarial search engine can extract the UOI’s queries, when
it is equipped with only a short-term user search query history, by
utilizing only the query content information and off-the-shelf ma-
chine learning classiﬁers. More speciﬁcally, by treating a selected
set of 60 users – from the publicly-available AOL search logs – as
the users of interest performing web search over an anonymizing
network, we show that each user’s queries can be identiﬁed with
25.95% average accuracy, when mixed with queries of 99 other
users of the anonymization service. This average accuracy drops
to 18.95% when queries of 999 other users of the anonymization
service are mixed together. Though the average accuracies are not
so high, our results indicate that few users of interest could be iden-
tiﬁed with accuracies as high as 80–98%, even when their queries
are mixed among queries of 999 other users. Our results cast seri-
ous doubts on the effectiveness of anonymizing web search queries
by means of anonymizing networks.
Categories and Subject Descriptors
C.2.0 [Computer-Communications Networks]: General—Secu-
rity and protection; K.4.1 [Computers and Society]: Public Policy
Issues—Privacy
Keywords
Web Search Privacy, Anonymizing Networks, Query Obfuscation
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’11, March 22–24, 2011, Hong Kong, China.
Copyright 2011 ACM 978-1-4503-0564-8/11/03 ...$10.00.
1.
INTRODUCTION
Today’s world wide web hosts an enormous amount and a wide
variety of data. Efﬁciently searching and retrieving this vast amoun-
t of information is very important, and currently more than one
search engine is available to the users. To improve their search
results, these search engines adopted the practice to log and anal-
yse the queries issued by the user. This received considerable at-
tention from media and public as well as researchers all over the
world because of the possible privacy breaches. The issue was ﬁrst
brought into limelight in August 2005, when the US Departmen-
t of Justice issued a subpoena to Google for a week’s worth of
search query records [14]. Later AOL has published three months
(pseudonymized) search query logs, from which identities of cer-
tain users had been extracted based on personal information embed-
ded in their queries [8, 2]. Since then, the media started shedding
more light on how several major search engines (Yahoo!, AOL,
MSN and Google) log, store and analyse individual search query
logs.
Archiving and analysing search queries is important from a search
engine’s perspective for improving the quality of search results, and
for generating revenue through sponsored search advertising. How-
ever, this logging of queries has serious privacy implications which
can be categorized into explicit and implicit versions. Explicit pri-
vacy breach happens because of the information embedded in the
query itself, and some common examples include searching for a
particular disease the user or a family member might be suffering
from, searching for one’s social security number to check if it exists
on the web, and performing “ego-surﬁng1”. Implicit privacy viola-
tions happen when the sensitive information can not be learned di-
rectly from the query logs, but has to be extracted using aggregation
and proﬁling methods or data mining techniques. An apt example
could be to infer the income level of a user by keeping track of the
brand of products he/she often searches for[23].
Many techniques have been proposed to address this problem of
privacy breach through web search queries. First class of solutions
involves use of private information retrieval (PIR) protocols [11],
which are a generic body of work. However, current PIR proto-
cols, due to their high communication and computation overload,
are not feasible to be deployed in practice with the existing infras-
tructure. A second class of solutions is based on the principle of
query obfuscation [24], where a client-side software injects noisy
queries into the stream of real queries transmitted to the search en-
gine. These methods protect the user against proﬁling, thereby pre-
venting implicit privacy violations. Unfortunately, a practical query
obfuscation tool - TrackMeNot [10, 22], has recently been shown
to be vulnerable [15]; an adversarial search engine can distinguish
1A common practice seen among users to search for their own
names, just to check what results appear.
483
between user’s queries and obfuscation queries with high accuracy,
and can extract a large fraction of user’s queries.
Another class of solutions involves the use of third-party infras-
tructure such as a single proxy, e.g., Scroogle [18] or an anonymiz-
ing network, e.g., Tor [21]. The use of single proxy is problematic
because it requires the users to impose (unwanted) trust on to a s-
ingle server hosted by a third-party company. Web search over an
anonymizing network, which is the focus of our paper, certainly
provides better protection and fault-tolerance than the use of a sin-
gle proxy. An anonymizing network is typically implemented using
onion routing and it involves routing one’s queries over a path con-
sisting of a series of nodes (called relay servers) distributed all over
the internet. This way the actual source of a query would poten-
tially remain hidden from the search engine. Private Web Search
(PWS) [17] is a client side tool that can be used to route search
queries privately over the Tor network. It has been mentioned in
[17] that search queries, even though stripped of the accompanying
information like IP address and cookies, reveal some information
about the user. They associate it to the linkability among queries,
which has been mentioned as an open problem in Table 1 in [17].
We try to address this open problem of linking queries by using
machine learning techniques and show that queries of a user can be
identiﬁed with reasonable accuracies, just by looking at the query
content.
Our Contributions.
A higher level goal of this work is to analyse how effective an
anonymizing network can be – in preserving users’ privacy in prac-
tice – against an adversarial search engine. (From here on, we will
call the anonymizing network as Tor, for simplicity of presentation
and without loss of generality.) We observe that the web search
over Tor network has one fundamental drawback: the search query
has to reach the search engine in clear text format for the search
engine to be able to process the query and return the response back
to the user. However, these queries are indeed “mixed” among the
queries issued by other users of the same anonymization service.
We ask the following question: Is it possible for an adversarial
search engine to associate queries coming out of Tor exit nodes to
Tor users who issued these queries?
In our attack model, the search engine is a passive adversary
who tries to make identiﬁcation decisions only by analysing the re-
ceived and logged queries. In an attempt to keep our attacks gener-
ic, we assume that the search engine does not make use of any
information associated with the queries besides the queries them-
selves, such as the Tor exit node IP address or even exact query
timestamps. We base our work on an important observation, made
by other researchers [4], that although a potentially large number
of users might be accessing web search over the Tor network, on-
ly a small fraction of these users really remain anonymous to the
search engine in practice. The reason is that a signiﬁcant number of
users, even while using Tor, remain logged in using their accounts
with search engines (e.g., Gmail accounts with Google) and may
not disable cookies and other identifying information [4]. This im-
plies that a user’s queries might be getting mixed among queries of
only a small number of other (anonymous) Tor users, potentially
making these queries more identiﬁable.
Indeed, we answer the aforementioned question afﬁrmatively.
More speciﬁcally, by treating a selected set of 60 users – from
the publicly-available AOL search logs – as ‘users of interest’ per-
forming web search over an anonymizing network, we show that
their queries can be identiﬁed with 25.95% average accuracy, when
queries of upto 99 other Tor users are mixed together and this aver-
age accuracy drops to 18.95% when queries of 999 other Tor users
are mixed together. For few users, these accuracies reached up-
to 80–98%, even when queries of upto 999 ‘other users’ (other
Tor users) are mixed together. Our results cast serious doubt on
the effectiveness of anonymizing web search queries by means of
anonymizing networks.
In the rest of this paper, we denote the AOL users, whose queries
are to be separated from the mixed query set received at Tor exit
nodes as ‘users of interest’ and the total number of users using web
search over Tor as U. The users present in U, apart from the users
of interest, will be referred as ‘other users’.
2. PROBLEM FORMULATION AND STUDY
METHODOLOGY
In this paper, we investigate if it is possible for an adversarial
search engine to associate queries coming out of Tor exit nodes to
Tor users. While using any anonymizing network, the search query
must reach the search engine in clear format so we base our work on
the query information alone, which is always going to be revealed
to the search engine. We assume that the search engine does not
make use of any accompanying information like exit node IP ad-
dress, unblocked cookies accompanying the queries or the Click-
through patterns followed by the user. Speciﬁcally, in our attack
model, the search engine is a passive adversary which tries to make
identiﬁcation decisions only by analysing the received and logged
queries.
For conducting our study, we should simulate real user queries
being channelled through anonymizing networks, like Tor, but s-
ince our model does not require any other information apart from
the query content, it is needless to simulate the Tor functionality.
Therefore, we work directly with real user search query logs. For
obtaining real user queries, one option could be to seek volunteer-
s who may allow us to record their search queries over a period of
time, but it is not a viable solution considering the privacy concerns
(the same concerns that motivate our work). Instead, we chose to
utilize the publicly available real user search logs, such as the AOL
search logs [1] released in 2006. These AOL logs are spread over a
reasonably long duration (3 months).
For our study, we assume that the adversarial search engine has
access to the list of possible Tor users performing web search over
Tor(U). This is a realistic assumption because the search engine has
access to a user’s search history and it can determine whether a par-
ticular user has possibly started to use Tor by identifying changes in
his query patterns (such as query frequency). If for a reasonable du-
ration, e.g., a week, the search engine does not receive any queries
from a user or an IP address, violating the user’s typical querying
pattern, it can mark that user as a potential Tor user. Even when the
users delete their cookies, there are chances that the search engine
might mistake these users to be possible Tor users. However, since
the user querying patterns do not change, the search engine might
be able to map these mistaken Tor users to new cookies if the query-
ing patterns match, and continue proﬁling the users. Such mapping
techniques or anti-aliasing techniques have been studied before in
[13]. Though the content they deal with in [13] are large texts like
bulletin boards and web pages, we believe similar techniques could
be developed for mapping web search users associated with differ-
ent cookies. Thus, we assume throughout our study that the search
engine can generate a possible Tor user list and keep updating it.
Over a period of time, the search engine logs a set of queries
(denoted Q) that it receives from the Tor exit nodes (list of exit n-
odes is publicly available). These queries are issued by the users
appearing in the list U and are all mixed with one another. Our
goal (i.e., the adversarial search engine) is to identify the queries in
Q that correspond to some or all users in U. We model this iden-
tiﬁcation problem as a classiﬁcation problem in machine learning,
484
whereby we train a classiﬁer with the prior search history of the Tor
users (collected prior to the time they started using Tor) and ask the
classiﬁer to classify the queries in Q to their respective users in
U. Since we might want to associate the queries to all users, we
will need one class per user. Therefore, the problem reduces to a
multiclass classiﬁcation problem.
The size of U (denoted N) is an important parameter for our s-
tudy and for the level of privacy that can be provided to the users
over Tor. We argue that in practice N may not be very large. As dis-
cussed in Section 1, recent research [4] shows that although there
are, on an average 1893 Google users at one Tor exit node over one
week, about 872 of these users access the services by signing into