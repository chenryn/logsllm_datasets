(
y
c
n
e
t
a
l
)
s
m
(
y
c
n
e
t
a
l
0
0
0
2
0
0
5
1
0
0
0
1
0
0
5
0
0
0
8
0
0
6
0
0
4
0
0
2
0
100
200
300
400
500
time (s)
(b) End of session artifacts
Figure 6. Artifacts under investigation
tion tear down could be tracked through the network to gain
information about the route of a connection.
Aside from the precise load information extracted from
the probe trafﬁc, these secondary trafﬁc artifacts could also
be used to perform trafﬁc analysis and assess which Tor
server is being used to relay the target trafﬁc. Therefore a
strategy to eliminate information leakage into other streams
should also try to eliminate these artifacts.
6 Conclusions
We have presented an attack against Tor, a deployed and
well used, anonymising protocol. This attack can be per-
formed by a modest adversary, using powers well within
the restricted Tor threat model. In fact, we show that the
anonymising network itself can be used to route probe traf-
ﬁc and gather information otherwise available only to a
global passive adversary.
In November 2004 we performed extensive experiments
on current Tor nodes and found them to be susceptible to
/* Tor main loop */
for(;;) {
timeout = prepare_for_poll();
...
/* poll until we have an event,
or the second ends */
poll_result = tor_poll(poll_array, nfds, timeout);
...
/* do all the reads and errors first,
so we can detect closed sockets */
for(i=0;i<nfds;i++)
/* this also marks broken connections */
conn_read(i);
/* then do the writes */
for(i=0;i<nfds;i++)
conn_write(i);
/* any of the conns need to be closed now? */
for(i=0;i<nfds;i++)
conn_close_if_marked(i);
...
}
/* Read from connection */
static void conn_read(int i) {
...
if(!(poll_array[i].revents & (POLLIN|POLLHUP|POLLERR)))
if(!connection_is_reading(conn) ||
!connection_has_pending_tls_data(conn))
return; /* this conn should not read */
...
connection_handle_read(conn) < 0) {
...
}
Figure 5. The Tor 0.0.9 polling code
two examples that could be used to perform trafﬁc-analysis,
if they were linked with particular states of the Tor nodes.
Figure 6(a) shows the results of probes against an exit
node in the Tor network. Again, the top graph represents
the latency over time of probe trafﬁc, while the bottom rep-
resents the times the corrupt server was sending data. Note
that the latency of the probes seems to be quantised into
four or ﬁve bands – even when a high volume of trafﬁc is
injected. The quantisation could be explained by the lack of
precision or quantisation of the measurement process. An-
other explanation is that the bands are formed by measuring
the node when one, two, three or four other streams are be-
ing served at the time. This seems to match with the experi-
mental data: only four clusters are visible when the corrupt
server is not relayed, and ﬁve when the stream is present.
This technique could be developed to extract information
about the number of streams relayed – and in turn used to
infer the beginning and termination of a stream.
Figure 6(b) illustrates a completely different type of traf-
ﬁc pattern. After the last burst of trafﬁc from the corrupt
server (bottom) the latency of the probe trafﬁc exhibits a
very peculiar pattern, it goes up six times each time falling
back into the average latency. This event has been observed
many times in conjunction with the closure of a Tor con-
nection, and could be due to time devoted in tearing down
connections. If such events can be observed, the connec-
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
our attack. This does not give us the ability to trace the
actual originator of the communication, since we do not
have the ability to observe who is connected to a Tor node.
Nevertheless our attacks greatly degrade the anonymity pro-
vided by Tor, by allowing adversaries to discover the path
of a Tor connection and thereby reducing the protection to
the level provided by a collection of simple proxy servers.
We expect the same attack to be usable against other low-
latency anonymising network designs, since none of them
have been specially hardened against it.
Furthermore, since Tor reuses the same path for multi-
ple streams within a short time interval, our attacks allow
different operations to be linked to the same initiator with
greater certainty. The observable path of each stream can
act as an identiﬁer or identity that links streams amongst
themselves and to the initiator – a property that makes Tor
weaker than a simple proxy when it comes to protecting the
unlinkability of actions.
We discussed some strategies that could be used to pro-
tect Tor against our attacks. They all, to some degree, in-
volve an increase in the latency of the communication. They
also highlight the need for a full covert-channel analysis of
such anonymising networks, to assess whether any informa-
tion that could be used for trafﬁc-analysis is leaked to other
streams that are potentially observable by an adversary.
This attack brings the ﬁeld of anonymous communica-
tions even closer to more traditional computer security dis-
ciplines. On one hand we show that the literature on covert
channel analysis and elimination is directly applicable and
necessary to truly secure Tor. On the other hand, our attack
relies on using Tor nodes as oracles that disclose their load
– therefore not requiring a global observer. Similar tech-
niques have been used in the past in breaking cryptographic
protocols, by using and combining the services they pro-
vide. It is the ﬁrst time that such techniques are applied for
trafﬁc-analysis of anonymous communication systems.
Acknowledgements
Paul Syverson and Roger Dingledine, part of the team
that designed Tor, have provided us with very useful feed-
back and information concerning the architecture of Tor and
the true impact of our attacks. This work would not have
been possible without the dedication of the volunteers run-
ning Tor nodes.
George Danezis is supported by the Cambridge-MIT In-
stitute (CMI) project on ‘Third generation peer-to-peer net-
works’ and part of this work was done while visiting MIT
CSAIL and the Brown University Watermyn Coop. Steven
J. Murdoch is supported by a scholarship from the Carnegie
Trust for the Universities of Scotland.
References
[1] A. Acquisti, R. Dingledine, and P. F. Syverson:. On the eco-
nomics of anonymity.
In R. N. Wright, editor, Financial
Cryptography, volume 2742 of Lecture Notes in Computer
Science, pages 84–102. Springer, 2003.
[2] D. Agrawal, D. Kesdogan, and S. Penz. Probabilistic treat-
ment of mixes to hamper trafﬁc analysis. In IEEE Sympo-
sium on Security and Privacy, pages 16–27, Berkeley, CA,
USA, May 2003. IEEE Computer Society.
[3] A. Alsaid and D. Martin. Detecting web bugs with bugnosis:
Privacy advocacy through education. In Privacy Enhancing
Technologies (PET 2002), San Francisco, CA, May 2002.
[4] A. Back, I. Goldberg, and A. Shostack. Freedom systems 2.1
security issues and analysis. White paper, Zero Knowledge
Systems, Inc., May 2001.
[5] A. Back, U. M¨oller, and A. Stiglic. Trafﬁc analysis at-
tacks and trade-offs in anonymity providing systems.
In
I. S. Moskowitz, editor, Information Hiding workshop (IH
2001), volume 2137 of LNCS, pages 245–257. Springer-
Verlag, April 2001.
[6] O. Berthold, H. Federrath, and S. K¨opsell. Web MIXes:
A system for anonymous and unobservable Internet access.
In H. Federrath, editor, Designing Privacy Enhancing Tech-
nologies, volume 2009 of LNCS, pages 115–129. Springer-
Verlag, July 2000.
[7] A. Blum, D. Song, and S. Venkataraman. Detection of inter-
active stepping stones: Algorithms and conﬁdence bounds.
In Recent Advances in Intrusion Detection: 7th Interna-
tional Symposium, RAID 2004, Sophia Antipolis, France,
September 2004.
[8] R. Bohme, G. Danezis, C. Diaz, S. Kopsell, and A. Pﬁtz-
mann. Mix cascades vs. peer-to-peer: Is one concept su-
perior?
In Privacy Enhancing Technologies (PET 2004),
Toronto, Canada, May 2004.
[9] P. Boucher, A. Shostack, and I. Goldberg. Freedom systems
2.0 architecture. White paper, Zero Knowledge Systems,
Inc., December 2000.
[10] D. Chaum. Untraceable electronic mail, return addresses,
and digital pseudonyms. Communications of the ACM,
24(2):84–88, February 1981.
[11] B. Chun, D. Culler, T. Roscoe, A. Bavier, L. Peterson,
M. Wawrzoniak, and M. Bowman. PlanetLab: An Over-
lay Testbed for Broad-Coverage Services. ACM SIGCOMM
Computer Communication Review, 33(3), July 2003.
[12] R. Clayton, G. Danezis, and M. G. Kuhn. Real world pat-
terns of failure in anonymity systems. In I. S. Moskowitz,
editor, Information Hiding, 4th International Workshop, vol-
ume 2137 of LNCS, pages 230–245. Springer-Verlag, April
2001.
[13] G. Danezis. Statistical disclosure attacks.
In Gritzalis,
Vimercati, Samarati, and Katsikas, editors, Security and Pri-
vacy in the Age of Uncertainty, (SEC2003), pages 421–426,
Athens, May 2003. IFIP TC11, Kluwer.
[14] G. Danezis. The trafﬁc analysis of continuous-time mixes.
In Proceedings of Privacy Enhancing Technologies work-
shop (PET 2004), volume 3424 of LNCS, May 2004.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
[31] I. S. Moskowitz, R. E. Newman, D. P. Crepeau, and A. R.
Miller. Covert channels and anonymizing networks.
In
Workshop on Privacy in the Electronic Society (WPES
2003), Washington, DC, USA, October 2003.
[32] I. S. Moskowitz, R. E. Newman, and P. F. Syverson. Quasi-
anonymous channels. In Communication, Network, and In-
formation Security (CNIS 2003), New York, USA, 10–12
December 2003.
[33] A. Pﬁtzmann, B. Pﬁtzmann, and M. Waidner. ISDN-mixes:
Untraceable communication with very small bandwidth
overhead. In W. Effelsberg, H. W. Meuer, and G. M¨uller, ed-
itors, GI/ITG Conference on Communication in Distributed
Systems, volume 267 of Informatik-Fachberichte, pages
451–463. Springer-Verlag, February 1991.
[34] R Development Core Team. R: A language and environ-
ment for statistical computing. R Foundation for Statistical
Computing, Vienna, Austria, 2004.
ISBN 3-900051-07-0
http://www.R-project.org/.
[35] M. G. Reed, P. F. Syverson, and D. M. Goldschlag. Anony-
mous connections and onion routing. IEEE Journal on Se-
lected Areas in Communications, 16(4):482–494, May 1998.
[36] M. Rennhard and B. Plattner. Introducing MorphMix: Peer-
to-Peer based Anonymous Internet Usage with Collusion
Detection. In Workshop on Privacy in the Electronic Society
(WPES 2002), Washington, DC, USA, November 2002.
[37] G. Rieger et al. socat – multipurpose relay. http://www.
dest-unreach.org/socat/.
[38] A. Serjantov and P. Sewell. Passive attack analysis for
connection-based anonymity systems. In European Sympo-
sium on Research in Computer Security (ESORICS 2003),
Gjovik, Norway, 13–15 October 2003.
[39] P. F. Syverson, G. Tsudik, M. G. Reed, and C. E. Landwehr.
Towards an analysis of onion routing security. In H. Fed-
errath, editor, Designing Privacy Enhancing Technologies,
volume 2009 of LNCS, pages 96–114, Berkeley, CA, USA,
25-26 July 2000. Springer-Verlag.
[40] J. Young and E. M. On obtaining “lawful interception” doc-
uments. http://www.quintessenz.org/etsi.
[41] Y. Zhang and V. Paxson. Detecting stepping stones. In 9th
USENIX Security Symposium, August 2000.
[42] Y. Zhu, X. Fu, B. Graham, R. Bettati, and W. Zhao. On ﬂow
correlation attacks and countermeasures in mix networks. In
Proceedings of Privacy Enhancing Technologies workshop
(PET 2004), volume 3424 of LNCS, May 2004.
[15] G. Danezis, R. Dingledine, and N. Mathewson. Mixminion:
Design of a type III anonymous remailer protocol. In IEEE
Symposium on Security and Privacy, Berkeley, CA, 11-14
May 2003.
[16] W. Difﬁe and M. E. Hellman. New directions in cryp-
IEEE Transactions on Information Theory, IT-
tography.
22(6):644–654, 1976.
[17] R. Dingledine and N. Mathewson.
Tech-
report, The Free Haven Project, October 20
http://www.freehaven.net/tor/cvs/
Tor spec.
nical
2004.
doc/tor-spec.txt.
[18] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
second-generation onion router. In Proceedings of the 13th
USENIX Security Symposium, August 2004.
[19] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter,
P. Leach, and T. Berners-Lee. Hypertext transfer protocol –
HTTP/1.1. RFC 2616, Network Working Group, June 1999.
[20] M. J. Freedman and R. Morris. Tarzan: A peer-to-peer
anonymizing network layer. In V. Atluri, editor, ACM Con-
ference on Computer and Communications Security (CCS
2002), pages 193–206, Washington, DC, November 2002.
ACM.
[21] M. J. Freedman, E. Sit, J. Cates, and R. Morris. Introducing
tarzan, a peer-to-peer anonymizing network layer. In P. Dr-
uschel, M. F. Kaashoek, and A. I. T. Rowstron, editors, In-
ternational workshop on Peer-to-Peer Systems (IPTPS), vol-
ume 2429 of LNCS, pages 121–129, Cambridge, MA, March
2002. Springer-Verlag.
[22] V. D. Gligor. A Guide to Understanding Covert Channel
Analysis of Trusted Systems. National Computer Security
Center, 1993. NCSC-TG-030, Version 1.
[23] I. Goldberg. A Pseudonymous Communications Infrastruc-
ture for the Internet. PhD thesis, UC Berkeley, December
2000.
[24] D. M. Goldschlag, M. G. Reed, and P. F. Syverson. Onion
routing. Communications of the ACM, 42(2):39–41, 1999.
[25] Guirguis, Mina, Bestavros, Azer, and I. Matta. Exploiting
the Transients of Adaptation for RoQ Attacks on Internet
Resources. In Proceedings of ICNP’04: The 12th IEEE In-
ternational Conference on Network Protocols, Berlin, Ger-
many, October 2004.
[26] C. G¨ulc¨u and G. Tsudik. Mixing E-mail with Babel.
In
Network and Distributed Security Symposium — NDSS ’96,
pages 2–16, San Diego, California, February 1996. IEEE.
[27] D. Kesdogan, D. Agrawal, and S. Penz. Limits of anonymity
in open environments. In F. A. P. Petitcolas, editor, Infor-
mation Hiding workshop (IH 2002), volume 2578 of LNCS,
pages 53–69, Noordwijkerhout, The Netherlands, 7-9 Octo-
ber 2002. Springer-Verlag.
[28] B. N. Levine, M. K. Reiter, C. Wang, and M. K. Wright.
Timing attacks in low-latency mix-based systems.
In
A. Juels, editor, Proceedings of Financial Cryptography (FC
’04). Springer-Verlag, LNCS 3110, February 2004.
[29] N. Mathewson and R. Dingledine. Practical trafﬁc analysis:
Extending and resisting statistical disclosure.
In Proceed-
ings of Privacy Enhancing Technologies workshop (PET
2004), LNCS, May 2004.
[30] U. Moeller, L. Cottrell, P. Palfrader, and L. Sassaman. Mix-
master protocol version 2. Technical report, Network Work-
ing Group, May 25 2004. Internet-Draft.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE