of response 
and adversarial 
horizon 
discounted 
cost technique 
reward measure received 
weight to nearer future rewards by recursively 
after a sequence 
actions3. Using the infinite­
[14], EliMet gives more 
high}, 
e.g., {low, medium, 
i.e., {O.25,O.5,O.75} 
adding up the 
which are 
2EliMet can take qualitative 
values. 
In particular, 
Vlt that associates 
optimality 
the unique optimal 
To formulate, 
immediate 
the discounted 
expected 
reward, i.e., security 
measure value Sec(.), and 
policy 1t* that 
with any belief state b E B an optimal action 
game value from then on. 
EliMet computes 
the optimal 
associates 
global reward 
pro­
problem. 
(Equation 
the response 
a value function 
action selection 
maximin 
cedure as a  game-theoretic 
equation 
value function 
be easily derived: 
1t* (b). EliMet formulates 
every policy 1t is assigned 
every belief state b E B with an expected 
Vlt(b) obtained 
(4» characterizes 
by applying 1t in b. Bellman's 
V*, from which an optimal policy 1t* can 
V*(b) = max 'P(V*,b,ar), 
(4) 
where 'P denotes the value function 
'P(V* ,b,a) = 
p(b a) + vY' min [p(b, a ) + vY' V(b, a)]}, (5) 
,  aaEA(bb,a) ' a 
in which b,a denotes the updated next belief state if the 
state is b and action a is taken: 
], 
b,a(s') = [[P(s'ls,a).b(s)
arEA(b) 
action is taken: 
response 
current 
, a 
(6) 
given that a specific 
and the p function 
belief states using security 
levels of individual 
computes security 
measure values for 
states: 
sES 
(7) 
p(b) = [[b(s) ·Sec(s)]. 
V* numerically, 
[5] that applies 
sES 
to calculate 
algorithm 
updates to gradually 
Briefly, 
EliMet uses the value 
iteration 
iterative 
til it converges 
I V; (b) -V; -\ (b) I optimal 
of the value, 
dynamic programming 
improved 
the policy is implicitly 
observable 
process 
value function 
response 
decision 
strategy 
is formulated 
EliMet determines 
is calculated, 
1t* at any given belief state using: 
1t* (b) = arg max 'P(V*, b, ar). 
as well. Once the partially 
and the E-optimal 
the optimal 
(8) 
arEA(b) 
In the rest of this section, 
we discuss 
behavior 
how EliMet makes 
at a subset of states 
responsive 
use of the operator's 
to refine the calculated 
tion IV). The security 
goal is to make sure that the automatically 
measure values Seci(') (Sec­
security 
measure value refinement's  ultimate 
calculated 
policy 1t* (using the refined values and the optimal 
optimal 
response 
action selection 
response 
strategies 
algorithm 
discussed 
above) matches the 
taken by the expert operator. 
C. Passive 
Observation 
later translated 
3 As discussed 
into crisp values, 
expertise 
in Section 
levels who may not always select optimal 
V-C, EliMet can model operators 
response 
with different 
strategies. 
trol problem in which Sec(.) is desired 
given 1t*. In particu­
policy is essentially 
an inverse 
con­
response 
lar, EliMet employs a game-theoretic 
inverse 
reinforcement 
Computation 
the operator's 
of a security 
measure function 
that explains 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:31 UTC from IEEE Xplore.  Restrictions apply. 
Evaluation 
, m, deadline] 
" 
measure 
Similar 
measure 
policy as evi­
security 
function: 
knowledge 
algorithm 
to consider 
that the security 
the operator's 
Distribution 
of the prior security 
values Seci(')' 
P(Sec(s) 
is modeled using the Laplace density 
update the apriori 
2cr 
the probability 
to [31], uncertainty 
learning 
dence, and consequently 
= r) = -e-  \Is E S 
1 1,.-Sec·(s)1 
Algorithm 1: Posterior 
Input: [CMDP, P(TISec), 
P(Sec), 
Output: [P(SecIT)] 
1 List Samples; 
2 Sec lSI xm +- Pick m random security 
3 nlSlxm +- Valuelterat
(9) 
4 while geCtime(
where P( Sec( s) = r) denotes 
5 
measure value for the state s is equal to r. Seci(') is 
6 
7 
8 
cr denotes the 
9 
10 
as well as the above 
11 
distribution 
12 
an attack scenario 
13 
pairs 
15  P( Secl T) +- I sam1
'"  , (Sn,a,l)] that denotes the system 
14  end 
16  Return P(SecIT); 
of CMDP, determination 
17 end 
) :s: deadline 
for every core in parallel 
Sec +- Select  a 
'P +-Recompute 
the 'P functions; 
it +-ValueIteration(CMD
p,Sec); 
x Pft(Tlsec)}. 
a+-min{ 1 P(Sec) 
, P(Sec) Pn(TISec)' 
if RandUniformO 
(p,P(als,sec))) 
I Samples I 
(13) 
Intomot 
ost(28.1.1.1l 
7SIXlNW(101.'1.o.0I16l 
/'  Busn9SSl.Is«lf:2(101.11.0.3) 
Co!poratoRouIOf 
S = -
H( ) 
. 
1 
L.  u p, a s,sec . og 
' Finally, 
IA(s)I'ISamplesl secESamples 
Pft(TISec) 
density Pn(TISec)
<> denotes 
the Kronecker 
the security 
measure 
BuslnossUsor" 01.10.0.3) 
CorporatoSlbNW,l 1.10.0.0116) 
and the ratIO of the proposal 
the subroutine  estimates 
and returns 
posterior  distribution 
delta function. 
(Lines 15-16). 
observation 
results 
in a refined 
The good point is that the more 
are encountered 
and incidents 
during 
Consequently, 
the passive 
measure function. 
security 
common system states 
the passive 
are accurately 
are later used in automated 
response 
system security 
policies 
states. 
observation, 
refined. Therefore, 
and hence their security 
measures 
if the refined measures 
the 
solutions, 
for common 
response 
correctly 
intrusion 
would be selected 
However, accuracy 
level of the measures 
for the whole 
upon the observation 
dependent 
state space is strongly 
phase. In particular, 
and the more states are encountered, 
refined security 
operator's 
impact on the refinement 
measure function 
procedure 
expertise 
phase is 
the longer the observation 
the 
the more accurate 
level could have positive 
or negative 
results. 
will be. Additionally,  the 
Figure 3. Experimental 
Power Network Topology 
D. Active 
Querying 
measures 
for 
sufficient 
infor­
Although 
EliMet also estimates 
the security 
system states indirectly, 
rarely encountered 
mation may not be gained during the passive 
phase for some of the states. 
of an active learning 
highest 
uncertainty 
for the action. 
in order, and explicitly 
EliMet makes use 
to select the states with the 
Therefore, 
algorithm 
query the operator 
observation 
In particular, 
EliMet determines 
the order of the selected 
like in generic 
First, 
settings 
artificial 
[20], the less EliMet knows about a 
state the more chance that state has to be selected. 
information 
states based on two criteria. 
intelligence 
particular 
Second, in addition 
gain, the probability 
also affects its chance of being selected. 
given CMDP's initial 
attack and is usually 
security 
more important 
requires 
measure estimation 
to amount of the expected 
that the system enters a particular 
state 
As  a case in point, 
state So = 0, in which there no ongoing 
than that of the states reaching 
a large number of state transitions. 
the most common system state, 
of its immediate 
neighbors 
accurate 
to which 
is 
For every state selection 
distribution 
iteration, 
P(SecIT) 
EliMet uses the calcu­
as well as the inter-state 
values to choose the most informative 
lated posterior 
distance 
state. 
denotes 
and not individual 
The problem with directly 
the distribution 
over the security 
states (Algorithm 
the issue, we define the f.1 density 
f.1s,a(P)  P(P((s,a)) 
is that it 
and important 
measure functions, 
using P(SecIT) 
1, Line 15). To resolve 
= piT),  (14) 
(11)) 
as follows 
function 
[20]: 
which characterizes distribution 
given the attack scenario 
of the policy (Equation 
for individual 
state-action 
pairs. 
The f.1 function 
during the passive 
observation 
phase: 
1 
f.1s,a(P) = I  I I L <>(p,P((s,a)lsec)), 
(15) 
EliMet uses the f.1 function 
Samp es sec E Samples 
to distinguish 
the Shannon 
policy uncertainties. 
highest 
tainty of individual 
entropy associated 
To quantify 
EliMet measures 
states, 
with the f.1 function: 
H(f.1s,a) = -fa1 f.1s,a(P) log [.us,a (p)]dp.  (16) 
using Equation (13) 
H(s) = lArs)] LaH(f.1s,a) is calculated 
Hence, the mean entropy 
for each individual 
which is denved by few simple replacements. 
EliMet selects 
the best state choice: 
system state 
states with the 
the policy uncer­
Consequently, 
s* = argmax H(s) , 
sES logd(so,s) 
(l7) 
action a* in 
state. 
about the correct 
and queries the operator 
that particular 
account the amount of entropy (uncertainty) 
and distance 
the correct 
between the state and the initial 
EliMet updates the posterior 
As shown, the optimization 
state So. Given 
action, 
takes into 
on the policy, 
P(SecIT, 
(s*, a*)) and continues 
procedure 
by choosing 
the iterative 
the next most suitable 
state selection 
state. 
distribution 
VI. EVALUATIONS 
the accuracy 
We evaluated 
ious components 
experiments. 
of the var­
of EliMet through an extensive 
set of 
An Ubuntu ll.lO computer  system 
with Intel® 
Core™ i7 3.4 GHz Processor and 6 GB of memory was 
and performance 
can be calculated 
using the generated samples 
used for the experiments. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:31 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4. AutomaticaUy 
Generated 
Competitive 
Markov Decision 
Process for the Case Study  Power  Control 
Networks 
Table I 
Host IP Address  Host IP Address 
(IP HOST) MAPPINGS FROM FIGURE 3 TO FIGURE 4 
h2  101.10.0.3 
hi  28.1.1.1 