**LogFiT: Log Anomaly Detection using Fine-Tuned Language Models**

**Authors:**
- Crispin Almodovar¹
- Fariza Sabrina¹
- Sarvnaz Karimi²
- Salahuddin Azad¹

¹Central Queensland University, Australia
²CSIRO Data61, Sydney, Australia

**Contact:**
- {f.sabrina, s.azad}@cqu.edu.au
- sarvnaz.karimi@csiro.au

**Abstract:**
System logs are a critical source of information for monitoring and maintaining the security and stability of computer systems. Deep Learning and Natural Language Processing (NLP) techniques have shown promise in detecting abnormal behavior from these logs. However, existing approaches are often inflexible and impractical. Methods relying on log templates struggle with variability in log content, while classification-based methods require labeled data, which is costly to prepare. This paper introduces LogFiT, a novel log anomaly detection model that is robust to changes in log content and requires only self-supervised training. LogFiT uses a pre-trained BERT-based language model fine-tuned to recognize the linguistic patterns of normal log data. The model is trained using masked token prediction on normal log data. During inference, the model's top-k token prediction accuracy is used as a threshold to determine if new log data deviates from the norm. Experimental results show that LogFiT outperforms baseline models on the HDFS, BGL, and Thunderbird datasets, especially when log data variability is introduced.

**Index Terms:**
- Service monitoring
- Fault management
- Log anomaly detection
- Deep learning
- Natural language processing
- Language modeling

**I. Introduction**
Cybercrime results in billions of dollars in losses annually for businesses [1]–[3]. Log anomaly detection can help protect digital infrastructure by identifying abnormal activities, such as network intrusions, from large volumes of event logs. Recent research has employed Deep Learning and NLP techniques to address this issue. State-of-the-art models, like DeepLog [4] and LogBERT [5], use Long Short-Term Memory (LSTM) and Transformer architectures, respectively. A key challenge is the availability of labeled data for training. Most techniques assume a zero-positive training scenario, where only normal log data is available for self-supervised training [7]. Additionally, self-supervised models for log anomaly detection include forecasting-based and reconstruction-based models [8].

**II. Related Work**
The process of log anomaly detection typically involves four key steps:
1. **Log Data Pre-processing:** Cleaning and standardizing raw system logs.
2. **Vectorisation:** Converting pre-processed log data into numeric vectors.
3. **Model Development:** Selecting the optimal combination of training objective, neural network architecture, and performance metrics.
4. **Model Operationalisation:** Deploying the best-performing model to a production environment and continuously monitoring its performance.

**A. Log Templates**
Log anomaly detection methods often use log parsing to convert log data into standardized log templates [14], [16], [19]. These templates form the vocabulary for the model. For example, DeepLog [4] and LogBERT [5] use the Drain parser [20] to generate log templates. However, this approach can be semantically deficient and unable to handle variability in log content over time [6], [11], [12].

**B. Semantic Vectorisation**
Recent studies suggest that log parsing may reduce accuracy and should not be recommended [11], [17]. Instead, semantic vectorisation, which enriches log data with semantic information, has been proposed to improve accuracy [11], [17].

**C. Pre-trained Language Models**
There is growing interest in using pre-trained language models (LMs) like BERT [21] for log anomaly detection. Studies by Ott et al. [10] and Le and Zhang [11] show that pre-trained LMs capture contextual information at the sequence level, unlike word embeddings used in models like LogRobust [17]. BERT generates context-sensitive semantic vectors that encode the order of words and can handle out-of-vocabulary words.

**III. Methodology**
This section outlines the methodology for developing and evaluating the LogFiT model.

**A. Model Architecture**
LogFiT utilizes a pre-trained BERT-based LM fine-tuned to understand the linguistic and sequential patterns of normal log data. The model can handle log sequences of up to 4096 tokens, ensuring robustness to changes in log content.

**B. Training and Inference**
During training, LogFiT is trained on normal log data using masked token prediction to minimize cross-entropy loss. At inference, the model's top-k token prediction accuracy is compared against a predefined threshold to determine if new log data is anomalous.

**C. Experimental Setup**
Experiments were conducted on three datasets: HDFS, BGL, and Thunderbird. LogFiT was compared to baseline models, DeepLog and LogBERT, in terms of precision, recall, F1 score, and specificity.

**IV. Results and Discussion**
Experimental results demonstrate that LogFiT outperforms baseline models, particularly when log data variability is introduced. The F1 scores for LogFiT exceed those of the baselines on all three datasets, highlighting its effectiveness in detecting anomalous log sequences.

**V. Conclusion**
LogFiT is a robust and effective log anomaly detection model that leverages a fine-tuned BERT-based LM. It requires only self-supervised training and can handle changes in log content. The model's superior performance on benchmark datasets makes it a promising solution for real-world applications.

**References:**
[1] - [21] (List of references provided in the original document)

**Figure 1.** HDFS log sentences converted to log templates.

**Figure 2.** Comparison of the DeepLog and LogBERT log anomaly detection methods.