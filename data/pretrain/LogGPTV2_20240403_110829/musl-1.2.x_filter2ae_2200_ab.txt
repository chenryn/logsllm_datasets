      idx = 0;
      goto success;
     }
     //先从ctx中找meta
     sc = size_to_class(n); //计算size类别
     rdlock();      //对malloc上锁
     g = ctx.active[sc];    //根据size类别找到对应的meta
     // use coarse size classes initially when there are not yet
     // any groups of desired size. this allows counts of 2 or 3
     // to be allocated at first rather than having to start with
     // 7 or 5, the min counts for even size classes.
     /*
      当没有任何合适的size的group时使用更粗粒度的size classes
     */
     //对应meta为空 AND 4= 4 && sc avail_mask && !ctx.active[sc | 1]->freed_mask))
       usage += 3;
      if (usage avail_mask : 0; //meta中的可用内存的bitmap, 如果g为0那么就设为0, 表示没有可用chunk
      first = mask & -mask;    //一个小技巧, 作用是找到mask的bit中第一个为1的bit
      if (!first)       //如果没找到就停止
       break;
      //设置avail_mask中first对应的bit为0
      if (RDLOCK_IS_EXCLUSIVE || !MT) //如果是排它锁, 那么下面保证成功
       g->avail_mask = mask - first;
      else if (a_cas(&g->avail_mask, mask, mask - first) != mask) //如果是cas原子操作则需要for(;;)来自旋
       continue;
      //成功找到并设置avail_mask之后转为idx, 结束
      idx = a_ctz_32(first);
      goto success;
     }
     upgradelock();
     /*
      - 如果这个group没法满足, 那就尝试从别的地方获取: 
       - 使用group中被free的chunk
       - 使用队列中别的group
       - 分配一个group
     */
     idx = alloc_slot(sc, n);
     if (idx avail_mask--;
     queue(&ctx.active[sc], g); //新分配的g入队
     return 0;
    }
  * try_avail() 
    * 首先会再次尝试从avail_mask分配
    * 然后查看这个meta中freed_mask中有无chunk,
    * 如果freed_mask为空, 说明这个meta全部分配出去了, 就从队列中取出
    * 如果有的话就会通过active_group()把freed_mask中的chunk转移到avail_mask中
    static uint32_t try_avail(struct meta **pm)
    {
     struct meta *m = *pm;
     uint32_t first;
     if (!m) //如果ctx.active[sc]==NULL, 那么就无法尝试使用avail
      return 0;
     uint32_t mask = m->avail_mask;
     if (!mask) //如果avail中没有可用的, 有可能其他线程释放了chunk
     {
      if (!m) //同上
       return 0;
      if (!m->freed_mask) //如果freed_mask也为空
      {
       dequeue(pm, m); //那么就从队列中弹出
       m = *pm;
       if (!m)
        return 0;
      }
      else
      {
       m = m->next; //否则pm使用m的下一个作为队列开头, 应该是为了每次malloc与free的时间均衡
       *pm = m;
      }
      mask = m->freed_mask; //看一下group中被free的chunk
      // skip fully-free group unless it's the only one
      // or it's a permanently non-freeable group
      //如果这个group所有的chunk都被释放了, 那么就尝试使用下一个group, 应该是为了每次malloc与free的时间均衡
      if (mask == (2u last_idx) - 1 && m->freeable)
      {
       m = m->next;
       *pm = m;
       mask = m->freed_mask;
      }
      //((2u mem->active_idx) - 1)建立一个掩码, 如果acctive_idx为3, 那么就是0b1111
      if (!(mask & ((2u mem->active_idx) - 1))) //如果这个group中有free的chunk, 但是不满足avtive_idx的要求
      {
       //如果meta后面还有meta, 那么就切换到后一个meta, 由于avail与free都为0的group已经在上一步出队了, 因此后一个group一定有满足要求的chunk
       if (m->next != m)
       {
        m = m->next;
        *pm = m;
       }
       else
       {
        int cnt = m->mem->active_idx + 2;
        int size = size_classes[m->sizeclass] * UNIT;
        int span = UNIT + size * cnt;
        // activate up to next 4k boundary
        while ((span ^ (span + size - 1))  m->last_idx + 1)
         cnt = m->last_idx + 1;
        m->mem->active_idx = cnt - 1;
       }
      }
      mask = activate_group(m);  //激活这个group, 把free的chunk转移到avail中,其实就是交换下bitmap的事
      assert(mask);     //由于group中freed_mask非空, 因此一定会找到可用的chunk, 所以返回的avail_mask一定非0
      decay_bounces(m->sizeclass); //?
     }
     //经过上面的操作, 已经使得m的group中有可用的mask, 因此取出就好
     first = mask & -mask;
     m->avail_mask = mask - first;
     return first;
    }
  * alloc_group() 
    * 首先会通过alloc_meta()分配一个meta, 用来管理后面分配的group
    * 计算好需要的长度后通过mmap()匿名映射一片内存作为group
    * 然后初始化meta中相关信息
    //新分配一个size_class为sc的group
    static struct meta *alloc_group(int sc, size_t req)
    {
     size_t size = UNIT * size_classes[sc]; //大小
     int i = 0, cnt;
     unsigned char *p;
     struct meta *m = alloc_meta(); //分配group前先分配一个meta用来管理group
     if (!m)
      return 0;
     size_t usage = ctx.usage_by_class[sc];
     size_t pagesize = PGSZ;
     int active_idx;
     if (sc  usage)
       i++;
      cnt = small_cnt_tab[sc][i];
     }
     else
     {
      ...
     }
     // If we selected a count of 1 above but it's not sufficient to use
     // mmap, increase to 2. Then it might be; if not it will nest.
     if (cnt == 1 && size * cnt + UNIT  pagesize / 2)
     {
      // check/update bounce counter to start/increase retention
      // of freed maps, and inhibit use of low-count, odd-size
      // small mappings and single-slot groups if activated.
      int nosmall = is_bouncing(sc);
      account_bounce(sc);
      step_seq();
      // since the following count reduction opportunities have
      // an absolute memory usage cost, don't overdo them. count
      // coarse usage as part of usage.
      if (!(sc & 1) && sc  usage && !nosmall)
      {
       ...
      }
      size_t needed = size * cnt + UNIT;
      needed += -needed & (pagesize - 1);
      // produce an individually-mmapped allocation if usage is low,
      // bounce counter hasn't triggered, and either it saves memory
      // or it avoids eagar slot allocation without wasting too much.
      if (!nosmall && cnt = 4 * pagesize && 2 * cnt > usage))
       {
        cnt = 1;
        needed = req;
       }
      }
      //映射一片内存作为group, 被一开始分配的meta管理
      p = mmap(0, needed, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);
      if (p == MAP_FAILED)
      {
       free_meta(m);
       return 0;
      }
      m->maplen = needed >> 12;
      ctx.mmap_counter++;
      active_idx = (4096 - UNIT) / size - 1;
      if (active_idx > cnt - 1)
       active_idx = cnt - 1;
      if (active_idx maplen = 0;
      p[-3] = (p[-3] & 31) | (6 avail_mask = (2u freed_mask = (2u avail_mask;
     m->mem = (void *)p;
     m->mem->meta = m;
     m->mem->active_idx = active_idx;
     m->last_idx = cnt - 1;
     m->freeable = 1;
     m->sizeclass = sc;