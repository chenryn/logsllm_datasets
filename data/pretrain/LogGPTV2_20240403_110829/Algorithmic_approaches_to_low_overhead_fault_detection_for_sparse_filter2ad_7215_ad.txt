# F-Score Targets and Performance Overheads

## F-Score Targets
- 0.5
- 0.75
- 0.9

## Detection Techniques
- IC (Inclusion Check)
- NC (No Check)
- NCAC (No Check, Accuracy Control)
- NCAR (No Check, Accuracy Rate)
- ICAC (Inclusion Check, Accuracy Control)
- ICAR (Inclusion Check, Accuracy Rate)

## Figures and Analysis

### Figure 11: Performance Overheads
**Performance overheads with varying:**
- **F-Score targets (left)**
- **Fault Models (center)**
- **Fault Rates (right)**

#### Varying F-Score (faultRate=1e−3, faultModel=1)
- Dense Oracle D-Tree
- Performance Overhead: 35%, 30%, 25%, 20%, 15%

#### Varying Fault Model (faultRate=1e−3, fscore>0.9)
- Dense Oracle D-Tree
- Performance Overhead: 30%, 25%, 20%, 15%, 10%, 5%, 0%

#### Varying Fault Rate (fscore>0.9, faultModel=1)
- Dense Oracle D-Tree
- Performance Overhead: 80%, 60%, 40%, 20%

### Figure 12: Success Rate
**The success rate or frequency at which problems meet the given F-Score target with varying:**
- **F-Score targets (left)**
- **Fault Models (center)**
- **Fault Rates (right)**

### Results and Observations
- **No benefit with preconditioning (2x):** Of the 5 problems solved successfully with CG-pre, only 1 met the accuracy target with IR-pre.
- **Linear Solvers:** Dense checks can have large performance overheads (30-50%).
  - **CG:** Sparse check-based implementation spent 17% less time in MVM operations, resulting in a 9% lower total execution time.
  - **IR:** Sparse check-based implementation spent 10% less time in MVM operations, resulting in a 5% lower total execution time.

- **Larger Setup Overheads:** The impact of larger setup overheads for techniques like clustering and preconditioning is negligible (< 0.01%) due to high reuse.
- **Error Rate Impact:** The error rate affects the number of iterations and the amount of reuse within the algorithm.
- **Sparse Techniques:** By minimizing overhead from missed faults and false positives, the runtime benefits for many sparse techniques are reduced to < 5%.

### Figure 13: Performance Across Different Error Rates
- **Zero Fault Rate:** The impact of recovery overheads is reduced, allowing better utilization of sparse fault detection techniques.
- **Increasing Error Rate:** Detection accuracy requirements become more stringent, and the total overhead from missed faults and false positives must be balanced.
- **Large Error Rate:** Recovery overheads are reduced, allowing sparse techniques to further reduce runtime and total overheads.

### Figure 14: Preconditioning Benefits
- **CG-pre:** Total benefits from sparse checks were small (5%-10%).
- **IR-pre:** Sparse check-based implementations spent 30%-40% less time overall than dense check-based implementations.
- **CG, IR, CG-pre, IR-pre:** These demonstrate that sparse techniques can exploit structure and reuse in sparse problems to reduce overall overhead compared to traditional dense checks.

## Conclusions
Future Exascale computing systems will be prone to errors and energy constraints. Low overhead fault detection for sparse linear algebra algorithms is crucial. Proposed techniques minimize overhead by up to 2x over traditional dense checks while maintaining high error detection accuracy. Experiments show benefits up to 40% in MVM operations and up to 20% in non-MVM operations.

## Acknowledgments
This research was supported by the FCRP Gigascale Systems Research Center (GSRC), Semiconductor Research Corporation, and the National Science Foundation. Part of this work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344 (LLNL-CONF-546472) and partially supported by the Department of Energy Office of Science (Advanced Scientific Computing Research) Early Career Grant, award number NA27344.

## References
[References listed as provided, with minor formatting adjustments for clarity]