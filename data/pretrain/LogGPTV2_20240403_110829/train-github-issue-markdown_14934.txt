When constructing validation or learning curves, repeatedly fitting a model can be computationally expensive, while evaluating the scorer is typically much faster. It would be beneficial to evaluate multiple scorers in a single pass. Specifically, it would be useful if the `sklearn.model_selection.learning_curve` and `sklearn.model_selection.validation_curve` functions could accept a list of scorers as an argument, such as `scoring=[scorer1, scorer2, scorer3, ...]`.

As a workaround, I am considering whether my custom scorer can return a float along with additional information, such as extra properties or even confusion matrices. However, I am relatively new to Python and unsure if this is feasible or straightforward. This approach seems unnecessarily complex.

The `learning_curve` and `validation_curve` functions are particularly relevant to my use case. I am not aware of other methods that might benefit from this enhancement.

Would it be feasible to expand the scoring functionality to accept a list of scorers?