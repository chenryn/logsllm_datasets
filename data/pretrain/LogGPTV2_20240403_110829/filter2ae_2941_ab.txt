‘的二度分布是来自同一分布还是来自单个分布。我们首先估计幂律分布p (x)∝x−α的标度参数α(等价于G
‘)。虽然在离散数据的情况下没有精确的和封闭的解来估计α，但是可以导出一个近似表达式，在这里我们将图G转换为
其中dmin表示幂律测试中一个节点所需的最小度
DG则是一个多重集，包括了节点度的列表，其中dvG是G的节点v的度。通过这种方法就可以估计了。
给定尺度参数αx，对样本的对数似然性Dx可以很容易地计算为
利用这些对数似然分数，我们建立了显著性检验，估计两个样本DG(0)和DG
‘是否来自相同的幂律分布(原假设H0)，而不是单独的幂律分布(H1)。也就是说，我们提出了两个相互竞争的假设
经过似然比检验后，最终的检验统计量为
拒绝原假设H0的典型p值(即两个样本都来自不同的分布)是0.05，即在统计学上，在20个案例中，我们拒绝原假设，尽管它成立(第一类错误)。虽然在我们的例子中，我们不能很容易地计算第二类误差，但一般来说，第一类和第二类误差概率呈反比关系。因此，通过选择一个非常保守的对应于高类型I错误的p值，我们可以减少类型II错误的概率。因此，我们将临界p值设为0.95，也就是说，如果我们从相同的幂律分布中抽样二度序列，我们将在95%的情况下拒绝零假设，然后可以根据最初的怀疑来调查数据是否已经受损。另一方面，如果我们修改的图的度序列通过了这个非常保守的检验，我们可以得出这样的结论:度分布的变化是不明显的。
使用χ2分布中的上述p值，我们只接受度分布满足的扰动G’=(A’,X’)，其中度的分布满足
**保持特征统计量的扰动**
由于设计基于共现的统计检验需要对特征上的联合分布进行建模，这对于相关多元二进制数据来说是难以处理的，因此我们将其称为确定性检验。在这方面，将特性设置为0是不重要的，因为它不会引入新的共现。问题是:什么样的特征会被认为是不值得注意的?
为了回答这个问题，我们在来自G(0)的特征的共发生图C=(F,E)上考虑一个概率随机漫步者，其中F是特征的集合，E⊆F ×
F表示到目前为止哪些特征同时出现。我们认为，如果从节点u最初呈现的特征开始的随机步行者到达特征i的概率非常大，那么添加特征i是不明显的。形式上，设
是节点u表现出来的特征集合。我们认为如果满足下式，则表明将特征i加到节点u上是不会被注意到的
其中，dj表示共现图C的度。
也就是说,假设概率步行者从任意特征j∈Su开始，在执行一个步骤之后，它将以概率σ达到我特征i。在我们的实验中，我们简单地选择σ为最大可达概率的一半，即
如果满足上述原则，实际上就会有这两个效果:第一，特征i与u的许多特征(即在其他节点上)同时出现的概率高;当它们被添加时，就不那么明显了。第二，特征i仅与特征j∈Su同时出现，而不是特定于节点u(例如，特征j几乎与所有其他特征同时出现)有低概率;加上“i”将会引人注目。因此，实现了添加特征却不被注意的效果。  
使用上述测试，我们只在特征值满足下式时才接收扰动G’
## 生成对抗图
我们使用一种顺序方法，首先攻击代理模型，从而获得被攻击的图。这个图随后被用来训练最终的模型。实际上，这种方法可以直接被视为可迁移性的检查，因为我们并不特别关注使用的模型，而是只关注代理模型。
为了获得一个易于处理的代理模型，却仍然应用到图卷积的思想，我们对模型进行线性化，用一个简单的线性激活函数代替非线性σ(.)，得到
由于W(1)和W(2)是需要学习的参数，因此可以将它们合为单个矩阵W∈RD ×K。
由于我们的目标是最大化目标v0的对数似然的差异(给定一个特定的budget∆)，因此可以忽略由softmax引起的与实例相关的归一化。因此，对数概率可以简单地简化为Aˆ2
XW。因此，如果训练的代理模型(未损坏)输入了带有学习参数W的数据，我们定义了代理损失
并尝试求解
这个问题虽然简单得多，但由于离散域和约束，仍然难以解决。因此，我们使用一个可扩展的贪婪近似方案。为此，我们定义了评分函数来评估从添加/删除一个特征f
=(u,i)或者edgee=(u,v)到任意graphg =(a,X)所得到的额外损失:
近似解的方案伪码如下
**复杂度分析**
候选集的生成(即哪些边/特征允许改变)和score function可以递增计算，并利用图的稀疏性，从而确保可伸缩性。算法的运行时复杂度可以很容易地计算如下
其中thv0表示节点v0在算法运行过程中2-hop邻居的大小。
在每个∆次迭代中，每个攻击者评估潜在的边扰动(最多N)和特征扰动(最多D).对于前者，由于有两个卷积层，需要更新目标的2-hop邻域。假设图是稀疏的，thv0远小于N。每个特征在恒定的时间内进行特征扰动。因为所有的约束都可以在常数时间内检查，所以它们不会影响复杂度。
## 复现及分析
###  分析
先来看看攻击所需的运行时间，根据前面分析的复杂度，在下图中，我们可以看到，我们的算法与图结构的扰动数和考虑的影响节点的数量线性相关。
接下来我们评估两种攻击类型的Nettack的性能:分别是规避攻击和投毒攻击。在下图中，每个点代表一个目标节点。
正如我们所见，直接攻击是非常成功的——即使是在这个棘手的投毒攻击中，几乎每个目标都被错误分类了。而间接的攻击(显示在双线右侧)更加困难。接下来看看在GCN和CLN上的攻击效果
可以看到，不论是哪种情况，我们发现直接攻击比间接攻击更困难。在这些方案中，我们也比较了两种基线Rnd和FGSM，如图所示，Nettack的表现优于两者。
在下表中我们总结了不同数据集和分类模型的结果。
这里给出的是正确分类的目标节点的比例。在我们评估的所有数据集上，邻模型上的对抗扰动都是可迁移到所有三个模型上的。我们看到FGSM的性能比Nettack差，原因之前已经说过的，因为梯度方法对离散数据不是最优的。下图显示了这种情况的原因:当改变A中的元素时，我们绘制了梯度与损失的实际变化之间的关系
通常梯度不能很好地接近损失。而Nettack的一个关键优势是，我们可以精确和有效地计算出ls的变化。
在之前的实验中，我们假设攻击者知道输入图的全部知识，这是假设最强的情况。接下来我们分析在知识有限的情况下的结果:给定一个目标节点v0，我们只提供相对于Cora图的大小增加的子图。我们通过选择距离v0越来越远的节点来构造这些子图，即我们首先选择1跳邻居，然后选择2跳邻居，以此类推，直到我们达到所需的图大小。然后对子图进行扰动。然后，这些扰动被迁移到我们训练GCN的全图中。下图是绘制了攻击者只有关于数据的有限知识的情况下的攻击效果
上图比较了直接攻击和间接攻击。在直接攻击中可以看到，即使只观察到图的10%，仍然可以显著地攻击它。如果攻击者知道整个图，则需要的扰动次数最少。在间接攻击中，我们注意到需要更多的扰动和75%的图大小，攻击才能成功。尽管如此，这个实验攻击者并不需要掌握全部的数据的知识就可以成功发动攻击
###  复现
首先确定后要目标节点，同时训练代理模型
初始化相关参数，这里比较重要的就是扰动次数
开始投毒
我们这里扰动的是特征，可以将其打印出来
接下来我们分别在有扰动和没有扰动的情况下训练GCN
这是没有扰动的
这是有扰动的
然后可以分别将可视化的结果打印出来
可以看到攻击生效了
## 参考
1.
2.图神经网络前沿进展与应用
3.Adversarial Attacks on Neural Networks for Graph Data