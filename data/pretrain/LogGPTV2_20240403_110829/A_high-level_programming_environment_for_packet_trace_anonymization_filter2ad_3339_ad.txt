(arguments of USER/ACCT commands)
User
are
anonymized except
and “ftp”.
However, the anonymizer leaves a user ID in the clear if the login
attempt fails and the user ID is one of the IDs deﬁned as sensitive
in Bro’s default security policy (for example, “backdoor”,
“bomb”, “issadmin”, “netphrack”, “r00t”, “sync”,
“y0uar3ownd”, and many others). This allows us to preserve
one form of attack, namely attempted backdoor access, without
exposing any actual account information.
When we anonymize a user ID, we apply HMAC-MD5, anno-
tating the user ID prior to hashing with 1) the server IP to prevent
“shared-text” matching, and 2) an indication of whether the login
was successful to prevent “known-text” matching.
Password: we replace the arguments of PASS commands with the
string “”.
(An alternative would be to hash pass-
words for anonymous logins, with the email addresses annotated
with the client IP address to achieve “knowledge separation”.)
File/directory names: are replaced by the string “” for
non-anonymous logins. For anonymous logins, ﬁle names are left
in the clear if they appear on a white list of well-known sensitive ﬁle
names (e.g., “/etc/passwd”), in order to preserve occurrences
of attacks; and anonymized with hashing otherwise. The hashing
input is the absolute path annotated with the server IP to minimize
shared-text matching across directories or servers. The reason to
anonymize ﬁle names even for anonymous FTP trafﬁc is that we
cannot readily tell truly public ﬁles apart from private (hidden) ones
that happen to be access using anonymous FTP, but only by users
who know the otherwise unpublicized location of the ﬁle.
Arguments of commands with pre-deﬁned argument sets:
(TYPE, STRU, MODE, ALLO, REST, MACB): are left intact if
well-formed. For example, a TYPE argument should match the
regular expression /([AE]( [NTC])?)|I|(L[0-9]+)/ ac-
cording to RFC 959. However, the anonymizer does not assume
clients follow the RFC—it checks whether the argument matches
the pattern, and leaves it in the clear only if that is the case, other-
wise anonymizing the argument as a string.
We apply similar techniques for the “HELP” and “SITE” com-
mands, for which we only expose the arguments if they match a
manually determined “white list” of privacy-safe HELP/SITE ar-
guments.
Unrecognized commands: are anonymized along with their argu-
ments and recorded for optional manual inspection.
Timestamps/dates: are left in the clear. While timestamps could
help an adversary match up known trafﬁc (such as trafﬁc they in-
jected) with its occurrence in the trace, there are enough other ways
the adversary can perform such matching (by making the injected
trafﬁc singular) that leaving them intact costs little. On the other
hand, timestamps are valuable for various research purposes.
File sizes: are considered to be safe. As argued when analyzing ﬁn-
gerprinting, exposing ﬁle sizes may allow the adversary to identify
public ﬁles. But this is not a concern for LBNL.
Server software version/conﬁguration: is also considered to be
safe, as the information that can be inferred from the trace can be
readily obtained through other means (since the servers are public).
4.4.3 Reﬁning with Manual Inspection
Whether data is to be left in the clear or anonymized, the anony-
mous script logs the decision and the reason for later inspection.4
Identical entries are only logged once. Inspection of the log (with
various text processing tools) helps us to discover 1) privacy holes
(or to demonstrate the absence of holes), and also 2) overly con-
servative anonymization of nonsensitive information (important for
working towards more reﬁned scripts). We discuss log inspection
techniques in detail below.
A “ﬁlter-in”-style script always makes conservative judgments
on unknown data. Sometimes it can be too conservative, miss-
ing an opportunity to expose interesting, nonsensitive data, e.g., a
mistyped command like “UUSER” or a user id like “annonymous”.
It is difﬁcult to hardwire such commands and user names into the
general anonymization script, as they may appear in unpredictable
forms. Nevertheless, these special cases do not appear very often in
traces, so we can afford to manually inspect each case by looking
at the log after anonymization and then customizing the script to
expose the nonsensitive ones. Figure 4 shows three log entries we
have seen: the ﬁrst entry records a common-case anonymization of
a path name; while the other two, recording anonymizations of the
“UUSER” command and user name “annonymous”, are the kinds
of entries we look for during manual inspection.
Note that the customization for special cases should be optional.
The script should always ﬁrst anonymize any unknown data, and
should make no assumptions about whether the log will be manu-
ally inspected.
As most entries in the anonymization log record the anonymi-
zation of “common” cases, the trick to digging up special cases
is to look for deviant entries through text classiﬁcation. Here, we
examine command arguments as an example to illustrate how we
discover special cases:
First, we classify entries by the type of data being anonymized.
The type can be, for example, a non-guest user name (e.g.,
4Here we assume that the administrator of the trace anonymization can
see the original trace—this helps in verifying results and generating better
traces.
“annonymous”), or a non-public ﬁle name, or the argument of
a PORT command. Some types of anonymization, e.g., of path
names and passwords, happen very often, while others rarely ap-
pear in the log. These rare types of anonymization often present
interesting cases. For example, for a trace of an FTP server that
only allows anonymous login, there can still be a few user names
being anonymized. We have seen: “anno”, “anonyo\010”,
“anonymouse”, “help”, and “anamouse”, as well as a pass-
word mistyped for a USER command. Except for the password, all
of the other user names actually do not reveal any private informa-
tion. But it’s important to catch the password. Note that none of
these strange user names will appear in the output trace unless we
modify the script to explicitly allow them, so the password will not
appear without speciﬁc action to keep it.
Furthermore, we look for “malformed” path names—those
do not match a heuristic pattern for well-formed path names.
We ﬁnd, for example: “#”, “\xd0\xc2\xce\xc4\xbc\xfe
\xbc\xd0”, “/n/nThis file was not retrieved by
Tele-port Pro, because it did not meet the
project”. 5
In addition, applying similar techniques lets us ﬁnd misspelled
e.g.,
commands, or commands containing control characters:
“USE”, “UUSER”, “RETR”, all of which
we have seen in practice (these commands likely indicate users typ-
ing directly rather than using client software).
4.4.4 Reply Anonymization
An FTP reply consists of a reply code and a text message. We
leave reply codes in the clear, as they do not reveal any private
information. Reply messages, on the other hand, do often contain
sensitive information and are hard to anonymize because there is
no standard format for most reply messages—the format depends
on the server implementation and its conﬁguration.
One possibility is to discard the original text (except for replies
to PASV, which are well-deﬁned) and replace it with a dummy mes-
sage. This has the virtue of being simple. On the other hand, re-
ply messages do sometimes carry useful information that cannot be
inferred from the reply codes. For example, a reply of code 530
(denial of login) usually explains why the login was rejected–it can
be “guest login not permitted” or “Sorry, the maximum number of
users from your host are already connected.”. Such information can
be valuable in some cases. So we explored methods to anonymize
FTP replies.
As messages may contain variables such as ﬁle names/sizes,
dates, and domain names, there can be countless distinct messages.
However, we observe that there is only a limited set of message
templates, as the number of templates is bounded by the number of
different server software/conﬁgurations at the site. And we can ex-
tract templates (along with human assistance) by comparing mes-
sages against each other and distilling the common parts. Figure 5
shows a few example message templates. Once we have extracted
the message templates, we can parse messages by matching them
against the templates and thereby understanding the semantics of
the data elements in the text.
Message templates are ﬁrst automatically extracted by a script
then manually sanitized before used for template matching. The
automated template extraction is done in three steps: splitting, ab-
straction, and merging (as shown in Figure 6). We ﬁrst split a mes-
sage into parts—each part contains a word or a data element such as
an IP address or a ﬁle name. Next, in abstraction, we try to guess
whether each part is a variable or a constant part of the message
template. Through abstraction we are able to ﬁnd most of variable
5Teleport Pro is the name of an ofﬂine browser.
anonymize_arg: (path name) [CWD] "conferencing" to "U42117b96U" in [xxx.xxx.xxx.xxx/xxxx > xxx.xxx.xxx.xxx/ftp]
anonymize_cmd: (unrecognized command) "UUSER" [anonymous] to "U7b402a69U" in [xxx.xxx.xxx.xxx/xxxx > xxx.xxx.xxx.xxx/ftp]
anonymize_arg: (user name) [USER] "annonymous" to "Ufb6db9afU" in [xxx.xxx.xxx.xxx/xxxx > xxx.xxx.xxx.xxx/ftp]
Figure 4: Anonymization Log Entries
150 |opening| |ascii, binary| |mode| |data| |connection| |for| |˜ arg| |˜ ip| |˜ num| |˜ num| |bytes|
211 |connected| |to| |˜ domain, ˜ ip|
220 |welcome| |to| |˜ *| |ftp| |server|
550 |˜ arg| |not| |a| |directory|
Figure 5: FTP Reply Message Templates
slots in message templates, and merging helps to reveal the rest of
them. We merge two templates when they are identical on all but
one part, and this process is iterated till no templates can be further
merged.
The message extraction process is reﬁned through the accumu-
lation of experience. We found that the key issue in abstraction is
to recognize the corresponding command argument echoed in the
reply message. This is tricky because the echoed argument is some-
times different from the original argument, particularly when it is
a ﬁle name. For example, the echoed argument can be the absolute
ﬁle path or only contain the base ﬁle name with the directory parts.
Therefore we need to recognize variants of the argument. The key
for good message splitting is to know where not to split. By default
we split at spaces and punctuation; however, we do not want to split
an IP address or a ﬁle name, otherwise they cannot be recognized
during abstraction.
Extracted message templates need to be examined and sanitized
before being used for message matching. This can be a tedious
process and we strived to minimize the required effort. Currently,
when extracting templates from a set of ten-day long FTP traces,
which contain more than 1.4 M lines of replies in 22.6 K connec-
tions to 318 distinct servers, we wound up with 461 message tem-
plates for 32 kinds of reply codes. Among the 461 templates, 25
require sanitization to remove server identity information. Exam-
ining a few hundreds of templates is feasible but still not easy—
perhaps this is the price for processing free format text.
4.4.5 Veriﬁcation
Veriﬁcation is a fundamental step of the anonymization process.
No matter how much thought we apply to the anonymization policy,
the safety of the anonymization also depends on the correctness of
the policy script and on the underlying Bro mechanisms. Therefore,
besides inspecting the anonymization description and script, it is
also important to examine the output trace directly.
Ideally, the veriﬁcation process would guarantee that the trans-
formed trace complies with the intended anonymization policy.
This is a different notion that the expressed anonymization policy,
due to the possiblity of errors occurring in coding up the expres-
sion. Our strategy therefore is to attempt to analyze the general
properties of the transformed trace without tying these too closely
to the anonymization script that was used to effect the transfor-
mation. As such, we cannot guarantee that there are no “hole” in
the anonymized trace (but indeed doing so appears fundamentally
intractable). Instead, we aim to provide another dimension of pre-
caution.
In general, it is particularly important to have a strong
“veriﬁcation story” in order to persuade sites that the anonymiza-
tion process will meet their requirements.
For veriﬁcation we do not use Bro to parse the output trace’s
packets—doing so would introduce a common point of failure
across anonymization and veriﬁcation.
Instead, we look at the
packets directly, using different tools. Automating the veriﬁcation
process remains an open problem—currently, it requires human as-
sistance, although some of the steps can be automated to reduce the
burden.
For packet headers, we inspect the source and destination IP ad-
dresses. As the anonymized addresses are sequentially numbered,
veriﬁcation that these lie in the expected range can be performed
automatically.
For FTP requests in packet payloads, we enumerate all distinct
commands and arguments present in the trace, except those which
are already hashed (hash results follows a particular textual format
and thus can automatically excluded). When the text parts of re-
ply messages are discarded, it is straightforward to verify that FTP
replies only contain reply codes and a placeholder of dummy text.
When we choose to anonymize reply messages, veriﬁcation con-
sists of two parts, checking vocabulary and numbers, respectively.
Vocabulary checking is similar to message template extraction, but
simpler and implemented separately. Messages are again split at
blanks and punctuation, this time without worrying about special
cases as in splitting for message template extraction. Next we ab-
stract the parts by two rules: 1) if a part is a decimal number, sub-
stitute it with the string “”; 2) if a part is a hashing output,
substitute it with the string “”. This way we can reduce
1.4 M anonymized messages to about 600 patterns. We then man-
ually inspect these, which can be expedited by ﬁrst sorting them so
that similar patterns are clustered.
In checking numbers we are mainly concerned about numbers
constituting IP addresses. Accordingly, we look for any four con-
secutive number parts in split messages and record each instance
that does not fall within the range of anonymized addresses. In-
terestingly, such cases do appear, though they are quite rare, and
safe—e.g., part of a software version string such as “wu-2.6.2(1)”.
Veriﬁcation helped us ﬁnd a potential hole in an earlier version
of our anonymization script. We found two suspicious command
arguments: “GSSAPI” and “KERBEROS_V4”. Though the strings
themselves do not disclose any private information, their appear-
ance is alarming because they are not deﬁned anywhere to be “safe”
in the script.
Looking into the logs revealed that they were arguments for two
rejected “AUTH” commands. According to RFC 2228, the argu-
ment for the “AUTH” command speciﬁes the authentication mech-
anism. Thus, a rejected mechanism seems safe to expose. How-
ever, doing so overlooks the possibility that a user might mistak-
enly specify sensitive information, such as a password, instead of
an authentication mechanism. A “fail-safe” solution is to white list
“GSSAPI” and “KERBEROS_V4” and anonymize any unknown