### OneHot is Strongly Stackable

#### Procedure:
- **Input:** Parties input shared bitstrings \(\langle a \rangle, \langle b \rangle\) where \(a \in \{0, 1\}^n\) and \(b \in \{0, 1\}^m\).
- **Output:** Parties output a shared matrix \(\langle a \otimes b \rangle\).

**Steps:**
1. **Color Gates:** Parties release \(\langle a \oplus \alpha \rangle\) and \(\langle b \oplus \beta \rangle\) to \(E\) for uniform \(\alpha \in \{0, 1\}^n\) and \(\beta \in \{0, 1\}^m\). The Color gates ensure that the outputs are indistinguishable from uniform random values.
2. **Chunking:** Parties agree on a "chunk size" \(k\) which is at most logarithmic in the overall circuit input size. The input vectors are split into \(\lceil n/k \rceil\) \(k\)-bit subvectors to avoid expensive exponential scaling.
3. **One-Hot Gate Computation:**
   - For each \(k\)-bit subvector \(\langle a \oplus \alpha \rangle_i^{i+k}\), parties compute:
     \[
     T (id)^\top \cdot \langle H((a \oplus \alpha))_i^{i+k} \otimes b \rangle = \langle (a \oplus \alpha)_i^{i+k} \otimes b \rangle
     \]
   - The parties then vertically concatenate the \(\lceil n/k \rceil\) resultant matrices into a single matrix \(\langle (a \oplus \alpha) \otimes b \rangle\).
4. **Symmetric Computation:**
   - Symmetrically, the parties compute \(\langle (b \oplus \beta) \otimes \alpha \rangle\) by splitting \(\langle b \oplus \beta \rangle\) into \(\lceil n/k \rceil\) \(k\)-bit chunks.
5. **Local Computation:**
   - \(G\) locally computes \(\alpha \otimes \beta\) and injects \(\langle \alpha \otimes \beta \rangle\) as a constant.
6. **Final Output:**
   - Parties compute and output:
     \[
     \langle (a \oplus \alpha) \otimes b \rangle \oplus \langle (b \oplus \beta) \otimes \alpha \rangle^\top \oplus \langle \alpha \otimes \beta \rangle = \langle a \otimes b \rangle
     \]
   - (See Figure 5 for proof of the above equality.)

### B. Applications – Extended

In this appendix, we expand on details deferred from Section 5.

#### B.1 General Binary Outer Products – Extended

In Section 7.2, we explained our general outer product technique but did not formalize it. Figure 8 provides the formal module.

**Figure 8: Efficient general outer product module.** The module implements the function \(a, b \mapsto a \otimes b\). Unlike Figure 5, this module handles outer products for input vectors of arbitrary length.

#### B.2 Binary Matrix Multiplication – Extended

It is well known that outer products can be used to efficiently compute matrix products. Specifically, the binary matrix product of input matrices \(a\) and \(b\) can be expressed by:
1. For each \(i\), taking the outer product of column \(i\) of \(a\) with row \(i\) of \(b\).
2. XORing the resulting matrices.

This technique does not use our low-level primitives directly but uses our outer product module as a black box. Hence, we need not formalize a module for matrix multiplication.

Because our technique reduces the cost of outer products by a factor of \(k\) (see Section 7.2), we similarly reduce the cost of binary matrix multiplication by a factor of \(k\). For input matrices with dimensions \(n \times m\) and \(m \times l\), we require \(O(nml/k)\) communication rather than the standard \(O(nml)\). Formally, \(k\) is a logarithmic factor; in practice, we instantiate \(k\) with small constants.

We implemented matrix multiplication; Figure 9 plots our improvement over the standard approach.

#### B.3 Integer Multiplication – Extended

Consider the multiplication of two \(n\)-bit numbers \(a\) and \(b\). Standard GC techniques multiply such numbers using the schoolbook method. Each summand can be expressed by bits in the outer product of \(a\) and \(b\). Hence, we improve multiplication by using our general outer product module (Section 7.2). Each summand must still be added inside GC; we do so by traditional GC means. This addition is now the bottleneck of multiplication performance. We leave potential improvements, perhaps by incorporating arithmetic GC techniques [BMR16], to future work.

Our integer multiplication technique does not use our lowest level primitives directly, so we need not formalize a module.

#### B.4 Binary Field Inverses – Extended

We now describe our field inverse module in detail. We first compute and release to \(E\) \(a \cdot \alpha\). To do so, we use a Reveal gate to sample a uniform non-zero element \(\alpha\) from \(GF(2^n)\).

**Figure 10: Our binary field inverse module.**

**Input:**
- Parties input shared bitstring \(\langle a \rangle\) where \(a \in \{0, 1\}^n\).

**Output:**
- Let \(f : \{0, 1\}^n \to \{0, 1\}^n\) be defined as follows:
  \[
  f(x) \triangleq
  \begin{cases}
   0 & \text{if } x = 0 \\
   x^{-1} & \text{otherwise}
  \end{cases}
  \]
- Parties output a shared bitstring \(\langle f(a) \rangle\).

**Procedure:**
1. **Compute Zero Check:**
   - The parties first compute \(\langle z \rangle \triangleq \langle a == 0 \rangle\). This is achieved using a circuit with \(n - 1\) AND gates.
2. **Reveal Gate:**
   - The parties next compute a Reveal gate to mask \(a \oplus z\). The gate samples a uniform non-zero element \(\alpha\) from \(GF(2^n)\).
   - The Reveal gate’s internal circuit is itself a module that computes \(x \mapsto x \cdot \alpha\); it is implemented as follows:
     - The internal module takes as arguments \(a\) and \(\alpha\). Via a Color gate, it reveals \(a \oplus \gamma\) to \(E\) where \(\gamma\) is a uniform mask.
     - Note, \(G\) knows \(\gamma \otimes \alpha\) and hence can inject it as a constant. The parties compute the following by a one-hot gate:
       \[
       T (id)^\top \cdot \langle H(a \oplus \gamma) \otimes \alpha \rangle \oplus \langle \gamma \otimes \alpha \rangle = \langle (a \oplus \gamma) \otimes \alpha \rangle \oplus \langle \gamma \otimes \alpha \rangle = \langle a \otimes \alpha \rangle
       \]
     - The internal module then computes \(\langle a \cdot \alpha \rangle\) via a linear function (see Section 7.5) and outputs the result.
3. **Secure Release:**
   - The above Reveal gate releases \((a \oplus z) \cdot \alpha\) to \(E\). This is secure because both \(a \oplus z\) and \(\alpha\) are non-zero field elements and because \(\alpha\) is uniform; hence the product is indistinguishable from a uniform non-zero field element.
4. **Compute Inverse:**
   - The parties compute the following by a one-hot gate:
     \[
     T ((\cdot)^{-1})^\top \cdot \langle H((a \oplus z) \cdot \alpha) \otimes \alpha \rangle = \langle ((a \oplus z) \cdot \alpha)^{-1} \otimes \alpha \rangle
     \]
5. **Final Output:**
   - Finally, the parties compute the following via a linear function (see Section 7.5) and output the result:
     \[
     \langle ((a \oplus z) \cdot \alpha)^{-1} \cdot \alpha \oplus z \rangle =
     \begin{cases}
      \langle 0 \rangle & \text{if } z = 1 \\
      \langle a^{-1} \rangle & \text{otherwise}
     \end{cases}
     \]

**S-Boxes – Extended:**
In Section 7.6, we discussed the 8-bit AES S-Box. 16-bit S-Boxes, based on an inversion in \(GF(2^{16})\), have also been proposed for some applications [KKK+15]. The state-of-the-art Boolean circuit uses 226 ciphertexts (113 AND gates) [BMP13]. Our approach produces an S-Box that consumes only 122 ciphertexts, a ∼45% improvement. Unfortunately, this application is less practical in terms of wall clock time since the parties must each compute a \(2^{16} \times 16\) one-hot outer product matrix.

**Figure 9:**
We used our implementation to compute the bitwise matrix product of two \(128 \times 128\) square bit matrices. We plot total communication consumption (top) and wall clock runtime (bottom). We instantiated our approach with various "chunking factors" \(k\) (see Figure 8). At \(k = 6\), we improve over the standard by 6.2× (communication) and 5× (time).

#### B.5 Modular Reduction – Extended

**Figure 11: Our public modular reduction module.**

**Input:**
- Parties input shared bitstring \(\langle a \rangle\) where \(a \in \{0, 1\}^n\).
- Parties agree on a public constant \(\ell\).

**Output:**
- Parties output a shared bitstring \(\langle a \mod \ell \rangle\).

**Procedure:**
1. **Parameter Agreement:**
   - Parties agree on a parameter \(m\) such that \(m \cdot \ell > 2^n\).
2. **Reveal Gate:**
   - The parties use a Reveal gate to (1) sample a uniform mask \(\alpha \in \mathbb{Z}_{m \cdot \ell}\), (2) compute \(\langle a + \alpha \mod m \cdot \ell \rangle\), and (3) reveal \(a + \alpha \mod m \cdot \ell\) to \(E\). Because \(\alpha\) is uniform, this revelation is secure.
3. **Chunking:**
   - The parties view \(\langle a + \alpha \mod m \cdot \ell \rangle\) as the concatenation of \(k\)-bit "chunks". For each \(i\)-th chunk \(\langle c_i \mod (m \cdot \ell) \rangle\), the parties compute:
     \[
     T (((\cdot) \ll (i \cdot k)) \mod \ell) \cdot \langle H(c_i) \otimes 1 \rangle = (c_i \ll (i \cdot k)) \mod \ell
     \]
4. **Final Output:**
   - The parties compute and output:
     \[
     \left( \sum_{i} (c_i \ll (i \cdot k)) \mod \ell \right) + \alpha \mod \ell = ((a + \alpha) - \alpha) \mod \ell = a \mod \ell
     \]
   - Each addition is computed by an AND-gate-based circuit that efficiently computes \((x + y) \mod \ell\) for \(x, y\) strictly less than \(\ell\).

#### B.6 Exponentiation – Extended

**Figure 12: Our integer exponent of a public constant module.**

**Input:**
- Parties input shared bitstring \(\langle a \rangle\) where \(a \in \{0, 1\}^n\).
- Parties agree on a public constant \(\ell\).

**Output:**
- Parties output a shared bitstring \(\langle \ell^a \mod 2^n \rangle\).

**Procedure:**
1. **Reveal Gate:**
   - The parties use a Reveal gate to (1) sample a uniform \(\alpha\), (2) compute \(\langle a - \alpha \rangle\), and (3) reveal \(a - \alpha\) to \(E\). Because \(\alpha\) is uniform, this revelation is secure.
2. **Chunking:**
   - The parties view \(\langle a - \alpha \rangle\) as the concatenation of \(\lceil n/k \rceil\) \(k\)-bit "chunks". For each \(i\)-th chunk \(\langle c_i \rangle\), the parties compute:
     \[
     T (\ell^{(\cdot)} \ll (i \cdot k)) \cdot \langle H(c_i) \otimes 1 \rangle = \ell^{c_i} \ll (i \cdot k)
     \]
3. **Final Output:**
   - The parties compute and output:
     \[
     \left( \prod_{i} \ell^{c_i} \ll (i \cdot k) \right) \cdot \ell^\alpha = (\ell^{a-\alpha}) \cdot \ell^\alpha = \ell^a
     \]
   - Note that \(\ell^\alpha\) is a constant known to \(G\). Each multiplication is computed via the technique described in Section 7.4.

---

This optimized version aims to make the text more clear, coherent, and professional, while maintaining the technical accuracy and structure of the original content.