Boston
magnate
denounced, denunciation
http://multimedia.belointeractive.com/attack
/binladen/1004blfamily.html
http://www.time.com/time/magazine/article
/0,9171,1000943,00.html?promoid=googlep
http://www.outpostoffreedom.com/bin ladin.htm
http://www.cairnet.org/html/911statements.html
Having 50 or more siblings is very
characteristic of Osama Bin Laden.
Many of Osama’s relatives reside in Boston.13
Osama’s father was a building magnate.
A number of groups (including Bin Laden’s
family) have denounced his actions.
condemnation
http://www.usnews.com/usnews/politics/whispers A number of groups (including Bin Laden’s
/archive/september2001.htm
family) have condemned his actions.
Figure 5: Words redacted as a result of Web-based inference detection. Column 1 is the word or words, column 2 is a link using those words
output by the algorithm, and column 3 explains why the word(s) are sensitive.
82
16th USENIX Security Symposium
USENIX Association
of keywords when looking for inferences. In contrast, if
readability is an important concern, then the considered
sets might be those favoring certain word types.
What we discuss here is one example of using
Web-based inference detection to improve the redaction
process. The approach we take is inﬂuenced by readabil-
ity and performance (i.e. speed of the redaction process)
but is by no means an optimal approach with respect
to either concern. We began by applying some simple
redaction rules to the document [8]. Speciﬁcally, we re-
moved all location references since our example in sec-
tion 1 indicated those were important to identifying the
biography subject, any dates near September 11, 2001,
which is clearly a memorable date, and ﬁnally, all cita-
tion titles since when paired with the associated publi-
cation, these enable the citation articles to be easily re-
trieved. The resulting redacted document is depicted in
ﬁgure 6, where grey rectangles indicate the redaction re-
sulting from the rules just described.
Our subsequent redaction proceeded iteratively. At
each stage, we extracted the text from the current doc-
ument, calculated the keywords ordered by the TF.IDF
metric and searched for inferences drawn from subsets
of a speciﬁed number of the top keywords. We then eval-
uated the output of the algorithm by checking to ensure
the produced links did indeed reﬂect identifying infer-
ences. If a link did not use all the queried keywords in a
discussion about Osama Bin Laden then it was deemed
invalid. A common source of invalid links were news ar-
ticle titles printed in the side-bar of the link that did not
make use of the keywords found in the main body. For
example, the query “condone citing prestigious”, yields
the top hit [6] (a humor site) because a sidebar links to
an article with “Osama” in the title, however, none of the
keywords are used in the description of that article.14
We incorporated manual review of the links because
the current form of our algorithms involves too little con-
tent analysis to provide conﬁdence that a returned link
reﬂects a strong connection between the associated key-
words and Osama Bin Laden. In addition, given the high
security nature of most redaction settings it is unlikely
that a purely automated process will ever be accepted.
For those inferences that were found valid, we made
redactions to prevent such inferences and repeated this
process for the newly redacted document. The following
makes the steps we followed precise.
1. Dates near September 11, 2001, titles of all citations
and location names were removed from the biogra-
phy [8].
2. For i = 2, . . . , 5:
(a) We executed Google queries for each i-tuple
in the top ni keywords in the biography. The
ni values were chosen based on performance
constraints as described in section 5.15 The
(i, ni) values were:
(2, 50), (3, 20), (4, 15)
and (5, 13). We concluded with 5-tuples be-
cause no valid inferences were found for that
run of the algorithm, and only 7% of the links
returned by the algorithm run for (i, ni) =
(4, 15) were valid. For each (i, ni) execu-
tion of the algorithm we received a list of sets
of keywords that were potentially inference-
enabling, and the associated top link leading
the algorithm to make this conclusion.
(b) We reviewed the returned links to see if all the
corresponding keywords were used in a dis-
cussion of Osama Bin Laden. If so, we made
a judgement as to which keyword or keywords
to remove to remove the inference while pre-
serving readability of the document.
(c) We incremented i and returned to step (a) with
the current form of the redacted document.
Figure 5 lists the words that were redacted as a result
of our Web-based inference detection algorithm. The ta-
ble also gives an example link output by the algorithm
that motivates the redaction and a brief explanation of
why the word is sensitive (gained from the manual re-
view of the link(s)). Note that while our algorithm found
some document features to be identifying that are un-
likely to have been covered by a generic redaction rule
(e.g. Osama Bin Laden’s father’s attribute of being a
building magnate) it left other, seemingly unusual, at-
tributes (such as Osama Bin Laden potentially being one
of 20 children). Since the Web is at best a proxy for hu-
man knowledge, and our algorithm used the Web in a
limited way (i.e. our analysis was limited to a few hits
with little NLP use), it seems likely that inferences were
missed. Hence, we emphasize that our tool is best used
to semi-automate the redaction process.
Finally, we note that the act of redacting informa-
tion may introduce as well as remove, privacy problems.
For example, as noted by Vern Paxson [39], redacting
“Boston” without redacting “Globe” may allow the sen-
sitive term “Boston” to be inferred. Our tool suggests
“Boston” for redaction, as opposed to “Boston Globe”,
because a number of Osama Bin Laden’s relatives reside
there, however, acting on this recommendation is prob-
lematic precisely because of the difference between the
nature of the inference and the document usage of the
term. An improved algorithm would understand the use
of the term within the document and use this to guide the
redaction process.
Our ﬁnal redacted document is shown in the right hand
side of ﬁgure 6.
USENIX Association
16th USENIX Security Symposium
83
Output from using the Web-
based inference detection 
algorithm
Figure 6: The left picture shows the original FBI-redacted biography. The right hand side shows the document resulting
from using the Web-based inference detection algorithm, where black rectangles represent redactions recommended
by the algorithm and grey rectangles are redactions coming from removing dates in 2001, locations and the titles of
cited articles (i.e. the grey and black rectangles are redactions made by the authors of this paper).
84
16th USENIX Security Symposium
USENIX Association
7 Conclusion
We have introduced the notion of using the Web to detect
undesired inferences. Our proof-of-concept experiments
demonstrate the power of the Web for ﬁnding the key-
words that are likely to identify a person or topic.
As is to be expected with an initial work, there re-
mains a lot of room for improvement in the algorithms.
In particular, to produce an inference detection tool ca-
pable of functioning in real-time, as is needed in some
applications, improvements already discussed such as
Web caching, additional ﬁltering of results to improve
precision, and deeper hit analysis to improve recall, are
needed. Another avenue for improvement is through
deeper content analysis (i.e. beyond keyword extrac-
tion). For example, employing a tool capable of deeper
semantic analysis such as [15] may allow for both more
meaningful extraction of words and phrases for generat-
ing queries, and improved analysis of the returned hits
for more accurate inference detection. In addition, sim-
ple improvements to the content analysis such as bet-
ter ﬁltering of stop words and html syntax, would create
more useful keyword lists.
Acknowledgement
The authors are very grateful to Richard Chow and Vern
Paxson for their help in revising earlier versions of this
paper.
References
[1] B. Aleman-Meza, M. Nagarajan, C. Ramakrishnan, L. Ding, P.
Kolari, A. Sheth, B. Arpinar, A. Joshi and T. Finin. Semantic an-
alytics on social networks: experiences in addressing the prob-
lem of conﬂict of interest detection. 15th International World
Wide Web Conference, 2006.
[2] M. Atallah, C. McDonough, S. Nirenburg, and V. Raskin. Nat-
ural Language Processing for Information Assurance. Proc. 9th
ACM/SIGSAC New Security Paradigms Workshop (NSPW 00),
pp.51-65, 2000.
[3] Apache Lucene. http://lucene.apache.org/java/
docs/
[4] AOL Keyword Searches. http://dontdelete.com/
default.asp
[5] M. Barbaro and T. Zeller. A face is exposed for AOL searcher
no. 4417749. The New York Times, August 9, 2006.
[6] http://www.bongonews.com/layout1.php?
event=2315
[9] Executive Order 12958, Classiﬁed National Security Informa-
tion. http://www.dss.mil/seclib/eo12958.htm
[10] B. Davison, D. Deschenes and D. Lewanda. Finding relevant
website queries. Twelfth International World Wide Web Confer-
ence, 2003.
[11] O. de Vel, A. Anderson, M. Corney and G. Mohay. Mining email
content for author identiﬁcation forensics. SIGMOD Record,
Vol. 30, No. 4, December 2001.
[12] Mike Dowman, Valentin Tablan, Hamish Cunningham and
Borislav Popov. Web-Assisted Annotation, Semantic Indexing
and Search of Television and Radio News. WWW, 2005.
[13] Factiva Insight:
factiva.com
Reputation Intelligence. http://www.
[14] Fetch Technologies. http://www.fetch.com
[15] GATE: General Architecture
Text
http://gate.ac.uk/projects.html
for
Engineering.
[16] N. Glance. Community Search Assistant. IUI, 2001.
[17] P. Golle. Revisiting the Uniqueness of Simple Demographics in
the US Population. Workshop on Privacy in the Electronic Soci-
ety, 2006.
[18] Google SOAP search API. http://code.google.com/
apis/soapsearch/
[19] J. Hale and S. Shenoi. Catalytic inference analysis: detecting
inference threats due to knowledge discovery. IEEE Symposium
on Security and Privacy, 1997.
[20] S. Hill and F. Provost. The myth of the double-blind review? Au-
thor identiﬁcation using only citations. SIGKDD Explorations,
2003.
[21] T. Hinke. Database inference engine design approach. Database
Security II: Status and Prospects, 1990.
[22] D. Jones. Google’s PowerPoint blunder was preventable.
IR Web Report. http://www.irwebreport.com/
perspectives/2006/mar/google blunder.htm
[23] E. Kin, Y. Matsuo, M. Ishizuka. Extracting a social network
among entities by web mining. ISWC ‘06 Workshop on Web
Content Mining with Human Language Technologies, 2006.
[24] M. Koppel and J. Schler. Authorship veriﬁcation as a one-class
classiﬁcation problem. Proceedings of the 21st International
Conference on Machine Learning, 2004.
[25] M. Koppel, J. Schler, S. Argamon and E. Messeri. Authorship
attribution with thousands of candidate authors. SIGIR ‘06.
[26] M. Lapata and F. Keller. The Web as a Baseline: Evaluating the
Performance of Unsupervised Web-based Models for a Range of
NLP Tasks, HLT-NAACL, 2004.
[27] G. Leech, P. Rayson and A. Wilson. Word frequencies in writ-
ten and spoken english: based on the British National Corpus.,
Longman, London, 2001.
[7] W. Broad. U. S. Web Archive is Said to Reveal a Nuclear Primer.
The New York Times, November 3, 2006.
[28] C. Manning and H. Schutze. Foundations of statistical natural
language processing. MIT Press, 1999.
[8] http://www.judicialwatch.org/archive/2005/
osama.pdf
[29] MedicineNet.com.
script/main/hp.asp
http://www.medterms.com/
USENIX Association
16th USENIX Security Symposium
85
4The AOL data can potentially be used to demonstrate the Web’s
ability to de-anonymize ([5] may be one such example), which is one
of the goals of our algorithms, however because our target application
is the protection of English language content, we opted not to vet our
algorithms with that data.
5The vast majority of the biographies we used identiﬁed their sub-
ject by both a ﬁrst and last name with no middle name or initial. Also,
name sufﬁxes (e.g. Jr. or annotations made by Wikipedia authors re-
garding profession), were ignored.
6This was done to avoid difﬁculties parsing non-ascii pages.
7These are the ﬁrst three links that appear on the results page,
whether or not one URL is a substring of another.
8Here “known site” means any site with “medterm” or “medword”
in the URL. As this certainly not sufﬁcient to remove all medical terms
sites, we manually reviewed the results before generating the example
keyword pairs in Figure 3.
9Note this extracted non-word indicates a ﬂaw in our text-from-html
extraction algorithm.
10In a manual review of the word pairs from W 0
B yielding a top hit
containing word(s) in K∗
ST D, we did not ﬁnd any hits using the word
pair in a meaningful way in relation to a sensitive word. Rather, the hits
generally turned out to be medical term lists.
11Since all of our sensitive words pertain to the same topic, alco-
holism, we did not record which particular sensitive word was con-
tained in the top hit (if any).
12Note this is the 4th
strategy would improve recall.
returned hit, indicating a change in our search
13The biography only mentions “Boston” in a citation, so this is a
conservative redaction choice.
14Alternative metrics for validity are of course possible. For exam-
ple, a more thorough algorithms might look for shared topic (e.g. the
events of September 11, 2001) amongst links, and retain any links per-
taining to the most popular topic as valid.
15We tended to experience problems communicating with Google
when when executing algorithm runs that exceeded 1500 queries,
{ni}i that yielded query counts in the range
hence we chose values of
of 1000 − 1500.
[30] P. Nakov and M. Hearst. Using the Web as an Implicit Train-
ing Set: Application to Structural Ambiguity Resolution. HLT-
NAACL, 2005.
[31] Nstein Technologies. http://www.nstein.com/pim.
asp
[32] G. Pant, S. Bradshaw and F. Menczer. Search engine-crawler
symbiosis: adapting to community interests.7th European Con-
ference on Digital Libraries, 2003.
[33] X. Qian, M. Stickel, P. Karp, T. Lunt and T. Garvey. Detection
and elimination of inference channels in multilevel relational
database systems. IEEE Symposium on Security and Privacy,
1993.
[34] M. Steyvers, P. Smyth, M. Rosen-Zvi and T. Grifﬁths. Proba-
bilistic author-topic models for information discovery. KDD ‘04.
[35] L. Sweeney. AI Technologies to Defeat Identity Theft Vulnera-
bilities. AAAI Spring Symposium on AI TEchnologies for Home-
land Security, 2005.
[36] L. Sweeney. Uniqueness of Simple Demographics in the U.S.
Population. LIDAP-WP4. Carnegie Mellon University, Labora-
tory for International Data Privacy, Pittsburgh, PA, 2000.
[37] P. Turney. Coherent Keyphrase Extraction via Web Mining. IJ-
CAI, 2002.
[38] Uniﬁed Medical Language System. http://www.umm.
edu/glossary/a/index.html
[39] Personal communication.
[40] Wikipedia. Alcoholism. http://en.wikipedia.org/
wiki/Alcoholism
[41] Wikipedia. Sexually
transmitted
wikipedia.org/wiki/Sexually transmitted
disease
disease. http://en.
[42] http://wordweb.info/free/
[43] R. Yip and K. Levitt. Data level inference detection in database
systems. IEEE Eleventh Computer Security Foundations Work-
shop, 1998.
[44] D. Zhao and T. Sapp. AOL Search Database. http://www.
aolsearchdatabase.com/
[45] http://www.zoominfo.com/
Notes
1http://www.popandpolitics.com/2005/09/06/and-lite-jazz-singers-
shall-lead-the-way/, www.popandpolitics.com/2006/10/06/our-paris/
2http://en.wikipedia.org/wiki/
Madonna and the gay community,
http://gaybookreviews.info/review/2807/615,
http://www.youtube.com/results?search type=related
&search query=madonna%20oh%20father
3Example results from our experiments appear in section 5. Be-
cause of the dynamic nature of the Web, issuing the same queries today
may yield somewhat different results.
86
16th USENIX Security Symposium
USENIX Association