title:Familiarity breeds contempt: the honeymoon effect and the role of
legacy code in zero-day vulnerabilities
author:Sandy Clark and
Stefan Frei and
Matt Blaze and
Jonathan M. Smith
Familiarity Breeds Contempt
The Honeymoon Effect and the Role of Legacy Code in Zero-Day Vulnerabilities
Sandy Clark
University of Pennsylvania
PI:EMAIL
Matt Blaze
University of Pennsylvania
PI:EMAIL
ABSTRACT
Work on security vulnerabilities in software has primarily
focused on three points in the software life-cycle: (1) ﬁnding
and removing software defects, (2) patching or hardening
software after vulnerabilities have been discovered, and (3)
measuring the rate of vulnerability exploitation. This paper
examines an earlier period in the software vulnerability life-
cycle, starting from the release date of a version through to
the disclosure of the fourth vulnerability, with a particular
focus on the time from release until the very ﬁrst disclosed
vulnerability.
Analysis of software vulnerability data, including up to
a decade of data for several versions of the most popular
operating systems, server applications and user applications
(both open and closed source), shows that properties ex-
trinsic to the software play a much greater role in the rate
of vulnerability discovery than do intrinsic properties such
as software quality. This leads us to the observation that
(at least in the ﬁrst phase of a product’s existence), soft-
ware vulnerabilities have diﬀerent properties from software
defects.
We show that the length of the period after the release of
a software product (or version) and before the discovery of
the ﬁrst vulnerability (the ’Honeymoon’ period) is primarily
a function of familiarity with the system. In addition, we
demonstrate that legacy code resulting from code re-use is
a major contributor to both the rate of vulnerability dis-
covery and the numbers of vulnerabilities found; this has
signiﬁcant implications for software engineering principles
and practice.
1.
INTRODUCTION
Software vulnerabilities are the root cause of many secu-
rity breaches, so understanding software systems is essential
to developing models for how and when to invest eﬀort in
securing software. The most important software systems to
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’10 Dec. 6-10, 2010, Austin, Texas USA
Copyright 2010 ACM 978-1-4503-0133-6/10/12 ...$10.00.
Stefan Frei
Secunia
PI:EMAIL
Jonathan Smith
University of Pennsylvania
PI:EMAIL
understand are those of large scale and those in wide use.
Since almost all software systems today are large and com-
plex, we can focus our attention on those in wide use. Rang-
ing from document preparation programs to web browsers
and operating systems, such systems can each comprise mil-
lions of lines of source code, a very rough measure of software
complexity. Given the importance of such systems, models
for their creation, use, maintenance and upgrades - their
“life-cycle” - are clearly necessary.
Figure 1: Bugs per month, Left:Figure 11.2 from
“The Mythical Man Month”, Right: Security vul-
nerabilities per month
Models are useful in estimating project costs and timing.
For example, if a model predicts that the bug discovery rate
drops rapidly after an initial ﬂurry of discoveries, this fact
can be used to determine when software is ready for release:
once the rate has reached an acceptable level, the software
can be shipped. Such estimation can have signiﬁcant eco-
nomic eﬀects upon an enterprise: ship too early and pay
a price in service calls; ship too late and potentially lose
customers who might look elsewhere. A powerful predictive
model can therefore be worth signiﬁcant amounts of revenue,
as it allows trading development costs and time against a
combination of sales revenue and maintenance costs.
Software Reliability Models (SRMs) are primarily con-
cerned with increasing the quality of the code by predicting
and locating software defects. A major assumption made
251
by SRMs is that software is released with some number of
defects that can be categorized based on how easy each is
to ﬁnd. A further assumption is made that the easy-to-ﬁnd
defects are discovered and ﬁxed early in the software life-
cycle, quickly leading to a state where only diﬃcult-to-ﬁnd
vulnerabilities are left and the software can be considered
reliable. Figure 11.2 from Brooks [5] is reproduced on the
left of Figure 1 to illustrate this point.
Software Vulnerability Discovery Models (VDMs) resem-
ble SRMs, but VDMs focus predominantly on predicting
attacks against mature software systems. VDMs rely on the
intrinsic qualities of the software for a measure of its initial
security. For a VDM the expectation is that the low-hanging
fruit vulnerabilities are found quickly and patched. The re-
maining vulnerabilities (which are increasingly diﬃcult to
ﬁnd) are presumed to take much longer to discover, and the
software is considered “secure”. A VDM with those expec-
tations would predict that vulnerabilities are found fastest
shortly after the release of a product, and the rate of dis-
covery decreases thereafter.
The implications of such a VDM are signiﬁcant for soft-
ware security. It would suggest, for example, that once the
rate of vulnerability discovery was suﬃciently small, that the
software is “safe” and needs little attention. It also suggests
that software modules or components that have stood this
“test of time” are appropriate candidates for reuse in other
software systems. If this VDM model is wrong, these impli-
cations will be false and may have undesirable consequences
for software security.
Unlike much of the previous work [25, 2, 28] which focused
on understanding time to exploit after a vulnerability has
been discovered, this paper focuses on measuring time to
vulnerability discovery.
The remainder of the paper is organized as follows. Sec-
tion 2 describes our unique dataset of vulnerabilities, cover-
ing several versions of the most popular software products,
operating systems, server applications and user applications.
In Section 3 we analyze this data, which show that the
period between the release date of a product and its very
ﬁrst 0-day vulnerability is considerably longer than the mean
time between the ﬁrst vulnerability and second or between
the second and the third. We call this unexpected grace
period the honeymoon eﬀect and believe it to be important,
because these numbers challenge our expectations and intu-
ition about the eﬀect of software quality on security. The
interval between software release and the discovery of it’s
ﬁrst 0-day vulnerability also appears to be a strong predic-
tor of the arrival rate of subsequent vulnerability discoveries.
The honeymoon eﬀect also illustrates another incompat-
ibility between current software engineering practices and
security: the eﬀect of code reuse. “Good programmers write
code, Great programmers reuse ” is a well-known aphorism,
and the assumption made is that reusing code is not only
more eﬃcient, but since the code has already been deployed
successfully, it is more reliable and therefore, by implication,
also more secure. In Section 4 our data again show this is
not the case.
We set our results in the context of prior work in Section
5 and conclude the paper by summarizing our claims and
discussing the implications for engineering secure software
systems in Section 6.
2. OUR DATASET
In this paper, we are concerned speciﬁcally with the early
post-release vulnerability life-cycle for modern, mass mar-
ket software, including operating systems, web clients and
servers, text and graphics processors, server software, and
so on.
Our analysis focuses on publicly distributed software re-
leased between 1999 and 2007. (2007 is the latest date for
which complete vulnerability information was reliably avail-
able from various published data sources). We included both
open and closed source software.
To encompass the most comprehensive possible range of
relevant software releases, we collected data about all re-
leased versions of the major operating systems (Windows,
OS X, Redhat Linux, Solaris, FreeBSD), all released ver-
sions of the major web browsers (Internet Explorer, Firefox,
Safari), and all released versions of various server and end
user applications, both open and closed source. The server
and user applications were based on the top 25 downloaded /
purchased / favorite application identiﬁed in lists published
by ZDNet, CNet, and Amazon, excluding only those appli-
cations for which accurate release date information was un-
available or that were not included in the vulnerability data
sources described below. In total, we were able to compile
data about 38 of the most popular and important software
packages.
For each software package and version during the period
of our study, we examined public databases, product an-
nouncements, and published press releases to assign each
version a release date. For the period of versions (1990-
2007) and for the period of vulnerabilities (1999-2008), we
identiﬁed 700 distinct released versions (’major’ and ’minor’)
of the 38 diﬀerent software packages.
We then compiled a dataset of more than 30,000 exploitable
vulnerabilities that were disclosed during the period under
analysis (January 1999 through January 2008). Our baseline
sources were publicly available databases from the National
Vulnerability Database (NVD) [23] and from the Common
Vulnerabilities and Exposures (CVE) [9] initiative that feeds
NVD. (For each vulnerability, NVD provides a publication
date, a short description, a risk rating, references to original
sources, and information on the vendor, version and name of
the product aﬀected.) We also downloaded, parsed, and cor-
related the information from over 200,000 individual secu-
rity bulletins from several “Security Information Providers”
(SIPs), choosing the set of SIPs based on criteria such as in-
dependence, accessibility, and available history of informa-
tion. Ultimately, we processed all security advisories from
the following seven SIPs: Secunia, US-CERT, SecurityFo-
cus, IBM ISS X-Force, SecurityTracker, iDefense’s (VPC),
and TippingPoint(ZDI) [29, 33, 30, 14, 34, 31, 15, 32].
For this study, we selected from these bulletins and database
entries bugs identiﬁed as exploitable vulnerabilities that ren-
der the software vulnerable to actual attack and for which a
practical exploit has been demonstrated. We then calculated
the initial disclosure date for each exploitable vulnerability
to be the earliest calendar day on which information on a
speciﬁc vulnerability is made freely available to the public
in a consistent format by some recognized published source
[11]. To help ensure accuracy, we manually checked and cor-
rected over 3,000 instances of software version information
for the speciﬁc product versions under analysis in this paper
to normalize for inconsistencies in NVD’s vulnerability to
product mapping.
252
3. THE HONEYMOON EFFECT
Virtually all mass-market software systems undergo a lengthy
period, after their release, during which end-users discover
and report bugs and other deﬁciencies. Most software sup-
pliers (whether closed-source or open-source) build into their
life-cycle planning a mechanism for reacting to bug reports,
repairing defects, and releasing patched versions at regular
intervals. The number of latent bugs in a particular version
of a given version of a given piece of software thus tends to
decrease over time, with the initial, unpatched, release suf-
fering from the largest number of defects. (This excludes, of
course, defects introduced by patches, which are a minority
in practice).
In systems where bugs are ﬁxed in response
to user reports, the most serious and easily triggered bugs
would be expected to be reported early, with increasingly es-
oteric defects accounting for a greater fraction of bug reports
as time goes on.
Empirical studies in both the classic [5] and the current
[16] software engineering literature have shown that, indeed,
this intuition reﬂects the software life-cycle well (see Fig-
ure 2).
Invariably, these and other software engineering
studies have shown that the rate of bug discovery is at
its highest immediately after software release, with the rate
(measured either as inter-arrival time of bug reports or as
number of bugs per interval) slowing over time.
Note that some (but not all) of the bugs discovered and
repaired in this process represent security vulnerabilities; in
security parlance a vulnerability that allows an attacker to
exploit a newly discovered, previously unknown bug is called
a 0-day vulnerability. Virtually all software vendors give
high priority to repairing defects once a 0-day exploit is dis-
covered.
It seems reasonable, then, to presume that users of soft-
ware are at their most vulnerable, with software suﬀering
from the most serious latent vulnerabilities, immediately af-
ter a new release. That is, we would expect attackers (and
legitimate security researchers) who are looking for bugs to
exploit to have the easiest time of it early in the life cy-
cle. This, after all, is when the software is most intrinsically
weak, with the highest density of ”low hanging fruit” bugs
still unpatched and vulnerable to attack. As time goes on,
after all, the number of undiscovered bugs will only go down,
and those that remain will presumably require increasing ef-
fort to ﬁnd and exploit.
In other words, to the extent that security vulnerabilities
are a consequence of software bugs, conventional software
engineering wisdom tells us to expect the discovery of 0-day
exploits to follow the same pattern as other reported bugs.
The pace of exploit discovery should be at its most rapid
early on, and slowing down as the software quality improves
and the ”easiest” vulnerabilities are repaired.
But our analysis of the rate of the discovery of exploitable
bugs in widely-used commercial and open-source software,
tells a very diﬀerent story than what the conventional soft-
ware engineering wisdom leads us to expect. In fact, new
software overwhelmingly enjoys a honeymoon from attack
for a period after it is released. The time between release
and the ﬁrst 0-day vulnerability in a given software release
tends to be markedly longer than the interval between the
ﬁrst and the second vulnerability discovered, which in turn
tends to be longer than the time between the second and the
third. That is, when the software it at its weakest, with the
”easiest” exploitable vulnerabilities still unpatched, there is
253
Figure 3: The Honeymoon Period, both Positive and
Negative time-lines
a lower risk that this will be discovered by an actual attacker
on a given day than there will be after the vulnerability is
ﬁxed!
3.1 The Honeymoon Effect and Mass-Market
Software
For the purposes of this paper, we deﬁne the ﬁrst (publicly
reported) exploitable vulnerability as the primal vulnerabil-
ity, we deﬁne a software release as experiencing a positive
honeymoon if the interval p0 between the (public) release of
the software and the primal vulnerability in the software is
greater than the interval p0+1 between the primal vulner-
ability and the second(publicly reported) vulnerability.(see
Figure 3) We will refer here to the interval p0 as the honey-
moon period and the ratio p0/p0+1 as the honeymoon ratio.
In other words, a software release has experienced a positive
honeymoon when its honeymoon ratio > 1.
We examined 700 software releases of the most popular re-
cent mass-market software packages for which release dates
and vulnerability reports were available (see Section 2). In
431 of 700 (62%) of releases, the honeymoon eﬀect was pos-
itive. Most notably, the median overall honeymoon ratio
(including both positive and negative honeymoons) p0/p0+1
was 1.54. That is, the median time from initial release and
the primal vulnerability is 1 1/2 times greater than the time
from primal to the discovery of the second. The honeymoon
eﬀect is not only present, it is quite pronounced, and the ef-
fect is even more pronounced when we exclude minor version
updates and focus on major releases. For major releases, the
honeymoon ratio(including both positive and negative hon-
eymoons) rises to 1.8.
Remarkably, positive honeymoons occur across our entire
dataset for all classes of software and across the entire pe-
riod under analysis. The honeymoon eﬀect is strong whether
the software is open- or closed- source, whether it is an OS,
web client, server, text processor, or something else, and re-
gardless of the year in which the release occurred.(see Table
1)
Although the honeymoon eﬀect is pervasive across the en-
tire dataset, one factor appears to inﬂuence its length more
than any other: the re-use of code from previous releases,
which, counter-intuitively, shortens the honeymoon. Soft-
Figure 2: Current Software Engineering literature supports the Brooks life-cycle model - image taken from
“Post-release reliability growth in software products”, ACM Trans. Softw. Eng Methodol. 2008 see references
Table 1: Percentages of Honeymoons by Year
Year Honeymoons
1999
56%
2000
2001
2002
2003
2004
2005
2007
62%
50%
71%
53%
49%
66%
58%
ware releases based on ”new” code have longer honeymoons
than those that re-use old code. We discuss this in detail in
the following sections.
3.2 Honeymoons in Different Software Envi-
ronments
The number of days in the honeymoon period varies widely
from software release to software release, and ranged from
a single day to over three years in our dataset. The length
of the honeymoon presumably varies due to many factors,
including the intrinsic quality of the software and extrinsic
factors such as attacker interest, familiarity with the system,