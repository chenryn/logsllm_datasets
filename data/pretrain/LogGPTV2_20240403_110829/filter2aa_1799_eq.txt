Cache
manager
Call the memory
manager to access
the mapped file
FIGURE 11-56 Log file service (LFS).
696
CHAPTER 11
Caching and file systems
The LFS divides the log file into two regions: a restart area and an “infinite” logging area, as shown in 
Figure 11-57.
Log records
Logging area
Copy 2
Copy 1
LFS restart area
FIGURE 11-57 Log file regions.
NTFS calls the LFS to read and write the restart area. NTFS uses the restart area to store context in-
formation such as the location in the logging area at which NTFS begins to read during recovery after a 
system failure. The LFS maintains a second copy of the restart data in case the first becomes corrupted 
or otherwise inaccessible. The remainder of the log file is the logging area, which contains transaction 
records NTFS writes to recover a volume in the event of a system failure. The LFS makes the log file ap-
pear infinite by reusing it circularly (while guaranteeing that it doesn’t overwrite information it needs). 
Just like CLFS, the LFS uses LSNs to identify records written to the log file. As the LFS cycles through the 
file, it increases the values of the LSNs. NTFS uses 64 bits to represent LSNs, so the number of possible 
LSNs is so large as to be virtually infinite.
NTFS never reads transactions from or writes transactions to the log file directly. The LFS provides 
services that NTFS calls to open the log file, write log records, read log records in forward or backward 
order, flush log records up to a specified LSN, or set the beginning of the log file to a higher LSN. During 
recovery, NTFS calls the LFS to perform the same actions as described in the TxF recovery section: a redo 
pass for nonflushed committed changes, followed by an undo pass for noncommitted changes.
Here’s how the system guarantees that the volume can be recovered:
1.
NTFS first calls the LFS to record in the (cached) log file any transactions that will modify the
volume structure.
2.
NTFS modifies the volume (also in the cache).
3.
The cache manager prompts the LFS to flush the log file to disk. (The LFS implements the flush
by calling the cache manager back, telling it which pages of memory to flush. Refer back to the
calling sequence shown in Figure 11-56.)
4.
After the cache manager flushes the log file to disk, it flushes the volume changes (the meta-
data operations themselves) to disk.
These steps ensure that if the file system modifications are ultimately unsuccessful, the correspond-
ing transactions can be retrieved from the log file and can be either redone or undone as part of the 
file system recovery procedure.
CHAPTER 11
Caching and file systems
697
File system recovery begins automatically the first time the volume is used after the system is re-
booted. NTFS checks whether the transactions that were recorded in the log file before the crash were 
applied to the volume, and if they weren’t, it redoes them. NTFS also guarantees that transactions not 
completely logged before the crash are undone so that they don’t appear on the volume.
Log record types
The NTFS recovery mechanism uses similar log record types as the TxF recovery mechanism: update re-
cords, which correspond to the redo and undo records that TxF uses, and checkpoint records, which are 
similar to the restart records used by TxF. Figure 11-58 shows three update records in the log file. Each 
record represents one suboperation of a transaction, creating a new file. The redo entry in each update 
record tells NTFS how to reapply the suboperation to the volume, and the undo entry tells NTFS how to 
roll back (undo) the suboperation.
Redo: Allocate/initialize an MFT file record
Undo: Deallocate the file record
Redo: Set bits 3–9 in the bitmap
Undo: Clear bits 3–9 in the bitmap
Redo: Add the file name to the index
Undo: Remove the file name from the index
LFS restart area
Logging area
Log file records
T1a
T1b
T1c
…
...
FIGURE 11-58 Update records in the log file.
After logging a transaction (in this example, by calling the LFS to write the three update records to the 
log file), NTFS performs the suboperations on the volume itself, in the cache. When it has finished updat-
ing the cache, NTFS writes another record to the log file, recording the entire transaction as complete—a 
suboperation known as committing a transaction. Once a transaction is committed, NTFS guarantees that 
the entire transaction will appear on the volume, even if the operating system subsequently fails.
When recovering after a system failure, NTFS reads through the log file and redoes each commit-
ted transaction. Although NTFS completed the committed transactions from before the system failure, 
it doesn’t know whether the cache manager flushed the volume modifications to disk in time. The 
updates might have been lost from the cache when the system failed. Therefore, NTFS executes the 
committed transactions again just to be sure that the disk is up to date.
After redoing the committed transactions during a file system recovery, NTFS locates all the transac-
tions in the log file that weren’t committed at failure and rolls back each suboperation that had been 
logged. In Figure 11-58, NTFS would first undo the T1c suboperation and then follow the backward 
pointer to T1b and undo that suboperation. It would continue to follow the backward pointers, undoing 
suboperations, until it reached the first suboperation in the transaction. By following the pointers, NTFS 
knows how many and which update records it must undo to roll back a transaction.
698
CHAPTER 11
Caching and file systems
Redo and undo information can be expressed either physically or logically. As the lowest layer of 
software maintaining the file system structure, NTFS writes update records with physical descriptions that 
specify volume updates in terms of particular byte ranges on the disk that are to be changed, moved, 
and so on, unlike TxF, which uses logical descriptions that express updates in terms of operations such as 
“delete file A.dat.” NTFS writes update records (usually several) for each of the following transactions:
I 
Creating a file
I 
Deleting a file
I 
Extending a file
I 
Truncating a file
I 
Setting file information
I 
Renaming a file
I 
Changing the security applied to a file
The redo and undo information in an update record must be carefully designed because although 
NTFS undoes a transaction, recovers from a system failure, or even operates normally, it might try to 
redo a transaction that has already been done or, conversely, to undo a transaction that never occurred 
or that has already been undone. Similarly, NTFS might try to redo or undo a transaction consisting of 
several update records, only some of which are complete on disk. The format of the update records 
must ensure that executing redundant redo or undo operations is idempotent—that is, has a neutral ef-
fect. For example, setting a bit that is already set has no effect, but toggling a bit that has already been 
toggled does. The file system must also handle intermediate volume states correctly.
In addition to update records, NTFS periodically writes a checkpoint record to the log file, as illus-
trated in Figure 11-59.
Checkpoint
record
LFS restart area
NTFS restart
Logging area
Log file records
LSN
2058
LSN
2061
...
...
LSN
2059
LSN
2060
FIGURE 11-59 Checkpoint record in the log file.
A checkpoint record helps NTFS determine what processing would be needed to recover a volume if 
a crash were to occur immediately. Using information stored in the checkpoint record, NTFS knows, for 
example, how far back in the log file it must go to begin its recovery. After writing a checkpoint record, 
NTFS stores the LSN of the record in the restart area so that it can quickly find its most recently written 
checkpoint record when it begins file system recovery after a crash occurs; this is similar to the restart 
LSN used by TxF for the same reason.
CHAPTER 11
Caching and file systems
699
Although the LFS presents the log file to NTFS as if it were infinitely large, it isn’t. The generous size 
of the log file and the frequent writing of checkpoint records (an operation that usually frees up space 
in the log file) make the possibility of the log file filling up a remote one. Nevertheless, the LFS, just like 
CLFS, accounts for this possibility by tracking several operational parameters:
I 
The available log space
I 
The amount of space needed to write an incoming log record and to undo the write, should
that be necessary
I 
The amount of space needed to roll back all active (noncommitted) transactions, should that
be necessary
If the log file doesn’t contain enough available space to accommodate the total of the last two 
items, the LFS returns a “log file full” error, and NTFS raises an exception. The NTFS exception handler 
rolls back the current transaction and places it in a queue to be restarted later.
To free up space in the log file, NTFS must momentarily prevent further transactions on files. To 
do so, NTFS blocks file creation and deletion and then requests exclusive access to all system files and 
shared access to all user files. Gradually, active transactions either are completed successfully or receive 
the “log file full” exception. NTFS rolls back and queues the transactions that receive the exception.
Once it has blocked transaction activity on files as just described, NTFS calls the cache manager to 
flush unwritten data to disk, including unwritten log file data. After everything is safely flushed to disk, 
NTFS no longer needs the data in the log file. It resets the beginning of the log file to the current posi-
tion, making the log file “empty.” Then it restarts the queued transactions. Beyond the short pause in 
I/O processing, the log file full error has no effect on executing programs.
This scenario is one example of how NTFS uses the log file not only for file system recovery but also for 
error recovery during normal operation. You find out more about error recovery in the following section.
Recovery
NTFS automatically performs a disk recovery the first time a program accesses an NTFS volume after 
the system has been booted. (If no recovery is needed, the process is trivial.) Recovery depends on two 
tables NTFS maintains in memory: a transaction table, which behaves just like the one TxF maintains, 
and a dirty page table which records which pages in the cache contain modifications to the file system 
structure that haven’t yet been written to disk. This data must be flushed to disk during recovery.
NTFS writes a checkpoint record to the log file once every 5 seconds. Just before it does, it calls 
the LFS to store a current copy of the transaction table and of the dirty page table in the log file. NTFS 
then records in the checkpoint record the LSNs of the log records containing the copied tables. When 
recovery begins after a system failure, NTFS calls the LFS to locate the log records containing the most 
recent checkpoint record and the most recent copies of the transaction and dirty page tables. It then 
copies the tables to memory.
The log file usually contains more update records following the last checkpoint record. These 
update records represent volume modifications that occurred after the last checkpoint record was 
700
CHAPTER 11
Caching and file systems
written. NTFS must update the transaction and dirty page tables to include these operations. After 
updating the tables, NTFS uses the tables and the contents of the log file to update the volume itself.
To perform its volume recovery, NTFS scans the log file three times, loading the file into memory 
during the first pass to minimize disk I/O. Each pass has a particular purpose:
1.
Analysis
2.
Redoing transactions
3.
Undoing transactions
Analysis pass
During the analysis pass, as shown in Figure 11-60, NTFS scans forward in the log file from the begin-
ning of the last checkpoint operation to find update records and use them to update the transaction 
and dirty page tables it copied to memory. Notice in the figure that the checkpoint operation stores 
three records in the log file and that update records might be interspersed among these records. NTFS 
therefore must start its scan at the beginning of the checkpoint operation.
Analysis pass
Beginning of
checkpoint operation
End of checkpoint
operation
Dirty page
table
Update
record
Transaction
table
Checkpoint
record
Update
record
Update
record
...
...
FIGURE 11-60 Analysis pass.
Most update records that appear in the log file after the checkpoint operation begins represent a 
modification to either the transaction table or the dirty page table. If an update record is a “transac-
tion committed” record, for example, the transaction the record represents must be removed from the 
transaction table. Similarly, if the update record is a page update record that modifies a file system data 
structure, the dirty page table must be updated to reflect that change.
Once the tables are up to date in memory, NTFS scans the tables to determine the LSN of the oldest 
update record that logs an operation that hasn’t been carried out on disk. The transaction table con-
tains the LSNs of the noncommitted (incomplete) transactions, and the dirty page table contains the 
LSNs of records in the cache that haven’t been flushed to disk. The LSN of the oldest update record that 
NTFS finds in these two tables determines where the redo pass will begin. If the last checkpoint record 
is older, however, NTFS will start the redo pass there instead.
Note In the TxF recovery model, there is no distinct analysis pass. Instead, as described in 
the TxF recovery section, TxF performs the equivalent work in the redo pass.
CHAPTER 11
Caching and file systems
701
Redo pass
During the redo pass, as shown in Figure 11-61, NTFS scans forward in the log file from the LSN of the 
oldest update record, which it found during the analysis pass. It looks for page update records, which 
contain volume modifications that were written before the system failure but that might not have been 
flushed to disk. NTFS redoes these updates in the cache.
Redo pass
Beginning of
checkpoint operation
Oldest unwritten
log record
Dirty page
table
Update
record
Update
record
Transaction
table
Checkpoint
record
Update
record
...
...
...
FIGURE 11-61 Redo pass.
When NTFS reaches the end of the log file, it has updated the cache with the necessary volume modi-
fications, and the cache manager’s lazy writer can begin writing cache contents to disk in the background.
Undo pass
After it completes the redo pass, NTFS begins its undo pass, in which it rolls back any transactions that 
weren’t committed when the system failed. Figure 11-62 shows two transactions in the log file; transac-
tion 1 was committed before the power failure, but transaction 2 wasn’t. NTFS must undo transaction 2.
...
LSN
4044
LSN
4049
LSN
4045
LSN
4046
LSN
4047
LSN
4048
“Transaction committed” record
Transaction 1
Transaction 2
Undo pass
Power failure
FIGURE 11-62 Undo pass.
Suppose that transaction 2 created a file, an operation that comprises three suboperations, each 