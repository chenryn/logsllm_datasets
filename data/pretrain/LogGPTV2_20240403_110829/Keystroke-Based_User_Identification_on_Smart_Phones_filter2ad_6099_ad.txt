8.54
8.11
7.63
6.19
8.11
7.23
3.71
9.73
7.29
8.92
9.31
8.22
9.31
8.34
8.81
9.42
7.71
8.73
7.29
6.32
9.82
9.63
8.24
7.31
4.72
7.94
1.56
2.13
1.61
2.14
1.19
1.87
2.01
1.46
2.14
3.34
1.73
2.43
1.71
3.44
1.29
3.37
2.31
1.82
1.01
1.21
2.04
1.41
2.12
2.02
3.11
2.97
2.07
0.73
1.76
0.82
1.71
1.56
2.01
2.33
2.15
1.61
1.14
1.28
1.86
1.92
1.81
1.38
1.95
2.11
2.04
1.72
1.04
1.33
2.38
2.24
2.92
1.14
1.19
1.73
0.47
Keystroke-Based User Identiﬁcation on Smart Phones
235
compared with existing classiﬁers in Table 2 – are still far from acceptable. These
accuracy results do not meet the requirements that we have set for our system.
In our performance evaluation, we observed that the main accuracy limiting fac-
tor for the fuzzy classiﬁer was the dynamically changing keystroke behavior of
mobile phone users. Thus the performance of the feed-forward fuzzy classiﬁer
can be improved if we use an online dynamic optimizer that can dynamically
track and provide the changing feature trends as feedback into the fuzzy system.
Prior work has shown that Particle Swarm Optimization (PSO) and Genetic
Algorithms (GAs) have the capability to adapt with changes in datasets [10],[4].
Therefore, in subsequent sections, we study the eﬀect of incorporating a PSO-
and GA-based optimizer into the fuzzy classiﬁer.
Continuous Learning using Dynamic Optimizers. As mentioned above,
after an initial rule base is generated, we use Particle Swarm Optimization (PSO)
and Genetic Algorithms (GAs) to adapt the rule base to dynamically varying
user keystoke behavior.
Particle Swarm Optimization (PSO). The main idea of PSO [16] is to use
a swarm of agents that is spread on the landscape of search space, and these
agents, through local interactions, try to ﬁnd an optimal solution to the problem.
The characteristic that makes PSO successful is the communication between the
agents which allows agents to converge to the best location. Table 3 tabulates the
results of our fuzzy classiﬁer optimized using PSO. It can be seen that the FAR
and FRR values have improved signiﬁcantly to approximately 8% (averaged).
However, even after this improvement, a system with an error rate of around 8%
is not usable in the real-world.
Genetic Algorithm (GA). Genetic algorithms are well-known for providing
acceptable solutions to dynamic optimization problems [4]. Unlike PSO, GA
does not utilize feedback explicitly; rather, it uses genetic operators of selection,
crossover and mutation to ﬁnd the best solution. Use of GA reduces error rate
to approximately 8% (averaged) which is almost the same as obtained by the
fuzzy classiﬁer optimized using PSO.
Hybrid PSO-GA. PSO utilizes the concept of feedback and GA uses the diver-
sity achieved by randomness. Both of these optimizers have improved FAR and
FRR considerably. If we can somehow combine the concept of feedback with
randomness, theoretically the accuracy of our fuzzy classiﬁer should improve.
For this scenario, we use PSO and GA together for optimizing the database and
rule base of the feed-forward fuzzy classiﬁer. The results of the fuzzy classiﬁer
optimized by a hybrid PSO-GA optimizer are tabulated in Table 3. It can be
seen that the FAR and FRR have improved substantially to approximately 2%;
as a result, our hybrid system is able to meet the accuracy requirements set
earlier.
Another important thing to mention here is the standard deviation of the
results. The standard deviation of our proposed hybrid PSO-GA-Fuzzy system
is only 0.73% for FAR and 0.47% for FRR which is negligible. We have repeated
the experiments for our scheme 500 times and the conﬁdence interval of our
236
S. Zahid et al.
results is 95% using the t-distribution. This shows that the results produced
by our system are statistically signiﬁcant and the variation in the results is
signiﬁcantly small.
5.2 Algorithm in Veriﬁcation Mode
If the detection mode raises an alarm, the system moves to the veriﬁcation mode.
In this mode, we ask the suspicious user to enter a remembered 8-character
PIN. During the PIN entry process, we observe his/her keystroke patterns and
conclude whether or not the current user is an imposter. In this mode, the system
extracts three features – key hold time, digraph (irrespective of the position of
keys), and error rate – from the key log of the PIN entry process. Note that here
we use only three features because we have empirically determined that these
features are suﬃcient to achieve approximately 0% error rate.
We have also empirically concluded a rule: if a potential imposter passes the
test twice in three attempts, we declare him/her a legitimate user. We have
arrived at this conﬁguration by running a controlled experiment. We asked 10
of our colleagues to enter their PINs 30 times for training. After training, we
asked all of these 10 colleagues to enter their passwords 5 times. We observed
that each of them was able to enter his/her password with correct behavior at
least two out of the ﬁrst three attempts. Later, we selected three imposters for
each of those 10 colleagues and told them the correct passwords of respective
legitimate users. We again requested imposters to enter the password 5 times
and it was interesting to note that none of them was able to successfully enter
the password with a correct keystrokes pattern even once.
For PIN veriﬁcation, we have designed a simple, eﬃcient and accurate classiﬁer
speciﬁcally for keystroke dynamics. The motivation behind developing a new
classiﬁer for PIN veriﬁcation mode was that in case of PIN veriﬁcation we already
know the correct PIN and consequently we know what to expect from the user.
Thus a classiﬁer with signiﬁcantly small computational complexity can perform
this task. Our classiﬁer dynamically assigns an impression coeﬃcient (iC) to
a user on the basis of his/her PIN typing pattern. We argue that a legitimate
user is less likely to commit a mistake while entering his/her PIN; therefore,
committing a mistake during the PIN entry process counts negatively towards
the possibility that the current user is the legitimate user. We calculate the
diﬀerence between the key hold times of keys of current proﬁle with the key
hold times of all the corresponding keys of the standard proﬁles of a user and
then sum up all these diﬀerences to ﬁnd the overall diﬀerence in the key hold
time. Similarly, we ﬁnd an overall diﬀerence in the digraph time. Finally, we sum
overall key hold time diﬀerence and digraph diﬀerence to deﬁne the impression
coeﬃcient of PIN entry process. If a user commits a mistake during the PIN
entry process, we penalize him/her for each error by adding l milliseconds to the
overall diﬀerence value.
The overall diﬀerence is compared with a threshold value that is also dynamically
calculated. If iC of a user is larger than this threshold value, we classify him as an
imposter otherwise he/she is a legitimate user. It is important to emphasize that
Keystroke-Based User Identiﬁcation on Smart Phones
237
we do not train our system with imposters’ proﬁles. The mathematical explanation
of our proposed classiﬁer is given in the following text.
The size of the PIN is s characters, the number of keys pressed by the user
to enter s characters is represented by t, and the number of training proﬁles is
represented by n. P k is a matrix consisting of n rows corresponding to n training
proﬁles and t columns corresponding to t key hold times. P uk is a row vector
of t columns; each column corresponds to a key hold time for a key press in an
unknown proﬁle. Dk, similarly, is a matrix of dimensions n × t − 1 for digraph
times obtained from training proﬁles and Duk is a row vector of t − 1 columns
representing the digraph times of an unknown user. The mathematical model is
given in following equations:
(cid:3) t(cid:2)
t−1(cid:2)
n(cid:2)
(cid:4)(cid:4)pk
ij − puk
j
(cid:4)(cid:4) +
(cid:4)(cid:4)dk
ij − duk
j
(cid:5)
(cid:4)(cid:4)
+ e × l,
(1)
iC =
i=1
j=1
n(cid:2)
(cid:6) n(cid:2)
(cid:3) t(cid:2)
j=1
(cid:4)(cid:4)pk
ij − pk
mj
(cid:4)(cid:4) +
m=1
i=1
j=1
(cid:4)(cid:4)dk
ij − dk
mj
(cid:5)(cid:7)
(cid:4)(cid:4)
t−1(cid:2)
j=1
μ =
⎡
⎣ n(cid:2)
σ =
(cid:6) n(cid:2)
(cid:3) t(cid:2)
(cid:4)(cid:4)pk
ij − pk
mj
m=1
i=1
j=1
,
(2)
(cid:5)
(cid:4)(cid:4)
(cid:7)
− μ
2
/n
1
2
⎤
⎦
,
(3)
n
t−1(cid:2)
(cid:4)(cid:4)dk
ij − dk
(cid:4)(cid:4) +
mj ∈ Dk; duk
j=1
mj
ij, pk
ij, dk
j ∈ P uk; dk
mj ∈ P k; puk
j ∈ Duk; and e represents
where pk
the number of backspaces during PIN entry. Moreover, if iC ≥ μ + aσ then the
user is classiﬁed as an imposter; otherwise the user is classiﬁed as a legitimate
user. We have empirically determined that values of l = 5 and a = 3 provide
0% error. The following section evaluates the accuracy of the proposed tri-mode
system for varying system parameters.
6 Performance Evaluation
In this section, we ﬁrst evaluate the accuracy of the proposed system for a
ﬁxed training proﬁle. We then systematically evaluate the system’s performance
for diﬀerent parameters. Speciﬁcally, we chronologically answer the following
questions: (1) What is the accuracy of the system for a ﬁxed proﬁle?, (2) What
is the impact of number of proﬁles on the accuracy of our system?, (3) What is
the relationship between the size of a proﬁle and the accuracy of our system?, (4)
What is the average user identiﬁcation delay in terms of mobile phone usage (we
report it in terms of the number of SMSs)?, (5) How much damage an imposter
can do in 250 keystrokes?, and (6) What are the training and testing times of
our system?
What is the accuracy of the system for a ﬁxed proﬁle? The accuracy of
our system can be viewed from the Table 4. It can be seen that our tri-mode
238
S. Zahid et al.
Table 4. Accuracy results after detection mode and veriﬁcation mode for a ﬁxed proﬁle
size of 250 keystrokes
After
After
Detection
Veriﬁcation
After
After
Detection
Veriﬁcation
Mode
Mode
Mode
Mode
FRR
Users FAR
2.13
2.14
1.87
1.46
3.34
2.43
3.44
3.37
1.82
1.21
1.41
2.02
2.97
0.73
u1
u3
u5
u7
u9
u11
u13
u15
u17
u19
u21
u23
u25
SD
FRR
1.76
1.71
2.01
2.15
1.14
1.86
1.81
1.95
2.04
1.04
2.38
2.92
1.19
0.47
FAR
2.13
2.14
1.87
1.46
3.34
2.43
3.44
3.37
1.82
1.21
1.41
2.02
2.97
0.73
FRR Users FAR
1.61
1.19
2.01
2.14
1.73
1.71
1.29
2.31
1.01
2.04
2.12
3.11
2.07
—
u2
u4
u6
u8
u10
u12
u14
u16
u18
u20
u22
u24
Avg
0
0
0
0
0
0
0
0
0
0
0
0
0
0
—
FRR
0.82
1.56
2.33
1.61
1.28
1.92
1.38
2.11
1.72