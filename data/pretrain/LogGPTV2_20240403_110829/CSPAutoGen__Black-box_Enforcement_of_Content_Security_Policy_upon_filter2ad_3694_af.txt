95.9%
(421/439)
a Python implementation parser) with a more efﬁcient one, such
as Mozilla’s DOMParser [2]. Because the CSPAutoGen JavaScript
server and applier engine reside in the same physical server, the
script transmission delay in rewriting phase is acceptable: the me-
dian value is 51 ms per webpage.
The overhead of gAST building and template matching is small:
during loading time, CSPAutoGen processes ∼20 scripts on aver-
age for each webpage, so the estimated overall overhead of gAST
building would be 4 ms and overall overhead for template matching
would be 2 ms respectively.
6.6 Compatibility
In this section, we evaluate CSPAutoGen’s compatibility with
real-world websites from two aspects: the appearance and the deep,
behind-the-login functionalities.
Appearance. We evaluate whether the front pages of Alexa Top 50
websites can be correctly displayed based on the similarity scores
of screenshots taken with and without CSPAutoGen deployed. Here
is our methodology. We browse each front pages twice: at ﬁrst, we
deploy CSPAutoGen and take a screenshot of the webpage after it
is loaded, which we refer to as CSP_image; next, we repeat the
process without deploying CSPAutoGen and obtain another screen-
shot referred to as std_image. We then calculate the image similar-
ity score, called CSP_score, between CSP_image and std_image,
based on image histogram [26]. If CSP_score is larger than 0.9,
indicating that users can hardly notice any difference [26], we will
not examine the website. Note that, for about half of the 50 web-
sites, due to the existence of advertisement and real-time contents
(such as news), even consecutive screenshots of the same front page
without deploying CSPAutoGen render a similarity score, which we
refer to as std_score, less than 0.9. Therefore, if CSP_score is less
than 0.9, we will manually compare these two screenshots.
The results show that the front pages of 28 websites pass our
initial ﬁltering stage, i.e., CSP_score is larger than 0.9. Then, we
manually examine the rest 22 websites’ front pages, and ﬁnd that
the differences that a human eye can notice are all caused by adver-
tisements and news update. We further compare CSP_score with
std_score for these 22 websites’ front pages, and ﬁnd out that the
differences between two scores are all less than 0.1, which is an-
other evidence that the low similarity scores are caused by the web-
site itself. In addition, we ﬁnd that the DOM tree structures of these
webpages with and without CSPAutoGen are exactly the same.
Behind-the-login Functionalities. To explore the deep, behind-
the-login functionalities of websites with CSPAutoGen deployed,
we choose ﬁve major website categories based on their functional-
ities: email, online searching, online shopping, online social net-
work and web portal. For each category, we manually conduct one
extensive case study on the most popular website (based on Alexa
ranking) that has not deployed CSP at the time of our study.
The results show that all the tested functionalities of these web-
sites work properly with CSPAutoGen deployed. Table 7 shows
the matching rates of unique dynamic and runtime-included inline
scripts that CSPAutoGen has encountered and processed in the ex-
periment. Now we introduce the experiment details.
Email—Gmail. We register and log into a new Google account.
Then, we send ten emails to different recipients with various attach-
ments, links and photos from this account. All the ten recipients can
receive the emails successfully. Next, these recipients reply to the
emails with different attachments and contents. We can receive all
these emails and the client-side Gmail with CSPAutoGen deployed
can correctly render the contents. For the ones with attachments,
we successfully download all of them from graphic user interface.
Online Searching—Google. We use the Google account in the Gmail
experiment, and search ten different keywords on different Google
products. These products include Google Search, Google Images,
Google Books, Google Maps, Google Shopping, Google Videos,
Google News, Google Flights and Google Apps. All the searching
results can be displayed correctly. Then, we use Google’s advanced
search functionality, searching ten times with random conditions.
Online Shopping—Amazon. We register and log into an Amazon
account. Then, we search ten different products, such as jewelry
and books. After reviewing product descriptions and customer re-
views, we successfully purchase a book and a coffee maker with a
newly-added credit card.
Online Social Network—Linkedin. Because both Facebook and
Twitter have deployed CSP, we use Linkedin in the experiment. We
register and log into a new Linkedin account. Then, we upload a
photo, publish a post, search and connect to ﬁve people. Next, we
like, comment and share two posts from these connections. Lastly,
we send messages to two people, one connected with the account
and one not.
Web Portal—Yahoo. We register a Yahoo account via Audio code
and log into the account. Then we open ten news/posts belonging
to different categories. We like, comment on two news and then
share them to our Facebook and Twitter accounts.
7. DISCUSSION
Inline CSS. In this version of CSPAutoGen, we do not disable
inline CSS. However, CSPAutoGen is easily extendable to sup-
port disabling inline CSS without incurring compatibility issues, as
what we did for JavaScript, and we plan to support disabling inline
CSS in next version of CSPAutoGen. Note that even if CSPAu-
toGen does not support disabling inline CSS, an attacker cannot
inject JavaScript embedded in CSS rules because injected scripts
are blocked by CSPAutoGen.
Obfuscated Code. Code obfuscation does not inﬂuence the gen-
eration of gAST and symbolic templates, because obfuscated code
is still parsed and executed in the browser. In addition, the number
of ﬂexible types in obfuscated code is similar to the one in normal
code, because most of the strings in obfuscated code are inferred as
const or enum type.
Event Triggering. In the headless browser cluster of the training
phase, we triggered all the registered events. However, the trigger-
ing does not have any effects on the template generation. The rea-
son is that we obtain all the scripts in the DOM, no matter they are
triggered or not. The only exception is that when dynamic scripts
or runtime-included scripts are embedded inside an event handler,
but in practice we did not ﬁnd any web developers did so.
Script Execution Sequence. CSPAutoGen does not change the
original script execution sequence, i.e., both synchronous and asyn-
chronous scripts are still executed the way as they are. For example,
synchronous scripts inside eval or eval-like functions are executed
synchronously through symbolic templates, an essentially built-in
function call; asynchronous, runtime-included, inline scripts are
executed inside DOM event handlers, an asynchronous script ex-
ecution method.
8. RELATED WORK
In this section, we ﬁrst introduce several works in automatic en-
forcement of CSP. Then we present past works preventing XSS at-
tacks. Lastly, we discuss related works in academia and industry
using rewriting and AST techniques.
Automatic Enforcement of CSP. Researchers have proposed sev-
eral interesting works on automatic enforcement of CSP [12,14,17,
23]. The ﬁrst work of facilitating CSP adoption is deDacota [12].
Primarily, it statically rewrites ASP.NET applications to separate
data and codes; AutoCSP [14] uses dynamic taint analysis in PHP
to ﬁnd trusted elements of dynamically generated HTML pages
and then infers a policy to block untrusted elements, while allow-
ing trusted ones. Both AutoCSP and deDacota are white-box ap-
proaches, i.e., they need to access target application’s codes and re-
quire server modiﬁcations. Moreover, neither AutoCSP nor deDa-
cota can securely transform runtime-included inline scripts or dy-
namic scripts to comply with the strictest CSP. As a comparison,
CSPAutoGen requires no server-side modiﬁcations, and allows trusted
runtime-included inline scripts and dynamic scripts.
A black-box approach, autoCSP [17], ﬁrst generates strictest poli-
cies and then gradually relaxes them by adding the scripts received
from users’ violation reports to its whitelist. Kerschbaumer et al. [23]
adopt crowdsourcing approach to collect JavaScripts’ hashes and
then generate CSP rules based on these collected hashes, i.e., they
adopt strict string matching for inline scripts. Neither of the afore-
mentioned approaches can process inline scripts with runtime in-
formation, runtime-included inline scripts and dynamic scripts. Ac-
cording to our manual analysis, 46 of Top 50 Alexa websites con-
tain such script usages. That is, they cannot be deployable with
real-world websites. As a comparison, CSPAutoGen is compatible
with all Alexa Top 50 websites.
To defend against XSS attacks, other than CSP, researchers have
also proposed many approaches before, which can be further classi-
ﬁed as sever-side methods [9,10,19,21,22,29,30,36–38,40,42] and
client-side methods [20, 32]. We focus on the deployment of CSP,
because it has been adopted by all major browsers and standardized
by W3C [1].
Server-side Defenses of XSS Attacks. XSS-GUARD [10] dy-
namically determines legitimate scripts and removes illegitimate
ones from responses. However, since it only works at server side,
XSS-GUARD cannot determine whether dynamic scripts are le-
gitimate or not. As a comparison, CSPAutoGen can address both
static scripts and dynamic scripts. BLUEPRINT [30] proposes an
approach to ensure the safe construction of the intended HTML
parse tree on the client without changing browser. Template-based
approaches [36, 37] propose novel web frameworks that incorpo-
rate correct sanitization based on contexts. There are also many
works based on server-side input sanitization [9, 19, 40]. All the
aforementioned approaches require server-side modiﬁcations. As
a comparison, CSPAutoGen has a much more ﬂexible deployment
model, which can be at a server, client, or middlebox.
Many other XSS defenses are based on ﬂow analysis or taint
tracking [21, 22, 29, 29, 31, 38, 42]. Compared with CSPAutoGen,
such programming analysis requires server modiﬁcation and is bound
to a certain programming language. For example, Taj [42] works
speciﬁcally for Java, while Pixy [21] only operates on PHP.
Client-side Defenses of XSS Attacks. Lekies et al. [27] focus on
detecting DOM-based XSS vulnerabilities using taint analysis ap-
proach. Saxena et al. [39] highlight a new class of vulnerabilities,
referred to as client-side validation vulnerabilities, and propose a
dynamic analysis system to discover it. Noxes [25] is a client-side
ﬁrewall-based defense that protects users with permit/deny rules
to restrict HTTP requests. Similar to CSP, BEEP [20] and Con-
Script [32] are policy-based approaches: websites specify security
policies and the client-side browser enforces these policies. Un-
like CSP used in CSPAutoGen, they are not supported by existing
browsers so client-side modiﬁcations are required.
Rewriting Technique. CSPAutoGen rewrites webpages to auto-
matically generate CSPs without compromising compatibility. Rewrit-
ing techniques have been widely used in academia [13, 24, 28] and
industry [4, 6].
In academia, WebShield [28] rewrites webpages
to enable web defense techniques. Erlingsson et al. [13] enforce
security policies on binaries by taking advantage of rewriting tech-
niques. In industry, ShapeSecurity [6], a commercial product, rewrites
websites to prevent bot and malware. Google’s PageSpeed Mod-
ule [4] improves websites’ performance by rewriting webpages.
AST Technique. Abstract Syntax Tree (AST) has been widely
used by web security researchers to extract JavaScript structure in-
formation [11, 18, 35]. However, these works do not aim to gener-
ate script templates and thus cannot address the challenges of inline
scripts with runtime information or dynamic scripts.
9. CONCLUSION
In conclusion, we propose CSPAutoGen, which generates CSPs
from training dataset, rewrites webpages in real-time to insert CSPs,
and applies CSPs at client browsers. CSPAutoGen is able to deal
with all the real-world yet unsafe script usages, such as inline scripts
with runtime information and dynamic scripts, and securely convert
them to be compatible with CSP.
Our evaluation shows that CSPAutoGen can correctly render all
Top 50 Alexa websites. The correctness evaluation that compares
generated gAST templates with web framework source code shows
that CSPAutoGen can successfully infer type information with 95.9%
accuracy. In addition, CSPAutoGen only incurs 9.1% overhead in
median when rendering the front pages of Alexa Top 50 websites.
10. ACKNOWLEDGEMENTS
This work is collectively supported by U.S. National Science
Foundation (NSF) under Grants CNS-1646662, CNS-1563843, by
National Natural Science Foundation of China (NSFC) under Grant
No. 61472359, and by Defense Advanced Research Projects Agency
(DARPA) under Agreement No. FA8650-15-C-7561. The views
and conclusions contained herein are those of the authors and should
not be interpreted as necessarily representing the ofﬁcial policies or
endorsements, either expressed or implied, of NSF, NSFC, DARPA,
or the Government.
11. REFERENCES
[1] Content Security Policy. http://www.w3.org/TR/2012/CR-CSP-20121115/.
[2] Domparser. https://developer.mozilla.org/en-US/docs/Web/API/DOMParser.
[3] Esprima. http://esprima.org/.
[4] Pagespeed module: open-source server modules that optimize your site
automatically. https://developers.google.com/speed/pagespeed/module/.
[5] Scrapy | a fast and powerful scraping and web crawling framework.
http://scrapy.org/.
[6] Shape security. https://www.shapesecurity.com/.
[7] Standards-compliant library for parsing and serializing html documents and
fragments in python. https://github.com/html5lib/html5lib-python.
[8] VirusTotal. https://www.virustotal.com/.
[9] D. Balzarotti, M. Cova, V. Felmetsger, N. Jovanovic, E. Kirda, C. Kruegel, and
G. Vigna. Saner: Composing static and dynamic analysis to validate
sanitization in web applications. In IEEE S&P, 2008.
[10] P. Bisht and V. Venkatakrishnan. XSS-GUARD: precise dynamic prevention of
cross-site scripting attacks. In DIMVA. 2008.
[11] C. Curtsinger, B. Livshits, B. G. Zorn, and C. Seifert. Zozzle: Fast and precise
in-browser javascript malware detection. In USENIX Security, 2011.
[12] A. Doupé, W. Cui, M. H. Jakubowski, M. Peinado, C. Kruegel, and G. Vigna.
deDacota: toward preventing server-side XSS via automatic code and data
separation. In SIGSAC, 2013.
[13] U. Erlingsson and F. B. Schneider. Irm enforcement of java stack inspection. In
IEEE S&P, 2000.
[14] M. Fazzini, P. Saxena, and A. Orso. AutoCSP: Automatically Retroﬁtting CSP
to Web Applications. In ICSE, 2015.
[15] D. Flanagan. JavaScript: the deﬁnitive guide. " O’Reilly Media, Inc.", 2006.
[16] H. Gao, Y. Chen, K. Lee, D. Palsetia, and A. N. Choudhary. Towards online
spam ﬁltering in social networks. In Proceedings of Network and Distributed
Systems Security Symposium, NDSS, 2012.
[17] N. Golubovic. autoCSP: CSP-injecting reverse HTTP proxy. B.S. Thesis, Ruhr
University Bochum, 2013.
[18] S. Guarnieri and V. B. Livshits. Gatekeeper: Mostly static enforcement of
security and reliability policies for javascript code. In USENIX Security, 2009.
[19] P. Hooimeijer, B. Livshits, D. Molnar, P. Saxena, and M. Veanes. Fast and
precise sanitizer analysis with BEK. In USENIX Security, 2011.
[20] T. Jim, N. Swamy, and M. Hicks. Defeating script injection attacks with
browser-enforced embedded policies. In WWW, 2007.
[21] N. Jovanovic, C. Kruegel, and E. Kirda. Pixy: A static analysis tool for
detecting web application vulnerabilities. In IEEE S&P, 2006.
[22] N. Jovanovic, C. Kruegel, and E. Kirda. Precise alias analysis for static
detection of web application vulnerabilities. In PLAS, 2006.
[23] C. Kerschbaumer, S. Stamm, and S. Brunthaler. Injecting csp for fun and
security. In ICISSP, 2016.
[24] E. Kiciman and B. Livshits. Ajaxscope: a platform for remotely monitoring the
client-side behavior of web 2.0 applications. In SIGOPS, 2007.
[25] E. Kirda, C. Kruegel, G. Vigna, and N. Jovanovic. Noxes: a client-side solution
for mitigating cross-site scripting attacks. In SAC, 2006.
[26] S. Lee, J. Xin, and S. Westland. Evaluation of image similarity by histogram
intersection. Color Research & Application, 2005.
[27] S. Lekies, B. Stock, and M. Johns. 25 million ﬂows later: large-scale detection
of DOM-based XSS. In CCS, 2013.
[28] Z. Li, Y. Tang, Y. Cao, V. Rastogi, Y. Chen, B. Liu, and C. Sbisa. Webshield:
Enabling various web defense techniques without client side modiﬁcations. In
NDSS, 2011.
[29] V. B. Livshits and M. S. Lam. Finding Security Vulnerabilities in Java
Applications with Static Analysis. In USENIX Security, 2005.
[30] M. T. Louw and V. Venkatakrishnan. Blueprint: Robust prevention of cross-site
scripting attacks for existing browsers. In IEEE S&P, 2009.
[31] M. Martin and M. S. Lam. Automatic generation of XSS and SQL injection
attacks with goal-directed model checking. In USENIX Security, 2008.
[32] L. Meyerovich and B. Livshits. ConScript: Specifying and enforcing
ﬁne-grained security policies for Javascript in the browser. In IEEE S&P, 2010.
[33] R. Perdisci, D. Dagon, W. Lee, P. Fogla, and M. I. Sharif. Misleadingworm
signature generators using deliberate noise injection. In IEEE S&P, 2006.
[34] PhantomJS. PhantomJS . http://phantomjs.org/.
[35] E. B. Pratik Soni and P. Saxena. The SICILIAN Defense: Signature-based
Whitelisting of Web JavaScript. In CCS, 2015.
[36] W. K. Robertson and G. Vigna. Static Enforcement of Web Application
Integrity Through Strong Typing. In USENIX Security, 2009.
[37] M. Samuel, P. Saxena, and D. Song. Context-sensitive auto-sanitization in web
templating languages using type qualiﬁers. In CCS, 2011.
[38] P. Saxena, D. Akhawe, S. Hanna, F. Mao, S. McCamant, and D. Song. A
symbolic execution framework for javascript. In IEEE S&P, 2010.
[39] P. Saxena, S. Hanna, P. Poosankam, and D. Song. FLAX: Systematic Discovery
of Client-side Validation Vulnerabilities in Rich Web Applications. In NDSS,
2010.
[40] P. Saxena, D. Molnar, and B. Livshits. SCRIPTGARD: automatic
context-sensitive sanitization for large-scale legacy web applications. In CCS,
2011.
[41] S. Stamm, B. Sterne, and G. Markham. Reining in the web with content
security policy. In WWW, 2010.
[42] O. Tripp, M. Pistoia, S. J. Fink, M. Sridharan, and O. Weisman. TAJ: effective
taint analysis of web applications. SIGPLAN, 2009.
[43] G. Wang, T. Wang, H. Zheng, and B. Y. Zhao. Man vs. machine: Practical
adversarial detection of malicious crowdsourcing workers. In USENIX Security,
2014.
[44] R. Wang, W. Enck, D. S. Reeves, X. Zhang, P. Ning, D. Xu, W. Zhou, and
A. M. Azab. Easeandroid: Automatic policy analysis and reﬁnement for
security enhanced android via large-scale semi-supervised learning. In USENIX
Security, 2015.
[45] M. Weissbacher, T. Lauinger, and W. Robertson. Why is CSP Failing? Trends
and Challenges in CSP Adoption. In RAID. 2014.
[46] XCampo. A XSS payload generator. https://code.google.com/p/xcampo/.