3 Used addresses are those assigned an authority at http://
www.iana.org/assignments/ipv4-address-space. At
the time of this writing, roughly 120 of the 255 /8’s available are listed
as reserved or otherwise unroutable.
4 While the IP speciﬁcation dictates that ephemeral port numbers should
be assigned randomly, very few stack implementations actually do so.
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
s
t
e
k
c
a
P
s
t
e
k
c
a
P
Traffic
2.5e+06
2e+06
1.5e+06
1e+06
500000
0
500
1000
1500
2000
2500
3000
Bins (30 seconds)
(i) Packets per 30s
Dropped
2.5e+06
2e+06
1.5e+06
1e+06
500000
0
500
1000
1500
2000
2500
3000
Bins (30 seconds)
(ii) Packets dropped by router
800
700
600
500
400
300
200
100
s
e
s
s
e
r
d
d
A
l
a
t
o
T
0
26:30
26:40
26:50
27:00
Start time
27:10
27:20
27:30
(iii) New attackers per second
Figure 1. Attack
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
In addition, the heightened drop rate in the latter half of Fig-
ure 1(ii) is the result of an ACL modiﬁcation to protect the
target.
NetFlow reporting is a secondary process for routers, and
so during stress, routers will naturally drop a certain per-
centage of NetFlow records before sending them for collec-
tion. As such, the information conveyed in Table 1 and Fig-
ure 1 does not represent the entirety of attack trafﬁc. Ap-
proximately 8% of NetFlow records are lost every day off
of the router adjacent to the target and, during the attack,
the router drops a larger percentage, up to 17%, undoubt-
edly due to the impact of the attack. This implies that the
volume, and possibly the sources, of the attack are underre-
ported.
4.3. Network map reconstruction
The trafﬁc records collected by SiLK provide IP ad-
dresses, times and volumes. However, for three of the tech-
niques discussed (PI, NAC and HCF), we require informa-
tion about the network in order to evaluate them. To gener-
ate this information, we used two forms of network maps.
4.3.1. Networks maps for path-based ﬁlters Evaluating
PI requires the most detailed network information: an in-
ventory of routers between the sources and the targets. To
build this inventory, we constructed partial internet maps
from the Skitter internet map data.5 Skitter collects rout-
ing information by regularly issuing traceroute calls
from sensors across the internet. From this information, we
constructed a table of routes to each of 26 Skitter sensors
and, in each evaluation run of a path-based ﬁlter, treated
one of these sensors as the machine targeted in the attack.
(Mapping routes to the network we monitor was not per-
missible.) As such, this experiment more precisely evalu-
ates how a server at this sensor (rather than the actually at-
tacked server) would fare under the attack.
HCF also uses route-speciﬁc information, but this infor-
mation is less detailed than that used by PI: the length (hop
count) of the route from the source to the target. To develop
a table of lengths, we used the lengths of the paths derived
from Skitter.
Since the exact IP addresses of the attackers in the at-
tack are not in the Skitter dataset, we reduced the Skitter
maps to a /24 resolution. More precisely, suppose we ﬁx a
Skitter sensor. For this sensor, each attacking IP address is
treated as the node mapped by the Skitter sensor with the
same /24 preﬁx as the attack IP address, if such a node ex-
ists. Even then, the Skitter map covered a very limited por-
tion of the addresses contacting the server: e.g., on aver-
age, the route map to a Skitter sensor contained nodes with
5
http://www.caida.org/tools/measurement/skitter
IP addresses matching the /24 preﬁxes of 4.63% of the at-
tack addresses, with a standard deviation of 2.33%. As a
result of this address reduction, we used a reduced inter-
net when evaluating PI and HCF. In this reduced internet,
the only IP addresses available are ones found in the Skit-
ter maps (using the /24 rule above). Addresses which do not
appear in the map are not used. Furthermore, when spoof-
ing trafﬁc for evaluating HCF and PI, spoofed addresses are
drawn only from the networks in the reduced internet, but
otherwise are chosen uniformly at random.
Total unique clusters for maps
 20000
 18000
 16000
 14000
s
r
e
 12000
t
s
u
C
e
u
q
n
U
l
i
 10000
 8000
 6000
 4000
 2000
 0
 0
 5
 10
 15
 20
Cluster Width
 25
 30
 35
Figure 2. Cluster lengths in union of three
BGP routing tables
4.3.2. Network maps for address-based ﬁlters NAC
uses BGP tables to determine the ﬁltering attribute value
for a packet. Though NAC recommends drawing BGP ta-
bles from across the internet [16], we used a more limited
set of tables for this evaluation, drawn from an ATT Canada
route server6, a Telus route server7, and a CERFnet route
server8. The information provided by the union of these ta-
bles is incomplete, providing routing preﬁxes of at least
16 bits for only roughly 10% of the total internet ad-
dress space. Given the limits of this data, we implemented
an approach where the cluster table was initialized with
“default” static clusters to use if no network-aware clus-
ter (routing preﬁx) was available. Figure 2 shows the
distribution of cluster lengths in the tables; since the over-
whelming majority of clusters are 16 bits or more, we ini-
tialized the network-aware cluster space using default
6
7
8
route-server.east.attcanada.com
route-views.on.bb.telus.com
route-server.cerf.net
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
16 bit static clusters. Due to this approximation, we be-
lieve our results give a moderately pessimistic view of the
performance of NAC.
5. Evaluation
In this section we evaluate each of the ﬁltering ap-
proaches described in Section 3 using the attack data de-
scribed in Section 4. In addition to this attack data, our eval-
uation employs two weeks of normal trafﬁc records for each
of ten different HTTP servers (one of which is the server ac-
tually attacked). At a high level, in our evaluation we build
a model of normal trafﬁc (in normalcy learning) based upon
thirteen days of normal trafﬁc for a server, or a model of at-
tack trafﬁc (in attacker learning) based upon the attack data
set. Once this model is built, we determine a false nega-
tive and false positive rate as described below. By averag-
ing over the models constructed using the sets of normal
server data from 10 different servers and, for path-based
ﬁlters, over the 26 network maps corresponding to the 26
Skitter sensors (260 combinations in total), we obtain av-
erage false positive and false negative rates for each ﬁlter
against the attack we consider. Since each scheme provides
parameters that can be tuned, tuning these parameters in
fact yields a curve of false positive rate versus false neg-
ative rate, that characterizes the points that can be achieved
by varying these parameters.
In all of our evaluations, the false positive percentage
for a server is the percentage of addresses in a day of nor-
mal trafﬁc other than the thirteen used to train that server’s
model that would be discarded by the ﬁlter. The false nega-
tive percentage for a server in a non-spoofed attack is anal-
ogous, i.e., the percentage of attacker addresses in our at-
tacker data set that the ﬁlter would permit to pass. In a
spoofed attack, the false negative percentage is computed
to be the percentage of spoofed packets that the ﬁlter would
permit to pass, assuming that each attacking computer emit-
ted trafﬁc at the same rate and spoofed the source address
of each packet by selecting it uniformly at random.
5.1. HCF
The ﬁltering attribute of HCF is the pair consisting of the
/24 preﬁx of the packet and its hop count, i.e., the length of
the path it traversed. As described in [13], this hop count
is an estimate only, though for the purposes of our analysis
here, we ignore the potential for error in this value and as-
sume that the target can exactly determine the hop count of
the packet. We revisit this (generous) assumption below.
HCF assumes normalcy learning only. The ﬁlter drops
packets for which the hop count does not match the hop
count seen for the same /24 during learning. A more per-
missive version drops only packets for which the hop count
differs from that seen for the same /24 by greater than ,
where  = 1 and  = 2 are considered by the authors [13].
In our experiment, we trained the HCF learning algo-
rithm on thirteen days of normal trafﬁc. For the servers
we considered, thirteen days of normal trafﬁc (without
map reduction) permitted the ﬁlter to observe only a rela-
tively small portion of the internet. For example, Figure 3(i)
demonstrates that in thirteen days, the actually attacked
server was exposed to a maximum of 160,000 /24’s, assum-
ing no map reduction, and that the number of new /24’s the
target saw per day generally decreased. Since the internet
consists of approximately 16 million /24 blocks, roughly 8
million of which are used, servers handling this much ac-
tivity would require well over a year to see even half of the
used internet space. We note that this learning time is an or-
der of magnitude longer than that projected in the original
HCF paper, which is roughly consistent with the thirteen
days of training that we chose for our experiment.9
Such a learning period has dramatic implications for
HCF. During a spoofed attack, the server typically sees a
huge number of previously unseen addresses (/24s). HCF
will drop such packets, leading to a very low false negative
rate. In this way, however, HCF induces a signiﬁcant false
positive rate, dropping trafﬁc from roughly 25% of normal
addresses on average in our tests, even in the most permis-
sive conﬁguration recommended by the authors ( = 2); see
Figure 3(ii). Here and throughout this paper, error bars show
one standard deviation.
Figure 3(ii) also shows a false negative rate for HCF for
 ∈ {0, 1, 2}. This false negative rate reﬂects the optimistic
assumption, described above, that the ﬁlter can determine
the accurate hop count of each packet. In reality, and as
noted in [13], an attacker can intelligently modify the ini-
tial TTLs of the packets it sends to achieve roughly a 10%
false negative rate, even without detailed knowledge of the
network topology.
A ﬁnal point about HCF regards the recommended al-
gorithm to prevent an attacker from “poisoning” the hop
count data during training with forged packets. The authors
of HCF recommend that during learning, only hop counts
associated with packets received on a completed TCP con-
nection be used to learn the hop count of a new /24. In this
way, forged TCP SYN packets will not poison the hop count
data; presumably the attacker will be unable to complete
the TCP handshake for a forged SYN. While reasonable,
we comment that this approach is effective only for servers
for which TCP connections are the dominant form of inter-
action. This is true for most, but certainly not all, types of
servers; for example, DNS servers communicate with the
majority of their clients using UDP.
9
“For a very busy site, a collection period of a few days could be suf-
ﬁcient, while for a lightly-loaded site, a few weeks might be more ap-
propriate.” [13, Section 5.2]
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
Total Seen
20000
18000
16000
14000
12000
10000
8000
6000
’
s
4
2
/
w
e
N
4000
0
2
4
6
8
Days
10
12
14
(i) New /24s seen per day at attacked server, without map
reduction (example)
t
e
g
a
n
e
c
r
e
P
e
v
i
t
a
g
e
N
e
s
a
F
l
 0.55
 0.5
 0.45
 0.4
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 5
Hop Count Filtering
ε = 2
ε = 0
 10
 15
 20
 25
 30
 35
 40
False Positive Percentage
(ii) False negative vs. false positive rate
Figure 3. HCF Results
As a spoof detection mechanism, HCF does not defend
against non-spoofed attacks, and so we did not evaluate it
under such conditions.
5.2. PI