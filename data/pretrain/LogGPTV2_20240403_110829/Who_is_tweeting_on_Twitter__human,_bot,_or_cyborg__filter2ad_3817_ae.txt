5.3 Classiﬁcation System Accuracy
To validate the accuracy of our proposed classiﬁcation system,
we create a test set containing one thousand users of each class. It
does not share any samples with the training set. The confusion
matrix listed in Table 3 shows the classiﬁcation results on the test
set.
The “Actual” rows in Table 3 denote the actual classes of the
users, and the “Classiﬁed” columns denote the classes of the users
as decided by the classiﬁcation system. For example, 949 in the
“Human” row and column means that 949 humans are classiﬁed
(correctly) as humans, whereas 51 in the “Human” row and “Cy-
borg” column means that 51 humans are classiﬁed (incorrectly) as
cyborgs. There is no misclassiﬁcation between human and bot.
and analyze each category as follows.
We examine the logs of those users being classiﬁed by mistake,
• For the human category, 5.1% of human users are classiﬁed
as cyborg by mistake. One reason is that, the overall scores of
some human users are lowered by spam content penalty. The
tweet size is up to 140 characters. Some patterns and phrases
are used by both human and bot, such as “I post my on-
line marketing experience at my blog at http://bit.ly/xT6klM.
Please ReTweet it." Another reason is that the tweeting inter-
val distribution of some human users is slightly lower than
the entropy means, and they are penalized for that.
• For the bot category, 6.3% of bots are wrongly categorized
as cyborg. The main reason is that, most of them escape the
spam penalty from the machine learning component. Some
spam tweets use very obscure text content, like “you should
check it out since it’s really awesome. http://bit.ly/xT6klM".
Without checking the spam link, the component cannot de-
termine if the tweet is spam merely based on the text.
• For the cyborg category, 9.8% of cyborgs are mis-classiﬁed
as human, and 7.4% of them are mis-classiﬁed as bot. A
cyborg can be either a human-assisted bot or a bot-assisted
human. A strict policy could categorize cyborg as bot, while
a loose one may categorize it as human.
Overall, our classiﬁcation system can accurately differentiate hu-
man from bot. However, it is much more challenging for a classiﬁ-
cation system to distinguish cyborg from human or bot.
28
Table 3: Confusion Matrix
Classiﬁed
Human Cyborg Bot
0
74
937
949
98
0
51
828
63
Total True Pos.%
1000
1000
1000
94.90%
82.80%
93.70%
Human
Actual Cyborg
Bot
5.4 Twitter Composition
We further use the classiﬁcation system to automatically clas-
sify our whole dataset of over 500,000 users. We can speculate the
current composition of Twitter user population based on the classi-
ﬁcation results. The system classiﬁes 48.7% of the users as human,
37.5% as cyborg, and 13.8% as bot. Thus, we speculate the pop-
ulation proportion of human, cyborg and bot category roughly as
5:4:1 on Twitter.
5.5 Resistance to Evasion
Now we discuss the resistance of the classiﬁcation system to
possible evasion attempts made by bots. Bots may deceive cer-
tain features, such as the followers to friends ratio as mentioned
before. However, our system has two critical features that are very
hard for bots to evade. The ﬁrst feature is tweeting device makeup,
which corresponds to the manual/auto device percentage in Table
2. Manual device refers to web and mobile devices, while auto
device refers to API and other auto-piloted programs (see Section
4.3). Tweeting via web requires a user to login and manually post
via the Twitter website in a browser. Posting via HTTP form is con-
sidered by Twitter as API. Furthermore, currently it is impractical
or expensive to run a bot on a mobile device to frequently tweet. As
long as Twitter can correctly identify different tweeting platforms,
device makeup is an effective metric for bot detection. The second
feature is URL ratio. Considering the limited tweet length that is up
to 140 characters, most bots have to include a URL to redirect users
to external sites. Thus, a high URL ratio is another effective met-
ric for bot detection. Other features like timing entropy, bot could
mimic human behaviors but at the cost of much reduced tweeting
frequency. We will continue to explore new features emerging with
the Twitter development for more effective bot detection in the fu-
ture.
6. CONCLUSION
In this paper, we have studied the problem of automation by bots
and cyborgs on Twitter. As a popular web application, Twitter has
become a unique platform for information sharing with a large user
base. However, its popularity and very open nature have made
Twitter a very tempting target for exploitation by automated pro-
grams, i.e., bots. The problem of bots on Twitter is further com-
plicated by the key role that automation plays in everyday Twitter
usage.
To better understand the role of automation on Twitter, we have
measured and characterized the behaviors of humans, bots, and
cyborgs on Twitter. By crawling Twitter, we have collected one-
month of data with over 500,000 Twitter users with more than 40
million tweets. Based on the data, we have identiﬁed features that
can differentiate humans, bots, and cyborgs on Twitter. Using en-
tropy measures, we have determined that humans have complex
timing behavior, i.e., high entropy, whereas bots and cyborgs are
often given away by their regular or periodic timing, i.e., low en-
tropy. In examining the text of tweets, we have observed that a high
proportion of bot tweets contain spam content. Lastly, we have dis-
covered that certain account properties, like external URL ratio and
tweeting device makeup, are very helpful on detecting automation.
Based on our measurements and characterization, we have de-
signed an automated classiﬁcation system that consists of four main
parts:
the entropy component, the machine learning component,
the account properties component, and the decision maker. The
entropy component checks for periodic or regular tweet timing pat-
terns; the machine learning component checks for spam content;
and the account properties component checks for abnormal values
of Twitter-account-related properties. The decision maker summa-
rizes the identiﬁed features and decides whether the user is a hu-
29
man, bot, or cyborg. The effectiveness of the classiﬁcation system
is evaluated through the test dataset. Moreover, we have applied the
system to classify the entire dataset of over 500,000 users collected,
and speculated the current composition of Twitter user population
based on the classiﬁcation results.
7. REFERENCES
[1] Amazon comes to twitter.
http://www.readwriteweb.com/archives/
amazon_comes_to_twitter.php [Accessed: Dec. 20,
2009].
[2] Barack obama uses twitter in 2008 presidential campaign.
http://twitter.com/BarackObama/ [Accessed:
Dec. 20, 2009].
[3] Best buy goes all twitter crazy with @twelpforce.
http://twitter.com/in_social_media/
status/2756927865 [Accessed: Dec. 20, 2009].
[4] The crm114 discriminator.
http://crm114.sourceforge.net/ [Accessed:
Sept. 12, 2009].
[5] Alexa. The top 500 sites on the web by alexa.
http://www.alexa.com/topsites [Accessed: Jan.
15, 2010].
[6] Meeyoung Cha, Haewoon Kwak, Pablo Rodriguez,
Yong-Yeol Ahn, and Sue Moon. I tube, you tube, everybody
tubes: analyzing the world’s largest user generated content
video system. In Proceedings of the 7th ACM SIGCOMM
Conference on Internet Measurement, San Diego, CA, USA,
2007.
[7] Meeyoung Cha, Alan Mislove, and Krishna P. Gummadi. A
measurement-driven analysis of information propagation in
the ﬂickr social network. In Proceedings of the 18th
International Conference on World Wide Web, Madrid,
Spain, 2009.
[8] Thomas M. Cover and Joy A. Thomas. Elements of
information theory. Wiley-Interscience, New York, NY,
USA, 2006.
[9] Marcel Dischinger, Andreas Haeberlen, Krishna P.
Gummadi, and Stefan Saroiu. Characterizing residential
broadband networks. In Proceedings of the 7th ACM
SIGCOMM conference on Internet Measurement, San Diego,
CA, USA, 2007.
[10] Il-Chul Moon Dongwoo Kim, Yohan Jo and Alice Oh.
Analysis of twitter lists as a potential source for discovering
latent characteristics of users. In To appear on CHI 2010
Workshop on Microblogging: What and How Can We Learn
From It?, 2010.
[11] Henry J. Fowler and Will E. Leland. Local area network
trafﬁc characteristics, with implications for broadband
network congestion management. IEEE Journal of Selected
Areas in Communications, 9(7), 1991.
[12] Steven Gianvecchio and Haining Wang. Detecting covert
timing channels: An entropy-based approach. In Proceedings
of the 2007 ACM Conference on Computer and
Communications Security, Alexandria, VA, USA,
October-November 2007.
[13] Steven Gianvecchio, Zhenyu Wu, Mengjun Xie, and Haining
Wang. Battle of botcraft: ﬁghting bots in online games with
human observational proofs. In Proceedings of the 16th ACM
conference on Computer and Communications Security,
Chicago, IL, USA, 2009.
[14] Steven Gianvecchio, Mengjun Xie, Zhenyu Wu, and Haining
Wang. Measurement and classiﬁcation of humans and bots in
internet chat. In Proceedings of the 17th USENIX Security
symposium, San Jose, CA, 2008.
[15] Minas Gjoka, Maciej Kurant, Carter T Butts, and Athina
Markopoulou. Walking in facebook: A case study of
unbiased sampling of osns. In Proceedings of the 27th IEEE
International Conference on Computer Communications,
San Diego, CA, USA, March 2010.
[16] Google. Google safe browsing API. http:
//code.google.com/apis/safebrowsing/
[21] A. L. Hughes and L. Palen. Twitter adoption and use in mass
[39] Twitter. Twitter api wiki.
[Accessed: Feb. 5, 2010].
[17] Paul Graham. A plan for spam, 2002.
http://www.paulgraham.com/spam.html
[Accessed: Jan. 25, 2008].
[18] Monika R. Henzinger, Allan Heydon, Michael
Mitzenmacher, and Marc Najork. On near-uniform url
sampling. In Proceedings of the 9th International World
Wide Web Conference on Computer Networks, Amsterdam,
The Netherlands, May 2000.
[19] Christopher M. Hill and Linda C. Malone. Using simulated
data in support of research on regression analysis. In WSC
’04: Proceedings of the 36th conference on Winter
simulation, 2004.
[20] B A Huberman and T Hogg. Complexity and adaptation.
Phys. D, 2(1-3), 1986.
convergence and emergency events. In Proceedings of the
6th International ISCRAM Conference, Gothenburg,
Sweden, May 2009.
[22] H. Husna, S. Phithakkitnukoon, and R. Dantu. Trafﬁc
shaping of spam botnets. In Proceedings of the 5th IEEE
Conference on Consumer Communications and Networking,
Las Vegas, NV, USA, January 2008.
[23] Bernard J. Jansen, Mimi Zhang, Kate Sobel, and Abdur
Chowdury. Twitter power: Tweets as electronic word of
mouth. American Society for Information Science and
Technology, 60(11), 2009.
[24] Akshay Java, Xiaodan Song, Tim Finin, and Belle Tseng.
Why we twitter: understanding microblogging usage and
communities. In Proceedings of the 9th WebKDD and 1st
SNA-KDD 2007 Workshop on Web Mining and Social
Network Analysis, San Jose, CA, USA, 2007.
[25] Balachander Krishnamurthy, Phillipa Gill, and Martin Arlitt.
A few chirps about twitter. In Proceedings of the First
Workshop on Online Social Networks, Seattle, WA, USA,
2008.
[26] G. J. McLachlan. Discriminant Analysis and Statistical
Pattern Recognition. Wiley Interscience, 2004.
[27] Alan Mislove, Massimiliano Marcon, Krishna P. Gummadi,
Peter Druschel, and Bobby Bhattacharjee. Measurement and
analysis of online social networks. In Proceedings of the 7th
ACM SIGCOMM Conference on Internet Measurement, San
Diego, CA, USA, 2007.
[28] A Porta, G Baselli, D Liberati, N Montano, C Cogliati,
T Gnecchi-Ruscone, A Malliani, and S Cerutti. Measuring
regularity by means of a corrected conditional entropy in
sympathetic outﬂow. Biological Cybernetics, Vol. 78(No. 1),
January 1998.
[29] P. Real. A generalized analysis of variance program utilizing
binary logic. In ACM ’59: Preprints of papers presented at
the 14th national meeting of the Association for Computing
Machinery, New York, NY, USA, 1959.
[30] Erick Schonfeld. Costolo: Twitter now has 190 million users
tweeting 65 million times a day.
http://techcrunch.com/2010/06/08/
twitter-190-million-users/ [Accessed: Sept. 26,
2010].
[31] Fabrizio Sebastiani. Machine learning in automated text
categorization. ACM Computing Surveys, Vol. 34(No. 1),
2002.
[32] Kate Starbird, Leysia Palen, Amanda Hughes, and Sarah
Vieweg. Chatter on the red: What hazards threat reveals
about the social life of microblogged information. In
Proceedings of the ACM 2010 Conference on Computer
Supported Cooperative Work, February 2010.
[33] Statsoft. Statistica, a statistics and analytics software package
developed by statsoft. http://www.statsoft.com/
support/download/brochures/ [Accessed: Mar. 12,
2010].
[34] Brett Stone-Gross, Marco Cova, Lorenzo Cavallaro, Bob
Gilbert, Martin Szydlowski, Richard Kemmerer, Christopher
Kruegel, and Giovanni Vigna. Your botnet is my botnet:
analysis of a botnet takeover. In Proceedings of the 16th
ACM conference on Computer and Communications
Security, Chicago, IL, USA, 2009.
[35] J. Sutton, Leysia Palen, and Irina Shlovski. Back-channels on
the front lines: Emerging use of social media in the 2007
southern california wildﬁres. In Proceedings of the 2008
ISCRAM Conference, Washington, DC, USA, May 2008.
[36] Alan M. Turing. Computing machinery and intelligence.
Mind, Vol. 59:433–460, 1950.
[37] Tweetadder. Automatic twitter software.
http://www.tweetadder.com/ [Accessed: Feb. 5,
2010].
[38] Twitter. How to report spam on twitter.
http://help.twitter.com/entries/64986
[Accessed: May. 30, 2010].
http://apiwiki.twitter.com/ [Accessed: Feb. 5,
2010].
[40] Mengjun Xie, Zhenyu Wu, and Haining Wang. Honeyim:
Fast detection and suppression of instant messaging malware
in enterprise-like networks,. In Proceedings of the 23rd
Annual Computer Security Applications Conference, Miami
Beach, FL, USA, 2007.
[41] Mengjun Xie, Heng Yin, and Haining Wang. An effective
defense against email spam laundering. In Proceedings of the
13th ACM conference on Computer and Communications
Security, Alexandria, VA, USA, 2006.
[42] Jeff Yan. Bot, cyborg and automated turing test. In
Proceedings of the 14th International Workshop on Security
Protocols, Cambridge, UK, March 2006.
[43] Sarita Yardi, Daniel Romero, Grant Schoenebeck, and Danah
Boyd. Detecting spam in a twitter network. First Monday,
15(1), January 2010.
[44] Jonathan A. Zdziarski. Ending Spam: Bayesian Content
Filtering and the Art of Statistical Language Classiﬁcation.
No Starch Press, 2005.
[45] Dejin Zhao and Mary Beth Rosson. How and why people
twitter: the role that micro-blogging plays in informal
communication at work. In Proceedings of the ACM 2009
International Conference on Supporting Group Work,
Sanibel Island, FL, USA, 2009.
30