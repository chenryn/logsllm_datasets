half the nominal 
ROB entries (50)
half the nominal 
size store queue (8)
–
–
Leakage 
Increase
2x in the 
L1 caches
2x for the 
whole core
2x in the 
store and 
load queues
–
–
2x in the 
integer 
cluster
2x in the 
FP cluster
2x in the 
front-end 
In  a  CMP  where  cores  could  be  affected  in  a 
multitude  of  ways,  there  are  numerous  heterogeneous 
core  configurations  that  could  arise.  In  this  study,  we 
assume  the  degraded  CMP  configuration  shown  in 
Table 3. We assumed each core experienced some form 
of  faults  or  variation  but  each  processor  was  only 
affected by at most a few problems.
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE47DSN 2008: Winter & AlbonesiTo 
the 
test 
the  effectiveness  of  our  scheduling 
algorithms,  we  created 
four  eight-threaded 
workloads  of  SPEC  CPU2000  applications  shown  in 
Table  4.  Each  benchmark  was used evenly among the 
four workloads. For each simulation, we fast forwarded 
every  benchmark  five  billion  instructions,  and  then 
executed one billion cycles in SESC, or 0.25 seconds at 
a nominal frequency of 4 GHz. Cores that run at lower 
frequencies execute for proportionally fewer cycles.
Workload 1
applu, bzip2, equake, gcc, mcf, mesa, 
Table 4: Workloads
parser, swim
Workload 2
ammp, apsi, art, crafty, twolf, vortex, 
vpr, wupwise
Workload 3 mesa, ammp, applu, crafty, vortex, gcc, 
wupwise, mcf
Workload 4
swim, parser, vpr, bzip2, art, apsi, 
twolf, equake
The OS scheduler periodically switches between the 
exploration  and  steady-state  phases  of  the  algorithm. 
During the exploration phase, which constitutes 10% of 
the  total  execution  time,  the  algorithm  adapts  to 
workload  changes  to  find  the  best  assignment  of 
threads to cores. During the longer steady-state phase, 
the  CMP  runs  with  this  best  configuration.  The 
performance  of  the  algorithm  is  based  on  both  the 
exploration  and  steady-state  phases.  The  length  and 
number  of 
intervals are  algorithm 
dependent  parameters  and  are  chosen  to  the  best 
advantage  of  each  technique.  For  each  workload,  we 
performed five different runs with different application-
to-core  starting  assignments,  and  report  the  average, 
best, and worst results. 
the  sampling 
For 
the  simpler  randomized  and  round  robin 
algorithms,  we  modeled  10  million  cycle  operating 
system  time  slices,  the  equivalent  of  2.5  milliseconds. 
These  algorithms  do  not  require  exploration  and 
instead  they  use  each  time  slice  interval  to  perform 
their reassignments.
5. Results and Discussion
In this section, we present the results of the various 
scheduling  algorithms  on  our  degraded  eight  core 
CMP.  All  comparisons  are  made  using  the  energy-
delay squared (ED2) metric against  a baseline with no 
errors or variations and an oracle scheduler which uses 
a  priori knowledge to derive the best schedule among 
all  possible  options.  We  chose  ED2  as  the  metric  in 
order  to  balance  performance  with  power  dissipation 
[19].  Section  5.1 discusses  how  simple  schedulers 
compare  to  the  non-degraded  baseline.  Section  5.2 
shows  how  the  Hungarian  and  AI  search  algorithms 
fare against  the  offline  oracle.  Finally,  Section  5.3 
provides  an  overall  comparison  of  the  scheduling 
algorithms.
5.1. Simple Scheduling Algorithms
We  first  evaluate  the  effectiveness  of  two  simple 
scheduling algorithms – round robin and randomized –
that are suitable for homogeneous CMPs and statically 
designed  heterogeneous  CMPs,  on  the  degraded CMP 
of  Table  3.  The  round  robin  scheduler  rotates  the 
threads  on  the  cores  at  the  beginning  of  each  OS 
interval. This approach avoids a worst case assignment 
by limiting how long an application runs on any given 
core.  The  even  assignment  of  applications 
to 
processors  also  avoids  high  power  density  scenarios 
and uneven wear-out of a core through over-activity or 
high temperature. 
The randomized scheduler randomly assigns threads 
to cores every operating system interval. This approach 
avoids degenerate behavior that might occur with round 
robin  such  as  destructive  interference  with  program 
phases. 
Figure 6 shows the results of these schedulers on the 
degraded  CMP  relative 
to  a  baseline  with  no 
degradation.  Both  approaches  degrade  ED2  by  over 
22% on average. The final bar on the graph, the worst-
case  schedule,  shows  that  an  arbitrary  assignment  of 
threads  to  cores  can  degrade  ED2  by  almost  45% 
compared  to  the  baseline.  Clearly,  naïve  policies  can 
result  in  an  unacceptable  loss  in  power/performance 
that may render the degraded microprocessor unusable. 
o
t
e
v
i
t
a
l
e
R
2
y
a
l
e
D
x
y
g
r
e
n
E
n
i
e
s
a
e
r
c
n
I
n
o
i
t
a
d
a
r
g
e
D
o
N
h
t
i
w
e
n
i
l
e
s
a
B
50.00%
45.00%
40.00%
35.00%
30.00%
25.00%
20.00%
15.00%
10.00%
5.00%
0.00%
Workload 1 Workload 2 Workload 3 Workload 4
Average
Benchmark Group
Round Robin
Randomized
Worst Case
Figure 6: Comparison of simple schedulers
5.2. Hungarian Policy and Search Algorithms
The  Hungarian  scheduling  policy  samples  each 
benchmark on each core during the exploration phase, 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE48DSN 2008: Winter & Albonesiand  then  computes  the  best  assignment  among  all 
permutations  (assuming  no 
interactions  or  phase 
behavior).  For  the  Hungarian  policy,  the  exploration 
phase is divided into eight intervals, each 12.5 million 
cycles  long,  during  which  the  eight  applications  are 
executed once on each core, by starting with an initial 
assignment  and  then  rotating  the  threads  in  a  round 
robin fashion seven times. This allows the scheduler to 
generate  the  8×8  cost  matrix  of  ED2  values  to  use  as 
input to the algorithm. 
o
t
e
v
i
t
a
l
e
R
2
y
a
l
e
D
x
y
g
r
e
n
E
n
i
e
s
a
e
r
c
n
I
r
e
l
u
d
e
h
c
S
e
l
c
a
r
O
e
n
i
l
f
f
O
50.00%
45.00%
40.00%
35.00%
30.00%
25.00%
20.00%
15.00%
10.00%
5.00%
0.00%
Workload 1 Workload 2 Workload 3 Workload 4
Average
Benchmark Group
Hungarian Policy
Local Search 4
Figure 7: Comparison of advanced schedulers
Local Search 1
Local Search 2
Global Search
Figure 7 shows the ED2 of the Hungarian scheduling 
algorithm compared to the oracle scheduler. The solid 
bar  represents  the  average  of  the  five  runs,  and  the 
error  bars  show  the  best  and  worst  results.  The 
algorithm  performs  well,  suffering  only  a  7.3% 
increase in ED2 relative to the oracle. The performance 
and power characteristics of the benchmarks during the 
initial  100  million  cycle  exploration  phase  are  quite 
reflective of the overall traits of the benchmarks. Thus, 
using  the  Hungarian  Algorithm  to  calculate  the  best 
solution  among  all  possible  scheduling  permutations 
based  on  this  sampling  information  yields  a  good 
assignment  over  the  whole  run,  regardless  of  the 
starting assignment.
it 
found 
While effective, the Hungarian scheduling algorithm 
has O(N3) complexity, while the other algorithms are of 
O(N).  We  simulated  the  Hungarian  Algorithm  on  our 
baseline  core  configuration  and 
takes 
approximately 200K cycles to solve a cost matrix with 
eight cores, a non-trivial cost that may not scale well to 
larger-scale  CMPs.  Since  the  number  of  sampling 
intervals  scales  linearly  with  the  number  of  cores,  a 
large  amount  of  online  profiling  will  also  be  required 
for chips with tens or hundreds of cores. Moreover, the 
algorithm may not work well when there are significant 
interactions  among  applications  or 
rapid  phase 
changes. 
The  global  and  local  search  algorithms  divide  the 
exploration  phase  into  25  intervals  of  four  million
cycles. Both start with the initial configuration and try 
other  configurations,  greedily  pursuing  paths  that 
improve  on  the  best  schedule  to  date.  Global  search 
simply  tries  the  initial  configuration  and  24  other 
randomly chosen ones and then selects the best among 
them 
the  steady-state  phase.  This  strategy 
sometimes  works  quite  well  but  can  perform  poorly
depending  on  the  25  configurations  pursued.  Overall, 
global  search  degrades  ED2  by  19.5%  over  the  oracle 
scheduler.
for 
a 
to 
explore 
performed 
Three  versions  of  the  local  search  method  were 