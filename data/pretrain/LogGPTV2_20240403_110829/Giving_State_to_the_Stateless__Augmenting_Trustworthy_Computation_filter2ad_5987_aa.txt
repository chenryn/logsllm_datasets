title:Giving State to the Stateless: Augmenting Trustworthy Computation
with Ledgers
author:Gabriel Kaptchuk and
Matthew Green and
Ian Miers
Giving State to the Stateless:
Augmenting Trustworthy Computation with Ledgers
Gabriel Kaptchuk, Matthew Green
Johns Hopkins University
{gkaptchuk, mgreen}@cs.jhu.edu
Ian Miers
Cornell Tech
PI:EMAIL
Abstract—In this work we investigate new computational
properties that can be achieved by combining stateless trusted
devices with public ledgers. We consider a hybrid paradigm in
which a client-side device (such as a co-processor or trusted
enclave) performs secure computation, while interacting with a
public ledger via a possibly malicious host computer. We explore
both the constructive and potentially destructive implications of
such systems. We ﬁrst show that this combination allows for the
construction of stateful interactive functionalities (including gen-
eral computation) even when the device has no persistent storage;
this allows us to build sophisticated applications using inexpensive
trusted hardware or even pure cryptographic obfuscation tech-
niques. We further show how to use this paradigm to achieve
censorship-resistant communication with a network, even when
network communications are mediated by a potentially malicious
host. Finally we describe a number of practical applications
that can be achieved today. These include the synchronization of
private smart contracts; rate limited mandatory logging; strong
encrypted backups from weak passwords; enforcing fairness in
multi-party computation; and destructive applications such as
autonomous ransomware, which allows for payments without an
online party.
I.
INTRODUCTION
In recent years a new class of distributed system has
evolved. Loosely categorized as decentralized ledgers, these
systems construct a virtual “bulletin board” to which nodes
may publish data. Many protocols, including cryptocurrencies
such as Bitcoin [47], construct such a ledger to record ﬁnancial
transactions. More recent systems target other speciﬁc applica-
tions, such as identity management [30], [1], or the execution
of general, user-deﬁned programs, called “smart contracts” [6].
Some companies have also deployed centralized public ledgers
for speciﬁc applications; for example, Google’s Certiﬁcate
Transparency [3] provides a highly-available centralized ledger
for recording issued TLS certiﬁcates.
While the long-term success of speciﬁc systems is uncer-
tain, two facts seem clear: (1) centralized and decentralized
ledger systems are already in widespread deployment, and
this deployment is likely to continue. Moreover (2) the decen-
tralized nature of these systems makes them potentially long-
lived and resilient to certain classes of network-based attack.
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2019 
24-27  February  2019,  San  Diego,  CA,  USA
ISBN  1-891562-55-X
http://dx.doi.org/10.14722/ndss.2019.23060
www.ndss-symposium.org
This provides a motivation to identify new ways that these
technologies can be used to enhance the security of distributed
systems.
In this work we focus on one such application: using
ledgers to enhance the security of Trusted Execution Envi-
ronments (TEE). In the context of this work, we use TEE
to refer to any limited, secure computing environment that is
dependent on a (possibly malicious) host computer for correct
operation. Examples of such environments include Hardware
Security Modules, smart cards [51], and the “secure element”
co-processors present in many mobile devices [12], as well
as virtualized TEE platforms such as Intel’s Software Guard
Extensions (SGX), ARM TrustZone, and AMD SEV [5], [14],
[8]. While many contemporary examples rely on hardware, it
is conceivable that future trusted environments may be im-
plemented using pure software virtualization, general-purpose
hardware obfuscation [26], [23], [48], or even cryptographic
program obfuscation [42].
While TEEs have many applications in computing, they
(like all secure co-processors) have fundamental limitations.
A trusted environment operating perfectly depends on the host
computer for essential functionality, creating an opportunity
for a malicious host to manipulate the TEE and its view of the
world. For example, an attacker may:
1)
2)
Tamper with network communications, censoring cer-
tain inputs or outputs and preventing the TEE from
communicating with the outside world.
Tamper with stored non-volatile data, e.g. replaying
old stored state to the TEE in order to reset the state
of a multi-step computation.
We stress that these attacks may have a catastrophic impact
even if the TEE itself operates exactly as designed. For exam-
ple, many interactive cryptographic protocols are vulnerable
to “reset attacks,” in which an attacker rewinds or resets the
state of the computation [17], [7], [27]. State reset attacks
are not merely a problem for cryptographic protocols; they
are catastrophic for many typical applications such as limited-
attempt password checking [57].
When implemented in hardware, TEE systems can mitigate
reset attacks by deploying a limited amount of tamper-resistant
non-volatile storage [50].1 However, such countermeasures
increase the cost of producing the hardware and are simply
1 The literature affords many examples of attackers bypassing such mech-
anisms [58], [38], [57] using relatively inexpensive physical and electronic
attacks.
not possible in software-only environments. Moreover, these
countermeasures are unavailable to environments where a
single state transition machine is run in a distributed fashion,
with the transition function executed across different machines.
In these environments, which include private smart contract
systems [31] and “serverless” cloud step-function environ-
ments [9], [28], state protections cannot be enforced locally by
hardware. Similarly, hardware countermeasures cannot solve
the problem of enforcing a secure channel to a public data
network.
A hypothetical solution to these problems is to delegate
statekeeping and network connectivity to a remote, trusted
server or small cluster of peers, as discussed in [44]. These
could keep state on behalf of the enclave and would act as
conduit to the public network. However, this approach simply
shifts the root of trust to a different physical location, failing
to solve our problem because this new system is vulnerable
to the same attacks. Moreover, provisioning and maintaining
the availability of an appropriate server can be a challenge for
many applications, including IoT deployments that frequently
outlive the manufacturer.
Combining TEEs with Ledgers. In this work we consider
an alternative approach to ensuring the statefulness and con-
nectivity of trusted computing devices. Unlike the strawman
proposals above, our approach does not require the TEE to
include secure internal non-volatile storage, nor does it require
a protocol-aware external server to keep state. Instead, we
propose a model in which parties have access to an append-
only public ledger, or bulletin board with certain properties.
Namely, upon publishing a string S on the ledger, a party
receives a copy of the resulting ledger – or a portion of it
– as well as a proof (e.g. a signature) to establish that the
publication occurred. Any party, including a trusted device,
can verify this proof to conﬁrm that the received ledger data
is authentic. The main security requirement we require from
the ledger is that its contents cannot be modiﬁed or erased
and proofs of publication cannot be (efﬁciently) forged. This
model has been previously investigated independently in a
more limited fashion by other works, notably in the context of
fair multiparty computation [22], [29]. In this work we propose
a broader paradigm for secure computation.
Our contributions. In this work we propose a new general
protocol, which we refer to as an Enclave-Ledger Interaction
(ELI). This proposal divides any multi-step interactive com-
putation into a protocol run between three parties: a stateless
client-side TEE, which we refer to as an enclave (for the rest
of this work, we use these two terms interchangeably) that
contains a secret key; a ledger that logs posted strings and
returns a proof of publication; and a (possibly adversarial) host
application that facilitates all communications between the two
preceding parties. Users may provide inputs to the computation
via the host, or through the ledger itself. We illustrate our
model in Figure 1.
We assume that the enclave is a trustworthy computing
environment, such as a tamper-resistant hardware co-processor,
SGX enclave, or a cryptographically obfuscated circuit [48],
[42]. Most notably, the enclave need not store persistent state
or possess a secure random number generator; we only require
that the enclave possesses a single secret key K that is not
known to any other party. We similarly require that the host
application can publish strings to the ledger; access the ledger
contents; and receive proofs of publication.
As a ﬁrst contribution, we show how this paradigm can
facilitate secure state management for randomized multi-step
computations run by the enclave, even when the enclave has
no persistent non-volatile storage or access to trustworthy ran-
domness. Building such a protocol is non-trivial, as it requires
simultaneously that the computation cannot be rewound or
forked, even by an adversarial host application that controls
all state and interaction with the ledger.
As a second contribution, we show that the combination
of enclave plus ledger can achieve properties that may not
be achievable even when the enclave uses stateful
trusted
hardware. In particular, we show how the enclave-ledger
interaction allows us to condition program execution on the
publication of particular messages to the ledger, or the receipt
of messages from third parties. For example, an application can
require that devlopers be alerted on the ledger that user activity
is anomolous, perhaps even dangerous, before it continues
execution.
As a third contribution, we describe several practical appli-
cations that leverage this paradigm. These include private smart
contracts, limited-attempt password checking (which is known
to be difﬁcult to enforce without persistent state [57]), enforced
ﬁle access logging, and new forms of encryption that ensure
all parties receive the plaintext, or that none do. As a practical
matter, we demonstrate that on appropriate ledger systems
that support payments, execution can be conditioned on other
actions, such as monetary payments made to the ledger. In
malicious hands, this raises the specter of autonomous ran-
somware that operates veriﬁably and without any need for a
command-and-control or secret distribution center.
Previous and concurrent work. A manuscript of this work
was initially published in February 2017 [37]. Several pre-
vious and concurrent works haved focused on similar goals,
speciﬁcally preventing rollback attacks on trusted execution
environments and private computation on the ledger.
[50]
In previous work, Memoir
leverages hashchains,
NVRAM, and monotonic counters to efﬁciently prevent state
rollback in the presence of a malicious host. While Memoir’s
protocol has many similarities to our ELI protocols, the system
design is quite different. In Memoir, each TEE device uses its
internal NVRAM to checkpoint state, while our systems rely
on a public ledger and communication through an untrustwor-
thy host. A second proposal, ROTE [44], uses a consensus
between a cluster of distributed enclaves to in order to address
the rollback problem. Neither Memoir nor ROTE deals with the
problem of conditioning execution on data publication, which
is a second contribution of our work. Several early works have
focused on the problem of preventing reset attacks via de-
randomization, i.e., by deriving (pseudo)random coins from
the computation input [20]. Unfortunately this approach does
not generalize to multi-step calculations where the adversary
can adaptively select the input prior to each step.
Two concurrent research efforts have considered the use
of ledgers to achieve secure computation. In late 2017, Goyal
and Goyal proposed the use of blockchains for implement-
ing one time programs [29] using cryptographic obfuscation
2
Fig. 1. Two example ELI deployments. In the basic scenario (a) a single TEE (with a hard-coded secret key K) interacts with a ledger functionality via a
(possibly adversarial) host application. Program inputs are provided by a user via the host machine. In scenario (b) multiple copies of the same enclave running
on different host machines interact with the ledger (e.g., as in a private smart contract system), which allows them to synchronize a multi-step execution across
many different machines without the need for direct communication. Program inputs and outputs may be provided via the ledger.
techniques. While our work has a similar focus, we aim
for a broader class of functionalities and a more practical
set of applications. Also in 2017, the authors of the present
work, along with others, proposed to use ledgers to obtain
fairness for MPC protocols, an application that is discussed
in later sections of this work [22]. Bowman et al. of Intel
Corporation [19] independently proposed “Private Data Ob-
jects” for smart contract systems that use ideas related to
this work, and have begun to implement them in production
smart contract systems that support private computation. We
believe Bowman’s effort strongly motivates the formal analysis
we include in this work. There have also been a number of
attempts to combine trusted execution environments and public
ledgers, but aimed at slightly different goals [39], [35], [65].
Finally, the Ekiden system [21], proposed in April 2018, builds
on the ideas proposed in this work and [22] to achieve goals
similar to those of Intel’s Private Data Objects.
A. Intuition
We now brieﬂy present the intuition behind our construc-
tion. Our goal is to securely execute a multi-step interactive,
probabilistic program P , which we will deﬁne as having the
following interface:
P (Ii, Si; ¯ri) → (Oi, Si+1)
At each step of the program execution, the program takes a
user input Ii, an (optional) state Si from the previous execution
step, along with some random coins ¯ri. It produces an output
Oi as well as an updated state Si+1 for subsequent steps.
(Looking forward, we will add public ledger inputs and outputs
to this interface as well, but we now omit these for purposes
of exposition.) For this initial exposition, we will assume a
simple ledger that, subsequent to each publication, returns the
full ledger contents L along with a proof of publication σ.2 We
also require a stateless enclave with no native random number
generator, that stores a single, hardcoded, secret key K.
Figure 1 illustrates the way the user, host, ledger and enclave
can interact. We now discuss several candidate approaches,
beginning with obviously insecure ideas, and building on them
to describe a ﬁrst version of our main construction.
2In later sections we will discuss improvements that make this Ledger
response succinct.
Attempt #1: Encrypt program state. An obvious ﬁrst step
is for the enclave to simply encrypt each output state using
its internal secret key, and to send the resulting ciphertext to
the host for persistent storage. Assuming that we use a proper
authenticated encryption scheme (and pad appropriately), this
approach should guard both the conﬁdentiality and authenticity
of state values even when they are held by a malicious host.3
It is easy to see that while this prevents tampering with the
contents of stored state, it does not prevent a malicious host
from replaying old state ciphertexts to the enclave along with
new inputs. In practice, such an attacker can rewind and fork
execution of the program.
Attempt #2: Use the ledger to store state. A superﬁcially
appealing idea is to use the ledger itself to store an encrypted
copy of the program state. As we will show, this does not
mitigate rewinding attacks.
For example, consider the following strawman protocol:
after the enclave executes the program P on some input, the
enclave sends the resulting encrypted state to the ledger (via
the host). The enclave can then condition future execution of
P on receiving valid ledger contents L, as well as a proof of
publication σ, and extracting the encrypted state from L.
Unfortunately this does nothing to solve the problem of
adversarial replays. Because the enclave has no trusted source
of time and relies on the host to communicate with the ledger,
a malicious host can simply replay old versions of L (including
the associated proofs-of-publication) to the enclave, while
specifying different program inputs. As before, this allows the
host to fork the execution of the program.
Attempt #3: Bind program inputs on the ledger. To address
the replay problem, we require a different approach. As in our
ﬁrst attempt, we will have the enclave send encrypted state to
the host (and not the ledger) for persistent storage. As a further
modiﬁcation, we will add to this encrypted state an iteration
counter i which identiﬁes the next step of the program to be
executed.
To execute the ith invocation of the program, the host ﬁrst
commits its next program input Ii to the ledger. This can be
3For the moment we will ignore the challenge of preventing re-use of nonces
in the encryption scheme; these issues will need to be addressed in our main