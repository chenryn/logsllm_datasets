More closely related to the VloGraph approach proposed in this paper, a stream of
literaturehasemergedthatrecognizestheinterrelatednatureoflogdataandconceiveslog
Mach.Learn.Knowl.Extr.2022,4 376
eventsandtheirconnectionsasgraphs—i.e.,labeledpropertygraphs(LPGs)orsemantically
explicitRDFknowledgegraphs.
In the former category, LPGs are stored in graph databases and queried through
specializedgraphquerylanguages. Fornetworklogfiles,forinstance,Ref.[37]proposes
anapproachthatmaterializestheloginaNeo4Jgraphdatabaseandmakesitavailable
forqueryingandvisualization. Theapproachislimitedtoasinglelogsourceandfocuses
exclusively on network log analysis. Similar to this, CyGraph [38] is a framework that
integratesisolateddataandeventsinaunifiedgraph-basedcybersecuritymodeltoassist
decision making and improve situational awareness. It is based on a domain-specific
languageCyQLtoexpressgraphpatternsandusesathird-partytoolforvisualization.
Another stream of literature transforms logs into RDF knowledge graphs that can
be queried with SPARQL, a standardized query language. Early work such as [39] has
illustratedthattheuseofexplicitsemanticscanhelptoavoidambiguity,imposemeaning
onrawlogdata,andfacilitatecorrelationinordertolowerthebarrierforloginterpretation
and analysis. In this case, however, the log source considered is limited to a firewall
log. Approaches like this do not directly transform log data into a graph, but impose
semanticstoexistingrawlogdataorlogdatastoredinarelationaldatabase. Morerecently,
approacheshavebeendevelopedthataimtotransformlogdatafrommultiplesourcesinto
anintegratedlogknowledgegraph.
Forstructuredlogfiles,Ref.[40]discussesanapproachthatanalyzestheirschemato
generateasemanticrepresentationoftheircontentsinRDF.Similartoourwork,theap-
proachlinkslogentitiestoexternalbackgroundknowledge(e.g.,DBPedia),butthelog
sourceprocessedislimitedtoasinglelogtype. Ref.[41]leveragesanontologytocorrelate
alertsfrommultipleIntrusionDetectionSystems(IDSs)withthegoalofreducingthenum-
beroffalse-positiveandfalse-negativealerts. Itreliesonasharedvocabularytofacilitate
securityinformationexchange(e.g.,IDMEF,STIX,TAXII),butdoesnotfacilitatelinkingto
otherlogsourcesthatmaycontainindicatorsofattacks.
LEKG[42]providesalogextractionapproachtoconstructknowledgegraphsusing
inference rules and validates them from a background knowledge graph. It uses local
inferencerulestocreategraphelements(triples)whichcanlaterbeusedtoidentifyand
generatecausalrelationsbetweenevents. ComparedtoVloGraph,theapproachdoesnot
aimtoprovideintegrationandinterlinkingovermultipleheterogeneouslogsources.
Tofacilitatelogintegration,contextualizationandlinkingtobackgroundknowledge,
Ref.[17]proposesamodularlogvocabularythatenableslogharmonizationandintegration
between heterogeneous log sources. A recent approach proposed in [25] introduces a
vocabularyandarchitecturetocollect,extract,andcorrelateheterogeneouslow-levelfile
accesseventsfromLinuxandWindowseventlogs.
Comparedtotheapproachinthispaper,theapproachesdiscussedsofarrelyona
centralizedrepository. Amethodologicallysimilarapproachforloganalysisoutsideofthe
securitydomainhasalsobeenintroducedin[43],whichleveragesontology-baseddata
accesstosupportlogextractionanddatapreparationonlegacyinformationsystemsfor
processmining. Incontrasttothispaper,thefocusisonlogdatafromlegacysystemsin
existingrelationalschemasandonontology-basedquerytranslation.
DecentralizedSecurityLogAnalysis
Decentralizedeventcorrelationforintrusiondetectionwasintroducedinearlywork
suchas[44],wheretheauthorsproposeaspecificationlanguagetodescribeintrusionsina
distributedpatternanduseapeer-to-peersystemtodetectattacks. Inthisdecentralized
approach, the focus is on individual IDS events only. To address scalability limitations
ofcentralizedlogprocessing,Ref.[4]distributescorrelationworkloadsacrossnetworks
to the event-producing hosts. Similar to this approach, we aim to tackle challenges of
centralizedloganalysis. However,weleveragesemanticwebtechnologiestoalsoprovide
contextualizationandlinkingtoexternalbackgroundknowledge.Inthecloudenvironment,
Ref.[45]proposesadistributedandparallelsecurityloganalysisframeworkthatprovides
analyses of a massive number of systems, networks, and transaction logs in a scalable
Mach.Learn.Knowl.Extr.2022,4 377
manner. Itutilizesthetwo-levelmaster-slavemodeltodistribute, execute, andharvest
tasksforloganalysis.Theframeworkisspecifictocloud-basedinfrastructuresandlacksthe
graph-orienteddatamodelandcontextualizationandqueryingcapabilitiesofourapproach.
4. Requirements
Existing log management systems typically ingest log sources from multiple log-
producingendpointsandstoretheminacentralrepositoryforfurtherprocessing. Before
theycanbeanalyzed,suchsystemstypicallyparseandindextheselogs,whichtypically
requires considerable amounts of disk space to store the data as well as computational
powerforloganalysis. Theconcentratednetworkbandwidth, CPU,memory, anddisk
spaceneedslimitthescalabilityofsuchcentralizedapproaches.
Decentralizedloganalysis,bycontrast,(partly)shiftsthecomputationalworkloads
involvedinlogpre-processing(e.g.,acquisition,extraction,andparsing)andanalysistothe
log-producinghosts[4].Thismodelhasthepotentialforhigherscalabilityandapplicability
inlarge-scalesettingswherethescopeoftheinfrastructureprohibitseffectivecentralization
ofallpotentiallyrelevantlogsourcesinasinglerepository.
Existing approaches for decentralized log processing, however, primarily aim to
provide correlation and alerting capabilities, rather than the ability to query dispersed
logdatainadecentralizedmanner. Furthermore,theylackeffectivemeansforsemantic
integration,contextualization,andlinking,i.e.,dynamicallycreatingconnectionsbetween
entities and potentially involving externally available security information. They also
typicallyhavetoingestalllogdatacontinuouslyonthelocalendpoints,whichincreases
continuousresourceconsumptionacrosstheinfrastructure.
In this paper, we tackle these challenges and propose a distributed approach for
securitylogintegrationandanalysis. Thereby,wefacilitatead-hocqueryingofdispersed
rawlogsourceswithoutprioringestionandaggregationinordertoaddressthefollowing
requirements(R):
• R.1—Resource-efficiency Traditionallogmanagementsystems, suchasSIEMs, per-
formcontinuouslogingestionandpreprocessing,typicallyfrommultiplemonitoring
endpoints,beforeanalyzingthelogdata. Thisrequiresconsiderableresourcesasall
dataneedstobeextractedandparsedinadvance. Akeyrequirementfordistributed
securityloganalysisistoavoidunnecessaryex-antelogpreprocessing(acquisition,
extraction,andparsing),thusminimizingresourcerequirementsintermsofcentral-
izedstoragespaceandnetworkbandwidth. Thisshouldmakeloganalysisbothmore
efficientandmorescalable.
• R.2—Aggregationandintegrationovermultipleendpoints Asdiscussedinthecontext
ofthemotivatingexampleinSection1,asingleattackmayleavetracesinmultiple
log sources, which can be scattered across different systems and hosts. To detect
sophisticatedattacks,itisthereforenecessarytoidentifyandconnectsuchisolated
indicatorsofcompromise[17]. Theproposedsolutionshouldthereforeprovidethe
abilitytoexecutefederatedqueriesacrossmultiplemonitoringendpointsconcurrently
anddeliverintegratedresults.Thismakesitpossibletodetectnotonlypotentialattack
actions, butalsotoobtainanintegratedpictureoftheoverallattack(e.g., through
linkingoflogentries).
• R.3—Integration, Contextualization & Background-Linking the interpretation of log
informationforattackinvestigationdependshighlyonthecontext;isolatedindicators
on their own are, however, often inconspicuous in their local context. Therefore,
the proposed approach should provide the ability to contextualize disparate log
information,integrateit,andlinkittointernalbackgroundknowledgeandexternal
securityinformation.
• R.4—Standards-based query language The proposed approach should provide an
expressive, standards-based query language for log analysis. This should make it
easierforanalyststoformulatequeries(e.g.,definerules)duringattackinvestigation
inanintuitiveanddeclarativemanner.
Mach.Learn.Knowl.Extr.2022,4 378
5. VloGraphFrameworkArchitecture
BasedontherequirementssetoutinSection4,weproposeVloGraph,anapproachand
architectureforsecurityloganalyticsbasedontheconceptofVirtualKnowledgeGraphs
(VKGs). TheproposedapproachleveragesSemanticWebTechnologiesthatprovide(i)a
standardizedgraph-basedrepresentationtodescribedataandtheirrelationshipsflexibly
usingRDF[46],(ii)semanticlinkingandalignmenttointegratemultipleheterogeneous
log data and other resources (e.g., internal/external background knowledge), and (iii)
astandardizedsemanticquerylanguage(i.e.,SPARQL[23])toretrieveandmanipulate
RDFdata.
ToaddressR.1,ourapproachdoesnotrelyoncentralizedlogprocessing,i.e., weonly
extract relevant log events based on the temporal scope and structure of a given query
anditsqueryparameters. Specifically,weonlyextractlinesinalogfilethat: (i)arewithin
thetemporalscopeofthequery,and (ii)maycontainrelevantinformationbasedonthe
specifiedqueryparametersandfilters.
The identified log lines are extracted, parsed, lifted to RDF, compressed, and tem-
porarily stored in a local cache on the respective endpoint. This approach implements
theconceptofdatavirtualizationandfacilitateson-demandlogprocessing. Byshifting
computationalloadstoindividualmonitoringagentsandonlyextractinglogentriesthat
arerelevantforagivenquery,thisapproachcansignificantlyreduceunnecessarylogdata
processing. Furthermore,duetotheuseofRDFcompressiontechniques,thetransferred
dataarerathersmall;wediscussthisfurtherinSection7.
To address R.2, we distribute queries over multiple log sources across distributed
endpointsandcombinetheresultsinasingleintegratedoutputviaqueryfederation[24].
ToaddressR.3,weinterlinkandcontextualizeourextractedlogdatawithinternal
andexternalbackgroundknowledge—suchas,e.g., ITassetinformationandcybersecurity
knowledge—viasemanticlinkingandalignment. Finally,weuseSPARQLtoformulate
queriesandperformloganalyses,whichaddressesR.4. WewillillustrateSPARQLquery
federationandcontextualizationinmultipleapplicationscenariosforinSection6.
Figure4illustratestheVloGraphvirtualloggraphandqueryfederationarchitecture
for log analysis; (i) a Log Parser on each host, which receives and translates queries,
extractsrawlogdatafromhosts,parsestheextractedlogdataintoanRDFrepresentation,
compresses the resulting RDF data into a binary format, and sends the results back to
a (ii) Query Processor, which provides an interface to formulate SPARQL queries and
distributesthequeriesamongindividualendpoints;furthermore,itretrievestheindividual
loggraphsfromtheendpoints,integratesthem,andpresentstheresultingintegratedgraph.
Inthefollowing,weexplaintheindividualcomponentsindetail.
SPARQLQueryEditor
ThisSub-ComponentisPartoftheQueryProcessorandallowsanalyststodefineset-
tingsforqueryexecution,including: (i)TargetHosts: asetofendpointstobeincludedinthe
loganalysis,(ii)Knowledgebases: acollectionofinternaland/orexternalsourcesofback-
groundknowledgethatshouldbeincludedinthequeryexecution(e.g.,ITinfrastructure,
cyberthreatintelligenceknowledgebases,etc.),(iii)TimeInterval: thetimerangeofinterest
fortheloganalysis(i.e.,starttimeandendtime).
Mach.Learn.Knowl.Extr.2022,4 379
Figure4.Virtualloggraphandqueryfederationarchitecture.
QueryParsing
TheSPARQLqueryspecification[47]providesanumberofalternativesyntaxesto
formulatequeries. Foruniformaccesstothepropertiesandvariablesinsidethequery,we
thereforeparsetherawSPARQLsyntaxintoastructuredformatpriortotransferringthe
querytothemonitoringhosts. ThepreparedSPARQLqueryisthensentasaparameterto
theQueryTranslatorviatheWebAPIintheLogParserComponent.
QueryTranslation
Thissub-componentdecomposestheSPARQLquerytoidentifyrelevantproperties
for log source selection and log line matching. Algorithm 1 outlines the general query
translationprocedure,whichidentifiesrelevantlogsourcesandloglinesbasedonthree
criteria,i.e., (i)prefixesusedinthequery;(ii)triples;and (iii)filters.
Prefixes(P)isasetoflogvocabularyprefixesthatappearinagivenqueryQ. Ineach
query,thecontainedprefixeswillbeusedbythequerytranslatortoidentifyrelevantlog
sources. AvailableprefixescanbeconfiguredfortherespectivelogsourcesintheLogParser
configurationoneachclient,including,e.g.,thepathtothelocallocationofthelogfile.
Asanexample,PREFIX auth: istheprefixfor AuthLog;its
presenceinaqueryindicatesthatthe AuthLogontheselectedhostswillbeincludedinthe
logprocessing.
Triples(T)isasetoftriplesthatappearinaquery,eachrepresentedasTriplePattern
oraBasicGraphPattern(BGP)(i.e.,  ).
We match these triples to log lines (e.g., hosts and users) as follows: Function
getTriplePattern(Q)collectsthetriplepatternsTcontainedwithinthequeryQ. Foreach
triplestatementinaquery,weidentifythetypeofObjectT . IfthetypeisLiteral,we
iObject
identifytheT aswell. Forexample,forthetriple{?Subject cl:originatesFrom
iPredicate
"Host1"},thefunctiongetLogProperty()identifiesT "Host1",andadditionally,looks
iObject
upthepropertyrangeprovidedinregexPatterns(RP).
regexPatterns(RP)linkspropertytermsinavocabularytothetermsinalogentryand
therespectiveregularexpressionpattern. Forexample,thepropertycl : originatesFrom
is linked to the concept "hostname" in regexPattern (RP), which has a connected regex
patternfortheextractionofhostnames. TheoutputofthegetLogProperty()functionisa
setofkey-valuepairs.
iObject
Similartotriples,wealsoincludeFilters(F)thatappearinaqueryQforlog-linematch-
ing. Filterstatementscontaintheterm FILTER andasetofpairs(i.e.,VariableandValue),
thereforeeach Filterstatement F hasthemembersVariable F andValue F . Cur-
i iVariable iValue
rently,wesupportFILTERclauseswithsimplepatternmatchingandregularexpressionssuch
asFILTER(?variable =”StringValue”),FILTERregex(str(?variable),”StringValue”)).
Mach.Learn.Knowl.Extr.2022,4 380
Algorithm1:Querytranslation.
size
Input: SPARQLQuery(Q),Vocabulary(V),regexPatterns(RP)
Output: QueryElements(Qe)
1 PrefixesP={P 1,...,P n}(cid:101)Q;
2 TriplesT={Subject,Predicate,Object}(cid:101)Q;
3 FiltersF={Variable,Value}(cid:101)Q;
4 FunctiontranslateQuery(Q,V,RP):
P←getPrefix(Q);
5
T←getTriplePattern(Q);
6
7 foreachTripleT i (cid:101)Tdo
8 iftype(T iObject)=Literalthen
9 logProperty←getLogProperty(T iPredicate,V,RP);
keyValue←{logProperty,T iObject};
10
11 end
12 triplesKV +=keyValue;
13 end
F←getFilterStatement(Q);
14
15 foreachFilterF i (cid:101)Fdo
16 iftype(F iValue)=Literalthen
17 predicate←getPredicate(Q,F iVariable);
logProperty←getLogProperty(predicate,V,RP);
18
keyValue←{logProperty,F iValue};
19
20 end
21 filtersKV +=keyValue;
22 end
Qe←{P,triplesKV,filtersKV};
23
24 returnQe;
25 EndFunction