-3
...
f2
f3
2
3
2
0
1
2
3
2
3
2
-3
-1
5
0
...
f4
yv
2
3
5
3
Fig. 5: The operation of the transformed max pooling layer.
The ﬁrst function is f MP(xv) = W MP · xv, which reorders
its input vector xv to a vector xMP in which the values
of each max pooling subrectangle of x are adjacent. The
remaining functions execute standard max pooling. Concretely,
the function fi ∈ {f1, . . . , f m
q ·r} executes max pooling
p · n
on the ith subrectangle by selecting the maximal value and
removing the other values. We provide formal deﬁnitions of
the CAT functions f MP and fi
in Appendix A. Here, we
illustrate them on the example from Fig. 4c, where r = 1.
The CAT computation for this example is shown in Fig. 5.
The computation begins from the input vector xv, which is
the reshaping of x from Fig. 4c. The values of the ﬁrst 2 × 2
subrectangle in x (namely, 0, 1, 2 and −4) are separated in
xv by values from another subrectangle (3 and −2). To make
them contiguous, we reorder xv using a permutation matrix
W MP, yielding xMP. In our example, W MP is:
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
W MP=
One entry in each row of W MP is 1, all other entries are zeros.
6
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:59:05 UTC from IEEE Xplore.  Restrictions apply. 
p · n
If row i has entry j set to 1, then the jth value of xv is moved
to the ith entry of xMP. For example, we placed a one in the
ﬁfth column of the third row of W MP to move the value xv
5
to entry 3 of the output vector.
Next, for each i ∈ {1, . . . , m
q }, the function fi takes
as input a vector whose values at the indices between i and
i + p · q − 1 are those of the ith subrectangle of ¯x in Fig. 4c.
It then replaces those p · q values by their maximum:
fi(x) = (x1, . . ., xi−1, xk, xi+p·q, . . . , xm·n−(p·q−1)·(i−1)),
where the index k ∈ {i, . . . , i + p · q − 1} is such that
xk is maximal. For k given, fi can be written as a CAT
function: fi(x) = W (i,k) · x, where the rows of the matrix
W (i,k) ∈ R
(m·n−(p·q−1)·i)×(m·n−(p·q−1)·(i−1)) are given by
the following sequence of standard basis vectors:
e1, . . . , ei−1, ek, ei+p·q, . . . , em·n−(p·q−1)·(i−1).
For example, in Fig. 5, f1(xMP) = W (1,3) · xMP deletes 0, 1
and −4. Then it moves the value 2 to the ﬁrst component,
and the values at indices 5, . . . , 16 to components 2, . . . , 13.
Overall, W (1,3) is given by:
⎞
⎟⎟⎟⎟⎟⎟⎠
0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
⎛
⎜⎜⎜⎜⎜⎜⎝
W (1,3)=
f1(x) =
As, in general, k is not known in advance, we need to write
fi as a CAT function with a different case for each possible
index k of the maximal value in x. For example, in Fig. 5:
case (x1 ≥ x2) ∧ (x1 ≥ x3) ∧ (x1 ≥ x4) : W (1,1) · x,
case (x2 ≥ x1) ∧ (x2 ≥ x3) ∧ (x2 ≥ x4) : W (1,2) · x,
case (x3 ≥ x1) ∧ (x3 ≥ x2) ∧ (x3 ≥ x4) : W (1,3) · x,
case (x4 ≥ x1) ∧ (x4 ≥ x2) ∧ (x4 ≥ x3) : W (1,4) · x.
In our example, the vector xMP in Fig. 5 satisﬁes the third
condition, and therefore f1(xMP) = W (1,3) · xMP. Taking into
account all four subrectangles, we obtain:
2,2 = f4 ◦ f3 ◦ f2 ◦ f1 ◦ f MP.
(cid:2)
MaxPool
In summary, each function fi replaces p·q components of their
input by the maximum value among them, suitably moving
other values. For xv in Fig. 5:
(cid:2)
2,2(xv
MaxPool
) = W (4,7) · W (3,6) · W (2,2) · W (1,3) · W MP · xv.
Network Architectures. Two popular architectures of neural
networks are fully connected feedforward (FNN) and convo-
lutional (CNN). An FNN is a sequence of fully connected
layers, while a CNN [19] consists of all previously described
layer types: convolutional, max pooling, and fully connected.
x2
4
3
2
1
−1
(cid:9)
(cid:10)(cid:9)
x1
x2
(cid:10)
(cid:10)
(cid:9)
y1
y2
=
2 −1
1
0
x1
2
3
1
(a)
−3 −2 −1
y2
4
333
33
3
22
2
1
11
1
(b)
y1
1
2
3
Fig. 6: (a) Abstracting four points with a polyhedron (gray),
zonotope (green), and box (blue). (b) The points and abstracti-
ons resulting from the afﬁne transformer.
III. BACKGROUND: ABSTRACT INTERPRETATION
m
(cid:11)
2 −1
0 1
n
),
2 → R
) → P(R
We now provide a short introduction to Abstract Interpre-
tation (AI). AI enables one to prove program properties on a
set of inputs without actually running the program. Formally,
m → R
m,
given a function f : R
and a property C ⊆ R
n, the goal is to determine whether the
property holds, that is, whether ∀x ∈ X. f (x) ∈ C.
n, a set of inputs X ⊆ R
Fig. 6 shows a CAT function f : R
(cid:12)· x and four input points for the function f,
2 that is deﬁned
as f (x) =
given as X = {(0, 1), (1, 1), (1, 3), (2, 2)}. Let the property be
C = {(y1, y2) ∈ R
2 | y1 ≥ −2}, which holds in this example.
To reason about all inputs simultaneously, we lift the deﬁnition
of f to be over a set of inputs X rather than a single input:
Tf (X) = {f (x) | x ∈ X}.
Tf : P(R
The function Tf is called the concrete transformer of f.
With Tf , our goal is to determine whether Tf (X) ⊆ C for
a given input set X. Because the set X can be very large
(or inﬁnite), we cannot enumerate all points in X to com-
pute Tf (X). Instead, AI overapproximates sets with abstract
elements (drawn from some abstract domain A) and then
deﬁnes a function, called an abstract transformer of f, which
works with these abstract elements and overapproximates the
effect of Tf . Then, the property C can be checked on the
resulting abstract element returned by the abstract transformer.
Naturally, because AI employs overapproximation, it is sound,
but may be imprecise (i.e., may fail to prove the property when
it holds). Next, we explain the ingredients of AI in more detail.
Abstract Domains. Abstract domains consist of shapes
expressible as a set of logical constraints. A few popular
numerical abstract domains are: Box (i.e., Interval), Zonotope,
and Polyhedra. These domains provide different precision
versus scalability trade-offs (e.g., Box’s abstract transformers
are signiﬁcantly faster than Polyhedra’s abstract transformers,
but polyhedra are signiﬁcantly more precise than boxes). The
Box domain consists of boxes, captured by a set of constraints
of the form a ≤ xi ≤ b, for a, b ∈ R∪{−∞, +∞} and a ≤ b.
A box B contains all points which satisfy all constraints in B.
In our example, X can be abstracted by the following box:
B = {0 ≤ x1 ≤ 2, 1 ≤ x2 ≤ 3}.
7
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 05:59:05 UTC from IEEE Xplore.  Restrictions apply. 
Note that B is not very precise since it includes 9 integer
points (along with other points), whereas X has only 4 points.
The Zonotope domain [10] consists of zonotopes. A zono-
tope is a center-symmetric convex closed polyhedron Z ⊆ R
n
that can be represented as an afﬁne function:
z : [a1, b1] × [a2, b2] × ··· × [am, bm] → R
n.
In other words, z has the form z() = M ·  + b where  is a
vector of error terms satisfying interval constraints i ∈ [ai, bi]
for 1 ≤ i ≤ m. The bias vector b captures the center of the
zonotope, while the matrix M captures the boundaries of the
zonotope around b. A zonotope z represents all vectors in the
image of z (i.e., z[[a1,1 ] × ··· × [am, bm]]). In our example,
X can be abstracted by the zonotope z : [−1, 1]3 → R
2:
z(1, 2, 3) = (1 + 0.5 · 1 + 0.5 · 2, 2 + 0.5 · 1 + 0.5 · 3).
Zonotope is a more precise domain than Box: for our example,
z includes only 7 integer points.
The Polyhedra [8] domain consists of convex closed po-
lyhedra, where a polyhedron is captured by a set of linear
constraints of the form A · x ≤ b, for some matrix A and a
vector b. A polyhedron C contains all points which satisfy the
constraints in C. In our example, X can be abstracted by the
following polyhedron:
C = {x2 ≤ 2 · x1 + 1, x2 ≤ 4 − x1, x2 ≥ 1, x2 ≥ x1}.
Polyhedra is a more precise domain than Zonotope: for our
example, C includes only 5 integer points.
To conclude, abstract elements (from an abstract domain)
represent
large, potentially inﬁnite sets. There are various
abstract domains, providing different levels of precision and
scalability.
Abstract Transformers. To compute the effect of a function
on an abstract element, AI uses the concept of an ab-
transformer. Given the (lifted) concrete transformer
stract
Tf : P(R
m) → P(R
n, an abstract
transformer of Tf is a function over abstract domains, denoted
f : Am → An. The superscripts denote the number of
by T #
components of the represented vectors. For example, elements
in Am represent sets of vectors of dimension m. This also
determines which variables can appear in the constraints
associated with an abstract element. For example, elements
in Am constrain the values of the variables x1, . . . , xm.
n) of a function f : R
m → R
Abstract transformers have to be sound. To deﬁne sound-
ness, we introduce two functions: the abstraction function α
and the concretization function γ. An abstraction function
αm : P(R
m) → Am maps a set of vectors to an abstract
element in Am that overapproximates it. For example, in the
Box domain:
f
A concretization function γm : Am → P(R
m) does the
opposite: it maps an abstract element to the set of concrete
vectors that it represents. For example, for Box:
γ2({0 ≤ x1 ≤ 2, 1 ≤ x2 ≤ 3}) ={(0, 1), (0, 2), (0, 3),
(1, 1), (1, 2), (1, 3),
(2, 1), (2, 2), (2, 3), . . .}.
This only shows the 9 vectors with integer components. We
can now deﬁne soundness. An abstract transformer T #
is
sound if for all a ∈ Am, we have Tf (γm(a)) ⊆ γn(T #
f (a)),
where Tf is the concrete transformer. That is, an abstract
transformer has to overapproximate the effect of a concrete
transformer. For example, the transformers illustrated in Fig. 6
are sound. For instance, if we apply the Box transformer on the
box in Fig. 6a, it will produce the box in Fig. 6b. The box in
Fig. 6b includes all points that f could compute in principle