tions, with no samples for the ‘under attack’ class. Thus, adversarial
training here does not apply: indeed, we cannot train the system
to be resilient to adversarial attacks since samples from the class
‘under attack’ is unknown to the defender.
5 EVALUATION
In this section, we experimentally evaluate the proposed attacks. We
start by introducing the datasets we used for our experiments: the
BATADAL dataset and data coming from a real industrial process
(WADI dataset). We start the evaluation targeting an Autoencoder-
based detector and explore the performance of replay, iterative,
and learning based attacks in constrained and unconstrained con-
ditions. Then, we show that our learning based attack generalizes
to other schemes based on LSTM and CNN. Finally, we show the
concealment attack results obtained in a real industrial testbed.
5.1 Dataset 1: BATADAL
The first dataset was generated with epanetCPA [52], an open-
source, object-oriented Matlab toolbox for modeling the hydraulic
response of water distribution systems to cyber-physical attacks.
The dataset was originally generated for the BATADAL [53] com-
petition, which ran between 2016 and 2017. The BATADAL compe-
tition was based on three datasets: the first contains data coming
from the simulation of 365 days of normal operations, while the sec-
ond and third contains 14 attacks (7 attacks each). The details of the
attacks can be found in [53]. These datasets contain readings from
43 sensors: tank water levels (7 variables), inlet and outlet pressure
for one actuated valve and all pumping stations (12 variables), as
well as their flow and status (24 variables). All variables are con-
tinuous, except for the status of valve and pumps, represented by
binary variables.
The original attack dataset (from http://www.batadal.net/data.
html) contained sensor data readings that were manually concealed.
For that reason, we could not use the original attack dataset directly
(as we wanted to add concealment ourselves). Instead, we re-created
the attacks (and resulting sensor data) from the BATADAL dataset
for this work using the original setup, without any manual conceal-
ment. In our new version, the data are collected from sensors every
15 minutes.
5.2 Dataset 2: WADI
Our second dataset is based on the Water Distribution (WADI)
testbed, a real-world ICS testbed located at the Singapore Univer-
sity of Technology and Design [2]. It is composed of two elevated
reservoir tanks, six consumer tanks, two raw water tanks, and a
return tank. It contains chemical dosing systems, booster pumps
and valves, instrumentation, and analyzers. WADI is controlled by 3
PLCs that operate over 103 network sensors. Moreover, the testbed
is equipped with a SCADA system. WADI consists of three main
processes: P1 (Primary supply and analysis), P2 (Elevated reservoir
with Domestic grid and leak detection), and P3 (Return process).
For anomaly detection purposes, we consider sensor data from P1
and P2, since the return process is only implemented for recycling
water. Considering stages P1 and P2, we have data coming every
second from 82 sensors. In this work, we use two WADI datasets.
The first dataset contains data of 14 days of normal operations. The
second contains 15 attacks on physical processes spanned over two
days of operations. This dataset is available on request [28].
We primarily use the WADI dataset for two reasons: i) to show
that the discussed detection mechanism applies to real-world ICS
data, and ii) to see whether our attack methodology is transferable
from a scenario in which simulated data are used to another scenario
in which real data are used.
5.3 Evaluation Setup
We evaluate the detection Recall over datasets under original con-
ditions (i.e., no concealment attacks), replay, iterative, and learning-
based concealment attacks. The 𝑅𝑒𝑐𝑎𝑙𝑙 (True Positive Rate) is de-
fined as:
𝑇 𝑃
,
𝑅𝑒𝑐𝑎𝑙𝑙 =
𝑇 𝑃 + 𝐹 𝑁
(5)
where 𝑇 𝑃 stands for True Positive and 𝐹 𝑁 for False Negative. Recall
measures the rate of correctly classified positive instances. When
the anomaly detector is tuned, a higher Recall means that the anom-
aly detector is correctly retrieving anomalies. The attacker’s con-
cealment goal can be expressed in terms of 𝑅𝑒𝑐𝑎𝑙𝑙: the concealment
attack is successful if the detector Recall over the concealed tuples
ACSAC 2020, December 7–11, 2020, Austin, USA
A. Erba et al.
goes to 0. The closer the Recall comes to 0, the higher the amount of
misclassified tuples. Note that we launch our concealment attacks
over the instances of anomalous data, i.e., data reporting ground
truth ‘under attack’.
Both iterative and learning based attacks are implemented using
Python 3.7.1; neural networks are implemented and trained using
Keras 2.3.1 with TensorFlow 1.11.0 backend. Experiments use a lap-
top equipped with Intel i7-7500U CPU, 16GB of RAM, and NVIDIA
GeForce 940MX GPU 4GB.
(cid:77)Training of Attack Detector For both BATADAL and WADI,
we trained the third party attack detector [51] on sensor readings
occurring during normal operational data.
For the BATADAL dataset (where sensor readings are sampled
every 15 minutes), we found that parameter window = 3 quarter
of hours is a reasonable decision boundary to flag correctly at-
tacks and do not raise False alarms. This gives a Accuracy = 0.93,
Precision = 0.90, Recall = 0.60, FPR = 0.01. Changing the 𝑤𝑖𝑛𝑑𝑜𝑤
parameter, we can increase the Recall at the price of decreasing
Precision that means raising a higher number of False Alarms.
For the WADI dataset, we found that parameter window = 60 sec-
onds is a reasonable decision boundary to flag correctly attacks and
distinguish them from False Positives. This gives a Accuracy = 0.97,
Precision = 0.77, Recall = 0.68, FPR = 0.01.
Results are in line with the current state of the art detection over
the BATADAL dataset [51] and WADI [16].
(cid:77)Replay attack In this attack, the attacker replays for the whole
duration of the physical manipulation, using the sensor readings
as recorded at the same hour 𝑠 days before (assuming that process
operations are often periodic within 24h). 𝑠 is chosen to let the
replay contain only normal operations data. For example, given a
physical manipulation that lasts 50 hours, we replay sensor readings
as happened 72 hours earlier.
(cid:77)Iterative attack The attacker manipulates variables required
to find a solution (according to the two stopping criteria intro-
duced in Section 4.3 and constraints over modifiable sensor read-
ings). For BATADAL dataset, we tuned the two stopping criteria
via grid search to guarantee a trade-off between the decrease of
detection accuracy and computational time. Specifically we selected
patience = 15 and the budget = 200. For WADI dataset, the iterative
parameters (following the same rational as in BATADAL case) we
choose are patience = 40 and the budget = 300. The result of this
experiment depends on the detection mechanism. The attacker is
using the oracle to determine if the concealment is successful.
(cid:77)Learning based attack For the learning based attack, the at-
tacker uses an autoencoder (AE) as the generator and sends pre-
dicted readings to the SCADA. According to the attacker’s con-
straints, we train an autoencoder over the readable features. We
used sigmoid as activation function, Gorlot initialization [19] as
weights initializer and mean squared error as loss function. More-
over, we split the data in train 2
3, use early stop-
ping [29] to avoid overfitting and reduce learning rate on plateaus [30].
Depending on the constrained scenario (i.e., the features that the
attacker can read X or the amount of data that she spoofed ˆD), the
adversarially trained autoencoder has a different number of input
neurons. Given 𝑛 as input/output dimension, the autoencoder is
composed of 3 hidden-layers with respectively 2𝑛, 4𝑛, 2𝑛 neurons.
3 and validation 1
Table 2: Detector Recall (BATADAL (B) and WADI (W)
datasets), before and after unconstrained concealment at-
tacks. The column ‘Original’ refers to the detection Recall
over the data without concealment; ‘Replay’, reports the Re-
call after replay attack, while ‘Iterative’ and ‘Learning based’
columns report the Recall after our proposed adversarial
concealment attacks.
Detection Recall
Data Original
B
W
0.60
0.68
Replay