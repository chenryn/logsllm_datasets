title:Dynamic behavior of slowly-responsive congestion control algorithms
author:Deepak Bansal and
Hari Balakrishnan and
Sally Floyd and
Scott Shenker
Dynamic Behavior of Slowly-Responsive Congestion
Control Algorithms
Deepak Bansal and Hari Balakrishnan
MIT Laboratory for Computer Science
Sally Floyd and Scott Shenker
AT&T Center for Internet Research at ICSI
fbansal,PI:EMAIL
fﬂoyd,PI:EMAIL
Abstract
The recently developed notion of TCP-compatibility has led to a
number of proposals for alternative congestion control algorithms
whose long-term throughput as a function of a steady-state loss rate
is similar to that of TCP. Motivated by the needs of some stream-
ing and multicast applications, these algorithms seem poised to take
the current TCP-dominated Internet to an Internet where many con-
gestion control algorithms co-exist. An important characteristic of
these alternative algorithms is that they are slowly-responsive, re-
fraining from reacting as drastically as TCP to a single packet loss.
However, the TCP-compatibility criteria explored so far in the
literature considers only the static condition of a ﬁxed loss rate.
This paper investigates the behavior of slowly-responsive, TCP-
compatible congestion control algorithms under more realistic dy-
namic network conditions, addressing the fundamental question of
whether these algorithms are safe to deploy in the public Internet.
We study persistent loss rates, long- and short-term fairness prop-
erties, bottleneck link utilization, and smoothness of transmission
rates.
1.
Introduction
In the Internet’s current congestion control paradigm, routers
play a relatively passive role:
they merely indicate congestion
through packet drops or explicit congestion notiﬁcation. It is the
end-systems that perform the crucial role of responding appropri-
ately to these congestion signals. This paradigm of passive routers
and active hosts has been spectacularly successful; the conges-
tion management mechanisms of TCP developed by Jacobson [10],
based on the principles of packet conservation, slow-start, and
additive-increase / multiplicative-decrease (AIMD) [3], is in large
part responsible for the remarkable stability of the Internet despite
rapid (to say the least) growth in trafﬁc, topology, and applications.
Balakrishnan and Bansal were supported in part by an NSF CA-
REER Award, by DARPA Grant No. MDA972-99-1-0014, and by
a research grant from the NTT Corporation. Bansal was also sup-
ported for a summer by ACIRI.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’01, August 27-31, 2001, San Diego, California, USA.
Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.
An important property of the TCP congestion control algorithm
is that similarly situated end-systems receive roughly equal band-
widths. TCP does not assure equality of bandwidth between end-
systems with different round-trip times, or with multiple congested
hops, or which use different packet sizes, but it does assure users
that similarly situated ﬂows using the same packet sizes will re-
ceive roughly the same bandwidth. We will call such bandwidth
allocations equitable (to avoid the overloaded term fair) and it is
the bandwidth allocation goal that we pursue in this paper.
Because routers don’t exercise active control over bandwidth,
the resulting bandwidth allocations are a function of the conges-
tion control mechanisms used by the various end-systems. Before
the advent of the TCP-compatible paradigm, which we describe be-
low, the only way to reliably achieve equitable bandwidth alloca-
tions was for the end-systems to all use the same congestion control
mechanism. Thus, for fairness reasons, TCP was seen not only as
a sufﬁcient condition but also as a necessary one.
The TCP congestion control mechanism produces rapidly vary-
ing transmission rates in the way it probes for spare capacity and
reacts to congestion. While several classes of best-effort Internet
trafﬁc tolerate these variations quite well, other applications such as
best-effort, unicast streaming video and audio are better served by
congestion control mechanisms that respond more slowly to con-
gestion and thereby produce a smoother bandwidth usage proﬁle.
The Internet community has struggled with this tension between the
uniformity needed so that fairness can be obtained, and the desire
to meet the demands of applications for whom TCP is a far-from-
ideal solution. For multicast trafﬁc, for example, TCP congestion
control would be a particularly bad ﬁt because it requires acknowl-
edgements from all receivers in the multicast group.
A recently proposed resolution to this dilemma is the TCP-
compatible paradigm.1 The cornerstone of this approach is the ob-
servation, made by a number of researchers [11, 13, 14], that one
can characterize the bandwidth usage of a TCP ﬂow in the pres-
ence of a constant packet loss rate ; to ﬁrst order the bandwidth
is proportional to 1=. A congestion control mechanism is TCP-
compatible if its bandwidth usage, in the presence of a constant loss
rate, is the same as TCP [11]. The TCP-compatible paradigm sim-
ply transforms the requirement that all congestion control mecha-
nisms be TCP into the looser requirement that all congestion con-
trol algorithms must be TCP-compatible.
This approach is a dramatic change from the earlier notions of
congestion control.
It could take us from an almost exclusively
TCP-controlled world to one where there is no single dominant
congestion control mechanism and instead there is a wide variety
of mechanisms tailored to different application requirements. Al-
ready several alternative congestion control mechanisms have been
1This is also known as TCP-friendliness [11].
proposed, including TCP-Friendly Rate Control (TFRC) [6] and
other forms of equation-based congestion control, AIMD with dif-
ferent linear constants from TCP [20], binomial congestion con-
trol [2], and TCP Emulation at Receivers (TEAR) [17]. Unlike
TCP, such mechanisms refrain from halving their congestion win-
dow (or transmission rate) in response to a single packet loss, and
are more slowly responsive to packet loss events compared to TCP.
These proposals are no mere academic exercises: the IETF has al-
ready adopted as Best Current Practice a document discussing and
suggesting TCP-compatibility as a requirement for the standard-
ization of new congestion control procedures for trafﬁc likely to
compete with best-effort TCP trafﬁc [4]. In addition, the process
of standardization of one mechanism for equation-based conges-
tion control is already underway in the IETF, at the moment as an
Internet-Draft [9].
Thus, we are possibly on the edge of a rather signiﬁcant change
in the set of congestion control mechanisms deployed on the In-
ternet. However, this new approach is based on a condition—the
TCP compatibility condition—that refers only to the behavior of
the congestion control mechanism under static conditions. The In-
ternet is clearly a very dynamic environment, and certainly static
equivalence to TCP does not imply dynamic equivalence. The fun-
damental question we address here is: are these new congestion
control algorithms safe to deploy in the current Internet? That is,
even though they were developed with the static equivalence in
mind, are they still TCP-compatible under more dynamic condi-
tions?
We address two aspects of this question. First, we use simulation
and analysis to evaluate the behavior of several TCP-compatible
congestion control mechanisms under dynamic conditions; we fo-
cus on persistent packet loss rates, long- and short-term fairness
properties, bottleneck link utilization, and smoothness of transmis-
sion rates. We ﬁnd that most of the TCP-compatible algorithms
we studied appear to be safe for deployment. While there are ex-
amples of algorithms that are TCP-compatible under static condi-
tions but that exhibit unfortunate behavior in dynamic settings, the
algorithms that have actually been proposed mostly avoided this
problem. However, we ﬁnd that two algorithms that are compatible
under static conditions may not compete equitably under more dy-
namic conditions, even over long time-scales. In particular, while
slowly-responsive TCP-compatible algorithms are safe to deploy
in that they do not mistreat TCP, it is also true that they may not
always get their equitable share when network conditions change
dynamically.
This leads to the second question: Why? That is, what as-
pects of these algorithms are responsible for their remaining TCP-
compatible under dynamic conditions? We ﬁnd that incorporating
the principle of packet conservation (e.g., by self-clocking trans-
missions as in TCP) is crucial in dynamic settings to ensure safety.
The absence of long-term fairness despite static TCP-compatibility
is caused by a fundamental trade-off: in return for smoother trans-
mission rates, slowly-responsive algorithms lose throughput to
faster ones (like TCP) under dynamic network conditions.
The rest of this paper describes these results. The next section
is an overview of TCP-compatible algorithms. We describe the
dynamic experiments and scenarios in Section 3, and present and
explain our results in detail in Section 4. We conclude with a sum-
mary of our ﬁndings in Section 5. We discuss the role of timeouts
in Appendix A.
2. TCP-Compatible Congestion Control Algo-
rithms
Binomial(k,l)
l  0.5
TCP-compatible
Figure 1: A classiﬁcation of different end-to-end congestion
control algorithms in relation to each other, with speciﬁc ex-
amples in rectangular boxes. This classiﬁcation is based on a
static notion, and our goal is to understand their behavior un-
der dynamic conditions as well.
In steady-state, a long-running TCP connection uses two con-
gestion control mechanisms: AIMD, which governs the size of the
window, and self-clocking, which uses the principle of packet con-
servation to decide when the window must change and data trans-
mitted. Proposals for end-to-end congestion control may be classi-
ﬁed as TCP-equivalent, TCP-compatible, or not TCP-compatible,
based on their steady-state behavior. Based on their transient re-
sponse to congestion, end-to-end proposals can be classiﬁed as
TCP-equivalent, slowly-responsive, or responding faster than TCP.
A congestion control algorithm is TCP-equivalent if it uses
AIMD to govern its transmission window or rate, with the same
increase and decrease parameters as TCP. Examples of TCP-
equivalent schemes include various TCP variants, and rate-based
schemes like Rejaie et al.’s Rate Adaptation Protocol (RAP) [16].
Because of the absence of self-clocking, TCP-equivalent schemes
such as RAP can have different transient behavior than TCP, as we
discover.
A congestion control mechanism is TCP-compatible in the static
sense (or simply TCP-compatible) if it displays congestion control
behavior that, on time scales of several round-trip times (RTTs), ob-
tains roughly the same throughput as a TCP connection in steady-
state when the available bandwidth does not change with time. Un-
der conditions of an invariant packet loss rate , the throughput of a
TCP-compatible algorithm obeys the “TCP-friendly” formula giv-
ing the sending rate of a TCP sender under the same conditions.
In this paper we use the TCP response function derived by Pad-
hye et al. [14], observing that even for the static case, deriving a
formula that correctly characterizes the sending rate of a particular
TCP implementation or model across the entire range of values for
 is a non-trivial chore [18]. It is easy to see that all TCP-equivalent
schemes are also TCP-compatible, but not vice versa.
Not all TCP-compatible algorithms need to react in the same
fashion as TCP on detecting congestion. A congestion control
mechanism is said to be slowly-responsive (relative to TCP) if its
window or rate reduction on a single packet loss or congestion no-
tiﬁcation is smaller than TCP. This slower response to individual
packet drops allows applications using a slowly-responsive con-
gestion control, or SlowCC, algorithm to beneﬁt from a smoother
sending rate than if they had used TCP’s strategy. Examples of
such algorithms include equation-based mechanisms such as TFRC
(TCP-Friendly Rate Control) [6], AIMD-based mechanisms with
different increase/decrease constants from TCP, and binomial con-
gestion control mechanisms. A SlowCC algorithm may or may not
be TCP-compatible, and conversely. Figure 1 summarizes the rela-
tionship between these different classes.
Two other key components of TCP’s congestion control mech-
anisms that are not reﬂected in the above categories are the slow-
start procedure and the exponential backoff of the retransmit timer.
TCP’s slow-start procedure is a key congestion control mechanism
that is not used in steady-state, but is critical for transient behavior
such as the initial start-up. The exponential backoff of the retrans-
mit timer is critical in modeling TCP’s behavior in environments
with very high packet loss rates, in particular when a ﬂow’s aver-
age sending rate is less than one packet per round-trip time.
An AIMD-based algorithm is characterized by two parameters,
a and b, corresponding to the increase and decrease parameters of
the algorithm [8, 20]. After a loss event, the congestion window is
decreased from W to 1   bW packets; in the absence of packet
loss, the congestion window is increased from W to W  a pack-
ets each RTT. TCP without delayed acknowledgments is an AIMD
scheme with a = 1 and b = 0:5. For an AIMD scheme to be TCP-
compatible, a and b are not independent—rather, a = 42b b2=3.
Given an equation such as the one above for deriving a from b, a
TCP-compatible AIMD algorithm is completely characterized by
the parameter b; values of b > b0.
2 B; 1 Æ
Another concern with SlowCC congestion control mechanisms
is that of a temporarily under-utilized link, resulting from the slow-
ness of SlowCC mechanisms in taking advantage of a sudden in-
crease in the available bandwidth. We study link utilization in this
scenario in Section 4.2.3 using a new metric, f k. f k is de-
ﬁned as the fraction of bandwidth achieved by a congestion con-
trol mechanism in the ﬁrst k RTTs after the available bandwidth
has doubled. In addition, we explore link utilization in a dynamic
environment with rapid changes in the available bandwidth in Sec-
tion 4.2.4, where we study scenarios with a competing ON/OFF
CBR source, as described earlier. Here, we consider link utilization
as a function of the magnitude and frequency of the oscillations.
We are also interested in the beneﬁts of SlowCCs, and in Sec-
tion 4.3 we explore the relative smoothness of SlowCC mechanisms
in a range of dynamic environments. The smoothness metric for
TFRC has been deﬁned as the largest ratio between the sending
rates in two consecutive round-trip times. In Section 4.3 we con-
sider smoothness over longer time intervals, without introducing
any new metrics to quantify this.
The responsiveness of a congestion control mechanism has been
deﬁned as the number of round-trip times of persistent congestion
until the sender halves its sending rate, where persistent congestion
is deﬁned as the loss of one packet per round-trip time [6]. The
responsiveness of TCP is 1 round-trip time, and the responsiveness
of the currently proposed TFRC schemes tends to vary between 4
and 6 round-trip times, depending on initial conditions [6]. One
of the goals of this paper is to rigorously explore the impact of
SlowCC congestion control mechanisms with a range of respon-
siveness measures. Thus, we explore TFRC(k) for k ranging from 1
to 256. Similarly, we explore TCP(1=b) for b from 1 to 256. We de-
ﬁne RAP(1=b) and SQRT(1=b) as the TCP-compatible instances of
those congestion control mechanisms with multiplicative decrease