proximately consistent with the predicted probability of
71%.
A real attacker would not have the luxury of opening
the box and focusing just on the memory; it would be
necessary to apply heat from the outside. For a palmtop
or notebook-computer form factor, it might be possible to
apply a focused light at just the place on the outside of
the box under which the memory chips sit. For a desktop
PC, this would be impossible; the attacker would have to
heat the entire box (in an oven, or by blocking the cooling
fan), and we don’t know whether the memory would be-
come unreliable before other components failed. A high-
wattage AMD or Intel P4 processor would likely fail be-
fore the memory, but a low-wattage VIA C3 would not
heat up as quickly as the memory [16].
It might also be possible for the attacker to heat speciﬁc
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
References
[1] R. Anderson and M. Kuhn. Tamper Resistance - a Cau-
tionary Note. In Proceedings of the Second Usenix Work-
shop on Electronic Commerce, pages 1–11, Nov. 1996.
[2] R. Anderson and M. Kuhn. Low cost attacks on tamper
resistant devices. In IWSP: International Workshop on Se-
curity Protocols, LNCS, 1997.
[3] D. Boneh, R. A. DeMillo, and R. J. Lipton. On the im-
portance of checking cryptographic protocols for faults.
Lecture Notes in Computer Science, 1233:37–51, 1997.
[4] S. Borman. Understanding the IBM Java garbage col-
lector. www-106.ibm.com/developerworks/ibm/library/i-
garbage2/, Aug. 2002. web page fetched October 8, 2002.
[5] C. Colby, P. Lee, G. C. Necula, F. Blau, K. Cline, and
M. Plesko. A certifying compiler for Java. In Proceedings
of the 2000 ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI ’00), New
York, June 2000. ACM Press.
[6] A.
Corporation.
error
rates Q&As.
Soft
http://www.actel.com/appnotes/SER QAs.pdf,
Corporation, July 2002.
Neutrons
from above:
Technical Report
Actel
[7] D. Dean, E. W. Felten, and D. S. Wallach. Java security:
From HotJava to Netscape and beyond.
In Proceedings
of 1996 IEEE Symposium on Security and Privacy, May
1996.
[8] S. Drossopoulou and S. Eisenbach. Describing the se-
mantics of Java and proving type soundness. In J. Alves-
Foss, editor, Formal Syntax and Semantics of Java, LNCS.
Springer, 1998.
[9] S. Drossopoulou, T. Valkevych, and S. Eisenbach. Java
type soundness revisited. Technical report, Imperial Col-
lege London, Sept. 2000.
[10] G. McGraw and E. W. Felten. Securing Java. John Wiley
& Sons, 1999.
[11] E. Normand. Single event upset at ground level.
Transactions on Nuclear Science, 43:2742, 1996.
IEEE
[12] E. Normand. Boeing Radiation Effects Laboratory, per-
sonal communication, Oct. 2002.
[13] E. Normand. Boeing Radiation Effects Laboratory, e-
mail, Oct. 2002.
[14] T. J. O’Gorman, J. M. Ross, A. H. Taber, J. F. Ziegler, H. P.
Muhlfeld, C. J. Montrose, H. W. Curtis, and J. L. Walsh.
Field testing for cosmic ray soft errors in semiconductor
memories.
IBM Journal of Research and Development,
40:41–50, Jan. 1996.
[15] D. Patterson. personal communication, Oct. 2002.
[16] M. Schuette. Enhanced Memory Systems Inc., e-mail,
Nov. 2002.
[17] M. Schuette. Enhanced Memory Systems Inc., personal
communication, Sept. 2002.
[18] T. Tso.
random.c – a strong random number generator,
1994. drivers/char/random.c in Linux 2.4.19 source tree.
by error detection, then the attacker can attempt to induce
errors in that bus. It is not sufﬁcient to apply ECC just
within the memory subsystem. Only a few high-end x86-
compatible processors handle ECC on the processor chip
[17].
Logging. Experts have long recommended logging of
errors — even the single-bit errors that are automatically
corrected by ECC hardware — so that patterns of prob-
lems can be detected after the fact. However, many oper-
ating systems do not log errors; this has made it difﬁcult
to diagnose problems [11].
To defend against attacks by heat or other means of in-
ducing errors, the logging system must be able to react to
a substantial increase in the number of errors. If several
errors are detected in a short period, it would be wise to
assume that the system is under attack, and to shut down
— or at least to disable untrusted software that might con-
tain implementations of our attack.
However, if a 3-bit or 4-bit error can be induced before
very many 1-bit and 2-bit errors occur, then logging will
not be successful: the attack will succeed before logging
detects it. For a strong defense, more than 2-bit errors
need to be detected, which can be done by increasing the
number of ECC (overhead) bits in the memory.
9 Conclusion
Allowing the attacker to choose the program to be
run alters many of the assumptions under which error-
protection mechanisms are designed. Virtual machines
that use static checking for protection can be vulnerable
to attacks that exploit soft memory errors. The best de-
fense is the use of hardware error-detection and correction
(ECC), with software logging of errors and appropriate
response to unusual patterns of errors.
Acknowledgments
We would like to thank Yeﬁm Shuf, David Fisch,
Michael Schuette, Eugene Normand, Peter Creath, Perry
Cook, Brent Waters, Lujo Bauer, Gang Tan, Tom van
Vleck, Crispin Cowan, Ed Felten, Jim Roberts, and
Karthik Prasanna for their help in various stages of the
project.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
[19] D. von Oheimb and T. Nipkow. Machine-checking the
Java speciﬁcation: Proving type-safety. In J. Alves-Foss,
editor, Formal Syntax and Semantics of Java, volume
1523 of LNCS, pages 119–156. Springer, 1999.
[20] J. Xu, S. Chen, Z. Kalbarczyk, and R. K. Iyer. An exper-
imental study of security vulnerabilities caused by errors.
In Proceedings of the IEEE International Conference on
Dependable Systems and Networks (DSN-01), July 2001.
[21] J. F. Ziegler, H. W. Curtis, H. P. Muhlfeld, C. J. Montrose,
B. Chin, M. Nicewicz, C. A. Russell, W. Y. Wang, L. B.
Freeman, P. Hosier, L. E. LaFave, J. L. Walsh, J. M. Orro,
G. J. Unger, J. M. Ross, T. J. O’Gorman, B. Messina, T. D.
Sullivan, A. J. Sykes, H. Yourke, T. A. Enger, V. Tolat,
T. S. Scott, A. H. Taber, R. J. Sussman, W. A. Klein, and
C. W. Wahaus. IBM experiments in soft fails in computer
electronics (1978-1994).
IBM Journal of Research and
Development, 40:3–18, Jan. 1996.
A Defeating address obfuscation in IBM’s
JVM
In our attack, it helps to have the address of an ob-
ject so that we can design an an optimal layout to trap bit
ﬂips. If an applet can learn the address of an object, that
in itself is not bad, but it may make other attacks easier.
Dean et al. used the hashCode function to determine the
object address in their attacks [7]. To defeat such attacks,
modern JVMs try not to expose the address of an object.
IBM JVM uses a cloaked object address in its hashCode.
In this appendix, we show that IBM’s cloaking method is
ineffective.
HashCode function. Given an object, the Java speciﬁ-
cation requires that the hashCode method on the object
return the same integer on every call. This method is pro-
vided to provide a good hash function for implementing
hash tables. To reduce the number of collisions, it is desir-
able that given two objects, their hashCodes are different.
One implementation is to return a pseudo-random num-
ber for each object and store the number in the header of
the object. Another implementation, one that saves space
in the object header, is to convert the internal object ad-
dress into an integer. This is a typical implementation,
and works if the object address is the same over its life-
time. In this implementation, if the object were to move
during its lifetime due to compaction or due to a copying
garbage collector, it is required to store the hashCode in
the object header.
A.1 Hashcode Implementation in IBM’s JVM
We used GDB to reverse engineer IBM’s hashCode
function implementation. The hashCode function in the
IBM JVM is implemented as:
2 * sp + clock()
2 * sp + time() - 70
A =
B =
hashCode (address) {
t1 = address >> 3
t2 = t1 ˆ A
t3 = (t2 > 17)
t4 = t3 ˆ B
t5 = t4 >> 1
return t5
}
The JVM computes two global constants A and B dur-
ing its initialisation. These constants are used in the com-
putation of hashCode. In the above code, sp refers to the
stack pointer at the entry of the function where A and B are
computed. Time is the number of seconds elapsed since
January 1, 1970; clock is the processor time used by the
JVM since the start of the current process.
Apparently, the purpose of all the shifting and XOR-
ing is to obfuscate the address of the object. Exposing the
address of an object is a bad security practice. Any bug in
the type system or in the byte-code veriﬁer coupled with
the ready availability of the address might make the sys-
tem vulnerable to attack [7].
Even without knowing the clock and time values, we
can ﬁnd if two objects’ addresses differ by examining
their hashCodes. If c is a constant, a1 and a2 differ in a bit
if and only if c  a1 and c  a2 differ in a bit. Similarly,
if both a1 and a2 are shifted circularly (as in the compu-
tation of t3) or shifted right to remove constant bits (as
in the computation of t1—all objects in the JVM are allo-
cated on an 8-byte boundary), then the resulting values a0
1
and a0
2 will differ in just one bit at a known position. This
implies that for all bits, except bit 20, the object addresses
differ in a bit if and only if the corresponding hashCodes
differ in the corresponding bit. Bit 20 is the bit that is lost
in the computation of t5.
A.2 Obtaining the layout
To maximize our success probability, we base our at-
tack on the object with the maximum number of cousins.
We now describe an algorithm to obtain a layout which
optimizes the cousin number of the object of type A.
IBM’s JVM implements a mark-and-sweep garbage col-
lector [4]. We perform the following steps :
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
environment string. The size of the environment string is
unknown, but can be expected to be less then 10 kbytes.
Based on the limited randomness available in the
sources of A and B, and given the applet’s ability to al-
locate several objects (which will often be placed at con-
secutive addresses) and then query their hashCodes, we
can ﬁnd the values A and B with high conﬁdence, or at
least restrict them to a small set of possible values.
Even bit 20 of the address, which seems irretrievably
lost in the computation of t5, can be recovered by other
means: objects allocated early will likely be in the ﬁrst
megabyte of process address space (bit 20 equals zero),
and objects allocated later will be in the second megabyte
(bit 20 equals one), and so on. The transitions can be
observed in bit 19, and then the transitions in bit 20 can
be inferred.
A.4 Conclusion
IBM’s implementation of hashCode fails to provide ef-
fective obfuscation of the object address. The implemen-
tors would have done better to use a more effective source
of randomness (such as /dev/random on Linux [18]), and
to use a transformation that is less easily reversible than
XORing with a constant. Alternatively, the JVM could
have returned a random number and stored the number in
the header.
(cid:15) Allocate a large number of objects b1 ; b2 ; : : : each
of type B.
(cid:15) Compute the cousin number of each object, by ﬂip-
ping each bit in its hashCode, one at a time, and see-
ing if we have an object with the resulting hashCode.
Choose the object β with the maximum cousin num-
ber; let the address of β be x.
(cid:15) Deallocate the object β. This is done by setting all
variables pointing to it to null. (Java does not have a
free function.)
(cid:15) Call the garbage collector; the address x is added to
front of the free list by the mark-and-sweep garbage
collector. The garbage collector is called by invoking
the method System.GC. This JVM puts objects on
the free list only if they are larger than 512 bytes (it
relies on compaction to reclaim smaller objects), but
our objects are large enough.
(cid:15) Allocate an object α of type A. The memory man-
ager reuses the address x, especially because objects
of types A and B are of the same size.
(cid:15) Set each ﬁeld of type A of each object to α. Set the
ﬁeld b in object α to one of the B objects.
We thus have a layout where the cousin number of the
object α (type A) is optimal. This layout maximizes our
success probability.
A.3 Completely cracking the hashCode
For our attack, we did not need to ﬁnd the exact clock,
time, and sp values used in the hashCode function. But it
is possible to (almost completely) undo the obfuscation.
A Java applet may call System.currentTimeMillis() itself;
it won’t get the same value as the JVM did when initial-
izing the constants A and B, but it will get a value that is
delayed in a predictable way from the original call, espe-
cially if the JVM was invoked speciﬁcally to immediately
load and execute only this applet. The applet can’t call
clock(), but this system call (on our Linux) is measured in
increments of hundredths of a second, and the number of
CPU centiseconds to initialize the JVM has only about 11
possible values (9 to 19).
The stack-pointer value is predictable too: in Linux, it
depends only on the total sizes of the stack frames from
the entry of main to the initialization of A and B—this is a
constant that can be easily learned from reverse engineer-
ing of the JVM—and on the size of the Unix argv and
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE