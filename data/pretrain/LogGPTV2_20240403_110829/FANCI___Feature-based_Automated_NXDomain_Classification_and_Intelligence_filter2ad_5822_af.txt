### Table 14: Results for LOGO CV for mAGDs of Single DGAs Grouped by Seed Using SVMs
In total, 150 sets of 30 DGAs were considered.

| Metric | Value |
|--------|-------|
| 0.00026 |       |
| 0.99133 |       |
| 0.99185 |       |
| 0.99240 |       |
| 0.99252 |       |
| 0.00014 |       |
| 0.99211 |       |
| 0.99254 |       |
| 0.99272 |       |
| 0.99108 |       |
| 0.00047 |       |
| 0.99016 |       |
| 0.99112 |       |
| 0.99207 |       |
| 0.00748 |       |
| 0.00014 |       |
| 0.00728 |       |
| 0.00746 |       |
| 0.00789 |       |
| 0.00892 |       |
| 0.00047 |       |
| 0.00793 |       |
| 0.00888 |       |
| 0.00984 |       |

### Table 18: Classification Accuracy for Training on RWTH Aachen Data and Prediction on Siemens Data Using SVMs

| Metric | Value |
|--------|-------|
| ACC    | 0.99464 |
| TPR    | 0.00017 |
| TNR    | 0.99430 |
| FNR    | 0.99468 |
| FPR    | 0.99492 |
| ACC    | 0.99148 |
| TPR    | 0.00056 |
| TNR    | 0.99037 |
| FNR    | 0.99156 |
| FPR    | 0.99245 |
| ACC    | 0.99779 |
| TPR    | 0.00037 |
| TNR    | 0.99721 |
| FNR    | 0.99784 |
| FPR    | 0.99854 |
| ACC    | 0.00852 |
| TPR    | 0.00056 |
| TNR    | 0.00755 |
| FNR    | 0.00844 |
| FPR    | 0.00963 |
| ACC    | 0.00221 |
| TPR    | 0.00037 |
| TNR    | 0.00146 |
| FNR    | 0.00216 |
| FPR    | 0.00279 |

### Table 15: Results for Detecting mAGDs with SVMs of Arbitrary Mixed DGAs Using 5 Repetitions of 5-Fold CV for Each Set
In total, 20 sets were considered.

| Metric | Value |
|--------|-------|
| ACC    | 0.97972 |
| TPR    | 0.00041 |
| TNR    | 0.97894 |
| FNR    | 0.97967 |
| FPR    | 0.98073 |
| ACC    | 0.96195 |
| TPR    | 0.00056 |
| TNR    | 0.96088 |
| FNR    | 0.96207 |
| FPR    | 0.96304 |
| ACC    | 0.99746 |
| TPR    | 0.00040 |
| TNR    | 0.99672 |
| FNR    | 0.99747 |
| FPR    | 0.99839 |
| ACC    | 0.02635 |
| TPR    | 0.00061 |
| TNR    | 0.02517 |
| FNR    | 0.02622 |
| FPR    | 0.02751 |
| ACC    | 0.00254 |
| TPR    | 0.00040 |
| TNR    | 0.00161 |
| FNR    | 0.00253 |
| FPR    | 0.00328 |

### Table 16: Results for LOGO CV for Sets of mAGDs of Mixed DGAs Grouped by DGA Using SVMs
In total, 20 sets were considered.

| Metric | Value |
|--------|-------|
| ACC    | 0.99394 |
| TPR    | 0.00031 |
| TNR    | 0.99327 |
| FNR    | 0.99402 |
| FPR    | 0.99436 |
| ACC    | 0.99331 |
| TPR    | 0.00070 |
| TNR    | 0.99135 |
| FNR    | 0.99341 |
| FPR    | 0.99425 |
| ACC    | 0.99456 |
| TPR    | 0.00047 |
| TNR    | 0.99371 |
| FNR    | 0.99451 |
| FPR    | 0.99533 |
| ACC    | 0.00669 |
| TPR    | 0.00070 |
| TNR    | 0.00575 |
| FNR    | 0.00659 |
| FPR    | 0.00865 |
| ACC    | 0.00544 |
| TPR    | 0.00047 |
| TNR    | 0.00467 |
| FNR    | 0.00549 |
| FPR    | 0.00629 |

### Table 17: Results for Classifying mAGDs of Arbitrary Mixed DGAs and bNXD from Siemens Applying 5 Repetitions of 5-Fold CV for 20 Sets Each of Size 100,000 Using SVMs

| Metric | Value |
|--------|-------|
| ACC    | 0.99448 |
| TPR    | 0.00017 |
| TNR    | 0.99419 |
| FNR    | 0.99447 |
| FPR    | 0.99479 |
| ACC    | 0.99412 |
| TPR    | 0.00017 |
| TNR    | 0.99387 |
| FNR    | 0.99415 |
| FPR    | 0.99442 |
| ACC    | 0.99485 |
| TPR    | 0.00033 |
| TNR    | 0.99432 |
| FNR    | 0.99483 |
| FPR    | 0.99559 |
| ACC    | 0.00588 |
| TPR    | 0.00017 |
| TNR    | 0.00558 |
| FNR    | 0.00585 |
| FPR    | 0.00613 |
| ACC    | 0.00515 |
| TPR    | 0.00033 |
| TNR    | 0.00441 |
| FNR    | 0.00517 |
| FPR    | 0.00568 |

### Table 19: Classification Accuracy for Training on Siemens Data and Prediction on RWTH Aachen Data Using SVMs

| Metric | Value |
|--------|-------|
| ACC    | 0.93683 |
| TPR    | 0.00059 |
| TNR    | 0.93565 |
| FNR    | 0.93689 |
| FPR    | 0.93778 |
| ACC    | 0.98900 |
| TPR    | 0.00049 |
| TNR    | 0.98807 |
| FNR    | 0.98913 |
| FPR    | 0.99010 |
| ACC    | 0.88465 |
| TPR    | 0.00103 |
| TNR    | 0.88269 |
| FNR    | 0.88470 |
| FPR    | 0.88629 |
| ACC    | 0.01100 |
| TPR    | 0.00049 |
| TNR    | 0.00990 |
| FNR    | 0.01087 |
| FPR    | 0.01193 |
| ACC    | 0.11535 |
| TPR    | 0.00103 |
| TNR    | 0.11371 |
| FNR    | 0.11530 |
| FPR    | 0.11731 |

### Table 20: Classification Accuracy for 5-Fold CV on Successfully Resolved Domains and mAGDs of Arbitrary DGAs Using SVMs

### B. Grid Search Results
In this section, we present the results of our grid search. To reduce the number of grid searches required for single-DGA detection, we performed one grid search per DGA generation scheme as introduced in the taxonomy by Plohmann et al. [14]. All grid searches were conducted on sets of size 20,000. To avoid overfitting, we performed grid searches on 6 independent sets for the multi-DGA detection case. The final parameter selection for multi-DGA detection is based on mathematical constraints of the respective ML algorithm and domain knowledge on the classification problem. The ML algorithm parameters are named according to standard references for SVMs [7] and RFs [6].

#### For Random Forests (RFs)
- **Parameter T**: An integer drawn uniformly at random from [10, 1000], where we considered 64 values for T.
- **Parameter F**: An integer selected from [2, 44], where each possible value is assigned to F.
- **Impurity Criterion i(N)**: Either Gini impurity or entropy impurity.

This results in \(64 \times 43 \times 2 = 5504\) 5-fold CVs in total per data set.

#### For Support Vector Machines (SVMs)
- **Parameter C and γ**: After some initial tests, we fixed the parameter range for C and γ to [2\(^{-16}\), 2\(^3\)] and considered 80 values drawn logarithmically at random for both parameters.
- This results in 80 5-fold CVs for the linear kernel and \(80^2 = 6400\) 5-fold CVs for the RBF kernel per data set.

### Table 24: Best Parameter Choices Depending on the Type of DGA for SVMs
The above parameters are used in all experiments where single DGAs are considered and are applied depending on the DGA’s generation scheme.

| Generation Scheme | DGA | Kernel | C | γ | ACC |
|-------------------|-----|--------|---|---|-----|
| Arithmetic        |     | Linear | 3.4669 | — | 0.9999 |
| Hash              |     | Linear | 0.0052 | — | 1.0 |
| Wordlist          |     | Linear | 0.2289 | — | 0.9999 |
| Permutation       |     | RBF    | 0.0234 | 0.0327 | 1.0 |

### Table 21: Best Parameter Choices for Independent Data Sets of Mixed DGAs for RFs
For the final selection, i(N) is selected by majority vote. F is the arithmetic mean. For T, the maximum is chosen.

| Set # | i(N) | F | T | ACC |
|-------|------|---|---|-----|
| 1     | Entropy | 25 | 17 | 0.9981 |
| 2     | Gini   | 10 | 33 | 0.9993 |
| 3     | Entropy | 22 | 72 | 0.9983 |
| 4     | Gini   | 7  | 161 | 0.9987 |
| 5     | Gini   | 13 | 227 | 0.9984 |
| 6     | Gini   | 31 | 785 | 0.9983 |
| Final | Gini   | 18 | 785 | — |

### Table 22: Best Parameter Choices Depending on the Generation Scheme of the DGA for RFs
The above parameters are used in all experiments where single DGAs are considered and are applied depending on the DGA’s generation scheme.

| Generation Scheme | DGA | i(N) | F | T | ACC |
|-------------------|-----|------|---|---|-----|
| Arithmetic        |     | Gini | 8 | 681 | 0.9999 |
| Hash              |     | Gini | 2 | 388 | 1.0 |
| Wordlist          |     | Gini | 5 | 57 | 0.9999 |
| Permutation       |     | Gini | 2 | 513 | 1.0 |

### Table 23: Best Parameter Choices for Independent Data Sets of Mixed DGAs for SVMs
For the final selection, the kernel is selected by majority vote. C is selected as the median. γ is chosen as the arithmetic mean, only among the RBF results.

| Set # | Kernel | C | γ | ACC |
|-------|--------|---|---|-----|
| 1     | RBF    | 2.9423 | 0.0198 | 0.9992 |
| 2     | Linear | 0.1729 | — | 0.9982 |
| 3     | RBF    | 1.7844 | 0.0102 | 0.9985 |
| 4     | RBF    | 2.9423 | 0.0234 | 0.9982 |
| 5     | RBF    | 4.8517 | 0.0073 | 0.9982 |
| 6     | RBF    | 5.7317 | 0.0751 | 0.9979 |
| Final | RBF    | 0.9160 | 0.0198 | — |