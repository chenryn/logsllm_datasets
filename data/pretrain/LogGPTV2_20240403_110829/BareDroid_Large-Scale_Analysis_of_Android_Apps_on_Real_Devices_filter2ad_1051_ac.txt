can start either one of the following two procedures:
SupervisorUpdate_managerdeviceUpdate_managerrecoveryUpdate_managerAnalysisconfig.cfgdevices.infoTable 1: Time necessary by BareDroid to restore a de-
vice
Restoring step Time (seconds)
restore the recovery partition using ADB
reboot into recovery mode
swap userdata partitions
boot the operating system
total
if dm-verity detects errors
in the system partition:
send system partition through ADB
rewrite system partition
total
0.963
8.923
1.976
19.900
31.762
27.927
35.233
94.922
1. Update manager device, which manages the up-
date of the userdata partition;
2. Update manager recovery, which manages the
swap of the userdata partitions when the device
is in \recovery mode";
5. EVALUATION
In this section we will evaluate BareDroid under dif-
ferent aspects. First of all, we will measure the time our
system needs to restore a device before starting a new anal-
ysis in the scenarios outlined in Section 3.2. Then, we will
evaluate the cost-eﬀectiveness of BareDroid when com-
pared to both an emulator-based analysis system, and a
system naively restoring a device at every reboot.
In ad-
dition, we will demonstrate that BareDroid is resilient to
current state-of-the-art approaches to detect emulators. Fi-
nally, we will show how existing real-world malware samples
are unable to detect our system, allowing dynamic analyses
on them to return more detailed and realistic results.
5.1 Performance Overhead
5.1.1 Device Restoring Time
For our experiments, we used an LG Nexus 5 device with
Android 5.1.0 r3. All reported measures have been aver-
aged on 5 runs of the experiment. Table 1 reports the time
needed by all the steps performed by BareDroid to restore
a device. In total, 31.762 seconds are necessary to restore a
device.
As explained in Section 3.3, if one of the integrity veri(cid:12)-
cation steps fails, restoring the device obviously takes addi-
tional time. Speci(cid:12)cally, if dm-verity detects corruption in
the system partition, 63.797 additional seconds are required,
bringing the total restoring time to 94.922 seconds.
We also tested the time needed to perform a full restore
of a device, without using BareDroid. Recall that with-
out using BareDroid the only feasible way to completely
restore a device’s state is to read using ADB and write on
the device’s (cid:13)ash memory a full clean copy of the recovery,
system, and userdata partitions. This procedure requires
141.268 seconds. Thus, BareDroid’s restore time is 4.44
times faster than the restore time of the vanilla approach.
Table 2: Values used in our cost analysis
Cost per
device/cpu
BareDroid
full device restore system
emulator-based system
$349
$349
$300
Restore
time
31.768s
141.268s
1s
Figure 2: Cost analysis of using BareDroid and other
approaches when performing large-scale malware analy-
ses.
5.1.2 Analysis Slowdown
After the completion of the device’s boot, BareDroid
restores a copy of the userdata partition to speedup the
next restore, as explained in Section 3.3. The time required
by this step is 25.351 seconds. This part of the restoration
happens in parallel with the sample analysis. Hence, this
time overhead can be ignored if a sample-analysis run lasts
longer than 25 seconds, which is usually the case in practice.
Moreover, we evaluated if the presence of an underlying
process performing this step slows down an analysis running
on the device. For this, we run the benchmarking app An-
TuTu 2 while the restoring process was running, and while it
was not. The benchmarking application did not report any
signi(cid:12)cant diﬀerence in the two cases. The score reported
by AnTuTu with and without the restore process is 28,353
and 28,355 respectively. For this reason, we believe that
the performance impact caused by the restoring process is
negligible.
5.2 Cost Analysis
Based on the speed and cost of one device, we evaluate
and compare the throughput (in terms of apps per second)
that can be achieved using BareDroid, an emulator-based
system, and a system in which a full restore of a device is
performed every time.
For this evaluation, we assumed that BareDroid is used
with a Nexus 5 device (since this is the device we used to
perform the experiments described in this section), with a
cost per unit of $349 [5]. To evaluate the cost of an emulator-
2www.antutu.com
406080100120140160180Appexecutiontime(seconds)0123456Throughput(apps/seconds)Baredoid($50,000)Full-restore($50,000)Emulator($50,000)BareDroid($75,000)Table 3: Number of (cid:12)le operations generated by ma-
licious samples in BareDroid and in an emulator-based
system. The percentage between (cid:12)le operations detected
by an emulator-based system and BareDroid is written in
parenthesis. The * symbol indicates that the app crashed
upon start, probably due to anti-emulator checks.
Sample Emulator-based system BareDroid
Android.HeHe.1
Android.HeHe.2
Android.HeHe.3
Android.HeHe.4
Android.HeHe.5
Android.HeHe.6
Android Pincer.A
OBAD.1
OBAD.2
2 (11.76)%
9 (27.27)%
2 (11.76)%
0* (0.00)%
0* (0.00)%
9 (27.27)%
3 (8.82)%
0* (0.00)%
0* (0.00)%
17
33
17
50
50
33
34
32
32
total
25 (8.39%)
298
BareDroid infrastructure (e.g., the setup of the Supervisor
machine and the cabling), and the wear of the (cid:13)ash memory
(the program-erase cycles of a NAND (cid:13)ash is typically about
100K). Another limitation of our cost analysis is that it does
not take into account that malware might speci(cid:12)cally tar-
get our infrastructure, for example by tampering with the
in such case, BareDroid’s restore time
system partition:
would be higher. Although we are currently not aware of
any malicious sample with such capability, future malware
samples could attempt to do so. However, while restoring
the system partition takes more time, it is trivial to detect
such tampering attempts, thus making this kind of advanced
malware easily identi(cid:12)able.
5.3 Security Evaluation
As discussed throughout the paper, one of the key limi-
tations of modern analysis systems for Android apps is that
they are based on emulators, and can therefore be easily
detected and evaded. In this section, we will discuss the re-
sults of several experiments that highlight the resilience of
BareDroid against these emulation-detection techniques.
We (cid:12)rst tested the app developed as part of the paper de-
scribing Morpheus [16]. This app is designed to detect emu-
lators via hundreds of diﬀerent checks, and it represents the
current state-of-the-art in emulation detection in Android.
As expected, when run in BareDroid, this application did
not detect it was being run within an analysis environment.
As a second experiment, we also tested the resilience of
BareDroid against emulator-detection techniques used by
real-world malicious samples: when these malware samples
detect they are running within an emulator, they do not
perform speci(cid:12)c behaviors to avoid detection and hinder re-
verse engineering. To show that BareDroid improves the
analysis of these samples, we designed a prototype analysis
system, and we veri(cid:12)ed that this analysis elicits more behav-
iors when run in BareDroid compared to when it is run in
an emulator-based system. It is important to note that while
we believe many diﬀerent malware analysis systems can be
run on top of BareDroid, it would not be possible to run
those analysis approaches that intrinsically rely on system
emulation, such as taint analysis on native code.
Our analysis dynamically stimulates a sample (by using a
manual approach) for 1 minute, and it monitors its behav-
Figure 3: Throughput ratio between the diﬀerent
analyzed systems.
based system, we considered the price of a high-end server
and we evaluated the cost per physical core. We then consid-
ered a scenario in which a physical core and 4GB of RAM are
allocated for each emulator. This implies a cost of $300 [28]
for each running emulator. Note that this is a conserva-
tive assumption, likely to overestimate the performance of
an emulator-based system.
In fact, apps run signi(cid:12)cantly
slower in emulators with respect to when run on real de-
vices and, for this reason, when using an emulator it is usu-
ally necessary to run a given app for a longer amount of time
to achieve comparable results. Finally, we assume that in an
emulator-based system, the restoring time is almost instant
(1 second). Table 2 summarizes the parameters used in our
cost analysis.
Figure 2 assumes a $50,000 equipment investment, and
it shows the throughput in the three considered scenar-
ios, given a desired analysis time. This evaluation shows
how BareDroid achieves a performance that is in-between
an emulator-based system and a system performing a full-
device restore, while, at the same time, oﬀers a realistic exe-
cution environment that cannot easily evaded by emulator-
aware malware. Moreover, the cost overhead necessary to
achieve the same throughput of an emulator-based system
is only about 50% (as shown by the blue dotted line in Fig-
ure 2).
Assuming the same scenario, we also computed the ratio
of the throughput obtained with BareDroid and a system
performing a full restore at every reboot, and the ratio of
the throughput obtained with an emulator-based system and
BareDroid. Figure 3 reports the results. It is interesting
to note how, for analysis times higher than two minutes,
the ratio between the emulator and BareDroid is less than
1.5, whereas the ratio between BareDroid and a full-restore
system is always higher than 1.5. We believe these results
clearly show the practicality of using BareDroid.
That being said, it is important to note that our cost
analysis has some limitations. For instance, it does not take
into consideration the power consumption, the extra main-
tenance factors such as the human time spent to setup the
406080100120140160180Appexecutiontime(seconds)1.01.52.02.53.0ThroughputratioBareDroidvs.Full-restoreEmulatorvs.Baredroidiors. As described in [25, 31], one of the approaches to de-
scribe the behavior of Android malware is to log the system-
calls invoked during the execution, and to then perform out-
of-the-box behavioral analysis. To leverage this approach
without introducing modi(cid:12)cations to the kernel or adding
speci(cid:12)c components we take advantage of SELinux [29]: In
practice, before the execution of each system call, the kernel
queries SELinux to know whether a given process is autho-
rized to perform the requested operation.
In particular, since, by default, SELinux records only the
denied operations, we modi(cid:12)ed the SELinux policy to obtain
information about each \granted" system call. The modi(cid:12)ca-
tion used to implement our analysis consists in the introduc-
tion of an auditallow rule per each allow rule in order to get
a complete report of the operations performed by an app.
From this report, we extracted information about (cid:12)le opera-
tions and we used it as an empirical measure of the amount
of behaviors performed by the malicious application under
analysis.
We run our experiment on several malicious samples that
were known to be able to detect whether they are executed
within an emulator. In particular, we considered the follow-
ing applications:
(cid:15) six variants of Android.HeHe [12]. This sample is able
to steal text messages and intercept phone calls;
(cid:15) one sample of Android Pincer.A [10]. This sample is
able to forward SMS messages and perform other ac-
tions based on commands it receives from a remote
C&C server;
(cid:15) two variants of OBAD [6]. This sample supports a
wide variety of malicious features and communicates
with a remote C&C server.
The results of our analysis are summarized in Table 3.
Our results show that, globally, the emulator-based sys-
tem detected only 8.39% of the (cid:12)le operations performed
by the analyzed samples in BareDroid. These results show
how emulator-based systems are ineﬀective in analyzing such
samples. In addition, it is interesting to notice that 4 sam-
ples did not perform any (cid:12)le operation at all when executed
in an emulator-based system.
6. DISCUSSION
6.1 Fingerprinting
As discussed in Section 2, an emulator can be detected us-
ing several techniques. Although it is possible to adopt a set
of countermeasures for some of these techniques (e.g., check-
ing for speci(cid:12)c emulator’s properties), it is extremely chal-
lenging, if not outright impossible, to correctly implement
mitigations for some others (e.g., performance and timing
issues). The key observation that makes this aspect prob-
lematic is the following: normal users do not use emulators,
and hence the mere detection of the presence of an emulator
is already enough for a malicious application to (cid:12)ngerprint
and evade all existing analysis systems. We believe Bare-
Droid signi(cid:12)cantly raises the bar when analyzing evasive
malware applications. In fact, our infrastructure is consti-
tuted by the very same devices that a normal user would
use on a daily basis.
That being said, we note that, even if BareDroid dras-
tically reduces the (cid:12)ngerprinting surface by executing apps
on a very common device class, ad-hoc (cid:12)ngerprinting tech-
niques could still be used to detect the speci(cid:12)c devices
running BareDroid. For example, malicious applications
could try to (cid:12)ngerprint a given analysis infrastructure by
checking the device’s MAC address or IMEI number, or
by analyzing the partitions table. However, our proposed
solution pushes malicious applications from attempting to
(cid:12)ngerprint a device class (emulator vs. real device), to at-
tempting to (cid:12)ngerprint a very speci(cid:12)c device (e.g., one of
the speci(cid:12)c Nexus 5 phone we used). We believe this to
be a much more challenging goal.
In fact, mimicking a
diﬀerent instance of a speci(cid:12)c device (another Nexus 5) is
considerably easier than mimicking another device class (as
emulators do). Moreover, (cid:12)ngerprinting the speci(cid:12)c device
can be in part mitigated by, for example, reusing some of
the anti-evasion techniques employed by emulator-based dy-