Hello, and Welcome. My name is Tom Ritter, and I work for iSEC Partners.  If you don’t 
know who Zax is, you will by the end of this talk. 
This talk is about an anonymity network that was started in the fledgling days of the 
Cypherpunk era – the early 1990s.   
This book hadn’t even come out yet – this is the second edition.  But this is the first 
edition, and it had come out, and the US had ruled you while you could export the 
book itself, you couldn’t export the floppy disk with the source code. 
The United States government was actively investigating Phil Zimmerman for violating 
the Arms Control Export Act, for making the first few versions of PGP available.   
Dan Bernstein and the toddler-aged EFF went on the offensive taking the US 
government to court and suing over the export controls on cryptography.   
Another group of people ultimately printed the source code for PGP, exported the 
book to Europe, scanned it in, and OCR-ed it in 1997 releasing a version of PGP that 
bypassed export controls 
Alt.Anonymous.Messages was forged in the heyday of the cypherpunks, and really, 
overall, has changed very little in the intervening decade since it was last shaped in 
any major way.   
And in that decade, what we have seen is a monumental focus of the nations spy  
1 
agencies on not what was thought to be the most critical piece of information to 
encrypt – the content itself.  But instead….  
1 
The people who know won’t talk, and the people who talk don’t know.   But the 
leaked court orders require Verizon to turn over call records local and abroad.  Now, 
I’m talking here, so I don’t know anything and am just speculating – but the most 
straightforward thing to do with this data is to build communication graphs.  Analyze 
the metadata, looking for patterns.  Identify people of interest, and figure out who 
they talk to. 
The metadata around an encrypted channel tells volumes. 
2 
SSL, is the most widely used encrypted channel on the internet today.  And even 
ignoring the numerous attacks we’ve seen on it in the past few years, and even 
ignoring how it breaks just about every cryptographic best practice there is – there is 
a wealth of information you can learn from observing an SSL session.  There are 
protocol level leaks – SSL says a lot about what type of client you’re using, and it’s 
version.  It also includes what you think the local time is. 
3 
But from an information theoretic perspective, an adversary can see that you’re 
sending packets, and communicating.  That seems obvious, of course they can – but 
it’s important to bear in mind for the future.  Ideally, our adversary wouldn’t even 
know if we’re communicating.   
Secondly, SSL makes no attempt at hiding who you’re talking to.  So the fact that 
you’re on Facebook is straightforward.   
And similarly, the adversary knows when you’re on Facebook.  And when you are 
sending data and when you are receiving data.  The resolution on this goes down 
literally to the microsecond. 
So they know exactly when, and they also know exactly how much data you receive.  
SSL doesn’t have any real padding, and I don’t know of any website that adds variable 
padding to frustrate length analysis.  
4 
So let’s talk about Tor.  Tor is an implementation of Onion Routing, where you pass 
messages along a chain, each node peeling off a layer of encryption, until an exit 
node talks to the intended destination.  The destination responds, and it’s routed 
back. 
5 
Onion Routing specifically aims to disguise Who is talking.   An adversary observing 
you can’t see that you’re talking to a website (or a service), and an adversary 
observing that website or service can’t see who is talking to that website. 
But it doesn’t stop an adversary from knowing you’re talking to someone, knowing 
when you’re talking, and how much you’re saying.   
Tor doesn’t really do padding what little it does is not intended to be a security 
feature.  Tor explicitly leaves _out_ link padding. 
6 
And if you stayed through Runa’s talk, you know that Tor cannot protect you if the 
adversary can see the entire path of the circuit.   
Let’s say hypothetically, New Zealand, Australia, the US, Canada, and the UK were to, 
say, conspire secretly on some sort of spy program.   
Well if your circuit went through those countries – Tor can’t help you.  The adversary 
can track your traffic, and find out who you’re talking to.  I’m not saying this is actively 
happening, I’m saying we’ve proved in papers that it’s possible, and it’s outside Tor’s 
threat model. 
7 
And a slightly more difficult version of that attack is if the adversary can see you, and 
then see the last leg of the path later on, like say, you’re in China visiting a Chinese 
website.  Well, they can do a similar attack, and track you down.  It requires a little bit 
more math, but again, we’ve proved it’s possible, and it’s outside Tor’s threat model.   
And this is particularly concerning seeing as I, like most of you probably, are in the 
US…. And so much of what we do online is hosted in the Virginia datacenter of EC2. 
8 
So if either of those two cases apply, we’re basically back at SSL, because the 
adversary can tell who you’re talking to. 
9 
And at this point, I think it’s worthwhile to show a couple of attacks on metadata. 
IOActive built a proof of concept traffic analysis tool, that looks at your SSL session 
with Google, and figures out what part of google maps you’re looking at – all based 
off the sizes of the tiles you’re downloading over SSL.   
It’s worthwhile to note this is an attack on a client, on someone browsing google 
maps at that moment.  I want to show an alternate example. 
10 
You’re sitting on facebook, with facebook chat enabled – all over SSL.  Heck, all over 
Tor.   
Well Facebook chat acts as a _server_ - you are able to receive messages from 
people, and they will be pushed down to you.  The *attacker*, not you, determines 
when you will receive a message.  That’s a pretty powerful capability, and it can lead 
to time-based correlation attacks.  An adversary sends you a message, and then looks 
at all the people connected to Facebook, or Tor, and sees who recieves a message 
right after that. 
11 
And even easier, because Facebook chats tend to be small – it can lead to size-based 
correlation attacks.  Now not only do I send you a Facebook chat, but I send you a 
HUGE Facebook chat.  With only a couple of trials you can be pretty confident that 
the user whose internet connection you’re monitoring is the same anonymous Syrian 
dissident you’re messaging on Facebook. 
And it’s interesting to note that a very similar attack was used to de-anonymize 
Jeremy Hammond, who is currently awaiting trial for allegedly dumping Stratfor’s 
mailspools.  The police staked out his home, watched him enter, saw some Tor traffic, 
and whoop – the username they thought was him, popped onto IRC.  Classic traffic 
confirmation attack.  And I’ve gotten some comments they also cut his Internet 
connection, and watched him drop off IRC, but I haven’t seen the police logs from 
that side of things – if that is true, that’s another type of traffic confirmation attack 
on a low latency connection. 
http://arstechnica.com/tech-policy/2012/03/stakeout-how-the-fbi-tracked-and-
busted-a-chicago-anon/ 
12 
Now the good news is that even if the adversary can see the start and end nodes, or 
even the entire path, there is a way to disguise who you’re talking to.  And that’s Mix 
Networks.  Mix Networks introduce a delay, while they collect messages into a pool, 
and then fire them all out.  Collecting the messages prevents an adversary who’s 
observing the mix from knowing what message went where.  It introduces 
uncertainty.   
Mix Networks are a super important part of anonymous communication, that I want 
to encourage the growth of, so I want to take a quick minute to demonstrate it to 
you, live on stage. 
13 
Alright, so Mix Networks demonstrated, we’ve gained back a certain amount of 
protection against figuring out who it is I’m communicating with. Given enough time, 
or a low enough traffic volume, an adversary can perform the same types of attacks I 
described against Tor – but it takes a lot more observation.  And the easiest thing to 
learn, that takes no time or analysis, is the fact that I’m communicating, when I send 
a message, and how large it is – that is still apparent to someone observing my 
network connection. 
14 
Enter Shared Mailboxes, and Alt.Anonymous.Messages.  A shared Mailbox is what is 
sounds like.  Imagine an email account where everyone in the room has the 
username and password – but it’s read only access – you can’t delete messages, or 
even send them from this mailbox.  
All of the messages are encrypted, so what you do, as one of the people with access 
to this inbox, is download all the messages, and try and decrypt each message with 
your private key. 
15 
And a couple of those messages happen to be for you.  The rest, you can’t decrypt, so 
they must not be.   
16 
Well, someone watching this encrypted connection can tell that you’re accessing the 
shared mailbox, and downloading all of the messages – that’s certain.  But they don’t 
actually know if you’ve received messages – they only know that you downloaded all 
of the messages, not if you could decrypt any of them. 
And because of that, they don’t know when you’ve received a message, who it was 
from, or how large it was.  All they know if that you’re checking the mailbox. 
At the cost of a lot of bandwidth, receiving messages via a Shared Mailbox provides 
an awful lot of security comparatively! 
17 
Now, shared mailboxes are an awesome anonymity tool, but the difference between 
an awesome anonymity tool and an anonymity tool that’s actually used is the answer 
to the question: “Can I interact with the rest of the world?”  Tor, wildly successful 
compared to other systems, because you can browse the actual internet with it.  It’s 
not a closed system where you only interact with hidden services. 
So for a shared mailbox to actually be used, it needs to interact with normal email.  
That’s where nymservs come in.  The simplest nymserv, the newest and easiest to 
use, receives a message at a domain name, and post it immediately to 
alt.anonymous.messages.  This is a nymserv written by Zax, and it’s on github. 
18 
The much more complicated Type I or ghio nymservs can forward the mail to another 
email address, directly to alt.anonymous.messages, or route it through a remailer 
network to eventually wind up one of those two places.  I’ll talk more about this 
nymserv later on. 
19 
So if we add in nymservs, Shared Mailboxes have awesome anonymity for the 
recipient.  When you send a message to a nym that uses a shared mailbox, you’re 
ideally using an Onion Router or a Mix Network (although you don’t have to), and 
thus have those security properties – an adversary can see that you’re sending a 
message, when you sent it, and how large it was 
20 
So, now that I’ve walked through the security properties of the different types of 
anonymity networks, let’s actually dive into AAM.  It should have really strong 
security, afterall it’s the most theoretically secure.   
If you’ve never looked at it before, this is what it looks like in Google Groups.  A 
bunch of hexadecimal subjects, posted by Anonymous or Nobody 
21 
And any individual message usually looks like a PGP Message that may or may not 
have a version string. 
22 
There’s about 190 messages posted per day these days, but what’s interesting is 
while the average certainly has decreased over the last decade, it’s held somewhat 
steady in the last 5 years. 
23 
The dataset I worked off of was about 1.1 million messages from the last ten years.   
Now we can already see some shortcomings here.  Over half of the messages in my 
dataset go through nodes operated by two people.  The network diversity is horrible, 
and the network itself would be thrown into disarray if either one of these folks got 
subpoena-ed, shut down, or retired.   But, it’s actually much worse than this slide. 
603,844 / 1,128,312 = 53.5% 
Dizum: 416579 
Zax: 192317 
24 
You see that 53.5% statistic was over the entire dataset.  Today, these two folks make 
up virtually all of AAM. 
That dip: 7,800 messages through Frell, which operates a remailer and a 
newsgateway 
Subject: España busca que el consejo resuelva problema de activos tóxicos 
No unique headers, identical PGP signaturas of Tag types 10,3,9 
I couldn’t get much out of those messages, other than that someone sent out 7800 
messages in a group, over a short timespan, and then stopped.. 
25 
So, with network diversity pretty clearly abolished, let’s take a look at the data, and 
see what types of analysis we can do. 
26 
I don’t think I can say anything as ironic as this quote, which I pulled from literally, 
1994.   
Read it 
And here we are, just shy of 20 years later. 
27 
So the first thing to do is to break it up by PGP or Not-PGP.  And you can see it’s 
overwhelmingly PGP messages. 
So, really quickly, what are the non-PGP messages? 
28 
Well, I was trying to come up with a nice way to say crackpots – I’m not sure if I 
succeeded. 
But there are several people who have and continue to post just… random… rants.  
About… I’m not really sure.  And there are actually Frequently Asked Questions that 
have sprung up in response to the crackpots, because people were just getting flat 
out confused. 
29 
So, besides those there are some other non-PGP messages.  I think most interesting is 
a set of about 10K messages with the subject ‘SATANIC OPERATION’ , or OPERATION 
SATANIC.  What’s interesting about these messages is they’re clearly ciphertext, but 
alphabetic.  If you look at a single message, you almost think it’s a Ceaser Cipher, or a 
Vigenere, or a polyalphabetic.  But if you analyze the messages in whole, you discover 
a 16 letter alphabet with a perfectly even distribution.   