served applications reading stored SMS messages (125
times per user/day), reading browser history (5 times per
user/day), and accessing the camera (once per user/day).
Though the use of these permissions does not necessarily
lead to privacy violations, users have no contextual cues
to understand that these requests are occurring.
4.2 High Frequency Requests
Some permission requests occurred so frequently that a
few applications (i.e., Facebook, Facebook Messenger,
Google Location Reporting, Google Maps, Farm Heroes
Saga) had to be rate limited in our log ﬁles (see Sec-
tion 3.1.1), so that the logs would not ﬁll up users’ re-
maining storage or incur performance overhead. Table 4
shows the complete list of application/permission com-
binations that exceeded the threshold. For instance, the
most frequent requests came from Facebook requesting
ACCESS NETWORK STATE with an average interval
of 213.88 ms (i.e., almost 5 times per second).
it
is regained.
With the exception of Google’s applications, all rate-
limited applications made excessive requests for the
connectivity state. We hypothesize that once these
applications lose connectivity,
they continuously poll
the system until
Their use of the
getActiveNetworkInfo() method results in permis-
sion checks and returns NetworkInfo objects, which al-
low them to determine connection state (e.g., connected,
disconnected, etc.) and type (e.g., WiFi, Bluetooth, cel-
lular, etc.). Thus, these requests do not appear to be leak-
ing sensitive information per se, but their frequency may
have adverse effects on performance and battery life.
It is possible that using the ConnectivityManager’s
NetworkCallback method may be able to fulﬁll this
need with far fewer permission checks.
Application / Permission
com.facebook.katana
ACCESS NETWORK STATE
com.facebook.orca
ACCESS NETWORK STATE
com.google.android.apps.maps
ACCESS NETWORK STATE
com.google.process.gapps
AUTHENTICATE ACCOUNTS
com.google.process.gapps
WAKE LOCK
com.google.process.location
WAKE LOCK
com.google.process.location
ACCESS FINE LOCATION
com.google.process.location
GET ACCOUNTS
com.google.process.location
ACCESS WIFI STATE
com.king.farmheroessaga
ACCESS NETWORK STATE
com.pandora.android
ACCESS NETWORK STATE
com.taptu.streams
ACCESS NETWORK STATE
Peak (ms) Avg. (ms)
213.88
956.97
334.78
1146.05
247.89
624.61
315.31
315.31
898.94
1400.20
176.11
991.46
1387.26
1387.26
373.41
1878.88
1901.91
1901.91
284.02
731.27
541.37
541.37
1746.36
1746.36
Table 4: The application/permission combinations that
needed to be rate limited during the study. The last two
columns show the fastest interval recorded and the aver-
age of all the intervals recorded before rate-limiting.
4.3 Frequency of Data Exposure
Felt et al. posited that while most permissions can be
granted automatically in order to not habituate users to
relatively benign risks, certain requests should require
runtime consent [14]. They advocated using runtime di-
alogs before the following actions should proceed:
1. Reading location information (e.g., using conven-
tional location APIs, scanning WiFi SSIDs, etc.).
2. Reading the user’s web browser history.
3. Reading saved SMS messages.
4. Sending SMS messages that incur charges, or inap-
propriately spamming the user’s contact list.
These four actions are governed by the 12 Android per-
missions listed in Table 1. Of the 300 applications that
we observed during the experiment, 91 (30.3%) per-
formed one of these actions. On average, these permis-
sions were requested 213 times per hour/user—roughly
every 20 seconds. However, permission checks occur un-
der a variety of circumstances, only a subset of which ex-
pose sensitive resources. As a result, platform develop-
506  24th USENIX Security Symposium 
USENIX Association
8
Resource
Location
Read SMS data
Sending SMS
Browser History
Total
Visible
Data Exposed Requests
2,205
486
7
14
2,712
758
378
7
12
1,155
Invisible
Data Exposed Requests
8,755
125
1
5
8,886
3,881
72
1
2
3,956
Total
Data Exposed Requests
10,960
611
8
19
11,598
4,639
450
8
14
5,111
Table 5: The sensitive permission requests (per user/day) when requesting applications were visible/invisible to users.
“Data exposed” reﬂects the subset of permission-protected requests that resulted in sensitive data being accessed.
ers may decide to only show runtime warnings to users
when protected data is read or modiﬁed. Thus, we at-
tempted to quantify the frequency with which permission
checks actually result in access to sensitive resources for
each of these four categories. Table 5 shows the number
of requests seen per user/day under each of these four
categories, separating the instances in which sensitive
data was exposed from the total permission requests ob-
served. Unlike Section 4.1, we include “visible” permis-
sion requests (i.e., those occurring while the user was ac-
tively using the application or had other contextual infor-
mation to indicate it was running). We didn’t observe any
uses of NFC, READ CALL LOG, ADD VOICEMAIL,
accessing WRITE SYNC SETTINGS or INTERNET
while roaming in our dataset.
location provider
Of the location permission checks, a majority were
due to requests for
information
(e.g., getBestProvider() returns the best location
provider based on application requirements), or check-
ing WiFi state (e.g., getWifiState() only reveals
whether WiFi
is enabled). Only a portion of the
requests actually exposed participants’ locations (e.g.,
getLastKnownLocation() or getScanResults()
exposed SSIDs of nearby WiFi networks).
Although a majority of requests for the READ SMS per-
mission exposed content in the SMS store (e.g., Query()
reads the contents of the SMS store), a considerable por-
tion simply read information about the SMS store (e.g.,
renewMmsConnectivity() resets an applications’ con-
nection to the MMS store). An exception to this is the use
of SEND SMS, which resulted in the transmission of an
SMS message every time the permission was requested.
Regarding browser history, both accessing visited URLs
(getAllVisitedUrls()) and reorganizing bookmark
folders (addFolderToCurrent()) result in the same
permission being checked. However, the latter does not
expose speciﬁc URLs to the invoking application.
Our analysis of the API calls indicated that on average,
only half of all permission checks granted applications
access to sensitive data. For instance, across both visible
and invisible requests, 5,111 of the 11,598 (44.3%) per-
mission checks involving the 12 permissions in Table 1
resulted in the exposure of sensitive data (Table 5).
While limiting runtime permission requests to only the
cases in which protected resources are exposed will
greatly decrease the number of user interruptions, the fre-
quency with which these requests occur is still too great.
Prompting the user on the ﬁrst request is also not appro-
priate (e.g., `a la iOS and Android M), because our data
show that in the vast majority of cases, the user has no
contextual cues to understand when protected resources
are being accessed. Thus, a user may grant a request the
ﬁrst time an application asks, because it is appropriate in
that instance, but then she may be surprised to ﬁnd that
the application continues to access that resource in other
contexts (e.g., when the application is not actively used).
As a result, a more intelligent method is needed to de-
termine when a given permission request is likely to be
deemed appropriate by the user.
5 User Expectations and Reactions
To identify when users might want to be prompted
about permission requests, our exit survey focused on
participants’ reactions to the 12 permissions in Ta-
ble 1, limiting the number of requests shown to each
participant based on our reservoir sampling algorithm,
which was designed to ask participants about a diverse
set of permission/application combinations. We col-
lected participants’ reactions to 673 permission requests
(≈19/participant). Of these, 423 included screenshots
because participants were actively using their phones
when the requests were made, whereas 250 permission
requests were performed while device screens were off.2
Of the former, 243 screenshots were taken while the re-
questing application was visible (Category 1 and 3 from
Section 4.1), whereas 180 were taken while the applica-
tion was invisible (Category 2 and 4 from Section 4.1). In
this section, we describe the situations in which requests
2Our ﬁrst 11 participants did not answer questions about permission
requests occurring while not using their devices, and therefore the data
only corresponds to our last 25 participants.
USENIX Association  
24th USENIX Security Symposium  507
9
deﬁed users’ expectations. We present explanations for
why participants wanted to block certain requests, the
factors inﬂuencing those decisions, and how expectations
changed when devices were not in use.
5.1 Reasons for Blocking
When viewing screenshots of what they were doing
when an application requested a permission, 30 partic-
ipants (80% of 36) stated that they would have preferred
to block at least one request, whereas 6 stated a willing-
ness to allow all requests, regardless of resource type or
application. Across the entire study, participants wanted
to block 35% of these 423 permission requests. When we
asked participants to explain their rationales for these de-
cisions, two main themes emerged: the request did not—
in their minds—pertain to application functionality or it
involved information they were uncomfortable sharing.
5.1.1 Relevance to Application Functionality
When prompted for the reason behind blocking a permis-
sion request, 19 (53% of 36) participants did not believe
it was necessary for the application to perform its task.
Of the 149 (35% of 423) requests that participants would
have preferred to block, 79 (53%) were perceived as be-
ing irrelevant to the functionality of the application:
location.” (P1)
• “It wasn’t doing anything that needed my current
• “I don’t understand why this app would do anything
with SMS.” (P10)
Accordingly, functionality was the most common reason
for wanting a permission request to proceed. Out of the
274 permissible requests, 195 (71% of 274) were per-
ceived as necessary for the core functionality of the ap-
plication, as noted by thirty-one (86% of 36) participants:
• “Because it’s a weather app and it needs to
know where you are to give you weather informa-
tion.”(P13)
• “I think it needs to read the SMS to keep track of the
chat conversation.”(P12)
Beyond being necessary for core functionality, partici-
pants wanted 10% (27 of 274) of requests to proceed be-
cause they offered convenience; 90% of these requests
were for location data, and the majority of those appli-
cations were published under the Weather, Social, and
Travel & Local categories in the Google Play store:
scroll through the whole list.” (P0)
• “It selects the closest stop to me so I don’t have to
• “This app should read my current location. I’d like
for it to, so I won’t have to manually enter in my zip
code / area.” (P4)
Thus, requests were allowed when they were expected:
when participants rated the extent to which each request
was expected on a 5-point Likert scale, allowable re-
quests averaged 3.2, whereas blocked requests averaged
2.3 (lower is less expected).
5.1.2 Privacy Concerns
Participants also wanted to deny permission requests that
involved data that they considered sensitive, regardless
of whether they believed the application actually needed
the data to function. Nineteen (53% of 36) participants
noted privacy as a concern while blocking a request, and
of the 149 requests that participants wanted to block, 49
(32% of 149) requests were blocked for this reason:
• “SMS messages are quite personal.” (P14)
• “It is part of a personal conversation.” (P11)
• “Pictures could be very private and I wouldn’t like
for anybody to have access.” (P16)
Conversely, 24 participants (66% of 36) wanted requests
to proceed simply because they did not believe that the
data involved was particularly sensitive; this reasoning
accounted for 21% of the 274 allowable requests:
cerns.” (P3)
• “I’m ok with my location being recorded, no con-
• “No personal info being shared.” (P29)
5.2
Based on participants’ responses to the 423 permission
requests involving screenshots (i.e., requests occurring
while they were actively using their phones), we quan-
titatively examined how various factors inﬂuenced their
desire to block some of these requests.
Inﬂuential Factors
Effects of Identifying Permissions on Blocking: In the
exit survey, we asked participants to guess the permis-
sion an application was requesting, based on the screen-
shot of what they were doing at the time. The real an-
swer was among four other incorrect answers. Of the
149 cases where participants wanted to block permission
requests, they were only able to correctly state what per-
mission was being requested 24% of the time; whereas
when wanting a request to proceed, they correctly iden-
tiﬁed the requested permission 44% (120 of 274) of the
time. However, Pearson’s product-moment test on the
average number of blocked requests per user and the av-
erage number of correct answers per user3 did not yield a
statistically signiﬁcant correlation (r=−0.171, p<0.317).
Effects of Visibility on Expectations: We were particu-
larly interested in exploring if permission requests orig-
inating from foreground applications (i.e., visible to the
3Both measures were normally distributed.
508  24th USENIX Security Symposium 
USENIX Association
10
user) were more expected than ones from background ap-
plications. Of the 243 visible permission requests that
we asked about in our exit survey, participants correctly
identiﬁed the requested permission 44% of the time, and
their average rating on our expectation scale was 3.4. On
the other hand, participants correctly identiﬁed the re-
sources accessed by background applications only 29%
of the time (52 of 180), and their average rating on our
expectation scale was 3.0. A Wilcoxon Signed-Rank
test with continuity correction revealed a statistically sig-
niﬁcant difference in participants’ expectations between
these two groups (V=441.5, p<0.001).
Effects of Visibility on Blocking: Participants wanted
to block 71 (29% of 243) permission requests originat-
ing from applications running in the foreground, whereas
this increased by almost 50% when the applications were
in the background invisible to them (43% of 180). We
calculated the percentage of denials for each partici-
pant, for both visible and invisible requests. A Wilcoxon
Signed-Rank test with continuity correction revealed a
statistically signiﬁcant difference (V=58, p<0.001).
Effects of Privacy Preferences on Blocking: Partici-
pants completed the Privacy Concerns Scale (PCS) [10]
and the Internet Users’ Information Privacy Concerns
(IUIPC) scale [31]. A Spearman’s rank test yielded no
statistically signiﬁcant correlation between their privacy
preferences and their desire to block permission requests
(ρ = 0.156, p<0.364).
Effects of Expectations on Blocking: We examined
whether participants’ expectations surrounding requests
correlated with their desire to block them. For each par-
ticipant, we calculated their average Likert scores for
their expectations and the percentage of requests that
they wanted to block. Pearson’s product-moment test
showed a statistically signiﬁcant correlation (r=−0.39,
p<0.018). The negative correlation shows that partici-
pants were more likely to deny unexpected requests.
5.3 User Inactivity and Resource Access