1. 过滤候选
   1. 搜索是从查询关键字中解析得到查询意图，以及结构化的搜索条件，再用结构化的查询条件从倒排索引中检索出排序候选
   2. 广告也是查询关键字去检索候选广告
   3. 基于内容的就和搜索一样，用标签检索候选，协同过滤则检索出相似物品来
2. 排序候选
   1. 搜索的排序目标是高相关性
   2. 推荐系统的排序要根据业务来决定
   3. 广告系统的排序更多是从经济学角度去看，如何做才符合更长远的利益
3. 个性化输出
   1. 最被推荐系统所看重
   2. 搜索的个性化需求相对来说松弛一些，常见的是利用地域等人口统计学体现个性化
## 模块
### 数据采集
用途：
1. 报表
2. 数据分析
3. 机器学习
#### 数据模型
矩阵|行|列|数据类型
-|-|-|-
人、属性矩阵|用户ID|属性|用户属性数据
物、属性矩阵|物品ID|属性|物品属性数据
人、人矩阵|用户ID|用户ID|关系数据
人、物矩阵|用户ID|物品ID|用户发生的所有行为和动作
#### 数据来源
- [埋点](/运维/埋点设计.md)
#### 事件元素
1. 用户ID
2. 物品ID
3. 事件名称
4. 发生时间
#### 架构
数据 -> 采集器 -> 消息队列 -> 实时计算框架 -> 分布式存储
#### 数据质量
- 完整性
- 一致性
- 正确性
- 及时性
### 实时推荐
- 服务的实时响应
- 特征的实时更新
- 模型的实时更新
![20221213151113](/assets/20221213151113.webp)
效率提升的方法：
1. 剪枝：不需要对每种可能进行计算
2. 加窗：时间窗口内的历史行为数据参与实时计算，窗口外的不再参与实时计算
3. 采样：短时间产生大量的数据，只采样部分数据进行实时计算
4. 合并：合并若干事件数据之后，再送入下游去更新相似度和推荐结果
5. 缓存：活跃用户的历史行为、热门物品的特征、热门物品的相似物品
### AB测试
- 流量
- 参数
- 结果
考虑的问题：
1. 起止时间
2. 流量大小
3. 流量分配方式，每一个流量在为其选择参数分支时，希望是不带任何偏见的
4. 流量分配条件，一些实验需要针对某个流量的子集
5. 流量如何无偏置，同时做多个实验，那么如何避免前面的实验给后面的实验带来影响
#### 重叠实验架构
一个流量从进入产品服务，到最后返回结果呈现给用户，中间设置了好几个检查站，每个检查站都在测试某些东西
![20221213153826](/assets/20221213153826.webp)
上一层实验带来的影响被均匀地分散在了这一层的每一个桶中，也就是可以认为上一层实验对这一层没有影响，但是需要注意的是对流量分配，要保证每个桶能被分配的流量都要是一致的
#### 统计效果
$$N >= 10.5{(\frac{标准差}{检测敏感度})}^2$$
#### 弊端
- 实验期间，可能要冒着一定的风险得到不好的用户体验
- 要得得到较高统计功效的话，就需要较长时间的测试
## 技术选型
- 特征：会是最多的，更新并不频繁
- 模型：它们大都是键值对，更新比较频繁
- 结果：任何一个数据都可以直接做推荐结果，如协同过滤结果
特征数据又常常要以两种形态存在：一种是正排，一种是倒排。正排就是以用户 ID 或者物品 ID 作为主键查询，倒排则是以特征作为主键查询
型数据也是一类重要的数据，模型数据又分为机器学习模型和非机器学习模型。机器学习模型可以用PMML 文件作为模型的存储方式
推荐结果，或者叫候选集，这种列表类的数据一般也是采用高效的 KV 存储
ES 拥有一定的扩展性和尚可的性能，也常常被采用来做推荐系统的简单第一版
## 测试
- 不确定性
### 业务规则扫描
- 软：对业务规则违反情况做一个基线规定，在一定范围内就算及格
- 硬：不能逾越的业务红线
### 离线模拟测试
先收集业务数据，也就是根据业务场景特点，构造用户访问推荐接口的参数，产生推荐结果日志
### 在线对比测试
- AB测试
### 用户访谈
评测推荐系统的指标，设计是否合理，是否其高低反映了预先的设定
## 指标
### 系统有多好
1. 评分准确度
2. 排序
3. 分类准确率
4. 覆盖率
5. 失效率
6. 新颖性
7. 更新率
### 还能好多久
1. 个性化
2. 基尼系数
3. 多样性
## 安全性
### 基于用户的协同过滤算法
#### 相似攻击
要让自己扶持的物品在推荐算法决定是否要推荐给一个用户时，得到高分
攻击者会注册一批用户，这部分用户就是攻击者可以操纵的选民，然后让这批用户去做出和被欺骗用户一样的历史评分行为
被欺骗的用户打高分的物品，这批水军也打高分，这样一来就可以在计算用户相似度时，这一批新注册的用户都和那个用户有较高的相似度
这样就伪造了用户相似，这些伪造用户喜欢的物品就有可能推荐给被欺骗用户
#### 热门攻击
想办法让目标物品和热门物品扯上关系，最常用的就是，使用假用户同时给热门物品和目标物品评上高分，基于用户的协同过滤算法，会把消费过多个热门物品的用户计算为假用户的相似用户，从而为这些用户推荐出目标物品
#### 防守
- 平台级：高批量注册用户的成本，拦截机器操作，提高系统数据真实比例
- 数据级：别出哪些数据是假的
- 算法级：基于物品的协调过滤更不容易被攻击
## 推荐系统设计
![](/assets/2023918192746.webp)
### 线上服务
```mermaid
stateDiagram-v2
   候选物品 --> 召回层: 百万量级
   召回层 --> 排序层: 几百量级
   排序层 --> 用户: 几十量级
   note right of 召回层
      数据量大、速度快、
      模型简单、特征较少
   end note
   note left of 排序层
      数据量小、排序精准
      复杂模型、特征较多
   end note
```
#### 召回层
单策略召回：制定一条规则或者利用一个简单模型来快速地召回可能的相关物品。 这里的规则其实就是用户可能感兴趣的物品的特点，因为简单，所以它的计算速度一定是非常快的，但不一定是用户感兴趣的
多路召回：采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略，但在确定每一路的召回物品数量时，往往需要大量的人工参与和调整，具体的数值需要经过大量线上 AB 测试来决定
基于 Embedding 的召回：通过获取用户的 Embedding。计算所有物品 Embedding 和用户 Embedding 的相似度，再根据相似度排序，返回规定大小的候选集，当物品集过大，这种计算会造成巨大的开销，这就需要一些[近似最近邻检索](/数据技术/检索技术.md#近似最近邻检索)算法来解决
#### 模型服务
生产环境中，模型需要在线上运行，实时地根据用户请求生成模型的预估值。这个把模型部署在线上环境，并实时进行模型推断（Inference）的过程就是模型服务
预存推荐结果或 Embedding 结果：在离线环境下生成对每个用户的推荐结果，然后将结果预存到以 Redis 为代表的线上数据库中
预训练 Embedding+ 轻量级线上模型：用复杂深度学习网络离线训练生成 Embedding，存入内存数据库，再在线上实现逻辑回归或浅层神经网络等轻量级模型来拟合优化目标
利用 PMML 转换和部署模型：一种标准的XML格式，用于表示和交换预测模型。利用PMML可以将训练好的机器学习模型导出为一个标准格式，然后在不同的平台和环境中加载和运行模型
TensorFlow Serving：PMML 语言的表示能力比较有限，TensorFlow Serving 可以在 TensorFlow 在离线把模型序列化，存储到文件系统后，再把模型文件载入到模型服务器，还原模型推断过程，对外以 HTTP 接口或 gRPC 接口的方式提供模型服务