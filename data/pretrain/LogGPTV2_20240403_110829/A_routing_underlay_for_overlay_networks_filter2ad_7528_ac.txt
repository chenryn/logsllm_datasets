30
35
40
Figure 3: Distribution of shortest disjoint paths
Figure 4: Cumulative distribution of disjoint paths found as a
function of the number of probes.
will correct for this later. However, we do make up a little for it
at PG level, by excluding illegal paths using peering relationship
inference [15], which basically says a customer AS does not carry
trafﬁc for its provider AS. For each node w 2 N, we concatenate
the AS sequences from the shortest AS path (u; w) and the short-
est AS path (w; v) into the path (u; w; v). We sort the list of these
composite paths by the AS count.
Second, we discard any intermediate nodes w for which we know
that the path (u; w) is not edge-disjoint from the default AS path
(u; v). We use the GetPath primitive to ensure that the sequence
of ASes on the AS path (u; v) does not share two consecutive ASes
(and hence a peering point) with the AS path (u; w); otherwise we
drop the path from consideration.
Finally, we verify our inference about the path (w; v) by invok-
ing GetPath(w, v). Since node w has access to its local BGP
information, it can return the actual AS path (w; v) in response to
this query. At this point we know all of the AS hops along the
path (u; w; v), and can verify our inference about the AS sequence
along the path, as well as discard all w such that (w; v) and (u; v)
share a peering point.
Note that the algorithm just described selects k paths from the
candidate set based on AS hop count. One could further discrim-
inate among (or order) the candidates based on actual round-trip
latency, that is, using the GetDistance with the RTT metric. This
could be done at a cost of k probes.
4.1.2 Evaluation
We ﬁrst try to get a feel for how many disjoint paths exist be-
tween two ASes using RouteViews [6], which approximates a fully
implemented GetGraph primitive. One observation is that there
is no disjoint path available if either of two end ASes are single-
homed, i.e peer with only a single ingress/egress AS. Therefore, in
our analysis we consider only multi-homed ASes.
The RouteViews router listens to BGP updates from 64 vantage
points and stores them in its own BGP table. This means that the
RouteViews BGP table should contain 64 entries for each network
preﬁx. We use the NextHop ﬁeld of each entry to match up entries
with actual vantage points, and thus extract the local BGP table at
that vantage point. This enables us to construct a clique of AS paths
between 42 vantage points (the remaining 22 had incomplete BGP
tables). For each pair of vantage points u and v, we then construct
indirect paths (u; w; v) through every other vantage point w and
check whether these paths are edge-disjoint with the direct path
(u; v).
Among 1722 (=42 (cid:2) 41) possible direct paths, we discard 374
paths due to inconsistencies, and another 113 because one of the
endpoints is in a single-homed AS. Among the remaining 1235 di-
rect paths, we ﬁnd that 1157 (93.7%) have at least one disjoint path
through an intermediate node.
Next, we evaluate how often our heuristic can ﬁnd a disjoint path
with the same number of AS hops as the direct path. Most of the
direct paths have several such shortest disjoint paths, as shown by
Figure 3. For instance, 17.4% have one shortest disjoint path, 6.0%
have two, and so on. Figure 4 shows the cumulative distribution of
direct paths for which our heuristic ﬁnds at least one of its shortest
disjoint paths within a given number of queries. The plot com-
pares our heuristics and a random scheme where we randomly pick
a node and examine if that gives us a shortest disjoint path. As Fig-
ure 4 shows, we ﬁnd a shortest disjoint path for 90% of the direct
paths for which one exists within 5 probes.
4.2 Finding Nearest Neighbors
Our second library service ﬁnds the nearest overlay nodes in
terms of distance:
Nodes = NearestNodes(N, k)
Relative to the local overlay node and a given set of candidate
neighbor nodes N, this library returns k nodes in N that are closest
to the local node, while minimizing the number of probes.
4.2.1 Implementation
The implementation of this service is relatively simple. As in the
disjoint path service, we use information from the peering graph to
narrow down the set of potential candidates before actively prob-
ing the network. First, we use GetPath to sort the list of candidate
nodes by increasing number of hops from the source; this has no
cost. It has been observed that latency and AS hop count are cor-
related [20], although with high variance, so we expect that nodes
near the top of the list should enjoy better latency from the source.
Next, we reﬁne the result by invoking GetDistance on the top j
nodes in the list, where j (cid:21) k, and we choose the k with the lowest
latency. The key is choosing the right value of j to send out as few
probes as possible but still get a good result for k.
4.2.2 Evaluation
We evaluate the heuristic using 81 nodes (34 PlanetLab [22]
nodes and 47 randomly selected public traceroute servers [17]).
We also suggest a method for choosing the value j, the number
of nodes to probe to ﬁnd the best k.
n
o
i
t
u
b
i
r
t
s
i
D
e
v
i
t
a
l
u
m
u
C
100
90
80
70
60
50
40
30
20
10
0
Using AS Path Length
Random
0
10
20
30
40
50
60
70
80
)
c
e
s
m
(
r
o
r
r
E
e
g
a
r
e
v
A
60
50
40
30
20
10
0
0
k=1
k=2
k=5
k=10
10
20
30
40
50
60
70
80
Number of Candidate Nodes
Number of Candidates
(a) Number of probes required to ﬁnd smallest latency
neighbor (k=1)
(b) Absolute average error (msec) after a given number
of probes
Figure 5: Evaluation of heuristic to ﬁnd the k smallest-latency neighbors
First, we compare our heuristic against random guessing when
trying to ﬁnd the neighbor with the smallest latency. Figure 5(a)
shows the number of candidates j that were probed before ﬁnd-
ing the one that had the absolute lowest latency (i.e., k = 1), for
both our heuristic and a random solution. Not surprisingly, we see
that our method performs signiﬁcantly better than random guess-
ing. For example, about 50% of the nodes were able to ﬁnd their
optimal neighbor within 10 probes using our method, while ran-
dom guessing requires 40 probes on average to achieve the same
result. 1
Second, we evaluate the quality of the result returned by the
heuristic after probing j candidates and returning the top k. Fig-
ure 5(b) presents the results for k = 1; 2; 5 and 10. We note that
even when our heuristic does not return the k best nodes, usually
it can ﬁnd k neighbors that have close to optimal latency with a
small number of probes. For instance, to ﬁnd k neighbors within
10 msec of the optimal latency required 7 probes on average for
k = 1, 11 probes for k = 2, 18 probes for k = 5, and 27 probes
for k = 10. Based on these observations, it appears possible to im-
plement a table within our service that could translate the number
of desired neighbors k and the error tolerance e to the number of
probes j that the service needs to perform. More investigation is
required to conﬁrm this intuition.
4.3 Building a Representative Mesh
Our third example routing service constructs a mesh that is phys-
ically representative of the underlying Internet, but with far fewer
edges than the fully connected Internet allows. Speciﬁcally,
Mesh = BuildMesh(N)
Given a set of overlay nodes N, the BuildMesh call returns the
local node’s neighbor set in a mesh. Our mesh-building strategy is
to identify and remove topologically redundant edges (virtual links)
between overlay nodes, or said another way, retain only those edges
that we can determine to be independent in the underlying physical
network. Each overlay node performs this analysis independently
using the GetPath primitive. The entire mesh could be formed
1The CDF curves reach 100% at less than 80 nodes because we had to exclude some
paths due to invalid traceroute results.
AS W
ww
AS W
ww
AS X
AS Y
AS X
AS Y
AS U
uu
AS U
AS V
vv
uu
AS V
vv
(a) Topology A
(b) Topology B
Figure 6: Black dots u, v, and w denote overlay nodes and the
white dots denote routers. Virtual link (u; v) is redundant and
can be removed from the mesh, since edges (u; w) and (w; v)
connect u to v.
by aggregating the neighbor sets; however, many routing overlays,
such as RON and ESM, maintain only immediate neighbor sets at
each node.
Our approach is limited to edges that can be removed without
building a global picture of the network. An alternative strategy
would be for a central authority to collect global network informa-
tion, build the entire mesh, and distribute it throughout the overlay.
We opt for a localized approach for reasons of scalability and cost,
though the resulting mesh may not be as sparse as that produced by
a centralized algorithm. One could imagine building a more sparse
mesh on top of the one we build, for example by lowering the de-
gree of each node by discriminating among the edges according to
latency or throughput. Doing so would require a distributed algo-
rithm to ensure that the resulting mesh does not become partitioned.
4.3.1 Implementation
Our algorithm prunes an edge from the local node u to remote
node v if the AS path from u to v includes AS W , such that there is
a node w 2 N that is located within AS W . This scenario is illus-
trated in Figure 6(a). We call the pruned edge (u; v) a virtualized
edge. The simplest version of our algorithm prunes an edge (u; v),
only when we ﬁnd an intermediate node w such that both (u; w)
and (w; v) are not virtualized before pruning. Note that these edges
may become virtualized later by pruning other edges during the
s
e
g
d
e
f
o
r
e
b
m
u
n
e
h
t
n
i
)
%
(