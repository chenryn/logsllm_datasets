title:RacketStore: measurements of ASO deception in Google play via mobile
and app usage
author:Nestor Hernandez and
Ruben Recabarren and
Bogdan Carbunar and
Syed Ishtiaque Ahmed
RacketStore: Measurements of ASO Deception in Google Play
via Mobile and App Usage
Nestor Hernandez
FIU, Miami, USA
PI:EMAIL
Bogdan Carbunar
FIU, Miami, USA
PI:EMAIL
Ruben Recabarren
FIU, Miami, USA
PI:EMAIL
Syed Ishtiaque Ahmed
University of Toronto, Toronto, CA
PI:EMAIL
ABSTRACT
Online app search optimization (ASO) platforms that provide bulk
installs and fake reviews for paying app developers in order to fraud-
ulently boost their search rank in app stores, were shown to employ
diverse and complex strategies that successfully evade state-of-the-
art detection methods. In this paper we introduce RacketStore,
a platform to collect data from Android devices of participating
ASO providers and regular users, on their interactions with apps
which they install from the Google Play Store. We present measure-
ments from a study of 943 installs of RacketStore on 803 unique
devices controlled by ASO providers and regular users, that con-
sists of 58,362,249 data snapshots collected from these devices, the
12,341 apps installed on them and their 110,511,637 Google Play
reviews. We reveal significant differences between ASO providers
and regular users in terms of the number and types of user accounts
registered on their devices, the number of apps they review, and
the intervals between the installation times of apps and their re-
view times. We leverage these insights to introduce features that
model the usage of apps and devices, and show that they can train
supervised learning algorithms to detect paid app installs and fake
reviews with an F1-measure of 99.72% (AUC above 0.99), and de-
tect devices controlled by ASO providers with an F1-measure of
95.29% (AUC = 0.95). We discuss the costs associated with evading
detection by our classifiers and also the potential for app stores to
use our approach to detect ASO work with privacy.
CCS CONCEPTS
• Security and privacy → Social network security and pri-
vacy; Social aspects of security and privacy;
KEYWORDS
App Store Optimization; Crowdturfing; Fake Review; Opinion Spam
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’21, November 2–4, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9129-0/21/11...$15.00
https://doi.org/10.1145/3487552.3487837
639
1 INTRODUCTION
The global mobile application market is worth hundreds of billions
of USD and is expected to grow by more than 10% per year un-
til 2027 [22]. To stand out among millions of apps hosted in app
stores [8, 24] and get a share of this market, many app developers
resort to app search optimization (ASO) to increase the rank of their
apps during search. ASO platforms use a variety of techniques to
achieve this [83], including providing retention installs [12] and
posting fake reviews [3, 7]. Such activities can be illegal in coun-
tries like the US [1], Canada [14], Australia [77], are banned in
the EU [16], violate the terms of service of app stores [2, 11], and
influence users to install and purchase low quality apps and even
malware [46, 68, 80].
Identifying ASO-promoted apps and the accounts from which
they are promoted allows app stores to filter fake reviews and
ratings, generate more accurate install count and aggregate rating
values thus compute more accurate search ranks for apps, and
enable users to make better informed app-installation decisions.
A key to achieve this is to build an accurate understanding of
the behaviors and strategies employed by fraudulent app search
optimization (ASO) workers. In previous work, Farooqi et al. [38]
have shown that incentivized app install platforms (IIP) are able
to provide thousands of installs that successfully evade Google
defenses. Rahman et al. [67] have reported a variety of detection-
avoidance techniques employed by organizations that specialize
in retention installs and fake reviews. Such techniques include
crowdsourcing ASO work to organic workers, who use their personal
devices to conceal ASO work among everyday activities.
Identifying organic ASO activities is an open problem due to the
ability of such workers to evade existing detection solutions, e.g.,
that leverage lockstep behaviors [32, 43, 51, 72, 73, 78, 85, 86, 89,
92, 93] or review bursts [27, 28, 35, 39, 40, 42, 44, 45, 50–53, 53, 57–
59, 65, 66, 84, 87, 88, 92].
In an effort to determine whether solutions can be developed
to detect these ASO strategies, in this paper we seek to measure
and compare the device and app usage of ASO workers and regular
users. Our work is partially motivated by Farooqi et al. [38]’s finding
that ASO workers lack interest in the apps that they promote. We
conjecture this also results in, e.g., workers posting reviews for
promoted apps soon after installing them, see Figure 1.
To enable such measurements, we develop RacketStore, a plat-
form to collect and analyze app and device-use data from consenting
ASO workers and regular users. The RacketStore mobile app peri-
odically collects data from the devices where it is installed, e.g., the
To validate this, we leverage our findings and the RacketStore-
collected data to develop features that model the interaction of
a user with a device and the engagement of the user with the
apps installed on the device. We found that supervised learning
algorithms trained with these features distinguish between apps
installed for promotion purposes and those installed for personal
use, thus detect incentivized installs and fake reviews, with an F1-
measure of 99.72% and AUC over 0.99. Further, our classifiers detect
worker-controlled devices with an F1-measure of 95.29% and AUC
of 0.95.
We found that 69.1% of the worker devices that we analyzed
have organic-indicative behaviors, while the remaining devices
were seemingly used exclusively for app promotion activities. This
suggests that our device and app-engagement features can train
classifiers to accurately detect not only promotion-dedicated de-
vices but even elusive organic ASO efforts that hide low levels of
app promotion activities among regular, personal use of devices
and of the apps installed therein.
We note that to protect user privacy, the proposed classifiers can
execute directly on the user device (e.g., implemented into the Play
Store app). Locally-running classifiers can access sensitive app and
device usage data and do not need to report it remotely (§ 9).
In summary, we introduce the following contributions:
• RacketStore. We develop a platform to collect information
about the interaction of users with their Android devices
and the apps installed therein, with user consent. Racket-
Store was compatible with 298 device models from 28 An-
droid manufacturers [§ 3]. The RacketStore code is available
at [10].
• App and Device Use Measurements. We present measure-
ments from a study of the device and app use of regular users
and ground truth ASO workers, through a deployment of
RacketStore on 803 unique devices [§ 4]. We build datasets
of app and device usage, integrated with Google Play reviews
and VirusTotal analysis. We present findings from this data
in the context of feedback obtained from participants during
a follow-up discussion [§ 6].
• Fraud Detector and Classifier. We introduce novel fea-
tures that model the user interaction with devices and in-
stalled apps and use them to train classifiers to detect ASO
activities [§ 7] and worker-controlled devices [§ 8]. We re-
port differences in app and device-engagement for workers
and regular users that explain the accuracy of the classifiers.
2 SYSTEM MODEL
We consider the ecosystem depicted in Figure 2. In the following
we describe its main components.
The App Store and Consumers. We focus our work on the Google
Play app store [6]. Consumers use the pre-installed Play Store app to
search and install other apps on their Android devices. A consumer
can register multiple accounts on an Android device, including
Gmail and other services. The consumer is then able to post re-
views for an app, from all the Gmail accounts registered on the
device where the app was installed.
App Developers. Developers upload their apps on the Play Store [6].
To monetize these apps while facing intense competition, they need
640
Figure 1: On-device app interaction timelines for two ASO
workers (top) and one regular user (bottom). Worker time-
lines start with the app installation event (type 4 on y axis),
followed by several review posting events across several
days (type 3), with no interaction with the app. In contrast,
the regular user timeline shows frequent interaction with
the app, e.g., placing the app in the foreground (type 2 event),
but no review even after 5 days of monitoring.
foreground app and the list of installed apps with 5s granularity,
and the types and number of registered accounts, with 2 min granu-
larity. The RacketStore server aggregates this information with data
collected from the Play Store and VirusTotal [15]. RacketStore first
discloses the types of data it collects. RacketStore collects the data
only after receiving participant consent (§ 4.1 and Appendix D).
We present measurements from a study of ASO workers and
regular users recruited to keep the RacketStore app installed on
their devices for at least two days. In total, RacketStore was installed
943 times on 803 unique devices: 580 devices controlled by ASO
workers recruited from Facebook groups that specialize in ASO
work, and 223 devices of regular Android users recruited through
ads purchased in Instagram. We have collected 58,362,249 snapshots
from the participating devices, including their 12,341 apps installed
and in-use, and their 110,511,637 reviews from the Play Store.
We found that ASO work continues to be successful and evade
app store detection: The worker-controlled devices of participants
in our studies had 10,310 Gmail accounts registered on them and at
the time of writing, Google Play was still displaying 217,041 reviews
posted from them.
Measurements reveal that many participant ASO worker devices
have organic-indicative behaviors, i.e., similar to those of regu-
lar devices, in terms of their app churn (daily installed and unin-
stalled apps), permissions granted, the total number of installed
apps, stopped apps, or daily used apps. However, we found sig-
nificant differences between regular user and worker-controlled
devices in terms of their number and types of registered accounts,
the number of apps reviewed, and the intervals between the in-
stallation times of apps and their review times. This suggests that
the constraints associated with ASO work provide opportunities to
detect even organic workers.
consists of a mobile app to be installed by study participants on
their Android devices, a web app to collect and validate data from
the installed app, and database servers to store the data, see Figure 3.
In the following we describe the main components of RacketStore.
RacketStore Mobile App. We have developed the RacketStore
app in Android to help us investigate fraudulent and honest behav-
iors of Google services users. The app needs to be installed by study
participants on their devices. Upon first start-up, the app displays
the consent form (see Appendix C for excerpts) which the partici-
pant needs to approve. Then, to comply with the Google anti-abuse
policy [23], the app asks for explicit consent of our privacy policy
(Figure 18(a) in Appendix C) then shows an in-app disclosure of
the data being collected (Figure 18(b)). In the following we detail
the main components of the rest of the app.
The sign-in interface asks the participant to enter a unique
participant ID, a 6-digit code, that we send upon recruitment (§ 4)
through a different channel, i.e., e-mail or Facebook messenger.
This code serves the dual goal of preventing RacketStore use by
non-recruited users, and of allowing us to match data and send
payments to the correct participants. The passcode is given only
after the user has accepted to participate in our study and has
agreed to the data collection process. RacketStore does not collect
any information if the user has not entered the 6-digit passcode.
Upon sign-in, the app generates the install ID, a 10-digit random
identifier.
The initial data collector module operates once the app has
been installed and the user has used the sign-in interface to enter
the participant ID. It retrieves the list of other apps installed on
the device, and device information including Android API version,
device model, manufacturer, and Android ID [21].
Following the installation of the RacketStore app, the snapshot
collector module periodically collects information with two lev-
els of granularity, slow and fast. The slow snapshot collector is
triggered by an alarm every 2 minutes, and collects (1) identifiers:
Install ID, participant ID, and Android ID, (2) registered accounts,
the accounts registered on the device across different services, (3)
device status, i.e., save mode status (on/off), and (4) stopped apps,
the list of stopped apps. Starting with Android 3.1 all applications
upon installation are placed in a stopped state: the application will
only run after a manual launch of an activity, or an explicit intent
that addresses an activity, service or broadcast. The user can also
manually force stop an app.
The fast snapshot collector module further activates every 5s
and collects (1) identifiers, i.e., install ID and participant ID, (2) the
foreground app currently running on the device foreground, (3)
the device status, i.e., the screen status (on/off) and battery level,
and (4) app install/uninstall events, i.e., deltas between the current
and previously reported sets of installed apps. For each installed
app we collect the install time, the last update time, the required
permissions and the MD5 hash of the app apk file.
RacketStore requires participants to explicitly grant two per-
missions, PACKAGE_USAGE_STATS and GET_ACCOUNTS [9]. Partici-
pants can accept any subset of the requested permissions. If they
do not grant a permission, we do not collect the corresponding
data. RacketStore also uses install-time permissions (GET_TASKS,
RECEIVE_BOOT_COMPLETED, INTERNET, ACCESS_NETWORK_STATE, and
Figure 2: System model. Developers recruit ASO platforms
to promote their apps in app stores. ASO platforms leverage
in-house, dedicated workers, and organic workers accessed
through communication boards to install and review apps.
to achieve top-5 rank in keyword searches [25]. Some of the factors
with most impact on search rank are the number of installs and
reviews, and the aggregate rating of the app: 80% of consumers
check reviews and ratings before installing an app [34], and a 1-
star increase in aggregate rating was shown to increase app store
conversion by up to 280% [83].
ASO Organizations. Many developers hire specialized app search
optimization (ASO) organizations to improve the search rank of
their apps. While some ASO organizations are white hat [25], pro-