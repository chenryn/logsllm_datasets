their own list lock to support concurrent updates. Every node of each list rep-
resenting a page is composed of a node lock, a page ID, a status ﬂag and a
node pointer pointing to its next node. The node lock is required to avoid race
conditions and thus other nodes can be processed in parallel.
Page ID. The page ID is used to identify a page especially during the database
updates. As kernel-level randomization is enabled within the kernel, we use the
multi-hash-value approach for the identiﬁcation. Speciﬁcally, we trace the kernel
for 10 rounds to make sure that all the used pages are collected. Pages in diﬀerent
rounds are considered to be identical (i.e., a same page) if they satisfy two
properties: (1) more than 3366 out of 4096 bytes (i.e., over 82%) are constant and
the same among these pages; (2) the maximum byte-length of the consecutive
diﬀerent bytes (i.e., dynamic bytes) among these pages is no greater than 4. And
then we perform a per-byte comparison of the identical pages so as to build a
map of what bytes are constant and what bytes are dynamic with the pages. By
doing so, each used page has multiple ranges of consecutive constant bytes and
dynamic bytes are between these ranges. As a result, all the constant bytes of
every range are hashed as a value and all the hash values make up the page ID.
702
Z. Zhang et al.
Status Flag. The status ﬂag indicates the phase status (i.e., startup, runtime
and shutdown) of a used page. The ﬂag is initialized as startup when the kernel
boots up. Once the kernel switches from the startup phase to the runtime phase,
or from the runtime phase to the shutdown phase, appropriate exceptions are
triggered so that the oﬄine training processor can update the ﬂag accordingly.
In our implementation, all code pages of the guest OS are deprived of executable
permissions. Once the OS starts to boot, it will raise numerous EPT exceptions.
In the hypervisor space, there is a handler (i.e., ept handle violation) responding
to the exception, and thus the oﬄine training processor can mark the beginning
of the runtime phase by intercepting the ﬁrst execution of the user-space code
as well as its end by intercepting the execution of the reboot system call.
5.2 Database Operations
The database operations are mainly composed of three parts, i.e., populating,
saving and loading.
Populate Database. To populate the database, the KASR oﬄine training pro-
cessor must trace all the used pages and thus dictates that only the page raising
the exception would become executable while others are non-executable. How-
ever, we ﬁnd that this will halt the kernel. The reason is that the x86 instructions
have variable lengths and an instruction may cross a page boundary, which means
that the ﬁrst part of the instruction is at the end of a page, while the rest is in
the beginning of the next page. Under such situations, the instruction-fetch will
result in inﬁnite loops (i.e., trap-and-resume loops).
To address this issue, we relax the dictation and implement a queue of 2
pages that own executable permissions. When the queue is full of two pages that
have caused the ﬁrst two exceptions (i.e., the ﬁrst two used pages), it will then
be updated by First-in, First-out, i.e., the newest used page will be pushed in
while the oldest used page will be popped out. Besides solving the cross-page-
boundary problem, we also accelerate the tracing performance. Besides, we can
capture all loaded modules, as all of them have no less than 2 code pages.
To the end, it is not enough to obtain all the used pages by running the oﬄine
training stage just once. Thus, it is necessary to repeat this stage for multiple
rounds until the database size becomes stable. In our experiments, 10 rounds
are enough to get a stable database (see Sect. 6).
Save and Load Database. The database is generated in the hypervisor space,
and stored in the hard disk for reuse. Speciﬁcally, we have developed a tiny tool
in the privileged domain to explicitly save the database into the domain’s disk
after the oﬄine training stage, and load the existing database into the hypervisor
space during the runtime enforcement stage.
6 Evaluation
We have implemented a KASR prototype on our private cloud platform, which
has a Dell Precision T5500 PC with eight CPU cores (i.e., Intel Core Xeon-
E5620) running at 2.40 GHz. Besides, Intel VT-x feature is enabled and supports
A Reliable and Practical Approach to Kernel Attack Surface Reduction
703
the page size of 4 KB. Xen version 4.8.2 is the hypervisor while Hardware-assisted
Virtual Machine (HVM) is the Ubuntu Server 16.04.3 LTS, which has a KASLR-
enabled Linux kernel of version 4.4.0-87-generic with four virtual CPU cores and
4 GB physical memory. KASR only adds around 1.2K SLoC in Xen.
In the rest of this section, we measure the reduction rates of the kernel attack
surface. On top of that, we characterize the reduced kernel attack surface in the
metrics of Common Vulnerabilities and Exposures (CVEs). The use cases we
choose are SPECint, httperf, bonnie++, LAMP (i.e., Linux, Apache, MySQL and
PHP) and NFS (i.e., Network File System). Furthermore, we test and analyze its
eﬀectiveness in defending against 6 real-world kernel rootkits. Also, we measure
the performance overhead introduced by KASR through the selected use cases
above. The experimental results demonstrate that we can eﬀectively reduce ker-
nel attack surface by 64%, CVEs by 40%, safeguard the kernel against 6 popular
kernel rootkits and impose negligible (less than 1%) performance overhead on
all use cases.
6.1 Kernel Attack Surface Reduction
In the runtime enforcement stage, we measure the kernel attack surface reduction
through three representative benchmark tools, namely, SPECint, httperf and
bonnie++ and two real-world use cases (i.e., LAMP and NFS).
SPECint [29] is an industry standard benchmark intended for measuring the
performance of the CPU and memory. In our experiment, the tool has 12 sub-
benchmarks in total and they are all invoked with a speciﬁed conﬁguration ﬁle
(i.e., linux64-ia32-gcc43+.cfg).
On top of that, we measure the network I/O of HVM using httperf [23].
HVM runs an Apache Web server and Dom0 tests its I/O performance at a rate
of starting from 5 to 60 requests per second (100 connections in total).
Also, we test the disk I/O of the guest by running bonnie++ [5] with its
default parameters. For instance, bonnie++ by default creates a ﬁle in a speciﬁed
directory, size of which is twice the size of memory.
Besides, we run the LAMP-based web server inside the HVM. Firstly, we use the
standard benchmark ApacheBench to continuously access a static PHP-based
website for ﬁve minutes. And then a Web server scanner Nikto [30] starts to
run so as to test the Web server for insecure ﬁles and outdated server software
and also perform generic and server type speciﬁc checks. This is followed by
launching Skipﬁsh [22], an active web application security reconnaissance tool.
It operates in an extensive brute-force mode to carry out comprehensive security
checks. Running these tools in the LAMP server aims to cover as many kernel
code paths as possible.
Lastly, the other comprehensive application is NFS. HVM is conﬁgured to
export a shared directory via NFS. In order to stress the NFS service, we also use
bonnie++ to issue read and write-access to the directory.
All results are displayed in Table 1. Note that the average results for SPECint
are computed based on 12 sub-benchmark tools. We determine two interesting
properties of the kernel attack surface from this table. First, the attack surface
704
Z. Zhang et al.
Table 1. In every case, the kernel code pages are signiﬁcantly tailored after each step.
Generally, KASR can reduce the kernel attack surface by 54% after the permission
deprivation, and 64% after the lifetime segmentation. (Orig.Kern = Original Kernel,
Aft.Per.Dep. = After Permission Deprivation, Aft.Lif.Seg. = After Lifetime Segmenta-
tion)
Cases
Orig.Kern Aft.Per.Dep.
Page(#)
Page(#) Reduction(%) Page(#) Reduction(%)
Aft.Lif.Seg.
SPECint
httperf
2227
2236
bonnie++ 2235
LAMP
NFS
2238
2395
1034
1026
1034
1043
1096
54%
54%
54%
53%
54%
808
763
761
817
939
64%
66%
66%
63%
61%
reduction after each step is quite signiﬁcant and stable for diﬀerent use cases.
Generally, the attack surface is reduced by roughly 54% and 64% after the per-
mission deprivation and lifetime segmentation, respectively, indicating that less
than half of the kernel code is enough to serve all provided use cases. Second,
complicated applications (i.e., LAMP and NFS) occupy more kernel code pages
than the benchmarks, indicating that they have invoked more kernel functions.
CVE Reduction. Although some kernel functions (e.g., architecture-speciﬁc
code) contain past CVE vulnerabilities, they are never loaded into memory dur-
ing the kernel’s lifetime run and do not contribute to the attack surface. As a
result, we only consider the CVE-vulnerable functions that are loaded into the
kernel memory. We investigate CVE bugs of recent two years that provide a link
to the GIT repository commit and identify 14 CVEs that exist in the kernel
memory of all ﬁve use cases.
We observe that KASR has removed 40% of CVEs in the memory. To be spe-
ciﬁc, some CVE-vulnerable kernel functions within the unused kernel code pages
are deprived of executable permissions after the permission deprivation. For
example, the ecryptfs privileged open function in CVE-2016-1583 before Linux
kernel-4.6.3 is unused, thus being eliminated. After the lifetime segmentation,
some other vulnerable functions are also removed (e.g., icmp6 send in CVE-
2016-9919).
6.2 Rootkit Prevention
Even though the kernel attack surface is largely reduced by KASR, still there
may exist vulnerabilities in the kernel, which could be exploited by rootkits. We
demonstrate the eﬀectiveness of KASR in defending against real-world kernel
rootkits. Speciﬁcally, we have selected 6 popular real-world kernel rootkits com-
ing from a previous work [25] and the Internet. These rootkits work on typical
Linux kernel versions ranging from 3.x to 4.x, representing the state-of-the-art
A Reliable and Practical Approach to Kernel Attack Surface Reduction
705
kernel rootkit techniques. All these rootkits launch attacks by inserting a load-
able module and they can be divided into three steps:
1. inject malicious code into kernel allocated memory;
2. hook the code on target kernel functions (e.g., original syscalls);
3. transfer kernel execution ﬂow to the code.
KASR is able to prevent the third step from being executed. Speciﬁcally, rootkits
could succeed at Step-1 and Step-2, since they can utilize exposed vulnerabilities
to modify critical kernel data structures, inject their code and perform target-
function hooking so as to redirect the execution ﬂow. However, they cannot
execute the code in Step-3, because KASR decides whether a kernel page has an
executable permission. Recall that KASR reliably dictates that unused kernel
code (i.e., no record in the database) has no right to execute in the kernel space,
including the run-time code injected by rootkits. Therefore, when the injected
code starts to run in Step-3, EPT violations deﬁnitely will occur and then be
caught by KASR. The experimental results from Table 2 clearly show that KASR
has eﬀectively defended against all 6 rootkits. As a result, KASR is able to defend
against the kernel rootkits to a great extent.
Table 2. KASR successfully defended against all 6 kernel rootkits. (LKM = Loadable
Kernel Module)
OS kernel
Rootkit
Linux 3.x-4.x adore-ng
Attack vector Attack failed?
LKM
LKM
xingyiquan
rkduck
LKM
Diamorphine LKM
LKM
suterusu
nurupo
LKM
√
√
√
√
√
√
6.3 Performance Evaluation
In this section, we evaluate the performance impacts of KASR on CPU computa-