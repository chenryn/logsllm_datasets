and Communications Security, CCS, 2011.
[25] Robin David, Sébastien Bardin, Josselin Feist, Laurent Mounier, Marie-Laure
Potet, Thanh Dinh Ta, and Jean-Yves Marion. Specification of concretization and
symbolization policies in symbolic execution. In International Symposium on
Software Testing and Analysis, ISSTA 2016, 2016.
[26] Robin David, Sébastien Bardin, Thanh Dinh Ta, Laurent Mounier, Josselin Feist,
Marie-Laure Potet, and Jean-Yves Marion. BINSEC/SE: A dynamic symbolic
execution toolkit for binary-level analysis. In IEEE 23rd International Conference
on Software Analysis, Evolution, and Reengineering, SANER, 2016.
[27] Leonardo Mendonça de Moura and Nikolaj Bjørner. Z3: an efficient SMT solver.
In Tools and Algorithms for the Construction and Analysis of Systems, TACAS, 2008.
[28] Saumya K. Debray and Jay Patel. Reverse engineering self-modifying code:
Unpacker extraction. In Working Conference on Reverse Engineering, WCRE, 2010.
[29] Ninon Eyrolles, Louis Goubin, and Marion Videau. Defeating mba-based ob-
In Proceedings of the 2016 ACM Workshop on Software PROtection,
fuscation.
SPRO@CCS 2016, 2016.
[30] Patrice Godefroid, Michael Y. Levin, and David A. Molnar. SAGE: whitebox
fuzzing for security testing. Commun. ACM, 55(3), 2012.
[31] Thomas A. Henzinger, Ranjit Jhala, Rupak Majumdar, and Grégoire Sutre. Lazy ab-
straction. In The 29th SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), 2002.
[32] Min Gyung Kang, Pongsin Poosankam, and Heng Yin. Renovo: a hidden code
extractor for packed executables. In ACM Workshop Recurring Malcode (WORM).
ACM, 2007.
[33] Johannes Kinder. Towards static analysis of virtualization-obfuscated binaries.
In 19th Working Conference on Reverse Engineering, WCRE, 2012.
[34] Dave King, Boniface Hicks, Michael Hicks, and Trent Jaeger.
Implicit flows:
Can’t live with ’em, can’t live without ’em. In Information Systems Security, 4th
International Conference, ICISS, 2008.
[35] Yin Liu and Ana Milanova. Static information flow analysis with handling of
implicit flows and a study on effects of implicit flows vs explicit flows. In 14th
European Conference on Software Maintenance and Reengineering, CSMR, 2010.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Mathilde Ollivier, Sébastien Bardin, Richard Bonichon, and Jean-Yves Marion
[36] Saeed Nejati, Jia Hui Liang, Catherine H. Gebotys, Krzysztof Czarnecki, and Vijay
Ganesh. Adaptive restart and cegar-based solver for inverting cryptographic
hash functions. In VSTTE, 2017.
[37] Jonathan Salwan, Sébastien Bardin, and Marie-Laure Potet. Symbolic deobfusca-
tion: from virtualized code back to the original. In 5th Conference on Detection of
Intrusions and malware & Vulnerability Assessment (DIMVA), 2018.
[38] Florent Saudel and Jonathan Salwan. Triton : Framework d’exÃľcution concolique.
In SSTIC, 2015.
[39] Sebastian Schrittwieser, Stefan Katzenbeisser, Johannes Kinder, Georg Merz-
dovnik, and Edgar Weippl. Protecting software through obfuscation: Can it keep
pace with progress in code analysis? ACM Comput. Surv., 49(1), 2016.
[40] Edward J. Schwartz, Thanassis Avgerinos, and David Brumley. All you ever
wanted to know about dynamic taint analysis and forward symbolic execution
(but might have been afraid to ask). In Symposium on Security and Privacy, S&P,
2010.
[41] Hovav Shacham. The geometry of innocent flesh on the bone: return-into-libc
without function calls (on the x86). In Conference on Computer and Communica-
tions Security, CCS, 2007.
[42] Monirul I. Sharif, Andrea Lanzi, Jonathon T. Giffin, and Wenke Lee. Impeding
malware analysis using conditional code obfuscation. In Network and Distributed
System Security Symposium, NDSS, 2008.
[43] Yan Shoshitaishvili, Ruoyu Wang, Christopher Salls, Nick Stephens, Mario Polino,
Andrew Dutcher, John Grosen, Siji Feng, Christophe Hauser, Christopher Krügel,
and Giovanni Vigna. SOK: (state of) the art of war: Offensive techniques in
binary analysis. In IEEE Symposium on Security and Privacy, SP, 2016.
[44] Venkatesh Srinivasan and Thomas W. Reps. An improved algorithm for slicing
machine code. In Proceedings of the 2016 ACM SIGPLAN International Conference
on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA
2016. ACM.
[45] Jon Stephens, Babak Yadegari, Christian S. Collberg, Saumya Debray, and Carlos
Scheidegger. Probabilistic obfuscation through covert channels. In European
Symposium on Security and Privacy, EuroS&P, 2018.
[46] Julien Vanegue and Sean Heelan. SMT solvers in software security. In 6th USENIX
Workshop on Offensive Technologies, WOOT’12, 2012.
[47] Chenxi Wang, Jonathan Hill, John Knight, and Jack Davidson. Software tamper
resistance: Obstructing static analysis of programs. Technical report, Char-
lottesville, VA, USA, 2000.
[48] Chenxi Wang, Jonathan Hill, John C. Knight, and Jack W. Davidson. Protection
In International Conference on
of software-based survivability mechanisms.
Dependable Systems and Networks (DSN), 2001.
[49] Zhi Wang, Jiang Ming, Chunfu Jia, and Debin Gao. Linear obfuscation to combat
symbolic execution. In European Symposium on Research in Computer Security,
ESORICS, 2011.
[50] Babak Yadegari and Saumya Debray. Symbolic execution of obfuscated code. In
Conference on Computer and Communications Security (CCS), 2015.
[51] Babak Yadegari, Brian Johannesmeyer, Ben Whitely, and Saumya Debray. A
generic approach to automatic deobfuscation of executable code. In Symposium
on Security and Privacy, SP, 2015.
[52] Yongxin Zhou, Alec Main, Yuan Xiang Gu, and Harold Johnson. Information
hiding in software with mixed boolean-arithmetic transforms. In Information
Security Applications, WISA, 2007.
A FORMAL PROOFS
Theorem 1 (Optimal Composition) Suppose that P′ is ob-
tained by obfuscating the program P. If every original path of P goes
through at least k independent forking points of P′ inserting at least
θ feasible paths, then #ΠP′ ≥ #ΠP · θk
Proof. Let’s consider a program P with #Π original paths σi,
i ∈ {1 . . . #Π}. We obfuscate P into P′ with an obfuscation scheme
adding n independent forking points inserting #σ1..n feasible paths.
The forking points are placed such that every original path now
contains at least k forking points.
• The total number of paths of P′ is:
#ΠP′ =
σi
#σi ,
σi ∈ ΠP
• According to the definition of independence, one original
path σi with at least k forking points inserting #σi, {1..k }
feasible paths creates #σi ≥k
j=1 #σi, j new paths
• Then,
#ΠP′ ≥
( k
#ΠP′ ≥
j=1
We write θ = mini, j(#σi, j)
(θk),
σi
σi
#σi, j),
σi ∈ ΠP
σi ∈ ΠP
#ΠP′ ≥ #ΠP × θk
■
Theorem 2 (Resistance by design) Let us consider a program
P and a forking point F . Assuming F is built upon relevant variables,
then F is slice and taint resistant.
Proof. By definition, a sound taint analysis AT will mark any
relevant variable (as they depend from input). Hence, if F is built
upon relevant variables, then all variables v ∈ V ar(F) will be
marked by AT, hence taint analysis AT will yield no simplification
on F . In the same manner, a sound slice analysis AS will mark
any relevant variable (as they impact the output), implying that if
F is built upon relevant variables, then analysis AS will yield no
simplification on F .
■
B STATISTICS ON DATASETS
We present additional statistics on Dataset #1 (Appendix Table 7)
and Dataset #2 (Appendix Table 8). For Dataset #1, recall that 1-byte
input programs from the original dataset from Banescu et al. [5]
are automatically turned into equivalent 8-byte input programs
with same number of paths: additional input are not used by the
program, but latter protections will rely on them. We must do so as
they are otherwise too easy to enumerate.
C ADDITIONAL EXPERIMENTS
Search heuristics. Results in Appendix Table 9 shows that DSE
search heuristics does not impact that much overall results (cf. Ta-
ble 3). Depth-first search appears to be slightly better than the two
other ones for Split, and non-uniform random search appears to be
How to Kill Symbolic Deobfuscation for Free
(or: Unleashing the Potential of Path-Oriented Protections)
Table 7: Statistics on Dataset #1 (46 programs)
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Entry size
16 bytes
1 byte (*)
‘
#LOC
average
21
17
StdDev.
1.9
2.2
loc: line of code
KLEE exec. (s)
average
2.6s
1.8s
StdDev.
6.2
6.2
(*) 1-byte input programs are automatically turned into equivalent
8-byte input programs with same number of paths. We report
KLEE execution time on the modified versions.
Table 8: Statistics on Dataset #2 (7 programs)
Program
City hash
Fast hash
Spooky hash
MD5 hash
AES
DES
GRUB
locs KLEE exec. (s)
7.41
547
934
7.74
7.12
625
33.31
157
1.42
571
424
0.15
0.06
101
slightly worse than the two other ones for For. Nothing dramatic
yet.
Table 9: Impact of search heuristics – Dataset #1 – secret find-
ing – 1h TO
Figure 9: Runtime overhead w.r.t. to the number of For ob-
fuscation loops
D CODE SNIPPET FOR WRITE
Fig. 10 shows an example of an assembly-level implementation of
the Write protection over the expression “var = input;”.
__asm__ ( " movl %[ s r c ] ,
( . L \%=+1)
" jmp . L%=
" %=:
" . s e c t i o n . L %= , \ " awx \ "
" movl
" jmp %=b
" . p r e v i o u s
: [ d s t ]
\ $0 , %[ d s t ]
"=&a "
( var )
\ n \ t "
\ n \ t "
\ n \ t "
\ n \ t "
\ n \ t "
\ n \ t "
\ n \ t "
" r "
:
[ s r c ]
( input ) ) ;
Timeouts
Virt
Virt ×2
Virt ×3
Flat-Virt
Flat-MBA
Split (×10)
Split (×13)
For (k = 1)
For (k = 2)
For (k = 3)
For (k = 4)
NURS
0/15
0/15
1/15
0/15
0/15
0/15
1/15
0/15
1/15
10/15
15/15
BFS
0/15
0/15
1/15
0/15
0/15
0/15
1/15
0/15
1/15
8/15
15/15
DFS
0/15
0/15
1/15
0/15
0/15
0/15
0/15
0/15
1/15
8/15
15/15
Figure 10: ASM encoding of protection Write
allpath
0/15
0/15
2/15
0/15
0/15
0/15
1/15
0/15
4/15
13/15
15/15
Runtime overhead. We evaluate how the performance penalty
evolved for protection For on very high values of k. We take the
15 examples of Dataset #1 with large input space, and we vary the
size of the input string from 3 to 100000, increasing the number of
forking points accordingly (k between 3 and 100000), one forking
point (loop) per byte of the input string. We run 15 random inputs
15 times for each size and measure the average runtime overhead.
Fig. 9 shows the evolution of runtime overhead w.r.t. the number
of For loops.
The runtime overhead stays below 5% (×1.05) for fewer than
k = 250. This means in particular that one can significantly boost
For-based protections without incurring big runtime penalties.
020000400006000080000100000# for loops1.01.11.21.31.41.51.61.71.8Runtime overhead