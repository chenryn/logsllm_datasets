title:Learning-based Practical Smartphone Eavesdropping with Built-in Accelerometer
author:Zhongjie Ba and
Tianhang Zheng and
Xinyu Zhang and
Zhan Qin and
Baochun Li and
Xue Liu and
Kui Ren
Learning-based Practical Smartphone Eavesdropping
with Built-in Accelerometer
Zhongjie Ba∗†§, Tianhang Zheng‡§, Xinyu Zhang∗, Zhan Qin∗, Baochun Li‡, Xue Liu† and Kui Ren∗
∗School of Cyber Science and Technology, Zhejiang University
Email: PI:EMAIL, PI:EMAIL, PI:EMAIL
†School of Computer Science, McGill University
Email: PI:EMAIL, PI:EMAIL
‡Department of Electrical and Computer Engineering, University of Toronto
Email:PI:EMAIL, PI:EMAIL
Abstract—Motion sensors on current smartphones have been
exploited for audio eavesdropping due to their sensitivity to
vibrations. However, this threat is considered low-risk because of
two widely acknowledged limitations: First, unlike microphones,
motion sensors can only pick up speech signals traveling through
a solid medium. Thus, the only feasible setup reported previously
is to use a smartphone gyroscope to eavesdrop on a loudspeaker
placed on the same table. The second limitation comes from a
common sense that these sensors can only pick up a narrow
band (85-100Hz) of speech signals due to a sampling ceiling of
200Hz. In this paper, we revisit the threat of motion sensors
to speech privacy and propose AccelEve, a new side-channel
attack that employs a smartphone’s accelerometer to eavesdrop
on the speaker in the same smartphone. Speciﬁcally, it utilizes the
accelerometer measurements to recognize the speech emitted by
the speaker and to reconstruct the corresponding audio signals. In
contrast to previous works, our setup allows the speech signals to
always produce strong responses in accelerometer measurements
through the shared motherboard, which successfully addresses
the ﬁrst limitation and allows this kind of attacks to penetrate
into real-life scenarios. Regarding the sampling rate limitation,
contrary to the widely-held belief, we observe up to 500Hz
sampling rates in recent smartphones, which almost covers the
entire fundamental frequency band (85-255Hz) of adult speech.
On top of these pivotal observations, we propose a novel deep
learning based system that learns to recognize and reconstruct
speech information from the spectrogram representation of ac-
celeration signals. This system employs adaptive optimization on
deep neural networks with skip connections using robust and gen-
eralizable losses to achieve robust recognition and reconstruction
performance. Extensive evaluations demonstrate the effectiveness
and high accuracy of our attack under various settings.
I.
INTRODUCTION
Smartphones have permeated into our daily lives as an
indispensable communication interface to the rest of the world.
Among all different modalities of communication, voice com-
munication is always considered as one of the top choices. Due
to its importance, the system permission level of microphone
§The ﬁrst two authors contribute equally to the paper.
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.24076
www.ndss-symposium.org
usage is the highest by default in most operating systems [2].
A signiﬁcant amount of research in the literature focused on
how to eavesdrop on a user’s phone call by exploiting the
vulnerability of communication protocols, or by implanting a
backdoor to access the permission of utilizing a microphone.
In this paper, we consider the problem of eavesdropping on
the speaker in a smartphone by side-channel attacks without
the requirement of sensitive system permissions. Instead of
hacking into the operating system and gaining access to the ad-
ministrator authority, we recognize and reconstruct the speech
signals emitted by a smartphone’s speaker through analyzing
the measurements of motion sensors on the same smartphone.
This attack could arise due to the following reasons. First,
because the acceleroemeter and gyroscope are considered low-
risk, they are usually set to be zero-permission sensors and
can be accessed without warning smartphone users. Second,
motion sensors can response to external vibrations, which
allows them to pick up certain audio signals. Additionally,
there is an overlap between the fundamental frequencies of
human voice and the sampling frequencies of smartphone
sensors. Therefore, it is theoretically possible to capture speech
signals by zero-permission motion sensors.
In the literature, motion sensor based speech recognition
has attracted a number of studies. Michalevsky et al. [32]
is the ﬁrst work towards this direction, which utilizes a
smartphone’s gyroscope to pick up surface vibrations incurred
by an independent
loudspeaker placed on the same table.
The captured vibrations are then analyzed to recognize the
speech information played by the loudspeaker. The proposed
method suffers from its feasibility and the poor performance
on recognition accuracy, i.e., the accuracy is only 26% in
differentiating single digit pronunciations. Another line of
research focuses on exploiting the air as the medium rather
than a solid surface. Zhang et al. [44] use the accelerometer
as a “microphone” to detect the voice input of the smartphone.
Recently, Anand et al. [5] (S&P 2018) study the problem of
detecting speech signals through either solid surfaces (such as
desks) or air. Their experimental results show that among all
tested audio sources and medium, only the loudspeaker placed
on the desk has sufﬁcient power and sound path for generating
and transmitting vibrations to motion sensors. Based on this
observation, [5] claims that the threat under investigation will
not go beyond the loudspeaker setup studied in [32].
collects accelerometer measurements in the background and
utilizes the collected signals to recognize and reconstruct the
played speech signals. It is worth noting that the spy app could
be disguised as any kind of mobile apps since accessing the
accelerometer does not require any permission.
The main intent of the proposed system is to recognize
and reconstruct
the speech signals from the accelerometer
measurements. Since raw acceleration signals usually cap-
ture multiple “words” and could be severely distorted by
human movement, our system ﬁrst implements a preprocessing
module to automatically eliminate signiﬁcant distortions from
acceleration signals and to cut long signals into single word
segments. We then convert each single word acceleration signal
to its spectrogram representation and pass it to a recognition
module and a reconstruction module for further analysis.
The recognition module adopts the DenseNet [24] as the
base network to recognize the speech information (text) carried
by the spectrogram of the acceleration signal. Extensive eval-
uations demonstrate that our recognition module achieves new
state-of-the-art results under different settings. In particular,
our recognition module has 78% accuracy on recognizing 10
digits and 70% accuracy on identifying 20 speakers when the
smartphone is placed on a table, while the previous SOTA
results are 26% accuracy in the digit task and 50% accuracy
on recognizing only 10 speakers. Also, evaluations under
different noisy ambient conditions demonstrate the robustness
of our recognition model. Except for digits and letters, we also
demonstrate that our recognition and reconstruction models
can be used to identify hot (sensitive) words in phone calls.
With the help of our speaker-identiﬁcation model, the adver-
sary might acquire multiple pieces of sensitive information for
the callers’ contacts by linking the hot words identiﬁed across
multiple phone calls to a speciﬁc caller. Furthermore, we also
realize an end-to-end attack based on our recognition model
in real-world conversations.
In the reconstruction module, we implement a reconstruc-
tion network that learns the mapping between the accelerom-
eter measurements and the audio signal played by the smart-
phone speaker. Because most of the speech information in the
high frequency band are the harmonics of the fundamental fre-
quency, the reconstruction module can convert an acceleration
signal into an audio (speech) signal with enhanced sampling
rates (1500Hz). According to our experimental results, the
reconstruction module was able to recover nearly all the vowel
information, including the fundamental frequency components
in the low frequency band and its harmonics in the high-
frequency band. The unvoiced consonants are not recovered
because these components have no information distributed in
the frequency band below 2000Hz.
Our contributions are summarized as follows:
1) We propose AccelEve, an accelerometer-based side
channel attack against smartphone speakers. Contrary
to the previous belief, the proposed setup inﬁltrates
this kind of attacks into common scenarios in daily
life, e.g., answering a phone call or receiving voice
messages. Comprehensive experiments are conducted
to evaluate the feasibility of the setup.
2) We ﬁrst report an important observation that ac-
celerometers on recent smartphones almost cover the
Fig. 1. Accelerometer-based smartphone eavesdropping and the workﬂow of
speech recognition and speech reconstruction.
However, all of the above works failed to cover the most
adverse setup, where the motion sensors are utilized as a side-
channel to capture the speech signals played by the speaker
on the same smartphone. In this case, the motion sensors and
the speaker are in physical contact with the same board and
locate in very close proximity to each other. Hence, contrary
to the claim in [5], speech signals emitted by the speaker will
always have a signiﬁcant impact on the motion sensors like the
gyroscope and the accelerometer, no matter where and how the
smartphone is placed (on a table or in your hand).
Furthermore, all previous works in the literature share
a misleading common sense that the sampling rates of the
accelerometer and gyroscope in Android-powered smartphones
cannot exceed 200Hz [32], [44], [5]. Because the typical
fundamental frequency for adult speech lies in the range 85-
255Hz [38], [7],
the previously believed sampling ceiling
leads to a consensus that motion sensors can only capture
a very small range of human speech in 85-100Hz. However,
we show that this is not the case. According to the ofﬁcial
documents for Android [2], an Android application selecting
the SENSOR_DELAY_FASTEST mode will receive sensor
measurements as fast as possible. Thus the actual sampling
rates of motion sensors are determined by the performance of
the smartphone, which has been conﬁrmed by our experiments.
In particular, for certain smartphones released in 2018, we
observe a sampling frequency of up to 500Hz, which indicates
that the accelerometer is able to capture speech information in
the range of 85-250Hz. It covers almost the entire fundamental
frequency band (85-255Hz) of adult speech.
In this paper, we address the limitations of previous works
by presenting a novel and practical setup and a deep learn-
ing based system for speech recognition and reconstruction,
which outperforms all similar related works. In our setup,
the adversary is a spy app whose objective is to eavesdrop
on the speaker in the same smartphone. When the speaker
emits speech signals (e.g., during a phone call), the spy app
2
entire fundamental frequency band of adult speech.
3) We design a deep learning-based system to recog-
nize and reconstruct speech signals only from ac-
celerometer measurements. Extensive evaluations on
the existing and our datasets show that the system
signiﬁcantly and consistently outperforms existing so-
lutions1. To the best of our knowledge, the proposed
system gives the ﬁrst trail on accelerometer-based
speech reconstruction.
II. BACKGROUND AND RELATED WORK
In this section, we ﬁrst describe the design of the motion
sensors on current smartphones. We then review the existing
works that exploit motion sensors to capture speech signals
and other topics related to AccelEve.
A. MEMS Motion Sensors
Modern smartphones typically come equipped with a three-
axis accelerometer and a three-axis gyroscope. These sensors
are highly sensitive to the motion of the device and have been
widely applied to sense orientation, vibration, shock, etc.
Accelerometer: a three-axis accelerometer is a device that
captures the acceleration of its body along three sensing axes.
Each axis is normally handled by a sensing unit consisting of
a movable seismic mass, several ﬁxed electrodes, and several
spring legs, as shown in Fig.2(a). When the accelerometer
experiences an acceleration along a sensing axis, the corre-
sponding seismic mass shifts to the opposite direction and
creates a change in the capacitance between the electrodes.
This change yields an analog signal that is then mapped to
acceleration measurements.
Gyroscope: gyroscopes on smartphones normally leverage
the Coriolis force [1] to measure the angular rate around three
axes. As shown in Fig.2(b), the sensing unit for each axis has
a similar structure to the accelerometer’s, except that the mass
is constantly vibrating and is allowed to move along two axes.
When the gyroscope experiences an external angular rate, due
to the Coriolis effect, the mass tends to continue vibrating in
the same plane and exerts a Coriolis force perpendicular to the
rotating axis and the moving direction of the mass. This force
creates a displacement of the mass and changes the capacitance
between the electrodes. Through measuring the capacitance
change, the angular rate of the device can be obtained.
In practice, the information captured by a motion sensor
is determined not only by its sensitivity to the surround-
ing environment, but also by the sampling frequency. On
Android-powered smartphones, motion sensors can be ac-
cessed with four delay options as listed in Table I. Each
option speciﬁes an interval at which sensor measurements are
sent to the application. In particular, if an application selects
SENSOR_DELAY_FASTEST, sensor measurements will be
sent to that application as fast as possible and the actual
sampling rate will be mainly determined by the performance
of the smartphone. In 2014, the actual sampling rate achieved
200Hz [32], which allows the motion sensors to accurately
capture frequency components below 100 Hz, according to the
Nyquist sampling theorem.
1Our code and collected datasets are available on https://github.com/
tianzheng4/learning speech from accelerometer.
(a) Accelerometer structure
(b) Gyroscope structure
Fig. 2. Sketches of an accelerometer and gyroscope.
TABLE I.
SAMPLING FREQUENCIES SUPPORTED BY ANDROID [2].
Delay Options
SENSOR_DELAY_NORMAL
SENSOR_DELAY_UI
SENSOR_DELAY_GAME
SENSOR_DELAY_FASTEST
Delay
200 ms
20 ms
60 ms
0 ms
Sampling Rate
5 Hz
50 Hz
16.7 Hz
As fast as possible
B. Speech Recognition via Motion Sensors
Human speech signals have a fundamental frequency that
carries important linguistic and non-linguistic information such
as naturalness, emotion, and speaker idiosyncrasy [18]. It is
deﬁned as the vibration rate of the vocal folds and varies
widely depending on age, gender, individual physiological dis-
positions, etc [13], [19]. Typically, the fundamental frequencies
for an adult male and adult female lie in the range 85-180Hz
and 165-255Hz, respectively. [38], [7]. Because the frequency
range of this fundamental frequency partially overlaps with
that of smartphone sensors, the accelerometer and gyroscope
have been exploited to capture a small portion of the speech
signals in the low frequency band.
Michalevsky et al. [32] (Usenix Security 2014) study the
setup where a smartphone is placed on the same solid surface
as a loudspeaker. They employ the smartphone’s gyroscope to
“pick up” speech signals emitted by the loudspeaker and use
the captured information to conduct speech recognition and
speaker identiﬁcation. In this scenario, the signals captured
by the gyroscope are actually surface vibrations. Because the
gyroscope shows low sensitivity to surface vibrations and
suffers from limited sampling rate (200Hz), it is difﬁcult to
achieve high success rates for the recognition tasks.
Zhang et al. [44] study the setup where a user speaks to a
smartphone held in her hand or placed on a desk. In this setup,
the authors employ the accelerometer to pickup speech signals
traveling through the air and used the obtained accelerometer
readings to conduct hot words detection (”Okay Google” and
”Hi Galaxy”). However, the experimental results in [5] suggest
3
that the speech signals traveling through the air are unlikely
to have any noticeable impact on motion sensors. Therefore,
the accelerometer may not be able to collect sufﬁcient speech
information through airborne vibrations.
In order to better understand the threat of motion sensors
to speech privacy, Anand et al. [5] (S&P 2018) systemati-
cally study the response of accelerometers and gyroscopes to
speech signals in various settings. They stimulate both sen-
sors with human-rendered, laptop-rendered and loudspeaker-
rendered speech signals traveling through the air or a solid
surface. Their experimental results show that only loudspeaker-
rendered speech signals traveling through a solid surface can
create noticeable impacts on motion sensors. Based on this
observation, Anand et al. [5] claim that the threat under in-
vestigation does not go beyond the Loudspeaker-Same-Surface
setup studied by Michalevsky et al. [32].
However, all the above works failed to cover the most
adverse setup where the motion sensors are on the same
smartphone as the target speaker. In this case, the motion
sensors and the speaker will be in physical contact with
the same board and locate in very close proximity to each
other. Thus here, contrary to the claim in [5], speech signals
emitted by the speaker will always have a signiﬁcant impact
on the gyroscope and the accelerometer. It does not matter
where and how the smartphone is placed, which could
be on a table (solid surface), on a bed (soft surface),
or in your hand. Moreover, a smartphone speaker is more
likely to reveal sensitive information than an independent
loudspeaker. For instance, when a user is making a phone
call, an application running in the background can access
to the zero-permission motion sensors and use the collected
signals to recover sensitive speech information. In this paper,
we look into this setup and explore accelerometer-based speech
recognition and reconstruction using deep learning techniques.
In parallel and independent work, Anand et al. (arXiv
2019) [6] also study accelerometer-based speech recognition
under the setup that the accelerometer is on the same smart-
phone as the speaker. While Anand et al. employ existing fea-
ture selection and classiﬁcation tools that work well on small
datasets, we implement deep learning-based speech recognition
that achieves higher accuracy. The proposed model is also