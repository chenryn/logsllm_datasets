# Life Management
## [Computer configuration management](configuration_management.md)
* New: Introduce configuration management.
    Configuring your devices is boring, disgusting and complex. Specially when your
    device dies and you need to reinstall. You usually don't have the time or energy
    to deal with it, you just want it to work.
    To have a system that allows you to recover from a disaster it's expensive in
    both time and knowledge, and many people have different solutions.
    This article shows the latest step of how I'm doing it.
# Coding
## Languages
### [Libraries](python_gnupg.md)
* New: How to encrypt a file.
    ```python
    gpg.encrypt_file('path/to/file', recipients)
    ```
    Where `recipients` is a `List[str]` of gpg Key IDs.
### [Configure Docker to host the application](docker.md)
* New: [Troubleshoot Docker python not showning prints.](python_docker.md#docker-python-not-showning-prints)
    Use `CMD ["python","-u","main.py"]` instead of `CMD ["python","main.py"]`.
* New: [Get the difference of two lists.](python_docker.md#prevent-pip-install--r-requirements.txt-to-run-on-each-docker-build:-prevent-`pip-install--r-requirements.txt`-to-run-on-each-`docker-build`
i'm-assuming-that-at-some-point-in-your-build-process,-you're-copying-your-entire-application-into-the-docker-image-with-copy-or-add:
```dockerfile
copy-.-/opt/app
workdir-/opt/app
run-pip-install--r-requirements.txt
```
the-problem-is-that-you're-invalidating-the-docker-build-cache-every-time-you're-copying-the-entire-application-into-the-image.-this-will-also-invalidate-the-cache-for-all-subsequent-build-steps.
to-prevent-this,-i'd-suggest-copying-only-the-requirements.txt-file-in-a-separate-build-step-before-adding-the-entire-application-into-the-image:
```dockerfile
copy-requirements.txt-/opt/app/requirements.txt
workdir-/opt/app
run-pip-install--r-requirements.txt
copy-.-/opt/app
```
feat(python_snippets)
    If we want to substract the elements of one list from the other you can use:
    ```python
    for x in b:
      if x in a:
        a.remove(x)
    ```
* New: [Override entrypoint.](docker.md#override-entrypoint)
    ```bash
    sudo docker run -it --entrypoint /bin/bash [docker_image]
    ```
### [Click](click.md)
* New: Split stdout from stderr in tests.
    By default the `runner` is configured to mix `stdout` and `stderr`, if you wish to tell apart both sources use:
    ```python
    def test(runner: CliRunner):
      ...
      runner.mix_stderr = False
    ```
### [Promql](promql.md)
* New: [Add basic operations.](promql.md#usage)
    Selecting series:
    * Select latest sample for series with a given metric name:
      ```promql
      node_cpu_seconds_total
      ```
    * Select 5-minute range of samples for series with a given metric name:
      ```promql
      node_cpu_seconds_total[5m]
      ```
    * Only series with given label values:
      ```promql
      node_cpu_seconds_total{cpu="0",mode="idle"}
      ```
    * Complex label matchers (`=`: equality, `!=`: non-equality, `=~`: regex match, `!~`: negative regex match):
      ```promql
      node_cpu_seconds_total{cpu!="0",mode=~"user|system"}
      ```
    * Select data from one day ago and shift it to the current time:
      ```promql
      process_resident_memory_bytes offset 1d
      ```
    Rates of increase for counters:
    * Per-second rate of increase, averaged over last 5 minutes:
      ```promql
      rate(demo_api_request_duration_seconds_count[5m])
      ```
    * Per-second rate of increase, calculated over last two samples in a 1-minute time window:
      ```promql
      irate(demo_api_request_duration_seconds_count[1m])
      ```
    * Absolute increase over last hour:
      ```promql
      increase(demo_api_request_duration_seconds_count[1h])
      ```
    Aggregating over multiple series:
    * Sum over all series:
      ```promql
      sum(node_filesystem_size_bytes)
      ```
    * Preserve the instance and job label dimensions:
      ```promql
      sum by(job, instance) (node_filesystem_size_bytes)
      ```
    * Aggregate away the instance and job label dimensions:
      ```promql
      sum without(instance, job) (node_filesystem_size_bytes)
      ```
      Available aggregation operators: `sum()`, `min()`, `max()`, `avg()`, `stddev()`, `stdvar()`, `count()`, `count_values()`, `group()`, `bottomk()`, `topk()`, `quantile()`.
    Time:
    * Get the Unix time in seconds at each resolution step:
      ```promql
      time()
      ```
    * Get the age of the last successful batch job run:
      ```promql
      time() - demo_batch_last_success_timestamp_seconds
      ```
    * Find batch jobs which haven't succeeded in an hour:
      ```promql
      time() - demo_batch_last_success_timestamp_seconds > 3600
      ```
### [sh](python_sh.md)
* New: [Passing environmental variables to commands.](python_sh.md#passing-environmental-variables-to-commands)
    The `_env` special `kwarg` allows you to pass a dictionary of environment variables and their corresponding values:
    ```python
    import sh
    sh.google_chrome(_env={"SOCKS_SERVER": "localhost:1234"})
    ```
    `_env` replaces your processâ€™s environment completely. Only the key-value pairs in `_env` will be used for its environment. If you want to add new environment variables for a process in addition to your existing environment, try something like this:
    ```python
    import os
    import sh
    new_env = os.environ.copy()
    new_env["SOCKS_SERVER"] = "localhost:1234"
    sh.google_chrome(_env=new_env)
    ```
* New: [Use commands that return a SyntaxError.](python_sh.md#use-commands-that-return-a-syntaxerror)
    `pass` is a reserved python word so `sh` fails when calling the password store command `pass`.
    ```python
    pass_command = sh.Command('pass')
    pass_command('show', 'new_file')
    ```
### [Typer](typer.md)
* New: [Print to stderr.](typer.md#print-to-stderr)
    You can print to "standard error" with a Rich `Console(stderr=True)`
    ```python
    from rich.console import Console
    err_console = Console(stderr=True)
    err_console.print("error message")
    ```
# DevOps
## Infrastructure as Code
### [Gitea](gitea.md)
* New: [Disable the regular login, use only Oauth.](gitea.md#disable-the-regular-login-use-only-oauth)
    You need to add a file inside your [`custom` directory](https://docs.gitea.io/en-us/customizing-gitea/). The file is too big to add in this digest, please access the article to get it.
* New: [Configure it with terraform.](gitea.md#configure-it-with-terraform)
    Gitea can be configured through terraform too. There is an [official provider](https://gitea.com/gitea/terraform-provider-gitea/src/branch/main) that doesn't work, there's a [fork that does though](https://registry.terraform.io/providers/Lerentis/gitea/latest/docs). Sadly it doesn't yet support configuring Oauth Authentication sources. Be careful [`gitea_oauth2_app`](https://registry.terraform.io/providers/Lerentis/gitea/latest/docs/resources/oauth2_app) looks to be the right resource to do that, but instead it configures Gitea to be the Oauth provider, not a consumer.
    In the article you can find how to configure and use it to:
    * [Create an organization](gitea.md#create-an-organization)
### [Chezmoi](helm_installation.md)
* New: Introduce chezmoi.
    [Chezmoi](https://www.chezmoi.io/) stores the desired state of your dotfiles in
    the directory `~/.local/share/chezmoi`. When you run `chezmoi apply`, `chezmoi`
    calculates the desired contents for each of your dotfiles and then makes the
    minimum changes required to make your dotfiles match your desired state.
    What I like:
    - Supports `pass` to retrieve credentials.
    - Popular
    - Can remove directories on `apply`
    - It has a `diff`
    - [It can include dotfiles from an URL](https://www.chezmoi.io/user-guide/include-files-from-elsewhere/)
    - [Encrypt files with gpg](https://www.chezmoi.io/user-guide/encryption/gpg/)
    - [There's a vim plugin](https://github.com/alker0/chezmoi.vim)
    - Actively maintained
    - Good documentation
    What I don't like:
    - Go templates, although
      [it supports autotemplating](https://www.chezmoi.io/user-guide/templating/#creating-a-template-file)
      and it's
      [well explained](https://www.chezmoi.io/user-guide/templating/#template-variables)
    - Written in Go
    In the article you can also find:
    * [How to install it](chezmoi.md#installation)
    * [How to use it](chezmoi.md#basic-usage)
    * [How to install a binary from an external url](chezmoi.md#install-a-binary-from-an-external-url)
* Correction: Update the project url of helm-secrets.
    From https://github.com/futuresimple/helm-secrets to https://github.com/jkroepke/helm-secrets
### [Helmfile](dotdrop.md)
* New: [Troubleshoot Yaml templates in go templates.](helmfile.md#yaml-templates-in-go-templates)
    If you are using a `values.yaml.gotmpl` file you won't be able to use `{{ whatever }}`. The solution is to extract that part to a yaml file and include it in the go template. For example:
    * `values.yaml.gotmpl`:
      ```gotmpl
      metrics:
      serviceMonitor:
        enabled: true
        annotations:
        additionalLabels:
          release: prometheus-operator
      {{ readFile "prometheus_rules.yaml" }}
      ```
    * `prometheus_rules.yaml`
      ```yaml
      prometheusRule:
        enabled: true
        additionalLabels: