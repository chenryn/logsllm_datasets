1486 ns
439 ns
1821 ns
Table 1: Processing overhead of different types of packets.
policy described in Section 3.3: a destination initially grants all re-
quests, but stops renewing capabilities for senders that misbehave
by ﬂooding trafﬁc. We set the destination to grant an initial capabil-
ity of 32KB in 10 seconds. This allows an attacker to ﬂood at a rate
of 1Mb/s, but for only 32KB until the capability expires. The desti-
nation does not renew capabilities because of the attack. Figure 11
shows how the transfer time changes for TVA with this policy as
an attack commences. There are two attacks: a high intensity one
in which all 100 attackers attack simultaneously; and a low inten-
sity one in which the 100 attackers divide into 10 groups that ﬂood
one after the other, as one group ﬁnishes their attack. We see that
both attacks are effective for less than 5 seconds, causing temporary
congestion and increasing the transfer time of some connections by
about 2 seconds.
Figure 11 also shows the results for SIFF under the same attacks.
In SIFF, the expiration of a capability depends on changing a router
secret – even if the destination determines that the sender is misbe-
having it is powerless to revoke the authorization beforehand. This
suggests that rapid secret turnover is needed, but there are practi-
cal limitations on how quickly the secret can be changed, e.g., the
life time of a router secret should be longer than a small multi-
ple of TCP timeouts. In our experiment, we assume SIFF can ex-
pire its capabilities every three seconds. By contrast, TVA expires
router secret every 128 seconds. We see that both attacks have a
much more pronounced effect on SIFF. The high intensity attack
increases the transfer time by 4 seconds, and the low intensity at-
tack lasts for 30 seconds. In each attack period of three seconds, all
legitimate requests are blocked until the next transition. As a result,
the transfer time jumps to more than three seconds.
6.
IMPLEMENTATION
We prototyped TVA using the Linux netﬁlter framework [19]
running on commodity hardware. We implemented the host por-
tion of the protocol as a user-space proxy, as this allows legacy
applications to run without modiﬁcation. We implemented router
capability processing as a kernel module using the AES-hash as the
ﬁrst hash function (for pre-capabilities) and SHA1 as the second
hash function [17] (for capabilities).
The purpose of this effort was to check the completeness of our
design and to understand the processing costs of capabilities. We
did not consider the processing costs of fair queuing. In our exper-
iment, we set up a router using a dual-processor 3.2GHz Pentium
Xeon machine running a Linux 2.6.8 Kernel.
It used the native
Linux forwarding module. We then used a kernel packet genera-
tor to generate different types of packets and sent them through the
router, modifying the code to force the desired execution path. For
each run, our load generator machines sent one million packets of
each type to the router. We recorded the average number of instruc-
tion cycles for the router to process each type of packet, averaging
the results over ﬁve experiments.
Table 1 shows the results of this experiment, with cycles con-
verted to time.
In normal operation, the most common type of
packet is a regular packet with an entry at a router. The processing
)
s
p
p
k
(
t
e
a
r
t
t
u
p
u
O
 400
 350
 300
 250
 200
 150
 100
 50
 0
 0
legacy IP
regular w/ entry
request
renewal w/ entry
regular w/o entry
renewal w/o entry
 100
 200
 300
 400
Input rate (kpps)
Figure 12: The peak output rate of different types of packets.
overhead for this type is the lowest at 33 ns. The processing over-
head for validating a capability for a packet without a cached entry
is about 1486 ns, as it involves computing two hash functions. The
cost to process a request packet is lower and similar to the cost to
process a renewal packet with a cached entry because both involve a
pre-capability hash computation. The most computation-intensive
operation is forwarding a renewal packet without a cached entry. In
this case the router needs to compute three hash functions: two to
check the validity of the old capability, and one to compute a new
pre-capability hash. The processing cost is 1821 ns.
We also tested how rapidly a Linux router could forward capa-
bility packets. The results are shown in Figure 12. The output rate
increases with the input rate and reaches a peak of 160 to 280Kpps,
depending on the type of packet. This compares well with the
peak lossless rate for vanilla IP packets of about 280Kpps. In both
cases these rates are dominated by per packet interrupt handling,
and they could be increased markedly with a polling device driver,
as demonstrated by Click [13]. We expect that removing the 3.5us
interrupt penalty would improve the output rate to 500-1400Kpps,
equivalent to 240 to 670Mbps with minimum size packets (of 40
TCP/IP bytes plus 20 capability bytes). An attacker might attempt
to overwhelm the CPU by ﬂooding spoofed short renewal pack-
ets; they would not match, but that might still lead to packet loss
of good trafﬁc if the processing was done in the order received.
Fortunately, we can use Lazy Receiver Processing (LRP) for this
case [7]: when the CPU is overloaded, separately queue incoming
packets based on their required computation per input bit. Normal
trafﬁc, consisting of short requests and full-size regular packets will
then be processed at full speed.
We conclude that our implementation can handle 100 Mbps in-
terfaces with off-the-shelf hardware; in the near future, we expect
to be able to demonstrate that an optimized implementation can run
at a gigabit without specialized hardware.
7. SECURITY ANALYSIS
The security of TVA is based on the inability of an attacker to ob-
tain capabilities for routers along the path to a destination they seek
to attack. We brieﬂy analyze how TVA counters various threats.
An attacker might try to obtain capabilities by breaking the hash-
ing scheme. We use standard cryptographic functions with a suf-
ﬁcient amount of key material and change keys every 128 seconds
as to make breaking keys a practical impossibility.
An attacker may try to observe the pre-capabilities placed in its
requests by routers, e.g., by causing ICMP error messages to be re-
turned to the sender from within the network, or by using IP source
routing. To defeat these vulnerabilities, we use a packet format that
does not expose pre-capabilities in the ﬁrst 8 bytes of the IP packet
(which are visible in ICMP messages) and require that capability
routers treat packets with IP source routes as legacy trafﬁc. Beyond
this, we rely on Internet routing to prevent the intentional misdeliv-
ery of packets sent to a remote destination.
A different attack is to steal and use capabilities belonging to a
sender (maybe another attacker) who was authorized by the desti-
nation. Since a capability is bound to a speciﬁc source, destination,
and router, the attacker will not generally be able to send packets
along the same path as the authorized sender. The case in which
we cannot prevent theft is when the attacker can eavesdrop on the
trafﬁc between an authorized sender and a destination. This in-
cludes a compromised router. In this case, the attacker can co-opt
the authorization that belongs to the sender. In fact, it can speak for
any senders for whom it forwards packets. However, even in this
situation our design provides defense in depth. The compromised
router is just another attacker – it does not gain more leverage than
an attacker at the compromised location. DoS attacks on a destina-
tion will still be limited as long as there are other capability routers
between the attacker and the destination.
Another attack an eavesdropper can launch is to masquerade
a receiver to authorize attackers to send attack trafﬁc to the re-
ceiver. Similarly, our design provides defense in depth.
If the
attacker is a compromised router, this attack can only congest the
receiver’s queues at upstream links, because the router cannot forge
pre-capabilities of downstream routers. This attack is no worse than
the router simply dropping all trafﬁc to the receiver. If the attacker
is a comprised host that shares a local broadcast network with a
receiver, the attacker can be easily spotted and taken off-line.
Alternatively, an attacker and a colluder can spoof authorized
trafﬁc as if it were sent by a different sender S. The attacker sends
requests to the colluder with S’s address as the source address, and
the colluder returns the list of capabilities to the attacker’s real ad-
dress. The attacker can then ﬂood authorized trafﬁc to the colluder
using S’s address. This attack is harmful if per-source queuing is
used at a congested link. If the spoofed trafﬁc and S’s trafﬁc share
the congested link, S’s trafﬁc may be completely starved. This at-
tack has little effect on a sender’s trafﬁc if per-destination queueing
is used, which is TVA’s default.
ISPs should not use per-source
queuing if source addresses cannot be trusted.
Finally, other attacks may target capability routers directly, seek-
ing to exhaust their resources. However, the computation and state
requirements for our capability are bounded by design. They may
be provisioned for the worst case.
8. DEPLOYMENT
Our design requires both routers and hosts to be upgraded, but
does not require a ﬂag day. We expect incremental deployment to
proceed organization by organization. For example, a government
or large scale enterprise might deploy the system across their in-
ternal network, to ensure continued operation of the network even
if the attacker has compromised some nodes internal to the organi-
zation, e.g., with a virus. Upstream ISPs in turn might deploy the
system to protect communication between key customers.
Routers can be upgraded incrementally, at trust boundaries and
locations of congestion, i.e., the ingress and egress of edge ISPs.
This can be accomplished by placing an inline packet processing
box adjacent to the legacy router and preceding a step-down in ca-
pacity (so that its queuing has an effect). No cross-provider or inter-
router arrangements are needed and routing is not altered. Further
deployment working back from a destination then provides greater
[7] P. Druschel and G. Banga. Lazy Receiver Processing (LRP):
A Network Subsystem Architecture for Server Systems. In
2nd OSDI, 1996.
[8] P. Ferguson and D. Senie. Network Ingress Filtering: Defeat-
ing Denial of Service Attacks that Employ IP Source Address
Spooﬁng. Internet RFC 2827, 2000.
[9] M. Handley and A. Greenhalgh. Steps Towards a DoS-
Resistant Internet Architecture. In ACM SIGCOMM Work-
shop on Future Directions in Network Architecture (FDNA),
2004.
[10] J. Ioannidis and S. Bellovin. Implementing Pushback: Router-
Based Defense Against DoS Attacks. In NDSS, 2002.
[11] S. Kandula, D. Katabi, M. Jacob, and A. Berger. Botz-4-sale:
Surviving organized DDoS attacks that mimic ﬂash crowds.
In 2nd NSDI, May 2005.
[12] A. Keromytis, V. Misra, and D. Rubenstein. SOS: Secure
Overlay Services. In ACM SIGCOMM, 2002.
[13] E. Kohler, R. Morris, B. Chen, J. Jannotti, and M. F.
Kaashoek. The Click Modular Router. ACM Transactions on
Computer Systems, 18(3):263–297, Aug. 2000.
[14] K. Lakshminarayanan, D. Adkins, A. Perrig, and I. Stoica.
Taming IP Packet Flooding Attacks. In Proc. HotNets-II,
2003.
[15] S. Machiraju, M. Seshadri, and I. Stoica. A Scalable and Ro-
bust Solution for Bandwidth Allocation . In IWQoS’02, 2002.
[16] R. Mahajan, S. Bellovin, S. Floyd, J. Ioannidis, V. Paxson,
and S. Shenker. Controlling High Bandwidth Aggregates in
the Network. Computer Communications Review, 32(3), July
2002.
[17] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone. Hand-
book of applied cryptography, chapter 9. CRC Pres, 1997.
[18] D. Moore, G. Voelker, and S. Savage. Inferring Internet De-
nial of Service Activity. In Usenix Security Symposium 2001,
2001.
[19] http://www.netfilter.org/.
[20] S. Savage, D. Wetherall, A. Karlin, and T. Anderson. Practi-
cal Network Support for IP Traceback. In ACM SIGCOMM,
2000.
[21] A. Snoeren, C. Partridge, L. Sanchez, C. Jones, F. Tchakoun-
tio, S. Kent, and W. Strayer. Hash-Based IP Traceback. In
ACM SIGCOMM, 2001.
[22] D. Song and A. Perrig. Advance and Authenticated Marking
Schemes for IP Traceback. In Proc. IEEE Infocom, 2001.
[23] I. Stoica, S. Shenker, and H. Zhang. Core-Stateless Fair
Queueing: Achieving Approximately Fair Bandwidth Allo-
cations in High Speed Networks. In ACM SIGCOMM, 1998.
[24] A. Yaar, A. Perrig, and D. Song. Pi: A Path Identiﬁcation
Mechanism to Defend Against DDoS Attacks. In IEEE Sym-
posium on Security and Privacy, 2003.
[25] A. Yaar, A. Perrig, and D. Song. SIFF: A Stateless Internet
Flow Filter to Mitigate DDoS Flooding Attacks. In IEEE Sym-
posium on Security and Privacy, 2004.
protection to the destination in the form of better attack localiza-
tion, because ﬂoods are intercepted earlier.
Hosts must also be upgraded. We envision this occurring with
proxies at the edges of customer networks in the manner of a NAT
box or ﬁrewall. This provides a simpler option than upgrading indi-
vidual hosts and is possible since legacy applications do not need to
be upgraded. Observe that legacy hosts can communicate with one
another unchanged during this deployment because legacy trafﬁc
passes through capability routers, albeit at low priority. However,
we must discover which hosts are upgraded if we are to use capa-
bilities when possible and fall back to legacy trafﬁc otherwise. We
expect to use DNS to signal which hosts can handle capabilities
in the same manner as other upgrades. Additionally, a capability-
enabled host can try to contact a destination using capabilities di-
rectly. This will either succeed, or an ICMP protocol error will be
returned when the shim capability layer cannot be processed, as
evidence that the host has not been upgraded.
9. CONCLUSION
We have presented and evaluated TVA, a network architecture
that limits denial of service attacks so that two hosts are able to
communicate effectively despite a large number of attackers; we
have argued that existing mechanisms do not meet this goal. Our
design is based on the concept of capabilities that enable destina-
tions to authorize senders, in combination with routers that pref-
erentially forward authorized trafﬁc. Our main contribution is to
ﬂesh out the design of a comprehensive and practical capability
system for the ﬁrst time. This includes protections for the initial
request exchange, consideration of destination policies for autho-
rizing senders, and ways to bound both router computation and
state requirements. Our simulation results show that, with our de-
sign, even substantial (10x) ﬂoods of legacy trafﬁc, request trafﬁc,
and other authorized trafﬁc have little or limited impact on the per-
formance of legitimate users. We have striven to keep our design
practical. We implemented a prototype of our design in the Linux
kernel, and used it to argue that our design will be able to run at gi-
gabit speeds on commodity PCs. We also constrained our design to
be easy to transition into practice. This can be done by placing in-
line packet processing boxes near legacy routers, with incremental
deployment providing incremental gain.
10. ACKNOWLEDGEMENTS
We thank Ratul Mahajan for help with the pushback approach,
Ersin Uzun for pointing out the attack on per-source queuing, and
the anonymous SIGCOMM reviewers for their comments. This
work was supported in part by the NSF (Grant CNS-0430304).
11. REFERENCES
[1] D. Andersen. Mayday: Distributed Filtering for Internet Ser-
vices. In 3rd Usenix USITS, 2003.
[2] T. Anderson, T. Roscoe, and D. Wetherall. Preventing Internet
Denial of Service with Capabilities. In Proc. HotNets-II, Nov.
2003.
[3] K. Argyraki and D. Cheriton. Active Internet Trafﬁc Filter-
ing: Real-Time Response to Denial-of-Service Attacks. In
USENIX 2005, 2005.
[4] DDoS attacks still pose threat to Internet. BizReport, 11/4/03.
[5] Extortion via DDoS on the rise. Network World, 5/16/05.
[6] A. Demers, S. Keshav, and S. Shenker. Analysis and Sim-
ulation of a Fair Queueing Algorithm. In ACM SIGCOMM,
1989.