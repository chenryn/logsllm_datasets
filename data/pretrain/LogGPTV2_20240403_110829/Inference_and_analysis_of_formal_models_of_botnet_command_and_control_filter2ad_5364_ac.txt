o
p
s
e
R
y
r
e
u
Q
p
h
s
r
e
b
m
e
M
L*
Figure 3: Architecture of Our Protocol Inference Engine. Our
inference system is encircled with a dashed line.
4.
INFERENCE OF PROTOCOL MODELS
This section presents our technique for inference of complete
protocol state-machines in the realistic network setting. The high-
level architecture of our implementation is shown in Figure 3. Our
implementation is composed of several components: a bot emula-
tor, a query cache, a membership query predictor, and L∗.
The bot emulator is a script we wrote that receives queries (strings
of symbols from the input alphabet) from L∗ and concretizes them
into valid protocol messages sent to botnet servers. Once the bot
emulator receives a response, it abstracts the response into strings
of symbols from the output alphabet and sends such abstracted
strings to L∗. We describe abstraction and concretization in Sec-
tion 4.1.
We built our bot emulator from scratch, to assure it cannot per-
form any of the malicious activities (spamming and infection) of
the real bot. In addition, we carefully crafted our experiments not
to cause any harm to any party involved (infected users, ISPs, C&C
servers, and botmasters). For example, our bot emulator is careful
not to construct corrupted messages intentionally, minimizing the
impact even on the C&C servers.
The query cache acts as a concentrator of parallel query responses
and caches the results, so that each sequence of messages has to
be sent over the network only once. Through parallelization, we
achieved 4.85X reduction in the time required for the inference us-
ing eight machines, each running one bot emulator. We describe
both parallelization and caching in Section 4.2.
The membership query predictor attempts to predict what is the
most likely response to membership queries. Learning even a state-
machine of a medium size can require a signiﬁcant number of que-
ries (c.f. Section 3.1). As queries can be long strings of input mes-
sages, and getting a response to each message can take a long time
due to network delay (6.8 sec on average in our experiments), ac-
curate prediction of responses is important to infer protocol state-
machines in reasonable amount of time. Erroneous predictions are
guaranteed to be detected (with desired accuracy and conﬁdence)
using sampling queries and ﬁxed by backtracking to the ﬁrst mis-
take made by the predictor. We present our prediction heuristic in
Section 4.3.
In Section 4.4, we explain how we handled the only discovered
source of non-determinism in the MegaD protocol, state-machine
resetting, and generation of sampling queries.
4.1 Message Abstraction and Concretization
L∗ constructs queries over the abstract input alphabet and passes
them to our bot emulator, which concretizes the alphabet sym-
bols into valid network messages and sends them to botnet servers.
When responses are received, our emulator does the opposite — it
abstracts the response messages into the output alphabet and passes
them to L∗. Construction of the input and output alphabets is a par-
tially automatic and partially manual process. We reverse-engineer
the message formats and their semantic content using automatic
protocol reverse engineering [6] and encryption/decryption mod-
ules extracted from the bot binary [5]. Once we learn the message
formats, we perform abstraction manually. The manual abstraction
is a straight-forward process, but requires intelligence in deciding
which message ﬁelds are important. In particular, the most impor-
tant ﬁeld, not surprisingly, turns out to be the message type ﬁeld.
Besides abstraction, another important aspect of automatic pro-
tocol inference is concretization of messages, i.e., generation of
valid network messages.
If messages are invalid or have invalid
session tokens, the server will simply reject them. To generate
valid messages, the bot emulator uses the automatically reverse-
engineered message format grammar, rewrites the message ﬁelds
as needed, and encrypts the messages before transmission. The bot
emulator rewrites the tokens of server-bound messages using to-
kens issued by the server in the same session. If the token has not
been issued, the emulator rewrites tokens with a random value, to
learn how servers handle invalid tokens.
To assure our experiments are reproducible, we include MegaD’s
C&C message format tree in Figure 4 and a list of all abstracted
messages used in this paper in Table 1. MegaD uses a propri-
etary C&C protocol for communication with its master and tem-
plate servers, and a non-standard SMTP protocol for communica-
tion with its SMTP server. To model the C&C protocol messages,
we use three ﬁelds: the MsgType ﬁeld found in all messages, the
SubType ﬁeld in the INIT and GETCMD messages, and the Conﬁg
element found only in the spam template messages. We deﬁne a
unique symbol for each unique {MsgType, SubType, Conﬁg} com-
bination as described in Table 1. To model the bot’s communica-
tion with the SMTP server, we abstract MegaD’s SMTP dialogs at
two different levels of abstraction. When we model the role of the
SMTP server in the overall C&C protocol, we abstract MegaD’s
spam capability test dialog and pre-spam notiﬁcation dialog each
with two symbols, one in either direction (IDs 14 and 15 in upper
half and IDs 12 and 13 in lower half of Table 1 respectively). When
we analyze the details of MegaD’s SMTP protocol implementation,
we abstract each individual SMTP message within a TCP connec-
tion into individual symbols.
4.2 Query Cache
In our implementation, the query cache is just a ﬁle that stores
pairs of input message sequences and the corresponding responses
(i.e., sequences of output messages). The cache acts primarily as a
concentrator of parallel query responses. This architecture (Figure
3) simpliﬁes the implementation of L∗, for only the queries have to
be issued in parallel, but responses can be processed sequentially.
More precisely, the membership query loop starting on Line 4 of
Algorithm 1 and the column extension loop starting on Line 3 of
Algorithm 2 both execute a number of independent membership
queries, which can all be either predicted or run on the network in
parallel. Our implementation of L∗ emits all these queries in paral-
lel. The queries are partitioned among a number of machines (eight,
in our case) and independently run on the network. In addition, the
cache has a more traditional role of caching the responses that have
been tested on the network — such responses can be reused at any
point, because of the determinism assumption (Section 2.3).
4.3 Response Prediction
Studying the membership queries that L∗ makes while learn-
ing protocol models, we came to realize that there is a signiﬁcant
431ID MsgTy
0x00
-
1
0x00
0x03
2
0x05
3
0x06
4
0x09
5
0x16
6
7
0x22
0x23
8
0x25
9
0x09
10
0x1c
11
12
0x1d
13
0x1e
14
15
-
1
0x01
-
-
-
2
3
4
5
6
7
8
9
10
11
12
13
0x04
0x07
0x0a
0x0e
0x15
0x18
0x1c
0x21
0x24
0x1c
-
-
SubTy
0x00
0x01
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
Template
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
None
-
-
-
-
Direct.
Semantic Label
→ MS
INIT
→ MS
GETCMD
→ MS
DLSUCCESS
→ MS
DLERROR
→ MS
DL1
→ MS
DL2
→ MS
HOSTINFO
→ MS
CAP_TESTPASS
→ MS
CAP_TESTFAIL
→ MS
TS_RECVED
→ MS
PONG
TEMPLATE_ACK → TS
GET_TEMPLATE → TS
→ TS
SPAM_STATUS
→ SS
TEST
→ SS
NOTIFY
← MS
INFO
← MS
TCP_CLOSE(-)
← TS
ACK_DLRESULT ← MS
← MS
ACK_DL1
← MS
ACK_DL2
← MS
WAIT2
← MS
GETHOSTINFO
← MS
WAIT1
← TS
TEMPLATE
← MS
TESTSPAMCAP
← MS
DLTEMPLATE
← TS
← SS
TESTPASS
NOTIFY_RECVED ← SS
RENEW RENEW
Table 1: Abstraction of MegaD’s Communication with its Mas-
ter and Template Servers. The upper half of the table shows the
input alphabet (sent by our bot emulator to various servers),
and the lower half the output alphabet (responses sent by
servers to our bot). We use the MsgType, SubType and Tem-
plate conﬁg ﬁelds for abstraction. Messages sent to and re-
ceived from C&C servers are abstracted as input and output
alphabet symbols (the ID column) respectively, where MS is the
Master Server, TS is the Template Server and SS is the SMTP
Server. The no-response message is denoted as TCP_CLOSE(-
). The INIT message is sent to reset each session. The INFO
message is always followed by another message, and that sec-
ond message is used for abstraction. The SMTP messages are
abstracted according to the standard [23].
1
17
2/2
7/1
9/18/1
4/36/19/111/113/115/12
2/24/36/110/112/1113/115/12
amount of redundancy in the
inference process. Namely,
many states have many self-
loops (Deﬁnition 6). The ﬁg-
ure on the left illustrates this
phenomenon on a small piece
of the MegaD state-machine.
Such self-loops increase the
number of membership queries, without helping L∗ to distinguish
states. We believe that there are two major factors contributing to
the abundance of self-loops: (1) Our goal is to learn complete mod-
els, which means we need to determine the response to all input
alphabet symbols (i.e., messages) from every state. Most protocols
use each message for a single, well-deﬁned purpose, which means
that most often sending an unexpected message from some state
causes that message to be ignored, either at that state or in an er-
ror state. (2) We need to abstract conservatively the messages into
the input and output alphabets before the protocol state-machine is
known. The conservative overestimation frequently increases the
Figure 4: MegaD’s C&C Message Format Tree. Message type
ﬁelds used for abstraction are shown in bold. We elide the tails
of messages not relevant to our abstraction process. Abstracted
messages are shown on the right in italics.
redundancy in the model, e.g., increasing the number of self-loops,
which cannot be eliminated before the state-machine is known —
a chicken and egg problem. On the other hand, reducing the size of
the alphabet oversimpliﬁes the inferred state-machine. Thus, it is
important to be conservative in choosing the alphabet and develop
effective techniques for improving the performance of the inference
process.
To understand the intuition behind response prediction, consider
the running example shown in Figure 2a. There are three self-loops,
and we shall focus on the self-loop incident to state 2. Since self-
loops return back to the same state, the response to 2 · 1 · u (with
self-loop) and 2 · u (without self-loop) will be the same for every
input string u. Accordingly, the table entries for 2 · 1 · u (row 5) and
2 · u (row 2) in Table 2b are the same. Recall from Algorithm 1
that the length of membership queries increases with each outer-
for-loop iteration. Thus, the 2 · u query must preceede the 2 · 1 · u
query, and the response to the former can be used to predict the
response to the latter at the end of each outer-for-loop iteration.
We exploit the redundancy with a two-level heuristic. The ﬁrst