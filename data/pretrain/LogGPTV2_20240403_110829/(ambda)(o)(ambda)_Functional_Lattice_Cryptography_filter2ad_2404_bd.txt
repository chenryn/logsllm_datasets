ğ‘— Â¯ğ‘’ğ‘—ğ‘‘ğ‘— where
ğ‘— ğ‘’ğ‘—ğ‘‘ğ‘— where each ğ‘’ğ‘— âˆˆ
Q âˆ© [âˆ’ ğ‘
2, ğ‘
2) is the distinguished representative of Â¯ğ‘’ğ‘—.
218
4. check that â€–ğ‘’â€– â‰¤ ğµ (where recall that â€–ğ‘’â€– := â€–ğœ(ğ‘’)â€–, the length of the canonical
embedding of ğ‘’).
For a discrete instance one does the same, but with ğ¾ replaced by ğ‘…âˆ¨ and Q replaced
by Z. In either case, properly generated Ring-LWE samples for our instantiations will
correctly verify (with high probability) because the original errors ğ‘’ âˆˆ ğ¾ have coefï¬cients
of magnitude smaller than ğ‘/2 with respect to the decoding basis, hence they are correctly
recovered from ğ‘ âˆ’ ğ‘  Â· ğ‘ = ğ‘’ mod ğ‘ğ‘…âˆ¨. Moreover, we show below that they have Euclidean
norms below the error bound ğµ with high probability.
Implementation. Î›âˆ˜ğœ† (and hence the challenges themselves) actually uses the â€œtweakedâ€
form of Ring-LWE as described in subsection 2.2.7, in which ğ‘…âˆ¨ is replaced by ğ‘… by
implicitly multiplying each ğ‘ component, and thereby the secret ğ‘  and each error term ğ‘’,
by the â€œtweakâ€ factor ğ‘¡ (where ğ‘¡ğ‘…âˆ¨ = ğ‘…). Correspondingly, the basis ğ‘¡ Â· âƒ—ğ‘‘ is referred to as
the decoding basis of ğ‘…. Therefore, we use an equivalent veriï¬cation procedure to the one
above, which simply replaces ğ‘…âˆ¨, âƒ—ğ‘‘ with ğ‘…, ğ‘¡ Â· âƒ—ğ‘‘, and the test â€–ğ‘’â€– â‰¤ ğµ with â€–ğ‘” Â· ğ‘’â€– â‰¤ Ë†ğ‘šğµ,
where ğ‘” âˆˆ ğ‘… is the special element such that ğ‘” Â· ğ‘¡ = Ë†ğ‘š. (Recall that Ë†ğ‘š = ğ‘š/2 when ğ‘š is
even, and Ë†ğ‘š = ğ‘š otherwise.)
The Î›âˆ˜ ğœ† framework provides operations for efï¬ciently â€œliftingâ€ elements of ğ¾/ğ‘ğ‘…
or ğ‘…/ğ‘ğ‘… to ğ¾ or ğ‘… (respectively) using the decoding basis of ğ‘…, and for computing
Ë†ğ‘šâˆ’1 Â· â€–ğ‘” Â· ğ‘’â€–2 (see subsection 3.5.1). Thus our veriï¬er actually checks the equivalent
condition Ë†ğ‘šâˆ’1 Â· â€–ğ‘” Â· ğ‘’â€–2 â‰¤ Ë†ğ‘šğµ2. For convenience, we also include the bound Ë†ğ‘šğµ2 with
the challenges, see [CP16a] for details.
Continuous error bound. For continuous Ring-LWE instantiations with spherical Gaus-
sian error ğ·ğ‘Ÿ over ğ¾, we use Lemma 2.1.1 and Corollary 2.1.2 to get rather sharp tail
bounds on the Euclidean norm of the error. In our actual challenge instances, the error
bound we use was typically within a factor of â‰ˆ 1.10 of the largest error in each instance,
so it gives little room for misbehavior relative to the correct error distribution.
219
The bound is obtained as follows. For an appropriate small ğœ€ > 0 we compute the
âˆš
minimal ğ‘ > 1/
2ğœ‹ (up to â‰ˆ 10âˆ’4 precision) such that
ğœ‹ğ‘2 âˆ’ ln ğ‘ â‰¥ 1
ğ‘›
ln(1/ğœ€) +
1
2
ln(2ğœ‹ğ‘’).
Then by Corollary 2.1.2, we have Prğ‘¥âˆ¼ğ·ğ‘Ÿ[â€–ğ‘¥â€– > ğµ]  1. (Note that the proof never
222
uses the fact that â„ divides ğ‘ğ‘….) For simplicity, in our Grande instantiations we always use
ğ‘¡ = 2 and hence ğ‘Ÿ =âˆšï¸€8/(ğœ‹ğ‘’) â‰ˆ 0.968. For dimensions (say) ğ‘› > 256 one could take
Lemma 7.3.1. For any ğ‘› â‰¥ 17, ğ‘¡ > 1, and ğ‘Ÿ â‰¥ ğ‘¡âˆšï¸€2/(ğœ‹ğ‘’) â‰ˆ 0.484ğ‘¡, the time/advantage
ğ‘¡ = 2256/ğ‘› to obtain an even smaller ğ‘Ÿ.
ratio of the homomorphism attack (for any choice of the ideal â„) is at least ğ‘¡ğ‘›.
Proof. Let ğ‘  = N(â„)1/ğ‘›, and note that the running time of the attack is at least N(â„) = ğ‘ ğ‘›,
so we may assume without loss of generality that ğ‘  â‰¤ ğ‘¡.
The dual ideal of â„ğ‘…âˆ¨ is (â„ğ‘…âˆ¨)âˆ’1 Â· ğ‘…âˆ¨ = â„âˆ’1, which has norm N(â„)âˆ’1, so by
âˆš
2ğœ‹ğ‘’Â·ğ‘¥Â·exp(ğœ‹ğ‘¥2)
Lemma 2.2.1 its minimum distance is ğœ†1(â„âˆ’1) â‰¥ âˆš
ğ‘›/ğ‘ . Letting ğ‘“ (ğ‘¥) =
be as in Equation (2.1.1), deï¬ne
ğ‘Ÿğœ†1(â„âˆ’1)âˆš
ğ‘›
â‰¥ ğ‘Ÿ
ğ‘ 
â‰¥ ğ‘Ÿ
ğ‘¡
ğ‘ :=
â‰¥âˆšï¸€2/(ğœ‹ğ‘’) > 1/
âˆš
2ğœ‹,
ğ¶ := ğ‘“ (ğ‘) â‰¤ 2 exp(âˆ’2/ğ‘’)  1/
2ğœ‹,
ğ‘ /ğ¶ = ğ‘ /ğ‘“ (ğ‘) â‰¥ ğ‘ /ğ‘“ (ğ‘Ÿ/ğ‘ ) =
âˆš
2ğœ‹ğ‘’ Â· (ğ‘Ÿ/ğ‘ )2 Â· exp(âˆ’ğœ‹(ğ‘Ÿ/ğ‘ )2)
ğ‘Ÿ
.
A straightforward calculation shows that the denominator (as a function of ğ‘ ) has a global
âˆš
maximum when ğ‘Ÿ/ğ‘  = 1/
ğœ‹, so as desired, ğ‘ /ğ¶ â‰¥ ğ‘Ÿâˆšï¸€ğœ‹ğ‘’/2 â‰¥ ğ‘¡.
223
7.3.2 Modulus
For a given Gaussian error parameter ğ‘Ÿ, we choose moduli ğ‘ to reï¬‚ect a typical Ring-
LWE public-key encryption or key-exchange application following the basic template
from [LPR13b; Pei14]. Essentially, this means that ğ‘ must be large enough to accomodate the
ultimate error term, which is a combination of the original errors, without any â€œwraparound.â€
A bit more precisely, we need that with sufï¬ciently high probability, the ultimate error has
coefï¬cients (with respect to an appropriate choice of basis) in the interval (âˆ’ ğ‘
4). The
precise meaning of â€œhigh probabilityâ€ depends on the low-level details of the application.
4, ğ‘
For example, wraparound of a few coefï¬cients might be acceptable if error-correcting codes
are used, or a ï¬nal key-conï¬rmation step may handle the rare case when wraparound does
occur.
The Ring-LWE â€œtoolkitâ€ [LPR13a] provides general techniques and reasonably sharp
concentration bounds for analyzing the coefï¬cients of sums and products of (discretized)
error terms in arbitrary cyclotomics (see, e.g., [LPR13a, Lemma 6.6]). However, their
generality makes them a bit pessimistic, so they do not capture the strongest possible
concentration properties for concrete cases of interest.
In this work we take a combined empirical and theoretical approach to more tightly
bound the ultimate error in encryption/key-exchange applications, and thereby obtain smaller
values of the modulus and larger error rates. Our empirical approach is as follows:
1. We simulate thousands of ultimate error terms ğ¸ := Ë†ğ‘š(ğ‘’ Â· ğ‘’â€² + ğ‘“ Â· ğ‘“â€²) âˆˆ ğ‘…âˆ¨, where
ğ‘’, ğ‘’â€², ğ‘“, ğ‘“â€² âˆˆ ğ‘…âˆ¨ are independent samples from ğ·ğ‘Ÿ, discretized to ğ‘…âˆ¨ using the
decoding basis.11
2. We compute the largest magnitude ğµ among all the coefï¬cients of all the ğ¸s (again
with respect to the decoding basis), and use 4ğµ as a heuristic â€œvery high probabilityâ€
bound on the coefï¬cients.
11Depending on the primes dividing the cyclotomic index ğ‘š, replacing the ^ğ‘š factor by ğ‘¡ in the expression
for ğ¸ can sometimes yield smaller coefï¬cients. We use the best of the two choices in our simulation.
224
3. Using 4ğµ as a lower bound on ğ‘/4, we choose moduli ğ‘ of different arithmetic forms
(e.g., completely split, power of two, ramiï¬ed) that all conform to this bound.
The theoretical (though heuristic) basis for this approach is as follows: in the canonical
embedding, the coordinates of ğ·ğ‘Ÿ are i.i.d. Gaussians over C (up to conjugate symmetry),
and the same nearly holds for the discretization to ğ‘…âˆ¨ when ğ·ğ‘Ÿ is â€œwell-spreadâ€ relative
to ğ‘…âˆ¨ (as it is in our instantiations). Because multiplication is coordinate-wise in the
canonical embedding, the products ğ‘’ Â· ğ‘’â€², ğ‘“ Â· ğ‘“â€² have nearly i.i.d. subexponential coordinates.
(The multiplication by Ë†ğ‘š simply scales them all by the same factor.) Finally, each coefï¬cient
of ğ¸ with respect to the decoding basis is by deï¬nition the inner product of ğœ(ğ¸) with
a vector consisting of various roots of unity. Bernsteinâ€™s inequality says that such inner
products have subgaussian exp(âˆ’Î˜(ğ‘˜2)) tail probabilities in the â€œnear zone,â€ which in our
âˆš
setting goes all the way out to ğ‘˜ = ğ‘‚(
ğ‘›) standard deviations. In the â€œfar zoneâ€ beyond
that, the tails are still subexponential exp(âˆ’Î˜(ğ‘˜)).
Because the near zone is so wide, the largest coefï¬cient among the tens or hundreds of
thousands in our simulation should be not much smaller than a true high-probability bound.