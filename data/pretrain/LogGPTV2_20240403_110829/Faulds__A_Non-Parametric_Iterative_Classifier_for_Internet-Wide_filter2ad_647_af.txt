### 7.3 User Distortion
In the computation of (29), we obtain \( E[\phi_v^\infty] = 0.81 \), indicating that the average probability of encountering a non-default value is 19%. Faulds generated 420 × 6 = 2,520 distributions of user features, from which we derived our results.

### 7.4 Classification Results
We define Faulds as successful for sample \( j \) if the denominator of (1) is non-zero, i.e., \( p(x_j | \theta_t, \alpha_t) > 0 \). This implies that at least one operating system (OS) matches \( x_j \) with a non-zero probability. Using the Plata database, Table 12 shows the classification results for Faulds at iteration 1 (left) and iteration 100 (right).

#### Table 12: Faulds Classification at Iteration 1 (left) and 100 (right)
| OS                                      | \(\alpha_1\) | Count            | \(\alpha_{100}\) | Count            | Change   |
|-----------------------------------------|--------------|------------------|------------------|------------------|----------|
| Ubuntu / Redhat / CentOS                | 0.224        | 14,098,093       | 0.334            | 21,361,956       | 0.52     |
| Ubuntu / SUSE / CentOS                  | 0.111        | 8,896,622        | -                | -                | -        |
| Embedded Linux                          | 0.082        | 6,326,349        | 0.103            | 6,467,303        | 0.02     |
| Windows 7 / 2008 / 2012                 | 0.047        | 2,942,254        | 0.056            | 3,669,372        | 0.25     |
| Ubuntu / Redhat / SUSE                  | 0.037        | 2,408,386        | 0.031            | 2,001,329        | -0.17    |
| Schneider / APC Embedded                | 0.022        | 1,587,396        | 0.055            | 3,632,638        | 1.29     |
| Windows XP / 2003                       | 0.021        | 1,314,967        | 0.018            | 1,248,619        | -0.05    |
| Redhat / CentOS / SUSE                  | 0.018        | 1,254,797        | 0.016            | 1,046,567        | -0.17    |
| Dell Laser / Xerox WorkCenters          | -            | -                | 0.015            | 976,717          | 0.25     |
| Windows 2008 R2 / 2012                  | 0.015        | 1,044,028        | 0.014            | 837,466          | -0.08    |
| Cisco Embedded                          | -            | -                | 0.013            | 824,039          | 2.29     |

The left side of Table 12 shows the top ten OSes after one iteration of Faulds. The Plata database was auto-generated from a pool of devices found in a university network. Although this process produced only a high-level description of each OS, additional manual effort can provide more specific kernel versions and physical device information. This issue is orthogonal to the paper's topic since Faulds operates on TCP/IP signatures, and its accuracy does not depend on the name associated with each fingerprint \( x_i \).

The dominance of Linux and embedded devices in Table 12 (left) aligns with previous studies [24], [41], [42]. However, the relative change in classification as Faulds progresses through iterations is more interesting. Table 12 (right) shows the \(\alpha\) vector after 100 steps. The top Linux signature gains 52%, Windows 7 in third place increases by 25%, and two other Linux stacks drop 17% each. Further down the list, significant movement is observed, with certain embedded systems, such as Schneider APC, Dell printers, and Cisco, increasing their membership by 25-229%.

### Table 13: Types of Devices Running Webservers
| Device Type                            | Count           | Fraction  |
|----------------------------------------|-----------------|-----------|
| General purpose                        | 42,277,294      | 67%       |
| Switch/router/gateway/network controller| 8,854,290       | 14%       |
| No label in database                   | 7,038,785       | 11%       |
| Printers                               | 2,813,292       | 4.5%      |
| RAID controller/NAS                    | 1,348,895       | 2.1%      |
| Video conferencing/telepresence        | 603,035         | 1.0%      |
| Cyberphysical systems                  | 91,033          | 0.14%     |
| IP phones                              | 61,400          | 0.10%     |

Table 13 categorizes all classified hosts into eight categories. The top two signatures are desktop/server OSes and various stacks from network-device manufacturers (e.g., switches and routers). In third place, there are 7M hosts with no label, meaning Faulds finds a matching signature for each, but Plata does not know what these devices are. The bottom half of the table, with a substantial count of cyber-physical systems and office equipment, is more concerning. These devices often run on default manufacturer passwords and allow reconfiguration using a built-in webserver.

### Table 14: Unprotected Industrial and Enterprise Devices
| Device                                    | Type              | Count     |
|-------------------------------------------|-------------------|-----------|
| Polycom HDX 8000 HD                      | IP Phone          | 266,565   |
| Hickman ITV 450D                         | Telepresence      | 67,091    |
| Cisco Unified IP Phone 7900 Series        | IP Phone          | 27,151    |
| AVTech RoomAlert/Rockwell Automation     | Cyberphysical     | 21,756    |
| Loytec L-DALI Lighting Control Systems    | Cyberphysical     | 20,517    |
| Codian Telepresence MCU                  | Telepresence      | 20,036    |
| Polycom RealPresence Server 4000         | Telepresence      | 18,977    |
| AdTran IP Phone Manager                  | IP Phone          | 11,909    |
| HWg-STE: Ethernet thermometer            | Cyberphysical     | 11,826    |
| D-Link DCS Series Internet Camera        | Telepresence      | 9,279     |

Table 14 lists the top-ten signatures from these categories, including camera systems, building lighting controllers, and temperature monitors. These devices present high security risks because malicious actors may use them to gain access to workplace audio/video recordings, printed documents, and critical infrastructure settings (e.g., cooling in data centers).

### Table 15: OSes with Expired Support Life Cycles
| OS                                      | Count             | Released  |
|-----------------------------------------|-------------------|-----------|
| Windows 2000 / XP / 2003                | 1,512,725         | 2000/2001/2003 |
| FreeBSD 7.3 / 8.0                       | 433,978           | 2010/2009 |
| Windows Server 2003 SP1 SP2             | 195,169           | 2005/2007 |
| Windows Server 2000 SP4/XP SP3          | 146,421           | 2003/2008 |
| FreeBSD 6.4                             | 71,190            | 2008      |
| Solaris 9 / Solaris 10                   | 78,269            | 2003/2005 |
| Mac OS X 10.4                           | 36,834            | 2005      |
| Windows 2000/XP SP1                     | 9,623             | 2001/2002 |
| Novell Netware OES 2 SP1                | 1,108             | 2005      |

With recent leaks of NSA exploits and the widespread infection by ransomware like WannaCry [21], [31], outdated operating systems (e.g., Windows XP/Server 2003) have gained renewed attention. Table 15 shows several signatures that have reached the end of support and are no longer being patched for new vulnerabilities. We find over 1.8M old Windows hosts still visible on the public Internet, 500K FreeBSD, and 78K Solaris. Faulds not only allows for timely measurement of such devices but also paves the way for scalable, low-overhead Internet characterization, robust device identification, and better modeling of distortion \(\theta\) experienced by numerous hardware artifacts on the Internet.

### 8. Conclusion
In this work, we developed novel theory and algorithms for improving OS-classification accuracy in single-probe fingerprinting, measuring one-way Internet path properties, and extracting latent distributions of feature distortion. Simulations demonstrated exceptional robustness of our EM techniques against various types of noise. When applied to Internet scans, this methodology can be used to detect vulnerable devices, estimate stack popularity, network delays, packet loss, and header-tuning probabilities.

### References
[1] H. Abdelnur, R. State, and O. Festor, “Advanced Network Fingerprinting,” in Proc. RAID, Sep. 2008, pp. 372–389.
[2] Apple Support, “OS X Yosemite: Prevent others from discovering your Mac.” [Online]. Available: https://support.apple.com/kb/PH18642?locale=en_US.
[3] O. Arkin, “A Remote Active OS Fingerprinting Tool using ICMP,” USENIX login, vol. 27, no. 2, pp. 14–19, Apr. 2002.
[4] P. Auffret, “SinFP, Unification of Active and Passive Operating System Fingerprinting,” Journal in Computer Virology, vol. 6, no. 3, pp. 197–205, Nov. 2010.
[5] T. Beardsley, “Snacktime: A Perl Solution for Remote OS Fingerprinting,” Jun. 2003. [Online]. Available: http://www.packetfu.com/wp/snacktime.html.
[6] R. Beverly, “A Robust Classifier for Passive TCP/IP Fingerprinting,” in Proc. PAM, Apr. 2004, pp. 158–167.
[7] R. Beverly and A. Berger, “Server Siblings: Identifying Shared IPv4/IPv6 Infrastructure via Active Fingerprinting,” in Proc. PAM, Mar. 2015, pp. 149–161.
[8] Y.-C. Chen, Y. Liao, M. Baldi, S.-J. Lee, and L. Qiu, “OS Fingerprinting and Tethering Detection in Mobile Networks,” in Proc. ACM IMC, Nov. 2014, pp. 173–180.
[9] H. K. J. Chu, “Tuning TCP Parameters for the 21st Century,” Jul. 2009. [Online]. Available: http://www.ietf.org/proceedings/75/slides/tcpm-1.pdf.
[10] A. Crenshaw, “OSfuscate,” 2008. [Online]. Available: http://www.irongeek.com/i.php?page=security/code.
[11] A. Dempster, N. Laird, and D. Rubin, “Maximum Likelihood from Incomplete Data via the EM Algorithm,” Journal of the Royal Statistical Society, vol. 39, no. 1, pp. 1–38, 1977.
[12] Z. Durumeric, D. Adrian, A. Mirian, M. Bailey, and J. A. Halderman, “A Search Engine Backed by Internet-Wide Scanning,” in Proc. ACM CCS, Oct. 2015, pp. 542–553.
[13] Z. Durumeric, E. Wustrow, and J. Halderman, “ZMap: Fast Internet-wide scanning and its Security Applications,” in Proc. USENIX Security, Aug. 2013, pp. 605–620.
[14] R. Ensafi, D. Fifield, P. Winter, N. Feamster, N. Weaver, and V. Paxson, “Examining How the Great Firewall Discovers Hidden Circumvention Servers,” in Proc. ACM IMC, Oct. 2015, pp. 445–458.
[15] X. Feng, Q. Li, H. Wang, and L. Sun, “Characterizing Industrial Control System Devices on the Internet,” in Proc. IEEE ICNP, Nov. 2016, pp. 1–10.
[16] S. Guoqiang and D. Lee, “Network Protocol System Fingerprinting: A Formal Approach,” in Proc. IEEE INFOCOM, Apr. 2006, pp. 1–12.
[17] H. O. Hartley, “Maximum Likelihood Estimation from Incomplete Data,” Biometrics, vol. 14, no. 2, pp. 174–194, 1958.
[18] J. Heidemann, Y. Pradkin, R. Govindan, C. Papadopoulos, G. Bartlett, and J. Bannister, “Census and Survey of the Visible Internet,” in Proc. ACM IMC, Oct. 2008, pp. 169–182.
[19] Kaspersky Labs, “Targeted Cyberattacks Logbook.” [Online]. Available: https://apt.securelist.com.
[20] M. Kearns, Y. Mansour, and A. Ng, “An Information-Theoretic Analysis of Hard and Soft Assignment Methods for Clustering,” in Proc. Uncertainty in Artificial Intelligence, Aug. 1997, pp. 282–293.
[21] Z. Kleinman, “Cyber-attack: Is my computer at risk?” BBC News, May 2017. [Online]. Available: http://www.bbc.com/news/technology-39896393.
[22] T. Kohno, A. Broido, and K. C. Claffy, “Remote Physical Device Fingerprinting,” IEEE Transactions on Dependable and Secure Computing, vol. 2, no. 2, pp. 93–108, May 2005.
[23] E. Kollmann, “Chatter on the Wire: A Look at DHCP Traffic.” [Online]. Available: http://myweb.cableone.net/xnih/download/chatter-dhcp.pdf.
[24] D. Leonard and D. Loguinov, “Demystifying Service Discovery: Implementing an Internet-Wide Scanner,” in Proc. ACM IMC, Nov. 2010, pp. 109–122.
[25] Z. Li, A. Goyal, Y. Chen, and V. Paxson, “Automating Analysis of Large-Scale Botnet Probing Events,” in Proc. ACM AsiaCCS, Mar. 2009, pp. 11–22.
[26] M. Luckie, R. Beverly, T. Wu, and M. Allman, “Resilience of Deployed TCP to Blind Attacks,” in Proc. ACM IMC, Oct. 2015, pp. 13–26.
[27] J. Matherly, “Shodan Search Engine.” [Online]. Available: https://shodan.io.
[28] T. Matsunaka, A. Yamada, and A. Kubota, “Passive OS Fingerprinting by DNS Traffic Analysis,” in Proc. IEEE AINA, Mar. 2013, pp. 243–250.
[29] C. McNab, Network Security Assessment: Know Your Network. O’Reilly Media, Inc., 2007.
[30] J. Medeiros, A. Brito, and P. Pires, “An Effective TCP/IP Fingerprinting Technique Based on Strange Attractors Classification,” in Proc. DPM/SETOP, Sep. 2009, pp. 208–221.
[31] Microsoft Technet, “Microsoft Security Bulletin MS17-010 – Critical.” [Online]. Available: https://technet.microsoft.com/en-us/library/security/ms17-010.aspx.
[32] Microsoft Technet, “Stealth Mode in Windows Firewall with Advanced Security.” [Online]. Available: https://technet.microsoft.com/en-us/library/dd448557(WS.10).
[33] A. Mirian, Z. Ma, D. Adrian, M. Tischer, T. Chuenchujitasphon, T. Yardley, R. Berthier, J. Mason, Z. Durumeric, and J. A. Halderman, “An Internet-Wide View of ICS Devices,” in Proc. IEEE PST, Dec. 2016, pp. 96–103.
[34] NetApplications, “Market Share Statistics for Internet Technologies.” [Online]. Available: http://netmarketshare.com/.
[35] Netcraft Web Server Survey. [Online]. Available: http://news.netcraft.com/.
[36] Nmap. [Online]. Available: http://nmap.org/.
[37] G. Prigent, F. Vichot, and F. Harrouet, “IpMorph: Fingerprinting Spoofing Unification,” Journal in Computer Virology, vol. 6, no. 4, pp. 329–342, Nov. 2010.
[38] A. Quach, Z. Wang, and Z. Qian, “Investigation of the 2016 Linux TCP Stack Vulnerability at Scale,” in Proc. ACM SIGMETRICS, Jun. 2017, pp. 3:1–3:19.
[39] G. Roualland and J.-M. Saffroy, “IP Personality.” [Online]. Available: http://ippersonality.sourceforge.net/.
[40] S. Shah, “An Introduction to HTTP Fingerprinting,” May 2004. [Online]. Available: http://net-square.com/httprint_paper.html.
[41] Z. Shamsi and D. Loguinov, “Unsupervised Clustering Under Temporal Feature Volatility in Network Stack Fingerprinting,” in Proc. ACM SIGMETRICS, Jun. 2016, pp. 127–138.
[42] Z. Shamsi, A. Nandwani, D. Leonard, and D. Loguinov, “Hershel: Single-Packet OS Fingerprinting,” in Proc. ACM SIGMETRICS, Jun. 2014, pp. 195–206.
[43] Z. Shamsi, D. B. Cline, and D. Loguinov, “Faulds: A Non-Parametric Iterative Classifier for Internet-Wide OS Fingerprinting,” Texas A&M University, Tech. Rep. 2017-8-2, Aug. 2017. [Online]. Available: http://irl.cs.tamu.edu/publications/.
[44] U. Shankar and V. Paxson, “Active Mapping: Resisting NIDS Evasion Without Altering Traffic,” in Proc. IEEE S&P, May 2003, pp. 44–61.
[45] B. Skaggs, B. Blackburn, G. Manes, and S. Shenoi, “Network Vulnerability Analysis,” in Proc. IEEE MWSCAS, Aug. 2002, pp. 493–495.
[46] M. Smart, G. R. Malan, and F. Jahanian, “Defeating TCP/IP Stack Fingerprinting,” in Proc. USENIX Security, Jun. 2000, pp. 229–240.
[47] A. K. Sood and R. J. Enbody, “Targeted Cyberattacks: A Superset of Advanced Persistent Threats,” IEEE S&P, vol. 11, no. 1, pp. 54–61, Jan. 2013.
[48] G. Taleck, “Ambiguity Resolution via Passive OS Fingerprinting,” in Proc. RAID, Sep. 2003, pp. 192–206.
[49] G. Taleck, “SYNSCAN: Towards Complete TCP/IP Fingerprinting,” CanSecWest, Apr. 2004.
[50] F. Veysset, O. Courtay, O. Heen, and I. R. Team, “New Tool and Technique for Remote Operating System Fingerprinting,” Apr. 2002. [Online]. Available: http://www.ouah.org/ring-full-paper.pdf.
[51] K. Wang, “Frustrating OS Fingerprinting with Morph,” 2004. [Online]. Available: http://hackerpoetry.com/images/defcon-12/dc-12-presentations/Wang/dc-12-wang.pdf.
[52] F. V. Yarochkin, O. Arkin, M. Kydyraliev, S.-Y. Dai, Y. Huang, and S.-Y. Kuo, “Xprobe2++: Low Volume Remote Network Information Gathering Tool,” in Proc. IEEE/IFIP DSN, Jun. 2009, pp. 205–210.
[53] M. Zalewski, “Strange Attractors and TCP/IP Sequence Number Analysis,” Apr. 2001. [Online]. Available: http://lcamtuf.coredump.cx/newtcp/.
[54] M. Zalewski, “p0f v3: Passive Fingerprinter,” 2012. [Online]. Available: http://lcamtuf.coredump.cx/p0f3.

Session D5: Network Security, CCS'17, October 30-November 3, 2017, Dallas, TX, USA