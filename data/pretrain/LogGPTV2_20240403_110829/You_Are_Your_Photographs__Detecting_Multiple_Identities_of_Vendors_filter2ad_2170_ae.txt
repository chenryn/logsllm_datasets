Adversarial Countermoves.
method is not designed for adversarial settings. If a vendor wants
to prevent her multiple accounts from being linked together, tech-
nically there are potential countermoves that the vendor can make.
Before we discuss the adversarial countermoves, we want to stress
that there are no real motivations for vendors to hide their multiple
accounts in different markets. The only case where vendors may be
motivated to hide their Sybil identifies is when they create Sybils in
the same market. Intra-market Sybils are prohibited by the market
administrators who actively seek to detect Sybil accounts.
To examine the impact of potential countermoves from vendors,
we consider a number of image transformations. More specifically,
to avoid detection, a vendor may slightly transform the photos (to
hide personal styles) before posting them via the Sybil account.
Here, we consider 3 simple transformations including blurring the
image, reducing the contrast, and adding random noises. For simplic-
ity, we apply Gaussian smoothing with σ = 2 for image blurring,
we adjust the image contrasts to 50% of the original ones, and we
add noise by randomly picking 5% of the pixels and changing them
to black or white. Figure 10 shows an example.
We run a quick test on the impact of the above adversarial coun-
termoves using the Agora dataset with Tr = 20. We follow the
same ground-truth evaluation workflow as §4.2, but apply image
 0 0.2 0.4 0.6 0.8 1-4-3-2-1 0 1 2 3 4CDFlog(PA/PB)Evolution-SilkRoad2Agora-SilkRoad2Agora-Evolution 0 0.2 0.4 0.6 0.8 1-4-3-2-1 0 1 2 3 4CDFlog(PA/PB)SilkRoad2EvolutionAgora 0 0.2 0.4 0.6 0.8 1-4-3-2-1 0 1 2 3 4CDFlog(PA/PB)EvolutionSilkRoad2AgoraDuplicated
Images
Yes
No
Model
ResNet
VGG
ResNet
VGG
Original
0.979
0.977
0.883
0.832
Blur
0.960
0.967
0.715
0.752
Contrast Noise
0.485
0.771
0.285
0.394
0.969
0.979
0.803
0.818
Table 7: Impact of adversarial image transformations to the
classifier accuracy.
Figure 10: Illustrating the image transformations.
transformation to the testing images. The results are shown in
Table 7. We observe that blurring and contrast adjustment only
slightly decrease the matching accuracy. However, adding random
noise points can greatly reduce the accuracy. With just 5% noise
pixels, the products are still clearly recognizable in the images.
Beyond adding random noises, vendors can also apply stronger
adversarial noises that are optimized against the DNN based classi-
fier [8, 8, 18, 31, 37, 41, 50, 53]. At the same time, defenders (in this
case, the market administrators) can adopt defense techniques to
“de-noise” the images to reduce the adversarial effect [3, 19, 36, 59]
or enhance the robustness of the image classifier [18, 31, 44, 62].
Another way of defense is to set a smaller similarity threshold to
include more candidate pairs for investigation.
In addition to adversarial image transformation, vendors can
also sell different products using different accounts or change their
photo style. Again, this type of adversarial behavior is only relevant
to certain intra-market Sybils, but not the vast majority of the inter-
market Sybil accounts. Our future work will measure the adversarial
adaptations of vendors in the wild.
Our study has a few limitations. First, our study
Limitations.
only covers three darknet markets, and there are many other mar-
kets out there [5]. Our future work will explore to apply our tool to
the more recent and a broader range of darknet markets. Second,
although no evidence suggests that Sybil vendors are attempting
to avoid detection by changing their photos, adversarial machine
learning should be further explored to improve the robustness of the
analysis. Third, during our manual inspection, we find additional
features that can be used to match two accounts (e.g., username,
image trademarks, shipping information), which can be integrated
to build a more powerful analysis tool.
9 RELATED WORK
Researchers have studied
Cybercrimes and Blackmarkets.
the darknet markets [11, 48] and underground forum [2, 23, 35] from
various aspects. Some researchers use the underground forums to
study specific cybercriminal activities such as pharmaceutical affili-
ate programs [35], large spam operations [49], trading stolen credit
cards [20] and search engine optimization services [14]. Other re-
searchers study the products sold on the blackmarkets [23], build
automated tools to identify forum posts related transactions [42],
and analyze the network footprints of underground vendors [51].
Recent works also have looked into the “social networks” and the
communities among cybercriminals [15, 38, 60]. In this paper, we de-
velop a novel system to link Sybil identities through image analysis
to support more efficient investigations of cybercrimes.
Stylometry analysis has been a useful
Stylometry Analysis.
tool to attribute authorship of anonymous online posts [13, 42].
The most related work to us is to use stylometry analysis to link
Sybil accounts in underground forums [1, 6, 17, 22]. In this paper,
we show that stylometry analysis is less effective to model darknet
market vendors due to the short and repetitive text. In comparison,
our image-based approach achieved more promising results.
Deep neural
Image Analysis using Deep Neural Networks.
networks have contributed to the fast development of computer
vision in recent years. Deep learning algorithms [30, 45] now reach
the human-level accuracy in recognizing objects from images. Deep
learning algorithms can take advantage of the massive training data
to build highly accurate models. For many deep learning applica-
tions, transfer learning can be applied when the application-specific
training dataset is insufficiently large [40, 46, 54].
A related body of work is photographer identification based on
photos [9, 10, 26, 34, 43, 55, 56] or egocentric videos [24]. However,
recent results show that lower-level features are not as effective as
high-level features in photograph authorship attribution tasks [56].
Existing high-level feature based methods focus on several famous
photographers who already have strong personal styles [56]. In
contrast, we model a much larger population of darknet vendors
who are typically not professional photographers.
10 CONCLUSION
In this paper, we demonstrate the feasibility of fingerprinting dark-
net vendors through their posted photographs. By evaluating the
proposed system on real-world datasets, we demonstrate its advan-
tage over existing stylometry methods in terms of both the accuracy
and the coverage of fingerprintable vendors. In addition, we use
the system to detect previously unknown Sybil account pairs in the
wild, both within the same markets and across different markets.
As a future work, we will continue to monitor the darknet markets
and measure the potential adversarial evasions from vendors.
ACKNOWLEDGMENTS
This project was supported by NSF grant CNS-1717028. Any opin-
ions, conclusions or recommendations expressed in this material
do not necessarily reflect the views of the funding agency.
REFERENCES
[1] Sadia Afroz, Aylin Caliskan-Islam, Ariel Stolerman, Rachel Greenstadt, and Da-
mon McCoy. 2014. Doppelganger Finder: Taking Stylometry to the Underground.
In Proc. of IEEE SP’14.
[2] Sadia Afroz, Vaibhav Garg, Damon McCoy, and Rachel Greenstadt. 2013. Honor
among thieves: A common’s analysis of cybercrime economies. In Proc. of
eCrime’13.
[3] Arjun Nitin Bhagoji, Daniel Cullina, and Prateek Mittal. 2017. Dimensionality
reduction as a defense against evasion attacks on machine learning classifiers.
arXiv preprint arXiv:1704.02654 (2017).
[4] Danny Bradbury. 2014. Silk Road 2 Loses Over $2.6 Million in Bitcoins in Alleged
Hack. (2014). https://www.coindesk.com/silk-road-2-loses-bitcoins-hack
[5] Gwern Branwen, Nicolas Christin, David DÃľcary-HÃľtu, Rasmus Munksgaard
Andersen, StExo, El Presidente, Anonymous, Daryl Lau, Sohhlz, Delyan Kratunov,
(a) Original(b) Blur(c) Contrast(d) NoiseVince Cakic, Van Buskirk, Whom, Michael McKenna, and Sigi Goode. 2015. Dark
Net Market archives, 2011-2015. (2015). https://www.gwern.net/DNM-archives.
[6] Aylin Caliskan-Islam, Richard Harang, Andrew Liu, Arvind Narayanan, Clare
Voss, Fabian Yamaguchi, and Rachel Greenstadt. 2015. De-anonymizing Program-
mers via Code Stylometry. In Proc. of USENIX Security’15.
[7] Alfredo Canziani, Adam Paszke, and Eugenio Culurciello. 2016. An analy-
sis of deep neural network models for practical applications. arXiv preprint
arXiv:1605.07678 (2016).
[8] Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of
neural networks. In Proc. of IEEE SP’17.
[9] M. Chen, J. Fridrich, M. Goljan, and J. Lukas. 2008. Determining Image Origin
and Integrity Using Sensor Noise. IEEE Transactions on Information Forensics and
Security 3, 1 (2008), 74–90.
[10] Kai San Choi, Edmund Y. Lam, and Kenneth K. Y. Wong. 2006. Source cam-
era identification using footprints from lens aberration. In Proc. of SPIE Digital
Photography II.
[11] Nicolas Christin. 2013. Traveling the Silk Road: A Measurement Analysis of a
Large Anonymous Online Marketplace. In Proc. of WWW’13.
[12] Roger Dingledine, Nick Mathewson, and Paul Syverson. 2004. Tor: The Second-
generation Onion Router. In Proc. of USENIX Security’04.
[13] Greg Durrett, Jonathan K. Kummerfeld, Taylor Berg-Kirkpatrick, Rebecca S.
Portnoff, Sadia Afroz, Damon McCoy, Kirill Levchenko, and Vern Paxson. 2017.
Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-
grained Domain Adaptation. In Proc. of EMNLP’17.
[14] S. Farooqi, G. Jourjon, M. Ikram, M. A. Kaafar, E. De Cristofaro, Z. Shafiq, A.
Friedman, and F. Zaffar. 2017. Characterizing key stakeholders in an online
black-hat marketplace. In Proc. of eCrime’17.
[15] Vaibhav Garg, Sadia Afroz, Rebekah Overdorf, and Rachel Greenstadt. 2015.
Computer-supported cooperative crime. In Proc. of FC’15.
[16] Stamatios Georgoulis, Konstantinos Rematas, Tobias Ritschel, Mario Fritz, Tinne
Tuytelaars, and Luc Van Gool. 2017. What Is Around The Camera?. In Proc. of
ICCV’17.
[17] Oana Goga, Howard Lei, Sree Hari Krishnan Parthasarathi, Gerald Friedland,
Robin Sommer, and Renata Teixeira. 2013. Exploiting Innocuous Activity for
Correlating Users Across Sites. In Proc. of WWW’13.
[18] Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and
harnessing adversarial examples. In Proc. of ICLR’15.
[19] Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. 2017.
Countering Adversarial Images using Input Transformations. arXiv preprint
arXiv:1711.00117 (2017).
[20] Andreas Haslebacher, Jeremiah Onaolapo, and Gianluca Stringhini. 2016. All
Your Cards Are Belong To Us: Understanding Online Carding Forums. In Proc. of
eCrime’17.
[21] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proc. of CVPR’16.
[22] Thanh Nghia Ho and Wee Keong Ng. 2016. Application of Stylometry to DarkWeb
Forum User Identification. In Proc. of ICICS’16.
[23] Thomas J Holt and Eric Lampke. 2010. Exploring stolen data markets online:
products and market forces. Criminal Justice Studies 23, 1 (2010), 33–50.
[24] Yedid Hoshen and Shmuel Peleg. 2016. An Egocentric Look at Video Photographer
Identity. In Proc. of CVPR’16.
[25] Gao Huang, Zhuang Liu, Kilian Q Weinberger, and Laurens van der Maaten. 2016.
Densely connected convolutional networks. arXiv preprint arXiv:1608.06993
(2016).
[26] C. R. Johnson, E. Hendriks, I. J. Berezhnoy, E. Brevdo, S. M. Hughes, I. Daubechies,
J. Li, E. Postma, and J. Z. Wang. 2008. Image processing for artist identification.
IEEE Signal Processing Magazine 25, 4 (2008), 37–48.
[27] Rasoul Kaljahi, Jennifer Foster, Johann Roturier, Corentin Ribeyre, Teresa Lynn,
and Joseph Le Roux. 2015. Foreebank: Syntactic analysis of customer support
forums. In Proc. of EMNLP’15.
[28] Su Nam Kim, Li Wang, and Timothy Baldwin. 2010. Tagging and linking web
forum posts. In Proc. of CoNLL’10.
[29] Frederik Kratzert. 2016. Finetune AlexNet with Tensorflow.
//github.com/kratzert/finetune_alexnet_with_tensorflow
(2016). https:
[30] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classifi-
cation with deep convolutional neural networks. In Proc. of NIPS’12.
[31] Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. 2017. Adversarial examples
in the physical world. In Proc. of ICLR workshop.
[32] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature
521, 7553 (2015), 436–444.
[33] Marco Lui and Timothy Baldwin. 2010. Classifying user forum participants: Sep-
arating the gurus from the hacks, and other tales of the internet. In Australasian
Language Technology Association Workshop 2010.
[34] J. Lukas, J. Fridrich, and M. Goljan. 2006. Digital Camera Identification from
Sensor Pattern Noise. IEEE Transactions on Information Forensics and Security 1,
2 (2006), 205–214.
[35] Damon McCoy, Andreas Pitsillidis, Jordan Grant, Nicholas Weaver, Christian
Kreibich, Brian Krebs, Geoffrey Voelker, Stefan Savage, and Kirill Levchenko. 2012.
PharmaLeaks: Understanding the Business of Online Pharmaceutical Affiliate
Programs. In Proc. of UNENIX Security’12.
[36] Dongyu Meng and Hao Chen. 2017. MagNet: a Two-Pronged Defense against
Adversarial Examples. In Proc. of CCS’17.
[37] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.
DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks. In
Proc. of CVPR’16.
[38] Marti Motoyama, Damon McCoy, Kirill Levchenko, Stefan Savage, and Geoffrey M
Voelker. 2011. An analysis of underground forums. In Proc. of IMC’11.
[39] NLTK. 2017. Natural Language Toolkit. (2017). http://www.nltk.org/.
[40] Maxime Oquab, Leon Bottou, Ivan Laptev, and Josef Sivic. 2014. Learning and
transferring mid-level image representations using convolutional neural net-
works. In Proc. of CVPR’14.
[41] Nicolas Papernot, Patrick D. McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay
Celik, and Ananthram Swami. 2016. The Limitations of Deep Learning in Adver-
sarial Settings. In Proc. of Euro SP’16.
[42] Rebecca S Portnoff, Sadia Afroz, Greg Durrett, Jonathan K Kummerfeld, Taylor
Berg-Kirkpatrick, Damon McCoy, Kirill Levchenko, and Vern Paxson. 2017. Tools
for Automated Analysis of Cybercriminal Markets. In Proc. of WWW’17.
[43] Tong Qiao, Florent Retraint, RÃľmi Cogranne, and Thanh Hai Thai. 2017. Indi-
vidual camera device identification from JPEG images. Signal Processing: Image
Communication 52 (2017), 74 – 86.
[44] Andras Rozsa, Ethan M. Rudd, and Terrance E. Boult. 2016. Adversarial Diversity
and Hard Positive Generation. In Proc. of CVPR Workshop.
[45] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C.
Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition Challenge.
International Journal of Computer Vision (IJCV) 115, 3 (2015), 211–252.
[46] Hoo-Chang Shin, Holger R Roth, Mingchen Gao, Le Lu, Ziyue Xu, Isabella Nogues,
Jianhua Yao, Daniel Mollura, and Ronald M Summers. 2016. Deep convolutional
neural networks for computer-aided detection: CNN architectures, dataset char-
acteristics and transfer learning.
IEEE transactions on medical imaging 35, 5
(2016), 1285–1298.
[47] Karen Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks
for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).
[48] Kyle Soska and Nicolas Christin. 2015. Measuring the Longitudinal Evolution of
the Online Anonymous Marketplace Ecosystem. In Proc. of USENIX Security’15.
[49] Brett Stone-Gross, Thorsten Holz, Gianluca Stringhini, and Giovanni Vigna. 2011.
The Underground Economy of Spam: A Botmaster’s Perspective of Coordinating
Large-scale Spam Campaigns. In Proc. of LEET’11.
[50] Jiawei Su, Danilo Vasconcellos Vargas, and Sakurai Kouichi. 2017. One pixel
attack for fooling deep neural networks. arXiv preprint arXiv:1710.08864 (2017).
[51] Srikanth Sundaresan, Damon McCoy, Sadia Afroz, and Vern Paxson. 2016. Profil-
ing underground merchants based on network behavior. In Proc. of eCrime’16.
[52] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander A Alemi.
2017. Inception-v4, Inception-ResNet and the Impact of Residual Connections on
Learning. In Proc. of AAAI’17.
[53] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks.
In Proc. of ICLR’14.
[54] Nima Tajbakhsh, Jae Y Shin, Suryakanth R Gurudu, R Todd Hurst, Christopher B
Kendall, Michael B Gotway, and Jianming Liang. 2016. Convolutional neural net-
works for medical image analysis: Full training or fine tuning? IEEE transactions
on medical imaging 35, 5 (2016), 1299–1312.
[55] Thanh Hai Thai, Florent Retraint, and Rémi Cogranne. 2016. Camera Model
Identification Based on the Generalized Noise Model in Natural Images. Digit.
Signal Process. 48, C (2016), 285–297.
[56] Christopher Thomas and Adriana Kovashka. 2016. Seeing Behind the Camera:
Identifying the Authorship of a Photograph. In Proc. of CVPR’16.
[57] Kristina Toutanova, Dan Klein, Christopher D Manning, and Yoram Singer. 2003.
Feature-rich part-of-speech tagging with a cyclic dependency network. In Proc.
of NAACL’03.
[58] Nicky Woolf. 2015. Bitcoin “exit scam”: deep-web market operators disappear
(2015). https://www.theguardian.com/technology/2015/mar/18/
with $12m.
bitcoin-deep-web-evolution-exit-scam-12-million-dollars
[59] Weilin Xu, David Evans, and Yanjun Qi. 2017. Feature Squeezing: Detecting
Adversarial Examples in Deep Neural Networks. arXiv preprint arXiv:1704.01155
(2017).
[60] M. Yip, N. Shadbolt, and C. Webber. 2012. Structural analysis of online criminal
social networks. In Proc. of ISI’12.
[61] Felix Yu. 2016. Fine-tune Convolutional Neural Network in Keras with ImageNet
Pretrained Models. (2016). https://github.com/flyyufelix/cnn_finetune
[62] Stephan Zheng, Yang Song, Thomas Leung, and Ian J. Goodfellow. 2016. Improv-
ing the Robustness of Deep Neural Networks via Stability Training. In Proc. of
CVPR’16.