title:FTP: The Forgotten Cloud
author:Drew Springall and
Zakir Durumeric and
J. Alex Halderman
2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
FTP: The Forgotten Cloud
Drew Springall Zakir Durumeric
J. Alex Halderman
University of Michigan
{aaspring, zakir, jhalderm}@umich.edu
Abstract—Once pervasive, the File Transfer Protocol (FTP)
has been largely supplanted by HTTP, SCP, and BitTorrent for
transferring data between hosts. Yet, in a comprehensive analysis
of the FTP ecosystem as of 2015, we ﬁnd that there are still more
than 13 million FTP servers in the IPv4 address space, 1.1 million
of which allow “anonymous” (public) access. These anonymous
FTP servers leak sensitive information, such as tax documents
and cryptographic secrets. More than 20,000 FTP servers allow
public write access, which has facilitated malicious actors’ use
of free storage as well as malware deployment and click-fraud
attacks. We further investigate real-world attacks by deploying
eight FTP honeypots, shedding light on how attackers are abusing
and exploiting vulnerable servers. We conclude with lessons and
recommendations for securing FTP.
I.
INTRODUCTION
The File Transfer Protocol (FTP), ﬁrst introduced nearly
45 years ago [7], was for decades the protocol of choice for
moving ﬁles between hosts and for distributing them to the
world [17]. In recent years, FTP has been largely eclipsed
by newer protocols such as HTTP, SCP, and BitTorrent— all
of which have received vastly more attention from security
researchers. Nevertheless, as of 2015, FTP remains in use by
millions of servers that offer more than half a billion ﬁles to
the public: it is largely forgotten but far from gone.
We present the ﬁrst comprehensive security analysis on
how FTP is used and abused in modern practice. We begin by
using Internet-wide scanning to characterize the contemporary
FTP server ecosystem, which we ﬁnd consists of 13.8 million
servers in the public IPv4 address space1. Of these servers,
1.1 million (8%) permit anonymous logins, making their
contents accessible to the public at large. Although many of
these publicly accessible servers are operated by large hosting
providers, a substantial fraction are consumer devices that
provide remote access to data and appear to be mistakenly
conﬁgured to allow public access.
Publicly accessible FTP sites host an alarming number and
variety of sensitive ﬁles, which suggests that misconﬁguration
is widespread. To measure the scope of this phenomenon,
we construct a robust FTP enumerator and use it to collect
the directory listings of over a million anonymous FTP sites.
Since the protocol has accumulated layers of ad hoc extensions
over the years, this is challenging to automate at large scale.
Nevertheless, our toolchain is able to collect listings of over
600 million ﬁles and directories, which range from ﬁnancial
information to email archives, password databases, private keys,
and personal photographs. Startlingly, we ﬁnd that nearly 5%
of anonymous FTP servers appear to expose at least one such
sensitive ﬁle.
1In comparison, about 30M hosts complete a TLS handshake on TCP/443,
but these have been studied far more extensively (e.g., [21], [30], [32]).
Beyond information exposure, FTP is prone to abuse by
malicious parties who seek to attack the server or use it to ex-
ploit other systems. Drawing on data from our FTP enumerator
and from a series of honeypots, we uncover evidence of several
malicious campaigns that leverage anonymous FTP servers to
distribute malware, launch DDoS attacks, and carry out SEO
campaigns. Among our ﬁndings is that more than 20K FTP
servers allow anonymous users to write data —which malicious
actors are using to deploy malware and trade illicit ﬁles—and
more than 140K fail to properly validate PORT commands—
which can be used to probe remote, third-party servers. We
also ﬁnd that nearly 10% of FTP servers listening on public IP
addresses report software versions that are susceptible to one
or more publicly disclosed vulnerabilities.
With regard to the security provided by FTPS (a protocol
extension which allows FTP connections to communicate over
TLS), we analyzed the adoption rate as well as how it is being
implemented. We ﬁnd only 793K certiﬁcates are in use across
3.4 million servers who support FTPS. While a large number of
these are shared-hosting providers, we also ﬁnd evidence that
embedded device manufacturers are shipping identical FTPS
certiﬁcates and private keys built-in to their devices.
We conclude by attempting to distill the root causes of
FTP’s persistent vulnerability, by offering potential solutions to
improve the FTP ecosystem, and by drawing lessons about user-
centered security issues that apply even beyond FTP. Along with
these solutions, we analyze possible methods of encouraging
their deployment.
FTP is a product of a time when security was much less
of a focus than it is on today’s Internet. Although the protocol
continues to be implemented and deployed, the FTP ecosystem
as a whole has only marginally advanced in terms of security.
While the existence of FTP-related vulnerabilities may not
come as a surprise, the vast number of vulnerable systems and
sensitive ﬁles—and their persistence up to the present—is
shocking. Our study presents a dismal portrait of how FTP is
deployed in 2015, but we hope that by shedding light on these
ongoing vulnerabilities, the network security community can
begin to address them.
II. BACKGROUND
FTP was introduced in 1971 to allow users to transfer ﬁles
between network hosts [7]. Clients send text requests in the form
of “ [arguments]\r\n” to the server and extract a
three-digit return code and other request-dependent information
from the server’s response to determine whether the request was
successful. In a typical scenario, a client initiates a connection
on TCP/21, and, after receiving a “banner” containing arbitrary
text from the server, logs in with the USER and PASS commands.
Once authenticated, the client can list and traverse the accessible
978-1-4673-8891-7/16 $31.00 © 2016 IEEE
DOI 10.1109/DSN.2016.52
503
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:25 UTC from IEEE Xplore.  Restrictions apply. 
directory structure and upload and download ﬁles (depending
on the permissions set by the administrator).
carry out all actions autonomously while being robust enough to
correctly communicate with diverse real-world implementations.
In a peculiarity of the protocol, FTP requires two con-
nections: one for control messages and one for transferring
the requested data. In traditional active FTP, the client sends
the PORT command whose arguments indicate the client’s IP
address and an open, ephemeral port that the server should
connect back to using a second connection. Unfortunately, this
is incompatible with many ﬁrewalls and NATs, which are unable
to detect that the inbound connection is associated with the
original outgoing FTP connection. To address this, passive FTP
was introduced, in which the client sends the PASV command
and the server responds with and listens on an ephemeral port
that the client opens a second connection to [6]. Regardless
of whether the connection is active or passive, the client can
then send requests via the control connection to list directory
contents and retrieve or store ﬁles, which are transmitted via
the secondary (PORT/PASV negotiated) connection.
Although FTP provided an easy and efﬁcient way to transfer
ﬁles, the mandatory authentication hindered publicly posting
data. To address this, the protocol was extended to support
anonymous FTP, which allows administrators to explicitly allow
public access. To use anonymous FTP, the client authenticates
with the username “anonymous” and their contact e-mail
address as the password (if the server requires one). A server
conﬁgured to allow anonymous FTP will accept any password
for the anonymous user [17].
As with many early protocols, FTP was designed with only
minimal consideration for security, such that both commands
and data are sent in unauthenticated, unencrypted form. To
address this, FTPS was introduced [3], [26]. FTPS allows the
endpoints to upgrade the connection to TLS, akin to STARTTLS
for SMTP. The client sends the AUTH SSL or AUTH TLS request
to the server and reads the response to determine if TLS is
supported. If so, the client and servers complete a standard
TLS handshake and then continue with the FTP protocol over
the secure connection.
This patchwork of extensions—some described in RFCs
and some not—has resulted in diverse behavior by different
FTP implementations. Server responses to the USER login
request are a prime example. The return code 331 has at
least four meanings depending on the implementation- and
language-speciﬁc text that accompanies it: “User accepted,
send password”, “User rejected”, “Send virtual-site hostname
with username”, or “FTPS required prior to login”.
While other protocols might fragment under such loose
standardization, FTP has been surprisingly resilient. Bare-
bones FTP clients are capable of talking to most server
implementations. This is largely due to the human-centered
nature of the protocol. FTP clients perform very little of the
“heavy lifting” for the user and mainly serve to make FTP
communication less tedious. For many operations, replacing a
console-based FTP client with a bare TCP connection would
result in little additional work for the user.
Unfortunately, this level of user control is an obstacle
to large-scale automation and to our goal of analyzing FTP
behavior on an Internet-wide basis. In order to study the FTP
ecosystem as a whole, we needed to build tools that could
III. METHODOLOGY
To survey FTP at Internet scale, we needed to address three
main challenges. The ﬁrst was how to automate handling of
the FTP protocol, with its quirks and myriad implementations.
We adopted a reverse-engineering perspective: starting from
a simple enumerator that implemented a minimal subset of
the FTP protocol, we began testing on a local testbed that
consisted of a diverse collection of server implementations.
After ensuring correct behavior on our testbed, we tested against
gradually larger random samples of live servers. By iteratively
expanding the capabilities of the enumerator and reactively
adjusting its behavior to oddities found in the wild, we attained
a good balance of RFC correctness and compatibility with real
implementations.
The second challenge was how to efﬁciently collect data
from FTP servers throughout the IPv4 address space. We
adopted a methodology based on the ZMap toolchain [23]
coupled with our custom FTP enumerator. In the ﬁrst stage
of our data collection, we used ZMap to perform a host
discovery scan on TCP port 21. We then used our enumerator
to perform a follow-up connection to each responsive host,
attempt an anonymous login (per RFC 1635 [17]), parse
each host’s robots.txt ﬁle, and traverse the host’s directory
structure in a breadth-ﬁrst manner. Once we ﬁnished traversing
any publicly accessible directories, we collected the data
returned by the HELP, FEAT, and SITE commands. Regardless
of whether the server allowed anonymous access, we attempted
to initiate a TLS session prior to disconnecting to collect the
server’s SSL certiﬁcate. Our enumerator is written in C using
the libevent framework [36] and is publicly available at
https://github.com/aaspring/ftp-enumerator.
The last main challenge was how to process and analyze the
resulting data, which is largely unstructured. Server banners
contain arbitrary text, users name ﬁles in varying manners
and in different languages, and, in some cases, ﬁlenames may
not describe ﬁle content. In order to sift through all this data
and establish lower bounds on vulnerability and data exposure,
we iteratively processed the dataset, manually selecting and
investigating speciﬁc evidence of abuse or accidentally exposed
data. After each iteration, we measured the number of servers
displaying the same or similar behavior. Although this provides
an estimate of the range and scope of vulnerability, it may
result in the statistics we report underestimating the true scale
of the problems.
Since many ﬁles appeared to contain sensitive data that
was inadvertently made public, we chose not to download
ﬁles in bulk using our enumerator. For purposes of high-
level statistics, we attempted to infer ﬁle contents based on
the ﬁlename and extension. Without attempting downloads,
we cannot determine with certainty whether the anonymous
FTP user has permission to read the ﬁles. To address this,
we examined the all-users permission in directory listings to
determine whether an anonymous user could likely retrieve
each speciﬁc ﬁle. In cases where the server did not display
permissions (as with most Windows-based servers), we labeled
the ﬁles as “unk-readability”.
504
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:25 UTC from IEEE Xplore.  Restrictions apply. 
A. Ethical Considerations
As with any research conducted through Internet-wide
scanning, our work raises important ethical considerations. We
carefully considered the impact of our experimental measure-
ments on parties ranging from our local institutional network
to the owners of remote systems, and we took numerous steps
to prevent or mitigate potential harms.
When scanning for FTP sites, we followed the recommen-
dations set forth by Durumeric et al. [23]. We coordinated with
our local network administrators and upstream ISP to ensure
that our scans did not adversely impact network operations.
We signaled the benign intent of our scanning hosts by setting
descriptive WHOIS records and reverse DNS entries for them
and posting a simple website on port 80 that described the
goals of the research, including what data we collected and how
to contact us. We invited user exclusion requests and responded
to requests within 24 hours, and we preemptively excluded any
hosts that our institution had previously been asked to exclude
from scanning research as part of other studies.
When logging into FTP servers, we never attempted to
guess login credentials or to exploit vulnerabilities to access
non-public data. We also made a concerted effort to parse FTP
banners for messages stating that the server did not permit
anonymous access and discontinued the login attempt in that
case. We strictly followed RFC 1635 (“How to Use Anonymous
FTP”) [17]. If the server required a password for the anonymous
login, we sent our team’s abuse contact email address.
When traversing sites, we followed the community’s Robots
Exclusion Standard, fetching each host’s robots.txt ﬁle,
if present, and following it per Google’s speciﬁcation [29].
To ensure that we did not inundate a server with requests,
we spread concurrent connections across a large number of
widely dispersed hosts, and we limited the speed of interactions
with each host to two requests per second. We also imposed
a maximum of 500 requests per connection. If the server
terminated the connection at any point during directory traversal,
we interpreted this as an explicit refusal of service and ceased
interaction with that server.
As we will discuss in the remainder of the paper, we
were surprised to ﬁnd that a signiﬁcant fraction of the data
available via anonymous FTP appears to have been inadvertently
published. For this reason, we stopped short of downloading
ﬁles except in a few particular instances as necessary for
veriﬁcation and even then only after careful deliberation and
consultation with colleagues. Despite the fact that these ﬁles
and directory listings are publicly accessible, there would be
signiﬁcant risk in publishing an exhaustive list of ﬁles that
could then be then be trivially retrieved and potentially abused.
As such, we do not intend to publish our enumeration dataset.
We are working to notify responsible entities in likely instances
of sensitive information disclosure.
IV. FTP LANDSCAPE
Between June 18 and 21, 2015, we performed a scan of
the IPv4 address space and enumerated publicly accessible
FTP servers. In this scan, 21.8M hosts responded on port 21
and 13.8M sent an FTP-compliant banner. Of these, 1.1M
(8%) allowed anonymous access (see Table I). Of the servers
TABLE I.
GENERAL METRICS FROM FTP ENUMERATION
IPs scanned . . . . . . . . . . . . 3,684,755,175 (85.79% of IPv4 address space)
Open port 21 . . . . . . . . . . . . . . 21,832,903 ( 0.59% of scanned IPs)
FTP servers . . . . . . . . . . . . . . . 13,789,641 (63.16% of IPs with port open)
Anonymous FTP servers . . . . . 1,123,326 ( 8.15% of responsive FTP servers)
TABLE II.
BREAKOUT OF SERVERS IN EACH CATEGORY
Server Classiﬁcation
All FTP Servers
Anonymous FTP Servers