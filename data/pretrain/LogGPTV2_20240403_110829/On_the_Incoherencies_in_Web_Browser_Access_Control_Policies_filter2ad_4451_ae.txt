# Analysis of Browser Access Control Policies and Web Functionality

## Table VII: Comparison of User-Driven Analysis vs. WebAnalyzer for the Top 100 Alexa Sites

| Feature | User-Driven | WebAnalyzer |
|---------|-------------|-------------|
| Cookie read in response of XMLHttpRequest | 93 | 86 |
| Cross-origin descendant-navigation (reading descendant’s location) | 78 | 59 |
| Cross-origin descendant-navigation (changing descendant’s location) | 0 | 11 |
| Child navigation (parent navigating direct child) | 27 | 17 |
| document.domain (read) | 32 | 0 |
| document.domain (write) | 0 | 0 |
| Use of cookies after change of effective domain | 0 | 0 |
| Use of XMLHttpRequest after change of effective domain | 1 | 78 |
| Use of localStorage after change of effective domain | 18 | 18 |
| Use of session storage | 4 | 2 |
| Use of local storage | 0 | 4 |
| Use of fragment identifier for communication | 1 | 0 |
| Use of postMessage | 1 | 1 |
| Use of XDomainRequest | 16 | 1 |
| Presence of JavaScript within CSS | 2 | 3 |
| Setting top-level window’s location | 86 | 76 |
| Change focus of window | 70 | 59 |
| Reading user’s Geolocation | 2 | 8 |
| Number of sites | 100 | 100 |

**Note:** Features not shown here were used by zero sites for both user-driven and WebAnalyzer studies.

## V. Discussion and Limitations

### Benefits of Heuristics-Driven Automated Crawling
In the initial design, WebAnalyzer only visited the top-level page of each site. This approach was insufficient for sites that hide much of their functionality behind "splash" home pages. By adding simple heuristics to mimic user behavior, such as clicking links and filling out search forms, we improved the coverage. For example, the number of pages using XMLHttpRequest increased from 13 to 32, as the new system triggered auto-complete features on search boxes.

### Limits of Automated Crawler-Based Measurements
While our measurements provide a good representation of browser feature usage on popular websites, some features may be missed if the code path to invoke them is not triggered. For instance, sites requiring user sign-in, specific mouse gestures, or form inputs may not be fully analyzed. Additionally, exhaustive crawling of each site was not attempted, and our aim was to favor breadth over depth.

### Picking the Right Browser
Some sites check the client's browser version before invoking certain code paths. WebAnalyzer uses Internet Explorer (IE), which may miss features intended for non-IE browsers. For example, XMLHttpRequest2 is not supported by IE, so it would be missed if the site checks for browser support. Fallback code that invokes alternative implementations for unsupported features can also lead to incomplete logging. Future work could include integrating other browsers into WebAnalyzer or modifying it to render sites with different user-agent strings.

### Studying Other Web Segments
Our focus on the top 100,000 sites provides a good balance but covers only a small fraction of the web. Intranet sites, which are hidden from traditional crawlers, were excluded, and they can influence backward compatibility decisions for browsers. Exploring these other segments is an important future direction.

## VI. Related Work
Previous research has examined security flaws in browser policies, including cross-frame communication, frame navigation, and client-side state. Our work complements these efforts by identifying incoherencies in browser access control policies. Tools like DOM Access Checker and Browserscope have been developed to validate security policies, but our analysis extends to the HTTP network layer and display. We also present results from a significantly larger dataset compared to similar studies.

## VII. Conclusions
This paper examines the current state of browser access control policies, identifies incoherencies, and measures the cost of removing unsafe policies for a large set of popular websites. Our findings contribute to the understanding of browser security and provide insights into the compatibility vs. security dilemma.

## Acknowledgements
We thank Xiaofeng Fan, Yutaka Suzue, and Carl Edlund for their help in implementing this work. We also acknowledge Collin Jackson and David Wagner for their valuable discussions, as well as the anonymous reviewers and our shepherd Michael Locasto for their comments.

## References
[1] H. J. Wang, X. Fan, J. Howell, and C. Jackson, “Protection and Communication Abstractions for Web Browsers in MashupOS,” in Proceedings of the 21st ACM Symposium on Operating Systems Principles (SOSP), Stevenson, WA, Oct. 2007.
...
[34] A. Moshchuk, T. Bragin, D. Deville, S. D. Gribble, and H. M. Levy, “SpyProxy: Execution-based Detection of Malicious Web Content,” in Proceedings of the 16th USENIX Security Symposium, Boston, MA, Aug. 2007.