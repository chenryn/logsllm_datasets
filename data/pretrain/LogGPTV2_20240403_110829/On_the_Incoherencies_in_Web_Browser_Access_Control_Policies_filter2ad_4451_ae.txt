Cookie read in response of XMLHttpRequest
Cross-origin descendant-navigation (reading descendant’s location)
Cross-origin descendant-navigation (changing descendant’s location)
Child navigation (parent navigating direct child)
document.domain (read)
document.domain (write)
Use of cookies after change of effective domain
Use of XMLHttpRequest after change of effective domain
Use of localStorage after change of effective domain
Use of session storage
Use of local storage
Use of fragment identiﬁer for communication
Use of postMessage
Use of XDomainRequest
Presence of JavaScript within CSS
Setting top-level window’s location
Change focus of window
Reading user’s Geolocation
Number of sites
WebAnalyzer
Manual
93
86
78
59
0
11
27
17
32
0
0
0
1
78
18
18
4
2
0
4
0
1
1
16
1
2
3
86
76
70
59
2
8
30
8
28
0
0
0
2
59
19
19
2
1
0
3
1
1
2
27
2
2
9
COMPARISON OF USER-DRIVEN ANALYSIS VS. WEBANALYZER FOR THE TOP 100 ALEXA SITES. FEATURES NOT SHOWN HERE WERE USED BY ZERO
SITES FOR BOTH USER-DRIVEN AND WEBANALYZER STUDIES.
Table VII
functionality on a given site. Overall, we felt our heuristics-
driven approach achieved good coverage, though larger-scale
user-driven measurements would still be very valuable in
complementing WebAnalyzer measurements.
V. DISCUSSION AND LIMITATIONS
Beneﬁts of heuristics-driven automated crawling. In
our original design, WebAnalyzer visited only the top-
level page of each site we studied. We quickly realized
that this analysis failed for sites that hide much of their
functionality behind “splash” home pages. This became most
apparent when studying the original results for Table VII. We
observed that for many sites, clicking on a link or ﬁlling out
a search form on the home page would expose a noticeably
larger (though still not complete) set of functionality. Thus,
we augmented WebAnalyzer with simple heuristics that
imitate this user behavior (see Section III).
As an example, our original system saw XMLHttpRequest
calls on only 13 pages of the top 100 pages, whereas the
new one identiﬁed 32 such pages (see Table VII). One of
the reasons is that many search sites use XMLHttpRequest
to auto-complete the search string as users type it; our old
system did not trigger this behavior, whereas our new system
triggered it when auto-ﬁlling the search textbox. Many other
features showed a similarly dramatic jump in prevalence.
Limits of automated crawler-based measurements. Al-
though we believe that our resulting measurements provide a
good representation of the use of browser features on popular
web sites, it is likely that we missed certain features because
the code path to invoke them was not triggered in our
analysis. For example, sites like Facebook or banks require a
user to sign in, game sites require particular mouse gestures
to invoke certain behavior, and numerous sites require appro-
priate text (such as stock symbols or user’s personal data) to
be entered into forms. Even if we could solve some of these
problems, for example by enumerating all events registered
on a page or using a database of dummy usernames and
passwords [27], automatically invoking certain features, such
as buying products on shopping sites, is inappropriate. This
ultimately limits our ability to explore all features invoked
on today’s web.
We also did not try to exhaustively crawl each site. Even in
our user-driven analysis (Section IV-G), we did not attempt
to enumerate and invoke all gadgets on every page of each
site. Thus, the results we collect for a particular site cannot
be used as a list of all features the site might have. Our aim
was to favor breadth over depth and obtain good coverage
for the representative features of 100,000 sites we tested.
While our infrastructure could also be used for exhaustively
crawling each site, we would need to dramatically scale up
our current infrastructure to cover a comparable number of
sites, and we leave this as future work.
Picking the right browser. Some sites check the client’s
browser version (using the user-agent header) before de-
ciding to invoke a particular code path. Although not a
base requirement, we developed WebAnalyzer with IE as
the underlying browser. This could prevent code invocations
that are intended for non-IE browsers, thereby leading to
missed features. For example, XMLHttpRequest2 [15] is
currently not supported by IE, and it would be missed
by WebAnalyzer if the site invokes it only after verifying
browser support.
A related problem is fallback code that invokes an alter-
native implementation of a feature that a browser doesn’t
support. For example, a site could ﬁrst check whether the
browser supports postMessage for cross-frame commu-
nication, and fall back on fragment identiﬁer messaging if it
does not. Because we use IE 8, we will log that this site uses
postMessage, but older browsers would utilize fragment
identiﬁer messaging.
The compatibility cost of features invoked in browser-
dependent code paths depends not only on the number
of web sites using a feature, but also on the number of
visitors utilizing a particular browser that relies on such
code. Evaluating the second part of this cost is orthogonal
to our goals in this paper: rather than exploring prevalence
of features on web sites, it asks how many of a web site’s
clients rely on a particular browser. Web server operators
can easily answer this question by proﬁling “user-agent”
strings in incoming HTTP requests. As future work, we
can integrate other browsers into WebAnalyzer, or we can
modify IEWA to render a site with a set of user-agent strings
representing other browsers;
this would capture a more
complete set of the site’s code.
Studying other web segments. Our focus on the top
100,000 sites represents a particular segment of the web
with a good balance of the very top sites and some of the
less popular “tail”. However, this still covers only a tiny
fraction of the billions of pages on today’s web. In addition,
our analysis excluded intranet sites, which are hidden from
traditional crawlers, and which can inﬂuence backwards
compatibility decisions for a browser. We leave exploration
of these other segments of the web as important future work.
VI. RELATED WORK
We are not the ﬁrst to ﬁnd and analyze ﬂaws in browser
security policies. Previous work has looked at weaknesses in
cross-frame communication mechanisms [13], frame naviga-
tion policies [3], [13], client-side browser state [21], cookie
path protection [28], protection among documents within
same origin [2], display protection [3], and other issues.
Zalewski [9] documents the security design in browsers
including some loopholes. This work complements these
efforts by identifying incoherencies in browser’s access
control policies. To our knowledge, this is the ﬁrst principal-
driven analysis on browsers’ access control policies.
DOM access checker [22] is a tool designed to au-
tomatically validate numerous aspects of domain security
policy enforcement (cross-domain DOM access, JavaScript
cookies, XMLHttpRequest calls, event and transition han-
dling) to detect common security attacks or information
disclosure vectors. Browserscope [29] is a community-driven
project for tracking browser functionality. Its security test
suite [23] checks whether new browser security features
are implemented by a browser. In our analysis of access
control policies, we uncovered incoherencies by examining
the interplay between resources, runtime identity changes,
and the user principal’s resource access control. This focus
and methodology differ from this previous or ongoing work,
and our analysis not only touches on DOM, but also on the
HTTP network layer and display. Nevertheless, we plan to
contribute our test programs to one of these test suites.
Compared to previous work, a unique aspect of this
work is our extensive evaluation of the cost of removing
unsafe policies from the current web by actively crawling
and executing web content. Yue et al. [24] also used a
crawling-based, execution-based approach to measure the
prevalence of unsafe JavaScript features on 6805 popular
web sites. They used a JavaScript interposition technique
that
they
lack IEWA’s network and display interposition capabilities,
limiting the policies they can monitor. As well, we present
results from a signiﬁcantly larger dataset.
is similar to IEWA’s script engine proxy, but
Our active crawling infrastructure builds on previous
efforts that have analyzed safety of web pages by rendering
them in real browsers running within virtual machines [30]–
[34]. We extend these frameworks with additional browser
interposition support to monitor unsafe browser security
policies.
VII. CONCLUSIONS
In this paper, we have examined the current state of
browser access control policies and analyzed the incoheren-
cies that arise when browsers mishandle their principals
by (1) inconsistently labeling resources with principal IDs,
(2) inappropriately handling principal identity changes via
document.domain, and (3) neglecting access control for
certain resources belonging to the user principal. In addition
to pointing out these incoherencies, we have developed a
web compatibility analysis infrastructure and measured the
cost of removing many unsafe policies we identiﬁed for a
large set of popular web sites. Overall, this work contributes
to the community’s understanding of browser access control
policies, and it provides the much-needed answer to the
browsers’ compatibility vs. security dilemma by identifying
unsafe policies that can be removed with little compatibility
cost.
ACKNOWLEDGEMENT
We would like to thank Xiaofeng Fan, Yutaka Suzue, and
Carl Edlund for their valuable help during the implementa-
tion of this work. We would also like to acknowledge Collin
Jackson and David Wagner for their helpful discussions.
We also thank the anonymous reviewers and our shepherd
Michael Locasto for their valuable comments.
REFERENCES
[1] H. J. Wang, X. Fan, J. Howell, and C. Jackson, “Protec-
tion and Communication Abstractions for Web Browsers in
MashupOS,” in Proceedings of the 21st ACM Symposium on
Operating Systems Principles (SOSP), Stevenson, WA, Oct.
2007.
[2] C. Jackson and A. Barth, “Beware of Finer-Grained Origins,”
in Web 2.0 Security and Privacy (W2SP), Oakland, CA, May
2008. [Online]. Available: http://seclab.stanford.edu/websec/
origins/fgo.pdf
[3] H. J. Wang, C. Grier, A. Moshchuk, S. T. King, P. Choudhury,
and H. Venter, “The Multi-Principal OS Construction of the
Gazelle Web Browser,” in Proceedings of the 18th USENIX
Security Symposium, Montreal, Canada, Aug. 2009.
[4] J. Ruderman,
“Same Origin Policy for
JavaScript,”
http://www.mozilla.org/projects/security/components/
same-origin.html. Accessed on Nov. 14, 2009.
[5] “Alexa,” http://www.alexa.com/.
[6] “Document Object Model,” http://www.w3.org/DOM/. Ac-
cessed on Nov. 14, 2009.
[7] D. Kristol and L. Montulli, “HTTP State Management Mech-
anism,” in IETF RFC 2965, Oct. 2000.
[8] D. Flanagan, Javascript: The Deﬁnitive Guide.
O’Reilly
Media Inc., 2006.
[9] M. Zalewski, “Browser Security Handbook,” 2008, http://
code.google.com/p/browsersec/wiki/Main. Accessed on Nov.
14, 2009.
[10] A. Barth,
“HTTP
State Management Mechanism,”
IETF Draft 2109, Feb 2010, http://tools.ietf.org/html/
draft-ietf-httpstate-cookie-03.
[11] C. Jackson and A. Barth, “ForceHTTPS: Protecting High-
Security Web Sites from Network Attacks,” in WWW, 2008.
[12] “HTML 5 Editor’s Draft,” October 2008, http://www.w3.org/
html/wg/html5/.
[13] A. Barth, C. Jackson, and J. C. Mitchell, “Securing Frame
Communication in Browsers,” in Proceedings of the 17th
USENIX Security Symposium, San Jose, CA, Jul. 2008.
[14] “XMLHttpRequest,”
http://www.w3.org/TR/
XMLHttpRequest/. Accessed on Nov. 14, 2009.
[15] “XMLHttpRequest
Level
2,”
http://www.w3.org/TR/
XMLHttpRequest2/. Accessed on Nov. 14, 2009.
[16] “Mitigating Cross-site Scripting With HTTP-only Cookies,”
http://msdn2.microsoft.com/en-us/library/ms533046.aspx.
Accessed on Nov. 14, 2009.
[17] “HttpOnly,”
http://www.owasp.org/index.php/HTTPOnly.
Accessed on Nov. 14, 2009.
[18] “Mozilla
Foundation
2009-05:
XMLHttpRequest allows reading HTTPOnly cookies,” http://
www.mozilla.org/security/announce/2009/mfsa2009-05.html.
Accessed on Nov. 14, 2009.
Advisory
Security
[19] “Clickjacking,” http://en.wikipedia.org/wiki/Clickjacking.
[20] “Whats New in Internet Explorer 8,” 2008, http://
msdn.microsoft.com/en-us/library/cc288472.aspx. Accessed
on Nov. 14, 2009.
[21] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell, “Protect-
ing Browser State from Web Privacy Attacks,” in Proceedings
of the 15th International Conference on World Wide Web
(WWW), Edinburgh, Scotland, May 2006.
[22] M. Zalewski and F. Almeida, “Browser DOM Access Checker
1.01,” http://lcamtuf.coredump.cx/dom checker/. Accessed
on Nov. 14, 2009.
[23] C.
Jackson
and A. Barth,
“Browserscope Security
Test
http://mayscript.com/blog/collinj/
browserscope-security-test-suite. Accessed on Nov. 14,
2009.
Suite,”
[24] C. Yue and H. Wang, “Characterizing Insecure JavaScript
Practices on the Web,” in Proceedings of the 18th Inter-
national Conference on World Wide Web (WWW), Madrid,
Spain, Apr. 2009.
[25] E. Lawrence, “Fiddler web debugging tool,” http://www.
ﬁddler2.com/ﬁddler2/. Accessed on Nov. 14, 2009.
[26] “FiddlerCore,”
http://ﬁddler.wikidot.com/ﬁddlercore.
Accessed on Nov. 14, 2009.
[27] “BugMeNot,” http://www.bugmenot.com/. Accessed on Mar.
1, 2010.
[28] M. O’Neal, “Cookie Path Best Practice,” http://research.
corsaire.com/whitepapers/040323-cookie-path-best-practice.
pdf. Accessed on Nov. 14, 2009.
[29] “Browserscope,” http://www.browserscope.org/. Accessed on
Nov. 14, 2009.
[30] A. Moshchuk, T. Bragin, S. D. Gribble, and H. M. Levy, “A
Crawler-based Study of Spyware on the Web,” in Proceedings
of the 13th Annual Network and Distributed Systems Security
Symposium (NDSS), San Diego, CA, Feb. 2006.
[31] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski,
S. Chen, and S. King, “Automated Web Patrol with Strider
HoneyMonkeys,” in Proceedings of the 13th Network and
Distributed System Security Symposium (NDSS), San Diego,
CA, Feb. 2006.
[32] N. Provos, P. Mavrommatis, M. Rajab, and F. Monrose,
“All Your iFrames Point to Us,” in Proceedings of the 17th
USENIX Security Symposium, San Jose, CA, Jul. 2008.
[33] N. Provos, D. McNamee, P. Mavrommatis, K. Wang, and
N. Modadugu, “The Ghost in the Browser: Analysis of Web-
Based Malware,” in Proceedings of the 1st Workshop on Hot
Topics in Understanding Botnets (HotBots), Berkeley, CA,
USA, 2007.
[34] A. Moshchuk, T. Bragin, D. Deville, S. D. Gribble, and H. M.
Levy, “SpyProxy: Execution-based Detection of Malicious
Web Content,” in Proceedings of the 16th USENIX Security
Symposium, Boston, MA, Aug. 2007.