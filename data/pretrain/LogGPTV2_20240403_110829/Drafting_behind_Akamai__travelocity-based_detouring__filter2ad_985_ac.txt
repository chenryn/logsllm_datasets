addition, every 5 seconds, each PL node pings a set of the 10 best
Akamai edge servers. That is, whenever a new server ID is returned
by Akamai, it replaces the longest-RTT edge server in the current
set. It is essential to understand that by pinging, instead of fetching
parts of Akamai-hosted pages from servers as done in [16], we ef-
fectively avoid measuring combined network and server latencies,
and isolate the network-side effects. Finally, the results of 7 days
of measurements from all 140 nodes are collected and processed in
a database.
4.2 Rank
The latency between a client and its servers varies depending on
the client’s location. For example, the latencies for nodes located
in the middle of Akamai “hot-spots” are on the order of few mil-
liseconds; on the other hand, the RTTs of other nodes (e.g., located
in South America) to the closest Akamai server are on the order of
several hundreds of milliseconds. To determine the relative qual-
ity of paths to edge servers selected by Akamai, we introduce the
rank metric to represent the correlation of Akamai’s redirection de-
cisions to network latencies. In each 20-second-long round of the
k
n
a
r
e
g
a
r
e
v
A
 16
 14
 12
 10
 8
 6
 4
 2
 0
 0
 20
 40
 60
 80
Yahoo
CNN
AOL
The New York Times
Monster
Fox News
 120
 100
 140
 160
Host id
Figure 8: Averaged rank for all PL nodes.
ferent Akamai customers as indicated in the ﬁgure. The key insight
from the ﬁgure is that Akamai redirections overwhelmingly corre-
late with network conditions. For example, for the set of customers
showing the best performance (e.g. Fox News), more than 97%
of the paths chosen by Akamai (IDs 5-140 in Figure 8) are better
than average (rank larger than 8); at the same time, more than 70%
of Akamai paths are approximately among the best 10% of paths
(rank larger than 14).
Figure 8 also reveals that Akamai offers different performance
depending on the customer. As we previously explained, this oc-
curs because different Akamai servers can, and often do, host a dif-
ferent set of customers. It is interesting, however, to ﬁnd that CNN
(CNAME a1921.aol.akamai.net) shows by far the worst
result in our measurement. Further investigation showed that all
of the edge servers we found for CNN are from the same region
in the US; moreover, they are all from the same subnet. This ﬁnd-
ing seems to contradict Akamai’s policy of using globally deployed
edge servers to serve content. We later learned that none of CNN’s
servers are currently owned by Akamai. Therefore, it appears that
CNN is no longer an Akamai customer, though they still have ”aka-
mai.net” as the postﬁx of their CNAME. For this reason, we re-
moved CNN from all other ﬁgures in this study. Regardless, this
ﬁnding provides evidence that CDN services that utilize network
measurements and global server deployment are signiﬁcantly bet-
ter than traditional web content distribution using load-balancing
server farms in a few data centers.
4.3 Latency
In this subsection, we measure the latency gains made possi-
ble by following the paths to edge servers returned by Akamai.
Such measurements not only reveal the performance of the Aka-
mai CDN, but also indicate the spectrum of potential latency gains
achievable with Akamai-driven one-hop source routing, which we
explore in the next section.
For each PL node, we collect the statistics for the RTTs on the
paths between the client and the Akamai servers as follows. (i) Best
delay, deﬁned as the lowest RTT in each 20-second-long measure-
ment round among the current ten best Akamai paths. (ii) Aka-
mai’s delay, deﬁned as the average of RTTs on the paths to the
two edge servers selected by Akamai in each measurement round.
(iii) Average delay, deﬁned as the average of the ten best Akamai-
recommended paths. (iv) Worst delay, deﬁned as the highest RTT
in each measurement round among all ten paths.
Figure 9 plots the CDF curves for two PL nodes, csmail.
mit.edu and cs.vu.nl, previously shown in Figure 7. Both
ﬁgures conﬁrm that Akamai indeed does a great job in these two
scenarios; the Akamai path is almost identical to the best path in
both cases. However, the key insight from the ﬁgure is that the
Figure 6: Measurement Methodology.
experiment, the 10 best Akamai paths are ranked by the RTTs mea-
sured from the client, in the order from 0 (the longest) to 9 (the
shortest). Akamai returns IP addresses of two edge servers in each
round; thus, we assign ranks r1 and r2 to the corresponding edge
server. We deﬁne the total rank, r, as r = r1 + r2 − 1. If the paths
returned by Akamai are the best two among all ten paths, the rank
is 16; similarly, if the Akamai paths are the worst in the group, the
rank equals zero.
n
o
l
i
t
c
e
e
s
s
’
i
a
m
a
k
A
f
o
k
n
a
R
 16
 14
 12
 10
 8
 6
 4
 2
 0
0
csail.mit.edu
cs.vu.nl
pop-ce.rnp.br
20
100
Percentage of time Akamai’s selection is better or equal to rank
40
60
80
Figure 7: Ranks for three characteristic PL nodes.
Figure 7 plots the rank of Internet paths measured from the sources
indicated in the ﬁgure to the Akamai servers. A point in the ﬁgure
with coordinates (x,y) means that the rank of the two paths returned
by Akamai is better than or equal to the rank y during x percent of
the duration of the 7-day experiment. Thus, the closer the curve
is to the upper right corner, the better the corresponding paths se-
lected by Akamai. Indeed, Figure 7 indicates that the Akamai redi-
rections for csail.mit.edu and cs.vu.nl almost perfectly
follow network conditions. On the other hand, because the aver-
age redirection interval is quite high in the Brazil case (6 minutes,
as shown in Figure 5), we observe a relatively poor selection of
servers in terms of path latency. Indeed, even a random or round-
robin path selection over shorter time intervals would achieve a bet-
ter result in this case. This is because Brazil’s node performance is
below average. Theoretically, random selection should achieve av-
erage performance.
Figure 8 depicts the average rank of the paths that Akamai re-
turns to all 140 PL nodes. We plot the curves in Figure 8 in the in-
creasing rank order. Hence, the order of PL node IDs on the x-axis,
while similar, is not identical for different customers. To examine
the effect of Akamai customer on this metric, we measure six dif-
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 20
 40
 60
Delay (ms)
(a) MIT
 1
 0.8
 0.6
 0.4
 0.2
F
D
C
 100
 0
 0
Best
Akamai
Average
Worst
 80
Best
Akamai
Average
Worst
 150
 200
 50
 100
Delay (ms)
(b) Amsterdam
Figure 9: CDF of RTTs for Akamai paths for two PL nodes.
relative latency gain depends on the distance between the PL node
and its Akamai edge servers. For example, the MIT node obviously
operates in an Akamai hot-spot, since the difference between the
medians (CDF = 0.5) of the best and the worst path is only 20 ms.
On the contrary, the corresponding difference is as much as 100 ms
in the Amsterdam case. Indeed, as the distance between the Aka-
mai CDN and a PL node increases, both the number of servers (and
paths) increases and the variance of path quality increases. Thus,
following the Akamai redirections brings the largest latency gains
for nodes that are distant from their edge servers.
)
s
m
(
e
c
n
e
r
e
f
f
i
d
y
a
e
d
l
e
v
a
l
t
e
u
o
s
b
A
 100
 10
 1
 0.1
 0.01
 0.001
 0
 20
 40
 60
Yahoo
AOL
The New York Times
Monster
Fox News
 100
 80
 120
 140
Host id
Figure 10: Latency gains for all measured PL nodes.
Figure 10 plots the latency performance over all 140 PL nodes
for different Akamai customers. For each node, we compute the av-
erage difference between (i) the RTT corresponding to the average
of the ten best Akamai paths seen by the node, and (ii) the RTT
corresponding to the Akamai path. The y-axis of Figure 10 plots
the absolute value of the above average difference between the two
paths. Thus, nodes on the left of the ﬁgure (e.g., 0-20) show the
worst performance, i.e., the path that Akamai selects is worse than
the average of the current ten best Akamai paths. We found that
this group is dominated by nodes that have a large server (and path)
diversity and a small redirection frequency. Nodes with IDs in the
range 20-30 are dominated by a small number of short-latency Aka-
mai paths; in this case, although Akamai redirections correlate well
with measured network latencies, the difference among the paths is
negligible, e.g., less than 1 ms. Finally, the vast majority of nodes
(IDs 30-140) are directed to better-than-average paths. For a large
percentage of nodes (IDs 50-140), the gains are quite substantial,
ranging from 10 ms to 170 ms.
To summarize, we demonstrated that Akamai redirections over-
whelmingly reveal the network conditions over the paths between
end-users and Akamai edge-servers. Thus, by querying low-level
Akamai DNS servers, an endpoint can reveal information about
quality Internet paths without extensively probing and monitoring
them. While this is potentially useful for many applications, in the
next section, we necessarily focus on one such application.
5. AKAMAI-DRIVEN ONE-HOP SOURCE
ROUTING
In this section, we examine the potential for performance im-
provement by using Akamai to drive an example network applica-
tion: one-hop routing in a large-scale overlay network. Since Aka-
mai redirections generally reveal low-latency paths between nodes
and edge servers, such an overlay network can use these redirec-
tions to route its own trafﬁc. Even if an application is not primarily
interested in low latency, but rather strives for high-bandwidth, the
Akamai-driven approach is still viable. Measurements from [26]
indicate that the vast majority of TCP ﬂows are limited by the re-
ceiver advertised window parameter. Similarly, a recent measure-
ment study shows that as much as 85% of the KaZaA clients do not
suffer any packet loss [15]. Hence, in such cases, lower latencies
directly translate to larger throughputs [30].
The key prerequisite in this environment is for the overlay net-
work to be able to map a subset of its nodes to Akamai edge servers.
Fortunately, the number of nodes in large-scale peer-to-peer (P2P)