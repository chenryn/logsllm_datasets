---6-2_logging-sidecar.yml--- 
apiVersion: v1 
kind: Pod 
metadata: 
  name: myapp 
spec: 
  containers: 
  - image: busybox 
    name: application 
    args: 
     - /bin/sh 
     - -c 
     - > 
      while true; do 
        echo "$(date) INFO hello" >> /var/log/myapp.log ; 
        sleep 1; 
      done 
    volumeMounts: 
    - name: log 
      mountPath: /var/log 
  - name: sidecar 
    image: busybox 
    args: 
     - /bin/sh 
     - -c 
     - tail -fn+1 /var/log/myapp.log 
    volumeMounts: 
    - name: log 
      mountPath: /var/log 
  volumes: 
  - name: log 
emptyDir: {}  
```
现在我们可以看到写有`kubectl logs`的日志:
```
$ kubectl logs -f myapp -c sidecar
Tue Jul 25 14:51:33 UTC 2017 INFO hello
Tue Jul 25 14:51:34 UTC 2017 INFO hello
...
```
# 投资 kubernetes 活动
我们在`kubectl describe`的输出中看到的事件消息包含有价值的信息，并补充了 kube-state-metrics 收集的指标，这使我们能够知道我们的 Pod 或节点到底发生了什么。因此，它应该与系统和应用日志一起成为我们的日志记录要素的一部分。为了实现这一点，我们需要一些东西来观察 Kubernetes API 服务器，并将事件聚合到日志接收器中。有一个事件发生者做了我们需要做的事情。
Eventer 是 Heapster 的一部分，目前它支持 Elasticsearch、InfluxDB、Riemann 和 Google 云日志作为它的接收器。如果不支持我们使用的日志系统，Eventer 也可以直接输出到`stdout`。
eventer 的部署类似于 Heapster 的部署，除了容器启动命令，因为它们被打包在同一个映像中。每个接收器类型的标志和选项可以在这里找到:([https://github . com/kubernetes/heap ster/blob/master/docs/sink-configuration . MD](https://github.com/kubernetes/heapster/blob/master/docs/sink-configuration.md))。
我们为本章提供的示例模板还包括 eventer，它被配置为与 Elasticsearch 一起工作。我们将在下一节中描述它。
# 具有流动性和弹性研究的测井
到目前为止，我们已经讨论了现实世界中可能遇到的各种测井条件，现在是时候卷起袖子，利用我们所学的知识来构建一个测井系统了。
日志系统和监控系统的体系结构在某些方面几乎是相同的——收集器、存储和用户界面。我们将要设置的相应组件分别是 Fluent/event er、Elasticsearch 和 Kibana。这个部分的模板可以在`6-3_efk`下找到，它们将被部署到上一部分的名称空间`monitoring`中。
Elasticsearch 是一个功能强大的文本搜索和分析引擎，它是持久化、处理和分析集群中运行的所有日志的理想选择。本章的弹性搜索模板使用非常简单的设置来演示这个概念。如果您希望部署一个弹性搜索集群用于生产，利用 StatefulSet 控制器并使用适当的配置调整弹性搜索，正如我们在[第 4 章](04.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)、*中讨论的那样。使用存储和资源，推荐使用*。让我们使用以下模板部署 elastic search(https://github . com/DevOps-wit-Kubernetes/examples/tree/master/chapter 6/6-3 _ efk/):
```
$ kubectl apply -f elasticsearch/es-config.yml
$ kubectl apply -f elasticsearch/es-logging.yml
```
如果`es-logging-svc:9200`有回应，弹性搜索就准备好了。
下一步是设置节点日志代理。因为我们会在每个节点上运行它，所以我们肯定希望它在节点的资源使用方面尽可能轻，因此选择了 Fluentd([www.fluentd.org](http://www.fluentd.org))。Fluentd 的特点是内存占用较低，这使它成为满足我们需求的合格日志代理。此外，因为容器化环境中的日志记录需求非常集中，所以有一个兄弟项目，Fluent Bit ( `fluentbit.io`)，它旨在通过删除不会用于其目标场景的功能来最小化资源使用。在我们的示例中，我们将使用 Kubernetes([https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset))的 Fluentd 映像来执行我们之前提到的第一个测井模式。
该映像已经配置为在`/var/log/containers`下转发容器日志，在`/var/log`下转发某些系统组件的日志。如果需要，我们绝对能够进一步定制它的日志配置。这里提供了两个模板:`fluentd-sa.yml`是 Fluentd DaemonSet 的 RBAC 配置，`fluentd-ds.yml`:
```
$ kubectl apply -f fluentd/fluentd-sa.yml
$ kubectl apply -f fluentd/fluentd-ds.yml  
```
另一个必备的日志记录组件是 eventer。这里我们为不同的条件准备了两个模板。如果您使用的是已经部署了 Heapster 的托管 Kubernetes 服务，那么在这种情况下将使用独立事件器的模板`eventer-only.yml`。否则，考虑在同一个窗格中运行 Heapster 和 eventer 的模板:
```
$ kubectl apply -f heapster-eventer/heapster-eventer.yml
or
$ kubectl apply -f heapster-eventer/eventer-only.yml
```
要查看发送到 Elasticsearch 的日志，我们可以调用 Elasticsearch 的搜索 API，但是还有一个更好的选择，即 Kibana，一个允许我们玩 Elasticsearch 的 web 界面。基巴纳的模板是[下的`elasticsearch/kibana-logging.yml`。](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter6/6-3_efk/)
```
$ kubectl apply -f elasticsearch/kibana-logging.yml  
```
我们例子中的基巴纳正在监听端口`5601`。在将服务暴露在集群之外并用任何浏览器连接到它之后，您可以开始从 Kubernetes 搜索日志。eventer 发出的日志索引名为`heapster-*`，Fluentd 转发的日志为`logstash-*`。下面的截图显示了弹性搜索中日志条目的样子。
该条目来自我们前面的示例`myapp`，我们可以发现该条目已经在 Kubernetes 上用方便的元数据进行了标记。
![](img/00105.jpeg)
# 从日志中提取指标
下图显示了我们围绕 Kubernetes 之上的应用构建的监控和日志记录系统:
![](img/00106.jpeg)
日志部分和监控部分看起来像是两个独立的轨迹，但是日志的价值远不止是一个简短文本的集合。它们是结构化数据，像往常一样用时间戳发出；因此，将日志转换为时间序列数据的想法是有希望的。然而，虽然普罗米修斯非常擅长处理时间序列数据，但如果没有任何转换，它就无法摄取文本。
来自 HTTPD 的访问日志条目如下所示:
`10.1.8.10 - - [07/Jul/2017:16:47:12 0000] "GET /ping HTTP/1.1" 200 68`。
它由请求 IP 地址、时间、方法、处理程序等组成。如果我们根据其含义来划分测井曲线段，那么计数的剖面就可以被视为一个度量样本，如下所示:`"10.1.8.10": 1, "GET": 1, "/ping": 1, "200": 1`。
mtail([https://github.com/google/mtail](https://github.com/google/mtail))和 Grok Exporter([https://github.com/fstab/grok_exporter](https://github.com/fstab/grok_exporter))等工具对日志条目进行计数，并将这些数字组织成指标，以便我们可以在 Prometheus 中进一步处理它们。
# 摘要
在这一章的开始，我们描述了如何通过`kubectl`等内置函数快速获取运行容器的状态。然后我们将讨论扩展到监控的概念和原则，包括为什么有必要进行监控，监控什么，如何监控。之后，我们建立了一个以普罗米修斯为核心的监控系统，并设立了出口商来收集 Kubernetes 的指标。还介绍了 Prometheus 的基础知识，以便我们能够利用指标来更好地了解我们的集群以及运行在其中的应用。在日志部分，我们提到了常见的日志模式以及如何在 Kubernetes 中处理它们，并部署了一个 EFK 栈来聚合日志。我们在本章中构建的系统提高了我们服务的可靠性。接下来，我们正在推进建立一条管道，在 Kubernetes 持续交付我们的产品。