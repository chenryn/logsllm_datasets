CDS Input Auth. MUSE
CDS Evaluation
MUSE
system
threads
time (s)
MNIST
comm. (GB)
CIFAR-10
time (s)
comm. (GB)
1
1
2
2
8
6
2
2
3.93
4.74
1.81
4.34
1.67
7.32
4.10
2.17
0.03
0.04
0.18
0.51
0.02
2.66
0.43
0.53
36.21
40.78
19.31
62.19
5.2
112.51
59.579
31.34
0.05
0.07
2.95
7.45
0.35
44.36
7.00
8.79
r
a
e
n
i
l
-
n
o
N
g
n
i
s
s
e
c
o
r
p
e
r
P
e
n
i
l
Online
Online
DELPHI
MUSE
8
8
0.48
0.80
0.01
0.01
3.74
8.37
0.16
0.23
n
O
Table 3: Latency and communication cost of the individual components of MUSE and DELPHI.
See Section 6.2 for more information on the network architectures and number of threads used.
of MUSE’s individual components when performing infer-
ence and how do they compare to the semi-honest DELPHI?
• Section 6.4: How does MUSE compare to other inference
protocols secure against malicious clients?
• Section 6.5: How do our client-malicious Overdrive sub-
protocols compare to standard Overdrive?
6.1 System implementation
We implemented MUSE in Rust and C++. We use the SEAL
homomorphic encryption library [Sea] to implement HE, the
fancy-garbling library9 to implement garbled circuits, and
MP-SPDZ10 [Kel20] to implement zero-knowledge proofs.
MUSE achieves 128 bits of computational security, and 40
bits of statistical security.
6.2 Evaluation setup
All experiments were carried out on AWS c5.9xlarge in-
stances possessing an Intel Xeon 8000 series CPU at 3.6GHz.
The client and server instances were located in the us-west-1
(Northern California) and us-west-2 (Oregon) regions re-
spectively with 21ms round-trip latency. The client and server
executions used 8 threads each. We evaluate MUSE on the
following datasets and network architectures:
1. MNIST is a standardized dataset consisting of (28× 28)
greyscale images of the digits 0–9. The training set con-
tains 60,000 images, while the test set has 10,000 images.
Our experiments use the 2-layer CNN architecture speci-
ﬁed in MiniONN [Liu+17a] with average pooling in place
of max pooling.
2. CIFAR-10 is a standardized dataset consisting of (32×
32) RGB images separated into 10 classes. The training
set contains 50,000 images, while the test set has 10,000
images. Our experiments use the 7-layer CNN architecture
speciﬁed in MiniONN [Liu+17a].
In our experiments, MUSE runs all of its various prepro-
cessing components in parallel using a work-stealing thread-
pool with 8 threads. For simplicity, in Table 3 we provide
9https://github.com/GaloisInc/fancy-garbling/
10https://github.com/data61/MP-SPDZ
microbenchmarks for each component using a static thread
allocation that closely reﬂects the allocation used during ac-
tual execution. The current end-to-end numbers for MUSE
are estimates as we have implemented all of the individual
components, but are still in the process of integrating them
into a full system. We carefully tested CPU time, memory
usage, and bandwidth usage of each component to ensure that
our estimated end-to-end numbers are accurate.
Baselines.
Since there are no specialized protocols for
client-malicious secure inference, we chose to use generic
MPC frameworks as our baselines to compare MUSE against:
maliciously-secure Overdrive [Kel+18] and Overdrive with
our client-malicious optimizations. We used MP-SDPZ’s im-
plementation of the maliciously-secure Overdrive protocol,
and estimated the total runtime and communication costs
of client-malicious Overdrive using microbenchmarks from
MUSE’s triple generation, MUSE’s input authentication, and
MP-SPDZ.
Additionally, we use microbenchmarks in Table 3 to demon-
strate the concrete costs of strengthening each individual com-
ponent of MUSE from semi-honest to client-malicious secu-
rity. As a semi-honest baseline, we chose to compare against
DELPHI and not against more recent works which offer better
performance [Rat+20] because (1) these newer works use dif-
ferent techniques for both linear and non-linear layers, which
would make isolating the cost of upgrading security difﬁcult,
and (2) it is unclear how to upgrade their semi-honest proto-
cols to achieve client-malicious security in an efﬁcient way.
6.3 Microbenchmarks
In Table 3 we compare microbenchmarks for MUSE and DEL-
PHI on the MNIST and CIFAR-10 networks using a simi-
lar number of threads to demonstrate the concrete costs of
strengthening each component of DELPHI to client-malicious
security.
6.3.1 Preprocessing phase
The primary difference between MUSE and DELPHI occurs
in the preprocessing phase.
USENIX Association
30th USENIX Security Symposium    2211
(a) MNIST Preprocessing Time
(b) CIFAR-10 Preprocessing Time
(c) Online Time
Figure 8: Comparison of execution times between MUSE, Overdrive, and client-malicious Overdrive
(a) MNIST Preprocessing Communication
(b) CIFAR-10 Preprocessing Communication
(c) Online Communication
Figure 9: Comparison of communication cost between MUSE, Overdrive, and client-malicious Overdrive
Linear layers. As discussed in Section 5.1, the primary
difference in how DELPHI and MUSE preprocess linear layers
lies in the fact that the former uses a plain correlations gen-
erator (CG), while MUSE use an authenticated correlations
generator (ACG). Because the ACG requires additional ho-
momorphic operations and zero-knowledge proofs, we should
expect MUSE to be slightly slower than DELPHI and require
slightly more communication. In Table 3 we observe that this
is precisely the case.
Non-linear layers. To preprocess the non-linear layers in
DELPHI, the server garbles a circuit corresponding to ReLU
and sends to the client. The two parties than engage in an
oblivious transfer whereby the client learns the garbled labels
corresponding to their input.
In MUSE, a number of modiﬁcations to this procedure must
be made. First, MUSE cannot use simple oblivious transfer
and must opt for the much more expensive CDS protocol to
ensure the client receives the correct garbled labels. Second,
as detailed in Remark 5.3, MUSE pushes some checks from
the CDS to the online garbled circuits which roughly doubles
the number of AND gates in the circuit.
As a result, we should expect a 2×–3× increase in latency
and communication for the garbling in MUSE when compared
to DELPHI, and a much higher cost for the CDS compared to
oblivious transfer. Table 3 validates these hypotheses.
6.3.2 Online phase
MUSE retains the same structure for the online phase, but has
a few small additions. For subsequent linear layers, MUSE
requires the client to send additional MAC shares (see Re-
mark 5.2). For non-linear layers, MUSE requires an extra hash
key to be sent, and the circuit being evaluated is roughly twice
the size as the one in DELPHI.
As a result, we should expect the garbled circuit evaluation
time to be the only signiﬁcant difference in online runtime
between MUSE and DELPHI, and for MUSE to have slightly
higher communication. In Table 3, we see that the difference
in online runtime is 1.7×–2.2× and the communication dif-
ference is approximately 1.4×.
In conclusion, MUSE’s overhead when compared to DEL-
PHI is minimal in every component except the CDS. MUSE’s
online phase outperforms all prior two-party semi-honest
works listed in Table 1 besides DELPHI, CrypTFlow2
[Rat+20], and XONN [Ria+19].
6.4 Full system comparisons
Fig. 8 and Fig. 9 demonstrate how MUSE performs against ma-
licious Overdrive and client-malicious Overdrive. Note that
our client-malicious optimizations for Overdrive don’t affect
the online phase which is why we exclude client-malicious
Overdrive in the online ﬁgures.
In summary, MUSE’s preprocessing is 13.4×–21× faster
and reduces communication by 2×–3.6× compared to stan-
dard Overdrive. For client-malicious Overdrive, MUSE’s pre-
processing phase is 6.4×–7× faster. For the smaller MNIST
network, the communication cost of MUSE is slightly higher
than that of client-malicious Overdrive (due to a constant
2212    30th USENIX Security Symposium
USENIX Association
020406080100120Execution time (s)OverdriveClient-malicious OverdriveMuse05001000150020002500Execution time (s)OverdriveClient-malicious OverdriveMuseMiniONNMNIST010203040506070Total execution time (s)MuseOverdrive0246Communication (GB)OverdriveClient-malicious OverdriveMuse04080120Communication (GB)OverdriveClient-malicious OverdriveMuseMiniONNMNIST02004006008001000Online communication (MB)MuseOverdrive7 Related work
7.1 Model extraction attacks
A number of recent works extract convolutional neural net-
works (CNNs) [Tra+16; Mil+19; Jag+20; Rol+20; Car+20]
given oracle access to a neural network. Unlike our attack,
these works do not exploit properties of any secure inference
protocol (and indeed do not rely on the existence of these),
but require a much larger number of queries. We compare
against the state-of-the-art attack [Car+20] in Section 2.3.
Mitigations. While MUSE protects against our attack, it
does not defend against attacks that leverage only the predic-
tion result. Mitigations fall into two camps: those that inspect
prediction queries [Kes+18; Juu+19], and those that try to
instead modify the network to make it resilient to extraction
[Tra+16; Lee+19]. While the latter kind of defense can be ap-
plied independently of secure inference, adapting the ﬁrst kind
of defense to work with secure inference protocols is tricky,
because it requires inspecting the client’s queries, which can
violate privacy guarantees.
7.2 Secure inference protocols
A number of recent works have attempted to design special-
ized protocols for performing secure inference. These pro-
tocols achieve efﬁciency by combining secure computation
techniques such as homomorphic encryption [Gen09b], Yao’s
garbled circuits [Yao86], and homomorphic secret sharing
[Boy+17] with various modiﬁcations such as approximating
ReLU activations with low-degree polynomials or binariz-
ing (quantizing to one bit of accuracy) network weights. See
Table 1 for a high-level overview of these protocols.
While these works have improved on latency and communi-
cation costs by orders of magnitude, all of the two-party pro-
tocols in Table 1 assume a semi-honest adversary. Currently-
existing maliciously-secure inference protocols generally fall
into the following categories: 3PC-based protocols, generic
MPC frameworks, TEE-based protocols, and GC-based proto-
cols. In the remainder of the section we discuss each of these
categories:
3PC-based protocols. Recent works have explored how
the addition of a third party can greatly improve efﬁciency
for secure machine learning applications [Moh+17; Ria+18;
Moh+18; Wag+19; Wag+21; Kum+20]. Many of these pro-
tocols also allow for easy extensions to handle malicious
adversaries [Moh+18; Wag+19; Wag+21]. These extensions
are made possible by the fact that these works assume only
one of the parties is corrupted. In other words, these works
consider honest majority malicious security. On the other
hand, MUSE addresses the fundamentally more difﬁcult prob-
lem of a dishonest majority. While having three non-colluding
parties is convenient from a protocol design perspective, in
practice, it is difﬁcult to setup such a third party running in a
separate trust domain out of the control of the server or client.
Figure 10: Triple Generation amortized on a batch of 10,000,000
triples over a 44 bit prime ﬁeld with 40 bit statistical security.
Threat Model
Malicious
Client-mal.
Client Inputs
time (s)
comm. (MB)
Server Inputs
time (s)
comm. (MB)
12.11
7.406
90
320
12.11
0.32
90
20
Table 4: Input Authentication on 1,000,000 inputs over a 44 bit
prime ﬁeld with 40 bit statistical security using a single thread.
Relies on the LTME Assumption.
Improvements to Overdrive