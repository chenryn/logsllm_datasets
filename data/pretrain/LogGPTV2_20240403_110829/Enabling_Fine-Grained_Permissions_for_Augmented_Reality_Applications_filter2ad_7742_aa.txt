# Enabling Fine-Grained Permissions for Augmented Reality Applications with Recognizers

**Authors:**
- Suman Jana, The University of Texas at Austin
- David Molnar, Microsoft Research
- Alexander Moshchuk, Microsoft Research
- Alan Dunn, The University of Texas at Austin
- Benjamin Livshits, Microsoft Research
- Helen J. Wang, Microsoft Research
- Eyal Ofek, Microsoft Research

**Abstract:**
Augmented reality (AR) applications sense the environment and render virtual objects on human senses. Examples include smartphone applications that annotate storefronts with reviews and Xbox Kinect games that show avatars mimicking human movements. Current operating systems (OSes) do not provide specialized support for such applications, leading to coarse-grained permissions. Applications must request access to raw sensor data, such as video and audio, which exposes significant additional information beyond what is necessary, including sensitive data like the user's location, face, or surroundings.

To address this, we introduce a new OS abstraction: the recognizer. A recognizer processes raw sensor data and exposes higher-level objects, such as skeletons or faces, to applications. We propose a fine-grained permission system where applications request permissions at the granularity of these recognizer objects. Our analysis of 87 shipping AR applications indicates that a set of four core recognizers covers almost all current apps. Additionally, we introduce privacy goggles, a visualization tool that shows users the sensitive data exposed to an application. Surveys of 962 people establish a clear "privacy ordering" over recognizers and demonstrate the effectiveness of privacy goggles in communicating application capabilities.

We have built a prototype on Windows that exposes nine recognizers to applications, including the Kinect skeleton tracker. Our prototype incurs negligible overhead for single applications while improving performance for concurrent applications and enabling secure offloading of heavyweight recognizer computation.

## 1. Introduction

Augmented reality (AR) applications take natural user interactions (such as gestures, voice, and eye gaze) as input and overlay digital content on top of the real world. For example, mobile AR browsers like Layar and Junaio allow users to see annotations about a magazine article or a storefront. Furniture applications on the iPad let users preview how a couch would look in a real room. The Xbox Kinect, with over 19 million units sold, allows developers to overlay avatars on a user's pose, creating new kinds of games and natural user interfaces. Even heads-up displays, once restricted to academic and limited military/industrial use, are now reaching consumers with products like Google Glass.

Today's AR applications are monolithic, performing sensing, rendering, and user input interpretation themselves, often aided by user-space libraries or cloud services. Because current OSes are not designed with AR in mind, they offer only coarse-grained access to sensor streams, such as video or audio data. This raises privacy concerns, as it is difficult to build applications that follow the principle of least privilege, having access to only the information they need and no more.

### Motivating Example

Figure 1 illustrates the problem with coarse-grained abstractions in today's AR applications. It shows a video frame captured from a Kinect, containing the user's face, private whiteboard drawings, and a bottle of medicine. An application must ask for raw camera access to perform video-based AR, which means the application will see all sensitive information in the frame. However, many applications do not need this sensitive information to function. For instance, the "Kinect Adventures!" game (Figure 2) only needs body position to render an avatar and simulate game physics.

## 2. AR Overview

We characterize AR applications using a pipeline shown in Figure 5. First, the sensing stage acquires raw video, audio, and other sensor data from platform hardware. Next, the recognition stage applies object recognition algorithms to the raw sensor data. For example, voice recognition may run on audio to look for specific keywords, or a skeleton detector may estimate the presence and pose of a human in the video. The output of the recognition stage is a set of software objects that "mirror" recognized real-world objects.

In the transformation stage, applications consume the recognized objects and add virtual objects of their own. Finally, the presentation stage creates the final view for the user, resolving any remaining logical conflicts and checking the desired placement of objects. Today, this rendering is done using standard OS abstractions, such as DirectX or OpenGL.

## 3. The Recognizer OS Abstraction

We propose a new OS abstraction called a recognizer. A recognizer is an OS component that takes a sensor stream, such as video or audio, and recognizes objects in the stream. For example, a recognizer for face detection (Figure 6) takes a raw RGB image and outputs a face object if a face is present. The recognizer abstraction captures that most AR applications operate on specific entities with high-level semantics, such as the face or the skeleton. To enable least privilege, the OS exposes higher-level entities through recognizers.

Recognizers create events when objects are recognized. These events contain structured data encoding information about the objects. Each recognizer declares a public type for this structured data, available to applications. Applications register callbacks with the OS that fire for events from a particular recognizer; the callbacks accept arguments of the specified type. For example, the recognizer in Figure 6 returns a list of points corresponding to facial features and an RGB texture for the face itself. A callback for an application receives the points and texture but not the rest of the raw RGB frame.

The recognizer is the unit of permission granting. Every time an application attempts to register a callback with the OS for a specific recognizer, the application must be authorized by the user. Different applications can, depending on the user's authorization, have access to different recognizers, providing a fine-grained permission mechanism.

Users can restrict applications to only "see" a subset of the raw data stream. For example, Figure 6 shows a bounding box in the raw RGB frame that can be associated with a specific application.

## 4. Implementation

We have implemented a prototype of our system on Windows, using the Kinect for Windows SDK. Our system includes nine recognizers, including face detection, skeleton detection, and a "plane recognizer" built on top of KinectFusion. Our prototype incurs negligible overhead for single applications while improving performance for concurrent applications and enabling secure offloading of heavyweight recognizer computation.

## 5. Evaluation

We evaluate our system in several ways:
- **Privacy Goggles:** We introduce privacy goggles, a visualization tool that shows users the sensitive data exposed to an application. Surveys of 462 people show that privacy goggles are effective at communicating capabilities to users.
- **Recognizer Errors:** We address recognizer errors with a new OS component, recognizer error correction. We evaluate three approaches: blurring, frame subtraction, and recognizer combination. Our techniques reduce false positives across a set of seven recognizers implemented in the OpenCV library.
- **Performance:** Our implementation has negligible overhead for single applications, yet greatly increases performance for concurrent applications and allows the OS to offload heavyweight recognizer computation.

## 6. Related Work and Future Directions

We discuss related work on fine-grained permission systems and future directions for our research, including extending the recognizer abstraction to other domains and further refining the permission model.

## 7. Conclusion

In conclusion, we introduce a new OS abstraction, the recognizer, which enables fine-grained permissions for AR applications. Our system improves privacy, performance, and user understanding of application capabilities. Future work will focus on expanding the recognizer abstraction and refining the permission model.

---

This revised version aims to make the text more coherent, professional, and easier to understand, with a clear structure and flow.