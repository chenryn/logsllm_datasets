0
0
1
0
8
0
6
0
4
0
2
0
VRASED
SMART
SANCUS
VRASED
SMART
SANCUS
(a) Additional HW overhead (%)
in Number of Look-Up Tables
(b) Additional HW overhead (%)
in Number of Registers
0
0
5
1
0
0
0
1
0
0
5
0
8
6
4
2
0
VRASED
SMART
SANCUS
VRASED
SMART
SANCUS
(c) Additional Verilog Lines of
Code
(d) Time to attest 4KB (in millions
of CPU cycles)
SHA-256, Poly1305, AES and ECDSA. More recently, Zinzin-
dohoué, et al. [52] developed HACL*, a veriﬁed cryptographic
library containing the entire cryptographic API of NaCl [5].
As discussed earlier, HACL*’s veriﬁed HMAC forms the core
of VRASED’s software component.
Larger security-critical systems have also been successfully
veriﬁed. For example, Bhargavan [6] implemented the TLS
protocol with veriﬁed cryptographic security. CompCert [33]
is a C compiler that is formally veriﬁed to preserve C code se-
mantics in generated assembly code. Klein et al. [29] designed
and proved functional correctness of seL4 – the ﬁrst veri-
ﬁed general-purpose microkernel. More recently, Tuncay et al.
veriﬁed a design for Android OS App permissions model [48].
The importance of verifying RA has been recently acknowl-
edged by Lugou et al. [36], which discussed methodologies
for speciﬁcally verifying HW/SW RA co-designs. A follow-on
result proposed the SMASH-UP tool [37]. By modeling a hard-
ware abstraction, SMASH-UP allows automatic conversion of
assembly instructions to the effects on hardware representa-
tion. Similarly, Cabodi et al. [11, 12] discussed the ﬁrst steps
towards formalizing hybrid RA properties. However, none of
these results yielded a fully veriﬁed (and publicly available)
RA architecture, such as VRASED.
Figure 13: Comparison between RA architectures targeting
low-end devices
8 Conclusion
at [22]). Compared to VRASED, SANCUS requires 12× more
Look-Up Tables, 22× more registers, and its (unveriﬁed) TCB
is 2.5 times larger in lines of Verilog code. This comparison
demonstrates the cost of relying on a HW-only approach even
when designed for minimality. SMART’s overhead is slightly
smaller than that of VRASED due to lack of DMA support. In
terms of attestation execution time, SMART is the slowest, re-
quiring 9.2M clock cycles to attest 4KB of memory. SANCUS
achieves the fastest attestation time (1.3M cycles) due to the
HW implementation of SPONGENT-128/128/8. VRASED sits
in between the two with a total attestation time of 3.6M cycles.
7 Related Work
We are unaware of any previous work that yielded a formally
veriﬁed RA design (RA architectures are overviewed in Sec-
tion 2.1). To the best of our knowledge, VRASED is the ﬁrst
veriﬁcation of a security service implemented as HW/SW co-
design. Nevertheless, formal veriﬁcation has been widely used
as the de facto means to guarantee that a system is free of
implementation errors and bugs. In recent years, several efforts
focused on verifying security-critical systems.
In terms of cryptographic primitives, Hawblitzel et al. [23]
veriﬁed new implementations of SHA, HMAC, and RSA.
Beringer et al. [4] veriﬁed the Open-SSL SHA-256 implemen-
tation. Bond et al. [8] veriﬁed an assembly implementation of
This paper presents VRASED – the ﬁrst formally veriﬁed RA
method that uses a veriﬁed cryptographic software implementa-
tion and combines it with a veriﬁed hardware design to guaran-
tee correct implementation of RA security properties. VRASED
is also the ﬁrst veriﬁed security service implemented as a
HW/SW co-design. VRASED was designed with simplicity
and minimality in mind. It results in efﬁcient computation
and low hardware cost, realistic even for low-end embedded
systems. VRASED’s practicality is demonstrated via publicly
available implementation using the low-end MSP430 platform.
The design and veriﬁcation methodology presented in this pa-
per can be extended to other MCU architectures. We believe
that this work represents an important and timely advance in
embedded systems security, especially, with the rise of hetero-
geneous ecosystems of (inter-)connected IoT devices.
The most natural direction for future work is to adapt
VRASED to other MCU architectures. Such an effort could
follow the same veriﬁcation methodology presented in this
paper. It would involve: (1) mapping MCUs speciﬁcations
to a set of axioms (as we did for MSP430 in Section 3), and
(2) adapting the proofs by modifying the LTL Speciﬁcations
and hardware design (as in Section 4) accordingly. A second
direction is to extend VRASED’s capabilities to include and
verify other trusted computing services such as secure updates,
secure deletion, and remote code execution. It would also be
interesting to verify and implement other RA designs with
different requirements and trade-offs, such as software- and
hardware-based techniques. In the same vein, one promising
1442    28th USENIX Security Symposium
USENIX Association
direction would be to verify HYDRA RA architecture [20],
which builds on top of the formally veriﬁed seL4 [29]
microkernel. Finally, the optimization of VRASED’s HMAC,
with respect to computation and memory allocation, while
retaining its veriﬁed properties, is an interesting open problem.
Acknowledgments: UC Irvine authors’ work was supported
in part by DHS, under subcontract from HRL Laboratories,
and ARO under contract: W911NF-16-1-0536, as well as NSF
WiFiUS Program Award #: 1702911. The authors thank the
paper’s shepherd, Stephen McCamant, and the anonymous
reviewers for their valuable comments.
References
[1] VRASED source code. https://github.com/sprout-uci/
vrased, 2019.
[2] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallit-
sis, et al. Understanding the mirai botnet. In USENIX Security, 2017.
[3] Arm Ltd. Arm TrustZone. https://www.arm.com/products/
security-on-arm/trustzone, 2018.
[4] L. Beringer, A. Petcher, Q. Y. Katherine, and A. W. Appel. Veriﬁed
In USENIX Security,
correctness and security of OpenSSL HMAC.
2015.
[5] D. J. Bernstein, T. Lange, and P. Schwabe. The security impact of a new
cryptographic library. In International Conference on Cryptology and
Information Security in Latin America, 2012.
[6] K. Bhargavan, C. Fournet, M. Kohlweiss, A. Pironti, and P.-Y. Strub.
Implementing TLS with veriﬁed cryptographic security. In IEEE S&P,
2013.
[7] A. Bogdanov, M. Knezevic, G. Leander, D. Toz, K. Varici, and I. Ver-
bauwhede. Spongent: The design space of lightweight cryptographic
hashing. IEEE Transactions on Computers, 62, 2013.
[8] B. Bond, C. Hawblitzel, M. Kapritsos, K. R. M. Leino, J. R. Lorch,
B. Parno, A. Rane, S. Setty, and L. Thompson. Vale: Verifying high-
performance cryptographic assembly code. In USENIX Security, 2017.
[17] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore,
M. Roveri, R. Sebastiani, and A. Tacchella. NuSMV 2: An opensource
tool for symbolic model checking. In CAV, 2002.
[18] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, M. Steiner, and
G. Tsudik. Formally veriﬁed hardware/software co-design for remote
attestation. arXiv preprint arXiv:1811.00175, 2018.
[19] A. Duret-Lutz, A. Lewkowicz, A. Fauchille, T. Michaud, E. Renault, and
L. Xu. Spot 2.0—a framework for ltl and ω-automata manipulation. In
ATVA, 2016.
[20] K. Eldefrawy, N. Rattanavipanon, and G. Tsudik. HYDRA: hybrid
design for remote attestation (using a formally veriﬁed microkernel). In
WiSec, 2017.
[21] K. Eldefrawy, G. Tsudik, A. Francillon, and D. Perito. SMART: Secure
and minimal architecture for (establishing dynamic) root of trust. In
NDSS, 2012.
[22] O. Girard. openMSP430, 2009.
[23] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang,
and B. Zill. Ironclad apps: End-to-end security via automated full-system
veriﬁcation. In USENIX OSDI, 2014.
[24] G. Hinterwälder, A. Moradi, M. Hutter, P. Schwabe, and C. Paar. Full-
size high-security ECC implementation on MSP430 microcontrollers.
In International Conference on Cryptology and Information Security in
Latin America, pages 31–47. Springer, 2014.
[25] A. Ibrahim, A.-R. Sadeghi, and S. Zeitouni. SeED: secure non-interactive
attestation for embedded devices. In ACM WiSec, 2017.
[26] T.
Instruments.
ment mcus.
msp430-ultra-low-power-mcus/overview.html.
Msp430 ultra-low-power sensing & measure-
http://www.ti.com/microcontrollers/
[27] Intel.
Intel Software Guard Extensions (Intel SGX). https://
software.intel.com/en-us/sgx.
[28] A. Irfan, A. Cimatti, A. Griggio, M. Roveri, and R. Sebastiani. Ver-
ilog2SMV: A tool for word-level veriﬁcation. In DATE, 2016.
[29] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin,
D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch,
and S. Winwood. seL4: Formal veriﬁcation of an OS kernel. In SOSP,
2009.
[30] P. Koeberl, S. Schulz, A.-R. Sadeghi, and V. Varadharajan. TrustLite: A
security architecture for tiny embedded devices. In EuroSys, 2014.
[9] F. Brasser, B. El Mahjoub, A.-R. Sadeghi, C. Wachsmann, and P. Koeberl.
TyTAN: tiny trust anchor for tiny devices. In DAC, 2015.
[31] X. Kovah, C. Kallenberg, C. Weathers, A. Herzog, M. Albin, and J. But-
terworth. New results for timing-based attestation. In IEEE S&P, 2012.
[10] F. Brasser, A.-R. Sadeghi, and G. Tsudik. Remote attestation for low-end
embedded devices: the prover’s perspective. In DAC, 2016.
[11] G. Cabodi, P. Camurati, S. F. Finocchiaro, C. Loiacono, F. Savarese,
and D. Vendraminetto. Secure embedded architectures: Taint properties
veriﬁcation. In DAS, 2016.
[32] H. Krawczyk and P. Eronen. HMAC-based extract-and-expand key
derivation function (HKDF). Internet Request for Comment RFC 5869,
Internet Engineering Task Force, May 2010.
[33] X. Leroy. Formal veriﬁcation of a realistic compiler. Communications
of the ACM, 52(7):107–115, 2009.
[12] G. Cabodi, P. Camurati, C. Loiacono, G. Pipitone, F. Savarese, and
D. Vendraminetto. Formal veriﬁcation of embedded systems for remote
attestation. WSEAS Transactions on Computers, 14, 2015.
[34] Y. Li, Y. Cheng, V. Gligor, and A. Perrig. Establishing software-only root
of trust on embedded systems: Facts and ﬁction. In Security Protocols—
22nd International Workshop, 2015.
[13] X. Carpent, K. Eldefrawy, N. Rattanavipanon, A.-R. Sadeghi, and
G. Tsudik. Reconciling remote attestation and safety-critical opera-
tion on simple iot devices. In DAC, 2018.
[14] X. Carpent, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik. Tempo-
ral consistency of integrity-ensuring computations and applications to
embedded systems security. In ASIACCS, 2018.
[15] X. Carpent, N. Rattanavipanon, and G. Tsudik. ERASMUS: Efﬁcient
In
remote attestation via self-measurement for unattended settings.
DATE, 2018.
[16] X. Carpent, N. Rattanavipanon, and G. Tsudik. Remote attestation of iot
devices via SMARM: Shufﬂed measurements against roving malware.
In IEEE HOST, 2018.
[35] Y. Li, J. M. McCune, and A. Perrig. VIPER: verifying the integrity of
peripherals’ ﬁrmware. In CCS, 2011.
[36] F. Lugou, L. Apvrille, and A. Francillon. Toward a methodology for
uniﬁed veriﬁcation of hardware/software co-designs. Journal of Crypto-
graphic Engineering, 2016.
[37] F. Lugou, L. Apvrille, and A. Francillon. Smashup: a toolchain for uniﬁed
veriﬁcation of hardware/software co-designs. Journal of Cryptographic
Engineering, 7(1):63–74, 2017.
[38] J. Noorman, J. V. Bulck, J. T. Mühlberg, F. Piessens, P. Maene, B. Preneel,
I. Verbauwhede, J. Götzfried, T. Müller, and F. Freiling. Sancus 2.0: A
low-cost security architecture for iot devices. ACM Trans. Priv. Secur.,
20(3):7:1–7:33, July 2017.
USENIX Association
28th USENIX Security Symposium    1443
[39] I. D. O. Nunes, G. Dessouky, A. Ibrahim, N. Rattanavipanon, A.-R.
Sadeghi, and G. Tsudik. Towards systematic design of collective remote
attestation protocols. In ICDCS, 2019.
[40] D. Perito and G. Tsudik. Secure code update for embedded devices via
proofs of secure erasure. In ESORICS, 2010.
[41] J. Protzenko, J.-K. Zinzindohoué, A. Rastogi, T. Ramananandro, P. Wang,
S. Zanella-Béguelin, A. Delignat-Lavaud, C. Hri¸tcu, K. Bhargavan,
C. Fournet, et al. Veriﬁed low-level programming embedded in F*.
Proceedings of the ACM on Programming Languages, 1, 2017.
[42] S. Ravi, A. Raghunathan, and S. Chakradhar. Tamper resistance mecha-
nisms for secure embedded systems. In VLSI Design, 2004.
[43] A. Seshadri, M. Luk, A. Perrig, L. van Doorn, and P. Khosla. Scuba:
Secure code update by attestation in sensor networks. In ACM workshop
on Wireless security, 2006.
[44] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla. Pio-
neer: Verifying code integrity and enforcing untampered code execution
on legacy systems. ACM SIGOPS Operating Systems Review, December
2005.
[45] L. Simon, D. Chisnall, and R. Anderson. What you get is what you c:
Controlling side effects in mainstream c compilers. In IEEE EuroS&P,
2018.
A.2 Machine Model
To prove that VRASED’s design satisﬁes end-to-end deﬁnitions
of soundness and security for RA, we start by formally deﬁning
(in LTL) memory and execution models corresponding to the
architecture introduced in Section 3.
Deﬁnition 4 (Memory model).
1. K is stored in ROM ↔ G : {KR = K }
2. SW-Att is stored in ROM ↔ G : {CR = SW-Att}
3. MR, CR, AR, KR, and X S are non-overlapping memory regions
The memory model in Deﬁnition 4 captures that KR and CR
are ROM regions, and are thus immutable. Hence, the values
stored in those regions always correspond to K and SW-Att
code, respectively. Finally, the memory model states that MR,
CR, AR, KR, and X S are disjoint regions in the memory layout,
corresponding to the architecture in Figure 3.
[46] Texas Instruments. MSP430 GCC user’s guide, 2016.
[47] Trusted Computing Group. Trusted platform module (tpm), 2017.
Deﬁnition 5 (Execution model).
[48] G. S. Tuncay, S. Demetriou, K. Ganju, and C. A. Gunter. Resolving the