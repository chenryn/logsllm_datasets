whether measurement Z is secured. Then, the following two
conditions ensure if measurement Z is secured:
∀I∈IedSet∀Z (Z ∈ MsrSet I ∧ SecuredDelivery I ) → SZ
If a measurement is secured, the variables corresponding to
this measurement can be securely estimated. If SE X denotes
whether state X is securely estimated, then:
∀Z ∀X∈StateSet Z SZ → SE X
We identify the set of securely delivered unique measure-
ments (with respect to U M srSetE). If this set is denoted by
SecUMsr E, it is formed as follows:
∀E ∃Z∈UMsrSet E SZ → SecUMsr E
The secured observability (SecuredObservability) ensures
that the minimum number (i.e., at least n) of secured measure-
ments are received and all states are covered by these secured
measurements. Thus,
the system is securely unobservable
(¬SecuredObservability) when either or both of these two
conditions fail:
¬SecuredObservability →
(∃X ¬SE X ) ∨ (
(cid:88)
SecUMsr E < n)
k−Resilient Secured Observability:
E
This constraint veriﬁes whether secured observability is
ensured even if k ﬁeld devices (or k1 IEDs and k2 RTUs) are
unavailable due to technical failures or cyber attacks. Similar
to the k−resilient observability, we verify these properties
by searching for threat vectors under the speciﬁcation of
maximum k failures.
When the number of unavailable devices is no larger than
k devices (or k1 IEDs and k2 RTUs), we formalize the
threat against the k−resilient secured observability constraint
(¬ResilientSecuredObservability) as follows:
¬SecuredObservability
→ ¬ResilientSecuredObservability
The threat vector (V) includes a list of devices such that if
they fail, the secured observability is impossible. In this way,
this proposed modeling synthesizes attack vectors and, thus,
it helps us learn the dependability breach points.
E. Formal Modeling of k, r−Resilient Bad Data Detectability
The obtained measurements for observability must be able
to detect bad data. It is worth mentioning that a measurement
can be delivered in a secured way, but the data itself can
be incorrect or noisy due to random variations and other
inaccuracies at the sensor/IED corresponding to this mea-
surement, or if the measuring device is compromised. Such
1≤i≤N
((N − (cid:88)
((N1 − (cid:88)
((N2 − (cid:88)
1≤i≤N1
1≤i≤N2
Node i) ≤ k) ∧ ¬SecuredObservability
→ ¬ResilientSecuredObservability
(Node i × Ied i)) ≤ k1)∧
(Node i × Rtu i)) ≤ k1)∧
noisy measurements are considered as outliers with respect
to the rest, since usually a few measurements can have
such alterations. There are bad data detection algorithms to
detect such bad measurements and eliminate them from the
estimation process. We verify the resiliency of the bad data
detectability in a formal way as follows.
r-Bad Data Detectability:
If there is a single measurement associated with a state, the
measurement is a critical one. When such a measurement is
bad, it is not possible to detect that. Therefore, in order to de-
tect bad data, it is required to have at least two measurements
corresponding to each state, if we assume no more than one
measurement among them can be bad at a time. If we assume
r measurements can be corrupted at a time, then it is r-bad
data detectability. It is worth mentioning that we only rely
on secured measurements for detecting the bad data, since
non-secured measurements cannot be trusted [6]. Similar to
the resilient observability, we verify the bad data detectability
from the threat veriﬁcation point of view.
If a measurement is secured, the state corresponding to this
measurement can be securely estimated. We deﬁne SE X,Z as
a Boolean variable that denotes whether state X is securely
estimated by measurement Z. The following two equations
valuate SE X,Z with respect to SZ:
∀Z ∀X∈StateSet Z SZ → SE X,Z
∀Z ∀X∈StateSet Z ¬SZ → ¬SE X,Z
Now,
a
bad measurement
¬BadDataDetectability) if the following condition holds:
is
not
detectable
(i.e.,
¬BadDataDetectability →
SE X,Z < r + 1)
(cid:88)
Z
∃X (
k, r−Resilient Bad Data Detectability Constraint:
We deﬁne k, r−resilient bad data detectability as if k
devices (RTUs or IEDs) are unavailable, the bad data is still
detectable even if r measurements are corrupted. Now, we
verify the threats with respect to this requirement by extending
the previous equation:
((N − (cid:88)
1≤i≤N
Node i) ≤ k) ∧ ¬BadDataDetectability
→ ¬ResilientBadDataDetectability
We can extend this k resiliency threat veriﬁcation to
k1, k2−resiliency veriﬁcation.
IV. A CASE STUDY
In this section, we brieﬂy discuss the implementation of the
model and illustrate the model’s execution with an example.
Fig. 3. An example SCADA topology of a 5-bus power grid.
A. Implementation
We use SMT logics [1] to encode the formalizations pre-
sented in the previous section. We use Boolean and integer
terms in encoding. It is solved using Z3, an efﬁcient SMT
solver [5], [7]. The solution to the model gives a result as sat
or unsat. In the case of sat, the solver provides elaborate result,
speciﬁcally the values of the terms. From these valuations,
we can ﬁnd out the detailed scenario that makes the threat
possible. For example, the result (particularly, Node i terms)
shows us the devices (IEDs and/or RTUs) that are unavailable,
and as a result, the (secured) observability is impossible. In the
case of unsat, we can conclude that there is no threat scenario,
i.e., the failures of devices no more than given thresholds, that
can make system unobservable.
B. Example: Scenario 1
This example considers a 5-bus SCADA system as shown
in Fig. 3. This is an subsystem taken from the IEEE 14-Bus
Test System [8]. The input is partially shown in Table II. The
input includes primarily the Jacobian matrix corresponding to
the bus system, the connectivity between the communicating
devices, the association of the measurements with the IEDs,
and security proﬁles of each communicating host pair. Each
row of the Jacobian matrix corresponds to a measurement.
The ﬁrst row corresponds to measurement 1, and subsequent
rows correspond to following measurements. Each row has
5 entries (columns) which correspond to 5 states/buses. We
assume that the measurements are recorded by different IEDs
to the MTU (i.e.,
only, and these measurements are sent
the SCADA server at the control center) through RTUs. The
server needs these measurements to estimate the current states
of the system. The resiliency requirement specify that the
secured observability must be satisﬁed even if one IED and one
RTU are unavailable (due to having suffered from technical
Fig. 4. The modiﬁed SCADA topology of the 5-bus power grid.
failures or cyber attacks). In this example, we demonstrate
the k1, k2−resilient observability constraint. Thus, the security
properties will not be used in this case.
The solution to the formal model corresponding to this
example returns unsat. That is, there is no resiliency threat
vector that can make the system unobservable. The system
is (1, 1)−resilient observable. However, if we increase the
resiliency speciﬁcation to (2, 1), the model now provides a
resiliency threat vector. The result shows that if IED 2, IED
7, and RTU 11 are unavailable, then the observability fails. It
is worth mentioning that there are another 8 different threat
vectors in this scenario that can make the system unobservable.
In the case of IED failures only, the system can tolerate up to
the failures of 3 IEDs.
Let us change the SCADA topology to Fig. 4. The difference
with the previous topology is that RTU 9 is now connected to
G 5 G 1 G 2 3 4 2 1 5 7 4 6 3 1 2 3 5 9 7 4 6 8 10 11 12 13 14 MTU 13 rtu12 Ied 8 rtu11 rtu9 rtu10 Ied 7 Ied 4 Ied 1 Ied 3 Ied 2 Ied 6 Ied 5 # - Bus #’s - Transmission Line #’s - Power Flow Measurement #’s # # - Consumption Measurement #’s # Router 14 G 5 G 1 G 2 3 4 2 1 5 7 4 6 3 1 2 3 5 9 7 4 6 8 10 11 12 13 14 MTU 13 rtu12 Ied 8 rtu11 rtu9 rtu10 Ied 7 Ied 4 Ied 1 Ied 3 Ied 2 Ied 6 Ied 5 # - Bus #’s - Transmission Line #’s - Power Flow Measurement #’s # # - Consumption Measurement #’s # Router 14 TABLE II
THE INPUT TO THE CASE STUDY
# Number of states and measurements
5 14
# Jacobian matrix (mapping between the states and the measurements)
0 -5.05 5.05 0 0
0 -5.67 0 5.67 0
0 -5.75 0 0 5.75
0 0 0 -23.75 23.75
16.9 -16.9 0 0 0
4.48 0 0 0 -4.48
0 5.67 0 -5.67 0
0 5.75 0 0 -5.75
0 0 5.85 -5.85 0
0 0 0 23.75 -23.75
-16.9 33.37 -5.05 -5. 67 -5.75
0 -5.05 10.9 -5.85 0
0 -5.67 -5.85 41.85 -23.75
-4.48 -5.75 0 -23.75 37.95
# Number of each type of devices in the topology
# IEDs (Id 1-8), RTUs (Id 9-12), MTU (Id 13), Router (Id 14)
8 4 1 1
# Topology (Links)
13 #Number of communicating links
1 9
2 9
3 9
4 10
5 11
6 11
7 12
8 12
9 14
10 11
11 14
12 14
# Measurements corresponding to IEDs
1 1 2
2 3 5
3 11
4 12
5 4 7 9
6 13
7 6 8 10
8 14
# Security proﬁle (if exists) between the communicating entities
11 # Number entries of security proﬁles
1 9 hmac 128
2 9 chap 64 sha2 128
3 9 chap 64 sha2 128
5 11 chap 64 sha2 256
6 11 chap 64 sha2 256
7 12 chap 64 sha2 128
8 12 chap 64 sha2 128
9 13 rsa 2048 aes 256
10 11 hmac 128
11 13 rsa 4096 aes 256
12 13 rsa 2048 aes 256
# k−resiliency requirements (IED, RTU)
1 1
RTU 12. In this case, (1, 1)−resiliency veriﬁcation fails. The
model returns a satisﬁable result, showing that if IED 4 and
RTU 12 are unavailable, then the system is unobservable. We
also ﬁnd that this system (in this case) is not resilient to any
RTU failure. If RTU 12 fails, there is no way to observe the
system. This system is maximally (3, 0)-resilient observable.
C. Example: Scenario 2
In this scenario, we demonstrate the k1, k2−resilient se-
cured observability constraint. Let us consider the topology
of Fig. 3 and the same inputs from Table II. In this case of
(1, 1)−resiliency veriﬁcation, the model provides a sat result.
That is, the system is not (1, 1)−resilient in terms of secured
observability, although it is (1, 1)−resilient observable. Ac-
cording to the result, if IED 3 and RTU 11 are unavailable,
it is not possible to observe the system securely. There are 4
more threat vectors that can make the system unobservable.
This is because, as the result also shows, measurements from
IED 1 and RTU 9 are not data integrity protected, and thus,
when IED 3 and RTU 11 are unavailable, some states cannot
be observed securely anymore.
If we reduce the resiliency speciﬁcation to (1, 0) or (0, 1),
the model gives unsat result. That is, the system is securely
observable even if any IED or RTU fails. If we consider the
topology of Fig. 4, the system is not resilient any more for
one RTU failure. However, there is only one threat vector
(unavailability of RTU 12) to fail the secured observability.
V. EVALUATION
In this section, we present the evaluation results showing the
scalability of the proposed resiliency veriﬁcation framework
with respect to the synthetic SCADA systems.
A. Methodology
We evaluate the scalability of the proposed veriﬁcation
model by analyzing the time requirements for executing the
model in different problem sizes, particularly with respect to
the number of buses. It is worth mentioning that the number
of SCADA devices (IEDs and RTUs) and the number of
links are not ﬁxed for a speciﬁc bus size for a SCADA
system. However, their number is usually proportional with
the number of bus sizes. We generate the synthetic SCADA
systems based on different sizes of IEEE test systems, i.e.,
14-bus, 30-bus, 57-bus, and 118-bus [8]. We arbitrarily create
the SCADA network. On average, we choose one IED for
two power ﬂow measurements and one IED for each power
consumption measurement. The communication path from an
IED to the MTU is formed arbitrarily considering a parameter,
hierarchy level. This hierarchy speciﬁes the average number
of intermediate RTUs on the path toward the MTU.
In addition, we also analyze the average maximum re-
siliency (or the number of resiliency threat vectors) of a
SCADA system in different problem sizes, hierarchy levels,
and resiliency speciﬁcations. We run our experiments on an
Intel Core i5 Processor with 8 GB memory. We run a speciﬁc
experiment several times and take the average of the results. In
this evaluation, we did not compare the scalability or efﬁciency
of our proposed model with other works, as no work we have
found address a similar resiliency veriﬁcation.
B. Scalability Evaluation