52 000 neighbors (all combinations of up to 50 removals and
50 additions with 20 samples per combination) for each of
the 36 ways to distribute the data between two parties (6
data sets from [11, 33, 51, 54] distributed between 2 parties).
PRUNE-neighboring provides only limited group privacy for
the largest number of pruning steps ( = 2). However, for our
strongest privacy guarantee  = 0.25 we found changes leading
to violations in only 2 from 36 data set combinations, requiring
at least 12 changes. Note that this is a worst-case analysis, and
an average-case is provided in Appendix H. Also, sequential
composition is still supported as the result of our protocol
is the median selected by the exponential mechanism which
can be used as input for another (DP) mechanism. (Parallel
composition, running our protocol on multiple subsets of the
data at once, outputs multiple median values of these subsets.)
9Some values are the same for  ∈ {1, 2} as we only report the minimum
number of changes over all pruning steps.
11
(a) Credit card data [54], ﬁrst 105
payment records in Cents.
(b) Walmart supply chain data [33],
175k shipment weights as integers.
Fig. 9. Absolute error averaged over 100 runs with and without pruning.
C. Precision & Absolute Error
Our implementation uses ﬁxed-point numbers (see Sec-
tion III). As probabilities are ﬂoating point numbers we
evaluated the loss of decimal precision of our secure imple-
mentation compared to a ﬂoating point operation with access to
unprotected data [11]. For the maximum evaluated number of
remaining elements, i.e., 256 (corresponding to  = 0.25), the
difference for all elements combined was less than 6.5· 10−15.
Pruning preserves the elements closest to the median and
the absolute error compared to the original data is small.
We evaluated the absolute error, i.e., actual median versus
DP median, for the exponential mechanism on original data
and pruned data: Fig. 9 shows the average over 100 runs,
where brackets indicate the 95% conﬁdence interval. Before
pruning the data was randomly split between both parties.
Our evaluation shows the absolute error decreases by 3% on
average over all evaluated  ∈ {0.1, 0.25, 0.5}. However, this
is within the margin of error, since the conﬁdence intervals for
pruned data overlap with original data’s conﬁdence intervals.
D. Circuit size & Communication
We only report circuit size and communication for 106
records as smaller data sizes (i.e., fewer pruning steps) do not
noticeably reduce the numbers (recall, a pruning step consists
of a single comparison). The number of garbled gates for GC
and GC + SS depends on the number of remaining elements
and is visualized in Fig. 10a. GC requires an order of magni-
tude more gates as GC + SS since GC requires larger circuits
for arithmetic operations whereas GC + SS avoids the need
for this additional circuit complexity. The communication cost,
measured in megabytes per number of remaining elements, can
be found in Fig. 10b. We do not distinguish between (precom-
puted) setup and online phase and present the total number of
megabytes sent. Whereas GC sends about 15 megabytes for 64
remaining elements ( = 1), GC + SS requires less than that
even for 256 remaining elements ( = 0.25) as fewer gates
have to be garbled and evaluated.
E. Comparison to Related Work
Pettai and Laud [44] compute differentially private ana-
lytics on distributed data via secret sharing for three parties,
whereas we optimize our protocol for rank-based statistics
of two parties and also use garbled circuits.10 Both parties
10Note that 3-party computation on secret shares are usually faster than
cryptographic 2-party computations [2].
(a) Number of garbled circuit gates.
(b) Total megabytes sent.
Fig. 10. Circuit size and communication for GC vs. GC + SS.
Fig. 11.
remaining elements,  = 0.25) vs. Pettai and Laud [44] (LAN).
Runtime of GC + SS (∼25 ms RTT and ∼160 MBits/s, 256
learn the PRUNE-neighborhood (for large data sets requiring
pruning), but the median output can be shared (or output to
only a single party) and processed further. Pettai and Laud
evaluated their median computation with 48GB RAM and
a 12-core 3GHz CPU in a LAN. We, on the other hand,
used a comparatively modest setup (t2.medium instances with
2GB RAM, 4vCPUs) and evaluated in multiple WANs. A
comparison of our protocol (with ∼25 ms delay, ∼160 MBits/s)
and [44] (in a LAN) is visualized in Fig. 11. Their median
computation requires 34.5 seconds for 106 elements in a LAN.
Our protocol runs in less than 2.6 seconds with twice as many
elements even with network delay and restricted bandwidth.
VII. RELATED WORK
We describe related work combining secure computation
with differential privacy, outline alternatives to reduce the size
of the data universe, and discuss other work that computes the
differentially private (DP) median.
Secure Computation and DP: Dwork et al. [19] ﬁrst
mentioned that differential privacy combines well with secure
computation. E.g., secure computation of DP sums is easily
achieved via additive noise (see [25] for an overview). It
was shown in [26] that some distributed DP protocols (e.g.,
XOR computation) can only achieve optimal accuracy when
combined with secure computation. We utilize the iterative
pruning from Aggarwal et al. [1] as it is a basis for more
efﬁcient secure computation protocols as shown in [49]. (Not
all protocols can utilize this approach, e.g., it is not applicable
when only one party learns the output [10]). Naor et al. [42]
use secure two-party computation to ﬁnd differentially private
heavy hitters (e.g., to blacklist frequently used passwords) in
the local model. They also consider malicious adversaries that
try to skew the frequency. We, on the other hand, simulate the
more accurate central model in the local model to ﬁnd the DP
median in the semi-honest model. For functions that are not
12
0.10.250.501234Avg.Abs.ErrorsOriginalDPrunedDs0.10.250.500.250.50.7511.251.51.752Avg.Abs.ErrorsOriginalDPrunedDs(2)(1)(0.5)(0.25)326412825601·1062·1063·1064·1065·1066·1067·1068·106Remainingelements(corresponding)NumberofGatesGCGC+SS(2)(1)(0.5)(0.25)32641282560102030405060Remainingelements(corresponding)MBytesSentGCGC+SS10410510605101520253035DatasetsizesRuntimeinSecondsPettai&LaudGC+SSrobust to potentially large noise, e.g., the median, a speciﬁc
value from a data universe, the exponential mechanism, devel-
oped by McSherry and Talwar [39], is the better choice [35].
The exponential mechanism deﬁnes a probability distribution
over all possible output values. Eigner et al. [21] implement the
exponential mechanism in secure multiparty computation for
semi-honest and malicious parties. However, they are linear in
the size of the data universe: 3 semi-honest parties require 42.3
seconds to sample a universe of size 5 in a LAN on a machine
with 32GB RAM and 3.2GHz. Our protocol is sublinear in the
size of the data universe, requiring less than 500 milliseconds
for millions of elements in a LAN with less powerful hardware
(see Fig. 4b). Efﬁciently sampling the distribution deﬁned by
the exponential mechanism is non-trivial [18], thus, a reduction
of the sampling space is considered by [6, 27, 35, 44].
Pruning and Reduction: Gupta et al. [27] suggest pruning
the set of outputs for combinatorial problems from exponen-
tial to polynomial size and sample it with the exponential
mechanism. We follow a different approach based on [1].
Another technique divides U into equal-sized ranges, selects a
range with the exponential mechanism and samples a range
element at uniform random [35]. However, any element in
the selected range is equally likely to be output independent
of its utility. Our protocol samples the median only among
elements with the same utility which is exponentially more
likely to select elements closer to the actual median. Pettai and
Laud [44] deﬁne algorithms for privacy-preserving analytics.
They securely compute the DP median with three parties but
chose not to optimize their computation for the exponential
mechanism and instead use the sample-and-aggregate mecha-
nism [43]. The sample-and-aggregate mechanism divides the
output in multiple equal-sized ranges, selects from each range
the element closest to the median and returns a noisy average
of these elements. However, the exponential mechanism, which
we securely implement for the median utility function, selects
an actual universe element and not a noisy approximation. The
authors of [44] also apply input pruning and replace half of
the excluded values with a small (resp. large) constant. They
mention that this does not always preserve the median. Blocki
et al. [6] use a relaxed exponential mechanism to sample a
DP password frequency list in the central model. They allow
a negligible error δ, i.e., they only sample the exponential
mechanism correctly with probability 1 − δ, which improves
sampling from (potentially) exponential time to O(|D|1.5/).
However, they require full access to the data D in clear.
Differentially Private Median: As mentioned above, Pettai
and Laud [44] also securely compute the DP median. Their
work is more general, supporting multiple DP statistics over
secret-shared data, whereas we optimized our protocol for
rank-based DP statistics (e.g., pth-percentile, median) in a
two-party setting without powerful hardware. Their protocol
requires 34.5 seconds for a data size of 106 in a LAN [44,
Fig. 1] whereas our protocol runs in less than 500 ms with
twice as many elements in a LAN (Fig. 4b) and is still
13 times faster in a WAN as [44] in a LAN (Fig. 11).
Median computation has also been considered in the DP
query framework PINQ, developed by McSherry [40], which
requires a trusted third party. Smooth sensitivity, presented in
[43], analyzes the data to provide instance-speciﬁc additive
noise. Yet, when smooth sensitivity is high, it still provides
less accuracy than the exponential mechanism (see Section
II). Also, computing the exact sensitivity itself is not trivial
and requires access to the entire, sensitive data set. Another
approach from Dwork and Lei [17] considers the statistical
setting, where data are actually i.i.d. samples from a distribu-
tion. Their approach requires additive noise proportional to the
scale of the data (approximated via interquartile range), i.e.,
potentially large noise, whereas our result is independent of
the scale. Smith et al. [50] compute the DP median in the
local model and achieve optimal error bounds without relying
on secure computation and even avoid interaction; however,
√
the local model’s accuracy is limited compared to the central
n) vs. O(1) for n parties [30]). They approximate
model (Ω(
for each party the count of elements in all subintervals of a
range, structured as nodes in a tree. A server combines these
noisy counts to learn the DP median. Hsu et al. [30] consider
approximate counts for heavy hitters and say an algorithm is α-
accurate if the returned universe element occurs with frequency
that differs at most by an additive α from the true heavy hitter.
They show that the lower bound for accuracy in the local
model (the setting of [50]) is Ω(
n) for n parties, whereas the
central model, which we simulate via secure computation of
the exponential mechanism, can achieve O(1) accuracy. The
authors of [50] note that general techniques combining secure
computation and differential privacy suffer from bandwidth
and liveness constraints, rendering them impractical for large
data sets. Our protocol shows that specially crafted protocols,
combining different
techniques and optimizations, achieve
performance numbers suitable for practical applications.
√
VIII. CONCLUSION
We presented a protocol for secure differentially private
median computation on private data sets from two parties
with a runtime sublinear in the size of the data universe.
Our protocol implements the exponential mechanism as in the
local model using a distributed, secure computation protocol
to achieve accuracy as in the central model without trusting
a third party. For the median the exponential mechanism pro-
vides the best utility vs. privacy trade-off for low  compared
to additive noise (see Section II). The output is selected with
an exponential bias towards elements close to the median while
providing differential privacy for the individuals contained in
the sensitive data. We note that our protocol can be easily
extended to compute differentially private rank-based statistics
such as pth-percentile and interquartile range. Our experiments
evaluate real-world delay and bandwidth, unlike related work
[44], which we still outperform by at least a factor of 13
(with 25 ms delay and less powerful hardware) by utilizing
secret sharing as well as garbled circuits for their respective
advantages. We optimize our protocol by computing as little
as possible using cryptographic protocols and by applying dy-
namic programming with a static, i.e., data-independent, access
pattern, yielding lower complexity of the secure computation
circuit. Our comprehensive evaluation with a large real-world
payment data set [11] achieves the same high accuracy as in
the central model and a practical runtime of less than 7 seconds
for millions of records in real-world WANs.
ACKNOWLEDGEMENT
This work has received funding from the European Union’s
Horizon 2020 research and innovation programme under grant
agreement No 825333 (MOSAICrOWN).
13
REFERENCES
[1] G. Aggarwal, N. Mishra, and B. Pinkas, “Secure com-
putation of the median (and other elements of speciﬁed
ranks),” Journal of cryptology, 2010.
[2] D. W. Archer, D. Bogdanov, B. Pinkas, and P. Pullo-
nen, “Maturity and performance of programmable secure
computation,” IEEE security & privacy, 2016.
[3] M. Bellare, V. T. Hoang, and P. Rogaway, “Foundations
of garbled circuits,” in Proceedings of the annual ACM
conference on Computer and Communications Security,
ser. CCS, 2012.
[4] A. J. Biega, R. Saha Roy, and G. Weikum, “Privacy
through solidarity: A user-utility-preserving framework
to counter proﬁling,” in Proceedings of the International
ACM SIGIR Conference on Research and Development
in Information Retrieval, 2017.
[5] A. Bittau, U. Erlingsson, P. Maniatis,
I. Mironov,
A. Raghunathan, D. Lie, M. Rudominer, U. Kode,
J. Tinnes, and B. Seefeld, “Prochlo: Strong privacy for
analytics in the crowd,” in Proceedings of the Symposium
on Operating Systems Principles, ser. SOSP, 2017.
[6] J. Blocki, A. Datta, and J. Bonneau, “Differentially
private password frequency lists.” in Network and Dis-
tributed Systems Security Symposium, ser. NDSS, 2016.
[7] Bloomberg News. (2018) Google and mastercard cut a
secret ad deal to track retail sales. [Online]. Available:
https://www.bloomberg.com/news/articles/2018-08-
30/google-and-mastercard-cut-a-secret-ad-deal-to-track-
retail-sales
[8] D. Bogdanov, M. J˜oemets, S. Siim, and M. Vaht, “How
the estonian tax and customs board evaluated a tax fraud
detection system based on secure multi-party computa-
tion,” in International Conference on Financial Cryptog-
raphy and Data Security, ser. FC.
[9] D. Bogdanov, L. Kamm, B. Kubo, R. Rebane, V. Sokk,
and R. Talviste, “Students and taxes: a privacy-preserving
study using secure computation,” 2016.
[10] E. Boyle, Y. Ishai, and A. Polychroniadou, “Limits of
practical sublinear secure computation,” in Annual Inter-
national Cryptology Conference, 2018.
[11] Centers for Medicare & Medicaid Services. (2017) Com-
plete 2017 program year open payments dataset. [Online].
Available: https://www.cms.gov/OpenPayments/Explore-
the-Data/Dataset-Downloads.html
[12] A. Cheu, A. Smith, J. Ullman, D. Zeber, and M. Zhilyaev,
“Distributed differential privacy via shufﬂing,” in Annual
International Conference on the Theory and Applications
of Cryptographic Techniques, ser. EUROCRYPT, 2019.
[13] R. A. DeMillo, D. Dobkin, and R. J. Lipton, “Even data
bases that lie can be compromised,” IEEE Transactions
on Software Engineering, 1978.
[14] D. Demmler, T. Schneider, and M. Zohner, “Aby-a frame-
work for efﬁcient mixed-protocol secure two-party com-
putation.” in Network and Distributed Systems Security
Symposium, ser. NDSS, 2015.
[15] B. Ding, J. Kulkarni, and S. Yekhanin, “Collecting
telemetry data privately,” in Advances in Neural Infor-
mation Processing Systems, ser. NIPS, 2017.
[16] C. Dwork, “Differential privacy,” in International Collo-
quium on Automata, Languages, and Programming, ser.
ICALP, 2006.
14
[17] C. Dwork and J. Lei, “Differential privacy and robust
statistics,” in Proceedings of the annual ACM symposium
on Theory of Computing, ser. STOC, 2009.
[18] C. Dwork and A. Roth, “The algorithmic foundations of
differential privacy,” Foundations and Trends in Theoret-
ical Computer Science, 2014.
[19] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and
M. Naor, “Our data, ourselves: Privacy via distributed
noise generation.” in Annual International Conference
on the Theory and Applications of Cryptographic Tech-
niques, ser. EUROCRYPT, 2006.
[20] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Cal-
ibrating noise to sensitivity in private data analysis,” in
Theory of Cryptography Conference, ser. TCC, 2006.
[21] F. Eigner, A. Kate, M. Maffei, F. Pampaloni, and I. Pry-
valov, “Differentially private data aggregation with op-
timal utility,” in Proceedings of the Annual Computer
Security Applications Conference, ser. ASAC, 2014.
´U. Erlingsson, V. Pihur, and A. Korolova, “Rappor:
Randomized aggregatable privacy-preserving ordinal re-
sponse,” in Proceedings of the annual ACM conference on
computer and communications security, ser. CCS, 2014.
[23] S. Even, O. Goldreich, and A. Lempel, “A randomized
protocol for signing contracts,” Communications of the
ACM, 1985.