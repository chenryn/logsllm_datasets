2142
---
## Page 2144
2009-04-25-14-41-02+0200,frefox,1.9.1,debug,darwin,tomcat2.1ocal
tests_mozilla.org_top-sites.log
使用文本编辑工具或grep之类的命令，我们可以在日志文件中搜索
崩溃的记录（以退出状态表示）等。
这个工具是一个非常简单的命令行工具。我们仅仅用它做了一轮测
试就意识到它有潜力做更多的事情。同时，我们需要一个生成和管
理更多的URL列表（要大很多个数量级）的办法！
另外一个困扰我们的是Firefox渲染页面和Firefox扩展之间的交互上
存在问题。如何加载扩展才能使它们完美结合呢？
[1]网页和蜘蛛爬虫的主要功能是检索一个页面上的全部链接，然后
根据这些链接导航至相应页面。这个过程可以一直递归到任何期望
深度。整个过程就好像是在蜘蛛网上旅行。
[2]这里可以找到更多关于Spider的信息：
http:/bclary.com/projects/spider/。
[3]Sisyphus是希腊神话中一个国王，因生前罪而在阴间受罚，被
罚推一巨石至山顶，但石头总是滚下来，任务循环不止（参见
http://wikipedia.org/wiki/Sisyphus）。循环往复地执行半手工测试用
例跟这个故事的确颇为神似。Sisyphus安装、使用以及脚本引用信息
参见https://wiki.mozilla.org/Sisyphus
工具的整合与改进
于是，我们开始寻找具备以下特性的混合技术：
用从alexa.com获得的URL列表生成URL的自定义集合，可以测试一
百万个URL
在测试框架环境下管理这些巨大的URL集合（Spider）
启动指定版本的Firefox，打开一个页面，收集内存泄漏和断言信
息，然后退出Firefox(Sisyphus)
加载扩展（Sisyphus）
2143
---
## Page 2145
崩溃后能继续测试（Sisyphus）
除了启动网页外，遍历其上的链接以做一些更严格的测试
(Spider)
我们可以从alexa.com获得URL。起初我们只有Alexa前100或前500个
URL的列表。在会议期间我们一边研究Alexa网一边讨论我们的想法
（真是个无聊的会议）。我们发现它有超过一百万个链接。口为什
么要止步于50000或者100000个页面呢？现在我们已经可以支持一
个超大的URL列表了，并且把测试扩展到1000、50000甚至1000000
个站点！我们也可以创建自定义的站点集合进行测试。
我们从Alexa下载了前1000000个站点的列表
（http://s3.amazonaws.com/alexa-static/top-1mcsv.zip），然后把它转
换成我们的测试脚本可识别格式（其实就是一个简单的.tx文件，每
一行都是一个URL，例如http://example.com）。这样非常灵活，可以
增加任何想要的链接。
Spider还配有数据库。这个数据库可以更高效更灵活地跟踪URL以及
相关的信息。这样可以很容易地扩展到5方或更多的预先定义的
URL。我们用Spider链接前500个站点框架，试运行一下。效果非常
好！
在我们刚开始进行扩展测试的时候，仅仅希望能找到一个较好的方
法来运行泄漏测试。我们需要程序来启动Firefox，加载站点，然后
退出Firefox。运行调试版本中提供的功能来收集内存泄漏和断言信
息，即使Firefox崩溃也仍然可以继续测试。怎么保存日志文件也是
个问题。输出结果需要优先把泄漏数据写入日志文件。接下来需要
考虑的是如何在不同版本的Firefox上运行它。我们特别为Firefox的
trunk版、3.0版、3.5版整合了TraceMonkey（TraceMonkey是Mozilla上
的新一代JavaScript的引擎，将JavaScript编译成本地代码）。我们可
以很容易地把它整合到Sisyphus里。
我们开始在Sisyphus上运行自动化JavaScript测试。在看测试框架代码
的时候我们无意中发现Sisyphus是可以加载扩展的，于是觉得可以在
这上面多做些文章。如果它能自动化加载Spider扩展，那么它就可以
自动化加载任何扩展。最初我们就只想到了Firebug，其实它可以应
用任何扩展。这让我们想到了测试扩展。开始还是有一些麻烦的，
比如大家都认为Firefox经常会有泄漏，其实大部分时候泄漏是由于
扩展造成的。虽然我们在3.0版和3.5版上已经尽量减少泄漏的发生，
2144
---
## Page 2146
但是Firefox仍然存在这个问题。目前较之Firefox本身，扩展仍是造
成泄漏的主要原因。
那时候Sisyphus执行一个URL列表，然后遍历它们到任何我们想要的
深度。我们为其增加了自动从Alexa抓取站点列表和收集泄漏测试数
据的能力。
对于内存泄漏，[2]我们按站点URL分类记录输出到日志文件，例
如：
nsTraceRefcntlmpl:DumpStatistics:701 entries
nsStringStats
=>mAllocCount:14412
=>mReallocCount:1458
=>mFreeCount:14256--LEAKED 156!!!
=>mShareCount:9327
=>mAdoptCount:1150
=>mAdoptFreeCount:1147--LEAKED3!!!
对于断言，我们记录如下一些信息：
###!ASSERTION:nsWyciwygChannel:GetOriginalURI-mOriginalURI not
set!:
'mOriginalURI!=mURr,fle c:/work/mozilla/builds/1.9.1-trace-
malloc/mozilla/
content/html/document/src/nsWyciwygChannel.cpp,line 182
2145
---
## Page 2147
同时，每当一个URL被测试完，它的退出状态都会被记录在日志文
件里。根据这个退出状态我们就可以知道某个特定的URL测试有没
有崩溃。
例如：
http://www.cnn.com:EXIT STATUS:NORMAL(9.594268seconds)
退出状态为NORMAL，说明网页运行正常（没有崩溃），否则：
Assertion failure:! rt- >
gcRunning,at/work/mozilla/builds/1.9.1/mozilla/js/src/jsgc.cpp:1873
http://www.download.com:EXIT STATUS:CRASHED signal 5
SIGTRAP (100.560452 seconds)
退出状态为CRASHED（在Windows环境下称作ABNORMAL），说
明某一个断言失败或者崩溃。对于调试版本生成各种各样的错误和
警告信息，参见http://mxr.mozilla.org/mozilla-
[1]参考以下链接“免费下载排名前一百万的站点（每天更新）”；
http://alexa.com/topsites.
[2]参考“在调试版本下测试扩展和Firefox的内存泄漏”
(https://wiki.mozilla.org/MozillaQualityAssurance:Home_Page:Firefox
3.0_TestPlan:leaks:leakTesting-How-To）以及“调试内存泄漏’
(https://developer.mozilla.org/En/debugging_memory_leaks)。
问题的本质
好了，历史说得够多了。它到底是怎么运行的呢？Sisyphus不负责安
装Firefox，但是可以启动已安装好的特定版本的Firefox。这样的好
处是，可以随意切换到任意自定义版本，如特定的补丁版本或调试
版本。其实包括安装过程也是可以的。目前的操作是选择一个已安
装好的Firefox，启动Firefox，安装扩展，运行测试，退出Firefox。只
要你愿意这个过程可以重复一百万次。
2146
---
## Page 2148
命令行大致如下：
/tester.sh-tSTEST_DIR/tests/mozilla.org/top-websites/test.sh
s $TEST_DIR/tests/mozilla.org/top-sites/global1000.txt-D 0 -r
frefox 1.9.1-tracemonkey debug
t=which tests to run
-s=fle containing URLs to test with
-D is how deep to spider(O=just load the current URL)
r=whichrevision of Firefox to test
下面是一些重要的环境变量：
XPCOMDEBUG_BREAK=stack（根据断言获取栈信息）
XPCOM_MEM_LOG=1（记录泄漏数据）
它具有非常强的灵活性。我们可以关注于断言测试、内存泄漏测试
或其他重要的部分。而且它们是跨平台的，因为它也可以应用到
Thunderbird、SeaMonkey等。
有了这个工具我们就无须在地址栏中手工输入即可加载成千上万个
站点。（事实上我们经常这么十！）我们也可以用这个工具来测试
不同语系的站点而无须了解任何关于语言或文化的知识。记住这不
是一个功能测试：我们不是在为站点并发者做网页的质量保证。功
能测试在本书中已经多次提及，这里不再赘述。我们只期望Firefox
具有初步应对那些恼人的JavaScript、HTML和CSS的功能，以及加载
这些页面的功能。JavaScript有抛出任何的异常么？这个贞面导致了
内存泄漏吗？它会导致浏览器崩溃吗？
这些测试运行一般需要很长的时间。一百万个URL的列表大概得花
一个月左右。我们称这些为"持久"测试。虽然一次测试需要执行好
几个月实在有点离谱，但是我们仍然开发了这些工具，然后考虑优
2147
---
## Page 2149
化这些测试的时间范围和频率。频紧测试实时更新的站点看起来就
像是站点在被病毒恶意攻击。不过这是另外一回事了。
我们遇到的一个挑战是：主要的问题在活动分支上很快就被发现并
修正了。所以我们不想花了一个月的时间找了个bug，结果发现它早
就被我们的社区发现并且已经改完了。TraceMonkey分支是处理这个
问题的一个例子，维护分支（到成文时正为Firefox3.o版）的持久测
试是安全的。我们有一个15万个URL的集合，运行一次大概需要3~
4周。我们在活动分支上只运行1000个URL的集合。运行一次大概需
要4个小时，我们就可以每天都得到一次测试结果了。这是我们不断
整合自动化测试的一部分。
那么，当我们遇到崩溃的时候会怎么样呢？
首先要做的是抓取这个页面，然后把它保存到本地。eb页面是会
经常变的，所以依赖于一个实时更新的页面的风险就太大了。一旦
页面被保存到本地，我们就需要做一些工作来重新对其进行测试，
这是个很有技术含量的工作。如果崩溃是可重现的，我们就成功了
一大半。
下一步我们需要把测试范围缩到最小最简单的形式。在一个完整的
Web页面中会发生很多事情。有问题的代码需要被隔离出来，否则
程序员得花费很多时间在看代码上。好消息是我们有Lithium山这个
工具来做这个事情。它自动地把失败的页面抽象成为一个简单的测
试用例。这个工具原本的用途是抓取那些被各类模糊测试工具搞前
溃的页面，这其中就包括jsfunfuzz[2]。
又是一个漂亮的工具复用的例子！通常使用这个工具我们可以把一
个页面从3000行降低为大概5～10行。
[1]更多将问题页面抽象为测试用例的信息请参考
http://www.squarefree.com/2007/09/15/introducing-lithium-a-testcase-
reduction-tool/或参考http://www.squarefree.com/2009/01/11/reducing-
real-world-scripts/。
[2] http://www.squarefree.com/2007/08/02/introducing-jsfunfuzz/
总结
2148
---