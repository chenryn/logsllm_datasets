o
c
n
i
e
g
a
r
e
v
o
c
k
n
i
l
  1.00
  0.95
  0.90
  0.85
  0.80
  0.75
  0.70
  0.65
  0.00   0.20   0.40   0.60   0.80   1.00
p
classic DT
clustered skitter
capped skitter
clustered DT
capped DT
(a) Nodes
(b) Links
Fig. 5. Coverage when capping and clustering
of the additional discovery would presumably take place near the new monitors
and new destinations, rounding out an overall map of the network.
If capping is a reasonable approach, then the question arises of how to assign
monitors to destinations. It could be done purely at random. Future work might
reveal that a topologically informed approach provides better yield. However, one
straightforward method that promises reductions in communication overhead
is to create clusters of monitors within which all monitors target a common
destination set. This would allow the Doubletree global stop sets to be encoded
into Bloom ﬁlters, as described in Sec. 3, and shared within each cluster. There
would be no need to share between clusters, as no destinations would overlap.
We evaluate capping and clustering through experiments similar to those de-
scribed in Sec. 3. Using the same data sets as described in Sec. 2, we cap the
number of monitors per destination at 6. This means that each monitor traces to-
wards 1/4 of the destinations, or 12,500 destinations per monitor. We investigate
the eﬀects on redundancy and coverage of the capping. We also investigate the
diﬀerence between capping with and without the clustering of monitors around
common destination sets.
Experiments for clustering and capping employ the methodology that is de-
scribed in Sec. 3. However, for capping, six monitors are chose at random for
each destination. For clustering, six monitors and 12,500 destinations are chosen
at random for each cluster. Each monitor appears in only one cluster, and each
destination appears in only one cluster.
4.1 Capping and Clustering Results
In these plots, we vary Doubletree’s single parameter, p, over its entire range,
from p = 0 to p = 1, with more measurements being taken in the range p < 0.2,
where most change occurs. The abscissa is in linear scale. Error bars, where
visible, show the 95% conﬁdence intervals for the mean.
Fig. 5 shows how the average node and link coverage varies as a function
Doubletree’s parameter p. The ordinate values are shown on linear scales, and
represent coverage proportional to that which is discovered by skitter. A value
of 1.0 would mean that application of the given approach had discovered exactly
the same set of nodes or links as had skitter.
Improved Algorithms for Network Topology Discovery
159
y
c
n
a
d
n
u
d
e
r
e
c
a
f
r
e
t
n
i
 600
 550
 500
 450
 400
 350
 300
 250
 200
 150
 100
  0.00
classic DT
clustered DT
capped DT
y
c
n
a
d
n
u
d
e
r
n
o
i
t
a
n
i
t
s
e
d
 26
 24
 22
 20
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0
  0.00
  0.20
  0.40
  0.60
  0.80
  1.00
p
  0.20
  0.40
  0.60
  0.80
  1.00
p
classic DT
clustered DT
capped DT
(a) Internal interfaces: gross
(b) Destinations: inter-monitor
Fig. 6. Redundancy on 95th percentile interfaces when capping and clustering
The straight horizontal line labeled capped skitter in each plot shows the
coverage that is obtained by a hypothetical version of skitter in which each
destination is assigned to just six monitors. The lines show the cost of capping
skitter at this level, as already discussed. The straight horizontal line labeled
clustered skitter in each plot shows what would be obtained by skitter if its
monitors were to be divided into four clusters. In both plots, the results are very
close. Clustered skitter has slightly better coverage than capped skitter, so there
is a small eﬀect of promoting exploration due to restricting the global stop sets
to within clusters.
The curve labeled classic DT in each plot shows how uncapped, unclustered
Doubletree performs, and can be compared to the curves labeled capped DT and
clustered DT. As for skitter, the coverage for capping and clustering is slightly
better than for simply capping. While it appears that capping imposes signiﬁcant
coverage costs when compared to an uncapped version, these plots alone do not
tell the entire story. To better understand the tradeoﬀ we need to look at the
redundancy plots as well.
Fig. 6 show the 95th percentile of redundancy for internal interfaces and des-
tinations, in the same manner as in Fig. 4. Fig. 6(b) is of particular interest,
because the purpose of capping is to constrain redundancy on destinations. We
see that the maximum redundancy for the 95th percentile destination is indeed
maintained at six. But this was a foregone conclusion by the design of the ex-
periment. Much more interesting is to compare the parameter settings at which
both uncapped and capped Doubletree produce the same redundancy level. To
obtain a redundancy of six or less on the 95th percentile destination, uncapped
Doubletree must operate at p = 0.015. Capped Doubletree can operate at any
value in the range 0.180 (cid:1) p (cid:1) 1.
If the goal is to maintain a constant level of redundancy at the destinations,
the performance, in terms of coverage, of capped and uncapped Doubletree is
much closer than it initially appeared. Capped Doubletree can use a value of
p = 0.800 to maximise both its node and link coverage, at 0.920 and 0.753,
respectively. Uncapped Doubletree must use a value of p = 0.015, obtaining
values of 0.905 and 0.785. Capping, in these circumstances, produces a slightly
better result on nodes and a slightly worse on on links.
160
B. Donnet, T. Friedman, and M. Crovella
If destination redundancy results similar to capping can be obtained simply
by operating at a lower value of p, then what is the advantage of capping? As dis-
cussed earlier, there is a penalty associated with conducting forward traceroutes
starting close to the monitor. The same router interfaces are probed repeatedly.
We see the eﬀects in Fig. 6(a). The gross redundancy on the 95th percentile
router interface is 510 visits for uncapped Doubletree at p = 0.015. It is 156
for capped Doubletree at p = 0.800. Additional beneﬁts, not displayed in plots
here, come from reduced communication costs. If Bloom ﬁlters are used to com-
municate stop sets, and monitors are clustered, then ﬁlters of a quarter the size
are shared within sets of monitors that are a quarter the size, compared to the
uncapped, unclustered case.
5 Conclusion
This paper addresses an area, eﬃcient measurement of the overall internet topol-
ogy, in which very little related work has been done. This is in contrast to the
number of papers on eﬃcient monitoring of networks that are in a single ad-
ministrative domain (see for instance, Bejerano and Rastogi’s work [18]). The
two problems are extremely diﬀerent. An administrator knows their entire net-
work topology in advance, and can freely choose where to place their monitors.
Neither of these assumptions hold for monitoring the internet with screen saver
based software. Since the existing literature is based upon these assumptions,
we need to look elsewhere for solutions.
Some prior work has addressed strategies for tracing routes in the internet.
Govindan and Tangmunarunkit [19] proposed the idea of starting traceroutes
far from the source, and incorporated a heuristic based on it into the Mercator
system. No results on heuristic’s performance have been published.
A number of papers have examined the tradeoﬀs involved in varying the
number of monitors used for topological exploration of the internet. As previously
mentioned, Barford et al. [16] found a low marginal utility for added monitors
for the purpose of discovering certain network characteristics, implying that a
small number of monitors should be suﬃcient. However, Lakhina et al. [20] found
that this depends upon the parameters under study, and that small numbers of
monitors could lead to biased estimates. These biases have been further studied
by Clauset and Moore [21], Petermann and De Los Rios [22], and Dall’Asta et
al. [15]. Guillaume and Latapy [23] have extended these studies to include the
tradeoﬀ between the number of monitors and the number of destinations.
We believe that, employing the heuristics described here, a system such as
skitter can be safely extended to a more widely deployed set of monitors, or a
system such as DIMES could safely increase its rate of probing. The next prudent
step for future work would be to test the algorithms that we describe here on an
infrastructure of intermediate size, on the order of hundreds of monitors. We have
developed a tool called traceroute@home that we plan to deploy in this manner.
While we have seen the potential beneﬁts of capping and clustering, we are not
yet prepared to recommend a particular cluster size. Data from traceroute@home
Improved Algorithms for Network Topology Discovery
161
should allow us better to determine the marginal beneﬁts and costs of adding
monitors to clusters.
We also plan further steps to reduce communication overhead and increase
probing eﬀectiveness. One promising means of doing this would be to make use
of BGP [24] information to guide probing. We are collaborating with Bruno
Quoitin to incorporate his C-BGP simulator [25] into our studies.
Acknowledgments
Without the skitter data provided by kc claﬀy and her team at CAIDA, this
research would not have been possible. They also furnished much useful feedback.
Marc Giusti and his team at the Centre de Calcul MEDICIS, Laboratoire STIX,
Ecole Polytechnique, oﬀered us access to their computing cluster, allowing faster
and easier simulations. Finally, we are indebted to our colleagues in the Networks
and Performance Analysis group at LiP6, headed by Serge Fdida, and to our
partners in the traceroute@home project, Jos´e Ignacio Alvarez-Hamelin, Alain
Barrat, Matthieu Latapy, Philippe Raoult, and Alessandro Vespignani, for their
support and advice.
References
1. Jacobsen, V., et al.:
traceroute. man page, UNIX (1989) See source code:
ftp://ftp.ee.lbl.gov/traceroute.tar.gz, and NANOG traceroute source code:
ftp://ftp.login.com/pub/software/traceroute/.
2. Huﬀaker, B., Plummer, D., Moore, D., claﬀy, k: Topology discovery by active
probing. In: Proc. Symposium on Applications and the Internet. (2002) See also
the skitter project: http://www.caida.org/tools/measurement/skitter/.
3. Georgatos, F., Gruber, F., Karrenberg, D., Santcroos, M., Susanj, A., Uijter-
waal, H., Wilhelm, R.: Providing active measurements as a regular service
for ISPs.
In: Proc. PAM. (2001) See also the RIPE NCC TTM service:
http://www.ripe.net/test-traffic/.
4. McGregor, A., Braun, H.W., Brown, J.: The NLANR network analysis infrastruc-
ture. IEEE Communications Magazine 38 (2000) 122–128 See also the NLANR
AMP project: http://watt.nlanr.net/.
5. Cheswick, B., Burch, H., Branigan, S.: Mapping and visualizing the internet. In:
Proc. USENIX Annual Technical Conference. (2000)
6. Anderson, D.P., Cobb, J., Korpela, E., Lebofsky, M., Werthimer, D.:
Communica-
the ACM 45 (2002) 56–61 See also the SETI@home project:
in public-resource computing.
SETI@home: An experiment
tions of
http://setiathome.ssl.berkeley.edu/.
La m´et´eo
7. Schmitt, A.,
du
net
(ongoing
service)
See:
et
al.:
http://www.grenouille.com/.
8. Simpson, Jr., C.R., Riley, G.F.: NETI@home: A distributed approach to collecting
end-to-end network performance measurements. In: Proc. PAM. (2004) See also
the NETI@home project: http://www.neti.gatech.edu/.
9. Shavitt, Y., et al.: DIMES (ongoing project) See: http://www.netdimes.org/.
10. Donnet, B., Raoult, P., Friedman, T., Crovella, M.: Eﬃcient algorithms for large-
scale topology discovery. Preprint (under review). arXiv:cs.NI/0411013 v1 (2004)
See also the traceroute@home project: http://www.tracerouteathome.net/.
162
B. Donnet, T. Friedman, and M. Crovella
11. Bloom, B.H.: Space/time trade-oﬀs in hash coding with allowable errors. Com-
munications of the ACM 13 (1970) 422–426
12. Mitzenmacher, M.: Compressed Bloom ﬁlters. In: Proc. Twentieth Annual ACM
Symposium on Principles of Distributed Computing. (2001) 144–150
13. Matsumoto, M., Nishimura, T.: Mersenne Twister: A 623-dimensionally equidis-
tributed uniform pseudorandom number generator. ACM Trans. on Modeling and
Computer Simulation 8 (1998) 3–30 See also the Mersenne Twister home page:
http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html.
14. Fan, L., Cao, P., Almeida, J., Broder, A.Z.: Summary cache: A scalable wide-area
web cache sharing protocol. In: Proc. ACM SIGCOMM. (1998)
15. Dall’Asta, L., Alvarez-Hamelin, I., Barrat, A., V´azquez, A., Vespignani, A.: A
statistical approach to the traceroute-like exploration of networks: theory and sim-
ulations. In: Proc. Workshop on Combinatorial and Algorithmic Aspects of Net-
working (CAAN). (2004) Preprint: arXiv:cond-mat/0406404.
16. Barford, P., Bestavros, A., Byers, J., Crovella, M.: On the marginal utility of net-
work topology measurements. In: Proc. ACM SIGCOMM Internet Measurement
Workshop (IMW). (2001)
17. Fuller, V., Li, T., Yu, J., Varadhan, K.: Classless inter-domain routing (CIDR):
an address assignment and aggregation strategy. RFC 1519, IETF (1993)
18. Bejerano, Y., Rastogi, R.: Robust monitoring of link delays and faults in IP net-
works. In: Proc. IEEE Infocom. (2003)
19. Govindan, R., Tangmunarunkit, H.: Heuristics for internet map discovery.
In:
Proc. IEEE Infocom. (2000)
20. Lakhina, A., Byers, J., Crovella, M., Xie, P.: Sampling biases in IP topology
measurements. In: Proc. IEEE Infocom. (2003)
21. Clauset, A., Moore, C.: Why mapping the internet is hard. Technical report.
arXiv:cond-mat/0407339 v1 (2004)
22. Petermann, T., De Los Rios, P.: Exploration of scale-free networks. Eur. Phys. J.
B 38 (2004) Preprint: arXiv:cond-mat/0401065.
23. Guillaume, J.L., Latapy, M.: Relevance of massively distributed explorations of
the internet topology: Simulation results. In: Proc. IEEE Infocom. (2005)
24. Rekhter, Y., Li, T., et al.: A border gateway protocol 4 (BGP-4). RFC 1771, IETF
(1995)
25. Quoitin, B., Pelsser, C., Bonaventure, O., Uhlig, S.: A performance evaluation of
BGP-based traﬃc engineering. International Journal of Network Management (to
appear) See also the C-BGP simulator page: http://cbgp.info.ucl.ac.be/.