6.被动关闭端P：收到ACK后结束Socket。
---
## Page 58
58
>TIME_WAIT & CLOSE_WAIT 的讨论总结
因此，TIME_WAIT状态是出现在主动发起连接关闭的一点，和是谁发起的连接无
关，可以是client 端，也可以是server端。
而从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是
2*MSL（RFC793 定义了 MSL为 2 分钟，Linux 设置成了 30s)。
为什么需要TIME_WAIT?
主要有两个原因：
1）为了确保两端能完全关闭连接。
假设A服务器是主动关闭连接方，B服务器是被动方。如果没有TIME_WAIT
状态，A服务器发出最后一个ACK就进入关闭状态，如果这个ACK对端没有
收到，对端就不能完成关闭。对端没有收到ACK，会重发FIN，此时连接关闭，
这个 FIN 也得不到 ACK, 而有 1IME_WAII， 则会重发这个 ACK, 确保对端
能正常关闭连接。
2）为了确保后续的连接不会收到“脏数据”。
刚才提到主动端进入TIME_WAIT后，等待2MSL后 CLOSE，这里的MSL
是指（maximum segment lifetime，我们内核一般是30s，2MSL就是1分
钟），网络上数据包最大的生命周期。这是为了使网络上由于重传出现的 old
duplicate segment 都消失后，才能创建参数（四元组，源IP/PORT，目标IP/
PORT）相同的连接，如果等待时间不够长，又创建好了一样的连接，再收到
old duplicate segment，数据就错乱了。
TIME_WAIT会导致什么问题
1）新建连接失败。
TIME_WAIT 到 CLOSED, 需要 2MSL=6Os 的时间]。 这个时间非常长。 每个
---
## Page 59
TIME_WAIT&CLOSE_WAIT 的讨论总结 TIME_WAIT & CLOSE_WAIT 的讨论总结
风险，没有什么收益，只是表面上通过netstat 看到的 TIME_WAIT少了些而
已，有啥用呢？并且，建议是当遇到条目不够，增加这个值，仅仅是浪费一点点
内存而已。
如何解决time_wait?
1）最佳方案是应用改造长连接，但是一般不太适用。
2）修改系统回收参数。
设置以下参数。
net. ipvl top_tinestamps = 1
net ipv4 .top_tv_recyele = 1
设置该参数会带来什么问题？
如果这两个参数同时开启，会校验源ip过来的包携带的timestamp是否递增，
如果不是递增的话，则会导致三次握手建联不成功，具体表现为抓包的时候看到
syn 发出，server 端不响应 syn ack。
通俗一些来讲就是，一个局域网有多个客户端访问您，如果有客户端的时间比别
的客户端时间慢，就会建联不成功。
治标不治本的方式：
放大端口范围。
sysctl net.ipv4.ip_local_port_range
net. ipvl ip_local_port_range = 32768 61000
放大 time_wait 的 buckets
sysctl net.ipv4.tcp_max_tw_buckets
net. ipv4 .ccp_nax_tv_bucketa = 180000
---
## Page 61
TIME_WAIT & CLOSE_WAIT 的讨论总结 TIME_WAIT & CLOSE_WAIT 的讨论总结
tw的开销是什么？
1.特别少量的内存。
2.占用本地端口。
tw放大的好与坏？
1.放大的话需要更多的内存开销，但是几乎可以忽路不计。
2.占用更多的本地端口，需要适当的放大本地端口范围，端口范围经过简单的测
试，建议设置为tw的1.5倍。
net.ipv4.ip_local_port_range
3.netstat 大量的扫描 socket 的时候（ss 不会扫描，但是 ss 在 slab 内存特别高
的时候，也有可能会引起抖动），极端情况下可能会引起性能抖动。
4.tw放大，local_port_range放大，还可以配置复用以及快速回收等参数。
5.使用快速回收可能会导致snat时间戳递增校验问题，不递增的话syn不响应。
特殊场景的时候（本机会发起大量短链接的时候）。
1.nginx结合 php-fpm 需要本地起端口。
2.nginx反代如（java，容器等）。
tcp_tw_reuse 参数需要结合 net.ipv4.tcp_timestamps = 1一起来用。
即服务器即做客户端，也做server端的时候。
tcp_tw_reuse参数用来设置是否可以在新的连接中重用TIME_WAIT状态的套接
字。注意，重用的是TIME_WAIT套接字占用的端口号，而不是TIME_WAIT套
接字的内存等。这个参数对客户端有意义，在主动发起连接的时候会在调用的inet
hash_connect()中会检查是否可以重用TIME_WAlT状态的套接字。如果你在服务
器段设置这个参数的话，则没有什么作用，因为服务器端ESTABLISHED状态的套
接字和监听套接字的本地IP、端口号是相同的，没有重用的概念。但并不是说服务器
---
## Page 63
TIME_WAIT & CLOSE_WAIT 的讨论总结TIME_WAIT & CLOSE_WAIT 的讨论总结
关于CLOSEWAIT
Client
Server
Client State
Server State
ESTASLISHED
Receive Close
ESTABLISHED
#1
Normal Operation
FIV
Receive FIW,
FW From Server
Tell App To Close
Send AcK,
ACK
CLOSE-WAIT
FIN-WAIT-2
Recelve ACK
(Wait for App)
Wait for Server FIN
App ls Ready To
FIV
Close,Send FW
Receive FN,
LAST-
Send ACK
Wait for ACK
ACK
to FW
Recelve ACK
CLOSED
Wait For Double
ME
Life (MSL)Tin
CLOSED
如上所示，CLOSE_WAIT的状态是服务器端/客户端程序收到外部过来的FIN之
后，响应了ACK包，之后就进入了CLOSE_WAIT状态。一般来说，如果一切正
常，稍后服务器端/客户端程序需要发出FIN包，进而迁移到LAST_ACK状态，
收到对端过来的ACK后，完成TCP连接关闭的整个过程。
注：不管是服务器还是客户端，只要是被动接收第一个FIN的那一方才会进入
CLOSE_WAIT状态。
---
## Page 65
次网络抖动经典案例分析一次网络抖动经典案例分析
有非常深入的了解，所以用户的应用日志具体含义和记录方式对我们来说更像黑盒。
我们所要做的是将问题现象转移到我们常见的系统组件上来，比如简单到ping。所以
我们第一件所做的事情就是编与脚本进行两台机器的内网互ping，并将每次ping的
延迟记录到文件。选择ping 当然也是由于ping的间隔是可以设置到白毫秒的，比较
容易说明问题。
在互ping的测试中我们确实发现有百毫秒以上的延迟，那么随后我们为了排除物理
网络的影响，选择一台机器进行对网关的ping测试，同样发现了类似的延迟：
bytes from 18.189.8.253: ic
bytes from 18.189.8.253: icmp_seq=56 tt1=64 time=833
9.253:
tt 1
61
18.189.8.253:
63 tt1=64
18.189.8.253:
9=112gbasdw
1 bytes from 18.189.8.253: icmp_seg=78 tt1=64 time=14.1 m
来看看上面的ping测试结果吧，初看也仅仅是一些百毫秒延迟的集中发生而已，但
是仔细观察就会发现每次发生都有这样的情况，就是延迟在一组连续的ping上发生
的，并且延迟是倒序排列的。那么这意味着什么呢？
分析一
通过以上的ping 测试我们把问题简单化到了ping 网关延迟上，但是上面如此规律的
测试结果的具体含义是什么。首先他意味着并没有丢包发生，所以的ICMP请求都被
系统发出并且收到回复，但是这样的倒序排列，更像是在问题时间段内所有的回复都
---
## Page 67
一次网络抖动经典案例分析一次网络抖动经典案例分析
dentry项可能代表这系统有大量被打开的文件。然而此时我们首先需要解释大量的
dentry项与禁用中断的关系，我们来看看2.6内核的这一段代码：
const char *n
int node;
har
r = NULL;
struct kmen_list3 *13;
13 coc
e_node(node){
if(113)
hep->nodetists[node]:
contimse:
list_for_
sis-dqe
error a "stabs_futt accounting error*;
error s *slabs_partial inuse accounting error;
66lerror)
这是一段计算slab总量的代码，我们注意到它是以遍历链表的方式来统计slab总量
的，而在进入链表之前调用了spin_lock_irq函数，我们来看看它的实现：
atat:ic Inline void _apin_1ock_1rq(splnlock_c *1ock)
1oca1_1rg_disab1e [) ;
于是我们可以确认在统计slab信息的时候，系统的行为是首先禁用中断，然后遍历
链表统计slab，最后再次启用中断。那么整个禁用中断的时间将取决于链表中对象的
个数，如果其对象数量惊人，很可能就会导致禁用中断时间过长。