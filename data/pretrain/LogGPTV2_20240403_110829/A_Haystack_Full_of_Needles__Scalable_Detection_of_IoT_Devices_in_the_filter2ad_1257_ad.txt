we are able to distinguish between di(cid:130)erent products of a man-
ufacturer, e.g., Samsung TV, or Amazon Echo vs. Amazon Fire
TV. For detection at the product level, we underline the impor-
tance of side information about the purpose associated with a do-
main. With this information, we can improve our classi(cid:128)cation
accuracy. For example, for Alexa Enabled devices, the domain
avs-alexa.*.amazon.com is critical, as it is the base URL for the
Alexa Voice Service API [13] (shown in Figure 8 as amazon do-
main23). Other examples are the Samsung devices that use the
domain samsungotn.net to check for (cid:128)rmware updates [25].
Additionally, some advanced services of the devices o(cid:137)en require
additional backend support from manufacturers. (cid:140)ese may then
contact additional domains. By considering more speci(cid:128)c features
(domains), the capabilities to distinguish products increases. We
leverage these specialized features e.g., to distinguish Amazon Fire
TV, which contacts signi(cid:128)cantly more domains than other Amazon
products, e.g., Echo Dot.
4.3.2 Generation of Detection Rules. For any of our three lev-
els of detection, we require that a subscriber contacts at least one
IP/port combination associated with a Primary domain of the IoT
service, to claim detectability of IoT activity at the subscriber. How-
ever, if there are many domains, requiring only one such activity
7
may not have enough evidence. For example, by monitoring a
single domain we can detect all Alexa Enabled devices, but this
service can be integrated into third party hardware as well. (cid:140)ere-
fore, in order to detect products manufactured by Amazon, e.g.,
Amazon Echo, it is essential to monitor additional domains that are
contacted by the Amazon Echo devices. For this, we introduce the
detection threshold D. If an IoT service has N IoT-Speci(cid:128)c domains,
we require to observe tra(cid:129)c involving k IP/port combinations that
are associated with max(1, (cid:98)D × N(cid:99)) of the N domains. To deter-
mine an appropriate value for this threshold, we rely on our ground
truth dataset, see Section 5.
We start with 96 devices in our testbeds. We have multiple copies
of a same device deployed in di(cid:130)erent continents. (cid:140)is reduces the
set of devices to 56 unique products. Of these, many are from the
same manufacturer, e.g., a Xiaomi rice cooker, a Xiaomi plug, and
a Xiaomi light bulb. Since these devices are o(cid:137)en supported by
the same backend infrastructure of the manufacturer, the list of
domains has signi(cid:128)cant overlap and o(cid:137)en fully overlaps. In our
methodology we can detect 3 di(cid:130)erent IoT platforms, the coarsest
level, as 4 of our products rely on them. Moreover, we generated
rules for the detection of 29 IoT devices at the manufacturer level.
We had a diverse range of products from Amazon and Samsung
in our testbed that allowed us an in-depth analysis, and cross-
examination of domains contacted by di(cid:130)erent products. (cid:140)erefore,
for devices using Alexa voice service (i.e., Alexa Enabled), and for
Samsung IoT devices, we detect the former at the platform level
and the la(cid:138)er at the manufacturer level. For Alexa Enabled and
Samsung IoT devices, we compared the domains across di(cid:130)erent
devices and obtained enough side information about the purpose
of their domains that allowed us to further divide each of them into
two subclasses at more (cid:128)ne grained levels. For this, we de(cid:128)ned
a hierarchy, namely Amazon products, and Fire TV, under Alexa
Enabled devices. Amazon products are detected at manufacturer
level, and include products such as Amazon Echo family and is
superclass of Fire TV. We identi(cid:128)ed 33 additional domains, besides
the Alexa voice service domain, that were contacted by Amazon
products. Moreover, Fire TV contacts up to 67 domains (34 more
domains than Amazon products). (cid:140)is allows us to establish its
subclass, at product level, under Amazon products. Using side
information [25] and comparing the set of domains across di(cid:130)erent
Samsung products, we monitor 14 domains in total, but only one
domain is important to detect Samsung IoT devices with Samsung
(cid:128)rmware (these include a broad range of products, such as fridges,
washing machines and TVs). Samsung TVs contact 16 additional
domains that are not used by any of the other Samsung devices in
our testbed.
Using the above methodology, except for the devices listed
in section 4.2.3, we generated detections rules at di(cid:130)erent levels
for our testbed devices. We generated rules for the detection of
20 manufacturers, and 11 products that amounts to the 77% of
manufacturers in our testbeds. We generate rules for 4 unique IoT
platforms by monitoring 1 to 4 domains (2 platforms were contacted
by 4 devices, we report them separately). Finally, for 11 products
we consider between 1 to 67 domains. For a detailed number of
domains per IoT device see Figure10.
8
Figure 10: Home-VP: Time to detect IoT (per threshold).
5 METHODOLOGY: CROSSCHECK
We use our ground truth dataset to check how long it takes for our
methodology (applied to the sampled (cid:131)ow data from the ISP) to
detect the presence of the IoT devices for the idle and the active
experiments (see 4 of Figure 2). For this, we report the time that
it takes to detect an IoT device that is hosted in our ground truth
subscriber line when it is in active mode (Figure 10 le(cid:137)) and idle
mode (Figure 10 right). We only include the ones that are detectable
with our methodology, i.e., those that do not rely exclusively on
shared infrastructures. We also annotate the device name with its
detection levels: Platform (Pl.), Manufacturer (Man.), and Product
level (Pr.).
On average, by requiring the evidence of at least 40% of domains,
we are able to detect 72/93/96% of IoT devices that are detectable at
manufacturer or product level within 1/24/72 hours in the active
mode. Even in idle mode their the percentage is 40/73/76% with
1/24/72 hours. For the devices detectable only at product level (Pr.),
with the same required evidence, we detected 63/81/90% of them
within the 1/24/72 hours respectively, in active mode. Note, we
are using the sampled ISP data. Indeed, popular products such
as Amazon products (i.e., Echo Dot, Echo Spot) can be almost in-
stantly detected. (cid:140)is is a signi(cid:128)cant (cid:128)nding and underlines that
it is possible to use sampled (cid:131)ow data within an ISP to accurately
detect the presence of a speci(cid:128)c IoT product within a subscriber
line, despite di(cid:130)erences in activity and IP churn due to operational
requirements.
A closer look reveals that, in general, it takes longer to detect
an idle IoT device in comparison to when it is active. (cid:140)is is not
surprising, as most IoT devices show more network activity in
active mode. However, this does not mean that the increase will
occur across all of the services contacted by a device, since there
are exceptions that take longer to detect even in active mode, e.g.,
SmartLife, and Nest.
Active ExperimentIdle Experiment1 Domain2 Domains3 D.4 Domains5+ Domains0.250.500.751.000.250.500.751.00Alexa Enabled(Pl.)Anova Sousvide(Pr.)iKettle(Pl.)Insteon Hub(Pr.)Magichome Stripe(Pr.)Meross Dooropener(Man.)Microseven Cam.(Pr.)Netatmo Weather St.(Man.)Smarter Coffee(Pl.)AppKettle(Pr.)Blink Hub & Cam.(Man.)Flux Bulb(Pl.)GE Microwave(Man.)Icsee Doorbell(Pr.)Lightify Hub(Pl.)Luohe Cam.(Pr.)Reolink Cam.(Pr.)Sengled Dev.(Man.)Smartthings Dev.(Man.)Wansview Cam.(Man.)Honeywell T−stat(Man.)Xiaomi Dev.(Man.)Nest Device(Man.)Ring Doorbell(Man.)Smartlife(Pl.)Ubell Doorbell(Man.)Yi Camera(Man.)Amazon Product(Man.)Amcrest Cam.(Man.)Dlink Motion Sens.(Man.)Fire TV(Pr.)Philips Dev.(Man.)Roku TV(Pr.)Samsung IoT(Man.)Samsung TV(Pr.)TP−link Dev.(Man.)ZModo Doorbell(Man.)ThresholdIoT Device w/ (Detection Level)01020304050Duration(Hours)NotDetected(a) Per Hour.
(b) Per Day.
Figure 11: ISP: Per Hour, Subscriber lines with IoT activity (Alexa Enabled, Samsung IoT, and others).
the targeted domains or the sampling rate shall be increased. For
Samsung TV, we require to observe enough domains to con(cid:128)rm
the presence of a Samsung IoT device, before moving forward with
detection. (cid:140)us, if we do not see enough Samsung IoT domains, then
we do not claim the detection of Samsung TVs. Nevertheless, the
results look very promising for us to a(cid:138)empt on detecting deployed
IoT devices in the wild.
6 RESULTS: IOT IN THE WILD
In this section, we apply our methodology for detecting IoT activity
in the ISP and IXP data (see 5 in Figure 2). For this we focus
on the two weeks in which we collected the data from the ground
truth experiments to obtain up-to-date mappings of domains to IPs.
6.1 Ethical Considerations and Privacy
Implications
Applying our methodology to tra(cid:129)c data from ISPs and IXPs may
raise ethical concerns as it may be considered as analyzing customer
activities. However, this is not the goal of this paper. (cid:140)e goal here
is to showcase that it is possible to detect and map the penetration of
IoT device usage. As such, this study is not about subscribers’ device
activities, instead it is about detection capabilities and aggregated
usage. (cid:140)us, we report on percentages of subscriber lines where
we can observe IoT related activity. Indeed, we are unable to trace
IoT activity back to individuals as the raw data was anonymized
as per recommendations by [5] and never le(cid:137) our collaborators’
premises. Moreover, we do not analyze any data that is not related
to the detection of IoT presence, e.g., DNS queries [26], or (cid:131)ows
that are not related to IoT backend infrastructures, to eliminate any
user Web visit pro(cid:128)ling.
6.2 Vantage Point: ISP
IoT related activity in-the-wild. Figure 11 shows the number
of ISP subscriber lines for which we detect IoT related activity.
(cid:140)e ISP does not operate a carrier-grade NAT. Even if multiple
IoT devices are hosted at an ISP subscriber, we count the hosting
subscriber only once. (cid:140)us, the number of subscribers that host
a given IoT device is a lower bound for the number of the given
IoT device in the premises of ISP subscribers. Figure 11(a) and
9
Figure 12: ISP: Drill down for Amazon and Samsung IoT devices–per
day.
Figure 10 also contains information regarding the number of
monitored domains per IoT device with their detection level. For
9 IoT devices, a single domain is considered. For the others, we
consider many more (up to 67). A threshold determines the fraction
of domains for which we require evidence of network tra(cid:129)c to
claim detection. To understand the impact of such threshold on
detection time, we variate its value from 0.1 to 1 and show the
corresponding detection times. Note, for IoT devices where we
consider only one domain, the variation of the threshold does not
change the detection time, as we always require evidence of at
least one domain. Overall, we note that a larger threshold can
increase the detection time, and some IoT devices may no longer be
detectable. However, it may also increase the false positive rate. We
crosscheck possible false positives by running another experiment
where we only enable a small subset of IoT devices. We then apply
our detection methodology to these traces and do not identify any
devices that are not explicitly part of the experiment. We also try
to avoid false positives by ensuring that the domain sets per device
di(cid:130)er.
Regarding detectability, we notice that 6 IoT devices could not be
detected even a(cid:137)er the entire duration of our idle experiments. A
closer investigation shows that for 5 of these, the frequency of tra(cid:129)c
is so small that their likelihood of detection is very low. Indeed,
for this speci(cid:128)c time period, they were invisible in the NetFlow
data. (cid:140)is highlights that in order to be able to con(cid:128)dently detect
a device, the device have to either exchange enough packets with
lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll10k100k1mNov−15Nov−16Nov−17Nov−18Nov−19Nov−20Nov−21Nov−22Nov−23Nov−24Nov−25Nov−26Nov−27Nov−28# Unique Subscribers/Hourlog10Device TypelSamsung IoTAlexa EnabledOther 32 IoT Device typesllllllllllllll50k500k1m1.5m2m2.5mNov−15Nov−16Nov−17Nov−18Nov−19Nov−20Nov−21Nov−22Nov−23Nov−24Nov−25Nov−26Nov−27Nov−28# Unique Subscribers Per 24HDevice TypelSamsung IoTAlexa EnabledOther 32 IoT Device typesllllllllllllllllllllllllllll50k500k1m1.5m2m2.5mNov−15Nov−16Nov−17Nov−18Nov−19Nov−20Nov−21Nov−22Nov−23Nov−24Nov−25Nov−26Nov−27Nov−28# Unique Subscribers Per 24HDevice Type llAlexa EnabledAmazon ProductAmazon FiretvSamsung IoTSamsung TVFigure 13: ISP: Cumulative # of subscriber lines resp. /24s with daily
IoT activity across two weeks.
Figure 11(b) focus on hourly and daily summaries. Since the top
IoT devices detected are Alexa Enabled and Samsung IoT, we show
them separately. We see IoT related activity for roughly 20% of
the subscriber lines. Our results show a signi(cid:128)cant penetration of
Alexa Enabled devices of roughly 14%. (cid:140)is is slightly more than
estimates of national surveys in the country where the ISP operates,
stating that the market penetration of Alexa Enabled devices, as of
June 2019, is around 12% [27–29]. Yet, these reports cannot capture
which devices are in active use at any particular day, e.g., Nov. 2019,
contrary to our study. Note, in Figures 11, 12, 14 and 15 we apply
our methodology on each time bin independently.
Daily patterns of IoT related activity. By looking at the hourly
plots in Figure 11(a), we see some signi(cid:128)cant daily pa(cid:138)erns for
Alexa Enabled and Samsung IoT devices. We do not see diurnal
pa(cid:138)erns for the other 32 IoT device types. Such diurnal pa(cid:138)erns
are correlated with human activities. Typically, during the day,
network activity increases as the users interact with the IoT devices
while it decreases during the night when the devices are idle. As
detection likelihood is correlated with network activity, the devices
detectability also correlates with this diurnal pa(cid:138)ern. We note
that the pa(cid:138)erns for Alexa Enabled does not di(cid:130)er from those for
Samsung. (cid:140)e reason is that many of the Alexa Enabled and Sam-
sung IoT (Samsung TVs) class may be used more for entertainment,
which is why their activity is higher in the evenings. Samsung
IoT devices have a small spike in the mornings before gradually
reaching their peak around 18:00 (ISP timezone).
For the drill down for Samsung IoT devices see Figure 12. Even
with the presence of a diurnal variation for Alexa Enabled, there
is a signi(cid:128)cant baseline during the night. (cid:140)is is expected as IoT
devices o(cid:137)en have tra(cid:129)c even when they are idle and are thus
detectable. Over the course of a day, the diurnal variation is rather
low compared with the typical network activity driven by human
activity. (cid:140)is explains the low variance of the observed number of
subscriber lines for Alexa Enabled devices.