c, respectively. The two scores are computed using conditional
entropy analysis. Speciﬁcally, let n denote the total number of
messages, nt and nc denote the number of messages belonging
to message type t and cluster c, and nt,c denote the number of
messages from type t assigned to cluster c. Then the entropy
of the types (H(T )) is deﬁned as:
H(T ) = −
nt
n
∗ log
nt
n
|T|(cid:88)
t=1
|T|(cid:88)
|C|(cid:88)
t=1
c=1
And the conditional entropy of the types given the cluster
assignments is deﬁned as:
H(T|C) = −
nt,c
n
∗ log
nt,c
nc
The entropy of the clusters (H(C)) and the conditional entropy
of clusters given type (H(C|T )) are deﬁned in a symmetric
way. Then scores h and c are computed as:
h = 1 − H(T|C)
c = 1 − H(C|T )
H(T )
H(C)
(a) Clustering results in homogeneity
(b) Clustering results in completeness
(c) Clustering results in V-measure
Fig. 10: Clustering result
(a) Clustering results in homogeneity
(b) Clustering results in completeness
(c) Clustering results in V-measure
Fig. 11: Clustering result on datasets of different sizes
The two scores range from 0 to 1 and the higher the better.
To consider the two metrics together, we also introduce their
harmonic mean, which is called V-measure. The score of V-
measure (v) can be computed as:
v = 2 ∗ h ∗ c
h + c
In the following experiments, we will compute the three
metrics to measure the clustering results.
Results of Different Protocols. We compare our method with
Netzob and Discoverer on different protocols. As Netzob and
Discoverer only consider messages from one side, we use them
to cluster messages of the client side and server side separately,
and then compute metrics with all clusters, while NETPLIER
infers the keywords of both sides at the same time and its
results consider all messages already.
NETPLIER identiﬁes the keyword after two rounds of the
iterative alignment and clustering for DHCP, and uses only
one round for other protocols. This is due to the complex ﬁeld
structures of DHCP, which causes some alignment errors in
the ﬁrst round. The clustering results of different protocols
are shown in Figure 10. NETPLIER substantially outperforms
Netzob and Discoverer for all protocols. Homogeneity and
completeness are determined by correctly recovering message
types. Since NetPlier recognizes keywords correctly, both
metrics are 100%, which is the advantage of NetPlier. The
only exception is NTP, for which NETPLIER generates a few
more clusters and gets a completeness score of 0.788. This
is because NTP uses several bits representing its keyword,
while the minimal keyword candidate generated in NETPLIER
is a byte. Nonetheless, NETPLIER still outperforms Netzob
and Discoverer clearly. Netzob and Discoverer have similar
performance. Although they perform well
in homogeneity,
their completeness scores are much lower. As we discussed
before, Netzob and Discoverer are not able to identify the exact
number of clusters. They are sensitive to their parameters and
11
make deterministic decisions in the presence of uncertainty,
which makes it hard to balance both homogeneity and com-
pleteness. Hence they usually generate more clusters to make
sure the accuracy, which leads to a low completeness score.
Datasets of Different Sizes. Besides different protocol types,
the protocol reverse engineering methods may also be affected
by the data sizes. To show the stability of NETPLIER, we
also compare the results of datasets with different sizes. We
choose ﬁve common protocols with enough messages and
construct three datasets with different sizes (100, 1000, and
10000 messages) for each protocol. Figure 11 shows the
clustering results on these datasets. We can see that NETPLIER
performs stably on different sizes with most scores being 1.
For DHCP of 10000 messages, NETPLIER’s performance on
completeness drops slightly (0.993) due to the complex option
ﬁelds. Note that Netzob could not handle the datasets of 10000
messages due to the exponential complexity and huge memory
consumption of its pair-wise alignment. In general, when the
number of messages increases, the homogeneity of Netzob and
Discoverer stays in the same level or increases slightly, while
the completeness decreases obviously. This shows that Netzob
and Discoverer are not stable for inputs of different sizes even
for the same protocol.
All experiments were conducted on a server equipped with
32-cores CPU (Intel R(cid:13) XeonTM E5-2690 @ 2.90GHz) and
128G main memory. Table IV shows the execution time and
maximum memory on datasets of 1000 messages. NETPLIER
and Discoverer also generate formats of each cluster at the
same time, while Netzob only conducts clustering. NETPLIER
consumes similar memory resource to Discoverer and is much
less than Netzob. Note that Netzob consumes lots of memory
and it stops execution for datasets with 10000 messages as
shown in Figure 11. The bottleneck of NETPLIER lies in
MSA, as we use iterative reﬁnement in MSA and constraints
generation. The time complexity of MSA could vary a lot for
different protocols. For well-formatted protocols, e.g., DNP3,
0.100.250.400.550.700.851.00DHCPDNP3FTPICMPModbusNTPSMBSMB2TFTPZeroAccessNetzobDiscovererNetPlier1.0000.9170.9230.100.250.400.550.700.851.00DHCPDNP3FTPICMPModbusNTPSMBSMB2TFTPZeroAccessNetzobDiscovererNetPlier0.9790.4890.5570.100.250.400.550.700.851.00DHCPDNP3FTPICMPModbusNTPSMBSMB2TFTPZeroAccessNetzobDiscovererNetPlier0.9880.5710.6600.100.250.400.550.700.851.000.1K1K10K0.1K1K10K0.1K1K10K0.1K1K10K0.1K1K10KNetzobDiscoverNetPilerDHCPDNP3ICMPModbusSMB1.0000.9600.5620.100.250.400.550.700.851.000.1K1K10K0.1K1K10K0.1K1K10K0.1K1K10K0.1K1K10KNetzobDiscoverNetPilerDHCPDNP3ICMPModbusSMB1.0000.5270.3910.100.250.400.550.700.851.000.1K1K10K0.1K1K10K0.1K1K10K0.1K1K10K0.1K1K10KNetzobDiscoverNetPilerDHCPDNP3ICMPModbusSMB1.0000.6400.422TABLE IV: Overhead measurement (The unit of Time is min and the unit of Memory is MB)
MSA
Constraints Generation Probabilistic Inference
NETPLIER
Time
4.645
1.207
5.862
0.385
0.660
6.402
6.348
9.628
0.466
2.332
Memory
14.882
15.208
15.365
14.829
14.894
17.681
15.481
15.048
4.120
18.163
Time
9.996
25.891
103.022
2.055
4.781
242.330
122.812
37.799
0.044
0.396
Memory
5.411
60.965
58.962
8.919
20.439
106.033
61.950
31.890
1.336
1.170
Protocol
Netzob
Discoverer
DHCP
DNP3
FTP
ICMP
Modbus
NTP
SMB
SMB2
TFTP
0.059
0.059
0.059
0.059
0.059
0.059
0.059
0.059
0.059
0.059
0.034
0.002
0.002
0.005
0.004
0.013
0.015
0.017
0.049
0.072
13.973
0.519
0.210
0.995
1.268
2.510
3.687
4.176
30.966
32.571
Time Memory Time Memory Time Memory
17.092 124.420
1.361
104.282
103.815
1.549
102.543
1.735
99.336
1.357
122.784
2.090
1.917
109.549
114.231
5.803
3.299
34.400
ZeroAccess 19.258 109.291
82.555
4.598
20.668
6.780
7.384
6.171
23.053
39.392
83.585
59.127
it is close to O(N ∗ L), where N is the number of messages
and L is the length of a message. However, for complex
protocols, e.g., with many variable-length ﬁelds, the worst case
is O(L ∗ N 2). The time complexity for constraints generation
is O(N 2) as we need to compare each two messages for
similarity. The time for probabilistic inference is determined
by the number of ﬁelds which does not grow with the dataset
sizes. Although NETPLIER executes slower than the other two
baselines due to the need of aligning complex messages and
probabilistic inference in datasets of 1000 messages, we argue
that the overhead is reasonable as it is an ofﬂine technique and
hence one-time effort. Also, as discussed above, NETPLIER is
not sensitive to data sizes, which means the overhead could be
improved by executed on smaller datasets.
TABLE V: Evaluation of format inference
Netzob
Protocol
DHCP
DNP3
FTP
ICMP
Modbus
Discoverer NETPLIER
Corr. Perf. Corr. Perf. Corr. Perf.
0.089 0.000 0.768 0.016 0.994 0.014
0.702 0.099 0.486 0.018 0.752 0.183
1.000 1.000 1.000 1.000 1.000 1.000
0.571 0.144 0.259 0.102 0.972 0.090
0.587 0.084 0.344 0.049 0.698 0.049
0.830 0.000 0.661 0.000 0.851 0.000
0.660 0.152 0.608 0.207 0.964 0.237
0.349 0.003 0.793 0.041 0.923 0.069
0.666 0.454 0.147 0.000 0.986 0.009
ZeroAccess N/A N/A 0.155 0.000 0.980 0.000
NTP
SMB
SMB2
TFTP
C. Evaluation of Format Inference
To show the beneﬁts of our clustering results, we further
infer the ﬁeld structures. The clustering results of Discover and
NETPLIER already contain the format information. Netzob’s
format
inference is based on its pairwise alignment [25].
However, it has to consider the alignment results of all pairs in
a cluster at the same time. As such, its format inference can
handle fewer messages than the clustering stage. We utilize
tshark [12] to obtain the ground truth, i.e., the information
of true ﬁelds. Then for each inferred ﬁeld, we compare its
boundaries and values with true ﬁelds. We consider an inferred
ﬁeld as a correct one if the inferred ﬁeld is part of a single true
ﬁeld or combines several consecutive true ﬁelds. Speciﬁcally,
the ﬁeld is accurate if it perfectly matches a true ﬁeld.
However, an inferred ﬁeld is considered to be incorrect if it
contains multiple incomplete true ﬁelds. It is also incorrect if a
dynamic ﬁeld is mistaken as static. For example, as discussed
above, prior works usually generate more clusters to improve
the homogeneity, so messages of the same type may be placed
into multiple clusters. Some ﬁelds may be considered as static
as all messages in the cluster have the same value. However,
messages of the same type in other clusters may have different
values, which means they are actually dynamic ﬁelds. Note that
h, c, and v scores are common metrics used in clustering when
having ground truth labels. They cannot be directly applied to
measuring the results of format and state machine inferences.
Then two metrics, correctness and perfection, are computed to
measure the inferred formats, which are deﬁned as follows: