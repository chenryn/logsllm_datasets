Once Jenkins knows where to find the test reports, it does a great job of reporting on them. Indeed, one
of Jenkins’s main jobs is to detect and to report on build failures. And a failing unit test is one of the
most obvious symptoms.
As we mentioned earlier, Jenkins makes the distinction between failed builds and unstable builds. A
failed build (indicated by a red ball) indicates test failures, or a build job that is broken in some brutal
manner, such as a compilation error. An unstable build, on the other hand, is a build that is not considered
of sufficient quality. This is intentionally a little vague: what defines “quality” in this sense is largely
up to you, but it is typically related to code quality metrics such as code coverage or coding standards,
that we will be discussing later on in the book. For now, let’s focus on the failed builds.
In Figure 6.5, “Jenkins displays test result trends on the project home page” we can see how Jenkins
displays a Maven build job containing test failures. This is the build job home page, which should be
your first port of call when a build breaks. When a build results in failing tests, the Latest Test Result
link will indicate the current number of test failures in this build job (“5 failures” in the illustration), and
also the change in the number of test failures since the last build (“+5” in the illustration—five new test
failures). You can also see how the tests have been faring over time—test failures from previous builds
will also appear as red in the Test Result Trend graph.
141
Figure 6.5. Jenkins displays test result trends on the project home page
If you click on the Latest Test Result link, Jenkins will give you a rundown of the current test results (see
Figure 6.6, “Jenkins displays a summary of the test results”). Jenkins understands Maven multimodule
project structures, and for a Maven build job, Jenkins will initially display a summary view of test results
per module. For more details about the failing tests in a particular module, just click on the module you
are interest in.
Figure 6.6. Jenkins displays a summary of the test results
For freestyle build jobs, Jenkins will directly give you a summary of your test results, but organized by
high-level packages rather than modules.
In both cases, Jenkins starts off by presenting a summary of test results for each package. From here,
you can drill down, seeing test results for each test class and then finally the tests within the test classes
themselves. And if there are any failed tests, these will be prominently displayed at the top of the page.
142
This full view gives you both a good overview of the current state of your tests, and an indication of
their history. The Age column tells you how for how long a test has been broken, with a hyperlink that
takes you back to the first build in which this test failed.
You can also add a description to the test results, using the Edit Description link in the top right-hand
corner of the screen. This is a great way to annotate a build failure with some additional details, in order
to add extra information about the origin of test failures or some notes about how to fix them.
When a test fails, you generally want to know why. To see the details of a particular test failure, just click
on the corresponding link on this screen. This will display all the gruesome details, including the error
message and the stack trace, as well as a reminder of how long the test has been failing (see Figure 6.7,
“The details of a test failure”). You should be wary of tests that have been failing for more than just a
couple of builds—this is an indicator of either a tricky technical problem that might need investigating,
or a complacent attitude to failed builds (developers might just be ignoring build failures), which is more
serious and definitely should be investigated.
Figure 6.7. The details of a test failure
Make sure you also keep an eye on how long your tests take to run, and not just whether they pass or fail.
Unit tests should be designed to run fast, and overly long-running tests can be the sign of a performance
issue. Slow unit tests also delay feedback, and in CI, fast feedback is the name of the game. For example,
running one thousand unit tests in five minutes is good—taking an hour to run them is not. So it is a
good idea to regularly check how long your unit tests are taking to run, and if necessary investigate why
they are taking so long.
Luckily, Jenkins can easily tell you how long your tests have been taking to run over time. On the build
job home page, click on the “trend” link in the Build History box on the left of the screen. This will give
you a graph along the lines of the one in Figure 6.8, “Build time trends can give you a good indicator
of how fast your tests are running”, showing how long each of your builds took to run. Now tests are
not the only thing that happens in a build job, but if you have enough tests to worry about, they will
143
probably take a large proportion of the time. So this graph is a great way to see how well your tests
are performing as well.
Figure 6.8. Build time trends can give you a good indicator of how fast your tests are running
When you are on the Test Results page (see Figure 6.6, “Jenkins displays a summary of the test results”),
you can also drill down and see how long the tests in a particular module, package or class are taking
to run. Just click on the test duration in the test results page (“Took 31 ms” in Figure 6.6, “Jenkins
displays a summary of the test results”) to view the test history for a package, class, or individual test
(see Figure 6.9, “Jenkins also lets you see how long your tests take to run”). This makes it easy to isolate
a test that is taking more time than it should, or even decide when a general optimization of your unit
tests is required.
6.5. Ignoring Tests
Jenkins distinguishes between test failures and skipped tests. Skipped tests are ones that have been
deactivated, for example by using the @Ignore annotation in JUnit 4:
@Ignore("Pending more details from the BA")
@Test
public void cashWithdrawalShouldDeductSumFromBalance() throws Exception {
Account account = new Account();
account.makeDeposit(100);
account.makeCashWithdraw(60);
assertThat(account.getBalance(), is(40));
}
144
Figure 6.9. Jenkins also lets you see how long your tests take to run
Skipping some tests is perfectly legitimate in some circumstances, such as to place an automated
acceptance test, or higher-level technical test, on hold while you implement the lower levels. In such
cases, you don’t want to be distracted by the failing acceptance test, but you don’t want to forget that the
test exists either. Using techniques such as the @Ignore annotation are better than simply commenting
out the test or renaming it (in JUnit 3), as it lets Jenkins keep tabs on the ignored tests for you.
In TestNG, you can also skip tests, using the enabled property:
@Test(enabled=false)
public void cashWithdrawalShouldDeductSumFromBalance() throws Exception {
Account account = new Account();
account.makeDeposit(100);
account.makeCashWithdraw(60);
assertThat(account.getBalance(), is(40));
}
In TestNG, you can also define dependencies between tests, so that certain tests will only run after
another test or group of tests has run, as illustrated here:
@Test
public void serverStartedOk() {...}
@Test(dependsOnMethods = { "serverStartedOk" })
145
public void whenAUserLogsOnWithACorrectUsernameAndPasswordTheHomePageIsDisplayed(){..}
Here, if the first test (serverStartedOk()) fails, the following test will be skipped.
In all of these cases, Jenkins will mark the tests that were not run as yellow, both in the overall test results
trend, and in the test details (see Figure 6.10, “Jenkins displays skipped tests as yellow”). Skipped tests
are not as bad as test failures, but it is important not to get into the habit of neglecting them. Skipped tests
are like branches in a version control system: a test should be skipped for a specific reason, with a clear
idea as to when they will be reactivated. A skipped test that remains skipped for too long is a bad smell.
Figure 6.10. Jenkins displays skipped tests as yellow
6.6. Code Coverage
Another very useful test-related metric is code coverage. Code coverage gives an indication of what
parts of your application were executed during the tests. While this in itself is not a sufficient indication
of quality testing (it is easy to execute an entire application without actually testing anything, and
code coverage metrics provide no indication of the quality or accuracy of your tests), it is a very good
indication of code that has not been tested. And, if your team is introducing rigorous testing practices
such as Test-Driven-Development, code coverage can be a good indicator of how well these practices
are being applied.
Code coverage analysis is a CPU and memory-intensive process, and will slow down your build job
significantly. For this reason, you will typically run code coverage metrics in a separate Jenkins build
job, to be run after your unit and integration tests are successful.
There are many code coverage tools available, and several are supported in Jenkins, all through dedicated
plugins. Java developers can pick between Cobertura and Emma, two popular open source code coverage
tools, or Clover, a powerful commercial code coverage tool from Atlassian. For .NET projects, you can
use NCover.
146
The behavior and configuration of all of these tools is similar. In this section, we will look at Cobertura.
6.6.1. Measuring Code Coverage with Cobertura
Cobertura1 is an open source code coverage tool for Java and Groovy that is easy to use and integrates
well with both Maven and Jenkins.
Like almost all of the Jenkins code quality metrics plugins,2 the Cobertura plugin for Jenkins will not
run any test coverage metrics for you. It is left up to you to generate the raw code coverage data as part
of your automated build process. Jenkins, on the other hand, does an excellent job of reporting on the
code coverage metrics, including keeping track of code coverage over time, and providing aggregate
coverage across multiple application modules.
Code coverage can be a complicated business, and it helps to understand the basic process that Cobertura
follows, especially when you need to set it up in more low-level build scripting tools like Ant. Code
coverage analysis works in three steps. First, it modifies (or “instruments”) your application classes, to
make them keep a tally of the number of times each line of code has been executed.3 They store all this
data in a special data file (Cobertura uses a file called cobertura.ser).
When the application code has been instrumented, you run your tests against this instrumented code.
At the end of the tests, Cobertura will have generated a data file containing the number of times each
line of code was executed during the tests.
Once this data file has been generated, Cobertura can use this data to generate a report in a more usable
format, such as XML or HTML.
6.6.1.1. Integrating Cobertura with Maven
Producing code coverage metrics with Cobertura in Maven is relatively straightforward. If all you are
interested in is producing code coverage data, you just need to add the cobertura-maven-plugin to
the build section of your pom.xml file:
...
org.codehaus.mojo
cobertura-maven-plugin
2.5.1
html
xml
1 http://cobertura.sourceforge.net
2With the notable exception of Sonar, which we will look at later on in the book.
3This is actually a slight over-simplification; in fact, Cobertura stores other data as well, such as how many times each possible
outcome of a boolean test was executed. However this does not alter the general approach.
147
...
...
This will generate code coverage metrics when you invoke the Cobertura plugin directly:
$ mvn cobertura:cobertura
The code coverage data will be generated in the target/site/cobertura directory, in a file called
coverage.xml.
This approach, however, will instrument your classes and produce code coverage data for every build,
which is inefficient. A better approach is to place this configuration in a special profile, as shown here:
...
metrics
org.codehaus.mojo
cobertura-maven-plugin
2.5.1
html
xml
...
In this case, you would invoke the Cobertura plugin using the metrics profile to generate the code
coverage data:
$ mvn cobertura:cobertura -Pmetrics
Another approach is to include code coverage reporting in your Maven reports. This approach is
considerably slower and more memory-hungry than just generating the coverage data, but it can make
148
sense if you are also generating other code quality metrics and reports at the same time. If you want to
do this using Maven 2, you need to also include the Maven Cobertura plugin in the reporting section,
as shown here:
...
org.codehaus.mojo
cobertura-maven-plugin
2.5.1
html
xml
Now the coverage data will be generated when you generate the Maven site for this project:
$ mvn site
If your Maven project contains modules (as is common practice for larger Maven projects), you just need
to set up the Cobertura configuration in a parent pom.xml file—test coverage metrics and reports will
be generated separately for each module. If you use the aggregate configuration option, the Maven
Cobertura plugin will also generate a high-level report combining coverage data from all of the modules.
However, whether you use this option or not, the Jenkins Cobertura plugin will take coverage data from
several files and combine them into a single aggregate report.
At the time of writing, there is a limitation with the Maven Cobertura plugin—code coverage will only
be recorded for tests executed during the test life cycle phase, and not for tests executed during the
integration-test phase. This can be an issue if you are using this phase to run integration or web
tests that require a fully packaged and deployed application—in this case, coverage from tests that are
only performed during the integration test phase will not be counted in the Cobertura code coverage
metrics.
6.6.1.2. Integrating Cobertura with Ant
Integrating Cobertura into your Ant build is more complicated than doing so in Maven. However it does
give you a finer control over what classes are instrumented, and when coverage is measured.
Cobertura comes bundled with an Ant task that you can use to integrate Cobertura into your Ant builds.
You will need to download the latest Cobertura distribution, and unzip it somewhere on your hard disk.
149
To make your build more portable, and therefore easier to deploy into Jenkins, it is a good idea to place
the Cobertura distribution you are using within your project directory, and to save it in your version
control system. This way it is easier to ensure that the build will use the same version of Cobertura no
matter where it is run.
Assuming you have downloaded the latest Cobertura installation and placed it within your project in a
directory called tools, you could do something like this:
¶
•
‚
„
¶ Tell Ant where your Cobertura installation is.
• We need to set up a classpath that Cobertura can use to run.
‚ The path contains the Cobertura application itself.
„ And all of its dependencies.
Next, you need to instrument your application classes. You have to be careful to place these instrumented