enqueue/dequeue the element, and then write back the updated
sublist to SRAM. Thus, with this design, we only require O(√
N)
flip-flops and comparators, unlike O(N) in PIFO, at the cost of few
extra clock cycles to execute each primitive operation (§5.2) and 2×
SRAM overhead (Invariant 1). We evaluate these trade-offs in §6.
5.2 Implementation
In SRAM, PIEO maintains an array (of size 2√
N ) of sublists, called
Sublist-Array. Each sublist in the array is of size √
N . Further, each
sublist comprises two ordered sublists—Rank-Sublist and Eligibility-
Sublist. Each element in Rank-Sublist comprises three attributes:
(1) flow_id: This is the flow id of the element.
(2) rank: This is the rank value assigned to the element by the
enqueue function.
(3) send_time: This encodes the eligibility predicate assigned
to the element by the enqueue function. PIEO exploits the
fact that most scheduling algorithms use eligibility predicate
of the form (curr_time ≥ send_time) (§4), where send_time is
the time the element becomes eligible for scheduling. Thus,
the eligibility predicate in PIEO is encoded using a single
send_time value for each element. Predicate that is always
true is encoded by assigning send_time to 0, and predicate
that is always false is encoded by assigning send_time to ∞.
The Rank-Sublist is ordered by increasing rank values. Further,
corresponding to each Rank-Sublist, there is an Eligibility-Sublist of
the same size, which maintains a copy of the send_time attribute
from it’s corresponding Rank-Sublist. Eligibility-Sublist is ordered
by increasing send_time values.
In flip-flops, PIEO maintains an array of size 2√
N , called Ordered-
Sublist-Array, where each entry in the array points to a sublist in the
Sublist-Array. More specifically, each entry in the Ordered-Sublist-
Array comprises three attributes:
(1) sublist_id: This is the index (pointer) into the Sublist-Array,
pointing to sublist Sublist-Array[sublist_id].
(2) smallest_rank: This is the smallest rank value in the sublist
Sublist-Array[sublist_id], i.e.,
Sublist-Array[sublist_id].Rank-Sublist[0].rank.
(3) smallest_send_time: This is the smallest send_time value
in the sublist Sublist-Array[sublist_id], i.e.,
Sublist-Array[sublist_id].Eligibility-Sublist[0].
(4) num: This stores the current number of elements in
Sublist-Array[sublist_id].
^^^^^^^^^^^^^^^^^^^^Priority Encoder^^^^^^Flip-FlopsSRAMDual-port SRAM blocksSublistRank-SublistEligibility-SublistEmpty sublists}ComparatorsPriority EncoderPriority EncoderPointers to sublistsPriority EncoderFast, Scalable, and Programmable Packet Scheduler in Hardware
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 6: An example enqueue into the PIEO ordered list of size 16 elements (8 sublists each of size 4).
Ordered-Sublist-Array is ordered by increasing smallest_rank
value. Further, Ordered-Sublist-Array is dynamically partitioned
into two sections, as shown in Fig. 5—the section on the left points
to sublists which are not empty, while the section on the right
points to all the currently empty sublists.
By stitching together sublists in the order they appear in the
Ordered-Sublist-Array, one can get the entire list of elements in
PIEO. We call this list Global-Ordered-List. Global-Ordered-List is
ordered by increasing rank value. Logically, enqueue and dequeue
operations happen on top of the Global-Ordered-List.
Enqueue(f). The enqueue operation inserts element f into the
Global-Ordered-List. It ensures that after every enqueue operation,
the resulting Global-Ordered-List is ordered by increasing rank
value. This is implemented in hardware as follows:
• Cycle 1: In this cycle, we select the sublist to enqueue f
into, using the parallel compare operation (Ordered-Sublist-
Array[i].smallest_rank > f.rank). We feed the resulting bit-
vector into a priority encoder, which outputs index j. Sublist S
pointed by Ordered-Sublist-Array[j-1] is selected for enqueue.
• Cycle 2: In this cycle, we read the sublist S from SRAM.
In case S was full, the enqueue operation would push out
an existing element in S. Hence, we also read an additional
sublist S' to store the pushed out element. S' is either the
sublist to the immediate right of S in the Ordered-Sublist-
Array, provided it is not full, or else a new empty sublist.
• Cycle 3: In this cycle, we figure out the position to en-
queue within sublist S, by running priority encoders on
top of bit vectors returned by parallel compare operations
(S.Rank-Sublist[i].rank > f.rank), and (S.Eligibility-Sublist[i] >
f.send_time) resp. In case S was full, the tail element in S.Rank-
Sublist will be moved to the head of S'.Rank-Sublist, while
we use parallel compare operation (S'.Eligibility-Sublist[i] >
S[tail].send_time), followed by priority encoding, to figure
out the position to enqueue the send_time value of the ele-
ment moving from S into the eligibility sublist within S'. In
case S' was initially empty, we also re-arrange the Ordered-
Sublist-Array by shifting S' to the immediate right of S.
• Cycle 4: In this cycle, we enqueue/dequeue respective ele-
ments at the positions output from the last cycle, and write
back S (and S') to the SRAM. We also update the Ordered-
Sublist-Array entries for S and S' with the new values of (i)
num, (ii) smallest_rank (read from the corresponding Rank-
Sublist), and (iii) smallest_send_time (read from the corre-
sponding Eligibility-Sublist).
Invariant 1 [Bounding the number of sublists]. The key
to ensuring O(1) enqueue time is choosing a new empty sublist
for enqueue whenever both the sublist to which the new element
is to be enqueued and the sublist to it’s immediate right in the
Ordered-Sublist-Array are full. This avoids the chain-reaction of
shifting the tail element of one sublist to the head of next (which
would result in worst-case O(√
N) SRAM accesses), at the cost of
memory fragmentation (Fig. 6). However, an upshot of this design
is the invariant that there cannot be two consecutive partially full
sublists in the Ordered-Sublist-Array. As a consequence, to store N
elements using √
N -sized sublists, one would require at most 2√
N
sublists (2× SRAM overhead). We evaluate this overhead in §6.1.
375
7988929976044341505555399625011815410298352564026371401075312901214921615969768953439501525262940391216281541445437140147534098762567Rank-SublistEligibility-Sublistﬂow_idranksend_timesublist_idsmallest_ranksmallest_send_timenumOrdered-Sublist-ArrayEnqueue request  f = [13, 12, 2]Sublist 2 selected for enq.798892997604434150555539962501181541029835256402637140107531290121492161596976895343950152526294039121628154144543714014753409876256779889299760443415055553996250118154102983525640263714010753129012149216159697689534395015252629403912162815451445437140147534098762677988929976044341505555399625011815410291312283525371401075312901214921615969640267689534395021525294039121626Sublist 2 read from SRAM. Since Sublist 2 is full, and so is Sublist 1, empty list 5 is also read from SRAM.Priority encoder used to ﬁgure out positions to enq/deq.Ordered-Sublist-Array re-arranged by shifting Sublist 5 to right of 2.2824540261144543714014753409876267CYCLE - 1CYCLE - 2CYCLE - 3enq posdeq posCYCLE - 4Elements enq/deq at right positions.Sublists 2 and 5 written back to SRAM.Ordered-Sublist-Array entriesfor Sublists 2 and 5 updated.SIGCOMM ’19, August 19–23, 2019, Beijing, China
Vishal Shrivastav
Figure 7: An example dequeue from the PIEO ordered list of size 16 elements (8 sublists each of size 4).
Dequeue(). This operation returns the "smallest ranked eligible"
element in Global-Ordered-List. It is implemented as follows:
• Cycle 1: In this cycle, we select the sublist that contains the
"smallest ranked eligible" element. For this, we use the prior-
ity encoder to extract the sublist at the smallest index in the
Ordered-Sublist-Array that satisfies the predicate (curr_time
≥ Ordered-Sublist-Array[i].smallest_send_time). We call it S.
The predicate ensures that S will have at least one eligible
element, and since the Ordered-Sublist-Array is ordered by
increasing smallest_rank value, the "smallest ranked eligible"
element in the entire list is guaranteed to be in S.
• Cycle 2: In this cycle, we read the sublist S from SRAM. In
case S was full, after a dequeue it would be partially full. So, to
ensure Invariant 1 is not violated, we read another sublist,
either to the immediate left of S in the Ordered-Sublist-Array,
or to it’s immediate right, whichever is not full, and choose
either in case both of them are not full. We call it S'. If both
left and right sublists are full, we only read S, as in that case
even a partially full S would not violate Invariant 1.
• Cycle 3: In this cycle, we figure out the position to dequeue
the "smallest ranked eligible" element from S. For that, we use
the priority encoder that outputs the smallest index idx in
S.Rank-Sublist satisfying the predicate (curr_time ≥ S.Rank-
Sublist[i].send_time). The "smallest ranked eligible" element
to be dequeued and returned as the final output of dequeue()
operation is S.Rank-Sublist[idx]. Further, in the case S was
full, we move an element from S' to S, to ensure that S remains
full even after dequeue, hence ensuring that Invariant 1
will not be violated. The element to be moved, e, is deter-
ministically added to either the head (if S' is to the left of
S) or to the tail (if S' is to the right of S) of S.Rank-Sublist
in the next cycle. However, we have to rely on priority en-
coding to figure out the position to dequeue e.send_time
from S'.Eligibility-Sublist, and the corresponding position in
S.Eligibility-Sublist where it would be enqueued. For that, we
use parallel compare operations (S'.Eligibility-Sublist[i] ==
e.send_time) and (S.Eligibility-Sublist[i] > e.send_time) resp.
Finally, in case either S or S' becomes empty after dequeue,
we re-arrange the Ordered-Sublist-Array by shifting S or S' to
the head of the logical partition comprising empty sublists.
• Cycle 4: In this cycle, we enqueue/dequeue respective ele-
ments at the positions output from the last cycle, and write
back S (and S') to the SRAM. We also update the Ordered-
Sublist-Array entries for S and S' with the new values of (i)
num, (ii) smallest_rank (read from the corresponding Rank-
Sublist), and (iii) smallest_send_time (read from the corre-
sponding Eligibility-Sublist).
Dequeue(f). This operation dequeues a specific element f from
the Global-Ordered-List. PIEO keeps track of the sublist id that each
element (flow) within the Global-Ordered-List is stored at, as part
of the flow state, and updates this information after each primitive
operation. In cycle 1, we use that information to select the sublist
storing f, and then repeat cycles 2-4 from the dequeue() operation,
with a modification in cycle 3 where we use the predicate (f ==
S.Rank-Sublist[i].flow_id) to figure out the index idx of the element
in S.Rank-Sublist to be dequeued and returned as the final output.
376
7988929976044341505555399625011815410298352564026371401075312901214921615969768953439501525262940391216281541445437140147534098762567Rank-SublistEligibility-Sublistﬂow_idranksend_timesublist_idsmallest_ranksmallest_send_timenumOrdered-Sublist-ArrayDequeue triggered at curr_time = 6Sublist 1 selected for deq.7988929976044341505555399625011815410298352564026371401075312901214921615969768953439501525262940391216281541445437140147534098762567798892997604434150555539962501181541029835256402637140107531290121492161596976895343950152526294039121628154144544753409876237140156779889299760443455539962503714011815410298352564026107531290121492161596976893439405015252629391216Priority encoder used to ﬁgure out positions to enq/deq.Ordered-Sublist-Array re-arranged by moving 3 to head of empty list.CYCLE - 1CYCLE - 2CYCLE - 3CYCLE - 428154144344475340987623567[1, 50, 5] dequeued as the outputenq posdeq posSublist 1 read from SRAM.Since Sublist 1 is full, Sublist 3 also read from SRAMto ensure Invariant-1 is not violated.Elements enq/deq at right positions.Sublists 1 and 3 written back to SRAM.Ordered-Sublist-Array entriesfor Sublists 1 and 3 updated.Fast, Scalable, and Programmable Packet Scheduler in Hardware
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 8: Percentage of logic modules
(ALMs) consumed (out of 234 K).
Figure 9: Percentage of SRAM con-
sumed (out of 6.5 MB).
Figure 10: Clock rates achieved by the
scheduler circuit.
6 PROTOTYPE AND EVALUATION
We prototyped the PIEO scheduler on an Altera Stratix V [17]
FPGA comprising 234 K Adaptive Logic Modules (ALMs), 52 Mbits
(6.5 MB) SRAM, and 40 Gbps interface bandwidth. Our prototype
was written in System Verilog [49] comprising ∼1300 LOCs.
We evaluate the performance of our prototype across three
metrics—(i) Scalability, (ii) Scheduling rate, and (iii) Programma-
bility. To serve as the baseline, we synthesized the open-source
PIFO implementation [26] atop our FPGA. We use 16-bit rank and
predicate fields, same as in PIFO implementation.
6.1 Scalability
In this section, we evaluate how the logic and memory resources
consumed by PIEO’s design scale with the size of the PIEO sched-
uler. We report the percentage of available Adaptive Logic Modules
(ALMs) consumed to implement the combinational and flip-flop
based logic (Fig. 8), and the percentage of available SRAM consumed
to store the ordered list (Fig. 9). The baseline PIFO implementation
consumes 64% of the available logic modules to implement a PIFO
scheduler of size 1 K elements, and this scales linearly with the size
of PIFO, meaning we can’t fit a PIFO with 2 K elements or more on
our FPGA. In contrast, the logic consumption for PIEO increases
sub-linearly (as the square root function), and we can easily fit a
PIEO scheduler with 30 K elements on our FPGA. This is a direct
consequence of PIEO’s design, which unlike PIFO, exploits the mem-
ory hierarchy available in hardware to efficiently distribute storage
and processing across SRAM and flip-flops. Finally, even with 2×
SRAM overhead ( Invariant 1), the total SRAM consumption for
PIEO’s implementation is fairly modest (Fig. 9).
6.2 Scheduling rate
In this section, we evaluate the rate at which PIEO scheduler can
make the scheduling decisions. Scheduling rate is typically a func-
tion of: (a) the clock rate of the scheduler circuit, and (b) number of
cycles needed to execute each primitive operation6. Each primitive
operation in PIEO takes 4 clock cycles and Fig. 10 shows the clock
rate of PIEO circuit against increasing PIEO size. The clock rate
naturally decreases with increasing circuit complexity, but even at
80 MHz and assuming a non-pipelined design, one can execute a
6For output-triggered model (§3.2.1), the complexity of Pre-Enqueue function also
affects the scheduling rate, as explained in §3.2.1.
PIEO primitive operation every 50 ns, which is sufficient to schedule
MTU-sized packets at 100 Gbps line rate.
PIEO’s scheduling rate can be further improved by pipelining the
primitive operations. In a fully pipelined design, one could execute
one primitive operation every clock cycle. However, PIEO’s design
is limited by the number of SRAM access ports. As such, the mem-
ory stages of each primitive operation (cycle 2 and 4) uses both the
available access ports of dual-port SRAM to read/write two sublists.
Hence, memory stages of different primitive operations cannot be
executed in parallel, thus preventing a fully pipelined design. In
principle, by carefully scheduling the primitive operations, one can
still achieve some degree of pipelining, resulting in a better sched-
uling rate than a non-pipelined design. However, for simplicity, our
prototype only implements the non-pipelined design, and all the
analysis and results in the paper are for a non-pipelined design.
Further, the clock rates achieved by PIEO is a function of both
the PIEO design and the hardware device used to run the design.
We expect our design to run at much higher clock rates on more
powerful FPGAs [18], but even more importantly, on an ASIC hard-
ware, as ASIC based implementations tend to be more performant
than an equivalent FPGA based implementation of the same design
[20]. To back this using a concrete example, we note that PIFO’s
design on top of our FPGA was clocked at 57 MHz, as opposed to
1 GHz on an ASIC hardware as shown in [37]. At 1 GHz clock rate,
each primitive operation in PIEO would only take 4 ns.
PIEO vs. PIFO trade-offs. Unlike PIEO, PIFO’s hardware design
can be fully pipelined, partly because it does not access SRAM at all,