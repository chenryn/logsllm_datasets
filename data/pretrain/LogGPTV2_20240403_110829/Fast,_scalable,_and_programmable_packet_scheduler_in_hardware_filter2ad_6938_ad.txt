### Enqueue/Dequeue Operations and Design Trade-offs

In our design, elements are enqueued and dequeued by updating the corresponding sublist in SRAM. This approach requires only \(O(\sqrt{N})\) flip-flops and comparators, compared to \(O(N)\) in PIFO, at the cost of a few extra clock cycles for each primitive operation (§5.2) and 2× SRAM overhead (Invariant 1). We evaluate these trade-offs in §6.

### 5.2 Implementation

#### Data Structures in SRAM

PIEO maintains an array (of size \(2\sqrt{N}\)) of sublists, called `Sublist-Array`. Each sublist in this array is of size \(\sqrt{N}\). Each sublist consists of two ordered sublists: `Rank-Sublist` and `Eligibility-Sublist`.

- **Rank-Sublist**: Each element in the `Rank-Sublist` has three attributes:
  1. `flow_id`: The flow ID of the element.
  2. `rank`: The rank value assigned to the element by the enqueue function.
  3. `send_time`: The time at which the element becomes eligible for scheduling. Most scheduling algorithms use an eligibility predicate of the form \((\text{curr_time} \geq \text{send_time})\). A predicate that is always true is encoded by setting `send_time` to 0, and one that is always false is encoded by setting `send_time` to \(\infty\).

- **Eligibility-Sublist**: This sublist maintains a copy of the `send_time` attribute from the corresponding `Rank-Sublist` and is ordered by increasing `send_time` values.

#### Data Structures in Flip-Flops

PIEO also maintains an array of size \(2\sqrt{N}\), called `Ordered-Sublist-Array`, where each entry points to a sublist in the `Sublist-Array`. Each entry in the `Ordered-Sublist-Array` has the following attributes:

1. `sublist_id`: An index (pointer) into the `Sublist-Array`.
2. `smallest_rank`: The smallest rank value in the sublist.
3. `smallest_send_time`: The smallest `send_time` value in the sublist.
4. `num`: The current number of elements in the sublist.

The `Ordered-Sublist-Array` is ordered by increasing `smallest_rank` values and is dynamically partitioned into two sections: the left section points to non-empty sublists, and the right section points to empty sublists.

By stitching together sublists in the order they appear in the `Ordered-Sublist-Array`, we can construct the `Global-Ordered-List`, which is ordered by increasing rank value. Enqueue and dequeue operations logically occur on this `Global-Ordered-List`.

### Enqueue Operation

The enqueue operation inserts an element \(f\) into the `Global-Ordered-List` while maintaining the order by increasing rank value. The hardware implementation involves the following steps:

- **Cycle 1**: Select the sublist to enqueue \(f\) into using a parallel compare operation. The resulting bit-vector is fed into a priority encoder, which outputs the index \(j\). The sublist pointed to by `Ordered-Sublist-Array[j-1]` is selected for enqueue.
- **Cycle 2**: Read the selected sublist \(S\) from SRAM. If \(S\) is full, read an additional sublist \(S'\) to store the pushed-out element. \(S'\) is either the next non-full sublist or a new empty sublist.
- **Cycle 3**: Determine the position to enqueue within \(S\) using priority encoders on bit vectors returned by parallel compare operations. If \(S\) was full, move the tail element of \(S.Rank-Sublist\) to the head of \(S'.Rank-Sublist\). Use parallel compare operations to determine the position to enqueue the `send_time` value of the moved element in \(S'.Eligibility-Sublist\). If \(S'\) was initially empty, rearrange the `Ordered-Sublist-Array` by shifting \(S'\) to the immediate right of \(S\).
- **Cycle 4**: Enqueue/dequeue the respective elements at the determined positions and write back \(S\) (and \(S'\)) to SRAM. Update the `Ordered-Sublist-Array` entries for \(S\) and \(S'\) with the new values of `num`, `smallest_rank`, and `smallest_send_time`.

### Invariant 1: Bounding the Number of Sublists

To ensure \(O(1)\) enqueue time, a new empty sublist is chosen whenever both the target sublist and the next sublist in the `Ordered-Sublist-Array` are full. This avoids a chain-reaction of shifting elements, but introduces memory fragmentation. As a result, there cannot be two consecutive partially full sublists in the `Ordered-Sublist-Array`. To store \(N\) elements using \(\sqrt{N}\)-sized sublists, at most \(2\sqrt{N}\) sublists (2× SRAM overhead) are required.

### Dequeue Operation

The dequeue operation returns the "smallest ranked eligible" element in the `Global-Ordered-List`. The hardware implementation involves the following steps:

- **Cycle 1**: Select the sublist \(S\) that contains the "smallest ranked eligible" element using a priority encoder to find the sublist at the smallest index in the `Ordered-Sublist-Array` that satisfies the predicate \((\text{curr_time} \geq \text{smallest_send_time})\).
- **Cycle 2**: Read the sublist \(S\) from SRAM. If \(S\) was full, read another sublist \(S'\) to ensure Invariant 1 is not violated.
- **Cycle 3**: Determine the position to dequeue the "smallest ranked eligible" element from \(S\) using a priority encoder. If \(S\) was full, move an element from \(S'\) to \(S\) to keep \(S\) full. Use parallel compare operations to determine the position to dequeue the `send_time` value from \(S'.Eligibility-Sublist` and the corresponding position in `S.Eligibility-Sublist` where it would be enqueued. Rearrange the `Ordered-Sublist-Array` if either \(S\) or \(S'\) becomes empty.
- **Cycle 4**: Enqueue/dequeue the respective elements at the determined positions and write back \(S\) (and \(S'\)) to SRAM. Update the `Ordered-Sublist-Array` entries for \(S\) and \(S'\) with the new values of `num`, `smallest_rank`, and `smallest_send_time`.

### Prototype and Evaluation

We prototyped the PIEO scheduler on an Altera Stratix V FPGA with 234 K Adaptive Logic Modules (ALMs), 52 Mbits (6.5 MB) SRAM, and 40 Gbps interface bandwidth. Our prototype, written in System Verilog, comprises approximately 1300 lines of code.

#### Scalability

We evaluated the scalability of PIEO's design in terms of logic and memory resources. PIEO's logic consumption increases sub-linearly (as the square root function), allowing us to fit a scheduler with 30 K elements on our FPGA. In contrast, PIFO consumes 64% of the available logic modules for a 1 K element scheduler, scaling linearly and preventing fitting a 2 K element PIFO on the FPGA. Even with 2× SRAM overhead, PIEO's SRAM consumption is modest.

#### Scheduling Rate

The scheduling rate is a function of the clock rate and the number of cycles needed for each primitive operation. Each primitive operation in PIEO takes 4 clock cycles. At 80 MHz, a non-pipelined design can execute a primitive operation every 50 ns, sufficient for scheduling MTU-sized packets at 100 Gbps line rate. Pipelining can further improve the scheduling rate, but is limited by the number of SRAM access ports. Our prototype implements a non-pipelined design, achieving a clock rate of 80 MHz. On more powerful FPGAs or ASICs, higher clock rates (e.g., 1 GHz) can reduce the execution time to 4 ns per primitive operation.

#### Trade-offs

Compared to PIFO, PIEO uses fewer logic resources but requires more SRAM and a few extra clock cycles per operation. PIFO can be fully pipelined, but its design does not scale well in terms of logic resources. PIEO's design efficiently distributes storage and processing across SRAM and flip-flops, making it more scalable and suitable for large-scale packet scheduling.