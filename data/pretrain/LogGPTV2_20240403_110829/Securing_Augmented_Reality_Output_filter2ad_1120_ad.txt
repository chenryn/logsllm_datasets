goals, future AR system designers may wish to make different
design choices. Our work surfaces a number of challenges and
tradeoffs that must be considered, which we hope will help
guide potential alternate design paths.
V.
IMPLEMENTATION
We now describe our prototype implementation of Arya.
Developing our prototype gives us the opportunity to deeply
explore and evaluate Arya’s AR output policy module, and
iteratively feeds back into our design process. Our prototype
consists of several parts: an AR simulator and virtual scenes
to represent the real world, the Arya core implementation
(including the output policy module and infrastructure to
support multiple applications), standalone applications that run
on Arya, and AR output policies that are enforced by Arya.
We detail these components in turn.
AR Simulator. In practice, a full-ﬂedged AR system has many
moving parts — crucially, it continuously senses and processes
real-world input, which feeds into applications as well as, in
our design, the output policy module itself. However, real-
world input is by its nature noisy and variable, as we discuss
328
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
in Section VII. Even if we had perfect sensor hardware and
sensor data processing algorithms, we would still
like to
evaluate in controlled, possibly hard-to-stage scenarios (e.g.,
while driving).
Since the focus of our work is not on improving or evalu-
ating AR input processing (a topic of other research efforts,
e.g., [9, 22, 31]), and to support controlled experiments, we
abstract away the input handling part of Arya for our prototype.
Instead, we create an AR simulator, which consists of a
virtual reality (VR) backend to represent the real world. This
approach is similar to driving simulators commonly used in
other research, e.g., [48].
Speciﬁcally, rather than outﬁtting our prototype with real
hardware sensors, we build on the Unity game engine, using
Unity virtual environments, or “scenes”, to represent the real
world. This technique allows us to isolate the output manage-
ment portion of the system and reliably “detect” our simulated
real-world objects. AR applications running on Arya can create
virtual objects to place into these scenes, and Arya’s output
policy module can regulate those objects given information
about the fully-speciﬁed underlying VR world.
Virtual Scenes Representing the Physical World. A beneﬁt
of our AR simulator is that it easily allows us to test out-
put policies in different Unity scenes that represent various
real-world scenarios. Speciﬁcally, we developed three scenes
to represent HMD and automotive scenarios: an “in-home”
scene,3 an “AR-windshield” scene, and an “ofﬁce” scene.
These scenes are shown in Figure 6; the bare scenes, without
AR applications running, are shown in the left column of
that ﬁgure. We emphasize that these scenes represent the real
world, and that no virtual content created by AR applications
is shown in the bare scenes.
Arya Core. Up to this point, we have described only our
prototyping infrastructure for representing a model of the real
world. We now turn to Arya itself. We build Arya’s core also
on top of Unity, written in 3767 lines of C# code4. Loading
this core into a new scene requires only a few user interface
actions within the Unity editor. While Arya interfaces with our
virtual scenes, it is largely modularized.
The Arya core includes infrastructure for running multiple
AR applications on top of it,
including handling multiple
application threads and managing communication over local
sockets. Arya exposes APIs to those applications for querying
the real-world scene as well as for creating and modifying AR
objects (such as Object.Move() and CreateObject()).
We implement recognizers in our prototype by labeling
speciﬁc “real-world” objects in our virtual scenes as objects
of interest, e.g., people, billboards, and signs. This information
about the real world, as well as the state Arya keeps about ap-
plications’ AR objects created and modiﬁed through its APIs,
feeds into Arya’s output policy module. This module enforces
policies on application output, as detailed in Section IV-C2.
3We augmented a pre-built scene, “Brian’s House”, purchased from the
Unity Asset Store: https://www.assetstore.unity3d.com/en/#!/content/44784
4We use the CLOC tool for calculating lines of code: https://github.com/
AlDanial/cloc/releases/tag/v1.70
Application Interface. Our prototype supports multiple stan-
dalone applications running atop the Arya core, which can
simultaneously create and interact with AR objects and aug-
ment the same “real-world” scene. Applications are isolated
by running as separate OS processes, such that their only
interaction is implicitly by augmenting the same “reality.”
Arya applications are written in C# and extend our base class
ARApplication. This base class contains 889 lines of C#
code and provides the infrastructure for communicating with
the Arya core over local sockets to make API calls (e.g., to
create or modify objects). We describe case study applications
that we implemented for our evaluation in Section VI.
Prototype Policies. Finally, we prototype an AR output policy
framework. Policies are written as standalone C# modules that
extend our ARPolicy base class and are programmatically
instantiated by the Arya core. As described in Section IV, poli-
cies follow a well-deﬁned structure consisting of a condition
and a mechanism. The Arya core provides a ﬁxed set of AR
object attributes (used in conditions) and enforcement mecha-
nisms that policies can employ. Table II details the speciﬁc case
study policies we implemented. We stress that the conditions
and mechanisms we chose to implement are not the only
possible options that Arya can support. Additional attributes
could be deﬁned, as could additional mechanisms that meet our
composability criteria (moving objects towards “less intrusive”
states). For example, our most complex attribute (determining
if one AR object occludes another object) consists of only 49
lines of code, suggesting that developing new attributes could
be easily done.
VI. EVALUATION
Our evaluation goals are two-fold. First, we seek to evaluate
Arya’s ability to support and enforce a variety of policies from
different sources. Second, since policy enforcement is on the
critical path for rendering output, we measure the performance
overhead introduced by our prototype’s output policy mod-
ule. Our results suggest that Arya is a promising approach
for constraining AR output — not only does it successfully
address, for the ﬁrst time, many output security issues, but
it also does so with reasonable performance. We use these
results to surface additional lessons and recommendations for
future AR platform developers.
A. Case Studies: Policy Expressiveness and Effectiveness
We evaluate the efﬁcacy of Arya’s output policy module
through case study applications that run within our three virtual
scenes, described in Section V: a home, a driving scene, and
an ofﬁce. We design our case study applications to exhibit both
(a) acceptable or desirable behaviors, as well as (b) behaviors
that violate one or more of our prototype policies detailed
in Table II. Figure 6 shows screenshots of our applications
running in these scenes both without (center column) and
with (right column) policy enforcement active. The left column
shows the bare scenes, with no applications running.
Case-Study Applications. We developed two applications per
scene that test our various policies. Our focus is to exercise
329
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
Identiﬁer
P1
P2
P3
P4
P5
P6
P7
P8
P9
P10
Conditions
If an AR object’s speed exceeds X
If an AR object is within X feet of the user
If an AR object occupies more than X percent of the display
If an application attempts to create a head-locked object
If a user’s vehicle is in motion
If an AR object is occluding pedestrians or road signs
If an AR object is occluding exit signs
If an AR object’s alpha value is less than X
If an AR object is not bounded by a real-world billboard
If an AR object is occluding another application’s AR object
Mechanisms
Set the object’s speed to X
Set the object’s alpha value to 0
Set the object’s alpha value to 0
Deny the creation request
Set the alpha value of all applicable AR objects to 0
Set the object’s alpha value to 0
Set the object’s alpha value to 0
Disable user interactions with the object
Set the object’s alpha value to 0
Set the object’s alpha value to 0
TABLE II: Implemented Policies. This table details the conditions under which our prototype policies are violated and the mechanisms Arya
uses to enforce them. This list matches the policies in Table I. X represents a parameterized value speciﬁed by individual policies. We note that
policies may be selectively applied to speciﬁc applications or groups of applications — for example, P9 may only apply to an advertising app.
logic. Nevertheless,
our output policies, and thus we did not implement complex
application-level
these applications are
inspired by real applications that might (or already do) exist
for these emerging platforms.
HMD in the Home. For the home scene (top row of Figure 6),
we created a “Virtual Pet” app, which displays a world-
locked virtual cat that can move independently in the user’s
environment. However, the application moves the cat at a
distractingly fast speed through the user’s view, and it displays
a head-locked spider that the user cannot look away from.
Additionally, we built a tabletop game5 in which the user
increases their score by hitting coins with a ball. However, the
application pops up in-game purchase notiﬁcations that block
the output of other applications and may annoy the user.
AR Windshields. For the driving scene (center row of Figure 6),
we created an advertising application that displays targeted ads
over real-world blank billboards. However, the application also
displays ads throughout the rest of the user’s view, potentially
creating a driving hazard. Additionally, we implemented a
“notiﬁcation” application that displays dummy text message,
calendar, and email alerts. Unfortunately, it continues to gen-
erate distracting alerts while the car is in motion.
HMD in the Workplace. For the ofﬁce scene (bottom row
of Figure 6), we imagine a group of engineers using AR
to design a new automobile.6 We built an application that
allows users to view their car models from different angles
simultaneously. Additionally, we created an application that
displays information to users about their colleagues, such as
their names and roles in the company. While both of these
applications do not exhibit intentionally malicious behavior,
their outputs sometimes obscure the user’s view by taking up
too much of the screen, appearing too close to the user’s face,
or blocking out important information in the real world such
as exit signs.
Security Discussion. As illustrated in Figure 6, Arya success-
fully allows multiple case study applications to concurrently
display content while simultaneously enforcing our prototype
policies to prevent malicious or undesirable output behaviors.
5Inspired by https://unity3d.com/learn/tutorials/projects/roll-ball-tutorial.
6Inspired by an application for HoloLens: https://www.youtube.com/watch?
v=yADhOKEbZ5Q.
•
Speciﬁcally, referring to policies by their identiﬁers in Table II:
In the home scene, P4 prevents the head-locked spider
from being created. Additionally, P10 prevents the in-
app purchase dialog from occluding the cat (a virtual
object from another application), and P1 prevents the
cat from moving too fast.
In the driving scene, P6 prevents virtual ads from ob-
scuring real-world pedestrians, and P9 constrains them
to appearing only over real-world billboards. P5 prevents
notiﬁcations from popping up while the car is in motion.
In the ofﬁce scene, P7 prevents the modeling application
from blocking real-world exit signs. Meanwhile, P2 and
P3 make objects that get too close to the user or take
up too much space partially transparent.
•
•
These case studies exercise all but one of the policies we
implemented (Table II). The exception is P8, which disables
user input on obscured AR objects. Though we implemented
this policy, we cannot exercise it, because our prototype
is designed to focus on generating output and hence lacks
meaningful user input for application interactions.
Through these case studies, we conﬁrm the ability of our
policy framework to support policies that constrain a range of
behaviors in different contexts. Our case studies also highlight,
for completeness, an output safety risk that our current policies
cannot mitigate: risks with unsafe or frightening content,
such as spiders. Our policies — just like conventional web
browsers, desktops, and mobile devices — do not prevent ap-
plications from displaying speciﬁc undesirable objects. This
issue presents a potential avenue for future work.
B. Performance Evaluation
Arya’s output policy module directly mediates content that
applications wish to display and thus lies on the critical path
for rendering. As such, the output policy module should incur
minimal overhead. While our prototype implementation is not
optimized or representative of a full-ﬂedged AR system, ana-
lyzing its performance can nevertheless shed light on possible
output bottlenecks and other considerations that must go into
implementing an output policy module in a production system.
Our case-study applications successfully exercise our proto-
type policies, but they contain relatively few AR objects. To
identify potential bottlenecks, we next analyze the performance
330
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 6: Case Studies. These screenshots show our case study scenarios: HMD in the home (top), car windshield (center), and HMD in the
ofﬁce (bottom). The left column shows the bare scenes in our Unity-based AR simulator, representing the real world without any apps running.
From our prototype’s perspective, everything in the bare scene is part of the real world. The center column shows our case study apps running,
exhibiting both desirable and undesirable AR output behaviors. The right column shows the result of policy enforcement, leaving only desirable
AR output. Note that Unity’s alpha adjustment mechanism leaves transparency artifacts to outline where violating AR objects would be.
of the output policy module under heavier workloads, i.e.,
when there are many objects present. We ﬁrst proﬁle the
performance of our output policy module in the absence of
our application communication infrastructure to isolate the
performance impact of our policies. We then analyze our com-
munication infrastructure and conduct a full-system evaluation.
1) PROFILING THE OUTPUT POLICY MODULE
We begin by proﬁling our prototype’s output policy module
without the overhead of application communication. To isolate
the impact of the output policy module, we create a simple
evaluation scene containing several objects (a “person”, a
“billboard”, and an “exit sign”). Rather than having a separate
application process create and update AR objects, we instead
programmatically trigger API calls directly in Arya’s core on a
per-frame basis. From the output policy module’s perspective,
these requests appear to come from an actual application.
This setup simulates application behaviors but eliminates any
performance impact of the communication infrastructure and
allows us to focus on the output policy module itself. This
methodology also allows us to ensure the same amount of
work occurs each frame, enabling repeatable experiments.
Our primary performance metric for proﬁling the output
policy module is the frame rate, or average frames-per-second
(FPS), of Arya’s Unity backend. Since Arya’s core functions
(handling API calls and enforcing policies) operate on a per-
frame basis, extra overhead introduced by the output policy
module directly decreases the frame rate, making FPS a mean-
ingful metric. For each data point in our measurements, we
calculated the average FPS over a 30 second interval (after an
initial 10 second warm-up period), repeating each trial 5 times.
We conduct two evaluations with this experimental setup: ﬁrst,
we compare the individual performance of the policies we
implemented, and then we investigate policy performance as
we scale the number of virtual objects in the scene.
Individual Policy Performance. We begin by trying to un-
derstand the performance impact of our individual policies
relative to a baseline scene without any policy enforcement.
These results are shown in Tables III and IV.
In designing this experiment, our goal is to fully tax the
system, such that differences between policies become visible.
To do so, we simulate the following application behaviors:
we create N overlapping objects directly in front of the user,
and move each object a small amount every frame. For these
experiments, we chose N objects such that the baseline would
be under load — i.e., less than 60 FPS, which is considered a
standard for smooth gameplay in many PC video games [13] —
so that we could see the effects of policies. We experimentally
determined that N = 500 objects would give us a baseline
331
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
Baseline
51.4
1.2
P1
51.3
1.3
P2
48.0
1.1
P3