### Goals and Future Directions
Future AR system designers may opt for different design choices. Our work highlights several challenges and trade-offs that must be considered, which we hope will guide potential alternative design paths.

### V. Implementation
In this section, we describe the prototype implementation of Arya. Developing our prototype allows us to deeply explore and evaluate Arya’s AR output policy module, providing iterative feedback into our design process. The prototype consists of several components: an AR simulator and virtual scenes representing the real world, the core Arya implementation (including the output policy module and infrastructure to support multiple applications), standalone applications running on Arya, and AR output policies enforced by Arya. We detail these components below.

#### AR Simulator
A full-fledged AR system continuously senses and processes real-world input, which feeds into applications and, in our design, the output policy module. However, real-world input is inherently noisy and variable, as discussed in Section VII. Even with perfect sensor hardware and data processing algorithms, evaluating in controlled, hard-to-stage scenarios (e.g., while driving) remains challenging.

Since our focus is not on improving or evaluating AR input processing (a topic of other research efforts, e.g., [9, 22, 31]), and to support controlled experiments, we abstract away the input handling part of Arya for our prototype. Instead, we create an AR simulator using a virtual reality (VR) backend to represent the real world. This approach is similar to driving simulators used in other research, e.g., [48].

Specifically, we use the Unity game engine to build Unity virtual environments, or "scenes," to represent the real world. This technique allows us to isolate the output management portion of the system and reliably "detect" simulated real-world objects. AR applications running on Arya can create virtual objects to place into these scenes, and Arya’s output policy module can regulate those objects based on information about the fully-specified underlying VR world.

#### Virtual Scenes Representing the Physical World
Our AR simulator easily allows us to test output policies in different Unity scenes representing various real-world scenarios. We developed three scenes to represent HMD and automotive scenarios: an "in-home" scene, an "AR-windshield" scene, and an "office" scene. These scenes are shown in Figure 6; the bare scenes, without AR applications running, are shown in the left column of that figure. These scenes represent the real world, and no virtual content created by AR applications is shown in the bare scenes.

#### Arya Core
We have described our prototyping infrastructure for representing a model of the real world. Now, we turn to Arya itself. The Arya core is built on top of Unity, written in 3767 lines of C# code. Loading the core into a new scene requires only a few user interface actions within the Unity editor. While Arya interfaces with our virtual scenes, it is largely modularized.

The Arya core includes infrastructure for running multiple AR applications, handling multiple application threads, and managing communication over local sockets. Arya exposes APIs to these applications for querying the real-world scene and creating and modifying AR objects (such as `Object.Move()` and `CreateObject()`).

We implement recognizers in our prototype by labeling specific "real-world" objects in our virtual scenes as objects of interest, e.g., people, billboards, and signs. This information, along with the state Arya keeps about applications' AR objects, feeds into Arya’s output policy module. This module enforces policies on application output, as detailed in Section IV-C2.

#### Application Interface
Our prototype supports multiple standalone applications running atop the Arya core, which can simultaneously create and interact with AR objects and augment the same "real-world" scene. Applications are isolated by running as separate OS processes, interacting implicitly by augmenting the same "reality." Arya applications are written in C# and extend our base class `ARApplication`. This base class contains 889 lines of C# code and provides the infrastructure for communicating with the Arya core over local sockets to make API calls (e.g., to create or modify objects). We describe case study applications implemented for our evaluation in Section VI.

#### Prototype Policies
Finally, we prototype an AR output policy framework. Policies are written as standalone C# modules that extend our `ARPolicy` base class and are programmatically instantiated by the Arya core. As described in Section IV, policies follow a well-defined structure consisting of a condition and a mechanism. The Arya core provides a fixed set of AR object attributes (used in conditions) and enforcement mechanisms that policies can employ. Table II details the specific case study policies we implemented. We stress that the conditions and mechanisms we chose to implement are not the only possible options that Arya can support. Additional attributes could be defined, as could additional mechanisms that meet our composability criteria (moving objects towards "less intrusive" states). For example, our most complex attribute (determining if one AR object occludes another object) consists of only 49 lines of code, suggesting that developing new attributes could be easily done.

### VI. Evaluation
Our evaluation has two main goals. First, we seek to evaluate Arya’s ability to support and enforce a variety of policies from different sources. Second, since policy enforcement is on the critical path for rendering output, we measure the performance overhead introduced by our prototype’s output policy module. Our results suggest that Arya is a promising approach for constraining AR output, successfully addressing many output security issues with reasonable performance. We use these results to surface additional lessons and recommendations for future AR platform developers.

#### A. Case Studies: Policy Expressiveness and Effectiveness
We evaluate the efficacy of Arya’s output policy module through case study applications running in our three virtual scenes: a home, a driving scene, and an office. We designed our case study applications to exhibit both acceptable or desirable behaviors and behaviors that violate one or more of our prototype policies detailed in Table II. Figure 6 shows screenshots of our applications running in these scenes both without (center column) and with (right column) policy enforcement active. The left column shows the bare scenes, with no applications running.

##### Case-Study Applications
We developed two applications per scene to test our various policies. Our focus is to exercise our output policies, and thus we did not implement complex application-level logic. Nevertheless, these applications are inspired by real applications that might (or already do) exist for these emerging platforms.

- **HMD in the Home:** For the home scene (top row of Figure 6), we created a "Virtual Pet" app, which displays a world-locked virtual cat that can move independently in the user’s environment. However, the application moves the cat at a distractingly fast speed through the user’s view and displays a head-locked spider that the user cannot look away from. Additionally, we built a tabletop game5 in which the user increases their score by hitting coins with a ball. However, the application pops up in-game purchase notifications that block the output of other applications and may annoy the user.
- **AR Windshields:** For the driving scene (center row of Figure 6), we created an advertising application that displays targeted ads over real-world blank billboards. However, the application also displays ads throughout the rest of the user’s view, potentially creating a driving hazard. Additionally, we implemented a "notification" application that displays dummy text message, calendar, and email alerts. Unfortunately, it continues to generate distracting alerts while the car is in motion.
- **HMD in the Workplace:** For the office scene (bottom row of Figure 6), we imagine a group of engineers using AR to design a new automobile. We built an application that allows users to view their car models from different angles simultaneously. Additionally, we created an application that displays information to users about their colleagues, such as their names and roles in the company. While both of these applications do not exhibit intentionally malicious behavior, their outputs sometimes obscure the user’s view by taking up too much of the screen, appearing too close to the user’s face, or blocking out important information in the real world such as exit signs.

##### Security Discussion
As illustrated in Figure 6, Arya successfully allows multiple case study applications to concurrently display content while simultaneously enforcing our prototype policies to prevent malicious or undesirable output behaviors. Specifically, referring to policies by their identifiers in Table II:

- **Home Scene:**
  - P4 prevents the head-locked spider from being created.
  - P10 prevents the in-app purchase dialog from occluding the cat (a virtual object from another application).
  - P1 prevents the cat from moving too fast.

- **Driving Scene:**
  - P6 prevents virtual ads from obscuring real-world pedestrians.
  - P9 constrains them to appearing only over real-world billboards.
  - P5 prevents notifications from popping up while the car is in motion.

- **Office Scene:**
  - P7 prevents the modeling application from blocking real-world exit signs.
  - P2 and P3 make objects that get too close to the user or take up too much space partially transparent.

These case studies exercise all but one of the policies we implemented (Table II). The exception is P8, which disables user input on obscured AR objects. Though we implemented this policy, we cannot exercise it because our prototype is designed to focus on generating output and lacks meaningful user input for application interactions.

Through these case studies, we confirm the ability of our policy framework to support policies that constrain a range of behaviors in different contexts. Our case studies also highlight, for completeness, an output safety risk that our current policies cannot mitigate: risks with unsafe or frightening content, such as spiders. Our policies, like conventional web browsers, desktops, and mobile devices, do not prevent applications from displaying specific undesirable objects. This issue presents a potential avenue for future work.

#### B. Performance Evaluation
Arya’s output policy module directly mediates content that applications wish to display and thus lies on the critical path for rendering. As such, the output policy module should incur minimal overhead. While our prototype implementation is not optimized or representative of a full-fledged AR system, analyzing its performance can shed light on potential output bottlenecks and considerations for implementing an output policy module in a production system.

Our case-study applications successfully exercise our prototype policies but contain relatively few AR objects. To identify potential bottlenecks, we next analyze the performance of the output policy module under heavier workloads, i.e., when there are many objects present. We first profile the performance of our output policy module in the absence of our application communication infrastructure to isolate the performance impact of our policies. We then analyze our communication infrastructure and conduct a full-system evaluation.

##### 1. Profiling the Output Policy Module
We begin by profiling our prototype’s output policy module without the overhead of application communication. To isolate the impact of the output policy module, we create a simple evaluation scene containing several objects (a "person," a "billboard," and an "exit sign"). Rather than having a separate application process create and update AR objects, we programmatically trigger API calls directly in Arya’s core on a per-frame basis. From the output policy module’s perspective, these requests appear to come from an actual application.

This setup simulates application behaviors but eliminates any performance impact of the communication infrastructure, allowing us to focus on the output policy module itself. This methodology also ensures the same amount of work occurs each frame, enabling repeatable experiments.

Our primary performance metric for profiling the output policy module is the frame rate, or average frames-per-second (FPS), of Arya’s Unity backend. Since Arya’s core functions (handling API calls and enforcing policies) operate on a per-frame basis, extra overhead introduced by the output policy module directly decreases the frame rate, making FPS a meaningful metric. For each data point in our measurements, we calculated the average FPS over a 30-second interval (after an initial 10-second warm-up period), repeating each trial 5 times.

We conduct two evaluations with this experimental setup: first, we compare the individual performance of the policies we implemented, and then we investigate policy performance as we scale the number of virtual objects in the scene.

**Individual Policy Performance:**
We begin by understanding the performance impact of our individual policies relative to a baseline scene without any policy enforcement. These results are shown in Tables III and IV.

In designing this experiment, our goal is to fully tax the system, such that differences between policies become visible. To do so, we simulate the following application behaviors: we create N overlapping objects directly in front of the user and move each object a small amount every frame. For these experiments, we chose N objects such that the baseline would be under load—i.e., less than 60 FPS, which is considered a standard for smooth gameplay in many PC video games [13]—so that we could see the effects of policies. We experimentally determined that N = 500 objects would give us a baseline.

| Policy | Average FPS | Standard Deviation |
|--------|-------------|--------------------|
| Baseline | 51.4 | 1.2 |
| P1 | 51.3 | 1.3 |
| P2 | 48.0 | 1.1 |
| P3 | ... | ... |

[Continued in the next section]