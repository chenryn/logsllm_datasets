MC (90s)
MC−Path (90s)
 10
 15
 20
 25
 30
Cycle Length (sec)
(b) False Alarms (log scale)
Table 3: Number of alarms in about two weeks.
We use the same measurements introduced in Sec. 3.5.2.
Both experiments lasted for slightly less than two weeks.
The PlanetLab experiment has 16,262 cycles of one minute
(C = 60) and the enterprise network experiment has 228,806
cycles of ﬁve seconds each (C = 5). We use a conservative
−6, resulting in κ = 7 and μ = 420 ms for
value for F = 10
PlanetLab and κ = 4 and μ = 280 ms for the enterprise. We
conﬁgure multi-cycle strategies to identify failures of more
than 11 minutes, as a result we have n = 10 for PlanetLab
and n = 120 for the enterprise network.
Tab. 3 shows the number of alarms with and without con-
ﬁrmation for each aggregation strategy. We have no ground
truth for these deployments, so we cannot label which of
these alarms are false. Considering the Emulab results from
Sec. 4.2, most of the alarms we eliminate with our conﬁrma-
tion and aggregation strategies should be false.
These results highlight the contrast between the dynamic
PlanetLab environment and the more stable enterprise net-
work. Applying tomography to raw measurements in either
network (represented by basic without conﬁrmation) would
lead to thousands of alarms: PlanetLab would have one
alarm per minute, and the enterprise network would have
one alarm every three minutes. Although the enterprise ex-
periments have considerably more cycles, fewer than 3% of
them have an alarm, whereas PlanetLab raises alarms at
every cycle. Not even failure conﬁrmation helps reduce the
number of alarms in PlanetLab. This result may seem to
contradict the results from Fig. 3, which shows that failure
conﬁrmation signiﬁcantly reduces the fraction of conﬁrmed
path failures in PlanetLab. Failure conﬁrmation does re-
duce the total number of path failures in PlanetLab from
1,739,776 to 160,777. Nevertheless, every cycle still has at
least one conﬁrmed path failure, which triggers basic to
build a reachability matrix. Failure conﬁrmation is more
eﬀective to remove alarms in the enterprise network.
mc-path’s ﬂexible aggregation strategy works for both de-
ployments. As shown in our controlled experiments, mc is
not useful in dynamic environments; it never builds a reach-
ability matrix for PlanetLab. In the enterprise deployment,
mc can detect some failures, but not as many as mc-path.
mc-path with conﬁrmation triggers 135 alarms in Planet-
Lab (approximately 12 alarms per day). This number is
more than a hundred times smaller than using basic without
conﬁrmation. In the enterprise network, mc-path reduces
the number of alarms to 2 per day. It is more realistic to
expect that an operational team will deal with two alarms
per day than one alarm every three minutes. We could also
conﬁgure our mechanisms to only identify longer failures,
which would reduce even more the number of alarms.
4.4 Comparison to State of the Art
We compare our approach to that of Kompella et al. [16],
which is the most closely related work to ours. We present a
brief overview of the previous approach, describe the exper-
iment setup, and compare the performance of each method.
Figure 9: Aggregation with overlapping failures.
90 seconds and shorter ones last for 20 seconds. In contrast
to the other plots in this section, the x-axis presents the
cycle length. These experiments show that mc misses most
of the longer failures because of the instability of path sta-
tuses created by shorter failures, which have the same eﬀect
as detection errors. All failures that mc identiﬁes are cases
where short failures only aﬀect paths that are also aﬀected
by long failures. mc is very conservative and never trig-
gers a false alarm. basic correctly identiﬁes all long failures
because there are intervals where the long failure persists
but no short failure is happening, but it triggers many false
alarms (Fig. 9(b)). mc-path is a good compromise between
these extremes.
It correctly identiﬁes long failures, while
keeping a small number of false alarms. All of these false
alarms occur when a short failure occurs just after a long
one, and this short failure aﬀects a subset of the paths that
were aﬀected by the long failure. In this scenario, mc-path
identiﬁes the short failure, which we label as a false alarm.
These results conﬁrm the ﬁndings from our analysis. Both
detection errors and short failures reduce the accuracy of
aggregation strategies. basic triggers many false alarms and
mc misses some failures, so mc-path is a good method to
use in environments where detection errors are common.
4.3 Wide-area Experiments
We apply the tomography algorithm on measurements
from PlanetLab and the enterprise network to evaluate the
eﬀect of conﬁrmation and aggregation on the number of
alarms raised in a real network. We show that conﬁrmation
and multi-cycle aggregation reduces the number of alarms
from thousands to a few.
264t
e
a
R
n
o
i
t
a
c
i
f
i
t
n
e
d
I
 1
 0.8
 0.6
 0.4
 0.2
 0
 2
MC−Path (n=2)
Absolute (τ=2)
Absolute (τ=4)
Absolute (τ=9)
Absolute (τ=18)
 8  10  12  14  16  18  20
 6
 4
Failure Length / Cycle Length
l
s
m
r
a
A
e
s
a
F
l
l
a
t
o
T
1000
500
200
100
50
20
10
5
2
1
0
 2
Absolute (τ=2)
Absolute (τ=4)
Absolute (τ=9)
Absolute (τ=18)
MC−Path (n=2)
 6
 8  10  12  14  16  18  20
 4
Failure Length / Cycle Length
Figure 10: Comparison of identiﬁcation rate.
Figure 11: Comparison of number of false alarms.
We ﬁnd that our approach has both a higher identiﬁcation
rate and lower false-alarm rate for all blackholes that last at
least three cycles.
Overview and experiment setup. Kompella et al.’s
method works as follows: (1) A coordinator groups every
lost probe into a failure signature; this failure signature is a
type of reachability matrix, except that each element counts
the number of lost probes in a path. (2) The coordinator
builds a hypothesis set for a failure signature by iteratively
selecting the link that explains the largest number of lost
probes. (3) The coordinator removes links from the hypoth-
esis set that may be due to transient packet losses. In step
three, we consider only their best ﬁltering technique, called
absolute. This technique removes links from the hypoth-
esis set if the absolute number of failures they could have
caused is less than a chosen threshold, τ . We keep the net-
work topology ﬁxed and do not apply their techniques to
merge diﬀerent topology snapshots. absolute works oﬄine
and does not use failure conﬁrmation. Thus, we also con-
sider our aggregation strategies without conﬁrmation.
We compare mc-path and absolute with controlled ex-
periments in Emulab.
In these experiments, we use the
GEANT topology, because it is bigger than Abilene, and
inject failures of 60 seconds. A bigger topology and longer
failures allows for a more fair comparison; otherwise, the
number of probes that traverse a failure in each measure-
ment bin of absolute would be too small. We vary per-link
loss rates from zero to 1% and average burst lengths from
4 ms to 40 ms. We found that varying the measurement bin
length in absolute does not aﬀect the trade-oﬀs.
Identiﬁcation rate. Fig. 10 shows the identiﬁcation rate
of absolute when varying τ for diﬀerent values of f /C.
We show results for average path loss rates of 1.4% and
average loss bursts of 40 ms (results were similar for other
settings). Reducing τ allows more links in the hypothesis
set, ultimately increasing the number of identiﬁed failures.
False alarms. Because absolute only counts probe losses
and does not reset these counters upon a successful probe,
it raises many false alarms. Successful probes are clearly
useful for removing working links from hypothesis sets, but
absolute ignores them. We favor absolute by consider-
ing failures as correctly identiﬁed even if its hypothesis set
contains some working links besides the failed links. Fig. 11
shows that decreasing τ increases the number of false alarms,
because with a small threshold, absolute will misclassify
many links as failed.
For both identiﬁcation rate and false alarms, no conﬁgu-
ration of absolute achieves the same accuracy as mc-path.
As pointed out by the authors [16], absolute is biased to-
ward adding links visited by many paths to the hypothesis
set, because these links tend to explain more observations
in the failure signature than less visited links. Because ab-
solute has no failure conﬁrmation and ignores successful
probes in building failure signatures, detection errors have a
high probability of causing highly visited links to be added
to the hypothesis set. This approach increases false alarms
and reduces identiﬁcation rate if the wrong link is chosen to
explain a failure. The delay (not shown) of absolute is pro-
portional to its bin length. The average delay of mc-path
is lower than absolute’s for C > 12 (i.e., f /C > 5).
5. RELATED WORK
Network tomography and monitor selection. Exist-
ing binary tomography algorithms rely on end-to-end path
measurements collected by monitors, as well as a coordinator
that combines this information with the network topology
to identify failures [9, 10, 16, 22]. These algorithms may ben-
eﬁt from our conﬁrmation and aggregation techniques. In
a recent survey, Huang et al. stated the challenges of using
binary tomography in practice [14]. The methods we pro-
pose in this paper systematically address these challenges;
our methods are more ﬂexible and adaptable to various net-
work conditions and achieve higher identiﬁcation rates with
fewer false alarms. Other previous work has developed path
and monitor selection algorithms [2, 19, 30], which reduce
the number of paths to probe and, consequently, the cycle
length. Our analysis formally relates the cycle length to
overall aggregation delay for various aggregation strategies.
Fault identiﬁcation systems. NICE [18] correlates diﬀer-
ent data sources from an ISP network to identify intermit-
tent failures. The method incorporates end-to-end measure-
ments but focuses mostly on failures that already appear in
the network’s alarm system (as opposed to blackholes). The
alarms from a system based on binary tomography could be
one more data source for NICE. PlanetSeer [28] passively
monitors TCP traﬃc in PlanetLab nodes to detect paths
experiencing problems and triggers traceroutes from a set of
vantage points to the eﬀected destinations. Hubble [15] uses
RouteViews data and low-rate pings to run traceroutes to
destinations that are more likely to be experiencing reach-
ability problems. Both systems use traceroutes to identify
problems in the Internet, but traceroutes often reveal the ef-
265fect of a failure (i.e., where paths stop), but not necessarily
its location. It is not known to what extent PlanetSeer and
Hubble are accurate, since both were evaluated in the wide-
area Internet without a notion of ground truth; in contrast,
we have evaluated our methods in a controlled setting to de-
termine the accuracy and false alarm rates of our methods
for various failure scenarios.
6. CONCLUSION
Binary tomography algorithms hold great promise for
helping network operators detect and locate a large class
of network failures, including those that are diﬃcult to de-
tect with other methods (e.g., network “blackholes”). De-
spite much previous attention to binary tomography algo-
rithms, two signiﬁcant obstacles have prevented network to-
mography from being applied in practice: (1) the inability
to distinguish persistent blackholes from bursty, congestion-
related losses; and (2) the lack of synchronized end-to-end
measurements. This paper has designed and evaluated con-
ﬁrmation and aggregation methods that address these two
problems, respectively. We generated analytical models to
explain the accuracy of detection and consistency of the
reachability matrix, validated these models using controlled
experiments on the Emulab testbed, and showed that these
methods quickly and accurately identify all failures that are
longer than two measurement cycles, with few false alarms.
In our future work, we plan to use these methods in conjunc-
tion with the algorithms themselves to build a real-time,
tomography-based monitoring system that can detect and
locate network blackholes in real time.
Acknowledgements
We thank Darryl Veitch and Laurent Massouli´e for their
feedback on our failure conﬁrmation mechanism. This
work was supported by the European Community’s Sev-
enth Framework Programme (FP7/2007-2013) no. 223850,
the ANR project C’Mon, NSF CNS-0721581, and NSF CA-
REER Award 0643974. Nick Feamster was also partially
supported by Thomson.
7. REFERENCES
[1] F. Baccelli, S. Machiraju, D. Veitch, and J. Bolot. The Role
of PASTA in Network Measurement. SIGCOMM CCR,
36(4):231–242, 2006.
[2] P. Barford, N. Duﬃeld, A. Ron, and J. Sommers. Network
Performance Anomaly Detection and Localization. In Proc.
IEEE INFOCOM, Rio de Janeiro, Brazil, 2009.
[3] P. Barford and J. Sommers. Comparing Probe- and
Router-Based Packet-Loss Measurement. Internet
Computing, 8(5):50–56, 2004.
[4] N. Beheshti, Y. Ganjali, M. Ghobadi, N. McKeown, and
G. Salmon. Experimental Study of Router Buﬀer Sizing. In
Proc. IMC, Vouliagmeni, Greece, 2008.
[5] J. Bolot, S. Fosse-Parisis, and D. Towsley. Adaptive
FEC-Based Error Control for Internet Telephony. In Proc.
IEEE INFOCOM, New York, NY, 1999.
[6] R. Caceres, N. Duﬃeld, J. Horowitz, and D. Towsley.
Multicast-based Inference of Network-internal Loss
Characteristics. IEEE Trans. on Information Theory,
45(7):2462 – 2480, 1999.
[7] M. Caesar and J. Rexford. Building Bug-tolerant Routers
with Virtualization. In Proc. SIGCOMM PRESTO,
Seattle, WA, 2008.
[8] I. Cunha, R. Teixeira, N. Feamster, and C. Diot. Fast and
Accurate Blackhole Identiﬁcation with Network
Tomography. Thomson Technical Report
CR-PRL-2009-05-0006.
[9] A. Dhamdhere, R. Teixeira, C. Dovrolis, and C. Diot.
NetDiagnoser: Troubleshooting Network Unreachabilities
Using End-to-end Probes and Routing Data. In Proc.
CoNEXT, New York, NY, 2007.
[10] N. G. Duﬃeld. Network Tomography of Binary Network
Performance Characteristics. IEEE Trans. on Information
Theory, 52(12):5373–5388, 2006.
[11] L. Fang, A. Atlas, F. Chiussi, K. Kompella, and
G. Swallow. LDP Failure Detection and Recovery. IEEE
Communication Magazine, 42(10):117–123, 2004.
[12] N. Feamster and H. Balakrishnan. Detecting BGP
Conﬁguration Faults with Static Analysis. In Proc. NSDI,
Boston, MA, 2005.
[13] E. Gilbert. Capacity of a Burst-Noise Channel. Bell
Systems Technical Journal, 39(5):1253–1265, 1960.
[14] Y. Huang, N. Feamster, and R. Teixeira. Practical Issues
with Using Network Tomography for Fault Diagnosis.
SIGCOMM CCR, 38(5):53–58, 2008.
[15] E. Katz-Bassett, H. V. Madhyastha, J. P. John,
A. Krishnamurthy, D. Wetherall, and T. Anderson.
Studying Black Holes in the Internet with Hubble. In Proc.
NSDI, San Francisco, CA, 2008.
[16] R. Kompella, J. Yates, A. Greenberg, and A. Snoeren.
Detection and Localization of Network Blackholes. In Proc.
IEEE INFOCOM, Anchorage, AK, 2007.
[17] R. Mahajan, D. Wetherall, and T. Anderson.
Understanding BGP Misconﬁguration. In Proc. ACM
SIGCOMM, Pittsburgh, PA, 2002.
[18] A. Mahimkar, J. Yates, Y. Zhang, A. Shaikh, J. Wang,
Z. Ge, and C. Ee. Troubleshooting Chronic Conditions in
Large IP Networks. In CoNEXT, Madrid, Spain, 2008.
[19] H. Nguyen and P. Thiran. Active Measurement for Multiple
Link Failure Diagnosis in IP Networks. In Proc. PAM,
Antibes-Juan les Pins, France, 2004.
[20] V. Padmanabhan, L. Qiu, and H. Wang. Server-based
Inference of Internet Link Lossiness. In Proc. IEEE
INFOCOM, San Francisco, CA, 2003.
[21] K. Papagiannaki, R. Cruz, and C. Diot. Network
Performance Monitoring at Small Time Scales. In Proc.
IMC, Miami Beach, FL, 2003.
[22] M. Rabbat, M. Coates, and R. Nowak. Multiple Source,
Multiple Destination Network Tomography. In Proc. IEEE
INFOCOM, Hong Kong, China, 2004.
[23] R. Sherwood, A. Bender, and N. Spring. DisCarte: a
Disjunctive Internet Cartographer. In Proc. ACM
SIGCOMM, Seattle, WA, 2008.
[24] J. Sommers and P. Barford. An Active Measurement
System for Shared Environments. In Proc. IMC, San Diego,
CA, 2007.
[25] J. Sommers, P. Barford, N. Duﬃeld, and A. Ron. Improving
Accuracy in End-to-end Packet Loss Measurement. In Proc.
ACM SIGCOMM, Philadelphia, PA, 2005.
[26] J. Sommers, P. Barford, N. Duﬃeld, and A. Ron. Accurate
and Eﬃcient SLA Compliance Monitoring. In Proc. ACM
SIGCOMM, Kyoto, Japan, 2007.
[27] N. Spring, R. Mahajan, and D. Wetherall. Measuring ISP
Topologies with Rocketfuel. In Proc. ACM SIGCOMM,
Pittsburgh, PA, 2002.
[28] M. Zhang, C. Zhang, V. Pai, L. Peterson, and R. Wang.
PlanetSeer: Internet Path Failure Monitoring and
Characterization in Wide-area Services. In Proc. OSDI,
San Francisco, CA, 2004.
[29] Y. Zhang, N. Duﬃeld, V. Paxson, and S. Shenker. On the
Consistency of Internet Path Properties. In Proc. IMW,
San Francisco, CA, 2001.
[30] Y. Zhao, Z. Zhu, Y. Chen, D. Pei, and J. Wang. Towards
Eﬃcient Large-Scale VPN Monitoring and Diagnosis under
Operational Constraints. In Proc. IEEE INFOCOM, Rio
de Janeiro, Brazil, 2009.
266