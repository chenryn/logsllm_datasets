## 组件化 & 容器化Hybrid App能够较好的平衡"用户体验"和"快速开发"两个复杂度问题（注意是"平衡"，不是"同时解决"），但对于一些超级App 来说，随着业务规模越来越大、业务越来越复杂，虽然在用户看来可能是一个App，但事实上承载了几十上百个业务。以手机淘宝为例，阿里确认"All in无线"战略后，手机淘宝定位为阿里集团移动端的"航空母舰"，上面承载了非常多的子业务，下图是淘宝的首页第一屏，相关的子业务初步估计就有10 个以上。![](Images/6c6506cc554c3d7762f8a7ced74e1f6d.png){savepage-src="https://static001.geekbang.org/resource/image/4a/8c/4a5a9e9db6351b2a86afa6a564c21b8c.png"}再以微信为例，作为腾讯在移动互联网的"航空母舰"，其业务也是非常的多，如下图，"发现"tab页就有 7 个子业务。![](Images/d243923ceb9164259d70e0e8a9d678e6.png){savepage-src="https://static001.geekbang.org/resource/image/a0/e0/a0f224e4f6fe331a00c9007bea4a68e0.png"}这么多业务集中在一个 App上，每个业务又在不断地扩展，后续又可能会扩展新的业务，并且每个业务就是一个独立的团队负责开发，因此整个App 的可扩展性引入了新的复杂度问题。我在[专栏第 32期](http://time.geekbang.org/column/article/10688)提到，可扩展的基本思想就是"拆"，但是这个思想应用到App 和后端系统时，具体的做法就明显不同了。简单来说，App和后端系统存在一个本质的区别，App是面向用户的，后端系统是不面向用户的，因此 App再怎么拆，对用户还是只能呈现同一个 App，不可能将一个 App拆分为几十个独立App；而后端系统就不一样了，采用微服务架构后，后端系统可以拆分为几百上千个子服务都没有问题。同时，App的业务再怎么拆分，技术栈是一样的，不然没法集成在一个 App里面；而后端就不同了，不同的微服务可以用不同的技术栈开发。在这种业务背景下，组件化和容器化架构应运而生，其基本思想都是将超级 App拆分为众多组件，这些组件遵循预先制定好的规范，独立开发、独立测试、独立上线。如果某个组件依赖其他组件，组件之间通过消息系统进行通信，通过这种方式来实现组件隔离，从而避免各个团队之间的互相依赖和影响，以提升团队开发效率和整个系统的可扩展性。组件化和容器化的架构出现遵循架构设计的"演化原则"，只有当业务复杂度发展到一定规模后才适应，因此我们会看到大厂应用这个架构的比较多，而中小公司的App，业务没那么复杂，其实并不一定需要采用组件化和容器化架构。对于组件化和容器化并没有非常严格的定义，我理解两者在规范、拆分、团队协作方面都是一样的，区别在于发布方式，组件化采用的是静态发布，即所有的组件各自独自开发测试，然后跟随App的某个版本统一上线；容器化采用的是动态发布，即容器可以动态加载组件，组件准备好了直接发布，容器会动态更新组件，无需等待某个版本才能上线。关于手机淘宝 App更详细的架构演进可以参考[《](http://www.infoq.com/cn/articles/shoutao-atlas)[Atlas：手淘Native容器化框架和思考](http://www.infoq.com/cn/articles/shoutao-atlas)[》](http://www.infoq.com/cn/articles/shoutao-atlas)，微信App的架构演进可以参考[《](http://www.infoq.com/cn/articles/wechat-android-app-architecture)[微信Android客户端架构演进之路](http://www.infoq.com/cn/articles/wechat-android-app-architecture)[》](http://www.infoq.com/cn/articles/wechat-android-app-architecture)。
## 跨平台 App前面我介绍的各种 App 架构，除了 Web App外，其他都面临着同一个问题：跨平台需要重复开发。同一个功能和业务，Android开发一遍，iOS也要开发一遍，这里其实存在人力投入的问题，违背了架构设计中的"简单原则"。站在企业的角度来讲，当然希望能够减少人力投入成本（虽然我站在程序员的角度来讲是不希望程序员被减少的），因此最近几年各种跨平台方案不断涌现，比较知名的有Facebook 的 React Native、阿里的 Weex、Google 的Flutter。虽然也有很多公司在尝试使用，但目前这几个方案都不算很成熟，且在用户体验方面与原生App 还是有一定差距，例如 Airbnb 就宣布放弃使用 ReactNative，回归使用原生技术（）。前端的情况也是类似的，有兴趣的同学可以看看玉伯的文章[《](https://github.com/lifesinger/blog/issues/184)[Web研发模式演变](https://github.com/lifesinger/blog/issues/184)[》](https://github.com/lifesinger/blog/issues/184)，专栏里我就不在赘述了。
## 小结今天我为你讲了 App 架构演进背后的原因和架构分析，希望对你有所帮助。这就是今天的全部内容，留一道思考题给你吧，你认为 App架构接下来会如何演进？谈谈你的思考和分析。欢迎你把答案写到留言区，和我一起讨论。相信经过深度思考的回答，也会让你对知识的理解更加深刻。（编辑乱入：精彩的留言有机会获得丰厚福利哦！）![](Images/f2eae62fce5bba3ca5ee38d11da01862.png){savepage-src="https://static001.geekbang.org/resource/image/ba/37/ba6fcd186893b8cc9977d18e1fa5ab37.jpg"}
# 50 \| 架构实战：架构设计文档模板在前面的专栏里，有同学留言说想看看具体的架构设计文档。由于信息安全的原因，再加上稍微复杂的系统，设计文档都是几十页，因此专栏无法直接给出详细的文档案例。但我认为提供一个架构设计文档模板还是很有必要的，可以方便你在实际进行架构设计的时候更好地编写相关文档。我还以前面讲过的"前浪微博"消息队列为例，给出[架构设计中最重要的两个文档的模板和关键说明]{.orange}。这个案例文档仅给出一些关键内容供你参考，部分细节无法全面覆盖或者完全保证正确。
## 备选方案模板1\. 需求介绍\[需求介绍主要描述需求的背景、目标、范围等\]]{.orange}随着前浪微博业务的不断发展，业务上拆分的子系统越来越多，目前系统间的调用都是同步调用，由此带来几个明显的系统问题：-   性能问题：当用户发布了一条微博后，微博发布子系统需要同步调用"统计子系统""审核子系统""奖励子系统"等共    8 个子系统，性能很低。-   耦合问题：当新增一个子系统时，例如如果要增加"广告子系统"，那么广告子系统需要开发新的接口给微博发布子系统调用。-   效率问题：每个子系统提供的接口参数和实现都有一些细微的差别，导致每次都需要重新设计接口和联调接口，开发团队和测试团队花费了许多重复工作量。基于以上背景，我们需要引入消息队列进行系统解耦，将目前的同步调用改为异步通知。``{=html}2\. 需求分析\[需求分析主要全方位地描述需求相关的信息\]]{.orange}**5W**\[5W 指 Who、When、What、Why、Where。]{.orange}Who：需求利益干系人，包括开发者、使用者、购买者、决策者等。]{.orange}When：需求使用时间，包括季节、时间、里程碑等。]{.orange}What：需求的产出是什么，包括系统、数据、文件、开发库、平台等。]{.orange}Where：需求的应用场景，包括国家、地点、环境等，例如测试平台只会在测试环境使用。]{.orange}Why：需求需要解决的问题，通常和需求背景相关\]]{.orange}消息队列的 5W 分析如下：Who：消息队列系统主要是业务子系统来使用，子系统发送消息或者接收消息。When：当子系统需要发送异步通知的时候，需要使用消息队列系统。What：需要开发消息队列系统。Where：开发环境、测试环境、生产环境都需要部署。Why：消息队列系统将子系统解耦，将同步调用改为异步通知。**1H**\[这里的 How不是设计方案也不是架构方案，而是关键业务流程。消息队列系统这部分内容很简单，但有的业务系统1H 就是具体的用例了，有兴趣的同学可以尝试写写 ATM机取款的业务流程。如果是复杂的业务系统，这部分也可以独立成"用例文档"\]]{.orange}消息队列有两大核心功能：-   业务子系统发送消息给消息队列。-   业务子系统从消息队列获取消息。**8C**\[8C 指的是 8 个约束和限制，即 Constraints，包括性能 Performance、成本Cost、时间 Time、可靠性 Reliability、安全性 Security、合规性Compliance、技术性 Technology、兼容性 Compatibility\]]{.orange}注：需求中涉及的性能、成本、可靠性等仅仅是利益关联方提出的诉求，不一定准确；如果经过分析有的约束没有必要，或成本太高、难度太大，这些约束是可以调整的。]{.orange}性能：需要达到 Kafka 的性能水平。成本：参考 XX 公司的设计方案，不超过 10 台服务器。时间：期望 3 个月内上线第一个版本，在两个业务尝试使用。可靠性：按照业务的要求，消息队列系统的可靠性需要达到 99.99%。安全性：消息队列系统仅在生产环境内网使用，无需考虑网络安全；如消息中有敏感信息，消息发送方需要自行进行加密，消息队列系统本身不考虑通用的加密。合规性：消息队列系统需要按照公司目前的 DevOps 规范进行开发。技术性：目前团队主要研发人员是 Java，最好用 Java 开发。兼容性：之前没有类似系统，无需考虑兼容性。3\. 复杂度分析\[分析需求的复杂度，复杂度常见的有高可用、高性能、可扩展等，具体分析方法请参考专栏前面的内容\]]{.orange}注：文档的内容省略了分析过程，实际操作的时候每个约束和限制都要有详细的逻辑推导，避免完全拍脑袋式决策，具体请参考[专栏第10 期](http://time.geekbang.org/column/article/7563)的分析。]{.orange}**高可用**对于微博子系统来说，如果消息丢了，导致没有审核，然后触犯了国家法律法规，则是非常严重的事情；对于等级子系统来说，如果用户达到相应等级后，系统没有给他奖品和专属服务，则VIP用户会很不满意，导致用户流失从而损失收入，虽然也比较关键，但没有审核子系统丢消息那么严重。综合来看，消息队列需要高可用性，包括消息写入、消息存储、消息读取都需要保证高可用性。**高性能**前浪微博系统用户每天发送 1000 万条微博，那么微博子系统一天会产生 1000万条消息，平均一条消息有 10 个子系统读取，那么其他子系统读取的消息大约是1 亿次。将数据按照秒来计算，一天内平均每秒写入消息数为 115条，每秒读取的消息数是 1150条；再考虑系统的读写并不是完全平均的，设计的目标应该以峰值来计算。峰值一般取平均值的3 倍，那么消息队列系统的 TPS 是 345，QPS 是3450，考虑一定的性能余量。由于现在的基数较低，为了预留一定的系统容量应对后续业务的发展，我们将设计目标设定为峰值的4 倍，因此最终的性能要求是：TPS 为 1380，QPS 为 13800。TPS 为 1380并不高，但 QPS 为 13800 已经比较高了，因此高性能读取是复杂度之一。**可扩展**消息队列的功能很明确，基本无须扩展，因此可扩展性不是这个消息队列的关键复杂度。4\. 备选方案\[备选方案设计，至少 3个备选方案，每个备选方案需要描述关键的实现，无须描述具体的实现细节。此处省略具体方案描述，详细请参考[专栏第11 期](http://time.geekbang.org/column/article/7800)\]]{.orange}**备选方案 1：直接引入开源 Kafka**\[此处省略方案描述\]]{.orange}**备选方案 2：集群 + MySQL 存储**\[此处省略方案描述\]]{.orange}**备选方案 3：集群 + 自研存储**\[此处省略方案描述\]]{.orange}5\. 备选方案评估\[备选方案 360 度环评，详细请参考[专栏第 12期](http://time.geekbang.org/column/article/7832)。注意备选方案评估的内容会根据评估会议的结果进行修改，也就是说架构师首先给出自己的备选方案评估，然后举行备选方案评估会议，再根据会议结论修改备选方案文档\]]{.orange}