the semantics of an expression, yet they are sensitive to syntactic
complexity and will not return simple versions of highly obfuscated
expressions. Conversely, blackbox deobfuscation treats the code as
a blackbox, considering only sampled I/O behaviors. Thus increas-
ing syntactic complexity, as usual state-of-the-art protections do, has
simply no impact on blackbox methods.
3.3 Blackbox deobfuscation in practice
We now present how blackbox methods integrate in a global deob-
fuscation process and highlight crucial properties they must hold.
Global workflow. Reverse engineering can be fully automated,
or handmade by a reverser, leveraging tools to automate specific
tasks. While the deobfuscation process operates on the whole ob-
fuscated binary, blackbox modules can be used to analyze parts of
the code like conditions or VM handlers. Upon meeting a complex
code fragment, the blackbox deobfuscator is called to retrieve a
simple semantic expression. After synthesis succeeds, the inferred
expression is used to help continue the analysis.
Session 10A: Crypto, Symbols and Obfuscation CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2515Requirements. In virtualization based obfuscation, the blackbox
module is typically queried on all VM handlers [7]. As the number
of handlers can be arbitrarily high, blackbox methods need to be
fast. In addition, inferred expressions should ideally be as simple as
the original non-obfuscated expression and semantically equivalent
to the obfuscated expression (i.e., correct). Finally, robustness (i.e.,
the capacity to synthesize complex expressions) is needed to be
usable in various situations. Thus, speed, simplicity, correctness
and robustness, are required for efficient blackbox deobfuscation.
Discussion. One may argue that local blackbox deobfuscation can
be easily parallelized, limiting the need for fast synthesis. However,
reverse engineering is often performed incrementally (e.g., packing,
self-modification), or/and with a human in the loop and the need
for quick feedback. In those scenarios, parallelization cannot help
that much while slow synthesis obstructs analysis. Also, in some
cases Syntia fails in 12h (Sections 5.3 and 8.2) â€“ parallelism cannot
help there.
4 UNDERSTAND BLACKBOX
DEOBFUSCATION
We propose a general view of search-based code deobfuscation fit-
ting state-of-the-art solutions [7, 16]. We also extend the evaluation
of Syntia by Blazytko et al. [7], highlighting both some previously
unreported weaknesses and strengths. From that we derive general
lessons on the (in)adequacy of MCTS for code deobfuscation, that
will guide our new approach (Section 5).
4.1 Problem at hand
Search-based deobfuscation takes an obfuscated expression and
tries to infer an equivalent one with lower syntactic complexity.
Such problem can be stated as following:
Deobfuscation. Let ğ‘’, ğ‘œğ‘ ğ‘“ be 2 equivalent expressions such that
ğ‘œğ‘ ğ‘“ is an obfuscated version of ğ‘’ â€“ note that ğ‘œğ‘ ğ‘“ is possibly much
larger than ğ‘’. Deobfuscation aims to infer an expression ğ‘’â€² equiva-
lent to ğ‘œğ‘ ğ‘“ (and ğ‘’), but with size similar to ğ‘’. Such problem can be
approached in three ways depending on the amount of information
given to the analyzer:
Blackbox We can only run ğ‘œğ‘ ğ‘“ . The search is thus driven by
sampled I/O behaviors. Syntia [7] is a blackbox approach;
Greybox Here ğ‘œğ‘ ğ‘“ is executable and readable but the seman-
tics of its operators is mostly unknown. The search is driven by
previously sampled I/O behaviors which can be applied to subparts
of ğ‘œğ‘ ğ‘“ . QSynth [16] is a greybox solution;
Whitebox The analyzer has full access to ğ‘œğ‘ ğ‘“ (run, read) and
the semantics of its operators is precisely known. Thus, the search
can profit from advanced pattern matching and symbolic strategies.
Standard static analysis falls in this category.
Blackbox methods. Search-based blackbox deobfuscators follow
the framework given in Algorithm 1. In order to deobfuscate code,
one must detail a sampling strategy (i.e., how inputs are generated),
a learning strategy (i.e., how to learn an expression mapping sam-
pled inputs to observed outputs) and a simplification postprocess.
For example, Syntia samples inputs randomly, uses Monte Carlo
Tree Search (MCTS) [9] as learning strategy and leverages the Z3
SMT solver [17] for simplification. The choice of the sampling and
learning strategies is critical. For example, too few samples could
lead to incorrect results while too many could impact the search
efficiency, and an inappropriate learning algorithm could impact
robustness or speed.
Let us now turn to discussing Syntia learning strategy. We show
that using MCTS leads to disappointing performances and give
insights to understand why.
Algorithm 1 Search-based blackbox deobfuscation framework
Inputs:
ğ¶ğ‘œğ‘‘ğ‘’ : code to analyze
ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’ : sampling strategy
ğ¿ğ‘’ğ‘ğ‘Ÿğ‘› : learning strategy
ğ‘†ğ‘–ğ‘šğ‘ğ‘™ğ‘– ğ‘“ ğ‘¦ : expression simplifier
Output: learned expression or Failure
1: procedure Deobfuscate(ğ¶ğ‘œğ‘‘ğ‘’, ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’, ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›)
2:
3:
4:
5:
ğ‘‚ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’ â† ğ‘†ğ‘ğ‘šğ‘ğ‘™ğ‘’(ğ¶ğ‘œğ‘‘ğ‘’)
ğ‘ ğ‘¢ğ‘ğ‘, ğ‘’ğ‘¥ğ‘ğ‘Ÿ â† ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›(ğ‘‚ğ‘Ÿğ‘ğ‘ğ‘™ğ‘’)
if ğ‘ ğ‘¢ğ‘ğ‘ = ğ‘‡ğ‘Ÿğ‘¢ğ‘’ then return ğ‘†ğ‘–ğ‘šğ‘ğ‘™ğ‘– ğ‘“ ğ‘¦(ğ‘’ğ‘¥ğ‘ğ‘Ÿ)
else return ğ¹ğ‘ğ‘–ğ‘™ğ‘¢ğ‘Ÿğ‘’
4.2 Evaluation of Syntia
We extend Syntia evaluation and tackle the following questions left
unaddressed by Blazytko et al. [7].
RQ1 Are results stable across different runs?
This is desirable due to the stochastic nature of MCTS;
RQ2 Is Syntia fast, robust and does it infer simple and correct results?
Syntia offers a priori no guarantee of correctness nor quality.
Also, we consider small time budget (1s), adapted to human-
in-the-loop scenarios but absent from the initial evaluation;
RQ3 How is synthesis impacted by the set of operators size?
Syntia learns expressions over a search space fixed by prede-
fined grammars. Intuitively, the more operators in the gram-
mar, the harder it will be to converge to a solution. We use 3
sets of operators to assess this impact.
4.2.1 Experimental setup. We distinguish the success rate (num-
ber of expressions inferred) from the equivalence rate (number of
expressions inferred and equivalent to the original one). The equiv-
alence rate relies on the Z3 SMT solver [17] with a timeout of 10s.
Since Z3 timeouts are inconclusive answers, we define a notion of
equivalence range: its lower bound is the proven equivalence
rate (number of expressions proven to be equivalent) while its
upper bound is the optimistic equivalence rate (expressions not
proven different, i.e., optimistic = proven + #timeout). The equiva-
lence rate is within the equivalence range, while the success rate is
higher than the optimistic equivalence rate. Finally, we define the
quality of an expression as the ratio between the number of oper-
ators in recovered and target expressions. It estimates the syntactic
complexity of inferred expressions compared to the original ones.
A quality of 1 indicates a perfect result: the recovered expression
has the same size as the target expression.
Benchmarks. We consider two benchmark suites: B1 and B2. B13
comes from Blazytko et al. [7] and was used to evaluate Syntia.
It comprises 500 randomly generated expressions with up to 3
3https://github.com/RUB-SysSec/syntia/tree/master/samples/mba/tigress
Session 10A: Crypto, Symbols and Obfuscation CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2516arguments, and simple semantics. It aims at representing state-of-
the-art VM-based obfuscators. However, we found that B1 suffers
from several significant issues: (1) it is not well distributed over the
number of inputs and expression types, making it unsuitable for
fine-grained analysis; (2) only 216 expressions are unique modulo
renaming â€“ the other 284 expressions are ğ›¼-equivalent, like x+y
and a+b. These problems threaten the validity of the evaluation.
We thus propose a new benchmark B2 consisting of 1,110 ran-
domly generated expressions, better distributed according to the
number of inputs and the nature of operators â€“ see Table 1. We
use three categories of expressions: Boolean, Arithmetic and Mixed
Boolean-Arithmetic, with 2 to 6 inputs. Especially, expressions are
spread equally between categories to prevent biased results. Each ex-
pression has an Abstract Syntax Tree (AST) of maximal height 3. As
a result, B2 is more challenging than B1 and enables a finer-grained
evaluation. Considering such diverse and complex expressions is
crucial as blackbox deobfuscation evolves in an adversarial context
where limitations can be exploited to thwart analysis.
Note that we also consider QSynth datasets [16] in Section 6,
developed by the Quarkslab R&D company.
Type
# Inputs
Bool. Arith. MBA
370
370
6
#Expr.
90
Table 1: Distribution of samples in benchmark B2
2
150
3
600
4
180
5
90
370
Operator sets. Table 2 introduces three operator sets: Full, Expr
and Mba. We use these to evaluate sensitivity to the search space
and answer RQ3. Expr is as expressive as Full even if Expr âŠ‚ Full.
Mba can only express Mixed Boolean-Arithmetic expressions [37].
Table 2: Sets of operators
Full : {âˆ’1,Â¬,+,âˆ’,Ã—, â‰«ğ‘¢, â‰«ğ‘ , â‰ª,âˆ§,âˆ¨, âŠ•,Ã·ğ‘ ,Ã·ğ‘¢, %ğ‘ , %ğ‘¢,++ }
Expr : {âˆ’1,Â¬,+,âˆ’,Ã—,âˆ§,âˆ¨, âŠ•,Ã·ğ‘ ,Ã·ğ‘¢,++ }
Mba : {âˆ’1,Â¬,+,âˆ’,Ã—,âˆ§,âˆ¨, âŠ•}
Configuration. We run all our experiments on a machine with 6
Intel Xeon E-2176M CPUs and 32 GB of RAM. We evaluate Syntia in
its original configuration [7]: the SA-UCT parameter is 1.5, we use
50 I/O samples and a maximum playout depth of 0. We also limit
Syntia to 50,000 iterations per sample, corresponding to a timeout
of 60s per sample on our test machine.
4.2.2 Evaluation Results. Let us summarize here the outcome of
our experiments.
RQ1. Over 15 runs, Syntia finds between 362 and 376 expressions
of B1 i.e., 14 expressions of difference (2.8% of B1). Over B2, it finds
between 349 and 383 expressions i.e., 34 expressions of difference
(3.06% of B2). Hence, Syntia is very stable across executions.
RQ2. Syntia cannot efficiently infer B2 (â‰ˆ 34% success rate). More-
over, Table 3 shows Syntia to be highly sensitive to time budget.
More precisely, with a time budget of 1 s/expr., Syntia only retrieves
16.3% of B2. Still, even with a timeout of 600 s/expr., it tops at 42%
of B2. In addition, Syntia is unable to synthesize expressions with
more than 3 inputs â€“ success rates for 4, 5 and 6 inputs respectively
falls to 10%, 2.2% and 1.1%. It also struggles over expressions us-
ing a mix of Boolean and arithmetic operators, synthesizing only
21% (see Table 4). Still, Syntia performs well regarding quality and
correctness. On average, its quality is around 0.60 (for a timeout of
60 s/expr.) i.e., resulting expressions are simpler than the original
(non obfuscated) ones, and it rarely returns non-equivalent expres-
sions â€“ between 0.5% and 0.8% of B2. We thus conclude that Syntia
is stable and returns correct and simple results. Yet, it is not efficient
enough (solves only few expressions on B2, heavily impacted by time
budget) and not robust (number of inputs and expression type).
Table 3: Syntia depending on the timeout per expression (B2)
1s
10s
25.6%
60s
34.5%
Succ. Rate
Equiv. Range
Mean Qual.
16.5%
16.3% 25.1 - 25.3% 33.7 - 34.0% 41.4 - 41.6%
0.35
0.49
0.59
0.67
600s
42.3%
RQ3. Default Syntia synthesizes expressions over the Full set of
operators. To evaluate its sensitivity to the search space we run it
over Full, Expr and Mba. Smaller sets do exhibit higher success
rates (42% on Mba) but results remain disappointing. Syntia is
sensitive to the size of the operator set but is inefficient even with Mba.
Conclusion. Syntia is stable, correct and returns simple results. Yet,
it is heavily impacted by the time budget and lacks robustness. It thus
fails to meet the requirements given in Section 3.3.
4.3 Optimal Syntia
To ensure the conclusions given in Section 4.4 apply to MCTS
and not only to Syntia, we study Syntia extensively to find better
set ups for the following parameters: simulation depth, SA-UCT
value (configuring the balance between exploitative and explorative
behaviors), number of I/O samples and distance. Optimizing Syntia
parameters slightly improves its results which stay disappointing
(at best, â‰ˆ 50% of success rate on Mba in 60 s/expr.).
Conclusion. By default, Syntia is well configured. Changing its
parameters lead in the best scenario to marginal improvement, hence
the pitfalls highlighted seem to be inherent to the MCTS approach.
4.4 MCTS for deobfuscation
Let us explore whether these issues are related to MCTS.
Monte Carlo Tree Search. MCTS creates here a search tree where
each node is an expression which can be terminal (e.g. ğ‘ + 1, where
ğ‘ is a variable) or partial (e.g. ğ‘ˆ + ğ‘, where ğ‘ˆ is a non-terminal
symbol). The goal of MCTS is to expand the search tree smartly,
focusing on most pertinent nodes first. Evaluating the pertinence of
a terminal node is done by sampling (computing here a distance
between the evaluation of sampled inputs over the node expression
against their expected output values). For partial nodes, MCTS
relies on simulation: random rules of the grammar are applied to
the expression (e.g., ğ‘ˆ + ğ‘ ; ğ‘ + ğ‘ ) until it becomes terminal and
is evaluated. As an example, let {(ğ‘ â†¦â†’ 1, ğ‘ â†¦â†’ 0), (ğ‘ â†¦â†’ 0, ğ‘ â†¦â†’ 1)}
be the sampled inputs. The expression ğ‘ + ğ‘ (simulated from ğ‘ˆ + ğ‘)
evaluates them to (1, 1). If the ground-truth outputs are 1 and âˆ’1,
the distance will equal ğ›¿(1, 1)+ğ›¿(1,âˆ’1) where ğ›¿ is a chosen distance
function. We call the result the pertinence measure. The closer it is
to 0, the more pertinent the node ğ‘ˆ + ğ‘ is considered and the more
the search will focus on it.
Session 10A: Crypto, Symbols and Obfuscation CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2517Analysis. This simulation-based pertinence estimation is not reliable
in our code deobfuscation setting.
â€¢ We present in Fig. 2, for different non-terminal nodes, the
distance values computed through simulations. We observe
that from a starting node, a random simulation can return
drastically different results. It shows that the search space is
very unstable and that relying on simulation is misleading
(especially in our context where time budget is small);
â€¢ Moreover, our experiments show that in practice Syntia is
not guided by simulations and behaves almost as if it were an
enumerative (BFS) search â€“ MCTS where simulations are non
informative. As an example, Fig. 3 compares how the distance
evolves over time for Syntia and a custom, fully enumerative,
MCTS synthesizer: both are very similar. Actually, Syntia
and enumerative MCTS perform similarly over B2: with a
60s (resp. 600s) timeout, enumerative MCTS reaches 41.4%
(resp. 51.6%) success rate vs. 42.6% (resp. 54.9%) for Syntia
(Mba operators set);
â€¢ Finally, on B2 (resp. B1) with a timeout of 60s, only 34/341
(resp. 20/376) successfully synthesized expressions are the
children of previously most promising nodes. It shows that
Syntia successfully synthesized expressions due to its ex-
ploratory (i.e., enumerative) behavior rather than to the se-
lection of nodes according to their pertinence.
)
ğ‘
+
ğ‘
(
Ã—
)
ğ‘
âˆ§
ğ‘
(
m
o
r
f
.
t
s
i
d
.
h
t
i
r
a
g
o
L
1800
1800
1600
1600
1400
1400
1200
1200