such a way that we can re-identify the scanner once its scan
result (the set of ampliﬁers) is used in subsequent ampliﬁ-
cation attacks. Our approach ensures that within a network
segment under our control, every scanner ﬁnds a diﬀerent
set of potential ampliﬁers. That is, we launch honeypots
on all IP addresses on that segment, but only selectively re-
spond to a scanner-derived and therefore unique subset of IP
addresses. If our assumption on single-source scans was cor-
rect, this would mean that attacks based on diﬀerent scans
would also use diﬀerent ampliﬁer sets.
4.2 Implementation
Technically, we implemented the selective response scheme
as follows. We ﬁx a fraction α of the network that re-
sponds to a scan, so that every scanner that performs a full
scan on the network of size N would see replies from α · N
hosts. In order to maximize the number of possible combi-
(cid:1), we set α = 1/2, i.e., respond with exactly half
nations(cid:0) N
of the honeypots, and remain “quiet” with the other half.
αN
To select the αN IP addresses from the network, we com-
pute a hash over the source IP address (i.e., an identiﬁer for
the scanner), the protocol, the base of the network, and a
secret key (string). We added the secret key such that an
attacker cannot precompute the set of responding honeypots
based on our (otherwise deterministic) hash function. The
resulting hash is then used to derive a permutation of the
N IP addresses in the network. From this permutation, the
ﬁrst αN addresses are selected as responding honeypots.
Our selective response honeypot uses three /28 networks,
which gives a total of 48 static IPs distributed over three
networks with 16 IP addresses each. Due to the split over
three distinct /28 networks, we decided to perform the selec-
tion per subnet. Separating the networks into three indepen-
dent ranges has the advantage that we can even attribute
scanners that scanned only one of the networks. Although
this separation reduces the number of possible combinations
(cid:1)3 ≈ 2.1× 1012, it is still two or-
(cid:1) ≈ 3.2× 1013 to(cid:0)16
from(cid:0)48
ders of magnitude larger than the number of IPv4 addresses,
i.e., it is very likely that every scanner will be assigned a
unique set of 24 ampliﬁers.
24
8
5. ATTRIBUTING ATTACKS TO SCANS
5.1 Methodology
The basic idea of our attribution is simple yet eﬀective.
For every attack we monitor, we inspect the set of honey-
pots that were abused for this attack. Typically, attack-
ers leverage multiple ampliﬁers at the same time, and often
also multiple of our honeypots are abused for the same at-
tack. Figure 1 shows the cumulated percentage of attacks
(y-axis) that have an attack set of at least a given size (x-
axis). Over 95% of all attacks use at least four honeypots;
80% use at least 10 of our honeypots simultaneously.
Remember that the ampliﬁer set greatly depends on the
scan prior to the attack, for which our selective response
scheme has introduced artiﬁcial entropy. From the set of
honeypots abused in an attack, we therefore aim to derive
which scanner has discovered these very same honeypots.
Technically, for every IP of our honeypot, we maintain a
set of all sources that discovered this IP as an ampliﬁer, i.e.,
sent a packet to this IP and got back a response. We denote
those sources as being aware of the corresponding IP. Since
we cannot perfectly distinguish attacks from scans, we will
consider every source that contacted our honeypot, which
explicitly includes victims of attacks.
Upon attributing an attack, we ﬁrst extract the set of
IPs used as ampliﬁers in this attack. Conjecturing that the
1428packets per IP. This happens, e.g., for scanners that
start with a full scan (i.e., a single packet per IP ad-
dress) and then verify each responding IP address by
sending additional packets.
Thirdly, because AmpPot considers an attack to have
ended only if the packet-rate drops below 100/hour
for one hour, two attacks targeting the same source in
quick succession can be aggregated into a single attack.
Although we could neither observe nor refute the ﬁrst
scenario, we have observed both the second and third
scenarios in our data.
2. Exactly one candidate. If the set of candidates con-
tains exactly one candidate, only a single scanner is
aware of this set of ampliﬁers. We will consider this
as a potential attribution. However, since we cannot
exclude that the set of ampliﬁers was chosen by other
means (e.g., combining data from multiple scans), we
compute a conﬁdence for this attribution. The com-
puted conﬁdence gives an indication of how likely it
is that this attribution is correct. We give a detailed
explanation of the conﬁdence in Section 5.2.
3. More than one candidate.
If the set of candi-
dates contains multiple candidates, multiple scanners
are aware of this set of ampliﬁers. We will call such
attacks non-unique. This case occurs if the set of cho-
sen ampliﬁers is relatively small and multiple scanners
got responses from those IPs during their scans.
In this case, we will reﬁne the candidate set by ﬁnd-
ing scanner-to-victim relations in the set of candidates.
That is, if both A and B are contained in the set
of candidates, but have previously observed an attack
against B which we could attribute to A, we will re-
move B from the set of candidates. This is based on
the assumption that victims of DDoS attacks will most
likely not act as scanners for DDoS attacks themselves,
and even if they did, the set of ampliﬁers found would
still be based on A’s scan.
5.2 Conﬁdence
Even if an attack can uniquely be attributed to an attack
(case 2), it is unclear how conﬁdent this mapping is.
In
an ideal world, a scanner would scan all of our 48 IPs and
subsequent attacks would use the full reply set of 24 IPs.
Since the full reply set is unique per scanner, this would
allow for a perfect attribution. However, in practice, several
things impede this ideal-world assumption. For example,
scanners might not query all 48 IP addresses. Even if they
did, attackers could select a random subset of the found
IP addresses to use in attacks. Worse, attackers might not
base their attacks on the results of only a single scanner,
but rather combine scan results from multiple sources. This
raises the question whether our attribution is actually robust
under such real-world conditions.
Our approach to answer this question is to deﬁne a conﬁ-
dence that expresses how likely is that our attribution result
is actually correct, based on the following two sets. We will
call the set of IP addresses that were queried by a scanner
the query set Q, and refer to the set of IP addresses that
replied as the reply set R. Since the reply set is determined
using a hash function, which we assume to generate uni-
Figure 1: Percentages of attacks (y-axis) that use at
least the given number of honeypots (x-axis)
honeypot IP
aware sources
10.0.0.1
10.0.0.2
10.0.0.3
10.0.0.4
{169.254.0.10, 192.168.2.100, 198.18.3.24}
{169.254.0.10, 172.16.5.27, 198.18.3.24}
{192.168.2.100, 172.16.5.27, 198.18.3.24}
{169.254.0.10, 172.16.5.27, 192.168.2.100}
Table 1: Example honeypots and aware scanners
scanner behind this attack must have scanned all of these
IPs and received a reply, it must be contained in the set of
aware sources for each of them. We can therefore ﬁnd the
scanner by building the intersection of these sets.
Since neither maintaining the list of aware sources nor
computing a set intersection is computationally expensive,
our methodology can also be applied in real-time, i.e., once
an attack is detected, the result of the attribution can be
obtained without any noticeable delay.
Consider the toy example in Table 1 that lists the set of
aware sources for 4 honeypots. Assume that we observe an
attack using honeypot IPs 10.0.0.1, 10.0.0.3, and 10.0.0.4.
We can then ﬁnd the potential scanner in the following
way: As 10.0.0.1 is contained in the attack set, the scanner
should be one of {169.254.0.10, 192.168.2.100, 198.18.3.24}.
Since 10.0.0.3 is contained as well, we can narrow this down
to {192.168.2.100, 198.18.3.24}, because 169.254.0.10 is not
aware of 10.0.0.3. We can likewise exclude 198.18.3.24, as it
is not aware of 10.0.0.4. This leaves only {192.168.2.100} as
a potential scanner behind the attack.
Mapping scanners this way can result in three cases:
1. Zero candidates If the set of candidates is empty,
then no single scanner was aware of this set of ampli-
ﬁers. We will call such attacks non-attributable. This
can occur for multiple reasons:
Firstly, it could be that the attack is based on data
from multiple scans, in which case the combined am-
pliﬁer set is likely distinct from the sets found by other
scanners. This is especially true for attacks that use
more than αN = 8 IP addresses per honeypot subnet,
as a single scanner can only ﬁnd up to eight ampliﬁers
in each /28 network.
Secondly, due to the threshold of 100 packets that de-
termines an attack, a scan can also be mistaken for
an attack. If a scanner scans all of our 48 IPs, it can
easily exceed the threshold by sending a little over 2
81624324048#honeypots0.0%20.0%40.0%60.0%80.0%100.0%attacks1429formly distributed values, we can consider the distribution
of reply sets to be uniform as well.
We then analyze the probability with which we would
falsely accuse a scanner of being responsible for an attack.
The intuition behind this is as follows: Assuming that a
given attack was not based on the reply set of a single scan-
ner, what is the probability that any of the scanners still
matches this attack by chance? That is, what is the prob-
ability we falsely accuse a scanner? If this probability is
suﬃciently small, we can conclude that—if we can attribute
this attack to a scanner—this attribution is correct.
Formally, assume an attack that uses the IPs A = A1 ∪
A2 ∪ A3, where Ai is the set of IPs from the ith subnet.
We are now interested in the probability that a scanner that
scanned a superset of A also gets replies from all IPs in
A, i.e., Pr [A ⊆ R | A ⊆ Q]. In each /28 subnet, the reply
set the scanner observes is a subset of one out of (cid:0)16
Out of these,(cid:0)16−|Ai|
(cid:1) sets.
(cid:1) are supersets of Ai (since the Ai IPs
8
8−|Ai|
from the attack are ﬁxed, a scanner could potentially receive
responses from 8−|Ai| out of the remaining 16−|Ai|). Thus,
assuming a uniform distribution of reply sets, it holds that
Pr [Ai ⊆ R | A ⊆ Q] =
8
8−|Ai|
(cid:0)16−|Ai|
(cid:1)
(cid:0)16
(cid:1)
(cid:0)16−|A2|
(cid:1)
(cid:0)16
(cid:1)
8−|A2|
·
Therefore, the total probability that a scanner that scanned
a superset of A also got replies from all IPs in A is
(cid:0)16−|A1|
(cid:1)
(cid:0)16
(cid:1)
8−|A1|
(cid:0)16−|A3|
(cid:1)
(cid:0)16
(cid:1)
8−|A3|
·
p = Pr [A ⊆ R | A ⊆ Q] =
8
8
8
From this individual probability for a single scanner we
can now derive a probability for any scanner in our dataset.
The probability that any of the S scanners that scanned a
superset of A got replies from all IPs in A follows the “at-
least-once” semantics and is
1 − (1 − p)S
Put diﬀerently, if we can attribute the attack to a scanner,
our conﬁdence that this attribution is correct is
(1 − p)S
For example, assume an attack that uses 5 IPs from the
ﬁrst, 4 IPs from the second, and 6 IPs from the third subnet
respectively, i.e., |A1| = 5, |A2| = 4, |A3| = 6. A single
scanner then has probability
(cid:0)16−5
(cid:1)
(cid:0)16
(cid:1) ·
8−5
(cid:0)16−4
(cid:1)
(cid:0)16
(cid:1) ·
8−4
(cid:0)16−6
(cid:1)
(cid:0)16
(cid:1) =
8−6
8
8
8
165 · 495 · 45
12, 8703
3, 675, 375
2, 131, 746, 903, 000
≈ 0.0001742%
p =
=
of receiving responses from this precise attack set during its
scan. If at the time of the attack we had had contact with
200 scanners that scanned our entire network, the probabil-
ity that any of them found this precise attack set is thus
(cid:18)
(cid:19)200
1 − (1 − p)S = 1 −
1 − 165 · 495 · 45
12, 8703
≈ 0.03448%.
Consequently, if we ﬁnd a scanner that matches this attack,
in 99.966% of all cases this does not happen by chance, and
Figure 2: Attribution results per protocol
hence for such an attack we have a conﬁdence of 99.966%
that our attribution is correct.
Obviously, a larger set A will lead to a smaller probability,
implying a higher conﬁdence.
5.3 Experimental Results
We will now turn to the results of our attribution process
using the dataset described in Section 3.
Figure 2 shows the percentages of attacks that were marked
as attributable, non-unique, and non-attributable, respectively.
Percentages are given both overall and per protocol. The
absolute numbers for each category are given in Table 2, as