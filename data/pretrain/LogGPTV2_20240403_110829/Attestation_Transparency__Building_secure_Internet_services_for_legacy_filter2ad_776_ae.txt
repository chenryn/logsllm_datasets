protect against side-channel attacks [21]. The operating sys-
tem is in an excellent position to mount side-channel attacks
as well as Iago attacks [11]. SGX also has software compo-
nents that are critical to its security, which might be more
easily compromised than the hardware [14]. Compromise of
SGX on the system running the secure service provides an
attacker with access similar to that of directly compromising
the secure service. But, even if SGX is broken, future sys-
tems might provide better secure enclave functionality that
can be used for the secure service design in this paper.
7.3 Adoption
Previous Trusted Computing approaches have not seen
much practical use. Our scheme diﬀers from most ap-
proaches in that the required hardware and software sup-
port is only needed on the server side. A single entity can
decide to adopt our approach and make it happen without
being dependent on their customer’s hardware or software
choices.
Some service providers may be reluctant to adopt our
scheme. However, we believe there is motivation to strongly
consider it. The ITIF has predicted that the U.S. cloud
computing industry could lose up to $35 billion by 2016 due
to loss of trust in the post-Snowden era [18]. Forrester Re-
search has predicted that losses could eventually be up to
$180 billion [35]. Our scheme provides a mechanism that
partially addresses these trust concerns.
8. RELATED WORK
Our work builds on the development of several important
advancements.
An early line of research strove to verify the integrity of a
known system stack. This was important since malicious or
unreliable system software would certainly prevent the se-
cure operation of even well written applications which were
themselves safe. The AEGIS system [5] proposed verify-
ing the entire stack by having a chain of integrity checks
where each step in the boot process veriﬁes the next before
proceeding. This work has been extended to protect other
critical software like BIOS code which, if corrupted, presents
the application developer with insurmountable barriers for
safe operations. Parno et al. provide an overview [29] of the
relevant techniques and research in this area.
Wobber et al. describe how in the Taos operating sys-
tem they treat code (represented, say, as a cryptographic
hash) as a ﬁrst class security principal which can be authen-
ticated [39]. This enabled distributed programs to establish
an authentication and authorization model that was as rich
and reliable as that for a single program running in batch
mode on a single machine.
It is not always desirable to
attest directly to code principals, as software can change
frequently and can exist in many diﬀerent conﬁgurations.
Property-based attestation [12] aimed to solve this by us-
ing properties of software, instead of the software itself, as
security principals.
Since secure distributed computing relied on increasingly
well studied and accepted cryptographic mechanisms, re-
searchers sought a key management mechanism that al-
lowed remote veriﬁcation of program identity and isolation
properties of program elements running on widely dispersed
machines. Trusted computing primitives combining a dis-
crete security chip [37] coupled with processor features [20]
provided the necessary underlying capabilities. Brannock
et al. propose a Secure Execution Environment [9] with
properties similar to our secure enclave. The CloudProxy
Tao [25]
is a consolidated execution environment imple-
mented recursively at each layer of software (VMM, OS,
Linux process, container, plug-in) that programmers could
generally use without extensive training using existing pro-
gramming tools. The relentless march towards cloud com-
puting made these capabilities more critical since cloud data
centers are widely dispersed, employ powerful insiders who,
absent these capabilities can access or control keys and un-
detectably change code running security critical services, vi-
tiating many of the hoped for beneﬁts of scale and elastic-
ity. These new primitives allowed the safe operation of well
written programs on computers that also ran untrustworthy
applications written by adversaries.
Researchers recognizing that even with the foregoing ad-
vances, large TCBs made security diﬃcult to assure and
maintain and thus attempted to minimize the footprint to
help ensure that security guarantees could be credibly met.
To remedy this, Hawblitzel et al. propose a system using
Ironclad Apps [16] for secure remote computations by for-
mally verifying the entire server stack. Flicker [26] empha-
sized application of the Trusted Computing primitives on
small services within an application isolating them from the
rest of the application and the operating system; for exam-
ple, Flicker enclaves were well suited as a virtual Hardware
Security Module or as an authentication enclave that used
a long term secret; the security model ensured that the OS,
other applications and other portions of the same application
could not get private key material. However, it was shown
that Intel Trusted Execution Technology, which Flicker is
11
based on, is not secure [40].
Various other systems were proposed to marry cloud com-
puting with trusted computing, such as Self-service Cloud
Computing [10], Cryptography-as-a-Service [7], and My-
Cloud [24]. These systems focused on providing trust in the
cloud hypervisor to a customer of the cloud service provider,
not on providing trust of Internet services to users of those
services.
SGX [19] employed specialized hardware for this same
purpose and also encrypted enclave memory in DRAM thus
protecting from an adversary with system bus access. Sev-
eral recent works employ SGX to protect cloud service com-
ponents. Haven [6] employed SGX to run MS SQL Server
entirely in a secure enclave. Clients of that database server
could beneﬁt from the Attestation Transparency Framework
to verify the server they’re connecting to. VC3 [33] imple-
ments secure MapReduce operations for the Hadoop dis-
tributed computation platform using SGX.
Attacks on PKI [1] threatened the trustworthiness of co-
dependent services which can beneﬁt from the execution
ﬂexibility of cloud computing and the vast quantity of com-
munity curated data. This prompted the development of
Certiﬁcate Transparency [22] to highlight misissued certiﬁ-
cates.
9. CONCLUSION
In this paper we have shown how to build secure services
and how to enable clients to verify those services. This
brings to clients the beneﬁts of the cloud—including scal-
ability, availability, elasticity, maintainability—while guard-
ing against principal attacks (e.g. from insiders) that make
cloud usage worrisome.
We have presented a system enabling ﬂexible policy op-
tions to let users meaningfully choose security properties.
Policies can be established by anyone, including software de-
velopers, auditors, independent organizations and communi-
ties. The policies are enforced through a compulsory trans-
parency mechanism that brings malicious intent to light.
This deters bad actors since they can be easily identiﬁed for
purposes of legal action or reputation damage.
We have extended the certiﬁcate transparency model to
code, providing a technical mechanism for users to rely
on the security principal which ultimately ensures secu-
rity properties—code. In addition, we provide ﬂexible trust
models that allow any user to meaningfully adduce behavior
guarantees from actual implementations. We demonstrate
that resulting systems can be nearly as eﬃcient and scal-
able as existing services and provide strong protection from
mischievous providers, foreign governments and sloppy cloud
data center operations.
All proposed mechanisms include incremental deployment
paths which make our techniques usable now for present-
day clients, whereas future deployment will increase secu-
rity guarantees. In conclusion, we have presented a ﬂexible,
practical mechanism to build secure Internet services.
10. ACKNOWLEDGEMENTS
11. REFERENCES
[1] Comodo, DigiNotar Attacks Expose Crumbling
Foundation of CA System. ThreatPost, 2011. URL:
https://threatpost.com/090211/75609.
[2] D. Akhawe, F. Marier, F. Braun, and J. Weinberger.
Subresource Integrity. W3C working draft, W3C, July
2015. URL: http://www.w3.org/TR/SRI/.
[3] D. Akhawe, P. Saxena, and D. Song. Privilege
Separation in HTML5 Applications. In 21st USENIX
Security Symposium, pages 429–444. USENIX, Aug.
2012.
[4] I. Anati, S. Gueron, S. Johnson, and V. Scarlata.
Innovative Technology for CPU Based Attestation and
Sealing. In Proceedings of the 2nd International
Workshop on Hardware and Architectural Support for
Security and Privacy, 2013.
[5] W. A. Arbaugh, D. J. Farber, and J. M. Smith. A
secure and reliable bootstrap architecture. In IEEE
Symposium on Security and Privacy, pages 65–71,
1997.
[6] A. Baumann, M. Peinado, and G. Hunt. Shielding
Applications from an Untrusted Cloud with Haven. In
11th USENIX Symposium on Operating Systems
Design and Implementation, pages 267–283. USENIX
Association, Oct. 2014.
[7] S. Bleikertz, S. Bugiel, H. Ideler, S. N¨urnberger, and
A.-R. Sadeghi. Client-controlled
cryptography-as-a-service in the cloud. In Proceedings
of the 11th International Conference on Applied
Cryptography and Network Security, pages 19–36,
2013.
[8] R. Boivie and P. Williams. SecureBlue++: CPU
support for secure execution. Technical report, IBM
Research Report, 2013.
[9] K. Brannock, P. Dewan, F. McKeen, and
U. Savagaonkar. Providing a Safe Execution
Environment. Intel Technology Journal, 13(2):36–51,
2009.
[10] S. Butt, H. A. Lagar-Cavilla, A. Srivastava, and
V. Ganapathy. Self-service cloud computing. In
Proceedings of the 2012 ACM Conference on Computer
and Communications Security, pages 253–264, 2012.
[11] S. Checkoway and H. Shacham. Iago attacks: Why the
system call api is a bad untrusted rpc interface. In
Proceedings of the Eighteenth International Conference
on Architectural Support for Programming Languages
and Operating Systems, ASPLOS ’13, pages 253–264.
ACM, 2013.
[12] L. Chen, R. Landfermann, H. L¨ohr, M. Rohe, A.-R.
Sadeghi, and C. St¨uble. A protocol for property-based
attestation. In Proceedings of the 1st ACM Workshop
on Scalable Trusted Computing, pages 7–16, 2006.
[13] D. Cooper, S. Santesson, S. Farrell, S. Boeyen,
R. Housley, and W. Polk. Internet X.509 Public Key
Infrastructure Certiﬁcate and Certiﬁcate Revocation
List (CRL) Proﬁle. RFC 5280 (Proposed Standard),
May 2008. Updated by RFC 6818. URL:
http://www.ietf.org/rfc/rfc5280.txt.
We thank Jon McCune and our anonymous reviewers for
their feedback. This work was supported by Intel through
the ISTC for Secure Computing, AFOSR under MURI
award FA9550-12-1-0040, and NSF under CCF-0424422.
[14] V. Costan and S. Devadas. Intel SGX explained.
Cryptology ePrint Archive, Report 2016/086, 2016.
https://eprint.iacr.org/2016/086.
[15] E. Felten. A court order is an insider attack, 2013.
12
URL: https://freedom-to-tinker.com/blog/felten/
a-court-order-is-an-insider-attack/.
[16] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan,
B. Parno, D. Zhang, and B. Zill. Ironclad Apps:
End-to-End Security via Automated Full-System
Veriﬁcation. In 11th USENIX Symposium on
Operating Systems Design and Implementation, pages
165–181. USENIX Association, Oct. 2014.
[17] M. Hoekstra, R. Lal, P. Pappachan, C. Rozas,
V. Phegade, and J. del Cuvillo. Using Innovative
Instructions to Create Trustworthy Software
Solutions. In Proceedings of the 2nd International
Workshop on Hardware and Architectural Support for
Security and Privacy, 2013.
[18] Information Technology and Innovation Foundation.
How much will PRISM cost the U.S. cloud computing
industry?, 2013. URL:
http://www.itif.org/2013-cloud-computing-costs.pdf.
[19] Intel Corporation. Intel Software Guard Extensions
Programming Reference, October 2014.
[20] Intel Corporation. Intel 64 and IA-32 Architectures,
Software Developer’s Manual, volume 2C: Instruction
Set Reference, chapter 5: Safer Mode Extensions
Reference. 2015.
[21] Intel Corporation. Intel Software Guard Extensions
Enclave Writer’s Guide, 2015.
[22] B. Laurie, A. Langley, and E. Kasper. Certiﬁcate
Transparency. RFC 6962 (Experimental), June 2013.
URL: http://www.ietf.org/rfc/rfc6962.txt.
[23] N. Lawson. Final post on Javascript crypto, 2010.
URL: http://rdist.root.org/2010/11/29/
ﬁnal-post-on-javascript-crypto/.
[24] M. Li, W. Zang, K. Bai, M. Yu, and P. Liu. Mycloud:
Supporting user-conﬁgured privacy protection in cloud
computing. In Proceedings of the 29th Annual
Computer Security Applications Conference, pages
59–68, 2013.
Harmful, 2011. URL: http://www.matasano.com/
articles/javascript-cryptography/.
[31] Rust programming language.
https://www.rust-lang.org/.
[32] P. Saint-Andre and J. Hodges. Representation and
Veriﬁcation of Domain-Based Application Service
Identity within Internet Public Key Infrastructure
Using X.509 (PKIX) Certiﬁcates in the Context of
Transport Layer Security (TLS). RFC 6125 (Proposed
Standard), Mar. 2011. URL:
http://www.ietf.org/rfc/rfc6125.txt.
[33] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis,
M. Peinado, G. Mainar-Ruiz, and M. Russinovich.
VC3: Trustworthy Data Analytics in the Cloud Using
SGX. In 36th IEEE Symposium on Security and
Privacy, pages 38–54, May 2015.
[34] R. Sleevi and M. Watson. Web Cryptography API.
W3C candidate recommendation, W3C, Dec. 2014.
URL: http://www.w3.org/TR/WebCryptoAPI/.
[35] J. Staten. The cost of PRISM will be larger than ITIF
projects. Forrester Research, 2013. URL:
http://blogs.forrester.com/james staten/13-08-14-the
cost of prism will be larger than itif projects.
[36] P. Stone. Pixel perfect timing attacks with HTML5.
Presented at Black Hat USA 2013, 2013. URL:
http://www.contextis.com/documents/2/Browser
Timing Attacks.pdf.
[37] Trusted Computing Group. TPM Main Speciﬁcation,
2011. URL: http://www.trustedcomputinggroup.org/
resources/tpm main speciﬁcation.
[38] J. Winter. Trusted Computing Building Blocks for
Embedded Linux-based ARM Trustzone Platforms. In
Proceedings of the 3rd ACM Workshop on Scalable
Trusted Computing, pages 21–30. ACM, 2008.
[39] E. Wobber, M. Abadi, M. Burrows, and B. Lampson.
Authentication in the Taos operating system. ACM
Trans. Computer Systems, 12(1):3–32, 1994.
[25] J. L. Manferdelli, T. Roeder, and F. B. Schneider. The
[40] R. Wojtczuk and J. Rutkowska. Attacking Intel
Trusted Execution Technology. Presented at Black
Hat DC 2009, 2009. URL: http://invisiblethingslab.
com/resources/bh09dc/AttackingIntelTXT-slides.pdf.
[41] Zetetic LLC. SQLCipher.
https://www.zetetic.net/sqlcipher/.
CloudProxy Tao for Trusted Computing. Technical
Report UCB/EECS-2013-135, EECS Department,
University of California, Berkeley, Jul 2013. URL:
https://github.com/jlmucb/cloudproxy.
[26] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter,
and H. Isozaki. Flicker: An Execution Infrastructure
for TCB Minimization. In Proceedings of the 3rd ACM
SIGOPS/EuroSys European Conference on Computer
Systems, pages 315–328. ACM, 2008.
[27] F. McKeen, I. Alexandrovich, A. Berenzon, C. Rozas,
H. Shaﬁ, V. Shanbhogue, and U. Savagaonkar.
Innovative Instructions and Software Model for
Isolated Execution. In Proceedings of the 2nd
International Workshop on Hardware and
Architectural Support for Security and Privacy, 2013.
[28] B. Parno, J. R. Lorch, J. R. Douceur, J. Mickens, and
J. M. McCune. Memoir: Practical state continuity for
protected modules. In 32nd IEEE Symposium on
Security and Privacy, pages 379–394, 2011.
[29] B. Parno, J. M. McCune, and A. Perrig.
Bootstrapping trust in commodity computers. In 31st
IEEE Symposium on Security and Privacy, pages
414–429, 2010.
[30] T. Ptacek. Javascript Cryptography Considered
13