title:SAMPL: Scalable Auditability of Monitoring Processes using Public
Ledgers
author:Gaurav Panwar and
Roopa Vishwanathan and
Satyajayant Misra and
Austin Bos
SAMPL: Scalable Auditability of Monitoring Processes using
Public Ledgers
Gaurav Panwar, Roopa Vishwanathan, Satyajayant Misra, Austin Bos
New Mexico State University
Las Cruces, New Mexico
{gpanwar,roopav,misra,abos}@nmsu.edu
ABSTRACT
Organized surveillance, especially by governments poses a major
challenge to individual privacy, due to the resources governments
have at their disposal, and the possibility of overreach. Given the
impact of invasive monitoring, in most democratic countries, gov-
ernment surveillance is, in theory, monitored and subject to public
oversight to guard against violations. In practice, there is a diffi-
cult fine balance between safeguarding individual’s privacy rights
and not diluting the efficacy of national security investigations, as
exemplified by reports on government surveillance programs that
have caused public controversy, and have been challenged by civil
and privacy rights organizations.
Surveillance is generally conducted through a mechanism where
federal agencies obtain a warrant from a federal or state judge
(e.g., the US FISA court, Supreme Court in Canada) to subpoena
a company or service-provider (e.g., Google, Microsoft) for their
customers’ data. The courts provide annual statistics on the re-
quests (accepted, rejected), while the companies provide annual
transparency reports for public auditing. However, in practice, the
statistical information provided by the courts and companies is at a
very high level, generic, is released after-the-fact, and is inadequate
for auditing the operations. Often this is attributed to the lack of
scalable mechanisms for reporting and transparent auditing.
In this paper, we present SAMPL, a novel auditing framework
which leverages cryptographic mechanisms, such as zero knowl-
edge proofs, Pedersen commitments, Merkle trees, and public ledgers
to create a scalable mechanism for auditing electronic surveillance
processes involving multiple actors. SAMPL is the first framework
that can identify the actors (e.g., agencies and companies) that
violate the purview of the court orders. We experimentally demon-
strate the scalability for SAMPL for handling concurrent monitoring
processes without undermining their secrecy and auditability.
CCS CONCEPTS
• Security and privacy → Distributed systems security; Security
protocols; Social aspects of security and privacy; Privacy protections;
• Social and professional topics → Governmental regulations; •
Applied computing → Law.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3354219
ACM Reference Format:
Gaurav Panwar, Roopa Vishwanathan, Satyajayant Misra, Austin Bos. 2019.
SAMPL: Scalable Auditability of Monitoring Processes using Public Ledgers.
In 2019 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’19), November 11–15, 2019, London, United Kingdom. ACM, New York,
NY, USA, 18 pages. https://doi.org/10.1145/3319535.3354219
1 INTRODUCTION
With increases in connected devices and electronic communica-
tions becoming the mainstay of human interactions, monitoring of
human electronic activities have become pervasive both by com-
panies trying to use the information for business advantage and
governments trying to surveil citizens for national security and
criminal activities [31]. Organized surveillance, particularly by state
actors poses a serious challenge to an individual’s privacy on ac-
count of the resources at disposal and its potential for overreaching
use [11, 31]. Further, individual or representative entities do not
have a mechanism to audit the surveillance, even after it’s comple-
tion, to assess if their rights were violated.
To motivate the discussion, we use the well-known United States
Surveillance law, namely Electronic Communications Privacy Act
(ECPA), it’s amendments, and it’s corresponding processes as an
example. Similar laws exist in other countries, e.g., the Investigatory
Powers Act in the UK, and the Telecommunications (Interception
and Access) Act in Australia. Several studies have shown that said
processes, although technically auditable, tend to be opaque and sel-
dom fully auditable, even when the audit is performed by powerful
oversight bodies, such as the US Congress [31, 40].
In these monitoring processes, the active players include the
law enforcement/intelligence gathering agency (L) that makes the
surveillance request; the judge/court (J) that grants the requests;
and the company (C) that provides the data corresponding to the
request. The other actors include the individual (I) being surveilled
and other users/agencies, e.g., American Civil Liberties Union
(ACLU) [6] whose mission is to defend and safeguard individual
privacy rights. The steps in the process generally start with the
agency L requesting a court order from the judge J. If J approves
the request, she creates a sealed court order, which can only be
unsealed by L for the company C; the sealed order can be unsealed
for the public after a pre-defined time (set during the issue of the
order). The company C either accepts the request and provides the
data or challenges the order on perceived violations. Once all parties
agree, C sends the data requested. The agency L and company C
can iteratively request and transmit data respectively several times,
as needed, within the purview of the order.
Challenges and Motivation: The said monitoring processes
present several issues that hinder accountability and public au-
ditability, that are desirable for transparency: 1) The fact that there
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2249exists a sealed order is not publicly notified. 2) Further, as per stud-
ies [35], there is no systematic mechanism to unseal orders. In the
absence of information, there is no way for the public to even know
if there is any order, let alone request its unsealing when the sealing
date expires. Note that an order not getting unsealed might not
necessarily mean the judge issuing the order is malicious, rather,
the judge might simply forget to unseal the order at the right time.
3) An important missing piece in all accountability mechanisms to-
day is that there is no way to make sure that exchanges happening
between L and C, at the time of the surveillance, followed the letter
and spirit of the sealed order (enabling an auditable trail). 4) The
scalability of the processes given the number of requests (around
16K to 33K, as discussed below) and the frequency of exchanges
between/among the parties has not been explored.
Currently the only information that is publicly available is sum-
marized information from the courts themselves or from annual
aggregate reporting by companies [21, 27]. For instance, the FISA
court rulings present the number of requests made under different
sections, the number fully or partially granted, and the number
denied. For example in 2018, 1204 requests were submitted for Sec-
tions U.S.C. 50 §1805 and §1804, with 868 granted, 308 modified,
41 partly denied, and 18 completely denied. However, this infor-
mation usually tends to be high level aggregate statistics, and are
not useful for public accountability. It does not equip individuals
being surveilled with the means to determine if any of the players
involved (law enforcement agencies, companies) reached beyond
the ambit of the court’s order, or if they were unfairly surveilled,
e.g., wholesale or dragnet surveillance.
As a result, the exchanges and dealings between governments
conducting surveillance, citizens being surveilled, and non-profit
privacy advocates and organizations, are uneasy at best, and pug-
nacious at worst. This is evidenced in the steady stream of lawsuits
challenging the constitutionality of various government surveil-
lance programs, raising pertinent questions about the legality and
ethics of the surveillance itself, and if citizens’ privacy and consti-
tutional rights were violated [34, 41, 42].
Google’s transparency report [27] states the number of user
data and account requests made over a six-month period and the
proportion of requests under each category (such as subpoena and
search warrants). Notable is the fact that the number of requests to
Google have been rising steadily for the last five years, e.g., in the
US, 16,407 user data requests for roughly 31,072 user accounts for
year 2012, to 32,877 user data requests corresponding to roughly
68,456 user accounts in 2017.
For the first months of 2018 (the last reported data), there were
20,936 user requests for approximately 62,142 user accounts. Similar
reports are also available from other companies, such as Microsoft
and Facebook [19, 30]. According to our findings, frequently, the
information presented is scarce and there are neither well-defined
mechanisms to audit surveillance processes from the outset, nor
to enable the surveilled individual the capability to assess post-
completion of the surveillance whether the search violated their
privacy rights, e.g., the right of citizens to be secure against un-
reasonable searches and seizures, per the US Constitution’s Fourth
Amendment.
Contributions: In this paper, we propose our framework, SAMPL
that addresses the challenges mentioned above. Our novel contri-
butions include: i) Design of SAMPL: a generic and scalable frame-
work for accountability of monitoring processes. ii) Capability for
auditing the compliance of the entities over the lifetime of the
surveillance order, from the outset, using cryptographic techniques,
such as zero knowledge proofs (ZKPs), and Pedersen commitments.
We introduce an entity called Enforcer who serves as the conduit
for interactions between law enforcement/intelligence gathering
agencies and companies, and verifies their interactions to guar-
antee compliance. We qualitatively prove that auditability of the
surveillance process when the court order is active is only possi-
ble if an entity like our proposed enforcer serves as the conduit
for information and the process does not leak information about
the surveillance to the public, just provides audit insights. iii) A
case study of our system in the context of the US legal system. iv)
Security analysis of the the proposed framework. v) Validation of
the framework using a near-real world implementation to assess
scalability.
Outline: In Section 2, we review related work. In Sections 3 and 4,
we present the system model, and threat model and privacy/security
properties, respectively. In Section 5, we present our construction
for SAMPL; in Section 6 we discuss SAMPL in the context of the
US legal system; and in Section 7, we present the security analysis
for SAMPL. In Section 8, we present our implementation of the
framework and our evaluations to demonstrate both feasibility
and scalability. In Section 9, we discuss possible enhancements,
extensions and generalizations of SAMPL. For better readability,
we give the proof of security of SAMPL in the appendix.
2 RELATED WORK
Our related work falls into three broad categories: auditing and
access control mechanisms, dragnet surveillance, and surveillance
with accountability. We review each of these below.
Auditing and access control mechanisms: Goldwasser and
Park [25] proposed cryptographic mechanisms involving ZKPs and
commitments to provide auditability in the application of secret
laws. For example, the U.S. Foreign Intelligence Surveillance Act
(FISA) court operations are classified, and the court typically hears
arguments only from government agencies [22]. While the focus
of [25] was on providing the public auditable records that secret
laws were correctly applied by courts, our focus is on verifying
whether the interactions between the law enforcement agencies
and companies, follow the letter and spirit of a court’s order.
Bates et al. [8] proposed mechanisms to enable secure audits
of wiretapping systems. Kroll et al. [28] designed a way for enti-
ties such as companies, law enforcement/intelligence-gathering
agencies to prove using cryptographic techniques that they are
authorized to access data such as phone records and email data.
These works focus on providing auditability using encrypted au-
dit logs that are not accessible to the general public, whereas our
goal is to focus on public accountability. Kamara [29] proposed a
mechanism for federal agencies to carry out warranted tapping on
phones of users, which focuses on providing access-control, not
public accountability.
Dragnet surveillance: Segal et al. [38, 39] focused on building
mechanisms to avoid contact chaining, where a large number of
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2250users get pulled into a surveillance net, chiefly because they were
associated with a legitimate target of surveillance. Their account-
ability mechanism ensures that government agencies can safely
disclose statistics such as number of warrants per month and maxi-
mum number of individuals affected per warrant.
Variable
λ
J, L, C, E, I, U, I
σ
T
RI = (V KRI, SKRI)
AI = (V KAI, SKAI)
PI = (V KPI1, SKPI1), . . .
,(V KPIm , SKPIm)
KCI
KJ LC
KEJ LC
C
bSize
bNum
πPIi
SO
IO
ι
Verify()
ZKPVerify()
Jdecide()
Ldecide()
Cdecide()
OrderGen()
SR
SRR
||
BC()
BC.read()
BC.write()
Table 1: Notations
Definition
Security parameter
Judge, Law enforcement agency, Com-
pany, Enforcers Set, Individual, Set of
Users, Set of Individuals
Signature
I’s total data records
Real identity of individual I
Anonymized identity of individual I
Pseudonymous identities of individual I
Key shared between company C and indi-
vidual I
Key shared between J, L, C
Key shared between E, J, L, C
Ciphertext
Batch Size for a client
Batch number for a specific client message
ZKP that PIi is valid pseudonym of indi-
vidual I
Surveillance order
Intermediate order
time period for surveillance
Verification function
ZKP Verification function
Judge decision function
Law enforcement agency decision func-
tion
Company decision function
Judge order generating function
Law enforcement agency’s surveillance
request
Company’s surveillance request response
Concatenation operator
Blockchain
Blockchain read function
Blockchain write function
Surveillance: Frankle et al. [24], proposed a system which deals
with accountability in secret processes, which is most relevant to
our work. There are two significant differences between [24] and
our work: 1) [24] requires law enforcement agencies and companies
to post cryptographic commitments and ZKPs to the blockchain
at regular intervals. Moreover, in their system, honest parties are
trusted to log information regularly, and honest parties are expected