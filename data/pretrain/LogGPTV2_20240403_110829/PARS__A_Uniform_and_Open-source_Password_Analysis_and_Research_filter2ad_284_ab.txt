sideration of n − 1 previous characters. However, the algo-
rithm in [7, 16] cannot enumerate passwords in the decreas-
ing order of likelihood. To address this limitation, D¨urmuth
et al. proposed an improved cracking algorithm, namely
Ordered Markov ENumerator (OMEN) in [13], which can
make password guesses in the decreasing order of likelihood.
Furthermore, they also extended OMEN to OMEN+, where
users’ social proﬁles are considered in password cracking.
Taking another approach, Weir et al. proposed a pass-
word cracking algorithm using Probabilistic Context-Free
Grammars (PCFGs) [17]. Basically, the cracking can be
conducted in two steps. In the ﬁrst step, PCFGs are gener-
ated based on a training dataset. In the second step, word-
mangling rules are created from the trained PCFGs and
password guesses are generated for actual cracking. From
[8], the designed PCFG based cracking algorithm in [17]
does not consider the probability of letter segments. To ad-
dress this issue, Veras et al.
in [14] proposed an improved
PCFG based password cracking algorithm, where the gram-
mars take into account structure, syntax, and semantics of
passwords.
In [18], Zhang et al. studied the eﬀect of expired pass-
words on the security of current passwords. Leveraging a
dataset of 7.7K accounts, they proposed an approximately
optimal searching strategy to crack users’ new passwords
from their expired passwords. Another similar scheme is
presented in [12], where Das studied the password reuse
problem. Based on 6K accounts, they designed a cracking
algorithm to guess users’ passwords on one site from their
leaked passwords on other sites. Both the algorithms in [18]
and [12] are based on some transformation and mangling
rules, e.g., capitalization, insertion, deletion, and leet-speak.
There are also many password cracking tools available,
among which the most popular one is John the Ripper (JtR)
[19]. JtR supports multiple modes: Wordlist mode (JtR-
W), Single mode (JtR-S), Incremental mode (JtR-I), and
Markov mode (JtR-M). In JtR-W, a dictionary and a pass-
word hash ﬁle serve as inputs. JtR will try each word in
the dictionary as a password guess to perform cracking. In
JtR-S, each password hash serves as an input along with an
auxiliary string, e.g., username. Then JtR-S applies a set
of mangling rules to the auxiliary string to generate pass-
word guesses. JtR-I is an intelligent brute force cracking
method, in which the statistical character frequencies will be
employed to brute force the entire password space following
a quasi-decreasing order of password probabilities. JtR-M is
a similar Markov model based cracking strategy as in [16].
In [15], Amico et al. evaluated the Markov model and
PCFG based cracking algorithms in [16] and [17], and JtR-
M (all developed before 2010). According to their results,
all the algorithms have their advantages in diﬀerent scenar-
ios. Diﬀerent conclusions are drawn in [10], where Ma et al.
evaluated n-gram Markov model and PCFG based password
cracking schemes. They concluded that the Markov model
along with diﬀerent normalization and smoothing methods
performs better than PCFG under the probability thresh-
old model (we will discuss this model later). Consequently,
inconsistent conclusions of existing password cracking algo-
rithms remain. Furthermore, with the emergence of new
cracking algorithms and new versions of cracking tools, e.g.,
OMEN [13], semantics based algorithm [14], JtR 1.7.9 [19],
which cracking algorithm works best in what scenarios is not
known. Therefore, a uniform platform to comprehensively
and fairly evaluate existing cracking algorithms could be a
tremendous resource to the password research community.
4.2
Implementation and Analysis
We implement all the password cracking algorithms sum-
marized in Section 4.1. Besides that, we also integrate the
popular password cracking tool John the Ripper (JtR) [19]
into the crackability evaluation component. For convenience,
we denote Narayanan and Shmatikov’s algorithm as NS [16],
Zhang et al.’s algorithm as ZMR [18], Veras et al.’s algorithm
as VCT [14], and Das et al.’s algorithm as DBCBW [12]
(initials of authors). Then, we summarize and analyze the
implemented algorithms in Table 3, where Dic., Str., Syn.,
and Sem. stand for Dictionary, Structure, Syntax, and Se-
mantics, respectively; SP indicates that an algorithm con-
siders Social Proﬁles (SP) of users when cracking; DO in-
dicates that an algorithm makes password guesses in the
Decreasing Order (DO) of probabilities; CC indicates that
the entire password space (i.e., the set of all the possible
passwords) can be Completely Covered (CC) by an algo-
rithm’s guesses; On/Oﬀ indicates that an algorithm is an
Online/Oﬄine (On/Oﬀ) attack; G/S indicates that the al-
gorithm is designed to perform a General/Special password
attack; DT and BF indicate Direct Try and Brute Force
(BF) respectively; and (cid:32), (cid:72)(cid:35), and (cid:35) represent true, partially
true, and false, respectively.
Table 3: Password cracking algorithms analysis.
Year Dic. Train Model Str. Syn. Sem. SP DO CC On/Oﬀ G/S
(cid:32) Markov (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:35) (cid:35) (cid:72)(cid:35) (cid:35)/(cid:32) G
(cid:32)
PCFG (cid:32) (cid:35) (cid:35) (cid:35) (cid:32) (cid:72)(cid:35) (cid:35)/(cid:32) G
(cid:72)(cid:35) Heuristic (cid:35) (cid:35) (cid:35) (cid:35) (cid:72)(cid:35) (cid:35) (cid:32)/(cid:32) S
(cid:32) Markov (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:35) (cid:32) (cid:72)(cid:35) (cid:35)/(cid:32) G
(cid:32) Markov (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:32) (cid:32) (cid:72)(cid:35) (cid:35)/(cid:32) G/S
(cid:32) Markov (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:35) (cid:35) (cid:72)(cid:35) (cid:35)/(cid:32) G
(cid:32)
PCFG (cid:32) (cid:32) (cid:32) (cid:35) (cid:32) (cid:72)(cid:35) (cid:35)/(cid:32) G
(cid:72)(cid:35) Heuristic (cid:35) (cid:35) (cid:35) (cid:35) (cid:72)(cid:35) (cid:35) (cid:32)/(cid:32) S
(cid:35)
(cid:35) (cid:35) (cid:35) (cid:35) (cid:35) (cid:35) (cid:35)/(cid:32) G
(cid:35) Mangling (cid:35) (cid:35) (cid:35) (cid:72)(cid:35) (cid:35) (cid:35) (cid:35)/(cid:32) S
(cid:35)
(cid:35) (cid:35) (cid:35) (cid:35) (cid:72)(cid:35) (cid:32) (cid:35)/(cid:32) G
(cid:32) Markov (cid:72)(cid:35) (cid:72)(cid:35) (cid:35) (cid:35) (cid:32) (cid:72)(cid:35) (cid:35)/(cid:32) G
DT
BF
NS
ZMR
05 (cid:35)
PCFG 09 (cid:32)
10 (cid:35)
OMEN 13 (cid:35)
OMEN+ 13 (cid:35)
n-gram 12/14 (cid:35)
14 (cid:32)
DBCBW 14 (cid:35)
JtR-W 12 (cid:32)
12 (cid:35)
12 (cid:35)
JtR-M 12 (cid:35)
JtR-S
JtR-I
VCT
We discuss Table 3 as follows.
(1) JtR-W, PCFG, and VCT are dictionary-based attacks,
while all the other attacks are dictionary-free. JtR-W, JtR-
S, and JtR-I are training-free attacks. This is because that
JtR-W cracks passwords by directly trying the words from a
dictionary, JtR-S makes password guesses by applying man-
gling rules to an auxiliary string, and JtR-I is an intelligent
brute force algorithm. All the Markov model and PCFG
based algorithms are training-based since they need to build
a model to generate password guesses in an optimal order.
For the two heuristics based algorithms ZMR, which gener-
ates guesses by applying password transformation heuristics
to expired passwords, and DBCBW, which generates guesses
by applying password transformation heuristics to leaked
passwords from other sites, they can be (partially) training-
based or training-free. If the cracking heuristics are trained,
they can be applied in an optimal order and thus accelerate
the cracking process.
(2) All of the Markov model based algorithms partially
consider passwords’ structure and syntax. This is due to
the property of the Markov model.
If a password struc-
ture/syntax appears frequently in the training data, the
transition probability of the corresponding structure/syntax
path will be high in the Markov model. PCFG is a structure-
based algorithm. During the process of password guesses
generation, all the letter segments are replaced by words
with the same length from an input dictionary. There-
fore, PCFG does not consider password syntax or seman-
tics. Because of similar reasons as discussed before, ZMR,
DBCBW, JtR-W, JtR-S, and JtR-I do not employ password
structure, syntax, or semantics information in their crack-
ing. Note that VCT is the only algorithm that considers
passwords’ structure, syntax, and semantics, under which a
PCFG model based password generator will be trained.
(3) OMEN+ is the only existing algorithm that uses users’
social proﬁles to facilitate password cracking. The motiva-
tion of OMEN+ is that with a nontrivial probability, user-
chosen passwords have correlations with their social pro-
ﬁles, e.g., name, birthday, and education. According to the
results in [13], about 5% more passwords can be cracked
compared to OMEN which does not use users’ social pro-
ﬁles. Depending on the input auxiliary information (string),
which could be the name, username, email, birthday, etc.,
JtR-S can be considered as a technique that partially con-
siders users’ social proﬁles.
(4) All the Markov model and PCFG based algorithms
except NS and n-gram can generate password guesses in the
decreasing order of likelihood, which is intuitively the op-
timal strategy for password cracking. ZMR and DBCBW
can generate password guesses in a quasi-decreasing order
of probabilities depending on whether their password trans-
formation heuristics are trained. Also, by employing the
statistical character frequency information, JtR-I can make
password guesses in a quasi-decreasing order of probability.
(5) According to our previous discussion, it is intuitive
that ZMR, DBCBW, JtR-W, and JtR-S cannot completely
cover the entire password space. It is also intuitive that JtR-
I can completely cover the entire password space since it is a
brute force algorithm. For all the other algorithms, it is pos-
sible however without guarantee that they can completely
cover the password space. For Markov model based algo-
rithms, it depends on whether the trained Markov model can
cover the password space, and for PCFG based algorithms,
it depends on the trained PCFGs and the used dictionaries.
Generally speaking, given the same training data, NS [16] is
more likely to cover the entire password space.
(6) Other than ZMR and DBCBW, all the other algo-
rithms are initially designed for an oﬄine attack. ZMR and
DBCBW can be used for both online and oﬄine attacks.
This is because in ZMR and DBCBW, an adversary is as-
sumed to have a victim’s expired password information and
password information from other sites respectively, and thus
an adversary can achieve a high probability of success with
a small number of guesses based on the auxiliary knowledge.
(7) As we discussed before, ZMR is an expired password
based attack, DBCBW is a password reuse based attack, and
JtR-S is an auxiliary information based attack for speciﬁed
users. Therefore, these three algorithms can be employed to
perform special purpose attacks. OMEN+ can be used for
both special and general purpose attacks, depending on the
available social proﬁles of victims. All the other attacks are
designed to perform general purpose password cracking.
4.3 Evaluation
In this subsection, we evaluate our implementation. Since
we do not have any available expired passwords, reused pass-
words, or the social proﬁles of any users, we do not evaluate
ZMR, DBCBW, and OMEN+ at this moment1.
Evaluation Setting. In the evaluation, JtR-W uses its
default dictionary. For other algorithms that need an in-
put dictionary, we use the combination of the widely em-
ployed Dic-029 [17] and Pinyin [3]. When evaluating n-
gram [7] [10], we use 3-gram (3g). For JtR-W, its guesses
are the input dictionary words. For other algorithms, they
will make guesses based on their models. Here, we limit
each algorithm (except for JtR-W) to generate two billion
guesses2. Furthermore, to make the comparison fair and re-
duce possible bias, all the training and testing data are the
standard datasets.
Results and Analysis. The results of training-free and
training-based cracking algorithms are shown in Tables 4
and 5, respectively. We analyze the results as follows.
1We could crawl the web for the social proﬁles of victims
who have emails available in Table 1. However, this raises
ethical concerns and could be illegal.
2It is straightforward for us to generate more guesses or
even exhaust the entire password space. However, since our
main purpose is to implement existing password cracking al-
gorithms in a uniform research system, we here only show
their performance on this platform. Further, it takes sig-
niﬁcant more time for some algorithms to generate a large
number guesses. For instance, it takes VCT several days to
generate two billion guesses on a moderate PC.
Table 5: Training-based password cracking. Each value indicates the percentages of passwords been cracked.
Training
Duduniu
Renren
CSDN
Data PCFG VCT NS 3g OMEN JtR-M PCFG VCT NS 3g OMEN JtR-M PCFG VCT NS 3g OMEN JtR-M PCFG VCT NS 3g OMEN JtR-M
7k7k
CSDN
−
9.4
Training
Tianya
LinkedIn
Rockyou
Gamigo
Data PCFG VCT NS 3g OMEN JtR-M PCFG VCT NS 3g OMEN JtR-M PCFG VCT NS 3g OMEN JtR-M PCFG VCT NS 3g OMEN JtR-M
7k7k
CSDN
2.5 0.5 6.2
12.3 0.2 1.8
8.5
8.8
7k7k
− − −
11.8 0.7 3.6
−
30.9
Duduniu 10.0 12.3 1.2 10.2 68.7
13.1 15.0 1.7 15.9 71.3
Renren
11.5 14.2 1.5 12.9 71.1
Tianya
2.4
36.1
62.8
3.2
1.4
8.9
3.5 0.0 2.9
3.8 0.1 7.5
2.8 0.0 2.1
LinkedIn
Rockyou
Gamigo
9.8 0.7 15.3 33.9
17.1 0.3 2.2
19.9
38.2
Duduniu 10.3 17.3 0.6 6.6
11.4 15.9 1.0 9.7
37.5