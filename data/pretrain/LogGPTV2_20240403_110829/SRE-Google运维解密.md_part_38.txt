代码中以及依赖中的安全漏洞等）。
定时地每晚构建和每周构建将失去意义。
不工作的代码会对团队造成影响，因为它们必须手动绕过这些问题。
只是效率低）API客户端代码。
比想象的要严重，因为它们可能会迷惑其他开发团队，使他们写出错误的（或者
他部分很干净地剥离开进行测试。
涉及计费系统的代码通常对业务来说是很关键的。同时计费代码也经常可以从其
是否有某些函数或者类是非常关键的，或者对业务运营极为重要的？举例来说，
试的系统组件按重要度排序（用什么标准来衡量重要度都可以，关键要排序）？
如果所有任务都是高优先级的，那么它们就也全是低优先级的。是否可以将要测
第17章
测试可靠性
---
## Page 207
当然，如果某次测试失败，常常意味着你需要再选择更多的分支点，以尽快确定出错的
测试应该有针对性地覆盖整个测试环境中组件相互作用的部分。如果某个单元测试依赖
本地硬件。一个可靠的测试环境要求这些测试分别也有它们自己的对应测试覆盖。这些
小型的单元测试可能只有很少的依赖：一个代码文件，测试类库，运行时库，编译器和
行测试以提高稳定性的。
我们已经描述了测试的基础知识，现在来看一下SRE是如何系统化地在大规模系统上进
大规模测试
系统相对一些非生产使用的脚本来说当然需要对应更高的测试质量和测试覆盖度。
要注意，不是所有的软件项目都可以平等对待。某些人身安全相关或者业务收入相关的
工程项目。与其不停地重复说：“我们还需要更多的测试”，不如设立更准确的目标和期限
更好地聚焦你的测试：将创建一个高度测试过的代码库从一个复杂的哲学理念变成一个
有很多工具可以帮助量化和可视化测试覆盖程度（参见文献[Cra10]）。使用这些工具可
有测试，只运行修改部分。于是，测试成本变得更低，也执行得更快。
受影响的部分。这样的一套系统可以提供可重现的构建结果。这样不必每次重复运行所
Bazel可以为软件项目生成依赖图。当某个文件改动后，Bazel可以仅仅重新构建项目中
某些构建系统，如Bazel注"，为精确地控制测试执行提供了非常有价值的功能。例如，
形
版本。
点（branchpoint）进行合并，以使用最少次数的选代周期解决最大程度的不可预知性。
需要一套完整的灾难复原周期才能进行。实际的测试环境常常通过选择某几个版本分支
相反，某项发布测试可能依赖特别多，以至于它最终间接地依赖了整个代码仓库中的所
测试执行结果永远是通过，失去了测试的意义。
了运行时中某个没有测试覆盖的代码，那么环境中一个毫不相干的改动注”可能会导致该
者才能迭代得更快！
这段代码时很多参数异常的情况可能都找不到。
例如，
参见https://github.com/google/bazelo
个异常
待测试的代码是
在future
一个复杂API调用的包，提供了一个简单以及向后兼容的抽象层。该代码将
大规模测试
165
<193
<192
---
## Page 208
166
注10本节主要讨论了SRE工具中需要大规模部署使用的。但是，SRE也开发和使用很多不需要大规模部
对这些工具的测试也更为隐嗨。例如下列这些自动化工具：
自动化工具也是软件项目。因为它们代表的危险性对另一层服务来说是不可预知的，针
SRE工具具有两个特点：
SRE的工具也是软件项目，也需要测试10。SRE开发的工具可能负责以下操作：
测试大规模使用的工具
3.使用与黑盒监控一样的副本健康检查机制。
2.修改危险的工具类代码，使得它们上线之后就检查防护边界。只允许这些工具
1.使用一个独立的工具在复制配置文件中设立一道防护边界，
造成用户可见的数据问题。应该利用设计方式避免这种大问题：
进行批量操作，但是这个引擎如果一旦意外地在用户可见的实例上运行，可能会
理者缩短维护窗口期，而提供了一种暂时关闭事务的功能。这个引擎可能被用来
的软件可能会在生产系统上造成严重后果。举例来说，某数据库引擎为了便于管
绕过常见的、大量测试过的API而进行某种操作（哪怕是基于良好理由的前提下
·快速重排中继日志，以尽快重建主记录的工具。
·数据中心之间的负载均衡器。
●数据库索引的选择。
过健康检查。于是这个副本永远不会被负载均衡选择直接面向用户。
·由于现存的验证和发布流程，这些工具基本不会对用户造成直接影响，
·这些工具的副作用基本处于被良好地测试过的主流API范围内。
终用户的危险性，所以这里讨论的策略也适用于这些工具。
类代码访问处于不健康状态下的副本。
修改某些文件。
·从数据库中获取并且传递的性能度量指标。
重构某个用户不可见的备份副本中的数据。
用度量指标预测未来用量，进行容量规划。
第17章测试可靠性
这
些工具仍然需要测试
针对危险性高的软件设立防护边界
确保该副本无法通
---
## Page 209
那些在主流API之外工作的在线修复工具的测试就更有意思了。在一个分布式系统中，
就不大可能正常工作。
线、可记录、可加载、安全边界检查、干净启动）无法被满足，
在很多情况中，我们可以将这些功能以一种易于测试的方式编写。如果任何一个条件（离
很多灾难恢复工具都被精心设计为离线运行。这样的工具主要做以下事情：
针对灾难的测试
记得针对这种情况写测试就行了。
产生了。这种循环依赖可能并不是问题，只要API提供良好的重启机制，同时只要有人
到其他机器上。有的时候当该集群升级工具试图升级容器平衡工具的时候，循环依赖就
两个工具正在同时修改对方依赖的环境！例如，某个集群升级工具可能在推进更新的时
更有意思的是，我们的自动化工具可能正在修改另一个自动化工具依赖的环境，或者这
迁移失败，这就太丢人了。就算针对这种情况编写了集成测试，该测试也不太可能使用
的一个新版本带来的新算法修改内存的速度过快，最后导致网络带宽无法保持镜像从而
新调派以提高利用率，那么在某一点上该工具也要将自己所在的容器移动。如果该工具
我们如何来定义自动化工具所运行的环境呢？毕竟，如果某个自动化工具负责将容器重
既然这些自动化工具需要针对环境进行变化，就需要为其他代码文件写更多的部署测试
间，但是内部缓存的状态不太可能同时传递过去。
器被替换成一个缓存代理DNS服务器。虽然两个服务器都可以将DNS查询缓存一定时
TTL已经过期）。举例来说，如果一个机器上的runlevel发生变化，导致本地DNS服务
供正确结果。但是有一些API的行为在测试前后会改变（比如说DNS缓存在执行前后
API暴露的服务内部状态是否一致。例如，数据库可以在索引不存在的情况下，仍然提
测试可以保证在测试前后，服务的其他部分保持正确的行为。有时候甚至可以测试通过
自动化工具具有两个共同特点：
候需要消耗集群资源。同时，某个容器平衡器将会意识到这个问题，试图将该工具迁移
一个跟生产环境类似的模型。同时也非常不可能使用宝贵的跨大陆带宽来进行这种测试，
·对另外一个API用户来说，它们的调用结果是不可预知或不可见的。
·计算出一个可记录状态（checkpoint state），一个等同于服务完全停止的状态。
）它们的实际操作都是通过调用一个可靠的、经过良好测试的API。
支持常见的发布安全边界检查工具，确保启动结果是干净的。
将该可记录状态推送给一个非灾难验证工具，以验证状态。
，这些工具在灾难来临前
大规模测试
167
195
---
## Page 210
的是比较有用的。这些情景在不同程度上对所有测试都有影响，因为它们常常是强耦合
行一定数量的测试，以获取一个足够可靠的推断。这些情景有的是无关痛痒的，但是有
所以，我们必须针对某些感兴趣的可能情景建立起某种假设，然后针对这些情况重复运
该测试实际的通过率，同时可以计算出统计学意义上的不确定性。然而，针对每个测试
察要测试的事务。
杂。为了解决这个问题，你可能需要在这些测试中编译一套统一的工具，以便正确地观
一致更加便于测试。由于修复工具和生产工具常常是分开编译的，这种情况会变得更复
竞争问题。离线工具一般预期得到立即一致的结果，而不是最终一致的结果，因为立即
对灾难修复过程造成灾难性的后果。举例来说，假设你正在使用离线工具调查某项数据
你将会遇到的一大挑战就是某个正常行为可能是最终一致的（eventual consistent），这会
168
的每次变动都进行这项计算是不可行的。
有时候这个信号在看起来一样的重复运行下会发生改变。我们可以根据历史记录估算出
代码库中的每一个测试对代码的每一次改动都提供了对应的测试通过和不通过的信号
对速度的渴求
B
二
手段还是很有用的：
码修改后运行一次这些测试，不能确定地证明相应的问题已经修复。
状态的Chaos Monkey注ll以及Jepsen注12，不一定是可以重复执行的测试。仅仅在代
统计学手段，例如用于模糊测试的Lemon（参见文献[Ana07]），用于测试分布式
·利用该问题的几种不同表现形式可以帮你定位代码中可疑的区域。
·如果该记录可以形成一个发布测试，在开始研究错误报告之前多运行几次可能
·这些测试可以在某次测试中，提供所有随机选择的动作执行顺序的记录。有时
即使某个测试是以同样的随机数发生器种子重复运行的，
有时候多运行几次会显示这个失败问题比想象的要严重，你可以有针对性地升
再次重现。
杀掉任务与伪造的用户流量之间并没有任何序列化保证。
参见https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkeyo
级这个Bug的优先级和严重程度。
问题可以100%重现，那么修复之后就是100%不可重现。）
很有帮助，该问题重现的频率可以帮助预估问题是否已经被修复。（如果一个
候仅仅是靠记录随机数发生器的种子值就够了。
第17章测试可靠性
利用统计学工具
。因此之前测试过的错误代码路径不一定能
所有的任务都是按相同顺序被杀掉的，
。注13但是这些
在
---
## Page 211
注14参见htp://xkcd.com/303/。
提交前后各1次)。这样的话：
这就意味着我们的准确率需要达到0.99（正确率）的42.000次平方根。（21,000项测试，
错误计算环境因素导致错误地认为工程师的修改是有问题的几率是多少？如果每10个
结果良好，那么这次修改就可以被称为可发布的。这样的比较过程可以进而鼓励工程师
测试该项修改，我们需要对比提交前后代码库中这些测试的通过/失败结果。如果比较
假设某工程师正在一个有21,000个简单测试的服务上修改代码，提交了一份修改。为了
靠了）。
争问题，从而导致这项测试更为不可靠（或者是由于其他因素不可靠的测试变得更不可
罪于其他人的代码。换句话来讲，工程师关心的是他写的代码是否有预料之外的数据竞
部分代码——是否有问题。通常情况下，代码如果没问题，那么这次失败的测试可以归
使用测试框架基础设施的工程师想要知道他们的代码一
景同时进行估算。
的，所以可靠且快速得到一系列可操作的假设（哪些组件真的坏掉了）需要针对所有场
拒绝，用户可能比较容易接受。
改动中有1个被拒绝，那么用户肯定会非常不满意。但是如果100个修改中只有一个被
的算法）。
是否需要更多的本地资源），以及复杂度（检验这项修改在某个地方使用了一个非线性
运行更多的发布测试和集成测试，更多的分布式测试检查系统的扩展性（检验这项修改
果只有在工程师走神之前才有用，否则工程师下次走神可能就像XKCD说的那样
一个测试的非官方运行截止时间就是当工程师转而处理下一个事情的时候。测试结