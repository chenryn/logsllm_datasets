would provide an even stronger same-time security guarantee.
Setup. Using mOPE (or similarly stOPE) in a database
requires the following setup:
• A trusted client-side application that uses the mOPE
client to encode values. Unmodiﬁed applications can be
supported by using a proxy that intercepts and rewrites
the application’s SQL queries [33].
• User-deﬁned functions (UDFs) in the database server
that implement mOPE’s Order function and update
encodings in the database.
The client application maintains separate mOPE client state
(e.g., secret key) for every column encrypted with OPE.
Insert queries. To understand how values in a query are
encrypted, consider an application that wants to execute the
query INSERT INTO secret VALUES (5). The application
ﬁrst encrypts 5 using mOPE.Enc (Fig. 4) and obtains c ←
DET.Enc(5). It then issues the query INSERT INTO secret
473473
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:32 UTC from IEEE Xplore.  Restrictions apply. 
VALUES (MOPE_ORDER(c)), where MOPE_ORDER is a UDF
implementation of mOPE.Order.
Transformation summaries.
If mOPE rebalances its tree,
it must update OPE encodings stored in the database. One
challenge lies in describing the transformation from old to
new encodings in a succinct way; a naïve approach of storing
a mapping between all old and new encodings would scale
poorly when a large subtree (e.g., the root) is rebalanced.
Updates due to a B-tree balancing can be summarized
succinctly in a transformation summary as a sequence of
split and merge operations. Consider a b-ary B-tree. For
each node that split, we record the location where an item
was inserted in the node causing the split, and the location
of the split (from 1 to b). If there are N items in the tree,
there are at most logN such splits for a single mOPE
insertion, because the height of the B-tree is bounded by
logN. We record similar information for node merges in
the case of deletions in stOPE. We can further determine
a tight interval [low, high] of the OPE encodings that must
change. The server can then update all affected OPE
encodings with one SQL query of the form UPDATE secret
SET item=MOPE_TRANSFORM(item, summary) WHERE
item>=low AND item5. As before,
the proxy
computes mOPE.Enc of 5 to obtain c
and then
rewrites the query into SELECT * FROM secret WHERE
val>MOPE_ORDER(c). At the server, the UDF MOPE_ORDER
returns the OPE encoding of 5, and the server executes the
query on encrypted data as if the data were not encrypted.
For simple queries that perform comparison on exactly
one encoded column (as in the example above), the work
of the client is the same as the work of the server because
executing the query consists of performing one tree traversal
and collecting the output; in this case, the client saves only
on storage. However, most realistic queries perform ﬁltering
on other ﬁelds at the same time. In such cases, the work
of the server is more signiﬁcant than the work of the client
because the server has to process joins, compute ﬁlters on
various columns, intersect results, and so on, before sending
a potentially small result set to the client. For example, one
query from the industry-standard TPC-C benchmark requests
stock items from warehouse number 2 with order numbers
between 1245 and 1873 and quantity less than 1.0:
SELECT COUNT(DISTINCT(s_i)) FROM order_line, stock
WHERE ol_w=2 AND s_w=2 AND ol_d=3 AND s_i=ol_i AND
ol_o1245 AND s_quantity<1.0
such a complicated query can now be processed without
changing the DBMS and without incurring overheads from
comparing the relative positions of values in the OPE Tree.
Bulk loading. mOPE allows efﬁcient bulk loading for a
database by constructing the entire mOPE state in a single
pass. Bulk loading is often used to initially load a large data
set into a database. To encrypt a large batch of plaintext
values, mOPE simply sorts the values, builds a B-tree on
top of the sorted values in linear time, and uploads the tree
to the server. The resulting OPE Tree is a valid state, and
can support subsequent individual insertion operations. We
demonstrate the efﬁciency of this approach in §X-B.
Concurrency. Databases often allow multiple queries on
the same column to execute concurrently. With mOPE,
modiﬁcations of either the OPE state (e.g., due to Enc)
or the encoded values stored in a database table (e.g., due
to tree balancing) must be carefully ordered with respect to
other modiﬁcation or lookup operations (e.g., invocations of
Order). Our current prototype issues one query at a time,
although more ﬁne-grained ordering may be possible, perhaps
using ﬁne-grained tree locking [11].
IX. IMPLEMENTATION
We implemented mOPE and stOPE, including malicious
server protection (§VII), in 3,480 lines of C++ code (of
which the largest portion is 950 lines for Merkle veriﬁcation).
We also added support for our scheme in MySQL, with
transformation summaries, UDFs, and bulk loading as
discussed in §VIII, to demonstrate its usage for performing
SQL queries on encrypted data. We made no change to
the MySQL code because UDFs are part of the MySQL
interface. For DET and RND, we use Blowﬁsh for 32- and
64-bit plaintexts and AES for larger plaintext sizes.
X. EVALUATION
To evaluate the performance of mOPE, we answer the
following questions in the respective subsections:
• How is the mOPE encoding time affected by various
parameters, such as plaintext size, number of total items
encoded, number of items encoded in a batch, order of
items encoded, malicious vs. honest-but-curious server
scenarios, and network latency? (§X-B)
• How does the encoding time using mOPE compare
to the encryption time using the state-of-the-art OPE
scheme by Boldyreva et al. [6] (BCLO)? (§X-B)
• What are the storage costs of mOPE? (§X-C)
• How many ciphertext updates does mOPE perform, and
how costly are they in a real application? (§X-D)
A. Experimental setup
Such queries also show why it is important to store the
OPE encoding explicitly in the database rather than just using
the OPE Tree, which implicitly stores the order of values:
We measured the performance of mOPE and BCLO (our
shorthand for the scheme of Boldyreva et al. [6]) on a
machine with an Intel Core 2 Q9400 processor running
474474
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:32 UTC from IEEE Xplore.  Restrictions apply. 
Linux 3.3 with only a single core enabled for consistency,
running both the client and the server on the same machine.
For network experiments, we use a second identical machine
connected over a Gigabit network link, and we use Linux tc
to simulate additional network latency. We conﬁgure mOPE
to produce 64-bit OPE encodings, although none of our
experiments come close to a tree that deep. We evaluate
our schemes for the honest-but-curious (HbC) as well as
malicious server model.
We use an optimized implementation of the BCLO scheme
from CryptDB [33]. We extend it to support more efﬁcient
batch encryption by caching HGD samples when encrypting
a batch of values at once.
B. Throughput
Fig. 8 shows the throughput of mOPE in several con-
ﬁgurations as a function of the number of items encoded.
Overall, mOPE’s throughput in each conﬁguration goes down
slightly as the number of encrypted items goes up by orders of
magnitude. This is caused by the OPE Tree’s depth increasing
logarithmically with the number of encrypted items. The top
two curves show mOPE’s throughput when the items are
encrypted in sequential order starting from 1, and when
they are encrypted in random order. mOPE achieves nearly
identical performance in these two cases, because the B-tree
always remains balanced. Enabling malicious server checking
using Merkle hashing reduces mOPE’s throughput by 3.3×
compared to an honest-but-curious scenario. The bottom
curve shows the throughput of BCLO; it does not depend
on the number of items, and mOPE outperforms it by 43×
at 103 items in the honest-but-curious case.
104
103
102
d
n
o
c
e
s
r
e
p
d
e
t
p
y
r
c
n
e
s
m
e
t
I
101
101
mOPE random HbC
mOPE seq. HbC
mOPE seq. malicious
BCLO
102
103
104
105
106
Number of items encrypted
Figure 8. Throughput of mOPE and BCLO for 64-bit plaintext values
in the honest-but-curious (HbC) server setting and in the malicious server
setting, under either a random or a sequential distribution of inputs. BCLO’s
performance is independent of the number of items encrypted.
Applications often need to load large amounts of data,
making batch encryption an important workload. Fig. 9
shows the throughput of mOPE for batch encryption. mOPE
achieves signiﬁcantly higher throughput in batch mode than
in single-item encryption (shown in Fig. 8), since it does
475475
not traverse the tree for every item. mOPE’s throughput at
small batch sizes is dominated by tree construction startup
costs. Constructing the Merkle tree adds a 1.6× overhead.
mOPE in HbC mode achieves 83× higher batch throughput
than BCLO at 105 items, even when using our HGD caching
optimization for BCLO with sequential inputs (the ideal case
for HGD caching).
106
105
104
103
d
n
o
c
e
s
r
e
p
d
e
t
p
y
r
c
n
e
s
m
e
t
I
102
101
mOPE batch HbC, sequential
mOPE batch malicious, sequential
BCLO with caching, sequential
102
103
104
105
106
Number of items in a batch
Figure 9. Throughput of mOPE and BCLO when encrypting a batch of
64-bit plaintext values at once, as a function of the batch size.
Fig. 10 shows the effect of plaintext sizes on throughput.
mOPE is largely unaffected by plaintext sizes, in both the
HbC and malicious server settings; plaintext size affects only
the size of tree nodes and the time spent encrypting and
decrypting tree nodes using a block cipher. The throughput
of BCLO, however, drops exponentially as the plaintext size
increases; for 256-bit values (which correspond to relatively
short strings), BCLO takes 176 msec to encrypt a single
value, compared to < 1 msec for mOPE in the HbC model.
d
n
o
c
e
s
r
e
p
d
e
t
p
y
r
c
n
e
s
m
e
t
I
104
103
102
101
100
mOPE seq. HbC
mOPE seq. malicious
BCLO
32
64
128
Plaintext size (bits)
256
Figure 10. Throughput of mOPE and BCLO when encrypting 1000 plaintext
values of different size.
Since mOPE requires interaction with a server to encode