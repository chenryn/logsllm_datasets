title:Reducing Permission Requests in Mobile Apps
author:Sai Teja Peddinti and
Igor Bilogrevic and
Nina Taft and
Martin Pelikan and
&apos;Ulfar Erlingsson and
Pauline Anthonysamy and
Giles Hogben
Reducing Permission Requests in Mobile Apps
Sai Teja Peddinti, Igor Bilogrevic, Nina Taft
Martin Pelikan, Úlfar Erlingsson, Pauline Anthonysamy, Giles Hogben
Google Inc.
ABSTRACT
Users of mobile apps sometimes express discomfort or concerns
with what they see as unnecessary or intrusive permission requests
by certain apps. However encouraging mobile app developers to re-
quest fewer permissions is challenging because there are many rea-
sons why permissions are requested; furthermore, prior work [25]
has shown it is hard to disambiguate the purpose of a particular
permission with high certainty.
In this work we describe a novel, algorithmic mechanism in-
tended to discourage mobile-app developers from asking for unnec-
essary permissions. Developers are incentivized by an automated
alert, or “nudge”, shown in the Google Play Console when their apps
ask for permissions that are requested by very few functionally-
similar apps—in other words, by their competition. Empirically, this
incentive is effective, with significant developer response since its
deployment. Permissions have been redacted by 59% of apps that
were warned, and this attenuation has occurred broadly across both
app categories and app popularity levels. Importantly, billions of
users’ app installs from the Google Play have benefited from these
redactions.
CCS CONCEPTS
• Security and privacy → Domain-specific security and pri-
vacy architectures; Economics of security and privacy; • Informa-
tion systems → Data mining; • Computing methodologies →
Machine learning;
KEYWORDS
Mobile Apps, Permissions
ACM Reference Format:
Sai Teja Peddinti, Igor Bilogrevic, Nina Taft and Martin Pelikan, Úlfar Er-
lingsson, Pauline Anthonysamy, Giles Hogben. 2019. Reducing Permission
Requests in Mobile Apps. In Internet Measurement Conference (IMC ’19),
October 21–23, 2019, Amsterdam, Netherlands. ACM, New York, NY, USA,
8 pages. https://doi.org/10.1145/3355369.3355584
1 INTRODUCTION
The Android ecosystem and Google Play are popular platforms
with over 2 million apps and 2 billion active devices worldwide.
Many apps require access to private or protected data on users’
devices, which they request via the Android permissions system.
Recent versions of Android (6.0 and higher) organize individual
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
© 2019 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-6948-0/19/10.
https://doi.org/10.1145/3355369.3355584
259
permissions into groups, such as Storage, Contacts, and Location.
Users are asked to grant or deny a permission for an app at the level
of these groups via a runtime prompt. These prompts are usually
surfaced at the moment when an app needs a permission, and are
therefore made in context.
There are a number of reasons why an app may request per-
missions outside of those needed for its core functionality, such
as for analytics, personalization, testing, performance assessment,
advertising (especially for free apps), or support for (unused) func-
tionality in libraries that the app includes. Prior research has shown
that many mobile apps request potentially unnecessary permissions
[21, 27, 29] or permissions that are not directly related to their core
functionality [2, 8, 17, 24, 28, 35], or use permissions in unexpected
ways [21]. This has also been reported by the press [12, 33, 37]. Fur-
thermore, several studies have documented user frustration with
what is viewed as unnecessary permission requests [11, 18, 34, 35]
and how this can lead to a feeling of erosion of privacy [10, 12].
Permission usage can differ greatly, as mobile-app developers
comprise a large community with varying experience and disparate
working environments. A 2018 survey that reached over 40,000 de-
velopers from 160 countries, showed that 49% had less than 5 years
experience and 40% worked for organizations with less than 50 em-
ployees [9]. Small- to medium-sized businesses, or businesses with
limited experience, may be less likely to have privacy experts on
their teams, or understand the tradeoffs of designing with privacy
in mind [7]. For example, well meaning developers that include
third-party libraries in their code, may not realize that their app’s
manifest need not request all the permissions requested by a library,
and may be unaware of the privacy implications of different per-
mission requests. Indeed, the study in [19] showed that developers
mostly use the default configuration of ad libraries, choose libraries
based on popularity and ease-of-use rather than risk assessment,
and feel themselves unable to address the risks. Our aim is to help
such developers become more privacy-aware in their handling of
app permissions.
Developers who are aware of how their users perceive exces-
sive permission requests may be motivated to refrain from using
permissions that aren’t strictly needed, e.g., for the sake of their
reputation. A perusal of app reviews can reveal comments about
invasive and unnecessary permissions. Beyond complaints in app
reviews, there are other reasons why a developer may remove a
previously requested permission, including: (i) a change in a library
they use; (ii) an update to the APIs associated with a permission
such that the permission is no longer required; (iii) a change in the
app functionality; (iv) Google’s developer outreach efforts [4]; and
(v) in response to negative press articles [37].
Uncovering whether a permission request is necessary or not,
with certainty, has proved challenging; even powerful techniques
like static and dynamic analysis methods do not offer comprehen-
sive answers [25]. For instance, dynamic analysis has code coverage
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
S. Peddinti et al.
issues, and static analysis cannot examine code downloaded dur-
ing runtime. Thus, the decision as to whether or not to ask for a
permission should ultimately be left up to each developer.
Our first contribution is an automated algorithmic approach that
uncovers situations in which there is a significant chance a per-
mission request is unnecessary. We inform developers via a nudge.
Nudges are a well-known technique from behavioral economics
which have been used in many contexts to encourage positive
behavior without being punitive [32]. Recently researchers have
started studying nudges surfaced to users to assist them with deci-
sion making [3, 18]. We focus on nudges that target developers.
To incentivize developers to act on our nudge, we employ the
following metric. For a given app, we let the developer know when
other apps with very similar functionality refrain from requesting
a particular permission. For each specific app, we compute a ‘peer
group’ of functionally-similar apps, automatically determining sim-
ilarity from textual app descriptions and Google Play user-behavior
data (as described in Section 2.2). If a specific app requests a per-
mission that nearly none of its peers request, then we inform the
developer of this and also remind the developer of research show-
ing that users are more likely to select apps that request fewer
permissions, when given a choice [15].
Previous research studies have explored other ways to give de-
velopers privacy related feedback, such as giving apps privacy
grades [23], giving privacy policies grades [31, 36], or providing
privacy risk metrics on public websites [6, 26]. We chose to explore
giving developers feedback via the tools they use to create and
manage their apps, such as Android Studio, Play Console, GitHub,
and the Gradle build system, to name just a few. These tools provide
opportunities to surface nudges. We deployed our privacy warning
in August 2017 as part of the Pre-Launch Report shown in the Play
Console.
Our second contribution is an assessment on the effectiveness of
our nudge. After the live deployment of the nudge, we observed that
59% of apps who received a warning did indeed remove permissions.
These removals occurred across all app categories, all app popularity
levels, and over a broad set of permission types. This demonstrates
developers’ willingness to remove permissions when it is pointed
out to them. We show that the removal of these permission requests,
in aggregate, affected over 55 billion app installs. We also show that
the existing permission redaction activity that happens for other
reasons is significantly boosted by our warnings.
Our warning is one component of Google’s larger strategy to
protect users and help developers achieve good security and privacy
practices. One component focuses on device security, with services
such as Play Protect1 that offer malware protection services for
Android. A second component focuses on robust enforcement of
Google Play’s user data policies, which require developers to pro-
vide clear notice and control over collection of data in their apps,
as well as recent policy changes further limiting developers’ ability
to request access to certain permissions. For instance, Google Play
announced (in October 2018) further limitations of apps’ ability to
request Call Log and SMS permissions on Android devices [30] .
A third component aims at educating developers to adopt better
practices. In addition to our privacy warning, other signals have
1https://www.android.com/play-protect/
260
also been incorporated into the Play Console, such as warnings
that discourage use of HTTP and permanent identifiers. Also, Lint
warnings are surfaced in the Android Studio IDE to alert developers
if their app is using a version of a library that has been identified
by the library developer as a potential source of privacy and/or
security risks [1]. In isolation, each approach has its own benefits
and limitations, yet together they’re all complementary.
2 NUDGING DEVELOPERS
2.1 Our Approach
Developers interact with Google Play via the Play Console [5],
both before and after launching an app. This console includes a
‘Pre-Launch Report’, accessible to developers who submit apps for
testing, that surfaces the results of automated tests on app APKs
(e.g. that identify performance issues and many other things) before
the app is published on Google Play. Our approach to incentivize
developers to avoid requesting permissions that aren’t strictly nec-
essary is to show them a motivating warning in this Pre-Launch
Report.
Consider a developer who asks for a specific permission in their
new app. We compute a set of functionally similar apps and check
if this set of apps also ask for the same specific permission. The
permissions in the set of functionally-similar apps, or peer apps,
provide a baseline for the set of permissions needed for an app, as
well as a baseline for user expectations about which permissions
make sense for the app to request. Hence if nearly all of their
competition does not ask for the same permission, then we let
developer know. We thus make it easier for developers to assess
their needs as compared to their peers. We leave the decision to
the developer as we recognize there may be other specific reasons
for the permission.
Your app is requesting the permission, ,
which is used by less than X % of functionally similar apps.
 functionally similar apps which initially requested
 have stopped requesting it.
Users prefer apps that request fewer permissions and requesting
unnecessary permissions can affect your app’s visibility on
Google Play. If these permissions aren’t necessary, you may be
able to use alternative methods in your app and request fewer
permissions. If they are, we recommend providing an explanation
to users of why you need the permissions. Learn more.
Table 1: Privacy warning shown to developers
The warning message we show developers is depicted in Table 1.
We point out a few properties of this warning. First, developers
can choose to adhere to or ignore it. If a developer ignores the
warning, then it will re-appear in the report for the next version of
their app as long as the conditions for the signal remain true (e.g.
peer groups would be recomputed at that time). Second, we further
motivate developers by reminding them that users prefer apps with
fewer permissions and that the perception of a permission request
being unnecessary could affect their installs. Third, we recommend
Reducing Permission Requests in Mobile Apps
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
providing an explanation for the permission request. Fourth, pa-
rameter X is a design choice that influences how conservative the
warning aims to be. A very small value, such as 1%, ensures that
the developers receiving the warnings are highly unlikely to need
the permission.
2.2 Finding Similar Apps
The simplest approach would be to identify peer groups using
Google Play app categories; but this is too coarse-grained as apps
within the same category can offer very different functionality. For
example, the category ‘Travel and Local’ contains navigation apps
but also hotel reservation apps and tour guides. The category ‘Auto’
contains car software as well as apps that help users buy a car.
Another potential method for identifying similar apps could be
based on user behavior while browsing in Google Play. When users
look at a particular app on Google Play, suggestions of other apps
that users may want to install are also shown. When users click on
these suggestions, it may indicate that the user thought the clicked
app is similar or related to the original one they were viewing. A
method based on clustering analysis of these user co-clicks, (called
UBC for user behavior clustering method), iteratively improves over
time. However, the UBC data alone is not sufficient for our task for
a number of reasons. First, the UBC method is optimized to find
interesting suggestions, and not to find functionally-similar apps;
for example, for a game app the UBC method may suggest a game
discussion-forum app, or a game media editor. Second, to model
user preferences, the UBC method favors apps in the same primary
language, designed for the same locale. We do not want to limit our
peer app assessment by language since app functionality is often
independent of language. For example, the peer group of a French
email app could include a Japanese email app. Finally and perhaps
most importantly, the UBC method fails to provide any suggestions
for brand-new apps or very unpopular apps, since Google Play has
no user-behavior data for these cases.
Prior work has suggested analyzing the app description text via
LDA analysis to identify apps with similar functionality [14, 16].
Our approach follows this direction but, as explained below, we use
a different model and supplement the basic app descriptions with
user co-click data. Further below we compare our approach to a
pure LDA-based one.
Design of our App Peer Group Mechanism: To determine
when to surface a nudge in a Pre-Launch Report, we must be able
to compute app peer groups for all apps, including brand-new apps,
unpopular ones, and do so for apps in any language. We have
developed a deep-learning algorithm that creates an embedding
based on word2vec for each app, thereby mapping apps into a
high-dimensional space where closeness in distance corresponds
to similarity [13, 20].