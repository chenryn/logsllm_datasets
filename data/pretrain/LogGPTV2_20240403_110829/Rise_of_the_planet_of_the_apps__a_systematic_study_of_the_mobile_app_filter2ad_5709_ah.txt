case of random wandering. Our (cid:12)ndings show that there is a strong a(cid:14)nity
of users’ comments to app categories which validates our hypothesis about
the clustering e(cid:11)ect.
6
A Model of Appstore Workloads
In Chapter 4.2 we hypothesized that the non-ZIPF behavior of smartphone
app downloads can be explained by combining the fetch-at-most-once behav-
ior of smartphone users with the clustering e(cid:11)ect in user downloads. Then,
in chapter 5 we validated our intuition that app clustering has a signi(cid:12)cant
e(cid:11)ect on user comments, and thus, on user downloads as well. This chap-
ter presents a novel model of appstore usage (APP-CLUSTERING model),
based on both fetch-at-most-once and clustering e(cid:11)ect properties, that en-
ables us to further explore our hypothesis. First, we describe the proposed
model and its key parameters, and then we vary these parameters using
a Monte-Carlo simulator to approximate the observed distribution of app
downloads and validate our APP-CLUSTERING model.
6.1 Model Description and Analysis
Table 6.1 summarizes the key parameters used in our model. Note that we
have no parameter related with time in our model: we demonstrate that the
model is valid for every snapshot of our appstores. The number of apps A
is derived directly from the appstore’s snapshot. Similarly, we can (cid:12)nd the
total number of downloads D for all apps in the appstore until this date.
If we set the number of users U in our model, then the average number of
downloads per user d is d = D=U . We set the number of clusters C to be
equal to the actual number of app categories in the modeled appstore. We
found through simulations that indeed this number of clusters give the best
approximation of the actual downloads.
43
44
CHAPTER 6. A MODEL OF APPSTORE WORKLOADS
Symbol Parameter Description
A
U
D
d
zr
C
p
zc
D(i; j)
Number of apps
Number of users
Total downloads
Downloads per user
ZIPF exponent for generic app ranking
Number of clusters
Percentage of downloads based on the clustering e(cid:11)ect
ZIPF exponent for cluster’s app ranking
Predicted downloads for app with total rank i and rank j in its cluster
Table 6.1: APP-CLUSTERING model parameters and notation.
In our APP-CLUSTERING model, each app has a unique rank i from
1 to A. Moreover, apps are distributed to the C clusters in a way that an
app belongs to exactly one cluster. Thus, each app has also a second rank j
compared with the other apps in the same cluster, based on its overall rank
i and the overall ranking of the other apps in this cluster. Then, each user
randomly selects and downloads d apps. Apps are selected for downloading
by the users based on an overall ZIPF distribution, using their rank i and the
zr ZIPF exponent, with two exceptions: (i) fetch-at-most-one, i.e., each user
downloads the same app at most once, and (ii) clustering-e(cid:11)ect, i.e., once
an app a is downloaded, the user subsequently downloads a number of apps
which belong to the a’s cluster. In the latter case, apps from this cluster
are also selected based on a ZIPF-based distribution, using the apps’ rank
j in this cluster and the ZIPF exponent zc. The parameter p in our model
de(cid:12)nes the percentage of the user downloads that are selected based on the
clustering e(cid:11)ect, while the (cid:12)rst (1 (cid:0) p) (cid:2) d app downloads of each user are
selected using the overall ZIPF distribution. Based on these parameters, the
APP-CLUSTERING model estimates the total number of downloads D(i; j)
for each app with overall rank i and rank j in this cluster.
We believe that the main abstraction introduced by our approach with
respect to the previous download models is the abstraction of a cluster.
The cluster may be used to model (i) app categories, (ii) recommendation
systems, (iii) user groups, and other possible grouping forces. For example,
several appstores categorize apps into di(cid:11)erent groups: games, wallpapers,
ebooks, utilities, lifestyle, and other. Once a user downloads an app from
a particular category, this user may stay in the same category a bit longer
before switching to another category.
Analysis. We assume an appstore with U users, where each user down-
loads d apps. For simplicity we assume that all users download the same
number of apps. Out of the total D downloads, (1(cid:0)p)(cid:2)D are app selections
based on a pure ZIPF distribution. That is, an app with rank i has a prob-
ability to be selected for downloading equal to 1=izr . Similarly, when apps
are selected from a speci(cid:12)c cluster, an app with rank j in this cluster will be
6.2. SIMULATION-BASED MODEL VALIDATION
45
selected with probability equal to 1=jzc. Overall, the expected downloads
D(i; j) for an app with overall rank i and rank j in its respective cluster
with the APP-CLUSTERING model are:
UX
1 (cid:0)
1 (cid:0) 1=izr
AP
!
1=kzr
D(i; j) =
u=1
(1(cid:0)p)(cid:2)d (cid:2)
!
p(cid:2)d
SCP
1 (cid:0) 1=jzc
1=lzc
(6.1)
k=1
l=1
The expected downloads per each app are estimated by adding the prob-
ability of all users to download this app. The probability of a single user
to download this app is one minus the probability for not downloading this
app with (1 (cid:0) p) (cid:2) d ZIPF-based selections and p (cid:2) d clustering-based se-
lections. We see that the number of downloads for very popular apps are
limited by the number of users U . We found that the results from ana-
lytical evaluation, based on Equation 6.1, are very close to the simulation
results for the same parameters, so in the next section we present only the
simulation-based results.
6.2 Simulation-based Model Validation
To evaluate our model and understand the impact of clustering e(cid:11)ect in
the app downloads distribution, we developed three Monte-Carlo simulators
of an appstore, using ZIPF, ZIPF-at-most-once, and APP-CLUSTERING
models. In the ZIPF simulator we set the number of users U equal to the
number of total downloads D, which results to D independent random app
selections. In the ZIPF-at-most-once simulator we set the number of users
to a proper value, and each user randomly selects d apps for downloading.
However, the same app can not be selected more than once by the same
user. For both ZIPF and ZIPF-at-most-once simulators we group all apps
in a single cluster, and thus all app selections are made based on a pure ZIPF
distribution with the zr exponent. In the APP-CLUSTERING simulator we
randomly group the A apps to C clusters, and each user downloads d apps
based on the simulation parameters zr, p and zc.
Then we ran these simulators for all appstores in our dataset while vary-
ing their key parameters, in order to approximate the observed distribution
of app downloads as close as possible. To measure how close each simulation
approaches the actual downloads distribution of A apps we calculate the dis-
tance between the observed and simulated downloads of each app using the
mean relative error:
AX
distance =
1
A
jDo(i) (cid:0) Ds(i)j
i=1
Do(i)
(6.2)
where Do(i) and Ds(i) are the observed and simulated downloads respec-
tively for the app with overall rank i.
46
CHAPTER 6. A MODEL OF APPSTORE WORKLOADS
6.3 Choosing the Right Number of Users
In our (cid:12)rst set of simulations we would like to explore how the number of
users U in(cid:13)uences the simulation results. Unfortunately, since we do not
have access to the logs of the appstores we do not know the actual number
of users who have accessed each appstore. We know the total number of
downloads, the total number of apps, but we do not know the total num-
ber of users. Nevertheless, we will conduct simulations in order to explore
whether there is a reasonable range for the number of users in the appstores
studied that results to very close approximations of the actual downloads
distribution per app. Given that di(cid:11)erent appstores have a di(cid:11)erent actual
number of users, we express the number of users as a function of the total
number of downloads of the most popular app.
Figure 6.1: E(cid:11)ect of the number of users on the accuracy of the simulation.
We see that we have the minimum distance from the actual downloads when
the number of users is close to the downloads of the most popular app.
Figure 6.1 shows our simulation results using the APP-CLUSTERING
model while varying the number of users U and setting the rest simulation
parameters to the values that produce the minimum distance from the actual
results for each dataset. The x-axis is the number of users simulated, as a
ratio of the total number of downloads of the most popular app, and the
y-axis reports the distance between the simulation results and the measured
downloads, using the mean relative error as shown in equation 6.2. We plot
the simulation results for the app downloads of the (cid:12)rst and last day of
the AppChina, Anzhi, and 1Mobile appstores. We see that in all cases the
 0 0.5 1 1.5 2 2.5 3 3.5 40.10.250.5125102050Distance from measured dataNumber of users (as a fraction of the downloads of the most popular app)AppChina 2012-03-30AppChina 2012-06-03Anzhi 2012-06-04Anzhi 2012-08-031Mobile 2012-05-151Mobile 2012-08-016.4. COMPARING MODELED AND ACTUAL DOWNLOADS
47
minimum distance from the measured data is achieved when the number of
users is very close to the number of downloads of the most popular app.
Thus, in the subsequent simulations we set the number of users equal to the
downloads of the most popular app for each simulated dataset, which seems
like a good approximation of the actual number of users.
6.4 Comparing Modeled and Actual Downloads
In this section, we compare the simulation results of APP-CLUSTERING,
ZIPF and ZIPF-at-most-once models with the measured downloads as a
function of app ranking, for the (cid:12)rst and last day of our crawling period in
AppChina, Anzhi and 1Mobile. The results of AppChina are summarized
in Figure 6.2, while the results of Anzhi and 1Mobile are illustrated in Fig-
ure 6.3 and Figure 6.4 respectively. We plot the results of each model using
the parameters that produced the minimum distance from actual results. We
see that a pure ZIPF distribution clearly deviates from the measured data.
For example, for small x (i.e., popular apps) it overshoots the measured
data by more than an order of magnitude. ZIPF-at-most-once (cid:12)ts the data
better but deviates from the actual data mainly for large x values. On the
other hand, APP-CLUSTERING matches the data very close, better than
any other model, both for large x and for small x values (i.e., least popular
apps). Indeed, we see that APP-CLUSTERING has the smallest distance
from the measured data for all appstores. For instance, in the AppChina
dataset of the (cid:12)rst day (Figure 6.2(a)), APP-CLUSTERING predictions
result to distance 0:15 from the actual downloads, that is a factor or 4:7
improvement over ZIPF-at-most-once and a factor of 5:1 improvement over
ZIPF. Similar results are seen for the simulations of the other appstores as
well.
Dataset
ZIPF
ZIPF-at-most-once
APP-CLUSTERING
Distance from Measured
AppChina 2012-03-30
AppChina 2012-06-03
Anzhi 2012-06-04
Anzhi 2012-08-03
1Mobile 2012-05-15
1Mobile 2012-08-01
0.77
0.79
0.36
0.30
0.49
0.74
0.71
0.70
0.32
0.19
0.49
0.72
0.15
0.18
0.05
0.07
0.16
0.28
Table 6.2: Distances of the di(cid:11)erent models from Measured data.
Moreover, we observe that our APP-CLUSTERING model is able to ap-
proximate the actual results of an appstore very well from the (cid:12)rst day up
to the last day of our measurement period. We see that the best approxi-
48
CHAPTER 6. A MODEL OF APPSTORE WORKLOADS
mations of the actual data are achieved when the percentage of simulated
downloads based on clustering is 90% and 95%. This outcome shows the
great extent to which clustering actually a(cid:11)ects the app downloads distribu-
tion. Moreover, the distance of each model from the measured data shows
that APP-CLUSTERING is able to approximate the actual downloads up
to 7.2 times closer than ZIPF and up to 6.4 times closer than ZIPF-at-most-
once. An overview of distances of the di(cid:11)erent models from the actual data
is presented in Table 6.2, as well as in Figure 6.5.
6.4. COMPARING MODELED AND ACTUAL DOWNLOADS
49
(a) AppChina 2012-03-30
(b) AppChina 2012-06-03
Figure 6.2: Predicted versus measured app popularity of AppChina app-
store for two di(cid:11)erent days.
We see that APP-CLUSTERING (cid:12)ts very close the measured data. ZIPF-at-most-