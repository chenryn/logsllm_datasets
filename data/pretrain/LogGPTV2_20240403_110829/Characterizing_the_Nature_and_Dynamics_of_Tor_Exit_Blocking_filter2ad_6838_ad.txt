Figure 7a shows the distribution of discrimination (for
any interaction) faced by relays from websites in the
Alexa Top 500. We ﬁnd that no relay experiences dis-
crimination by more than 32.6% of the 500 websites,
but 50% of the exit relays are discriminated against by
more than 27.4% of the 500 websites. Figure 7b shows
the distribution of discrimination performed by websites
against Tor exit relays. Here, we see that 51% of the
websites perform discrimination against fewer than 5%
of our studied exits, while 11% of websites perform dis-
crimination against over 70% of our studied exits.
We now examine various factors associated with Tor
discrimination. Since we did not (and in many cases can-
not) randomly assign these factors to websites or relays,
these associations might not be causal.
Hosting Provider. Figure 8 shows the fraction of relays
discriminated against by websites hosted on four of the
six most-used hosting platforms. We ﬁnd that Amazon-
and Akamai-hosted websites show the most diversity
in discrimination policy, which we take as indicative
of websites deploying their own individual policies and
blacklists. In contrast, CloudFlare has several clusters of
websites, each employing a similar blacklisting policy.
This pattern is consistent with CloudFlare’s move to al-
low individual website administrators to choose from one
of several blocking policies for Tor exit relays [1]. Fi-
nally, we see 80% of China169- and CloudFlare-hosted
websites perform discrimination against at least 60% of
our studied relays.
Relay Characteristics. Our analysis of the association
(a) Distribution of discrimination faced by relays.
(b) Distribution of discrimination performed by websites.
Figure 7: Distribution of discrimination by Alexa Top
500 websites against 110 exit relays.
Figure 8: Distribution of discrimination performed by
websites hosted on four of the six most popular hosting
platforms.
between exit-relay characteristics and the discrimination
faced by them found no signiﬁcant correlations when ac-
counting for relay-openness (fraction of ports for which
the exit relay will service requests) or for the age of the
relay. We found a small positive correlation (Pearson
correlation coefﬁcient: 0.147) between the relay band-
width and degree of discrimination faced, but the result
was not statistically signiﬁcant (p-value: 0.152). Fig-
ure 9 presents these results graphically. We further ana-
lyze the impact of relay characteristics on discrimination
performed by websites using popular hosting providers .
We ﬁnd that only Amazon has a statistically signiﬁcant
positive correlation between discrimination observed and
relay bandwidth (Pearson correlation coefﬁcient: 0.247,
p-value: 0.015). These results are illustrated in Fig-
ure 10.
Service Category. We now analyze how aggressively
USENIX Association
26th USENIX Security Symposium    335
0.00.20.40.60.81.0Fraction of sites discriminating against relay0.00.20.40.60.81.0CDF of relays0.00.20.40.60.81.0Fraction of relays discriminated against by site0.00.20.40.60.81.0CDF of sites0.00.20.40.60.81.0Fraction of relays discriminated against by site0.00.20.40.60.81.0CDF of sitesAkamaiAmazonChina169CloudFlareFigure 9: Relationship between relay characteristics and
discrimination faced. Each circle represents a single re-
lay. Lighter colors indicate younger relays and larger
circles indicate more open exit policies. The legend
shows the Pearson correlation co-efﬁcient (PCC) and the
p-value for each characteristic.
Figure 11: Distribution of discrimination performed by
websites in various categories.
Day -1 crawl utilized the crawler from Khattak et al.; see
below), although we note that the IP addresses used by
our exit relays were never used by other Tor exit relays
in the past, and did not appear in any of our studied com-
mercial blacklists before Day 0, while they immediately
manifested after setting the exit ﬂags.
Figure 10: Impact of relay characteristics on discrimina-
tion performed by websites hosted by Amazon.
four different categories of sites—search engines, shop-
ping, news, and social networking—discriminate against
Tor exit relays. We categorize sites using the McAfee
URL categorization service [34]. We ﬁnd that search
engines are the least likely to discriminate against exit
relays, with 83% of all search engines discriminating
against fewer than 20% of our studied exit relays, com-
pared to 30% of social networking sites, 32% of shop-
ping sites, and 53% of news sites. We also ﬁnd social net-
working and online shopping sites share similar blocking
behavior. Websites in these categories are also observed
to be the most aggressive—with 50% of them blocking
over 60% of the chosen relays. Figure 11 illustrates the
results.
The Evolution of Tor Discrimination. We now fo-
cus on discrimination changes over time. For this ex-
periment, we conducted four crawls via our own ten exit
relays to the Alexa Top 500 websites. Let Day 0 denote
the day when we set the relay’s exit ﬂag. We conducted
crawls on Day -1, Day 0, and once a week thereafter.
Table 7 shows the fraction of websites found to to dis-
criminate against each exit set during each crawl. We
observe increases in discrimination when the exit ﬂag is
assigned. We can attribute some of this can to our im-
proved crawling methodology deployed on Day 0 (the
Conﬁguration
Large-Default
Medium-Default
Medium-RR
Small-Default
Small-RR
Day -1 Day 0 Wk. 2 Wk. 3 Wk. 4
25.4
24.8
24.7
23.6
25.3
21.1
25.6
22.7
23.9
25.7
NA
9.4
9.9
9.3
9.4
17.0
20.5
18.3
20.3
20.5
19.0
24.4
24.1
20.9
20.7
Table 7: Percentage of discriminating page loads for each
set of deployed relays.
The high amount of discrimination observed on our
Day-0 crawl for all exit relays is indicative of proactive
discrimination against Tor exit relays. Our results do not
indicate differences due to relay cateogry in the amount
of discrimination experienced.
Figure 12: Impact of methodological changes on mea-
sured discrimination from data generated by a single
front-page crawl.
Measurement Methodology. We now measure the
impact of changes in our discrimination identiﬁcation
methodology compared to previous work by Khattak et
al. [2]. The key differences between the methodologies
are: (1) The measurements conducted by Khattak et al.
336    26th USENIX Security Symposium
USENIX Association
102103104105Bandwidth (KBps)0.00.10.20.30.40.5Fraction of discriminating sitesBandwidth PCC: 0.15, p-value: 0.15Openness PCC: 0.04, p-value: 0.72Age PCC: -0.07, p-value: 0.51102103104105Bandwidth (KBps)0.00.10.20.30.40.5Fraction of Amazondiscriminating sitesBandwidth PCC: 0.25, p-value: 0.02Openness PCC: 0.02, p-value: 0.82Age PCC: 0.01, p-value: 0.930.00.20.40.60.81.0Fraction of relays discriminated against by site0.00.20.40.60.81.0CDF of sitesNewsSearchShoppingSocialNetworking0.00.20.40.60.81.0Fraction of relays discriminated against by site0.00.20.40.60.81.0CDF of sitesOur crawlKhattak et alare limited to identifying front-page discrimination. Our
crawler also tests search and login interactions. Table
6 presents the impact of this feature. (2) Khattak et al.
identify discrimination using the difference in HTTP sta-
tus codes returned by the control and test nodes. This
method is prone to underestimating discrimination due
to the inability to detect block pages that return a HTTP
200 OK status code. Our method relies on screenshot
differences and HTTP status codes as a signal for dis-
crimination. As a result, we are able to detect discrim-
ination performed by sites such as livejournal.com,
hdfc.com, and glassdoor.com. (3) Khattak et al. rely
on sending HTTP requests for front pages of websites
using the python urllib2 library. Although they mod-
ify the user agent of their crawler to match a regular web
browser, they are easily identiﬁable as an irregular user
since they do not load third-party objects and JavaScript.
Such crawlers are blocked by many websites and bot-
mitigation tools [35]. In contrast, we perform complete
page loads, including third-party content and execution
of JavaScript. As a consequence, our crawls are slower,
requiring around 12 hours for 500 page loads (compared
to 1–2 minutes required by the urllib2 crawler).
To understand the impact of (2) and (3), we compare
the discrimination results obtained from a single front-
page crawl performed by both crawlers. We started both
crawls on the same day, on the same set of websites, us-
ing the same set of 100 randomly sampled exit relays.
The results, illustrated in Figure 12, conﬁrm that previ-
ous work underestimates the amount of discrimination.
7 Privacy-sensitive Exit Logging
While our crawls systematically explore popular web-
sites, they might not be typical of actual Tor usage. Thus,
we performed privacy-sensitive logging on our deployed
exit relays to measure how commonly users interacting
with Alexa Top 1M web pages experienced failed TLS
handshakes or HTTP requests This observational dataset,
based on actual Tor-user web trafﬁc distributions and
user interactions, provides us with a picture of the dis-
crimination actually encountered by users.
7.1 Logging Approach
In order to measure the number of failed TLS handshakes
and HTTP requests, we developed a custom logger. Al-
though tools such as PrivEx [36], Historε [37], and Priv-
Count [38] were speciﬁcally built for measuring charac-
teristics of Tor exit trafﬁc, they are not suitable for our
study for two reasons: First, they currently do not have
the capability to inspect HTTP and TLS trafﬁc head-
ers. Adding such functionality to the tools requires mod-
ifying the Tor relay source code—possibly introducing
users of our relays to new vulnerabilities. Second, they
were built with the goal of performing secure data ag-
gregation across multiple relays. Since a single entity
owned and operated all of the relays used in our study,
this feature was unnecessary for our purposes.
We maintain counters for several events of interest
associated with users browsing websites in the Alexa
Top 1M. Our approach, designed after consultation with
members of the Tor developer community, takes precau-
tions to avoid de-anonymization of users. Since neither
the Tor users nor the service operators were the subjects
of our study, we were exempt from an IRB review.
First, we use bucketing and split the Alexa Top 1M
websites into exponentially growing sets based on their
Alexa ranks, as follows: The ﬁrst set contains the top
100 websites (ranked 1–100) and the nth set for n > 1
contains the top 100× 2n−2 + 1 to 100× 2n−1 websites.
We keep a separate event counter for each set. Second,
we maintain our event counters in memory and write to
disk only once a day. Doing so allows our event counters
to attain higher count values, increasing anonymity-set
sizes. Third, to deal with the possibility of encountering
cases where 24 hours does not sufﬁce to achieve reason-
ably high anonymity-set sizes—e.g., if only one person
visited a site during a 24 hour period—we round up each
event counter to the nearest multiple of eight before writ-
ing to disk. A similar approach is used by Tor metrics [3]
for reporting counts of bridge users per country.
We maintained per-bucket event counters for the num-
ber of: (1) HTTP requests to website front pages, (2)
error status codes observed in their corresponding re-
sponses, (3) HTTP(S) handshakes initiated, and (4)
timed-out handshakes encountered. Additionally, we
also maintained a counter for the number of packets sent
through each open port.
7.2 Results
Table 8 shows the percentage of failed HTTP requests
and incomplete HTTPS handshakes encountered by
users of our exit relays. We ﬁnd that the fraction of in-
complete handshakes steadily increases over time. We
attribute the steep increase in HTTP error codes received
during weeks four and ﬁve to our relays being (ab)used
in a scraping attempt on a popular website (we received
a complaint notice due to this behavior). Besides this
sudden increase, we see that the fraction of HTTP errors
accords with data observed through our crawls, but the
fraction of incomplete HTTPS handshakes runs higher.
This is likely because incomplete handshakes provide
only very noisy indicators for user discrimination, with
many reasons for them to occur naturally.
HTTP requests and error response codes.
exiting packets using the HTTP protocol, iff
For
the URI
USENIX Association
26th USENIX Security Symposium    337
Week
HTTP
HTTPS
1
15.8
36.3
2
18.1
35.0
3
19.8
41.1
4
32.8
45.2
5
33.4
47.9
6
17.9
49.6
Table 8: The percentage of failed HTTP requests and
incomplete HTTPS handshakes observed over time.
on the HTTP request was identical (ignoring case) to
a Top 1M website, we incremented a front-page re-
quest event counter associated with the set containing the
site. For every matching request, we maintained state
to identify the corresponding response packet.
If the
corresponding response packet contained an error status
code (4XX/5XX), we incremented an error-status event
counter associated with the corresponding set. We break
down the fraction of errors by website ranks and time in
Figure 13a. We see that the fraction of error response
codes is nearly evenly distributed across each set, indi-
cating that errors are independent of website ranks.
HTTPS handshake initiation and failure. The pro-
cedure for HTTPS is similar to that for HTTP. However,
we use the SNI value of client-hello handshake initiation
packets instead of the URI of HTTP requests. Further-
more, we look for handshake failures and timed-outs in-
stead of HTTP errors. The results in Figure 13b show a
strong increasing trend in incompletion rates over time.
8 Discussion and Future Work
Limitations. Our studies each come with their own
limitations, some resulting from our desire to protect the
privacy of Tor users, others from the limited data sets
available for study. Neither our set of emails nor our set
of blacklists are complete. Given that Tor assigns traf-
ﬁc to exits in a mostly random fashion, we believe the
emails from our sample to be representative of the com-
plaints during their time periods for exits with similar
exit policies. While there are blacklists that we were not
able to observe during the period of our study, the set of
blacklists used in our analysis includes numerous types
from a wide range of suppliers, leading us believe that
they capture all common blacklisting phenomena. Our
crawls, while more in-depth than prior efforts [2], were
too time-consuming to run often enough to gain statisti-
cal guarantees about discrimination by any one website.
Nevertheless, taken together, they show that discrimina-
tion is common and sometimes subtle.
Implications for Tor. The large amounts of block-
ing and discrimination identiﬁed by our crawling and
privacy-sensitive measurements suggest that Tor’s utility
is threatened by online service providers opting to stiﬂe
Tor users’ access to their services (§6 & §7).
From studying blacklists we learned that some, but
not all, proactively add Tor exit IP addresses (§5), pre-
sumably in response to prior undesired trafﬁc and an ex-
pectation of more. This result highlights that Tor users
fate-share with not just the Tor users sharing their cur-
rent exit relay, but all Tor users—present and past. Other
blacklisting appears to be reacting to undesired trafﬁc,
suggesting that blocking may decrease if Tor can reduce
the amount of abuse it emits. Such a reduction may