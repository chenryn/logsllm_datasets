to the noisy labels. In this case, the GNN becomes a predictor for
y′ rather than y, yielding a small forward correction loss. This is
an incorrect validation signal as it favors 𝐾𝑦 to be close to zero.
To overcome this issue and detect overfitting to label noise, our
approach is to look instead at the accuracy of the target classifier
𝑓 (x) = arg maxy ˆ𝑝(y | x) for predicting the noisy labels y′. From
the randomized response algorithm, we know that the probability
of keeping the label is
𝑒𝜖+𝑐−1. This gives us an upper bound on
the expected accuracy of a perfect classifier, i.e., the classifier with
100% accuracy on predicting clean labels. In other words, a per-
fect classifier can predict y′ with an expected accuracy of at most
𝐴𝑐𝑐∗ =
𝑒𝜖+𝑐−1. Therefore, if during training the model we get accu-
racy above 𝐴𝑐𝑐∗, either on the training or validation dataset, we can
consider it a signal of overfitting to the noisy labels. More specif-
ically, we train the GNN for a maximum of 𝑇 epochs and record
the forward correction loss and the accuracy of the target classifier
for predicting noisy labels over both training and validation sets at
every epoch. At the end of training, we pick the model achieving
𝑒𝜖
𝑒𝜖
Algorithm 3: Locally Private GNN Training with Drop
:Graph G = (VL ∪ VU, E); GNN model 𝑔(x, G; W);
Input
KProp layer ℎ(x, G; 𝐾); KProp step parameter for features
𝐾𝑥 ≥ 0; KProp step parameter for labels 𝐾𝑦 ≥ 0; privacy
budget for feature perturbation 𝜖𝑥 > 0; privacy budget for
label perturbation 𝜖𝑦 > 0; range parameters 𝛼 and 𝛽;
number of classes 𝑐; maximum number of epochs 𝑇 ;
learning rate 𝜂;
Output:Trained GNN weights W
1 Server-side:
2 V ← VL ∪ VU
3 Send 𝜖𝑥 , 𝜖𝑦, 𝛼, and 𝛽 to every node 𝑣 ∈ V.
4 Node-side:
5 Obtain a perturbed vector x∗ by Algorithm 1.
6 if current node is in VL then
Obtain a perturbed label y′ by (11).
y′ ← (cid:174)0
𝑣 using (4) for all 𝑣 ∈ V.
𝑣, G; 𝐾𝑥) for all 𝑣 ∈ V.
𝑣, G; 𝐾𝑦) for all 𝑣 ∈ VL.
7
8 else
9
10 end
11 Send (x∗, y′) to the server.
12 Server-side:
13 Obtain x′
14 h𝑣 ← ℎ(x′
15 ˜y𝑣 ← ℎ(y′
16 Partition VL into train and validation sets VL𝑡𝑟 and VL 𝑣𝑎𝑙 .
17 𝐴𝑐𝑐∗ ← 𝑒𝜖𝑦/(𝑒𝜖𝑦 + 𝑐 − 1)
18 for 𝑡 ∈ {1, . . . ,𝑇 } do
19
20
21
22
23
24
for all 𝑣 ∈ VL do in parallel
ˆ𝑝(y | x𝑣) ← 𝑔(h𝑣, G; W)
Obtain ˆ𝑝(y′ | x𝑣) using (13)
Obtain ˆ𝑝( ˜y | x𝑣) using (14)
W𝑡+1 ← W𝑡 − 𝜂∇𝑣∈VL 𝑡𝑟 ℓ ( ˜y𝑣, ˆ𝑝( ˜y | x𝑣))
𝑣∈VL 𝑣𝑎𝑙 ℓ(cid:0)y′
𝑣𝑎𝑙 ←

|VL 𝑡𝑟 |𝑣∈VL 𝑡𝑟 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦( ˆ𝑝(y | x𝑣), y′
𝑣∈VL 𝑣𝑎𝑙 𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦( ˆ𝑝(y | x𝑣), y′
𝑣)
𝑣)
𝑣, ˆ𝑝(y′ | x𝑣)(cid:1)
𝑣𝑎𝑙 ← 1
𝑡𝑟 ← 1
ℓ𝑡
𝐴𝑐𝑐𝑡
|VL 𝑣𝑎𝑙 |
end
25
26
𝐴𝑐𝑐𝑡
27
28 end
29 𝑡 ← arg min𝑡 ℓ𝑡
30 return W𝑡
𝑣𝑎𝑙
such that 𝐴𝑐𝑐𝑡
𝑡𝑟 ≤ 𝐴𝑐𝑐∗ and 𝐴𝑐𝑐𝑡
𝑣𝑎𝑙 ≤ 𝐴𝑐𝑐∗
the lowest forward correction loss such that their accuracy is at
most 𝐴𝑐𝑐∗.
Putting all together, the pseudo-code of the LPGNN training
algorithm with Drop is presented in Algorithm 3, where we use
two different privacy budgets 𝜖𝑥 and 𝜖𝑦 for feature and label per-
turbation, respectively. The following corollary entails from our
algorithm:
Corollary 3.7. Algorithm 3 satisfies (𝜖𝑥 + 𝜖𝑦)-local differential
privacy for graph nodes.
Corollary 3.7 shows that the entire training procedure is LDP
due to the robustness of differential privacy to post-processing [15].
Furthermore, any prediction performed by the LPGNN is again
subject to the post-processing theorem [15], and therefore, satisfies
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2136Table 1: Descriptive statistics of the used datasets
Dataset
Classes Nodes
Edges
Features Avg. Degree
Cora
Pubmed
Facebook
LastFM
7
3
4
10
2,708
19,717
22,470
7,083
5,278
44,324
170,912
25,814
1,433
500
4,714
7,842
3.90
4.50
15.21
7.29
LDP for the nodes, as the LDP mechanism is applied to the private
data only once.
4 EXPERIMENTS
We conduct extensive experiments to assess the privacy-utility
performance of the proposed method for the node classification
task and evaluate it under different parameter settings that can
affect its effectiveness.
4.1 Experimental settings
Datasets. We used two different sets of publicly available real-
world datasets: two citation networks, Cora and Pubmed [61], which
have a lower average degree, and two social networks, Facebook
[42], and LastFM [43] that have a higher average degree. The de-
scription of the datasets is as followed:
• Cora and Pubmed [61]: These are well-known citation network
datasets, where each node represents a document and edges
denote citation links. Each node has a bag-of-words feature vector
and a label indicating its category.
• Facebook [42]: This dataset is a page-page graph of verified Face-
book sites. Nodes are official Facebook pages, and edges corre-
spond to mutual likes between them. Node features are extracted
from the site descriptions, and the labels denote site category.
• LastFM [43]: This social network is collected from the music
streaming service LastFM. Nodes denote users from Asian coun-
tries, and links correspond to friendships. The task is to predict
the home country of a user given the artists liked by them. Since
the original dataset was highly imbalanced, we limited the classes
to the top-10 having the most samples.
Summary statistics of the datasets are provided in Table 1.
Experiment setup. For all the datasets, we randomly split nodes
into training, validation, and test sets with 50/25/25% ratios, respec-
tively. Without loss of generality, we normalized the node features
of all the datasets between zero and one1, so in all cases, we have
𝛼 = 0 and 𝛽 = 1. LDP feature perturbation is applied to the fea-
tures of all the training, validation, and test sets. However, label
perturbation is only applied to the training and validation sets, and
the test set’s labels are left clean for performance testing. We tried
three state-of-the-art GNN architectures, namely GCN [26], GAT
[47], and GraphSAGE [18], as the backbone model for LPGNN, with
GraphSAGE being the default model for ablation studies. All the
GNN models have two graph convolution layers with a hidden
1Note that this normalization step does not affect the privacy, as the range parameters
(𝛼, 𝛽) are known to both the server and users, so the server could ask users to
normalize their data between 0 and 1 before applying the multi-bit encoder.
dimension of size 16 and the SeLU activation function [27] followed
by dropout, and the GAT model has four attention heads. For both
feature and label KProps, we use GCN aggregator function. We opti-
mized the hyper-parameters of LPGNN based on the validation loss
of GraphSAGE using the Drop algorithm as described in Section 3
with the following strategy, and used the same values for other GNN
models: First, we fix 𝐾𝑥 and 𝐾𝑦 to (16, 8), (16, 2), (4, 2), and (8, 2),
on Cora, Pubmed, Facebook, and LastFM, respectively, and for every
pair of privacy budgets (𝜖𝑥, 𝜖𝑦) in (1, 1), (1,∞), (∞, 1), and (∞,∞),
we perform a grid search to find the best choices for initial learning
rate and weight decay both from {10−4, 10−3, 10−2} and dropout
rate from {10−4, 10−3, 10−2}. Second, we fix the best found hyper-
parameters in the previous step and search for the best performing
KProp step parameters 𝐾𝑥 and 𝐾𝑦 both within {0, 2, 4, 8, 16} for
all 𝜖𝑥 ∈ {0.01, 0.1, 1, 2, 3,∞} and 𝜖𝑦 ∈ {0.5, 1, 2, 3,∞}. More specifi-
cally, for every 𝜖𝑥 (resp. 𝜖𝑦) except ∞, we use the best learning rate,
weight decay, and dropout rate found for 𝜖𝑥 = 1 in the previous
step (resp. 𝜖𝑦 = 1) to search for the best KProp step parameters.
All the models are trained using the Adam optimizer [25] over a
maximum of 500 epochs, and the best model is picked for testing
based on the validation loss. We measured the accuracy on the test
set over 10 consecutive runs and report the average and 95% confi-
dence interval calculated by bootstrapping with 1000 samples. Our
implementation is available at https://github.com/sisaman/LPGNN.
4.2 Experimental results
Analyzing the utility-privacy trade-off. We first evaluate
how our privacy-preserving LPGNN method performs under vary-
ing feature and label privacy budgets. We changed the feature
privacy budget 𝜖𝑥 in {0.01, 0.1, 1, 2, 3,∞} and the label privacy bud-
get within {1, 2, 3,∞}. The cases where 𝜖𝑥 = ∞ or 𝜖𝑦 = ∞, are
provided for comparison with non-private baselines, where we did
not apply the corresponding LDP mechanism (multi-bit for fea-
tures and randomized response for labels) and directly used the
clean (non-perturbed) values. We performed this experiment using
GCN, GAT, and GraphSAGE as different backbone GNN models and
reported the node-classification accuracy, as illustrated in Figure 3.
We can observe that all the three GNN models demonstrate
robustness to the perturbations, especially on features, and per-
form comparably to the non-private baselines. For instance, on the
Cora dataset, both GCN and GraphSAGE could get an accuracy of
about 80% at 𝜖𝑥 = 0.1 and 𝜖𝑦 = 2, which is only 6% lower than the
non-private (𝜖 = ∞) method. On the other three datasets, we can
decrease 𝜖𝑥 to 0.01 and 𝜖𝑦 to 1, and still get less than 10% accuracy
loss compared to the non-private baseline. We believe that this is a
very promising result, especially for a locally private model perturb-
ing hundreds of features with a low privacy loss. This result shows
that different components of LPGNN, from multi-bit mechanism to
KProp, and the Drop algorithm are fitting well together.
According to the results, the GAT model slightly falls behind
GCN and GraphSAGE in terms of accuracy-privacy trade-off, espe-
cially at high-privacy regimes 𝜖𝑥 ≤ 1, which is mainly due to its
stronger dependence on the node features. Unlike the other two
models, GAT uses node features at each layer to learn attention
coefficients first, which are then used to weight different neighbors
in the neighborhood aggregation. This property of GAT justifies its
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2137N
C
G
T
A
G
)
%
(
y
c
a
r
u
c
c
A
)
%
(
y
c
a
r
u
c
c
A
E
G
A
S
h
p
a
r
G
)
%
(
y
c
a
r
u
c
c
A
100
80
60
40
20
0
100
80
60
40
20
0
100
80
60
40
20
0
)
%
(
y
c
a
r
u
c
c
A
)
%
(
y
c
a
r
u
c
c
A
N
C
G
𝜖𝑦 = 1
𝜖𝑦 = 2
𝜖𝑦 = 3
𝜖𝑦 = ∞
0.01 0.1 1.0 2.0 3.0 ∞
𝜖𝑥
T
A
G
𝜖𝑦 = 1
𝜖𝑦 = 2
𝜖𝑦 = 3
𝜖𝑦 = ∞
0.01 0.1 1.0 2.0 3.0 ∞
𝜖𝑥
E
G
A
S
h
p
a
r
G
)
%
(
y
c
a
r
u
c