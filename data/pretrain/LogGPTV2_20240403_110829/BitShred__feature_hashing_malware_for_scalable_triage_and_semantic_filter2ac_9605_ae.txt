internet malware. In Proceedings of the Symposium on
Recent Advances in Intrusion Detection, September 2007.
[13] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and
E. Kirda. Scalable, behavior-based malware clustering. In
Proceedings of the Network and Distributed System Security
Symposium, 2009.
[14] D. Bernstein.
http://www.cse.yorku.ca/~oz/hash.html.
[15] A. Broder and M. Mitzenmacher. Network applications of
bloom ﬁlters: A survey. Internet Mathematics,
1(4):485–509, 2005.
[16] D. Chakrabarti, S. Papadimitriou, D. Modha, and
C. Faloutsous. Fully automatic cross associations. In
Proceedings of ACM SIGKDD, August 2004.
[17] J. Dean and S. Ghemawat. MapReduce: Simpliﬁed data
processing on large clusters. In Proceedings of the USENIX
Symposium on Operating System Design and
Implementation, 2004.
[18] A. Dinaburg, P. Royal, M. Sharif, and W. Lee. Ether:
malware analysis via hardware virtualization extensions. In
ACM CCS, 2008.
[19] D. Eppstein. Fast hierarchical clustering and other
applications of dynamic closest pairs. In Proceedings of
ACM Symposium on Discrete Algorithms (SODA), 1998.
[20] F. Guo, P. Ferrie, and T.-C. Chiueh. A study of the packer
problem and its solutions. In Proceedings of the
International Symposium on Recent Advances in Intrusion
Detection, pages 98–115, 2008.
[21] X. Hu, T. cker Chiueh, and K. G. Shin. Large-scale malware
indexing using function call graphs. In Proceedings of the
ACM Conference on Computer and Communications
Security, 2009.
[22] N. Jain, M. Dahlin, and R. Tewari. Using bloom ﬁlters to
reﬁne web search results. In Proceedings of Eighth
International Workshop on the Web and Databases (WebDB
2005), June 2005.
[23] M. Karim, A. Walenstein, A. Lakhotia, and L. Parida.
Malware phylogeny generation using permutations of code.
Journal in Computer Virology, 1(1):13–23, November 2005.
[24] G. Karypis. CLUTO: a clustering toolkit, release 2.1.1.
Technical report, University of Minnesota, 2003.
[25] J. Z. Kolter and M. A. Maloof. Learning to detect and
classify malicious executables in the wild. Journal of
Machine Learning Research, 7:2721–2744, Dec. 2006.
[26] P. Li, L. Lu, D. Gao, and M. Reiter. On challenges in
evaluating malware clustering. In Proceedings of the
International Symposium on Recent Advances in Intrusion
Detection, 2010.
[27] L. Martignoni, M. Christodorescu, and S. Jha. OmniUnpack:
Fast, generic, and safe unpacking of malware. In In
Proceedings of the Annual Computer Security Applications
Conference, 2007.
[28] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple
execution paths for malware analysis. In Proceedings of the
IEEE Symposium on Security and Privacy, 2007.
[29] A. Moser, C. Kruegel, and E. Kirda. Limits of static analysis
for malware detection. In Proceedings of the Annual
Computer Security Applications Conference, 2007.
[30] S. Papadimitrou and J. Sun. Disco: Distributed co-clustering
with map-reduce. In Proceedings of ICDM, 2008.
[31] R. Perdisci, A. Lanzi, and W. Lee. Classiﬁcation of packed
executables for accurate computer virus detection. Pattern
Recogn. Lett., 29(14):1941–1946, 2008.
[32] R. Perdisci, W. Lee, and N. Feamster. Behavioral clustering
of HTTP-based malware and signature generation using
malicious network traces. In Proceedings of NSDI, 2010.
[33] P. Royal, M. Halpin, D. Dagon, R. Edmonds, and W. Lee.
PolyUnpack: Automating the hidden-code extraction of
unpack-executing malware. In Proceedings of Computer
Security Applications Conference, December 2006.
[34] S. Schleimer, D. Wilkerson, and A. Aiken. Winnowing:
Local algorithms for document ﬁngerprinting. In
Proceedings of the ACM SIGMOD/PODS Conference, 2003.
319[35] M. Sharif, A. Lanzi, J. Gifﬁn, and W. Lee. Automatic reverse
engineering of malware emulators. In Proceedings of the
IEEE Symposium on Security and Privacy, 2009.
[36] Q. Shi, J. Petterson, G. Dror, J. Langford, A. Smola, and
S. Vishwanathan. Hash kernels for structured data. Journal
of Machine Learning Research, 2009.
[37] Q. Shi, J. Petterson, G. Dror, J. Langford, A. Smole,
A. Strehl, and V. Vishwanathan. Hash kernels. In
Proceedings of the 12th International Conference on
Artiﬁcial Intelligence and Statisics (AISTATS), 2009.
[38] A. Walenstein and A. Lakhotia. The software similarity
problem in malware analysis. In Duplication, Redundancy,
and Similarity in Software, 2007.
[39] K. Weinberger, A. Dasgupta, J. Langford, A. Smola, and
J. Attenberg. Feature hashing for large-scale multitask
learning. In Proceedings of ICML, 2009.
c
S(fi∨fj ) is close to
APPENDIX
A. PROOF OF THEOREM 1
Our analysis shows that with high probability, the Jaccard index
|gi∩gj|
|gi∪gj| is well approximated by the S(fi∧fj )
S(fi∨fj ) , where fi and fj are
the ﬁngerprints of gi and gj. Throughout this analysis, we let c
denote the number of shared elements between sets gi and gj; note
|gi∩gj|
2N−c . The focus of our anal-
that the Jaccard index
|gi∪gj| is then
ysis is to show that the ratio S(fi∧fj )
2N−c with high
probability (unlike other analyses [22] that restrict their focus to
computing the expected value of S(fi ∧ fj)). We make the usual
assumption that the hash functions used are k-wise independent.
We ﬁrst consider the union gi ∪ gj. We note that the bitvector
obtained by computing the bitwise-or of the two ﬁngerprints fi and
fj is equivalent to the bitvector that would be obtained by directly
inserting all the elements in gi ∪ gj, if the same k hash functions
are used on a bitvector of the same size.
Let the random variable U denote the number of bits set to 1
in fi ∨ fj. Note that the set gi ∪ gj contains 2N − c elements.
If these elements are inserted into a bitvector of size m with k
hash functions, the probability qu that a bit is set to 1 is: 1 −
´k(2N−c). We can use this to compute the expected value
`1 − 1
c
m
of U:
„
1 −
1 − 1
m
«k(2N−c)!
E[U ] = mqu = m
(3)
−22m2/(2N−c)k ≤ 2e
As U is tightly concentrated around its expectation [15], we get:
P r[|U − E[U ]| ≥ m] ≤ 2e
−22m2/N k.
Next, we consider the intersection gi ∩ gj. Let the random vari-
able I denote the number of bits set to 1 in fi ∧ fj. A bit z is set
in fi ∧ fj in one of two ways: (1) it may be set by some element
in gi ∩ gj, or (2) it may be set by some element in gi − (gi ∩ gj)
and by some element gj − (gi ∩ gj). Let Iz denote the indicator
variable for bit z in fi ∧ fj. Then,
1 − 1
m
P r[Iz = 1] =
„
1 −
«k(|gi|−c)!
„
·
«kc 
„
1 − 1
m
1 − 1
m
1 −
+
«kc!
„
«k(|gj|−c)!
1 − 1
m
1 −
which may be simpliﬁed as:
1 −
„
„
„
1 − 1
m
«kN
«k(2N−c)
With linearity of expectation, we can compute E[I] asP
«k(2N−c)!
«kN −
„
«kN
1 − 1
m
1 − 1
m
„
+
.
1], which reduces to:
1 − 2
E[I] = m
1 − 1
m
+
1 − 1
m
z P r[Iz =
.
(4)
m
m
`1 − 1
m
Note that the random variables I1, I2 . . . Im are negatively de-
pendent, and so we can apply Chernoff-Hoeffding bounds to com-
pute the probability that I deviates signiﬁcantly from E[I]: e.g.,
P r[I ≥ E[I](1 + 2) ≤ e−mq2
2/3, where q = 1 −`1 − 1
´kN −
´kN +`1 − 1
´k(2N−c).
We now turn to the ratio S(fi∧fj )
S(fi∨fj ) ; let the random variable Y de-
note this ratio. We have just shown that U and I are both likely to
remain close to their expected values, and we can use this to com-
pute upper and lower bounds on Y – since U and I lie within an
additive or multiplicative factor of their expectations with probabil-
ity at least 1 − 2e−mq2
2/3 and 1 − 2e−22m2/N k respectively, we
can derive upper and lower bounds on Y that hold with probability
at least 1 − 2e−mq2
To do this, we ﬁrst simplify the quantities E[U ] and E[I]. As-
suming that m (cid:29) 2kN, we can approximate E[U ] and E[I] by
discarding the higher-order terms in each of binomials in 3 and 4:
2/3 − 2e−22m2/N k.
E[U ] ≥ m
««
1 − k(2N − c)
«
m
= k(2N − c).
1 −
„
„
„ 2N − c
«
m
1 − kN
m
„
Likewise, we can approximate E[I] as:
= mk
„
“ c
m
”
E[I] ≤ m
1 − 2
= mk
= ck.
„
1 − k(2N − c)
m
+
««
c
2c
c(1+2)
„ c(1− 1√
Using these approximations for E[I] & E[U ], we see that Y ≤
2/3 − 2e−22m2/N k.
2N−c−m , with probability at least 1− e−mq2
We can compute a similar lower bound for Y , i.e., Y ≥ c(1−2)
(2N−c)+m ,
2/2 − 2e−22m2/N k. Thus, this
with probability at least 1 − e−mq2
shows that with high probability, the ratio S(fi∧fj )
S(fi∨fj ) is close to the
Jaccard index
2N−c , for appropriately chosen values of m and k.
We have thus proven our Theorem 1.
Lastly, we give an example to illustrate our bounds in our appli-
cation scenario. Suppose we set m ≥ 5, m ≈ 1000N, k = 6.
Then, our analysis shows us that with probability at least 95%,
Y ∈
, i.e., that ratio of the bits set to the
union is very close to the Jaccard index.
B. EXTENSION
Containment. BITSHRED-JACCARD measures the proportional sim-
ilarity between features. However, we may want to also measure
when one feature set is contained within another, e.g., whether one
malware is completely contained in another code. For example,
suppose malware A is the composition of two malware samples B
and C, and suppose |B| (cid:29) |C|. Then the similarity between A and
C will be proportionally very low. An alternative similarity metric
for this case can be given as:
c(1+ 4√
)
c
2N−c−5
)
2N−c+5 ,
«
S(fa ∧ fb)
,
when fi is the ﬁngerprint for malware si and |sa| (cid:29) |sb|.
BITSHRED-JACCARDc(fa, fb) =
S(fb)
320