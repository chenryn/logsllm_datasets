the other four groups as a training set; and then (iii) evaluate
the perplexity score of each procedure in the test set. We
repeat steps (ii)-(iii) ﬁve times using each of the ﬁve groups
as our test set. Each time, we compute three sets of perplexity
scores using bigram, trigram, and four-gram probabilities.
Finally, we cluster the computed perplexity scores into two
classes, anomalous and benign, using the Jenks natural breaks
optimization technique [31]. Table I summarizes various metric
scores for evaluating each of the three models.3
For anomaly detection, we desire high recall (true positives /
(true positives + false negatives)), because running anomalous
procedures could be disastrous. Our recall across all three
models is 1.0, indicating that all the models correctly classify
the three anomalies. From bigram to trigram, the number of
true negatives increases while the number of false positives
decreases, resulting in the improvement of accuracy, precision,
and F1-score metrics. The performance slightly degrades
3In Table I, weighted accuracy is computed by assigning a higher weight
(2×) to the true positive count over the true negatives count.
TABLE I
Metrics
Accuracy
Weighted accuracy
Precision
F1 score
True positives (negatives)
False positives (negatives)
84%
Bigram Trigram Four-gram
64%
67.85% 85.71%
0.25
0.4
3 (13)
9 (0)
80%
82.14%
0.38
0.54
3 (17)
5 (0)
0.43
0.6
3 (18)
4 (0)
between trigrams and four-grams, suggesting that selecting
an ideal model size is nontrivial.
These experiments show that perplexity scores can be used
to classify unexpected procedure variations (RQ2). However,
our models raise too many false positives. We are guardedly
optimistic that a larger and more varied training dataset will
let us produce models that retain perfect recall, while reducing
the number of false positives.
VI. POWER DATASET ANALYSIS
The previous section suggests that we can likely build an
intrusion detection system by analyzing the communication
stream between the lab computer and the devices. However,
capturing that data requires a RATracer-like infrastructure and
the ability to modify the existing software infrastructure. While
we were able to do this for the Hein Lab, deploying such an
integrated system might not always be feasible. We collected a
power dataset to allow us to answer the question, RQ3, “Can
we use power monitoring to identify the same kinds of patterns
identiﬁed via command tracing to facilitate anomaly detection
in an unobtrusive fashion?”
Side-channel data such as power consumption can be
collected unobtrusively by attaching probes at power outlets or
even on the robot body itself. However, in our prototype, we
use RATracer and UR3e’s real-time monitoring API as a proxy
for such probes. While it is possible for us to gather power
data from a collection of robotic arms, during the course of
our data collection, the UR3e was the only robot arm with a
power monitoring API, so our dataset contains joint-speciﬁc
current proﬁles for each of the six joints in the UR3e only.
We conducted three sets of controlled experiments using
procedure types P2, P5, and P6 (see §IV for details).
P2 (Automated Solubility with N9 and UR3e) includes a
sequence of 58 commands, a majority of which are UR3e
move commands. Fig. 7(a) shows ﬁve portions of joint 1’s
current trace, corresponding to ﬁve different instances of the
move_joints() command. Each instance moves the robot
arm from location Li to Li+1, for i ∈ {0, 1, 2, 3, 4}. We
observe that the current trace for each command instance
is unique and that these unique patterns remain identical
across multiple iterations of this experiment. These results
suggest that while the command type alone does not correlate
with the current proﬁle, the robot arm trajectories identiﬁed
by the command type and its arguments (e.g.,
location
endpoints) correlate strongly with the current proﬁle. We test
this hypothesis by repeating the current experiment varying
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:16 UTC from IEEE Xplore.  Restrictions apply. 
106
(a) Different locations
(b) Different solids
(c) Different velocities
(d) Different weights
Fig. 7. UR3e joint 1 current proﬁles for four different scenarios. (a) The ﬁve curves show the current proﬁle for ﬁve different instances of move_joint(),
each of which moves the robot arm from location Li to Li+1 for i ∈ {0, 1, 2, 3, 4}. Each curve is a subset of the time series of currents from the procedure
P2. (b) The time series of current measurements from a subset of procedure P2 during with the UR3e picks up a vial from the storage rack, places it in the
Quantos, and then returns to the home position. The three curves correspond to selecting three different solids. (c) The time series of currents from executions
of procedure (P5) moving the arm at different velocities. (d) The time series of currents from procedure (P6) with the arm carrying different weights.
the solid used in procedure P2. As shown in Fig. 7(b), the
current proﬁles do not vary as the solid changes (the Pearson
correlation coefﬁcient exceeds 0.97), supporting the claim that
the variation in the power consumption is due to the speciﬁc
robot arm trajectories.
Next, we investigate the effect of robot arm velocities on
the current usage. We execute a procedure P5 where the robot
arm is moved between two speciﬁed locations with varying
linear velocities while keeping all other arguments (e.g., angle
and positions) constant. Fig. 7(c) illustrates the current traces
on joint 1 for velocities 100 mm/s, 200 mm/s, and 250 mm/s.
The current traces have similar shapes in each conﬁguration,
i.e., same number of peaks, similar slopes and gradients, and the
amplitudes are proportional to the velocity. However, the curve
for 100 mm/s is “stretched”, because at low velocity, the robot
arm requires more time to move from one location to another.
Finally, we execute P6, where the robot arm moves payloads
of different weights from one location to another. Fig. 7(d)
illustrates the current traces on joint 1 for weights 20 g, 500 g,
and 1000 g. As expected, lifting heavier objects draws more
power. Typically, weights are not speciﬁed as part of command
arguments; they are simply an artifact of the object lifted by
the arm. A power-based IDS can detect varying weights in
the power proﬁle, while a command-based IDS would need
additional information to make such a determination.
While the results shown here are for only one of the six UR3e
joints, we observe similar correlations in the current proﬁles
collected from other ﬁve joints. This data provides compelling
evidence that the power traces do reveal important information
about the particular procedure being run and features such as
velocity and payload weights, the latter of which is unavailable
from other means.
VII. CONCLUSION AND FUTURE WORK
Security is of grave concern in Industry 4.0 and IIoT
deployments. The risk of security attacks is potentially high,
because device controllers and lab workstations are routinely
connected to the Internet. In the worst case, if the CPS devices
in these deployments are maliciously controlled, they can harm
people and/or their surroundings. This is particularly concerning
in domains such as chemical sciences, where CPS devices such
as robot arms are surrounded by potentially lethal chemicals,
and a catastrophic outcome is just one misstep away.
We are collaborating with the Hein Lab, a research lab
that studies methods to fully automate chemical synthesis
procedures, to design and deploy a multi-level defense system
for the CPS devices in their lab. Using RATracer, we showed
the feasibility of deploying a middlebox-based design that
intercepts all communication between the lab computer and the
CPS devices. We open-source our Robotic Arm Dataset (RAD),
which is the ﬁrst of its kind, as it captures automation exper-
iments spanning multiple heterogeneous automation devices.
Finally, we presented two sets of preliminary analyses based
on the command and power data in RAD to infer procedure
types, command parameters, and experimental contexts.
However, we are still a long way from deploying a full-
ﬂedged IDS in the Hein Lab. As the number of devices grows
from ﬁve to ﬁfty (as is expected in the Hein Lab), a single
middlebox will not sufﬁce. While a single middlebox can easily
scale to tens of devices, we expect space and cabling issues
to be a more signiﬁcant challenge. Expansion will therefore
require, potentially, a distributed architecture with multiple
middleboxes in smaller form factors.
Modeling robot commands as a language and using NLP
techniques for intrusion detection is a new approach, with
no precedent in the robotics literature. We therefore need to
investigate a wider array of techniques that are best suited for
our dataset and objectives. Our immediate goals are to bring
command arguments into the fold, ﬁnd ways to automatically
generate labels, and evaluate models such as long short-term
memory [30] (which have been successfully deployed to model
time series data in many domains).
We also plan to conduct a more comprehensive study of
side channels by monitoring the power usage of all devices
in the lab. Recent results [28, 29] showing how to classify
device-speciﬁc power usages from the main power usage inside
a room are encouraging. Finally, while RAD is novel, we need
to generate many more anomalous traces for testing, or for
benchmarking other IDS. However, doing so in a manner that
does not destroy equipment remains an open question.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:16 UTC from IEEE Xplore.  Restrictions apply. 
107
ACKNOWLEDGEMENTS
We acknowledge the support of the Natural Sciences
and Engineering Research Council of Canada (NSERC) and
the UBC Science STAIR Grant. We also acknowledge the
contributions of other Hein Lab members, Veronica Lai, Tara
Zepel, Daniel Grifﬁn, Jonathan Reifman, Shad Grunert, Lars
P.E. Yunker, Sebastian Steiner, Henry Situ, Fan Yang, and
Paloma L. Prieto, to the development of the automated and
crystal solubility procedures.
REFERENCES
[1] “Kortex Gazebo,” https://github.com/Kinovarobotics/ros kortex/
tree/noetic-devel/kortex gazebo.
[2] “UR3 Unity Simulation,” https://github.com/tonydle/ur3 unity
sim.
[3] “Intrusion detection system for cyber-manufacturing system.”
[4] “Fsv2-series,”
https://docs.microsoft.com/en-us/azure/
virtual-machines/fsv2-series.
[5] “Fisher Scientiﬁc,” https://www.ﬁshersci.com.
[6] “Command Data Analysis,” https://github.com/ubc-systopia/
dsn-2022-rad-artifact/tree/main/analysis/Dataset
CommandAnalysis.
[7] “Power Data Analysis,”
https://github.com/ubc-systopia/
dsn-2022-rad-artifact/tree/main/analysis/Dataset
PowerAnalysis.
[8] “Python Library to Control the Robots from Universal Robots,”
https://github.com/SintefManufacturing/python-urx.
[9] “Code for Hein Lab’s Automated Solubility Experiment,”
https://gitlab.com/heingroup/robotic security experiments/-/
blob/master/n9/experiments/main solubility.py.
[10] “Code for Hein Lab’s Crystal Solubility Experiment,” https:
//gitlab.com/heingroup/robotic security experiments/-/blob/
master/n9/experiments/main crystal solubility proﬁling.py.
[11] “Serial Library that uses the FTDI Driver for More Reliable
Serial Communications,” https://gitlab.com/ada-chem/ftdi serial.
[12] “Code repositories for the Hein Group at the University of
British Columbia,” https://gitlab.com/heingroup.
[13] “Quantos Python API Wrapper,” https://gitlab.com/heingroup/
mtbalance.
[14] “Code for UR3e Movements with Different Payload Weights,”
https://gitlab.com/heingroup/robotic security experiments/-/
blob/master/ur/tests/ur different weights.py.
[15] “Hein Lab,” http://heinlab.com/.
[16] “IKA,” https://www.ika.com.
[17] “Mettler Toledo,” https://www.mt.com.
[18] “North Robotics,” https://www.northrobotics.com.
[19] “A Library that Routes all Communication to the N9 and
UR3 Robots via a Secure Middlebox,” https://pypi.org/project/
niraapad/.
[20] “pySerial’s documentation,” https://pythonhosted.org/pyserial/.
[21] “socket – Low-level networking interface,” https://docs.python.
org/3/library/socket.html.
[22] “RosyChem Lab Robotic Arm Dataset,” https://github.com/
ubc-systopia/dsn-2022-rad-artifact.
[23] “Robotic Arm Dataset
(RAD) Features Description,”
https://github.com/ubc-systopia/dsn-2022-rad-artifact/blob/
main/docs/RAD Description.pdf.
[24] “Tecan,” https://www.tecan.com.
[25] “Universal Robots,” https://www.universal-robots.com.
[26] P. F. Brown, V. J. Della Pietra, P. V. Desouza, J. C. Lai, and
R. L. Mercer, “Class-Based n-gram Models of Natural Language,”
Computational linguistics, vol. 18, no. 4, pp. 467–480, 1992.
[27] T. B. Duman, B. Bayram, and G. ˙Ince, “Acoustic Anomaly
Detection Using Convolutional autoencoders in Industrial Pro-
cesses,” in 14th International Conference on Soft Computing
Models in Industrial and Environmental Applications, 2019.
[28] J. Froehlich, E. Larson, S. Gupta, G. Cohn, M. Reynolds, and
S. Patel, “Disaggregated End-Use Energy Sensing for the Smart
Grid,” IEEE Pervasive Computing, vol. 10, no. 1, pp. 28–39,
2010.
[29] S. Gupta, M. S. Reynolds, and S. N. Patel, “ElectriSense:
Single-Point Sensing Using EMI for Electrical Event Detection
and Classiﬁcation in the Home,” in 12th ACM International
Conference on Ubiquitous Computing, 2010.
[30] S. Hochreiter and J. Schmidhuber, “Long short-term memory,”
Neural Computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[31] G. F. Jenks, “The Data Model Concept in Statistical Mapping,”
International Yearbook of Cartography, vol. 7, pp. 186–190,
1967.
[32] H. A. Khan, N. Sehatbakhsh, L. N. Nguyen, R. L. Callan,
A. Yeredor, M. Prvulovic, and A. Zaji´c, “IDEA: Intrusion
Detection through Electromagnetic-Signal Analysis for Critical
Embedded and Cyber-Physical Systems,” IEEE Transactions on
Dependable and Secure Computing, vol. 18, no. 3, pp. 1150–
1163, 2019.
[33] B. Leporowski, D. Tola, C. Hansen, and A. Iosiﬁdis, “AURSAD:
Universal Robot Screwdriving Anomaly Detection Dataset,”
arXiv preprint arXiv:2102.01409, 2021.
[34] ——, “Detecting Faults during Automatic Screwdriving: A
Dataset and Use Case of Anomaly Detection for Automatic
Screwdriving,” in Towards Sustainable Customization: Bridging
Smart Products and Manufacturing Systems. Springer, 2021,
pp. 224–232.
[35] W. McKinney, “Data Structures for Statistical Computing in
Python,” in 9th Python in Science Conference, 2010.
[36] V. Narayanan and R. B. Bobba, “Learning Based Anomaly
Detection for Industrial Arm Applications ,” in 4th ACM
Workshop on Cyber-Physical Systems Security and PrivaCy,
2018.
[37] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg,
J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot,
and E. Duchesnay, “Scikit-learn: Machine Learning in Python,”
Journal of Machine Learning Research, vol. 12, pp. 2825–2830,
2011.
[38] H. Pu, L. He, C. Zhao, D. K. Yau, P. Cheng, and J. Chen,
“Detecting Replay Attacks against Industrial Robots via Power
Fingerprinting,” in 18th Conference on Embedded Networked
Sensor Systems, 2020.
[39] G. Salton and C. Buckley, “Term-Weighting Approaches in Au-
tomatic Text Retrieval,” Information Processing & Management,
vol. 24, no. 5, pp. 513–523, 1988.
[40] P. Shiri, V. Lai, T. Zepel, D. Grifﬁn, J. Reifman, S. Clark,
S. Grunert, L. P. Yunker, S. Steiner, H. Situ et al., “Automated
Solubility Screening Platform Using Computer Vision,” Iscience,
vol. 24, no. 3, p. 102176, 2021.
[41] A. Vijayan, H. Singanamala, B. Nair, C. Medini, C. Nutakki, and
S. Diwakar, “Classiﬁcation of Robotic Arm Movement using
SVM and Na¨ıve Bayes Classiﬁers,” in 3rd IEEE International
Conference on Innovative Computing Technology, 2013.
[42] M. Wu, “Intrusion Detection for Cyber-Physical Attacks in
Cyber-Manufacturing System,” Ph.D. dissertation, Syracuse
University, 2019.
[43] M. Wu and Y. B. Moon, “Alert Correlation for Detecting Cyber-
Manufacturing Attacks and Intrusions,” Journal of Computing
and Information Science in Engineering, vol. 20, no. 1, p. 011004,
2020.
[44] Y. Zuo, W. Qiu, L. Xie, F. Zhong, Y. Wang, and A. L.
Yuille, “CRAVES: Controlling Robotic Arm with a Vision-based
Economic System,” in 32nd IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2019.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:16:16 UTC from IEEE Xplore.  Restrictions apply. 
108