perfectly and the CH must determine the actual location of 
the  event.  One  sensor  network  problem  that  can  be  solved 
through  this  extension  is  where  a  network  is  attempting  to 
track a mobile sensor node that is transmitting a signal as it 
moves throughout the network.  
Simplifying  Assumptions:  Let  us  assume  there  is  a  time 
difference of  at  least Tout  between  any  two  events  to  avoid 
overlapping event neighbors. A correct event report sent in 
4
by a sensing node reports the location of an event to within a 
radius rerror surrounding the event.  
Once time Tout has elapsed after the first event report, let 
there be k other reports that have come in from the nodes in 
the  cluster  during  this  time.  The  CH  performs  a  clustering 
algorithm  based  on  K-Means  which  groups  these  k  event 
reports  into  a  number  of  event  clusters  based  on  the 
locations  indicated  by  the  reports  [14].  Each  event  cluster 
represents  a  possible  location  where  the  event  could  have 
occurred,  as  indicated  by  the  reports.  The  clustering 
algorithm is a heuristic based on K-Means, so as to minimize 
the sum of squares error.  
Goal of the algorithm presented below is to organize the 
event reports into disjoint event clusters of radius rerror. Let C 
be  the  set  of  all  event  clusters  consisting  of  elements  {C1, 
C2…Cr}.  Let  {c1,  c2…cr}  be  the  centers  around  which  the 
event clusters {C1, C2…Cr} are formed. Let d(x, y) denote 
the distance between two points x and y. d(ci, cj) > rerror ∀ Ci, 
Cj   ∈  C.  Ck.cg  (Center  of  gravity)  denotes  the  average 
location indicated by all event reports in cluster Ck. 
 Event clusters are created using the following procedure.  
(1)  The clustering algorithm is started once Tout has elapsed 
after the first event report. The set of all event reports in 
this time Tout is referred to as E. The distances between 
each pair of event reports are computed and sorted in a 
2D array. 
(2)  Let E1 and E2 be event reports from the set E with the 
greatest  distance  between  them.  Event  clusters  C1  and 
C2 are created with E1 and E2 as centers, and C1, C2 are 
added to C.  
(3)  Condition  for  any  event  report  Ek  to  form  a  separate 
event cluster is that d(Ek, ci) > rerror ∀Ci ∈C. The set E is 
iterated  through  and  the  set  of  all  cluster  centers  are 
identified,  so  that  the  remaining  event  reports  are  at  a 
distance of less than rerror from at least one element in C, 
i.e.,  the  remaining  event  reports  cannot  form  separate 
event clusters. 
(4)  Once  the  initial  set  of  clusters  in  C  are  formed, 
remaining  event  reports  in  E  are  added  to  one  of  the 
clusters in C based on which cluster center it is nearest 
to. Ck.cg for the clusters are updated appropriately. 
(5)   If the centers of two or more clusters lie within rerror of 
each  other  the  clustering  algorithm  is  repeated  by 
forming a new cluster center at the weighted average of 
these centers. The rounds are executed until no change 
in cluster constituency takes place in a new round.  
The  final  elements  in  C  represent  the  set  of  all  events. 
Ck.cg  represents  the  location  of  the  event  k.  The  event 
neighbors can be determined for the location determined and 
a  determination  of  whether  an  event  has  occurred  is  made 
based  on  the  trust  indices  of  the  associated  nodes  as  in 
Section  3.1.  This  design  successfully  throws  out  event 
reports  from  nodes  that  make  a  localization  error  of  more 
than rerror.  
3.3  Concurrent Events 
Additions: In this section we build on the previous model by 
assuming that multiple events can occur within Tout of each 
other  (referred  to  as  concurrent  events  from  here  on).  We 
however assume that concurrent events cannot occur closer 
than a distance of rerror. 
(1)  When  the  CH  receives  the  first  event  report  E1,  a 
symbolic circle of radius rerror is drawn around it. A new 
timer  E1.Tout is  started  for  the  associated  event  reports 
from other event neighbors to come in. All subsequent 
events  that  lie  within  rerror  of  E1  reported  within  time 
Tout are added to the same circle.  
(2)  If any subsequent event report Ek received lies outside 
this  circle,  a  new  circle  of  radius  rerror  is  formed  with 
this  event  report  Ek  as  its  center.  Associated  Ek.Tout  is 
started. 
(3)  Once time Ek.Tout has passed from the reception of event 
report  Ek  that  is  the  center  of  a  circle,  all  the  event 
reports  inside  this  circle  are  put  into  a  group  and  the 
clustering algorithm described in the previous section is 
performed  on  them  to  determine  the  location  of  the 
event.  
(4)  However if one or more other circles overlap with this 
circle, then the CH must wait until time Tout has elapsed 
for  all  such  overlapping  circles.  The  clustering 
algorithm is performed on the union of all event reports 
in  all  the  overlapping  circles  to  determine  the  event 
clusters  and  thus  how  many  events  have  actually 
occurred. 
3.4  Unreliable Cluster Heads 
Though the CHs are chosen based on high TI values, it is 
still  possible  for  a  selected  CH  to  fail.  To  combat  this 
problem  we  assign  two  additional  shadow  cluster  heads 
(SCH)  to  each  cluster  such  that  the  SCHs  can  monitor  all 
input and output traffic associated with the selected CH. The 
SCHs  themselves  may  be  considered  to  be  reliable  as  they 
are chosen based on the fact that they have the highest trust 
indices among nodes within one hop of the CH. The SCHs 
listen in to the communication going in and out of the CH 
and perform all the functions as the CH except transmitting 
the  aggregated  event  reports  to  the  base  station.  On 
perceiving a wrong conclusion being drawn at the CH based 
on the input data, the SCHs also send the result of their own 
computations  to  the  base  station.  The  base  station,  on 
receiving  data  from  all  CHs  in  the  cluster,  does  a  simple 
voting to arrive at the right conclusion. It also prompts CH 
election in that cluster to pick a new CH and reduces the TI 
of the previous faulty CH. Thus, only a single CH failure can 
be tolerated.  
TIBFIT  can  also  be  extended  to  scenarios  where  the 
sensing  nodes  are  more  than  one  hop  away  from  the  data 
sink.  The  data  sink  still  needs  to  know  the  location  of  the 
constituent  node  and  reliable  data  dissemination  primitive 
needs to be introduced to ensure that the data sent out by the 
sensing nodes reliably reach the data sink without alteration 
[15],[16].  
5
4  Simulation 
The  TIBFIT  protocol  is  simulated  using  the  network 
simulator  –  ns-2  [6].  A  sensing  radius  of  20  units  is 
considered. Events are generated at regular time intervals by 
the  event  generator,  using  a  uniform  random  variable  to 
generate  X  and  Y  coordinates  uniformly  distributed  in  the 
network. The event generator informs the event neighbors of 
the event and its location. 
We  run  three  different  experiments.  In  experiment  1  we 
show  the  accuracy  of  the  binary  event  model  versus 
percentage  of  the  network  compromised  by  level  0  faulty 
nodes. In experiment 2 we show the accuracy of the location 
event model versus percentage of the network compromised 
by level 0, 1, and 2 faulty nodes. In experiment 3 we show 
the accuracy of the location event model versus time, where 
the  percentage  of  the  network  compromised  increases 
linearly over time. 
For each simulation we use either the TIBFIT system that 
uses  the  trust  index,  or  we  use  the  baseline  system,  which 
uses  majority voting  to  make  event  decisions.  Experiments 
are run with faulty nodes belonging to only one level for a 
given experiment. Nodes are stationary in all experiments. 
4.1  Experiment 1 – Binary Events 
A  cluster  of  ten  nodes  is  formed,  and  all  nodes  are  
considered  event  neighbors  for  every  randomized  event. 
Level 0 faulty nodes are used for the fault model, generating 
both  missed  alarms  and  false  alarms.  The  CH  makes  a 
decision regarding occurrence of the event based on the data 
forwarded to it from the sensing nodes.  
Type of Event 
Independent Variable 
Correct Nodes NER 
Faulty Nodes NER 
Binary Event Model 
Percentage  Faulty  Nodes: 
varied from 40%-90% 
0, 1, and 5% 
Level 0:Missed Alarm 50% 
False alarm 0,10, and 75% 
10 sensing nodes, 1 CH 
Size of network 
Number of Event neighbors  10 
100 
Events per simulation 
0.1 
 λ 
Same as NER 
Fault rate (fr) 
Table 1: Parameters for Experiment 1 
For this experiment we started simulations with 40% of the 
network  compromised.  As  Section  5  shows,  even  for  the 
baseline system, the probability of failure with less than 40% 
of the network compromised is very small, and therefore not 
simulated. 
The  results  in  figure  2  include  only  missed  alarms.  The 
most  noteworthy  result  from  this  experiment  is  that  the 
network  can  have  70%  of  its  nodes  compromised  and  still 
maintain  over  85%  accuracy.  This  result  is  superior  to  the 
analytical results shown in figure 10 in Section 5.  
Accuracy of Detection
100
y
c
a
r
u
c
c
A
80
60
40
60
70
50
40
90
Percentage Network Compromised
NER = 0% NER = 1% NER = 5%
80
Figure 2: Experiment 1 – 50% accurate faulty 
Nodes, missed alarms only 
Accuracy of Detection, NER=1%
100
y
c
a
r
u
c
c
A
80
60
40
40
50
60
70
80
90
Percentage Network Compromised
0% False Alarms
75% False Alarms
10% False Alarms
Figure 3: Experiment 1 – 50% accurate faulty nodes, 
missed alarms and false alarms 
Figure 3 shows the simulation with both false alarms and 
missed alarms from faulty nodes. All correct nodes have 1% 
NER. Again, the network performance starts to degrade with 
70%  faulty  nodes.  The  interesting  results  is  that  75%  false 
alarms shows the best accuracy when less than 80% of the 
network is compromised, indicating that the excessive false 
alarms lower faulty nodes’ TIs and therefore increase system 
reliability.  At  80%  faulty  nodes  with  75%  false  alarms, 
accuracy falls dramatically, as the system is no longer able 
to  tolerate  the  excessive  false  alarms.  10%  false  alarms 
maintains the highest accuracy at this point, indicating that 
occasional  false  alarms  lower  faulty  nodes’  trust  indices 
enough to outperform 0% false alarms.  
4.2  Experiment 2 – Location Determination 
Model 
In  the  second  type  of  simulation,  100  nodes  are  placed 
uniformly on a 100X100 grid. The CHs and event generator 
are  two  other  entities  present  in  the  network.  The  CH 
decides  on  both  the  occurrence  of  the  event  as  well  as  its 
location. The network is a single cluster, and the CH knows 
6
the positions of all 100 nodes. All nodes can reach the CH in 
a single hop. For location estimation rerror is 5 units. Table 2 
shows various experimental parameters for this experiment. 
Due to the ns-2 wireless model, correct nodes’ packets are 
naturally dropped less than 1% of the time.  
A lower threshold (lowerTI) of 0.5 is used for level 1 and 
level 2 nodes to ensure their trust indices do not fall too low. 
If they reach the lower threshold they behave like a correct 
node  until  they  reach  an  upper  threshold  (upperTI)  of  0.8, 
after  which  they  begin  erring  again.  Each  node  reports  an 
event with error in both the X and Y directions as dictated 
by a Gaussian random variable with standard deviation σ. 
Type of Event 
Independent variable 
Location Determination 
Concurrent or single events 
Percentage 
faulty  nodes, 
varied from 10%-58% 
deviation of 1.6 or 2.0 
Location  report  has  std. 
dev.  of  4.25  or  6.0,  drop 
packets 25% of the time 
100 sensing nodes, 5 CH 
Error rate for correct nodes  Location  report  has  std. 
Error  rate  for  faulty  nodes 
(levels 0, 1, and 2) 
Size of network 
Number of event neighbors  Variable on location 
λ 
Fault rate (fr) 
0.25  
0.1 (different from NER to 
compensate 
for  wireless 
channel model losses) 
Table 2: Parameters for Experiment 2 
it 
The error percentage indicated in Table 2 is calculated as 
the  joint  probability  distribution  of  the  two  Gaussian  rv’s, 
which  are  Rayleigh  distributed,  and 
the 
probability a node reports an event more than 5 units away 
from the actual event location. The standard deviation for a 
correct node is much less than that for a faulty node. Level 1 
nodes work independently, while level 2 nodes collude with 
each other and all either send the event report for the same 
location or do not send the event report.  
indicates 
This experiment initialized a network with a percentage of 
the  network  compromised  by  Level  0,  1,  or  2  malicious 
nodes.  58%  was  the  upper  limit  for  the  compromised 
network  as  past  this  point  the  system  did  not  work  with 
much accuracy. The output accuracy metric was the number 
of events detected by the CH within rerror of the actual event. 
Simulations are run with both concurrent and single events. 
The legend format for all the result figures from this point on 
is “Lvl M W-Z [TIBFIT or Baseline]”, where M is the type of 
malicious  node  used,  W  is  the  standard  deviation  of  the 
correct  nodes,  Z  is  the  standard  deviation  of  the  malicious 
nodes, and the final parameter is whether the TIBFIT or the 
baseline model was used.  
The results in figure 4 show that at low percentages of the 
network  compromised,  the  TIBFIT  system  and  the  baseline 
system  perform  similarly.  However,  after  40%  of  the 
network is compromised, the TIBFIT model performs better 
than  the  baseline  model  by  at  least  7%  percent,  and  by  as 
much  as  20%  percent.  More  importantly,  TIBFIT  has 
accuracy  near  80%  even  with  faulty  nodes  having  errors 
70%  of  the  time.  A  consequence  of  the  execution  of  the 
network  with  TIBFIT  is  that  the  trust  index  values  of  the 
faulty  nodes  continue  to  decrease  and  once  they  reach  the 
threshold, the nodes can be removed from the network, thus 
eliminating 
damage.   
future 
from 
causing 
them 
Level 0 TIBFIT versus Baseline
The  graph  indicates  that  tolerating  concurrent  events  does 
not  significantly  alter  the  success  of  the  nodes  in  accurate 
detection of events. 
Level 2 TIBFIT versus Baseline
y
c
a
r
u
c
c
A
100
90
80
70
60
50
40
30
y
c
a
r
u
c
c
A
100
90
80
70
60
50
40
10
20
30
40
50
Percentage Network Compromised
55
58
Lvl 0 2-6 Baseline
Lvl 0 1.6-6 Baseline
Lvl 0 2-6 TibFit
Lvl 0 1.6-6 TibFit
Figure 4: Experiment 2 – Level 0 faulty nodes 
Level 1 TIBFIT versus Baseline
y
c
a
r
u
c
c
A
100
90
80
70
60
50
40
10
20
30
40
50
55
58
Percentage Network Compromised
Lvl 1 2-6 with TI
Lvl 1 2-6 without TI
Lvl 1 1.6-6 without TI
Lvl 1 1.6-6 with TI
Figure 5: Experiment 2 – Level 1 faulty nodes 
The second graph for location estimation, shown in figure 
5, is for level 1 nodes. The result shows that even with 58% 
of  the  network  compromised,  TIBFIT’s  accuracy  remains 
over  90%.  In  contrast,  the  baseline  model  falls  well  below 