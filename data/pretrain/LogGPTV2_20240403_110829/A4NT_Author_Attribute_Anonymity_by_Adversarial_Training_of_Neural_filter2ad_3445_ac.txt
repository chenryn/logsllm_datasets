entailment [47]
Since we do not have annotations of semantic related-
ness on our datasets, it is not possible to train a semantic
embedding model but instead we have to rely on pre-
trained models known to have good transfer learning per-
formance. Several such semantic sentence embeddings
are available in the literature [47, 48]. We use the univer-
sal sentence embedding model from [47], pre-trained on
the Stanford natural language inference dataset [49].
The A4NT network can minimize the style and the
semantic losses, while still producing text which is broken
and grammatically incorrect. To minimize the style loss
the A4NT network needs to add words typical of the target
attribute style. While minimizing the semantic loss, it
needs to retain the semantically relevant words from the
input text. However neither of these two losses explicitly
enforces correct grammar and word order of ˜s.
On the other hand, unconditional neural language mod-
els are good at producing grammatically correct text. The
likelihood of the sentence produced by our A4NT model
˜s under an unconditional language model, My, trained on
the text by target attribute authors y, is a good indicator
of the grammatical correctness of ˜s. The higher the like-
lihood, the more likely the generated text ˜s has syntactic
properties seen in the real data. Therefore, we add an ad-
ditional language smoothness loss on ˜s in order to enforce
Z to produce syntactically correct text.
Llang( ˜s)=−logMy( ˜s)
(12)
Ltot(Zxy)= wstyLstyle+ wsemLsem+ wlLlang
Overall loss function: The A4NT network is trained
with a weighted combination of the three losses: style
loss, semantic consistency and language smoothing loss.
(13)
We chose the above three weights so that the magnitude
of the weighted loss terms are approximately equal at the
beginning of training. Model training was not sensitive to
exact values of the weights chosen that way.
Implementation details: We implement our model using
the PyTorch framework [50]. The networks are trained by
optimizing the loss functions described with stochastic
gradient descent using the RMSprop algorithm [51]. The
A4NT network is pre-trained as an autoencoder, i.e to
reconstruct the input sentence, before being trained with
the loss function described in (13). During the GAN
training, the A4NT network and the attribute classiﬁers
are trained for one minibatch each alternatively. We will
open source our code, models and data at the time of
publication.
5 Experimental Setup
We test our A4NT network on obfuscation of three dif-
ferent attributes of authors on two different datasets. The
three attributes we experiment with include author’s age
(under 20 vs over 20), gender (male vs female authors),
and author identities (setting with two authors).
USENIX Association
27th USENIX Security Symposium    1639
5.1 Datasets
We use two real world datasets for our experiments:
Blog Authorship corpus [37] and Political Speech dataset.
The datasets are from very different sources with distinct
language styles, the ﬁrst being from mini blogs written by
several anonymous authors, and the second from political
speeches of two US presidents Barack Obama and Donald
Trump. This allows us to show that our approach works
well across very different language corpora.
Blog dataset: The blog dataset is a large collection of mi-
cro blogs from blogger.com collected by [37]. The dataset
consists of 19,320 “documents” along with annotation of
author’s age, gender, occupation and star-sign. Each doc-
ument is a collection of all posts by a single author. We
utilize this dataset in two different settings; split by gen-
der (referred to as blog-gender setting) and split by age
annotation (blog-age setting). In the blog-age setting, we
group the age annotations into two groups, teenagers (age
between 13-18) and adults (age between 23-45) to obtain
data with binary age labels. Age-groups 19-22 are miss-
ing in the original dataset. Since the dataset consists of
free form text written while blogging with no proper sen-
tence boundaries markers, we use the Stanford CoreNLP
tool to segment the documents into sentences. All num-
bers are replaced with the NUM token. For training and
evaluation, the whole dataset is split into training set of
13,636 documents, validation set of 2,799 documents and
test set of 2,885 documents.
Political speech dataset: To test the limits of how far
style imitation based anonymization can help protect au-
thor identity, we also test our model on two well known
political ﬁgures with very different verbal styles. We col-
lected the transcriptions of political speeches of Barack
Obama and Donald Trump made available by the The
American Presidency Project [52]. While the two authors
talk about similar topics they have highly distinctive styles
and vocabularies, making it a challenging dataset for our
A4NT network. The dataset consists of 372 speeches,
with about 65,000 sentences in total as shown in Table I.
We treat each speech as a separate document when eval-
uating the classiﬁcation results on the document-level.
This dataset contains a signiﬁcant amount of references
to named entities like people, organizations, etc. To avoid
that both attribute classiﬁers and the style transfer model
rely on these references to speciﬁc people, we use the
Stanford Named Entity Recognizer tool [53] to identify
and replace these entities with entity labels. The dataset
is split into training set of 250 speeches, validation set of
49 speeches and test set of 73 speeches.
The comparison of the two datasets can be found in Ta-
ble I. The blog dataset is much larger and therefore we run
most of our evaluation on it. Using these two datasets, we
evaluate our model in three different attribute obfuscation
settings, namely age (blog-age), gender (blog-gender) and
Dataset
Speech
Blog
Attributes
Identity
Age, Gender
# Documents
# Sentences
# Vocabulary
372
19320
65k
3.38 Mil
5.6k
22k
Table I: Comparing statistics of the two datasets.
identity obfuscation (speech dataset). Detailed analysis
of our model presented in Section 6.2 is done on the val-
idation split of the blog dataset, in the blog-age setting,
containing 2,799 documents and 518,268 sentences.
5.2 Evaluation Methods
We evaluate our models with according to two different
aspects: (a) Privacy effectiveness, to measure how well
the A4NT network can fool the attribute classiﬁers and (b)
Semantic similarity, quantifying how much of the input
sentence semantics is preserved after style transfer.
To quantify privacy effectiveness we compare the F1-
score of the attribute classiﬁers on the original data
and the generated text. To mimic a real-world setting
where we will not have access to the parameters of the
attribute-classiﬁer used by the adversary to train our
A4NT network, we test it against attribute classiﬁers
which have been separately trained on real data.
The F1-score for the attribute classiﬁers is deﬁned as:
F1= 2∗ precision∗ recall
precision+ recall
(14)
With successful style transfer, the attribute classiﬁer will
misclassify generated text and the F1-scores will drop. We
consider the obfuscation to be successful if the F1-score
drops below that of a random guessing classiﬁer. Note that
since the datasets are not perfectly balanced with respect
to the binary attributes, the F1-score for random classiﬁer
is not 0.5. The expected document-level F1-scores of
random guessing are 0.54 for the blog-age setting, 0.5 for
the blog-gender setting, and 0.61 for the speech data.
For achieving obfuscation, having the attribute classi-
ﬁer around random chance-level is more desirable than
pushing the classiﬁer to 0% accuracy. Zero accuracy
means the classiﬁer has perfectly misclassiﬁed every sam-
ple. In a binary classiﬁcation setting like age-group or
gender, if the adversary detects there has been obfus-
cation he can fully recover the original classes by just
ﬂipping the decisions of the classiﬁer. However if the
obfuscation is to the random chance-level, even upon
detection, the best the adversary can do is to get the ran-
dom chance accuracy. This also holds true for multi-class
situation, as can be seen from the information theoretic
point of view. To achieve perfect obfuscation, we want
the attribute classiﬁer output to contain minimum infor-
mation about the true class of the input text. When the
classiﬁer accuracy of the k-class attribute classiﬁer is at
the random chance-level, it is guessing the class labels
with uniform probability p(y c)∼ Uniform(1,2,,k).
1640    27th USENIX Security Symposium
USENIX Association
In this case the mutual information between the clas-
siﬁer predicted label y and true label c is zero, since
the p(y c)= p(y). However, the prediction of classiﬁer
p(y c) at 0% accuracy is not independent of the input
i.e p(y c)∼ Uniform(1,2,,c− 1,c+ 1,,k). This leads
class-label since it cannot take the correct class value c,
to non-zero mutual information between y and c. Hence,
we use the random chance-level as our success criteria for
obfuscation instead of targeting 0% classiﬁer accuracy.
To quantify semantic similarity, we use the meteor
metric [54]. It is used in machine translation and image
captioning to evaluate the similarity between the can-
didate text and a reference text. Meteor compares the
candidate text to one or more references by matching n-
grams, while allowing for soft matches using synonym
and paraphrase tables. Meteor score lies between zero
and one with zero indicating no similarity and one indi-
cating identical sentences. For a point of reference, the
state-of-the-art methods for paraphrase generation task
achieve meteor scores between 0.35-0.4 [55] and for mul-
timodal machine translation task achieve meteor score
in the range 0.5-0.55 [56]. We use the meteor score
between the generated and input text as the measure of
semantic similarity.
However, the automatic evaluation for semantic simi-
larity is not perfectly correlated with human judgments,
especially with few reference sentences. To address this,
we additionally conduct two user studies on a subset of
the test data of 745 sentences, ﬁrst to compare the se-
mantic similarity between different obfuscation methods
relatively, and second to measure the semantic similarity
between the model output and input text on an absolute
scale. We ask human annotators on Amazon Mechani-
cal Turk (AMT) to judge the semantic similarity of the
generated text from our models. No other information
was collected from the annotators, thereby keeping them
anonymous. The annotators were compensated for their
work through the AMT system. We manually screened
the text shown to the annotators to make sure it contained
no obvious offensive content.
5.3 Baselines
We use the two baseline methods below to compare
our model with. Both chosen baselines are automatic
obfuscation methods not relying on hand-crafted rules.
Autoencoder We train our A4NT network Z as an autoen-
coder, where it takes as input sx and tries to reproduce it
from the encoding. The autoencoder is trained similar to
a standard neural language model with cross entropy loss.
We train two such auto-encoders Zxx and Zyy for the two
attributes. Now simple style transfer can be achieved from
x to y by feeding the sentence sx to the autoencoder of
the other attribute class Zyy. Since Zyy is trained to output
text in the y domain, the sentence Zyy(sx) tends to look
similar to sentences in y. This model sets the baseline for
style transfer that can be achieved without cross domain
training using GANs, with the same network architecture
and the same number of parameters.
Google machine translation: A simple and accessible
approach to change writing style of a piece of text without
hand designed rules is to use generic machine transla-
tion software. The input text is translated from a source
language to multiple intermediate languages and ﬁnally
translating back to the source language. The hope is that
through this round-trip the style of the text has changed,
with the meaning preserved. This approach was used in
the PAN authorship obfuscation challenge recently [16].
We use the Google machine translation service1 to
perform the round-trip translation of our input sentences.
We have tried a varying number of intermediate languages,
results of which will be discussed in Section 6. Since
Google limits the api calls and imposes character limits on
manual translation, we use this baseline only on the subset
of 745 sentences from the test set for human evaluation.
6 Experimental Results
We test our model on the three settings discussed in
Section 5 with the goal to understand if the proposed
A4NT network can fool the attribute classiﬁers to protect
the anonymity of the author attributes. Through quanti-
tative evaluation done in Section 6.1, we show that this
is indeed the case: our A4NT network learns to fool the
attribute classiﬁers across all three settings. We compare
the two semantic loss functions presented in Section 4.4
and show that the proposed reconstruction likelihood loss
does better than pre-trained semantic encoding.
However, this privacy gain comes with a trade-off. The
semantics of the input text is sometimes altered. In Sec-
tion 6.2, using qualitative examples, we analyze the fail-
ure modes of our system and identify limits up to which
style-transfer can help preserve anonymity.
We use three variants of our model in the following
study. The ﬁrst model uses the semantic encoding loss de-
scribed in Section 4.4.2 and is referred to as FBsem. The
second uses the reconstruction likelihood loss discussed in
Section 4.4.1 instead, and is denoted by CycML. Finally,
CycML+Lang uses both cyclic maximum likelihood and
the language smoothing loss described in Section 4.5.
6.1 Quantitative Evaluation
Before
the
of
the
evaluate
performance
our
analyzing
A4NT network, we
classi-
ﬁers on the three settings we use. For this, we train
the attribute classiﬁer model in Section 4.1 on all three
settings. Table II shows the F1-scores of the attribute
classiﬁers on the training and the validation splits of the
blog and the speech datasets. Document-level scores are
attribute
1https://translate.google.com/
USENIX Association
27th USENIX Security Symposium    1641
Setting
Speechdata
Blog-age
Blog-gender
Training Set
Validation Set
Sentence Document Sentence Document
1.00
0.88
0.75
0.68
0.74
0.52
0.84
0.76
0.64
1.00
0.92
0.93
Table II: F1-scores of the attribute classiﬁers. All of them
do well and better than the document-level random chance
(0.62 for speech), (0.53 for age), and (0.50 for gender).
obtained from accumulating the class log-probability
scores on each sentence in a document before picking
the maximum scoring class as the output label. We also
tried hard voting to accumulate sentence level decisions,
and observed that the hard voting results follow the same
trend across datasets and splits.
On the smaller political speech dataset, the attribute
classiﬁer is able to easily discriminate between the two
authors, Barack Obama and Donald Trump, achieving per-
fect F1-score of 1.0 on both the training and the validation
splits. The model also performs well on the age-group