(3) Phase response of receiving sensor. The phase response of
receiving sensor is typically unknown, which will also introduce
phase shifts.
As a result, the accuracy of phase response measurement cannot
be guaranteed. That means the entire frequency response cannot
be accurate. Also we can prove that even small measurement errors
for phase response can cause ringing artifacts (see Theorem 3).
â–¡
Theorem A.2. Compared to the genuine signal ğ‘¥(ğ‘¡), there are
phase shifts for each frequency component in the modulated replay
signal ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡).
Proof. In the modulated replay attack, the inverse filter only
needs to compensate the amplitude spectrum because the features
(e.g. CQCC, MFCC, LPCC) in the existing defenses only derives from
the amplitude spectrum. However, a loudspeaker has a non-zero
phase response in the real world, though it cannot be accurately
measured (see Theorem A.1).
Suppose the genuine audio x(t) is a digital signal. Through the
fast Fourier transform, x(t) would be decomposed as ğ‘ frequency
components with the frequency set {ğ‘“1, ğ‘“2, ..., ğ‘“ğ‘ }. The frequency
spectrum of ğ‘¥(ğ‘¡) is denoted as {ğ´ğ‘›, ğœ‘ğ‘›}, where {ğ´ğ‘›} is the ampli-
tude spectrum while {ğœ‘ğ‘›} is the phase spectrum. So, ğ‘¥(ğ‘¡) can be
represented as
ğ‘¥(ğ‘¡) =
ğ´ğ‘› Â· sin(2ğœ‹ ğ‘“ğ‘›ğ‘¡ + ğœ‘ğ‘›).
(4)
Assume that the frequency response of the loudspeaker is ğ» =
{ğºğ‘›,ğœ“ğ‘›}, where {ğºğ‘›} is the amplitude response while {ğœ“ğ‘›} is the
phase response. By measuring the input and output test signals,
attacker can achieve the estimated frequency response Ë†ğ» = { Ë†ğºğ‘›, 0}.
The inverse filter is then designed based on Ë†ğ», denoted as ğ¼ =
Ë†ğ»âˆ’1 = { Ë†ğºğ‘›
, 0}. As a result, the generated modulated audio would
be
âˆ’1

ğ‘›
ğ‘¥ğ‘š(ğ‘¡) =
(ğ´ğ‘›/ Ë†ğºğ‘›) Â· sin(2ğœ‹ ğ‘“ğ‘›ğ‘¡ + ğœ‘ğ‘›).
(5)
If the loudspeaker is ideal that does not have phase shift effects.
And the amplitude estimation is enough accurate. The estimated
replay output of the modulated audio would be
Ë†ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡) =
(ğ´ğ‘› Â· ğºğ‘›/ Ë†ğºğ‘›) Â· sin(2ğœ‹ ğ‘“ğ‘›ğ‘¡ + ğœ‘ğ‘›)
ğ´ğ‘› Â· sin(2ğœ‹ ğ‘“ğ‘›ğ‘¡ + ğœ‘ğ‘›) = ğ‘¥(ğ‘¡),
which is approximately equal to the genuine audio.
However, if the modulated audio ğ‘¥ğ‘š(ğ‘¡) passes through the real
loudspeaker system ğ», the real modulated replay ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡) audio
would be
(6)
ğ‘›
ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡) =
(ğ´ğ‘› Â· ğºğ‘›/ Ë†ğºğ‘›) Â· sin(2ğœ‹ ğ‘“ğ‘›ğ‘¡ + ğœ‘ğ‘› + ğœ“ğ‘›)
ğ´ğ‘› Â· sin(2ğœ‹ ğ‘“ğ‘›ğ‘¡ + ğœ‘ğ‘› + ğœ“ğ‘›) â‰  ğ‘¥(ğ‘¡).
(7)

â‰ˆ
ğ‘›
ğ‘›

ğ‘›

â‰ˆ
ğ‘›


ğ‘›â‰ ğ‘
ğ‘›
ğ‘¥â€²(ğ‘¡) =
=
Because ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡) has almost the same amplitude spectrum with
the genuine audio ğ‘¥(ğ‘¡), it can bypass the existing defense systems.
However, compared to the genuine signal ğ‘¥(ğ‘¡), there are phase
shifts for each frequency component in the modulated replay signal
ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡).
â–¡
Theorem A.3. The phase shifts will cause the spurious oscillations
(ringing artifacts) in the original audio.
Proof. Suppose there is a small phase shift dğœ‘ in the ğ‘ -th fre-
quency component of the signal ğ‘¥(ğ‘¡), while other frequency com-
ponents remain unchanged. The new signal would be
ğ´ğ‘› Â· sin(2ğœ‹ ğ‘“ğ‘› + ğœ‘ğ‘›) + ğ´ğ‘ Â· sin(2ğœ‹ ğ‘“ğ‘ + ğœ‘ğ‘ + dğœ‘)
ğ´ğ‘› Â· sin(2ğœ‹ ğ‘“ğ‘› + ğœ‘ğ‘›) + ğ´ğ‘ Â· sin(2ğœ‹ ğ‘“ğ‘ + ğœ‘ğ‘ + dğœ‘)
âˆ’ ğ´ğ‘ Â· sin(2ğœ‹ ğ‘“ğ‘ + ğœ‘ğ‘)
= ğ‘¥(ğ‘¡) + 2 Â· ğ´ğ‘ Â· sin( dğœ‘
= ğ‘¥(ğ‘¡) + ğ¶ Â· cos(2ğœ‹ ğ‘“ğ‘ + ğœ‘ğ‘ + dğœ‘
2 )
= ğ‘¥(ğ‘¡) + ğ‘œğ‘ (ğ‘¡).
2 ) Â· cos(2ğœ‹ ğ‘“ğ‘ + ğœ‘ğ‘ + dğœ‘
2 )
(8)
Because dğœ‘ is a very small shift value, ğ¶ is a small constant that
satisfies |ğ¶| < |ğ´ğ‘› Â· dğœ‘|.
ğ‘¥(ğ‘¡) is an audio signal that is statistically smooth in the time do-
main. Hence, the new signal ğ‘¥â€²(ğ‘¡) contains small ringing artifacts
because of the additional oscillations signal ğ‘œğ‘ (ğ‘¡) with the fre-
quency of ğ‘“ğ‘ . The maximum amplitude of the spurious oscillations
is limited by |ğ¶| value.
Assume that the phase shifts of a loudspeaker system are denoted
as ğœ“ = {ğœ“ğ‘›} for all frequency components. The modulated replay
signal would be
ğ‘¥ğ‘šğ‘Ÿ (ğ‘¡) =
ğ´ğ‘› Â· sin(2ğœ‹ ğ‘“ğ‘› + ğœ‘ğ‘› + ğœ“ğ‘›)
ğ´ğ‘› Â· sin(ğœ“ğ‘›
2 ) Â· cos(2ğœ‹ ğ‘“ğ‘› + ğœ‘ğ‘› + ğœ“ğ‘›
2 )
(9)
ğ¶ğ‘› Â· cos(2ğœ‹ ğ‘“ğ‘› + ğœ‘ğ‘› + ğœ“ğ‘›
2 )
ğ‘›

= ğ‘¥(ğ‘¡) + 2 Â·
= ğ‘¥(ğ‘¡) +
ğ‘œ(ğ‘¡) = 2 Â·
= ğ‘¥(ğ‘¡) + ğ‘œ(ğ‘¡).
ğ‘›
ğ‘›
ğ‘›
The total spurious oscillations ğ‘œ(ğ‘¡) can be presented as
2 ) Â· cos(2ğœ‹ ğ‘“ğ‘› + ğœ‘ğ‘› + ğœ“ğ‘›
2 ).
ğ´ğ‘› Â· sin(ğœ“ğ‘›
(10)
The maximum amplitude ğ´ğ‘œ of the spurious oscillations is con-
straint by the following condition.

ğ‘›
|ğ¶ğ‘›| <
ğ‘›
ğ´ğ‘œ =
ğ´ğ‘› Â· |ğœ“ğ‘–|
(11)
As a result, the phase shifts of the loudspeakers will lead to the
ringing artifacts in the modulated replay audio.
â–¡
B PARAMETERS IN DETECTION METHODS
We list the parameters of different replay detection methods here
for better understanding the modulated replay attack.
(1) Constant Q Cepstral Coefficients (CQCC) based method.
The Constant-Q Transform (CQT) is applied with a maximum fre-
quency of ğ¹ğ‘šğ‘ğ‘¥ = ğ‘“ğ‘ /2 = 48ğ‘˜ğ»ğ‘§. The minimum frequency is set
to ğ¹ğ‘šğ‘–ğ‘› = ğ¹ğ‘šğ‘ğ‘¥/212 = 11.7ğ»ğ‘§ (12 is the number of octaves). The
value of bins per octave is set to 96. Re-sampling is applied with a
sampling period of ğ‘‘ = 16. The dimension of the CQCC features is
19. Experiments were performed with all possible combinations of
static and dynamic coefficients.
(2) Mel Frequency Cepstral Coefficents (MFCC) based method.
The window length is set to 3072 samples (32 ms), and the window
shift is 1536 samples (16 ms). Thus, the frequency bins would be
4096 samples. When we create the triangular mel-scale filterbanks,
the number of filterbanks is 26. The length of each filter is set to
2049. The sampling rate in experiments is 96 kHz.
(3) Linear Predictive Cepstral Coefficients (LPCC) based method.
In the LPCC feature, the frame length is set to 1280 and the offset is
0. The threshold of the silence power is 10âˆ’4. The prediction order
in the LPC coefficients is set to 14.
(4) Mel Wavelet Packet Coefficients (MWPC) based method.
MWPC feature is based on wavelet packet transform, adapted to the
mel scale. Instead of using the energy of the frequency sub-bands,
MWPC use Teager Keiser Energy (TKE) Operator as the following
equation, Î¨(ğ‘ (ğ‘¡)) = ğ‘ (ğ‘¡)2âˆ’ğ‘ (ğ‘¡âˆ’1)ğ‘ (ğ‘¡+1). The dimension of MWPC
features is 12, derived from the principle component analysis.
(5) High-frequency sub-band power based method. High fre-
quency energy ratio is measured between (2-4) kHz and (0-2) kHz.
(6) High-frequency CQCC based method. Similar to CQCC-
based methods. But it concerns the high-frequency (2-4kHz) band.
(7) FM-AM based method. This method aim to detect the fre-
quency modulation (FM) and amplitude modulation (AM) features
in replay audio. Here, the feature vector consists of the modula-
tion centroid frequency (MCF) and modulation static energy (MSE).
Which are both extracted from modulation spectrum. The Gaussian
mixture model (GMM) is employed as the back-end classifier.
(8) Sub-bass Frequency based method. Energy balance metric
indicates the energy ratio of the sub-bass range (20-80 Hz) to the
low-frequency range (20-250 Hz). The threshold is set to 0.228
according to the study [8].
C INVERSE FILTER IMPLEMENTATION
The speaker response estimation process contains two steps: dis-
crete amplitude response measurement and continuous amplitude
response fitting. In the discrete amplitude response measurement,
we measure the speaker input/output response coefficient by test-
ing 68 discrete typical frequency values. The discrete frequency
values are within four audio frequency ranges: bass (from 60 Hz to
225 Hz with a spacing of 15 Hz), low midrange (from 250 Hz to 500
Hz with a spacing of 50 Hz), midrange (from 550 Hz to 2 kHz with a
spacing of 50 Hz), and upper midrange (from 2.1 kHz to 4 kHz with
a spacing of 100 Hz). The input test signals are single-frequency
(a) iPhone X
(b) iPad Pro
(c) Mi Phone 4
(d) Google Nexus 5
(e) Bose Soundlink Micro
(f) Samsung Smart TV
Figure 12: The amplitude response curves of different
speaker devices and their corresponding inverse filters.
signals with the same amplitude of 1, which are generated by using
the wavwrite tool and stored in a lossless format. The test audio is
then transferred to replay devices and played at medium volume
on loudspeakers, since the response function is not directly related
to the input amplitude according to our experiments. After the
spectrum analysis, we can get a rough response polygonal curve
across 68 discrete points.
In the finer-grained amplitude response fitting, we need to first
calculate the spectral resolution of the modulated signal Î”ğ‘“ = ğ‘“ğ‘ /ğ‘ ,
where ğ‘“ğ‘  is the signal sampling rate. ğ‘ is the FFT point number
which is the minimum power of 2 that is greater than or equal
to the signal length ğ¿, denoted as ğ‘ = 2âŒˆlog2 ğ¿âŒ‰. The finer-grained
amplitude response curve can be achieved by the cubic spline fitting.
And the estimated response used in the inverse filter generation is
sampled with the signal spectral resolution Î”ğ‘“ . The inverse filter
is designed by using the finer-grained speaker response ğ»(ğ‘˜). In
order to avoid divide-by-zero error in our experiments, the inverse
filter transfer function is calculated as 1/(ğ»(ğ‘˜) + ğ‘’ğ‘ğ‘ ), where ğ‘’ğ‘ğ‘ 
is a small value from 0.001 to 0.002.
Figure 12 shows the amplitude response curves of different
speaker devices and their inverse filters. For mobile devices, the
response curves are high-pass filters due to the limited size of speak-
ers. Therefore, the inverse filters should be low-pass filters. For Bose
Soundlink Micro which has a tweeter and a woofer, there are obvi-
ous two-stage enhancements in the amplitude response. However,
the transfer function still cannot be considered as a pass-through
filter. The frequency response of Samsung Smart TV fluctuates with
frequency due to its two speakers that create stereo audio. We can
 0  0.2 0.4 0.6 0.8 1.001234 0 1 2 3 4 5Frequency ResponseGainFrequency (kHz)SpeakerInverse Filter 0  0.2 0.4 0.6 0.8 1.001234 0 1 2 3 4 5Frequency ResponseGainFrequency (kHz)SpeakerInverse Filter 0  0.2 0.4 0.6 0.8 1.001234 0 1 2 3 4 5Frequency ResponseGainFrequency (kHz)SpeakerInverse Filter 0  0.2 0.4 0.6 0.8 1.001234 0 1 2 3 4 5Frequency ResponseGainFrequency (kHz)SpeakerInverse Filter 0  0.2 0.4 0.6 0.8 1.001234 0 1 2 3 4 5Frequency ResponseGainFrequency (kHz)SpeakerInverse Filter 0  0.2 0.4 0.6 0.8 1.001234 0 1 2 3 4 5Frequency ResponseGainFrequency (kHz)SpeakerInverse FilterD CLASSIFIERS IN TIME-DOMAIN DEFENSE
In the time-domain defense, the local extreme ratio (LER) is a ro-
bust feature that can describe the ringing artifacts in modulated
replay audios. Therefore, the classifier selection has little impact
on the defense performance. To verify this hypothesis, we conduct
experiments to evaluate the effects of different classifiers on the
feature classification.
We classify the LER features using five common classifiers, in-
cluding Support Vector Machine (SVM), Decision Tree (DT), Naive
Bayes (NB), Gaussian Mixture Model (GMM), and K-Star. The 10-
fold cross-validation accuracy is used as the evaluation standard.
The performance of different classifiers is shown in Figure 13. We
can see that SVM, Decision Tree, and KStar achieve better perfor-
mance than other classifiers. Gaussian Mixture Model obtains the
worst accuracy since the data distribution of LER features does
not subject to the normal distribution. Above all, we choose the
SVM model in our system due to its easy deployment and high
performance.
Figure 13: Performance of different classifiers in the time-
domain defense.
use designed inverse filters to compensate the speaker amplitude
response, mitigating the decay of frequency components.
 50 55 60 65 70 75 80 85 90 95 100SVMDecisonTree    NaiveBayesGMMKStarDetection Accuracy (%)