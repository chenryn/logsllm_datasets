startswith = \"click on \\\"查询\\\"\"
endswith = \"click on \\\"提交\\\"\"
busi_type = \"缴费\"
busi_channel = \"营业厅\"
},
{
busi_url =
\"/custsvc/business.action?BMEBusiness=rec.chgprod&\_cntRecTimeFlag=true\"
startswith = \"click on \\\"套餐变更\\\"\"
endswith = \"click on \\\"确定\\\"\"
busi_type = \"套餐变更\"
busi_channel = \"营业厅\"
},
{
busi_url =
\"/charge/business.action?BMEBusiness=charge.personalBillQry\"
startswith = \"click on \\\"查询\\\"\"
endswith = \"click on \\\"返回\\\"\"
busi_type = \"账单查询\"
busi_channel = \"营业厅\"
}
\]
####### 5.2.3告警
目前日志分析软件提供事件数告警、字段统计告警、连续统计告警和基线对比告警四种告警模式。
(1)事件数告警
用户可以创建基于搜索结果的告警触发条件，在一个给定的时间范围内触发告警的阈值数。例如，用户可以设置告警条件为5分钟内搜索结果计数超过10次（基于时间戳）：
(2)字段统计告警
字段统计告警为用户提供针对字段内容的告警设置，在触发条件中用户需要填写字段名，统计方式可以在下拉框中选择，cardinality（独立计数）、sum
（求和）、avg（平均值）、max（最大值）、min（最小值）。
例如，告警触发条件为：clientip在5分钟之内某个ip的计数值超过10，则设定如下：
(3)连续统计告警
连续告警为用户提供连续触发告警功能，即当某个告警条件在某个时间内连续触发次数达到阀值，才触发告警。
例如，告警触发条件为：apache.status在1小时之内超过404的次数超过50，则触发告警，则设定如下：
(4)基线对比告警
基线告警是将阈值设定为一个统计的基线值（随时间变动），用户需要选择基线生成的时间范围，同时，基线对比告警给用户提供了更灵活的触发范围设定方式------用户可以在下拉框中选择大于、小于、在区间内、在区间外。
例如，resp_len如果与上周的统计平均值相比，小于基线值50%或者超过基线值150%即触发告警，设定的告警条件如下：
(5)通知方式
用户可以配置收到告警通知的邮箱地址，需要提醒的是用户只能在该账户下已注册的电子信箱中进行选择。
![https://www.rizhiyi.com/img/rzy/doc/howtouse/alert-9.jpg](media/image2.jpeg){width="8.135416666666666in"
height="0.53125in"}
（6）检测频率
设置运行搜索的周期，我们将把搜索结果和用户设置的告警条件进行匹配。例如：用户设置检测频率为5分钟，后台将每5分钟执行一次，如果执行结果符合告警条件设置的阈值，我们将推送一次告警邮件。
###### 5.3 海量数据的流式处理是大数据平台数据处理部分的核心，需要支持万级eps数据的处理
索引集群是一个的分布式搜索引擎，具备高可靠性和高性能。支持时间文本索引和全文检索，提供丰富的api用于索引、检索、修改大多数配置。能够快速搜索数百亿的日志以及TB级的数据，结构化或者非结构化的数据都可以。
集群由2台及2台以上节点组成，其中一个为主节点，节点通过选举产生，主从节点是对于整个集群内部来说的，从外部来看整个集群，逻辑上是一个整体，与任何一个节点的通信和与整个集群通信是完全一致的。集群自动创建索引，通过配置我们可以非常方便的调整索引分片和索引副本。通过索引分片技术，一个大的索引被拆分成多个，然后分布在不同的节点上，以构成分布式搜索。索引副本的作用一是提供系统的容错性，当摸个节点摸个分片损毁或丢失时，可以从副本中恢复；二是提供查询效率，集群内部会自动实现搜索请求的负载均衡。
**功能特点：**
（1）[集群](http://baike.baidu.com/view/302477.htm)部署，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。搜索引擎的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看搜索引擎集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。
（2）索引分片，搜索引擎可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。
（3）副本，搜索引擎可以设置多个索引的副本，副本的作用一是提高系统的[容错性](http://baike.baidu.com/view/2700299.htm)，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高搜索引擎的查询效率，搜索引擎会自动对搜索
请求进行负载均衡。
（4）数据恢复或叫数据重新分布，搜索引擎在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。
（5）数据源，也是其它存储方式（如：数据库）同步数据到搜索引擎的一个方法。它是以插件方式存在的一个搜索引擎服务，通过读取数据源中的数据并把它索引到搜索引擎中。
（6）索引快照的存储方式，搜索引擎默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。对索引快照进行存储，当这个搜索引擎集群关闭再重新启动时就会从中读取索引备份数据。搜索引擎支持多种类型的存储方式，有本地文件系统（默认），[分布式文件系统](http://baike.baidu.com/view/771589.htm)。
（7）自动发现节点机制，搜索引擎是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过[多播](http://baike.baidu.com/view/378050.htm)协议来进行节点之间的通信，同时也支持[点对点](http://baike.baidu.com/view/1145124.htm)的交互。
（8）内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、[thrift](http://baike.baidu.com/view/1698865.htm)、servlet、memcached、zeroMQ等的[传输协议](http://baike.baidu.com/view/441895.htm)（通过[插件](http://baike.baidu.com/view/18979.htm)方式集成）
###### 5.4 并可以通过设备横项扩展，增加平台的数据接入性能
在硬件系统资源得到保障的前提下，系统原则上可以无限扩展，每天的数据存为一个索引文件，拆分分块到集群的各个节点上，因此索引文件为分布式存储，支持水平扩展，并且有副本，保障高可用。
##### 6. 海量数据搜索引擎
###### 6.1灵活的对各种类型业务数据进行结构化字段提取
实时流处理平台内置了常用的日志解析规则，能够识别、解析常见的日志格式。对于平台预置规则不支持的日志格式，用户可以在产品页面的"设置"标签下的"日志格式"标签里配置日志格式解析规则，抽取自定义字段。
event（事件）: 一条日志称为一个事件
timestamp（时间戳）:
这里的timestamp指日志本身的时间戳而不是进入系统的时间戳
field（字段）:
即通过日志分析软件系统抽取出来的字段，由字母数字下划线组成，例如apache中clientip字段
appname：appname用来标识一个日志格式，由字母数字下划线组成，在上传日志的时候需要指定对应的appname
logtype：logtype可以认为是给用户的日志格式起的一个别名，同样也由字母数字下划线组成（不能设置为security,
appname, hostname, timestamp, tag, raw_message,
index）用户在左侧字段栏和搜索栏中可以通过logtype.field来引用。
**功能特点：**
（1）日志的解析
日志解析的主要作用是抽取用户认为重要的字段，这就需要用户熟悉解析规则的配置。例如这样一条日志：
192.168.1.103 - - \[01/Aug/2014:12:07:39 +0800\] \"GET / HTTP/1.1\\\"
200 3228 \"-\" \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1;
Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR
3.5.30729; .NET CLR 1.1.4322; .NET4.0C)\"
要抽取出如下字段：
1 \"ua\" : \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1;
Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR
3.5.30729; .NET CLR 1.1.4322; .NET4.0C)\"
1.1 \"os\" : \"Windows XP\"
1.2 \"os_v\" : \"Windows XP\"
1.3 \"browser\" : \"IE\"
1.4 \"browser_v\" : \"IE 8.0\"
1.5 \"device\" : \"Other\"
2 \"clientip\" : \"192.168.1.103\"
3 \"status\" : 200
4 \"resp_len\" : 3228
5 \"method\" : \"GET\"
6 \"version\": \"1.1\"
（2）正则解析
正则是处理文本解析的有力工具
例如有这样一条日志：
2014-05-14 23:24:47 15752 \[Note\] InnoDB: 128 rollback segment(s) are
active
我们希望提取出以下字段：timestamp，pid，loglevel和message，可以配置如下的表达式：
(?\\\S+ \\S+) (?\\\S+) \\\[(?\\\S+\\\]
(?\.\*)
其中
\\S表示匹配非空格字符，\\S+表示匹配连续的非空格字符，(?\value)
表示提取名字为key的字段，其值为value，会解析出如下字段：
1 timestamp：2014-05-14 23:24:47
2 pid：15752
3 loglevel：Note
4 message：InnoDB: 128 rollback segment(s) are active
除了正常的正则表达式，我们还提供了一些常用的正则表达式，可以通过%{XXX}的方式来引用。比如可以使用%{NOTSPACE}来代替\\S+，这样的正则表达式为：
(?\%{NOTSPACE} %{NOTSPACE}) %{NOTSPACE:pid}
\\\[%{NOTSPACE:loglevel}\\\] %{GREEDYDATA:message}
默认的字段值是string类型的，如果用户想将其转换为number类型，可以在引用中加入type类型，目前仅支持int和float类型，例如：
%{XXX:int} 或者 %{XXX:float}
常用的正则表达式
1 基本：
%{NUMBER} (?:%{BASE10NUM})
%{POSINT} \\b(?:\[1-9\]\[0-9\]\*)\\b
%{NONNEGINT} \\b(?:\[0-9\]+)\\b
%{WORD} \\b\\w+\\b
%{NOTSPACE} \\S+
%{SPACE} \\s\*
%{MORESPACE} \\s+
%{DATA} .\*?
%{GREEDYDATA} .\*
%{IP} 略
%{PORT} 略
2 Apache/Nginx：
%{ApcClientIP}
%{ApcIdent}
%{ApcUser}
%{ApcTimestamp｝
%{ApcStatus}
%{ApcRespLen}
%{ApcReferer}
%{ApcUa}
%{ApcXForward}
%{ApcRequest}
例如原始日志:
192.168.1.139 - - \[24/Jan/2015:17:03:49 +0800\] \"GET
/api/v0/search/fields/?field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
HTTP/1.1\" 200 363
\"http://alltest.rizhiyi.com/search/?query=\*&time_range=-2d%2Cnow&order=desc&size=20&page=1&sourcegroup=all&type=timeline&\_t=1422088066859&title=%E9%BB%98%E8%AE%A4&index=0\"
\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:35.0) Gecko/20100101
Firefox/35.0\"
可以采用如下配置：
%{ApcClientIP} %{ApcIdent} %{ApcUser} %{ApcTimestamp} %{ApcRequest}
%{ApcStatus} %{ApcRespLen} %{ApcReferer} %{ApcUa}
（3）KeyValue分解
KV主要用来解析明显的KV字符串，例如上面的例子中正则表达式解析后，request_query字段为：
field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
这是一个按照\"&\"和\"＝\"来分割的KV字段。添加解析规则：KeyValue分解，source字段选择request_query，定义字段间分隔符为&，定义k-v分隔符为=。
（4）数值型字段转换
默认提取出来的字段都是字符串类型的。如果用户希望将这个值转换成数值类型，以方便再后面做统计，则需要通过这个功能来做转换。转换时需要用户配置数值的类型：int/float
例如： 用户的日志经过解析得出如下字段：
k1: \"123\",
k2: \"123.0\"
经过转换可以转变为：
k1: 123,
k2: 123.0
（5）url解码