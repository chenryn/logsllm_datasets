that only load from their own domain).
Of course, a site’s home page may not be representative of its
entire contents. So, as a further test we traversed large sections of
a major news site (www.cbc.ca) and determined that the number
of domains needed in the manifest was approximately 45; this value
was close to the 33 needed for that particular site’s home page.
Given the remarkable diversity of the Internet, there probably
exist sites today that would require extremely large manifest ﬁles.
This cursory survey, however, gives evidence that manifests for
common sites would be relatively small.
5.5.3 Content provider sites: Approval ﬁles
Approvals result in tiny amounts of data being transferred: either
a YES or NO response (around 4 bytes of data) plus any necessary
headers.
Using data from the top 500 Alexa sites [2], we examined 3244
cases in which a content provider served data to an origin site.
The average request size was 10459 bytes. Because many content
providers are serving up large video, however, the standard devia-
tion was fairly large: 118197 bytes. The median of 2528 bytes is
much lower than the average. However, even this smaller median
dwarfs the 4 bytes required for a soma-approval response. As
such, we feel it safe to say that the additional network load on con-
tent providers due to SOMA is negligible compared to the data they
are already providing to a given origin site.
6. RELATED WORK
Web-based execution environments have all been built with the
understanding that unfettered remote code execution is extremely
dangerous. SSL and TLS can protect communication privacy, in-
tegrity, and authenticity, while code signing [30, 35] can prevent the
execution of unauthorized code; neither, however, protect against
the execution of malicious code within the browser. Java [8] was
the ﬁrst web execution environment to employ an execution sand-
box [39] and the same origin policy for restricting network commu-
nication. Subsequent systems for executing code within a browser,
including JavaScript, have largely followed the model as originally
embodied in Java applets.
While there has been considerable work on mitigating the fail-
ures of language-based sandboxing [18] and on sandboxing other,
less trusted code such as browser plugins and helper applications
[12], only recently have researchers begun addressing the limita-
tions of sandboxing and same origin policy with respect to JavaScript
applications.
Many researchers have attempted to detect and block malicious
JavaScript. Some have proposed to instrument JavaScript automat-
ically to detect known vulnerabilities [29], while others have pro-
posed to ﬁlter JavaScript to prevent XSS [19] and XSRF [17] at-
tacks. Another approach has been to perform dynamic taint track-
ing (combined with static analysis) to detect the information ﬂows
associated with XSS attacks [38].
Instead of attempting to de-
tect dangerous JavaScript code behaviour before it can compromise
user data, SOMA prevents unauthorized cross-domain information
ﬂows using site-speciﬁc policies.
Recently several researchers have focused on the problem of web
mashups, which may be created on the client or server. Client-
side mashups are composite JavaScript-based web pages that draw
functionality and content from multiple sources. To make these
mashups work within the conﬁnes of same origin policy, remote
content must either be separated into different iframes or all code
must be loaded into the same execution context. The former so-
lution is in general too restrictive while the latter is too permis-
sive; client-side mashup solutions are designed to bridge this gap.
Two pioneering works in this space are Subspace [16] and Mashu-
pOS [14, 40]. SOMA restricts communication between the web
page (browser) and servers while mashup solutions restrict local
communication between elements on the page.
SOMA breaks client-side mashups which use unapproved code.
In order for a mashup to work with SOMA, every web site involved
must explicitly allow participation. While such restrictions may in-
hibit the creation of novel, third party mashup applications, they
also prevent attackers from creating malicious mashups (e.g., com-
binations of a legitimate bank’s login page and a malicious login
box). Given the state of security on the modern web, we believe
such a trade-off is beneﬁcial and, moreover, necessary. SOMA does
not affect server-side mashups.
While the general problem of unauthorized information ﬂow is
a classic problem in computer security [10], little attention has
been paid in the research community to the problems of unautho-
rized cross-domain information ﬂow in web applications beyond
the strictures of same origin policy—this, despite the fact that XSS
and XSRF attacks very heavily rely upon such unauthorized ﬂows.
Of course, the web was originally designed to make it easy to em-
bed content from arbitrary sources. With SOMA, we are simply
advocating that any such inclusions should be approved by both
parties.
While SOMA is a novel proposal, we based the design of
soma-approval and soma-manifest on existing systems.
The soma-approval mechanism was
inspired by the
crossdomain.xml [1] mechanism of Flash. External content
may be included in Flash applications only from servers with a
crossdomain.xml ﬁle [1] that lists the Flash applications’ orig-
inating server.
logic behind a
soma-approval request can be arbitrarily complex, we have
chosen to specify that it be a server-side script rather than an XML
ﬁle that must be parsed by a web browser.
response
Because
the
The soma-manifest ﬁle was inspired by Tahoma [7], an ex-
perimental VM-based system for securing web applications. Tahoma
allows users to download virtual machine images from arbitrary
servers. To prevent these virtual machines from contacting unau-
thorized servers (e.g., when a virtual machine has been compro-
mised), Tahoma requires every VM image to include a manifest
specifying what remote sites that VM may communicate with.
Note that by themselves Flash’s crossdomain.xml and
Tahoma’s server manifest do not provide the type of protection pro-
vided by SOMA. With Flash, a malicious content provider can al-
ways specify a crossdomain.xml ﬁle that would allow a com-
promised Flash program to send sensitive information to the at-
tacker. With Tahoma, a malicious origin server can specify a man-
ifest that would cause a user’s browser to send data to an arbitrary
web site, thus causing a denial-of-service attack or worse. By in-
cluding both mechanisms, we address the limitations of each.
Subsequent to our preliminary report [25], B. Sterne of Mozilla
introduced a related proposal called Site Security Policy (SSP) [36]
which is still in development. Another related proposal by Schuh
[33] involves the browser enforcing ﬁrewall-style rulesets provided
by the origin.
7. DISCUSSION AND CONCLUSION
Most JavaScript-based attacks require that compromised web
pages communicate with attacker-controlled web servers. Here we
propose an extension to same origin policy—the same origin mu-
tual approval (SOMA) policy—which restricts cross-domain com-
munication to a web page’s originating server and other servers that
mutually approve of the cross-site communication. By prevent-
ing inappropriate or unauthorized cross-domain communication,
attacks such as cross-site scripting and cross-site request forgery
can be blocked.
The SOMA architecture’s beneﬁts versus other JavaScript de-
fences include: 1) it is incrementally deployable with incremen-
tal beneﬁt; 2) it imposes no conﬁguration or usage burden on end
users; 3) the required changes in browser functionality and server
conﬁguration affect those who have the most reason to be con-
cerned about security, namely the administrators of sensitive web
servers and web browser developers; 4) these changes are easy to
understand, simple to implement technically, and efﬁcient in exe-
cution; and 5) it gives server operators a chance to specify what
sites can interact with their content. While SOMA does not prevent
attackers from injecting JavaScript code, with SOMA such code
cannot leak information to attackers without going through an ap-
proved server.
We believe that SOMA represents a reasonable and practical
compromise between beneﬁts (increased security) and costs (adop-
tion pain). Perhaps more signiﬁcantly, our proposal of the SOMA
architecture highlights that the ability to create web pages using ar-
bitrary remote resources is a key enabling factor in web security
exploits (including some techniques used in phishing). While other
JavaScript defences will no doubt arise, we believe that among the
contributions of this paper are a focus on the underlying problem,
namely, deﬁciencies in the JavaScript same origin policy, and the
identiﬁcation of several important characteristics of a viable solu-
tion.
It is easy to dismiss any proposal requiring changes to web in-
frastructure; however, there is precedence for wide scale changes
to improve security. Indeed, much as open email relays had to be
restricted to mitigate spam, we believe that arbitrary content inclu-
sions must be restricted to mitigate cross-site scripting and cross-
site request forgery attacks. We hope this insight helps clarify the
threats that must be considered when creating next-generation web
technologies and other Internet-based distributed applications.
Acknowledgements. The ﬁrst and second authors acknowledge
NSERC for funding their PGS D scholarships. The third author
acknowledges NSERC for an NSERC Discovery Grant and his
Canada Research Chair in Network and Software Security. The
fourth author acknowledges an NSERC Discovery Grant. We also
thank RIM and NSERC ISSNet for partial funding, as well as anony-
mous referees for their comments.
8. REFERENCES
[1] Adobe Systems Incorporated. External data not accessible
outside a Macromedia Flash movie’s domain. Technical
Report tn_14213, Adobe Systems Incorporated, Feb 2006.
[2] Alexa top 500 sites. Web page (viewed 14 Apr 2008).
http://www.alexa.com/site/ds/top_sites?
ts_mode=global&lang=none.
[3] R. Auger. The cross-site request forgery (CSRF/XSRF) FAQ.
Web page, Jan 2007. http://www.cgisecurity.
com/articles/csrf-faq.shtml.
[4] R. Berends. Bandwidth stealing. Web page, Apr 2001.
http://www.website-awards.net/articles/
article39.htm.
[5] CERT advisory CA-2000-02 malicious HTML tags
[24] A. D. Miglio. “Referer" ﬁeld used in the battle against online
embedded in client web requests. Web page, Feb 2000.
http://www.cert.org/advisories/
CA-2000-02.html.
[6] The cross site scripting (XSS) FAQ. Web page, Aug 2003.
http://www.cgisecurity.com/articles/
xss-faq.shtml.
[7] R. S. Cox, J. G. Hansen, S. D. Gribble, and H. M. Levy. A
safety-oriented platform for web applications. In Proc. IEEE
Symposium on Security and Privacy, pages 350–364, 2006.
[8] D. Dean, E. Felten, and D. Wallach. Java security: From
HotJava to Netscape and beyond. In Proc. IEEE Symposium
on Security and Privacy, pages 190–200, 1996.
[9] S. DeDeo. Pagestats extension. Web page, May 2006.
http://www.cs.wpi.edu/~cew/pagestats/.
fraud. Web page, Jan 2008.
http://www.symantec.com/enterprise/
security_response/weblog/2008/01/
referer_field_used_in_the_batt.html.
[25] T. Oda, G. Wurster, P. van Oorschot, and A. Somayaji.
SOMA: Mutual approval for included content in web pages.
Technical Report TR-08-07, School of Computer Science,
Carleton University, Apr 2008.
[26] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Monrose.
All your iframes point to us. In Proc. 17th USENIX Security
Symposium, Aug 2008.
[27] N. Provos, D. McNamee, P. Mavrommatis, K. Wang, and
N. Modadugu. The ghost in the browser: Analysis of
web-based malware. In Proc. HotBots ’07, 2007.
[10] D. E. Denning. A lattice model of secure information ﬂow.
[28] J. Reimer. Microsoft apologizes for serving malware. Ars
Communications of the ACM, 19(2):236–243, 1976.
Technica, Feb 2007.
[11] E. W. Felten and M. A. Schneider. Timing attacks on web
[29] C. Reis, J. Dunagan, H. J. Wang, O. Dubrovsky, and
privacy. In Proc. 7th ACM CCS, pages 25–32, 2000.
[12] I. Goldberg, D. Wagner, R. Thomas, and E. Brewer. A secure
environment for untrusted helper applications (conﬁning the
wily hacker). In Proc. 6th USENIX Security Symposium,
1996.
[13] J. Grossman and T. Niedzialkowski. Hacking intranet
websites from the outside – JavaScript malware just got a lot
more dangerous. In Blackhat USA, Aug 2006.
S. Esmeir. BrowserShield: Vulnerability-driven ﬁltering of
dynamic HTML. In Proc. IEEE Symposium on Security and
Privacy, May 2006.
[30] A. Rubin and D. Geer. Mobile code security. IEEE Journal
on Internet Computing, 2(6):30–34, 1998.
[31] J. Ruderman. The same origin policy. Web page, Aug 2001.
http://www.mozilla.org/projects/
security/components/same-origin.html.
[14] J. Howell, C. Jackson, H. Wang, and X. Fan. MashupOS:
[32] B. Schiffman. Rogue anti-virus slimeballs hide malware in
Operating system abstractions for client mashups. In Proc.
Workshop on Hot Topics in Operating Systems, May 2007.
[15] C. Jackson, A. Barth, A. Bortz, W. Shao, and D. Boneh.
Protecting browsers from DNS rebinding attacks. In Proc.
14th ACM CCS, 2007.
ads. Wired, Nov 2007.
[33] J. Schuh. Same-origin policy part 2: Server-provided
policies? Web page, Feb 2007.
http://taossa.com/index.php/2007/02/17/
same-origin-proposal/.
[16] C. Jackson and H. J. Wang. Subspace: secure cross-domain
[34] T. Scott. Smarter image hotlinking prevention. A List Apart,
communication for web mashups. In Proc. 16th International
World Wide Web Conference, pages 611–620, 2007.
[17] N. Jovanovic, E. Kirda, and C. Kruegel. Preventing cross site
request forgery attacks. In Proc. 2nd IEEE Conference on
Security and Privacy in Communication Networks
(SecureComm), Aug 2006.
[18] K. Keahey, K. Doering, and I. Foster. From sandbox to
playground: Dynamic virtual environments in the grid. In
Proc. 5th IEEE/ACM International Workshop on Grid
Computing, pages 34–42, 2004.
[19] E. Kirda, C. Kruegel, G. Vigna, and N. Jovanovic. Noxes: A
client-side solution for mitigating cross site scripting attacks.
In Proc. 21st ACM Symposium on Applied Computing, Apr
2006.
[20] J. Kyrnin. Are you invading your customers’ privacy? Web
page (viewed 14 Apr 2008). http://webdesign.
about.com/od/privacy/a/aa112601a.htm.
[21] V. T. Lam, S. Antonatos, P. Akritidis, and K. G.
Anagnostakis. Puppetnets: misusing web browsers as a
distributed attack infrastructure. In Proc. 13th ACM CCS,
pages 221–234, 2006.
[22] G. Maone. NoScript - JavaScript/Java/Flash blocker for a
safer Firefox experience! Web page (viewed 14 Apr 2008).
http://noscript.net/.
[23] Microsoft. Mitigating cross-site scripting with HTTP-only
cookies. Web page (viewed 18 Jul 2008).
http://msdn.microsoft.com/en-us/library/
ms533046.aspx.
Apr 2004.
[35] R. Sekar, C. R. Ramakrishnan, I. V. Ramakrishnan, and S. A.
Smolka. Model-carrying code (MCC): a new paradigm for
mobile-code security. In Proc. 2001 NSPW, pages 23–30,
Sep 2001.
[36] B. Sterne. Site security policy draft (version 0.2). Web Page,
Jul 2008.
http://people.mozilla.org/~bsterne/
site-security-policy/details.html.
[37] L. Tauscher and S. Greenberg. How people revisit web
pages: empirical ﬁndings and implications for the design of
history systems. In International Journal of Human
Computer Studies, 1997.
[38] P. Vogt, F. Nentwich, N. Jovanovic, C. Kruegel, E. Kirda,
and G. Vigna. Cross site scripting prevention with dynamic
data tainting and static analysis. In Proc. 14th NDSS
Symposium, Feb 2007.
[39] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham.
Efﬁcient software-based fault isolation. SIGOPS Operating
System Review, 27(5):203–216, 1993.
[40] H. J. Wang, X. Fan, C. Jackson, and J. Howell. Protection
and communication abstractions for web browsers in
MashupOS. In 21st ACM SOSP, Oct 2007.
[41] WordPress.org. Enable sending referrers. Web page (viewed
14 Apr 2008). http://codex.wordpress.org/
Enable_Sending_Referrers.