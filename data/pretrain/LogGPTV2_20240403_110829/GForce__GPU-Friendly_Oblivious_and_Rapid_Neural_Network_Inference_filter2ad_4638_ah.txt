expr modulo 2(cid:96), i.e., expr mod 2(cid:96).
We ﬁrst consider the case that z does not wrap around, i.e.,
z = y− x + 2(cid:96) + τ  β) = (cid:98)(y−
x + τ2(cid:96))/2(cid:96)(cid:99) +(cid:98)τ/2(cid:96)(cid:99)−(cid:98)τ/2(cid:96)(cid:99) + (1− (α > β)) = (cid:98)(y− x +
τ2(cid:96))/2(cid:96)(cid:99) + (α ≤ β). We denote (cid:98)(y− x + τ2(cid:96))/2(cid:96)(cid:99) by ∆, so
(x ≤ y)(cid:48) = ∆ + (α ≤ β).
Since x,y∈ (−2(cid:96)−1,2(cid:96)−1), we have −2(cid:96) +1  β(cid:105)2 + wrap =
(cid:98)(y − x + 2(cid:96) + τ − q)/2(cid:96)(cid:99) − (cid:98)τ/2(cid:96)(cid:99) − (cid:104)α > β(cid:105)2 + (cid:98)q/d(cid:99) =
((cid:98)(y− x + τ2(cid:96) + q2(cid:96))/2(cid:96)(cid:99) + 1 +(cid:98)τ/2(cid:96)(cid:99)−(cid:98)q/2(cid:96)(cid:99))−(cid:98)τ/2(cid:96)(cid:99)−
(cid:104)α > β(cid:105)2 +(cid:98)q/d(cid:99) = (cid:98)(y− x + τ2(cid:96) + q2(cid:96))/2(cid:96)(cid:99) +(cid:104)α ≤ β(cid:105)2. Re-
call that we have imposed a constraint q2(cid:96) = 1 and that
(α ≤ β) = (r2(cid:96) ≤ (y− x + τ2(cid:96) + q2(cid:96))2(cid:96)). We can rewrite (x ≤
y)(cid:48) = (cid:98)((y +1)−x +τ2(cid:96))/2(cid:96)(cid:99) +(cid:104)r2(cid:96) ≤ ((y +1)−x +τ2(cid:96))2(cid:96)(cid:105)2.
This is equivalent to (x ≤ (y + 1))(cid:48) with no wrap around,
whose correctness has been proven above. Hence, (x ≤ y)(cid:48) =
(x ≤ (y + 1)), which is wrong only when x = y.
C Security of Cryptographic Building Blocks
C.1 Additive Secret Sharing
(2,2)-additive SS leaks no information of the secret (except its
domain). Formally, there exists a PPT simulator Sim such that
p and role ∈ {S, C}.
(cid:104)m(cid:105)role ≈ Sim(Zn
p), for any secret m ∈ Zn
C.2 Additive Homomorphic Encryption
C.2.1 Semantic Security and Circuit Privacy
AHE schemes possess the following security properties.
Semantic security requires that any PPT adversary can-
not distinguish the plaintext of a ciphertext. More for-
mally, (pk, AHE.Enc(pk,m0)) ≈c (pk, AHE.Enc(pk,m1)) for
any messages m0 and m1. The views are distributed over the
choices of public key pk and the random coins of AHE.Enc.
Circuit privacy requires that any PPT adversary, even
holding the secret key of AHE, cannot learn anything about
the homomorphic operations f performed on an AHE
ciphertext except what can be inferred by the message, i.e.,
f (m). In other words, there exists a PPT simulator Sim such
(sk,pk,{mi}i∈[1:n], f ({mi}i∈[1:n]),{cti}1∈[1:n], ct(cid:48)) ≈c
that
{cti =
Sim(sk,pk,{mi}1∈[1:n], f ({mi}1∈[1:n])), where
AHE.Enc(pk,mi)}i∈[1:n], ct(cid:48) = AHE.Eval(pk,{mi}i∈[1:n], f )),
n < poly(λ), and f is a linear function.
C.2.2 Noise Flooding
Our implementation adopts BFV-FHE [8] as the AHE scheme
for ofﬂine preprocessing. However, the “textbook” BFV-FHE
scheme does not preserve circuit privacy because the secret
key holder may be able to extract information about the homo-
morphic operations performed on a ciphertext. Very roughly,
the culprit is the noise e it uses to hide the plaintext. The cor-
responding defense is noise ﬂooding [1]. Before S sends the
ciphertext to C for decryption, we add an extra huge “smudg-
ing” noise in the ciphertext to smudge out the distribution of
the original output noise f (e). By the smudging lemma [1],
the smudging noise in any two ciphertexts produced by the
same protocol will have a statistical distance of 2−λ if the
smudging noise is λ bit larger than the original output noise.
Although the exact parameters in the linear function f are
secret of S and they may be uncertain before the actual exe-
cution of the protocol, we still can evaluate Beval, the bound
of the noise’s magnitude | f (e)|. Then, we deﬁne the bound
of the smudging noise to be Bsmud ≥ 2λ · Beval. The smudg-
ing noise esmud = (esmud
) are uniformly sampled from
[−Bsmud,Bsmud]2. The smudged ciphertext is f (c) + esmud.
,esmud
1
2
C.2.3 An Estimation of the Noise Bound
Our implementation has two sets of (n, p) where n is the
degree of the ciphertext polynomial and Zp is the underly-
ing ﬁeld. We use (16384,65537) in SC-DGK since it com-
putes at the bit level and (16384,7340033) for the rest (e.g.,
GPU-DGK) of the ofﬂine phase (which is denoted by Zq here).
√
According to the manual of SEAL [12], a (loose) noise bound
2π).
of a newly encrypted ciphertext is BEnc = np(p + 336/
Their corresponding BEnc is of 44 bits and 51 bits.
SEAL’s manual [12] suggests the noise bound after these
operations is BEval = BEnc · knp, where k is the number of
addition over the ciphertexts. For our DGK bit-comparison
protocol, k roughly equals the bit-length (cid:96) ≈ 20. Hence, BEval
is about 78 bits. The largest k occurs in our VGG-16’s fully-
connected layer, which is up to k ≈ 210, and the corresponding
2162    30th USENIX Security Symposium
USENIX Association
BEval is about 98 bits.
For 128-bit security, as suggested by the smudging
lemma [1], we add extra 128 bits to the noise bound BEval for
smudging noise, meaning that BSmud should be at least 206
for DGK bit-comparison and 226 for the other protocols. For
128-bit security and n = 16384, we follow SEAL’s recommen-
dation to pick a 438-bit coefﬁcient modulus. BSmud should
be smaller than it to prevent incorrect decryption. Hence, we
set BSmud to be 330 bits to leave a safety margin for security
while avoiding BSmud being too large for correct decryption.6
D Security Proofs for Our Protocols
We use the simulation-based security deﬁnition for two-party
computation. Our goal is to exhibit a PPT simulator Simrole
for party role ∈ {S, C} taking its private input inrole, its private
output outrole, and the leakage leakrole it could learn from the
protocol to be proven, which can generate a view computation-
ally indistinguishable from Viewrole, its view in a real protocol
invocation, i.e., Viewrole ≈c Sim(inrole, outrole, leakrole).
Due to the page limit, we only show the security proof of
our AHE-to-SOS transformation for its central role in GForce,
which leads to the proof for the GForce as a whole. For other
protocols, we mostly only highlight the intuition for the simu-
lation or rely on the security arguments of the original proto-
cols in the respective papers.
D.1 Security of AHE-to-SOS Transformation
Theorem 4. The protocol obtained from our AHE-to-SOS
transformation remains secure against a semi-honest server or
client in that it does not leak more than the original protocol.
Security Proof against a Corrupted Client. The simulator
Sim(inC, outC, leakC) can be constructed with leakage leakC
being empty. Namely, the private input inC of C is χC and
its private output (cid:104) f (χ)(cid:105)C, which comes from decrypting the
only protocol message [(cid:104) f (χ)(cid:105)C] it receives from S, can be
simulated by randomly picking a secret share (cid:104) f (χ)(cid:105)C from
an appropriate domain and encrypting it under pkAHE.
We remark that this is a sub-protocol in which the client
would probably be interacting with server S that takes the
private output outS of the server as an input in a subsequent
step. In this case, eventually, we need outS to simulate the
subsequent view of the client (otherwise, the private output to
the client is just a random value). This can be easily simulated
by using the knowledge of f (χ) by outS = f (χ)−(cid:104) f (χ)(cid:105)C.
Security Proof against a Corrupted Server. The simulator
Sim(inS, outS, leakS) can be constructed with leakage leakS
being empty. Suppose the private server input is (cid:104)χ(cid:105)S, and
the server randomness is rS. S sees two protocol messages.
The ﬁrst one [rC] can be simulated by encryption of a dummy
plaintext (e.g., 0) of the same size, which remains indistin-
guishable to S since S does not have the decryption key. The
second protocol message can be easily simulated by randomly
picking an element Y from an appropriate domain.
The corresponding private output of the client can be sim-
ulated given the knowledge of f (·) and f (χ) by outC =
f (χ)− f ((cid:104)χ(cid:105)S +Y ) + rS since the simulated view based on Y
and the server randomness rS will make the server computes
outS = f ((cid:104)χ(cid:105)S +Y )− rS.
D.2 Security of SC-DGK, DGK, and Comp
Theorem 5. The vanilla DGK, Protocol 5, and its SOS ver-
sion, Protocol 1, are secure against a semi-honest PPT cor-
rupted server or client that learns nothing more than its input.
The proof of Protocol 5 can be found in the original pa-
per [7]. Since Lines 5-9 of Protocol 5 can be aggregated into
a linear function, we can use our AHE-to-SOS transformation
to produce Protocol 1, which is secure by Theorem 4.
Theorem 6. Protocol 6 is secure against a semi-honest PPT
corrupt server or client that learns nothing more than its input.
Protocol 6 slightly modiﬁes the existing protocol of Veu-
gen [26] and can be proven secure in a similar manner.
D.3 Security of GPU-Wrap and GPU-Trun
Theorem 7. GPU-Wrap and GPU-Trun (Protocols 3-4) are
secure against any semi-honest, computationally bounded,
corrupted server or client, i.e., either one cannot learn anything
other than its input and the corresponding protocol output.
We have PPT simulators Sim-WrapS(), Sim-WrapC(),
Sim-TrunS(d), Sim-TrunC(d), which simulate the respec-
tive view of the server and of the client in GPU-Wrap and
GPU-Trun, respectively, where d is the (public) divisor for
truncation. The proof is deferred to the full version.
D.4 Security of GPU-DGK
Theorem 8. GPU-DGK (Protocol 2), as the SOS version
of Comp (Protocol 6), is secure against a semi-honest PPT
corrupt server or client that learns nothing more than its input.
6Our security model assumes the client to be semi-honest. When C is
malicious, noise ﬂooding may provide less protection than expected. A
malicious client may pick an initial noise larger than the protocol speciﬁed
for encryption, making our estimation on the noise bound too small. The
smudging noise cannot provide sufﬁcient obfuscation in this case.
We ﬁrst note that Comp (Protocol 6) can be viewed as
the secure computation of a linear function deﬁned over the
private server input ([x], [y]) because both of its sub-protocols
DGK() and Wrap() can be expressed as a linear function.
USENIX Association
30th USENIX Security Symposium    2163
• Hyb0: We start from the real-world protocol and assume
that the simulator SimC knows C’s view.
• Hyb1: The simulator does not receive the (additive SS of)
outputs of all SRT, ReLU, and maxpool layers. Instead,
it invokes the simulators of GPU-DGK and Beaver’s
trick to generate the views for ReLU and maxpool lay-
ers as Hyb2 in the security proof for a corrupted server.
For the SRT layers, it provides {di} to the simulator for
GPU-Trun, similar to Hyb1 in the security proof for a
corrupted server, to generate the view.
• Hyb2: The simulator does not receive the (additive SS
of) outputs of all linear layers. It treats the linear layers
as linear functions and calls the simulator of our AHE-
to-SOS transformation, which does not need the input
of {Mi}, to generate the resulting additive SS.
Protocol 2 is almost an AHE-to-SOS transformed version
of Protocol 6. The difference is that Protocol 2 takes additive
SS as inputs, i.e., (cid:104)x(cid:105) and (cid:104)y(cid:105). We can still view the private
function f () of S, which is the private input of S, as expressed
in the form of (cid:104)x(cid:105)S and (cid:104)y(cid:105)S since the only operations over
them in Protocol 2 are, again, linear computations.
More speciﬁcally, the computation of z, which is to be sent
to C in an encryption form originally, is now sent as an addi-
tive SS that C can recover the original value of z. Since Pro-
tocol 6 is secure, we can use its simulator to create the view,
including z and the client shares of the two sub-protocols for
a corrupted client. Similarly, the view for a corrupted server
can also be simulated. With these simulators and the security
of our AHE-to-SOS transformation, the resulting Protocol 2
is secure for computing the same linear function as its “un-
derlying” Protocol 6.
D.5 Security of GForce
Security Proof of GForce against a Corrupted Server.
We prove by hybrid games that the simulated view is indistin-
guishable from the server’s view, which additionally includes
the additive SS of all intermediate values of the underlying
protocols.
• Hyb0: We start from the real-world protocol and assume
that the simulator SimS knows S’s view.
• Hyb1: The simulator does not receive the (additive SS
of) outputs of all SRT layers, but it generates them by
involving the simulator of GPU-Trun with the known
divisor {di} as inputs.
• Hyb2: The simulator does not receive the (additive SS
of) outputs of all ReLU and maxpool layers but involves
the simulators of Beaver’s trick [3] and GPU-DGK to
generate them.
• Hyb4: The simulator does not receive the (additive SS
of) outputs of all linear layers. It constructs the linear
functions with {Mi} and calls the simulator of the AHE-
to-SOS transformation to provide the additive SS output
for the linear layers.
• Hyb5: The simulator has simulated most layers except
the input layer. The view originated from the computa-
tion of the input layers is an additive SS of the input,
and the simulator replaces the SS with a random value
from Zq. Now, the view originated from the interactive
computation of GForce for all layers can be simulated
without knowing the query x and the result out.
Security Proof of GForce against a Corrupted Client. We
prove by hybrid games that the simulated view is indistin-
guishable from the client’s view, which additionally includes
the additive SS of all intermediate values of the underlying
protocols.
2164    30th USENIX Security Symposium
USENIX Association