这是源于落后的编译器技术已经无法满足日益增长的并发需求。很多看似无错的代码在优化
和并发面前又产生了麻烦。最简单的例子，让我们看看如下代码：
× = 0;
lock() :
Thread1
Thread2
1ock () ;
unlock():unlock(1;
X++;
X++:
由于有lock和unlock的保护，x++的行为不会被并发所破坏，那么x的值似乎必然是2
了。然而，如果编译器为了提高x的访问速度，把x放到了某个寄存器里，那么我们知道不
同线程的寄存器是各自独立的，因此如果ThreadI先获得锁，则程序的执行可能会呈现如下
的情况：
·[Thread1]读取x的值到某个寄存器R[1]（R[1]=0）。
·[Thread1]R[1]++（由于之后可能还要访间x，因此Thread1暂时不将R[1]写回x）。
·[Thread2]读取x的值到某个寄存器R[2]（R[2]=0）。
·[Thread2]R[2]++(R[2]=1)。
·[Thread2]将 R[2]写回至x（x=1）。
·[Thread1]（很久以后）将R[1]写回至x（x=1）。
可见在这样的情况下即使正确地加锁，也不能保证多线程安全。下面是另一个例子：
Thread1Thread2
x=y=0;
x = 1;
r1 = Y;
Y = 1;
r2 = x1
很显然，r1和r2至少有一个为1，逻辑上不可能同时为0.然面，事实上r1=r2=0的情
况确实可能发生。原因在于早在儿十年前，CPU就发展出了动态调度，在执行程序的时候
为了提高效率有可能交换指令的顺序。同样，编译器在进行优化的时候，也可能为了效率面
程序员的自我修养一链接、装载与库
---
## Page 52
1.6众人拾柴火姐高
29
交换毫不相干的两条相邻指令（如x=1和rl=y）的执行顺序。也就是说，以上代码执行的
时候可能是这样的：
x = y = 0;
Threadl Thread2
r1 = y:
x = 1;
r2 = x;
=
那么rl=r2=0就完全可能了，我们可以使用volarile关键字试图阻止过度优化，volatile基本
可以做到两件事情：
（1）阻止编译器为了提高速度将一个变量缓存到寄存器内面不写回。
（2）阻止编译器调整操作volatile变量的指令顺序。
可见volatile可以完美地解决第一个问题，但是volatile是否也能解决第二个间题呢？答
案是不能。因为即使volatile能够阻止编译器调整顺序，也无法阻止CPU动态调度换序。
另一个颜为著名的与换序有关的问题来自于Singleton模式的double-check，一段典型的
double-check的singleton代码是这样的（不熟悉Singleton的读者可以参考《设计模式：可
复用面向对象软件的基础》，但下面所介绍的内容并不真正需要了解Singleton）：
volati1e T*_pInst = 0;
T* GetInstance()
if (pInst == NULL)
if (pInst == NULL)
lock () ;
unlock () ;
pInst
 =
return pInst;
抛开逻辑，这样的代码乍看是没有问题的，当函数返回时，PInst总是指向一个有效的
对象。而lock和unlock防止了多线程竞争导致的麻频。双重的if在这里另有妙用，可以让
lock的调用开销降低到最小，读者可以自己描摩。
但是实际上这样的代码是有问题的。问题的来源仍然是CPU的乱序执行，C++里的new
其实包含了两个步骤：
（1）分配内存。
（2）调用构造函数。
所以plnst=newT包含了三个步骤：
（1）分配内存。
程序员的自我修养一链接、装载与库
---
## Page 53
第1章温故而知新
（2）在内存的位置上调用构造函数。
（3）将内存的地址赋值给plnst。
在这三步中，（2）和（3）的顺序是可以颠倒的。也就是说，完全有可能出现这样的情
况：plnst 的值已经不是NULL，但对象仍然没有构造完毕，这时候如果出现另外一个对
GetlInstance 的并发调用，此时第一个if 内的表达式plnst==NULL为false，所以这个调用会
直接返回尚未构造完全的对象的地址（plnst）以提供给用户使用。那么程序这个时候会不会
期溃就取决于这个类的设计如何了。
从上面两个例子可以看到CPU的乱序执行能力让我们对多线程的安全保障的努力变得
异常困难。因此要保证线程安全，阻止CPU换序是必需的。速憾的是，现在并不存在可移
植的阻止换序的方法，通常情况下是调用CPU提供的一条指令，这条指令常常被称为barier。
一条barrier指令会阻止CPU将该指令之前的指令交换到barrier之后，反之亦然。换甸话说，
barrier指令的作用类似于一个拦水坝，阻止换序“穿透”这个大坝。
许多体系结构的CPU都提供barrier指令，不过它们的名称各不相同，例如POWERPC
提供的其中一条指令名叫Iwsync。我们可以这样来保证线程安全：
define barrier() asm_ volatile (*lwsync*)
volatile T* plnst
=01
T* Get Instance ()
if (ipTnst)
lock()=
if (ipInat)
T* temp - new T;
barziez();
pInst = temp:
unlock(1 :
fqsund uangea
由于bamier的存在，对象的构造一定在barier执行之前完成，因此当plnst被赋值时，
对象总是完好的。
1.6.3多线程内部情况
三种线程模型
线程的并发执行是由多处理器或操作系统调度来实现的。但实际情况要更为复杂一些：
大多数操作系统，包括Windows和Linux，都在内核里提供线程的支持，内核线程（注：这
程序员的自我修养一链接、装载与库
---
## Page 54
1.6众人拾柴火焰高
31
里的内核线程和Linux 内核里的kemel_thread并不是一回事）和我们之前讨论的一样，由多
处理器或调度来实现并发。然而用户实际使用的线程并不是内核线程，面是存在于用户态的
用户线程。用户态线程并不一定在操作系统内核里对应同等数量的内核线程，例如某些轻量
级的线程库，对用户来说如果有三个线程在同时执行，对内核来说很可能只有一个线程。本
节我们将详细介绍用户态多线程库的实现方式。
1.一对一模型
对于直接支持线程的系统，一对一模壁始终是最为简单的模型。对一对一模型来说，
个用户使用的线程就唯一对应一个内核使用的线程（但反过来不一定，一个内核里的线程在
用户态不一定有对应的线程存在），如图1-11所示。
User Thread
Kenel Thread
图1-11一对一线程模型
这样用户线程就具有了和内核线程一致的优点，线程之间的并发是真正的并发，一个线
程因为某原因阻塞时，其他线程执行不会受到影响。此外，一对一模型也可以让多线程程序
在多处理器的系统上有更好的表现。
般直接使用API或系统调用创建的线程均为一对一的线程。例如在Linux里使用clone
（带有CLONE_VM参数）产生的线程就是一个一对一线程，因为此时在内核有一个唯一的
线程与之对应。下列代码演示了这一过程：
int thread_funct ion (void*)
char thread_stack [4096]:
----}
void foo
clone (thread_function, thread_stack, CLONE_VK, 0) :
在Windows里，使用API CreateThread即可创建一个一对一的线程。
一对一线程缺点有两个：
程序员的自我修养一—链接、装载与库
---
## Page 55
32
第1章温故而知新
由于许多操作系统限制了内核线程的数量，因此一对一线程会让用户的线程数量受到
限制。
许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下
降。
2.多对一模型
进行，因此相对于一对一模型，多对一模型的线程切换要快速许多，多对一的模型示意图如
图1-12所示。
User Thread
Kemel Thread
图1-12多对-线程模型
多对一模型一大间题是，如果其中一个用户线程阻塞，那么所有的线程都将无法执行，
因为此时内核里的线程也随之阻塞了。另外，在多处理器系统上，处理器的增多对多对一模
型的线程性能也不会有明显的帮助。但同时，多对一模型得到的好处是高效的上下文切换和
儿乎无限制的线程数量。
3.多对多模型
多对多模型结合了多对一模型和一对一模型的特点，将多个用户线程映射到少数但不止
一个内核线程上，如图1-13所示。
在多对多模型中，一个用户线程阻塞并不会使得所有的用户线程阻塞，因为此时还有
别的线程可以被调度米执行。另外，多对多模型对用户线程的数量也没什么限制，在多处
理器系统上，多对多模型的线程也能得到一定的性能提升，不过提升的幅度不如一对一模
型高。
程序员的自我修养一链接、装载与库
---
## Page 56
1.7本章小结
User Thread
Q
Kemel Thread
图1-13多对多线程模型
1.7
本章小结
在这一章中，我们对整个计算机的软硬件基本结构进行了回顾，包括CPU与外围部件
的连接方式、SMP与多核、软硬件层次体系结构、如何充分利用CPU及与系统软件十分相
关的设备驱动、操作系统、虚拟空间、物理空间、页映射和线程的基础概念。虽然这些概念
都是大家所了解的，但是我们认为还是有必要回顾一下，它们跟本书后面章节介绍的内容息
息相关。正所谓温故面知新，这就是本章的目的。
程序员的自我修养一链接、装载与库
---
## Page 58
第2
部分
【程序员的自我修养】
静态链接
---
## Page 60
编译和链接
2.1被隐藏了的过程
2.2编译器做了什么
2.3链接器年龄比编译器长
2.4模块拼装—静态链接
2.5本章小结
程序员的自我修养——链接、装载与库
---
## Page 61
38
第2章编译和链接
对于平常的应用程序开发，我们很少需要关注编译和链接过程，因为通常的开发环境
都是流行的集成开发环境（IDE），比如 Visual Studio、Delphi等，这样的IDE一般都将编
译和链接的过程一步完成，通常将这种编译和链接合并到一起的过程称为构建（Build）。
即使使用命令行来编译一个源代码文件，简单的一句“gcchello.c”命令就包含了非常复
杂的过程。
IDE和编译器提供的默认配置、编译和链接参数对于大部分的应用程序开发面言已经
足够使用了。但是在这样的开发过程中，我们往往会被这些复杂的集成工具所提供的强大
功能所迷惑，很多系统软件的运行机制与机理被掩盖，其程序的很多莫名其妙的错误让我
们无所适从，面对程序运行时种种性能瓶颈我们束手无策。我们看到的是这些问题的现象，
但是却很难看清本质，所有这些问题的本质就是软件运行背后的机理及支撑软件运行的各
种平台和工其，如果能够深入了解这些机制，那么解决这些问题就能够游刃有余，收放自
如了。
2.1
被隐藏了的过程
C语言的经典，“HelloWorld”程序儿乎是每个程序员闭着眼晴都能写出的，编译运行
通过一气呵成，基本成了程序入门和开发环境测试的默认的标准。
include 
int main()
print f (*He11o Wor1d\n*) ;
return 0;
在Linux下，当我们使用GCC来编译HelloWorld程序时，只须使用最简单的命令（假
设源代码文件名为hello.c）：
$gcc he1lo.c
Hello World
$./&.out
事实上，上述过程可以分解为4个步骤，分别是预处理（Prepressing）、编译
（Compilation）、汇编（Assembly）和链接（Linking），如图 2-1所示。
程序员的自我修养一链接、装载与库
---
## Page 62
2.1被隐藏了的过程
39
Header Files
(epp)