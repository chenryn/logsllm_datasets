3m4s
37s
1m26s
3267 12m35s
8m
12s
83
49
4073
90
50
Table 4: Average branch coverage and TTE at the time of exposure for ParmeSan and several other state-of-the-art fuzzers.
Compared to other fuzzers, ParmeSan requires a signiﬁcantly lower coverage (and shorter time) to expose bugs. AFLGo uses
the targets obtained using the ParmeSan analysis stage. All fuzzers run with sanitizers enabled.
preprocessing time is in the order of the normal compilation
time (as seen in Table 8). Every benchmark in the suite is
run with the sanitizers enabled (as per the test suite).
In every single case except one, our results show that
ParmeSan requires signiﬁcantly less coverage to trigger the
bug compared to the other state-of-the-art fuzzers. Like-
wise, AFLGo, which uses the targets obtained by the Parme-
San pipeline, also fares well in this regard, requiring slightly
more coverage than ParmeSan to trigger the bugs. These re-
sults suggest that directing the fuzzing process towards sani-
tizer instrumentation reduces the coverage required to trigger
bugs between 14 and 51%.
8.3 Sanitizer impact
We now take a look at how the particular sanitizer used in our
analysis impacts the ﬁnal results of the fuzzing pipeline. We
show that the sanitizer used determines the classes of bugs
ParmeSan can ﬁnd, allowing us to focus fuzzing on speciﬁc
types of bugs.
Table 3, shows ParmeSan performs the worst on the
memory-leak bugs. This is a ﬁrst indication that our sanitizer
analysis has a signiﬁcant impact on the end result. Since we
use ASan for target acquisition, the fuzzing will be directed
to possible invalid uses of memory. This still covers the ac-
tual use of allocated memory, but ideally we would like to
direct the fuzzing towards calls that allocate memory. We re-
peat the experiment on the memory leak bugs, but now using
LeakSanitizer (LSan) instead of ASan for target acquisition
(see Table 5). LSan keeps track of allocated memory ob-
jects at runtime and generates a summary of memory leaks
when the program terminates. Note that LSan does not mod-
ify the IR, but rather intercepts library calls to functions such
as malloc , which happens at link time. Instead, we create a
custom LLVM pass that inserts dummy calls to the hooks of
the intercepted functions, yielding the same behavior as nor-
mal LSan while still changing the IR at the relevant locations.
This is a process that can be easily automated in the future,
and is a limitation only of the current implementation. With
our custom LSan pass for target acquisition, the mean TTE
for the memory leak bugs in libssh, libxml, openssl, proj4
then changes signiﬁcantly, yields a geomean improvement of
32% compared to using ASan for target acquisition. Like-
wise for the integer overﬂow in freetype2 , we see that us-
ing the correct sanitizer which actually catches the bug (i.e.,
UBSan) for target acquisition improves the performance sig-
niﬁcantly, ﬁnding the bug in 20 hours rather than 47 hours.
As shown in Table 5, there is a stark contrast between san-
itizers used for target acquisition. We run a number of ap-
plications with known bugs of a certain type, while using
three different sanitizers (ASan, UBSan, and TySan) to auto-
matically ﬁnd targets. Note that triggering the bugs requires
sanitizers also (as the bugs usually do not crash the program).
To eliminate the variance caused by overhead of each sani-
tizer, we always instrument the program with the same set of
runtime sanitizer (ASan + LeakSan + UBsan, which is able
to detect all the selected bugs), regardless of the one used for
target acquisition.
As shown in Table 5, a sanitizer that detects the bug
will always allow ParmeSan to ﬁnd the bug within the least
amount of time. Overall, we see that using the sanitizers that
covers the bug and instruments a minimum set of targets al-
lows ParmeSan to ﬁnd bugs faster.
For example, CVE-2018-13785 is a hard-to-trigger inte-
USENIX Association
29th USENIX Security Symposium    2299
Bug
CVE-2014-0160 BO
CVE-2015-8317 BO
libssh
libxml
openssl
proj4
pcre2
freetype2
CVE-2011-1944
CVE-2018-13785 IO
UAF
IO
IO
Type Sanitizer Targets Covered µTTE
5m
6m
6m
10m
50m
50m
10m
20m
8m
47h
20h
>48h
30s
20s
50s
11h
32m
5h
31s
33s
35s
25s
15m
22m
25m
12m
40s
50s
43s
32s
1m30s
1m55s
2m10s
57s
ASan
UBSan
TySan
ASan
UBSan
TySan
ASan
UBSan
TySan
ASan
UBSan
TySan
ASan
UBSan
TySan
ASan
UBSan
TySan
ASan
UBSan
TySan
LSan
ASan
UBSan
TySan
LSan
ASan
UBSan
TySan
LSan
ASan
UBSan
TySan
LSan
533
120
5
352
75
30
122
52
12
437
48
71
230
125
8
450
45
31
590
57
13
104
352
75
30
191
533
120
5
191
729
170
373
43
✓
7
7
✓
7
7
✓
7
✓
7
✓
7
✓
✓
7
7
✓
7
7
7
7
✓
7
7
7
✓
7
7
7
✓
7
7
7
✓
ML
ML
ML
ML
Table 5: Bugs found by ParmeSan using different sanitizers
in the analysis stage. ✓ in targets, bug found; 7 not in targets,
bug found; For the memory leak (ML) bugs we also show the
performance of LeakSanitizer.
ger overﬂow in libpng. Here we see the most signiﬁcant im-
provement as result of selecting the right sanitizer. Specif-
ically, using UBsan, we trigger the bug in an average time
of 32 minutes, but using the other sanitizers, ParmeSan does
not consider the site triggering the bug as a target, and there-
fore takes a signiﬁcantly longer time to ﬁnd the bug, while
using the right sanitizer for target acquisition improves the
performance by an order of magnitude.
For the use-after-free bug in pcre2 , both ASan and TySan
instrument the location of the vulnerability. Since the num-
ber of targets obtained by TySan is smaller than for ASan,
the input generation is steered towards the target containing
the actual bug faster than for ASan, triggering the bug in
less time. CVE-2011-1944 is an integer overﬂow in libxml2,
which is easy to trigger. Here, again, we see that the less-
eager-to-instrument sanitizer lets ParmeSan trigger the bug
in the least amount of time.
For CVE-2014-0160 (HeartBleed), on the other hand, we
see that the sanitizer chosen does not have as signiﬁcant an
impact on how fast the bug is triggered. This is mainly due to
the fact that ASan gives us a large number of targets. Note,
that while fuzzing, we found a number of other crashes not
related to HeartBleed, due to other memory errors. However,
for CVE-2015-8317 (out-of-bounds heap read on libxml),
we see a major improvement, even though we get a large
set of targets.
The interesting insight we get from these experiments is
that ParmeSan is able to target speciﬁc kinds of bugs based
on the sanitizer used for target acquisition and can thus be
used to fuzz applications more effectively. For example, the
use-after-free bug in pcre2 might manifest itself as a type
confusion bug. Using Tysan for target acquisition, we are
able to trigger the bug 20% faster. We have focused our anal-
ysis on a small number of common off-the-shelf sanitizers.
For a more comprehensive overview of different sanitizers
and behavior, we would like to point to the work of Song &
al. [42].
8.4 New bugs
We apply ParmeSan to ﬁnding new bugs and compare the
results with a number of state-of-the-art fuzzers using a se-
lection of libraries. We include a random sampling of ap-
plications from OSS-Fuzz [39] and three target applications
(jhead , pbc , protobuf-c ) that were evaluated in recent
work in fuzzing [3,12,32] in which we were able to uncover
new bugs. We setup ParmeSan to fuzz the most recent com-
mits on the master branch of the applications from the OSS-
Fuzz sample. In total, ParmeSan was able to uncover 736
crashes, of which we determined 47 to be unique based on
the call stack. Of these crashes 37 were found in the (some-
what) outdated pbc library, while 10 of them were found in
up-to-date well-fuzzed libraries. The bugs found in the OSS-
Fuzz applications, jhead, and protobuf-c have all been been
triaged and resolved.
We emphasize that our analysis here (and in general evalu-
ating a fuzzer on the number of new bugs found) on selected
targets only serves as a case study and is not useful to assess
the overall fuzzing performance—given that the selection of
the targets and their particular versions can heavily inﬂuence
the results. We refer the reader to the previous subsections
for experiments detailing ParmeSan’s overall fuzzing perfor-
mance.
Overall, our results show that ParmeSan outperforms other
state-of-the-art directed greybox fuzzers by adding DFA in-
formation and dynamic control-ﬂow graph construction. We
have shown that directing fuzzing towards targets achieved
by a sanitizer-guided analysis is an effective bug-ﬁnding
strategy, allowing us to outperform state-of-the-art coverage-
2300    29th USENIX Security Symposium
USENIX Association
Prog
Version
Bugs NEUZZ QSYM Angora ParmeSan
24h
1h 24h 1h 24h 1h 24h 1h
54c622a
curl
ddd0490
json-c
804f40f3
libtiff
1fbcf40
libxml2
libpcap
c0d27d0
OpenSSL 6ce4ff1
9d92403
ffmpeg
b21c5ef
harfbuzz
libpng
3301f7a1
3.03
jhead
pbc
0.5.14
protobuf-c 1.3.1
2
37
1
0
0
0
0
0
0
0
0
0
OSS Fuzz [39]
0
1
0
0
0
1
2
0
0
1
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
Targets from prior work [3, 12, 32]
2
2
12 10
0
1
0
0
0
0
0
0
0
0
0
0
9
0
2
9
0
0
2
0
0
0
0
0
0
1
0
0
0
0
1
1
1
1
1
0
0
0
0
1
1
1
1
1
0
0
0
2
2
29 23
1
1
1
1
1
2
1
1
0
0
0
2
37
1
Table 6: New bugs found within 1h and 24h by ParmeSan
and other state-of-the-art fuzzers. The version is denoted by
either a version number or a commit id. In total ParmeSan
found 47 new bugs.