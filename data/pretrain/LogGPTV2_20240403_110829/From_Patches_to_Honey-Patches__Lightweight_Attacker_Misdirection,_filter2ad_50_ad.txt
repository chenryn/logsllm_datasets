6.2 Performance Benchmarks
This section evaluates RedHerring’s performance. Our
objectives are two-fold: to determine the performance overhead
imposed upon sessions forked to decoys (i.e., the impact on
malicious users), and to estimate the impact of honey-patching
on the overall system performance (i.e., its impact on legitimate
users). To obtain baseline measurements that are independent
of networking overhead, the experiments in this section are
executed locally on a single-node virtual machine using default
Apache settings. Performance is measured in terms of HTTP
request round-trip time.
Session forking overhead. As expected, forking attacker
sessions from target to decoy containers is the main source of
performance overhead in RedHerring. To estimate its impact
on attacker response times, we crafted and sent malicious
requests to the server in order to trigger its internal honey-
patching mechanism, and measured the request round-trip
time of each individual request. For accuracy, we waited for
the completion of each request before sending another one.
Since Apache allocates requests (including their content) on
the heap, payload size directly impacts the amount of data
to be dumped in each checkpoint operation. It is therefore
important to experiment using varying sizes of malicious
HTTP request payload data (from 0 KB to 36 KB, in steps
of 1.2 KB). Also, to estimate the response time overhead
incurred from the memory redaction process, we executed our
tests twice, with memory redaction enabled and disabled.
Figure 6a shows the encouraging results of this experiment.
Malicious HTTP request round-trip times tend to remain
almost constant as payload size increases. This desirable
relationship can be explained by two reasons. First, CRIU’s
approach of copying process memory pages into dump ﬁles
during checkpoints is extremely eﬃcient. It involves a direct
copy of data between ﬁle descriptors in kernel space using the
splice system call. As a consequence, the target memory
pages are never buﬀered into user space. Second, our approach
to memory redaction leverages the fact that Apache stores
session data in well-deﬁned structs (avoiding having multiple
copies in memory) to locate and redact it directly into the
dump images while they are being generated by the checkpoint
process. Our initial eﬀorts to implement redaction after
checkpointing exhibited far poorer performance, leading to
this more eﬃcient solution.
Overall, the round-trip times of malicious HTTP requests
incur a constant overhead of approximately 0.25 seconds
due to memory redaction. (When memory redaction is used,
the average request takes approximately 0.40 seconds; but
when disabled, it takes 0.15 seconds.) While possibly sig-
niﬁcant (depending on networking latencies), we emphasize
that this constant overhead only impacts malicious users, as
demonstrated by the next experiment.
Overall system overhead. To complete our evaluation, we
tested RedHerring on a wide variety of workload proﬁles
consisting of both legitimate users and attacker sessions on
a single node. In this experiment, we wrote a small Python
script modeling every user and attacker as a separate worker
thread triggering legitimate and malicious HTTP requests,
respectively. We chose the request payload size to be 2.4 KB,
based on the median of KB per request measured by Google
web metrics [29]. To simulate diﬀerent usage proﬁles, we
tested our system with 25–150 concurrent users, with 0–20
attackers.
Figure 6b plots our results. Observe that for the vari-
ous proﬁles analyzed, the HTTP request round-trip times
remain approximately constant (ranging between 1.7 and
2.5 milliseconds) when increasing the number of concurrent
malicious requests. This conﬁrms that adding honey-patching
capabilities has negligible performance impact on legitimate
requests and users relative to traditional patches, even during
concurrent attacks. It also conﬁrms our previous claims re-
garding the small freezing window necessary to checkpoint the
target application.
Finally, this also shows that RedHerring can cope with
large workloads. In this experiment, we have assessed its
baseline performance considering only one instance of the
target server running on a single node virtual machine. In
a real setting, we can deploy several similar instances using
a web farm scheme to scale up to thousands of users, as we
show next.
Stress testing. To estimate the throughput of our system
and test its scalability properties, we developed a small HTTP
load balancer in node.js to round-robin requests between
three-node VMs, each hosting one instance of Apache deployed
on RedHerring. In this experiment, we used ab (Apache
HTTP server benchmarking tool) to create a massive workload
of legitimate users (more than 5,000 requests in 10 threads) for
diﬀerent attack proﬁles (0 to 20 concurrent attacks). Each VM
is conﬁgured with a 2 GB RAM and one quad-core processor.
The load balancer and the benchmark tool run on a separate
VM on the same host machine. Apache runs with default
settings (i.e., no ﬁne tuning has been performed).
As Figure 6c illustrates, the system can handle the strenuous
workload imposed by our test suite. The average request time
for legitimate users ranged from 2.5 to 5.9 milliseconds, with
(a) 3 ≤ σ ≤ 15 ms, n = 10
(b) 0.6 ≤ σ ≤ 35, n = 10
(c) 0.3 ≤ σ ≤ 1.2, 25 ≤ σ ≤ 94
Figure 6: Performance benchmarks. (a) Eﬀect of payload size on malicious HTTP request round-trip time.
(b) Eﬀect of concurrent attacks on legitimate HTTP request round-trip time on a single-node VM. (c) Stress
test illustrating request throughput for a 3-node, load-balanced RedHerring setup (workload ≈ 5K requests).
measured throughput ranging from 169 to 312 requests per
second. In typical production settings we would expect this
delay to be amortized by the network latency (usually on the
order of several tens of milliseconds). This result is important
because it demonstrates that honey-patching can be realized
for large-scale, performance critical software applications with
minimal overheads for legitimate users.
6.3 Web Servers Comparison
We also tested RedHerring on Lighttpd [38] and Ng-
inx [43], web servers whose designs are signiﬁcantly diﬀerent
from Apache. The most notable diﬀerence lies in the pro-
cessing model of these servers, which employs non-blocking
systems calls (e.g., select, poll, epoll) to perform asynchronous
I/O operations for concurrent processing of multiple HTTP
requests. In contrast, Apache dispatches each request to a
child process or thread [45]. Our success with these three
types of server evidences the versatility of our approach.
Figure 7 shows our results. In comparison to Apache, session
forking performed considerably better on Lighttpd and Nginx
(ranging between 0.092 seconds without memory redaction and
0.156 seconds with redaction). This is mainly because these
servers have smaller process images, reducing the amount of
state to be collected and redacted during checkpointing.
7. DISCUSSION
Selective honey-patching. Our work evaluates the feasi-
bility of honey-patching as realistic application, but raises
interesting questions about how to evaluate the strategic
advantages or disadvantages of honey-patching various speciﬁc
vulnerabilities. For example, some patches close vulnerabilities
by adding new, legitimate software functionalities. Converting
such patches to honey-patches might be inadvisable, since it
might treat uses of those new functionalities as attacks. In
general, honey-patching should be applied judiciously based
on an assessment of attacker and defender risk. Future work
Figure 7: Malicious HTTP request round-trip times
for diﬀerent web servers (6 ≤ σ ≤ 11 ms, n = 20)
should consider how to reliably conduct such assessments.
Similarly, honey-patching can be applied selectively to simulate
diﬀerent software versions and achieve versioning consistency.
Automation. Our implementation approach oﬀers a semi-
manual process for transforming patches into honey-patches.
An obvious next step is to automate this by incorporating
it into a rewriting tool or compiler. One interesting chal-
lenge concerns the question of how to audit or validate the
secret redaction step for arbitrary software. Future research
should consider facilitating this by applying language-based
information ﬂow analyses (cf., [47]).
Active Defense. Honey-patching enhances the current realm
of weaponized software by placing defenders in a favorable
position to deploy oﬀensive techniques for reacting to attacks.
For example, decoys provide the ideal environment for im-
plementing stealthy traps to disinform attackers and report
precisely what attacks are doing in real-time [17], and further
insight into the attackers’ modus operandi can be gained by
forging and acting upon decoy data. There is existing work in
this direction in DARPA’s Mission-oriented Resilient Clouds
(MRC) program [55].
Deception. The eﬀectiveness of a honey-patch is contingent
upon the deceptiveness of decoy environments. Prior work
has investigated the problem of how to generate and maintain
convincing honey-data for eﬀective attacker deception (e.g.,
[11, 48, 54, 62]), but there are other potential avenues of
deception discovery that must be considered.
Response times are one obvious channel of possible discovery
that must be considered. Cloning is eﬃcient but still introduces
non-zero response delay for attackers. By collecting enough
timing statistics, attackers might try to detect response delays
to discern honey-patches. Our ongoing work is focusing on
improving the eﬃciency of the memory redaction step, which
is the source of most of the this delay.
In addition, RedHerring’s deceptiveness against discovery
through response delays is aided by the plethora of noisy
latency sources that most web servers naturally experience,
which tend to eclipse the relatively small delays introduced
by honey-patching [49]. Unpatched, vulnerable servers often
respond slower to malicious inputs than to normal traﬃc [25,
58], just like honey-patched servers. This suggests that
detecting honey-patches by probing for delayed responses
to attacks may yield many false positives for attackers. If
criminals react to the rise of honey-patching by cautiously
avoiding attacks against servers that respond slightly slower
when attacked, many otherwise successful attacks will have
been thwarted.
 0 0.2 0.4 0.6 0.8 0 7200 14400 21600 28800 36000median round-trip time (s)payload size (KB)with redactionno redaction 1 2 3 4 0 2 4 6 8 10 12 14 16 18 20median round-trip time (ms)concurrent attacks25 users50 users75 users100 users125 users150 users 0 2 4 6 8 10 0 2 4 6 8 10 12 14 16 18 20 0 100 200 300 400 500average round-trip time (ms)requests per secondconcurrent attacksaverage request timemeasured throughput 0 0.1 0.2 0.3 0.4 0.5 0.6Apache HTTPLighttpdNginxmedian round-trip time (s)no redactionwith redactionAlternatively, attackers who take full control of decoys
can potentially read and reverse-engineer the process image’s
binary code to discover the honey-patch (e.g., by injecting
malicious code that reads the process binary and ﬁnds the call
to hp_fork). While possible with enough eﬀort, we believe
this is nevertheless a signiﬁcant burden relative to the much
easier task of detecting failed exploits against traditionally
patched systems. The emergence of artiﬁcial software diversity
(e.g., [30]) and ﬁne-grained binary randomization tools (e.g.,
[59]) has made it increasingly diﬃcult to quickly and reliably
reverse-engineer arbitrary binary process images. Future work
should consider raising the bar further by unloading prominent
libraries, such as the honey-patch library, during cloning.
Additionally, RedHerring’s decoy environments are con-
structed to look identical to real distributed web servers from
inside the container; for example, many real web servers use
LXC containers that look like the decoy LXC containers.
Therefore, distinguishing decoys from real web servers on the
basis of environmental details (e.g., through init process
control groups) is diﬃcult for attackers. Although resource
exhaustion attacks (e.g., ﬂooding) can cause RedHerring to
run out of decoy resources (e.g., containers), this outcome is
diﬃcult for attackers to distinguish from running the same
attacks against a non-honey-patched server; both result in
observationally similar resource exhaustions.
Likewise, real-time behavior of the decoy inevitably diﬀers
from the target due to the lack of other, concurrent con-
nections. With a long enough observation period, attackers
can reliably detect this diﬀerence (cf., [24]). We mitigate
this by constraining decoy lifetimes with a timeout. This
resembles unpatched servers that automatically reset when a
crash or freeze is detected, and therefore limits the attacker’s
observations of real-time connection activity without revealing
the honey-patch or limiting the attacker’s access to decoy data
or honeyﬁles.
Detection granularity. One foundational assumption of our
work is that some attacks are not identiﬁable at the network
or system level before they do damage. Thus, detection
approaches that monitor network or system logs for malicious
activity are not a panacea. For example, encrypted, obfuscated
payloads buried in a sea of encrypted connection data, or
those that undertake previously unseen malicious behaviors
after exploiting known vulnerabilities, might be prohibitively
diﬃcult to detect by network or log mining. The goal of our
work is to detect such exploits at the software level, and then
(1) impede the attack by misdirecting the attacker, (2) lure
the attacker to give defenders more time and information
to trace and/or prosecute, (3) feed attackers disinformation
to lower the eﬀectiveness of current and future attacks, and
(4) gather information about attacker gambits to identify and
better protect conﬁdential data against future attacks.
Real-world deployment. It would be worthwhile to eval-
uate the eﬀects of honey-patching on web servers that are
frequent victims of targeted, tailored attacks by resourceful
adversaries. Over the long run, this can help us better under-
stand the practical implications of honey-patching and the
attacks they capture.
In addition to web servers, we consider our approach feasible
for protecting web applications and other Linux networking
applications in general. We would also like to test and deploy
RedHerring on cloud infrastructures that support LXC to
beneﬁt from the cloud’s dynamic scalability and performance
characteristics.
8. RELATED WORK
Remote Exploitation. Remote, exploitable attacks are one
of the biggest threats to IT-security, leading to exposure of
sensitive information and high ﬁnancial losses. While (zero-
day) attacks exploiting undisclosed vulnerabilities are the
most dangerous, attacks exploiting known vulnerabilities are
most prevalent—public disclosure of a vulnerability usually
heralds an increase of attacks against it by up to 5 orders
of magnitude [9]. Most attacks are remote code injections
against vulnerable network applications, and are automatically
exploitable by malware without user interaction. Fritz et
al. [23] survey the threat landscape of remote code injections
and their evolution over the past ﬁve years.
Unfortunately, ﬁnding vulnerabilities that lead to remote
exploits is becoming easier. ReDeBug [31] ﬁnds buggy code
that has been copied from project to project. This occurs since
programmers often reuse code, and patches are not applied
to every version. The Automatic Exploit Generation (AEG)
research challenge [6] involves automatically ﬁnding vulnera-
bilities and generating exploits by formalizing the notion of
an exploit and analyzing source code. Security patches can
also be used to automatically generate exploits, since they
reveal details about the underlying vulnerabilities [12].
To help overcome this, patch execution consistency models,
which guarantee that a patch is safe to apply if the tandem
execution of patched and unpatched versions does not diverge,
have been recommended as a basis for constructing honeypots
that detect and redirect attacks [40]. Our work pursues this
goal at the software level, where software exploit detection is
easier and more reliable than at the network level. Software