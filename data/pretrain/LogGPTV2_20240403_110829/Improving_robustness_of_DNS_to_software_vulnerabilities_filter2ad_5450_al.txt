most sophisticated and well resourced of adversaries.
Minimal Knowledge The minimal knowledge case represents the least sophisticated ad-
versary.
In this case, only the attacker graph G is known, as well as any open source
intelligence (OSINT). For example, the attacker can use OSINT to select potential data to
inject as noise, or can coordinate activities between their vertices in G. In the Pleiades
example, an attacker with minimal knowledge can draw information from their infected
hosts.
Moderate Knowledge The moderate knowledge case represents an adversary with ˜G,
If attacking Pleiades, ˜G would be a host/domain graph from a
an approximation of G.
large enterprise or university in order to approximate the view that the defender has. This
allows the adversary to evaluate their attacks. The size of ˜G affects the evaluation from
the attacker’s perspective, which we will explore by randomly sampling subgraphs of ˜G.
An attacker with moderate knowledge is similar to a sophisticated adversary with access
to large datasets through legitimate (i.e., commercial data offerings) or illegitimate (i.e.,
security compromises) means.
Perfect Knowledge Finally, the perfect knowledge case is for an adversary who has ob-
tained G from the defender. Given the full dataset and knowledge of the modeling process,
an adversary can completely reconstruct the clustering results of the defender to evaluate
the effectiveness of their attacks.
Ideally, this data would be well guarded making this
81
level of knowledge only realistic for the most sophisticated of attackers, e.g., nation-state
sponsored threats. Nevertheless, considering the damage that could be done by a perfect
knowledge attacker is important as a security evaluation, since it allows us to ﬁnd potential
weaknesses in the graph clustering techniques.
5.3.3 Attacks
We present two novel attacks against graph clustering. The ﬁrst, targeted noise injec-
tion, improves on random injections [124, 125] by emulating the legitimate signal’s graph
structure. The second, small community attack, exploits the known phenomenon of small
communities in graphs [42, 126]. Our attacks violate both the homophily and the struc-
tural equivalence assumptions used by graph clustering methods. That is, our attacks either
change what nodes are close together to violate homophily, or they change observations of
node neighborhoods so as to violate structural equivalence.
Identifying a successful attack depends on the system, which will be described in detail
in Section 5.4. Since we use Pleiades, we evaluate attacks by the impact on a subsequent
classiﬁcation of the resulting adversarial clusters. However, this could be done purely at
the unsupervised level by manually evaluating the accuracy of the output clusters, or lever-
aging prior work in adversarial malware clustering [19] to measure global cluster quality
decrease. Next, we evaluate the cost incurred by the attacker. We analyze the costs by
measuring changes to their graph’s structure that would either ﬂag them as anomalous or
damage connectivity between the graph’s vertices. In the descriptions below, an attacker’s
initial graph G is shown, and the alterations yield a modiﬁed graph, G(cid:48), that represents a
defender’s view of the attacker’s graph after the adversarial manipulation.
Targeted Noise Injection
Figure 5.1 illustrates two targeted noise injection attacks. Consider a bipartite attacker
graph G, with vertex sets U (circles) and V (squares). To mount the attack, noise is injected
82
Figure 5.1: Example of targeted noise injection attacks on a graph.
into G to generate G(cid:48). We inject noisy edges from nodes controlled by the attacker for the
purpose of mirroring real edges. This encourages newly connected nodes to be clustered
together with the attacker’s nodes.
To inject noise, the attacker creates an additional vertex set V (cid:48), represented by red
squares. Entities in V (cid:48) should differ substantially from those in V , which depend on the
underlying system to be evaded. In Pleiades’ case, this means the injected domains (V (cid:48))
must be different, in terms of character distribution, from the legitimate domains (V ). Then,
for every edge between U and V , the attacker creates a corresponding edge between U and
V (cid:48), as shown in Figure 5.1. That is, the attack function f : (u, v) ∈ E (cid:55)→ (u, v(cid:48)) ∈ E(cid:48) is
bijective. This creates G(cid:48) = (U, V ∪ V (cid:48), E ∪ E(cid:48)), where E(cid:48) are the corresponding edges
from U to V (cid:48), denoted by dotted red edges in the ﬁgure. The other way to inject noise is
to create edges from U to existing nodes from G, as shown in Figure 5.1. This does not
add additional nodes, but identiﬁes other vertices on the defender’s graph G to use as V (cid:48).
A new edge is created for all edges between U and V . Attacker information is used to
identify additional nodes to use. Example nodes may include other non-malicious domains
queried by infected hosts, or a machine’s existing behavior observed by the malware. More
commonly, it requires some knowledge of the graph being clustered, G. This process can
be repeated to increase |V (cid:48)| to be multiples of |V |.
Algorithm 2 formally describes noise injection for attacker A controlling the attacker
graph G, with noise level m. Line 1 to Line 6 repeats the noise injection process m times.
83
Add Noise toNew NodesGUVUV'G'VUG'VAdd Noise toExisting NodesV'Algorithm 2 Targeted Noise Injection Attack Algorithm for Attacker A controlling G
Input: A, m, G = (U, V, E)
Output: G(cid:48)
i ← according to knowledge of A
V (cid:48)
for v(cid:48) ∈ V (cid:48)
Mirror the edges such that f : (u, v) ∈ E (cid:55)→ (u, v(cid:48)) ∈ E(cid:48)
i do
i is bijective.
1: for i = 1 to m do
2:
3:
4:
5:
6: end for
7: Return G(cid:48) = (U, (
end for
m(cid:83)
i=1
m(cid:83)
i=1
i ) ∪ V, (
V (cid:48)
i) ∪ E)
E(cid:48)
In line 2, A generates the set of noisy nodes V (cid:48) according to her knowledge. From line 3 to
5, the attacker creates a one-to-one mapping from E to E(cid:48)
i. Line 8 returns the manipulated
i) ∪ E). We will evaluate two variants to
attacker graph G(cid:48) = (U, (
E(cid:48)
determine how much noise is needed to mount a successful, but low cost attack. In the ﬁrst
i ) ∪ V, (
V (cid:48)
m(cid:83)
m(cid:83)
i=1
i=1
variant m = 1, and in the second m = 2.
While additional edges and nodes could be injected arbitrarily at random, we choose
to mirror real edges in order to make both nodes from V (cid:48) and V have similar embeddings.
We deﬁne V (cid:48) to be the set of noisy nodes. The targeted noise injection attack exploits
the homophily assumption [38, 33] of graph clustering methods. In community discovery
and spectral methods, graph partitions cannot distinguish injected noisy nodes (V (cid:48)) from
real nodes (V ), which exhibit structurally identical connections to U. The co-occurrence
increases the observation of noisy nodes appearing in neighborhoods of real nodes, and
vice versa for node2vec. We expect nodes from V (cid:48) to join existing clusters containing V .
The targeted noise injection attack has a cost for the attacker of raising the proﬁle of
nodes belonging to attacker graph G, potentially making them outliers. Speciﬁcally, hosts
from U will increase in percentile with respect to their degree, i.e., a relatively high degree
could indicate anomalous behavior, which we can measure by the increase in percentile
ranking changes before and after an attack. We call this the anomaly cost.
84
For attacking Pleiades, consider a graph where U are infected hosts and V are the
domain names that the hosts in U query. To generate G(cid:48) an attacker instructs their malware
to query an additional domain (v ∈ V (cid:48)) for each domain used for its normal malicious
operation (v ∈ V ). This causes the domains from V and V (cid:48) to conﬂict such that the
clustering is not useful to the defender. However, the anomaly cost may make these trivial
to detect. Nonetheless, we will show in Section 5.5.2 that the cost of attack is small enough
to be practical.
Small Community
Figure 5.2 illustrates four potential small community attacks of increasing intensity. The
small community attack removes edges and/or nodes such that the graph clustering sepa-
rates a single attack graph into multiple clusters, while maintaining as much connectivity
from the original graph as possible. Again, G is a bipartite attacker graph with identical
vertex and edge sets as before. To mount the attack, an adversary ﬁrst constructs a complete
1 and G(cid:48)
3 and G(cid:48)
version of G, ˆG. In ˆG, every vertex in U has an edge to every vertex in V . To construct
G(cid:48), the adversary removes edges from ˆG. In Figure 5.2, the attacker has removed one and
two edges per vertex in V in G(cid:48)
4, the attacker has
removed a vertex from V , and then removed one and two edges per remaining vertex. The
attacker randomly chooses nv (such that 0 ≤ nv ≤ |V | − 1) nodes to remove, and ne (such
that 0 ≤ ne ≤ |U| − 1) edges from each remaining node V in ˆG. In the extreme case,
there is only one vertex remaining from V connecting to one in U, which often cannot be
2, respectively. Then in G(cid:48)
captured by graph embeddings. Each attack instance is conﬁgured with (nv, ne) pair, or, in
other words, the (|V | − nv, |U| − ne) pair to keep nodes and edges. We deﬁne the attack
success rate as the number of successful attack conﬁgurations divided by |U| ∗ |V |.
If the attacker has minimal knowledge, she can choose nv and ne randomly, and hope
for the best. With perfect knowledge (knows G), she can choose the smallest nv and ne
that succeed. Attackers without some knowledge or approximation of G will be unable to
85
Figure 5.2: Example small community attacks on a graph.
Algorithm 3 Small Community Attack Algorithm for Attacker A controlling G
Input: A, G = (U, V, E)
Output: G(cid:48)
1: Construct ˆG = (U, V, ˆE) from G, where | ˆE| = |U| ∗ |V |
2: nv, ne ← according to knowledge of A, where nv 
D(G(cid:48)), or zero if D(G) ≤ D(G(cid:48)). A loss in density implies a potential loss of connectivity,
but maintaining or increasing the density bodes well for the attacker. They can afford an
even denser structure, yet still evade defenders. It is important to note that, while nv is lost,
this is reﬂected in the density score, as |V | includes any removed vertices like nv. A lower
density, and therefore a higher cost, is incurred when edges and/or vertices are removed
relative to the original structure seen in G.
87
Consider an attack on Pleiades. ˆG is created by completing G. To mount the attack
like G(cid:48)
2, the adversary partitions the domain names that are used to control her malware by
removing one of the control domains (nv=1), and then excludes two distinct hosts that query
each of the remaining domains (ne=2). In other words, the adversary can also randomly
choose one host (|U| − ne) to query each one of remaining control domains. This reduces
the density from D(G) = 0.5 to D(G(cid:48)
2) = 1/3, and sacriﬁces one node (nv).
If the adversary has knowledge that allows testing whether the attack is successful or
not, the attacker can increasingly remove domains and queries from hosts until clustering
G no longer results in G(cid:48) being extracted as a single cluster. In practice, as described in
Section 2.1, the subdivided G(cid:48) often ends up either as portions of the “death star” cluster;
or in multiple, noisy clusters. In both cases, the legitimate cluster is effectively hidden in a
forest of noise. In order to verify an attack was successful, however, an attacker must have
G or an approximation.
5.4 Attacks in Practice
We chose to attack Pleiades because it has been commercially deployed and relies on graph
modeling. Our reimplementation has similar performance, as shown in Appendix A.3. We
now describe portions of the reimplementation in detail.
5.4.1 Pleiades
An overview of Pleiades is shown in Figure 5.3. We focus our attacks on the clustering
component and use the classiﬁcation phase to demonstrate attack success. First, Pleiades
clusters NXDOMAINs (V ) queried by local hosts (U) using the host-domain bipartite
graph (G). It groups together NXDOMAINs queried by common hosts into clusters C0, . . . , Ck,
based on the assumption that hosts infected with the same DGA malware query similar
groups of DGA domains. The graph clustering can be achieved by either community dis-
covery (1), spectral clustering (2) as in the original paper [25], or node2vec clustering (3).
88
Figure 5.3: Overview of the DGA detection system.
Table 5.1: Summary of datasets and their availability to minimal, moderate, and perfect
knowledge attackers.
Dataset
Reverse Engineered
DGA Domains
Host-NXDOMAIN
Graph (Surrogate)
Host-NXDOMAIN
Graph (Ground Truth)
Number of Records Minimal Moderate Perfect
14 DGA Families; 395K NXD