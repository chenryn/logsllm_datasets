title:Performance Evaluation of Exception Handling in I/O Libraries
author:John DeVale and
Philip Koopman
Performance Evaluation of Exception Handling in I/O Libraries 
John DeVale  Philip Koopman 
Carnegie Mellon University 
Department of Electrical and Computer Engineering 
Institute for Complex Engineering Systems 
5000 Forbes Ave 
Pittsburgh, PA 15213 
devale@cmu. edu PI:EMAIL 
Abstract 
Lack of data quantifj’ing the performance cost of imple- 
menting good  exception handling often causes developers 
to skimp on exception handling based on its overestimated 
perceived cost.  In an effort to remedy this problem wepro- 
vide pegormance data on the cost of building good excep- 
tion  handling3 into  software.  We  use  the  Safe  Fast  IO 
library as a basis for this study.  SFIO improves robustness 
by a factor of 3 to IO over STDIO without sacrificing yer- 
formance.  We were able to improve the robustness of  the 
critical SFIO functions by another factor of 5, thus quanti- 
fying and reducing robustness failure rates by a factor of up 
to 70 from standard 110 firnctions, with an average perfor- 
mance penalty  of I % as  measured  by  the original  SFIO 
benchmark  scheme.  Future  processor  architecture  im- 
provements  will further  improve  checking  speed,  essen- 
tially eliminating performance as an obstacle to improving 
software robustness. 
1. 
Introduction 
Recent advances in the ability  to  measure software ro- 
bustness have revealed that it is common for software to be 
non-robust when presented  with exceptional parameter val- 
ues.  For example,  both Unix and Windows operating sys- 
tems  and  their  C  libraries  tend  to  have  significant 
robustness failure rates, with C library  functions often be- 
ing less graceful at handling exceptions than system calls 
[81[151. 
Anecdotal data collected by robustness testing seems to 
suggest that  systems incapable of  gracefully handling ex- 
ceptional conditions (including exceptions caused by soft- 
ware defects in application programs calling other software 
packages)  tend  to be  somewhat  less  reliable  at  a  system 
level, and much less reliable at the task level[ 151. While the 
evidence  does not  prove  causality, in  many  cases overall 
system failures tended to be caused by  modules with poor 
overall exception handing characteristics [ 15][7]. 
Despite a general need for better exception handling and 
the existence of tools to identify exception handling short- 
comings, few projects pay  anything other than passing at- 
tention to this aspect of the system.  Some developers sim- 
ply  lack exposure to the need  and methods for exception 
handling [ 121.  Others eschew it because of perceived per- 
formance problems and development difficulty.  Neither of 
these need be the case. As Maxion points out in [ 121, even a 
small amount of effort  applied to raising the awareness of 
the importance of solid exception handling can result in sig- 
nificant improvements.  Additionally, there are now sev- 
eral  research  and  commercial  tools  to  help  developers 
detect potential robustness weaknesses [10][6][3]. But, be- 
yond the issue of finding and correcting  robustness  prob- 
lems,  we  believe  that  in  general  developers  greatly 
overestimate the performance  penalty of  making software 
highly robust and use this as a reason to avoid robustness 
improvement. 
An  example  of  a  software  package  developed  with 
safety and robustness as a goal, without compromise to per- 
formance, is the safe, fast, VO library (SFIO) developed by 
David Kom and K.-Phong Vo at AT&T research [9].  The 
functions included in SFIO implement the functionality of 
the standard C I/O libraries  found in STDIO.  This library 
adds a large  amount of  error checking ability  (as well  as 
other functionality) to the standard IO libraries, and man- 
ages to do so without adversely affecting performance. 
While the authors of SFIO were able to demonstrate that 
it was a high performance library, at the time it was devel- 
oped  there  was  no method  for  quantifying  robustness. 
They could  make a  case that  the library was safer due to 
their design decisions, but there was no method available to 
quantify how much they had improved over STDIO.  Fur- 
thermore, discussions with the developers of SFIO revealed 
that  even they  were concemed about the performance  im- 
pact of increasing the amount of exception checking done 
by their code. 
We saw the existence of SFIO as an opportunity to gain 
an initial understanding of how robust an Application Pro- 
graming Interface (API) implementation might be made us- 
ing  good  design  techniques  but  no metrics  for  feedback, 
and what the actual performance penalty might be for fur- 
0-7695-1101-5/01 $10.00 0 2001 IEEE 
519 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:15 UTC from IEEE Xplore.  Restrictions apply. 
ther improving robustness beyond the point judged practi- 
cal by  SFIO developers.  First, we used the Ballista tool to 
measure  the robustness  of SFIO to exceptional  parameter 
values at the API level.  This allowed us to quantify  SFIO 
robustness  and  find  that  it  was  significantly  more  robust 
than STDIO, but still had room for improvement.  Then we 
found some common types of robustness vulnerabilities  in 
SFIO and hardened against them, further improving robust- 
ness.  At first the improved SFIO did in fact have some per- 
formance problems; however, these  were largely remedied 
by optimizing for the common case and the result proved to 
be  significantly  more  robust  than  the  original  SFIO with 
only a slight performance penalty. 
The remainder of this paper describes our efforts 
to identify and fix general robustness failures within 
the SFIO system and quantify  the performance im- 
pact of the additional  code added to harden the sys- 
tem against those failures.  Additionally, we discuss 
the types of robustness  failures that  are still expen- 
sive to check  for, and  how  near-term  processor ar- 
chitecture  enhancements 
for  general  purpose 
computing will also reduce the cost of improving ro- 
bustness. 
2.  Robustness testing of SFIO 
We used the Ballista testing suite to measure the 
robustness of the 36 functions in the SFIO API.  This 
allowed us to objectively  evaluate the  SFIO library 
in terms of  exception  handling robustness.  To test 
SFIO we  used  existing data  types for POSIX tests 
and created two custom Ballista test types capable of 
generating tests cases for the SFIO types Sfio-t  and 
Void-t.  These types fit directly into the Ballista data 
type  framework, and inherited  much  of  their  func- 
tionality  from  the generic pointer  type.  This  made 
implementation  a simple exercise, requiring only a 
few  hours  to  implement  the  types,  and  to  test  the 
types  themselves  within  the  Ballista  framework  to 
ensure that they themselves were robust. 
Our testing  showed  that  while  the robustness of 
SFIO is far greater than STDIO (Figure I), SFIO still 
suffers from a fair number of robustness failures  in 
critical IO function such as write and read.  Analysis 
of  the  testing  data  showed  that  there  were  three 
broad causes for many of the SFIO robustness fail- 
ures.  Specifically these  were: 
Failure to ensure a file was valid 
Failure to ensure file modes and 
permissions were appropriate to the 
intended operation 
Failure to check buffers and data structures for 
size and accessibility 
These problems  were not  a case of defective checking 
code in the software itself, but rather a lack of attempting to 
check  For  these types of exceptions. 
Once identified, these  potential  causes of failures  were 
addressed in a generic fashion across  the eight most impor- 
tant  IC) functions in which  they  occurred: sfopen, sfwrite, 
sfread, sfclose, sffileno, sfseek, sfputc, and sfgetc (the “s” 
prefix  indicates  a  “safe”  version  of  the  corresponding 
STDIO library call).  For every function we were able to re- 
use the parameter validation  code for each specific failure 
mode, thus reducing the cost of developing such checks to 
being linear with the number of parameter types, rather than 
the number of functions hardened 
using  our  techniques.  For  this 
first version  of what we will call 
Robust  SFIO functions, only  or- 
dinary  attention  was paid to per- 
formance  - the  emphasis  was 
instead  placed  on  reducing  ro- 
bustness  failure rates.  Figure 2 
shows  that  the  percent  of  Abort 
failures  (i.e., percent of test cases 
resulting  in an abnormal task ter- 
mination instead of an error code) 
were significantly  reduced for the 
Robust SFIO software version. 
While  validating  file  parame- 
ters  was  fairly  straightforward, 
validating  the  buffers  and  data 
structures  was  more  difficult. 
the  POSIX  standard 
Because 
gives  no  assurance  that  a  task’s 
state will be valid after a memory 
access fault,  we  validated  mem- 
ory  prior  to  the  function  execu- 
tion  by  striding(read  then  write) 
through 
the  memory  structure 
with a stride  size of  the  memory 
page  size for the architecture the 
code  was  executed  on.  This al- 
lowed us to catch exceptions dur- 
ing  a  validation  stage  before 
modifying the system state, elim- 
inating issues of performing  roll- 
backs  or  otherwise  dealing  with 
partial completion of functions in 
the event of an exception. 
%Abort Failures 
Figure 1.  Robustness failure rates 
for SFIO, STDIO compared for 20 
functions with direct functional 
equivalence, as  measured on the 
Linux  test system.  SFIO failure 
rates on Digital Unix were lower 
for some SFlCl functions and are 
addressed later in section 2 
We  used  the  mechanisms de- 
scribed  in  [ l l ] to set up and per- 
form signal handling on a per call 
basis.  While  this  is  more  time 
consuming than  setting up global handlers, it does ensure 
that the exact state of the program at the time of the signal is 
known.  This reduces the complexity of the signal handlers, 
520 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:15 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2. Abort Failure Rate for Select SFlO Functions under Linux 
Abort Failure Rate for Select Functions 
R 
Function 
0 Original SFlO 
Robust SFlO 
original SFIO [9].  The results presented are the averages 
from I O  benchmark runs and are presented in figure 3 (exe- 
cution time variance across runs was minimal).  Each run 
consisted  of  a  single  complete execution  of  each  bench- 
mark.  The benchmarks were run on two diverse architec- 
tures with different development ideologies and goals.  The 
first test system had 333 MHz dual Pentium I1 processors, 
128 MB RAM, and executed Redhat Linux version 6, with 
kemel2.2.12smp and Gnu STDIO library version 2.1.2-1 1. 
The second system was an Alphaserver 4000 with two 600 
MHz 21 164 processors and IGB of physical RAM, running 
Digital Unix 4.OD and libc version 425. 
Table  1  describes  the  operations  performed  by  each 
benchmark,  with  a block  size of 8K.  Benchmarks  with  a 
757 suffix appended to the name used  a block  size of 757 
bytes.  The reason for the different transfer sizes is due to 
the  difference  in  how  the  machines  are configured.  We 
chose sizes that were large  enough to ensure the data was 
not being cached in main memory, and thus would have to 
be re-read from disk between each run.  The Linux platform 
had  to  run  smaller benchmarks  than  the  Alphaserver  to 
keep execution times reasonable. 
The goal of using two different testing platforms was not 
to directly compare performance of the hardware in ques- 
and makes the recovery from such exceptions 
easier to design and code. 
100 1 
Figure 2  shows the Abort failure rates for 
the 8  modified functions, both before and af- 
ter treatment.  The failures that remain in the 
modified functions represent cases where the 
data values  passed  into  the  functions  have 
been corrupted in a manner that is difficult to 
check  with  data  structure bounds  checking, 
pointer checking, or other similar techniques. 
Overall  the  unmodified SHO library had  an 
average  normalized  Abort  failure  rate  of 
5.61%, based  on  uniformly  weighting  the 
per-function failure rates of 186389 test cases 
across  36  functions  tested.  The underlying 
operating  system  can  sometimes  affect  ro- 
bustness[4],  and our testing showed that  the 
normalized failure rates for SFlO running on 
Digital Unix  were  2.86%  for  the  8 functions  of  interest. 
The Robust  SFIO library  had  an  average  failure  rate  of 
0.44% across the 8 modified functions. 
structures 
(e.g., 
While  even  the Robust  SFIO library does not  achieve 
perfect  robustness  failure  prevention,  it  is  significantly 
better  than  both  STDIO and  the  original  SFIO.  Addi- 
tionally, it is possible that Robust SFlO could be improved 
even further by employing techniques for detecting invalid 
memory 
from 
[17][1][18]).  However, many  of  these  techniques have a 
hefty performance penalty without their proposed architec- 
tural support to identify “bad data” situations.  Thus, further 
robustness improvements will become practical only when 
they are supported by future generations of microprocessor 