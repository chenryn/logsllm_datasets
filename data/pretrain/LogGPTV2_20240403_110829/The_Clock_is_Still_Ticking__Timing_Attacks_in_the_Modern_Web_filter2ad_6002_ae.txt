mation from the web server, e.g., the existence of a speciﬁc
username. Crosby et al. showed that a timing diﬀerence
as low as 20µs on a server-side process can be reliably dis-
tinguished over the Internet. The ability to obtain highly
accurate timing information has given rise to numerous at-
tacks that rely on remote timing information. The goals of
these attacks range from breaking cryptographic systems,
e.g. by extracting private keys from an OpenSSL-based web
server [8], to ﬁngerprinting the rules of Web Application
Firewalls [32].
Moreover, researchers have shown that cross-site timing
attacks can be employed to list network-enabled devices on
1391the victim’s local network [19]. An adversary could subse-
quently use this information to ﬁngerprint the user, or to
penetrate vulnerable devices, for instance by using CSRF
attacks. Contrary to these attacks, where the main focus is
to breach the security of machines that are generally only
available over the local network, Felten and Schneider pro-
posed various cross-site timing attacks that can be used by
adversaries to obtain information on a victim’s browsing his-
tory [12]. Based on the reduced loading time of cached re-
sources, the researchers found that it is possible for an at-
tacker to uncover whether a certain resource is present in a
victim’s cache. As cached resources originate from the web-
sites a user recently visited, the adversary is able to discover
a victim’s browsing history. Although this type of attack
has been known for over 15 years, relatively few changes
were made to the browser environment to mitigate this is-
sue. Just recently, Jia et al. showed that by using exactly
the same techniques, adversaries can launch geo-inference
attacks to discover a victim’s geographical location without
his consent [18]. The geo-inference attack exploits the fact
that various web services that are trusted by the victim and
know his location, cache location-speciﬁc resources. As a
result, an adversary can discover the victim’s location by
analyzing which of these resources are cached.
Next to the network response time and server-side pro-
cessing time, researchers discovered a variety of attacks that
leverage the time required by the browser to complete cer-
tain computations. In 2013, Kotcher et al. found that after
applying CSS ﬁlters on framed documents, the time required
to render the document becomes related to its visual con-
tent [21]. As a result, this attack allowed adversaries to read
out pixels from cross-origin documents in case framing was
not explicitly forbidden. Similarly, Paul Stone found that
applying SVG ﬁlters instead of CSS ﬁlters yielded the same
results [35].
6.2 Browser side-channel leaks
Due to the complex design and intricate implementations
of browsers, it comes as no surprise that researchers fre-
quently discover unintended behavior that often leads to a
leakage of users’ private information, or that can be used to
bypass the building block of security in modern web browsers,
namely the Same-Origin Policy.
One of the oldest, and most well-known side-channel leaks
in browsers, is the history sniﬃng attack ﬁrst introduced in
2002 [9]. By applying CSS styles to visited links and subse-
quently querying the computed style in JavaScript, an adver-
sary could easily determine whether a victim had previously
visited a certain link. By means of an empirical study on
the 50,000 most popular websites, Jang et al. discovered the
clandestine usage of these history sniﬃng attacks on 46 web-
sites [17]. This pressured browser vendors into adopting an
eﬀective countermeasure that restricted the CSS directives
that could be used in the :visited pseudo-class [4]. Shortly
thereafter, researchers discovered that even with this miti-
gation in place, history detection techniques were still possi-
ble, either by using the aforementioned timing attacks that
leverage SVG ﬁlters [34], or by user-interaction [40].
Next to attacks targeting a user’s browser behavior, re-
searchers have found that the inherent behavior of certain
browser features can allow an adversary to uncover a user’s
private information at a cross-origin website. For instance,
Heiderich et al. discovered that by leveraging various CSS
and HTML features, adversaries can exﬁltrate sensitive in-
formation, such as CSRF tokens [16]. Moreover, Lee et al.
found that the intrinsic behavior of the ApplicationCache
mechanism can be used to uncover the status code that is
returned for a cross-origin resource [22]. Consequently, this
allows an adversary to obtain sensitive information when the
resulting status code for certain endpoint is based on the
user’s state. The authors showed how these attacks could
be used to discover web servers on the local network, and to
detect the login-status of a user at various websites. Inter-
estingly, our proposed countermeasure, which aims to pre-
vent illicit cross-origin requests, can also be used to deﬂect
the ApplicationCache attacks proposed by Lee et al. Cor-
respondingly, their defense mechanism, i.e., providing more
control to website administrators over the cache-ability of
a resource, can be applied to restrict the two cache-based
timing techniques. As there is a variety of browser features,
including features unrelated to the browser cache, that may
leak timing information, we conjecture that a more system-
atic approach is required to thwart this type of side-channel
attacks.
7. CONCLUSION
In this paper, we propose several new timing techniques
for estimating the size of cross-origin resources. These at-
tacks exploit the side-channel information that is exposed by
the time required by a browser to process a resource, either
by parsing it, or by involving it in caching operations, i.e.
storage or retrieval. Because the timing measurements start
after the resource has been downloaded, the side-channel at-
tacks do not suﬀer from the limitations of traditional timing
techniques, and can thus be used by adversaries to obtain
more accurate timing measurements, regardless of the vic-
tim’s potentially unfavorable network conditions. We show
that these attacks can be applied on various platforms, pos-
ing an imminent threat to an extensive amount of web users.
Using ﬁve real-world attack scenarios, we illustrate how at-
tackers can leverage our novel timing techniques against a
variety of online web services, allowing them to extract pri-
vate data that a victim shared with trusted services.
Overall, our ﬁndings indicate that cross-site timing at-
tacks pose an imminent threat to the privacy of online users.
As the side-channel leaks exploited in the novel timing tech-
niques are inherent to the design of browsers and the web
in general, we conjecture that a systematic client-side coun-
termeasure would require structural changes to the browser
architecture. Due to the complexity of modern browsers, a
complete mitigation against all side-channels leaks appears
unlikely, pointing towards the need for CSRF-like counter-
measures at the server-side that hide the size of a resource
from cross-site attackers.
Acknowledgments
We thank the anonymous reviewers for the valuable com-
ments. For KU Leuven, this research was performed with
the ﬁnancial support of the Prevention against Crime Pro-
gramme of the European Union (B-CCENTRE), the Re-
search Fund KU Leuven, the IWT project SPION and the
EU FP7 project NESSoS. For Stony Brook University, this
work was supported by the National Science Foundation
(NSF) under grant CNS-1527086.
13928. REFERENCES
[1] Bose v. interclick, inc., 2011.
[2] G. Acar, C. Eubank, S. Englehardt, M. Juarez,
A. Narayanan, and C. Diaz. The web never forgets:
Persistent tracking mechanisms in the wild. In
Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security, pages
674–689. ACM, 2014.
[3] J. Archibald. Application Cache is a douchebag.
http://alistapart.com/article/application-
cache-is-a-douchebag, May 2012.
[4] L. D. Baron. Preventing attacks on a user’s history
through CSS: visited selectors.
http://dbaron.org/mozilla/visited-privacy, 2010.
[5] A. Barth, C. Jackson, and J. C. Mitchell. Robust
defenses for cross-site request forgery. In Proceedings
of the 15th ACM conference on Computer and
communications security, pages 75–88. ACM, 2008.
[6] Beevolve. An exhaustive study of Twitter users across
the world.
http://www.beevolve.com/twitter-statistics/,
October 2012.
[7] A. Bortz and D. Boneh. Exposing private information
by timing web applications. In Proceedings of the 16th
international conference on World Wide Web, pages
621–628. ACM, 2007.
[8] D. Brumley and D. Boneh. Remote timing attacks are
practical. Computer Networks, 48(5):701–716, 2005.
[9] A. Clover. CSS visited pages disclosure, 2002.
[10] X. Ding, L. Zhang, Z. Wan, and M. Gu. A brief survey
on de-anonymization attacks in online social networks.
In CASoN, pages 611–615, 2010.
[11] Facebook. Company info.
http://newsroom.fb.com/company-info/.
[12] E. W. Felten and M. A. Schneider. Timing attacks on
web privacy. In Proceedings of the 7th ACM conference
on Computer and communications security, pages
25–32. ACM, 2000.
[13] R. Fielding, J. Gettys, J. Mogul, H. Frystyk,
L. Masinter, P. Leach, and T. Berners-Lee. Hypertext
transfer protocol–HTTP/1.1, 1999. RFC2616, 2006.
[14] H. Gao, J. Hu, T. Huang, J. Wang, and Y. Chen.
Security issues in online social networks. Internet
Computing, IEEE, 15(4):56–63, 2011.
[15] D. Goodin. Marketer taps browser ﬂaw to see if you’re
pregnant. http://www.theregister.co.uk/2011/07/
22/marketer_sniffs_browser_history/, July 2011.
[16] M. Heiderich, M. Niemietz, F. Schuster, T. Holz, and
J. Schwenk. Scriptless attacks: Stealing the pie
without touching the sill. In Proceedings of the 2012
ACM conference on Computer and communications
security, pages 760–771. ACM, 2012.
[17] D. Jang, R. Jhala, S. Lerner, and H. Shacham. An
empirical study of privacy-violating information ﬂows
in JavaScript web applications. In Proceedings of the
17th ACM conference on Computer and
communications security, pages 270–283. ACM, 2010.
[18] Y. Jia, X. Dong, Z. Liang, and P. Saxena. I know
where you’ve been: Geo-inference attacks via the
browser cache. Web 2.0 Security & Privacy (W2SP),
2014.
[19] M. Johns. Exploiting the intranet with a webpage.
http://web.sec.uni-passau.de/members/martin/
docs/070906_HITB_Martin_Johns.pdf, September
2007.
[20] P. C. Kocher. Timing attacks on implementations of
Diﬃe-Hellman, RSA, DSS, and other systems. In
Advances in Cryptology—CRYPTO’96, pages 104–113.
Springer, 1996.
[21] R. Kotcher, Y. Pei, P. Jumde, and C. Jackson.
Cross-origin pixel stealing: timing attacks using CSS
ﬁlters. In Proceedings of the 2013 ACM SIGSAC
conference on Computer & communications security,
pages 1055–1062. ACM, 2013.
[22] S. Lee, H. Kim, and J. Kim. Identifying cross-origin
resource status using Application Cache. In
Proceedings of the ISOC Network and Distributed
System Security Symposium (NDSS’15), 2015.
[23] LinkedIn. About LinkedIn.
https://press.linkedin.com/about-linkedin.
[24] J. Mann. High Resolution Time. W3C
recommendation, 2012.
[25] Microsoft. modern.IE - platform status.
https://status.modern.ie/serviceworker.
[26] Mozilla Developer Network. ServiceWorker api.
https://developer.mozilla.org/en-
US/docs/Web/API/ServiceWorker_API.
[27] Mozilla Developer Network. Using HTML5 audio and
video. https://developer.mozilla.org/en-US/docs/
Web/Guide/HTML/Using_HTML5_audio_and_video.
[28] Y. Nagami, D. Miyamoto, H. Hazeyama, and
Y. Kadobayashi. An independent evaluation of web
timing attack and its countermeasure. In Availability,
Reliability and Security (ARES), 2008.
[29] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel,
F. Piessens, and G. Vigna. Cookieless monster:
Exploring the ecosystem of web-based device
ﬁngerprinting. In Security and privacy (SP), 2013
IEEE symposium on, pages 541–555. IEEE, 2013.
[30] OOKLA Net Index. Household download index.
http://www.netindex.com/download/allcountries/,
February 2015.
[31] S. Schinzel. An eﬃcient mitigation method for timing
side channels on the web. In 2nd International
Workshop on Constructive Side-Channel Analysis and
Secure Design (COSADE), 2011.
[32] I. Schmitt and S. Schinzel. WAFFle: Fingerprinting
ﬁlter rules of web application ﬁrewalls. In WOOT,
pages 34–40, 2012.
[33] StatCounter. Top 5 desktop browsers on jan 2015.
http://gs.statcounter.com/#desktop-browser-ww-
monthly-201501-201501-bar, January 2015.
[34] P. Stone. Bug 711043 - (CVE-2013-1693) SVG ﬁlter
timing attack. https:
//bugzilla.mozilla.org/show_bug.cgi?id=711043,
December 2011.
[35] P. Stone. Pixel perfect timing attacks with HTML5.
Context Information Security (White Paper), 2013.
[36] Twitter. Company info.
https://about.twitter.com/company, February 2015.
[37] A. Van Kesteren and WHATWG. Fetch.
https://fetch.spec.whatwg.org/, January 2015.
[38] W3C. Navigation Timing.
http://www.w3.org/TR/navigation-timing/,
December 2012.
[39] W3C. Service Workers.
http://www.w3.org/TR/service-workers/, February
2015.
[40] Z. Weinberg, E. Y. Chen, P. R. Jayaraman, and
C. Jackson. I still know what you visited last summer:
Leaking browsing history via user interaction and side
channel attacks. In Security and Privacy (SP), 2011
IEEE Symposium on, pages 147–161. IEEE, 2011.
[41] WHATWG. Oﬄine web applications.
https://html.spec.whatwg.org/multipage/
browsers.html#offline, January 2015.
[42] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel. A
practical attack to de-anonymize social network users.
In Security and Privacy (SP), 2010 IEEE Symposium
on, pages 223–238. IEEE, 2010.
1393