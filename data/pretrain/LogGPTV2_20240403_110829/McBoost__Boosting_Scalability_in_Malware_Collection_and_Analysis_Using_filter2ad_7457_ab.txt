}i=1..k derived from the packed exe-
cutables, and a dataset S (N ) = {s(N )
}i=1..l derived from
the non-packed executables, and we call S = S (P) ∪ S (N ).
An n-gram is deﬁned as an n-bytes-long substring of a
binary string s. We extract all the possible n-grams from
each string s ∈ S, and then we select the M most informa-
tive n-grams, i.e., the most discriminative (or “powerful”)
i
i
features that allow us to separate instances of the positive
and negative class, according to an information gain met-
ric [23]. Speciﬁcally, the information gain of an n-gram g
is
IG(g) = (cid:88)
1
log P (c)
c
P (c)
+P (g)(cid:88)
+P (¯g)(cid:88)
c
P (c|g) log P (c|g)
P (c|¯g) log P (c|¯g)
c
where c ∈ {P,N} represents either the class of packed
executables P or the class of non-packed executables N ,
P (c|g) is the probability of a string s (i.e., an executable)
being of class c given that g is present in s, and P (c|¯g) is
the probability of a string s being of class c given that g is
not present in s.
Once the M most informative n-grams have been se-
lected, each executable e can be translated into a binary vec-
tor f(e) = x ∈ {0, 1}M , where the i-th element xi tells us
whether the string s that represents the executable (either its
code or the entire ﬁle) contains the i-th most informative n-
gram (xi = 1) or not (xi = 0). Using this approach, S can
be translated into a labeled dataset of pattern vectors that
can in turn be used to train a statistical classiﬁer.
We use a Bagged-Decision-Tree (BDT) classiﬁer [3] for
both A2 and A3. Bagged-Decision-Trees usually perform
very well and have the characteristic of producing calibrated
posterior class probabilities [11], which may be useful when
combining multiple classiﬁers (see Section 2.1.3). The de-
tails regarding the algorithm and parameters we used for
training the classiﬁers are reported in Section 3.
The utility of n-gram analysis for the code section (mod-
ule A2) is intuitive. The average length of the instructions
of Windows executables for x86 processors is between 2
and 3 bytes (we measured it on the code section of thou-
sands of benign executables). Choosing n ≥ 2, the pres-
ence or absence of an informative n-gram is related to the
presence or absence of a certain instruction in the code, or
a sequence of instructions, given that an n-gram may cap-
ture the end of an instruction and the beginning of the next,
for example. Therefore, each element of a pattern vec-
tor f(e) = x ∈ {0, 1}M given to the classiﬁer is related
to the presence or absence of an instruction or sequence
of instructions in the code of an executable e. Since the
code section of a packed executable usually contains the
unpacking/decryption routine and (possibly) the hidden (en-
crypted) code, its distribution of n-grams will likely be dif-
ferent from the distribution of n-grams of a non-packed ex-
ecutable. Module A2 is designed to detect this difference in
the distribution of n-grams.
The utility of n-gram analysis for the entire ﬁle (module
A3) is also intuitive. If the hidden (encrypted) code is stored
in a data section, hidden in unused ﬁelds of the main and
section headers, or somewhere else in the ﬁle, module A2
may not detect the fact that the executable is packed. The
n-gram analysis on the entire ﬁle adds a piece of evidence
for making a ﬁnal decision, and is based on the fact that the
presence of encrypted code in the ﬁle will cause a perturba-
tion of the overall “normal” distribution of n-grams (i.e., the
distribution of n-grams of non-packed executables). There-
fore, module A3 tries to capture this perturbation.
2.1.3 Combining Multiple Classiﬁers
For each input executable e, the output of each of the
modules A1, A2 and A3 is a posterior class probability
PAi(P|e), i.e., the probability that e is a packed executable
as estimated by module Ai, with i=1, 2, 3. Module A is
a Multiple Classiﬁer System (MCS) [10] that combines the
output of A1, A2, and A3, and produces an overall posterior
class probability PA(P|e) of e being packed.
Multiple Classiﬁer Systems usually perform better than
the single classiﬁer in the ensemble. This is particularly
true when the classiﬁers are diverse, in the sense that they
make different (ideally independent) mistakes on different
input vectors (i.e., different representations of PE executa-
bles, in our case) [10]. Diversity may be induced in a num-
ber of ways [6]. In our application we introduced diversity
among A1, A2, and A3 by training them on diverse repre-
sentations of the same dataset of packed and non-packed ex-
ecutables. Also, we used different classiﬁcation algorithms
(Multi-Layer Perceptron for A1 and Bagged-Decision Trees
for A2 and A3). Another important characteristic of MCS
is that the output of the single classiﬁers should be compa-
rable [6]. We chose Multi-Layer Perceptron and Bagged-
Decision-Tree as base classiﬁers because they both out-
put well-calibrated posterior class probabilities [11]. Also,
MCS are more robust and have been shown to be useful in
making evasion by mimicry attacks harder [12]
We use a simple but effective combination rule to com-
(cid:80)
bine the output of A1, A2, and A3, namely the average of
probabilities [10] and we set a decision threshold θ so that
if PA(P|e) = 1
i=1..3 PAi(P|e) > θ the executable e is
classiﬁed as packed (and sent to the unpacker), otherwise e
is classiﬁed as non-packed (and sent directly to module C).
θ can be tuned in order to ﬁnd the desired trade-off between
the false positive and false negative rates for module A.
3
2.2 Extracting Hidden Code
We implemented our unpacker (module B) in a way very
similar to Renovo [8], using the QEMU emulator [1]. Ev-
ery time an instruction i is executed on behalf of a process
P , the unpacker U will intercept it and check whether i was
previously dynamically generated by P itself. If this is the
304304
case, i will be marked as hidden code. i will then be con-
sidered as the ﬁrst instruction of a layer of unpacking [8].
Whenever U detects that P is trying to execute a new dy-
namically generated instruction i(cid:48), this will mark the end of
a layer of unpacking and the start of a new one. U will then
dump the binary code of the ﬁrst layer to disk and will keep
tracing the execution of the next layer [8].
We adopt two different strategies to dump the hidden bi-
nary code in each layer of unpacking:
• bpage. This strategy dumps all the memory pages
where the instructions belonging to a hidden layer re-
side. For example, assume instruction i1 belongs to an
unpacking layer l and is located in page p1, and an-
other instruction i2 also belongs to the same layer l,
but is located in page p2. In this case both the p1 and
p2 (the entire pages) will be dumped by U and marked
as related to the layer l.
• bbexec. This strategy dumps only the instructions of a
layer of unpacking that were actually executed by P .
In order to do this, the monitor U keeps trace of the in-
structions in the QEMU translation blocks [1] (or basic
blocks) that were actually executed by the emulator.
The bbexec dumps may be useful in those cases when a bi-
nary is packed using executable packing tools that perform
encryption/decryption operations at the single instruction
level. On the other hand, the bpage dumps may be useful to
extract the hidden code of binaries that were packed by ex-
ecutable packing tools that perform encryption/decryption
at the memory page level. It is worth noting that both tech-
niques may provide only a partial reconstruction of the orig-
inal executable code embedded in the packed binary.
We set two time-out parameters, namely a per layer
time-out Tl and a global time-out Tg.
If any time-out is
reached the process P will be terminated. Apart from reach-
ing a time-out, there are other reasons why U may terminate
the process P . For example, our unpacker is able to in-
tercept calls to the NtRaiseHardError native API and
therefore report an application crash. Also, the unpacker is
able to detect “normal” process exits and system errors.
2.3 Detecting Malicious Code
Similarly to module A2, the classiﬁers in module C are
based on the n-gram analysis of the code portion of exe-
cutables. The difference is in the fact that module A2 is spe-
cialized in detecting packed vs. non-packed code, whereas
modules C1 and C2 are responsible for distinguishing be-
tween malware vs. benign non-packed or hidden (extracted
by the unpacker) code, respectively. The design and imple-
mentation of specialized classiﬁers based on n-gram analy-
sis of non-packed code (C1) and hidden code extracted from
packed executables (C2) is one of the contributions of this
work.
In order to train module C1 we collect a dataset of non-
packed malware and non-packed benign executables (the
details of how we construct the dataset are reported in Sec-
tion 3.1.1), and extract their code sections. We then select
the M most informative n-grams in the code of executa-
bles from the two classes, as explained in Section 2.1.2,
and we use these n-grams to translate each executable into
a pattern vector representation that can be used to train a
statistical classiﬁer. As for modules A1 and A2, we use
Bagged-Decision-Trees (BDT) as classiﬁer. During test,
for each analyzed executable e the output of module C1
(i.e., of the BDT classiﬁer) is an estimate of the probabil-
ity P (malware|e) that e’s (non-packed) code is malicious.
We use the same approach to train module C2. The
only difference is that the training dataset is made of a
collection of hidden-code extracted (using our unpacker)
from packed malware and packed benign executables. Like
for C1, the output of C2 is an estimate of the probability
P (malware|e) that e’s hidden code is malicious. The use
of either module C1 or module C2 for each executable e un-
der test depends on the results of modules A and B (i.e., of
the packer detector and the unpacker), as explained above
(at the beginning of Section 2) and shown in Fig. 1.
The intuition behind the use of n-gram analysis is that
the presence or absence of an informative n-gram (see Sec-
tion 2.1.2) is related to the presence or absence of a certain
instruction or sequence of instructions in the code of an ex-
ecutable e. We speculate that the code section of malicious
executables contain certain instructions, or sequences of in-
structions more than others. These instructions are used to
carry out malicious activities and may not be present with
the same frequency or sequence in benign code. This in-
tuition is (partially) in accordance with the results reported
in [2]. Modules C1 and C2 capture this difference in the
distribution of sequences of instructions between malicious
and benign code using n-gram analysis.
3 Experiments
In this section we discuss in detail how we performed the
evaluation of McBoost and its components, and we present
the obtained experimental results. We performed our exper-
iments on a machine with a 2GHz dual-core AMD Opteron
processor and 8 GByte of memory.
3.1 Experimental Setup
3.1.1 Preparation of the Datasets
To evaluate the effectiveness of McBoost, we collected sev-
eral thousands of Windows benign and malicious PE exe-
305305
cutables. Overall we collected 5,586 distinct known mal-
ware binaries and 2,258 benign, which we divided in the
following labeled datasets:
Malware-Dataset (MDset). We collected a set of 5,586
malware executables from the Malfease dataset (http:
//malfease.oarci.org) in July 2007. We used three
Anti-virus (AV) software products, namely clamAV (www.
clamav.net), F-Prot (www.f-prot.com), and AVG
(free.grisoft.com), to verify that the binaries col-
lected from the Malfease dataset were actually all know
malware.
Packed-Malware-Dataset
(PMDset). We used PEiD
(http://www.peid.info) and the packer-detection
capabilities of F-Prot to select packed malware binaries
from Malware-Dataset, and we obtained 2,078 packed bi-
naries. PEiD detected 2,039 binaries packed using around
70 distinct packers, whereas F-Prot detected 328 binaries
packed using 20 distinct packers. The two sets slightly over-
lap. For around one third of the malware detected as packed
by F-Prot, the use of multiple layers of packing was reported
(to the best of our knowledge, PEiD is not capable of detect-
ing multi-layer packing).
the binaries in Packed-Malware-Dataset
Non-Packed-Malware-Dataset (NPMDset). We ﬁltered
out
from the
Malware-Dataset, thus keeping 3,508 binaries. On this set
we ran Polyunpack [16] and our dynamic unpacker and
found 174 executables for which neither Polyunpack nor
our unpacker were able to extract any hidden code, and that
did not cause any error (e.g., application crash). On these
174 executables we also ran Renovo1 [8] in order to further
ﬁlter any possibly packed executable missed (i.e., no hid-
den code was detected) by Polyunpack and our unpacker2.
We ﬁltered-out the binaries for which Renovo was able to
extract any hidden code and we obtained 146 likely non-
packed malware (although this dataset may still contain few
packed executables, we believe the use of multiple state-of-
the-art techniques allowed us to reduce possible noise to a
minimum).
Other-Malware-Dataset (OMDset). This dataset con-
sists of the 3,362 malware in MDset that do not belong
to neither PMDset nor NPMDset. Although many of this
executables are likely packed (because at least one of the
three universal unpackers we used was able to extract some
kind of hidden code from them), they were not detected by
1We were able to do this thanks to the kind collaboration of the authors
of Renovo.
2Although our universal unpacker follows the design described in [8],
some implementation details may be different, and therefore the result of
unpacking may differ from the result obtained with Renovo, in some cases.
the signature-based packer detectors, i.e., PEiD and F-Prot.
Therefore, we chose not to include them in the PMDset be-
cause we did not want to risk to “poison” the PMDset with