where c is the size of the context windows, xn denotes the
input central character and xn+ j for its neighboring character.
The basic skip-gram formulation deﬁnes p(xn+ j|xn) using the
following softmax function,
p(xn+ j|xn) =
exp(www(2)
k=1 exp(www(2)
∑V
k
n+ j · www(1)
n )
· www(1)
n )
,
(8)
where www(1)
n
WWW (2), corresponding to character xn and xk respectively.
k denote row vectors in matrices WWW (1) and
and www(3)
Glyph Embedding. In Chinese writing system, there are a
large set of characters that are visually similar but have totally
different meanings. This property has been exploited for craft-
ing glyph-based perturbations, e.g., replacing “赌”(gamble)
in “赌博” with a similar character “堵” (block). To improve
the resilience of a DLTC model against such perturbations,
we specially design a glyph embedding scheme to extract the
glyph-based features of each character for capturing the simi-
larity between the perturbed word and its benign counterpart.
To embed each character into a glyph embedding vector
with the same dimension as its semantic embedding vector,
we ﬁrst convert it into an image of size 24× 24× 3 by using
a Python tool 2 dedicated to image processing. Second, we
carefully design a simple convolutional neural network named
g-CNN, which is modiﬁed from LeNet-5 [24] by replacing
the fully connected layer and output layer with a convolution
layer consisting of d ﬁlters of size 1× 1 [28] and a global
2https://pypi.org/project/Pillow/
Figure 2: Architecture of the adversarial NMT model.
Eq. (2) can be rewritten as
p(xxx∗|xxx) =
N(cid:48)
∏
i=1
p(x(cid:48)
i|x(cid:48)
1,··· ,x(cid:48)
i−1,ccc) =
N(cid:48)
∏
i=1
g(x(cid:48)
i−1,sssi,ccci),
(4)
and the target character x(cid:48)
i generated at each time i is sampled
from the candidates by maximizing the conditional probabil-
ity g(x(cid:48)
i−1,sssi,ccci). Note that xxx and xxx∗ are both Chinese, and
we hence share the embedding vocabulary of E with D to re-
duce the amount of parameters. The designed NMT is ﬁnally
implemented based on the TensorFlow NMT tutorial [30].
Model Training. In the training phase, we ﬁrst construct
a large adversarial parallel corpora Dadv by generating a
plenty of (xxxadv,xxxori) sentence pairs through adversarial at-
tacks. Then, the designed NMT model is trained on Dadv to
learn the process of adversarial correction from adversarial
texts to the benign texts by minimizing the negative log prob-
ability of a correct translation xxxori given the source sequence
xxxadv. Formally, the training objective is deﬁned as
L(θ) = − 1
|Dadv|
∑
(xxxadv,xxxori)∈Dadv
log p(xxxori|xxxadv).
(5)
To avoid the error being ampliﬁed step by step during the
training process as well as improving the training stability to
accelerate the convergence, we apply the teacher forcing [45]
technique to train the NMT model by using the ground truth
from a prior time step as the current input of the decoder D.
Adversarial Correction. Once the training is completed,
the NMT model is then used as an adversarial text corrector
to reconstruct the original text through translation. Formally,
the corrected text xxx∗
opt is produced by ﬁnding an optimal
translation that maximizes the conditional probability, i.e.,
xxx∗
opt = argmax
xxx∗∈X
p(xxx∗|xxxadv;θ).
(6)
To improve the performance of the NMT model, we apply
beam-search [14] in the decoding phase to search for the
optimal translation. Finally, xxx∗
opt will be fed into F for multi-
modal embedding and then for the conventional classiﬁcation.
1384    29th USENIX Security Symposium
USENIX Association
洁身自好远离赌博Attention Layer洁身自好远离赌博Decoder洁身自好远离堵搏EncoderEmbedEmbedKeep your nose clean, keep away from gamblingaverage pooling layer. Then, we integrate g-CNN as a glyph
embedding layer into the DLTC model and train its parameters
together with the whole DLTC model. Finally, we use the
features extracted by the global average pooling layer of g-
CNN as the glyph embedding vector.
Phonetic Embedding. Most existing DLTC models have
only focused on the writing itself, while ignoring the fact
that spoken language expresses the meaning directly. Unlike
English whose pronunciation is tied to the alphabets, Chinese
characters do not reﬂect the pronunciation and need to be
annotated by Hanyu Pinyin 3. In addition, Pinyin can also be
directly used as a written language to express the meaning.
Hence, similar to glyph embedding, we design a phonetic em-
bedding scheme to extract phonetic-based features of Chinese
characters for enhancing the performance a DLTC model as
well as its robustness against the phonetic-based perturbations
such as “涩情” or “se qing” which are mutated from the toxic
word “色情” (porn) and have the same pronunciation.
For each character, we ﬁrst use Pinyin to annotate its pro-
nunciation, and non Chinese characters in the text are pre-
served. Then, we obtain a new sequence that contains N
Pinyin forms for each text consisting of N characters. Finally,
we apply the skip-gram model as used in semantic embedding
to embed the Pinyin form of each character into a phonetic
embedding vector of d dimensions.
3.5 Multimodal Fusion
Since multiple modalities can provide more valuable infor-
mation than a single one by describing the same content in
various ways, it is highly expected to learn effective joint
representation by fusing the features of different modalities.
Therefore, after multimodal embedding, we ﬁrst fuse the fea-
tures extracted from different modalities by multimodal fusion
and then feed the fused features into a classiﬁcation model
for regular classiﬁcation. In this paper, we experiment with
two different fusion strategies, i.e., early multimodal fusion
and intermediate multimodal fusion as shown in Fig. 10 in
Appendix A.
Early Multimodal Fusion (EMF). EMF [35] refers to di-
rectly concatenating features from all the modalities and then
employing multiple nonlinear transformations to generate the
high-level joint representation. More formally, denote by VVV (S)
the semantic embedding vector, by VVV (G) the glyph embedding
vector and by VVV (P) the phonetic embedding vector, the fused
vector VVV is obtained by
VVV = [VVV (S) ⊕VVV (G) ⊕VVV (P)].
(9)
Obviously, it is an input-level fusion scheme, which is easy to
capture the covariation between modalities, and other correla-
tions existed at the input level. Meanwhile, it is the simplest
to implement and requires less model parameters. However,
3Hanyu Pinyin is the ofﬁcial romanization system used for annotating the
pronunciation of Standard Chinese.
it is also a coarse-grained fusion scheme that lacks the ability
in capturing more complex correlation across modalities.
Intermediate Multimodal Fusion (IMF). The basic idea
of IMF is to reduce the inﬂuence of individual differences
and improve the shared semantic by building a joint feature
representation based on the output of modality-speciﬁc net-
works [41]. Under this fusion scheme, the embedding vector
from each modality is ﬁrst fed into a unimodal backbone net-
work, and then the outputs of the last hidden layers in all the
unimodal backbones are concatenated for fusion. Hence, the
fused vector VVV is obtained by
VVV = [Fs(VVV (S))⊕ Fg(VVV (G))⊕ Fp(VVV (P))],
(10)
where Fs(·), Fg(·) and Fp(·) are the unimodal backbones spe-
cialized for semantics, glyphs and phonetics, respectively.
Classiﬁcation. The vector VVV fused by EMF or IMF is then
classiﬁed by
F(y = i|xxx) =
exp( f (VVV )i)
j=0 exp( f (VVV ) j)
,
∑K
(11)
where F(y = i|xxx) is the conﬁdence of the i-th class, f (·) is the
classiﬁcation function of model F and K is the total number
of classes. Note that the parameters of the backbones used
for multimodal fusion are trained together with F .
4 Experimental Setting and Implementation
4.1 Dataset
We evaluate TEXTSHIELD on three datasets of which two are
used for toxic content detection and one is used for adversarial
NMT. Each dataset is divided into three parts, i.e., 80%, 10%,
10% as training, validation and testing, respectively [26].
Toxic Content Detection. Since there currently does not
exist a benchmark dataset for Chinese toxic content detection,
we used two user generated content (UGC) datasets, i.e., Abu-
sive UGC (Abuse) and Pornographic UGC (Porn) collected
from online social media (the data collection details can be
found in Appendix B). Each dataset contains 10,000 toxic
and 10,000 normal samples that are well annotated by Chi-
nese native speakers. The average text length of the Abuse
and Porn datasets are 42.1 and 39.6 characters, respectively.
The two datasets are used for building binary classiﬁcation
models for abuse detection and porn detection tasks.
Adversarial NMT. To increase the diversity of the ad-
versarial parallel corpora and ensure that the NMT model
can learn more language knowledge, we applied the Douban
Movie Short Comments (DMSC) dataset released by Kaggle
4 along with Abuse and Porn. We then generate a corpora
that consists of 2 million (xxxadv,xxxori) sentence pairs for each
task respectively, of which half is generated from DMSC and
half is generated from the toxic datasets. The method used
for generating sentence pairs is detailed in Section 4.3.
4https://www.kaggle.com/utmhikari/doubanmovieshortcomments/
USENIX Association
29th USENIX Security Symposium    1385
Example
傻逼 → 傻&逼
Table 1: Examples for six different kinds of bugs.
Bug
Example
裸体 → 裸体
Sim2Trad/1
裸体 → 裸&体
Sim2Trad/2
赌博 → 堵博
GlyphSim/1
赌博 → 堵搏
GlyphSim/2
赌博 → 堵t搏
GlyphSim/3
PhoneticSim/1 色情 → 涩情
PhoneticSim/2 色情 → 涩o情
Bug
Insert
PyConvert/1 智障 → zhi zhang
PyConvert/2 智障 → zhi zha.ng
PyConvert/3 智障 → zhi zhan
PyConvert/4 智障 → zhi zhnag
PyConvert/5 智障 → Zhi zhang
炸弹 → 火乍弓单
Split/1
炸弹 → 炸弓/单
Split/2
4.2 Target Model
We implement a TextCNN [23] model and a BiLSTM [50]
model as the backbone networks to design the target model
since these two DNNs are most widely used in real-world text
classiﬁcation tasks [10,23,50]. In addition, the two models are
often used in evaluating the efﬁcacy of adversarial attacks and
have been shown to be vulnerable to adversarial examples
[11, 12, 26]. Based on the two backbones and combined
with multimodal embedding and adversarial NMT, we totally
implemented ten target models for abuse detection and porn
detection, which are: Common TextCNN, Common BiLSTM,
TextCNN + EMF, TextCNN + IMF, TextCNN + EMF + NMT,
TextCNN + IMF + NMT, BiLSTM + EMF, BiLSTM + IMF,
BiLSTM + EMF + NMT and BiLSTM + IMF + NMT.
Speciﬁcally, the common TextCNN and BiLSTM are built
upon the TextCNN and BiLSTM backbones with no defense
applied. “+ EMF” and “+IMF” represent that the input of the
model is embedded by the multimodal embedding method and
the extracted features are fused by EMF and IMF strategies,
respectively. Similarly, “+EMF+NMT” and “+IMF+NMT”
represent that the input text is ﬁrst fed into the NMT model
for adversarial correction and then processed by multimodal
embedding, and ﬁnally fused by EMF and IMF, respectively.
4.3 Attack Method
In the real adversarial scenario, most of the Chinese adversar-
ial texts are manually crafted by malicious netizens with black-
box access to the models, which has posed severe threats
to the real-world applications [16, 25, 48]. However, man-
ual collection of these texts for evaluating the efﬁcacy of
TEXTSHIELD are usually laborious and costly. An intuitive
idea is to mimic their attack behavior via adversarial attacks
under the black-box setting. Since there is no proposed auto-
matic black-box attack specialized for Chinese-based DLTC
models in existing research, we then adopted TextBugger [26]
as the attack method.
Recall that TextBugger ﬁrst identiﬁes the important word by
sensitivity analysis based on the classiﬁcation conﬁdence and
then replaces the important word by an optimal adversarial
bug selected from the carefully crafted bug candidates. Since
it is initially designed for English-based NLP systems and
cannot be directly adopted for generating Chinese adversarial
texts, we extend it to our tasks by redesigning the adversar-
ial bugs. Based on the commonly used variation strategies
adopted by real-world malicious users [16, 25], we carefully
designed six kinds of bugs, which are: (1) Insert: Insert a
meaningless character into the benign word. (2) PyConvert:
Convert the word into its Pinyin form, e.g., replacing the
word “智障” (idiot) with “zhi zhang”. We can also modify
the converted Pinyin by insertion, deletion, swap or substitu-
tion operations for further perturbation. (3) Split: Split one
character into more characters and then replace the original
character with the splitted characters, e.g., replacing the word
“炸弹” (bomb) with “火乍弓单” which looks similar but has
completely different meanings. (4) Sim2Trad: Convert the
simpliﬁed Chinese character into its traditional form, e.g.,
converting the word “裸体” (nude) into “裸体”. The character
“体” has the same meaning with “体” but will be embedded
into a different vector, thus affecting the model’s classiﬁcation
result. (5) GlyphSim: Replace the character with another one
that has similar glyphs, e.g., replacing “赌博” (gamble) with
“堵搏”. This perturbation has little impact on human under-
standing due to the powerful human perception and cognition.
(6) PhoneticSim: Replace a character with another one that
has the same pronunciation, e.g., replacing the word “色情”
(porn) with “涩情” whose Pinyin are both “se qing”. The
empirical study on a corpus of real-world attack examples
shows that over 98% of the samples can be categorized into
one of the six types of bugs (see Fig. 5). More detailed bug
examples are shown in Table 1.
4.4 Baselines
We implement and compare two state-of-the-art methods
with TEXTSHIELD to evaluate their robustness against the
extended TextBugger. In total, the two methods are: (1) Py-
corrector: This method was ﬁrst proposed in [47] for dealing
with Chinese spelling errors or glyph-based and phonetic-
based word variations in user generated texts based on the
n-gram language model. In our experiments, we use an online
version of Pycorrector implemented in Python 5. (2) TextCor-
rector: It is a Chinese text error correction service developed
by Baidu AI 6 for correcting spelling errors, grammatical
errors and knowledge errors based on language knowledge,
contextual understanding and knowledge computing tech-
niques. In our experiments, we study the efﬁcacy of these two
defenses by combining them with the common TextCNN and
BiLSTM, respectively. In addition, the common TextCNN
and BiLSTM are baseline models themselves.
4.5 Evaluation Metrics
Translation Evaluation. We use three metrics, i.e, word error
rate, bilingual evaluation understudy and semantic similarity
5https://pypi.org/project/pycorrector/
6https://ai.baidu.com/tech/nlp/text_corrector
1386    29th USENIX Security Symposium
USENIX Association
to evaluate the translation performance of our adversarial
NMT model from word, feature and semantics levels.
(1) Word Error Rate (WER). It is derived from the Lev-
enshtein distance and is a word-level metric to evaluate the
performance of NMT systems [1]. It is calculated based on
the sum of substitutions (S), deletions (D) and insertions
(I) for transforming the reference sequence to the target se-
quence. Suppose that there are total N words in the reference
sequence. Then, WER can be calculated by W ER = S+D+I
.
The range of WER is [0,1] and a smaller value reﬂects a better
translation performance.
(2) Bilingual Evaluation Understudy (BLEU). This met-
ric was ﬁrst proposed in [38]. It evaluates the quality of trans-
lation by comparing the n-grams of the candidate sequence
with the n-grams of the reference sequence and counting the
number of matches. Concretely, it can be computed as
N
BLEU = BP· exp(
wn log pn),
(12)
N
∑
n=1
where pn is the modiﬁed n-grams precision (co-occurrence),
wn is the weight of n-grams co-occurrence and BP is the
sentence brevity penalty. The range of BLEU is [0,1) and a
larger value indicates a better performance. In our experiment,