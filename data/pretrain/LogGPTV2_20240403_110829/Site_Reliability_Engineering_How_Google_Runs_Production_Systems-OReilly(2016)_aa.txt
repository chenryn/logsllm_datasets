Site 
Reliability 
Engineering
HOW GOOGLE RUNS PRODUCTION SYSTEMS
Edited by Betsy Beyer, Chris Jones, 
Jennifer Petoff & Niall Richard Murphy
Praise for Site Reliability Engineering
Google’s SREs have done our industry an enormous service by writing up the principles, practices and patterns—architectural and cultural—that enable their teams to combine continuous delivery with world-class reliability at ludicrous scale. You owe it to yourself and your organization to read this book and try out these ideas for yourself.—Jez Humble, coauthor of Continuous Delivery and Lean Enterprise
I remember when Google first started speaking at systems administration conferences. It was like hearing a talk at a reptile show by a Gila monster expert. Sure, it was entertaining to hear about a very different world, but in the end the audience 
would go back to their geckos.would go back to their geckos.
Now we live in a changed universe where the operational practices of Google are not so removed from those who work on a smaller scale. All of a sudden, the best practices of SRE that have been honed over the years are now of keen interest to the rest of us. For those of us facing challenges around scale, reliability and operations, this book comes none too soon.—David N. Blank-Edelman, Director, USENIX Board of Directors, and founding co-organizer of SREcon
I have been waiting for this book ever since I left Google’s enchanted castle. It is the gospel I am preaching to my peers at work.
—Björn Rabenstein, Team Lead of Production Engineering at SoundCloud, Prometheus developer, and Google SRE until 2013A thorough discussion of Site Reliability Engineering from the company that invented the concept. Includes not only the technical details but also the thought process, goals, principles, and lessons learned over time. If you want to learn what SRE really means, start here.
—Russ Allbery, SRE and Security EngineerWith this book, Google employees have shared the processes they have taken, including the missteps, that have allowed Google services to expand to both massive scale and great reliability. I highly recommend that anyone who wants to create a set of integrated services that they hope will scale to read this book. The book provides an insider’s guide to building maintainable services.
—Rik Farrow, USENIX—Rik Farrow, USENIX
Writing large-scale services like Gmail is hard. Running them with high reliability is even harder, especially when you change them every day. This comprehensive“recipe book” shows how Google does it, and you’ll find it much cheaper to learn from our mistakes than to make them yourself.
—Urs Hölzle, SVP Technical Infrastructure, Google
Site Reliability Engineering How Google Runs Production SystemsEdited by Betsy Beyer, Chris Jones, Jennifer Petoff, and Niall Richard Murphy
Beijing Boston Farnham Sebastopol Tokyo 
Site Reliability Engineering 
Edited by Betsy Beyer, Chris Jones, Jennifer Petoff, and Niall Richard Murphy Copyright © 2016 Google, Inc. All rights reserved.
Printed in the United States of America.
Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are also available for most titles (). For more information, contact our corporate/ institutional sales department@oreilly.com.
Editor: Brian Anderson 
Production Editor: Kristen Brown Copyeditor: Kim Cofer 
Proofreader: Rachel Monaghan
Indexer: Judy McConville 
Interior Designer: David FutatoInterior Designer: David Futato 
Cover Designer: Karen Montgomery Illustrator: Rebecca Demarest
April 2016:	 First Edition
Revision History for the First Edition
2016-03-21: First Release
See  for release details.
The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Site Reliability Engineering, the cover image, and related trade dress are trademarks of O’Reilly Media, Inc.While the publisher and the authors have used good faith efforts to ensure that the information and instructions contained in this work are accurate, the publisher and the authors disclaim all responsibility for errors or omissions, including without limitation responsibility for damages resulting from the use of or reliance on this work. Use of the information and instructions contained in this work is at your own risk. If any code samples or other technology this work contains or describes is subject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and/or rights.978-1-491-92912-4
[LSI]
Table of Contents
Foreword. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xiii
Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xv
Part I.  Introduction1. Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  3 The Sysadmin Approach to Service Management                                                      3 Google’s Approach to Service Management: Site Reliability Engineering               5 Tenets of SRE                                                                                                                    7 The End of the Beginning                                                                                             122. The Production Environment at Google, from the Viewpoint of an SRE. . . . . . . . . . . .  13 Hardware                                                                                                                         13 System Software That “Organizes” the Hardware                                                     15 Other System Software                                                                                                  18 Our Software Infrastructure                                                                                         19 Our Development Environment                                                                                  19 Shakespeare: A Sample Service                                                                                    20Part II.  Principles
3. Embracing Risk. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  25 Managing Risk                                                                                                                25 Measuring Service Risk                                                                                                 26 Risk Tolerance of Services                                                                                            28v
Motivation for Error Budgets                                                                                       33
4. Service Level Objectives. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  37Service Level Terminology                                                                                           37 Indicators in Practice                                                                                                    40 Objectives in Practice                                                                                                    43 Agreements in Practice                                                                                                 475. Eliminating Toil. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  49Toil Defined                                                                                                                    49 Why Less Toil Is Better                                                                                                  51 What Qualifies as Engineering?                                                                                   52 Is Toil Always Bad?                                                                                                        52 Conclusion                                                                                                                      546. Monitoring Distributed Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  55Definitions                                                                                                                      55 Why Monitor?                                                                                                                56 Setting Reasonable Expectations for Monitoring                                                      57 Symptoms Versus Causes                                                                                             58 Black-Box Versus White-Box                                                                                       59 The Four Golden Signals                                                                                              60 Worrying About Your Tail (or, Instrumentation and Performance)                      61 Choosing an Appropriate Resolution for Measurements                                        62 As Simple as Possible, No Simpler                                                                              62 Tying These Principles Together                                                                                 63 Monitoring for the Long Term                                                                                    64 Conclusion                                                                                                                      667. The Evolution of Automation at Google. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  67The Value of Automation                                                                                             67 The Value for Google SRE                                                                                            70 The Use Cases for Automation                                                                                    70 Automate Yourself Out of a Job: Automate ALL the Things!                                  73 Soothing the Pain: Applying Automation to Cluster Turnups                                75 Borg: Birth of the Warehouse-Scale Computer                                                         81 Reliability Is the Fundamental Feature                                                                       83 Recommendations                                                                                                         848. Release Engineering. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  87
The Role of a Release Engineer                                                                                    87 Philosophy                                                                                                                      88
vi  |  Table of Contentsvi  |  Table of Contents
Continuous Build and Deployment                                                                            90 Configuration Management                                                                                         93 Conclusions                                                                                                                    959. Simplicity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  97System Stability Versus Agility                                                                                    97 The Virtue of Boring                                                                                                     98 I Won’t Give Up My Code!                                                                                           98 The “Negative Lines of Code” Metric                                                                         99 Minimal APIs                                                                                                                 99 Modularity                                                                                                                    100 Release Simplicity                                                                                                        100 A Simple Conclusion                                                                                                   101Part III.  Practices
10. Practical Alerting from Time-Series Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  107The Rise of Borgmon                                                                                                  108 Instrumentation of Applications                                                                               109 Collection of Exported Data                                                                                      110 Storage in the Time-Series Arena                                                                              111 Rule Evaluation                                                                                                            114 Alerting                                                                                                                         118 Sharding the Monitoring Topology                                                                          119 Black-Box Monitoring                                                                                                120 Maintaining the Configuration                                                                                  121 Ten Years On…                                                                                                            12211. Being On-Call. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  125Introduction                                                                                                                 125 Life of an On-Call Engineer                                                                                       126 Balanced On-Call                                                                                                         127 Feeling Safe                                                                                                                   128 Avoiding Inappropriate Operational Load                                                              130 Conclusions                                                                                                                  13212. Effective Troubleshooting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  133
Theory                                                                                                                           134 In Practice                                                                                                                     136 Negative Results Are Magic                                                                                        144 Case Study                                                                                                                     146Table of Contents  |  vii
Making Troubleshooting Easier                                                                                150 Conclusion                                                                                                                    150
13. Emergency Response. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  151What to Do When Systems Break                                                                             151 Test-Induced Emergency                                                                                            152 Change-Induced Emergency                                                                                     153 Process-Induced Emergency                                                                                      155 All Problems Have Solutions                                                                                     158 Learn from the Past. Don’t Repeat It.                                                                        158 Conclusion                                                                                                                    15914. Managing Incidents. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  161Unmanaged Incidents                                                                                                 161 The Anatomy of an Unmanaged Incident                                                               162 Elements of Incident Management Process                                                             163 A Managed Incident                                                                                                    165 When to Declare an Incident                                                                                     166 In Summary                                                                                                                  16615. Postmortem Culture: Learning from Failure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  169
Google’s Postmortem Philosophy                                                                              169 Collaborate and Share Knowledge                                                                            171 Introducing a Postmortem Culture                                                                          172 Conclusion and Ongoing Improvements                                                                17516. Tracking Outages. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  177
Escalator                                                                                                                        178 Outalator                                                                                                                       17817. Testing for Reliability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  183
Types of Software Testing                                                                                           185 Creating a Test and Build Environment                                                                   190 Testing at Scale                                                                                                             192 Conclusion                                                                                                                    20418. Software Engineering in SRE. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  205
Why Is Software Engineering Within SRE Important?                                          205 Auxon Case Study: Project Background and Problem Space                               207 Intent-Based Capacity Planning                                                                                209 Fostering Software Engineering in SRE                                                                   218 Conclusions                                                                                                                  222viii  |  Table of Contents
19. Load Balancing at the Frontend. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  223
Power Isn’t the Answer                                                                                                223 Load Balancing Using DNS                                                                                        224 Load Balancing at the Virtual IP Address                                                                22720. Load Balancing in the Datacenter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  231
The Ideal Case                                                                                                              232 Identifying Bad Tasks: Flow Control and Lame Ducks                                          233 Limiting the Connections Pool with Subsetting                                                     235 Load Balancing Policies                                                                                              24021. Handling Overload. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  247The Pitfalls of “Queries per Second”                                                                         248 Per-Customer Limits                                                                                                   248 Client-Side Throttling                                                                                                 249 Criticality                                                                                                                      251 Utilization Signals                                                                                                        253 Handling Overload Errors                                                                                          253 Load from Connections                                                                                              257 Conclusions                                                                                                                  25822. Addressing Cascading Failures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  259Causes of Cascading Failures and Designing to Avoid Them                               260 Preventing Server Overload                                                                                       265 Slow Startup and Cold Caching                                                                                 274 Triggering Conditions for Cascading Failures                                                        276 Testing for Cascading Failures                                                                                   278 Immediate Steps to Address Cascading Failures                                                     280 Closing Remarks                                                                                                          28323. Managing Critical State: Distributed Consensus for Reliability. . . . . . . . . . . . . . . . . .  285Motivating the Use of Consensus: Distributed Systems Coordination Failure  288 How Distributed Consensus Works                                                                          289 System Architecture Patterns for Distributed Consensus                                     291 Distributed Consensus Performance                                                                        296 Deploying Distributed Consensus-Based Systems                                                 304 Monitoring Distributed Consensus Systems                                                           312 Conclusion                                                                                                                    31324. Distributed Periodic Scheduling with Cron. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  315
Cron                                                                                                                               315 Cron Jobs and Idempotency                                                                                       316
Table of Contents  |  ixCron at Large Scale                                                                                                      317 Building Cron at Google                                                                                             319 Summary                                                                                                                       32625. Data Processing Pipelines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  327Origin of the Pipeline Design Pattern                                                                       327 Initial Effect of Big Data on the Simple Pipeline Pattern                                       328 Challenges with the Periodic Pipeline Pattern                                                        328 Trouble Caused By Uneven Work Distribution                                                      328 Drawbacks of Periodic Pipelines in Distributed Environments                           329 Introduction to Google Workflow                                                                            333 Stages of Execution in Workflow                                                                               335 Ensuring Business Continuity                                                                                   337 Summary and Concluding Remarks                                                                         33826. Data Integrity: What You Read Is What You Wrote. . . . . . . . . . . . . . . . . . . . . . . . . . . .  339Data Integrity’s Strict Requirements                                                                         340 Google SRE Objectives in Maintaining Data Integrity and Availability              344 How Google SRE Faces the Challenges of Data Integrity                                      349 Case Studies                                                                                                                  360 General Principles of SRE as Applied to Data Integrity                                         367 Conclusion                                                                                                                    36827. Reliable Product Launches at Scale. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  369Launch Coordination Engineering                                                                           370 Setting Up a Launch Process                                                                                      372 Developing a Launch Checklist                                                                                 375 Selected Techniques for Reliable Launches                                                              380 Development of LCE                                                                                                   384 Conclusion                                                                                                                    387Part IV.  Management
28. Accelerating SREs to On-Call and Beyond. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  391You’ve Hired Your Next SRE(s), Now What?                                                          391 Initial Learning Experiences: The Case for Structure Over Chaos                      394 Creating Stellar Reverse Engineers and Improvisational Thinkers                      397 Five Practices for Aspiring On-Callers                                                                     400 On-Call and Beyond: Rites of Passage, and Practicing Continuing Education  406 Closing Thoughts                                                                                                         406x  |  Table of Contents
29. Dealing with Interrupts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  407
Managing Operational Load                                                                                      408 Factors in Determining How Interrupts Are Handled                                           408 Imperfect Machines                                                                                                     40930. Embedding an SRE to Recover from Operational Overload. . . . . . . . . . . . . . . . . . . . . .  417
Phase 1: Learn the Service and Get Context                                                            418 Phase 2: Sharing Context                                                                                            420 Phase 3: Driving Change                                                                                            421 Conclusion                                                                                                                    42331. Communication and Collaboration in SRE. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  425Communications: Production Meetings                                                                  426 Collaboration within SRE                                                                                           430 Case Study of Collaboration in SRE: Viceroy                                                          432 Collaboration Outside SRE                                                                                        437 Case Study: Migrating DFP to F1                                                                              437 Conclusion                                                                                                                    44032. The Evolving SRE Engagement Model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  441SRE Engagement: What, How, and Why                                                                 441 The PRR Model                                                                                                            442 The SRE Engagement Model                                                                                     443 Production Readiness Reviews: Simple PRR Model                                               444 Evolving the Simple PRR Model: Early Engagement                                             448 Evolving Services Development: Frameworks and SRE Platform                        451 Conclusion                                                                                                                    456Part V.  Conclusions
33. Lessons Learned from Other Industries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  459Meet Our Industry Veterans                                                                                      460 Preparedness and Disaster Testing                                                                            462 Postmortem Culture                                                                                                    465 Automating Away Repetitive Work and Operational Overhead                          467 Structured and Rational Decision Making                                                              469 Conclusions                                                                                                                  47034. Conclusion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  473
Table of Contents  |  xiA. Availability Table. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  477 B. A Collection of Best Practices for Production Services. . . . . . . . . . . . . . . . . . . . . . . . . . . .  479 C. Example Incident State Document. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  485 D. Example Postmortem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  487 E. Launch Coordination Checklist. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  493 F. Example Production Meeting Minutes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  497 Bibliography. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  501 Index. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  511xii  |  Table of Contents
Foreword
Google’s story is a story of scaling up. It is one of the great success stories of the com‐puting industry, marking a shift towards IT-centric business. Google was one of the first companies to define what business-IT alignment meant in practice, and went on to inform the concept of DevOps for a wider IT community. This book has been writ‐ten by a broad cross-section of the very people who made that transition a reality.Google grew at a time when the traditional role of the system administrator was being transformed. It questioned system administration, as if to say: we can’t afford to hold tradition as an authority, we have to think anew, and we don’t have time to wait for everyone else to catch up. In the introduction to Principles of Network and System Administration[Bur99], I claimed that system administration was a form of human-computer engineering. This was strongly rejected by some reviewers, who said “we are not yet at the stage where we can call it engineering.” At the time, I felt that the field had become lost, trapped in its own wizard culture, and could not see a way for‐ward. Then, Google drew a line in the silicon, forcing that fate into being. The revised role was called SRE, or Site Reliability Engineer. Some of my friends were among the first of this new generation of engineer; they formalized it using software and auto‐mation. Initially, they were fiercely secretive, and what happened inside and outside of Google was very different: Google’s experience was unique. Over time, information and methods have flowed in both directions. This book shows a willingness to let SRE thinking come out of the shadows.Here, we see not only how Google built its legendary infrastructure, but also how it studied, learned, and changed its mind about the tools and the technologies along the way. We, too, can face up to daunting challenges with an open spirit. The tribal nature of IT culture often entrenches practitioners in dogmatic positions that hold the industry back. If Google overcame this inertia, so can we.This book is a collection of essays by one company, with a single common vision. The fact that the contributions are aligned around a single company’s goal is what makes it special. There are common themes, and common characters (software systems)
xiiithat reappear in several chapters. We see choices from different perspectives, and know that they correlate to resolve competing interests. The articles are not rigorous, academic pieces; they are personal accounts, written with pride, in a variety of per‐sonal styles, and from the perspective of individual skill sets. They are written bravely, and with an intellectual honesty that is refreshing and uncommon in industry litera‐ture. Some claim “never do this, always do that,” others are more philosophical and tentative, reflecting the variety of personalities within an IT culture, and how that too plays a role in the story. We, in turn, read them with the humility of observers who were not part of the journey, and do not have all the information about the myriad conflicting challenges. Our many questions are the real legacy of the volume: Why didn’t they do X? What if they’d done Y? How will we look back on this in years to come? It is by comparing our own ideas to the reasoning here that we can measure our own thoughts and experiences.The most impressive thing of all about this book is its very existence. Today, we hear a brazen culture of “just show me the code.” A culture of “ask no questions” has grown up around open source, where community rather than expertise is championed. Goo‐gle is a company that dared to think about the problems from first principles, and to employ top talent with a high proportion of PhDs. Tools were only components in processes, working alongside chains of software, people, and data. Nothing here tells us how to solve problems universally, but that is the point. Stories like these are far more valuable than the code or designs they resulted in. Implementations are ephem‐eral, but the documented reasoning is priceless. Rarely do we have access to this kind of insight.This, then, is the story of how one company did it. The fact that it is many overlap‐ping stories shows us that scaling is far more than just a photographic enlargement of a textbook computer architecture. It is about scaling a business process, rather than just the machinery. This lesson alone is worth its weight in electronic paper.We do not engage much in self-critical review in the IT world; as such, there is much reinvention and repetition. For many years, there was only the USENIX LISA confer‐ence community discussing IT infrastructure, plus a few conferences about operating systems. It is very different today, yet this book still feels like a rare offering: a detailed documentation of Google’s step through a watershed epoch. The tale is not for copy‐ing—though perhaps for emulating—but it can inspire the next step for all of us. There is a unique intellectual honesty in these pages, expressing both leadership and humility. These are stories of hopes, fears, successes, and failures. I salute the courage of authors and editors in allowing such candor, so that we, who are not party to the hands-on experiences, can also benefit from the lessons learned inside the cocoon.— Mark Burgess 
author of In Search of Certainty 
Oslo, March 2016
xiv  |  Foreword
PrefaceSoftware engineering has this in common with having children: the labor before the birth is painful and difficult, but the labor after the birth is where you actually spend most of your effort. Yet software engineering as a discipline spends much more time talking about the first period as opposed to the second, despite estimates that 40–90% of the total costs of a system are incurred after birth.1 The popular industry model that conceives of deployed, operational software as being “stabilized” in production, and therefore needing much less attention from software engineers, is wrong. Through this lens, then, we see that if software engineering tends to focus on design‐ing and building software systems, there must be another discipline that focuses on the whole lifecycle of software objects, from inception, through deployment and oper‐ation, refinement, and eventual peaceful decommissioning. This discipline uses—and needs to use—a wide range of skills, but has separate concerns from other kinds of engineers. Today, our answer is the discipline Google calls Site Reliability Engineer‐ing.So what exactly is Site Reliability Engineering (SRE)? We admit that it’s not a particu‐larly clear name for what we do—pretty much every site reliability engineer at Google gets asked what exactly that is, and what they actually do, on a regular basis.Unpacking the term a little, first and foremost, SREs are engineers. We apply the prin‐ciples of computer science and engineering to the design and development of com‐puting systems: generally, large distributed ones. Sometimes, our task is writing the software for those systems alongside our product development counterparts; some‐times, our task is building all the additional pieces those systems need, like backups or load balancing, ideally so they can be reused across systems; and sometimes, our task is figuring out how to apply existing solutions to new problems.1 The very fact that there is such large variance in these estimates tells you something about software engineer‐	ing as a discipline, but see, e.g., [Gla02] for more details.
xvNext, we focus on system reliability. Ben Treynor Sloss, Google’s VP for 24/7 Opera‐tions, originator of the term SRE, claims that reliability is the most fundamental fea‐ture of any product: a system isn’t very useful if nobody can use it! Because reliability2 is so critical, SREs are focused on finding ways to improve the design and operation of systems to make them more scalable, more reliable, and more efficient. However, we expend effort in this direction only up to a point: when systems are “reliable enough,” we instead invest our efforts in adding features or building new products.3Finally, SREs are focused on operating services built atop our distributed computing systems, whether those services are planet-scale storage, email for hundreds of mil‐lions of users, or where Google began, web search. The “site” in our name originally referred to SRE’s role in keeping the google.com website running, though we now run many more services, many of which aren’t themselves websites—from internal infra‐structure such as Bigtable to products for external developers such as the Google Cloud Platform.Although we have represented SRE as a broad discipline, it is no surprise that it arose in the fast-moving world of web services, and perhaps in origin owes something to the peculiarities of our infrastructure. It is equally no surprise that of all the post-deployment characteristics of software that we could choose to devote special atten‐tion to, reliability is the one we regard as primary.4 The domain of web services, both because the process of improving and changing server-side software is comparatively contained, and because managing change itself is so tightly coupled with failures of all kinds, is a natural platform from which our approach might emerge.Despite arising at Google, and in the web community more generally, we think that this discipline has lessons applicable to other communities and other organizations. This book is an attempt to explain how we do things: both so that other organizations might make use of what we’ve learned, and so that we can better define the role and what the term means. To that end, we have organized the book so that general princi‐ples and more specific practices are separated where possible, and where it’s appropri‐ate to discuss a particular topic with Google-specific information, we trust that the reader will indulge us in this and will not be afraid to draw useful conclusions about their own environment.2 For our purposes, reliability is “The probability that [a system] will perform a required function without fail‐	ure under stated conditions for a stated period of time,” following the definition in [Oco12].
3 The software systems we’re concerned with are largely websites and similar services; we do not discuss the reliability concerns that face software intended for nuclear power plants, aircraft, medical equipment, or other safety-critical systems. We do, however, compare our approaches with those used in other industries in Chap‐ter 33.4 In this, we are distinct from the industry term DevOps, because although we definitely regard infrastructure as code, we have reliability as our main focus. Additionally, we are strongly oriented toward removing the necessity for operations—see Chapter 7 for more details.
xvi  |  Prefacexvi  |  Preface
We have also provided some orienting material—a description of Google’s production environment and a mapping between some of our internal software and publicly available software—which should help to contextualize what we are saying and make it more directly usable.Ultimately, of course, more reliability-oriented software and systems engineering is inherently good. However, we acknowledge that smaller organizations may be won‐dering how they can best use the experience represented here: much like security, the earlier you care about reliability, the better. This implies that even though a small organization has many pressing concerns and the software choices you make may dif‐fer from those Google made, it’s still worth putting lightweight reliability support in place early on, because it’s less costly to expand a structure later on than it is to intro‐duce one that is not present. Part IV contains a number of best practices for training, communication, and meetings that we’ve found to work well for us, many of which should be immediately usable by your organization.But for sizes between a startup and a multinational, there probably already is some‐one in your organization who is doing SRE work, without it necessarily being called that name, or recognized as such. Another way to get started on the path to improv‐ing reliability for your organization is to formally recognize that work, or to find these people and foster what they do—reward it. They are people who stand on the cusp between one way of looking at the world and another one: like Newton, who is sometimes called not the world’s first physicist, but the world’s last alchemist.And taking the historical view, who, then, looking back, might be the first SRE?
We like to think that Margaret Hamilton, working on the Apollo program on loan from MIT, had all of the significant traits of the first SRE.5 In her own words, “part of the culture was to learn from everyone and everything, including from that which one would least expect.”A case in point was when her young daughter Lauren came to work with her one day, while some of the team were running mission scenarios on the hybrid simulation computer. As young children do, Lauren went exploring, and she caused a “mission”to crash by selecting the DSKY keys in an unexpected way, alerting the team as to what would happen if the prelaunch program, P01, were inadvertently selected by a real astronaut during a real mission, during real midcourse. (Launching P01 inadver‐tently on a real mission would be a major problem, because it wipes out navigation data, and the computer was not equipped to pilot the craft with no navigation data.)5 In addition to this great story, she also has a substantial claim to popularizing the term “software engineering.”
Preface  |  xviiWith an SRE’s instincts, Margaret submitted a program change request to add special error checking code in the onboard flight software in case an astronaut should, by accident, happen to select P01 during flight. But this move was considered unneces‐sary by the “higher-ups” at NASA: of course, that could never happen! So instead of adding error checking code, Margaret updated the mission specifications documenta‐tion to say the equivalent of “Do not select P01 during flight.” (Apparently the update was amusing to many on the project, who had been told many times that astronauts would not make any mistakes—after all, they were trained to be perfect.)Well, Margaret’s suggested safeguard was only considered unnecessary until the very next mission, on Apollo 8, just days after the specifications update. During midcourse on the fourth day of flight with the astronauts Jim Lovell, William Anders, and Frank Borman on board, Jim Lovell selected P01 by mistake—as it happens, on Christmas Day—creating much havoc for all involved. This was a critical problem, because in the absence of a workaround, no navigation data meant the astronauts were never coming home. Thankfully, the documentation update had explicitly called this possi‐bility out, and was invaluable in figuring out how to upload usable data and recover the mission, with not much time to spare.As Margaret says, “a thorough understanding of how to operate the systems was not enough to prevent human errors,” and the change request to add error detection and recovery software to the prelaunch program P01 was approved shortly afterwards.Although the Apollo 8 incident occurred decades ago, there is much in the preceding paragraphs directly relevant to engineers’ lives today, and much that will continue to be directly relevant in the future. Accordingly, for the systems you look after, for the groups you work in, or for the organizations you’re building, please bear the SRE Way in mind: thoroughness and dedication, belief in the value of preparation and docu‐mentation, and an awareness of what could go wrong, coupled with a strong desire to prevent it. Welcome to our emerging profession!xviii  |  Preface