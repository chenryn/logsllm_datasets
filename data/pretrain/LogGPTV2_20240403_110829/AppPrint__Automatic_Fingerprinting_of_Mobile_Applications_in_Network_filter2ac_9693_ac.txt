#
100101102103104105106107
TP
FP
NV
HH
UA
MS
100101102103104105106107
s
w
o
l
f
f
o
#
Fig. 5. Number of identiﬁed app instances without ﬂow grouping.
)
%
(
n
o
i
s
i
c
e
r
P
 100
 80
 60
 40
 20
 0
precision
coverage
HH
UA
MS
)
%
 100
 80
 60
 40
 20
 0
(
e
g
a
r
e
v
o
C
Fig. 6. Precision and coverage of app-instance identiﬁcations in the lab trace without
ﬂow grouping.
AppPrint: Automatic Fingerprinting of Mobile Applications
67
approach by preventing any grouping, i.e., we apply AppPrint on the ﬂow sets
containing only single ﬂows. The settings for these experiments are similar to
the ones described in Sect. 4.2.
Real traﬃc: We ﬁrst evaluate the number of identiﬁed app instances on the
7th day of the real traﬃc. The results for header data (HH) and user agent
(UA) approaches do not change signiﬁcantly; a slight increase in identiﬁcation
is due to counting distinct app identiﬁcations per each ﬂow vs. counting them
once per ﬂow set. Next, this setting enables us to better qualify MAP-SCORE
(MS) results. Speciﬁcally, using per-ﬂow indications of deterministic HH and
UA approaches, we can classify MS results as (i) true positives (TP) when MS
agrees with HH or UA, (ii) false positives (FP) when there is a disagreement, and
(iii) non-veriﬁable characterizations (NV) when HH or UA cannot characterize
a ﬂow, but MS can.
The results in Fig. 5 indicate that although MS identiﬁes one order of mag-
nitude more app instances than with ﬂow grouping enabled (compare Figs. 4
and 5), the number of true positives decreases from 85K to 26K. This clearly
demonstrates a positive eﬀect of ﬂow grouping on AppPrint’s accuracy.
Lab traﬃc: We use the lab trace to assess the impact of single-ﬂow ﬂow sets
on precision (see Fig. 6). Our results indicate that MAP-SCORE (MS) achieves
much higher coverage than HH and UA, but its precision drops to 82.3 % (about
10 % less than with ﬂow grouping enabled, see Sect. 4.2). In summary, not lever-
aging tokens from multiple ﬂows has notable negative eﬀects on both coverage
and precision of AppPrint.
4.4 Identifying Apps Without A&A Traﬃc
To evaluate AppPrint’s capabilities on paid apps (without incurring high mon-
etary costs of purchasing the apps), we leverage the key diﬀerence between free
and paid apps: Paid apps mostly do not exchange ads and analytic (A&A) traf-
ﬁc [7,13], while the rest of their communications are largely similar to free apps.
Thus, we can still employ our lab- and real-traﬃc traces by removing all A&A
ﬂows. Also note that our MAP repository still remains representative because
most paid apps have their free counterparts developed on the same code base,
thus using similar traﬃc tokens (readily captured by our MAP repository). Our
experimental settings are otherwise similar to the ones described in Sect. 4.2.
Figure 7 shows the number of app instances identiﬁed by the three techniques
on the real trace. In this experiment header data (HH) approach identiﬁes only
3.7K app instances, user agent (UA) approach identiﬁes 13K (remaining unaf-
fected), and MAP-SCORE (MS) identiﬁes 1, 508K. In comparison with A&A
ﬂows included (see Fig. 4), MAP-SCORE identiﬁes only about 11 % less app
instances.
For the lab trace, precision and coverage are plotted in Fig. 8. Note that
the coverage of HH gets very low because this technique largely relies on A&A
traﬃc for explicit app identiﬁers. UA still has a low coverage, but it is largely
68
S. Miskovic et al.
s
e
c
n
a
t
s
n
i
p
p
a
f
o
#
106
105
104
103
102
101
100
106
105
104
103
102
101
100
s
e
c
n
a
t
s
n
i
p
p
a
f
o
#
HH
UA
MS
Fig. 7. Number of app instances identiﬁed in the real trace without A&A ﬂows.
)
%
 100
 80
 60
 40
 20
 0
(
n
o
i
s
i
c
e
r
P
precision
coverage
HH
UA
MS
102
101
100
10-1
)
%
(
e
g
a
r
e
v
o
C
Fig. 8. Precision and coverage of app-instance identiﬁcations on the lab trace without
A&A ﬂows.
unaﬀected by the lack of A&A ﬂows. Finally, MAP-SCORE associates apps to
about 50 % of ﬂow sets, but its precision drops to around 70 %.
5 Conclusion
The paper proposes AppPrint, a system for automatic identiﬁcation of mobile
apps in arbitrarily small samples of Internet traﬃc. AppPrint enables network
administrators to regain ﬁne grained visibility into their traﬃc, thus beneﬁting
network management and security. The system achieves this by its unique capa-
bility to learn app ﬁngerprints dispersed over multiple and often individually
inconclusive traﬃc ﬂows. We evaluated AppPrint on a trace of a large cellu-
lar provider in the United States and on our comprehensive lab trace spanning
thousands of apps. The results show that AppPrint outperforms state-of-the-art
approaches by identifying over one order of magnitude more instances of apps
in the real traﬃc, while achieving up to 93.7 % precision.
References
1. Apsalar: Data-Powered Mobile Advertising. http://apsalar.com/
2. Choi, Y., Chung, J.Y., Park, B., Hong, J.W.K.: Automated classiﬁer generation
for application-level mobile traﬃc identiﬁcation. In: Proceedings of Network Oper-
ations and Management Symposium (NOMS) (2012)
3. Dai, S., Tongaonkar, A., Wang, X., Nucci, A., Song, D.: NetworkProﬁler: towards
automatic ﬁngerprinting of Android apps. In: INFOCOM. Turin, Italy, April 2013
AppPrint: Automatic Fingerprinting of Mobile Applications
69
4. Falaki, H., Lymberopoulos, D., Mahajan, R., Kandula, S., Estrin, D.: A ﬁrst look
at traﬃc on smartphones. In: Proceedings of the 10th ACM SIGCOMM Conference
on Internet Measurement, IMC 2010, pp. 281–287. ACM, New York (2010)
5. Falaki, H., Mahajan, R., Kandula, S., Lymberopoulos, D., Govindan, R., Estrin, D.:
Diversity in smartphone usage. In: Proceedings of the 8th International Conference
on Mobile Systems, Applications, and Services, MobiSys 2010, pp. 179–194. ACM,
New York (2010)
6. Gember, A., Anand, A., Akella, A.: A comparative study of handheld and non-
handheld traﬃc in campus Wi-Fi networks. In: Spring, N., Riley, G.F. (eds.) PAM
2011. LNCS, vol. 6579, pp. 173–183. Springer, Heidelberg (2011)
7. Leontiadis, I., Efstratiou, C., Picone, M., Mascolo, C.: Don’t kill my ads!: Bal-
ancing privacy in an ad-supported mobile application market. In: Proceedings of
the Twelfth Workshop on Mobile Computing Systems & Applications, HotMobile
2012, pp. 2:1–2:6. ACM, New York (2012)
8. Maier, G., Schneider, F., Feldmann, A.: A ﬁrst look at mobile hand-held device
traﬃc. In: Krishnamurthy, A., Plattner, B. (eds.) PAM 2010. LNCS, vol. 6032, pp.
161–170. Springer, Heidelberg (2010)
9. Mobile App Usage Further Dominates Web. http://www.ﬂurry.com/bid/80241/
Mobile-App-Usage-Further-Dominates-Web-Spurred-by-Facebook#.VAZhp9-c3PE
10. Moore, D., Keys, K., Koga, R., Lagache, E., Claﬀy, K.C.: The coralreef software
suite as a tool for system and network administrators. In: Proceedings of the 15th
USENIX Conference on System Administration, LISA 2001, pp. 133–144. USENIX
Association, Berkeley (2001)
11. Rastogi, V., Chen, Y., Enck, W.: AppsPlayground: automatic security analysis of
smartphone applications. In: Proceedings of the Third ACM Conference on Data
and Application Security and Privacy, CODASPY 2013, pp. 209–220 (2013)
12. UI/Application Exerciser Monkey. http://developer.android.com/tools/help/
monkey.html
13. Wei, X., Gomez, L., Neamtiu, I., Faloutsos, M.: ProﬁleDroid: multi-layer proﬁling
of android applications. In: Proceedings of the 18th Annual International Confer-
ence on Mobile Computing and Networking, Mobicom 2012, pp. 137–148. ACM,
New York (2012)
14. Xu, Q., Erman, J., Gerber, A., Mao, Z., Pang, J., Venkataraman, S.: Identi-
fying diverse usage behaviors of smartphone apps. In: Proceedings of the 2011
ACM SIGCOMM Conference on Internet Measurement Conference, IMC 2011,
pp. 329–344. ACM, New York (2011)