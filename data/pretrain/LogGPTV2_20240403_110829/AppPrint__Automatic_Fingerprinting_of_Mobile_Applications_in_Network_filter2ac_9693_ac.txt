### Evaluation of AppPrint Without Flow Grouping

**Figure 5: Number of Identified App Instances Without Flow Grouping**

```
100101102103104105106107
TP
FP
NV
HH
UA
MS
100101102103104105106107
s
w
o
l
f
f
o
#
```

**Figure 6: Precision and Coverage of App-Instance Identifications in the Lab Trace Without Flow Grouping**

```
)
%
(
n
o
i
s
i
c
e
r
P
 100
 80
 60
 40
 20
 0
precision
coverage
HH
UA
MS
)
%
 100
 80
 60
 40
 20
 0
(
e
g
a
r
e
v
o
C
```

### Evaluating AppPrint Without Flow Grouping

To further evaluate the performance of AppPrint, we conducted experiments without flow grouping, meaning each flow was treated individually. The experimental settings were similar to those described in Section 4.2.

#### Real Traffic Analysis

We first evaluated the number of identified app instances on the 7th day of real traffic. The results for the header data (HH) and user agent (UA) approaches showed only slight changes, with a minor increase in identification due to counting distinct app identifications per flow rather than per flow set. This setting allowed us to better classify the results from MAP-SCORE (MS). Specifically, using the deterministic indications from HH and UA, we classified MS results as:
- **True Positives (TP)**: When MS agrees with HH or UA.
- **False Positives (FP)**: When there is a disagreement between MS and HH or UA.
- **Non-Verifiable Characterizations (NV)**: When HH or UA cannot characterize a flow, but MS can.

**Results:**
- Figure 5 shows that while MS identifies one order of magnitude more app instances compared to when flow grouping is enabled (see Figures 4 and 5), the number of true positives decreases from 85K to 26K. This demonstrates the positive effect of flow grouping on AppPrint's accuracy.

#### Lab Traffic Analysis

Using the lab trace, we assessed the impact of single-flow flow sets on precision (see Figure 6). Our results indicate that MAP-SCORE (MS) achieves much higher coverage than HH and UA, but its precision drops to 82.3% (about 10% less than with flow grouping enabled, see Section 4.2). In summary, not leveraging tokens from multiple flows has notable negative effects on both coverage and precision of AppPrint.

### Identifying Apps Without A&A Traffic

To evaluate AppPrint's capabilities on paid apps (without incurring high monetary costs of purchasing the apps), we leveraged the key difference between free and paid apps: Paid apps mostly do not exchange ads and analytics (A&A) traffic [7,13], while their other communications are similar to free apps. Thus, we used our lab and real traffic traces by removing all A&A flows. Our MAP repository remains representative because most paid apps have free counterparts developed on the same code base, using similar traffic tokens.

**Experimental Settings:**
- Similar to those described in Section 4.2.

**Figure 7: Number of App Instances Identified in the Real Trace Without A&A Flows**

```
s
e
c
n
a
t
s
n
i
p
p
a
f
o
#
106
105
104
103
102
101
100
106
105
104
103
102
101
100
s
e
c
n
a
t
s
n
i
p
p
a
f
o
#
HH
UA
MS
```

**Figure 8: Precision and Coverage of App-Instance Identifications on the Lab Trace Without A&A Flows**

```
)
%
 100
 80
 60
 40
 20
 0
(
n
o
i
s
i
c
e
r
P
precision
coverage
HH
UA
MS
102
101
100
10-1
)
%
(
e
g
a
r
e
v
o
C
```

**Results:**
- In the real trace, the header data (HH) approach identified only 3.7K app instances, the user agent (UA) approach identified 13K (remaining unaffected), and MAP-SCORE (MS) identified 1,508K. Compared to including A&A flows (see Figure 4), MAP-SCORE identifies about 11% fewer app instances.
- For the lab trace, the coverage of HH is very low because it relies heavily on A&A traffic for explicit app identifiers. UA still has low coverage but is largely unaffected by the lack of A&A flows. Finally, MAP-SCORE associates apps to about 50% of flow sets, but its precision drops to around 70%.

### Conclusion

AppPrint is a system for automatic identification of mobile apps in small samples of Internet traffic, enabling network administrators to regain fine-grained visibility into their traffic, benefiting network management and security. The system achieves this by learning app fingerprints dispersed over multiple and often individually inconclusive traffic flows. We evaluated AppPrint on a large cellular provider's trace and a comprehensive lab trace spanning thousands of apps. The results show that AppPrint outperforms state-of-the-art approaches by identifying over one order of magnitude more instances of apps in real traffic, achieving up to 93.7% precision.

### References

1. Apsalar: Data-Powered Mobile Advertising. <http://apsalar.com/>
2. Choi, Y., Chung, J.Y., Park, B., Hong, J.W.K.: Automated classifier generation for application-level mobile traffic identification. In: Proceedings of Network Operations and Management Symposium (NOMS) (2012)
3. Dai, S., Tongaonkar, A., Wang, X., Nucci, A., Song, D.: NetworkProfiler: towards automatic fingerprinting of Android apps. In: INFOCOM. Turin, Italy, April 2013
4. Falaki, H., Lymberopoulos, D., Mahajan, R., Kandula, S., Estrin, D.: A first look at traffic on smartphones. In: Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement, IMC 2010, pp. 281–287. ACM, New York (2010)
5. Falaki, H., Mahajan, R., Kandula, S., Lymberopoulos, D., Govindan, R., Estrin, D.: Diversity in smartphone usage. In: Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services, MobiSys 2010, pp. 179–194. ACM, New York (2010)
6. Gember, A., Anand, A., Akella, A.: A comparative study of handheld and non-handheld traffic in campus Wi-Fi networks. In: Spring, N., Riley, G.F. (eds.) PAM 2011. LNCS, vol. 6579, pp. 173–183. Springer, Heidelberg (2011)
7. Leontiadis, I., Efstratiou, C., Picone, M., Mascolo, C.: Don’t kill my ads!: Balancing privacy in an ad-supported mobile application market. In: Proceedings of the Twelfth Workshop on Mobile Computing Systems & Applications, HotMobile 2012, pp. 2:1–2:6. ACM, New York (2012)
8. Maier, G., Schneider, F., Feldmann, A.: A first look at mobile hand-held device traffic. In: Krishnamurthy, A., Plattner, B. (eds.) PAM 2010. LNCS, vol. 6032, pp. 161–170. Springer, Heidelberg (2010)
9. Mobile App Usage Further Dominates Web. <http://www.flurry.com/bid/80241/Mobile-App-Usage-Further-Dominates-Web-Spurred-by-Facebook#.VAZhp9-c3PE>
10. Moore, D., Keys, K., Koga, R., Lagache, E., Claffy, K.C.: The coralreef software suite as a tool for system and network administrators. In: Proceedings of the 15th USENIX Conference on System Administration, LISA 2001, pp. 133–144. USENIX Association, Berkeley (2001)
11. Rastogi, V., Chen, Y., Enck, W.: AppsPlayground: automatic security analysis of smartphone applications. In: Proceedings of the Third ACM Conference on Data and Application Security and Privacy, CODASPY 2013, pp. 209–220 (2013)
12. UI/Application Exerciser Monkey. <http://developer.android.com/tools/help/monkey.html>
13. Wei, X., Gomez, L., Neamtiu, I., Faloutsos, M.: ProfileDroid: multi-layer profiling of android applications. In: Proceedings of the 18th Annual International Conference on Mobile Computing and Networking, Mobicom 2012, pp. 137–148. ACM, New York (2012)
14. Xu, Q., Erman, J., Gerber, A., Mao, Z., Pang, J., Venkataraman, S.: Identifying diverse usage behaviors of smartphone apps. In: Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference, IMC 2011, pp. 329–344. ACM, New York (2011)