## Page 59
在软件编译的过程中，编译软件会向运行在数据中心的编译服务器发送请求。Google编
除了一些开源项目之外（Android和Chrome等），其他Google软件工程师全部使用同-
Google非常注重研发效率，我们围绕着自己的基础设施构建了一整套研发环境（参见文
研发环境
似。Protobuf相比XML有很多优势，更为简单易用，数据大小比XML格式要小3~10倍，
Protocol Buffer准4是GoogleRPC的传输格式，通常简写为Protobuf，与Apache Thrift类
些RPC发往该服务器的后端（backend）。一般来说，前端被称为客户端（client），后端
有良好的支持。
来有需要时，可以很容易地将其重构为多个组件并行的架构。GSLB对RPC的负载均衡
一个开源实现，gRPC。注3有时候，一个程序的内部函数调用也会用RPC实现，因为未
所有的Google服务之前都使用远程调用（RPC）通信，称为Stubby。我们目前还公布了
控等使用。
件服务器都有一个内置的HTTP服务，
的代码库大量采用了多线程设计方式，
Google的底层软件基础设施的设计目标是最高效地使用Google的硬件基础设施。我们
软件基础设施
注注
献[Mor12b]）。
序列化和反序列化速度快100倍，并且协议更加明确。
被称为服务端（server）。
通常来说，
https://developer.google.com/protocol-buffers/
ProtocolBuffer是编程语言中性的、运行平台中性的一种数据序列化机制。更详细的内容可参见
具体信息参见http://gprpc.io。
任何对自己项目代码的改动也需要代码评审。
改这个问题，向管理者提交一份改动申请（changelist，CL），等待代码评审，最
检查资源使用量随时间的变化情况，这个信息对合理制定资源计划很有用。
后直接提交。
一个软件服务器从该服务的前端（frontend）接收RPC请求，同时将另外一
，提供一些调试信息和统计信息，供在线调试、监
一个任务实例可以同时利用很多个CPU。每个软
研发环境
GSLB通过全局流量负载信息，决定使用哪个IP地址回复用户。
DNS请求最后会到达Google的DNS服务器。Google的DNS服务器会请求GSLB系统。
shakespeare.google.com。为了获得IP地址，用户设备需要请求DNS服务器（1)。该
图2-4显示了一个用户请求的处理全过程。首先，用户使用浏览器访问https://
用户请求的处理过程
最后，程序将每一个单词或位置列表写入Bigtable中，RowKey就是这个单词。
批处理部分可以用MapReduce框架完成，三个阶段的实现分别如下所示。
整个系统可以分为两大部分：
比亚的文献中搜索给定的词语。
部署的，我们在这里提供一个假想的莎士比亚搜索服务。这个服务的作用是在所有莎士
为了更好地说明一个服务是怎样利用各种基础设施，以及是如何在Google生产环境中
莎士比亚搜索：一个示范服务
部署于生产环境。
送通知。有些项目组甚至在实践自动部署机制：提交一个新版本，测试通过后，将直接
如果测试框架检测到一个CL破坏了其他某个系统的正常工作，测试框架会向提交者发
测试。每当一个CL被提交时，所有被这个CL直接或间接影响到的测试都会运行一次。
译软件可以通过并行机制处理超大型编译请求。这套技术架构体系同时也用来进行持续
·Mapping阶段：该程序遍历所有的莎士比亚的文字，将其分成具体的单词。这项
·批处理部分（batch）。给全部莎士比亚文献创建索引，同时将索引写入一个
Reduce 阶段：将上一阶段产生的单词或位置等按单词合并，产生一个新的单词
Shuffle阶段：该程序将上一阶段产生的所有单词和位置等进行排序。
或位置列表。
任务可以利用多实例并行加速。
运行的，因为全球范围的用户都需要使用我们的服务。
一个应用程序前端服务器（frontend），用以接收处理用户请求。该服务器是一直
再运行一次。）
Bigtable中。这项任务只需运行一次（如果发现了新的莎土比亚文献，那就需要
第2章Google生产环境：SRE视角
---
## Page 61
过对用户进行的调查显示，我们预计峰值流量会达到3470QPS，为了处理这些流量，
假设压力测试的结果显示，我们的服务器可以每秒处理大概100个请求（100QPS）。
任务和数据的组织方式
验证他们的网络服务是否正常。
常稳定的服务。由于Google的可靠性举世闻名，人们经常通过访问www.google.com来
测试和灰度发布流程，以及很多主动优雅降级的措施，使得我们可以为用户提供一个非
须相当可靠才行，GSLB服务如果出现问题将会造成严重故障。但是Google依靠严格的
上述这些连锁事件其实一共耗时几百毫秒。因为一个请求涉及很多组件，这些组件都必
将其回复给Shakespeare前端服务器，前端服务器最终根据这个数据结构构建HTML回
最终结果被写入一个Protobuf 结构体中，返回给Shakespeare后端服务器，后端服务器
Shakespeare后端服务器随后请求Bigtable服务器来获得最终查询结果（5）。
GSLB服务，获取目前可用的（同时符合负载均衡条件的）后端服务器的BNS地址（4）。
时 Shakespeare前端服务器需要联系后端服务器来做具体查询。前端服务器也需要联系
Shakespeare 前端服务器分析接收到的请求，构建出一个具体查询的Protobuf 请求。这
复给最终用户。
目前可用的Shakespeare服务器地址，向其发送一个RPC请求（3）。
maps以及本例中的Shakespeare）。GFE再次咨询GSLB系统，获得一个GSLB分配的
中找到该请求对应的后端服务（配置文件中包括所有的Google服务，例如WebSearch、
GFE）负责终结TCP连接，并且反向代理请求到真正的服务器上（2）。GFE从配置文件
用户浏览器利用获得的IP地址连接到HTTP服务器，这个服务器（Google前端服务器
图2-4:用户请求处理过程
Balancer
(ReverseProxy
GSLB
Load
GFE
莎士比亚搜索：一个示范服务
品
Backend
Application
DB
至
通
<22
---
## Page 62
20
注5
我们在这一章中介绍了很多术语，在接下来的章节中还会重复引用它们，所以读者并不
频繁，所以对我们来说这并不是问题。
虽然Bigtable仅仅提供最终一致性保障（eventual consistency），但是由于数据更新并不
利用Bigtable的复制功能，我们可以同时达到两个目的：
以我们在每个地理区域都存放了Bigtable的副本。
安排数据存储。亚洲的后端服务器尝试访问部署在美国的Bigtable会面临延迟问题。所
因为Shakespeare后端服务器需要连接Bigtable服务读取数据，我们同时也需要合理地
地方，我们还会将任务实例分散在不同的集群中，以便更好地提升可靠性。
美洲的用户流量导向其他可用的数据中心，可以节省大概20%的硬件资源。在有条件的
们选择在极端情况下牺牲一些用户体验以降低成本。因为当容量不足时，GSLB会将南
选择使用只部署4个实例（而不是5个），将余度降低为N+1。这样做的原因是，我
地服务用户，我们需要将服务分别部署在美国、南美洲、欧洲和亚洲。在南美洲，我们
QPS，南美洲290QPS，欧洲和非洲1400QPS，亚洲及澳大利亚共350QPS。为了更好
假设，对用户流量的进一步观察显示我们的峰值流量其实是来自全球的。北美洲1430
也就是N+2模式：
少需要35个任务实例。
一定现在就将它们完全记住。
供电设施问题，或者机柜交换机问题，可能会影响这里的假设。
我们假设同时出现两个任务实例不可用的情况的可能性很低，
任务实例可以利用本地Bigtable加速数据访问。
如果另外一个物理服务器同时也出现问题，那么另外一个任务实例也受到影响，
在更新过程中，有一个任务实例将会短暂不可用，只有36个实例可提供服务。
当Bigtable服务出现问题时，可以利用副本提供服务。
只剩35个实例可以对外服务，刚好可以满足峰值要求。
第2章Google生产环境：SRE视角
但是，由于以下几点考量，我们最终决定至少采用37个实例，
足以忽略不计。但是单点故障源，例如
注5
---
## Page 63
也可以保障每次发布的顺利进行。
统稳定性的一个关键环节，因为大部分故障都是由于新的变更引起的。在这方面的投入
大部分公司不太重视发布工作。然而，在第8章中，我们可以看到，发布工作是整体系
过程中的一些成功和失败的案例。
第7章描述了Google SRE进行自动化工作的方法论。这一章同时讨论了SRE在自动化<24
最佳实践。
谈起维护服务的可靠性。第6章描述了监控的手段和目标，以及一些与具体实现无关的
果没有针对服务的监控，就无从得知目前服务的状态，如果不知道服务的状态，就无从
对Google或者其他任何一个公司来说，监控系统都是运维生产环境必不可少的组件。如
重复性的运维工作，这些工作通常不具有长期价值，而且会随着服务规模的扩大而增长。
消除琐事（toil）是SRE的一项重要工作，详情请参见第5章。我们将琐事定义为无聊
的选择提供了一些建议。
SLA区分开来，详细描述SRE是如何区分这两个术语的，同时针对应用程序性能指标
概念都归结为服务质量协议（SLA），这样使得讨论变得很复杂。第4章试图将SLO与
服务质量目标（SLO）是SRE的另外一个基本概念。运维行业经常会将一系列离散的
以及利用错误预算的手段来推进中立性的服务运维。
工作，以及背后的指导思想。这一章从“风险”人手，描述了如何评估风险、管理风险，
本部分的第一章（第3章）是最重要的一章。这一章从最广泛的角度描述了SRE的日常
作中关注的重点等。
本部分将描述SRE日常工作背后的指导思想一
一工作模式、行为方式，以及平时运维工
指导思想
第Ⅱ部分
<23
---
## Page 64
中将人工操作去除，这可以降低SRE需要做的琐事，同时可以增加系统的可靠性。
GreenaReality（参见文献[Kle14]，发布于2014年10月）中，我们描述了从发布环节
在保障安全的前提下，提升产品选代速度是所有组织都想达到的目标。在MakePush On
其他GoogleSRE阅读材料
渐简化。在第9章，我们详细讨论了这个主题。
就很难找回来了。但是不管如何，随着陈旧组件的不断下线，原来复杂的系统一定会逐
广义软件工程中（不仅仅是运维部分）的一个关键思想是保持简单。这个特性一旦失去，
---
## Page 65
冗余物理服务器/计算资源的成本
的下一个改进可能比之前的改进成本增加100倍。高昂的成本主要存在于以下两个维度。
验表明，在构建系统的过程中，可靠性进一步提升的成本并不是线性增加的一—可靠性
不可靠的系统会很快侵蚀用户的信心，所以我们想要减少系统出故障的几率。然而，经
管理风险
的功能、服务和性能。
简单地将服务在线时间最大化。这样一来，我们可以优化用户的整体幸福感，平衡系统
基于这一点，SRE旨在寻求快速创新和高效的服务运营业务之间的风险的平衡，而不是
99.999%的服务可靠性的区别的！