**作者：LoRexxar'@知道创宇404实验室  
时间：2020年9月21日**  
**英文版：**
### 前言
自从人类发明了工具开始，人类就在不断为探索如何更方便快捷的做任何事情，在科技发展的过程中，人类不断地试错，不断地思考，于是才有了现代伟大的科技时代。在安全领域里，每个安全研究人员在研究的过程中，也同样的不断地探索着如何能够自动化的解决各个领域的安全问题。其中自动化代码审计就是安全自动化绕不过去的坎。
这一次我们就一起聊聊自动化代码审计的发展史，也顺便聊聊如何完成一个自动化静态代码审计的关键。
### 自动化代码审计
在聊自动化代码审计工具之前，首先我们必须要清楚两个概念， **漏报率** 和 **误报率** 。  
\- **漏报率** 是指没有发现的漏洞/Bug  
\- **误报率** 是指发现了错误的漏洞/Bug
在评价下面的所有自动化代码审计工具/思路/概念时，所有的评价标准都离不开这两个词，如何消除这两点或是其中之一也正是自动化代码审计发展的关键点。
我们可以简单的把自动化代码审计（这里我们讨论的是白盒）分为两类，一类是动态代码审计工具，另一类是静态代码审计工具。
### 动态代码审计的特点与局限
动态代码审计工具的原理主要是基于在 **代码运行的过程中** 进行处理并挖掘漏洞。我们一般称之为IAST（interactive Application
Security Testing）。
其中最常见的方式就是通过某种方式Hook恶意函数或是底层api并通过前端爬虫判别是否触发恶意函数来确认漏洞。
我们可以通过一个简单的流程图来理解这个过程。
在前端Fuzz的过程中，如果Hook函数被触发，并满足某种条件，那么我们认为该漏洞存在。
这类扫描工具的优势在于，通过这类工具发现的漏洞 **误报率比较低**
，且不依赖代码，一般来说，只要策略足够完善，能够触发到相应恶意函数的操作都会相应的满足某种恶意操作。而且可以跟踪动态调用也是这种方法最主要的优势之一。
但随之而来的问题也逐渐暴露出来：  
(1) 前端Fuzz爬虫可以保证对正常功能的覆盖率，却很难保证对代码功能的覆盖率。
如果曾使用动态代码审计工具对大量的代码扫描，不难发现，这类工具针对漏洞的扫描结果并不会比纯黑盒的漏洞扫描工具有什么优势，其中最大的问题主要集中在功能的覆盖度上。
一般来说，你很难保证开发完成的所有代码都是为网站的功能服务的，也许是在版本迭代的过程中不断地冗余代码被遗留下来，也有可能是开发人员根本没有意识到他们写下的代码并不只是会按照预想的样子执行下去。有太多的漏洞都无法直接的从前台的功能处被发现，有些甚至可能需要满足特定的环境、特定的请求才能触发。这样一来，代码的覆盖率得不到保证，又怎么保证能发现漏洞呢？
(2) 动态代码审计对底层以及hook策略依赖较强
由于动态代码审计的漏洞判别主要依赖Hook恶意函数，那么对于不同的语言、不同的平台来说，动态代码审计往往要针对设计不同的hook方案。如果Hook的深度不够，一个深度框架可能就无法扫描了。
拿PHP举例子来说，比较成熟的Hook方案就是通过PHP插件实现，具体的实现方案可以参考。
  * 
由于这个原因影响，一般的动态代码审计很少可以同时扫描多种语言，一般来说都是针对某一种语言。
其次，Hook的策略也需要许多不同的限制以及处理。就拿PHP的XSS来举例子，并不是说一个请求触发了echo函数就应该判别为XSS。同样的，为了不影响正常功能，并不是echo函数参数中包含``就可以算XSS漏洞。在动态代码审计的策略中，需要有更合理的前端->Hook策略判别方案，否则会出现大量的误报。
除了前面的问题以外，对环境的强依赖、对执行效率的需求、难以和业务代码结合的各种问题也确切的存在着。当动态代码审计的弊端不断被暴露出来后，从笔者的角度来看，动态代码审计存在着原理本身与问题的冲突，所以在自动化工具的发展过程中，越来越多的目光都放回了静态代码审计上(SAST).
### 静态代码审计工具的发展
静态代码审计主要是通过分析目标代码，通过纯静态的手段进行分析处理，并挖掘相应的漏洞/Bug.
与动态不同，静态代码审计工具经历了长期的发展与演变过程，下面我们就一起回顾一下（下面的每个时期主要代表的相对的发展期，并不是比较绝对的诞生前后）：
#### 上古时期 - 关键字匹配
如果我问你“如果让你设计一个自动化代码审计工具，你会怎么设计？”，我相信，你一定会回答我，可以尝试通过匹配关键字。紧接着你也会迅速意识到通过关键字匹配的问题。
这里我们拿PHP做个简单的例子。
虽然我们匹配到了这个简单的漏洞，但是很快发现，事情并没有那么简单。
也许你说你可以通过简单的关键字重新匹配到这个问题。
    \beval\(\$
但是可惜的是，作为安全研究员，你永远没办法知道开发人员是怎么写代码的。于是选择用关键字匹配的你面临着两种选择：
  * 高覆盖性 – 宁错杀不放过
这类工具最经典的就是Seay，通过简单的关键字来匹配经可能多的目标，之后使用者可以通过人工审计的方式进一步确认。
    \beval\b\(
  * 高可用性 – 宁放过不错杀
这类工具最经典的是Rips免费版
    \beval\b\(\$_(GET|POST)
用更多的正则来约束，用更多的规则来覆盖多种情况。这也是早期静态自动化代码审计工具普遍的实现方法。
但问题显而易见， **高覆盖性和高可用性是这种实现方法永远无法解决的硬伤，不但维护成本巨大，而且误报率和漏报率也是居高不下**
。所以被时代所淘汰也是历史的必然。
#### 近代时期 - 基于AST的代码分析
有人忽略问题，也有人解决问题。关键字匹配最大的问题是在于你永远没办法保证开发人员的习惯，你也就没办法通过任何制式的匹配来确认漏洞，那么基于AST的代码审计方式就诞生了，开发人员是不同的，但编译器是相同的。
在分享这种原理之前，我们首先可以复现一下编译原理。拿PHP代码举例子：
随着PHP7的诞生，AST也作为PHP解释执行的中间层出现在了编译过程的一环。
通过词法分析和语法分析，我们可以将任意一份代码转化为AST语法树。常见的语义分析库可以参考：
  * 
  * 
当我们得到了一份AST语法树之后，我们就解决了前面提到的关键字匹配最大的问题，至少我们现在对于不同的代码，都有了统一的AST语法树。如何对AST语法树做分析也就成了这类工具最大的问题。
在理解如何分析AST语法树之前，我们首先要明白 **information flow、source、sink** 三个概念，
  * source： 我们可以简单的称之为输入，也就是information flow的起点
  * sink： 我们可以称之为输出，也就是information flow的终点
而information flow，则是指数据在source到sink之间流动的过程。
把这个概念放在PHP代码审计过程中，Source就是指用户可控的输入，比如`$_GET、$_POST`等，而Sink就是指我们要找到的敏感函数，比如`echo、eval`，如果某一个Source到Sink存在一个完整的流，那么我们就可以认为存在一个可控的漏洞，这也就是基于information
flow的代码审计原理。
在明白了基础原理的基础上，我举几个简单的例子：
在上面的分析过程中，Sink就是eval函数，source就是`$_GET`，通过逆向分析Sink的来源，我们成功找到了一条流向Sink的information
flow，也就成功发现了这个漏洞。
ps: 当然也许会有人好奇为什么选择逆向分析流而不是正向分析流，这个问题会在后续的分析过程中不断渗透，慢慢就可以明白其关键点。
在分析information flow的过程中， **明确作用域是基础中的基础.** 这也是分析information
flow的关键，我们可以一起看看一段简单的代码
如果我们很简单的通过左右值去回溯，而没有考虑到函数定义的话，我们很容易将流定义为：
这样我们就错误的把这段代码定义成了存在漏洞，但很显然并不是，而正确的分析流程应该是这样的:
在这段代码中，从主语法树的作用域跟到Get函数的作用域， **如何控制这个作用域的变动，就是基于AST语法树分析的一大难点**
，当我们在代码中不可避免的使用递归来控制作用域时，在多层递归中的统一标准也就成了分析的基础核心问题。