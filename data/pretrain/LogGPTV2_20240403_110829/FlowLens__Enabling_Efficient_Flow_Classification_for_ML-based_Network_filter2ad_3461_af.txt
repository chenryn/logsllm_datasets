(cid:104)QL=0, Top-N=20(cid:105) = 0.870
(cid:104)QL=5, Top-N=10(cid:105) = 0.840
Botnets (i=10)
(cid:104)QLP L=2, QLIP T =2(cid:105) = 0.970
(cid:104)QLP L=0, QLIP T =6(cid:105) = 0.969
(cid:104)QLP L=4, QLIP T =6(cid:105) = 0.960
(cid:104)QLP L=3, QLIP T =1024(cid:105) = 0.953
while generating compact ﬂow markers. For instance, for Facet,
the top-3 conﬁgurations exhibit a marker size of 375, 50, and
30 bins, respectively. Our proﬁler chooses a conﬁguration that
provides a marker size of 10 bins while achieving an accuracy
only 1.6% worse than the conﬁguration with the best-found
accuracy (and with a 37× smaller marker). Our reward policy
leads the optimizer to perform good decisions over the explored
conﬁgurations. In website ﬁngerprinting, the proﬁler outputs the
top-2 conﬁguration rather than top-1 since the latter’s marker
size is too big in comparison (1500 vs 94 bins). The proﬁler
also refrains from choosing top-3, a conﬁguration whose marker
is 2× smaller but less accurate. This trend can be observed for
the remaining use cases.
Smaller marker for target accuracy: FlowLens can ﬁnd a
conﬁguration that exceeds a minimum accuracy threshold, and
that provides the smallest marker. For instance, we set a target
accuracy of 0.85 for a DeltaShaper conﬁguration. Among the
10 experimented conﬁgurations, the optimizer has found 3
candidate conﬁgurations with an accuracy larger than the set
threshold. The system output (cid:104)QL=4, Top-N=30(cid:105) = 0.850, albeit
ﬁnding (cid:104)QL=5, Top-N=40(cid:105) = 0.876 or (cid:104)QL=0, Top-N=40(cid:105) =
0.880, two other conﬁgurations which produced larger accuracy
at the expense of a larger marker.
Best accuracy given a size constraint: The system is also
able to ﬁnd conﬁgurations with a larger accuracy value, given
a maximum marker size. Additionally, and since the size
of a marker can be computed ofﬂine without ﬁrst trying a
conﬁguration, we achieve a reduction in the search space. In
the case of DeltaShaper, setting a maximum marker size equal
to 30 enables the reduction of the search space from 48 to
21 possible conﬁgurations. In this case, the optimizer outputs
(cid:104)QL=2, Top-N=30(cid:105) = 0.890, albeit ﬁnding other smaller but
less accurate alternatives such as (cid:104)QL=3, Top-N=20(cid:105) = 0.850.
H. Comparison with Related Approaches
In this section, we compare FlowLens against two related
approaches: i) techniques which are able to produce compressed
representations of packet distributions, and ii) techniques for
collection of trafﬁc features resorting to programmable switches.
Alternative feature compression approaches: Online Sketch-
ing (OSK) [22] and Compressive Trafﬁc Analysis (CTA) [55]
generate compressed packet length/inter-packet timing distribu-
tions using linear transformations. However, both approaches
depend on matrix multiplications and/or ﬂoating-point oper-
ations unsupported by current switching hardware. Yet, we
compare the classiﬁcation accuracy of FlowLens against the
accuracy obtained by OSK and CTA when using each technique
to compress ﬂow representations.
For evaluating the quality of the solutions yielded by the
different compression techniques, we leverage the concept of
Figure 11. Pareto frontier for covert channel detection when using FlowLens,
OSK, and CTA. Dots show individual conﬁgurations.
Pareto optimality [57] which allows us to compare possible
solutions to multi-criteria optimization problems (ﬂow marker
size vs. accuracy, in our case). A solution is said to be Pareto
optimal if it cannot be improved in one of the objectives without
adversely affecting the other. By generating the set of all of the
potentially optimal solutions (Pareto frontier) for each approach,
we can observe which approach delivers the best trade-offs
between classiﬁcation accuracy and marker size.
Figure 11 depicts the accuracy obtained in the classiﬁcation
of covert channels when using ﬂow markers (with size up
to 100 bins) generated by FlowLens, OSK, and CTA, while
using different compression ratios. FlowLens conﬁgurations are
achieved by combining the different quantization and truncation
parameters. Solid lines represent the Pareto frontiers [44] that
capture the best conﬁgurations for the three approaches. Overall,
FlowLens produces ﬂow markers that exhibit a better accura-
cy/memory trade-off and obtain the most accurate compressed
representations of ﬂows. For instance, in DeltaShaper, most
FlowLens conﬁgurations achieve over 0.80 accuracy (and a
maximum of 0.89 using a ﬂow marker with a size of only 10
bins). In comparison, the most accurate OSK marker takes 16
bins and achieves an accuracy of only 0.76. A similar trend
occurs in the case of Facet detection.
Alternative feature collection approaches: Systems such as
*Flow [74] are able to collect ﬁne-grained packet features at
line rate from the switch and ofﬂoad them to dedicated servers,
where the packet distributions can be computed and analyzed
by other dedicated systems for speciﬁc applications. FlowLens
provides a complementary decentralized design where both the
collection of packet distribution features and the application-
speciﬁc analysis (i.e., ﬂow classiﬁcation) take place on the
switches, thus achieving considerable savings in communication,
compute, and storage hardware resources.
To estimate the potential gains of our design, we analyze the
communication costs of both *Flow and FlowLens. Assuming
the existence of 250k concurrent ﬂows where each ﬂow sends
15k packets during a collection window of 30 seconds, *Flow
ofﬂoads data structures named grouped packet vectors (GPVs),
each containing a ﬂow key and a list of packet lengths, from a
sequence of packets in a ﬂow, on an average of 640ms [74]
12
020406080100Marker Size (Bins)0.00.20.40.60.81.0FacetFlowLensOSKCTA020406080100Marker Size (Bins)0.00.20.40.60.81.0DeltaShaperFlowLensOSKCTAwhich totals 47 evictions. Since each GPV has a ﬁxed header
of 24 bytes, assuming 2 bytes to encode a packet length,
*Flow must transfer (24B×47 + 2B×15k)×250k = 7.78GB per
collection window. This data would then need to be processed
on a dedicated server. In contrast, FlowLens only transfers the
classiﬁcation score of each ﬂow at the end of the collection
window which involves sending a ﬁxed-size header per ﬂow
(13B for ﬂow ID plus a 4B score value) times 250k ﬂows, i.e.,
≈4.25MB. Thus, FlowLens exhibits a communication footprint
three orders of magnitude smaller than *Flow.
VIII. SECURITY ANALYSIS
We now analyze the security properties of FlowLens when
functioning under an adversarial model. The overarching
goal of the adversary is to be able to generate ﬂows of a
target application class without being detected by FlowLens.
We consider three categories of increasingly sophisticated
adversaries considering their knowledge about FlowLens and
the models employed in ML-based security applications.
1. No knowledge about FlowLens nor the ML model: In
the weakest threat model, the attacker knows nothing about
the presence of FlowLens in the network infrastructure, nor
the details of the models being used by the ML-based security
applications leveraging the capabilities of our system. In such
a case, as shown in the sections above, ML-based security
applications making use of the vanilla FlowLens setup can
identify different target classes of trafﬁc with high accuracy.
2. FlowLens-aware adversary: In the second case, we con-
sider an adversary that is aware of the deployment of FlowLens
in the network infrastructure, but who is unaware of the
particular machine learning models being used to ﬁlter the
network for particular classes of trafﬁc. In this case, the
adversary may attempt to launch two particular types of attacks:
Flow aggregation attacks: An adversary may attempt
to
evade FlowLens’s classiﬁer by misusing the truncation and
quantization steps to make the aggregation of ﬂows of a given
class of trafﬁc indistinguishable from another class. In this
sense, this type of attack is similar to our covert channel
scenario (Section VII-D) where the adversary’s goal is to
mimic the distribution of legitimate trafﬁc and evade a classiﬁer.
Figure 6 and Figure 8 show that a ﬁner-grained aggregation of
packet distributions does make it harder to evade the classiﬁer.
This suggests that increasing ﬂow marker granularity makes
FlowLens more robust against ﬂow aggregation attacks.
Evading collection windows: When analyzing long-lived net-
work ﬂows, FlowLens collects ﬂow markers during a maximum
pre-deﬁned collection window. Once this window elapses, the
FMA located on a given switch stops monitoring ﬂows while
the ﬂow markers are read and FMA data structures are reset. An
adversary may attempt to exploit this window of opportunity
to transmit a class of trafﬁc targeted by FlowLens during this
period. However, as mentioned in Section IV-D, FlowLens can
tolerate such attacks provided that multiple switches are used
in an interleaved fashion to ensure that at least one switch can
collect trafﬁc pertaining to ﬂows traversing the network.
DoS attacks: A FlowLens-aware adversary may also attempt
to compromise the availability of our system. For instance, it
may try to mount a DoS attack based on the transmission of
Figure 12. Features (PL bins) collected by the FMA for the (cid:104)QL=4, top-N=10(cid:105)
conﬁguration, when considering different classiﬁers to identify Facet covert
channels. Features in bold are shared among at least two classiﬁers.
packets with random IP addresses, forcing FlowLens to keep
track of multiple dummy ﬂows and waste the switch memory.
To mitigate such a threat, FlowLens can temporarily prevent
the installation of new rules in the FMA ﬂow table when it
detects unusual bursts of trafﬁc, or reconﬁgure FMA parameters
on-the-ﬂy to store smaller (yet less accurate) ﬂow signatures
so as to increase the number of measured ﬂows.
3. FlowLens and ML model-aware adversary: The third
adversary we consider is cognizant of the operation of FlowLens
and knowledgeable about the ML model used by a given ML-
based application. Apart from an adversary’s attempts to evade
or compromise the availability of our system, such an adversary
aims to leverage adversarial ML techniques [3] to subvert the
correct behavior of the model. These attacks can be grouped
in two main categories [3]: i) training-time, where an attacker
aims at manipulating the training set used by the ML model
through the insertion of speciﬁc samples that alter the decision
boundaries of the classiﬁer; ii) test-time, where an attacker
aims to evade classiﬁers by crafting trafﬁc samples in such a
way that these fool the classiﬁer during its operational phase.
In general, providing defenses to such attacks is orthogonal
to FlowLens’s ability to collect ﬂow markers and it concerns
the particular models used by the different ML-based security
applications. Nevertheless, FlowLens is compatible with various
techniques aimed at increasing the robustness of the models
used for trafﬁc analysis. For mitigating training-time attacks,
FlowLens’s proﬁling phase can incorporate mechanisms aimed
at ﬁltering out contaminated instances upon training [45,
83, 25, 67]. Alternatively, FlowLens operators can leverage
recent models whose training is explicitly hardened against
the introduction of adversarial samples [16, 15, 78, 34]. For
tackling execution-time attacks, FlowLens is compatible with
the use of several techniques that increase the difﬁculty of an
adversary to successfully evade network trafﬁc classiﬁers. For
instance, FlowLens can leverage classiﬁer ensembles [1, 11, 42]
or randomize the classiﬁers deployed at test-time [50].
Hardening FlowLens against adversarial ML attacks: We
performed a simple experiment to understand whether FlowLens
can leverage the above techniques to improve its robustness
to adversarial attacks, while still collecting ﬂow markers of
small size. To this end, we proﬁled three different classiﬁers –
XGBoost, Random Forest, and Decision Tree [7] – to identify
Facet trafﬁc in a (cid:104)QL=4, top-N=10(cid:105) FMA conﬁguration.
Figure 12 depicts the importance of the top 10 features
selected by the different classiﬁers after FlowLens’s proﬁling
step. Recall that, for a QL=4, there is a total of 94 features
(bins), from which only the top-10 is considered. We draw
two main observations from this ﬁgure. First, since all three
classiﬁers share several features (marked in bold), crafting the
13
0.00.10.20.30.40.5Feature Importance1185910129547613Facet - XGBoostAcc = 0.920.00.10.20.30.40.5Feature Importance12118136174191415Facet - Random ForestAcc = 0.920.00.10.20.30.40.5Feature Importance12114187134683851Facet - Decision TreeAcc = 0.87trafﬁc to subvert a given feature (e.g., feature 12), requires
extra effort to collectively assess how it affects the classiﬁcation
accuracy not just of a single, but of all three classiﬁers. Second,
each classiﬁer selects a subset of features that are exclusive to
it. Thus, while an adversary may shape a given ﬂow to respect
the features analyzed by a particular classiﬁer, there may be
another classiﬁer that considers a different set of features. For
instance, XGBoost leverages bins 59, 10, 54, and 6 to better
inform a prediction, while the Random Forest classiﬁer ignores
these features and includes 61, 14, 15 in its top-10 instead.
To run multiple classiﬁers in execution-time, FlowLens
must collect a superset of all meaningful features required
by each model. Thus, it is expected that ﬂow markers will
increase their size. Figure 12 suggests that randomization, i.e.,
the random selection of one possible classiﬁer, can provide a
good compromise between robustness to adversarial ML and
ﬂow marker size. While a ﬂow marker consists of 10 features
for a given classiﬁer (amounting to 20B), a ﬂow marker that
enables FlowLens to choose from three different models to
classify ﬂows uses a total of 18 distinct features, producing
a ﬂow marker amounting to just 36B. In a similar fashion,
FlowLens could use all three classiﬁers to produce an ensemble
which will ultimately classify a ﬂow by majority voting [11].
Performance impact of the defense mechanisms: Although
we have not empirically assessed the performance overheads
caused by the proposed defense mechanisms, we argue that
these mechanisms should not signiﬁcantly impair the perfor-
mance of FlowLens. Nevertheless, we reckon that they may
require additional resources. The impact on resource allocation
could be estimated, e.g., by measuring the memory consumed
using ensembles, or by studying how many switches would
sufﬁce to plummet the risks of window evasion attacks.
IX. RELATED WORK
There is a considerable body of work proposing approaches
for building efﬁcient network telemetry systems for large scale
networks [87]. Programmable switches can leverage TCAM-
based ﬂow tables for keeping ﬂow data [80, 76, 52] and wildcard
rules [13] to record a few statistics about a given ﬂow [46]. The
major drawback of this technique is tied to the limited size of
TCAM which prevents the bookkeeping of more than a few
thousand ﬂows [88]. While multiple ﬂows can be combined in
the same table entry [91, 52], this aggregation jeopardizes the
accurate representation of a large number of ﬂows [88].
Trafﬁc sampling techniques enable the collection of statis-
tics for a large set of ﬂows by recording a small number