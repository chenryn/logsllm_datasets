## 小结我们小结一下，看看 HDFS是如何通过大规模分布式服务器集群实现数据的大容量、高速、可靠存储、访问的。1\. 文件数据以数据块的方式进行切分，数据块可以存储在集群任意 DataNode服务器上，所以 HDFS 存储的文件可以非常大，一个文件理论上可以占据整个HDFS 服务器集群上的所有磁盘，实现了大容量存储。2.HDFS 一般的访问模式是通过 MapReduce 程序在计算时读取，MapReduce对输入数据进行分片读取，通常一个分片就是一个数据块，每个数据块分配一个计算进程，这样就可以同时启动很多进程对一个HDFS 文件的多个数据块进行并发访问，从而实现数据的高速访问。关于MapReduce 的具体处理过程，我们会在专栏后面详细讨论。3.DataNode存储的数据块会进行复制，使每个数据块在集群里有多个备份，保证了数据的可靠性，并通过一系列的故障容错手段实现HDFS 系统中主要组件的高可用，进而保证数据和整个系统的高可用。
## 思考题今天留一道有意思的思考题，你可以先想象一个场景，我们想利用全世界的个人电脑、手机、平板上的空闲存储空间，构成一个可以付费共享的分布式文件系统，希望用户可以安装一个App在自己的个人设备上，将个人资料安全地存储到这个分布式文件系统中，并支付一定费用；用户也可以用这个App将自己设备上的空闲存储空间共享出去，成为这个分布式文件系统存储的一部分，并收取一定费用。我想问你的是，如果是你来设计这个分布式文件系统，你是怎么思考的？你的设计方案是什么？欢迎你写下自己的思考或疑问，与我和其他同学一起讨论。![](Images/db513920e735cd054f4c7a22f3dcebc3.png){savepage-src="https://static001.geekbang.org/resource/image/47/93/47dd770400282d41275ee517d7eb7d93.jpg"}
# 07 \| 为什么说MapReduce既是编程模型又是计算框架？在 Hadoop问世之前，其实已经有了分布式计算，只是那个时候的分布式计算都是专用的系统，只能专门处理某一类计算，比如进行大规模数据的排序。很显然，这样的系统无法复用到其他的大数据计算场景，每一种应用都需要开发与维护专门的系统。而Hadoop MapReduce 的出现，使得大数据计算通用编程成为可能。我们只要遵循MapReduce 编程模型编写业务处理逻辑代码，就可以运行在 Hadoop分布式集群上，无需关心分布式计算是如何完成的。也就是说，我们只需要关心业务逻辑，不用关心系统调用与运行环境，这和我们目前的主流开发方式是一致的。请你先回忆一下，在前面[专栏第 4期](http://time.geekbang.org/column/article/65106)我们讨论过，大数据计算的核心思路是移动计算比移动数据更划算。既然计算方法跟传统计算方法不一样，移动计算而不是移动数据，那么用传统的编程模型进行大数据计算就会遇到很多困难，因此Hadoop 大数据计算使用了一种叫作 MapReduce 的编程模型。其实 MapReduce 编程模型并不是 Hadoop 原创，甚至也不是 Google 原创，但是Google 和 Hadoop 创造性地将 MapReduce编程模型用到大数据计算上，立刻产生了神奇的效果，看似复杂的各种各样的机器学习、数据挖掘、SQL处理等大数据计算变得简单清晰起来。``{=html}今天我们就来聊聊[Hadoop解决大规模数据分布式计算的方案------MapReduce]{.orange}。在我看来，**MapReduce既是一个编程模型，又是一个计算框架**。也就是说，开发人员必须基于MapReduce 编程模型进行编程开发，然后将程序通过 MapReduce 计算框架分发到Hadoop 集群中运行。我们先看一下作为编程模型的 MapReduce。为什么说 MapReduce 是一种非常简单又非常强大的编程模型？简单在于其编程模型只包含 Map 和 Reduce 两个过程，map 的主要输入是一对\ 值，经过 map 计算后输出一对 \ 值；然后将相同Key 合并，形成 \；再将这个 \ 输入reduce，经过计算输出零个或多个 \ 对。同时，MapReduce 又是非常强大的，不管是关系代数运算（SQL计算），还是矩阵运算（图计算），大数据领域几乎所有的计算需求都可以通过MapReduce 编程来实现。下面，我以 WordCount 程序为例，一起来看下 MapReduce 的计算过程。WordCount主要解决的是文本处理中词频统计的问题，就是统计文本中每一个单词出现的次数。如果只是统计一篇文章的词频，几十KB 到几 MB 的数据，只需要写一个程序，将数据读入内存，建一个 Hash表记录每个词出现的次数就可以了。这个统计过程你可以看下面这张图。![](Images/e83feef7bfd1d7583f91c42f61ee3b80.png){savepage-src="https://static001.geekbang.org/resource/image/fc/1d/fc8d1ca01c9a81bb75c16dcd504c281d.png"}如果用 Python 语言，单机处理 WordCount 的代码是这样的。    
# 文本前期处理strl_ist = str.replace('\n', '').lower().split(' ')count_dict = {}