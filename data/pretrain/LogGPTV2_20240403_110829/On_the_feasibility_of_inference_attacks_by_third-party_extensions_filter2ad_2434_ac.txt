1
9
.
3
9
9
.
3
9
4
.
7
7
4
.
7
7
3
.
8
2
5
.
2
3
8
.
9
8
.
9
partner
sibling
polView
P i
acc1(1)
oldestF
hometown
genre
birthday
author
P i
acc2(1)
P i
ava(1)
P i
app(1)
Figure 2: Success rates of inference algorithms when α = 1
100
50
1
.
2
8
8
.
4
2
8
.
4
2
9
.
3
3
7
.
2
5
7
.
2
5
2
.
9
5
5
.
9
6
7
.
6
6
1
.
7
5
0
5
9
.
1
1
9
6
.
6
2
6
.
6
2
1
.
0
3
7
.
1
5
7
.
1
5
9
.
1
4
9
.
1
4
9
.
9
3
9
.
9
3
7
.
9
7
8
8
0
8
0
8
1
.
7
9
1
.
7
9
8
.
9
6
7
.
0
6
1
2
1
2
partner
sibling
polView
P i
acc1(4)
oldestF
hometown
genre
birthday
author
P i
acc2(4)
P i
ava(4)
P i
app(4)
Figure 3: Success rates of inference algorithms when α = 4
there is at least one birthday greeting on a user proﬁle, then
the success probability (P i
ava (1)) is even higher, at 93.9%.
The polView had the lowest number of available proﬁles
(3.4%), but P i
ava (1) is a moderate 0.5. This implies, al-
though it is unlikely that an application can access and ﬁnd
the required information for inferring a user’s political view,
if such an access could be gained and the data is present,
then the probability of success is 0.5. This moderately high
success rate compared to the small number of available pro-
ﬁles for polView shows that the inference strategy behind
this algorithm is a reasonable one, but the conditions for
the availability of data is rarely satisﬁed.
6.2.2 Unexpected disclosure
Prior to the experiment, there were a number of algo-
rithms that we expected a low success rate. One of them
was partner because its inference strategy did not appear
for us to be universally applicable. However, the experi-
ment shows that if a user has a partner, algorithm partner
can identify his/her partner with a non-trivial probability
(P i
app(1)) of 56.1%.
The diﬀerence between P i
ava (1) and P i
app(1) in partner is
signiﬁcant (23.2% versus 56.1%) due to the large diﬀerence
between the number of its available and applicable proﬁles.
The algorithm partner has a large number of available pro-
ﬁles because ﬁnding at least one photo containing a tagged
user of the opposite gender is not diﬃcult. But many of our
participants were single. As a result, the number of appli-
cable proﬁles is much lower. The high applicability success
rate of partner conﬁrms the eﬀectiveness of its simple in-
ference strategy, contrary to our original expectation.
Although information about one’s partner is sensitive on
its own, revealing an individual’s ex-partner is an even more
dangerous kind of privacy violation. People typically hide
information about their former relationships. Based on the
feedbacks we received from the participants, in at least 7%
of cases when all inferred answers by partner were wrong,
the participant’s ex-partner (e.g., ex-wife) was identiﬁed in-
stead. More importantly, a few participants told us that al-
gorithm partner has identiﬁed a person whom they are look-
ing forward to date. Identifying such information through
other information sources is not straightforward. In other
words, inference attacks through SNS extension API could
result in accessing highly sensitive information that are not
easy to achieve through other adversarial techniques.
6.2.3 Multiple attempts
By increasing the value of α from one to four, some al-
gorithms showed much higher success rates (Figure 3). For
example, P i
app(4) for genre increases to 88% (compared with
P i
app(1) = 32.8%). On the contrary, success rate of some al-
gorithms like birthday and hometown do not change signiﬁ-
cantly: i.e., they are likely to either return the right answer
in their ﬁrst attempt or fail.
7.
INFERENCE ATTACKS AS BUILDING
BLOCKS: IDENTITY THEFT
Inference attacks are not only privacy violations, they are
building blocks for launching other security attacks. For
instance, an individual who wants to register for an online
banking access account is usually asked to select an alterna-
tive authentication mechanism. One of such mechanisms is
security questions. The idea is that, a user ﬁrst conﬁgures k
supposedly private questions out of a set of N questions pre-
pared by the service provider, together with their answers,
and then when it is necessary, she is challenged to answer
those k security questions (e.g., ”What is the ﬁrst name of
your youngest sibling? ”). Inference attacks can be employed
by adversaries to ﬁnd the answers to such security questions.
An adversary who knows an individual’s username, claims
that she forgot her password. The pre-conﬁgured security
questions will now be presented to the adversary. Then,
the adversary launches inference attacks against the victim
to ﬁnd the answers to these security questions. As SNS
users disclose a vast amount of private information in their
proﬁles, SNS API inference attacks launched by third-party
applications could yield an alarming success rate in identity
theft attacks, as we shall see in the following.
In the following, we estimate the probability of success
for an identity theft attack when the above authentication
strategy is used by the service provider. We assume that the
type-1 permissions required for launching inference attacks
are indeed granted. Let Z be the set of questions supported
by the service provider. Assume every subset of k questions
is equally likely to be adopted by a user. The probability
that an adversary can answer all k questions is the following:
friends’ proﬁles and/or her fellow group members’ proﬁles.
Such works assume they have full access to the social net-
work data set (i.e., proﬁles), and then they suppose half of
the proﬁles are public and the other half are private. How-
ever, they do not specify a realistic mechanism (crawling,
SNS API, etc.) through which certain proﬁles come to be-
come visible (or private) to the adversary. On the contrary,
we make the more realistic assumption that an application
only has access to a proﬁle as well as the information that
is accessible via that proﬁle.
Inference attacks can use diﬀerent inference channels and
target diﬀerent types of users. In [1], inference attacks are
classiﬁed along two dimensions: (1) inference channel, and
(2) victim. Knowing all possible inference channels and all
potential victims of inference attacks is of great use to re-
searchers for proposing the required protection mechanisms.
Felt and Evans [2] proposed the ﬁrst work on protecting
SNS users against threats speciﬁcally posed by third-party
applications. But, they did not relate their work to inference
attacks. In other words, they present a protection mecha-
nism, called privacy-by-proxy, to prevent third-party appli-
cations from accessing original information in user proﬁles.
9. CONCLUSION
In this work, we took the ﬁrst step to understand the
feasibility of SNS API inference attacks, as well as to assess
their privacy impacts. Future work includes the redesign
of SNS APIs that would mitigate the threat of inference
attacks.
10. ACKNOWLEDGMENTS
πk(Z) = X
S∈[Z]k
Qi∈S P i
acc1 (4)
(cid:0)N
k (cid:1)
(1)
This work is funded in part by a Google Research Award,
stipends from ISSNet – an NSERC Strategic Research Net-
work, and an NSERC Discover Grant.
where [Z]k is the set of all size-k subsets of Z, and N = |Z|.
We use P i
acc1(4) in (1) because a user is typically allowed to
make more than one attempt to answer his security ques-
tions. Note that we assume the successful execution of an
algorithm is independent from the other algorithms.
If Z contains exactly the 8 inference algorithms that we
designed (i.e., N = 8) and k = 3, then the value of πk(Z)
equals 0.04, i.e.
for 4% of the potential victims, all three
selected security questions can be answered correctly. The
impression that this success probability is low and thus the
expected number of victims is low is deceptive. One should
be reminded that there are applications in Facebook with
around 50M, 28M, or 15M monthly active users. With a
success probability of 4%, an application with 15M users
means an adversary can successfully impersonate 600,000
users by ﬁrst launching inference attacks, and then following
up with identity theft attacks. This analysis testiﬁes to the
unfortunate eﬀectiveness of SNS API inference attacks as a
stepping stone for dangerous security attacks.
8. RELATED WORK
Inference attacks in social networks is a new research prob-
lem. [6, 5, 3] proposed inference techniques that mainly use
two types of information as the basis of inference: (1) friend-
ship information, and (2) group membership. The main idea
is that the value of an attribute in an individual’s proﬁle is
likely to be the same as its value in the majority of her
11. REFERENCES
[1] S. Ahmadinejad, M. Anwar, and P. Fong. Inference
attacks by third-party extensions to social network
systems. In Proc. of IEEE 9th International Conference
on Pervasive Computing and Communications
Workshops, pages 282 –287, 2011.
[2] A. Felt and D. Evans. Privacy protection for social
networking APIs. Web 2.0 Security and Privacy, 2008.
[3] J. He, W. Chu, and Z. Liu. Inferring Privacy
Information from Social Networks. In Intelligence and
Security Informatics, volume 3975 of Lecture Notes in
Computer Science, pages 154–165. 2006.
[4] J. Kotrlik and C. Higgins. Organizational research:
Determining appropriate sample size in survey research
appropriate sample size in survey research. Information
Technology, Learning, and Performance Journal,
19(1):43, 2001.
[5] W. Xu, X. Zhou, and L. Li. Inferring privacy
information via social relations. In Proc. of IEEE 24th
International Conference on Data Engineering
Workshop, pages 525–530, 2008.
[6] E. Zheleva and L. Getoor. To join or not to join: the
illusion of privacy in social networks with mixed public
and private user proﬁles. In Proc. of the 18th
international conference on World wide web, pages
531–540, 2009.