Assessing BitTorrent Client Popularity (cid:3)
(through uTP handshake messages)
Determining Number of Disks (cid:3)
(through re-seeding of Witty’s PRNG)
Table 4: Example inferences. Inferences made through IBR require various numbers of packets and types of packet-level information.
grows slowly, despite observing over 200k open resolvers in many
hour bins. Since we observe only a fraction of the known lower
bound for open resolvers [9], this behavior indicates reuse, i.e., the
phenomenon generating the DNS responses is repeatedly sending
spoofed packets to the same set of open resolvers. Due to this rep-
etition, smaller subnets of UCSD-NT capture a similar number of
open resolvers (at least 89% of all open resolvers in UCSD-14-DNS
with /16 subnets).
Validation. We verify that the open resolvers we include in UCSD-14-DNS
are actually open resolvers by examining overlap with the ORP
data in the same time period. Almost all (84%) of IP addresses ob-
served in UCSD-14-DNS also appear as open resolvers in the ORP
dataset. The remaining 16% are likely due to hosts intermittently
online or were affected by Internet middleware (e.g., ﬁrewalls may
drop packets from the ORP scan).
Comparison to other data sources. Although ORP has better cov-
erage, active probing cannot reveal which open resolvers are actu-
ally used in attacks. The open resolvers ORP missed may include
DNS servers that respond to packets from any source IP address,
but only on certain interfaces (e.g., behind a ﬁrewall).
Through IBR, we can add to the knowledge of the phenomenon
starting around February 2014. Speciﬁcally, we considered the “at-
tack” trafﬁc from the 462 second-level domains in UCSD-14-DNS
that resulted in over 50k open resolvers sending trafﬁc to UCSD-
NT.
• baidu.com was the ﬁrst second-level domain used in the at-
tack – six days prior the second domain reaching our “attack”
threshold. This was likely a testing phase.
Figure 9: Open resolvers in UCSD-14-DNS
week [9]. For comparison, we consider all open resolvers4 in ORP
data in the same time period of UCSD-14-DNS. Table 5 shows that
the 1.5M open resolvers found in UCSD-14-DNS are about 4% of
the total found by ORP.
Figure 9 shows the number of open resolvers observed each hour,
as well as the cumulative number, observed in UCSD-14-DNS.
After an initial spike, the cumulative number of open resolvers
4 Speciﬁcally, the IP address of the responding DNS server, which
is not necessarily the queried IP address.
0.0M0.5M1.0M1.5M2.0M2.5M3.0M3.5M/8/9/10/11/12/13/14/15/16/24 Blocks Observed0.0M0.5M1.0M1.5M2.0M2.5M3.0MX.0/16X.64/16X.128/16X.192/16X.255/16 } Conficker } BitTorrent BitTorrent & Encap. IPv6/24 Blocks Observed0.0M0.2M0.4M0.6M0.8M1.0M1.2M1.4M1.6MJan23Jan30Feb06Feb13Feb20Feb27Open Resolvers ObservedCumulativeHourly• The attacks reused name servers (e.g., 36 domains had a
nameserver matching *.dnspod.net), suggesting victims are
repeatedly targeted.
• UCSD-14-DNS observes more sources with errors (e.g., SERV-
FAIL or NAMEFAIL) than ORP. Many of the open resolvers
discovered in UCSD-14-DNS responded with non-errors and
errors for queries for the same second-level domain, imply-
ing that the attack successfully inundated authoritative name
servers with queries.
# Srcs Veriﬁed Distribution
OS (from p0f)
Linux 2.4.x
217,989
Wraps @27 hours
Windows 7 or 8 102,097
70% up for less than 1 day
Linux 3.x
52,200
Longer uptimes less likely
48,360 × Most uptimes 3 to 13 days
iOS iPhone/iPad
32,721 × Most uptimes 3 to 13 days
Mac OS X 10.x
28,034
Linux 2.2.x-3.x
21,717
FreeBSD
Linux 2.6.x
17,290
Linux 2.4.x-2.6.x 14,800
Wraps @27 hours
Reboots for patch [8]
Longer uptimes less likely
Longer uptimes less likely
Include?
no
yes
yes
no
no
no
yes
yes
yes
Discussion. IBR can supplement other measurement techniques,
Dainotti et al.
leveraged IBR to discover hosts that are intermit-
tently used or behind ﬁrewalls in a study of IPv4 address space
utilization [21, 22]. For similar reasons, we ﬁnd additional open
resolvers through IBR. Additionally, the observation in IBR or the
differences between datasets may reveal additional information about
our inferences, e.g., that an open resolver is being used maliciously,
or that port ﬁltering is used [44].
We observe more open resolvers due to a change in the com-
position of IBR. It is possible that this phenomenon could halt, in
which case our coverage of open resolvers would decrease signif-
icantly. This variability is, in part, due to our dependence on a
speciﬁc application. When many types of trafﬁc contribute to a
signal, we expect our ability to make inferences to improve. For
example, in IPv4 address space utilization, any type of trafﬁc can
imply usage [21].
8.2 Determining uptime
Table 6: We verify that the uptime inferred by TCP timestamp
method matches the actual uptime of a machine, and by examining
the distribution of suspected uptimes observed in UCSD-13.
Figure 10: Distribution of uptime in days for IP addresses with TCP
timestamps.
We explore inferring end host uptime. Studying uptime can help
understand human behavior, identify machines that have not ap-
plied security updates, and select resources with better availability.
Our objectives in this case study are: (1) to explore an inference
requiring repeated contact; (2) to highlight the beneﬁt of relying
on information from the transport layer over upper-layer informa-
tion from a speciﬁc application; (3) to show how IBR can provide
unique insights, unavailable through other data sources.
Method. We use TCP timestamps to calculate uptime [37], a
technique already implemented in Nmap [2] and p0f [49]. RFC
1323 speciﬁes that TCP timestamps should be obtained from a
clock that is approximately proportional to the real time [30]. Un-
der the assumptions that (1) the OS zeros the counter at boot time,
(2) the timestamp has not wrapped, and (3) network speeds are
about constant, we can compute the frequency of the timestamp
increments and total uptime. Speciﬁcally, for two packets j and k
received at times rj and rk respectively with TCP timestamps tj
and tk, the frequency of the timestamp increments is f = tk−tj
,
rk−rj
and the uptime (when packet k is sent) is tk
f .
For each hour of data, we calculate frequency and uptime for
each source IP sending TCP timestamps, and use p0f to determine
the operating system that sent the packets. We then aggregate over
all hours of data, excluding sources when either p0f reports con-
ﬂicting OSes, or we determine that the OS violates assumption (1),
or we receive packets that reveal conﬂicting uptimes (e.g., from two
hosts behind a NAT). Additionally, we verify that the uptime is less
than a year and that the frequency is close to a typically used value
(e.g., one-third of IP addresses have a clock rate of 1000Hz) before
including an IP address in our analysis.
Validation. To validate this technique, we analyze the accuracy
of assumptions (1) and (2). Table 6 summarizes our ﬁndings in
ensuring that the TCP timestamp is set to zero at boot time. First,
we verify the accuracy of TCP timestamps on our own machines
using p0f. We found inconsistencies for iOS and Mac OS, and
exclude IP addresses with these OSes from analysis. Additionally,
we examine the distribution of uptimes in UCSD-13 for each OS
individually. We exclude two OSes, Linux 2.4.x and Linux 2.2.x-
3.x, because the TCP timestamps appear to reset when the counter
reaches 100M (at approximately 27 hours). We include Windows
7/8, which has a similar distribution from hour 0 to 24; but there is
no evidence of a reset, implying that Windows 7/8 users generally
turn off their machines every day.
Another concern is that the TCP timestamp will wrap once it
meets its maximal value. The fastest timestamps we observe show
clocks with frequencies on the order of 1000Hz, which will wrap
about every 49 days. In Figure 10, about 0.1% percent of hosts
have an uptime of 49 days, which suggest the impact of a wrapping
timestamp is minimal.
Results. In UCSD-12, UCSD-13, partial-UCSD-13, and
MERIT-13, we were able to infer uptimes associated with 290,697,
208,104, 57,990, and 47,122 IP addresses respectively. Both
partial-UCSD-13 and MERIT-13 reveal signiﬁcantly fewer
uptimes than UCSD-12 and UCSD-13, showing the inﬂuence of
darknet size and temporal ﬂuctuations (Section 7). Despite the dif-
ferences in coverage, the data sets provide a consistent picture of
uptime. Figure 10 shows that most hosts have short uptimes in all
datasets, and a signiﬁcant fraction have an uptime of less than 1
day. For the next three weeks, the fraction of up hosts decays ex-
ponentially, consistent with a constant probability of being turned
off/rebooted. In UCSD-12, we observe many hosts with an uptime
of about 35 days, many of which run Linux. The boot times of
these machines are consistent with applying a newly released ker-
nel security ﬁx [7]. Similarly, in 2013, FreeBSD required a reboot
after an update to BIND [8], but the inﬂuence on our aggregated
data is smaller.
Discussion. The main beneﬁt of using IBR to infer uptime is
the diversity in end hosts analyzed. To the best of our knowledge,
this is the ﬁrst study to provide an Internet-wide analysis of up-
time. Nmap and p0f both use the TCP timestamp technique, but
 0.0025 0.05 1 0 5 10 15 20 25 30 35 40 45Fraction SourcesUptime (days)UCSD-12UCSD-13part-UCSD-13MERIT-13measurements from a single vantage point (and not based on IBR)
are limited in the sources they can evaluate. Active probing will not
reach end hosts behind a ﬁrewall or NAT, whereas passive obser-
vation will be biased based on the population observed. Our study
used over a half a million sources to validate the approach; but we
could only determine uptime for 40k to 200k hosts (our analysis
could improve, if instead of discarding all trafﬁc from IP addresses
used by multiple hosts, we isolated the timestamps for each host).
Kumar et al. examined IBR from the Witty worm to extract host
uptimes. However, since Witty targeted a buffer overﬂow in net-
work security products, the number of networks they could analyze
was limited (inferring uptime for only about 800 machines) and not
diverse (about a quarter of the machines were from only two insti-
tutions) [32]. Inferring properties from information extracted at the
transport layer expands our coverage.
8.3
Identifying path changes
Detecting and analyzing path changes provides insight into Inter-
net path stability [19, 42], and outages [12, 31, 51]. Our goals with
this case study are to explore an inference that: (1) requires succes-
sive measurements; (2) has an element of predictability (although
IBR composition is erratic, TTL is predictable); and (3) shows how
to use IBR to reduce the active probing required to infer changes
(similar to [31, 51]).
Method. We extend the technique of [12] to identify path changes
from remote ASes to the darknet, which relies on the insight that
the TTL of a received packet reﬂects the number of hops on the
path to the darknet. If the path is unchanged, all packets from a
host will have the same TTL. We calculate the number of hops by
subtracting the TTL from the next highest power of 2 (a technique
used in [13]), excluding any packets with a TTL less than 3 since
they likely originate from traceroute and are not a predictable mea-
sure of hop count. When the number of hops from a source to the
darknet increases or decreases, we infer a likely path change (sim-
ilar to a previous technique for monitoring trafﬁc at a CDN [51]).
Note this method will not detect changes that result in the same
length path (but through different routers).
For each IP address, we calculate for each 5-minute time bin,
t, maxt and mint−1, the most and least number of hops taken at
time t respectively. We consider a path to have changed if maxt
> maxt−1 or if mint < mint−1. We expect most path changes to
occur during a 5-minute bin, and not at time bin boundaries; our
requirement for a change will identify changes that occur during a
5-minute bin (the time bin includes packets with the old TTL and
the new TTL). This method should also account for a change in
load balancing paths (the whole distribution shifts). The method
will have some false positives due to NAT (when a new host, with
a longer/short path starts transmitting) as well as false negatives.
To study changes affecting larger source granularities, e.g., a pre-
ﬁx or AS, for each time bin we also calculate the percentage of IP
addresses that sent packets in that time bin as well as the previous
one, and also indicated a path change. Using multiple sources from
a preﬁx or AS increases our conﬁdence that an event occurred. In
particular, we can identify path changes affecting large portions of
the address space (as opposed to the Internet edge).
Results. We are interested in paths that we can continually moni-
tor, which we call always-analyzable. Section 6 showed that only
countries and a few ASes send IBR to our darknets every minute.
Table 7 conﬁrms that few sources are always-analyzable; not shown
is the signiﬁcant overlap of such sources across datasets: 1300
ASes are in both UCSD-13 and MERIT-13, and 1000 ASes are
in both UCSD-13 and UCSD-12. The UCSD-13 data yields the
best insight into path changes for transit/access ASes. Although
IP addresses
/24 blocks
Preﬁxes
ASes
Countries
2.5k 2.8k
2.3k 2.6k
3.3k 3.6k
1.6k 1.7k
146 155
Partial
2.4k
2.1k
2.7k
1.4k
145
UCSD-12 UCSD-13 MERIT-13
2.2k
2.0k
2.9k
1.4k
148