command such as cat in > out, the shell, typically
running at high-integrity, creates the (cid:12)le out with
high-integrity. If in is a low-integrity (cid:12)le, then cat
will be downgraded on reading it, and then its at-
tempt to write to out will be denied.
6.4. Performance Overheads
We present both the microbenchmark and macrobench-
mark results for PPI. For microbenchmark evaluation,
we used LMbench version 3 [23] to check the perfor-
mance degradation of popular system calls. The results
are summarized in Figure 4. We observed that PPI did
not introduce noticeable overhead for most system calls
except for open (and other similar system calls such as
stat). For macrobenchmark, we measured 3 typical
applications running within PPI during runtime. As
illustrated in the Figure 5, the runtime overhead for
applications in PPI is about 5% or less.
6.5. Limitations
Our approach cannot support arbitrary untrusted soft-
ware. Some software, by its very nature, may need re-
source accesses that cannot safely be granted to un-
trusted applications. Our results show that for the
type of programs that tend to be downloaded from un-
trusted sources, our approach is indeed applicable.
Our work does not focus on con(cid:12)dentiality or avail-
Original
PPI Mode
Time
1.269
2.476
22.467
Time Overhead
1.271
2.604
23.345
0.1%
5.1%
3.8%
gzip
xpdf
make
Figure 5. Application Performance Overhead.
All numbers are in seconds averaged across
10 runs.
ability, but it still contributes to them in two ways.
First, solutions for con(cid:12)dentiality and availability must
build on solutions for integrity. Second, our techniques
halt malware that exploits integrity violations to attack
con(cid:12)dentiality; for example, by preventing a rootkit
from installing itself, we also prevent it from subse-
quently harvesting and sending con(cid:12)dential account in-
formation. But no protection is provided from malware
that targets violation of con(cid:12)dentiality without violat-
ing integrity.
7. Related Work
Information Flow Based Systems. Biba model [7]
has a strict \no read down and no write up" policy. The
low-water mark model [7] relaxes this strict policy to
permit subjects to be downgraded when they read low-
integrity inputs. LOMAC [12], a prototype implemen-
tation of low-water mark model on Linux, addresses the
\self-revocation" problem to a certain extent: a group
of processes that share the same IPC can continue to
communicate after one of the processes is downgraded
by having the entire group downgraded, but the prob-
lem still remains for (cid:12)les. SLIM (Simple Linux In-
tegrity Model) [28] is part of the IBM research trusted
client project, and is also based on the LOMAC model.
It also incorporates the Caernarvon model [17], which
supports veri(cid:12)ed trusted programs and limits the trust
on these programs by separating read and execute priv-
ileges. The features developed in this paper are more
general in this regard, allowing distinctions between
data input and control input, and so on.
IX [22] is an experimental MLS variant of Unix. It
uses dynamic labels on processes and (cid:12)les to track in-
formation (cid:13)ow for providing privacy and integrity. In
contrast, our technique generalizes the LOMAC model
by o(cid:11)ering several other policy choices, which we have
260
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
shown to be helpful for improving usability. Other im-
portant distinctions between these works and ours are
that we decouple policies from labels, and provide au-
tomated techniques for policy development.
Windows Vista enforces only the \no write up" part
of an information (cid:13)ow policy, \no read down" is not en-
forced as it causes usability problems. Unfortunately,
malware writers can adapt their malware to defeat this
protection, as discussed in the introduction.
In con-
trast, Back to the Future system [14] enforces only the
\no read down" policy. Its main advantages are that
it can recognize any attempt by malware to inject it-
self into inputs consumed by trusted applications, and
the ability to rollback malware e(cid:11)ects. A drawback is
that any attempt to \use" the output of an untrusted
(but not malicious) application would require user in-
tervention. It can be di(cid:14)cult for users to judge whether
such inputs are \safe" and respond correctly to such
prompts. Secondly, malware can freely overwrite criti-
cal (cid:12)les, which need to be \recovered" when the data is
subsequently accessed | a potentially time-consuming
operation.
Safe Execution Environments [3, 30, 37] and virtual
machines [32, 9, 4] rely on isolation to con(cid:12)ne untrusted
processes. While isolation is an e(cid:11)ective protection
technique, maintaining multiple isolated working en-
vironments is not very convenient for users. In partic-
ular, objects such as (cid:12)les that need to be accessed by
untrusted code have to be copied into and/or out of
the isolated environment each time.
Li et al [20] also address the problem of making
mandatory access control usable by focusing on tech-
niques for policy development. However, their focus
is on servers exposed to network attacks, as opposed
to untrusted software threats on workstations. The
nature of the threat (remote attacks versus adaptive
malware) is quite di(cid:11)erent, causing them to focus on
techniques that are quite di(cid:11)erent from ours. For in-
stance, they donâ€™t protect user (cid:12)les, while we consider
corrupting of user (cid:12)les to be a very powerful attack vec-
tor in our context. Moreover, they do not consider the
problem of securing software installations, or provide
analysis techniques that can leverage resource access
logs to generate policies. Nevertheless, there are some
similarities as well: we have been able to use their no-
tion of limiting trust to certain network channels. In
addition, we provide a re(cid:12)nement of this notion in the
context of (cid:12)les.
All of the above works were based on central-
ized policies, which are less (cid:13)exible than decentralized
information-(cid:13)ow control (DIFC) policies. DIFC poli-
cies allow applications to control how their data is used.
In this regard, JFlow [24] is a language level approach.
Asbestos [10] and Hi-Star [38] are new operating sys-
tem projects that have been architected with infor-
mation (cid:13)ow mechanisms incorporated in their design.
Flume [19] is focused on implementing an extension
to existing operating systems to provide process level
DIFC. Like most other previous works in information-
(cid:13)ow based security, these projects too focus on mech-
anisms, whereas our focus has been on generating the
policies needed to build working systems.
SELinux, Sandboxing and Related Techniques.
Several techniques have been developed for sand-
boxing [13, 2, 26]. Model-carrying code [29] is focused
on the problem of policy development, and provides a
framework for code producers and code consumers to
collaborate for developing policies that satisfy their se-
curity goals. Nevertheless, development of sandboxing
policies that can robustly defend against adaptive mal-
ware is a challenge due to the ease of indirect attacks
as described in the Introduction.
SELinux [21] uses domain and type enforcement
(DTE) policies to con(cid:12)ne programs. Their main fo-
cus has been on servers, and they have developed very
detailed policies aimed at providing the least privilege
needed by such applications. Systrace project [26] has
also developed system-call based sandboxing policies
for several applications, and is widely used in FreeBSD.
Neither approach ensures system integrity by design.
SELinux as well as Systrace can log accesses made dur-
ing trial runs of an application, and use it as the basis
to generate a policy for that application. Their policy
generation technique is useful for trusted code, such as
servers, but would be dangerous for untrusted applica-
tions.
Whereas our focus is on generating policies that
ensure integrity, other researchers have worked on
the complementary problem of determining whether a
given policy guarantees system integrity [16].
8. Conclusion
In this paper, we presented techniques for proactive
integrity protection that scales to a modern operat-
ing system distribution. By enforcing information
(cid:13)ow policies, our approach provides positive assurances
against malware from damaging system integrity. One
of the central problems in developing practical systems
based on such mandatory access control policies has
been the complexity of policy development. We have
developed several techniques to automate the genera-
tion of low level information (cid:13)ow policies from data
contained in software package managers, and logs that
capture normal usage of these systems. Our experi-
mental results show that the technique is e(cid:14)cient, can
261
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
provide protection from most malware, and does not
unduly impact system usability.
References
[1] Linux rootkits. http://www.eviltime.com.
[2] A. Acharya and M. Raje. Mapbox: Using parameterized
behavior classes to con(cid:12)ne applications. In USENIX Secu-
rity Symposium, 2000.
[3] Alcatraz. http://www.seclab.cs.sunysb.edu/alcatraz.
[4] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris,
A. Ho, R. Neugebauer, I. Pratt, and A. War(cid:12)eld. Xen and
the art of virtualization. In Proceedings of the nineteenth
ACM symposium on Operating systems principles, volume
37, 5 of Operating Systems Review, pages 164{177, New
York, Oct. 19{22 2003. ACM Press.
[5] S. Bhatkar, D. C. DuVarney, and R. Sekar. Address ob-
fuscation: an e(cid:14)cent approach to combat a broad range of
memory error exploits. In Proceedings of the 12th Usenix
Security Symposium, Washington, D.C., August 2003.
[6] K. J. Biba.
Integrity considerations for secure computer
systems. Technical Report MTR-3153, Mitre Corporation,
June 1975.
[7] K. J. Biba.
Integrity considerations for secure computer
systems. In Technical Report ESD-TR-76-372, USAF Elec-
tronic Systems Division, Hanscom Air Force Base, Bed-
ford, Massachusetts, 1977.
[8] M. Bishop and M. Dilger. Checking for race conditions in
(cid:12)le accesses. Computing Systems, 9(2), 1996.
[9] J. Dike. A User-Mode port of the linux kernel. In Proceed-
ings of the 4th Annual Showcase and Conference (LINUX-
00), pages 63{72, Berkeley, CA, Oct.
10{14 2000. The
USENIX Association.
[10] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey,
D. Ziegler, E. Kohler, D. Mazires, F. Kaashoek, and
R. Morris. Labels and event processes in the asbestos op-
erating system. In 20th Symposium on Operating Systems
Principles (SOSP 2005), 2005.
[11] The
buildsystem.
scholz.de/fedora.us-build/html/.
fedora.us
http://enrico-
[12] T. Fraser. Lomac: Low water-mark integrity protection for
COTS environments. In IEEE Symposium on Security and
Privacy, 2000.
[13] I. Goldberg, D. Wagner, R. Thomas, and E. A. Brewer. A
secure environment for untrusted helper applications: con-
(cid:12)ning the wily hacker. In USENIX Security Symposium,
1996.
[14] F. Hsu, T. Ristenpart, and H. Chen. Back to the future:
A framework for automatic malware removal and system
repair. In Annual Computer Security Applications Confer-
ence (ACSAC), December 2006.
[15] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell. Pro-
tecting browser state from web privacy attacks. In WWW
â€™06: Proceedings of the 15th international conference on
World Wide Web, pages 737{744, New York, NY, USA,
2006. ACM.
[16] T. Jaeger, R. Sailer, and X. Zhang. Analyzing integrity
protection in the selinux example policy. In Proceedings of
the 12th USENIX Security Symposium, 2003.
[17] P. Karger, V. Austel, and D. Toll. Using a mandatory
secrecy and integrity policy on smart cards and mobile de-
vices. In EUROSMART Security Conference, pages 134{
148, Marseilles, France, 2000.
[18] P. Karger, V. Austel, and D. Toll. Using gconf as an ex-
ample of how to create an userspace object manager. page
SELinux Symposium, 2007.
262
[19] M. Krohn, A. Yip, M. Brodsky, N. Cli(cid:11)er, M. F. Kaashoek,
E. Kohler, and R. Morris. Information (cid:13)ow control for stan-
dard os abstractions. In SOSP â€™07: Proceedings of twenty-
(cid:12)rst ACM SIGOPS symposium on Operating systems prin-
ciples, pages 321{334, New York, NY, USA, 2007. ACM.
[20] N. Li, Z. Mao, and H. Chen. Usable mandatory integrity
protection for operating systems. In IEEE Symposium on
Security and Privacy, 2007. To appear.
[21] P. A. Loscocco and S. D. Smalley. Meeting critical security
objectives with security-enhanced linux. In Proceedings of
the 2001 Ottawa Linux Symposium, 2001.
[22] M. D. McIlroy and J. A. Reeds. Multilevel security in
the UNIX tradition. Software - Practice and Experience,
22(8):673{694, 1992.
and
[23] L. McVoy
Lmbench.
Staelin.
http://www.bitmover.com/lmbench/.
C.
[24] A. C. Myers and B. Liskov. Protecting privacy using the
decentralized label model. ACM Transactions on Software
Engineering and Methodology, 9(4):410{442, 2000.
[25] J. Newsome and D. Song. Dynamic taint analysis for au-
tomatic detection, analysis, and signature generation of ex-
ploits on commodity software. In Proceedings of 12th An-
nual Network and Distributed System Security Symposium
(NDSS), 2005.
[26] N. Provos. Improving host security with system call poli-
cies. In Proceedings of the 11th USENIX Security Sympo-
sium, pages 257{272, 2003.
[27] F. Qin, C. Wang, Z. Li, H. seop Kim, Y. Zhou, and
Y. Wu. LIFT: A low-overhead practical information (cid:13)ow
tracking system for detecting general security attacks. In
IEEE/ACM International Symposium on Microarchitec-
ture, December 2006.
[28] D. Sa(cid:11)ord and M. Zohar. A trusted linux client (tlc), 2005.
[29] R. Sekar, V. Venkatakrishnan, S. Basu, S. Bhatkar, and
D. C. DuVarney. Model-carrying code: A practical ap-
proach for safe execution of untrusted applications. In ACM
Symposium on Operating System Principles, Bolton Land-
ing, New York, October 2003.
[30] W. Sun, Z. Liang, R. Sekar, and V. Venkatakrishnan. One-
way Isolation: An E(cid:11)ective Approach for Realizing Safe
Execution Environments. Proceedings of the Network and
Distributed System Security Symposium, 2005.
[31] E. F. Walsh.
Integrating xfree86 with security-enhanced
linux. In X Developers Conference, Cambridge, MA, 2004.
[32] B. Walters. VMware virtual platform. j-LINUX-J, 63, July
1999.
[33] D. P. Wiggins. Security extension speci(cid:12)cation, version 7.0.
Technical report, X Consortium, Inc., 1996.
[34] C. Wright, C. Cowan, J. Morris, S. Smalley, G. KroahHart-
man, s modules, and G. support. Linux security modules:
General security support for the linux kernel, 2002.
[35] J. Xu, Z. Kalbarczyk, and R. K. Iyer. Transparent runtime
randomization for security. In Symposium on Reliable and
Distributed Systems (SRDS), Florence, Italy, October 2003.
[36] W. Xu, S. Bhatkar, and R. Sekar. Taint-enhanced policy
enforcement: A practical approach to defeat a wide range
of attacks. In USENIX Security Symposium, August 2006.
[37] Y. Yu, F. Guo, S. Nanda, L. chung Lam, and T. cker Chi-
ueh. A feather-weight virtual machine for windows applica-
tions. In Proceedings of the 2nd ACM/USENIX Conference
on Virtual Execution Environments (VEEâ€™06), June 2006.
[38] N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazires.
Making information (cid:13)ow explicit in histar. In Seventh Sym-
posium on Operating Systems Design and Implementation
(OSDI06), 2006.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply.