cally – such as a regular Datalog rule like r1 – or in a
distributed fashion, as in r2. In A3, initiators specify re-
lay selection policies using local rules (Section 5), and
path instantiation using distributed rules (in fact, a series
of distributed recursive queries as we show in Section 6).
A3LOG shares a similar execution model with the
Click modular router [18], which consists of elements
that are connected together to implement a variety of
network and ﬂow control components.
In the case of
A3LOG, these elements include database operators (such
as joins, aggregation, selections, and projections) that
are directly generated from queries. Reference [19] pro-
vides more details on the compilation process and ex-
ecution model used in declarative networking that A3
adopts.
3.3 Materialized Soft-state Tables and Events
Declarative networking incorporates a soft-state stor-
age model, where each relation has an explicit “time to
live” (TTL) or lifetime. All facts in the relation must be
periodically updated before their TTL expires, or they
are deleted.
A3LOG
the
materialize [19] directive, which speciﬁes the TTL
of each relation. A materialize directive has the form:
materialize(Relation, Timeout, Max entries,
soft-state
supports
through
Keys), where Relation is the name of the relation,
Timeout is the maximum time in seconds that any
fact in the relation may persist, Max entries is the
maximum facts allowed in a relation before facts are
ejected according to a FIFO policy, and Keys speciﬁes
the relation’s primary keys.
If a fact is derived with
the same primary keys as an existing fact in the same
relation, the new fact replaces the old one, and the TTL
is restored.
If a relation has no corresponding materialize di-
rective, it is treated as an event predicate with zero life-
time. Event predicates – whose names are preﬁxed with
an “e” – are used to denote transient tables used as input
to rules.
4 A3 Design Goals and Architecture
A3 is a ﬂexible and extensible anonymity system in
which protocol designers publish their particular relay
selection and path instantiation algorithms along with
a description of their corresponding performance and
anonymity tradeoffs. In contrast to existing anonymity
systems in which an immutable relay selection algo-
rithm is hardcoded into the anonymity service, A3 al-
lows the sender to provide a relay selection policy that
precisely speciﬁes the manner in which relays are cho-
sen for its anonymous paths. The A3LOG policy lan-
guage (Section 5) enables the application to not only in-
telligently tune relay selection in favor of performance
or anonymity [40, 36], it also allows the application to
easily deﬁne its individual characterization of perfor-
mance in terms of bandwidth, latency, loss, jitter, etc.,
or some combination of the above. In addition to sup-
porting ﬂexible relay selection, A3 also permits the cus-
tomization of path instantiation policies (Section 6).
A3’s use of declarative networking provides the ca-
pability for applications to rapidly customize and reﬁne
the policies that best meet their application constraints.
However, our system does not preclude similar tuning
outside the use of declarative languages. A user of A3
who is not familiar with declarative policy languages
can, for example, simply download and install an A3LOG
policy that produces low latency and low jitter paths for
his VoIP application, while using a different policy to
deliver high downstream throughput for anonymous web
browsing.
Since the anonymity offered by an anonymous path
depends in no small part on the mechanisms for relay
selection [24, 36, 26] and path instantiation, policies
should be used with extreme caution until their security
properties can be fully understood. A thorough review
of the performance and anonymity properties of various
relay selection and path instantiation algorithms is out-
side the scope of this paper. Our goal in this paper is
to provide a ﬂexible architecture for developing, test-
ing, and studying path strategies and implementations
(though A3 constitutes a very useful tool for conducting
security evaluations).
System Overview. An application, or a proxy acting
on the application’s behalf, provides relay and path in-
stantiation policies that reﬂect the application’s commu-
nication requirements. Figure 1 shows the architecture
of the A3 client running on the initiator’s host. The Re-
lay Selection Engine interprets the initiator’s relay se-
lection policy and applies that policy to produce (but not
instantiate) an anonymous path consisting of relays from
the Local Directory Cache. To populate the cache, the
A3 instance periodically contacts a Directory Server to
ascertain membership information – that is, a listing of
available relays – and, optionally, one or more Informa-
tion Providers.
Information Providers are data aggre-
gating services that report performance characteristics
of relays (e.g., bandwidth) and links (e.g., the latency
between two relays). The Relay Selection Engine uses
cached data to generate paths that conform to the pro-
vided relay selection policy.
Once the Relay Selection Engine produces a path, the
Forwarding Engine instantiates that path according to
the provided path instantiation policy. After path es-
tablishment, a Proxy Service on the local machine in-
tercepts the application’s trafﬁc and relays it through
the anonymous path. Likewise, incoming data from the
anonymous channel is transparently forwarded through
the Proxy Service to the application. To forward up-
stream and downstream packets, each relay also includes
a Forwarding Engine.
Below, we describe each component of A3 in more
detail.
4.1 Information Providers
To support non-trivial relay selection policies, A3
makes use of Information Providers (also referred to as
Providers) that aggregate node and/or link performance
data. Policies may utilize such information to more pre-
cisely deﬁne their requirements (e.g., “include only re-
lays that have been online for at least an hour”).
A3 imposes few restrictions on the types of Infor-
mation Providers. Each Information Provider is inter-
faced through an adapter that resides on the A3 relay.
Adapters are small programs or scripts that periodically
query a Provider for new information, storing the results
in the Local Directory Cache. Our current implemen-
tation includes adapters for the Vivaldi [6] embedded
coordinate system (described below) and CoMon [27],
although others can be easily constructed.
Network Coordinate Information Providers Tradi-
tional anonymous relay selection algorithms (most no-
tably Tor [9], and the reﬁnement proposed by Snader and
Borisov [40]) bias selection in favor of relays that ad-
vertise high bandwidths. However, in addition to band-
width, an application may also prefer paths that exhibit
low latency. Unlike bandwidth, latency is not a node
characteristic that can be associated with an individual
relay. Rather, latency is a link characteristic that has
meaning only when deﬁned in terms of a connection be-
tween a pair of relays.
(cid:1) links in a network composed
Given that there are(cid:0)N
2
of N relays, maintaining link characteristics for all re-
lays in the anonymity network is infeasible. One prac-
tical solution to succinctly capture pairwise link laten-
cies is via the use of virtual coordinate embedding sys-
tems (also called network coordinate systems). These
distributed algorithms enable the pairwise latencies be-
tween all participating relays to be estimated to high ac-
curacy with low overhead. Network coordinate systems,
such as Vivaldi [6], PIC [5], NPS [25], and Big Bang
Simulation [34] map each relay to multidimensional co-
ordinates such that the Euclidean distance between any
two relays’ coordinates corresponds to the latency be-
tween the pair. By representing pairwise distances us-
ing N virtual coordinates, these systems effectively lin-
earize the information that must be stored and main-
tained by the Information Provider.
Coordinate systems use distributed algorithms in
which each participant periodically measures the dis-
tance between itself and a randomly selected peer. By
comparing the empirical measurement with the Eu-
clidean distance between the two nodes’ coordinates, the
relay can adjust its coordinate either towards (in the case
of over-estimation) or away from (for under-estimation)
the neighbor’s coordinate. Although network distances
cannot be perfectly represented in Euclidean space due
to the existence of triangle inequality violations on the
Internet, virtual coordinate systems efﬁciently estimate
pairwise distances with very low error [6]. Since net-
work coordinate systems require only periodic measure-
ments (on the order of a single ping every 15 seconds),
participation in the system does not incur a signiﬁcant
bandwidth cost.
A Network Coordinate Information Provider main-
tains the current coordinates of the relays in the A3 net-
Figure 1. The A3 architecture.
work. Relays periodically send updates to the Provider
whenever its coordinate changes from its last reported
value (e.g., by more than 10ms).
Unfortunately, the distributed nature of coordinate
systems make them particularly vulnerable to insider
manipulation. Recent studies [16] on Vivaldi have
shown that when 30% of nodes lie about their coordi-
nates, Vivaldi’s accuracy decreases by a factor of ﬁve.
Attacking the coordinate system provides a vector for
an adversary to either prevent high performance rout-
ing or bias routing decisions in favor of relays under
their control. Fortunately, practical coordinate protec-
tion techniques may be applied on top of the embed-
ding system to protect the veracity of advertised coordi-
nates [5, 33, 15, 43, 37]. Often, these coordinate security
techniques rely on spatial and temporal heuristics to spot
false coordinate advertisements [43], utilize a small set
of trusted surveyor nodes [33, 15], or assess coordinate
accuracy using a distributed voting protocol [37]. Net-
work Coordinate Information Providers should employ
such services to ensure that the coordinate information
it provides to A3 nodes is trustworthy.
Relay-Assisted Information Providers Relays have
access to a signiﬁcant number of local performance in-
dicators. For instance, a relay can measure its current
upstream and downstream throughput, processor usage,
and available memory, and estimate its bandwidth ca-
pacity. Such information can be collected and stored in a
Relay-Assisted Information Provider. The CoMon Mon-
itoring Infrastructure [27] that operates on the PlanetLab
testbed [28] is one such example.
As has been pointed out by Øverlier [26] and oth-
ers [40, 3, 36], malicious relays may purposefully at-
tract a large fraction of anonymous trafﬁc by falsely ad-
vertising favorable performance, consequently increas-
ing their view of trafﬁc in the anonymous network. To
mitigate such attacks, Snader and Borisov propose the
use of opportunistic measurements in which relays re-
port the observed throughput of their network peers. The
Provider (or in their case, the directory service) reports
the median of the reported measurements [40]. Sim-
ilar protection schemes are applicable to A3 Informa-
tion Providers. Here, relays report the bandwidth and
responsiveness of peer relays with whom they interact.
Certain metrics (e.g., memory usage) cannot easily be
probed by remote parties, and if reported by Informa-
tion Providers, should be treated with some degree of
skepticism by the relays that make use of them.
Other Potential Information Providers There have
been a number of proposals (e.g.
iPlane [21],
IDMaps [11], OASIS [12], and Meridian [42]) that
attempt to succinctly map the structure of the Inter-
net and provide estimates of latency and (in some
cases) bandwidth between arbitrary Internet hosts.
Such systems have typically been deployed to pro-
vide proximity-based routing [38], neighbor selection in
overlays [7], network-aware overlays, and replica place-
ment in content-distribution networks. However, these
systems are also applicable to anonymity services in
which the initiator is interested in discovering the cost
of routing through a particular relay. By constructing
adapters that access the interfaces to these systems, ini-
tiators can construct relay selection policies that take ad-
vantage of such services. The mechanism for inserting
polled information into the Local Directory Cache is de-
scribed in the following section.
4.2 Other Components of A3
We brieﬂy describe the other components of the A3
system, namely the directory service, local directory
cache, relay selection engine, and forwarding engine.
ApplicationRelay Selection EngineForwarding EngineRelay Selection PolicyPath Instantiation PolicyA3ClientLocalDirectory CacheProxy ServiceInitiatorInternetInformationProviderDirectoryServiceAdapter4.2.1 Directory Service
Node discovery is facilitated by a Directory Service (or
simply Directory) that maintains membership informa-
tion on all the relay nodes currently participating in the
A3 platform. Relays that join the A3 network publish
their network address and public key to the Directory
Service. Initiators periodically poll the Directory to dis-
cover peer nodes that may potentially be used as routers
in anonymous paths.
The Directory Server represents a central point of
failure in the network. If the server becomes unavail-
able,
then initiators cannot discern the network ad-
dresses of available relays. If the Directory is malicious
or becomes compromised, then it can answer queries
with only the identities of misbehaving relays.
Tor reduces this risk by establishing multiple semi-
trusted directory authorities [1]. The authorities period-
ically vote on a summary of the network (that is, the re-
lays that constitute the network), and disseminate signed
consensus documents to Tor routers. The routers further
redistribute this network information to other routers and
to clients. Clients verify signatures on consensus doc-
uments based on certiﬁcates shipped with the Tor bi-
nary. Although our current implementation uses a single
Directory Service, such protections can be straightfor-
wardly applied to A3.
4.2.2 Local Directory Cache
The Local Directory Cache periodically queries and
stores performance data from Information Providers.
The rate at which the cache polls Providers affects both
the freshness of cached data as well as the relay’s com-
munication overhead. The tradeoff between update in-
tervals and bandwidth costs depends on the rate at which
performance characteristics change in the network, and
is explored in more detail in Section 7.
The Local Directory Cache uses adapters to query the
various Information Providers, storing the results in ta-
bles that are accessible by the Relay Selection Engine.
Adapters deﬁne tables using the materialize keyword
as described in Section 3. For example, given the fol-
lowing A3LOG statements,
materialize(tBandwidth, Infinity, Infinity, keys(1)).
materialize(tVivaldiCoordinates, Infinity,
Infinity,keys(1)).
tBandwidth("10.0.0.1", 1000, 500, 3000).
tVivaldiCoordinates("10.0.0.1", [10,-6]).
the Local Directory Cache will create two tables:
tBandwidth and tVivaldiCoordinates. The former
holds the address of a remote node, its upstream band-
width, downstream bandwidth, and bandwidth capacity.
The keys(1) argument speciﬁes that an existing tuple
should be replaced if a new tuple arrives with the same
ﬁrst ﬁeld (the network address). Similarly, the latter ta-
ble stores the coordinates of a remote node. The two
example tBandwidth and tVivaldiCoordinates state-
ments insert data into the respective table. Such state-
ments are executed by the adapter as new data is polled
from Information Providers.
4.2.3 Relay Selection Engine
The Relay Selection Engine provides the ﬂexibility that