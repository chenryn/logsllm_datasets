response ← fetch(url)
ﬁllStorage()
size ← 0
loop
freeByteFromCache()
size ← size + 1
storageResult ← cache.put(response)
if storageResult == True then
return size
end if
end loop
devices. This advancement requires that all the char-
acteristics that are specific to mobile devices are prop-
erly accommodated. For instance, mobile devices travel
along with their users, which means that every now and
then the devices become disconnected, preventing the
user from accessing any web-based content. Recent ad-
vancements in browser design aim to tackle this problem
with a promising API named ServiceWorker [66]. The
core idea behind the SeviceWorker API is to allow web-
sites to gracefully handle offline situations for their users.
For example, a news website might download and tem-
porarily store news articles when users are connected,
allowing them to still access these while being discon-
nected. Note that although we mainly focus on the Ser-
viceWorker API, all attacks can also be applied by using
ApplicationCache [63], the caching mechanism that Ser-
vicerWorker aims to replace.
3.4.1 Per-site quota
For caching operations, the ServiceWorker API provides
a specific set of interfaces, named Cache API, which can
be used to store, retrieve and delete resources. A note-
worthy aspect of the Cache API is that it allows one
to cache any resource, including cross-origin responses.
Furthermore, to limit misuse cases where a malicious
player takes up all available space, the per-site2 storage
is restricted. This restriction is shared among a few other
browser features that allow persistent data storage, for in-
stance localStorage and IndexedDB. The way per-site
quota is applied, is decided by the browser vendor; for
the most popular browsers this is either a fixed value in
the range of 200MB to 2GB, or a percentage - typically
20% - of the global storage quota [22, 42, 32].
For the purpose of exposing the size of resources, hav-
ing full control over the cache, and the fact that this cache
2According to the current specification of
the Storage API,
a site is defined as eTLD+1, meaning foo.example.org and
bar.example.org belong to the same site, whereas foo.host.com
belongs to a different site [70].
USENIX Association  
25th USENIX Security Symposium  453
is limited by a fixed quota, are two very interesting as-
pects. An adversary can directly leverage these two fea-
tures to expose the size of any resource by means of the
pseudo-code listed in Algorithm 1. In the attack, the re-
source is first downloaded using the Fetch API, which
will result in an "opaque" Response. Next, the adver-
sary makes sure that the site’s available storage is filled
up to the quota.
In practice, we found that by storing
large data blobs using the IndexedDB API, the storage
speed approaches the maximum writing speed of the hard
disk, allowing the attacker to reach the quota in a few sec-
onds. In a final step, the adversary will free up one byte
from the cache and attempt to store the response. This
storage attempt will only succeed if sufficient quota is
available, otherwise more bytes should be freed. Even-
tually, the attacker learns the exact size of the resource
by the number of bytes that were freed until the resource
could be stored. Note that the resource only needs to be
downloaded once, resulting in a significant speed-up of
the attack. In our experimental setup, the initial attack
could be executed in less than 20 seconds, and subse-
quent size-exposing attempts were performed in less than
a second as the quota had already been reached.
3.4.2 Global quota
In addition to the storage restrictions of sites, browsers
also enforce a global storage quota to ensure normal sys-
tem operations are not affected. When this global quota
is exceeded, the storage operation will not be canceled,
but instead the storage of the least-recently used site will
be removed. As a result, the two features required to
expose the size of a resource, i.e., full control over the
cache and an indication when the quota is exceeded, are
present. In comparison to the size-exposing attack that
leverages the per-site quota, this vulnerability is consid-
erably harder to successfully exploit: the attacker needs
to reach the global quota limit, which needs to be spread
over multiple sites, and has to take into account that the
global quota can fluctuate as a result of unrelated system
operations. Nevertheless, for the purpose of creating an
improved design, it is important to consider all flaws of
the current system. Furthermore, on systems with a lim-
ited storage capacity, e.g., mobile devices, some of these
restrictions may not apply, increasing the feasibility of
an attack.
A simplified, unoptimized method that can be used to
expose the size of an arbitrary resource is provided in
Algorithm 2. Similar to the per-site quota attack, the
adversary first downloads the resource and temporarily
stores it in a variable. Next, a site is filled with a cer-
tain amount of bytes (storageAmount) which should be
larger than the size of the resource. In a following step,
the adversary will need to fill the complete quota. Since
Algorithm 2 Uncover the size of resources by abusing
the global quota limit
response ← fetch(url)
storageAmount ← 5MB
site0.addBytes(storageAmount)
i ← 1
while !isEvicted(site0) do
storageResult ← sitei.addBytes(1)
if storageResult ! = True then
i ← i + 1
end if
end while
site0.cache.put(response)
remainingBytes ← 0
while !isEvicted(site1) do
site0.addBytes(1)
remainingBytes ← remainingBytes + 1
end while
size ← storageAmount− remainingBytes
for most major browsers, the global quota is set to 50%
of the total available space on the device, and the per-site
quota is set to either a percentage of the global quota or
a fixed size, the adversary will need to divide this over
multiple domains. As soon as the eviction of the first site
is triggered, the adversary knows the exact amount of
freed space, namely storageAmount. Finally, the adver-
sary adds the resource to an empty site and fills it until the
global quota is reached again, which can be observed by
checking for the eviction of the next least-recently used
site, i.e., site1. The size of the resource can then be cal-
culated as the original size of the first site subtracted by
the number bytes required to reach the global quota again
(remainingBytes).
3.4.3 Quota Management API & Storage API
The last attack involving browser storage abuses the
Quota Management API [65], and the similar Storage
API [70]. These APIs aim to give web developers
more insight into their website’s storage properties, more
specifically the number of bytes that have been stored
and the space that is still available. At the time of writing,
the Storage API is still being designed, and will consoli-
date the storage behavior of all browsers into one agreed-
upon standard.
The functionality provided by the Quota Management
API is the direct source of a size-exposing vulnerabil-
ity that is worryingly trivial to exploit. An adversary
can simply request the current storage usage, add a re-
source to the cache, and retrieve the storage usage again.
Since the Quota Management API will return the us-
age in bytes, the exact resource size can be obtained by
subtracting the two usage values. Although the Quota
454  25th USENIX Security Symposium 
USENIX Association
Management API has only been adopted by the Google
Chrome browser, this browser alone accounts for approx-
imately 48% of the market share [56], leaving hundreds
of millions of internet users vulnerable to this highly triv-
ial size-exposing attack vector. Despite our efforts of re-
porting these findings to the Chrome team, all up-to-date
versions of the Google Chrome browser remain allowing
this API to be used by any website, without the user’s
knowledge.
Because the per-site quota is related to the global
quota3, the Quota Management API can also be used to
infer the caching operations of a different website. For
instance, a malicious iframe that is embedded on a web-
site could observe changes in the available quota, and
infer the length of cached resources. This information
could in turn be used to either analyze the interactions of
the user on the website, or disclose private information
based on the length of the cached resources. A similar
attack scenario is discussed in more detail in Section 4.4.
Another interesting case occurs when making the obser-
vation that the per-site quota is also related to the total
free disk space. The byproduct of this behavior is that an
adversary can also observe the disk operations of other,
possibly security-sensitive, processes. As this issue is
unrelated to size-exposing techniques, we do not explore
this vulnerability in more detail.
The functionalities provided by the Quota Manage-
ment API are directly responsible for the vulnerabilities
discussed in this section. It is unclear why this API was
developed without taking into account potential security
and privacy implications. In essence, these findings serve
as a strong indicator that new browser features should
be thoroughly reviewed for security and privacy flaws.
Since the Storage API provides the same functionality as
the Quota Management API, the same issues arise there
as well. At the time of writing, the Storage Standard de-
viates from the Quota Management API in the sense that
it states that a “rough estimate” should be returned. Be-
cause the term “rough estimate” is not formally defined,
implementations of this specification are likely to still be
vulnerable to statistical attacks, as the quota limit can
easily be requested thousands of times. In Section 5.1
we propose a new API design that protects against all
browser-based size-exposing techniques we discussed in
this paper.
4 Real-world Consequences
In contrast to prior work on size-exposing techniques,
which is mainly focused on passive network observa-
tion, the attacks presented in this paper leverage the abil-
3The per-site quota is 20% of the global quota in Google Chrome;
for Firefox this is the case as well when the disk space is less than
20GB.
ity to request arbitrarily chosen resources in the victim’s
browser. To provide more insight into the consequences
and potential attack scenarios, we explore a selection of
real-world cases where one of the size-exposing tech-
niques can be used to extract private and sensitive in-
formation from the victim. The list of attacks that are
discussed, is by no means the exclusive list of possible
targets. Instead, we made a selection of attack scenarios
to provide a variety in methodology, type of disclosed
information, and category of web service.
Ethical Considerations To evaluate the severity and
impact of size-exposing techniques on internet users, it
cannot be avoided to evaluate these attacks on real-world
services. To prevent any nefarious consequences of this
evaluation, all attacks were manually tested, and were
performed exclusively against our own accounts. As a
result, from the perspective of the tested services our
analysis only generated a restricted amount of legitimate
traffic. Moreover, users of the analyzed websites were
not directly involved in our attacks. For the quantitative
case-studies, we only obtained publicly available infor-
mation, and present it in anonymized form. Given the
above-mentioned precautions, we believe our evaluation
of real-world services did not have any adverse effects
on the tested subjects.
4.1 User Identification
Virtually every online social network provides its users
with their own profile page. Depending on the user’s
privacy settings, these profile pages typically are com-
pletely or partially available to anyone. In the attack sce-
nario where the adversary is interested in learning the
identity of the victim, the adversary first collects the pub-
licly available data from (a subset of) the users of the
social network. Later, during the actual size-exposing at-
tack, he tries to associate the data obtained from the vic-
tim to a single entry from the public data, allowing him
to expose the victim’s identity. To evaluate the feasibil-
ity in a real-world environment, we exemplify the attack
scenario on Twitter, one of the largest social networks.
By default, the profile of each Twitter user is public,
and contains information on the latest tweets that were
created by the user, the list of followers and followees,
the tweets that were “liked” by the user, and the lists
he/she follows and is a member of. Except for the user’s
tweets, each type of information can be accessed by a
link that is shared by all Twitter users, e.g., the page
located at https://twitter.com/followers lists the
last 18 accounts that follow the user. For each follower,
the name, account name and short biography is shown.
The main assumption in this attack scenario is that
the combined length of all parts that constitute to the
USENIX Association  
25th USENIX Security Symposium  455
resource, i.e., the names, account names and bios of
the last 18 followers, is relatively unique. To validate
this assumption, we performed an experiment that re-
flects an adversary’s actions in an actual attack sce-
nario. For this experiment, we obtained publicly avail-
able information of 500,000 users, which were selected
at random from the directory of public profiles provided
by Twitter4. More specifically, we downloaded the re-
sources located at /following, /followers, /likes,
/lists and /memberships, and recorded the associated
resource size, both with and without gzip compression.
Next, we grouped together Twitter accounts that share
the same resource length, e.g., if the /following re-
source is 281026 bytes for only two users, these users
form a group of size 2. In Figure 4 we show the per-
centage of Twitter accounts for all group sizes, for the
compressed and uncompressed resource size. Note that
a logarithmic scale is used for the percentage of Twit-
ter accounts on the y-axis. This graph clearly shows that
when the size of multiple resources is combined, the ma-
jority of Twitter accounts can be uniquely identified. By
exposing the size of the uncompressed /following and
/followers resources, 89.66% of the 500,000 Twit-
ter accounts can be uniquely identified. When the size
of all five resources is known, the identity of 97.62%
of the Twitter accounts can immediately be uncovered.
The graph also clearly shows that when gzip compres-
sion is applied, the group sizes of individual resources
becomes larger, which is most likely due to the reduc-
tion in entropy of resource sizes. Nevertheless, when
the size of multiple compressed resources are combined,
a uniqueness comparable to the size of uncompressed
resources is achieved: 81.69% Twitter accounts can be
uniquely identified when the size of the /following
and /followers resources is combined; for all five re-
sources, this is 99.96%. The most likely explanation for
this is that in case a resource is virtually empty, i.e., the
account name is the only dynamic part of the resource,
not only the length but also the content of the account
name is reflected in the compressed resource size.
Although the viability of this attack was only evalu-
ated on a subset of all Twitter accounts5, this experi-
ment does suggest that adversaries can immensely nar-
row down the number of possible candidates for the
user’s identity by knowing the size of just five resources.
Furthermore, various techniques exist that can uniquely
identify a user among a limited set of accounts [33, 26],
making user-identification by exposing the size of re-
sources well within the reach of a moderately motivated
attacker.
4https://twitter.com/i/directory
5Twitter has approximately 320 million active accounts.
4.2 Revealing Private Information
Next to revealing the identity of a web user, adversaries
may also be interested in learning private information.
A particular type of information that, in general, is con-
sidered highly sensitive, is information concerning med-
ical conditions. To evaluate whether our novel size-
exposing techniques can be used to also disclose this type
of data, we explored the performance of such techniques
on WebMD, one of the leading health information ser-
vices websites. One of the features provided by WebMD
is “Health Record”, a web service that allows users to
organize their personal health records6. More precisely,
users can add, and keep track of, their medical condi-
tions, medications, allergies, etc. For each entry, the user
can choose among an exhaustive list of terms. For in-
stance, there are 4,105 different medical conditions that
can be selected.
At any point in time, users can download their own
medical report, either as automatically generated PDF or
in plain text format.
It should be noted that the types
of medical records that are shown in this report is spec-
ified by the user (or attacker), and that the PDF is sent
without compression, whereas the textual report is served
with gzip compression. Although there is some variety
in the length of the possible terms, it is insufficient for
an adversary to determine which medical conditions the
user suffers from: on average, a certain length is shared
among 124.59 possible medical conditions. However,
if the adversary can obtain the resource size both with
and without compression, this can significantly improve
his attack: in this case, the group size can be limited to
35.50 on average. This can be achieved by various meth-
ods, e.g., by obtaining the length from two resources that
share the same content, where one is served with com-
pression and the other without, or by tricking the server
in sending the resource without compression7, or even by
combining the browser-based attacks with the network-
based attacks. In case the sensitive content is present on
multiple compressed resources (in this case, this can be
triggered by varying the types of medical records that are
reported), the group size can be reduced even further. In