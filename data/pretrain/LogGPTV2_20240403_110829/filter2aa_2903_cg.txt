（High-Level Shading Language，HLSL）。与此对应，2002年，
OpenGL引入了汇编语言形式的着色器语言。2004年，高层语言形式的
OpenGL着色器语言（GLSL）发布。HLSL和GLSL至今仍在图形领域广
泛应用。
应通用计算的需要，HLSL和GLSL后来都曾加入支持通用计算的计
算着色器（compute shader）。在2009年发布的DirectX 11中，微软还特
别包含了一系列API来特别支持计算任务，称为Direct Compute。但是着
色器就是着色器，这个名字就注定了它难以承担通用计算这个大任务，
无法流行起来。
8.5.2 Brook和CUDA
斯坦福大学计算机图形实验室（Stanford Computer Graphics
Laboratory）为现代GPU的发展做出了巨大的贡献，不但培养出了很多
顶尖人才，而且孕育了多个重要项目，其中之一就是著名的Brook项
目。如果把时光倒流回2001年10月的斯坦福大学，那里的流语言
（Streaming Languages）课题组正在设计一门新的流式编程语言，名叫
Brook。10月8日，一个名叫Ian Buck的在读博士生起草出了0.1版本的
Brook语言规约，给项目组审查讨论。项目组广泛研究了当时的其他并
行编程技术，包括Stream C、C*、CILK、Fortran M等。当时项目组的
成员有Mark Horowitz、Pat Hanrahan、Bill Mark、Ian Buck、Bill Dally、
Ben Serebrin、Ujval Kapasi和Lance Hammond。
Brook语言是基于C语言进行的扩展，目的是让用户可以从熟悉的编
程语言自然过渡到并行编程。
到了2003年，Brook语言的讨论和定义应该基本完成了。一个新的
名为BrookGPU（Brook for GPU）的项目开始[7]，目的是为Brook语言开
发在GPU上运行所需的编译器和运行时（库）。这个项目的带头人就是
起草Brook语言规约的Ian Buck。整个项目组的成员有Ian Buck、Tim
Foley、Daniel Horn、Jeremy Sugerman、Pat Hanrahan、Mike Houston和
Kayvon Fatahalian。
在上面的名单里，Pat Hanrahan是导师，Mike Houston毕业后加入
AMD，参与了AMD多款GPU的设计，曾经是AMD的院士架构师，其他
几个人也都成为GPU和并行计算领域的名人。
在2004年的SIGGRAPH大会上，Ian Buck发表了题为“Brook for
GPUs:Stream Computing on Graphics Hardware”的演讲，公开介绍了
BrookGPU项目。
在Ian Buck的演讲稿的最后一页中有个征集合作的提示。我们不知
道有多少家公司当年曾经对Brook项目感兴趣，但可以确定的是ATI和
Nvidia都在其列。因为ATI曾经推出基于Brook的ATI Brook+技术，而
Nivida的做法更加彻底，2004年11月，直接把Ian Buck雇为自己的员
工。
Ian Buck加入Nvidia时，前一年加入的约翰·尼可尔斯应该正在思考
如何改变GPU的内部设计，使用新的通用核心来取代固定的硬件流水
线，让其更适合并行计算。作者认为两个人见面时一定有志同道合、相
见恨晚的感觉。2006年，使用通用核心思想重新设计的G80 GPU问世。
2007年，基于Brook的CUDA技术推出。高瞻远瞩的硬件，配上优雅别
致的软件，二者相辅相成，共同开创了GPGPU的康庄大道。
CUDA本来是Compute Unified Device Architecture的缩写，但后来
Nvidia取消了这个全称。CUDA就是CUDA，不需要解释。CUDA项目
所取得的成功众所周知，详细情况将在下一章介绍。
8.5.3 OpenCL
CUDA是Nvidia私有的，竞争对手不可以使用。其他公司怎么办
呢？要么开发自己的，要么选择开放的标准。
上文曾经提到，微软在DirectX 11中曾高调推出支持通用计算的
Direct Compute技术。但是Direct Compute基于蹩脚的Shader语言，难以
推广。但是微软没有放弃，大约在2012年，又推出了基于C++语言的
C++ AMP（Accelerated Massive Parallelism）。
2007年前后，苹果公司也在设计新的并行编程技术。但是在正式推
出前选择了把它交给著名的开放标准制定组织Khronos Group。2008年
Khronos Group基于苹果公司所做的工作推出了1.0版本的OpenCL（Open
Computing Language）标准。
OpenCL也是基于C语言进行的扩展，但是与CUDA相比，相差悬
殊。CUDA和OpenCL的核心任务都是从CPU上给GPU编程。如何解决
CPU代码和GPU代码之间的过渡是关键之关键。CUDA比较巧妙地掩盖
了很多烦琐的细节，让代码自然过渡，看起来很优雅。而OpenCL则简
单粗暴。以关键的发起调用为例，在OpenCL中要像下面这样一个一个
地设置参数。
clSetKernelArg(kernel, 0, sizeof(cl_mem), (void *)&memobjs[0]);
clSetKernelArg(kernel, 1, sizeof(cl_mem), (void *)&memobjs[1]);
clSetKernelArg(kernel, 2, sizeof(float)*(local_work_size[0] + 1) * 16, NUL
L);
clSetKernelArg(kernel, 3, sizeof(float)*(local_work_size[0] + 1) * 16, NUL
L);
然后，再调用一个名字拗口、参数非常多的排队函数。
clEnqueueNDRangeKernel(queue, kernel, 1, NULL, global_work_size, local_wor
k_size, 0, NULL, NULL);
而CUDA只要一行。
mykernel>>(para1, para2, para3, para4);
二者相比，高下自见。一个简单，一个笨拙，一个是高山流水，一
个是下里巴人。后面将在介绍英特尔GPU时进一步介绍OpenCL。
在CUDA和OpenCL中，都把在GPU中执行的计算函数称为算核
（compute kernel），有时也简称核（kernel），本书统一将其称为算
核。
8.6 调试设施
因为并行度的跃升，GPU程序比CPU程序更加复杂和难以驾驭，所
以需要更强大的调试设施。GPU硬件和软件模型的设计者大多都认识到
了这一点，不仅继承了CPU端的成熟经验，还有创新和发展。本节先简
要介绍目前GPU调试的常见设施，后面各章将根据具体的软硬件平台分
别展开介绍。
8.6.1 输出调试信息
在CUDA和OpenCL中都定义了printf函数，让运行在GPU上的算核
函数可以很方便地输出各种调试信息。GPU版本的函数原型与标准C一
样，但是某些格式符号可能略有不同。
到目前为止，算核函数不能直接显示内容到屏幕，所以GPU上的
printf实现一般都先把信息写到一个内存缓冲区，然后再让CPU端的代码
从这个缓冲区读出信息并显示出来，如图8-10所示。
图8-10 从GPU上输出调试信息
以CUDA为例，算核函数调用printf时会把要输出的信息写到一个先
进先出（FIFO）的内存缓冲区中，格式模板和动态信息是分别存放的。
CPU端的代码启动算核函数后，一般会调用
cudaDeviceSynchronize()这样的同步函数等待GPU的计算结果。在同步
函数中，会监视FIFO内存区的变化，一旦发现新信息，便将模板信息和
动态信息合成在一起，然后输出到控制台窗口。
可以通过CUDA的如下两个函数分别获取和改变FIFO缓冲区的大
小。
cudaDeviceGetLimit(size_t* size,cudaLimitPrintfFifoSize)
cudaDeviceSetLimit(cudaLimitPrintfFifoSize, size_t size)
在OpenCL中，printf函数的实现是与编译器和运行时相关的，在英
特尔开源的Beignet编译器中，也使用与图8-10类似的内存缓冲区方法。
当一个算核完成或者CPU端调用clFinish等函数时，保存在内存区中的调
试信息会显示出来。
8.6.2 发布断点
在调试GPU程序时，用户可能希望在GPU真正开始执行自己的代码
前就中断下来，仿佛一开始执行算核函数就遇到断点一样，这样的中断
与CPU调试时的初始断点类似，本书将其称为发布断点（launch
breakpoint）。
例如，在CUDA GDB（见第9章）中，可以通过set cuda
break_on_launch命令来启用和禁止发布断点（参数all表示启用，none表
示禁止）。
CUDA GDB的帮助手册把发布断点称为算核入口断点（kernel entry
breakpoint）。
8.6.3 其他断点
当然，今天的大多数GPU都支持普通的软件断点。Nvidia GPU中有
专门的软件断点指令，英特尔GPU中每一条指令的操作码部分都有一个
调试控制位，一旦启用，这个指令便具有了断点指令的效果。
英特尔GPU还支持操作码匹配断点，可以针对某一种指令操作来设
置断点。这将在第11章详细介绍。
8.6.4 单步执行
今天的多种GPU调试器都支持单步执行GPU上的程序，可以在高级
语言级别单步，也可以在汇编语言级别单步。在CUDA中，每次单步
时，整个WARP的所有线程都以同样的步调执行一步。
8.6.5 观察程序状态
在CUDA GDB等工具中，可以观察GPU程序的各类变量，包括内置
变量等，也可以直接观察原始的GPU内存。
GPU的寄存器数量通常都远远超过CPU，在CUDA GDB和英特尔的
OpenCL调试工具（GT调试器，详见第11章）中，也可以观察GPU寄存
器。
GPU的汇编指令和机器码对很多程序员来说很神秘，对于Nvidia
GPU和SoC GPU等不公开指令集的GPU来说，更是难得一见。在CUDA
GDB中，通过反汇编窗口，既可以观察中间指令身份的PTX指令，也可
以观察GPU硬件真正使用的机器指令。在GT调试器中，也可以观察反
汇编。
8.7 本章小结
本章从GPU的简要历史讲起，追溯了GPU的发展历史，特别强调了
对GPU领域的诸多问题都有根本影响的设备身份问题。因为设备身份，
今天必须从CPU端“喂程序”给GPU。这种“喂程序”的工作模式带来了一
系列复杂的问题。首先需要在GPU与CPU之间建立高速的通信渠道和通
信接口，其次需要在CPU端建立复杂的“管理团队”来对GPU实施“远
程”管理。当然，“喂”模式也增大了编写GPU程序的复杂度。要编写两
种代码，在程序中不仅要编写CPU端的代码，还要编写GPU端的代码。
在写程序时，要考虑两个地址空间，很多内存要分配两次，一次分配在
CPU端，一次分配在GPU端。高复杂度增加了对GPU开发者的要求，
GPU程序的开发和调试技术还处于起步阶段，发展的空间还很大。
参考资料
[1] The 10 most important graphics cards in PC history .
[2] NVIDIA Launches the World's First Graphics Processing Unit:
GeForce 256 .
[3] Technical Brief: NVIDIA GeForce 8800 GPU Architecture
Overview.
[4] Nvidia Tesla: A UNIFIED GRAPHICS AND COMPUTING
ARCHITECTURE.
[5] John Nickolls Obituary.
[6] Shading Language (RSL) .
[7] BrookGPU.
第9章 Nvidia GPU及其调试设施
虽然很早就有GPU这个名字，但现代意义的GPU离不开Nvidia[1]
[2]。从某种程度上讲，Nvidia成就了GPU，GPU也成就了Nvidia。正因
为如此，讨论GPU不能不谈到Nvidia和Nvidia GPU。本章分三部分。前
面五节是基础，首先介绍Nvidia及其GPU的概况，然后介绍Nvidia GPU
的微架构和指令集，包括硬件相关的SASS指令集和跨硬件兼容的PTX
指令集，接着介绍Nvidia GPU的编程模型和CUDA技术。中间两节介绍
与调试关系密切的异常和陷阱机制，以及系统调用。后面几节涉及调试
设施，首先介绍断点指令和数据断点，然后介绍调试符号和CUDA
GDB，最后介绍用于扩展调试功能的CUDA调试器API。
9.1 概要
Nvidia公司成立于1993年4月，主要创始人为出生于中国台南的黄
仁勋（Jensen Huang）。创建Nvidia公司之前，他曾在AMD和LSI公司工
作。另两位创始人分别叫Chris Malachowsky和Curtis Priem，都曾在Sun
公司工作。三位创始人在电子和芯片设计领域有很强的技术背景。
9.1.1 一套微架构
2006年推出的G80在Nvidia GPU历史上具有重要意义，它开创的以
通用流处理器为主导的统一设计思想代表了现代GPU的发展方向，为
Nvidia在GPU领域的领导地位打下了坚实的基础[3]。此后十几年中，
Nvidia的GPU基本沿着G80所开创的技术路线发展，以大约两年推出一
种微架构的速度优化和改进。Nvidia的微架构都以科学家的名字命名，
G80的微架构称为特斯拉（Tesla）。特斯拉之后的微架构名字分别为费
米（Fermi）、开普勒（Kepler）、麦斯威尔（Maxwell）、帕斯卡
（Pascal）和伏特（Volta）。下一节将分别介绍这些微架构。
9.1.2 三条产品线
Nvidia的GPU产品分为三条产品线，分别是面向PC市场的GeForce
产品线、针对工作站市场的Quadro产品线和针对高性能计算（HPC）的
Tesla产品线。
比如前面介绍的G80就是基于特斯拉微架构的，基于这个微架构的
GPU还有G84、G86、G92、G94、G96、G98等。其中，G84便是Quadro
产品线中的Quadro FX 370显卡产品的GPU[4]。而特斯拉产品线中的
Tesla S870虽然使用的也是G80 GPU，但是把4个G80组合在一起[5]。
值得解释的是，可能是特斯拉这个名字在Nvidia太受欢迎了，G80
的微架构叫特斯拉，针对HPC的产品线也叫特斯拉。在同一个公司里，
出现这样的情况是不应该的，有点撞衫的感觉，约翰先生在一次演讲时
也承认这有点搞笑。不过这也无伤大雅，没有阻碍Nvidia GPU的流行。
9.1.3 封闭