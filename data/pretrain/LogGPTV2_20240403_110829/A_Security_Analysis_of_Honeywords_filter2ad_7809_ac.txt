implicitly made (or missed) in previous studies [7], [14], [21].
Other attackers. As discussed in [21], other valid threats
facing honeywords include attacking the honeychecker sys-
tem, denial-of-service (DoS) attacks that game the honeyword
system and intersection attacks where an attacker exploits user
passwords reused across different systems. Since these attacks
have little relevance to the strength of a honeyword-generation
method, and thus they are beyond our scope.
C. Evaluation metrics
Juels and Rivest [21] proposed a notion of ϵ-ﬂat to measure
the security of a honeyword generation method. ϵ-ﬂat denotes
the maximum success rate ϵ that, when given Ui’s k sweet-
words, the distinguishing attacker A can gain by submitting
only one online guess to S. However, this metric is inadequate
for measuring a method’s security level when A is allowed
to make more than one online guess per user (e.g., when
T1 > 1). In addition, ϵ-ﬂat falls short of reﬂecting the system’s
“low-hanging fruits” produced by a method, i.e. these most
vulnerable honeywords that can be easily distinguished.
Accordingly, we propose two new metrics: ﬂatness graph
and success-number graph. These two metrics (see Fig. 2)
4
desired number of positions to tweak. Juels and Rivest [21]
mainly discussed the “tweaking by tail” version, and we also
focus on this version. Each character in the last t positions of
PWi is replaced by a randomly-chosen character of the same
type: a digit is replaced by a digit, a letter by a letter, and a
special character by a special character. For instance, if PWi
is trustno1 and t = 3, then the sweetword list SWi might
be trustyp0, trustmi7, trustno1, trustme5, etc.
Modeling syntax. Their second method,
inspired by [4],
into tokens of consecutive characters of
is to parse PWi
the corresponding syntax, and
the same type and extract
then honeywords are generated by replacing tokens with
randomly selected values that match the syntax. For instance,
the syntax L7D1 can be abstracted from trustno1, and then
honeywords, such as dfdphus3, letmein4 and kebrton9
can be generated.
Hybrid. Their third method is to combine the tweaking-tail
and modelling syntax methods, aiming to gain advantages from
both methods. More specially, when given Ui’s password PWi,
the hybrid method ﬁrst employs the modeling syntax approach
to extract PWi’s syntax and produces a seed sweetwords
(including PWi), and then generates b − 1 honeywords by
tweaking each seed sweetword, where a · b ≥ k. Finally,
k− 1 honeywords except for PWi are randomly selected from
these a · b − 1 honeywords. It is recommended that a≈b≈√
k.
For instance, assume k=20, and a=4, b=5; the syntax L7D1
can be abstracted from trustno1, and 3 seed sweetwords
dfdphus3, letmein4 and kebrton9 are generated. Then,
4 new honeywords are produced for each of the 4 seed
sweetwords, resulting in 20 sweetwords for Ui.
Simple model. Their fourth method is to use real password
samples as an aid to generate honeywords (see Appendix of
[21]). First, a list L is built by combining large-scale real-
life passwords and 8% random passwords of varying lengths.
Then, a random element w = w1w2 ··· wd of length d is picked
from L, and a honeyword c with char sequence w1c2 ··· cd is
generated heuristically. More speciﬁcally, for j = 2, 3,··· d,
• With probability 10%, replace w by a random element
• With probability 40%, replace w by a random element
• With probability 50%, set cj = wj.
For fair evaluation, when implementing Juels-Rivest’s meth-
in L satisfying cj−1 = wj−1, and set cj = wj;
in L, and then set cj = wj;
ods, we strictly follow the speciﬁcations in [21].
Remark 1. We note that in a passing comment, Juels and
Rivest mention the possibility of using probabilistic password
models (e.g., Weir et al.’s PCFG [32]) to build honeywords:
“see Weir et al. [32] for a presentation of an interesting alterna-
tive model for passwords, based on probabilistic context-free
grammars” [21]. However, due to the Zipf-distribution nature
of passwords [28], generating decoy passwords (according to a
probabilistic password model or not) that are equally probable
to the user’s real password is inherently impossible (see Sec.
VI). Moreover, each password model has its own inherent
weaknesses. Other challenges like sparsity also arise. They
all make the use of probabilistic models not straightforward
but rather challenging, Juels and Rivest explicitly leave it as
an open question (see Section 9 of [21]): “can the password
(a) Metric 1: Flatness graph.
(b) Metric 2: Success-number graph.
Fig. 2. Two metrics for measuring the resistance of a honeyword generation
method against
the distinguishing attacker. Here methods A and B are
conceptual. The closer to the perfect line, the better a method will be.
measure a method’s resistance against the honeyword distin-
guishing attacker in the average and worse-case point of view.
Flatness graph plots the probability of distinguishing the real
password vs. the number of sweetword login attempts per user.
As shown in Fig. 2(a), a point (x, y) on a curve indicates
that the real password is guessed with a probability y in the
ﬁrst x attempts, where x≤k. In reality, it also requires that
x≤T1 (e.g., T1=1 or 3). Clearly, the data point (x=1, y) on
our ﬂatness curve corresponds to the ϵ-ﬂat metric introduced
in [21], i.e., ϵ=y|x=1. A ﬂatness graph provides a view of the
average resistance against a distinguishing attacker with varied
guess numbers per user all the way to k.
Success-number graph measures to what extent a method
will produce vulnerable “low-hanging fruits” for A. This
graph plots the total number of successful login attempts (i.e.,
login with a real password) vs. the total number of failed
login attempts (i.e., login with a honeyword). A point (x, y)
on a curve in Fig. 2(b) indicates that y real passwords are
successfully distinguished from the system before the x-th
honeyword login attempt occurs, where x ≤ T2 (e.g., T2=104).
k -ﬂat method is perfect, since it produces no “low-hanging
A 1
fruits” and each of the k sweetwords per user is of the same
probability to be a real password.
III. TRAWLING GUESSING ATTACKS
The stated security goal for Juels-Rivest’s four primary
honeyword-generation methods is that, when given Ui’s k
sweetwords, the distinguishing attacker A can gain a maximum
success rate about 1
k by making an online query to S (see Table
1 of [21]). However, by using large-scale real-world datasets
as listed in Table I, we now show that these methods all fall
short of its intended security goal. We ﬁrst provide a review of
Juels-Rivest’s methods, and then show that their methods fail
to achieve the expected security (i.e., 1
k -ﬂat) under the weak
assumptions of the attacker (i.e., a type-A1 attacker).
A. Review of Juels-Rivest’s methods
Juels-Rivest’s four main methods (see Table 1 of [21]) are all
based on the random-replacement approach: each honeyword
is produced by randomly replace parts (or whole) of the real
password. Particularly, the ﬁrst three are real-password related
ones, i.e., the k− 1 honeywords depend on the structure of the
real password PWi.
Tweaking by tail. Their ﬁrst method is to “tweak” the selected
character positions of the real password PWi
to generate
the k − 1 honeywords. Let t (e.g., t = 2 or 3) denote the
5
models underlying cracking algorithms (e.g., [32]) be easily
adapted for use?” In Sec. III-E, we will provide a negative
answer to this question.
Remark 2. Also note that, besides the above four methods,
there is another legacy-UI method called “Chafﬁng with tough
nuts”. It needs to be used together with other methods, and
aims to generate some tough honeywords that are much harder
to crack to render A’s ofﬂine guessing work more challenging.
However, as pointed out by Erguler [14], the attacker A cares
cost-effectiveness: if the cracking time exceeds her acceptable
time-threshold, A would stop cracking these tough nuts and
simply avoid using these “tough nuts”, because common user
rarely use “tough nuts”. In this regard, introducing “tough
nuts” as honeywords would make the number of a user’s
effective honeywords less than k-1 and thus actually decreases
security. Hence, we do not consider it.
B. Two attacking strategies
We now present two simple yet practical honeyword dis-
tinguishing strategies (with varying tunings) against Juels-
Rivest’s methods. They work on real-world password datasets,
inherently different from the existing heuristic strategy (see
[7], [14], [21]) that is mainly based on some speciﬁc counter-
example passwords. Essentially, they make use of the fact that
user-chosen passwords follow the Zipf’s law [28], and ranks
the sweetwords based on some known probability distribution,
either normalized within a user or not. The probability distri-
bution can be calculated from a leaked password dataset, or
based on a probabilistic password model such as Markov [24].
For fair evaluation, here we consider the attacker capabilities
of A1, i.e., a basic attacker (see Sec. II-B). In brief, A1 has got
the password hash ﬁle, knows all cryptographic algorithms and
public info, but does not exploit user PII. Such an assumption
of attacker capabilities is in line with Juels-Rivest’s work [21]
as well as the other previous studies [7], [14].
Top-PW attack. This attack is simple yet effective. The
distinguishing attacker A is faced with a password ﬁle F of
n lists {SW1, SW2, ··· , SWn}, where each list consists of a
set k of distinct sweetwords. Given such a multi-set of n · k
sweetwords, A’s aim is to ﬁnd as many real passwords as
possible before making T2 (e.g., 104) failed honeyword login
attempts. Note that A can only make at most T1 (e.g., 1,
3, or 10) honeyword logins against each account. A simply
tries these n· k sweetwords in decreasing order of probability,
where the probability of each sweetword swi,j (1 ≤ i ≤ n
and 1 ≤ j ≤ k) comes directly from a known probability
distribution PD (e.g., a leaked dataset D like the 32 million
Rockyou) as follows:
Step 1. ∀swi,j ∈ F ,
Step 2. ∀swi,j ∈ F , if swi,j ̸∈ D, set Pr(swi,j) = 0.
We call PD(·) the List password model, where ∀x∈ D,
PD(x) = Count(x)
, where Count(x) means the occurrence
number of password x and |D| is the size of the multi-set D.
We empirically evaluate this attack against the four methods
in [21]. More speciﬁcally, we randomly split the Dodonew
dataset into two parts of equal size, resulting in: 8.129 million
if swi,j ∈ D, set Pr(swi,j) =
PD(swi,j);
|D|
Algorithm 1: Distinguish the real passwords from a given
password ﬁle F that is consisted of n lists of sweetwords.
Input: n sweetword lists fSW1, SW2, (cid:1) (cid:1) (cid:1) , SWng, one list per user;
Output: A vector V shows the success-number graph.
the threshold T1 of honeyword login attempts per user; the
threshold T2 of honeyword login attempts for the system.
ranked by the conditional probability of sweetwords. */
1 Initialize the vector V to be ∅;
2 Initialize the priority queue crackQueue to be ∅; /* crackQueue is
3 numF ailure = 0, numSucess = 0;
4 for i = 1 to n do
(p, sw) = getSweetword(SWi);
/* according to the speciﬁed
5
attacking strategy, get the sweetword sw with the highest priority p
normalized among all the un-attempted sweetwords in SWi. */
crackQueue.Insert((p, SWi, sw));
6
7 while numF ailure < T2 and !crackQueue.empty() do
8
9
10
11
(p, SWj , sw) = crackQueue.getF irst();
crackQueue.removeF irst();
if SWj .numF ailure < T1 then
success=Login(SWj .id, sw);/*use SWj .id as user name
and sw as password to login as user Uj. */
if success then
else
numSuccess++;
SWj .numF ailure++, numF ailure++;
V.Insert((numF ailure, numSuccess));
(p, sw) = getSweetword(SWj );
crackQueue.Insert((p, SWj , sw));
12
13
14
15
16
17
18
19 return V;
Dodonew-tr and 8.129 million Dodonew-ts. For each method
in [21], k − 1 honeywords are produced for each of the
password in Dodonew-ts, while PD of the Top-PW attack
comes from Dodonew-tr. As shown in Figs. 3(a)∼3(d), the
Top-PW attack tells apart at least 615,664 passwords from
the 8,129,445 Dodonew-ts accounts protected by any of the
four methods in [21]. However, according to Juels-Rivest’s
original security goal, an attacker should distinguish only about
526(=T2/(k− 1)) real passwords from Dodonew-ts. That is, in
terms of the success-number metric, their methods are weaker
than the claimed security by a factor of at least 1170.
We also employ the Top-PW attacking strategy to evaluate
the ﬂatness of the four methods in [21]. In brief, when given
a list SWi of k sweetwords for user Ui, A simply tries
these k sweetwords in decreasing order of probability, where
each sweetword’s probability comes directly from a known
probability distribution PD as above. Fig. 3(e) shows that all
methods are 0.35+-ﬂat. In other words, there is over 35% of
success rate in telling part the real password from the k=20
sweetwords with just one guess. See more details in Sec. III-D.
Evidently, there is a large gap between these four methods and
the expected (perfect) method.
Though this attack is effective, it is subject to an obvious
defect: when identifying the next sweetword swi,j
to be
guessed, this identifying process bears little relevance to the
nature of the underlying sweetword list to which swi,j belongs.
For example, assume there are two sweetword lists left: SWi
and SWi+1, where (1) Pr(swi,j)=0.030 and all the other 19
sweetwords in SWi are with a equal probability 0.029; (2)
Pr(swi+1,j)=0.028, and all the other 19 sweetwords in SWi+1
are with a equal probability 0.001. Then, which sweetword
shall be tried next, swi,j or swi+1,j? It is more likely that
swi+1,j will be the real password for SWi+1 than swi,j
for SWi. Thus, it is better to ﬁrst try swi+1,j against user
Ui+1. This intuition gives rise to the following more effective
attacking strategy.
6
Normalized top-PW attack. The essential difference between
this strategy and the above one is that, A now tries these