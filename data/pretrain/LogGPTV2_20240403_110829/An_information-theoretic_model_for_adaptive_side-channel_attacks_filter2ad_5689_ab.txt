B (cid:18) P that contains k.
Conversely, given a set of partitions P, one can easily de(cid:12)-
ne a (non-unique) function f , with Pf = P. In this sense,
the partition-based and the functional viewpoints are equi-
valent. Formalizing f in terms of Pf only abstracts from
the concrete values that f takes, which are irrelevant for
assessing the information that is revealed by f . For clarity
of presentation, we will subsequently focus on the partition-
based viewpoint.
For this, we need to introduce additional notation. We
say that a partition Q of a set K re(cid:12)nes a partition P of
K (denoted by Q v P ) i(cid:11) every block of Q is contained in
some block of P . For A (cid:18) K, we de(cid:12)ne the restriction of P
to A as fA \ B j B 2 P g and denote it by A \ P . Clearly,
A \ P is a partition of A. For partitions P and Q, we de(cid:12)ne
P \ Q as the partition fA \ B j A 2 P; B 2 Qg. Note that
P \ Q v P and P \ Q v Q. We are now ready to generalize
from single attack steps to entire attacks.
Formalizing Attack Strategies.
To model adaptive attacks, we proceed as follows. We as-
sume a (cid:12)xed set of partitions P of K and we use a tree
whose nodes are labeled with subsets of K to formalize the
attacker’s decisions with respect to his possible observations.
In this tree, an attack step is represented by a node together
with its children. The label A of the parent node is the set
of keys that are coherent with the attacker’s observation at
f1; 2; 3; 4g
@@
(cid:0)(cid:0)
f1; 2g
@@(cid:0)(cid:0)
f3; 4g
@@(cid:0)(cid:0)
f1g
f2g
f3g
f4g
Figure 1: Attack Strategy
this point; hence it represents the basis for the attacker’s
decision. The labels of the children form a partition of A.
We require that this partition is of the form A \ P for some
P 2 P. This corresponds to the attacker’s choice of a que-
ry. By observing the system’s response, the attacker learns
which successor’s block actually contains the key. This no-
de is the starting point for subsequent attack steps. Trees
of this form represent attack strategies, which we formalize
below.
Example 4. Let K = f1; 2; 3; 4g and consider the set of
partitions P = fff1g; f2; 3; 4gg, ff1; 2g; f3; 4gg, ff1; 2; 3g;
f4ggg of K. Suppose the attacker picks ff1; 2g; f3; 4gg as
his (cid:12)rst query. If the system responds with f1; 2g, the at-
tacker chooses ff1g; f2; 3; 4gg as his next query. Otherwise,
he chooses ff1; 2; 3g; f4gg. In this way, he can determine
any key in two steps. The corresponding attack strategy is
depicted in Figure 1.
Formally, let T = (V; E) be a tree with nodes V and edges
E (cid:18) V (cid:2) V . For every node v 2 V , we denote the set of its
successors as succ(v) = fw j (v; w) 2 Eg. The height of a
tree T is the length of a longest path in T .
De(cid:12)nition 1. Let P be a set of partitions of K. An attack
strategy against P is a triple (T; r; L), where T = (V; E) is a
tree, r 2 V is the root, and L : V ! 2K is a node labeling
with the following properties:
1. L(r) = K, and
2. for every v 2 V , there is a P 2 P with L(v) \ P =
fL(w) j w 2 succ(v)g.
An attack strategy is of length l if T has height l. An attack
is a path (r; : : : ; t) from the root r to a leaf t of T .
Requirement 1 of De(cid:12)nition 1 expresses that, a priori, every
key in K is possibly chosen by the honest agent. Require-
ment 2 expresses that the labels of the children of each node
form a partition of their parent’s label and that this par-
tition is obtained by intersecting the label with a P 2 P.
A simple consequence of requirements 1 and 2 is that the
labels of the leaves of an attack strategy partition the label
of the root node. This leads to the following de(cid:12)nition.
De(cid:12)nition 2. The partition induced by the attack strategy
a = (T; r; L) is the set fL(v) j v is a leaf of T g, which we
denote by Pa. We de(cid:12)ne the set of keys that are coherent
with an attack a = (r; : : : ; t) as L(t).
Observe that this de(cid:12)nition of coherence corresponds to our
prior de(cid:12)nition considering attacks (r; t) of length 1: The
keys that are coherent with an observation o under m form
the block L(t) that the system reveals when queried with
Pm.
To clearly distinguish between adaptive and non-adaptive
attacks, we brie(cid:13)y sketch how the latter can be cast in our
model.
Non-adaptive Attack Strategies.
An attack strategy is called non-adaptive if the attacker
does not have access to the system’s responses until the end
of the attack. Thus, when choosing a message, he cannot
take into account the outcomes of his previous queries. In
our model, this corresponds to the attacker choosing the
same partition in all nodes at the same level of the attack
strategy.
Formally, the level of a node v 2 V in an attack strategy
a = (T; r; L), with T = (V; E), is the length of the path from
the root r to v. A tree is full if all leaves have the same level.
De(cid:12)nition 3. An attack strategy a = (T; r; L) is non-
adaptive i(cid:11) T is full and for every level i there is a Pi 2 P
such that L(v) \ Pi = fL(w) j w 2 succ(v)g, for every v of
level i.
Note that we require the tree to be full to exclude observation-
dependent termination of attacks. The structure of non-
adaptive attacks is simpler than that of adaptive attacks
and we can straightforwardly represent the partitions indu-
ced.
Proposition 1. Let a be a non-adaptive attack strategy
of length l against P. Then we have
Pa =
l(cid:0)1
\
i=0
Pi ;
where Pi 2 P is the partition chosen at level i 2 f0; : : : ; l(cid:0)1g
of a.
Proof. We prove the assertion by induction on the length
l of a = (T; r; L). If l = 0, we have Pa = L(r) = K = T ;. If
l > 0, consider the full subtree T 0 of height l(cid:0)1 of T . We have
Pa = fL(w) j w is a leaf of T g = SvfL(w) j w 2 succ(v)g,
where v ranges over the leaves of T 0. By De(cid:12)nition 3 and the
induction hypothesis, we conclude Pa = Sv L(v) \ Pl(cid:0)1 =
Tl(cid:0)2
Observe that, since \ is commutative, the order of the que-
ries is irrelevant. This is consistent with the intuitive notion
of a non-adaptive attack, as the side-channel information is
only analyzed when the attack has (cid:12)nished.
i=0 Pi \ Pl(cid:0)1 = Tl(cid:0)1
i=0 Pi.
In the next section, we will extend the model presented
with measures for the quantitative evaluation of attack stra-
tegies. Afterwards, we use this quantitative model to give
bounds on what attackers can possibly achieve in a given
number of attack steps.
3. QUANTITATIVE EVALUATION OF
ATTACK STRATEGIES
In Section 2, we used the induced partition Pa to represent
what an attacker learns about the key by following an attack
strategy a. Intuitively, the attacker obtains more informati-
on (or equivalently, reduces the uncertainty) about the key
as Pa is re(cid:12)ned. Information-theoretic entropy measures can
be used to express the remaining uncertainty. Focusing on
the remaining entropy, instead of the attacker’s information
gain, provides a concrete, meaningful measure that quan-
ti(cid:12)es the attacker’s e(cid:11)ort for key recovery by brute-force
guessing under the worst-case assumption that he can ac-
tually determine the set of keys that are coherent with his
observations during the attack. The viewpoints are informal-
ly related by the equation initial uncertainty = information
gain + remaining uncertainty, which we will make explicit
in the following.
3.1 Measures of Uncertainty
We now introduce three entropy measures, which corre-
spond to di(cid:11)erent notions of resistance against brute-force
guessing. Presenting these di(cid:11)erent measures serves two pur-
poses. First, it accommodates the fact that di(cid:11)erent types of
guesses and di(cid:11)erent notions of success for brute-force gues-
sing correspond to partially incomparable notions of entropy
[22, 7, 30]. Second, it demonstrates how the possibilistic mo-
del presented in Section 2 can serve as a basis for a variety
of probabilistic extensions.
In the following, assume a probability measure p is given
on K and is known to the attacker. For a random variable
X : K ! X with range X , we de(cid:12)ne pX : X ! R as
pX (x) = Pk2X(cid:0)1(x) p(k), which in the literature is often
denoted by p(X = x). For a partition P of K, there are
two variables of particular interest. The (cid:12)rst is the random
variable U that models the random choice of a key in K
according to p (i.e., U = idK ). The second is the random
variable VP that represents the choice of the enclosing block
(i.e., VP : K ! P , where k 2 VP (k)). For an attack strategy
a, we abbreviate VPa by Va.
Shannon Entropy.
The (Shannon) entropy [35] of a random variable X : K !
X is de(cid:12)ned as
H(X) = (cid:0) X
pX (x) log2 pX(x) :
x2X
The entropy is a lower bound for the average number of bits
required for representing the results of independent repeti-
tions of the experiment associated with X. Thus, in terms
of guessing, the entropy H(X) is a lower bound for the ave-
rage number of binary questions that need to be asked to
determine X’s value [7].
Given another random variable Y : K ! Y, H(XjY = y)
denotes the entropy of X given Y = y, that is, with respect
to the distribution pXjY =y. The conditional entropy H(XjY )
of X given Y is de(cid:12)ned as the expected value of H(XjY = y)
over all y 2 Y, namely,
H(XjY ) = X
pY (y)H(XjY = y) :
y2Y
Entropy and conditional entropy are related by the equati-
on H(XY ) = H(Y ) + H(XjY ), where XY is the random
variable de(cid:12)ned as XY (k) = (X(k); Y (k)).
Consider now an attack strategy a and the corresponding
variables U and Va. H(U ) is the attacker’s initial uncertainty
about the key and H(U jVa = B) is the attacker’s remaining
uncertainty about the key after learning the key’s enclosing
block B 2 Pa. H(U jVa) is the attacker’s expected remaining
uncertainty about the key after performing an attack with
strategy a. As the value of Va is determined from U , we have
H(U Va) = H(U ). The equation H(U ) = H(Va) + H(U jVa)
is the formal counterpart of the informal equation given at
the start of this section.
Guessing Entropy.
The guessing entropy of a random variable X is the avera-
ge number of questions of the kind \does X = x hold" that
must be asked to guess X’s value correctly [22].
As we assume p to be public, the optimal procedure is to
try each of the possible values in order of their decreasing
probabilities. W.l.o.g., let X be indexed such that pX(xi) (cid:21)
pX (xj), whenever i (cid:20) j. Then the guessing entropy G(X) of
X is de(cid:12)ned as G(X) = P1(cid:20)i(cid:20)jX j i pX(xi). Analogously to
the conditional Shannon entropy, one de(cid:12)nes the conditional
guessing entropy G(XjY ) as
G(XjY ) = X
pY (y)G(XjY = y) :
y2Y
G(XjY ) represents the expected number of optimal gues-
ses needed to determine X when the value of Y is already
known. Hence, G(U jVa) is a lower bound on the expected
number of o(cid:11)-line guesses that an attacker must perform for
key recovery after having carried out a side-channel attack
with strategy a.
Marginal Guesswork.
For a (cid:12)xed (cid:11) 2 [0; 1], the marginal guesswork of a random
variable X quanti(cid:12)es the number of questions of the kind
\does X = x hold" that must be asked until X’s value is
correctly determined with a chance of success given by (cid:11) [30].
Again, w.l.o.g. let X be indexed such that pX(xi) (cid:21) pX (xj),
whenever i (cid:20) j. Then the ((cid:11))-marginal guesswork of X is
de(cid:12)ned as
W(cid:11)(X) = minfj j X
pX(xi) (cid:21) (cid:11)g :
1(cid:20)i(cid:20)j
We de(cid:12)ne the conditional marginal guesswork W(cid:11)(XjY )
analogously to the conditional entropy. As before, W(cid:11)(U jVa)
is a lower bound on the expected number of guesses that an
attacker needs to perform in order to determine the secret
with a success probability of more than (cid:11) after having car-
ried out a side-channel attack with strategy a.
Uniform Distributions.
If p is uniformly distributed, one can derive simple explicit
formulae for the entropy measures presented so far.
Proposition 2. Let a be an attack strategy with Pa =
fB1; : : : ; Brg, jBij = ni, and jKj = n. If p is uniformly
distributed, then
1. H(U jVa) = 1
i=1 ni log ni,
2. G(U jVa) = 1
i=1 n2
i + 1
2 , and
3. W(cid:11)(U jVa) = 1