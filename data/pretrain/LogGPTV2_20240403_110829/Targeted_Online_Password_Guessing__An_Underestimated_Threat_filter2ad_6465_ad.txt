associated 126 dataset. To follow the basic machine learning principles, this
dataset hereafter will never be used as the test set.
It is not difﬁcult to see that the training phase of TarGuess-I can
indeed automatically derive a PCFG. For more background, see
[35]. Using this grammar, in the guess generation process (see Fig.
7) we can further derive: (1) all the terminals (e.g., love@1314)
which are instantiated from base structures that only consist of L, D
and S tags; and (2) all the pre-terminals (e.g., N3B5 and N31234)
which are intermediate guesses consisting of PII-based tags. The
ﬁnal guess candidates come from these terminals as well as from
instantiating all the pre-terminals with the victim’s PII.
Note that, to improve accuracy, we match using the longest-
preﬁx rule and also only consider PII-segments with len (cid:21) 2.
For example, if john06071982 matches John Smith’s account
name “john0607”, it will be parsed into A1B5 using the longest-
preﬁx rule, but not N3B2. In addition, we have only considered full
MMDD dates in the deﬁnition of B1 (cid:24) B10, yet many users tend
to use an abbr. of date when possible (e.g., “198267” instead of
“19820607”). Thus, when matching a birthday-based segment in
the training phase, if an abbreviation happens, the tag related to the
corresponding full segment will be counted by one; In the password
generation process, both full and abbreviated date segments will be
produced. For instance, both “john06071982” and “john671982”
will be produced if the structure N3B2 is used for guess generation.
Our type-based PII tags are widely applicable. In the above, we
have shown how to employ type-based PII tags to build a semantic-
aware grammar using PCFG. Actually, they can also be employed
by various other guessing algorithms (e.g., Markov-based [21] and
TarGuess-II in Sec. 4.2) to build PII-enriched cracking algorithms.
For instance, to build a PII-enriched Markov-based algorithm, we
only need to incorporate the type-based PII tags {N1, (cid:1)(cid:1)(cid:1) , N7; B1,
(cid:1)(cid:1)(cid:1) , B10; A1, A2, A3; E1, E2, E3; P1, P2; I1, I2, I3} into the
alphabet (cid:6) (e.g., (cid:6) = f95 printable ASCII charactersg in [21]) of
the Markov n-gram model, and then all operations for these type-
based PII tags are the same with the original characters in (cid:6).
GI is highly adaptive. On the one hand, whenever we want to
consider new semantic usages (e.g., website name) or new type-1
PII usages (e.g., hobby), we can simply deﬁne new corresponding
type-based tags (e.g., W for website name and H for hobby), the
same as we deﬁne the N and B tags.
In the training and guess
generation phases, all the operations related to H and W are similar
to that of N and B tags. It is “Plug-and-Play”. On the other hand,
even if TarGuess-I deﬁnes the B tag yet the training set has no
birthday information, GI still works properly—it will not parse
passwords using B tags and simply parse birthday information in
passwords using the D tag. That is, GI is “self-dumping” and we
do not need to specially eliminate the B-related tags in such cases.
An independent study.
In a recent paper (published in April
2016), Li et al. [20] presented a length-based PII matching method.
Our work is independent from theirs.
Besides the L, D, S tags in PCFG [35], Li et al. introduced six
kinds of PII tags: N for name, B for birthdate, E for email, A for
account (user) name, P for phone number, and I for NID. In contrast
to our type-based approach, each PII-based tag in [20] uses a sub-
script number to denote the length len of the matched PII segment
(only len (cid:21) 3 are considered in [20]), following the same approach
of the L, D and S tags as in PCFG [35]. As a result, in [20],
wanglei@1982 now is parsed into the N segment “wanglei”, S
segment “@” and B segment “1982”, and its base structure will be
N7S1B4; “loveyou@1314” is parsed into L7S1D4. Within 100
guesses, their “Personal-PCFG” algorithm cracked about 17% of
their test dataset by using “perfect dictionaries”.
However, we discovered a weakness in their Personal-PCFG.
Their algorithm uses length-based tags, the same as Weir et al.’s
algorithm [35]: it differentiates a segment’s length, but is insensi-
tive to a segment’s subtype. For example, both john@1982 and
wang@1982 will be parsed into N4S1B4, because both “wang”
and “john” are of length 4, despite the fact that “wang” is a family
name while “john” is a given name. As shown in Fig. 9, this not
only introduces both under-estimations and over-estimations in the
training phase, but also leads to illogical situations in the guess
generation phase. In the training phase, since “wang”, “smith”
and “li” are all family names and “1982” is a user’s year of birth,
the probability of N4B4 shall be 0.6 but not 0.4, the probability of
L2B4 shall be 0 but not 0.2. In the guess generation phase, “lee”
is of length 3, but there is no base structure N3B4 available, and
thus the guess lee1977 will be given a probability 0 and thus not
be generated by Personal-PCFG.
Figure 9: A weakness of Personal-PCFG [20].
According to our grammar GI, both wang1982 and li1982
will be parsed into the same base structure N3B5, john1982 is
parsed into N4B5, and thus the guess lee1977 can be generated
using the base structure N3B5 for “David Lee” born in 1977. This
addresses the weakness in [20].
Evaluation. For fair comparison, we leverage the 12306 dataset
as with [20] and follow their experimental setups (see Fig. 8) as
closely as possible. The only exception is that, we do not use “the
perfect (L-) dictionary” which is collected directly from the test
set, because this not only introduces overﬁtting issues [21, 35] but
also is unrealistic in practice. Instead, all our experiments directly
learn the L- dictionary from the 12306 training set, a recommended
practice in password cracking [13, 21]. Fig. 8 shows that, within
10(cid:24)103 guesses, our TarGuess-I outperforms Persona-PCFG [20]
by 37.11%(cid:24)73.33%, and outperforms the three trawling online
guessing algorithms [6, 21, 35] by at least 412%(cid:24)740%.
We have further examined to what extent each individual PII
would impact TarGuess-I. As shown in Fig. 8, within 100 guesses,
our TarGuess-I can successfully crack a 12306 user’s password
with an average chance of 20.26% when given this user’s email,
account name, name, birthday, phone number and NID. This ﬁgure
is 20.18% when given email, account name, name and birthday.
This ﬁgure is 13.61% when given name and birthday; this ﬁgure
is 6.04% when given only name. Our results suggest that email,
account name, name and birthday would be very valuable for an
online attacker, while phone number and NID provide marginally
improved success rates. Interestingly, Personal-PCFG [20] exploits
two more PII attributes than TarGuess-I
yet is much less effective,
suggesting that simply incorporating more PII information into
algorithms will not always yield more effectiveness.
Summary. We are the ﬁrst to propose type-based PII tags for
building a semantics-aware PCFG. Such PII tags can also be em-
ployed by other trawling algorithms (e.g., Markov n-grams [21])
to build targeted ones. Within 102 guesses, TarGuess-I has a
success rate of 20.18% when given a 12306 user’s email, user
name, name and birthday. Within 10(cid:24)103 guesses, TarGuess-
I outperforms Personal-PCFG [20] by cracking 37.11%(cid:24)73.33%
more passwords. Particularly, TarGuess-I is highly adaptive.
4.2 TarGuess-II
′
TarGuess-I aims to online guess a user U’s password P Wx at
one service (e.g., CSDN) when given U’s one sister password P Ws
leaked from another service (e.g., Dodonew). This is a challenging
task for two reasons. Firstly, the online guessing number allowed is
small. Secondly, there are over a dozen transformation rules, such
as insert, delete, capitalize, leet (e.g., password! passw0rd)
and the synthesized ones (e.g., password! Passw0rd), at user-
s’ choices to create P Wx by modifying P Ws. This process de-
pends on the password creation policy, the value of service and
each user’s creativity. Moreover, even if A knows that U is likely
to insert three digits, which digital sequence will be exactly used
by U? It is worth noting that, users also love to use top popular
passwords instead of modifying P Ws (see Sec. 3.2). The sole
work by Das et al. [12] considers cross-site guessing by using U’s
one sister password, yet it is ineffective due to four reasons as we
have shown in Sec. 1.
Figure 10: The training process of TarGuess-II
In this work, we prefer a data-driven approach. We use two
lists of passwords as training sets, one leaked from a similar poli-
cy/service with the target site, the other is similar with that of P Ws,
and look for the same users in these two lists by matching email.
Further, the identical PW pairs are eliminated, and this creates a
new list of non-identical sister PW pairs fP WA, P WBg. Then,
we measure how P WB is modiﬁed from P WA, or whether P WB
is simply a popular password. To determine whether P WB is a
popular one, we build a top-104 list L for the target service (e.g.,
CSDN) from various leaked lists with consideration of policy and
language, e.g., L={pw jlen(pw)(cid:21) 8 and the value of Pcsdn(pw) (cid:3)
P126(pw) (cid:3) Pdodonew(pw) ranks top-104}.
As shown in Fig. 10, in the training phase of TarGuess-II,
ﬁrst of all it determines whether P WB 2 L or not.
If yes, the
occurrence of P WB 2 L increases by one; If not, the pair (P WA,
P WB) ﬁrst goes through the structure-level training and then the
segment-level training.
In the structure-level process, TarGuess-
II ﬁrst parses passwords with L, D, S tags as with TarGuess-I.
For instance, abc123 is parsed into L3D3. According to [12,
32], we consider six main types of structure-level transformation
rules: insertion (e.g., L3D3! L3D3S2), deletion (e.g., L3D3S2)
! L3D3), capitalization C, leet L, substring movement SM (e.g.,
abc123!123abc) and reverse R (e.g., abc123!321cba).
insertion (e.g., L3 : abc !
There are two segment-level rules:
L4 : abcd) and deletion (e.g., L3 : abc ! L2 : bc). For each of
these eight types of rules, there exist a number of sub-types and
we consider the most common ones. More speciﬁcally, for both
levels of insertion (see Fig. 11), there are tail insertion ti (resp.
′
); For both levels of deletion,
ti
′
there are tail deletion td(resp. td
);
For capitalization, there are four types as in Table 7; For leet, we
consider 5 sub-types as in Table 8; For reverse, we consider 2 sub-
types as in Table 10. Note that, a combination of our insertion and
deletion operations can transform abc123 to abc!123, achieving
the middle insertion.
′
) and head insertion hi (resp. hi
) and head deletion hd(resp. hd
The ﬁrst step of the structure-level training is to employ the
Levenshtein-distance (LD) algorithm (with only insertion and
deletion enabled) to measure the similarity score d1=LD(P WA;
P WB) between the pair P WA and P WB. Then, we use each
structure-level rule (except for insertion and deletion) in the C, L,
′
R, SM order to obtain P W
A based on P WA, when considering
that their popularity order is C>L>SM>R [12, 32] and that the
rule R would result in a more drastic change than SM. Upon each
′
rule, we compute d2=LD(P W
A; P WB). If d2>d1, such a rule is
′
called a “live” one,
A, and the
occurrence of the corresponding rule (see Tables 7 to 10) increases
then P WA is updated to P W
′
by one. Then, we execute the next rule on P W
P W
“live” and counted.
′′
A, and compute d3=LD(P W
′
A to produce
′′
A; P WB). If d3>d2, this rule is
′′′
Upon all these live rules, assume P W
A will be created from
the original P WA. To avoid futile transformations to dilute the
′′′
effective ones, we require that if LD(P W
A ; P WB) is smaller than
a predeﬁned threshold (e.g., 0:5 as suggested in this work), then all
these “live” rules are un-counted, and the training process switches
′′′
to the next password pair in the training set. Otherwise, both P W
A
and P WB are parsed with L, D and S tags to be, e.g., L4D3S2 and
L6S1. Since we do not consider the length of a PW segment in
the structure-level, L4D3S2 and L6S1 will be seen as LDS and LS.
Now we use the LD metric to compute d3=LD(“LDS”, “LS”) and
meanwhile, the LD algorithm returns a LD edit route which records
how to arrive “LS” from “LDS”: ﬁrst use the rule td on the S2-
segment, then use the rule td on the D3-segment, and ﬁnally use the
′′′′
rule ta on the S1-segment, producing P W
A with a base structure
L4S1. Accordingly, the occurrence of all the corresponding items
in Fig. 11(a) is updated.
,
′
hd
′
, td
′
, hi
} is a ﬁnite set of variables.
Now we come to the segment-level training phase, and the focus
is in the inner of the L-, D- or S- segment of a password. For
′′′′
A (whose structure is L4S1) and P WB (L6S1), we use the
P W
LD metric to measure the similarity of their L-segments. As with
the structure-level training, the LD metric is used to update the
occurrence of all the corresponding rules in Fig. 11(b).
In our
experiments, we ﬁnd that the probabilities in the right-most row
of Fig. 11(b) are better by computing using Markov n-grams [21]
which are trained on a million-sized large password list, than by
using the training as stated above. This is mainly because the size
of the non-identical PW pairs in our training sets is only moderate
and may lead to the sparsity issue. Fortunately, Markov n-gram
model trained on million-sized PW lists can overcome this issue.
Our above two training phases give rise to a password-reuse
based context-free grammar GII = (V; (cid:6);S;R), where:
1) V = fS; L; D; S; L, R, C, SM; ti, td, hi, hd; ti
′
2) S 2 V is the start symbol.
3) (cid:6)={95 printable ASCII codes; C1,(cid:1)(cid:1)(cid:1) ,C4; R1,R2; L1, (cid:1)(cid:1)(cid:1) ,
L5; Yes, No; No
4) R is a ﬁnite set of rules of the form A ! (cid:11), with A 2 V and
(cid:11) 2 V [ (cid:6) (see Fig. 11 and Tables 7 to 10).
Note that, GII is a probabilistic context-free grammar due to the
fact that, for a speciﬁc left-hand side (LHS) variable (e.g., R !)
of GII, all the probabilities associated with its rules (e.g., R !No,
R ! R1 and R ! R2) can add up to 1. Using GII, in the guess
generation phase we can create a list of guesses with possibilities.
For instance, when given password, Pr(“Pa$$word123”)=
Pr(S ! L8)* Pr(L8 ! ti)(cid:3) Pr(ti! D3)* Pr(D3!123) (cid:3)P (C
! C1) (cid:3) Pr(L! L2) (cid:3) Pr(L! L2) (cid:3) Pr(R!No)(cid:3) Pr(SM!No)
=1 * 0.1 * 0.15 * 0.08 * 0.03 * 0.01 * 0.01 * 0.97 * 0.97 = 3.39 *
−9, where the related probabilities are referred to Tables 7 to 10.
10
Then, all the probabilities of guesses generated by GII should be