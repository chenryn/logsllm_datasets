detailed technical report on the security issue by either replying
to our email messages or accessing our Web interface (with the
secret token). For each domain, we recorded if and when we
observed an email response or Web site visit with its associated
token. For the Friendly group, our initial message did not
include detailed information about the security issues or any
links, and site operators were to request more information. We
marked the report as accessed when we replied with the report
(within at most 12 hours after receiving a request).
Email Delivery Status — To determine if message delivery
failed to certain recipients, we checked the email inboxes of
our senders for email bounces. For our Tracking group, we
monitored for retrievals of our image resources, unique to each
recipient (without logging IP addresses or other identiﬁers).
Experiment Parameters — On January 30th, 2017, we
checked the Alexa Top 1M for the presence of one of the
outlined security issues. We then randomly assigned the sites
into seven groups as shown in Table I: one for each email
variant and an unnotiﬁed control group. All groups except
for Friendly contained approximately 4,000 domains in total.
As manual interaction was required for recipients of Friendly
messages, we limited the number of domains in this group
to 1,000 sites. As previously mentioned, we initially also
considered core dumps, but removed them during the course
of our experiments as the diversity of recipients was too low.
Additionally, administrators for 395 domains requested to opt
out of any notiﬁcation or further analysis. Table I shows the
ﬁnal population sizes for each group after those contacts were
removed. The notiﬁcation campaign started on February 3rd,
2017 and lasted six weeks. We sent two reminders on February
17th and on March 3rd.
C. Manual Notiﬁcation Experiments
Automated email disclosures may be tenable, but may not
be the most effective method of notiﬁcation. Prior work [19,
25] observed that a signiﬁcant fraction of notiﬁed contacts
exhibited no responses. To explore alternative notiﬁcation
options, we followed up our email notiﬁcations with ﬁve dif-
ferent forms of manual notiﬁcations, including communication
channels that may be challenging to automate delivery for.
Given the manual nature of these efforts, we chose to
focus on the Web sites that did not react to our notiﬁcations
(i.e., those who did not remediate or respond to our mes-
sages), as we may uncover a better method of reaching these
webmasters. In particular, we reached out to email addresses,
Groups
Plain
S/MIME
Mailbot
Tracking
HTML
Friendly
Control
Git
1,561
1,559
1,560
1,548
1,565
367
1,561
WP
2,371
2,374
2,371
2,370
2,371
585
2,373
Total
3,932
3,933
3,931
3,918
3,936
952
3,934
TABLE I.
SIZE OF OUR NOTIFICATION GROUPS
phone numbers, and postal addresses listed on affected Web
sites, and submitted “contact us” web forms. We also searched
the sites for links to their social media accounts on Twitter
and Facebook. We describe the method behind our manual
notiﬁcations in more detail in Section V. We collected the
same measurements as with the automated email notiﬁcations.
D. Recipient Survey
Our automated and manual notiﬁcation experiments al-
lowed us to observe the externally visible effects of our
outreach efforts. However, to gain insights on site operator
perspectives, we distributed surveys to recipients we had
emailed the notiﬁcations to. Our survey extends beyond those
sent in prior studies [13, 19] to notiﬁcation recipients, which
focused on the acceptability of the notiﬁcations. In our survey,
we additionally aim to understand the demographics of our re-
cipients, their prior experiences with security notiﬁcations and
reports, reasons behind the observed remediation behaviors,
and suggestions for improvements to our notiﬁcation process.
The details of our survey are described in Section VI.
E. Ethical Considerations
We note that our primary institution does not provide an
IRB nor mandate (or enable) approval for such experiments.
However, as described next, we took great care to ensure the
privacy of message recipients in our experiments.
We designed our detection of security issues to minimize
the impact on Web sites. To reduce load on Web sites, we only
checked each site once a day, and our detection methods only
required requesting a public static resource ﬁle, which does
not interfere with normal server operations. We respected any
opt-out requests and extensively tested our detection methods
prior to their deployments.
The ethics of performing security notiﬁcations themselves
are not fully settled, although a number of prior notiﬁcation
studies [6, 13, 17, 19, 25] have set a precedence for acceptable
notiﬁcations. In particular, surveys in two prior studies [13, 19]
documented the acceptability and helpfulness of these no-
tiﬁcations in the eyes of message recipients. We likewise
believe that the potential good from informing vulnerable hosts
outweighs the potential risks and costs. Following the best
practices outlined in these previous notiﬁcation efforts, we re-
spect requests to opt-out of our notiﬁcations. Additionally, we
attempted to message all unnotiﬁed contacts at the conclusion
of our study (such as those in our control groups). We offered a
feedback channel through an anonymous survey for the notiﬁed
organizations, which followed best practices, e.g., it was fully
anonymous and optional. We note that we only collected data
on organization decisions and not individuals, thus our study
does not constitute human subjects research.
Our experiments did rely on the ability to monitor resource
requests to our servers, which could potentially be used for
tracking and violating the privacy of notiﬁcation recipients.
However, we employed safeguards to ensure that no private
information was collected. We did not log IP addresses or
any identiﬁers for any resource requests except for the random
token unique to each recipient. This only allowed us to learn
if that recipient or domain performed a speciﬁc action (visited
our web interface or opened our email), and nothing else
4
Git
WP
403
351
403
374
363
75
203
25.8%
22.5%
25.8%
24.2%
23.2%
20.4%
13.0%
383
399
420
375
379
93
336
16.2%
16.8%
17.7%
15.8%
16.0%
15.9%
14.2%
Plain
S/MIME
Mailbot
Tracking
HTML
Friendly
Control
TABLE II.
NON-EXPLOITABLE DOMAINS PER GROUP AND
VULNERABILITY BY MARCH 17TH, 2017
Timeline of Remediation — Figures 2 and 3 show the ratio
of ﬁxed vulnerabilities for Git and WP over the course of
our notiﬁcation campaign. The vertical lines denote the two
notiﬁcation reminders sent.
For Git, we note distinct behavioral differences between
the control group and the notiﬁed groups. After two weeks,
an additional 7% of the notiﬁed groups had ﬁxed on aver-
age, compared to the control group. After four weeks, this
improvement rose to 11% of the notiﬁed population, indicating
our ﬁrst reminder messages spurred further viewed reports and
ﬁxed sites. However, no further improvements occurred after
the second reminder message. This behavior contrasts slightly
with the re-notiﬁcation results by Li et al. [19], who found
no increased remediation from a second round of messages
to network operators. We observe this effect occurred but only
after the second set of reports, reinforcing the notion that there
is a period after which notiﬁcations are no longer effective, but
that this period may be longer for webmasters than network
operators. This time period is likely due to recipients deciding
to not heed our messages, or never receiving our messages in
the ﬁrst place (e.g., bounced emails or spam ﬁlters).
Amongst the notiﬁed Git groups, Plain and Mailbot reme-
diated at the highest levels, exhibiting commensurate perfor-
mance. The HTML and Tracking groups are likewise similar
but at a lower ﬁx rate. Interestingly, even though its content
exactly matched the other plaintext emails, S/MIME performed
worse than HTML emails. The least effective notiﬁcation
group was Friendly. We discuss implications of our ﬁndings
in the following section.
WP sites, in contrast, do not display drastic differences
between the notiﬁed and control groups across our entire
the Mailbot group
measurement window. We observe that
performed best, followed by S/MIME and Plain. Again HTML
and Tracking show a similar ﬁx rate. We hypothesize that
this may be due to the population characteristics we discussed
earlier, running older versions of WordPress without automatic
updates and without actively maintaining it.
Signiﬁcance of Effects — To determine if our notiﬁcation
efforts had a statistically signiﬁcant impact on remediation,
we compared the fraction of the population remediated after
six weeks for each notiﬁed group with that of the control
group. Our null hypothesis was that the remediation levels
for a given notiﬁed group did not differ from that of the
control group. We use Fisher’s exact test to determine the
signiﬁcance of the observed improvements, with a signiﬁcance
threshold of α = 0.05. Since we test multiple hypotheses,
we must additionally perform multi-test corrections. Thus, we
apply the Holm-Bonferroni correction method [16]. Under this
Fig. 2. Non-exploitable Git domains over time
Fig. 3. Non-exploitable WP domains over time
about the recipient. We only report aggregate results from this
monitoring, without ever revealing the outcome for a particular
domain or recipient. We believe the insights we can gain from
this monitoring can signiﬁcantly improve our understanding of
notiﬁcations at a reduced risk to message recipients.
III. REMEDIATION BEHAVIOR
Here we describe the details of our automated email
notiﬁcations and the observed remediation from affected sites.
A. Remediation Levels
Table II shows the number of remediated Web sites at the
end of our campaign (March 17th). For the control group,
13% and 14% of the domains were ﬁxed for Git and WP
respectively. For Git, the notiﬁed domains had a ﬁx rate of
approximately 24%, whereas for WP, the average ﬁx rate
was merely 17%. The impact of notiﬁcations for the WP
groups may be inﬂuenced by WordPress’s automatic updates,
which was deployed in late 2013 (with WordPress 3.7 [2]). We
speculate that those sites that did not automatically or quickly
manually update to a new version yet (which implicitly ﬁxed
our targeted XSS vulnerabilities) perhaps were less actively
maintained (if at all), reducing the likelihood that our outreach
efforts would spur actions at those sites.
5
02/0802/1502/2203/0103/0803/15  0%  5% 10% 15% 20% 25% 30% 35%Fixed DomainsHTMLTrackingPlainMailbotS/MIMEFriendlyControl02/0802/1502/2203/0103/0803/15  0%  5% 10% 15% 20% 25%Fixed DomainsHTMLTrackingPlainMailbotS/MIMEFriendlyControlFig. 4. Viewed reports for Git
Fig. 5. Viewed reports for WP
correction approach, all m resulting hypothesis p-values are
ordered from lowest to highest. Let k be the minimal index in
the ordered p-value list such that pk > α
m+1−k , where m = 6
and α = 0.05. The hypotheses corresponding to the ﬁrst k − 1
p-values (in order) are rejected while the rest are not.
Table III summarizes our signiﬁcance test results. For Git,
we ﬁnd that the null hypothesis is rejected for every notiﬁ-
cation group, under the Holm-Bonferroni correction. Hence,
all notiﬁcation variants show a signiﬁcant improvement in
remediation for Git groups. In contrast, for WP, only the
Mailbot remediated at a statistically signiﬁcantly higher level
(again after multi-test corrections). It must be noted though
that no group performed signiﬁcantly better than all others.
Git
WP
1.159 e-19
3.291 e-12
7.996 e-20
9.971 e-16
1.156 e-13
0.0004916
0.0570939
0.0114718
0.0008576
0.1127060
0.0882801
0.2948444
Plain
S/MIME
Mailbot
Tracking
HTML
Friendly
TABLE III.
FISHER’S EXACT TEST p VALUES
B. Report Views and Conversion to Fixes Rate
Table IV shows the number (and fraction) of recipients per
notiﬁcation group that accessed our report, and the likelihood
that they remediated conditioned on viewing the report.
For Git, we observe that the plaintext notiﬁcation groups
exhibited an approximately 12% view rate. For HTML mails,
9-10% of the reports were accessed, indicating that the mail
format inﬂuenced report viewing (albeit not statistically signif-
icantly). Moreover, we ﬁnd that the usage of a linked resource
did not result in differing user behavior when compared to an
HTML email with the image attached to it. Friendly had the
highest overall report access rate with 13%, possibly because
the initial message contained little technical information about
the security issue and required a response, but also since it did
not contain any links (which likely increases the spam score).
Figure 4 shows how reports were accessed over time. We do
observe a short burst of increased report accesses after our
reminders for all notiﬁed groups (similar to what we found
in prior work [25]), indicating that recipients do not wholesale
ignore our reminders. However, as noted earlier, this no longer
translated into additional remediation by the second reminder.
Across all message types, we ﬁnd that Git Web site operators
who viewed our report were likely to remediate correctly, with
at least 72% of operators in each group addressing the issue.
Thus, if we can communicate our report information to a Web
site operator, we can likely spur positive actions.
For WP (Figure 5), we observe similar patterns in behav-
iors, with the Friendly group accessing the report at the highest
rate, followed by the plaintext message groups, and ﬁnally the
HTML message groups. Likewise, we observed increases in
report views after reminders. The overall view rates are lower
than with Git Web sites, as are the ﬁx rates for those that did