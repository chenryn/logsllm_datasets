websites need to be set up in order to manipulate the list.
The effort
to generate many ranked entries is further
reduced by the inclusion of subdomains, as all subdomains at
lower depths are automatically ranked: we were able to rank
12 subdomains simultaneously with one set of requests. Fur-
thermore, the number of requests is aggregated per subdomain,
so a low number of requests to many subdomains can result
in both many ranked subdomains and a good rank for the pay-
level domain.
Combining the ability to insert fake domains with the low
overhead of requests to additional domains, the inclusion of
subdomains and the lack of any ﬁltering or manipulation detec-
tion means that the scale at which an attacker can manipulate
Umbrella’s list can be very large.
2) Alternatives:
(cid:15) Tor. The Tor service provides anonymous communica-
tion between a user and the service they use. Trafﬁc is relayed
across multiple nodes before being sent to the destination from
an exit node, meaning that the destination observes trafﬁc
originating from that node’s IP address. This set of exit nodes
provide a pool of IP addresses, and by switching the routing
over the Tor network, DNS requests can be altered to appear
to originate from multiple IP addresses in this pool. However,
8
025050075010001250150017502000IPs2000004000006000008000001000000Rankas there are less than 1 000 exit nodes at any given point in
time [69], it will be possible to inject domains in the list, but
infeasible to obtain a high rank solely through this technique.
(cid:15) IP spooﬁng. IP packets contain the IP address of its
sender, that can however be arbitrarily set in a technique known
as IP spooﬁng. We could leverage this technique to set the
source IP of our DNS packets to many different addresses,
in order for our requests to appear for Umbrella to originate
from many unique IPs. As IP spooﬁng is often used during
denial-of-service attacks, many ISPs block outgoing packets
with source IPs outside their network. Leveraging IP spooﬁng
for sending DNS requests therefore requires ﬁnding a network
that supports it. Karami et al. [41] found that certain VPS
providers allow IP spooﬁng; as such these could be used for
our experiment.
Due to the ethical concerns that are raised by leveraging
IP spooﬁng (the responses of our DNS requests would arrive
at the users of the forged source IPs, and the associated trafﬁc
may cause the VPS provider to be ﬂagged as malicious), we
did not further explore this technique. It is important to note
however that an adversary only needs to ﬁnd a single provider
or network that does not prevent IP spooﬁng in order to send
a very large number of DNS requests to Umbrella’s resolvers
and thus manipulate the list at a very large scale.
C. Majestic
Majestic’s ranking is based on the number of subnets
hosting a website that links to the ranked domain. Therefore,
we cannot construct data reporting requests sent directly to
Majestic, but must use techniques where website owners
knowingly or unknowingly serve a page that contains a link to
our domain and that is then crawled independently by Majestic.
1) Backlinks: Backlink providers offer a paid service where
they place incoming links for a requested website (‘backlinks’)
on various sites. The goal of this service is usually to achieve
a higher position in search engine rankings, as part of search
engine optimization (SEO) strategies; the deceptive nature of
this technique makes that this is considered ‘black-hat’ SEO.
Backlinks are priced differently according to the reputation
of the linking site. While we need a sufﬁciently diverse set
of websites hosted on different subnets, Majestic does not
take the quality of our backlinks into account when ranking
domains. This means that we can reduce our cost by choosing
the cheapest type of backlink. Moreover, we have the choice
of removing backlinks after they have been found, as these
are no longer billed but still count towards the subnets for a
period of at most 120 days, reducing monetary cost.
We use the services of BackLinks.com, as they operate
only on sites under their control, therefore avoiding impact of
our experiment on unaware site owners. The choice for this
particular backlink provider brings about certain constraints
(such as the pool of available backlink sites, or a limit on daily
backlink deletions), but these can be alleviated by using other
and/or multiple backlink providers. We buy backlinks if they
are located in a subnet not covered by any already purchased
site, but have to use OCR as the URLs on which links would
be placed are only available as a warped image. We therefore
curated the set of backlinks through manual veriﬁcation to
compensate for any errors, increasing our required effort.
Fig. 9. The relation between subnets and rank in the Majestic list for May
31, 2018, with our obtained ranks highlighted.
The cheapest type of backlink costs USD 0.25 a month,
but since there was not a sufﬁcient amount of such pages to
cover the necessary number of subnets, more expensive back-
links were also required. The backlinks were partially found
organically by Majestic; in this case there is no additional cost.
Through a subscription on Majestic’s services, backlinks can
also be submitted explicitly for crawling: the minimum cost is
USD 49.99 for one month.
We bought backlinks for our test domain and curated them
for two and a half months, in order to capture as many subnets
as possible while managing the monetary cost. Our total cost
was USD 500. We successfully inserted our domain, with
Figure 9 showing the achieved rankings on top of the relation
between the rank and the number of found subnets for all
ranked sites as published by Majestic.
There exists a trade-off between the cost and the time
required to enter the rank: if the monetary cost should be kept
low, more time is needed as the set of eligible backlink pages
is smaller and backlinks will need to be deleted. Alternatively,
a higher number of possibly more expensive backlinks would
allow to achieve the necessary number of subnets more quickly,
but at a higher monetary cost. Conversely, because Majestic
considers links for at least 120 days, the cost for long-term
manipulation is relatively limited: even though we stopped
buying backlinks and these subsequently disappeared, our
ranking was still maintained for more than two months as
previously found backlinks were still counted.
2) Reﬂected URLs: An alternative technique that we dis-
covered, for which it is not required to purchase services from
external parties, is to leverage websites that reﬂect a GET
parameter into a link. Note that for our purpose, reﬂected cross-
site scripting (XSS) attacks could also be used; however, this
technique is more intrusive as it will inject HTML elements,
so we did not evaluate it out of ethical considerations. To
discover web pages that reﬂect a URL passed as a parameter,
we started crawling the 2.8 million domains from the four lists,
ﬁnding additional pages by following links from the homepage
of these domains. If GET parameters were found on the page,
we replaced each one with a URL and tested whether this URL
was then included in the href of an a tag on the page.
Through this crawl, we found that certain MediaWiki sites
were particularly susceptible to reﬂecting URLs on each page,
depending on the conﬁguration of the site. We therefore tested
this reﬂection on the wikis from a number of data sources:
the root domains as well as the subdomains containing wiki
of the four top lists, the set of wikis found by Pavlo and
9
103104105Subnets02500005000007500001000000RankBacklinksReflected URLsShi in 2011 [59] and the wikis found by WikiTeam10. As
the reﬂection is purely achieved through altering the GET
parameters, we do not permanently alter the wiki.
Given the special construction of their URLs, the pages
reﬂecting our domain will not be found organically by Majestic.
The list of affected URLs can be submitted directly to Majestic,
but this requires a subscription. The links can also be placed
on one aggregating web page: by verifying ownership of
the hosting domain with Majestic, a crawl of this page and
subsequently of the links placed on it can be triggered for
free; alternatively, using Majestic’s site to request the freely
available subset of backlinks data for this special web page
also seems to trigger this crawl.
Through our crawls, we found 1 041 pages that reﬂected
the URL of our test domain when passed in a GET param-
eter. Through submitting these reﬂecting URLs to Majestic’s
crawler, we successfully ranked our domain, with Figure 9
showing the achieved rankings over time. Through this tech-
nique, we also successfully had one backlink to a non-existing
domain crawled and counted as a referring subnet. By scaling
this up to the number of subnets required to be ranked, this
implies that Majestic’s list ranking is also susceptible to fake
entries; as there are unavailable sites in the list, Majestic likely
does not actively check whether entries in the list are real.
This technique allows to construct backlinks at no monetary
cost, but requires a high effort to ﬁnd appropriate pages. We
found only small subsets of wikis and domains in general to
reﬂect our URL, so the number of pages and subnets that can
be discovered using this technique may not be sufﬁcient to
achieve very high rankings. Given a deeper crawl of pages,
more sites that reﬂect URLs passed through a GET parameters
may be found, more subnets can be covered and a higher
ranking can be achieved. Moreover, an attacker can resort
to more ‘aggressive’ techniques where URLs are permanently
stored on pages or XSS vulnerabilities are exploited.
Once found however, a reﬂecting URL will be counted
indeﬁnitely: a site would effectively have to be reconﬁgured or
taken ofﬂine in order for the backlink to disappear. This means
maintaining a rank comes at no additional cost. Furthermore,
every website that is susceptible to URL reﬂection can be
leveraged to promote any number of attacker-chosen (fake)
domains, at the cost of submitting more (crafted) URLs to
Majestic. This means that manipulation of Majestic’s list is
also possible on a large scale.
3) Alternatives:
(cid:15) Hosting own sites. Using domains seen in passive DNS
measurements, Tajalizadehkhoob et al. [67] identiﬁed 45 434
hosting providers in 2016, and determined their median address
space to contain 1 517 IP addresses. Based on these ﬁgures,
we can assume that the number of subnets available through
hosting providers is well above the threshold to be ranked by
Majestic. An attacker could therefore set up websites on a
sufﬁcient number of these providers, all with a link back to
the domain to be ranked. By making all the websites link to
each other, a larger set of domains could easily be ranked. This
technique incurs a high cost however: in effort, as setting up
accounts with these providers is very likely to require a lot of
10https://github.com/WikiTeam/wikiteam
manual effort, as well as in monetary cost, as for each hosting
provider a subscription needs to be bought.
(cid:15) Pingbacks. Content management systems such as Word-
Press provide a pingback mechanism for automatically report-
ing URLs that link to one of the pages hosted on that system.
Many sites will then insert a link back to the reported URL on
that page. By ﬁnding a set of domains supporting pingbacks
(similar to ﬁnding wikis) and reporting a URL on the domain
we want to see ranked, we could again have links to our domain
on a large set of domains and therefore subnets. However, this
permanently changes pages on other websites, and although
enabling the pingback feature implies some consent, we opted
to not explore this technique for ethical reasons.
D. Quantcast
1) Quantiﬁed: Quantcast mainly obtains
trafﬁc data
through its tracking script that webmasters install on their
website. We extracted the reporting algorithm from the tracking
script, and automatically sent requests to Quantcast from a set
of 479 VPN servers located in the United States, as Quantcast’s
ranking only takes US trafﬁc into account. We sent requests
for 400 generated users per day, presenting ourselves as a new
user on the ﬁrst request and subsequently reusing the generated
token and received cookie in four more requests. As opposed
to Alexa’s tracking script, reporting page views for only new
users did not result in any visits being counted.
Our forged requests were acknowledged by Quantcast and
its analytics dashboard reports that on May 30, 2018, "the
destination reaches over 6,697 people, of which 6,696 (100%)
are in the U.S." The latter metric is used to determine the rank.
However, our test domain has not appeared in the ranking.
This is likely due to the short age of our domain; although we
have sent requests for more than a month, Quantcast’s slow
update frequency means its ranking algorithm may not take
our domain into account yet.
As Quantcast publishes the number of visits counted for
each ranked domain, the relation between the desired rank and
required effort is known as shown in Figure 10. Up to around
5 000 visits, the achieved rank remains relatively low; this tail
contains primarily quantiﬁed sites that are ranked even with
almost no visits. Above 5 000 visits, Quantcast’s list includes
many more domains for which a rank is estimated; especially at
worse ranks, large blocks of estimated domains are interspersed
with quantiﬁed domains, so increasing the number of visits to
jump across such a block gives a large improvement in rank.
If a rank were to be assigned to our domain, we can determine
that we would theoretically be given a rank around 367 000.
Achieving higher ranks only requires submitting more forged
requests, so the increased cost in time and effort is minimal.
Quantcast will only start processing trafﬁc data once it has
veriﬁed (through crawling) that its tracking pixel is present on
the domain. It is therefore required to register the domain and
set up a real website to manipulate the rankings, so scaling to
multiple domains incurs a higher cost; Quantcast’s analytics
platform itself is free however, limiting the additional cost. As
Quantcast performs the check only once, the domain and the
website also do not need to be sustained. Merely registering for
tracking may even sufﬁce to be ranked: over 2 000 domains are
ranked but reported to have 0 visits, with over half registered
by DirectEmployers as discussed in Section III-C.
10
that in general many more ranked domains are unavailable
or unrepresentative. Our sites only hosted benign content, so
whitelists using rankings are unaffected.
VI. AN IMPROVED TOP WEBSITES RANKING
As we showed, the different methods used to generate
popularity rankings cause undesirable effects on their prop-
erties that can potentially sway the results and conclusions of
studies. In addition, we showed that researchers are prone to
ignore or be unaware of these effects. We also proved that
these rankings show several pitfalls that leave them vulnerable
to large-scale manipulation, further reducing their reliability
and suitability to research. Nevertheless, popularity rankings
remain essential for large-scale empirical evaluations, so we
propose improvements to existing rankings as well as a new
ranking that has characteristics geared towards research.
A. Defending existing rankings against manipulation
Even though the methods for data collection and processing
of the existing lists are usually unknown, our experiments
suggest that their providers employ little defense against large-
scale manipulation. We outline techniques that the providers
could use to make these lists more resilient to attacks.
Detecting and deterring singular instances of fraud ensures
that all data used in ranking domains is deemed valid. Alexa
and Quantcast rely on the reporting of page visits; within the
realm of online advertising, techniques have been designed to
subvert click inﬂation [2], [16], [51]. As we saw that not all
attempts at manipulating Alexa’s ranking were successful, this
may imply that Alexa already employs some of these tactics.
To deter large-scale manipulation, ranking providers could
employ tactics that increase the effort and resources required
to affect many domains to prohibitive levels. This therefore
avoids signiﬁcant inﬂuence on research results, even if these
tactics may not be sufﬁcient to stop small-scale manipulation.
For a trafﬁc reporting extension, the proﬁle setup could
be tied to an account at an online service; while a normal
user can easily create one account, creating many accounts
in an automated way can be countered by techniques that try
to detect fake accounts [20]. In the case of Alexa, given its
ownership by Amazon, a natural choice would be to require
an Amazon account; in fact, a ﬁeld for such an account ID is
available when registering the extension, but is not required.
This technique is not useful for tracking scripts, since no user
interaction can be requested, and fraud detection as discussed
earlier may be required. For providers that use both, the two
metrics can be compared to detect anomalies where only one
source reports signiﬁcant trafﬁc numbers, as we suspect such
manipulation is already happening for Alexa Certify.
Data could be ﬁltered on the IP address from which it
originates. Ignoring requests from ranges belonging to cloud
providers or conversely requiring requests to come from ranges
known to belong to Internet service providers (e.g. through
its autonomous system) does not block a single user from
reporting their trafﬁc. However, using many IP addresses
concurrently is prevented as these cannot be easily obtained
within the permitted ranges. This technique is particularly
useful for Umbrella’s list; for the other lists, using many IP
addresses is not strictly necessary for large-scale manipulation.
Fig. 10. The relation between measured visits and rank in the Quantcast list
for May 31, 2018, with the theoretical rank for our visit count highlighted.
2) Alternatives: Quantcast states that it also uses trafﬁc
data from ‘ISPs and toolbar providers’ [64]. ISPs sell trafﬁc
data to third parties [18], and Quantcast may be buying these
services to generate the number of page visits and therefore
the rank for non-quantiﬁed websites. However, we cannot
determine which ISPs may be used. As for extensions, we
were unable to discover any extensions reporting to a URL
that was obviously related to Quantcast.
Ethical considerations: Because our experiments may
have a large impact on the reputation of the rankings as well as
potentially affect third parties, we conduct an ethical review of
our experimental methods. Such reviews have been advocated
for by the academic community [58] and ensure that
the
potential damage inﬂicted is minimized. We base this review