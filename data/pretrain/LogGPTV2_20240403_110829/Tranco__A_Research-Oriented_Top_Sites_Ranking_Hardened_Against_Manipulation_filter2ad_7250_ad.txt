### Optimized Text

#### Manipulating Website Rankings

To manipulate the list, websites must be set up. The effort to generate many ranked entries is reduced by including subdomains, as all subdomains at lower depths are automatically ranked. We were able to rank 12 subdomains simultaneously with a single set of requests. Additionally, the number of requests is aggregated per subdomain, so a low number of requests to multiple subdomains can result in both a high number of ranked subdomains and a good rank for the pay-level domain.

Combining the ability to insert fake domains with the low overhead of requests to additional domains, the inclusion of subdomains, and the lack of any filtering or manipulation detection, an attacker can manipulate Umbrella’s list on a large scale.

#### Alternatives

**Tor:**
The Tor service provides anonymous communication between a user and the service they use. Traffic is relayed across multiple nodes before being sent to the destination from an exit node, making it appear that the traffic originates from that node’s IP address. This set of exit nodes provides a pool of IP addresses. By switching the routing over the Tor network, DNS requests can be made to appear to originate from multiple IP addresses in this pool. However, with fewer than 1,000 exit nodes at any given time, it is possible to inject domains into the list but infeasible to achieve a high rank solely through this technique.

**IP Spoofing:**
IP packets contain the sender's IP address, which can be arbitrarily set in a technique known as IP spoofing. This technique can be used to make DNS requests appear to originate from many different IP addresses. However, IP spoofing is often used in denial-of-service attacks, and many ISPs block outgoing packets with source IPs outside their network. Leveraging IP spoofing for sending DNS requests requires finding a network that supports it. Karami et al. [41] found that certain VPS providers allow IP spoofing, which could be used for our experiment.

Due to ethical concerns (the responses of our DNS requests would arrive at the users of the forged source IPs, potentially causing the VPS provider to be flagged as malicious), we did not further explore this technique. It is important to note that an adversary only needs to find a single provider or network that does not prevent IP spoofing to send a large number of DNS requests to Umbrella’s resolvers and thus manipulate the list on a large scale.

### Majestic

Majestic’s ranking is based on the number of subnets hosting a website that links to the ranked domain. Therefore, we cannot directly report data to Majestic but must use techniques where website owners knowingly or unknowingly serve a page that contains a link to our domain, which is then crawled independently by Majestic.

#### Backlinks
Backlink providers offer a paid service where they place incoming links (backlinks) on various sites. The goal is usually to achieve a higher position in search engine rankings as part of SEO strategies. Backlinks are priced differently based on the reputation of the linking site. While we need a diverse set of websites hosted on different subnets, Majestic does not consider the quality of backlinks when ranking domains. This allows us to reduce costs by choosing the cheapest type of backlink. Additionally, we can remove backlinks after they have been found, as these still count towards the subnets for up to 120 days, reducing monetary cost.

We used the services of BackLinks.com, as they operate only on sites under their control, avoiding impact on unaware site owners. This choice brings certain constraints, such as the pool of available backlink sites and daily backlink deletion limits, but these can be alleviated by using other or multiple backlink providers. We bought backlinks if they were located in a subnet not covered by any already purchased site, but had to use OCR as the URLs on which links would be placed were only available as warped images. We curated the set of backlinks through manual verification to compensate for errors, increasing our required effort.

**Cost and Time Trade-off:**
The cheapest type of backlink costs USD 0.25 a month, but there were not enough such pages to cover the necessary number of subnets, so more expensive backlinks were also required. Some backlinks were found organically by Majestic, incurring no additional cost. Through a subscription on Majestic’s services, backlinks can be submitted explicitly for crawling, with a minimum cost of USD 49.99 for one month.

We bought backlinks for our test domain and curated them for two and a half months to capture as many subnets as possible while managing the monetary cost. Our total cost was USD 500. We successfully inserted our domain, with Figure 9 showing the achieved rankings and the relation between the rank and the number of found subnets for all ranked sites as published by Majestic.

There is a trade-off between cost and time: if the monetary cost should be kept low, more time is needed as the set of eligible backlink pages is smaller and backlinks will need to be deleted. Alternatively, a higher number of possibly more expensive backlinks would allow achieving the necessary number of subnets more quickly but at a higher monetary cost. Conversely, because Majestic considers links for at least 120 days, the cost for long-term manipulation is relatively limited. Even though we stopped buying backlinks and these subsequently disappeared, our ranking was maintained for more than two months as previously found backlinks were still counted.

#### Reflected URLs
An alternative technique we discovered, which does not require purchasing services from external parties, is to leverage websites that reflect a GET parameter into a link. To discover web pages that reflect a URL passed as a parameter, we started crawling 2.8 million domains from the four lists, finding additional pages by following links from the homepage of these domains. If GET parameters were found on the page, we replaced each one with a URL and tested whether this URL was then included in the href of an a tag on the page.

Through this crawl, we found that certain MediaWiki sites were particularly susceptible to reflecting URLs on each page, depending on the configuration of the site. We tested this reflection on the wikis from a number of data sources: the root domains and subdomains containing wiki of the four top lists, the set of wikis found by Pavlo and Shi in 2011 [59], and the wikis found by WikiTeam. As the reflection is purely achieved through altering the GET parameters, we do not permanently alter the wiki.

Given the special construction of their URLs, the pages reflecting our domain will not be found organically by Majestic. The list of affected URLs can be submitted directly to Majestic, but this requires a subscription. The links can also be placed on one aggregating web page: by verifying ownership of the hosting domain with Majestic, a crawl of this page and subsequently of the links placed on it can be triggered for free; alternatively, using Majestic’s site to request the freely available subset of backlinks data for this special web page also seems to trigger this crawl.

Through our crawls, we found 1,041 pages that reflected the URL of our test domain when passed in a GET parameter. By submitting these reflecting URLs to Majestic’s crawler, we successfully ranked our domain, with Figure 9 showing the achieved rankings over time. This technique allows constructing backlinks at no monetary cost but requires a high effort to find appropriate pages. We found only small subsets of wikis and domains in general to reflect our URL, so the number of pages and subnets that can be discovered using this technique may not be sufficient to achieve very high rankings. Given a deeper crawl of pages, more sites that reflect URLs passed through a GET parameter may be found, covering more subnets and achieving a higher ranking. Moreover, an attacker can resort to more aggressive techniques where URLs are permanently stored on pages or XSS vulnerabilities are exploited.

Once found, a reflecting URL will be counted indefinitely: a site would effectively have to be reconfigured or taken offline for the backlink to disappear. This means maintaining a rank comes at no additional cost. Furthermore, every website that is susceptible to URL reflection can be leveraged to promote any number of attacker-chosen (fake) domains, at the cost of submitting more (crafted) URLs to Majestic. This means manipulation of Majestic’s list is also possible on a large scale.

#### Alternatives

**Hosting Own Sites:**
Using domains seen in passive DNS measurements, Tajalizadehkhoob et al. [67] identified 45,434 hosting providers in 2016, with a median address space of 1,517 IP addresses. Based on these figures, the number of subnets available through hosting providers is well above the threshold to be ranked by Majestic. An attacker could set up websites on a sufficient number of these providers, all with a link back to the domain to be ranked. By making all the websites link to each other, a larger set of domains could easily be ranked. This technique incurs a high cost in effort, as setting up accounts with these providers is very likely to require a lot of manual effort, as well as in monetary cost, as a subscription needs to be bought for each hosting provider.

**Pingbacks:**
Content management systems such as WordPress provide a pingback mechanism for automatically reporting URLs that link to one of the pages hosted on that system. Many sites will then insert a link back to the reported URL on that page. By finding a set of domains supporting pingbacks (similar to finding wikis) and reporting a URL on the domain we want to see ranked, we could again have links to our domain on a large set of domains and therefore subnets. However, this permanently changes pages on other websites, and although enabling the pingback feature implies some consent, we opted not to explore this technique for ethical reasons.

### Quantcast

Quantcast mainly obtains traffic data through its tracking script that webmasters install on their website. We extracted the reporting algorithm from the tracking script and automatically sent requests to Quantcast from a set of 479 VPN servers located in the United States, as Quantcast’s ranking only takes US traffic into account. We sent requests for 400 generated users per day, presenting ourselves as a new user on the first request and subsequently reusing the generated token and received cookie in four more requests. Unlike Alexa’s tracking script, reporting page views for only new users did not result in any visits being counted.

Our forged requests were acknowledged by Quantcast, and its analytics dashboard reported that on May 30, 2018, "the destination reaches over 6,697 people, of which 6,696 (100%) are in the U.S." The latter metric is used to determine the rank. However, our test domain has not appeared in the ranking, likely due to the short age of our domain. Although we sent requests for more than a month, Quantcast’s slow update frequency means its ranking algorithm may not yet take our domain into account.

As Quantcast publishes the number of visits counted for each ranked domain, the relation between the desired rank and required effort is known, as shown in Figure 10. Up to around 5,000 visits, the achieved rank remains relatively low, primarily containing quantified sites that are ranked even with almost no visits. Above 5,000 visits, Quantcast’s list includes many more domains for which a rank is estimated. Especially at worse ranks, large blocks of estimated domains are interspersed with quantified domains, so increasing the number of visits to jump across such a block gives a large improvement in rank. If a rank were assigned to our domain, we would theoretically be given a rank around 367,000. Achieving higher ranks only requires submitting more forged requests, so the increased cost in time and effort is minimal.

Quantcast will only start processing traffic data once it has verified (through crawling) that its tracking pixel is present on the domain. It is therefore required to register the domain and set up a real website to manipulate the rankings, so scaling to multiple domains incurs a higher cost. Quantcast’s analytics platform itself is free, limiting the additional cost. As Quantcast performs the check only once, the domain and the website do not need to be sustained. Merely registering for tracking may even suffice to be ranked: over 2,000 domains are ranked but reported to have 0 visits, with over half registered by DirectEmployers as discussed in Section III-C.

### Improving Top Websites Ranking

Our experiments show that the different methods used to generate popularity rankings cause undesirable effects on their properties, potentially swaying the results and conclusions of studies. Researchers are prone to ignore or be unaware of these effects. We also proved that these rankings show several pitfalls that leave them vulnerable to large-scale manipulation, further reducing their reliability and suitability for research. Nevertheless, popularity rankings remain essential for large-scale empirical evaluations, so we propose improvements to existing rankings and a new ranking geared towards research.

#### Defending Existing Rankings Against Manipulation

Even though the methods for data collection and processing of the existing lists are usually unknown, our experiments suggest that their providers employ little defense against large-scale manipulation. We outline techniques that the providers could use to make these lists more resilient to attacks.

**Detecting and Deterring Fraud:**
Ensuring that all data used in ranking domains is valid is crucial. Alexa and Quantcast rely on the reporting of page visits. Techniques have been designed to subvert click inflation within the realm of online advertising. Since not all attempts at manipulating Alexa’s ranking were successful, this may imply that Alexa already employs some of these tactics.

To deter large-scale manipulation, ranking providers could employ tactics that increase the effort and resources required to affect many domains to prohibitive levels. This avoids significant influence on research results, even if these tactics may not stop small-scale manipulation.

For a traffic reporting extension, the profile setup could be tied to an account at an online service. While a normal user can easily create one account, creating many accounts in an automated way can be countered by techniques that try to detect fake accounts. For Alexa, given its ownership by Amazon, requiring an Amazon account would be a natural choice. A field for such an account ID is available when registering the extension but is not required.

This technique is not useful for tracking scripts, as no user interaction can be requested, and fraud detection as discussed earlier may be required. For providers that use both, the two metrics can be compared to detect anomalies where only one source reports significant traffic numbers, as we suspect such manipulation is already happening for Alexa Certify.

**Filtering Data by IP Address:**
Data could be filtered based on the IP address from which it originates. Ignoring requests from ranges belonging to cloud providers or requiring requests to come from ranges known to belong to Internet service providers (e.g., through its autonomous system) does not block a single user from reporting their traffic. However, using many IP addresses concurrently is prevented as these cannot be easily obtained within the permitted ranges. This technique is particularly useful for Umbrella’s list; for the other lists, using many IP addresses is not strictly necessary for large-scale manipulation.

**Alternatives:**
Quantcast states that it also uses traffic data from ‘ISPs and toolbar providers’ [64]. ISPs sell traffic data to third parties, and Quantcast may be buying these services to generate the number of page visits and, therefore, the rank for non-quantified websites. However, we cannot determine which ISPs may be used. As for extensions, we were unable to discover any extensions reporting to a URL that was obviously related to Quantcast.

**Ethical Considerations:**
Because our experiments may have a large impact on the reputation of the rankings and potentially affect third parties, we conducted an ethical review of our experimental methods. Such reviews have been advocated for by the academic community [58] and ensure that the potential damage inflicted is minimized. We base this review on the principles outlined in the relevant literature.