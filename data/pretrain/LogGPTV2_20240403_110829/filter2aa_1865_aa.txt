Breaking Forensics Software:
Weaknesses in Critical Evidence Collection
Tim Newsham - 
Chris Palmer - 
Alex Stamos - 
iSEC Partners, Inc
115 Sansome Street, Suite 1005
San Francisco, CA 94104
http://www.isecpartners.com
July 1, 2007
Abstract
This article presents speciﬁc vulnerabilities in common forensics tools that were not previously known
to the public. It discusses security analysis techniques for ﬁnding vulnerabilities in forensic software, and
suggests additional security-speciﬁc acceptance criteria for consumers of these products and their forensic
output. Traditional testing of forensics software has focused on robustness against data hiding techniques
and accurate reproduction of evidence. This article argues that more security focused testing, such as that
performed against security-sensitive commercial software, is warranted when dealing with such critical
products.
Note: Due to the deadline for submitting presentation materials to Black Hat and the ongoing nature
of our conversation with Guidance Software, we are unable to present in this revision of the paper all
the details of the defects in EnCase that we found.
By the time you read this, this version of the
paper will be out of date and the canonical version may have the defect details.
Please see https:
// www. isecpartners. com/ blackhat to ﬁnd the most recent version of this paper as well as several of
the tools we created during our research.
1
Introduction
This article presents speciﬁc vulnerabilities in common forensics tools that were not previously known to
the public, discusses techniques for ﬁnding vulnerabilities in forensic software, and recommends additional
security-speciﬁc acceptance criteria buyers should apply. The primary contribution of this work is to take
an adversarial look at forensics software and apply fuzzing and vulnerability assessment common to analysis
of other products, such as operating systems or oﬃce suites, to forensic software.
Two popular software packages for performing forensic investigations on computer evidence, Guidance
EnCase and Brian Carrier’s The Sleuth Kit (TSK), are vulnerable to attack. The most common problems
are “crashers”, that is, damaged data ﬁles, storage volumes, and ﬁlesystems which cause the software to
crash before the forensic analyst can interpret the evidence.
http://www.isecpartners.com
1/12
We performed some random and targeted fault injection testing against the two products and uncovered
several bugs, including data hiding, crashes that result in denial of service, and inﬁnite loops that cause the
program to become unresponsive.
2
Prior Art
While blind fuzzing and targeted fault injection are not new techniques, there has not been much (public)
research into the relatively small niche of forensics software.
There is not much on EnCase or TSK in the Common Vulnerabilities and Exposures database1, for
example. Searching on “encase” in the CVE search engine returns only one result (at the time of writing, 28
June 2007), http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2005-1578 (“EnCase Forensic Edi-
tion 4.18a does not support Device Conﬁguration Overlays (DCO), which allows attackers to hide information
without detection”). Searching CVE for “sleuth” (http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=
sleuth) and “sleuthkit” (http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=sleuthkit) return 0 re-
sults, and a searching on “sleuth kit” returns results containing the word “kit” but not “sleuth”.
3
Classes of Attacks Against Forensic Software
Forensic software is especially diﬃcult to secure, yet must be especially robust against attack. It must
acquire data from any type of device, in any format; it must parse, render, and search as many data formats
as possible; and it must do all this with acceptable performance without sacriﬁcing correctness or accuracy
— in the presence both of malicious tampering and of accidental faults in the evidence.
In a forensic investigation, denial of service (DoS) vulnerabilities are no longer merely annoyances, but
can impede the investigation, making evidence diﬃcult or impossible to examine. “Crasher” bugs (often the
result of the overﬂow of buﬀers on the stack or heap) are sometimes exploitable, leading to a situation in
which a maliciously crafted evidence ﬁle might allow an attacker to frustrate analysis or possibly execute
code on the investigator’s workstation2. This may compromise the integrity of investigations performed on
the machine (or allow a lawyer to argue the point).
3.1
Data Hiding
The purpose of forensic software is to discover and analyze evidence stored on digital media. If the
software fails to detect information on the medium for some reason, an attacker could exploit the weakness
to hide evidence. For example, a data acquisition tool is vulnerable to a data hiding attack if it fails to
acquire the host protected area of a hard disk.
Note that we do not include cryptography as a data hiding attack because, while it may be uninter-
pretable, encrypted information is still visible.
Another type of data hiding attack is the “attack by tedium”: where there exist asymmetries such that
an attacker can obfuscate data more easily than the forensic investigator can unobfuscate it, the eﬀect can
1http://cve.mitre.org/
2To be clear, we have not found any code execution vulnerabilities.
http://www.isecpartners.com
2/12
be similar to a steganographic attack. This method of attack is relatively weak since it relies on the usability
aﬀordances of a particular forensic software kit. A determined investigator could defeat the attack by using
multiple software kits or scripting the toolkit for automated evidence analysis, for example.
3.2
Code Execution, Evidence Corruption
Code execution vulnerabilities result from particular implementation ﬂaws such as stack and heap over-
ﬂows. Programming errors in native code may allow an attacker to specify data that overwrite control ﬂow
information in the program and provide new code of the attacker’s choice to be executed in the context of
the vulnerable process (including accessing ﬁles and the network).
If an attacker succeeds in executing arbitrary code on the forensic workstation, such as by exploiting a
buﬀer overﬂow in one of the data format parsers or renderers, he can — among a vast array of other things
— cause the forensic image to become corrupted, hiding or destroying evidence. A subtle attack would be
to cause the forensic toolkit not to alter the forensic image, but simply to ignore the evidence the attacker
wishes to hide. There would be no obvious tip-oﬀ that an attack has occured, such as if the checksums of the
evidence ﬁles changed, yet the toolkit would be instructed by the attacker never to reveal the incriminating
evidence.
All the usual “mundane” attacks are of course also possible, such as planting spyware or other malware
on the forensic workstation.
Bugs that allow an attacker to overwrite memory, even without arbitrary code execution, could also
allow an attacker to spoil or hide evidence3.
3.3
Denial of Service, Blocking Analysis
Denial of service vulnerabilities (when the program crashes or hangs) frustrate forensic analysis. If an
attacker hides the incriminating evidence in a ﬁle that crashes the forensic software but does not crash the
attacker’s own ﬁle viewer (and we observed many instances of this type of bug), the analyst must perform
extra work to discover the evidence. If the analyst is diligent, the attack is a mere service downgrade (the
analyst loses the rich search and parse functionality of their forensic tool). If the analyst is overworked, on
a tight deadline, or lazy, they might miss important evidence.
This might seem minor, but note that the sophisticated searching, parsing, key recovery, and ﬁle carving
features are the entire reason forensic software toolkits exist as a distinct class of software. Forensic analysis
can of course be done with nothing but a write-blocker and the standard Unix tools, but few professional
analysts would be satisﬁed with such a limited toolbox. Until forensic toolkits become more robust, analysts
may be in the dark without knowing it.
4
Techniques Used to Find Vulnerabilities
Because one of the most obvious attack surfaces on forensic software is the ﬁlesystem metadata parsing
code and the rich data ﬁle parsing and rendering code, we attacked it by generating fuzzed ﬁlesystems and
3We do not know of any such defects.
http://www.isecpartners.com
3/12
data ﬁles. We also made attempts to hide data by making disks with many partitions, and deeply-nested
archive ﬁles (TAR, ZIP, etc.).
4.1
Fuzzing Data Formats
We did not need sophisticated fuzzing to discover many of the vulnerabilities. We used simple random
fuzzing with no special provision for the particulars of any given data format. The fuzzer is instantiated
with a random seed and provides a set of mutator functions; when fed source data, one of the mutators is
chosen and invoked on the source. iSEC has a library of mutators that can
• randomly choose a substring (of random length) of the source and replace it with a random string of
the same size;
• replace a random number of single bytes in the source with random bytes;
• increment or decrement a random number of single bytes in the source;
• replace a randomly-selected NUL byte or sequence of two NULs in the source with a given value of the
same size;
• replace the entire source with a random string of the same size;
• overwrite 32-bit values in the source with some other given 32-bit value, advancing the replacement
position on successive calls;
• delete or insert a randomly-selected substring (of random size) from the source; and
• randomly choose any two mutators and perform both mutations on the source.
When fuzzing disk and volume images we did not use the mutators that change the size of the object,
since ﬁlesystems are based on ﬁxed-size blocks with many structures expected to be aligned at particular
oﬀsets. Perturbing a ﬁlesystem too drastically tends to cause implementations to reject it completely, with
no chance of bug discovery.
We fuzzed otherwise normal data ﬁles (JPEGs, PDFs, MS Word documents, etc.), volumes and parti-
tions, and disk device images. Each successive fuzzing target also includes the previous targets, but also
fuzzes more data: fuzzing partitions aﬀects ﬁlesystem metadata and ﬁle data; and fuzzing disks aﬀects par-
tition metadata, ﬁlesystem metadata, and ﬁle data). We then performed appropriate tasks for the object
with the forensic application: viewing and acquiring disks and volumes, viewing and searching ﬁles, etc.
4.2
Manual, Targeted Manipulation of Data Formats
We also performed targeted, manual mangling of data formats, such as by creating directory loops in
ﬁlesystems, creating loops in MBR partition tables, creating disk images with very many partitions, tweaking
data objects in JPEG ﬁles that inﬂuence memory management, and so on.
MBR partition tables. We wrote code to identify all of the MBR records and performed fuzzing on only
those blocks. The fuzzing was again simplistic. The reason we did this was to increase the amount
of mutations in each test case (since we can only test one disk at a time, whereas we can test many
http://www.isecpartners.com
4/12
ﬁlesystems at a time, for example) without causing other issues (i.e. in the ﬁlesystem code) that might
mask ﬁndings.
Directory loops. We manually edited ext2fs and NTFS ﬁlesystems so that a directory became a child
subdirectory in its own directory, and then analyzed the resulting image.
Long ﬁle names. We generated ﬁlesystems with very long ﬁle names. These were created both inside a
single directory and in a chain of deeply nested directories.
Large directories. We generated ﬁlesystems with a directory containing large numbers of ﬁles. These were
ﬁlled with ﬁles having really short names, medium length names and long ﬁlenames.
Deeply nested directories. We generated ﬁlesystems with deeply nested directories. The directory names
were very short and very long.
5
Defects Found in The Sleuth Kit
Brian Carrier’s The Sleuth Kit (TSK) is a tool-oriented forensic software suite in the Unix tradition
(although it does run on Windows in addition to Linux, Mac OS X, and other Unix variants). Individual
programs with command-line interfaces each do one task — extracting inode metadata from a disk image,
copying data referenced by an inode to a ﬁle — and to work together by reading and writing streams of text.
It is implemented in C and tied together by a web interface implemented as Perl CGIs (Autopsy).
In contrast to EnCase, TSK almost completely relegates evidence display to third-party software. TSK
consists of 23 separate single-purpose programs, but we found vulnerabilities in only a few:
ﬂs lists the ﬁle and directory names in a give ﬁlesystem image, including deleted ﬁles;
fsstat displays the metadata for the ﬁlesystem, including inode numbers and mount times;
icat copies ﬁles in the disk image by inode number (Unix ﬁlesystems) or MFT entry number (NTFS), as
discovered and chosen by the investigator using e.g. the istat tool; and
istat displays the metadata stored in an inode or MFT entry;
Simple fuzzing raised several issues, and the inherent programmability of Unix-type tools allowed us to
easily isolate the particular spot in damaged ﬁles that was causing the problem. In general it appears that
the implementation is suﬃciently careful about keeping buﬀer writes in bounds, but it places too much trust
in the data from the disk image when reading from buﬀers. Most issues involve out-of-bounds reads that
can lead to incorrect data, or crashes. There were also some issues that may lead to denial of service.
5.1
Data Dereferenced After Free
A crash can occur when processing a corrupted ext2fs image because the error processing code derefer-
ences data after it frees it. In ext2fs.c:
1230
f o r
(n = 0 ;
length > 0 && n d i r e c t c o u n t ;
n++) {
1231
read b = e x t 2 f s
f i l e
w a l k
d i r e c t ( fs ,
buf ,
length ,
1232
inode−>d i r e c t a d d r [ n ] ,
f l a g s ,
action ,
ptr ) ;
1233
1234
i f
( read b == −1) {
http://www.isecpartners.com
5/12
1235
f r e e ( buf ) ;
1236
d a t a b u f f r e e ( buf [ 0 ] ) ;
1237
return
1 ;
1238
}
If read b is -1 (line 1234) then buf is freed (line 1235) before data in buf[0] is freed (line 1236). This
leads to a crash on some systems.
5.1.1
Reproduction
$
patch . py
NtfsPart . dsk Bad . dsk
7616332
\x01
$
i c a t
Bad . dsk 56−128−3
5.2
Corrupted NTFS image Causes icat to Run Indeﬁnitely
icat runs virtually forever when run on some altered NTFS images. It appears that a 64-bit value was
read oﬀ the disk and used as a byte count. We observed the following in gdb:
#9
0 x080892ef
in
n t f s d a t a w a l k
( n t f s=0x80ee0c0 ,
inum=56,
f s d a t a=0x80f0400 ,
f l a g s =0,
a ct i o n=0x80a45d0 ,
ptr=0x0 )
at
n t f s . c :1639
1639
r e t v a l = a ct i o n ( fs ,
addr ,
buf ,
b u f s i z e ,
myflags ,
ptr ) ;
( gdb )
p/x
f s i z e
\$3 = 0 x f f f f f f f f f f 8 e c d 4 2
( gdb )
p/x
fs dat a −>s i z e
\$4 = 0x9342
( gdb )
p/x
fs dat a −>runlen
\$5 = 0 x f f f f f f 0 6 0 0 0 0 9 2 0 0
5.2.1
Reproduction
$
patch . py
NtfsPart . dsk Bad . dsk
7616332
\x01
$