# 八、Pod 放置控制
本章描述了在 Kubernetes 中控制 Pod 放置的各种方法，并解释了为什么首先实现这些控制可能是一个好主意。Pod 放置意味着控制 Pod 在 Kubernetes 中被调度到哪个节点。我们从像节点选择器这样的简单控件开始，然后转向像污点和容忍这样的更复杂的工具，最后是两个 beta 特性，节点相似性和 Pod 间相似性/反相似性。
在过去的章节中，我们已经了解了如何在 Kubernetes 上最好地运行应用 Pods–从使用部署来协调和扩展它们，使用配置映射和机密注入配置，到使用持久卷来添加存储。
然而，在所有这些过程中，我们一直依赖于 Kubernetes 调度程序来将 Pods 放在最佳节点上，而没有给调度程序很多关于所讨论的 Pods 的信息。到目前为止，我们已经在 Pod 中添加了资源限制和请求(`resource.requests`和`resource.limits`)。资源请求指定了 Pod 需要的节点上的最小空闲资源级别，以便进行调度，而资源限制则指定了 Pod 允许使用的最大资源量。但是，我们没有对 Pod 必须运行的节点或节点集提出任何具体要求。
对于许多应用和集群来说，这很好。然而，正如我们将在第一节中看到的，在许多情况下，使用更细粒度的 Pod 放置控件是一种有用的策略。
在本章中，我们将涵盖以下主题:
*   确定 Pod 放置的用例
*   使用节点选择器
*   实施污点和宽容
*   用节点相似性控制 Pods
*   使用 Pod 间亲和力和反亲和力
# 技术要求
为了运行本章中详细介绍的命令，您将需要一台支持`kubectl`命令行工具的计算机以及一个工作正常的 Kubernetes 集群。参见 [*第一章*](01.html#_idTextAnchor016)*与 Kubernetes*通讯，了解几种快速与 Kubernetes 一起起床跑步的方法，以及如何安装`kubectl`工具的说明。
本章使用的代码可以在本书的 GitHub 资源库中找到[https://GitHub . com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/chapter 8](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter8)。
# 确定 Pod 放置的用例
Pod 放置控件是 Kubernetes 提供给我们的工具，用于决定在哪个节点上调度 Pod，或者何时由于缺少我们想要的节点而完全阻止 Pod 调度。这可以用于几种不同的模式，但是我们将回顾几种主要的模式。首先，Kubernetes 本身在默认情况下完全实现了 Pod 放置控件——让我们看看如何实现。
## Kubernetes 节点健康放置控件
Kubernetes 使用一些默认的放置控件来指定哪些节点在某种程度上是不健康的。这些通常是使用污点和容忍来定义的，我们将在本章后面详细讨论。
Kubernetes 使用的一些默认污点(我们将在下一节中讨论)如下:
*   `memory-pressure`
*   `disk-pressure`
*   `unreachable`
*   `not-ready`
*   `out-of-disk`
*   `network-unavailable`
*   `unschedulable`
*   `uninitialized`(仅针对云提供商创建的节点)
这些条件可以将节点标记为无法接收新的 Pods，尽管调度程序处理这些污点的方式有一定的灵活性，我们将在后面看到。这些系统创建的放置控制的目的是防止不健康的节点接收可能无法正常工作的工作负载。
除了系统为节点运行状况创建的放置控制之外，还有几个用例，作为用户，您可能希望实现微调调度，我们将在下一节中看到。
## 需要不同节点类型的应用
在异构的 Kubernetes 集群中，每个节点不是平等创建的。您可能有一些功能更强大的虚拟机(或裸机)和一些功能更弱的虚拟机，或者有不同的专用节点集。
例如，在运行数据科学管道的集群中，您可能有具有 GPU 加速功能的节点来运行深度学习算法，有常规计算节点来服务于应用，有大量内存的节点来根据已完成的模型进行推理，等等。
使用 Pod 放置控件，您可以确保平台的各个部分在最适合手头任务的硬件上运行。
## 需要特定数据合规性的应用
类似于前面的示例，其中应用需求可能要求不同类型的计算，某些数据合规性需求可能要求特定类型的节点。
例如，AWS 和 Azure 等云提供商通常允许您购买具有专用租赁的虚拟机，这意味着底层硬件和虚拟机管理程序上不会运行其他应用。这不同于其他典型的云提供商虚拟机，在这些虚拟机中，多个客户可能共享一台物理机。
对于某些数据法规，需要此级别的专用租赁来保持合规性。为了满足这一需求，您可以使用 Pod 放置控制来确保相关应用仅在具有专用租赁的节点上运行，同时通过在没有控制平面的更典型虚拟机上运行控制平面来降低成本。
## 多租户集群
如果您正在运行一个具有多个租户的集群(例如，由名称空间分隔)，您可以使用 Pod 放置控件为一个租户保留特定的节点或节点组，以物理方式或其他方式将它们与集群中的其他租户分开。这类似于 AWS 或 Azure 中专用硬件的概念。
## 多个故障域
虽然 Kubernetes 已经通过允许您调度在多个节点上运行的工作负载来提供高可用性，但是扩展这种模式也是可能的。我们可以创建自己的 Pod 调度策略，解决跨多个节点的故障域。处理这个问题的一个很好的方法是通过 Pod 或节点相似性或反相似性特性，我们将在本章后面讨论。
现在，让我们将一个案例概念化，在这个案例中，我们的集群位于裸机上，每个物理机架有 20 个节点。如果每个机架都有自己的专用电源连接和备份，则可以将其视为故障域。当电源连接出现故障时，机架上的所有机器都会出现故障。因此，我们可能希望鼓励 Kubernetes 在单独的机架/故障域上运行两个实例或 Pods。下图显示了应用如何跨故障域运行:
![Figure 8.1 – Failure domains](img/B14790_08_001.jpg)
图 8.1–故障域
如图所示，由于应用单元分布在多个故障域中，而不仅仅是同一故障域中的多个节点，因此即使*故障域 1* 发生故障，我们也可以保持正常运行时间。*App-A-Pod 1*和*App-B- Pod 1*处于同一个(红色)故障域。但是，如果该故障域(*机架 1* )关闭，我们仍将在*机架 2* 上拥有每个应用的副本。
我们在这里使用“鼓励”这个词，因为在 Kubernetes 调度程序中，可以将某些功能配置为硬要求或尽力而为。
这些示例应该让您对高级放置控件的一些潜在用例有一个坚实的理解。
现在让我们逐一讨论每个放置工具集的实际实现。我们将从最简单的节点选择器开始。
# 使用节点选择器和节点名称
节点选择器是 Kubernetes 中一种非常简单的布局控件。每个 Kubernetes 节点都可以在元数据块中用一个或多个标签进行标记，Pods 可以指定一个节点选择器。
要标记现有节点，可以使用`kubectl label`命令:
```
> kubectl label nodes node1 cpu_speed=fast
```
在这个例子中，我们用标签`cpu_speed`和值`fast`来标记我们的`node1`节点。
现在，让我们假设我们有一个真正需要快速 CPU 周期来有效执行的应用。我们可以在工作负载中添加一个`nodeSelector`，以确保它只安排在具有快速 CPU 速度标签的节点上，如下面的代码片段所示:
带有节点选择器的 pod . YAML
```
apiVersion: v1
kind: Pod
metadata:
  name: speedy-app
spec:
  containers:
  - name: speedy-app
    image: speedy-app:latest
    imagePullPolicy: IfNotPresent
  nodeSelector:
    cpu_speed: fast
```
部署时，作为部署的一部分或单独部署，我们的`speedy-app` Pod 将仅在带有`cpu_speed`标签的节点上进行调度。
请记住，与我们稍后将回顾的一些其他更高级的 Pod 放置选项不同，节点选择器中没有回旋余地。如果没有具有所需标签的节点，则根本不会调度应用。
对于更简单(但更脆弱)的选择器，您可以使用`nodeName`，它指定了 Pod 应该被调度的确切节点。你可以这样使用它:
带有节点名的 pod . YAML
```
apiVersion: v1
kind: Pod
metadata:
  name: speedy-app
spec:
  containers:
  - name: speedy-app
    image: speedy-app:latest
    imagePullPolicy: IfNotPresent
  nodeName: node1
```
正如你所看到的，这个选择器将只允许 Pod 被安排在`node1`上，所以如果它当前由于任何原因没有接受 Pod ，Pod 将不会被安排。
对于稍微细致的位置控制，让我们继续讨论污点和容忍。
# 实施污染和容忍
Kubernetes 中的污点和容忍就像反向节点选择器一样工作。节点不会因为有适当的标签而吸引 Pods，这些标签会被选择器使用，我们会污染节点，这会阻止所有 Pods 在节点上被调度，然后用容忍标记我们的 Pods，这允许它们在被污染的节点上被调度。
正如本章开头提到的，Kubernetes 使用系统创建的污点将节点标记为不健康，并阻止在它们上面安排新的工作负载。例如，`out-of-disk`污点将阻止任何新的 PODS 被安排到带有该污点的节点。
让我们使用与节点选择器相同的用例，并使用污点和容忍来应用它。由于这基本上与我们之前的设置相反，让我们首先使用`kubectl taint`命令给节点一个污点:
```
> kubectl taint nodes node2 cpu_speed=slow:NoSchedule
```
让我们把这个命令拆开。我们给`node2`一个名为`cpu_speed`的污点和一个值`slow`。我们也用一个效果来标记这个污点——在这个例子中是`NoSchedule`。
一旦我们完成了我们的示例(如果您正在跟随命令，请不要这样做)，我们可以使用减运算符删除`taint`:
```
> kubectl taint nodes node2 cpu_speed=slow:NoSchedule-
```
`taint`效果让我们在调度器处理污点的方式上增加了一些粒度。有三种可能的影响值:
*   `NoSchedule`
*   `NoExecute`
*   `PreferNoSchedule`
前两个效果`NoSchedule`和`NoExecute`提供了硬效果——也就是说，像节点选择器一样，只有两种可能性，要么在 Pod 上存在容忍(我们稍后会看到)，要么 Pod 没有被调度。`NoExecute`通过驱逐节点上所有有容忍能力的 PODS 来增加这个基本功能，而`NoSchedule`让现有 PODS 留在原地，同时防止任何没有容忍能力的新 PODS 加入。
`PreferNoSchedule`另一方面，为 Kubernetes 调度器提供了一些回旋余地。它告诉调度程序尝试为 Pod 找到一个没有不可容忍的污点的节点，但是如果不存在污点，继续进行调度。它实现了柔和的效果。
在我们的例子中，我们选择了`NoSchedule`，所以不会给节点分配新的 Pods 当然，除非我们提供了一个宽容。我们现在就开始吧。假设我们有第二个不关心 CPU 时钟速度的应用。它很高兴生活在我们较慢的节点上。这是 Pod 清单:
无速度要求的 Pod 
```
apiVersion: v1
kind: Pod
metadata:
  name: slow-app
spec:
  containers:
  - name: slow-app
    image: slow-app:latest
```
现在，我们的`slow-app` Pod 不会在任何有污点的节点上运行。我们需要为这个 Pod 提供一个容忍度，以便将其安排在有污点的节点上——我们可以这样做:
宽容的 PODS
```
apiVersion: v1
kind: Pod
metadata:
  name: slow-app
spec:
  containers:
  - name: slow-app
    image: slow-app:latest
tolerations:
- key: "cpu_speed"
  operator: "Equal"
  value: "slow"
  effect: "NoSchedule"
```
让我们分离我们的`tolerations`条目，它是一个值数组。每个值都有一个`key`，这和我们的污点名称是一样的。然后还有一个`operator`值。这个`operator`可以是`Equal`也可以是`Exists`。对于`Equal`，您可以像前面的代码一样使用`value`键来配置一个污点必须相等的值，以便 Pod 能够容忍。对于`Exists`，污点名称必须在节点上，但值是什么并不重要，如本 Pod 规范中所示:
宽容的 PODS 2.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: slow-app
spec:
  containers:
  - name: slow-app
    image: slow-app:latest
tolerations:
- key: "cpu_speed"
  operator: "Exists"
  effect: "NoSchedule"
```
如你所见，我们已经使用`Exists` `operator`值来允许我们的 Pod 容忍任何`cpu_speed`污染。
最后，我们有了我们的`effect`，它的工作方式与污点本身的`effect`相同。它可以包含与污点效应完全相同的值–`NoSchedule`、`NoExecute`和`PreferNoSchedule`。
一个具有`NoExecute`耐受性的 PODS 将无限期地忍受与之相关的污染。但是，您可以添加一个名为`tolerationSeconds`的字段，以便让 Pod 在规定的时间过后离开受感染的节点。这允许您指定一段时间后生效的容忍。让我们看一个例子:
宽容的 PODS 3.yaml