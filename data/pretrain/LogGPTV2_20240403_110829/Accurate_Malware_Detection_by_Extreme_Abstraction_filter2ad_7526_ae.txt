We are unaware of previous work on intentional abstraction of the
operating system for the purposes of malware analysis. In [3], the
authors use an abstraction of program behavior, but it is created
from a concrete operating system. Similarly, the authors of [25]
describe their method as “abstracting the API calls", but in practice
they are using the API call sequence as an abstraction of the be-
havior seen on a concrete system; [11] use the term “abstraction"
in this sense as well. In [24], malware detection is performed by
abstract interpretation, which is an analysis technique that uses
successive sound approximations of the semantics of computer pro-
grams, and is distinct from our loose and unsound approximations.
Furthermore the work uses a synthetic programming language, and
no reference is made to the operating system.
109
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
F. Copty et al.
protecting programs with obfuscation, while in contrast our work is
aimed at malware classication. Finally, they attempt complete code
coverage as a way to nd all functionality, while we use extreme
abstraction as a way to elicit as much functionality as possible.
4.3 Malware classication
Malware classication using machine learning methods is an active
research area. The research can be roughly divided to works based
on features extracted from the static binary les, and to models
that employ sample execution inside a sandbox or another isolation
environment.
Static analysis. In [27], the authors extract various features
from the PE header and content to feed to the machine learning
model, whereas the authors of [26] take the opposite approach and
feed the raw bytes of the le into the machine learning model. In
constrast, we emulate the sample’s execution in an abstract envi-
ronment and gather information about its behavior, and therefore
our system is able to overcome packed and obfuscated executables
which might pose a problem to models based on static le features.
The architecture of [10] includes a decompressor, whose task is to
unpack PE les that were compressed by a binary compression tool,
such as UPX. However, this limits the system’s ability to correctly
classify malware or benign samples compressed with proprietary
packers and obfuscators, for which no standard unpacker is avail-
able. Our system, on the other hand, emulates the sample execution
through the unpacking code, reaching the actual behavior of the
original executable (whether it is benign or malicious), and there-
fore extracting enough information for an accurate classication
by the machine learning model.
Dynamic analysis. Several works suggested feeding logs of
API calls collected by a sandbox executing the sample into a ma-
chine learning model. Similar to the n-grams formed from API calls
and anti-research indicators used in our work, [6] uses 3-grams of
API calls produced by a proprietary sandbox. The authors of [22]
use Echo State Networks (ESN) and Recurrent Neural Networks
(RNN) fed from a stream of high-level events gathered from samples
analyzed in a proprietary anti-malware engine. Similar approaches
are used for the task of malware classication into malware fami-
lies: for example, the authors of [7] and [15] gather sample logs of
API calls using the Cuckoo sandbox, and then train a deep learning
model to classify each sample into its malware family.
In contrast to the above works, we use features extracted from
the logs of an extremely abstract OS. Also, all of the above works
use an API call log of one execution of each sample. In contrast, our
system uses multiple paths extracted from an extremely abstract
analysis, and aggregates information from the paths to form a
single feature vector fed into the machine learning model. This
allows our system to accurately detect malware samples that hide
their malicious behavior in some of the execution paths but not
in others. Furthermore, in contrast to the above works, we use a
funnel-based approach that saves runtime and also provides more
accurate classication.
5 FUTURE WORK
While our results are very good, every fraction of a percentage
point is important when dealing with the reality of tens or hun-
dreds of thousands of samples per day. Future work is to complete
training for layers 3 and later of the funnel in order to measure
the eectiveness of layers based on an increasing number of paths
and/or longer timeouts. Also we plan to augment the training set
with packed versions of every sample in it and to measure whether
this improves our detection rate. We also plan to explore feature
clustering of API functions based on their natural language descrip-
tions. Finally, we have started exploring the use of deep learning
for classifying sequences of events recorded during the execution
of a sample, and we have found bidirectional LSTM to be very
promising when applied to sequences of informative, suspicious
and malicious features. We plan to explore how to leverage this in
a multiple path scenario.
6 CONCLUSION
We have presented a novel approach to malware detection that
is based on extreme abstraction of the operating system, which
proves to be extraordinarily eective in distinguishing between
benign and malicious samples. We use lightweight symbols, which
can be understood as a kind of taint, to drive symbolic execution,
and we use time models as an even lighter weight alternative to
exploring multiple paths. By exploring multiple paths in a system
that only approximates the behavior of a real system, we discover
behavior that would often be hard to elicit using the real system.
By aggregating features from multiple paths into a single feature
vector that considers dierences between the paths, we achieve a
higher TPR compared to a single path analysis. By using a funnel-
like conguration of classiers, we achieve an even higher TPR,
while also reducing the average runtime from four minutes (one
minute per path) to just over one minute.
We have described TAMALES, a malware detection system based
on these ideas, in detail, and presented machine learning results on a
330K sample set (230K training, 100K test) showing an FPR of 0.10%
with a TPR of 99.11%. We have also provided experimental evidence
showing that we are learning more than just packed/unpacked or
obfuscated/unobfuscated code, and that extreme abstraction can be
useful for family classication as well.
ACKNOWLEDGMENTS
Our thanks to the following people who worked on or supported
the project in various ways: Oshri Adler, Sandy Bird, Lior Keshet,
Amit Klein, Moshe Levinger, Shmulik Regev, Tamer Salman, Mak-
sim Shudrak. The authors acknowledge the IBM Research Cognitive
Computing Cluster service for providing resources that have con-
tributed to the research results reported within this paper.
REFERENCES
[1] Sebastian Banescu, Christian S. Collberg, Vijay Ganesh, Zack Newsham, and
Alexander Pretschner. 2016. Code obfuscation against symbolic execution attacks.
In Proceedings of the 32nd Annual Conference on Computer Security Applications,
ACSAC 2016, Los Angeles, CA, USA, December 5-9, 2016. ACM, New York, NY,
USA, 189–200.
[2] Clark W. Barrett, Roberto Sebastiani, Sanjit A. Seshia, and Cesare Tinelli. 2009.
Satisability Modulo Theories. In Handbook of Satisability. IOS Press, Amster-
dam, 825–885.
110
Accurate Malware Detection by Extreme Abstraction
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
[3] Philippe Beaucamps, Isabelle Gnaedig, and Jean-Yves Marion. 2010. Behavior
Abstraction in Malware Analysis. In Runtime Verication, Howard Barringer, Ylies
Falcone, Bernd Finkbeiner, Klaus Havelund, Insup Lee, Gordon Pace, Grigore
Roşu, Oleg Sokolsky, and Nikolai Tillmann (Eds.). Springer, Berlin Heidelberg
New York, 168–182.
[4] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32.
[5] L Breiman, JH Friedman, RA Olshen, and CJ Stone. 1984. Classication and
regression trees. Wadsworth & Brooks, Monterey, CA.
[6] George E Dahl, Jack W Stokes, Li Deng, and Dong Yu. 2013. Large-scale malware
classication using random projections and neural networks. In Acoustics, Speech
and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 3422–
3426.
[7] Omid E David and Nathan S Netanyahu. 2015. Deepsign: Deep learning for
automatic malware signature generation and classication. In Neural Networks
(IJCNN), 2015 International Joint Conference on. IEEE, 1–8.
[8] Martin Davis and Hilary Putnam. 1960. A Computing Procedure for Quantica-
tion Theory. J. ACM 7, 3 (1960), 201–215.
[9] Serge Gaspers and Toby Walsh (Eds.). 2017. Theory and Applications of Satisa-
bility Testing - SAT 2017 - 20th International Conference, Melbourne, VIC, Australia,
August 28 - September 1, 2017, Proceedings. Lecture Notes in Computer Science,
Vol. 10491. Springer.
[10] William Hardy, Lingwei Chen, Shifu Hou, Yanfang Ye, and Xin Li. 2016. DL4MD:
A deep learning framework for intelligent malware detection. In Proceedings of
the International Conference on Data Mining (DMIN). The Steering Committee of
The World Congress in Computer Science, Computer Engineering and Applied
Computing (WorldComp), 61.
[11] Grégoire Jacob, Hervé Debar, and Eric Filiol. 2009. Malware Behavioral Detec-
tion by Attribute-Automata Using Abstraction from Platform and Language. In
Recent Advances in Intrusion Detection, 12th International Symposium, RAID 2009,
Saint-Malo, France, September 23-25, 2009. Proceedings (Lecture Notes in Computer
Science), Vol. 5758. Springer, Berlin Heidelberg New York, 81–100.
[12] John T Kent. 1983.
Information gain and a general measure of correlation.
Biometrika 70, 1 (1983), 163–173.
19, 7 (July 1976), 385–394.
[13] James C. King. 1976. Symbolic Execution and Program Testing. Commun. ACM
[14] Clemens Kolbitsch, Benjamin Livshits, Benjamin G. Zorn, and Christian Seifert.
2012. Rozzle: De-cloaking Internet Malware. In IEEE Symposium on Security and
Privacy, SP 2012, 21-23 May 2012, San Francisco, California, USA. IEEE Computer
Society, Washington, DC, USA, 443–457.
[15] Bojan Kolosnjaji, Apostolis Zarras, George Webster, and Claudia Eckert. 2016.
Deep learning for classication of malware system call sequences. In Australasian
Joint Conference on Articial Intelligence. Springer, 137–149.
[16] Christopher Kruegel. 2014. Full system emulation: Achieving successful auto-
mated dynamic analysis of evasive malware. (August 2014).
Process hollowing. www.autosectools.com/process-
[17] John Leitch. [n. d.].
hollowing.pdf. ([n. d.]).
[18] Tamas K. Lengyel, Steve Maresca, Bryan D. Payne, George D. Webster, Sebastian
Vogl, and Aggelos Kiayias. 2014. Scalability, Fidelity and Stealth in the DRAKVUF
Dynamic Malware Analysis System. In Proceedings of the 30th Annual Computer
Security Applications Conference (ACSAC ’14). ACM, New York, NY, USA, 386–395.
[19] Andreas Moser, Christopher Kruegel, and Engin Kirda. 2007. Limits of Static
Analysis for Malware Detection. In 23rd Annual Computer Security Applications
Conference (ACSAC 2007), December 10-14, 2007, Miami Beach, Florida, USA. IEEE
Computer Society, Washington, DC, USA, 421–430.
[20] Andreas Moser, Christopher Krügel, and Engin Kirda. 2007. Exploring Multiple
Execution Paths for Malware Analysis. In 2007 IEEE Symposium on Security and
Privacy (S&P 2007), 20-23 May 2007, Oakland, California, USA. IEEE Computer
Society, Washington, DC, USA, 231–245.
[21] Robert Moskovitch, Clint Feher, Nir Tzachar, Eugene Berger, Marina Gitelman,
Shlomi Dolev, and Yuval Elovici. 2008. Unknown Malcode Detection Using OP-
CODE Representation. In Intelligence and Security Informatics, First European
Conference, EuroISI 2008, Esbjerg, Denmark, December 3-5, 2008. Proceedings (Lec-
ture Notes in Computer Science), Vol. 5376. Springer, Berlin Heidelberg New York,
204–215.
[22] Razvan Pascanu, Jack W Stokes, Hermineh Sanossian, Mady Marinescu, and
Anil Thomas. 2015. Malware classication with recurrent networks. In Acoustics,
Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on.
IEEE, 1916–1920.
[23] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M.
Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cour-
napeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine
Learning in Python. Journal of Machine Learning Research 12 (2011), 2825–2830.
[24] Mila Dalla Preda. 2007. Code Obfuscation and Malware Detection by Abstract
Interpretation. Ph.D. Dissertation. Università degli Studi di Verona, Dipartimento
di Informatica.
[25] Yong Qiao, Yuexiang Yang, Lin Ji, and Jie He. 2013. Analyzing Malware by Ab-
stracting the Frequent Itemsets in API Call Sequences. In 12th IEEE International
Conference on Trust, Security and Privacy in Computing and Communications,
TrustCom 2013 / 11th IEEE International Symposium on Parallel and Distributed
Processing with Applications, ISPA-13 / 12th IEEE International Conference on Ubiq-
uitous Computing and Communications, IUCC-2013, Melbourne, Australia, July
16-18, 2013. IEEE Computer Society, Washington, DC, USA, 265–270.
[26] Edward Ra, Jon Barker, Jared Sylvester, Robert Brandon, Bryan Catanzaro, and
Charles Nicholas. 2017. Malware Detection by Eating a Whole EXE. arXiv
preprint arXiv:1710.09435 (2017).
[27] Joshua Saxe and Konstantin Berlin. 2015. Deep neural network based malware
detection using two dimensional binary program features. In Malicious and
Unwanted Software (MALWARE), 2015 10th International Conference on. IEEE,
11–20.
[28] Edward J. Schwartz, Thanassis Avgerinos, and David Brumley. 2010. All You
Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic
Execution (but Might Have Been Afraid to Ask). In Proceedings of the 2010 IEEE
Symposium on Security and Privacy (SP ’10). IEEE Computer Society, Washington,
DC, USA, 317–331.
[29] Marcos Sebastián, Richard Rivera, Platon Kotzias, and Juan Caballero. 2016. AV-
Class: A Tool for Massive Malware Labeling. In Research in Attacks, Intrusions,
and Defenses - 19th International Symposium, RAID 2016, Paris, France, September
19-21, 2016, Proceedings (Lecture Notes in Computer Science), Vol. 9854. Springer,
Berlin Heidelberg New York, 230–253.
[30] Michael Sikorski and Andrew Honig. 2012. Practical Malware Analysis: The
Hands-On Guide to Dissecting Malicious Software (1st ed.). No Starch Press, San
Francisco, CA, USA.
[31] Themida [n. d.]. www.oreans.com/themida.php. ([n. d.]).
[32] UPX [n. d.]. upx.github.io. ([n. d.]).
[33] VirusSign [n. d.]. www.virussign.com. ([n. d.]).
[34] VirusTotal [n. d.]. www.virustotal.com. ([n. d.]).
[35] VMProtect [n. d.]. vmpsoft.com. ([n. d.]).
[36] Kilian Q. Weinberger, Anirban Dasgupta, John Langford, Alexander J. Smola,
and Josh Attenberg. 2009. Feature hashing for large scale multitask learning.
In Proceedings of the 26th Annual International Conference on Machine Learning,
ICML 2009, Montreal, Quebec, Canada, June 14-18, 2009. ACM, New York, NY,
USA, 1113–1120.
[37] Jerey Wilhelm and Tzi-cker Chiueh. 2007. A Forced Sampled Execution Ap-
proach to Kernel Rootkit Identication. In Recent Advances in Intrusion Detection,
10th International Symposium, RAID 2007, Gold Goast, Australia, September 5-7,
2007, Proceedings (Lecture Notes in Computer Science), Vol. 4637. Springer, Berlin
Heidelberg New York, 219–235.
[38] Babak Yadegari and Saumya Debray. 2015. Symbolic Execution of Obfuscated
Code. In Proceedings of the 22Nd ACM SIGSAC Conference on Computer and
Communications Security (CCS ’15). ACM, New York, NY, USA, 732–744.
111