Compatibility with libpcap. Considering libpcap is widely
used in networking frameworks and middleboxes for packet captur-
ing [27, 49, 69, 81? ], we create an adaption layer that implements
libpcap interfaces over etap, including the commonly used packet
reading routines (e.g., pcap loop, pcap next), and (cid:128)lter routines
(e.g., pcap compile). (cid:140)is layer allows many legacy systems, in-
cluding the ones discussed in Section 5, to transparently access
protected raw packets inside the enclave.
TCP reassembly. (cid:140)is common function organizes the payloads
of possibly out-of-order packets into streams for subsequent pro-
cessing. To facilitate middleboxes demanding such functionality,
Figure 6: (cid:135)e networking stack enabled by etap.
we port a lightweight reassembly library libntoh [28] on top of
etap. It exposes a set of APIs to create stream bu(cid:130)ers for new
(cid:131)ows, add new TCP segments, and (cid:131)ush the bu(cid:130)ers with callback
functions. It is used in one of our middlebox case-studies.
Advanced networking stack. We also manage to port an ad-
vanced networking stack called mOS, which allows for program-
ming stateful (cid:131)ow monitoring middleboxes [45], into the enclave
on top of etap. As a result, a middlebox built with mOS can au-
tomatically enjoy all security and performance bene(cid:128)ts of etap,
without the need for the middlebox developer to even have any
knowledge of SGX. (cid:140)e porting is a non-trivial task as mOS has
complicated TCP context and event handling, as well as more so-
phisticated payload reassembly logic than libntoh. Our current
porting retains the core processing logic of mOS and only removes
the threading features.
Note that the two stateful frameworks above track (cid:131)ow states
themselves, so running them inside the enclave e(cid:129)ciently requires
delicate state management, as described in the next section.
4 FLOW STATE MANAGEMENT
To get rid of the expensive application-agnostic EPC paging, a
natural idea would be to carefully partition the working set of
an SGX application into two parts, a small one that can (cid:128)t in the
enclave, and a large one that can securely reside in the untrusted
main memory, while ensuring data swapping between the two in
an on-demand manner. A related idea has been positively validated
in a prior study [63]. But it still falls within the paradigm of paging,
and reports a slowdown over native processing of several factors,
even for moderate working sets of a few hundreds of MBs.
To e(cid:130)ectively implement the idea above, we design a set of novel
data structures speci(cid:128)cally for managing (cid:131)ow states in stateful
middleboxes. (cid:140)ey are compact, such that collectively adding a few
tens of MBs overhead to track one million (cid:131)ows concurrently. (cid:140)ey
are also interlinked, such that the data relocation and swapping
involves only cheap pointer operations in addition to necessary
data marshalling. To overcome the bo(cid:138)leneck of (cid:131)ow lookup, we
further leverage the space-e(cid:129)cient cuckoo hashing to create a fast
dual lookup algorithm. Altogether, our state management scheme
introduces small and nearly constant computation cost to stateful
middlebox processing, even with 100,000s of concurrent (cid:131)ows.
Note that we focus on (cid:131)ow-level states, which are the major
culprits that overwhelm memory. Other runtime states, such as
global counters and pa(cid:138)ern matching engines, do not grow with
the number of (cid:131)ows, so we leave them in the enclave and handled
by EPC paging whenever necessary. Our experiments con(cid:128)rm that
etapKernel/DPDK/NetmapPhysical NICUntrustednetworkinglibpcap adaption layerPRADSlwIDSmIDSmOSlibntohTrusted networkingSecured middleboxesEnclaveHostAlgorithm 2: Fast (cid:131)ow tracking with dual lookup
Input: A fid extracted from input packet.
Output: (cid:140)e state of (cid:131)ow fid.
1 entry = flow cache cuckoo lkup(fid);
2 if entry empty then
3
4
entry = flow store cuckoo lkup(fid);
if entry empty then
entry = flow store alloc();
check memory safety(entry);
victim = drop from rear(flow cache);
victim = encrypt(victim);
swap(entry.state, victim.state);
entry = decrypt(entry);
5
6
7
8
9
10 raise to front(entry, flow cache);
11 Return entry.state;
// flow cache miss
// flow store miss
enclave immediately a(cid:137)er (cid:131)ow tracking to avoid being accidentally
paged out. (cid:140)e full (cid:131)ow tracking procedure is described in Alg. 2.
Initialization. For e(cid:129)ciency, we preallocate entries for all three
components. During initialization, a random key is generated and
stored inside the enclave for the required authenticated encryption.
Flow tracking. Given a fid, we (cid:128)rst search through lkup table
to check if the (cid:131)ow has been tracked. If it is found in flow cache,
we will relocate it to the front of the cache by updating its log-
ical position via the pointers, and return the raw state data. If
it is found in flow store, we will swap it with the LRU victim
in flow cache. In case of a new (cid:131)ow, an empty store entry is
created for the swapping. (cid:140)e entry swapping involves a series
of strictly de(cid:128)ned operations: 1) Checking memory safety of the
candidate store entry; 2) Encrypting the victim cache entry; 3)
Decrypting the store entry to the just freed flow cache cell; 4)
Restoring the lookup consistency in the lkup entry; 5) Moving
the encrypted victim cache entry to store entry. At the end of
(cid:131)ow tracking, the expected (cid:131)ow state will be cached in the enclave
and returned to the middlebox.
Tracking termination. (cid:140)e tracking of a (cid:131)ow can be explicitly
terminated (e.g., upon seeing FIN or RST (cid:131)ag). When this happens,
the corresponding lkup entry is removed and the cache entry is
nulli(cid:128)ed. (cid:140)is will not a(cid:130)ect flow store, as the (cid:131)ow has already
been cached in the enclave.
Expiration checking. We periodically purge expired (cid:131)ow states
to avoid performance degradation. (cid:140)e last access time (cid:128)eld will be
updated at the end of (cid:131)ow tracking for each packet using the etap
clock. (cid:140)e checking routine will walk through the lookup table
and remove inactive entries in the tables.
4.3 Fast Flow Lookup
(cid:140)e fastest path in the (cid:131)ow tracking process above is indicated by
flow cache hit, where only a few pointers are updated to refresh
LRU linkage. In case of flow cache miss and flow store hit, two
memory copy (for swapping) and cryptographic operations are
entailed. Due to the interlinked design, these operations have
constant cost irrelevant to the number of tracked (cid:131)ows.
Figure 7: Data structures used in (cid:131)ow state management.
the memory explosion caused by (cid:131)ow states is the main source of
performance overhead.
4.1 Data Structures
(cid:140)e state management is centered around three abstract tables:
of active (cid:131)ows in the enclave;
• flow cache, which maintains the states of a (cid:128)xed number
• flow store, which keeps the encrypted states of inactive
• lkup table, which allows fast lookup of all (cid:131)ow states
(cid:131)ows in the untrusted memory;
from within the enclave.
Among them, flow cache has a (cid:128)xed capacity, while flow store
and lkup table can grow as more (cid:131)ows are tracked. Our de-
sign principle is to keep the data structures of flow cache and
lkup table functional and minimal, so that they can scale to mil-
lions of concurrent (cid:131)ows. Figure 7 gives an illustration of them.
• (cid:140)e cache entry holds raw state data. It keeps two point-
ers (do(cid:138)ed arrows) to implement the Least Recently Used
(LRU) eviction policy, and links (dashed arrow) to a lkup entry.
• (cid:140)e store entry holds encrypted state data and authenti-
cation MAC. It is maintained in untrusted memory so does
not consume enclave resources.
• (cid:140)e lkup entry stores fid, a pointer (solid arrow) to either
cache entry or store entry, and two small (cid:128)elds. (cid:140)e
fid represents the conventional 5-tuple to identify (cid:131)ows.
(cid:140)e swap count serves as a monotonic counter to ensure
the freshness of state; it is initialized to a random value and
incremented by 1 on each encryption. (cid:140)e last access as-
sists (cid:131)ow expiration checking, it is updated with etap clock
on each (cid:131)ow tracking. Note that the design of lkup entry
is independent of the underlying lookup structure, which
for example can be plain arrays, search trees or hash tables.
(cid:140)e data structures above are succinct, making it e(cid:129)cient to han-
dle high (cid:131)ow concurrency. Assume 8B (byte) pointer and 13B fid,
then cache entry uses 24B per cached (cid:131)ow and lkup entry uses
33B per tracked (cid:131)ow. Assume 16K cache entries and full utilization
of the underlying lookup structure, then tracking 1M (cid:131)ows requires
only 33.8MB enclave memory besides the state data itself.
4.2 Management Procedures
We refer to (cid:131)ow tracking as the process of (cid:128)nding the correct (cid:131)ow
state on a given fid. It takes place in the early stage of the packet
processing cycle. (cid:140)e identi(cid:128)ed state may be accessed anywhere
and anytime a(cid:137)erwards [46, 47]. (cid:140)us, it should be pinned in the
lkup_entry*lkup;cache_entry*prev;cache_entry*next;bytes plain_state;fid_typefid;intswap_counter;time last_access;cache_entry*data;fid_typefid;intswap_counter;time last_access;store_entry*data;bytes enc_state;bytes mac;flow_cachelkup_tableflow_storeEnclaveWhen encountering high (cid:131)ow concurrency, we found that the
(cid:131)ow lookup sub-procedure becomes the main factor of performance
slowdown, as con(cid:128)rmed by one of our tested middleboxes with
an ine(cid:129)cient lookup design (PRADS, see Section 6.3). Given the
constrained enclave resources, two requirements are therefore im-
posed on the underlying lookup structure: search e(cid:129)ciency and
space e(cid:129)ciency.
Dual lookup design with cuckoo hashing. We recognize
cuckoo hashing as the one to simultaneously achieve the two prop-
erties. It has guaranteed O(1) lookup and superior space e(cid:129)ciency,
e.g., 93% load factor with two hash functions and a bucket size
of 4 [25]. One downside with hashing is their inherent cache-
unfriendiness [36], which incurs a higher cache miss penalty in
the enclave. (cid:140)us, while adopting cuckoo hashing, we still need a
cache-aware design.
Our idea is to split lkup table into a small table dedicated for
flow cache, and a much larger one for flow store. (cid:140)e large one
is searched only a(cid:137)er a miss in the small one. (cid:140)e smaller table
contains the same number of entries as flow cache and has a (cid:128)xed
size that can well (cid:128)t into a typical L3 cache (8MB). It is accessed
on every packet and thus is likely to reside in L3 cache most of the
time. Such a dual lookup design can perform especially well when
the flow cache miss rate is relatively low.
To validate the design, we evaluate the two lookup approaches
with 1M (cid:131)ows, 512B states and flow cache with 32K entries. As
expected, Figure 8 shows that the lower the miss rate, the larger
speedup the dual lookup achieves over the single lookup. Real-
world tra(cid:129)c o(cid:137)en exhibits temporal locality [11, 48]. We also esti-
mate the miss rate of flow cache over a real trace [9]. As shown
in Fig. 9, the miss rate can be maintained well under 20% with 16K
cache entries, con(cid:128)rming the temporal locality in the trace, hence
the e(cid:129)ciency of the dual lookup design in practice.
4.4 Security of State Management
We show that the adversary can only gain li(cid:138)le knowledge from
the management procedures. It can neither manipulate the proce-
dures to in(cid:131)uence middlebox behavior. (cid:140)erefore, the proposed
management scheme retains the same security level as if it is not
applied, i.e., when all states are handled by EPC paging.
We (cid:128)rst analyze the adversary’s view throughout the procedures.
Among the three tables, flow cache and lkup table are always
kept in the enclave, hence invisible to the adversary. Stored in
untrusted memory, flow store is fully disclosed. (cid:140)e adversary
can obtain all store entry’s, but never sees the state in clear text.
She will notice the creation of new (cid:131)ow state, but cannot link it
to a previous one, even if the two have exactly the same content,
because of the random initialization of the swap count. Similarly,
she is not able to track tra(cid:129)c pa(cid:138)erns (e.g., packets coming in
bursts) of a single (cid:131)ow, because the swap count will increment
upon each swapping and produce di(cid:130)erent ciphertexts for the same
(cid:131)ow state. In general, she cannot link any two store entry’s.
(cid:140)e explicit termination of a (cid:131)ow is unknown to the adversary,
as the procedure takes place entirely in the enclave. In contrast, she
will notice state removal events during expiration checking. Yet,
this information is useless as the entries are not linkable.
Figure 8: (cid:135)e speedup of
dual lookup design over sin-
gle lookup design.
Figure 9: (cid:135)e miss rate of
flow cache with varying size
for a real network trace [9].
Now we consider an active adversary. Due to the authenticated
encryption, any modi(cid:128)cation of state entry’s is detectable. Ma-
licious deletion of a state entry will be also caught when it is
supposed to be swapped into the enclave a(cid:137)er a hit in lkup table.
She cannot inject a fake entry since lkup table is inaccessible
to her. Furthermore, the replay a(cid:138)ack will be thwarted because
swap count keeps the freshness of the state.
5 INSTANTIATIONS OF LIGHTBOX
We have implemented a working prototype of LightBox and instan-
tiated it for three case-study stateful middleboxes.
5.1 Porting Middleboxes to SGX
A middlebox system should be (cid:128)rst ported to the SGX enclave before
it can enjoy the security and performance bene(cid:128)ts of LightBox, as
illustrated in Fig. 2. A(cid:137)er that, the middlebox’s original insecure
I/O module will be seamlessly replaced with etap and the network
frameworks stacked thereon; its (cid:131)ow state management procedures,
including memory management, (cid:131)ow lookup and termination, will
be changed to that of LightBox as well.
(cid:140)ere are several ways to port a legacy middlebox. One is to
build the middlebox with trusted LibOS [7, 87], which are pre-ported
to SGX and support general system services within the enclave.
Another more specialized approach is to identify only the necessary
system services and customize a trusted shim layer for optimized
performance and TCB size [55]. To prepare for our middlebox case-
studies, we follow the second approach and implement a shim layer
that supports the necessary system calls and struct de(cid:128)nitions.
Some prior systems allow modular development of middleboxes
that are automatically secured by SGX [35, 66, 86]. For middleboxes
built this way, we can directly substitute their network I/O and (cid:131)ow
state management with LightBox, augmenting them with full-stack
protection and e(cid:129)cient stateful processing.
5.2 Middlebox Case Studies
We now introduce the three middleboxes we instantiated for Light-
Box. For discussions on the e(cid:130)orts of instantiating them with
LightBox, we assume that they have already been ported to SGX.
Both PRADS and lwIDS use libpcre for pa(cid:138)ern matching, so we
manually port it as a trusted library to be used within the enclave.
PRADS [27]. Capable of detecting network assets (e.g., OSes,
devices) in packets against prede(cid:128)ned (cid:128)ngerprints, PRADS has
been widely used in academic research [29, 45, 47]. It uses libpcap