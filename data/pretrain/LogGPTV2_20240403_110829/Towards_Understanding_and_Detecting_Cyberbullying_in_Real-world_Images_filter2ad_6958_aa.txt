# Towards Understanding and Detecting Cyberbullying in Real-World Images

**Authors:**
Nishant Vishwamitra<sup>∗</sup>, Hongxin Hu<sup>∗</sup>, Feng Luo<sup>†</sup>, Long Cheng<sup>†</sup>

**Affiliations:**
<sup>∗</sup>Computer Science and Engineering, University at Buffalo  
Email: {nvishwam, hongxinh}@buffalo.edu  
<sup>†</sup>School of Computing, Clemson University  
Email: {luofeng, lcheng2}@clemson.edu

## Abstract
Cyberbullying is a critical social issue affecting today's internet users. Perpetrators use internet-based technologies to bully their victims by sharing cyberbullying-related content. While most research has focused on textual content, such as comments and text messages, the misuse of visual content in cyberbullying has been largely overlooked. Recent technological advancements have introduced new paradigms, where perpetrators can use visual media to bully victims through images. This paper presents a comprehensive study on the nature of images used in cyberbullying. We collected a dataset of 19,300 real-world cyberbullying images and analyzed the factors related to these images. Our analysis reveals that unlike traditional offensive image content (e.g., violence and nudity), the factors in cyberbullying images are highly contextual. We further demonstrate the effectiveness of these factors by evaluating several classifier models. The best multimodal classification model achieves a mean detection accuracy of 93.36% on our dataset.

## 1. Introduction
Today's internet users heavily rely on the internet for socializing and interaction. According to recent reports, 92% of users go online daily [31]. The Pew Research Center [16] found that 95% of adolescents (ages 12-17) spend time online, with 74% being "mobile internet users" who access the internet via cell phones, tablets, and other mobile devices.

The rise of social networks has redefined friendships, relationships, and social communications. However, one of the major issues is the potential for cyberbullying, which has been recognized as a serious social problem. Multiple studies suggest that cyberbullying can cause deep emotional trauma, psychological, and psychosomatic disorders [22], [78]. Over 40% of teenagers in the U.S. have reported being cyberbullied [60]. Dooley et al. define cyberbullying as "Bullying via the Internet or mobile phone" [39]. It encompasses all aggressive acts conducted using information and communication technologies, often repeatedly, against victims who cannot easily defend themselves [41].

Perpetrators' techniques in cyberbullying evolve rapidly. Modern multimedia devices, such as smartphones and tablets, have integrated cameras, enabling the instant capture and sharing of images. Social networking sites like Facebook, Instagram, and Twitter provide options for users to freely share images, leading to a significant increase in the popularity of image-sharing. This trend has introduced a shift from traditional text-based cyberbullying to visual-based cyberbullying, which can be more distressing for victims [76], [63].

Figure 1 illustrates two examples of cyberbullying: (a) a tweet with demeaning words and (b) an image showing a person making a 'loser' hand gesture. While text-based cyberbullying detection has been extensively studied, research on cyberbullying in images is limited. State-of-the-art offensive image detectors, which are effective for traditional offensive content like nudity and violence, do not detect cyberbullying in images effectively. For example, the image in Figure 1 (b) is not detected as offensive by Google Cloud Vision API, Amazon Rekognition, and Clarifai NSFW. Therefore, there is a crucial need for research on cyberbullying in images.

## 2. Threat Model and Scope
### 2.1 Threat Model
In this work, we consider two types of users:
1. **Perpetrator:** A user who sends a cyberbullying image to another user.
2. **Victim:** A user who receives a cyberbullying image from a perpetrator.

We focus on scenarios where perpetrators upload, post, or share cyberbullying images online, on social networks, or via mobile devices. The affected users are the victims viewing these images. We do not consider images accompanied by cyberbullying text or traditional offensive content like nudity, pornography, and violence. We also exclude cases with inside meanings only understandable to specific users.

### 2.2 Problem Scope
Our goal is to identify factors of cyberbullying in images and demonstrate that they can be used to detect such content. We aim to analyze typical classifier models to show that they can effectively detect cyberbullying in images after integrating the identified visual factors.

## 3. Data Collection
To identify factors of cyberbullying in images, we need a large, representative dataset of real-world cyberbullying images. We introduce a method to collect such a dataset, starting with extracting keywords and keyphrases from self-reported cyberbullying stories. These keywords are then used to collect a dataset of 19,300 valid images, annotated by online participants from Amazon Mechanical Turk (MTurk).

### 3.1 Methodology
We use self-reported cyberbullying stories from [7], a collection of anonymized stories from voluntary online users who have experienced cyberbullying. We mined this corpus and compiled 265 unique stories, contributed by users, with 30 adults and 197 users below 18 years old. Most users reported themselves as female (178 out of 265).

## 4. Analysis and Results
We analyzed the collected dataset against five state-of-the-art offensive image detectors: Google Cloud Vision API, Yahoo Open NSFW, Clarifai NSFW, DeepAI Content Moderation API, and Amazon Rekognition. We found that 39.32% of the cyberbullying samples could circumvent these detectors. We then identified five high-level contextual visual factors associated with cyberbullying in images: body-pose, facial emotion, object, gesture, and social factors.

We evaluated four classifier models (baseline, factors-only, fine-tuned pre-trained, and multimodal) based on deep-learning techniques. The best multimodal classifier model achieved a detection accuracy of 93.36%, with precision and recall of 94.27% and 96.93%, respectively.

## 5. Conclusion
This paper presents a comprehensive study on the nature of images used in cyberbullying. We collected a large dataset of 19,300 real-world cyberbullying images and identified five contextual visual factors. Our results show that incorporating these factors into classifier models can significantly improve the detection of cyberbullying in images. Future work will focus on refining these models and expanding the dataset to cover a broader range of cyberbullying scenarios.

---

**Acknowledgments:**
We thank the anonymous reviewers for their valuable feedback. This work was supported by [funding sources, if any].

**References:**
[Please include the full list of references here.]

---

This revised version aims to enhance the clarity, coherence, and professionalism of the original text.