title:Towards Understanding and Detecting Cyberbullying in Real-world Images
author:Nishant Vishwamitra and
Hongxin Hu and
Feng Luo and
Long Cheng
Towards Understanding and Detecting Cyberbullying
in Real-world Images
Nishant Vishwamitra∗, Hongxin Hu∗, Feng Luo† and Long Cheng†
∗Computer Science and Engineering, University at Buffalo
Email: ∗{nvishwam, hongxinh}@buffalo.edu, †{luofeng, lcheng2}@clemson.edu
†School of Computing, Clemson University
Abstract—Cyberbullying has become widely recognized as
a critical social problem plaguing today’s Internet users. This
problem involves perpetrators using Internet-based technologies
to bully their victims by sharing cyberbullying-related content.
To combat this problem, researchers have studied the factors
associated with such content and proposed automatic detection
techniques based on those factors. However, most of these studies
have mainly focused on understanding the factors of textual
content, such as comments and text messages, while largely over-
looking the misuse of visual content in perpetrating cyberbullying.
Recent technological advancements in the way users access the
Internet have led to a new cyberbullying paradigm. Perpetrators
can use visual media to bully their victims through sending and
distributing images with cyberbullying content. As a ﬁrst step to
understand the threat of cyberbullying in images, we report in
this paper a comprehensive study on the nature of images used in
cyberbullying. We ﬁrst collect a real-world cyberbullying images
dataset with 19,300 valid images. We then analyze the images
in our dataset and identify the factors related to cyberbullying
images that can be used to build systems to detect cyberbullying
in images. Our analysis of factors in cyberbullying images reveals
that unlike traditional offensive image content (e.g., violence and
nudity), the factors in cyberbullying images tend to be highly
contextual. We further demonstrate the effectiveness of the factors
by measuring several classiﬁer models based on the identiﬁed
factors. With respect
to the cyberbullying factors identiﬁed
in our work, the best classiﬁer model based on multimodal
classiﬁcation achieves a mean detection accuracy of 93.36% on
our cyberbullying images dataset.
I.
INTRODUCTION
Today’s Internet users have fully embraced the Internet for
socializing and interacting with each other. It has been reported
that 92% of users go online daily [31]. Particularly, according
to recent ﬁndings from the Pew Research Center [16], 95% of
adolescents surveyed (ages 12-17) spend time online, reﬂecting
a high degree of user engagement, and 74% of them are
“mobile Internet users” who access the Internet on cell phones,
tablets, and other mobile devices at least occasionally.
The rise of social networks in the digital domain has led
to new deﬁnitions of friendships, relationships, and social
communications. However, one of the biggest issues of social
networks is their inherent potential to engender cyberbullying,
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24260
www.ndss-symposium.org
Fig. 1: Cyberbullying in text v.s. cyberbullying in an im-
age. (a) shows a tweet with demeaning words and phrases.
(b) shows an image of a person showing a ‘loser’ hand gesture.
which has been widely recognized as a serious social prob-
lem. Multiple studies have suggested that cyberbullying can
have severe negative impact on an individual’s health, which
include deep emotional trauma, psychological and psychoso-
matic disorders [22], [78]. According to a National Crime
Prevention Council report, more than 40% of teenagers in
U.S. have reported being cyberbullied [60]. Dooley et al.
deﬁne cyberbullying as “Bullying via the Internet or mobile
phone” [39]. Cyberbullying encompasses all acts that are
aggressive, intentionally conducted by either a group or an
individual in cyberspace using information and communication
technologies (e.g. e-mail, text messages, chat rooms and social
networks) repeatedly or over time against victims who cannot
easily defend themselves [41].
Techniques used by perpetrators in cyberbullying change
rapidly. For example, multimedia devices (such as mobile
phones, tablets, and laptops) have now evolved from basic,
single-purpose tools to high-tech multi-media devices that are
fully integrated into the daily lives of millions of users. These
devices introduce several new dimensions to usage of Internet
services. For example, they provide on-board cameras to cap-
ture and instantly share images online. Therefore, perpetrators
can use the camera-capacity of their multi-media devices to
bully others through sending and distributing harmful pictures
or videos to their victims via these devices. Furthermore,
the current trend for social networking websites (e.g. Face-
book [9], Instagram [13] and Twitter [18]) is to provide
users with options to freely share their images. Indeed, the
popularity of image-sharing has seen a signiﬁcant increase,
thereby enabling numerous social networking websites, such
as Instagram, Flickr [1] and Pinterest [2], to exclusively focus
lmao.. & yurr reall funny skinny ass bitchh &.. hm.. that isn't really much of an insult now is it? what if i was fat? lol u suck at talkn shit :] later white trash skank :] ur super ugly nd that guy u like really isnt gonna come back around for u. (a)(b)to cyberbullying content
on image-sharing. These trends have introduced a shift from
traditional text-based cyberbullying content like messages and
tweets,
that makes use of visual
items to perpetrate cyberbullying behaviours among victims.
Empirical evidence demonstrates that
the cyberbullying in
images may cause more distress for victims than do other
forms of cyberbullying [76], [63]. This enhanced form of
cyberbullying perpetrated through images now affects one of
every two cyberbullying victims [6].
Figure 1 presents two examples of cyberbullying in text and
in an image, respectively. Figure 1 (a) depicts a cyberbullying
tweet [54] with the cyberbullying-related words shown in
bold (such as ‘a**’, ‘fat’, and ‘ugly’). Figure 1 (b) depicts
an image, in which a person is showing a demeaning hand
sign (a ‘loser’ hand gesture) to bully his victim. We note that
over the years, text-based cyberbullying detection has been
a topic of in-depth study by researchers [33], [36], [37], and
some state-of-the-art detectors for text-based offensive1 content
detection have been developed that are sufﬁciently effective in
combating text-based cyberbullying. For example, on running
the text in Figure 1 (a) against three state-of-the-art offensive
text detectors namely Google Perspective API [15], Amazon
Comprehend [3], and IBM Toxic Comment Classiﬁer [12], all
of them are able to detect this text as offensive with very
high conﬁdence (Google Perspective API as 92.84% likely to
be offensive; Amazon Comprehend as negative sentiment with
score of 0.97; and IBM Toxic Comment Classiﬁer as offensive
with score of 0.99). However, such kind of research with
respect to cyberbullying in images has been largely missed, and
the state-of-the-art offensive image detectors, which are very
accurate on the detection of traditional offensive image content,
such as nudity and violence, also do not have the capability
to effectively detect cyberbullying in images. For example, on
running the image in Figure 1 (b) through three state-of-the-
art offensive image detectors namely, Google Cloud Vision
API [10], Amazon Rekognition [4], and Clarifai NSFW [5],
none of them could detect this image as offensive (detected by
Google Cloud Vision API as “Unlikley” to cause any harm;
Amazon Rekognition as no need of moderation; and Clarifai
NSFW as safe for work with score of 0.67). Therefore, there
is a crucial need for research that can shed more light on the
phenomenon of cyberbullying in images.
The social and psychological aspects of cyberbullying in
text have been the subject of intense study [24], [56], [58].
These studies have revealed that the cyberbullying in text is
characterized by certain factors, such as harassing words or
phrases, name-calling, and humiliating insults. However, these
studies have mainly focused on its textual factors used by the
perpetrators of cyberbullying with text, while largely overlook-
ing the study of visual factors associated with cyberbullying in
visual media such as images. It is a challenging task to identify
the factors of cyberbullying content in images due to two
reasons. First, cyberbullying in images is highly contextual and
often subtle, depending on the complex interactions of several
aspects of an image. Studying its factors therefore is not as
straightforward as cyberbullying in text. Second, several clear
deﬁnitions of cyberbullying in text are available (such as [39],
[41]) and used to identify its factors, whereas the deﬁnition of
1We have used the term “offensive” here to mean harassing, harmful, toxic,
or hateful content.
2
cyberbullying in images is not established, which makes the
study of its factors much harder. To examine cyberbullying in
images, new ways to understand its personal and situational
factors should be studied.
Based on above observations and studies, we believe it is
timely and important to systematically investigate cyberbul-
lying in images and understand its factors, based on which
automatic detection approaches can be formulated. In this
work, we ﬁrst collect a large dataset of cyberbullying images
labeled by online participants. We analyze the cyberbullying
images in our dataset against ﬁve state-of-the-art offensive
image detectors, Google Cloud Vision API, Yahoo Open
NSFW [19], Clarifai NSFW, DeepAI Content Moderation
API [8], and Amazon Rekognition 2. We ﬁnd that 39.32% of
the cyberbullying samples can circumvent all of these existing
detectors. Then, we study the cyberbullying images in our
dataset
to determine the visual factors that are associated
with such images. Our study shows that cyberbullying in
images is with highly contextual nature unlike traditional
offensive image content (e.g., violence and nudity). We ﬁnd
that cyberbullying in images can be characterized by ﬁve
important, high-level contextual visual factors: body-pose,
facial emotion, object, gesture, and social factors. We then
measure four classiﬁer models (baseline, factors-only, ﬁne-
tuned pre-trained, and multimodal classiﬁer models) to identify
cyberbullying in images based on deep-learning techniques that
use visual cyberbullying factors outlined by our study. Based
on the identiﬁed factors, the best classiﬁer model (multimodal
classiﬁer model) can achieve a detection accuracy of 93.36%
in classifying cyberbullying images. Our ﬁndings about the
factors of cyberbullying in images and the best suited classiﬁer
model for their detection can provide useful
insights for
existing offensive image content detection systems to integrate
the detection capability of cyberbullying in images.
The key contributions of this paper are as follows:
•
New Dataset of Cyberbullying Images. We present
a novel methodology to collect a large dataset of
cyberbullying images. We ﬁrst compile a set of key-
words based on a collection of stories of cyberbullying
provided by online users with real cyberbullying ex-
periences. We then use these keywords to collect a
large, real-world images dataset with 117,112 images
crawled from online sources. The dataset with 19,300
valid images has been annotated by online participants
from Amazon Mechanical Turk (MTurk) 3.
• Measurement of State-of-the-art Offensive Image
Detectors. We present a measurement of ﬁve state-
of-the-art offensive image detectors against our cy-
berbullying images dataset, wherein we study their
effectiveness of detecting cyberbullying images. We
ﬁnd that these state-of-the-art detectors are not capable
of effectively identifying cyberbullying in images.
New Factors of Cyberbullying in Images. We ana-
lyze our dataset and identify ﬁve visual factors (i.e.,
•
2The offensive image detectors have been selected based on their ability
to detect images with certain features, such as violence, profanity, and hate
symbols, which have been found in cyberbullying images.
3Our dataset will be made publicly available (subject to ethical concerns,
discussed in Section VII).
•
body-pose, facial emotion, object, gesture, and social
factors) of cyberbullying in images. We also ﬁnd that
the factors linked to cyberbullying images are highly
contextual. Those factors discovered by our study play
an important role towards understanding cyberbullying
in images and building systems that can be used to
detect cyberbullying in images.
Extensive Evaluation of Visual Factors of Cy-
berbullying. We ﬁrst analyze the visual factors of
cyberbullying identiﬁed in our work with exploratory
factors analysis and our study reveals that the factors
are associated with two underlying social constructs,
which we interpret as ‘Pose Context’ and ‘Intent Con-
text’. We then measure four classiﬁer models based on
our identiﬁed factors. We note that by including the
visual factors identiﬁed in this work in those classiﬁer
models, they can effectively detect cyberbullying con-
tent in images as offensive content with high accuracy.
The best classiﬁer model, which is a multimodal
classiﬁer model, can detect cyberbullying images with
an accuracy of 93.36% (along with a precision and a
recall of 94.27% and 96.93%, respectively).
The rest of this paper is organized as follows. We ﬁrst
lay down the threat model of our work in Section II. Next,
we present our cyberbullying images data collection strategy
in Section III. We then present the motivation of our work
in Section IV. This is followed by the details of our ap-
proach in Section V. We discuss the implementation details
of the cyberbullying images classiﬁer models and present the
evaluations of those models from different perspectives in
Section VI. We discuss some important aspects of our approach
in Section VII. This is followed by a discussion of related work
in cyberbullying defense in Section VIII. Finally, we conclude
our work in Section IX.
II. THREAT MODEL AND SCOPE
Threat Model. In this work, we consider two types of
users: 1) a perpetrator is a user who sends a cyberbullying
image to other users; and 2) a victim is a user who receives
a cyberbullying image from a perpetrator. We consider the
scenario where images depicting cyberbullying are sent by
a perpetrator to a victim when the perpetrator uploads such
images online, posts such images on social networks or shares
such images via mobile devices. The affected users are the
victims viewing the photo. In our current work, we focus
on addressing cyberbullying in images, and do not consider
images accompanying with cyberbullying text. We also do
not consider the traditional offensive image content, such as
nudity, pornography, and violence, which have been deeply
studied by previous work [8], [4], [5]. Besides, we do not
consider cyberbullying cases with inside meaning that is only
understandable to speciﬁc users. For example, a perpetrator
Alice sends images of snakes to a victim Bob since Bob has a
fear of snakes.
Problem Scope. In this work, our goal is to identify factors
of cyberbullying in images and to demonstrate that they can
be used to detect cyberbullying content in images. Our major
purpose is not to design a novel classiﬁer model that achieves
the highest detection accuracy, instead we analyze several typ-
ical classiﬁer models to demonstrate that they can effectively
detect cyberbullying content in images after integrating the
visual factors of cyberbullying identiﬁed by our work.
III. CYBERBULLYING IMAGES DATA
COLLECTION
To identify factors of cyberbullying in images, we
need an effective mechanism to collect a large amount of
cyberbullying-related visual information, which should be rep-
resentative of real-world cyberbullying found in images. In
our work, we introduce an approach to collect a large dataset
of cyberbullying images, wherein we ﬁrst extract a set of
keywords and keyphrases of cyberbullying from cyberbully-
ing stories about self-reported experiences of real victims of
cyberbullying, which are then used to collect a cyberbullying
images dataset. Our data collection tasks are approved by IRB.
We elaborate the methodology of our approach in the following
section.
A. Methodology
In this section, we discuss our pre-data collection study for
collecting cyberbullying images dataset. In this study, we use
the cyberbullying stories from Internet users with their own
cyberbullying experiences to collect an images dataset that is
representative of real-world cyberbullying in images.
We use the self-reported stories from [7], a collection of
anonymized stories of cyberbullying collected from voluntary
online users who have themselves experienced cyberbullying.
Therefore, this corpus of cyberbullying stories and experiences
is a wealth of cyberbullying related information for research
in this ﬁeld. We mined this corpus and compiled 265 unique
stories of cyberbullying, each of which is contributed by a user.
Among the users in this study, 30 users reported themselves
as adults and 197 reported themselves as below the age of 18
years. A majority of users reported themselves as female (178