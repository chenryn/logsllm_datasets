title:New models of cache architectures characterizing information leakage
from cache side channels
author:Tianwei Zhang and
Ruby B. Lee
New Models of Cache Architectures Characterizing
Information Leakage from Cache Side Channels
Tianwei Zhang
Princeton University
PI:EMAIL
ABSTRACT
Side-channel attacks try to breach conﬁdentiality and re-
trieve critical secrets through the side channels. Cache mem-
ories are a potential source of information leakage through
side-channel attacks, many of which have been proposed.
Meanwhile, diﬀerent cache architectures have also been pro-
posed to defend against these attacks. However, there are
currently no means for comparing and evaluating the eﬀec-
tiveness of diﬀerent defense solutions against these attacks.
In this paper, we propose a novel method to evaluate a
system’s vulnerability to side-channel attacks. We establish
side-channel leakage models based on the non-interference
property. Then we deﬁne how the security aspects of a cache
architecture can be modeled as a ﬁnite-state machine (FSM)
with state transitions that cause interference. We use mutual
information to quantitatively reveal potential side-channel
leakage of the architectures, and allow comparison of these
architectures for their relative vulnerabilities to side-channel
attacks. We use real attacks to validate our results.
1.
INTRODUCTION
Conﬁdentiality is a major concern in information secu-
rity. Strong encryption is often used for conﬁdentiality pro-
tection. Many attacks have been designed to break these
cryptographically protected systems. Among them, side-
channel attacks exploit the physical characteristics of the
system to derive the crypto keys. These attacks are serious
security threats for several reasons. First, side-channel at-
tacks target the vulnerabilities of the systems instead of the
cryptographic algorithms. So the same attack strategies can
often be applied to diﬀerent ciphers. Second, side-channel
attacks can be successfully performed in a short period of
time (e.g., average 3 minutes in [1]), which may not cause
any noticeable impact on the system. Third, the attackers
do not need high privileges to launch an attack. All the op-
erations are within their authorized privilege level. Fourth,
side-channels exist widely in diﬀerent systems. Power [2, 3],
electromagnetic radiation [4, 5], timing [6], etc., can all be
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee. Request permissions from Permissions@acm.org.
ACSAC ’14, December 08 - 12 2014, New Orleans, LA, USA
Copyright 2014 ACM 978-1-4503-3005-3/14/12 ...$15.00
http://dx.doi.org/10.1145/2664243.2664273.
Ruby B. Lee
Princeton University
PI:EMAIL
exploited by the attacker to infer the inaccessible critical in-
formation. Fifth, the observable side-channel information is
due to the inherent physical features of the system, so it is
very diﬃcult to eliminate these side-channels.
A popular target of side channel attacks is the hardware
cache. Caches are one of the most important features for im-
proving performance in modern processors. Their use in the
memory hierarchy signiﬁcantly reduces the memory access
time. However, the diﬀerent access times due to fast cache
hits versus slow cache misses can be exploited in cache side
channel attacks to leak information. [1, 7–9]. It is typically
unacceptable to eliminate this side channel by disabling the
cache, because of the severe performance degradation that
would result. Recent work has also shown the possibility
of cross-VM side-channel attacks in cloud computing [10],
making side-channel attacks a real and serious threat.
To defend against cache side-channel attacks, a variety of
software defenses [1,8,11,12] have been proposed. These de-
fenses tend to degrade performance severely [11], and are not
applicable to arbitrary programs [12]. Furthermore, software
defenses are not completely secure, since software has no
control over hardware caches. For example, a software solu-
tion [1,8,11] may add instructions to load an entire security-
sensitive table into the cache, before each access to this ta-
ble, in the software-implemented cipher. However, this does
not prevent the cipher from being context-switched out and
having the cache lines containing table entries evicted by an-
other program (possibly the attacker). Also, hardware cache
controllers have the freedom to invalidate, evict or replace
any cache lines – beyond the control of any software.
Hardware defenses have also been proposed to mitigate in-
formation leakage through cache side-channels, with the goal
of providing more security and higher performance than soft-
ware defenses. The idea is to rethink cache architectures to
thwart certain types of side-channel attacks without impact-
ing the essential performance provided by caches. Diﬀerent
secure cache architectures have been proposed [13–15]. The
performance of these architectures can be tested by perfor-
mance benchmarks, but their security eﬀectiveness have only
been analyzed qualitatively. Currently, there are no reliable
methods for comparing the eﬀectiveness of diﬀerent secure
cache architecture approaches. In this paper, we propose a
new way of modeling caches to answer two questions: (1)Do
these secure caches really defend against cache side-channel
attacks? and (2)What are the relative vulnerabilities of dif-
ferent cache architectures to diﬀerent side-channel attacks?
Our approach is to model the security aspects of diﬀerent
cache architectures as ﬁnite state machines, and accurately
Tianwei Zhang and Ruby B. Lee, “New Models of Cache Architectures Characterizing Information Leakage from Cache Side
Channels”, Annual Computer Security Applications Conference (ACSAC), December, 2014
model the interference property which can show preserva-
tion or breaches of conﬁdentiality under side-channel at-
tacks. Our cache state machines include diﬀerent subjects
and states. Transitions between diﬀerent states can leak
conﬁdential information between diﬀerent subjects, when the
non-interference property is violated. In addition, we pro-
pose some quantitative representations of the potential vul-
nerabilities of the modeled cache architectures to the side
channel attacks. To the best of our knowledge, our method
of modeling the security aspects of cache architectures and
interferences is novel, as are our quantitative measures of
side-channel vulnerability which allow comparison of diﬀer-
ent cache defense strategies and analysis of the root causes
of side-channel leakage.
The key contributions of this paper are:
• Showing how to apply the principle of non-interference
to the modeling of side-channel information leakage;
• Exploiting mutual information for measuring the side-
channel information leakage, and identifying three con-
ditions for achieving non-interference properties;
• A new way of building ﬁnite-state machines for mod-
eling the security aspects of cache architectures, and
using a model-checking tool for quantitative character-
ization of the systems’ side-channel vulnerabilities;
• Verifying our cache security models and their relative
side-channel vulnerabilities with real attacks.
The rest of the paper is organized as follows: Section 2
gives the background of cache side-channel attacks and dif-
ferent secure cache defenses. Section 3 describes our side-
channel leakage models and quantiﬁcation for measuring in-
formation leakage. In Section 4, we show how to build new
security models of cache architectures. In Section 5, we inte-
grate the side-channel leakage model into the cache security
models and quantify the caches’ potential information leak-
age. We consider other side-channel attacks in Section 6.
Section 7 uses experimental data with real attacks to vali-
date our security models of the diﬀerent cache architectures.
Section 8 discusses related work. Section 9 gives our conclu-
sions and suggestions for future work.
2. BACKGROUND
2.1 Cache Side-channel Attacks
Cache side-channel attacks are particularly dangerous as
they are simple software attacks on essential hardware com-
ponents. The attacker does not need to share the address
space with the victim and access its memory. However, he
shares the hardware caches with the victim, which provides
the attacker a side channel to observe the victim’s secret in-
formation: a victim’s programs executing on the system may
have diﬀerent cache behaviors (hits or misses) when memory
accesses are made. These behaviors have diﬀerent timing
characteristics. The attacker tries to capture these char-
acteristics, and deduce the victim’s memory accesses that
might help him recover the key and break the ciphers.
A large number of cache side-channel attacks have been
proposed during the past few years [1, 7–9, 16–18]. The root
cause of all the existing attacks is due to interference: either
external interference between the attacker’s program and the
victim’s program, or internal interference inside the victim’s
own program [13]. Combined with the cache behaviors the
attackers want to observe (cache misses or hits), we have four
cache side-channel attack categories [19] shown in Table 1
and described below.
Table 1: Cache side-channel attack categories
Cache
Misses
Cache
Hits
External Interference
I. Access-based attacks
e.g., Percival’s attack
III. Access-based attacks
e.g., Shared library
Internal Interference
II. Timing-based attacks
e.g., Bernstein’s attack
IV. Timing-based attacks
e.g., Bonneau’s attack
Type I: Attacks based on Cache Misses due to Ex-
ternal Interference. In this class of attacks, the attacker
and the victim run their processes on the same processor,
and they share the same data cache. So the victim’s pro-
cess may evict the cache lines holding the attacker’s data,
which will cause the attacker future cache misses and give
the attacker the chance to infer the victim’s cache accesses.
Some access-based cache attacks belong to this class, and a
typical one is Percival’s attack [7].
Type II: Attacks based on Cache Misses due to
Internal Interference. In this class, the attacker does not
run programs simultaneously with the victim. Instead, he
only measures the total execution time of the victim, e.g., for
encryption of one plaintext block. A longer execution time
indicates there may be more cache misses from the victim’s
own execution; this can give the attacker information about
the victim’s memory accesses. Some timing-based cache at-
tacks belong to this class, such as Bernstein’s attack [8].
Type III: Attacks based on Cache Hits due to Ex-
ternal Interference.
In this class, the attacker and the
victim share some memory space (e.g, a shared cryptogra-
phy library). First, the attacker evicts all, or some, shared
memory blocks out of the cache. After a certain time inter-
val of the victim’s execution, the attacker reads the shared
memory blocks and measures the access time. A short time
means the attacker has a cache hit, indicating that this cache
line has been accessed by the victim during that interval and
re-fetched into the cache by the victim. Then the attacker
can infer the memory addresses the victim has accessed. The
access-based attack in [1] belongs to this class.
Type IV: Attacks based on Cache Hits due to In-
ternal Interference. Similar to type II attacks, the at-
tacker still only needs to measure the total execution time
of the victim. But he only cares about cache hits inside the
victim’s code. If the attacker measures a shorter execution
time, it may be due to more cache hits during the victim’s
execution. So the attacker may be able to infer information
about the encryption keys through the “cache collision” (i.e.,
cache hits) of memory accesses. Some timing-based attacks
belong to this class, such as Bonneau’s attack [9].
2.2 Cache Defenses and Architectures
Diﬀerent cache defenses and secure cache architectures
have been proposed to protect against cache side-channel
attacks. Basically these designs follow one of two strategies:
Partitioning or Randomization [20]:
2.2.1 Partitioning.
Caches can be exploited as side-channels in the external
interference attacks because the attacker and the victim can
share the caches, and thus interfere with each other’s cache
usage. So one straightforward approach to prevent informa-
tion leakage is to prevent the cache sharing by dividing the
cache into diﬀerent zones for diﬀerent processes. We have
the following cache designs using this idea:
Static-Partitioning (SP) cache: This cache is stati-
cally divided into two parts either by ways (like columns)
or by sets (like rows). In set-associative caches partitioned
by ways, each way is reserved for either the victim or the
attacker program. The cache can also be partitioned by
sets, where each set is reserved for either the victim or the
attacker program. Due to the elimination of cache line shar-
ing, SP caches can eﬀectively prevent external interference,
but at the well-known cost of degrading the computer’s per-
formance because of the static cache partitions.
Partition-Locked (PL) cache: PL cache [13] uses a
ﬁner-grained dynamic cache partitioning policy. In PL cache,
each memory line has a protection bit to represent if it needs
to be locked in the cache. Once the protected line (e.g., the
victim’s critical data) is locked in the cache, it can not be
replaced by an unprotected line (e.g., the attacker’s data).
Instead, the attacker’s data will be directly sent between
the processor and the memory, without ﬁlling the cache.
This replacement policy will thwart the attacker’s plot to
spy on the victim’s cache accesses to security-critical data
lines (e.g., those containing AES tables). This leverages, for
cache security, the Lock-bit already provided by some caches
to improve cache performance for frequently accessed data.
The proper use of a PL cache is to preload the sensitive
cache lines (e.g., AES table) before encryption begins.
2.2.2 Randomization.
In this approach, side-channel information is randomized,
thus no accurate information is leaked out from caches. There
are at least two ways to realize randomization: adding ran-
dom noise to the attacker’s observations and randomizing
the mappings from memory addresses to cache sets.
Random-Eviction (RE) cache: a RE cache periodi-
cally selects a random cache line to evict. This can add
random noise into the attacker’s observations so he cannot
tell if an observed cache miss is due to the cache line re-
placement or the system’s random eviction policy. This will
increase the attacker’s diﬃculty in recovering secret infor-
mation like a cipher key.
Random-Permutation (RP) cache: RP cache [13]
uses random memory-to-cache mappings to defend against
side-channel attacks. There is a permutation table for each
process. This enables a dynamic mapping from memory ad-
dresses to hardware-remapped cache sets. When one process
A wants to insert a new line D into the cache, it checks A’s
permutation table and ﬁnds the corresponding cache line R
in set S. If this R belongs to another process B, instead of
evicting R, thus revealing information to outsiders, a random
line R’ in a random set S’ is selected, evicted and replaced
by D. At the same time, the sets S and S’ in A’s permu-
tation table are swapped, and the lines in these two sets
belonging to A are invalidated. Since process A’s memory-
to-cache mappings are dynamic, random and unknown to
process B, process B cannot tell which memory addresses
process A actually accessed. This is diﬀerent from conven-
tional caches, which have static and ﬁxed memory-to-cache
mappings, rather than dynamic and randomized mappings.
NewCache: NewCache [14, 21] randomizes the memory-
to-cache mappings by introducing the concept of a Logical
Direct-Mapped Cache (LDM), which does not physically ex-
ist. The mapping from memory addresses to the LDM cache
is direct-mapped, with the beneﬁts of simplicity and speed.
The mapping from the LDM cache to the physical cache is
fully-associative and is realized using Line Number Registers
(LNreg’s). This dynamic and random mapping enhances
the security against information leakage, as each memory
line can be mapped to any physical cache line with equal
probability; and the cache access pattern changes with each
execution of the same program. Furthermore, the perfor-
mance is enhanced since the LDM cache can be much larger
than the physical cache, by merely adding extra index bits
to each LNreg [14]. For the replacement policy, if the incom-
ing line D cannot ﬁnd any line in the physical cache with the
same index (called an index miss), it will randomly choose
a line R to replace. If the incoming line can ﬁnd a line R
in the physical cache with the same index, but the tag of
the line (i.e. the rest of the memory address minus the in-
dex bits) is diﬀerent (called a tag miss), then D may replace
R [21]. The advantage of NewCache is achieving the security
beneﬁts of dynamic randomized mapping of memory lines to
cache lines, with the same (or even better) performance as
conventional caches [14].
3. SIDE-CHANNEL LEAKAGE MODELING
We now build a model for side-channel leakage. First we
consider a general system which can be modeled as a ﬁnite
state machine. The state machine consists of a set of subjects
and states. Each subject may provide some actions to the
machine, causing it to transition from one state to another,
and generate some observations. In order to study the infor-
mation ﬂow between diﬀerent subjects in this machine, we
use the concept of non-interference [22], as deﬁned below:
Deﬁnition: Given a state machine M, and its subjects
S and S(cid:48), we say S does not interfere with (or is non-
interfering with) S(cid:48), if the actions of S on M do not aﬀect
the observations of S(cid:48).