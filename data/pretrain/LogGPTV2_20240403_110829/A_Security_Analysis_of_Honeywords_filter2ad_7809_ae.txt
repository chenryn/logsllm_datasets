ϵ
1(cid:0)ϵ
TABLE V.
ϵ-FLAT INFO ABOUT EACH HONEYWORD METHOD.y
Tweak-tail Model-syntax Hybrid Simple model
TABLE IV.
SUCCESS-NUMBER INFORMATION (%) ABOUT EACH
HONEYWORD METHOD, EVALUATED UNDER THE (TYPE-A1) “NORM
TOP-PW: SMOOTH, 1T” STRATEGY AND T2 = 104.y
Tianya
Dodonew
CSDN
12306
Rockyou
000webhost
ClixSense
Yahoo
Rootkit
QNB
Average
Tweak-tail Model-syntax Hybrid Simple model
5.81%
8.75%
16.32%
9.51%
2.41%
4.56%
6.08%
16.84%
19.57%
20.48%
11.03%
13.04% 14.90%
9.06% 10.46%
15.75% 18.39%
7.88% 9.17%
7.35% 14.01%
14.33% 16.86%
5.27% 9.52%
7.61% 13.81%
12.72% 17.82%
20.85% 20.97%
11.39% 14.59%
14.41%
10.10%
18.78%
9.32%
21.63%
9.56%
16.87%
24.25%
20.39%
20.99%
16.63%
yA value in bold means the corresponding method perform best among
four methods, while a value with background color means the worst.
Tianya
Dodonew
CSDN
12306
Rockyou
000webhost
ClixSense
Yahoo
Rootkit
QNB
Average
0.4368
0.3755
0.3664
0.1309
0.5498
0.3550
0.3055
0.2785
0.2293
0.2348
0.3262
0.4400
0.3582
0.3437
0.1177
0.4831
0.3587
0.2221
0.2080
0.1636
0.2342
0.2929
0.4580
0.3796
0.3716
0.1287
0.5334
0.3594
0.2758
0.2527
0.2052
0.2355
0.3200
0.4463
0.3828
0.3978
0.1327
0.5035
0.3541
0.2943
0.2661
0.2210
0.2313
0.3230
yBoth our attacking strategies in Sec. III-B would produce the same
ﬂatness graph. The experimental
the
setups and the meaning of
bold/background-color emphasis are the same with that of Table IV.
maining million-sized datasets (i.e., Tianya, Rockyou and
000webhost) can be found in the companion site. Tables
IV and V summarize all the evaluation results for our ten
datasets. As said earlier, the choices of training and test sets
follow the “half-half” practice. When allowing 10000 failed
attempts, 11.03%∼16.63% accounts of the ten test sets can
be successfully guessed; Tweak-tail provides the worst ϵ-
ﬂatness (i.e., 0.3262), even the best method Model-syntax are
0.2929-ﬂat: users’ real passwords can be distinguished with a
success rate of 29.29% by a trawling guessing attacker, but
not the expected 5%, with just one guess (when k=20 as
recommended). No method always performs the best in both
metrics, yet in general there does show a hierarchy: Model-
syntax > Simple model ≈ Hybrid > Tweak-tail.
Remark 5. Why our experiments are so effective? It has
been discussed in Remark 4 that, our “Normalized top-PW”
attacking strategy is essentially effective in distinguishing pop-
ular sweetwords from unpopular ones. Thus, it is particularly
suitable for attacking Juels-Rivest’s four random-replacement
methods which generate a set of k-1 honeywords that are
generally less probable than the user’s original password.
For instance, Table VI shows that the typical most popular
passwords in Dodonew-ts was rarely ( Tianya > Tianya sample > Rockyou
> Rockyou sample. We also experimented on the three other
methods, and get similar results.
The high success-rates of English datasets (e.g., Rockyou)
against the Chinese dataset Dodonew-ts (see Fig. 4(a) and 4(b))
are because: (1) Different kinds of “low-hanging fruits” can be
revealed by the List model when trained on Dodonew-tr and
Rockyou, respectively; (2) there are many internationally popu-
lar passwords(e.g., digital-sequences and keyboard-patterns) in
both Dodonew-tr and Rockyou (see Fig. 3 of [30]). However,
when measuring “ﬂatness” (see Fig. 4(b)), the training set
Rockyou is ineffective against Dodonew-ts.
In all, our results suggest that: (1) the closer the training set
is to the test set, the more effective the attack will be; (2) the
larger the training set, the more effective the attack will be;
(3) under quite practical attacks, all the four methods examined
provide far less security than expected.
Attacking password-model-based methods. Juels-Rivest’s
four primary methods are random-replacement based: the k-
1 honeywords for a given user are generated by randomly
replacing parts (or whole) of the real password. In a passing
comment, Juels and Rivest [21] mention the possibility of using
probabilistic password models (e.g., Weir et al.’s PCFG [32])
(a) Success-number graph of the tweaking-tail method.
(b) Flatness graph of the tweaking-tail method.
Fig. 4.
An investigation of the effectiveness of different training sets:
tested on Dodonew-ts, attacking with the “norm top-PW: smooth, 1t” strategy.
Whenever a perfect method line is presented, the closer to the perfect line,
the better the corresponding honeyword-method will be.
to build password model based honeyword methods. They
explicitly left it as an open question (see Section 9 of [21]):
“can the password models underlying cracking algorithms
(e.g., [32]) be easily adapted for use?” Here we provide a
negative answer to this question.
Here we take the well-known PCFG password model for
example. We assume that, for a given user’s password PWi,
the k-1 honeywords are produced according to the PCFG
model (denoted by PPCFG(D)(·)) trained on a speciﬁed dataset
D. Thus, the k-1 honeywords will be independent to PWi.
In such methods, sweetwords with a higher probability gen-
erally will not be more likely to be the real password, because
now the k-1 honeywords generated for PWi are completely
dependent on the password model (e.g., PPCFG(D)(·)) but not
PWi: more popular events in the password model will be more
likely selected as honeywords for PWi.
As a result, the “Norm top-PW” strategy in Sec. III-B will
not be effective. We now propose a new attacking strategy,
called “Norm PW-model” strategy, by revising the “Norm
top-PW” strategy. More speciﬁcally, all the settings in “Norm
PW-model” strategy are the same with the “Norm top-PW”
strategy, except for that (using the PCFG model for instance):
1) Add an additional Step 0 to the “Norm top-PW” attack
strategy: the known password distribution D (e.g., a
leaked password list) is ﬁrst applied to the PCFG model
(we use the laplace smoothing, see [24]), and this results
in a password distribution PCFG(D).
be: ∀swi,j ∈ SWi, set
2) Revise the Step 3 of “Norm top-PW” attack strategy to
Pr(swi,j) =
10
PrD (swi;j )
∑
PrPCFG(D)(swi;j )
PrD (swi;t )
k
t=1
PrPCFG(D) (swi;t)
.
TABLE VII.
SUCCESS NUMBER INFO AND ϵ-FLAT INFO ABOUT JUELS-RIVEST’S 4 METHODS (UNDER THE “NORM TOP-PW” STRATEGY) AND 2
PASSWORD-MODEL-BASED METHODS (UNDER THE “NORM PW-MODEL” STRATEGY): TRAINED ON DODONEW-TR, TESTED ON DODONEW-TS.
Tweak tail Model-syntax Hybrid Simple model PCFG-based method Markov-based method Perfect method (base line)
10.10%
0.006%
0.0500
0.3755
Success number info