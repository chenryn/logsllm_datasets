where the top rows are zero and the bottom have the identity;
and in between we use the identity. We randomize the “real” and
“dummy” programs using the same random low-norm matrices in
the lower-right quadrants, as illustrated in Figure 1.
After this randomization step, we use the GGH15 graph-induced
encoding scheme to encode the resulting randomized matrices.
As described in Section 3, the GGH15 scheme encodes matrices
relative to edges of a public directed graph, and in our case we use
a construction with two separate chains (with the same source and
sink), one for encoding the “real” branch and the other for encoding
the “dummy” branch. The encoded matrices form our obfuscated
branching program. To evaluate this obfuscated branching program
on some input, we choose the same matrix (0 or 1) from both
the “real” and “dummy” programs, multiply in order, subtract the
product of the “dummy” program from the product of the “real”
one, and test for zero.
3
Session D1:  Functional Encryption and ObfuscationCCS’17, October 30-November 3, 2017, Dallas, TX, USA785Real
(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)
(cid:40)
(cid:18)M1,b
(cid:19)
(cid:40)(cid:18)Mi,b
(cid:19)
(cid:40)(cid:18)Mn,b
R1,b
Ri,b
,
,
(cid:19)
Rn,b
0⌈d/2⌉
Dummy
(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)
(cid:169)(cid:173)(cid:171)I⌊d/2⌋
(cid:170)(cid:174)(cid:172)
(cid:18)Id
(cid:169)(cid:173)(cid:171)0⌊d/2⌋
(cid:170)(cid:174)(cid:172)
1⌈d/2⌉
R1,b
Rn,b
Ri,b
(cid:19)
,
First M1,b :
Other Mi,b’s :
Last Mn,b :
Figure 1: Randomizing transition matrices, the Ri,b’s are ran-
dom low-norm matrices, and the same Ri,b is used for the
“real” and “dummy”. Ik and 0k are the k × k identity matrix
and k × k zero matrix respectively.
2.2 No “multiplicative bundling”
The obfuscation scheme as described by Gorbunov et al. in [11] has
another randomization step of “multiplicative bundling” to protect
against “mixed input attacks”: in general branching programs, one
has to ensure that when a single input bit controls many steps of the
branching program, an attacker is forced to either choose the matrix
corresponding to zero in all of the steps or the matrix corresponding
to one (but cannot mix and match between the different steps of
the same input bit). To do that, Gorbunov et al. use a variant of the
encoding scheme that encodes matrices over a large extension ring
(rather than integer matrices), and multiply different matrices by
different scalars (called “bundling factors”) from this large ring.
Our implementation does not use bundling factors, since to get
sufficient entropy for the bundling scalars we would have to work
with scalars from a fairly large extension ring R (rather than just the
integers). This would have required that we scale up all our param-
eters by a factor equal to the extension degree of the large ring (at
least in the hundreds), rendering the system unimplementable even
for very short inputs. As a result, our implementation is vulnerable
to mixed input attacks if it is used for general branching programs,
so it should only be used for read-once programs.
2.3 Non-binary input
Our implementation also supports non-binary input, namely input
over an alphabet ∆ with more than two symbols. The only differ-
ence is that instead of having pairs of matrices in each step of the
program, we have |∆| matrices per step, and the input symbol de-
termines which of them to use. We still have only two branches in
the obfuscated program (“real” and “dummy”), encoded relative to a
DAG with two chains, where on each edge in this DAG we encode
|∆| matrices. The run time and space requirements of obfuscation
are linear in |∆|, while initialization and evaluation are unaffected
by the alphabet size. In our tests, we used |∆| as large as 16.
3 GRAPH-INDUCED ENCODING
Graded encoding schemes are the main tool in contemporary obfus-
cation techniques. They allow us to “encode” values to hide them,
while allowing a user to manipulate these hidden values. A graded
encoding scheme has three parts: key generation, which outputs a
(cid:41)
(cid:41)
(cid:41)
public key and a secret key; an encoding procedure, which uses the
secret key to encode values of interest; and operations that act on
the encoded values using the public key. (These encoding schemes
are “graded” in that the encoded values are tagged and operations
are only available on encoded values relative to “compatible” tags.)
In the GGH15 graph-induced encoding scheme of Gentry, Gor-
bunov, and Halevi [11], the tags correspond to edges in a transitive
directed acyclic graph (DAG). The DAG has a single source node s
and a single sink node t. An instance of this scheme is parameterized
by the underlying graph, and also by some integers n < m < b < q
that can be derived from the graph and the security parameter.
(Roughly, we have m = O(n log q), q = nO(d), where d is the diame-
ter of the graph and b = qδ for some δ < 1.) With these parameters,
the functionality of the GGH15 scheme is as follows:
q
q
• The plaintext space consists of integer matrices M ∈ Zn×n.
An encoding of such an integer matrix M (relative to any
edge i → j) is a matrix C ∈ Zm×m
over Zq. There is an
efficient procedure that takes the secret key, a matrix M ∈
Zn×n, and two vertices i, j, and produces a matrix C ∈ Zm×m
that encodes M relative to i → j.
• If C1, C2 encode M1, M2, respectively, relative to the same
edge i → j, then their sum modulo q, C = [C1 + C2]q,
encodes the matrix M1 + M2 relative to the same edge. (Here
and throughout the paper we use [·]q to denote operations
modulo q, representing elements in Zq as integers in the
interval [−q/2, q/2).)
• If C1, C2 encode M1, M2, relative to consecutive edges i → j,
j → k, respectively, and if in addition the entries of M1
are all smaller than b in magnitude, then their product C =
[C1 × C2]q encodes the matrix M1 × M2 relative to the edge
i → k (in the transitive closure).
• There is an efficient zero-test procedure that, given the public
key and an encoding of some matrix M relative to the source-
to-sink edge s → t, determines if M = 0.
q
In more detail, key generation in the basic GGH15 scheme chooses
for every vertex i a matrix Ai ∈ Zn×m
, together with a trap-
door as in [18] (see Section 4.1). The secret key consists of all
the matrices and their trapdoors, and the public key consists of
the source-node matrix As. An encoding of a plaintext matrix M
with respect to edge i → j is a “low-norm” matrix C ∈ Zm×m
such that AiC = MAj + E (mod q), for a “low-norm” noise matrix
E ∈ Zn×m. The encoding procedure chooses a random small-norm
error matrix E, computes B = [MAj + E]q, and uses trapdoor-
sampling to find a small-norm matrix C as above. Encoded matrices
relative to the same edge Ai → Aj can be added, and we have
Ai(C + C′) = (M + M′)Aj + (E + E′) (mod q). Furthermore, en-
coded matrices relative to consecutive edges i → j, j → k can be
multiplied, such that
Ai(C × C
′) = (MAj + E) × C
Ak + (ME
= MM
′
′ = M(M
′ + EC
′)
′
′
′) + EC
Ak + E
(mod q).
More generally, if we have a sequence of Ci’s representing Mi’s
relative to (i − 1) → i for i = 1, 2, . . . , k, then we can set C∗ =
4
Session D1:  Functional Encryption and ObfuscationCCS’17, October 30-November 3, 2017, Dallas, TX, USA786(cid:2)k
(cid:3)
∗ = (cid:0) k
q
i =1 Ci
A0C
and we have
(cid:1)Ak +
Mi
i =1
(cid:0)
(cid:1)Ej
k
(cid:0) j−1
k
(cid:1)
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
i =j+1
i =1
j=1
Mi
Ci
(mod q).
q
E∗ :=
have the invariant that C∗ is an encoding of M∗ = Mi relative
If we set the parameters so as to ensure that ∥E∗∥ ≪ q, then we still
to the source-to-sink edge 0 → k. By publishing the matrix A0, we
make it possible to recognize the case M∗ = 0 by checking that
∥A0C∗∥ ≪ q.
3.1 The GGH15 “Safeguards”
Since the security properties of their construction are still unclear,
Gentry et al. proposed in [11] certain “safeguards” that can plausibly
make it harder to attack. With every matrix Ai, we also choose a
low-norm “inner transformation matrix” Pi ∈ Zn×n and a random
“outer transformation matrix” Ti ∈ Zm×m
, both invertible modulo q.
For the source node A0 and sink node Ak, we use the identity
matrices P0 = Pk = In×n and T0 = Tk = Im×m.
To encode a matrix M ∈ Zn×n relative to the edge i → j,
we first apply the inner transformation to the plaintext, setting
M′ = [P−1
i MPj]q, then compute a low-norm C as before satisfying
AiC = M′Aj + E, and finally apply the outer transformation to
]q. For the invariant of this
the encoding, outputting(cid:98)C = [TiCT−1
encoding scheme,(cid:98)C encodes M relative to i → j if
i (cid:98)CTj) = (P
i (cid:98)CTj]q have low norm. Since we get telescopic
k
(cid:1)Ak +
out on a source-to-sink product. Setting C∗ =(cid:2)k
i =1(cid:98)Ci
k
∗ =(cid:0) k
(cid:1)
where E and C = [T−1
cancellation on multiplication (and the 0 and k transformation
matrices are the identity), then the non-small matrices all cancel
, we get
(cid:1)Pj−1Ej
−1
i MPj)Aj + E
(cid:0) j−1
(mod q),
Ai(T
A0C
(cid:3)
(1)
(cid:0)
−1
Mi
Mi
Ci
q
j
i =1
j=1
i =1
i =j+1
(mod q).
(2)
3.2 A Few Optimizations
Special case for source-based encoding. Encoding relative to an
edge 0 → i can be substantially optimized. This is easier to see
without the safeguards, where instead of publishing the vertex-
matrix A0 and the encoding-matrix C, we can directly publish their
product A0C = [MAj + E]q. Not only would this save some space
(since A0C has dimension n × m rather than m × m), we could
also do away with the need to use the trapdoor to compute a low-
norm C. Instead, we just choose the low-norm E and compute
B = [MAj + E]q.
When using the safeguards, we recall that P0 and T0 are both set
as the identity, and so to encode M we would compute M′ = [MPj]q,
then set B = [M′Aj + E]q, and output(cid:98)B = [BT−1
]q.
j
Special case for sink-bound encoding. We can also optimize en-
codings relative to an edge j → k by choosing a much lower-
dimensional matrix Ak. Specifically, we make A ∈ Zn×1
, i.e. a single
q
5
Trapdoor Generation & Sampling (§4.1)
G-sampling (§4.3)
Stash (§4.5)
Ellipsoidal Gaussians (§4.4)
1-dimensional Gaussians (§4.4)
Figure 2: Components of our trapdoor-sampling.
q
and finally outputting(cid:101)C = [T−1
column vector. Note that we cannot choose such a matrix with a
trapdoor, but we never need to use a trapdoor for the sink Ak.
Encoding M relative to j → k is done by choosing a low-norm
column vector E, setting B = [P−1
j MAk + E]q ∈ Zn×1
, using the Aj
trapdoor to sample a small C ∈ Zm×1
such that AjC = B (mod q),
q
j C]q.
4 TRAPDOOR SAMPLING
We implemented the trapdoor-sampling procedure of Micciancio
and Peikert [18]. The structure of this implementation is depicted
in Figure 2. At the bottom level, we have an implementation of one-
dimensional discrete Gaussian sampling, with a stash for keeping
unused samples. At the next level, we have procedures for sam-
pling high-dimension ellipsoidal discrete Gaussians and solutions
to equations of the form G(cid:174)z = (cid:174)v (mod q), where G is the “easy
gadget matrix.” At the top level, we have procedures for choosing
a matrix A with a trapdoor and then using the trapdoor to sample
solutions to equalities of the form A(cid:174)x = (cid:174)u (mod q).
4.1 Background: The Micciancio-Peikert
Trapdoor Sampling Procedure
I
I
q
(cid:17)
Recall that the Micciancio-Peikert approach [18] is based on a
“gadget matrix” G ∈ Zn×w for which it is easy to sample small
solutions (cid:174)z to equations of the form G(cid:174)z = (cid:174)v (mod q). The trapdoor-
generation procedure outputs a (pseudo)random matrix A ∈ Zn×m
together with a low-norm trapdoor matrix R ∈ Z ¯m×w such that
(cid:17) has the top rows taken from R
= G (mod q), where(cid:16) R
A ×(cid:16) R
and the bottom rows taken from the identity matrix I. In our im-
plementation, the entries of R are drawn independently from a
Gaussian distribution over the integers with parameter r = 4.
tor (cid:174)u ∈ Zn
dure for sampling small solutions to A(cid:174)x = (cid:174)u (mod q):
Given the matrix A, the trapdoor R, and a target syndrome vec-
q, Micciancio and Peikert described the following proce-
(1) Sample a small perturbation vector (cid:174)p ∈ Zm according to an
ellipsoidal discrete Gaussian distribution, with covariance