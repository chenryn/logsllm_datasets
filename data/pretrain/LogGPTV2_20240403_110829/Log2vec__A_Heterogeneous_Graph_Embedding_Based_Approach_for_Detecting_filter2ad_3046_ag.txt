Priv. Secur. 20, 4, Article 12 (Sept. 2017), 28 pages. https://doi.org/10.1145/3105761
[50] Hossein Siadati and Nasir Memon. 2017. Detecting Structurally Anomalous
Logins Within Enterprise Networks. In Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security (CCS ’17). ACM, New York,
NY, USA, 1273–1284. https://doi.org/10.1145/3133956.3134003
[51] SolarWinds. 2015. SolarWinds Survey Investigates Insider Threats to Federal
Cybersecurity. http://www.solarwinds.com/company/newsroom/press\_releases/
threats_to_federal_cybersecurity.aspx. Accessed August 22, 2017.
[52] Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and Tianyi Wu. 2011. Pathsim:
Meta path-based top-k similarity search in heterogeneous information networks.
Proceedings of the VLDB Endowment 4, 11 (8 2011), 992–1003.
[53] Yizhou Sun, Brandon Norick, Jiawei Han, Xifeng Yan, Philip S. Yu, and Xiao Yu.
2012. Integrating Meta-path Selection with User-guided Object Clustering in
Heterogeneous Information Networks. In Proceedings of the 18th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining (KDD ’12).
ACM, New York, NY, USA, 1348–1356. https://doi.org/10.1145/2339530.2339738
[54] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei.
2015. LINE: Large-scale Information Network Embedding. In Proceedings of the
24th International Conference on World Wide Web (WWW ’15). International World
Wide Web Conferences Steering Committee, Republic and Canton of Geneva,
Switzerland, 1067–1077. https://doi.org/10.1145/2736277.2741093
[55] Yutao Tang, Ding Li, Zhichun Li, Mu Zhang, Kangkook Jee, Xusheng Xiao, Zhenyu
Wu, Junghwan Rhee, Fengyuan Xu, and Qun Li. 2018. NodeMerge: Template
Based Efficient Data Reduction For Big-Data Causality Analysis. In Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’18). ACM, New York, NY, USA, 1324–1337. https://doi.org/10.1145/3243734.
3243763
[56] TrendMicro. 2012. APT myths and challenges. http://blog.trendmicro.com/
trendlabs-security-intelligence/infographic-apt-myths-and-challenges/. Ac-
cessed November 21, 2018.
[57] Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, and Sean Robin-
son. 2017. Deep Learning for Unsupervised Insider Threat Detection in Structured
Cybersecurity Data Streams. CoRR abs/1710.00811 (2017). arXiv:1710.00811
[58] N. E. Weiss and R. S. Miller. 2015. The Target and other financial data breaches:
Frequently asked questions. https://fas.org/sgp/crs/misc/R43496.pdf. Accessed
November 21, 2018.
[59] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. 2017.
Neural Network-based Graph Embedding for Cross-Platform Binary Code Simi-
larity Detection. In Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security (CCS ’17). ACM, New York, NY, USA, 363–376.
https://doi.org/10.1145/3133956.3134018
[60] Pinar Yanardag and S.V.N. Vishwanathan. 2015. Deep Graph Kernels. In Pro-
ceedings of the 21th ACM SIGKDD International Conference on Knowledge Dis-
covery and Data Mining (KDD ’15). ACM, New York, NY, USA, 1365–1374.
https://doi.org/10.1145/2783258.2783417
[61] Ting-Fang Yen, Alina Oprea, Kaan Onarlioglu, Todd Leetham, William Robertson,
Ari Juels, and Engin Kirda. 2013. Beehive: Large-scale Log Analysis for Detecting
Suspicious Activity in Enterprise Networks. In Proceedings of the 29th Annual
Computer Security Applications Conference (ACSAC ’13). ACM, New York, NY,
USA, 199–208. https://doi.org/10.1145/2523649.2523670
A EDGE WEIGHT COMPUTATION AMONG
DAILY LOG SEQUENCES
Edge weight w is directly proportional to similarity of the numbers
of logs that two daily log sequences contain. Specifically, if the
numbers of them are close, their weight w is high (smaller than 1)
and even equals to 1 when identical. We employ the function:
d(a, b) = max(a, b)
min(a, b) − 1
(5)
where a and b indicate the numbers of log entries that two se-
quences contain. Apparently, when a and b are close, then d(a, b)
is approaching zero and d(a, b) equals to 0 only if a = b. Specially,
when a or b is zero, let d(a, b) equals to 10000 that is large enough
to achieve our purpose and let d(a, b) equals to 0 when a and b are
both zero, which are both needed in Section 3.2.3. After getting
d(a, b), we introduce the following edge weight function:
w(u, v) = e
−d(a,b)
(6)
where u and v denote two daily log sequences.
It can be seen that this function is well suited to our requirement.
For instance, if a and b are close, d(a, b) approaches zero and w
tends to be maximum, that is, 1. In particular, when d(a, b) is too
large resulting from the huge difference between a and b, w tends
to be zero. In fact, w has been zero in our prototypical system when
d(a, b) is 10000. In summary, weight w belongs to [0, 1].
B EDGE WEIGHT COMPUTATION AMONG
LOG SEQUENCES OF DIFFERENT DOMAIN
NAMES
Weights of sequences of the same host and different domain names
depend on the similarities of accessing modes and numbers of log
entries. Specifically, we employ function 5 to separately calculate
each d(a, b) for the numbers of visit, upload, download and sum
of them between two sequences. We then add these four results
together as function 7 and feed it into function 6.
d(a,b)=d(a,b)visit +d(a,b)upload +d(a,b)download +d(a,b)total
(7)
We take w3 in Figure 5b as an example. As a result of the absence
of upload and download operations in sequence of domain name3,
minimums in function 5 are both zero, and hence d(a, b)upload
and d(a, b)download are both 10000, which we have defined in Ap-
pendix A, thus producing the output that w3 is zero. Specially,
d(a, b)upload is zero if neither domain name1 nor domain name3
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1791has upload operations, not affecting d(a, b). Access mode therefore
can be taken into consideration through such functions.
C SETTING PROPORTION OF SETS OF EDGE
TYPE
With respect to the way how the proportion of sets (ps) is deter-
mined, we consider a user’s behavior and his colleagues’ during
current period and the last one. First, we define a month or several
months as a time interval and take the same number of months
before this period as the last one. Second, the organizational units
in an enterprise (e.g. functional_unit, department) and role (e.g.
Salesman, ITAdmin) are used to define a colleague in log2vec.
As presented in Section 4.1.3, log2vec selects sets of {edge3,
edge6}, {edge7, edge8} and {edge9, edge10} to adjust. The reference
to adjust the proportion is changes of operation types in quantity.
Specifically, with respect to {edge9, edge10}, we focus on change of
network operation in quantity, corresponding to detecting pene-
tration of malware from Internet and data breach through it, while
{edge7, edge8} relies on that of logon operation with authentication
protocol, corresponding to detecting APT. {edge3, edge6} is based
on changes of device connect operation and file operation in quan-
tity, and which one is taken into account depends on whether this
operation type explicitly has an average of daily operations in this
period. This design corresponds to detecting data breach through
removable storage device and system sabotage (e.g. install, modify
and delete software) on user’s own host or others’.
We set the proportion 1:1:1:1:1 corresponding to sets of {edge1,
edge4}, {edge2, edge5}, {edge3, edge6}, {edge7, edge8} and {edge9,
edge10} separately. Moreover, we set the number of random walk,
r. Each value of the proportion is multiplied by r and the result is
the number of walks of the corresponding set.
We propose three policies to determine the proportion of sets of
edge type (ps). The first one is to observe whether daily averages
of connect/file, logon and network operation of the detected user
change between two periods, namely current period and the last
one. The result is 1:1:1:1:1 if none of them change, meaning no
anomalies regarding these operation types explicitly occur. If one
of them (e.g. network operation) changes, the corresponding value
in the proportion is multiplied by two times of sum of other sets
(e.g. 1:1:1:1:8) so that random walk extracts more corresponding
context (e.g. context regarding network operation).
Second, if two of them change, e.g. connect operation and net-
work operation, function 8 and function 9 are presented to compare
changes of these two operation types of the user and his colleagues
in quantity. In other word, change of his colleagues’ operations is
used as a reference to determine the change degrees of the user’s
operations.
r = max(a, b) − min(a, b)
min(a, b)
(8)
In the above function, for instance, a and b respectively indicate
averages of connect operation of the user in this period and the last
one and we can obtain ruser
connect . In fact, we can obtain four results
colleaдue
(ruser
, ruser
connect , r
network, r
network ) separately correspond-
ing to connect operation/network operation of the user and his
colleagues. This function obviously denotes the rate of change of
the same operation type in quantity between two periods for the
colleaдue
connect
user or his colleagues. It does not yet involve relationship between
the user and his colleagues that is solved in the function:
out = rmax
rmin
connect , r
(9)
where out (e.g. outconnect ) is a comparison of the same operation
colleaдue
type between the user and his colleagues (e.g. ruser
).
connect
Put another way, it compares the rates of change of the same oper-
ation type during two periods between the user and his colleagues.
Last, outconnect and outnetwork are compared and the higher
one makes its corresponding set’s value multiplied by two times
of sum of other sets in the proportion (e.g. 1:1:8:1:1 if outconnect is
high). If identical, the proportion remains invariant. In particular,
if operation type of colleagues is always zero, it is not taken into
account because there is no useful information and it cannot be
calculated in function 8. A constant (e.g. 0.1) is used to replace its
result in function 8 that is attained by taking into account users’
behavior in other departments.
If all the three operation types change in quantity, namely con-
nect operation (or file operation), logon operation and network
operation, log2vec calculates outconnect (or outf ile), outloдon and
outnetwork. Afterward, they are compared and the highest one
makes its corresponding set’s value multiplied by two times of sum
of other sets in the proportion.
Algorithm 1 Random walk with different sets of edge types
Input: The heterogeneous graph G = (V , E,T), all sets of edge
type Se and sets of the corresponding numbers of walk R, walk
length l, the number of neighbor nodes neiдh
initialize walk to [v]
cur_v = v
for j = 1 to l do
for i = 1 to r do
for v ∈ V do
Output: Random walk traces
1: Initialize walks to Empty
2: for s ∈ Se and r ∈ R do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15: end for
16: return walks
end for
end for
next_v = GetN eiдhbors(cur_v, G, s, neiдh)
append next_v to walk
cur_v = next_v
end for
append walk to walks
D PSEUDOCODE OF RANDOM WALK
We give the following pseudocode of random walk. For each set
of edge type s, the algorithm generates its corresponding number
of random walk r (line2) and each round contains l steps (line7).
Notice that r and l are hyperparameters. When a walker resides at
cur_v, he chooses next_v to traverse according to function 4, where
Sn indicates s here (line8). After putting next_v into walk used to
record trace in this round (line9), the walker has stands at next_v
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1792(line10) and chooses the next node again. walks, sets of walk is the
sequences of log entries/nodes fed into the later word2vec model.
E PSEUDOCODE OF CLUSTERING
Algorithm 2 depicts the pseudocode of clustering algorithm. set1
contains all logs (line2) and for each log entry, line4 ∼ line13 aim to
search its neighbors. Specifically, set2 is used to record logs whose
neighbors have been found and set3 includes logs that are close
to each other. set4 is their difference set to preserve logs whose
neighbors have not been searched. The algorithm searches log
entries’ neighbors until set4 is empty (line7 ∼ line13). After line15
each time, we obtain a cluster. Ultimately, the algorithm outputs
clusters that meet the conditions in Section 5.1. This algorithm
ensures that each log entry, whose similarity with the given one
is larger than δ1 (cosine distance, two log entries become similar
when δ1 is 0 → 1), must be grouped into the same cluster.
Algorithm 2 Clustering Algorithm
Input: Triple [log1, log2, similarity(sim)], all log entries V , a thresh-
old δ1
Output: Clusters
1: Initialize output to Empty
2: set1 = V
3: for v ∈ set1 do
set2 = [v]
4:
set3 = GetN eiдhbors(v,[loд1, loд2, sim], δ1)
5:
set4 = set3\set2
6:
while set4 (cid:44) ϕ do
7: