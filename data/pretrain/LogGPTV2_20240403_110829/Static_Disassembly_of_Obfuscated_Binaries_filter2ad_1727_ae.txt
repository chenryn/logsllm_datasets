m88ksim
perl
vortex
Mean
general
CFG
87.09
85.12
89.13
87.02
85.63
87.18
86.22
88.04
86.93
Gap
12.91
14.88
10.87
12.98
14.37
12.82
13.78
11.96
13.07
tool-speciﬁc
CFG Gap
3.64
96.36
93.10
6.90
4.89
95.11
4.97
95.03
4.89
95.11
96.00
4.00
4.43
95.57
5.33
94.67
95.12
4.88
Table 2: CFG vs. gap completion.
Because most of the output is derived from the control
ﬂow graph, it is important that the conﬂict resolution
phase is effective. One third of the control transfer in-
structions that are used to create the initial control ﬂow
graphs are invalid. To achieve a good disassembler ac-
curacy, it is important to remove the invalid nodes from
the CFG. The ﬁrst two steps of the conﬂict resolution
phase remove nodes that are guaranteed to be invalid,
given our assumptions. The third and forth step imple-
ment two heuristics and the ﬁfth step randomly selects
one of two conﬂicting nodes. It is evident that it is desir-
able to have as many conﬂicts as possible resolved by the
ﬁrst and second step, while the ﬁfth step should never be
required.
Table 3 shows for each program the number of basic
blocks in the initial control ﬂow graphs (column Initial
Blocks) and the number of basic blocks in the control
ﬂow graphs after the conﬂict resolution phase (column
Final Blocks). In addition, the number of basic blocks
that were removed in each of the ﬁve steps of the con-
ﬂict resolution phase are shown. The numbers given in
Table 3 were collected when the tool-speciﬁc modiﬁca-
tion was enabled. The results were very similar when
only general techniques were used.
It can be seen that most conﬂicts were resolved after the
ﬁrst three steps. About two thirds of the removed ba-
sic blocks were guaranteed to be invalid. This supports
our claim that invalid control ﬂow instructions, caused
by the misinterpretation of instruction arguments, often
result in impossible control ﬂows that can be easily de-
tected. Most of the remaining blocks are removed by
the ﬁrst heuristic that checks how tight a block is con-
nected with the rest of the CFG. Invalid blocks are often
loosely coupled and can taken out during this step. The
last two steps were only responsible for a small fraction
of the total removed blocks. The heuristic in step four
was sometimes able to provide an indication of which
block was valid. Otherwise, a random node had to be
selected.
Program
Initial Blocks
compress95
gcc
go
ijpeg
li
m88ksim
perl
vortex
54674
245586
91140
70255
63459
77344
104841
118703
Conﬂict Resolution
Step 1
7021
21762
10667
9414
8350
10061
10940
15004
Step 2
4693
25680
8934
6069
5297
6933
11442
9221
Step 3
4242
29801
9405
5299
4952
6938
11750
13424
Step 4
93
900
231
140
125
177
291
407
Step 5
48
565
154
95
78
101
152
373
Final Blocks
38577
166878
61749
49238
44657
53134
70266
80274
Table 3: Conﬂict resolution.
Static analysis tools are traditionally associated with
poor scalability and the inability to deal with real-world
input. Therefore, it is important to ascertain that our dis-
assembler can process even large real-world binaries in
an acceptable amount of time. In Section 4, we claimed
that the processing overhead of the program is linear in
the number of instructions of the binary. The intuitive
reason is the fact that the binary is partitioned into func-
tions that are analyzed independently. Assuming that the
average size of an individual function is relatively inde-
pendent of the size of the binary, the amount of work per
function is also independent of the size of the binary. As
a result, more functions have to be analyzed as the size
of the binary increases. Because the number of func-
tions increases linearly with the number of instructions
and the work per function is constant (again, assuming
a constant average function size), the overhead of the
static analysis process is linear in the number of instruc-
tions.
Program
openssh
compress95
li
ijpeg
m88ksim
go
perl
vortex
gcc
emacs
Size (Bytes)
263,684
1,768,420
1,820,768
1,871,776
2,001,616
2,073,728
2,176,268
2,340,196
2,964,740
4.765,512
Instructions Time (s)
4
9
7
9
8
11
15
16
28
38
46,343
92,137
109,652
127,012
127,358
145,953
169,054
204,230
387,289
405,535
SPECint 95 benchmark are in the range of 1.77 MB to
2.96 MB. To obtain more diversiﬁed results, we also dis-
assembled one smaller (openssh 3.7) and one larger
binary (emacs 21.3). The processing times were taken
as the average of ten runs on a 1.8 GHz Pentium IV
system with 512 MB of RAM, running Gentoo Linux
2.6. The results (in seconds) for the disassembler are
listed in Table 4. There was no noticeable difference
when using tool-speciﬁc modiﬁcation.
Figure 7 shows a plot of the processing times and the
corresponding number of instructions for each binary.
The straight line represents the linear regression line.
The close proximity of all points to this line demon-
strates that the processing time increases proportional to
the number of instructions, allowing our disassembler to
operate on large binaries with acceptable cost.
)
s
d
n
o
c
e
s
n
i
(
e
m
T
g
n
s
s
e
c
o
r
P
i
i
 50
 45
 40
 35
 30
 25
 20
 15
 10
 5
 0
Linear Regression Line
 0
 50000
 100000
 150000
 200000
 250000
 300000
 350000
 400000
Instructions
Figure 7: Processing times and linear regression.
Table 4: Disassembler processing times.
7 Conclusions
To support this claim with experimental data, the time
for a complete disassembly of each evaluation binary
was taken. The size of obfuscated programs of the
Correct disassembler output is crucial for many security
tools such as virus scanners [3] and intrusion detection
systems [11]. Recently, Linn and Debray [13] presented
obfuscation techniques that successfully confuse current
state-of-the-art disassemblers. We developed and imple-
mented a disassembler that can analyze obfuscated bina-
ries. Using the program’s control ﬂow graph and statis-
tical techniques, we are able to correctly identify a large
fraction of the program’s instructions.
It is
Obfuscation and de-obfuscation is an arms race.
possible to devise obfuscation techniques that will make
the disassembly algorithms describe in this paper less ef-
fective. However, this arms race is usually in favor of the
de-obfuscator. The obfuscator has to devise techniques
that transform the program without seriously impacting
the run-time performance or increasing the binary’s size
or memory footprint while there are no such constraints
for the de-obfuscator. Also, the de-obfuscator has the
advantage of going second. That is, the obfuscator must
resist all attacks, while the de-obfuscator can tailor the
attack to a speciﬁc obfuscation technique. In this direc-
tion, a recent theoretical paper [1] also proved that ob-
fuscation is impossible in the general case, at least for
certain properties.
Acknowledgments
[5] C. Cifuentes and A. Fraboulet.
Intraprocedu-
ral Static Slicing of Binary Executables.
In In-
ternational Conference on Software Maintenance
(ICSM ’97), Bari, Italy, October 1997.
[6] C. Cifuentes and K. Gough. Decompilation of Bi-
nary Programs. Software Practice & Experience,
25(7):811–829, July 1995.
[7] F. B. Cohen.
through Program Evolution.
net/books/IP/evolve.html.
Operating System Protection
http://all.
[8] C. Collberg and C. Thomborson. Watermarking,
Tamper-Prooﬁng, and Obfuscation - Tools for Soft-
ware Protection. IEEE Transactions on Software
Engineering, 28(8):735–746, August 2002.
[9] C. Collberg, C. Thomborson, and D. Low. A Tax-
onomy of Obfuscating Transformations. Techni-
cal Report 148, Department of Computer Science,
University of Auckland, July 1997.
[10] Free Software Foundation. GNU Binary Util-
http://www.gnu.org/
ities, Mar 2002.
software/binutils/manual/.
[11] J.T. Gifﬁn, S. Jha, and B.P. Miller. Detecting ma-
nipulated remote call streams. In 11th USENIX Se-
curity Symposium, 2002.
This research was supported by the Army Research
Ofﬁce under agreement DAAD19-01-1-0484 and by
the National Science Foundation under grants CCR-
0209065 and CCR-0238492.
[12] W.C. Hsieh, D. Engler, and G. Back. Reverse-
Engineering Instruction Encodings.
In USENIX
Annual Technical Conference, pages 133–146,
Boston, Mass., June 2001.
References
[1] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,
A. Sahai, S. Vadhan, and K. Yang. On the
(Im)possibility of Software Obfuscation.
In
Crypto, 2001.
[2] J. Bergeron, M. Debbabi, M.M. Erhioui, and
B. Ktari. Static Analysis of Binary Code to Isolate
Malicious Behaviors. In 8th Workshop on Enabling
Technologies: Infrastructure for Collaborative En-
terprises, 1999.
[3] M. Christodorescu and Somesh Jha. Static Analy-
sis of Executables to Detect Malicious Patterns. In
12th USENIX Security Symposium, 2003.
[4] C. Cifuentes and M. Van Emmerik. UQBT: Adapt-
IEEE Com-
able binary translation at low cost.
puter, 40(2-3), 2000.
[13] C. Linn and S. Debray. Obfuscation of executable
code to improve resistance to static disassembly. In
10th ACM Conference on Computer and Commu-
nications Security (CCS), pages 290–299, October
2003.
[14] T. Ogiso, Y. Sakabe, M. Soshi, and A. Miyaji. Soft-
ware obfuscation on a theoretical basis and its im-
plementation. IEICE Transactions on Fundamen-
tals, E86-A(1), 2003.
[15] R. Sites, A. Chernoff, M. Kirk, M. Marks, and
S. Robinson. Binary Translation. Digital Technical
Journal, 4(4), 1992.
[16] Symantec. Understanding and Managing Polymor-
phic Viruses. http://www.symantec.com/
avcenter/whitepapers.html.
[17] G. Wroblewski. General Method of Program Code
Obfuscation. In Proceedings of the International
Conference on Software Engineering Research and
Practice (SERP), Las Vegas, NV, June 2002.