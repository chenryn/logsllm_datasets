# Control Flow Graph (CFG) vs. Gap Completion

| Program | Mean | General | CFG | Tool-Specific |
|---------|------|---------|-----|---------------|
| m88ksim  | 87.09 | 85.12   | 89.13 | 87.02        |
| perl     | 85.63 | 87.18   | 86.22 | 88.04        |
| vortex   | 86.93 | -       | -    | -            |

| Program | Gap | General | CFG | Tool-Specific |
|---------|-----|---------|-----|---------------|
| m88ksim  | 12.91 | 14.88  | 10.87 | 12.98        |
| perl     | 14.37 | 12.82  | 13.78 | 11.96        |
| vortex   | 13.07 | -      | -    | -            |

| Program | CFG Gap | Tool-Specific |
|---------|---------|---------------|
| m88ksim  | 3.64    | 96.36         |
| perl     | 4.89    | 95.11         |
| vortex   | 4.89    | 95.11         |

**Table 2: CFG vs. Gap Completion**

The effectiveness of the conflict resolution phase is crucial because most of the output is derived from the control flow graph (CFG). Approximately one-third of the control transfer instructions used to create the initial CFGs are invalid. To achieve high disassembler accuracy, it is essential to remove these invalid nodes. The first two steps of the conflict resolution phase eliminate nodes that are guaranteed to be invalid based on our assumptions. The third and fourth steps implement heuristics, while the fifth step randomly selects one of two conflicting nodes. Ideally, as many conflicts as possible should be resolved by the first and second steps, and the fifth step should not be necessary.

# Conflict Resolution

| Program      | Initial Blocks | Final Blocks | Step 1 | Step 2 | Step 3 | Step 4 | Step 5 |
|--------------|----------------|--------------|--------|--------|--------|--------|--------|
| compress95   | 54,674         | 38,577       | 7,021  | 4,693  | 4,242  | 93     | 48     |
| gcc          | 245,586        | 166,878      | 21,762 | 25,680 | 29,801 | 900    | 565    |
| go           | 91,140         | 61,749       | 10,667 | 8,934  | 9,405  | 231    | 154    |
| ijpeg        | 70,255         | 49,238       | 9,414  | 6,069  | 5,299  | 140    | 95     |
| li           | 63,459         | 44,657       | 8,350  | 5,297  | 4,952  | 125    | 78     |
| m88ksim      | 77,344         | 53,134       | 10,061 | 6,933  | 6,938  | 177    | 101    |
| perl         | 104,841        | 70,266       | 10,940 | 11,442 | 11,750 | 291    | 152    |
| vortex       | 118,703        | 80,274       | 15,004 | 9,221  | 13,424 | 407    | 373    |

**Table 3: Conflict Resolution**

Most conflicts are resolved after the first three steps. About two-thirds of the removed basic blocks are guaranteed to be invalid, supporting our claim that invalid control flow instructions, caused by misinterpreted instruction arguments, often result in impossible control flows that can be easily detected. The remaining blocks are primarily removed by the first heuristic, which checks how tightly a block is connected to the rest of the CFG. Invalid blocks are often loosely coupled and can be removed during this step. The last two steps are responsible for only a small fraction of the total removed blocks. The heuristic in step four sometimes provides an indication of which block is valid; otherwise, a random node must be selected.

# Scalability and Performance

Static analysis tools are traditionally associated with poor scalability and the inability to handle real-world input. Therefore, it is important to ensure that our disassembler can process even large real-world binaries in an acceptable amount of time. We claimed in Section 4 that the processing overhead of the program is linear in the number of instructions in the binary. This is because the binary is partitioned into functions that are analyzed independently. Assuming the average size of an individual function is relatively independent of the size of the binary, the amount of work per function is also independent of the binary's size. As a result, more functions need to be analyzed as the binary size increases. Since the number of functions increases linearly with the number of instructions and the work per function is constant, the overhead of the static analysis process is linear in the number of instructions.

| Program  | Size (Bytes) | Instructions | Time (s) |
|----------|--------------|--------------|----------|
| openssh  | 263,684      | 4,343        | 4        |
| compress95 | 1,768,420   | 92,137       | 9        |
| li       | 1,820,768    | 109,652      | 7        |
| ijpeg    | 1,871,776    | 127,012      | 9        |
| m88ksim  | 2,001,616    | 127,358      | 8        |
| go       | 2,073,728    | 145,953      | 11       |
| perl     | 2,176,268    | 169,054      | 15       |
| vortex   | 2,340,196    | 204,230      | 16       |
| gcc      | 2,964,740    | 387,289      | 28       |
| emacs    | 4,765,512    | 405,535      | 38       |

**Table 4: Disassembler Processing Times**

To obtain more diversified results, we also disassembled one smaller (openssh 3.7) and one larger binary (emacs 21.3). The processing times were taken as the average of ten runs on a 1.8 GHz Pentium IV system with 512 MB of RAM, running Gentoo Linux 2.6. There was no noticeable difference when using tool-specific modifications.

**Figure 7: Processing Times and Linear Regression**

A plot of the processing times and the corresponding number of instructions for each binary is shown in Figure 7. The straight line represents the linear regression line. The close proximity of all points to this line demonstrates that the processing time increases proportionally to the number of instructions, allowing our disassembler to operate on large binaries with acceptable cost.

# Conclusions

Correct disassembler output is crucial for many security tools such as virus scanners and intrusion detection systems. Recently, Linn and Debray presented obfuscation techniques that successfully confuse current state-of-the-art disassemblers. We developed and implemented a disassembler that can analyze obfuscated binaries. Using the program's control flow graph and statistical techniques, we are able to correctly identify a large fraction of the program's instructions.

Obfuscation and de-obfuscation is an arms race. It is possible to devise obfuscation techniques that will make the disassembly algorithms described in this paper less effective. However, this arms race is usually in favor of the de-obfuscator. The obfuscator must transform the program without seriously impacting runtime performance or increasing the binary's size or memory footprint, while the de-obfuscator has no such constraints. Additionally, the de-obfuscator has the advantage of going second, tailoring the attack to a specific obfuscation technique. A recent theoretical paper also proved that obfuscation is impossible in the general case, at least for certain properties.

# Acknowledgments

This research was supported by the Army Research Office under agreement DAAD19-01-1-0484 and by the National Science Foundation under grants CCR-0209065 and CCR-0238492.

# References

[1] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan, and K. Yang. On the (Im)possibility of Software Obfuscation. In Crypto, 2001.

[2] J. Bergeron, M. Debbabi, M.M. Erhioui, and B. Ktari. Static Analysis of Binary Code to Isolate Malicious Behaviors. In 8th Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, 1999.

[3] M. Christodorescu and Somesh Jha. Static Analysis of Executables to Detect Malicious Patterns. In 12th USENIX Security Symposium, 2003.

[4] C. Cifuentes and M. Van Emmerik. UQBT: Adaptable Binary Translation at Low Cost. IEEE Computer, 40(2-3), 2000.

[5] C. Cifuentes and A. Fraboulet. Intraprocedural Static Slicing of Binary Executables. In International Conference on Software Maintenance (ICSM '97), Bari, Italy, October 1997.

[6] C. Cifuentes and K. Gough. Decompilation of Binary Programs. Software Practice & Experience, 25(7):811–829, July 1995.

[7] F. B. Cohen. Operating System Protection through Program Evolution. http://all.net/books/IP/evolve.html.

[8] C. Collberg and C. Thomborson. Watermarking, Tamper-Proofing, and Obfuscation - Tools for Software Protection. IEEE Transactions on Software Engineering, 28(8):735–746, August 2002.

[9] C. Collberg, C. Thomborson, and D. Low. A Taxonomy of Obfuscating Transformations. Technical Report 148, Department of Computer Science, University of Auckland, July 1997.

[10] Free Software Foundation. GNU Binary Utilities, Mar 2002. http://www.gnu.org/software/binutils/manual/.

[11] J.T. Giffin, S. Jha, and B.P. Miller. Detecting Manipulated Remote Call Streams. In 11th USENIX Security Symposium, 2002.

[12] W.C. Hsieh, D. Engler, and G. Back. Reverse-Engineering Instruction Encodings. In USENIX Annual Technical Conference, pages 133–146, Boston, Mass., June 2001.

[13] C. Linn and S. Debray. Obfuscation of Executable Code to Improve Resistance to Static Disassembly. In 10th ACM Conference on Computer and Communications Security (CCS), pages 290–299, October 2003.

[14] T. Ogiso, Y. Sakabe, M. Soshi, and A. Miyaji. Software Obfuscation on a Theoretical Basis and Its Implementation. IEICE Transactions on Fundamentals, E86-A(1), 2003.

[15] R. Sites, A. Chernoff, M. Kirk, M. Marks, and S. Robinson. Binary Translation. Digital Technical Journal, 4(4), 1992.

[16] Symantec. Understanding and Managing Polymorphic Viruses. http://www.symantec.com/avcenter/whitepapers.html.

[17] G. Wroblewski. General Method of Program Code Obfuscation. In Proceedings of the International Conference on Software Engineering Research and Practice (SERP), Las Vegas, NV, June 2002.