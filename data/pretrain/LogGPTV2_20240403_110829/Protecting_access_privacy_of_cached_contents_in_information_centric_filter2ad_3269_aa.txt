title:Protecting access privacy of cached contents in information centric
networks
author:Abedelaziz Mohaisen and
Xinwen Zhang and
Max Schuchard and
Haiyong Xie and
Yongdae Kim
Protecting Access Privacy of Cached Contents in
Information Centric Networks
Abedelaziz Mohaisen
Verisign Labs, VA, USA
Xinwen Zhang
Max Schuchard
Huawei Technologies, CA, USA
University of Minnesota, MN, USA
Haiyong Xie
Yongdae Kim
Huawei Technologies and USTC, China
KAIST, Daejeon, South Korea
ABSTRACT
In recently proposed information centric networks (ICN), a user is-
sues “interest” packets to retrieve contents from network by names.
Once fetched from origin servers, “data” packets are replicated and
cached in all routers along routing and forwarding paths, thus al-
lowing further interests by other users to be fulﬁlled quickly. How-
ever, the way ICN caching works poses a great privacy risk: the
time difference between responses for an interest of cached and un-
cached content can be used as an indicator to infer whether or not a
near-by user has previously requested the same content as that re-
quested by an adversary. This work introduces the extent to which
the problem is applicable in ICN and provides several solutions that
try to strike a balance between their cost and beneﬁts, and raise the
bar for the adversary to apply such attack.
Categories and Subject Descriptors
C.2.0 [Computer Communication Networks]: General – Security
and Protection; C.4 [Performance of Systems]: Design studies
Keywords
Information centric networks, privacy, side channel attacks, caching.
1.
INTRODUCTION
Information centric networks (ICNs) have been proposed as new
Internet architectures towards secure and efﬁcient content dissemi-
nation. In several ICNs such as content centric network (CCN) [11]
and named data network (NDN) [19], contents are fetched by their
names from caches deployed in the network or from origin servers—
servers that serve the contents if they are not cached in the network.
In such ICN architectures, once a content data packet is fetched
from an origin server, it is replicated and cached in all routers along
the routing and forwarding path—starting from the router that con-
nects user who issues the interest to the one that connects the origin
server to the ICN—thus allowing further interests with the same
content name to be fulﬁlled quickly [11]. For example, when an-
other user issues an interest in these contents that have been pre-
viously served to a user on the same path, the interest is fulﬁlled
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIA CCS’13, May 8–10, 2013, Hangzhou, China.
Copyright 2013 ACM 978-1-4503-1767-2/13/05 ...$15.00.
origin server
r0
r1
r2
t′′
1
AP2
U2
t2
t′
1
AP1
U1
Figure 1: Toy example of timing attack in ICN.
from the near-by cache. This design choice—as advocated by many
ICN designs and architectures—is considered a great advantages in
reducing overall content retrieval latency [11, 19]. However, this
universal caching mechanism poses a great privacy risk: the time
difference between a response of cached, when compared to un-
cached content, can be used as a side channel to infer whether a
near-by user has previously requested that content.
For example, consider the topology in Figure 1, which depicts
users U1 and U2, and a set of routers r0 to r2 (each with its own
cache) connecting both users to an origin server that holds con-
tent with name n. Suppose that user U2 is the adversary, whereas
user U1 is honest.
If U1 issues an interest in content n that re-
sides behind r0, the interest traverses the path U1 → AP1 →
r2 → r1 → r0, from which it retrieves a requested packet of
the content. The packet is then sent back over the returning path
r0 → r1 → r2 → AP1 → U1. In total, the path from U1 to the
source of the content and the returning path to U1 have four-hop
each. The total round trip time required for sending the request un-
til starting to receive data packets on the returning path is t1. On
the other hand, if U2 is to request the same content by its name, n,
the path that the interest would traverse is U2 → AP2 → r2, and
the contents would return on the reversed path (r2 → AP2 → U2),
which is two-hop in each direction, and would require a time t2.
Obviously, the time t1 is greater than t2, which an adversary U2
can use to infer that user U1 has accessed the content n.
Although pinpointing U1 precisely may require additional side
information, an attack like the one described above is still critical
since it reduces the anonymity set of that user greatly. Such sce-
nario is equal in value to identifying individual users when com-
bined with easily available information. For example, an adver-
sary launching a business intelligence attack might be interested in
knowing what contents are being retrieved by a competing com-
pany, rather than by individual users. This attack would be possi-
ble if the adversary is co-located with that company behind an edge
router, and using the above technique.
Shortcomings of Simple Solutions. Simple solutions cannot pre-
vent the attack. For example, a user can mark a content object with
a privacy ﬂag to disable in-network caching. However, this will
degrade the quality of experience of other users. Also, an adver-
sary can send two consecutive requests of the same name to infer
routers’ behavior. In the ﬁrst request, and assuming caching is en-
abled, the requested data will result in data caching The second
request in that case will result in cache-hit, and the content will be
served to the adversary quickly. However, if caching is disabled,
the second request will result in a delay close to the delay in the
ﬁrst request, from which the adversary can infer that caching is dis-
abled, and that another user has likely used the privacy ﬂag.
Other solutions to the attack by “intelligent caching” based on
router-to-user distance have their limitations. To do that, a router
has to either know the user’s location in advance or have the lo-
cation provided at the time of caching. While the ﬁrst approach
requires partial topology information that can easily exceed typ-
ical routers’ resources, the latter one is vulnerable to misuse; to
negatively impact the users’ experience the adversary can ﬂag any
content from an arbitrary location so as to disable caching.
1.1 Contributions
We make the following contributions:
• we demonstrate timing attacks on the universal caching mech-
anism proposed in ICN designs like CCN and NDN. For that,
we make use of ﬁne-grain per-hop timing measurements of
cached and uncached contents using real-world time mea-
surements with CCNx, a prototype implementation of the
CCN [2]. We disclaim the originality of the attack in its gen-
eral form but claim its suitability and applicability to ICN.
• we propose three protocols, each with different levels of com-
plexity, cost, and privacy guarantees that prevent an adver-
sary co-located with benign users to infer whether they have
accessed certain contents or not by relying on the timing.
Each and every of these protocols tries to strike a balance be-
tween the privacy provided to legitimate users from potential
adversary, and the overhead added for requests performed by
other legitimate users to the privacy-related contents.
1.2 Organization
The organization of the rest of this paper is as follows. In Sec-
tion 2 we review the preliminaries and terminologies used in this
paper. In Section 3 we introduce three protocols to solve the prob-
lem and maintain the privacy of users access, where each protocol
comes at different cost and privacy guarantees. In Section 4 we
present our simulation results to validate the attack and evaluate
the performance of our defense protocols. In Section 5 we high-
light several discussion points, including potential attacks and their
applicability to our protocols. Section 6 reviews related work and
Section 7 concludes this work and point out our future work.
2. PRELIMINARIES AND TERMINOLOGY
In ICN, contents are fetched by their names [11]. An ICN con-
sists of routers, where each router has a cache, and edge routers are
connected to users and origin servers. An Interest in ICN encapsu-
lates a request for a content packet by its name. An origin server
is a server that originates contents to be served in the network, thus
fulﬁlling interests. The contents (data packets) may or may not be
cached in the network. In the rest of this work, we use total Round
Trip Time (RTT) to denote the time from the start of sending the
ﬁrst interest until the start of receiving a content packet fulﬁlling it
(also known in the literature as Time to First Byte; TTFB). Simi-
larly, we deﬁne RTT per hop. In ICN, contents are forwarded back
to a user on the same path as they are requested by that user, thus
PIT (pending interest table) at each ICN router records which in-
terest is not fulﬁlled yet. A face in ICN is the port at which data
is sent or received in a router. In our protocols we make use of an
access point (AP), which is the closest connecting point of the user
to the ICN (not to be confused with a wireless access point). Each
router maintains a set of states to record the number of times that
a privacy-sensitive content object has been fetched by each user or
face. pmode is a ﬂag to indicate that the privacy of a content name
being accessed need to be preserved in future access and requests.
2.1 Attack Model
We consider an adversary co-located with an honest user who
tries to access contents from ICN . To this end, we assume that
the adversary has the capability to perform ﬁne-grained time mea-
surements to perform attacks. We also assume that the attacker has
a list of potential “names”, where he wants to verify whether the
benign user has accessed such names or not. We do not assume
any insider attacks, since such names are easy to infer given that
domain-speciﬁc names are common among people working in that
domain, and are easy to infer. From this assumption it follows that
the adversary has no control over which path interests are sent, and
cannot be geographically distributed to perform an intersection at-
tacks by combining several measurements at different network lo-
cations (see Section 5). Finally, for the operation of our attack, we
assume that the adversary has enough time to perform the attack,
which implies that the content caching lifetime is long enough that
the adversary would have a cache hit for contents previously cached
by the benign user’s requests.
In this paper we assume that the underlying infrastructure used
by both adversaries and benign users is honest.
In particular, a
common router that holds trafﬁc of the adversary and the honest
user cannot collude to perform an attack against the benign user
(e.g., r2 in Figure 1). On the other hand, the adversary, if at the
scale of a subdomain, may control a router where no trafﬁc of the
benign user passes through (e.g., r3 could replace AP2 in Figure 1).
This assumption can be further used by the adversary to enumerate
in real-time what contents are being consumed by other users in his
domain, and to help him improve the inference attack on other users
within proximity but in other domains (see §1 for such scenario).
Finally, the attack discussed in this paper is applicable to CCN, and
to a lesser extent to other proposals [5, 10, 16].
2.2 Design Goals and Privacy Deﬁnition
The design goals in this paper is to protect the privacy of the
users fetching contents using the ICN at reasonable cost. We use
the classical deﬁnition and meaning of the privacy as “anonymity”:
the adversary should not be able with his reasonable resources (as
assumed in section 2.1) to pinpoint the user fetching such contents
among a ﬁnite number of users within his proximity. To end, we
deﬁnite the anonymity set of a user fetching the contents as the
number of users at an less than or equal distance from the adver-
sary to that user, who could potentially be fetching that same con-
tents. To this end, we outline the following design goals. (i) Protect
the user privacy: the main design goal in this work is to defend an
adversary from inferring users’ access patterns to contents fetched
and distributed using ICN (details below). The privacy is deﬁned as
anonymity, and increasing the anonymity set of the requested trafﬁc
so that to make the inference as less accurate as possible would suf-
ﬁce the purpose. (ii) Cost effective: the modiﬁcations and overhead
for providing privacy to the access pattern of the users should not
represent a great overhead in relation with the operational overhead
of the ICN (used for routing or caching). Furthermore, the protec-
tion mechanisms should not generate an excessive amount of com-
munication overhead (in the form of bits on wire). (iii) Minimal
change to existing ICN protocols: ideally, we want our solutions
not to alter the way caching and routing operate in the ICN.
3. PROTECTION MECHANISMS
As mentioned earlier, simple solutions cannot prevent the timing
attacks for privacy while they greatly degrade the beneﬁts of ICN
architectures. Also, intelligent caching requires a topology knowl-
edge that is beyond a router’s resources. To this end, we propose
several solutions without requiring such knowledge.
Before going into the details of the protocols, we introduce the
time (delay) generation procedure performed by an edge router, and
takes several parameters based on the speciﬁc protocol, and the
number of hops to be added as noise to prevent the timing attack.
For a content name n ∈ N , the total number of hops h, RTT tdx,
and the time delay for the ﬁrst hop td0, td(n) is chosen as follows
to balance privacy and loss in performance. For a given n, the same
value of td(n) is used for subsequent requests.
td(n) =(cid:26) 0
2td0  1
(1)
3.1 The “Vanilla” Approach
The vanilla algorithm to prevent timing attacks on privacy in ICN
is described in Algorithm 1. The main ingredient of the algorithm
is a carefully chosen delay added to subsequent responses to make
them similar to the responses that fall back on the origin servers to
ensure that the contents that are sent to an adversary do not expose
timing patterns—such patterns could be used to infer if other users
have requested the same contents. For that, the protocol relies on
states stored by each edge router to name the contents that are of
privacy-value to users, the number of times the contents are being
served to each user, and the user id.
Particularly, for a user u (U1 in Fig. 1), its edge router (r2 in
Fig. 1) maintains ϕ(u, n) : U × N → IN T , where U , N , and
IN T are the sets of users, content names, and integers, respec-
tively. ϕ(u, n) indicates the number of times that user u has ac-
cessed the content name n. At the beginning, assuming benign
user U1 ﬁrst generates interest Ints = (U1, n, pmode, ts0) with
pmode = 1, where ts0 is the timestamp of when the interest is is-
sued. When r2 receives this, it follows the ICN protocol [11] to
retrieve a data packet Data from the origin server, and records ts2
upon the arrival of the ﬁrst packet in response of the interest. Fol-
lowing Eq. 1, r2 computes expected number of hops from the user
U1 to the origin server as h = tdx(N )/(2td0)+1, and then records
tdx along with (U1, n), and updates the ϕ to indicate the times that
the user has accessed the content. r2 then serves the content to U1.
When another interest for n is issued by user U2, who is a potential
attacker, the router r2 acts in response to this interest as follows:
If U2 has previously requested n, r2 responses directly and serves
contents from the cache. Else r2 applies the random delay and re-
turns Data to U2.
3.2 An Efﬁcient Approach
While the vanilla algorithm preserves the privacy of user’s access
history from attackers in the same domain, it consumes signiﬁcant