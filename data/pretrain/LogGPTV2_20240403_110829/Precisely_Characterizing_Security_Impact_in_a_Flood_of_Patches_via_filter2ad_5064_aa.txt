title:Precisely Characterizing Security Impact in a Flood of Patches via
Symbolic Rule Comparison
author:Qiushi Wu and
Yang He and
Stephen McCamant and
Kangjie Lu
Precisely Characterizing Security Impact in a Flood
of Patches via Symbolic Rule Comparison
Qiushi Wu, Yang He, Stephen McCamant, and Kangjie Lu
University of Minnesota, Twin Cities
{wu000273, he000242}@umn.edu, PI:EMAIL, PI:EMAIL
Abstract—A bug is a vulnerability if it has security impacts
when triggered. Determining the security impacts of a bug is
important to both defenders and attackers. Maintainers of large
software systems are bombarded with numerous bug reports and
proposed patches, with missing or unreliable information about
their impact. Determining which few bugs are vulnerabilities is
difficult, and bugs that a maintainer believes do not have security
impact will be de-prioritized or even ignored. On the other hand,
a public report of a bug with a security impact is a powerful first
step towards exploitation. Adversaries may exploit such bugs to
launch devastating attacks if defenders do not fix them promptly.
Common practice is for maintainers to assess the security impacts
of bugs manually, but the scaling and reliability challenges of
manual analysis lead to missed vulnerabilities.
We propose an automated approach, SID, to determine the
security impacts for a bug given its patch, so that maintainers
can effectively prioritize applying the patch to the affected
programs. The insight behind SID is that both the effect of a
patch (either submitted or applied) and security-rule violations
(e.g., out-of-bound access) can be modeled as constraints that can
be automatically solved. SID incorporates rule comparison, using
under-constrained symbolic execution of a patch to determine
the security impacts of an un-applied patch. SID can further
automatically classify vulnerabilities based on their security
impacts. We have implemented SID and applied it to bug patches
of the Linux kernel and matching CVE-assigned vulnerabilities
to evaluate its precision and recall. We optimized SID to reduce
false positives, and our evaluation shows that, from 54K recent
valid commit patches, SID detected 227 security bugs with at
least 243 security impacts at a 97% precision rate. Critically,
197 of them were not reported as vulnerabilities before, leading
to delayed or ignored patching in derivative programs. Even
worse, 21 of them are still unpatched in the latest Android
kernel. Once exploited, they can cause critical security impacts
on Android devices. The evaluation results confirm that SID’s
approach is effective and precise in automatically determining
security impacts for a massive stream of bug patches.
I.
INTRODUCTION
Major system programs receive an overwhelming number of
bug reports, and dealing with these bug reports is much of the
life-cycle cost of the software. For instance, Mozilla developers
dealt with almost 300 bugs per day in 2005 [2], and a similar
rate of new bugs are received in the Mozilla bug database [36]
today. The Linux kernel also experiences this problem. As of
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.24419
www.ndss-symposium.org
August 2019, more than 855K patches have been applied by
kernel maintainers [49], and the actual number of submissions
examined is even higher because many proposed patches are
not applied, or require several rounds of revision. Linux also
receives many proposed patches from external contributors.
Sometimes, these patches fix important bugs, while other
patches fix general bugs or even insignificant bugs. Therefore,
maintainers must manually review and prioritize the submitted
patches to decide if they should be applied immediately or not.
Large-scale commercial software development faces similar
challenges with bug reports from internal testers and changes
proposed by less-experienced developers. This work is time-
consuming and error-prone. For example, Hooimeijer et al. [25]
showed that 70% of the total life-cycle cost of software is
consumed by maintenance, such as modifying existing code
and dealing with bugs.
Given their limited resources, maintainers have to prioritize
which bugs to fix by assigning bugs to different priority levels.
Highest-priority bugs, such as an obvious security vulnerability,
must be fixed immediately. However, lower-priority bugs may
be fixed slowly, remain unpatched for a long period of time, or
fall through the cracks completely. The common practice is for
maintainers to assess the security impacts of bugs manually [39],
which is not only challenging and expensive, but also error-
prone. This manual classification requires considerable human
effort and requires code maintainers to have wide security
domain knowledge.
If the security impacts of a critical bug cannot be correctly
identified, it will be treated as a lower-priority bug, which
will lead to serious security problems. For instance, Arnold
et al. [3] described a high-impact compromise of servers for
Debian Linux made possible by a Linux kernel vulnerability
for which a patch had been available for eight weeks. The
Debian administrators had not updated the kernels because
the security implications of the patch were not clear until
after it was used in a successful exploit. Arnold et al. called
this kind of bug a hidden-impact vulnerability: one that is
not identified as a vulnerability until after it is made public
and potentially exploited by attackers. Their work shows that
32% of vulnerabilities in the Linux kernel were hidden impact
vulnerabilities before they were publicized.
Lack of reliable information about the security impacts of
bugs is even more critical when open-source software is used
in other projects. For example, the Linux kernel is widely used
and customized by a large number of platforms such as the
Internet of Things (IoT) devices and mobile devices (most
prominently Android). A 2018 survey reported by Hall [24]
shows that more than 70% of IoT developers use Linux, and
Android had a 75% share of the worldwide mobile OS market
as of April 2019 [14]. Given the fragmentation of versions and
uses of the Linux kernel, it would be impossible for every patch
to be promptly applied to every Linux-based device. Instead,
patches must be prioritized based on their severity. For instance,
under the Android Security Rewards Program [22], reporters
are typically required to demonstrate the reproducibility and
impact of the reported bugs; otherwise, the reported patches
will likely be declined. Previously, we reported three new
NULL-pointer dereference bugs to the Android Security team
without mentioning their security impacts or providing a proof-
of-concept exploit. We considered these to be vulnerabilities
because they can cause DoS, but the Android Security team
declined the patches because we did not prove the security
impact of the bugs. The empirical results we report also show
that bugs that cannot be determined to have security impacts
may not be fixed promptly, and thus may introduce serious
security problems.
Given the significance of security bugs, many recent
papers [5, 19, 23, 50, 53, 54, 65] have attempted to distinguish
security bugs from general bugs automatically. Most of these
works focus on analyzing textual information, such as a bug
description, and their classification of security impacts is mainly
based on text-mining techniques. A fundamental limitation is
that such classification is highly dependent on the quality of the
textual information, which in turn depends on the experience
and security-related knowledge of the reporters. Unfortunately,
our results indicate that, in many cases, the reporters themselves
are not aware of the potential security impacts of the bugs
they report. We found that 60.8% of vulnerability patches
for the Linux kernel do not mention security impacts in the
patch description or subjects. Thus, we cannot expect any
classification based on this textual information to reliably
classify security bugs. This observation is consistent with recent
results by Chaparro et al. [8] which show that many textual
bug reports are missing important details and the measurements
of Tian et al. [47] which suggest that bug severity ratings are
unreliable (i.e., they differ even for duplicate reports of the
same bug). To identify security-related patches precisely, we
need a more reliable approach to determine the security impacts
of bug patches based on code instead of prose.
Existing automated tools also do not provide sufficient
support to analyze the security impacts of bugs. Static-analysis
tools can warn about code constructs that may have security
impacts when misused. However, they generally do not analyze
all the factors that affect security impacts. Instead, they make
conservative assumptions and thus produce a significant number
of false-positive reports that must be filtered out in another
step. Providing a proof-of-concept exploit (“PoC”) is strong
evidence of security impacts, but it requires every patch to
include an exploit, which would be a major burden on bug
reporters. Bug-finding tools based on fuzzing [44, 59] or whole-
program symbolic execution [42, 60] often create a PoC when
detecting a problem, but such tools currently generate only a
minority of kernel-bug reports, because of challenges such as
state explosion and modeling hardware devices. We would like
the process of fixing a vulnerability to be faster than the process
of exploiting it if defenders are to stay ahead of attackers. Thus
we need an approach to assess the security impact of a bug
that is easier than generating a PoC. For adoption, such a tool
must have a low false-positive rate and the ability to relate the
results to the specific security impact that is implicated. An
analysis tool must be trustworthy to convince developers to
take a second look at a patch they would otherwise pass by.
In this paper, we propose an automated system, SID, to
determine the security impacts of bugs, given their patches.
Using security rules that capture common security impacts, SID
distinguishes unsafe (rule-violating) and safe (rule-compliant)
behaviors of patched and unpatched code, which allows SID
to characterize the security impacts of a bug. SID employs
differential, under-constrained symbolic execution to match a
security risk that is fixed by a patch. The intuition is that both
security rules and the program behaviors that are feasible in
the unpatched and patched versions can be captured precisely
with symbolic constraints. By comparing security constraints
with code, SID can reliably determine: (1) if the unpatched
code must violate a security rule—the unpatched code has
a security problem, and (2) whether the patched code can
never violate the same security rule—the patched code has
eliminated the security problem present in the unpatched code.
If both conditions are evaluated to be true, this is a strong
confirmation that the patch will fix a security violation, and
thus that the bug will have a security impact. More importantly,
the conservativeness of under-constrained symbolic execution
ensures the reliability and the scalability of SID’s determination
of security impacts. We use slicing and under-constrainted
symbolic execution to precisely analyze just the code region that
is directly relevant to a patch, making conservative assumptions
about interactions with other kernel states. This approach avoids
most false positives but without expanding the analysis to the
whole kernel or requiring an effort that is equivalent to fuzzing
or exploit generation. SID determines security impacts based
on the code semantics instead of textual information. Based
on the semantics, SID can detect the security bugs reliably
and provide details about how a bug can be exploited to cause
security impacts. This supports developers in formulating an
appropriate response to a security bug.
Our priority is for SID’s reports of security impact to be
reliable, i.e., with high precision and few false positives. To
achieve this, we are willing to accept false-negative cases where
there is a security impact that the current implementation of
SID is unable to recognize. Some causes include unusual types
of security impacts that are not captured by SID’s current
security rules and the conservative strategy of under-constrained
symbolic execution that may miss some cases. An empirical
analysis of SID’s false-negative results for known vulnerabilities
appears in §VI-B. Further development to reduce false negatives
would expand the benefits of SID, but since the current state of
practice does not use automated tools to analyze impact at all,
we believe that the best path to adoption and security benefit
is to begin with tools whose results developers can easily trust
when they signal a security bug.
We have implemented SID based on LLVM as multiple
static analysis passes. One is a data-flow analysis pass, which
identifies vulnerable operations and security operations; the
other is an under-constrained symbolic execution pass, which
precisely reasons about security impacts. We choose the Linux
kernel as our experimental target because it is one of the
most widely used and actively-maintained open-source system
programs. The security of the Linux kernel is also important to
many IoT and mobile devices. For evaluation, we selected 66K
2
recent git commits from the Linux kernel. From these commits,
we identified 54K valid commit patches and finally compiled
and analyzed 110K LLVM IR files in total. By analyzing these
files, SID successfully found 227 security bugs with a 97%
precision rate. These security bugs may introduce security
impacts such as out-of-bound access, use-after-free, double-
free, uninitialized use, and permission bypass. More critically,
we found that 21 of these security bugs are still not patched in
Android, which can cause severe security problems for billions
of Android devices.
To further confirm that the identified security bugs are
vulnerabilities, we analyzed the reachability of the security bugs
from attacker-controllable entry points (e.g., system calls) and
also reported them to CVE maintainers. As a result, we find that
67.8% of identified security bugs are potentially reachable from
entry points. On the other hand, we in total reported 154 security
bugs to CVE maintainers and have received 37 responses with
24 new CVEs assigned. The evaluation results show that SID is
effective and precise in automatically determining the security
impacts of a large number of bug patches.
We make the following contributions in this paper.
• A study of security bugs and patches. The boundary
between bugs and vulnerabilities can be unclear. We first
study the differences between bugs and vulnerabilities. We
then model patches for common security bugs, including
missing/wrong bound check, missing pointer nullification,
missing initialization, and missing permission check. The
modeling enables us to define the security impacts of bugs
and thus confirm security bugs.
• Symbolic rule comparison for determining security
impacts. We propose SID to determine the security
impacts of bugs automatically. The core of SID is symbolic
rule comparison which employs differential and under-
constrained symbolic execution to precisely confirm the
security impacts that a patch fixes. In addition, SID also
provides details about the security impacts to facilitate
bug fixing.
• Finding of security bugs and unpatched vulnerabilities.
With SID, we found 227 security bugs in the Linux kernel;
21 of them still remain unpatched in Android, which can
be exploited to attack billions of Android devices. Also, 24
new CVEs have been assigned to the identified security
bugs. Further, we evaluated the reachability of all the
identified security bugs, and found that 67.8% of them
are potentially reachable from attacker-controllable entry
points.
The rest of this paper is organized as follows. We review
background concepts in §II, and give an overview of our
approach in §III. We then present the design of SID in section
§IV; the implementation of SID in section §V; the evaluation
of SID in section §VI; limitations and future work in section
§VII; related work in §VIII; and the conclusion in §IX.
II. BACKGROUND
To propose an effective approach to understand the causes
and security impacts of bugs and thus to find security bugs,
we analyzed some existing patches for vulnerabilities in the
Linux kernel. Specifically, we first show differences between
general bugs and vulnerabilities. Then, we analyze the common
causes and security impacts of vulnerabilities. Based on the
statistical results, we summarize the model and components
of the vulnerability patches. After that, we define the problem
scope and the assumptions of this work.
A. General Bugs, Security Bugs, and Vulnerabilities
A bug is a vulnerability if it causes security impacts when
triggered. A vulnerability is also called a security-critical bug
(or just a security bug), and is distinguished from a general
bug. Different kinds of vulnerabilities often differ in security
impacts. The example in Figure 1 shows the difference between
a general bug and a vulnerability. In this example, missing
the check in line 3 is a vulnerability because it leads to an
out-of-bound access in line 9. In comparison, missing the check
in line 6 will not introduce any security impact; thus, it is just
a general bug. More details about the definition and detection
for security checks can be found in previous work [51].
{
char colors[4] = {’r’,’g’,’b’,’-’};
if (Type > 3)
return -1;
1 int Bug_Vuln(unsigned int Type)
2
3
4
5
6
7
8
9
10
11 }
printf("Color Type: %c", colors[Type]);
return 0;
if (Type == 3)
return 0;
Fig. 1: Differences between a vulnerability and a general bug. Missing
the check in line 3 results in a vulnerability while missing the check
in line 6 is a general semantic bug.
B. Common Security Bugs and Impacts
Common security bugs
(root cause)
Missing/wrong bound check
Missing initialization
Missing permission check
Missing NULL check
Missing/wrong locks/unlocks
API misuse
Missing error-code check
Missing pointer nullification
Others such as
numerical errors
Percent Main security impacts
of bugs
21%
9%
9%
7%
6%
5%
5%
4%
34%
Out-of-bound access
Uninitialized use
Permission bypass
NULL-pointer dereference
Use-after-free, double-free,
Permission bypass,
NULL-pointer dereference
Out-of-bound access,
Permission bypass,
Uninitialized use
Out-of-bound access,
Uninitialized use,
NULL-Pointer dereference
Use-after-free, double-free
Uninitialized use,
Out-of-bound access,
NULL-pointer dereference,
Others
TABLE I: Common security bugs and security impacts.
In this work, we aim to cover the most common security
bugs and their corresponding security impacts. To this end, we
first examined recent Linux-kernel vulnerabilities included in
the national vulnerability database (NVD). There are nearly
800 vulnerabilities reported in the past three years, but only
a small part of them include valid git-commit information of
their patches. Thus, we chose to analyze 100 of them across
these years.
3
Table I presents the analysis results. The most common
causes for security bugs in the Linux kernel are missing
or wrong security checks (bound check, permission check,
NULL check, etc.), missing initialization, missing or incorrect
locks/unlocks, API misuse, and missing nullification. The
following results also show the relationship between the
root causes of security bugs and their security impacts: (1)
missing/wrong bound check typically leads to out-of-bound
access; (2) missing initialization often leads to uninitialized
use; (3) missing permission check leads to permission bypass;
(4) missing NULL check commonly leads to NULL-pointer
dereference; and (5) missing pointer nullification leads to use-
after-free and double-free.
In the study, we differentiate the bugs (i.e., the root causes)
from their security impacts, which are often mixed up in
traditional vulnerability classification (e.g., in NVD). While
traditional vulnerability classification tends to focus on security
impacts, they are not the root causes. For example, missing
a bound check is the bug; however, the out-of-bound access
caused by the missing-check bug is the security impact. As
such, bug patches typically fix the root causes and only
indirectly prevent security impacts. Therefore, to determine
security impacts, we need to analyze the “effects” of patches.
Moreover, we define security impacts based on the security-rule
violating operations (e.g., out-of-bound access and use-after-
free) instead of the resulting exploits such as information leaks
or control-flow hijacking. This is consistent with the goal of
SID—determining how a bug results in security-rule violating