𝑏 ∈ 𝐄𝐱𝐩(𝔹), 𝑘 ∈ 𝐄𝐱𝐩(𝕂).
view of 𝑒 to an adversary that can decrypt under (all and
only) the keys in 𝑆.
∙ A function 𝐫(𝑝) mapping a pattern 𝑝 to a corresponding
set of keys, which may be recoverable by an adversary
that sees all the parts of 𝑝.
The deﬁnition of these functions is virtually identical to the
one given in [18] for expressions with pseudorandom keys,
extended with an additional case for our “controlled swap”
expressions. Informally, 𝐩(𝑒, 𝑆) replaces all subexpressions of
𝑒 of the form ⦃𝑒′⦄𝑘 for some 𝑘 ∉ 𝑆 and 𝑒′ ∈ 𝐏𝐚𝐭(𝑠), with
the pattern ⦃𝑠⦄𝑘. The formal deﬁnition is given in Fig. 1.
The formal deﬁnition of 𝐫 is more technical, and uses the
auxiliary functions 𝐊𝐞𝐲𝐬 and 𝐏𝐚𝐫𝐭𝐬 describing the keys and
parts of an expression given in Fig. 2. As a matter of notation,
for any two expressions 𝑒′ and 𝑒, we say that 𝑒′ is a sub-
expression of 𝑒, denoted as 𝑒′ ⋐ 𝑒, if 𝑒′ ∈ 𝐏𝐚𝐫𝐭𝐬(𝑒). Notice that
encryption keys 𝑘 are not considered sub-expressions of⦃𝑒⦄𝑘,
cannot, in general, recover 𝑘 from ⦃𝑒⦄𝑘. Informally, 𝐫(𝑒) is
as, even an adversary with unlimited decryption capabilities
deﬁned as the set of all keys that can be potentially recov-
ered from 𝐏𝐚𝐫𝐭𝐬(𝑒). In [18], this is deﬁned using a general
framework to model partial information in symbolic security
analysis. For simplicity, here we only give the deﬁnition
specialized to our class of expressions.
Deﬁnition 3. For any 𝑒 ∈ 𝐏𝐚𝐭, we deﬁne the key recovery
)
function 𝐫 ∶ 𝐏𝐚𝐭 → ℘(𝐏𝐚𝐭(𝕂)) as follows:
𝐫(𝑒) = 𝖦∗
{𝑘 ∈ 𝐊𝐞𝐲𝐬(𝑒) ∣ (𝑘 ⋐ 𝑒) ∨ (∃𝑘′ ∈ 𝐊𝐞𝐲𝐬(𝑒).𝑘 ≺ 𝑘′)}
Informally, 𝐫(𝑒) contains all keys 𝑘 from 𝐊𝐞𝐲𝐬(𝑒) (and
pseudorandom keys that can be derived from 𝑘) such that
either 𝑘 appears in 𝑒 as a sub-expression, or 𝑘 is related to
(
some other key in 𝐊𝐞𝐲𝐬(𝑒). The intuition behind this deﬁnition
is that the adversary can learn a key 𝑘 either by reading it
directly from the parts of 𝑒, or by combining diﬀerent pieces
of partial information about 𝑘. We refer the reader to [18] for
further discussion and justiﬁcation of this deﬁnition.
One can check by induction that the following commutative
properties hold for 𝐩 and 𝐫: For any pattern 𝑒 ∈ 𝐏𝐚𝐭, set
of keys 𝑆 ⊆ 𝐊∗, and pseudorandom renaming 𝛼, we have
𝛼(𝐩(𝑒, 𝑆)) = 𝐩(𝛼(𝑒), 𝛼(𝑆)), and 𝛼(𝐫(𝑒)) = 𝐫(𝛼(𝑒)).
h) Computational soundness: We can now return to
the framework of [12] to associate computationally sound
symbolic patterns to cryptographic expressions. The functions
𝐩 and 𝐫 are used to deﬁne, for any 𝑒 ∈ 𝐏𝐚𝐭, a key recovery
operator
𝑒(𝑆) = 𝐫(𝐩(𝑒, 𝑆))
mapping any set of keys 𝑆 ⊆ 𝖦∗(𝐊), to the set of keys
potentially recoverable by an adversary that
is capable of
decrypting under the keys in 𝑆. This operator is used in [12]
to prove the following general computational soundness result.
Theorem 2 ([12, Theorem 1]). Assume the functions 𝐩, 𝐫
satisfy the following properties:
1) 𝐩(𝑒, 𝐊∗) = 𝑒
2) 𝐩(𝐩(𝑒, 𝑆), 𝑇 ) = 𝐩(𝑒, 𝑆 ∩ 𝑇 ) for all 𝑆, 𝑇 ⊆ 𝐊∗
3) 𝐫(𝐩(𝑒, 𝑇 )) ⊆ 𝐫(𝑒) for all 𝑇 ⊆ 𝐊∗
4) The distributions (cid:2)𝑒(cid:3) and (cid:2)𝐩(𝑒, 𝐫(𝑒))(cid:3) are computation-
ally indistinguishable.
Then, the key recovery operator 𝑒 has a (unique) greatest
ﬁxed point Fix(𝑒) = ∩𝑖>0 (𝑖)
𝑒 (𝐊∗), and the pattern
𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒) = 𝐩(𝑒, Fix(𝑒))
is computationally sound, in the sense that (cid:2)𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒)(cid:3) and
(cid:2)𝑒(cid:3) are computationally indistinguishable distributions.
One can check that the functions 𝐩 and 𝐫 satisfy all the
conditions 1 to 3 in Theorem 2. For the last condition, the
following lemma shows that (cid:2)𝑒(cid:3) and (cid:2)𝐩(𝑒, 𝐫(𝑒))(cid:3) are indis-
tinguishable for all patterns 𝑒. The proof is omitted due to
space constraint. Using the soundness theorem of the general
symbolic framework of [12] we can then conclude that our
symbolic semantics is computationally sound.
Lemma 3. For any 𝑒 ∈ 𝐏𝐚𝐭, the probability distributions (cid:2)𝑒(cid:3)
and (cid:2)𝐩(𝑒, 𝐫(𝑒))(cid:3) are computationally indistinguishable.
Recall that renamings commute with the pattern function
𝐩, i.e., for any expression 𝑒 and for any set of keys 𝑆 ⊆ 𝐊∗,
𝐩(𝛼(𝑒), 𝛼(𝑆)) = 𝛼(𝐩(𝑒, 𝑆)). It follows that 𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝛼(𝑒)) =
𝛼(𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒)), and therefore we can extend the computational
soundness theorem to pattern equivalence up to renaming. That
is, for any two expressions 𝑒1 and 𝑒2, symbolic equivalence
(up to pseudorandom renaming) of their patterns 𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒1)
and 𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒2) implies that the two probability distributions
(cid:2)𝑒1(cid:3) and (cid:2)𝑒2(cid:3) are computationally indistinguishable.
Theorem 3. For any two symbolic expressions 𝑒0, 𝑒1,
if
𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒0) ≈ 𝐏𝐚𝐭𝐭𝐞𝐫𝐧(𝑒1), then (cid:2)𝑒0(cid:3) and (cid:2)𝑒1(cid:3) are compu-
tationally indistinguishable.
152
III. INDUCTIVE CIRCUITS
𝑖=1 and wires {𝑤𝑖}𝑝
Traditionally, boolean circuits are described by two sets of
gates {𝑔𝑖}𝑞
𝑖=1 and a description of how they
are connected together. Each wire carries a boolean value, that
is either given as part of the input to the circuit, or is computed
by a gate. Each gate is associated to a number of input and
output wires, and sets the value of the output wires to some
ﬁxed function of the values of the input wires. For simplicity,
we consider circuits using just two types of gates:
S
Swap
A
U
Assoc
Unassoc
D
Dup
↑N
NAnd
∙ a NAND gate that on input two boolean values 𝑥0, 𝑥1,
computes the output 𝑦 = 𝑥0 ↑ 𝑥1, and
∙ a DUP gate, which duplicates the value on its single input
wire 𝑥 to its two output wires 𝑦0 = 𝑦1 = 𝑥.
The NAND function itself is complete for the set of all
boolean functions, and the DUP gate can be used to implement
arbitrary fan-out. So any boolean circuit can be converted to
this notation. A circuit with 𝑛 input wires and 𝑚 output wires
computes a boolean function 𝑓 ∶ {0, 1}𝑛 → {0, 1}𝑚
.
This traditional formalization of circuits is completely un-
structured, making it inconvenient to use in symbolic construc-
tions and proofs of security. Below we present an alternative
way to describe boolean circuits, which is inductive (larger
circuits are built from smaller ones), and supports deﬁnitions
and proofs by structural induction.
We begin by putting some structure on the set of input and
output wires of a circuit, by deﬁning the notion of a wire
bundle. Informally, the shape of a wire bundle is deﬁned by
a well parenthesized expression like (◦, (◦, ◦)). Formally, we
can deﬁne bundle to be either a single wire (represented by
the symbol ◦), or an ordered pair (𝑢, 𝑣) where 𝑢 and 𝑣 are wire
bundles. The size of a bundle is simply the number of wires
in it, i.e., the number of ◦ subexpressions. Each wire ◦ carries
a bit 𝑏 ∈ {0, 1}, and a bundle of 𝑛 wires naturally carries a
bit vector in {0, 1}𝑛
, but the additional bundle structure will
give us easier access to individual bits, without having to index
them. We remark that the grouping of wires is not associative,
i.e., ((𝑢, 𝑣), 𝑤) is diﬀerent from (𝑢, (𝑣, 𝑤)).
We deﬁne circuits inductively, specifying a number of
basic circuits, and some general operations to combine them
together. Each circuit takes as input a bundle of wires, and
produces as output another bundle. The set of circuits with
input shape 𝑠 and output shape 𝑡 is denoted by Circuit(𝑠, 𝑡).
Circuits,
their inputs and outputs, and the functions they
compute, are formally speciﬁed in the following deﬁnition,
with the base and inductive cases illustrated in Fig. 3 and 4.
Deﬁnition 4. A circuit
from the
set {𝐒𝐰𝐚𝐩, 𝐀𝐬𝐬𝐨𝐜, 𝐔𝐧𝐚𝐬𝐬𝐨𝐜, 𝐃𝐮𝐩, 𝐍𝐀𝐧𝐝}, or it is a composite
circuit built using operations ⋙ and 𝐅𝐢𝐫𝐬𝐭. The semantics of
basic circuits are:
is either a basic circuit
((𝑢, 𝑣), 𝑤).
∙ 𝐒𝐰𝐚𝐩 consumes wires (𝑢, 𝑣) and produces wires (𝑣, 𝑢).
∙ 𝐀𝐬𝐬𝐨𝐜 consumes wires (𝑢, (𝑣, 𝑤)) and produces wires
∙ 𝐔𝐧𝐚𝐬𝐬𝐨𝐜 consumes wires ((𝑢, 𝑣), 𝑤) and produces wires
∙ 𝐃𝐮𝐩 consumes a single wire 𝑤 and produces wires (𝑤, 𝑤).
(𝑢, (𝑣, 𝑤)).
Fig. 3. The atomic circuits 𝐒𝐰𝐚𝐩, 𝐀𝐬𝐬𝐨𝐜, 𝐔𝐧𝐚𝐬𝐬𝐨𝐜, 𝐃𝐮𝐩, and 𝐍𝐀𝐧𝐝. The
dotted lines indicate how values are transferred from input wires to output
wires. For 𝐒𝐰𝐚𝐩, 𝐀𝐬𝐬𝐨𝐜, and 𝐔𝐧𝐚𝐬𝐬𝐨𝐜, an arrow may represent a bundle of
more than one wires.
𝐶0
𝐶1
𝐶0 ⋙ 𝐶1
𝐶
𝐅𝐢𝐫𝐬𝐭(𝐶)
Fig. 4. Composite circuits 𝐶0 ⋙ 𝐶1 and 𝐅𝐢𝐫𝐬𝐭(𝐶) using operations ⋙ and
𝐅𝐢𝐫𝐬𝐭 on circuits 𝐶0, 𝐶1, 𝐶. Dotted lines draw the boundaries of composite
circuits.
∙ 𝐍𝐀𝐧𝐝 consumes wires (𝑢, 𝑣), where 𝑢 and 𝑣 are single
wires carrying bits 𝑥 and 𝑦, and its output is a single
wire that carries the bit 𝑥 ↑ 𝑦.
For composite circuits, assume 𝐶0 is a circuit that takes 𝑢
as input wires and produces output wires 𝑤, and 𝐶1 a circuit
that takes 𝑤 as input wires and produces output wires 𝑣. Then
∙ 𝐶0 ⋙ 𝐶1 is a circuit that takes input 𝑢 and produces
output 𝑣, obtained by ﬁrst applying 𝐶0 on 𝑢 to get an
intermediate result 𝑤, and then applying 𝐶1 on 𝑤 to get 𝑣.
∙ 𝐅𝐢𝐫𝐬𝐭(𝐶0) is a circuit that takes input wires (𝑢, 𝑢′) and
produces output wires (𝑤, 𝑢′) for any wires 𝑢′, where 𝑤
is the output of 𝐶0 on input 𝑢, and 𝑢′ is left unchanged
by the circuit.
To evaluate a circuit, we deﬁne the function 𝐄𝐯(𝐶, 𝑤) that
takes a circuit 𝐶 ∈ Circuit(𝑠, 𝑡) and a wire bundle 𝑤 of shape
𝑠, and return a bundle of shape 𝑡 according to the above
semantics. For simplicity, we usually just write 𝐶(𝑥) for the
boolean value carried on the wires 𝑢 = 𝐄𝐯(𝐶, 𝑤) where 𝑥 is
the value carried on 𝑤.
We remark that the circuit concatenation operation ⋙ is
associative, i.e., (𝐶0 ⋙ 𝐶1) ⋙ 𝐶2 and 𝐶0 ⋙ (𝐶1 ⋙ 𝐶2)
produce the same circuit. So, we may omit the parentheses
when writing a sequence of concatenations 𝐶0 ⋙ 𝐶1 ⋙ 𝐶2.
For a circuit 𝐶, we say that 𝐶′ is a sub-circuit of 𝐶 if one
of the following holds: