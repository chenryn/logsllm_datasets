User: 如何配置Hadoop集群，以及如何在集群中进行数据存储和计算。
Assistant: 配置Hadoop集群的步骤大致如下：

1. 安装Hadoop
在所有的节点（主节点和从节点）上安装相同版本的Hadoop。可以从Hadoop官网下载最新版本的二进制文件。

2. 配置SSH登录
所有的节点必须安装OpenSSH并且SSH命令必须能够在任何节点中运行（即在每个节点中添加公钥）。

3. 配置Hadoop文件系统
将Hadoop的hadoop-env.sh和core-site.xml文件中的配置更新为适合当前集群的值。在主节点上创建一个HDFS文件系统，并通过Namenode的web页进行验证。

4. 配置YARN
将YARN的yarn-env.sh和yarn-site.xml文件中的配置更新为适合当前集群的值。在主节点上启动YARN ResourceManager和NodeManager。

5. 配置MapReduce
将MapReduce的mapred-env.sh和mapred-site.xml文件中的配置更新为适合当前集群的值。在主节点上启动MapReduce JobHistoryServer和TaskTracker。

6. 测试Hadoop集群是否成功
创建一个HDFS目录、上传文件、运行一个MapReduce作业。

一旦Hadoop集群配置完成，就可以在集群中进行数据存储和计算，步骤如下：

1. 数据存储
将数据放在一个HDFS文件系统上，主要是通过hadoop fs命令来存储数据。可以使用put命令将本地文件上传到HDFS上，也可以使用copyFromLocal命令从本地文件系统复制数据到HDFS上。另外，使用hadoop distcp命令可以将一个HDFS上的目录复制到另一个HDFS上。

2. 数据计算
使用MapReduce框架进行数据计算，MapReduce是一个分布式计算框架，可以将大规模的任务分解成小的任务并在集群中分布式执行，从而加速计算过程。首先需要编写MapReduce的mapper和reducer代码，然后将代码打包成JAR文件，最后使用hadoop jar命令来提交作业。

除了MapReduce框架，还可以使用Hadoop的其他组件来进行数据计算，例如Spark、Hive、Pig以及HBase等。使用这些组件可以加快数据计算的速度，并提高计算效率。