wrappers (described above); (iii) support communication
between the user-mode policy manager and the kernel-
mode security monitor through the character device in-
terface for installing policies and registering handlers for
ON POLICY VIOLATION events; and (iv) trap exec calls
which execute programs from speciﬁed directories and
switch control to the policy manager so that the program
can be sandboxed. Changes to TxOS included (i) allowing
system calls responsible for external I/O to execute non-
transactionally without affecting the current transaction and
(ii) enabling the TXBOX security monitor to force another
process to execute in a transaction.
The latter task presented an interesting challenge. In
TxOS, an application starts a transaction by calling xbe-
gin, which causes the common system-call handler in ‘en-
try.S’ to invoke the beginT ransaction kernel function,
followed by do sys xbegin. Obviously, there is no xbe-
gin in the sandboxed process. To force it into a transac-
tion (possibly in the middle of a system-call execution),
TXBOX cannot call beginT ransaction directly because
is xbegin
beginT ransaction checks if the current call
and, if so, stores the context of the user process so that
it can be restored if the transaction is aborted. We added a
f orced transaction ﬂag (set by the TXBOX enforcer) to
the process-speciﬁc task structure and modiﬁed the handler.
If the sandboxed process makes a system call when the ﬂag
is set, the handler saves the eax register which contains the
number of the actual call, replaces it with 342, the number of
xbegin, then calls beginT ransaction and do sys xbegin.
Once the forced transaction starts, eax is restored to the
number of the actual call.
To implement the TXBOX policy decision engine, we
ported a regular expression library to execute in the kernel.
We use hash tables to store and quickly look up policy-
related information. The hash-table key for every policy
object is the pid of the process on which that policy is
being enforced. A policy object contains the list of all
WHITELIST and BLACKLIST regular expressions which
are part of that policy. It also contains three hash tables for
looking up, respectively, if a system call should be logged,
if it should be denied, and if it is critical.
transaction. If the process is later found to have violated
the policy, TXBOX cannot roll back the I/O calls, but local
recoverability is always preserved.
In summary, TXBOX gives two enforcement options. The
ﬁrst option is to deny external I/O (possibly depending on the
arguments).2 This preserves full recoverability if a violation
is detected, but may cripple functionality of the untrusted
program. The second option is to allow external I/O, but if
the program violates the policy after I/O has been executed,
recover locally by undoing all of its effects on the host. We
argue that this is the best any sandbox can hope to achieve.
D. Handling external I/O by sandboxed process
A typical application mostly performs two types of I/O:
disk and network. System transactions buffer all disk I/O un-
til the transaction commits or aborts. Certain operations—in
particular, those requiring bidirectional communication to
an external entity (this includes network I/O) and writing
to external devices—cannot be buffered until the end of a
transaction and thus have to be executed non-transactionally.
How to handle external I/O whose effects cannot be
undone is a generally unsolvable problem faced by any
sandbox. If the sandboxed code attempts to make a remote
network call, the sandbox must allow or deny the call—even
if the information about
the code’s execution so far is
insufﬁcient to determine whether the code is malicious or
benign. Distributed transactions are not feasible in most
sandboxing scenarios because the destination of the call
made by an untrusted application may be malicious and not
conform to transactional semantics (e.g., it may refuse to
roll back when instructed by the security monitor).
Conventional system-call monitors make the allow/deny
decision on a call-by-call basis. The TXBOX solution is
superior. When the sandboxed process attempts to perform
an external I/O call, TXBOX ﬁrst checks if the currently
enforced policy has any DENY primitives that match this
system call and its arguments. If such a DENY primitive
exists, TXBOX returns an error without performing the
external I/O operation and continues executing the program
as part of the current transaction, giving it an opportunity to
handle the failed call. Denying an I/O call is always a safe
decision because it guarantees full recoverability, regardless
of what the sandboxed process does to the local system.
If there are no DENY primitives matching the call,
control is switched to the policy decision engine. The engine
inspects the trace of the process, which includes all of its
prior system calls, their arguments, and all system objects
affected by the process, and matches the trace against the
policy as in normal enforcement (see Section V-C).
If the process has already violated the policy, TXBOX
terminates it and aborts the current transaction, rolling back
all of its effects. If the process has not yet violated the policy,
TXBOX executes the I/O operation outside of the current
transaction but continues running the process in the current
VI. EVALUATION
In this section, we benchmark the performance of TXBOX
and evaluate its ability to sandbox substantial applications
and roll back the effects of malicious execution. In perfor-
mance tests, we compare TXBOX with the standard Linux
kernel (version 2.6.22.6) as well as the Linux kernel with the
Dazuko module (version 2.3.4) installed. Because TXBOX
uses Dazuko’s system-call hooking mechanism and char-
acter device interface, Linux kernel with Dazuko installed
is an appropriate baseline for measuring the overhead of
transactional execution and security checks on transactional
worksets. All experiments were performed on a server with
one quad-core Intel X5355 processor running at 2.66 GHz
with 4GB of memory, unless otherwise mentioned. We omit
the statistical variance, which is low in all cases.
For installing test policies automatically, we put all test
programs in a dedicated directory and register the policy
manager for the ON EXEC event so that its gets control
whenever a program from this directory is executed. The
policy manager installs the policy and instructs the enforcer
to put the sandboxed process into a forced transaction.
A. Performance
Micro-benchmarks. Table II shows the overhead of TXBOX
for individual system calls—including read, write, and
fork/exec—compared to the base Linux kernel with and
without Dazuko. The policy for all tests is BLACKLIST
WREGEX *I:1234* unless otherwise speciﬁed.
In most cases, the cost of transactional execution and
security checks—represented by the performance penalty
of TXBOX viz. standard Linux with Dazuko installed—is
negligible. The single exception is open. Note that open is
by far the worst possible system call for TXBOX, because the
TxOS kernel needs to create a shadow copy of the object and
add it to the transactional workset. The overhead of a single
open call is broken down in Table III; security enforcement
is responsible for less than 5%. In practical applications, the
cost of open will be amortized over many system calls.
2It may also be possible to make decisions speciﬁc to a network protocol
such as DNS or HTTP. This requires the monitor to accurately mirror
protocol state, which is hard in general and prone to the same semantic
gaps that allow malicious processes to exploit incorrect mirroring of kernel
state in system-call monitors.
338
Table II
SYSTEM-CALL MICRO-BENCHMARKS. TIMES SHOWN FOR THE FIRST
FOUR ROWS ARE AVERAGES OF WALL-CLOCK TIMES OVER 100,000
RUNS FOR 10 DIFFERENT SETS. TIMES SHOWN FOR FORK AND
FORK+EXEC ARE AVERAGES OF WALL-CLOCK TIMES OVER 10,000
RUNS FOR 10 DIFFERENT SETS.
Syscall
getuid
open
read
write
fork
fork+
exec
Linux
0.08 µs
1.53 µs
0.27 µs
0.27 µs
82.7 µs
136.7 µs
TXBOX
Kernel
Linux+Dazuko
0.08 µs 1.00× 0.08 µs 1.00×
1.62 µs 1.06× 4.72 µs 3.09×
0.27 µs 1.00× 0.27 µs 1.00×
0.27 µs 1.00× 0.32 µs 1.18×
82.8 µs 1.00× 83.4 µs 1.01×
136.7 µs 1.00× 138.9 µs 1.01×
BREAKDOWN OF PERFORMANCE OVERHEAD FOR OPEN.
Table III
Cause
open
System-call interposition (Dazuko)
Transactional overhead
Policy overhead
Total
Time
1.53 µs
0.09 µs
2.98 µs
0.12 µs
4.72 µs
Application benchmarks. We evaluated TXBOX on gzip,
make, and PostMark. PostMark (version 1.51) is a ﬁle-
system benchmark which simulates the behavior of an email,
network news, and e-commerce client. Evaluation on larger
applications can be found in Section VI-B.
Table IV shows the slowdowns for gzip and make. For
gzip, which does not involve many ﬁle-system operations,
the overhead of TXBOX is negligible (1.007×). For make,
Table IV
TIME TAKEN BY GZIP TO COMPRESS A 4 MB FILE AND BY MAKE TO
COMPILE TWO SOURCE FILES WITH POLICY BLACKLIST WREGEX
*I:1234* ON TXBOX AND LINUX. TIMES SHOWN ARE AVERAGES OF
WALL-CLOCK TIMES OVER 100 RUNS.
gzip
0.0401 sec
0.0403 sec 1.004× 0.145 sec 1.00×
Linux
Linux+
Dazuko
TXBOX 0.0404 sec 1.007× 0.177 sec 1.18×
make
0.145 sec
Table V
POSTMARK BENCHMARK RESULTS IN FILE-SYSTEM TRANSACTIONS
PER SECOND WITH POLICY BLACKLIST WREGEX *I:1234*. THE
NUMBER OF FS-TRANSACTIONS IS SET TO 100,000. POSTMARK IS
CONFIGURED TO USE NON-BUFFERED I/O FOR ALL THE TESTS.
Linux
Linux+Dazuko
TXBOX
8411 FS-transactions/sec
7692 FS-transactions/sec 1.09×
16666 FS-transactions/sec 0.50×
which involves more ﬁle-system operations than gzip, the
overhead is 1.18×. On the other hand, PostMark benchmark
involves a large number of ﬁle-system operations and repre-
sents the worst-case scenario for TXBOX because it requires
a large number of shadow objects to be created. Furthermore,
because the transaction can only be committed once the
PostMark benchmark calls exit, TxOS kernel needs to keep
track of all shadow objects until the end of the program.
Performance results for the PostMark benchmark are
shown in Table V. They are presented in terms of ﬁle-system
transactions per second (we refer to them as FS-transactions
to avoid confusion with system transactions). TXBOX results
in a factor-of-2 speed-up (represented in the table as 0.5×
slowdown) due to the fact that the transaction commit groups
all writes and presents them to the I/O scheduler all at once,
thus improving disk arm scheduling.
)
s
d
n
o
c
e
s
i
l
l
i
m
n
i
(
e
d
o
m
l
e
n
r
e
k
n
i
t
n
e
p
s
e
m
T
i
 8.5
 8
 7.5
 7
 6.5
 6
 5.5
 5
 4.5
 4
 0
 50
 100
 150
 200
Policy size(in number of conjunctions)
Figure 3. Time spent in kernel mode (as reported by “time”) for a simple
program which opens 100 existing ﬁles, as a function of the policy size.
Times shown are averages over 10 runs.
Scalability. To evaluate the scalability of TXBOX, we built
a simple application which opens 100 existing ﬁles and
measured how its runtime varies with the increase in the size
of the policy (the number of inodes included in the policy).
In this test, we enforce a policy which is a conjunction of N
statements, each of which is a blacklist on a single inode. We
run this test on a laptop with an Intel Core Duo 2.00 GHz
CPU and 2 GB RAM. The results are shown in Figure 3.
I/O-intensive applications. Because transactional semantics
cannot be preserved over external I/O, the security monitor
must be invoked before allowing any system call which
performs external (e.g., network) I/O. The call is then exe-
cuted outside the current transaction. For example, consider
a process making the following sequence of calls:
fd = open("foo",..)
read(fd, ..)
sockfd = socket(..)
sendto(sockfd,..)
close(sockfd)
339
close(fd)
..
Because sendto performs network I/O, TXBOX checks if it
matches any DENY primitive in the current policy. If yes, the
call is denied. If not, the monitor is invoked twice to check
if the process violates any BLACKLIST or WHITELIST:
TX BEGIN
fd = open("foo",..)
read(fd, ..)