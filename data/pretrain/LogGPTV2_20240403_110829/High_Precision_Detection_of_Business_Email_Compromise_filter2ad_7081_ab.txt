our dataset, and classiﬁed the roles of the recipient of the
attack, as well as the impersonated sender. Table 2 presents
the results. Based on the results, the term “CEO fraud” used
to describe BEC is indeed justiﬁed: about 43% of the imper-
sonated senders were the CEO or founder. The targets of the
attacks are spread much more equally across different roles.
However, even for impersonated senders, the majority (about
57%) are not the CEO. Almost half of the impersonated roles
and more than half of targets are not of “sensitive” positions,
such as executives, ﬁnance or HR. Therefore, simply protect-
ing employees in sensitive departments in not sufﬁcient to
protect against BEC.
2.2 Common Types of BEC
To guide the discussion, we describe the three most common
examples of BEC attacks within our dataset: wire transfer,
rapport, and impersonation phishing. In §6 we will discuss
other attacks that are not covered by this paper. All three
examples we present are real BEC attacks from within our
dataset, in which the names, companies, email addresses and
links have been anonymized.
Example 1: Wire transfer example
From : " Jane Smith " 
To : " Joe Barnes " 
Subject : Vendor Payment
Hey Joe ,
Are you around ? I need to send a wire
transfer ASAP to a vendor .
Jane
In Example 1, the attacker asks to execute a wire transfer.
Other similar requests include asking for W-2 forms, medical
information or passwords. In the example the attacker spoofs
the name of an employee, but uses an email address that
USENIX Association
28th USENIX Security Symposium    1293
Example 2: Rapport example
From : " Jane Smith " 
Reply - to : " Jane Smith " 
To : " Joe Barnes " 
Subject : At desk ?
Joe , are you available for something urgent ?
Example 3: Spoofed Name with Phishing Link
From : " Jane Smith " 
To : " Joe Barnes " 
Subject : Invoice due number 381202214
I tried to reach you by phone today but I
couldn ’t get through . Please get back to me
with the status of the invoice below .
Invoice due number 381202214:
[http://firetruck4u.net/past-due-invoice/]
does not belong to the organization’s domain. Some attackers
even use a domain that looks similar to the target organiza-
tion’s domain (e.g., instead of acme.com, the attacker would
use acrne.com). Since many email clients do not display the
sender email address, some recipients will be deceived even
if the attacker uses an unrelated email address.
Example 2 tries to create a sense of urgency. After the recip-
ient responds to the email, the attacker will typically ask for a
wire transfer. The email has the from address of the employee,
while the reply-to address will relay the response back to the
attacker. Email authentication technologies such as DMARC,
SPF and DKIM can help stop spoofed emails. However, the
vast majority of organizations do not enforce email authenti-
cation [25], because it can be difﬁcult to implement correctly
and often causes legitimate emails to be blocked.2 Therefore,
our goal is to detect these attacks without relying on DMARC,
SPF and DKIM.
Example 3 uses a spoofed name, and tries to get the re-
cipient to follow a phishing link. Such phishing links are
typically not detected by existing solutions, because the link
is unique to the recipient (“zero-day”) and will not appear
in any black lists. In addition, attackers often compromise
relatively reputable websites (e.g., small business websites)
for phishing links, which are often classiﬁed as high repu-
tation links by email security systems. The link within the
email will typically lead the recipient to a website, where they
will be prompted to log in a web service (e.g., an invoicing
application) or download malware.
3 Intuition: Exploiting the Unique Attributes
of Each Attack
The three examples all contain unique characteristics, which
set them apart from innocent email messages. We ﬁrst de-
2Many organizations have legitimate systems that send emails on their
behalf, for example, marketing automation systems, which can be erroneously
blocked if email authentication is not setup properly.
scribe the unique attributes in the header of each example,
and then discuss the attributes of the email body and how they
can be used to construct the features of a machine learning
classiﬁer. We also discuss legitimate corner cases of these
attributes that might fool a classiﬁer and cause false positives.
Header attributes.
In Example 1 and 3, the attacker im-
personates the name of a person, but uses a different email
address than the corporate email address. Therefore, if an
email contains a name of an employee, but uses an email
address that is not the typical email address of that employee,
there is a higher probability that the sender is an imposter.
However, there are legitimate use cases of non-corporate
emails by employees. First, an employee might use a personal
email address to send or forward information to themselves
or other employees in the company. Ideally, a machine learn-
ing classiﬁer should be able to learn all the email addresses
that belong to a certain individual, including corporate and
personal email addresses. Second, if an external sender has
the same name as an internal employee, it might seem like an
impersonation.
In Example 2, the attacker spoofs the legitimate email ad-
dress of the sender, but the reply-to email address is different
than the sender address, which is unusual (we will also dis-
cuss the case where the attacker sends a message from the
legitimate address of the sender without changing the reply-to
ﬁeld in §6). However, such a pattern has legitimate corner
cases as well. Some web services and IT systems, such as
LinkedIn, Salesforce, and other support and HR applications,
“legitimately impersonate” employees to send notiﬁcations,
and change the reply-to ﬁeld to make sure the response to the
message is recorded by their system.
Other header attributes might aid in the detection of BEC
attacks. For example, if an email is sent at an abnormal time of
day, or from an abnormal IP or from a foreign country. How-
ever, many BEC attacks are designed to seem legitimate, and
are sent in normal times of day and from seemingly legitimate
email addresses.
Body attributes. The body of Example 1 contains two
unique semantic attributes. First, it discusses sensitive in-
formation (a wire transfer). Second, it is asking for a special,
immediate request. Similarly, the text of Example 2 is ask-
ing whether the recipient is available for an urgent request.
Such an urgent request for sensitive information or availabil-
ity might be legitimate in certain circumstances (for example,
in an urgent communication within the ﬁnance team).
The unique attribute in the body of Example 3 is the link
itself. The link is pointing to a website that does not have
anything to do with the company: it does not belong to a web
service the company typically uses, and it is not related to the
company’s domain.
Finally, all three examples contain certain textual and visual
elements that are unique to the identity of the sender. For
example, Example 1 contains the signature of the CEO and
all of the emails contain a particular grammar and writing
1294    28th USENIX Security Symposium
USENIX Association
style. If any of these elements deviate from the style of a
normal email from a particular sender, they can be exploited
to detect an impersonation. Since in many BEC emails the
attackers take great care in making the email appear legitimate,
we cannot overly-depend on detecting stylistic aberrations.
As shown above, each of the examples has unique anoma-
lous attributes that can be used to categorize it as a BEC attack.
However, as we will show in §7, none of these attributes on
its own is sufﬁcient to classify an email with a satisfactory
false positive rate.
Leveraging historical emails. Much of prior work in de-
tecting email-borne threats relies on detecting malicious sig-
nals in the email, such as sender and link domain reputa-
tion [2, 48], malicious attachments [49], as well as relying on
link click logs and IP logins [20]. However, as Table 1 and
the examples we surveyed demonstrate, most BEC attacks
do not contain any obviously malicious attachments or links.
Intuitively, access to the historical emails of an organization
would enable a supervised learning system to identify the
common types of BEC attacks by identifying anomalies in
the header and body attributes. We make the observation that
popular cloud-based email providers, such as Ofﬁce 365 and
Gmail, enable their customers to allow third party applications
to access their account with certain permissions via public
APIs. In particular, these APIs can enable third-party applica-
tions to access historical emails. This allows us to design a
system that uses historical emails to identify BEC attacks.
4 Classiﬁer and Feature Design
In this section, we describe BEC-Guard’s design goals, and its
training dataset. We then describe the initial set of classiﬁers
we used in BEC-Guard, and present our approach to training
and labeling.
4.1 Design Goals
The goal of BEC-Guard is to detect BEC attacks in real-time,
without requiring the users of the system to utilize security
analysts to manually sift through suspected attacks. To meet
this goal, we need to optimize two metrics: the false positive
rate, and the precision. The false positive rate is the rate of
false positives as a percentage of total received emails. If we
assume an average user receives over 100 emails a day, in
an organization with 10,000 employees, our goal is that it
will be infrequent to encounter a false positive (e.g., once a
day for the entire organization). Therefore, our target false
positive rate is less than one in a million. The precision is the
rate of true positives (correctly detected BEC attacks) as a
percentage of attacks detected by the system, while the false
positive rate is a percentage of false positives of all emails
(not just emails detected by the system). If the precision is not
high, users of BEC-Guard will lose conﬁdence in the validity
of its predictions. In addition to these two metrics, we need
to ensure high coverage, i.e., that the system catches the vast
majority of BEC attacks.
4.2 Dataset and Privacy
We developed the initial version of BEC-Guard using a dataset
of corporate emails from 1,500 organizations, which are ac-
tively paying customers of Barracuda Networks. The organi-
zations in our dataset vary widely in their type and size. The
organizations include companies from different industries
(healthcare, energy, ﬁnance, transportation, media, education,
etc.). The size of the organization varies from 10 mailboxes to
more than 100,000. Overall, to train BEC-Guard, we labeled
over 7,000 examples of BEC attacks, randomly selected from
the 1,500 organizations.
To access the data, these organizations granted us permis-
sion to access to the APIs of their Ofﬁce 365 email environ-
ments. The APIs provide access to all historical corporate
emails. This includes emails sent internally within the orga-
nization, and from all folders (inbox, sent, junk, etc.). The
API also allows us to determine which domains are owned by
each organization, and even whether an email was read.
Ethical and privacy considerations. BEC-Guard is part
of a commercial product, and the 1,500 customers that partic-
ipate in the dataset provided their legal consent to Barracuda
Networks to access their historical corporate emails for the
purpose identifying BEC. Customers also have the option of
revoking access to BEC-Guard at any time.
Due to the sensitivity of the dataset, it was only exposed to
the ﬁve researchers who developed BEC-Guard, under strict
access control policies. The research team only accessed his-
torical emails for the purposes of labeling data to develop
BEC-Guard’s classiﬁers. Once the classiﬁers were developed,
we permanently deleted all of the emails that are not actively
used for training the classiﬁers. The emails used for classiﬁ-
cation are stored encrypted, and access to them is limited to
the research team.
4.3 Dividing the Classiﬁcation into Two Parts
The relative rare occurrence of BEC attacks inﬂuenced several
of our design choices. Our ﬁrst design choice was to rule out
unsupervised learning. Unsupervised learning typically uses
clustering algorithms (e.g., k-means [15]) to group email cat-
egories, such as BEC emails. However, a clustering algorithm
would typically categorize many common categories (e.g.,
social emails, marketing emails), but since BEC is so rare, it
results in low precision and many false positives. Therefore,
supervised learning algorithms are more suitable for detecting
BEC at a high precision. However, using supervised learning
presents its own set of challenges.
In particular, BEC is an extreme case of imbalanced data.
When sampled uniformly, in our dataset, “legitimate” emails
are 50,000× more likely to appear than the BEC emails. This
presents two challenges. First, in order to label a modest
number of BEC emails (e.g., 1,000), we need to label a corpus
USENIX Association
28th USENIX Security Symposium    1295
on the order of 50 million legitimate emails. Second, even
with a large number of labeled emails, training a supervised
classiﬁer over imbalanced datasets is known to cause various
problems, including biasing the classiﬁer to prefer the larger
class (i.e., legitimate emails) [24,26,47,51]. To deal with this
extreme case of imbalanced data, we divided the classiﬁcation
and labeling problem into two parts. The ﬁrst classiﬁer looks
only at the metadata of the email, while the second classiﬁer
only examines the body and subject of the email.
The ﬁrst classiﬁer looks for impersonation emails. We de-
ﬁne an impersonation as an email that is sent with the name of
a person, but was not actually sent by that person. Imperson-
ation emails include malicious BEC attacks, and they also in-
clude emails that legitimately impersonate an employee, such
as internal systems that send automated emails on behalf of
an employee. The impersonation classiﬁer only analyzes the
metadata of the email (i.e., sender, receiver, CC, BCC ﬁelds).
The impersonation classiﬁer detects both spoofed name (Ex-
ample 1 and 3) and spoofed emails (Example 2). The second
set of classiﬁers, the content classiﬁers, only classify emails
that were detected as impersonation emails, by examining
the email’s subject and body to look for anomalies. We use
two different content classiﬁers that each look for different
types of BEC attacks.3 The two content classiﬁers are: the
text classiﬁer, which relies on natural language processing to
analyze the text of the email, and the link classiﬁer, which
classiﬁes any links that might appear in the email.
All of our classiﬁers are trained globally on the same
dataset. However, to compute some of the features (e.g., the
number of time the sender name and email address appeared
together), we rely on statistics that are unique to each organi-
zation.
4.4
Table 3 includes the main features used by the impersonation
classiﬁer. The features describe the number of times speciﬁc
email addresses and names have appeared before in the sender
and reply-to ﬁelds, as well as statistics about the sender’s
identity.
Impersonation Classiﬁer
To demonstrate why it is helpful to maintain historical
statistics of a particular organization, consider Figure 1. The
ﬁgure depicts the number of email addresses that were used
by each sender in an organization with 44,000 mailboxes
over three months. 82% of the users had emails sent from
only one address, and the rest had emails that were sent from
more than one address. The reason that some of the senders
used a large number of email addresses, is that they were