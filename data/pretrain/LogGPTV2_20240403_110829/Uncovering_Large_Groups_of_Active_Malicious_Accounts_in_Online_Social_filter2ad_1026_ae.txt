stage of SynchroTrap’s pipeline under different parameter settings.
In a daily job, the action-matching window Tsim de-
Daily jobs.
termines the size of the sliding comparison windows (§ 4.5.2). To
examine its impact, we vary the value of Tsim from 10 minutes to 5
hours. Figure 13 shows that the execution time of daily jobs grows
as we set Tsim to higher values. This is because a higher compar-
ison window Tsim causes more user pairs to be compared. As we
partition data using overlapping sliding windows, each daily job in
an application ﬁnishes within a few hours.
Aggregation jobs. Figure 14 shows the execution time of aggre-
gation jobs in each application with Tsim set to different values.
)
s
r
u
o
h
(
e
m
i
t
n
o
i
t
u
c
e
x
E
 10
 8
 6
 4
 2
 0
Tsim=10 mins
Tsim=1 hour
Tsim=5 hours
Photo upload
Instagram follow
Page like
Application install
Login
Figure 13: The execution time of SynchroTrap’s daily jobs in
each deployed application. We set Tsim to 10 mins, 1 hour, and
5 hours. Error bars represent 95% conﬁdent intervals.
)
s
r
u
o
h
(
e
m
i
t
n
o
i
t
u
c
e
x
E
 16
 14
 12
 10
 8
 6
 4
 2
 0
Tsim=10 mins
Tsim=1 hour
Tsim=5 hours
Photo upload
Instagram follow
Page like
Application install
Login
Figure 14: The execution time of aggregation jobs in each appli-
cation. The input data volume varies as we generate daily user
pairs using different Tsim values (10 mins, 1 hour, and 5 hours).
Error bars represent 95% conﬁdent intervals.
)
s
n
m
i
(
e
m
i
t
n
o
i
t
u
c
e
x
E
 100
 80
 60
 40
 20
 0
Thresh=0.8
Thresh=0.6
Thresh=0.4
Thresh=0.2
Photo upload
Instagram follow
Page like
Application install
Login
Figure 15: Execution time of ﬁnding connected components in
each application. We set the similarity thresholds in our user-
pair ﬁltering function to 0.2, 0.4, 0.6, and 0.8. Error bars rep-
resent 95% conﬁdent intervals.
As can be seen, an aggregation job takes longer time when we in-
crease Tsim in the daily jobs. This is because a daily job with a
larger Tsim value generates more user pairs with matched actions,
and hence increases the aggregation time. In all applications, each
set of aggregation jobs completes execution within ∼15 hours.
Single-linkage hierarchical clustering on Giraph. SynchroTrap’s
user-pair ﬁltering function (§ 4.4) allows distinct similarity thresh-
olds on different granularities. We use a one-week data set to ex-
amine the execution time of clustering under varying similarity
thresholds. For simplicity we assign the same value to all simi-
larity thresholds and set this value to 0.2, 0.4, 0.6, and 0.8, respec-
tively. Figure 15 shows that the execution time in each application
increases as we set the thresholds to lower values. This is because
a smaller threshold value leads to fewer user pairs to be ﬁltered,
and hence makes the user similarity graph denser. A Synchro-
Trap’s clustering job ﬁnishes within ∼100 minutes as Giraph [11]
is highly efﬁcient.
9. RELATED WORK
In this section, we brieﬂy describe previous OSN defense pro-
posals and compare them with this work. We classify prior work
into three broad categories: social-graph-based approaches, feature-
based account classiﬁcation, and aggregate behavior clustering. This
work belongs to the category of aggregate behavior clustering.
The social-graph-based approaches [19, 46] use social connec-
tivity to infer fake accounts that have limited social connections to
legitimate users. They can detect a signiﬁcant fraction of fake ac-
counts that are created in bulk, but can miss well-maintained fake
accounts and compromised accounts.
Feature-based account classiﬁcation uses various account fea-
tures to train classiﬁers to detect malicious accounts [20,35,42,44].
For example, the Facebook Immune System provides system sup-
port to manage many Facebook attack classiﬁers [35]. COMPA [20]
identiﬁes compromised accounts using statistical models that catch
sudden changes in a user’s behavior, i.e., message sending.
Clickstream [42] and CopyCatch [16] pioneered the work in ag-
gregate behavior clustering for online social network users. Click-
stream compares the pairwise similarity of the http requests from
social network accounts, and clusters accounts with similar http re-
quest patterns together. It uses pre-labeled data to classify a cluster
as fake or legitimate. If the number of pre-labeled fake accounts
in a cluster is larger than a certain threshold, then the cluster is
classiﬁed as fake; otherwise, it is legitimate. Although Clickstream
achieved good detection results on a data set of 16K RenRen net-
work users, we cannot directly borrow this approach mainly be-
cause we aim to deploy SynchroTrap at much larger online social
networks. First, it is practically challenging to compare all clicks
from every pair of users at a large social network with hundreds of
millions of active users. Second, it is difﬁcult to obtain large vol-
umes of training data at a large social network because it requires
expensive manual labeling. Thus, many clusters may not contain
any labeled data, leaving them unclassiﬁed.
CopyCatch [16], a Facebook internal system, detects fake likes
casted in loose synchrony. SynchroTrap’s design is based on a sim-
ilar insight that malicious accounts tend to act together. However,
CopyCatch assumes that a user can perform a malicious action only
once (e.g., like a page at most once) and models the detection prob-
lem as a co-clustering problem [31]. When a user can repeat the
same malicious action multiple times, such as log on from the same
IP address repeatedly, the computational complexity of CopyCatch
grows exponentially with the number of repeated actions.
In contrast, SynchroTrap assumes malicious accounts can repeat
any action many times, and adopts a clustering algorithm whose
computational complexity grows linearly with the number of ac-
tions an account performs (§ 4.7). Moreover, SynchroTrap uses the
source IP addresses and campaign targets to further reduce its com-
putational complexity, making it deployable at a large-scale social
network such as Facebook.
In addition to social network defense systems, SynchroTrap also
borrows insight from previous work on botnet detection [21–23,43,
47], as some attackers use botnets to control malicious accounts. In
particular, BotMiner [21] and BotSniffer [22] detect the bots that
respond to commands in a similar way. BotGraph [47] detects bot-
net IP addresses that are shared by a large number of spamming
email accounts. SynchroTrap also uses shared IP addresses as a
signal to detect groups of malicious accounts, but uses the times-
tamps of user actions to further improve detection accuracy.
10. CONCLUSION
This work aims to detect large groups of active malicious ac-
counts in OSNs, including both fake accounts and compromised
real user accounts. We designed a generic and scalable detection
system, SynchroTrap, that uses clustering analysis to detect large
groups of malicious users that act in loose synchrony. To cope
with the enormous volume of user activity data in a large OSN, we
implemented SynchroTrap as an incremental processing system on
top of Hadoop and Giraph. We further optimize it by partitioning
user activity data by time and only comparing pair-wise user ac-
tions that fall into overlapping sliding windows. We deployed Syn-
chroTrap in ﬁve applications at Facebook and Instagram. During
one month of deployment, SynchroTrap unveiled 1156 large cam-
paigns and more than two million malicious accounts that involved
in the campaigns.
Although we designed SynchroTrap for OSNs, we believe that
the approach of detecting loosely synchronized actions can also
uncover large attacks in other online services, such as web email
and electronic commerce, at the present time. Furthermore, the in-
cremental processing and data partitioning techniques we have ex-
plored may beneﬁt other applications that analyze large volume of
time-independent data by reducing the requirements on their com-
puting infrastructure.
Finally, we note that SynchroTrap’s design uses unsupervised
learning and does not detect malicious actions in real time. In the
future, we can extract attack signatures from the malicious cam-
paigns and accounts it detects and use supervised learning to de-
velop fast classiﬁers that can detect attacks in real time.
11. ACKNOWLEDGMENTS
We thank Yuchun Tang and the anonymous reviewers for their
valuable suggestions. We are grateful to Matt Jones, Benjamin
Yang, Abe Land, Ioannis Papagiannis, and many other members
from the Facebook Site Integrity team for their help during this
project. We are particularly thankful to Michael Sirivianos for his
extensive feedback. We also thank the Facebook Digraph team for
providing the graph processing infrastructure. This work was sup-
ported in part by NSF Awards CNS-0845858 and CNS-1017858.
12. REFERENCES
[1] Better Security through Software. http://www.facebook.com/notes/
facebook/better-security-through-software/248766257130, 2010.
[2] Staying in Control of Your Facebook Logins. http://www.facebook.com/
notes/facebook/staying-in-control-of-your-facebook-logins/
389991097130, 2010.
[15] I. Anderson. Combinatorics of ﬁnite sets. Clarendon Press, 1987.
[16] A. Beutel, W. Xu, V. Guruswami, C. Palow, and C. Faloutsos. CopyCatch:
Stopping Group Attacks by Spotting Lockstep Behavior in Social Networks. In
Proceedings of the 22nd International Conference on World Wide Web (WWW),
2013.
[17] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All Your Contacts Are Belong
to Us: Automated Identity Theft Attacks on Social Networks. In WWW, 2009.
[18] F. Brunk. Intersection Problems in Combinatorics. University of St Andrews
thesis. University of St Andrews, 2009.
[19] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro. Aiding the Detection of Fake
Accounts in Large Scale Social Online Services. In NSDI, 2012.
[20] M. Egele, G. Stringhini, C. Krügel, and G. Vigna. COMPA: Detecting
Compromised Accounts on Social Networks. In NDSS, 2013.
[21] G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner: Clustering Analysis of
Network Trafﬁc for Protocol- and Structure-Independent Botnet Detection. In
USENIX SECURITY, 2008.
[22] G. Gu, J. Zhang, and W. Lee. BotSniffer: Detecting Botnet Command and
Control Channels in Network Trafﬁc. In NDSS, 2008.
[23] S. Hao, N. A. Syed, N. Feamster, A. G. Gray, and S. Krasser. Detecting
Spammers with SNARE: Spatio-Temporal Network-Level Automatic
Reputation Engine. In USENIX SECURITY, 2009.
[24] P. Jaccard. The Distribution of the Flora in the Alpine Zone. New Phytologist,
11(2), 1912.
[25] T. N. Jagatic, N. A. Johnson, M. Jakobsson, and F. Menczer. Social Phishing.
Communications of the ACM, 50(10), 2007.
[26] A. K. Jain, M. N. Murty, and P. J. Flynn. Data Clustering: a Review. ACM
Computing Surveys, 31(3), 1999.
[27] U. Kang, C. E. Tsourakakis, and C. Faloutsos. PEGASUS: Mining Peta-Scale
Graphs. Knowl. Inf. Syst., 27(2), 2011.
[28] G. Karypis and V. Kumar. Multilevel Algorithms for Multi-Constraint Graph
Partitioning. In Proceedings of the 1998 ACM/IEEE conference on
Supercomputing, 1998.
[29] H.-P. Kriegel, P. Kröger, and A. Zimek. Clustering High-Dimensional Data: A
Survey on Subspace Clustering, Pattern-Based Clustering, and Correlation
Clustering. ACM Trans. Knowl. Discov. Data, 3(1), 2009.
[30] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and
G. Czajkowski. Pregel: a System for Large-Scale Graph Processing. In
SIGMOD, 2010.
[31] I. V. Mechelen, H. H. Bock, and P. D. Boeck. Two-mode clustering methods: a
structured overview. Statistical Methods in Medical Research, 13:363–394,
2004.
[32] D. Moore, C. Shannon, G. M. Voelker, and S. Savage. Internet Quarantine:
Requirements for Containing Self-Propagating Code. In INFOCOM, 2003.
[33] M. Motoyama, D. McCoy, K. Levchenko, S. Savage, and G. M. Voelker. Dirty
Jobs: the Role of Freelance Labor in Web Service Abuse. In USENIX
SECURITY, 2011.
[34] R. Nishtala, H. Fugal, S. Grimm, M. Kwiatkowski, H. Lee, H. C. Li,
R. McElroy, M. Paleczny, D. Peek, P. Saab, D. Stafford, T. Tung, and
V. Venkataramani. Scaling Memcache at Facebook. In NSDI, 2013.
[35] T. Stein, E. Chen, and K. Mangla. Facebook Immune System. In Proceedings of
the 4th Workshop on Social Network Systems (SNS), 2011.
[36] K. Thomas, C. Grier, D. Song, and V. Paxson. Suspended accounts in
retrospect: An analysis of twitter spam. In IMC, 2011.
[37] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson. Trafﬁcking
Fraudulent Accounts: The Role of the Underground Market in Twitter Spam
and Abuse. In USENIX SECURITY, 2013.
[38] A. Thusoo, Z. Shao, S. Anthony, D. Borthakur, N. Jain, J. Sen Sarma,
R. Murthy, and H. Liu. Data Warehousing and Analytics Infrastructure at
Facebook. In SIGMOD, 2010.
[3] Working Together to Keep You Secure. http://www.facebook.com/notes/
[39] D. N. Tran, B. Min, J. Li, and L. Subramanian. Sybil-Resilient Online Content
facebook/working-together-to-keep-you-secure/68886667130,
2010.
[4] Amazon EC2 Pricing. http://aws.amazon.com/ec2/pricing/, 2013.
[5] Apache Giraph. http://giraph.apache.org/, 2013.
[6] Apache Hadoop. http://hadoop.apache.org/, 2013.
[7] Cookies, Pixels & Similar Technologies. https://www.facebook.com/
help/cookies, 2013.
Rating. In NSDI, 2009.
[40] C. E. Tsourakakis, C. Gkantsidis, B. Radunovic, and M. Vojnovic. Fennel:
Streaming Graph Partitioning for Massive Scale Graphs. Microsoft Technical
Report MSR-TR-2012-113, 2012.
[41] B. Viswanath, A. Post, K. P. Gummadi, and A. Mislove. An Analysis of Social
Network-based Sybil Defenses. In SIGCOMM, 2010.
[42] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y. Zhao. You are
[8] Facebook Reports Fourth Quarter and Full Year 2012 Results. http://
investor.fb.com/releasedetail.cfm?ReleaseID=736911, 2013.
How You Click: Clickstream Analysis for Sybil Detection. In USENIX
SECURITY, 2013.
[9] Facebook’s New Way to Combat Child Pornography. http://gadgetwise.
[43] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Osipkov. Spamming
blogs.nytimes.com/2011/05/19/facebook-to-combat-child-porn-
using-microsofts-technology, 2013.
Botnets: Signatures and Characteristics. In SIGCOMM, 2008.
[44] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and Y. Dai. Uncovering
[10] Malicious Chrome extensions on the rise. http://www.zdnet.com/
Social Network Sybils in the Wild. In IMC, 2011.
malicious-chrome-extensions-on-the-rise-7000019913/, 2013.
[11] Scaling Apache Giraph to a trillion edges. https://www.facebook.com/
notes/facebook-engineering/scaling-apache-giraph-to-a-
trillion-edges/10151617006153920, 2013.
[45] H. Yu, P. Gibbons, M. Kaminsky, and F. Xiao. SybilLimit: A Near-Optimal
Social Network Defense Against Sybil Attacks. In IEEE S&P, 2008.
[46] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman. SybilGuard: Defending
Against Sybil Attacks via Social Networks. In SIGCOMM, 2006.
[12] Types of cookies used by Google. http://www.google.com/policies/
[47] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum. BotGraph: Large
technologies/types/, 2013.
Scale Spamming Botnet Detection. In NSDI, 2009.
[13] Rate Limiting at Facebook. https://developers.facebook.com/docs/
[48] C. C. Zou, W. Gong, and D. Towsley. Worm Propagation Modeling and
reference/ads-api/api-rate-limiting, 2014.
[14] Rate Limiting at Google+. https://developers.google.com/+/
Analysis Under Dynamic Quarantine Defense. In Proceedings of the 2003 ACM
Workshop on Rapid Malcode (WORM), 2003.
domains/faq, 2014.