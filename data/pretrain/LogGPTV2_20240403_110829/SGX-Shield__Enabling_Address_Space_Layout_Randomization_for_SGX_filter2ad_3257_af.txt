times without developer’s help), T-SGX [53] suggests a defense
based on Intel Transactional Synchronization Extensions (TSX)
to hide page faults against the untrusted kernel.
Also, incorrect use of SGX instructions or bugs related to
memory accesss inside the enclave makes enclave programs
vulnerable. To handle this problem, Moat [56] suggests a new
programming model that checks services related to the security
of the SGX program (e.g., remote attestation and cryptographic
sealing). It not only verifies the confidentiality of an enclave
program, but also checks whether the enclave program actually
leaks the data. Rohit et al. [55] introduce a runtime library that
offers an interface to securely communicate with the external
party of the enclave. It also provides core services for the secure
memory management and runtime checks for verification.
Commodity TEEs and software-based solutions. While
much commodity hardware, including Intel SGX [30, 39] and
ARM TrustZone [8],provide Trusted Execution Environments
(TEEs), Sancus [43] designs a hardware architecture for TEEs.
To the best of our knowledge, Secure OS of the ARM TrustZone
does not support ASLR and software DEP [51]. However,
applying ASLR and software DEP to ARM TrustZone is another
research issue to be explored with different challenges (e.g.,
different side-channel) compared to SGX-Shield.
There are several approaches to shield applications from
untrusted privileged software in the software manner [22, 25, 35,
63]. Minibox [35] ensures mutual distrust between the program
code and the OS on top of a trusted hypervisor with small
TCB (pieces of application logic). CloudVisor [63] protects
the virtual machines of customers by separating resource
management from the virtualization layer. InkTag [25] proposes
the defense mechanism against compromised system call
interfaces to protect persistent storage, and Virtual Ghost [22]
similarily protects the memory from the host OS using compiler
instrumentation.
ASLR and runtime re-randomization. ASLR is applied
to commodity OS [3, 44] to defend against return-to-libc
[42] and return-oriented-programming (ROP) attacks [49]
by obfuscating locations of code gadgets. However, several
ways to bypass ASLR have been reported [36, 48, 50, 58],
stemming from the low entropy of randomness [36, 50] and
memory disclosures [48, 58]. To address the low entropy issue,
13
many fine-grained ASLR techniques [13, 23, 24, 32, 45, 59]
claim that randomizing the code in various fine-grained units
(e.g., basic block or instruction level) can be a solution. Several
studies [10, 21, 38] show that the encryption of visible pointers
and non-readable executable pages prevents attackers from
abusing memory disclosures.
The runtime re-randomization [14, 34, 37] is a strong
defense mechanism against both brute-force attacks and memory
disclosure exploits. In particular, RUNTIMEASLR [37] and
Oxymoron [11] aim to protect from attacks using random
memory corruption tests during the process forks [16]. By re-
randomizing the memory layout of child processes, attackers
cannot guess the memory layout of the parent process. Similar
to process fork, in Android system address space of the user
process is copied from a pre-initialized process called Zygote
that makes the memory layouts of user processes the same at
the initial state. Morula [34] re-randomizes the child process
to mitigate this problem.
Software DEP. The software DEP design of SGX-Shield is
inspired by Native Client (NaCL) [47, 62]. NaCl [62] proposes
an efficient SFI mechanism based on masking instructions and
adopting the memory segment of an x86 system. The goal
of NaCl is to sandbox a memory region in a user process to
run a third-party component such as an untrusted library in
the region. The next version of NaCl [47] extends it to ARM
and x86-64 architectures. The instrumentation of software DEP
in SGX-Shield is similar to NaCl on x86-64, but we cannot
assume that the base address of data pages is aligned with
4GB, while NaCl for x86-64 makes the assumption. Because
of this limitation, our software DEP has a penalty to add one
more sub instruction for the instrumentation.
IX. CONCLUSION
In this paper, we identified fundamental challenges in
enabling ASLR for the SGX environment. We took the real-
world example, Linux and Windows SDKs for Intel SGX, and
found its critical security limitations. This paper also proposes
a solution, SGX-Shield, a new ASLR implementations for SGX
programs. SGX-Shield incorporates a secure in-enclave loader,
software DEP, and software fault isolation to provide secure
ASLR for SGX. The evaluation that we conducted on the real
Intel SGX hardware demonstrates SGX-Shield’s effectiveness
in both security and performance.
X. ACKNOWLEDGMENT
We thank the anonymous reviewers and our proofreader,
Tricia Grindel, for their helpful feedback. This work was
supported in part by BSRP (NRF-2015R1D1A1A01058713),
Office of Naval Research Global (ONRG), IITP (B0101-15-
0557) funded by the Korea Government (MEST), KAIST
Venture Research Program for Graduate & Ph.D students, and
NSF awards DGE-1500084, CNS-1563848 and CRI-1629851.
REFERENCES
[1] “Apache hadoop project.” [Online]. Available: http://hadoop.apache.org/
[2] “Linux/unix nbench.” [Online]. Available: http://www.tux.org/~mayer/
linux/bmark.html
[3] “Documentation for the pax project (address space layout randomization),”
2003. [Online]. Available: https://pax.grsecurity.net/docs/aslr.txt
[4] “mbedtls,” 2016. [Online]. Available: https://tls.mbed.org/
[5] “musl-libc,” 2016. [Online]. Available: https://www.musl-libc.org/
[6] “Writing an llvm backend,” 2016. [Online]. Available: http://llvm.org/
docs/WritingAnLLVMBackend.html
[7] M. Abadi, M. Budiu, Ú. Erlingsson, and J. Ligatti, “Control-flow integrity
principles, implementations, and applications,” ACM Transactions on
Information and System Security (TISSEC), vol. 13, no. 1, p. 4, 2009.
[8] T. Alves and D. Felton, “Trustzone: Integrated hardware and software
security,” ARM white paper, vol. 3, no. 4, pp. 18–24, 2004.
[9] S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe, J. Lind,
D. Muthukumaran, D. Oâ ˘A ´ZKeeffe, M. L. Stillwell et al., “Scone: Secure
linux containers with intel sgx,” in Proceedings of the 12th Symposium
on Operating Systems Design and Implementation (OSDI), Savannah,
GA, Nov. 2016.
[10] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. Nürnberger, and J. Pewny,
“You can run but you can’t read: Preventing disclosure exploits in
executable code,” in Proceedings of the 21st ACM Conference on
Computer and Communications Security, Scottsdale, Arizona, Nov. 2014.
[11] M. Backes and S. Nürnberger, “Oxymoron: Making fine-grained memory
randomization practical by allowing code sharing,” in Proceedings of the
23rd Usenix Security Symposium (Security), San Diego, CA, Aug. 2014.
[12] A. Baumann, M. Peinado, and G. Hunt, “Shielding applications from
an untrusted cloud with haven,” in Proceedings of the 11th Symposium
on Operating Systems Design and Implementation (OSDI), Broomfield,
Colorado, Oct. 2014.
[13] S. Bhatkar, D. C. DuVarney, and R. Sekar, “Efficient techniques for
comprehensive protection from memory error exploits.” in Proceedings
of the 14th Usenix Security Symposium (Security), Baltimore, MD, Aug.
2005.
[14] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and H. Okhravi, “Timely
rerandomization for mitigating memory disclosures,” in Proceedings of
the 22nd ACM Conference on Computer and Communications Security,
Denver, Colorado, Oct. 2015.
[15] C. M. Bishop and N. M. Nasrabadi, Pattern recognition and machine
learning.
springer New York, 2006.
[16] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazières, and D. Boneh,
“Hacking blind,” in Proceedings of the 35th IEEE Symposium on Security
and Privacy (Oakland), San Jose, CA, May 2014.
[17] N. Carlini and D. Wagner, “Rop is still dangerous: Breaking modern
the 23rd Usenix Security Symposium
defenses,” in Proceedings of
(Security), San Diego, CA, Aug. 2014.
[18] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham, and
M. Winandy, “Return-oriented programming without returns,” in Pro-
ceedings of the 17th ACM Conference on Computer and Communications
Security, Chicago, Illinois, Oct. 2010.
[19] S. Checkoway and H. Shacham, Iago Attacks: Why the System Call API
is a Bad Untrusted RPC Interface, Houston, TX, Mar. 2013.
[20] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, S. Beattie, A. Grier,
P. Wagle, Q. Zhang, and H. Hinton, “Stackguard: Automatic adaptive
detection and prevention of buffer-overflow attacks,” in Proceedings of
the 7th Usenix Security Symposium (Security), San Antonio, TX, Jan.
1998.
[21] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi,
S. Brunthaler, and M. Franz, “Readactor: Practical code randomization
the 36th IEEE
resilient
Symposium on Security and Privacy (Oakland), San Jose, CA, May
2015.
to memory disclosure,” in Proceedings of
[22] J. Criswell, N. Dautenhahn, and V. Adve, “Virtual ghost: Protecting
applications from hostile operating systems,” 2014.
[23] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced operating
system security through efficient and fine-grained address space random-
ization,” in Proceedings of the 21st Usenix Security Symposium (Security),
Bellevue, WA, Aug. 2012.
[24] J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson, “Ilr:
Where’d my gadgets go?” in Proceedings of the 33rd IEEE Symposium
on Security and Privacy (Oakland), San Francisco, CA, May 2012.
[25] O. S. Hofmann, S. Kim, A. M. Dunn, M. Z. Lee, and E. Witchel, “Inktag:
Secure applications on an untrusted operating system,” in Proceedings
14
the 18th International Conference on Architectural Support
of
for
Programming Languages and Operating Systems (ASPLOS), Houston,
TX, Mar. 2013.
[26] T. Hunt, Z. Zhu, Y. Xu, S. Peter, and E. Witchel, “Ryoan: A distributed
sandbox for untrusted computation on secret data,” in Proceedings of
the 12th Symposium on Operating Systems Design and Implementation
(OSDI), Savannah, GA, Nov. 2016.
[27] Intel,
2015,
Software-Guard-Extensions-Enclave-Writers-Guide.pdf.
Intel Software Guard Extensions Enclave Writer’s Guide,
https://software.intel.com/sites/default/files/managed/ae/48/
[28] ——, Intel Software Guard Extensions Evaluation SDK for Windows OS,
2016, https://software.intel.com/en-us/sgx-sdk-support/documentation.
[29] ——, Intel(R) Software Guard Extensions SDK for Linux* OS, 2016,
https://01.org/sites/default/files/documentation/intel_sgx_sdk_developer_
reference_for_linux_os_pdf.pdf.
[30] ——, Intel Software Guard Extensions Programming Reference (rev2),
Oct. 2014.
[31] P. Jain, S. Desai, S. Kim, M.-W. Shih, J. Lee, C. Choi, Y. Shin, T. Kim,
B. B. Kang, and D. Han, “Opensgx: An open platform for sgx research,”
in Proceedings of the 2016 Annual Network and Distributed System
Security Symposium (NDSS), San Diego, CA, Feb. 2016.
[32] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address space layout
permutation (aslp): Towards fine-grained randomization of commodity
software,” in Annual Computer Security Applications Conference.
IEEE,
2006, pp. 339–348.
[33] S. Kim, Y. Shin, J. Ha, T. Kim, and D. Han, “A first step towards
leveraging commodity trusted execution environments for network
applications,” in Proceedings of the 14th ACM Workshop on Hot Topics
in Networks (HotNets), Philadelphia, PA, Nov. 2015.
[34] B. Lee, L. Lu, T. Wang, T. Kim, and W. Lee, “From zygote to morula:
Fortifying weakened aslr on android,” in Proceedings of the 35th IEEE
Symposium on Security and Privacy (Oakland), San Jose, CA, May 2014.
[35] Y. Li, J. McCune, J. Newsome, A. Perrig, B. Baker, and W. Drewry,
“Minibox: A two-way sandbox for x86 native code,” in Proceedings of
the 2014 ATC Annual Technical Conference (ATC), Philadelphia, PA,
Jun. 2014.
[36] L. Liu, J. Han, D. Gao, J. Jing, and D. Zha, “Launching return-
oriented programming attacks against randomized relocatable executables,”
in Trust, Security and Privacy in Computing and Communications
(TrustCom), 2011 IEEE 10th International Conference on.
IEEE, 2011,
pp. 37–44.
[37] K. Lu, S. Nürnberger, M. Backes, and W. Lee, “How to make aslr win
the clone wars: Runtime re-randomization,” Feb. 2016.
[38] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee, “Aslr-guard:
Stopping address space leakage for code reuse attacks,” in Proceedings of
the 22nd ACM Conference on Computer and Communications Security,
Denver, Colorado, Oct. 2015.
[39] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shafi,
V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and
software model for isolated execution.” in HASP@ ISCA, 2013, p. 10.
[40] I. Molnar, “Exec shield,” new Linux security feature, 2003.
[41] ——, “Nx (no execute) support for x86, 2.6.7-rc2-bk2,” LWN.net, 2004.
[42] Nergal, “The advanced return-into-lib(c) exploits: Pax case study,”
Phrack. [Online]. Available: http://phrack.org/issues/58/4.html
[43] J. Noorman, P. Agten, W. Daniels, R. Strackx, A. Van Herrewege,
C. Huygens, B. Preneel, I. Verbauwhede, and F. Piessens, “Sancus:
Low-cost trustworthy extensible networked devices with a zero-software
trusted computing base.” in Proceedings of the 22th Usenix Security
Symposium (Security), Washington, DC, Aug. 2013.
[44] S. A. T. R. Ollie Whitehouse, Architect, “An analysis of address space
layout randomization on windows vista,” White paper, 2007.
[45] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Smashing the
gadgets: Hindering return-oriented programming using in-place code
randomization,” in Proceedings of the 33rd IEEE Symposium on Security
and Privacy (Oakland), San Francisco, CA, May 2012.
[46] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado, G. Mainar-
Ruiz, and M. Russinovich, “Vc3: Trustworthy data analytics in the cloud
using sgx,” in Proceedings of the 36th IEEE Symposium on Security and
Privacy (Oakland), San Jose, CA, May 2015.
[47] D. Sehr, R. Muth, C. Biffle, V. Khimenko, E. Pasko, K. Schimpf, B. Yee,
and B. Chen, “Adapting software fault isolation to contemporary cpu
architectures.” in Proceedings of the 19th Usenix Security Symposium
(Security), Washington, DC, Aug. 2010.
[48] F. J. Serna, “The info leak era on software exploitation,” Black Hat USA,
2012.
[49] H. Shacham, “The geometry of innocent flesh on the bone: Return-into-
libc without function calls (on the x86),” in Proceedings of the 14th ACM
Conference on Computer and Communications Security, Alexandria, VA,
Oct.–Nov. 2007.
[50] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh,
“On the effectiveness of address-space randomization,” in Proceedings of
the 11th ACM Conference on Computer and Communications Security,
Washington, DC, Oct. 2004.
[51] D. Shen, “Attacking your trusted core: Exploiting trustzone on android,”
Blackhat, 2015.
[52] M.-W. Shih, M. Kumar, T. Kim, and A. Gavrilovska, “S-nfv: Securing
nfv states by using sgx,” in Proceedings of the 2016 ACM International
Workshop on Security in Software Defined Networks & Network Function
Virtualization. ACM, 2016, pp. 45–48.
[53] M.-W. Shih, S. Lee, T. Kim, and M. Peinado, “T-sgx: Eradicating
controlled-channel attacks against enclave programs,” in Proceedings
of the 2017 Annual Network and Distributed System Security Symposium
(NDSS), San Diego, CA, Feb. 2017.
[54] S. Shinde, Z. L. Chua, V. Narayanan, and P. Saxena, “Preventing your
faults from telling your secrets: Defenses against pigeonhole attacks,”
arXiv preprint arXiv:1506.04832, 2015.
[55] R. Sinha, M. Costa, A. Lal, N. Lopes, S. Seshia, S. Rajamani, and
K. Vaswani, “A design and verification methodology for secure isolated
regions,” in Proceedings of the 2016 ACM SIGPLAN Conference on
Programming Language Design and Implementation, Jun. 2016.
[56] R. Sinha, S. Rajamani, S. Seshia, and K. Vaswani, “Moat: Verifying
confidentiality of enclave programs,” in Proceedings of the 22nd ACM
Conference on Computer and Communications Security, Denver, Colorado,
Oct. 2015.
[57] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R.
Sadeghi, “Just-in-time code reuse: On the effectiveness of fine-grained
address space layout randomization,” in Proceedings of the 34th IEEE
Symposium on Security and Privacy (Oakland), San Francisco, CA, May
2013.
[58] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund, and
T. Walter, “Breaking the memory secrecy assumption,” in Proceedings
of the Second European Workshop on System Security. New York, NY,
USA: ACM, 2009.
[59] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary stirring:
Self-randomizing instruction addresses of legacy x86 binary code,” in
Proceedings of the 19th ACM Conference on Computer and Communica-
tions Security, Oct. 2012.
[60] J. Wilander, N. Nikiforakis, Y. Younan, M. Kamkar, and W. Joosen,
“Ripe: Runtime intrusion prevention evaluator,” in Proceedings of the
27th Annual Computer Security Applications Conference. ACM, 2011,
pp. 41–50.
[61] Y. Xu, W. Cui, and M. Peinado, “Controlled-channel attacks: Determin-
istic side channels for untrusted operating systems,” in Proceedings of
the 36th IEEE Symposium on Security and Privacy (Oakland), San Jose,
CA, May 2015.
[62] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy, S. Okasaka,
N. Narula, and N. Fullagar, “Native client: A sandbox for portable,
untrusted x86 native code,” in Proceedings of the 30th IEEE Symposium
on Security and Privacy (Oakland), Oakland, CA, May 2009.
[63] F. Zhang, J. Chen, H. Chen, and B. Zang, “Cloudvisor: retrofitting protec-
tion of virtual machines in multi-tenant cloud with nested virtualization,”
in Proceedings of the 23rd ACM Symposium on Operating Systems
Principles (SOSP), Cascais, Portugal, Oct. 2011.
15