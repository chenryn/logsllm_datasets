title:Modeling BBR's Interactions with Loss-Based Congestion Control
author:Ranysha Ware and
Matthew K. Mukerjee and
Srinivasan Seshan and
Justine Sherry
Modeling BBR’s Interactions with
Loss-Based Congestion Control
Ranysha Ware
PI:EMAIL
Matthew K. Mukerjee
PI:EMAIL
Srinivasan Seshan
PI:EMAIL
Justine Sherry
PI:EMAIL
Carnegie Mellon University
Nefeli Networks
Carnegie Mellon University
Carnegie Mellon University
ABSTRACT
BBR is a new congestion control algorithm (CCA) deployed for Chromium
QUIC and the Linux kernel. As the default CCA for YouTube (which
commands 11+% of Internet traffic), BBR has rapidly become a major
player in Internet congestion control. BBR’s fairness or friendliness to
other connections has recently come under scrutiny as measurements
from multiple research groups have shown undesirable outcomes when
BBR competes with traditional CCAs. One such outcome is a fixed,
40% proportion of link capacity consumed by a single BBR flow when
competing with as many as 16 loss-based algorithms like Cubic or
Reno. In this short paper, we provide the first model capturing BBR’s
behavior in competition with loss-based CCAs. Our model is coupled
with practical experiments to validate its implications. The key les-
son is this: under competition, BBR becomes window-limited by its
‘in-flight cap’ which then determines BBR’s bandwidth consumption.
By modeling the value of BBR’s in-flight cap under varying network
conditions, we can predict BBR’s throughput when competing against
Cubic flows with a median error of 5%, and against Reno with a
median of 8%.
1 INTRODUCTION
In 2016, Google published a new algorithm for congestion control
called BBR [4, 5]. Now deployed as the default congestion control
algorithm (CCA) for Google services including YouTube, which
commands 11% [13] of US Internet traffic, BBR consequently im-
pacts a large fraction of Internet connections today. In this short
paper, we focus on BBR’s behavior – ‘fairness’ or ‘friendliness’ –
when competing with legacy, loss-based CCAs such as Reno or
Cubic.
We are not the first to investigate BBR’s properties when com-
peting with traditional loss-based CCAs. Experimental studies have
noticed two key phenomena. First, in shallow-buffered networks,
BBR’s bandwidth probing phase causes buffer overflows and bursty
loss for competing flows; these bursts can lead to Cubic and Reno
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6948-0/19/10...$15.00
https://doi.org/TBA
nearly starving for bandwidth. This phenomena was first explored
in [11] and BBRv2 is expected to patch the problem [7].1
In residential capacity links (e.g. 10-100Mbps) with deep buffers,
studies [4, 9, 14, 16, 17] have generated conflicting reports on how
BBR shares bandwidth with competing Cubic and Reno flows.
We [17] and others [9, 14] observed a single BBR flow consum-
ing a fixed 35-40% of link capacity when competing with as many
as 16 Cubic flows. These findings contradict the implication of early
presentations on BBR [4] which illustrated scenarios where BBR
was generous to competing Cubic flows. In short, the state of af-
fairs is confusing, with no clear indication as to why any of the
empirically observed behaviors might emerge.
The contribution of this paper is to model BBR’s behavior when it
competes with traditional, loss-based congestion control algorithms
in residential, deep-buffered networks (studies [12] suggest that
residential routers typically have buffer depths 10-30× a bandwidth-
delay product for a 100ms RTT). The key insight behind our model
is that, while BBR is a rate-based algorithm when running alone,
BBR degrades to window-based transmission when it competes
with other flows. BBR’s window is set to a maximum ‘in-flight
cap’ which BBR computes as 2 × RTTest × Btlbwest , for RTTest
and Btlbwest , BBR’s estimates of the baseline RTT and its share of
bandwidth.
While the original BBR publication presented the in-flight cap
as merely a safety mechanism – included to allow BBR to handle
delayed ACKs [5] – this mechanism, unexpectedly, is the key factor
controlling BBR’s share of link capacity under competition. Our
model focuses on how BBR estimates its in-flight cap under different
network conditions; by computing what we expect BBR’s in-flight
cap to be, we can predict BBR’s share of link capacity for long-
lived flows. The size of the in-flight cap is influenced by several
parameters: the link capacity and latency, the size of the bottleneck
queue, and the number of concurrent BBR flows. But, notably absent,
the number of competing loss-based (Cubic or Reno) flows does not
play a factor in computing this in-flight cap. Hence, BBR’s sending
rate is not influenced by the number of competing traditional flows;
this is the reason behind reports that BBR is ‘unfair’ to Cubic and
Reno in multi-flow settings [9, 17].
In what follows, we discuss our testbed in §2 and early measure-
ments of BBR’s ‘fairness’ or ‘friendliness’ in §3. We then provide a
primer on the BBR algorithm in §4. We then develop our analysis
of BBR in §5 along with an explanation of BBR’s convergence to
40% of link capacity. We connect our results to related work in §6
and and conclude in §7.
1BBRv2 has very recently been released; in this paper we focus on BBRv1 which was
the only version available at the time of this study.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Ranysha Ware et al.
(a) Testbed for congestion experiments
which introduces queueing at a controlled
bottleneck.
(b) Average goodput for two competing
flows over 4 min in a 40ms×10Mbps net-
work with varying queue sizes.
(c) BBR’s goodput over time competing
with 16 Cubic flows in a 40ms×10Mbps net-
work with a 32 BDP queue.
Figure 1: Testbed and initial measurements of BBR’s empirical behaviors.
(a) Convergence time for 1 BBR
flow and 1 Cubic flow over vary-
ing queue sizes
(b) Goodput for 1 BBR flow and
1 Cubic flow over varying mea-
surement intervals.
Figure 3: BBR and Cubic or Reno’s queue when competing for 4 min-
utes over a network with a 64 BDP (1024 packet) queue.
.
Figure 2: BBR vs Cubic in a 40ms × 10Mbps network
2 TESTBED
Throughout this paper, we show experiments generated in the
testbed illustrated in Fig. 1a. Each experiment involves three servers:
a server/sender, a BESS [10] software switch, and a client/receiver.
All servers are running Linux 4.13 (using internal TCP pacing),
have Intel E5-2660V3 processors, and have dual-port Intel X520
10Gb NICs. Senders and receivers use iPerf 3 [1] to generate/receive
traffic. Within BESS, traffic is serviced at a configurable rate below
the link capacity to introduce queueing. The queue size is set to
ratios relative to BDP; since the BESS queue module only supports
powers-of-two sizes we rounded to the nearest power-of-two. To
configure delay, we hold all ACKs for a configurable amount of
time. Unless otherwise noted, we set bandwidth to 10 Mbps and
RTT to 40ms, following Google’s parameters in IETF presentations
[4, 6].
3 BBR IN COMPETITION
A natural concern when deploying a new CCA on the Internet is
how the new CCA will interact with other deployed algorithms.
Will the new CCA be ‘fair’ to existing CCAs, or starve them?
An early BBR presentation [4] provided a glimpse into these
questions. A graph in the presentation measures 1 BBR flow vs. 1
Cubic flow over 4 minutes, and illustrates a correlation between the
size of the bottleneck queue and BBR’s bandwidth consumption.
We set out to replicate Google’s experiments and easily did so –
shown in Fig. 1b – as did other studies [14]. The implication of
these graphs is that BBR is generous to existing CCAs in typical
buffer bloated networks, especially to Cubic.
Subsequent studies in our group and others questioned both
the results – what fraction of the link BBR consumed – as well as
the implication of generosity [9, 14, 17]. Some data [17] showed
that BBR converged to different rates – around 40% of the link
capacity for queue sizes up to 32×BDP, matching the Reno graph,
but not matching the Cubic graph. We show in Figs. 3 and 2 that this
incongruity is merely the result of differing experimental conditions
and the amount of time it takes for BBR to converge to its steady-
state share of link capacity. Where BBR quickly matches Reno’s
queue occupancy – and therefore consumption of the link capacity –
BBR takes longer to scale up when competing with Cubic (Fig. 3). As
a consequence, the ‘average goodput’ one computes is dependent
on how long one measures the competition between BBR and Cubic
(Fig. 2b). Furthermore, to reach convergence can take on the order
of minutes in very deep buffered networks (Fig. 2b).
Another set of experiments [9, 17] suggest that BBR may con-
sume far more than its ‘fair’ share of link capacity. Fig. 1c shows
goodput over time of BBR vs 16 Cubic flows in the same 40ms ×
10Mbps scenario. BBR consumes an outsized share of bandwidth,
leaving just over half to be shared by the sixteen other connections.
Unfortunately, relying only on these empirical studies leave us
like the blind men and the elephant, each relying on only pieces of
the overall picture to understand BBR’s characteristics. To get to the
bottom of why BBR behaves in the way it does, and to predict how
BBR might behave in unobserved scenarios, we turn to modeling
in the rest of this paper.
service at k Mbpsdelay by j millisecondsServersClientBESS NodeModeling BBR’s Interactions with
Loss-Based Congestion Control
Figure 4: BBR’s steady-state operation.
4 BBR PRIMER
BBR is designed to be a rate-based algorithm. BBR maintains two
key variables: Btlbwest BBR’s estimate of the available throughput
for it to transmit over the network, and RTTest BBR’s estimate
of the baseline round-trip time. BBR paces packets at Btlbwest
rate. Assuming that BBR is transmitting over a single link with no
queueing (and a sender which ACKs instantaneously), BBR should
expect to never have more than Btlbwest ×RTTest unacked packets
outstanding.
As a failsafe and to keep the pipe full in networks that delay or
aggregate ACKs, BBR implementations impose a ‘in-flight cap’ –
it will never allow itself to have more than 2 × Btlbwest × RTTest
unacknowledged packets outstanding [5, 6]. As we will show, this
cap turns out to be the central parameter controlling BBR’s link
utilization in competition with Cubic and Reno.
To estimate Btlbwest and RTTest , BBR cycles (post-startup)
through a simple state machine illustrated in Fig. 4.2
Estimating the rate. BBR sends at a fixed rate BWest . BBR sets
its initial rate using its own version of ‘slow start’; henceforth
BBR ‘probes for bandwidth’ (ProbeBW in Fig. 4) one out of every 8
RTTs. During this stage, BBR inflates the rate to 1.25∗Btlbwest and
observes the achieved throughput during that interval. BBR then