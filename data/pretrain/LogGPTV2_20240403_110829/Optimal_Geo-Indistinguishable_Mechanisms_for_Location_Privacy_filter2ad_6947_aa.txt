title:Optimal Geo-Indistinguishable Mechanisms for Location Privacy
author:Nicol&apos;as Emilio Bordenabe and
Konstantinos Chatzikokolakis and
Catuscia Palamidessi
Optimal Geo-Indistinguishable Mechanisms for
Location Privacy
Nicolás E. Bordenabe
INRIA and École Polytechnique
PI:EMAIL
Konstantinos Chatzikokolakis
CNRS and École Polytechnique
PI:EMAIL
Catuscia Palamidessi
INRIA and École Polytechnique
PI:EMAIL
ABSTRACT
We consider the geo-indistinguishability approach to loca-
tion privacy, and the trade-oﬀ with respect to utility. We
show that, given a desired degree of geo-indistinguishability,
it is possible to construct a mechanism that minimizes the
service quality loss, using linear programming techniques. In
addition we show that, under certain conditions, such mech-
anism also provides optimal privacy in the sense of Shokri
et al. Furthermore, we propose a method to reduce the
number of constraints of the linear program from cubic to
quadratic, maintaining the privacy guarantees and without
aﬀecting signiﬁcantly the utility of the generated mecha-
nism. This reduces considerably the time required to solve
the linear program, thus enlarging signiﬁcantly the location
sets for which the optimal mechanisms can be computed.
Categories and Subject Descriptors
C.2.0 [Computer–Communication Networks]: General—
Security and protection; K.4.1 [Computers and Society]:
Public Policy Issues—Privacy
Keywords
Location privacy; Location obfuscation; Geo-indistinguisha-
bility; Diﬀerential privacy; Linear optimization
1.
INTRODUCTION
While location-based systems (LBSs) have demonstrated
to provide enormous beneﬁts to individuals and society, these
beneﬁts come at the cost of users’ privacy: as discussed in
[1, 2, 3], location data can be easily linked to a variety of
other information about an individual, and expose sensitive
aspects of her private life such as her home address, her polit-
ical views, her religious practices, etc.. There is, therefore, a
growing interest in the development of location-privacy pro-
tection mechanisms (LPPMs), that allow to use LBSs while
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11˙..$15.00.
http://dx.doi.org/10.1145/2660267.2660345.
providing suﬃcient privacy guarantees for the user. Most of
the approaches in the literature are based on perturbing the
information reported to the LBS provider, so to prevent the
disclosure of the user’s location [4, 5, 6, 7, 8, 9].
Clearly, the perturbation of the information sent to the
LBS provider leads to a degradation of the quality of ser-
vice, and consequently there is a trade-oﬀ between the level
of privacy that the user wishes to guarantee and the service
quality loss (QL) that she will have to accept. The study
of this trade-oﬀ, and the design of mechanisms which opti-
mize it, is an important research direction started with the
seminal paper of Shroki et al. [10].
Obviously, any such study must be based on meaningful
notions of privacy and of quality loss. The authors of [10]
consider the privacy threats deriving from a Bayesian ad-
versary. More speciﬁcally, they assume that the adversary
knows the prior probability distribution on the user’s pos-
sible locations, and they quantify privacy as the expected
error, namely the expected distance between the true loca-
tion and the best guess of the adversary once she knows the
location reported to the LBS. We refer to this quantity as
AdvError. The adversary’s guess takes into account the
information already in her possession (the prior probabil-
ity), and it is by deﬁnition more accurate, in average, than
the reported location. We also say that the adversary may
remap the reported location.
The notion of quality loss adopted in [8] is also deﬁned in
terms of the expected distance between the real location and
the reported location, with the important diﬀerence that the
LBS is not assumed to know the user’s prior distribution (the
LBS is not tuned for any speciﬁc user), and consequently it
does not apply any remapping. Note that the notion of dis-
tance used for expressing QL does not need to be the same
as the one used to measure location privacy. When these two
notions coincide, then QL is always greater than or equal to
the location privacy, due to the fact that the adversary can
make use of the prior information to her advantage. The op-
timal mechanism of [8] is deﬁned as the one which maximizes
privacy for a given QL threshold, and since these measures
are linear functions of the noise (characterized by the con-
ditional probabilities of each reported location given a true
location), such mechanism can be computed by solving a
linear optimization problem.
In this paper, we consider the geo-indistinguishability fra-
mework of [9], a notion of location privacy based on dif-
ferential privacy [11], and more precisely, on its extension
to arbitrary metrics proposed in [12]. Intuitively, a mecha-
251nism provides geo-indistinguishability if two locations that
are geographically close have similar probabilities to gener-
ate a certain reported location. Equivalently, the reported
location will not increase by much the adversary’s chance to
distinguish the true location among the nearby ones. Note
that this notion protects the accuracy of the location: the
adversary is allowed to distinguish locations which are far
away.
It is important to note that the property of geo-
indistinguishability does not depend on the prior. This is a
feature inherited from diﬀerential privacy, which makes the
mechanism robust with respect to composition of attacks in
the same sense as diﬀerential privacy.
We study the problem of optimizing the trade-oﬀ between
geo-indistinguishability and quality of service. More pre-
cisely, given a certain threshold on the degree of geo-indistin-
guishability, and a prior, we aim at obtaining the mechanism
K which minimizes QL. Thanks to the fact that the prop-
erty of respecting the geo-indistinguishability threshold can
be expressed by linear constraints, we can reduce the prob-
lem of producing such a K to a linear optimization problem,
which can then be solved by using standard techniques of
linear programming.
It should be remarked that our approach is, in a sense,
dual wrt the one of [8]. The latter ﬁxes a bound on QL and
optimizes the location privacy. Here, on the contrary, we ﬁx
a bound on the location privacy and then optimize QL. An-
other important diﬀerence is that in [8] the privacy degree of
the optimal mechanism, measured by AdvError, is guar-
anteed for a speciﬁc prior only, while in our approach the
privacy guarantee of the optimal mechanism is in terms of
geo-indistinguihability, which does not depend on the prior.
In our opinion, this is an important feature of the present
approach, as it is diﬃcult to control the prior knowledge of
the adversary. Consider, for instance, a user for which the
optimal mechanism has been computed with respect to his
average day (and consequent prior π), and who has very dif-
ferent habits in the morning and in the afternoon. By simply
taking into account the time of the day, the adversary gains
some additional knowledge that determines a diﬀerent prior,
and the privacy guarantees of the optimal mechanism of [8]
can be severely violated when the adversary uses a prior
diﬀerent from π.
However, when the notion of distance used to measure
the QL coincides with that used for expressing the degree
of privacy according to AdvError, then, somewhat sur-
prisingly, our optimal mechanism K turns out to be also
optimal in terms of AdvError, in a sense getting the best
of both approaches. Intuitively, this is due to the fact that
the property of geo-indistinguishability is not aﬀected by
remapping. Hence, the expected error of the adversary must
coincide with QL, i.e., the adversary cannot gain anything
by any remapping H, or otherwise KH would be still geo-
indistinguishable and provide a better QL. Since privacy co-
incides with the QL, it must also be optimal. In conclusion,
we obtain a geo-indistinguishable K with minimum QL and
maximum degree of privacy (for that QL).
Note that the optimal mechanisms are not unique, and
ours does not usually coincide with the one produced by the
algorithm of [8]. In particular the one of [8] in general does
not provide geo-indistinguishability, while ours does, by de-
sign. The robustness of the geo-indistinguishability property
seems to aﬀect favorably also other notions of privacy: We
have evaluated the two mechanisms with the privacy deﬁni-
tion of [8] on two real datasets, and we have observed that,
while the mechanism of [8] by deﬁnition oﬀers the best pri-
vacy on the prior for which it is computed, ours can perform
signiﬁcantly better when we consider diﬀerent priors.
We now turn our attention to eﬃciency concerns. Since
the optimal mechanism is obtained by solving a linear op-
timization problem, the eﬃciency depends crucially on the
number of constraints used to express geo-indistinguishability.
We note that this number is, in general, cubic with respect
to the amount of locations considered. We show that we are
able to reduce this number from cubic to quadratic, using
an approximation technique based on constructing a suitable
spanning graph of the set of locations. The idea is that, in-
stead of considering the geo-indistinguishability constraints
for every pair of locations, we only consider those for every
edge in the spanning graph. We also show, based on exper-
imental results, that for a reasonably good approximation
our approach oﬀers an improvement in running time with
respect to method of Shokri et al. We must note however
that the mechanism obtained this way is no longer optimal
with respect to the original metric, but only with respect to
the metric induced by the graph, and therefore the QL of
the mechanism might be higher, although our experiments
also show that this increase is not signiﬁcant.
Note that in this paper we focus on the case of sporadic
location disclosure, that is, we assume that there is enough
time between consecutive locations reported by the user,
and therefore they can be considered independent. Geo-
indistinguishability can be applied also in case of correla-
tion between consecutive points, but additional care must
be taken to avoid the degradation of privacy, that could be
signiﬁcant when the number of consecutive locations is high.
The problem of correlation is orthogonal to to the goals of
this paper. We refer to [13] for a study of this problem.
Contribution.
The main contributions of this paper are the following:
• We present a method based on linear optimization
to generate a mechanism that is geo-indistinguishable
and achieves optimal utility. Furthermore when the
notions of distance used for QL coincide with that used
for geo-indistinguishability, then the mechanism is also
optimal with respect to the expected error of the ad-
versary.
• We evaluate our approach under diﬀerent priors (gen-
erated from real traces of two widely used datasets),
and show that it outperforms the other mechanisms
considered.
• We propose an approximation technique, based on span-
ning graphs, that can be used to reduce the number of
constraints of the optimization problem and still ob-
tain a geo-indistinguishable mechanism.
• We measure the impact of the approximation on the
utility and the number of constraints, and analyze the
running time of the whole method, obtaining favorable
results.
Plan of the paper.
The rest of the paper is organized as follows. Next section
recalls some preliminary notions. In Section 3 we illustrate
252our method to produce a geo-indistinguishable and optimal
mechanism as the solution of a linear optimization prob-
lem, and we propose a technique to reduce the number of
constraints used in the problem. In Section 4 we evaluate
our mechanism with respect to other ones in the literature.
Finally, in Section 5, we discuss related work and conclude.
The missing proofs can be found in the report version of
this paper [14].
2. PRELIMINARIES
2.1 Location obfuscation, quality loss and ad-
versary’s error
A common way of achieving location privacy is to apply a
location obfuscation mechanism, that is a probabilistic func-
tion K : X → P(X ) where X is the set of possible locations,
and P(X ) denotes the set of probability distributions over
X . K takes a location x as input, and produces a reported
location z which is communicated to the service provider.
In this paper we generally consider X to be ﬁnite, in which
case K can be represented by a stochastic matrix, where kxz
is the probability to report z from location x.
A prior distribution π ∈ P(X ) on the set of locations can
be viewed either as modelling the behaviour of the user (the
user proﬁle), or as capturing the adversary’s side informa-
tion about the user. Given a prior π and a metric d on
X , the expected distance between the real and the reported
location is:
ExpDist(K, π, d) =(cid:80)
x,z πxkxzd(x, z)
From the user’s point of view, we want to quantify the
service quality loss (QL) produced by the mechanism K.
Given a quality metric dQ on locations, such that dQ(x, z)
measures how much the quality decreases by reporting z
when the real location is x (the Euclidean metric d2 being
a typical choice), we can naturally deﬁne the quality loss
as the expected distance between the real and the reported
location, that is QL(K, π, dQ) = ExpDist(K, π, dQ). The
QL can also be viewed as the (inverse of the) utility of the
mechanism.
Similarly, we want to quantify the privacy provided by
K. A natural approach, introduced in [10] is to consider a
Bayesian adversary with some prior information π, trying to
remap z back to a guessed location ˆx. A remapping strategy
can be modelled by a stochastic matrix H, where hz ˆx is the
probability to map z to ˆx. Then the privacy of the mech-
anism can be deﬁned as the expected error of an adversary
under the best possible remapping:
AdvError(K, π, dA) = min
H
ExpDist(KH, π, dA)
Note that the composition KH of K and H is itself a mech-
anism. Similarly to dQ, the metric dA(x, ˆx) captures the
adversary’s loss when he guesses ˆx while the real location is
x. Note that dQ and dA can be diﬀerent, but the canonical