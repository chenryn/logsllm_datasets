# Quality Model and Bandwidth Savings

1. **Traditional JND-Related Factors:**
   The quality model, which includes only the traditional Just-Noticeable Difference (JND)-related factors [29, 30], already achieves a 17% reduction in bandwidth consumption.

2. **Benefits of 360JND over Classic JND:**
   By incorporating three new 360°-specific quality-determining factors into the PSPNR model (§4) and quality adaptation (§6), we can further reduce bandwidth consumption by an additional 11%.

3. **Variable-Size Tiling:**
   The PSPNR-aware variable-size tiling (§5) reduces bandwidth consumption by another 17% compared to grid tiling.

## Evaluation with Real Throughput Traces

Our evaluation using real throughput traces shows that Pano achieves the same PSPNR with 41-46% less bandwidth consumption than the viewport-driven baseline (Figure 18(b)).

## Limitations of the 360JND Model

### Survey Methodology
The 360JND model (§4) is based on a survey study where participants rated their experience for videos with varying viewpoint speeds, degrees of freedom (DoF) differences, and luminance changes. This approach is similar to those used in related work [29, 30]. However, we acknowledge two limitations:

1. **Variation in 360° Video-Specific Factors:**
   The values of 360° video-specific factors were varied in a specific manner (see Appendix for details), which may not accurately reflect how these factors vary and are perceived in real-world scenarios. For example, when emulating different viewpoint moving speeds, the viewpoint was always moved horizontally at a constant rate. In actual 360° video viewing, users may move the viewpoint in any direction and at varying speeds.

2. **Impact of Multiple Factors:**
   We have tested the impact of two factors at non-zero values (Figure 7) but have not tested the 360JND under all three factors simultaneously. Instead, we assume that their effects on JND are mutually independent and can be directly multiplied (Equation 1). While Figure 8 suggests a strong correlation between our 360JND calculation and user-perceived quality, Pano could benefit from a more comprehensive and fine-grained profiling of the relationship between 360JND and various factors.

## Related Work

### 360° Video Streaming
360° video streaming has gained significant attention in both industry [3, 7, 55] and academia [25, 32, 33, 35, 36, 41, 52, 59–62, 66]. Here, we review the most relevant work to Pano.

#### Viewport Tracking
Viewport-driven adaptation is a popular approach in 360° video streaming [32, 33, 35, 55, 62, 66]. The user's viewport is delivered in high quality, while other areas are encoded in low quality or not streamed. Some studies expand the recent viewport to a larger region to accommodate slight viewpoint movements [36, 62], but this may still miss the real-time viewport if it moves too much [53]. Various viewport-prediction schemes [48, 52, 60, 61] have been developed to extrapolate the user’s viewport from historical viewpoint movements [53], cross-user similarity [25], or deep content analysis [34]. Pano not only predicts the viewpoint location but also predicts the new quality-determining factors (viewpoint-moving speed, luminance, and DoF) using ideas from prior viewport-prediction algorithms.

#### 360° Video Tiling
Tile-based 360° video encoding is crucial for viewport-adaptive streaming [32, 35, 52, 61, 66]. The panoramic video is spatially split into tiles, each encoded at multiple bitrates, allowing only a small number of tiles to display the user’s dynamic viewport. This introduces additional encoding overhead as the number of tiles increases. Grid-like tiling is the most common scheme, but alternative schemes like ClusTile [68] cluster small tiles into one large tile to improve compression efficiency. Pano innovates by splitting the video into variable-size tiles that align well with the spatial distributions of the new quality-determining factors.

#### Bitrate Adaptation in 360° Videos
Both 360° and non-360° videos rely on bitrate-adaptation algorithms to handle bandwidth fluctuations. However, 360° videos need to spatially allocate bitrates among the tiles of a chunk, with tiles closer to the viewpoint receiving higher bitrates [52, 60]. Non-360° videos only change bitrates at the boundaries between consecutive chunks [43, 58, 64]. Pano follows the tile-based bitrate adaptation but differs in that the importance of each tile is dependent not only on its distance to the viewpoint but also on users’ sensitivities to its quality distortion.

#### Just-Noticeable Distortion and Perceived Quality
Psychological visual studies [29, 30, 67] have shown that the sensitivity of the Human Visual System (HVS) can be measured by Just-Noticeable Distortion (JND) [42]. JND has been used in other video quality metrics [30] to quantify subjective user-perceived quality, but most existing studies focus on video coding and non-360° videos. This work aims to leverage the impact of interactive user behaviors (such as viewpoint movements) on JND and how users perceive 360° video quality to achieve higher 360° video quality with less bandwidth consumption.

## Conclusion

High-quality 360° video streaming can be highly bandwidth-intensive. Prior solutions have largely assumed the same quality perception model as traditional non-360° videos, limiting the potential for improving 360° video quality within the same bandwidth constraints. In contrast, we show that users perceive 360° video quality differently from non-360° videos. This difference leads us to revisit key concepts in video streaming, including perceived quality metrics, video encoding schemes, and quality adaptation logic. We developed Pano, a design inspired by these insights. Our experiments demonstrate that Pano significantly improves the quality of 360° video streaming, achieving 25%-142% higher mean opinion scores with the same bandwidth consumption.

## Acknowledgment

We thank our shepherd Zafar Ayyub Qazi and SIGCOMM reviewers for their valuable feedback. Xinggong Zhang was supported in part by Project 2018YFB0803702, ALI AIR project XT622018001708, and iQIYI. Junchen Jiang was supported in part by a Google Faculty Research Award and CNS-1901466. Xinggong Zhang is the corresponding author.

## References

[References remain unchanged and are listed as provided.]

---

This version of the text is more structured, clear, and professional, making it easier to read and understand.