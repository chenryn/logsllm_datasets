19
20
21
22
23
24 end
end, states of faces are stored and maintained in each router, and
decisions to preserve privacy of access are made upon those states.
Unlike Algorithm 1, each router stores ̺ : F × N → IN T ,
where F is the set of faces. ̺(f, n) indicates the number of times
that content name n has been requested from face f .
3.3 Low Granularity Approach
The main limitation of the approach in §3.2 is that it does not
enable low granularity of the preserved privacy when both the ad-
versary and honest user are using the same AP, unlike the protocol
described in §3.1. To enable that, in the protocol in §3.1 we main-
tain several states in the router, which is a high overhead that can be
misused whereas the protocol in §3.2 reduces this overhead greatly.
The protocol in algorithm 3 aims to maintain the advantage of both
protocols by maintaining and distributing these states concerning
access pattern of individual users at the APs.
The main idea of the protocol is to distribute states of users send-
ing interests from within a certain domain on the APs associated
with these users, where decisions for access privacy are made at
the router with the help of the AP. The protocol assumes that faces’
states are maintained in the routers and the users states are in the
APs. We keep in mind that an AP is the closest connecting point of
the users to routers (e.g., between U1 and r3 in Figure 1).
4.
INITIAL RESULTS AND ANALYSIS
To understand the potential of the attack proposed in this work
in reality and how our designs impact the performance of ICN, we
instrument the CCNx simulator (https://www.ccnx.org/)
with real-world per-hop round trip delays when issuing interests
from within our campus in Santa Clara, CA, to each of the Alexa
top-100 sites. We use traceroute (http://www.traceroute.org/)
to obtain the hop count and per-hop RTT delay to each site (origin
10023
4
5
6
7
8
9
10 else
11
12
13
14
Algorithm 2: An efﬁcient approach.
Input: n - content name, f - face id, ̺ - access state,
Ints = (n, pmode, ts0)
Output: A data packet to f in a privacy preserving manner.
1 When R receives Ints from an access point AP through face f ,
it records ts1, the timestamp of interest arrival, and computes
td0 = ts1 − ts0 as a one-hop time delay.
2 if n is not in R’s cache then
R follows the ICN protocol to obtain data packet Data
from the origin server;
R records ts2 upon the arrival of Data, and computes:
tdx = ts2 − ts1; // RTT from R to origin server
h = tdx/(2td0) + 1; // expected # of hops
Generate td(n) according to Eq. 1;
̺(f, n) + +;
R returns Data to AP via f ;
if ̺(f, n) == 0 then
R generates td(n) as in Eq. 1;
R delays td(n).
R returns Data to the AP via f ;
end
15
16 end
server), and feed them to a dummy CCNx topology corresponding
to the toy example in Figure 1. To unify our analysis and discus-
sion, we limit our attention to 24 sites that have exactly 16 returned
valid hops in traceroute (15 hops outside of our campus). A box-
plot of the RTT up to each hop (1 to 15, until reaching the origin
server) as a ratio of the total RTT to the origin server is shown in
Figure 2 (more details on characteristics of this data are in [2]).
First, we examine whether an adversary co-located one-hop away
from a legitimate user will be able to exploit the timing attack ex-
plained earlier to infer whether some contents are being retrieved
by that user or not. We note that as per the ICN caching policy, con-
tents are replicated and cached at each hop, thus future requests are
fulﬁlled immediately from the closest router to the user. From Fig-
ure 2, we observe that an adversary who is co-located with the user
who requested these sites will beneﬁt from the caching, and would
ideally reduce the total RTT for fulﬁlling a request by a cache hit
at the ﬁrst hop by around 98% for the most conservative site (and
more than 99% for the average site). Even when a cache-miss hap-
pens, an RTT by a cache hit at the fourth hop away from the user,
for example, would be 40 times at average (and 25 times at worst)
less than the RTT when retrieving contents directly from the origin
server—although this scenario may not breach the privacy of users
access pattern since a 4-hop network has a large anonymity set. By
feeding the timing proﬁles of Figure 2 in CCNx we observe that the
T
T
R
l
t
a
o
t
e
h
t
f
o
n
o
i
t
c
a
r
F
T
T
R
0
1
.
8
.
0
6
.
0
.
4
0
2
0
.
0
.
0
V1
V3
V5
V7
V9
V11
V13
V15
Hop count
Figure 2: A boxplot of the RTT as a ratio of the total RTT for
24 sites in Alexa’s top 100, with 16 hops to each site.
Algorithm 3: Low granularity approach.
Input: n - content name, f - face id, u - user id, ̺ - access
state, Ints = (n, pmode, ts0, f lag = f alse)
Output: Returns data packet to u in a privacy preserving
manner.
1 u issues Ints with pmode enabled for n. u records ts0 of Ints
and sends them AP that connects u to the ICN.
2 When the AP receives Ints:
3 if ϕ(u, n) == 0 then
4
AP discards the pmode tag and ﬂags Ints with
f lag = true;
AP forwards Ints to router R;
AP forwards Ints to router R;
5
6 else
7
8 end
9 Upon receiving Ints from face f , the router R:
10 if n is not in R’s cache then
R follows the ICN protocol to retrieve the contents from
the origin server and serve them to u.
11
12 else
13
14
15
16
17
18
19
20
21
22
23
24
25
26 end
if ̺(f, n) == 0 then
R generates td(n) with Eq. 1;
else
if f lag == true then
R fulﬁlls the interest from cache
else
end
R generates delay td(n) as in Eq. 1;
R delays response by td(n);
R returns cached content n;
end
R delays td(n);
R returns Data to face f ;
network latency is the dominating part of the RTT in ICN, and other
ICN-related delay is negligible. We conclude that an adversary that
relies only on the timing information can easily and successfully
infer that the contents are being cached in a near-by router.
Second, we look at how our designs impact the performance of
ICN. One critical parameter for our designs is d, the number of hops
that an edge router estimates and generates to use as timing noise.
Even when the router has the capability to record a per-hop RTT
and add them as noise, the overhead as additional time delay added
to the RTT of fulﬁlling requests to users still maintains the beneﬁts
of ICN. For example, when td = 6 (which is one-third of the hop
count to the origin server thus providing reasonable anonymity set),
a request to an average site would be fulﬁlled about 40x faster than
retrieving contents from the origin server. Even for sites with the
longest RTT, that would be 25x faster than getting contents from the
origin server—25% and 75% RTT sites fulﬁll requests at about 33x
and 4x respectively for td = 7. As before, RTT is dominated by
network latencies, whereas CCNx delays are negligible, supporting
our claim that our designs maintain ICN’s beneﬁts.
5. REFERENCES
[1] V. Jacobson, D. K. Smetters, J. D. Thornton, M. F. Plass, N. H. Briggs, and
R. Braynard. Networking named content. In J. Liebeherr, G. Ventre, E. W.
Biersack, and S. Keshav, editors, CoNEXT, pages 1–12. ACM, 2009.
[2] A. Mohaisen, X. Zhang, M. Schuchard, H. Xie, and Y. Kim. Protecting access
privacy of cached contents in information centric networks. TR, UMN, 2012.
[3] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage. Hey, you, get off of my
cloud: exploring information leakage in third-party compute clouds. In ACM
Conference on Computer and Communications Security, pages 199–212, 2009.
[4] E. W. Felten and M. A. Schneider Timing Attacks on Web Privacy. In ACM
Conference on Computer and Communications Security. 2000.
1003