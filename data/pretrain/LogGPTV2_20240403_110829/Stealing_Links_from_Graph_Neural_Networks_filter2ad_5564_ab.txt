which contains its own nodes’ attributes and graph. The
adversary can use this to build a GNN model, referred
to as shadow target model (denoted by f (cid:48)) in order to
perform a transferring attack. It is worth noting that
the shadow dataset does not need to come from the
same domain of the target dataset. For instance, the
shadow dataset can be a chemical network, while the
target dataset can be a citation network. However, results
in Section 5 show that same-domain shadow dataset
indeed leads to better transferring attack performance.
We denote the adversary’s background knowledge as a triplet:
K = (F ,A∗,D(cid:48)).
Whether the adversary has each of the three items is a binary
choice, i.e., yes or no. Therefore, we have a comprehensive
taxonomy with 8 different types of background knowledge,
which leads to 8 different link stealing attacks. Table 2 sum-
marizes our attack taxonomy.
3.2 Link Stealing Attack
After describing our threat model, we can formally deﬁne our
link stealing attack as follows:
USENIX Association
30th USENIX Security Symposium    2671
Table 2: Attack taxonomy. (cid:88) (×) means the adversary has
(does not have) the knowledge.
Attack
F
Attack-0
×
Attack-1
×
Attack-2 (cid:88)
Attack-3
×
Attack
A∗ D(cid:48)
F
Attack-4
×
×
×
(cid:88) Attack-5 (cid:88)
×
Attack-6 (cid:88)
×
×
(cid:88)
Attack-7 (cid:88)
×
A∗ D(cid:48)
(cid:88)
(cid:88)
(cid:88)
×
(cid:88)
×
(cid:88)
(cid:88)
Deﬁnition 1 (Link Stealing Attack). Given a black-box ac-
cess to a GNN model that is trained on a target dataset, a
pair of nodes u and v in the target dataset, and an adversary’s
background knowledge K , link stealing attack aims to infer
whether there is a link between u and v in the target dataset.
4 Attack Taxonomy
In this section, we present the detailed constructions of all the
8 attacks in Table 2. Given different knowledge K , the ad-
versary can conduct their attacks in different ways. However,
there are two problems that exist across different attacks.
The ﬁrst problem is node pair order. As we consider undi-
rected graph, when the adversary wants to predict whether
there is a link between two given nodes u and v, the output
should be the same regardless of the input node pair order.
The second problem is dimension mismatch. The shadow
dataset and the target dataset normally have different dimen-
sions with respect to attributes and posteriors (as they are
collected for different classiﬁcation tasks). For transferring
attacks that require the adversary to transfer information from
the shadow dataset to the target dataset, it is crucial to keep
the attack model’s input features’ dimension consistent no
matter which shadow dataset she has.
We will discuss how to solve these two problems during
the description of different attacks. For presentation purposes,
features used in our supervised attacks and transferring attacks
are summarised in Table 3.
4.1 Attack Methodologies
Attack-0: K = (×,×,×). We start with the most difﬁcult
setting for the adversary, that is she has no knowledge of the
target dataset’s nodes’ attributes, partial graph, and a shadow
dataset. All she has is the posteriors of nodes obtained from
the target model f (see Section 2).
As introduced in Section 2, GNN essentially aggregates
information for each node from its neighbors. This means
if there is a link between two nodes, then their posteriors
obtained from the target model should be closer. Follow-
ing this intuition, we propose an unsupervised attack. More
speciﬁcally, to predict whether there is a link between u and
v , we calculate the distance between their posteriors, i.e.,
d( f (u), f (v)), as the predictor.
We have in total experimented with 8 common distance
metrics: Cosine distance, Euclidean distance, Correlation dis-
tance, Chebyshev distance, Braycurtis distance, Canberra dis-
tance, Manhattan distance, and Square-euclidean distance.
Their formal deﬁnitions are in Table 13 in Appendix. It is
worth noting that all distance metrics we adopt are symmetric,
i.e., d( f (u), f (v)) = d( f (v), f (u)), this naturally solves the
problem of node pair order.
Since the attack is unsupervised, to make a concrete pre-
diction, the adversary needs to manually select a threshold
depending on application scenarios. To evaluate our attack,
we mainly use AUC which considers a set of thresholds as
previous works [2, 21, 26, 32, 54, 70]. In addition, we pro-
pose a threshold estimation method based on clustering (see
Section 5 for more details).
Attack-1: K = (×,×,D(cid:48)). In this attack, we broaden the
adversary’s knowledge with a shadow dataset, i.e., D(cid:48). This
means the adversary can train a classiﬁer for a supervised
attack, more speciﬁcally, a transferring attack. She ﬁrst con-
structs a shadow target model f (cid:48) with D(cid:48). Then, she derives
the training data from f (cid:48) to train her attack model.
The adversary cannot directly use the posteriors obtained
from the shadow target model as features to train her attack
model, as the shadow dataset and the target dataset very likely
have different numbers of labels, i.e., the corresponding pos-
teriors are in different dimensions. This is the dimension
mismatch problem mentioned before. To tackle this, we need
to design features over posteriors.
As discussed in Attack-0, for any dataset, if two nodes are
linked, then their posteriors obtained from the target model
should be similar. This means if the attack model can capture
the similarity of two nodes’ posteriors from the shadow target
model, it can transfer the information to the target model.
We take two approaches together to design features. The
ﬁrst approach is measuring distances between two nodes’
posteriors. To this end, for each pair of nodes u(cid:48) and v(cid:48) from
the shadow dataset D(cid:48), we adopt the same set of 8 metrics
used in Attack-0 (formal deﬁnitions are listed in Table 13)
to measure their posteriors f (cid:48)(u(cid:48)) and f (cid:48)(v(cid:48))’s distances, and
concatenate these different distances together. This leads to
an 8-dimension vector.
The second approach is to use entropy to describe each
posterior inspired by previous works [32,42]. Formally, for the
posterior of node u(cid:48) obtained from the shadow target model
f (cid:48), its entropy is deﬁned as the following.
e( f (cid:48)(u(cid:48))) = −∑
i
f (cid:48)i (u(cid:48))log( f (cid:48)i (u(cid:48)))
(3)
where f (cid:48)i (u(cid:48)) denotes the i-th element of f (cid:48)(u(cid:48)). Then, for each
pair of nodes u(cid:48) and v(cid:48) from the shadow dataset, we obtain
two entropies e( f (cid:48)(u(cid:48))) and e( f (cid:48)(v(cid:48))). To eliminate the node
pair order problems for these entropies, we further take the
approach of Grover and Leskovec [25], by applying pairwise
vector operation, denoted by Ψ(·,·). In total, we have used
2672    30th USENIX Security Symposium
USENIX Association
Table 3: Features adopted by our supervised attacks (Attack-3 and Attack 6) and transferring attacks (Attack-1, Attack-4, Attack-5,
and Attack-7). Here, (∗) means the features are extracted from the shadow dataset in the training phase, and ((cid:63)) means the
features are extracted from both the shadow dataset and the target dataset (its partial graph) in the training phase. d(·,·) represents
distance metrics deﬁned in Table 13, Ψ(·,·) represents the pairwise vector operations deﬁned in Table 14. Note that the features
used in these attack models include all the distance metrics and pairwise vector operations.
Attack
Attack-1 ∗
Attack-3
Attack-4 (cid:63)
Attack-5 ∗
Attack-6
Attack-7 (cid:63)
d( f (u), f (v)) Ψ( f (u), f (v))) Ψ(e( f (u)),e( f (v)))
d(g(u),g(v)) Ψ(g(u),g(v)) Ψ(e(g(u)),e(g(v)))
d(Fu,Fv) Ψ(Fu,Fv)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
×
(cid:88)
×
×
(cid:88)
×
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
×
×
×
(cid:88)
(cid:88)
(cid:88)
×
×
×
×
(cid:88)
×
×
×
×
(cid:88)
(cid:88)
(cid:88)
×
×
×
(cid:88)
(cid:88)
(cid:88)
×
×
×
×
(cid:88)
×
all the 4 operations deﬁned in Table 14 (in Appendix) for our
attack. Note that these operations in Table 14 are applied on
two single numbers, i.e., scalars, in this attack. However, they
can also be applied to vectors and we will adopt them again
on posteriors and nodes’ attributes in other attacks.
In total, the features used for training the attack model
is assembled with 8 different distances between two nodes’
posteriors from the shadow target model and 4 features ob-
tained from pairwise vector operations between two nodes’
posteriors’ entropies. Regarding labels for the training set,
the adversary uses all the links in D(cid:48) and samples the same
number of node pairs that are not linked (see Section 5 for
more details). We adopt an MLP as our attack model.
Attack-2: K = (F ,×,×). In this attack, we assume that the
adversary has the knowledge of the target dataset’s nodes’
attributes F . Since the adversary has no knowledge of the
partial graph and a shadow dataset, her attack here is also
unsupervised (similar to Attack-0). We again rely on the dis-
tance metrics to perform our attack. For each pair of nodes
u and v from the target dataset, we consider four types of
information to measure distance with all the metrics listed
in Table 13. Similar to Attack-0, we experimentally decide
which is the most suitable distance metric for Attack-2.
• d( f (u), f (v)). The ﬁrst type is the same as the method
for Attack-0, i.e., distance between posteriors of u and v
from the target model f , i.e., f (u) and f (v).
• d(Fu,Fv). The second type is calculating the pairwise
distance over u and v’s attributes Fu and Fv.
• d( f (u), f (v))− d(g(u),g(v)). For the third type, since
we have the target model’s nodes’ attributes (as well
as a subset of their corresponding labels), we train a
separate MLP model, namely reference model (denoted
by g). Our intuition is that if two nodes are connected,
the distance between their posteriors from the target
model should be smaller than the corresponding dis-
tance from the reference model. Therefore, we calculate
d( f (u), f (v))− d(g(u),g(v)) to make prediction.
• d(g(u),g(v)). For the fourth type, we measure the dis-
tance over u and v’s posteriors from the reference model.
Attack-3: K = (×,A∗,×). In this scenario, the adversary
has access to the partial graph A∗ of the target dataset. For the
attack model, we rely on links from the known partial graph
as the ground truth label to train an attack model (we again
adopt an MLP). Features used for Attack-3 are summarized in
Table 3. For each pair of nodes u and v from the target dataset,
we calculate the same set of features proposed for Attack-1 on
their posteriors and posteriors’ entropies. Besides, since we
can directly train the attack model on the partial target graph
(i.e., we do not face the dimension mismatch problem), we
further deﬁne new features by adopting the pairwise vector
operations listed in Table 14 to f (u) and f (v).
Attack-4: K = (×,A∗,D(cid:48)). In this attack, the adversary has
the knowledge of the partial graph A∗ of the target dataset
and a shadow dataset D(cid:48). To take both knowledge into consid-
eration, for each pair of nodes either from the shadow dataset
or the partial graph of the target dataset, we calculate the same
set of features over posteriors as proposed in Attack-1. This
means the only difference between Attack-4 and Attack-1 is
that the training set for Attack-4 also includes information
from the target dataset’s partial graph (see Table 3).
Different from Attack-3, Attack-4 cannot perform the pair-
wise vector operations to f (u) and f (v). This is due to the
dimension mismatch problem as the adversary needs to take
both A∗ and D(cid:48) into account for her attack.
Attack-5: K = (F ,×,D(cid:48)). In this attack, the adversary has
the knowledge of the target model’s nodes’ attributes F and
a shadow dataset D(cid:48). As we do not have A∗ to train the attack
model, we need to rely on the graph of the shadow dataset.
To this end, we ﬁrst calculate the same set of features used
for Attack-1. Moreover, as we have the target dataset’s nodes’
attributes, we further build a reference model (as in Attack-
2), and also a shadow reference model in order to transfer
more knowledge from the shadow dataset for the attack. For
this, we build the same set of features as in Attack-1 over
the posteriors obtained from the shadow reference model,
i.e., the distance of posteriors (Table 13) and pairwise vector
USENIX Association
30th USENIX Security Symposium    2673
operations performed on posteriors’ entropies (Table 14). In