0
Bit error probability
Capacity
]
s
p
b
M
[
y
t
i
c
a
p
a
C
2
1
0
3
3.5
0.5
1
1.5
2.5
Raw bitrate [Mbps]
2
(a) Desktop setup (Haswell)
Bit error probability
Capacity
]
s
p
b
M
[
y
t
i
c
a
p
a
C
1.5
1
0.5
0
2.5
3
0.5
1.5
1
Raw bitrate [Mbps]
2
(b) Server setup, cross-CPU (Haswell-EP)
Figure 8: Performance of our covert channel implemen-
tation (native).
run natively. On our desktop setup (Figure 8a), the error
probability stays below 1% for bitrates of up to 2 Mbps.
The channel capacity reaches up to 2.1 Mbps (raw bitrate
of 2.4 Mbps, error probability of 1.8%). Beyond this
peak, the increasing error probability causes a decrease
in the effective capacity. On our server setup (Figure 8b)
the cross-CPU communication achieves 1.2 Mbps with a
1% error rate. The maximum capacity is 1.6 Mbps (raw
2.6 Mbps, 8.7% error probability).
For the cross-core cross-VM scenario, we deployed
two VMs which were configured to use 1 GB pages for
second-stage address translation. We reach a maximum
capacity of 309 kbps (raw 411 kbps, 4.1% error probabil-
ity) on our desktop system. The server setup (cross-CPU
cross-VM) performs much better, we achieved a bitrate
of 596 kbps with an error probability of just 0.4%.
5.3 Comparison with state of the art
We compare the bitrate of our DRAM covert chan-
nel with the normalized implementation of three cache
covert channels by Gruss et al. [5]. For an error rate that
is less than 1%, the covert channel using Prime+Probe
obtains 536 Kbps, the one using Flush+Reload 2.3 Mbps
and the one using Flush+Flush 3.8 Mbps. With a ca-
pacity of up to 2 Mbps, our covert channel is within the
same order of magnitude of current cache-based chan-
nels. However, unlike Flush+Reload and Flush+Flush, it
does not require shared memory. Moreover, in contrast
to our attack, these cache covert channels do not allow
cross-CPU communication.
The work of Irazoqui et al. [11] focuses on cross-CPU
cache-based side-channel attacks. They did not imple-
ment a covert channel, thus we cannot compare our per-
formance with their cache attack. However, their ap-
proach also requires shared memory and thus it would
not work in our attack setting.
The covert channel by Xiao et al. [26] using memory
deduplication achieves up to 90 bps. However, due to
security concerns, memory deduplication has been dis-
abled in many cloud environments. The covert channel
of Wu et al. [25] using the memory bus achieves 746 bps
with error correction. Our covert channel is therefore
three to four orders of magnitude faster than state-of-the-
art memory-based covert channels.
6 A low-noise cross-CPU side channel
In this section, we present a second DRAMA attack,
a highly accurate side-channel attack using DRAM ad-
dressing information. We again exploit the row buffer
and its behavior similar to a directly-mapped cache. In
this attack, the spy and the victim can run on sepa-
rate CPUs and do not share memory, i.e., no access
to shared libraries and no page deduplication between
VMs. We mainly consider a local attack scenario where
Flush+Reload cache attacks are not applicable due to
the lack of shared memory. However, our side-channel
attacks can also be applied in a cloud scenario where
multiple users on a server and one malicious user spies
on other users through this side channel. The side
channel achieves a timing accuracy that is compara-
ble to Flush+Reload and a higher spatial accuracy than
Prime+Probe. Thus, it can be used as a highly accurate
alternative to Prime+Probe cache attacks in cross-core
scenarios without shared memory.
6.1 Basic concept
In case of the covert channel, an active sender caused
row conflicts.
In the side-channel attack, we infer the
activity of a victim process by detecting row hits and row
conflicts following our definitions from Section 3. For
the attack to succeed, spy and victim need to have access
to the same row in a bank, as illustrated in Figure 9. This
is possible without shared memory due to the DRAM
addressing functions.
Depending on the addressing functions, a single 4 KB
page can map to multiple DRAM rows. As illustrated
in Figure 10, in our Haswell-EP system the contents
of a page are split over 8 DRAM rows (with the same
row index, but different bank address). Conversely, a
USENIX Association  
25th USENIX Security Symposium  575
11
Page A
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
6
4
·
6
4
b
y
t
e
s
(
4
K
B
p
a
g
e
)
128· 64 bytes (8 KB DRAM row)
AAAAAAAABBBBBBBBCCCCNNNNOOOOOOOOPPPPPPPP
Row in bank 0
AAAAAAAABBBBBBBBCCCCNNNNOOOOOOOOPPPPPPPP
Row in bank 1
AAAAAAAABBBBBBBBCCCCNNNNOOOOOOOOPPPPPPPP
Row in bank 2
AAAAAAAABBBBBBBBCCCCNNNNOOOOOOOOPPPPPPPP
Row in bank 3
AAAAAAAABBBBBBBBCCCCNNNNOOOOOOOOPPPPPPPP
Row in bank 4
Figure 10: Mapping between a 4 KB page and an 8 KB
DRAM row in the Haswell-EP setup. Banks are num-
bered 0 − 7, pages are numbered A − P. Every eighth
64-byte region of a 4 KB page maps to the same bank
in DRAM. In total 8 out of 64 regions (= 512B) map to
the same bank. Thus, the memory of each row is divided
among 16 different pages (A− P) that use memory from
the same row. Occupying one of the pages B− P is suffi-
cient to spy on the eight 64-byte regions of page A in the
same bank.
ing all but one of the pages that map to a row, the attacker
maximizes the spatial accuracy.
Based on this attack principle, we build a fully auto-
mated template attack [6] that triggers an event in the
victim process running on the other core or CPU (e.g.,
by sending requests to a web interface or triggering user-
interface events). For this attack we do not need to re-
construct the full addressing functions nor determine the
exact bank address. Instead, we exploit the timing dif-
ference between row hits and row conflicts as shown in
Figure 1.
To perform a DRAMA template attack, the attacker al-
locates a large fraction of memory, ideally in 4 KB pages.
This ensures that some of the allocated pages are placed
in a row together with pages used by the victim. The
attacker then profiles the entire allocated memory and
records the row-hit ratio for each address.
False positive detections are eliminated by running the
profiling phase with different events. If an address has a
high row-hit ratio for a single event, it can be used to
monitor that event in the exploitation phase. After such
an address has been found, all other remaining mem-
Figure 9: Victim and spy have memory allocated in the
same DRAM row. By accessing this memory, the spy
can determine whether the victim just accessed it.
DRAM row contains content of at least two 4 KB pages,
as the typical row size is 8 KB. More specifically, in our
Haswell-EP setup a single row stores content for 16 dif-
ferent 4 KB pages, as again shown in Figure 10. The
amount of memory mapping from one page to one spe-
cific row, e.g., 512 bytes in the previous case, is the
achievable spatial accuracy of our attack.
If none of
the DRAM addressing functions uses low address bits
(a0 − a11), the spatial accuracy is 4 KB, which is the
worst case. However, if DRAM addressing functions
(channel, BG0, CPU, etc.) use low address bits, a better
accuracy can be achieved, such as the 512 B for the server
setup. On systems where 6 or more low address bits are
used, the spatial accuracy of the attack is 64 B and thus
as accurate as a Flush+Reload cache side-channel attack.
Assuming that an attacker occupies at least one other
4 KB page that maps (in part) to the same bank and row,
the attacker has established a situation as illustrated in
Figure 9.
To run the side-channel attack on a private memory ad-
dress t in a victim process, the attacker allocates a mem-
ory address p that maps to the same bank and the same
row as the target address t. As shown in Figure 10, al-
though t and p map to the same DRAM row, they belong
to different 4 KB pages (i.e., no shared memory). The
attacker also allocates a row conflict address ¯p that maps
to the same bank but to a different row.
The side-channel attack then works in three steps:
1. Access the row conflict address ¯p
2. Wait for the victim to compute
3. Measure the access time on the targeted address p
If the measured timing is below a row-hit threshold (cf.
the highlighted “row hit” region in Figure 1), the victim
has just accessed t or another address in the target row.
Thus, we can accurately determine when a specific non-
shared memory location is accessed by a process running
on another core or CPU. As p and ¯p are on separate pri-
vate 4 KB pages, they will not be prefetched and we can
measure row hits without any false positives. By allocat-
576  25th USENIX Security Symposium 
USENIX Association
12
Row BuﬀerVictimVictimVictimVictimVictimSpySpySpyory pages will be released and the exploitation phase is
started.
6.2 Evaluation
We evaluated the performance of our side-channel attack
in several tests. These tests were performed on a dual-
core laptop with an Ivy Bridge Intel i5-3230M CPU with
2 Samsung DDR3-1600 dual-rank 4 GB DIMMs in dual-
channel configuration.
The first test was a DRAMA template attack. The at-
tack ran without any shared memory in an unprivileged
user program.
In this template attack we profiled ac-
cess times on a private memory buffer while triggering
keystrokes in the Firefox address bar. Figure 11 shows
the template attack profile with and without keystrokes
being triggered. While scanning a total of 7 GB of al-
located memory, we found 1195 addresses that showed
at least one row hit during the tests. 59 of these ad-
dresses had row hits independent of the event (false pos-
itives), i.e., these 59 addresses cannot be used to monitor
keystroke events. For the remaining 1136 addresses we
only had row hits after triggering a keystroke in the Fire-
fox address bar. Out of these addresses, 360 addresses
had more than 20 row hits. Any of these 360 addresses
can be used to monitor keystrokes reliably. The time to
find an exploitable address varies between a few seconds
and multiple minutes. Sometimes the profiling phase
does not find any exploitable address, for instance if there
is no memory in one row with victim memory. In this
case the attacker has to restart the profiling phase.
After automatically switching to the exploitation
phase we are able to monitor the exact timestamp of ev-
ery keystroke in the address bar. We verified empirically
that row hits can be measured on the found addresses
after keystrokes by triggering keystrokes by hand. Fig-
ure 12 shows an access time trace for an address found in
a DRAMA template attack, while typing in the Firefox
address bar. For every key the user presses, a low access
time is measured. We found this address after less than
2 seconds. Over 80 seconds we measured no false posi-
tive row hits and when pressing 40 keys we measured no
false negatives. During this test the system was entirely
idle apart from the attack and the user typing in Firefox.
In a real attack, noise would introduce false negatives.
Comparison with cache template attacks. To compare
DRAMA template attacks with cache template attacks,
we performed two attacks on gedit. The first uses the re-
sult from a cache template attack in a DRAMA exploita-
tion phase. The second is a modified cache template at-
tack that uses the DRAMA side channel. Both attacks
use shared memory to be able to compare them with
cache template attacks. However, the DRAMA side-
Keystroke False positive
s
e
s
a
c
f
o
r
e
b
m
u
N
300
200
100
0
0
200
600
400
800
Set (Bank,Row)
1,000 1,200
Figure 11: A DRAM template of the system memory
with and without triggering keystrokes in the Firefox ad-
dress bar. 1136 sets had row hits after a keystroke, 59 sets
had false positive row hits (row hits without a keystroke),
measured on our Ivy Bridge i5 test system.
300
250
200
e
m
i
t
s
s
e
c
c
A
w
w w.
f a
c e b o o k . co m
0
5
10
15
Time in seconds
Figure 12: Exploitation phase on non-shared memory
in a DRAMA template attack on our Ivy Bridge i5 test
system. A low access time is measured when the user
presses a key in the Firefox address bar. The typing gaps
illustrate the low noise level.
channel attack takes no advantage of shared memory in
any attack.
In the first attack on gedit, we target tab open and
tab close events. In an experiment over 120 seconds we
opened a new tab and closed the new tab, each 50 times.