title:AccEar: Accelerometer Acoustic Eavesdropping with Unconstrained Vocabulary
author:Pengfei Hu and
Hui Zhuang and
Panneer Selvam Santhalingam and
Riccardo Spolaor and
Parth H. Pathak and
Guoming Zhang and
Xiuzhen Cheng
6
1
7
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
AccEar: Accelerometer Acoustic Eavesdropping
with Unconstrained Vocabulary
Pengfei Hu∗, Hui Zhuang∗, Panneer Selvam Santhalingam†, Riccardo Spolaor∗, Parth Pathak†,
Guoming Zhang∗, Xiuzhen Cheng∗
∗ Shandong University, China
† George Mason University, USA
Email: {phu, rspolaor, guomingzhang, xzcheng}@sdu.edu.cn, {psanthal, phpathak}@gmu.edu, {zhuanghui303}@gmail.com
Abstract—With the increasing popularity of voice-based appli-
cations, acoustic eavesdropping has become a serious threat to
users’ privacy. While on smartphones the access to microphones
needs an explicit user permission, acoustic eavesdropping attacks
can rely on motion sensors (such as accelerometer and gyroscope),
which access is unrestricted. However, previous instances of such
attacks can only recognize a limited set of pre-trained words
or phrases. In this paper, we present AccEar, an accelerometer-
based acoustic eavesdropping attack that can reconstruct any au-
dio played on the smartphone’s loudspeaker with unconstrained
vocabulary. We show that an attacker can employ a conditional
Generative Adversarial Network (cGAN) to reconstruct high-
ﬁdelity audio from low-frequency accelerometer signals. The
presented cGAN model learns to recreate high-frequency compo-
nents of the user’s voice from low-frequency accelerometer signals
through spectrogram enhancement. We assess the feasibility and
effectiveness of AccEar attack in a thorough set of experiments
using audio from 16 public personalities. As shown by the results
in both objective and subjective evaluations, AccEar successfully
reconstructs user speeches from accelerometer signals in different
scenarios including varying sampling rate, audio volume, device
model, etc.
I. INTRODUCTION
Nowadays, voice-based applications (e.g., voice over IP,
video conferencing, voice assistants) on smartphones are part
of our daily lives. Since the audio from such applications can
reveal private information about the user, mobile operating
systems grant access to the microphone only with explicit
user permission. To bypass this restriction, security researchers
leverage the unrestricted motion sensors (e.g., accelerometer,
gyroscope) as a side-channel to carry out acoustic eavesdrop-
ping attacks [1]–[5]. These side-channel attacks are possible
since motion sensors are sensitive to the vibrations produced
by sound waves. From motion sensors data, these prior works
can recognize words/phrases that are either spoken by the user
or emitted from the smartphone’s speaker.
While effective, most of prior attacks of audio eavesdrop-
ping using motion sensors treat the audio extraction problem
as a classiﬁcation problem. Here, an attacker can create signa-
tures of motion sensor data for different words or phrases and
can recognize them using a machine learning model. However,
such an attack is primarily limited to the pre-trained set of
words and phrases and does not work well in reconstructing
any unknown audio signals. Ba et al. [4] propose a deep neural
network based approach for speech reconstruction, however
they can only recover the partial vowels in low frequency
region (below 1500Hz). The low sampling rate of motion
sensors imposes a limit, making the complete reconstruction
of audio an extremely challenging problem.
In this work, we present AccEar, a new type of
accelerometer-based eavesdropping attack that can reconstruct
any audio signal with unconstrained vocabulary. It uses the
accelerometer signals measured on a smartphone while the
audio is being played on the built-in smartphone speaker.
Given that the sampling rate of the accelerometer is limited
(maximum of 500Hz) by the mobile operating systems, the
low-frequency, low-resolution signal cannot be directly used
for audio reconstruction. We address this challenge by devel-
oping Conditional Generative Adversarial network (cGAN) [6]
based model that infers and recreates the high frequency com-
ponents based on the measured low-frequency accelerometer
signal. Through a limited amount of training set, our cGAN-
based model can learn the mapping between low-frequency
accelerometer data and the corresponding phonemes that they
represent, enabling us to reconstruct any audio signal (e.g.,
words, phrases, sentences, etc.) that is unknown to the model
(not used in training). For achieving this reconstruction, we
design our cGAN model to operate on spectrograms where it
learns to generate the complete audio spectrogram from the
given low-frequency accelerometer signal spectrogram. The
generated enhanced spectrograms are then used along with
the Grifﬁn-Lim algorithm [7] to reconstruct clear, human-
perceivable audio.
Since our presented attack is not limited to the speciﬁc pre-
trained set of words or phrases, it greatly increases the risk of
information leakage in a wide range of commonly occurring
scenarios. Some of the scenarios are listed below:
• When a remote contact talks, shares videos or sends
voice messages to a user via smartphone, an attacker
© 2022, Pengfei Hu. Under license to IEEE.
DOI 10.1109/SP46214.2022.00101
1757
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:50 UTC from IEEE Xplore.  Restrictions apply. 
can reconstruct the remote contact’s voice to steal private
information using AccEar.
• An attacker can listen to user’s voice memos or com-
mands that may contain conﬁdential information such
as passwords, schedules, phone numbers, social security
numbers, passcodes, etc.
• When the user uses voice navigation, the attacker can
use AccEar to infer user’s location and other preferences
such as the type of location user likes to visit, restaurants,
points-of-interest, etc.
• When the user’s smartphone plays an audio that may con-
tain a speciﬁc product name, the attacker can learn about
the user’s preferences of products, medical conditions,
etc.
• The attacker can intercept the (voice-based) veriﬁcation
codes commonly used in two-factor authentications to
obtain the access to user’s account.
Our contributions can be summarized as follows:
1) We propose AccEar, an acoustic eavesdropping system
that uses accelerometer data to accurately reconstruct
the user speech played by the smartphone speaker. To
the best of our knowledge, AccEar is the ﬁrst method
that actually recovers the speech content with an uncon-
strained vocabulary rather than recognizing individual
hot words/phrases.
2) Our proposed method converts
low-frequency ac-
celerometer data into a comprehensible audio signal.
To do so, we train cGAN models to learn the mapping
between accelerometer data and the correspondent audio
played by the smartphone speaker. The cGAN model can
enrich an accelerometer signal by adding its missing
high-frequency components and using the previously
learned mapping to produce an audio signal. Our method
demonstrates that cGAN can substantially enhance an
attacker’s capabilities even when the available data has
limited resolution due to hardware or software restric-
tions.
3) We carry out an extensive evaluation of AccEar attack
using an audio dataset from 16 public personalities
and several real-world scenarios. AccEar achieves an
average Mel-Cepstral Distortion (a lower value indicates
a better reconstruction performance) of 4.784, a Mean
Opinion Score (a higher value indicates a better recon-
struction performance) of 3.637, and an average Word
Error Rate (a lower value indicates a better reconstruc-
tion performance) of 13.434% for twenty volunteers.
Through cross-user training, we also demonstrate that
AccEar can effectively reconstruct audio even when no
audio samples of the victim are available for the training.
The remaining paper is organized as follows. Section II
discusses the related work. Section III discusses the prelimi-
naries of accelerometer, phoneme, and GAN. In Section IV,
we present our system and describe its components in detail.
Section V performs the evaluation on our system. In Sec-
tion VI, we discuss the obtained results, meaningful insights,
and limitations of our work. Section VII summaries our work.
II. RELATED WORK
In this section, we introduce the works related to speech
reconstruction via IMU (Inertial Measurement Unit) and other
acoustic eavesdropping methods.
A. Acoustic eavesdropping attacks via IMU
In recent years, some security researchers focus on eaves-
dropping via motion sensors in smartphones as the motion
sensors are sensitive and precise enough to capture the vibra-
tions emitted by the object.
Michalevsky et al. [1] show that the gyroscopes in smart-
phones are sufﬁciently sensitive to measure acoustic signals
in their vicinity. The authors place a smartphone and an
active loudspeaker (i.e., playing sound) on the same solid
surface. The sound emitted by the loudspeaker passes through
the solid surface, which vibrations inﬂuence the readings
of the smartphone’s built-in gyroscope. Through analyzing
the gyroscope measurements, they enable to recognize the
person’s identity and even retrieve some particular speech
information. However, IMU data can only preserve informa-
tion from frequencies below 200Hz, which results in a low
accuracy (77%) of digits recognition.
Zhang et al. [2] assess that accelerometers are also sensitive
to the human voice. The authors hold the smartphone in
their hands or place it on the desk and speak to the phone,
which will cause the vibration of the accelerometer. Through
observing the changes in the accelerometer data, they observe
the vibration has speciﬁc pattern related to human’s spoken
words, and it is possible to extract the unique signatures of
the hot words from the accelerometer data. Based on this
observation, they design AccelWord to recognize the hot words
such as “Okay Google” or “Hi Galaxy” from accelerometer
data. However, Anand et al. [3] argue that both human- and
machine-rendered speech is not powerful enough to affect
smartphone motion sensors through the air.
More recently, Ba et al. [4] propose a new side-channel
attack which eavesdrops on the speaker based on the ac-
celerometer on the same smartphone. The vibration produced
by the speaker can propagate through the motherboard and
induce strong response on the accelerometer [4], [8]. Hence
they can utilize the accelerometer measurements to recognize
the sensitive information speech emitted by the speaker. They
employ a deep neural network to further improve hot words
recognition, which could achieve an accuracy of 99% for digits
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:36:50 UTC from IEEE Xplore.  Restrictions apply. 
1758
(a) The accelerometer data spectro-
gram of vowels
(b) The spectrogram of vowels
(c) The accelerometer data spectro-
gram of consonants
(d) The spectrogram of consonants
Fig. 1: Spectrogram of phonemes
only and 87% for the combination of digits and letters. How-
ever, this deep neural network fails to reconstruct phonemes
in high frequency (above 1500Hz), which renders it incapable
to perform full speech reconstruction.
All aforementioned works share the same disadvantage that
they can only recognize or reconstruct hot words from the pre-
established vocabulary. Since audio emitted by the speaker in
a real-world scenario typically carries much more information
instead of hot words solely, such a limitation drastically
reduces the amount of speech privacy that can be inferred.
B. Other acoustic eavesdropping attacks
Nowadays, the works related to eavesdropping have been
extensively studied. Davis et al. [9] recover sounds from high-
speed footage of a variety of objects with different properties,
such as a glass of water or a bag of chips, by using the
principle that sound hitting an object causes the surface of the
object to vibrate sightly. Kwong et al. [10] demonstrate that the
mechanical components in magnetic hard disk drives are sensi-
tive enough to extract and parse human speech. Guri et al. [11]
introduce the malware “SPEAKE(a)R”, which enables to turn
the headphones, earphones, or earbuds connected to a personal
computer into microphones when the standard microphone is
not working or tapped. Roy et al. [12] demonstrate that the
vibration motor in mobile devices enables them to serve as a
microphone by processing their response to the air vibrations
from nearby sounds. Wang et al. [13] access the information
of human conversations by detecting and analyzing the ﬁne-
grained radio reﬂections from mouth movements. Wei et al.
[14] use the acoustic-radio transformation (ART) algorithm to
recover the sounds of the speaker device. Muscatell et al. [15]
use a laser transceiver to eavesdrop on the sound in the room.
In particular, the authors use a laser generator to shoot a laser
onto an object in the room and a laser receiver to receive the
reﬂected laser back. They can recover the sound by analyzing
the reﬂected laser. Nassi et al. [16] use the hanging bulb and
remote electro-optical sensor to eavesdrop sounds. The authors
show that the sound causes the air pressure on the surface
of the bulb to ﬂuctuate so that the lamp is slightly vibrated.
Then they use the electro-optical sensor to analyze the hanging
bulb’s frequency response to sound to recover the sound.
III. PRELIMINARIES
In this section, we brieﬂy introduce the principles of the
accelerometer, the characteristics of phonemes, and the idea
of generative adversarial networks. We also provide references
for an in-depth understanding of those topics.