6.1 Reconﬁgurable Hardware Security
The closest work to ours is the work of Huffmire et. al.
To provide memory protection on an FPGA, Huffmire et
al. propose the use of a reconﬁgurable reference monitor
that enforces the legal sharing of memory among cores [19].
A memory access policy is expressed in a specialized lan-
guage, and a compiler translates this policy directly to a cir-
cuit that enforces the policy. The circuit is then loaded onto
the FPGA along with the cores. While their work addresses
the speciﬁcs of how to construct a memory access moni-
tor efﬁciently in reconﬁgurable hardware, they do not ad-
dress the problem of how to protect that monitor from rout-
ing interference, nor do they describe how to enforce that
all memory accesses go through this monitor. This paper
directly supports their work by providing the fundamental
primitives that are needed to implement memory protection
on a reconﬁgurable device.
There appears to be little other work on the speciﬁcs
of managing FPGA resources in a secure manner. Chien
and Byun have perhaps the closest work, where they ad-
dressed the safety and protection concerns of enhancing
a CMOS processor with reconﬁgurable logic [8]. Their
design achieves process isolation by providing a reconﬁg-
urable virtual machine to each process, and their architec-
ture uses hardwired TLBs to check all memory accesses.
Our work could be used in conjunction with theirs, using
soft-processor cores on top of commercial off-the-shelf FP-
GAs rather than a custom silicon platform. In fact, we be-
lieve one of the strong points of our work is that it may
provide a viable implementation path to those that require a
custom secure architecture, for example execute-only mem-
ory [31] or virtual secure co-processing [29].
Gogniat et al. propose a method of embedded system
design that implements security primitives such as AES en-
cryption on an FPGA, which is one component of a secure
embedded system containing memory, I/O, CPU, and other
ASIC components [12]. Their Security Primitive Controller
(SPC), which is separate from the FPGA, can dynamically
modify these primitives at runtime in response to the de-
tection of abnormal activity (attacks). In this work, the re-
conﬁgurable nature of the FPGA is used to adapt a crypto
core to situational concerns, although the concentration is
on how to use an FPGA to help efﬁciently thwart system
level attacks rather than chip-level concerns. Indeed, FP-
GAs are a natural platform for performing many crypto-
graphic functions because of the large number of bit-level
operations that are required in modern block ciphers. How-
ever, while there is a great deal of work centered around
exploiting FPGAs to speed cryptographic or intrusion de-
tection primitives, systems researchers are just now start-
ing to realize the security ramiﬁcations of building systems
around hardware which is reconﬁgurable.
Most of the work relating to FPGA security has been tar-
geted at the problem of preventing the theft of intellectual
property and securely uploading bitstreams in the ﬁeld. Be-
cause such attacks directly impact their bottom line, indus-
try has already developed several techniques to combat the
theft of FPGA IP, such as encryption [6] [23] [24], ﬁnger-
printing [27], and watermarking [28]. However, establish-
ing a root of trust on a ﬁelded device is challenging because
it requires a decryption key to be incorporated into the ﬁn-
ished product. Some FPGAs can be remotely updated in
the ﬁeld, and industry has devised secure hardware update
channels that use authentication mechanisms to prevent a
subverted bitstream from being uploaded [16] [15]. These
techniques were developed to prevent an attacker from up-
loading a malicious design that causes unintended function-
ality. Even worse, the malicious design could physically
destroy the FPGA by causing the device to short-circuit
[14]. However, these authentication techniques merely en-
sure that a bitstream is authentic. An “authentic” bitstream
could contain a subverted core that was designed by a third
party.
6.2 Covert Channels, Direct Channels,
and Trap Doors
The work in Section 4.1 directly draws upon the ex-
isting work on covert channels. Exploitation of a covert
channel results in the unintended ﬂow of information be-
tween cores. Covert channels work via an internal shared
resource, such as power consumption, processor activity,
disk usage, or error conditions [47] [41]. Classical covert
channel analysis involves the articulation of all shared re-
sources on chip, identifying the share points, determining
if the shared resource is exploitable, determining the band-
width of the covert channel, and determining whether reme-
dial action can be taken [25]. Storage channels can be mit-
igated by partitioning the resources, while timing channels
can be mitigated with sequential access, a fact we exploit in
the construction of our bus architecture. Examples of reme-
dial action include decreasing the bandwidth (e.g., the intro-
duction of artiﬁcial spikes (noise) in resource usage [44]) or
closing the channel. Unfortunately, an adversary can extract
a signal from the noise, given sufﬁcient resources [37].
Of course our technique is primarily about restricting the
opportunity for direct channels and trap doors [49]. Our
memory protection scheme is an example of that. With-
out any memory protection, a core can leak secret data by
writing the data directly to memory. Another example of a
direct channel is a tap that connects two cores. An uninten-
tional tap is a direct channel that can be established through
luck. For example, the place-and-route tool’s optimization
strategy may interleave the wires of two cores.
7 Conclusion
The design of reconﬁgurable systems is a complex pro-
cess, with multiple software tool chains that may have dif-
ferent trust levels. Since it is not cost-effective to develop an
optimized tool chain from scratch to meet assurance needs,
only the most sensitive cores should be designed using a
trusted tool chain. To meet performance needs, most cores
could be designed with commodity tools that are highly op-
timized but untrusted, which results in multiple cores on a
chip with different trust levels. Our methodology will not
lead to those less trusted portions becoming more depend-
able or correct, but it will isolate trusted portions from the
effects of their subversion or failure. To address this situ-
ation, developers will need to build monitored or fail-safe
systems on top of FPGAs to prevent the theft of critical se-
crets.
We have presented two low-level protection mechanisms
to address these challenges, moats and drawbridges, and
we have analyzed the trade-offs of each. Although larger
moats consume more area than smaller moats, they have
better performance because longer segments can be used.
Our interconnect tracing primitive works together with our
moat primitive in a complementary way by allowing smaller
moats to be used without sacriﬁcing performance. We have
also described how these basic primitives are useful in the
implementation of a higher-level memory protection prim-
itive, which can prevent unintended sharing of information
in embedded systems.
Acknowledgments
The authors would like to thank Virgil Gligor for his in-
sightful comments on this paper. We also wish to thank the
anonymous reviewers for their helpful feedback. This re-
search was funded in part by National Science Foundation
Grant CNS-0524771, NSF Career Grant CCF-0448654, and
the SMART Defense Scholarship for Service.
References
[1] Z. Baker and V. Prasanna. Efﬁcient architectures for intrusion
detection.
In Twelfth Annual International Conference on Field-
Programmable Logic and its Applications (FPL ’04), August 2004.
[2] Z. Baker and V. Prasanna. Computationally-efﬁcient engine for ﬂex-
ible intrusion detection. October 2005.
[3] V. Betz, J. S. Rose, and A. Marqardt. Architecture and CAD for
deep-submicron FPGAs. Kluwer Academic, Boston, MA, 1999.
[4] K. Bondalapati and V. Prasanna. Reconﬁgurable computing systems.
In Proceedings of the IEEE, volume 90(7), pages 1201–17, 2002.
[5] U. Bondhugula, A. Devulapalli, J. Fernando, P. Wyckoff, and P. Sa-
dayappan. Parallel fpga-based all-pairs shortest-paths in a directed
graph. In Proceedings of the 20th IEEE International Parallel and
Distributed Processing Symposium (IPDPS’06), April 2006.
[6] L. Bossuet, G. Gogniat, and W. Burleson. Dynamically conﬁgurable
security for SRAM FPGA bitstreams. In Proceedings of the 18th In-
ternational Parallel and Distributed Processing Symposium (IPDPS
’04), Santa Fe, NM, April 2004.
[7] D. Buell and K. Pocek. Custom computing machines: an introduc-
In Journal of Supercomputing, volume 9(3), pages 219–29,
tion.
1995.
[8] A. Chien and J. Byun.
Safe and protected execution for the
morph/AMRM reconﬁgurable processor.
In Seventh Annual IEEE
Symposium on Field-Programmable Custom Computing Machines,
Napa, CA, April 1999.
[9] K. Compton and S. Hauck. Reconﬁgurable computing: a survey of
systems and software. In ACM Computing Surveys, volume 34(2),
pages 171–210, USA, 2002. ACM.
[10] A. DeHon. Comparing computing machines. In SPIE-Int. Soc. Opt.
Eng. Proceedings of SPIE - the International Society for Optical En-
gineering, volume 3526, pages 124–33, 1998.
[11] A. DeHon and J. Wawrzynek. Reconﬁgurable computing: what,
why, and implications for design automation.
In Proceedings of
the Design Automation Conference, pages 610–15, West Point, NY,
1999.
[12] G. Gogniat, T. Wolf, and W. Burleson. Reconﬁgurable security sup-
port for embedded systems. In Proceedings of the 39th Hawaii In-
ternational Conference on System Sciences, 2006.
[13] S. Guccione, D. Levi, and P. Sundararajan.
Jbits: Java-based in-
terface for reconﬁgurable computing. In Proceedings of the Second
Annual Conference on Military and Aerospace Applications of Pro-
grammable Logic Devices and Technologies (MAPLD), Laurel, MD,
USA, September 1999.
[14] I. Hadzic, S. Udani, and J. Smith. FPGA viruses. In Proceedings of
the Ninth International Workshop on Field-Programmable Logic and
Applications (FPL ’99), Glasgow, UK, August 1999.
[15] S. Harper and P. Athanas. A security policy based upon hardware
encryption. In Proceedings of the 37th Hawaii International Confer-
ence on System Sciences, 2004.
[16] S. Harper, R. Fong, and P. Athanas. A versatile framework for fpga
ﬁeld updates: An application of partial self-reconﬁguration. In Pro-
ceedings of the 14th IEEE International Workshop on Rapid System
Prototyping, June 2003.
[17] T. Hill. Acceldsp synthesis tool ﬂoating-point to ﬁxed-point conver-
sion of matlab algorithms targeting fpgas, April 2006.
[18] W.-M. Hu. Reducing timing channels with fuzzy time. In IEE Com-
puter Society Symposium on Research in Security and Privacy, Oak-
land, CA, May 1991.
[19] T. Huffmire, S. Prasad, T. Sherwood, and R. Kastner. Policy-driven
memory protection for reconﬁgurable systems.
In Proceedings of
the European Symposium on Research in Computer Security (ES-
ORICS), Hamburg, Germany, September 2006.
[20] B. Hutchings, R. Franklin, and D. Carver. Assisting network in-
trusion detection with reconﬁgurable hardware.
In Proceedings of
the 10th Annual IEEE Symposium on Field-Programmable Custom
Computing Machines (FCCM’02), 2002.
[21] A. Jain, D. Koppel, K. Kaligian, and Y.-F. Wang. Using stationary-
dynamic camera assemblies for wide-area video surveillance and se-
lective attention. In IEEE Conference on Computer Vision and Pat-
tern Recognition, 2006.
[22] R. Kastner, A. Kaplan, and M. Sarrafzadeh. Synthesis Techniques
and Optimizations for Reconﬁgurable Systems. Kluwer Academic,
Boston, MA, 2004.
[23] T. Kean. Secure conﬁguration of ﬁeld programmable gate arrays.
In Proceedings of the 11th International Conference on Field Pro-
grammable Logic and Applications (FPL ’01), Belfast, UK, August
2001.
[24] T. Kean. Cryptographic rights management of FPGA intellectual
In Tenth ACM International Symposium on Field-
property cores.
Programmable Gate Arrays (FPGA ’02), Monterey, CA, February
2002.
[25] R. Kemmerer. Shared resource matrix methodology: An approach
to identifying storage and timing channels. In ACM Transactions on
Computer Systems, 1983.
[26] P. Kocher, R. Lee, G. McGraw, A. Raghunathan, and S. Ravi. Secu-
rity as a new dimension in embedded system design. In Proceedings
of the 41st Design Automation Conference (DAC ’04), San Diego,
CA, June 2004.
[27] J. Lach, W. Mangione-Smith, and M. Potkonjak. FPGA ﬁngerprint-
ing techniques for protecting intellectual property. In Proceedings of
the 1999 IEEE Custom Integrated Circuits Conference, San Diego,
CA, May 1999.
[28] J. Lach, W. Mangione-Smith, and M. Potkonjak. Robust FPGA in-
tellectual property protection through multiple small watermarks. In
Proceedings of the 36th ACM/IEEE Conference on Design Automa-
tion (DAC ’99), New Orleans, LA, June 1999.
[29] R. Lee, P. Kwan, J. McGregor, J. Dwoskin, and Z. Wang. Architec-
ture for protecting critical secrets in microprocessors. In Proceed-
ings of the 32nd International Symposium on Computer Architecture
(ISCA), June 2005.
[30] J. Lewis and B. Martin. Cryptol: High assurance, retargetable crypto
In Military Communications Confer-
development and validation.
ence (MILCOM), October 2003.
[31] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell,
and M. Horowitz. Architectural support for copy and tamper resistant
software. In Proceedings of the Ninth International Conference on
Architectural Support for Programming Languages and Operating
Systems (ASPLOS-IX), Cambridge, MA, November 2000.
[32] B. Lisanke. Logic synthesis and optimization benchmarks. Technical
report, Microelectronics Center of North Carolina, Research Triangle
Park, NC, USA, January 1991.
[33] P. Lysaght and D. Levi. Of gates and wires. In Proceedings of the
18th International Parallel and Distributed Processing Symposium,
2004.
[34] P. Lysaght and J. Stockwood. A simulation tool for dynamically re-
conﬁgurable ﬁeld programmable gate arrays. IEEE Transactions on
Very Large Scale Integration (VLSI) Systems, 4(3), September 1996.
[35] W. Mangione-Smith, B. Hutchings, D. Andrews, A. DeHon, C. Ebel-
ing, R. Hartenstein, O. Mencer, J. Morris, K. Palem, V. Prasanna, and
H. Spaanenburg. Seeking solutions in conﬁgurable computing. In
Computer, volume 30(12), pages 38–43, 1997.
[36] D. McGrath. Gartner dataquest analyst gives asic, fpga markets clean
bill of health. EE Times, June 13 2005.
[37] J. Millen. Covert channel capacity. In Proceedings of the 1987 IEEE
Symposium on Security and Privacy, 1987.
[38] E. Nakashima. Used cellphones hold trove of secrets that can be hard
to erase. Washington Post, October 21 2006.
[39] H. Ngo, R. Gottumukkal, and V. Asari. A ﬂexible and efﬁcient hard-
ware architecture for real-time face recognition based on eigenface.
In Proceedings of the IEEE Computer Society Annual Symposium on
VLSI, 2005.
[40] W. Niu, J. Long, D. Han, and Y.-F. Wang. Human activity detection
and recognition for video surveillance. In Proceedings of the IEEE
Multimedia and Expo Conference, Taipei, Taiwan, 2004.
[41] C. Percival. Cache missing for fun and proﬁt.
In BSDCan 2005,
Ottowa, Ontario, Canada, 2005.
[42] B. Salefski and L. Caglar. Reconﬁgurable computing in wireless. In
Proceedings of the Design Automation Conference (DAC), 2001.
[43] J. Saltzer and M. Schroeder. The protection on information in com-
puter systems. Communications of the ACM, 17(7), July 1974.
[44] H. Saputra, N. Vijaykrishnan, M. Kandemir, M. Irwin, R. Brooks,
S. Kim, and W. Zhang. Masking the energy behavior of des encryp-
tion. In IEEE DEsign Automation and Test in Europe (DATE ’03),
2003.
[45] P. Schaumont, I. Verbauwhede, K. Keutzer, and M. Sarrafzadeh. A
In Proceedings of
quick safari through the reconﬁguration jungle.
the Design Automation Conference, pages 172–7, 2001.
[46] A. Senior, S. Pankanti, A. Hampapur, L. Brown, Y.-L. Tian, and
A. Ekin. Blinkering surveillance: Enabling video privacy through
computer vision. Technical Report RC22886, IBM, 2003.
[47] F. Standaert, L. Oldenzeel, D. Samyde, and J. Quisquater. Power
analysis of FPGAs: How practical
Field-
Programmable Logic and Applications, 2778(2003):701–711, Sept.
2003.
is the attack?
[48] The Math Works Inc. MATLAB User’s Guide, 2006.
[49] K. Thompson. Reﬂections on trusting trust. Communications of the
ACM, 27(8), 1984.
[50] J. Vuillemin, P. Bertin, D. Roncin, M. Shand, H. Touati, and P. Bou-
card. Programmable active memories: Reconﬁgurable systems come
of age. In IEEE Transactions on Very Large Scale Integration (VLSI)
Systems, volume 4(1), pages 56–69, 1996.
[51] S. Weingart and S. Smith. Building a high-performance, pro-
grammable secure coprocessor. Computer Networks (Special Issue
on Computer Network Security), 31:831–860, April 1999.
[52] S. Wilton. Architectures and Algorithms for Field-Programmable
Gate Arrays with Embedded Memory. PhD thesis, University of
Toronto, 1997.
[53] Xilinx Inc. Getting Started with the Embedded Development Kit
(EDK), 2006.