Structure-Behavior-Function (SBF) framework was proposed
by Goel et al. [52] to describe complex systems based on
three pillars: (1) structure (system components), (2) behavior
(change of the system over time), and (3) function (effect of
the system on the environment). It is often used by cognitive
psychologists to describe mental models and compare them
to actual system descriptions.
Hmelo-Silver et al. [53] applied the SBF framework in order
to model novices and experts’ understandings of complex
systems. They found that
the novices’ system perceptions
mostly focused on concrete aspects related to the structure of
the system, often simplifying causality and assuming central
control. In contrast, experts were more likely to discuss
behavioral aspects.
Applying this model to HTTPS, we model an end user’s
computer or a server hosting a web page as structural com-
Fig. 7. Attacker models in participant drawings. Each bar indicates how many
percent of all drawings feature a certain attacker type.
ponents. We model behavioral aspects as perceivable browser
indications, such as warning messages or security indicators.
Functional aspects comprise authentication of end users and
encryption of the communication path, resulting in a protection
against various attack vectors such as eavesdropping or trafﬁc
injection.
The results from our study suggest similar trends to those
presented by Hmelo-Silver et al. [53]. End users’ represen-
tations frequently include structural aspects and assume a
central entity pursuing encryption. Furthermore, the end users
from our study rarely included descriptions of behavioral or
functional aspects, showing neither that their perception of
security indicators is particularly strong nor that they are aware
of the actual purpose of HTTPS.
In contrast, the administrators largely focused on behavioral
aspects and delivered abstract representations of state transi-
tions (such as sequence diagrams of protocols). Nevertheless,
the administrators’ system descriptions are lacking functional
aspects. The administrators furthermore described the proto-
col behavior mainly decoupled from its actual purpose. An
interesting observation from our study is that none of our
expert participants clearly pointed out at which point of the
protocol execution the encryption starts. Hence, our results
show that neither end users nor administrators are able to link
the structural aspects of HTTPS and behavioral aspects to the
actual function that the protocol achieves.
C. Threat Models
After the participants ﬁnished all three drawing tasks, we
asked them a set of warm-up questions about attacker models
followed by another drawing task asking a participant to mark
where an attacker could eavesdrop. We coded these vulnerable
components and present the results in Figure 7.
The most mentioned component believed to be vulnerable
to attacks were the communication endpoints, which 26 of
54 end user drawings and 10 of 35 expert drawings featured.
Besides the endpoints, many end users stated that attackers
could eavesdrop everywhere within the communication pro-
(cid:19)(cid:22)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
cess, while expert users tended to differentiate more and name
concrete attackers or attack models.
Most participants visualized the attackers with arrows or
circles indicating the vulnerable components of their drawings.
However, some participants chose to insert attackers with a
drawn representation, e.g., a set of eyes (A08), exclamation
marks (A11), or stick ﬁgures as actual shoulder surfers (A10).
Especially regarding the endpoint attackers, not only were
malware or infected devices given as the enablers of eaves-
dropping, but also shoulder surﬁng (A10) and actual violence
against human users (A11).
V. DISCUSSION AND IMPLICATIONS
In this section, we discuss our ﬁndings and derive potential
implications on correct, incorrect, and sparse models (where
essential components are missing for cases which put users
directly at security or privacy risks).
Our analysis of mental models of HTTPS indicates dif-
ferences between the two groups of participants. While ad-
ministrator mental models were generally protocol-based and
correct even if sparse, the mental models of end users were
sometimes not only sparse but simply wrong or non-existent.
Indeed, our user study was an opportunity for some end
users to think about HTTPS and web encryption for the ﬁrst
time. However, we argue that ﬁne-grained and fully correct
mental models can and should not be expected from end users
and partly not even from knowledgeable administrators. Thus,
the following discussion places emphasis on misconceptions
which crucially interfere with a secure and privacy preserv-
ing usage or conﬁguration of HTTPS as well as actionable
conclusions to mitigate these risks.
We also observed interesting corner cases which should not
be ignored when discussing consolidated ﬁndings. Examples
of such corner cases include contradictions, the confusion
of authentication and encryption, or the assumption that
publicly-available comments (i.e., consumer ratings) are not
sent encrypted since this would prevent other consumers from
reading them in plaintext. In contrast to the lower bounds
of comprehension, we also found examples for the higher
levels, e.g., an administrator who had a deep understanding
of technical and operational details.
A. Implications from Correct Mental Models
The condensed representations of correct models show that
participants of both user groups have a basic understanding of
end-to-end encryption. In addition, the threat awareness was
better than we initially expected. Many end users were aware
that communication endpoints are often vulnerable (e.g. inse-
cure devices like smartphones). This is a realistic assessment,
since many smartphone vendors cease to ship security updates
for their devices long before they reach their end of life. In
contrast, administrators seem to focus on sophisticated but
rare attacks, such as “man-in-the-middle.” This may indicate
an inﬂuence of tech news outlets and scientiﬁc publications
which usually focus on more sophisticated attackers. Overall,
we regard this as a benevolent effect since administrators
should be aware of these attack types in order to deploy
adequate countermeasures, and end users are currently held
responsible for managing the security of their devices through,
for example, regular OS and app updates.
Our results also indicate that mental models of end users
may be inﬂuenced by media and marketing campaigns as
the comprehension of message encryption (task 1) was often
higher than the understanding of general HTTPS-encrypted
trafﬁc in web browsers. We hypothesize that one reason for
this difference may be higher media coverage of message
encryption in comparison to HTTPS. In addition, several app
manufactures (e.g., WhatsApp) speciﬁcally point out end-to-
end encryption when users start a new conversation.
Finally, the pictorial representations of mental models indi-
cate interesting differences between end users and administra-
tors: while end users’ correct models were rather conceptual,
administrators’ models were mostly protocol-related and often
illustrated operational details. The protocol-based representa-
tions reminded us of ﬂow charts common to academic lectures
and online tutorials, suggesting that many administrators tried
to recall previously-seen educational material.
However, there is still room for improvement, since even
correct representations were often sparse. For example, only
the best representations pointed out security indicators, and
important aspects like key exchange and certiﬁcation authori-
ties (CA) were hardly mentioned. Overall, the correct mental
models indicate that media coverage, marketing, and education
can help in forming folk models, even for complex processes
like HTTPS.
B. Implications from Incorrect Mental Models
While correct mental models emphasized the value of end-
to-end encryption, participants with incorrect mental models
tended to underestimate the security beneﬁts of HTTPS and
furthermore assume that omnipotent attackers can eavesdrop
at multiple stages of online communication. We hypothesize
that this might be the result of press attention on misuse of
SSL/TLS in mobile apps created by the work of Fahl et al.
[10] and Cothia et al, among others. [19]. Consequently, end
users are incapable of making informed security decisions as
they do not trust the protocol in even its best-case conﬁg-
uration. As a consequence, end users do not demand proper
conﬁgurations. Even though WhatsApp was already mentioned
as an example of an application which explicitly advertises
end-to-end encryption, some users might not even recognize
such notiﬁcations (or simply mistrust them) as WhatsApp was
constantly mentioned as an example for an app being not or
only partly encrypted. While this seems to not prevent users
from using WhatsApp, it shows that the security beneﬁts of
end-to-end encryption are often not perceived as such.
Even more worrisome, we identiﬁed corner cases of in-
correct mental models which may directly put users at risk.
For example, one end user thought that HTTPS can protect
against phishing web sites. Such assumptions may lead to an
unjustiﬁed sense of security whenever HTTPS connections are
indicated by the browser. We also found that end users were
(cid:19)(cid:22)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
often not aware of security indicators or they were perceived
as unimportant. Overall, the results show that the end users’
interest in these indicators is mitigated by general mistrust
in the protocol (i.e.,
the belief that cryptography/HTTPS
cannot prevent attacks and eavesdropping). Similarly, we
impressed by warnings of
found that many users are not
insecure connections, since they do not
the protocol
in the ﬁrst place. While administrators generally have more
correct mental models, their representations frequently lacked
important parts and meaningful interconnections. Also, the
administrators’ statements indicated a high level of mistrust.
As an example, one administrator (A06) claimed that “The
lock symbol does not mean anything, it is pure marketing”.
Additionally, administrators frequently expressed mistrust in
the PKI system. These two facts might explain a diminished
interest in conﬁguring certiﬁcates correctly.
trust
In summary, the incorrect mental models indicate that end
users do not trust the security that HTTPS can offer if deployed
in a best-case working scenario. We argue that recent news
reports about
intelligence activities inﬂuenced perceptions
about omnipotent attackers and that users need to build up
trust before concepts like security indicators and warnings
can be effective. The multi-step approach of our user study
indicates that education and brain teasers can be promising in
that they helped many users adjust their mental models even
if considering some aspects of HTTPS for the ﬁrst time. For
example, we observed that thinking about threat models caused
participants to review and reﬁne their mental model drawings
in some cases. End user participant U12 stated, “Now I see
that I didn’t think logically” before revising her drawing for
task 1. The same was true for administrators who became more
aware of metadata leakage after being asked about potential
attacks.
C. Implications from Missing and Sparse Mental Models
In addition to correct and incorrect mental models, interest-
ing implications can be derived from sparse models, as well.
We found that keys and certiﬁcates are not part of the correct
conceptional representations of most mental models, which
implies that users do not understand their purpose within
the concept. We argue that not being aware of their purpose
reduces the chance that users verify certiﬁcates manually. The
same is true for keys in other application scenarios: it is no
surprise that key veriﬁcation in mobile messaging apps is
rarely performed, as users are not aware of its necessity nor the
underlying threat model that this measure protects them from.
Helping users understand the functional perspective of keys
and certiﬁcates in HTTPS and encrypted messaging is thus
one of the main challenges for future research. While not all
conceptual parts need to be understood by users, it is essential
that users are motivated to engage measures demanded by the
security concept.
Even though some administrators mentioned keys and cer-
tiﬁcates with respect to HTTPS, they tended to use them
as buzzwords in their articulations and were often unable
to explain how these components contribute to a secure
conﬁguration. In addition, we found that most administrators
were not aware that server authentication is a prerequisite for
establishing a securely encrypted channel (which corresponds
to the results from Fahl et al. [10]).
D. Potential Countermeasures and Improvements
While our data does not provide direct evidence for
this, we hypothesize that education and online tutorials
contribute to these mental models. This corresponds to the
ﬁndings from Krombholz et al. [4], who showed that even
administrators who successfully conﬁgure HTTPS strongly
rely on online sources as they do not have a full understanding
of the underlying concepts. For end users, our results have
implications on security indicators, warnings and other UX
cues that are designed to assist users in making informed
security decisions.
that
1) Suggested Workﬂow Changes for Tools and APIs: We
found that administrators often do not understand the interplay
of functional protocol components (e.g. the CA, certiﬁcates
for E2E, keys). In particular, our results suggest
the
role of certiﬁcates and PKI as a whole for setting up an
encrypted channel are poorly understood by administrators
which indicates that administrators could beneﬁt from a de-
ployment process which more clearly illustrates the linkage
between these components, resp. hides this complexity from
them. Hence, as keys and certiﬁcates remain important func-
tional components even in more user-friendly deployment
concepts such as Let’s Encrypt2 and Certbot3, it is necessary
to provide tangible explanations to make their contribution
to a secure conﬁguration more intuitive. We acknowledge
that Let’s Encrypt and the ACME Protocol offer promising
usability enhancements from the administrators’ point of view,
since they enable automatic issuance of certiﬁcates. However,
these initiatives mainly simplify the process of obtaining a
certiﬁcate, but do not completely obviate the need for its
users to deal with certiﬁcates, keys and additional hardening
measures. As our results show that the biggest challenge for
administrators is to put these different components together in
order to deploy a secure authenticated-encryption mechanism,
we suggest that future protocol designs should aim at hiding
this additional complexity from users.
Although we expected that server authentication was part of
user mental models, our results suggest that this is rarely the
case. Hence, the concept of server authentication along with its
importance for communication security needs to be reﬂected
in the user interface in order to make server authentication
part of user mental models. Such UI components should also
motivate users to verify the server’s authenticity.
An example for a promising starting point in this regard is
the NaCl API presented by [54], which provides one simple
function referred to as crypto box that comprises several
functionality for authenticating and encrypting a message.
2https://letsencrypt.org – accessed: 05/08/2018.
3https://certbot.eff.org – accessed: 05/08/2018.
(cid:19)(cid:22)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
2) Trust Establishment: Our results suggest that especially
end users need UX cues that help to construct valid mental
models, as these are important to establish trust in the protocol
and its security properties. In order to deal with general mis-
trust towards HTTPS, we argue that the protocols in today’s
Internet ecosystem and the upcoming Internet of Things should
provide state of the art encryption by default and that insecure
protocols such as HTTP should be abandoned to establish a
more user-friendly distinction between best-case security and
vulnerable connections. Also, a security-by-default state would
obviate the need for users to regularly check HTTPS-speciﬁc
UI components. For end users, mistrust in the protocol and
misconceptions about the role of certiﬁcates can lead to wrong
decisions when warnings are displayed, putting users at danger
of privacy and security violation. This is in-line with latest
innovations enforced by Google4, who at the time of writing
began to roll out a new version of the web browser Chrome not
showing any security indicators for HTTPS secured websites
anymore. At the same time, websites still using HTTP are
marked as insecure by displaying a red insecurity indicator
in the address bar. Google argued that users should expect a
secure Internet by default, which is in-line with our ﬁndings.
Also, our results suggest that security indicators are often not
part of end user mental models, which is why we agree with
Google’s less ubiquitous yet more precise risk communication
with indicators.
VI. LIMITATIONS
While we refrained from recruiting computer science stu-
dents, our sampling method still has limitations. We aimed to
recruit a diverse sample of users, however our sample is still
skewed towards the more educated social class. Furthermore,
our end user sample skewed female, but we did not manage to
recruit a single non-male administrator. Sadly, female adminis-
trators are very rare in our region. Our sample was recruited in
Central Europe which is generally privacy-aware, and HTTPS
adoption rates are generally higher than e.g., in Japan [2]. Our
results are therefore impacted by cultural effects. As research
on perceptions of cryptographic tools and algorithms is still in
its early stages, we followed an inductive approach and opted
for a qualitative study to construct models and theory grounded
in the data. Naturally, our methodology also has its limitations.
The data is self-reported and qualitative in nature. While
our sample is still sufﬁciently large to perform basic statistic
tests, further investigations are necessary to determine large-
scale effects and hence obtain signiﬁcant results with larger
effect sizes. We refrained from asking closed-ended knowledge
questions. Also, the results from our pre-study showed that
participants like to litter buzzwords which is why we designed
our study to get a deeper context of their understanding. Our
goal was to allow our participants to openly articulate how they
think the protocol works. We decided to group our participants
based on their role of being an administrator instead of their
4https://blog.chromium.org/2018/05/evolving-chromes-security-indicators.
html
knowledge to avoid biasing effects by previously deﬁned
answer options.
VII. CONCLUSION AND FUTURE WORK
In this paper, we presented the ﬁrst qualitative study on user
mental models of HTTPS. In examining 18 end users and
12 administrators, our approach revealed four types of user
mental models of HTTPS and (abstract) message encryption.
We furthermore revealed misconceptions about threat models
and protocol components that lead to decisions that inﬂuence
the security of the systems and, as a result, directly put users
at risk.
Additionally, we shed light on differences between end
users’ and administrators’ perceptions; while end user mental
models were mostly conceptual, administrators’ mental models