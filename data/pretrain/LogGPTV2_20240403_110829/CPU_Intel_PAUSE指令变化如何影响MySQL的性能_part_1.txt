# Intel PAUSE指令变化如何影响MySQL的性能
## 导读
x86、arm指令都很多，无论是应用程序员还是数据库内核研发大多时候都不需要对这些指令深入理解，但是 Pause 指令和数据库操作太紧密了，本文通过一次非常有趣的性能优化来引入对 Pause 指令的理解，期望可以事半功倍地搞清楚 CPU指令集是如何影响你的程序的。
文章分成两大部分，第一部分是 MySQL 集群的一次全表扫描性能优化过程； 第二部分是问题解决后的原理分析以及Pause指令的来龙去脉和优缺点以及应用场景分析。
## 业务结构
为理解方便做了部分简化：
client -> Tomcat -> LVS -> MySQL（32 个 MySQLD实例集群，每个实例8Core）
## 场景描述
通过 client 压 Tomcat 和 MySQL 集群（对数据做分库分表），MySQL 集群是32个实例，每个业务 SQL 都需要经过 Tomcat 拆分成 256 个 SQL 发送给 32 个MySQL（每个MySQL上有8个分库），这 256 条下发给 MySQL 的 SQL 不是完全串行，但也不是完全并行，有一定的并行性。
业务 SQL 如下是一个简单的select sum求和，这个 SQL在每个MySQL上都很快（有索引）
```
SELECT SUM(emp_arr_amt) FROM table_c WHERE INSUTYPE='310' AND Revs_Flag='Z' AND accrym='201910' AND emp_no='1050457';
```
## 监控指标说明
-   后述或者截图中的逻辑RT/QPS是指 client 上看到的Tomcat的 RT 和 QPS；
-   RT ：response time 请求响应时间，判断性能瓶颈的唯一指标;
-   物理RT/QPS是指Tomcat看到的MySQL  RT 和QPS（这里的 RT 是指到达Tomcat节点网卡的 RT ，所以还包含了网络消耗）
## 问题描述：
通过client压一个Tomcat节点+32个MySQL，QPS大概是430，Tomcat节点CPU跑满，MySQL  RT 是0.5ms，增加一个Tomcat节点，QPS大概是700，Tomcat CPU接近跑满，MySQL  RT 是0.6ms，到这里性能基本随着扩容线性增加，是符合预期的。
继续增加Tomcat节点来横向扩容性能，通过client压三个Tomcat节点+32个MySQL，QPS还是700，Tomcat节点CPU跑不满，MySQL  RT 是0.8ms，这就严重不符合预期了。
性能压测原则：
> 加并发QPS不再上升说明到了某个瓶颈，哪个环节RT增加最多瓶颈就在哪里
![image-20221026145848312](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/411f164cdedbddcc-image-20221026145848312.png)
**到这里一切都还是符合我们的经验的，看起来就是 MySQL 有瓶颈（RT 增加明显）。**
## 排查 MySQL
现场DBA通过监控看到MySQL CPU不到20%，没有慢查询，并且尝试用client越过所有中间环节直接压其中一个MySQL，可以将 MySQL CPU 跑满，这时的QPS大概是38000（对应上面的场景client QPS为700的时候，单个MySQL上的QPS才跑到6000) 所以排除了MySQL的嫌疑(这个推理不够严谨为后面排查埋下了大坑)。
那么接下来的嫌疑在网络、LVS 等中间环节上。
## LVS和网络的嫌疑
首先通过大查询排除了带宽的问题，因为这里都是小包，pps到了72万，很自然想到了网关、LVS的限流之类的
pps监控，这台物理机有4个MySQL实例上，pps 9万左右，9*32/4=72万
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/b84245c17e213de5-b84245c17e213de528f2ad8090d504f6.png)
…………（省略巨长的分析、拉人、扯皮过程）
最终所有网络因素都被排除，核心证据是：做压测的时候反复从 Tomcat 上 ping 后面的MySQL，RT 跟没有压力的时候一样，也说明了网络没有问题(请思考这个 ping 的作用)。
## 问题的确认
尝试在Tomcat上打开日志，并将慢 SQL 阈值设置为100ms，这个时候确实能从日志中看到大量MySQL上的慢查询，因为这个SQL需要在Tomcat上做拆分成256个SQL，同时下发，一旦有一个SQL返回慢，整个请求就因为这个短板被拖累了。平均 RT  0.8ms，但是经常有超过100ms的话对整体影响还是很大的。
将Tomcat记录下来的慢查询（Tomcat增加了一个唯一id下发给MySQL）到MySQL日志中查找，果然发现MySQL上确实慢了，所以到这里基本确认是MySQL的问题，终于不用再纠结是否是网络问题了。
同时在Tomcat进行抓包，对网卡上的 RT 进行统计分析：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/ffd66d9a6098979b-ffd66d9a6098979b555dfb00d3494255.png)
上是Tomcat上抓到的每个sql的物理RT 平均值，上面是QPS 430的时候， RT  0.6ms，下面是3个server，QPS为700，但是 RT 上升到了0.9ms，基本跟Tomcat监控记录到的物理RT一致。如果MySQL上也有类似抓包计算 RT 时间的话可以快速排除网络问题。
网络抓包得到的 RT 数据更容易被所有人接受。尝试过在MySQL上抓包，但是因为LVS模块的原因，进出端口、ip都被修改过，所以没法分析一个流的响应时间。
## 重心再次转向MySQL
这个时候因为问题点基本确认，再去查看MySQL是否有问题的重心都不一样了，不再只是看看CPU和慢查询，这个问题明显更复杂一些。
> 教训：CPU只是影响性能的一个因素，RT 才是结果，要追着 RT 跑，而不是只看 CPU
通过监控发现MySQL CPU虽然一直不高，但是经常看到running thread飙到100多，很快又降下去了，看起来像是突发性的并发查询请求太多导致了排队等待，每个MySQL实例是8Core的CPU，尝试将MySQL实例扩容到16Core（只是为了验证这个问题），QPS确实可以上升到1000（没有到达理想的1400）。
这是Tomcat上监控到的MySQL状态：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/e73c1371a02106a5-e73c1371a02106a52f8a13f89a9dd9ad.png)
同时在MySQL机器上通过vmstat也可以看到这种飙升：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/4dbd9dff9deacec0-4dbd9dff9deacec0e9911e3a7d025578.png)
以上分析可以清晰看到虽然 MySQL 整体压力不大，但是似乎会偶尔来一波卡顿、running 任务飙升。
像这种短暂突发性的并发流量似乎监控都很难看到（基本都被平均掉了），只有一些实时性监控偶尔会采集到这种短暂突发性飙升，这也导致了一开始忽视了MySQL。
所以接下来的核心问题就是MySQL为什么会有这种飙升、这种飙升的影响到底是什么？
## perf top
直接用 perf 看下 MySQLD 进程，发现 ut_delay 高得不符合逻辑：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/cd145c494c074e01-cd145c494c074e01e9d2d1d5583a87a0.png)
展开看一下，基本是在优化器中做索引命中行数的选择：
跟直接在 MySQL 命令行中通过 show processlist看到的基本一致：
这是 MySQL 的优化器在对索引进行统计，统计的时候要加锁，thread running 抖动的时候通过 show processlist 看到很多 thread处于 statistics 状态。也就是高并发下加锁影响了 CPU 压不上去同时 RT 剧烈增加。
这里ut_delay 消耗了 28% 的 CPU 肯定太不正常了，于是将 innodb_spin_wait_delay 从 30 改成 6 后性能立即上去了，继续增加 Tomcat 节点，QPS也可以线性增加。
> 耗CPU最高的调用函数栈是…`mutex_spin_wait`->`ut_delay`，属于锁等待的逻辑。InnoDB在这里用的是自旋锁，锁等待是通过调用 ut_delay 让 CPU做空循环在等锁的时候不释放CPU从而避免上下文切换，会消耗比较高的CPU。
## 最终的性能
调整参数 innodb_spin_wait_delay=6 后在4个Tomcat节点下，并发40时，QPS跑到了1700，物理RT：0.7，逻辑RT：19.6，cpu：90%，这个时候只需要继续扩容 Tomcat 节点的数量就可以增加QPS
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/48c976f989747266-48c976f989747266f9892403794996c0.png)
再跟调整前比较一下，innodb_spin_wait_delay=30，并发40时，QPS 500+，物理RT：2.6ms 逻辑RT：72.1ms cpu：37%
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/fdb459972926cff3-fdb459972926cff371f5f5ab703790bb.png)
再看看调整前压测的时候的vmstat和tsar --cpu，可以看到process running抖动明显
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_CPU_3e1490cf/Intel_PAUSE指令变化如何影响MySQL的性能/4dbd9dff9deacec0-4dbd9dff9deacec0e9911e3a7d025578.png)
对比修改delay后的process running就很稳定了，即使QPS大了3倍