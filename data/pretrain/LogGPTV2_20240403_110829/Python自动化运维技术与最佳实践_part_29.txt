字节数：①访问来源；客户测览器信息（不具体拆分）。
接下来在5台Web服务器部署HDFS的客户端，以便定期上传Web日志到HDFS存储
平台，最终实现分布式计算。需要安装（JDK配置环境变量）、Hadoop（原版tar包解析即可），
详细见12.2相关内容。添加上传日志功能作业到crontab，内容如下：
[<Z ttnu/nap/ << Adndsgpu/doopeu/aee/euou/ uoq/d/uya/xsn/ +* < CZ SS
通过 subprocess.PopenO方法调用Hadoop HDFS 相关外部命令，实现创建HDFS目录及
客户端文件上传，详细代码如下：
[ /home/test/hadoop/hdfsput.py ]
Lmport subprocess
---
## Page 238
第12章Python大数据应用详解217
inport sys
Inport datetime
ebid=web1*#HDFS 存储日志标志，其他 Web服务器分别为 web2、web3、web4、web5
currdate=datet ime , datet ime.now () .strftime (*4Ytmd*)
1og8path=*/data/logs/*+currdate+*/access.1og”日本地展径
1ogname=*access.1og.*+vebidHDFS 存储日志名
1A11
subprocess.Popen([*/usr/local/hadoop-1.2.1/bin/hadoop*, *dfs*, *-mkdir*,
"hdfs://192.168 .1.20:9000/user/root/website.com/*+currdate]。 stdout=subprocess.PIPE)
创建HDFS目录，目录格式：website,com/20140205
except Exception,e:
putinfo=subproce８s.Popen([*/uｓt/1ocal/hａdoop-1.2.1/bin/hａdoop*,
pass
"dfs*, "-put*, logspath,
"hdfs://192.168.1,20:9000/user/root/vebsite
com/"+currdate+*/*+1ogname]， stdout=subprocess.PIPE)# 上传本述目志到 HDFS
for lise in putinfo,stdout:
print line
在crontab定时作业运行后，5台Web服务器的日志在HDFS上的信息如下：
+ /usr/1oca1/hadoop-1.2.1/bin/hadoop dfs -1s /user/root/vebsite,com/20140215
Found 5 itens
-----
3 root supergroup
com/20140215/access .1og.veb1
156541746 2014-02-15 23:55 /user/root/vebsite.
--2--1-R1
3root supergroup
251245315 2014-02-15 23:53 /user/root/vebsite,
com/20140215/access 1og.web2
-1----
3 root supergroup
134256412 2014-02-15 23:55 /usez/root/vebsite,
com/20140215/access .1og.veb3
com/20140215/acce88.1og.veb4
--r---.
3 root supergroup
192314554 2014-02-15 23:54 /u8er/root/vebsite.
-1---.
3 root supergroup  183267834 2014-02-15 23:55 /user/root/vebsite,
com/20140215/access.1og.veb5
截至目前，数据的分析源已经准备就绪，接下来的工作便是分析了。
12.4.2网站访问流量统计
网站访问流量作为衡量一个站点的价值、热度的重要标准，另外在CDN服务中流量会
涉及计费，如何快速准确分析当前站点的流量数据至关重要，当然，使用Mrjob可以很轻松
实现此类需求。下面实现精确到分钟统计网站访间流量，原理是在mapper操作时将Web日
志中小时的每分钟作为key，将对应的行发送字节数作为value，在reducer操作时对相同key
作累加（sum）统计，详细源码如下：
[ /home/test/hadoop/httpflow.py 1
---
## Page 239
218第二部分高级篇
from mrjob,job inport MRJob
lmport re
class HRCounter (MR.Tob) :
def sapper (eelf, key, line) :
1=0
for flow in 1ine.split()1
11==3：+获取时风字段，位于日志的第4列，内客如“[06/Aug/2010：03：19：44°
timerov= flow,split (":*)
hm=timerow[1] +*;*+t imerow[2]获取*小时 ：分钟*, 作为 key
if 1==9 and re,mat.ch (r"\d(1, 1 °,flov) :获取日本第 10 列 - 复选的字节数。
乍力 va1ue
YleLd hs,int (flo×)初始{ key:value
+=1
def reducer (self,  key, occurrences) 1
e：。x (soun）usxp
SE
_name_ -- '_nain_.':
MRCounter ,run ()
生成Hadoop任务，运行：
priority=vεRr_nicn =o hdfs1// /output/httpflov hdfs:///user/root/webs1te,
qo.aonpazdew guooqo(-- doopeu 1- Ad-xotgdaq/doopeq/4s9/esou/ uoutd 
com/20140215
分析结果见图12-14
2922136
图12-14任务分析结果（部分截图）
建议将分析结果数据定期入库MySQL，利用MySQL灵活、丰富的SQL支持，可以
很方便地对数据进行加工，轻松输出比较美观的数据报表。图12-15为网站一天的流量趋
势图。
---
## Page 240
第12章Python大数据应用详解219
900
800
*30
609
1/N
500
300
200
100
01234567891011121314151617181920212223
图12-15业务流量趋势图
12.4.3网站HTTP状态码统计
统计一个网站的HTTP状态码比例数据，可以帮助我们了解网站的可用度及健康状态，
比如我们关注的200、404、5xx状态等。在此示例中我们利用Mrjob的多步调用的形式来实
现，除了基本的mapper、reducer方法外，还可以添加自定义处理方法，在 steps 中添加调用
即可，详细源码如下：
[ /home/test/hadoop/httpstatus.py ]
from mrjob.job import MRJob
cla88 MRCounter (MRJob) :
inport re
def mapper (self, key, lioe) :
for httpcode in 1ine split ():
1 = 0
1.r==8 and re,match(r*\d(1, 3)*,httpcode) :# 获取目志中 HrTP 状态码役,作为 key
yield httpcode, 1 初始化 key:value,value 计数为 1,方便 reducer 累加
 +=1
def reducer(self, httpcode, occurrences) :
yield httpcode，sun(occurrences)对排序后的 key 对皮的 value作 sum 累加
return[self.mr(mapper-self,mapper)，在 steps 方法中添如调用民列
se1f .mr (reducer=self ,reducer) 1
Lf
1,ureu, "- oueu
MRCounter, run ()
---
## Page 241
220第二部分高级篇
生成hadoop任务，分析数据源保持不变，输出目录改成/output/httpstatus，执行：
priority=VERy_HIG8 -o hdfs:///output/httpstatus hdfs:///user/root/webs1te,
qo( aonpesdeu guooqo[-- doopeg a- Adsnesdsu/doopeu/qsa/asou/ uou.d 
com/20140215
分析结果见图12-16
Lroot
286
412334
420
127633
549
416
图12-16任务分析结果
我们可以根据结果数据输出比例饼图，如图12-17所示。
30
*301
*0
*405
*30I
 509
图12-17生成HTTP状态码饼图
12.4.4网站分钟级请求数统计
一个网站的请求量大小，直接关系到网站的访问质量，非常有必要对该数据进行分析且
关注。本示例以分钟为单位对网站的访间数进行统计，原理与12.4.2类似，区别是value初
始为1，以便作累加统计，详细源码如下：
[ /home/test/hadoop/http_minute_conn.py 1
from mrjob,job Import MRJob
ax120dut
---
## Page 242
第12章Python大数据应用详解221
class MRCounter (MBJob) :
def mapper (self, key, line) :
0=1
for dt in line.split()1
ifi=-3：获取时间字段，位于日志的第4列，内客如[06/Aug/2010:03：19:44”
(1μ)Tds*p =03ew1
x：[2]++[]x
yield hm,1和始化 key:value，value 计数为 1，方便 reducer f累加
1 +=1
def reducer (self, key, occurrences):
yield key, sum(occurrences)
1.f
_nane_ "= ._main_.':
MRCounter.run ()
生成Hadoop任务，输出目录/output/http_minute_conn，执行：
aonpezdeu-zuoogo(-- doopeq 1- 《d.uuososnutudau/doopeu/4eaa/awou/ uoqld 
/0ox/z///:sgpquuoonudu/ndo///sgpuo-Hxxoxqo
vebsite com/20140215
分析结果见图12-18。
41
图12-18任务分析结果（部分截图）
12.4.5网站访问来源IP统计
统计用户的访问来源IP可以更好地了解网站的用户分布，同时也可以帮助安全人员
捕捉攻击来源。实现原理是定义匹配IP正则字符串作为key，将value初始化为1，执行
reducer操作时作累加（sum）统计，详细源码如下：
---
## Page 243
222第二部分高级篇
[ /home/test/hadoop/ipstat.py 1
from mrjob.job import MRJob
import re
IF_RE = re ,compi1e (x\d(1, 3)\, \d(1, 3)\,\d(1, 3)\ \d(1, 3)*) 定义 IP 至则区配
c1a88 MRCountex (MRJob) :
def mapper (self, key, line) :
匹配 IP 正则后生成 key:value，其中 key 为 IP 地址，value 初始焦为 1
for ip in IP_RE.findal1 (1ine) :
yleld ip, 1
def redscer (self, ip, occurrences) :
yleld ip, sum(occurrences)
:,urew. -- eseu
MRCounter,run ()
生成Hadoop任务，输出目录/output/ipstat，执行：
qo[ oonpaadeu guooqo(-- doopeu a- Ad*esdt/doopeu/es/ewos/ uoqa(d 
priority=VERY_HIGH -o hdfs:///output/ipstat hdfs:///user/root/vebsite,
com/20140215
分析结果见图12-19。
图12-19任务分析结果（部分截图）
12.4.6网站文件访问统计
通过统计网站文件的访问次数可以帮助运维人员了解访问最集中的文件，以便进行有针
---
## Page 244
第12章Python大数据应用详解223
对性的优化，比如调整静态文件过期策略、优化动态cgi的执行速度、拆分业务逻辑等。实
现原理是将访问文件作为key，初始化value为1，执行reducer时作累加（sum）统计，详细
源码如下：
[ /home/test/hadoop/httpfile.py ]
from mrjob.job inport MRJob
class MRCounter (MRJob) :
Lmport re
def mapper (self, key, line) :
=0
for url in line.split ():
if ==6:
获取B志中URL文价资源字段。作为key
↓+=1
yield ur1, 1
def reducer (self, url, occurrences) :
yleld url, sun(occurrences)
if
:,ureu, -- oueu"
MRCounter.run ()
执行结果如图12-20所示。
"/laage/gin
图12-20任务分析结果（部分截图）
同理，我们可以使用以上方法对User-Agent域进行分析，包括测览器类型及版本、操作
系统及版本、浏览器内核等信息，为更好地提升用户体验提供数据支持。
?
12.2.1 小节原生 Python 编写mapreduce 示例参考 htp:/www.michael-noll.com/tutorials/
writing-an-hadoop-mapreduce-program-in-python/。
---
## Page 246
第三部分73
案例篇
■第13章从零开始打造B/S自动化运维平台
·第14章打造Linux系统安全审计功能
·第15章构建分布式质量监控平台
■第16章构建桌面版C/S自动化运维平台
---
## Page 247
Cly3第13章
从零开始打造B/S自动化运维平台
随着企业业务的不断发展，在运营方面，如何保障业务的高可用及服务质量，系统管理
员将面临越来越多的挑战。目前，很多企业还处在传统的“半自动化”状态，一旦出现运维
事故，技术部的每个人都会加人“教火”行列，最后弄得疲惫不堪。因此，构建高效的运营
模式已迫在眉睫，可以从以下儿个方面人手，包括定制符合企业特点的IT制度、流程规范、
质量与成本管理、运营效率建设等。本章将介绍如何使用Python从零开始打造一个易用、扩
展性强、安全、高效的自动化运维平台，从而提高运营人员的工作效率。（本章的源码也可从
https:/github.com/yorkoliu/pyauto 下载。)
13.1平台功能介绍
作为ITIL体系当中的一部分，本平台同样遵循ITIL标准设计规范。OMServer是本平台
的名称，后面的内容将使用它作为平台的称号。OMServer实现了一个集中式的Linux集群管
理基础平台，提供了模块扩展的支持，可以随意添加集群操作任务模块，服务器端模块支持
前端HTML表单参数动态定制，可灵活实现日常运维远程操作、文件分发等任务；在安全方
面，采用加密（RC4算法）指令传输、操作日志记录、分离WebServer与主控设备等：在效
率方面，管理员只需选择操作目标对象及操作模块即可完成一个现网变更任务。另外，在用
户体验方面，采用前端异步请求，模拟Linux终端效果接收返回串。任何人都可以根据自身
的业务特点对OMServer平台进行扩展，比如与现有资产平台进行对接，或整合到现有的运
营平台当中。平台首页如图13-1所示。
---
## Page 248
第13章从零开始打造B/S自动化运维平台227
oMServer
图13-1平台首页界面
13.2
系统构架设计
OMServer平台采用了三层设计模式，第一层为Web交互层，采用了Django+prototype
js+MySQL实现，服务器端采用了Nginx+uwsgi构建高效的Web服务；第二层为分布式计算
层，采用rpye分布式计算框架实现，作为第一层与第三层的数据交互及实现主控端物理分
离，提高整体安全性，同时具备第三层的多机服务的能力；第三层为集群主控端服务层，支
持Saltstack、Ansible、Func等平台。具体见如图13-2所示的系统架构图。
图13-2系统架构图
---
## Page 249