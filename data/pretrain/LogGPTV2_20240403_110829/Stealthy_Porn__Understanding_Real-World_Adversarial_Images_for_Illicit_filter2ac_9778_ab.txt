Google Cloud Vision API is capable of detecting faces,
objects and text content from an image. It uses the ma-
chine learning models that also power SafeSearch [8] to
capture Ô¨Åve categories of inappropriate content,
including
adult, spoof, medical, violence, and racy. For each cate-
gory, the API returns one of Ô¨Åve possible likelihood val-
ues: ‚ÄúVERY UNLIKELY‚Äù, ‚ÄúUNLIKELY‚Äù, ‚ÄúPOSSIBLE‚Äù,
‚ÄúLIKELY‚Äù, or ‚ÄúVERY LIKELY‚Äù.
Baidu AIP ImageCensor API provides a series of image
recognition interfaces such as pornography recognition, terror-
ism identiÔ¨Åcation, etc. Given an input image, the pornography
recognition API rates it with a porno level, which can be
‚ÄúNORMAL‚Äù, ‚ÄúSEXY‚Äù, or ‚ÄúPORN‚Äù, as well as a list of
probabilities indicating whether the image belongs to a certain
category of pornography.
In 2017 Yahoo open-sourced its deep learning model for
NSFW detection. The model rates an image using a score
between 0‚àí1: a score below 0.2 indicates that the image is
likely to be safe with high conÔ¨Ådence, while the images rated
above 0.8 are considered to be NSFW; those in-between could
be binned based upon their diÔ¨Äerent NSFW levels. Also a
similar NSFW API is provided by Clarifai [5].
C. Threat Model
In our research, we consider an adversary who tries to
use the adversarial promotional explicit
images to evade
inappropriate image detectors for promoting illicit products
(e.g., sexual products, gamble sites, illicit online pharmacies,
etc.).
the adversary can obfuscate the
image, using various distortion techniques (such as noise, blur
and occlusion). However, we assume that such adversarial
promotional explicit images, even evasive and distorted, should
still be correctly recognized by humans.
For this purpose,
III. Adversarial Explicit Image Identification
Here we elaborate the technique we used to identify ad-
versarial promotional porn images (APPI), starting with an
overview of the idea behind our detection tool, Mal`ena, which
is followed by the design details of each component.
(cid:26)(cid:22)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
A. Overview
To make their images less detectable and therefore less
likely to be removed from high-proÔ¨Åle forums, the adver-
sary increasingly introduces strong distortions to obfuscate
explicit image content. Finding such images in a large scale
is challenging due to the stealthy nature of APPIs, which
circumvent at least one existing detector, as observed in our
research (Section V-B). To detect such images, we leverage
two unique features of the APPIs. First, to promote illicit
products, these images must contain promotional content such
as text or QR codes. So we can use a scene text detection tool
to capture the images with such content. More importantly, to
preserve some level of sexual appeal, some explicit content
of an APPI needs to be less obfuscated, which makes it
easier to identify by ROI-based detection. More speciÔ¨Åcally,
our Malicious Explicit Content Analyzer (Mal`ena) runs an R-
CNN to locate all regions of interest from an image and then
checks the presence of explicit content within individual ROIs.
Once found, such an image is scanned by four mainstream
detectors (Google Cloud Vision API, Baidu AipImageCensor
API, Yahoo Open NSFW model, and Clarifai NSFW API).
Only those successfully evade at least one detectors but Ô¨Çagged
by Mal`ena are reported as APPIs.
Architecture. As illustrated in Figure 2, Mal`ena consists of
four components: preprocessor, promotional content identiÔ¨Åer,
regional explicit content detector and evasiveness checker. The
preprocessor identiÔ¨Åes the format of an input image and uniÔ¨Åes
its color space (Section III-B). Then, the promotional content
identiÔ¨Åer is run to seek scene text and QR codes from the
image, and drops it if neither can be found (Section III-C).
Otherwise,
the image is further analyzed by the regional
explicit content detector (Section III-D), which locates all
ROIs and inspects each region for explicit content. Once
discovered, the image is sent to the evasiveness checker to Ô¨Ånd
out whether it can be detected by any of the four mainstream
detectors (Section III-E) and Ô¨Çagged when it cannot.
B. Preprocessing
Online forums often receive images in various formats, such
as JPG, PNG, GIF etc. For simplicity, some forums change the
extensions of all such image Ô¨Åles to the same one (e.g., .JPG)
without actually altering their formats. For example, all images
scrapped from Baidu Tieba [1], the largest online forum in
China, have the ‚Äú.JPG‚Äù extension, though their true formats
can be not only JPG but also PNG and GIF, which can all be
displayed by the same interpretor.
Format recognition. To analyze these images for explicit
content, the preprocessor Ô¨Årst identiÔ¨Åes their real formats,
which is necessary for properly processing animated images
such as GIFs, and Ô¨Åltering out non-image Ô¨Åles with image
Ô¨Åle extensions. For this purpose, we utilize Libmagic [15],
a library for recognizing image formats from their magic
numbers.
Animation processing. Once the correct format is discovered,
the preprocessor throws away non-image Ô¨Åles, keeps static
images and breaks an animated image such as GIF into a
set of pictures using Python Imaging Library [23]. Note that
animated images are very common amongst APPIs since they
are not only eye-catching but also hard to detect. In our
research, we process such an image based upon the relations
among its consecutive frames: when each frame looks similar
to its subsequent one (e.g., video), our approach just picks out
the Ô¨Årst frame as the image‚Äôs representative for the follow-up
analysis; when every frame turns out to be quite diÔ¨Äerent from
the next one (e.g., slide show), we keep all frames for explicit
content detection.
SpeciÔ¨Åcally, our preprocessor runs a uniformity check on
all the frames of an animated image, based upon perceptual
hash (pHash) [12]. Perceptual hashing summarizes an image
into a short bit string, 128 bits used in our research. Two
similar images have a small Hamming distance between their
strings, while dissimilar ones are distance away. Our prepro-
cessor measures the similarity between two consecutive frames
according to the ratio of their Hamming distance (the distance
divided by the string length): the ratio is 0 if the two frames
are identical, 0.5 if totally diÔ¨Äerent, and 1 if one is the exact
inversion of the other. We consider that an animated image
is not ‚Äúuniform‚Äù if the average similarity score across all its
consecutive frame pairs is between 0.4 and 0.6. In this case, all
frames are kept for the follow-up content analysis. Otherwise,
the image is considered to be uniform and only the Ô¨Årst frame
is used for the analysis.
C. Promotional Content IdentiÔ¨Åcation
The next step is to identify promotional content in the
images. In our research, we manually collected 250 APPIs
from Baidu Tieba and found that all of them carry the contacts
for the products and services being promoted. So Mal`ena uses
the presence of such content as a necessary condition to Ô¨Ålter
out non-APPI images. More speciÔ¨Åcally, promotional content
is typically in the form of text (URL, QQ ID etc.) or QR
code, which is sought by the promotional content identiÔ¨Åer
in an image to determine whether it needs to go through the
follow-up content analysis. Here the text content is captured
using PixelLink [31], a state-of-the-art scene text detection
tool. Recognizing QR code, however, is more complicated, as
elaborated below.
Finding QR code. As a machine-readable matrix barcode, QR
code is supposed to be easily recognizable by bar code readers.
However, we found that some spammers (the adversary posting
APPIs) apparently do not want their code to be identiÔ¨Åed by
popular scanners (such as ZBar [13], ZXing [14], and BoofCV
[3]) and instead only accessible to some speciÔ¨Åc ones (e.g.,
the scanner used by WeChat, a popular Chinese social network
app). Examples of such QR code are shown in Figure 3. Unlike
standard QR codes, these codes have position patterns less
conspicuous and in a nonstandard shape (circle) and alignment
patterns even less identiÔ¨Åable. In our study, we found that
scanner software including ZBar, ZXing and BoofCV could
not detect them. However, WeChat can always pick them up.
(cid:26)(cid:22)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
"

"$ &
$"!+$
! &"!
#$"%%"$
&*& "!&!&
!&$

"&"$
 "
!&$
*#& "!&!&
$
"'
%"!
# 
!%"$

#!


$



$)$

$#$"%%"$

$" "&"! "!&!&
!&$

"! 	*#&
"!&!& &&"$

	(%(!%%
$
Fig. 2: System architecture.
All we want to do here is just to conÔ¨Årm the presence of
these codes. For this purpose, we come up with a simple al-
gorithm, which attempts to capture the three position patterns
(i.e., three big squares on the three corners) and the alignment
pattern (i.e.,
the other smaller one on the fourth corner).
SpeciÔ¨Åcally, QR code recognition is based upon separation of
the dark and the relatively bright components from the image
before the position and the alignment can be found. This can
be done using the threshold within OpenCV [22], which
coverts each pixel on a standard QR code image into one of the
two values: 0 if the pixel‚Äôs grayscale is above a given threshold
and 1 if not. For a standard QR code, such a threshold is
typically set to 127. For those obfuscated ones, however, we
can no longer rely on a single threshold 127, because of the
ability of spammers to manipulate the QR code, making (part
of) the dark components‚Äô grayscale larger than the threshold,
and causing false separation (as shown in the upper left Ô¨Ågure
in Figure 3). Nevertheless, the spammers have to a maintain
large enough contrast for the QR code to make feasible the
separation of the dark and bright components. Therefore, our
approach utilizes multiple thresholds (31, 63, 95, 127, 159,
191, and 223 for our implementation) and for each threshold
generates a binary image (with each pixel either 0 or 1).
The idea is to analyze all such images to determine whether
a QR code is indeed present. To this end, for each image,
our approach runs the OpenCV function findContours to
search for contours (i.e., the boundaries of continuous non-
zero pixels). After dropping the contours that are too small or
too large, if there is a QR code, we should be able to Ô¨Ånd
three contours under the following constraints: 1) they have
similar size and shape (approximately square or circle) and 2)
the centers of these contours form an isosceles right triangle.
Note that the shape of a contour can be determined by looking
at whether the square of the contour‚Äôs perimeter comes close
to 16 (if it is a square) or 4œÄ (if it is a circle) times its area.
Finally, we check whether there exists another square-or-circle
like contour near the fourth corner to conÔ¨Årm the presence of
the QR code.
We found that this algorithm is capable of identifying most
unconventional, oriented, and distorted QR codes like those in
Figure 3.
It was evaluated in our research using 50 images
with obfuscated QR codes and 50 images without the code,
Fig. 3: Examples of unconventional, oriented, and distorted
QR codes.
and found to achieve 100% accuracy.
D. Regional Explicit Content Detection
From the images carrying text or QR codes, Mal`ena further
detects whether they also contain explicit content. As men-
tioned earlier, even though an APPI attempts to hide such
content from detection, it is constrained by the need to preserve
the sexual appeal of the image. To exploit this observation, our
approach is designed to search for the explicit content from
some regions of the image, so as to avoid the interference
of the noise introduced to other regions that may cause the
whole image to be misclassiÔ¨Åed. SpeciÔ¨Åcally, Mal¬¥ena adopts
object recognition algorithms [34], [35], [39], [53], [57] to
Ô¨Årst Ô¨Ånd a few regions of interest where explicit adult content
possibly resides, and then runs R-CNN to extract features from
each ROI for further detection. Unlike typical region proposal
algorithms for object recognition [34], [35], [39], [53], [57],
our approach locates the image regions involving humans for
Ô¨Ånding adult content. Serving this purpose is Mask R-CNN
[39], an edge-cutting object recognition framework that applies
region proposal networks (RPN) [39], [53] to Ô¨Ånd ROIs (a
bounding box for the object classiÔ¨Åed as ‚Äúperson‚Äù) and further
(cid:26)(cid:22)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:56 UTC from IEEE Xplore.  Restrictions apply. 
More speciÔ¨Åcally, for Baidu Tieba, we gather images from
top 63 most active ‚Äúbars‚Äù (a forum on a certain topic).
Considering the relatively short lifespan of porn images, our
crawler is designed to iteratively visit the 150 latest posts
at each ‚Äúbar‚Äù without sleep. This strategy gives our crawler
a better chance to discover APPIs once they emerge before
they are reported and deleted. In this way, we totally obtain
3,813,888 unique images from 648,621 posts on Tieba from
03/15/2018 to 07/15/2018.
On Sina Weibo, microblog comments are the spammers‚Äô
favorite channel to distributing APPIs to the large number
of blog fans. Therefore, our crawler focuses on 76,763 mi-
croblogs with more than 10K fans. For each microblog, we
retrieve 100 latest posts, and crawl the images from their
comments. In total, we discover 228,810 images on Weibo
from 07/01/2018 to 08/25/2018.
‚Ä¢ Porn and non-porn picture sets. These datasets are used
for training the ResNet-50 model (see Section III-D). The
non-porn picture set serves as the negative samples, which
comes from three sources: (1) 50k images from Microsoft‚Äôs
Celeb-1M [16], (2) 17k images of females with casual wear