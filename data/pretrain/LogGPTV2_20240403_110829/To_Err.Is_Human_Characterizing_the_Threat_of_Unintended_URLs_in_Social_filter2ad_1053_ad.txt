the TLD is valid, registrations of domains ending in “.you”
are not yet available to the public. As such, even though
Twitter renders .you-ending domains as clickable links, none
of these domains actually serve any content. While this limits
the immediate exploitation of these unintended URLs, it also
means that, when registrations open to the public, all of these
domains will be exploitable, essentially overnight.
C. Impact of an Unintended URL
Intuitively, one would expect that not all unintended URLs
have the same impact on Twitter users. Instead, their ability
to reach users is inﬂuenced by how popular was the account
TABLE II: unintended URLs with highest original author follower
count.
Fig. 7: Average daily requests for all unintended domains registered.
that posted it as well as how many times the tweet was
shared (retweeted). In this section, we aim to investigate the
relationship between the popularity of a Twitter account and
the impact of the unintended URLs that they post.
In Table II we record the top 20 unintended URLs that
we recorded, ranked by account popularity in terms of their
number of followers. The follower count of these authors
ranges between 34M and 4.2M. For example, when Harry
Styles tweeted “SEE.YOU” from his Twitter account, there
are potentially 34M users who can view the tweet on their
timelines and click on the unintended URL. If an attacker
registered this domain name shortly after the tweet is posted,
up to 34M victims (ignoring re-tweets that could further
enlarge the users who are exposed to the tweet) could have
visited their website and be directed to a malicious page.
Therefore we say that the magnitude of the audience, in this
case, is at least 34M.
As described in Section III-C, part of our study involves
the registration of the domains corresponding to unintended
URLs so that we can more precisely quantify the number of
users that attackers could victimize.
9
020406080100Days Since Registration0100200300400500Number of OccurrencesMedianMinMaxFig. 8: Frequency unintended URLs are included in tweets throughout
our study.
Figure 7 shows the number of daily requests to the 45
unintended domains that we register during our data collection
period. Our data shows that requests for unintended URLs are
at their peak immediately after appearing in a tweet, followed
by a downward trend each day thereafter. The magnitude of the
spike in trafﬁc after a tweet’s publishing is dependent on the
following of the tweet’s author. Hence, we observe a number
of tweets from users with large followings directing hundreds
of visitors to our web server promptly after registration and
continually providing residual trafﬁc for the days following.
The decrease in trafﬁc over time to the domains we register
is indicative of the effect unintended URLs located in tweets
have on driving views to websites. Attackers who register
domains before (e.g., by predicting common unintended URLs)
or shortly after they appear in a tweet will receive signiﬁcantly
more requests compared to registering the same domains a few
days later.
We also discover isolated spikes in requests to unintended
domains in the days following registration. These spikes can be
attributed to the same unintended URLs appearing in additional
tweets. Figure 8 shows the number of times that unintended
URLs were included in tweets throughout our entire dataset.
We ﬁnd that 20% of these URLs are tweeted more than once,
hence driving new trafﬁc to the websites of potential attackers.
D. Unintended Domain Properties
As we discussed earlier, most unintended URLs (72%)
belong to non-existing (i.e., available for registration) domain
names. In this section, we focus on the minority of URLs
(28%) pointing to domains that were registered, in an effort to
understand what kind of content is hosted on the websites and
whether these domain registrations are coincidental as opposed
to motivated by tweets including unintended URLs. During
our period of experiments, our data collection infrastructure
visited and recorded information for 15,301 unintended URLs.
Analyzing the content and reputation of these webpages allows
us to uncover the dangers users face when visiting unintended
URLs.
a) Unintended URL Website Content: Figure 9 shows
the content of unintended-URL websites as determined through
10
Fig. 9: Content of unintended URL websites.
the perceptual hash clustering of screenshots and manual
labeling. We ﬁnd that 43.4% of websites hosted on unintended
URLs in our dataset belong to benign entities hosting original
content such as small business webpages. A large percentage
of these domains are registered under one of the country TLDs
including “.it,” “.so” and “.is.” Given that these are the
prominent TLDs of each respective country as well as com-
monly used words, we attribute this to the over-representation
of such content in our dataset.
An additional 39.5% of our dataset is made up of domain
parking webpages. Previous work has shown that domain
parking services commonly serve malicious content to visitors
including malware and technical support scams [50], [15].
Additionally, 171 webpages contain sensitive or malicious
content such as deceptive surveys and downloads. Thus, we
ﬁnd 42.3% of the webpages in our dataset could expose users
to potentially dangerous and unwanted content.
b) Unintended Domain Maliciousness:
In total, 118
target domains and an additional 40 landing domains appear on
at least one blacklist reported by VirusTotal [13]. Furthermore,
we discovered a large-scale malvertising campaign consisting
of 71 domains registered to the same IP address. When visiting
any one of these domains, the user is met with an attacker-
controlled Trafﬁc Distribution System [30] which, through a
series of redirections, lead users to one of many malicious
webpages. These webpages contain content including phishing,
deceptive surveys, and ﬁle downloads. An example of the
malicious content served by this campaign can be found in
Figure 10.
Our results show that users who follow URLs present in
tweets may be subjected to malicious content. The trust users
have in the authors of tweets increases the potential damage a
malicious webpage can cause, as more users will be conﬁdent
in the validity of the content.
c) Unintended Domain Registration Date: For the un-
intended URLs that correspond to registered domain names, a
critical question is the following: were these domains already
registered at the time of the tweet, or were they registered
some time after the URL-including tweet? In the former case,
one could straightforwardly argue that these domains are most
likely benign and their matching with tweets is coincidental.
In the latter case, however, a domain that was registered after
02468101214Number of Times Tweeted0.00.20.40.60.81.0Percentage of Typo URLs050010001500200025003000Number of WebsitesOriginal ContentParkedErrorEmptyConstructionGamblingAdultServer SetupRate LimitedFile DownloadCopyrightDeceptive SurveyScamTag2663242233431914510341393424421TotalTop 3 Country Code TLDsFig. 10: Deceptive survey from malicious campaign found among
unintended URLs.
Fig. 11: Days between the registration of domains and detection by
our infrastructure.
a tweet including a corresponding unintended URL is a clear
indication of malice.
Figure 11 shows the registration date of domains in our
dataset relative to detection by our infrastructure. We observe
a long tail distribution with the majority of registrations
occurring within ﬁve years of detection. We note a spike in
registrations occurring at around 6,000 days before detection.
These domains all belong to the .in TLD and were registered
after a relaxing of regulations for that TLD in 2005 [8]. As
shown in Figure 9, most of the domains in our dataset belong
to benign entities. These registrations are therefore most likely
independent of tweets recorded by our infrastructure. However,
we also observe a spike in domain registrations shortly before
detection. Given the detection lag of our infrastructure as
well as the fact that some unintended domains are tweeted
repeatedly by different users making the same mistake, the
spikes at the right-hand side of the graph can be attributed to
attackers who observe these tweets and attempt to beneﬁt from
the trafﬁc that they generate.
11
Fig. 12: Statistics on tweets from users observed publishing at least
one tweet containing an unintended URL. Data is grouped by the
number of tweets each user publishes weekly.
V. DEVELOPING A COUNTERMEASURE AGAINST
UNINTENDED URLS ON TWITTER
In Section III-A we showed that it is possible to train a
machine learning classiﬁer to be able to detect unintended
URLs on Twitter with high accuracy (94% on our ground truth
dataset). In the long run, we expect that Twitter as well as other
social media platforms will adopt a classiﬁer similar to the one
we proposed and alert users about unintended URLs before
posting them on their timelines. We argue that it is important
that users are involved in this process, being warned about
the potentially unintended URLs that they introduce and being
given a chance to correct their tweets. If Twitter (or another
social media platform) makes this decision automatically, users
whose ﬂagged tweets were false positives, may consider the
forced change as a form of censorship.
In the mean time, however, given the potential threat posed
by unintended URLs, we want to equip users with tools that
they can use to protect themselves and their audience. Since we
assume a non-cooperating social network, any solution must be
limited to the client side. Given Twitter’s software ecosystem,
a client-side solution can either be in the form of a special
Twitter client (that a user must install and adopt) or in the
form of a browser extension (for the users who operate Twitter
through its web interface). Due to the non-intrusive nature of
browser extensions, their cross-platform operation, and the fact
that they can be installed and uninstalled without requiring any
other changes to the user’s workﬂow, we opted to deploy our
countermeasure through a browser extension.
Speciﬁcally, we developed a Chrome browser extension
that parses the text of tweets as users type them and runs our
unintended URL classiﬁer on that text. In the case of a positive
label (i.e., a discovered unintended URL) the extension will
alert users so that they can correct their typos (or override our
warning) before posting their tweets. In this section, we ﬁrst
describe the functionality of our browser extension and then
analyze its performance impact on a user’s browser.
80006000400020000Days Relative to Detection01020304050Number of Unintended Domains[0,50](50,100](100,inf]User Tweets per Week110100Number of TweetsTotal TweetsTweets w/ URLsTweets FlaggedA. Browser Extension
Our Chrome browser extension analyzes the text of new
tweets as the user is typing them,
identifying unintended
URLs. When enabled, our extension registers event handles
on the “Post Tweet” button in the Twitter Web interface. After
the user types the tweet text and clicks the post button, the
extension analyzes the tweet text and applies the preﬁltering
step described in Section III-A. Tweets containing URLs that
pass the preﬁltering steps are then evaluated using a pre-
trained machine learning model that uses most of the features
of our aforementioned classiﬁer. Speciﬁcally, for our proof-
of-concept extension, we excluded the Sentence Segmentation
feature that our regular classiﬁer uses. Our analysis of features
indicated that this feature had a low importance in our model,
in a way that did not justify the time investment that was
necessary to port it to the JavaScript language (a step that is
necessary for the extension to be self contained).
If the model reports that the tweet contains one or more
unintended URLs, the browser extension shows a warning
dialog containing all the unintended URLs (positive predic-
tions). This dialog enables the users to review the posted URLs
and optionally edit their text before posting. Alternatively,
in the case of a negative prediction, the tweet is posted as
usual. A video demonstrating our extension along with the
source code of our extension can be found in our public
GitHub repository: https://github.com/belizkaleli/TypoNoMo.
Note that our browser extension only operates locally, and no
data about the Twitter user or the text they typed is sent to a
third party. As such, our extension is not privacy invasive.
B. Performance Impact
A browser extension should not disrupt the overall user
experience if it is to be adopted by users. To understand
the number of alerts that Twitter users would experience, we
measure the frequency in which the average user (of those who
are prone to unintended URLs) would see an alert from our
browser extension. We accomplish this by analyzing tweets
from each user we observed publishing a tweet containing an
unintended URL in SectionIV-C. For each user, we download
all authored tweets using the Twitter API (maximum of 200
per user) and record the following: the total number of tweets
published, the number of tweets containing at least one URL,
and the number of tweets ﬂagged as containing an unintended
URL by our extension. We divide our dataset into three groups,
based on the number of tweets users in each group publish
each week. Figure 12 demonstrates our ﬁndings. Overall, out of
93,187 total tweets in our dataset, only 51 would be ﬂagged by
our browser extension, with users on average seeing no more
than one alert each week. Moreover, we ﬁnd that medium and
high-activity users post a similar number of tweets containing
URLs, demonstrating an upper-bound on tweets which could
potentially trigger an alert from our extension.
Additionally, we measure the time overhead induced by
our extension in the following tweet-posting scenarios:
•
•
The posted tweet does not contain any links.
The posted tweet contains only one link which does
not get ﬁltered in the Preﬁltering step (tested for both
positive predictions and negative predictions).
Fig. 13: Chrome extension response time for different test cases.
•
•
The posted tweet contains two links which do not get
ﬁltered in Preﬁltering step (tested for both positive
predictions and negative predictions)
The posted tweet contains three links which do not
get ﬁltered in Preﬁltering step (tested for both positive
predictions and negative predictions)
For the tweets including negative predictions (i.e.,
the
URLs are classiﬁed to be intended ones), we record the time
from the moment the user clicks the “Tweet” button to the
tweet getting posted on the user’s timeline. For the tweets
including positive predictions (i.e., the URLs are classiﬁed
to be intended ones), we record the time from the moment
user clicks the “Tweet” button to the time they are shown
the extension’s warning dialog. The posting of tweets is
automated using Selenium. Figure 13 shows the results of our
performance tests, averaged over ten runs. The results show
that while our extension does add a delay to the posting of
tweets, this delay is typically under a second, even in the
extreme cases of a user posting three URLs (thereby causing
three classiﬁcation tasks) in the same tweet. We can therefore
conclude that our extension could protect users and their
followers from unintended URLs, for a minimal performance
overhead.
VI. DISCUSSION
In this section, we ﬁrst discuss the implications of our
results for online services. We then highlight the limitations
of our study and sketch some future work directions.
A. Implications for Online Services
In this paper, we show that the efforts expended by many
online services (including Twitter) to identify URLs in the text
of their users and render them as clickable links, can produce
unintended URLs with negative security consequences. There
is an inherent tension between the usability of an online service
and its security, leading to problems that platform designers
12
need to face. Our advice to online services is to consider
the threats highlighted in this paper when designing and
updating their URL rendering systems. An option would be to
develop an unintended URL detection system similar to the one
proposed in this paper on their side. This deployment, however,
should follow a rigorous risk-beneﬁt analysis weighing the
security of users, the usability of the platform, and the user
friction introduced by false positive alerts. Given that, accord-
ing to our results in Section IV, 72% of unintended URLs
point to unregistered domain names, we argue that showing a
warning whenever users post tweets including an unregistered
domain name, would cover the majority of unintended URLs
posted by users with virtually no negative side effects.
B. Limitations
Our dataset comes from the 1% streaming API that Twitter
provides to vetted researchers. As such, we expect that all the
numbers that we presented in this paper are lower bounds
of the problem of unintended URLs. Another limitation is
that we focus on tweets authored in English for both our
model as well as our mitigation. Since most of our features
depend on language, building a language-agnostic model is not
a straightforward task and therefore we chose not to pursue it
in the scope of this work.
C. Future Work
In this paper, we presented a series of promising results
towards automatically detecting unintended URLs on Twitter.
However,
the accuracy of our machine learning algorithm
could be further improved. Adding more complicated features
and potentially analyzing each tweet in the context of other
tweets from the same user, could lead to higher accuracy. At
the same time, heavyweight features will also considerably
increase the time needed for analysis and therefore increase
the performance overhead, particularly if it is to be applied at
the client side.
A possible direction for future work is designing a system
that preemptively identiﬁes future unintended domains, based
on commonly used words and the evolution of TLDs. These
domains could then be essentially “cached” by the classiﬁer,
leading to classiﬁcation speedups. This approach would be