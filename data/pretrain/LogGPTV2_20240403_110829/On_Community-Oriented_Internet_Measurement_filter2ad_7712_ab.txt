limited coupled with a web-of-trust (see § 3.2), mitigates the potential clogging problems that
would result from overly long TTL values.
4 MPs will be expected to be roughly time synchronized (e.g., to within seconds, not minutes).
This could be tracked with a heartbeat measurement built on top of the generic platform.
On Community-Oriented Internet Measurement
117
identiﬁer for each measurement both avoids name clashes between MPs and allows the
measurement results to reside in the DHT only once, but be indexed in a variety of
ways. The key U will be placed into both the results table given in the measurement
request and the results table advertised by the measurement point as the depository for
all its results.5 Additional pointers could be placed in other tables as the measurement
point deems appropriate (e.g., a table for all ping measurements taken in Europe).
We note that DHTs often have a limitation on the size of each entry. For instance,
OpenDHT has a 1024 byte limit on the size of the records that can be placed into the
system. Obviously, this may be inadequate for many measurement results and therefore
the MPs will have to split the results across a number of entries with the consumers
of those results being required to reassemble the pieces. As discussed in § 3.3 we in-
tend to make this process seamless for MPs and measurement consumers by providing
fragmentation and reassembly primitives. Therefore, instead of using the DHT’s stan-
dard put() and get() functions, alternate forms will be available that abstract away any
required fragmentation and reassembly.
3.1.1 Example. We now step through an example usage of our framework. This ex-
ample is meant to be illustrative and help the reader gain intuition in the system, rather
than exhaustively showing all possible behavior and capabilities.
MP Registration. When a measurement point for a particular measurement comes on
line it registers four pieces of information in the “AllMPs” master table: (i) the type of
measurement and version being provided (e.g., ping-0.45b), (ii) the name of the request
queue the measurement point services (e.g., “reqQ”), (iii) the name of the list that
the measurement point adds results to upon completion (e.g., “respQ”) and (iv) other
ancillary data that may aid researchers (e.g., location of measurement point, operating
system version, etc.).6 Example:
put (“AllMPs”,”ping-0.45b reqQ respQ extra info”)
Finding MPs. When a researcher wants to run a particular kind of measurement they
can access the “AllMPs” table to obtain a list of the MPs, their capabilities and the
tables they use. Example:
get (“AllMPs”)
⇒
ping-0.45b reqQ respQ extra
Measurement Request. After a researcher has determined MPs that meet their needs
they request a particular MP perform a measurement by adding an entry to the MP’s
request queue that gives (i) the time the measurement should be undertaken (e.g.,
184866301), (ii) the name of a result queue the researcher will monitor for results
(e.g., “MyResults”) and (iii) arguments to the particular measurement tool (e.g., “-n
www.icir.org”). Examples:
5 Note that there will inevitably be additional details included with the results, such as a check-
sum of the results, time the measurement was taken, etc. These details are omitted here, where
we focus on the high-level design.
6 Note: We have not yet added structure to this information, but such structure (or partial struc-
ture) would likely be needed to make this ﬁeld useful for automated processing.
118
M. Allman et al.
put (“reqQ”,”184866301 MyResults -n www.icir.org”)
put (“reqQ”,”184866601 MyResults -n www.icir.org”)
Measurement Point Polling. Periodically, the measurement point polls the DHT to
retrieve its request queue. If the MP sketched above polled it would ﬁnd the two mea-
surements inserted into the queue in the last step. Example:
get (“reqQ”)
⇒
1184866301 MyResults -n www.icir.org
1184866601 MyResults -n www.icir.org
Running Measurements. Upon receiving requests the MP schedules and executes the
requested measurements. Upon completion assume the results will be held in some local
variable R. The MP will generate a universally unique identiﬁer as the key under which
to place the measurement result (e.g., U). After having placed the results in the DHT the
MP then places pointers to the results in its own result queue and the queue requested
in the researcher’s measurement request. Example:
put (U,R)
put (“respQ”,U)
put (“MyResults”,U)
Researcher Retrieving Results. The researcher who requests some measurements sim-
ply polls on the result queue provided in their request to retrieve pointers to measure-
ment results. Following these pointers will then yield the results. Example:
get (“MyResults”)
⇒
U
get (U)⇒
measurement results (R, in this case)
Watcher Retrieving Results. An uninvolved researcher can simply watch results roll
into the DHT based on other’s requests. In order to do this the watcher will ﬁrst have
to identify MPs conducting desirable measurements (as shown above in the “Finding
MPs” step. From this information the passive observer can then poll on the MP’s re-
sponse queue for pointers to measurement results as shown in the previous example
above (but starting with retrieving the “respQ” table instead of “MyResults”).
3.2 Security
As sketched above, the system has a number of security vulnerabilities. First, a mea-
surement requester can attempt to increase the load on a measurement point simply by
requesting large quantities of measurements. Even more problematic is the distributed
nature of the system which could allow a requester to coax many MPs to simultane-
ously send (potentially large volumes of) trafﬁc towards a particular victim. Finally, an
attacker could launder requests through the measurement infrastructure in an attempt to
gain a layer of anonymity. We offer several approaches to mitigate such problems.
First, we note that measurement requests are just that: requests. We make no as-
sumptions that the MPs must satisfy all (or any) requests. The requests will receive
On Community-Oriented Internet Measurement
119
“best effort”-like service. That is, a measurement point should do its best to conduct
the requested measurement at the requested time, but does not make any guarantees.
Given this notion, every measurement point can implement local policy related to its
willingness to conduct measurements to mitigate some of the security concerns. For
instance, a measurement point can both limit the rate of requests that will be serviced
(in the aggregate and from a given requester) and can monitor and limit the host and
network resources a particular measurement consumes—terminating the measurement
if certain thresholds are eclipsed (a la ScriptRoute [10] and DipZoom [8]).
Protecting against nefarious use of a given measurement point is difﬁcult within our
framework because we do not have a central authority through which requests can be
vetted. For instance, an attacker could coax a large number of measurement points to
engage in a DDoS of some service. Or, an attacker could launder their web connections
through such a service to add a layer of anonymity. The MPs themselves each only
understand a small part of an attack which could look nothing at all like an attack from
their viewpoint. Rather than trying to somehow vet all requests that are inserted into
the system in a centralized fashion, we again take a community-based approach to the
problem and offer two mitigations.
– MPs could inform each other about the measurements they are conducting. For
instance, a measurement point executing a measurement towards some target host
H could insert that fact into a table in the DHT. Before MPs run measurements they
consult this target-based table to assess the load already being placed on the target
before deciding whether to execute the given measurement.
– A second mechanism is that we impose the requirement that all entries placed
in the DHT be cryptographically signed. We then construct a table in the DHT
whereby researchers can recognize each other’s cryptographic keys as legitimate
(i.e., to build a web-of-trust). MPs can then only act on requests from known well-
intentioned researchers. There is a one-time cost in getting on such a list, but the
cost is small (getting a small number of colleagues to vouch for you in the system).
This web-of-trust provides a reasonable sense of a requester’s intention before run-
ning a measurement and accountability afterwards.
While the general problem of trusting requesters in an open measurement system is
difﬁcult, our intention is to leverage the fact that when scoped to a system by and for
researchers the problem becomes tractable to suitably mitigate with simple techniques.
3.3 Primitives
Our system does not attempt to provide a stock measurement system that will satisfy all
researchers and all tasks. Rather, researchers will have to integrate new tools and new
data collection techniques into the system as they are needed. The following primitives
are designed to aid researchers in this integration task by providing high-level abstrac-
tions to the low-level details required to interact with the DHT. In addition, we will
provide tools for common tasks that use these primitives.
Registration. As noted above, MPs will register and maintain their presence and in-
formation about the measurement tools they provide. While the speciﬁc contents of the
registration will be tool speciﬁc, the process will be common across tools.
120
M. Allman et al.
Removing Duplicates. Since we rely on polling and on entries in the DHT to sim-
ply time out there must be a way for actors to discover entries that have already been
processed when retrieving a table. For instance, a measurement point would only want
to schedule one measurement no matter how many times a given request is retrieved.
Also, retrieving a measurement result once is sufﬁcient and just because a result pointer
is observed multiple times does not mean the result needs to be fetched multiple times.
Our design calls for an abstraction that only exposes previously unseen items.
Assessing Trust. As sketched above, one common task across measurement types will
be interacting with a web-of-trust to assess a requester’s legitimacy. Primitives to aid in
this process will be key to making such a trust model work.
Fragmentation and Reassembly. As discussed above, measurement results may need
to be fragmented across a number of DHT entries due to limitations on the size of a
single entry (e.g., 1024 bytes in OpenDHT). Therefore, primitives for fragmentation
and reassembly will be required such that researchers and developers can be provided
with an abstraction that works on entire measurements and are not bothered by the
details of how they are placed into the DHT.
Miscellaneous Tasks. There are important common measurement-oriented primitives
that will aid researchers in setting up their measurements. For instance, a common task
is to derive a measurement schedule, and primitives for this task that will allow for direct
use with the overall measurement framework will be crucial. Another example is for a
measurement point to implement an event loop that polls the DHT for needed informa-
tion and executes measurements at the appointed times. Having a primitive for easily
constructing such an event loop will inevitably aid those integrating new measurement
tools into the system.
The above primitives are designed to work across a variety of measurement applica-
tions. We note, however, that the above list is likely incomplete. As we progress beyond
our proof-of-concept implementation (see § 4) we will likely ﬁnd additional primitives
that are broadly useful and we will include these in the released toolkit.
3.4 Passive Measurements
We note that our discussion above is in terms of active measurements. However, passive
monitors can also be used in our system. We envision these manifesting themselves in
two forms: by-request monitoring and continuous monitoring. In the ﬁrst category a re-
searcher can place a request into an appropriate DHT table to have a measurement point
monitor some facet of the network for some prescribed amount of time. For example,
an MP can register as being capable of monitoring a local Web site, and a request could
be to watch a web log for the next 10 minutes. The latter category allows for passive
monitors to simply run continuously and dump their results into the DHT for public
consumption via live feeds (e.g., a distributed dark address space monitor that provides
a wide view of malicious activity). As with sharing of any passive measurements the
provider may wish to apply anonymization and sanitization policies to the data before
release. For instance, a passive monitor might provide the length (in bytes or seconds)
of each TCP connection without providing the IP addresses (even in anonymized form).
On Community-Oriented Internet Measurement
121
4 Summary
Because of the established difﬁculties in maintaining coherent measurement infrastruc-
tures, we propose to build a measurement platform with no dedicated infrastructure at
all. Instead, we utilize an existing overlay substrate already maintained for a variety of
other purposes, and we concentrate all functionality that is speciﬁc to our platform in
the end hosts. We further make end hosts totally autonomous and loosely connected to
the platform: they can join and depart at will without any reconﬁguration in the rest of
the platform. This allows the platform to grow and shrink naturally with the needs of
the community and be resilient to failures (either technical or logistical). It is important
to note that we do not tackle all the hard problems associated with measurement, but
rather provide a reasonable platform as a basis.
We have built a small prototype of our system that includes a generic client and
an MP that provides traceroute measurements on request. While modest, this small
prototype is aiding us as we ﬂesh out the details of the system as we work towards
providing a toolkit for the broader community.
Acknowledgments
We thank Ethan Blanton, Josh Blanton and Yaohan Chen for discussions of the system
described in this paper. Vern Paxson and the anonymous reviewers provided valuable
suggestions on a draft of this paper. This work was sponsored by NSF grants ITR/ANI-
0205519, NSF-0722035 and NSF/CNS-0721890 for which we are grateful.
References
1. PREDICT: Protected Repository for the Defense of Infrastructure Against Cyber Threats,
http://www.predict.org
2. CAIDA. Archipelago measurement infrastructure,
http://www.caida.org/projects/ark/
3. CAIDA. Internet Measurement Data Catalog, http://www.datcat.org
4. CAIDA. Skitter, http://www.caida.org/tools/measurments/skitter/
5. claffy, k., Crovella, M., Friedman, T., Shannon, C., Spring, N.: Community-Oriented Net-
work Measurement Infrastructure (CONMI) Workshop Report. ACM Computer Communi-
cation Review 36(2), 41–48 (2006)
6. Kalidindi, S., Zekauskas, M.J.: Surveyor: An infrastructure for internet performance mea-
surements. In: INET 1999 (1999)
7. Paxson, V., Mahdavi, J., Adams, A., Mathis, M.: An architecture for large-scale internet
measurements. IEEE Communications 36(8), 48–54 (1998)
8. Rabinovich, M., Triukose, S., Wen, Z., Wang, L.: Dipzoom: the internet measurements mar-
ketplace. In: 9th IEEE Global Internet Symp. (2006)
9. Rhea, S., Godfrey, B., Karp, B., Kubiatowicz, J., Ratnasamy, S., Shenker, S., Stoica, I., Yu,
H.: OpenDHT: A Public DHT Service and Its Uses. In: SIGCOMM (2005)
10. Spring, N., Wetherall, D., Anderson, T.: Scriptroute: A public internet measurement facility.
In: Usenix Symp. on Internet Technologies and Systems (2003)