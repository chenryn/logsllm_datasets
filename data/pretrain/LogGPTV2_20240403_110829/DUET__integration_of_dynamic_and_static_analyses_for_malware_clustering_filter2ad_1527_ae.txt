40.40%
N/A
Preci- Avg. Imp- Coverage Avg. Imp-
sion
0.8
0.84
0.71
0.7275 N/A
Ensemble
Approach
Ball
Agglomerative
Hypergraph
Non-Ensemble
7.4 Improvement with Cluster-Quality Metrics
We ﬁrst examine whether cohesion and separation are
eﬀective measures of cluster quality. We take four best-
coverage cases, one from each clustering (see Table 7), and
compute cohesion and separation for each constituent clus-
ter. We separate “clean” clusters (i.e., those consisting of
malware from only one family) from “mixed” clusters (i.e.,
those consisting of malware samples from multiple families),
and plot their CDFs in Figs. 5. These ﬁgures show that
Co and Cs work fairly well in distinguishing between good
and bad clusters, with clean clusters often having a smaller
cohesion8 and a higher separation than mixed clusters.
Next, we integrate the cluster-quality measures into the
DUET according to Section 6 and apply same ensemble al-
gorithms on the augmented connectivity matrices for both
best-case and random scenarios (Table 7). Fig. 6 compare
the precision and coverage results of the agglomerative en-
semble algorithm with and without quality measures. The
results for other algorithms share the same trends and are
8a smaller cohesion means better (Section 6) cluster quality.
86
Clean Cluster
Mixed Cluster
1
0.8
0.6
0.4
0.2
F
D
C
0
0
0.2
0.4
Cluster Cohesion
0.6
0.8
1
1
0.8
0.6
0.4
0.2
F
D
C
0
0.9
Clean Cluster
Mixed Cluster
0.92
0.94
0.96
Cluster Separation
0.98
1
Figure 5: CDF for Cohesion Co and Separation Cs
1
0.9
1
0.8
n
o
s
i
0.8
i
c
e
r
P
0.7
0.6
0.5
0.2
Quality measures (B)
No quality measures (B)
Quality measures (R)
No quality measures (R)
0.4
0.6
Threshold
0.8
e
g
a
r
e
v
o
C
0.6
0.4
0.2
1
0
0.2
0.4
Quality measures (B)
No quality measures (B)
Quality measures (R)
No quality measures (R)
0.6
1
0.8
Threshold
Figure 6: Agglomerative ensemble algorithm with
quality measures. (B) and (R) represent the best
and random scenario. Avg recall: 0.27; stdev: 0.07
omitted due to space limit. From the ﬁgure, we can ob-
serve that ensemble algorithms with quality-measures out-
perform their original counterpart, by 5–10% in terms of
precision. However, Fig. 6 also shows that the improve-
ment of precision does not come without cost. We ob-
serve a decrease in the malware coverage after incorporat-
ing the quality-measures.9 This is because employing the
quality-measures weakens connectivity between samples in
low-quality clusters, making them more likely to be excluded
from ﬁnal clusters. In all the plots, the coverage is shown
to be reduced by 3–30%, with the biggest drop often oc-
curring when the threshold is around 0.5. This is due to
the composition of member clusterings (i.e., a half from dy-
namic approaches and a half from static approaches). With-
out quality-measures, a threshold of 0.5 (i.e., majority vot-
ing) can result in a false consensus among approaches of the
same type. Fortunately, by using the quality-measures, the
reduced connectivity between weakly-related samples drop
below the threshold, improving precision but lowering the
sample coverage (Fig. 6). However, the decrease in coverage
is not necessarily a disadvantage, as the remaining clusters
are often of better quality, allowing higher conﬁdence when
using these clusters. Incorporating diversiﬁed sets of clus-
tering techniques could potentially mitigate this problem.
7.5 Run Time Performance of DUET
DUET consists of two main components: trace collector and
clustering system. The most time-consuming step is the
trace collection. For all 5,647 malware programs, it took
approximately 12 hours to extract static features and 7 days
to collect dynamic traces on a single machine with an Intel
Core i7 3.0G CPU and 16 GB of RAM. The trace-collector
step, albeit expensive, (1) is required for any malware anal-
ysis tasks and has already been eﬃciently conducted as a
daily process in AV industry, (2) only needs to be done once
and is also amenable to parallelization thanks to the inde-
pendence between malware samples. For instance, Anubis,
an online service for executing and dynamically analyzing
9Astute readers may notice that the same trade-oﬀ can be
obtained by changing the parameters, e.g., Pmax and M ind.
However, the trade-oﬀ made here provides additional bene-
ﬁts of enhancing the cluster qualities.
Figure 7: Running times
of diﬀerent components
Figure 8:
DUET’s components
Scalability of
malware, can process more than 1 million samples on the ﬂy,
as they were submitted during one week period of time [21].
Hence, scalability is becoming a less concern for dynamic
malware analysis, making its integration with static analy-
sis very practical and beneﬁcial.
The second component of DUET is the clustering system
including individual static/dynamic clusterings and cluster
ensemble. Their running times on the entire data set is
summarized in Fig. 7. We observe that the clustering runs
much faster for dynamic features than static features. This
is because the space of static features is orders-of-magnitude
larger than that of dynamic features. As a result, DUET-
S takes longer to compare similarity between longer static
feature vectors (which also help DUET-S achieve better pre-
cision than DUET-D as shown in Section 7.2). The running
times of diﬀerent ensemble algorithms are usually in the
range of 70–90 seconds except for the hypergraph partition-
ing being the most complicated and time-consuming (about
200s). To better understand the scalability, we measure the
running time of DUET with diﬀerent number of input malware
samples, as shown in Fig. 8. The ﬁgure conﬁrms the runtime
complexity of DUET’s ensemble component is O(n2) where n
is the number of malware samples. Because of this quadratic
complexity, DUET’s performance may suﬀer when the number
of malware samples grows signiﬁcantly. A potential solution
is to employ the principle of the ProtoCluster. The ensem-
ble algorithms can ﬁrst be applied to a relatively small set of
prototypes and then propagate to associated samples, avoid-
ing expensive computation over entire dataset.
8. DISCUSSIONS
Here we discuss several limitations of the current DUET pro-
totype, and possible improvements to alleviate them. DUET’s
performance hinges on the successful extraction of useful fea-
tures from malware binaries and run-time behaviors. First,
like any other static-analysis approach, DUET-S is vulner-
able to binary/instruction-level obfuscation and advanced
run-time packers. For instance, anti-disassembly techniques,
such as mixture of code and data, and indirect control ﬂow,
can be used to confuse disassemblers, thus preventing DUET-
S from extracting features. Instruction-level polymorphism
can be used to create syntactically distinct but semantically
similar variants, bypassing DUET’s similarity comparison, Al-
though the current DUET prototype does not handle these
types of obfuscation for simplicity, advanced de-obfuscation
and normalization [22, 30] can be used to mitigate the prob-
lems. For the packers than cannot be handled by generic
unpacking algorithm e.g. in section 4.1, specialized unpack-
ing tools such as Armadillo Killer [1] can be employed.
Similarly, DUET-D as a dynamic analysis system can be cir-
cumvented by speciﬁcally crafted evasion techniques. First,
since any dynamic analysis system typically can only aﬀord
87
to execute a malware program for a small period of time,
it can be circumvented by inserting stalling codes before
the real malicious codes. Systems such as HASEN [18] have
been proposed to detect and automatically skip such stalling
code. Another limitation of DUET-D is its reliance on virtual
machines to provide a controlled environment, for malware
execution. Unfortunately, malware programs can check for
virtual environments [25] and behave diﬀerently from what
they do when running in a real system. Countermeasures in-
clude use of more transparent environments [8, 9], detecting
split identities of malware samples [5] and forcing multiple
path exploration [26]. Finally, both DUET-S and DUET-D can-
not handle ﬁle infectors or parasitic malware which injects
itself into host binaries (e.g. Sality virus), because major-
ity of extracted features may belong to the host binaries.
In practice, techniques for detecting parasitic malware [29]
should be used to pre-ﬁlter these samples.
Malware analysis has always been covering an active bat-
tle ﬁeld between adversaries and defenders. None of the
aforementioned countermeasures are perfect or long-lasting.
Nevertheless, new emerging techniques can be leveraged to
raise the bar and handle common malware types, which, in
practice, prove to be beneﬁcial. Furthermore, the respective
limitations of static and dynamic analysis again strengthen
the necessity and importance for integrating these two ap-
proaches to deal with advanced malware samples.
9. CONCLUDING REMARKS
In this paper, we design, develop and evaluate an au-
tomatic malware-clustering system, called DUET, which ex-
ploits cluster ensemble as a principled method to eﬀectively
integrate static and dynamic analyses. Using a number
of real-life malware samples, we have evaluated the perfor-
mance of ensemble methods for both best-case and random
scenarios, demonstrating that DUET can improve coverage by
20–40% while achieving nearly the highest precision of the
individual clustering algorithms. We have also made fur-
ther improvements of existing cluster ensemble algorithms
by leveraging cluster-quality measures. Overall, the evalua-
tion results have shown DUET’s ability of combining multiple
malware clustering techniques to create more eﬀective and
accurate clusters.
10. REFERENCES
[1] Unpackers. http://www.exetools.com/unpackers.htm.
[2] C. C. Alexander Strehl, Joydeep Ghosh. Cluster
ensembles - a knowledge reuse framework for
combining multiple partitions. Journal of Machine
Learning Research, 2002.
[3] B. Anderson, C. Storlie, and T. Lane. Improving
malware classiﬁcation: bridging the static/dynamic
gap. In Proceedings of the 5th ACM workshop on
Security and artiﬁcial intelligence, AISec ’12, 2012.
[4] M. Bailey, J. Andersen, Z. M. mao, and F. Jahanian.
Automated classiﬁcation and analysis of internet
malware. In In Proceedings of RAID, 2007.
[5] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel,
E. Kirda, and G. Vigna. Eﬃcient detection of split
personalities in malware. In NDSS, 2010.
[6] U. Bayer, P. Comparetti, C. Hlauschek, C. Kruegel,
and E. Kirda. Scalable, behavior-based malware
clustering. In Proc. of the 16th NDSS, 2009.
[7] M. Christodorescu and S. Jha. Static analysis of
executables to detect malicious patterns. In Proc. of
the 12th USENIX Security Symposium, 2003.
[8] A. Dinaburg, P. Royal, M. Sharif, and W. Lee. Ether:
malware analysis via hardware virtualization
extensions. In Proceedings of CCS’08, 2008.
[9] A. Fattori, R. Paleari, L. Martignoni, and M. Monga.
Dynamic and transparent analysis of commodity
production systems. In Proceedings of ASE’10, 2010.
[10] A. Fred. Finding consistent clusters in data partitions.
In Proc. 3d Int. Workshop on Multiple Classiﬁer, 2001.
[11] A. L. N. Fred and A. K. Jain. Data clustering using
evidence accumulation. In Proceedings of the 16 th
International Conf. on Pattern Recognition, 2002.
[12] A. Gionis, H. Mannila, and P. Tsaparas. Clustering
aggregation. ACM Trans. Knowl. Discov. Data, 1,
March 2007.
[13] F. Guo, P. Ferrie, and T.-C. Chiueh. A study of the
packer problem and its solutions. In RAID ’08, 2008.
[14] Y. Hong, S. Kwong, Y. Chang, and Q. Ren.
Unsupervised feature selection using clustering
ensembles and population based incremental learning
algorithm. Pattern Recognition, 41(9):2742–2756, 2008.
[15] J. Jang, D. Brumley, and S. Venkataraman. Bitshred:
feature hashing malware for scalable triage and
semantic analysis. In Proceedings of CCS’11, 2011.
[16] M. E. Karim, A. Walenstein, A. Lakhotia, and
L. Parida. Malware phylogeny generation using
permutations of code. J. in Computer Virology, 2005.
[17] Karypis Lab. Hypergraph partitioning software.
http://glaros.dtc.umn.edu/gkhome/views/metis, 2010.
[18] C. Kolbitsch, E. Kirda, and C. Kruegel. The power of
procrastination: detection and mitigation of
execution-stalling malicious code. CCS ’11, 2011.
[19] J. Z. Kolter and M. A. Maloof. Learning to detect and
classify malicious executables in the wild. Journal of
Machine Learning Research, 7:2006, 2006.
[20] C. W. Konrad Rieck, Philipp Trinius and T. Holz.
Automatic analysis of malware behavior using
machine learning. Technical report, 2011.
[21] C. Kruegel, E. Kirda, U. Bayer, D. Balzarotti, and
I. Habibi. A view on current malware behaviors. In
2nd USENIX Workshop on LEET, 2009.
[22] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna.
Static disassembly of obfuscated binaries. In USENIX
Security’04, 2004.
[23] T. Lee and J. J.Mody. Behavioral classiﬁcation. In
Proceedings of EICAR Conference, 2006.
[24] C. Leita, U. Bayer, and E. Kirda. Exploiting diverse
observation perspectives to get insights on the
malware landscape. In DSN, 1 2010.
[25] T. Liston. On the cutting edge: Thwarting virtual
machine detection http://handlers.sans.org.
/tliston/ThwartingVMDetection Liston Skoudis.pdf.
[26] A. Moser, C. Kruegel, and E. Kirda. Exploring
multiple execution paths for malware analysis. In
Proceedings of Oakland’07, 2007.
[27] K. Rieck, T. Holz, C. Willems, P. D¨ussel, and
P. Laskov. Learning and classiﬁcation of malware
behavior. In Proceedings of DIMVA’08, 2008.
[28] P. Security. Bredolab.aw.
http://www.pandasecurity.com/homeusers/security-
info/220087/Bredolab.AW.
[29] A. Srivastava and J. Giﬃn. Raid. In Recent Advances
in Intrusion Detection. 2010.
[30] S. K. Udupa, S. K. Debray, and M. Madou.
Deobfuscation: Reverse engineering obfuscated code.
Reverse Engineering, Working Conference on, 2005.
[31] G. Wicherski. pehash: A novel approach to fast
malware clustering. In LEET’2009.
[32] Y. Ye, T. Li, Y. Chen, and Q. Jiang. Automatic
malware categorization using cluster ensemble. In
Proceedings of the 16th ACM SIGKDD, 2010.
88