```
这根本不是一个好的 UX，也因为当我们谈到几十台主机时，机器规模仍然非常糟糕。
### (不推荐使用的)新 Docker 驱动程序
曾经，Nova 有一个驱动程序，将 Docker 容器作为 Nova 的最终目的地(例如，这些驱动程序允许从 Nova 创建和管理 Docker 容器，而不是创建 KVM 或 VmWare 虚拟机)。如果对旧的*Swarm 使用这样的工具是有意义的(因为一切都是作为容器编排的)，那么 Swarm Mode 对此不感兴趣，它需要 Docker Hosts 而不是裸容器。*
 *## 现实——友好的方式打开栈
幸运的是，OpenStack 是一个非常有活力的项目，现在已经到了发布**O**(**octa**)的时候，它被很多可选模块丰富了。从 Docker Swarm 的角度来看，最有趣的是:
*   **热度:**这是指挥系统，可以通过模板创建 VMs 配置。
*   **Murano:** 这是应用目录，可以从开源社区维护的目录中运行应用，包括 Docker 和 Kubernetes 容器。
*   **Magnum:** 这是 Rackspace 的容器即服务解决方案。
*   **Kuryr:** 这是网络抽象器。使用 Kuryr，您可以链接中子租户网络和用 Docker Libnetwork 创建的 Docker 网络(如 Swarm 网络)，并将 OpenStack 实例与 Docker 容器连接起来，就像它们连接到同一个网络一样。
## 打开栈加热
OpenStack Heat 有点像 Docker Compose，允许您通过模板启动系统，但它要强大得多:您不仅可以从一个映像引导一组实例，比如 Ubuntu 16.04，还可以编排它们，这意味着创建网络，将虚拟机接口连接到网络，放置负载平衡器并在实例上执行后续任务，例如安装 Docker。大致来说，Heat 相当于亚马逊为 OpenStack 开发的 CloudFormation。
在热火，一切都是从 YAML 模板开始的，得益于它，你可以在启动基础设施之前对其进行建模，就像你使用 Compose 一样。例如，您可以创建如下模板文件:
```
...
resources:
  dockerhosts_group:
    type: OS::Heat::ResourceGroup
    properties:
      count: 10
      resource_def:
        type: OS::Nova::Server
        properties:
          # create a unique name for each server
          # using its index in the group
          name: docker_host_%index%
          image: Ubuntu 16.04
          flavor: m.large
...
```
然后，您可以从中启动一个栈(`heat stack-create -f configuration.hot dockerhosts`)。Heat 将调用 Nova、中子、煤渣和所有必要的 OpenStack 服务来编排资源并使它们可用。
这里我们不打算展示如何通过 Heat 启动 Docker Swarm 基础设施，而是在这里我们将看到 Magnum，它在下面使用 Heat 来操作 OpenStack 对象。
## OpenStack Magnum
Magnum 于 2015 年末发布，由 OpenStack 容器团队开发，旨在使 Docker Swarm 和 **Kubernetes** 等**容器编排引擎** ( **COEs** )成为 OpenStack 中的一流资源。OpenStack 领域曾经有并将有许多项目专注于提供容器支持，但 Magnum 走得更远，因为它旨在支持*容器编排*，而不是裸容器管理。
![OpenStack Magnum](img/image_10_008.jpg)
到目前为止，重点特别放在了 Kubernetes 上，但我们这里说的是 **Magnum** ，因为它是最有希望的开源技术，提供了一种在私有云上运行 CaaS 编排的便捷方式。在撰写本文时，马格南还不支持最新的蜂群模式:这个特性必须得到解决。作者打开了一个启动板蓝图，最终可能会在书出版后开始工作:[https://蓝图.启动板. net/magnum/+spec/swarm-mode-support](https://blueprints.launchpad.net/magnum/+spec/swarm-mode-support)。
### 架构和核心概念
Magnum 有两个主要组件，运行在控制器节点上:
```
magnum-api
magnum-conductor
```
第一个进程`magnum-api`是典型的 OpenStack API 提供程序，由 magnum Python 客户端或其他进程调用进行操作，例如创建集群。后者`magnum-conductor`由`magnum-api`(或多或少与`nova-conductor`功能相同)通过一个 AMQP 服务器调用，如 Rabbit，其目标是与 Kubernetes 或 Docker APIs 接口。实际上，这两个二进制文件共同提供了一种编排抽象。
![Architecture and core concepts](img/image_10_009.jpg)
在 OpenStack 集群计算节点上，除了`nova-compute`进程之外，没有什么特别需要运行的:Magnum conductor 直接利用 Heat 创建栈，从而在 Nova 中创建网络并实例化虚拟机。
随着项目的进行，马格南术语也在不断发展。但这些是主要的概念:
*   **容器**是 Docker 容器。
*   一个**集群**(以前是一个湾)是一个节点对象的集合，在那里工作被调度，例如，Swarm 节点。
*   一个**集群模板**(以前的 BayModel)是存储集群类型信息的模板。例如，一个集群模板定义*一个有 3 个经理和 5 个工人的集群*。
*   **Pods** 是在同一台物理机或虚拟机上运行的容器的集合。
至于高级选项，如存储、新的 Coe 支持和扩展，Magnum 是一个非常活跃的项目，我们建议您在[http://docs.openstack.org/developer/magnum/](http://docs.openstack.org/developer/magnum/)上关注它的发展。
### 在 Mirantis OpenStack 上安装 HA Magnum
安装 Magnum 并不是一件小事，尤其是如果你想保证 OpenStack HA 部署中的一些典型故障转移。网上有很多关于如何在 DevStack(开发人员的 1 节点分段设置)中配置 Magnum 的教程，但是没有一个说明如何在有多个控制器的真实生产系统上工作。这里我们展示了如何在真实的设置中安装 Magnum..
通常，生产 OpenStack 安装会计算专用于不同目标的节点数量。在最小高可用性部署中，通常有:
*   三个或更多(出于法定人数原因为奇数)**控制器节点**，负责托管 OpenStack 程序的 API 和配置服务，如 Rabbit、MySQL 和 HAproxy
*   任意数量的**计算节点**，工作负载物理运行于此(虚拟机托管于此)
可选地，可以有专用的存储、监控、数据库、网络和其他节点。
在这里的设置中，基于安装了 Heat 的运行 Newton 的 **Mirantis OpenStack** ，我们有三个控制器和三个计算加存储节点。HA 配置了起搏器，使 MySQL、Rabbitmq 和 HAproxy 等资源保持高可用性。API 由 HAproxy 代理。这是显示起搏器中配置的资源的屏幕截图。它们都已启动并正常工作:
![Install HA Magnum on Mirantis OpenStack](img/image_10_010.jpg)
集群中所有节点都运行 Ubuntu 16.04 (Xenial)，对于这个版本稳定的 Magnum 2.0 包是存在的，从上游消耗下来，用`apt-get install`安装就足够了。
然而，在安装 Magnum 之前，有必要准备环境。首先，需要一个数据库。只需键入以下命令，即可从任何控制器进入 MySQL 控制台:
```
node-1# mysql
```
在 MySQL 中，创建 magnum 数据库和用户，并授予正确的权限:
```
CREATE DATABASE magnum;
GRANT ALL PRIVILEGES ON magnum.* TO 'magnum'@'controller' \
  IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON magnum.* TO 'magnum'@'%' \
  IDENTIFIED BY 'password';
```
现在，有必要在 Keystone 中创建服务凭证，首先定义一个必须添加到服务组的 magnum OpenStack 用户。服务组是一个特殊的组，其中包括跨集群运行的 OpenStack 服务，如 Nova、中子等。
```
openstack user create --domain default --password-prompt magnum
openstack role add --project services --user magnum admin
```
之后，必须创建新的服务:
```
openstack service create --name magnum \   --description "OpenStack 
    Container Infrastructure" \   container-infra
```
OpenStack 程序通过它们的 API 被调用和对话。通过端点访问应用编程接口，端点是一对网址和端口，在高可用性设置中由高可用性代理。在我们的设置中，HAproxy 在`10.21.22.2`接收 HTTP 请求。并在控制器 IPs 之间平衡它们，即`10.21.22.4, 5`和`6`。
![Install HA Magnum on Mirantis OpenStack](img/image_10_011.jpg)
我们必须为 Magnum 创建这样的端点，默认情况下，Magnum 在端口 9511 上监听每个区域(公共、内部和管理):
```
openstack endpoint create --region RegionOne \
  container-infra public http://10.21.22.2:9511/v1
openstack endpoint create --region RegionOne \
  container-infra internal http://10.21.22.2:9511/v1
openstack endpoint create --region RegionOne \
  container-infra admin http://10.21.22.2:9511/v1
```
此外，Magnum 需要额外的配置来在域内部组织其工作负载，因此必须添加一个专用域和一个域用户:
```
openstack domain create --description "Magnum" magnum
openstack user create --domain magnum --password-prompt 
    magnum_domain_admin
openstack role add --domain magnum --user magnum_domain_admin admin
```
现在一切就绪，终于可以运行`apt-get`了。在所有三个控制器上，运行以下命令，并在 ncurses 界面中，始终回答“否”，以不更改环境或保持默认配置:
```
apt-get install magnum-api magnum-conductor
```
### 配置高可用性马格南安装
马格南的配置非常简单。要使它处于启动和运行状态，需要做的是:
1.  通过`magnum.conf`文件进行配置。
2.  重启马格南二进制文件。
3.  打开端口`tcp/9511`。
4.  配置 HAproxy 以接受和平衡 magnum APIs。
5.  重新载入 HAproxy。
必须在每个控制器上完成的关键配置如下。首先，在每个控制器上，主机参数应该是管理网络上接口的 IP:
```
[api]
host = 10.21.22.6