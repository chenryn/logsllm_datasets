#BHUSA @BlackHatEvents
Human or Not: Can You Really 
Detect the Fake Voices?
Liu Xin, Tan Yuan
School of Information Science and Engineering, Lanzhou University
#BHUSA @BlackHatEvents
Information Classification: General
Contents
 What’s Fake Voice
 Introduction of AI-synthesized speeches
 Existing Detectors
 Existing AI-synthesized Speech Detection Approaches
 Problems in Existing Approaches
 SiF-DeepVC
 Voice Clone based on Deep Learning and Speaker-irrelative Features
 Detection Bypass using SiF-DeepVC
 Evaluation
 Four experiments to prove our findings
 Conclusion
 Takeaways
 Open-source code and datasets
#BHUSA @BlackHatEvents
Information Classification: General
What’s Fake Voice
#BHUSA @BlackHatEvents
Information Classification: General
What’s Fake Voice
 Novel fake voices are AI-synthesized speeches
 Commonly used for fraud, customer service, and authorization bypass 
 Voice Clone (VC) is the most dangerous one
#BHUSA @BlackHatEvents
Information Classification: General
VC-based Crime
#BHUSA @BlackHatEvents
Information Classification: General
History of Speech Synthesis
 Old Days (Before 20th Century)
Simulate sounds with different machines
Very difficult to simulate human voice
 “Jigsaw Era” (Before 2010)
Automatic “unit selection”
Very poor coherence and easy to detect
 AI-synthesized speeches (Since 2010)
Smooth and natural
Difficult to detect
#BHUSA @BlackHatEvents
Information Classification: General
AI-synthesized Speeches
 Input: what you want to say, output: voice
 Voice Clone (VC): Replace “Voice Features”!
Linguistical 
Data
Encoder
Concat
Attention
Decoder
Synthesizer
Vocoder
Voice
Features
Output Voice
#BHUSA @BlackHatEvents
Information Classification: General
Existing Detectors
#BHUSA @BlackHatEvents
Information Classification: General
Existing Detection Approaches
 All existing approaches are reported very promising performance
 Computer Vision (CV)-based approaches
Inspired by image recognition techniques that are now quite mature
 Convert voice to image and then use image techniques for classification
Most of existing approaches are using CV
Top conferences or journals
Deep4SNet (2021, ACC > 98%)
RES-EfficientCNN (2020, F1 > 97%)
Farid et al.(2019, AUC > 99%)
#BHUSA @BlackHatEvents
Information Classification: General
Existing Detection Approaches
 All existing approaches are reported very promising performance
 Neural Network Feature (NNF)-based approaches
 Proposed in ACM MM 2020 (Top Conference)
 Use neuronal activity in neural network as features
 SOTA: DeepSonar (2020, ACC=100%)
 End-to-End (E2E)-based approaches
 Novel approaches, commonly used in NLP problems
 SOTA: RawNet2 (2021, Baseline for ASVspoof 2021, EER=6.1%)
 Statistical-based approaches
 Traditional approaches. Not popular in recent years.
 No publications on top conferences/journals in recent 3 years.
#BHUSA @BlackHatEvents
Information Classification: General
Problems in Existing Approaches
Unrealistic Datasets
Speaker-irrelative Features
Multiple Classifications
#BHUSA @BlackHatEvents
Information Classification: General
Speaker-irrelative Features
 Features that should NOT be used to determine "human or not"
Not a necessary part of the transmission content
Not related to the speaker
 Examples
Meaningless Silences: before and after the human voice
Background Noises: current sound, wind, and so on
Different Languages: English, Chinese, French, and so on
#BHUSA @BlackHatEvents
Information Classification: General
SiF-DeepVC
#BHUSA @BlackHatEvents
Information Classification: General
What’s SiF-DeepVC
 Voice Clone based on Deep Learning and Speaker-irrelative Features
 “SiF-DeepVC”
“SiF” stands for “Speaker-irrelative Feature”
“Deep” stands for “Deep Learning”
“VC” stands for “Voice Clone”
 PWN detectors with Speaker-irrelative Features
#BHUSA @BlackHatEvents
Information Classification: General
Overview
Human Voice
Linguistical 
Data
Encoder
Concat
Attention
Decoder
Synthesizer
Vocoder
Voice Cloner
Cloned 
Voice
Denoiser
Frequency 
Remover
Volume 
Adjuster
SI Feature Extractor
Output Voice
Crafted
Voice
Soundtrack
Merger
Voice Merger
Speaker
Encoder
Feature
Vector
#BHUSA @BlackHatEvents
Information Classification: General
Voice Cloner
 Speaker Encoder
 Based on G2EE
 It computes a fixed dimensional feature vector from the speech signal
 Synthesizer
 Sequence-to-sequence and based on Tacotron implementation
 It generates a mel spectrum under the constraint of speaker embedding vector
 Vocoder
 Based on WaveRNN
 It converts the mel spectrum generated by Synthesizer into time-domain waveforms
 Denoiser
 It removes the noisy part of the voice generated by Synthesizer and Vocoder
 high-frequency noise, current sound, etc.
#BHUSA @BlackHatEvents
Information Classification: General
A Demo: Mr. Musk
 Based on a recording of Mr. Elon Reeve Musk
Here are the original voice and the voice generated by Voice Cloner
 The latest top-journal published detector (Deep4SNet) still marks it as fake
Speaker
Encoder
Encoder
Concat
Attention
Decoder
Synthesizer
Vocoder
Voice Cloner
Denoiser
Human Voice
Cloned Voice
“I will give 
everyone 
10 million 
dollars”
Fake Voice 
Detected
#BHUSA @BlackHatEvents
Information Classification: General
SI Feature Extractor
 VC attack
Convey the information we want to convey through speech
 A successful VC attack needs:
The intelligibility of cloned voice is acceptable
The size of output cannot be too large
 How to get the speaker-irrelative features from human speeches
Remove human audible sound (most of human voice are in 1 kHz~3 kHz)
Lower the volume to avoid to be “too noisy”
#BHUSA @BlackHatEvents
Information Classification: General
SI Feature Extractor
 First, for a specific audio file W:
Its amplitude set is A, timestamp set is T, frequency set is F
We have:
 Then, the amplitude a ∈ A at specific timestamp and frequency is:
#BHUSA @BlackHatEvents
Information Classification: General
SI Feature Extractor
 We denote the silence frequency range       
 If              , we have:
 Then, the amplitude at specific timestamp and frequency is:
#BHUSA @BlackHatEvents
Information Classification: General
SI Feature Extractor
 We silence all the voices below 4 kHz (human voice mainly in 0.3 kHz~3 kHz)
 Since most of 4 kHz+ sounds are noise, we reduce their volume
 We define:
: the processing function of SI Feature Extractor
: the audio generated by SI Feature Extractor
 We have:
 Its amplitude:
#BHUSA @BlackHatEvents
Information Classification: General
SI Feature Extractor
 Time-domain spectrums
Human Voice (Left) and Voice after Frequency-based Process (Right)
We can see most of high amplitudes are below 3 kHz in human voice
#BHUSA @BlackHatEvents
Information Classification: General
A Demo: Mr. Musk
 Based on a recording of Mr. Elon Reeve Musk
Target: “I will give everyone 10 million dollars!”
Here are the original voice and the voice extracted by SI Feature Extractor
Frequency 
Remover
Volume 
Adjuster
SI Feature Extractor
Crafted Voice
Human Voice
#BHUSA @BlackHatEvents
Information Classification: General
Voice Merger
 It combines voices from SI Feature Extractor and Voice Cloner
: voice from SI Feature Extractor
: voice from Voice Cloner
 If the length of         is smaller or larger than       
Repeat or crop         until its length is the same as 
 Its output can be denoted as        :
#BHUSA @BlackHatEvents
Information Classification: General
Voice Merger
 For all                                            , we have:
 Time-domain spectrums: 
Cloned Voice (Left) and Output Voice (Right)
Clearly, the differences are very little
#BHUSA @BlackHatEvents
Information Classification: General
A Demo: Mr. Musk
 Based on a recording of Mr. Elon Reeve Musk
Target: “I will give everyone 10 million dollars!”
Here are the original voice, the cloned voice and the output voice
 The latest detector published on top journal (Deep4SNet) marks it as real
Cloned Voice
Crafted Voice
Voice Merger
Output Voice
#BHUSA @BlackHatEvents
Information Classification: General
A Demo: Mr. Musk
Human Voice
Encoder
Concat
Attention
Decoder
Synthesizer
Vocoder
Voice Cloner
Cloned 
Voice
Denoiser
Frequency 
Remover
Volume 
Adjuster
SI Feature Extractor
Output Voice
Crafted
Voice
Soundtrack
Merger
Voice Merger
Speaker
Encoder
Feature
Vector
“I will give 
everyone 
10 million 
dollars”
#BHUSA @BlackHatEvents
Information Classification: General
Evaluation
#BHUSA @BlackHatEvents
Information Classification: General
Evaluation
 Questions for evaluation
 RQ1: Are existing detection approaches practical in real-world environments
 RQ2: Do the speaker-irrelative features really affect existing detection approaches
 RQ3: Can the SiFDeepVC-generated cloned voices bypass existing detection approaches
 RQ4: Can people understand the speeches generated by SiF-DeepVC
 Baseline Datasets
 Original human recordings from two open-source datasets as the base datasets
FoR Validation: English, 5400 original human recordings, all silence-removed
MagicData Test: In Mandarin, 24279 Samples
 Recordings covering different ages, lengths, and environments, and are well represented