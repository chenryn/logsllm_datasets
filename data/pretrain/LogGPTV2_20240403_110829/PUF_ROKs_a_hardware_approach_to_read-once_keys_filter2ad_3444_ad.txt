of the PUF produced 32 bits of output. Consequently, to
generate larger keys, the ARM processor polled the PUF
multiple times, caching the result until the key size was met.
To put the performance of the PUF into perspective, we
compared the execution time with measurements [2] reported
by NXP, the device manufacturer. Some of NXP’s measure-
ments are reported in Figure 5. As each PUF execution
(producing 32 bits of output) requires 2.73 ms to overﬂow
the timer, it is slower than encrypting one kB of data in
AES. Observe, though, that larger PUFs would still only re-
quire 2.73 ms. Consequently, the overhead of executing the
PUF can remain small, especially as large amounts of data
are encrypted or decrypted.
Symmetric
Algorithm
AES-CBC
AES-ECB
3DES-CBC
3DES-ECB
Time
(ms/kB)
1.21
1.14
3.07
3.00
RSA
Operation
1024-bit encrypt
1024-bit decrypt
2048-bit encrypt
2048-bit decrypt
Time
(s)
0.01
0.27
0.05
2.13
Figure 5: NXP cryptographic measurements
The comparison the RSA encryption and decryption is
stark. Observe that the 2.73 ms required to execute the
PUF is 27.3% of the time to perform a 1024-bit encryption
in RSA. As the key size increases (assuming the PUF size is
increased accordingly so that only one polling is needed), the
PUF execution time becomes 0.13% overhead for 2048-bit
RSA decryption. Thus, the performance impact of polling
the PUF during key generation is minimal.6
6Obviously, there is additional work required to convert the
PUF output into a usable key. However, the precise tim-
ing of this work is implementation-dependent, and the al-
gorithms typically employed are signiﬁcantly more eﬃcient
than the modular exponentiation. As such, we focus solely
on the PUF measurement in our analysis.
6. SECURITY ANALYSIS
For our security analysis, we consider the case of a proba-
bilistic polynomial-time (PPT) attacker A, with two goals.
First, the goal of A is to recover just the key used to encrypt
or decrypt a single message. The second goal considered is
to model the PUF, which would enable the attacker to em-
ulate the PUF ROK in software, thereby negating the hard-
ware ROK guarantee.
Initially, in both cases, we assume
the adversary is capable of (at most) eavesdropping on bus
communication. That is, the adversary is unable to observe
communication between the cores in the SoC design.
Under this model, A is able to observe the data passing
between the PC and memory, or between the PC and a net-
work. Observe, though, that these messages consist exclu-
sively of the plaintext m and the encrypted e(m). Thus, the
attack is a known-plaintext attack. However, this informa-
tion oﬀers no additional knowledge to A. Even if A managed
to reconstruct the key K (with negligible probability under
the PPT model), this key is never used again.
The only use of reconstructing K in this manner is to at-
tempt to reverse engineer the behavior of the PUF. However,
recall that our design involved hashing the PUF output when
creating the keys. Consequently, K = H(Ri), where H is a
robust cryptographic hash function. As a result, A again
has only a negligible probability of reconstructing Ri. Yet,
we can take this analysis even further, because Ri by itself
is useless. That is, A would also need to know the corre-
sponding Ci (or Ri+1) to begin to model the PUF. Thus, A
would have to accomplish a minimum of four feats, each of
which has only a negligible probability of occurring. Thus,
we do not ﬁnd such an attack to be feasible.
To continue the analysis, we loosen our assumed restric-
tions and grant A the ability to probe inside the SoC and
observe all data transferred between the cores. Clearly, such
an adversary would succeed, as the data passed between the
PUF and the CC occurs in the open. However, this attack
model is so extreme that only the most dedicated and mo-
tivated adversaries would undertake such a task. Similarly,
users who are faced with such powerful adversaries are likely
to have extensive resources themselves. Thus, these users are
likely to shield the processor using known tamper-resistance
techniques, and we ﬁnd this threat to be minimal.
Moving away from the PPT model, we can return to the
discussion of fault injection [11, 10, 9, 8, 30] and freezing [5]
attacks. Fault injection attacks fail to threaten the conﬁ-
dentiality of the system, because these attacks are based on
repeatedly inducing the fault with the same key. However,
PUF ROKs can only be used once. At best, a fault injec-
tion would become a denial-of-service, as the key would not
correctly enrypt or decrypt the message. Freezing attacks
are similarly unsuccessful, because they operate on the as-
sumption that the key existed in addressable memory at
some point. However, that is not the case with PUF ROKs.
These keys are generated dynamically and are never explic-
itly stored outside the processor itself. Thus, PUF ROKs
oﬀer robust defenses against these physical attacks.
One ﬁnal class of attacks to consider is power analysis [26].
Simple power analysis (SPA) involves monitoring the sys-
tem’s power ﬂuctuation to diﬀerentiate between portions of
cryptographic algorithms. This information leakage can re-
veal how long, for instance, a modular exponentiation takes,
which reveals information about the key itself. Diﬀerential
power analysis (DPA) observes the power ﬂuctuations over
time by repeatedly executing the cryptographic algorithm
with the targeted key. Ironically, DPA is considered harder
to defend against than SPA. And yet, PUF ROKs are im-
mune to DPA (since repeated execution is not allowed) while
vulnerable to SPA. Even though SPA is a potential threat,
known techniques can prevent these attacks [37].
7. CONCLUSION
In conclusion, this work presents a novel hardware-based
approach to generating read-once keys (ROKs). Our un-
derlying strategy is to integrate a PUF with a register to
create a feedback loop. The result is that no data required
for the PUF ROK ever exists outside of the processor itself.
In addition, the feedback loop continuously overwrites the
contents of the register, thereby destroying the key imme-
diately upon use. As such, the design successfully captures
the notion of a ROK.
In this work, we have deﬁned a ROK in terms similar to
a Turing machine. We presented our architectural design
and proved that it matches the formalism. We described
applications of PUF ROKs and addressed concerns regard-
ing their practicality and usability. We presented details
of our prototype design and shared insights regarding fu-
ture production-quality implementations. We presented a
security analysis of PUF ROKs under the PPT adversary
model, and we also demonstrated that PUF ROKs are re-
silient against even more powerful adversaries with the abil-
ity to perform physical attacks on the device. In summary,
we have demonstrated that PUF ROKs are both feasible
and secure.
8. REFERENCES
[1] Polarssl: Small cryptographic library.
http://www.polarssl.org/, 2008.
[2] Encryption for ARM MCUs. http://ics.nxp.com/
literature/presentations/microcontrollers/pdf/
nxp.security.innovation.encryption.pdf, 2010.
[3] Ironkey military strength ﬂash drives.
http://www.ironkey.com/, 2010.
[4] KNJN FPGA development boards.
http://www.knjn.com/FPGA-FX2.html, 2010.
[5] A. Akavia, S. Goldwasser, and V. Vaikuntanathan.
Simultaneous hardcore bits and cryptography against
memory attacks. In TCC ’09: Proceedings of the 6th
Theory of Cryptography Conference on Theory of
Cryptography, pages 474–495, Berlin, Heidelberg,
2009. Springer-Verlag.
[6] M. J. Atallah, E. D. Bryant, J. T. Korb, and J. R.
Rice. Binding software to speciﬁc native hardware in a
VM environment: The PUF challenge and
opportunity. In VMSEC ’08. ACM, 2008.
[7] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,
A. Sahai, S. Vadhan, and K. Yang. On the
(im)possibility of obfuscating programs. In Lecture
Notes in Computer Science, pages 1–18.
Springer-Verlag, 2001.
[8] A. Berzati, C. Canovas, J.-G. Dumas, and L. Goubin.
Fault attacks on RSA public keys: Left-to-right
implementations are also vulnerable. In CT-RSA ’09:
Proceedings of the The Cryptographers’ Track at the
RSA Conference 2009 on Topics in Cryptology, pages
414–428, Berlin, Heidelberg, 2009. Springer-Verlag.
[9] A. Berzati, C. Canovas, and L. Goubin. In(security)
against fault injection attacks for CRT-RSA
implementations. Fault Diagnosis and Tolerance in
Cryptography, Workshop on, 0:101–107, 2008.
[10] A. Berzati, C. Canovas, and L. Goubin. Perturbating
RSA public keys: An improved attack. In E. Oswald
and P. Rohatgi, editors, Cryptographic Hardware and
Embedded Systems (CHES 2008), volume 5154 of
Lecture Notes in Computer Science, pages 380–395.
Springer Berlin / Heidelberg, 2008.
[11] E. Brier, B. Chevallier-mames, M. Ciet, C. Clavier,
and ´Ecole Normale Sup´erieure. Why one should also
secure RSA public key elements. In Cryptographic
Hardware and Embedded Systems (CHES 2006),
volume 4249 of Lecture Notes in Computer Science,
pages 324ˆa ˘A¸S–338. Springer-Verlag, 2006.
[12] B. Danev, T. S. Heydt-Benjamin, and S. ˇCapkun.
Physical-layer identiﬁcation of RFID devices. In
Proceedings of the USENIX Security Symposium, 2009.
[13] S. Devadas, E. Suh, S. Paral, R. Sowell, T. Ziola, and
V. Khandelwal. Design and implementation of
PUF-based “unclonable” RFID ICs for
anti-counterfeiting and security applications. In 2008
IEEE International Conference on RFID, pages
58–64, 2008.
authentication with trusted hardware. In The Fourth
Annual Workshop on Scalable Trusted Computing
(ACM STC ’09), November 2009.
[23] M. S. Kirkpatrick and S. Kerr. Enforcing physically
restricted access control for remote data. In 1st ACM
Conference on Data and Application Security and
Privacy (CODASPY), February 2011.
[24] M. S. Kirkpatrick, S. Kerr, and E. Bertino. PUF
ROKs: Generating read-once keys with physically
unclonable functions (extended abstract). In 6th
Annual Cyber Security and Information Intelligence
Research Workshop (CSIIRW), April 2010.
[25] N. Koblitz. Elliptic curve cryptosystems. Mathematics
of Computation, pages 203–209, 1987.
[26] P. Kocher, J. Jaﬀe, and B. Jun. Introduction to
diﬀerential power analysis and related attacks.
Technical report, Cryptography Research, 1998.
[27] V. Kolesnikov. Truly eﬃcient string oblivious transfer
using resettable tamper-proof tokens. In TCC, pages
327–342, 2010.
[28] K. Lofstrom, W. Daasch, and D. Taylor. IC
identiﬁcation circuit using device mismatch. In
Solid-State Circuits Conference, 2000. Digest of
Technical Papers. ISSCC. 2000 IEEE International,
pages 372–373, 2000.
[14] K. B. Frikken, M. Blanton, and M. J. Atallah. Robust
[29] S. Narayanan, A. Raghunathan, and R. Venkatesan.
authentication using physically unclonable functions.
In Information Security Conference (ISC), September
2009.
[15] B. Gassend, D. Clarke, M. van Dijk, and S. Devadas.
Controlled physical random functions. In Proceedings
of the 18th Annual Computer Security Applications
Conference (ACSAC), 2002.
[16] B. Gassend, D. Clarke, M. van Dijk, and S. Devadas.
Silicon physical random functions. In Proceedings of
the 9th ACM Conference on Computer and
Communications Security (CCS ’02), 2002.
Obfuscating straight line arithmetic programs. In
DRM ’09: Proceedings of the nineth ACM workshop
on Digital rights management, pages 47–58, New
York, NY, USA, 2009. ACM.
[30] A. Pellegrini, V. Bertacco, and T. Austin. Fault-based
attack of RSA authentication. In Design Automation
and Test in Europe (DATE), March 2010.
[31] M. Riley and I. Richardson. Reed-solomon codes.
http://www.cs.cmu.edu/afs/cs.cmu.edu/project/
pscico-guyb/realworld/www/reedsolomon/reed_
solomon_codes.html, 1998.
[17] R. Geambasu, T. Kohno, A. Levy, and H. M. Levy.
[32] S. Rockliﬀ. The error correcting codes (ecc) page.
Vanish: Increasing data privacy with self-destructing
data. In Proc. of the 18th USENIX Security
Symposium, 2009.
[18] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum.
One-time programs. In CRYPTO 2008: Proceedings of
the 28th Annual conference on Cryptology, pages
39–56, Berlin, Heidelberg, 2008. Springer-Verlag.
[19] V. Goyal, Y. Ishai, A. Sahai, R. Venkatesan, and
A. Wadia. Founding cryptography on tamper-proof
hardware tokens. In D. Micciancio, editor, Theory of
Cryptography, volume 5978 of Lecture Notes in
Computer Science, pages 308–326. Springer Berlin /
Heidelberg, 2010.
[20] J. Guajardo, S. S. Kumar, G.-J. Schrijen, and
P. Tuyls. FPGA intrinsic PUFs and their use for IP
protection. In Proceedings of the 9th Cryptographic
Hardware and Embedded Systems Workshop (CHES),
pages 63–80, 2007.
[21] J. Guajardo, S. S. Kumar, G.-J. Schrijen, and
P. Tuyls. Physical unclonable functions and public-key
crypto for FPGA IP protection. In International
Conference on Field Programmable Logic and
Applications, pages 189–195, 2007.
[22] M. Kirkpatrick and E. Bertino. Physically restricted
http://www.eccpage.com/, 2008.
[33] L. F. G. Sarmenta, M. van Dijk, C. W. O’Donnell,
J. Rhodes, and S. Devadas. Virtual monotonic
counters and count-limited objects using a tpm
without a trusted os. In STC ’06: Proceedings of the
ﬁrst ACM workshop on Scalable trusted computing,
pages 27–42, New York, NY, USA, 2006. ACM.
[34] G. E. Suh and S. Devadas. Physcal unclonable
functions for device authentication and secret key
generation. In Proceedings of the 44th IEEE Design
Automation Conference (DAC), pages 9–14. IEEE
Press, 2007.
[35] G. E. Suh, C. W. O’Donnell, and S. Devadas. AEGIS:
A single-chip secure processor. In Elsevier Information
Security Technical Report, volume 10, pages 63–73,
2005.
[36] G. E. Suh, C. W. O’Donnell, and S. Devadas. Aegis:
A single-chip secure processor. IEEE Design and Test
of Computers, 24(6):570–580, 2007.
[37] V. Sundaresan, S. Rammohan, and R. Vemuri.
Defense against side-channel power analysis attacks on
microelectronic systems. pages 144–150, Jul. 2008.