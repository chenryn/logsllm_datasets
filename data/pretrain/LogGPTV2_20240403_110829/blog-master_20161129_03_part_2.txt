如果说 map 提供了高度概括的总体的报告，那么 trace 就提供了最详细，最底层的细节报告。    
```  
  pipe-test-100k-13520 [001]  1254.354513808: sched_stat_wait:     
 task: pipe-test-100k:13521 wait: 5362 [ns]     
  pipe-test-100k-13520 [001]  1254.354514876: sched_switch:     
 task pipe-test-100k:13520 [120] (S) ==> pipe-test-100k:13521 [120]     
          :13521-13521 [001]  1254.354517927: sched_stat_runtime:     
 task: pipe-test-100k:13521 runtime: 5092 [ns], vruntime: 133967391150 [ns]     
          :13521-13521 [001]  1254.354518984: sched_stat_sleep:     
 task: pipe-test-100k:13520 sleep: 5092 [ns]     
          :13521-13521 [001]  1254.354520011: sched_wakeup:     
 task pipe-test-100k:13520 [120] success=1 [001]    
```  
要理解以上的信息，必须对调度器的源代码有一定了解，对一般用户而言，理解他们十分不易。幸好这些信息一般也只有编写调度器的人感兴趣。。。    
Perf replay 这个工具更是专门为调度器开发人员所设计，它试图重放 perf.data 文件中所记录的调度场景。很多情况下，一般用户假如发现调度器的奇怪行为，他们也无法准确说明发生该情形的场景，或者一些测试场景不容易再次重现，或者仅仅是出于“偷懒”的目的，使用 perf replay，perf 将模拟 perf.data 中的场景，无需开发人员花费很多的时间去重现过去，这尤其利于调试过程，因为需要一而再，再而三地重复新的修改是否能改善原始的调度场景所发现的问题。    
下面是 replay 执行的示例：    
```  
 $ perf sched replay     
 run measurement overhead: 3771 nsecs     
 sleep measurement overhead: 66617 nsecs     
 the run test took 999708 nsecs     
 the sleep test took 1097207 nsecs     
 nr_run_events:        200221     
 nr_sleep_events:      200235     
 nr_wakeup_events:     100130     
 task      0 (                perf:     13519), nr_events: 148     
 task      1 (                perf:     13520), nr_events: 200037     
 task      2 (      pipe-test-100k:     13521), nr_events: 300090     
 task      3 (         ksoftirqd/0:         4), nr_events: 8     
 task      4 (             swapper:         0), nr_events: 170     
 task      5 (     gnome-power-man:      3192), nr_events: 3     
 task      6 (     gdm-simple-gree:      3234), nr_events: 3     
 task      7 (                Xorg:      3122), nr_events: 5     
 task      8 (     hald-addon-stor:      2234), nr_events: 27     
 task      9 (               ata/0:       321), nr_events: 29     
 task     10 (           scsi_eh_4:       704), nr_events: 37     
 task     11 (            events/1:         8), nr_events: 3     
 task     12 (            events/0:         7), nr_events: 6     
 task     13 (           flush-8:0:      6980), nr_events: 20     
 ------------------------------------------------------------     
 #1  : 2038.157, ravg: 2038.16, cpu: 0.09 / 0.09     
 #2  : 2042.153, ravg: 2038.56, cpu: 0.11 / 0.09     
 ^C    
```  
## perf bench    
除了调度器之外，很多时候人们都需要衡量自己的工作对系统性能的影响。benchmark 是衡量性能的标准方法，对于同一个目标，如果能够有一个大家都承认的 benchmark，将非常有助于”提高内核性能”这项工作。    
目前，就我所知，perf bench 提供了 3 个 benchmark:    
1\. Sched message    
```  
[lm@ovispoly ~]$ perf bench sched messaging     
# Running sched/messaging benchmark...# 
20 sender and receiver processes per group# 
10 groups == 400 processes run 
Total time: 1.918 [sec]
sched message 
```  
是从经典的测试程序 hackbench 移植而来，用来衡量调度器的性能，overhead 以及可扩展性。该 benchmark 启动 N 个 reader/sender 进程或线程对，通过 IPC(socket 或者 pipe) 进行并发的读写。一般人们将 N 不断加大来衡量调度器的可扩展性。Sched message 的用法及用途和 hackbench 一样。    
2\. Sched Pipe    
```  
[lm@ovispoly ~]$ perf bench sched pipe    
# Running sched/pipe benchmark...# 
Extecuted 1000000 pipe operations between two tasks 
Total time: 20.888 [sec] 
20.888017 usecs/op 
47874 ops/secsched 
pipe 
```
从 Ingo Molnar 的 pipe-test-1m.c 移植而来。当初 Ingo 的原始程序是为了测试不同的调度器的性能和公平性的。其工作原理很简单，两个进程互相通过 pipe 拼命地发 1000000 个整数，进程 A 发给 B，同时 B 发给 A。。。因为 A 和 B 互相依赖，因此假如调度器不公平，对 A 比 B 好，那么 A 和 B 整体所需要的时间就会更长。    
3\. Mem memcpy    
```  
[lm@ovispoly ~]$ perf bench mem memcpy    
# Running mem/memcpy benchmark...# 
Copying 1MB Bytes from 0xb75bb008 to 0xb76bc008 ... 
364.697301 MB/Sec
```
这个是 perf bench 的作者 Hitoshi Mitake 自己写的一个执行 memcpy 的 benchmark。该测试衡量一个拷贝 1M 数据的 memcpy() 函数所花费的时间。我尚不明白该 benchmark 的使用场景。。。或许是一个例子，告诉人们如何利用 perf bench 框架开发更多的 benchmark 吧。    
这三个 benchmark 给我们展示了一个可能的未来：不同语言，不同肤色，来自不同背景的人们将来会采用同样的 benchmark，只要有一份 Linux 内核代码即可。    
## perf lock    
锁是内核同步的方法，一旦加了锁，其他准备加锁的内核执行路径就必须等待，降低了并行。因此对于锁进行专门分析应该是调优的一项重要工作。    
我运行 perf lock 后得到如下输出：    
```  
 Name acquired contended total wait (ns) max wait (ns) min     
 &md->map_lock 396 0 0 0     
 &(&mm->page_tabl... 309 0 0 0     
 &(&tty->buf.lock... 218 0 0 0     
 &ctx->lock 185 0 0 0     
 key 178 0 0 0     
 &ctx->lock 132 0 0 0     
 &tty->output_loc... 126 0 0 0     
。。。    
 &(&object->lock)... 1 0 0 0     
 &(&object->lock)... 0 0 0 0     
 &(&object->lock)... 0 0 0 0     
 &p->cred_guard_m... 0 0 0 0     
 === output for debug===     
 bad: 28, total: 664     
 bad rate: 4.216867 %     
 histogram of events caused bad sequence     
  acquire: 8     
  acquired: 0     
  contended: 0     
  release: 20    
```  
对该报表的一些解释如下：    
```  
“Name”: 锁的名字，比如 md->map_lock，即定义在 dm.c 结构 mapped_device 中的读写锁。    
“acquired”: 该锁被直接获得的次数，即没有其他内核路径拥有该锁的情况下得到该锁的次数。    
“contended”冲突的次数，即在准备获得该锁的时候已经被其他人所拥有的情况的出现次数。    
“total wait”：为了获得该锁，总共的等待时间。    
“max wait”：为了获得该锁，最大的等待时间。    
“min wait”：为了获得该锁，最小的等待时间。    
```  
目前 perf lock 还处于比较初级的阶段，我想在后续的内核版本中，还应该会有较大的变化，因此当您开始使用 perf lock 时，恐怕已经和本文这里描述的有所不同了。不过我又一次想说的是，命令语法和输出并不是最重要的，重要的是了解什么时候我们需要用这个工具，以及它能帮我们解决怎样的问题。    
## perf Kmem    
Perf Kmem 专门收集内核 slab 分配器的相关事件。比如内存分配，释放等。可以用来研究程序在哪里分配了大量内存，或者在什么地方产生碎片之类的和内存管理相关的问题。    
Perf kmem 和 perf lock 实际上都是 perf tracepoint 的特例，您也完全可以用 Perf record – e kmem:* 或者 perf record – e lock:* 来完成同样的功能。但重要的是，这些工具在内部对原始数据进行了汇总和分析，因而能够产生信息更加明确更加有用的统计报表。    
perf kmem 的输出结果如下：    
```  
 [root@ovispoly perf]# ./perf kmem --alloc -l 10 --caller stat     
 ---------------------------------------------------------------------------     
 Callsite       | Total_alloc/Per | Total_req/Per | Hit | Ping-pong| Frag     
 ---------------------------------------------------------------------------     
 perf_mmap+1a8 | 1024/1024 | 572/572|1 | 0 | 44.141%     
 seq_open+15| 12384/96 | 8772/68 |129 | 0 | 29.167%     
 do_maps_open+0| 1008/16 | 756/12 |63 | 0 | 25.000%     
 ...| ... | ...| ... | ... | ...     
 __split_vma+50| 88/88 | 88/88 | 1 | 0 | 0.000%     
 ---------------------------------------------------------------------------     
  Alloc Ptr | Total_alloc/Per | Total_req/Per | Hit |Ping-pong| Frag     
 ---------------------------------------------------------------------------     
 0xd15d4600|64/64 | 33/33  1 |  0 | 48.438%     
 0xc461e000|1024/1024 | 572/572 |1 | 0 | 44.141%     
 0xd15d44c0| 64/64 | 38/38 |1 | 0 | 40.625%     
 ... | ... | ... | ... | ... | ...     
 ---------------------------------------------------------------------------     
 SUMMARY     
 =======     
 Total bytes requested: 10487021     
 Total bytes allocated: 10730448     
 Total bytes wasted on internal fragmentation: 243427     
 Internal fragmentation: 2.268563%     
 Cross CPU allocations: 0/246458    
```  
该报告有三个部分：根据 Callsite 显示的部分，所谓 Callsite 即内核代码中调用 kmalloc 和 kfree 的地方。比如上图中的函数 perf_mmap，Hit 栏为 1，表示该函数在 record 期间一共调用了 kmalloc 一次，假如如第三行所示数字为 653，则表示函数 sock_alloc_send_pskb 共有 653 次调用 kmalloc 分配内存。    
对于第一行 Total_alloc/Per 显示为 1024/1024，第一个值 1024 表示函数 perf_mmap 总共分配的内存大小，Per 表示平均值。    
比较有趣的两个参数是 Ping-pong 和 Frag。Frag 比较容易理解，即内部碎片。虽然相对于 Buddy System，Slab 正是要解决内部碎片问题，但 slab 依然存在内部碎片，比如一个 cache 的大小为 1024，但需要分配的数据结构大小为 1022，那么有 2 个字节成为碎片。Frag 即碎片的比例。    
Ping-pong 是一种现象，在多 CPU 系统中，多个 CPU 共享的内存会出现”乒乓现象”。一个 CPU 分配内存，其他 CPU 可能访问该内存对象，也可能最终由另外一个 CPU 释放该内存对象。而在多 CPU 系统中，L1 cache 是 per CPU 的，CPU2 修改了内存，那么其他的 CPU 的 cache 都必须更新，这对于性能是一个损失。Perf kmem 在 kfree 事件中判断 CPU 号，如果和 kmalloc 时的不同，则视为一次 ping-pong，理想的情况下 ping-pone 越小越好。Ibm developerworks 上有一篇讲述 oprofile 的文章，其中关于 cache 的调优可以作为很好的参考资料。    
后面则有根据被调用地点的显示方式的部分。    
最后一个部分是汇总数据，显示总的分配的内存和碎片情况，Cross CPU allocation 即 ping-pong 的汇总。    
## Perf timechart    
很多 perf 命令都是为调试单个程序或者单个目的而设计。有些时候，性能问题并非由单个原因所引起，需要从各个角度一一查看。为此，人们常需要综合利用各种工具，比如 top,vmstat,oprofile 或者 perf。这非常麻烦。    
此外，前面介绍的所有工具都是基于命令行的，报告不够直观。更令人气馁的是，一些报告中的参数令人费解。所以人们更愿意拥有一个“傻瓜式”的工具。    
以上种种就是 perf timechart 的梦想，其灵感来源于 bootchart。采用“简单”的图形“一目了然”地揭示问题所在。    
加注了引号的原因是，perf timechart 虽然有了美观的图形输出，但对于新手，这个图形就好象高科技节目中播放的 DNA 图像一样，不明白那些坐在屏幕前的人是如何从密密麻麻的点和线中找到有用的信息的。但正如受过训练的科学家一样，经过一定的练习，相信您也一定能从下图中找到您想要的。    
### 图 1. perf timechart    
![pic](20161129_03_pic_001.jpg)      
人们说，只有黑白两色是一个人内心压抑的象征，Timechart 用不同的颜色代表不同的含义。上图的最上面一行是图例，告诉人们每种颜色所代表的含义。蓝色表示忙碌，红色表示 idle，灰色表示等待，等等。    
接下来是 per-cpu 信息，上图所示的系统中有两个处理器，可以看到在采样期间，两个处理器忙碌程度的概括。蓝色多的地方表示忙碌，因此上图告诉我们，CPU1 很忙，而 CPU2 很闲。    
再下面是 per-process 信息，每一个进程有一个 bar。上图中进程 bash 非常忙碌，而其他进程则大多数时间都在等待着什么。Perf 自己在开始的时候很忙，接下来便开始 wait 了。    
总之这张图告诉了我们一个系统的概况，但似乎不够详细？    