### Summary and Analysis of the Reasoning System Output

**Figure 5. Partial Output Trace from the Reasoning System Network (5)**
- The two pieces of evidence both indicate the compromise of the web server, increasing our confidence level to "certain."
- In total, there were 18 such proofs verifying that the two web servers were compromised.
- **Table 6** shows the reduction in the amount of data presented to the system administrator for further analysis.
- The raw alerts corresponding to the summarized internal condition can be identified using the mapping variable `obslist(Var)`.

**Validation of Raw Alerts**
- We manually validated the raw alerts of the 18 proofs generated by the reasoning engine for false positives.
- All the alerts were found to be plausible.
- The published TH dataset did not include a truth file, making it impossible to determine if the reasoning engine missed any true attack traces (false negatives).

### Experiment on Data Collected from a Honeypot

- **Data Source**: A honeypot deployed at Purdue University, primarily intended to collect spam relayed through open proxies.
- **Data Collection**: Network traffic was captured over a two-month period, resulting in approximately 68GB of zipped TCPdump files.
- **Analysis**: The reasoning engine concluded that the honeypot host was compromised. We manually validated the traces with knowledge of the operating system and services running on the honeypot host.

### Experiments on a Production System

- **Context**: SnIPS with an updated knowledge base was applied to a university network with 300 workstations and various servers.
- **Data Analysis**: Over three days, Snort reported about 1.1 million alerts with 150 different alert types and 15 class types.
- **Results**: 
  - 17 high-confidence proofs indicated that 4 hosts had a higher chance of being compromised.
  - Further analysis of other log data, which we did not have access to, would be required to verify these results.
  - Our tool helped reduce the search space and time spent on intrusion analysis by filtering out likely false positives.

### Reduction of Alerts to High-Confidence Proofs

| Data Set   | Snort Alerts | Summarized Alerts | High-Confidence Proofs |
|------------|--------------|-------------------|------------------------|
| TH         | 4,849,937    | 278               | 18                     |
| Honeypot   | 637,564      | 30                | 8                      |
| Department | 1,138,572    | 6,634             | 17                     |

**Figure 6. Reduction of Alerts to High-Confidence Proofs**

### Related Work

**Uncertainty in Security Analysis**
- Probabilistic reasoning is a natural candidate for handling uncertainty, but obtaining the necessary logical structure and statistical parameters is challenging.
- Estimating or learning from real-life data is difficult due to background noise.
- Calibration of analysis techniques with metrics like false positive/negative ratios is a significant challenge.
- Our approach approximates human reasoning with a qualitative assessment on a few confidence levels, bypassing some fundamental problems.

**Closely Related Work: BotHunter**
- BotHunter [21] identifies bot machines by correlating Snort alerts with other system-monitoring events.
- It uses "confidence score" and "evidence threshold" to capture uncertainty.
- Our goal is to provide a simple but more general model for intrusion analysis.

**Suspicion in Intrusion Analysis**
- Hollebeek and Waltzman [22] proposed a notion of "suspicion" in modeling uncertainty.
- Their approach lacks differentiation of meanings associated with a "suspicious" event.
- Our observation correspondence model assigns direct meaning to observations and allows flexible linking based on semantics.

**Intrusion Alert Correlation**
- Many works model IDS-specific states using pre- and post-conditions, but this approach is limited for ubiquitous alerts.
- Our model includes data reduction based on clustering and simple correlation of local observations, drawing on previous research [5], [8].

### Conclusion

- We presented an empirical approach to modeling uncertainty in intrusion analysis, aiding system administrators in reaching quick conclusions about possible intrusions.
- The model language has two components: observation correspondence and internal model.
- The reasoning system handles uncertainty and finds high-confidence attack traces from low-level monitoring data.
- Experiments show that the model developed from one dataset is effective for analyzing different datasets with minimal effort, indicating its practicality for enterprise networks.

### Acknowledgment

- This work was partially supported by the U.S. National Science Foundation under Grant No. 0716665.
- We thank Abhinav Pathak from Purdue for providing the Honeypot data for evaluation.

### References

[References listed as in the original text]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the essential content and structure of the original text.