(1)
In this paper, we use a “1-/5+” criterion for labeling a
given ﬁle as malicious or benign: if a ﬁle has one or fewer
vendors reporting it as malicious, we label the ﬁle as ‘be-
nign’ and use a weight of 1.0 for the malware loss for that
sample. Similarly, if a sample has ﬁve or more vendors re-
porting it as malicious, we label the ﬁle as ‘malicious’ and
use a weight of 1.0 for the malware loss for that sample.
3.2 Vendor Count Loss
To more ﬁnely distinguish between positive results, we in-
vestigate the use of the total number of ‘malicious’ reports
for a given sample from the vendor aggregation service as
an additional target; the rationale being that a sample with a
higher number of malicious vendor reports should, all things
being equal, be more likely to be malicious. In order to prop-
erly model this target, we require a suitable noise model for
count data. A popular candidate is a Poisson noise model,
parameterized by a single parameter µ, which assumes that
counts follow a Poisson process, where µ is the mean and
variance of the Poisson distribution. The probability of an
observation of y counts conditional on µ is
P(y|µ) = µye−µ /y!.
(2)
In our problem, as we expect the mean number of posi-
tive results for a given sample to be related to the ﬁle it-
self, we attempt to learn to estimate µ conditional on each
sample x(i) in such a way that the likelihood of y(i)|µ (i) is
maximized (or, equivalently, the negative log-likelihood is
minimized). Denote the output of the neural network with
which we are attempting to estimate the mean count of ven-
dor positives for sample i as fcnt(x(i)). Note that under a
non-distributional loss, this would be denoted by ˆy(i), how-
ever since we are ﬁtting a parameter of a distribution, and
not the sample label y directly, we use different notation in
this section. By taking some appropriate activation function
a(·) that maps fcnt(x(i)) to the non-negative real numbers, we
can write µ (i) = a
. Consistent with generalized
linear model (GLM) literature [18], we use an exponential
activation for a, though one could equally well employ some
other transformation with the correct output range, for in-
stance the ReLU function.
fcnt(x(i))
Letting y(i) here denote the actual number of vendors that
recognized sample x(i) as malicious, the corresponding neg-
ative log-likelihood loss over the dataset is
(cid:16)
(cid:17)
306    28th USENIX Security Symposium
USENIX Association
(cid:16)
(cid:16)
a
(cid:96)p
(cid:17)
fcnt(x(i))
,y(i)(cid:17)
µ (i) − y(i) log(µ (i)) + log(y(i)!),
(3)
Lp(X,Y ) =
=
1
M
1
M
M
∑
i=1
M
∑
i=1
which we will refer to as the Poisson or vendor count loss.
In practice, we ignore the log(y(i)!) term when minimizing
this loss since it does not depend on the parameters of the
network.
A Poisson loss is more intuitive for dealing with count
data than other common loss functions, even for count data
not generated by a Poisson process. This is partly due to the
discrete nature of the distribution and partly because the as-
sumption of increased variance with predicted mean is more
accurate than a homoscedastic – i.e., constant variance –
noise model.
While the assumption of increasing variance with pre-
dicted count value seems reasonable, it is very unlikely that
vendor counts perfectly follow a Poisson process – where
the mean is the variance – due to correlations between ven-
dors, which might occur from modeling choice and licens-
ing/OEM between vendor products. The variance might in-
crease at a higher or lower rate than the count and might not
even be directly proportional to or increase monotonically
with the count. Therefore, we also implemented a Restricted
Generalized Poisson distribution [10] – a slightly more intri-
cate noise model that accommodates dispersion in the vari-
ance of vendor counts. Given dispersion parameter α, the
Restricted Generalized Poisson distribution has a probability
mass function (pmf):
(cid:18) µ
(cid:19)y
(cid:18)−µ(1 + αy)
(cid:19)
P(y|α, µ) =
(1+αy)y−1 exp
1 + αµ
1 + αµ
/y!.
(4)
When α = 0, this reduces to Eq. 2. α > 0 accounts for
over-dispersion, while α < 0 accounts for under-dispersion.
Note that in our use case α, like µ, is estimated by the neu-
ral network and conditioned on the feature vector, allowing
varying dispersion per-sample. Given the density function in
Eq. 4, the resultant log-likelihood loss for a dataset with M
samples is deﬁned as:
Lgp(X,Y ) = − 1
M
M
∑
i=1
(cid:20)
y(i)(cid:0)log µ (i) − log(1 + α (i)µ (i))(cid:1)
(cid:21)
+ (y(i) − 1)log(1 + α (i)y(i))
− µ (i)(1 + α (i)y(i))
+ log(y(i)!)
1 + α (i)µ (i)
, (5)
where α (i) and µ (i) are obtained as transformed outputs of
the neural network in a similar fashion as we obtain µ (i) for
In practice, as for the Poisson loss, we
the Poisson loss.
dropped the term related to y! since it does not affect the
optimization of the network parameters.
Note also that restrictions must be placed on the negative
value of the α (i) term to keep the arguments of the logarithm
positive. For numerical convenience, we used an exponential
activation over the dense layer for our α (i) estimator, which
accommodates over-dispersion but not under-dispersion. Re-
sults from experiments comparing the use of Poisson and
Generalized Poisson auxiliary losses are presented in Sec-
tion 4.1.
While the Poisson distribution is a widely used model for
count data, other discrete probability distributions could also
be used to model the count of vendor positive results. Dur-
ing early experimentation we also examined the binomial,
geometric, and negative binomial distributions as models for
vendor counts, but found that they produced unsatisfactory
results and so do not discuss them further.
3.3 Per-Vendor Malware Loss
The aggregation service from which we collected our data
sets contains a breakout of individual vendor results per sam-
ple. We identiﬁed a subset V = {v1, . . . ,vV} of 9 vendors
that each produced a result for (nearly) every sample in our
data. Each vendor result was added as a target in addition to
the malware target by adding an extra fully connected layer
per vendor followed by a sigmoid activation function to the
end of the shared architecture. We employed a binary cross-
entropy loss per vendor during training. Note that this differs
from the vendor count loss presented above in that each high-
coverage vendor is used as an individual binary target, rather
than being aggregated into a count. The aggregate vendors
loss Lvdr for the V = 9 selected vendors is simply the sum of
the individual vendor losses:
(cid:16)
(cid:0)x(i)(cid:1),y(i)
v j
(cid:17)
fvdr j
Lvdr(X,Y ) =
M
∑
i=1
1
M
= − 1
M
V
∑
(cid:96)vdr
j=1
M
V
∑
i=1
∑
j=1
v j log( ˆy(i)
y(i)
v j ) + (1− y(i)
v j )log(1− ˆy(i)
v j ),
(6)
(cid:0)x(i)(cid:1) = ˆy(i)
where (cid:96)vdr is the per-sample binary cross-entropy function
and fvdr j
is the output of the network that is
trained to predict the label y(i)
v j assigned by vendor j to in-
put sample x(i).
v j
Results from experiments exploring the use of individual
vendor targets in addition to malware label targets are pre-
sented in Section 4.2.
USENIX Association
28th USENIX Security Symposium    307
3.4 Malicious Tags Loss
In this experiment we attempt exploit information contained
in family detection names provided by different vendors in
the form of malicious tags. We deﬁne each tag as a high level
description of the purpose of a given malicious sample. The
tags used as auxiliary targets in our experiments are: ﬂooder,
downloader, dropper, ransomware, crypto-miner, worm, ad-
ware, spyware, packed, ﬁle-infector, and installer.
We create these tags from a parse of individual vendor
detection names, using a set of 10 vendors which from
our experience provide high quality detection names. Once
we have extracted the most common tokens, we ﬁlter them
to keep only tokens related to well-known malware family
names or tokens that could easily be associated with one or
more of our tags, for example, the token xmrig – even though
it is not a malware family – can be recognized as referring to
a crypto-currency mining software and therefore can be asso-
ciated with the crytpo-miner tag. We then create a mapping
from tokens to tags based on prior knowledge. We label a
sample as associated with tag ti if any of the tokens associ-
ated with ti are present in any of the detection names assigned
to the sample by the set of trusted vendors.
Annotating our dataset with these tags, allows us to de-
ﬁne the tag prediction task as multi-label binary classiﬁca-
tion, since zero or more tags from the set of possible tags
T = {t1, . . . ,tT} can be present at the same time for a given
sample. We introduce this prediction task in order to have
targets in our loss function that are not not directly related
to the number of vendors that recognize the sample as ma-
licious. The vendor counts and the individual vendor labels
are closely related with the deﬁnition of our main target, i.e.
the malicious label, which classiﬁes a sample as malicious if
5 or more vendors identify the sample as malware (see Sec-
tion 3.1). In the case of the tag targets, this information is
not present. For instance, if all the vendors recognize a given
sample as coming from the WannaCry family in their detec-
tion names, the sample will be associated only once with the
ransomware tag. On the converse, because of our tagging
mechanism, if only one vendor considers that a given sam-
ple is malicious and classiﬁes it as coming from the Wan-
naCry family, the ransomware tag will be present (although
our malicious label will be 0).
In order to predict these tags, we use a multi-headed archi-
tecture in which we add two additional layers per tag to the
end of the shared base architecture, a fully connected layer
of size 512-to-256, followed by a fully connected layer of
size 256-to-1, followed by a sigmoid activation function, as
shown in Figure 1. Each tag t j out of the possible T = 11 tags
has its own loss term computed with binary cross-entropy.
Like the per-vendor malware loss, the aggregate tag loss is
the sum of the individual tag losses. For the dataset with M
samples it becomes:
Ltag(X,Y ) =
M
∑
i=1
1
M
= − 1
M
j=1
M
T
∑
i=1
∑
j=1
(cid:16)
(cid:0)x(i)(cid:1),y(i)
t j
(cid:17)
ftag j
T
∑
(cid:96)tag
y(i)
t j log( ˆy(i)
t j ) + (1− y(i)
t j )log(1− ˆy(i)
t j ),
(7)
indicates if sample i is annotated with tag j, and
(cid:0)x(i)(cid:1) is the prediction issued by the network for
where y(i)
t j
ˆy(i)
t j = ftag j
that value.
3.5 Sample Weights
While our multi-objective network has the advantage that
multiple labels and loss functions serve as additional sources
of information, this introduces an additional complexity:
given many (potentially missing) labels for each sample, we
cannot rely on having all labels for a large quantity of the
samples. Moreover, this problem gets worse as more la-
bels are added. To address this, we incorporated per-sample
weights, depending on the presence and absence of each la-
bel. For labels that are missing, we assign them to a default
value and then set the associated weights to zero in the loss
computation so a sample with a missing target label will not
add to the loss computation for that target. Though this in-
troduces slight implementation overhead, it allows us to train
our network, even in the presence of partially labeled sam-
ples (e.g., when a vendor decides not to answer).
intelligence feed:
3.6 Dataset
We collected two datasets of PE ﬁles and associated meta-
data from a threat
a set for train-
ing/validation and a test set. For the training/validation
set, we pulled 20M PE ﬁles and associated metadata, ran-
domly sub-selecting over a year – from September 6, 2017
to September 6, 2018. For the test set, we pulled ﬁles from
October 6, 2018 to December 6, 2018. Note also that we
indexed ﬁles based on unique SHA for ﬁrst seen time, so ev-
ery PE in the test set comes temporally after the ones in the
training set. We do not use a randomized cross-validation
training/test split as is common in other ﬁelds, because that
would allow the set on which the classiﬁer was trained to
contain ﬁles “from the future”, leading to spuriously opti-
mistic results. The reason for the one month gap between the
end of the training/validation set and the start of the test set is
to simulate a realistic worst-case deployment scenario where
the detection model of interest is updated on a monthly basis.
All ﬁles used in the following experiments – both malicious
and benign – were obtained from the threat intelligence feed.
We then extracted 1024-element feature vectors for all
those ﬁles using feature type described in [25] and derived
308    28th USENIX Security Symposium
USENIX Association
an aggregate malicious/benign label using a 1-/5+ criterion
as described above. Invalid PE ﬁles were discarded.
Of the valid PE ﬁles from which we were able to ex-
tract features we further subsampled our training dataset to
9,000,000 training samples, with 7,188,150 (79.87%) ma-
licious and 1,587,035 (17.63%) benign. The remaining
224,815 (2.5%) are gray samples, without a benign or ma-
licious label, i.e., samples where the total number of vendor
detections is between 2 and 4 and thus do not meet our 1-/5+
labeling criterion. Our validation set was also randomly sub-
sampled from the same period as the training data and used to
monitor convergence during training. It consisted of 100,000
samples; of these, 17,620 were benign (17.62%), 79,819
were malicious (79.82%) , and 2,561 were gray (2.56%).
Our test set exhibited similar statistics, with 7,656,573 to-
tal samples, 1,606,787 benign (21.8%), 5,762,064 malicious