work has primarily studied hardware security keys. In a lab
study with 94 participants, Lyastani et al. [32] studied user per-
ceptions of using FIDO2-compatible hardware security keys
as a single factor for authentication. Participants were ran-
domly assigned to register and sign into a website with either
a security key or a site-speciﬁc password. Participants gen-
erally preferred the security key over traditional passwords,
but identiﬁed limitations. They had concerns about several
hardware issues, such as access on computers without USB
ports. They also desired the ability to recover and revoke ac-
cess if the security key was lost. Unsurprisingly, participants’
mental models of FIDO2 lacked the natural understanding of
traditional passwords.
In a ﬁeld setting, Farke et al. [18] observed the authentica-
tion routines of 10 employees in a small software company.
Employees were given the choice between using a FIDO2-
compatible security key and a traditional password to log in.
Over four weeks, several employees stopped using the key as
its security beneﬁts were perceived as unnecessary and it was
slower than using their browser’s password manager.
Oogami et al. [40] had 10 participants use biometric Web-
Authn to register their Android phones with their existing
Yahoo! Japan accounts. Some participants were confused by
the user interface, mistakenly pressing the ﬁngerprint icon
on screen rather than the actual ﬁngerprint sensor. While
their results highlighted some usability issues with biometric
WebAuthn, their small sample limited generalizability.
Independent of the use of biometrics, FIDO2 and Web-
Authn have usability drawbacks [2, 33, 41, 42, 54]. The in-
ability to transfer private keys across devices requires users
to register multiple times (e.g., on both a phone and laptop).
There is no secure fallback if authenticators are lost or broken,
shifting the problem from primary to fallback authentication.
There is also no security beneﬁt if insecure methods, like a
password, remain valid even after FIDO2 is enabled.
2.3 Misconceptions About Biometrics
While we are among the ﬁrst to study the use of biometrics
within FIDO2 and WebAuthn, prior work has investigated
users’ mental models of biometric authentication in other
USENIX Association
30th USENIX Security Symposium    93
In this section, we highlight (and number) key
contexts.
misconceptions identiﬁed in prior work. We investigate these
potential misconceptions, among others, in our user studies.
Speciﬁcally, several user studies have investigated miscon-
ceptions about using biometrics to unlock smartphones [9,
12, 34, 36, 57]. In a survey of smartphone users, De Luca
et al. [14] found that usability was one of the major factors
for choosing biometrics to unlock mobile devices. Apple’s
Touch ID was considered as 1(cid:13) easy and fast as the normal
slide to unlock. Interestingly, security and privacy concerns
did not play a large role in decisions about adopting biomet-
ric unlocking. Bhagavatula et al. [7] also found usability
to be crucial to user acceptance. They reported misconcep-
tions about the 2(cid:13) storage location, with a few participants
thinking that biometrics were sent over the network or to
the cloud even when unlocking the phone. Revisiting this
misconception is a focus of our study because we expected
misconceptions that websites process a user’s biometric itself
to heavily inﬂuence perceptions. Participants considered bio-
metric authentication 3(cid:13) more secure than PINs, not realizing
that PINs remained enabled as fallback authentication. Many
participants were unaware of security risks like 4(cid:13) spooﬁng.
To delve further into misconceptions about biometric phone
unlocking, Wolf et al. [63] conducted semi-structured inter-
views. Based on misconceptions about 5(cid:13) biometrics being
processed (whether the data stored enables reconstruction
of a user’s face/ﬁngerprint), both experts and non-experts
expressed concerns about biometric data being 6(cid:13) accessed
by third parties. They also highlighted misunderstandings
around using 7(cid:13) multiple devices, 8(cid:13) delegating access to
others, and 9(cid:13) availability due to wet/oily ﬁngers.
2.4 Notiﬁcation Design
A large body of prior work evaluated and improved warn-
ing messages and notiﬁcations, including browser warnings
in general [1, 6, 8, 28], as well as warnings about phish-
ing [15, 16, 46], malware [3], and PDF downloads [29]. Early
work by Egelman et al. [15] studied the effectiveness of phish-
ing warnings. They found that the warnings were ineffective
overall, with high click-through rates. They recommended
clear action instructions, making them more distinguishable
from less severe warnings to prevent habituation, and to make
them blocking, full-screen, active warnings. The most ex-
tensive set of work studied TLS warnings [6, 21, 52, 53]. To
improve the adherence of warnings, the use of opinionated
design proved to be effective in a study by Felt et al. [21].
Egelman et al. [16] showed how small design changes can
increase the time users spend looking at a notiﬁcation. More
recently, Reeder et al. [50] conducted a survey on browser
warnings in situ with Google Chrome and Mozilla Firefox
users. They did not ﬁnd major issues in modern browser
warnings, concluding that future improvements only need to
be made on smaller, contextual misunderstandings. These
real-world improvements show the value and importance of re-
search on designing effective notiﬁcations. The best practices
for communicating about security identiﬁed in this literature
informed the design of our notiﬁcations. However, our notiﬁ-
cations do not aim to warn or stop users, but instead aim to
correct misconceptions to spur the adoption of WebAuthn.
2.5 Participatory Design and Focus Groups
Warning designers have commonly applied heuristics or
expert views during the development and improvement pro-
cess [21, 46, 56]. For the design of the notiﬁcations in this
work, we use focus groups and apply a participatory de-
sign (PD) approach. PD describes a technique where prospec-
tive users are actively involved in the development and design
process of new products or interfaces. End users can con-
tribute valuable insights about issues experts are unaware of
by challenging implicit assumptions and preconceptions the
experts might have [39]. Within security and privacy, Weber
et al. [60] applied PD to develop new TLS warning messages.
They described the approach as “suitable and versatile” for
interface design in the security domain. Their participants
stated that existing notiﬁcations were too long, complicated,
technical, and that they would prefer warnings that are short,
focus on recommended actions, and use more concrete and
alarming language, which falls in line with prior research
on warning design [6]. Research by Redmiles et al. [49] is
closest to our approach since they also studied notiﬁcations
that aim to encourage adoption. Their PD sessions with de-
mographically diverse users revealed that using personalized
headlines, bullet points, and the color blue can increase 2FA
adoption. Contrary to prior work, their participants chose
to avoid graphics since they found those less professional.
Gorski et al. [25] used PD to target professional developers to
improve security-related console warnings. They found that
design recommendations that apply to end users do not neces-
sarily align with experts’ wishes. Althobaiti et al. [4] worked
with focus groups on improving the usability of phishing re-
ports [4]. McNally et al. [35] applied PD with children to
improve and extend the functionalities of mobile child protec-
tive apps. Chouhan et al. [10] used PD to design a smartphone
app that allows collaborative decision-making for privacy and
security. To elicit mental models of HTTPS, Krombholz et
al. [30] used a drawing task, a technique we also use.
3 Study 1: Online Study of Misconceptions
The goal of this study was to understand what misconcep-
tions users might have about using biometric WebAuthn. In
this two-part study, participants registered and authenticated
at a website we created, ExampleTech, using their personal
mobile device. Our implementation is based on Spomky-
Labs’ PHP WebAuthn Framework [38]. We modiﬁed the
94    30th USENIX Security Symposium
USENIX Association
(b) Notiﬁcation.
Figure 2: An overview of the structure of Study 1 (L), as well as the intentionally vague baseline notiﬁcation (R) we used.
(a) Study 1 procedure.
account registration steps and WebAuthn settings such that
only platform authenticators were allowed, user veriﬁcation
was required, and timeout occurred after 60 seconds. Our
code is available on GitHub.1 Note that we used the same
WebAuthn implementation for Study 3 (Section 5).
3.1 Method
Figure 2a depicts the overall study ﬂow. Participants were
recruited via Proliﬁc for a study with two parts, registration
and authentication, conducted a week apart. We required
participants be age 18+, live in the US or UK, and have a
95%+ approval rating. We required that participants have an
Android phone (running Android 7+), Google Chrome, and
biometric phone unlocking conﬁgured and enabled. FIDO2
fully supports this conﬁguration [20] and it reﬂects the devices
and software supporting WebAuthn at the time we conducted
our study. All our study protocols were approved by the Uni-
versity of Chicago Institutional Review Board (IRB). We paid
participants $5 for each of the two phases of the study.
Registration Phase: Participants ﬁrst created an account
on the ExampleTech website. The main goal of Study 1 was
to establish a baseline for misconceptions and opinions about
WebAuthn. We were interested in participants’ opinions about
WebAuthn’s pros and cons overall, as well as relative to pass-
words. Thus, we crafted an intentionally vague baseline
notiﬁcation that informed participants, “Depending on your
device, you can sign in with your ﬁngerprint, face, or iris.”
This was based on real-world notiﬁcations (cf. Figure 2b).
After showing this notiﬁcation, we simulated a sign-up page
by asking participants to provide their age and gender. When
participants pressed “register,” the WebAuthn protocol be-
gan, launching an OS-speciﬁc WebAuthn instruction screen.
At this point, the user locally authenticated on their phone
(e. g., with their ﬁngerprint or fallback mechanism, such as a
PIN). The wording and graphics on the WebAuthn instruction
screen varies across vendors. Figure 1b shows an example for
a Google Pixel 3a device running Android 11 with a PIN as a
fallback. Our instructions requested participants authenticate
using a biometric, not a PIN, pattern, or password.
If the participant successfully authenticated, their account
was created and they were redirected to complete the reg-
istration survey.
If they failed to create an account, they
completed an alternate survey aiming to understand why the
failure occurred. The registration survey began with questions
about the participant’s use of biometrics both in registering
on ExampleTech and in unlocking their phone. Participants
also responded to the System Usability Scale (SUS) about
using WebAuthn to register for ExampleTech. To gauge par-
ticipants’ mental models about WebAuthn and the technology
it replaces (passwords), we then asked participants to describe
how they believed WebAuthn and passwords worked behind
the scenes. We also asked speciﬁc questions about where
their authentication data (e. g., biometric or password) or data
derived from it is stored. We hypothesized misconceptions
about where biometrics are stored, and with whom they are
shared, might heavily inﬂuence opinions about WebAuthn.
The next section solicited a series of multiple-choice re-
sponses using Likert scales and free-text justiﬁcations related
to additional potential misconceptions surrounding security
and usability when registering an account for a website us-
ing WebAuthn. We developed this series of questions about
misconceptions through iterative piloting to investigate the
relevant misconceptions observed in prior user studies about
biometric authentication outside the WebAuthn context (cf.
Section 2.3). The survey ended with demographic questions.
Piloting: We developed our questions based on previously
documented misconceptions about biometrics, WebAuthn,
and 2FA. We focused on misconceptions that were relevant
in the biometric WebAuthn context (cf. Section 2). Since
our main goal was to document users’ initial expectations
and potential misconceptions when interacting with biometric
WebAuthn, participants were not expected to have any prior
knowledge of WebAuthn, nor expected to have any techni-
cal knowledge. Therefore, to minimize biased, confusing,
or technical wording, we conducted formal think-aloud cog-
nitive pilot interviews with three domain experts and four
non-technical pilot participants. Based on responses from the
pilots, we iteratively reﬁned the survey wording and ﬂow.
Authentication Phase: The authentication phase followed
a similar procedure. Participants were asked to sign into
the ExampleTech website with the account they had created
previously. Participants who were not able to create an ac-
count in the previous week were not invited to complete this
follow-up session. The one-week waiting period was intended
to minimize the effect of account creation on the login pro-
cess. Typically, users log in more frequently than they create
accounts, so it was important to explore both separately.
USENIX Association
30th USENIX Security Symposium    95
1 weeklaterInviteEmailBiometricBaselineNotificationReg. SurveyBiometric Usage, Usability,Misconceptions, DemographicsWebAuthnInformedConsentBiometricAuth. SurveySecurity Perception,Preference, Usability,SeBISWebAuthnRegistrationAuthenticationOnce participants had signed in, they were asked a set of
questions regarding possible misconceptions with the login.
If they failed to log into their account, they were given two
more attempts. After this, they were redirected to an alternate
survey aiming to understand why the failure occurred.
Survey questions were developed similarly to the registra-
tion phase. The authentication-phase survey asked partici-
pants more direct questions about their opinions regarding the
use of biometric WebAuthn. These questions were asked at
the end of the authentication phase to avoid priming partici-
pants when they were responding to questions that aimed to
understand their initial expectations.
We also provided a help page with a note that they needed
to use the same device as they used for account registration. If
participants tried to use a device or browser that was not An-
droid or Google Chrome, they were automatically redirected
to this help page, where we also provided an option to exit
the study early with partial compensation.
3.2 Participants
We recruited 50 participants, 42 of whom registered success-
fully. 41 registered with their ﬁngerprint, and one with their