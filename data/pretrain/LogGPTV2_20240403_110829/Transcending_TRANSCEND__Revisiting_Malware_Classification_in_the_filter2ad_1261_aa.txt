title:Transcending TRANSCEND: Revisiting Malware Classification in the
Presence of Concept Drift
author:Federico Barbero and
Feargus Pendlebury and
Fabio Pierazzi and
Lorenzo Cavallaro
9
5
6
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
Transcending TRANSCEND: Revisiting Malware
Classiﬁcation in the Presence of Concept Drift
Federico Barbero∗†(cid:107), Feargus Pendlebury∗‡§¶, Fabio Pierazzi†, Lorenzo Cavallaro¶
† King’s College London, ‡ Royal Holloway, University of London, § The Alan Turing Institute,
(cid:107) University of Cambridge, ¶ University College London
Abstract—Machine learning for malware classiﬁcation shows
encouraging results, but real deployments suffer from perfor-
mance degradation as malware authors adapt their techniques to
evade detection. This phenomenon, known as concept drift, occurs
as new malware examples evolve and become less and less like the
original training examples. One promising method to cope with
concept drift is classiﬁcation with rejection in which examples
that are likely to be misclassiﬁed are instead quarantined until
they can be expertly analyzed.
We propose TRANSCENDENT, a rejection framework built on
Transcend, a recently proposed strategy based on conformal
prediction theory. In particular, we provide a formal treatment of
Transcend, enabling us to reﬁne conformal evaluation theory—its
underlying statistical engine—and gain a better understanding
of the theoretical reasons for its effectiveness. In the process,
we develop two additional conformal evaluators that match
or surpass the performance of the original while signiﬁcantly
decreasing the computational overhead. We evaluate TRANSCEN-
DENT on a malware dataset spanning 5 years that removes
sources of experimental bias present in the original evaluation.
TRANSCENDENT outperforms state-of-the-art approaches while
generalizing across different malware domains and classiﬁers.
To further assist practitioners, we showcase optimal opera-
tional settings for a TRANSCENDENT deployment and show how
it can be applied to many popular learning algorithms. These
insights support both old and new empirical ﬁndings, making
Transcend a sound and practical solution for the ﬁrst time. To
this end, we release TRANSCENDENT as open source, to aid the
adoption of rejection strategies by the security community.
Index Terms—security, machine learning, malware detection
I. INTRODUCTION
Machine learning (ML) algorithms have displayed superhu-
man performance across a wide range of classiﬁcation tasks
such as computer vision [23] and natural language process-
ing [17]. However, a great deal of this success is conditional
on one central assumption: that the training and test data are
drawn identically and independently from the same underlying
distribution (i.i.d.) [12].
In a security setting this assumption often does not hold.
In particular, malware classiﬁers are deployed in dynamic,
hostile environments [34]. New paradigms of malware evolve
to pursue proﬁts, new variants arise as novel exploits are
discovered, and adversaries switch behavior suddenly and
dramatically when faced with strengthened defenses. This
causes the incoming test distribution to diverge from the
original training distribution, a phenomenon known as concept
∗Equal contribution.
drift [28]. Over time, classiﬁer performance begins to degrade
as the model fails to classify the new objects correctly.
There appear to be two broad approaches to tackling concept
drift. The ﬁrst is to design systems which are intrinsically
more resilient
to drift by developing more robust feature
spaces. For example, it has recently been suggested that neural
networks may be more resilient to concept drift as the latent
feature space better generalizes to new variants [35]. However,
designing robust feature spaces is an open research question
and it is not clear if there exists such a malware representation
for which concept drift will not occur.
A second solution is to adapt to the drift, for example
by updating the model using incremental retraining or online
learning [30, 50], or rejecting drifting points. However, to be
effective, decisions about when and how to take action on
aging classiﬁers must be taken quickly and decisively. To do
so, accurate detection and quantiﬁcation of drift is vital.
This problem is precisely the focus of Transcend [20],
a statistical
framework that builds on conformal predic-
tion theory [47] to detect aging malware detectors during
deployment—before their accuracy deteriorates to unaccept-
able levels. Transcend [20] proposes a conformal evaluator
that utilizes the notion of nonconformity to identify and reject
new examples that differ from the training distribution and
are likely to be misclassiﬁed; the corresponding apps can
then be quarantined for further analysis and labeling. While
effective, the original proposal suffers from experimental bias,
is extremely resource intensive and thus impractical, lacks
experiments to support generalization claims, fails to provide
guidance on how to integrate it
into a detection pipeline
and, perhaps more importantly, lacks a theoretical analysis to
explain its effectiveness.
In this paper, we revisit conformal evaluator and Transcend
to root its internal workings in sound theory and determine its
most effective operational settings. We additionally propose
TRANSCENDENT, a framework that surpasses the performance
of the original in terms of drift detection and computational
overhead, making it a sound and practical solution.
In summary, we make the following contributions:
• Formal Treatment. We investigate the theory underpin-
ning the motivation and intuition of conformal evaluation
to provide a missing link between conformal evaluation
and conformal prediction theory that explains its effec-
tiveness and supports the empirical evaluations presented
in both this work and the original (§III).
© 2022, Federico Barbero. Under license to IEEE.
DOI 10.1109/SP46214.2022.00068
805
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:22:16 UTC from IEEE Xplore.  Restrictions apply. 
• Novel Conformal Evaluators. Building on this insight,
we develop two novel conformal evaluators: inductive
conformal evaluator (ICE) (§IV-B) and cross-conformal
evaluator (CCE) (§IV-C), both of which are ﬁrmly
grounded in conformal prediction theory and able to
effectively identify and reject drifting examples while
being signiﬁcantly less computationally demanding than
the original. We formalize Transcend’s calibration proce-
dure as an optimization problem and propose an improved
search strategy for ﬁnding thresholds (§V).
• Operational Guidance. We evaluate our proposals on
a dataset spanning 5 years (2014–2019) that eliminates
sources of bias present in past evaluations (§VI). We
compare different operational settings, including the ef-
fects of including algorithm conﬁdence (§VI-C) and of
using different search strategies (§VI-D) during thresh-
olding. Our methods outperform existing state-of-the-art
approaches (§VI-E), and generalize well across different
malware domains and underlying classiﬁers (§VI-F). To
aid practitioners in adopting rejection strategies, we in-
clude a discussion of how to integrate TRANSCENDENT
into a typical security detection pipeline (§VII).
To enable researchers and practitioners to make better use
of classiﬁcation with rejection strategies, we publicly release
our data and implementation of TRANSCENDENT.1
II. BACKGROUND
We focus on classiﬁcation for security tasks (§II-A) which
are affected by concept drift (§II-B). In particular, we are
interested in improving the state-of-the-art approaches for
classiﬁcation with rejection (§II-C).
A. Machine Learning and Security Detection
Machine learning is a set of statistical methods for automat-
ing data analysis and enabling systems to perform tasks on
the data without being explicitly programmed for them. In
the malware domain, typical tasks include binary classiﬁcation
(detecting malicious examples [6, 50]) and multiclass classiﬁ-
cation (predicting the malware family [16, 42, 43]) but can also
extend to more complex tasks such as predicting how many
AV engines would detect an example [22], inferring Android
malware app permissions based on their icons [49], or gener-
ating Windows malware using reinforcement learning [4].
In this paper we focus on classiﬁcation tasks where a
classiﬁer g aims to learn a function mapping X → Y, where
X ⊆ Rn is a feature space of vectors capturing interesting
properties of the apps and Y is a label space containing binary
labels for the detection task or the names of malware families
for the multiclass classiﬁcation task.
B. Concept Drift
One of the greatest challenges facing machine learning-
based malware classiﬁers is the presence of dataset shift [1,
20, 27] as the distribution of malware at test time begins to
1https://s2lab.cs.ucl.ac.uk/projects/transcend/
diverge from the training distribution. This violates one of
the core assumptions of most classiﬁcation algorithms: that
the training and test time examples are identically and inde-
pendently drawn from the same joint distribution (i.i.d.). As
this assumption weakens over time, the classiﬁer’s predictions
become less and less reliable and performance degrades.
Dataset shift can be broadly categorised into three types of
shift [28]. Covariate shift refers to a change in the distribution
of P (x ∈ X ), when the frequency of certain features rises or
falls (e.g., variations in API call frequencies over time). Prior
probability shift or label shift is a change in the distribution
of P (y ∈ Y), when the base rate of a particular class is
altered (e.g., an increase in malware prevalence over time).
Concept drift is a change in the distribution P (y ∈ Y|x ∈ X ).
This often occurs when the deﬁnition of the ground truth
changes, e.g.,, if a new family of malware arises which, given
the feature space representation X , is indistinguishable from
benign applications. Due to limited knowledge, the model will
start misclassifying examples from the new family, even if no
covariate or prior probability shift has occurred. In practice, it
can be extremely difﬁcult to determine how much error should
be attributed to each type of shift [28]. Given this, it is common
in the security community to collectively refer to all types of
shift as concept drift, a custom that we continue in this work.
in malware classiﬁcation
is the adversarial nature of the task. Malware authors are
driven by the proﬁt motive to try and evade detection or
classiﬁcation by app store owners, antivirus companies, and
users. This incentivizes them to innovate: to obfuscate features
of their malware, develop new methods for exploitation and
persistence, and explore new avenues of proﬁteering and
abuse. This causes the deﬁnition of malware to evolve over
time, sometimes in drastic or unexpected ways.
The impetus for concept drift
C. Rejection
it
is entirely robust
There are multiple routes to dealing with concept drift.
The most effective would be to design a feature space X
such that
to concept drift, essentially
distilling all possible malware behaviour down to a ‘Platonic
ideal’ [37] that captures maliciousness no matter what form it