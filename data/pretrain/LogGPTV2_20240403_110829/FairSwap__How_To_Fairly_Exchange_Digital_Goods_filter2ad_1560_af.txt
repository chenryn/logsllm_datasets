CRYPTO 2002, volume 2442 of Lecture Notes in Computer Science, pages 111–126, Santa
Barbara, CA, USA, August 18–22, 2002. Springer, Heidelberg, Germany.
[38] Chris O’Falt.
Bittorrent to now oﬀer legal movie downloads, 2015.
http://www.
hollywoodreporter.com/news/bittorrent-offer-legal-movie-downloads-769733.
[39] Henning Pagnia and Felix C G¨artner. On the impossibility of fair exchange without a trusted
third party. Technical report, Technical Report TUD-BS-1999-02, Darmstadt University of
Technology, Department of Computer Science, Darmstadt, Germany, 1999.
[40] Bryan Parno, Jon Howell, Craig Gentry, and Mariana Raykova. Pinocchio: Nearly practical
veriﬁable computation. In 2013 IEEE Symposium on Security and Privacy, pages 238–252,
Berkeley, California, USA, May 19–22, 2013. IEEE Computer Society Press.
[41] Muntasir Raihan Rahman. A survey of incentive mechanisms in peer-to-peer systems. Cheriton
School of Computer Science, University of Waterloo, Tech. Rep. CS-2009-22, 2009.
[42] Lakshmish Ramaswamy and Ling Liu. Free riding: A new challenge to peer-to-peer ﬁle sharing
In System Sciences, 2003. Proceedings of the 36th Annual Hawaii International
systems.
Conference on, pages 10–pp. IEEE, 2003.
[43] Jason Teutsch and Christian Reitwiessner. TrueBit – a scalable veriﬁcation solution for
blockchains, 2018. https://truebit.io/.
[44] Torrentfreak.
to Share Public Spending Data,
2014. https://torrentfreak.com/uk-government- uses-bittorrent- to-share-public-
spending-data-100604/.
UK Government uses Bittorrent
[45] Bitcoin Wiki. Zero Knowledge Contingent Payment, 2018. https://en.bitcoin.it/wiki/
Zero_Knowledge_Contingent_Payment.
[46] Andrew Chi-Chih Yao. How to generate and exchange secrets (extended abstract). In 27th
Annual Symposium on Foundations of Computer Science, pages 162–167, Toronto, Ontario,
Canada, October 27–29, 1986. IEEE Computer Society Press.
28
A Programmable global random oracle
A common model for crpytographic proofs is the random oracle model. This model assumes that
hash functions can be modeled to return perfectly random values, which can not be predicted. For
this reason hash functions are instantiated with random oracles. For proving security in the UC-
model, we use a random oracle ideal functionality H which (unless otherwise instructed) responds
to all queries with uniformly random sampled values r ← {0, 1}µ and stores all query response pairs
(q, r) in the set Q. If the query value q has been answered before, such that (q, r) ∈ Q is stored, H
responds with r.
It is common for UC security proofs to work with a programmable random oracle. Programma-
bility means that the ideal UC adversary Sim can control the random oracle and program its hashes
to speciﬁc responses. Additionally, it can see all queries made by the environment Z to the random
oracle. Traditionally, such a random oracle is modeled as a local functionality, which is in control
of the Simulator. This again implies that every unique protocol execution has its own local disjunct
hash function. Since we want to explicitly allow composition of multiple protocols, we follow the
argument of [17, 14] that such local functionalities are not a good model for standard hash function
like keccak. A global functionality would respond to all queries in all sessions with the same values,
which cannot be done with local random oracle functionalities.
Our construction models as a global functionality H following the works of [17, 14]. Every
party in this model has oracle access to a global functionality H which represents our idealized
hash function. Since we require programmability in the GUC model, we follow the work of [14]
and model H as a restricted programmable and observable random oracle as deﬁned in Figure 8.
This functionality allows parties to simulate and observe only queries made from their own session
(denoted with session and contract identiﬁer id ).
The ﬁrst feature of the random oracle is that parties can query it on some value q, by calling
(query, id , q). For simplicity we will write r ← H(q). The random oracle will return a uniformly
sampled value or an already existing value r from the set Q.
But next to this straightforward functionality, we require programmability, which is a special
property needed for proving security in the UC model. Programmability means that the adversary
is allowed to ﬁx the response of the oracle for certain queries if they have not been queried before
by sending (program, q, r) (we say the adversary programs the random oracle).
Programmable random oracles are a useful and practical tool in many UC simulations, which
has been studied intensively before in the non global setting [37, 21].
In the local UC model,
the adversary is always the simulator, who requires these properties to simulate indistinguishable
commitments. In the global UC model, there might be multiple executions that all interact with
the same global random oracle. Note, that the inﬂuence of any global functionality is not only for
the simulator of a single execution, but also applies for all adversaries from diﬀerent executions7.
Intuitively, this adversarial power seems to break security of schemes that are based on this
functionality since any adversary is allowed to program collisions, but we will show that this is not
true. As protection against this adversarial power parties have the ability to verify if some response
of the random oracle has been programmed by calling H(isPrgrmd, r). If H responds with 1, the
parties know that the values is programmed and reject the value.
Additionally to the restricted programmability the functionality H allows leakage of all illegiti-
7In our case the the environment could access the global random oracle through the adversary of another session
or protocol execution and program collisions.
29
The H functionality is the global random oracle with restricted programming and observ-
ability, which takes as input queries q ∈ {0, 1}∗ and outputs values r ∈ {0, 1}µ. Internally it
stores initially empty sets Q, P and a set Qid for all sessions id .
Upon receiving message (query, id , q) from a party of session id(cid:48) proceed as follows:
Query
• If (id , q, r) ∈ Q respond with (query, q, r).
• If (id , q, r) /∈ Q sample r ∈ {0, 1}µ, store (id , q, r) in Q and respond with (query, q, r).
• If the query is made from a wrong session (id (cid:54)= id(cid:48)), store (q, r) in Qid .
Upon receiving message (program, id , q, r) by the adversary A check if (id , q, r(cid:48)) is deﬁned in
Q. If this is the case, abort. Otherwise, if r ∈ {0, 1}µ store (id , q, r) in Q and (id , q) in P .
Upon receiving message (isPrgrmd, q) from a party of session id check if (id , q) ∈ P . If this
is the case respond with (isPrgrmd, 1).
Program
Upon receiving message (observe)
(observe, Qid ).
Observe
from the adversary of
session id respond with
Figure 8: The ideal restricted programmable and observable random oracle functionality H [14]
mate queries, which were made by the environment over the adversary, by sending H(observe). The
functionality H will respond with the set Qid which contains all illegitimate queries made from that
session. This includes all queries from adversaries that are not from the desired session. For more
information about the construction and properties of this ideal functionality we refer the reader
to [14].
B Cryptographic building blocks
In this section, we give a detailed explanation of the properties we need from the encryption and
commitment functions used in our protocol. Additionally, we will construct these schemes in the
programmable random oracle model and show why they provide the required equivocability and
extractability properties.
Note, that it is not easily possible to use a UC-style commitment and encryption functionalities
here, since our smart contract hybrid functionality needs to run the open/decrypt procedure. Since
in the UC-model functionalities are permitted from interacting with other functionalities, this
prevents us from using ideal functionalities here.
Commitment Scheme. Let κ be the security parameter and (a||b) denote the concatenation
of two values a and b. Then we construct a commitment scheme (Commit, Open) in the global
programmable random oracle model as follows:
30
Algorithm 7 Algorithm Commit
Input: x ∈ {0, 1}∗
d ← {0, 1}κ s.t. H(isPrgrmd, x||d) (cid:54)= 1
c ← H(x||d)
Output: (c, d)
(cid:46) choose d uniformly at random
(cid:46) query the oracle on x||d
To show that this scheme is hiding, it needs to hold that any ppt algorithm A cannot distin-
guish two commitments. From the randomness of the outputs of H it follows that this construction
is hiding because the output of H(x) ≈c H(y) is indistinguishable if the A does not know (or
programmed) H(x) or H(y) (which by chance only happens with a negligible probability for com-
putationally bounded distinguishers). If d is chosen uniformly at random from domain {0, 1}κ and
κ large enough, any A cannot distinguish Commit(x) from Commit(y) if he does not know the
opening d.
Algorithm 8 Algorithm Open
Input: c ∈ {0, 1}µ, d ∈ {0, 1}κ
c(cid:48) ← H(x||d)
if c == c(cid:48) and H(isPrgrmd, x||d) (cid:54)= 1 then
b = 1
b = 0
Output: b
(cid:46) query the oracle on x||d
(cid:46) ensure that the commitment was not programmed
(cid:46) otherwise reject the opening
In order to break the binding property, an adversary A needs to ﬁnd a collision H(x) = H(y),
without programming H. Since the outputs of H are uniformly distributed, the best strategy for
A is to guess values and query H on them. If µ is large, this is hard for computationally bounded
adversaries, since they can only make a polynomial in κ number of queries to H. Thus, the scheme
is computationally binding.
Encryption Scheme. The second cryptographic building block, which we need to construct for
our protocol is a symmetric encryption scheme, which satisﬁes the IND-CPA security property. We
instantiate our encryption scheme as follows. To encrypt to a tuple x = (x1, . . . , xm) randomly
chose k ← {0, 1}κ. Then compute z = z1, . . . , zn as follows:
Algorithm 9 Algorithm Enc
Input: x = (x1, . . . , xm), s.t. ∀i ∈ [m] : |xi| = λ
k ← {0, 1}κ s.t. ∀i ∈ [m] : H(isPrgrmd(k||i)) (cid:54)= 1
for each xi ∈ x do
ki = H(k||i)
zi = ki ⊕ xi
Output: z = (z1, . . . , zn)
(cid:46) choose k uniformly at random
(cid:46) generate i-th key
(cid:46) xor key and plaintext
The decryption is only accepted by the receiver if none of the results of H were programmed.
Therefore, the receiver queries H(isPrgrmd(k||i)) and rejects the result if for any i the random
oracle responds with true.
This scheme is correct, i.e. Dec(k, Enc(k, x)) = x since for all xi ∈ x it holds that H(k||i)⊕ zi =
H(k||i) ⊕ H(k||i) ⊕ xi = xi. As long as all outputs of the random oracle are uniformly distributed
31
Algorithm 10 Algorithm Dec
Input: z = (z1, . . . , zm), s.t. |zi| = λ and k ∈ {0, 1}κ
for each zi ∈ z do
ki = H(k||i)
if H(isPrgrmd(k||i)) then
Terminate and Output ⊥
xi = ki ⊕ zi
else
(cid:46) generate i-th key
(cid:46) reject if any key is programmed
(cid:46) xor key and ciphertext
Output x = (x1, . . . , xn)
over {0, 1}µ, the ciphertexts are indistinguishable, which means that the scheme satisﬁes the chosen
plaintext indistinguishability (IND-CPA). This property holds for as long as no programmed values
are queried, which does not happen when the encryption was done honestly.
In our protocol we consider the special case where we commit to the key for the encryption. The
authors of [37] show how to construct a non committing encryption scheme in the programmable
random oracle model, but also state the danger that a commitment to the key in this construction
might lead to a leakage of the plaintext. In our implementation, we make sure this is not the case,
by letting the commitment be Commit(k) = (H(k), k). Note, that even with knowledge of H(k) it is
not possible to distinguish xi ⊕H(k||i) from xi ⊕H(k(cid:48)||i) for computationally bounded adversaries.
B.1 Extending Merkle Trees to Commitments
For the our protocol Π we need that both parties S and R jointly commit to the values x using
a Merkle tree commitment towards the smart contract. The commitment on the values x =
(x1, . . . , xn) is generated using randomly sampled d = (d1, . . . dn), di ∈ {0, 1}κ as follows:
let x(cid:48) = (x1||d1, . . . , xn||dn))
Commit(x) = (root(Mtree(x(cid:48))), d) = (c, d)
x, if root(Mtree(x(cid:48))) = c
0, otherwise
Open(c, x, d) =
(cid:40)
The scheme is hiding, as long as the randomness r ∈ {0, 1}κ is chosen uniformly at random
because then the commitments are indistinguishable for any ppt adversary. Note, that this commit-
ment scheme does not satisfy the binding property if the random oracle is programmable, since the
adversary has the power to program two values x, y to result in the same response H(x) = H(y). In
our protocol we do not need classical hiding when at least on of the parties S or R is honest (which
is the only case in which our protocol satisﬁes fairness). In our case S generates the commitment
(which he will do correctly if he is honest) and sends it together with the committed values to
R. The receiver R recomputes the commitment and additionally checks if any of the labels of the
Merkle tree are programmed in H. If he encounters any programmed value, an honest R will reject
the root r and abort the protocol execution. This ensures that (as long as there is one honest
party) the commitment is binding.
32
(Gjc,L,H)-Hybrid World
Ideal World
leakage
inﬂuence
H
GL,H
jc
A
secure channel
S
S
n
i
S
t
u
o
R
e
c
n
e
u
ﬂ
n
i
e
g
a
k
a
e
l
R
n
i
R
t
u
o
outS
inS
˜S
Sim
F L
cfe
in
R
o
ut
R
˜R
e
c
n
e
u
ﬂ
n
i
e
g
a
k