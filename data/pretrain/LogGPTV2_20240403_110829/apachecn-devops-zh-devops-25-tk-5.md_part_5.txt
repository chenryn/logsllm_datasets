  ----    ------             ----   ----                       -------
  Normal  SuccessfulRescale  12m    horizontal-pod-autoscaler  New size: 6; reason: Ingress metric http_req_per_second_per_replica above target
  Normal  SuccessfulRescale  9m20s  horizontal-pod-autoscaler  New size: 9; reason: Ingress metric http_req_per_second_per_replica above target
  Normal  SuccessfulRescale  4m20s  horizontal-pod-autoscaler  New size: 3; reason: All metrics below target
```
目前，住房管理局没有理由扩大部署规模。当前值低于阈值。就我而言，是`1100m`。
现在，我们可以测试基于源自工具的定制度量的自动缩放是否如预期的那样工作。通过入口发送请求可能会很慢，尤其是当我们的集群运行在云中时。从笔记本电脑到服务的往返可能太慢。因此，我们将从集群内部发送请求，方法是旋转一个 Pod 并从它内部执行一个请求循环。
```
 1  kubectl -n go-demo-5 \
 2      run -it test \
 3      --image=debian \
 4      --restart=Never \
 5      --rm \
 6      -- bash
```
通常，我更喜欢`alpine`映像，因为它们小得多，效率高得多。但是`for`循环在`alpine`不工作(或者我不知道怎么写)，所以我们改用`debian`。但是它没有`curl`，所以我们必须安装它。
```
 1  apt update
 2
 3  apt install -y curl
```
现在，我们可以发送请求，为 HPA 生成足够的流量来触发扩展过程。
```
 1  for i in {1..500}; do
 2      curl "http://go-demo-5:8080/demo/hello"
 3  done
 4  
 5  exit
```
我们向`/demo/hello`端点发送了五百个请求，然后我们退出了容器。由于我们在创建 Pod 时使用了`--rm`参数，它将自动从系统中移除，因此我们不需要执行任何清理操作。
让我们来看看发生了什么。
```
 1  kubectl -n go-demo-5 \
 2      describe hpa go-demo-5
```
输出限于相关部分，如下所示。
```
...
Reference:                                                Deployment/go-demo-5
Metrics:                                                  ( current / target )
  "http_req_per_second_per_replica" on Service/go-demo-5: 1794m / 1500m
Min replicas:                                             3
Max replicas:                                             10
Deployment pods:                                          3 current / 4 desired
...
Events:
... Message
... -------
... New size: 6; reason: Ingress metric http_req_per_second_per_replica above target
... New size: 9; reason: Ingress metric http_req_per_second_per_replica above target
... New size: 3; reason: All metrics below target
... New size: 4; reason: Service metric http_req_per_second_per_replica above target
```
HPA 检测到`current`值高于目标值(在我的例子中是`1794m`)，并将所需的副本数量从`3`更改为`4`。我们也可以从上次事件中观察到这一点。如果在您的情况下，副本的`desired`数量仍然是`3`，请等待一会儿进行下一次 HPA 评估，并重复`describe`命令。
如果我们需要额外的确认来证明缩放确实如预期的那样工作，我们可以检索`go-demo-5`命名空间中的 Pods。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME           READY STATUS  RESTARTS AGE
go-demo-5-db-0 2/2   Running 0        33m
go-demo-5-db-1 2/2   Running 0        32m
go-demo-5-db-2 2/2   Running 0        32m
go-demo-5-...  1/1   Running 2        33m
go-demo-5-...  1/1   Running 0        53s
go-demo-5-...  1/1   Running 2        33m
go-demo-5-...  1/1   Running 2        33m
```
在我们停止发送请求后，可能不需要确认 HPA 将很快缩减`go-demo-5`部署。相反，我们将跳到下一个话题。
# 将指标服务器数据与自定义指标相结合
到目前为止，少数 HPA 示例使用单个自定义指标来决定是否扩展部署。您已经从[第 1 章](1.html)、*根据资源使用情况自动调整部署和状态集*中了解到，我们可以在一个 HPA 中组合多个指标。但是，该章中的所有示例都使用了来自度量服务器的数据。我们了解到，在许多情况下，来自度量服务器的内存和 CPU 度量是不够的，因此我们引入了 Prometheus Adapter，它向度量聚合器提供自定义度量。我们成功地配置了一个 HPA 来使用这些自定义指标。尽管如此，在我们的 HPA 定义中，我们经常需要这两种度量的组合。虽然内存和 CPU 指标本身还不够，但它们仍然是必不可少的。我们能两者结合吗？
让我们再来看看另一个 HPA 定义。
```
 1  cat mon/go-demo-5-hpa.yml
```
输出限于相关部分，如下所示。
```
...
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 80
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 80
  - type: Object
    object:
      metricName: http_req_per_second_per_replica
      target:
        kind: Service
        name: go-demo-5
      targetValue: 1500m
```
这一次，HPA 在`metrics`部分有三个条目。前两个是基于`Resource`类型的“标准”`cpu`和`memory`条目。最后一个条目是我们之前使用的`Object`类型之一。结合这些因素，我们告诉 HPA，如果满足三个标准中的任何一个，就要扩大规模。同样，它也会缩小规模，但要做到这一点，所有三个标准都必须低于目标。
我们来`apply`一下定义。
```
 1  kubectl -n go-demo-5 \
 2      apply -f mon/go-demo-5-hpa.yml
```
接下来，我们将描述 HPA。但是，在我们这样做之前，我们必须等待一段时间，直到更新后的 HPA 完成下一次迭代。
```
 1  kubectl -n go-demo-5 \
 2      describe hpa go-demo-5
```
输出限于相关部分，如下所示。
```
...
Metrics:                                                  ( current / target )
  resource memory on pods  (as a percentage of request):  110% (5768533333m) / 80%
  "http_req_per_second_per_replica" on Service/go-demo-5: 825m / 1500m
  resource cpu on pods  (as a percentage of request):     20% (1m) / 80%
...
Deployment pods:                                          5 current / 5 desired
...
Events:
... Message
... -------
... New size: 6; reason: Ingress metric http_req_per_second_per_replica above target
... New size: 9; reason: Ingress metric http_req_per_second_per_replica above target
... New size: 4; reason: Service metric http_req_per_second_per_replica above target
... New size: 3; reason: All metrics below target
... New size: 5; reason: memory resource utilization (percentage of request) above target
```
我们可以看到，基于内存的度量从一开始就高于阈值。我的情况是`110%`，而目标是`80%`。因此，HPA 扩大了部署规模。在我的例子中，它设置新的尺寸为`5`复制品。
没有必要确认新的 Pods 正在运行。到现在，我们应该相信 HPA 会做正确的事情。相反，我们将简要评论整个流程。
# 事件的完整横向流程
度量服务器正在从工作节点上运行的 Kubelets 获取内存和 CPU 数据。与此同时，普罗米修斯适配器正在从普罗米修斯服务器获取数据，正如您已经知道的，该服务器从不同的来源获取数据。来自度量服务器和普罗米修斯适配器的数据在度量聚合器中合并。
HPA is periodically evaluating metrics defined as scaling criteria. It's fetching data from Metrics Aggregator, and it does not really care whether they're coming from Metrics Server, Prometheus Adapter, or any other tool we could have used.
一旦达到扩展标准，HPA 就会通过更改副本数量来操纵部署和状态集。
因此，滚动更新是通过创建和更新复制集来执行的，而复制集又会创建或删除 Pods。
![](img/3a9e1aa2-f19e-47a8-ba94-b5c03eccf23a.png)
Figure 5-3: HPA using a combination of metrics from Metrics Server and those provided by Prometheus Adapter (arrows show the flow of data)
# 达到涅槃
现在，我们知道了如何将几乎任何指标添加到高性能计算中，它们比在[第 1 章](1.html)、*根据资源使用情况自动调整部署和状态集*中看起来要有用得多。最初，高性能计算不是很实用，因为在许多情况下，内存和中央处理器不足以决定是否扩展我们的 Pods。我们必须学习如何收集指标(我们使用普罗米修斯服务器)，以及如何测试我们的应用以获得更详细的可见性。自定义指标是拼图中缺失的一块。如果我们将“标准”指标(中央处理器和内存)扩展到我们需要的额外指标(例如，普罗米修斯适配器)，我们将获得一个强大的过程，使我们应用的副本数量与内部和外部需求保持同步。假设我们的应用是可扩展的，我们可以保证它们将(几乎)总是根据需要表现良好。不再需要人工干预，至少在缩放有问题的时候。具有“标准”和自定义指标的 HPA 将保证 Pods 的数量满足需求，集群自动缩放器(如果适用)将确保我们有足够的容量来运行这些 Pods。
我们的系统离自给自足又近了一步。它会自我适应变化的条件，我们(人类)可以将注意力转向比那些将系统保持在满足需求的状态所需的更具创造性和更少重复的任务。我们离涅槃又近了一步。
# 现在怎么办？
请注意，我们使用的是`autoscaling/v2beta1`版本的 HorizontalPodAutoscaler。在撰写本文时(2018 年 11 月)，只有`v1`是稳定的，可以生产的。然而，`v1`是如此有限(它只能使用 CPU 指标)以至于它几乎没有用。Kubernetes 社区在新的(`v2` ) HPA 上工作了一段时间，根据我的经验，它工作得相当好。主要问题不是稳定性，而是应用编程接口中可能不向后兼容的潜在变化。不久前，`autoscaling/v2beta2`发布，使用了不同的 API。我没有将它包括在书中，因为(在撰写本文时)大多数 Kubernetes 集群还不支持它。如果你正在运行 Kubernetes 1.11+，你可能想切换到`v2beta2`。如果您这样做了，请记住，您需要对我们探讨的 HPA 定义进行一些更改。逻辑还是一样的，行为也是一样的。唯一可见的区别在于 API。
Please consult *HorizontalPodAutoscaler v2beta2 autoscaling* ([https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#horizontalpodautoscaler-v2beta2-autoscaling](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#horizontalpodautoscaler-v2beta2-autoscaling)) for the changes from `v2beta1` we used to `v2beta2` available in Kubernetes 1.11+.
就这样。如果这本书是专用的，就销毁它，如果不是，或者你打算马上跳到下一章，就保留它。如果您保留它，请通过执行以下命令删除`go-demo-5`资源。
```
 1  helm delete go-demo-5 --purge
 2
 3  kubectl delete ns go-demo-5
```
在你离开之前，你可能要复习一下本章的要点。
*   HPA 定期评估定义为扩展标准的指标。
*   HPA 从度量聚合器获取数据，它并不关心这些数据是来自度量服务器、普罗米修斯适配器还是我们可以使用的任何其他工具。