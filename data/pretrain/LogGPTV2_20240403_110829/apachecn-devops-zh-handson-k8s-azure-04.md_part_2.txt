    忽必烈得到 hpa -w
    这将跟踪 HPA 并向您显示部署的逐步缩减，如*图 4.14* 所示:
    ![Tracking the HPA scale down using the kubectl get hpa -w command](img/B17338_04_14.jpg)
    图 4.14:观察 HPA 的缩小
8.  Before we move on to the next section, let's clean up the resources we created in this section:
    忽必烈 delete -f hpa.yaml
    kubectl delete -f 留言簿一体机. yaml
在本节中，您首先手动然后自动缩放应用。然而，支持应用的基础设施是静态的；您在双节点集群上运行了这个程序。在许多情况下，集群上的资源可能也会耗尽。在下一节中，您将处理这个问题，并了解如何自己扩展 AKS 集群。
## 缩放集群
在前一节中，您讨论了扩展运行在集群之上的应用。在本节中，您将了解如何扩展您正在运行的实际集群。首先，您将手动将集群扩展到一个节点。然后，您将配置集群自动缩放器。群集自动缩放器将监控您的群集，并在群集上存在无法调度的 Pod 时向外扩展。
### 手动扩展集群
您可以通过为集群设置静态节点数来手动扩展 AKS 集群。集群的扩展可以通过 Azure 门户或命令行完成。
在本节中，您将了解如何通过将集群缩减到一个节点来手动扩展集群。这将导致 Azure 从您的集群中删除一个节点。首先，将要删除的节点上的工作负载将被重新调度到另一个节点上。一旦安全地重新安排了工作负载，该节点将从您的集群中删除，然后虚拟机将从 Azure 中删除。
要扩展集群，请执行以下步骤:
1.  Open the Azure portal and go to your cluster. Once there, go to **Node pools** and click on the number below **Node count**, as shown in *Figure 4.15*:
    ![Manually scaling the cluster using the Azure portal](img/B17338_04_15.jpg)
    图 4.15:手动扩展集群
2.  This will open a pop-up window that will give the option to scale your cluster. For our example, we will scale down our cluster to one node, as shown in *Figure 4.16*:
    ![Pop-up window confirming the new cluster size](img/B17338_04_16.jpg)
    图 4.16:确认新集群大小的弹出窗口
3.  点击屏幕底部的**应用**按钮保存这些设置。这将导致 Azure 从集群中删除一个节点。这个过程大约需要 5 分钟才能完成。您可以通过单击 Azure 门户顶部的通知图标来跟踪进度，如下所示:
![Clicking the notification icon in the Azure portal to check the progress of the scale-down operation](img/B17338_04_17.jpg)
图 4.17:可以使用 Azure 门户中的通知来跟踪集群扩展
缩小操作完成后，在这个小集群上重新启动留言簿应用:
kubectl create -f 留言簿一体机. yaml
在下一节中，您将扩展留言簿，使其不再能在这个小集群上运行。然后，您将配置群集自动缩放器来横向扩展群集。
### 使用集群自动缩放器缩放集群
在本节中，您将探索集群自动缩放器。集群自动缩放器将监控集群中的部署，并缩放集群以满足您的应用需求。集群自动缩放器会监视集群中由于资源不足而无法调度的 Pod 数量。您将首先强制部署无法计划的 pods，然后配置集群自动缩放器来自动缩放集群。
要强制您的集群资源不足，您将手动横向扩展**重新复制**部署。为此，请使用以下命令:
kubectl 扩展部署 redis-副本-副本 5
您可以通过查看集群中的 Pod 来验证该命令是否成功:
忽必烈得到 pods
这将向您显示类似于*图 4.18* 所示的输出:
![Output displaying four out of five pods as pending due to the cluster being out of resources](img/B17338_04_18.jpg)
图 4.18:五个 Pod 中有四个是待定的，这意味着它们不能被调度
如您所见，您现在有两个处于**待定**状态的 PODS。Kubernetes 中的**待定**状态意味着该 pod 不能被调度到节点上。在这种情况下，这是由于群集资源不足。
#### 注意
如果您的集群运行在比 DS2v2 更大的虚拟机上，您可能不会注意到 pods 现在处于**挂起**状态。在这种情况下，将副本的数量增加到更高的数量，直到您看到处于挂起状态的 pods。
现在，您将配置群集自动缩放器来自动缩放群集。与上一节中的手动缩放类似，有两种方法可以配置集群自动缩放器。您可以通过 Azure 门户进行配置，类似于我们手动缩放的方式，也可以使用**命令行界面** **(CLI)** 进行配置。在本例中，您将使用命令行界面来启用群集自动缩放器。以下命令将为您的集群配置集群自动缩放器:
az aks 节点池更新-启用-集群-自动缩放\
-g rg-handsonaks-cluster-name handsonaks \
-名称代理池-最小计数 1 -最大计数 2
此命令在集群中的节点池上配置集群自动缩放器。它将其配置为最少一个节点，最多两个节点。这将需要几分钟来配置。
配置集群自动缩放器后，您可以使用以下命令观察集群中的节点数量，从而看到它正在运行:
kubectl 获取节点-w
新节点出现并在集群中变为 **Ready** 大约需要 5 分钟。一旦新节点**准备好**，点击 *Ctrl* + *C* 即可停止观看节点。您应该会看到类似于在*图 4.19* 中看到的输出:
![Output showing a new node joining the cluster ](img/B17338_04_19.jpg)
图 4.19:新节点加入集群
新节点应确保您的群集有足够的资源来安排扩展的 **redis-** **副本**部署。要验证这一点，请运行以下命令来检查 pods 的状态:
忽必烈得到 pods
这将向您显示处于**运行**状态的所有 Pod ，如下所示:
![Output displaying all pods in a Running state](img/B17338_04_20.jpg)
图 4.20:所有 Pod 现在都处于运行状态
现在清理您创建的资源，禁用集群自动缩放器，并确保您的集群在下一个示例中有两个节点。为此，请使用以下命令:
kubectl delete -f 留言簿一体机. yaml
az aks 节点池更新-禁用-集群-自动缩放\
-g rg-handsonaks-cluster-name handsonaks-name agent pool
az aks 节点池规模-节点数 2 -g rg-handsonaks \
-集群名 handsonaks -名称代理池
#### 注意
上一个示例中的最后一个命令将向您显示一条错误消息，**新节点计数与当前节点计数相同。**，如果集群已经有两个节点。您可以放心地忽略这个错误。
在本节中，您首先手动缩减集群，然后使用集群自动缩放器来扩展集群。您使用 Azure 门户手动缩小集群，然后使用 Azure 命令行界面配置集群自动缩放器。在下一节中，您将了解如何升级 AKS 上运行的应用。
## 升级您的应用
在 Kubernetes 中使用部署使得升级应用成为一项简单的操作。与任何升级一样，您应该有良好的故障恢复，以防出现问题。您将遇到的大多数问题都会在升级过程中发生。云原生应用应该使处理这个问题变得相对容易，如果您有一个非常强大的支持 DevOps 原则的开发团队，这是可能的。
DevOps 状态报告([https://puppet . com/resources/report/2020-State-devo PS-report/](https://puppet.com/resources/report/2020-state-of-devops-report/))多年来报告称，软件部署频率较高的公司，其应用的可用性和稳定性也较高。这似乎违反直觉，因为软件部署会增加问题的风险。但是，通过更频繁地部署和使用自动化 DevOps 实践进行部署，您可以限制软件部署的影响。
有多种方法可以对 Kubernetes 集群中运行的应用进行更新。在本节中，您将探索以下更新 Kubernetes 资源的方法:
*   通过更改 YAML 文件进行升级:当您可以访问进行更新所需的完整 YAML 文件时，此方法非常有用。这可以通过命令行或自动系统来完成。
*   使用 **kubectl edit** 升级:这种方法主要用于集群上的小更改。这是一种在集群上实时更新配置的快速方法。
*   使用 **kubectl 补丁**升级:当您需要对一个 Kubernetes 编写一个特定的小更新脚本，但是不能访问完整的 YAML 文件时，这种方法非常有用。它可以通过命令行或自动化系统来完成。如果您可以访问原始 YAML 文件，通常最好编辑 YAML 文件，并使用 **kubectl apply** 应用更新。
*   使用 Helm 升级:当您的应用通过 Helm 部署时，会使用此方法。
如果您有无状态的应用，下面几节中描述的方法会很有用。如果您在任何地方都存储了状态，请确保在尝试升级应用之前备份该状态。
让我们从通过更改 YAML 文件进行第一种类型的升级开始这一部分。
### 通过更改 YAML 文件进行升级
为了升级 Kubernetes 服务或部署，您可以更新实际的 YAML 定义文件，并将其应用于当前部署的应用。通常，我们使用 **kubectl create** 来创建资源。类似地，我们可以使用 **kubectl apply** 来更改资源。
部署会检测更改(如果有)，并将运行状态与所需状态相匹配。让我们看看这是如何做到的:
1.  Start with our guestbook application to explore this example:
    kubectl apply -f 留言簿一体机. yaml
2.  After a few minutes, all the pods should be running. Let's perform the first upgrade by changing the service from **ClusterIP** to **LoadBalancer**, as you did earlier in the chapter. However, now you will edit the YAML file rather than using **kubectl edit**. Edit the YAML file using the following command:
    代码留言簿一体机. yaml
    取消对该文件第 102 行的注释，将**类型**设置为**负载平衡器**，并保存该文件，如图*图 4.21* :
    ![Changing the service type from ClusterIP to LoadBalancer using the YAML file](img/B17338_04_21.jpg)
    图 4.21:在留言簿多合一 YAML 文件中将类型设置为负载平衡器
3.  Apply the change as shown in the following code:
    kubectl apply -f 留言簿一体机. yaml
    您应该会看到类似于*图 4.22* 的输出:
    ![Output confirming that the service’s frontend has been updated](img/B17338_04_22.jpg)
    图 4.22:服务的前端被更新
    在*图 4.22* 中可以看到，只有 YAML 文件中更新的对象，也就是本例中的服务，在 Kubernetes 上进行了更新，其他对象保持不变。
4.  You can now get the public IP of the service using the following command:
    忽必烈得到服务
    给它几分钟，你应该会看到 IP，如*图 4.23* 所示:
    ![Using the kubectl get service command to display the public IP of the service](img/B17338_04_23.jpg)
    图 4.23:显示公共 IP 的输出
5.  You will now make another change. You'll downgrade the front-end image on line 127 from **image: gcr.io/google-samples/gb-frontend:v4** to the following:
    图片:gcr.io/google-samples/gb-frontend:v3
    可以通过使用这个熟悉的命令在编辑器中打开留言簿应用来进行此更改:
    代码留言簿一体机. yaml
6.  Run the following command to perform the update and watch the pods change:
    忽必烈应用-f 盖斯特布鲁克多功能一体 yaml 和忽必烈得到 pods -w
    这将产生类似于图 4.24 的输出:
    ![Output displaying new pods created from a new ReplicaSet](img/B17338_04_24.jpg)
    图 4.24:创建了一个新副本集中的荚
    这里你可以看到一个新版本的 pod 被创建(基于一个新的复制集)。一旦新的 Pod 运行并准备就绪，其中一个旧的 Pod 就被终止。重复这个创建-终止循环，直到只有新的 Pod 在运行。在*第 5 章【处理 AKS 中的常见故障】*中，您将看到这样一个升级出错的例子，您将看到 Kubernetes 在新的 Pod 健康之前不会继续升级过程。
7.  Running **kubectl get events | grep ReplicaSet** will show the rolling update strategy that the deployment uses to update the front-end images:
    ![Monitoring Kubernetes events and filtering to only see ReplicaSet-related events](img/B17338_04_25.jpg)
    图 4.25:监视 Kubernetes 事件并过滤以仅查看与 ReplicaSet 相关的事件
    #### 注意
    在前面的示例中，您正在使用管道(由 **|** 符号显示)和 **grep** 命令。Linux 中的管道用于将一个命令的输出发送到另一个命令的输入。在这种情况下，您将 **kubectl get events** 的输出发送到 **grep** 命令。Linux 使用 **grep** 命令过滤文本。在这种情况下，您使用 **grep** 命令仅显示包含单词 ReplicaSet 的行。
    您可以在这里看到，新的副本集被放大，而旧的副本集被缩小。您还将看到前端的两个副本集，新副本集一次替换另一个 pod:
    忽必烈得到复制集
    这将显示如图 4.26 所示的输出:
    ![Output showing two ReplicaSets are available for the frontend deployment, one with 0 pods, the other with 3 pods](img/B17338_04_26.jpg)
    图 4.26:两个不同的复制集
8.  Kubernetes will also keep a history of your rollout. You can see the rollout history using this command:
    kubectl 部署历史部署前端
    这将产生如图 4.27 所示的输出:
    ![Displaying the rollout history of the deployment](img/B17338_04_27.jpg)
    图 4.27:应用的部署历史
9.  Since Kubernetes keeps a history of the rollout, this also enables rollback. Let's do a rollback of your deployment:
    kubectl 卷展栏撤销部署前端
    这将触发回滚。这意味着新的复制集将缩小到零个实例，旧的复制集将再次扩大到三个实例。您可以使用以下命令验证这一点:
    忽必烈得到复制集