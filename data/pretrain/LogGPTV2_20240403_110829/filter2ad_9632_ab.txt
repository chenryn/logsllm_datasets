Entropy:y^ 的熵至少可以有两种状态：(i) 接近最大熵，即 H(y^) = log，或 (ii) 接近最小熵，即 H(y^) = 0。
实际上，在不干扰argmax(y^)的情况下，
H(y^)确实可以被用于预测二值s
不失一般性，我们假设Y=2, 考虑 ^1 ≡ ^ 和 ^0 = 1 – ^1，yˆ = [ˆ0,ˆ1]
下图展示了我们如何使用单个实值 ^ 来预测两个属性，例如，y^ = [.95, .05] 和 y^ = [.75, .25] 具有相同的 argmax
但不同的熵：分别为 0.29 和 0.81
根据上图，我们观察y^，当其小于0.5时，我们可以预测y-=-,否则为1；而我们可以训练一个分类器，使得对于 = 0 的样本，ˆ 接近边界（0 或
1），具体取决于 ； 否则，对于 = 1，^ 远离边界。 使用阈值 ，我们从 ˆ 预测二元属性 和 。
接下来我们就要定义用于训练分类器的损失函数
其中乘数和旨在控制诚实和好奇之间的权衡。 第一项是交叉熵，第二项是香农熵，旨在对于 = 0 的样本最小化 y^ 的熵，同时对于 = 1最大化 y 的熵。
这样训练之后，在推理阶段，当观察到y^，会计算其熵值，并使用阈值t来估计s-，如下所示
所以其实攻击者G就是一个简单的阈值函数，阈值则可以通过在训练期间的验证集进行优化得到
###  参数化攻击
当S>=2时，上一种攻击方式就不可行了，所以这里介绍第二种攻击方式，在此之前我们简单提一下信息瓶颈
之前我们提到了马尔科夫链
服务器希望找到一个分类器F*可以将用户的数据x映射到一个向量y^
同时使得y^尽可能地包含关于y和s的信息
这种F*可以被定义为下面数学优化公式的解
其中、和是拉格朗日乘数，它们允许我们沿着不同的可能局部最小值移动，并且都是非负实值
上面这条公式实际上是信息瓶颈公式的扩展，其中由 F * 产生的最优 y^ 是根据其与三个变量 x、 和 的关系来决定的。 通过改变
乘数，我们可以探索不同速率的压缩之间的权衡，即通过最小化 I(y^;x) 和我们旨在保留的信息量，即通过最大化 I(y^;) 和 I(y^;)。 特别是对于
DNN，压缩可能有助于分类器实现更好的泛化
现在我们来看看对于一个计算有界且只能访问原样本的服务器，应该怎么求解上式并创建最优的HBC分类器
我们有
对于固定的训练集而言，在优化过程中H(y)和H(s)是常量，而对于一个判别F来说，有
所以我们将上式简化如下
上式可以看做是一个优化问题，旨在最小化y^的熵，并将尽可能多的关于y和s的信息编码进去。因为优化的过程是寻求一个函数 F∗ 来产生一个低熵 y^ ，使得
y^ 只提供关于 和 的信息，而没有关于其他任何信息的信息。 乘数 和 指定 和 如何在 y^ 的熵中竞争剩余容量
现在，服务器需要训练一个已知的现成分类器。 在这里，我们对目标属性 使用交叉熵损失函数，并使用 SGD 训练分类器 F。
然而，除了这个交叉熵损失之外，我们还需要为属性寻找另一个损失函数。 因此，我们需要一种方法来为模拟这样的损失函数。
让 |y^ 表示给定 y^ 的真实但未知的 概率分布， |y^ 表示 |y^ 的近似值。 考虑到这两个分布 H |y^ ( |y^ ) 之间的交叉熵，已知有
这个不等式告诉我们，未知分布之间的交叉熵和它的任何估计，是H的上界，并且当|y\^=|y^ 时，等式成立。 因此，如果我们为 |y^
找到一个有用的模型，那么最小化H( |y^ ) 的问题可以通过最小化 H |y^ ( |y^ ) 来解决。
我们可以下面的交叉熵来估计 H |yˆ ( |yˆ )
在为 |yˆ 初始化一个参数化模型以估计H( |yˆ )后，我们对下式进行优化
此时优化问题的变分近似可以写作
其中联合最小化是在参数化模型 F 和 G 上执行的。这里，H^(·) 和 H^(·|·)
表示分别在每批采样数据上计算的经验熵和条件熵。该方案的训练示意图如下所示
至此，两种攻击方案都介绍完毕。在正则化攻击里，我们只需要修改F的损失函数，在参数化攻击里，我们不仅要修改损失函数，还有利用额外的模型G来估计敏感属性。因此，F可以被看做在同时扮演两个角色，一个是诚实方，用于估计目标属性，一个是好奇的编码方，用于编码敏感属性；而G则是好奇的解码方，用于解码收到的输出并估计敏感属性。
## 实验分析及复现
###  分析
我们以UTKFace为例。我们假设性别Gender为目标属性y，种族Race为敏感属性s
实验得到的ROC曲线如下
上一行是标准分类器，下一行是通过正则化攻击得到的HBC分类器
在左上图中，标准分类器的 ROC 曲线下面积 (AUC) 为 0.97，而在左下图中，分类器是 HBC，但仍达到相当大的 0.94
AUC。而对于好奇方而言，右上图中的标准分类器没有提供有关 Race 的信息，它基本上与随机猜测一样。 但是，右下角的 HBC 分类器通过正则化攻击预测
Race 可以达到 0.89 AUC。
这表明正则化攻击确实可以实现HBC分类器及其攻击效果。
而当S>2时，我们进一步的实验结果如下所示，这里我们将性别、年龄或种族中的一个设置为，另一个设置为，并比较实现的和
上表是参数化攻击的结果，其中目标属性是年龄，敏感属性是种族
上表是各类攻击的结果，其中目标属性是种族，敏感属性是性别
从表格中我们可以看到，对于所有 RawHBC 的情况，HBC 分类器的 非常接近 Std 中相应分类器的 。此外，我们看到在某些情况下，HBC
甚至有助于实现更好的泛化，从而获得更好的诚实度；这非常重要，因为 HBC 分类器可以看起来尽可能诚实。
当我们可以拿到原始输出时，攻击在所有任务中都非常成功，并且在许多情况下，我们可以达到与我们可以针对特定敏感属性训练 F
的情况相似的准确性。例如，在第一个表中，对于 = 3 和 > 2，我们可以达到大约 83% 的好奇来从针对年龄属性训练的分类器中推断种族属性。
在 SoftHBC 中，通过参数化攻击实现高好奇度更加困难，因为需要降低更多的诚实度。特别是对于具有 >
的任务，其中敏感属性比目标属性更精细。此外，虽然我们之前已经看到 SoftHBC 成功的正则化攻击，但正则化攻击不能应用于 > 2 的任务。此外，尽管
RawHBC 的好奇心比 SoftHBC 更高，但随着输出的大小变大，两者之间的差异会变小。
另外我们还可以观察到，当 ≤ 时，攻击非常成功，因为释放的输出容量更大。但是，当 > 时，攻击也是成功的。最有难度的情况是 = 2
并且我们只能访问软输出，因为在这些任务中我们只释放一个值（即 ^1 = 1 – ^2）。此外，我们在第二个表中看到，对于具有 = = 2 的
SoftHBC，正则化攻击比参数化攻击实现了更好的权衡。
###  复现
准备UTKFace的数据
数据集信息如下
准备模型
打印出summary如下
我们来复现参数化攻击
参数化攻击的G的架构
打印出summary如下
参数化攻击主体代码
其中评估acc的代码如下
测试结果如下
可以看到通过训练，模型推理目标属性y和敏感属性s的acc都一直在上升，说明HBC攻击确实有效，能够从模型的输出中成功推理出敏感属性。
## 参考
1.Honest-but-Curious Nets: Sensitive Attributes of Private Inputs Can Be
Secretly Coded into the Classifiers’ Outputs
2.The InformationBottleneck Method
3.Stealing Machine Learning Models Via Prediction APIs
4.A Hybrid Approach to Privacy-Preserving Federated Learning