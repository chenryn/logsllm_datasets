### 5.2 Cluster Generalization and Signature Generation

**Signature Generation:**
The process of signature generation involves creating a Network Intrusion Detection System (NIDS) signature from a cluster of similar network connections or sessions. We aim to generalize the variations observed within a cluster, assuming that effective clustering has grouped together sessions that are variants of the same attack. These variations typically correspond to obfuscation attempts or differences among attack variants. By generalizing these differences, we produce a resilient signature that can detect data not necessarily observed during the training period.

**Signature Representation:**
The signature is represented as a finite state automaton (FSA). Initially, we construct a probabilistic FSA (PFSA) that accepts exactly the event sequences contained in a cluster. The edge weights in the PFSA correspond to the number of times an edge is traversed when accepting all cluster data exactly once. We then use PFSA learning algorithms to generalize the data variations observed in the cluster. For HTTP connection-level signatures, we employ the sk-strings method [24], which merges states that are probabilistically indistinguishable. For session-level clusters, we use beam search [17]. In the case of NetBIOS signatures, our algorithm combines both sk-strings and simulated beam annealing [23] to handle the generalization. These generalizations add transitions to the state machine to accommodate variations such as data reordering and character alterations in attack strings, as well as repeated strings with any number of repeats.

**Further Generalization:**
We further enhance the signatures at points of high data variability by converting a signature that matches a sequence of session data into one that matches a subsequence of that data. This is achieved by inserting "gaps" that accept any sequence of arbitrary symbols. Gaps are inserted whenever we observe four or more patterns with a common prefix, common suffix, and one dissimilar data element. For example, if the signature accepts sequences like AvB, AwB, AxB, and AyB, we replace these with the regular expression A[.∗]B. This allows for large variations in the signature, making it more flexible and robust.

**Example Signatures:**
- **Welchia Worm:** Figure 4 shows a session-level signature for the Welchia worm, which exploits a buffer overflow. Nemean's generalization produces a signature that matches a wide class of Welchia scans while retaining the essential buffer overflow information.
- **Nimda Exploit:** Figure 5 shows connection-level signatures for the Nimda exploit, which targets Windows Media Player, and the Deloder NetBIOS worm. The Nimda signature is an example of a signature for an exploit with high diversity, where the subsequence creation generalization allows it to match a wide class of Nimda attacks.
- **Deloder Worm:** The Deloder signature demonstrates Nemean's capability to generate signatures for exploits using more complex protocols like NetBIOS/SMB.

### 6 Data Collection

**Data Sources:**
The data used for our evaluation comes from two primary sources:
1. **Honeypot Packet Traces:** Collected from unused address space, these traces were used to build signatures and evaluate Nemean's detection capability.
2. **Production Traffic:** Packet traces collected from our departmental border router, used to test the resilience of our signatures to false positives.

**Production Traffic:**
Obtaining packet traces for live network traffic is challenging due to privacy concerns. While network operators are willing to share flow-level summaries, anonymizing payloads remains difficult. We were able to access such data from our department’s border router, which is a sparsely allocated, well-managed /16 network with approximately 24 web servers and around 400 clients. We monitored all outgoing and incoming HTTP packets on this network for an 8-hour period. Table 1 provides a summary of this dataset.

**Honeypot Traffic:**
Traffic from two unused /19 IP address blocks totaling 16K addresses was routed to our honeynet monitoring environment. To normalize the traffic, a simple source-filtering rule was employed: one destination IP address per source. Connections to additional destination IP addresses were dropped by the filter.

- **HTTP Requests:** Forwarded to a fully patched Windows 2000 Server running on VMware.
- **NetBIOS/SMB Traffic:** Routed to a virtual honeypot system similar to Honeyd. This was done for two reasons: first, the fully patched Windows 2000 Server often rejected or disconnected sessions before we could classify the attack vector accurately; second, Windows 2000 servers limit the number of simultaneous network share accesses, inhibiting connection requests.

We collected two sets of traces: a short-term training set (2 days) and a longer testing set (7 days) to evaluate Nemean's detection capability. Table 2 summarizes these datasets. The reduction in port 80 traffic volume from the 2-day to the 5-day dataset is typical in honeynets due to the bursty nature of botnet activity.

### 7 Evaluation

**Effectiveness Testing:**
We tested the effectiveness of Nemean's HTTP and NetBIOS signatures and examined the session clusters used to produce these signatures. Section 7.1 reveals the major classes of attacks in our recorded data and quantitatively measures the clusters produced by the clustering module. We evaluated the detection and false positive rates of Nemean's signatures and compared our results with Snort's HTTP capabilities. Finally, we provide a qualitative discussion of our experience with Honeycomb.

**Cluster Evaluation:**
- **HTTP Clusters:** WebDAV scans, which allow users to collaboratively edit and manage documents on remote web servers, account for the majority of the attacks in our dataset. Popular WebDAV methods include OPTIONS, SEARCH, and PROPFIND, supported by Microsoft IIS web servers. Nimda attacks exhibit great diversity in attack variants and HTTP URL obfuscation techniques, exploiting directory traversal vulnerabilities on IIS servers.
- **NetBIOS Clusters:** Dominated by worms known as email viruses, these clusters can be classified into three types: hidden and open share exploits, MS-RPC query exploits, and MS-RPC service buffer overflow exploits. Detailed information on these exploits is provided in the technical report [35].

**Cluster Quality:**
We quantitatively evaluated the quality of clusters produced by the star clustering algorithm using precision and recall metrics. Precision measures the proportion of positive matches among all elements in each cluster, while recall measures the fraction of positive matches in the cluster among all possible positive matches in the dataset. We manually tagged each session with conjectures to estimate the quality of our clusters. The conjectures allowed us to compute weighted precision (wp) and weighted recall (wr) for our clustering, taking into account the total number of conjectures at a given cluster of sessions.

### Summary of Clusters
- **Cluster 1:** 9175 unique client IPs, identified as OPTIONS.
- **Cluster 2:** 597 unique client IPs, identified as Search.
- **Cluster 4:** 742 unique client IPs, identified as Nimda.
- **Cluster 5:** 51 unique client IPs, identified as Nimda.
- **Cluster 17:** 47 unique client IPs, identified as PROPFIND and OPTIONS.
- **Cluster 8:** 20 unique client IPs, identified as Nimda.
- **Cluster 7:** 11 unique client IPs, identified as Windows Media Exploit.
- **Cluster 6:** 10 unique client IPs, identified as Search.
- **Cluster 9:** 8 unique client IPs, identified as Code Red Retina and Search.
- **Cluster 11:** 6 unique client IPs, identified as various exploits.
- **Cluster 19:** 5 unique client IPs, identified as various exploits.

This structured approach ensures that the text is clear, coherent, and professional, providing a detailed and organized overview of the research and its findings.