ular, we connect to Akamai’s streaming servers via MMS by
9To preserve the physical locations of some of the most vul-
nerable points in the Akamai’s streaming network, we refrain
from providing detailed network maps in this section.
modifying the MiMMS program [6]. This helps us to observe
and record a monitored ﬂow’s throughput in each second.
4.2 Edge-level Experiments
Slow Load Balancing Experiment
4.2.1
Here, we evaluate the slow load balancing problem elab-
orated in Section 3.2.1 above. We demonstrate that DNS-
driven redirections are fundamentally incapable of preserv-
ing high quality experiences during system overloads. We
setup our experiment as follows: we assign seven machines
as probers and one as an observer, which has two roles here.
First, it monitors Akamai’s DNS redirections; and second,
it monitors the throughput of a video stream it is fetching
from an edge server.
Figure 7: Slow load balancing experiment
Figure 7 shows the throughput of the observed video stream
in time. At 11:42:00 the observer connects to an edge server
appointed by Akamai’s DNS and start streaming a live video.
Each second, the observer also monitors DNS redirections by
sending queries to Akamai’s DNS to obtain the up to date
IP addresses associated with the hostname in the stream’s
URL. After the observering stream reaches the projected
throughput (i.e., 1.4 Mb/s), at 11:42:30 (a), the seven prob-
ing machines start requesting streams from the same edge
server that the observer is connected to. As explained above,
they are overriding DNS redirections and request one addi-
tional unique stream per second.
At 11:43:00 (b), the edge server (or the access network
link) starts becoming overloaded and throughput of the ob-
served stream starts ﬂapping and gradually degrades. At
11:43:28 (c), we observe that the edge server has been re-
moved from DNS entries. At the same moment, the seven
probing machines abort their connections to the edge server.
At that point, the observing stream’s throughput has al-
ready been degraded to approximately 300Kb/s.
In addi-
tion, the throughput does not recover immediately, but re-
establishes approximately 30 seconds later (at 11:44:00 (d)).
Thus, we conﬁrm that the DNS-based system is incapable
of reacting quickly to overloaded conditions. By the time
the DNS entry gets updated and refreshed, the server is
already overloaded. In our experiment, the congestion clears
after 30 seconds, but this happens because our seven probing
machines disconnected. In a real scenario, e.g., either due
to a ﬂash crowd or a DoS attack, regular clients would have
to disconnect. And such disruptions can motivate clients to
search content from competing sites [13]. In section 5, we
discuss how to mitigate this problem.
 0 200 400 600 800 1000 1200 1400 1600 180011:42:0011:42:3011:43:0011:43:3011:44:0011:44:30Throughput(Kb/s)Timestamp(a)(b)(c)(d)Observercongestion exists on the path between Akamai’s cache and
the edge server. Therefore, the edge server is able to buﬀer
the stream when the out-bound connection (from the edge
server to our monitoring node) is congested. Consequently,
after congestion clears, the edge server attempts to ’reﬁll’
client’s media player buﬀer by delivering a burst of data to
the client.
4.2.3 Migration Experiment
Here, we explore the migration problem elaborated in Sec-
tion 3.4 above. The question is what happens to newly ar-
riving ﬂows that get redirected once a default edge server
becomes overloaded. Given that majority of edge clusters
are relatively small in size (Figure 6), once they become
overloaded, clients might be redirected to distant edge clus-
ters, or the default IDC at Boston.
It is well known that such long redirections work well for
the web for two reasons. First, web objects are relatively
small in size, while browsing sessions might be long; hence,
a client does not necessarily remain with the backup server
for the entire browsing session. Second, downloading web
objects is not time critical, i.e., slow images loading do not
severely deteriorate client’s browsing experience. On the
contrary, since live streaming is very sensitive to network
latency as well as bandwidth [24], this approach might not
be as eﬀective. We explore this issue below.
4.2.2 No Isolation Experiment
Figure 8: Akamai’s streaming models
Here, we evaluate the problem of the lack of isolation
among diﬀerent media in the Akamai’s architecture elab-
orated in Section 3.3 above. In particular, we focus on live
video and video-on-demand services.
Figure 8 depicts models of two Akamai’s streaming ser-
vices [11]. As explained in Section 2.1, for live streaming,
customers’ streams enter Akamai’s network via entry points,
they are replicated to reﬂectors, transferred to subscribed
edge servers, and ﬁnally transmitted to connected clients.
For video on demand streaming, streams are transferred to
edge servers directly from customers’ web servers or Aka-
mai’s net storage (cache server).
To verify our hypothesis described above, we perform an
Internet experiment, similar to the one from Section 4.2.1,
but at a diﬀerent edge server. In this experiment, the ob-
server downloads a video on demand stream via the MMS
protocol, while the seven probing machines again request
unique live video streams from the same edge server. We
select a video on demand stream that is transferred from an
Akamai’s cache in an attempt to avoid any potential bot-
tlenecks that are more likely to happen at a customer’s web
site.
Figure 10: Migration model
Figure 10 shows the redirections we observe from one net-
work node located in Singapore. We measure DNS redirec-
tions from that node to one of the hostnames in our collected
set of Akamai’s streaming ARLs. We ﬁnd that, for 80% of
time, it is redirected to an edge server located in Japan
for this speciﬁc hostname. In addition, the measured net-
work RTT between the two machines is 135 ms on average.
Meanwhile, we also observe that this node gets redirected
to edge servers located in Boston and France during con-
gestion epochs. The corresponding RTTs are 286 ms and
305 ms, respectively.
Next, we measure streaming throughputs between the Sin-
gapore’s node and the three Akamai’s edge servers (Japan,
Boston, and France), for a particular live stream. For the
edge server located in Japan, we enjoy a throughput of
1.4Mb/s, which corresponds to the encoding bit rate for the
stream. Whereas, for the edge servers located in Boston and
France, we are only able to obtain 800Kb/s and 600Kb/s, re-
spectively. We recorded the three traces and replayed them
to colleagues in our institution. All involved in this evalua-
tion conﬁrm that the video quality for the paths to Boston
Figure 9: No-isolation experiment
Figure 9 depicts the observed video on demand through-
put. After the VoD ﬂow establishes, at time 8:36:20 (a),
the seven probing nodes start sending requests to the edge
server. At 8:37:50 (b), the throughput starts ﬂapping again
and it degrades from 500Kb/s to 123Kb/s when the edge
server (or the network) becomes overloaded. We abort the
experiment at 08:38:40 (c), immediately after we observe
the congestion. Contrary to the video streaming experi-
ment (Figure 7), after the probing machines are terminated,
there is a traﬃc burst as high as 2Mb/s (d). Apparently, no
 0 200 400 600 800 1000 1200 1400 1600 1800 200008:35:0008:35:3008:36:0008:36:3008:37:0008:37:3008:38:0008:38:3008:39:0008:39:3008:40:0008:40:30Throughput(Kb/s)Timestamp(a)(b)(c)(d)Observerand France is perceptibly degraded relative to the Japan
case.
4.3 Reﬂector-level Experiments
Here, we explore the potential to excite bottlenecks at a
higher level in the Akamai’s multicast network - at reﬂectors,
as explained in Section 3.4 above. Because Akamai uses the
same DNS mechanisms to balance the load by redirecting
edge servers to reﬂectors, the slow load balancing problem
holds for this scenario as well. Moreover, nodes at a higher
level in the multicast hierarchy (reﬂectors) are necessarily
carring higher traﬃc load than the leafs (edge servers). Fi-
nally, given that streams from the same region and the same
channel share the same reﬂectors, i.e., [22], implies that it
is possible to provoke congestion at the reﬂector level, as we
explain below.
Figure 11: Ampliﬁcation scenario
Figure 11 depicts this scenario. Assume that reﬂector R
is associated with n streaming edge servers. Next, assume
that each edge server gets requests for m unique streams.
Inevitably, the number of clients’ requests is ampliﬁed to
n*m at the reﬂector level. Clearly, the larger the number
of edges, n, in an edge server cluster, the more vulnerable
the reﬂector becomes. In Section 3.4, we have demonstrated
that relatively large (e.g., about 10 servers) clusters do exist.
Hence, we select one such cluster to verify this hypothesis.
In particular, we select 7 Akamai’s edge servers in the same
class C subnet as our experimental objects. For each of
the edge servers, we assign one observer and one probing
machine.
Figure 12: Ampliﬁcation experiment
Figure 12 depicts recorded throughput from 3 of the 7 ob-
servers. In general, we repeat the same procedure as above.
The diﬀerence is that our seven nodes probe diﬀerent edge
servers in the class C network. At 09:48:45, the 3 observers
perceive throughput degradation at a very similar pace. In
addition, the lowest throughput points ( 100Kb/s) recorded
by the observers are almost identical to each other. Fur-
ther, after the probing processes are aborted at 09:49:23,
the measured throughput recover almost simultaneously.
The results indicate that thinning did not happen at the
edge servers for two reasons. First, we perform additional
experiments and verify that no local bottlenecks exist be-
tween our machines and the edge servers for the given re-
quest rates.
In particular, we execute our experimental
setup to 7 edge servers individually at diﬀerent times to
make sure the observing stream does not get thinned. Sec-
ond, thinning shown in Figure 12 did not happen at the
edge because other 4 monitors (not shown in the ﬁgure),
which fetch their streams from the same edge cluster, did
not experience any degradation.
We hypothesize that the following happened. The seven
edge servers, while sharing the same channel, are ’backed-up’
by two diﬀerent reﬂectors. When one of them, which served
the three ﬂows shown in the ﬁgure, was overloaded, the thin-
ning happened. Another possibility is that the three ﬂows
experienced a bottleneck at the network level. Whatever
happened, two things are evident. First, it was the probing
machines which created thinning, because it cleared when
they stopped. Second, this experiment demonstrates that
it is possible to excite bottlenecks at a higher level in the
multicast tree, by using edge servers as proxies.
4.4 Source-Level Exploits
Here, we explore a similar, yet probably even more se-
vere vulnerability. In the video-on-demand service (Figure
8), no reﬂectors are used, and streams are fetched directly
from customers’ web servers or Akamai’s net storage (cache
server). In both cases, web server or network storage host-
names are embedded in ARLs, and thus publicly available.
Such a design enables edge servers to be stateless, because
all information needed to redirect traﬃc is already present
in ARLs. Likewise, this approach enables eﬃcient network
storage load balancing using the uniﬁed DNS redirection
mechanism adopted throughout Akamai’s network. Still,
this approach opens the doors to misbehaviors in a simi-
lar way as in the above reﬂector scenario (Figure 11), yet
even more straightforwardly. We discover that the source
hosts embedded in the ARLs can be modiﬁed by clients, thus
disregarding Akamai’s original assignments. Consequently,
misbehaving clients can overload the source hosts by prox-
ying their requests via edge servers. We discuss methods to
resolve such vulnerabilities below.
5. COUNTERMEASURES
Here, we propose a set of countermeasures to help address
the above problems. First, we discuss existing solutions to
related problems that appear applicable to our problem; yet
we argue that such solutions would not solve the problem
in a comprehensive way. Second, we present a set of coun-
termeasures that can dramatically raise the bar for the at-
tackers and hence make the system more secure. Finally, we
discuss how our ﬁndings and countermeasures could be ap-
plied in a general way to improve the resilience of large-scale
distributed and networked systems to DoS attacks.
 0 100 200 300 400 500 600 70009:42:0009:42:0009:43:0009:43:0009:44:0009:44:0009:45:0009:45:0009:46:0009:46:0009:47:0009:47:0009:48:0009:48:0009:49:0009:49:0009:50:0009:50:0009:51:0009:51:0009:52:0009:52:0009:53:0009:53:0009:54:00Throughput(Kb/s)TimestampObserver AObserver BObserver C5.1 Existing Approaches are Not
Comprehensive
5.1.1 Stream Replication
The key problem in the Akamai’s streaming architecture
stems from the slow redirection timescales, which opens the
doors to DoS attacks, i.e., overloading edge servers or reﬂec-
tors. One way to address this problem is to stream the same
packets from multiple sources to a single destination.
In
particular, (i) from several reﬂectors to a single edge server;
and (ii) from several edge servers to a single client. Thus,
even if a reﬂector or an edge server becomes overloaded, the
receiver could eﬀectively recover the stream because it is re-
ceiving packets from multiple sources. According to [22], in
certain scenarios, Akamai may feed a single stream to an
edge server from multiple reﬂectors. However, this happens
only in areas prone to packet losses.
In general, it is infeasible to replicate each of the streams
to each of the reﬂectors or edge servers due to resource limi-
tations. Moreover, we showed that it is possible to create ar-
tiﬁcial streaming ﬂash crowds at reﬂectors or origin servers.
Consequently, by the time multiple reﬂectors get invoked to
help the overloaded reﬂector, the damage has already been
done. On the other side, sending multiple copies of a packet
from multiple edge servers to a client can utilize precious
resources. As we explained above, global-scale streaming
services distribute streaming servers to edge regions that
typically have limited, often moderate bandwidth, which is
shared by the rest of the ISPs’ traﬃc.
5.1.2 Resource-Based Admission Control
Resource-based admission control at the edge servers could
help address certain aspects of the problem. The approach is
to reject all additional incoming requests whenever a server
reaches a resource limit (e.g., a predeﬁned number of streams).
The state of the art streaming servers apply this approach to
preserve the quality perceived by admitted clients. While it
may appear counter productive to reject clients when there
exists suﬃcient spare capacity (at other edge servers), this
is not the case. Our research implies that due to slow DNS
redirections, rejecting clients is required to protect the qual-
ity of the admitted ones.
Unfortunately, resource-based admission control would still
not solve many aspects of the problem.
In particular, (i)
when the resource bottleneck does not reside at the server
side, but rather in the network, server-level admission con-
trol is necessarily not eﬀective. Indeed, given that Akamai’s
streaming edge servers typically do not have any guaran-
teed bandwith at edge networks, but simply share the same
pipes with the rest of the traﬃc, network-level bottlenecks
are quite possible to excite, as we demonstrated above. Like-
wise, (ii) resource-based admission control cannot eﬀectively