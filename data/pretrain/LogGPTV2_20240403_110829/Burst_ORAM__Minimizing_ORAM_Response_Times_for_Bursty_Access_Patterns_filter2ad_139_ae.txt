the idle period, satisfying more requests quickly in both
bursts. Burst ORAM also does better with local level
caching. Without level caching, we start with more avail-
able client space, but the extra server levels yield more
early shufﬂe reads to store, ﬁlling client space sooner.
7.5 NetApp Workload Experiments
The NetApp experiments show how each scheme per-
forms on a realistic, bursty workload. Burst ORAM ex-
ploits the bursty request patterns, minimizing online IO
and delaying shufﬂe IO to achieve near-optimal response
times far lower than ObliviStore’s. Level caching keeps
Burst ORAM’s overall bandwidth costs low.
Figure 10 shows 99.9-percentile response times for
several schemes running the 15-day NetApp workload
for varying bandwidths. All experiments assume a 50ms
network latency. For most bandwidths, Burst ORAM re-
sponse times are orders of magnitude lower than those
760  23rd USENIX Security Symposium 
USENIX Association
12
99.9% Reponse Time Comparison on NetApp Trace
(50ms network latency, 32 TB ORAM, 100 GB client storage)
Burst ORAM
ObliviStore
Burst ORAM No Job Prioritization
Burst ORAM No Level Caching
Without ORAM (Optimal)
0
1
2
3
4
5
6
7
8
9
Available Bandwidth (Gpbs)
(Enlarged Sub-region)
)
s
m
(
d
a
e
h
r
e
v
O
e
s
n
o
p
s
e
R
1E+8 
1E+7 
1E+6 
1E+5 
1E+4 
1E+3 
1E+2 
1E+1 
1E+0 
1E-1 
1E+9
1E+8
1E+7
1E+6
1E+5
1E+4
1E+3
1E+2
1E+1
1E+0
)
s
m
(
i
e
m
T
e
s
n
o
p
s
e
R
%
9
.
9
9
140
130
120
110
100
90
80
80
70
70
60
60
50
40
1E+7 
)
s
m
(
i
e
m
T
e
s
n
o
p
s
e
R
1E+6 
1E+5 
1E+4 
1E+3 
1E+2 
1E+1 
1E+0 
Baseline Percentile Reponse Times, NetApp Trace 
Highest 
Bandwidths 
with Baseline 
over 100ms 
90% 
99% 
99.9% 
50ms Network Latency 
0 
0.1 
0.2 
0.3 
0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1 
1.1 
1.2 
Available Bandwidth (Gpbs) 
Percentile Burst ORAM Overhead, NetApp Trace 
Corresponding 
ORAM Overheads 
under 100ms 
90% 
99% 
99.90% 
50ms Network Latency 
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Figure 10: (Top) Burst ORAM achieves short response
times in bandwidth-constrained settings. Since Oblivi-
Store has high effective cost, it requires more available
client-server bandwidth to achieve short response times.
(Bottom) Burst ORAM response times are comparable
to those of the insecure (without ORAM) scheme.
of ObliviStore and comparable to those of the insecure
baseline. Shufﬂe prioritization and level caching notice-
ably reduce response times for bandwidths under 1Gbps.
Figure 11 compares p-percentile response times for
p values of 90%, 99%, and 99.9%.
It gives absolute
p-percentile response times for the insecure baseline,
and differences between the insecure baseline and Burst
ORAM p-percentile response times (Burst ORAM over-
head). When baseline response times are low, Burst
ORAM response times are also low across multiple p.
The NetApp dataset descriptions [2, 14] do not spec-
ify the total available network bandwidth, but since it
was likely sufﬁcient to allow decent performance, we ex-
pect from Figure 10 that it was at least between 200Mbps
and 400Mbps. Figure 12 compares the overall bandwidth
costs incurred by each scheme running the NetApp work-
load at 400Mbps. Costs for other bandwidths are simi-
lar. Burst ORAM clearly achieves an online cost several
times lower than ObliviStore’s.
Level caching reduces Burst ORAM’s overall cost
from 42X to 29X. Burst ORAM’s higher cost is due to a
combination of factors needed to achieve short response
times. First, Burst ORAM uses the XOR technique,
which is less efﬁcient overall than ObliviStore’s mutu-
ally exclusive level compression. Second, Burst ORAM
handles smaller jobs ﬁrst. Such jobs are more efﬁcient
in the short-term, but since they frequently write blocks
0 
0.1 
0.2 
0.3 
0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1 
1.1 
1.2 
Available Bandwidth (Gpbs) 
Figure 11:
(Top) Insecure baseline (no ORAM) p-
percentile response times for various p. (Bottom) Over-
head (difference) between insecure baseline and Burst
ORAM’s p-percentile response times. Marked nodes
show that when baseline p-percentile response times are
< 100ms, Burst ORAM overhead is also < 100ms.
NetApp Trace Bandwidth Costs 
(50ms network latency, 32 TB ORAM, 100 GB client storage, 400Mbps bandwidth) 
t
s
o
C
h
t
d
w
d
n
a
B
i
40X 
30X 
20X 
10X 
0X 
Offline Cost 
Online Cost 
ObliviStore  Burst ORAM 
without Job 
Prioritization 
Burst ORAM  Burst ORAM 
without Level 
Caching 
Without 
ORAM 
(Optimal) 
Figure 12: To achieve shorter response times, Burst
ORAM incurs higher overall bandwidth cost than Oblivi-
Store, most of which is consumed during idle periods.
Level caching keeps bandwidth costs in check. Job pri-
oritization does not affect overall cost, but does reduce
effective costs and response times (Figures 8, 10).
to small levels, they create more future shufﬂe work. In
ObliviStore, such jobs are often delayed during a large
job, so fewer levels are created, reducing overall cost.
8 Conclusion
We have presented Burst ORAM, a novel Oblivious
RAM scheme based on ObliviStore and tuned for practi-
cal response times on bursty workloads. We presented a
USENIX Association  
23rd USENIX Security Symposium  761
13
novel ORAM architecture for prioritizing online IO, and
introduced the XOR technique for reducing online IO.
We also introduced a novel scheduling mechanism for
delaying shufﬂe IO, and described a level caching mech-
anism that uses extra client space to reduce overall IO.
We simulated Burst ORAM on a real-world workload
and showed that it incurs low online and effective band-
width costs during bursts. Burst ORAM achieved near-
optimal response times that were orders of magnitude
lower than existing ORAM schemes.
Acknowledgements.. This work was supported in part
by grant N00014-07-C-0311 from ONR, the National
Physical Science Consortium Graduate Fellowship; by
NSF under grant number CNS-1314857, a Sloan Re-
search Fellowship, a Google Faculty Research Award;
by the NSF Graduate Research Fellowship under Grant
No. DGE-0946797, a DoD National Defense Science
and Engineering Graduate Fellowship, an Intel award
through the ISTC for Secure Computing, and a grant
from Amazon Web Services.
References
[1] BONEH, D., MAZIERES, D., AND POPA, R. A. Remote
oblivious storage: Making oblivious RAM practical. Manuscript,
http://dspace.mit.edu/bitstream/handle/
1721.1/62006/MIT-CSAIL-TR-2011-018.pdf, 2011.
[2] CHEN, Y., SRINIVASAN, K., GOODSON, G., AND KATZ, R.
Design implications for enterprise storage systems via multi-
dimensional trace analysis. In Proc. ACM SOSP (2011).
[3] CHOW, R., GOLLE, P., JAKOBSSON, M., SHI, E., STADDON,
J., MASUOKA, R., AND MOLINA, J. Controlling data in the
cloud: outsourcing computation without outsourcing control. In
Proc. ACM CCSW (2009), pp. 85–90.
[4] DAMG ˚ARD, I., MELDGAARD, S., AND NIELSEN, J. B. Per-
In TCC
fectly secure oblivious RAM without random oracles.
(2011), pp. 144–163.
[5] DAUTRICH, J., AND RAVISHANKAR, C. Compromising privacy
in precise query protocols. In Proc. EDBT (2013).
[6] FLETCHER, C., VAN DIJK, M., AND DEVADAS, S. Secure
Processor Architecture for Encrypted Computation on Untrusted
Programs.
In Proc. ACM CCS Workshop on Scalable Trusted
Computing (2012), pp. 3–8.
[7] GENTRY, C., GOLDMAN, K., HALEVI, S.,
JULTA, C.,
RAYKOVA, M., AND WICHS, D. Optimizing ORAM and using
it efﬁciently for secure computation. In PETS (2013).
[8] GOLDREICH, O. Towards a theory of software protection and
simulation by oblivious rams. In STOC (1987).
[9] GOLDREICH, O., AND OSTROVSKY, R. Software protection and
simulation on oblivious RAMs. Journal of the ACM (JACM) 43,
3 (1996), 431–473.
[10] GOODRICH, M., AND MITZENMACHER, M. Privacy-preserving
access of outsourced data via oblivious RAM simulation. Au-
tomata, Languages and Programming (2011), 576–587.
[11] GOODRICH, M. T., MITZENMACHER, M., OHRIMENKO, O.,
AND TAMASSIA, R. Privacy-preserving group data access via
stateless oblivious RAM simulation.
In Proc. SODA (2012),
SIAM, pp. 157–167.
[12] ISLAM, M., KUZU, M., AND KANTARCIOGLU, M. Access pat-
tern disclosure on searchable encryption: Ramiﬁcation, attack
and mitigation. In Proc. NDSS (2012).
[13] KUSHILEVITZ, E., LU, S., AND OSTROVSKY, R. On the
(in)security of hash-based oblivious RAM and a new balancing
scheme. In Proc. SODA (2012), SIAM, pp. 143–156.
[14] LEUNG, A. W., PASUPATHY, S., GOODSON, G., AND MILLER,
E. L. Measurement and analysis of large-scale network ﬁle sys-
tem workloads. In Proc. USENIX ATC (2008), USENIX Associ-
ation, pp. 213–226.
[15] LORCH, J. R., PARNO, B., MICKENS, J. W., RAYKOVA, M.,
AND SCHIFFMAN, J. Shroud: Ensuring private access to large-
scale data in the data center. FAST (2013), 199–213.
[16] MAAS, M., LOVE, E., STEFANOV, E., TIWARI, M., SHI, E.,
ASANOVIC, K., KUBIATOWICZ, J., AND SONG, D. PHAN-
TOM: Practical oblivious computation in a secure processor. In
ACM CCS (2013).
[17] MAYBERRY, T., BLASS, E.-O., AND CHAN, A. H. Efﬁcient
In NDSS
private ﬁle retrieval by combining ORAM and PIR.
(2014).
[18] OSTROVSKY, R., AND SHOUP, V. Private information storage
(extended abstract). In STOC (1997), pp. 294–303.
[19] PINKAS, B., AND REINMAN, T. Oblivious RAM revisited. In
CRYPTO (2010).