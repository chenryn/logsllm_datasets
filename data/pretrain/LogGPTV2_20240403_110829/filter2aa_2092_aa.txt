Betrayed by the keyboard
How what you type can give you away
Matt Wixey
Research Lead, PwC UK Cyber Security
www.pwc.com
Building a secure 
digital society.
PwC │ 2
Disclaimer
•
The views and opinions expressed here are not 
necessarily those of PwC
•
This content is presented for educational purposes only
•
What this presentation isn’t…
PwC │ 3
Introduction
Matt Wixey
• Research Lead for the Cyber Security BU
• Work on the Ethical Hacking team
• PhD student at UCL
• Previously worked in LEA doing technical R&D
PwC │ 4
Why this talk?
• Based on some research I did at UCL
• Interest in side-channel attacks
• Humans have side-channels too
• Previous work on forensic linguistics
• First degree = English Literature and Language
PwC │ 5
Agenda
• What is attribution?
• Problems 
• Case Linkage Analysis
• Experimentation
• Results
• Implications
• Summary
PwC │ 6
What is attribution?
• Why would we want to do it?
• Benefits
• Types
• Approaches
PwC │ 7
What is attribution?
• Identifying an attacker’s location? 
• Hunker et al, 2008; Wheeler and Larsen, 2003
• Identify the country or organisation behind an attack?
• Rid and Buchanan, 2014
• “Determining who is responsible for a hostile cyber act”?
• Mejia, 2014
• “We must find a person, not a machine” 
• Clark and Landau, 2011
PwC │ 8
Benefits of attribution
• Deterring future attacks
• Improving defences
• Interrupting and disrupting attacks (Hunker et al, 2008)
• Does attribution actually lead to deterrence? (Guitton, 2012)
• Regardless, attribution is a desirable outcome (depending on 
which side you’re on!)
PwC │ 9
Types of attribution
• Hutchins et al, 2011:
Atomic
Computed
Behavioural
PwC │ 10
Problems with attribution
• Hiding atomic IOCs
• Issues with computed IOCs
• Lack of tangible benefits from 
behavioural IOCs
PwC │ 11
Hiding atomic IOCs
• These are the most effective identifiers
• Easy to resolve (usually)
• But also easiest to spoof/anonymise/obfuscate
PwC │ 12
Issues with computed IOCs
• Changes to malware make it harder
• Other methods:
• Correlating activity with office hours in timezones (Rid & Buchanan, 
2014; CloudHopper)
• Deanonymising developers through artefacts (Caliskan et al, 2015)
• Similar malware capabilities (Moran & Bennett, 2013; Symantec, 2011)
• Distinguishing humans vs bots (Filippoupolitis et al, 2014)
PwC │ 13
Mo methods, mo problems
• Less focused on individuals
• Sufficient if aim is to identify a state/sponsor
• Challenge is then legal/procedural
PwC │ 14
Behavioural profiling
• Less attribution
• More trying to understand who hacks, and why
• Motivation, skills, attack behaviours (Landreth, 1985)
• Attitudes and culture (Chiesa et al, 2008; Watters et al, 2012)
• Psychological (Shaw et al, 1998)
PwC │ 15
Attack profiling
• Humans vs bots
• Filippoupolitis et al, 2014: Skill, education, typing speed, mistakes, etc
• Skill level
• Salles-Loustau et al, 2011: SSH honeypot. Stealth, enumeration, malware 
familiarity, protection of target
• Attacker behaviour
• Ramsbrock et al, 2007: Specific actions undertaken
PwC │ 16
The problem
• Profiling attackers is interesting
• Next logical step is comparison
• To what extent is an attacker’s profile similar to another’s?
• Not really explored
PwC │ 17
• The idea
• Discovering case linkage analysis
• Benefits of linking offences
• What case linkage analysis is (and isn’t)
• Methodology
• Example
• Exceptions
Case Linkage Analysis
PwC │ 18
The idea
• I had an idea (rare occurrence - to be celebrated)
• Lurking in OSCP labs a few years ago
• Discussing attack techniques, commands, methodologies
• Casual observation 1: everyone has their own way of doing things
• Casual observation 2: this way of doing things rarely changes
PwC │ 19
Science!
• This seems obvious
• My first degree was English Lit
• Could pretty much make it up as you went along
• Apparently, in science, you have to prove stuff
• Can’t just write “this seems obvious” 
• Science is hard 
PwC │ 20
Discovering case linkage analysis
• How could I empirically test this?
• Came across “Case Linkage Analysis”
• Methodology used in crime science literature
• Designed to link separate crimes to common offenders
• Based on behavioural aspects (Woodhams & Grant, 2006)
PwC │ 21
Benefits of linking offences
• Can attribute previously unsolved crimes
• Can investigate offences under one grouping – focused resources 
• Useful evidentially
• Database of offences grows = better chance of success
• A minority of offenders commit the majority of crimes (?)
• Not necessarily true of crime generally
• But more accurate with specialist crimes
PwC │ 22
Benefits of linking offences
• Best method for linking = physical evidence (DNA, fingerprints, etc)
• Highly accurate, but:
• May be absent or inconclusive (Grubin et al, 1997)
• Does not really apply to cyber attacks
• Closest approximation is forensic artefacts, but these are not always unique
• Time-consuming and expensive (Craik and Patrick, 1994)
PwC │ 23
What case linkage analysis is
• Uses behavioural evidence
• Things the offender does during the commission of an offence
• Classify granular crime behaviours into domains
• Create linked and unlinked pairs of offences
• Compare with behaviours in other offences
• Determine degree of similarity
PwC │ 24
What case linkage analysis isn’t
• It’s not offender profiling
• Offender profiling makes inferences about the offender
• Based on assumption of consistency between criminal and 
everyday behaviour (Canter, 2000)
• Based on this behaviour, I infer that the perpetrator is a balding but 
charismatic researcher from the UK
PwC │ 25
What case linkage analysis isn’t
• CLA: statistical inferences about the similarity of 2 or 
more offences, based on common behaviours
• Crime A, perpetrated by Matt “Charismatic But Balding” 
Wixey, has several features in common with Crime B
• Therefore, Wixey may have also committed Crime B
PwC │ 26
Case linkage analysis in context
• Two key assumptions
• Behavioural consistency
• Offenders display similar offending behaviours across crimes
• Behavioural distinctiveness
• The way an offender commits crimes is characteristic of that offender
• And distinguishable from the style of other offenders (Canter, 1995)
PwC │ 27
Case linkage analysis in context
• Both assumptions must be present
• Otherwise CLA is unlikely to be useful
• e.g. homicide: dumping a body in a remote location is 
consistent for many offenders
• But not distinctive
PwC │ 28
Case linkage analysis in context
• Individuals have stable, distinctive responses (Shoda et al, 1994)
• Cognitive-affective personality system (CAPS)
• Mischel & Shoda, 1995; Mischel, 1999
• System of goals, expectations, beliefs, plans, strategies, memories
• CAPS is consistent yet distinctive (Zayas et al, 2002)
PwC │ 29
Case linkage analysis in context
• Assumptions of stability/distinctiveness made in other fields
• Forensic linguistics
• Word and sentence length; slang; typos; errors; syntax; idiolect; article 
frequency; syllable count; punctuation; hapax legomena; sentence length; 
stylistics
• Language is socially acquired, continually – so may change
• Some biometrics
• Typing speed; typos; typing habits
PwC │ 30
Case linkage analysis – does it work?
• Consensus: yes, in most cases
• Observed variance significantly smaller in linked crimes
• Grubin et al, 1997; Mokros & Alison, 2002
• Significant evidence for cross-situational consistency
• Both criminal and non-criminal behaviours (Tonkin et al, 2008)
PwC │ 31
Methodology
• Separate behaviours into domains
• Calculate similarity coefficient
• Input into logistic regression model
• Determine optimal combination of domains
• Receiver Operating Characteristic (ROC) curves
PwC │ 32
Methodology
• Lots of stats stuff
• I hate stats. I am bad at stats.
• Will try and explain this with a worked example
• None of that “left as an exercise for the reader” nonsense 
PwC │ 33
Example
• Two burglaries, A and B
• We want to find out if the same offender did both
• Define a dichotomous dependent variable
• This is a Y/N question, and we’re trying to ‘predict’ the answer
• And find out what variables contribute more
• “Are these two crimes linked?”
PwC │ 34
Example
• Take granular behaviours and put them into domains
• e.g. Entry behaviours = method of entry; tools used; time of day; etc
• Property behaviours = property taken; property damaged; and so on
• These are our independent variables
• Make these dichotomous by turning into yes/no questions
• e.g. Entry behaviours: “was a screwdriver used? Was a crowbar used? 
Was a window open? Were the occupants home?” etc
PwC │ 35
Example
• Then apply a similarity coefficient
• Index of similarity
• Jaccard’s is coarse, but the measure of choice (Tonkin et al, 2008)
• x = count of behaviours present in both
• y = count of behaviours present in A but not in B
• z = inverse of y
PwC │ 36
Example
• 1 = perfect similarity
• 0 = perfect dissimilarity
• 1 coefficient per domain
• Ignores joint non-occurrences
• This is a concern when dealing with police data
• Something may have been present, but not recorded
• Less of a concern in this case
PwC │ 37
Example
• Each coefficient into direct logistic regression model
• Predictive analysis
• “To what extent does a given factor contribute to an outcome?”
• e.g. “to what extent does being a smoker contribute to the risk of having a 
heart attack?” 
• Or “does similarity in the entry behaviours domain predict whether or 
not the two burglaries are linked?”
PwC │ 38
Example
• Logistic regression tells us:
• Whether a variable is positively or negatively correlated with the outcome
• How well a given variable fits with the data
• The amount of variance that a given variable explains
• A p-value (probability of seeing this result if the null hypothesis is true)
• Run for each domain
PwC │ 39
Example
• Then forward stepwise logistic regression
• Start with one domain
• Add a domain at each step
• If this contributes to the model’s predictive power, keep it
• Else discard it
• Determines optimal combination of domains
PwC │ 40
Example
• Regression results into ROC curves
• Graphical representation
• x (probability of false positive) against y (probability of true positive)
• More reliable measure of predictive accuracy
• Based on area under the curve (AUC)
PwC │ 41
Example
• Overcomes statistical issue of using pairs from same sample 
(Tonkin et al, 2008)
• No reliance on arbitrary thresholds (Santtila et al, 2005)
• Measure of overall predictive accuracy (Swets, 1988)
PwC │ 42
Example
http://www.statisticshowto.com/wp-content/uploads/2016/08/ROC-curve.png
• Diagonal: no better than 
chance
• The higher the AUC value, the 
greater the predictive accuracy
• 0.5 – 0.7 = low
• 0.7 – 0.9 = good
• 0.9 – 1.0 = high 
• Swets, 1988
PwC │ 43
Exceptions
• Some offences are less suitable, e.g. homicide
• Bateman & Salfati, 2007; Harbort & Mokros, 2001; Sorochinski & Salfati, 2010
• Some offenders show more distinctiveness than others
• Bouhana et al, 2016
• Some behaviours less consistent, e.g. property stolen in burglaries
• Bennell & Canter, 2002; Bennell & Jones, 2005
PwC │ 44
Exceptions
• MO is a learned behaviour, and offenders develop
• Pervin, 2002; Douglas & Munn, 1992
• Offenders will change behaviours in response to events
• Donald & Canter, 2002
• Behaviours under offender’s control more likely to be stable
• Furr & Funder, 2004; Hettema & Hol, 1998
• So offences involving victim interaction may differ
• e.g. whether victim fights back / runs / shouts for help, etc
PwC │ 45
Exceptions
• Most research only applied to solved crimes
• Woodhams & Labuschagne, 2012
• Relatively small samples
• Only serial offences
• Slater et al, 2015
PwC │ 46
Experimentation
• Concept
• Research design
• Hypothesis
• Analysis
• Results
PwC │ 47
Concept
• Could CLA be applied to network intrusions?
• Specifically, where attacker has code execution
• Has never been done before
• Take granular behaviours (keystrokes, commands, etc)
• Apply CLA methodology
PwC │ 48
Research design
• Common approach historically: use police reports