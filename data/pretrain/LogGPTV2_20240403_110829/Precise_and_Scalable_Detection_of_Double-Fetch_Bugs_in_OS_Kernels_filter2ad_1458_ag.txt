for Loop loop : cf g.loops() do
if loop.isAtomic() then
changed ← f alse;
for Node node : path do
if node.isLoopNode() then
for int i = 0; i )
affect the double-fetch pair
In : F - A function contains a double-fetch pair 
In :  - A double-fetch pair callsites in F
Out : P - A set of paths
1 Si ← ∅;
2 Sv ← ∅;
3 G ← F ’s CFG;
/* do backward slicing to identify instructions that can
*/
4 Vv ← C1.params ∪ C2.params;
5 while !Vv.empty() do
v ← Vv.pop();
6
Sv.insert(v);
7
if v.isInst() then
8
Si.insert(v);
9
for Use u : v.operands() do
10
11
12
13
14
15
16 end
if !Sv.ﬁnd(u) then
Vv.append(u);
end
end
end
/* do forward slicing to identify instructions that are
affected by the double-fetch pair
17 Vv ← C1.params ∪ C2.params;
18 Sv.clear();
19 while !Vv.empty() do
v ← Vv.pop();
20
Sv.insert(v);
21
if v.isInst() then
22
Si.insert(v);
23
24
25
26
27
28
29
30 end
31 reﬁneCFG(G, Si) ;
32 P ← getPaths(G) ;
end
for User u : v.users() do
if !Sv.ﬁnd(u) then
Vv.append(u);
end
end
*/
676
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
C. Samples of double-fetch bug patches with different patching strategies
kernel/events/core.c | 2 ++
1 file changed, 2 insertions(+)
1
2
3
4 diff --git a/kernel/events/core.c b/kernel/events/core.c
5 index ee20d4c..c0d7946 100644
6 --- a/kernel/events/core.c
7 +++ b/kernel/events/core.c
8 @@ -9611,6 +9611,8 @@ static int perf_copy_attr(struct perf_event_attr __user *uattr,
9
10
11
12 +
13 +
14
15
if (attr->__reserved_1)
attr->size = size;
return -EFAULT;
if (ret)
return -EINVAL;
Fig. 8: The patch to perf_copy_attr follows the override strategy
}
ucmsg = cmsg_compat_nxthdr(kmsg, ucmsg, ucmlen);
net/compat.c | 7 +++++++
1 file changed, 7 insertions(+)
1
2
3
4 diff --git a/net/compat.c b/net/compat.c
5 index 6ded6c8..2238171 100644
6 --- a/net/compat.c
7 +++ b/net/compat.c
8 @@ -185,6 +185,13 @@ int cmsghdr_from_user_compat_to_kern(struct msghdr *kmsg, struct sock *sk,
9
10
11
12 +
13 +
14 +
15 +
16 +
17 +
18 +
19
20
21
/* Ok, looks like we made it. Hook it up and return success. */
kmsg->msg_control = kcmsg_base;
kmsg->msg_controllen = kcmlen;
* check the length of messages copied in is the same as the
* what we get from the first loop
*/
if ((char *)kcmsg - (char *)kcmsg_base != kcmlen)
goto Einval;
/*
Fig. 9: The patch to cmsghdr_from_user_compat_to_kern follows the abort on change strategy
*/
block/scsi_ioctl.c | 8 +++++++-
1 file changed, 7 insertions(+), 1 deletion(-)
1
2
3
4 diff --git a/block/scsi_ioctl.c b/block/scsi_ioctl.c
5 index 7440de4..8fe1e05 100644
6 --- a/block/scsi_ioctl.c
7 +++ b/block/scsi_ioctl.c
8 @@ -463,7 +463,13 @@ int sg_scsi_ioctl(struct request_queue *q, struct gendisk *disk, fmode_t mode,
9
10
11
12 -
13 +
14 +
15 +
16 +
17 +
18 +
19 +
20
21
22
err = -EFAULT;
req->cmd_len = cmdlen;
if (copy_from_user(req->cmd, sic->data, cmdlen))
memcpy(req->cmd, &opcode, sizeof(opcode));
if (copy_from_user(req->cmd + sizeof(opcode),
* avoid copying the opcode twice
*/
if (in_len && copy_from_user(buffer, sic->data + cmdlen, in_len))
sic->data + sizeof(opcode), cmdlen - sizeof(opcode)))
goto error;
/*
Fig. 10: The patch to sg_scsi_ioctl follows the incremental copy strategy
677
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
is = file->private_data;
if (!lp)
else {
/*
printk(KERN_DEBUG "isdn_ppp_write: lp == NULL\n");
return count;
if (lp->isdn_device isdn_channel huptimer = 0;
* Don’t reset huptimer for
* LCP packets. (Echo requests).
*/
if (copy_from_user(protobuf, buf, 4))
unsigned char protobuf[4];
/*
* Don’t reset huptimer for
* LCP packets. (Echo requests).
*/
return -EFAULT;
proto = PPP_PROTOCOL(protobuf);
if (proto != PPP_LCP)
lp->huptimer = 0;
isdn_net_local *lp;
struct ippp_struct *is;
int proto;
unsigned char protobuf[4];
drivers/isdn/i4l/isdn_ppp.c | 37 +++++++++++++++++++++++++------------
1 file changed, 25 insertions(+), 12 deletions(-)
1
2
3
4 diff --git a/drivers/isdn/i4l/isdn_ppp.c b/drivers/isdn/i4l/isdn_ppp.c
5 index 6c44609..cd2b3c6 100644
6 --- a/drivers/isdn/i4l/isdn_ppp.c
7 +++ b/drivers/isdn/i4l/isdn_ppp.c
8 @@ -825,7 +825,6 @@ isdn_ppp_write(int min, struct file *file, const char __user *buf, int count)
9
10
11
12 -
13
14
15
16 @@ -839,24 +838,28 @@ isdn_ppp_write(int min, struct file *file, const char __user *buf, int count)
17
18
19
20 -
21 -
22 -
23 -
24 -
25 -
26 -
27 -
28 -
29 +
30 +
31 +
32 +
33 +
34 +
35 +
36 +
37 +
38 +
39 +
40 +
41
42 -
43
44 +
45
46
47
48
49
50
51 +
52
53
54
55 @@ -869,11 +872,21 @@ isdn_ppp_write(int min, struct file *file, const char __user *buf, int count)
56
57
58
59 -
60 +
61 +
62
63
64
65
66 +
67 +
68 +
69 +
70 +
71 +
72 +
73 +
74 +
75
76
77
}
skb_reserve(skb, hl);
if (copy_from_user(skb_put(skb, count), buf, count))
cpy_buf = skb_put(skb, count);
if (copy_from_user(cpy_buf, buf, count))
{
lp->dialstate == 0 &&
(lp->flags & ISDN_NET_CONNECTED)) {
unsigned short hl;
struct sk_buff *skb;
unsigned char *cpy_buf;
/*
printk(KERN_DEBUG "ppp xmit: len %d\n", (int) skb->len);
isdn_ppp_frame_log("xmit", skb->data, skb->len, 32, is->unit, lp->ppp_slot);
* Don’t reset huptimer for
* LCP packets. (Echo requests).
*/
proto = PPP_PROTOCOL(cpy_buf);
if (proto != PPP_LCP)
lp->huptimer = 0;
* we need to reserve enough space in front of
* sk_buff. old call to dev_alloc_skb only reserved
kfree_skb(skb);
return -EFAULT;
}
/*
if (lp->isdn_device isdn_channel drv[lp->isdn_device]->flags & DRV_FLAG_RUNNING) &&
if (is->debug & 0x40) {
Fig. 11: The patch to isdn_ppp_write follows the refactoring to single-fetch strategy
678
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply.