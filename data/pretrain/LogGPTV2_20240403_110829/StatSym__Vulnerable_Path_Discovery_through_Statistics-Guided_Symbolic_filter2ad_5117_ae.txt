all matching execution paths that are no more than τ nodes
different) at node send response():enter with node index 71.
This candidate path is marked as infeasible. With StatSym
support, we are able to explore function defang() fairly quickly
using the guidance from a candidate path identiﬁed in the
second round. The predicate associated with this candidate
node (len(str) > 999.5) further helps prune the search space
for KLEE because additional forks of states relating to every
loop iteration and switch-case branches can be eliminated
for strings with shorter lengths. Overall, StatSym used two
candidate paths to ﬁnally discover the vulnerable path for
thttpd.
3) CTree
and Grep: The buffer overﬂow bug in
CTree is triggered when an environment variable named
stonesoup stack buf f er 64 with length over 64 bytes is
read by CTree, which overﬂows a ﬁxed stack buffer of size 64
L1L11P1L4P5L12P3L9P1L5P6L1L2P3L3P4L4P5L9P1L5P6L1L11P1L4P5L9P1L5P6Start pointLiCandidate nodePredicatepi Failure PointStatSym’s statistical analysis module and symbolic execu-
tion module, respectively. Note that in all these experiments,
StatSym is able to discover the vulnerable path. In particular,
as sampling rate increases from 20% to 100%,
the time
spent by statistical analysis increases from 1.6 seconds to 1.9
seconds in polymorph and from 43.2 seconds to 58.7 seconds
in CTree because of the larger sized log ﬁles.
As more program proﬁle information is logged at runtime
and becomes available for statistical analysis, the accuracy of
results improve (i.e., increasing the probability of ﬁnding the
vulnerable path). This is able to trim down the search space
for symbolic executor signiﬁcantly. Thus, the time spent by
symbolic execution module to discover the vulnerable path
decreases from 213.0 to 179.5 for polymorph and from 2.4
to 1.6 for CTree. These experimental results illustrate an in-
teresting trade-off between more accurate inference (requiring
increased runtime information and overhead) and larger search
space that needs to be explored by symbolic execution. We
note that with smarter techniques to implement partial logging,
we are likely to achieve the same effectiveness for StatSym
with even lower sampling rates.
VIII. RELATED WORK
Statistical analysis has been employed to construct bug-
related predicates [9], [10], [11], [37] to facilitate testing
and debugging. In practice, this approach relies on partial
logging (often through random sampling) of target programs
to amortize monitoring overheads
[9]. Prior works have
studied predicate construction algorithms for bug localization,
identifying multiple bugs [11], [38], [10]. Although these
techniques can assist testing and debugging, their outputs still
require manual analysis. Another line of work builds bug
detection models using machine learning techniques, such as
mining control-ﬂow graphs [39] and hidden Markov model
for anomaly detection [40], and modiﬁed support vector ma-
chine [41]. Different from those works, StatSym focuses on
automated vulnerable program path diagnosis and debugging.
Symbolic execution, model checking and tainting are well
studied techniques for formal veriﬁcation, static analysis or
test generation [13], [14], [42], [17], [43], [44], [45]. In [45],
symbolic execution and symbolic reachability analysis are
combined to improve the effectiveness of analyzing branches.
This is further improved by ﬁtness-guided symbolic execu-
tion [46], partial or directed symbolic execution [18], [19],
[47], complex path constraints solving techniques [48], [49],
[50], [51], [52], and concolic execution to generate concrete
inputs for paths coverage [53], [54]. Although they are able
to provide formal veriﬁcation of program vulnerabilities, these
techniques suffer from prohibitive overheads especially when
analyzing large software programs that contain an exponential
number of potential execution paths.
Li et al. [31], [30] leverage program runtime information for
program debugging and security enhancement. Jin el al. [20]
propose a bug synthesis tool that reproduces the observed ﬁeld
failures using execution data collected from users. However,
this approach can have some practical limitations where log-
ging entire (or most of) call sequences at runtime is infeasible.
In this paper, by taking advantage of incomplete logging at
a very low sampling rate, StatSym is able to minimize the
runtime overhead. Crameri et al. [19] propose a technique that
utilizes branch selection history to guide symbolic execution
for debugging. This approach only offers a local view of
program execution (at each individual branch) and thus are less
effective in identifying the entire vulnerable path. In contrast,
StatSym employs predicate and candidate path construct for a
global search and is semantically more powerful. For example,
consider the example of a loop that is branch-heavy: a branch
direction for the loop only implies a direction choice for KLEE
in this iteration, however, a statistically generated predicate
that governs the number of iterations will be able to guide
KLEE more effectively in reducing its overall search space.
IX. CONCLUSION
In this paper, we proposed StatSym, a novel framework
for vulnerable path discovery, which harnesses the scalability
of statistical analysis and the rigorousness of symbolic ex-
ecution. Program runtime information is analyzed using the
StatSym statistical analysis module to construct predicates
and identify candidate vulnerable paths. Our statistical-guided
symbolic executor leverages the paths to search vulnerable
paths in a prioritized manner. We evaluated StatSym on
four applications polymorph from Bugbench, CTree, Grep
from NIST STONESOUP benchmarks and thttpd. Our results
show StatSym has a 15× speedup to ﬁnd vulnerable paths
compared to the pure symbolic execution - KLEE, and is able
to correctly identify the vulnerabilities for all applications even
when a pure symbolic executor fails in three out of the four
applications.
ACKNOWLEDGMENT
This work was supported by the US Ofﬁce of Naval Re-
search (ONR) under Award N00014-15-1-2210. Any opinions,
ﬁndings, conclusions, or recommendations expressed in this
article are those of the authors, and do not necessarily reﬂect
those of ONR.
REFERENCES
[1] M. C. Libicki, L. Ablon, and T. Webb, The Defenders Dilemma:
Charting a Course Toward Cybersecurity. Rand Corporation, 2015.
[2] P. Akulavenkatavara, J. Girouard, and E. Ratliff, “Mitigating Malicious
Exploitation of A Vulnerability in A Software Application by Selectively
Trapping Execution along A Code Path,” 2010. US Patent 7,845,006.
[3] J. S. Mertoguno, “Human Decision Making Model for Autonomic Cyber
Systems,” International Journal on Artiﬁcial Intelligence Tools, 2014.
[4] Z. Guo, X. Wang, J. Tang, X. Liu, Z. Xu, M. Wu, M. F. Kaashoek, and
Z. Zhang, “R2: An Application-level Kernel for Record and Replay,” in
USENIX Conference on Operating Systems Design and Implementation,
2008.
[5] K. Veeraraghavan, D. Lee, B. Wester, J. Ouyang, P. M. Chen, J. Flinn,
and S. Narayanasamy, “DoublePlay: Parallelizing Sequential Logging
and Replay,” ACM Transactions on Computer Systems, 2012.
[6] D. Subhraveti and J. Nieh, “Record and Transplay: Partial Checkpointing
for Replay Debugging across Heterogeneous Systems,” in ACM SIG-
METRICS joint international conference on Measurement and modeling
of computer systems, 2011.
[7] G. W. Dunlap, S. T. King, S. Cinar, M. A. Basrai, and P. M. Chen,
“ReVirt: Enabling Intrusion Analysis through Virtual-machine Logging
and Replay,” ACM SIGOPS Operating Systems Review, 2002.
[8] R. McNally, K. Yiu, D. Grove, and D. Gerhardy, “Fuzzing: The State
of the Art,” tech. rep., DTIC Document, 2012.
[9] B. Liblit, A. Aiken, A. X. Zheng, and M. I. Jordan, “Bug Isolation via
Remote Program Sampling,” ACM SIGPLAN Notices, 2003.
[10] P. Arumuga Nainar, T. Chen, J. Rosin, and B. Liblit, “Statistical Debug-
ging Using Compound Boolean Predicates,” in International Symposium
on Software Testing and Analysis, ACM, 2007.
[11] B. Liblit, M. Naik, A. X. Zheng, A. Aiken, and M. I. Jordan, “Scalable
Statistical Bug Isolation,” ACM SIGPLAN Notices, 2005.
[12] H. Xue, Y. Chen, F. Yao, Y. Li, T. Lan, and G. Venkataramani, “SIM-
BER: Eliminating Redundant Memory Bound Checks via Statistical
Inference,” in International Conference on ICT Systems Security and
Privacy Protection-IFIP SEC, Springer, 2017.
[13] C. Cadar, D. Dunbar, and D. Engler, “KLEE: Unassisted and Automatic
Generation of High-Coverage Tests for Complex Systems Programs,” in
USENIX Conference on Operating Systems Design and Implementation,
2008.
[14] I. Doudalis, J. Clause, G. Venkataramani, M. Prvulovic, and A. Orso,
“Effective and Efﬁcient Memory Protection Using Dynamic Tainting,”
IEEE Transactions on Computers, vol. 61, pp. 87–100, 2012.
[15] S. Bucur, V. Ureche, C. Zamﬁr, and G. Candea, “Parallel Symbolic
Execution for Automated Real-world Software Testing,” in European
Conference on Computer Systems, ACM, 2011.
[16] G. Venkataramani, I. Doudalis, Y. Solihin, and M. Prvulovic, “Mem-
Tracker: An Accelerator for Memory Debugging and Monitoring,” ACM
Transactions on Architecture and Code Optimization, vol. 6, no. 2,
pp. 5:1–5:33, 2009.
[17] J. Shen, G. Venkataramani, and M. Prvulovic, “Tradeoffs in Fine-grained
Heap Memory Protection,” in Workshop on Architectural and System
Support for Improving Software Dependability, ACM, 2006.
[18] K.-K. Ma, K. Y. Phang, J. S. Foster, and M. Hicks, “Directed Symbolic
Execution,” in International Static Analysis Symposium, Springer, 2011.
[19] O. Crameri, R. Bianchini, and W. Zwaenepoel, “Striking A New Balance
between Program Instrumentation and Debugging Time,” in European
Conference on Computer Systems, 2011.
[20] W. Jin and A. Orso, “BugRedux: Reproducing Field Failures for In-
house Debugging,” in International Conference on Software Engineer-
ing, IEEE Press, 2012.
[21] D. Yuan, J. Zheng, S. Park, Y. Zhou, and S. Savage, “Improving Software
Diagnosability via Log Enhancement,” ACM Transactions on Computer
Systems, vol. 30, no. 1, pp. 4:1–4:28, 2012.
[22] D. Yuan, S. Park, P. Huang, Y. Liu, M. M. Lee, X. Tang, Y. Zhou,
and S. Savage, “Be Conservative: Enhancing Failure Diagnosis with
Proactive Logging,” in USENIX Conference on Operating Systems
Design and Implementation, 2012.
[23] ACME Lab, “Thttpd.” http://www.acme.com/software/thttpd/.
[24] S. Lu, Z. Li, F. Qin, L. Tan, P. Zhou, and Y. Zhou, “BugBench: A
Benchmark for Evaluating Bug Detection Tools,” in Workshop on the
Evaluation of Software Defect Detection Tools, 2005.
[25] NIST, “IARPA STONESOUP Phase 3.” https://samate.nist.gov/SARD/
testsuite.php.
[26] J.-C. Laprie, “Dependable Computing: Concepts, Limits, Challenges,”
in International Symposium On Fault-Tolerant Computing, 1995.
[27] E. Buchanan, R. Roemer, H. Shacham, and S. Savage, “When Good
Instructions go bad: Generalizing Return-oriented Programming to
RISC,” in ACM SIGSAC Conference on Computer and Communications
Security, 2008.
[28] CVE, “Vulnerability of thttpd in defang function.” http://www.cvedetails.
com/cve/2003-0899.
[29] Y. Zheng and X. Zhang, “Path Sensitive Static Analysis of Web
Applications for Remote Code Execution Vulnerability Detection,” in
International Conference on Software Engineering, IEEE, 2013.
[30] Y. Li, F. Yao, T. Lan, and G. Venkataramani, “POSTER: Semantics-
Aware Rule Recommendation and Enforcement for Event Paths,” in
International Conference on Security and Privacy in Communication
Systems, pp. 572–576, Springer, 2015.
[31] Y. Li, F. Yao, T. Lan, and G. Venkataramani, “SARRE: Semantics-
Aware Rule Recommendation and Enforcement for Event Paths on
Android,” IEEE Transactions on Information Forensics and Security,
vol. 11, no. 12, pp. 2748–2762, 2016.
[32] R. Agrawal and R. Srikant, “Fast Algorithms for Mining Association
Rules,” in International Conference on Very Large Data Bases, 1994.
[33] N. Nethercote and J. Seward, “Valgrind: A Framework for Heavyweight
Dynamic Binary Instrumentation,” ACM Sigplan notices, vol. 42, no. 6,
pp. 89–100, 2007.
[34] P. J. Guo, “A Scalable Mixed-level Approach to Dynamic Analysis of
C and C++ Programs,” Master’s thesis, MIT, 2006.
[35] “Verisec Suite.” https://se.cs.toronto.edu/index.php/Verisec Suite.
[36] E. Wong, L. Zhang, S. Wang, T. Liu, and L. Tan, “DASE: Document-
assisted Symbolic Execution for Improving Automated Software Test-
ing,” in International Conference on Software Engineering, IEEE, 2015.
[37] C. Liu, X. Yan, L. Fei, J. Han, and S. P. Midkiff, “SOBER: Statistical
Model-based Bug Localization,” ACM SIGSOFT Software Engineering
Notes, 2005.
[38] S. Wang, F. Khomh, and Y. Zou, “Improving Bug Localization Using
Correlations in Crash Reports,” in International Conference on Mining
Software Repositories, IEEE, 2013.
[39] X. Shu, D. Yao, and N. Ramakrishnan, “Unearthing Stealthy Program
Attacks Buried in Extremely Long Execution Paths,” in ACM SIGSAC
Conference on Computer and Communications Security, 2015.
[40] K. Xu, K. Tian, D. D. Yao, and B. G. Ryder, “A Sharper Sense of Self:
Probabilistic Reasoning of Program Behaviors for Anomaly Detection
with Context Sensitivity,” in International Conference on Dependable
Systems & Networks, IEEE/IFIP, 2016.
[41] Z. Gu, K. Pei, Q. Wang, L. Si, X. Zhang, and D. Xu, “LEAPS:
Detecting Camouﬂaged Attacks with Statistical Learning Guided by
Program Analysis,” in International Conference on Dependable Systems
& Networks, IEEE/IFIP, 2014.
[42] G. Venkataramani, I. Doudalis, Y. Solihin, and M. Prvulovic, “Flexi-
taint: A programmable Accelerator for Dynamic Taint Propagation,” in
International Symposium on High Performance Computer Architecture,
IEEE, 2008.
[43] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf, “Bugs as
Deviant Behavior: A General Approach to Inferring Errors in Systems
Code,” in SIGOPS Operating Systems Review, ACM, 2001.
[44] D. Engler, B. Chelf, A. Chou, and S. Hallem, “Checking System Rules
Using System-speciﬁc, Programmer-written Compiler Extensions,” in
USENIX Conference on Operating Systems Design and Implementation,
2000.
[45] M. Baluda, G. Denaro, and M. Pezze, “Bidirectional Symbolic Analysis
for Effective Branch Testing,” IEEE Transactions on Software Engineer-
ing, 2015.
[46] T. Xie, N. Tillmann, J. De Halleux, and W. Schulte, “Fitness-guided
Path Exploration in Dynamic Symbolic Execution,” in International
Conference on Dependable Systems & Networks, IEEE/IFIP, 2009.
[47] C. Zamﬁr and G. Candea, “Execution Synthesis: A Technique for
Automated Software Debugging,” in European Conference on Computer
Systems, ACM, 2010.
[48] A. Aquino, F. A. Bianchi, M. Chen, G. Denaro, and M. Pezz`e, “Reusing
Constraint Proofs in Program Analysis,” in International Symposium on
Software Testing and Analysis, ACM, 2015.
[49] P. A. Abdulla, M. F. Atig, Y.-F. Chen, L. Hol´ık, A. Rezine, P. R¨ummer,
and J. Stenman, “Norn: An SMT Solver for String Constraints,” in
International Conference on Computer Aided Veriﬁcation, 2015.
[50] J. D. Scott, P. Flener, and J. Pearson, “Constraint Solving on Bounded
String Variables,” in International Conference on Integration of AI and
OR Techniques in Constraint Programming, Springer, 2015.
[51] X. Xie, Y. Liu, W. Le, X. Li, and H. Chen, “S-looper: Automatic
Summarization for Multipath String Loops,” in International Symposium
on Software Testing and Analysis, ACM, 2015.
[52] P. Saxena, P. Poosankam, S. McCamant, and D. Song, “Loop-extended
Symbolic Execution on Binary Programs,” in International Symposium
on Software Testing and Analysis, ACM, 2009.
[53] J. Zhang, X. Chen, and X. Wang, “Path-oriented Test Data Generation
Using Symbolic Execution and Constraint Solving Techniques,” in
International Conference on Software Engineering and Formal Methods,
IEEE, 2004.
[54] P. Dinges and G. Agha, “Targeted Test Input Generation Using Sym-
bolic Concrete Backward Execution,” in International Conference on
Automated Software Engineering, ACM/IEEE, 2014.