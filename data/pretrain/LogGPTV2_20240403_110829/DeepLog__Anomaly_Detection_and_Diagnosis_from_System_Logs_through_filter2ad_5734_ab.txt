2.3 (cid:135)reat model
DeepLog learns the comprehensive and intricate correlations and
pa(cid:138)erns embedded in a sequence of log entries produced by normal
system execution paths. Henceforth, we assume that system logs
themselves are secure and protected, and an adversary cannot a(cid:138)ack
the integrity of a log itself. We also assume that an adversary cannot
modify the system source code to change its logging behavior and
pa(cid:138)erns. (cid:140)at said, broadly speaking, there are two types of a(cid:138)acks
that we consider.
(1) A(cid:138)acks that lead to system execution misbehavior and hence
anomalous pa(cid:138)erns in system logs. For instance, Denial of Service
(DoS) a(cid:138)acks which may cause slow execution and hence perfor-
mance anomalies re(cid:131)ected in the log timestamp di(cid:130)erences from
the parameter value vector sequence; a(cid:138)acks causing repeated
server restarts such as Blind Return Oriented Programming (BROP)
a(cid:138)ack [5] shown as too many server restart log keys; and any at-
tack that may cause task abortion such that the corresponding log
sequence ends early and/or exception log entries appear.
(2) A(cid:138)acks that could leave a trace in system logs due to the
logging activities of system monitoring services. An example is
suspicious activities logged by an Intrusion Detection System (IDS).
3 ANOMALY DETECTION
3.1 Execution path anomaly
We (cid:128)rst describe how to detect execution path anomalies using the
log key sequence. Since the total number of distinct print statements
(that print log entries) in a source code is constant, so is the total
number of distinct log keys. Let K = {k1, k2, . . . , kn} be the set of
distinct log keys from a log-producing system source code.
Once log entries are parsed into log keys, the log key sequence
re(cid:131)ects an execution path that leads to that particular execution
order of the log print statements. Let mi denote the value of the
key at position i in a log key sequence. Clearly, mi may take one of
the n possible keys from K, and is strongly dependent on the most
recent keys that appeared prior to mi.
We can model anomaly detection in a log key sequence as a multi-
class classi(cid:128)cation problem, where each distinct log key de(cid:128)nes
a class. We train DeepLog as a multi-class classi(cid:128)er over recent
context. (cid:140)e input is a history of recent log keys, and the output is a
probability distribution over the n log keys from K, representing the
probability that the next log key in the sequence is a key ki ∈ K.
Figure 2 summarizes the classi(cid:128)cation setup. Suppose t is the
sequence id of the next log key to appear. (cid:140)e input for classi-
(cid:128)cation is a window w of the h most recent log keys. (cid:140)at is,
w = {mt−h, . . . , mt−2, mt−1}, where each mi is in K and is the log
key from the log entry ei. Note that the same log key value may
appear several times in w. (cid:140)e output of the training phase is a
model of the conditional probability distribution Pr[mt = ki|w] for
each ki ∈ K(i = 1, . . . , n). (cid:140)e detection phase uses this model to
make a prediction and compare the predicted output against the
observed log key value that actually appears.
Training stage. (cid:140)e training stage relies on a small fraction of log
entries produced by normal execution of the underlying system.
For each log sequence of length h in the training data, DeepLog
Training StageDetection StageLog KeyAnomaly Detection model......Parameter ValueAnomaly Detection model for each log keyWorkflowsnormal executionlog fileLog Parser........................each log entry = log key + parameter value vectorA new log entryLog Parserparameter value vector+Train modelConstruct workflowAnomaly?Yes  No,checkvectorAnomaly?YesDiagnosisUpdatemodel iffalse positivelog keyTrain modelsNoFigure 2: An overview of log key anomaly detection model.
updates its model for the probability distribution of having ki ∈ K
as the next log key value. For example, suppose a small log (cid:128)le
resulted from normal execution is parsed into a sequence of log
keys: {k22, k5, k11, k9, k11, k26}. Given a window size h = 3, the
input sequence and the output label pairs to train DeepLog will be:
{k22, k5, k11 → k9}, {k5, k11, k9 → k11}, {k11, k9, k11 → k26}.
Detection stage. DeepLog performs anomaly detection in an on-
line, streaming se(cid:138)ing. To test if an incoming log key mt (parsed
from an incoming log entry et ) is to be considered normal or abnor-
mal, we send w = {mt−h, ..., mt−1} to DeepLog as its input. (cid:140)e
output is a probability distribution Pr[mt |w] = {k1 : p1, k2 : p2, ...,
kn : pn} describing the probability for each log key from K to
appear as the next log key value given the history.
In practice, multiple log key values may appear as mt . For in-
stance, if the system is a(cid:138)empting to connect to a host, then mt
could either be ‘Waiting for * to respond’ or ‘Connected to *’; both
are normal system behavior. DeepLog must be able to learn such
pa(cid:138)erns during training. Our strategy is to sort the possible log
keys K based on their probabilities Pr[mt |w], and treat a key value
as normal if it’s among the top ❕ candidates. A log key is (cid:131)agged
as being from an abnormal execution otherwise.
3.1.1 Traditional N-gram language model. (cid:140)e problem of as-
cribing probabilities to sequences of words drawn from a (cid:128)xed
vocabulary is the classic problem of language modeling, widely
studied by the natural language processing (NLP) community [24].
In our case, each log key can be viewed as a word taken from
the vocabulary K. (cid:140)e typical language modeling approach for
assigning probabilities to arbitrarily long sequences is the N-gram
model. (cid:140)e intuition is that a particular word in a sequence is
only in(cid:131)uenced by its recent predecessors rather than the entire
history. In our se(cid:138)ing, this approximation is equivalent to se(cid:138)ing
Pr(mt = ki|m1, . . . , mt−1) = Pr(mt = ki|mt−N , . . . , mt−1) where
N denotes the length of the recent history to be considered.
For training, we can calculate this probability using relative fre-
quency counts from a large corpus to give us maximum likelihood
estimates. Given a long sequence of keys {m1, m2, . . . , mt }, we
can estimate the probability of observing the ith key ki using the
relative frequency counts of {mt−N , . . . , mt−1, mt = ki} with re-
spect to the sequence {mt−N , . . . , mt−1}. In other words, Pr(mt =
ki|m1, . . . , mt−1) = count(mt−N , . . ., mt−1, mt = ki)/count(mt−N ,
. . ., mt−1). Note that we will count these frequencies using a sliding
window of size N over the entire key sequence.
To apply the N-gram model in our se(cid:138)ing, we simply use N as
the history window size, i.e., we set h = N in our experiments when
the N-gram model is used where h is the history sliding window
size as depicted in Figure 2. We use this as a baseline method.
3.1.2 The LSTM approach. In recent years, neural language mod-
els that use recurrent neural networks have been shown to be highly
e(cid:130)ective across various NLP tasks [3, 25]. Compared to a N-gram
Figure 3: A detailed view of log key anomaly detection
model using stacked LSTM.
language model, a LSTM-based one can encode more intricate pat-
terns and maintain long-range state over a sequence [34]. Complex
pa(cid:138)erns and interleaving log entries from concurrent tasks in a sys-
tem log can render a traditional language model less e(cid:130)ective. (cid:140)us,
DeepLog uses a LSTM neural network [18] for anomaly detection
from a log key sequence.
Given a sequence of log keys, a LSTM network is trained to
maximize the probability of having ki ∈ K as the next log key value
as re(cid:131)ected by the training data sequence. In other words, it learns
a probability distribution Pr(mt = ki|mt−h, . . ., mt−2, mt−1) that
maximizes the probability of the training log key sequence.
Figure 3 illustrates our design. (cid:140)e top of the (cid:128)gure shows a
single LSTM block that re(cid:131)ects the recurrent nature of LSTM. Each
LSTM block remembers a state for its input as a vector of a (cid:128)xed
dimension. (cid:140)e state of an LSTM block from the previous time
step is also fed into its next input, together with its (external) data
input (mt−i in this particular example), to compute a new state
and output. (cid:140)is is how historical information is passed to and
maintained in a single LSTM block.
A series of LSTM blocks form an unrolled version of the recurrent
model in one layer as shown in the center of Figure 3. Each cell
maintains a hidden vector Ht−i and a cell state vector Ct−i. Both
are passed to the next block to initialize its state. In our case, we
use one LSTM block for each log key from an input sequence w (a
window of h log keys). Hence, a single layer consists of h unrolled
LSTM blocks.
Within a single LSTM block, the input (e.g. mt−i) and the previ-
ous output (Ht−i−1) are used to decide (1) how much of the previous
cell state Ct−i−1 to retain in state Ct−i, (2) how to use the current
input and the previous output to in(cid:131)uence the state, and (3) how
to construct the output Ht−i. (cid:140)is is accomplished using a set of
gating functions to determine state dynamics by controlling the
amount of information to keep from input and previous output, and
the information (cid:131)ow going to the next step. Each gating function
is parameterized by a set of weights to be learned. (cid:140)e expressive
capacity of an LSTM block is determined by the number of memory
DeepLogInput: h recent log keys up toOutput: conditional probability of next log key given the input recent sequence LSTMblockOutput of last state is forwarded as current input stateLSTMblockLSTMblockDeepLogOutputInputLSTMblockLSTMblockLSTMblock     Roll outStack upLSTMblockLSTMblockLSTMblockLSTMblockunits (i.e. the dimensionality of the hidden state vector H). Due to
space constraints, we refer the reader to NLP primers (e.g., [12])
for a formal characterization of LSTMs.
(cid:140)e training step entails (cid:128)nding proper assignments to the weights
so that the (cid:128)nal output of the sequence of LSTMs produces the de-
sired label (output) that comes with inputs in the training data set.
During the training process, each input/output pair incrementally
updates these weights, through loss minimization via gradient de-
scent. In DeepLog, an input consists of a window w of h log keys,
and an output is the log key value that comes right a(cid:137)er w. We use
the categorical cross-entropy loss for training.
A(cid:137)er training is done, we can predict the output for an input
(w = {mt−h, . . . , mt−1}) using a layer of h LSTM blocks. Each log
key in w feeds into a corresponding LSTM block in this layer.
If we stack up multiple layers and use the hidden state of the
previous layer as the input of each corresponding LSTM block in
the next layer, it becomes a deep LSTM neural network, as shown at
the bo(cid:138)om of Figure 3. For simplicity, it omits an input layer and an
output layer constructed by standard encoding-decoding schemes.
(cid:140)e input layer encodes the n possible log keys from K as one-hot
vectors. (cid:140)at is, a sparse n-dimensional vector −→
u i is constructed
for the log key ki ∈ K, such that −→
u i[i] = 1 and −→
u i[j] = 0 for all
other j (cid:44) i. (cid:140)e output layer translates the (cid:128)nal hidden state into
a probability distribution function using a standard multinomial
logistic function to represent Pr[mt = ki|w] for each ki ∈ K.
layers, but more layers can be used.
(cid:140)e example at the bo(cid:138)om of Figure 3 shows only two hidden
3.2 Parameter value and performance anomaly
(cid:140)e log key sequence is useful for detecting execution path anom-
alies. However, some anomalies are not shown as a deviation from
a normal execution path, but as an irregular parameter value. (cid:140)ese
parameter value vectors (for the same log key) form a parame-
ter value vector sequence, and these sequences from di(cid:130)erent log
keys form a multi-dimensional feature space that is important for
performance monitoring and anomaly detection.
Baseline approach. A simple approach is to store all parameter
value vector sequences into a matrix, where each column is a pa-
rameter value sequence from a log key k (note that it is possible to
have multiple columns for k depending on the size of its parameter
value vector). Row i in this matrix represents a time instance ti.
Consider the log entries in Table 1 as an example. (cid:140)ere are
3 distinct log key values in this example, and the sizes of their
parameter value vectors are 2, 2, and 1 respectively. Hence, row
1 in this matrix represents time instance t1 with values [t1 − t0,
(cid:128)le1Id, null, null, null]. Similarly, row 2 and row 3 are [null, null,
t2 − t1, 0.61, null] and [null, null, null, null, t3 − t2] respectively.
We may also ask each row to represent a range of time instances
so that each row corresponds to multiple log messages within that
time range and becomes less sparse. But the matrix will still be very
sparse when there are many log key values and/or exists some large
parameter value vectors. Furthermore, this approach introduces
a delay to the anomaly detection process, and it is also di(cid:129)cult to
(cid:128)gure out a good value for the length of each range.
Given this matrix, many well-known data-driven anomaly detec-
tion methods can be applied, such as principal component analysis
(PCA) and self-organizing maps (SOM). (cid:140)ey are useful towards
capturing correlation among di(cid:130)erent feature dimensions. How-
ever, a major limitation of this method in the context of log data is
that o(cid:137)en times the appearance of multiple log keys at a particular
time instance is equally likely. For instance, the order of k1 and
k2 in Table 1 is arbitrary due to concurrently running tasks. (cid:140)is
phenomena, and the fact that the matrix is sparse, render these tech-
niques ine(cid:130)ective in our se(cid:138)ing. Lastly, they are not able to model
auto-correlation that exists in a parameter value vector sequence
(regular pa(cid:138)erns over time in a single vector sequence).
Our approach. DeepLog trains a parameter value anomaly detec-
tion model by viewing each parameter value vector sequence (for a
log key) as a separate time series.
Consider the example in Table 1. (cid:140)e time series for the parame-
ter value vector sequence of k2 is: {[t2−t1, 0.61],[t(cid:48)
1, 1]}. Hence,
our problem is reduced to anomaly detection from a multi-variate
time series data. It is possible to apply an LSTM-based approach
again. We use a similar LSTM network as shown in Figure 3 to
model a multi-variate time series data, with the following adjust-
ments. Note that a separate LSTM network is built for the parameter
value vector sequence of each distinct log key value.
2−t(cid:48)
Input. (cid:140)e input at each time step is simply the parameter value
vector from that timestamp. We normalize the values in each vector
by the average and the standard deviation of all values from the
same parameter position from the training data.
Output. (cid:140)e output is a real value vector as a prediction for the
next parameter value vector, based on a sequence of parameter
value vectors from recent history.
Objective function for training. For the multi-variate time series
data, the training process tries to adjust the weights of its LSTM
model in order to minimize the error between a prediction and an
observed parameter value vector. (cid:140)us, mean square loss is used to
minimize the error during the training process.
Anomaly detection. (cid:140)e di(cid:130)erence between a prediction and an
observed parameter value vector is measured by the mean square
error (MSE). Instead of se(cid:138)ing a magic error threshold for anomaly
detection purpose in an ad-hoc fashion, we partition the train-
ing data to two subsets: the model training set and the validation
set. For each vector −→
v in the validation set, we apply the model
produced by the training set to calculate the MSE between the pre-