a single access
can be represented with the access type (read or
write), READ inode->i size, or without it, ACCESS
inode->i size. Similarly, the same access can be rep-
resented with the structure ﬁeld, READ inode->i size,
or without it, READ inode. Theoretically, ﬁner granu-
larity causes more false negatives and fewer false pos-
itives for violation detection compared to coarser gran-
ularity. The choice of granularity can greatly affect the
accuracy of rule inference and violation detection. Al-
most all previous rule generation and violation detection
techniques [3, 9, 10, 11, 20, 22, 30] choose ﬁxed gran-
ularity without quantitatively evaluating how good their
choice is.
function
Interestingly,
In our work, we quantitatively evaluate the impact of
different rule granularity on rule inference and violation
detection. This approach is orthogonal to our automatic
rule inference techniques and can be applied to other rule
extraction techniques.
our
if we
then the inferred
do not distinguish the ﬁelds,
the
operation
code-level
and
check
failing to
security file unlink() is the same,
distinguish the two different operations. Using our
ﬁnest granularity, AutoISES can disambiguate the
two similar operations (the unlink operation contains
for
security inode link()
security
sensitive
results
show that
the link operation does
READ inode->i size, but
not). Our results also show that on average our most
ﬁne-grained rules causes 33% fewer false positives than
the most coarse-grained rules, and detected all of the true
violations that the most coarse-grained rules can detect.
This indicates rule granularity signiﬁcantly affects
violation detection accuracy and could be considered a
tuning parameter for other rule inference and violation
detection tools to reduce false positives.
On the other hand, coarse-grained rules help us dis-
cover high level rules that are shared by different secu-
rity check functions, which ﬁne-grained rules fail to un-
cover (examples shown in Section 5.3). These results
call for attention that different levels of granularity have
measurable advantages and disadvantages, and one could
quantitatively evaluate the tradeoffs when designing rule
inference and violation detection tools in order to choose
the most suitable granularity.
In summary, AutoISES closes an important gap in
achieving secure software systems. To have truly secure
software systems, not only must one have a secure de-
sign, but the implementation must faithfully realize the
design. To verify that the implementation faithfully real-
izes the design, one must write a correct code-level spec-
iﬁcation which can be veriﬁed by automatic tools such as
a model checker or a static analyzer. AutoISES allows
the security speciﬁcations to be automatically extracted
from the actual implementation, alleviating the develop-
ers from the burden of manually writing speciﬁcations
while at the same time signiﬁcantly improving the accu-
racy of the speciﬁcation.
1.3 Paper Layout
The remainder of the paper is organized as follows. Sec-
tion 2 provides background information about MAC,
DAC and the assumptions we make in our work. In Sec-
tion 3, we present an overview of our approach, includ-
ing some formal deﬁnitions and how we quantitatively
evaluate rule granularity, followed by a detailed design
in Section 4. Our methodology and experimental results
are described in Section 5, and Section 6 discusses and
summarizes our key techniques, their generalization and
limitations. In Section 7 a discussion of the related work
is presented, and ﬁnally we conclude with Section 8.
2 Background and Assumptions
2.1 DAC and MAC Background
The traditional Linux kernel uses Discretionary Access
Control (DAC), meaning the access control policies are
set at the discretion of the owner of the objects. For ex-
ample, the root user typically sets the password ﬁle to be
382 
17th USENIX Security Symposium 
USENIX Association
writable only by herself. However, if the root user mis-
takenly makes the password ﬁle publicly writable, then
the whole system is at risk. This example shows one ma-
jor deﬁciency of DAC, that is, mistakes of individual pol-
icy decisions can result in the breach of security for the
entire system. Mandatory Access Control (MAC) is pro-
posed to address this issue. In a MAC system, there ex-
ists a system wide security policy, such as “high-integrity
ﬁle must not be modiﬁed by low-integrity users”. Even
if the root mistakenly grants write permissions on the
password ﬁle to everyone, when a normal user tries to
write the password ﬁle the attempt would fail because it
is against the system-wide policy. MAC is considerably
“safer” than DAC, but it is also more complex and more
difﬁcult to implement, especially for large systems like
Linux [18]. It took Linux developers about two years to
add MAC to the Linux kernel, and since then it has un-
dergone many rounds of reﬁnements and extensions. It
is expected that its development will continue well into
the future.
2.2 Assumptions
We make the following assumptions in our work.
Reasonably mature code base: Similar to previous
work on automatic rule extraction [3, 10, 11, 20, 22], we
assume that the code we work with is reasonably ma-
ture, i.e., it is mostly correct and already contains an im-
plementation of the security architecture that is mostly
working. This does not mean that software development
ceases. In fact, the software might still be under active
development and new features continue to be added. Al-
most all open source and proprietary software falls into
this category, therefore this assumption does not signiﬁ-
cantly limit the applicability of this work.
Software developers not adversarial: We assume
that software developers are trusted and will not delib-
erately write code to defeat our rule generation mecha-
nism. This in general holds for majority of the software
that exists today, i.e., we believe that the majority of soft-
ware developers intend to write correct and secure soft-
ware. In the limited cases where this assumption does
not hold [25], there exist static analysis techniques that
can detect such malicious code [29]. However, detecting
malicious code in general is challenging and remains an
active open research problem.
Kernel and hypervisor in the trusted computing
base: For the two pieces of software that we experi-
mented with, namely, the Linux kernel and the Xen hy-
pervisor (virtual machine monitor), we assume that both
are part of the trusted computing base. Thus, the manda-
tory access control is in place to prevent user level or
guest OS level processes from breaking security poli-
cies. This assumption implies that only if a user process
or a guest OS process can bypass the MAC mechanism
(placed in the kernel or the hypervisor) do we consider it
a breach of security. The kernel or the hypervisor is free
to modify the data structures on its own behalf (e.g., for
bookkeeping purposes) without going through the secu-
rity checks. This assumption is adopted from the MAC
architecture of the Linux kernel and Xen hypervisor.
3 Overview of Our Approach
In this section, we will present our high level design
choices of rule inference and violation detection; for-
mal deﬁnitions of security rules, security sensitive oper-
ations, and security violations; and how we explore dif-
ferent levels of rule granularity. The detailed design will
be discussed in the next section.
3.1 Our approach
Our approach consists of two steps, as shown in Figure 3.
In the ﬁrst step, we generate security speciﬁcations auto-
matically from the source code. The input to the gen-
erator is the source code and the set of security check
functions. The output of this step is a set of security
rules containing a security check function and a security
sensitive operation represented by a group of data struc-
ture accesses as shown in Figure 2 (a) (the advantages
of using a group of data structure accesses to represent
a sensitive operation are discussed in Section 3.2).
In
the second step, AutoISES takes the source code and
the rules automatically inferred in the ﬁrst step as the
input, and outputs ranked security violations. Note that
these automatically inferred rules can be used directly by
AutoISES without manual examination, which reduces
human involvement to its minimum.
Source code
A list of security
check functions
Step 1: Automatically infer security
specifications
Security
specifications
Step 2: Automatically detect violations
to inferred security specifications
A ranked list of
security violations
Figure 3: The analysis ﬂow of AutoISES.
Step 1: Inferring Security Rules This paper focuses
on inferring security rules which mandate that a secu-
rity sensitive operation must be protected by a security
check function, i.e., the sensitive operation must not be
allowed to proceed if the security check fails. In order
to effectively check such rules against the source code to
USENIX Association  
17th USENIX Security Symposium 
383
detect violations, it is crucial to specify the security rule
at the source code level. Unfortunately, in reality such
rules are usually not documented. Therefore, our goal is
to automatically infer such rules from the source code.
To infer one rule, we want
to discover, for the
same security check function, what ﬁxed security sen-
sitive operation must be protected by it. We can in-
fer this security rule from two angles: (1) we search
for all instances of the same security check function
(e.g., security file permission()) and discover
what sensitive operation is frequently protected by (e.g.,
performed after) the check function, or (2) we search
for all instances of the same security sensitive operation
(e.g., the 22 data structure accesses shown in Figure 2(a))
and then check what security check function is frequently
used to protect (e.g., invoked before) the operation. We
use the ﬁrst method, because it is relatively easy to know
what the security check functions are in the source code
(usually documented), but knowing what security sen-
sitive operations are in the source code itself is still a
challenge (not documented). Speciﬁcally, we look for all
instances of the same security check in the source code
and collect sensitive operations protected by it. If this se-
curity check is frequently used to protect a ﬁxed sensitive
operation, represented by a ﬁxed set of data structure ac-
cesses, we infer a security rule: this set of data structure
accesses must be protected by this security check func-
tion. Our rationale is that released software is mostly
correct, so we can infer correct behavior from it.
It is not uncommon that more than one security check
function is required to protect one sensitive operation. In
such cases, our inference approach still works because
it will infer several separate rules, one for each security
check function. The set of rules related to the same sensi-
tive operation combined can detect violations where not
all of the check functions are invoked to protect the op-
eration.
We can infer security rules statically or dynamically.
While a dynamic approach is more precise, it has poorer
coverage because only executed code is analyzed. As
we study large software with millions lines of code, a
dynamic approach may not be sufﬁcient, which is con-
ﬁrmed by previous work [9, 13]. Therefore, we use inter-
procedural and ﬂow-insensitive static program analysis
for rule inference. A more detailed description of our
static analysis techniques can be found in Section 4.3.
In summary, our tool AutoISES automatically infers
sensitive operations in the form of a group of data struc-
ture accesses that are commonly or frequently protected
by the same security check function, given a list of secu-
rity check functions. Similar to previous rule inference
studies [3, 10, 11, 20, 22], we cannot discover all secu-
rity rules from the source code alone (discussed in Sec-
tion 6.3). However, it is effective to infer some important
security rules from source code, and detect previously
unknown security vulnerabilities.
Step 2: Detecting Violations The goal of this step is to
use the rules inferred above to detect security violations.
Similarly, we use inter-procedural and ﬂow-insensitive
analysis for violation detection. As we already know
which data structure accesses represent the security sen-
sitive operation from an inferred rule, we can search for
instances of the security sensitive operation that are not
protected by the security check function, indicating se-
curity violations.
Speciﬁcally, AutoISES starts from each root function
(automatically generated starting function for our anal-
ysis and detection as discussed later in Section 4.2.1),
and collects all data structure accesses and calls to
security check functions.
Then it calculates the
accessV iolationCount, which is the number of ac-
cesses in the rule that are not protected by the par-
ticular security check function.
if an
access in the rule is performed without being pro-
tected by a security check function, AutoISES in-
creases the accessV iolationCount by one. We then
use the accessV iolationCount for violation ranking
– the higher the accessV iolationCount is, the more
likely it is a true violation. We also allow our tool
users to set up a threshold and only report violations
with its accessV iolationCount higher than the thresh-
old. Users can always set the threshold to zero to see all
violation reports.
Speciﬁcally,
Untrusted-space exposability analysis One key tech-
nique we used to greatly reduce false positives is our
untrusted-space exposability analysis. As we consider
the kernel and the hypervisor to be our trusted comput-
ing base, security sensitive operations in kernel space and
hypervisor that do not interact with the untrusted space
(user space or guest OS processes), do not need to be pro-
tected by a security check function. On the other hand,
if such sensitive operations interact with the untrusted
space, e.g., are performed by a user space process via
system calls, or use data copied from user space, then a
security check may be mandatory. Since it is typical that
a large number of sensitive operations are not exposed
to the untrusted space, most of the detected violations
would be false alarms, which is detrimental to a detec-
tion tool.
To reduce such false positives, we perform a simple
trusted space exposability study. Speciﬁcally, we com-
piled a list of user space interface functions that are
known a priori to be exposed to user space, e.g., sys-
tem calls such as sys read() and hypercalls. Then,
AutoISES checks what sensitive operations are reach-
able from these interface functions. If a sensitive oper-
ation that can be exposed to the untrusted space is not
384 
17th USENIX Security Symposium 
USENIX Association
protected by the proper security check function, we re-
port the violation as an error; otherwise, we report the
violation as a warning. Our goal is to ensure most of the
errors are true violations, but we still generate the warn-
ings so that developers can examine them if they want
to. This approach relies on easy-to-obtain information
(system calls and hypercalls) to automatically reduce the
number of false positives.
3.2 Formal Deﬁnitions
Based on our reasoning above, we formally deﬁne the
rule inferencing problem, security sensitive operations,
security rules, our inference rule, and violations.
Rule Inferencing Problem Given the target source
code and a set of n kernel security check functions,
CheckSet = {Check1, ..., Checkn}, each of which can
check if a subject (e.g., a process), is authorized to per-
form a certain security sensitive operation, Opi (e.g.,
read, where 1 ≤ i ≤ n), on a certain object (e.g., a ﬁle)
we want to uncover security speciﬁcations or security
rules, Rulei, in the form of a pair, (Checki, Opi), man-
dating that a security sensitive operation Opi, must be
protected,  Opi <protected Checki.
Representing Security Sensitive Operations There
are several ways to represent security sensitive opera-
tions at the code level. We can use a list of data structures
that the operation manipulates, a list of functions the op-
eration invokes, or the combination of the two. The list
can be ordered or not ordered, indicating whether we re-
quire these accesses to be performed in any particular
order.
InstanceOf (Opi)u
We use data structure accesses to represent a secu-
rity sensitive operation, because it has two advantages
over using function calls. First, it can infer rules that
that
<protected
function call based analysis would not be able to ﬁnd.
For example, if a sensitive operation is performed after
a check function via different function calls, e.g., A and
B, by using function A and B to represent the operation,
we may mistakenly consider nothing is commonly pro-
tected by the check function and miss the rule. Zoom-
ing into the functions will allow us to ﬁnd the shared
data structure accesses in both A and B. Additionally,
we can detect more violations by using data structure
accesses. For examples, if we ﬁnd that a check func-
tion always protects function call A at many places, but