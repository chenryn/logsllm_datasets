2f + 1
3f + 1
2f + 1
Quorum
f + 1 replicas
1 replica + middlebox
f + 1 replicas
Consistency
Strong
Weak
Strong
Prophecy [5], a middlebox-based approach that mimics clients
towards the BFT replicas and is tailored to improve the
performance of read-heavy workloads; and (3) with Troxy.
Table I summarizes the three implementations regarding their
read optimization approaches and consistency level.
The baseline protocol implements a PBFT-like read optimiza-
tion, which optimistically executes non-ordered read requests
and accepts a result as soon as f + 1 identical replies are
received. In case of a failed quorum due to concurrent write
operations, the client has to resend the request and ask for a
regular ordering to enforce linearizability. Prophecy deploys
a cache in a middlebox placed between the client and the
replicas. This cache stores the results of the ordered reads to
reduce the execution cost of read requests with large payloads
for read-heavy applications. It requires only one reply from
a randomly chosen replica to be compared with the cached
result. However it trades consistency for a higher throughput:
the reply of a read operation reﬂects the state of the latest
read, so in the worst case it would return a stale but correct
result to the client. In contrast, Troxy actively manages the
fast-read cache to reﬂect the state changes of the latest write,
thus guaranteeing strong consistency.
For the baseline, we run JMeter on the same machine as
the client-side library, and use a local socket connection for
message forwarding. As for Prophecy, JMeter is running on a
separate machine, and establishes a secure socket connection
to the client machine where the middlebox is located. Since
Troxy provides transparent access to clients, JMeter can directly
connect to the replicas without any modiﬁcations. Besides that,
we also run a stand-alone version of the HTTP service using
Jetty (v9.4) [40] to see its original performance.
in
the local network and with 100± 20 ms network delay. The
GET and POST requests are issued with a payload size
of 200 B, while the response message size ranges between
4 KB and 18 KB. The average latency to execute requests
The measurements are conducted in two scenarios:
Read only
10% Write
6
4
1
1
)
s
m
(
y
c
n
e
t
a
L
8
7
6
5
4
3
2
1
0
200
180
160
140
120
100
80
60
40
20
0
3.6
2
3.8
2.8
Read only
10% Write
103
105
115
108.6
158
119
Jetty
Prophecy
BL
Troxy
Jetty
Without delay
Prophecy
With 100 ± 20 ms delay
BL
105
108
Troxy
Fig. 11. HTTP service in local network and with network delay.
68
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:31:39 UTC from IEEE Xplore.  Restrictions apply. 
is reported in Figure 11. In both scenarios, the stand-alone
implementation (Jetty) indicates the original performance of the
service. In case of a local network, both the baseline and Troxy
keep a low latency, with an overhead of at most 1.8 ms, while
the two socket connections in Prophecy contribute to a latency
almost twice as high. When the network delay is applied, the
latency of the baseline implementation raises dramatically, as
its reply voter is located on the client machine. The network
delay between the client and the replicas signiﬁcantly impacts
the latency observed by the client. For Prophecy and Troxy, as
their voters are close to the replicas (on the middlebox machine
and in the fast-read cache on a replica, respectively), this extra
round-trip impact is negligible. The results of this measurement
show that in a wide-area network, using Troxy-backed BFT
systems is beneﬁcial for user-facing legacy applications.
VII. RELATED WORK
Traditional BFT state machine protocols consist of libraries
attached to both client and server [1], [3], [4], [6], [41]. The
client-side library is mainly responsible for service invocation,
message transfer, and reply voting. In contrast, Troxy provides
a transparent and secure connection between the client and the
replicated service by leveraging trusted computing technology.
The complexity of the replicated fault-tolerant system, in terms
of protocol, exchanged messages, and interface is therefore
hidden from the clients and legacy clients can interact with
BFT services without any changes.
Troxy is not the ﬁrst protocol to explore the usage of trusted
subsystems in BFT systems. A2M-PBFT [15] is based on
a trusted append-only log, enabling it to reduce the number
of required replicas compared to traditional protocols from
3f + 1 to 2f + 1. TrInc [22] is a subsystem providing
trusted counters that can be employed as a less complex
replacement for the trusted log of A2M-PBFT. MinBFT and
MinZyzzyva [14] are two protocols that directly make use of a
counter-based trusted subsystem. The most recent representative
of this class of protocols is Hybster [13]. Hybster is also
based on trusted counters and 2f + 1 replicas. However, it
overcomes the difﬁculties of other hybrid protocols such as a
time-dependent memory demand and exhibits a signiﬁcantly
improved performance by introducing the consensus-oriented
parallelization [2] into the hybrid fault model. Besides using
an FPGA-based trusted subsystem, CheapBFT [21] saves
resources by exploiting passive replication: f out of 2f + 1
required replicas remain passive and are activated only in case
a faulty behavior is suspected. Similarly, V-PR [23] employs
trusted computing technology, named XMHF/TrustVisor [42],
to design a fully-passive replicated system for tolerating
Byzantine failures. By leveraging a trusted subsystem, all those
protocols have a lower complexity, in terms of exchanged
messages and number of replicas, compared to traditional BFT
protocols. Nevertheless, none of the aforementioned systems
are transparent from the client’s point of view.
Prophecy [5] executes a special component between the
client and the server and thus does not require modiﬁcations at
the client side. As in Troxy, this component needs to be trusted
and acts as a proxy by receiving the client request, collecting
the replies from the replicas and sending a single reply back to
the client. However, compared to Troxy, Prophecy (i) requires
a large trusted computing base comprised of a middlebox,
operating system, and network stack; and (ii) is not able to
ensure strong consistency.
SPARE [43] is transparent to the clients by locating the reply
voter on the server side. SPARE executes replicas inside virtual
machines, thus requiring a virtualization layer and hypervisor,
and considers a speciﬁc fault model where the replicas can
exhibit Byzantine behavior; the hypervisor and reply voter fail
by crashing only. The practicality of SPARE is limited by its
large trusted computing base, composed of an entire hypervisor,
a management operating system, and the reply voter.
Thema [44] and BFT-WS [45] extend the classic approach
of having a generic client-side library and a server-side library
with an additional web-service library. This library collects
identical request messages from the different replicas, sends the
request to a non-replicated web service, and forwards the reply
back to the replicas. Thus, these works address an orthogonal
problem and could be combined with Troxy.
Avoine et al. [46] present a deterministic fair exchange
algorithm running in untrusted hosts with security modules.
The untrusted hosts are unable to forge valid protocol messages
due to the security modules comprising the entire consensus-
protocol implementation. In contrast, the goal of BFT protocols
such as Hybster (the protocol used by Troxy) is to keep the
trusted computing base as small as possible by implementing
most protocol parts in the untrusted host.
There is a growing number of systems that utilize SGX to
secure computing in the context of cloud computing [31], [47],
perform application level secure data processing [48], and
enable trusted client-side computing and ofﬂoading [49], [50],
just to name a few. To our knowledge, none of these systems
have used trusted execution to enable compatibility with legacy
systems as proposed by Troxy.
VIII. CONCLUSION
We have presented Troxy, a system which leverages trusted
execution environments to offer clients transparent access to
BFT systems. In contrast to traditional BFT systems, a Troxy-
backed system does not require to execute a special library
at the client side. Instead, it implements a substitute of the
library inside each replica. In addition, it introduces a novel
read optimization that features a managed fast-read cache
to accelerate read-heavy operations while providing strong
consistency guarantees. We implemented a prototype of Troxy
in C/C++ with Intel SGX and evaluated its performance with
both microbenchmarks and an HTTP service. The results
indicate that (1) while Troxy is slower by up to 43% for
small payloads, it outperforms a state-of-the-art hybrid BFT
protocol by 130% for larger, read-heavy workloads and a
realistic network delay; (2) Troxy introduces a negligible
latency overhead and is transparent to legacy clients when
providing Byzantine fault tolerance to an HTTP service.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:31:39 UTC from IEEE Xplore.  Restrictions apply. 
69
[25] J. Yin, J.-P. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin,
“Separating agreement from execution for byzantine fault tolerant services,”
in ACM SIGOPS Operating Systems Review, 2003.
[26] L. Lamport, “The Part-time Parliament,” ACM Transactions on Computer
Systems, vol. 16, no. 2, pp. 133–169, 1998.
[27] D. Ongaro and J. Ousterhout, “In Search of an Understandable Consensus
Algorithm,” in Proceedings of the 2014 USENIX Annual Technical
Conference (USENIX ATC ’14), 2014, pp. 305–320.
[28] “Intel SGX SDK,” https://software.intel.com/sgx-sdk.
[29] S. Checkoway and H. Shacham, Iago attacks: Why the system call api
is a bad untrusted rpc interface. ACM, 2013.
[30] N. Weichbrodt, A. Kurmus, P. Pietzuch, and R. Kapitza, “Asyncshock:
Exploiting synchronisation bugs in intel sgx enclaves,” in European
Symposium on Research in Computer Security. Springer, 2016.
[31] S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe, J. Lind,
D. Muthukumaran, D. O’Keeffe, M. Stillwell et al., “SCONE: Secure
Linux Containers with Intel SGX.” in OSDI, 2016, pp. 689–703.
[32] M. Orenbach, P. Lifshits, M. Minkin, and M. Silberstein, “Eleos: Exitless
os services for sgx enclaves,” in Proceedings of the Twelfth European
Conference on Computer Systems. ACM, 2017, pp. 238–253.
[33] P.-L. Aublin, F. Kelbert, D. OKeeffe, D. Muthukumaran, C. Priebe,
J. Lind, R. Krahn, C. Fetzer, D. Eyers, and P. Pietzuch, “TaLoS: Secure
and Transparent TLS Termination inside SGX Enclaves.”
[34] B. Calder, J. Wang, A. Ogus, N. Nilakantan, A. Skjolsvold, S. McKelvie,
Y. Xu, S. Srivastav, J. Wu, H. Simitci et al., “Windows Azure Storage:
a highly available cloud storage service with strong consistency,” in
Proceedings of the 21st ACM Symposium on Operating Systems Principles.
ACM, 2011, pp. 143–157.
[35] M.-W. Shih, S. Lee, T. Kim, and M. Peinado, “T-SGX: Eradicating
controlled-channel attacks against enclave programs,” in Proceedings of
the 2017 Annual Network and Distributed System Security Symposium
(NDSS), San Diego, CA, 2017.
[36] S. Lee, M.-W. Shih, P. Gera, T. Kim, H. Kim, and M. Peinado, “Inferring
ﬁne-grained control ﬂow inside SGX enclaves with branch shadowing,”
arXiv preprint arXiv:1611.06952, 2016.
[37] J. Seo, B. Lee, S. Kim, M.-W. Shih, I. Shin, D. Han, and T. Kim, “SGX-
Shield: Enabling address space layout randomization for SGX programs,”
in Proceedings of the 2017 Annual Network and Distributed System
Security Symposium (NDSS), San Diego, CA, 2017.
[38] A. Clement, E. L. Wong, L. Alvisi, M. Dahlin, and M. Marchetti, “Making
Byzantine Fault Tolerant Systems Tolerate Byzantine Faults.” in NSDI,
vol. 9, 2009, pp. 153–168.
[39] “Apache JMeter,” http://jmeter.apache.org/.
[40] “Embedded Jetty v.9.4,” https://goo.gl/cTEMge.
[41] R. Kotla, L. Alvisi, M. Dahlin, A. Clement, and E. Wong, “Zyzzyva:
speculative byzantine fault tolerance,” in ACM SIGOPS Operating
Systems Review, vol. 41, no. 6. ACM, 2007, pp. 45–58.
[42] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor, and A. Perrig,
“TrustVisor: Efﬁcient TCB reduction and attestation,” in IEEE Symposium
on Security and Privacy.
IEEE, 2010, pp. 143–158.
[43] T. Distler, R. Kapitza, I. Popov, H. P. Reiser, and W. Schr¨oder-Preikschat,
“SPARE: Replicas on hold,” in Proc. of the 18th Network and Distributed
System Security Symposium (NDSS ’11), 2011.
[44] M. G. Merideth, A. Iyengar, T. Mikalsen, S. Tai, I. Rouvellou, and
P. Narasimhan, “Thema: Byzantine-fault-tolerant middleware for web-
service applications,” in Reliable Distributed Systems, 2005. SRDS 2005.
24th IEEE Symposium on.
IEEE, 2005, pp. 131–140.
[45] W. Zhao, “BFT-WS: A byzantine fault tolerance framework for web
services,” in Eleventh International IEEE EDOC Conference Workshop,
2007, 2007, pp. 89–96.
[46] G. Avoine, F. G¨artner, R. Guerraoui, and M. Vukoli´c, “Gracefully
degrading fair exchange with security modules,” in European Dependable
Computing Conference. Springer, 2005, pp. 55–71.
[47] T. Hunt, Z. Zhu, Y. Xu, S. Peter, and E. Witchel, “Ryoan: A Distributed
Sandbox for Untrusted Computation on Secret Data,” in OSDI 16, 2016.
[48] S. Brenner, C. Wulf, D. Goltzsche, N. Weichbrodt, M. Lorenz, C. Fetzer,
P. Pietzuch, and R. Kapitza, “SecureKeeper: Conﬁdential ZooKeeper
using Intel SGX,” in Proceedings of the 16th Annual Middleware
Conference, ser. Middleware ’16, 2016.
[49] D. Goltzsche, C. Wulf, D. Muthukumaran, K. Rieck, P. Pietzuch, and
R. Kapitza, “TrustJS: Trusted Client-side Execution of JavaScript,” in
EuroSec’17, 2017.
[50] K. Mast, L. Chen, and E. G. Sirer, “Scaling Databases Through Trusted
REFERENCES
[1] M. Castro and B. Liskov, “Practical byzantine fault tolerance,” in Proc. of
the 3rd USENIX Symp. on Operating Systems Design and Implementation
(OSDI ’99), 1999, pp. 173–186.
[2] J. Behl, T. Distler, and R. Kapitza, “Consensus-Oriented Parallelization:
How to Earn Your First Million,” in Proc. of the 16th Middleware
Conference (Middleware ’15). ACM, 2015, pp. 173–184.
[3] T. Distler and R. Kapitza, “Increasing performance in Byzantine fault-
tolerant systems with on-demand replica consistency,” in Proc. of the
6th ACM European Conf. on Computer Systems (EuroSys ’11), 2011.
[4] R. Kotla and M. Dahlin, “High throughput Byzantine fault tolerance,” in
Dependable Systems and Networks, 2004 International Conference on.
IEEE, 2004, pp. 575–584.
[5] S. Sen, W. Lloyd, and M. J. Freedman, “Prophecy: Using History for
High-Throughput Fault Tolerance.” in NSDI, 2010, pp. 345–360.
[6] G. S. Veronese, M. Correia, A. Bessani, and L. C. Lung, “Spin one’s
wheels? byzantine fault tolerance with a spinning primary,” in Proc. of
the 28th IEEE Int’l Symp. on Reliable Distributed Systems (SRDS ’09).
IEEE, 2009, pp. 135–144.
[7] J. Sousa, A. Bessani, and M. Vukoli´c, “A Byzantine Fault-Tolerant
Ordering Service for the Hyperledger Fabric Blockchain Platform,” ArXiv
e-prints, Sep. 2017.
[8] R. Ferraz, B. Gonc¸alves, J. Sequeira, M. Correia, N. F. Neves, and
P. Ver´ıssimo, “An intrusiontolerant web server based on the distract
architecture,” in In Proceedings of
the Workshop on Dependable
Distributed Data Management. Citeseer, 2004.
[9] I. Anati, S. Gueron, S. Johnson, and V. Scarlata, “Innovative technology
for CPU based attestation and sealing,” in Proc. of the 2nd international
workshop on hardware and architectural support for security and privacy,
vol. 13. ACM, 2013.
[10] “Intel SGX,” https://software.intel.com/en-us/sgx, 2017.
[11] “We’re Halfway to Encrypting the Entire Web,” https://goo.gl/em8elg,
2017.
[12] M. P. Herlihy and J. M. Wing, “Linearizability: A correctness condition
for concurrent objects,” ACM Transactions on Programming Languages
and Systems (TOPLAS), vol. 12, no. 3, pp. 463–492, 1990.
[13] J. Behl, T. Distler, and R. Kapitza, “Hybrids on Steroids: SGX-Based
High Performance BFT,” in Proceedings of the 12th European Conference
on Computer Systems (EuroSys ’17), 2017, pp. 222–237.
[14] G. S. Veronese, M. Correia, A. N. Bessani, L. C. Lung, and P. Ver´ıssimo,
“Efﬁcient Byzantine Fault-Tolerance,” IEEE Transactions on Computers,
vol. 62, no. 1, pp. 16–30, 2013.
[15] B.-G. Chun, P. Maniatis, S. Shenker, and J. Kubiatowicz, “Attested
Append-only Memory: Making Adversaries Stick to Their Word,” in
Proceedings of the twenty-ﬁrst ACM SIGOPS Symposium on Operating
Systems Principles (SOSP ’07), New York, NY, USA, 2007. [Online].
Available: http://doi.acm.org/10.1145/1294261.1294280
[16] “HAProxy,” http://www.haproxy.org/, 2017.
[17] “Amazon S3 Availability Event,”
s3-20080720.html, 2008.
http://status.aws.amazon.com/
[18] “WhatsApp messenger service suffers major outage,” https://goo.gl/
uTv3TW, 2017.
[19] “What did OVH learn from 24-hour outage? Water and servers do not
mix,” https://goo.gl/BabnkY, 2017.
[20] T. Distler, C. Cachin, and R. Kapitza, “Resource-efﬁcient Byzantine
Fault Tolerance,” IEEE Transactions on Computers, vol. 65, no. 9, pp.
2807–2819, 2016.
[21] R. Kapitza, J. Behl, C. Cachin, T. Distler, S. Kuhnle, S. V. Mohammadi,
W. Schr¨oder-Preikschat, and K. Stengel, “CheapBFT: resource-efﬁcient
byzantine fault tolerance,” in Proc. of the 7th ACM european conference
on Computer Systems, 2012.
[22] D. Levin, J. R. Douceur, J. R. Lorch, and T. Moscibroda, “TrInc: Small
trusted hardware for large distributed systems,” in Proceedings of the 6th
Symposium on Networked Systems Design and Implementation (NSDI ’09),
2009, pp. 1–14.
[23] B. Vavala, N. Neves, and P. Steenkiste, “Securing Passive Replication
Through Veriﬁcation,” in Reliable Distributed Systems (SRDS), 2015
IEEE 34th Symposium on.
IEEE, 2015, pp. 176–181.
[24] M. Castro and B. Liskov, “Proactive recovery in a byzantine-fault-tolerant
system,” in Proc. of the 4th Conf. on Symp. on Operating System Design
& Implementation-Volume 4. USENIX, 2000, pp. 19–19.
70
Hardware Proxies,” in SysTEX’17, 2017.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:31:39 UTC from IEEE Xplore.  Restrictions apply.