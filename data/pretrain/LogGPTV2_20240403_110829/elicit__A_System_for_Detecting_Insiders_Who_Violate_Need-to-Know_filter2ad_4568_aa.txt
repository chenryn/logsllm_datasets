title:elicit: A System for Detecting Insiders Who Violate Need-to-Know
author:Marcus A. Maloof and
Gregory D. Stephens
elicit: A System for Detecting Insiders
Who Violate Need-to-Know
Marcus A. Maloof1 and Gregory D. Stephens2
1 Department of Computer Science,
Georgetown University, Washington, DC 20057, USA
PI:EMAIL
2 Center for Integrated Intelligence Systems,
The MITRE Corporation, McLean, VA 22102, USA
PI:EMAIL
Abstract. Malicious insiders do great harm and avoid detection by us-
ing their legitimate privileges to steal information that is often outside
the scope of their duties. Based on information from public cases, con-
sultation with domain experts, and analysis of a massive collection of
information-use events and contextual information, we developed an ap-
proach for detecting insiders who operate outside the scope of their du-
ties and thus violate need-to-know. Based on the approach, we built and
evaluated elicit, a system designed to help analysts investigate insider
threats. Empirical results suggest that, for a speciﬁed decision threshold
of .5, elicit achieves a detection rate of .84 and a false-positive rate
of .015, ﬂagging per day only 23 users of 1, 548 for further scrutiny. It
achieved an area under an roc curve of .92.
Keywords: misuse, insider threat, anomaly detection.
1 Introduction
Recently, the fbi arrested analyst Leandro Aragoncillo after he allegedly “con-
ducted extensive keyword searches relating to the Philippines” and “printed
or downloaded 101 classiﬁed documents”, also relating to the Philippines [1].
Although Aragoncillo was an intelligence analyst, information about the Philip-
pines was “outside the scope of his assignments” [1].
We are interested in detecting this type of malicious insider, but the problem
of detecting insiders is much more complex and multi-faceted. For instance, ma-
licious insiders are often disgruntled [2], so better working environments could
lead to a reduced threat. Better processes for screening employees could also
reduce the threat. On corporate intranets, one may be able to deploy methods
traditionally used against external intruders to counter an insider who is, say,
attempting to gain unauthorized access to a server. In contrast, we are interested
in detecting malicious insiders who operate within their privileges, but who en-
gage in activity that is outside the scope of their legitimate assignments and
thus violate need-to-know.
C. Kruegel, R. Lippmann, and A. Clark (Eds.): RAID 2007, LNCS 4637, pp. 146–166, 2007.
c(cid:2) Springer-Verlag Berlin Heidelberg 2007
elicit: A System for Detecting Insiders Who Violate Need-to-Know
147
In this paper, we describe our eﬀorts to develop and evaluate methods of
detecting insiders who violate need-to-know. Based on analysis, research, and
consultation with domain experts, we designed an approach that consists of four
main steps. First, decoders process network traﬃc from protocols associated with
the use of information into higher-level information-use events. Second, a suite
of detectors, supplanted with contextual information about users, groups, and
organizations, examines these events and issues alerts. Third, a Bayesian network
uses these alerts as evidence and computes threat scores. Fourth, an interface
presents events, alerts, and threat scores of users to security analysts. Based
on this approach, we implemented a system named elicit, which stands for
“Exploit Latent Information to Counter Insider Threats.”
To support elicit’s development and evaluation, we derived a data set from
284 days of network traﬃc collected from an operational corporate intranet. Over
a period of 13 months, we processed 16 terabytes of raw packets into more than
91 million information-use events for more than 3, 900 users. We then examined
these events to characterize the searching, browsing, downloading, and printing
activity of individuals, groups of individuals, and the organization as a whole.
We built 76 detectors and a Bayesian network that, together, produce an overall
threat score for each user in the organization.
To evaluate our approach and elicit, a red team developed scenarios based
on information from real, publicly-available cases. They translated the scenarios
to the target environment and executed them during normal network operation.
A trusted agent1 used scripts to insert events of the scenarios into our collection
of events. We then ran elicit, as would an analyst, in an eﬀort to identify the
users corresponding to the scenarios.
Over a period of two months, using a speciﬁed decision threshold of .5, elicit
detected the insiders on 16 of the 19 days they were acting maliciously, corre-
sponding to a detection rate of .84. During this same period, elicit scored an
average of 1, 548 users per day, with an average of only 23 users scoring high
enough to warrant further scrutiny, meaning that elicit’s average false-positive
rate is .015. By varying the decision threshold, we produced an roc curve, the
area under which was .92.
2 Problem Statement
There are many detection tasks important for securing systems, their software,
and their information, such as detecting intruders [3,4], and anomalous command
[5] and system-call [6] sequences. We focus on the task of detecting misuse,
deﬁned as legitimate users abusing their privileges.
Detecting misuse is a complex, multi-faceted problem, and malicious insid-
ers, or simply insiders, may engage in a variety of activities. Insiders could use
knowledge of their organization’s intranet and behave in a manner similar to an
intruder. Such activities could include scanning ports, executing buﬀer overﬂows,
1 Herein, all uses of the term trusted agent refer to the person serving as the interme-
diary between the red team and the research team.
148
M.A. Maloof and G.D. Stephens
and cracking password ﬁles, and one can detect these activities with methods of
intrusion detection. Insiders could also masquerade as another user by compro-
mising his or her account. However, in our work, we are interested in detecting
malicious insiders who do not engage in these activities.
In a computing system, access-control mechanisms yield a set of illegal and
legal actions for each user. Such actions include viewing certain documents, and
so, there will be documents that a user can and cannot view. Unfortunately,
for large, dynamic organizations, it is diﬃcult to design and maintain eﬀective
access control. Consequently, given the set of legal actions for a user, there is a
set of such actions that is suspect, especially given contextual information about
the user. In our work, we are interested in detecting insiders who browse, search,
download, and print documents and ﬁles to which they have access, but that
are inappropriate or uncharacteristic for them based on contextual information,
such as their identity, past activity, and organizational context.
Our conception of detecting insiders is quite diﬀerent than detecting external
intruders. One rarely, if ever, has the contextual information for such intruders
that one has for insiders. Our aim is to leverage this context for detection.
It is also diﬀerent than detecting internal intruders, since insiders who violate
need-to-know do not need to break rules to achieve their goals. All detection
systems must analyze events at correct levels of abstraction, and the insiders
of interest to us usually gather and exﬁltrate documents. Consequently, rather
than detecting malicious activity based on connections, packets, or system-call
sequences, we chose to detect insiders based on information-use events, which
we describe further in the next section.
3 Data Collection
We derived the data set for our study from an operational corporate intranet.
In the following subsections, we describe how we processed network traﬃc into
information-use events, collected contextual information about users and the
information they accessed, and developed scenarios for the purpose of evaluation.
3.1 Transforming Network Traﬃc into Information-Use Events
To collect network events, we placed passive sensors between clients and servers
within a large corporate intranet for 284 days.2 The sensors collected packets
from network protocols correlated with the legitimate use of information, a criti-
cal aspect of our work. In total, we captured approximately 16 terabytes of data,
2 We experienced three outages. Two months into the period, an administrative error
resulted in an outage for two days. Three months later, an unanticipated network
reconﬁguration caused a near-complete loss of data for ﬁve days. Four months into
collection, we discovered and corrected an error in the software that captured packets.
Subsequent analysis indicating that the ﬂawed version failed to capture about 9% of
the packets, with the majority of the loss occurring during traﬃc bursts. Nonetheless,
data from this period was helpful for analysis and development. Crucially, the red
team did not execute the scenarios until after we resolved these problems.
elicit: A System for Detecting Insiders Who Violate Need-to-Know
149
Table 1. Information Stored for Events
Field
Protocol
File Name/Path
Start/Stop Time
Client/Server ip
User Name
Bytes
Original File Name
Printer
Pages
Search Phrase
E-mail Headers
Actions
X
X
X
X
X
X
X
X
X
X
X
X
List Delete Read Write Move Print Query Send
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
corresponding to 27 billion packets. In the collection, 61% of packets were from
the smb protocol, 35% were from http, 3%, from smtp, and 1%, from ftp.
We developed a series of protocol decoders to transform the packets into
information-use events. These decoders also tracked authenticated users across
sessions and captured clues about their identity, which aided in subsequent attri-
bution. Oﬀ-line, the trusted agent used Ethereal [7] to ﬁlter and dissect packets,
and then applied our decoders to produce information-use events. Over a period
of 13 months, the decoders processed more than 3.7 billion packets, producing
more than 91 million events, which we stored in a relational database.
Referring to Table 1, each event consisted of an action and variable number of
ﬁelds. Decoders extracted eight actions. In our collection, 35.8% of the actions
were lists of ﬁles or directories, 42.1% were reads, 12.9% were writes, 4.6% were
deletes, 2.9% were sends of e-mail, 1.1% were search-engine queries, 0.4% were
prints of documents, and 0.3% were moves of ﬁles or directories. The decoders
also extracted ﬁelds such as the start and end time of the action, the protocol
involved, and other pertinent information. Table 2 contains an example of a
print event in which user p0314508p printed a document named Liz’s form
fax.doc to the printer \\spool2\335-HP. Values for all other ﬁelds are null.
With the exception of send, we selected these actions and ﬁelds based on
analysis of past insider cases and hypotheses about which would be useful for
detecting violations of need-to-know. Then, during decoder development, we
implemented routines to capture information from e-mail because we realized
that it would be useful for constructing social networks.
We did not collect data directly on clients, so our approach is network-based,
rather than host-based. In the environment we monitored, it would have been
impractical—though desirable—to instrument every machine with the software
necessary to collect events. We also did not collect packets inbound from or
outbound to the Internet due to concerns about privacy. If our approach were
used in an organization where such technical and privacy issues could be re-
solved, elicit’s design is ﬂexible enough to accommodate these new sources of
information.
150
M.A. Maloof and G.D. Stephens
Table 2. Example of the Relevant Fields of a Print Event
Value
print
smb
Field
Action
Protocol
File Name Liz’s form fax.doc
Start Time 2005-02-03 10:32:16.993
Stop Time 2005-02-03 10:32:17.003
Client ip
Server ip
User Name p0314508p
Bytes
Printer
Pages
2672
\\spool2\335-HP
1
ddd.ddd.ddd.13
ddd.ddd.ddd.239
3.2 Collection of Contextual Information
In addition to events, we developed sensors that periodically collected contextual
information about the users and the information they accessed and manipulated.
This included information from an employee directory, such as name, oﬃce loca-
tion, job description, seniority, and projects. We also copied the contents of ﬁles
in users’ public directories on a shared ﬁle system, and we extracted information
from the directory structure itself, the branches of which often corresponded to
users, projects, and the organization’s business units. We stored this information
in a database, and Table 3 shows an example.
With this contextual information, we were able to build simple social networks
with e-mail traﬃc, use a person’s job description in the analysis of his or her
search-engine queries, and determine if someone printed to a printer close to his
or her oﬃce. It also let us compare a user’s behavior to that of peers, such as
those with the same job description and those working on the same ﬂoor, in the
same department, and on joint projects.
These comparisons illustrate a critical aspect of our work. We are not simply
examining network events between client and server ip addresses. We are mon-
itoring how users access and manipulate information, and we are coupling this
activity with contextual information about the users and the information itself.
3.3 Data Anonymization
To protect the privacy of the users, the trusted agent removed, anonymized,
or abstracted any identifying information before releasing it to us, the research
team. The trusted agent removed hire dates and phone numbers, replaced names
and user ids with pseudonyms, and abstracted oﬃce numbers to their ﬂoor.
An important concern is whether the process of anonymization introduced
artifacts that may have aﬀected detection. For this study, phone numbers and
hire dates were not important for detection, so their removal was not problem-
atic. Name and user id are not relevant for detection, but are critical as labels
elicit: A System for Detecting Insiders Who Violate Need-to-Know
151
Table 3. Example of Contextual Information for User p0314508p
Value
Field
User Name
p0314508p
E-mail Address p0314508p
User id
p0314508p
Home Directory s:\p0314508p\public
Department
Accounts Payable
Division
Purchasing
Oﬃce Location 7th Floor
Job Title
Job Category
Job Level
Project 1
Project 2
General Accounting Specialist
General Accounting
3
Accounts Payable
Travel Accounting
connecting events and detector outputs. However, pseudonyms serve this purpose
equally well.
Abstracting oﬃce location to its ﬂoor did make it diﬃcult or impossible to
conduct certain analyses, which may have negatively aﬀected detection. For ex-
ample, we could not identify relationships between people who shared oﬃces
or who worked in adjacent oﬃces. Since ours is a research eﬀort, we had to
accept that there was certain information we simply could not use or collect.
Nonetheless, even without this information, our results are promising.