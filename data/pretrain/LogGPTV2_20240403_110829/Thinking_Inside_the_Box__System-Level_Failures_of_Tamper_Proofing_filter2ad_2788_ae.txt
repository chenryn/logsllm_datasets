an ideal world, evaluations would be conducted by repre-
sentatives of the end users. But here, the cardholders and
small merchants are not in a position to act collectively.
Where evaluation by the relying party is impractical, the
next best option might be a hostile laboratory. The clos-
est we often get to this ideal is an evaluation by academics,
such as the one in this paper. But the quantity and timeli-
ness of these evaluations falls far short of the optimum: over
200 types of PEDs have been offered for sale in Europe, and
this paper is the ﬁrst open evaluation. Why weren’t the other
products looked at years ago?
Our experience discussed in this paper, and similar ex-
periences in previous projects, could offer an explanation.
The industry’s attitude towards independent evaluation is at
best unhelpful and at worst actively obstructive. Most im-
portantly, merchants fear that if they are discovered to have
assisted in the conﬁrmation of security vulnerabilities, they
might face retribution from their bankers. Our co-operation
with merchants and other insiders has only been possible
when we could protect their identity. In many ways, crim-
inals are in a better position as they can easily set up fake
merchant accounts, take higher risks, and be more anony-
mous than an independent researcher cooperating with a le-
gitimate merchant.
One possible solution is to use markets. People who ﬁnd
vulnerabilities in operating system platforms can sell them
into a thriving market: companies such as iDefense and Tip-
ping Point buy and sell such information [11]. The problem
for PED evaluations is where the money would come from.
Who would be the buyers of PED vulnerabilities?
It does rather look like a certiﬁcation body of some kind
is inescapable in some circumstances. However, if the Com-
mon Criteria are to provide the framework, then that brand
must be better protected. The certiﬁcation bodies should
register ‘Common Criteria’ as a trademark, and protect it
as vigorously as the banks do theirs. Anyone claiming that
a device is ‘Common Criteria Evaluated’ when it has not
been through the full certiﬁcation process should face hav-
ing their website taken down for trademark infringement.
Furthermore, given the very strong incentives for ven-
dors to shop around for the easiest evaluation lab, the result-
ing race to the bottom among labs, and the lack of institu-
tional incentives for the CB to exercise proper discipline, we
propose that evaluations of equipment on which the public
is forced to rely should in future come with a sufﬁcient re-
ward to motivate independent evaluation. For an evaluation
at level EAL3 we propose a mandatory reward of $10,000
for each vulnerability, while for EAL4 the reward should be
$100,000.
The introduction of real money will call forth a more
socially optimal level of attack effort; while the condition-
ing of the rewards on responsible disclosure could control
any increase in exposure. What’s more, we propose that the
rewards be paid not by the vendors, nor even by the eval-
uation labs, but by the certiﬁcation bodies that license the
labs. That way, careless evaluators cost their regulators real
money, and are more likely to be disciplined.
(The CBs
might in turn require vendors to post performance bonds.)
6 Conclusions
Smartcard payments depend on the anti-tampering mea-
sures in PIN entry devices. We examined the market-
leading products and have found them quite inadequate to
protect cardholders. We’ve shown that it’s not enough to
concentrate on the design of anti-tampering features. PED
designers put a lot of effort into protecting the wrong as-
sets; they appear to have misunderstood the system aspects
of attacks. This raises serious questions on the design of
tamper-proof systems.
We have therefore proposed an improved design method-
ology: in particular, complex systems should have a secu-
rity architecture document to inform all the participants in
the design and evaluation process, and protection properties
need to be traced across boundaries and interfaces to ensure
they don’t slip away there. Systems engineering – and in-
deed computer science – are increasingly about managing
293
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:13:41 UTC from IEEE Xplore.  Restrictions apply. 
complexity; this will be a growing concern of security en-
gineers, and EMV may provide a good case study.
But the failure here was not limited to the technical as-
pects of the security engineering. Claims that terminals
were ‘Common Criteria Evaluated’ turned out to be almost
meaningless; the devices in question were not Common Cri-
teria Certiﬁed, and the certiﬁcation body was not interested
in protecting its brand. If the Common Criteria brand is to
have any value in the future, other than as a marketing slo-
gan that will be progressively discredited by works such as
this paper, the incentives need to be ﬁxed.
Finally, the lessons we learned are not limited to bank-
ing. Other ﬁelds, such as voting machines, suffer from the
same combination of stupid mistakes, sham evaluations and
obstructive authorities. Technology alone won’t be enough.
We need regulatory reform too.
Acknowledgments
We are grateful to Markus Kuhn for providing equip-
ment, and to Richard Clayton and Mike Bond for proof-
reading and comments. Saar Drimer is funded by Xilinx
Inc. Steven Murdoch is funded by the Tor Project and em-
ployed part-time by Cronto Ltd.
References
[1] R. Anderson, M. Bond, and S. J. Murdoch. Chip and spin,
March 2005.
http://www.chipandspin.co.uk/spin.pdf.
[2] R. Anderson and M. Kuhn. Tamper resistance – a cautionary
note. In USENIX Workshop on Electronic Commerce, pages
1–11, Oakland, California, November 1996.
[3] R. J. Anderson. Security engineering: A guide to building
dependable distributed systems. John Wiley & Sons, Inc.,
New York, NY, USA, 2001.
[4] R. J. Anderson, M. Bond, J. Clulow, and S. P. Skoroboga-
tov. Cryptographic processors – a survey. Technical Re-
port UCAM-CL-TR-641, University of Cambridge, Com-
puter Laboratory, August 2005.
[5] APACS. PIN entry device protection proﬁle, July 2003.
http://www.commoncriteriaportal.org/
public/files/ppfiles/PED_PPv1_37.pdf.
[6] APACS. Fraud abroad drives up card fraud losses. Press
release, October 2007. http://www.apacs.org.uk/
media_centre/press/03.10.07.html.
[7] APACS: The UK payments association.
PIN entry de-
vice protection proﬁle common criteria evaluation, Septem-
ber 2007. http://www.apacs.org.uk/payment_
options/PINEntryDevices.html.
[8] D. J. Armstrong. The quarks of object-oriented develop-
ment. Communications of the ACM, 49(2):123–128, Febru-
ary 2006.
[9] J. Bale. Shell halts Chip-and-PIN after fraud. The Times,
May 2006. http://business.timesonline.co.
uk/tol/business/law/article714402.ece.
[10] L. Bauer, S. Garriss, J. M. McCune, M. K. Reiter, J. Rouse,
and P. Rutenbar. Device-enabled authorization in the Grey
system. In J. Zhou, J. Lopez, R. H. Deng, and F. Bao, editors,
Information Security, 8th International Conference, volume
3650 of LNCS, pages 431–445, Singapore, September 2005.
Springer.
[11] R. B¨ohme. Vulnerability markets. In Chaos Communication
Congress (23C3), Berlin, Germany, December 2006. CCC.
[12] M. Bond. Chip & PIN (EMV) interceptor, March 2006.
http://www.cl.cam.ac.uk/research/
security/banking/interceptor/.
[13] S. Bowles, B. Cuthbert, and W. Stewart. Typical attack tech-
niques for compromising point of sale PIN entry devices.
Technical report, Payment Assurance Lab EWA-Canada,
September 2005. http://csrc.nist.gov/groups/
STM/cmvp/documents/fips140-3/physec/
papers/physecpaper04.pdf.
[14] S. L. Brand. DoD 5200.28-STD Department of Defen-
se Trusted Computer System Evaluation Criteria (Orange
Book). National Computer Security Center, December 1985.
[15] Brightsight. Common Criteria portal, February 2008.
http://www.commoncriteriaportal.org/.
[16] Bull, Dassault, Diebold, NCR, Siemens Nixdorf and Wang
Global. Protection Proﬁle: Automatic Cash Dispensers /
Teller Machines, 1999.
[17] D. Chaum. Design concepts for tamper responding systems.
In Advances in Cryptology (CRYPTO ’83), pages 387–392.
Plenum Press, 1983.
[18] Cronto mobile phone client.
http://www.cronto.com/.
[19] S. Drimer. Keep your keypads close, September 2007.
http://www.lightbluetouchpaper.org/
2007/09/15/keep-your-keypads-close/.
[20] S. Drimer and S. J. Murdoch. Keep your enemies close: Dis-
tance bounding against smartcard relay attacks. In USENIX
Security Symposium, August 2007.
[21] S. Drimer, S. J. Murdoch, and R. Anderson. Thinking inside
the box: system-level failures of tamper prooﬁng. Tech-
nical Report UCAM-CL-TR-711, University of Cambridge,
Computer Laboratory, February 2008.
[22] EMVCo, LLC. EMVCo Type Approval Terminal Level 1 Test
Cases, December 2002. http://www.emvco.com/.
[23] EMVCo, LLC. EMV 4.1, June 2004.
http://www.emvco.com/.
[24] P. Gutmann. Secure deletion of data from magnetic and
In USENIX Workshop on Smartcard
solid-state memory.
Technology, pages 77–89, San Jose, California, July 1996.
[25] P. Gutmann. Data remanence in semiconductor devices.
USENIX Security Symposium, pages 39–54, August 2001.
[26] Ingenico. i3300 Keypad, September 2007.
http://www.ingenico.com/i3300-i3300_28.
html?lg=UK&productId=14#0.
[27] International Organization for Standardization.
ISO/IEC
18092:2004 Information technology – Telecommunications
and information exchange between systems – Near Field
Communication – Interface and Protocol (NFCIP-1), 1st
edition, January 2007.
[28] R. G. Johnston, A. R. Garcia, and A. N. Pacheco. Efﬁcacy
of tamper-indicating devices. Journal of Homeland Security,
April 2002.
294
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:13:41 UTC from IEEE Xplore.  Restrictions apply. 
[29] M. G. Kuhn. Compromising emanations: eavesdropping
risks of computer displays. Technical Report UCAM-CL-
TR-577, University of Cambridge, Computer Laboratory,
December 2003.
[30] M. W. Tobias, personal communication, October 2007.
[31] Masabi. Two factor authentication (2FA) – opportunity and
pitfalls, September 2007.
http://blog.masabi.com/2007/09/
two-factor-authentication-2fa.html.
[32] Monopolies and Mergers Commission. Credit card ser-
vices: A report on the supply of credit card services in the
United Kingdom, 1989. http://www.mmc.gov.uk/
rep_pub/reports/1989/255creditcard.htm.
[33] Ofﬁce of Fair Trading, UK. Mastercard agreement anti-
competitive, rules OFT, September 2005. http://www.
oft.gov.uk/news/press/2005/168-05.
[34] S. P. Skorobogatov. Low temperature data remanence in
static RAM. Technical Report UCAM-CL-TR-536, Univer-
sity of Cambridge, Computer Laboratory, June 2002.
[35] S. W. Smith. Fairy dust, secrets, and the real world. IEEE
Security and Privacy, 1(1):89–93, 2003.
[36] S. W. Smith and S. H. Weingart. Building a high-perf-
ormance, programmable secure coprocessor. Computer Net-
works: The International Journal of Computer and Telecom-
munications Networking, 31(9):831–860, April 1999.
[37] Trintech. VeriFone to acquire Trintech’s payment systems
business, August 2006. http://www.trintech.com/
verifone-to-acquire-trintechs-payment-
systems-business/.
[38] VeriFone. Xtreme Keypad, September 2007.
http://www.verifone.com/products/
devices/countertop/xtreme.html.
[39] Visa. Chip terms explained, November 2002.
http://www.visa-asia.com/ap/center/
merchants/productstech/includes/
uploads/CTENov02.pdf.
[40] Visa Canada. Visa chip card information for cardholders,
October 2007.
http://www.visa.ca/chip/cardholders.cfm.
[41] Visa International Service Association. PIN entry device
security requirements manual, March 2004.
https://partnernetwork.visa.com/
vpn/global/retrieve_document.do?
documentRetrievalId=35.
[42] Visa International Service Association. Approved PIN entry
devices, October 2007.
http://partnernetwork.visa.com/dv/pin/
pedapprovallist.jsp.
[43] D. Wagner and B. Schneier. Analysis of the SSL 3.0 pro-
tocol. In D. Tygar, editor, 2nd USENIX Workshop on Elec-
tronic Commerce. USENIX, November 1996.
[44] S. H. Weingart. Physical security devices for computer
In Crypto-
subsystems: a survey of attacks and defences.
graphic Hardware and Embedded Systems Workshop, vol-
ume 1965 of LNCS, pages 302–317, London, UK, August
2000. Springer-Verlag.
[45] S. H. Weingart, S. R. White, W. C. Arnold, and G. P. Double.
An evaluation system for the physical security of comput-
ing systems. In Computer Security Applications Conference,
pages 232–243, December 1990.
[46] C. Yang, G. Tian, and S. Ward.
Security systems of
point-of-sales devices. In The International Journal of Ad-
vanced Manufacturing Technology, volume 34, pages 799–
815, London, October 2007. Springer.
295
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:13:41 UTC from IEEE Xplore.  Restrictions apply.