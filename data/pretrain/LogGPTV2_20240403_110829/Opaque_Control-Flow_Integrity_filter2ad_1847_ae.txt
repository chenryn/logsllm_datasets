details can be more easily protected from disclosure.
Giuffrida et al. [17] present a comprehensive compiler-
based software diversiﬁcation approach that allows live re-
randomization. The resulting overheads depend on the re-
randomization frequency. Snow et al. [40] report that JIT-ROP
attacks can run in as little as 2.3 seconds. Re-randomizing
every two seconds, however, adds an overhead of about 20%.
The foundations for the basic block randomization portion
of our implementation are based upon the STIR system [45].
13
STIR analyzes and rewrites binaries ahead of time to make
them self-randomizing (or self-stirring). At load-time, a small
randomization stub permutes the basic block and function
layout inside the binary. To account for disassembly errors, the
original code is loaded as non-executable data, allowing the
stirred binaries to compensate for disassembly errors.
B. Control-Flow Integrity
In its most precise form, Control-Flow Integrity CFI [1]
conﬁnes indirect branches to ﬂow only to a precise set of
statically identiﬁed targets for each branch. CFI has yet to
see widespread adoption in the industry. We believe the two
main reasons for this to be (i) difﬁculty reconstructing an
accurate CFG for a binary without access to source code or
debug symbols, neither of which are readily available for the
large majority of COTS binaries, and (ii) higher overheads than
solutions based on code randomization.
A number of low-overhead solutions have been proposed
which impose less strict integrity checks on program exe-
cutions. These include ROPecker [7], ROPGuard [16] and
kBouncer [33]. ROPecker and kBouncer use the x86 last
branch record (LBR) register set to accomplish their checks.
kBouncer, for instance, performs CFI validation on the LBR
during any Windows API invocation, and ensures that all returns
all are call-preceded (i.e., that each return address points to an
instruction that follows a call instruction). ROPecker creates an
ofﬂine gadget database, which is then compared at runtime with
LBR entries to detect attacks. ROPGuard also performs CFI
validation on Windows API calls. Like kBouncer, it requires
that return addresses are call-preceded. It also veriﬁes that the
memory word before each return address is the start address
of the API function.
CFI for COTS binaries [50] is another proposed coarse-
grained CFI solution. This technique can be applied to binaries
without access to source code or debug information. It relies on
a static disassembly step where all potential branch (and return)
targets are identiﬁed, and all indirect branches are instrumented
with code that jumps to a CFI validation routine. The validation
routine ensures that target and return addresses are either call-
preceded, or belong to the set of statically identiﬁed targets.
Similarly, Compact Control Flow Integrity and Random-
ization (CCFIR) [49] applies coarse-grained CFI to binaries
without source code or debug information (but with relocation
information). In this technique, permissible targets for indirect
branches are collected into a separate Springboard section,
and indirect branches are only allowed to ﬂow into the
Springboard. CCFIR also incorporates some elements of code-
randomization—target entries are placed at random locations
within the Springboard. Although this confers an additional
degree of security against traditional ROP attacks, disclosure
attacks are able to read the full contents of the Springboard,
nullifying its advantages against that class of attacks.
Davi et al. [11] test these coarse-grained CFI solutions and
show that they fail to adequately secure binaries against ROP
attacks.
Forward CFI [43] and SafeDispatch [25] are two recent
compiler-based CFI solutions. Forward CFI protects binaries
by inserting validation checks for all forward-edge control
ﬂows. This solution is only intended to secure forward control-
ﬂows, and does not protect against attacks that rely purely on
return-terminated gadgets.
SafeDispatch protects C++ binaries from virtual table
hijacking by recompiling binaries with a modiﬁed C++ compiler
that instruments all virtual method call sites with runtime checks
that ensure that all method calls jump to valid implementations
during execution. Additionally, SafeDispatch only protects
virtual method calls, leaving binaries vulnerable to ROP attacks
that rely on modiﬁed return addresses on the stack.
VIII. CONCLUSIONS
CFI and artiﬁcial software diversity are well-established,
complementary strategies for protecting software against code-
reuse attacks, including ROP attacks. Recent advances in
offensive security have alarmingly demonstrated how to bypass
both: The security relaxations introduced by coarse-grained
CFI to achieve acceptable performance are exploitable by
skillful control-ﬂow hijacking, and implementation disclosure
vulnerabilities can be leveraged to derandomize even ﬁne-
grained artiﬁcial diversity defenses.
O-CFI combines and extends both CFI and ﬁne-grained
diversity to address this dual threat of code-reuse and imple-
mentation disclosure attacks. To do so, we reformulate CFI as
a bounds-checking problem, and repurpose ﬁne-grained binary
code randomization to diversify and conceal the exploitable
edges of the protected program’s control-ﬂow graph. As a result,
O-CFI can protect software even against attackers who have
complete read-access to the randomized program code.
Our prototype implementation demonstrates that O-CFI
can be effectively applied to protect legacy binaries without
source code, and experimental evaluation exhibits performance
overheads of just 4.7% on legacy processors. Performance is
expected to be even higher (c. 4.17% overhead) on future-
generation processors, since our bounds-checking implementa-
tion centers around Intel MPX instructions that will be hardware-
accelerated on forthcoming Intel-based processors.
ACKNOWLEDGMENTS
We thank Julian Lettner for benchmarking assistance, and
Lucas Davi, Andrei Homescu, Christopher Liebchen, Matt
Miller, and the anonymous reviewers for their insightful
comments and suggestions.
This material is based upon work partially supported by
National Science Foundation (NSF) CAREER award #1054629,
Ofﬁce of Naval Research (ONR) award N00014-14-1-0030, Air
Force Ofﬁce of Scientiﬁc Research (AFOSR) award FA9550-
14-1-0173, an Industry-University Collaborative Research
Center grant from Raytheon Company, Defense Advanced
Research Projects Agency (DARPA) contracts D11PC20024
and N660001-1-2-4014, and by gifts from Mozilla Corporation
and Oracle Corporation. Any opinions, ﬁndings, conclusions,
or recommendations expressed in this material are those of the
authors and do not necessarily reﬂect the views of the above
supporters, their contracting agents, or any other agency of the
U.S. Government.
REFERENCES
[1] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti, “Control-
ﬂow integrity principles, implementations, and applications,”
ACM Trans. Information and System Security (TISSEC),
vol. 13, no. 1, 2009.
[2] M. Backes and S. N¨urnberger, “Oxymoron: Making
ﬁne-grained memory randomization practical by allowing
code sharing,” in Proc. 23rd Usenix Security Sym., 2014,
pp. 433–447.
14
[3] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. N¨urnberger,
and J. Pewny, “You can run but you can’t read: Preventing
disclosure exploits in executable code,” in Proc. 21st ACM
Conf. Computer and Communications Security (CCS),
2014, pp. 1342–1353.
[4] A. Bittau, A. Belay, A. Mashtizadeh, D. Mazi`eres, and
D. Boneh, “Hacking blind,” in Proc. 35th IEEE Sym.
Security & Privacy (S&P), 2014, pp. 227–242.
[5] T. K. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang,
“Jump-oriented programming: A new class of code-reuse
attack,” in Proc. 6th ACM Sym. Information, Computer and
Communications Security (ASIACCS), 2011, pp. 30–40.
[6] N. Carlini and D. Wagner, “ROP is still dangerous: Breaking
modern defenses,” in Proc. 23rd Usenix Security Sym.,
2014, pp. 385–399.
[7] Y. Cheng, Z. Zhou, M. Yu, X. Ding, and R. H. Deng,
“ROPecker: A generic and practical approach for defending
against ROP attacks,” in Proc. 21st Annual Network &
Distributed System Security Sym. (NDSS), 2014.
[8] F. Cohen, “Operating system protection through program
evolution,” Computers and Security, vol. 12, no. 6, pp.
565–584, 1993.
[9] Corelan Team, “Mona,” 2014, https://github.com/corelan/
mona.
[10] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and
F. Monrose, “Isomeron: Code randomization resilient to
(just-in-time) return-oriented programming,” in Proc. 22nd
Network and Distributed Systems Security Sym. (NDSS),
2015.
[11] L. Davi, A.-R. Sadeghi, D. Lehmann, and F. Monrose,
“Stitching the gadgets: On the ineffectiveness of coarse-
grained control-ﬂow integrity protection,” in Proc. 23rd
Usenix Security Sym., 2014, pp. 401–416.
[12] J. DeMott, “Bypassing EMET 4.1,” Bromium Labs,
2014, http://labs.bromium.com/2014/02/24/bypassing-emet-
4-1.
[13] C. Evans, “Exploiting 64-bit Linux like a boss,”
2013, http://scarybeastsecurity.blogspot.com/2013/02/
exploiting-64-bit-linux-like-boss.html.
[14] A. Fog, “Lists of instruction latencies, throughputs and
micro-operation breakdowns for Intel, AMD and VIA CPUs,”
2014, http://www.agner.org/optimize/instruction tables.pdf.
[15] S. Forrest, A. Somayaji, and D. H. Ackley, “Building
diverse computer systems,” in Proc. Workshop Hot Topics
in Operating Systems, 1997, pp. 67–72.
[16] I. Fratri´c, “Runtime prevention of return-oriented pro-
gramming attacks,” University of Zagreb, 2012, http:
//www.ieee.hr/ download/repository/Ivan Fratric.pdf.
[17] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced
operating system security through efﬁcient and ﬁne-grained
address space randomization,” in Proc. 21st USENIX
Security Sym., 2012, pp. 475–490.
[18] E. G¨oktas¸, E. Athanasopoulos, H. Bos, and G. Portokalidis,
“Out of control: Overcoming control-ﬂow integrity,” in
Proc. 35th IEEE Sym. Security & Privacy (S&P), 2014, pp.
575–589.
[19] E. G¨oktas¸, E. Athanasopoulos, M. Polychronakis, H. Bos,
and G. Portokalidis, “Size does matter: Why using gadget-
chain length to prevent code-reuse attacks is hard,” in Proc.
23rd Usenix Security Sym., 2014, pp. 417–432.
[20] A. Homescu, M. Stewart, P. Larsen, S. Brunthaler, and
M. Franz, “Microgadgets: Size does matter in Turing-
complete return-oriented programming,” in Proc. 6th
USENIX Workshop Offensive Technologies (WOOT), 2012,
pp. 64–76.
[21] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz,
“Librando: Transparent code randomization for just-in-time
compilers,” in Proc. 20th ACM Conf. Computer and
Communications Security (CCS), 2013, pp. 993–1004.
[22] A. Homescu, S. Neisius, P. Larsen, S. Brunthaler, and
M. Franz, “Proﬁle-guided automated software diversity,” in
Proc. 11th IEEE/ACM Int. Sym. Code Generation and
Optimization (CGO), 2013, pp. 1–11.
[23] R. N. Horspool and N. Marovac, “An approach to the
problem of detranslation of computer programs,” The
Computer J., vol. 23, no. 3, pp. 223–229, 1980.
[24] Intel, “Introduction to intel memory protection exten-
sions,” https://software.intel.com/en-us/articles/introduction-
to-intel-memory-protection-extensions, 2013.
[25] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing
C++ virtual calls from memory corruption attacks,” in
Proc. 21st Annual Network & Distributed System Security
Sym. (NDSS), 2014.
[26] N. Joly, “Advanced exploitation of Internet Explorer
10 / Windows 8 overﬂow (Pwn2Own 2013),”
VUPEN Vulnerability Research Team (VRT), 2013,
http://www.vupen.com/blog/20130522.Advanced
Exploitation of IE10 Windows8 Pwn2Own 2013.php.
[27] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz, “SoK:
Automated software diversity,” in Proc. 35th IEEE Sym.
Security & Privacy (S&P), 2014, pp. 276–291.
[28] A. Majumdar and C. Thomborson, “Securing mobile
agents control ﬂow using opaque predicates,” in Proc. 9th
Int. Conf. Knowledge-based Intelligent Information and
Engineering Systems, vol. 3, 2005, pp. 1065–1071.
[29] S. McCamant and G. Morrisett, “Evaluating SFI for a CISC
architecture,” in Proc. 15th USENIX Security Sym., 2006.
[30] Microsoft, “Enhanced mitigation experience toolkit,”
https://www.microsoft.com/emet, 2014.
[31] V. Mohan and K. W. Hamlen, “Frankenstein: Stitching
malware from benign binaries,” in Proc. 6th USENIX
Workshop Offensive Technologies (WOOT), 2012, pp.
77–84.
[32] B. Niu and G. Tan, “RockJIT: Securing just-in-time
compilation using modular control-ﬂow integrity,” in Proc.
21st ACM Conf. Computer and Communications Security
(CCS), 2014, pp. 1317–1328.
[33] V. Pappas, M. Polychronakis, and A. D. Keromytis,
“Transparent ROP exploit mitigation using indirect branch
tracing,” in Proc. 22nd USENIX Security Sym., 2013, pp.
447–462.
[34] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit
hardening made easy,” in Proc. 20th USENIX Security
Sym., 2011.
[35] J. Seibert, H. Okhravi, and E. S¨oderstr¨om, “Information
leaks without memory disclosures: Remote side channel
attacks on diversiﬁed code,” in Proc. 21st ACM Conf.
Computer and Communications Security (CCS), 2014, pp.
54–65.
[36] F. J. Serna, “The info leak era on software exploitation,”
Black Hat USA, 2012.
[37] ——, “CVE-2012-0769, the case of the perfect info leak,”
Google Security Team, 2012, http://zhodiac.hispahack.com/
my-stuff/security/Flash ASLR bypass.pdf.
[38] H. Shacham, “The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86),” in
Proc. 14th ACM Conf. Computer and Communications
Security (CCS), 2007, pp. 552–561.
[39] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu,
and D. Boneh, “On the effectiveness of address-space
randomization,” in Proc. 11th ACM Conf. Computer and
Communications Security (CCS), 2004, pp. 298–307.
[40] K. Z. Snow, F. Monrose, L. V. Davi, A. Dmitrienko,
C. Liebchen, and A.-R. Sadeghi, “Just-in-time code reuse:
On the effectiveness of ﬁne-grained address space layout
randomization,” in Proc. 34th IEEE Sym. Security &
Privacy (S&P), 2013, pp. 574–588.
[41] A. Sotirov, “Heap feng shui in JavaScript,” Black Hat Europe,
2007, https://www.blackhat.com/presentations/bh-europe-
07/Sotirov/Presentation/bh-eu-07-sotirov-apr19.pdf.
[42] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens,
S. Lachmund, and T. Walter, “Breaking the memory secrecy
assumption,” in Proc. 2nd European Workshop System
Security (EUROSEC), 2009, pp. 1–8.
[43] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway,
´U. Erlingsson, L. Lozano, and G. Pike, “Enforcing forward-
edge control-ﬂow integrity in GCC & LLVM,” in Proc.
23rd USENIX Security Sym., 2014.
[44] C. Wang, J. Hill, J. Knight, and J. Davidson, “Software
tamper resistance: Obstructing static analysis of programs,”
University of Virginia Charlottesville, Tech. Rep., 2000.
[45] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary
stirring: Self-randomizing instruction addresses of legacy
x86 binary code,” in Proc. 19th ACM Conf. Computer and
Communications Security (CCS), 2012, pp. 157–168.
[46] ——, “Securing untrusted code via compiler-agnostic
binary rewriting,” in Proc. 28th Annual Computer Security
Applications Conf. (ACSAC), 2012, pp. 299–308.
[47] R. Wartell, Y. Zhou, K. W. Hamlen, and M. Kantarcioglu,
“Shingled graph disassembly: Finding the undecidable path,”
in Proc. 18th Paciﬁc-Asia Conf. Knowledge Discovery and
Data Mining (PAKDD), 2014, pp. 273–285.
[48] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth,
T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar,
“Native Client: A sandbox for portable, untrusted x86
native code,” in Proc. 30th IEEE Sym. Security & Privacy
(S&P), 2009, pp. 79–93.
[49] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres,
S. McCamant, D. Song, and W. Zou, “Practical control
ﬂow integrity and randomization for binary executables,” in
Proc. 34th IEEE Sym. Security & Privacy (S&P), 2013, pp.
559–573.
[50] M. Zhang and R. Sekar, “Control ﬂow integrity for COTS
binaries,” in Proc. 22nd USENIX Security Sym., 2013, pp.
337–352.
15