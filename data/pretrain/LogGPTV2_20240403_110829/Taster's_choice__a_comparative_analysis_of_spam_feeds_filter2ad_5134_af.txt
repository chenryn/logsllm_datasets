last appearance of a domain in a particular and the
domain campaign end calculated from an aggregate
of the same ﬁve feeds. Solid lines are medians; boxes
range from the 25th to the 75th percentile.
results as Figure 9, but with the Hu, Hyb, and blacklist feeds
removed. (We chose these feeds because, as discussed further
below, they all contain domains reported by users, which
aﬀects the last appearance times of domains.) Restricting
the feeds we use to determine campaign start times reduces
the total set of domains, but also increases the likelihood
that a domain appears in all traces. When we focus on just
the MX honeypot and account traces in this way, we see that
relative to just each other they continue to have consistent
ﬁrst appearance times with each other, but the relative ﬁrst
appearance times are now very short (roughly less than a
day). As with other metrics, these results show that timing
estimates are quite relative and fundamentally depend on
the feeds being considered.
4.4.2 Last Appearance Time
Last appearance times are often used to estimate when
spam campaigns end. Figure 11 shows the time between
the last appearance of a domain in a feed and the domain’s
campaign end time. As with Figure 10 we focus on only a
subset of the feeds where the last appearance of a domain
Ac2Ac1MX3MX2MX10123456789101112HoursAc2Ac1MX3MX2MX102468101214161820222426283032HoursAc2Ac1MX3MX2MX1024681012141618202224262830323436Hours438it is necessary to perform introspective studies such as this
one to understand the limits of what we can conclude from
available data.
While our analysis is not comprehensive, we have found
signiﬁcant variation among the ten feeds we did study. Based
on these ﬁndings we recommend that researchers consider
four diﬀerent challenges whenever using spam data:
• Limited purity. Even the best spam feeds include be-
nign domains and these domains should be anticipated
in analyses. We should identify the “kinds” of benign
domains that appear in a dataset and determine if their
existence will bias results—in particular when spam
feed data will be correlated with other data sources.
• Coverage limitations. MX and honey account spam
sources are inherently biased towards loud broad cam-
paigns. If we desire a broader view of what is advertised
via spam and are unable to strike an arrangement with
a large e-mail provider, operational domain blacklists
are the next best source of such information.
• Temporal uncertainty. Studies of spam campaign tim-
ing should recognize how timing error can be introduced
via diﬀerent feeds. Botnet-based feeds are among the
best for timing information, but naturally coverage is
limited. Other feeds provide highly accurate “onset”
information (e.g., blacklists and human-identiﬁed feeds)
but may not provide a correspondingly accurate end-
ing timestamp. This area is one where combining the
features of diﬀerent feeds may be appropriate.
• Lack of proportionality.
It is tempting to measure
the prevalence of one kind of spam in a feed and ex-
trapolate to the entire world—“25% of all spam adver-
tises eBooks!” or “My spam ﬁlter can block 99.99% of
all spam”. However, the signiﬁcant diﬀerences in the
makeup of the feeds we have studied suggests that any
such conclusion is risky. For example, spam ﬁlter results
trained on botnet output may have little relevance to a
large Web mail provider. In general, we advise making
such claims based on knowledge of the source data set.
For example, MX-based honeypots may be appropriate
for characterizing relative prevalence among distinct
high volume spam campaigns.
While it is important to be aware of the limitations and
challenges of spam feeds, an even more interesting question
is what feeds one should use for related studies. The clear
answer, as shown by our results, is that there is no perfect
feed. Instead, the choice should be closely related to the
questions we are trying to answer. It is still possible, though,
to provide some general guidelines that would apply for most
cases:
• Human identiﬁed feeds, which are provided by large
mail providers, will usually be the best choice for most
studies. They provide a clear advantage when it comes
to coverage, due to their wide exposure, and allow for
visibility inside low-volume campaigns. They do so
with reasonable purity, but due to the presence of the
human factor, ﬁltering is required. On the other hand,
we should avoid human identiﬁed feeds when we are
interested in timing, and especially last appearance
information.
• If it is not possible to get access to human identiﬁed
feeds, due to their limited availability, high-quality
blacklist feeds oﬀer very good coverage and ﬁrst ap-
pearance information. They also oﬀer the best purity
since they are usually commercially maintained, and
have low false positives as their primary goal. Similar to
human identiﬁed feeds, they are less useful for studies
that rely on last appearance or duration information.
• When working with multiple feeds, the priority should
be to obtain a set that is as diverse as possible. Addi-
tional feeds of the same type oﬀer reduced added value,
and this situation is especially true in the case of MX
honeypot feeds.
• It is very challenging to obtain accurate information
regarding volume and provide conclusions that apply
to the entirety of the spam problem. Given our lim-
ited view into the global spam output, all results are
inherently tied to their respective input datasets.
In a sense, the spam research community is blessed by
having so many diﬀerent kinds of data sources available to
it. In many other measurement regimes the problem of bias
is just as great, but the number of data sources on hand is
far fewer. However, with great data diversity comes great
responsibility. It is no longer reasonable to take a single spam
feed and extrapolate blindly without validation. Our paper
provides a basic understanding of the limitations of existing
feeds and provides a blueprint for reﬁning this understanding
further.
Acknowledgments
We would like to thank the named and anonymous providers
of our feeds, whose willingness to share data with us made
a paper such as this possible. We are also grateful to Brian
Kantor and Cindy Moore who have managed our systems
and storage needs.
This work was supported by National Science Foundation
grants NSF-0433668, NSF-0433702, NSF-0831138, by Oﬃce
of Naval Research MURI grant N000140911081, and by gen-
erous research, operational and in-kind support from the
UCSD Center for Networked Systems (CNS).
6. REFERENCES
[1] Alexa. Alexa top 500 global sites.
http://www.alexa.com/topsites, June 2011.
[2] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker.
Spamscatter: Characterizing Internet Scam Hosting
Infrastructure. In Proc. of 16th USENIX Security, 2007.
[3] I. Androutsopoulos, J. Koutsias, K. Chandrinos,
G. Paliouras, and C. D. Spyropoulos. An Evaluation of Naive
Bayesian Anti-Spam Filtering. In Proc. of 1st MLNIA, 2000.
[4] R. Beverly and K. Sollins. Exploiting Transport-Level
Characteristics of Spam. In Proc. of 5th CEAS, 2008.
[5] X. Carreras and L. M`arquez. Boosting Trees for Anti-Spam
Email Filtering. In Proceedings of RANLP-2001, 2001.
[6] R. Clayton. How much did shutting down McColo help? In
Proc. of 6th CEAS, 2009.
[7] H. Drucker, D. Wu, and V. N. Vapnik. Support vector
machines for spam categorization. In Proc. of IEEE
Transactions on Neural Networks, 1999.
[8] G. Gee and P. Kim. Doppleganger Domains.
http://www.wired.com/images_blogs/threatlevel/2011/
09/Doppelganger.Domains.pdf, 2011.
439[9] P. H. C. Guerra, D. Guedes, W. M. Jr., C. Hoepers, M. H.
P. C. Chaves, and K. Steding-Jessen. Spamming Chains: A
New Way of Understanding Spammer Behavior. In Proc. of
6th CEAS, 2009.
[10] P. H. C. Guerra, D. Guedes, W. M. Jr., C. Hoepers, M. H.
P. C. Chaves, and K. Steding-Jessen. Exploring the Spam
Arms Race to Characterize Spam Evolution. In Proc. of 7th
CEAS, 2010.
[11] J. P. John, A. Moshchuk, S. D. Gribble, and
A. Krishnamurthy. Studying Spamming Botnets Using
Botlab. In Proc. of 6th NSDI, 2009.
[12] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M.
Voelker, V. Paxson, and S. Savage. Spamalytics: An
Empirical Analysis of Spam Marketing Conversion. In Proc.
of 15th ACM CCS, 2008.
[13] M. Konte, N. Feamster, and J. Jung. Dynamics of Online
Scam Hosting Infrastructure. In PAM, 2009.
[26] B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. P.
Rubinstein, U. Saini, C. Sutton, J. D. Tygar, and K. Xia.
Exploiting Machine Learning to Subvert Your Spam Filter.
In Proc. of 1st USENIX LEET, 2008.
[27] ODP – Open Directory Project. http://www.dmoz.org,
September 2011.
[28] A. Pathak, Y. C. Hu, , and Z. M. Mao. Peeking into
Spammer Behavior from a Unique Vantage Point. In Proc.
of 1st USENIX LEET, 2008.
[29] A. Pathak, F. Qian, Y. C. Hu, Z. M. Mao, and S. Ranjan.
Botnet Spam Campaigns Can Be Long Lasting: Evidence,
Implications, and Analysis. In Proc. of 9th ACM
SIGMETRICS, 2009.
[30] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich,
G. Voelkera, V. Paxson, N. Weaver, and S. Savage. Botnet
Judo: Fighting Spam with Itself. In Proc. of 17th NDSS,
2010.
[14] C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M.
[31] Z. Qian, Z. Mao, Y. Xie, and F. Yu. On network-level
Voelker, V. Paxson, and S. Savage. On the Spam Campaign
Trail. In Proc. 1st USENIX LEET, 2008.
[15] C. Kreibich, C. Kanich, K. Levchenko, B. Enright, G. M.
Voelker, V. Paxson, and S. Savage. Spamcraft: An Inside
Look at Spam Campaign Orchestration. In Proc. of 2nd
USENIX LEET, 2009.
[16] M. Lee. Why My Email Went. http:
//www.symantec.com/connect/blogs/why-my-email-went,
2011.
[17] N. Leontiadis, T. Moore, and N. Christin. Measuring and
Analyzing Search-Redirection Attacks in the Illicit Online
Prescription Drug Trade. In Proc. of USENIX Security,
2011.
[18] K. Levchenko, A. Pitsillidis, N. Chachra, B. Enright,
M. F´elegyh´azi, C. Grier, T. Halvorson, C. Kanich,
C. Kreibich, H. Liu, D. McCoy, N. Weaver, V. Paxson, G. M.
Voelker, and S. Savage. Click Trajectories: End-to-End
Analysis of the Spam Value Chain. In Proc. of IEEE
Symposium on Security and Privacy, 2011.
[19] H. Liu, K. Levchenko, M. F´elegyh´azi, C. Kreibich, G. Maier,
G. M. Voelker, and S. Savage. On the Eﬀects of
Registrar-level Intervention. In Proc. of 4th USENIX LEET,
2011.
[20] M86 Security Labs. Top Spam Aﬃliate Programs. http://
www.m86security.com/labs/traceitem.asp?article=1070,
2009.
[21] Marshal8e6 TRACELabs. Marshal8e6 Security Threats:
Email and Web Threats. http://www.marshal.com/
newsimages/trace/Marshal8e6_TRACE_Report_Jan2009.pdf,
2009.
[22] M. M. Masud, L. Khan, and B. Thuraisingham. Feature
Based Techniques for Auto-Detection of Novel Email Worms.
In Proc. of 11th PACKDDD, 2007.
[23] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver, C. Kreibich,
B. Krebs, G. M. Voelker, S. Savage, and K. Levchenko.
PharmaLeaks: Understanding the Business of Online
Pharmaceutical Aﬃliate Programs. In Proc. of the USENIX
Security Symposium, 2012.
[24] D. K. McGrath and M. Gupta. Behind Phishing: An
Examination of Phisher Modi Operandi. In Proc. of 1st
USENIX LEET, 2008.
[25] T. Moore and R. Clayton. Examining the Impact of Website
Take-down on Phishing. In Proceedings of the Anti-Phishing
Working Group’s 2nd annual eCrime Researchers Summit.
ACM, 2007.
clusters for spam detection. In Proc. of 17th NDSS, 2010.
[32] A. Ramachandran, N. Feamster, and S. Vempala. Filtering
Spam with Behavioral Blacklisting. In Proc. of 14th ACM
CCS, 2007.
[33] D. Samosseiko. The Partnerka — What is it, and why should
you care? In Proc. of Virus Bulletin Conference, 2009.
[34] F. Sanchez, Z. Duan, and Y. Dong. Understanding Forgery
Properties of Spam Delivery Paths. In Proc. of 7th CEAS,
2010.
[35] S. Sinha, M. Bailey, and F. Jahanian. Shades of Grey: On
the eﬀectiveness of reputation-based blacklists. In Proc. of
3rd MALWARE, 2008.
[36] O. Thonnard and M. Dacier. A Strategic Analysis of Spam
Botnets Operations. In Proc. of 8th CEAS, 2011.
[37] Trustwave. Spam Statistics – Week ending Sep 2, 2012.
https:
//www.trustwave.com/support/labs/spam_statistics.asp,
September 2012.
[38] G. Warner. Random Pseudo-URLs Try to Confuse
Anti-Spam Solutions. http://garwarner.blogspot.com/
2010/09/random-pseudo-urls-try-to-confuse-anti.html,
Sept. 2010.
[39] C. Wei, A. Sprague, G. Warner, and A. Skjellum. Identifying
New Spam Domains by Hosting IPs: Improving Domain
Blacklisting. In Proc. of 7th CEAS, 2010.
[40] A. G. West, A. J. Aviv, J. Chang, and I. Lee. Spam
Mitigation Using Spatio-temporal Reputations From
Blacklist History. In Proc of 26th. ACSAC, 2010.
[41] J. Whissell and C. Clarke. Clustering for Semi-Supervised
Spam Filtering. In Proc. of 8th CEAS, 2011.
[42] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and
I. Osipkov. Spamming Botnets: Signatures and
Characteristics. In Proceedings of ACM SIGCOMM, 2008.
[43] L. Zhuang, J. Dunagan, D. R. Simon, H. J. Wang, I. Osipkov,
G. Hulten, and J. Tygar. Characterizing Botnets from Email
Spam Records. In Proc. of 1st USENIX LEET, 2008.
[44] J. Zittrain and L. Frieder. Spam Works: Evidence from
Stock Touts and Corresponding Market Activity. Social
Science Research Network, March 2007.
440