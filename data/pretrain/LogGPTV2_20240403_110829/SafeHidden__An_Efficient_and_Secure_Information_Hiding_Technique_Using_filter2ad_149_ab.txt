reduce the number of probings. After spraying, the attackers
only need very few probes to locate the safe area.
2.2.1 Memory Scanning
2.2.2 Cache-based Side-Channel Attacks
The attackers could avoid crashes during their brute-force
probing. For example, some adversaries have discovered that
some daemon web servers have such features. The daemon
servers can fork worker processes that inherit the memory
layout. If a worker process crashes, a new worker process
will be forked. This enables the so-called clone-probing at-
tacks where an adversary repeatedly probes different clones
in order to scan the target memory regions [35]. CROP [19]
chooses to use the exception handling mechanism to avoid
crashes. During the probing, an access violation will occur
when an inadmissible address is accessed. But, it can be cap-
tured by an exception handler instead of crashing the system.
Attackers could also use memory management APIs to in-
fer the memory allocation information, and then locate the
safe area. In [43], it leverages the allocation oracles to ob-
tain the location of a safe area. In a user’s memory space,
there are many unmapped areas that are separated by code
and data areas. To gauge the size of the largest unmapped
and the offset is equal to 0. The only difference is that it will change the
value of the designated register.
To translate a virtual address to a physical address, the MMU
initiates a page table (PT) walk that visits each level of the
page table sequentially in the memory. To reduce the la-
tency, most-recently accessed page table entries are stored in
a special hardware cache, called translation lookaside buffer
(TLB). Because of the large virtual address space in 64-bit
architectures, a hierarchy of cache memories has been used
to support different levels of page-table lookup. They are
called the page table caches, or paging-structure caches by
Intel [2]. In addition, the accessed PT entries are also fetched
into the last level cache (LLC) during the page-table walk.
It has been demonstrated that cache-based side-channels
can break coarse-grained address space layout randomiza-
tion [22]. The location of the safe area can be deter-
mined through the following attack method: First, the at-
tacker triggers the defense system’s access to the safe area.
To ensure this memory access invokes a PT walk, the at-
tacker cleanses the corresponding TLB entries for the safe
area’s virtual address beforehand. Second, the attacker con-
ducts a Prime+Probe or Evict+Time cache side-channel
USENIX Association
28th USENIX Security Symposium    1241
attack [44] to monitor which cache sets are used during the
PT walk. As only certain virtual addresses map to a speciﬁc
cache set, the virtual address of the safe area can be inferred
using cache side-channel analysis.
However, it is worth mentioning that to successfully de-
termine the virtual address of one memory area, hundreds of
such Prime+Probe or Evict+Time tests are needed. It is also
imperative that the addresses of the PTEs corresponding to
this memory area are not changed during these tests. That
is, the cache entries mapped by these PTEs are not changed.
Our defense effectively invalidates such assumptions.
3 Threat Model
We consider an IH-based defense that protects a vulnerable
application against code reuse attacks. This application ei-
ther stands as a server that accepts and handles remote re-
quests (e.g., through a web interface), or executes a sand-
boxed scripting code such as JavaScript as done in a mod-
ern web browsers. Accordingly, we assume the attacker has
the permission to send malicious remote requests to the web
servers or lure the web browsers to visit attacker-controlled
websites and download malicious JavaScript code.
This IH-based defense has a safe area hidden in the vic-
tim process’s memory space. We assume the design of the
defense is not ﬂawed: That is, before launching code reuse
attacks, the attacker must circumvent the defense by reveal-
ing the locations of the safe areas (e.g., using one of many
available techniques discussed in Section 2.2). We also as-
sume the implementation of defense system itself is not vul-
nerable, and it uses IH correctly. We assume the underlying
operating system is trusted and secured.
We assume the existence of some vulnerabilities in the ap-
plication that allows the attacker to (a) read and write arbi-
trary memory locations; (b) allocate or free arbitrary mem-
ory areas (e.g., by interacting with the application’s web in-
terface or executing script directly); (c) create any number of
threads (e.g., as a JavaScript program). These capabilities al-
ready represent the strongest possible adversary given in the
application scenarios. Given these capabilities, all known at-
tacks against IH can be performed.
3.1 Attack Vectors
Particularly, we consider the following attack vectors. All
known attacks employ one of the four vectors listed below to
disclose the locations of the safe areas.
• Vector-1: Gathering memory layout information to help
to locate safe areas, by probing memory regions to infer
if they are mapped (or allocated);
• Vector-2: Creating opportunities to probe safe areas
without crashing the system, e.g., by leveraging resum-
able exceptions;
Figure 1:
randomization with the dispersed trap areas.
The high-level overview of
the proposed re-
• Vector-3: Reducing the entropy of the randomized safe
area locations to increase the success probability of
probes, by decreasing the size of unmapped areas or in-
creasing the size of safe areas;
• Vector-4: Monitoring page-table access patterns using
cache side-channels to infer the addresses of safe areas,
while triggering legal accesses to safe areas.
4 SafeHidden Design
We proposed SafeHidden, an IH technique that leverages re-
randomization to prevent the attackers from locating the safe
areas. It protects safe areas in both single-threaded programs
and multi-threaded programs.
It is designed primarily for
Linux/X86 64 platform, as most of the defenses leveraging
IH are developed on this platform.
At runtime, SafeHidden detects all potential memory
probes. To avoid overly frequent re-randomization, it mi-
grates the safe area to a new randomized location only af-
ter the detection of a suspicious probing.
It then leaves a
trap area of the same size behind. Figure 1 illustrates the
high-level overview of the re-randomization method. In the
ﬁgure, the memory layout is changed as the location of the
safe area is being moved continuously, and the unmapped
memory space becomes more fragmented by trap areas. The
ever-changing memory layout could block Vector-1.
As the attackers continue to probe, new trap areas will be
created. Gradually, it becomes more likely for probes to
stumble into trap areas. If the attacker touches a trap area
through any type of accesses, SafeHidden will trigger a se-
curity alarm and capture the attack. The design of trap areas
mitigates the attacks from Vector-2, and signiﬁcantly lim-
its the attackers’ ability to probe the memory persistently.
While the attackers are still able to locate a safe area before
accessing the trap areas, the probability is proven to be very
small (see Section 4.4).
To block Vector-3, SafeHidden prevents unlimited shrink
of unmapped areas and unrestricted growth of safe areas:
(1) Unmapped areas. Because IH assumes that safe areas
are hidden in a very large unmapped area, SafeHidden must
prevent extremely large mapped areas.
In our design, the
1242    28th USENIX Security Symposium
USENIX Association
safe areatrap areacode/dataunmapped areamove safe area and leave a trapprobe 1initialprobe 2probe nEvents
Interception Points
memory management syscalls
syscalls that could return EFAULT
cloning memory space
memory access instructions
mmap, munmap, mremap, mprotect, brk, ...
read, write, access, send, ...
clone, fork, vfork
page fault exception
SA
Alarm
Alarm
Rand
–
Responses in SafeHidden
UA
Rand
Rand
Rand
Rand
TA
Alarm
Alarm
Rand
Alarm
OA
–
–
Rand
–
Table 2: Summary of potential stealthy probings and SafeHidden’s responses. “SA”: safe areas, “UA”: unmapped areas, “TA”: trap areas,
“OA”: other areas. “Alarm”: triggering a security alarm. “Rand”: triggering re-randomization. “–”: do nothing.
maximum size of the mapped area allowed by SafeHidden
is 64 TB, which is half of the entire virtual address space
in the user space. Rarely do applications consume terabytes
of memory; even big data applications only use gigabytes
of virtual memory space; (2) Safe areas. Although safe ar-
eas in IH techniques are typically small and do not expand
at runtime, attackers could create a large number of threads
to increase the total size of the thread-local safe areas. To
defeat such attacks, SafeHidden uses thread-private mem-
ory space to store thread-local safe areas. It maintains strict
isolation among threads. When the thread-local safe area is
protected using such a scheme, the entropy will not be re-
duced by thread spraying because any thread sprayed by an
attacker can only access its own local safe area.
To mitigate Vector-4, SafeHidden also monitors legal ac-
cesses to the safe area that may be triggered by the attacker.
Once such a legal access is detected, SafeHidden randomizes
the location of the safe area. As the virtual address of the safe
area is changed during re-randomization, the corresponding
PTEs and their cache entries that are used by the attacker to
make inferences no longer reﬂects the real virtual address of
the safe area. Thus, Vector-4 is blocked. It is worth noting
that unlike the cases of detecting illegal accesses to the safe
area, no trap area is created after the re-randomization.
In the following subsections, we will detail how SafeHid-
den recognizes and responds to the stealthy memory probes
(see Section 4.1), how SafeHidden achieves the thread-
private memory (see Section 4.2) and how SafeHidden de-
feats cache-based side-channel analysis (see Section 4.3).
4.1 Stealthy Memory Probes
In order to detect potential stealthy memory probes, we list
all memory operations in the user space that can potentially
be used as probings from the attackers (see Table 2).
The ﬁrst row of Table 2 lists system calls that are related
to memory management. The attackers could directly use
them to gauge the layout of the memory space by allocat-
ing/deallocating/moving the memory or changing the per-
mission to detect whether the target memory area is mapped
or not. The second row lists the system calls that could return
an EFAULT (bad address) error, such as “ssize t write
(int fd, void * buf, size t count)”. These system
calls have a parameter pointing to a memory address.
If
the target memory is not mapped, the system call will fail
without causing a crash, and the error code will be set to
EFAULT. These system calls can be used to probe the mem-
ory layout without resulting in a crash. The third row lists
the system calls that can clone a memory space. The at-
tackers could use them to reason about the memory layout
of the parent process from a child process. The fourth row
lists memory access instructions that can trigger a page fault
exception when the access permission is violated. The at-
tackers could register or reuse the signal handler to avoid a
crash when probing an invalid address.
Four types of memory regions are considered separately:
safe areas, unmapped areas, trap areas, and other areas. Un-
mapped areas are areas in the address space that are not
mapped; trap areas are areas that were once safe areas; other
areas store process code and data. As shown in Table 2,
SafeHidden intercepts different types of memory accesses to
these areas and applies different security policy accordingly:
• If the event is an access to an unmapped area, SafeHid-
den will randomize the location of all safe areas. The
original location of a safe area become a trap area.
• If the event is a memory cloning, it will perform ran-
domization in the parent process after creating a child
process, in order to make the locations of their safe ar-
eas different.
• If the event is an access to safe areas through memory
management system calls or system calls with EFAULT
return value, SafeHidden will trigger a security alarm.
• If the event is an access to trap areas through memory
access instructions, memory management system calls,
or system calls with EFAULT return value, it will trig-
ger a security alarm.
• SafeHidden does not react to memory accesses to other
areas. Since they do not have pointers pointing to the
safe areas, probing other areas do not leak the locations.
To avoid excessive use of the virtual memory space, Safe-
Hidden sets an upper limit on the total size of all trap areas
(the default is 1 TB). Once the size of trap areas reaches the
upper limit, SafeHidden will remove some randomly chosen
trap area in each randomization round.
USENIX Association
28th USENIX Security Symposium    1243
The design of such a security policy is worth further dis-
cussion here. Trap areas are previous locations of safe areas,
which should be protected from illegal accesses in the same
way as safe areas. As normal application behaviors never
access safe areas and trap areas in an illegal way, accesses
to them should raise alarms. For accesses to unmapped ar-
eas, an immediate alarm may cause false positives because
the application may also issue memory management system
calls, system calls with an EFAULT return value, or a mem-
ory access that touches unmapped memory areas. Therefore,
accesses to unmapped areas only trigger re-randomization of
the safe area to restore the randomness (that could invali-
date the knowledge of previous probes), but no alarm will be
raised. An alternative design would be counting the num-
ber of accesses to unmapped areas and raising a security
alarm when the count exceeds a threshold. However, setting
a proper threshold is very difﬁcult because different probing
algorithms could have different probing times. Therefore,
monitoring critical subsets of the unmapped areas—the safe
areas and trap areas—appears a better design choice.
4.2 Thread-private Memory
Thread-private memory technique was usually used in multi-
threaded record-and-replay techniques [25, 7, 31]. We pro-
pose to use thread-private memory to protect safe areas.
Conventional methods to implement thread-private memory
is to make use of thread-private page tables in the OS ker-
nel. As a separate page table is maintained for each thread,
a reference page table for the entire process is required to
keep track of the state of each page. The modiﬁcation of
the kernel is too complex, which cannot be implemented as
a loadable kernel module: For example, to be compatible
with kswapd, the reference page table must be synchronized
with the private page tables of each thread, which requires
tracking of CPU accesses of each PTE (especially the setting
of the accessed and dirty bits2 by CPU). The need for ker-
nel source code modiﬁcation and recompilation restricts the
practical deployment of this approach.
To address this limitation, we propose a new approach to
implement thread-private memory using the hardware vir-
tualization support. Currently, a memory access in a guest
VM needs to go through two levels of address translation: a
guest virtual address is ﬁrst translated into a guest physical
address through the guest page table (GPT), which is then
translated to its host physical address through a hypervisor