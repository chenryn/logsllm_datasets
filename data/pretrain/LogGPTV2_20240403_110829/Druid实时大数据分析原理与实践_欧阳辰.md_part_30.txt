245
---
## Page 270
考虑使用其他的商用工具，如OneAPMCloudInsight等，如图9-12所示。
架构实现，如图9-1所示。
本章不作过多描述。至此，我们便可以将该基于HTTP方法的方案简化并映射为一个具体的
项目druid-metrics-to-kafka的具体使用方法，我们将在第11章“Druid生态与展望”中分析
数据到Kafka消息缓存系统中，所以你可以直接利用该项目来加速实现监控系统。关于开源
kafka的开源项目帮助你完成了同样的工作一
HTTP Server。幸运的是，你不需要这样做，因为目前已经有了一个叫作druid-metrics-to-
246
对于Druid指标的可视化展示与交互式分析，除了使用开源的Pivot等工具外，也可以
图9-2
图9-1
druid-metrics-
Druid Cluster
to-kafka
OneAPM Cloud Insight 对 Druid 监控的支持
基于HTTP方法的监控系统架构示意图
LH
druid
一直接接收并转发通过HTTP发送过来的指标
saprogram.
druidanalytic
Druid实时大数据分析原理与实践
---
## Page 271
它，而是使用了ApacheFlume，主要原因如下。
此，特在本章向读者朋友们做相应介绍。
技术得以普及的一个重要因素。Elasticsearch技术栈中的Elasticsearch、Logstash和Kibana三
提供了许多补充性功能，这使得Elasticsearch技术的可接受度得以大大提高一这也正是该
Elasticsearch还拥有一个较为完善的生态系统，即有很多其他项目围绕着Elasticsearch展开并
搜索引擎，目前可以说是业内使用最广泛的一款产品。除了拥有出色的搜索引擎这一优点外，
要求的监控系统。
技术栈构建的解决方案一—该技术的确很适合目前的场景，帮助我们加速从零创建一个满足
介绍的方案一样使用Druid本身来存储这些指标数据。接下来将介绍一个基于Elasticsearch
容的应用程序并在其中使用正则表达式来解析和提取出所期待的指标数据，也可以和上文所
析所获得的指标数据。当然，有很多方法可以实现这些功能，比如编写能够读取新增日志内
据，然后将这些指标数据存储到适当的数据库中，接下来最好还有可视化工具帮助查看和分
应的程序能够获取不断更新的日志内容，从中解析并提取出所有感兴趣的Druid监控指标数
第9章
在实际工作中利用相似的技术栈来构建自己的Druid监控系统并取得了很好的应用效果。因
自己的日志分析与监控系统，而Druid正好可以将指标数据输出到日志文件中，所以我们也
个模块常常被一起使用，因此被广大用户简称为ELK。实际上，ELK经常被用户用来构建
基于日志方法的监控系统设计方案
Elasticsearch是一个基于Lucene技术的全文检索平台，它提供了一个分布式且多租户的
虽然Logstash是一款轻量级且使用方便的ETL工具，但我们的解决方案中并没有使用
首先介绍一下ELK中除Elasticsearch之外的两个项目。
如果Druid系统采取的是基于日志的方法往外直接发送监控指标，那么你首先需要有对
·以Hadoop为中心的大数据技术生态圈基本以Java为主要开发语言，Flume也一样。但
·同样是主要用于ETL任务的Apache Flume，作为Apache顶级项目，比Logstash 有着
·Kibana：为Elasticsearch提供一个基于Web的可视化展示与分析接口。
·Logstash：主要用来收集日志信息，并可以对其进行一些自定义操作，然后再将数据
ETL工具进行二次开发或改进时，Logstash的成本可能会高于Flume。
是Logstash却不是用Java开发的，如果我们想对自己的以Java为主的大数据平台中的
更广泛的开源基础与社区活跃度，并且已经成为Hadoop生态圈的事实标准。
数据ETL（抽取Extract，转换Transform，加载Load）操作。
信息传送到指定的服务器上。简而言之，它适合在数据进人Elasticsearch之前为其做
监控和安全
247
---
## Page 272
砖引玉的效果。
可以轻松地得知查询性能问题究竟出于何处。
析，就需要同时对这三个角色的节点进行统计分析方可得到较为客观的判定。因此，我们的
能是实时节点和历史节点的问题。所以，如果用户想通过监控系统对查询性能问题进行剖
客户通过查询节点进行查询时感觉性能不好，也不能确定一定是查询节点的问题，因为也可
我们知道查询节点、实时节点和历史节点都能决定Druid集群的查询性能。也就是说，即使
统的效果图（见图9-4、图9-5和图9-6），希望能够给读者朋友们一些感性认识。
Flume→Kafka→Flume→Elasticsearch→Kibana。系统架构如图9-3所示。
情况。
监控系统收集了这三个角色上的所有request time指标值，然后通过Kibana端图像化展示便
248
我们就先展示这几个实际生产系统中的监控指标及其对应的监控界面，希望能够起到抛
首先，我们看看通过监控系统来分析Druid集群的查询性能问题。根据前面章节的介绍，
当然，我们还可以通过收集events thrown away指标来统计实时节点对超时数据的丢弃
我们也可以通过收集events processed指标来统计实时节点的成功消费数据情况。
下面展示几张我们在实际生产环境中基于上述 Elasticsearch技术栈构建的Druid监控系
同时，我们采用了Kafka作为消息缓存系统，
Druid Cluster
图9-3基于日志方法的监控系统架构示意图
Log
elasticsearch.
，因此Druid 监控系统的数据流是：Log→
kibana
Elasticsearch analytic
program.
Druid实时大数据分析原理与实践
---
## Page 273
第9章
监控和安全
图9-6在监控系统中统计实时节点对超时数据的丢弃情况
图9-5在监控系统中统计实时节点的成功消费数据情况
图9-4在监控系统中分析Druid查询性能问题
249
---
## Page 274
统与上文所介绍的监控系统集成的架构示例，供大家参考。
在通常情况下，大多数解决方案都会同时包含监控系统与告警系统，图9-7所示便是告警系
定好告警规则与告警方式，在接收到Druid发送过来的告警信息时系统就可触发告警行为。
将指标数据发送到具备告警功能的系统（AlertSystem）中。在告警系统中，用户只要提前设
或Flume来完成告警信息的抽取，并通过用户自己编写的指标发送模块（MetricsForwarder）
备告警系统的模块实现一个完整的告警功能。比如，如同监控系统一样，可以使用Logstash
9.2.2
送两种方式发送告警信息的。Druid告警信息一般包含的字段如下。
其告警信息默认也是关闭不开启的，而且也是通过发送到日志文件，或者通过HTTP往外发
9.2.1
个功能完备的告警系统，而仅仅是提供最基础的告警信息给用户。
指标数据的监控系统。对于告警功能来说，Druid也采取了同样的措施一
持，自己并不会直接提供完整的监控模块，因此用户需要自己搭建起能够接收并分析Druid
9.2
250
正如上文所述，Druid并不会提供一个功能完备的告警系统，因此用户可以通过其他具
Druid系统会在系统发生异常情况时产生告警信息。如同普通的Druid监控指标一样，
·data：如果告警信息是异常（Exception）类型，那么它会以JSON格式往外发出，并
·description：告警信息的描述。
·service：发出告警信息的服务。
·timestamp：告警信息产生时间的时间戳。
通过上文的介绍，大家可以了解到Druid主要通过提供指标数据来实现监控功能的支
severity：告警信息的级别。
host：发出告警信息的主机。
Druid告警信息
Druid告警
Druid与告警系统的集成
Druid实时大数据分析原理与实践
一它并不会提供
---
## Page 275
能，或者至少也将Kerberos当作其安全认证方面的组件选择之一，因此Kerberos 几乎在很多
9.3.1
者对基本的安全问题有所了解。
系统与其他系统进行安全集成这个角度来介绍实际工作中的一些相关经验，希望能够帮助读
网系统中，安全往往都是必须要考虑并完善的部分。因此在本节中，笔者就从如何将Druid
们在实际工作中使用Druid时就可以完全不考虑安全问题。相反，在很多企业级或大型互联
是授权方面都做得很少，甚至可以说基本上没有任何实质性的相关功能。但是这并不表示我
9.3
第9章！
在当今的分布式技术领域，很多组件都会选择Kerberos来为其加强安全认证方面的功
然而，遗憾的是，
·授权（Authorization）：限定用户在系统中的权限范围，即指明某个用户在哪些系统模
·认证（Authentication）：证明用户的确是他自己声明的那个用户的过程，即身份验证
如同对其他信息系统的考虑一样，我们对Druid安全的关注也主要分为两个部分。
Druid安全
块中有哪些行为权限。
的过程。
Druid与利用Kerberos加强安全认证的系统集成
监控和安全
Metrics
，即使拿目前Druid的最新版本（0.9.1.1）来看，它自身无论在认证还
图9-7Druid告警系统与监控系统集成架构示例
Druid Cluster
Log
LO
elasticsearch.
kibana
Elasticsearch analytic
eibod
251
---
## Page 276
性、效率更高等。
加密算法，使其拥有许多单机版认证服务器所难以拥有的优点，比如更高的安全性、更具弹
安全认证模块，Kerberos不是一个单独的认证服务器，而是采用了客户端/服务器结构与对称
者，也通过该寓意来表明Kerberos系统希望自己能够成为系统安全之守护神。不同于传统的
1.Kerberos简介
与该类系统进行集成。
统集成使用，比如 HDFS、Kafka、Zookeeper等，因此有必要在本节中举例介绍如何将 Druid
Kerberos的直接支持，但是Druid系统常常需要同那些自身通过Kerberos完成安全认证的系
领域都成为了事实上的标准。虽然目前Druid系统自身并无认证方面的功能模块，也没有对
252
·客户端（Client）：发起服务请求的系统。
Kerberos系统的应用场景主要包含三个组件模块（见图9-8）。
Kerberos系统的命名十分贴切：它借鉴于希腊神话中拥有三个头的狗，即地狱之门守护
·密钥分发中心（KeyDistribution Center，KDC）：第三方服务，用来对不同计算机的
·服务端（Service）：真正提供服务的系统
Kerberos认证服务器和票据授权服务器。
身份进行验证，并建立密钥以保证计算机间安全连接。KDC又包含两个子模块一
图9-8Kerberos系统模块
Request
Service Request
7Broker/KDC
Authentication
Store
Druid实时大数据分析原理与实践
---
## Page 277
概思路。
部分也不是本书的重点，因此就不在此处进行更多的描述了。
第9章监控和安全
方法，因此仅仅拿与启用了Kerberos的HDFS系统集成作为示例，从而说明这一类集成的大
等，而它们都可能与Druid系统进行集成，但是本书没有办法穷举Druid与这些系统集成的
2.
Druid与使用了Kerberos的HDFS进行集成
·用户与服务器之间的安全连接问题。NameNode、DataNode和JobTracker都没有安全
Hadoop在其版本1.0.0之前存在着较大的安全问题，简单总结起来有以下两点。
现在很多系统的安全认证模块都基于Kerberos搭建而成，比如HDFS、Kafka、Zookeeper
关于Kerberos的知识介绍，无论在互联网上还是各种相关书籍中已有很多资料，而且这
（5）服务端返回响应给客户端。
（4）服务端对从客户端得到的服务票据进行验证。
（3）客户端带着获得的服务票据将请求发送给服务端。
（2）KDC返回服务票据给客户端。
（1）客户端向KDC请求认证票据。
基于Kerberos的完整认证过程一般包含以下几个步骤（见图9-9）。
的系统风险。
认证，因此任何用户登录都可以伪装成其他用户以执行几乎任何操作，从而导致较高
Client
图9-9
Ticket Request
SendResponse
Kerberos认证过程的步骤
③SendRequest
Service
K
validateTicket
253
---
## Page 278
以下步骤。
来要将DeepStorage 迁移到一个启用了Kerberos 安全认证模块的 HDFS集群上，所以执行了
来进行实例说明。当时，我们的 Druid集群在一开始并没有使用 HDFS 作为 DeepStorage，后
就要将Druid系统通过符合Kerberos的方式来访问HDFS，即需要如下操作。
Kerberos的安全认证功能模块。因此，在这些环境中如果要添加Druid系统，而且Druid系
从而完美地解决了上述安全问题。所以，现在很多企业的Hadoop集群往往都会启用基于
254
（1）创建Druid节点所需的Kerberos principal和keytab。
大家看了上述内容后可能会觉得有些抽象，现在笔者就举一个在实际工作中碰到的情况
·在Druid系统相关节点（实时节点和历史节点）上安装配置kerberos客户端和HDFS
简单总结来说，要想使Druid系统成功与启用了Kerberos安全认证模块的HDFS集成，
正因如此，Hadoop在其版本1.0.0之后，引人了Kerberos模块作为其安全认证的基石
·服务器之间的安全连接问题。DataNode和TaskTracker没有安全认证，因此用户可以
·生成 keytab（参考命令： xst-norandkey-k appd.keytab appd/x86-ubuntu HTTP/x86-ubuntu ）,
·尽量为每一个需要访问KerberizedHDFS的Druid节点都分别创建一个principal，prin-
·在Druid系统相关节点（实时节点和历史节点）启动后，要保证其所需的Kerberos
·在Druid系统相关节点（实时节点和历史节点）启动时添加Kerberos所依赖的文件。
·在Druid系统相关节点（实时节点和历史节点）上生成Kerberos principal和keytab。
伪装成DataNode和 TaskTracker接受来自NameNode和 JobTracker的任务。
复制到Druid节点的相应目录下，并保证Druid进程用户有读权限。
客户端。
myname/x86-ubuntu@DRUID.COM.
的名称请参考KDC的配置，必须使用与当前KerberizedHDFS一致的realm，比如
令查看当前机器的静态主机名，或者使用当前主机在Druid集群中的主机名；realm
参考）。其中principal的名称可以任意；所在主机的主机名可以通过hostnamectl命
TGT一直处于有效时间内。
Druid实时大数据分析原理与实践
---
## Page 279
9.3.2
够访问其HDFS配置文件和HDFS所需要的jar包，并能够读写HDFS上分配给Druid集群
第9章监控和安全
问题。比如，假设对所有Druid用户都不设置权限的话，可能会导致如下问题。
但是在此之前，我们依然需要考虑Druid的一些授权问题，否则可能会导致一些比较严重的
早日完成该开发任务，以便广大Druid用户可以尽早将安全模块应用到自己的生产系统中。
行相关的开发任务（主要是对DataSource进行用户权限的划分与管理），我们期待社区能够
了解情况以及实际需求来制定自已的集成方案。
集群进行了集成。当然，上述步骤并非唯一的集成方法，大家也可以根据自己对Kerberos的
文件（如-Djava.security.krb5.conf=/etc/krb5.conf）和其他文件等。
用的目录。
执行了上述步骤后，我们的Druid集群就成功与启用了Kerberos安全认证模块的HDFS
目前Druid并没有授权方面的具体功能，但是值得庆幸的是，Druid开发社区已经在进
（3）在所有Druid的实时节点和历史节点上安装HDFS客户端，保证Druid进程用户能
·检查/etc/krb5.conf配置文件。其中参数ticket_lifetime为TGT超时时长，renew_lifetime
（2）在所有Druid的实时节点和历史节点上安装配置kerberos客户端。
·任何用户都能够向任何DataSource写入数据，这可能会导致由于误操作而带来的数据
·任何用户都可以查询任意时间范围内的数据，这可能会造成Druid集群的负载难以管
·任何用户都能够访问Druid集群的任何DataSource，这可能会导致有些保密程度较高
·添加Crontab 任务，定期执行kinit 命令来更新TGT（供参考的kinit命令：kinit-k
的数据也会被不加限制地访问到，从而造成泄密。
准确度变差问题，甚至给系统带来经济方面的损失。
影响到其他正常查询的进行。
控与分配，而某些超长时间范围的查询甚至有可能会导致系统陷入不稳定状态，从而
小于TGT的有效期，即必须在TGT失效前就更新TGT。
-tappd.keytabappd/PI:EMAIL）。需要注意的是，kinit 的更新频率必须
为TGT刷新的生命周期时长。
集成外部权限模块完成用户授权
---
## Page 280
驾驭Druid，使它发挥出更大的能量。
实践出真知，大家可以在使用Druid的过程中活学活用这些知识，这样就能帮助自己更好地
9.4
的示例。
成，从而形成一套完整且易与其他已有系统进行集成的权限模块。图9-10所示是一个简单
模块来访问Druid集群，并且同时将用户自己的系统以及权限管理模块与该代理模块进行集
限管理模块来补齐Druid在这方面的缺陷。举个具体的例子，我们可以让用户通过一个代理
256
通过本章的介绍，相信读者朋友们已经对Druid的监控与安全相关知识有了不少了解。
正因如此，即使 Druid自身不提供用户权限管理，我们也应该在Druid之外提供一些权
小结
图9-10用户自定义权限管理模块与Druid系统的集成
Systemi
Druid Authorizati
ition
Write
Druid Access
Proxy
druid
Read
Druid实时大数据分析原理与实践
User System
---
## Page 281
中国的优质科技产品。
品，用工匠精神做产品，用互联网模式节省了中间环节，致力于让全球每个人都能享用来自
家居生态链建设的创新型科技企业。
10.1小米
较大的公司对Druid的使用实践，希望能够帮助读者事半功倍地学习Druid这项年轻的技术。
恰是有助于更加深人学习、多角度理解Druid的宝贵材料。因此，本章会介绍一些背景差异
景也大相径庭，所以各自对Druid的使用场景也有许多迥异之处一而这些独到的地方也恰
然而，Druid用户其实分布在许多不同的行业和领域，大家使用Druid的业务基础与技术背
性，因此不同用户对Druid的使用也势必有许多相似之处，这可以说是件顺理成章的事情。
小米、优酷土豆、腾讯、蓝海讯通等），同时也覆盖了许多朝气蓬勃的创业团队。
（如雅虎、eBay、MetaMarkets与Hulu等），也包含了很多国内同样声名遐迩的知名公司（如
技术栈中赢得了一席之地。在成为Druid用户的公司中不乏很多国外赫赫有名的互联网企业
名度与口碑，并且陆续成为了很多技术团队解决方案中的关键一环，从而真正在很多公司的
“让每个人都能享受科技的乐趣”是小米公司的愿景。小米公司应用互联网模式开发产
小米公司正式成立于2010年4月，是一家专注于高端智能手机、互联网电视以及智能
Druid收获了如此多的用户，那么大家一定都是不约而同地看中了Druid的某些关键属