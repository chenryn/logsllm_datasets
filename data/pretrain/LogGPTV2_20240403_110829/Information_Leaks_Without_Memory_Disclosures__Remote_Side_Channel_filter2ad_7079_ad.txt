2
Crash Locations Known
10
60
180
All
 0
 10
 20
 30
 40
 50
 60
 70
 0
 10
 20
 30
 40
 50
 60
 70
Uncertainty Set Size
Uncertainty Set Size
Figure 5: Information learned as more re-
turn values are known
s
n
o
i
t
c
n
u
F
f
o
n
o
i
t
c
a
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Timing Values Known
All
3
4
1
2
 0
 10
 20
 30
 40
 50
 60
 70
Uncertainty Set Size
Figure 6:
timing values are known
Information learned as more
Information learned as more
Figure 4:
crash locations are known
uses the most efﬁcient capability to leak more information about
the unknown parts of the code. Third, it updates the pool with any
newly discovered gadgets. We stop when we have either leaked
enough information to learn the exploit gadgets or have leaked the
entire code.
Slow Side Channel Attack. If certain gadgets are available to
use, then those are put into the pool of gadgets. Otherwise, we
assume that initially the attacker can only conduct a slow timing
attack, where a piece of code can only be executed once.
This attack requires that a piece of code is found where pointers
can be manipulated such that the code performs some computa-
tion on itself and that the execution time is dependent on the input.
Thus, if code such as a spinlock is found, we can use it to discern
what code is at some memory address.
To know how long the piece of code should take to execute, we
can use a database of timing values, similar to what was developed
in §4. To get a proper timing baseline for the vulnerable remote
host, we ﬁrst send many requests without exploiting it. We time
how long the baseline execution takes, which will be subtracted
from any future timing measurements. We then start probing mem-
ory locations by overwriting the data pointer, and measuring the
execution time. If a certain amount of timing precision is needed,
the experiment is repeated.
Fast Side Channel Attack. If enough gadgets are found to cre-
ate a ROP conditional jump, we use it to increase efﬁciency. The
conditional jump allows a payload to be constructed where a piece
of code executes x times. We can then reduce the number of mea-
surements needed. For example, if enough gadgets are available we
can implement a spinlock itself.
The timing payload will then contain either the memory address
of a code pointer (e.g., a return address on the stack) or the code
itself. A gadget then loads the memory address into a register
and other gadgets somehow use that register as an iterator in the
conditional jump. The timing result will then indicate how many
times that piece of code was executed. This requires knowing how
much time executing the piece of code once takes, which will be
known through the database previously constructed. Eventually, as
more memory addresses are measured, enough information will be
leaked so as to learn a system call gadget. Once accomplished, we
are able to compile the exploit based on the exact code in memory.
6. MEASUREMENTS AND RESULTS
We develop a tool to conduct a timing attack against Apache
2.4.7 and evaluate the accuracy of timing information for two types
of networks: a 802.11g wireless network and a wired LAN with
two routers. We evaluate our attack against four types of code
diversiﬁcation defenses: coarse-grained ASLR [40], function per-
mutation (medium-grained ASLR) [26], basic block randomization
(ﬁne-grained ASLR) [45], and NOP insertion [16].
In our attack we use Apache HTTP Server 2.4.7 (the most recent
version at the time of writing this paper) and glibc 2.16. A stack
overﬂow vulnerability (CVE-2004-0488) from an earlier version of
Apache was reapplied to create the initial vulnerability. The vulner-
ability allows an attacker to place arbitrary values on the stack.
Below is one example of a side channel vulnerable code from
Apache, which is in Apache’s /server/log.c ﬁle and is responsible
for formatting error logs. We redirect the fmt pointer using the
overﬂow vulnerability to a chosen byte in memory. The additional
delay in processing the request is proportional to the byte value.
1 for (i = 0; i nelts; ++i) {
2
ap_errorlog_format_item *item = &items[i];
6.1 Slow Timing Attack
During the slow side channel attack, we redirect the loop itera-
tor (fmt->nelts) using the Apache vulnerability to measure a
chosen byte. This adds a small amount of delay into the query pro-
cessing part of Apache. The success of our attack depends on the
ability to observe the small delay caused by the loop over the net-
work. Although this delay is small, by sending many queries to the
server, the extra delay adds up over the baseline delay.
We measure the cumulative delay in two different setups: one in
which the attacker is on the same 802.11g wireless access point as
the victim and another one in which the attacker is three hops away
from the victim on a wired LAN with two routers in between.
In each case, we start by measuring the time between an HTTP
request and response 10,000 times to collect the timing samples (we
will later reduce the sample size to its minimum). Since Crosby et
al. [12] show that the ﬁrst percentile yields the most precise timing
measurement, we only keep the fastest 1% samples and discard the
rest to account for abnormally large delays caused by various net-
work conditions. Figures 7 and 8 illustrate the results. For the sake
of space and readability, we just show the delay for eleven different
byte values pointed to by fmt. The maximum standard deviation
among all the LAN measurements for different byte values is 0.557
ms and for the wireless measurements it is 0.715 ms.
We use these measurements to estimate the bytes on the victim
Apache machine. For the actual attack, we point the fmt to a cho-
sen location. Given the slope of the cumulative delay, we estimate
the byte stored at that location. We repeat the measurements for the
subsequent bytes at that location.
To determine where that location is, while taking jitter into ac-
count, we develop and implement a fuzzy n-gram matching algo-
rithm. This algorithm takes as input n measured bytes, where some
measured bytes may be inaccurate due to noise, and will determine
the most likely location in the libc library that is being measured.
To accomplish this in an efﬁcient manner, we build a trie, where for
every offset in libc the next n bytes are put in the trie. We can
then do a scoped depth ﬁrst search on the trie, ﬁnding the strings
that most closely match the measured bytes. We analyze libc to
determine what is the expected number of measured bytes needed
)
s
m
(
y
a
l
e
D
e
v
i
t
a
l
u
m
u
C
1000 
800 
600 
400 
200 
0 
0 
20 
80 
40 
60 
Sample Number 
Timing measurement
100 
Figure 7:
Apache 2.4.7 over wired LAN
Byte Value 
0 
1 
5 
10 
40 
80 
120 
160 
200 
240 
255 
)
s
m
(
y
a
l
e
D
e
v
i
t
a
l
u
m
u
C
1000 
800 
600 
400 
200 
0 
Byte Value 
0 
1 
5 
10 
40 
80 
120 
160 
200 
240 
255 
0 
20 
40 
80 
60 
Sample Number 
Timing measurement
100 
for
Figure 8:
Apache 2.4.7 over WiFi 802.11g
e
u
l
a
V
e
t
y
B
250 
200 
150 
100 
50 
0 
1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 21 22 
Byte Number 
Actual Bytes 
Estimated Bytes over LAN 
Estimated Bytes over WiFi 
for
Figure 9: Estimated bytes using timing at-
tack against Apache
to uniquely determine the offset, given a certain timing precision.
We ﬁnd that even if our timing precision is poor, the expected num-
ber of total measured bytes needed is low. For example, when any
measured byte could be off by ±15, tolerating a 6% margin of er-
ror, at most only 13 measured bytes are needed for the majority
(54%) of offsets, and at most 40 measured bytes are needed for
85% of offsets. 6% is chosen based on the fact that for the code
bases we have analyzed (libc speciﬁcally), with error rates higher
than 6%, the fuzzy matching starts to return erroneous results.
To establish the minimum number of samples necessary for the
slow timing attack, we repeat it with increasing sample sizes and
calculate the average byte error. We start with a small sample size
of 1000 and increase it until the error is less than the targeted 6%.
We only keep the ﬁrst percentile. Table 2 shows the errors for dif-
ferent sample sizes. For the slow timing attack, the minimum sam-
ple size acceptable is 5000 samples.
The amount of time it takes to collect one sample for the slow
timing is approximately 8.64 ms over the wired network and 41.94
ms over WiFi. Since 5000 samples must be collected, the amount
of time it takes to estimate one byte using the slow timing attack is
43.2 sec and 3.49 min for LAN and WiFi respectively.
6.2 Fast Timing Attack
After enough gadgets are found to build a simple ROP loop, the
vulnerable code can be repeated many times (500,000 time in our
case) locally on the victim’s machine to reduce the network noise
and speed up the attack. The ROP loop in pseudo-code is shown
below. In the next section, we will describe how this ROP loop is
constructed for Apache.
1 i=0;
2 while (i value)
3
i++;
Since the error is small due to the ROP loop, our samples sizes
can be very small (see Table 2). As such, we only keep the fastest
sample. As can be observed from the table, the minimum number
of samples necessary for the fast timing attack is 4 samples.
Table 2: The amount of error for different sample sizes
Sample Size
Slow Timing Error
5,000
1,000
22.79% 16.96% 5.89%
2,500
Sample Size
2
3
Fast Timing Error
20.56%
9.48%
4
5.7%
The time to collect one sample is mainly dominated by the ROP
loop and is about 348 ms for both WiFi and LAN. Since 4 sam-
ples must be collected, the time to estimate one byte using the fast
timing attack is 1.39 sec for both WiFi and LAN.
6.3 Coarse-Grained ASLR
In the coarse-grained implementation of ASLR, the location of
the executable is not randomized. As a result, it is easy to construct
the ROP loop using the gadgets in the Apache executable only (no
linked libraries used). We know the locations of these gadgets from
our local Apache copy. Thus, for the coarse-grained ASLR, only