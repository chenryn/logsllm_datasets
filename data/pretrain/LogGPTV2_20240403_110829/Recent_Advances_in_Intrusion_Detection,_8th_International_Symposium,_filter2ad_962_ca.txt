Instruction recovery is central to static analysis and there are two general
approaches - 1) linear sweep, which begins decoding from the ﬁrst byte, and
2) recursive traversal [9], which follows instruction ﬂow as it decodes. The ﬁrst
approach is straightforward with the underlying assumption that the entire byte
stream consists exclusively of instructions. In contrast, the common case for
our approach is the byte stream exclusively contains data. The second approach
tries to account for data embedded among instructions. This may seem similar to
our approach but the major diﬀerence is that the execution entry point must be
known for recursive traversal to follow control ﬂow. When the branch targets are
not obvious due to obfuscations, then it is not trivial to determine control ﬂow.
To address this issue, an extension called speculative disassembly was proposed
A Fast Static Analysis Approach
291
by Cifuentes et al. [12], which as the name suggests attempts to determine via
a linear sweep style disassembly whether a portion of the byte stream could be
a potential control ﬂow target. This is similar to our approach since the main
idea is to reason whether a stream of bytes can be executable code. In general,
all these approaches aim for accuracy but for our approach although accuracy is
important, it is closely accompanied by the additional design goal of eﬃciency.
The diﬀerences between static analysis of malicious programs and exploit code
inside network ﬂows notwithstanding, there are lessons to be learnt from stud-
ies of obfuscation techniques which hinder static analysis as well as techniques
proposed to counter them. Christodorescu et al. reported that even basic ob-
fuscation techniques [11] can cause anti-virus scanners to miss malicious code.
They go on to describe a technique to counter these code transformation us-
ing general representations of commonly occurring virus patterns. Linn et al.
describe several obfuscation techniques [26] which are very relevant to our ap-
proach, such as embedding data inside executable code to confuse automatic
disassembly. Kruegel et al. devised heuristics [24] to address some of these ob-
fuscations. These algorithms tackle a much harder problem and aim for accuracy
in static analysis, while our approach does not for reasons of eﬃciency and only
partial knowledge being available.
3 Convergent Binary Disassembly
Static analysis of binary programs typically begins with disassembly followed
by data and control ﬂow analysis. In general, the eﬀectiveness of static analysis
greatly depends on how accurately the execution stream is reconstructed. This
is still true in our case even if we use static analysis to distinguish data and exe-
cutable code in a network ﬂow rather than in the context of programs. However,
this turns out to be a signiﬁcant challenge as we do not know if a network ﬂow
contains executable code fragments and even if it does, we do not know where.
This is a signiﬁcant problem and it is addressed in our approach by leveraging
the self-correcting property of Intel binary disassembly [26]. In this section, we
perform an analysis of this property in the context of network ﬂows.
3.1 Convergence in Network Flows
The self-correcting property of Intel binary disassembly is interesting because
it tends to converge to the same instruction stream with the loss of only a few
instructions. This appears to occur in spite of the network stream consisting
primarily of random data and also when disassembly is performed beginning
at diﬀerent oﬀsets. These observations are based on experiments conducted over
network ﬂows in our dataset. We considered four representative types of network
ﬂows - HTTP (plain text), SSH (encrypted), X11 (binary) and CIFS (binary). As
for the exploit code, we used the Metasploit framework to automatically generate
a few instances. We studied the eﬀects of binary disassembly by varying the
oﬀsets of the embedded exploit code as well as the content of the network ﬂow.
292
R. Chinchani and E. van den Berg
Fig. 2. General IA-32 instruction format
Convergence occurred in every instance but with diﬀerent number of incorrectly
instructions, ranging from 0 to 4 instructions.
The phenomenon of convergence can be explained by the nature of the Intel
instruction set. Since Intel uses a complex instruction set computer architecture,
the instruction set is very dense. Out of the 256 possible values for a given
start byte to disassemble from, only one (0xF1) is illegal [2]. Another related
aspect for rapid convergence is that Intel uses a variable-length instruction set.
Figure 2 gives a overview of the general instruction formation for the IA-32
architecture [2]. The length of the actual decoded instruction depends not only
on the opcode, which may be 1-3 bytes long, but also on the directives provided
by the preﬁx, ModR/M and SIB bytes wherever applicable. Also note that not
all start bytes will lead to a successful disassembly and in such an event, they
are decoded as a data byte.
3.2 Analysis
We give a more formal analysis for this phenomenon. Given a byte stream, let’s
assume that the actual exploit code is embedded at some oﬀset x = 0, 1, 2, . . ..
Ideally, binary disassembly to recover the instruction stream should begin or at
least coincide at x. However, since we do not know x, we start from the ﬁrst
byte in the byte stream. We are interesting in knowing how soon after x does our
disassembly synchronize with the actual instruction stream of the exploit code.
To answer this question, we model the process of disassembly as a random
walk over the byte stream where each byte corresponds to a state in the state
space. Disassembly is a strictly forward-moving random walk and the size of
each step is given by the length of the instruction decoded at a given byte.
There are two random walks, one corresponding our disassembly and the other
corresponding to the actual instruction stream. Note that both random walks
do not have to move simultaneously nor do they take the same number of steps
to reach the point where they coincide.
Translating to mathematical terms, let L = {1, . . . , N} be the set of possible
step sizes or instruction lengths, occurring with probabilities {p1, . . . , pN}. For
the ﬁrst walk, let the step sizes be {X1, . . . ,|Xi ∈ L}, and deﬁne Zk =
j=1 Xj.
(cid:2)
Similarly for the second walk, let step sizes be { ˜X1, . . . ,| ˜Xi ∈ L} and ˜Zk =
˜Xj. We are interested in ﬁnding the probability that the random walks
{Zk} and { ˜Zk} intersect, and if so, at which byte position.
(cid:2)
k
j=1
k
A Fast Static Analysis Approach
293
(cid:2)
T
T
i=1 Gi.
(cid:2)
One way to do this, is by studying ‘gaps’, deﬁned as follows: let G0 = 0,
G1 = | ˜Z1 − Z1|. G1 = 0 if ˜Z1 = Z1, in which case the walks intersect after 1
step. In case G1 > 0, suppose without loss of generality that ˜Z1 > Z1. In terms of
our application: {Zk} is the walk corresponding to our disassembly, and { ˜Zk} is
the actual instruction stream. Deﬁne k2 = inf{k : Zk ≥ ˜Z1} and G2 = Zk2 − ˜Z1.
In general, Z and ˜Z change roles of ‘leader’ and ‘laggard’ in the deﬁnition of
each ’gap’ variable Gn. The {Gn} form a Markov chain. If the Markov chain is
irreducible, the random walks will intersect with positive probability, in fact at
the ﬁrst time the gap size is 0. Let T = inf{n > 0 : Gn = 0} be the ﬁrst time the
walks intersect. The byte position in the program block where this intersection
occurs is given by ZT = Z1 +
In general, we do not know Z1, our initial position in the program block,
because we do not know the program entry point. Therefore, we are most inter-
ested in the quantity
i=1 Gi, representing the number of byte positions after
the dissassembly starting point that synchronization occurs.
Using partitions and multinomial distributions, we can compute the ma-
trix of transition probabilities pn(i, j) = P (Gn+1 = j|Gn = i) for each i, j ∈
{0, 1, . . . N − 1}. In fact pn(i, j) = p(i, j) does not depend on n, i.e. the Markov
chain is homogeneous. This matrix allows us e.g. to compute the probability that
the two random walks will intersect n positions after disassembly starts.
The instruction length probabilities {p1, . . . , pN} required for the above com-
putations are dependent on the byte content of network ﬂows. The instruction
length probabilities were obtained by disassembly and statistical computations
over the same network ﬂows chosen during empirical analysis (HTTP, SSH, X11,
i=1 Gi > n), that inter-
CIFS). In Figure 3, we have plotted the probability P (
section (synchronization) occurs beyond n bytes after start of disassembly, for
n=0, . . . , 99.
(cid:2)
T
P(No intersection after n disassembled bytes)
HTTP
SSH
X11
CIFS
y
t
i
l
i
b
a
b
o
r
p
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
0
20
40
60
80
100
n
Fig. 3. Probability that the walk corresponding to our disassembly and the actual
instruction ﬂow will not have intersected after n bytes
294
R. Chinchani and E. van den Berg
It is clear that this probability drops fast, in fact with probability 0.95 the
disassembly walk’ and the ’program walk’ will have intersected on or before
the 21st (HTTP), 16th (SSH), 15th (X11) and 16th (CIFS) byte respectively,
after the disassembly started. On average, the walks will intersect after just 6.3
(HTTP), 4.5 (SSH), 3.2 (X11) and 4.3 (CIFS) bytes respectively.
4 Static Analysis Based Detection
From a security standpoint, static analysis is often used to ﬁnd vulnerabilities
and related software bugs in program code. It is also used to determine if a given
program contains malicious code or not. However, due to code obfuscation tech-
niques and undecidability of aliasing, accurate static analysis within reasonable
time bounds is a very hard problem. On one hand, superﬁcial static analysis
is eﬃcient but may lead to poor coverage, while on the other, a high accuracy
typically entails a prohibitively large running time.
4.1 Working Premise
In our approach, we use static analysis over network ﬂows, and in order to realize
an online network-based implementation, eﬃciency is an important design goal.
Normally, this could translate to poor accuracy, but in our case we use static
analysis only to devise a process of elimination. which is based on the premise
that an exploit code is subject to several constraints in terms of the exploit code
size and control ﬂow. Subsequently, these constraints will help determine if a
byte stream is data or program-like code.
Exploit Code Size. For every vulnerable buﬀer, an attacker can potentially
can write arbitrary amount of data past the bounds of the buﬀer, but this will
most likely result in a crash as the writes may venture into unmapped or invalid
memory. This is seldom the goal of a remote exploit and in order to be successful,
the exploit code has to be carefully constructed to ﬁt inside the buﬀer. Each
vulnerable buﬀer has a limited size and this in turn puts limits on the size of
the transmitted infection vector.
Branch Instructions. The interesting part of a branch instruction is the branch
target and for an exploit code, the types of branch targets are limited - 1) due
to the uncertainty involved during a remote infection, control ﬂow cannot be
transferred to any arbitrary memory location, 2) due to the size constraints,
branch targets can be within the payload component and hence, calls/jumps
beyond the size of the ﬂow are meaningless, or 3) due to the goals which must
be achieved, the exploit code must eventually transfer control to a system call.
Branch instructions of interest [2] are jmp family, call/ret family, loop family
and int.
System Calls. Even an attacker must look to the underlying system call subsys-
tem to achieve any practical goal such as a privileged shell. System calls can be
invoked either through the library interface (glibc for Linux and kernel32.dll,
A Fast Static Analysis Approach
295
ntdll.dll for Windows) or by directly issuing an interrupt. If the former is cho-
sen, then we look for the preferred base load address for libraries which on Linux
is 0x40—— and 0x77—— for Windows. Similarly, for the latter, then the corre-
sponding interrupt numbers are int 0x80 for Linux and int 0x2e for Windows.
A naive approach to exploit code detection would be to just look for branch
instructions and their targets, and verify the above branch target conditions.
However, this is not adequate due to the following reasons, necessitating addi-
tional analysis. First, in our experience, although the byte patterns satisfying
the above conditions occur with only a small probability in a network ﬂow, it
is still not suﬃciently small to avoid false positives. Second, the branch targets
may not be obvious due to indirect addressing, that is, instead of the form ‘call
0x12345678’, we may have ‘call eax’ or ‘call [eax]’.
There two general categories of exploit code from a static analysis viewpoint
depending on the amount of information that can be recovered. To the ﬁrst cat-
egory belong those types of exploit code which are transmitted in plain view
such as known exploits, zero-day exploits and metamorphic exploits. The sec-
ond category contains exploit code which is minimally exposed but still contains
some hint of control ﬂow, and polymorphic code belongs to this category. Due
to this fundamental diﬀerence, we approach the process of elimination for poly-
morphic exploit slightly diﬀerently although the basic methodology is still on
static analysis. Note that if both polymorphism and metamorphism are used,
then the former is the dominant obfuscation. We now turn to the details of our
approach starting with binary disassembly.
4.2 Disassembly
In general, Intel disassembly is greedy in nature, quickly consuming bytes until
the actual instruction stream is reached. As this happens regardless of where
the disassembly begins, it is already an eﬃcient instruction recovery mechanism.
Convergent dissembly is also useful when data is embedded inside the instruction
stream. As an illustration, consider the following byte sequence which begins
with a jmp instruction and control ﬂow is directed over a set of data bytes into
NOPs. Observe that convergence holds good even in this case with the data
bytes being interpreted as instructions, and although there is a loss of one NOP,
it still synchronizes with the instruction stream.
jmp short 0x6
Byte sequence: EB 04 DD FF 52 90 90
00000000: EB04
00000002: DD0A ﬁsttp dword [edx]
00000004: DD
00000005: FF5290 call near [edx-0x70]
00000008: 90
db 0xDD
nop
However, there are caveats to relying entirely on convergence; the technique
is lossy and this does not always bode well for static analysis because while the
loss of instructions on the NOOP sled is not serious, loss of instructions inside
the exploit code can be.
296
R. Chinchani and E. van den Berg
Due to the nature of conditions being enforced, branch instructions are im-
portant. It is desirable to recover as many branch instructions as possible, but
it comes at the price of a large processing overhead. Therefore, depending on
whether the emphasis is on eﬃciency or accuracy, two disassembly strategies
arise.
Strategy I: (Eﬃciency). The approach here is to perform binary disassembly
starting from the ﬁrst byte without any additional processing. The convergence
property will ensure that at least a majority of instructions including branch
instructions has been recovered. However, this approach is not resilient to data
injection.
Strategy II: (Accuracy). The network ﬂow is scanned for opcodes corre-
sponding to branch instructions and these instructions are recovered ﬁrst. Full
disassembly is then performed over the resulting smaller blocks. As a result, no
branch instructions are lost.
The latter variation of binary disassembly is slower not only because of an ad-
ditional pass over the network ﬂow but also the number of potential basic blocks
that may be identiﬁed. The resulting overheads could be signiﬁcant depending
on the network ﬂow content. For example, one can expect large overheads for
network ﬂows carrying ASCII text such as HTTP traﬃc because several condi-
tional branch instructions are also printable characters, such as the ’t’ and ’u’,
which binary disassembly will interpret as je and jne respectively.
4.3 Control and Data Flow Analysis
Our control and data ﬂow analysis is a variation of the standard approach.
Having performed binary disassembly using one of the aforementioned strategies,
we construct the control ﬂow graph (CFG). Basic blocks are identiﬁed as usual
via block leaders - the ﬁrst instruction is a block leader, the target of a branch
instruction is a block leader, and the instruction following a branch instruction
is also a block leader. A basic block is essentially a sequence of instructions in
which ﬂow of control enters at the ﬁrst instruction and leaves via the last. For
each block leader, its basic block consists of the leader and all statements upto
but not including the next block leader. We associate one of three states with
each basic block - valid, if the branch instruction at the end of the block has a
valid branch target, invalid, if the branch target is invalid, and unknown, if the
branch target is not obvious. This information helps in pruning the CFG. Each
node in the CFG is a basic block, and each directed edge indicates a potential
control ﬂow. We ignore control predicate information, that is, true or false on
outgoing edges of a conditional branch. However, for each basic block tagged as
invalid, all incoming and outgoing edges are removed, because that block cannot
appear in any execution path. Also, for any block, if there is only one outgoing
edge and that edge is incident on an invalid block, then that block is also deemed
invalid. Once all blocks have been processed, we have the required CFG. Figure 4
shows the partial view of a CFG instance. In a typical CFG, invalid blocks form