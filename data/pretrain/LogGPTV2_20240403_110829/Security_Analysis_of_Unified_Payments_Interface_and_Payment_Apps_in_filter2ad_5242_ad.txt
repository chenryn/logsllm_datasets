gerprint or a SPay PIN. SPay does not integrate with UPI;
instead, it integrates with two UPI apps—Paytm and MobiK-
wik. Hence a user can choose one of the two apps that come
with SamsungPay (they are also available for download sepa-
rately on Google Play). Since both Paytm and MobiKwik app
servers do not integrate with KNOX, they cannot use KNOX’s
hardware-based security features for device hard-binding at
the time of user registration. The user’s ﬁngerprint or SPay
PIN is used to authenticate a user with the device; neither the
payment app servers nor the UPI server uses it for user regis-
tration. We test SamsungPay using MobiKwik. Mobikiwk’s
workﬂow is the same as Ola Money except that its passcode
reset workﬂow uses a passcode and OTP, both of which we
can intercept. This makes SPay prone to attacks that result
from integrating with third-party UPI apps.
3.5 UPI 1.0 Responsible Disclosures
We reported the vulnerabilities of BHIM to NPCI, CERT-IN,
and CERT-US, with the initial disclosure to CERT-IN in June
2017. We followed up with our disclosures again in Oct 2017
(timelines in Figure 5). Subsequently, we reported the vulnera-
bilities to CERT-US and got the following CVEs: CVE-2017-
9818, CVE-2017-9819, CVE-2017-9820, CVE-2017-9821 for
BHIM. We also got CVEs for our disclosures to other app ven-
dors from CERT-US (CVE-2018-15660, CVE-2018-15661,
CVE-2018-17400, CVE-2018-17401, CVE-2018- 17402,
CVE-2018-17403) and a $5k bounty from Samsung (CVE-
2018-17083) for a sensitive data leak. The original CVEs
disclosed relied on accessibility permission, though we later
determined that the attacks can be carried out without it.
3.6 Preliminary Analysis of UPI 2.0 Protocol
In August 2018, UPI made the ﬁrst update to the UPI speci-
ﬁcation, UPI 2.0, over a year after we ﬁrst reported the vul-
nerabilities to them. Based on our disclosures, UPI 2.0 does
prevent our attacks in the current form. We present our pre-
liminary ﬁndings; a detailed analysis of UPI 2.0 is currently
ongoing. We follow the same approach we employed for
UPI 1.0 and reverse-engineered the UPI 2.0 protocol using
UPI 2.0 versions of four popular apps— BHIM, Google Pay,
Paytm, and Amazon Pay. Google Pay (GPay) and Paytm are
the leaders in the market, each with a 36% market share.
Some of our ﬁndings are as follows. We evaluate the UPI
2.0 version of BHIM (which is also used by many banks as
their ofﬁcial UPI app under their own brand, e.g., BHIM SBI
Pay and BHIM PNB). We found that NPCI now forces an
update on BHIM to its latest version. In UPI 2.0, in addition to
the device information we saw in UPI 1.0, BHIM also sends
the device’s IMEI number, SIM number, network type, etc.,
to the UPI server for device hard-binding. In BHIM’s latest
update, NPCI removed the alternate workﬂow1, and hence the
Potential Security Hole #1 that we exploited for our attacks, a
positive change. However, the other vulnerabilities persist as
detailed below.
On GPay, we can set up a user’s proﬁle similar to how we
did for Attack #1 and Attack #1(cid:48) in third-party UPI 1.0 apps.
From GPay’s trafﬁc, we ﬁnd that GPay authenticates with
Gmail servers using OAuth2. Thus an adversary Eve can set
up a GPay account as follows. Eve can use her own Gmail ID
on her phone and can key-in Alice’s cell number at the time of
1508    29th USENIX Security Symposium
USENIX Association
login to GPay. Google sends an OTP to Alice’s cell number,
which Mally can intercept (given Mally’s RECEIVE_SMS
permission). For Eve to proceed, GPay must send an SMS
message containing Alice’s device registration token back to
the UPI server from Alice’s phone.
In the absence of the alternate workﬂow1 that previously
enabled the attacks, we explored SMS spooﬁng as a means for
Eve to send an SMS message to the UPI server. For the attack
to work, the UPI server must get the spoofed SMS message
from Alice’s cell number. For proof-of-concept, we tested
SMS spooﬁng with several services that claim to provide non-
anonymous SMS spooﬁng. However, it did not work for a test
number we own in India. While we can send SMS messages
either anonymously or using a default number provided by
the SMS spooﬁng service, we are unable to control the sender
number of the SMS message, a must for the attacks to work.
We are currently exploring this and other SMS related attack
vectors noted in prior research [49]. Alternatively, Mally can
request SEND_SMS permission and send the SMS message
from Alice’s phone.
On Paytm, we studied the handshake by instrumenting the
app with debug statements at the bytecode level. Below is a
snippet of the bank account information that Paytm receives
during the handshake. The authors mask all the details below
for privacy. We note that just as before, UPI sends back the
bank account details without requiring a user to provide any
credentials shared with the bank. We conﬁrm the same on
Amazon Pay as well. Amazon Pay uses Amazon credentials
and the default cell number set in a user’s Amazon account. To
create a proﬁle, an adversary Eve can set Alice’s cell number
in her Amazon credentials.
1
2
3
4
5
6
7
" name ":"956785 XXXX@paytm ",
" defaultCredit ":{" bank ":" State Bank Of India ",
" ifsc ":" SBIN 0008626",
" account ":"000000379085 XXXXX ",
" accountType ":" SAVINGS ",
" name ":" BXXXXXX TXXXX ",
" branchAddress ":" AMXXXXXXXXX "
Thus, we have conﬁrmed that sensitive information leaks
(similar to those in Attack #1) still exist. An open question
remains on the possibility of other attacks, such as performing
unauthorized transactions.
4 Lessons Learned
Below, we summarize the problems in the design of the UPI
1.0 protocol that enabled potential attacks.
1. The UPI protocol reveals bank account details of a user
in any handshake (default or alternate), given the user’s
cell number and no bank-related credentials.
2. Device hard-binding, the ﬁrst factor, relies on data that
is easily harvested from a device. UPI does not use any
secrets for this step.
3. A weak device binding mechanism allows a user (or an
adversary) to bind her cell phone with a cell number
registered to the bank account of another user.
4. Setting the UPI PIN, the second factor, requires partial
debit card information printed on the card, which is not
a secret. The debit card PIN, a secret a user shares with
the bank, is never used. This is a lower bar as online, and
in-store purchases require the entire card number and
the debit card PIN.
5. When transferring an existing user’s UPI account to a
new phone, UPI does not require the user to provide any
bank-related credentials or the printed debit card infor-
mation to authorize transactions from the new phone.
The UPI protocol relies on the UPI PIN alone.
6. On third-party apps, the passcode, the third factor, is
managed by the third-party app server and hence easy
to bypass. An attacker can bypass the passcode require-
ment by setting up an attacker-controlled proﬁle (using
attacker credentials) with the app. In this case, UPI ef-
fectively relies only on two factors— device binding and
UPI PIN.
7. The bank account number leaked from the default work-
ﬂow of any of the third-party apps is enough to reset a
user’s passcode on another app (such as BHIM).
We note that though UPI 2.0 closes the weak device binding
mechanism #3 above, the other issues persist. The overall
weakness in UPI is that user registration requires only the
knowledge of a cell number and the ability to receive one
SMS message from that number.
Attacks only require Mally to do two things: provide the
OTP during registration and, for attacks on existing users of
UPI, steal their UPI PIN. Need for Mally can be circumvented
in two ways— unauthorized transfer of a user’s cell number to
the attacker or by social engineering attacks. Both are feasible,
and social engineering attacks are scalable in India, given the
cheap labor cost. For non-users of UPI, getting them to reveal
an OTP during registration is sufﬁcient.
There are signiﬁcant risks associated with relying on cell
numbers as the only means of user identiﬁcation. Banks in
India accept any cell number that the user registers with their
accounts—there is no cross-check to verify if the cell number
given actually belongs to the user. It is not uncommon, for
example, for members of a family to provide the same cell
number to the bank for their individual bank accounts. Thus,
a person with access to family members’ debit card numbers
can add all their bank accounts to the same app for transac-
tions. One may view this either as a convenience or a security
and privacy risk, depending on one’s perspective.
Finally, we would like to clarify that our claim is not that
all the high-level lessons learned are new; most security prin-
ciples are well-known by now. Nevertheless, we want to con-
USENIX Association
29th USENIX Security Symposium    1509
textualize the lessons learned from the perspective of a widely
adopted ﬁnancial protocol. We note that both the designers of
Android and UPI contribute to the ﬂaws we discovered, which
made getting app vendors to do ﬁxes difﬁcult. App vendors
often blame it on Android design or users, who should not
be granting dangerous permissions to apps. At the same time,
UPI protocol designers could have factored in the current
state of Android and security-awareness among users in India
and made the protocol more secure.
It is well-known by now that security by obscurity does
not help. We think the risks could have been better addressed
had UPI published the protocol details once it was internally
vetted, thus allowing the research community to analyze it fur-
ther. We show how protocol analysis from the point-of-view
of an adversary trying to uncover unpublished workﬂows and
secrets, though important, is often overlooked for application-
level protocols.
Limitations of our study: A limitation of our study is that
we only studied seven UPI apps to analyze the security of the
UPI protocol. Automated analysis techniques could not be
used given the number of security defenses these apps use.
Prior research by Reaves et al. [48] also reverse-engineered
seven apps that resisted automated analysis. However, we
consider seven to be a reasonable number for our work since
our focus was on uncovering ﬂaws with the UPI protocol that
is common across the apps. Also, the apps we analyzed have
88% of the market share combined, and of the 88 UPI apps, a
majority of them are minor variations of BHIM, which we an-
alyzed. Nevertheless, a larger study could provide additional
insights into the security of the payment ecosystem in India
and will also be useful to other countries that decide to use a
common payment interface.
5 Mitigation
We discuss possible mitigation strategies against the attacks
and their pros and cons below.
UPI mitigations. We discuss steps the government can take
to address some of the issues we have raised.
Minimizing protocol data: Our attacks show how proto-
col data revealed during the default workﬂow was used to
exploit an alternate workﬂow. This was possible because the
UPI server sent more data than the client needed to see. For
instance, while the masked bank account number is useful to
display on the screen, bank-speciﬁc details such as the bank
name, account number and IFSC code, sent in the clear can
be excluded from the handshake.
Secure alternate workﬂows: We leveraged two alternate
workﬂows in our attacks, as summarized in Section 4. Though
UPI 2.0 closes one of the ﬂows, the other alternate ﬂows
are either unsecured or secured using weak credentials. For
instance, an alternate workﬂow allowed a user to bind her cell
phone with a cell number registered to the bank account of
another user, even without providing any secrets pertaining to
the other user.
Mandate opt-in into UPI apps: Currently, as we are
aware, UPI services are by default available to users of a
bank that is integrated with UPI; the UPI guidelines do not
require users to opt-in with their bank. An opt-in requirement
would increase risk awareness as well as cut down security
risks for non-UPI users such as credit card users, cash users,
or users of wallet apps. Alternatively, a user could be required
to do an in-person veriﬁcation with their local bank branch
to register for UPI services on their cell phone. This can pre-
vent unauthorized registrations of a user, which automatically
eliminates the other attacks.
Provide opt-out option: As a follow-up on the previous
mitigation, non-users and users wanting to discontinue UPI
services must be allowed to opt-out for security and privacy
reasons. The downside of making UPI optional is the negative
impact it may have on UPI adoption.
Use debit card number + something user knows: Debit
cards in India are Chip+PIN cards, and doing transactions
with them always requires entering a PIN. In contrast, doing
transactions via the UPI apps requires neither—only the in-
formation that is printed on the card—resulting in a weaker
authentication path. Fixes to this are unfortunately difﬁcult
if Mally is powerful enough to intercept PIN entry. However,
assuming user interactions can be secured on Android (e.g.,
see [18]), UPI guidelines requiring the user to enter a secret
shared with the bank to enable transactions will be useful.
Require strong device binding: The UPI speciﬁcation
could require payment apps to do a stronger device-to-cell
number binding. Since binding is one of the most critical
steps of the protocol, the bank may issue a one-time secret
to the user out-of-band, say, when the user visits the bank for
UPI activation. The user has to enter this secret the ﬁrst time
she uses the UPI app on her phone. Additionally, the UPI
server must verify that the UPI app it is communicating with
is an ofﬁcial app running on a non-rooted phone. If the UPI
server can somehow establish that, then an attacker may not
be able to use a repackaged version of a UPI app to register
an account. Unfortunately, this is tricky to enforce.
Android mitigations.
In the attacks we describe, the attack
starts when Mally on a user’s phone gets the user’s cell num-
ber as an SMS from the attacker. A possible defense would be
for Android to have a policy that prevents SMS permissions
from being requested by apps. Google is already moving in
that direction. As of January 2019, Google announced that
apps could not request SMS permissions unless they are the
default SMS handler and get explicit approval from Google.
How effective this policy is, remains to be studied. We note
that this does not make the attack impossible. It would merely
require Mally not just to be installed but also accepted as
1510    29th USENIX Security Symposium
USENIX Association
the default SMS handler (or get approved as an exception
by Google). Also, the policy is speciﬁc to the Google Play
store—apps from other stores could still introduce risks. Many
popular carriers in India support alternate app stores such as
Aircel and Airtel that allow SMS-triggered downloads [43].
User mitigations. Since Eve requires a user’s cell number
to initiate the attack, using a private cell number for bank
accounts may slow down an attack. Unfortunately, it does
not entirely prevent it. If the user has installed Mally, Mally
sufﬁces to detect the user’s cell phone number (Section 3.3.6.
Thus, users would also need to be careful to never install apps
with read or receive SMS permissions on phones they use for
banking.
6 Related Work
Panjwani et al. did one of the ﬁrst studies on an Indian pay-
ment system called EKO, a mobile service provider [47]. They
show PIN recovery attacks that could result in a user imperson-