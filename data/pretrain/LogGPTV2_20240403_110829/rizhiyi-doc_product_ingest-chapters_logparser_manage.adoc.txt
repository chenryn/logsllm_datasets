[[parserule-manage]]
=== 规则管理
==== 复制已有规则
在字段提取规则列表中，找到想要复制的规则，点击"更多"->“复制”：
image::images/parserule-copy.png[]
然后点击进入“配置规则”页，页面展示原解析规则内容，但是“规则名称”采用了后缀加(1)的方式，推荐您在这里修改成新的规则名称。logtype 则按需修改，可保留重名。
其余流程与创建规则相同。
==== 编辑已有规则
点击已有规则的“编辑”按钮，进入“配置规则”页。修改“解析规则”，点击“下一步”，进入“运用”页。点击“完成”。
==== 将已有规则运用到其他 appname/tag
点击已有规则的“编辑”按钮，进入“配置规则”页。点击“下一步”，进入“运用”页。修改运用的 appname/tag。点击“完成”。
==== 禁用已有规则[[disable]]
在字段提取规则列表中，找到想要禁用的规则，点击行首位置的“禁用”开关。
由于内置规则需要逐一匹配，对程序运行性能影响较大，在可确认的前提下，用户可以主动禁用部分内置规则提高运行性能。
=== 规则运行性能统计
日志易提供对字段提取规则运行时的性能统计查看，包括界面交互和单机 HTTP 接口两种形式。
==== 界面查看运行性能
字段提取模块的运行性能指标长期存储在 rzy_internal 索引中，为了方便用户快速了解运行状态，在规则列表页直接展示了最近一天的每小时数据处理量和平均耗时趋势:
image::images/parser_stat.png[]
虽然展示的是每小时的统计值，实际汇报的数据粒度远高于此。用户可以通过日志易 Manager 中 logriver 的配置项 `parser_stat_report_interval` 来调整汇报间隔，默认是 1 分钟。
===== 临时统计解析算子运行性能详情
日志易同样支持对每个解析算子的运行性能进行统计记录，考虑到细粒度统计对运行效率本身可能造成一定的影响，默认并不开启。想要长期统计的用户，可以修改日志易 Manager 中 logriver 的配置项 `parser_stat_report_level` 为 `high`，默认为 `low`。
即使默认 `low` 的情况，在需要排查问题时，用户也可以在界面上点击开启"运行统计"，系统将默认记录之后 30 分钟内的解析算子运行性能详情，30 分钟之后自动关闭。如果需要修改时间范围的，可以通过日志易 Manager 中 logriver.cfg 文件模板中的 `parser_stat_report_level_reset_duration = 30m` 修改。
查看具体某个规则的算子运行详情，在列表右侧对应行点击"详情"，弹层查看结果如下:
image::images/parserule_stats.png[]
===== 检索查询性能历史
如果需要查看最近一天以前的历史数据，或者进行界面上未提供的其他复杂统计，可以直接利用日志易检索功能。
查询全部结果，可以使用 `index=rzy_internal appname:logriver_stat` 语句。其中规则性能和算子性能分别以 `logtype:parser_stat` 和 `logtype:parser_rule_stat` 为标记。
比如: 统计一段时间内的抽取规则解析结果用的 spl 是:
[source]
index=rzy_internal logtype: parser_stat| eval parser_id = parser_stat.id| bucket timestamp span=1h as ts| stats sum(parser_stat.total) as total, sum(parser_stat.success) as success, sum(parser_stat.cost_us) as cost_us  by parser_id, ts|eval avg_cost_us = cost_us/total
统计一段时间内规则统计用的 spl 是(parser_id 可以在对应的编辑页面的URL上复制):
[source]
index=rzy_internal logtype: parser_rule_stat AND parser_rule_stat.parser_id:3 | eval rule_id = parser_rule_stat.rule_index| bucket timestamp span=1h as ts| stats sum(parser_rule_stat.total) as total, sum(parser_rule_stat.success) as success, sum(parser_rule_stat.skip) as skip, sum(parser_rule_stat.fail) as fail, sum(parser_rule_stat.error) as error, sum(parser_rule_stat.cost_us) as cost_us by rule_id, ts |eval avg_cost_us = cost_us / total
==== 接口查看运行性能
为了方便用户查看，日志易附带有专用的统计脚本程序，支持以下三种统计指标：
1.	消费耗时统计
2.	appname耗时top排行统计
3.	字段提取规则耗时top排行统计
脚本程序分发路径位于logriver模块运行时的bin/目录下，例如：
 /var/run/rizhiyi_manager_agent/process/17001-logriver/bin/toolbox.sh
===== 消费耗时统计
运行命令示例如下：
[source]
 # sh toolbox.sh speed
host time(ms) in [in-queue cost(ms/e)] parsed cost(ms/e) [out-queue cost(ms/e)] out cost(ms/e)
localhost 3014 0 [     0      0.00]          0       0.00 [         0       0.00]          0       0.00
输出信息各列含义如下：
* ms/e：每条日志花的毫秒
* time：时间间隔
* in：这段时间内输入的日志数量
* in-queue：在任务队列等待的日志数量
* in-queue-cost：写入任务队列的平均耗时
* parsed：这段时间内解析的日志数量
* parsed-cost：解析的平均耗时
* out-queue：sink队列等待的日志数量
* out-queue-cost：写入sink队列的平均耗时
* out：这段时间输出的日志数量
* out-cost：输出的平均耗时
===== appname耗时top排行统计
运行命令示例如下：
[source]
 # sh toolbox.sh appname
host      appname.tag         count cost(us) avg(us/e) succ
localhost test_json.test_json 1     107447   107447    1
该指令支持--sortby参数，参数可选项包括：
* count：按日志总数排序
* succ_count：按解析成功数排序
* cost：按总耗时排序
* avg_cost：按平均耗时排序
===== 字段提取规则耗时top排行统计
和appname统计类似，运行示例如下：
[source]
 # sh toolbox.sh rule
timestamp    timetotal name  count cost(us) avg(us/e) succ
    - id  [type] count cost(us) avg(us/e) succ fail skip error
localhost:
1516791600000 3485461  mysql 1     13209    13209     0
    - 0.0 [grok] 1     9143     9143      0    1    0    0
运行输出中，顶头开始的列为字段提取规则的信息，然后下面附属有其内部解析算子的统计详情。比如上例中，展示的是mysql规则及其grok算子的运行情况。
该指令同样支持--sortby参数，参数可选项包括：
* count：按日志总数排序
* succ_count：按解析成功数排序
* cost：按总耗时排序
* avg_cost：按平均耗时排序
=== 自定义Geo地址库
目前日志易有自己标准的ip.db和geo.db库。为了应对某些用户需要使用他们自己定制的ip.db和geo.db的需求，我们提供ip.db和geo.db的生成工具，但是需要用户按照我们制定的格式提供原始数据。
原始数据的样例：
[options="header"]
|============
|起始ip|结束ip|国家|省份|城市|保留列|运营商|纬度|经度
|001.000.004.000
|001.000.007.255
|澳大利亚
|维多利亚州
|墨尔本
|*
|goldenit.com.au
|37.50
|144.58
|001.000.008.000
|001.000.015.255
|中国
|广东
|*
|*
|电信
|*
|*
|============
[IMPORTANT]
====
1. CSV 文件第一行不用写表头。
2. 字段之间是制表符\t；每个字段值不能包含\t，但是可以包含一个空格。例如：the united states。
3. 保留地址和经纬度不提供的时候，都可以用`*`代替。
====
==== 生成步骤
1.	准备数据源：将整理好符合我们格式标准的数据写入文件ip-utf8.data(暂时要求必须使用该文件名)。
2.	执行命令：找到或下载工具包。请联系日志易技术支持人员索要。然后在 ip-utf8.data 相同目录下运行：
+
  wget http://222.128.29.229:9999/geo/geo_tool.jar
  java -Xmx1024m -Xms1024m -cp ./geo_tool.jar cn.yottabyte.logparser.tool.GeoConverterTool2
+
3.	 获得ip.db和geo.db
检查在项目目录下是否生成了ip.db和geo.db，这两个文件是日志易所需要的。将其复制到logparser对应目录下替换原始文件即可。