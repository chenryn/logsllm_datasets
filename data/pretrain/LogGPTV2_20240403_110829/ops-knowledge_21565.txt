User: Use Python to write a simple web crawler that can crawl relevant information of a specified website and store it in a local file
Assistant: The following is a basic Python web crawler example that can crawl the information of a specified URL and save the result to a local file: ```python import requests from bs4 import BeautifulSoup # Define the URL to crawl url = 'https://www .example.com' # Send HTTP request to get webpage content response = requests.get(url) # Parse HTML webpage content soup = BeautifulSoup(response.content, 'html.parser') # Find titles and paragraphs in the page title = soup.find('title').get_text() paragraphs = soup.find_all('p') # write the result to the file with open('output.txt', 'w') as file: file.write('Title : {}\n\n'.format(title)) file.write('Paragraphs:\n\n') for p in paragraphs: file.write('{}\n\n'.format(p.get_text ())) print('Done.') ``` You can change the URL in the above sample code to the website you want to crawl, and write the results to other file names (for example: result.txt), The acquired information may also be processed in other ways.