### Expectations on Security Indicators and User Knowledge

We presumed that security indicators, such as the "https" prefix or the padlock icon, are integral components of end users' mental models. We did not anticipate that end users would possess deep knowledge about encryption concepts and keys. For instance, we did not expect them to be aware of metadata or to understand the role of additional network nodes. While all researchers agreed that end users should distinguish between encryption and authentication, there was no consensus on whether end users should recognize the absence of a centralized encryption component.

For administrators, we expected a more in-depth understanding, including knowledge of symmetric and asymmetric encryption, as well as familiarity with keys, certificates, and certificate authorities. We also assumed that their implicit knowledge of data transport routes would include intermediary network nodes. Additionally, we anticipated that they would have more sophisticated threat models and an awareness of metadata.

### Pilot Interviews

Prior to the main study, we conducted a series of pilot interviews: four in Vienna and two in Bonn. The initial interview guideline included only two drawing tasks: message encryption in theory and visiting a site with HTTPS. However, the results from these pilot interviews indicated that this was insufficient to elicit detailed articulations of participants' mental models. Therefore, we added a third drawing task, which involved visiting an online banking site. This task, while technically similar, is often perceived as more security-critical. The pilot results also suggested minor adjustments to the order of questions.

### Recruitment and Participants

We recruited a total of 45 participants. The first six and the last nine interviews were used for the pilot study and for validating the results, leaving us with a final dataset of 30 participants, consisting of 18 end users and 12 administrators.

For non-expert users, our goal was to recruit a diverse sample. We used three recruitment methods: mailing lists, online forums, and personal contacts. We deliberately limited the number of students and excluded computer science students and IT professionals. For administrators, the criteria were that they must be responsible for administering systems and regularly-used services, whether in paid or voluntary roles.

To recruit administrators, we contacted IT departments directly (e.g., national newspapers) and used personal contacts to reach out to larger organizations. Five administrators were recruited through this channel. We also posted advertisements on social media and a hackerspace mailing list, recruiting seven more administrators. Unfortunately, we were unable to recruit any female or non-binary administrators. Table III provides information about our participants, Table I summarizes the demographics, and Table II outlines the administrators' previous work experience and security-specific education.

The recruitment text did not disclose the actual purpose of the study to prevent participants from researching HTTPS beforehand. All participants were compensated with 10 Euros for their time.

### Data Analysis

Our data collection included both qualitative and quantitative data. Qualitative analysis was based on audio recordings, handwritten notes, and drawings from the drawing tasks. We used inductive coding, a common method in social sciences and usable security, to construct models and theories. Two rounds of open coding were followed by Strauss and Corbin’s descriptive axial coding and selective coding to group the data into categories and models. Analytic memos were used to track emerging themes. The final set of codes is listed in Appendix A.

Three researchers independently coded all questions and drawings, and the resulting codes were discussed and refined to create a final codebook. Two coders then independently coded the data, resolving conflicts through discussions. To code the drawings, the coders reviewed the drawings and read the audio transcripts aloud, assigning one or more codes after each item. Figure 1 shows an example of a drawing and the assigned codes.

Krippendorff’s Alpha was calculated to measure coding agreement, with an α = 0.98, indicating a high level of agreement. Despite the high agreement, we believe it is important to discuss how and why disagreements arose and to disclose insights gained from these discussions. Most conflicts were related to the level of granularity in the drawings and were resolved through discussions and additional consultations of the protocols and audio transcripts.

Additionally, three researchers independently performed axial and selective coding to generate two models and two anti-models for HTTPS and message encryption. These were then discussed and conflicts resolved in person.

Quantitative analysis was based on close-ended questions from the questionnaire, and we also evaluated quantitative aspects based on particular codes.

### Pilot and Post-hoc Validity Study

We conducted pilot interviews to validate our study design. However, due to the lack of ground truth, our exploratory study instrument may still be subject to bias and priming effects. During analysis, we observed that most participants naturally used the term "encryption" when discussing HTTPS, suggesting a possible priming effect. We conducted a post-hoc validity study with nine participants (four administrators and five end users) using a different set of warm-up questions and task ordering to avoid the word "encryption." The modified interview guideline is in Appendix D. No new codes emerged from this data, indicating saturation with the original protocol. Our results suggest that the term "encryption" is commonly used and understood as a synonym for security.

### Ethical Considerations

Our institutions in central Europe follow a set of guidelines for user studies, emphasizing the preservation of participants' privacy and limiting the collection of personal data. Each participant was assigned an ID, and all signed consent forms explaining the study's goals, expectations, and data usage. The consent forms were stored separately without the assigned IDs to ensure anonymity. The study complied with national privacy regulations and the EU’s General Data Protection Regulation (GDPR).

### Results

#### Mental Models

Our qualitative analysis identified four types of mental models representing the lower and upper bounds of correspondence to the technical concepts of message encryption and HTTPS. These models are shown in Figures 2, 3, 4, and 5, and we discuss the differences between administrators and end users.

1. **Model of Message Encryption**: This model correctly abstracts the underlying technology. Key properties include:
   - Encryption and decryption are performed at the communication endpoints.
   - Data in transit is protected from attackers and eavesdroppers.
   - The existence of keys is acknowledged, with some models recognizing public and private keys.
   - A key exchange process is required, though often vaguely defined.

   Administrators more frequently mentioned public and private keys compared to end users. Twenty-three participant drawings reflected this model (12 administrators, 11 end users).

2. **Anti-Model of Message Encryption**: This model deviates from the actual components and workflow of message encryption. Key characteristics include:
   - A centralized authority acts as an authentication service, message relay, or centralized encryption service.
   - Encryption is handled by the centralized authority, but decryption is not part of the model.
   - Data in transit is not protected from attacks.
   - Keys are not articulated, but a vague code is exchanged between communication endpoints and the centralized service.

   Six participant drawings (all end users) featured elements of this anti-model.

3. **Model of HTTPS**: This model correctly represents the concept and components of HTTPS. Key properties include:
   - Data in transit is encrypted and protected from attacks.
   - The existence of a CA, but no awareness of its role and context.
   - The browser is a relevant entity.
   - Best-case representations include security indicators like the "https" prefix or a lock icon.
   - Administrators’ mental models often include protocol-related tasks such as certificate checks, TLS handshakes, or HTTP GET requests, though often without a deep understanding of their purposes.

   Nineteen participant drawings substantially overlapped with this model (12 administrators, 7 end users).

### Conclusion

Our study provided valuable insights into the mental models of end users and administrators regarding message encryption and HTTPS. The findings highlight the importance of clear and consistent security indicators and the need for better education on key concepts and processes.