our expectations on them.
Consequently, we assumed security indicators (e.g.,
the
https preﬁx or the padlock icon) as part of end user mental
models. We did not expect deep knowledge about encryption
concepts and keys, e.g., we did not expect awareness for
metadata from end users or an understanding about additional
network nodes. While all researchers agreed that end users
should not confuse encryption with authentication, we did
not agree on whether the absence of a centralized encryption
component can be expected from end users.
We expected more in-depth knowledge from administrators,
e.g., knowledge about symmetric and asymmetric encryption.
We also expected keys, certiﬁcates, and certiﬁcate authorities
to be components of their mental models. We also assumed
that
their tacit knowledge on data transport routes would
contain intermediary nodes in the network. We expected more
sophisticated threat models and awareness of metadata.
C. Pilot Interviews
Before the actual study, we conducted a series of pilot
interviews, four in Vienna and two in Bonn. The ﬁrst version
of the interview guideline had only two different drawing
tasks (message encryption in theory and visiting a site with
HTTPS). As the results from our pilot interviews suggest,
this was not enough to elicit a detailed articulation of the
participants’ mental models. We therefore decided to include
a third drawing task (i.e., visiting an online banking site) that,
from a technical perspective, presents a similar scenario but is
often understood as a more security-critical task. Our results
also suggested minor modiﬁcations to the order of questions.
D. Recruitment and Participants
In total, we recruited 45 participants. Since the ﬁrst six and
the last nine interviews were used for the pilot study and for
the validation of the results, we excluded them from the ﬁnal
data set and thus had a ﬁnal set of 30 participants, consisting
of 18 end users and 12 administrators, respectively.
For the non-expert users, our goal was to recruit a diverse
sample of participants. Hence, we used three separate recruit-
ing mechanisms to build our sample: mailing lists, online
forums, and personal contacts for recruitment. We especially
limited the number of students in our sample and refrained
from recruiting computer science students or IT professionals.
In contrast, the recruitment criteria for administrators was
that they had to be in charge of administering systems and
regularly-used services. We allowed both paid and voluntary
work.
To recruit administrators, we contacted companies’ IT de-
partments directly (e.g. national newspapers) or used per-
sonal contacts as entry points to larger organizations and
asked them to forward the announcement to their employers’
IT department. Five administrators were recruited over this
channel. Additionally, we posted advertisements on social
media and a hackerspace mailing list to recruit another seven
administrators. Sadly, we were unable to recruit female or
non-binary administrators. Table III lists information of our
participants. Table I presents a summary of demographics.
Table II summarizes the administrators’ previous work
experience and security-speciﬁc education. Four of the 12
administrators reported that they never received any security-
speciﬁc education. Four administrators were employed at
IT service providers, two at national newspapers, and the
remaining ones were administrating servers in the ﬁelds of
data protection, social services, advertisement, mobility, radio
and television, and education. Eleven administrators were full-
time administrators at a company, and one was voluntarily
administrating at a non-proﬁt organization.
The recruitment text did not include information on the
actual purpose of the study in order to prevent the participants
from informing themselves about HTTPS before participation.
All participants were compensated with 10 Euros for their
time.
PARTICIPANT DEMOGRAPHICS. TOTAL N = 30;
TABLE I
Demographic
Gender
Male
Female
No Information
Age
Min.
Max.
Median
Mean
Highest Completed Education
Junior high
High school
University
End users
Administrators
NEnd = 18 NAdmin = 12
7 (39%)
11 (61%)
0 (0%)
12 (100%)
0 (0%)
0 (0%)
24
60
28
34
1
4
13
29
42
34
34
0
5
7
ADMINISTRATORS’ EXPERIENCE, AS ASKED IN THE INTRODUCTORY
QUESTIONNAIRE. TOTAL NAdmins = 12;
TABLE II
Paid admin work
Voluntary admin work
Special IT-Sec Training
Conﬁgured HTTPS Before
Has written TLS-speciﬁc code
Number
11
1
6
11
4
Percent
92%
8%
50%
92%
33%
(cid:19)(cid:21)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1. Example of a participant drawing (U09). Among other codes, this
drawing was coded with F.5 scribbled line, G.4 local encryption component,
J.5 not part of the model, N.5 model too sparse.
E. Data Analysis
We collected both qualitative and quantitative data. Our
qualitative analysis is based on audio-recordings, hand-written
notes, and the drawings that emerged from the drawing tasks.
For our analysis, we conducted inductive coding [41], [42],
[43], [44], [45], [46] as commonly used to construct models
and theories based on qualitative data in social sciences and
usable security, e.g.,
[4], [47].
We applied two rounds of open coding to detect observable
patterns. We then performed Strauss and Corbin’s descriptive
axial coding [45] and selective coding to group our data
into categories and models. We also used selective coding
to relate the categories to our research questions. Throughout
the coding process, we used analytic memos to keep track
of thoughts about emerging themes. The ﬁnal set of codes is
listed in Appendix A.
As a ﬁrst step, three researchers independently coded all
questions and drawings of mental models. Subsequently, the
resulting codes were discussed and reﬁned to agree on a ﬁnal
code book. As a second step, two coders independently coded
the data and again conﬂicts were resolved in discussions. To
code drawings along with the think-aloud protocol, the coders
looked at the drawings and read the audio transcript aloud.
After each item, one or more codes were assigned. Our goal
was to code contextual statements instead of singular entities
of the drawings. Figure 1 shows an example of a drawing and
selected assigned codes.
We calculated Krippendorff’s Alpha [48] to measure the
level of agreement among the coders. Our α = 0.98 indicates
a good level of coding agreement since the value is greater
than 0.8 [48]. A potential reason for the high α lies in
the technical nature of the coding categories that have a
limited scope of interpretation. Irrespective of the high level of
coding agreement and in line with other qualitative research
methodologists, we believe that it is important to elaborate
how and why disagreements in coding arose and to disclose
the insights gained from discussions about them. Each coder
brought a unique perspective on the topic that contributed to a
more complete picture. Most conﬂicts arose regarding the level
of granularity of a drawing or representation. The conﬂicts
were resolved based on discussions among all coders and
additional consultation of the protocols and audio transcripts
from the study.
Additionally, three researchers independently performed ax-
ial and selective coding to generate two models and two anti-
models for HTTPS and message encryption. Then, the three
coders met in person to reach agreement on these models and
to resolve conﬂicts.
Our quantitative analysis is based on the close-ended ques-
tions from the questionnaire. We also evaluate quantitative
aspects based on particular codes.
F. Pilot and Post-hoc Validity Study
We performed a series of pilot interviews to validate our
study design prior to conducting the actual study. However,
due to the lack of available ground truth, our exploratory study
instrument may still be subject to bias and priming effects.
During analysis, we observed that most participants naturally
used the term encryption when articulating their understanding
of HTTPS. Hence, it is natural to suspect a priming effect
due to spatial task arrangement [49]. We conducted a post-
hoc validity study with nine participants (four administrators
[VA1-5] and ﬁve end users [VU1-5], demographics are shown
in Figure III) and a different set of warm-up questions and
task ordering. The goal was to completely avoid the word
encryption and let participants start with the HTTPS drawing
tasks. The modiﬁed interview guideline is presented in Ap-
pendix D. The additional data was again coded, but no new
codes emerged from these data, indicating that saturation was
reached with the original study protocol. Our results suggest
that the term encryption did not emerge from the interview
questions but is often used and understood as a synonym for
security.
G. Ethical Considerations
Both our institutions located in central Europe do not have
a formal IRB process but a set of guidelines to follow for
this kind of user study. A fundamental requirement of our
universities’ ethics guidelines is to preserve the participants’
privacy and limit the collection of person-related data as much
as possible. Therefore, every study participant was assigned
an ID, which was used throughout the experiment and for
the questionnaire. All participants signed consent forms prior
to participating in our study. The consent form explained the
goal of our research, what we expected from them, and how
the collected data was to be used. The signed consent forms
were stored separately and did not contain the assigned IDs
to make them unlinkable to their real identities. The study
complied with strict national privacy regulations and the EU’s
General Data Protection Regulation (GDPR).
IV. RESULTS
In the following we present both quantitative and qualitative
results along with selected direct participant quotes.
A. Mental Models
Our qualitative analysis yielded four different
types of
mental models representing the lower and upper bound
of correspondence to the technical concepts of message
encryption (as collected via drawing task 1 and shown in
Figure 2, Figure 3) and HTTPS (as collected via drawing tasks
(cid:19)(cid:22)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
2 and 3, shown in Figure 4 and Figure 5). In the following,
we provide qualitative descriptions and visualizations of the
models and discuss the differences between administrators
and end users. These differences are color-coded in the
visualizations. Section IV-B discusses quantitative aspects of
these models based on particular codes. The corresponding
codebook can be found in Appendix F.
1) Model of message encryption: This model incorporates
mental representations that correctly abstract the underlying
technology and is shown in Figure 2. The main properties of
this model are
• encryption and decryption are performed on the devices
at the communication end-points,
• the data in transit is protected from attackers and
eavesdroppers,
• the existence of keys is acknowledged, well-articulated
models acknowledge the existence of two different keys
(public and private), and
the model
• that a vaguely deﬁned key exchange process is required.
is conceptually correct and contains
While this model
relevant entities of message encryption,
for
both administrators and end users is sparse when it comes
to the purpose of these entities, especially regarding key
exchange. Ten administrator participants mentioned that a
key exchange via a key server or an in-person meeting needs
to happen before sending encrypted messages, and 10 end
users inferred during their think-aloud process that some
kind of exchange needs to happen prior to communication.
It is also notable that key creation is not at all reﬂected in
this model. Only one participant vaguely mentioned that
the key should be created at some point without being able
to further articulate how the process works. None of our
participants actually incorporated key creation. Our results
indicate that administrators incorporated public and private
keys more often than end users (as discussed in Section IV-B).
Twenty-three participant drawings reﬂect properties of this
model (thereof 12 by administrators and 11 by end users).
Apublic/ 
Aprivate
(admin-speciﬁc)
(public) key exchange
Bpublic/ 
Bprivate
Fig. 2. Model of message encryption. Entities that are solely reﬂecting
administrator mental models are visually highlighted (dashed box in pink).
2) Anti-model of message encryption: Contrary to the (cor-
rect) model, the anti-model incorporates all mental represen-
tations that deviate from the actual components and workﬂow
of message encryption. The model is shown in Figure 3, and
its key characteristics are
• a centralized authority is a major component of this model
and acts as authentication service, message relay, or
centralized encryption service.
• while encryption is handled by the centralized authority,
decryption is not part of the model.
• data in transit is not protected from attacks.
• keys are not articulated as components. However, a
vaguely deﬁned code is exchanged between the commu-
nication end-points and the centralized service.
Our results suggest that the misconception of a centralized
authority is more common and speciﬁc to end user mental
models. Six participant drawings (0 administrators, 6 end
users)
this anti-model of message
encryption.
feature elements of
plaintext message
centralized crypto/ 
authentication service 
code
(end user-speciﬁc)
code
Fig. 3. Anti-model of message encryption. Entities that are solely reﬂecting
end user mental models are visually highlighted (dashed boxes in blue).
3) Model of HTTPS: The best case model of HTTPS
incorporates correct mental representations of the concept and
components of HTTPS and is shown in Figure 4. Contrary to
the correct model of message encryption, the correct model of
HTTPS does not acknowledge the existence of keys (neither
administrators nor end users mentioned them). This model is
based on the data gathered through drawing tasks 2 and 3. The
main properties of this model are:
• data in transit is encrypted and protected from attacks,
• the existence of a CA, but no awareness of its role and
context,
• the browser is perceived as relevant entity,
• best-case representations contain security indicators like
the “https” preﬁx or a lock icon.
• (Mostly) administrators’ mental representations contain
protocol-related tasks such as certiﬁcate checks, TLS
handshakes, or HTTP GET requests that are articulated
as check lists without any further understanding of their
purposes and the involved entities.
Similar to the correct model of message encryption,
this
model contains multiple nodes between sender and receiver.
Administrators’ mental models generally contained more
entities (e.g., CA’s, different devices) and protocol-related
tasks. Nineteen participant drawings substantially overlap
with the correct model of HTTPS; 12 were articulated by
administrators and seven by end users.
(cid:19)(cid:22)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
Server
plaintext 
message 
code
2nd factor
HTTPS
Proxy 
(Blackbox) 
intelligence agencies,  
ad trackers, hackers(cid:2)
Online