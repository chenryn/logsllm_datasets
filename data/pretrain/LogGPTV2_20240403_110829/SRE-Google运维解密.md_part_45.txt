一子集大小一
一和选择算
201
236
---
## Page 244
202
30%的子集大小已经比我们想要使用的值要大得多。每次计算的负载分布情况都会变化
个连接），而负载最高的后端程序是平均负载值的121%（109个连接）。在大多数情况下，
如图20-3所示，负载最低的后端程序只有平均负载值的63%（57个连接，平均值为90
情况下的负载均衡情况。举例如下：
在Google负载均衡系统设计之初，我们实现了这种随机子集算法，并且计算了在各种
不均衡。
的数量。
启和任务失败情况（在这些情况下连接变动很小），因为这种算法限制了所考虑的后端
的可解析／可服务状态的后端提取出来。一次性随机排列并顺序选取可以很好地处理重
子集选择算法一：随机选择
端任务滚动重启时，我们需要客户端任务持续服务，对重启透明，同时连接的变动最小。
整个后端任务集群滚动重启（例如升级时）的时候尤为重要（也很难正确实现）。在后
动，同时在无法预知这些具体数字的情况下做到这一点。该功能在整个客户端集群或者
该算法应该同时处理客户端程序和后端程序集群的大小调整，避免对现有连接的大幅变
程序重启时，它可能要重新与所有的后端建立连接。
能还要进行应用级别的交互），这些都带来了额外的成本消耗。同样的，当一个客户端
选择一个替换后端。当这个替换后端被选中时，客户端必须建立新的TCP连接（同时可
幅变动”指的是后端替换的过程。例如，当某一个后端进程不可用时，客户端需要临时
以自动处理重启和任务失败，持续不断地均衡后端任务，同时避免大幅变动。在这里，“大
导致某个后端过载10%，那么整个集群都需要过度分配10%的容量。这个算法也应该可
选择算法应该将后端平均分配给客户端，以优化资源利用率。举例来说，如果该算法将
就很困难了。
这可能看起来很容易，但是在一个需要高效利用资源，并且不可避免重启的大型系统中
当确定子集大小之后，我们需要使用一个算法来定义每个客户端任务使用的后端子集。
30%的子集大小（每个客户端连接90个后端）
300个后端
300个客户端
。但是我们发现，这个算法在大多数实际应用场景中效果非常差，因为负载非常
够更好地将这些请求分发给更多的后端任务。
性请求会集中发送给该客户端任务的后端子集，我们需要更大的子集尺寸以便能
第20章数据中心内部的负载均衡系统
---
## Page 245
我们最终的结论是，如果使用随机子集分布算法，
图20-4:300个客户端、300个服务器端和子集大小为10%的连接分布图
值的50%（15个连接），而最高负载的后端接受了平均值的150%（45个连接）。
更不幸的是，子集大小降低时，负载会更为不平衡。图20-4描述了如果子集大小降低为
图20-3：300个客户端、300个后端和子集大小为30%的连接分布图
（因为有随机因素），但是总体趋势保持不变。
10%（每个客户端连接30个后端）的情况。在这种情况下，最低负载的后端只接受平均
利用划分子集限制连接池大小
、要相对地平均分配负载，需要至少
203
238
---
## Page 246
239
204
务可能同时进入临时不可用状态（例如，因为后端任务正在从第一个任务到最后一个任
这个列表应该被随机重排，否则客户端将会被分配给一组连续的后端任务，这些后端任
会被分配给2个或3个客户端任务。
户端（除了最后一轮，可能没有足够的客户端分配）。在这个例子中，每个后端任务都
这里要注意的关键点是，每一轮计算仅仅将整个列表中的每一个后端分配给唯一一
会产生如下结果：
4个客户端任务（subset_count=12/3）。如果有10个客户端任务，那么前述算法可能
例如，我们有12个后端任务[0，11]，想要的子集大小为3，我们会进行三轮计算，每轮
户端任务（最后一轮除外，这时可能客户端数量不够，所以有些后端没有被分配）。
除以想要的子集大小)。在每一轮计算中，每个后端都会被分配给一个而且仅有一个客
从客户端subset_count*i开始，同时subset_count是子集的个数（也就是后端数量
我们将客户端任务划分在多“轮”中，每一轮i包含了subset_count个连续的客户端
细解释在后文：
Google 对随机算法限制的解决方案是：确定性算法，以下这段代码实现了这个算法，详
子集选择算法二：确定性算法
下是不适用的。
75%的子集大小。这样大的子集是不可行的：分布如此不均衡的算法在大规模部署情况
def Subset（backends,client_id,subset_size)
start = subset_id * subset_size
#将客户端划分为多轮，每一轮计算使用同样的随机排列的列表。
subset_count=len(backends)/subset_size
return backends[start:start+ subset_size]
subset_id=client_id%subset_count
#subset_id代表了目前的客户端
random.shuffle(backends)
random.seed(round)
round=client_id / subset_count
·Round2:[8,3,7,2,1,4,9,10,6,5,0,11]
·Round1:[8,11,4,0,5,6,10,3,2,7,9,1]
·Round0:[0,6,3,5,1,7,11,9,2,4,8,10]
第20章数据中心内部的负载均衡系统
一个客
---
## Page 247
法下结果非常好：每个后端都接收到同样数量的连接。
如图20-5所示，前述案例中的300个客户端每个连接300个后端中的10个，在这个算
户端数量相差最多不超过1个。
除时，我们允许少部分子集比其他的稍大。但是大部分情况下，每个后端所分配到的客
会使用不同的子集，所以整个连接负载会均匀地分布。当后端总数不能被子集大小所整
因为在不同轮的客户端会使用不同的重排列表（子集也就不同），而同一轮的客户端也
4个子集的情况下就是（i%4））。
客户端任务时，我们可以取该客户端在该轮中的位置对应的子集（对客户端i来说，在
这里每个重排列表是每个客户端对应的轮中的新创建的列表。将某个子集被指派给某个
大小来定义，如：
但是不同轮中的客户端会使用不同的列表。接下来，算法将子集用重排过的列表和子集
一轮计算中使用不同的随机排列是均衡负载的更好方式。
端出现故障，那么它们对应的负载将会分布给其他的（subset_size－N）个后端。在每
其他的故障，
端出现问题时，它的负载将会被分配给它所在子集的剩余后端中。如果剩余后端中再有
务滚动更新）。不同的轮应该使用不同的随机重排种子。如果没有变化，那么当一个后
●客户端[0]，客户端[4]，客户端[8]会使用子集[0]
客户端[3]，客户端[7]，客户端[11]会使用子集[3]
子集[0]=重排列表[0]到重排列表[2]
客户端[2]，客户端[6]，客户端[10]会使用子集[2]
客户端[1]，
子集[3]=重排列表[9]到重排列表[11]
子集[2]=重排列表[6]到重排列表[8]
子集[1]=重排列表[3]到重排列表[5]
，负载会继续叠加，从而使情况变得更严重：如果某个后端子集中有N个后
，客户端[5]，客户端[9】会使用子集[1]
利用划分子集限制连接池大小
240
---
## Page 248
241
206
成的，包括以下几项：
负载任务使用2倍的CPU资源。这样的负载均衡结果是非常浪费的，这是由很多因素造
理成本和物理服务器的差异等，但是我们发现轮询策略可能会导致最高负载任务比最低
该策略的负载均衡结果可能很差。这里的实际数据取决于很多因素，例如不同的请求处
不幸的是，虽然轮询策略（roundrobin）非常简单，并且比随机选择后端效果要好，但
务，只要这个后端可以成功连接并且不在跛脚鸭状态中即可。很长时间以来，这都是我
简单轮询算法
基于后端状态的算法（例如最小负载轮询，或者带权重的轮询)。
负载均衡策略可以是非常简单的，不考虑任何后端状态的算法（例如，轮询），或者是
端需要实时决定（利用部分甚至可能是过期的后端信息）哪个后端需要服务哪个请求。
们最普遍使用的策略，现在很多服务仍在使用。
用户请求的算法。大部分负载均衡策略的复杂度都来自于决策的分布式特性，每个客户
看一下负载均衡的策略，也就是客户端任务用来选择它的子集中哪个任务需要接收某个
现在我们已经知道了某个客户端任务是如何保持一定数量的健康后端的连接的，下面来
负载均衡策略
图20-5：300个客户端，300个后端，子集数量10，采用确定性算法的结果
一个非常简单的负载均衡策略是让每个客户端以轮询的方式发送给子集中的每个后端任
第20章数据中心内部的负载均衡系统
---
## Page 249
同时负载会在大请求结束后恢复正常），其他请求也会由于资源竞争原因导致延迟上升。
或者完全停止响应（由于内存不够）。但是就算在正常情况下（后端有足够资源处理请求
载会显著上升一段时间。这时，一个异常状态下的任务可能会超出内存限制而被杀掉，
让某些请求并行处理，以降低延迟。但是当该后端接收到一个这样的大请求时，它的负
但是某些请求可以轻易消耗10s。每个后端任务都预留了多个CPU内核资源，这样可以
后端偶尔接收到比其他后端成本更高的请求。在这种情况下，负载均衡的效果就取决于
100、1,000甚至10,000倍的资源。然而，这种多变的资源要求会导致某些不那么幸运的
为了保证服务接口（以及它们对应的实现）简单，服务经常允许成本最高的请求消耗
有些消息会重复出现，而有些会被漏掉。
并将结果结合在一起（而不是在一个固定视图中查询）可能会造成视图不一致的情况
了新的邮件，或者正在删除邮件。在这种情况下，客户端如果只是简单地枚举每个结果
改变，还需要考虑额外的一致性因素。例如，该用户可能在客户端分页查询的时候收到
天收到的邮件。”但是，这种语义改变通常是很困难的。这不仅需要所有客户端代码的
以引入一个分页接口，同时将该请求更改为“返回最近100封（或更少）用户XYZ昨
要调节服务接口以控制每个请求所执行的工作数量。例如，在上述邮件查询服务中，可
在一个请求处理成本差异性很大的系统中进行负载均衡是非常困难的。这时候有可能需
也可能成本非常高。
求处理成本无法事先预知的情况下，轮询策略就更难均衡负载了。例如，一个“返回用
成本最高的请求相比成本最低的请求会多消耗1000倍（甚至更多）的CPU资源。在请
很多服务的请求处理所需要的资源是不同的。在实际工作中，我们发现在很多服务中
请求处理成本不同
于发送请求较多的客户端的子集中的后端，负载就会越高。
率发送请求。在多个进程共享某个后端时，不同客户端请求速率不同是非常常见的，处
一个最简单的轮询负载均衡策略表现糟糕的原因就是所有的客户端可能不会以同样的速
子集过小
成本最高的请求。例如，我们的某个Java后端程序大概每个请求消耗15ms的CPU时间
无法预知的性能因素
物理服务器的差异
请求处理成本不同
子集过小
负载均衡策略
207
242
---
## Page 250
243