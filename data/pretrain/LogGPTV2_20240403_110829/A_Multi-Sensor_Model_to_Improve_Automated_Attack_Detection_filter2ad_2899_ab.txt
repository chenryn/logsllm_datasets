### General Prioritization in Correlation Techniques

Many correlation techniques aim to group alerts that pertain to the same attack, thereby simplifying the task of security operators. Since these techniques were developed after most intrusion detection methods, their developers have had limited influence on the operation of Intrusion Detection System (IDS) sensors. Instead, the focus has been on ensuring compatibility with any sensor.

## 3. Intrusion Detection Sensor Model

We begin by outlining our assumptions and requirements. With these clearly defined, we then present our proposed model, along with its advantages and disadvantages.

### 3.1 Assumptions and Requirements

As discussed in the previous section, handling conflicting information from different sensors requires additional information. We make the following assumption:

**Assumption 1:** The absence of a specific alert can be considered evidence that an attack is not occurring. This is already a common practice in IDS deployments; if no alert is generated, it is generally assumed that there is no ongoing attack (case (2a) in Section 2.2).

Based on this assumption, we formulate the following requirements:

**Requirement 1:** A sensor model should indicate whether a particular attack alert is within the set of possible alerts that the sensor can generate. Such a model could potentially be created using automated tools [15].

**Requirement 2:** The sensor model should describe the sensor's accuracy in detecting a specific attack. Knowledge of the sensor's accuracy is crucial for resolving cases with conflicting evidence.

**Requirement 3:** Sensors should have some degree of functional independence. Adding identical sensors to analyze the same event stream does not provide additional value beyond redundancy. Achieving and verifying this independence is challenging, and more work is needed to develop diverse types of sensors and measure their functional independence.

**Requirement 4:** Knowledge of the sensor status is essential for drawing correct conclusions. A missing alert can be due to either the sensor functioning normally and concluding that no attack is in progress, or the sensor malfunctioning. Only in the former case should a missing alert be considered as evidence that no attack is occurring. The sensor model must describe the conditions under which a sensor will not function, such as when encountering encrypted traffic.

Returning to case (2c) described in Section 2.2, where there is conflicting information (¬a1, a2), and using Assumption 1 (and knowing to look for the missing alert from Requirement 1), we can conclude that one of the sensors is unreliable. There are two possible interpretations:

- **An attack is indeed in progress:**
  - S1 is not working correctly and did not produce an alert, or
  - The attack detection mechanism in S1 does not cover all variants of the attack.
- **There is no attack in progress:**
  - S2 is not working correctly and produced a false alert, or
  - The attack detection mechanism in S2 falsely concluded that an attack was in progress (a traditional false alarm).

To resolve this, we first need to determine if all sensors are functioning correctly (Requirement 4). If a sensor is malfunctioning, we can differentiate between these situations. However, if all sensors appear to be functioning, we must weigh the evidence provided by one sensor against another (Requirement 2). For example, if S2 is known to be prone to false alarms for this specific attack, while S1 is more accurate, we can disregard the combined alert. This analysis is only possible if the sensors are somewhat independent (Requirement 3). Thus, our model must account for the sensor status (and its known weaknesses) as well as the detection capability of the sensor for the specific attack.

### 3.2 Model Description

We use a Bayesian framework to model the sensors and their interdependence. This framework offers several advantages, including an intuitive mix of graphical representation and formal probabilistic reliance. The model is depicted in Figure 1, consisting of nodes and directional connections forming a Directed Acyclic Graph (DAG). The nodes represent variables, and the edges signify dependencies between these variables. Efficient algorithms can calculate the posterior probability of a variable given the observed evidence of other variables.

The model helps determine whether an attack (node `investigate-A`) is occurring based on alerts (nodes `a∗∗`) collected from a set of intrusion detection sensors. The nodes `r∗` and `w∗` account for the sensor's status and detection capabilities. Observable nodes are shaded, while unobservable nodes are white.

In summary, the model uses four types of nodes:
- **Node `inv-A`:** Determines if the ongoing attack is serious enough to warrant further investigation. This node's value is never directly observed.
- **Nodes `a∗∗`:** Indicate whether specific alerts have been received.
- **Nodes `w∗`:** Model the sensor status, accounting for the possibility that a missing alert may mean either no attack or a broken sensor.
- **Nodes `r∗`:** Represent parameters and observations used to calculate the sensor status. These nodes are often observed and populated with data from the sensor environment.

The nodes are organized into groups based on the IDS they belong to. Keeping each IDS as isolated as possible simplifies the model. We elaborate on this and describe the dotted edge with the `x` in Figure 1.

### Parameter Estimation

Estimating parameters for each node in the model is challenging but feasible for several reasons:
- **Using Independence Assumptions:** The model leverages independence assumptions visible in the graphical structure, reducing the number of estimates needed compared to a full joint distribution.
- **Robust Parameter Estimation:** Capturing the ratio between parameters is often sufficient, even if their exact values are less important [5].
- **Local Parameters:** Model parameters are expressed in terms familiar to security officers, such as false positives and false negatives for each rule.

We envision that most parameters will have reasonable default values provided by the IDS vendor, with the security officer fine-tuning them at the local site. Machine learning algorithms can also perform some of this fine-tuning based on current traffic.

### Problematic Interdependence between IDSs

We highlight the problem of independence assumptions in the model. While the model in Figure 1 is simplified, maintaining a simple and modular structure introduces incorrect independence assumptions. For example, if IDS i and IDS j are both signature-based, and IDS i has one alert for attack A while IDS j has two, the model assumes the alert from IDS i is independent of the others. In reality, the alerts may be dependent, as indicated by the dotted line with the `x` in Figure 1. Despite this, the model can still work well due to the following reasons:
- **Model Robustness:** Models like Naive Bayes work surprisingly well despite inaccurate independence assumptions [11].
- **Simplification:** Excluding inter-IDS dependencies simplifies the model. Including these dependencies would require re-evaluating many parameters whenever a new IDS is added.
- **Difficulty in Estimation:** Estimating the dependence between IDSs is challenging and requires expertise in both systems.

For these reasons, we sometimes explicitly ignore inter-IDS dependencies, balancing simplicity and accuracy.

### 3.3 Model Example: Estimating the Parameters

Figure 2 shows a simplified example of the model, focusing on the phf attack [12]. The attack involves sending a request to run a vulnerable CGI script (`phf`) with a newline character in hex encoding (%0a), allowing arbitrary command execution. Snort, a network-based IDS, can detect this attack using rule 1762, which looks for the string “/phf” followed by a newline character in the URI. However, Snort cannot detect attacks in encrypted traffic.

To estimate the necessary parameters for the model in Figure 2, we restrict each node to be either true (T) or false (F). Using conditional probability tables (CPTs), we reduce the number of parameters from 16 to 8. Several parameters are easy to specify, and we can use conditional independence not visible in the structure.

**Underlying Risk of the Attack:**
- **Node `inv-A`:** Signifies whether the attack is serious enough to warrant an investigation. Setting the prior probability \( P(\text{inv-A} = T) \) is the most challenging part. We exaggerate the risk of the attack to account for the higher cost of false negatives.

**Likelihood of IDS Degrading Tricks:**
- **Node `r0_1`:** Indicates whether the web request is encrypted, a typical failure mode for a network IDS. We estimate how often web requests are encrypted.

**False Positive / False Negative Rate:**
- **Node `a1_1`:** Signifies whether the sensor outputs an alert from rule 1762. When the sensor is not working, we do not expect any alerts. Formally, \( a1_1 \) is conditionally independent of `inv-A` given that the sensor is broken (¬w1). For the last two rows, we need to determine the probabilities based on the sensor's accuracy.