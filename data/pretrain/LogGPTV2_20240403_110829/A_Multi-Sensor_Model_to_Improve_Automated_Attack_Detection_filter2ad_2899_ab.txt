Generality Has Been Prioritized. Many correlation techniques try to group
alerts belonging to the same attack to make the security operator’s task easier.
As correlation techniques have been developed after most intrusion detection
techniques, the developers of correlation techniques have not had much inﬂuence
on the operation of IDS sensors; instead, the focus has been to work with any
sensor.
3 Intrusion Detection Sensor Model
We ﬁrst describe our assumptions and our requirements. With these clearly in
mind, we then describe our proposed model and its advantages and disadvantages.
296
M. Almgren, U. Lindqvist, and E. Jonsson
3.1 Assumptions and Requirements
As shown in the previous section, we need more information to be able to handle
cases with conﬂicting information from diﬀerent sensors. We make the following
assumption in our work:
Assumption 1. We assume that the absence of a particular alert may consti-
tute evidence that an attack is not taking place. At ﬁrst glance this assump-
tion may look strange, but this is already the case in any IDS deployment
today; with no alert, one assumes that all is well and one does not follow up
with an investigation (this is case (2a) in Section 2.2).
We can then formulate the following requirements.
Requirement 1. We require a sensor model, which tells us whether an alert
for a particular attack is in the set of possible alerts that this sensor can
produce. Such a model could possibly be created by automatic tools [15].
Requirement 2. Furthermore, we require that this sensor model describe the
sensor’s accuracy with respect to detecting a particular attack. Knowing the
sensor’s accuracy helps us resolve cases with conﬂicting evidence.
Requirement 3. We require sensors to have some degree of functional inde-
pendence. Additional identical sensors analyzing the same event stream do
not provide added value beyond redundancy. However, independence is a
diﬃcult requirement to satisfy and to verify. More work is needed to de-
velop diﬀerent types of sensors and to measure the functional independence
between them.
Requirement 4. We require knowledge of the sensor status to draw the correct
conclusion. There are two reasons why a sensor may not produce an alert; the
sensor is either functioning normally and has concluded that an attack is not
in progress, or the sensor is malfunctioning. Only in the former case should
we consider a missing alert to be evidence that an attack is not occurring.
The sensor model needs to describe under what conditions a sensor will not
work (for example, when it encounters encrypted traﬃc).
Now let us return to case (2c) described in Section 2.2 with conﬂicting in-
formation: ¬a1 , a2. Using assumption 1 above (and knowing to look for the
missing alert from req. 1 ), we can conclude that one of the sensors is not reliable
in this case. There are two possible interpretations:
– An attack is indeed in progress
– There is no attack in progress
• S1 is not working correctly, and therefore did not produce an alert, or
• the attack detection mechanism in S1 does not cover all variants of this
attack.
• S2 is not working correctly and produced this alert as a result of mal-
functioning, or
• the attack detection mechanism in S2 falsely concluded that an attack
was in progress based on its analysis of the audit source (a traditional
false alarm).
Thus, we are faced with ﬁrst deciding if all sensors are working in the system
(req. 4 ). Clearly, if a sensor is malfunctioning in an easily discernible way, we
A Multi-Sensor Model to Improve Automated Attack Detection
297
Fig. 1. A template of the Bayesian model we use.
Each IDS is treated as somewhat independent of
the others, but the complete details are given in
Section 3.2.
Fig. 2. An example of the model
using Snort with the rule for de-
tecting the phf attack (sid=1762).
We use conditional probability ta-
bles with labels (where l-m stands
for low-medium), which are later
replaced with actual probabilities.
can diﬀerentiate between these situations. However, if all sensors seem to work
correctly we need to weigh the evidence given by one sensor for this particular
attack against the evidence given by another sensor (req. 2 ). Simply put, if it
is known that S2 is prone to false alarms for this particular attack, while S1
is more accurate, we can ignore the combined alert for now. This analysis is
possible only if the sensors are somewhat independent (req. 3 ). Thus, our model
needs to account for the sensor status (and its known weaknesses) as well as the
detection capability of the sensor (rule) for this particular attack.
3.2 Model Description
We use a Bayesian framework to model the sensors and their interdependence.
Such a framework has several advantages, and among them is the intuitive mix
between the graphical model with the underlying formal reliance on probabil-
ity. The model is shown in Figure 1. As shown, the model consists of a series
of nodes and the directional connections between these nodes. The model can
graphically be represented as a DAG (directionally acyclic graph). The nodes
represents variables, and the edges between nodes signify a dependence between
these particular variables. There are eﬃcient algorithms to calculate the poste-
rior probability of a variable, given the observed evidence of other variables.
We use the model to ﬁnd out whether an attack that should be further in-
vestigated (node investigate-A) is occurring, based on evidence in the form of
∗∗) collected from a set of intrusion detection sensors. Based on
alerts (nodes a
∗
∗), a sensor may accurately detect
several parameters and observations (nodes r
∗).
an attack or fail to do so, and this is accounted for in the model (nodes w
The value of each node may be observed in some circumstances (for example, a
speciﬁc alert is triggered). In this particular application domain, some nodes will
298
M. Almgren, U. Lindqvist, and E. Jonsson
probably almost always be observed while some others will never be observed.
In Figure 1, the observable nodes are shaded, while the white nodes are seldom
observed directly.
To summarize, in the model we use four types of nodes:
the basis to calculate the node inv-A.
Node inv-A is used to determine if the ongoing attack is serious enough to
be further investigated. Obviously, the value of this node is never directly
observed.
Nodes a∗∗ signify whether we have received particular alerts, and thus serve as
Nodes w∗ model the sensor status, as a missing alert may mean two diﬀerent
conditions: no attack or a broken sensor. These nodes cannot directly be
observed.
∗) in a fashion sim-
∗
∗ are used to calculate inv-A. These nodes are of-
ilar to how the nodes a
ten observed and populated with particular observations from the sensor
environment.
The nodes are informally organized into groups based on which intrusion
detection system they belong to. Keeping each IDS as isolated from others as
possible leads to a simpler model and below we elaborate on this topic and
describe the dotted edge with the x found in Figure 1.
∗ are used to calculate the sensor status (nodes w
Nodes r∗
Even though each IDS has its own particular failure modes, some observations
are important to several IDSs. For that reason, there are both global (r0) and
local r-nodes. Furthermore, some of the r-nodes report transient observations
while others may report more stationary conditions where a value is sticky,
i.e., remains until explicitly changed. We describe the implementation in further
detail in Section 5. Below we expand on the features of the model.
Parameter Estimation. As with any other probability model, one needs to
estimate parameters for each node. This is diﬃcult, but there are several reasons
why we believe it is feasible for our model.
Using Independence Assumptions: the model takes advantage of the inde-
pendence assumptions visible in the graphical structure and thus reduces
the number of estimates that are necessary as compared with a full joint
distribution without explicit independence assumptions.
Robust Parameter Estimation: furthermore, it is many times enough to
capture the ratio between the parameters while their actual values are less
important [5].
Local Parameters: the model parameters are expressed as something the se-
curity oﬃcer is already familiar with, e.g., false positives and false negatives
for each rule.
We envision that most of these parameters have reasonable default values that
can be estimated by the IDS vendor, and that the security oﬃcer then only
needs to ﬁne-tune the settings at the local site. It is possible that some of this
ﬁne-tuning can be performed by machine learning algorithms based on current
traﬃc seen at the site.
A Multi-Sensor Model to Improve Automated Attack Detection
299
Problematic Interdependence between IDSs. We would like to highlight
the problem concerning independence assumptions. Clearly, the model in Fig-
ure 1 is simpliﬁed. Keeping a simple and modular structure introduces some
incorrect independence assumptions. For example, let us assume that IDS i and
IDS j are both signature-based IDSs. IDS i has one alert for A while IDS j has
two alerts. In Figure 1, we show that the two alerts from IDS j are dependent,
but that the alert from IDS i is independent of the others. In reality, it is likely
that aj
1 as indicated in Figure 1 with the dotted
line with the x. Even diﬀerent commercial IDSs many times use similar signa-
tures to detect attacks. As will be seen in the examples shown in Section 4, we
sometimes ignore this particular dependence. The reasons are the following:
2 is dependent on, for example, ai
– First, a model may work very well despite some broken independence as-
sumptions; consider for example the Naive Bayes model, which works surpris-
ingly well despite being very inaccurate in terms of
independence
assumptions [11].
– Second, excluding the inter-IDS dependence simpliﬁes the model. If we in-
clude these dependencies between IDSs, it would mean that the inclusion of
a new IDS to the whole system would necessitate a re-evaluation of many
parameters (and thus invalidate the opportunity to have pre-set default
values).
– Third, estimating this dependence is diﬃcult. Someone would have to be an
expert on both IDSs to be able to set the level of dependence between two
alerts.
For these reasons, we sometimes explicitly ignore the inter-IDS dependencies
even though we acknowledge that they exist. Thus, we balance the simplicity of
the model against its accuracy.
3.3 Model Example: Estimating the Parameters
In Figure 2 we show a simpliﬁed example of the model, where we have limited the
number of nodes to make it more understandable. In this case, we concentrate
on the phf attack [12]. The background and execution of the attack can be found
in Almgren et al. [3]. By sending a request to run the vulnerable cgi script phf
and including the newline character in hex encoding (%0a), the attacker may
be able to execute arbitrary commands. The script passes control to the shell
without removing the newline character, which has special meaning to the shell.
The open-source IDS Snort has several potential ways to detect this attack
([3]). For example, one can use rule 1762, which detects the string “/phf”
matched with a newline character within the URI. Snort is a network-based
IDS, and for that reason it cannot detect attacks in encrypted traﬃc (among
other things).
Now let us consider how to estimate the necessary parameters for the model
shown in Figure 2. The structure is given from Figure 1 and we have restricted
each node to be either true (T) or false (F). Even though one can give probability
distributions over each node, we use conditional probability tables (CPTs) in
this paper. A full joint probability distribution would need 16 parameters, but
300
M. Almgren, U. Lindqvist, and E. Jonsson
taking advantage of the independence shown in the ﬁgure, we are left with only
8 parameters. As we will show, several of these parameters are easy to specify
and we can also use some conditional independence not visible in the structure.
For example, there is no need to compare the eﬀectiveness of diﬀerent IDSs,
but all values are set in relation to the current IDS and the underlying attack
it tries to detect. In principle, one needs to consider the following three areas:
the underlying risk of the attack, the likelihood of IDS degrading tricks, and the
false positive / false negative rate. These are discussed in detail below.
Underlying Risk of the Attack. Starting with inv-A, being the node that
signiﬁes whether the attack is serious enough to warrant an investigation, we need
to set a value for the probability P (inv-A = T), known as the prior probability
in a Bayesian model. We consider this to be the most diﬃcult value to specify in
the model. Axelsson [4] has discussed the problems of setting certain parameters
for an anomaly detection system. If false positives are more acceptable than false
negatives one should exaggerate the risk of the attack, which we have done in
our example.
Likelihood of IDS Degrading Tricks. In Section 3.2, we introduced the
r-nodes for observations that may aﬀect the IDS’s detection capability. For a
network-based IDS, this may include encrypted traﬃc, diﬀerent types of obfus-
cating techniques, a heartbeat message, and so on. In Figure 2, we have only
one such node, r0
1. This node signiﬁes whether the web request is encrypted (a
typical failure mode for a network IDS). Thus, we estimate how often the web
requests are encrypted.
We can then move on to w1, a node that signiﬁes whether the sensor is working
correctly but which is never directly observed. If the traﬃc is encrypted, we
consider it very unlikely that the sensor is working. However, the sensor may fail
for conditions other than encrypted traﬃc, and thus we let this be reﬂected in
the estimate for P (w1|¬r0
1).
False Positive / False Negative Rate. For the node a1
1, which signiﬁes
whether the sensor outputs an alert from rule 1762, the ﬁrst two parameters are
easy to set. When the sensor is not working (the ﬁrst two rows), we do not expect
to see any alerts. Formally, a1
1 is conditionally independent of inv-A, given that
the sensor is broken (¬w1). For the last two rows, we need to determine the