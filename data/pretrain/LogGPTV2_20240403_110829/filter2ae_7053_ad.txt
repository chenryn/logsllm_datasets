                        # Duplicate its expansions recursively
                        # {**seen, **{s: new_s}} is seen + {s: new_s}
                        _duplicate_context(grammar, orig_grammar, new_s, expansion=None,
                                           depth=depth - 1, seen={**seen, **{s: new_s}})
                        new_expansion += new_s
                grammar[symbol][i] = new_expansion
    def duplicate_context(grammar: Grammar, 
                          symbol: str,
                          expansion: Optional[Expansion] = None, 
                          depth: Union[float, int] = float('inf')):
        """Duplicate an expansion within a grammar.
        In the given grammar, take the given expansion of the given `symbol`
        (if `expansion` is omitted: all symbols), and replace it with a
        new expansion referring to a duplicate of all originally referenced rules.
        If `depth` is given, limit duplication to `depth` references
        (default: unlimited)
        """
        orig_grammar = extend_grammar(grammar)
        _duplicate_context(grammar, orig_grammar, symbol,
                           expansion, depth, seen={})
        # After duplication, we may have unreachable rules; delete them
        for nonterminal in unreachable_nonterminals(grammar):
            del grammar[nonterminal]
在完成上下文复制之后就可以通过类似下面的操作得到我们想要的结果：
    set_prob(probabilistic_ip_address_grammar, "", "127", 1.0)
    set_prob(probabilistic_ip_address_grammar, "", "0", 1.0)
不过这就又引入一个问题，概率在赋予给symbol之后一成不变真的合适吗？在真实世界的Fuzz中随着我们对于目标的不断了解，或者一些其它情况比如长时间未出现想要的结果等，及时改变策略也是非常必要的，但是如果Fuzz可以智能的自己调节调整不同symbol的概率值的话，会减轻很多的负担并获得更好的软件测试效果。一个比较好的办法是让Fuzz通过最开始被给予Inputs种子来学习应该赋予某些symbol多大的一个概率值，这种方法在某些场景下非常有用：
  1. 测试常用功能，因为很多软件测试更希望常用的功能确保安全，但是对于漏洞挖掘研究人员来说可能目标不在于此。
  2. 测试不常用功能，通过规避Inputs中解析到的symbol，Fuzz就会更偏向于测试一些不常用的功能。
  3. 专注于指定的Inputs，一些漏洞挖掘可能希望专注于已有的非常有价值的poc inputs，通过专注于这些inputs，Fuzz可以测试软件的一些薄弱环节从而达到很好的效果。
理论已经存在，那么如何实现呢？第一步肯定是需要将已经存在的Inputs种子恢复成为派生树，然后对派生树种每个Symbol对应的值有多少来计算将来的概率值。
如上图，假设我给与一个`127.0.0.1`的种子，那么被解析之后，0在``中的概率值就会被限制为`50%`，127和1分别为`25%`，那么在Fuzz运行的时候相关的概率值就可以赋予给``。那么如果测试一些不常用功能该怎么办呢？其实就是通过原来测常用功能的Inputs得到相关概率，然后进行概率翻转就行了，比如常用功能的Inputs概率如下：
    [('http', {'prob': 0.2222222222222222}),
     ('https', {'prob': 0.6666666666666666}),
     ('ftp', {'prob': 0.0}),
     ('ftps', {'prob': 0.1111111111111111})]
那么经过翻转之后就是：
    [('http', {'prob': 0.1111111111111111}),
     ('https', {'prob': 0.0}),
     ('ftp', {'prob': 0.6666666666666666}),
     ('ftps', {'prob': 0.2222222222222222})]
上述就是之前讲到的专注测试常用功能或者非常用功能的基本思路，从此处引出的另一个比较关键的是通过Inputs帮我们专注于目标的特定功能，它和测试常用功能的区别就是首先要找到一批特殊的Inputs，通过这些Inputs作为seeds就可以对语法解析的过程进行概率分析和限制，使得后续的变异可以一直有较高的目标命中率。
### Generator With Pre or Post or order Func
在某些Inputs在生成的时候，Fuzz作者可能希望对他们进行一些限制调整，获取其它的操作，这些都可以通过`pre
func`完成。这类似于hook，那么对于func触发的时机一般就分为两种，在Inputs的生成之前或者是生成之后，在语法里面的表示就是：
    CHARGE_GRAMMAR: Grammar = {
        "": ["Charge  to my credit card "],
        "": ["$"],
        "": ["."],
        "": ["", ""],
        "": crange('0', '9'),
        "": [""],
        "": [""],
        "": [""],
    }
    CHARGE_GRAMMAR.update({
        "": [(".", opts(pre=high_charge))], # high_charge是函数名称
    })
    CHARGE_GRAMMAR.update({
        "": [(".",
                     opts(pre=lambda: random.randint(10000000, 90000000) / 100.0))] # 或者选择使用lambda表达式
    })
另一种就是在Seeds的生成之后了：
    CHARGE_GRAMMAR.update({
        "": [("", opts(post=lambda digits: fix_credit_card(digits)))]
    })
比如生成的digits不能满足Fuzz的需求，我们就可以通过这种方式来进行及时的修正，以提高Fuzz的效率。
### Greybox Fuzzing with Grammars
除了Fuzzing性能类的问题之外的另一个问题就是变异的导向问题，在Grammars
Fuzz生成Input的过程中对于Grammar的内部解析是随机的，但是对于Fuzz目标来说，大量的Input可能会触发相同的分支进而导致代码覆盖率难以达到理想的值。对于AFL类似的覆盖引导型Fuzz来说，因为白盒Fuzz的源代码插桩缘故可以统计代码覆盖率来进行不错的引导，但是还存在很多情况，比如黑盒，甚至是以一种WebServer为目标的Fuzz，统计代码覆盖率并不是一件简单的事情，这时候采取的措施应该是不断的增加Inputs生成的多样性，比如在上述的派生树的子节点的扩展过程进行统计，使其在生成Input语料的时候偏向于还没扩展过的节点。这时候就会面临新的问题，如何快速提升代码覆盖率？
在进行Fuzz的时候，有时候一些输入的部分会被识别为关键字，比如C语言里面的int等，如果告诉Fuzz这些关键字就可以在短时间内极大的提升代码覆盖率，但是就长远来看整体的代码覆盖率还是要差于不使用关键字字典的情况。下面是使用关键字字典的变异Inputs生成器。
    class DictMutator(Mutator):
        """Mutate strings using keywords from a dictionary"""
        def __init__(self, dictionary: List[str]) -> None:
            """Constructor. `dictionary` is the list of keywords to use."""
            super().__init__()
            self.dictionary = dictionary
            self.mutators.append(self.insert_from_dictionary)
        def insert_from_dictionary(self, s: str) -> str:
            """Returns s with a keyword from the dictionary inserted"""
            pos = random.randint(0, len(s))
            random_keyword = random.choice(self.dictionary)
            return s[:pos] + random_keyword + s[pos:]
但是问题在于关键字通过字典随机引入的方式很可能破坏了Input本来的正确输入结构进而引发不必要的损耗。解决的方法其实也很简单：`Fuzzing with
Input Fragments`.
  1. 对原有的Input进行Parse，形成派生树。
  2. 对派生树进行节点互换或者节点替换等操作。
  3. 对派生树进行还原，形成新的Input。
以上的所有操作都在派生树上进行。为了更方便的进行编译操作，可以建立一个派生树的碎片池，每个碎片都由子树组成，子树包括符号和对应的Node节点和其子节点。不过对于派生树的parse其实是非常耗时的，因此可以设置一些时间限制来防止速度过低。不过以Fragments为基础的变异虽然可以很好的符合Inputs合法性的要求但是在代码覆盖率提升方面并不亮眼。而且以此为基础的`LangFuzz`其实在Inputs生成的速度上也远低于平常的结构化黑盒Fuzz。下面是两组对比数据：
    LangFuzz
    From the 300 generated inputs, 152 (50.67%) can be parsed.In total, 91 statements are covered.
    BlackFuzz
    From the 300 generated inputs, 36 (12.00%) can be parsed.In total, 161 statements are covered.
可以看出以Fragments为基础的变异的优势在于它可以很好的生成符合结构化语法的变异。那么现在的疑问就是如何在保证输入语法正确性的前提下提升代码覆盖率？
一种方法是利用类似AFL的覆盖引导方式，利用代码覆盖率不断作为变异的反馈，以此来不断的增添提高代码覆盖率的种子，同时提供`structural
mutations`和`32 byte-level mutations`两种变异方式，如下：
    class GreyboxGrammarFuzzer(GreyboxFuzzer):
        """Greybox fuzzer using grammars."""
        def __init__(self, seeds: List[str],
                     byte_mutator: Mutator, tree_mutator: FragmentMutator,
                     schedule: PowerSchedule) -> None:
            """Constructor.
            `seeds` - set of inputs to mutate.
            `byte_mutator` - a byte-level mutator.
            `tree_mutator` = a tree-level mutator.
            `schedule` - a power schedule.
            """
            super().__init__(seeds, byte_mutator, schedule)
            self.tree_mutator = tree_mutator
        def create_candidate(self) -> str:
            """Returns an input generated by structural mutation 
               of a seed in the population"""
            seed = cast(SeedWithStructure, self.schedule.choose(self.population))
            # Structural mutation
            trials = random.randint(0, 4)
            for i in range(trials):
                seed = self.tree_mutator.mutate(seed)
            # Byte-level mutation
            candidate = seed.data
            if trials == 0 or not seed.has_structure or random.randint(0, 1) == 1:
                dumb_trials = min(len(seed.data), 1  Tips:如何判断对面的代码覆盖率，一般黑盒情况下可以试时间，如果一个Input在对面耗费了更多的时间来运行，那么可以猜测其走过了更多的代码分支。
## 总结
在面对Fuzz的目标的时候最重要的是选择合适的变异方式以及较好的初始种子，根据目标和测试目的不断地进行取舍和针对性开发才能得到比较理想的结果。
## 参考链接
> 
>
> 文中数据测试来源大多为Fuzzingbook，因为根据电脑不同，其实具体数值结果会有一定偏差，但是结论都是一样的，因此就展示了书中的测试数据。
* * *