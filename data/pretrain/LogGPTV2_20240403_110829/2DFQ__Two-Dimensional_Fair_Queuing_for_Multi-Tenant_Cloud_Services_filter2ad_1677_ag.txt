_read Scheduling and Pre-Emption _read scheduling
in the operating system is analogous to packet scheduling.
In the research literature, lottery scheduling [(cid:254)˙] and stride
scheduling [(cid:254)(cid:146)] were independently developed and later found
to be equivalent to fair queueing [¸6, (cid:13)@]. Scheduling algo-
rithms have proliferated in both domains, for example start-
time fair queueing was proposed for both hierarchical link [zh]
and CPU [zz] sharing. On multicore systems, hierarchical
schedulers such as the Linux Completely Fair Scheduler [(cid:13)(cid:254)]
and Distributed Weighted Round Robin [(cid:13)§] extend fair queue-
ing to multiple cores by maintaining per-core run queues and
load-balancing runnable threads across cores.
_read schedulers can control the amount of time a thread
spends running on a core (i.e., the quantum or time slice).
_us they have the means to explicitly bound how long a
core can be occupied before a di(cid:242)erent thread gets to run. In
the worst case, this reduces burstiness to the granularity of
the largest time slice. For example, Li et al. [(cid:13)§] discuss for
infeasible thread weights: “Eventually, this thread becomes the
only one on its CPU, which is the best any design can do to fulßll
an infeasible weight.”
However, applications cannot control preemption or spec-
ify fairness goals because operating systems do not expose
suıcient control over these mechanisms. Current operat-
Figure ¸(cid:13): Illustration of the intuition behind zDFQ’s signißcantly improved
service for our workloads.
unavoidable, even for zDFQ. However, starting from the ßrst
extreme and transitioning to the second, with workloads be-
coming less predictable, zDFQ does not deteriorate as rapidly
as WFQ or WFzQ do. Between the two extremes lies a mid-
dle ground where WFQ and WFzQ experience blocking and
reduced quality of service, but zDFQ does not (). Many real-
world workloads lie between these two extremes, containing
both unpredictable and predictable tenants. Our results in
§@.z.¸ and §@.¸.¸ demonstrated this deterioration.
Estimators We designed zDFQE’s pessimistic estimation strat-
egy to take advantage of zDFQ’s cost-based partitioning. WFQ
and WFzQ lack cost-based partitioning, so there is nothing
fundamental about them that would beneßt from this esti-
mation strategy. Nonetheless, we can apply it to these algo-
rithms; we experimented with numerous combinations of
scheduler and estimator, and found that WFQ and WFzQ with
pessimistic estimation performed no better, and o(cid:22)en signiß-
cantly worse, than using an EMA. We view estimator choice
as an important design point for future work in this space – to
ensure good behavior when over- or under-estimating request
costs.
Limitations While zDFQ improves quality of service when
the system is backlogged, work-conserving schedulers in gen-
eral cannot improve service when the system is under-utilized.
Inevitably, all worker threads could be servicing expensive re-
quests if no other requests are present. Any subsequent burst
of small requests would have to wait for the expensive re-
quests to ßnish. _is behavior occurs under zDFQ and all
non-preemptive schedulers, and creates large delay for the
small requests. One way to avoid this is to make the sched-
uler not work-conserving, for example, by allowing threads
to remain idle despite the presence of queued requests. An-
other option is to allow a variable number of worker threads
and to spawn new threads when small requests show up. _is
would over-saturate the CPU and thus slow down already
running requests, but would allow the small requests to ßnish
faster; however, it would incur additional overhead from more
context-switching. In the extreme, we could take a thread-per-
tenant approach; however, this results in more context switch-
ing, contention for application level (e.g., locks, caches) and
system level (e.g., disk) resources, and substantially reduced
goodput. _is is especially relevant since requests can be very
short – less than ¸ms in duration for many requests – which
exacerbates context switching overheads. Our approach in
this paper – fair queue scheduling at the application level –
156
unpredictable workloads,expensive requests2DFQWF²QWFQqualityofservicetypicalworkloads➀➂➁ing systems do not give applications the ability to conßgure
thread preemption; at most, Windows User-Mode Schedul-
ing [(cid:254)(cid:254)] (most notably used by Microso(cid:22) SQL Server [h(cid:254)])
gives applications control over thread scheduling but lacks
conßgurable time slices – threads only yield to the sched-
uler when they make blocking systems calls or a direct call to
UmsThreadYield(). Operating systems also lack application-
level tenant information and do not have access to application-
level request queues. Fairness mechanisms like cgroups [¸¸]
enable operators to divide resources between processes and
threads to provide fairness and isolation, but do not have ac-
cess to application-level queues. More importantly, due to
the high number of tenants, a thread-per-tenant approach
is infeasible; short requests less than ¸ms in execution du-
ration exacerbate context-switching overheads and reduce
throughput, while higher concurrency increases contention
over application-level (e.g., locks, caches) and system-level
(e.g., disk) resources.
Event-based systems have long been debated in the op-
erating systems community as a dual to thread-based sys-
tems [h(cid:146),(cid:13)(cid:13),(cid:254)@]. A key feature of event-based systems is coop-
erative multitasking: event handlers are not preemptible and
run until completion, simplifying concurrent programming
on single-core machines because event handlers are implicitly
atomic [(cid:13)(cid:13),(cid:254)@]. _read-based systems also adapted this fea-
ture into cooperative scheduling [¸,(cid:254)6], whereby threads only
yield to the scheduler at pre-deßned points specißed by the
developer. For both event-based and thread-based systems,
cooperative scheduling is vulnerable to long-running event
handlers, or threads that go for a long time without yield-
ing to the scheduler. When this occurs, programs can block
for large periods of time and the program may become non-
responsive [¸,(cid:13)(cid:13),(cid:254)6]. To avoid this behavior, developers can ex-
plicitly split up long-running threads or handlers into smaller
ones that reenter the scheduler more frequently. _is solution
is similarly applicable in our domain, and is the approach
taken, for example, by Google’s Web search system [¸(cid:254)]. How-
ever, it requires manual intervention from developers, and
only reduces the range of request costs – it does not eliminate
variation entirely. _e approach is fundamentally constrained
by factors that a(cid:242)ect execution eıciency, e.g. data loaded in
various system caches and intermediary memory allocation,
and is burdened by need for “stack ripping” [¸]. An alternative
to manual intervention is framework support for automati-
cally reentering the scheduler, for example by analyzing code
to identify the boundaries of critical sections [(cid:254)6], or as part of
the language runtime [¸˙]. In all of these systems, if fairness is
a goal, then zDFQ can be used to provide smooth average-case
schedules.
Middlebox Packet Processing Dominant-Resource Fair
Queueing (DRFQ) [z¸], a multi-resource queue scheduler for
middlebox packet processing, allows concurrent execution
of multiple requests, such as on the CPU, but does not deal
with large variation in request costs and only permits serial
execution for each tenant. DRFQ builds on top of SFQ and
uses linear resource consumption models for di(cid:242)erent types
of requests. _e authors show that for several middle-box
modules linear models work relatively well, but acknowledge
that if models are inaccurate, allocated shares might be o(cid:242)
proportionally to the estimation error. Further, because the
resource models depend on which modules the packet exe-
cuted in, resource accounting happens only a(cid:22)er the request
completes, which limits DRFQ to executing single tenant’s
packets sequentially.
Storage and I/O pClock [z@], mClock [z(cid:254)], and Pisces [(cid:254)z]
propose queue schedulers for physical storage, where several
I/O requests execute concurrently. I/O request costs are much
less variable than in the cloud setting, and dynamic workloads
remain an open challenge [@¸]. Similar request cost modeling
has been done in the storage domain as well [z(cid:254),(cid:254)(cid:13)], where
type of operations and hardware variability are limited. For
example, IOFlow [(cid:254)(cid:13)] periodically benchmarks the storage
device to estimate costs of tokens used for pacing requests.
Also, to bound the uncertainty of arbitrary long IO requests,
they break them into ¸MB requests.
Distributed Systems Many distributed systems schedulers,
such as Retro [(cid:13)h], Cake [@§], and Pulsar [h] periodically
measure request costs and use these estimates in the next
interval. However, in dynamic workloads, such as shown in
Figure (cid:13), such approach can lead to arbitrary unfairness across
tenants unless estimation errors are addressed. _ese systems
enforce fair share using rate limiters, typically implemented
as token buckets, which are not designed to provide fairness
at short time intervals. Depending on the token bucket rate
and burst parameters, they can either under-utilize the system
or concurrent bursts can overload it without providing any
further fairness guarantees.
Web Applications A large body of work – for example
[6, (cid:13)˙] or see [z(cid:13)] for a survey – has focused on providing
di(cid:242)erentiated services or quality-of-service (QoS) for cluster-
based applications; they deßne multiple user classes (or ten-
ants) with di(cid:242)erent scheduling policies based on priorities,
achieved utility or required resources. _ese papers typically
consider problems related to admission control, allocating
resources to maximize total utility, or distributed scheduling
and do not deal with providing ßne-grained resource fairness.
Scheduling requests with inaccurate or unknown size has been
studied previously [z,@z]. However, these papers concentrate
on various priority-based policies, such as shortest-job-ßrst
or shortest-remaining-time-ßrst, and ignore resource fairness.
For example, Aalo [¸z], schedules co-(cid:6)ows in a network with-
out prior knowledge of their size; by using a priority queue
where new (cid:6)ows start at the highest priority and their priority
decreases as they send more data.
9. CONCLUSION
In this paper we demonstrated the challenges of fair queue-
ing in multi-tenant services, where requests with large cost
variance execute concurrently across many threads. We pro-
posed and evaluated a practical scheduler for such settings,
Two-Dimensional Fair Queueing, which achieves signißcantly
more smooth schedules and can improve latencies of small
requests when competing with large requests.
157
10. REFERENCES
[¸] A›(cid:149)*, A., H(cid:213){(cid:220)vv, J., T-(cid:220)T(cid:129)(cid:220)!, M., B(cid:213)v(cid:213)Mb(cid:149), W. J., *(cid:152)›
D(cid:213)n(cid:138)(cid:220)n!, J. R. Cooperative task management without
manual stack management. z§§z USENIX Annual Techni-
cal Conference (ATC ’§z). (§˙).
[z] A(cid:129)T(cid:138)(cid:213), M. D., C*!!*, D., *(cid:152)› MT(cid:138)-T*!›T, P. PSBS: Prac-
tical size-based scheduling. IEEE Transactions on Com-
puters (z§¸@). (§˙).
[h] A(cid:152)$(cid:220)v, S., B*vv*(cid:152)T, H., K*!*$T*(cid:152)(cid:152)TM, T., O’S-(cid:220)*, G.,
*(cid:152)› T-(cid:220)!(cid:220)Mb*, E. End-to-end performance isolation
through virtual datacenters. ¸¸th USENIX Symposium on
Operating Systems Design and Implementation (OSDI ’¸(cid:13)).
(§z, h.z, and ˙).
[(cid:13)] Microso(cid:22) Azure Storage. https://azure.microso(cid:22).com/
services/storage/. [Online; accessed June z§¸@]. (§¸, h,
and @).
[(cid:254)] B(cid:220)(cid:152)(cid:152)(cid:220)uu, J. C., *(cid:152)› Z-*(cid:152)$, H. Hierarchical packet fair
queueing algorithms. ¸(cid:146)(cid:146)@ Conference of the ACM Special
Interest Group on Data Communication (SIGCOMM ’(cid:146)@).
(§@).
[@] B(cid:220)(cid:152)(cid:152)(cid:220)uu, J. C., *(cid:152)› Z-*(cid:152)$, H. WFzQ: Worst-case fair
weighted fair queueing. ¸(cid:254)th IEEE Conference on Computer
Communications (INFOCOM ’(cid:146)@). (§¸, z, (cid:13), and ˙).