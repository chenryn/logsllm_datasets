### Scheduling and Pre-emption in Operating Systems

Scheduling in operating systems is analogous to packet scheduling. In the research literature, lottery scheduling and stride scheduling were independently developed and later found to be equivalent to fair queueing. These scheduling algorithms have proliferated in both domains. For example, start-time fair queueing has been proposed for both hierarchical link and CPU sharing.

On multicore systems, hierarchical schedulers such as the Linux Completely Fair Scheduler (CFS) and Distributed Weighted Round Robin (DWRR) extend fair queueing to multiple cores by maintaining per-core run queues and load-balancing runnable threads across cores. These schedulers can control the amount of time a thread spends running on a core, known as the quantum or time slice. This allows them to explicitly bound how long a core can be occupied before a different thread gets to run. In the worst case, this reduces burstiness to the granularity of the largest time slice. For instance, Li et al. discuss infeasible thread weights: "Eventually, this thread becomes the only one on its CPU, which is the best any design can do to fulfill an infeasible weight."

However, applications cannot control preemption or specify fairness goals because operating systems do not expose sufficient control over these mechanisms. Current operating systems lack the ability to configure thread preemption. At most, Windows User-Mode Scheduling (UMS), notably used by Microsoft SQL Server, gives applications control over thread scheduling but lacks configurable time slices. Threads only yield to the scheduler when they make blocking system calls or call UmsThreadYield() directly.

### Performance and Fairness in Schedulers

Figure 13 illustrates the intuition behind zDFQ's significantly improved service for our workloads. While zDFQ does not deteriorate as rapidly as WFQ or WFzQ with less predictable workloads, it still experiences some unavoidable issues. Many real-world workloads lie between the two extremes, containing both unpredictable and predictable tenants. Our results in Sections 4.2.1 and 4.2.2 demonstrated this deterioration.

### Estimators and Scheduling Strategies

We designed zDFQE’s pessimistic estimation strategy to take advantage of zDFQ’s cost-based partitioning. WFQ and WFzQ lack cost-based partitioning, so they do not benefit from this estimation strategy. We experimented with numerous combinations of scheduler and estimator and found that WFQ and WFzQ with pessimistic estimation performed no better, and often significantly worse, than using an Exponential Moving Average (EMA). The choice of estimator is an important design point for future work in this space to ensure good behavior when over- or under-estimating request costs.

### Limitations and Workarounds

While zDFQ improves quality of service when the system is backlogged, work-conserving schedulers in general cannot improve service when the system is under-utilized. If all worker threads are servicing expensive requests, subsequent small requests must wait. This behavior occurs under zDFQ and all non-preemptive schedulers, causing large delays for small requests. One way to avoid this is to make the scheduler not work-conserving, allowing threads to remain idle despite the presence of queued requests. Another option is to allow a variable number of worker threads and spawn new threads when small requests appear. This would oversaturate the CPU and slow down already running requests but would allow small requests to finish faster, albeit with additional overhead from more context-switching. In the extreme, a thread-per-tenant approach could be taken, but this results in more context switching, contention for application-level (e.g., locks, caches) and system-level (e.g., disk) resources, and substantially reduced goodput. This is especially relevant since requests can be very short—less than 5ms in duration for many requests—which exacerbates context-switching overheads.

### Event-Based and Thread-Based Systems

Event-based systems, a dual to thread-based systems, have been debated in the operating systems community. A key feature of event-based systems is cooperative multitasking: event handlers are not preemptible and run until completion, simplifying concurrent programming on single-core machines because event handlers are implicitly atomic. Thread-based systems also adapted this feature into cooperative scheduling, where threads only yield to the scheduler at predefined points specified by the developer. Both event-based and thread-based systems are vulnerable to long-running event handlers or threads. To avoid this, developers can split long-running threads or handlers into smaller ones that reenter the scheduler more frequently. This solution is applicable in our domain and is the approach taken, for example, by Google’s Web search system. However, it requires manual intervention and only reduces the range of request costs, not eliminating variation entirely. An alternative is framework support for automatically reentering the scheduler, for example, by analyzing code to identify critical sections or as part of the language runtime. In all of these systems, if fairness is a goal, zDFQ can be used to provide smooth average-case schedules.

### Middlebox Packet Processing

Dominant-Resource Fair Queueing (DRFQ), a multi-resource queue scheduler for middlebox packet processing, allows concurrent execution of multiple requests, such as on the CPU, but does not deal with large variations in request costs and only permits serial execution for each tenant. DRFQ builds on top of SFQ and uses linear resource consumption models for different types of requests. The authors show that for several middlebox modules, linear models work relatively well, but acknowledge that inaccurate models can lead to disproportionate allocation shares. Further, because resource accounting happens only after the request completes, DRFQ is limited to executing a single tenant’s packets sequentially.

### Storage and I/O

pClock, mClock, and Pisces propose queue schedulers for physical storage, where several I/O requests execute concurrently. I/O request costs are less variable than in cloud settings, and dynamic workloads remain an open challenge. Similar request cost modeling has been done in the storage domain, where the type of operations and hardware variability are limited. For example, IOFlow periodically benchmarks the storage device to estimate the costs of tokens used for pacing requests. Additionally, to bound the uncertainty of arbitrary long I/O requests, they break them into 1MB requests.

### Distributed Systems

Many distributed systems schedulers, such as Retro, Cake, and Pulsar, periodically measure request costs and use these estimates in the next interval. However, in dynamic workloads, such an approach can lead to arbitrary unfairness across tenants unless estimation errors are addressed. These systems enforce fair share using rate limiters, typically implemented as token buckets, which are not designed to provide fairness at short time intervals. Depending on the token bucket rate and burst parameters, they can either under-utilize the system or overload it without providing further fairness guarantees.

### Web Applications

A large body of work has focused on providing differentiated services or Quality of Service (QoS) for cluster-based applications. These studies define multiple user classes (or tenants) with different scheduling policies based on priorities, achieved utility, or required resources. They typically consider problems related to admission control, allocating resources to maximize total utility, or distributed scheduling and do not deal with providing fine-grained resource fairness. Scheduling requests with inaccurate or unknown size has been studied previously, but these papers concentrate on various priority-based policies, such as shortest-job-first or shortest-remaining-time-first, and ignore resource fairness. For example, Aalo schedules co-flows in a network without prior knowledge of their size by using a priority queue where new flows start at the highest priority and their priority decreases as they send more data.

### Conclusion

In this paper, we demonstrated the challenges of fair queueing in multi-tenant services, where requests with large cost variance execute concurrently across many threads. We proposed and evaluated a practical scheduler, Two-Dimensional Fair Queueing (zDFQ), which achieves significantly smoother schedules and can improve latencies of small requests when competing with large requests.

### References

[1] A. Agrawal, J. Hsu, M. Tariq, W. J. Bolosky, and J. R. Douceur. Cooperative task management without manual stack management. USENIX Annual Technical Conference (ATC '10).

[2] M. D. Alvisi, D. Culler, and P. Mutka. PSBS: Practical size-based scheduling. IEEE Transactions on Computers (2012).

[3] S. Arunagiri, H. Balakrishnan, T. Kiciman, G. O'Shea, and E. Thereska. End-to-end performance isolation through virtual datacenters. USENIX Symposium on Operating Systems Design and Implementation (OSDI '10).

[4] Microsoft Azure Storage. https://azure.microsoft.com/services/storage/. [Online; accessed June 2012].

[5] J. C. Bennett and H. Zhang. Hierarchical packet fair queueing algorithms. ACM SIGCOMM Conference (SIGCOMM '96).

[6] J. C. Bennett and H. Zhang. WF2Q: Worst-case fair weighted fair queueing. IEEE Conference on Computer Communications (INFOCOM '97).