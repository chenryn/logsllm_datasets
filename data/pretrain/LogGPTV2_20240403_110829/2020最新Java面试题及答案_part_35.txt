的；进一步的讲，被插入节点也一定存在叔叔节点(即使叔叔节点为空，我们也视之为存在，空节
点本身就是黑色节点)。理解这点之后，我们依据"叔叔节点的情况"，将这种情况进一步划分为 3
种情况(Case)。
第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。
22.1.6.2. 删除
第一步：将红黑树当作一颗二叉查找树，将节点删除。
这和"删除常规二叉查找树中删除节点的方法是一样的"。分3种情况：
① 被删除节点没有儿子，即为叶节点。那么，直接将该节点删除就OK了。
② 被删除节点只有一个儿子。那么，直接删除该节点，并用该节点的唯一子节点顶替它的位置。
③ 被删除节点有两个儿子。那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给
“该节点的内容”；之后，删除“它的后继节点”。
第二步：通过"旋转和重新着色"等一系列来修正该树，使之重新成为一棵红黑树。
因为"第一步"中删除节点之后，可能会违背红黑树的特性。所以需要通过"旋转和重新着色"来修正
该树，使之重新成为一棵红黑树。
选择重着色3种情况。
① 情况说明：x是“红+黑”节点。
处理方法：直接把x设为黑色，结束。此时红黑树性质全部恢复。
② 情况说明：x是“黑+黑”节点，且x是根。
处理方法：什么都不做，结束。此时红黑树性质全部恢复。
③ 情况说明：x是“黑+黑”节点，且x不是根。
处理方法：这种情况又可以划分为4种子情况。这4种子情况如下表所示：
13/04/2018 Page 251 of 283
参考：https://www.jianshu.com/p/038585421b73
代码实现：https://www.cnblogs.com/skywang12345/p/3624343.html
22.1.7. B-TREE
B-tree又叫平衡多路查找树。一棵m阶的B-tree (m叉树)的特性如下（其中ceil(x)是一个取上限
的函数）：
1. 树中每个结点至多有m个孩子；
2. 除根结点和叶子结点外，其它每个结点至少有有ceil(m / 2)个孩子；
3. 若根结点不是叶子结点，则至少有2个孩子（特殊情况：没有孩子的根结点，即根结点为叶子
结点，整棵树只有一个根节点）；
4. 所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部结点或查询
失败的结点，实际上这些结点不存在，指向这些结点的指针都为null)；
5. 每个非终端结点中包含有 n 个关键字信息： (n，P0，K1，P1，K2，P2，......，Kn，Pn)。其
中：
a) Ki (i=1...n)为关键字，且关键字按顺序排序K(i-1)< Ki。
b) Pi 为指向子树根的接点，且指针 P(i-1)指向子树种所有结点的关键字均小于 Ki，但都大于 K(i-
1)。
c) 关键字的个数n必须满足： ceil(m / 2)-1 <= n <= m-1。
13/04/2018 Page 252 of 283
一棵m阶的B+tree和m阶的B-tree的差异在于：
1.有n棵子树的结点中含有n个关键字； (B-tree是n棵子树有n-1个关键字)
2.所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本
身依关键字的大小自小而大的顺序链接。 (B-tree的叶子节点并没有包括全部需要查找的信息)
3.所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。
(B-tree的非终节点也包含需要查找的有效信息)
参考：https://www.jianshu.com/p/1ed61b4cca12
13/04/2018 Page 253 of 283
22.1.8. 位图
位图的原理就是用一个 bit 来标识一个数字是否存在，采用一个 bit 来存储一个数据，所以这样可
以大大的节省空间。 bitmap是很常用的数据结构，比如用于Bloom Filter中；用于无重复整数的
排序等等。bitmap 通常基于数组来实现，数组中每个元素可以看成是一系列二进制数，所有元素
组成更大的二进制集合。
https://www.cnblogs.com/polly333/p/4760275.html
13/04/2018 Page 254 of 283
23. 加密算法
23.1.1. AES
高级加密标准(AES,Advanced Encryption Standard)为最常见的对称加密算法(微信小程序加密传
输就是用这个加密算法的)。对称加密算法也就是加密和解密用相同的密钥，具体的加密流程如下
图：
23.1.2. RSA
RSA加密算法是一种典型的非对称加密算法，它基于大数的因式分解数学难题，它也是应用最广
泛的非对称加密算法。
非对称加密是通过两个密钥（公钥-私钥）来实现对数据的加密和解密的。公钥用于加密，私钥用
于解密。
13/04/2018 Page 255 of 283
23.1.3. CRC
循环冗余校验(Cyclic Redundancy Check, CRC)是一种根据网络数据包或电脑文件等数据产生简
短固定位数校验码的一种散列函数，主要用来检测或校验数据传输或者保存后可能出现的错误。
它是利用除法及余数的原理来作错误侦测的。
23.1.4. MD5
MD5 常常作为文件的签名出现，我们在下载文件的时候，常常会看到文件页面上附带一个扩展
名为.MD5 的文本或者一行字符，这行字符就是就是把整个文件当作原数据通过 MD5 计算后的值，
我们下载文件后，可以用检查文件 MD5 信息的软件对下载到的文件在进行一次计算。两次结果对
比就可以确保下载到文件的准确性。 另一种常见用途就是网站敏感信息加密，比如用户名密码，
支付签名等等。随着 https 技术的普及，现在的网站广泛采用前台明文传输到后台，MD5 加密
（使用偏移量）的方式保护敏感数据保护站点和数据安全。
13/04/2018 Page 256 of 283
24. 分布式缓存
24.1.1. 缓存雪崩
缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都
去查询数据库了，而对数据库 CPU 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列
连锁反应，造成整个系统崩溃。一般有三种处理办法：
1. 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
2. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓
存。
3. 为key设置不同的缓存失效时间。
24.1.2. 缓存穿透
缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在
缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请
求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。
有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈
希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存
储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不
存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。
24.1.3. 缓存预热
缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，
先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！
24.1.4. 缓存更新
缓存更新除了缓存服务器自带的缓存失效策略之外（Redis 默认的有 6 中策略可供选择），我们还可以
根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：
（1）定时去清理过期的缓存；
（2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数
据并更新缓存。
24.1.5. 缓存降级
当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然
需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开
关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的
（如加入购物车、结算）。
13/04/2018 Page 257 of 283
13/04/2018 Page 258 of 283
25. Hadoop
25.1.1. 概念
就是一个大数据解决方案。它提供了一套分布式系统基础架构。 核心内容包含 hdfs 和
mapreduce。hadoop2.0以后引入yarn.
hdfs是提供数据存储的，mapreduce是方便数据计算的。
1. hdfs 又对应 namenode 和 datanode. namenode 负责保存元数据的基本信息，
datanode直接存放数据本身；
2. mapreduce 对应 jobtracker 和tasktracker. jobtracker 负责分发任务，tasktracker负
责执行具体任务；
3. 对应到master/slave架构，namenode和jobtracker就应该对应到master, datanode
和tasktracker就应该对应到slave.
25.1.2. HDFS
25.1.2.1. Client
Client（代表用 户） 通过与 NameNode 和 DataNode 交互访问 HDFS 中 的文件。 Client提供
了一个类似 POSIX 的文件系统接口供用户调用。
25.1.2.2. NameNode
整个Hadoop 集群中只有一个 NameNode。 它是整个系统的“ 总管”， 负责管理 HDFS的目
录树和相关的文件元数据信息。 这些信息是以“ fsimage”（ HDFS 元数据镜像文件）和
“ editlog”（HDFS 文件改动日志）两个文件形式存放在本地磁盘，当 HDFS 重启时重新构造出
来的。此外， NameNode 还负责监控各个 DataNode 的健康状态， 一旦发现某个DataNode 宕
掉，则将该 DataNode 移出 HDFS 并重新备份其上面的数据。
25.1.2.3. Secondary NameNode
Secondary NameNode 最重要的任务并不是为 NameNode 元数据进行热备份， 而是定期合并
fsimage 和 edits 日志， 并传输给 NameNode。 这里需要注意的是，为了减小 NameNode压
力， NameNode 自己并不会合并 fsimage 和 edits， 并将文件存储到磁盘上， 而是交由
Secondary NameNode 完成。
25.1.2.4. DataNode
一般而言， 每个 Slave 节点上安装一个 DataNode， 它负责实际的数据存储， 并将数据信息定期
汇报给 NameNode。 DataNode 以固定大小的 block 为基本单位组织文件内容， 默认情况下
block 大小为 64MB。 当用户上传一个大的文件到 HDFS 上时， 该文件会被切分成若干个 block，
分别存储到不同的 DataNode ； 同时，为了保证数据可靠， 会将同一个block以流水线方式写到
13/04/2018 Page 259 of 283
若干个（默认是 3，该参数可配置）不同的 DataNode 上。 这种文件切割后存储的过程是对用户
透明的。
25.1.3. MapReduce
同 HDFS 一样，Hadoop MapReduce 也采用了 Master/Slave（M/S）架构，具体如图所示。它
主要由以下几个组件组成：Client、JobTracker、TaskTracker 和 Task。 下面分别对这几个组件
进行介绍。
25.1.3.1. Client
用户编写的 MapReduce 程序通过 Client 提交到 JobTracker 端； 同时， 用户可通过 Client 提
供的一些接口查看作业运行状态。 在 Hadoop 内部用“作业”（Job） 表示 MapReduce 程序。
一个 MapReduce 程序可对应若干个作业，而每个作业会被分解成若干个 Map/Reduce 任务
（Task）。
25.1.3.2. JobTracker
JobTracker 主要负责资源监控和作业调度。JobTracker监控所有TaskTracker与作业的健康状况，
一旦发现失败情况后，其会将相应的任务转移到其他节点；同时 JobTracker 会跟踪任务的执行进
度、资源使用量等信息，并将这些信息告诉任务调度器，而调度器会在资源出现空闲时，选择合
适的任务使用这些资源。在 Hadoop 中，任务调度器是一个可插拔的模块，用户可以根据自己的
需要设计相应的调度器。
13/04/2018 Page 260 of 283
25.1.3.3. TaskTracker
TaskTracker 会周期性地通过 Heartbeat 将本节点上资源的使用情况和任务的运行进度汇报给
JobTracker， 同时接收 JobTracker 发送过来的命令并执行相应的操作（如启动新任务、 杀死任
务等）。TaskTracker 使用“slot” 等量划分本节点上的资源量。“slot” 代表计算资源（CPU、
内存等）。一个 Task 获取到一个 slot 后才有机会运行，而 Hadoop 调度器的作用就是将各个
TaskTracker 上的空闲 slot 分配给 Task 使用。 slot 分为 Map slot 和 Reduce slot 两种，分别供
MapTask 和 Reduce Task 使用。 TaskTracker 通过 slot 数目（可配置参数）限定 Task 的并发
度。
25.1.3.4. Task
Task 分为 Map Task 和 Reduce Task 两种， 均由 TaskTracker 启动。 HDFS 以固定大小的 block
为基本单位存储数据， 而对于 MapReduce 而言， 其处理单位是 split。split 与 block 的对应关
系如图所示。 split 是一个逻辑概念， 它只包含一些元数据信息， 比如数据起始位置、数据长度、
数据所在节点等。它的划分方法完全由用户自己决定。 但需要注意的是，split 的多少决定了 Map
Task 的数目 ，因为每个 split 会交由一个 Map Task 处理。
Map Task 执行过程如图所示。 由该图可知，Map Task 先将对应的 split 迭代解析成一个个
key/value 对，依次调用用户自定义的 map() 函数进行处理，最终将临时结果存放到本地磁盘上，