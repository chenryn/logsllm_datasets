applicable to real world browsing environments at scale.
k-ﬁngerprinting is highly accurate even when an attacker
USENIX Association  
25th USENIX Security Symposium  1199
13
trains on a small fraction of the total data. Untrustworthy
data within that small fraction can then be ﬁltered and
removed before the attack is launched to later yield bet-
ter results, showing that long term website ﬁngerprinting
attacks on a targeted client is a realistic threat.
References
[1] Alexa The Web Information Company, [Accessed
[2] Leo
August 2015]. URL http://alexa.com.
Random
Breiman.
[Ac-
cessed
https:
//www.stat.berkeley.edu/˜breiman/
RandomForests/.
Forests,
URL
2015].
July
[3] The Nielsen Company,
[Accessed July 2015].
http://www.nielsen.com/us/
URL
en/insights/news/2010/led-by-
facebook-twitter-global-time-
spent-on-social-media-sites-up-
82-year-over-year.html.
[4] Tor Proposal 254, [Accessed November 2015].
URL https://gitweb.torproject.org/
torspec.git/tree/proposals/254-
padding-negotiation.txt.
[5] George Dean Bissias, Marc Liberatore, David
Jensen, and Brian Neil Levine. ”Privacy Vulner-
abilities in Encrypted HTTP Streams”. In Proceed-
ings of the 5th International Conference on Privacy
Enhancing Technologies, pages 1–11, 2006.
[6] Leo Breiman. ”Random Forests”. Mach. Learn.,
45(1):5–32, 2001.
[7] Xiang Cai, Xin Cheng Zhang, Brijesh Joshi, and
Rob Johnson. ”Touching from a distance: web-
site ﬁngerprinting attacks and defenses”. In ACM
Conference on Computer and Communications Se-
curity, pages 605–616, 2012.
[8] Xiang Cai, Rishab Nithyanand, and Rob Johnson.
”CS-BuFLO: A Congestion Sensitive Website Fin-
gerprinting Defense”.
In Proceedings of the 13th
Workshop on Privacy in the Electronic Society,
pages 121–130, 2014.
[9] Shuo Chen, Rui Wang, XiaoFeng Wang, and Ke-
huan Zhang. ”Side-Channel Leaks in Web Appli-
cations: A Reality Today, a Challenge Tomorrow”.
In Proceedings of the 2010 IEEE Symposium on Se-
curity and Privacy, pages 191–206, 2010.
[10] Heyning Cheng, , Heyning Cheng, and Ron Avnur.
”Trafﬁc Analysis of SSL Encrypted Web Brows-
ing”, 1998.
[11] Roger Dingledine, Nick Mathewson, and Paul F.
Syverson.
”Tor: The Second-Generation Onion
Router”. In Proceedings of the 13th USENIX Se-
curity Symposium, pages 303–320, 2004.
[12] Kevin P. Dyer, Scott E. Coull, Thomas Ristenpart,
and Thomas Shrimpton. ”Peek-a-Boo, I Still See
You: Why Efﬁcient Trafﬁc Analysis Countermea-
sures Fail”. In Proceedings of the 2012 IEEE Sym-
posium on Security and Privacy, pages 332–346,
2012.
[13] Jerome H. Friedman. ”Greedy Function Approxi-
mation: A Gradient Boosting Machine”. Annals of
Statistics, 29:1189–1232, 2000.
[14] Pall Oskar Gislason, Jon Atli Benediktsson, and Jo-
hannes R. Sveinsson. ”Random Forests for Land
Cover Classiﬁcation”. Pattern Recogn. Lett., 27(4):
294–300, March 2006.
[15] Xiaodan Gu, Ming Yang, and Junzhou Luo. ”A
novel Website Fingerprinting attack against multi-
tab browsing behavior”. In 19th IEEE International
Conference on Computer Supported Cooperative
Work in Design, CSCWD, pages 234–239, 2015.
[16] Dominik Herrmann, Rolf Wendolsky, and Hannes
Federrath.
”Website Fingerprinting: Attacking
Popular Privacy Enhancing Technologies with the
Multinomial Naive-bayes Classiﬁer”. In Proceed-
ings of the 2009 ACM Workshop on Cloud Comput-
ing Security, pages 31–42, 2009.
[17] Marc Ju´arez, Sadia Afroz, Gunes Acar, Claudia
D´ıaz, and Rachel Greenstadt. ”A Critical Evalu-
ation of Website Fingerprinting Attacks”. In Pro-
ceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security, pages
263–274, 2014.
[18] Marc Ju´arez, Mohsen Imani, Mike Perry, Clau-
dia D´ıaz, and Matthew Wright. ”WTF-PAD: to-
ward an efﬁcient website ﬁngerprinting defense for
tor”. CoRR, abs/1512.00524, 2015. URL http:
//arxiv.org/abs/1512.00524.
[19] Albert Kwon, Mashael AlSabah, David Lazar,
Marc Dacier, and Srinivas Devadas. ”Circuit Fin-
gerprinting Attacks: Passive Deanonymization of
Tor Hidden Services”.
In 24th USENIX Security
Symposium, pages 287–302, 2015.
[20] A. Liaw and M. Wiener. ”Classiﬁcation and Re-
gression by randomForest”. R News: The Newslet-
ter of the R Project, 2(3):18–22, 2002.
[21] Marc Liberatore and Brian Neil Levine. ”Inferring
the source of encrypted HTTP connections”.
In
Proceedings of the 13th ACM Conference on Com-
puter and Communications Security, pages 255–
263, 2006.
[22] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua
Zhou. ”Isolation-Based Anomaly Detection”. ACM
Trans. Knowl. Discov. Data, 6(1):3:1–3:39, March
2012.
[23] Liming Lu, Ee-Chien Chang, and Mun Choon
Chan. ”Website Fingerprinting and Identiﬁcation
Using Ordered Feature Sequences”.
In Proceed-
ings of the 15th European Conference on Research
1200  25th USENIX Security Symposium 
USENIX Association
14
[34] David Wagner and Bruce Schneier. ”Analysis of
the SSL 3.0 Protocol”. In Proceedings of the 2nd
Conference on Proceedings of the Second USENIX
Workshop on Electronic Commerce - Volume 2,
pages 4–4, 1996.
[35] T. Wang and I. Goldberg. ”Comparing website ﬁn-
gerprinting attacks and defenses”. Technical Re-
port, 2013.
[36] T. Wang and I. Goldberg. ”On Realistically Attack-
ing Tor with Website Fingerprinting”. Technical
Report, 2015.
[37] T. Wang and I. Goldberg. ”Walkie-Talkie: An Ef-
fective and Efﬁcient Defense against Website Fin-
gerprinting”. Technical Report, 2015.
[38] Tao Wang and Ian Goldberg. ”Improved Website
Fingerprinting on Tor”. In Proceedings of the 12th
ACM Workshop on Workshop on Privacy in the
Electronic Society, pages 201–212, 2013.
[39] Tao Wang, Xiang Cai, Rishab Nithyanand, Rob
Johnson, and Ian Goldberg. ”Effective Attacks and
Provable Defenses for Website Fingerprinting”. In
Proceedings of the 23rd USENIX Security Sympo-
sium, pages 143–157, 2014.
[40] Charles V. Wright, Scott E. Coull, and Fabian Mon-
rose.
”Trafﬁc Morphing: An Efﬁcient Defense
Against Statistical Trafﬁc Analysis”. In In Proceed-
ings of the 16th Network and Distributed Security
Symposium, pages 237–250, 2009.
in Computer Security, pages 199–214, 2010.
[24] Xiapu Luo, Peng Zhou, Edmond W. W. Chan,
Wenke Lee, Rocky K. C. Chang, and Roberto
Perdisci.
”HTTPOS: Sealing information leaks
with browser-side obfuscation of encrypted ﬂows”.
In In Proc. Network and Distributed Systems Sym-
posium (NDSS), 2011.
[25] Rishab Nithyanand, Xiang Cai, and Rob Johnson.
”Glove: A Bespoke Website Fingerprinting De-
fense”.
In Proceedings of the 13th Workshop on
Privacy in the Electronic Society, pages 131–134,
2014.
[26] A. Stolerman M. V. Ryan P. Brennan P. Juola, J.
I. Noecker Jr and R. Greenstadt. ”A Dataset for
Active Linguistic Authentication”.
In IFIP WG
11.9 International Conference on Digital Foren-
sics, 2013.
[27] Andriy Panchenko, Lukas Niessen, Andreas Zin-
nen, and Thomas Engel. ”Website ﬁngerprinting
in onion routing based anonymization networks”.
In Proceedings of the 10th annual ACM workshop
on Privacy in the electronic society, WPES, pages
103–114, 2011.
[28] Andriy Panchenko, Fabian Lanze, Andreas Zinnen,
Martin Henze, Jan Pennekamp, Klaus Wehrle, , and
Thomas Engel. ”Website Fingerprinting at Internet
Scale”. In Network and Distributed System Security
Symposium, 2016.
[29] Mike Perry.
”A Critique of Website Trafﬁc
https://blog.
Fingerprinting Attacks”.
torproject.org/blog/critique-
website-traffic-fingerprinting-
attacks, Accessed June 2015.
[30] Mike Perry.
trafﬁc
”Experimental defense web-
https:
ﬁngerprinting”.
site
//blog.torproject.org/blog/
experimental-defense-website-
traffic-fingerprinting, Accessed June
2015.
[31] Vitaly Shmatikov and Ming-Hsiu Wang. ”Timing
Analysis in Low-Latency Mix Networks: Attacks
and Defenses”. In ESORICS, 2006.
[32] Qixiang Sun, Daniel R. Simon, Yi-Min Wang, Wilf
Russell, Venkata N. Padmanabhan, and Lili Qiu.
”statistical identiﬁcation of encrypted web brows-
ing trafﬁc”. In Proceedings of the 2002 IEEE Sym-
posium on Security and Privacy, pages 19–, 2002.
[33] Vladimir Svetnik, Andy Liaw, Christopher Tong,
J. Christopher Culberson, Robert P. Sheridan, and
Bradley P. Feuston. ”Random Forest: A Classiﬁca-
tion and Regression Tool for Compound Classiﬁca-
tion and QSAR Modeling”. Journal of Chemical
Information and Computer Sciences, 43(6):1947–
1958, 2003.
USENIX Association  
25th USENIX Security Symposium  1201
15
A Total feature importance.
131 - 150 .
Feature Description
Packet concentration list features.
Figure 12: Feature importance score for all 150 features
in order. The table gives the description for the 20 least
important features.
B Closed World Error Rates
Figure 13 shows the confusion matrix in our closed-
world setting, that is, it shows the 49 misclassiﬁcations
(out of 550). We see that some persistent misclassiﬁca-
tion patterns of web pages appear, for example web page
54 is classiﬁed correctly four times but is misclassiﬁed as
web page 0 six times. The misclassiﬁcation rate in Fig-
ure 13 is 0.09 but this is the average error rate across all
web pages.
Figure 13 shows that the classiﬁcation error is not uni-
form across all web pages. Some pages are misclassiﬁed
many times, and confused with many others, while oth-
ers are never misclassiﬁed. An attacker can leverage this
information to estimate the misclassiﬁcation rate of each
web page instead of using the global average misclassiﬁ-
cation rate.
As in Section 10, an attacker can use their training
set of web pages to estimate the misclassiﬁcation rate of
each web page, by splitting the training set in to a smaller
training set and validation set. Since both sets are from
the original training set the attacker has access to the true
labels. The attacker then computes the misclassiﬁcation
rate of each web page, which they can use as an estima-
tion for the misclassiﬁcation rate when training on the
entire training set and testing on new trafﬁc instances.
Figures 14 and 15 show the global misclassiﬁcation
rate for a varying number of monitored pages. Moni-
tored pages are ﬁrst ordered in terms of the misclassiﬁ-
cation rate they have, ordered from smallest to largest.
From Figure 14, using the Wang et al. data set, we see
that if the attacker considers only the top 50% on web
pages in terms of per page misclassiﬁcation rate, the true
Figure 13: Confusion matrix for closed-world attack on
Tor using DSNorm. F1 score = 0.913, Accuracy: 0.915,
550 items.
Figure 14: The global misclassiﬁcation rate when con-
sidering different numbers of monitored pages from the
Wang et al. data set. The monitored pages are ordered in
terms of smallest misclassiﬁcation rate to largest.
global misclassiﬁcation rate and global misclassiﬁcation
rate estimated by the attacker drop by over 70%. Simi-
larly from Figure 15, using DSNorm, if the attacker con-
siders only the top 50% on web pages in terms of per
page misclassiﬁcation rate, the true global misclassiﬁca-
tion rate and global misclassiﬁcation rate estimated by
the attacker drop by over 80%. This allows an attacker
to train on monitored pages and then cull the pages that
have too high an error rate, allowing for more conﬁdence
in the classiﬁcation of the rest of the monitored pages.
The gap between the attacker’s estimate and the mis-
classiﬁcation rate of the test set is largely due to the size
of the data set. Figure 14 has a smaller error of estimate
than Figure 15 because the Wang et al. data set has 60
instances per monitored page, in comparison DSNorm has
20 instances per monitored page. In practice, an attacker
1202  25th USENIX Security Symposium 
USENIX Association
16
Figure 17: Attack out-of-bag score while varying the
number of monitored training pages.
size by 10,000 web pages. Training on approximately
30% of the 7000 unmonitored web pages k-ﬁngerprinting
gives a TPR of over 0.90 and a FPR of 0.01 for k=1.
Training on approximately 30% of the 17,000 unmoni-
tored web pages k-ﬁngerprinting gives a TPR of 0.90 and
a FPR of 0.006 for k=1.
The fraction of unmonitored pages that were incor-
rectly classiﬁed as a monitored page decreased as we in-
creased our world size. In other words, out of 12,000 un-
monitored pages only 72 were classiﬁed as a monitored
page, with this Figure dropping to 24 if we use k=10 for
classiﬁcation. This provides a strong indication that k-
ﬁngerprinting can scale to a real-world attack in which
a client is free to browse the entire internet, with no de-
crease in attack accuracy.
Number of monitored training pages in closed-world.
Figure 17 shows the out-of-bag score as we change the
number of monitored pages we train. We found that
training on any more than a third of the data gives
roughly the same accuracy.
Figure 15: The global misclassiﬁcation rate when con-
sidering different numbers of monitored pages from
DSNorm. The monitored pages are ordered in terms of
smallest misclassiﬁcation rate to largest.
Figure 16: Attack accuracy for 17,000 unmonitored web
pages. Each line represents a different number of un-
monitored web pages that were trained, while varying k,
the number of ﬁngerprints used for classiﬁcation.
cannot expect perfect alignment; they are generated from
two different sets of data, the training and training +
test set. Nevertheless the attacker can expect this dif-
ference to decrease with the collection of more training
instances.
C Attack on larger world size of DSNorm
We run k-ﬁngerprinting on DSNorm with the same number
of monitored sites but increase the numbered of unmon-
itored sites to 17,000. We evaluate when we have both
time and size features available.
Figure 16 shows the results of k-ﬁngerprinting while
varying the number of ﬁngerprints (k) used for classiﬁ-
cation, from between 1 and 10, for various experiments
trained with different numbers of unmonitored pages.
We see that the attack results are comparable to the attack
on 7000 unmonitored pages, meaning there is no degra-
dation in attack accuracy when we increase the world
USENIX Association  
25th USENIX Security Symposium  1203
17