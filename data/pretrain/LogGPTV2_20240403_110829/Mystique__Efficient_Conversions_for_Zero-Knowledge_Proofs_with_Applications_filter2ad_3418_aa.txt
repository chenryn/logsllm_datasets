title:Mystique: Efficient Conversions for Zero-Knowledge Proofs with Applications
to Machine Learning
author:Chenkai Weng and
Kang Yang and
Xiang Xie and
Jonathan Katz and
Xiao Wang
Mystique: Efficient Conversions for Zero-Knowledge 
Proofs with Applications to Machine Learning
Chenkai Weng, Northwestern University; Kang Yang, State Key Laboratory of 
Cryptology; Xiang Xie, Shanghai Key Laboratory of Privacy-Preserving Computation 
and MatrixElements Technologies; Jonathan Katz, University of Maryland; 
Xiao Wang, Northwestern University
https://www.usenix.org/conference/usenixsecurity21/presentation/weng
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Mystique: Efﬁcient Conversions for Zero-Knowledge Proofs
with Applications to Machine Learning
Chenkai Weng
Northwestern University
Xiang Xie
Shanghai Key Laboratory of
Privacy-Preserving Computation and
MatrixElements Technologies
Kang Yang (
)
State Key Laboratory of Cryptology
Jonathan Katz
Xiao Wang (
)
University of Maryland
Northwestern University
Abstract
Recent progress in interactive zero-knowledge (ZK) proofs
has improved the efﬁciency of proving large-scale computa-
tions signiﬁcantly. Nevertheless, real-life applications (e.g., in
the context of private inference using deep neural networks)
often involve highly complex computations, and existing ZK
protocols lack the expressiveness and scalability to prove
results about such computations efﬁciently.
In this paper, we design, develop, and evaluate a ZK system
(Mystique) that allows for efﬁcient conversions between arith-
metic and Boolean values, between publicly committed and
privately authenticated values, and between ﬁxed-point and
ﬂoating-point numbers. Targeting large-scale neural-network
inference, we also present an improved ZK protocol for ma-
trix multiplication that yields a 7× improvement compared
to the state-of-the-art. Finally, we incorporate Mystique in
Rosetta, a TensorFlow-based privacy-preserving framework.
Mystique is able to prove correctness of an inference on a
private image using a committed (private) ResNet-101 model
in 28 minutes, and can do the same task when the model is
public in 5 minutes, with only a 0.02% decrease in accuracy
compared to a non-ZK execution when testing on the CIFAR-
10 dataset. Our system is the ﬁrst to support ZK proofs about
neural-network models with over 100 layers with virtually no
loss of accuracy.
1 Introduction
Zero-knowledge (ZK) proofs allow one party with a secret
witness to prove some statement about that witness without
revealing any additional information. In recent years we have
seen massive progress in the efﬁciency and scalability of ZK
proofs based on many different ideas [14,17,34,38,39]. With
such improvements, we envision a huge potential in applying
ZK proofs to machine learning (ML) applications, particularly
neural-network inference. As examples:
• Zero-knowledge proofs of evasion attacks. A pre-trained
model M might be publicly released to be used by the
general public. Using a ZK protocol, a white-hat hacker
who discovers a bug in the model (e.g., an evasion attack)
could prove existence of that bug in zero knowledge, e.g.,
they could prove knowledge of two “close” inputs x1 and x2
for which M (x1) (cid:54)= M (x2).
• Zero-knowledge proofs of correct inference. An ML
model may require huge effort to train and thus may only
be accessible as a paid service (e.g., GPT-3 that contains
175 billion parameters [19]). In this case, the model param-
eters are kept private, and users need to send their inputs
to the owner of an ML model to be classiﬁed. Currently,
such users have no guarantee that the model owner applies
the correct model. Using a ZK protocol, the model owner
could publicly commit to a model, and then proves in zero
knowledge that the committed model was applied to the
user’s submitted input, yielding the claimed result.
• Zero-knowledge proofs of private benchmarks. An ML
model may be evaluated on private testing data. Here, the
owner of the testing data can publicly commit to its data;
a model trainer can then send its model (developed using
independent training data) to the data owner, who locally
evaluates the accuracy of the model. The data owner can
use a ZK protocol to prove that the submitted model was
executed on the committed data.
Unfortunately, after examining existing ZK proof systems,
we found that no existing solutions were sufﬁciently scalable
or practical for any of the above applications once reasonably
complicated neural-network models were involved. For exam-
ple, zk-SNARKs [9,10,12,16,20,41,47,50] provide excellent
proof size and veriﬁcation time, and support veriﬁable com-
putation on committed data [29]. However, state-of-the-art
zk-SNARKs require the memory of the prover to be pro-
portional to the statement size; proving a statement with a
billion constraints would require about 640 GB of memory.
For ML applications, they can only handle simple models like
decision trees [57]. Recent ZK protocols based on subﬁeld
vector oblivious linear evaluation (sVOLE) [7, 27, 52, 54],
USENIX Association
30th USENIX Security Symposium    501
resulting system for ZK proofs regarding neural-network in-
ference. As shown in Figure 1, linear layers of the neural
network are accelerated by using our matrix-multiplication
optimization, while the non-linear layers rely on our ﬁxed-
point/ﬂoating-point conversions. (We implemented ReLU,
Sigmoid, Max Pooling, SoftMax, and Batch Normalization
in the non-linear layers; other operations can be added eas-
ily.) All computations can be done using either arithmetic or
Boolean values, depending on which is more efﬁcient at any
given step. Due to our improved cryptographic protocols and
integrated implementation, we can implement ZK proofs on
large neural networks (e.g., ResNet-50 and ResNet-101) with
millions of model parameters; see Section 7.
2 Preliminaries
2.1 Notation
We use λ and ρ to denote the computational and statistical se-
curity parameters, respectively. For a ﬁnite set S, we use x ← S
to denote that x is chosen uniformly from S. For a,b ∈ N,
we denote by [a,b] the set {a, . . . ,b}, and by [a,b) the set
{a, . . . ,b− 1}. We use bold lower-case letters like xxx for col-
umn vectors, and denote by xi the i-th component of xxx where
x1 is the ﬁrst entry. We use xxx(cid:62) to denote the transposition of xxx.
We use negl(·) to denote a negligible function.
For an extension ﬁeld Fqk of a ﬁeld Fq, we ﬁx some
monic, irreducible polynomial f (X) of degree k so that Fqk ∼=
Fq[X]/ f (X). Thus, every element a ∈ Fqk can be uniquely
written as a = ∑h∈[1,k] ah · X h−1 with ah ∈ Fq for all h ∈ [1,k].
When we write arithmetic expressions involving both ele-
ments of Fq and Fqk, operations are performed in Fqk with
elements of Fq viewed as elements of Fqk in the natural way.
In general, we work in an extension ﬁeld such that qk ≥ 2ρ.
2.2 Universal Composability
We say that protocol Π UC-realizes ideal functionality F if for
any probabilistic polynomial time (PPT) adversary A, there
exists a PPT simulator S such that for any PPT environment Z
with arbitrary auxiliary input, the output distribution of Z in
the real-world execution where Z interacts with A and the par-
ties running Π is computationally indistinguishable from the
output distribution of Z in the ideal-world execution where
Z interacts with S and F. In the G-hybrid model the parties
execute a protocol given access to ideal functionality G. We
say that protocol Π UC-realizes F in the G-hybrid model
with statistical error ε if the statistical difference between
the output distributions of Z in the real-world execution and
hybrid-world execution is bounded by ε.
Figure 1: Overview of our system for ZK neural-network
inference.
privacy-free garbled circuits [30, 37, 39], or the “MPC-in-
the-head” paradigm [4, 8, 21, 33, 40] are efﬁcient in terms
of execution time and memory overhead, but do not work
efﬁciently with publicly committed data and the overall com-
munication is still fairly large. While in principle one could
use zk-SNARKs with recursive composition [15, 23], their
concrete performance is still quite poor.
1.1 Our Contributions
We propose a system (Mystique1) based on recent sVOLE-
based interactive ZK protocols that includes a set of building
blocks for efﬁcient ZK proofs of large-scale neural-network
inference. Crucially, our system includes efﬁcient techniques
for three types of conversions:
1. Arithmetic/Boolean values. Inspired by a similar ideas
in the setting of secure computation [28], we design opti-
mized protocols to efﬁciently convert between arithmetic
and Boolean values (to support mixed-mode circuits) in
the context of sVOLE-based zero knowledge.
2. Committed/authenticated values. To allow publicly
committed values to be used in ZK proofs, we design an
efﬁcient protocol that converts such values to values that
are privately authenticated by the prover and veriﬁer, and
can thus be used directly in sVOLE-based ZK protocols.
3. Fixed-point/ﬂoating-point values. We designed circuits
for IEEE-754-compliant ﬂoating-point operations, and de-
signed efﬁcient protocols to convert between ﬁxed-point
values (encoded in a ﬁeld) and ﬂoating-point numbers.
In addition to the above, we also design an efﬁcient ZK proof
for matrix multiplication, such that the number of private mul-
tiplications required is sublinear in the matrix size. Compared
to the previously best-known ZK proof for matrix multiplica-
tion [54], our ZK protocol improves the execution time by a
factor of 7×.
We integrated the above in Rosetta [22], a privacy-
preserving framework based on TensorFlow [1], and use the
1Mystique is a shape-shifter; our system supports efﬁcient conversions
(“shape shifting”) in zero knowledge.
502    30th USENIX Security Symposium
USENIX Association
Information-theoretic MACs
2.3
We use information-theoretic message authentication codes
(IT-MACs), which were originally proposed for maliciously
secure two-party computation [13,43]. We authenticate values
in Fq, but the authentication itself is done over an extension
ﬁeld Fqk. Speciﬁcally, let ∆ ∈ Fqk be a uniform global key
known only to the veriﬁer V . A value x ∈ Fq known by the
prover P is authenticated by giving V a uniform local key
K ∈ Fqk and giving P the corresponding tag
M = K + ∆· x ∈ Fqk .
We denote such an authenticated value by [x] = (x, M, K),
meaning that P holds (x, M) and V holds K. When we want
to make the ﬁeld explicit, we write [x]q. We extend the above
notation to vectors or matrices of authenticated values as well.
For example, [xxx] means that P holds xxx ∈ Fn
q and M ∈ (Fqk )n,
while V holds K ∈ (Fqk )n with M = K + ∆· xxx.
Authenticated values are additively homomorphic. That is,
given authenticated values [x1], . . . , [x(cid:96)] and public coefﬁcients
c1, . . . ,c(cid:96),c∈ Fq, the parties can compute [y] = ∑(cid:96)
i=1 ci·[xi]+c
using only local computation.
Batch opening. An authenticated value [x] can be opened by
having P send (x, M) to V , who veriﬁes M = K +∆·x. When
opening (cid:96) values, it is possible to do better than (cid:96) parallel
repetitions of this procedure; speciﬁcally, all (cid:96) values can be
opened using only (cid:96)logq + λ bits of communication. We use
BatchCheck for the following batch-opening procedure:
• Let H : {0,1}∗ → {0,1}λ be a hash function modeled as
a random oracle. Suppose that [x1], . . . , [x(cid:96)] are (cid:96) authenti-
cated values to be opened.
• P sends x1, . . . ,x(cid:96) ∈ Fq to V .
• Additionally:
– If q = 2 and k = λ, the two parties compute χ :=
H(x1, . . . ,x(cid:96)) ∈ F
2λ. P computes σ := ∑i∈[1,(cid:96)] Mi · χi ∈
F
2λ and sends it to V , who checks whether σ =
∑i∈[1,(cid:96)](Ki + ∆ · xi) · χi. As in prior work [35, 52],
the soundness error is bounded by (qH + (cid:96) + 1)/2λ =
negl(λ), where qH is the number of queries to H.
– Otherwise, P computes σ := H(M1, . . . , M(cid:96)) ∈ {0,1}λ
and sends it to V , who can then check whether σ :=
H(K1 + ∆· x1, . . . , K(cid:96) + ∆· x(cid:96)). The soundness error is at
most 1/pk + qH/2λ = 1/pk + negl(λ) [26].
When the opened values are all zero and so need not be sent,
we use CheckZero to denote the batch-opening procedure.
Authenticated values from sVOLE. We can view authen-
ticated values as subﬁeld vector oblivious linear evaluation
(sVOLE) correlations. Thus, random authenticated values can
be efﬁciently generated using the recent LPN-based sVOLE
protocols [18, 46, 52, 55], which have communication com-
plexity sublinear in the number of authenticated values.
2.4 Zero-Knowledge Proofs based on sVOLE
Several recent works [7, 27, 52, 54] explored the efﬁciency
of sVOLE-based interactive ZK proofs. One can consider
authenticated values as a form of commitments on values
held by a prover P , which can be veriﬁed by the veriﬁer V .
Therefore, one can construct a ZK protocol following the
“commit-and-prove” paradigm as follows:
1. In a preprocessing phase, P and V execute the sVOLE
protocol to generate n + N uniform authenticated values,
where n is the witness size and N is the number of mul-
tiplication gates in the circuit. The parties also compute
1 ∈ Fqk by generating k
a uniform authenticated value A∗
uniform authenticated values in Fq and then using packing
1 ∈ Fqk and V
(see [54] for details). Thus, P obtains A∗
0,A∗
gets B∗ ∈ Fqk such that B∗ = A∗
0 + ∆· A∗
1.
2. Using the uniform authenticated values, P commits to
all the wire values in an evaluation of the circuit on its
witness. In particular, for each input wire of the circuit or
output wire of a multiplication gate with associated value
x ∈ Fq, P sends d = x− r ∈ Fq to V and then both parties
compute [x] := [r] +d, where [r] is a random authenticated
value computed in the previous step. Due to the additively
homomorphic property of the underlying authenticated
values, the parties can process addition gates for free and
so this allows P and V to compute authenticated values
on every wire in the circuit.