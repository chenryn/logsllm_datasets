start of the regex, we need to make sure that the regex will still match only the fields
that we want. For our web logs, this is not a big issue. Most of the fields have unique
content, and our regular expression is sufficiently detailed. Our regular expression ex-
plicitly requires enclosing brackets and quotes for the entries that have them, allows
only numbers for numeric fields, matches fixed text such as *HTTP" exactly, and so
on. Had we been lazy and used \5+) to match all of the fields, then we would not be
able to efficiently shorten the regex any further, as ^5+ matches pretty much anything.
We also need to make sure the regular expression remains efficient. The caret at the
start of the regex makes sure that the regex is attempted only at the start of each line.
If it fails to match a line, because the status code is not 404 or the referrer is on another
domain, the regex immediately skips ahead to the next line in the log. If we were to cut
off everything before the [^"]+)?> group, our regex would begin with
[^*]+3. The regex engine would go through its matching process at every character
in the whole log file that is not a space or a double quote. That would make the regex
very slow on large log files.
A good point to trim this regex is before [A-Z]+). To further enhance
efficiency, we also spell out the two request methods we're interested in:
“(?GET|POST)(?[^”]+)?HTTP/[0-9. ］+”(?404) 
*(?[0-9]+1-)=*(?http://mw^ -yoursite^ com[^*]*)”
Regexoptions: ~ and $ match at line breaks
Regexflaver: .NET, Java 7, XRegExp, PCRE 7, Perl 5.10, Ruby 1.9
This regular expression begins with literal double quotes. Regular expressions that
begin with literal text tend to be very efficient because regular expression engines are
usually optimized for this case. Each entry in our log has six double-quote characters.
Thus the regular expression will be attempted only six times on each log entry that is
not a 404 error. Five times out of six, the attempt will fail almost immediately when
GET |posT> fails to match right after the double quote. Though six match attempts per
line may seem less efficient than one match attempt, immediately failing with GET|
POST> is quicker than having to match 5+)=^5+*(?\5+)=\[(?
[^\]]+)\]),
The last optimization is to eliminate the capturing groups that we do not use. Some
can be removed completely. The ones containing an alternation operator can be re-
placed with noncapturing groups. This gives us the regular expression presented in the
"Solution? section.
We left the “filea and *referrer” capturing groups in the final regular expression. When
using this regular expression in a text editor or grep tool that can collect the text
matched by capturing groups in a regular expression, you can set your tool to collect
just the text matched by the *file” and *referrer” groups. That will give you a list of
broken links and the pages on which they occur, without any unnecessary information.
7.14 Broken Links Reported in Web Logs I 433
---
## Page 450
SeeAlso
Recipe 7.12 explains how to match web log entries with a regular expression. It also
in this recipe.
has references to Chapter 2 where you can find explanations of the regex syntax used
434 I Chapter 7: Source Code and Log Fles
---
## Page 451
CHAPTER8
URLs,Paths,andInternetAddresses
Along with numbers, which were the subject of the previous chapter, another major
subject that concerns a wide range of programs is the various paths and locators for
finding data:
•URLs, URNs, and related srings
•Domain names
•IP addresses
• Microsoft Windows file and folder names
The URL format in paricular has proven so flexible and useful that it has been adopted
for a wide range of resources that have nothing to do with the World Wide Web. The
toolbox of parsing regular expressions in this chapter will thus prove valuable in a
surprising variery of situations.
8.1Validating URLs
Problem
You want to check whether a given piece of text is a URI that is valid for your purposes.
Solution
Allow almost any URL:
^(https?|ftp|file):// .+$
Regexoptions: Case insensitive
Regexflavers: .NET, Java, JavaScript, PCRE, Perl, Python
\A(https?|ftp|fi1e) :// .+\Z
Regex options: Case insensitive
Regexflavers: .NET, Java, PCRE, Perl, Python, Ruby
Require a domain name, and don’t allow a username or password:
435
---
## Page 452
LA
# Anchor
(https?|ftp)://
# Schene
[a-z0-9-]+(\- [a-20-9- ]+)+ # Domain
(*[/])
# Path and/or paraneters
Z
 Anchor
Regex options: Free-spacing, case insensitive
Regexflavers: .NET, Java, PCRE, Perl, Python, Ruby
^(https?|ftp)://[a-20-9-]+(\-[a-z0-9-]+)+
$(+[/])
Regex options: Case insensitive
Regexflavers: .NET, Java, JavaScript, PCRE, Perl, Python, Ruby
Require a domain name, and don’t allow a username or password. Allow the scheme
(http or ftp) to be omitted if it can be inferred from the subdomain (www or ftp):
\A
# Anchor
((https?|ftp)://1(awx|ftp)\.) # Scheme or subdomain
[a-z0-9-]+(\- [a-20-9- ]+)+
# Domain
(*[/])
# Path and/or parameters
3
# Anchor
Regex options: Free-spacing, case insensitive
Regexflaver: .NET, Java, PCRE, Perl, Python, Ruby
^((https?|ftp)://1(w|ftp)\-)[a-z0-9- ]+(\-[a-20-9-]+)+([/?] *)?$
Regex options: Case insensitive
Regexflavers: .NET, Java, JavaScript, PCRE, Perl, Python
Require a domain name and a path that points to an image file. Don’t allow a username,
password, or parameters:
LA
# Anchor
(https?|ftp)://
# Schene
[a-20-9-]+(\- [a-20-9- ]+)+
# Domain
(/[\w-]+)*
# Path
/[ ]+\-(gif|pnglJpg)
 Anchor
# File
Z
Regex options: Free-spacing, case insensitive
Regexflavers: .NET, Java, PCRE, Perl, Python, Ruby
^(https?|ftp)://[az0-9-]+(\-[az0-9-]+)+(/[\]+)*/[ and \Z> instead (Recipe 2.5). Strictly speaking, you’d have to make the same
change for Ruby for all the other regular expressions shown in this recipe. You should..
if your input could consist of multiple lines and you want to avoid matching a URL
that takes up one line in several lines of text.
The next two regular expressions are the free-spacing (Recipe 2.18) and regular versions
of the same regex. The free-spacing regex is easier to read, whereas the regular version
is faster to type. JavaScript does not support free-spacing regular expressions.
These two regexes accept only web and FTP URLs, and require the HTTP or FTP
scheme to be followed by something that loks like a valid domain name. The domain
name must be in ASCIl. Internationalized domains (IDNs) are not accepted. The do-
main can be followed by a path or a list of parameters, separated from the domain with
a forward slash or a question mark. Since the question mark is inside a character class
(Recipe 2.3), we don’t need to escape it. The question mark is an ordinary character in
character classes, and the forward slash is an ordinary character anywhere in a regular
expression If you see it escaped in source code, that's because Per and several other
programming languages use forward slashes to delimit literal regular expressons.)
No attempt is made tovalidate the path or the parameters. *> simply matches anything
that doesn’t include line breaks. Since the path and parameters are both optional,
8.1 Validating URLs I 437
---
## Page 454
[/?],*> is placed inside a group that is made optional with a question mark
(Recipe 2.12).
These regular expressions, and the ones that follow, don’t allow a usermame or pass-
word to be specified as part of the URL. Putting user information in a URL is considered
bad practice for security reasons.
Most web browsers accept URLs that don’t specify the scheme, and correctly infer the
scheme from the domain name. For example, w.regexbuddy .con is short for http:/
ww.regexbuddy .com. To allow such URLs, we simply expand the list of schemes allowed
by the regular expression to include the subdomains wsw. and ftp.
(https?|ftp) ://| (a|ftp)\> does this nicely. This list has rwo altermatives, each of
which starts with rwo altermatives. The first alternative allows chttps?> and ftp>, which
must be followed by . The second alternative allows swmw> and ftp), which must
be followed by a dot. You can easily edit both lists to change the schemes and subdo-
mains the regex should accept.
The last two regular expressions require a scheme, an ASClI domain name, a path, and
a filename to a GIF, PNG, or JPEG image file. The path and filename allow all letters
and digits in any script, as well as underscores and hyphens. The shorthand character
class , which includes all characters that are not whitespace.
Though the regex specifies the “case insensitive” option, the S must be uppercase,
because \5> is not the same as s. In fact, they’re exactly the opposite. Recipe 2.3 has
all the details.
The first regular expression is still quite crude. It will include the comma in the example
text into the URL. Though it's not uncommon for URLs to include commas and other
punctuation, punctuation rarely occurs at the end of the URL.
The next regular expression uses rwo character classes instead of the single shorthand
5. The first character class includes more punctuation than the second. The second
8.2 Finding URLs Within Full Text I 439
---
## Page 456
class excludes those characters that are likely toappear as English language punctuation
right after a URL when the URL is placed into an English sentence. The first character
class has the asterisk quantifier (Recipe 2.12), to allow URLs of any length. The second
character class has no quantifier, requiring the URL to end with one character from
that class. The character classes don’t include the lowercase letters; the αcase
insensitive² option takes care of those. See Recipe 3.4 to leam how to set such options
 in your programming language.
The second regex will work incorrectly with certain URLs that use odd punctuation,
matching those URL.s only partially. But this regex does solve the very common problem
of a comma or full stop right after a URL, while still allowing commas and dots within
the URL.
Most web browsers accept URLs that don’t specify the scheme, and correctly infe the
scheme from the domain name. For example, wu.regexbuddy.con is short for http://
ww.regexbuddy.com. To allow such URLs, the final regex expands the list of allowed
schemes to include the subdomains wsu. and ftp.
 does this nicely. This list has rwo altermatives, each of
which starts with rwo altermatives. The first alternative allows chttps?> and ftp, which
must be followed by . The second alternative allows wuw) and ftpo, which must
be followed by a dot. You can easily edit both lists to change the schemes and
subdomains the regex should accept.
See Also
Techniques used in the regular expressions in this recipe are discussed in Chapter 2.
Recipe 2.8 explains alternation. Recipe 2.9 explains grouping. Recipe 2.12 explains
Recipe 2.3 explains character classes. Recipe 2.6 explains word boundaries.
repetition.
Recipe 8.5 gives a replacement text that you can use in combination with this regular
expression to create a search-and-replace that converts URLs into HTML anchors.
8.3FindingQuotedURLsinFullText
Problem
You want to find URLs in a larger body of text. URLs may or may not be enclosed in
punctuation that is part of the larger body of text rather than part of the URL. You want
podxa ueo Aau1 os *sxueu uogenonb uaamaq sT8 aoed on uodo aqp siasn aar8 o1
indicate whether punctuation, or even spaces, should be part of the URL.
Solution
\b(?: (?:https?|ftp|fi1e) :// 1(w|ftp)\ -)[-A-Z0-9+&@#/%?=~_1$!:, ;J*
[-A-Z0-9+&e#/%=~_T$]
440 | Chapter 8: URLs, Paths, and Intemet Adreses
---
## Page 457
1°(?:(?:https?|ftp|file) :// 1(ww|ftp)\.)[^*\r\n]+"
1′ (?: (?:https?|ftp|file) :// |(ww|ftp)\ -)[^′\r^n]+
Regex ptions: Free-spacing, case insensitive, dot matches line breaks, anchors
march at line breaks
Regexflavers: .NET, Java, JavaScript, PCRE, Perl, Python, Ruby
Discussion
The previous recipe explains the issue of mixing URLs with English text, and how to
differentiate between English punctuation and URL characters. Though the solution
to the previous recipe is a very useful one that gets it right most of the time, no regex
will get it right all of the time.
If yourregex willbe used on text to be written in the future, you can provide a way for