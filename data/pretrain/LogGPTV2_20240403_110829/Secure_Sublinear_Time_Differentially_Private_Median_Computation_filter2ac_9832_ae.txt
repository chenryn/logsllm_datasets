computation. To analyze the security of the entire protocol
we rely on the well-known composition theorem [24, Section
7.3.1]. Basically, a secure protocol that uses an ideal function-
ality (a subroutine provided by a trusted third party) remains
secure if the ideal functionality is replaced with a secure
computation implementing the same functionality. We consider
PRUNE-neighboring data sets (Deﬁnition 3), i.e., neighboring
data sets with the same pruning result.
Theorem 4 (Security). Our protocol securely implements the
ideal functionality of differentially private median selection
via the steps PRUNE, MERGEANDSHARE, SELECTIONPROB-
ABILITY and MEDIANSELECTION in the semi-honest model.
•
Proof: We use the composition theorem to analyze the
security of our protocol: We deﬁne required ideal functionali-
ties, show how they map to our garbled circuit implementation
(steps (I), (II), (IV)), and how it combines with secret sharing
(step (III)). Aggarwal et al. [1] developed the input pruning
we utilize and give a simulation-based security proof only
using comparisons as ideal functionality. PRUNE, a partial
execution of [1], allows the same simulation argument (see
Appendix G). Note that these comparisons leak nothing about
PRUNE-neighboring data sets. For the interactive computation
we require the following ideal functionalities:
c ← SECURECOMPAREideal(mA; mB).
In step (I) the ideal functionality on input mA, mB,
i.e., median from A, B respectively, outputs the result
of comparison mA 
100 INDICATES NONE
WERE FOUND FOR UP TO 100 CHANGES.
DB
DA
Wages [51]
Transactions [54]
Times [54]
Payments [11]
Weights [33]
Quantities [33]
>
Wages
[51]
100 | 18
65 | 65
100 | 22
28 | 28
100 | 43
30 | 30
>
>
>
Trans-
actions
[54]
100 | 14
8 | 8
33 | 18
100 | 11
34 | 33
100 | 25
>
>
>
Times
[54]
12 | 12
100 | 20
6
100 | >
100
4
100 | 12
6 |
4 |
>
>
Pay-
ments
[11]
22 | 22
37 | 30
100 | 13
6 | 6
33 | 33
100 | 9
>
>
>
Weights
[33]
100 | 12
36 | 36
100 | 21
100 | 41
100 | 21
14 | 14
>
>
>
Quan-
tities
[33]
46 | 21
23 | 23
25 | 25
100 | 13
48 | 19
14 | 14
>
where all nodes have the same output of the PRUNE-function.
The result of the PRUNE steps in our protocol determines the
connected component the other party’s database is DP in. In
that sense DP with PRUNE-neighboring cannot be violated by
any adversary. Any choice of inputs by party A will lead to
one (but different) connected component for the DP of B’s
database, i.e., B’s database will always remain differentially
private. We empirically showed that PRUNE-neighboring is
not too restrictive, i.e., it does not remove too many edges
and make the resulting connected component too small. We
sampled edges from the neighboring graph resulting from the
common deﬁnition on real-world data sets [11, 33, 51, 54]
using the following method: Given a real-world database for
B, an element to be added or removed chosen by A (note
that A must choose before knowing the result), and a step in
the protocol does there exist any neighbor for B’s database
that is excluded by the PRUNE-neighboring deﬁnition. For
up to 16 consecutive pruning steps (the maximum according
to Theorem 3 for our highest evaluated parameters  = 2,
and accuracy of 0.9999), we found none. Given that
the
connectivity in the neighboring graph is high, this implies that
the connected component is expected to remain large.
Group privacy extends the neighboring deﬁnition from in-
cluding (or excluding) a single value to multiple values. There-
fore, to quantify group privacy we consider multiple changes
and provide a worst-case analysis for PRUNE-neighboring:
Table II shows the minimum changes required to produce a
neighbor that is not also a PRUNE-neighbor9. We evaluated