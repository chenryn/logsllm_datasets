only appears once in the library libdbus, or the CD whose IA is hard
to comprehend and translate, e.g., â€œif it wants to be able to provide
clients with OCSP Certificate Status responsesâ€. One possible direction
to further automate this step is to customize existing automatic
programming techniques [28, 39] to construct the VC for a rare CD
based upon its smaller syntactic units such as â€œarray-typed valueâ€.
Also we found that there is similarity between some rare CDs and
popular ones, in terms of their semantics, which could allow us to
morph existing VCs for checking these CDs. Such directions will
be pursued in our follow-up research.
7 Related Work
Recent years have witnessed numerous studies leveraging text anal-
ysis techniques to automatically discover various kinds of bugs,
including access control misconfiguration, inappropriate permis-
sion request, logic flaws, etc. For example, Zimmeck et al. [55] check
the compliance between Android App and privacy requirement.
WHYPER [43] and AutoCog [45] investigate whether an Android
app properly indicates its permission usage in its app description.
Tan et al. [47] extract implicit program rules from comments, then
use these rules to automatically detect inconsistencies between
comments and source code. Goffi et al. [27] and Blasi et al. [22] gen-
erate the test oracle from documentation to dynamically find the
inconsistency between documentation and code implementation.
Zhong et al. [54] and Pandita et al [42] extract API call sequence
6The CodeQL grammars is shown in https://help.semmle.com/QL/learn-ql/.
information from the documentation to check the inconsistency.
Different from previous works, our research provides an end-to-end
approach to enable detection of security-critical API misuse from
real-world applications.
Considering the approach to discover IAs, previous works mainly
utilized the approaches based on keywords [47] or template match-
ing [44]. For instance, Tan et al. [47] utilize a series of pre-defined
keywords, such as â€œshouldâ€, â€œmustâ€ and so on to extract IAs, which,
however, results in a relatively high false-negative rate. Pandita
et al. [44] and Chen et al. [23] define shallow parsing templates
such as â€œ(VB) (.)? (PRN)?â€ or regex template such as â€œCheck the
seller_id represents the supposed merchant.â€, respectively, for IA ex-
traction. In contrast to previous works, in our research, we propose
a corpora-insensitive and an efficient IA discovery method based
on the bidirectional GRU model with attention.
Another set of studies close to our work is automatic API misuse
detection through static or dynamic program analysis. For example,
to uncover API specifications, Mithun et al. [21], Kang et al. [30] and
Li et al. [36] leverage manually crafted rules to statically find API
error-handling blocks (EHBs) which contains the error handling
code. Hoan et al. [41] collect the execution paths leading to API
calls and then derive potential preconditions for such invocations.
Yun et al. [52] generate the symbolic context with relaxed symbolic
execution and explore four common API context patterns based on
that symbolic context. Maria et al. [31] combine static exception
propagation analysis with automatic search-based test case gener-
ation to pinpoint crash-prone API misuses in client applications.
Considering dynamic analysis for API misuse detection, Wen et
al. [50] discover API misuse patterns via mutation analysis. Differ-
ent from Advance, these methods heavily rely on the code set to
infer IAs and utilize manually-crafted rules to capture API misuses,
so a low quality code set will cause misuse cases to fall through the
cracks.
8 Conclusion
In this paper, we present a new technique to automatically detect
API misuses in applications based on analysis of library documen-
tation. Leveraging recent progress in machine learning and NLP,
our approach utilizes sentiment analysis to discover the integra-
tion assumptions from documentations, tree mining to identify
commonly-used CDs and lexical and semantic analysis to resolve
implicit references. Running our prototype on the documentations
of five libraries and 39 real-world applications integrating these
libraries, Advance successfully detected 193 API misuses, with 139
never reported before, outperforming all existing approaches. This
study demonstrates that new advancement in intelligent technolo-
gies can indeed move security science forward, even on the hard
problems long been studied, like API misuse detection.
Acknowledgments
IIE authors are supported in part by Beijing Natural Science Foun-
dation (No.JQ18011), NSFC U1836211, National Top-notch Youth
Talents Program of China, Youth Innovation Promotion Associa-
tion CAS, Beijing Nova Program, National Frontier Science and
Technology Innovation Project (No. YJKYYQ20170070), and Beijing
Academy of Artificial Intelligence (BAAI).
References
[1] 2016. stanfordParser. https://nlp.stanford.edu/software/dependencies_manual.
pdf. (2016).
[2] 2020. AFL fuzzer. https://lcamtuf.coredump.cx/afl/. (2020).
[3] 2020. Atril for MATE. https://mate-desktop.org/. (2020).
[4] 2020. CodeQL. https://securitylab.github.com/tools/codeql. (2020).
[5] 2020.
(2020).
confirmed bug. https://gitlab.gnome.org/GNOME/anjuta/-/issues/12.
[6] 2020. confirmed bug. https://gitlab.kitware.com/vtk/vtk/issues/17818. (2020).
[7] 2020. confirmed bug. https://bz.apache.org/bugzilla/show_bug.cgi?id=64264.
[8] 2020. confirmed bug. https://github.com/hughsie/colord/issues/110. (2020).
[9] 2020. confirmed bug. https://github.com/darktable-org/darktable/issues/6051.
(2020).
(2020).
(2020).
[10] 2020. confirmed bug. https://github.com/mate-desktop/atril/issues/485. (2020).
[11] 2020. confirmed bug. https://gitlab.gnome.org/GNOME/at-spi2-core/-/issues/24.
[12] 2020. CVE-2015-8867. https://nvd.nist.gov/vuln/detail/CVE-2015-8867. (2020).
[13] 2020. github. https://github.com/. (2020).
[14] 2020. gitlab. https://about.gitlab.com/. (2020).
[15] 2020. Google translation. https://translate.google.cn. (2020).
[16] 2020. lxml. https://lxml.de/. (2020).
[17] 2020. man3. https://linux.die.net/man/3/. (2020).
[18] 2020. National Vulnerability Datase. https://nvd.nist.gov/vuln/search. (2020).
[19] 2020. sourceforge. https://sourceforge.net/. (2020).
[20] 2020. ubuntu. https://packages.ubuntu.com/en/xenial/libs/. (2020).
[21] Mithun Acharya and Tao Xie. 2009. Mining API error-handling specifications
from source code. In International Conference on Fundamental Approaches to
Software Engineering. Springer, 370â€“384.
[22] Arianna Blasi, Alberto Goffi, Konstantin Kuznetsov, Alessandra Gorla, Michael D
Ernst, Mauro PezzÃ¨, and Sergio Delgado Castellanos. 2018. Translating code
comments to procedure specifications. In Proceedings of the 27th ACM SIGSOFT
International Symposium on Software Testing and Analysis. ACM, 242â€“253.
[23] Yi Chen, Luyi Xing, Yue Qin, Xiaojing Liao, XiaoFeng Wang, Kai Chen, and Wei
Zou. 2019. Devils in the guidance: predicting logic vulnerabilities in payment syn-
dication services through automated documentation analysis. In 28th {USENIX}
Security Symposium ({USENIX} Security 19). 747â€“764.
[24] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Y. Bengio. 2014. Em-
pirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.
(12 2014).
[25] Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018. Understanding
Back-Translation at Scale. (08 2018).
[26] Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi,
Nelson F. Liu, Matthew Peters, Michael Schmitz, and Luke S. Zettlemoyer.
2017. AllenNLP: A Deep Semantic Natural Language Processing Platform.
arXiv:arXiv:1803.07640
[27] Alberto Goffi, Alessandra Gorla, Michael D Ernst, and Mauro PezzÃ¨. 2016. Au-
tomatic generation of oracles for exceptional behaviors. In Proceedings of the
25th International Symposium on Software Testing and Analysis. 213â€“224.
[28] Sumit Gulwani, Oleksandr Polozov, Rishabh Singh, et al. 2017. Program synthesis.
Foundations and TrendsÂ® in Programming Languages 4, 1-2 (2017), 1â€“119.
[29] huggingface. 2020. neuralcoref. https://github.com/huggingface/neuralcoref.
[30] Yuan Kang, Baishakhi Ray, and Suman Jana. 2016. APEx: Automated Inference
of Error Specifications for C APIs. In 31st IEEE/ACM International Conference
on Automated Software Engineering (ASE). Singapore.
[31] Maria Kechagia, Xavier Devroey, Annibale Panichella, Georgios Gousios, and
Arie van Deursen. 2019. Effective and efficient API misuse detection via exception
propagation and search-based testing. In Proceedings of the 28th ACM SIGSOFT
International Symposium on Software Testing and Analysis. 192â€“203.
[32] Yoon Kim. 2014. Convolutional neural networks for sentence classification. arXiv
preprint arXiv:1408.5882 (2014).
[33] George Klees, Andrew Ruef, Benji Cooper, Shiyi Wei, and Michael Hicks. 2018.
Evaluating fuzz testing. In Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security. 2123â€“2138.
[34] Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Recurrent convolutional
neural networks for text classification. In Twenty-ninth AAAI conference on
artificial intelligence.
[35] Chi Li, Zuxing Gu, Min Zhou, Jiecheng Wu, Jiarui Zhang, and Ming Gu. 2019. API
Misuse Detection in C Programs: Practice on SSL APIs. International Journal of
Software Engineering and Knowledge Engineering 29, 11&12 (2019), 1761â€“1779.
https://doi.org/10.1142/S0218194019400205
[36] Chi Li, Min Zhou, Zuxing Gu, Ming Gu, and Hongyu Zhang. 2019. Ares: inferring
error specifications through static analysis. In 2019 34th IEEE/ACM International
Conference on Automated Software Engineering (ASE). IEEE, 1174â€“1177.
[37] Zhenmin Li and Yuanyuan Zhou. 2005. PR-Miner: automatically extracting
implicit programming rules and detecting violations in large software code. In
(2020).
(2018).
Proceedings of the 10th European Software Engineering Conference held jointly
with 13th ACM SIGSOFT International Symposium on Foundations of Software
Engineering, 2005, Lisbon, Portugal, September 5-9, 2005, Michel Wermelinger
and Harald C. Gall (Eds.). ACM, 306â€“315. https://doi.org/10.1145/1081706.1081755
[38] Lynten. 2018. stanfordcorenlp. https://github.com/Lynten/stanford-corenlp.
[39] Afsaneh Mahanipour and Hossein Nezamabadi-Pour. 2019. GSP: an automatic pro-
gramming technique with gravitational search algorithm. Applied Intelligence
49, 4 (2019), 1502â€“1516.
[40] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111â€“3119.
[41] Hoan Anh Nguyen, Robert Dyer, Tien N Nguyen, and Hridesh Rajan. 2014.
Mining preconditions of APIs in large-scale code corpus. In Proceedings of
the 22nd ACM SIGSOFT International Symposium on Foundations of Software
Engineering. 166â€“177.
[42] Rahul Pandita, Kunal Taneja, Laurie A. Williams, and Teresa Tung. 2016. ICON:
Inferring Temporal Constraints from Natural Language API Descriptions. 2016
IEEE International Conference on Software Maintenance and Evolution (ICSME)
(2016), 378â€“388.
[43] Rahul Pandita, Xusheng Xiao, Wei Yang, William Enck, and Tao Xie. 2013. WHY-
PER: Towards Automating Risk Assessment of Mobile Applications. In 22nd
USENIX Security Symposium (USENIX Security 13). USENIX Association, Wash-
ington, D.C., 527â€“542. https://www.usenix.org/conference/usenixsecurity13/
technical-sessions/presentation/pandita
[44] Rahul Pandita, Xusheng Xiao, Hao Zhong, Tao Xie, Stephen Oney, and Amit
Paradkar. 2012.
Inferring method specifications from natural language API
descriptions. In 2012 34th International Conference on Software Engineering
(ICSE). IEEE, 815â€“825.
[45] Zhengyang Qu, Vaibhav Rastogi, Xinyi Zhang, Yan Chen, Tiantian Zhu, and
Zhong Chen. 2014. Autocog: Measuring the description-to-permission fidelity in
android applications. In Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security. 1354â€“1365.
[46] Fei Sha and Fernando Pereira. 2003. Shallow Parsing with Conditional Random
Fields. In Proceedings of the 2003 Human Language Technology Conference of
the North American Chapter of the Association for Computational Linguistics.
213â€“220. https://www.aclweb.org/anthology/N03-1028
[47] Lin Tan, Ding Yuan, Gopal Krishna, and Yuanyuan Zhou. 2007. /* iComment:
Bugs or bad comments?*. In ACM SIGOPS Operating Systems Review, Vol. 41.
ACM, 145â€“158.
[48] Shin Hwei Tan, Darko Marinov, Lin Tan, and Gary T Leavens. 2012. @ tcomment:
Testing javadoc comments to detect comment-code inconsistencies. In 2012 IEEE
Fifth International Conference on Software Testing, Verification and Validation.
IEEE, 260â€“269.
[49] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Å ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All
you Need. In Advances in Neural Information Processing Systems 30, I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Gar-
nett (Eds.). Curran Associates, Inc., 5998â€“6008. http://papers.nips.cc/paper/7181-
attention-is-all-you-need.pdf
[50] Ming Wen, Yepang Liu, Rongxin Wu, Xuan Xie, Shing-Chi Cheung, and Zhendong
Su. 2019. Exposing library API misuses via mutation analysis. In 2019 IEEE/ACM
41st International Conference on Software Engineering (ICSE). IEEE, 866â€“877.
[51] Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, and Eduard Hovy.
2016. Hierarchical attention networks for document classification. In Proceedings
of the 2016 conference of the North American chapter of the association for
computational linguistics: human language technologies. 1480â€“1489.
[52] Insu Yun, Changwoo Min, Xujie Si, Yeongjin Jang, Taesoo Kim, and Mayur Naik.
2016. APISan: Sanitizing API Usages through Semantic Cross-Checking. In 25th
USENIX Security Symposium, USENIX Security 16, Austin, TX, USA, August
10-12, 2016, Thorsten Holz and Stefan Savage (Eds.). USENIX Association, 363â€“
378. https://www.usenix.org/conference/usenixsecurity16/technical-sessions/
presentation/yun
[53] Mohammed Javeed Zaki. 2005. Efficiently mining frequent trees in a forest: Algo-
rithms and applications. IEEE transactions on knowledge and data engineering
17, 8 (2005), 1021â€“1035.
[54] Hao Zhong, Lu Zhang, Tao Xie, and Hong Mei. 2009. Inferring resource specifica-
tions from natural language API documentation. In 2009 IEEE/ACM International
Conference on Automated Software Engineering. IEEE, 307â€“318.
[55] Sebastian Zimmeck, Ziqi Wang, Lieyong Zou, Roger Iyengar, Bin Liu, Florian
Schaub, Shomir Wilson, Norman Sadeh, Steven M. Bellovin, and Joel Reidenberg.
2017. Automated Analysis of Privacy Requirements for Mobile Apps. Korea
Society of Internet Information, Korea, Republic of. https://doi.org/10.14722/
ndss.2017.23034
[56] Radim Å˜ehÅ¯Å™ek. 2019. gensim. https://radimrehurek.com/gensim/. (2019).
==167813== ERROR : AddressSanitizer : SEGV on unknown address 0
x000000000018 ( pc 0 x7f92a84b1b31 bp 0 x7ffdba993ba0 sp 0
x7ffdba993b50 T0 )
==167813== The signal is caused by a READ memory access .
==167813== Hint : address points to the zero page .
#0 0 x7f92a84b1b30 in epub_document_check_hits / atril / backend / epub
/ epub - document .c :186
#1 0 x7f92fa1418a6 in ev_document_find_check_for_hits / atril /
libdocument /ev - document - find .c :59
#2 0 x7f92fa085698 in ev_job_find_run / atril / libview /ev - jobs .c
:1378
#3 0 x7f92fa07f7ef in ev_job_run / atril / libview /ev - jobs .c :192
#4 0 x7f92fa087a86 in ev_job_idle / atril / libview /ev - job - scheduler .
c :199
#5 0 x7f92f92e9dfd in g_main_context_dispatch (/ lib / x86_64 - linux -
gnu / libglib -2.0. so .0+0 x4fdfd )
#6 0 x7f92f92ea1af
(/ lib / x86_64 - linux - gnu / libglib -2.0. so .0+0
x501af )
#7 0 x7f92f92ea23e in g_main_context_iteration (/ lib / x86_64 - linux -
gnu / libglib -2.0. so .0+0 x5023e )
#8 0 x7f92f94f624c in g_application_run (/ lib / x86_64 - linux - gnu /
libgio -2.0. so .0+0 xd924c )
#9 0 x556d3653a419 in main / atril / shell / main .c :287
#10 0 x7f92f8f9abba in __libc_start_main ../ csu / libc - start .c :308
#11 0 x556d364e1349 in _start (/ usr / local / bin / atril +0 x3a349 )
SUMMARY : AddressSanitizer : SEGV / atril / backend / epub / epub - document .
c :186 in epub_document_check_hits
==167813== ABORTING
Listing 5: Sanitizer information of the case study.
9 Appendix
Figure 7: Bidirectional GRU model with Attention
Algorithm 1 Traverse the CD tree
Input: ğ¶ğ·_ğ‘¡ğ‘Ÿğ‘’ğ‘’
Output: ğ‘‰ğ¶
1: while ğ‘”ğ‘’ğ‘¡_ğ‘›ğ‘œğ‘‘ğ‘’ğ‘ (ğ¶ğ·_ğ‘¡ğ‘Ÿğ‘’ğ‘’) > 2 do
2:
3:
4:
5:
6:
7: end while
8: ğ‘‰ğ¶ â† ğ¶ğ·_ğ‘¡ğ‘Ÿğ‘’ğ‘’.ğ‘Ÿğ‘œğ‘œğ‘¡()
ğ‘™ğ‘’ğ‘ğ‘“ â† ğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡_ğ‘™ğ‘’ğ‘ğ‘“ (ğ¶ğ·_ğ‘¡ğ‘Ÿğ‘’ğ‘’)
ğ‘ ğ‘–ğ‘ğ‘™ğ‘–ğ‘›ğ‘”ğ‘  â† ğ‘”ğ‘’ğ‘¡_ğ‘ ğ‘–ğ‘ğ‘™ğ‘–ğ‘›ğ‘”ğ‘ (ğ‘™ğ‘’ğ‘ğ‘“ )
ğ‘ğ‘ğ‘Ÿğ‘’ğ‘›ğ‘¡ â† ğ‘”ğ‘’ğ‘¡_ğ‘ğ‘ğ‘Ÿğ‘’ğ‘›ğ‘¡(ğ‘™ğ‘’ğ‘ğ‘“ )
ğ‘›ğ‘’ğ‘¤_ğ‘›ğ‘œğ‘‘ğ‘’ â† ğ‘”ğ‘’ğ‘›_ğ‘›ğ‘œğ‘‘ğ‘’(ğ‘ ğ‘–ğ‘ğ‘™ğ‘–ğ‘›ğ‘”ğ‘ , ğ‘™ğ‘’ğ‘ğ‘“ , ğ‘ğ‘ğ‘Ÿğ‘’ğ‘›ğ‘¡)
ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘ğ‘ğ‘’(ğ¶ğ·_ğ‘¡ğ‘Ÿğ‘’ğ‘’, ğ‘ğ‘ğ‘Ÿğ‘’ğ‘›ğ‘¡, ğ‘›ğ‘’ğ‘¤_ğ‘›ğ‘œğ‘‘ğ‘’)
Table 3: Dependent tools and SLoC of each component in
Advance
Dependent tools
SLoC
3K
1K
1K
Components
IA discovery
IA derefence
VC generation
Gensim, Stanford-NLP, Keras
Gensim, Stanford-NLP, NLTK
Allennlp, CodeQL
1 ptr = xmlGetProp (...) ;
2 list = g_list_append ( list , ptr );
3 for ( iter = g_list_first ( list ); iter != NULL ; iter =
4
g_list_next ( iter ))
g_free ( iter -> data );
Listing 3: An example of false positives
1 import cpp , nullCheck
2 from FunctionCall fc
3 where fc . getTarget () . hasName (" xmlDocGetRootElement ")
4
5 select fc . getLocation ()
and not nullcheck ( fc )
Listing 4: Verification code
â„1â„1â„2â„2â„ğ‘‡ğ‘‡â„ğ‘‡ğ‘‡ğ‘¤ğ‘¤1ğ‘¤ğ‘¤2ğ‘¤ğ‘¤ğ‘‡ğ‘‡softmaxğ‘¢ğ‘¢1ğ‘¢ğ‘¢2ğ‘¢ğ‘¢ğ‘‡ğ‘‡ğ‘£ğ‘£softmaxAttentionEncoderğ›¼ğ›¼1ğ›¼ğ›¼2ğ›¼ğ›¼ğ‘‡ğ‘‡softmaxsoftmaxMLPâ€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦Table 4: List of manually-validated API misuses reported by Advance, including 139 undisclosed (labeled with "*" in the
Column "Advance") and 54 disclosed API misuses.
Advance APISAN APEx
AFL
0
0
0
0
0
0
0
0