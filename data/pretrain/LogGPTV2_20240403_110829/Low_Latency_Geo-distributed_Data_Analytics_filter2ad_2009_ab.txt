task collects latency values for a subset of user_id val-
ues and calculates the median per user.
We consider execution of the above query over three
sites; see Table 2a for input and intermediate data sizes
and bandwidths available at the sites. State-of-the-
art approaches to scheduling reduce tasks recommend
equal spreading of reduce tasks across sites (or racks
and machines) [19, 52]. Such an approach would re-
sult in one-third of the tasks on each of the three sites,
r = (0.33, 0.33, 0.33), resulting in a query response time
of 80s (Figure 2b and 2c). Each of the sites has data
traversing its up and down links, whose ﬁnish times (T U
i
and T D
i ) depend on their bandwidths. The transfer du-
ration is the maximum of all the link ﬁnish times, and
we colloquially refer to the slowest site as the bottleneck.
In this case the bottleneck is site-1 with a slow down-
link (1MB/s) which has to download 1/3 of intermediate
(a) Setup of three sites.
(b) When tasks are equally spread across the three sites,
2
3 of the data (Si) on each site is sent out (uplink), split
equally to the other two sites. The download at each site
(downlink) can, thus, be correspondingly summed up.
(c) Equal Spread
(d) Better Alternative
Figure 2: Intermediate Task Placement over 3 sites
(a), comparing equal spreading of tasks (b, c) and a
better alternative (d). Task fractions (ri) are shown
on the left y-axis in ((c) and (d)) while link ﬁnish
times (T D
i ) are on the right y-axis.
i or T U
data from sites 2 and 3, i.e., 120MB/3 + 120MB/3 =
80MB (Figure 2b).
A better alternative, covered in §3, distributes reduce
tasks with ratios r = (0.05, 0.475, 0.475) across the three
sites, reducing the query response time over ﬁve-fold to
14.25s, Figure 2d. The alternative, essentially, identi-
ﬁed site-1’s downlink to be the bottleneck link in Fig-
ure 2c, and hence moved tasks away from it to the other
sites. For brevity, we omit the corresponding illustra-
tion similar to Figure 2b on calculating link ﬁnish times.
We cannot improve the reduce task placement much
more, since site-1’s up and downlinks have approxi-
mately similar link ﬁnish times now. Increasing or de-
creasing r1 will increase T D
1 , respectively, and
thus increase response time. Thus, task placement needs
to carefully balance the up/down link usages of the sites.
WAN Usage: To minimize WAN usage [53, 54] we
need to collect the intermediate data (Si) from sites-2
and 3 into site-1 since site-1 already contains the most
intermediate data. This results in cross-site WAN us-
age of 240MB, but takes 240s (downlink D1 = 1MB/s).
In contrast, it can be calculated that the alternative
1 or T U
task placement we proposed results in 268.5MB of WAN
data usage; increase in WAN usage of just 12% reduces
query response time 17× (from 240s to 14.25s). Thus,
schemes minimizing WAN usage can be highly ineﬃ-
cient for query response time. This is because savings
in WAN usage accrue with each link on which we reduce
the amount of data transferred, whereas we reduce re-
sponse time only by optimizing the bottlenecked link.
In fact, task placements of both the policies—equal
spreading and minimizing WAN usage—could result in
arbitrarily large query response times. For example, as
S2 increases, response time of the equal-spread policy
increases linearly, while the optimal task placement will
place all reduce tasks in site-2 and keep the response
time constant. Similarly, as D1 gets smaller, e.g., when
D1 = 0.1MB/s, minimizing WAN usage requires 2400s,
while we achieve a response time of 15s by placing no
reduce tasks on site-1.
Input Data Placement
2.2.2
In §2.2.1, we assumed that the query inputs stayed
on the sites that they were initially generated/stored.
Since even the best task placements are limited by the
locations of the data, it may be beneﬁcial to move the
input data to diﬀerent sites before starting the query.3
For example, when input data was generated at time
a0 and query is submitted at time a1 (a1 > a0), we
can use this lag of (a1 − a0) to rearrange the input data
to reduce query response time. Even when a0 = a1
but intermediate data is larger than input data (α > 1,
Table 1), moving input data would be more eﬃcient
than moving the intermediate data. Recall that since
the input tasks write their outputs (intermediate data)
to the local site, any change in distribution of input
data carries over to the intermediate data.
Rearranging the input data, however, is non-trivial,
because as we change Si’s, we have to recompute the
optimal ri’s as well. Consider a query with input I =
(240, 120, 60)MB across three sites, α = 1, and a lag
of 24s between data generation and query arrival. As
before, we assume that IO and CPU operations of tasks
have zero duration and the WAN as the only bottleneck.
Figure 3a shows the data and bandwidths at the sites
along with query response time when data is left “in
place” (Figure 3b). Site-1’s uplink is the bottleneck link
whose link ﬁnish time is 21.6s.
A better input placement will move data out of the
bottlenecked site-1 in the available 24s, and Figure 3c
shows the beneﬁt of the best movement: from site-1 to
site-2. The moving is gated on site-1’s uplink (10MB/s)
moving 240MB of data in 24s. This new data distribu-
tion reduces the response time 4× from 21.6s to 5.4s.
The diﬀerent ri values between Figures 3b and 3c shows
that minimizing query response time indeed requires a
joint optimization over data and task placement.
3While we use the term “move” in describing our solution,
we in fact just replicate, i.e., create additional copies, §5.
Site-1Site-2Site-3Input Data (MB), I300240240IntermediateData (MB), S150120120Uplink (MB/s), U101010Downlink(MB/s), D11010111122223333222233332222333311113333111133331111222211112222S1=150S2=120S3=120(r1= 1/3)(r3=1/3)(r2= 1/3)00.20.40.60.81020406080100TiUTiDri(TDor TU)Task Fraction, ri(80)Site-1Site-2Site-300.20.40.60.81020406080100(14.25)TiUTiDriTask Fraction, riSite-1Site-2Site-3(TDor TU)(a) Setup of three sites.
(b) “In-place” Input Place-
ment
(c) Better Input Placement
Figure 3: Input Data Placement for (a). Comparison
of transfer durations when data is left in place (b)
with moving data from site-1 to site-2. The query
arrives with a lag of 24s after the data is available.
Intermediate data (Si) is shown on the left y-axis,
instead of ri in Figure 2. Link ﬁnish times (T D
i or
T U
i ) are on the right y-axis. The best ri’s for (b) and
(c) are (0.1, 0.45, 0.45) and (0, 0.85, 0.15).
In the presence of multiple datasets, an additional
challenge is determining which datasets to move. For
example, it is advantageous to move datasets with high
number of queries accessing them. As we will show in
§6, there is a two orders of magnitude variation in access
counts of datasets in Facebook’s production cluster.
2.3 Summary and Solution Overview
In summary, we illustrated a setup of WAN-connected
sites: a query’s dataset is spread across sites (where
they were originally generated), each site stores parts
of many datasets, and each dataset is accessed by mul-
tiple queries. Our goal is to minimize average query re-
sponse time while also being mindful of WAN usage. We
achieve this by, a) moving parts of datasets across sites
in the lag between data generation and query arrival,
and b) placing intermediate tasks during the query’s
execution. The intuition is to identify “bottleneck” sites
and balance the number of tasks and/or amount of data
on these sites.
Our solution Iridium is described next.
1. We solve the problem of task placement for a sin-
gle query (given a ﬁxed location of data) using an
eﬃcient linear formulation (§3).
2. We devise an eﬃcient heuristic to solve the prob-
lem of data placement (§4), that internally uses the
formulation developed in §3.
3. We incorporate a “knob” for budgeted WAN usage
in our data placement (§4.4).
For data and task placement, we ignore the (abun-
dant) CPU and memory resources at the sites.
3. TASK PLACEMENT
In this section, we describe how we place tasks of a
single query to minimize its response time given a ﬁxed
input data distribution. As we described in §2.1, input
tasks that load and ﬁlter the input data involve no cross-
site data movement. For such input tasks, data local-
ity [37, 58] and in-memory caching [17, 59] is suﬃcient
for eﬃcient execution; input tasks write their outputs
(intermediate data) locally on the site they run. Other
intermediate stages of the query, such as reduce and
join, communicate across the diﬀerent sites and require
careful task placement to minimize their duration.
As these tasks are data-intensive, i.e., their durations
are dominated by the times spent on communication,
our objective is to minimize the duration of the inter-
mediate data transfer. This problem can be solved ex-
actly and eﬃciently for the most common communica-
tion patterns on intermediate data—reduce or join [25].
We explain our solution for these two (§3.1 and §3.2)
before extending it to arbitrary DAGs (§3.3).
3.1 Placement of Reduce Tasks
the intermediate data at site i ((cid:80)
((cid:80)
Consider a map-reduce query across sites, where Si is
i Si = S). We decide
ri, the fraction of reduce tasks to place on each site i
i ri = 1) to minimize the longest link ﬁnish time.
For formulating the problem, we assume that the re-
duce tasks are inﬁnitesimally divisible. We also assume
that the intermediate data on site i, Si, is distributed
across the other sites proportionally to rj’s.
The main factors involved in the decision of ri’s are
the bandwidths of the uplinks (Ui) and downlinks (Di)
along with the size of intermediate data (Si) at the sites.
In the “all-to-all” shuﬄe communication, given the as-
sumptions above, each site i has to upload (1 − ri) frac-
tion of its data for a total of (1 − ri)Si, and download
ri fraction of data from all the other sites for a total of
ri(S − Si). Therefore, the time to upload data from site
i (ri) = (1−
i during the intermediate data transfer is T U
ri)Si/Ui, and time to download the data is T D
i (ri) =
ri(S − Si)/Di. Given our assumption of a congestion-
free core, the problem of reduce task placement can,
hence, be formulated as a linear program (LP). The LP
implicitly avoids bottlenecks; e.g., if a site has a lot of
data or links with low bandwidth, the placement avoids
sending too much data over the narrow link.
min z
s.t.
(cid:80)
∀i : ri ≥ 0
i ri = 1
∀i : T U
i (ri) ≤ z, T D
i (ri) ≤ z
The above formulation is highly eﬃcient and invoked
(repeatedly) for data placement in §4. Our implemen-
tation, described in §5, removes some of the above ap-
proximations and uses a more general (but less eﬃcient)
MIP for task placement.
Site-1Site-2Site-3Input Data (MB), I24012060IntermediateData (MB), S24012060Uplink (MB/s), U101010Downlink(MB/s), D1101001002003004000510152025TiUTiDSiIntermediate Data, S(21.6)Site-1Site-2Site-3(TDor TU)01002003004000510152025(5.4)TiUTiDSiSite-1Site-2Site-3Intermediate Data, S(TDor TU)3.2 Placement of Join Tasks
The above approach also extends to handle joins, e.g.,
a join of tables A and B on a common column M. There
are two join implementations: hash and broadcast, au-
tomatically chosen by query optimizers [3].
If both tables are large, they are joined using a hash
join which is executed as two all-to-all shuﬄes of both
tables (as in §3.1), followed by a pair-wise join operation
on data in the same key-range. To reduce the WAN
usage of the pair-wise join operation, reduce tasks of
the shuﬄe in both tables that are responsible for the
same key-range are scheduled on the same site. Thus,
for our purpose, we treat the whole join as a single all-
to-all shuﬄe and use the above LP with Si as the total
amount of data of tables A and B on site i.
If one of the tables is small, broadcast join will send
the smaller table to all sites storing any data of the
larger table. In the broadcast join, the amount of data
sent over WAN is both small and constant (size of the
small table). Placement of tasks does not impact join
completion time.
3.3 DAGs of Tasks
While task placement for a single intermediate data
transfer can be solved using an LP, doing so for general
DAGs is a much more challenging problem. For exam-
ple, placement of tasks for a query with two consecutive
intermediate data transfers results in a non-convex op-
timization (unlike the linear one above).
As a result, Iridium adopts a greedy approach of apply-
ing the task placement LP independently in each stage
of the query. Starting with the top-level stages, it ap-
plies the LP in topological order, which ensures that
when placing tasks of a stage, the tasks of their parents
have already been placed. While this approach is not
optimal, in queries with many stages in sequence, the
amount of data processed by each stage typically drops
oﬀ quickly [14]. The intermediate data transfer at the
query’s beginning is the most important.
Next, we use the approach described in this section
to ﬁnd the best data placement, i.e., how to adjust Ii’s
(and Si’s) to minimize query response time.
4. DATA PLACEMENT
In this section, we describe our solution for distribut-
ing datasets across the sites to reduce the ﬁnishing time
on the anticipated bottleneck links (motivated in §2.2.2).
Changing the distribution of the input data carries over
to the distribution of intermediate data since the in-
put tasks that produce the latter write their outputs
locally. Further, as the best task placement (§3) is lim-
ited by the distribution of the data (Ii’s or Si’s), data
placement is complementary towards reducing query re-
sponse time. Again, we use “moving of data” for ease of
exposition; our system just replicates additional copies
that are tracked by the global manager (§2.1).
(a) Setup of three sites.
(b) Original
ment
Input Place-
(c) Site-1 → Site-2
(d) Site-1 → Site-3
Figure 4: Exploring destination options for data
movement out of site-1 (same example as Figure 3).
In the initial conﬁguration (4b), site-1’s uplink is the
bottleneck. We evaluate moving 240MB from site-1
to the other two sites, site-2 (4c) and site-3 (4d).
Moving to site-2 results in the lowest intermediate
data transfer duration of 5.4s, from 21.6s.
While the task placement problem alone can be solved
as an LP, the joint optimization of input and task place-
ment contains many local optima (see discussion in §7),
making it impossible to formulate it as a linear or a
quadratic program, or solve using convex optimization
tools. Thus, we proceed to devise an eﬃcient heuristic.
We ﬁrst provide intuition for a single dataset and
query (§4.1), generalize to multiple datasets and queries
in §4.2, provide important enhancements in §4.3, and
ﬁnally describe the knob to budget WAN usage in §4.4.
4.1 Basic Intuition
The LP in §3 provides a useful starting point. It com-
putes the optimal query response time, z, but also iden-
tiﬁes the bottleneck link, where link ﬁnish time is equal
to z. Our heuristic rests on the intuition of moving data
out of the bottleneck site, thereby reducing this maxi-
mum link ﬁnish time (and hence the query duration).
Two natural questions arise in doing so: (i) where to
move the data? (ii) how much data to move out? We
answer both questions next.
(i) Figure 4 illustrates the eﬀect of picking diﬀerent des-
tinations to move data to, using the same example from
§2.2.2. Recall that query’s input across the three sites