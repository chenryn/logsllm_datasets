launches malicious code and establishes command and control (C2). The threat-actor then performs a
series of steps that includes situational awareness of current access, enumeration of potential new
targets, and identification of lateral movement options to those targets. In this case, the threat finds
clear text database credentials on an old test web application backup in a public share. The web
application has no direct significance or critical data other than access to a test database with no
critical data. It’s just a test application. The credentials provide the means to laterally move to a test
database server. Remember, the database doesn’t have sensitive data but is part of the “server zone”
in the network. Code execution on the database server provides elevated access. The situational
awareness cycle repeats. The threat-actor discovers elevated credentials stored in memory on the
database server. The threat extracts this credential material and uses to communicate with a Windows
domain controller to extract an even greater elevated credential from a Windows domain controller
using the dcsync[6] technique. The threat-actor repeats the situational awareness and enumeration
cycle using the newly gained credentials from the domain controller. The intended target is identified
and located on a sensitive file repository. The threat-actor prepositions themselves using the access
and information gained and achieves its final objective by exfiltrating sensitive data from the
network.
Answer the following questions as if you were part of the targeted organization.
Is this scenario reasonable?
Were opportunities presented to detect or prevent the threat?
Could your current security program prevent, detect, or respond to this threat?
Are you sure?
Have you verified?
If so, how?
What techniques or indicators were left behind by this threat?
Organizations often blame the end-user who clicked the link. This scenario indicates an organization's
entire security model may depend on users not clicking a link in an email. What about the actions the
threat took after the initial click? Many organizations do not intend to hinge all security on a single
user, but the steps taken to defend systems often say otherwise.
Consider This
A phishing attack leading to compromise is NOT the
fault of an end-user but rather, insufficient security
controls of a target environment.
End-users are often blamed for compromise due to a
phishing attack. Security defenses are not intended to
hinge on a user’s click decision to click or not. If a user
who falls victim to a phishing attack leads to system-wide
compromise, that user already had the potential to elevate
privileges or otherwise compromise the environment.
Why is this scenario successful?
Organizations often have the wrong mindset to security defense.
Users are blamed for clicking links
User education is only one piece of defense in security operations. Users will click. It’s their job!
Policies, procedures, and compliance measure security
These are extremely important to a security program but often only represent the minimum needed to
comply with a standard. Treat compliance as the stick at an amusement park. You must be "this tall" to
ride.
Log everything; You never know what you need
Security operations often log a tremendous amount of unactionable data. Logging may be due to
compliance requirements, vendor recommendations, lack of understanding of data sources, or a 'better
safe than sorry' mindset. This misunderstanding leads to bottlenecks and overburdened security
analysts.
Patch, patch, patch. Threats only use exploits
A common misunderstanding or viewpoint is threats only use exploits. This is far from the truth. Patch
management is an essential factor in a comprehensive security program that helps with attack surface
reduction. Threats understand this and may change their tactics. This concept is further explored and
discussed in the text as “exploitation without exploits”.
Our security tools will save us
The security industry is very dependent on security tools. Unfortunately, many do not know how these
tools work. The lack of understanding leads to poor tuning and misconfiguration. Tools should
improve the efficiency and capability of our security defenders and analysts and not drive security
operations directly. These are tools. A hammer and nails won't build a house without a carpenter.
There are numerous reasons why the above scenario is successful. These bullets are light-hearted
attempts at humor; they are more often than not issues in practices and thought processes of real-
world organizations.
How do we solve this dilemma?
We can solve through Red Teaming based exercises. Red Teaming captures the threat perspective.
Inspired by military philosophy, many industries have discovered the virtue of "Red Teaming" a
defensive capability, and that its effectiveness grows when tested under actual battlefield conditions.
Merely studying a threat's tactics is less useful than actually experiencing them. Simulated threats
build real confidence and muscle memory in network defenders and arm them with better situational
awareness of tooling and tactics as well as lessons learned from simulated failure.
Red Teaming may be referred to as threat emulation, threat simulation, adversary emulation,
adversary simulation, or some other phrase that expresses a threat-based approach to security testing.
Before we jump too deep into the concepts of red teaming, we must level set our definitions. A
common lexicon is critical to keep everyone on the same page to ensure we maintain a common
unbiased base of understanding. The authors of this book have seen misunderstood terms cause severe
complications and missed expectations. Concepts will be defined and explained throughout this book.
We begin by defining red teaming.
Red Teaming is the process of using Tactics,
Techniques, and Procedures (TTPs) to emulate
a real-world threat with the goals of training
and measuring the effectiveness of the people,
processes, and technology used to defend an
environment.
Assumptions, bias, misunderstandings, and disbelief have a significant impact on the security
operations of an environment. Red Teams provide formidable, honest assessments of internal
practices and security controls by challenging assumptions, disregarding norms, and exposing atrophy
and bias. An unbiased analysis using Red Teaming measures the gap between "what is" and "what
should be". The application of red teaming provides unbiased ground truth and a deep understanding
of security operations as a whole.
Red Teaming epitomizes the practice of attacking problems from an adversarial point of view. This
mindset challenges an idea to help prove its worth, identify weaknesses, or identify areas to improve.
Complex systems are developed, designed, and implemented by skilled, trusted professionals. These
individuals are well respected and trusted in their field and are highly capable of designing and
developing functional systems. Although these systems are highly functional and capable, the ideas,
concepts, and thoughts can sometimes be "boxed in," leading to incorrect assumptions about how a
system honestly operates. People build systems, and people make assumptions about capability,
functionality, and security. These assumptions lead to flaws in which a threat may take advantage.
Red Teaming provides a means to challenge and test conventional wisdom and thought. A few
standard methods to apply Red Teaming scenarios are:
Tabletop exercises – An activity where key individuals walk through a simulated situation to answer
"what if" questions. Actual technical testing does not occur. Discussions of potential outcomes are
explored and examined in an open discussion format.
Physical attacks – An attack on a physical resource, such as a facility or building, to test scenarios
based on attack paths involving physical assets.
Human attacks – An attack that involves social engineering and the manipulation of people to
achieve Red Team goals.
Cyber exercises – A Red vs. Blue exercise designed to train or evaluate staff and security operation
defenses. Exercises can range from a focuses offensive threat scenario to a full Red vs. Blue war
game.
Full-scale cyber operation – The most realistic attack an organization can endure outside of an attack
from a real threat. The elements of the operation collectively assess all aspects of a specific scenario.
The scenario drives the need and may leverage physical, human, and cyber weaknesses to accomplish
desired objectives.
Red Teaming does not focus on a vulnerability or weakness as a single "finding." During a Red Team
engagement, an operator may find an unpatched or misconfigured system. This flaw may be used to
the team's advantage to provide a more extensive compromise into a network or to pivot from the
vulnerable system to achieve a specific goal or may not be used at all. Although a single unpatched or
misconfigured system may give a Red Team Operator the means to compromise a network, it is just a
means to an end. This is a crucial distinguisher for Red Teaming.
Red Team engagements focus on specific goals and objectives.
These goals may include compromising an application or network, stealing data, emulating a specific
target, measuring the effectiveness of technical defenses, measuring the effectiveness of a security
team, etc. The vulnerabilities and weaknesses identified during an assessment may need to be
addressed and mitigated, but this is not the focus of Red Teaming. Red Teaming focuses on the bigger
picture by providing insight into a target's detection and response capabilities. It gives understanding
Mean-Time to Detect (MTTD) and Mean-Time to Recover (MTTR) from individual breaches. It
exercises the relationship between its incident response and threat hunting teams by testing network
defenders and their tools in ways that cannot be achieved through traditional threat intelligence,
literature, or structured testing.
The following categories summarize Red Teaming goals.
Measuring the effectiveness of the people, processes, and technology used to defend a network
When a Red Team uses real-world attack techniques against a target’s production network, the extent
of the organization’s defenses are challenged. For example, an engagement has the goal of stealing
critical data from a target. A targeted phishing attack tests the end user’s willingness to participate in
an attack. The payload of the attack tests the network and host defenses against the delivery of
malware and ultimately against code execution. If the attack does trigger a defensive control, the
response measures the defender’s actions in identifying, responding, or stopping the attack. Red
teaming provides a means to measure security operations as a whole and not only focus on technical
controls.
Training or measuring defensive or security operations
"We don't rise to the level of our expectations;
we fall to the level of our training." -
Archilochus, Greek Poet, around 650 BC
Training the Blue Team (defenders of a network) is one of the most valuable aspects of Red Teams.
Without training, how are defenders expected to defend against a real attack? Classroom exercises
and conceptual training is valuable; however, Red Teams provide the ability for defensive operations
to build skills against a threat in a safe, productive environment. Leadership that expects their
defending team to respond to that threat without practice and successfully defend is fooling
themselves. This form of training is more hands-on than typical security courses. The real-world
practice of people using technology and following their processes is needed to understand security
operation's ability to defend.
Testing and understanding specific threats or threat scenarios
A Red Team can execute and emulate a current, new, or custom threat as part of an engagement to test
or validate the effectiveness of security controls. Threat emulation scenarios distinguish red teaming
from other types of security assessments and can be used to understand an organization's posture
against various threats. This approach provides the means to test scenarios based on new
undiscovered threats or zero-day exploits. A great example is the EternalBlue[7] exploit. This exploit
involved remote code execution using the SMB protocol, a key protocol used in Microsoft
environments. Before the exploit was known, a Red Team could have easily designed a scenario
where an attacker was able to propagate over the SMB protocol to measure the impact of this type of
dangerous attack. Red teams don’t need (or shouldn’t) wait for a threat to develop and attack paths.
Custom scenarios are a great way to understand current and future threats. More information can be
found on ExternalBlue in CVE-2017-0144.
Remember This
Red Teams are used to measure the effectiveness of the
people, processes, and technology used to defend a
network, train or measure a Blue Team (defensive security
operations), and test and understand specific threats or
threat scenarios.
We’ve described what Red Teams do, but let’s give them a definition to add to our common lexicon.
A Red Team is an independent group that, from the perspective of a threat or adversary, explores
alternative plans and operations to challenge an organization to improve its effectiveness.
Red Teams perform actions during a Red Teaming engagement outlined by the Rules of Engagement
(ROE). We will discuss these rules in detail later. For now, think of them as a guide used by a Red
Team as to how they should conduct actions. Red Teams are independent groups that are technically
skilled and capable of executing a threat based-plan safely and professionally.
We keep describing Red Teams as “independent.” Why? As discussed, many organizations or groups
have significant biases and assumptions based solely on unproven or unconfirmed information. An
independent Red Team, unobstructed by the biases of the target, can provide a clean review, fresh
perspective, and accurate assessment of how a threat may cause an impact on various business
functions. This team may be an external consultant or an internal team managed and operated
separately from the rest of the organization. Independent reviews are invaluable in determining real-
world risks and consequences and a key component of Red Teaming.
Consider This
Independent Red Teams are invaluable in determining
real-world risks and potential impacts.
Independence allows the Red Team to accurately review
or assess while limiting many of the biases and
assumptions of the target.
What is the difference between a Red Team and a real-world attacker? A Red Team will provide a
report, or other deliverables, with the goal of understanding threat-based risks. Organizations that use
Red Teams effectively do not need to wait and learn from a real-world breach. Red Teams are
beneficial in analyzing systems for security weaknesses that may not be known or understood. The
mindset and thought processes used by a professional Red Team Operator can break through common
assumptions that severely weaken a system's security. Red Teams ask the "what if" questions to
challenge system defenses at its core. Effectively using Red Teams can bring to light security flaws
that have plagued a system for years and allow an organization to develop highly effective mitigating
solutions.
Although there are tremendous benefits to Red Teams, they can be challenging to use. They are
commonly used in name only. The activities performed during an engagement are no more than a
vulnerability test or penetration test. The output may be something as simple as a list of findings. Red
Teams must be able to think and act like a threat being portrayed. These engagements could be a
gloves-off, advanced threat, or limited actions to emulate a single or straightforward threat. We will
discuss how to do this by "adjusting the volume" of attacks and Indicator of Compromise (IOC)
management later. For now, understand that a Red Team must operate within its rules and boundaries
and focus on goals outlined in the engagement plan.
Red Teaming is about the overall story. Red Teams can document vulnerabilities and weaknesses
identified during an assessment but focus on the whole story of the attacker throughout an engagement.
Consider This
Assumptions, bias, misunderstandings, and disbelief
have a considerable impact on the security failures of
an environment.
An unbiased Red Team helps measure the gap between
"what is" and "what should be" to get to the truth of
security operations as a whole.
Let’s consider the following.
During early red team scenario planning, an organization's security leadership describes who has
access to their accounting systems. They say, "5 people in accounting have access to the accounting
system". In their minds, this is what "Is." When planning a threat scenario, you must think this is what
"Should Be." This scenario is the perfect opportunity for a Red Team to validate assumptions in a
professional and unbiased approach. The goal is not to prove that you can 'hack' into the system but to
understand what "Is" vs. "Should Be."
Another way to describe this:
Is – The actual truth about the security stance of an organization. (E.g., 20 People have access to the
sensitive accounting system.)
Should be – The perceived security stance of an organization. (E.g., only 5 people in accounting can
access the sensitive accounting system.)
Challenging assumptions is a fundamental concept of red teaming.
Red Teams in Security Testing
Vulnerability assessment, penetration testing, and Red Teaming are commonly (yet erroneously) used
interchangeably and fall under the general category of ethical hacking. This classification may be
adequate for high-level conversations about security, but distinctions must be made. Security
professionals and clients of security services will continue to blur the lines between these assessment
types if differences are not made. We do ourselves a disservice by loosely defining terms. This hurts
the security industry and the professionals themselves. This is more reason to level set definitions and
come to a common understanding. Misunderstanding of assessment types has led to low-quality
assessments claiming to be high-end. Terms must be defined early in an engagement to set
expectations and deliver the service a client need.
Vulnerability Assessment
According to NIST Special Publication 800-53 (Rev. 4)[8], a vulnerability assessment is a
“Systematic examination of an information system or product to determine the adequacy of security
measures, identify security deficiencies, provide data from which to predict the effectiveness of
proposed security measures, and confirm the adequacy of such measures after implementation.” In
short, a vulnerability assessment is an analysis of a system that focuses on finding vulnerabilities and
prioritizing them by risk.
The verification of identified vulnerabilities is left to the output of tools and the analyst's best
judgment. The validation or exploitation of a vulnerability is not performed during a vulnerability
assessment. When compared with Red Team engagements, vulnerability assessments are like good
housekeeping. The mitigations applied due to the result of a vulnerability assessment are an effort in
attack surface reduction with the intent to reduce the ability a threat has to gain an advantage of an
identified flaw. A Red Teamer or threat assumes these types of assessments are being performed and
mitigated appropriately. These steps in mitigation do impact the threat landscape and may reduce
attack paths, but does not directly address the threat. It's best to consider vulnerability assessments as
an effort in attack surface reduction.
Consider This
Red Teams rarely, if ever, run standard vulnerability
assessment tools.
These tools are loud and generate more traffic than a Red
Team engagement is willing to accept. If a vulnerability
assessment tool MUST be used, there should be a question
asked as to the type of security assessment being
conducted, or they should be run with high focus from a
"burned" attack location. Vulnerability assessments are
still a critical component to security program but are quite
different in scope and goals of a red team engagement.
Penetration Test
According to NIST Special Publication 800-53 (Rev. 4) CA-8 1, Penetration testing is defined as “…
a specialized type of assessment conducted on information systems or individual system components
to identify vulnerabilities that could be exploited by adversaries...”. In other words, penetration
testing is an authorized simulated attack against a system designed to identify and measure risks
associated with the exploitation of a target’s attack surface. This may sound like a red team
engagement. The differences are often misunderstood but critical to the success of both.
Penetration testing takes a vulnerability assessment to the next level by introducing exploitation into
the test. The goal of a penetration test is to determine the risk associated with vulnerabilities and
flaws. A penetration test can look and feel very similar to a Red Team engagement, and in many
cases, use the same tools. These similarities should not cause anyone to confuse the two. Penetration
tests focus on exploiting weaknesses to determine business risk. It is common for a penetration test to
explore a wide range of vulnerabilities to discover their risks. During a Red Team engagement, flaws
will be exploited but only to the degree needed to achieve the goals or objectives. If a single
vulnerability allows a Red Team to move forward, the team only uses this to move forward. The other
twenty flaws found (by the Red Team or a previous vulnerability assessment) will be documented but
may remain un-actioned during the Red Team engagement. Penetration testing, although more
narrowly focused than a vulnerability assessment, has a much broader focus than a Red Team
engagement. Like a vulnerability assessment, mitigation performed after a penetration test reduces the