### Online Memory Leak Detection in Cloud-based Infrastructures

**3. Change Point Detection and Anomaly Marking**

Once a window is marked as anomalous, the process is repeated by analyzing the observations between the last change point \( P \) and the previous next change point. This continues until all change points are used. This method is particularly useful when new data exhibits a similar trend to historical data but with a steeper slope and longer duration. The pseudo-code for the training and testing methods is provided in Algorithm 1.

**Definition 2: (Change Points)**

A set of time ticks that significantly deviate from the normal pattern of the data. These are identified by first computing the first-order difference of the input time series, then taking their absolute values, and calculating their Z-scores. The indices of observations whose Z-scores exceed a defined threshold (typically 3 times the standard deviation) are considered change points. The pseudo-code for this process is detailed in the CPD function of Algorithm 1.

**4. Evaluation**

We designed experiments to answer the following questions:

- **Q1. Memory Leak Detection Accuracy:** How accurate is Precog in detecting memory leaks?
- **Q2. Scalability:** How does the algorithm scale with an increase in data points?
- **Q3. Parameter Sensitivity:** How sensitive is the algorithm to changes in parameter values?

For performance evaluation, we used the F1-Score (denoted as F1). The evaluation tests were conducted on a machine with 4 physical cores (3.6 GHz Intel Core i7-4790 CPU) with hyperthreading enabled and 16 GB of RAM, conditions similar to a typical cloud VM. The algorithm assumes that there is an ongoing memory leak and that no memory leak existed previously. The hyper-parameters were set as follows: the maximum threshold \( U \) is 100, the critical time \( C \) is 7 days, the smoothing window size is 1 hour, and the re-sampling time resolution is 5 minutes. The minimum R-squared score \( R^2 \) for a line to be recognized as a good fit is 0.75. 

**4.1 Q1. Memory Leak Detection Accuracy**

To demonstrate the effectiveness of the developed algorithm, we initially generated synthetic time series. Table 2 shows the F1 scores corresponding to each memory leak pattern and the overall F1 score. Precog achieved an overall accuracy of 90%.

Additionally, we evaluated Precog on a real cloud dataset provided by Huawei Munich, which includes manually labeled memory leak data from 60 VMs over 5 days, with each time series consisting of an observation every minute. Out of these 60 VMs, 20 had memory leaks. This high number of VMs with memory leaks was due to the deliberate running of applications with memory leaks on the infrastructure. The algorithm achieved an F1-Score of 0.857, with a recall of 0.75 and precision of 1.0. The average prediction time per test data containing approximately 500 points was 0.32 seconds.

**4.2 Q2. Scalability**

Next, we verified that our prediction method scales linearly. We repeatedly duplicated our dataset, added Gaussian noise, and observed that Precog's prediction method scales linearly in time ticks. Precog provides prediction results under 1 second for data with 100,000 time ticks. However, the training method is quadratic in nature but needs to be conducted only once a week or a month and can be done offline.

**4.3 Q3. Parameter Sensitivity**

Precog requires tuning of certain hyper-parameters like the R2 score and critical time, which are currently set manually based on expert knowledge. Figure 5 compares the performance for different parameter values on a synthetically generated dataset. The algorithm performs consistently well across various values. Setting the minimum R2 score above 0.8 corresponds to stricter fitting of the line, leading to a drop in accuracy. On the other hand, setting the minimum critical time too low (less than 3 days) would mean the trend line never reaches the threshold within the timeframe, thus decreasing accuracy. These experiments show that these parameters play a role in the overall accuracy of the algorithm, but the algorithm is generally insensitive to them at most values. Further work to determine these parameters automatically based on historical data is in progress but out of the scope of this paper.

**5. Conclusion**

Memory leak detection has been a research topic for over a decade. Many approaches have been proposed, primarily focusing on the internal workings of applications or object allocation and deallocation. The Precog algorithm presented here is particularly relevant for cloud-based infrastructures where cloud administrators do not have access to the source code or know about the internals of deployed applications. Performance evaluation results showed that Precog achieves an F1-Score of 0.85 with less than half a second prediction time on real workloads. This algorithm can also be useful in Serverless Computing, where successive function invocations can add to a memory leak, resulting in a larger memory leak on the underlying system. Future work will include developing online learning-based approaches for detection and using other metrics like CPU, network, and storage utilization to enhance the accuracy and provide higher confidence in the detection results.

**Acknowledgements**

This work was supported by funding from the German Federal Ministry of Education and Research (BMBF) as part of the Software Campus program. The authors also thank the anonymous reviewers for their valuable comments.

**References**

[Include the references as provided in the original text, formatted consistently.]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the essential content and structure of the original text.