that window will be marked as anomalous. This procedure is further repeated
by analyzing the observations between the last change point P and the previ-
k
ous next change point until all the change points are used. This is done for the
cases where the new data has a similar trend as the historic data but now with
a higher slope and longer duration. The algorithm’s pseudo code showing the
training and test method are shown in the algorithm 1.
Online Memory Leak Detection in the Cloud-based Infrastructures 7
Definition 2. (Change Points) A set of time ticks which deviate highly from
the normal pattern of the data. This is calculated by first taking the first-order
difference of the input timeseries. Then, taking their absolute values and cal-
culating their Z-scores. The indexes of observations whose Z-scores are greater
than the defined threshold (3 times the standard deviation) represents the change
points. The method’s pseudocode is shown in the algorithm’s 1 CPD function.
4 Evaluation
We design experiments to answer the questions:
– Q1. Memory Leak Detection Accuracy: how accurate is Precog in the
detection of memory leaks?
– Q2. Scalability:Howdoesthealgorithmscalewiththeincreaseinthedata
points?
– Q3. Parameter Sensitivity: How sensitive is the algorithm when the pa-
rameters values are changed?
We have used F1-Score (denoted as F1) to evaluate the performance of the
algorithms. Evaluation tests have been executed on a machine with 4 physical
cores(3.6GHzIntelCorei7-4790CPU)withhyperthreadingenabledand16GB
of RAM. These conditions are similar to a typical cloud VM. It is to be noted
that the algorithm detects the cases where there is an ongoing memory leak
and assumes that previously there was no memory leak. For our experiments,
hyper-parameters are set as follows. The maximum threshold U is set to 100
and the defined critical time C is set to 7 days. The smoothing window size is 1
hourandre-samplingtimeresolutionwassetto5minutes.Lastly,theminimum
R-squared score R2 for a line to be recognized as a good fit is set to 0.75.
min
65%ofdatawasusedfortrainingandtherestfortesting.However,wealsoshow
experiments on parameter sensitivity in this section.
4.1 Q1. Memory Leak Detection Accuracy
To demonstrate the effectiveness of the developed algorithm, we initially syn-
thetically generated the timeseries. Table 2 shows the F1 score corresponding
to each memory leak pattern and also the overall F1 score. Table 2 shows that
Precog is able to reach an overall accuracy of 90%.
In addition, to demonstrate the effectiveness of the developed algorithm on
therealcloudworkloads,weevaluatedPrecogontherealClouddatasetprovided
byHuaweiMunichwhichconsistsofmanuallylabeledmemoryleakdatafrom60
VMs spanned over 5 days and each time series consists of an observation every
minute.Outofthese60VMs,20VMshadamemoryleak.Suchhighnumberof
VMshavingmemoryleaksisduetothefactthatapplicationswithmemoryleak
weredeliberatelyrunontheinfrastructure.ThealgorithmachievedtheF1-Score
of 0.857, recall equals to 0.75 and precision as 1.0. Average prediction time
per test data containing approximately 500 points is 0.32 seconds.
8 Jindal et al.
Algorithm 1: Precog Algorithm
Input: input Train Ts,R2 score min, input Test Ts, critical time
Output: anomalous list a
1 Function CPD(x=input Ts,threshold=3):
2 absDiffTs=first order absolute difference of x
3 zScores=calculate z-scores of absDiffTs
4 cpdIndexes=indexes of (zScores>threshold)
5 return cpdIndexes // return the change-points indexes
6 Function TRAINING(x=input Train Ts, R2 score min,C =critical time):
// Train on input Train Ts
7 P = CPD(x) // get Change-points
8 p1 = 0
9 while p1 <= length(P) do
10 p2 = p1
11 D b,S b,T b =0 // best local trend’s duration, slope, exit time
12 while p2 <= length(P) do
13 exit time,r2,dur,slope←LinearRegression(ts) // fitted
line’s exit time, R2 score, duration, slope
14 if r2≥R2 score min and dur≥D b and slope≥S b then
15 Update(D b,S b,T b) // update best local values
16 p2=p2+1
17 if T b ≤C then
18 if D b ≥D max and S b ≥S max then
19 Update(D max,S max) // update global trend values
20 saveTrend(D b,S b), save(D max,S max) // save values
21 p1=p1+1
22 Function TEST(x=input Test Ts,C =critical time):
// Test on the new data to find anomalous memory leak window
23 a=[0] // anomalous empty array of size input Test Ts
24 P = CPD(x) // get Change-points
25 len=length(P) // length of change point indexes
26 while i≤len do
27 ts=x[P[len−i]:P[len]] // i is a loop variable
28 exit time,r2,dur,slope=LinearRegression(ts)
29 D max,S max,Trends=get saved values
30 if exit time,≤C and r2≥R min then
31 if slope≥S max and dur≥D max then
32 a[P[len−i]:P[len]]=1 // current trend greater than
global saved so mark anomalous
33 else
34 For Each t in Trends if slope≥S t and dur≥D t then
35 a[P[len−i]:P[len]]=1 // current trend greater
than one of the saved trend so mark anomalous
36 i=i+1
37 return a // list with 0s and anomalous indexes represented by 1
Online Memory Leak Detection in the Cloud-based Infrastructures 9
Table2:Syntheticallygeneratedtimeseriescorrespondingtoeachmemoryleakpattern
and their accuracy score.
Memory Leak Pattern +ve cases-ve casesF1 ScoreRecallPrecision
Linearly Increasing 30 30 0.933 0.933 0.933
Linearly Increasing(with Noise)30 30 0.895 1.0 0.810
Sawtooth 30 30 0.830 0.73 0.956
Overall 90 90 0.9 0.9 0.91
(a)Linearlyincreasing (b)Sawtoothlinearlyincreasing
(c)Linearlyincreasingwithouttrends (d) Linearly increasing with similar trend as
detectedintrainingdata trainingdataandcorrectlynotdetected
Fig.3:Algorithmresulton3difficultcaseshavingmemoryleak(a-c)andonecasenot
having a memory leak (d).
Furthermore,wepresentthedetailedresultsofthealgorithmontheselected
4 cases shown in the Figure 3 : simple linearly increasing memory utilization,
sawtooth linearly increasing pattern, linearly increasing pattern with no trends
detected in training data, and linearly increasing with similar trend as training
data. The figure also shows the change points, training trends and the detected
anomalous memory leak window for each of the cases.
ForthefirstcaseshowninFig.3a,memoryutilizationisbeingusednormally
until it suddenly starts to increase linearly. The algorithm detected one training
trend and reported the complete test set as anomalous. The test set trend is
having similar slope as training trend but with a longer duration and higher
memory usage hence it is reported as anomalous.
In the second case (Fig. 3b), the trend represents commonly memory leak
sawtooth pattern where the memory utilization increases upto a certain point
10 Jindal et al.
(a)TrainingTime (b)PredictionTime
Fig.4: Precog’s prediction method scale linearly.
and then decreases (but not completely zero) and then again it start to increase
inthesimilarmanner.Thealgorithmdetectedthreetrainingtrendsandreported
mostofthetestsetasanomalous.Thetestsetfollowsasimilartrendascaptured
duringthetrainingbutwiththehighermemoryutilization,henceitisreported.
Inthethirdcase(Fig.3c),noappropriatetrainingtrendwasdetectedinthe
completetrainingdatabut,thealgorithmisabletodetectanincreasingmemory
utilization trend in the test dataset.
In Fig. 3d, the VM does not have a memory leak but its memory utilization
was steadily increasing which if observed without the historic data seems to be
a memory leak pattern. However, in the historic data, the same trend is already
observed and therefore it is a normal memory utilization pattern. Precog using
thehistoricdatafordetectingthetrainingtrendsandthencomparingthemwith
the test data correctly reports that trend as normal and hence does not flag the
window as anomalous. It is also to be noted that, if the new data’s maximum
goes beyond the maximum in the training data with the similar trend then it
will be regarded as a memory leak.
4.2 Q2. Scalability
Next, we verify that our prediction method scale linearly. We repeatedly dupli-
cateourdatasetintimeticks,addGaussiannoise.Figure4bshowsthatPrecog’
predict method scale linearly in time ticks. Precog does provide the prediction
results under 1 second for the data with 100,000 time ticks. However, the train-
ing method shown in Figure 4a is quadratic in nature but training needs to
conducted once a week or a month and it can be done offline as well.
4.3 Q3. Parameter Sensitivity
Precog requires tuning of certain hyper-parameters like R2 score, and critical
time,whichcurrentlyaresetmanuallybasedontheexpertsknowledge.Figure5
comparesperformancefordifferentparametervalues,onsyntheticallygenerated
dataset.Ouralgorithmperformconsistentlywellacrossvalues.Settingminimum
R2 score above 0.8 corresponds to stricter fitting of the line and that is why the
Online Memory Leak Detection in the Cloud-based Infrastructures 11
Fig.5:Insensitivetoparameters:Precogperformsconsistentlyacrossparametervalues.
accuracy drops. On the other hand, our data mostly contains trend lines which
would reach threshold withing 3 to 4 days, therefore setting minimum critical
timetooless(lessthan3days)wouldmeanthetrendlineneverreachingthresh-
oldwithinthetimeframeandhencedecreasingtheaccuracy.Theseexperiments
showsthattheseparametersdoesplayaroleintheoverallaccuracyofthealgo-
rithm but at most of the values algorithm is insensitive to them. Furthermore,
to determine these automatically based on the historic data is under progress
and is out of the scope of this paper.
5 Conclusion
Memory leak detection has been a research topic for more than a decade. Many
approacheshavebeenproposedtodetectmemoryleaks,withmostofthemlook-
ingattheinternalsoftheapplicationortheobject’sallocationanddeallocation.
ThePrecogalgorithmformemoryleakdetectionpresentedinthecurrentworkis
mostrelevantforthecloud-basedinfrastructurewherecloudadministratordoes
not have access to the source code or know about the internals of the deployed
applications. The performance evaluation results showed that the Precog is able
toachieveaF1-Scoreof0.85withlessthanhalfasecondpredictiontimeonthe
real workloads. This algorithm can also be useful in the Serverless Computing
where if a function is leaking a memory then its successive function invocations
will add on to that and resulting in a bigger memory leak on the underneath
system. Precog running on the underneath system can detect such a case.
Prospective directions of future work include developing online learning-
basedapproachesfordetectionandaswellusingothermetricslikeCPU,network
andstorageutilizationforfurtherenhancingtheaccuracyofthealgorithmsand
providing higher confidence in the detection results.
ACKNOWLEDGEMENTS
This work was supported by the funding of the German Federal Ministry of
EducationandResearch(BMBF)inthescopeoftheSoftwareCampusprogram.
The authors also thank the anonymous reviewers whose comments helped in
improving this paper.
12 Jindal et al.
References
1. Ataallah,S.M.A.,Nassar,S.M.,Hemayed,E.E.:Faulttoleranceincloudcomputing
-survey.In:201511thInternationalComputerEngineeringConference(ICENCO).
pp. 241–245 (Dec 2015). https://doi.org/10.1109/ICENCO.2015.7416355
2. Chen, K., Chen, J.: Aspect-based instrumentation for locating memory leaks
in java programs. In: 31st Annual International Computer Software and
Applications Conference (COMPSAC 2007). vol. 2, pp. 23–28 (July 2007).
https://doi.org/10.1109/COMPSAC.2007.79
3. Clause, J., Orso, A.: Leakpoint: pinpointing the causes of memory leaks. In: 2010
ACM/IEEE 32nd International Conference on Software Engineering. vol. 1, pp.
515–524 (May 2010). https://doi.org/10.1145/1806799.1806874
4. Gokhroo, M.K., Govil, M.C., Pilli, E.S.: Detecting and mitigating faults in
cloud computing environment. In: 2017 3rd International Conference on Com-
putational Intelligence Communication Technology (CICT). pp. 1–9 (Feb 2017).
https://doi.org/10.1109/CIACT.2017.7977362
5. Jain, N., Choudhary, S.: Overview of virtualization in cloud computing. In: 2016
Symposium on Colossal Data Analysis and Networking (CDAN). pp. 1–4 (March
2016). https://doi.org/10.1109/CDAN.2016.7570950
6. Jump, M., McKinley, K.S.: Cork: Dynamic memory leak detection for garbage-
collectedlanguages.In:Proceedingsofthe34thAnnualACMSIGPLAN-SIGACT
SymposiumonPrinciplesofProgrammingLanguages.pp.31–38.POPL’07,ACM,
NewYork,NY,USA(2007).https://doi.org/10.1145/1190216.1190224,http://doi.
acm.org/10.1145/1190216.1190224
7. Mitchell, N., Sevitsky, G.: Leakbot: An automated and lightweight tool for diag-
nosingmemoryleaksinlargejavaapplications.In:Cardelli,L.(ed.)ECOOP2003
–Object-OrientedProgramming.pp.351–377.SpringerBerlinHeidelberg,Berlin,
Heidelberg (2003)
8. Pooja, Pandey, A.: Impact of memory intensive applications on per-
formance of cloud virtual machine. In: 2014 Recent Advances in En-
gineering and Computational Sciences (RAECS). pp. 1–6 (March 2014).
https://doi.org/10.1109/RAECS.2014.6799629
9. Rudafshani, M., Ward, P.A.S.: Leakspot: Detection and diagnosis of memory
leaks in javascript applications. Softw. Pract. Exper. 47(1), 97–123 (Jan 2017).
https://doi.org/10.1002/spe.2406, https://doi.org/10.1002/spe.2406
10. Sor,V.,Srirama,S.N.:Astatisticalapproachforidentifyingmemoryleaksincloud
applications. In: CLOSER (2011)
11. Sor,V.,Srirama,S.N.:Memoryleakdetectioninjava:Taxonomyandclassification
of approaches. Journal of Systems and Software 96, 139–151 (2014)
12. Sor, V., Srirama, S.N., Salnikov-Tarnovski, N.: Memory leak detection in plumbr.
Softw., Pract. Exper. 45, 1307–1330 (2015)
13. Vilk,J.,Berger,E.D.:Bleak:Automaticallydebuggingmemoryleaksinwebappli-
cations.In:Proceedingsofthe39thACMSIGPLANConferenceonProgramming
Language Design and Implementation. pp. 15–29. PLDI 2018, ACM, New York,
NY, USA (2018). https://doi.org/10.1145/3192366.3192376, http://doi.acm.org/
10.1145/3192366.3192376
14. Xie, Y., Aiken, A.: Context- and path-sensitive memory leak de-
tection. SIGSOFT Softw. Eng. Notes 30(5), 115–125 (Sep 2005).
https://doi.org/10.1145/1095430.1081728, http://doi.acm.org/10.1145/1095430.
1081728