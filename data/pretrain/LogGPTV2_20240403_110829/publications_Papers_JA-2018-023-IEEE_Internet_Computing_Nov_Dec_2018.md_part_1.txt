### Department: View from the Cloud

#### Efficient Failure Diagnosis of OpenStack Using Tempest

**Authors:**
- Ankur Bhatia
- Michael Gerndt, Technical University of Munich
- Jorge Cardoso, Huawei Munich Research Center, University of Coimbra

**Abstract:**
As cloud computing continues to gain popularity in the IT world, companies offering cloud solutions are under pressure to provide the most reliable services to users. In this article, we describe an innovative approach to diagnosing service failures in an OpenStack-based cloud using Tempest as a starting point.

---

### Service Failure Diagnosis of OpenStack: Earlier Work

**OpenStack Overview:**
OpenStack is an open-source cloud operating system for building public and private clouds. It can manage large pools of compute, storage, and networking resources in data centers. OpenStack is a continuously evolving system with a major release cycle every six months.

**High Availability and Service Failures:**
To achieve high availability, Openstack service failures need to be continuously monitored. A service failure, as characterized by Avizienis et al., is "an event that occurs when the delivered service deviates from the correct service." This transition from correct to incorrect service means the system function is not being implemented properly.

**Monitoring and Diagnostics Tools:**
The OpenStack community maintains a wiki page listing over 50 different tools for monitoring and diagnosing failures. However, most of these are generic solutions. The ones specific to OpenStack typically show usage metrics or monitor if a certain process is running. Other tools require users to have expert knowledge and interpret large amounts of log information to diagnose failures. DevOps can also use Rally, an OpenStack tool capable of managing complex workflows for benchmarking and evaluation experiments.

**Anomaly Detection Techniques:**
Several approaches have been proposed to detect anomalies in software systems. The three most relevant techniques are:
1. **Log Analysis:** Uses clustering, heuristics, and templates to mine logs into events or flows. Features/graphs are extracted to model normal and abnormal behavior.
2. **Performance Analysis:** Identifies resource consumption models (e.g., CPU, memory, disk I/O) to establish patterns of normality and abnormality.
3. **Trace Analysis:** Instruments code to generate traces (sequences of correlated events) at runtime to identify normal and abnormal behavior.

**Challenges with Existing Techniques:**
- Log analysis requires frequent reparameterization and updates.
- Performance analysis is difficult due to the variability of cloud workloads and multi-tenancy.
- Trace analysis breaks when new instrumentation points are added, removed, or changed.

---

### Can Tempest Tests Be Used to Diagnose Failures in OpenStack?

**Tempest Overview:**
The OpenStack community developed a test suite named Tempest, used for validating all modules of OpenStack during the development cycle to ensure the code is error-free. It is the official integration test suite containing more than 1500 tests for API and scenario validation.

**Challenges with Tempest for Failure Diagnosis:**
- **Lack of Information:** Tempest tests do not provide information about non-responsive or failed services. They generate a list of passed and failed tests, which helps locate software errors but does not diagnose failures.
- **Execution Time:** With over 1500 tests, it takes a considerable amount of time (3â€“4 hours) to execute them. Custom tests are often developed, but they become outdated with each new release, making the approach costly for cloud operators.

**Need for a New Approach:**
A different approach is needed to diagnose service failures in OpenStack. The solution should be efficient, fast, and able to establish relationships between Tempest tests and the services they test. It should also cope with the fast release cycle of OpenStack.

---

### Failure Diagnosis of OpenStack Using Tempest Tests

**Phase 1: Tempest Test Suite Reduction**

**Architecture:**
The first phase involves reducing the Tempest test suite. This task is handled by the Tempest test manager, which consists of five subsystems:

1. **Identify Modules:**
   - Identify all modules where Tempest tests are implemented using naming conventions.
   - Example: `tempest.api.compute.flavors.test_flavors.FlavorsV2TestJSON.test_get_flavor` yields:
     - Path to the module: `tempest.api.compute.flavors.test_flavors`
     - Class name: `FlavorsV2TestJSON`
     - Test method: `test_get_flavor`

2. **Construct Abstract Syntax Tree (AST):**
   - Perform code analysis to identify test methods and their support methods.
   - Construct an AST to represent the source code in a tree structure.

3. **Filter AST:**
   - Eliminate irrelevant support methods using inverse document frequency (IDF).
   - IDF is calculated as: \( \text{IDF}(x) = \log\left(\frac{\# \text{modules}}{\# \text{modules with support method } x}\right) \)
   - Example: If a support method is present across most modules, it is considered irrelevant.

4. **Support Method Deduplication:**
   - Use the set cover algorithm to eliminate redundant test methods.
   - Consider parameters like execution time and coverage percentage.

5. **Cross-Module Deduplication:**
   - Eliminate redundant test methods across modules without losing coverage.
   - Example: If a test method in one module calls the same support methods as another, it can be eliminated.

**Results:**
Our experiment with OpenStack reduced 1392 Tempest tests to 518 tests with 100% coverage.

**Phase 2: Relationship Establishment and Isomorphic Test Elimination**

**Establishing Relationships:**
- Disable services one at a time to simulate failures.
- Run the reduced set of Tempest tests.
- Restart services.
- Repeat for all critical services.
- Establish relationships between Tempest tests and services in a matrix.

**Isomorphic Test Elimination:**
- Remove tests that establish the same relationships (isomorphic tests).

**Matrix Representation:**
- Each cell represents a relationship \( R(U_i, \text{service}_j) \):
  - \( R(U_i, \text{service}_j) = 1 \) means \( U_i \) depends on \(\text{service}_j\).
  - \( R(U_i, \text{service}_j) = 0 \) means \( U_i \) does not depend on \(\text{service}_j\).

---

**Conclusion:**
This approach provides an efficient and effective method for diagnosing service failures in OpenStack using Tempest tests. It reduces the number of tests required, establishes clear relationships between tests and services, and copes with the rapid release cycle of OpenStack.

**References:**
1. OpenStack Community. (n.d.). OpenStack. Retrieved from [OpenStack.org](https://www.openstack.org/)
2. Avizienis, A., Laprie, J.-C., Randell, B., & Landwehr, C. (2004). Basic Concepts and Taxonomy of Dependable and Secure Computing. IEEE Transactions on Dependable and Secure Computing, 1(1), 11-33.
3. OpenStack Community. (n.d.). Monitoring and Diagnostics. Retrieved from [OpenStack Wiki](https://wiki.openstack.org/wiki/Monitoring_and_Diagnostics)
4. Rally. (n.d.). OpenStack Rally. Retrieved from [Rally OpenStack](https://rally.readthedocs.io/en/latest/)

**Published by:**
IEEE Internet Computing
November/December 2018
Volume 22, Issue 6
ISSN: 1089-7801