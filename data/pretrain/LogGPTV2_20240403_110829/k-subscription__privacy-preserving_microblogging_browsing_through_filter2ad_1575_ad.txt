54the number of occurrences of each user ID. This is the number of
channels belonging in S that each user in our dataset follows. In
this analysis we found more than 530, 000 unique users. Figure 6
shows the respective distribution, which is approximated with a
typical power law function. This approximation is used in our sim-
ulations for realistic user selections. Also, we observe that only
0.85% of the users follow more than 4 sensitive channels, while
91.65% of the users follow just one sensitive channel.
The simulator keeps two counters per each channel: the num-
ber of users that (i) select this channel as actual interest (UC),
and (ii) select this channel as noise (URC ). Before exiting, the
simulator reports the disclosure probability per channel, which is
max(1/k, UC /(UC + URC ). Additionally, it keeps two lists per
user: (i) the channels she is interested in (Ci), and (ii) the chan-
nels she selects as noise (Cn). This way, the simulator reports
the disclosure probability per user, based on the set of sensitive
channels the user is interested in (Ci). This probability is equal to
max(1/k, UCi /(UCi + URCi
)), where UCi the number of users
interested in Ci and URCi
the number of users that Ci is included
within their Cn. This is because we assume that all channels in Ci
are semantically correlated. Among all the disclosure probabilities
reported per each user and each channel, the simulator reports the
overall average and maximum disclosure probability. We repeat
each simulation for 100 times and we use the average values.
We set |S| to 1,000 channels, U to 1,000,000 users, and we vary
k from 1 to 200. Figure 7 shows the average and maximum dis-
closure probability reported by the simulator as a function of k.
We see that k-subscription achieves a low average disclosure prob-
ability over all channels and users, which decreases rapidly with k.
However, we see that the maximum disclosure probability found
for an individual user remains equal to 1 for low values of k up
to k = 30. This is because there is at least one user interested in
an N-tuple that no other user has selected among her random noise
choices, especially for large values of N. However, as k increases,
we see that an increasing number of users tend to select a signiﬁcant
percentage of the channels in S as random choices, e.g., users with
large value of N. As these users follow most of the channels in S,
they tend to hide the actual users’ interests, even for large and rare
N-tuples, reducing effectively the maximum disclosure probability.
5.
IMPLEMENTATION
To evaluate the feasibility and efﬁciency of k-subscription we
have implemented a Twitter extension for the popular Chrome web
browser. The extension uses Twitter API v1.1 and complies with
the REST API Rate Limit.
It is developed using Javascript and
JQuery, Json2, OAuth and SHA-1 libraries.
Figure 8 shows the overall operation of k-subscription extension.
Upon installation, users can follow Twitter accounts in exactly the
same way, though Twitter’s web interface or “Follow me” buttons
in third-party web pages. To enhance user’s privacy, k-subscription
intercepts all follow requests and checks whether they correspond
to sensitive channels contained in S. If so, the extension transpar-
ently subscribes the user to k − 1 additional “noise” channels from
S according to the k-subscription-PROP algorithm, where k can
be conﬁgured by the user. These channels remain hidden and the
user never interacts with them, providing exactly the same Twitter
browsing experience as before. For this reason, the extension keeps
a list of all “noise” channels and dynamically ﬁlters out the unso-
licited tweets of these channels from user’s feed. Other affected
information, such as the number of channels followed, is adjusted
appropriately by excluding the effect of the “noise” channels.
At the ﬁrst run, the extension downloads the set S of sensitive
channels used for obscuring user’s selections. The set includes in-
twitter.com
Actual + Noise
Channels
k-Subscription
Actual Channels
Sensitive Channels
Set
https://twitter.com
Figure 8: Overall operation of the k-subscription browser ex-
tension for Twitter. Whenever a user follows a new sensi-
tive channel, k-subscription transparently follows additional
“noise” channels and removes the “noise” from user’s feed.
formation about each channel and its number of followers to im-
prove “noise” selection. The user can interfere with “noise” selec-
tion by proposing channels with predeﬁned features such as lan-
guage and country. Users can disable the effect of k-subscription
on a follow request if they consider the related channel as non-
sensitive. When a user unfollows a sensitive channel, the extension
transparently removes its corresponding “noise” channels as well.
We envision that the set of sensitive channels S along with the
project in general would be maintained by the broader community
of users and/or Non-Governmental Organizations (NGO) that have
a speciﬁc view towards protecting privacy. Hence, S can be seeded
by an initial set of sensitive channels and further improved through
human intervention and participation of the community. Similar
privacy-concerned projects, such as Tor, enlist the help of volun-
teers to maintain and improve its networks of routers. We expect
that similar approaches can be applied for k-subscription.
Although k-subscription is effective at hiding the channels a user
is interested in, a microblogging service may be able to ﬁnd the
user’s real preferences by collaborating with URL shortening ser-
vices. Users who click on a short URL are initially directed to the
URL shortening service (which may be operated by the microblog-
ging service, such as t.co in the case of Twitter) and then they are
redirected to the actual URL. By monitoring which short URLs a
user clicks, the microblogging service can learn the user’s interests.
We solve this problem within the k-subscription browser extension:
whenever a user clicks on a short URL, k-subscription opens all
short URLs posted in every channel the user follows. These URLs
are resolved to the ﬁnal destination URLs without the browser re-
ceiving a single byte from the targeted web pages. Then, the exten-
sion serves to the user only the actually requested URL. This way,
the microblogging service will not be able to see which URLs a
user clicks, as k-subscription transparently opens all of them.
6. EXPERIMENTAL EVALUATION
6.1 Environment and Dataset
For all our experiments we used a PC equipped with an Intel
Core 2 Duo Processor E8400 with 6MB L2 cache, 4GB RAM, and
an Intel 82567 1GbE network interface. To populate the set S with
sensitive channels we used Twellow [1], a web site that categorizes
Twitter accounts according to their subject. We created a set S with
7, 000 Twitter accounts dealing with health issues, political beliefs,
abuses, religious preferences and more.
55)
s
d
n
o
c
e
s
(
y
c
n
e
a
L
t
 140
 120
 100
 80
 60
 40
 20
 0
l
s
e
n
n
a
h
c
f
o
e
g
a
t
n
e
c
r
e
P
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
 0
 20  40  60  80  100  120  140  160  180  200
 0
 1
 2
 3
 4
 5
 6
 7
 8
k: Obfuscation level
Posts per hour
)
s
p
b
K
(
n
o
i
t
p
m
u
s
n
o
c
h
t
d
w
d
n
a
B
i
 50
 40
 30
 20
 10
 0
 25
 20
 15
 10
 5
 0
 6
 4
 2
 0
k=100
k=50
k=1
 0
 5
 10
 15
 20
 25
 30
Time (minute)
Figure 9: Time to follow a sensitive chan-
nel as a function of k.
Figure 10: Number of tweets posted per
channel per hour.
Figure 11: Bandwidth consumed for a
user receiving tweets as a function of time.
6.2 Adding Channels
In this ﬁrst set of experiments we set out to explore the delay
imposed by k-subscription when adding several noise channels in
order to follow and hide a sensitive channel the user is interested
in. Figure 9 shows how much time it takes to follow a sensitive
channel with k-subscription as a function of k, i.e., when also fol-
lowing k − 1 noise channels. We repeated our measurement for
each k 100 times with random choices, and we report the average
values. We see that the latency is an almost linear function of k, as
expected. Fortunately, the time to follow several tens of channels is
not signiﬁcant. Indeed, it takes a little more than 1 minute to follow
100 channels and around 2 minutes to follow 200 channels. Since
this operation is done only once, i.e., when a user wants to follow
a sensitive channel, we believe that it does not add any signiﬁcant
overhead. Moreover, this operation runs as a background process,
so it does not affect the user’s experience.
6.3 How Much Does the Noise Cost?
In our next experiment we tried to quantify how much more traf-
ﬁc is generated by the noise channels. To do so, we measured
the total number of tweets generated by all channels, divided by
each channel’s lifetime and found the average number of tweets
per channel per unit of time. The CDF of this function is shown in
Figure 10. We see that the median channel (y=50%) generates less
than one tweet (actually 0.25 tweets) per hour while 93% of the
channels generate less than two tweets per hour. Overall, we see
that the extra trafﬁc generated by the noise channels should be very
small. Even adding 100 noise channels generates no more than 25
tweets per hour, a negligible amount of trafﬁc by most standards.
The reader will notice that the maximum posting rate that we
have observed is about 6 posts per hour (averaged over the entire
lifetime of the channel). Published statistics [24] suggest that the
most proliﬁc twitter accounts post as much as one tweet update per
minute. Such accounts usually belong to news stations or even to
automated programs (bots). Given that each tweet corresponds to
just few hundred of bytes transferred over the network, even in such
cases the resulting network overhead will be relatively low.
6.4 Bandwidth Consumption
When a user follows k channels for each subscription, she down-
loads roughly k times more information than she actually needs.
However, we would like to see if the bandwidth needed for these
downloads can be sustained by a home DSL Internet connection or
not, and the respective network overhead in terms of used band-
A user interested in N sensitive channels will receive
width.
tweets from N × k channels. The network overhead will be the
same when a user is interested in one channel with N times higher
k value. Thus, we evaluate our system while varying only the k
parameter, assuming a user interested in a single channel. Fig-
ure 11 shows the trafﬁc load generated by our implementation over
a 30-minute period for a user following one sensitive channel with
k = 100, k = 50, and k = 1 (i.e, without using k-subscription).
We notice that the bandwidth consumption even in case of k = 100
is reasonably low, usually less than 1.5 Kbps. We see that even in
case of the vanilla system (see k = 1) the bandwidth consumption
is not signiﬁcantly lower than in high values of k. In all cases it
is usually between 0.5 and 1.0 Kbps. By manually inspecting the
trafﬁc we found that most of the bandwidth is used to download
information like images, trends and recommendations, which does
not depend on the value of k. The bandwidth used for downloading
the actual tweets, which increase with the value of k, was found to
be a small percentage of the total bandwidth consumption.
We observe a large spike at the beginning of each experiment,
when we have just opened the browser and loaded the Twitter page.
For instance, bandwidth consumption reaches 54 Kbps for k = 100,
29 Kbps for k = 50, and 7 Kbps for the vanilla system at the ﬁrst
second. During this initialization stage Twitter downloads all the
necessary content (widgets, scripts, CSS, proﬁle images, etc.). At
this stage, k-subscription downloads lot of tweets from all k chan-
nels. As we discard most of the tweets (belonging to noise chan-
nels) and keep only tweets from channels that a user is interested
in, we always download a larger chunk of tweets to be able to com-
pound the user’s actual timeline. For this reason we observe a rel-
atively higher spike as k increases. To improve browsing latency,
we transparently increase the page size to receive more tweets.
Note that proﬁle images are cacheable, so k-subscription down-
loads the additional images (depending on k) only once, without
affecting the overall bandwidth consumption. After the initial spike
in the ﬁrst few seconds, we see constantly low bandwidth consump-
tion, which correspond to the low rate of incoming tweets. The
average consumption in this 30-minute interval is 1.14 Kbps for
k = 100, 0.71 Kbps for k = 50, and 0.54 Kbps for k = 1. Overall,
we see that the total bandwidth consumed by k-subscription is not
really an issue even if the user follows as many as 100 channels.
To evaluate the effect of the obfuscation level on bandwidth con-
sumption while browsing Twitter with k-subscription, we plot in
Figure 12 the bandwidth consumption as a function of k for two
different stages: (i) when the user loads Twitter and downloads her
timeline, which consists of the latest 20 tweets from the channels
she is interested in, and (ii) when Twitter is idle and just receives
new incoming tweets for 30 minutes. We see that the overhead is
very low, even for large k, and can be easily handled by a home
DSL or even a mobile connection. The bandwidth consumption is
much lower in the idle stage, as expected, due to the low number
of tweets per second, as shown in Figure 10. The increased band-
width during initialization is because k-subscription asks for more
tweets to display the default page of 20 tweets only from channels
that user is interested in. However, the initialization lasts for just
few seconds, e.g., 7.7 seconds for k = 100 and 2.8 seconds for
the vanilla system. Thus, the increased bandwidth in Figure 12(a)
56)
s
p
b
K
(
n
o
i
t
p
m
u
s
n
o
c
h