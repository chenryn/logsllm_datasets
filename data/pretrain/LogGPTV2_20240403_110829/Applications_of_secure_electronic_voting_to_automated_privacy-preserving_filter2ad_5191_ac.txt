a1 = gr1 xd1
y
b1 = gr1s
g1
a2 = gw
b2 = gws
ťd1
If M = g1
w, r2, d2 ∈ Z
x = gr
y = grsg1
a1 = gw
b1 = gws
a2 = gr2 xd2
b2 = gr2są y
1
ćd2
d2 = c − d1
r2 = w − rd2
d1 = c − d2
r1 = w − rd1
x,y−→
a1,b1−→
c ?= d1 + d2
?= gr1 xd1
?= gr2 xd2
?= gr1s
y
g1
ş
?= gr2są y
a2,b2−→ a1
c←− a2
d1,d2−→ b1
r1,r2−→ b2
1
ťd1
ćd2
Figure 2: Zero knowledge proof that (x, y) = (gr, grs·
M ) where M = 1 or M = g1.
suﬃces to prove that an encrypted message (gr, grs · gm1
)
satisﬁes either m1 = 0 or m1 = 1, without revealing which
of the two is the case. In general, for a given value of C, the
proof requires transmitting C + 1 quadruplets (ai, bi, di, ri),
and expands the bandwidth requirement of the protocol by
a factor of 2C + 2.
1
If we transmit a vector of C2 encrypted messages as de-
scribed in Section 7, then we can transmit zero knowledge
proofs of validity for each component of a contributed vec-
tor, and apply the Shamir secret sharing scheme as described
in [10] to pick the challenges c in such a way that the va-
lidity of the vector as a whole can be veriﬁed (i.e., no more
than one component contains a vote). The total cost in
bandwidth remains 2C1 + 2 times that of the original unval-
idated vector, since the O(C2) cost factor is already reﬂected
in the size expansion of the original unvalidated vector.
Even if this bandwidth cost is too high to allow all of
the ﬁrst round data to be validated, it still makes sense
to perform retroactive validation of the top ranking entries
which appear in the second round (Section 9), since the
integrity of these entries is especially crucial to the success
of the troubleshooting request.
8.3 Zero Knowledge Proofs and Clustering
Zero knowledge validity proofs can be combined with clus-
tering by having each cluster member encrypt and sign the
N − 1 shares that it distributes to each of the N − 1 other
members of the cluster.
Instead of relying on the shared
keyholders’ encryption key, we require each member to gen-
erate a new encryption key from scratch in order to prevent
malicious keyholders from colluding with the cluster exit
and decrypting the encrypted values later. Since this en-
cryption key is diﬀerent from the encryption key used in the
homomorphic tally, the cluster member should also include
a zero knowledge proof that the encrypted share has the
same value as the unencrypted share, using the zero knowl-
edge equality proof of Figure 1. The recipients of each share
should then verify that the equality proof is correct—if it is
incorrect, then they should publish both the signed original
share and the signed encrypted share and proof, so that the
other cluster members can see that the proof is incorrect.
After verifying the equality proofs, the recipients forward
Figure 1: Zero knowledge proof that y = xr, given g
and gr
each. Using these parameters, the probability of any root
cause candidate triggering a simultaneous collision in all six
hash functions is under 5% for typical troubleshooting re-
quests. If we encode this list of 96 values using C1 = 3 and
C2 = 32, then a median troubleshooting request consisting
of 1171 suspect entries requires maintaining a list of ≈ 37000
atomic encryptions each representing three tallies.
8. ZERO KNOWLEDGE PROOFS
8.1 Proofs of Decryption
Certain portions of the protocol can take advantage of zero
knowledge proofs of validity to ensure that the encrypted
data values are not tampered with during aggregation. For
example, during the decryption phase, each keyholder must
divide the public key by some quantity x = gsi and the en-
crypted portion of the data by the quantity y = grsi . If the
previous and next nodes wish to verify that the keyholder is
performing a legitimate decryption operation (and not, for
example, altering the data values), they may combine their
shared knowledge of the pre-decryption and post-decryption
packets to infer what values of x and y were used in the de-
cryption phase. The keyholder can then execute the interac-
tive Chaum-Pedersen proof of knowledge protocol [6] given
in Figure 1 to prove that the values of x and y satisfy the
relation x = gsi and y = grsi , without revealing his private
key si. For practical applications, the Fiat-Shamir heuris-
tic [11] is used to implement the protocol non-interactively
by using pseudorandom hash functions to determine the val-
ues of the random inputs used in the interactive protocol.
8.2 Proofs of Validity
We now address the problem of proving validity of votes.
By “validity” we mean that each vote is syntactically valid
in the sense that it increments at most one component’s to-
tal by one. We do not attempt to guarantee that a valid
vote accurately reﬂects the actual internal conﬁguration of
the machine, since such a guarantee is impossible to achieve.
Therefore, the goal here is to allow participants to prove that
their contribution E(m) represents the encryption of a mes-
sage m = (m1, . . . , mC ) where at most one of the values mi
is 1 and the rest are 0, without revealing the values them-
selves. The generic construction of [10] provides a method
to transform the Chaum-Pedersen zero knowledge equality
protocol of Figure 1 into a zero knowledge proof of validity
for encrypted ballots of this form, at the cost of increasing
communications complexity by O(C). For example, if we
assume for simplicity that C = 1, then the interactive proto-
col of Figure 2 (or its non-interactive Fiat-Shamir analogue)
73the encrypted shares to the cluster exit and the cluster exit
combines the encrypted shares using the homomorphic prop-
erties of the encryption scheme to recover an encrypted ver-
sion of the original raw vote. The owner of this vote can then
provide a zero knowledge proof as in Section 8.2 to demon-
strate that this encrypted value represents a valid vote.
9. SECOND ROUND QUERY
The use of a hash function to digitize all entry values
means that the troubleshooting machine only knows the
hash of the most popular value of a top ranking, root-cause
candidate entry returned by the PeerPressure diagnosis (cf.
Section 2), and not the entry value itself. In order to com-
municate the actual most popular values of the top ranking
entries to the troubleshooter for the purpose of correcting
misconﬁgurations, we perform another round of queries us-
ing a Chaumian-style mixnet [5] to protect the identities of
the machines having those entries.
The second round uses the same clusters, keyholders, en-
trance and exit nodes as in the ﬁrst round. For each top
ranking, root-cause candidate entry e, the troubleshooter
queries the network asking for participants whose value for
entry e has a hash value equal to the known most popular
hash value of entry e. Those participants with the matching
hash value and who helped in the ﬁrst round convert their
actual entry values to integers Ve (using ASCII strings, say),
and Ve will be their contribution in the second round. All
other participants set their contribution to 0. Similarly to
the ﬁrst round, each cluster member ﬁrst generates and dis-
tributes random shares of its second round contribution to
every distinct cluster member. Each cluster member then
sums up all the shares that it has received, and encrypts this
subtotal m using the formula
E(m) = (gr, grs · m),
where r is chosen randomly and gs is the public key it used
in the ﬁrst round (for the i-th cluster, s = s0 + ··· + si).
If the length of m exceeds the length of grs, then we use
generic transforms such as CFB or CBC to convert a cipher
on a short block to one on a long block.
If m is shorter
than grs, then suitable padding such as OAEP is applied to
make it match grs in length. Finally, each cluster member
unicasts its encrypted subtotal to the cluster exit.
In addition, the cluster entrance modiﬁes each old en-
crypted message E(mold) = (grold , grold(s0+···+si−1) · mold)
that it has received from the previous hop to use the new
public key, and computes E0(mold) = (grold , grold(s0+···+si−1+si)·
mold) = (grold , grold·s · mold). As in the ﬁrst round, the
value E0(mold) constitutes a valid encryption for mold un-
der the new public key gs. The entrance then appends its
own subtotal, encrypted under the public key gs, and passes
the encrypted messages to the cluster exit. The set of all
encrypted messages from a cluster is collected into one large
packet and then passed to the next cluster, using the same
entrance and exit nodes as in the ﬁrst round.
In order to protect source anonymity, the troubleshooter
should initialize the second round query with a number of
randomly selected encrypted messages which will be dis-
carded upon conclusion of the query.
On the return path, each keyholder decrypts his share
of the secret key from each of the incoming messages as
in the ﬁrst round, and then passes the messages to the next
keyholder in randomly permuted order. We also require that
each decrypter re-encrypt the messages by transforming an
encrypted message (gr, grs·m) into an equivalent encryption
(gr+r0
, g(r+r0)s · m) for a randomly chosen value of r0, in
order to prevent other participants from correlating the gr
component of an encrypted message back to its originator.
If the decrypters do not re-encrypt, then the keyholder of
the last cluster in the chain (who is also the ﬁrst decrypter)
can store the previous cluster’s value of gr and collude with
the troubleshooter to determine which decrypted subtotal
corresponds to the previous cluster’s contribution.
In the ﬁnal step, the troubleshooter decrypts all the mes-
sages and recovers all the subtotals using its stored value of
s0. It then discards the random messages used to initialize
the second round request, and sums up all the decrypted
subtotals to obtain sume, which is an aggregate of the most
popular entry value Ve. The troubleshooter can compute
the most popular value Ve by dividing sume by the number
of helpers who contributed Ve in the second round, i.e., the
number of helpers whose entry e has a hash value match-
ing the most popular value. This number can be read from
the value distribution histogram that the troubleshooter re-
ceived in the ﬁrst round. The division result, interpreted as
an ASCII string, will be the most popular value for the top-
ranking suspect entry e, which can then be used to repair
the sick machine.
The eﬀect of this protocol is to implement a simple thresh-
old re-encryption mixnet guaranteeing data privacy, without
providing any integrity checks on the decryption process.
The techniques of Section 8 already protect the integrity of
the ﬁrst round hash values which determine the PeerPres-
sure diagnosis, and any node attacking the troubleshooter
with a data injection attack will not know the number of
helpers and hence at worse can only induce random faults
in the second round output, which can be easily recognized
and remedied by repeating the query (cf. Section 11.3).
A cluster exit participating in a troubleshooter attack (cf.
Section 3.2) could in principle fabricate all of the public
key data originating in the request path, and collude with
the keyholder to decrypt each member’s subtotal. Together
with the troubleshooter, they will be able to ﬁnd out the
aggregate value of Ve within their cluster. However, they
still cannot determine which individual member contributed
Ve if there is any. The forking mechanism of Section 11.2
can further reduce this threat of troubleshooter attacks.
10. RESOURCE USAGE
10.1 Bandwidth Overhead
If we assume the parameter values given at the end of
Section 7, then a median ﬁrst round troubleshooting request
of 1171 entries requires handling about 37000 ElGamal en-
cryptions, each one consisting of two elements of G. The
bit length of a request is therefore directly proportional to
the number of bits needed to represent an element of G.
Traditional ElGamal encryption uses a group G equal to
the multiplicative group of a ﬁnite ﬁeld, for which 512 bits
per group element is considered necessary for minimal secu-
rity, and 1024 bits for good security. At these group sizes,
an FTN request consisting of 37000 encryptions would be
about 4.8 MB in size for a 512 bit group, or 9.6 MB for a
1024 bit group. These estimates do not take into account
any extra overheads which would be incurred by zero knowl-
edge proofs.
74Using elliptic curve based ElGamal groups [19], we can
achieve the same level of security using fewer bits.
It is
estimated [20] that a 110 bit elliptic curve achieves crypto-
graphic security equivalent to that of a 512 bit ﬁnite ﬁeld,
and a 139 bit elliptic curve is comparable to a 1024 bit ﬁnite
ﬁeld. These group sizes result in FTN request sizes of 1.0
MB with 110 bit elliptic curves, or 1.25 MB with 139 bit
elliptic curves.
For the second round, if we use 1024 bits per suspect entry
and include the 20 top ranking suspect entries in the mixnet
then the total size of each user’s collection of encrypted en-
tries is 40∗1024 bits per user, for a ﬁnal accumulated packet
size of 1 MB assuming that 200 users participate in the
mixnet. Therefore, the packet size is comparable to the ﬁrst
round.
The above ﬁrst round and second round ﬁgures only ap-
ply to communications between cluster entrances, cluster ex-
its, and keyholders, and not to intra-cluster communications
within a single cluster. The latter transmissions do not need
encryption because the cluster-based secure multi-party sum
protocol already provides suﬃcient protection against pri-
vacy attacks. Accordingly, the bandwidth requirements for
communication within a single cluster remain the same as
in [15].
10.2 CPU Overhead
Recall from Section 7 that the tallying phase requires the
troubleshooter to recover, for each suspect value, a list of
C2 = 32 vectors each of the form m = (m1, m2, m3) where
mi ranges from 0 to the maximum number of participants in
an FTN request. If we assume no more than 255 participants
in a request, then each of the values mi ranges from 0 to 255
and we must recover the vector m = (m1, m2, m3) given the
quantity gm1
; this recovery must be done 32 times
per suspect value, or a total of ≈ 37000 times assuming a
median request size of 1171 candidate suspects.
2 gm3
1 gm2
3
We are mainly concerned with the amount of CPU time
needed to recover these 37000 vectors, since every other
computation required by the protocol is at least an order
of magnitude less time consuming than the recovery step.
Since there are 224 possible values for each m, and 37000
diﬀerent vectors m to recover, it would be too slow to re-
cover the vectors m by brute force trial and error. Instead
we use the baby-step-giant-step search algorithm from Sec-