aggregated risk occurrence probability ¯px
r shown in equation (4.1). If the individ-
ual occurrence probabilities px
r would
strongly depend on the number of services and data transfers. For px
rk = 0.5, the
aggregated ¯px
r of the risk to occur would be equal to or greater than 50%, 75%,
90%, 99%, and 99.9% for 1, 2, 4, 7, and 10 service components. Even for px
rk =
0.1, the aggregated occurrence probability ¯px
r would be larger than 90% for more
than 21 services or data transfers. In order to exclude this effect, based on the proof
shown in equations (4.11) to (4.18), the px
rk were not randomly drawn from [0; 1]
]. Using this formula, it is possible to specify the
resulting ˆpx
r regardless of the number of service components in the scenario. Please
note that this only holds true, if the parameter for the number of service or data
transfer invocations dx
In the following, we use a simpliﬁed notation, where |K| denotes the number
of components in a scenario and ˆp the targeted expected aggregated occurrence
probability for all risks. Additionally, we assume that all occurrence probabilities
are equal to p(cid:11), the adjusted occurrence probability deﬁned in equation (4.11). The
calculated aggregated occurrence probability for all risks ¯p (see equation (4.12);
deﬁned in equation (4.1)) can then be shown to be equal to the speciﬁed aggregated
risk occurrence probability ˆp:
k is not used for all components of the scenario.
(cid:8)
1− ˆpx
r
102
4 Risk Quantiﬁcation Framework
Table 4.2 Parameters used in Sensitivity Analysis
Variable
Number of services
Number of data transfers
Cost values cx
r
Expected aggregated probability ˆpx
Number of iterations I
Value-at-Risk Conﬁdence α
r 0.5
1,000
0.9
(cid:9)(cid:9)KS
(cid:9)(cid:9)
(cid:9)(cid:9)KT
(cid:9)(cid:9)
Default Value
500
500
∈ [1; 1,000]
p
:=1− |K|(cid:7)
(cid:6)
(cid:11)(cid:8)
1− ˆp
(cid:11)
1− p
¯p =1− ∏
=1−(cid:6)
(cid:11)(cid:8)|K|
k∈K
(cid:3)(cid:3)|K|
(cid:2)
(cid:2)
1− p
1− |K|(cid:7)
1− ˆp
1−
=1−
(cid:2)
(cid:3)|K|
1− 1 + |K|(cid:7)
=1−
1− ˆp
(cid:2)
(cid:3)|K|
|K|(cid:7)
=1−
=1− (1− ˆp)
= ˆp
1− ˆp
(4.11)
(4.12)
(4.13)
(4.14)
(4.15)
(4.16)
(4.17)
(4.18)
(cid:9)(cid:9)KS
(cid:9)(cid:9) +
(cid:9)(cid:9)KT
(cid:9)(cid:9) = 500 + 500 = 1,000, the cost values cx
If not stated otherwise, all simulation runs have been carried out using the
following parameter values: the number of scenario components has been ﬁxed
to 1,000, i. e., ∑x∈X |Kx| =
r
have been randomly drawn from [1; 1,000] (therefore, the ﬁxed expected ag-
gregated cost of risk r, ˆcx
r, the expected aggregated risk occurrence
probability, was ﬁxed to be 0.5 so that each risk, regardless of the number of
service components, had a chance of 50% to occur or not. The Value-at-Risk
was calculated with a conﬁdence α = 0.9. For each data point, we created 1,000
random scenarios, based on these parameters. Figures 4.6 to 4.8 are therefore
based on 81,000, 135,000 and 135,000 calculated probability density functions.
Table 4.2 lists the default values.
r = 500.5). ˆpx
Figure 4.6 shows that the Value-at-Risk (with α = 0.9) exceeds the expected
value (μ) as well as the standard deviation (σ), and that the difference between μ
and the Value-at-Risk gets bigger with every added risk. All three curves grow
4.2 Simulations
103
s
e
s
s
o
L
l
a
i
t
n
e
t
o
P
10,000
9,000
8,000
7,000
6,000
5,000
4,000
3,000
2,000
1,000
0
Average Value-at-Risk
Average μ
Average σ
 4
 6
 8
 10
 12
 16
 14
 20
Number of Total Risks R
 18
 22
 24
 26
 28
 30
Figure 4.6 Potential Losses Plotted Against the Number of Total Risks
linearly with the number of total risks R. The measured average μ of potential
losses can be approximated using equation (4.19):
Average μ ≈
∑
(x;r)∈{(X;Rx) | x∈X}
r · ¯cx
¯px
r
(4.19)
This means that every added risk increases μ by its expected aggregated occur-
r. If we would have used
rk instead of ﬁxed aggregated occur-
r for the sensitivity analysis simulations in this section, all
r = 1.0 because of the large number of services
r times its expected overall losses ¯cx
rence probability ¯px
ﬁxed individual occurrence probabilities px
rence probabilities ˆpx
risks r would have occurred with ¯px
and data transfers (i. e.,
(1− px
(cid:9)(cid:9)KS
(cid:9)(cid:9)KT
(cid:9)(cid:9) +
r = 1− ∏
rk) =1 − ∏
¯px
k∈Kx
k∈Kx
= 1− (1− 0.5)|Kx| = 1− 0.5500
≈ 1− 3× 10
−151 ≈ 1− 0 = 1
(cid:9)(cid:9) = 1,000):
(1− 0.5)
(4.20)
(4.21)
(4.22)
Since losses are the central object of IT risk management, in consequence, they
should be incorporated into the decision process in order to get an accurate pic-
ture of a scenario (McNeil et al., 2005, p. 35). Figure 4.6 shows that risk-neutral
decision makers loose information by only looking at the mean value of potential
losses and, therefore, neglecting the variance in the distribution of potential losses.
Instead of using only the μ-characteristic, risk management should be interested
104
s
e
s
s
o
L
l
a
i
t
n
e
t
o
P
f
o
μ
e
g
a
r
e
v
A
100,000
10,000
1,000
100
10
1
 4
4 Risk Quantiﬁcation Framework
 6
 8
 10
 12
 14
 16
 18
 20
 22
 24
 26
 28
 30
Number of Total Risks R
x
cr in [1; 1,000]
x
cr in [1; 10]
x
cr in [1; 10,000] 
x
cr in [1; 100]
x
cr in [1; 1]
Figure 4.7 Average Potential Losses Depending on the Magnitude of the Range of Different
Cost Values
in the probability of large losses and, thus, the upper tail of the distribution of
potential losses (McNeil et al., 2005, p. 26).
While a growing number of risks leads to an increase in the calculated μ,
the resulting increase of the Value-at-Risk characteristics is slightly stronger.
Therefore, looking at extremal values gets more important in larger scenarios.
Like shown in ﬁgure 4.6, the statistical spread increases with a growing number
of risks, which means that the uncertainty – and with it the “risk” associated with
the scenario – increases.
Table 4.3 lists the three probability density statistics μ, σ, and the Value-at-
Risk (with α=0.9), as well as the number of different cost values on the ﬁnally
resulting distribution’s x-axis (#c) for six different scenarios. The only difference
between each listed scenario is that one parameter is changed (i. e., arithmetically
doubled), while all other parameters remain equal. The “base” scenario uses the
following parameters: the number of risks R is set to 20, and the scenario consists
of 1,000 components in total2. The cost values for each risk cx
r are ﬁxed to 10. We
target an expected aggregated risk occurrence probability ˆpx
r of 0.1 in order to be
able to double the probability for the sensitivity analysis. If we would continue
2 Please note that the statistics remain the same, regardless of whether we use 1,000 services
with 1,000 service-related risks or a scenario with 500 services and 500 data transfers with 500
related risks each. The statistics for both alternatives are as shown in table 4.3 for the base sce-
nario.
4.2 Simulations
105
s
e
s
s
o
L
l
a
i
t
n
e
t
o
P
f
o
μ
e
g
a
r
e
v
A
16,000
14,000
12,000
10,000
8,000
6,000
4,000
2,000
0
x = 1.0
pr
x = 0.75
pr
x = 0.5
pr
x = 0.25
pr
x = 0.1
pr
 4
 6
 8
 10
 12
 16
 14
 20
Number of Total Risks R
 18
 22
 24
 26
 28
 30
Figure 4.8 Average Potential Losses as a Function of the Aggregated Risk Occurrence Proba-
bility
r = 0.5, arithmetical doubling would lead to ˆpx
using ˆpx
r = 1, which means that all
risks always occur, and, in consequence, there would be no statistical variance in
the distribution of potential losses.
The dependence of the average potential losses on the risks’ expected cost val-
ues is shown in ﬁgure 4.7. The ﬁve curves for the different magnitudes run parallel
on the log10-axis, which can again be explained using equation (4.19). For exam-
r leads to a tenfold increase of the average μ of the
ple, a tenfold increase of the cx
potential losses.
Comparison of the base scenario with the “double costs” scenario in table 4.3
shows that arithmetical doubling of the cost values leads to a doubling of all three
distribution characteristics μ, σ, and the Value-at-Risk. The number of values on
the x-axis (#c) remains the same for both scenarios and even the shape of the
distribution does not change.
Even with a doubling of the individual cost values cx
rk when dependent
losses are used, all risk characteristics are exactly doubled. This means that all
cost-related parameters do not change the shape of the distribution of potential
losses. Instead, they only affect the x-axis, i. e., if all of the risks’ expected cost
values are arithmetically doubled, than the x-axis is stretched by the factor two.
Likewise, if the potential losses of each risk can be reduced by one third, than all
values on the x-axis will shrunk by the same factor.
The steepness of the curves is inﬂuenced by the targeted expected aggregated
r = 0.5 (green)
r = 1.0 (red) and the x-axis. This means that
occurrence probability, ˆpx
runs exactly between the curve for ˆpx
r. Figure 4.8 shows that the curve for ˆpx
106
4 Risk Quantiﬁcation Framework
if a countermeasure can reduce all occurrence probabilities by half, the average μ
of the potential losses will be reduced by 50% accordingly.
The scenario “double components (with ﬁxed ˆpx
r)” in table 4.3 shows that the
introduced parameter ˆpx
r perfectly compensates the arithmetical doubling of the
number of scenario components. All risk characteristics are equal to the character-
istics of the “base” scenario.
r=0.1 are approximately 2.107 × 10−4
for 500 components, 1.0535 × 10−4 for 1,000 components and 5.2679 × 10−5
for 2,000 components. For the scenario “double probability” with 1,000 compo-
rk are approximately 2.2312× 10−4.
nents and px
Analogously to the simpliﬁed notation used for equations (4.11) to (4.18), it
can be shown that arithmetical doubling of the number of scenario components –
while ﬁxing the px
r (i. e., not readjusting the occurrence probabilities to the new
number of components) – leads to less than doubling of the aggregated occurrence
probability ¯pr
x. Some manipulation of equation (4.23) yields equation (4.28):
r=0.2, the calculated individual px
The calculated individual px
rk for px
Accordingly, for
(4.28)
ˆp=0.1 and |K|=1,000, an increase to |K(cid:11)|=2,000 scenario
components would lead to a calculated occurrence probability per risk of ¯p=0.19.
This, in combination with equation (4.19), explains the mean value μ of 38 for the
“double components (with ﬁxed px