[21] Google.
2019.
How you
sign
in with
2-Step Verification.
https://support.google.com/accounts/answer/1085463?hl=en.
[22] Google. 2020. Voice Match and media on Google Nest and Google Home speakers
and displays. https://support.google.com/googlenest/answer/7342711?hl=en.
[23] Tzipora Halevi, Di Ma, Nitesh Saxena, and Tuo Xiang. 2012. Secure proximity
detection for NFC devices based on ambient sensor data. In European Symposium
on Research in Computer Security. 379‚Äì396.
[24] Jun Han, Albert Jin Chung, and Patrick Tague. 2017. Pitchln: eavesdropping via
intelligible speech reconstruction using non-acoustic sensor fusion. In Proceedings
of the 16th ACM/IEEE International Conference on Information Processing in Sensor
Networks. 181‚Äì192.
[25] Matthieu H√©bert. 2008. Text-dependent speaker recognition. In Springer handbook
of speech processing. Springer, 743‚Äì762.
[26] Apple IOS. 2019. Siri. https://www.apple.com/ios/siri/.
[27] Dean M Karantonis, Michael R Narayanan, Merryn Mathie, Nigel H Lovell, and
Branko G Celler. 2006. Implementation of a real-time human movement classifier
using a triaxial accelerometer for ambulatory monitoring. IEEE transactions on
information technology in biomedicine 10, 1 (2006), 156‚Äì167.
[28] Tomi Kinnunen, Bingjun Zhang, Jia Zhu, and Ye Wang. 2007. Speaker verifi-
cation with adaptive spectral subband centroids. In International Conference on
Biometrics. Springer, 58‚Äì66.
[29] John Krumm and Ken Hinckley. 2004. The nearme wireless proximity server. In
International Conference on Ubiquitous Computing. 283‚Äì300.
[30] Johan Lindberg and Mats Blomberg. 1999. Vulnerability in speaker verification-a
study of technical impostor techniques. In Sixth European Conference on Speech
Communication and Technology.
[31] Logitech. 2018. Logitech S120 speaker. https://www.logitech.com/en-us/product/
s120-stereo-speakers.
[32] Yan Michalevsky, Dan Boneh, and Gabi Nakibly. 2014. Gyrophone: Recognizing
Speech from Gyroscope Signals. In USENIX Security Symposium. 1053‚Äì1067.
[33] K Sri Rama Murty and Bayya Yegnanarayana. 2006. Combining evidence from
residual phase and MFCC features for speaker recognition. IEEE signal processing
letters 13, 1 (2006), 52‚Äì55.
[34] Murray Newlands. 2017. THE TOP WEARABLE PAYMENT TECHNOLOGY.
https://due.com/blog/wearable-payment-technology/.
[35] Yao Qin, Nicholas Carlini, Ian Goodfellow, Garrison Cottrell, and Colin Raffel.
2019. Imperceptible, robust, and targeted adversarial examples for automatic
speech recognition. arXiv preprint arXiv:1903.10346 (2019).
[36] Douglas A Reynolds and Richard C Rose. 1995. Robust text-independent speaker
identification using Gaussian mixture speaker models. IEEE transactions on speech
and audio processing 3, 1 (1995), 72‚Äì83.
Secure Authentication With the Duo Mobile App.
https://duo.com/product/multi-factor-authentication-mfa/duo-mobile-app.
[37] Duo Security. 2019.
[38] Dave Singelee and Bart Preneel. 2005. Location verification using secure distance
bounding protocols. In IEEE International Conference on Mobile Adhoc and Sensor
Systems Conference. 7‚Äìpp.
[39] David Snyder, Daniel Garcia-Romero, Daniel Povey, and Sanjeev Khudanpur. 2017.
Deep Neural Network Embeddings for Text-Independent Speaker Verification. In
Interspeech. 999‚Äì1003.
[40] Statista. 2018. Number of connected wearable devices worldwide from 2016 to
2021. https://www.statista.com/statistics/487291/global-connected-wearable-
devices/.
[41] Keysight Technologies. 2018. Keysight Technologies 33509B. https://www.
alliedelec.com/keysight-technologies-33509b.
[42] Roberto Togneri and Daniel Pullella. 2011. An overview of speaker identification:
Accuracy and robustness issues. IEEE circuits and systems magazine 11, 2 (2011),
23‚Äì61.
[43] Niall Twomey, Tom Diethe, Xenofon Fafoutis, Atis Elsts, Ryan McConville, Peter
Flach, and Ian Craddock. 2018. A comprehensive study of activity recognition
using accelerometers. In Informatics, Vol. 5. Multidisciplinary Digital Publishing
Institute, 27.
[44] Ehsan Variani, Xin Lei, Erik McDermott, Ignacio Lopez Moreno, and Javier
Gonzalez-Dominguez. 2014. Deep neural networks for small footprint text-
dependent speaker verification. In 2014 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP). IEEE, 4052‚Äì4056.
[45] Kathryn Vasel. 2015. How your voice can protect you from credit card
fraud.
https://money.cnn.com/2015/11/02/pf/voice-biometrics-customer-
fraud/index.html.
[46] Chen Wang, S Abhishek Anand, Jian Liu, Payton Walker, Yingying Chen, and
Nitesh Saxena. 2019. Defeating hidden audio channel attacks on voice assistants
via audio-induced surface vibrations. In Proceedings of the 35th Annual Computer
Security Applications Conference. 42‚Äì56.
[47] Xiaohui Wang, Yanjing Wu, and Wenyuan Xu. 2016. WindCompass: Determine
Wind Direction Using Smartphones. In Sensing, Communication, and Networking
(SECON), 2016 13th Annual IEEE International Conference on. IEEE, 1‚Äì9.
[48] WeChat. 2017. Voiceprint. https://thenextweb.com/apps/2015/03/25/wechat-on-
ios-now-lets-you-log-in-using-just-your-voice/.
[49] Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen,
Shengzhi Zhang, Heqing Huang, XiaoFeng Wang, and Carl A Gunter. 2018. Com-
mandersong: A systematic approach for practical adversarial voice recognition.
In 27th {USENIX} Security Symposium ({USENIX} Security 18). 49‚Äì64.
[50] Hossein Zeinali, Luk√°≈° Burget, Jan ƒåernock`y, et al. 2019. A Multi Purpose
and Large Scale Speech Corpus in Persian and English for Speaker and Speech
Recognition: the DeepMine Database. arXiv preprint arXiv:1912.03627 (2019).
[51] Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and
Wenyuan Xu. 2017. DolphinAttack: Inaudible voice commands. In Proceedings
of the 2017 ACM SIGSAC Conference on Computer and Communications Security.
ACM, 103‚Äì117.
[52] Li Zhang, Parth H Pathak, Muchen Wu, Yixin Zhao, and Prasant Mohapatra.
2015. Accelword: Energy efficient hotword detection through accelerometer.
In Proceedings of the 13th Annual International Conference on Mobile Systems,
Applications, and Services. ACM, 301‚Äì315.
[53] Linghan Zhang, Sheng Tan, and Jie Yang. 2017. Hearing Your Voice is Not Enough:
An Articulatory Gesture Based Liveness Detection for Voice Authentication. In
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 57‚Äì71.
[54] Linghan Zhang, Sheng Tan, Jie Yang, and Yingying Chen. 2016. Voicelive: A
phoneme localization based liveness detection for voice authentication on smart-
phones. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 1080‚Äì1091.
A APPENDIX
(a) Spectrogram of microphone
(b) Spectrogram of wearable accelerome-
ter
Figure 1: Spectrogram of the single frequency signal (850Hz)
on microphone and wearable device (i.e., Huawei watch 2
sport).
(a) Correlation matrix
(b) CDF of the correlation
Figure 2: The time-domain correlation between the micro-
phone data and motion sensor, which are resampled to the
same sampling rate level (Illustrated with 10 words on Ama-
zon Echo and Huawei watch 2).
A.1 Difficulty of Comparing Microphone Data
with Motion Sensor Data
Figure 2 illustrates the difficulty of comparing the microphone
data with the motion sensor data, where a participant speaks ten
246810Microphone: Word Index246810Motion Sensor: Word Index00.050.10.1500.20.40.60.81Correlaiton coefficient00.20.40.60.81PercentageEmpirical CDFSame Word SoundDifferent Word SoundACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Cong Shi, Yan Wang, Yingying Chen, Nitesh Saxena, and Chen Wang
sound) and non-diagonal (i.e., different word sounds) are indistin-
guishable. The results indicate that the re-sampling technique and
the time-domain analysis are insufficient to address the similarity
comparison of the two different sensing modalities. Figure 2(b),
CDF of the correlation coefficients, further depicts the challenge of
matching the sound across the two domains, where the sound of
the same word and those of different words all show low correlation
values (i.e., less than 0.1). Thus, we need to investigate the inherent
unique relationship between the two sensing modalities to facilitate
their similarity comparison.
A.2 Examples of the Voice Commands
We evaluate WearID with 20 representative voice commands that
involve highly sensitive information or functionalities. The voice
commands could be used by an adversary to access sensitive infor-
mation or functionalities. Particularly, the adversary could acquire
private information (e.g., schedule, password, email, contact list) of
users. With these voice commands, they may also conduct unau-
thorized purchases or manipulate smart home devices. Note that
we use voice commands of different lengths since to examine the
generality of WeaID.
Figure 3: Directly converting the microphone data of a fre-
quency chirp (0 ‚àº 4ùêæùêªùëß) into the low frequency data.
words to both a microphone and a accelerometer, and both data
are re-sampled to the same sampling rate for similarity compari-
son. Particularly, Figure 2 (a) shows the time-domain correlation
coefficient between the microphone recorded sound (i.e., X axis)
and motion sensor data (i.e., Y axis) by cross-comparing ten words.
We observe that the correlations at the diagonal (i.e., same word
0.511.522.533.54Sound Frequency (KHz)020406080100120140Motion Sensor Frequency (Hz)AccelerationConverted MicrophoneWearID
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Table B: Representative words in voice commands.
ID Word
1
2
3
4
5
Tomorrow
Answer
Weather
Instrument
Information
ID Word
6
7
8
9
10
Good morning
Request
Country music
Spotify
Next Appointment
ID Word
Events
11
12
Remember
Password
13
Flight
14
15
New York
Team information
Shopping list
Living room camera
ID Word
16
17
18
19 Weekend forecast
20
Flash Briefing
Table C: Example of privacy leakages from voice assistant systems.
Security issues
Category
Event schedule
Potential privacy leakage
Reminder
Shopping account information
Contact
Neighborhood location
Unauthorized purchase
Voice assistant
Access smart home devices
Unauthorized operation
Voice Command Examples
"What‚Äôs on my calendar for tomorrow"
"Where is my next appointment"
"List all events for January 1st"
"How much is a round-trip flight to New York"
"Remember that my password is ‚Äômoney‚Äô"
"What is my password"
"Add ‚Äôgo to the grocery store‚Äô to my to-do list"
"What‚Äôs on my shopping list"
"Track my order"
"Read me my email"
"Call my mother"
"Find me a Italian near my home"
"What is the traffic to my home"
"Add paper towels to my cart"
"Order all items in my cart"
"Answer the call"
"Delete all my reminders"
"Play my favorite music on Spotify"
"Show the living room camera"
"Clear all Bluetooth devices"
Sentence Length
6
5
6
9
6
4
10
5
3
4
3
7
7
6
6
3
4
6
5
4