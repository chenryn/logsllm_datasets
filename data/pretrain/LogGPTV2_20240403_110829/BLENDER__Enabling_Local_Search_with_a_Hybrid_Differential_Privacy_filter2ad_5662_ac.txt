9: let ˆrC , ˆpC , ˆσ2
10: for q ∈ HL do
11:
let ˆrC,q be the fraction of queries q in DC .
ˆpC,q =
ˆrC,q− 1−t
k−1
t− 1−t
k−1
1
k−1
(cid:0)t− 1−t
(cid:1)2
ˆσ2
C,q =
for u ∈ HL[q] do
ˆrC,q (1−ˆrC,q )
|DC|−1
12:
13:
14:
15:
16:
17:
let ˆrC,(cid:104)q,u(cid:105) be the fraction of records which
are (cid:104)q, u(cid:105) in DC .
ˆpC,(cid:104)q,u(cid:105) =
ˆσ2
C,(cid:104)q,u(cid:105)
(cid:0)
2|DC|
|DC|−1
1−t
(k−1)kq
(cid:0)
(k−1)kq
− (1−t)(1− ˆpC,q )
ˆrC,(cid:104)q,u(cid:105)− (1−tq )t ˆpC,q
kq−1
t(tq− 1−tq
kq−1 )
|DC|−1
kt−1
(cid:16) ˆrC,(cid:104)q,u(cid:105)(1−ˆrC,(cid:104)q,u(cid:105))
(cid:1)(cid:0) k−2+t
(cid:17) ·
(cid:1)2 ˆσ2
t2(cid:0)tq− 1−tq
=
1−t
(k−1)kq
− t−ttq
kq−1
− t−ttq
kq−1
(cid:1)ˆrC,(cid:104)q,u(cid:105)+
(cid:1)2
C,q
+
1
kq−1
client.
• , δ: the diﬀerential privacy parameters.
• mC : the number of records to collect from the
• fC : the fraction of the privacy budget to allo-
cate to reporting queries.
• HL: the head list, represented as a map keyed
by queries {q1, . . . , qk, (cid:63)}. The value for each
q ∈ HL is deﬁned as HL[q] = {u1, . . . , ul, (cid:63)},
representing all URLs in the head list associ-
ated with q.
Body
1: let DC,i be the database aggregating at most mC
records from current client i.
2: (cid:48) = /mC , and δ(cid:48) = δ/mC .
U = (cid:48) − (cid:48)
3: (cid:48)
Q = fC (cid:48), (cid:48)
δ(cid:48) − δ(cid:48)
Q.
exp((cid:48)
Q = fC δ(cid:48), δ(cid:48)
U =
Q/2)(k−1)
Q and δ(cid:48)
Q)+(δ(cid:48)
exp((cid:48)
Q)+k−1
.
U )+(δ(cid:48)
exp((cid:48)
U /2)(kq−1)
U )+kq−1
.
kq = |HL[q]|, and tq = exp((cid:48)
Set q = (cid:63).
if q (cid:54)∈ HL then
if u (cid:54)∈ HL[q] then
With probability (1 − t),
4: k = |HL|, and t =
5: for each q ∈ HL do:
6:
7: for each (cid:104)q, u(cid:105) ∈ DC,i do
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
With probability (1 − tq),
Set u = (cid:63).
let q(cid:48) be a unif. random query from HL \ q.
let u(cid:48) be a unif. random URL from HL[q(cid:48)].
report (cid:104)q(cid:48), u(cid:48)(cid:105).
continue
let u(cid:48) be a unif. random URL from HL[q]\u.
report (cid:104)q, u(cid:48)(cid:105).
continue
report (cid:104)q, u(cid:105).
18: return ˆpC , ˆσ2
C .
Figure 6: Algorithm executed by each client for privately re-
porting their records.
Figure 5: Algorithm for estimating probabilities of records in the
head list from the locally privatized reports of the client users.
signiﬁcantly larger than the number of URLs asso-
ciated with any query, and hence allocating a larger
portion of the privacy budget to the query-reporting
stage is a prudent choice.
The process of local privatization of each client’s
value (Figure 6) follows the strategy of the Exponen-
tial mechanism introduced by [30]. The privatiza-
tion algorithm reports the true value with a certain
bounded probability, and otherwise, randomizes the
answer uniformly among all the other feasible values.
The fact that the head list (approximating the set
of the most frequent records) is available to each
client plays a crucial role in improving the utility
of the data produced by this privatization algorithm
compared to the previously known algorithms oper-
ating in the local privacy model. Knowledge of the
head list allows dedicating the entire privacy budget
to report the true value, rather than having to allo-
cate some of it for estimating an analogue of the head
list, as done in [15, 34]. Another distinction from the
Exponential mechanism designed to improve utility
is utilization of δ.
The choices of mC and fC are not related to pri-
vacy constraints, and can be made by Blender’s
developer to optimize utility goals, as will be dis-
USENIX Association
26th USENIX Security Symposium    753
cussed in Section 4.2.1.
The local nature of the privatization algorith, i.e.,
the use of a randomization procedure that can re-
port any record with some probability, induces a pre-
dictable bias to the distribution of reported records.
The removal of this bias, which we refer to as denois-
ing (discussed further in Section 3.2), results in the
proper probability estimates ˆpC (Figure 5). These
probability estimates along with the variance esti-
mates are then passed to the BlendProbabilities
part of Blender.
The technical discussion of the algorithm’s privacy
properties, the denoising procedure and variance es-
timate computations follow in Sections 3.2 and 3.3.
Algorithm for Blending (Figure 7): The blend-
ing portion of Blender combines the estimates pro-
duced by the opt-in and client probability-estimation
algorithms by taking into account the sizes of the
groups and the amount of noise each sub-algorithm
added. This produces a blended probability esti-
mate ˆp which, in expectation, is more accurate than
either group produced individually. The procedure
for blending is not subject to privacy constraints, as
it operates on the data whose privacy has already
been ensured by previous steps of Blender. The
motivation and technical discussion of blending fol-
lows in Section 3.3.
BlendProbabilities(ˆpO, ˆσ2
Parameters:
O, ˆpC , ˆσ2
C , HL)
• ˆpO, ˆpC : the probability estimates from the opt-in
and client algorithms.
• ˆσO, ˆσC : the variance estimates from the opt-in and
client algorithms.
• HL: the head list of records.
Body
1: let ˆp be a vector indexed by records in HL.
2: for (cid:104)q, u(cid:105) ∈ HL do
ˆσ2
C,(cid:104)q,u(cid:105)
3:
O,(cid:104)q,u(cid:105)+ˆσ2
ˆσ2
w(cid:104)q,u(cid:105) =
ˆp(cid:104)q,u(cid:105) = w(cid:104)q,u(cid:105) · ˆpO,(cid:104)q,u(cid:105) + (1− w(cid:104)q,u(cid:105))· ˆpC,(cid:104)q,u(cid:105).
5: Optional: Project ˆp onto probability simplex (e.g.,
C,(cid:104)q,u(cid:105)
4:
.
see [39]).
6: return ˆp.
Figure 7: Algorithm for combining record probability estimates
from opt-in and client estimates.
3 Technical Detail Summary
We now present further technical details related
to the instantiations of the sub-algorithms for
Blender, such as statements of privacy properties
and the motivation for BlendProbabilities.
3.1 Opt-in Data Algorithms
Diﬀerential privacy of the algorithms handling opt-
in client data follows directly from previous work.
Theorem 1. ([24]) CreateHeadList guarantees
(, δ)-diﬀerential privacy if mO = 1,  > ln(2), and
τ ≥ 1.
Theorem 2. ([10]) EstimateOptinProbabili-
ties guarantees (, 0)-diﬀerential privacy if mO = 1.
3.2 Client Data Algorithms
LocalAlg is responsible for the privacy-preserving
perturbation of each client’s data before it gets sent
to the server, and EstimateClientProbabilities
is responsible for aggregating the received privatized
data into a meaningful statistic. We present the
privacy statement and explain the logic behind the
aggregation procedure next and prove them in Ap-
pendix A.
Theorem 3. LocalAlg is (, δ)-diﬀerentially pri-
vate.
Denoising: The reports aggregated by the client
mechanism form an empirical distribution over the
records (and queries). Relative to the true under-
lying record distribution, this distribution is biased
in an explicit and publicly-known way, as described
by the reporting process. Thus, we seek to obtain
an unbiased estimate of the true record distribution
from this reported distribution. Concretely, we re-
fer to this as denoising the reported empirical dis-
tribution ˆrC to obtain the ﬁnal estimate from the
client algorithm, ˆpC. The denoising procedure relies
only on the publicly-known reporting process as well
as the already-privatized reports. Thus, this can be
considered a post-processing step, which has no nega-
tive impact on the diﬀerential privacy guarantee [11]
yet signiﬁcantly improves utility.
Observation 1. ˆpC gives the unbiased estimate
of record and query probabilities under Estimate-
ClientProbabilities.
3.3 Blending
The opt-in algorithm and the client algorithm both
output independent estimates ˆpO and ˆpC of the
record distribution p. The question we address now
is how to best combine these estimates using the in-
formation available.
A standard way to measure the quality of an esti-
mate is by its variance. Although it may seem natu-
ral to choose the estimate with lower variance as the
754    26th USENIX Security Symposium
USENIX Association
ﬁnal estimate ˆp, it is possible to achieve a better esti-
mate by jointly utilizing the information provided by
both algorithms. This is because the errors in these
algorithms’ estimates come from diﬀerent, indepen-
dent sources. The error in the estimates obtained
from the opt-in algorithm is due to the addition of
noise, whereas the error in the estimates obtained
from the client algorithm is due to randomization of
the reports over the set of records in the head list.
Thus, if we determine the variances of the estimates
obtained from the two algorithms, we can use these
variances to blend the estimates in the best way.
More formally, for each record (cid:104)q, u(cid:105) let σ2
O,(cid:104)q,u(cid:105)
and σ2
C,(cid:104)q,u(cid:105) be the variances of the opt-in and client
algorithm’s estimates of ˆpO,(cid:104)q,u(cid:105) and ˆpC,(cid:104)q,u(cid:105) respec-
tively. Since these variances depend on the underly-
ing distribution, which is unknown a priori, we will
compute sample variances ˆσ2
O,(cid:104)q,u(cid:105) in-
stead. For each record (cid:104)q, u(cid:105), we will weigh the esti-
mate from the opt-algorithm by w(cid:104)q,u(cid:105) and the esti-
mate from the client algorithm by (1−w(cid:104)q,u(cid:105)), where
w(cid:104)q,u(cid:105) is deﬁned as in line 3 of BlendProbabili-
ties. The optional step of projecting the blended
estimates (e.g., as in [39]) ensures that the estimates
sum to 1 and are non-negative.
O,(cid:104)q,u(cid:105) and ˆσ2
Theorem 4 presents our computation of the sam-
ple variance of EstimateOptinProbabilities,
Theorem 5 presents our computation of the sample
variance of EstimateClientProbabilities, and
Theorem 6 motivates the weighting scheme used in
BlendProbabilities. Their proofs are presented
in Appendix B.
For the variance derivations, we make an explicit
assumption that each piece of reported data is drawn
independently and identically from the same under-
lying distribution. This is reasonable when compar-
ing data across users. By setting mO = mC = 1,
we remove the need to assume iid data within each
user’s own data, while simplifying our variance com-
putations. We show in Section 4 that Blender
achieves high utility even when mO = mC = 1.
Theorem 4. When mO
ased
inProbabilities
variance
estimate
(cid:18) ˆpO,(cid:104)q,u(cid:105)(1− ˆpO,(cid:104)q,u(cid:105))
can
ˆσ2
O,(cid:104)q,u(cid:105) =
|DT |
|DT |−1
|DT |
(cid:16) bT|DT |
+ 2
= 1
the unbi-
for EstimateOpt-
be
as:
computed
(cid:17)2(cid:19)