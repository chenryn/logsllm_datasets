网络系统设计和实施研讨会的议事录*中。用前面提到的标识服务为例。应用程序可以假定具有已验证的特定标头的任何请求，而不是直接调用标识服务。标头可以包含客户端具有的范围和访问权限。标识中间件消除了从上游服务中调用外部服务的延迟和复杂性开销。
## 服务级别中间件的 API
  除了最微不足道的中间件之外的所有中间件都需要一些特定于应用程序的配置（例如，在特定页面上指定不同的缓存键）。直接的解决方案可能是在中间件代码库中对此配置进行硬编码。但是，随着时间的推移，硬编码的配置可能会偏离现实并导致本可避免的中断。
为了防止发散，建立明确的 API 非常重要，通过这些
API，应用程序可以不断与下游中间件通信。你可以使用自定义 HTTP
请求和响应标头作为通信总线，而配置是经过此渠道的。对于不适合请求/响应流的数据，可以使用带外消息总线将状态传播到所有负载均衡器。
## 案例研究：WAF/Bot 缓解
将 Web
服务作为分布式拒绝服务（DDoS）攻击的目标，或通过机器人进行自动抓取只是个时间问题。Kandula，Srikanth等（2005年）。["Botz-4-Sale：能够模仿Flash群体的有组织的DDoS攻击"](https://www.usenix.org/legacy/publications/library/proceedings/nsdi05/tech/kandula/kandula.pdf)。引自USENIX网络系统设计与实现研讨会论文集。DDoS
攻击可能导致严重的故障，也会带来漫长的服务停顿。机器人自动攻击往往导致真正的客户严重不满。你可以使用可编写脚本的负载平衡器来构建针对这些威胁的保护层，并在所有面向
Web 的服务上使用它们，而不必在每个应用程序中开发相同的反机器人或 DDoS
处理工具。Majkowski，Marek（2016）。"构建 DDoS 防空洞。"在 Enigma
上发表的演讲。
Cloudflare 已经建立了一个业务，通过 Web
应用程序防火墙功能提供这样一层保护。其中间件背后的任何服务都享有针对开放
Web 应用程序安全项目 （OWASP）漏洞、常见 DoS 攻击和 Zero-day
漏洞的保护。当请求的危险或真实性不明确时，中间件能够重定向请求到质询响应测试页面，以验证请求是否来自合法来源。
以前，保护应用程序层以下的攻击需要根据单个数据包的范围做出决策，而可编写脚本的负载均衡器允许您在分析整个事务后做出决策。现在，你可以优化用户体验，同时保持服务安全。最重要的要点是
WAF 中间件（如 Cloudflare
提供的中间件）允许将工作集中到单一服务中，从该服务中为多个应用程序提供保护。  
# 避免灾难
 在定义 SLO 时，它们通常关注服务的内部故障。 倒推 SLA
这个想法是最近出现的，也就是说为了获得服务的准确
SLO，必须考虑服务所依赖的所有直接（如数据库）和间接（如互联网路由）组件。Nygard，Michael
T（2007）。"SLA倒置。"引自发布、设计和部署生产就绪软件（O\'Reilly）。
在许多体系结构中，负载平衡层由多个应用程序和服务共享。负载平衡器中的任何问题都会影响*所有*上游应用程序的
SLO。鉴于这一现实，重点是在脚本化负载均衡器上保持高水平的弹性。
由于可编写脚本的负载均衡器具有众多优势，因此很容易使用逻辑重载负载均衡器。负载平衡器作为从一个强大的解决方案，特别适合困难的问题，如同正在寻找钉子的锤子。与所有体系结构一样，放置在可编写脚本的负载均衡器中的逻辑不会添加单点故障（或对可用性产生负面影响），这一点很重要。当你使用可编写脚本的负载均衡器时，一个特别危险的陷阱是管理失误。本章的其余部分将讨论如何最好地处理边缘状态。
## 获得状态的技巧
 通过前面的示例，我们已经看到了可编写脚本的负载均衡器的强大功能。尽管过去的示例侧重于单个请求，但实际上，当客户与我们的服务交互时，它通常是通过一系列我们通常称为会话的请求（例如，客户进店浏览商品、将商品添加到购物车，然后转到结帐）。
为了能够正确推理请求，了解请求的上下文非常重要。对缓慢加载页的单个请求可以像往常一样处理，而快速连续的
100 个请求则很可能是 DoS
攻击。存储状态允许你区分这两种情况。如果存储和访问状态的逻辑没有谨慎的对待，则单点故障会导致许多用户感到服务不稳定，或急剧增加复杂性。
负载均衡器通过访问共享的数据库来了解环境现状，数据库就是现实世界的表现形式。如果每个负载均衡器在每个请求上都与同一个数据库交谈，并且此数据库提供一致的保证，我们将对环境有一个完美的模型。如果进程、节点和数据中心的数量不断扩大，这样的模型将导致不切实际的开销和延迟成本。因此，实际上往往通过某种方式来避开这类完美模型。
 我们以限流机制为例。正如[#each_request_is_registered_in_a\_database](#each_request_is_registered_in_a_database)所示，节流阀将请求传递到特定限制达给定时间量，并阻止所有后续请求直到下一个时间段。这种节流通常需要在所有潜在的节流点之间共享一致的单个原始数据。
![每个请求都注册在由多个负载均衡器共享的数据库中。](media/rId52.png){width="2.8394641294838143in"
height="1.7959864391951006in"}
每个请求都注册在由多个负载均衡器共享的数据库中。
将计数器存储在共享数据存储中的替代方法是将计数器存储在每个负载均衡器上，如[#requests_are_only_registered_on_the_load](#requests_are_only_registered_on_the_load)中所示，但将最大节流大小除以接收请求的负载均衡器的数量。如果单个负载均衡器达到限制，则所有其他负载均衡器也可能达到相同的限制。这样我们虽然失去了精确度，但是获得了弹性。
![请求仅在接受请求的负载均衡器上注册。](media/rId53.png){width="2.6321062992125985in"
height="1.7926410761154856in"}
请求仅在接受请求的负载均衡器上注册。
## 案例研究：结帐队列
    在线购物网站将具有类似于实体店的结账队列的任务排队，以确保在大吞吐量写入（例如销售）发生期间服务不会失败。
Shopify
必须实施这样的结账队列，以处理由知名商家带来的大量闪购。解决这类问题的本能方法是将队列存储在数据库中，所有负载均衡器都可以访问该数据库。队列必须存储所有通过购物车结账的客户的订单。但是，这样的数据库队列增加了另一个潜在的故障源并增加了复杂性。
Shopify
实现了与队列类似的优先限制，而不是将客户队列存储在多个负载平衡节点之间共享的数据库中。这是在没有共享数据库的情况下完成的，只有签出队列条目时间戳，与某些会话状态配对，通过签名的
Cookie 存储在每个客户的浏览器中。
每个负载均衡器都有一个流控模块（类似于我们前面介绍的），用来决定是否有足够的容量供客户结账。客户首次尝试结帐时，会为其分配签出输入时间戳。如果服务过载，客户将在队列页面上等待后台轮询。[#request_flow_of_a\_customer_attempting_to](#request_flow_of_a_customer_attempting_to)说明了客户通过限制结帐流程的流程。
![请求客户尝试结账、受到限制，然后最终通过队列的流。](media/rId55.png){width="4.073578302712161in"
height="3.618728127734033in"}
请求客户尝试结账、受到限制，然后最终通过队列的流。
每次轮询时，各个负载均衡器会修改其对队列长度的视图。他们通过更新内部节点时间戳来做到这一点，该时间戳决定是否允许客户通过流控并转入结账模块。节点时间戳使用比例、积分、微分（PID）控制器进行修改，该控制器旨在最大化传递给节流阀的请求数，而不超过其限制。随着对如何以及存储状态的思考的轻微转变，具有更好弹性的脚本化负载平衡器的合适解决方案呈现出来。     
# 展望未来，进一步阅读
 与所有新技术一样，可编写脚本的负载均衡器并不完美。向负载平衡层添加逻辑是一把双刃剑。如果不努力提高其韧性，那么后果可能是灾难性的，会导致我们支持的应用程序的可用性降低。成为新事物的一个副产品是，对最佳实践没有明确的共识。
尽管常有磕磕碰碰，但脚本化的负载均衡器无可置疑的提高了系统的韧性和性能。脚本化的负载均衡器非常有机会成为关注点，并成为每个
SRE 中意的常用工具。我希望这一章能说服你尝试一下。  
如果你喜欢本章中的示例，我鼓励你更多地了解它们。Scott Francis 在
NginxConf 的演讲"使用 NGINX 和 Lua 构建 HTTP
请求路由器"，详细介绍了在使用 OpenResty 在 Nginx
中构建分片路由层的问题。约翰·格雷厄姆-库明和马雷克·马伊科夫斯基也曾多次谈到
Cloudflare 如何使用可编写脚本的负载均衡器实现其 WAF 系统。格雷厄姆
约翰（2014）["使用 Lua 在 NGINX 内部构建低延迟
WAF"](https://www.youtube.com/watch?v=nlt4XKhucS4)。在 NginxConf
的讲座。^,^马伊科夫斯基，马雷克（2016） ["构建 DDoS
防空洞"。](https://www.usenix.org/node/193951)在 Enigma
的讲座。暂停服务，请求暂停的示例，灵感来自由 Basecamp
构建的同名项目。暂停服务。最后，我在"使用脚本化的负载平衡器保持高写流量避险"中，对签出队列限制机制的工作原理进行了更深入的介绍。斯托拉斯基，埃米尔（2017）.
["使用脚本化的负载平衡器保持高写流量避险，第二部分"](https://shopifyengineering.myshopify.com/blogs/engineering/surviving-flashes-of-high-write-traffic-using-scriptable-load-balancers-part-ii)。博客文章。
对于负载均衡器这个主题的更一般资源，看看 Vivek Panyam 写的"扩展 Web
服务：负载平衡"Panyam，Vivek（2017）不会出错。["扩展 Web
服务：负载平衡"](https://blog.vivekpanyam.com/scaling-a-web-service-load-balancing/)。马特·克莱因的《现代网络负载平衡与代理简介》，克莱因，马特（2017年）。[现代网络负载平衡和代理简介。](https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236)和*的云系统管理实践：Web服务的
DevOps 和 SRE
实践*中"应用程序体系结构"那一章。利蒙切利、托马斯·阿等人（2014年）。"应用程序体系结构"。在*云系统管理实践中：Web
服务的 DevOps 和 SRE 实践。*波士顿：Addison-Wesley Professional。
# 编者介绍
Emil Stolarsky 是一位基础设施工程师，对负载平衡器、性能和 DNS
工具充满热情。当他不分析性能图时，你可以发现他正在听
Flume，并和他在附近的攀岩健身房里对抗对高度的恐惧。