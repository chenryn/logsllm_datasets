lie on the same degree-t polynomial, and if yes outputs it. As long as more
than t parties are honest, this interactive protocol guarantees that if [v]t is
not correct (see formal deﬁnition below), then Pi will output ⊥ and abort.
Otherwise, if [v]t is correct, then Pi will either output v or will abort.
– open([v]t) or open([v]2t): This procedure is the same as reconstruct, except
that all parties receive the shares. Thus, naively, once can deﬁne open([v]t)
as the execution of reconstruct([v]t, i) for every i = 1, . . . , n. This is expensive
since each party sends n elements overall. As shown in [3], in the ReconsPub
procedure, it is possible to run open in parallel on n − t sharings of degree-t
at the same cost. Thus, for t < n/3 each party sends n elements in order to
open 2n/3 degree-t sharings, at an average cost of 1.5 elements per opening.
Likewise, each party sends n elements in order to open n/3 degree-2t shar-
ings, at an average cost of 3 elements per opening. It is possible to run open
on sharings of degree-2t since there are 2t + 1 honest parties in our case, and
thus it is possible to detect (but not correct) any cheating.
– Local operations: We denote by [x] + [y] and c· [x] the local operation of each
party adding its share in x with its share in y, and multiplying its share in x
with a scalar c, respectively. These operations always result in valid sharings
of the result, since they are local operations only, and these can be carried
out on degree-t and degree-2t sharings.
We also denote by [x]· [y] the local operation of a party multiplying its share
in x with its share in y. Note that in this case, the result is not a valid
sharing of the same degree. However, it does hold that [x]t · [y]t = [x · y]2t.
2.2 Deﬁnition of Security
The security parameter is denoted κ; negligible functions and computational
indistinguishability are deﬁned in the standard way, with respect to non-uniform
polynomial-time distinguishers.
Ideal versus real model deﬁnition. We use the ideal/real simulation paradigm
in order to deﬁne security, where an execution in the real world is compared to
an execution in an ideal world where an incorruptible trusted party computes
the functionality for the parties [5,16]. We deﬁne security with abort (and with-
out fairness), meaning that the corrupted parties may receive output while the
honest parties do not. Our basic deﬁnition does not guarantee unanimous abort,
meaning that some honest party may receive output while the other does not. It
is easy to modify our protocols so that the honest parties unanimously abort by
running a single (weak) Byzantine agreement at the end of the execution [17];
we therefore omit this step for simplicity.
As we describe at the end of Section 6, our protocol is easily extended to
guarantee fairness. The basic deﬁnition can be modiﬁed to include fairness, as
will be described below.
6
The real model. In the real model, a n-party protocol π is executed by the parties.
For simplicity, we consider a synchronous network that proceeds in rounds and a
rushing adversary, meaning that the adversary receives its incoming messages in a
round before it sends its outgoing message.3 The adversary A can be malicious; it
sends all messages in place of the corrupted parties, and can follow any arbitrary
strategy. The honest parties follow the instructions of the protocol.
Let A be a non-uniform probabilistic polynomial-time adversary controlling
t < n
3 parties. Let realπ,A(z),I (x1, . . . , xn, κ) denote the output of the honest
parties and A in an real execution of π, with inputs x1, . . . , xn, auxiliary-input
z for A, and security parameter κ.
The ideal model. We deﬁne the ideal model, for any (possibly reactive) func-
tionality F, receiving inputs from P1, . . . , Pn and providing them outputs. Let
I ⊂ {1, . . . , n} be the set of indices of the corrupted parties controlled by the
adversary. The ideal execution proceeds as follows:
– Send inputs to the trusted party: Each honest party Pj sends its spec-
iﬁed input xj to the trusted party. A corrupted party Pi controlled by the
adversary may either send its speciﬁed input xi, some other x′i or an abort
message.
– Early abort option: If the trusted party received abort from the adversary
A, it sends ⊥ to all parties and terminates. Otherwise, it proceeds to the
next step.
– Trusted party sends output to the adversary: The trusted party com-
putes each party’s output as speciﬁed by the functionality F based on the
inputs received; denote the output of Pj by yj. The trusted party then sends
{yi}i∈I to the corrupted parties.
– Adversary instructs trusted party to continue or halt: For each j ∈
{1, . . . , n} with j /∈ I, the adversary sends the trusted party either abortj or
continuej. For each j /∈ I:
• If the trusted party received abortj then it sends Pj the abort value ⊥
• If the trusted party received continuej then it sends Pj its output value yj.
– Outputs: The honest parties always output the output value they obtained
from the trusted party, and the corrupted parties outputs nothing.
for output.
Let S be a non-uniform probabilistic polynomial-time adversary controlling
parties Pi for i ∈ I. Let idealF ,S(z),I (x1, . . . , xn, κ) denote the output of the
honest parties and S in an ideal execution with the functionality F, inputs
x1, . . . , xn to the parties, auxiliary-input z to S, and security parameter κ.
3 This modeling is only for simplicity, since in our protocol, all parties receive and send
messages in each round. Thus, by instructing each party to only send their round
i + 1 messages after receiving all round-i messages, we have that an execution of
the protocol in an asynchronous network is the same as for a rushing adversary in a
synchronous network. Note that we do not guarantee output delivery, so “hanging”
of the protocol is also allowed.
7
Security. Informally speaking, the deﬁnition says that protocol π securely com-
putes f if adversaries in the ideal world can simulate executions of the real world
protocol. In some of our protocols there is a statistical error that is not depen-
dent on the computational security parameter. As in [20], we formalize security
in this model by saying that the distinguisher can distinguish with probability at
most this error plus some factor that is negligible in the security parameter. This
is formally diﬀerent from the standard deﬁnition of security since the statistical
error does not decrease as the security parameter increases.
Deﬁnition 2.1. Let F be a n-party functionality, and let π be a n-party protocol.
We say that π securely computes f with abort in the presence of an adversary
controlling t < n
3 parties, if for every non-uniform probabilistic polynomial-
time adversary A in the real world, there exists a non-uniform probabilistic
polynomial-time simulator/adversary S in the ideal model with F, such that
for every I ⊂ {1, . . . , n} with |I| < n
3 ,
󰀋idealF,S(z),I (x1, . . . , xn, κ)󰀌 c
≡󰀋realπ,A(z),I (x1, . . . , xn, κ)󰀌
where x1, . . . , xn ∈ F∗ under the constraint that |x1| = ··· = |xn|, z ∈ F∗ and
κ ∈ N. We say that π securely computes f with abort in the presence of an
adversary controlling t < n
3 parties with statistical error 2−σ if there exists a
negligible function µ(·) such that the distinguishing probability of the adversary
□
is less than 2−σ + µ(κ).
Fairness. The above deﬁnition can be modiﬁed so that fairness is guaranteed
by merely modifying the ideal model so that after the “early abort option” the
trusted party simply sends each party its output. That is, if there is no early
abort, then all parties receive output. This is the only modiﬁcation required to
the deﬁnition.
The hybrid model. We prove the security of our protocols in a hybrid model,
where parties run a protocol with real messages and also have access to a trusted
party computing a subfunctionality for them. The modular sequential compo-
sition theorem of [5] states that one can replace the trusted party computing
the subfunctionality with a real secure protocol computing the subfunction-
ality. When the subfunctionality is g, we say that the protocol works in the
g-hybrid model.
Universal Composability [6]. Protocols that are proven secure in the universal
composability framework have the property that they maintain their security
when run in parallel and concurrently with other secure and insecure protocols.
In [18, Theorem 1.5], it was shown that any protocol that is proven secure with a
black-box non-rewinding simulator and also has the property that the inputs of
all parties are ﬁxed before the execution begins (called input availability or start
synchronization in [18]), is also secure under universal composability. Since the
input availability property holds for all of our protocols and subprotocols, it is
8
suﬃcient to prove security in the classic stand-alone setting and automatically
derive universal composability from [18]. We remark that this also enables us to
call the protocol and subprotocols that we use in parallel and concurrently (and
not just sequentially), enabling us to achieve more eﬃcient computation (e.g., by
running many executions in parallel or running each layer of a circuit in parallel).
3 Building Blocks and Sub-Protocols
In this section, we deﬁne a series of building blocks that we need for our protocol.
Most of these are used in previous works, like [3,19,2,8]. Our presentation is
similar, with some modiﬁcations where possible due to us working in the scenario
of t < n/3 (rather than t < n/2 like in [19,8]).
3.1 Generating Random Shares and Coins
We deﬁne the ideal functionality Frand to generate a sharing of a random value
unknown to the parties. A formal description appears in Functionality 3.1. The
functionality lets the adversary choose the corrupted parties’ shares, which to-
gether with the random secret chosen by the functionality, are used to compute
the shares of the honest parties.
FUNCTIONALITY 3.1 (Frand – Generating Random Shares)
Upon receiving ri for each corrupted party Pi with i ∈ I from the ideal adversary S,
the ideal functionality Frand chooses a random r ∈ F and generates a sharing [r]t
under the constraint that the share of Pi is ri for every Pi ∈ I. Then, Frand sends
each honest party Pj its share in [r]t.
The functionality F double
is deﬁned similarly to Frand, but generates double
sharings that are deﬁned to be two sharings of the same random value r, but
where one is of degree-t and the other of degree-2t.
rand
rand
– Random Double Sharings)
FUNCTIONALITY 3.2 (F double
Upon receiving ri, r′i for each corrupted party Pi with i ∈ I from the ideal adversary
S, the ideal functionality F double
chooses a random r ∈ F, and generates sharings
[r]t and [r]2t under the constraint that the shares of Pi in [r]t and [r]2t are ri and
r′i, respectively, for every i ∈ I. Then, F double
sends each honest party Pj its shares
in [r]t and [r]2t.
rand
rand
9
Method and complexity: We use the method called DoubleShareRandom from [2]
which is based on [3] in order to generate double random sharings with perfect
security in the presence of malicious adversaries where t < n/3. This protocol
generates n − 2t double-random sharings at the cost of 2n + 2(n − 2t) elements
sent by each party. For t < n/3, this generates n/3 sharings at the average
cost of 2n+2n/3
n/3 = 8 elements per party per double-sharing generated. Although
single random shares, as in Frand, can be generated more eﬃciently than double
random sharings, we only need a few of these. Thus, we will only use F double
rand ,
and will discard the 2t-degree share where not needed. This is the most eﬃcient
since F double
generates many random double sharings at once, and for typical
parameters one call to F double
is enough for the entire protocol.
rand
rand
Generating random coins. Fcoin is an ideal functionality that chooses a random
element from F and hands it to all parties. The simplest way to compute Fcoin
securely (in the sense of using existing building blocks) is to use Frand to generate
a random sharing and then open it. The security of this protocol is immediate,
and the cost of the protocol is one call to Frand and one execution of open (the
latter which costs sending n elements per party).
3.2 Checking Equality to 0
In our protocol, we will need to check whether a given sharing is a sharing of the
value 0, without revealing any further information on the shared value. For this
purpose, we use a variant of the protocol presented in [8]. The idea behind the
protocol is simple. Holding a sharing [v], the parties generate a random sharing
[r] and multiply it with [v] (using local multiplication of their shares). Then, the
parties open the obtained sharing and check equality to 0. This works since if
v = 0, then multiplying it with a random r will still yield 0. In contrast, if v ∕= 0,
then the multiplication will result with 0 only when r = 0, which happens with
probability 1
. By repeating suﬃciently many times, this probability of error can
|F|
be made negligible. However, in order to ensure that nothing is revealed by the
opening, we need to rerandomize the sharing of r· v by adding a random degree-
2t sharing of 0. This is easy to achieve by constructing a double random sharing
[ρ]t and [ρ]2t, opening the degree-t sharing to obtain ρ and then computing
[0]2t = [ρ]2t − ρ. In order to reduce the number of rounds required, we open [ρ]t
together with [r · v + ρ]2t and just verify that the values are equal to each other;
this is equivalent to r · v being equal to 0.
The zero-checking protocol that we present here is a bit more eﬃcient than
that of [8], since here we have a single opening of a share. In contrast, the
protocol for checking equality to 0 in [8] ﬁrst runs a multiplication protocol
involving opening and then has another opening.
The ideal functionality FcheckZero for checking equality to 0 is formally deﬁned
in Functionality 3.3.
10
FUNCTIONALITY 3.3 (FcheckZero – Checking Equality to 0)
The ideal functionality FcheckZero receives (valid) shares of [v]t from the honest
parties Pj for every j ∈ J, and uses them to compute v and the shares of the
corrupted parties in [v]t using the complete procedure.
FcheckZero sends the ideal adversary S the corrupted parties’ shares in [v]t. In