0.9
0.8
0.8
0.75
0.8
0.75
reports the PR-curve and AUPRC of TableGAN-MCA when 𝑁𝑠 = 10.
That is, the adversary has multiple copies of the released synthetic
data. In particular, when 𝑁𝑠 = 10, the adversary trains 10 inde-
pendent shadow GANs for each 𝑆𝑖 and finally obtains a shadow
𝑠 times of the size of |𝐷𝑡|. In Fig. 7, the performance of
dataset 𝑁 2
TableGAN-MCA is greatly improved by increasing the number of
synthetic copies 𝑁𝑠. We also show the PR-curve comparison for the
three datasets in Fig. 7. That is, given 30% recall, 10 copies boost
the precision from 86.81% (𝑁𝑠 = 1) to 90.70% (𝑁𝑠 = 10). Given
90% precision, the recall is boosted from 22.25% (𝑁𝑠 = 1) to 33.01%
(𝑁𝑠 = 10). We conclude that more copies of the synthetic data
allow the adversary to make better approximation to generated
distribution P𝑔, and thus generate more informative labeled shadow
samples to train the attack model. This leaves open an interesting
problem of whether the adversary could reconstruct the whole
training dataset with countably infinite queries.
TableGAN-MCA achieves commendable attack performance
even with fewer synthetic queries. Many target model predic-
tion APIs (MLaaS) implement a pay-per-query business model.
Hence, reducing the number of synthetic queries saves the cost of
performing TableGAN-MCA. However, a smaller synthetic dataset,
having less membership collisions with the training dataset, decays
the attack performance. To tackle this problem, we propose an ap-
proach that uses shadow data to fill up the synthetic data to match
the size of the training set. That is, the adversaries obtain a synthetic
dataset 𝑆 of size 0.25 · 𝑁 by querying the target Generator. The
adversaries then generate the shadow dataset of size |(cid:101)𝑆| = 0.75 · 𝑁 .
After that, the TableGAN-MCA adversaries attack 𝑆∥(cid:101)𝑆 instead of the
original 𝑆. We show the impact of a small 𝑁𝑠 on TableGAN-MCA in
Fig. 8. We find that few synthetic queries also yield decent attack
performance. In particular, when 𝑁𝑠 = 0.25 (an adversary queries
the target Generator 0.25 · |𝐷𝑡| times), TableGAN-MCA achieves
0.6674 AUPRC (𝑁𝑠 = 1 is 0.6697), and recovers 1, 409 data points
(𝑁𝑠 = 1 is 1565) under 75% precision in the Adult dataset. This
resonates with the memorization experiment (see Section 6.3) that
the success of TableGAN-MCA is contingent more on basic data
patterns.
Influences of model types. The generation quality of the
5.5.3
victim model(generator) positively impacts attack performance.
Fig. 9 depicts TableGAN-MCA’s performance on four different vic-
tim models: WGAN-GP, WGAN-WC, CTGAN and TVAE. The shadow
model in use is exactly the same as target models. Combining the
results of Fig. 9 and Table 4, we conclude that victim generators
with high generation quality often attain high attack performance.
For instance, TVAE with the lowest prediction accuracy score in
Figure 6: Attack effect of TableGAN-MCA. The dash-dot lines
imply random guess baselines (0.1690, 0.2389, 0.3400 for Adult,
Lawschool and Compas datasets, respectively.)
model in Fig. 6 when 𝑁𝑠 = 1, i.e., |𝑆| = |𝐷𝑡|. In Fig. 6, PR-curve
reflects the trade-off between precision and recall for different
probability thresholds T. Particularly, after providing the inference
data (the released GAN-synthesized tables) to the TableGAN-MCA
attack model, we receive a set of probabilities for each record of
the test data that predicts whether a record is a member.
As illustrated in Fig. 6, we find that by setting a suitable thresh-
old T, the adversary can expose approximate 30% colliding mem-
bers with confidence over 83.91%, 69.40% and 81.24% for the Adult,
Lawschool and Compas datasets, respectively. This means that the
adversary significantly increases its ability to assert that these en-
tities are members. Furthermore, when setting confidence to 80%,
we have 36.1%, 12.7%, 36.5% positive percentages being exposed,
which correspond to 1931, 1304 and 458 individual’s sensitive en-
tries in the Adult, Lawschool and Compas datasets, respectively.
According to Fig. 6, we list TableGAN-MCA’s recovery rates (Eq.(7))
with different precision configurations in Table 6.
The success of TableGAN-MCA is mainly due to the ob-
served collision, the membership collisions indicator and
the shadow model in use. In particular, the collision between
synthetic data and training set provides the opportunity for recov-
ering training data. The membership collisions indicator, which
captures the statistical patterns behind colliding members, guaran-
tees more accurate and informative features for training the attack
model. The shadow model in use provides enough labeled data to
train the attack model so as to learn from the statistical patterns of
the colliding members.
Influences of synthetic sample size. Adversary’s knowledge
5.5.2
enhances the attack performance of TableGAN-MCA. Fig. 7
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2102(a) Adult PR-curve
(b) Lawsch PR-curve
(c) Compas PR-curve
(d) AUPRC
Figure 7: TableGAN-MCA performance comparisons between one synthetic copy (𝑁𝑠 = 1) and ten synthetic copies (𝑁𝑠 = 10). (a),
(b), (c): PR-curve comparison for three datasets; (d): AUPRC comparisons for three benchmarks.
Figure 8: TableGAN-MCA performance when 𝑁𝑠 ≤ 1.
prediction accuracy (see Table 4) also achieves unsatisfactory per-
formance in TableGAN-MCA on the adult dataset. This echoes what
CTGAN performs in the Compas dataset. Additionally, we observe
that attack performance of TVAE is more sensitive to its generation
quality.
The type of shadow models has limited impact on attack
performance. Note that the adversary may have no knowledge
about the structures and parameters of victim generative models.
Fig. 9(b) compares the attack performance by using four different
shadow models (WGAN-GP, WGAN-WC, CTGAN and TVAE) to
attack victim WGAN-GP. As can be seen, various shadow model
attacks (“wganwc”, “ctgan”, “tvae”) work as well as the identical
shadow model attack (“wgangp”). TVAE shadow models perform
worst, in large part due to its poor learning ability in the Adult
dataset.
5.5.4 Attack scalability. The key to the success of the TableGAN-
MCA is the possibility of collisions between raw training datasets
and synthetic datasets. For real-world tabular data, attributes usu-
ally have a finite domain range. Hence, the dataset dimension in-
dicates its overall domain range. Namely, low-dimensional tables
are more likely to incur sample collisions when the generator cre-
ates those synthetic tables. Therefore, TableGAN-MCA discovers
additional privacy risks – membership disclosure via collision at-
tacks – for low-dimensional data. TableGAN-MCA potentially fits
high-dimensional data if adversaries reduce the data granularity
by generalizing attributes. The TableGAN-MCA works since the
synthetic data would have a higher chance to collide with the
training datasets. In our experiments, TableGAN-MCA achieves
(a) Different Target/Victim Models
(b) Different Shadow Models
Figure 9: TableGAN-MCA performance under different
target/victim-shadow model settings. In (a), shadow models
are the same as target/victim models.
0.871 AUPRC by bucketizing the "age" attribute in synthetic Adult
datasets into 10 bins (no-bucketization baseline: 0.668).
5.5.5 Comparisons between TableGAN-MCA and existing MIAs.
Firstly, TableGAN-MCA recovers member data points from
the GAN-synthesized tables previously assumed to be resilient
to table-GAN [35]. We evaluate the performance of table-GAN
against the same WGAN-GP that used in TableGAN-MCA evalu-
ation. Notice that we test their MIAs directly on the target dis-
criminator instead of the shadow discriminator due to the fact that
if the target discriminator fails, the shadow model will perform
even worse. We report the accuracy of membership prediction
(member/non-member) of table-GAN, which are 50.17%, 50.80%
and 50.67% for Adult, Lawschool and Compas datasets, respectively
(50% is the baseline of random guess). Taken altogether the experi-
ment results in Fig. 6, we conclude that GAN APIs with a black-box
access assumed to be resilient to table-GAN (targeting on a dis-
criminative model) [35] may still disclose partial sensitive training
information under TableGAN-MCA.
Secondly, the MIAs proposed in GAN-Leaks and LOGAN
cannot disclose membership collisions. Note that the existing
MIAs against GANs may work in the MCA scenario. Thus, we per-
form additional experiments to infer membership collisions of each
synthetic data point using their methods. In particular, we evalu-
ate LOGAN (black-box attack with no auxiliary knowledge) and
GAN-Leaks (full black-box generator attacks) under threat model
(1) (given one copy synthetic data, see details in Section 3.2) and
report the result in Table 7. MC and table-GAN are not included in
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2103Table 7: The attack AUPRC comparison (mean ± SD). Base
implies random guess baseline. We use WGAN-GP as tar-
get/victim as well as shadow models.
Adult
Lawschool
Compas
Base
LOGAN
GAN-Leaks
Proposed
0.1690 ± 0.0038
0.2237 ± 0.0194
0.1667 ± 0.0063
0.6681 ± 0.0348
0.2389 ± 0.0067
0.2512 ± 0.0172
0.2514 ± 0.0061
0.5805 ± 0.0144
0.3400 ± 0.0233
0.3154 ± 0.0343
0.3256 ± 0.0301
0.7228 ± 0.0556
this experiment. The reason is two-fold. First, the distance function
of MC is not directly applicable to non-image datasets. Second,
table-GAN requires predicted probability vectors of the target dis-
criminator, which is not permitted in our threat model. Note that
the synthetic dataset 𝑆 has imbalanced membership collisions labels
(Row 1 in Table 7) that are different from Shokri’s shadow model
MIA [43] (random observation with 50% real members) since the
number of colliding data points (members) is usually unequal to
non-colliding ones (non-members).
We observed that the results in GAN-Leaks are close to the ran-
dom guess baseline. This is due to the reconstruction loss 𝐿(𝑥, 𝑥∗) =
0 for all synthetic data regardless of membership collisions (the
optimal reconstruction of a synthetic data x is itself). Furthermore,
LOGAN did not show convincing inference results since it never
learns the intersection between the synthetic data and the private
training data. In comparison, TableGAN-MCA learns such an in-
tersection (by which we recover partial training data) through the
intersections of the published synthetic data (by mimicking the
private training data) and shadow (synthetic) data (by mimicking
the original synthetic data).
In summary, the MIA classifiers that identify membership fail to
identify those membership collisions since the decision boundaries
of our attack classifier is different from those of MIAs against GANs.
6 TABLEGAN-MCA ANALYSIS
In this section, we discuss the factors that may impact the attack
performance of TableGAN-MCA from the following aspects, such as
GAN training set size, GAN training epochs and GAN training data
frequencies. We choose WGAN-GP as targets as well as shadow
model for its superior modeling quality and stability in TableGAN-
MCA experiments.
6.1 GAN Training Set Size
The size of the training dataset for a GAN model positively
impacts the attack performance. Fig. 10 depicts the positive im-
pact of training dataset size on prediction accuracy and AUPRC of
TableGAN-MCA, where 1.0 in x-axis indicates the full size of a given
dataset, 𝑁𝑠 = 1. Especially, when the size of the training dataset
is less than 0.5 of the full dataset, increasing the size has a signifi-
cant impact on the attack performance. The intuition behind the
experimental results is two-fold. First, less training data decrease
the number of colliding members (positives) in fixed amount of
synthetic datasets thus decreases the attack effect. Second, GAN
learns a less accurate data distribution if trained on a smaller dataset.
Synthetic data generated by such a distribution contain less infor-
mation than the original training data hence hard for the adversary
to learn the statistical patterns of the members/non-members. Note
that our results do not conflict with [7, 20, 27] since we use differ-
ent measurements (PR space vs ROC space) that focus on different
domains [10]. Additionally, our attack target (test data) is also differ-
ent. We aim to recover the colliding member data from the released
synthetic dataset whereas they aim to infer the membership of
a random target data point, and thus we learn different decision
boundaries.
6.2 GAN Training Epochs
Epochs impact the attack performance of TableGAN-MCA
by impacting the knowledge learned by GAN models. We
study the attack performance on different training stages by setting
different epochs in Fig. 11, where we report the attack prediction
accuracy and attack AUPRC.
As seen from Fig. 11, we find that the membership leakage starts
at the very beginning of the training epoch, even before the GAN
reaches the Nash equilibrium. Interestingly, in Adult and Compas,
the attack effect seems to slightly decrease when we set a larger
epochs for training GAN models. Since TableGAN-MCA tends to
recover the data with high appearance frequency (recall Fig. 3),
we conclude that with increasing epochs, GAN models learn more
about the training data distribution; hence, the released synthetic
data contain more information, which enhances the attack perfor-
mance. However, once the GAN models learn the details of the
data distribution, such details about the distribution would dilute
the frequency of those data supposed to have high frequency. The
attack performance of TableGAN-MCA is then potentially dropped.
6.3 Training Data Frequencies
Training data frequencies are positively correlated with train-
ing data recovery probabilities by TableGAN-MCA. We first
compute the recovery possibility and appearance frequency for
each data point. We then plot the recovery possibility over the
values of data points frequency in Fig. 12. For each dataset, we set
two precision-scores of TableGAN-MCA and plot the training data
frequency-recovery rate curves. Overall, highly frequent training
data are more susceptible to TableGAN-MCA. For instance, when
attacking Adult datasets with 80% precision, 41.5%(784/1892) train-
ing data with appearance more than three times are recovered by
TableGAN-MCA whereas only 0.6%(510/25130) of unique training
data (#x = 1) are recovered by TableGAN-MCA.
For highly frequent training data, GANs inevitably learn and
output these common representations frequently; thus it is easy
to recover such highly frequent data by TableGAN-MCA. The re-
identification threats of these data caused by TableGAN-MCA are
limited since each of them correspond to several individuals and
lack of uniqueness.
Unique training data, on the other hand, have more risks for
being linked to specific people once recovered by TableGAN-MCA.
Therefore, it deserves further exploration for the reason of being
exposed.
Generalization of GAN models may accidentally increase
the appearance of some unique data points in the synthetic
data, therefore increasing their probability to be recovered
by TableGAN-MCA. Since the TableGAN-MCA is based on data
density in modeled distribution P𝑔, for a recovered unique training
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2104(a) Adult
(b) Lawschool
(c) Compas
Figure 10: The impact of GAN training data size on synthetic data utility (left) and TableGAN-MCA effect (right). The x-axis
indicates the amount of GAN training data
(a) Adult
(b) Lawschool
(c) Compas
Figure 11: The impact of GAN training epochs on Synthetic data utility (left) and TableGAN-MCA effect (right).
of the presence of one training input on the modeled distribution P𝑔