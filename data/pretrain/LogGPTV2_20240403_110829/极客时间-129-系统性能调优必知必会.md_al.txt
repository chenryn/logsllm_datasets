# 27 \| 消息队列：如何基于异步消息提升性能？你好，我是陶辉。在前 26讲中我们介绍了许多异步实现机制，这节课我们来看看如何通过消息队列slate-object="inline"提升分布式系统的性能。异步通讯是最常用的性能提升方式，比如 gRPC 提供的异步 API，或者基于write-back模式向缓存写入数据时，系统性能都可以提高。然而，对于复杂的大规模分布式系统，这些分散、孤立的异步实现机制，无法解决以下问题：1.  组件间耦合在一起，不只迭代变更时更为困难，而且当它们之间的性能有差异时，吞吐量较低的组件就会成为系统瓶颈；        2.  当业务在时间上具有明显的峰谷访问差异时，实现        **削峰填谷**        需要一定的开发成本；        3.  实现 BASE 理论中的 Basically Available    并不容易；        4.  每个组件都要自行维护负载均衡组件，以此提供可伸缩性；        5.  每个组件的请求格式、日志都不尽相同，因此系统总体的监控成本相对较高；        6.  批量处理请求、异步化都可以提升性能，但每个组件独立实现这些基础功能付出的成本并非完全必要。        想必你肯定听过 Kafka、RabbitMQ、RocketMQ这些流行的消息队列吧？通过消息队列实现组件间的异步交互方式，上述问题就会迎刃而解。这一讲我们就来看看如何在分布式系统中使用消息队列，以及高可用性又是如何保证的。消息队列解决了哪些问题？当进程中需要交互的两个模块性能差距很大时，我们会基于 FIFO先入先出队列实现生产者消费者模型，通过调整生产者、消费者的数量，实现线程间的负载均衡。而且，生产者仅将任务添加至队列首部就可以返回，这种异步操作释放了它的性能。比如\[第 13 课\中接收心跳包的分发线程性能要比处理心跳包的工作线程性能高得多，两者间就通过单机上的消息队列提高了整体性能。![](Images/60017c7a59124a0d6b91a7cec3e7a3d7.png)savepage-src="https://static001.geekbang.org/resource/image/18/21/1865eebccb3f65c6b56d526124c8e421.png"}把单机中的 FIFO队列放大到分布式系统中，就形成了独立的消息队列服务。此时，生产者、消费者的角色从线程变成了网络中的独立服务，如下图所示，生产者可以向消息队列发布多种消息，多个消费者也可以订阅同一种消息，如下图所示：![](Images/0a37ce448b6a9be6c3b7c8b84233de9d.png)savepage-src="https://static001.geekbang.org/resource/image/9c/7c/9ca376f54a0631b7e83e9fa024e3427c.png"}总结一下的话，消息队列就具备了以下 7个优点： 1.       降低了系统的耦合性。比如上图中，组件 2    发布了一条用户注册成功消息，原本只有负责通知用户注册结果的组件 3    在处理，如果组件 4    需要立刻开启新用户的营销工作，只需要同时向消息队列订阅即可；再比如，组件    2、组件 3、组件 4 通讯时并不需要统一应用层协议或者 RPC    接口，所有参与方只需要与消息队列服务的 SDK    打交道。        2.       可伸缩性很容易实现。比如，当组件 3    的性能不足时，添加订阅消息的新实例，就可以通过水平扩展提升消费能力。反之，也可以扩展组件    1，提升消息的生产能力。        3.       天然实现"削峰填谷"功能。消息队列服务会将消息持久化存储在磁盘中，在高峰期来不及处理的消息，会在低谷期被消费者服务处理完。通常，消息队列会使用廉价、高容量的机械磁盘存放消息，可以轻松缓存住高峰期超载的全部请求。        4.       提高了系统可用性。首先，持久化到磁盘中的消息，在宕机故障时比内存中的请求有更高的可用性；其次，消息队列可以隔离故障，比如，消费者服务宕机后，生产者服务短期内不会受到影响；再次，当总吞吐量超过性能上限时，还可以设置不同的消息优先级，通过服务降级保障系统的基本可用性。        5.       消息队列的生产者天然具备异步功能，这降低了生产者的请求处理时延，提升了用户体验。        6.       [\[第 21 课\             介绍过，基于 AKF Y    轴拆分功能可以降低数据规模，而且组件间分工更细也会带来更深入的性能优化。当消息队列作为通讯方式时，这种"事件驱动"的分布式系统很容易通过消息实现服务拆分，成本会低很多。        7.       消息队列服务对于各种消息的发布、消费情况都有统计，因此，从消息中就能获得业务的实时运行状态，以极低的成本实现系统的监控。        正是因为这么多的优点，所以消息队列成为了多数分布式系统必备的基础设施。而且，消息队列自身也拥有很高的性能，比如RabbitMQ 单机每秒可以处理 10 万条消息，而 Kafka单机每秒甚至可以处理百万条消息。消息队列的性能为什么如此夸张呢？除了消息队列处理逻辑简单外，还有一个重要原因，就是消息的产生、消费在时间上是连续的，这让消息队列在以下优化点上能获得很高的收益：1.  首先，在网络通讯中，很容易通过批量处理提高网络效率。比如生产者快速发布消息时，Kafka    的客户端 SDK 会自动聚集完一批消息，再一次性发送给    Broker，这样网络报文的有效载荷比会很高。        2.  其次，在数据写入磁盘的过程中，由于时序性特征，存放消息的文件仅以追加形式变更，这样多数情况下机械硬盘的磁头仅朝一个方向转动，这让磁盘写入速度可以轻松达到    100MB/s。        3.  最后，由于消费者也是按照 FIFO    规则有序接收消息的，这样消息队列的缓存就可以通过批量预读等优化方式，大幅提高读操作的缓存命中率。        而且，目前主流消息队列都支持集群架构，因此消息队列自身一般不会是性能瓶颈。消息队列的服务质量是如何保证的？为了提升整个分布式系统的性能，我们在处理消息时，还需要在生产端、消费端以及消息队列的监控上，做到以下3 件事： 1.  首先，虽然生产者会异步地发布消息，但毕竟需要接收到消息队列的确认，才构成完整的发布流程。网络传输是相对漫长、不可控的，所以在高性能场景中，生产者应基于多线程或者非阻塞    Socket    发布消息，以提高并发能力。        2.  其次，当消费端性能不足需要扩容时，必须同步增加消息队列服务中的队列（在    Kafka    中叫做分区），才能允许新增的消费节点并行接收消息，提高消息的处理能力。否则，当多个消费者消费同一消息队列时，消息的有序性会导致多个消费节点串行处理消息，无法发挥出它们的全部性能，如下图所示：        ![](Images/9f5d069a2f540558ca85ac1b544030d1.png)savepage-src="https://static001.geekbang.org/resource/image/bc/46/bc9b57604b2f15cf6fb95d64af99c546.png"}1.  最后，如果通过监控发现消息的消费能力小于生产能力，那就必须及时扩容消费端，或者降低消息的发布速度，否则消息就会积压，最终导致系统不可用。        接下来，我们再来看消息队列的 QoS（Quality ofService）是如何保证的，即：消息在传递过程中会不会丢失，以及接收方会不会重复消费消息。在MQTT 协议中，给消息队列定义了三种 QoS级别： 1.  at most    once，每条消息最多只被传送一次，这意味着消息有可能丢失；        2.  at least    once，每条消息至少会传送一次，这意味着消息可能被重复消费；        3.  exactly    once，每条消息恰好只传送一次，这是最完美的状态。        需要 at most once约束的场景较罕见，因此目前绝大部分消息队列服务提供的 QoS 约束都是 atleast once，它是通过以下 3点做到的： 1.  生产端发布消息时，只有消息队列确定写入磁盘后，才会返回成功；        2.  为防止消息队列服务出现故障后丢消息，我们也需要将数据存放在多个副本节点中。第    4 部分课程介绍的许多高可用策略，消息队列都会采用，比如 Kafka    就是使用        [\[第 22 课\             介绍过的 NWR 算法来选出副本中的    Leader    节点，再经由它同步数据副本。        3.  消费端必须在消费完消息（而不是收到消息）后，才能向消息队列服务返回成功。        这样，消息队列就能以很高的可用性提供 at least once 级别的 QoS。而exactly once 是在 at least once的基础上，通过幂等性idempotency  实现的。对于一条"幂等性消息"，无论消费 1次还是多次，结果都是一样的。因此，Kafka通过消息事务和幂等性约束实现了exactly once语义  slate-object="inline"，其中，发布消息时 Kafka 会创建全局唯一的递增ID，这样传输消息时它就能低成本地去除重复的消息，通过幂等性为单队列实现exactly once语义；针对生产者向多个分区发布同一条消息的场景，消息事务通过"要么全部成功要么全部失败"，也实现了exactly once 语义。小结这一讲我们介绍了消息队列及其用法。消息队列可以解耦分布式系统，其缓存的消息提供了削峰填谷功能，将消息持久化则提高了系统可用性，共享队列则为系统提供了可伸缩性，而且统计消息就可以监控整个系统，因此消息队列已成为当下分布式系统的必备基础设施。虽然消息队列自身拥有优秀的性能，但若想提高使用效率，我们就需要确保在生产端实现网络传输上的并发，在消费端扩容时同步增加队列或者分区，并且需要持续监控系统，确保消息的生产能力小于消费能力，防止消息积压。消息队列的 Qos 提供三种语义，其中 at most once 很少使用，而主流的 atleast once由消息持久化时的冗余，以及生产端、消息端使用消息的方式共同保障。Kafka通过幂等性、事务消息这两个特性，在 at least once 的基础上提供了 exactlyonce 语义。 思考题最后，留给你一道讨论题。你在实践中使用过消息队列吗？它主要帮你解决了哪些问题？欢迎你在留言区与大家一起探讨。感谢阅读，如果你觉得这节课对你有所帮助，也欢迎把今天的内容分享给你的朋友。
# 28 \| MapReduce：如何通过集群实现离线计算？你好，我是陶辉。接下来的 2节课我将介绍如何通过分布式集群优化计算任务。这一讲我们首先来看对于有边界静态数据的离线计算，下一讲再来看对无边界数据流的实时计算。对大量数据做计算时，我们通常会采用分而治之的策略提升计算速度。比如单机上基于递归、分治思想实现的快速排序、堆排序，时间复杂度只有O(N\*logN)，这比在原始数据集上工作的插入排序、冒泡排序要快得多（O(N2] slate-object="inline")）。然而，当单机磁盘容量无法存放全部数据，或者受限于 CPU频率、核心数量，单机的计算时间远大于可接受范围时，我们就需要在分布式集群上使用分治策略。比如，大规模集群每天产生的日志量是以 TB为单位计算的，这种日志分析任务单台服务器的处理能力是远远不够的。我们需要将计算任务分解成单机可以完成的小任务，由分布式集群并行处理后，再从中间结果中归并得到最终的运算结果。这一过程由Google 抽象为MapReduce 模式，实现在 Hadoop等分布式系统中。虽然 MapReduce已经有十多个年头的历史了，但它仍是分布式计算的基石，这种编程思想在新出现的各种技术中都有广泛的应用。比如当在单机上使用TensorFlow 完成一轮深度学习的时间过久，或者单颗 GPU显存无法存放完整的神经网络模型时，就可以通过 Map思想把数据或者模型分解给多个 TensorFlow 实例，并行计算后再根据 Reduce思想合并得到最终结果。再比如知识图谱也是通过 MapReduce思想并行完成图计算任务的。接下来我们就具体看看如何在分布式集群中实现离线计算，以及 MapReduce是怎样提供 SQL 语言接口的。分而治之：如何实现集群中的批量计算？分而治之的思想在分布式系统中广为使用，比如\[第 21 讲\ 介绍过的 AKF 立方体 Z轴扩展，就是基于用户的请求，缩小集群中单个节点待处理的数据量，比如下图中当关系数据库中单表行数达到千万行以上时，此时不得不存放在磁盘中的索引将会严重降低SQL语句的查询速度。而执行分库分表后，由应用或者中间层的代理分解查询语句，待多个不足百万行的表快速返回查询结果后，再归并为最终的结果集。![](Images/2cb5ddf20917a5c5f5bbaf6fd86c6b70.png)savepage-src="https://static001.geekbang.org/resource/image/71/81/712a0a73b71090abcaa7ac552f402181.png"}与上述的 IO类任务不同，并非所有的计算任务都可以基于分治策略，分解为可以并发执行的子任务。比如\[第 14 讲\介绍过的基于CBC 分组模式的 AES加密算法就无法分解执行，如下图所示，每 16 个字节的块在加密时，都依赖前 1个块的加密结果，这样的计算过程既无法利用多核 CPU，也无法基于 MapReduce思想放在多主机上并发执行。![](Images/9a1bc69e9f0e9e475e4e550e130eb485.png)savepage-src="https://static001.geekbang.org/resource/image/2b/3b/2b8bca7a74eb5f98125098e271d0973b.jpg"}](https://zh.wikipedia.org/zh-hans/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F)图片源自：https://zh.wikipedia.org/zh-hans/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F我们再来看可以使用 MapReduce的计算任务，其中最经典的例子是排序（Google在构建倒排索引时要为大量网页排序）。当使用插入排序（不熟悉插入排序的同学，可以想象自己拿了一手乱牌，然后在手中一张张重新插入将其整理有序）在整个数据集上操作时，计算的时间复杂度是O(N2] slate-object="inline")，但快排、堆排序、归并排序等算法的时间复杂度只有O(N\*logN)，这就是通过分治策略，缩小子问题数据规模实现的。比如下图是在 8个数字上使用归并排序算法进行排序的流程。我们将数组递归地进行3（log8）轮对半拆分后，每个子数组就只有 2 个元素。对 2个元素排序只需要进行 1次比较就能完成。接着，再将有序的子数组不断地合并，就可以得到完整的有序数组。![](Images/ee094fed89ccf55b9995aa548fed45e2.png)savepage-src="https://static001.geekbang.org/resource/image/8e/71/8e9f75013bcb26ae2befec6ff8739971.png"}其中，将两个含有 N/2 个元素的有序子数组（比如 1、3、7、19 和4、8、11、25），合并为一个有序数组时只需要做 N/2 到 N-1次比较（图中只做了 5次比较），速度非常快。因此，比较次数乘以迭代轮数就可以得出时间复杂度为O(N\*logN)。同样的道理引申到分布式系统中，就成为了 MapReduce模式。其中，原始数据集要通过 SPLIT步骤拆分到分布式系统中的多个节点中，而每个节点并发执行用户预定义的 MAP函数，最后将 MAP 运算出的结果通过用户预定义的 REDUCE函数，归并为最终的结果。比如上例中我们可以将 8 个元素拆分到 2个节点中并行计算，其中每个节点究竟是继续采用归并排序，还是使用其他排序算法，这由预定义的MAP 函数决定。当 MAP 函数生成有序的子数组后，REDUCE函数再将它们归并为完整的有序数组，具体如下图所示：![](Images/dc0fac38167cfaebe131b09259537247.png)savepage-src="https://static001.geekbang.org/resource/image/72/15/72bb89540bae52a46e69a5d802680715.png"}当面对 TB、PB 级别的数据时，MapReduce思想就成了唯一的解决方案。当然，在实际软件工程中实现 MapReduce的框架要比上面的示意图复杂许多，毕竟在大规模分布式系统中，故障每时每刻都会发生，如何分发数据、调度节点执行MAP映射、监控计算节点等，都需要精心的设计。特别是，当单个节点的磁盘无法存放下全部数据时，常常使用类似HDFS 的分布式文件系统存放数据，所以 MapReduce框架往往还需要对接这样的系统来获取数据，具体如下图所示：![](Images/f225742af825b80e1fc32d2880a77dec.png)savepage-src="https://static001.geekbang.org/resource/image/4f/39/4f3182c6334ec0c7b67e69b6ded2e839.png"}](http://a4academics.com/tutorials/83-hadoop/840-map-reduce-architecture)图片来源：http://a4academics.com/tutorials/83-hadoop/840-map-reduce-architecture而且，生产环境中的任务远比整数排序复杂得多，所以写对 Map、Reduce函数并不容易。另一方面，大部分数据分析任务又是高度相似的，所以我们没有必要总是直接编写Map、Reduce 函数，实现发布式系统的离线计算。由于 SQL语言支持聚合分析、表关联，还内置了许多统计函数，很适合用来做数据分析，它的学习成本又非常低，所以大部分MapReduce 框架都提供了类 SQL 语言的接口，可以替代自行编写 Map、Reduce函数。接下来我们看看，SQL 语言统计数据时，Map、Reduce函数是怎样工作的。SQL 是如何简化 MapReduce 模式的？我们以最常见的 Web 日志分析为例，观察用 SQL 语言做统计时，MapReduce流程是怎样执行的。举个例子，Nginx 的 access.log访问日志是这样的（基于默认的 combined格式）：     127.0.0.1 - - [18/Jul/2020:10:16:15 +0800] "GET /login？userid=101 HTTP/1.1" 200 56 "-" "curl/7.29.0"你可以通过正则表达式取出客户端 IP 地址、用户名、HTTP响应码，这样就可以生成结构化的数据表格：![](Images/d69eb5ef234c09633416ac02f0dd1c8c.png)savepage-src="https://static001.geekbang.org/resource/image/e9/e7/e9fcf8e7529f973b1679af93333b4ee7.jpg"}如果我们想按照客户端 IP、HTTP 响应码聚合统计访问次数，基于通用的 SQL规则，就可以写出下面这行 SQL语句：     select ClientIp, StatusCode, count(*) from access_log group by ClientIp, StatusCode而建立在 MapReduce 之上的框架（比如 Hive）会将它翻译成如下图所示的MapReduce 流程：![](Images/75f41c99cba3c796b0e9c5980bce5044.png)savepage-src="https://static001.geekbang.org/resource/image/4c/f9/4cb7443e0f9cdf2ba77fbbe230487ff9.png"}其中，我们假定 5 行数据被拆分到 2 个节点中执行 Map函数，其中它们分别基于 2 行、3行这样小规模的数据集，生成了正确的聚合统计结果。接着，在 Shuffle步骤基于 key 关键字排序后，再交由 Reduce函数归并出正确的结果。除了这个例子中的 count 函数，像max（求最大值）、min（求最小值）、distinct（去重）、sum（求和）、avg（求平均数）、median（求中位数）、stddev（求标准差）等函数，都很容易分解为子任务并发执行，最后归并出最终结果。当多个数据集之间需要做交叉统计时，SQL 中的 join功能（包括内连接、左外连接、右外连接、全连接四种模式）也很容易做关联查询。此时，我们可以在并行计算的Map 函数中，把 where 条件中的关联字段作为 key 关键字，经由 Reduce阶段实现结果的关联。由于 MapReduce操作的数据集非常庞大，还需要经由网络调度多台服务器才能完成计算，因此任务的执行时延至少在分钟级，所以通常不会服务于用户的实时请求，而只是作为离线的异步任务将运算结果写入数据库。小结这一讲我们介绍了在集群中使用分治算法统计大规模数据的 MapReduce模式。 当数据量很大，或者计算时间过长时，如果计算过程可以被分解为并发执行的子任务，就可以基于MapReduce思想，利用分布式集群的计算力完成任务。其中，用户可以预定义在节点中并发执行的Map 函数，以及将 Map 输出的列表合并为最终结果的 Reduce函数。 虽然 MapReduce 将并行计算抽象为统一的模型，但开发 Map、Reduce函数的成本还是太高了，于是针对高频场景，许多 MapReduce之上的框架提供了类 SQL 语言接口，通过 group by 的聚合、join连接以及各种统计函数，我们就可以利用整个集群完成数据分析。MapReduce模式针对的是静态数据，也叫有边界数据，它更多用于业务的事前或者事后处理流程中，而做事中处理时必须面对实时、不断增长的无边界数据流，此时MapReduce就无能为力了。下一讲我们将介绍处理无边界数据的流式计算框架。思考题最后，留给你一道思考题。你遇到过哪些计算任务是无法使用 MapReduce模式完成的？欢迎你在留言区与大家一起探讨。感谢阅读，如果你觉得这节课让你有所收获，也欢迎你把今天的内容分享给你的朋友。