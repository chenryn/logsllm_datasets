User: I'm writing a Python-based service that scans a specified drive for files changes and backs them up to a storage service. My concern is handling files which are open and being actively written to (primarily database files). 
I will be running this cross-platform so Windows/Linux/OSX. 
I do not want to have to tinker with volume shadow copy services. I am perfectly happy with throwing a notice to the user/log that a file had to be skipped or even retrying a copy operation x number of times in the event of an intermittent write lock on a small document or similar type of file. 
Successfully copying out a file in an inconsistent state and not failing would certainly be a Bad Thing(TM).
The users of this service will be able to specify the path(s) they want backed-up so I have to be able to determine at runtime what to skip.
I am thinking I could just identify any file which has a read/write handle and try to obtain exclusive access to it during the archival process, but I think this might be too intrusive(?) if the user was actively using the system.
Ideas?
Assistant: You could look for the file being closed and archive it. The phi notify library allows you to watch given files or directories for a number of events, including CLOSE-WRITE which allows you to detect those files which have closed with changes.