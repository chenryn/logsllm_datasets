# 如何对抗神一样的人工智能
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
> “你为什么要和人工智能对着干？ 你们安全人员为什么不能拥抱人工智能？ 能不能不吓唬人？”
我们发布深度学习系统中的威胁和攻击演示后，这是一个出乎意料，但又常被问到的问题。
当时我脑海闪过的是电影《终结者 I》中的场景：莎拉康纳被凶猛的T800追杀。施瓦辛格扮演的T800
智能机器人不仅仅有人脸识别技术，还有地图和大数据信息，而且还基本上打不死。 这是人工智能追杀人类的经典例子。 在电影世界里，康纳需要对抗人工智能（The
Terminator 系列），甚至复制人都需要抵抗智能的银翼杀手（BladeRunner 系列）…
对抗人工智能一直是我们对未来生活想象的一部分，而且一直是正义的需求。
跟PR打过几次交道的我，决定把这个回答咽到肚子里。
这个问题需要写文字来回答。
## 为什么要对抗人工智能
关于为什么要研究人工智能系统里的安全问题，我们在 ISC 2017 大会的时候给过一个冠冕堂皇的回答 —— “因为黑产在用人工智能”。
当深度学习作为一种日益大众化的技术手段，对技术采用的门槛自然会降低，所以人工智能技术不仅仅可以推动自动驾驶，人脸识别，也可以被用来刷帖和破解图片验证码，甚至会被用来收集特定目标信息，精准钓鱼攻击用户，包括你和我。
对行之有效的技术，黑产肯花钱，而且往往出的价钱超过互联网公司对相应技术的投入。 攻防有太多的不对称，这里不再赘述。
用个极端的例子，比如用无人机带着微型炸药来追杀你，它有你过去的行踪轨迹，并会在引爆之前对目标进行人脸识别。 要不要对抗？
这不是科幻，这是2017年已经被展示过的现实。
当你被人工智能追杀的是时候，对抗人工智能是生存的需求。从这个角度看，在网络空间中，安全人员研究人工智能的安全问题是名正言顺的，
## 对抗人工智能的另一个原因
聊完科幻之后，我们看看现实。 如果你被“杀人无人机”吓到的话，现实其实并没有那么可怕。
作为一个安全人员，我看到的情况挺拧巴的。
一方面我们总听到神一样的深度学习算法，它催发了大量新型应用，从人脸识别到自动驾驶。 各种应用,
从手机登录到移动支付，谁家不添加一个人工智能功能，谁好像就被留在石器时代了。
另一方面，安全圈里经常看到的是类似 “某平台人脸识别惊现重大漏洞” 这样的新闻，或者安全人员用两张纸就可以绕过人脸识别登录，
还有用胶带和导电笔可以破解指纹识别的。 用360团队的例子 — 安全人员可以让著名的图片识别程序把羊的图片认成狼，或者把狼认成羊。
被测试目标程序使用的是谷歌团队的深度学习模型加上 ImageNet 中最强大的数据！
在这个矛盾的世界里，当深度学习浪潮让众多年轻人冲到人工智能这块工地上搬砖的时候，我觉得安全研究人员有义务提醒大家：别忘带安全帽。
人工智能技术也许可以把一个应用加速建成一座美妙的楼阁， 但安全也是应用的一个基石，否则高空作业的同学可能需要配备降落伞。
所以研究对抗人工智能技术也是研究一种保护手段，避免一个顶着人工智能光环的应用被用户轻易愚弄。
## 风险的源头
为什么会出现智能系统很弱智地被轻易破解或绕过？ 难道我们不应该拥抱深度学习引领的这场技术革命吗？
说一个自己的亲身经历： 最近有机会和一个顶级人工智能专家交流 — 顶级是指在ImageNet夺冠N次这个级别的人工智能专家。
当我们展示用降维攻击导致深度学习系统识别出错的时候，人工智能专家立刻反应说：“这不是我们人工智能的错”。
同样，当我们告知一个著名深度学习框架作者，框架的数据处理层有bug, 因为没有对一个库调用做返回值检查，
回答是：“这个库应该确保返回值正常，不是我们的错”。
作为搞安全的老司机，这些回答我不吃惊，而且听起来特别熟悉。
你跟一个搞数据库的讲说他们的软件有SQL注入漏洞，回答往往是 — “这不是我们搞数据库的问题”； 你跟一个服务端开发人员说他写的软件有控制流劫持漏洞，回答是
— “我们客户端（浏览器）做了输入限制，你提供的输入是不可能的，这不是我们的错。”
安全人员听着耳熟吧？ 回答没毛病。
可是安全漏洞摆在那里，非要到展示PoC 或 到黑产窃取了用户信息被曝光之后才是毛病？
用两张纸就可以绕过的人脸识别没毛病吗？如果自动驾驶是在这种氛围里开发的，我们该不该上车？
一个算法在实验环境中，在众多假设条件下有精彩的结果当然是好事情。 但做一个被广大用户所使用的应用会遇到很多挑战。
所以在新的应用发布的时候，请不要只看到搞图像语音识别的同学在前台意气风发，大谈人工智能； 你很可能需要抚慰一下在后面灰着脸搭系统和做实现的同学。
## 如何对抗人工智能
回答了为什么做反人工智能研究，接下来是更复杂的问题 — 如何对抗人工智能。 如果看看2017年的媒体报道，人工智能就如神一样的存在。 弱点在哪里呢？
先从著名的例子开刀。 “你怎么对抗AlphaGo？”，这是一位业界领袖丢给我的一个问题。
AlphaGo碾压人类棋手，如果追杀你的无人机有AlphaGo级别的人工智能，你怎么应对？
如果你作为读者看到这里，仍然把人工智能算法想成神？那在 AlphaGo 面前，你只有束手就擒！
AlphaGo有自己的弱点。
你不信吗？ 这个在 AlphaGo 团队的采访里就有答案。
在与李世石对决的比赛里，作为”AlphaGo手臂“的黄士杰最担心的就是自己投错子。
之所以我们无法对抗人工智能，是因为我们的讨论是把它放在一个抽象的环境中，输入和输出都是完美的。如果说黄士杰可以被攻击的话，比如让他看错棋盘落错子，AlphaGo就不再是坚不可摧。
讲到这里，我学生的反应是，“李康老师，你这个不算。哪里有下棋攻击人的 。。。“
不可以吗？
海豚音攻击针对的是智能语音系统的麦克风，对特斯拉的第一个攻击是让摄像头致盲，发射欺骗信号给毫米波雷达。安全世界里这样的攻击数不胜数。
神一样的深度学习要求所有输入都符合一定格式，如果这样可以号称人工智能，那么当“杀人无人机”在头顶盘旋的时候，对它的传感器，摄像头进行对抗攻击不应该很合理吗？
## 对抗人工智能的方法是把它从神坛上请下来
对抗人工智能的方法是将它从神坛上请下来，给它赋予任何实际应用所需要的血肉之躯。对于人工智能来讲，就是要考虑全系统，包括数据采集，传感器实现，数据处理，以及软件如何与用户打交道等每一个环节。
当我们不再把人工智能应用看成一个抽象的算法，而是作为一个系统来看，我们才能全面讨论它的安全威胁，以及对抗人工智能的方法。这里我只简单介绍几个深度学习算法之外的威胁。
除了刚才提到的对输入输出子系统的攻击，或者对传感器的攻击，还有对系统软件供应链的攻击，包括模型的来源，软件开发环境的安全，机器学习培训数据的安全，数据流处理过程的安全。
参考最近爆出的CPU漏洞，系统硬件的设计实现，以及硬件供应链，任何一个环节都可能引入安全风险。
研究这些风险，从防守的角度，就是如何排除这些风险，从而保护人工智能系统，比如确保自动驾驶系统的安全。
从攻击的角度，就是如何对抗人工智能，例如如何规避无人机的追踪。 在这个后者的角度，人工智能系统越强大，对规避和对抗研究的需求就越强。
施瓦辛格样子的T800 今天也许仍然是想象，但好像离我们也不太远。
## 参考文献
【1】 某支付平台“人脸识别”惊现重大漏洞 
【2】 对深度学习的降维攻击 
【3】 用隐形眼镜和打印机破解三星虹膜识别
【4】两张A4纸破解虹膜人脸识别 