title:PrivateFS: a parallel oblivious file system
author:Peter Williams and
Radu Sion and
Alin Tomescu
PrivateFS: A Parallel Oblivious File System
Peter Williams, Radu Sion, and Alin Tomescu
Network Security and Applied Cryptography Lab
Stony Brook University, Stony Brook, NY, USA
{petertw,sion,alin}@cs.stonybrook.edu
ABSTRACT
Privatefs is an oblivious ﬁle system that enables access to re-
mote storage, while keeping both the ﬁle contents and client
access patterns secret. Privatefs is based on a new par-
allel Oblivious RAM mechanism (PD-ORAM)—instead of
waiting for the completion of all ongoing client-server trans-
actions, client threads can now engage a server in parallel
without loss of privacy.
This critical piece is missing from existing Oblivious RAMs
(ORAM), which can not allow multiple clients threads to
operate simultaneously without revealing intra- and inter-
query correlations and thus incurring privacy leaks. And
since ORAMs often require many communication rounds,
this signiﬁcantly and unnecessarily constrains throughput.
The mechanisms introduced here eliminate this constraint,
allowing overall throughput to be bound by server band-
width only, and thus to increase by an order of magni-
tude. Further, new de-amortization techniques bring the
worst case query cost in line with the average cost. Both of
these results are shown to be fundamental to any ORAM.
Extensions providing fork consistency against an actively
malicious adversary are then presented.
A high performance, fully functional PD-ORAM imple-
mentation was designed, built and analyzed.
It performs
multiple queries per second on a 1TB+ database across
50ms latency links, with unamortized, bound query laten-
cies. Based on PD-ORAM, privatefs was built and deployed
on Linux as a userspace ﬁle system.
Categories and Subject Descriptors
D.0 [Software]: General; E.3 [Data Encryption]
Keywords
Access Privacy, Cloud Computing, Oblivious RAM
1.
INTRODUCTION
Access pattern privacy addresses a critical side channel
leak present in many outsourced storage scenarios. Even on
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
encrypted data, the sequence of locations read and written to
storage reveals information about the user and the data. As
a motivating example, consider a database management sys-
tem running on top of an untrusted, encrypted ﬁle system.
The ﬁle system, in satisfying requests for the transaction
processor, learns semantic information about the transac-
tions through the sequence of disk blocks accessed. If, for
example, an alphabetical, encrypted keyword index is up-
dated as an encrypted record is inserted, it can learn what
keywords are present in the new record, based only on the
locations updated within the encrypted index.
An oblivious ﬁle system enables a client to read and write
without revealing the access pattern (which ﬁles are accessed,
and any correlation between accesses). Without access pat-
tern privacy, the act of accessing remote data leaks subtle
information about the data itself, making it impossible to
achieve full data conﬁdentiality outside a narrow deﬁnition.
The oblivious ﬁle system presented here is built on the
more general mechanism of Oblivious RAM (ORAM), which
allows a client to read and write records into a database /
memory hosted by an untrusted party, again hiding both
the data and the access pattern from this untrusted host.
Since the introduction of the ﬁrst ORAM [2], approaches
to increase query throughput have been sought and discov-
ered. Nevertheless, practical constructions (and thus prac-
tical oblivious ﬁle systems) have remained elusive.
This paper introduces PD-ORAM (“Parallel De-amortized
ORAM”), a collection of new techniques, applicable to a
large class of existing ORAMs, to improve their performance
and practical relevance by eliminating critical bottlenecks
and drawbacks. PD-ORAM is then used as the block-level
building block for privatefs, a parallel, oblivious ﬁle system.
First, the need for supporting parallel queries in ORAM is
identiﬁed and satisﬁed. Existing ORAMs are characterized
by a signiﬁcant number of round-trips, typically O(log(n)),
per query (with some notable exceptions; see the related
work discussion below). On wide-area networks, with mid
to high latency, this imposes strict limits on the query re-
sponse times as well as throughput. By supporting querying
in parallel from multiple clients, PD-ORAM eliminates the
eﬀect of query response time on throughput, while present-
ing an opportunity for new multi-client scenarios.
A new de-amortization construction (converting an algo-
rithm with an amortized bound into one with a worst-case
bound) is then introduced to process queries simultaneously
with database re-shuﬄing. Re-shuﬄing is an essential and
extremely costly task which, in amortized solutions, com-
pletely blocks the server for extended time periods after a
977In PD-ORAM and other de-
certain number of queries.
amortized solutions,
instead of suspending queries to re-
order data periodically, the server continuously re-shuﬄes
the database in the background, in loose synchronization
with querying, to guarantee minimal client latencies for both
the average and worst case.
At an overview level, the parallelization technique con-
sists of a round-trip-optimal and wait-optimal protocol to
transform a single-client “period-based” ORAM into a multi-
client parallel ORAM. A “period-based” ORAM is deﬁned
in Section 5.1 as an ORAM that operates on small batches
of queries, with its data structure not sensitive to the order
of reads or modiﬁcations within a particular batch.
A fully functional PD-ORAM implementation is devel-
oped and benchmarked at multiple queries per second on
a terabyte database, the highest throughput to date on a
medium-latency link. While the mechanisms described here
can be directly applied to a large number of diﬀerent ORAM
techniques, PD-ORAM is based on the ORAM described in
[19], but with de-amortized level construction, support for
parallel queries, and a new, simpler, Bloom ﬁlter (BF) con-
struction. PD-ORAM is then deployed and benchmarked in
Linux to build privatefs, the ﬁrst oblivious ﬁle system.
2. RELATED WORK
Oblivious RAM, introduced by Goldreich and Ostrovsky
[2] is a primitive that provides access pattern privacy to a
single client (or software process) accessing a remote database
(or RAM). The construction provided by Goldreich and Os-
trovsky (referred to as GO-ORAM) requires only logarith-
mic storage at the client; the amortized communication and
computational complexities of this construction are O(log3n).
A discussion of GO-ORAM and recent extensions follows.
2.1 ORAM Overview
In an ORAM, the database is considered to be a set of
n semantically-secure encrypted blocks (with an ORAM key
held by the client) and supported operations are read(id),
and write(id, newvalue). In GO-ORAM the data is orga-
nized into log2(n) levels, as a pyramid. Level i consists of
up to 2i blocks; each block is assigned to one of the 2i buck-
ets (originally log4(n) levels sized 4i; levels sized 2i are used
here for simplicity) at this level as determined by a hash
function. Due to hash collisions each bucket may contain
from 0 to k ln n blocks.
ORAM Reads. To obtain the value of block id, a client
must perform a read query in a manner that maintains two
invariants: (i) it never reveals which level the desired block
is at, and (ii) it never looks twice in the same spot for the
same block. To maintain (i), the client always scans a single
bucket in every level, starting at the top and working down.
The hash function informs the client of the candidate bucket
at each level, which the client then scans. Once the client
has found the desired block, the client still proceeds to each
lower level, scanning random buckets instead of those indi-
cated by their hash function. For (ii), once all levels have
been queried, the client re-encrypts the query result (so it
looks diﬀerent to the server) and places it in the top level.
This ensures that when it repeats a search for this block, it
will locate the block immediately (in a diﬀerent location),
and the rest of the search pattern is randomized. The top
level quickly ﬁlls up; how to dump the top level into the one
below is described later.
ORAM Writes. Writes are performed identically to reads
in terms of the data traversal pattern, with the exception
that the new value is inserted into the top level at the end.
Level Overﬂow. Once a level is full, it is emptied into the
level below. This second level is then re-encrypted and re-
ordered, according to a new hash function. Thus, accesses
to this new generation of the second level will henceforth be
completely independent of any previous accesses. Each level
overﬂows once the level above it has been emptied twice.
Any re-ordering must be performed obliviously: once com-
plete, the adversary must be unable to make any correlation
between the old block locations and the new locations. A
sorting network is used to re-order the blocks.
To enforce invariant (i), note also that all buckets must
contain the same number of blocks. For example, if the
bucket scanned at a particular level has no blocks in it, then
the adversary would be able to determine that the desired
block was not at that level. Therefore, each re-order pro-
cess ﬁlls all partially empty buckets to the top with fake
blocks. Recall that since every block is encrypted with a se-
mantically secure encryption function, the adversary cannot
distinguish between fake and real blocks.
2.2 Recent Developments
Starting with [18] researchers have sought to improve the
overhead from the polylogarithmic performance of the orig-
inal ORAM. Williams et al.
in [19] introduced a faster
ORAM variant which also features correctness guarantees,
with computational complexity costs and storage overheads
of only O(log n log log n) (amortized per-query), under the
assumption of O(
In their
work, the assumed client storage is used to speed up the
reshuﬄe process by taking advantage of the predictable na-
ture of a merge sort on uniform random data.
√
n) temporary client memory.
Recently, a new approach to speed up ORAM was revealed
by Pinkas et al. [13], showing the applicability of the Cuckoo
hash construction from [12]. Unfortunately, this was shown
to leak access privacy information [3]. A similar, but secure,
approach, allowing eﬃcient item lookup while hiding success
was then developed [3]. This approach has found continued
utility in other solutions [4, 8].
Researchers have long recognized the utility of construc-
tions with eﬃcient worst cases; the ﬁrst de-amortized con-
struction followed shortly after the introduction of Oblivi-
ous RAM [11]. More recent solutions have also featured de-
amortized constructions [1, 4, 8, 14]. These de-amortized so-
lutions are mostly based on the same core idea as we describe
here: constructing future levels in the background, while still
querying copies of current levels. One exceptional ORAM
[14] is naturally un-amortized (rather than de-amortized),
performing a well-deﬁned ORAM update on every query.
These previous solutions do not apply directly to a Bloom
ﬁlter-based ORAM; this de-amortization requires maintain-
ing a delete log to delay level updates until after the corre-
sponding shuﬄe.
A promising recursive construction technique is introduced
in [16] under the assumption of O(n log n) reliable client
storage. Using this storage, it promises to reduce the level
construction cost while requiring only a constant number
of online round trips. The clear drawback here is the as-
sumed O(n log n) client storage—enough to keep track of
the positions of all items, instead of querying recursively for
them as in the previously described ORAMs. The authors
978present the O(n log n) client storage assumption as not nec-
essarily unreasonable, since a large block size means that
the client only needs a fraction of the outsourced storage.
Their alternative construction, requiring only O(
n) stor-
age, recursively uses a log n-round-trip ORAM to store this
position map, but now incurs log n round trips per query.
√
Another notable alternative to the constructions of log(n)
round trips is found in [17]; Ding et al. build an Oblivi-
√
ous RAM requiring only a constant number of online round
trips. The main idea is to extend Goldreich’s
n-solution [2]
to store the recent query cache in client memory. The draw-
back is the signiﬁcantly higher shuﬄe cost, since the entire
database must be scanned once the cache is ﬁlled (e.g. after
n queries). Moreover, the amortized shuﬄe
a period of
costs in Oblivious RAMs easily dominate the online costs
both in theory and in practice [13]. Boneh et al. examine a
similar construction [1], and formalize the security model.
√
Another constant-round-trip solution, based on the same
core caching idea as [17] and [1], is introduced in [6], but the
single-level format prevents de-amortization. The constant-
round-trip claim depends on the assumption of M = n1/u
client memory for a constant u. Nevertheless, important
notions regarding optimal use of local memory in performing
eﬃcient oblivious external-memory sorts are introduced.
In addition to providing de-amortization for the construc-
tion in [19], PD-ORAM introduces a general approach to
de-amortization, based on rearranging levels to safely allow
querying during level re-construction. Diﬀerent constraints
of this base ORAM require new techniques, but the core
idea remains similar to related de-amortization work. This
de-amortization approach applies to any ORAM with a log-
arithmic number of levels. This includes a Bloom ﬁlter-
based ORAM [19], the original Goldreich-Ostrovsky loga-
rithmic ORAM [2], and recent cuckoo-hash based solutions
[3], though we remind the reader that prior work [4, 11] has
already de-amortized the latter two solutions.
A multi-client ORAM is introduced in [7]. Because the
client state (aside from the secret key) is stored on the server,
and scanned on every access, clients can take turns perform-
ing accesses. PD-ORAM takes this notion one step further:
not only are the clients “stateless,” but accesses are actually
performed in parallel. That is, clients begin future accesses
while other clients are still processing previous ones.
In this paper, we choose to instantiate our Bloom-ﬁlter
based ORAM from [19]. Regarding the choice to use Bloom
ﬁlter as an underlying ORAM, we are aware of two solu-
tions with better than the Bloom ﬁlter ORAM’s O(log2 n)
complexity: one provided by Stefanov et al [16] and one
provided by Goodrich and Mitzenmacher [3]. Neither solu-
tion, however, can provide detection of misbehavior by an
actively malicious adversary, which we deem to be an impor-
tant property. Moreover, the techniques we introduce still
apply to many existing ORAMs.
2.3 When Reality Hits
PD-ORAM is unique in providing a tangible de-amortized
implementation. De-amortized constructions do not always
lead readily to an actual implementation. Instructions such
as “perform a chunk of work sized x”, or “run the shuﬄe
in the background while querying”, are ﬁne for establishing
existence proofs, but can be devastatingly inappropriate in
achieving an actual prototype due to large hidden constants.
New techniques that address these hidden complications of
de-amortization are presented in Section 5.3.
A randomized shell sorting network identiﬁed by Goodrich
et al. [5] was subsequently employed to construct an Obliv-
ious RAM [3, 13]. This sort procedure was used in the
ﬁrst design of PD-ORAM, but was found to result in too
many disk seeks to make it usable on a even a medium-sized
database. The randomized nature of the shell short guaran-
tees that the order of item access appears non sequential and
random, making eﬃcient use of rotational hard disks diﬃ-
cult. The amortized cost of constructing the bottom level
in a terabyte database is in the range of hundreds of disk
seeks per query, already putting the implementation outside
of the targeted performance goals.
To understand this in more detail, consider the construc-
tion of the largest level of a 1 TB database. This level con-
tains at least 0.5 TB of data. For 10 KB blocks, this trans-
lates into 50 million blocks. The randomized shell sort makes
6k log2 n random passes across the database, incurring a to-
tal of 6kn log2 n seeks every n queries, where k inﬂuences
the sort failure probability. For n = 5 × 107, log2 n = 23,
translating to 138 × k disk seeks per query for the largest
level alone.
For k = 4 as suggested in the original paper [5], this amor-
tizes to 550+ disk seeks per query. Even for high-speed,
low-latency disks with 6ms seek times, this becomes at least
3.3 seconds/query (in addition to any/all other signiﬁcant
network and CPU overheads)!
Multiple Disks. Of course this can be mitigated by using
multiple disks at additional cost, in which case, the num-
ber of seeks for each disk is reduced (linearly in the added
cost) as they may occur in parallel. However, increasing
performance linearly in the added cost is not surprising nor
desirable, and an eﬃcient base-case construction should be
found instead.
Unfortunately, ORAM imposes a unique sorting require-
ment that is diﬃcult to satisfy using the randomized shell
sort. This requirement derives from the fact that, to main-
tain privacy, the sort must succeed with overwhelming prob-
ability. Moreover, all sorts must be indistinguishable, elimi-
nating the possibility of retrying in the case of failure. This
is because observation of a sort failure translates into an
advantage at distinguishing the permutation from random,
which translates into a privacy leak.
While in other applications it may suﬃce to repeat the
sort until it succeeds, when applied to ORAM, the sort pa-
rameter k must be chosen to guarantee success with over-
whelming probability. In [5] the failure rate is determined