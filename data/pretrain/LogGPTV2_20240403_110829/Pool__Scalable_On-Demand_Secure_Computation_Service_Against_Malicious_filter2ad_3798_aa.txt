title:Pool: Scalable On-Demand Secure Computation Service Against Malicious
Adversaries
author:Ruiyu Zhu and
Yan Huang and
Darion Cassel
Pool: Scalable On-Demand Secure Computation Service Against
Malicious Adversaries
Ruiyu Zhu
Indiana University
PI:EMAIL
Yan Huang
Indiana University
PI:EMAIL
Darion Cassel∗
Carnegie Mellon University
PI:EMAIL
ABSTRACT
This paper considers the problem of running a long-term on-demand
service for executing actively-secure computations. We examined
state-of-the-art tools and implementations for actively-secure com-
putation and identified a set of key features indispensable to offer
meaningful service like this. Since no satisfactory tools exist for the
purpose, we developed Pool, a new tool for building and executing
actively-secure computation protocols at extreme scales with nearly
zero offline delay. With Pool, we are able to obliviously execute, for
the first time, reactive computations like ORAM in the malicious
threat model. Many technical benefits of Pool can be attributed to
the concept of pool-based cut-and-choose. We show with experi-
ments that this idea has significantly improved the scalability and
usability of JIMU [38], a state-of-the-art LEGO protocol.
CCS CONCEPTS
• Security and privacy → Privacy-preserving protocols;
KEYWORDS
scalable actively-secure computation
1 INTRODUCTION
Secure computation has long been speculated to be a key tech-
nology for safely utilizing sensitive data owned by two or more
distrustful parties. Towards this goal, a number of theoretical and
implementational breakthroughs have significantly advanced the
practicality of secure computation. In the honest-but-curious model,
convenient programming tools [20, 28, 34] have enabled not only
benchmark applications such as AES and PSI, but also a range of
challenging applications with complex logic [31, 37], or handling
large-scale sensitive data [7, 23, 32]. Recent progresses have shown
that, with surprisingly small added cost, these protocols can be
executed even in presence of active adversaries [6, 19, 25, 27, 35],
at hundreds of thousands logical-gates per second.
∗Work done as an REU intern of Indiana University.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3134070
1
Following this exciting trend, we consider the problem of run-
ning actively-secure computation protocols as an on-demand ser-
vice between two “cautious” collaborating parties. Suppose two
standing servers are established that receive an everlasting sequence
of dynamically-supplied requests,
(f1, x1, y1),
(f2, x2, y2),
. . . ,
then securely compute them on-the-fly, and finally return the results
z1 (cid:66) f1(x1, y1),
z2 (cid:66) f2(x2, y2),
. . .
to the designated output receiver. Example scenarios of this ser-
vice can be that two credit card issuers collaboratively mine their
ever-growing databases of personal transactions using a secure
computation protocol to better identify credit card frauds; or that
two medical research institutions conduct secure cross-database
queries over their sensitive medical records, which potentially in-
volves private computations in the RAM-model.
First, we expect the security guarantee withholds across the life-
time of the everlasting secure computation service. Second, like
many other computing services, it would be natural and vital for
the service to be scalable. Here, good scalability implies being able
to efficiently handle functions that would (1) involve a large number
of inputs/outputs, (2) use arbitrarily many gates, and (3) need to be
dynamically-defined on-the-fly, and (4) be reactive sense like pri-
vately indexing a RAM. For the service to prosper, it is also expected
to offer convenient programming interfaces to allow non-crypto-
expert application developers to create innovative applications to
utilize the cryptographic marvels. We summarize a list of valuable
features for realizing such a service in Table 1.
Unfortunately, after a closer examination of existing tools in this
domain, we discover that none of them is satisfactory for running
such a service. For instance, the WMK protocol recently developed
by Wang et al. [35] offers very efficient gate execution and pro-
vides good programming support through emp-toolkit [34]. How-
ever, it couldn’t efficiently handle certain reactive computations,
such as RAM-based computation, against active adversaries (we
will discuss reactive computations in more detail in Section 2.2).
In the offline/online setting, protocols by Rindal-Rosulek [27] and
Lindell-Riva [19] enjoy very short amortized time but require know-
ing the target function well in advance, in addition to requiring
a substantial offline processing stage. It is neither clear how they
could be practically applied to RAM-based computations. Recent
works of JIMU [38] and NST [25] have revitalized much interest
in practical LEGO protocols. Nevertheless, applied naïvely, these
protocols will incur a prohibitive amount of time and memory in
offline processing, thus do not scale well to large computations.
Moreover, existing BatchedCut (a technique that batches the cut-
and-choose procedures across many computation instances) pro-
tocols [19, 25, 27, 38] require carefully selecting some protocol
Table 1: Comparison of Representative Implementations for Actively-Secure Computation Protocols.
Secure over
Infinite
Executions
Efficient
gate
processing
Efficient
input/output
processing
Short offline
delay for big
circuits
Reactive
computations1
(e.g., ORAM)
Memory-
efficient
Scaling
Blackbox
programming
APIs
KSS [17]
WMK [35]
JIMU [38]
NST [25]
LR [19]
RR [27]
WRK [36]
✓
✓
✓
✓
✓
✓
This
Work
1 We discuss reactive computations in more detail in Section 2.2.
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
parameters (such as bucket size and check rate) based on circuit
size and security requirement (e.g. 2−40 statistical security), but
did not provide a general, systematic procedure that can efficiently
scale up to arbitrary circuit-sizes and security requirements. Last
but most importantly, all existing protocols only guarantee security
for executing individual or a predefined (finite) number of instances,
hence are bound to fail if the service keeps running indefinitely.
Table 1 compares the state-of-the-art actively-secure computation
protocols.
In this work, we aim at building an actively-secure computation
framework that offers all those desirable features discussed above.
We adopt the same rationale behind the works on amortizing se-
cure computations, but go one step further by envisioning running
actively secure computations as an on-demand long-term service
between two mutually-distrusted organizations. Our starting point
is a BatchedCut protocol such as [36, 38]. But instead of always
beginning with garbling “sufficiently” many gates for a predefined
function f and then depleting all garbled-gates in the end, we opt
to always maintain a pool of garbled entries and always do cut-
and-choose within the pool. This seemingly simple idea allows
us to reap most of the benefit of BatchedCut without periodically
suffering from long delays and huge storage demands due to offline
processing, thus promising to offer a more secure, reliable, and
consistent service using moderate hardware resources.
1.1 Contribution
New Techniques. We propose a pool technique to efficiently run
batched cut-and-choose protocols at an unprecedented scale. As
a result, we are able to achieve competitive online efficiency with
nearly zero offline cost per execution. A security advantage of our
approach is that, without much extra costs, it carries over the sta-
tistical security guarantee of secure computation from a single
instance to infinitely many computation instances. We formally
analyze the security of the pool mechanism and give an efficient
algorithm to automatically identify the best parameters for running
pool-based cut-and-choose protocols. The main price of our scheme
is to build and maintain a pool, though our experiments show that
building and maintaining the pool is inexpensive in practice (see
Table 3) and the costs can be amortized over infinitely many exe-
cutions. Our approach can be applied to two underlying protocols,
JIMU [38] and WRK [36].
We also propose a more efficient way to realize actively-secure
multiplexers (MUX). The basic idea is to use a separate pool for
MUXCORE, a special gadget that is generated and checked indepen-
dently of ANDs and can then be used to implement MUX. While wire
processing accounts for roughly 60–70% of the cost of the underly-
ing LEGO protocols, our technique reduces the number of wires
of MUX by roughly 1/3. Overall, this optimization is able to boost
the performance by 30% for MUX and 6–23% for several benchmark
applications. (Section 7.2)
New Tool. We developed Pool, a software framework for building
pool-based actively secure computation protocols. Pool offers a
succinct set of APIs designed for creating future actively-secure
computations. We evaluated our approach over several applications
including Circuit ORAM, which were challenging to build and run
in the malicious threat model. To the best of our knowledge, this
is the first implementation of secure computation of ORAM in the
standard malicious model. To demonstrate the scalability of our
approach, we have run two single-threaded server programs for
actively-secure computations executing about 278M logical-AND
gates per hour, totaling at 47.3 billion logical-ANDs in seven days.
The service can continue to execute even more gates if we did not
interrupt and shutdown the servers. The source code of Pool is
made available at https://github.com/jimu-pool to stimulate future
exploration of related areas.
2 CRYPTOGRAPHIC BACKGROUND
This section briefly introduces the basic ideas of garbled circuits,
the cut-and-choose paradigm, and LEGO protocols.
w bi
i
,w
bj
j
2.1 Garbled Circuits
Garbled circuits allow two parties holding inputs x and y, respec-
tively, to evaluate an arbitrary function f (x, y) without leaking
any information about their inputs beyond what is implied by the
function output. The basic idea is that one party (the circuit gar-
bler) prepares an “encrypted” version of a circuit computing f ; the
second party (the circuit evaluator) then obliviously computes the
output of the circuit without learning any intermediate values.
i , w1
i encodes a 0-bit and w1
Starting with a Boolean circuit for f (agreed upon by both parties
in advance), the circuit generator associates two random crypto-
graphic keys w0
i (also known as wire-labels) with each wire i of
the circuit (w0
i encodes a 1-bit). Then, for
each binary gate д of the circuit with input wires i, j and output
wire k, the generator computes ciphertexts
д(bi,bj)
k
Enck
(cid:16)
(cid:17)
w
for all inputs bi , bj ∈ {0, 1}. The resulting four ciphertexts, in
random order, constitute a garbled gate. The collection of all garbled
gates forms the garbled circuit that is sent to the evaluator. In
addition, the generator reveals the mappings from output-wire
keys to bits.
x1
1 , . . . , w
The evaluator must also obtain the appropriate keys (that is,
the keys corresponding to each party’s actual input) for the input
xn
n , the keys that
wires. The generator can simply send w
correspond to its own input where each w
corresponds to the
generator’s ith input bit. The parties use oblivious transfers [13, 14,
22, 26] to enable the evaluator to obliviously obtain the input-wire
keys corresponding to its own inputs. Given keys wi , wj associated
with both input wires i, j of some garbled gate, the evaluator can
compute a key for the output wire of that gate by decrypting the
appropriate ciphertext. Thus, given one key for each input wire of
the circuit, the evaluator can compute a key for each output wire
of the circuit. With the mappings from output-wire keys to bits
provided by the garbler, the evaluator can learn the actual output
of f .
xi
i
(cid:66) w0
i , its 1-label w1
Free-XOR Technique. If the circuit garbler keeps a global secret
label ∆ and dictates that for every wire i in the circuit with 0-
i ⊕ ∆; and
label w0
i is always defined as w1
i
further, for every XOR gates with input wires i, j and an output
i ⊕ w0
wire k, the garbler always sets w0
j , then XOR can be
k
securely computed by the evaluator alone through XOR-ing the
two input wire-labels it got from evaluating previous gates. This
idea first appeared in BMR [2] for the multi-party setting and was
reinvigorated by Kolesnikov and Schneider [16] in the two-party
setting.
2.2 Dealing with Active Adversaries
(cid:66) w0
Active Adversaries. The garbled circuit protocol as described
above only works for passive adversaries who always follow the
protocol specification. However, this adversary model can be too
weak in practice as an adversary doesn’t have to follow the protocol
and can actually deviate from the protocol in arbitrary ways. For
example, a malicious garbler could plant garbage entries into a
garbled gate and infer plaintext signals on intermediate wires by
observing the evaluator’s response. Following the seminal work of
Canetti [3, 4], security of secure computation protocols in presence
of active adversaries is defined and proved with respect to an ideal
model execution where a trusted party exists to help compute the
desired functionality. Our work considers protocols against these
strong active adversaries.
The Cut-and-Choose Paradigm. The cut-and-choose paradigm is
a popular and efficient mechanism for ensuring that the garbled
circuit sent by the garbler is constructed correctly. The basic idea
is that the circuit generator produces and sends several garbled
circuits; the circuit evaluator checks a random subset of these, and
evaluates the rest to determine the final result. Existing cut-and-
choose protocols fall roughly into three categories: (1) MajorityCut,
whose security holds as long as a majority of the evaluated cir-
cuits are correct; (2) SingleCut, which guarantees security as long
as at least one of the evaluated circuits are correctly generated;
and (3) BatchedCut, where the parties batch the cut-and-choose
procedure either across multiple instances of an application or at
the gate level. Zhu et al. [39] have formalized these mechanisms
into zero-sum games and considered their cost-aware equilibrium
solutions in certain circumstances.
Reactive Functionalities. Certain reactive functionalities, such as
RAM-based secure computations, are especially cumbersome to
handle by some cut-and-choose mechanisms [1]. For example, let
f M(x, y) be a RAM-based computation that has access to a chunk
of (encrypted) memory M, through a randomized ORAM scheme.
In essence, the execution of f M(x, y) can be divided into a series
of smaller circuits f
such that:
, . . . , f
Mn
n
M1
1
(x, y;
addresses1),
(x, y; v1, addresses2),
(x, y; v2, addresses3),
vn (cid:66) f
(x, y; vn−1, addressesn).
v1 (cid:66) f
v2 (cid:66) f