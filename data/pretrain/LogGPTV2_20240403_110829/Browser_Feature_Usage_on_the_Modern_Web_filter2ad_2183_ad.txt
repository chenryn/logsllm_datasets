### Table 2: Popularity and Block Rate of Web Standards

**Columns:**
1. **Name and Abbreviation:** The name and abbreviation of the web standard.
2. **Instrumented Features:** The number of features (methods and properties) from the standard that were instrumented.
3. **Usage in Alexa 10k:** The number of pages in the Alexa 10k that used at least one feature from the standard.
4. **Block Rate:** The proportion of sites where no features in the standard executed in the presence of advertising and tracking blocking extensions, given that the website executed at least one feature from the standard in the default case.
5. **CVEs in Firefox:** The number of Common Vulnerabilities and Exposures (CVEs) associated with the standard’s implementation in Firefox within the last three years.

**Data:**
- **Web Audio API [4]:** Used on fewer than 2% of sites, but associated with at least 10 CVEs in the last 3 years.
- **WebRTC [9]:** Used on less than 1% of sites, but associated with 8 CVEs in the last 3 years.
- **Scalable Vector Graphics [13]:** Used on 1,554 sites, but blocked in 87% of cases, with at least 14 CVEs reported against Firefox’s implementation in the last 3 years.

### Figure 6: Popularity of Standards vs. Block Rate (Log Scale)

**Column 5 of Table 2:**
- Shows the number of CVEs associated with the standard’s implementation in Firefox within the last three years.
- Some standards have a high number of security vulnerabilities despite low popularity, such as the Web Audio API and WebRTC.
- Other standards, like Scalable Vector Graphics, are frequently blocked but still have a significant number of vulnerabilities.

### 5.7 Site Complexity

**Definition:**
- **Complexity:** Defined as the number of web standards used on a given website.

**Findings:**
- Most sites use between 14 and 32 out of the 74 available standards.
- No site used more than 41 standards.
- A small but measurable number of sites use little to no JavaScript at all, indicated by a second mode around zero.

### Figure 7: Comparison of Block Rates Using Advertising vs. Tracking Blocking Extensions

- Compares the block rates of standards using advertising and tracking blocking extensions.
- Shows the block rate and the number of sites using each standard.

### 6. Validation

**6.1 Internal Validation**

**Objective:**
- Verify that five rounds of automated measurements are sufficient to capture the full set of functionality used on a site.

**Method:**
- Applied the automated measurement technique to each site in the Alexa 10k ten times: five times in an unmodified browser and five times with blocking extensions.
- Measured the average number of new standards encountered on each subsequent automated crawl.

**Results:**
- By the fifth round, no new features were observed on any site, indicating that five rounds were sufficient.

**Table 3: Average Number of New Standards Encountered on Each Subsequent Automated Crawl**

| Round # | Avg. New Standards |
|---------|--------------------|
| 2       | 1.56               |
| 3       | 0.40               |
| 4       | 0.29               |
| 5       | 0.00               |

**6.2 External Validation**

**Objective:**
- Ensure that the automated measurement technique captures the same feature use as human web users.

**Method:**
- Randomly selected 100 sites from the Alexa 10k and interacted with each for 90 seconds in a casual browsing fashion.
- Compared the features used during manual interaction with the automated measurements.

**Results:**
- In 83.7% of cases, no features were observed during manual interaction that the automated measurements did not catch.
- Outliers, such as buzzfeed.com, were due to content updates between automated and manual measurements.

**Conclusion:**
- The automated measurement technique generally accurately elicits the feature use a human user would encounter, even if it does not perfectly emulate human behavior in all cases.