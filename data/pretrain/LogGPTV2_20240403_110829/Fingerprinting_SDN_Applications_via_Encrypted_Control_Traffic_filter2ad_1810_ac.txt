t contains control trafﬁc of the i-th application. As shown in
Figure 5b, we feed two types of control trafﬁc, i.e., control
trafﬁc including and excluding the i-th application, to train
the classiﬁer Ci. Thus, the architecture of neural networks
is simpliﬁed since a classiﬁer only outputs two classes, i.e.,
containing control trafﬁc of the i-th application or otherwise.
2n-ClassifierTrainControl Traffic2nTypes of Control Traffic0: consist of none of the n apps      1: consist of app-1            3: consist of app-1 and app-2…2n-1:consist of all n apps2: consist of app-2            2-ClassifierTrainControl Traffic1: contain app-iControl Traffic Includes App-i& Control Traffic Excludes App-i0: contain no app-i506          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationtween MAC addresses and switch ports, and forwards pack-
ets according to the mappings, which makes SDN switches
act as layer-2 switches. ARP Proxy provides a MAC ad-
dress of a host to answer an ARP query for an IP ad-
dress. Traffic Monitor and Link Delay Monitor mon-
itor network throughput and link delays to provide neces-
sary information for other applications, respectively. Load
Balancer optimally schedules the workloads across multi-
ple computing resources. The above six applications are bun-
dled applications in most controllers, including Floodlight,
ONOS, and OpenDaylight. Thus, we choose them as typical
applications to evaluate the effectiveness of our method on
ﬁngerprinting applications. The other four applications are
to enhance the security and privacy of SDN [27, 41, 42, 71].
Topoguard ﬁxes a vulnerability of topology poisoning that
widely exists in SDN controllers. DoS Detection applies
SDN based methods to detect the DoS attack that is one of
the most powerful attacks to disrupt a company or an or-
ganization. Anonymous Communication provides strong
anonymity guarantees for communications in SDN. Scan
Detection enables prominent trafﬁc anomaly detection al-
gorithms with SDN to effectively identify malicious activi-
ties of hosts.
The types of control messages between these applications
are overlapped. However, the control trafﬁc still has differ-
ent underlying patterns, such as packet length, contexts be-
tween packets, etc. We consider the applications as suitable
tests for deep learning both in the coverage of different ap-
plications and diversiﬁed control trafﬁc. We write a shell
script to automatically combine different applications to run
on controllers. We leverage tcpdump on the controller’s host
to capture TCP packets with the 6653 port (OpenFlow port)
between the Floodlight controller and a switch. Note that we
only leverage the above method to collect control packets for
training deep learning models. In the attacking phase, since
it is almost impossible for an attacker to run tcpdump on the
controller to collect control packets, an attacker should col-
lect them using methods mentioned in Section 3.1. We save
each captured control trafﬁc for one combination of SDN ap-
plications into a text ﬁle. We write a Python program to au-
tomatically label all control packets in each text ﬁle accord-
ing to the combination of the applications. Due to storage
constraints, we only save extracted metadata from traces of
control trafﬁc. The metadata consists of the capture time of
packets, the directions of packets, and the lengths of packets.
We discard encrypted payloads of packets since they have lit-
tle value for an adversary. We remove TCP acknowledgment
(ACK) packets containing no control messages.
there are 6,144,000,000 control packets and 1024 text ﬁles.
Our current dataset only contains control packets between
one switch and the controller. Although collecting more con-
trol ﬂows between multiple switches and the controller may
help to improve the accuracy of ﬁngerprinting applications,
we aim to study the accuracy of ﬁngerprinting in a general-
ized case since eavesdropping one control ﬂow for an adver-
sary is easy.
5 Evaluation
In this section, we conduct comprehensive experiments to
verify the feasibility of ﬁngerprinting SDN applications. We
ﬁrst evaluate the accuracy, precision, and recall rate for 10
applications with three popular deep learning models. Then,
we explore how the effectiveness changes with different split
lengths of control trafﬁc and different number of datasets.
Finally, we evaluate the training time for building a classiﬁer
to ﬁngerprint an SDN application.
5.1 Experiment Setup
We implement three models, i.e., SDAE, LSTM, and CNN,
for each of the 10 applications with Keras in Python. We
train each model on a server equipped with one Intel Xeon
Silver 4116 CPU (12 cores), 128 GB RAM, 1TB SSD, and
NVIDIA Quadro P4000 GPUs. To train a model for an appli-
cation, we divide all traces of mixed control trafﬁc into two
classes:
the ﬁrst contains control trafﬁc of the application
and the second contains no control trafﬁc of the application.
We randomly select 60% samples from both the classes as
the training set, 20% samples as the test set, and 20% sam-
ples as the validation set. We initially deﬁne a sequence of
150 control packets as one sample. Moreover, we change the
length of one sample to explore how different split lengths
affect the effectiveness of ﬁngerprinting SDN applications.
In order to accurately ﬁngerprint SDN applications, hy-
perparameters of each model should be well tuned so that
models have the best classiﬁcation performance and gener-
alize well to unseen trafﬁc traces. Although conducting an
exhaustive grid search or other search algorithms is effec-
tive, it is computationally expensive. In our experiment, we
semi-automatically tune hyperparameters. We ﬁrst conduct
a grid search with a small dataset, i.e., one-tenth of the orig-
inal dataset, to know the impacts of each hyperparameter.
We next manually adjust parameters with the original dataset
based on our experience and experimental results. We list
our ﬁnal parameters in Appendix A.
4.2 Dataset
Our dataset contains 6,000,000 control packets for each com-
bination of the 10 applications. Each type of control trafﬁc
for one combination is saved in a separated text ﬁle. Totally,
5.2 Effectiveness
Effectiveness with Different Models. We initially set the
split length of a sample as 150. Table 3 shows the accu-
racy, recall rate, and precision of ﬁngerprinting SDN ap-
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 507Table 3: The Effectiveness of Fingerprinting SDN Applications with different DNN Models.
SDN
Applications
Topology Discovery
Learning Switch
ARP Proxy
Traffic Monitor
Link Delay Monitor
TopoGuard
Load Balancer
DoS Detection
Anonymous Comm
Scan Detection
Average Value
Standard Deviation
SDAE
Accuracy Recall
90.8%
90.6%
97.3%
96.4%
83.7%
87.1%
96.5%
94.4%
93.4%
92.9%
94.8%
94.8%
91.9%
93.1%
90.2%
89.6%
98.2%
97.4%
94.5%
95.6%
93.0%
93.3%
3.2%
4.0%
LSTM
Precision Accuracy Recall
95.7%
94.1%
99.6%
92.7%
95.7%
83.9%
94.1%
92.5%
94.6%
98.5%
98.5%
97.5%
93.1%
87.2%
90.0%
88.7%
97.5%
94.9%
96.6%
87.7%
95.0%
92.3%
5.0%
2.5%
92.7%
98.3%
92.2%
92.8%
93.2%
95.4%
90.6%
94.3%
98.1%
94.2%
94.2%
2.4%
CNN
Precision Accuracy Recall
92.5%
89.0%
90.3%
88.8%
92.8%
88.1%
93.0%
91.7%
99.3%
84.5%
92.0%
83.5%
95.3%
85.4%
97.9%
90.3%
83.8%
89.3%
94.0%
94.2%
93.3%
88.3%
3.7%
3.3%
94.2%
96.4%
94.3%
90.6%
96.5%
95.7%
97.1%
97.8%
94.7%
96.8%
95.4%
2.0%
Precision
99.3%
99.5%
90.8%
97.9%
95.2%
98.7%
97.3%
96.3%
92.6%
98.7%
96.6%
2.8%
plications. For an application, different models perform
differently. For example, the accuracy for identifying ARP
Proxy is 87.1%, 92.2%, and 94.3% for SDAE, LSTM, and
CNN, respectively. The difference between the highest ac-
curacy and the lowest accuracy is 7.2%. The recall rate
and precision also change with different models. More-
over, SDAE performs best for Anonymous Communication
with a 98.2% accuracy, LSTM performs best for Learning
Switch with a 98.3% accuracy, and CNN performs best for
DoS Detection with a 97.8% accuracy. Our interpretation
is that different models have different capabilities to charac-
terize underlying patterns of applications. Besides, different
applications have unique patterns that may be more suitable
for extraction with some deep learning model.
Among the three models, LSTM performs the best for
the recall rate with an average value of 95.0%. However,
it achieves a low precision, i.e., 88.3% on average. Par-
ticularly, there is only an 83.8% precision for Anonymous
Communication. CNN performs the best both for the ac-
curacy and the precision, which achieves a 95.4% accuracy
and a 96.6% precision on average. 7 of the 10 applications
have the highest accuracy and 8 of the 10 applications have
the highest precision with CNN compared to the other two
models. Moreover, CNN achieves an acceptable recall rate
of 93.3% on average. SDAE achieves a 93.3% accuracy, a
93.0% recall rate, and a 92.3% precision on average. It per-
forms the worst for the accuracy and the recall rate.
We evaluate the stability of the three models on ﬁnger-
printing different applications with the standard deviation.
SDAE has the highest standard deviations of accuracy, recall
rate, and precision. LSTM has the lowest standard deviation
of recall rate and the moderate standard deviations of accu-
racy and precision. CNN outperforms the other two models
both in the standard deviations of accuracy and precision and
has a moderate standard deviation of recall rate, which is the
most stable deep learning model.
Overall, by comparing the three models with each other,
we observe that CNN is the most effective and stable for
an adversary to ﬁngerprint different SDN applications, es-
pecially in classiﬁcation accuracy and precision.
Effectiveness with Different Split Lengths. The effective-
ness of ﬁngerprinting SDN applications may change with
different lengths of samples. Thus, we divide sequences of
control packets into different lengths to train and test deep
neural networks. Because CNN performs best, we here ex-
plore its accuracy, recall rate, and precision of ﬁngerprinting
applications with different lengths of samples.
Figure 6 shows the accuracy for ﬁngerprinting differ-
ent applications with various split lengths. The results
show the accuracy of ﬁngerprinting an application goes up
with the split length. When the split length is 50, ﬁn-
gerprinting most applications achieves a low accuracy that
is less than 90%.
Particularly, ﬁngerprinting Traffic
Monitor only reaches an accuracy of 81.2%. When the
split length is increased to 250, the accuracy reaches more
than 95% for 9 of the 10 applications. The accuracy
of ﬁngerprinting Learning Switch, Traffic Monitor,
Topoguard, and Anonymous Communication increases
by more than 10%. The reason is that more packets in a
sample give more underlying patterns. Although the accu-
racy goes up with the split length, the growth rate of the ac-
curacy gradually slows down. When we increase the split
length from 200 to 250, the accuracy is increased less than
1% for most applications and tends to converge.
Figure 7 shows the recall rate for ﬁngerprinting different
applications with various split lengths. Similar to the ac-
curacy, the recall rate goes up with split lengths. When the
split length is increased from 50 to 150, the recall rate for ﬁn-
508          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association(a) Accuracy of First Five Apps.
(b) Accuracy of Last Five Apps.
Figure 6: Accuracy of Fingerprinting SDN Applications with Different Split Lengths.
(a) Recall Rate of First Five Apps.
(b) Recall Rate of Last Five Apps.
Figure 7: Recall Rate of Fingerprinting SDN Applications with Different Split Lengths.
gerprinting most applications increases signiﬁcantly. For in-
stance, the recall rate for ﬁngerprinting Learning Switch
increases by 13.2%. There are two exceptions of SDN appli-
cations, i.e., Link Delay Monitor and DoS Detection.
The recall rate of ﬁngerprinting the two applications is al-
ready more than 90% even with a small part of control traf-
ﬁc, i.e., 50 packets, and improves slightly with more control
packets in a sample. When the split length is greater than
150, the recall rate stops signiﬁcant improvement.
Figure 8 shows the precision for ﬁngerprinting different
applications with various split lengths. The precision gradu-
ally increases with the split length, following a similar trend
like the accuracy and the recall rate. When the split length
is increased from 50 to 250, the precision for ﬁngerprint-
ing Learning Switch improves the most, i.e., a 12.8% in-
crease, and the precision for ﬁngerprinting DoS Detection
improves the least, i.e., a 5.3% increase. Moreover, the pre-
cision for ﬁngerprinting most applications does not signiﬁ-