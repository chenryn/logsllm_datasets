if min id(RSpred) < min id(RSvn) then
if vn.id < min id(RSpred) then
pred.successorexternal.add(vn)
if br! = N U LL then
br.join external(vn, p)
The join external function (Algorithm 3) shows this process in
more detail. First, the external successor at a level is discovered by
routing towards the external predecessor at that level and then prun-
ing away any references to virtual nodes outside the current hierar-
chy in both the predecessor’s and the virtual node’s routing state.
After pruning, the virtual node with the minimum identiﬁer in the
predecessor’s routing state is kept if it is a better external succes-
sor than the virtual node’s current set of successors. The next step
of the algorithm tests if the virtual node itself is a better external
successor to the predecessor, and if so adds it to the predecessor’s
routing state. The ﬁnal step uses the path vector passed in as the
argument to recursively call this same function at the border router
of the next provider. This recursive call terminates at the root of the
hierarchy.
Exploiting network proximity: ROFL exploits network proxim-
ity to reduce routing stretch by maintaining proximity-based ﬁngers
in addition to successor pointers. That is, when selecting ﬁngers at
each level of the hierarchy, ROFL tries to select ﬁngers that are
nearby in the physical network. This reduces the number of net-
work level hops required to make a given amount of progress in the
namespace.
We store these ﬁngers in a preﬁx-based ﬁnger table (along the
lines of Bamboo/Pastry/Tapestry), where each row corresponds to
a given preﬁx-length and each column corresponds to a digit at that
preﬁx. Each entry contains an ID that is reachable via the smallest
number of up-links. In other words, an entry K may be inserted in
the element (i, j) in J’s ﬁnger table iff (a) K matches i bits of J’s
ID and K’s [i, i + b] bits are equal to digit j (b) of all joined IDs
L matching the position (i, j), it is not the case that the path from
J to L contains fewer up-links than the path J to K. If this table is
correctly maintained, the isolation property is preserved. To exploit
proximity, entries that are reachable via fewer AS-level hops are
preferred. For correctness purposes, each ID also maintains a list
of IDs that are pointing to it.
Our joining and maintenance protocols for these ﬁngers are
adapted from the proximity extensions in [9] to support the poli-
cies and properties described in Section 4.2. The join consists of
three phases. First, the joining host sends a join request towards its
own ID. At each network-level hop n, n attempts to insert entries
from its own ﬁnger table into the message. The message is then re-
turned back to J after it reaches J’s predecessor. At this point, J’s
entries are correct. Next, J may need to be inserted into the ﬁnger
tables of other IDs. This is done by having virtual nodes maintain
copies of their ﬁnger’s ﬁnger tables. In particular, we modify the
join to also record a list of IDs that need to insert J. J then sends
a multicast message containing its ID to every virtual node in this
list. Upon receipt of this message, virtual nodes check to see if any
of their ﬁngers need to insert J, and if so update their neighbors,
and so on. Nodes also piggyback probes on data packets to ensure
this state is maintained correctly (note if this state becomes incon-
sistent, isolation may be violated, but we will still reach the correct
ﬁnal destination).
We now describe several other detailed issues:
Failure recovery: The isolation property ensures that failures and
instability outside of a particular hierarchy will not inﬂuence rout-
ing within the hierarchy. Because of this, link failures that cause
partitions (the inability to reach successors via a certain level of the
hierarchy) are not reacted to immediately, as ROFL ensures that al-
ternate paths are available. Also, an ISP may host virtual servers
on behalf of a customer ISP, which it can maintain during that cus-
tomer’s outages. Finally, in the event of long-term failures, we need
to ensure that the ring converges consistently at each level of the
hierarchy. We do this using a similar approach to that given in Sec-
tion 3.2. In particular, each AS maintains a route to the zero-ID
(the ID closest to zero) in their down-hierarchy. Hosts then merge
changes to the zero-ID to ensure partitions and other anomalous
conditions (e.g. loopy cycles) heal properly.
Integrating EGP and IGP routing: Today’s Internet uses iBGP
to redistribute externally learned routes internally. In our architec-
ture, we have a similar need for a protocol to do this redistribution.
As mentioned in previous sections, packets contain a list of ISPs
that can be used to reach the ﬁnal destination. Hence a router con-
taining a packet needs to know how to reach the next-hop AS in
the list. To solve this problem, we have border routers ﬂood their
existence internally. We believe doing this does not signiﬁcantly
impact performance since even the largest ISPs typically only have
a few hundred border routers. Moreover, these advertisements can
be aggregated if ISPs wish to treat two routes to the same next-hop
ISP through different border routers as being equal.
Exploiting reference locality: ROFL exploits locality by us-
ing pointer-caches [7]. Routers maintain caches in fast memory
which contain frequently accessed routes. When routing a packet,
the router checks its pointer cache, and shortcuts if it observes a
cached pointer is numerically closer to the ﬁnal destination. How-
ever, naive pointer-caching violates the isolation property, as an AS
may select a pointer from its cache that traverses its provider. Hence
ASes that cache pointers maintain bloom ﬁlters containing the set
of hosts joined below that AS. When receiving a packet destined to
identiﬁer idb, the border router consults the bloom ﬁlter to see if
identiﬁer idb is below it in the hierarchy. If not, the router is free to
use its pointer-cache to ﬁnd a closer next-hop ID. The source-route
on the packet is used to determine which pointer-cache entry to use
based on policy. Note that the use of bloom ﬁlters guarantees the
Figure 4: Conversion rules for (a) peering (b) multihoming and
backup.
isolation property in the presence of caching. Further, the size of
bloom ﬁlters can be traded off against the false positive rate. Fi-
nally, the decision of whether to use pointer caches can be made
by each ISP in isolation. Unless otherwise mentioned, in our simu-
lations we assume no ISPs use interdomain pointer caches or their
associated bloom ﬁlters.
4.2 Handling policies
We aim to support four common types of inter-ISP relation-
ships arising from the Internet’s hierarchical structure: provider-
customer links where a customer ISP pays a provider to forward
its trafﬁc, peering links where two ISPs forward each other’s trafﬁc
typically without exchanging payment, backup links where an ISP
forwards to its neighbor only if there is a failure along its primary
link, and multihomed connections, where an ISP may have several
outgoing links. We extend Canon [17] to support policies using two
conversion rules (Figure 4) that conceptually convert the AS hierar-
chy into a Canon-style hierarchy (these rules do not actually mod-
ify ISP relationships, but rather are implemented as modiﬁcations
to the Canon join).
Handling peering: As previously mentioned, we can handle a
peering relationship in two ways. In the ﬁrst option, we modify
the AS relationship graph to include virtual ASes. A virtual AS is
a construct that allows ROFL to discover successors reachable via
peering links (it is not explicitly maintained as additional state, but
is implemented as an additional set of join rules). An example is
shown in Figure 4a. For each peering link, a virtual AS is con-
structed that acts as a provider for the ASes on either side of the
link, and as a customer of each AS’s provider. When virtual nodes
join, they treat links to virtual ASes as multihomed links, and join
them as they would a provider. In this fashion, a host in AS 2 will
discover its successors in AS 3, however Canon will ensure that
its join will not traverse AS 1 (because relaying between providers
is prevented as described below). Note that if several ASes are all
peered together in a clique (e.g. the Tier 1 ISPs), we only need a
single virtual AS rather than a separate virtual AS for each link.
In the second option, we use bloom ﬁlters to deduce when a
packet should be allowed to traverse a peering link. When the
packet is being routed via an AS (using successor pointers or rout-
ing table entries), the AS can check the bloom ﬁlters corresponding
to its peers to determine if the destination is a customer of any of
them. If so, the packet is routed over the peering link, and a bit
set to indicate that it has traversed a peering link. In this mode, the
packet is not allowed to go up the hierarchy (this ensures that an
AS would not use its provider to route packets for its peer). If the
destination is not found in the down hierarchy, then it is returned
over the peering link, at which point, the packet continues on its
original path.
These two options have complementary advantages and disad-
vantages. The virtual AS option has the disadvantage of increasing
join overhead (due to joins corresponding to the peering links), but
it makes the data plane protocol simpler. The bloom ﬁlter option
has the disadvantage of requiring a complicated backtracking pro-
tocol, but requires no joins over peering links. For this reason, we
describe simulation results comparing both of these design options.
Handling multihoming: A multihomed ISP purchases connectiv-
ity from more than one provider and typically has policies indi-
cating how each access link is to be used. There are three kinds
of multihomed connections: single-address multihoming, where an
ISP has a single block of addresses but is connected to multiple
providers, multi-address multihoming, where an ISP has a sepa-
rate block of addresses corresponding to each multihomed con-
nection, and single-neighbor multihoming, where an ISP is con-
nected with a neighboring ISP via multiple links. Multi-address
multihoming is handled by joining each ID via a different provider,
and single-neighbor multihoming is handled by applying policy
to select which link to use to reach the neighbor. Single-address
multihoming is done by repeating the Canon join for each mem-
ber of the AS’s up-hierarchy. The up-hierarchy for an AS consists
of its providers, their providers, and so on up to the Tier-1 ISPs,
plus ASes reachable across peering links (although repeating the
join increases overhead, the up-hierarchy above a node is typically
small [41], and we can eliminate redundant lookups that terminate
at the same successor at multiple levels). Finally, backup relation-
ships are supported by directing join requests only over non-backup
links.
5. ADDITIONAL ROUTING ISSUES
We now describe preliminary extensions to the ROFL design to
(a) support more ﬂexible routing policies and trafﬁc engineering
(b) provide improved delivery models such as anycast, multicast (c)
deal with security concerns, speciﬁcally, denial-of-service attacks.
The last two concerns are meant to be illustrative examples that
suggest how the clean-slate design of ROFL may provide better-
than-IP routing and security properties.
5.1 Routing Control
BGP and OSPF, two commonly used routing protocols today,
allow the operator extremely ﬂexible policy and trafﬁc engineering
knobs. We discuss the ﬂexibility of ROFL on these metrics.
Inter-domain routing control: ROFL’s policy extensions support
customer-provider, backup, and peering relationships. Although
these paths may sufﬁce for most trafﬁc, custom paths that satisfy
high-level policy goals, stronger QoS constraints, or multipath con-
nectivity may be desired. We propose to handle other policies and
route selection mechanisms via two complementary approaches.
We propose the use of endpoint-based negotiation where we al-
low the source and destination nodes to negotiate the path (or set of
paths) to be used. Here, we leverage a particular observation about
the Internet hierarchy: all paths that can be used to reach AS X
from AS Y traverse ASes in the intersection of X’s and Y ’s up-
hierarchies. Moreover, up-hierarchies are typically fairly small and
can be represented in just a few hundred bytes. Hence when send-
ing the ﬁrst packet in a session, we allow the source and destination
to negotiate a subset of ASes in this set that can be used to forward
packets between the two. This is done by having the destination se-
lect a subset of ASes above it in the hierarchy and appending this
set to the response.
Next, when a hosting router in a multihomed AS performs a join,
it sends a join out on each of its AS’s p providers with IDs with
variable sufﬁxes (G, xk) (1 ≤ k ≤ p). Hosts then route packets to
(G, r) where r is a randomly chosen sufﬁx. Hosts or intermediate
routers may vary r and the sufﬁxes xk to control the path selected
for forwarding packets.
Intra-domain routing control: We can leverage our interdomain
design to deal with certain intradomain policies. For example, a
transit AS that is spread over multiple countries can create sub-
rings corresponding to each of those regions. The isolation prop-
erty ensures that internal trafﬁc will not transit costly inter-country
links. Further, our inter-domain trafﬁc engineering mechanisms
may also be used in this context to perform trafﬁc-engineering be-
tween these regions.
5.2 Enhanced Delivery Services
There are a vast number of both overlay and network-level pro-
posals for multicast and anycast, many of which can run directly
on top of the ROFL design. A few representative (but grossly
incomplete) list of examples includes IP Multicast [12], Over-
cast [21], PIAS [5], and i3 [33]. However, traditional overlay-based
approaches don’t exploit the network layer to improve efﬁciency,
and current network-level designs don’t directly scale to or exploit
the properties of ﬂat-ID based routing. In this section, we describe
some simple extensions to previous approaches that enable anycast
and multicast.
Anycast: Anycast is an extension of ROFL’s multihoming design.
Servers belonging to group G join with ID (G, x). A host may then
route to (G, y), where y is set arbitrarily. Intermediate routers for-
ward the packet towards G, treating all sufﬁxes equally. This results
in the packet reaching the ﬁrst server in G for which the packet
encounters a route. This style of anycast can be extended to per-
form more advanced functions (e.g. load balancing) by modifying
X, Y and the size of G in a manner similar to the approach taken
in i3 [33]. This approach to anycast requires no additional state or
control message overhead beyond that of joining the network.
Multicast: A host wishing to join the multicast group G sends an
anycast request towards a nearby member of G. At each hop, the
message adds a pointer corresponding to the group pointing back
along the reverse path, in a manner similar to path-painting [20]. If
the message intersects a router that is already part of the group, the
packet does not traverse any further. The end result is a tree com-
posed of bidirectional links. A host wishing to multicast a packet
P forwards the packet along this tree. Routers forward a copy of
P out all outgoing links for which there are pointers, excluding the
link on which P was received. In the case of single-source multi-
cast, a more efﬁcient tree can be constructed by having nodes route
towards the source.
5.3 Security
ROFL identiﬁers allow us to leverage existing ﬁltering and capa-
bility mechanisms and provide stronger guarantees than possible in
the Internet today.
Default off: It has been proposed (for example, in [4, 19]) that in
the face of mounting security concerns, hosts should not by default
be reachable from other hosts. Our architecture eases this by en-
suring hosts are only reachable from their ﬁngers. The host (or its
upstream router on its behalf) can control pointer construction to
limit which other hosts are allowed to reach it. In addition, we re-
quire that hosts explicitly register with their providers and trafﬁc to
a host not registered with its provider be dropped. In the worst case
this trafﬁc can be dropped at the provider of the destination AS,
however the use of ﬂat identiﬁers can potentially allow this trafﬁc
to be dropped even earlier. Filtering mechanisms can also be imple-
mented more securely by verifying that the request for installing a
ﬁlter dropping trafﬁc to an identiﬁer comes from the host owning
that identiﬁer.
Capabilities: The use of ﬂat identiﬁers allows more ﬁne-grained
access control through the use of capabilities (similar to TVA [42]).
When a destination receives a route setup request, it grants access
according to its own policies. If permission is granted, the path in-
formation and capability are returned to the source, which it uses
to communicate further with the destination. This permission is
cryptographically secured by the self-certifying identiﬁer of the re-
ceiver. A capability [42] is a cryptographic token designating that
a particular source (with its own unique identiﬁer) is allowed to
contact the destination. Only with a proper capability will the data
plane forward the data packets. Capabilities are associated with a
lifetime to defend against sources that attempt to abuse the capa-
bility and commit a DoS attack against the destination. ROFL also
supports the use of path capabilities to further restrict communi-
cation along the AS-level path(s) to a destination. Path restriction
allows for ﬁne grain pushback mechanisms and hinders the ability
to conduct DDoS attacks.
6. EVALUATION
6.1 Methodology
Realistically simulating the Internet is itself a highly challeng-
ing problem, both due to scaling issues and because certain as-
pects of the Internet (e.g. ISP policies) are difﬁcult to infer. We
conducted some highly simpliﬁed simulations to make the evalua-
tion tractable, yet as much as possible attempted to use real-word
measurements for topologies and parameter settings.
Intradomain: The topologies we used were collected from Rock-
etfuel [32], over 4 large ISPs: AS 1221 (318 routers, 2.6 million
hosts), AS 1239 (604 routers, 10 million hosts), AS 3257 (240
routers, 0.5 million hosts), AS 3967 (201 routers, 2.1 million hosts).
The number of hosts in each of these ISPs were estimated using
CAIDA skitter [43] traces. We do this by correlating the IP ad-
dresses found in the traces with Routeviews [48] routing tables to
map IP addresses onto ASes. We then normalize by the number of
estimated hosts in the Internet, which we assume to be 600 million
hosts (one study [46] estimates 354 million as of July 2005) to es-
timate the number of hosts per AS. Each host is assigned a 128-bit
ID. Transit routers are presumed to have 9Mbits of fast memory
(e.g. TCAM) that can be devoted to intradomain forwarding state.
In these experiments we ﬁll pointer caches only with contents avail-
able from control packets (we do not snoop on data packet headers
for ﬁlling caches). We occasionally point out the overheads associ-
ated with CMU-ETHERNET [27], an alternate approach to a sim-
ilar problem. We acknowledge the authors of [27] were attempting
to provide a simpliﬁed ﬁrst-cut solution to this problem rather than
to achieve this level of scalability, so we reference their work only
as a baseline comparison point.
Interdomain: We use the complete inter-AS topology graph sam-
pled from Routeviews. The AS hierarchy inference tool developed
by Subramanian et al [35] was used to infer customer/provider re-
lationships and skitter traces were used to estimate the number of
hosts per ISP. Due to the limitations of our simulation approach and
our goals for preserving certain aspects of realism, our simulations
were not able to scale up to 600 million hosts. Instead, we ran sim-
ulations for smaller numbers of hosts (up to thirty thousand) and
present scaling trends from our evaluation. For simplicity and lack
of sufﬁciently ﬁne-grained measurements, we model each AS as a
single node, and start nodes up one at a time (in random order). Un-
less otherwise mentioned, the results shown do not use the bloom
ﬁlter or ﬁnger caching optimizations.
Metrics: We evaluate the join overhead, which corresponds to the
number of network-level messages required to add a host to the
network, the stretch, or the ratio between the traversed path and the
shortest path. For Interdomain, we consider stretch to be the ratio
of the traversed path to the path BGP would select.
6.2 Intradomain
Host joins: Figure 5a shows the number of messages required to
join a given number of hosts, while Figure 5b shows a CDF of the
per-host join overhead. Like CMU-ETHERNET (not shown due to
lack of space), ROFL scales linearly in the number of hosts. How-
ever, CMU-ETHERNET requires between 37 and 181 times more
messages to build the network. ROFL’s join overhead is roughly