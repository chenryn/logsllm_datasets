The Psychology of Security—DRAFT 
June 28, 2007 
Bruce Schneier 
13544 words 
Introduction 
Security is both a feeling and a reality.  And they’re not the same. 
The reality of security is mathematical, based on the probability of different risks and the 
effectiveness of different countermeasures.  We can calculate how secure your home is from 
burglary, based on such factors as the crime rate in the neighborhood you live in and your door-
locking habits.  We can calculate how likely it is for you to be murdered, either on the streets by a 
stranger or in your home by a family member.  Or how likely you are to be the victim of identity 
theft.  Given a large enough set of statistics on criminal acts, it’s not even hard; insurance 
companies do it all the time. 
We can also calculate how much more secure a burglar alarm will make your home, or how 
well a credit freeze will protect you from identity theft.  Again, given enough data, it’s easy. 
But security is also a feeling, based not on probabilities and mathematical calculations, but 
on your psychological reactions to both risks and countermeasures.  You might feel terribly 
afraid of terrorism, or you might feel like it’s not something worth worrying about.  You might 
feel safer when you see people taking their shoes off at airport metal detectors, or you might not.  
You might feel that you’re at high risk of burglary, medium risk of murder, and low risk of 
identity theft.  And your neighbor, in the exact same situation, might feel that he’s at high risk of 
identity theft, medium risk of burglary, and low risk of murder. 
Or, more generally, you can be secure even though you don’t feel secure.  And you can feel 
secure even though you’re not.  The feeling and reality of security are certainly related to each 
other, but they’re just as certainly not the same as each other.  We’d probably be better off if we 
had two different words for them. 
This essay is my initial attempt to explore the feeling of security: where it comes from, how 
it works, and why it diverges from the reality of security. 
Four fields of research—two very closely related—can help illuminate this issue.  The first is 
behavioral economics, sometimes called behavioral finance.  Behavioral economics looks at 
human biases—emotional, social, and cognitive—and how they affect economic decisions.  The 
second is the psychology of decision-making, and more specifically bounded rationality, which 
examines how we make decisions.  Neither is directly related to security, but both look at the 
concept of risk: behavioral economics more in relation to economic risk, and the psychology of 
decision-making more generally in terms of security risks.  But both fields go a long way to 
explain the divergence between the feeling and the reality of security and, more importantly, 
where that divergence comes from. 
There is also direct research into the psychology of risk.  Psychologists have studied risk 
perception, trying to figure out when we exaggerate risks and when we downplay them. 
A fourth relevant field of research is neuroscience.  The psychology of security is intimately 
The Psychology of Security—DRAFT 
2 
tied to how we think: both intellectually and emotionally.  Over the millennia, our brains have 
developed complex mechanisms to deal with threats.  Understanding how our brains work, and 
how they fail, is critical to understanding the feeling of security. 
These fields have a lot to teach practitioners of security, whether they’re designers of 
computer security products or implementers of national security policy.  And if this paper seems 
haphazard, it’s because I am just starting to scratch the surface of the enormous body of research 
that’s out there.  In some ways I feel like a magpie, and that much of this essay is me saying: 
“Look at this!  Isn’t it fascinating?  Now look at this other thing!  Isn’t that amazing, too?”  
Somewhere amidst all of this, there are threads that tie it together, lessons we can learn (other 
than “people are weird”), and ways we can design security systems that take the feeling of 
security into account rather than ignoring it. 
The Trade-Off of Security 
Security is a trade-off.  This is something I have written about extensively, and is a notion 
critical to understanding the psychology of security.  There’s no such thing as absolute security, 
and any gain in security always involves some sort of trade-off. 
Security costs money, but it also costs in time, convenience, capabilities, liberties, and so 
on.  Whether it’s trading some additional home security against the inconvenience of having to 
carry a key around in your pocket and stick it into a door every time you want to get into your 
house, or trading additional security from a particular kind of airplane terrorism against the 
time and expense of searching every passenger, all security is a trade-off. 
I remember in the weeks after 9/11, a reporter asked me: “How can we prevent this from 
ever happening again?”  “That’s easy,” I said, “simply ground all the aircraft.” 
It’s such a far-fetched trade-off that we as a society will never make it.  But in the hours 
after those terrorist attacks, it’s exactly what we did.  When we didn’t know the magnitude of the 
attacks or the extent of the plot, grounding every airplane was a perfectly reasonable trade-off to 
make.  And even now, years later, I don’t hear anyone second-guessing that decision. 
It makes no sense to just look at security in terms of effectiveness.  “Is this effective against 
the threat?” is the wrong question to ask.  You need to ask: “Is it a good trade-off?”  Bulletproof 
vests work well, and are very effective at stopping bullets.  But for most of us, living in lawful and 
relatively safe industrialized countries, wearing one is not a good trade-off.  The additional 
security isn’t worth it: isn’t worth the cost, discomfort, or unfashionableness.  Move to another 
part of the world, and you might make a different trade-off. 
We make security trade-offs, large and small, every day.  We make them when we decide to 
lock our doors in the morning, when we choose our driving route, and when we decide whether 
we’re going to pay for something via check, credit card, or cash.  They’re often not the only factor 
in a decision, but they’re a contributing factor.  And most of the time, we don’t even realize, it.  
We make security trade-offs intuitively. 
These intuitive choices are central to life on this planet.  Every living thing makes security 
trade-offs, mostly as a species—evolving this way instead of that way—but also as individuals.  
Imagine a rabbit sitting in a field, eating clover.  Suddenly, he spies a fox.  He’s going to make a 
security trade-off: should I stay or should I flee?  The rabbits that are good at making these 
trade-offs are going to live to reproduce, while the rabbits that are bad at it are either going to 
get eaten or starve.  This means that, as a successful species on the planet, humans should be 
really good at making security trade-offs. 
The Psychology of Security—DRAFT 
3 
And yet, at the same time we seem hopelessly bad at it.  We get it wrong all the time.  We 
exaggerate some risks while minimizing others.  We exaggerate some costs while minimizing 
others.  Even simple trade-offs we get wrong, wrong, wrong—again and again.  A Vulcan 
studying human security behavior would call us completely illogical. 
The truth is that we’re not bad at making security trade-offs.  We are very well adapted to 
dealing with the security environment endemic to hominids living in small family groups on the 
highland plains of East Africa.  It’s just that the environment of New York in 2007 is different 
from Kenya circa 100,000 BC.  And so our feeling of security diverges from the reality of 
security, and we get things wrong. 
There are several specific aspects of the security trade-off that can go wrong.  For example: 
1. The severity of the risk. 
2. The probability of the risk. 
3. The magnitude of the costs. 
4. How effective the countermeasure is at mitigating the risk. 
5. How well disparate risks and costs can be compared. 
The more your perception diverges from reality in any of these five aspects, the more your 
perceived trade-off won’t match the actual trade-off.  If you think that the risk is greater than it 
really is, you’re going to overspend on mitigating that risk.  If you think the risk is real but only 
affects other people—for whatever reason—you’re going to underspend.  If you overestimate the 
costs of a countermeasure, you’re less likely to apply it when you should, and if you overestimate 
how effective a countermeasure is, you’re more likely to apply it when you shouldn’t.  If you 
incorrectly evaluate the trade-off, you won’t accurately balance the costs and benefits. 
A lot of this can be chalked up to simple ignorance.  If you think the murder rate in your 
town is one-tenth of what it really is, for example, then you’re going to make bad security trade-
offs.  But I’m more interested in divergences between perception and reality that can’t be 
explained that easily.  Why is it that, even if someone knows that automobiles kill 40,000 people 
each year in the U.S. alone, and airplanes kill only hundreds worldwide, he is more afraid of 
airplanes than automobiles?  Why is it that, when food poisoning kills 5,000 people every year 
and 9/11 terrorists killed 2,973 people in one non-repeated incident, we are spending tens of 
billions of dollars per year (not even counting the wars in Iraq and Afghanistan) on terrorism 
defense while the entire budget for the Food and Drug Administration in 2007 is only $1.9 
billion? 
It’s my contention that these irrational trade-offs can be explained by psychology.  That 
something inherent in how our brains work makes us more likely to be afraid of flying than of 
driving, and more likely to want to spend money, time, and other resources mitigating the risks 
of terrorism than those of food poisoning.  And moreover, that these seeming irrationalities have 
a good evolutionary reason for existing: they’ve served our species well in the past.  
Understanding what they are, why they exist, and why they’re failing us now is critical to 
understanding how we make security decisions.  It’s critical to understanding why, as a 
successful species on the planet, we make so many bad security trade-offs. 
Conventional Wisdom About Risk 
Most of the time, when the perception of security doesn’t match the reality of security, it’s 
The Psychology of Security—DRAFT 
4 
because the perception of the risk doesn’t match the reality of the risk.  We worry about the 
wrong things: paying too much attention to minor risks and not enough attention to major ones.   
We don’t correctly assess the magnitude of different risks.  A lot of this can be chalked up to bad 
information or bad mathematics, but there are some general pathologies that come up over and 
over again. 
In Beyond Fear, I listed five: 
• 
People exaggerate spectacular but rare risks and downplay common risks. 
• 
People have trouble estimating risks for anything not exactly like their normal 
situation. 
• 
Personified risks are perceived to be greater than anonymous risks. 
• 
People underestimate risks they willingly take and overestimate risks in situations 
they can’t control. 
• 
Last, people overestimate risks that are being talked about and remain an object of 
public scrutiny.1   
David Ropeik and George Gray have a longer list in their book Risk: A Practical Guide for 
Deciding What’s Really Safe and What’s Really Dangerous in the World Around You: 
• 
Most people are more afraid of risks that are new than those they’ve lived with for a 
while.  In the summer of 1999, New Yorkers were extremely afraid of West Nile 
virus, a mosquito-borne infection that had never been seen in the United States.  By 
the summer of 2001, though the virus continued to show up and make a few people 
sick, the fear had abated.  The risk was still there, but New Yorkers had lived with it 
for a while.  Their familiarity with it helped them see it differently. 
• 
Most people are less afraid of risks that are natural than those that are human-
made.  Many people are more afraid of radiation from nuclear waste, or cell phones, 
than they are of radiation from the sun, a far greater risk. 
• 
Most people are less afraid of a risk they choose to take than of a risk imposed on 
them.  Smokers are less afraid of smoking than they are of asbestos and other indoor 
air pollution in their workplace, which is something over which they have little 
choice. 
• 
Most people are less afraid of risks if the risk also confers some benefits they want.  
People risk injury or death in an earthquake by living in San Francisco or Los 
Angeles because they like those areas, or they can find work there. 
• 
Most people are more afraid of risks that can kill them in particularly awful ways, 
like being eaten by a shark, than they are of the risk of dying in less awful ways, like 
heart disease—the leading killer in America. 
• 
Most people are less afraid of a risk they feel they have some control over, like 
driving, and more afraid of a risk they don’t control, like flying, or sitting in the 
passenger seat while somebody else drives. 
• 
Most people are less afraid of risks that come from places, people, corporations, or 
governments they trust, and more afraid if the risk comes from a source they don’t 
trust.  Imagine being offered two glasses of clear liquid.  You have to drink one.  One 
comes from Oprah Winfrey.  The other comes from a chemical company.  Most 
people would choose Oprah’s, even though they have no facts at all about what’s in 
either glass. 
The Psychology of Security—DRAFT 
5 
• 
We are more afraid of risks that we are more aware of and less afraid of risks that we 
are less aware of.  In the fall of 2001, awareness of terrorism was so high that fear 
was rampant, while fear of street crime and global climate change and other risks 
was low, not because those risks were gone, but because awareness was down. 
• 
We are much more afraid of risks when uncertainty is high, and less afraid when we 
know more, which explains why we meet many new technologies with high initial 
concern. 
• 
Adults are much more afraid of risks to their children than risks to themselves.  