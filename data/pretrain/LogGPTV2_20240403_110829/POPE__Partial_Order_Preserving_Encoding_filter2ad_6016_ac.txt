values.
Two-block ciphertexts. Even treating the two origin bits as part of
the label, each plaintext becomes two blocks long, so that a straight-
forward application of CTR or CBC mode encryption results in
ciphertexts of three blocks. One can achieve better efﬁciency by
not including the tie-breaking randomness but still enabling the re-
ceiver to compute it. In particular, let f be a PRP, and let:
• enck(m(cid:107)π): Choose a random string r. Return the pair
(r, fk(r + 1)⊕(m(cid:107)π)).
• deck(c1, c2): Compute m(cid:107)π ← fk(c1 + 1)⊕c2 and the tie
breaking randomness u← fk(c1 + 2). Return (m, π, u),
Note it’s just the CTR mode of encryption. Even though the
ciphertext doesn’t explicitly contain the tie-breaking randomness,
the reconstructed u serves for this purpose.
3.3 Server Memory Layout
Ser statefully maintains the POPE tree T , which is a balanced
L-ary tree with root r.
• Each non-leaf node u ∈ T stores a buﬀer and a list.
• Each leaf node u ∈ T stores a buﬀer only.
A buﬀer stores an unbounded, unsorted set of (encryptions of)
blocks {((cid:96)1, v(cid:96)1 ), ((cid:96)2, v(cid:96)2 ), ..}, and a list stores at most L sorted
(encryptions of) labels ((cid:96)1, ..., (cid:96)L).
Main invariant of the POPE tree T . We will enforce the follow-
ing, main order-invariant on Ser’s tree T :
Let (cid:96)j−1 and (cid:96)j be the (j − 1)th and jth sorted labels at some
(non-leaf) node u in T . Then, for all labels (cid:96) in the sub-tree Tuj
rooted at the jth child uj of u, we have (cid:96)j−1 < (cid:96) ≤ (cid:96)j.
Intuitively, this guarantee of global partial ordering enables the L
sorted labels (cid:96)1, ..., (cid:96)L at each node u to serve as an array of si-
multaneous pivot elements, in the sense of Quicksort [28], for the
L + 1 sub-trees rooted at u’s (at most) L + 1 children u1, ..., uL+1.
Looking ahead, we use this simple, parallel pivot idea in conjunc-
tion with the parameter setting L = n, implying T has depth
(cid:100)1/(cid:101) = O(1), to enable Ser to traverse and maintain the tree T
with low amortized latency over repeated batches of Cl queries.
3.4 The POPE Protocol
We now present more formally our protocol POPE consisting of
three operations: Setup, Insert, and Search. The Search protocol
results in additional calls to helper protocols Split and Rebalance,
described afterward.
Implementing Setup. At Setup, Cl and Ser do:
Setup:
– Cl generates private keys for label/block encryption.
– Ser initializes T as a root r with empty buffer and list.
Implementing Insert. To Insert a block ((cid:96), v), Cl and Ser do:
Insert ((cid:96), v):
– Cl sends (encrypted) block ((cid:96), v) to Ser.
– Ser appends block ((cid:96), v) to the end of the current root node’s buffer.
After Setup and possibly many Insert operations (but no Search
operations), the POPE tree T held by Ser appears as in Figure 3.
Figure 3: The state of Ser’s tree T prior to any Search queries.
Implementing Search. For Cl to Search for the range of blocks
held by Ser in T between two labels (cid:96)left and (cid:96)right, Cl and Ser do:
Search ((cid:96)left, (cid:96)right):
– Cl and Ser engage in an interactive protocol Split twice,
– After each Split, Cl identiﬁes for Ser the leaf node
once for (cid:96)left and once for (cid:96)right.
uleft (or uright) in T that matches the label (cid:96)left (or (cid:96)right).
– Ser sends the blocks in [uleft, uright] to Cl.
How to Split the POPE Tree. For Cl to Split Ser’s tree T at label
(cid:96) ∈ {(cid:96)left, (cid:96)right}, Cl and Ser engage in an interactive protocol. This
operation will return the leaf node whose buffer contains the given
label with the guarantee that all nodes along the path from the root
to that leaf have empty buffers.
Individual Split calls always begin at the current root r ∈ T .
After any (non-leaf) node u ∈ T is split, Ser learns (from Cl)
the index i ∈ [L + 1] of the next child ui of u to be Split. The
Split protocol proceeds recursively down some path of T , splitting
subsequent children ui, ui,j, ... until terminating at a leaf node u.
(For readability in what follows, we assume that Ser always returns
whole nodes to Cl for each Search response.)
We break our description of Split into two broad cases: (i) the
Splits of internal, i.e., non-leaf nodes, and (ii) the Splits of leaf
nodes.
Case (i) — Splits at internal nodes: For splits at internal nodes u
with children denoted ui, Cl and Ser do:
Split ((cid:96)) — for internal nodes u:
– Ser sends L = u.list to Cl.
– Ser streams ((cid:96)(cid:48), v(cid:48)) ∈ u.buﬀer to Cl.
– Cl sends the sorted index i ∈ [L + 1]
of each ((cid:96)(cid:48), v(cid:48)) in L to Ser.
– Ser appends block ((cid:96)(cid:48), v(cid:48)) to ui.buﬀer
During this operation, Cl either (a) sees the searched-for label
(cid:96) ∈ {(cid:96)left, (cid:96)right} (and discovers node ui to proceed to), or (b) dis-
covers the node ui that may contain label (cid:96) based on its boundary
values.
The block movement in splits at internal nodes is illustrated in
Figure 4. (The outcomes of three “splits” are shown.)
Figure 4: The ﬂow of blocks in recursive Split’s of Ser’s tree T .
Case (ii) — Splits at the leaves: For splits at leaf node u with
parent node u∗, Cl and Ser do:
Split ((cid:96)) — for leaf nodes u:
– If |u.buﬀer| ≤ L, return.
– Ser samples L labels L = {(cid:96)1, ..., (cid:96)L} from u.buﬀer.
– Ser creates new root u∗ if u is the root node, or sets u∗ to
– Ser sends L to Cl.
– Cl sorts L and returns it to Ser.
– Ser inserts L new sibling leaf nodes ui into parent u∗
u’s parent otherwise.
as well as new labels L into u∗.list at the position previously
occupied by u (node u is deleted after it is split).
– Ser streams ((cid:96)(cid:48), v(cid:48)) ∈ u.buﬀer to Cl
– Cl sends the sorted index i ∈ [L + 1]
of each ((cid:96)(cid:48), v(cid:48)) in u.buﬀer to Ser.
– Ser inserts block ((cid:96)(cid:48), v(cid:48)) into sibling node ui
– Cl indicates to Ser the index i of new leaf node matching l
Note that if the size of the buffer is smaller than the local storage
capacity L of Cl, then this operation does nothing, and the split is
complete. Otherwise, as in Case (i) of Split, Cl will learn which of
the sibling leaf nodes ui to recursively Split in order to ﬁnd label
(cid:96). In this way, a single Split operation may recursively result in
multiple leaf node Split’s, with smaller and smaller buffers.
As an example, the new state of Ser’s tree T immediately after
Cl’s ﬁrst Split call (which splits the starting leaf node of T , i.e. the
root) is as depicted in Figure 5.
Clean-up Step: Rebalancing a Split POPE Tree. After complet-
ing the Split protocol above, the resulting leaf node at which Split
terminates will have size at most L, but some internal node’s sorted
list may be larger than L because of the insertions from their chil-
dren — see case (ii) of Split. This would be problematic in future
Split operations on those internal nodes, as they would send u.list
to Cl, who only has room for L items.
4.2 Security Analysis
THEOREM 2. The POPE protocol is a frequency-hiding order-
preserving range query protocol.
PROOF. We show that our POPE scheme satisﬁes Deﬁnition 1
by showing a simulator. The simulator is very simple. For each
insert, the simulator sends enck(0); due to semantic security of the
underlying encryption, the simulation is indistinguishable. To sim-
ulate search queries, the simulator runs the adversarial server’s al-
gorithm, and during the simulation, when the server needs to com-
pare two encrypted labels, the simulator simply queries the rord
oracle to get the answer. It’s obvious that the simulated view is
(cid:4)
indistinguishable to the real view of the server.
order on n items always has(cid:0)n
Security with queries. Range query schemes leak some informa-
tion of underlying plaintexts from adaptive search queries. In this
case, one important security measure can be the number of pairs of
incomparable elements. In any range query scheme, search queries
reveal some partial order on the underlying plaintexts. Recall that
a partial order ≺ on a set of elements S is isomorphic to a directed
acyclic graph, closed under transitive closure, whose nodes are el-
ements of S and whose edges encode the binary relation. A total
elements x, y ∈ S are said to be incomparable iff neither x ≺ y
nor y ≺ x. In a total order (such as the randomized order of [29]),
no pair of elements is incomparable. In our POPE scheme, each
search query gradually leaks the ordering information of the un-
derlying plaintexts. In particular, with a small number of search
queries, there will be many pairs of incomparable elements.
(cid:1) edges. In any partial order, two
2
(cid:17)
THEOREM 3. After n insertions and m query operations with
local storage of size L, where mL ∈ o(n), our POPE scheme is
mL logL n − n
frequency-hiding partial-order-preserving with Ω
incomparable pairs of elements.
(cid:16)
n2
PROOF. Note the simulator in the above proof uses oracle rord
whenever the server algorithm needs to compare the elements. So,
we can prove the theorem by using a counting argument on the
number of labels that the server compares. We model the server’s
view of the ciphertext ordering as some k ciphertexts whose order
is completely known, and where the remaining n − k ciphertexts
are partitioned into one of k + 1 buckets according to the k ordered
ciphertexts. Essentially, this is a worst-case scenario where all in-
ternal node buffers in the POPE tree are empty, the total size of all
internal node sorted lists is k, and the remaining n − k ciphertexts
reside in leaf node buffers.
We focus on the round complexity for range queries (insertion
gives no change in the number of comparable elements). From
Theorem 1, the total rounds of communication for range queries,
after n insertions and m range queries, is O(m logL n). From the
construction, each round of communication can add at most L new
ciphertexts to those whose sorted order is completely known.
Therefore, in the worst case, the server has k = O(mL logL n)
ciphertexts in its sorted order, creating k + 1 buckets in which
the other values are placed. Thus, the worst-case split that mini-
mizes the total number of incomparable elements is for the remain-
ing values to be partitioned equally among these buckets. Thus,
we have b = (cid:98)(n − k)/(k + 1)(cid:99) ciphertexts in each unsorted
(cid:1) incomparable items, for a total
bucket. Each bucket contains(cid:0)b
of (k + 1) ·(cid:0)b
(cid:1) = Ω( n2
k − n) incomparable pairs.
(cid:4)
2
2
Privacy against a malicious server. Note the above theorem
considers the worst case. This implies we can easily achieve pri-
vacy against a malicious server with tiny additional costs, that is,
Figure 5: The state of Ser’s tree T after the very ﬁrst Split ends: the new
root r := u∗ (empty buffer, full list), plus L + 1 leaves.
To ﬁx this, after completing the Split protocol, Ser calls the fol-
lowing operation on the parent of the resulting leaf node in order to
rebalance the labels in the lists of the internal nodes. We empha-
size that Rebalance is purely a local data structure manipulation,
and does not require interaction from Cl, since the unsorted buffer
of the rebalanced nodes is empty due to prior Split, having only
sorted labels in the list.
More concretely, to Rebalance at node u (initially the parent of
the leaf where Split ended), Ser does:
Rebalance(u):
– If |u.list| ≤ L, return.
– If u has no parent u∗, create a fresh root node r for T
and set u∗ := r.
– Partition u.list into sorted sublists of size at most L each by selecting
L = [every (L + 1)’th element in u.list].
– Create |L| new sibling nodes and insert them as well as the new labels
L into parent node u∗.
– Call Rebalance(u∗).
This completes the description of our main POPE protocol.
4. ANALYSIS
4.1 Cost Analysis
We analyze amortized costs on the round complexity and band-
width per operation.
THEOREM 1. After n insertions and m query operations with
local storage of size L, our scheme has the following costs:
1. Insert always requires a single round, and Search requires
O(logL n) rounds in expectation.
2. The total expected bandwidth over all (n + m) operations
(excluding the bandwidth necessary for sending the search
results) is
O(cid:0)mL logL n + n logL m + n logL(lg n)(cid:1).
The proof is found in Appendix 8.
Remark. With L = n, 0 <  < 1, Theorem 1 implies that
Search takes O(1) rounds in expectation. Moreover, when L = n
and m = O(n1−) as well, the amortized bandwidth per opera-
tion becomes O(1). This is exactly our target scenario of many
insertions and relatively few searches.
by making sure that (1) all the ciphertexts that the server asks the
client to compare are legitimate, that is, created by the client (to en-
sure this, the labels should now be encrypted with IND-CCA2 en-
cryption), and (2) the number of the server’s comparison requests
should be within the bounds of Theorem 1.
Unfortunately, this augmented system doesn’t achieve full ma-
licious security; in particular, a malicious server may omit some
values from the query answers, although it cannot inject a fake re-
sult due to IND-CCA2 security of the underlying encryption. Ef-
ﬁciently achieving full malicious security is left as an interesting
open problem.
5. EVALUATION
5.1 Experimental setup
We have made a proof-of-concept implementation of our POPE
scheme in order to test the practical utility of our new approach.
The code is written in Python3 and our tests were performed using a
single core on a machine with an Intel Xeon E5-2440 2.4 GHz CPU
and 72GB available RAM. Our implementation follows the details
presented in Section 3. The symmetric cipher used is 128-bit AES,
as provided by the PyCrypto library. The full source code of our
implementation is available at https://github.com/dsroche/pope.
Database size. While we performed experiments on a wide range
of database sizes and number of range queries, our “typical” start-
ing point is one million insertions and one thousand range queries.
This is the same scale as recent work in the databases community
for supporting range queries on outsourced data [31], and would
therefore seem to be a good comparison point for practical pur-
poses.
Parameters. In our experiments, we varied the total database size
between one thousand and 100 million entries, each time perform-