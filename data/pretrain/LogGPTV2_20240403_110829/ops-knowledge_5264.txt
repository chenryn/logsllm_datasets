User: I am developing a simple data visualization application in python with Google AppEngine. The data has the following properties:
structure : simple key - tuple-of-int
size : in the order (1-10mb on disk or in memory when loaded by the python interpreter)
read-only (uploaded once and for all by me, not modified by users)
This data could be stored in:
the datastore
a large (1-10mb) python module
Since imported python module are cached, the costly import would be rare and the data would be held directly in memory most of the time which is bound to be more efficient (in time and money) than placing datastore requests.
Has anybody debated this before? Any experience to share? Would there be any cons to using the python module approach with that use case?
Many thanks,
Nic
Assistant: If it's small and read-only, it's a much better idea to store data in locally - nothing beats the latency of local memory. Note you don't have to store it as a Python module - any data file will work, if you write the code to read it into memory.