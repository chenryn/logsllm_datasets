# Tackling Bufferbloat in 3G/4G Networks

**Authors:**
- Haiqing Jiang, North Carolina State University, USA
- Yaogong Wang, North Carolina State University, USA
- Kyunghan Lee, Ulsan National Institute of Science and Technology, Korea
- Injong Rhee, North Carolina State University, USA

**Contact:**
- {hjiang5, ywang15, rhee}@ncsu.edu

## Abstract

Bufferbloat, the issue of excessive buffering in the Internet, has garnered significant attention from the research community. Cellular networks, which use large buffers at base stations to handle bursty data traffic over time-varying channels, are particularly susceptible to bufferbloat. Despite the increasing importance of cellular networks due to the proliferation of smartphones, there is a lack of comprehensive studies on bufferbloat in these networks and its impact on TCP performance. This paper presents extensive measurements of the 3G/4G networks of four major U.S. carriers and the largest carrier in Korea. Our findings reveal the severity of bufferbloat in current cellular networks and highlight some ad-hoc solutions implemented by smartphone vendors to mitigate its effects. These static solutions, however, can lead to performance degradation under various scenarios. We propose a dynamic scheme that only requires receiver-side modifications and can be easily deployed via over-the-air (OTA) updates. Our real-world tests show that this solution can reduce the latency experienced by TCP flows by 25% to 49% and increase TCP throughput by up to 51% in certain scenarios.

## Categories and Subject Descriptors

- C.2.2 [Computer-Communication Networks]: Network Protocols

## General Terms

- Design, Measurement, Performance

## Keywords

- Bufferbloat, Cellular Networks, TCP, Receive Window

## 1. Introduction

Bufferbloat, as defined by Gettys [10], is a phenomenon where oversized buffers in the network result in extremely long delays and other performance degradations. It has been observed in various parts of the Internet, including ADSL and cable modem users [5, 17, 26]. Cellular networks, with their large buffers to accommodate dynamic link conditions, are another area where bufferbloat is prevalent (Figure 1). However, systematic studies of bufferbloat in cellular networks are limited, with only a few ad-hoc observations [24].

In this paper, we conducted extensive measurements over the 3G/4G networks of all four major U.S. carriers (AT&T, Sprint, T-Mobile, Verizon) and the largest Korean carrier (SK Telecom). Our experiments spanned more than two months and consumed over 200GB of 3G/4G data. Our measurements revealed several performance issues for TCP in bufferbloated cellular networks, including extremely long delays and suboptimal throughput.

The primary reasons for these performance issues are:
1. Most widely deployed TCP implementations use loss-based congestion control, where the sender does not slow down until it detects packet loss.
2. Cellular networks are heavily buffered to handle traffic burstiness and channel variability [20]. The large buffers, combined with link-layer retransmissions, conceal packet losses from the TCP sender, leading to continued increases in sending rate even when the bottleneck link capacity is exceeded.

This results in round-trip delays of up to several seconds. While these delays do not currently cause critical user experience problems due to separate buffer spaces for each user and infrequent multitasking on smartphones, the situation is expected to change as smartphones become more powerful and users engage in more multitasking. For example, if a user is playing an online game while downloading a song, the time-sensitive gaming traffic will experience significant queuing delays caused by the background download. Therefore, addressing bufferbloat in 3G/4G networks is crucial.

Smartphone vendors have implemented ad-hoc solutions, such as setting a relatively small maximum TCP receive buffer size (tcp_rmem_max), to mitigate the issue. This limits the advertised receive window (rwnd) and prevents the TCP congestion window (cwnd) from excessive growth, controlling the round-trip time (RTT) within a reasonable range. However, this static configuration is suboptimal in many scenarios, especially in the dynamic wireless environment. In high-speed, long-distance networks (e.g., downloading from an overseas server over 4G LTE), the static value may be too small, leading to throughput degradation. Conversely, in small bandwidth-delay product (BDP) networks, the static value may be too large, resulting in excessively long RTTs.

We propose Dynamic Receive Window Adjustment (DRWA), a lightweight, receiver-based solution that is easy to deploy. DRWA modifies the existing receive window adjustment algorithm of TCP to indirectly control the sending rate. It increases the advertised window when the current RTT is close to the minimum observed RTT and decreases it when RTT increases due to queuing delay. With proper parameter tuning, DRWA can keep the queue size at the bottleneck link small yet non-empty, optimizing both throughput and delay. Our experiments show that DRWA reduces RTT by 25% to 49% and can achieve up to 51% throughput improvement in large BDP networks.

## 2. Observation of Bufferbloat in Cellular Networks

### 2.1 Measurement Setup

Our measurement framework includes servers and clients deployed in various locations in the U.S. and Korea, covering different BDPs (Figure 2(a)). All servers run Ubuntu 10.04 with the default TCP congestion control algorithm CUBIC [11]. We used several different phone models on the client side, each working with the 3G/4G network of a specific carrier (Figure 2(b)). The signal strength during our tests ranged from -75dBm to -105dBm, covering both good and weak signal conditions. We developed simple applications on the client side to download data from the server with different traffic patterns (short-lived, long-lived, etc.). The most common pattern was a long-lived TCP flow where the client downloaded a very large file from the server for 3 minutes. Experiments were repeated numerous times throughout the day with a one-minute interval between each run, resulting in over 300 samples for each experiment.

### 2.2 Bufferbloat in Cellular Networks

To estimate the buffer space in current cellular networks, we set up an experiment with a long-lived TCP flow from our server to a Linux laptop over the 3G networks of four major U.S. carriers. By default, Ubuntu sets the maximum TCP receive and send buffer sizes to a large value (greater than 3MB), so the flow is not limited by the buffer size of the endpoints. Due to the closed nature of cellular networks, we measured the size of packets in flight on the sender side to estimate the buffer space within the network. Figure 3 shows our results, revealing exceptionally fat pipes in all four major U.S. cellular carriers. For example, Sprint's EVDO network, with a peak downlink rate of 3.1 Mbps and a minimum RTT of around 150ms, has a BDP of around 58KB. However, Sprint can handle over 800KB of packets in flight.

As a comparison, we ran a similar experiment over a campus WiFi network, which, despite its large BDP, showed much smaller in-flight packet sizes compared to cellular networks. We extended the measurement to various scenarios, confirming the presence of extremely fat pipes in current cellular networks (Table 1).

To confirm that the bufferbloat is within the cellular segment rather than the backbone Internet, we used Traceroute on the client side to measure the RTT of each hop along the path to the server. The results in Figure 4 show that the queue is built up at the very first IP hop, indicating that the large buffers are likely at the base station.

Another concern is that the long delays in cellular networks might be due to Radio Resource Control (RRC) state transitions [1] rather than bufferbloat. To address this, we repeatedly pinged our server from the mobile station with different intervals between consecutive pings. Figure 5 shows that RRC state transitions only affect short-lived TCP flows with considerable idle periods (greater than 7 seconds), but do not affect long-lived flows with millisecond-scale packet intervals.

## 3. TCP Performance Over Bufferbloated Cellular Networks

Given the large buffer sizes in cellular networks, we investigated their impact on TCP behavior and performance. Our experiments, similar to those in Figure 3, focused on the congestion window size and RTT of long-lived TCP flows. As shown in Figure 6, TCP congestion windows continue to grow even when they far exceed the BDP of the underlying network, leading to extremely long RTTs (up to 10 seconds).

[Continued in next section...]

---

This revised version aims to provide a clearer, more coherent, and professional presentation of the original text.