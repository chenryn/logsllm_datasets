title:Tackling bufferbloat in 3G/4G networks
author:Haiqing Jiang and
Yaogong Wang and
Kyunghan Lee and
Injong Rhee
Tackling Bufferbloat in 3G/4G Networks
Haiqing Jiang1, Yaogong Wang1, Kyunghan Lee2, and Injong Rhee1
North Carolina State University, USA 1 Ulsan National Institute of Science and Technology, Korea 2
{hjiang5, ywang15, rhee}@ncsu.edu
PI:EMAIL
ABSTRACT
The problem of overbuﬀering in the current Internet (termed
as buﬀerbloat) has drawn the attention of the research com-
munity in recent years. Cellular networks keep large buﬀers
at base stations to smooth out the bursty data traﬃc over
the time-varying channels and are hence apt to buﬀerbloat.
However, despite their growing importance due to the boom
of smart phones, we still lack a comprehensive study of
buﬀerbloat in cellular networks and its impact on TCP per-
formance. In this paper, we conducted extensive measure-
ment of the 3G/4G networks of the four major U.S. carriers
and the largest carrier in Korea. We revealed the severity
of buﬀerbloat in current cellular networks and discovered
some ad-hoc tricks adopted by smart phone vendors to mit-
igate its impact. Our experiments show that, due to their
static nature, these ad-hoc solutions may result in perfor-
mance degradation under various scenarios. Hence, a dy-
namic scheme which requires only receiver-side modiﬁcation
and can be easily deployed via over-the-air (OTA) updates
is proposed. According to our extensive real-world tests, our
proposal may reduce the latency experienced by TCP ﬂows
by 25% ∼ 49% and increase TCP throughput by up to 51%
in certain scenarios.
Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network
Protocols
General Terms
Design, Measurement, Performance
Keywords
Buﬀerbloat, Cellular Networks, TCP, Receive Window
1.
INTRODUCTION
Buﬀerbloat, as termed by Gettys [10], is a phenomenon
where oversized buﬀers in the network result in extremely
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.
Conventional Networks
e.g., WiFi, Wired Networks
Server
Cellular Networks
e.g., 3G, 4G
Client
Figure 1: Buﬀerbloat has been widely observed in
the current Internet but is especially severe in cel-
lular networks, resulting in up to several seconds of
round trip delay.
long delay and other performance degradation. It has been
observed in diﬀerent parts of the Internet, ranging from
ADSL to cable modem users [5, 17, 26]. Cellular networks
are another place where buﬀers are heavily provisioned to
accommodate the dynamic cellular link (Figure 1). How-
ever, other than some ad-hoc observations [24], buﬀerbloat
in cellular networks has not been studied systematically.
In this paper, we carried out extensive measurements over
the 3G/4G networks of all four major U.S. carriers (AT&T,
Sprint, T-Mobile, Verizon) as well as the largest cellular car-
rier in Korea (SK Telecom). Our experiments span more
than two months and consume over 200GB of 3G/4G data.
According to our measurements, TCP has a number of per-
formance issues in buﬀerbloated cellular networks, includ-
ing extremely long delays and sub-optimal throughput. The
reasons behind such performance degradation are two-fold.
First, most of the widely deployed TCP implementations
use loss-based congestion control where the sender will not
slow down its sending rate until it sees packet loss. Sec-
ond, most cellular networks are overbuﬀered to accommo-
date traﬃc burstiness and channel variability [20]. The ex-
ceptionally large buﬀer along with link layer retransmission
conceals packet losses from TCP senders. The combination
of these two facts leads to the following phenomenon: the
TCP sender continues to increase its sending rate even if it
has already exceeded the bottleneck link capacity since all
of the overshot packets are absorbed by the buﬀers. This
results in up to several seconds of round trip delay. This
extremely long delay did not cause critical user experience
problems today simply because 1) base stations typically
has separate buﬀer space for each user [20] and 2) users
do not multitask on smart phones very often at this point.
This means only a single TCP ﬂow is using the buﬀer space.
If it is a short-lived ﬂow like Web browsing, queues will
not build up since the traﬃc is small. If it is a long-lived
329ﬂow like downloading a ﬁle, long queues will build up but
users hardly notice them since it is the throughput that mat-
ters rather than the delay. However, as the smart phones
become more and more powerful (e.g., several recently re-
leased smart phones are equipped with quad-core processors
and 2GB of memory), users are expected to perform multi-
tasking more often. If a user is playing an online game and
at the same time downloading a song in the background,
severe problem will appear since the time-sensitive gaming
traﬃc will experience huge queuing delays caused by the
background download. Hence, we believe that buﬀerbloat
in 3G/4G networks is an important problem that must be
addressed in the near future.
This problem is not completely unnoticed by today’s smart
phone vendors. Our investigation into the open source An-
droid platform reveals that a small untold trick has been
applied to mitigate the issue: the maximum TCP receive
buﬀer size parameter (tcp rmem max ) has been set to a rel-
atively small value although the physical buﬀer size is much
larger. Since the advertised receive window (rwnd) cannot
exceed the receive buﬀer size and the sender cannot send
more than what is allowed by the advertised receive win-
dow, the limit on tcp rmem max eﬀectively prevents TCP
congestion window (cwnd) from excessive growth and con-
trols the RTT (round trip time) of the ﬂow within a reason-
able range. However, since the limit is statically conﬁgured,
it is sub-optimal in many scenarios, especially considering
the dynamic nature of the wireless mobile environment. In
high speed long distance networks (e.g., downloading from
an oversea server over 4G LTE (Long Term Evolution) net-
work), the static value could be too small to saturate the
link and results in throughput degradation. On the other
hand, in small bandwidth-delay product (BDP) networks,
the static value may be too large and the ﬂow may experi-
ence excessively long RTT.
There are many possible ways to tackle this problem, rang-
ing from modifying TCP congestion control algorithm at the
sender to adopting Active Queue Management (AQM) at
the base station. However, all of them incur considerable
deployment cost. In this paper, we propose dynamic receive
window adjustment (DRWA), a light-weight, receiver-based
solution that is cheap to deploy. Since DRWA requires mod-
iﬁcations only on the receiver side and is fully compatible
with existing TCP protocol, carriers or device manufactur-
ers can simply issue an over-the-air (OTA) update to smart
phones so that they can immediately enjoy better perfor-
mance even when interacting with existing servers.
DRWA is similar in spirit to delay-based congestion con-
trol algorithms but runs on the receiver side.
It modiﬁes
the existing receive window adjustment algorithm of TCP
to indirectly control the sending rate. Roughly speaking,
DRWA increases the advertised window when the current
RTT is close to the minimum RTT we have observed so far
and decreases it when RTT becomes larger due to queuing
delay. With proper parameter tuning, DRWA could keep
the queue size at the bottleneck link small yet non-empty
so that throughput and delay experienced by the TCP ﬂow
are both optimized. Our extensive experiments show that
DRWA reduces the RTT by 25% ∼ 49% while achieving
similar throughput in ordinary scenarios. In large BDP net-
works, DRWA can achieve up to 51% throughput improve-
ment over existing implementations.
In summary, the contributions of this paper include:
Clients in Seoul, Korea
Server in Seoul, Korea
Server in Raleigh, NC, US
Internet
Server in Princeton, NJ, US
(a) Experiment testbed
Samsung
Droid Charge
(Verizon)
HTC 
EVO Shift
(Sprint)
LG G2x
(T-Mobile)
iPhone 4
(AT&T)
Samsung 
Galaxy S2
(AT&T and
SK Telecom)
(b) Experiment phones
Figure 2: Our measurement framework spans across
the globe with servers and clients deployed in vari-
ous places in U.S. and Korea using the cellular net-
works of ﬁve diﬀerent carriers.
• We conducted extensive measurements in a range of
cellular networks (EVDO, HSPA+, LTE) across vari-
ous carriers and characterized the buﬀerbloat problem
in these networks.
• We anatomized the TCP implementation in state-of-
the-art smart phones and revealed the limitation of
their ad-hoc solution to the buﬀerbloat problem.
• We proposed a simple and immediately deployable so-
lution that is experimentally proven to be safe and
eﬀective.
The rest of the paper is organized as follow. Section 2 in-
troduces our measurement setup and highlights the severity
of buﬀerbloat in today’s 3G/4G networks. Section 3 then
investigates the impact of buﬀerbloat on TCP performance
and points out the pitfalls of high speed TCP variants in
cellular networks. The abnormal behavior of TCP in smart
phones is revealed in Section 4 and its root cause is located.
We then propose our solution DRWA in Section 5 and eval-
uate its performance in Section 6. Finally, alternative so-
lutions and related work are discussed in Section 7 and we
conclude our work in Section 8.
2. OBSERVATION OF BUFFERBLOAT IN
CELLULAR NETWORKS
Buﬀerbloat is a phenomenon prevalent in the current In-
ternet where excessive buﬀers within the network lead to
exceptionally large end-to-end latency and jitter as well as
throughput degradation. With the recent boom of smart
phones and tablets, cellular networks become a more and
more important part of the Internet. However, despite the
3301000
)
B
K
(
t
h
g
i
l
F
n
i
s
t
e
k
c
a
P
800
600
400
200
0
0
AT&T HSPA+
Sprint EVDO T−Mobile HSPA+ Verizon EVDO Campus WiFi
500
1000
1500
For each ACK
2000
2500
3000
Figure 3: We observed exceptionally fat pipes across
the cellular networks of ﬁve diﬀerent carriers. We
tried three diﬀerent client/server locations under
both good and weak signal case. This shows the
prevalence of buﬀerbloat in cellular networks. The
ﬁgure above is a representative example.
abundant measurement studies of the cellular Internet [4,
18, 20, 23, 14], the speciﬁc problem of buﬀerbloat in cellular
networks has not been studied systematically. To obtain a
comprehensive understanding of this problem and its impact
on TCP performance, we have set up the following measure-
ment framework which is used throughout the paper.
2.1 Measurement Setup
Figure 2(a) gives an overview of our testbed. We have
servers and clients deployed in various places in U.S. and
Korea so that a number of scenarios with diﬀerent BDPs
can be tested. All of our servers run Ubuntu 10.04 (with
2.6.35.13 kernel) and use its default TCP congestion control
algorithm CUBIC [11] unless otherwise noted. We use sev-
eral diﬀerent phone models on the client side, each working
with the 3G/4G network of s speciﬁc carrier (Figure 2(b)).
The signal strength during our tests ranges from -75dBm to
-105dBm so that it covers both good signal condition and
weak signal condition. We develop some simple applications
on the client side to download data from the server with
diﬀerent traﬃc patterns (short-lived, long-lived, etc.). The
most commonly used traﬃc pattern is long-lived TCP ﬂow
where the client downloads a very large ﬁle from the server
for 3 minutes (the ﬁle is large enough so that the down-
load never ﬁnishes within 3 minutes). Most experiments
have been repeated numerous times for a whole day with a
one-minute interval between each run. That results in more
than 300 samples for each experiment based on which we
calculate the average and the conﬁdence interval.
For the rest of the paper, we only consider the perfor-
mance of the downlink (from base station to mobile station)
since it is the most common case. We leave the measure-
ment of uplink performance as our future work. Since we
are going to present a large number of measurement results
under various conditions in this paper, we provide a table
that summaries the setup of each experiment for the reader’s
convenience. Please refer to Table 1 in Appendix A.
2.2 Bufferbloat in Cellular Networks
The potential problem of overbuﬀering in cellular net-
works was pointed out by Ludwig et al. [21] as early as 1999
when researchers were focusing on GPRS networks. How-
ever, overbuﬀering still prevails in today’s 3G/4G networks.
To estimate the buﬀer space in current cellular networks,
)
s
m
(
p
o
H
h
c
a
E
f
o
T
T
R
2500
2000
1500
1000
500
0
Without background traffic
With background traffic
1
3
5
7
9
Hop Count
11
13
15
Figure 4: We veriﬁed that the queue is built up at
the very ﬁrst IP hop (from the mobile client).
we set up the following experiment: we launch a long-lived
TCP ﬂow from our server to a Linux laptop (Ubuntu 10.04
with 2.6.35.13 kernel) over the 3G networks of four major
U.S. carriers. By default, Ubuntu sets both the maximum
TCP receive buﬀer size and the maximum TCP send buﬀer
size to a large value (greater than 3MB). Hence, the ﬂow
will never be limited by the buﬀer size of the end points.
Due to the closed nature of cellular networks, we are unable
to know the exact queue size within the network. Instead,
we measure the size of packets in ﬂight on the sender side
to estimate the buﬀer space within the network. Figure 3
shows our measurement results. We observed exceptionally
fat pipes in all four major U.S. cellular carriers. Take Sprint
EVDO network for instance. The peak downlink rate for
EVDO is 3.1 Mbps and the observed minimum RTT (which
approximates the round-trip propagation delay) is around
150ms. Therefore, the BDP of the network is around 58KB.
But as the ﬁgure shows, Sprint is able to bear more than
800KB of packets in ﬂight!
As a comparison, we ran a similar experiment of a long-
lived TCP ﬂow between a client in Raleigh, U.S. and a server
in Seoul, Korea over the campus WiFi network. Due to the
long distance of the link and the ample bandwidth of WiFi,
the corresponding pipe size is expected to be large. However,
according to Figure 3, the size of in-ﬂight packets even in
such a large BDP network is still much smaller than the ones
we observed in cellular networks.
We extend the measurement to other scenarios in the ﬁeld
to verify that the observation is universal in current cellular
networks. For example, we have clients and servers in vari-
ous locations over various cellular networks in various signal
conditions (Table 1). All the scenarios prove the existence
of extremely fat pipes similar to Figure 3.
To further conﬁrm that the buﬀerbloat is within the cellu-
lar segment rather than the backbone Internet, we designed
the following experiment to locate where the long queue is
built up. We use Traceroute on the client side to measure the
RTT of each hop along the path to the server and compare
the results with or without a background long-lived TCP
ﬂow. If the queue is built up at hop x, the queuing delay
should increase signiﬁcantly at that hop when background
traﬃc is in place. Hence, we should see that the RTTs before
hop x do not diﬀer much no matter the background traﬃc is
present or not. But the RTTs after hop x should have a no-
table gap between the case with background traﬃc and the
case without. The results shown in Figure 4 demonstrate
that the queue is built up at the very ﬁrst hop. Note that
there could be a number of components between the mo-
331Verizon LTE
Verizon EVDO
AT&T HSPA+
800
700
600
500
400
300
200
100
)
s
m
(
g
n
P
i
f
o
T
T
R
)
B
K
i
i
(
e
z
S
w
o
d
n
W
n
o
i
t
s
e
g
n
o
C
0
1
3
Interval between Consecutive Pings (s)
11
5
7
9
13
15
Figure 5: RRC state transition only aﬀects short-
lived TCP ﬂows with considerable idle periods in
between (> 7s) but does not aﬀect long-lived ﬂows.
bile client and the ﬁrst IP hop (e.g., RNC, SGSN, GGSN,
etc.). It may not be only the wireless link between the mo-
bile station and the base station. Without administrative
access, we are unable to diagnose the details within the car-
rier’s network but according to [20] large per-user buﬀer are
deployed at the base station to absorb channel ﬂuctuation.
Another concern is that the extremely long delays we ob-
served in cellular networks are due to Radio Resource Con-
trol (RRC) state transitions [1] rather than buﬀerbloat. We
set up the following experiment to demonstrate that these
two problems are orthogonal. We repeatedly ping our server
from the mobile station with diﬀerent intervals between con-
secutive pings. The experiment has been carried out for a
whole day and the average RTT of the ping is calculated.
According to the RRC state transition diagram, if the in-
terval between consecutive pings is long enough, we should
observe a substantially higher RTT due to the state promo-
tion delay. By varying this interval in each run, we could ob-
tain the threshold that would trigger RRC state transition.
As shown in Figure 5, when the interval between consecutive
pings is beyond 7 seconds (speciﬁc threshold depends on the
network type and the carrier), there is a sudden increase in
RTT which demonstrates the state promotion delay. How-
ever, when the interval is below 7 seconds, RRC state tran-
sition does not seem to aﬀect the performance. Hence, we
conclude that RRC state transition may only aﬀect short-
lived TCP ﬂows with considerable idle periods in between
(e.g., Web browsing), but does not aﬀect long-lived TCP
ﬂows we were testing since their packet intervals are typi-
cally at millisecond scale. When the interval between pack-
ets is short, the cellular device should remain in CELL DCH
state and state promotion delays would not contribute to the
extremely long delays we observed.
3. TCP PERFORMANCE OVER BUFFER-
BLOATED CELLULAR NETWORKS
Given the exceptionally large buﬀer size in cellular net-
works as observed in Section 2, in this section we investigate
its impact on TCP’s behavior and performance. We carried
out similar experiments to Figure 3 but observed the con-
gestion window size and RTT of the long-lived TCP ﬂow
instead of packets in ﬂight. As Figure 6 shows, TCP con-
gestion window keeps probing even if its size is far beyond
the BDP of the underlying network. With so much over-
shooting, the extremely long RTT (up to 10 seconds!) as
shown in Figure 6(b) is not surprising.
1400
1200
1000
800
600
400