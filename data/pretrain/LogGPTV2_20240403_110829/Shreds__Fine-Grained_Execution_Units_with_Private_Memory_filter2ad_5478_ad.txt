and survives program and system reboots. As a result, an
attacker can read F only if she manages to intrude the program
during its ﬁrst run and access F before a shred does. Although
not completely preventing such attacks, S-driver makes them
very difﬁcult to succeed in reality. For a complete remedy,
we envision a new primitive for in-shred code to encrypt and
decrypt secret data with a persistent key assigned to each s-
pool and automatically managed by S-driver. However, our
current prototype does not support this primitive.
It is worth noting that, although the system call mediation
can prevent user-space malicious code that tries to break shreds
via the system interfaces,
is a more intrusive and less
conﬁgurable design choice than the well-known access control
and capability frameworks, such as SELinux, AppArmor, and
Capsicum [15]. However, we leave the integration with those
systems as future work because the system call mediation is
easy to implement and is sufﬁcient for the prototyping purpose.
it
Secure stacks for shreds: Although S-compiler forbids unsan-
itized data ﬂows from s-pools to unprotected memory regions,
it has to allow in-shred code to copy s-pool data to local
variables, which would be located in the regular stack and
E. Satisﬁed Requirements
ments for in-process private memory (R1-R4 in § II-B).
We now examine if the design of shreds meets the require-
Shreds remove the historical constraint facing developers
6363
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:20 UTC from IEEE Xplore.  Restrictions apply. 
that, memory protection domains can only be created at the
granularities of the rigid scheduling units, namely processes.
This constrain poses a major challenge to defend in-process
abuse. Using shreds, developers can ﬂexibly create execution
units of various sizes and individually grant these units access
to protected memory pools. As a result, shreds allow for ﬁne-
grained protection domains inside processes, and thus, meet
R1.
Developers create shreds and use s-pools via the four
intuitive APIs. They can easily adopt shreds in either new
or legacy applications, without major design changes. When
building applications, S-compiler automatically veriﬁes shred
usages and hardens the resulting executables. S-driver, the dy-
namically loadable kernel extension, enables runtime support
and protection of shreds without requiring a new or rebuilt
OS. The entire system is easy to use and deploy, which meets
R2.
Our design assumes that in-shred code would contain vul-
nerabilities that may lead to secret
leaks or control ﬂow
hijacks. Our design either precludes such vulnerabilities or
prevents them from being exploited. Speciﬁcally, S-compiler
rejects code containing unsanitized data ﬂows from s-pools
to unprotected memory regions. It also inserts checks before
statically undecidable memory dereferences whose values may
ﬂow to regular memory, preventing potential
leaks during
runtime. These static and dynamic checks together eliminate
outbound propagations of plain data in s-pools, and there-
fore, enforce the data ﬂow property in R3. S-compiler also
instruments indirect control ﬂow transfers in shreds, whose
destinations are checked during runtime and assured to be
basic block entrances inside containing shreds. These checks
enforce the control ﬂow property in R3.
To efﬁciently enable s-pools, or the in-process private
memory regions, our design leverages a widely available yet
largely overlooked feature in ARM CPUs, namely memory
domains [4] (Intel has prototyped a similar feature for future
CPUs [5], [6]. Compared with paging-based memory access
control, our domain-based design does not require page table
switches, full TLB ﬂushes, or disabling concurrent threads
when (un)locking s-pools. Besides, S-driver changes domain
assignments and access levels in a lazy fashion, which further
reduces the security enforcement overhead. As shown in our
evaluation (§ V), using shreds and s-pools only slows down
programs by 4.67%, which indicates that R4 is satisﬁed.
IV. SYSTEM IMPLEMENTATION
We fully implemented our designs of S-compiler and S-
driver. We built S-compiler based on LLVM [7] and its C front-
end Clang [16]. We built S-driver with Linux as the reference
OS. The implemented system was deployed and evaluated
on a quad-core ARM Cortex-A7 computer (Raspberry Pi 2
Model B running Linux 4.1.15). Table I shows the SLoC of
the implementation.
S-compiler: The modular and pass-based architecture of
LLVM allows us to take advantage of the existing analyzers
Language
SLOC
S-compiler
Analysis 
Pass
Instrumenta
tion Pass
S-driver
C++
C++
C
1345
275
1205
TABLE I: The SLoC for S-compiler and S-driver.
and easily extends the compilation pipeline. S-compiler adds
two new passes to LLVM: the shred analysis pass and the
security instrumentation pass. Both operate on LLVM bitcode
as the IR.
The analysis pass carries out the checks on the usages
and security properties of shreds, as described in § III-C.
We did not use LLVM’s built-in data ﬂow analysis for
those checks due to its overly heuristic point-to analysis
and the unnecessarily conservative transfer functions. Instead,
we implemented our specialized data ﬂow analysis based on
the basic round-robin iterative algorithm, with weak context
sensitivity and a straightforward propagation model (i.e., only
tracking value-conserving propagators). We also had to extend
LLVM’s compilation pipeline because it by default only sup-
ports intra-module passes while S-compiler needs to perform
inter-module analysis. We employed a linker plugin, called
the Link-Time Optimization (LTO), to cross link the IR of all
compilation modules and feed the linked IR to our analyzers.
The instrumentation pass uses the LLVM IR manipulation
interfaces to insert security checks into the analyzed IR that,
which are necessary for enforcing the in-shred control ﬂow
regulations and preventing dynamic data leaks, as discussed
in § III-C.
S-driver: We built S-driver into a Loadable Kernel Module
(LKM) for Linux. S-driver creates a virtual device ﬁle (/de-
v/shreds) to handle the ioctl requests made internally by
the shred APIs. It uses 13 out of 16 memory domains to
protect s-pools because the recent versions of Linux kernel
for ARM already occupies 3 domains (for isolating device,
kernel, and user-space memory). S-driver uses the available
domains to protect unlimited s-pools and controls each CPU’s
access to the domains as described in § III-D. Since Linux
does not provide callback interfaces for drivers to react to
scheduling events, in order to safely handle context switches or
signal dispatches in shreds, S-driver dynamically patches the
OS scheduler so that, during every context switch, the DACR
of the current CPU is reset, which locks the open s-pool,
if any. The overhead of this operation is negligible because
resetting the DACR only takes a single lightweight instruction.
To capture illegal access to s-pools and lazily adjust domain
assignments, S-driver registers itself to be the only handler of
domain faults and is triggered whenever a domain violation
happens. Algorithm 1 shows how S-driver handles a domain
fault. Purely implementing S-driver as a LKM allows shreds
6464
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:20 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 1: Domain Fault Handler
input : The faulting virtual address f ault addr
result: Recover from the domain fault, or kill the faulting
thread
/*Identity check*/
s pool ← FindSpool(f ault addr);
s owner ← GetOwner(s pool);
if fault
thread is NOT in shred then
goto bad_area
if fault
thread is NOT s owner then
goto bad_area
/*Recover from domain fault*/
cpu domain ← GetCPUDomain();
s pool domain ← GetSpoolDomain(s pool);
if s pool is unlocked then
if cpu domain = s pool domain then
/*No need to change domain for s pool*/
RestoreDACR();
else
AdjustSPool(cpu domain)
else
UnlockSPool(cpu domain)
LockOtherActiveSPools(s pool);
to be introduced into a host without installing a custom-build
kernel image.
V. ANALYSIS AND EVALUATION
A. Security Analysis
We now analyze our system design in terms of its robustness
against the evasions or manipulations that attacks may pursue.
For this analysis, we assume an attacker has already take
control of a victim process, either via remote exploitation or
malicious local libraries, which is the most powerful attacker
possible under our threat model. With the goal of accessing an
s-pool used by the victim program, the attacker may attempt
to bypass the security enforcement of shreds in the following
ways, all of which are prevented by our design.
First, the attacker may create a shred of her own and try
to associate the shred with the target s-pool by specifying
a same s-pool descriptor. This attack will fail because: (i)
if the attacker creates the shred via code in a different
executable or compilation unit (e.g., a malicious library), s-
driver forbids sharing of s-pools among different compilation
units by localizing s-pool descriptors during executable load;
(ii) if the attacker creates the shred by injecting code in
the compromised process, s-driver denies the shred creation
because no statically veriﬁed information about this shred exits
in the executable ﬁle.
Second, the attacker may try to hijack a shred execution.
She can exploit in-shred code and diverging the the control
ﬂow to selected malicious code. In that case, the malicious
code would run inside a shred and in turn gain access to
the s-pool. However, s-compiler and s-driver together prevent
such control ﬂow manipulations via code instrumentation and
runtime protection. The instrumentation code checks, among
other things, if an indirect control ﬂow transfer is bound by
the code coverage of the (vulnerable) shred, as determined by
s-compiler (§ III-C).
Third, the attacker may direct the control ﬂow to a legitimate
shred entry point in an ROP fashion, hoping to regain the
control after the next return instruction or the shred exits.
Since s-driver assigns a separate and protected stack for each
shred execution, the attacker cannot set up the stack to launch
ROP inside the shred. Even if the attacker regains the control
immediately after the shred exits, she cannot not learn anything
about the data processed in that shred because s-driver resets
the stack where before the shred is executed. Moreover, s-
driver also prevents other types of manipulation of legitimate
shreds, such as hooking the shred APIs and modiﬁed the
veriﬁed code mapped in memory.
Finally, using inline security checks and saving the shred
information in executables make an implicit security assump-
tion that, attackers cannot rewrite the executables generated
by s-compiler, such as removing the inline security checks or
modifying the shred section. We note that this is a common
assumption shared by all inline reference monitors. It is feasi-
ble in the context of preventing in-process memory abuse: if
attackers already control the executable of a program, memory
abuse would become unnecessary.
B. Experiments and Evaluation
Our experiments sought to answer the following questions:
• How easy or difﬁcult for developers to adopt shreds in
their code?
• How compatible and useful are shreds to real-world
programs?
• How do shreds affect
performance?
the application’s and system’s
Choice of Applications: We selected 5 popular open source
applications to evaluate our prototype system. The applications
are shown in Table II, ranging from the small HTTP server,
lighttpd, to the complex cryptography library, OpenSSL. The
applications were chosen because each of them has at least
one piece of sensitive data that is subject to in-process abuse,
and therefore, warrants shred’s protection. Moreover, the ap-
plications represent a good variety of software of different
functionalities and codebase sizes.
Adoption Tests: To measure the efforts required to adopt
shreds in reality, we hired several CS graduate students to
incorporate shreds into the 5 selected applications. They were
ﬁrst given a short tutorial on how to use shreds and s-pools,
and then asked to adopt shreds into the application source
code. The adoption in these tests did not intend to protect all
kinds of sensitive data in the applications, which is unrealistic
given that the student participants in the tests are not the
original developers of the applications and are unlikely to
identify all types of sensitive data. Instead, we asked the
participants to protect only one speciﬁc type of sensitive data
6565
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:20 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II: 5 open source softwares used in evaluation
curl
minizip
openssh
openssl
lighttpd
Executable Size(byte)
227071 curl
80572 miniunz
97749 minizip
2207588 ssh
3093920 libcrypto.so
85135 mod auth.so
Category
http client
ﬁle compression tool
remote login tool
crypto library
web server
Protected Data Type
Program Size(KLOC)
password
password
credential
crypto key
credential
177
7
130
526
56
in each application (as shown in the Protected Data Type
column in Table II). This measurable and realistic task for
the participants allowed us to examine how easy or difﬁcult
to use shreds correctly and effectively in practice.
After the tests ﬁnished, we manually conﬁrmed the cor-
rectness and completeness of the code changes. The modiﬁed
applications compile and run without any issue. As shown in
Table III, on average, the participants spent an hour on lighttpd
and 15 min on minizip, representing the longest and shortest
adoption time measured in the tests. These numbers show that
shreds are intuitive even to ﬁrst-time users. Given that the
participants spent most of the time understanding the codebase,
we expect that the time needed for adopting shreds will be even
shorter when the original application developers perform the
tasks. The number of shreds created and the number of SLoC
changes do not exhibit direct correlation with the adoption
time. The code changes are very small compared with the
size of the applications, which indicates that no major design
changes are required to apply shreds to existing applications.
TABLE III: Code changed and time spent in adoption tests