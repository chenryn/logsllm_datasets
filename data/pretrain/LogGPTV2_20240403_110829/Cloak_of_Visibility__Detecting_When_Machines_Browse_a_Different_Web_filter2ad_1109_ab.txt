### Browser Context and Capabilities

This section delves into the capabilities of cloaking software, such as content spinning and keyword stuffing. We will use this analysis later in Section IV to design an anti-cloaking system capable of defeating the cloaking techniques we discover. While our investigation does not exhaustively cover all cloaking software, it provides a comprehensive overview of the techniques used by the ten programs we analyzed. The cost and skill set required to operate some of these packages ensure that they are exclusive to only the most affluent or sophisticated miscreants. However, our analysis revealed that the set of cloaking techniques among the packages quickly converged to a fixed set of signals, suggesting that the best cloaking techniques are frequently shared or copied, much like exploit kits.

#### A. Cloaking Software Analysis

Among the cloaking applications we analyzed, only one (coincidentally, the most expensive) protected itself with a tool that had no publicly available unpacker. The languages used for these cloaking applications ranged from C++, Perl, JavaScript, and PHP. The sophistication of these tools varied from simple drop-in scripts and plugins for WordPress pages to custom compilations of Nginx for serving cloaked content. For each application, we manually investigated the underlying cloaking logic and any embedded blacklists.

#### B. Cloaking Techniques

The cloaking techniques employed by the services we analyzed span a wide range of network, browser, and contextual fingerprinting. Table I provides a detailed breakdown of key capabilities. These techniques include:

- **Network Fingerprinting:**
  - **IP Address:** Some crawlers do not obfuscate their IP addresses, allowing cloaking services to enumerate bot IPs. Four out of the ten cloaking services we examined included an IP blacklist, while the others allowed operators to upload their own. Three of the four IP blacklists mirrored the same blacklist-as-a-service, which was updated twice daily and contained 54,166 unique IP addresses tied to popular search engines and crawlers.
  - **Reverse DNS (rDNS):** In the event a crawler appears from a non-blacklisted IP, four of the ten cloaking services perform an rDNS lookup of the visitorâ€™s IP. If the rDNS record matches known crawler domains, the visitor is identified as a crawler.
  - **Geolocation:** Four of the ten cloaking services allow geographic targeting at a country level. One service even embeds a duplicate of the MaxMind public GeoIP list for live querying.

- **Browser Fingerprinting:**
  - **User-Agent:** Well-behaving search and advertisement crawlers announce their presence with specialized User-Agent strings. Cloaking services ubiquitously rely on User-Agent comparisons to block known crawlers. Table IV provides a detailed breakdown of the exact substring matching patterns.
  - **JavaScript & Flash:** JavaScript and Flash can serve as both a crawler fingerprinting technique and a redirection delivery method. Three cloaking services use JavaScript execution to block rudimentary crawlers. One service also allows operators to input custom JavaScript fingerprinting logic.

- **Contextual Fingerprinting:**
  - **HTTP Referer:** This technique involves scanning the HTTP Referer of incoming visitors to verify they originate from search portals. The default whitelist matches major crawlers, though miscreants can disable this feature.
  - **Incoming Keywords:** Two services support keyword cloaking, which checks the validity of the search keywords that brought a visitor to a page. The software triggers cloaking logic if the HTTP Referer contains negative keywords or lacks positive keywords.
  - **Time Window:** Timing-based cloaking prohibits visitors from accessing uncloaked content more than once in a specific time window. Repeat visitors within 24 hours are redirected to cloaked content.
  - **Order of Operations:** Two services support multiple hops, setting a short-lived cookie upon visiting a page. When legitimate users interact with the page, the next doorway checks for the presence and expiration of this cookie, enforcing a specific sequence of actions.

### Conclusion

Our analysis of cloaking software reveals a variety of techniques used to identify and block crawlers. By understanding these techniques, we can design more effective anti-cloaking systems. Future work will focus on developing robust methods to counteract these cloaking techniques and ensure the integrity of web content.