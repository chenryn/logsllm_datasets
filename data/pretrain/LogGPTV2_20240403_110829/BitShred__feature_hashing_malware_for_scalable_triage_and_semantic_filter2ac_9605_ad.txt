hierarchical clustering over 1.9 million malware per day.
In the
case of incremental clustering, this works out to comparing over
190,000 malware per day against 10 million known malware that
are already in a database.
Triage Tasks. Three common triage tasks are to automatically
identify malware families via clustering [13], to identify the near-
est neighbors to a particular malware sample [21], and to visualize
malware by creating phylogenetic trees [23].
In this experiment
we explore using BitShred with n-grams as the extracted features.
While we stress that we are not advocating n-gram analysis, we
also note it is interesting to see what the actual quality would be
in such a system. We repeat these analysis in § 5.2 using dynamic
behavior features.
• Clustering. We refer to how close a particular clustering is to the
“correct” clustering with respect to labeled data set as the quality of
a clustering. Overall quality will heavily depend upon the feature
extraction tool (e.g., static or dynamic), the particular data set (e.g.,
because malware analysis often relies upon undecidable questions),
and the quality of the reference data set.
To create a reference clustering data set, we used 30∼40 dif-
ferent anti-virus labels provided by VirusTotal [6]. First, we chose
samples that were detected as malware by at least 20 anti-virus pro-
grams to get more reliable labels. We normalized and tokenized
all the labels; then, we assigned the family name based upon only
the tokens occurring at the majority of the detecting anti-virus pro-
grams. As a result, we had 3,935 samples.
The overall clustering quality is measured with respect to two
metrics: precision and recall. Precision measures how well mal-
ware in separate families are put in different clusters, and recall
Pc
measures how well malware within the same family are put into
the same cluster. Formally, precision and recall are deﬁned as:
Pr
i=1 max(|Ci ∩ R1|, ...,|Ci ∩ Rr|)
i=1 max(|C1 ∩ Ri|, ...,|Cn ∩ Ri|)
Precision = 1
s
Recall = 1
s
We clustered the reference data set 3,935 samples based upon
n-grams. Figure 8 shows the overall quality of BitShred with Win-
nowing (BS32K (W4)). Surprisingly, simple n-gram analysis did
quite well. When t = 0.6, BS32K (W4) clustering produced 200
clusters with a precision of 0.932 and a recall of 0.928 in 8 minutes.
For a larger-scale experiment, we unpacked 131,072 malware
samples using off-the-shelf unpackers. We then clustered the mal-
ware and compared the identiﬁed families to a reference clustering
using ClamAV labels 2. Figure 9 shows the overall results with Bit-
Shred with Winnowing (BS32K (W12)). When t = 0.57, BS32K
(W12) clustering produced 7,073 clusters with a precision of 0.942
and a recall of 0.922. It took about 27m with 256 map tasks.
• Nearest Neighbor.
Hu et al. describe ﬁnding the nearest k-
neighbors to a given sample as a common triage task [21] (§2.3).
We have implemented similar functionality in BitShred by compar-
ing the given malware to all other malware. We performed experi-
ments ﬁnding the 5 nearest neighbors to randomly chosen malware
samples on the 102,391 malware data set. We achieved the same
94.2% precision and 92.2% recall as above. The average time to
ﬁnd the neighbors was 6.8s (w/ BS8K) and 27s (w/ BS32K), using
25MB memory, with variance always under 1s.
• Visualization. We also have implemented several ways to visual-
ize clustering within BitShred. First, we can create boxed malware
2Considerable amount of manual work is required to prepare a ref-
erence data set. For this reason, we simply used ClamAV as a ref-
erence for 131,072 samples.
0246810 0 100000 200000 300000 400000 500000 600000 700000Time to create fingerprints (minutes)The number of malware samplesBS8K (W12)BS32K (W1)0246810 0 100000 200000 300000 400000 500000 600000 700000Time to compare fingerprints (hours)The number of malware samplesBS8K (W12)BS32K (W1) 0 0.2 0.4 0.6 0.8 1 0.5 0.6 0.7 0.8 0.9 1Precision and RecallSimilarity threshold (t)BS32K (W4) - precisionBS32K (W4) -       recall 0 0.2 0.4 0.6 0.8 1 0.5 0.6 0.7 0.8 0.9 1Precision and RecallSimilarity threshold (t)BS32K (W12) - precisionBS32K (W12) -       recall316Figure 10: Clustering graph when t = 0.57
Figure 11: Lineage tree for a single malware family
graphs where each square represents a malware family, with circles
representing individual samples. Figure 10 shows a clustering of
20,000 malware samples when t = 0.57 3. In the ﬁgure we can see
larger families with many malware in the center, with the size of
the family decreasing as we move to the edges. At the very edge
are malware samples that cluster with no family.
Another way to visualize the results using BitShred is to create
phylogenetic family trees based upon similarity [23]. The more
alike two malware samples are, the closer they are on the tree.
Figure 11 depicts an example tree created from our data set, la-
beled with ClamAV nodes.
It is interesting to note ClamAV la-
bels the malware as coming from three families: Spy, Dropper, and
Ardamax. We manually conﬁrmed that indeed all three were ex-
tremely similar and should be considered of the same family, e.g.,
Trojan.Ardamax-305 and Trojan.Spy-42659 are in different Cla-
mAV families, but only differ in 1 byte.
5.2 BitShred with Dynamic Behaviors as
Features
Static analysis may be fooled by advanced obfuscation techniques,
which has led researchers to propose a variety of dynamic behavior-
based malware analysis approaches, e.g., [12, 13, 28, 29, 33, 35].
One popular variant of this approach is to load the malware into
a clean virtual machine. The VM is started, and observed behav-
iors such as system calls, conditional checks, etc. are recorded as
features.
Bayer et al. provided us with their implementation of clustering,
and the 2658 behavior proﬁles they used to measure accuracy from
3We pick 20,000 samples because larger numbers created graphs
that hung our, and potentially the reviewers’, PDF reader.
Figure 12: Clustering quality based upon behavior proﬁles
# of
proﬁles Clustering
Elapsed Time
Required
Memory (max)
2,658
BAYER-EXACT
BITSHRED-EXACT
16s
4s
75,692
BAYER-LSH
BITSHRED-SETBITS
BITSHRED-EXACT
2h 25m 44s
24m 35s
1h 2m 51s
Table 2: Scalability of Systems
86MB
12MB
4.3GB
89MB
89MB
their paper [13]. In this data set, each behavior proﬁle is a list of
feature index numbers. The total number of features was 172260.
In our experiments, we used only a 1KB ﬁngerprint size since the
number of features was relatively small.
As shown in Table 2, an exact clustering took 16s and 86MB of
memory using the code from Bayer et al. BitShred took 4s (4x as
fast) and used 12MB of memory ( 7x less memory). The average
error was 2% using the 1KB ﬁngerprint. Figure 12 depicts the exact
clustering vs BitShred as a function of precision and recall. Both
had the same precision of .99 and recall of .98 when t = .61. Over-
all, BitShred is faster and uses less memory, while not sacriﬁcing
accuracy for dynamic analysis feature sets.
Although Bayer et al. made the 2658 proﬁles they used for accu-
racy, they did not provide all 75,692 proﬁles they used when mea-
suring performance. In order to measure performance on this size
of data, we synthetically generated 73,034 variants using the 2658
as a basis. We then ran the code from Bayer et al. on 75,692 proﬁles
using the same parameters as described in [13]: k = 10, l = 90,
and t = 0.7. BAYER-LSH took 2h 25m 44s using 4.3GB of mem-
ory and performed 236,132,556 distance computations. BITSHRED-
SETBITS 4 took 24m 35s (5.9x as fast) using 89MB of memory
(49x less memory) and computed similarity of 1,021,322,219 pairs
when t = 0.7.
(Note that BITSHRED-SETBITS performed 4.3x
more distance computations.) Even BITSHRED-EXACT at 1h 2m
51s outperformed (2.3x as fast) BAYER-LSH.
5.3 Semantic Feature Information
Finally, we used the co-clustering phase in BitShred to iden-
tify semantic distinguishing features among malware families. We
performed a variety of experiments and found that, overall, co-
clustering automatically identiﬁed both inter-family and intra-family
semantic features. Typical features identiﬁed included distinguish-
ing register keys set and internet hosts contacted.
Co-clustering of Behavior-Based Proﬁles. We performed a full
co-clustering on the entire dynamic analysis data set from § 5.2.
4We sorted the samples based upon the number of set bits in ﬁn-
gerprints. Then each sample only needed to be compared to the
samples whose number of set bits are within the input threshold.
20181615121917131411Trojan.Ardamax−305Trojan.Ardamax−61Trojan.Ardamax−80Trojan.Dropper−2328Trojan.Dropper−2457Trojan.Dropper−2518Trojan.Dropper−3246Trojan.Dropper−3652Trojan.Dropper−3834Trojan.Dropper−3838Trojan.Spy−42659 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Precision and RecallThresholdBitShred - precisionBitShred -       recallBayer - precisionBayer -       recall317Figure 13a depicts the malware/feature matrix before co-clustering.
We then co-clustered, which took 15 minutes.
Figure 13b shows the complete results. The checkerboard pattern
corresponds to the sub-matrices identiﬁed as being homogeneous,
i.e., corresponding malware/feature pairs that are highly correlated.
For example, the large dark sub-matrix labeled g8 corresponds to
the fact that most malware had the same memory-mapped ﬁles in-
cluding WS2HELP.dll, icmp.dll, and ws2_32.dll. The sub-matrix
g9 shows a commonality between two families, but no others. The
commonality corresponds to opening the ﬁle \Device\KsecDD.
Figure 13c focuses on only the 717 samples in the Allaple mal-
ware family. One semantic feature, labeled g3, is that almost all
samples use the same memory-mapped ﬁles such as winrnr.dll,
WS2HELP.dll, icmp.dll, and ws2_32.dll. More importantly, we
also found that many family members were distinguished by the
register entry they create (e.g., HKLM\SOFTWARE\CLASSES\-
CLSID\{7BDAB28A-B77E-2A87-868A-C8DD2D3C52D3} in one
sample) and the IP address they connect to, e.g., one sample con-
nected to 24.249.139.x while another connected to 24.249.150.y
(shown as g4).
Co-clustering of n-gram features. We also experimented with
co-clustering using the n-gram features. Figure 13d shows intra-
family co-clustering for the Trojan.OnlineGames malware family.
The features labeled g2 correspond to all code from the code entry
to a particular point that overlap. The feature set g1 corresponds to
new functionality in a few variants that makes tcp connections to a
new host not found in previous variants.
We also performed inter-family analysis. In this set of experi-
ments we envision that an analyst uses co-clustering to mine dif-
ferences and similarities between malware family members or be-
tween malware families. We picked the Trojan.Dropper, Trojan.Spy,
Trojan.OnlineGames, and Adware.Downloader families, which have
1280 total members. The total time taken by co-clustering was 10
minutes (about 2s per sample), with about 1 minute for each col-
umn and row iteration. We used 10 maps for each row iteration and
64 maps for column iteration.
Figure 13e shows the resulting co-clustering. Trojan.Dropper
and Trojan.Spy were grouped together by co-clustering. This is
accurate: we manually conﬁrmed that the samples we have from
those families are not well-distinguished. The submatrix labeled g5
is one distinguishing feature corresponding to Adware.Downloader
connecting to a particular host on the internet. The submatrix la-
beled g6 corresponds to data section fragments shared between
the Trojan family, but not present in Adware. The submatrix la-
beled g7 corresponds to shared code for comparing memory loca-
tions. This code is shared between Adware.Downloader and Tro-
jan.OnlineGames, but not Trojan.Spy/Trojan.Downloader.
6. RELATED WORK
We are not the ﬁrst to propose the need for large-scale mal-
ware analysis and triage, e.g.,
[13, 21, 31] have similar goals.
As discussed in § 2.3, the main difference in our work is scal-
ability and co-clustering to automatically identify semantic fea-
tures. Our work builds on per-sample analysis and feature extrac-
tion, which is an extremely active area of research including un-
packing research [18, 20, 27, 33, 35], and even entire conferences
like DIMVA.
While we focus on analyzing malware binaries, Perdisci et al.
[32] have explored clustering based upon network behavior fea-
tures. Their similarity metric is based upon the weighted combi-
nation of Euclidean distance, Levenshtein distance, and Jaccard
distance. While BitShred could compute Hamming distance and
Jaccard distance, we leave adapting the analysis, implementation,
and experimentation for other distance metrics as future work.
(a) A typical matrix before co-clustering.
(b) Inter-family analysis based on dynamic behavior proﬁle
(c) Intra-family analysis based on dynamic behavior proﬁle
(d) Intra-family analysis based on static code analysis
(e) Inter-family analysis based on static code analysis
Figure 13: Feature extraction by co-clustering. Grey dots represent
1 in the binary matrix, i.e., the presence of a feature.
g8g9g3g4g1g2g5g6g7318Li et al.
[26] argue it is difﬁcult to get ground truth for clus-
tering accuracy.
In our setting the main metric is how close the
feature-hashed version of clustering comes to the quality of an ex-
act Jaccard clustering, which is different than looking for ground
truth. Nonetheless, we do report overall clustering accuracy, where
all the caveats from [26] apply.
7. CONCLUSION
In this paper we have presented BitShred, a system for large-
scale malware triage and similarity detection. The key idea behind
BitShred is using feature hashing to reduce the high-dimensional
feature space in malware analysis, which is supported by theoret-
ical and empirical analysis. Our approach makes inter-malware
comparisons in typical large-scale triage tasks such as clustering
and ﬁnding nearest neighbors up to 2,365x faster than existing meth-
ods while using less memory. As a result, BitShred scales to current
and future malware volumes where previous approaches do not. We
have also developed a distributed version of BitShred where 2x the
hardware gives 2x the performance. In our tests, we show we can
scale to up to clustering over 1.9 million malware per day. Finally,
we have developed novel techniques based upon co-clustering to
extract semantic features between malware samples and families.
The extracted features provide insight into the fundamental differ-
ences and similarities between and within malware data sets.
Acknowledgment
This research was supported in part by sub-award PO4100074797
from Lockheed Martin Corporation originating from DARPA Con-
tract FA9750-10-C-0170 for BAA 10-36. We would like to thank
Malware Analysis System (aka CWSandbox) and Offensive Com-
puting for providing malware data sets. We also would like to thank
VirusTotal for providing the private API to access their resources.
References
[1] Apache hadoop. http://hadoop.apache.org/.
[2] CMU Cloud Computer Cluster.
http://www2.pdl.cmu.edu/~twiki/cgi-bin/
view/OpenCloud/ClusterOverview.
[3] Malware Analysis System. http://mwanalysis.org/.
[4] Offensive Computing.
http://www.offensivecomputing.net/.
[5] SimMetrics. http:
//sourceforge.net/projects/simmetrics/.
[6] VirusTotal. http://www.virustotal.com/.
[7] zynamics bindiff.
http://www.zynamics.com/bindiff.html.
[8] Symantec internet security threat report.
http://www.symantec.com/business/theme.
jsp?themeid=threatreport, April 2010.
[9] T. Abou-Assaleh, N. Cercone, V. Keselj, and R. Sweidan.
N-gram-based detection of new malicious code. In
COMPSAC ’04: Proceedings of the 28th Annual
International Computer Software and Applications
Conference - Workshops and Fast Abstracts, 2004.
[10] A. Andoni and P. Indyk. Near-optimal hashing algorithms
for approximate nearest neighbor in high dimensions.
Communications of the ACM, 51(1):177–122, 2008.
[11] J. Attenberg, K. Weinberger, A. Dasgupta, A. Smola, and
M. Zinkevich. Collaborative email-spam ﬁltering with the
hashing-trick. In Proceedings of the Sixth Conference on
Email and Anti-Spam, 2009.
[12] M. Bailey, J. Oberheide, J. Andersen, F. J. Z. Morley Mao,
and J. Nazario. Automated classiﬁcation and analysis of