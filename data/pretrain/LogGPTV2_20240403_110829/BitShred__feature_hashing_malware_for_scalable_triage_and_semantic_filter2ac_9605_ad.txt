### Hierarchical Clustering of Malware

We perform hierarchical clustering on 1.9 million malware samples per day. In the case of incremental clustering, this involves comparing over 190,000 new malware samples daily against 10 million known malware samples in a database.

### Triage Tasks

Three common triage tasks include:
1. **Automatic Identification of Malware Families via Clustering** [13]
2. **Identification of Nearest Neighbors to a Particular Malware Sample** [21]
3. **Visualization of Malware by Creating Phylogenetic Trees** [23]

In this experiment, we explore the use of BitShred with n-grams as the extracted features. While we do not advocate for n-gram analysis, it is interesting to evaluate its performance in such a system. We repeat these analyses in ยง5.2 using dynamic behavior features.

#### Clustering

The quality of a clustering is determined by how closely it aligns with the "correct" clustering based on labeled data. The overall quality depends on the feature extraction tool (e.g., static or dynamic), the specific dataset, and the quality of the reference dataset.

To create a reference clustering dataset, we used 30-40 different antivirus labels provided by VirusTotal [6]. We selected samples detected as malware by at least 20 antivirus programs to ensure reliable labels. We normalized and tokenized all the labels, assigning the family name based on the majority of detecting antivirus programs. This resulted in 3,935 samples.

Clustering quality is measured using precision and recall:
- **Precision** measures how well malware from different families are placed in different clusters.
- **Recall** measures how well malware within the same family are placed in the same cluster.

Formally, precision and recall are defined as:
\[
\text{Precision} = \frac{1}{s} \sum_{i=1}^{s} \max(|C_i \cap R_1|, ..., |C_i \cap R_r|)
\]
\[
\text{Recall} = \frac{1}{s} \sum_{i=1}^{s} \max(|C_1 \cap R_i|, ..., |C_n \cap R_i|)
\]

We clustered the 3,935 reference samples based on n-grams. Figure 8 shows the overall quality of BitShred with Winnowing (BS32K (W4)). Surprisingly, simple n-gram analysis performed well. When \( t = 0.6 \), BS32K (W4) produced 200 clusters with a precision of 0.932 and a recall of 0.928 in 8 minutes.

For a larger-scale experiment, we unpacked 131,072 malware samples using off-the-shelf unpackers. We then clustered the malware and compared the identified families to a reference clustering using ClamAV labels. Figure 9 shows the results with BitShred with Winnowing (BS32K (W12)). When \( t = 0.57 \), BS32K (W12) produced 7,073 clusters with a precision of 0.942 and a recall of 0.922, taking about 27 minutes with 256 map tasks.

#### Nearest Neighbor

Finding the nearest k-neighbors to a given sample is a common triage task [21] (ยง2.3). We implemented this functionality in BitShred by comparing the given malware to all other malware. We performed experiments to find the 5 nearest neighbors to randomly chosen malware samples in a dataset of 102,391 malware. We achieved a precision of 94.2% and a recall of 92.2%. The average time to find the neighbors was 6.8 seconds (w/ BS8K) and 27 seconds (w/ BS32K), using 25MB of memory, with variance always under 1 second.

#### Visualization

We have implemented several ways to visualize clustering within BitShred. First, we can create boxed malware graphs where each square represents a malware family, and circles represent individual samples. Figure 10 shows a clustering of 20,000 malware samples when \( t = 0.57 \). Larger families with many malware samples are in the center, with the size of the family decreasing towards the edges. At the very edge are malware samples that do not cluster with any family.

Another visualization method is to create phylogenetic family trees based on similarity [23]. The more similar two malware samples are, the closer they are on the tree. Figure 11 depicts an example tree created from our dataset, labeled with ClamAV nodes.

It is interesting to note that ClamAV labels the malware as coming from three families: Spy, Dropper, and Ardamax. We manually confirmed that all three were extremely similar and should be considered part of the same family. For example, Trojan.Ardamax-305 and Trojan.Spy-42659 are in different ClamAV families but differ by only 1 byte.

### BitShred with Dynamic Behaviors as Features

Static analysis can be fooled by advanced obfuscation techniques, leading researchers to propose dynamic behavior-based malware analysis approaches [12, 13, 28, 29, 33, 35]. One popular variant is to load the malware into a clean virtual machine, record observed behaviors such as system calls, and use these as features.

Bayer et al. provided us with their implementation of clustering and 2,658 behavior profiles. In this dataset, each behavior profile is a list of feature index numbers, with a total of 172,260 features. In our experiments, we used only a 1KB fingerprint size due to the relatively small number of features.

As shown in Table 2, exact clustering took 16 seconds and 86MB of memory using Bayer et al.'s code. BitShred took 4 seconds (4x faster) and used 12MB of memory (7x less memory). The average error was 2% using the 1KB fingerprint. Figure 12 depicts the exact clustering versus BitShred as a function of precision and recall. Both had the same precision of 0.99 and recall of 0.98 when \( t = 0.61 \). Overall, BitShred is faster and uses less memory without sacrificing accuracy for dynamic analysis feature sets.

Although Bayer et al. provided 2,658 profiles for accuracy, they did not provide all 75,692 profiles used for performance measurement. To measure performance on this scale, we synthetically generated 73,034 variants using the 2,658 profiles as a basis. We ran the code from Bayer et al. on 75,692 profiles using the same parameters: \( k = 10 \), \( l = 90 \), and \( t = 0.7 \). BAYER-LSH took 2 hours 25 minutes 44 seconds using 4.3GB of memory and performed 236,132,556 distance computations. BITSHRED-SETBITS took 24 minutes 35 seconds (5.9x faster) using 89MB of memory (49x less memory) and computed the similarity of 1,021,322,219 pairs when \( t = 0.7 \). Even BITSHRED-EXACT at 1 hour 2 minutes 51 seconds outperformed (2.3x faster) BAYER-LSH.

### Semantic Feature Information

Finally, we used the co-clustering phase in BitShred to identify semantic distinguishing features among malware families. We performed various experiments and found that co-clustering automatically identified both inter-family and intra-family semantic features. Typical features included distinguishing register keys set and internet hosts contacted.

#### Co-clustering of Behavior-Based Profiles

We performed full co-clustering on the entire dynamic analysis dataset from ยง5.2. Figure 13a depicts the malware/feature matrix before co-clustering. After co-clustering, which took 15 minutes, Figure 13b shows the complete results. The checkerboard pattern corresponds to sub-matrices identified as being homogeneous, i.e., highly correlated malware/feature pairs.

For example, the large dark sub-matrix labeled g8 corresponds to most malware having the same memory-mapped files, including WS2HELP.dll, icmp.dll, and ws2_32.dll. The sub-matrix g9 shows a commonality between two families, but no others, corresponding to opening the file \Device\KsecDD.

Figure 13c focuses on the 717 samples in the Allaple malware family. One semantic feature, labeled g3, is that almost all samples use the same memory-mapped files such as winrnr.dll, WS2HELP.dll, icmp.dll, and ws2_32.dll. More importantly, we found that many family members were distinguished by the register entry they create and the IP address they connect to.

#### Co-clustering of n-gram Features

We also experimented with co-clustering using n-gram features. Figure 13d shows intra-family co-clustering for the Trojan.OnlineGames malware family. The features labeled g2 correspond to all code from the code entry to a particular point that overlap. The feature set g1 corresponds to new functionality in a few variants that make TCP connections to a new host not found in previous variants.

We also performed inter-family analysis. In these experiments, we envision that an analyst uses co-clustering to mine differences and similarities between malware family members or between malware families. We picked the Trojan.Dropper, Trojan.Spy, Trojan.OnlineGames, and Adware.Downloader families, which have 1,280 total members. The total time taken by co-clustering was 10 minutes (about 2 seconds per sample), with about 1 minute for each column and row iteration. We used 10 maps for each row iteration and 64 maps for column iteration.

Figure 13e shows the resulting co-clustering. Trojan.Dropper and Trojan.Spy were grouped together by co-clustering, which is accurate. The submatrix labeled g5 is a distinguishing feature corresponding to Adware.Downloader connecting to a particular host on the internet. The submatrix labeled g6 corresponds to data section fragments shared between the Trojan family but not present in Adware. The submatrix labeled g7 corresponds to shared code for comparing memory locations, shared between Adware.Downloader and Trojan.OnlineGames, but not Trojan.Spy/Trojan.Downloader.

### Related Work

We are not the first to propose the need for large-scale malware analysis and triage, e.g., [13, 21, 31] have similar goals. The main difference in our work is scalability and co-clustering to automatically identify semantic features. Our work builds on per-sample analysis and feature extraction, which is an active area of research, including unpacking [18, 20, 27, 33, 35], and even entire conferences like DIMVA.

While we focus on analyzing malware binaries, Perdisci et al. [32] have explored clustering based on network behavior features. Their similarity metric is based on the weighted combination of Euclidean distance, Levenshtein distance, and Jaccard distance. While BitShred can compute Hamming distance and Jaccard distance, we leave adapting the analysis, implementation, and experimentation for other distance metrics as future work.

### Conclusion

In this paper, we presented BitShred, a system for large-scale malware triage and similarity detection. The key idea behind BitShred is using feature hashing to reduce the high-dimensional feature space in malware analysis, supported by theoretical and empirical analysis. Our approach makes inter-malware comparisons in typical large-scale triage tasks such as clustering and finding nearest neighbors up to 2,365x faster than existing methods while using less memory. As a result, BitShred scales to current and future malware volumes where previous approaches do not. We have also developed a distributed version of BitShred where 2x the hardware gives 2x the performance. In our tests, we show we can scale to clustering over 1.9 million malware per day. Finally, we have developed novel techniques based on co-clustering to extract semantic features between malware samples and families. The extracted features provide insight into the fundamental differences and similarities between and within malware datasets.

### Acknowledgment

This research was supported in part by sub-award PO4100074797 from Lockheed Martin Corporation originating from DARPA Contract FA9750-10-C-0170 for BAA 10-36. We would like to thank Malware Analysis System (aka CWSandbox) and Offensive Computing for providing malware datasets. We also would like to thank VirusTotal for providing the private API to access their resources.

### References

[1] Apache Hadoop. http://hadoop.apache.org/.
[2] CMU Cloud Computer Cluster. http://www2.pdl.cmu.edu/~twiki/cgi-bin/view/OpenCloud/ClusterOverview.
[3] Malware Analysis System. http://mwanalysis.org/.
[4] Offensive Computing. http://www.offensivecomputing.net/.
[5] SimMetrics. http://sourceforge.net/projects/simmetrics/.
[6] VirusTotal. http://www.virustotal.com/.
[7] zynamics bindiff. http://www.zynamics.com/bindiff.html.
[8] Symantec Internet Security Threat Report. http://www.symantec.com/business/theme.jsp?themeid=threatreport, April 2010.
[9] T. Abou-Assaleh, N. Cercone, V. Keselj, and R. Sweidan. N-gram-based detection of new malicious code. In COMPSAC '04: Proceedings of the 28th Annual International Computer Software and Applications Conference - Workshops and Fast Abstracts, 2004.
[10] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Communications of the ACM, 51(1):177โ122, 2008.
[11] J. Attenberg, K. Weinberger, A. Dasgupta, A. Smola, and M. Zinkevich. Collaborative email-spam filtering with the hashing-trick. In Proceedings of the Sixth Conference on Email and Anti-Spam, 2009.
[12] M. Bailey, J. Oberheide, J. Andersen, F. J. Z. Morley Mao, and J. Nazario. Automated classification and analysis of