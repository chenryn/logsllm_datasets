1. Is there any anomalous behaviour in the system? (If yes, where?);
2. How can we measure the quality of tracing?
To answer the first question, using our proposed solution, one must use metrics ex-
tracted from tracing data, namely the number of incoming / outgoing requests and the
average response time for each service. These metrics are time-series metrics, and there-
fore, anomaly detection using unsupervised learning algorithms are the way to do it [25].
Metrics were obtained using methods defined in our OpenTSDB client, implemented in
Metrics Repository component.
After extracting these metrics, they are allocated in a data structure called dataframe
from Pandas, an open source library that provides high-performance, easy-to-use data
structures and data analysis tools. This library was chosen due to being one of the most
used and popular for this purpose [66] – data science and data analysis. A Dataframe is
a two-dimensional size-mutable, potentially heterogeneous tabular data structure with
labelled axes (rows and columns). In these data structures, values from time-series
metrics were stored in columns: timestamp (index), datetime, number_of_incoming_re-
51
Chapter 5
quests, number_of_outgoing_requests and average_response_time. In the end, a list of
dataframes are created, one dataframe for each service.
Before performing an analysis to detect if there are outliers presented in our data, the
information must be checked and tested to verify if data have missing values. This is done
because metrics are extracted from multiple sources and thus generates missing values.
For example, we may have missing information for one of the three features in a row of
one dataframe. Missing values are a pain in data analysis and are represented by NaN in
dataframes, and for this reason,one can not apply anomaly detection algorithms over data
with missing values. To fulfil missing information there are two approaches:
1. Remove rows with missing values, which degrades the overall data and may result
in insufficient data;
2. Impute missing values, however, it may be dangerous because it introduces ”wrong”
observations.
Wedecidedtoimputemissingvaluesbecausethereweretookeepinformationquantity.
However, there are multiple ways for imputation of missing values into time-series data,
depending on factors of trend and seasonality. Trending is the increasing or decreasing
value in the series, and seasonality is the repeating short-term cycle in the series [25].
Figure 5.7 shows the path to chose the correct method to fulfil information in time-series
data.
So, before applying the method, our component tests the data to chose the correct
method to fulfil data. Figure 5.8 contains trend and seasonality sample tests performed
over our data.
Figure 5.8 shows that there are clearly trends in our data, however, no seasonality was
detected. For this reason, the selected method to fulfil data presented in dataframes is
Linear Interpolation – Figure 5.7.
These dataframes are then processed by an unsupervised learning algorithm to detect
if there are outliers. For the unsupervised learning algorithm there were: Isolation Forests
and OneClassSVM [68]. The first one uses binary decision trees to isolate data points and
identify outliers presented in the data set, the second one, generates density areas using
max-margin methods, i.e. they do not model a probability distribution, hence the idea
is to find a function that is positive for regions with high density of points, and negative
for small densities, identifying outliers presented in data. Figure 5.9 displays the error
comparison of these two methods.
52
Implementation Process
Figure 5.7: Methods to handle missing data [67].
Trend and seasonality for time-series metric A
dnerT
2000
0
0.05 lanosaeS
0.00
0.05
Time
Trend and seasonality for time-series metric B
dnerT
1x10e6
0
0.05 lanosaeS
0.00
0.05
Time
Figure 5.8: Trend and seasonality results.
53
Chapter 5
Figure 5.9: Isolation Forests and OneClassSVM methods comparison [69].
From Figure 5.9, isolation forests prove to be a better method for outlier detection
because, from this test, it resulted in fewer errors as it did not construct a parametric
representation of the search space. For this reason, we decided to use Isolation Forests, to
detect and identify outliers presented in time-series metrics extracted from tracing data.
To implement Isolation Forests method we used Scikit-Learn, a library full of simple and
efficient tools for data mining, data analysis and machine learning. All configurations
used from this library to implement Isolation Forests were setted to default. Therefore,
Algorithm 4 presents the whole process to identify anomalous services presented in the
system.
Algorithm 4: Anomalous service detection algorithm.
Data: Processed data from tracing using OTP.
Result: Report, in CSV file, containing identified anomalous services and
correspondent times.
1 Read start_timestamp, end_timestamp, db_settings from configuration;
2 Connect to TSDB;
3 Retrieve metrics from TSDB using database connection, start_timestamp and
end_timestamp;
4 Create dataframes with metrics data;
5 Perform data imputation over dataframes;
6 Feed Isolation Forests with metric columns from dataframes;
7 Fire Isolation Forests method (Adds new column “anomaly” with -1 “Anomalous”
or 1 “Non-anomalous”);
8 Filter “anomaly” column with -1 values from dataframes into
anomalous_dataframes;
9 Write report with anomalous service names and times from
anomalous_dataframes data;
Algorithm 4 contains all the process explained above. The final outcome from this
algorithmisareportcontainingallanomalousservicesandcorrespondenttimesidentified.
Also, later we decided to study further the pattern observed in anomalous regions. For
this, the approach was to use the algorithm defined in 3 to analyse what happens to
work-flows in “anomalous” and “non-anomalous” regions.
To answer the second question, it requires to perform a structural and time coverage
analysis. For the first analysis, the approach is to define a specification schema based on
OpenTracing open source specification. This schema aims to test span structures in order
to detect structural problems present in spans, e.g., missed fields, wrong data types, typos
presented in structure. The method implemented is presented in Algorithm 5.
54
Implementation Process
Algorithm 5: Span structure analysis algorithm.
Data: Trace files/Trace data.
Result: CSV file reporting span structure analysis.
1 Read specification from open_tracing_specification_schema.json;
2 while not end of tracing do
3 Read Span;
4 Check Span against specification;
5 Write results from “Check” to CSV file;
As we can see in Algorithm 5, our method aims to produce a report containing the
results of span structural analysis. To do this, first it needs to read the OpenTracing
specificationschema. ThisschemaiswritteninaJSONfile, wherethefieldsareannotated
with tags: required, data-type:  and others. JSON Schema [70] was
the library used to verify if each span complies with the specification. For the second
analysis, the approach is to use spans presented in trace data to analyse the coverage of
each trace. Figure 5.10 presents an example for time coverage in a trace.
Time
Span A
(duration 100ms)
Span B Span C
(duration 50ms) (duration 10 ms)
Figure 5.10: Trace time coverage example.
Figure 5.10 gives us an example in which we have a trace with a root span of 100
milliseconds of duration, and this root span has two children spans, one with 50ms, the
otheronewith10ms, theentiretracehasacoverageof(50+10)/100 = 60%. Thismethod
is applied to every trace, and the results are the stored in a CSV file to be plotted for
visualisation. In this case we apply it and split the results by service, with the objective
of perceive the time coverability of tracing in each service. The method is presented in
Algorithm 6.
Algorithm 6: Trace coverability analysis algorithm.
Data: Trace files/Trace data.
Result: CSV file for each service reporting the coverability analysis.
1 Read start_time and end_time from configuration;
2 Get services from Zipkin;
3 while service in services do
4 Get traces from Zipkin using service, start_time and end_time;
5 Map traces in SpanTrees;
6 Calculate trace_coverability using SpanTrees;
7 Write trace_coverability to CSV file;
Algorithm 6 uses SpanTrees to calculate trace_coverability, this is due to causal re-
lationships presented in these trees. As explained above, through Figure 5.10, one must
have a trace mounted in span relationships (span trees), to know when a span is child
55
Chapter 5
of another, and be able to calculate the coverability presented in a trace. This method
performs this calculation for every service and, in the end, stores information about trace
coverability into a CSV file. This file is later used to produce plots about the service trace
coverability. Whatisexpectedfromthismethodisthatweachieveaplotting, whereevery
service has a counting of traces that cover a certain amount of time.
To summarise, this tools gathers processed data and time-series data from our TSDB,
extracted using OTP from original trace information. Then it perform data imputation
to solve missing values problems, analyses resulting data using Isolation Forests, an un-
supervised multiple feature machine learning algorithm, to identify outliers presented in
our extracted metrics, and therefore, detect anomalies presented in services, identifying
their occurrences in time. Also, this tools uses tracing to perform an analysis about the
structure of spans presented in tracing, and uses processed data from OTP, to perform an
analysis of time coverage provided by tracing data.
NextChapter6, wewillcoverresultsobtainedbythiscomponent, discusstheseresults
and present OpenTracing data limitations.
56
Chapter 6
Results, Analysis and Limitations
In this Chapter we present the final results gathered from the “Data Analysis” com-
ponent presented in Chapter 4 - Proposed Solution, to answer the questions defined in
Section3.2. Resultsforbothquestions, “1. Isthereanyanomalousservice?” and“2. How
can we measure the quality of tracing?”, are presented as well as a brief discussion regard-
ing both results in Sections 6.1 and 6.2 respectively. Later, in the end of this Chapter, in
Section 6.3, we explore some limitations regarding the OpenTracing data.
6.1 Anomaly Detection
For the first question, the approach was to use the OpenTracing processor (OTP)
tool to extract metrics from tracing data to further analyse it using the unsupervised
learning algorithm. The implemented algorithm used for metrics extraction is presented
in Algorithm 1.
After extract metrics, a tool for metrics visualisation (e.g., Grafana) was used to visu-
alise metrics from OpenTSDB database. Samples from these visualizations werepresented
in Figures 5.3, 5.4, 5.5 and 5.6. Therefore, the method explained in Algorithm 4 was ap-
plied to metrics extracted from tracing data. From this algorithm, a Comma-separated
values (CSV) file is generated containing candidates to “possible anomalous regions” for
each service presented in the system. Figure 6.1 shows a sample of the result of outliers
identified in time-series data for a given hypothetical service.
57
Chapter 6
stseuqeR 0003
gnimocnI
0001
0
stseuqeR
0002
gniogtuO 0001
0
)sm(
emiT 0000001
esnopseR
0
segnahC 01
5
hparG
0
1530140000 1530160000 1530180000 1530200000 1530220000
Time Stamp
Figure 6.1: Sample of detection, using multiple feature, of “Anomalous” and
“Non-Anomalous” time-frame regions for a service.
58
Results, Analysis and Limitations
Figure 6.1 contains a set of vertical red lines representing the points of identified
anomalies in time, involving the three distinct time-series metrics. From this outlier
detection, using Isolation Forests, plots containing candidates to “possible anomalous
regions” were generated. The outcome expected from these plots, were a clustering of
values in normal (“non-anomalous”) time-frame regions against clustering of values with
outliers scattered in distant regions (“anomalous”).
Figure 6.2 provides a representation of two time-frame samples, one for the “anoma-
lous” region, and the other for the “non-anomalous” region considering the same service.
In these samples we retrieved data to analyse and give answers to the first question. For
this, we considered three features (as shown in the samples bellow): the number of incom-
ing requests, the number of outgoing requests and the average response time. The sample
resolution for the time-frame is 10 minutes centred in a given timestamp.
Figure 6.2: Comparison between “Anomalous” and “Non-Anomalous” service time-frame
regions.
As we can see in Figure 6.2, there is a clear difference between anomalous and non-
anomalousregions. Thereisadrasticchangeintherangeofvaluesbetweentheanomalous
and non-anomalous regions, where the maximum for each feature changes greatly and
therefore, outliers are visible and evident in the observations. In the anomalous samples,
it is possible to notice a clear crowding of points near the origin point of the chart and
some outliers in the upper-left and down-right regions of the chart. On the other side, in
the non-anomalous samples, all that is possible to notice is the crowding of points near
the origin point of the chart. The crowding of points is what is expected to be the normal
behaviour for services, which means that is expected that the service can handle the load
with good response times. Furthermore, after this observations, what is expected is to
investigate what these points represent and what is causing this unexpected increment in
the number of incoming/outgoing requests and the average response time.
59
Chapter 6
There are two anomalous situations observed:
1. Services are increasing the response time when there are few incoming/outgoing
requests.
2. Services are receiving more incoming/outgoing requests, however it is having a good
response time.