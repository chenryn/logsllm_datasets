unused space to store such data without increasing their
inode sizes. If space were not available, the reverse lookup
table can be used instead, since it provides the same infor-
mation. Second, for each pathname component of a rule,
the reverse lookup table requires 20 + N bytes: a 16-byte
inode number, 2 bytes for the rule bitmask, and N +2 bytes
for a pathname component of length N. Third, the non-
existent names table contains one entry for every ﬁle be-
ing watched that does not currently exist. Each entry con-
sumes 274 bytes: a 16-byte inode number, 2 bytes for the
rule bitmask, and 256 bytes for the maximum pathname
supported.
To examine a concrete example of how an administrator
might use this system, we downloaded the open source
version of Tripwire [42]. Included with it is an example
rule ﬁle for Linux, containing (after expanding directories
to lists of ﬁles) 4730 rules. We examined a Red Hat Linux
6.1 [31] desktop machine to obtain an idea of the number
of watched ﬁles that actually exist on the hard drive. Of
the 4730 watched ﬁles, 4689 existed on our example sys-
tem. Using data structure sizes from above, reverse lookup
entries for the watched ﬁles consume 141 KB. Entries in
the non-existent name table for the remaining 41 watched
ﬁles consume 11 KB. In total, only 152 KB are needed for
the storage IDS.
6.4 False positives
We have explored the false positive rate of storage-based
intrusion detection in several ways.
To evaluate the ﬁle watch rules, two months of traces of all
ﬁle system operations were gathered on a desktop machine
in our group. We compared the ﬁles modiﬁed on this sys-
tem with the watched ﬁle list from the open source version
of Tripwire. This uncovered two distinct patterns where
ﬁles were modiﬁed. Nightly, the user list (/etc/passwd)
on the machine was overwritten by a central server. Most
nights it does not change but the create and rename per-
formed would have triggered an alert. Additionally, mul-
tiple binaries in the system were replaced over time by
the administrative upgrade process. In only one case was
a conﬁguration ﬁle on the system changed by a local user.
For alert-triggering modiﬁcations arising from explicit ad-
ministrative action, a storage IDS can provide an added
beneﬁt. If an administrator pre-informs the admin console
of updated ﬁles before they are distributed to machines,
the IDS can verify that desired updates happen correctly.
Speciﬁcally, the admin console can read the new contents
via the admin channel and verify that they are as intended.
If so, the update is known to have succeeded, and the alert
can be suppressed.
We have also performed two (much) smaller studies. First,
we have evaluated our “hidden ﬁlename” rules by examin-
ing the entire ﬁlesystems of several desktops and servers—
we found no uses of any of them, including the ‘.’ or ‘..’ fol-
lowed by any number of spaces discussed above. Second,
we evaluated our “inode time reversal” rules by examin-
ing lengthy traces of NFS activity from our environment
and from two Harvard environments [8]—we found a siz-
able number of false positives, caused mainly by unpack-
ing archives with utilities like tar. Combined with the lack
of time reversal in any of the toolkits, use of this rule may
be a bad idea.
7 Additional Related Work
Much related work has been discussed within the ﬂow of
the paper. For emphasis, we note that there have been many
intrusion detection systems focused on host OS activity
and network communication; Axelsson [1] recently sur-
veyed the state-of-the-art. Also, the most closely related
tool, Tripwire [18], was used as an initial template for our
prototype’s ﬁle modiﬁcation detection ruleset.
Our work is part of a recent line of research exploiting
physical [12, 44] and virtual [4] protection boundaries to
detect intrusions into system software. Notably, Garﬁnkel
et al. [13] explore the utility of an IDS embedded in a vir-
tual machine monitor (VMM), which can inspect machine
state while being compromise independent of most host
software. Storage-based intrusion detection rules could be
embedded in a VMM’s storage module, rather than in a
physical storage device, to identify suspicious storage ac-
tivity.
Perhaps the most closely related work is the original pro-
posal for self-securing storage [38], which argued for
storage-embedded support for intrusion survival. Self-
securing storage retains every version of all data and a
log of all requests for a period of time called the detec-
tion window. For intrusions detected within this window,
security administrators have a wealth of information for
post-intrusion diagnosis and recovery.
Such versioning and auditing complements storage-based
intrusion detection in several additional ways. First, when
creating rules about storage activity for use in detection,
administrators can use the latest audit log and version his-
tory to test new rules for false alarms. Second, the audit
log could simplify implementation of rules looking for pat-
terns of requests. Third, administrators can use the history
to investigate alerts of suspicious behavior (i.e., to check
for supporting evidence within the history). Fourth, since
USENIX Association
12th USENIX Security Symposium 
149
the history is retained, a storage IDS can delay checks until
the device is idle, allowing the device to avoid performance
penalties for expensive checks by accepting a potentially
longer detection latency.
8 Conclusions and Future Work
A storage IDS watches system activity from a new view-
point, which immediately exposes some common intruder
actions. Running on separate hardware, this functionality
remains in place even when client OSes or user accounts
are compromised. Our prototype storage IDS demonstrates
both feasibility and efﬁciency within a ﬁle server. Analysis
of real intrusion tools indicates that most would be imme-
diately detected by a storage IDS. After adjusting for stor-
age IDS presence, intrusion tools will have to choose be-
tween exposing themselves to detection or being removed
whenever the system reboots.
In continuing work, we are developing a prototype stor-
age IDS embedded in a device exporting a block-based
interface (SCSI). To implement the same rules as our aug-
mented NFS server, such a device must be able to parse and
traverse the on-disk metadata structures of the ﬁle system
it holds. For example, knowing whether /usr/sbin/sshd
has changed on disk requires knowing not only whether the
corresponding data blocks have changed, but also whether
the inode still points to the same blocks and whether the
name still translates to the same inode. We have developed
this translation functionality for two popular ﬁle systems,
Linux’s ext2fs and FreeBSD’s FFS. The additional com-
plexity required is small (under 200 lines of C code for
each), simple (under 3 days of programming effort each),
and changes infrequently (about 5 years between incom-
patible changes to on-disk structures). The latter, in partic-
ular, indicates that device vendors can deploy ﬁrmware and
expect useful lifetimes that match the hardware. Sivathanu
et al. [37] have evaluated the costs and beneﬁts of device-
embedded FS knowledge more generally, ﬁnding that it is
feasible and valuable.
Another continuing direction is exploration of less exact
rules and their impact on detection and false positive rates.
In particular, the potential of pattern matching rules and
general anomaly detection for storage remains unknown.
Acknowledgments
We thank the members and companies of the PDL Consor-
tium (including EMC, Hewlett-Packard, Hitachi, IBM, In-
tel, Microsoft, Network Appliance, Oracle, Panasas, Sea-
gate, Sun, and Veritas) for their interest, insights, feedback,
and support. We thank IBM and Intel for hardware grants
supporting our research efforts. This material is based on
research sponsored by the Air Force Research Labora-
tory, under agreement number F49620-01-1-0433, and by
DARPA/ITO’s OASIS program, under Air Force contract
number F30602-99-2-0539-AFRL.4 Craig Soules was sup-
ported by a USENIX Fellowship. Garth Goodson was sup-
ported by an IBM Fellowship.
References
[1] S. Axelsson. Research in intrusion-detection systems: a sur-
vey. Technical report 98–17. Department of Computer En-
gineering, Chalmers University of Technology, December
1998.
[2] M. Bishop and M. Dilger. Checking for race conditions
in ﬁle accesses. Computing Systems, 9(2):131–152, Spring
1996.
[3] M. Castro and B. Liskov.
Proactive recovery in a
Byzantine-fault-tolerant system. Symposium on Operat-
ing Systems Design and Implementation, pages 273–287.
USENIX Association, 2000.
[4] P. M. Chen and B. D. Noble. When virtual is better than
real. Hot Topics in Operating Systems, pages 133–138.
IEEE Comput. Soc., 2001.
[5] B. Cheswick and S. Bellovin. Firewalls and Internet secu-
rity: repelling the wily hacker. Addison-Wesley, Reading,
Mass. and London, 1994.
[6] D. Denning. An intrusion-detection model. IEEE Transac-
tions on Software Engineering, SE-13(2):222–232, Febru-
ary 1987.
[7] D. E. Denning. Information warfare and security. Addison-
Wesley, 1999.
[8] D. Ellard, J. Ledlie, P. Malkani, and M. Seltzer. Passive
NFS tracing of an email and research workload. Confer-
ence on File and Storage Technologies, pages 203–217.
USENIX Association, 2003.
[9] D. Farmer. What are MACtimes? Dr. Dobb’s Journal,
25(10):68–74, October 2000.
[10] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A.
Longstaff. A sense of self for UNIX processes.
IEEE
Symposium on Security and Privacy, pages 120–128. IEEE,
1996.
[11] G. R. Ganger, G. Economou, and S. M. Bielski. Find-
ing and Containing Enemies Within the Walls with Self-
securing Network Interfaces. Carnegie Mellon University
Technical Report CMU-CS-03-109. January 2003.
[12] G. R. Ganger and D. F. Nagle. Better security via smarter
devices. Hot Topics in Operating Systems, pages 100–105.
IEEE, 2001.
4The U.S. Government is authorized to reproduce and distribute
reprints for Governmental purposes notwithstanding any copyright no-
tation thereon. The views and conclusions contained herein are those of
the authors and should not be interpreted as necessarily representing the
ofﬁcial policies or endorsements, either expressed or implied, of the Air
Force Research Laboratory or the U.S. Government.
150
12th USENIX Security Symposium 
USENIX Association
[13] T. Garﬁnkel and M. Rosenblum. A virtual machine intro-
spection based architecture for intrusion detection. NDSS.
The Internet Society, 2003.
[14] H. Gobioff. Security for a high performance commodity
storage subsystem. PhD thesis, published as TR CMU–CS–
99–160. Carnegie-Mellon University, Pittsburgh, PA, July
1999.
[15] J. H. Howard, M. L. Kazar, S. G. Menees, D. A. Nichols,
M. Satyanarayanan, R. N. Sidebotham, and M. J. West.
Scale and performance in a distributed ﬁle system. ACM
Transactions on Computer Systems, 6(1):51–81, February
1988.
[16] Y. N. Huang, C. M. R. Kintala, L. Bernstein, and Y. M.
Wang. Components for software fault-tolerance and re-
juvenation. AT&T Bell Laboratories Technical Journal,
75(2):29–37, March-April 1996.
[17] J. Katcher. PostMark: a new ﬁle system benchmark. Tech-
nical report TR3022. Network Appliance, October 1997.
[18] G. H. Kim and E. H. Spafford. The design and implementa-
tion of Tripwire: a ﬁle system integrity checker. Conference
on Computer and Communications Security, pages 18–29.
ACM, 1994.
[19] C. Ko, M. Ruschitzka, and K. Levitt. Execution monitor-
ing of security-critical programs in distributed systems: a
speciﬁcation-based approach. IEEE Symposium on Secu-
rity and Privacy, pages 175–187. IEEE, 1997.
[20] P. Kumar and M. Satyanarayanan. Flexible and safe reso-
lution of ﬁle conﬂicts. USENIX Annual Technical Confer-
ence, pages 95–106. USENIX Association, 1995.
Putting fun back into hacking.
[21] R. Lemos.
Net News, 5 August 2002.
2100-1105-948404.html.
ZD-
http://zdnet.com.com/
[22] P. Liu, S. Jajodia, and C. D. McCollum. Intrusion conﬁne-
ment by isolation in information systems.
IFIP Working
Conference on Database Security, pages 3–18. IFIP, 2000.
[23] T. F. Lunt and R. Jagannathan. A prototype real-time
intrusion-detection expert system. IEEE Symposium on Se-
curity and Privacy, pages 59–66. IEEE, 1988.
[24] McAfee NetShield for Celerra.
EMC Corpora-
tion, August 2002.
http://www.emc.com/pdf/
partnersalliances/einfo/McAfee_netshield.pdf.
[25] NFR Security. http://www.nfr.net/, August 2002.
[26] Packet Storm Security. Packet Storm, 26 January 2003.
http://www.packetstormsecurity.org/.
[27] V. Paxson. Bro: a system for detecting network intruders
in real-time. USENIX Security Symposium, pages 31–51.
USENIX Association, 1998.
[28] J. Phillips. Antivirus scanning best practices guide. Tech-
nical report 3107. Network Appliance Inc. http://www.
netapp.com/tech_library/3107.html.
[29] P. A. Porras and P. G. Neumann. EMERALD: event mon-
itoring enabling responses to anomalous live disturbances.
National Information Systems Security Conference, pages
353–365, 1997.
[30] W. Purczynski. GNU ﬁleutils – recursive directory removal
race condition. BugTraq mailing list, 11 March 2002.
[31] Red Hat Linux 6.1, 4 March 1999. ftp://ftp.redhat.
com/pub/redhat/linux/6.1/.
[32] M. Rosenblum and J. K. Ousterhout. The design and im-
plementation of a log-structured ﬁle system. ACM Trans-
actions on Computer Systems, 10(1):26–52. ACM Press,
February 1992.
[33] V. Samar and R. J. Schemers III. Uniﬁed login with plug-
gable authentication modules (PAM). Open Software Foun-
dation RFC 86.0. Open Software Foundation, October
1995.
[34] J. Scambray, S. McClure, and G. Kurtz. Hacking exposed:
network security secrets & solutions. Osborne/McGraw-
Hill, 2001.
[35] B. Schneier and J. Kelsey. Secure audit logs to support
computer forensics. ACM Transactions on Information and
System Security, 2(2):159–176. ACM, May 1999.
[36] M. I. Seltzer, G. R. Ganger, M. K. McKusick, K. A. Smith,
C. A. N. Soules, and C. A. Stein. Journaling versus Soft Up-
dates: Asynchronous Meta-data Protection in File Systems.
USENIX Annual Technical Conference, 2000.
[37] M. Sivathanu, V. Prabhakaran, F.
I. Popovici, T. E.
Denehy, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau.
Semantically-smart disk systems. Conference on File and
Storage Technologies, pages 73–89. USENIX Association,
2003.
[38] J. D. Strunk, G. R. Goodson, M. L. Scheinholtz, C. A. N.
Soules, and G. R. Ganger. Self-securing storage: protect-
ing data in compromised systems. Symposium on Operat-
ing Systems Design and Implementation, pages 165–180.
USENIX Association, 2000.
[39] J. Sugerman, G. Venkitachalam, and B.-H. Lim. Virtualiz-
ing I/O Devices on VMware Workstation’s Hosted Virtual
Machine Monitor. USENIX Annual Technical Conference,
pages 1–14. USENIX Association, 2001.
[40] Sun Microsystems. NFS: network ﬁle system protocol spec-
iﬁcation, RFC–1094, March 1989.
[41] D. B. Terry, M. M. Theimer, K. Petersen, A. J. Demers,
M. J. Spreitzer, and C. H. Hauser. Managing update con-
ﬂicts in Bayou, a weakly connected replicated storage sys-
tem. ACM Symposium on Operating System Principles.
Published as Operating Systems Review, 29(5), 1995.
[42] Tripwire
Open
Souce
2.3.1,
August
2002.
http://ftp4.sf.net/sourceforge/tripwire/
tripwire-2.3.1-2.tar.gz.
[43] K. Vaidyanathan, R. E. Harper, S. W. Hunter, and K. S.
Trivedi. Analysis and implementation of software rejuve-
nation in cluster systems. ACM SIGMETRICS Confer-
ence on Measurement and Modeling of Computer Systems.
Published as Performance Evaluation Review, 29(1):62–71.
ACM Press, 2002.
[44] X. Zhang, L. van Doorn, T. Jaeger, R. Perez, and R. Sailer.
ACM
Secure Coprocessor-based Intrusion Detection.
SIGOPS European Workshop. ACM, 2002.
USENIX Association
12th USENIX Security Symposium 
151