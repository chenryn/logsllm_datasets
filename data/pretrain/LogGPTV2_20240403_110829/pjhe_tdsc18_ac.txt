are executed to generate the RDD, where the action is then this number is increasing quickly due to its active
936 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 15, NO. 6, NOVEMBER/DECEMBER 2018
TABLE 1 
Summary of Our System Log DatasetsSummary of Our System Log Datasets
| System | Log Size | Length #Events | Length #Events | Description |
|---|---|---|---|---|
| BGL |4,747,963 10102 |4,747,963 10102 |376 |BlueGene/L |
| BGL |4,747,963 10102 |4,747,963 10102 |376 |Supercomputer |
| HPC |433,490 |6104 |105 |High Performance |
| HPC |433,490 |6104 |105 |Cluster (Los Alamos) |
| HDFS |11,175,629 |829 |29 |Hadoop Distributed || HDFS |11,175,629 |829 |29 |File System |
| Zookeeper |74,380 |827 |80 |Distributed System |
| Zookeeper |74,380 |827 |80 |Coordinator |
| Proxifier |10,108 |1027 |8 |Proxy Client |
community. We need to select the most suitable operations
indicates whether a block has anomaly operations. Specifi-cally, the dataset with over 10 million log messages records operations on 575,061 blocks, among which 16,838 are anomalies.Log Parser Implementation. Among the four studied log parsing methods, we only find an open-source implementa-tion on SLCT in C language. To enable our evaluations, we have implemented the other three log parsing methods in Python and also wrapped up SLCT as a Python package. Currently, all our implementations have been open-source as a toolkit on Github [21].Evaluation Metric. We use F-measure [19], [20], a com-monly-used evaluation metric for clustering algorithms, to evaluate the parsing accuracy of log parsing methods. The definition of parsing accuracy is as the following.
| to avoid unnecessary performance degradation. For exam- | Parsing Accuracy ¼2  Precision  Recall Precision þ Recall ; | (3) |
|---|---|---||---|---|---|
| ple, if we use aggregateByKey in step 2 and step 3 instead of |Parsing Accuracy ¼2  Precision  Recall Precision þ Recall ; |(3) |
| aggregate, the running time will be one order of magnitude |Parsing Accuracy ¼2  Precision  Recall Precision þ Recall ; |(3) |
| longer. Second, we need to design tailored functions as |Parsing Accuracy ¼2  Precision  Recall Precision þ Recall ; |(3) || input for Spark operations, such as aggregate and reduce. |where Precision and Recall are defined as follows: |(3) |
Though we use aggregate in both step 2 and step 3, different functions have been designed. The source code of POP has been release [21] for reuse. Note that the existing log parser can also be parallelized, but they require non-trivial efforts.
Precision ¼ 	TP 
TP þ FP ; Recall ¼ 	TPTP þ FP ; Recall ¼ 	TP 
TP þ FN ; (4)
where a true positive (TP) decision assigns two log mes-
| 4 | EVALUATION | sages with the same log event to the same log group; a false |
|---|---|---|
| 4 |EVALUATION |positive (FP) decision assigns two log messages with differ- |This section presents our evaluation methodology first. Then we evaluate the performance of log parsers in terms of their accuracy, efficiency, and effectiveness on subsequent log mining tasks in different sections. For each of these three evaluation items, we first explain the evaluation study on representative log parsers and their implication; then we analyze the evaluation results of POP. Finally, we present parameter sensitivity analysis and conclude with experi-mental observations.ent log events to the same log group; and a false negative (FN) decision assigns two log messages with the same log event to different log groups. If the logs are under-partition-ing, the precision will be low because it leads to more false positives. If a log parsing method over-partitions the logs, its recall will decrease because it has more false negatives. Thus, we use F-measure, which is the harmonic mean of precision and recall, to represent parsing accuracy. To obtain the ground truth for the parsing accuracy evaluation, we split the raw log messages into different groups with the4.1 Study Methodology help of manually-customized regular expressions.Log Datasets. We used five real-world log datasets, including supercomputer logs (BGL and HPC), distributed system logs (HDFS and Zookeeper), and standalone software logs (Proxifier). Table 1 provides the basic information of these datasets. Log Size column describes the number of raw log messages, while #Events column is the number of log event types. Since companies are often reluctant to release their system logs due to confidentiality, logs are scarce data for research. Among the five real-world log datasets in Table 1, three log datasets are obtained from their authors. Specifi-cally, BGL is an open dataset of logs collected from a Blue-Gene/L supercomputer system at Lawrence LivermoreExperimental Setting. The experiments of systematic eval-uation on existing log parsers are run on a Linux server with Intel Xeon E5-2670v2 CPU and 128 GB DDR3 1600 RAM, running 64-bit Ubuntu 14.04.2 with Linux kernel 3.16.0. Experiments of POP are run on Spark 1.6.0 with YARN as the cluster controller on 32 physical machines. The cluster has 4TB memory and 668 executors in total. All 32 physical machines are inter-connected with 10 Gbps net-work switch. In our experiment, unless otherwise specified, we use 16 executors, each of which has 25G memory and 5 executor cores. We set Kryo as the Spark serializer because it is significantly faster and more compact than the defaultNational Labs (LLNL), with 131,072 processors and one [35]. The parameter setting follows the experience of
32,768 GB memory [33]. HPC is also an open dataset with logs collected from a high performance cluster at Los Ala-mos National Laboratory, which has 49 nodes with 6,152
Cloudera [36], a leading software company that provides big data software, services and supports. To avoid bias, each experiment is run 10 times and the averaged result is| cores and 128 GB memory per node [34]. HDFS logs are col-lected in [3] by engaging a 203-node cluster on Amazon EC2 platform. To enrich the log data for evaluation purpose, we | reported. | reported. |
|---|---|---|
| cores and 128 GB memory per node [34]. HDFS logs are col-lected in [3] by engaging a 203-node cluster on Amazon EC2 platform. To enrich the log data for evaluation purpose, we |4.2 |Accuracy of Log Parsing Methods |further collected two datasets: one from a desktop software Proxifier, and the other from a Zookeeper installation on a 32-node cluster in our lab. In particular, the HDFS logs from [3] have well-established anomaly labels, each of which
In this section, we first evaluate the accuracy of all five log parsing methods. Then we study whether these log parsers can consistently obtain high accuracy on large datasets if parameters tuned on small datasets are employed.HE ET AL.: TOWARDS AUTOMATED LOG PARSING FOR LARGE-SCALE LOG DATA ANALYSIS 	937
TABLE 2 
Parsing Accuracy of Log Parsing Methods (Raw/Preprocessed)
|  | BGL | HPC | HDFS | Zookeeper | Proxifier |
|---|---|---|---|---|---|
| SLCT |0.61/0.94 |0.81/0.86 |0.86/0.93 |0.92/0.92 |0.89/- |
| IPLoM |0.99/0.99 |0.64/0.64 |0.99/1.00 |0.94/0.90 |0.90/- |
| LKE |0.67/0.70 |0.17/0.17 |0.57/0.96 |0.78/0.82 |0.81/- || LogSig |0.26/0.98 |0.77/0.87 |0.91/0.93 |0.96/0.99 |0.84/- |
| POP |0.99 |0.95 |1.00 |0.99 |1.00 |
mainly because IPLoM considers preprocessing internally in its four-step process. Unnecessary preprocessing can lead to over-partitioning.After preprocessing, most of the methods have high overall parsing accuracy (larger than 0.90 in many cases). But none of them consistently lead to very accurate parsing results on all datasets. Specifically, SLCT obtains 0.86 accu-racy on HPC; IPLoM has 0.64 accuracy on HPC; LKE encounters 0.17 accuracy on HPC, 0.70 accuracy on BGL, and 0.81 accuracy on Proxifier; LogSig obtains 0.87 accuracy4.2.1 Parsing Accuracy on HPC and 0.84 accuracy on Proxifier.
In this section, we first evaluate the parsing accuracy of existing parsers with and without preprocessing. Then the parsing accuracy of POP is explained.To study the accuracy of log parsing methods, we use them to parse real-world logs. Similar to the existing work [18], we randomly sample 2k log messages from each data-set in our evaluation, LKE and LogSig cannot parse large log datasets in reasonable time (e.g., LogSig requires 1 day to parse the entire BGL data). For each experiment, we use the same 2k log messages for all 10 executions. These 2k datasets have been released on our project website [21]. The results are reported in Table 2 (i.e., the first number in each cell). As shown in the table, the accuracy of existing log parsers is larger than 0.8 in many cases. Besides, the overall accuracy on HDFS, Zookeeper and Proxifier datasets is higher than that on BGL and HPC. We find that this is mainly because BGL and HPC logs involve much more event types, and they have more various log length range compared with HDFS, Zookeeper and Proxifier.LKE has an accuracy drop on HPC dataset. This is because almost all the log messages are grouped into a single cluster in the first step of LKE, which aggressively groups two clus-ters if any two log messages between them have a distance smaller than a specified threshold. BGL contains a lot of log messages with “generating core.*” as log event, such as“generating core.1” and “generating core.2”. LogSig tends to separate these two log messages into different clusters, because 50 percent of them are different (core.1 and core.2). This causes LogSig’s low accuracy on BGL. Particularly, IPLoM employs heuristic rules based on the characteristics of log messages, while other log parsers rely on typical data mining models. However, we find that IPLoM enjoys the superior overall accuracy, which implies the importance of studying the unique characteristics of log data.Instead of directly parsing the raw log messages, devel-
Findings. Simple preprocessing using domain knowledge (e.g., removal of IP address) improves log parsing accuracy. With preprocessing, existing log parsers can achieve high overall accuracy. But none of them consistently generates accurate parsing results on all datasets.To evaluate the accuracy of POP, we employ it to parse the same 2k datasets. For dataset BGL, HPC, HDFS and Zookeeper, we set GS to 0.6, splitAbs to 10, splitRel to 0.1, maxDistance to 0. Parameter tuning is intuitive because all these parameters have physical meanings. Developer can easily find the suitable parameter setting with basic experi-ence on datasets. For dataset Proxifier, we set GS to 0.3, splitAbs to 5, splitRel to 0.1, maxDistance to 10. The param-eter setting of Proxifier is different because it contains much fewer log events (i.e., 8 as described in Table 1) compared with others. Besides, we extract log messages containing text “<1 sec” in step 1 of POP, which simulates the practical condition described in Section 3.1.The results are presented in the last line of Table 2. We observe that POP delivers the best parsing accuracy for all these datasets. For datasets that has relatively few log events (e.g., HDFS and Proxifier), its parsing accuracy is 1.00, which means all the logs can be parsed correctly. For data-sets that has relatively more log events, POP still delivers very high parsing accuracy (0.95 for HPC). POP has the best parsing accuracy because of three reasons. First, POP will recursively partition each log group into several groups until they become complete groups. Compared with other log parsers based on heuristic rules (e.g., SLCT), POP pro-vides more fine-grained partitioning. Second, POP merges similar log groups based on the extracted log event, which amends over-partitioning. Third, POP allows developers tomanually extract logs with certain properties, which
reduces noise for the partitioning process.
| opers may conduct preprocessing based on their domain | 4.2.2 | Parameter Tuning |
|---|---|---|
| knowledge. To figure out the effectiveness of preprocessing |4.2.2 |Parameter Tuning |on log parsing, we study the impact of preprocessing on parsing accuracy. Specifically, obvious numerical parame-ters in log messages (i.e., IP addresses in HPC&Zookee-per&HDFS, core IDs in BGL, and block IDs in HDFS) are removed. Preprocessing is mentioned in LKE and LogSig, but its effectiveness has not been studied.In Table 2, the second number in each cell represents the accuracy of log parsing methods on preprocessed log data. In most cases, accuracy of parsing is improved. Preprocess-ing greatly increases the accuracy SLCT on BGL, LKE on HDFS, and LogSig on BGL (in bold). However, preprocess-ing could not improve the accuracy of IPLoM. It even slightly reduces IPLoM’s accuracy on Zookeeper. This isThe accuracy of log parsers is affected by parameters. For large-scale log data, it is difficult to select the most suitable parameters by trying different values, because each run will cause a lot of time. Typically, developers will tune the parameters on a small sample dataset and directly apply them on large-scale data.To evaluate the feasibility of this approach, we sampled 25 datasets from the original real-world datasets. Table 3 shows the number of raw log messages in these 25 sample datasets, where each row presents 5 sample datasets gener-ated from a real-world dataset.
We apply parameters tuned on 2k datasets. In Fig. 6, we evaluate the accuracy of the log parsers on the datasets938 IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING, VOL. 15, NO. 6, NOVEMBER/DECEMBER 2018
TABLE 3 