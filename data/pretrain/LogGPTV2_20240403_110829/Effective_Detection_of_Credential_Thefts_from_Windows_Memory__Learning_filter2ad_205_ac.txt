performed a logistic regression with the least squares method
based on the following model:
X = a·Y + b + ε
(1)
where X and Y represent the number of bytes read and the
number of read attempts respectively, a and b are two con-
stants that we wish to estimate and ε represents the error term.
The obtained regression line is depicted on the plot. For all
positive real α, we also deﬁne the alert interval Iα to encom-
pass all the points which lie within a vertical distance of α
standard deviations from the regression line, i.e. all points
whose error term deﬁned in (1) veriﬁes |ε| ≤ α· σ where σ
represents the sampled standard deviation of the errors for
that regression. The graph also shows the alert interval I3.
For the technique L2, which enumerates Kerberos tickets,
a very similar plot is shown in Figure 9 in Appendix B. The
Figure 2: Read behaviour of LSASS memory under credential
theft technique L1 (password), L2 (ticket), and L3 (pass the
hash). The 1344 data points were collected on 244 different
machines during 7 months, as described in Experiment 2.
of our analysis. Most of those discarded were data points with
a particularly low number of bytes read, which we considered
as failed attempts to run Mimikatz by users who possibly did
not have the required privilege to do so. We were therefore
left with 1305 labelled instances of Mimikatz invocations.
A plot of the resulting dataset is seen in Figure 2; data is
labelled with the particular memory read technique that was
used. We compare in Figure 8 in Appendix A the position of
those malicious data points to those of benign read instances
that were studied in the previous section. This geometric
visualisation enables us to make two important observations.
First, the data in Figure 8 shows that processes that steal
credentials from LSASS memory follow a read behaviour that
is clearly identiﬁable by our behavioural model introduced in
Section 4. Indeed, we can see that the data points correspond-
ing to read access of LSASS memory by Mimikatz are easily
distinguishable from those that correspond to read access of
LSASS memory made by benign and legitimate security soft-
ware applications, whose task is to perform regular sanity
checks. The data points of malicious processes lie on a very
speciﬁc and localised area of the plot. In contrast, processes
of benign security software create data points that span other
regions of the feature space.
This analysis therefore encouraged us to build a detection
method based on the fact that malicious activity can be iden-
tiﬁed by looking at the LSASS memory read behaviour of a
process. This detector is developed in the next section.
Second, from the data shown in Figure 2 we can clearly see
that our behavioural model of LSASS memory reads enables
us to further characterise malicious processes by distinguish-
ing between different credential theft techniques used in such
attacks. Therefore, it seems possible to develop a detector
that can not only identify that malicious read behaviour of
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    187
4.555.5·10602468·103BytesreadReadattemptspasswordspthticketsInput: Data point (x,y) modelling a memory read session
Output: None or alert on malicious memory read
1: for τ in Γ do
if x ∈ [xmin
2:
if |aτ · x + bτ − y| < α· στ then
3:
Raise alert for technique τ
4:
end if
5:
end if
6:
7: end for
] then
,xmax
τ
τ
Figure 4: Algorithm that detects malicious LSASS mem-
ory read behaviour, parametrised by the interval width and a
hyper-parameter α for the alert threshold.
This algorithm takes as input a pair (x,y) as representation
of a read session: x is the total number of bytes read, and y
the total number of read attempts during the process session.
For each technique, the algorithm raises an alert if the input
data point lies within the respective alert interval Iα.
In order to compute the true positive rate that this algorithm
yields, we applied this detection on each of the N = 261
Mimikatz instances of the validation set, and then computed
the true positive rate as n/N where n was the number of
detections that correctly classiﬁed these a instances.
Experiment 3. For the computation of the false positive rate,
we ran our detector on all the benign (legitimate) read events
that we collected over 7 days from MDATP machines world-
wide. This amounted to a total M of 273 million reads from
MDATP customers’ machines world-wide.
We then computed the number m of alerts that our algo-
rithm generated for these events, and computed the false posi-
tive rate as m/M. Since the number of true positives obtained
in a single day is negligible compared to the daily number
of read events, the total number of benign read events can
be approximated by the total number of reads. In order to
compute the false positive rate, our security experts manually
examined all the positive cases that our detector alerted on
and excluded the true positive ones by inspection.
We also ran our detection algorithm for different values of α
and recorded the values of the false positive and true positive
rates for these variations, depicted in Figure 11 in Appendix
C. Naturally, we can see that, as the detector interval width
increases, so do the false positive and true positive rates. After
the analysis of this graph, we decided to select the value α = 3
for our detector, which seems to yield an excellent trade-off
between a high 95% true positive rate and an outstanding
false positive rate in the order of magnitude of 10−6.
This chosen value of α corresponds to the alert interval I3
highlighted in Figures 3, 9 and 10, and we can graphically
conﬁrm that this interval covers a large majority of the data
points we collected – without being too wide.
Figure 3: Memory read behaviour of passwords theft.
data acquired for the pass the hash technique (L3) is displayed
in Figure 10 in Appendix B. The data points corresponding
to this technique are divided into 2 different linear clusters for
which we therefore performed separate logistic regressions.
We can empirically observe on those plots that the alert
interval seems to include a large majority of the data points.
A natural question that arises in this context is what interval
width should be chosen in order to build an effective detector.
Large widths would lead to a higher true positive rate but
would also increase the false positive rate. On the other hand,
more narrow intervals would reduce the false positive rate but
would also be more likely to miss out on some true positives.
We study the inﬂuence of this interval width on the false
positive and true positive rates in the next subsection.
7.2 Validation
For validation, we study how the false positive and true posi-
tive rates vary as the margin for our detection interval varies.
The aim of this study is to ﬁnd an ideal trade-off between a
low false positive and a high true positive rate.
For this we use a parameter α, a positive real number that is
used to determine a threshold value for our detector. We build
this detector as follows: for each of the techniques L1-L3, a
data point is considered as belonging to that technique if it
lies within the corresponding alert interval Iα.
The pseudo-code for this is shown in Figure 4. In this
algorithm, α is a positive real number that characterises the
detector interval width. The set Γ refers to the set of the 4
linear regressions that we perform for the 3 credential theft
techniques, including 2 separate ones for the pass the hash
technique. For each regression τ:
refer to the minimal and maximal number
• xmin
, and xmax
τ
of bytes read for regression τ,
τ
• aτ, bτ and στ (resp.) represent the slope, the y-intersect
and the standard deviation of the regression residuals.
188    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
5.35.45.55.65.75.8·1060246·103BytesreadReadattemptsPasswordsRegressionlineAlertintervalI3Technique
Passwords
# alerts
Total
TP rate
118
125
0.94
PTH Tickets Total
249
120
261
125
0.95
0.96
11
11
1
Figure 5: True positive rates over the test set for the techniques
L1-L3, and the true positive rate across all those techniques.
7.3 Testing
Let us now summarise the results that our detection algorithm
yielded on the test set in terms of the true positive rate. Our
detector alerted on 249 out of the 261 instances of Mimikatz
in the test set. That corresponds to a recall number 249/261 =
95%, i.e. an excellent 5% false negative rate. The detailed
results that we obtained by running our algorithm on the test
set are displayed in Figure 5.
Experiment 4. In order to test the false positive rate of our
detection algorithm, we ran that algorithm on a total of 80
million read events that we collected over 2 days from 1.5
million MDATP customers’ machines world-wide and we ob-
served the alerts that it produced. Over the course of these
two days, our detection algorithm only alerted on 230 benign
read events, which yields an excellent false positive rate of
2.86 · 10−6. This is an acceptable FP rate for production
detectors within the MDATP product. Benign processes, such
as MsMpEng, can be identiﬁed as such based on other tech-
niques including some based on their ﬁle name and ﬁle hash.
8 Detecting Malicious Read Access to LSASS
So far, we have built a detection algorithm that models read
behaviours as linear regressions. The width of the detection
interval is set to achieve satisfactory recall and false positive
rate. This detector is running in production in the MDATP
code base and helps to protect thousands of customers.
Next, we provide further evidence of the effectiveness of
our detector by discussing interesting instances of true posi-
tives that it found, including two instances that other detec-
tion tools used at present cannot identify. Further information
about those processes is displayed in Appendix D.
Figure 12 depicts a renamed instance of Mimikatz. An
attacker performs such renaming in the hope that it obfuscates
the presence of this malware and so avoids detection. We
can see in the metadata that the ﬂags identifying Mimikatz
have not been erased or modiﬁed. Therefore, static methods
that anti-viruses use or methods based on Yara rules are able
to identify that this tool is malicious. The sha1 hash of the
calling process is also identiﬁable as being for Mimikatz –
making for example use of the online tool VirusTotal.
Figure 13 describes a custom process named lolz.exe that
we suspect is a bespoke and recompiled version of Mimikatz.
We can see that all metadata related to Mimikatz have been
replaced with a suspicious “Microsoft Windows” ﬂag. As
this executable ﬁle has been customised and recompiled, Yara
rules and anti-virus software would not be able to detect the
running of this process.
Finally, Figure 14 shows an instance of Mimikatz being
invoked remotely via PowerShell. As the calling process is
the legitimate Microsoft tool PowerShell, this process will not
be identiﬁed as being malicious – neither by Yara rules nor
by anti-virus software. This state of affairs would be similar
to a situation in which an attacker applies process injection:
injecting the code of Mimikatz into another benign process
P means that Mimikatz can hide within process P as static
rules of anti-virus software or Yara rules cannot identify that
process P contains injected code.
In both situations, the advantage of our approach is that it is
independent of the calling process and its executable ﬁle. Our
approach only focuses on the behaviour of that process, more
particularly on the way that this process reads memory from
the LSASS process, which holds very sensitive information.
9 Handling Windows Updates
The analyses performed in the previous sections were based
on the data that MDATP collected from their customers from
January to July 2019. On July 9th 2019, a major Windows up-
date was publicly released, namely Windows 10.0.17763.615.
Most MDATP customers migrated to that version in August
2019 and we noticed a slight impact of that migration on the
malicious data points that we were continuously collecting.
This led to the following experiment:
Experiment 5. We collected a total of 1009 Mimikatz in-
stances from 157 different machines over July and August
2019 in order to study the inﬂuence of this OS update. We plot
in Figure 6 the malicious data corresponding to the technique
L1 that steals logon passwords, collected over this period,
and we colour each data point according to the version of
Windows that was running. Windows versions that correspond
to version 10.0.17763.615 or later are denoted as 10+ while
others are denoted as 10−.
In this section, we only report data from the technique for
stealing logon passwords but we made very similar observa-
tions for the two other techniques. In Figure 6, we see that
the data seems to be clearly separated into two different lines
that correspond to credential theft actions on machines with
Windows 10+ and Windows 10− respectively.
In order to protect current customers on Windows 10+
against those threats, we reran our analyses on this newly
collected data and built a new model for ﬁtting the line corre-
sponding to the new OS version, following a similar approach
to that outlined in Section 7.
In order to handle future Windows updates on which the
memory read behaviour of credential theft would potentially
create new linear clusters, it would be of interest to develop
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    189
Figure 6: Inﬂuence of OS updates on memory read behaviours
of logon passwords theft: 1009 password stealing behaviours
collected from 157 different machines in Experiment 5 over
July and August 2019. The label 10− refers to the OS prior
to the update, whereas 10+ refers to the OS after the update.
Figure 7: Adversarial memory read behaviours. The dashed
arrow represents random read injections required to bypass
our current model. The solid arrow represents additional read
injections required to impersonate a benign software.
online machine-learning algorithms that can learn how to
model new linear clusters automatically as new network data
is ingested. One possible idea would be to store all the mali-
cious data points labelled with the corresponding Windows
version that they were collected on. For each of the Windows
versions, one would then perform a linear regression on all
the corresponding data points, possibly by updating already
existing regression lines. An optional optimisation step would
be to merge different regression lines that would appear to be
close, since memory read behaviours do not systematically
change when a new OS version is released. We could also
consider a multi-class classiﬁer.
10 Minimising our Detector’s Attack Surface
In this section, we discuss how an attacker who is aware
of our detection mechanism could defeat our detector, and
we suggest some improvements that we could implement in
order to tackle such evasions. This discussion is set within
the context of adversarial machine learning.
Injecting random memory reads. A direct and intuitive
method for an attacker to bypass our detection model is to in-
ject random memory reads so as to fall outside of the width of
the detection interval. Such a potential behaviour is depicted
by the dashed arrow in Figure 7. However, we recall that
we have also studied in Section 5 the behaviour of legitimate
software which follow characteristic patterns. A malicious
process injecting random memory reads would highly likely
appear as an “isolated” point as shown in Figure 7 that we
could detect using unsupervised detection methods.
Impersonating benign processes. More interestingly, an ad-
vanced attacker could reprogram his attack software so that its
read behaviour meets the linear model for some non-malicious
behaviour while still being able to steal credentials. Such a
potential behaviour is depicted by the solid arrow in Figure
7. Our model in its current form would be unable to detect
such an attacker since it would be indistinguishable from the
benign software it is impersonating.
However, reﬁning the telemetry that we get from MDATP
would enable us to detect such evasions. In addition to its
volume, we could in particular request more information about
the location of the data that processes read.
For example, we could look at the addresses at which each
read begins: we could expect legitimate processes to always
start reading at some predictable – albeit randomised – set of