title:rBridge: User Reputation based Tor Bridge Distribution with Privacy
Preservation
author:Qiyan Wang and
Zi Lin and
Nikita Borisov and
Nicholas Hopper
rBridge: User Reputation based Tor Bridge Distribution with Privacy
Preservation
Qiyan Wang
Department of Computer Science
University of Illinois at Urbana-Champaign
PI:EMAIL
Nikita Borisov
Department of Electrical & Computer Engineering
University of Illinois at Urbana-Champaign
PI:EMAIL
Zi Lin
Department of Computer Science
University of Minnesota
PI:EMAIL
Nicholas J. Hopper
Department of Computer Science
University of Minnesota
PI:EMAIL
Abstract
Tor is one of the most popular censorship circumven-
tion systems; it uses bridges run by volunteers as proxies to
evade censorship. A key challenge to the Tor circumvention
system is to distribute bridges to a large number of users
while avoiding having the bridges fall into the hands of
corrupt users. We propose rBridge—a user reputation sys-
tem for bridge distribution; it assigns bridges according to
the past history of users to limit corrupt users from repeat-
edly blocking bridges, and employs an introduction-based
mechanism to invite new users while resisting Sybil attacks.
Our evaluation results show that rBridge provides much
stronger protection for bridges than any existing scheme.
We also address another important challenge to the bridge
distribution—preserving the privacy of users’ bridge as-
signment information, which can be exploited by malicious
parties to degrade users’ anonymity in anonymous commu-
nication.
1
Introduction
Censoring the Internet is a means adopted by many re-
pressive regimes to control the information that their citi-
zens can access on the Internet. Many websites that allow
people to exchange political ideas (e.g., Facebook, Twitter,
and Flickr) or may provide political information contrary
to the state’s agenda (e.g., YouTube, Wikipedia, and CNN)
have been blocked by the repressive governments [23]. As
of April 2012, 7 out of the top 10 non-Chinese websites1
(70%) were blocked or partially blocked, and in total, 3716
out of 14521 websites (26%) were blocked, by the “Great
Firewall of China”2. To further tighten the Internet censor-
ship, the Chinese government employs an Internet police
force of over 30 000 people to constantly monitor the citi-
zens’ Internet usage [13].
A typical approach to skirting censorship is to deploy
circumvention proxies outside the censored network, which
can provide indirect access to blocked websites. Tor [10]
is one of the most popular proxy-based circumvention sys-
tems; it uses bridges run by volunteers as proxies to evade
censorship. Censors are, however, eager to discover such
bridges and block them as well. A particularly powerful ap-
proach to enumerating bridges is the insider attack, wherein
the censor colludes with corrupt users to discover and shut
down bridges; the censor can further amplify the attack by
deploying a large number of Sybils to accelerate the discov-
ery of bridges.
To make enumeration more difﬁcult, the bridge distribu-
tor gives a limited number of bridges to each user. But this
creates a new privacy problem, as this information could be
used to ﬁngerprint the user: an adversary who can monitor
the bridges used for a set of anonymous tunnels can poten-
tially link them back to the user. As a result, the bridge dis-
tributor becomes a fully trusted component, whereas other
components of Tor must be at most honest-but-curious.
In this work, we make the following contributions to
both bridge protection and user privacy preservation:
1) We propose rBridge—a user reputation system for
bridge distribution.
rBridge computes users’ reputation
based on the uptime of their assigned bridges, and allows a
user to replace a blocked bridge by paying a certain amount
of reputation credits; this prevents corrupt users from re-
1http://www.alexa.com/topsites
2https://zh.greatfire.org
In addition, high-reputation
peatedly blocking bridges.
users are granted opportunities to invite friends into the sys-
tem. The introduction-based approach ensures the system
can steadily grow the user base as recruiting new bridges,
while preventing adversaries from inserting a large number
of corrupt users or Sybils into the system. We performed
extensive evaluation to show that rBridge provides much
stronger protection for bridges than any existing scheme;
for instance, the number of user-hours served by bridges in
rBridge is at least one order of magnitude more than that of
the state-of-the-art proxy distribution scheme [15].
2) For privacy-preserving bridge distribution, the bridge-
related information on users’ reputation proﬁles must be
managed by the users themselves to avoid leaking the in-
formation to the bridge distributor. This raises the prob-
lem that malicious users could cheat the reputation system
by manipulating their records. In this work, we propose a
novel privacy-preserving user reputation scheme for bridge
distribution, which can not only ensure the bridge distribu-
tor learns nothing about users’ bridge assignment, but also
prevent corrupt users from cheating. To our best knowledge,
rBridge is the ﬁrst scheme that is able to perfectly preserve
users’ privacy in bridge distribution. We implemented the
privacy-preserving scheme, and experimental results show
that rBridge has reasonable performance.
The rest of this paper is organized as follows. We in-
troduce related work in Section 2. Section 3 presents the
basic concepts, including design goals, threat model, and
the scope of this work. In Section 4, we elaborate the basic
rBridge scheme without privacy preservation and provide
evaluation results. Section 5 presents the privacy-preserving
scheme and performance evaluation results. We analyze po-
tential attacks in Section 6, and conclude in Section 7.
2 Background and Related Work
2.1 Tor and Bridge Distribution
Tor [10] is primarily an anonymous communication sys-
tem. A Tor user randomly selects 3 relays to build an onion
encryption tunnel to communicate with a target anony-
mously. As of May 4 2012, there are about 3 000 relays
in the Tor network [1]. The selection of relays must be
kept private from any entity, because otherwise an adver-
sary could likely link the user to his communicating target.
To ensure this, each user is required to download all the re-
lays’ descriptors (from a directory authority or a Tor relay)
even though he only needs 3 relays, and make his selection
locally.
Recently, Tor has been increasingly used as a censorship
circumvention tool. Users in a censored country can use Tor
relays as proxies to access blocked sites. However, since all
of the Tor relays are publicly listed, many countries (e.g.,
China) have blocked the public Tor relays altogether. In re-
sponse, Tor turned to private relays run by volunteers, called
bridges, to circumvent censorship. A key challenge though
is to distribute the addresses of bridges to a large number of
users without exposing them to the censor.
The bridge distribution strategies that have been de-
ployed by Tor are to give a small subset of bridges to each
user, as identiﬁed by a unique IP address or a Gmail ac-
count. Unfortunately, these cannot survive a powerful ad-
versary who can access a large number of IP addresses and
Gmail accounts to create a large number of Sybils; the Chi-
nese government were able to enumerate all the bridges dis-
tributed using these strategies in under a month [2]. The al-
ternative approaches adopted by Tor employ more stringent
distribution strategies: the bridges are given to a few trusted
people in censored countries in an ad hoc manner, who fur-
ther disseminate the bridges to their social networks; or, in-
dividuals deploy their private bridges and give the bridges’
addresses only to trusted contacts. However, the stringent
bridge distribution can only reach a very limited fraction of
potential bridge users and restrict the openness of the sys-
tem.
2.2 Proxy Distribution Strategies
Researchers have tried to design better proxy distribution
strategies [11, 14, 15, 20]. Feamster et al. [11] proposed a
keyspace-hopping mechanism for proxy distribution, which
employs computational puzzles to prevent a corrupt user
from learning a large number of proxies. However, this
mechanism is not likely to withstand an adversary who has
strong computational power; the results of [11] show that
95% of 100 000 proxies would be discovered if the adver-
sary can solve about 300 000 puzzles. In the scheme pro-
posed by Sovran et al. [20], the address of a proxy is given
to a few highly trusted people who play as internal prox-
ies to relay other users’ trafﬁc to the external proxy; the
addresses of these forwarders are advertised by performing
random walks on social networks. However, this scheme
is unable to provide users reliable circumvention service as
forwarders may go ofﬂine from time to time; besides, the
forwarders (residing in the censored country) could receive
a severe penalty for facilitating circumvention, which may
make people hesitate to serve as forwarders.
Mahdian [14] studied the proxy distribution problem
from an algorithmic point of view, and theoretically ana-
lyzed the lower bound of the number of proxies required
to survive a certain number of malicious insiders. Never-
theless, their scheme is not practical, as it assumes that the
number of corrupt users is known in advance and there is
no limit on the capacity of each proxy. Recently, McCoy
et al. [15] proposed Proximax, which leverages social net-
works for proxy distribution and distributes proxies based
on the efﬁciency of each distribution channel to maximize
the overall usage of all proxies. In this work, we explicitly
compare rBridge with Proximax and show that rBridge is
able to provide much stronger protection for bridges than
Proximax.
We note that none of the existing proxy distribution
strategies is able to preserve users’ privacy. They assume
the proxy distributor is fully trusted and authorized to know
which proxies are given to a particular user. Applying
these distribution strategies to Tor would degrade users’
anonymity in anonymous communication.
2.3 Anonymous Authentication and Anonymous
Reputation Systems
Researchers have put forward several designs for anony-
mous authentication and anonymous reputation systems [7,
8, 21, 22] that are similar to what we are seeking. Au et
al. [8] proposed a k-times anonymous authentication (k-
TAA) scheme that allows a user to be authenticated anony-
mously for a bounded number of times. The work in [21,22]
extended this scheme to allow revocation without trusted
third parties. Later, Au et al. [7] further extended the anony-
mous authentication schemes to support users’ reputation
management. We note that, however, none of these schemes
is applicable to bridge distribution due to inability to limit
misbehavior of malicious users.
In bridge distribution, a
user’s reputation that is calculated based on the user’s bridge
assignment records should be managed by the user himself
to avoid leaking the bridge information to the bridge dis-
tributor, which raises the risk that a malicious user could
manipulate his reputation records, e.g., increasing his credit
balance. Whereas, in the aforementioned schemes, users’
reputation is calculated by servers that are trusted to per-
form the reputation calculation, and thus they do not need
to consider potential cheating of malicious users.
3 Concept
2. Minimized thirsty-hours of users: Another important
aspect, which is overlooked by prior work, is thirsti-
ness of honest users. We use thirsty-hours to measure
the time that an honest user has no bridge to use. We
aim to minimize it to ensure high quality of service.
3. Healthy growth of the user base: We assume the bridge
distributor can recruit new bridges from time to time,
and each bridge can support up to a certain num-
ber of users due to limited capacity. The consump-
tion of bridges is due to either new user joining or
bridge blocking. By “healthy growth of the user base”,
we mean the user base can grow correspondingly as
new bridges are added to the system, without causing
thirstiness of existing users. For an ineffective bridge
distribution strategy, corrupt users can drain out the
bridge resource, leaving little ability to grow the user
base.
4. Privacy preservation of bridge assignment: We aim
to prevent any entity (e.g., a curious bridge distrib-
utor) from learning any information about bridge as-
signment of a particular user; such information can be
exploited to degrade the user’s anonymity.
We note that 4) distinguishes rBridge from prior work,
as none of the existing approaches preserves users’ bridge
assignment information. For 1), 2), and 3), we shall show
that rBridge can achieve much higher performance than any
existing approach.
It is important to note that similar to prior work, we are
not interested in ensuring a single or a few important indi-
viduals can access unblocked bridges. Instead, we aim to
provide the circumvention service to the majority of users;
in other words, it is possible that a few honest users could
lose all their bridges before boosting their reputation to re-
ceive new bridges. Providing guaranteed circumvention ser-
vice to a few special users can be easily achieved by de-
ploying a few exclusive circumvention proxies; however,
we believe it is more valuable to provide the circumvention
service to a large number of ordinary users.
In this section, we present the design goals, threat model,
and scope of this work.
3.2 Threat Model
3.1 Goals
rBridge aims to achieve the following goals:
1. Maximized user-hours of bridges: McCoy et al. [15]
proposed the metric user-hours to evaluate the robust-
ness of a proxy distribution strategy. It represents the
sum of hours that a bridge can serve for all of its users
before being blocked.
We consider a state-level adversary (i.e., the censor),
who has access to rich human resource, i.e., controlling a
substantial number of potential bridge users.
In rBridge,
a new user needs an invitation ticket (which is probabilis-
tically distributed to high-reputation users) to register and
join the system. A registered malicious user can block his
assigned bridges by revealing them to the censor who can
later block the bridges (referred to as the insider attack).
Typically, the censor would like to block as many bridges
as quickly as possible, but in some instances she can adopt
other strategies, such as keeping known bridges unblocked
for some period of time to boost the number of insiders and
later performing a massive blocking attempt in a crisis. In
general, we assume the set of malicious users is a Byzan-
tine adversary, and can deviate from the protocol in arbi-
trary ways to maximize their chance of blocking bridges.
The adversary could also launch the Sybil attack by creat-
ing a large number of fake accounts in the population of
potential bridge users. We note that, however, the Sybils
can help the adversary discover bridges only if they can get
registered. In addition, we assume that the adversary can
access substantial network resources, e.g., a large number
of IP addresses and Email accounts, but she has bounded
computational power and is unable to subvert widely used
cryptographic systems.
Unlike the existing schemes [2, 11, 14, 15, 20] that as-
sume the bridge distributor is fully trusted, we consider an
honest-but-curious model for the bridge distributor, which
is within the threat model of Tor [10]. More speciﬁcally, we
assume the bridge distributor honestly follows the protocol,
but is interested in learning any private information about
users, such as which bridges are assigned to a particular
user. For ease of presentation, we assume there is a single
bridge distributor, but it is straightforward to duplicate the
bridge distributor by creating multiple mirrored servers.
3.3 Scope
For clarity, we do not attempt to address network-level
bridge discovery. We assume the censor is able to learn
bridges only from the distribution channels (i.e., based on
the knowledge of registered corrupt users and Sybils).
It
is possible that the censor employs other techniques to dis-
cover bridges. For instance, the censor could try to probe all
IP addresses on the Internet to ﬁnd hosts that run Tor hand-
shake protocols, ﬁngerprint Tor trafﬁc to identify bridges, or
monitor the users who connect to a discovered bridge to see
what other TLS connections these users establish and try to
further verify whether the connected hosts are bridges [2].
We note that if the censor were able to identify bridges using
such network-level bridge discovery techniques, any bridge
distribution strategy would not be able to work. Defending
against such attacks is an active research area; researchers
have been proposing various defense mechanisms, such as
obfsproxy [3], BridgeSPA [19], and client password autho-
rization [4]. We acknowledge that effective mechanisms for
resisting the network-level bridge discovery are important
research problems, but they are orthogonal to this work.
In rBridge, users’ reputation is calculated based on the
uptime of their assigned bridges, which requires a mecha-
nism to test reachability of bridges from censored countries.
Recently, the Tor project has proposed several methods to
accurately test bridges’ availability [6], and we expect these
mechanisms to be deployed soon. To clarify, we assume the
availability information of bridges can be provided by the
Tor network, and how to reliably check the bridges’ reach-
ability is out of the scope of this work.
4 The Basic rBridge Scheme
In this section, we present the basic rBridge scheme that
does not provide privacy preservation, i.e., the bridge dis-
tributor knows the bridge assignment details of each user.
We elaborate the privacy-preserving scheme in Section 5.
4.1 Overview
The openness of a proxy-based censorship circumven-
tion system and its robustness to the insider attack seem
to be in conﬂict. On the one hand, allowing anyone to
join the system and get bridges allows malicious users to
quickly enumerate all of the bridges [2]. On the other hand,
applying highly stringent restrictions on user registration
and bridge distribution (e.g., giving bridges only to highly