every row are used, which can be described as a convolution between them. To enforce compactness of the representations
of the log messages we utilize the Gaussian radial basis utilized for the inclusion of operator-labeled samples. This
function as l(·): enables the addition of even more realistic, however, costly
anomaly samples that help to learn the anomaly distribution,
l(z)=exp(−(cid:107)z(cid:107)2) (6) and further improve the performance. The labeled samples
either need to be added together with the auxiliary data
Replacing the function into the loss function we get the
and retrain, or pre-training the model with the normal and
hyper-spherical classifier:
auxiliary data followed by fine-tuning with the labeled data.
n Withsuchatrainingprocedure,themodelextractstherelevant
1 (cid:88)
(1−y i)(cid:107)φ(x i;θ)(cid:107)2 information from the auxiliary data and already learns good
n (7)
i=1 log representations for anomaly detection, as later shown in
−y ilog(1−exp(−(cid:107)φ(x i;θ)(cid:107)2)) the experiments. The replacement of the auxiliary data with
the labeled samples allows the model to only fine-tune its
Thisensurescompactnessofthenormalsamples,whichwill
parametersinafewepochs.Thispreservesthealreadylearned
be enforced to be around the center of a sphere c = 0. For
information from the larger auxiliary dataset as a bias to the
normal samples, i.e., y = 0, the loss function will minimize
i
fine-tuning procedure. In the experiments, we show that the
the distance to c. This results in low values for the left term
inclusion of a small portion of labeled samples improves the
in Equation 7. In contrast, the right term of the loss function
performance of the model.
favors large distances for the anomalous samples. The center
ofasphereccouldbeanyconstantvalue,whichisnotrelevant
F. Vector representations of the logs
during the optimization.
A possible problem that usually arises in such spherical Learning numerical vector representations from the logs
classifiers [17] is that the model is prone to learn trivial is fundamental for the performance of any machine learning
solutions by mapping the inputs to output a constant vector, method for log anomaly detection. Logsy can be utilized for
i.e. c. However, the proposed loss function will not find the obtaining such numerical log representations. These repre-
trivial solution because of the second term in the equation, sentations are used by the objective function of the method,
representing the auxiliary data or the anomalies. To formally to perform anomaly detection, but could be as well used to
show that, let φ(·) be the encoder network, which maps every replace other, less powerful representations (e.g., TF-IDF in
log message to c. It follows that that φ(·) = 0. In this case, previous log-based anomaly detection methods such as the
the second term in Equation 7 for y = 1 will be infinity in PCA [21]), aiming to enhance their anomaly detection.
i
the limit, which acts as a regularizer and prevents learning c
as a trivial vector representation.
D. Anomaly score and detecting anomalies
Considering that the assumption of the objective function
enforces compact, close to the center of the sphere c = 0,
representations, we define our anomaly score as the distance
of the log vectors (obtained from the ’EMBEDDING’ token)
to the center c of the hypersphere.
normal
A(x )=(cid:107)φ(x ;θ)(cid:107)2 (8) anomaly
i i
We define low anomaly scores A(x ) to be normal log
i
messages, while large scores stand for the anomalies. To Fig.3. Idealdistributionofthelogvectorrepresentationsinspace.
decide if the sample is anomalous or normal, we use a
threshold E. If the anomaly scores A(x ) > E, then the The transformed vector of the [’EMBEDDING’] token is
i
sample is an anomaly, otherwise, we consider it as normal. used for representing the context of the log message, which
This concludes the explanation of the inner workings of the is the only output of the model to the loss function. Thus, it
method. In the following, we describe two properties of the is forced to summarize the log message. By using the spher-
model. ical classification decision boundary, we enforce the normal
samples to be close to each one and compactly represented
E. Including expert knowledge
around the center of the sphere. This leaves the anomalies to
Mostcomputersystems,aretosomeextend,supervisedand disperse around the spherical decision boundary in the high-
operated by an administrator. Over time, the administrator dimensionalspace.InFig.3,weillustratealower-dimensional
can manually inspect a small portion of the log events and plot of how the ideal log representations should look like. A
provide labels. As additional option, Logsy allows incorpora- decision boundary (dashed line) can be drawn to optimally
tion of such labels from the target system. The second term separate the classes. We demonstrate such behavior in the
in Equation 7, used for the auxiliary data, could be also evaluation section on real data with Logsy, where we show
TABLEI
DATASETDETAILS.
#UniqueLogmessages
totalunique
System #Messages #Anomalies #Anomalies5m intestandnotintrainforeverysplit
messages
10% 20% 40% 60% 80%
BlueGene/L 4747963 348460 348460 2679 2621 2256 2231 465 4486
Thunderbird 211212192 3248239 226287 334 127 71 27 12 3279
Spirit 272298969 172816564 764890 1091 1028 297 129 73 3441
how the normal and abnormal samples are distributed in low systems were ranked on the Top500 Supercomputers List at
dimensional space. thetime(asofJune2006).Thevariousmachinesareproduced
by IBM, Dell, Cray, and HP. All systems were installed at
V. EVALUATION
Sandia National Labs (SNL), except Blue Gene/L, which is
To quantify the performance of Logsy, we perform a va- at Lawrence Livermore National Labs (LLNL). In Table I we
riety of experiments. We compare the method against two summarize the main characteristics of the datasets.
publicly available baselines DeepLog and PCA on three real- Table I shows that Thunderbird and Spirit are quite
world HPC log datasets. We describe the main properties large datasets of more than 200 million log messages. For
of the datasets, discuss the experimental setup, and present computation-time purposes we restrict the data size on the
the results. We empirically and qualitatively evaluate the log first 5 million, when sorted by timestamp, log messages. We
vector representations from Logsy, where we utilize them in ensure that the 5 million log lines preserve the properties of
the PCA method and observed improved performance. Logsy the dataset, as shown in Table I, which is that new unseen
is evaluated against unsupervised approaches, as from the logs appear in the test data split. The Blue Gene/L dataset
perspective of using labels of the target system, it is an has less than 5 million messages, thus we keep it in total.
unsupervised approach. #Anomalies5m shows the number of anomalous log messages
in those 5 million messages.
A. Experimental setup To evaluate the robustness and generalization of Logsy in
Weselectthreeopenreal-worlddatasetsfromHPCsystems detail, we conduct several experiments with different train-
for evaluation as target systems, namely Blue Gene/L, Spirit, test splits on the target dataset. To ensure that the test data
and Thunderbird [18]. They share an important characteristic contains new log messages previously unseen in the training
associated with the appearance of many new log messages we always split the data when sorted by the timestamp of the
in the timeline of the data, i.e., the systems change over log messages. We perform 5 different data splits to cover as
time. Furthermore, as an additional dataset for enriching the many possible scenarios, i.e., the first 10% training; 90% test
auxiliary data in all experiments we use the HPC RAS log data, 20% training – 80% test, 40% training – 60% test, 60%
dataset [31]. Due to the absence of labels this dataset cannot training – 40% test, and 80% training – 20% test.
be used for evaluation purposes–can not be a target dataset. The number of unique log messages after tokenization is
For each target dataset as an auxiliary data to represent the presented in Table I. We observe that in every split there are
anomaly class we use logs from the remaining datasets. It is new previously unseen log messages that appear in the test
importanttonotethatthetargetvsauxiliarysplits,ensurethat data, which is the main point for empirically proving general-
there is no leak of information from the target system into the ization. Decreasing the size of the training data increases the
auxiliary data. Meaning, there are no labeled samples from number of novel log messages in the test split.
the target system into the auxiliary data. These logs consist 1) Evaluation methods: To enable comparability between
only of easily accessible logs from other systems via the our method to the previous work, we adopt the standard eval-
internet. The non-anomalous samples from the target system uation scores. We evaluate our method in F1-score, precision,
are the target dataset. For example, when Blue Gene/L is our recall, accuracy, which depends on the true negatives (TN),
system of interest (i.e., the target system) proportion of the true positives (TP), false negatives (FN), and false positives
negative samples of Thunderbird, Spirit, and RAS are used (FP) predictions. The positive class of 1, is assumed to be an
as an auxiliary dataset to represent the anomaly class. These anomalous log.
auxiliary samples could be also error messages obtained from 2) Baselines: We compare Logsy against two publicly
online code repositories (e.g., GitHub). We perform anomaly available baseline methods, i.e., PCA [21] and Deeplog [8].
detection on the test samples from the target dataset for Thecurrentclaimedstate-of-the-artmethodLogAnomaly[11]
determining the scores. to best of our knowledge has no publicly available im-
The datasets are collected between 2004 and 2006 on plementation, as it is industry-related research. More-
three different supercomputing systems: Blue Gene/L, Thun- over, LogAnomaly reports only marginal improvement over
derbird, and Spirit. The logs contain anomaly and normal DeepLog of 0.03 F1 score, and thus both approaches are
messagesidentifiedbyanomalycategorytagsandaretherefore relatively comparable. The parameters of these methods are
amenable to anomaly detection and prediction research. All all tuned to produce their best F1 score.
DeepLog PCA Logsy
Blue Gene/L Thunderbird Spirit
1.00 0.99 0.99 0.82 0.99 0.830.840.99 0.9 0.880.99 0.84 0.84 0.99 erocs-1F
00 .. 57 05 0.41 0.41 0.41 0.44 0.65 0.39 0.45 0.49 0.65 0.42 0.6 0.4 0.69 0.55 0.5 0.56 0.62
0.25 0.24 0.14 0.180.12 0.170.12 0.190.2 0.190.18 0.16 0.27 0.28
0.040.05
0.00
10 20 40 60 80 10 20 40 60 80 10 20 40 60 80
1.00 0.810.98 0.81 0.980.98 0.9 0.980.980.97 0.970.980.93 0.961.0 0.87 0.991.0 1.0 0.971.0 1.0 0.831.0 1.0 0.871.0 1.0 0.9 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.991.0 1.0 0.971.0 0.991.0
0.75 llaceR
0.50 0.5 0.56
0.25
0.00
10 20 40 60 80 10 20 40 60 80 10 20 40 60 80
1.00 0.99 0.99 0.99 0.99 0.9 0.99 0.98
0.75 0.83 0.8 0.72 0.78 0.72 0.72 0.63 0.69 noisicerP
000 ... 025 050 0.070.27 0.060.26 0.090.060.26 0.110.110.29 0.52 0.24 0.3 0.32 0.48 0.27 0.43 0.25 0.53 0.38 0.170.33
0.14 0.1 0.110.1 0.09 0.16 0.020.03
10 20 40 60 80 10 20 40 60 80 10 20 40 60 80
1.00 0.81 0.87 0.91 0.88 0.86 0.95 0.84 1.0 0.87 1.0 0.97 0.851.0 0.980.971.0 0.990.981.0 0.85 0.95 0.84 0.95 0.9 0.830.99 0.9 0.960.98 0.9 0.920.99 ycaruccA
00 .. 57 05 0.54 0.71 0.55 0.61 0.42 0.510.52 0.6 0.57 0.48 0.7 0.62 0.65
0.25
0.00
10 20 40 60 80 10 20 40 60 80 10 20 40 60 80
Size of training data (%)
Fig.4. ComparisonoftheevaluationscoresagainstthetwobaselinesDeepLogandPCAonthreedifferentdatasets.
3) Logsy: Implementation details: Every log message dur- unseen log messages and the reduction of the false positive
ingtokenizationistruncatedtoamaximumofmax(|r |)=50 rate. For instance, on the Blue Gene/L dataset, DeepLog and
i
tokens. Logsy has two layers of the transformer encoder, i.e., PCArespectivelyshow2-4timeslowerprecisioncomparedto
N=2 in Fig. 1. The words are embedded with 16 neural units, Logsy. Overall, Logsy is the most accurate method having an
and the higher level vector representations obtained with the average of 0.9. If a log anomaly detection method generates
transformer encoding are all of the same sizes. The size of too many false alarms, it will add too much overhead to the
the feed-forward network that takes the output of the multi- operatorsandalargeamountofunnecessarywork.Therefore,
head self-attention mechanism is also 16, which makes the high precision methods are favourable. DeepLog leverage the
’[EMBEDDING]’ vector the same size. For the optimization indexes of log templates, which ignore the meaning of the
procedure for every experiment, we use a dropout of 0.05, wordsinthelogmessages,tolearntheanomalousandnormal
Adam optimizer with a learning rate of 0.0001, weight decay patterns.However,differenttemplateshavingdifferentindexes
of0.001.Weaddresstheimbalancednumberofnormalversus can share common semantic information and both could be
anomaly samples with adding weights to the loss function for normal. Ignoring this information results in the generation of
the two classes, 0.5 for the normal and 1.0 for the anomaly false positives for DeepLog compared to Logsy.
class. The models are trained until convergence and later We notice that increasing the training size also increases
evaluated on the respective test split. the F1 score in almost all methods, except for the last two
splitsinSpirit.Thesesplitsareunfortunateastheyhaveavery
B. Results and discussion small number of anomalies. Important to note is that Logsy
We show the overall performance of Logsy compared to outperforms the baselines even when only 10% of the data is