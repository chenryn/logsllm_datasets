every w seconds, the data structure associated with each interval is shifted to the left,
i.e., Bi+1 ← Bi. Thus, the contents of the current window B move to B0, the most
recently elapsed interval in the sliding window, and B is reset. At the same time, Bn
reaches the end of the sliding window and is discarded. Rather than keep track of each
of the interval boundaries (which have ﬁxed size), we use a single running timestamp
tALE that points to the end of the sliding window, i.e., corresponds to w0. After every
w seconds tALE is incremented by w. Thus, an entry stored in Bi would have arrived in
the time interval tALE − wi and tALE − w(i + 1).
Estimating TCP Latency Approximately with Passive Measurements
87
Now, suppose an acknowledgement arrives (possibly piggybacked on a data packet)
at time t2 (see lower half of Fig. 1): we need to look backwards in time and ﬁnd the
(ﬁrst) bucket where the corresponding segment was recorded. We ﬁrst check B (and if
there is a match, the RTT is just (t2 − tALE)/2). Then we check B0, B1, . . . , Bn until
we ﬁnd a match. In the ﬁgure, we ﬁnd a match in the window [w2, w3]. We estimate the
RTT as t2 − tALE + 2w + w/2. More generally, when a match is located in Bi, the RTT
is t − tALE + (2i + 1)w/2. If there is no match after checking the last bucket Bn, ALE
does not return an RTT estimate.
Notice that there are two parameters, w and W , that control accuracy and coverage.
For a given span W , increasing the accuracy requires smaller w; thus, more buckets and
associated data structures. A similar argument holds if we were to hold accuracy ﬁxed
(i.e., ﬁx w) but increase W . Rather than require accuracy to be uniform in each bucket
(necessitating a lot of buckets), one could also use non-uniform buckets. We now in-
troduce a variation of the estimator just introduced that we call ALE-E, which employs
exponentially increasing intervals. ALE-E attempts to support relative accuracy for the
same number of buckets i.e., better accuracy for smaller latency samples and lesser ac-
curacy for larger latencies. To differentiate the two, we use ALE-U to denote the use of
uniform sized buckets.
ALE with Exponential Buckets. ALE-E follows the same general idea of moving the
contents of buckets to its older neighbor. However, the buckets follow a slightly different
rule for the shift operation. Like before, bucket B0 shifts its contents to B1 after every
w seconds. However, bucket Bi is shifted (and merged) into Bi+1 every 2iw seconds.
This is illustrated in Fig. 2. Here, we see that every w seconds, B0 is merged with B1;
B1 is merged with B2 every 2w seconds; B2 is merged with B3 every 4w seconds
(not shown) and so on. Whenever the buckets are merged, we adjust their starting and
ending times appropriately. The actual merging is trivial if Bi is maintained as a CBF:
we simply add up the corresponding counters. Intuitively, the size of each interval is
twice as long as the one preceding it. That is to say the i-th interval is of size 2iw. If the
width of the smallest bucket is w, monitoring the span W requires 1 + (cid:4)log2(W/w)(cid:5)
buckets. ALE-E can cover the same range using fewer buckets. However, this comes
at a price: larger buckets cause larger errors in RTT estimate. Moreover, the merging
of bloom ﬁlters causes them to attenuate with each merge, i.e., the bitmaps get more
“crowded” and prone to false positives. Thus, ALE-E makes the estimation of longer
latencies inaccurate in return for parsimonious use of memory and better accuracy for
smaller latencies.
Other Sources of Error. When multiple data segments are acknowledged by a single
cumulative acknowledgement (e.g, a delayed ACK), we can only match (and remove)
the last data segment and generate a single RTT sample. The other data segments are
not removed from the CBFs until they drop out of Bn. The same phenomenon occurs
if the ACKs are not ﬂowing (or ﬂowing fast enough) towards the sender. If this persists
over time, the counting bloom ﬁlter becomes saturated and exhibits a high false positive
rate. We can deal with this by increasing the size of the CBFs.
Since ALE does not maintain the state for the TCP segments, we cannot identify
reordered packets. When this does happen, ALE will return an incorrect answer (rather
88
S. Gangam et al.
than discarding the RTT sample). Retransmitted packets also pose a source of error. In
general, retransmitted segments can be identiﬁed (and excluded from the RTT estima-
tion) in ALE by ﬁrst checking through all the buckets before recording the segment. If a
copy is found, one of the segments being matched is a duplicate and they should both be
discarded. However, this additional check makes the TCP segment insertion operation
go to O(n) from O(1).
Accuracy and Overhead Bounds. ALE has simple discretization error bounds on the
estimated latencies. Let w denote the width of the bucket B0. For ALE-U, the worst case
error is w/2 and the average case error is w/4. In ALE-E, when an ACK has a match
in bucket i, the worst case error is 2i−1w and the average case error is (3w/16)2i. We
omit the proofs due to a lack of space.
ALE with h hash functions takes O(h) time to insert an expected acknowledgement
number in the CBF of bucket B. Matching an ACK takes O(hn) time (answering CBF
membership queries on n buckets). For every time interval w, shifting buckets takes
O(1) time, if the buckets are implemented as a linked list. Additionally, ALE-E takes
O(C) time to add counters of two CBFs (merging). Finally, ALE takes n × C × d bits
of memory, where d is the number of bits in each counter of the CBFs.
ALE Parameters. The sliding window size, or span (W ) should be chosen to ensure
that most of the normal latencies observed fall inside of it. It is a limitation of ALE to
use a preconceived estimate of the maximum latencies in the network. Interval width
(w), the other ALE parameter, is mainly dictated by accuracy requirements. In an appli-
cation like VoIP, which needs latencies lower than 150 ms, an error of 20 ms is accept-
able to identify problematic scenarios. This requires setting w to 40 ms in ALE-U.
We use CBFs with 4 hash functions. For m entries and C counters, the optimal
number of hash functions h is given by h = (C/m) ln 2 and the corresponding false
positive rate is ≈ (2
− ln 2)C/m [5]. With 4 hash functions, this false positive probability
is 0.0625. One can estimate C based on the trafﬁc rate, the time interval w, and the
number of hash functions h. The trafﬁc rate R in our traces varies between 350, 000
and 600, 000 TCP packets per second [1]. For w = 20 ms, h = 4, and m = R × w, the
constraint for optimal h (h = (C/m) ln 2) yields C = 40396. In practice, we require
fewer counters (30000) as the matched ACK numbers are deleted from the CBFs. We
use CBFs with 4-bit counters as they work well in practice [7].
3 Evaluation
We compare different ALE variants against tcptrace as the baseline solution. The
terms tcptrace and baseline are interchangeable. We use two 60-second traces captured
at a backbone link of a tier-1 ISP obtained from CAIDA. The traces capture headers of
all packets in both directions of the link. Trace 1 starts on 07-21-2012 at 13:55 UTC,
contains 2,115,802 TCP ﬂows, and 50,022,761 TCP packets; Trace 2 starts on 02-17-
2011 at 13:01 UTC, contains 2,423,461 TCP ﬂows, and 54,089,453 packets. We ﬁnd
that only 1.8% and 2.1% of the captured ﬂows are bidirectional, a result of most Inter-
net paths being asymmetric at the core [8]. However, closer to the network edge (home
gateways and even most access networks), trafﬁc is bidirectional. Since we do not han-
dle unidirectional ﬂows in our current implementation, we pre-processed the traces to
Estimating TCP Latency Approximately with Passive Measurements
89
[ 0, 60 ]
[ 60, 120 ]
[ 120, 300 ]
[ 300, 2000 ]
)
2
1
(
E
)
2
1
(
U
)
4
2
(
U
)
8
4
(
U
)
6
9
(
U
)
2
1
(
E
)
2
1
(
U
)
4
2
(
U
)
8
4
(
U
)
6
9
(
U
)
2
1
(
E
)
2
1
(
U
)
4
2
(
U
)
8
4
(
U
)
6
9
(
U
)
2
1
(
E
)
2
1
(
U
)
4
2
(
U
)
8
4
(
U
)
6
9
(
U
)
s
m
(
y
c
n
e
a
L
t
e
n
i
l
e
s
a
B
m
o
r
f
e
c
n
e
r
e
f
f
i
d
y
c
n
e
t
a
L
50
0
−50
Fig. 3. Distribution of estimation error (RTTbaseline − RTTALE) over all samples
ﬁlter out unidirectional ﬂows. We point out that it is indeed feasible to ﬁlter out such
ﬂows in an online fashion, but this discussion out of the scope of this paper. In the rest
of the section, unless explicitly stated, we show results from Trace 1, but results for
Trace 2 are qualitatively similar.
We compare 4 different conﬁgurations of ALE-U with n = 12, 24, 48, and 96 buck-
ets; we refer to these conﬁgurations as ALE-U(n). Using tcptrace, we ﬁnd that the
majority of RTTs in Trace 1 are less than 100 ms and only 0.5% are larger than 2 s. We
thus conﬁgure ALE with a window span of two seconds, i.e., W = 2 s. This results