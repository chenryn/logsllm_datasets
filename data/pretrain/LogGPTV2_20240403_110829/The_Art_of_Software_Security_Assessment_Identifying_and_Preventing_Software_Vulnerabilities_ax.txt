Among the most common mistakes are off-by-one errors, in which a length 
calculation is incorrect by one array element. This error is typically caused by failing 
to account for a terminator element or misunderstanding the way array indexing 
works. Consider the following example: 
... 
void process_string(char *src) 
{ 
    char dest[32]; 
    for (i = 0; src[i] && (i  sizeof(buf)) 
        die("error: user string too long\n"); 
    strcpy(buf, user); 
    ... 
} 
This code uses the strlen() function to check that there's enough room to copy the 
username into the buffer. The strlen() function returns the number of characters in 
a C string, but it doesn't count the NUL terminating character. So if a string is 1024 
characters according to strlen(), it actually takes up 1025 bytes of space in memory. 
In the get_user() function, if the supplied user string is exactly 1024 characters, 
strlen() returns 1024, sizeof() returns 1024, and the length check passes. 
Therefore, the strcpy() function writes 1024 bytes of string data plus the trailing NUL 
character, causing one byte too many to be written into buf. 
You might expect that off-by-one miscalculations are rarely, if ever, exploitable. 
However, on OSs running on Intel x86 machines, these errors are often exploitable 
because you can overwrite the least significant byte of the saved frame pointer. As 
you already know, during the course of program execution, each function allocates a 
stack frame for local variable storage. The address of this stack frame, known as the 
base pointer or frame pointer, is kept in the register EBP. As part of the function 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
195 
prologue, the program saves the old base pointer to the stack, right next to the return 
address. If an off-by-one buffer overflow is triggered on a buffer located directly 
below the saved base pointer, the NUL byte is written one byte past the end of the 
buffer, which corresponds to the least significant byte of the saved base pointer. This 
means when the function returns, the restored base pointer is incorrect by up to 255 
bytes, as shown in Figure 5-9. 
Figure 5-9. Off-by-one stack frame 
[View full size image] 
If the new base pointer points to some user-controllable data (such as a character 
buffer), users can then specify local variable values from the previous stack frame as 
well as the saved base pointer and return address. Therefore, when the calling 
function returns, an arbitrary return address might be specified, and total control over 
the program can be seized. 
Off-by-one errors can also be exploitable when the element is written out of bounds 
into another variable used by that function. The security implications of the 
off-by-one error in this situation depend on how the adjacent variable is used 
subsequent to the overflow. If the variable is an integer indicating size, it's truncated, 
and the program could make incorrect calculations based on its value. The adjacent 
variable might also affect the security model directly. For example, it might be a user 
ID, allowing users to receive permissions they aren't entitled to. Although these types 
of exploits are implementation specific, their impact can be just as severe as 
generalized attacks. 
Heap Overflows 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
196 
Heap overflows are a more recent advance in exploitation. Although common now, 
general heap exploitation techniques didn't surface until July 2000. These techniques 
were originally presented by an accomplished security researcher known as Solar 
Designer. (His original advisory is available at 
www.openwall.com/advisories/OW-002-netscape-jpeg/.) To understand how heap 
exploitation works, you need to be familiar with how the heap is managed. The 
following sections cover the basics of heap management and show how heap-based 
buffer overflows are exploited. 
Heap Management 
Although heap implementations vary widely, some common elements are present in 
most algorithms. Essentially, when a call to malloc() or a similar allocation routine is 
made, some memory is fetched from the heap and returned to the user. When this 
memory is deallocated by using free(), the system must mark it as free so that it can 
be used again later. Consequently, state must be kept for regions of memory that are 
returned to the callers so that memory can be handed out and reclaimed efficiently. In 
many cases, this state information is stored inline. Specifically, most 
implementations return a block of memory to the user, which is preceded by a header 
describing some basic characteristics of the block as well as some additional 
information about neighboring memory blocks. The type of information in the block 
header usually includes the following: 
Size of the current block 
Size of the previous block 
Whether the block is free or in use 
Possibly some additional flags 
Note 
BSD systems manage heap memory differently from most other OSs. They store 
most block information out of band. 
Free blocks are often chained together using a standard data structure, such as a 
singly or doubly linked list. Most heap implementations define a minimum size of a 
block big enough to hold pointers to previous and next elements in a list and use this 
space to hold pointers when the block isn't in use. Figure 5-10 is an example of the 
two basic block structures specific to glibc malloc() implementations. 
Figure 5-10. Glibc heap structure 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
197 
Note that the organization of blocks in this way means that triggering an overflow 
results in corrupting header information for allocated memory chunks as well as list 
management data. 
Exploiting Heap Overflows 
As you might have guessed, the ability to modify header data and list pointers 
arbitrarily (as when a buffer overflow occurs) gives attackers the opportunity to 
disrupt the management of heap blocks. These disruptions can be used to manipulate 
block headers to gain reliable arbitrary execution by leveraging the heap 
maintenance algorithms, especially list maintenance of free blocks. After its initial 
discovery by Solar Designer, this process was described in depth in Phrack 57 
(www.phrack.org/phrack/57/p57-0x09). The following list summarizes the standard 
technique: 
1. Blocks marked as free are assumed to contain list pointers to next and 
previous blocks in the free chunks list. 
2. When a block is freed, it's often coalesced with adjacent blocks if they are also 
free. 
3. Because two blocks are being merged into one, the heap algorithm removes 
the next chunk that was originally on the free list, adjusts the size of the chunk 
being freed to reflect that it's now bigger, and then adds the new larger chunk 
onto the free list. 
4. An overflow on the heap is used to mark the next chunk as free so that it's 
later unlinked from the free list. 
5. The overflow buffer sets the list pointers in the corrupted chunk to locations 
useful to an attacker. 
6. When the unlink operation is performed, an attacker-supplied, fixed-size 
value is written to an attacker-determined memory location. 
To understand why unlinking a chunk leads to an arbitrary overwrite, consider the 
following code for unlinking an element from a doubly linked list: 
int unlink(ListElement *element) 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
198 
{ 
    ListElement *next = element->next; 
    ListElement *prev = element->prev; 
    next->prev = prev; 
    prev->next = next; 
    return 0; 
} 
This code removes a ListElement by updating pointers in adjacent elements of the list 
to remove references to the current element, element. If you could specify the 
element->next and element->prev values, you would see that this code unwittingly 
updates arbitrary memory locations with values you can control. This process is 
shown before unlinking in Figure 5-11 and after unlinking in Figure 5-12. 
Figure 5-11. Linked list before unlink operation 
[View full size image] 
Figure 5-12. Linked list after unlink operation 
[View full size image] 
Being able to overwrite a memory location with a controllable value is usually all that 
attackers need to gain control of a process. Many useful values can be overwritten to 
enable attackers to compromise the application. A few popular targets include the 
following: 
Global offset table (GOT)/process linkage table (PLT) UNIX ELF binaries use 
several loader structures to resolve called functions from libraries into 
addresses. These structures enable shared libraries to be located anywhere in 
memory so that the application doesn't need static addresses for API functions 
at compile time. By targeting these structures, attackers can redirect 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
199 
execution to an arbitrary location when a certain API function is called (for 
example, free()). 
Exit handlers Exit handlers are a table of function pointers that are called when 
the process exits in a UNIX OS. By overwriting one of these values, it's 
possible to gain arbitrary execution when the process calls the exit() function 
or returns from the main() function. 
Lock pointers Windows uses a set of function pointers in the process 
environment block (PEB) to prevent unsynchronized modification of process 
information by competing threads. These lock pointers can be overwritten and 
then triggered by certain types of exceptional conditions. 
Exception handler routines The Windows PEB maintains an address for the 
unhandled exception filter routine. This routine is called when an exception 
isn't handled successfully by any other exception handler. A common 
technique is to use the list maintenance code to overwrite the unhandled 
exception routine when updating one part of the list (such as the previous 
element) and then cause a memory access violation when updating the other 
part of the list (the next element). This technique ensures that the unhandled 
exception filter is called immediately, assuming that another exception 
handler doesn't successfully catch the resulting access violation exception. 
Function pointers Applications use function pointers for various reasons, such 
as calling functions from dynamically loaded libraries, for C++ virtual member 
functions, or for abstracting low-level worker functions in opaque structures. 
Overwriting application-specific function pointers can provide a reliable exploit 
against an application. 
Global and Static Data Overflows 
Global and static variables are used to store data that persists between different 
function calls, so they are generally stored in a different memory segment than stack 
and heap variables are. Normally, these locations don't contain general program 
runtime data structures, such as stack activation records and heap chunk data, so 
exploiting an overflow in this segment requires application-specific attacks similar to 
the vulnerability in Listing 5-2. Exploitability depends on what variables can be 
corrupted when the buffer overflow occurs and how the variables are used. For 
example, if pointer variables can be corrupted, the likelihood of exploitation increases, 
as this corruption introduces the possibility for arbitrary memory overwrites. 
7.1.3 Shellcode 
Buffer overflows are usually exploited by directing execution to a known location in 
memory where attacker-controlled data is stored. For an exploit to be successful, this 
location must contain executable machine code that allows attackers to perform 
malicious activities. This is achieved by constructing small snippets of machine code 
designed to launch a shell, connect back to the originating user, or do whatever the 
attacker chooses. At the time of this writing, the most common trend in shellcode 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
200 
construction uses stubs capable of loading additional components on demand over a 
connected socket, as needed by an attacker on the other end. 
Writing the Code 
At the most basic level, shellcode is a small chunk of position-independent code that 
uses system APIs to achieve your objectives. To see how this is done, consider the 
simple case of spawning a shell in UNIX. In this case, the code you want to run is 
roughly the following: 
char *args[] = { "/bin/sh", NULL }; 
execve("/bin/sh", args, NULL); 
This simple code spawns a command shell when it runs. If this code were run in a 
network service, the socket descriptor the user is connected with would need to be 
duplicated over stdin, stdout, and optionally stderr as well. 
To construct the machine code required to spawn the shell, you need to understand 
how this code works at a lower level. The execve() function is exported by the 
standard C library, so a normal program would first locate the libc execve() 
implementation with a little help from the loader, and then call it. Because this 
functionality could be difficult to duplicate in reasonably sized shellcode, generally 
you want to look for a simpler solution. As it turns out, execve() is also a system call 
on UNIX systems, and all the libc function does is perform the system call. 
Invoking system calls on an Intel-based OS usually involves building an argument list 
(in registers or on the stack, depending on the OS), and then asking the kernel to 
perform a system call on behalf of the process. This can be done with a variety of 
methods. For Intel systems, the system call functionality can rely on a software 
interrupt, initiated by the int instruction; a call gate, invoked with an lcall; or 
special-purpose machine support, such as sysenter. For Linux and many BSD variants, 
the int 128 interrupt is reserved for system calls. When this interrupt is generated, 
the kernel handles it, determines that the process needs some system function 
performed, and carries out the requested task. The procedure for Linux systems is as 
follows: 
1.  Put the system call parameters in general-purpose registers starting at EBX. If a 
system call requires more than five parameters, additional parameters are placed 
on the stack. 
2.  Put the system call number of the desired system call in EAX. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
201 
3.  Use the int 128 instruction to perform the system call. 
So the assembly code would look something like this initially: 
xorl %eax, %eax    ; zero out EAX 
movl %eax, %edx    ; EDX = envp = NULL 
movl $address_of_shell_string, %ebx; EBX = path parameter 
movl $address_of_argv, %ecx; ECX = argv 
movb $0x0b         ; syscall number for execve() 
int $0x80          ; invoke the system call 
Nearly all functionality you need when you create shellcode consists of a series of 
system calls and follows the same basic principles presented here. In Windows, the 
system call numbers aren't consistent in OS versions, so most Windows shellcode 
loads system libraries and calls functions in those libraries. A hacker group known as 
Last Stage of Delirium (LSD) documented the basis for what's used to write most 
modern Windows shellcode at www.lsd-pl.net/projects/winasm.zip. 
Finding Your Code in Memory 
The constructed machine code snippets must be position independentthat is, they 
must be able to run successfully regardless of their location in memory. To 
understand why this is important, consider the example in the previous section; you 
need to provide the address of the argument array vector and the address of the 
string "/bin/sh" for the pathname parameter. By using absolute addresses, you limit 
your shellcode's reliability to a large degree and would need to modify it for every 
exploit you write. Therefore, you should have a method of determining these 
addresses dynamically, regardless of the process environment in which the code is 
running. 
Usually, on Intel x86 CPUs, the strings or data required by shellcode is supplied 
alongside the code and their address is calculated independently. To understand how 
this works, consider the semantics of the call instruction. This function implicitly 
saves a return address on the stack; which is the address of the first byte after the call 
instruction. Therefore, shellcode is often constructed with the following format: 
jmp end 
code: 
... shellcode ... 
end: 
call code 
.string "/bin/sh" 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
202 
This example jumps to the end of the code and then uses call to run code located 
directly after the jmp instruction. What is the point of this indirection? Basically, you 
have the relative address of the string "/bin/sh" located on the stack because of the 
call instruction implicitly pushing a return address on the stack. Hence, the address of 
"/bin/sh" can be calculated automatically, regardless of where the shellcode is 
located in the target application. Combining this with the information in the previous 
section, execve() shellcode would look something like this: 
jmp end 
code: 
popl %ebx        ; EBX = pathname argument 
xorl %eax, %eax  ; zero out EAX 
movl %eax, %edx  ; EDX = envp 
pushl %eax       ; put NULL in argv array 
pushl %ebx       ; put "/bin/sh" in argv array 
movl %esp, %ecx  ; ECX = argv 
movb $0x0b, %al  ; 0x0b = execve() system call 
int $0x80        ; system call 
call code 
.string "/bin/sh" 
As you can see, the code to start a shell is fairly straightforward; you simply need to 
fill EBX, ECX, and EDX with pathname, argv, and envp respectively, and then invoke a 
system call. This example is a simple shellcode snippet, but more complex shellcode 
is based on the same principles. 
7.1.4 Protection Mechanisms 
The basics covered so far represent viable exploitation techniques for some 
contemporary systems, but the security landscape is changing rapidly. Modern OSs 
often include preventive technologies to make it difficult to exploit buffer overflows. 
These technologies typically reduce the attacker's chance of exploiting a bug or at 
least reduce the chance that a program can be constructed to reliably exploit a bug on 
a target host. 
Chapter 3(? [????.]), "Operational Review," discussed several of these technologies 
from a high-level operations perspective. This section builds on Chapter 3(? [????.])'s 
coverage by focusing on technical details of common anticorruption protections and 
addressing potential and real weaknesses in these mechanisms. This discussion isn't 