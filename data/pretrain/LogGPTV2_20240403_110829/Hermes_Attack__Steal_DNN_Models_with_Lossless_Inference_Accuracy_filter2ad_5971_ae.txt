### Context and Capabilities
One method lacks backward compatibility. An alternative approach involves data obfuscation, such as obfuscating commands, model commands, and parameters. However, this method requires the kernel to be extended to deobfuscate the data or understand the obfuscated data. While this can raise the barrier for attackers, it does not completely prevent the Hermes attack.

### Additional Defense Mechanisms
Beyond encryption and obfuscation, another mechanism is adding noise from a software perspective. For example, sending data in one process while simultaneously sending interference commands from a different process. However, this can be mitigated by using GPU channels, as discussed in Section 5.2. Another solution is to use dynamic command headers instead of static ones via the device driver, which significantly increases the difficulty of reverse engineering.

### Offloading Tasks to the CPU
Another possible defense mechanism is offloading some tasks to the CPU. This reduces the information obtained from PCIe traffic. Unfortunately, it results in significant performance loss due to frequent data transfer between the CPU and GPU, and the CPU's lower computing power compared to the GPU.

### Mitigation Countermeasures
The first potential defense approach is to encrypt the PCIe traffic. Adding a crypto engine on the CPU side is straightforward, but it is challenging for commodity GPUs that lack such capabilities.

### Related Work

#### Adversarial Examples
Adversarial examples were first highlighted by Szegedy et al. [48], who demonstrated that small, imperceptible perturbations could cause a network to misclassify images. They proposed the L-BFGS approach to generate adversarial examples by maximizing the networkâ€™s prediction error. Subsequently, numerous studies have focused on adversarial attacks, including both white-box [5, 6, 32, 48] and black-box [4, 7, 8, 10, 40, 41, 44] attacks.

#### Extraction Attacks
Table 4.5 summarizes various DNN model extraction attacks and compares them with our work. For instance, [23] proposed an attack by listening to memory bus and PCIe hints, building a classifier to predict the DNN model architecture. [58] introduced a cache-based side-channel attack to steal DNN architectures, while [24] performed a side-channel attack to reveal the network architecture and weights of a CNN model based on memory access patterns and input/output of the accelerator. [55] revealed the internal network architecture and estimated parameters by analyzing power traces. [53] presented an attack on an FPGA-based convolutional neural network accelerator, recovering the input image from collected power traces. [18] proposed an extraction attack by exploiting side timing channels to infer the depth of the network. [51] designed an attack to steal hyper-parameters of various machine learning algorithms. [25] demonstrated an attack that predicts image classification results by observing GPU kernel execution time. [43] assumed the model architecture is known and the softmax layer is accessible, proving that noise input is sufficient to replicate the original model parameters. [46] designed a membership inference attack to determine training datasets based on prediction outputs of machine learning models. [50] investigated extraction attacks on cloud-based ML models relying on outputs returned by ML prediction APIs. Some works generated clone models from query-prediction pairs of the victim model [27, 38, 39, 46, 50].

### Conclusion
In this paper, we identified the PCIe bus as a new attack surface for leaking DNN models. Based on this, we proposed a novel model-extraction attack, named the Hermes Attack, which is the first to fully steal entire DNN models. We addressed the main challenges through extensive reverse engineering, reliable semantic reconstruction, and skillful packet selection and order correction. We implemented a prototype of the Hermes Attack and evaluated it on three real-world NVIDIA GPU platforms. The evaluation results indicate that our scheme can handle customized DNN models, and the stolen models have the same inference accuracy as the original ones. We will open-source these reverse engineering results to benefit the entire community.

### References
[References are listed as provided, without changes.]

This revised version aims to enhance clarity, coherence, and professionalism, making the text more accessible and understandable.