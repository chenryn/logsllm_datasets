T.
4.1 Auxiliary Sample Generation
As described, student models are trained on auxiliary samples together with
teacher model outputs. These samples are drawn from a restricted range but
otherwiseindependentfromthetrainingdatathatwasusedtotraintheteacher.
In the conducted use case study of log anomaly detection auxiliary samples are
randomly generated as follows. Having T as the set of unique templates, an
auxiliary sample is defined as x˜ = (t ∼ T : i = 1,2,...,w +1), where w is
i
the input sequence length. Template t will be used as the prediction target.
w+1
Note that templates are randomly sampled from the unique template set T.
Thus, auxiliary input samples for DeepLog are random template sequences.
Decentralized Federated Learning 7
4.2 Experiment 1: Training of an Untrained Model
Inourfirstexperimentweinvestigatetheabilityoftheproposedmethodtomiti-
gatethecold-startproblem.Therefore,aDeepLogmodelistrainedontheHDFS
data.Outofthe570,204labeledlogsequencesoftheHDFSdataset,weusethe
first 4,855 normal sequences as training and the remaining 565,349 as test set.
The test set contains 16,838 anomalies and 553,366 normal sequences. The two
hyper-parameters of DeepLog were set as follow: w =10 and k =9, where w is
thewindowsizethatdeterminestheinputsequencelengthandisrequiredtogen-
erateauxiliarysamples.Furtherweusecross-entropylosstolearnadistribution
whenpredictingpossiblenextloglines.Theteachermodelusesabatchsizeof16
andwetraineditover20epochsonall4,855normallogsequences.Thetherewith
trained DeepLog model is utilized as the teacher while a completely untrained
model with the same architecture and parametrization adopts the role of a stu-
dent. The teacher performs following transformation: φ : Xw×|T| → Y|T|×R[−1,1]
to generate the knowledge representation. It takes a sequence with w one-hot
encodedtemplatesandoutputsatanhtransformedprobabilitydistributionover
allwtemplates.Differentamountsofknowledgerepresentationtuplesaretested:
{10,50,100,500,1000,5000}. The student model uses a batch size of 16 and we
trained it over 10 epochs for every knowledge representation size. Auxiliary in-
1.0
0.8
0.6 erocS-1F
0.4
0.2
0.0
Teacher 10 50 100 500 1000 5000
Transfer vectors
Fig.2.ComparisonbetweenF1-scoresofteachermodelandstudentmodelsthatwere
trained on different knowledge representation sizes.
put samples are generated as described in section 4.1. Due to this randomness
of sample generation, we repeat the experiment five times. Figure 2 shows the
results as a boxplot, which illustrated the the F1-scores for the teacher and stu-
dents. Bottom and top whiskers reflect the minimum and maximum non-outlier
values.Thelineinthemiddleoftheboxrepresentsthemedian.Theboxbound-
aries are the first quartile and third quartile of the value distribution. The most
left bar shows the F1-score for the teacher model, which is 0.965. This bar is
8 T. Wittkopp and A. Acker
a flat line, because it represents a single value. Remaining bars are visualizing
the F1-score for each knowledge representation size, from 10 to 5,000. First, it
can be observed that a knowledge representation size of at least 100 is required
to have a decent F1-score on the student model. As expected, the score of the
studentincreaseswiththenumberofusedknowledgerepresentationtuples.Due
to the random sampling F1-scored of student models trained with 100 and 500
knowledge representation tuples underlie high uncertainty. The 0.95 confidence
interval ranges from 0.153 to 0.558 for size 100 and from 0.313 to 0.805 for
size 500. The student model’s F1-score becomes increasingly stable with higher
knowledge representation sizes and reaches 0.961 within the 0.95 confidence in-
terval of [0.943,0.958] for size 5000. Compared to the teacher model’s F1-score
of 0.965 we conclude that our method can be utilized to mitigate the cold-start
problembytraininganuntrainedmodelviaknowledgerepresentationsoftrained
models.
4.3 Experiment 2: Federated Learning
InthisexperimentweinvestigatehowmultipleDeepLogmodelsbehaveasteach-
ersandstudents.Itallows totraindistributedmodelsonlocallyavailabletrain-
ing data and subsequently synchronize the knowledge of models. Therefore, we
simulate8distributedHDFSsystemsbycreatingasetofuniquesequences.Out
of the 570,204 labeled log sequences of the HDFS data set, we again use the
first4,855normalsequencestogenerateuniquesequencesofsizew.Thisresults
in 4,092 unique training samples. These 4,092 training samples were evenly and
randomlysplitinto8sets,henceeverysetcontains511trainingsamples.There-
fore, 8 DeepLog models are respectively trained. The two hyper-parameters of
each DeepLog were set as follow: w =10 and k =9. To evaluate the model per-
formanceonpredictingpotentiallyunseensamples,remaining565,349sequences
are used as a joint test set.
We initially trained the 8 DeepLog models over 10 epochs with a batch size
of 16 and cross-entropy-loss as a loss function. The therewith trained DeepLog
model are utilized as teacher models for each other. Hence, all 8 nodes are
also students and where trained with the knowledge representation from the
teacherswithabatchsizeof1over5epochs.Again,wetestdifferentamountsof
knowledgerepresentationpermodel:{10,50,100,500,1000}.Notethatastudent
model is trained on the representations of all teacher models that have a higher
or equal score than itself.
Auxiliary input samples are generated as described in section 4.1. Due to
this random generation of auxiliary samples, we repeat the experiment 7 times.
Figure 3 shows the results as a boxplot, which illustrates the F1-scores of all
8 models (marked as A-H) for different amounts of knowledge representation
tuples over 7 experimentexecutions. The propertiesof the boxplotare the same
as described in 4.2. The most left bars in the category Before for each model
after initially trained on the locally available unique sequence set. No federated
learning is applied here. It can be seen that their F1-scores ranging from 0.520
Decentralized Federated Learning 9
1.0
A
B
C
0.8
D
E
0.6 F erocS-1F
G
H
0.4
0.2
0.0
Before 10 50 100 500 1000
KR learned by student
Fig.3. Comparison of F1-scores of each node before and after the teacher student
process with different knowledge representation sizes.
to 0.938. The 0.95 confidence interval for all 8 nodes in this section ranges from
0.875 to 0.901.
0.940
A
0.935 B
C
0.930 D
E
0.925 F
erocS-1F
G
0.920 H
0.915
0.910
0.905
0.900
Before 10 50 100 500 1000
KR learned by student
Fig.4. Comparison of F1-scores between 0.90 and 0.94 of each node before and after
the teacher student process with different knowledge representation sizes.
The figure 4 shows a zoomed-in version of the same boxplot on the F1-score
rangeofbetween0.90and0.94.Asexpected,anincreasingamountofknowledge
representations leads to overall higher F1-scores. Furthermore, it is visible that
already 10 knowledge representations are improving the F1-scores significantly.
After 10 knowledge representation the lowest F1-score is 0.906 and the 0.95
confidenceintervalforthissectionrangesfrom0.923to0.933.Inthecategoryof
50 knowledge representations, the number of existing outliers is the same, but
the0.95confidenceintervalrangesfrom0.930to0.933,whichisanimprovement
compared to 10 knowledge representations. Also the highest F1-score of 0.939
10 T. Wittkopp and A. Acker
could be observed in this category. The lowest deviations of the F1-score for all
nodes occur at 1000 knowledge representations with a 0.95 confidence interval
from0.933to0.935.InthiscategorythehighestF1-scoreis0.938andthelowest
0.928. Compared to the 0.95 confidence interval of 0.875 to 0.901 before the
teacher student process, we observe an improvement in every category.
This experiment indicates, that it is able to train different models with the
same configuration in a distributed system. The method preserves data privacy
by using auxiliary samples to transfer knowledge between models. A central in-
stanceforsynchronizationofthetrainingprocessisnotrequired.Neithermodel
parameters nor gradients need to be transferred.
5 Conclusion
In this work we proposed a federated learning solution for synchronizing dis-
tributedmodelstrainedonlocallyavailabledata.Outmethoddoesnotrequired
a sharing of original training data or model parameter. Training is done via as-
signment of teacher and student roles to existing models. Students are trained
on the output of teachers via auxiliary samples and respective outputs, referred
to as knowledge representations. We evaluated our approach in a case study of
log anomaly detection. DeepLog models were trained on distinct and unique log
sequences from the HDFS data set. After that the teacher and student roles
were applied to the models in order to test the ability of synchronizing them.
In our first experiment we could show that this approach can mitigate the cold
start problem. For this experiment we setup a trained teacher DeepLog model
and an untrained DeepLog model as a student. We investigated how well they
studentadaptstheteacherwithdifferentamountsofknowledgerepresentations.
After applying the proposed method, the student model achieved a compara-
ble F1-score of 0.96 while the teacher achieved 0.97. In the second experiment,
we demonstrated that our method allows the synchronization of several models
trained on different distinct training data sets through the proposed decentral-
ized federated learning process. Therefore, we split the training set into 8 equal
anduniquelogsequencesubsetsanddistributedtheseamong8DeepLogmodels.
With this training data all nodes could perform an initial training step before
they entered the role of teachers and students. Even with distributing small
amount of 10 knowledge representations all nodes could improve to a F1-score
0.95confidenceintervalbetween0.923and0.933comparedtotheirinitialtrained
models, which reached a 0.95 confidence interval of 0.875 to 0.901. After 1,000
the models archive a 0.95 confidence interval of between 0.933 and 0.935.
For future work we plan to investigate more datasets in order to verify the
generalapplicabilityofourapproach.Furthermore,generatingrandomsequences
from a relatively small set of discrete elements represents a comparably limited
search space for auxiliary sample generation. We expect the knowledge transfer
tobeharderwithinlargerdiscretesetsorevenwithincontinuousspace.Another
goalistoresearchmethodsandheuristicstostabilizeandacceleratetheprocess
of knowledge transfer with increasingly complex auxiliary samples.
Decentralized Federated Learning 11
References
1. A. Acker, T. Wittkopp, S. Nedelkoski, J. Bogatinovski, and O. Kao, “Superiority
of simplicity: A lightweight model for network device workload prediction,” arXiv
preprint arXiv:2007.03568, 2020.
2. M. Du, F. Li, G. Zheng, and V. Srikumar, “Deeplog: Anomaly detection and di-
agnosisfromsystemlogsthroughdeeplearning,”inProceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security,2017,pp.1285–
1298.
3. S.Nedelkoski,J.Bogatinovski,A.Acker,J.Cardoso,andO.Kao,“Self-supervised
log parsing,” arXiv preprint arXiv:2003.07905, 2020.
4. L. Wu, J. Tordsson, E. Elmroth, and O. Kao, “Microrca: Root cause localization
of performance issues in microservices,” in IEEE/IFIP Network Operations and
Management Symposium (NOMS), 2020.
5. F. Lin, M. Beadon, H. D. Dixit, G. Vunnam, A. Desai, and S. Sankar, “Hardware
remediation at scale,” in 2018 48th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks Workshops (DSN-W). IEEE, 2018, pp.
14–17.
6. R. Shokri and V. Shmatikov, “Privacy-preserving deep learning,” in Proceedings
of the 22nd ACM SIGSAC conference on computer and communications security,
2015, pp. 1310–1321.
7. A.Hard,K.Rao,R.Mathews,S.Ramaswamy,F.Beaufays,S.Augenstein,H.Eich-
ner, C. Kiddon, and D. Ramage, “Federated learning for mobile keyboard predic-
tion,” arXiv preprint arXiv:1811.03604, 2018.
8. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized data,” in
Artificial Intelligence and Statistics, 2017, pp. 1273–1282.
9. Q.Yang,Y.Liu,T.Chen,andY.Tong,“Federatedmachinelearning:Conceptand
applications,” ACM Transactions on Intelligent Systems and Technology (TIST),
vol. 10, no. 2, pp. 1–19, 2019.
10. N. Papernot, M. Abadi, U. Erlingsson, I. Goodfellow, and K. Talwar, “Semi-
supervisedknowledgetransferfordeeplearningfromprivatetrainingdata,”arXiv
preprint arXiv:1610.05755, 2016.
11. M. Fredrikson, S. Jha, and T. Ristenpart, “Model inversion attacks that exploit
confidence information and basic countermeasures,” in Proceedings of the 22nd
ACM SIGSAC Conference on Computer and Communications Security, 2015, pp.
1322–1333.
12. R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership inference at-
tacks against machine learning models,” in 2017 IEEE Symposium on Security
and Privacy (SP). IEEE, 2017, pp. 3–18.
13. R. Hu, Y. Gong, and Y. Guo, “Sparsified privacy-masking for communication-
efficient and privacy-preserving federated learning,” arXiv preprint
arXiv:2008.01558, 2020.
14. K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth, “Practical secure aggregation for federated
learning on user-held data,” arXiv preprint arXiv:1611.04482, 2016.
15. R. C. Geyer, T. Klein, and M. Nabi, “Differentially private federated learning: A
client level perspective,” arXiv preprint arXiv:1712.07557, 2017.
16. P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings et al., “Advances and open
problems in federated learning,” arXiv preprint arXiv:1912.04977, 2019.
12 T. Wittkopp and A. Acker
17. T. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni, N. Asokan, and A.-R.
Sadeghi,“D¨ıot:Afederatedself-learninganomalydetectionsystemforiot,”in2019
IEEE 39th International Conference on Distributed Computing Systems (ICDCS).
IEEE, 2019, pp. 756–767.
18. Y. Liu, N. Kumar, Z. Xiong, W. Y. B. Lim, J. Kang, and D. Niyato,
“Communication-efficient federated learning for anomaly detection in industrial
internet of things.”
19. Y. Liu, S. Garg, J. Nie, Y. Zhang, Z. Xiong, J. Kang, and M. S. Hossain, “Deep
anomalydetectionfortime-seriesdatainindustrialiot:Acommunication-efficient
on-device federated learning approach,” IEEE Internet of Things Journal, 2020.
20. D.Preuveneers,V.Rimmer,I.Tsingenopoulos,J.Spooren,W.Joosen,andE.Ilie-
Zudor, “Chained anomaly detection models for federated learning: An intrusion
detection case study,” Applied Sciences, vol. 8, no. 12, p. 2663, 2018.
21. T.D.Nguyen,P.Rieger,M.Miettinen,andA.-R.Sadeghi,“Poisoningattackson
federated learning-based iot intrusion detection system,” 2020.
22. W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, “Detecting large-scale
system problems by mining console logs,” in Proceedings of the ACM SIGOPS
22nd symposium on Operating systems principles, 2009, pp. 117–132.
23. P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An online log parsing approach
with fixed depth tree,” in 2017 IEEE International Conference on Web Services
(ICWS). IEEE, 2017, pp. 33–40.
View publication stats