Locking and Isolation: ExecuteAndAdvance allows up-
dating the application data on replicas without involving
replica CPUs. However, if clients are allowed to read from all
replica nodes, they might observe inconsistent updates since
ExecuteAndAdvance does not offer isolation. To address this
issue, we offer group locking which is a single writer multi-
ple reader locking mechanism. The client calls wrLock and
wrUnlock to acquire and release exclusive write locks so that
other transactions working on the same data are blocked.
HyperLoop allows lock-free one-sided reads from exactly
one replica (head or tail of the chain) similar to existing
systems that use integrity checks to detect incorrect or in-
consistent values. However, we also implement read locks
for systems that need them and note that HyperLoop design
does not hinder systems from performing lock-free one-sided
reads when it is possible to detect inconsistent reads and
reject their values (e.g., FaRM [60]). However, such systems
can have low read throughput since only replica can serve
the reads. In HyperLoop, we additionally provide read locks
that work concurrently with the write locks to help all repli-
cas simultaneously serve consistent reads for higher read
throughput. Unlike write locks, read locks are not group
based and only the replica being read from needs to partici-
pate in the read lock.
We use these APIs to modify two existing popular trans-
actional storage systems (RocksDB [39] and MongoDB [32])
to show the efficacy of HyperLoop.
5.1 RocksDB
In this case study, we show how all the critical path oper-
ations in a write transaction can be offloaded to the NICs
of replicas. This helps the system require the CPU only for
coarse-grained off-the-critical path operations. Note that
even these operations can be offloaded to the NIC, which we
show in the next section.
RocksDB is an persistent key-value store library that can
be integrated into application logic. It serves all requests
using an in-memory data structure and uses a durable write-
ahead log to provide persistence. It periodically dumps the
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
D. Kim and A. Memaripour et al.
in-memory data to persistent storage and truncates the write-
ahead log. We replace the persistent storage in RocksDB with
NVM. Further, we modify the interface between RocksDB’s
write-ahead log and NVM to use HyperLoop APIs instead of
native NVM APIs. We modify/add only 120 lines of code.
Our version of RocksDB uses Append to replicate log records
to replicas’ NVM instead of using the native unreplicated
append implementation. Replicas need to wake up periodi-
cally off the critical path to bring the in-memory snapshot
in sync with NVM. Only one replica in the chain updates
its in-memory copy of the data structure in the critical path.
Therefore, reads from other replicas in our RocksDB imple-
mentation are eventually consistent [94]. Thus, HyperLoop
helps us convert an unreplicated system into a replicated
one with accelerated transactions with only a few modifica-
tions. Section 6.2 shows the performance of our replicated
RocksDB.
RocksDB Recovery: Our recovery protocol for RocksDB is
fairly straightforward. A new member in the chain copies the
log and the database from either downstream or an upstream
node; writes are paused for a short duration of catch-up
phase. Only then does it formally join the chain. While this
reduces write availability, we note that the focus of this paper
is not to optimize the control path but rather to facilitate
developers to build faster data paths. Complementary efforts
in chain replication research have outlined various ways to
speed up recovery.
Our primitives are low-level enough not to interfere with
the recovery protocols that deal with temporary and perma-
nent replica failures. Such a design is crucial for ensuring that
the control path of replication protocols remains unchanged
while only the data path is accelerated with the new primi-
tives. Therefore, in the absence of failures, HyperLoop accel-
erates the transactions and as soon as a failure is detected, the
recovery protocol takes over to bring back a stable data path
as soon as possible. A configurable number of consecutive
missing heartbeats is considered a data path failure [45].
5.2 MongoDB
MongoDB is a NoSQL database server (i.e., document store),
which offers both in-memory and persistent storage. It also
provides replication by copying operation logs to replicas and
asynchronously executing them against the replica version of
the application data [38]. Here, we use MongoDB’s memory
storage engine, which accesses persistent data through issu-
ing loads/stores against memory-mapped files [31] – a model
conducive for NVM and RDMA. We split the MongoDB code
base into a front end and a back end. The front end is inte-
grated with the client while the backend is HyperLoop-based
replicas with NVM.
We achieve this with modifying only 866 lines of code.
We use Append to replicate MongoDB’s write-ahead log (i.e.,
journal) entries to replicas. Then, we execute transactions on
replicas using ExecuteAndAdvance and the replicated write-
ahead log data. Additionally, to allow clients to read from
replicas, we surround each ExecuteAndAdvance on the pri-
mary with wrLock and wrUnlock. Additional replicas only
wake up to serve read requests when the chain is overloaded,
when they must acquire and release a shared lock using
rdLock and rdUnlock. Such an implementation completely
offloads both critical and off-the-critical path operations for
write transactions to the NIC while providing strong consis-
tency across the replicas. We note that there are techniques
(e.g., FaRM [60]) to perform lock free one-sided reads that
can be performed in HyperLoop as well if reads are restricted
only to one replica. The advantage of HyperLoop is that it
reduces the cost of keeping replicas strongly consistent and
therefore, reads can be served from more than one replica to
meet demand.
MongoDB Recovery: The goal of our recovery protocol
here was to bring the chain to a state where vanilla Mon-
goDB recovery can take over. To achieve this, whenever
the membership changes (heartbeat is lost), the entire chain
flushes the log of all valid entries, rejects invalid entries,
block reads temporarily and hand-off control to MongoDB
recovery protocol which helps the new empty replica catch
up and join a newly established HyperLoop data path. Rather
than focusing on control path optimizations that are out of
the scope of this paper, we focus on correctness and feasi-
bility of adopting the accelerated data path of HyperLoop.
6 EVALUATION
In this section, we evaluate HyperLoop by answering the
following questions:
1. How do HyperLoop primitives help improve the perfor-
mance of group memory access (§6.1)?
2. How does HyperLoop help improve the performance of
real-world storage systems (§6.2)?
Testbed setup: Our experimental testbed consists of 20
machines each equipped with two 8-core Xeon E5-2650v2
CPUs, 64 GB DRAM, and a Mellanox ConnectX-3 56 Gbps
RDMA-capable NIC. The operating system running on the
machines is Ubuntu Linux 14.04 with kernel version 3.13.0-
137-generic. In our evaluation, we assume storage nodes are
equipped with battery-backed DRAM [60] which is a form of
NVM available today. We emulate battery-backed DRAM by
mounting a tmpfs file system to DRAM and run applications
on it. We expect to observe similar benefits, i.e., no CPU
overhead on replicas while exhausting the bandwidth of
the network and/or NVM, when replacing battery-backed
DRAM with emerging technologies such as 3D XPoint [6].
Baseline RDMA implementation: To evaluate the perfor-
mance benefit of offloading the primitives to the NIC, we de-
velop a naïve version of primitives using RDMA operations
as a comparison point for HyperLoop. It can perform the
HyperLoop
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Naïve-RDMA-99th percentile
HyperLoop-99th percentile
Naïve-RDMA-Average
HyperLoop-Average
Table 2: Latency of gCAS compared to Naïve-RDMA.
Average
Naïve-RDMA 539us
10us
HyperLoop
95th percentile
3928us
13us
99th percentile
11886us
14us
105
103
101
)
s
µ
(
y
c
n
e
t
a
L
128 256 512 1K 2K 4K 8K
Message size (bytes)
(a) gWRITE
128 256 512 1K 2K 4K 8K
Message size (bytes)
(b) gMEMCPY
Figure 8: Latency of gWRITE and gMEMCPY compared to
Naïve-RDMA.
same set of operations (i.e., gWRITE, gMEMCPY, gCAS) as
HyperLoop and provides the same APIs, but involves backup
CPUs to handle receiving, parsing, and forwarding RDMA
messages in contrast to HyperLoop. In the rest of this section,
we call this implementation Naïve-RDMA.
6.1 Microbenchmark
We evaluate the performance of HyperLoop primitives in
terms of latency, throughput and CPU consumption com-
pared to Naïve-RDMA. We also evaluate the scalability of
HyperLoop under different replication group sizes.
Benchmark tools: We build custom latency and through-
put measurement tools for the microbenchmark. Our latency
benchmark generates 10,000 operations for each primitive
with customized message sizes and measures the comple-
tion time of each operation. The throughput benchmark for
gWRITE writes 1GB of data in total with customized message
sizes to backup nodes and we measure the total transmission
time to calculate the throughput. Also, we emulate back-
ground workloads by introducing CPU-intensive tasks using
stress-ng [42] in the testbed for HyperLoop and observe the
impacts on latency and throughput. The Naïve-RDMA how-
ever uses a pinned core for best case performance.
HyperLoop significantly reduces both average and tail
latency compared to Naïve-RDMA: Figure 8 shows the
average and tail latency of gWRITE and gMEMCPY primi-
tives with different message sizes, fixing replication group
size (number of member nodes) to 3. For both of gWRITE
and gMEMCPY, Naïve-RDMA shows much higher 99th per-
centile latency than HyperLoop. Particularly, for gWRITE,
we can see that with HyperLoop, 99th percentile latency can
be reduced by up to 801.8× with HyperLoop. gMEMCPY
shows a similar result; HyperLoop reduces the 99th per-
centile latency by up to 848× compared to Naïve-RDMA. Ta-
ble 2 shows the latency statistics of gCAS, in which HyperLoop
shortens the average latency by 53.9× and 95th and 99th la-
tencies by 302.2× and 849×, respectively.
HyperLoop achieves high throughput with almost zero
CPU usage: Figure 9 presents the operation throughput and
CPU utilization under different message sizes, fixing repli-
cation group size to 3. While HyperLoop provides a similar
throughput compared to Naïve-RDMA, almost no CPUs are
Naïve-RDMA-Throughput
Naïve-RDMA-CPU
d
n
o
c
e
s
/
s
p
o
K
1,000
500
0
1K
HyperLoop-Throughput
HyperLoop-CPU
100
50
0
16K 32K 64K
)
%
(
n
o
i
t
a
z
i
l
i
t
u
U
P
C
2K
4K
8K
Message size (bytes)
Figure 9: Throughput and critical path CPU consumption of
gWRITE compared to Naïve-RDMA.
Group size: 3
Group size: 5
Group size: 7
)
s
µ
(
y
c
n
e
t
a
L
105
103
101
128 256 512 1K 2K 4K 8K
128 256 512 1K 2K 4K 8K
Message size (bytes)
Message size (bytes)
(a) Naïve-RDMA
(b) HyperLoop
Figure 10: 99th percentile latency of gWRITE with different
group sizes compared to Naïve-RDMA.
consumed in the critical path of operations in contrast to
Naïve-RDMA which utilizes a whole CPU core. This is be-
cause CPUs are involved in polling NICs, receiving, parsing
and forwarding messages in Naïve-RDMA while HyperLoop
offloads all these processes to the NICs.
HyperLoop is scalable with increasing group size: We
evaluate the latency with different replication group sizes.
The latency is measured from a client that sends a ping into
the chain. Figure 10 illustrates the 99th percentile latency of
gWRITE when group size is 3, 5, and 7. As shown previously,
Naïve-RDMA incurs much higher tail latency in all group