 请求在那个 Pod 上部署（权限验证）。
 Core 计算 Pod 中资源是否满足上线需求（CPU 申明 * 上线数
目，当然这其中算法就复杂了，并不是一个简单乘的关系）。
 足够的话开始锁定 CPU 资源，调度 Host 上的 Docker Daemon
开始部署。
这个 By Core 的模型当然也会带来一些浪费，比如对一些不重要
的业务。
因此我们加入了一个 Public Server 的机制，不对机器的 CPU 等
资源做绑定，只从宏观的 Host 资源方面做监控和限制。使得 Eru
本身可以对服务进行降级操作，目前我们主要用 Public Server
来跑单元测试和镜像打包。
服务发现和安全
上线完容器后，那么接下来要考虑的就是服务发现和安全问题
了，我们把控制权交给了业务方和运维部门。一般情况下同类
高可用架构 32
Container 将会在同一个子网之中（就是依靠 SDN 的网络二层隔
离，一组 Container 理论上都会在一个或者多个同类子网中），调
用者接入子网即可调用这些 Container。同时我们也把防火墙策略
放到了二层上，保证其入口流量安全。因而整体上，对于业务部门
而言，服务基本上说一个完整的黑箱（组件），他们并不需要关心
服务的部署细节和分布情况，他们看到的是一组 IP（ 当然使用内网
DNS 的话会更加透明），同一子网内才有访问权限，直接调用就完
了。我们认为一个自建子网内部是安全的。
另外我们基于 Dnscache 和 Skydns 构建了可以实时生效的内网
DNS 体系，分别部署在了我们现有的三个机房里面。业务方可以
自行定义域名用来描述这个服务（其实也是 Eru App），完全不需
要关心服务背后的物理链路物理机器等，实现了线上的大和谐。
举个例子
目前我们 Redis Cluster 有 400个 instance，10个集群，按照
传统方式部署。每一次业务需求到我们这边之后我们需要针对业务
需求调配服务器，初始化安装环境，并做 instance 部署的操作。
在 我 们 完 成 Redis instance Dockerize 之 后，Redis Cluster
Administrator 只需要调取 API biu 一个最小集群，交付子网入
口 IP 即可（就是我们的 Proxy 地址）。遇到容量不足则会有对应
的 Redis Monitor 来自动调用 Eru API 扩容，如果过于清闲也能
非常方便的去缩容。现在已经实现了秒级可靠的 Redis 服务响应
和支撑。
高可用架构 33
此外我们另一个服务也打算基于这一套平台来解决自动扩容问题。
通过 Eru 的 Broadcasting 机制结合 Openresty 的 lua 脚本动
态的更新服务的 Upstream 列表，从而使得我们这样平时 500
QPS 峰值 150K QPS 的业务不再需要预热和准备工作，实现了
无人值守。
总结
总的来说，我们整个 Docker 调度和编排平台项目 Eru 的设计思
路是以组合为主，依托于现有的 Redis 解决方案，通过“消息”把
各个组件串了起来，从而使得整个平台的扩展性和自由度达到我们
的需求。除了一些特定的方法，比如构建 Image，其他的诸如构
建 Dockerfile，如何启动应用等，我们均不做强一致性的范式去
规范业务方/服务方怎么去做，当然这和我们公司本身体系架构有关，
主要还是为了减少落地成本。毕竟不是每个公司业务线都有能力和
眼界能接受和跟上。
最后我们现在主要在搞 Redis instance Dockerize 这么一件事，
又在尝试把大数据组 Yarn task executor docker 化。在这个过
程中我们搞定了 sysctl 的参数生效，容器内权限管理等问题，那
又是另外一个故事了……我们计划今年年末之前，业务/服务/离
线计算 3个方向，都会开始通过 Eru 这个项目构建的平台开始
Docker 化调度和部署，并对基于此实现一个 PaaS。
P.S. 所有代码均公开在了 github.com/HunanTV 里面，欢迎大
家围观。■
高可用架构 34
Q&A
Q1：首先是已有平台迁移到Docker过程中，有没有遇到
过阻力，应用适配成本高么，能否分享下典型问题和阻力？
记得我说过 NBE 第一代就是因为完整闭环落地困难所以我们才决
定做 Eru 的吧。我们是在14年开始做这件事的，当时对 Docker
的看法其实还不是很成熟。一方面业务方有很多的顾虑，另一方面
我们是 AWS 大客户了，为毛要用 Docker，直接虚机起啊。
然后呢，NBE 第一代是一个纯种 PaaS 去做的，那么自然有强制
性的范式和规则要求业务方遵守，其中我这边因为 DAE 带来的一
些经验，比较推崇与服务拆分和微服务化。但业务方觉得我流量现
在都快撑不住了，还拆分，所以很多那种一份代码按照启动命令不
同来实现线上角色的切换。其实整体上 NBE 第一代只需要增加一
个 App.yaml 就能使得大部分业务直接 Docker 化。
但是就是因为我们两方在这个业务代码角色和拆分上有重大矛盾，
导致落地阻力非常大。以至于我本组的人都直接参与业务组开发里
面去了。最后总结到这写现状之后，我们得出这么几个结论：
 尽可能的先满足业务，再推动重构（Eru 支持一份代码多个角色）。
 尽可能的降低自身平台耦合，服务发现安全交给上层去做（Eru
的消息广播机制）。
 对于新技术的落地，不要先从制定规范开始做起，尽可能的猥琐
的勾引他们落地后再去制定规范（目前平台架构部基于 Eru 在做
芒果TV 自己的 PaaS）。
高可用架构 35
Q2： Docker平台上有没有推荐的监控系统，监控数据存
储中InfluxDB上面，有没有遇到过坑？
cAdvisor 是 Google 出的一个监控 Agent，我们瞄了一眼代码后
决定写到自己的 Agent 中整合进去。说到这个其实技术细节和有
意思的事情就多了，两周前我还在看 libcontainer 的代码。
首先，cAdvisor 早期的实现里面，是通过 libcontainer 中的一个
struct 读取的 container 基础信息。但是，libcontainer 经过一
次重构之后，那个 struct 没了……所以 cAdvisor 自行维护了一
个版本的 libcontainer。
之前，我翻代码之后，认为 libcontainer.cgroups/fs 下面的
Manager 可以来做这件事件。但是会出问题，如果直接调用
libcontainer/cgourps/fs 下的 Manager 的话，会产生一个新的
cgroups profile，覆盖掉通过 Docker api 启动 container 的配
置，导致某些设备不可读，举个例子 /dev/urandom 变为不可读
状态，影响某些语言中的 random 包。
所以，目前我们自己的实现是直接通过 libcontainer 载入 /var/
lib/docker/execute/native 这个目录，直接读取容器信息后找
到这些 cgroups 状态文件来生成 influxdb 所需要的数据。
说到 InfluxDB 我觉得可以开一个吐槽大会了……InfluxDB 0.88
目前可以找到的最后一个 stable 版本，集群功能基本是废的，同
时会有内存泄露和丢数据的问题……而且我们还修过他们 API 的
高可用架构 36
一些边界条件问题，但是发到 InfluxDB组之后他们要我们不要
管了，直接等 0.9。然而……InfluxDB 的官网本来写的是 0.9
stable将会在4月发布……现在已经到了 coming soon，同时
master 里面的 rc 已经到了35还是多少来着了……对于 0.9 rc
而言，数据格式聚合函数和 0.88 已经有了很大的不同，举个例子，
derivative 这个聚合函数也就是前几天才合入的。并且 rc 之间的
落到磁盘数据并不通用，因此我们经常遇到升级后 influxdb 无法
启动的问题，只好清理数据。
目前因为实现问题，我们在暂时还是用 InfluxDB 但只保证一周数
据有效性（其实如果不升级可以保持很久）。同时我们在考虑第二方案，
就是我前同事 laiwei 来总团队在小米大规模铺的 open-falcon
方案。
Q3：申请碎片核，对性能是否有影响相对于整数核？
对于这个问题，其实 cgroups 是这样的一个逻辑；假设一个
container 有3个 CPU，其中一个共享核设定了 20% 的使用量，
那么在共享核，我们假设是 0 号核吧，没有其他 container 绑定
的时候，这个 container 可以近似的看成绑定了 3个核。它可以吃
满 0 号核 100% 的用量，但是一旦 0 号还让其他4个 container
绑定后，只要在高峰期，那么它只能最多吃满 20%。等于就是
说对于这个 container 而言，0号核的资源是弹性的，最少能保
证 20%。有一篇测试的文章，我给翻一下 https://goldmann.pl/
blog/2014/09/11/resource-management-in-docker/。
高可用架构 37
Q4：选择aws而非阿里，可否分享一下原因 ？
其实我不是运维部的，这个问题其实没那么简单，我们在役的公有
云有2家：AWS 和 Azure。接洽过的有2家，QingCloud 和阿
里云。选择 AWS，其实最大一个原因公司高层的看法是要做中国
的 Netflix。其实这很好理解，因此比较看重未来对海外的扩张。
另外一点是综合性能和价格等多个维度上，EC2 是一个比较不错
的选择，前提是对于大客户。
Q5：Redis自动扩容，缩容，依据什么来判定？是业务方
来控制，还是调度系统自己判定？
Redis 本身会提供很多监控信息，通过 info 命令即可，我们的
proxy 也实现了类似的原语，redis ctl daemon 通过它将整合后
的集群信息发送到了 influxdb。monitor 会通过这些信息来决定
是否调用 core 的 api 上新的 redis instance 并在部署完毕后通
知 redis-ctl 把 instance 配置好加入到集群中。举个简单的例子：
info 可以拿到 instance 现在使用内存量和cpu使用率，那么集群
所有 instance 使用内存量接近设定上限（现在是1G/500M一个）
的时候，monitor 就会开始做这件事情。
业务方对我们集群没多大的控制权，他们只需要提出申请即可。
Q6：可以稍微介绍下芒果TV的业务么，对芒果台很熟，
但对你们这个平台支撑的业务不清楚。
芒果TV 现在主要覆盖了3条线。
高可用架构 38
第一条线是湖南本地的 IPTV 内容，俗称 OTT 线，这一条线和传
统互联网企业不一样的在于，拥有XXXXW真金白银的付费用户。
第二条线是内容产出，作为广电旗下的一个互联网企业，依托于自
己的资源（广电的资源）。
第三条线就是网站线，因为独播策略内容为王，我们现在主要承
担湖南卫视所有节目的互联网渠道转播工作。同时，我们另辟蹊
径，在互联网直播技术上应该也是往前走了一大步，比如前几天的
billboard，全球同步直播。比如跨年晚会，五机位自由选择视角
互联网直播等。
Q7：启用Docker后，原有AWS的EC2主机有没有减少？
其实 EC2 主机减少和启用 Docker 没太多关系。我们目前平台大
多数是在我们自己的机房中的。我们 EC2 也真的减少了，但是相
信我，能做到这样绝对不是架构的问题，而是程序问题。至于有没
有估算过资源利用率提升了多少，从 Redis 集群利用率来看，不
太好估算。因为什么呢，以前是业务方说我需要15w QPS，那我
们就按照 Redis Cluster 性能曲线开了一堆 instance 去支撑这个
业务。
说回这个 Redis，那么业务方实际上能达到多少呢？即便是跨年
演唱会，我们的峰值也没过9w QPS，等于就是说大多数 redis
instance 是被浪费掉的。我们采取 Docker 之后，资源利用率是
上升了的，具体多少就没估算了。对于上面那个例子，我们会采取
给予一个基础性能的集群，让其自动扩容，满足业务需求，而不
高可用架构 39
是一开始就给一个能撑住 15W QPS 的集群。那么多出来的资源，
就给其他业务了。毕竟预先估算和实际还是有差距的。
Q8：如何做到应用和配置分离的，同一份代码，在测试
和产品上用不同的配置？
我们现在没做 UI，不过大家可以试想一下一个应用部署页面，应
用需要选择运行时资源，网络，CPU/MEM（就像一个滑动条在拖
动），以及启动的入口命令。选择的资源将会以 ENV 的形式写入
到 container 中，所以是一种组合搭配的节奏，项目并不会去指
定资源，而资源当然也是可以自定义的，就像买车，你可以定制座