nation remains challenging.
2.3 Key idea: Reference events
Our key idea is to use a reference event to improve the di-
agnosis. A good reference event is one that a) is as similar
as possible to the faulty event that is being diagnosed, but
b) unlike that event, has produced the “correct” outcome.
Since the reference event reﬂects the operator’s expectations
of what the buggy network ought to have done, we rely on
the operator to supply it together with the faulty event.
The purpose of the reference event is to show the debug-
ger which parts of the provenance are actually relevant to
the problem at hand. If the provenance of the faulty event
and the reference event have vertexes in common, these ver-
texes cannot be related to the root cause and can therefore be
pruned without losing information. If the reference event is
sufﬁciently similar to the faulty event, it is likely that almost
all of the vertexes in their provenances will be shared, and
that only very few will be different. Thus, the operator can
focus only on those vertexes, which must include the actual
root cause.
For illustration, we show the provenance of the reference
packet P from our scenario in Figure 2(c). There are quite
a few shared vertexes (shown in green), but perhaps not as
many as one might have expected. This is because of an
additional complication that we discuss in Section 2.5.
2.4 Are references typically available?
To understand whether reference events are typically avail-
able in practical diagnostic scenarios, we reviewed the posts
on the Outages mailing list from 09/2014–12/2014. There
are 89 posts in total, and 64 of them are related to network
diagnosis.
(The others are either irrelevant, such as com-
plaints about a particular iOS version, or are lacking infor-
mation that is needed to formulate a diagnosis, such as a
news report saying that a cable was vandalized.) We found
that 45 of the 64 diagnostic scenarios (70.3%) contain both
a fault and at least one reference event; however, in ten of
the 45 scenarios, the reference event occurred in another ad-
ministrative domain, so we cannot be sure that the operator
would have had access to the corresponding diagnostic data.
Nevertheless, even if we ignore these ten events, this leaves
us with 35 out of 64 scenarios (or slightly more than half) in
which a reference event would have been available.
We further classiﬁed the 45 scenarios into three categories:
partial failures, sudden failures, and intermittent failures. The
most prevalent problems were partial failures, where oper-
ators observed functional and failed installations of a ser-
vice at the same time. For instance, one thread reported
that a batch of DNS servers contained expired entries, while
records on other servers were up to date. Another class
of problems were sudden failures, where operators reported
the failure of a service that had been working correctly ear-
lier. For instance, an operator asked why a service’s status
suddenly changed from “Service OK” to “Internal Server
Error”. The rest were intermittent failures, where a ser-
vice was experiencing instability but was not rendered com-
pletely useless. For instance, one post said that diagnostic
queries sometimes succeeded, sometimes failed silently, and
sometimes took an extremely long time.
In most of the scenarios we examined, the reference event
could have been found in one of two ways: either a) by tak-
ing the malfunctioning system and looking back in time for
an instance where that same system was still working cor-
rectly, or b) by looking for a different system or service that
coexists with the malfunctioning system but has not been
affected by the problem. Although our survey is far from
universal, these strategies are quite general and should be
applicable in many other scenarios.
2.5 Why not compare the trees directly?
Intuitively, it may seem that the differences between two
provenance trees could be found with a conventional tree
comparison algorithm – e.g., some variant of tree edit dis-
tance algorithms [5] – or perhaps simply by comparing the
trees vertex by vertex and picking out the different ones.
However, there are at least two reasons why this would not
work well. The ﬁrst is that the trees will inevitably differ
in some details, such as timestamps, packet headers, packet
payloads, etc. These details are rarely relevant for root cause
analysis, but a tree comparison algorithm would nevertheless
try to align the trees perfectly, and thus report differences al-
most everywhere. Thus, an equivalence relation is needed to
mask small differences that are not likely to be relevant.
Second, and perhaps more importantly, small differences
in the leaves (such as forwarding a packet to port #1 in-
stead of port #2) can create a “butterﬂy effect” that results
in wildly different provenances higher up in the tree. For in-
stance, the packet may now traverse different switches and
match different ﬂow entries that in turn depend on differ-
ent conﬁguration states, etc. This is the reason why the two
provenances in Figures 2b and 2c still have considerable dif-
ferences: the former has 201 vertexes and the latter 156, but
the naïve “diff” has as many as 278 – even though the root
cause is only a single vertex! Thus, a naïve diff may actu-
ally be larger than the underlying provenances, which com-
pletely nulliﬁes the advantage from the reference events.
2.6 Approach: Differential provenance
Differential provenance takes a fundamentally different ap-
proach to identifying the relevant differences between two
provenance trees. We exploit the fact that a) each provenance
describes a particular sequence of events in the network, and
that b) given an initial state of the network, the sequence of
events that unfolds is largely deterministic. For instance, if
we inject two packets with identical headers into the network
at the same point, and if the state of the switches is the same
in each case, then the packets will (typically) travel along
the same path and cause the same sequence of events in the
network. This allows us to predict what the rest of the prove-
nance would have been if some vertex in the provenance tree
had been different in some particular way.
This enables the following three-step approach for com-
paring provenance trees: First, we locate a pair of “seed”
vertexes that triggered the diagnostic event and the refer-
ence event. We then conceptually “roll back” the state of
the network to the corresponding point, make a change that
transforms some “bad” vertex into a good one, and then “roll
forward” the network again while keeping track of the new
provenance along the way. Thus, the provenance tree for the
diagnostic event will become more and more like the prove-
nance tree for the reference event. Eventually, the two trees
are equivalent. At this point we output the set of changes (or
perhaps only one change!) that transformed the one tree into
the other; this is our estimate of the “root cause”.
3. DIFFERENTIAL PROVENANCE
In this section, we introduce the concept of differential prove-
nance. For ease of exposition, we adopt a declarative system
model that is commonly used in database systems when rea-
soning about provenance. This model describes a system’s
states as tuples, and its algorithm as derivation rules that
process the tuples. The key advantage of using this model is
that provenance is very easy to see in the syntax. Although
one can directly program with such rules and then compile
them into an executable [18], few deployed systems are writ-
ten that way today. However, DiffProv is not speciﬁc to the
declarative model: in Section 5, we describe several ways
in which rules and tuples can be extracted from systems that
are written in other languages, and our prototype debugger
has a front-end that accepts SDN programs that are written
in Pyretic [21], an imperative language.
3.1 System model
We assume that the system that is being diagnosed consists
of multiple nodes that run a distributed protocol, or a com-
bination of protocols. System states and events are repre-
sented as tuples, which are organized into tables. For in-
stance, the model for an SDN switch would have a table
called FlowEntry, where each row encodes an OpenFlow
rule and each column encodes a speciﬁc attribute of it, e.g.,
incoming port (in_port), match ﬁelds (nw_dst), actions
(actions), and others. As a simpliﬁed example, a tuple
FlowEntry(5,8,1.2.3.4) may indicate that packets
with destination IP 1.2.3.4 that arrive on port 5 should be
sent out on port 8.
The algorithm of the system is described by a set of deriva-
tion rules, which encodes how tuples could be derived when
and where. External events to the system, such as incoming
packets, are modeled as base tuples. Whenever a base tu-
ple arrives, it will trigger a set of derivation rules and cause
new derived tuples to appear; the derived tuples may in turn
trigger more rules and produce other derived tuples. Rules
have the form A :- B,C,..., which means that a tuple
A will be derived whenever tuples B,C,... are present;
for instance, the model for an SDN switch would have a
rule that derives PacketOut tuples from PacketIn and
FlowEntry tuples. Rules can also specify tuple locations
using the @ symbol to encode a distributed operation: for in-
stance, A(i,j)@X :- B(i)@X,C(j)@Y indicates that
an A(i,j) tuple should be derived on node X whenever a)
node X has a B(i) tuple and b) node Y has a C(j) tuple.
Here, i and j are variables of certain types, e.g., IP ranges,
switch ports, etc.
The provenance system observes how the primary system
runs, keeps track of its derivation chains, and uses them to
explain why a particular system event occurred. The prove-
nance of a tuple is very easy to explain in terms of the deriva-
tion rules: a base tuple’s provenance is itself, since it cannot
be explained further; a derived tuple’s provenance consists
of the rule(s) that have been used to derive it, as well as the
tuples used by the rule(s). For instance, if a tuple A was
derived using some rule A :- B,C,D, then A exists sim-
ply because tuples B, C, and D also exist. Without loss of
generality, we model tuple deletions as insertions of special
“delete” tuples; this results in an append-only maintenance
of the provenance graph.
3.2 The provenance graph
There are different ways to deﬁne provenance, and our ap-
proach does not depend on the speciﬁc details. For concrete-
ness, we will use a simpliﬁed version of the temporal prove-
nance graph from [35]. We chose this graph because its
temporal dimension enables the graph to “remember” past
events; this is useful, e.g., when the reference event is some-
thing that happened in the past. The graph from [35] consists
of the following seven vertex types:
• INSERT(n, τ, t), DELETE(n, τ, t): Base tuple τ was in-
serted (deleted) on node n at time t;
• EXIST(n, τ, [t1, t2]): Tuple τ existed on node n from
time t1 to t2;
• DERIVE(n, τ, R, t), UNDERIVE(n, τ, R, t): Tuple τ was
derived (underived) via rule R on n at time t;
• APPEAR(n, τ, t), DISAPPEAR(n, τ, t): Tuple τ appeared
(disappeared) on node n at time t;
The provenance graph is built incrementally at runtime. When
a base tuple is inserted, this causes an INSERT to be added to
the graph, followed by an APPEAR (to reﬂect the fact that a
new tuple appeared), and ﬁnally an EXIST (to reﬂect that the
tuple now exists in the system). Having three separate ver-
texes may seem redundant, but will be useful later – for ex-
ample, when DiffProv must ﬁnd tuples that “appeared” last.
If the appearance of a tuple triggers a derivation via a rule,
a DERIVE vertex is added to the graph. The remaining three
“negative” vertexes (DELETE, UNDERIVE, and DISAPPEAR)
are analogous to their positive counterparts.
3.3 Towards a deﬁnition
We are now ready to formalize the problem we have moti-
vated in Section 2. For clarity, we start with the following
informal deﬁnition (which we then reﬁne in several steps):
DEFINITION ATTEMPT 1. Given a “good” provenance tree
TG with root vertex vG and a “bad” provenance tree TB
with root vertex vB, differential provenance is the reason
why the two trees are not the same.
More precisely, we adopt a counterfactual approach to deﬁne
“the reason”: although the actual provenance of vG is clearly
different from that of vB, we can look for changes to the
system that would have caused the provenances to be the
same. For instance, in the example from Section 2, the actual
reason why the packets P and P ′ were routed differently was
an overly speciﬁc ﬂow entry; by changing that ﬂow entry
into a more general one, we can cause the two packets to
take the same path. Since any change can be captured by
a combination of changes to base tuples, we can restate our
goal as ﬁnding some set ∆B→G of changes to base tuples
that would transform the “bad” tree into the “good” one.
Reﬁnement #1 (Mutability): Importantly, not all changes
to base tuples make sense in practice. For instance, in our
SDN example, it is perfectly reasonable to change base tu-
ples that represent conﬁguration states, but it is not reason-
able to change base tuples that represent incoming packets,
since the operator has no control over the kinds of packets
that arrive at her border router. Thus, we distinguish between
mutable and immutable base tuples, and we do not consider
changes that involve the latter. (Note that this restriction im-
plies that a solution does not always exist.) We thus arrive at
our next attempt:
DEFINITION ATTEMPT 2. Given two provenance trees TG
and TB, their differential provenance is a set of changes
∆B→G to mutable tuples that transforms TB into TG.
Reﬁnement #2 (Preservation of seeds): Even when restric-
ted to mutable tuples, the above deﬁnition is not quite right,
because we are not looking to transform TB into TG ver-
batim: this contradicts our intuition that TB is about a dif-
ferent event, and that a meaningful solution must preserve
the events whose provenance the trees represent. To formal-
ize this notion, we designate one leaf tuple in each tree as
the seed of that tree, to reﬂect that the tree has “sprung”
from that event, and we require that the seeds be preserved
while the trees are being aligned. To identify the seed, ob-
serve that, whenever a tuple A is derived through some rule
A:-B,C,D,..., one of the underlying tuples B, C, D, ...
was the last one to appear and thus has “triggered” the deriva-
tion. Thus, we can follow the chain of triggers from the root
to exactly one of the leaves, which, in a sense, triggered the
entire tree.
Reﬁnement #3 (Equivalence): If the changes to TB must
preserve its seed, the question arises how the two trees could
ever be “the same” if their seeds are different. Therefore,
we need a notion of equivalence. For instance, suppose that
pkt(1.2.3.4,80,X) and pkt(1.2.3.5,80,Y) are
the seeds, representing two HTTP packets for two different
interfaces of the same server. Then, when aligning the two
trees, we must account for the fact that the IP addresses and
payloads are different. In simple cases, this might simply
mean that all the occurrences of 1.2.3.4 in TG are re-
placed with 1.2.3.5 in TB, but there are more compli-
cated cases – e.g., when the controller program computes
different ﬂow entries for the two IPs, perhaps even with dif-
ferent functions. We will discuss this more in Section 4.3.
With these reﬁnements, we arrive at our ﬁnal deﬁnition:
function DIFFPROV(TG, TB)
sG ← FINDSEED(TG)
sB ← FINDSEED(TB)
if sG 6≃ sB then FAIL
∆B→G ← ∅