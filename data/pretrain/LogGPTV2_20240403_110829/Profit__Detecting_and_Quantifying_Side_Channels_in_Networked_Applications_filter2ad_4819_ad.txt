4) Execution cost: The product of the above can spawn a large
set of inputs. For some systems, executing all inputs may
be costly. Running time vs. coverage is a classic trade-off.
For all the experiments presented in this paper, the inputs
were created by generalizing the example interaction scripts
that were included with the documentation of each system.
Based on the available scripts and documentation, we identiﬁed
the main degrees of freedom and strived to sweep each of
those dimensions as uniformly as possible, all while keeping
the total execution time of the Cartesian product within our
resource availability.
The size of our input suites varies from one application
to another because some applications take up to two orders
of magnitude longer than others to execute each interaction.
The number of parameters also varied from one application to
another because different applications’ inputs involve different
orthogonal degrees of freedom. Whenever multiple applica-
tions were executed for the same secret, we used the same
input suite for all of the applications.
Trace alignment parameters: When aligning biological
sequences, MSA tools can be sensitive to parameter tuning.
Our data often contains arbitrarily long unalignable regions,
so we set MAFFT to the mode recommended for that purpose
by its developers (–genafpair –maxiter 1000 –op 1.5 –ep 0.0),
and left all other parameters untouched at their default values.
Phase detection parameters: We used ω = 3 (minimum
stable phase width), ψ = 0.25 (maximum stable column
diversity), and a maximum size of up to 1000 traces for the
subset that we sent to MAFFT for alignment. For the input
suites that consist of less than 1000 traces (see Table IV),
external alignment sufﬁced. For input suites with more than
1000 traces, the traces that did not parse due to anomalies
(see Section IV-B) were always less than 1%.
Comparison with Leakiest. We have used a leakage quan-
tiﬁcation tool, Leakiest [14],
to compare to our leakage
quantiﬁcation methods. Leakiest computes mutual information
between an observable feature and a secret from a set of
samples. We provide Leakiest with the same feature-secret
pairs as in our methods. We have used Leakiest in its discrete
probability estimation mode for space features [10] and contin-
uous probability estimation for time features [13] to calculate
p(y|x) and information leakage estimates.
Histogram-based leakage parameters: We used a bin size
of 5 for space-based side-channel analyses, and of 0.001 for
time-based side-channel analyses.
Implementation details: Proﬁt comprises about 3,000 lines
of Python and 400 lines of Mathematica code. It uses Scapy [6]
for capturing network packets, Scipy [31] and Scikit-learn [39]
for computing information leakage, Matplotlib [29] for plotting
probability densities, and MAFFT [32] for trace alignment. We
used Mathematica to prototype the trace alignment module and
generate the trace alignment visualizations.
C. Experimental results
In this section, we are going to discuss our results and
explain our ﬁndings on DARPA STAC benchmark.
Comparison of different leakage estimation approaches:
Figure 10 shows the leakage results over three AIRPLAN
applications with both Gaussian and histogram-based estima-
tion with various bin sizes. In this ﬁgure, we can see that
Gaussian estimation is estimating 100%, 25% and 79% for
three AIRPLAN applications. The leakage results of histogram
estimation vary with different bin sizes, with overﬁtting taking
place in the smallest bin size and underﬁtting in the largest
bin size. Assuming the feature is sampled from a Gaussian
distribution, if we ﬁx the bin size according to one application,
it either overestimates or underestimates the leakage for other
applications. We can obtain different values of leakage by
changing the bin size; thus, the results are meaningless unless
the most accurate bin size is known in advance.
Table VI describes the leakage results obtained over all
applications with Gaussian, histogram-based estimation with
speciﬁc bin sizes and estimation using Leakiest over the
best feature that was manually found. For both AIRPLAN 2,
AIRPLAN 3 and their variants,
the calculated leakage for
all
three approaches according to the best feature is over
95% for vulnerable AIRPLAN variants and under 91% for
non-vulnerable variants. For SNAPBUDDY, both Gaussian and
histogram-based approaches reported leakage but Leakiest
reported 0% for the best feature. For some other feature, it
reported 18% leakage but that is the best result it can ﬁnd.
We attribute this result to Leakiest requiring a lot of samples
per secret to be conﬁdent of the leakage. With a low number
of samples, it underestimates the leakage. For BIDPAL and
POWERBROKER, in the variants where the vulnerability is
present, Gaussian-based estimation underestimates the leakage
and histogram-based method reports a high leakage. In variants
where the vulnerability is absent, the histogram-based report
overestimates the leakage and report over 90% leakage. We
attribute Gaussian reporting lower than expected leakage to
low amount of samples we could obtain for this application
where the estimated mean and variance is not fully accurate.
10
Leakiest reported that it could not run because of low number
of samples per secret. For all GABFEED variants and TOUR-
PLANNER, all three approaches report similar leakages.
In comparison, Leakiest works well when the number
of samples per secret is high, but we could not use it for
applications that take a long time to run, due to the number of
samples per secret being too low. For Proﬁt’s histogram-based
approach, its results are dependent on the parametrization and
it overestimates or underestimates in some cases. Gaussian-
based estimation underestimates leakage in cases with low
number of samples as well, but it is more resilient to those
cases than the other two estimation methods. For these reasons,
we have used the Gaussian-based estimation in Table VII.
Example of Proﬁt output: Table VIII shows a ranking
returned by Proﬁt, where the top-leaking features are shown
and ranked according to how much information they leak.
Comparison of best feature and top feature reported by
Proﬁt: Table VII summarizes the results returned by Proﬁt for
each group of applications associated with a particular side-
channel vulnerability. Each group begins with the vulnerable
application that was shown in Table II, followed by other
applications in which the vulnerability has been mitigated or
eliminated. For each application we show the secret leaked by
the known vulnerability and the type of the vulnerability (in
space or in time). We also show whether the vulnerability is
present or not. On the right side, we show the results returned
by Proﬁt. The Best feature column shows the manually found
best feature and the LeakG column shows the percentage
of information leakage computed by Proﬁt using Gaussian-
based probability estimation for that feature. We have chosen
Gaussian-based estimation because of the reasons described
in Section VI-C. Finally, for all applications, the Top feature
column shows the feature that appears at the top of Proﬁt’s
ranking (or the most speciﬁc one,
in the event of a tie
between features that subsume each other). We will describe
the results according to vulnerable applications and groups of
vulnerable and non-vulnerable applications using Table VII in
the following sections.
Results for vulnerable applications: In 6 out of 7 cases,
the best feature that most closely leads to the vulnerability
appeared at the very top of Proﬁt’s ranking. In all cases, it
appeared within the top-ﬁve. In all cases where the vulnera-
bility fully leaks the secret, Proﬁt computed a leakage of 95%
or more, except in the cases of BIDPAL, POWERBROKER 1,
and TOURPLANNER. For BIDPAL and POWERBROKER 1, a
larger number of samples per input would be needed in order
to compensate for the noise, but
this was hard to obtain
because both applications take several minutes per execution.
In the case of TOURPLANNER, where each sample takes very
little time, Proﬁt actually identiﬁed all four relevant time-
deltas, which appeared within the top-10 with leakages of
about 14% to 16% each. As mentioned in Section VI-A,
an even higher leakage (by no means 100%, but probably
above 50%) can be achieved by considering all four deltas
together as a multi-dimensional feature, but, as explained in
Section VII, this is beyond the abilities of the current version
of Proﬁt. Remarkably, although it only handles one feature
at a time, Proﬁt correctly inferred that the sum of the four
deltas (i.e., the total duration of the phase that isolated them)
yielded a greater leakage than any of the four separately, and
(a) AIRPLAN 2
(b) AIRPLAN 3
(c) AIRPLAN 5
Fig. 10: Information leakage comparison of Gaussian and
histogram-based entropy estimation for changing bin sizes for
three versions of the AIRPLAN application. Dashed line is
Histogram-based leakage estimation result, solid horizontal
line is Gaussian-based estimation result. Solid vertical line
shows the bin size where two estimation results meet.
reported that feature at the top of the ranking. It is also worth
noting, when looking at the Best feature column, that the phase
detection mechanism allowed Proﬁt to be very speciﬁc about
the location of the features listed at the top of its rankings.
Even in cases where the data was insufﬁcient to reach a fully
accurate quantiﬁcation of the leakage, Proﬁt was able to point
the user to the right features.
Results for groups of vulnerable and non-vulnerable ap-
plications: For all application groups we can see that, as the
vulnerability is mitigated or removed, the leakage computed
by Proﬁt decreases signiﬁcantly and in the correct relative
proportion. While we have no ﬁrm guarantee that the computed
leakages are exact (since, as stated in Section VII, they depend
on the input suite), we can observe that
they are always
consistent with the known facts about the different DARPA
STAC applications and their present and absent vulnerabilities.
Lastly, in 8 out of 13 cases, the top feature reported by Proﬁt
is indeed the best feature, and in all other cases, the top feature
reported was not signiﬁcantly higher (in rank or in leakage)
than the best one.
VII. LIMITATIONS
Quality of the proﬁling-input suite: The most important
limitation of our approach that the user should keep in mind
is that the quality of the leakage quantiﬁcations computed
11
0500100015002000020406080100HistogramBinSize%LeakageGaussianHistogram0500100015002000020406080100HistogramBinSize%LeakageGaussianHistogram0500100015002000020406080100HistogramBinSize%LeakageGaussianHistogramApplication
AIRPLAN
SNAPBUDDY
BIDPAL
GABFEED
POWERBROKER
TOURPLANNER
Description
Web-based system for management of airline routes and crew
Web-based system for image sharing with photo uploads and location tracking
Peer-to-peer system for management of multiple auctions
Web-based forum with authentication, posting, search, chat
Peer-to-peer system used by power suppliers to buy and sell energy
Client-server system that calculates optimal tours over cities
# Classes
265
338
251
115
315
321
# Methods
1,483
2,561
2,960
409
3,445
2,742
TABLE II: DARPA STAC systems used in our evaluation (summary).
Application
AIRPLAN 2
AIRPLAN 3
SNAPBUDDY 1
BIDPAL
GABFEED 1
POWERBROKER 1
TOURPLANNER
Secret
Number of cities
Strong connectivity
Location of user
Secret bid value
Server key Hamming wt.
Price offered
Places to visit
Type
Space
Space
Space
Time
Time
Time
Time
Network-level manifestation of the vulnerability (Known by DARPA)
Total size of the last HTML page sent by server after the Upload Map workﬂow
Size of the third HTML page sent by server after click on Get Map Properties
Sum of sizes of a few packets (2, 3, or 4) sent by client during Change location request
Time delta between two of the packets in a server response about bid comparison
Time delta between two packets in challenge-response authentication
Time delta between two packets in the server response about price comparison
4 timing deltas of 5 consecutive packets during travelling salesman problem calculation
TABLE III: Known network-level manifestation of each vulnerability.
Application
AIRPLAN 2, 3, 5
AIRPLAN 3, 4
SNAPBUDDY 1
BIDPAL 2, 1
GABFEED 1, 5, 2
POWERBROKER 1, 2, 4
TOURPLANNER
Secret
Number of cities
Strong connectivity
Location of user
Secret bid value
No. of 1s in server key
Price offered
Places to visit
# Different
secrets
13
2
294
49
12
49
250
# Unique
inputs
500
500
294
49
60
49
250
# Runs
per input
5
5
10
4
5
4
20
# Runs
per secret
192
1250
10
4
25
4
20
# Phases
detected
5
5
3
5
2
5
4
# Features
found
169
189
184
158
52
184
62
TABLE IV: Execution of each system. Number of phases detected and features obtained.
Application
AIRPLAN 2
AIRPLAN 3
SNAPBUDDY 1
BIDPAL 2
GABFEED 1
POWERBROKER 1
TOURPLANNER
Network-level manifestation of the vulnerability (Known by DARPA)
Total size of the last HTML page sent by server after the Upload Map workﬂow
Size of the third HTML page sent by server after click on Get Map Properties