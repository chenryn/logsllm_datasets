on the risk attitude of the organization: whether the organization is
risk averse, risk neutral, or risk seeking. The 5×5 risk matrix shown
in Table 4 of Appendix A is one instantiation of such a matrix.
The risk matrix outputs a qualitative malicious behavior risk
k ∈ K ⊆ Q. The risk matrix depends on a malicious behavior cost
(impact), and on the confidence level icf ∈ Icf ⊆ Q that the IDS
has on the intrusion (likelihood).
We define risk : Cmb×Icf → K, the function representing the risk
matrix that takes a malicious behavior cost, an intrusion confidence,
and returns the associated risk.
5.5 Policy Definition and Inputs
Having discussed the various models we rely on, we can define the
policy as a tuple of four functions ⟨rcost, rper f , mbcost, risk⟩. The
risk function is defined at the organization level, mbcost and rcost
are defined for each service depending on its context, and rper f
is constant and can be applied for any system. Hence, the most
time-consuming parameters to set are mbcost and rcost.
The function mbcost can be defined by someone that under-
stands the impact of malicious behaviors based on the service’s
context (e.g., an administrator). rcost can be defined by an expert,
5The most effective response would be to stop the service. While our model allows it,
in this paper we only mention responses that aim at maintaining the availability.
a developer of the service, or a maintainer of the OS where the ser-
vice is used, since they understand the impact of removing certain
privileges to the service. For example, some Linux distributions
provide the security policies (e.g., SELinux or AppArmor) of their
services and applications. Much like SELinux policies, rcost could
be provided this way, since the maintainers would need to test that
the response do not render a service unusable (i.e., by disabling a
core functionality).
5.6 Optimal Response Selection
We now discuss how we use our policy to select cost-sensitive
responses. Our goal is to maximize the performance of the response
while minimizing the cost to the service. We rely on known MOO
methods [43] to select the most cost-effective response, as does
other work on response selection [52, 62].
For conciseness, since we are selecting a response for a malicious
behavior m ∈ M and a service s ∈ S, we now denote rper f (r, m) as
pr , rcost(s, r) as cr , and mbcost(s, m) as cmb.
5.6.1 Overview. When the IDS triggers an alert, it provides the
confidence icf ∈ Icf of the intrusion i ∈ I and the set of malicious
behaviors Mi ⊆ M. Before selecting an optimal response, we filter
out any response that have a critical response cost from Rm (the
space of responses that can stop a malicious behavior m). Otherwise,
such responses would impact a core function of the service. We
denote ˆRm ⊆ Rm the resulting set:
[pr > pr′ ∧ cr ≤ cr′] ∨ [pr ≥ pr′ ∧ cr < cr′]
MOO methods rely on preferences to choose solutions among
the Pareto-optimal set (e.g., should we put the priority on the perfor-
mance of the response or on reducing the cost?) [43]. They rely on
a scalarization that converts a MOO problem into a SOO problem.
One common scalarization approach is the weighted sum method
that assigns a weight to each objective and compute the sum of the
product of their respective objective. However, this method is not
guaranteed to always give solutions in the Pareto-optimal set [43].
Shameli-Sendi et al. [62] decided to apply the weighted sum
method on the Pareto-optimal set instead of on the whole solution
ˆRm = { r ∈ Rm | pr < critical }
For each malicious behavior m ∈ Mi, we compute the Pareto-
optimal set from ˆRm, where we select an optimal response from.
We now describe these last steps.
5.6.2 Pareto-Optimal Set. In contrast to a Single-Objective Opti-
mization (SOO) problem, a MOO problem does not generally have
a single global solution. For instance, in our case we might not
have a response that provides both the maximum performance and
the minimum cost, because they are conflicting, but rather a set
of solutions that are defined as optimum. A common concept to
describe such solutions is Pareto optimality.
A solution is Pareto-optimal (non-dominated) if it is not possible
to find other solutions that improve one objective without weaken-
ing another one. The set of all Pareto-optimal solutions is called a
Pareto-optimal set (or Pareto front). More formally, in our context,
we say that a response is Pareto-optimal if it is non-dominated. A
response r ∈ Rm dominates a response r′ ∈ Rm, denoted r ≻ r′, if
the following is satisfied:
Survivor: A Fine-Grained Intrusion Response and Recovery Approach for Commodity Operating Systems
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
space to guarantee to have a solution in the Pareto-optimal set. We
apply the same reasoning, so we reduce our set to all non-dominated
responses. We denote the resulting Pareto-optimal set O:
O = { ri ∈ ˆRm | ∄rj ∈ ˆRm, rj ≻ ri }
5.6.3 Response Selection. Before selecting a response from the
Pareto-optimal set using use the weighted sum method, we need
to set weights, and to convert the linguistic constants, we use to
define the costs, into numerical values.
We rely on a function l that maps the linguistic constants to
a numerical value6 between 0 and 1. In our case, we convert the
constants critical, very high, high, moderate, low, very low, and
none, to respectively the value 1, 0.9, 0.8, 0.5, 0.3, 0.1, and 0.
For the weights, we use the risk k = risk(cmb, icf ) as a weight
for the performance of the response wp = l(k) which also gives us
the weight for the cost of a response wc = 1− wp. It means that we
prioritize the performance if the risk is high, while we prioritize
the cost if the risk is low.
We obtain the final optimal response by applying the weighted
sum method:
arg max
r ∈O wpl(pr) + wc(1 − l(cr))
6 IMPLEMENTATION
We implemented a Linux-based prototype by modifying several
existing projects. While our implementation relies on Linux fea-
tures such as namespaces [31], seccomp [10], or cgroups [24], our
approach does not depend on OS-specific paradigms. For example,
on Windows, one could use Integrity Mechanism [45], Restricted
Tokens [48], and Job Objects [46]. In the rest of this section, we
describe the projects we modified, why we rely on them, and the
different modifications we made to implement our prototype. You
can see in Table 1 the different projects we modified where we
added in total nearly 3600 lines of C code.
Table 1: Projects modified for our implementation
Project
CRIU
systemd
audit
user space
Linux kernel
Total
From version
3.9
239
Code added
383 lines of C
2639 lines of C
2.8.3
4.17.5
79 lines of C
460 lines of C
3561 lines of C
At the time of writing, the most common service manager on
Linux-based systems is systemd [65]. We modified it to checkpoint
and to restore services using CRIU [12] and snapper [63], and to
apply responses at the end of the restoration.
6An alternative would be to use fuzzy logic to reflect the uncertainty regarding the
risk assessment from experts when using linguistic constants [15].
6.1 Checkpoint and Restore
CRIU is a checkpoint and restore project implemented in user space
for Linux. It can checkpoint the state of an application by fetching
information about it from different kernel APIs, and then store this
information inside an image. CRIU reuses this image and other
kernel APIs to restore the application. We chose CRIU because it
allows us to perform transparent checkpointing and restoring (i.e.,
without modification or recompilation) of the services.
Snapper provides an abstraction for snapshotting filesystems
and handles multiple Linux filesystems (e.g., BTRFS [57]). It can
create a comparison between a snapshot and another one (or the
current state of the filesystem). In our implementation, we chose
BTRFS due its Copy-On-Write (COW) snapshot and comparison
features, allowing a fast snapshotting and comparison process.
When checkpointing a service, we first freeze its cgroup (i.e., we
remove the processes from the scheduling queue) to avoid incon-
sistencies. Thus, it cannot interact with other processes nor with
the filesystem. Second, we take a snapshot of the filesystem and a
snapshot of the metadata of the service kept by systemd (e.g., status
information). Third, we checkpoint the processes of the service
using CRIU. Finally, we unfreeze the service.
When restoring a service, we first kill all the processes belonging
to its cgroup. Second, we restore the metadata of the service and ask
snapper to create a read-only snapshot of the current state of the
filesystem. Then, we ask snapper to perform a comparison between
this snapshot and the snapshot taken during the checkpointing of
the service. It gives us information about which files were modified
and how. Since we want to only recover the files modified by the
monitored service, we filter the result based on our log of files
modified by this specific service (see section 6.3 for more details)
and restore the final list of files. Finally, we restore the processes
using CRIU. Before unfreezing the restored service, CRIU calls back
our function that applies the responses. We apply the responses
at the end to avoid interfering with CRIU that requires certain
privileges to restore processes.
6.2 Responses
Our implementation relies on Linux features such as namespaces,
seccomp, or cgroups, to apply responses. Here is a non-exhaustive
list of responses that we support: filesystem constraints (e.g., put
all or any part of the filesystem read-only), system call filters (e.g.,
blacklisting a list or a category of system calls), network socket
filters (e.g., deny access to a specific IP address), or resource con-
straints (e.g., CPU quotas or limit memory consumption).
We modified systemd to apply most of these responses just be-
fore unfreezing the restored service, except for system call filters.
Seccomp only allows processes to set up their own filters and pre-
vent them to modify the filters of other processes. Therefore, we
modified systemd so that when CRIU restores a process, it injects
and executes code inside the address space of the restored process
to set up our filters.
6.3 Monitoring Modified Files
The Linux auditing system [3, 29] is a standard way to trigger
events from the kernel to user space based on a set of rules. Linux
audit can trigger events when a process performs write accesses
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Chevalier et al.
on the filesystem. However, it cannot filter these events for a set of
processes corresponding to a given service (i.e., a cgroup). Hence,
we modified the kernel side of Linux audit to perform such filtering
in order to only log files modified by the monitored services. Then,
we specified a monitoring rule that relies on such filtering.
We developed a userland daemon that listens to an audit netlink
socket and processes the events generated by our monitoring rules.
Then, by parsing them, our daemon can log which files a mon-
itored service modified. To that end, we create a file hierarchy
under a per-service private directory. For example, if the service
abc.service modified the file /a/b/c/test, we create an empty
file /private/abc.service/a/b/c/test. This solution allows us
to log modified files without keeping a data structure in memory.
7 EVALUATION
We performed an experimental evaluation of our approach to an-
swer the following questions:
(1) How effective are our responses at stopping malicious be-
haviors in case a service is compromised?
(2) How effective is our approach at selecting cost-sensitive
responses that withstand an intrusion?
(3) What is the impact of our solution on the availability or
responsiveness of the services?
(4) How much overhead our solution incurs on the system re-
sources?
(5) Do services continue to function (i.e., no crash) when they
are restored with less privileges that they initially needed?
For the experiments, we installed Fedora Server 28 with the
Linux kernel 4.17.5, and we compiled the programs with GCC 8.1.1.
We ran the experiments that used live malware in a virtualized
environment to control malware propagation (see Appendix B.1
for more details). While malware could use anti-virtualization tech-
niques [8, 56], to the best of our knowledge, none of our samples
used such techniques.7 We executed the rest of the experiments
on bare metal on a computer with an AMD PRO A12-8830B R7 at
2.5 GHz, 12 GiB of RAM, and a 128 GB Intel SSD 600p Series.
Throughout the experiments, we tested our implementation
on different types of services, such as web servers (nginx [53],
Apache [2]), database (mariadb [42]), work queue (beanstalkd [7]),
message queue (mosquitto [19]), or git hosting services (gitea [21]).
It shows that our approach is applicable to a diverse set of services.
7.1 Responses Effectiveness
Our first experiments focus on how effective our responses against
distinct types of intrusions are. We are not interested, per se, in
the vulnerabilities that attackers can exploit, but on how to stop at-
tackers from performing malicious actions after they have infected
a service. Here we do not focus on response selection, which is
discussed in section 7.2.
The following list describes the malware and attacks used (see Ap-
pendix B.2 for the hashes of the malware samples):
7This is consistent with the study of Cozzi et al. [11] that showed that in the 10 548
Linux malware they studied, only 0.24 % of them tried to detect if they were in a
virtualized environment.
Linux.BitCoinMiner Cryptocurrency mining malware that con-
nects to a mining pool using attackers-controlled creden-
tials [68].
Linux.Rex.1 Malware that joins a Peer-to-peer (P2P) botnet to re-
ceive instructions to scan systems for vulnerabilities to repli-
cate itself, elevate privileges by scanning for credentials on
the machine, participate in a Distributed Denial-of-Service
(DDoS) attack, or send spam [17].
Hakai Malware that receives instructions from a Command and
Control (C&C) server to launch DDoS attacks, and to in-
fect other systems by brute forcing credentials or exploiting
vulnerabilities in routers [18, 54].
Linux.Encoder.1 Encryption ransomware that encrypts files com-
monly found on Linux servers (e.g., configuration files, or
HTML files), and other media-related files (e.g., JPG, or MP3),
while ensuring that the system can boot so that the adminis-
trator can see the ransom note [16].
GoAhead exploit Exploit that gives remote code execution to an
attacker on all versions of the GoAhead embedded web server
prior to 3.6.5 [25].
Our work does not focus on detecting intrusions but on how to
recover from and withstand them. Hence, we selected a diverse set
of malware and attacks that covered various malicious behaviors,
with different malicious behaviors.
For each experiment, we start a vulnerable service, we check-
point its state, we infect it, and we wait for the payload to execute
(e.g., encrypt files). Then, we apply our responses and we evaluate
their effectiveness. We consider the restoration successful if the
service is still functioning and its state corresponds to the one that
has been checkpointed. Finally, we consider the responses effective
if we cannot reinfect the service or if the payload cannot achieve
its goals anymore.
Table 2: Summary of the experiments that evaluate the effec-
tiveness of the responses against various malicious behav-
iors
Attack Scenario
Malicious Behavior
Per-service
Response Policy
Linux.BitCoinMiner Mine for cryptocurrency Ban mining pool IPs
Linux.BitCoinMiner Mine for cryptocurrency Reduce CPU quota
Linux.Rex.1
Hakai
Linux.Encoder.1
GoAhead exploit
GoAhead exploit
Determine C&C server
Receive data from C&C
Encrypt data
Exfiltrate via network
Data theft
Ban bootstrapping IPs
Ban C&C servers’ IPs
Read-only filesystem
Forbid connect syscall
Render paths inaccessible
The results we obtained are summarized in Table 2. In each
experiment, as expected, our solution successfully restored the
service after the intrusion to a previous safe state. In addition, as
expected, each response was able to withstand a reinfection for
its associated malicious behavior and only impacted the specific
service and not the rest of the system.
7.2 Cost-Sensitive Response Selection
Our second set of experiments focus on how effective is our ap-
proach at selecting cost-sensitive responses. We chose Gitea, a
Survivor: A Fine-Grained Intrusion Response and Recovery Approach for Commodity Operating Systems
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
self-hosted Git-repository hosting service (an open source clone of
the services provided by GitHub [22]), as a use case for a service.