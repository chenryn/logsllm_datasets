title:GAZELLE: A Low Latency Framework for Secure Neural Network Inference
author:Chiraag Juvekar and
Vinod Vaikuntanathan and
Anantha Chandrakasan
GAZELLE: A Low Latency Framework for  
Secure Neural Network Inference
Chiraag Juvekar, MIT MTL; Vinod Vaikuntanathan, MIT CSAIL;  
Anantha Chandrakasan, MIT MTL
https://www.usenix.org/conference/usenixsecurity18/presentation/juvekar
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.GAZELLE: A Low Latency Framework
for Secure Neural Network Inference
Chiraag Juvekar
MIT MTL
Vinod Vaikuntanathan
MIT CSAIL
Anantha Chandrakasan
MIT MTL
Abstract
The growing popularity of cloud-based machine learning
raises natural questions about the privacy guarantees that
can be provided in such settings. Our work tackles this
problem in the context of prediction-as-a-service wherein
a server has a convolutional neural network (CNN) trained
on its private data and wishes to provide classiﬁcations on
clients’ private images. Our goal is to build efﬁcient secure
computation protocols which allow a client to obtain the
classiﬁcation result without revealing their input to the
server, while at the same preserving the privacy of the
server’s neural network.
To this end, we design Gazelle, a scalable and low-
latency system for secure neural network inference, using
an intricate combination of homomorphic encryption and
traditional two-party computation techniques (such as gar-
bled circuits). Gazelle makes three contributions. First, we
design a homomorphic encryption library which provides
fast implementations of basic homomorphic operations
such as SIMD (single instruction multiple data) addition,
SIMD multiplication and ciphertext slot permutation. Sec-
ond, we implement homomorphic linear algebra kernels
which provide fast algorithms that map neural network lay-
ers to optimized homomorphic matrix-vector multiplica-
tion and convolution routines. Third, we design optimized
encryption switching protocols which seamlessly convert
between homomorphic and garbled circuit encodings to en-
able implementation of complete neural network inference.
We evaluate our protocols on benchmark neural net-
works trained on the MNIST and CIFAR-10 datasets and
show that Gazelle outperforms the best existing systems
such as MiniONN (ACM CCS 2017) and Chameleon
(Crypto Eprint 2017/1164) by 20–30× in online runtime.
When compared with fully homomorphic approaches like
CryptoNets (ICML 2016), we demonstrate three orders
of magnitude faster online run-time.
1 Introduction
Fueled by the massive inﬂux of data, sophisticated algo-
rithms and extensive computational resources, modern
machine learning has found surprising applications in
such diverse domains as medical diagnosis [43, 13],
facial recognition [38] and credit risk assessment [2].
We consider the setting of supervised machine learning
which proceeds in two phases: a training phase where a
labeled dataset is turned into a model, and an inference or
classiﬁcation or prediction phase where the model is used
to predict the label of a new unlabelled data point. Our
work tackles a class of complex and powerful machine
learning models, namely convolutional neural networks
(CNN) which have demonstrated better-than-human
accuracy across a variety of image classiﬁcation tasks [28].
One important use-case for machine learning models
(including CNNs) comes up in the setting of predictions-as-
a-service (PaaS). In the PaaS setting, a large organization
trains a machine learning model using its proprietary data.
The organization now wants to monetize the model by
deploying a service that allows clients to upload their
inputs and receive predictions for a price.
The ﬁrst solution that comes to mind is for the organi-
zation to make the model (in our setting, the architecture
and parameters of the CNN) freely available for public
consumption. This is undesirable for at least two reasons:
ﬁrst, once the model is given away, there is clearly no
opportunity for the organization to monetize it, potentially
removing its incentives to undergo the expensive data
curating, cleaning and training phases; and secondly, the
model, which has been trained on private organizational
data, may reveal information about users that contributed
to the dataset, violating their privacy and perhaps even
regulations such as HIPAA.
A second solution that comes to mind is for the orga-
nization to build a web service that hosts the model and
provides predictions for a small fee. However, this is also
undesirable for at least two reasons: ﬁrst, the users of such a
service will rightfully be concerned about the privacy of the
inputs they are providing to the web service; and secondly,
the organization may not even want to know the user inputs
for reasons of legal liability in case of a future data breach.
The goal of our work is to provide practical solutions
to this conundrum of secure neural network inference.
More concretely, we aim to enable the organization and
its users to interact in such a way that the user eventually
obtains the prediction (without learning the model) and the
organization obtains no information about the user’s input.
Modern cryptography provides us with many tools, such
as fully homomorphic encryption and garbled circuits, that
can help us solve this problem. A key take-away from our
work is that both techniques have their limitations; under-
standing their precise trade-offs and using a combination
of them judiciously in an application-speciﬁc manner
helps us overcome the individual limitations and achieve
substantial gains in performance. Indeed, several recent
works [30, 36, 29, 18, 32] have built systems that address
the problem of secure neural network inference using these
cryptographic tools, and our work improves on all of them.
USENIX Association
27th USENIX Security Symposium    1651
Let us begin by discussing these two techniques and
their relative merits and shortcomings.
Homomorphic Encryption. Fully Homomorphic
Encryption (FHE), is an encryption method that allows
anyone to compute an arbitrary function f on an encryption
of x, without decrypting it and without knowledge of the
private key [34, 15, 6]. Using just the encryption of x, one
can obtain an encryption of f (x). Weaker versions of FHE,
collectively called partially homomorphic encryption,
permit the computation of a subset of all functions,
typically functions that perform only additions (AHE) [31]
or functions that can be computed by depth-bounded
arithmetic circuits (LHE) [5, 4, 14]. Recent efforts,
both in theory and in practice have given us large gains
in the performance of several types of homomorphic
schemes [5, 16, 7, 21, 35, 8] allowing us to implement a
larger class of applications with better security guarantees.
The major bottleneck for these techniques, notwith-
standing these recent developments, is their computational
complexity. The computational cost of LHE, for example,
grows dramatically with the depth of the circuit that the
scheme needs to support. Indeed, the recent CryptoNets
system gives us a protocol for secure neural network
inference using LHE [18]. Largely due to its use of LHE,
CryptoNets has two shortcomings. First, they need to
change the structure of neural networks and retrain them
with special LHE-friendly non-linear activation functions
such as the square function. This has a potentially negative
effect on the accuracy of these models. Secondly, and
perhaps more importantly, even with these changes, the
computational cost is prohibitively large. For example,
on a neural network trained on the MNIST dataset, the
end-to-end latency of CryptoNets is 297.5 seconds, in
stark contrast to the 30 milliseconds end-to-end latency
of Gazelle. In spite of the use of interaction, our online
bandwidth per inference for this network is a mere 0.05MB
as opposed to the 372MB required by CryptoNets.
In contrast to the LHE scheme in CryptoNets, Gazelle
employs a much simpler packed additively homomorphic
encryption (PAHE) scheme, which we show can support
very fast matrix-vector multiplications and convolutions.
Lattice-based AHE schemes come with powerful features
such as SIMD evaluation and automorphisms (described
in detail in Section 3) which make them the ideal tools for
common linear-algebraic computations.
Secret Sharing and Garbled Circuits. Yao’s garbled
circuits [44] and the secret-sharing based Goldreich-
Micali-Wigderson (GMW) protocol [19] are two leading
methods for the task of two-party secure computation
(2PC). After three decades of theoretical and applied work
improving and optimizing these protocols, we now have
very efﬁcient implementations, e.g., [10, 9, 12, 33]. The
modern versions of these techniques have the advantage
of being computationally inexpensive, partly because they
rely on symmetric-key cryptographic primitives such as
AES and SHA and use them in a clever way [3], because
of hardware support in the form of the Intel AES-NI
instruction set, and because of techniques such as oblivious
transfer extension [27, 3] which limit the use of public-key
cryptography to an ofﬂine reusable pre-processing phase.
The major bottleneck for these techniques is their
communication complexity. Indeed, three recent works
followed the garbled circuits paradigm and designed sys-
tems for secure neural network inference: the SecureML
system [30], the MiniONN system [29], the DeepSecure
system [36].
DeepSecure uses garbled circuits alone; SecureML
uses Paillier’s AHE scheme to speed up some operations;
and MiniONN uses a weak form of lattice-based AHE
to generate “multiplication triples” similar to the SPDZ
multiparty computation framework [9]. Our key claim
is that understanding the precise trade-off point between
AHE and garbled circuit-type techniques allows us
to make optimal use of both and achieve large net
computational and communication gains. In particular, in
Gazelle, we use optimized AHE schemes in a completely
different way from MiniONN: while they employ AHE as
a pre-processing tool for generating triples, we use AHE
to dramatically speed up linear algebra directly.
For example, on a neural network trained on the CIFAR-
10 dataset, the most efﬁcient of these three protocols,
namely MiniONN, has an online bandwidth cost of 6.2GB
whereas Gazelle has an online bandwidth cost of 0.3GB. In
fact, we observe across the board a reduction of 20-80× in
the online bandwidth per inference which gets better as the
networks grow in size. In the LAN setting, this translates to
an end-to-end latency of 3.6s versus the 72s for MiniONN.
Even when comparing to systems such as Chameleon
[32] that rely on trusted third-party dealers, we observe
a 30× reduction in online run-time and 2.5× reduction in
online bandwidth, while simultaneously providing a pure
two-party solution. A more detailed performance com-
parison with all these systems, is presented in Section 8.
(F)HE or Garbled Circuits? To use (F)HE and garbled
circuits optimally, we need to understand the precise com-
putational and communication trade-offs between them.
Roughly speaking, homomorphic encryption performs
better than garbled circuits when (a) the computation has
small multiplicative depth, (ideally multiplicative depth
0 meaning that we are computing a linear function) and
(b) the boolean circuit that performs the computation has
large size, say quadratic in the input size. Matrix-vector
multiplication (namely, the operation of multiplying a
plaintext matrix with an encrypted vector) provides us
with exactly such a scenario. Furthermore, the most
time-consuming computations in a convolutional neural
network are indeed the convolutional layers (which are
1652    27th USENIX Security Symposium
USENIX Association
nothing but a special type of matrix-vector multiplication).
The non-linear computations in a CNN such as the ReLU
or MaxPool functions can be written as simple linear-size
circuits which are best computed using garbled circuits.
This analysis is the guiding philosophy that enables
the design of Gazelle (A more detailed description of
convolutional neural networks, is presented in Section 2).
Our System: The main contribution of this work is
Gazelle, a framework for secure evaluation of convolu-
tional neural networks. It consists of three components:
is the Gazelle Homomorphic
The ﬁrst component
Layer which consists of very fast implementations of
three basic homomorphic operations: SIMD addition,
SIMD scalar multiplication, and automorphisms (For a
detailed description of these operations, see Section 3).
Our innovations in this part consist of techniques for
division-free arithmetic and techniques for lazy modular
reductions. In fact, our implementation of the ﬁrst two
of these homomorphic operations is only 10-20× slower
than the corresponding operations on plaintext.
The second component is the Gazelle Linear Algebra
kernels which consists of very fast algorithms for homo-
morphic matrix-vector multiplications and homomorphic
convolutions, accompanied by matching implementations.
In terms of the basic homomorphic operations, SIMD
additions and multiplications turn out to be relatively
cheap whereas automorphisms are very expensive. At
a very high level, our innovations in this part consists of
several new algorithms for homomorphic matrix-vector
multiplication and convolutions that minimize the
expensive automorphism operations.
The third and ﬁnal component is Gazelle Network
Inference which uses a judicious combination of garbled
circuits together with our linear algebra kernels to
construct a protocol for secure neural network inference.
Our innovations in this part consist of efﬁcient protocols
that switch between secret-sharing and homomorphic
representations of the intermediate results and a novel
protocol to ensure circuit privacy.
Our protocol also hides strictly more information about
the neural network than other recent works such as the
MiniONN protocol. We refer the reader to Section 2 for
more details.
2 Secure Neural Network Inference
The goal of this section is to describe a clean abstraction
of convolutional neural networks (CNN) and set up the
secure neural inference problem that we will tackle in the
rest of the paper. A CNN takes an input and processes
it through a sequence of linear and non-linear layers in
order to classify it into one of the potential classes. An
example CNN is shown is Figure 1.
2.1 Linear Layers
The linear layers, shown in Figure 1 in red, can be of two
types: convolutional (Conv) layers or fully-connected
(FC) layers.
Convolutional Layers. We represent the input to a Conv
layer by the tuple (wi,hi,ci) where wi is the image width, hi
is the image height, and ci is the number of input channels.
In other words, the input consists of ci many wi×hi images.
The convolutional layer is then parameterized by co ﬁlter
banks each consisting of ci many fw × fh ﬁlters. This is
represented in short by the tuple ( fw, fh,ci,co). The com-
putation in a Conv layer can be better understood in terms
of simpler single-input single-output (SISO) convolutions.
Every pixel in the output of a SISO convolution is com-
puted by stepping a single fw× fh ﬁlter across the input im-
age as shown in Figure 2. The output of the full Conv layer
can then be parameterized by the tuple (wo,ho,co) which
represents co many wo×ho output images. Each of these
images is associated with a unique ﬁlter bank and is com-
puted by the following two-step process shown in Figure 2:
(i) For each of the ci ﬁlters in the associated ﬁlter bank, com-
pute a SISO convolution with the corresponding channel in
the input image, resulting in ci many intermediate images;
and (ii) summing up all these ci intermediate images.
There are two commonly used padding schemes when
performing convolutions. In the valid scheme, no input
padding is used, resulting in an output image that is smaller
than the initial input. In particular we have wo =wi− fw +1
and ho =hi− fh +1. In the same scheme, the input is zero
padded such that output image size is the same as the input.
In practice, the Conv layers sometimes also specify
an additional pair of stride parameters (sw, sh) which
denotes the granularity at which the ﬁlter is stepped. After
accounting for the strides, the output image size (wo,ho),
is given by ((cid:98)(wi − fw + 1)/sw(cid:99),(cid:98)(hi − fh + 1)/sh(cid:99)) for
valid style convolutions and ((cid:98)wi/sw(cid:99),(cid:98)hi/sh(cid:99)) for same
style convolutions.
Fully-Connected Layers. The input to a FC layer is a
vector vi of length ni and its output is a vector vo of length
no. A fully connected layer is speciﬁed by the tuple (W, b)
where W is (no×ni) weight matrix and b is an no element
bias vector. The output is speciﬁed by the following
transformation: vo =W·vi +b.
The key observation that we wish to make is that the
number of multiplications in the Conv and FC layers are
given by (wo · ho · co · fw · fh · ci) and ni · no, respectively.
This makes both the Conv and FC layer computations
quadratic in the input size. This fact guides us to use
homomorphic encryption rather than garbled circuit-based
techniques to compute the convolution and fully connected
layers, and indeed, this insight is at the heart of the much
of the speedup achieved by Gazelle.
USENIX Association
27th USENIX Security Symposium    1653
Figure 1: A CNN with two Conv layers and one FC layer. ReLU is used as the activation function and a MaxPooling layer
is added after the ﬁrst Conv layer.
2.3 Secure Inference: Problem Description
In our setting, there are two parties A and B where A holds a
convolutional neural network (CNN) and B holds an input
to the network, typically an image. We make a distinction
between the structure of the CNN which includes the
number of layers, the size of each layer, and the activation
functions applied in layer, versus the parameters of the
CNN which includes all the weights and biases that
describe the convolution and the fully connected layers.
We wish to design a protocol that A and B engage in at the
end of which B obtains the classiﬁcation result (and poten-
tially the network structure), namely the output of the ﬁnal
layer of the neural network, whereas A obtains nothing.
The Threat Model. Our threat model is the same as in
previous works, namely the SecureML, MiniONN and
DeepSecure systems and our techniques, as we argue
below, leak even less information than in these works.
To be more precise, we consider semi-honest cor-
ruptions as in [36, 29, 30], i.e., A and B adhere to the
software that describes the protocol, but attempt to infer
information about the other party’s input (the network
parameters or the image, respectively) from the protocol
transcript. We ask for the cryptographic standard of
ideal/real security [20, 19]. Two comments are in order
about this ideal functionality.
The ﬁrst is an issue speciﬁc to the ideal functionality
instantiated in this and past work, i.e., the ideal function-