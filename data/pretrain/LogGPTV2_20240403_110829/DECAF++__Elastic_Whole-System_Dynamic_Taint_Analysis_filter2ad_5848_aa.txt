title:DECAF++: Elastic Whole-System Dynamic Taint Analysis
author:Ali Davanian and
Zhenxiao Qi and
Yu Qu and
Heng Yin
DECAF++: Elastic Whole-System Dynamic Taint Analysis
Ali Davanian, Zhenxiao Qi, Yu Qu, and Heng Yin
University of California, Riverside
{adava003,zqi020,yuq, hengy}@ucr.edu
Abstract
Whole-system dynamic taint analysis has many unique appli-
cations such as malware analysis and fuzz testing. Compared
to process-level taint analysis, it offers a wider analysis scope,
a better transparency and tamper resistance. The main barrier
of applying whole-system dynamic taint analysis in practice is
the large slowdown that can be sometimes up to 30 times. Ex-
isting optimization schemes have either considerable baseline
overheads (when there is no tainted data) or speciﬁc hardware
dependencies. In this paper, we propose an elastic whole-
system dynamic taint analysis approach, and implement it in
a prototype called DECAF++. Elastic whole-system dynamic
taint analysis strives to perform taint analysis as least frequent
as possible while maintaining the precision and accuracy. Al-
though similar ideas are explored before for process-level taint
analysis, we are the ﬁrst to successfully achieve true elasticity
for whole-system taint analysis via pure software approaches.
We evaluated our prototype DECAF++ on nbench, apache
bench, and SPEC CPU2006. Under taint analysis loads, DE-
CAF++ achieves 202% speedup on nbench and 66% speedup
on apache bench. Under no taint analysis load, DECAF++
imposes only 4% overhead on SPEC CPU2006.
1
Introduction
Dynamic taint analysis (also known as dynamic information
ﬂow tracking) marks certain values in CPU registers or mem-
ory locations as tainted, and keeps track of the tainted data
propagation during the code execution. It has been applied
to solving many program analysis problems, such as mal-
ware analysis [17, 28, 29], protocol reverse engineering [5],
vulnerability signature generation [24], fuzz testing [26], etc.
Dynamic taint analysis can be implemented either at the
process level, or at the whole system level. Based on process-
level instrumentation frameworks such as Pin [19], Val-
grind [23], and StarDBT [3], process-level taint analysis tools
like LibDft [16], LIFT [25], Dytan [7] and Minemu [4] keep
track of taint propagation within a process scope. Whole-
system taint analysis tools (e.g., TaintBochs [6], DECAF [12]
and PANDA [10]) are built upon system emulators (e.g.,
Bochs [20] and QEMU [2]), and as a result can keep track of
taint propagation throughout the entire software stack, includ-
ing the OS kernel and all the running processes. Moreover,
whole-system dynamic taint analysis offers a better trans-
parency and temper resistance because code instrumentation
and analysis are completely isolated from the guest system
execution within a virtual machine; in contrast, process-level
taint analysis tools share the same memory space with the
instrumented process execution.
However, these beneﬁts come at a price of a much higher
performance penalty. For instance, the most efﬁcient imple-
mentation of whole-system taint analysis to our knowledge,
DECAF [12], incurs around 6 times overhead over QEMU
[12], which itself has another 5-10 times slowdown over the
bare-metal hardware. This overhead for tainting is paid con-
stantly no matter how much tainted data is actually propagated
in the software stack.
To mitigate such a performance degradation introduced by
dynamic taint analysis, some systems dynamically alternate
between the execution of program instructions and the taint
tracking ones [13,25]. For instance, LIFT [25] is based on the
idea of alternating execution between an original target pro-
gram (fast mode) and an instrumented version of the program
containing the taint analysis logic. Ho et al. proposed the idea
of demand emulation [13], that is, to perform taint analysis
via emulation only when there is an unsafe input.
Despite the above, there are still some unsolved problems
in this research direction. First, LIFT [25] works at the process
level, which means LIFT has the aforementioned shortcom-
ings of process level taint analysis. Moreover, LIFT still has
to pay a considerable overhead for checking registers and
the memory in the fast mode. Second, the demand emulation
approach [13] has a very high overhead in switching between
the virtualization mode and the emulation mode [13]. Third,
some optimization approaches depend on speciﬁc hardware
features for acceleration [4, 16, 25].
In this paper, we propose solutions to solve these prob-
lems, and provide a more ﬂexible and generally applicable
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 31dynamic taint analysis approach. We present DECAF++, an
enhancement of DECAF with respect to its taint analysis per-
formance based on these solutions. The essence of DECAF++
is elastic whole-system taint analysis. Elasticity, here, means
that the runtime performance of whole-system taint analysis
degrades gracefully with the increase of tainted data and taint
propagation. Unlike some prior solutions that rely on speciﬁc
hardware features for acceleration, we take a pure software
approach to improve the performance of whole-system dy-
namic taint analysis, and thus the proposed improvements are
applicable to any hardware architecture and platform.
More speciﬁcally, we propose two independent optimiza-
tions to achieve the elasticity: elastic taint status checking and
elastic taint propagation. DECAF++ elasticity is built upon
the idea that if the system is in a safe state, i.e., there is no data
from taint sources, there is no need for taint analysis as well.
Henceforth, we access the shadow memory to read the taint
statuses only when there is a chance that the data is tainted.
Similarly, we propagate the taint statuses from the source to
the destination operand only when any of the source operands
are tainted.
We implemented a prototype dubbed DECAF++ on top of
DECAF. Our introduced code is around 2.5 KLOC includ-
ing both insertions and modiﬁcations to the DECAF code.
We evaluated DECAF++ on nbench, SPEC CPU2006, and
Apache bench. When there are tainted bytes, we achieve 202%
(18% to 328%) improvement on nbench integer index, and
on average 66% improvement on apache bench in compar-
ison to DECAF. When there are no tainted bytes, on SPEC
CPU2006, our system is only 4% slower than the emulation
without instrumentation.
Contributions
butions:
In summary, we make the following contri-
• We systematically analyze the overheads of whole sys-
tem dynamic taint analysis. Our analysis identiﬁes two
main sources of slowdown for DECAF: taint status
checking incurring 2.6 times overhead, and taint propa-
gation incurring 1.8 times overhead.
• We propose an elastic whole-system dynamic taint anal-
ysis approach to reduce taint propagation and taint status
checking overhead that imposes low constant and low
transition overhead via pure software optimization.
• We implement a prototype based on elastic tainting
dubbed DECAF++ and evaluate it with three bench-
marks. Experimental results show that DECAF++ in-
curs nearly zero overhead over QEMU software emula-
tion when no tainted data is involved, and has consid-
erably lower overhead over DECAF when tainted data
is involved. The taint analysis overhead of DECAF++
decreases gracefully with the amount of tainted data,
providing the elasticity.
2 Related Work
2.1 Hardware Acceleration
Related works on taint analysis optimization focus on a single
architecture [4, 16, 25]. Henceforth, they utilize the capabili-
ties offered by the architecture and hardware to accelerate the
taint analysis. LIFT uses x86 speciﬁc LAHF/SAHF instruc-
tions to accelerate the context switch between the original
binary code and the instrumented code. Minemu uses X86
SSE registers to store the taint status of the general purpose
registers, and fails if the application itself uses these registers.
libdft uses multiple page size feature on x86 architectures to
reduce the Translation Lookaside Buffer (TLB) cache miss
for the shadow memory. In this work, we stay away from these
hardware-speciﬁc optimizations, and rely only on software
techniques to make our solution architecture agnostic.
2.2 Shadow Memory Access Optimization
Minimizing the overhead of shadow memory access is crucial
for the taint analysis performance. Most related works reduce
this overhead by creating a direct memory mapping between
the memory addresses and the shadow memory [4, 16, 25].
This kind of mapping removes the lookup time to ﬁnd the
taint status location of a given memory address. The imple-
mentation of the direct mapping requires a ﬁxed size memory
structure. This ﬁxed size structure to store the taint status
is practical only for 32-bit systems; to support every appli-
cation, such an implementation requires 32 TB of memory
space on 64 bits systems [16]. Even on 32-bit systems, the
implementation usually incurs a constant memory overhead
of around 12.5% [16]. Minemu furthers this optimization and
implements a circular memory structure that rearranges the
memory allocation of the analyzed application. The result
is that it quickly crashes for applications that have a large
memory usage [4]. In this work, we aim to follow a dynam-
ically managed shadow memory that can work not only for
applications with large memory usage but also for 64-bit ap-
plications.
In addition to the above, LIFT [25] coalesces the taint
status checks to reduce the frequency of access to the shadow
memory. To this end, LIFT needs to know ahead of time
what memory accesses are nearby or to the same location.
This requires a memory reference analysis before executing
a trace. LIFT scans the instructions in a trace and constructs
a dependency graph to perform this analysis. LIFT reports
that this optimization is application dependent (sometimes
no improvement), and depends on what percentage of time
the taint analysis is required for the application. LIFT is a
process level taint analysis tool, and in case of whole system
analysis, we expect the required taint analysis percentage for
a program to be very low in comparison to the size of the
system. Henceforth, we do not expect this optimization to
32          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationbe very useful for whole system analysis given the constant
overhead of performing memory reference analysis for the
entire system.
2.3 Decoupling
Several related works reduce the taint analysis overhead by de-
coupling taint analysis from the program execution [14,15,18,
21, 22]. ShadowReplica [14] decouples the taint analysis task
and runs it in a separate thread. TaintPipe [22] parallelizes the
taint analysis by pipelining the workload in multiple threads.
StraightTaint [21] ofﬂoads the taint analysis to an ofﬂine pro-
cess that reconstructs the execution trace and the control ﬂow.
LDX [18] performs taint analysis by mutating the source data
and watching the change in the sink. If the sink is tainted,
the change in the source would change the sink value. LDX
reduces the overhead by spawning a child process and run-
ning the analysis in the spawned process on a separate CPU
core. RAIN [15] performs on-demand dynamic information
level tracking by replaying an execution trace when there
is an anomaly in the system. RAIN reduces the overhead
by limiting the replay and the analysis to a few processes
in the system (within the information ﬂow graph) based on
a system call reachability analysis. Our work complements
these works as we aim to separate the taint analysis from the
original execution.
2.4 Elastic Tainting
Elastic taint propagation Similar ideas to elastic tainting
have been explored in the previous works [13, 25]. Qin et al.
introduced the idea of fast path optimization [25]. Fast path
optimization is based on the notion of alternating execution
between a target program and an instrumented version of
the program including the taint analysis logic. The former
is called check execution mode, and the latter is called track
execution mode. Qin et al. presented this idea for process
level taint analysis. We build upon this idea for whole system
analysis. While the intuition behind both elastic tainting and
fast optimization is the same, our work advances Qin et al.’s
work for the whole system.
Our ﬁrst novelty is that we reduce the overhead in the check
mode. LIFT [25] checks registers and memory locations of
every basic block regardless of the mode. Note that this over-
head in system level analysis is a major issue because it affects
every process (and the kernel) as we show in §3.3. We reduce
the overhead by releasing DECAF++ from checking registers
in the check mode and instead monitor the taint sources, data
from input devices or memory locations, directly. Combining
this with our low overhead taint checking, we reduce the over-
head in the check mode to nearly zero as we show in §6.4.
Our second novelty is that, unlike LIFT [25], we implement
elastic tainting in an architecture agnostic way. Meeting this
requirement while obtaining a low overhead is technically
challenging. As an example, LIFT uses a simple jump to
switch modes while such a jump in our case would panic the
CPU since a single guest instruction might break into several
host binary instructions that need to be executed atomically.
Finally, the effectiveness of elastic taint propagation for
whole system taint analysis has not been investigated before.
As we show in §6, this optimization for whole-system taint
analysis is application dependent and needs to be accompa-
nied with a taint status checking optimization. Our work is the
ﬁrst that shows the elastic property through comprehensive
evaluations, and provides a means to compare the elastic taint
propagation with elastic taint status checking.
Elastic taint status checking Ho et al. present the idea of
demand emulation [13] that has elements in common with our
elastic taint status checking. The demand emulation idea is
to perform taint analysis via emulation only when there is an
unsafe input e.g. network input in their case. Otherwise, the
system is virtually executed without extra overhead. Demand
emulation idea looks enticing because the virtualization over-
head is usually lower than emulation. However, as Ho et al.
state, the transition cost between virtualization and emulation
is quite high and possibly offsets the speedup gained through
the virtualization. In contrast, as we show in §6.4, our elastic
tainting incurs almost zero transition overhead. Further, Ho
et al. had to modify the underlying target operating system to
provide efﬁcient support for demand emulation. In contrast, in
this work, we implement elastic tainting using only emulation
without any modiﬁcations to the target systems, and show
substantial improvements in real world applications of taint
analysis.
3 Whole-System Dynamic Tainting
In this section, we introduce a basic background knowledge
on DECAF, mainly focusing on its taint analysis function-
ality related to this work. For further details on QEMU, the
underlying emulator, we refer the readers to Appendix A.
3.1 Taint Propagation
DECAF deﬁnes how instructions affect the taint status of their
operands. Going to the details of the rules for every instruction
is out of the scope of the current work; an interested reader
can refer to [27]. Just to give an idea, mov instructions in x86
result in a corresponding mov of the taint statuses from the
source to the destination (see Figure 1). What is important
about the DECAF taint propagation is that DECAF inserts a
few instructions before every Tiny Code Generator (TCG) IR
instruction that do the following:
• Read the taint status of the source operand. The taint sta-
tus depending on the operand type can be in the shadow
registers, temporary variables or in the shadow memory.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 33Figure 1: DECAF tcg instrumentation to apply tainting for
the instruction mov $0x7000, %esp. (a) shows the tcg IR after
translating the guest mov instruction, and (b) shows the tcg
IR after applying the taint analysis instrumentation.
• Decide the taint status of the destination operand based
on the instruction tainting rule. To implement the taint-
ing rule, a few TCG IRs are inserted before each IR to
propagate the taint status.
• Write the taint status of the destination operand to its
shadow variable.
3.2 Shadow Memory
DECAF stores the taint statuses of the registers and the mem-
ory addresses respectively in global variables and in the
shadow memory (allocated from heap). DECAF does not
make any assumptions about the memory and can support
any application with any memory requirements. The shadow
memory associates the taint statuses with guest physical ad-
dresses. This is a key design choice because the taint analysis
is done at the system level, and hence, virtual addresses point
to different memory addresses in different processes.
DECAF stores the taint statuses in a two-level tree data
structure. The ﬁrst level points to a particular page. The sec-
ond level stores the taint statuses for all the addresses within
a physical page. This design is based on the natural cache
design of the operating systems, and hence makes use of the
temporal and spatial locality of memory accesses.
DECAF instruments QEMU memory operations to main-
tain the shadow memory. Instrumentation is in fact on the
Tiny Code Generator (TCG) Intermediate Representation
(IR). DECAF instruments the IR instruction for memory
load, op_qemu_ld*, and the IR instruction for memory store,
op_qemu_st*. For load, DECAF loads the taint status of the
source operand of the current instruction along with the mem-