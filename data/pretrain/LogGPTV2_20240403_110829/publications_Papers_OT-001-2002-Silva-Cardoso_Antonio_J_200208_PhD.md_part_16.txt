and Kashyap 1992; Lee, Kim et al. 1993). Therefore, we rely on semantic information to
evaluate the similarity of concepts and properties that define the ST and SO interface.
This evaluation will be used to calculate their degree of integration.
4.6.1 SYNTACTIC SIMILARITY FUNCTION
The syntactic similarity of a ST and a SO is calculated with the function
SynSimilarity(ST, SO). The similarity computation relies on the SynNS(ST, SO) and
SynDS(ST, SO) functions, and the weights w and w . The functions SynNS and SynDS
1 2
are binary functions that compute the degree of similarity between two service names,
and two service descriptions, respectively. The computation is based only on syntactical
considerations, and no semantic information is taken into account at this time. Both
functions return a real value between 0 and 1, indicating the degree of syntactic
similarity. The weights w and w are real values between 0 and 1; they indicate the
1 2
degree of confidence that the designer has in the service name and service description he
supplied when constructing a ST.
w SynNS(ST.sn,SO.sn)+w SynDS(ST.sd,SO.sd)
SynSimilarty(ST,SO)= 1 2 ˛ [0..1],
w +w
1 2
and w ,w ˛ [0..1]
1 2
158
High weight values indicate the designer’s confidence in the supplied information.
For example, let consider that a user is searching for a service and supplies the service
name “Travel Agency” and a service description “Accepts a quote request for air travel.”
The user his allowed the association of a weight with the service name and with the
service description. If the user is not confident about the service description given, the
weight w can be set to a low value, for example 0.20. If the user is certain of the service
2
name given, the weight w can be set to 0.8. Please note that sum of the weights does not
1
have to add up to 1.
It is not realistic to expect that the majority of users will understand the relationship
between information confidence and weighting. In view of the fact that humans often feel
awkward in handling and interpreting such quantitative values( Tversky and Kahneman
1974), we have constructed a mapping table that establishes a correspondence between
quantitative values and a qualitative scale (Miles and Huberman 1994). Thus, instead of
explicitly specifying quantitative values, the designer can optinoally select qualitative
terms. An example of a mapping table (which can be customized) is expressed inT able
4-2.
159
Table 4-2 – Confidence Mapping Table
Qualitative Quantitative
Uncertain [0.0..0.2]
Hesitant [0.2..0.4]
Optimistic [0.4..0.6]
Confident [0.6..0.8]
Certain [0.8..1.0]
Several methods can be employed to match service names and descriptions. The
similarity of names can be defined and measured in variousw ays, including equality of
name, equality of canonical name representations after stemming and other
preprocessing, equality of synonyms, similarity of names based on common su-bstrings,
pronunciation, and soundex. Service descriptions contain comments in natural language
that express the intended semantics of a service. These comments can be evaluated
linguistically to determine the similarity between services. The linguistic analysis can be
as simple as extracting keywords from the descriptions which are used for synonym
comparison, much like names, or it could be as sophisticated as using natural language-
understanding technology to look for semantically equivalent expressions .
In our approach, we use “string-matching” as a way to calculate how closely service
names and service descriptions resemble each other. The functions SynNS(n , n ) and
1 2
SynDS(d , d ) evaluate syntactic similarity by considering the number of q-grams
1 2
(Zamora, Pollock et al. 1981; Angell, Freund et al. 1983; Salton 1988) that their
arguments have in common. To achieve a better comparison between two service
descriptions we pre-process the descriptions. A common stop list is applied to remove
common words with no information value such as “and” and “of” (Fox 1992); words are
160
also reduced to their stem by removing prefixes and suffixes (Porter 1980), and
duplicates are eliminated. Table 4-3 shows the results of two examples of calculating how
close two Web service names are.
Table 4-3 – Comparing Web service names
Service Name A Service Name B Result
“The Travel Agency” “Travel Agent” 0.87
“The Travel Agency” “An Internet Travel Agent” 0.63
We are not so much interested in introducing a clever function for syntactic
similarity, since our work focus on operational similarity, and on semantic similarity and
integration, as in showing the importance of considering syntactic information during
Web service discovery.
Another popular algorithm that may be considered to compare service names is the
edit distance formulated by Levenshtein (1966). For the service description comparison,
techniques borrowed from the information retrieval area may also be considered. For
example, the frequency-inverse document frequency (Salton 1988) weighting (TF-IDF)
has been used in the LARKS system (Sycara, Lu et al. 1998) to match heterogeneous
agents on the Internet. A very good source of information retrieval techniques can be
found in Belew (2000). There is some evidence that combining different ranking methods
to yield a new method can improve performance, possibly through capturing the best of
the different methods (Losee 1988; Hull, Pedersen et al. 1996).
161
4.6.2 OPERATIONAL SIMILARITY FUNCTION
The operational similarity of a ST and a SO is calculated with the function
OpSimilarity(ST, SO). The binary function OpSimilarity computes the geometric distance
of the QoS dimensions specified in the ST and the ones specified in the SO. The function
returns a real value between 0 and 1, indicating the similarity of the operational metrics
of its arguments. The closer to the value 1 the result is, the more similar a SO is to a ST.
OpSimilarity(ST,SO)=
3 QoSdimD(ST,SO,time)*QoSdimD(ST,SO,cost)*QoSdimD(ST,SO,reliability)
The distance of two QoS dimensions is calculated using function QoSdimD(ST, SO,
dim), where dim is a dimension. The function calculates the geometric distance of the
distance of the individual components making up the dimensiond im (i.e., the minimum,
average, and maximum value the dimension can take) of the ST and of the SO. The
distance of two dimension components is called the dimension component distance d(cd).
QoSdimD(ST,SO,dim) = 3 dcd (ST,SO,dim)*dcd (ST,SO,dim)*dcd (ST,SO,dim)
min avg max
Three dcd functions exist: dcd (ST, SO, dim), dcd (ST, SO, dim), and dcd (ST,
min avg max
SO, dim). The dcd (ST, SO, dim) is defined as follows:
min
|min(SO.qos(dim))- min(ST.qos(dim))|
dcd (ST,SO,dim)=1-
min min(ST.qos(dim))
162
The definition of the other two functions is similar; the symbol “min” should be
replaced with “avg” or “max”. The functions min, avg, and max return the minimum,
average, and maximum, respectively, of the QoS dimension specified in the argument.
Table 4-4 shows an example of how to compute the distance of two QoS dimensions
for the time dimension. The metrics shown are from the task Prepare Sample from a
genomics process (Cardoso, Miller et al. 2002). The results indicate a high similarity
between the time dimension metrics of the ST and of the SO.
Table 4-4 – Example on how to calculate the QoS distance for the time dimension
Min Avg Max
ST 190 197 199
SO 192 196 199
|192- 190| |196- 197| |199- 199|
dcd (ST, SO, time) 1- 1- 1-
x
190 197 199
188 196
QoSDimD(ST, SO, time) 3 * *1 = 0.99
190 197
4.6.3 SEMANTIC INTEGRATION
Web service integration differs from previous work on information integration due to the
number of services involved, the potential number of ontologies employed to describe
service interfaces, and the polarity of input/output schema. The polarity of schema forces
output schema to be connected to input schema. Furthermore, an input schema needs to
have all its input parameters satisfied. This is not required for an output schema.
Solutions involving a semiautomatic integration, requiring user input that defines
163
similarities between terms or semantic interrelations (Hammer, McLeod et al. 1994;
Kashyap and Sheth 1996; Bergamaschi, Castano et al. 1998) are not adequate for the
Web service integration problem. It is not realistic to expect the user to provide
information about potential mappings or semantic interrelations among terms for each
Web service object present in a registry. We desire to develop a mechanism that
automatically computes the similarity of two services, efficiently and without human
intervention, and that suggests potential mappings between a ST and a SO schema which
maximize their degree of integration, thus reducing structural and semantic heterogenetiy.
We now present our algorithm to compute the degree of integration of a ST and a
SO. This function bases its computation on the input and output parameters of both the
ST and the SO.
4.6.3.1 SEMANTIC INTEGRATION FUNCTION
The semantic integration function DIntegration(ST, SO) is a binary function that returns
the degree of integration between its operators. The operands are a service template (ST)
and a service object (SO), and the result is a real value between 0 and 1.
DIntegration(ST, SO)˛ [0..1]
The underlying goal of the function is to establish a mapping between the output of
the ST (ST.O) and the input of the SO (SO.I) and a mapping between the output of the SO
(SO.O) and the input of the ST (ST.I) that maximize the degree of integration.
Depending on the data present in a service template, four distinct cases can occur
when comparing input and output parameters. The definition of the functionD Integration
captures these four cases.
164
 P (ST.Os,SO.Is) P (SO.Os,ST.Is)
+
SO.Is ST.Is
 , ST.Os„ ˘ ,ST.Is„ ˘
 2
DIntegration(ST,SO)=
 P (ST.Os,SO.Is)/SO.Is, ST.Os„ ˘ ,ST.Is=˘
 P (SO.Os,ST.Is)/ST.Is, ST.Os=˘ ,ST.Is„ ˘
  0, ST.Os=˘ ,ST.Is=˘
The simplest case occurs when a ST does not specify any inputs or outputs. In this
case, the integration degree is evaluated to 0. If a ST only specifies a set of outputs and
no inputs, then the function P (Os, Is) is employed to compute the semantic mapping
between the outputs Os of the ST and the inputs Is of the SO. The result of applying the
function P is normalized with respect to the number of inputs being mapped. The
rationality of this normalization is that when matchingn outputs of a task a against m
inputs of a task b, we are interested in satisfying all the input requirements of task b. A
task or Web service always needs to have its mandatory inputs satisfied with data in order
to correctly carry out its intended function. Optional inputs are not taken into account.
Nevertheless, a designer may explicitly mark an optoinal input as mandatory if he wishes
optional inputs to be considered during the integration evaluation process. The same
concept is applied if the ST includes inputs but no outputs.
Finally, if a ST includes both a set of outputs and a set of inputs the mapping
function P is applied to both sets. In this case, we compute the arithmetic mean of the
normalized results from the evaluation of function P . We use the arithmetic mean
because we give the same importance to the normalized semantic mapping of the ST
outputs with the SO inputs and the normalized semantic mapping between SO outputs
with ST inputs.
165
4.6.3.2 MAPPING INPUTS AND OUTPUTS
The function P (Os, Is), where Os is a set of output parameters and Is a set of input
parameters, computes the best mapping that can be obtained from connecting the outputs
of the set Os to the inputs of set Is.
 Max(P (Os- O,Is- I)+p(O,I)), Os „ ˘ ,Is „ ˘ ,O˛ Os,I ˛ Is
P (Os,Is)= 
 0, Os =˘  Is =˘
Please note that the number of mappings established is Min(|Os|, |Is|). Each output O
of Os is matched against each input I of Is. Their semantic similarity degree is evaulated
with function p (O, I). Since input/output parameters are associated with ontological
concepts (see section 4.4.2), the function p (O, I) compares two concept classes
represented by O and I.
 SemS'(O,I), W (O)= W (I)
p(O,I) = 
 SemS''(O,I)/| p(I)|, W (O) „ W (I)
The function p (O, I) takes into consideration the ontology(ies) associated with the
concepts being compared. If the concepts are from the same ontology, i.e., W (O) = W (I),
the function SemS’(O, I) is employed to evaluate their similarity; otherwise, if they are
from distinct ontologies, i.e., W (O) „ W (I), the function SemS’’ (O, I) is used. We make
this distinction since the information available when comparing concept classes from the
same ontology has a different nature and structure which is not present when comparing
concepts from distinct ontologies. The result of function SemS’’ is normalized with
respect to the number of properties of the input concept I. As we will see, the evaluation
of the similarity of two concepts is based on their composing properties. Once again, the
166
reason for this normalization is to obtain a measure that reflects the fact that all the
mandatory input properties need to have an output property associated with them in order
for a task or Web service to work properly.
4.6.3.3 COMPARING OUTPUTS AND INPUTS FROM THE SAME ONTOLOGY
The function SemS’(O, I) evaluates the similarity of two concept classes associated with
an output (O) and an input (I), conceptualized within the same ontology. Four distinct
scenarios can occur: a) the concepts are the same (O=I), b) the concept I subsumes
concept O (O>I), c) the concept O subsumes concept I (O I
SemS'(O,I) =  | p(O)|
 , O < I
| p(I)|
 Similarity'(O,I), O „ I
In the first case, which is the simplest, if the two concepts are equal then intuitively
their similarity is maximal; therefore, it is evaluated to one. In the second case, if the
concept I subsumes the concept O, their similarity is also evaluated to 1. The similarity is
maximal since if an output represented with a concept O is a subclass of an input
represented with a concept I it has at least the same set of properties as I. Thus, all input
properties have a corresponding output property associated with them. In the third case,
the concept O subsumes the concept I (O<I). As a result, some properties of the concept I
may not have an output property associated with them. The similarity is set to the ratio of
the number of properties of concept O (represented with |p(O)|) and the number of
167
properties of concept I (|p(I)|). This ratio indicates the percentage of input properties of
the SO that are satisfied by output properties of the ST.
In the last case, the concepts O and I are not equal and do not subsume each other in
any way. In this case, assessing similarity is a judgment process that requires two
“things” to be decomposed into elements in which they are the same and into elements in
which they are different (Tversky 1977). Assessing the similarity of concepts is an
important process for systems such as information retrieval and information integration.
A number of approaches to measuring conceptual similarity between words have been
taken in the past. Tversky’s feature-based similarity model (Tversky 1977) has been
considered as the most powerful similarity model to date (Richardson and Smeaton
1995).
Tversky introduced a general feature-counting metric for similarity called the
feature-contrast model. This model is based on the idea that common features tend to
increase the perceived similarity of two concepts, while feature differences tend to
diminish perceived similarity. Tversky’s model claims that feature commonalities tend to
increase perceived similarity more than featured ifferences can diminish it. That is, when
assessing similarity we give more credence to those features that concepts have in
common than to those that distinguish them. For instance, a SUV (Sport Utility Vehicle)
and a sedan are similar by virtue of their common features, such as wheels, engine,
steering wheel, and gears, and are dissimilar by virtue of their differences, namely height
and the size of the tires. Based on Tversky’s model, we introduce a similarity function
based on the number of properties shared among two concepts c and c . Our similarity
1 2
function is defined as followed, where the function p(x) retrieves all the properties
associated with a concept a and function |s| corresponds to the number of elements in the
set s.