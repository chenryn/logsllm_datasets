likely to be victimized by scams [59].
At the same time, we observe instances of male accounts for
which attackers modiﬁed their proﬁle, while female accounts
recorded no proﬁle edits. The reason for this could be that
the attackers did not ﬁnd a proﬁtable way of monetizing these
accounts, and decided to vandalize them instead. This is in
line with previous research that showed that attackers disrupt
online resources (e.g., online accounts and online documents)
when they cannot ﬁnd a better way to exploit them [34, 42].
Key Lesson. Cybercriminals orchestrate attack activity dif-
ferently in online accounts that belong to men, women, adults,
and teens, as shown in our work. This observation is further
reinforced by the existing research literature which shows that
age, gender, and personality traits are factors that inﬂuence cy-
bercrime victimization, as previously discussed in Section 2.
In view of this, mitigation systems and interventions should
be customized along these different groups. In addition, there
is a need to evolve security systems away from defending the
“average user,” who does not really exist [24], towards adap-
tive mitigation systems that address the demographic-based
nature of groups of users.
5.3 Limitations and Future Work
Here, we highlight some limitations of our work and suggest
potential future directions. Our study articulates a number of
research hypotheses and uses statistical tests to back them up.
However, we acknowledge that our experiment only covers
the threat of account credentials leaked on paste sites, and
might not be representative of all compromises. We discussed
threats to the validity of our work in Section 3.4.
We acknowledge that our data is no longer as fresh as
it could possibly be (it was collected in 2018). To the best
of our knowledge, however, ours is the ﬁrst study exploring
demographic risk factors in Facebook accounts. While the
campaigns carried out by attackers might have since changed,
we argue that their motives are still the same and that these
demographic risk factors still hold.
Prior to the experiments, we wrote some publicly-available
data to the timelines of the test accounts and wrote no private
messages. On the other hand, real-world Facebook accounts
often contain private messages. We acknowledge that this may
affect the perception of criminals on visiting the test accounts.
In future work, we plan to incorporate private messages to
further approximate real accounts.
In the course of experiments, private messages and time-
line posts were written to some honey accounts by criminals.
We did not respond to any of them as dictated by our IRB
protocol. This may have affected the perception of the crimi-
nals: such activity in real accounts could elicit responses from
account owners. Additionally, this limited our visibility on
the attackers’ intentions, since we did not observe anything
beyond the initial messages. In the future, it would be interest-
ing to incorporate chatbots that will autorespond to messages;
this will further deepen the impression of “lived-in” accounts
(realism), but also has ethical implications.
We studied only two demographic attributes: age range
and gender. In the future, we propose investigating more at-
tributes, for instance, occupation, political leanings, and re-
ligious beliefs, among others. In addition to understanding
criminal activity in stolen accounts, such attributes may also
help the research community to investigate other problems—
especially cyberbullying and targeted attacks. Finally, to un-
derstand chain attacks, we will store authentication tokens to
other services in honey accounts, within private messages, to
observe how criminals would misuse them.
6 Conclusion
We presented the ﬁrst large-scale honeypot system for mon-
itoring compromised Facebook accounts. We created more
than 1000 realistic Facebook accounts, incorporated demo-
graphic attributes in them, and observed attacker behavior
in them, for six months. We showed that those demographic
attributes inﬂuenced the actions of attackers in the accounts
and characterized the activity of attackers in stolen social ac-
USENIX Association
30th USENIX Security Symposium    4129
counts. These ﬁndings will help the research community to
gain a deeper understanding of compromised online accounts
towards the development of better security systems.
Acknowledgments
We would like to thank the anonymous reviewers for their
comments. This work received support from a Facebook
Secure-the-Internet research gift. We would like to thank
Mark Atherton for his help during the early stages of this
work. We were partially supported by the National Science
Foundation (NSF) under Grant 1942610. Most parts of this
work were completed while Jeremiah Onaolapo was at Univer-
sity College London (UCL) with the support of the Petroleum
Technology Development Fund (PTDF) of Nigeria.
References
[1] Accessing & downloading your information. https://
www.facebook.com/help/1701730696756992. Ac-
cessed: 2020-09-18.
[2] The best free stock photos & videos shared by talented
https://www.pexels.com/. Accessed:
creators.
2020-09-18.
[3] Developer docs. https://developer.twitter.com/
en/docs. Accessed: 2020-09-18.
[4] Find your inspiration. https://www.flickr.com/.
Accessed: 2020-09-18.
[5] Googletrans: Free and unlimited Google trans-
late API for Python.
https://py-googletrans.
readthedocs.io/en/latest. Accessed: 2020-09-18.
[6] Information (on Facebook test accounts). https://www.
facebook.com/whitehat/info/. Accessed: 2020-09-
18.
[7] The Internet’s source of freely-usable images. https:
//unsplash.com/. Accessed: 2020-09-18.
[8] IP geolocation API. https://ip-api.com. Accessed:
2020-09-18.
[13] D. Alvarez-Melis and M. Saveski. Topic modeling in
Twitter: Aggregating tweets by conversations. In AAAI
Conference on Weblogs and Social Media (ICWSM),
2016.
[14] T. Barron and N. Nikiforakis. Picky attackers: Quanti-
fying the role of system properties on intruder behavior.
In Annual Computer Security Applications Conference
(ACSAC), 2017.
[15] H. Binsalleeh, T. Ormerod, A. Boukhtouta, P. Sinha,
A. Youssef, M. Debbabi, and L. Wang. On the analy-
sis of the Zeus botnet crimeware toolkit. In Privacy,
Security and Trust (PST), 2010.
[16] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ri-
peanu. The socialbot network: When bots socialize for
fame and money. In Annual Computer Security Appli-
cations Conference (ACSAC), 2011.
[17] A. M. Bossler and T. J. Holt. On-line activities, guardian-
ship, and malware infection: An examination of routine
activities theory. International Journal of Cyber Crimi-
nology, 3(1), 2009.
[18] E. Bursztein, B. Benko, D. Margolis, T. Pietraszek,
A. Archer, A. Aquino, A. Pitsillidis, and S. Savage.
Handcrafted fraud and extortion: Manual account hi-
In ACM Internet Measurement
jacking in the wild.
Conference (IMC), 2014.
[19] P. Cao, Y. Wu, S. S. Banerjee, J. Azoff, A. Withers,
Z. T. Kalbarczyk, and R. K. Iyer. CAUDIT: continuous
auditing of SSH servers to mitigate brute-force attacks.
In USENIX Symposium on Networked Systems Design
and Implementation (NSDI), 2019.
[20] J. DeBlasio, S. Savage, G. M. Voelker, and A. C. Sno-
eren. Tripwire: Inferring Internet site compromise. In
ACM Internet Measurement Conference (IMC), 2017.
[21] R. Dhamija, J. D. Tygar, and M. Hearst. Why phish-
ing works. In ACM Conference on Human Factors in
Computing Systems (CHI), 2006.
[9] nltk.stem package.
https://www.nltk.org/api/
[22] M. Duggan. Online harassment 2017. 2017.
nltk.stem.html. Accessed: 2020-09-18.
[10] nltk.tokenize package. https://www.nltk.org/api/
nltk.tokenize.html. Accessed: 2020-09-18.
[11] Random user generator. https://randomuser.me/.
Accessed: 2020-09-18.
[12] Stunning free images & royalty free stock. https://
pixabay.com/. Accessed: 2020-09-18.
[23] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna.
COMPA: Detecting compromised accounts on social
networks. In Symposium on Network and Distributed
System Security (NDSS), 2013.
[24] S. Egelman and E. Peer. The myth of the average user:
Improving privacy and security systems through indi-
vidualization. In Proceedings of the 2015 New Security
Paradigms Workshop, pages 16–28, 2015.
4130    30th USENIX Security Symposium
USENIX Association
[25] R. A. Fisher. On the interpretation of χ 2 from contin-
gency tables, and the calculation of p. Journal of the
Royal Statistical Society, 85(1):87–94, 1922.
[26] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao.
Detecting and characterizing social spam campaigns. In
ACM Internet Measurement Conference (IMC), 2010.
[27] W. G. Halfond, J. Viegas, and A. Orso. A classiﬁcation
of SQL-injection attacks and countermeasures. In IEEE
International Symposium on Secure Software Engineer-
ing, 2006.
[28] X. Han, N. Kheir, and D. Balzarotti. PhishEye: Live
monitoring of sandboxed phishing kits. In ACM Confer-
ence on Computer and Communications Security (CCS),
2016.
[29] B. Henson, B. W. Reyns, and B. S. Fisher. Does gen-
der matter in the virtual world? Examining the effect of
gender on the link between online social network activ-
ity, security and interpersonal victimization. Security
Journal, 26(4):315–330, 2013.
[30] J. Huang, G. Stringhini, and P. Yong. Quit playing games
with my heart: Understanding online dating scams. In
Detection of Intrusions and Malware, and Vulnerability
Assessment (DIMVA). 2015.
[31] J. Isacenkova, O. Thonnard, A. Costin, D. Balzarotti,
and A. Francillon. Inside the scam jungle: A closer look
at 419 scam email operations. In Security and Privacy
Workshops (SPW), 2013.
[32] A. Kedrowitsch, D. D. Yao, G. Wang, and K. Cameron.
A ﬁrst look: Using Linux containers for deceptive hon-
eypots. In Workshop on Automated Decision Making
for Active Cyber Defense, 2017.
[33] A. Kolmogorov. Sulla determinazione empirica di una
lgge di distribuzione. Inst. Ital. Attuari, Giorn., 4:83–91,
1933.
[34] M. Lazarov, J. Onaolapo, and G. Stringhini. Honey
sheets: What happens to leaked Google spreadsheets? In
USENIX Workshop on Cyber Security Experimentation
and Test (CSET), 2016.
[35] K. Lee, J. Caverlee, and S. Webb. The social honeypot
project: Protecting online communities from spammers.
In World Wide Web Conference (WWW), 2010.
[36] A. Lenhart, M. Ybarra, K. Zickuhr, and M. Price-Feeney.
Online harassment, digital abuse, and cyberstalking in
America. Data and Society Research Institute, 2016.
[37] F. L. Lévesque, J. M. Fernandez, and D. Batchelder.
Age and gender as independent risk factors for malware
victimisation. Electronic Visualisation and the Arts
(EVA 2017), pages 1–14, 2017.
[38] F. L. Lévesque, J. Nsiempba, J. M. Fernandez, S. Chias-
son, and A. Somayaji. A clinical study of risk factors
related to malware infections. In ACM Conference on
Computer and Communications Security (CCS), 2013.
[39] J. Leyden. Rockyou hack reveals easy-to-crack pass-
https://www.theregister.co.uk/2010/
words.
01/21/lame_passwords_exposed_by_rockyou_
hack/. Accessed: 2020-09-18.
[40] M. Näsi, A. Oksanen, T. Keipi, and P. Räsänen. Cyber-
crime victimization among young people: a multi-nation
study. Journal of Scandinavian Studies in Criminology
and Crime Prevention, 16(2):203–210, 2015.
[41] D. Oliveira, H. Rocha, H. Yang, D. Ellis, S. Dom-
maraju, M. Muradoglu, D. Weir, A. Soliman, T. Lin,
and N. Ebner. Dissecting spear phishing emails for
older vs young adults: On the interplay of weapons of
inﬂuence and life domains in predicting susceptibility
to phishing. In ACM Conference on Human Factors in
Computing Systems (CHI), 2017.
[42] J. Onaolapo, E. Mariconti, and G. Stringhini. What
happens after you are pwnd: Understanding the use of
leaked webmail credentials in the wild. In ACM Internet
Measurement Conference (IMC), 2016.
[43] E. M. Redmiles. “Should I Worry?” A Cross-Cultural
Examination of Account Security Incident Response. In
IEEE Symposium on Security and Privacy, 2019.
[44] C. Rossow, C. J. Dietrich, C. Grier, C. Kreibich, V. Pax-
son, N. Pohlmann, H. Bos, and M. van Steen. Prudent
practices for designing malware experiments: Status
quo and outlook. In IEEE Symposium on Security and
Privacy, 2012.
[45] S. Sheng, M. Holbrook, P. Kumaraguru, L. F. Cranor,
and J. Downs. Who falls for phish? A demographic
analysis of phishing susceptibility and effectiveness of
interventions. In ACM Conference on Human Factors
in Computing Systems (CHI), 2010.
[46] N. Smirnov. Table for estimating the goodness of ﬁt
of empirical distributions. The Annals of Mathematical
Statistics, 19(2):279–281, 1948.
[47] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert,
M. Szydlowski, R. Kemmerer, C. Kruegel, and G. Vigna.
Your botnet is my botnet: Analysis of a botnet takeover.
In ACM Conference on Computer and Communications
Security (CCS), 2009.
USENIX Association
30th USENIX Security Symposium    4131
[48] B. Stone-Gross, T. Holz, G. Stringhini, and G. Vigna.
The underground economy of spam: A botmaster’s per-
spective of coordinating large-scale spam campaigns. In
USENIX Workshop on Large-Scale Exploits and Emer-
gent Threats (LEET), 2011.
[49] G. Stringhini and O. Thonnard. That ain’t you: Block-
ing spearphishing through behavioral modelling.
In
Detection of Intrusions and Malware, and Vulnerability
Assessment (DIMVA), 2015.
[50] G. Suarez-Tangil, M. Edwards, C. Peersman, G. Stringh-
Automatically
arXiv preprint
ini, A. Rashid, and M. Whitty.
dismantling online dating fraud.
arXiv:1905.12593, 2019.
[51] K. Thomas, D. Akhave, M. Bailey, D. Boneh,
E. Burztein, S. Consolvo, N. Dell, Z. Durumeric, P. Kel-
ley, D. Kumar, D. McCoy, S. Meiklejohn, T. Ristenpart,
and G. Stringhini. SoK: Hate, harassment, and the chang-
ing landscape of online abuse. In IEEE Symposium on
Security and Privacy, 2021.
[52] K. Thomas, C. Grier, D. Song, and V. Paxson. Sus-
pended accounts in retrospect: An analysis of Twitter
spam. In ACM Internet Measurement Conference (IMC),
2011.
[54] S. G. A. van de Weijer and E. R. Leukfeldt. Big ﬁve per-
sonality traits of cybercrime victims. Cyberpsychology
Behav. Soc. Netw., 20(7):407–412, 2017.
[55] D. Wang, Z. Zhang, P. Wang, J. Yan, and X. Huang.
Targeted online password guessing: An underestimated
threat. In ACM Conference on Computer and Communi-
cations Security (CCS), 2016.
[56] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng,
and B. Y. Zhao. You are how you click: Clickstream
analysis for Sybil detection. In USENIX Security Sym-
posium, 2013.
[57] S. Webb, J. Caverlee, and C. Pu. Social honeypots:
Making friends with a spammer near you. In Conference
on Email and Anti-Spam (CEAS), 2008.
[58] M. T. Whitty. Anatomy of the online dating romance
scam. Security Journal, 28(4):443–455, 2015.
[59] M. T. Whitty. Is there a scam for everyone? Psycholog-
ically proﬁling cyberscam victims. European Journal
on Criminal Policy and Research, pages 1–11, 2020.
[60] M. T. Whitty and T. Buchanan. The online romance
scam: A serious cybercrime. CyberPsychology, Behav-
ior, and Social Networking, 15(3):181–183, 2012.
[53] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Pax-
son. Trafﬁcking fraudulent accounts: The role of the
underground market in Twitter spam and abuse.
In
USENIX Security Symposium, 2013.
[61] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and
Y. Dai. Uncovering social network Sybils in the wild.
ACM Transactions on Knowledge Discovery from Data
(TKDD), 8(1):2:1–2:29, 2014.
4132    30th USENIX Security Symposium
USENIX Association