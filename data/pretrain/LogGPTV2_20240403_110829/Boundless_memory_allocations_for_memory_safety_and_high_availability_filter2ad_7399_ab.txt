the splay tree of the corresponding partition needs to be
searched, and, consequently, the overhead is reduced. This
approach is completely orthogonal to ours; we believe it
can be merged with Boundless without major problems.
DieHard [10] uses a randomized heap to detect bound
violations probabilistically. The implementation is based on
a randomizing memory allocator. DieHard does not need
to instrument memory accesses. It detects spatial memory
errors only on the heap. Orchestra detects spatial memory
errors only on the stack [11]. We detect violations on the
heap, the stack, and the data segment.
Our FastPointer representation is similar to BaggyBounds’
implementation for x86 64 [3]. BaggyBounds uses a heuris-
tic to assign a concrete memory object to an out-of-bounds
pointer. If the out-of-bounds pointer is too far away from its
associated memory object, then BaggyBounds might falsely
associate the wrong memory object with this pointer.
SoftBound avoids meta-data look-ups by adding new
local variables and function arguments [2]. Both are used
to transport the buffer bounds in parallel with the point-
ers. For instance, a function foo(char* p), which has
a pointer argument p,
is changed to foo(char* p,
bufferBounds pBounds). In contrast, we use Fast-
Pointer to avoid meta-data look-ups without any additional
variables or arguments. Instead, we put the buffer bounds in
the unused upper 16 bits of the pointer.
Of all these approaches, DieHard is the only one that
supports arbitrary integer arithmetic on pointers. However,
DieHard detects buffer overﬂows only on the heap and only
probabilistically. The fuller the heap, the more likely it is
that DieHard misses a buffer overﬂow. Through our novel
combination of FastPointers and SlowPointers, we support
arbitrary integer arithmetic on pointers. It is common to use
integer arithmetic on pointer, e.g., to align a pointer. We
present a real world example in Section IV-B.
The fail-stop approach decreases the application’s avail-
ability. Therefore, we see the fail-stop behavior as one of
the reasons why buffer overﬂow detection is not widely
deployed. Tolerating buffer overﬂows at runtime does not
decrease the availability of the application. Thus, we believe
tolerance approaches are much more acceptable in practice
than detection-only approaches.
Tolerance
Most tolerance approaches increase the size
of an allocation to counteract overﬂows [12, 13, 14], i.e., if
a buffer overﬂow is detected on a buffer B, the next time
B is allocated its size is increased to incorporate the out-of-
bounds access. This approach has two problems:
First, it does not tolerate the buffer overﬂow that just
has been discovered. It only tolerates overﬂows that af-
fect buffers allocated after the ﬁrst detection. Some ap-
proaches [13, 14] use check-pointing and rollback to redo the
allocation and pad the memory object accordingly. However,
a rollback approach is only possible, if a checkpoint exists
from before the allocation. Even if one keeps all checkpoints,
rolling back too much into the past of an application is not
feasible in practice. Replaying hours or even minutes is just
not possible for many applications. Even worse, increasing
the allocation size of global variables forces a complete
application restart.
Second, increasing the allocation size does not ﬁx the
vulnerability. If an attacker is able to overﬂow a buffer to an
arbitrary extend, the attacker can exploited the vulnerability
multiple times. Eventually, the overﬂow offset will be too
large to allocate the object at all; the result may be perma-
nent denial-of-service. We believe increasing the allocation
size is not the right approach to achieve our goal of high
memory safety and availability.
We derived our tolerance strategy from failure oblivious
computing [15]. In failure oblivious computing, every out-
of-bounds write is ignored. For out-of-bounds reads values
are forged based on an heuristic. Instead of ignoring and
forging, we use an out-of-bounds store similar to [16]. All
out-of-bounds read and write operations are redirected to
this store. For uninitialized out-of-bounds reads, we return
zero.
Automatic Patching
In comparison to [16], we not
only use our novel overﬂow detection approach based on
the two pointer representations FastPointer and SlowPointer,
but we also apply vulnerability speciﬁc patching to speedup
tolerance even further. Vulnerability speciﬁc patching was
inspired by vulnerability speciﬁc ﬁltering [17]. Vulnerability
speciﬁc ﬁltering adds code to an application to ﬁlter input for
a given vulnerability. In contrast, we do not ﬁlter input, but
tolerate attacks targeting a given vulnerability. Vulnerability
speciﬁc patching and vulnerability speciﬁc ﬁltering share
a trade-off between security and performance overhead:
On the one hand, the needed instrumentation is minimal;
therefore, the performance overhead is also minimal. On the
other hand, every patching approach only protects against
previously discovered vulnerabilities. Collaborative vulner-
ability detection and automatic patch deployment systems
such as Vigilante [18] should be used to protect against zero-
day attacks. Patches created by Boundless can also be used
by the application developer to aid debugging and manual
patching [19].
IV. POINTER REPRESENTATION
Spatial memory errors are detected by comparing the
current memory address with the base address and the end
address of the underlying memory object. Those addresses
are necessary to verify that a pointer points into allocated
memory. Together, base and end form a meta data record.
Each meta data record must be uniquely associated with
an allocated memory object, and each pointer must be
associated with its memory object. This meta data record
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:38 UTC from IEEE Xplore.  Restrictions apply. 
16Figure 4. FastPointers carry the meta data in the spare bits. The pointers
marked 0x0005 and 0x0002 are in-bounds. The remaining two are out-
of-bounds. A FastPointer can express all in-bound pointer positions plus
pointers to the end address (0x0000). For the remaining out-of-bounds
pointer 0x0006 we resort to the SlowPointer representation.
is often stored in a meta data store, for example, a splay
tree [5, 8, 9].
We use two different pointer representations. Both repre-
sentations differ in the way they maintain meta data. The
FastPointer encodes the meta data directly into the pointer
itself (Section IV-A). The SlowPointer uses a traditional
meta data store (Section IV-B). We can convert between
both pointer representations at runtime. In this way, we can
always choose the most appropriate representation for the
current context.
Both pointer representations use the lower 48 bits to
represent
the pointer value. The highest bit determines
the pointer representation. If it is set to 1 the pointer is
represented as FastPointer. If it is set to 0 the pointer is a
SlowPointer. The usage of the remaining spare bits depends
on the pointer representation.
A. FastPointer
In the past, the speed of the CPU grew much faster than
the speed of the memory (RAM). Hence, in current architec-
tures it becomes increasingly difﬁcult to keep the processor
busy for memory intensive applications. The gap between
the performance of the processor and the performance of
the memory subsystem widens.
FastPointer is a runtime pointer representation that ex-
ploits the memory gap. Our goal is to decrease the pressure
on the memory subsystem. In order to achieve this, we trade
computational power for memory bandwidth.
FastPointers use the upper spare bits on current x86 64
architectures to store the offset between the current pointer
position and the end address of the object into them. Thus,
we can extract the offset from the pointer and recover the
end address at any point in time. We use this property to
detect buffer overﬂows. In the following we present a small
example of how this is accomplished. Subsequently, we will
explain how we detect buffer underﬂows.
Consider memory object A in Figure 4. The object is 5
bytes large; thus, a pointer to the base of this memory object
carries 0x0005 in its upper bits. A pointer to the fourth byte
of the same memory object can access two bytes without
triggering an out-of-bounds error. Therefore, this pointer
carries 0x0002 in the upper bits.
In order to bounds-check a pointer in FastPointer repre-
sentation, we extract the remaining size of the associated
memory object from the upper bits. If this size is greater or
equal to the size of the requested operation, the operation is
in-bounds. If it is smaller we detect an out-of-bounds error.
To keep the meta data stored in the spare bits cor-
rect, we have to update the upper 16 bits of the pointer
at any arithmetic affecting the pointer. For example, in-
stead of executing (buffer + i), we have to execute
(buffer + i - (i > 48) & 0x7F;
2
i f (offset >= 0) {
i f (offset = baseAddress)
return ptr + offset - (offset points = (long *)((char*)
(((unsigned long )points_unaligned &
˜(CACHE_LINE_SIZE-1))) + CACHE_LINE_SIZE);
Listing 3. Pointers are casted to integers to align the memory to the next
cache line boundary by using an and operation.
representation on line 5. We will explain the SlowPointer
representation in more detail in the next section. If the offset
is negative, we strip the meta data of the pointer on line 7.
Next, we read the base address from the padding after the
memory object. If the resulting pointer stays in-bounds, then
the pointer and the size in the upper bits is updated on
line 10. Otherwise, the resulting pointer is converted into
the SlowPointer representation (line 11).
In sum, we always use SlowPointers in case pointer
arithmetic results in an out-of-bounds position and the
position is not the end address. While we experimented with
different solutions to represent out-of-bounds pointer using
the FastPointer representation, in our experience the gains
are not worth the effort.
The FastPointer representation can use 15 bits to represent
the size. Hence, only memory objects up to a size of
215 − 1 = 32767 bytes can be represented by FastPointers.
Pointers to memory objects with a larger size are always
represented as SlowPointer.
B. SlowPointer
The FastPointer representation has some limitations. First,
it cannot be used to access objects larger than 215− 1 bytes.
Second,
is not worthwhile to represent out-of-bounds
pointer using FastPointer. Third, FastPointer are not stable
in the presence of integer arithmetic.
it
The example in Listing 3 is taken from one of the
benchmarks we used in our evaluation (Labyrinth from
Figure 5. Meta data store used by the SlowPointer representation. The
store consists of 215 buckets. Each bucket is a linked list of meta data
records. The bucket’s ID is stored in the unused 15 bits of a SlowPointer.
STAMP [20]). Most bounds checkers do not support arbi-
trary integer arithmetic on pointers like in Listing 3 on line 6.
We veriﬁed that SoftBound [2] signals a false positive for
this example. SoftBound loses the bounds meta data during
the integer arithmetic. We have not been able to verify the
behavior of BaggyBounds [3], but we expect it to work
ﬁne with this speciﬁc example. However, this is by accident
and not by design. For example, BaggyBounds will fail if
integer arithmetic changes the pointer to an out-of-bounds
address [3, §7].
To support integer arithmetic both checkers would require
additional instrumentation on any integer operations to track
and update the meta data of the pointer. These additional
instrumentations are difﬁcult to do correctly: Integer oper-
ations on non-pointer values must be explicitly excluded
from these instrumentations to avoid false positives. In
general, it is impossible to decide at compile time whether
an integer operation (such as and) will be applied on
pointers or integers at runtime. Furthermore, the additional
instrumentation would increase the performance overhead.
In contrast, we use a pointer representation that is stable
with respect to virtually2 all integer arithmetic operations.
Whenever a pointer is casted to an integer, we switch the
pointer representation to SlowPointer. For our SlowPointer
representation, we store the meta data in a separate meta data
store. The meta data store contains one record per allocated
memory object. Figure 5 depicts the meta data store for
the SlowPointer representation. The store is organized in