how long Ninja was in the Sleep state and when the next check
would be performed. With the measured interval and checking
time, we could launch transient attacks that avoided detection.
However, that particular strategy did not work on H-Ninja, as
it does not generate a /proc ﬁle in the target VM. Table III
shows result of a trial of this method, in which each interval
was sampled 30 times.
Rootkit combined attacks: In a more substantial attack,
we combined a privilege escalation exploit with a rootkit,
which was able to hide processes. After the terminal was
escalated, we immediately ran the rootkit to prevent Ninja
from discovering the presence of the terminal, bypassing both
versions of Ninja.
Spamming attacks: We increased the execution time of the
function that iterated over the process list by launching a
large number of valid processes together with one privilege
escalated process. The purpose was to increase the scanning
time so that the escalated process can complete before the scan
reached it. Note that a blocking H-Ninja is protected against
this attack. See the bottom of Fig. 6 for an illustration.
2) Active Monitoring with HT-Ninja: To show the beneﬁts
of HyperTap’s active monitoring mechanism, we compared the
detectability of the three versions of Ninja (O-Ninja, H-Ninja,
and HT-Ninja) against real exploits, coupled with the attack
strategies described in Section VIII-C1. It is worth mentioning
that both O-Ninja and H-Ninja are vulnerable to DKOM
rootkits, e.g., SucKIT, because they only use OS invariants.
Our experiments showed that O-Ninja with a 0-second
checking interval was quickly defeated by a privilege esca-
lation exploit CVE-2013-1763 [36] combined with spamming
and a rootkit.6 The attack was performed as follows: (i) a
number of idle processes were created; (ii) the exploit code
was run to grant root privileges to the current process; and
(iii) with root privileges, the rootkit was installed to remove
the escalated process from the process list. We repeated the
attack 300 times and have timed the attack to take ∼4ms on
an Intel(R) Core(TM)2 Duo CPU E8400 3GHz CPU. Without
creating extra processes on a system with 31 processes run-
ning, O-Ninja can detect ∼10% attacks. When we introduced
100 idle processes, the detection probability was reduced to
single-digit percentages (between 2 and 3%). With 200 or
more idle processes, O-Ninja cannot detect any attacks (with
the exception of outliers (cid:3) 1%).
To test H-Ninja, we used the same privilege escalation +
rootkit combination as with O-Ninja. Since the attack was
6https://github.com/ivyl/rootkit
22222222
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply. 
	C	3"C
	 
	 	3" 	
. &#+$+(
&#''&)#"
$3'#"(.(-("
  &$('49=#"+&&"(5
  &$('4>#"+&&"(5
  &$('49#"+&&"(5
$&#+$+(
/'(!  
,&
&(!)'(4(/$D#+ 5
&/'(#":+'"&'(&,& '
+&'#"'(33#-&#	"#
2'%&(4:5(#??! $ '
#!$ &&#+$+(
&(!)4(/$D#(5
&(!)4(/$D #"5
&(!)4(/$D"(5
&(!)4(/$D'#&(5
 #$/;8?=+'0>888
 &(;8?=+'0>888
 ;8?=+'0>888
 #$/: 20 ms, the detection probability became < 5%.
Although an attacker with no access to side channels must
rely on a certain amount of luck to defeat O-Ninja and H-
Ninja, his/her probability of success can be increased by
spamming (O-Ninja) or by reasoning that administrators would
not wish to incur the penalty of scanning the process tree with
a frequency in the single-digit milliseconds. Also, the speed of
the attack at 4 ms was extremely na¨ıve; a more sophisticated
attacker should be able to do better.
Since it uses active monitoring, HT-Ninja was able to detect
all attacks in all tested scenarios.
A main limitation of HT-Ninja, as well as O-Ninja and H-
Ninja, is that they do not detect privilege escalation attacks that
occur within the context of “white listed” processes. Those
processes, many of which are setuid programs, are ignored
by Ninja. An attacks that compromises (e.g., using buffer
overﬂow) and executes malicious code within the context of
a white listed process would not be detected.
IX. PERFORMANCE EVALUATION
We conducted experiments to measured the performance
overhead of individual HyperTap auditors as well as the
combined overhead of running multiple auditors. We measured
the runtime of the UnixBench7 performance benchmark when
(i) each auditor was enabled, and (ii) all three auditors are
enabled. The target VM was a SUSE 11 Linux VM with 2
vCPUs and 1GiB of RAM. The host computer ran SUSE
11 Linux and the KVM hypervisor, with an 8 core Intel i5
3.07GHz processor and 8 GiB of RAM. The results were
illustrated in Fig. 7. The baseline is the execution time
when running the workloads in the VM without HyperTap
integrated, and the reported numbers are the average of ﬁve
runs of the workloads.
In most cases, the performance overhead of running all three
auditors simultaneously was (i) only slightly higher than that
of running the slowest auditor, HT-Ninja, individually, and
(ii) substantially lower than the summation of the individual
overheads of all auditors. That result demonstrates the beneﬁts
of HyperTap’s uniﬁed logging mechanism.
For the Disk I/O and CPU intensive workloads, all three
auditors together produced less than 5% and 2% performance
losses, respectively. The Disk I/O intensive workloads appear
to have incurred more overhead than CPU intensive workloads
because they generated more VM Exit events, at which point
some monitoring code was triggered.
For
the
context
switching and system call micro-
benchmarks, all three auditors together induced about 10% (or
less) and 19% performance losses, respectively. It is important
to note that those micro-benchmarks were designed to measure
the performance of individual speciﬁc operations without
any useful processing; they do not necessarily represent the
performance overhead of general applications. The relatively
high overhead was caused by the HyperTap routines enabled
for logging those benchmarked operations. Since only HT-
Ninja needs to log system calls, it was the primary source
of the overhead in the system call micro-benchmark case.
X. CONCLUSIONS
This paper presents principles for unifying RnS monitoring.
We identify the boundary dividing the logging and auditing
phases in monitoring processes. That boundary allows us
to unify and develop dependable logging mechanisms. We
demonstrate the need for an isolated root of trust and ac-
tive monitoring to support a wide variety of RnS monitors.
We applied those principles when developing HyperTap, a
framework that provides uniﬁed logging, based on hardware
invariants, to safeguard VM environments. The feasibility of
the framework was demonstrated through the implementation
and evaluation of three monitors: Guest OS Hang Detection,
Hidden RootKit Detection, and Privilege Escalation Detection.
In all cases, the use of architectural invariants was central to
the high quality and performance observed in the experiments.
We presented additional analysis of the method so that other
reliability and security monitors can be built on top of the
HyperTap framework.
7http://code.google.com/p/byte-unixbench/
23232323
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply. 
XI. ACKNOWLEDGMENTS
This material is based upon work supported in part by
the National Science Foundation under Grant No. CNS 10-
18503 CISE, by the Army Research Ofﬁce under Award
No. W911NF-13-1-0086, by the National Security Agency
(NSA) under Award No. H98230-14-C-0141, by the Air Force
Research Laboratory and the Air Force Ofﬁce of Scientiﬁc
Research under agreement No. FA8750-11-2-0084, by an IBM
faculty award, and by Infosys Corporation. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the author and do not necessarily
reﬂect the views of the National Science Foundation, or other
organizations.
REFERENCES
[1] M. Bishop, “A model of security monitoring,” in Fifth Annual Computer
Security Applications Conference.
IEEE, 1989, pp. 46–52.
[2] S. Bahram, X. Jiang, Z. Wang, M. Grace, J. Li, D. Srinivasan, J. Rhee,
and D. Xu, “DKSM: Subverting virtual machine introspection for fun
and proﬁt,” in 29th IEEE Symposium onReliable Distributed Systems,
2010, pp. 82–91.
[3] B. D. Payne, M. Carbone, M. Sharif, and W. Lee, “Lares: An architecture
for secure active monitoring using virtualization,” in Security and
Privacy, 2008. SP 2008. IEEE Symposium on.
IEEE, 2008, pp. 233–
247.
[4] H. Moon, H. Lee, J. Lee, K. Kim, Y. Paek, and B. B. Kang, “Vigilare:
Toward snoop-based kernel integrity monitor,” in In Proc. of the 2012
ACM Conference on Computer and Communications Security, ser. CCS
’12. New York, NY, USA: ACM, 2012, pp. 28–37.
“Ninja:
for
[5] T.
R.
Flo,
Privilege
escalation
Ubuntu
detec-
Manual,
tion
http://manpages.ubuntu.com/manpages/lucid/man8/ninja.8.html, 2005.
gnu/linux,”
system
[6] R. G. Ragel and S. Parameswaran, “IMPRES: Integrated monitoring for
processor reliability and security,” in In Proc. of the 43rd Annual Design
Automation Conference, ser. DAC ’06. New York, NY, USA: ACM,
2006, pp. 502–505.
[7] N. Nakka, Z. Kalbarczyk, R. K. Iyer, and J. Xu, “An architectural
framework for providing reliability and security support,” in Dependable
Systems and Networks, 2004 International Conference on.
IEEE, 2004,
pp. 585–594.
[8] K. Pattabiraman, “Automated derivation of application-aware error
and attack detectors,” Ph.D. dissertation, Champaign, IL, USA, 2009,
aAI3363053.
[9] X. Jiang, X. Wang, and D. Xu, “Stealthy malware detection and monitor-
ing through VMM-based out-of-the-box semantic view reconstruction,”
vol. 13, no. 2. New York, NY, USA: ACM, Mar. 2010, pp. 12:1–12:28.
[10] B. D. Payne, M. de Carbone, and W. Lee, “Secure and ﬂexible moni-
toring of virtual machines,” in Twenty-Third Annual Computer Security
Applications Conference (ACSAC).
IEEE, 2007, pp. 385–397.
[11] T. Garﬁnkel and M. Rosenblum, “A virtual machine introspection based
architecture for intrusion detection,” in In Proc. Network and Distributed
Systems Security Symposium, 2003, pp. 191–206.
[12] B. Dolan-Gavitt, T. Leek, M. Zhivich, J. Gifﬁn, and W. Lee, “Virtuoso:
Narrowing the semantic gap in virtual machine introspection,” in Secu-
rity and Privacy (SP), 2011 IEEE Symposium on.
IEEE, 2011, pp.
297–312.
[13] O. S. Hofmann, A. M. Dunn, S. Kim, I. Roy, and E. Witchel, “Ensuring
operating system kernel integrity with osck,” in In Proc. of the Sixteenth
International Conference on Architectural Support for Programming
Languages and Operating Systems, ser. ASPLOS XVI. New York,
NY, USA: ACM, 2011, pp. 279–290.
[14] R. Hund, T. Holz, and F. C. Freiling, “Return-oriented rootkits: Bypass-
ing kernel code integrity protection mechanisms,” in In Proc. of the 18th
USENIX Security Symposium, 2009, pp. 383–398.
[15] J. Rhee, R. Riley, D. Xu, and X. Jiang, “Defeating dynamic data
kernel rootkit attacks via vmm-based guest-transparent monitoring,”
in International Conference on Availability, Reliability and Security
(ARES).
IEEE, 2009, pp. 74–81.
[16] B. Dolan-Gavitt, T. Leek, J. Hodosh, and W. Lee, “Tappan zee (north)
bridge: mining memory accesses for introspection,” in In Proc. of the
2013 ACM SIGSAC conference on Computer &#38; communications
security, ser. CCS ’13. New York, NY, USA: ACM, 2013, pp. 839–
850.
[17] S. T. Jones, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau, “Antfarm:
Tracking processes in a virtual machine environment,” in In Proc. of the
USENIX Annual Technical Conference, 2006, pp. 1–14.
[18] ——, “Vmm-based hidden process detection and identiﬁcation using
lycosid,” in In Proc. of the Fourth ACM SIGPLAN/SIGOPS International
Conference on Virtual Execution Environments, ser. VEE ’08. New
York, NY, USA: ACM, 2008, pp. 91–100.
[19] A. Dinaburg, P. Royal, M. Sharif, and W. Lee, “Ether: Malware analysis
via hardware virtualization extensions,” in In Proc. of the 15th ACM
Conference on Computer and Communications Security, ser. CCS ’08.
New York, NY, USA: ACM, 2008, pp. 51–62.
[20] F. Zhang, K. Leach, K. Sun, and A. Stavrou, “Spectre: A dependable
introspection framework via system management mode,” in In Proc. of
The 43rd Annual IEEE/IFIP International Conference on Dependable
Systems and Networks (DSN’13), June 2013.
[21] D. Pelleg, M. Ben-Yehuda, R. Harper, L. Spainhower, and T. Adeshiyan,
“Vigilant–out-of-band detection of failures in virtual machines,” Oper-
ating systems review, vol. 42, no. 1, p. 26, 2008.
[22] G. J. Popek and R. P. Goldberg, “Formal requirements for virtualizable
third generation architectures,” pp. 121–, 1973.
[23] L. Wang, Z. Kalbarczyk, W. Gu, and R. K. Iyer, “An os-level framework
for providing application-aware reliability,” in Dependable Computing,
2006. PRDC’06. 12th Paciﬁc Rim International Symposium on.
IEEE,
2006, pp. 55–62.
[24] J. Demme, M. Maycock, J. Schmitz, A. Tang, A. Waksman, S. Sethu-
madhavan, and S. Stolfo, “On the feasibility of online malware detection
with performance counters,” SIGARCH Comput. Archit. News, vol. 41,
no. 3, pp. 559–570, Jun. 2013.
[25] K. S. Yim, Z. T. Kalbarczyk, and R. K. Iyer, “Quantitative analysis of
long-latency failures in system software,” in Dependable Computing,
2009. PRDC’09. 15th IEEE Paciﬁc Rim International Symposium on.
IEEE, 2009, pp. 23–30.
[26] A. Kivity, Y. Kamay, D. Laor, U. Lublin, and A. Liguori, “kvm: the
linux virtual machine monitor,” in In Proc. of the Linux Symposium,
vol. 1, 2007, pp. 225–230.
[27] J. Butler and G. Hoglund, “Vice–catch the hookers,” Black Hat USA,
vol. 61, 2004.
[28] D. Sd, “Linux on-the-ﬂy kernel patching without lkm,” Phrack Magazine
#58, Article 7, http://www.phrack.org/issues.html?id=7&issue=58, 2001.
[29] T. Garﬁnkel, “Traps and pitfalls: Practical problems in system call
interposition based security tools,” in In Proc. of the Network and
Distributed Systems Security Symposium, vol. 33, 2003.
[30] N. Provos, “Improving host security with system call policies,” in
the 12th USENIX Security Symposium, vol. 1, no. 8.
In Proc. of
Washington, DC, 2003, p. 10.
[31] A. P. Kosoresow and S. Hofmeyer, “Intrusion detection via system call
traces,” Software, IEEE, vol. 14, no. 5, pp. 35–42, 1997.
[32] J. Criswell, N. Geoffray, and V. S. Adve, “Memory safety for low-level
software/hardware interactions.” in USENIX Security Symposium, 2009,
pp. 83–100.
[33] J. Criswell, A. Lenharth, D. Dhurjati, and V. Adve, “Secure virtual
architecture: A safe execution environment for commodity operating
systems,” in In Proc. of Twenty-ﬁrst ACM SIGOPS Symposium on
Operating Systems Principles, ser. SOSP ’07. New York, NY, USA:
ACM, 2007, pp. 351–366.
[34] D. Cotroneo, R. Natella, and S. Russo, “Assessment and improvement
of hang detection in the linux operating system,” in Reliable Dis-
tributed Systems, 2009. SRDS’09. 28th IEEE International Symposium
on.
IEEE, 2009, pp. 288–294.
[35] T. Ormandy, “The gnu c library dynamic linker expands $origin in se-
tuid library search path,” http://seclists.org/fulldisclosure/2010/Oct/257,
2010, [Online; accessed 29-April-2013].
[36] SecurityFocus, “Linux kernel cve-2013-1763 local privilege escalation
vulnerability,” http://www.securityfocus.com/bid/58137/info, 2013, [On-
line; accessed 29-April-2013].
[37] S. Jana and V. Shmatikov, “Memento: Learning secrets from process
footprints,” in Security and Privacy (SP), 2012 IEEE Symposium on,
2012, pp. 143–157.
24242424
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply.