primary goal of the four pilot studies is to examine different
priming levels. We use bankofamerica.com as an example:
At the low priming level, we showed the screenshot and
asked “is the website the real bankofamerica.com?” We
tried to avoid priming users to focus on the address bar.
At the medium priming level, we asked “is the domain name
in the browser address bar bankofamerica.com?” By explic-
itly mentioning the address bar, we cued users to examine the
address bar.
At the high priming level, we drew users’ attention
to the domain name even more by placing the homo-
graph domain name directly in the question. We asked “is
bankofamerl,ca.com the same as bankofamerica.com?”
We essentially asked the users to compare the two domain
names side-by-side.
We also tested two different designs for the answering
options. The ﬁrst design is to use binary answers: participants
can choose one from “Yes,” “No,” or “I can’t tell.” The second
design is to use 5-point Likert scale answer options.
8After our study, we received messages from participants who thanked us
for educating them about homograph IDNs.
9In the address bar of the screenshots, we always displayed the Unicode
version of the homograph IDNs to examine how users perceive them and to
fairly compare homograph IDNs missed by Chrome with the blocked ones.
We wanted to understand whether the missed IDNs are more or less difﬁcult
to detect by users compared with the blocked ones in the Unicode format.
Figure 3: An example screenshot, which always shows the
real webpage. The address bar was artiﬁcially added to display
either the real domain name or a homograph IDN in Unicode
(in this case, www.bankofamerl,ca.com). Right below the
screenshot, we asked “Is the domain name in the browser
address bar bankofamerica.com?” Participants can choose
one of three answers: “Yes,” “No,” “I can’t tell.”
Final Design.
After comparing the results of the pilot
studies, we decided to choose the medium priming level and
binary answer (plus “I can’t tell”) as the ﬁnal design. We
asked “is the domain name in the browser address bar [the
real domain name]?”. Participants can choose one of three
answers: “Yes,” “No,” “I can’t tell.” This is based on two
reasons. First, we did not observe a need to use a 5-point
Likert scale as the trend was the same for both conditions
and using the Likert scale can complicate the tasks. People
might also interpret the ﬁve levels differently. Instead, a binary
answer (plus “I can’t tell”) can reduce the ambiguity. Second,
the medium priming level (i.e., mildly cuing users to check
the address bar) is more suitable since our research questions
are about domain names. The pilot studies show that users
had a higher accuracy to label the domain authenticity under
a higher priming level (see Appendix-A). While we use the
medium priming level for our main study, the other pilot study
results can serve as the lower/upper bounds of detection rates.
6.2 Main User Study
After determining the study design, we now introduce the
setups of the main user study.
Websites.
For the main user study, we use a diverse set
of 90 websites. Out of the 90 target websites, 45 were from
the Chromium top domain list (i.e., “popular”), and the other
45 were not on the list (i.e., “unpopular”). We select these
websites from ﬁve common website categories (18 websites
per category): “Shopping,” “Banking,” “Social Networking,”
“Education,” and “Government & Military.”
For each target website, we can choose to display the real
domain name in the address bar of the screenshot (“Real”). We
can also choose to display the homograph IDN to impersonate
it. We consider two types of homograph IDNs: one IDN that
can be blocked by the latest Chrome (IDN-Block), and another
IDN that can bypass Chrome’s policy (IDN-Pass).
Out of the 90 websites, we set the ratio of “Real”, “IDN-
Block”, and “IND-Pass” to be roughly 1:1:2. We included
more IND-Pass domains because IDNs that can bypass
Chrome’s policies are less understood and studied. We cov-
ered more IDN-pass domains to better study this category.
More speciﬁcally, we randomly chose 23 of the 90 websites
to display the real domain names (“Real”), and select another
23 websites to display homograph IDNs that can be blocked
by Chrome (“IDN-Block”). For the remaining 44 websites,
we crafted homograph IDNs that would bypass Chrome’s
policies (“IDN-Pass”). A complete list of the websites and
domain names is available here10.
Factors.
In addition to website category and popularity,
we also considered other factors such as people’s demograph-
ics (e.g., age range, gender identity) and computing/Internet
experiences (e.g., years of using web browsers, computing
background). These questions are available under this link11.
Study Process.
In April 2020, we conducted a study on
MTurk. Each participant examined 30 websites. More speciﬁ-
cally, we divided the 90 websites into 3 blocks (each block
has 30 websites). In each block, the mixture ratio of “Real”,
“IDN-Block”, and “IND-Pass” was still roughly 1:1:2. We
randomly assigned each participant to one of the three blocks
(each participant can work on one block only). Once the block
was assigned, we presented a random order of the 30 sites in
the block to the participant.
To ensure the reliability of results, we randomly selected
one attention check question and inserted it in a random posi-
tion in the task/question list. We have two attention questions
to choose from. 1) “Is the domain name shown in the browser
address bar a social networking website?” The screenshot
shows the webpage of the Bank of America. 2) “Is the domain
name shown in the browser address bar a hospital website?”
The screenshot shows the webpage of Facebook. Both ques-
tions have the obvious answer “No.” The attention questions
were designed to help us ﬁlter out participants who did not
look at the domain names or webpages and simply answered
the subsequent question randomly. We also did not want the
attention questions to prime the participants to pay more atten-
tion than they would otherwise. We found that these questions
helped ﬁlter out several non-attentive participants.
To attract serious workers on MTurk, we used commonly
applied ﬁlters: we recruited U.S workers who have an ap-
proval rate greater than 90%, and have completed more than
50 approved tasks. Each participant was compensated $1 for
their time. The participants took 8 minutes on average to
complete the study. The compensation was about $8 per hour.
10https://github.com/stevetkjan/IDN_Testing/blob/master/
websites.xlsx
11https://github.com/stevetkjan/IDN_Testing/blob/master/
Questions-IDN.pdf
Yes
No
Domain Type
I can’t tell
Real
4 (0.2%)
IDN-Block
45 (2.7%)
IDN-Pass
79 (2.5%)
Table 7: Correct answer rates in the main study (6,510 an-
swers): 94.6%, 48.5%, 55.2% for real, IDN-Block, IDN-Pass.
86 (5.2%)
803 (48.5%)
1,768 (55.2%)
1,565 (94.6%)
807 (48.8%)
1,353 (42.3%)
)
%
(
s
r
e
s
U
f
o
F
D
C
 100
 80
 60
 40
 20
 0
 0
 0.2
 0.4
 0.6
 0.8
 1
Labeling Accuracy per User
Figure 4: Cumulative distribution function (CDF) of labeling
accuracy for each user.
Each worker can only participate in the study once. Pilot
study participants were not allowed to take part in the main
study, which had a total of 325 participants. After removing
incomplete submissions and those who failed the attention
check, we had 217 valid participants with 6,510 answers.
6.3 Overall Results
Table 7 shows the overall results of the main study. The results
were consistent with the pilot studies. When the domain name
was real, 94.6% of the answers were correct (by answering
“YES”). In comparison, when the domain name was homo-
graph IDN, only 55.2% of the answers were correct under
IDN-Pass, followed by 48.5% under IDN-Block.
This result answers RQ1: our participants fell for a large
percentage of homograph IDNs. We also examined how well
individual participants correctly labeled the authenticity of
websites based on the domain names. Figure 4 shows the
cumulative distribution function (CDF) of each participant’s
labeling accuracy (based on the 30 websites the user has
examined). All participants had an accuracy above 20%, and a
small portion (15%) of them had a 100% accuracy. However,
about half of the participants had an accuracy below 60%.
Overall, the results suggest that the majority of users will
struggle in correctly identifying homograph IDNs.
To answer RQ2, we then performed pair-wise comparisons
between these three conditions using Chi-square tests with
a Bonferroni correction (the adjusted p value threshold is
.01). We found that the differences among these conditions
were statistically signiﬁcant: the correct answer rates for Real
vs. IDN-Block (c2 = 859.3, p  3 Yr)
Computer background: base = NO
YES
Gender: base = Female
Gender: Male
Age: base = Younger ( 39)
Education: base = Lower (< Bachelor’s)
Higher Edu (Bachelor’s or higher)
0.235
0.133
-0.823
P-Value
0.006
<0.001
0.199
0.287
0.109
0.088
0.288
0.001
<0.001
<0.001
0.044
<0.001
Table 8: Logistic regression results: using website and user
factors to predict whether the authenticity of a website domain
name was correctly labeled by a user.
However, it is alarming that 45% of un-blocked domain
names (IDN-pass) were mistaken by our participants as real
sites. Thus, they pose a substantial issue as about half of the
times people fell for homograph IDNs not caught by Chrome.
6.4 Regression Analysis
To answer RQ3, we further analyzed the factors associated
with user performance in detecting IDNs. We used the dataset
of 6,510 answers and conducted logistic regression analyses
in R to predict a binary outcome: whether the authenticity of
a website domain name was correctly labeled by a user (i.e.,
correct answers for Real and IDN-Block/Pass are “Yes” and
“No,” respectively). Table 8 shows the regression results.
Predictor Variables.
The independent variables or pre-
dictors were all categorical variables, including the domain
type, website category and popularity as well as people’s de-
mographics and computing experience.
We had three predictors related to websites. First, the do-
main types included Real, IDN-Pass and IDN-Block. We
used IDN-Block as the baseline. Second, we had ﬁve website
categories and hypothesized that the website category may
affect users’ judgment of the website authenticity. For exam-
ple, users might be more likely to check the authenticity of
banking websites than education websites. As such, we used
banking websites as the baseline. Third, for website popular-
ity, we hypothesized that users may perform better on popular
websites since they might be more familiar with those. Thus,
we used popular websites as the baseline.
We had ﬁve predictors related to users. First, for users’
years of experience using web browsers, we converted this
variable to a binary variable: “short” and “long” using 3-year
as a threshold. We chose this threshold by examining the sign
of the regression coefﬁcients of the original levels and found
that 3-year was the level where the sign changed. To sim-
plify our analysis, we applied this method in converting other
user-related multi-level ordinal predictors to binary variables.
We hypothesized that users with a long experience with web
browsing may perform better in detecting IDNs. The second
and third variables were users’ computing background and
gender identity. The fourth variable was age level, and we
used a threshold of 39 to divide users into younger and older
categories. The last user variable is education level, and we
used “Bachelor’s degree” to divide users into two levels.
Result Interpretation.
As shown in Table 8, several fac-
tors were signiﬁcantly correlated with users’ performance
in detecting IDNs. These results answer RQ3. Overall, we
found that domain types and user-related factors were signiﬁ-
cantly associated with users’ performance whereas website
category and popularity were not. As a reference, in Figure 5,
we further illustrate the raw percentage of correct answers for
factors that have statistical signiﬁcance.
First, the domain type results imply that participants were
signiﬁcantly more likely to label the real domains and IDN-
Pass domains correctly compared to the baseline (IDN-Block).
The result is consistent with that in Table 7. More speciﬁcally,
Real has a b estimate of 31.23, which means the odds of
labeling real domains correctly is exp(3.441) = 31.23 times
of that of labeling IDN-Block correctly. Similarly, the odds
of labeling IDN-Pass correctly is exp(0.884) = 2.42 times of
that of labeling IDN-Block correctly. These results further
conﬁrm that Chrome indeed blocked the homograph IDNs
that are more deceptive to users than IDNs that were not
blocked (IDN-Pass). This does not necessarily mean IDN-
Pass is safe for users. As discussed in Section 6.3, homograph
IDNs that bypassed Chrome policies are also highly deceptive.
Unlike domain type, website category and popularity were not
found to be signiﬁcantly associated with user performance.
Second, we found several user factors were signiﬁcantly
correlated with correctly labeling the website authenticity. For
example, the odds of correct labeling for users with a longer
(3-year) web browsing experience is exp(0.450) = 1.59 times
of that of users with a shorter experience. Similarly, users’
frequency of visiting the ﬁve categories of sites were also
signiﬁcantly and positively correlated with user performance.
Male participants did better in correctly labeling the domain
names. However, as shown in Figure 5(c), the performance
difference between male and female participants was rather
small (but statistically signiﬁcant). Older participants seemed
to perform better than their younger counterparts. Again the
difference was small but statistically signiﬁcant.
Third, perhaps counter-intuitively, computing background
and educational level were also signiﬁcantly correlated with
s
r
e
w
s
n
A
t
c
e
r
r
o
C
f
o
o
i
t
a
R
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0