2.1.2.2.7多源日志关联分析
业务支撑系统中，存在大量的网络、安全、操作系统、数据库、中间件、业务系统日志数据，需要通过对日志的分析及时获取系统的运行情况和潜在威胁。通过 DM-ARM 算法，实现对告警事件关联规则的高效挖掘，实现多源异构日志中告警事件的关联分析，从而辅助问题的快速诊断和分析定位。
2.1.2.3 故障自愈
2.1.2.3.1能力开放服务故障自愈（新）2.1.2.3 故障自愈
2.1.2.3.1能力开放服务故障自愈（新）
随着5G应用的推广和业务发展趋势，能力开放平台承担的接口服务能力日渐增多，同时对接口连接的时效性要求越来越高。亟需提升接口的调用能力的故障自恢复，减少接口故障影响范围和影响时长。因此，基于接口调用日志、资源配置、告警数据、业务配置数据、知识库，利用大数据采集组件logstash对能力开放平台接口调用日志进行采集，通过LSTM长短期记忆模型算法对能力接口调用的失败情况进行时序分析，同时结合接口调用失败详情，利用智能算法模型，匹配业务自愈规则库，实现接口故障的自愈处理。
2.1.2.3.2容器云服务故障自愈（新）2.1.2.3.2容器云服务故障自愈（新）
近年来业务支撑系统加快云化、容器化、微服务化的架构转变，向云原生发展。随之而来的痛点有：告警量大，告警处理工作激增；冗余告警，故障定位难，故障恢复大部分依赖人工操作；容器环境故障诊断对人员的专业水平要求较高，而且人工分析时效性得不到保障，往往耗时较长。应用均迁移至容器环境，故障检测及故障定位相关算法需适配容器环境，可智能发现部署在容器上应用系统的故障，并对其进行智能AI定位（apriori、FP-growth、SBD、ridge、ewma）、关联操作。采集的指标：宿主机的性能指标、k8s组件的性能指标、业务集群pod集群的性能指标、容器内jvm应用性能指标、数据库性能数据、nginx等前端负载性能数据。
2.1.2.3.3数据库故障自愈（新）2.1.2.3.3数据库故障自愈（新）
数据库维护大规模数据库，经常有数据库异常等待、SQL执行异常、数据库hang住等情况，经常需要人为去干预处理，因此基于数据库性能指标、平台性能指标、会话数量、等待事件数量、告警事件等指标，通过引入随机森林算法实现多维度关联分析定位根因选择自愈方案，结合自动化处理，实现数据库自愈恢复。
2.1.2.3.4数据库关联应用故障自愈（新）
通常一个数据库都要关联至少一个或多个应用，每次系统出现故障进行定位和恢复处理的时候，如果整个过程完全依赖人的经验（如果一个新人来定位问题的话效率更低）,很容易因为定位和处理的不及时导致业务的积压或业务中断等问题，对于这些问题如果能采取智能手段进行故障诊断和恢复，将大大减少故障对业务的影响。基于数据库配置信息、sql信息、数据库日志、应用运行日志，通过多种收敛算法、Apriori 关联算法、FP-growth数据关联挖掘算法挖掘数据库关联的故障应用，实现应用故障自愈功能。2.1.2.3.5业务故障关联自愈（新）
随着业务数量的不断增多，经常会出现个别业务进程故障不断，这时单独的针对进程进行故障自愈已不能够满足需求，而主机作为业务进程运行的平台，中间件作为业务进程调用的对象，也是故障自愈需要考虑的重要环节。因此，基于业务进程、中间件、主机的CPU、内存、存储等性能指标的实时及历史数据，通过LSTM长短期记忆模型算法进行分析，在短期内出现多次故障预警时，联合分析相关业务所用中间件、所部署的主机的CPU、内存、存储等性能指标的实时及历史数据，分析业务进程的根本故障原因，并针对根因问题做到自愈，增强系统健壮性，减少故障的发生。
2.1.2.3.6智能策略匹配自愈（新）
前提是发现故障，以及知识库中有故障针对的处理方式，当故障发生后，去匹配知识库中已有的数据，匹配对应脚本，实现自愈策略的自动匹配。当故障发生时，能及时发现故障，并根据故障类型和特征匹配知识库，结合孤立森林(iForest)、指数加权移动平均(ewma)、岭回归(ridge)、平均绝对差算法(MAD)、基于3倍统计标准差的动态基线等智能AI能力获取对应脚本及自愈策略配置，实现自动匹配。2.1.2.3.7应用服务自愈
随着 IT 系统规模不断增大，应用进程规模已经破万，而云环境下，单组件的稳定性显著下降，导致个别应用实例运行经常出现异常。因此，基于基于指标数据、日志数据，通过时间序列检测算法 LSTM、聚类算法 K-Means、DTW，实现对异常实例的检测，同时触发自动化操作平台，实现应用进程的隔离自愈。
2.1.2.3.8主机平台自愈
主机组维护大规模的主机，经常有主机通断、主机 hang 等异常情况，需要经常人为去干预处理。因此，基于主机性能指标、告警事件、日志报错指标、CMDB 数据，通过异动图谱的聚合，实现多维异动的关联确认，并且打通自动化处理能力，实现主机的自愈恢复。
2.1.2.3.9网络故障自愈
为了提升网络故障的自愈能力，基于将网络性能指标异动情况、网管统计等动态数据与网络拓扑等静态信息关联整合，通过朴素贝叶斯算法判断故障根源对象，同时打通自动化处理能力，实现“先于用户发现问题，先于投诉解决问题”的目标。2.1.3 事后保障
2.1.3.1 知识库管理
系统知识梳理依赖人工梳理，投入成本高、效率低。基于大量的投诉工单、问题单、事件单等工单数据，应用 TFIDF 分词算法，对历史数据进行挖掘分析，总结出来历史问题的处理经验，并自动写入知识库，提升知识管理效能。
2.2效率提升类
2.2.1智能问答
2.2.1.1智能掌上工作台（新）
随着业务发展，业务系统日益庞大，对运维工作提出了新的挑战。主要是运维工作量日益加剧，对系统的保障更需要时刻待命，为保证敏捷高效运维，对7*24小时响应要求日益加大。通过掌上运维工作台，结合运维工作语料、问答数据等素材和bert、s-bert、rasa框架、CRF意图能AI能力，分类对生产系统各类运维操作，实现统一管理执行，提供界面化、智能交互问答方式操作，简化运维操作模式，提升运维执行效率。
2.2.1.2智能运维机器人2.2.1.2智能运维机器人
日常运维工作中，一线人员除了监控值班以外，还要应对大量的租户请求、处理咨询、生成事件通报、调度故障、查询变更状态等，耗费大量的一线人工成本。因此，基于 NLP 语义库和历史用户输入文本数据，通过 Bert 模型算法，实现日常热点问题的自动应答，从而提升一线的工作效率。
2.2.1.3智能客服机器人
为快速支撑一线业务，提升支撑效率，构建智能客服机器人。通过引入 Gensim 语义分析、Jiba 分词技术、聚合算法等 AI 技术，通过智能客服机器人登记问题、业务规则和操作指引咨询、问题定位，查看关注的问题进展、获取当前热点问题、系统公告、及业务部门业务规则正式答复等操作，全面提升内部客户服务支撑满意度。
2.2.1.4智能在线服务台2.2.1.4智能在线服务台
互联网化帮助台系统，以大数据/AI 为核心，拓展互联网渠道入口，重点提升帮助台的多媒体交互能力，以热线服务、在线服务、工单协同、智能知识库等方式，输出垂直领域核心能力，受理用户的故障处理、异常查询、业务咨询、投诉申告等诉求，提升内部用户的服务感知。涉及工单协作，公告管理，知识库，预服务/智能应答，在线服务，智能语音等。
2.2.2智能决策
2.2.2.1部件失效影响面分析（新）
部件失效影响分析，部件失效以后，影响范围如何？预计恢复时间如何？目前主要依靠依据事先制定的评估标准进行人工评估，维度比较多，评估不够及时，而且准确度带有主观性。考虑两点优化策略：根据jiba分词技术、NLP语义分析、Bert 模型算法、K-Means 聚类算法、推荐算法等AI智能分析自动处理并识别制定的规则，也可依据历史工单数据、历史告警数据，自动修正规则（自动修正可选）；根据失效的组件类型，例如中间件失效、数据库失效、主机失效、业务套餐失效等，依据系统现有规则给出影响面的准确评估。2.2.2.2微服务智能熔断降级（新）
在应用系统微服务化后，虽然此时每个微服务都拥有独立的进程资源、业务线程池以及单独的数据库，整体的系统吞吐量比以前高了很多，并且每个微服务也都是集群部署，但是因为整个调用的网络链路是非常长的，如果此时发生局部网络或者部分微服服务故障的话，依然可能会导致整个微服务系统的瘫痪。基于微服务调用链数据，通过LSTM时序预测对微服务链路的异常数据进行检测，对微服务链路异常检测以及通过提前干预实现熔断降级功能。
2.2.2.3容器亲和度（新）
在容器云部署中，为了避免不同节点的利用率不均匀，减少跨节点、跨集群访问，提高高可用能力，需要对容器的亲和度进行智能评估。基于容器资源的时序利用率等性能数据信息及集群节点的功能主从信息，通过LSTM时序预测，余弦相似度完成容器资源的亲和度评估，为容器迁移提供数据支撑，提高容器资源综合使用率提升。
2.2.2.4智能工单处理（新）2.2.2.4智能工单处理（新）
用户的大量投诉都是基于部分共性内容进行投诉，相似的问题需要大量的人工进行判断，不仅浪费人力，而且依赖于个人的主观判断。因此依据jiba分词技术、NLP语义分析、Bert等智能算法对历史工单的投诉内容、处理意见、工单类型等工单信息内容进行分析，实现工单去重合并、工单自动分派、建议推荐、预防投诉升级等效果。
2.2.2.5中间件配置优化（新）
现有中间件故障诊断，仅仅是分析到了中间件的某某原因引起了故障，比如jvm内存溢出、jdbc线程池无法获取链接，但是不能给出具体的修复优化建议，故障自愈也仅仅限于重启，重启后一段时间后，故障再次出现，并不能永久解决。基于中间件故障诊断，甄别出故障产生的原因在中间件的配置不合理后，结合内置专家运维经验和ridge、ewma、iforest等AI算法能力，给出合理的优化建议，比如原来2G的jvm调整到4G，50的线程池调整为100等等，为故障自愈联动操作提供分析依据。采集指标包括TPS、线程池使用率、jdbc链接数、每次jvm fullgc时长、jvm fullgc频率、jvm内存使用率、CPU使用率、活动请求数。2.2.2.6智能工单变更（新）
根据运维告警自动生产的运维工单，自动适配的告警级别不正确及工单时效性不灵活。运用AI手段分析告警成分，关联历史标记级别和专家经验，自动调整告警级别和优先级；针对非人为因素且已经愈合的（类似停电）历史告警，自动标记处理。通过词向量、余弦相似度、Apriori 挖掘算法，实现工单智能升降级。利用运维经验图谱，辨别工单的重要度及根因，从重要度灵活匹配级别；根据识别出的根因，从实时日志判断时效性。
2.2.2.7 知识图谱（新）
知识图谱是一种基于图的数据结构，由节点（point）和边（Edge）组成，每个节点表示一个“实体”，每条边为实体与实体之间的“关系”，知识图谱本质上是语义网络。知识图谱在中国移动业务及运维场景的知识搜索、自然语言处理、智能服务助手、故障根因分析等领域发挥着重要作用，在客户服务、存量运营、业务推荐、安全管控等都有成熟案例。更具体的内容参见《全网知识图谱试点工作白皮书》。
2.2.2.8中间件智能重启
现在分布式系统中，中间件支撑了上万个应用服务的运行基础，而云化以后单个基础组件的稳定性开始降低，给维护带来了不小的隐患和难度。因此，基于中间件的性能数据，通过利用孤立森林的算法，实现对异常实例的检测，结合自动化操作能力，完成中间件的智能重启。
2.2.2.9虚机智能扩缩容
为了优化硬件资源使用的合理性同时提升云资源池以及各承载系统的整体处理能力，基于主机 CPU、内存利用率、CMDB 配置数据，利用时序预测算法分析学习该应用服务对资源需求的消耗、时间分布等规律，预测新的时间周期内的资源使用情况，以用于各应用集群的及时扩缩容，提升云平台整体资源使用效率。