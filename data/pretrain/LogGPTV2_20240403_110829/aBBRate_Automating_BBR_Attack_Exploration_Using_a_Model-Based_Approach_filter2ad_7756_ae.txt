See Figure C2.
D BBR State Inference Algorithm
[32] Nupur Kothari, Ratul Mahajan, Todd Millstein, Ramesh
Govidan, and Madanlal Musuvathi. Finding Protocol
For completeness, we present a pseudocode of the BBR state
inference algorithm in Algorithm D2.
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    237
(a) Optimistic ACK: ac-
knowledge
highest byte,
dropping duplicates.
(b) Delayed ACK: delay ac-
knowledgments for a ﬁxed
amount of time.
(c) Limited ACK: prevent
ACK numbers from increas-
ing.
(d) Stretch ACKs: forward
only every nth ACK. In this
example, n = 2.
Figure B1: Time lines of acknowledgment-based manipulation actions used in our attack strategies.
(a) ACK burst: send n ACKs
in a single burst. In this
example, n = 3.
(b) Divided ACKs: ACK m
bytes using n ACKs, each
acknowledging m/n bytes.
(c) Duplicate ACKs: inject n
duplicate ACKs. In this
example, n = 3.
Figure C2: Time lines of acknowledgment-based manipulation actions that were previously known to be effective against TCP congestion
control, but were ineffective against BBR.
Algorithm A1 Attack strategy categorization algorithm: 20
benign experiments are ﬁrst executed to obtain a baseline
average and standard deviation. Since each strategy transfers
the same 100MB ﬁle, an strategy is categorized as a function
of its total transfer time and the baseline average and standard
deviation transfer time.
return FASTER
else
end if
else
end if
Input: Strategy execution metrics
Output: The category of the strategy
if s.Time > (s.TimeAvg + 2∗ TimeStddev) then
else if s.Time = (0.7∗100MB) then
1: function CATEGORIZEATTACKSTRATEGY(s)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end function
return STALLED
return BENIGN
E Background on Congestion Control
E.1 Congestion Control Overview
Congestion control determines whether to send a segment of
data based on information inferred about a network path be-
tween endpoints. A primary goal is to saturate the bottleneck
link (maintaining high utilization) while avoiding conges-
tion collapse (due to sending faster than the bottleneck link
can support). The bottleneck link is saturated when the total
amount of data in-ﬂight equals the path’s bandwidth-delay
product (BDP) which represents the maximum amount of
in-ﬂight data the network [31] can process without dropping
packets. A path’s BDP is dynamic and typically computed as
the product of the bottleneck link’s maximum bandwidth and
the path’s round-trip time without queue delay [37]. Conges-
tion control is also tasked with avoiding congestion collapse
and achieving fairness with other ﬂows sharing the network.
Accomplishing these goals is challenging because networks
are unpredictable: links vary in bandwidth capacity and are
shared anywhere between few to millions of hosts such as the
global Internet. While several congestion control algorithms
have been developed, most adhere to the same basic principles
ﬁrst described by Jacobson in 1988 [26]. Below we describe
the main goals of a congestion control algorithm.
Discovering the target sending rate. The target sending
238    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
senderreceiverattackerDATA 1DATA 1DATA2DATA 2ACK 1ACK 2ACK 2DATA 3DATA 4DATA 5DATA 6DATA 3DATA 4ACK 3ACK 6DATA 5DATA 6ACK 4ACK 5ACK 6senderreceiverattackerDATA 1DATA 1ACK 1ACK 1delayDATA 2DATA 2ACK 2ACK 2delaysenderreceiverattackerDATA 1DATA 1ACK 1RTODATA 2DATA 2ACK 2ACK 1ACK 1DATA 2DATA 2startsenderreceiverattackerDATA 1DATA 1DATA 2DATA 2DATA 3DATA 3DATA 4DATA 4ACK 1ACK 2ACK 3ACK 4ACK 2ACK 4RTODATA 1DATA 1senderreceiverattackerDATA 1DATA 1DATA 2DATA 2DATA 3ACK 1DATA 3ACK 2ACK 3ACKs 1, 2 & 3ACK 1ACK 2normal ACKsbursted ACKssenderreceiverattackerDATA (0:1500)ACK (1500)DATA (0:1500)ACK (500)ACK (1000)ACK (1500)spoofedACKsnormal ACKsenderreceiverattackerDATA 1ACK 1ACK 1DATA 1ACK 1ACK 1ACK 1spoofedACKsnormal ACKAlgorithm D2 BBR state inference algorithm
function ONNEWBBRPACKET(packet)
newInt = CHECKINTERVAL(packet) /* a round-trip has passed */
if dataPackets > 0 and RTOPASSEDFORDATAPACKET() then
priorState = currentState
currentState = EXPONENTIAL_BACKOFF
COMPUTEINTERVALMETRICS()
else if retransmissions > 0 and not currentState == RECOVERY then
priorState = currentState
currentState = RECOVERY
/* leave recovery when high water is ACK’d */
highWater = highestDataSequence
else if currentState == RECOVERY then
ratio = THROUGHPUTRATIOSINCELASTROUNDTRIP()
if totalAcked ≥ highWater then
currentState = priorState /* return to previous state */
SETRETRANSMISSIONCOUNT(0)
else if newInt and priorState == STARTUP and 0.7 > ratio > 0.1 then
priorState = DRAIN
end if
else if currentState == PROBERTT and dataPackets > 10 then
currentState = priorState
else if newInt then
else if dataPackets ≥ 10 then
currentState = UPDATEBBRNEWINTERVAL()
/* check for drain on frequent basis */
ratio = THROUGHPUTRATIOSINCELASTROUNDTRIP()
if currentState == STARTUP and 0.7 > ratio > 0.1 then
priorState = currentState
return DRAIN
end if
end if
end function
function UPDATEBBRNEWINTERVAL()
ratio = THROUGHPUTRATIOSINCELASTROUNDTRIP()
dataPackets = GETDATAPACKETCOUNT()
nonIncrease = NONINCREASEINTERVALCOUNT()
if 6 > dataPackets > 3 then /* small amount of data in-flight */
return PROBERTT
else if currentState == DRAIN and ratio > 1.4 then
else if not currentState == PROBEBW and ratio > 1.4 then
else if currentState == STARTUP and 0.7 > ratio > 0.1 then
else if currentState == STARTUP and nonIncrease > 10 then
else if intervalCount > 16 and throughputVariance  ratio > 0.6 then
function CHECKINTERVAL(packet)
if not inInterval and ISDATAPACKET(packet) then
CLEARINTERVALDATA()
ackMark = packet.sequenceNumber
inInterval = true
end if
if inInterval and packet.ackNumber ≥ ackMark then
inInterval = false
COMPUTEINTERVALMETRICS()
return true
end if
return false
end function
rate is one that achieves high throughput and avoids conges-
tion. The sending rate is dictated by a per-connection variable
known as the congestion window cwnd which governs the
maximum amount of unacknowledged data allowed in-transit.
When a connection ﬁrst starts, congestion control performs
slow start to quickly discover the available bandwidth of the
link. Afterwards, congestion avoidance is performed whereby
data is sent conservatively while slowly probing the network
for available bandwidth.
Inferring congestion. Congestion control must use sig-
nals from the network to infer congestion as an indicator
to “back off”, or reduce its load on the network. The most
popular paradigms have been loss-based congestion control
and delay-based congestion control. Loss-based congestion
control has dominated the Internet since its creation and uses
packet loss as signal of congestion. Packet loss occurs when
switch buffers along a network path ﬁll to capacity and are
left with no choice but to discard, i.e., drop, incoming pack-
ets. Delay-based congestion control compares predicted and
actual round-trip time (RTT) samples to signal congestion.
These signals, be they packet loss or RTT, govern the rate at
which data is sent into the network.
Achieving fairness with competing ﬂows. Since net-
works today are shared by several end-hosts, congestion con-
trol aims to share the limited resources of a bottleneck link
evenly across all ﬂows. Coexisting congestion control algo-
rithms may not be fair to each other due to differing probing
and backoff mechanisms. For example, delay and loss-based
congestion control do not operate well together. Delay-based
congestion control has been shown to reduce its congestion
window much earlier than loss-based [3], resulting in unfair
bandwidth allocation. Because of this, delay-based congestion
control is not commonly used in today’s networks.
E.2 Congestion Signal
Loss-based congestion control uses two signals to detect
packet loss: re-transmission timeouts (RTOs) and duplicate
acknowledgment packets. Delay-based congestion control
leverages changes in RTT samples to infer congestion. All
methods leverage feedback from the receiver (i.e. acknowl-
edgment packets) to detect congestion.
Re-transmission timeout. RTOs ensure data delivery
when there is no feedback from the receiver. Each time a
data segment is sent, a timer starts and expires if the seg-
ment has not been acknowledged after a certain amount of
time (usually several RTTs). Each time the timer expires, the
data segment is re-transmitted and the timer restarts with a
doubled timeout time. The initial timeout time is typically
a function of RTT samples, gathered over the duration of a
connection. This event can indicate congestion so severe that
acknowledgments cannot be delivered in a sufﬁcient amount
of time.
Duplicate acknowledgments. When an out-of-order data
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    239
segment is received, a receiver will ignore its payload and
reply acknowledging the last correctly received data byte. If
a data segment becomes lost in-transit, then the following
in-transit segments will be received out-of-order, causing the
receiver to send several duplicate acknowledgments. When a
sender receives multiple (e.g., three) duplicate acknowledg-
ments in a row, congestion is inferred. This event signiﬁes
less severe network congestion because despite the loss of a
data packet, acknowledgments are still able to be received by
the sender.
Delayed acknowledgments. Delay-based congestion con-
trol, used by TCP Vegas [6], FAST TCP [38] and CARD [27],
takes a proactive approach for detecting congestion rather
than loss-based which takes a reactive approach after conges-
tion already occurs. The advantage of delay over loss-based
congestion control is that it detects the onset of congestion
as switch buffers grow instead of waiting until they have
ﬁlled for packet loss to occur. Delay-based congestion con-
trol infers congestion by comparing actual throughput to ex-
pected throughput. If actual throughput is signiﬁcantly less
than expected throughput, then the network is inferred to be
congested.
Adapting to congestion. Congestion control adapts the
sending rate based on the above congestion signals, typically
accomplished by adjusting cwnd based on congestion severity.
The most common approach for adjusting cwnd is the additive
increase/multiplicative decrease (AIMD) scheme where cwnd
linearly increases on each new ACK to probe for available
bandwidth until a congestion event occurs, where cwnd expo-
nentially decreases to “back off” from the network. When an
RTO occurs, cwnd resets to 1 segment as this usually implies
major changes in network conditions. Upon three duplicate
acknowledgments, cwnd halves as this implies small amounts
of packet loss. Fairness is achieved because ﬂows back off at
different times, allowing others to occupy the available band-
width. The limitation of AIMD is while it can attain its fair
share of bottleneck bandwidth, it backs off shortly after its
discovery. The AIMD scheme is a high-level approach which
varies depending on implementation.
E.3 A State Machine for Congestion Control
Acknowledgment packets. Every byte of data is associated
with a unique sequence number [21] that increments by 1
with each additional data byte. A packet containing data is
accompanied by a sequence number, which represents the
sequence of the ﬁrst byte of the data. Sequence numbers allow
data segments to be easily reassembled and acknowledged by
receivers. Acknowledgment packets are sent from the receiver
to explicitly inform the sender about the highest correctly
received data byte thus far. They also implicitly inform the
sender about current network conditions. An acknowledgment
packet acknowledging sequence X implies all bytes up to but
not including X have been correctly received. This allows
the sender to either re-transmit lost segments or send new
data. Receivers typically send one acknowledgment packet
for every two received data packets.
Slow Start. This is the ﬁrst state a connection enters and
aims to quickly discover the available bandwidth of the net-
work before congestion avoidance is entered. Since network
capacities today span several orders of magnitude, this state
performs an exponential search for the available bandwidth.
When slow start is entered, cwnd starts at 1 MSS and dou-
bles on every round-trip until either congestion is detected
or cwnd reaches the target rate, the slow start threshold, or
ssthresh. The slow start threshold deﬁnes the upper limit
for cwnd growth while in slow start, which is initially set to
the receive window, or rwnd.
Congestion Avoidance. The goal of this state is to avoid
congestion by sending data at the estimated available band-
width while slowly increasing cwnd to probe for available
bandwidth. On every round-trip, cwnd increases by 1 MSS
until congestion is detected: a RTO timeout or the recipient
of three duplicate acknowledgments.
Fast Recovery. This state is entered from any other state
when three duplicate acknowledgments are received. This
event indicates less severe congestion because while it may
indicate lost packets, it also indicates the network is at least
able transmit acknowledgments from the receiver. This state
aims to quickly recover from the lost packets by halving cwnd
and re-transmitting the last unacknowledged data segment.
Fast recovery returns to congestion avoidance once all unac-
knowledged data before fast recovery was entered has been
acknowledged.
Exponential Backoff. This state is entered when a re-
transmission timeout (RTO) expires which infers major
changes in network conditions. Re-transmission timers begin
when data segments are ﬁrst sent and expire when a certain
amount of time has elapsed without the segment being ac-
knowledged (usually several RTTs). Each time an RTO time-
out expires, the segment is re-transmitted and the timer restarts
with a doubled timeout time. This results in the sender expo-
nentially backing-off from the network by allowing more time
to elapse before it re-transmits the lost segment in response
to the perceived network congestion. This repeats until an ac-
knowledgment is received after which ssthresh becomes
half of cwnd, cwnd restarts from 1 MSS and exponential-
backoff transitions into slow start.
240    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association