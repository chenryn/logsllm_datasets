title:ProTracer: Towards Practical Provenance Tracing by Alternating Between
Logging and Tainting
author:Shiqing Ma and
Xiangyu Zhang and
Dongyan Xu
ProTracer: Towards Practical Provenance Tracing by
Alternating Between Logging and Tainting
Shiqing Ma
Purdue University
Xiangyu Zhang
Purdue University
PI:EMAIL
PI:EMAIL
Dongyan Xu
Purdue University
PI:EMAIL
Abstract—Provenance tracing is a very important approach
to Advanced Persistent Threat (APT) attack detection and in-
vestigation. Existing techniques either suffer from the depen-
dence explosion problem or have non-trivial space and run-
time overhead, which hinder their application in practice. We
propose ProTracer, a lightweight provenance tracing system that
alternates between system event logging and unit level taint
propagation. The technique is built on an on-the-ﬂy system event
processing infrastructure that features a very lightweight kernel
module and a sophisticated user space daemon that performs
concurrent and out-of-order event processing. The evaluation
with different realistic system workloads and a number of attack
cases show that ProTracer only produces 13MB log data per
day, and 0.84GB(Server)/2.32GB(Client) in 3 months without
losing any important information. The space consumption is
only < 1.28% of the state-of-the-art, 7 times smaller than an
off-line garbage collection technique. The run-time overhead
averages <7% for servers and <5% for regular applications.
The generated attack causal graphs are a few times smaller than
those by existing techniques while they are equally informative.
I.
INTRODUCTION
There is an increasing need of detecting and investigating
APT attacks in an enterprise environment. A very important
approach to addressing this problem is provenance tracking.
According to previous works [17], [32], provenance captures
multiple aspects of information about an entity in a system:
what the entity’s origin is; how the entity is derived; and when
it originated. In the context of APT defense, entities with
trackable provenance information are of various granularity,
such as processes, network connections, ﬁles, and data items
within ﬁles. Correspondingly, the what-provenance of such an
entity e is the set of external entities that have causally inﬂu-
enced e’s value or state (e.g., if one ﬁle’s content comes from
a number of network connections, then its what-provenance
contains the IDs of the corresponding sessions); whereas, the
how-provenance of entity e consists of events and their causal
ordering – which can be organized as a causal graph – that
demonstrates how (and when) other entities inﬂuence e’s value
or state.
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’16, 21-24 February 2016, San Diego, CA, USA
Copyright 2016 Internet Society, ISBN 1-891562-41-X
http://dx.doi.org/10.14722/ndss.2016.23350
Existing Approaches. Existing techniques fall into two cate-
gories: audit logging and provenance propagation (or tainting).
Audit
logging [16], [21], [25], [27], [29], [34]–[36], [39]
records events during system execution and then causally
connects events during attack investigation. They treat pro-
cesses as subjects; ﬁles, sockets, and other passive entities as
objects; and assume causality between subjects and objects
involved in the same syscall event (e.g., a process reading a
ﬁle). In general, audit logging incurs much lower overhead
than per-instruction provenance propagation. Causal graphs
can be constructed to denote both what- and how-provenance.
Provenance propagation, or tainting [8], [11], [22], [23], [31],
[37], [40], [51] works by ﬁrst assigning IDs/tags to provenance
sources (e.g., network sessions), and then propagating the
IDs through program dependencies captured during execution.
Provenance propagation usually entails set operations at the
instruction level. Eventually, the set of provenance IDs that
reaches a sink (e.g., a socket for send) denotes the sink’s
provenance. Provenance propagation usually only captures the
what-provenance.
Consider the example in Figure 1. Figure 1 (a) denotes a
simple attack. The user received a phishing email from attacker
“Yellow Spring” and opened the URL in the email through
Firefox. Upon visiting the website, a Trojan executable
for task management was saved on the local disk. Later, the
malware is executed and sends some secret to a remote host.
Fig. 1 (b) shows the events captured by audit logging. Causality
can be derived from events. Depending on the precision
demanded and the scope of the analysis, events can be captured
at different granularity (e.g., syscalls or memory accesses) and
different scopes (e.g., host or whole enterprise).
Fig. 1 (c) shows the provenance propagation approach. IDs
ys and x denote the different provenance sources. Observe
that when pine spawns Firefox, the latter inherits the
provenance of the former. The malware taskman’s prove-
nance is the union of the provenance set of Firefox and
the download URL x. At the end, we know the origins of the
stolen secret, but we do not know its history. Such propagation
can be exhibited within an application, across applications, and
across hosts.
Both approaches have pros and cons, and neither meets
the requirements for enterprise-wide APT detection/forensics.
Logging has the following limitations:
(1) Dependence explosion is a major limitation of most audit
logging. For a long-running process, an output event is as-
sumed to be causally dependent on all preceding input events,
Fig. 1: Basic approaches to provenance tracing. (a) Actual executions in a top-down order; (b) Approach I: audit logging; (c)
Approach II: provenance propagation.
and an input event is assumed to have causal inﬂuence on
all subsequent output events. Such conservative assumptions
create excessive false positive causal relations, making it
difﬁcult to reveal the true causality. In our previous work, we
proposed to divide an execution to autonomous units [27] such
that an output is only dependent on the preceding inputs within
the same unit.
In this paper, we develop ProTracer that leverages the
advantages of both approaches and overcomes their respective
limitations. It collects system events and processes them on
the ﬂy. The cost-effective online processing ﬁlters out events
that are redundant or irrelevant for provenance analysis, sub-
stantially reducing the space consumption and the size of the
generated causal graphs without affecting effectiveness.
(2) High storage overhead. According to [28], audit logging
easily generates gigabytes of log data per host every day. This
is particularly problematic for APT defense, as APT malware
tends to lurk in the victim host for a long time.
(3) Non-trivial run-time overhead. Although logging has rela-
tively lower run-time overhead compared to provenance prop-
agation because it does not require expensive per-instruction
set operations, many existing logging systems [27], [28] are
built on the default Linux audit logging infrastructure that
can cause up to 40% slow-down to the whole system due to
its poor design (Section V). This makes it undesirable in a
production environment. Researchers have proposed advanced
infrastructures [34]–[36] that can achieve much lower over-
head. However, to achieve the low overhead, these systems
usually do not perform any online event processing, but rather
just record the events, leading to substantial space consumption
and dependence explosion.
The propagation-based approach features much lower space
overhead compared to logging as it does not generate log. It
also has higher precision due to its ﬁne-grained instrumenta-
tion. However it has many limitations that hinder its application
in the real world:
(1) Substantial run-time overhead. Because propagation based
techniques track individual instructions’ execution and prop-
agate (potentially) large provenance sets (Fig. 1 (c)), they
usually incur substantial run-time overhead. State-of-the-art
implementations without hardware support incur multiple fac-
tor of slow-down [23].
(2) Lack of implicit ﬂow handling. Many propagation based
techniques have difﬁculty handling implicit ﬂow, which is
information ﬂow through control dependencies [30] (usually
induced by program predicates).
(3) Complexity in implementation. Developers have to deﬁne
provenance propagation logic for each instruction, a task
which is tedious and error-prone. This problem is exacerbated
when programs rely on third-party libraries;
internal run-
time engines (e.g., VMs); and various languages and their
run-times, which all require speciﬁc instrumentation/tracking
mechanisms.
System Goals. The goal of ProTracer is to provide efﬁcient
support for both the what-provenance and the how-provenance
queries on any system objects such as processes and ﬁles.
For example, given a corrupted ﬁle x, two what-provenance
queries are: (1) “What is the source/entry point of x?” and
(2) “which other ﬁles in the enterprise were derived from
(and corrupted by) x?” A sample how-provenance query is:
“Construct a causal graph showing the events/entities that
led to the corruption of x and those that have been further
corrupted by x.” We aim to achieve completeness. In particular,
the result of a what-provenance query on x must include all the
external entities that directly/transitively affected x; the result
of a how-provenance query must capture the set of internal
and external entities that affected x and their causal relations
with x.
The technique works as follows. It ﬁrst leverages a selective
instrumentation technique similar to BEEP [27] to partition
an execution to units, by emitting special syscalls denoting
the unit boundaries. Intuitively, an unit is an iteration of the
event handling loop that processes an external request or a UI
event. Different from [27], ProTracer does not simply log all
the syscalls and the unit related events. Instead, it alternates
between logging and provenance propagation. Logging is
conducted when changes are made to the permanent storage
or the external environment such as writing a ﬁle and sending
a packet. For other events such as ﬁle reads and network
receives, ProTracer performs coarse-grained provenance prop-
agation (tainting), which taints at the level of a unit and an
system object (e.g. ﬁle) instead of an instruction and a memory
byte. For example, if a unit receives packets from two network
sessions x1 and x2, the unit is tainted with both sources. If
later the same unit writes to a ﬁle on disk, a log entry is
emitted containing the two sources. Then if the ﬁle is read by
another unit, the unit is tainted with the two sources too. Note
that avoiding logging as much as possible reduces the space
overhead, and performing unit level and system object level
taint propagation substantially reduces the run-time overhead
compared to instruction level tainting. Unit level tainting does
not lose any precision compared to a log-all-events strategy.
Furthermore, ProTracer decouples its implementation from the
2
expensive Linux audit logging system. It builds from scratch
a highly optimized system. It has a lightweight kernel module
that simply saves events to a ring buffer. The buffer is shared
with a user space daemon that retrieves these events and
processes them using a thread pool. ProTracer features out-of-
order event processing, meaning that the event processing order
does not need to be identical to the event order, maximizing
concurrency.
Our contributions are summarized as follows.
• We propose the novel idea of combining both logging
and unit level tainting to achieve cost-effective prove-
nance tracing.
• We develop an efﬁcient run-time that features on-the-
ﬂy event processing. It not only collects system events,
but also ﬁlters out the redundant and irrelevant events
on the ﬂy. It achieves low run-time overhead by out-
of-order event processing through a thread pool.
• We build a prototype and evaluate it on different
systems with various users and workloads for over 3
months, and on a number of real-world attacks that we
reproduce. Our results show that the space consump-
tion of ProTracer is <1.28% of BEEP’s on average,
and about 7 times smaller than our previous ofﬂine
log garbage collection technique LogGC [28]. The log
generated per day is roughly 13MB without losing
precision compared to BEEP. The run-time overhead
averages <7% for servers and <5% for user systems,
which is 4-10 times lower than the default Linux
Audit Logging system, on which many techniques
including BEEP were built, and comparable to light-
weight logging systems such as Hi-Fi [34]–[36] that
simply record events without processing them.
Like most existing audit logging systems [15], [27], [28],
ProTracer trusts the kernel and any user space daemon asso-
ciated with the provenance tracing system. More discussion
about the assumptions, limitations and security analysis of
ProTracer can be found in Section VI.
II. MOTIVATION
Scenario: We will use a cyber attack scenario to motivate
our technique. It is a phishing attack, in which an employee
received an phishing email with a malicious link via pine,
an email client. The email mentions that a free beta version
of a costly program that the employee has been hoping to
own is released on the Internet. The employee was excited
and decided to try it out. He clicked the link; a new tab in
Firefox was opened; he then downloaded the ﬁle to the local
machine. However, the ﬁle is actually a back-door malware.
Later when it is executed, a back-door process is started and
sends some local ﬁle to a remote IP address.
State-of-The-Art: In BEEP [27], we observed that many pro-
grams share a common property: their execution is dominated
by event handling loops. More importantly, individual itera-
tions of these loops tend to handle relatively independent tasks
such as serving a client request or handling a UI event. These
observations were made by a study of more than 100 widely
used open-source applications such as servers, browsers, and
social networking applications. It was then proposed to par-
tition an execution to autonomous units, each corresponding
to an iteration of some event handling loop. In particular,
program analysis was developed in [27] to recognize the unit-
inducing loops, leveraging the following three observations:
(1) such loops tend to be at the top level; (2) their loop
bodies must make some I/O syscalls; and (3) their loop bodies
dominate the execution time. Binary instrumentation is hence
used to instrument the loop entry and exit points such that
special syscalls are generated to indicate unit boundaries. An
output syscall is considered only dependent on the preceding
input syscalls in the same unit, whereas in other logging
techniques [15], [16], [25], it is dependent on all the preceding
input syscalls in the whole execution, leading to dependence
explosion.
In some cases, a unit by itself may not fully cover the sub-
execution that handles an independent input. Instead, a few
inter-dependent units together constitute a semantically inde-
pendent sub-execution. In practice, there are memory depen-
dencies across unit boundaries. However, only some of them
– called workﬂow dependencies – are helpful in connecting
units that belong to the same sub-execution. Examples include
the dependencies caused by the enqueue and dequeue
operations of a task queue. In [27], inter-unit dependencies are
identiﬁed via program analysis. A small number of memory
operations that induce inter-unit dependencies are instrumented
to emit special syscalls that help constructing the dependencies
during off-line processing.
Fig. 2 shows the causal graph constructed by BEEP. The
ovals on the left represent the units of sendmail, which
checks the IP address through the Domain Name System
(DNS) (a.a.a.a), and then interacts with the authentication
server (b.b.b.b) and mail server (c.c.c.c) to fetch all emails.
An email is further processed by a separate thread, whose
unit is the one on the right of the dashed circle. The email
is further ﬁltered by procmail before it
is opened by
pine. Inside pine, the user clicks the phishing link, which
triggers Firefox. Firefox uses multiple threads to process
a request. The units in the dashed area correspond to units
of the main thread and the tab thread, which uses an IPC
channel i.i.i.i to communicate with a worker thread that
downloads the backdoor ﬁle from d.d.d.d. The malware is
later executed through bash and sends a ﬁle f to e.e.e.e.
Limitations of the State-of-the-Art. Although the causal
graphs generated by BEEP (e.g. Fig. 2) are usually precise
and concise, there are a few critical limitations that hinder the
application of BEEP in practice.
(1) Substantial space overhead. BEEP generates a few GB
log per-day for a system with a normal workload. This is
because it logs all the provenance related syscalls including
those generated by instrumentation. In [28], an ofﬂine garbage
collection (GC) technique LogGC was proposed to prune
redundant events from BEEP logs. However, it still requires
storing all the events before pruning them. During pruning, it
traverses the large log ﬁle back and forth in order to identify
the redundant events. Due to the high cost of processing large
ﬁles, one cannot afford running the GC technique frequently.
(2) Non-trivial run-time overhead. Although BEEP’s instru-
mentation is lightweight, like many other audit logging systems
3
c.c.c.c
b.b.b.b
sendmail
sendmail
pine
Firefox
d.d.d.d
Backdoor
Firefox
bash
e.e.e.e
a.a.a.a
sendmail
procmail
Mail ﬁle
Firefox
l.l.l.l
File: f
backdoor
Fig. 2: The simpliﬁed causal graph of a phishing attack generated by BEEP [27]. The ovals represent execution units; the
diamonds represent network sessions; the rectangles represent ﬁles. The nodes inside the dashed areas are those pruned away
by ProTracer.