• Set the property com.ibm.msg.client.commonservices.log.outputName in the IBM MQ classes for JMS
configuration file or as a system property on the java command.
In the following example, the property is set as a system property and identifies a specific file:
java -Djava.library.path= library_path
-Dcom.ibm.msg.client.commonservices.log.outputName=/mydir/mylog.txt
MyAppClass
IBM MQ troubleshooting and support 97
In the command, library_path is the path to the directory containing the IBM MQ classes for JMS
libraries (see Configuring the Java Native Interface (JNI) libraries ).
The values System.err and System.out can be set to send log output to the System.err and
System.out streams.
• To disable log output, set the property com.ibm.msg.client.commonservices.log.status to OFF. The
default value of this property is ON.
JMS provider version troubleshooting
Use the advice that is given here to help you to resolve common problems that can arise when you are
connecting to a queue manager with a specified provider version.
JMS 2.0 function is not supported with this connection error
• Error code: JMSCC5008
• Scenario: You receive a JMS 2.0 function is not supported with this connection error.
• Explanation: The use of the JMS 2.0 functionality is only supported when connecting to an IBM MQ 8.0
or later queue manager that is using IBM MQ messaging provider Version 8 mode.
• Solution: Change the application to not use the JMS 2.0 function, or ensure that the application
connects to an IBM MQ 8.0 queue manager that is using IBM MQ messaging provider Version 8 mode.
JMS 2.0 API is not supported with this connection error
• Error code: JMSCC5007
• Scenario: You receive aJMS 2.0 API is not supported with this connection error.
• Explanation: The use of the JMS 2.0 API is only supported when you are connecting to an IBM
WebSphere MQ 7.0 or IBM MQ 8.0 queue manager that is using IBM MQ messaging provider Normal
or Version 8 mode. You might, for example, receive this error if you are attempting to connect to an
IBM WebSphere MQ 6.0 queue manager or if you are connecting by using migration mode. This typically
happens if SHARECNV(0) or PROVIDER_VERSION=6 is specified.
• Solution: Change the application to not use the JMS 2.0 API, or ensure that the application connects to
an IBM WebSphere MQ 7.0 or IBM MQ 8.0 queue manager by using IBM MQ messaging provider Normal
or Version 8 mode.
Queue manager command level did not match the requested provider version error
• Error code: JMSFMQ0003
• Scenario: You receive a queue manager command level did not match the requested
provider versionerror.
• Explanation: The queue manager version that is specified in the provider version property on the
connection factory is not compatible with the requested queue manager. For example, you might have
specified PROVIDER_VERSION=8, and attempted to connect to a queue manager with a command level
less than 800, such as 750.
• Solution: Modify the connection factory to connect to a queue manager that can support the provider
version required.
For more information about provider version, see Configuring the JMS PROVIDERVERSION property.
PCF processing in JMS
IBM MQ Programmable Change Format (PCF) messages are a flexible, powerful way in which to query and
modify attributes of a queue manager, and the PCF classes that are provided in the IBM MQ classes for
Java provide a convenient way of accessing their functionality in a Java application. The functionality can
also be accessed from IBM MQ classes for JMS, but there is a potential problem.
98 Troubleshooting and Support for IBM MQ
The common model for processing PCF responses in JMS
A common approach to processing PCF responses in JMS is to extract the bytes payload of the
message, wrap it in a DataInputStream and pass it to the com.ibm.mq.headers.pcf.PCFMessage
constructor.
Message m = consumer.receive(10000);
//Reconstitute the PCF response.
ByteArrayInputStream bais =
new ByteArrayInputStream(((BytesMessage)m).getBody(byte[].class));
DataInput di = new DataInputStream(bais);
PCFMessage pcfResponseMessage = new PCFMessage(di);
See Using the IBM MQ Headers package for some examples.
Unfortunately this is not a totally reliable approach for all platforms - in general the approach works for
big-endian platforms, but not for little-endian platforms.
What is the problem?
The problem is that in parsing the message headers, the PCFMessage class must deal with issues of
numeric encoding - the headers contain length fields that are in some encoding that is big-endian or
little-endian.
If you pass a pure DataInputStream to the constructor, the PCFMessage class has no good indication
of the encoding, and must assume a default, quite possibly incorrectly.
If this situation arises, you will probably see a "MQRCCF_STRUCTURE_TYPE_ERROR" (reason code 3013)
in the constructor:
com.ibm.mq.headers.MQDataException: MQJE001: Completion Code '2', Reason '3013'.
at com.ibm.mq.headers.pcf.PCFParameter.nextParameter(PCFParameter.java:167)
at com.ibm.mq.headers.pcf.PCFMessage.initialize(PCFMessage.java:854)
at com.ibm.mq.headers.pcf.PCFMessage.(PCFMessage.java:156)
This message almost invariably means that the encoding has been misinterpreted. The probable reason
for this is that the data that has been read is little-endian data which has been interpreted as big-endian.
The solution
The way to avoid this problem is to pass the PCFMessage constructor something that tells the
constructor the numeric encoding of the data it is working with.
To do this, make an MQMessage from the data received.
The following code is an outline example of the code you might use.
Attention: The code is an outline example only and does not contain any error handling
information.
// get a response into a JMS Message
Message receivedMessage = consumer.receive(10000);
BytesMessage bytesMessage = (BytesMessage) receivedMessage;
byte[] bytesreceived = new byte[(int) bytesMessage.getBodyLength()];
bytesMessage.readBytes(bytesreceived);
// convert to MQMessage then to PCFMessage
MQMessage mqMsg = new MQMessage();
mqMsg.write(bytesreceived);
mqMsg.encoding = receivedMessage.getIntProperty("JMS_IBM_Encoding");
mqMsg.format = receivedMessage.getStringProperty("JMS_IBM_Format");
mqMsg.seek(0);
PCFMessage pcfMsg = new PCFMessage(mqMsg);
IBM MQ troubleshooting and support 99
JMS connection pool error handling
Connection pool error handling is carried out by various methods of a purge policy.
The connection pool purge policy comes into operation if an error is detected when an application is using
a JMS connection to a JMS provider. The connection manager can either:
• Close only the connection that encountered the problem. This is known as the
FailingConnectionOnly purge policy and is the default behavior.
Any other connections created from the factory, that is, those in use by other applications, and those
that are in the free pool of the factory, are left alone.
• Close the connection that encountered the problem, throw away any connections in the free pool of the
factory, and mark any in-use connections as stale.
The next time the application that is using the connection tries to perform a connection-based
operation, the application receives a StaleConnectionException. For this behavior, set the purge
policy to Entire Pool.
Purge policy - failing connection only
Use the example described in How MDB listener ports use the connection pool. Two MDBs are deployed
into the application server, each one using a different listener port. The listener ports both use the
jms/CF1 connection factory.
After 600 seconds, you stop the first listener, and the connection that this listener port was using is
returned to the connection pool.
If the second listener encounters a network error while polling the JMS destination, the listener port shuts
down. Because the purge policy for the jms/CF1 connection factory is set to FailingConnectionOnly,
the connection manager throws away only the connection that was used by the second listener. The
connection in the free pool remains where it is.
If you now restart the second listener, the connection manager passes the connection from the free pool
to the listener.
Purge policy - entire pool
For this situation, assume that you have three MDBs installed into your application server, each one using
its own listener port. The listener ports have created connections from the jms/CF1 factory. After a
period of time you stop the first listener, and its connection, c1, is put into the jms/CF1 free pool.
When the second listener detects a network error, it shuts itself down and closes c2. The connection
manager now closes the connection in the free pool. However, the connection being used by third listener
remains.
What should you set the purge policy to?
As previously stated, the default value of the purge policy for JMS connection pools is
FailingConnectionOnly.
However, setting the purge policy to EntirePool is a better option. In most cases, if an application
detects a network error on its connection to the JMS provider, it is likely that all open connections created
from the same connection factory have the same problem.
If the purge policy is set to FailingConnectionOnly, the connection manager leaves all of the
connections in the free pool. The next time an application tries to create a connection to the JMS provider,
the connection manager returns one from the free pool if there is one available. However, when the
application tries to use the connection, it encounters the same network problem as the first application.
Now, consider the same situation with the purge policy set to EntirePool. As soon as the first
application encounters the network problem, the connection manager discards the failing connection
and closes all connections in the free pool for that factory.
100 Troubleshooting and Support for IBM MQ
When a new application starts up and tries to create a connection from the factory, the connection
manager tries to create a new one, as the free pool is empty. Assuming that the network problem has
been resolved, the connection returned to the application is valid.
Connection pool errors while trying to create a JMS Context
If an error occurs while you are trying to create a JMS Context, it is possible to determine from the error
message if the top-level pool or lower-level pool had the issue.
How pools are used for Contexts
When using Connection and Sessions, there are pools for each type of object; a similar model is followed
for Contexts.
A typical application that uses distributed transactions involves both messaging and non-messaging
workloads in the same transaction.
Assuming that no work is currently working, and the application makes its first createConnection method
call, a context facade or proxy is created in the equivalent of the connection pool (the top-level pool).
Another object is created in the equivalent of the session pool. This second object encapsulates the
underlying JMS Context (lower-level pool).
Pooling, as a concept, is used to permit an application to scale. Many threads are able to access a
constrained set of resources. In this example, another thread will execute the createContext method call
to get a context from the pool. Should other threads still be doing messaging work, then the top-level pool
is expanded to provide an additional context for the requesting thread.
In the case where a thread requests a context and the messaging work has completed but the non-
messaging work has not, so the transaction is not complete, the lower-level pool is expanded. The
top-level context proxy remains assigned to the transaction until that transaction is resolved, so cannot
be assigned to another transaction.
In the case of the lower pool becoming full, this means that the non-messaging work is taking potentially
a long time.
In the case of the top-level pool becoming full, this means that the overall messaging work is taking a
while and the pool should be expanded.
Identifying which pool an error originated from
You can determine the pool in which an error originated from the error message text:
• For the top-level pool, the message text is Failed to create context. This message means that
the top-level pool is full of Context-proxy objects, all of which have currently running transactions that
are performing messaging.
• For the lower-level pool, the message text is Failed to set up new JMSContext. This message
means that although a connect-proxy is available, it is still necessary to wait for non-messaging work to
complete.
Top-level pool example (Jakarta Messaging 3.0)
***********************[8/19/16 10:10:48:643 UTC] 000000a2
LocalExceptio E CNTR0020E: EJB threw an unexpected (non-declared) exception during
invocation of method "onMessage" on bean
"BeanId(SibSVTLiteMDB#SibSVTLiteMDBXA_RecoveryEJB_undeployed.jar#QueueReceiver, null)".
Exception data: jakarta.jms.JMSRuntimeException: Failed to create context
at com.ibm.ejs.jms.JMSCMUtils.mapToJMSRuntimeException(JMSCMUtils.java:522)
at
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContextInternal(JMSConnectionFactoryHandle.java:4
49)
at
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContext(JMSConnectionFactoryHandle.java:335)
at sib.test.svt.lite.mdb.xa.SVTMDBBase.sendReplyMessage(SVTMDBBase.java:554)
at sib.test.svt.lite.mdb.xa.QueueReceiverBean.onMessage(QueueReceiverBean.java:128)
IBM MQ troubleshooting and support 101
at
sib.test.svt.lite.mdb.xa.MDBProxyQueueReceiver_37ea5ce9.onMessage(MDBProxyQueueReceiver_37ea5ce9.j
ava)
at
com.ibm.mq.jakarta.connector.inbound.MessageEndpointWrapper.onMessage(MessageEndpointWrapper.java:
151)
at com.ibm.mq.jms.MQSession$FacadeMessageListener.onMessage(MQSession.java:129)
at com.ibm.msg.client.jms.internal.JmsSessionImpl.run(JmsSessionImpl.java:3236)
at com.ibm.mq.jms.MQSession.run(MQSession.java:937)
at com.ibm.mq.jakarta.connector.inbound.ASFWorkImpl.doDelivery(ASFWorkImpl.java:104)
at
com.ibm.mq.jakarta.connector.inbound.AbstractWorkImpl.run(AbstractWorkImpl.java:233)
at com.ibm.ejs.j2c.work.WorkProxy.run(WorkProxy.java:668)
at com.ibm.ws.util.ThreadPool$Worker.run(ThreadPool.java:1892)
Caused by: com.ibm.websphere.ce.j2c.ConnectionWaitTimeoutException:
CWTE_NORMAL_J2CA1009
at com.ibm.ejs.j2c.FreePool.createOrWaitForConnection(FreePool.java:1783)
at com.ibm.ejs.j2c.PoolManager.reserve(PoolManager.java:3896)
at com.ibm.ejs.j2c.PoolManager.reserve(PoolManager.java:3116)
at com.ibm.ejs.j2c.ConnectionManager.allocateMCWrapper(ConnectionManager.java:1548)
at com.ibm.ejs.j2c.ConnectionManager.allocateConnection(ConnectionManager.java:1031)
at
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContextInternal(JMSConnectionFactoryHandle.java:4
43)
... 12 more
Top-level pool example (JMS 2.0)
***********************[8/19/16 10:10:48:643 UTC] 000000a2
LocalExceptio E CNTR0020E: EJB threw an unexpected (non-declared) exception during
invocation of method "onMessage" on bean
"BeanId(SibSVTLiteMDB#SibSVTLiteMDBXA_RecoveryEJB_undeployed.jar#QueueReceiver, null)".
Exception data: javax.jms.JMSRuntimeException: Failed to create context
at com.ibm.ejs.jms.JMSCMUtils.mapToJMSRuntimeException(JMSCMUtils.java:522)
at
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContextInternal(JMSConnectionFactoryHandle.java:4
49)
at
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContext(JMSConnectionFactoryHandle.java:335)
at sib.test.svt.lite.mdb.xa.SVTMDBBase.sendReplyMessage(SVTMDBBase.java:554)
at sib.test.svt.lite.mdb.xa.QueueReceiverBean.onMessage(QueueReceiverBean.java:128)
at
sib.test.svt.lite.mdb.xa.MDBProxyQueueReceiver_37ea5ce9.onMessage(MDBProxyQueueReceiver_37ea5ce9.j
ava)
at
com.ibm.mq.connector.inbound.MessageEndpointWrapper.onMessage(MessageEndpointWrapper.java:151)
at com.ibm.mq.jms.MQSession$FacadeMessageListener.onMessage(MQSession.java:129)
at com.ibm.msg.client.jms.internal.JmsSessionImpl.run(JmsSessionImpl.java:3236)
at com.ibm.mq.jms.MQSession.run(MQSession.java:937)
at com.ibm.mq.connector.inbound.ASFWorkImpl.doDelivery(ASFWorkImpl.java:104)
at com.ibm.mq.connector.inbound.AbstractWorkImpl.run(AbstractWorkImpl.java:233)
at com.ibm.ejs.j2c.work.WorkProxy.run(WorkProxy.java:668)
at com.ibm.ws.util.ThreadPool$Worker.run(ThreadPool.java:1892)
Caused by: com.ibm.websphere.ce.j2c.ConnectionWaitTimeoutException:
CWTE_NORMAL_J2CA1009
at com.ibm.ejs.j2c.FreePool.createOrWaitForConnection(FreePool.java:1783)
at com.ibm.ejs.j2c.PoolManager.reserve(PoolManager.java:3896)
at com.ibm.ejs.j2c.PoolManager.reserve(PoolManager.java:3116)
at com.ibm.ejs.j2c.ConnectionManager.allocateMCWrapper(ConnectionManager.java:1548)
at com.ibm.ejs.j2c.ConnectionManager.allocateConnection(ConnectionManager.java:1031)
at
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContextInternal(JMSConnectionFactoryHandle.java:4
43)
... 12 more
Lower-level pool example (Jakarta Messaging 3.0)
***********************
[8/19/16 9:44:44:754 UTC] 000000ac SibMessage W [:] CWSJY0003W: MQJCA4004: Message delivery to
an MDB
'sib.test.svt.lite.mdb.xa.MDBProxyQueueReceiver_37ea5ce9@505d4b68
(BeanId(SibSVTLiteMDB#SibSVTLiteMDBXA_RecoveryEJB_undeployed.jar#QueueReceiver, null))' failed
with exception:
'nested exception is: jakarta.jms.JMSRuntimeException: Failed to set up new JMSContext'.
ˆC[root@username-instance-2 server1]# vi SystemOut.log
102 Troubleshooting and Support for IBM MQ
:com.ibm.ejs.j2c.work.WorkProxy.run(WorkProxy.java:668)
: com.ibm.ws.util.ThreadPool$Worker.run(ThreadPool.java:1892)
Caused by [1] --> Message : jakarta.jms.JMSRuntimeException: Failed to set up new
JMSContext
Class : class jakarta.jms.JMSRuntimeException
Stack :
com.ibm.ejs.jms.JMSCMUtils.mapToJMSRuntimeException(JMSCMUtils.java:522)
:
com.ibm.ejs.jms.JMSContextHandle.setupInternalContext(JMSContextHandle.java:241)
:
com.ibm.ejs.jms.JMSManagedConnection.getConnection(JMSManagedConnection.java:783)
:
com.ibm.ejs.j2c.MCWrapper.getConnection(MCWrapper.java:2336)
:
com.ibm.ejs.j2c.ConnectionManager.allocateConnection(ConnectionManager.java:1064)
:
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContextInternal(JMSConnectionFactoryHandle.java:4
43)
:
com.ibm.ejs.jms.JMSConnectionFactoryHandle.createContext(JMSConnectionFactoryHandle.java:335)
:
sib.test.svt.lite.mdb.xa.SVTMDBBase.sendReplyMessage(SVTMDBBase.java:554)
:
sib.test.svt.lite.mdb.xa.QueueReceiverBean.onMessage(QueueReceiverBean.java:128)
: