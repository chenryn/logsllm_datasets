A. Attacks Settings
The detailed parameter settings of all the attacks are sum-
marized in Table XIII.
B. Defense Settings
• NAT: The loss function of NAT is weighted with 100%
normal examples and 30% AEs generated by LLC. For
MNIST,  is randomly chosen from a normal distribution
N (μ = 0, σ = 50) and then clipped into interval [0, 0.3]. For
CIFAR-10,  is randomly chosen from a normal distribution
N (μ = 0, σ = 15) and clipped into interval [0, 0.1].
• EAT: EAT augments training data with AEs generated
by R+FGSM on 4 different pre-trained models. For MINST,
 = 0.3 and α = 0.05 are set for R+FGSM. For CIFAR-10,
 = 0.0625 and α = 0.03125 are set for R+FGSM.
• PAT: The PAT method retrains the model with only AEs
generated by the PGD attack. For MNIST: attack steps = 40,
step size = 0.01 and  = 0.3; For CIFAR-10: attack steps =
7, step size = 0.007843,  = 0.03137.
• DD: For both MNIST and CIFAR-10, T is set to be 50.
• IGR: The λ regularization terms of MNIST and CIFAR-
• EIT: In our evaluation, we orderly employ the following
10 are set to 316 and 10, respectively.
four image transformation techniques.
1) Image Crop and Rescaling. For MINST,
images are
cropped from 28*28 to 26*26, and then rescaled back to
(cid:23)(cid:25)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:30 UTC from IEEE Xplore.  Restrictions apply. 
PARAMETER SETTING FOR ALL ADVERSARIAL ATTACKS IN EVALUATIONS
TABLE XIII
Attacks
t
e
s
a
t
a
D
UA/
TA
Objec-
tive
Attacks
FGSM
 = 0.3
 = 0.5
R+FGSM
U-MI-FGSM
BIM
PGD
UAP
DF
OM
LLC
R+LLC
ILLC
JSMA
BLB
T-MI-FGSM
L∞
 = 0.3
UA
L2
L∞
 = 0.3
L0
TA
T
S
I
N
M
L2
CW2
EAD
FGSM
κ = 0
κ = 20
EN
L1
 = 0.1
 = 0.2
R+FGSM
L∞
 = 0.1
UA
0
1
-
R
A
F
I
C
L2
L∞
 = 0.1
L0
TA
U-MI-FGSM
BIM
PGD
UAP
DF
OM
LLC
R+LLC
ILLC
JSMA
BLB
T-MI-FGSM
Conﬁgurations
 = 0.3
 = 0.5
overshoot=0.02
batch size=1000;
initial const=0.02;
bin search steps=4
 = 0.3
None
batch size=10;
learning rate=0.02
batch size=10;
learning rate=0.02
 = 0.1
 = 0.2
 = 0.15
 = 0.3
 = 0.3
 = 0.3
 = 0.3
 =0.15
 = 0.3
 = 0.3
θ = 1
κ = 0
κ = 0
 = 0.05
 = 0.1
 = 0.1
 = 0.1
 = 0.1
α = 0.15
eps iter=0.05
eps iter=0.05
eps iter=0.05
fool rate=30%
max iter=50
learning rate=0.2;
noise count=20;
noise mag=0.3
α = 0.15
eps iter=0.05
eps iter=0.05
γ = 0.1
box=-0.5, 0.5;
init const=0.001
box=-0.5, 0.5;
init const=0.001
batch size=10;
β = 1e − 3
batch size=10;
β = 1e − 3
α = 0.05
eps iter=0.01
eps iter=0.01
eps iter=0.01
fool rate=80%
max iter=50
α = 0.05
eps iter=0.01
eps iter=0.01
γ = 0.1
box=-0.5, 0.5;
init const=0.001
box=-0.5, 0.5;
init const=0.001
batch size=10;
β = 1e − 3
batch size=10;
β = 1e − 3
overshoot=0.02
batch size=1;
bin search steps=4;
initial const=1
learning rate=0.02;
noise count=20;
noise mag=8/255
 =0.05
 = 0.1
 = 0.1
θ = 1
 = 0.1
None
L2
CW2
EAD
κ = 0
κ = 20
EN
L1
batch size=10;
learning rate=0.02
batch size=10;
learning rate=0.02
κ = 0
κ = 0
28*28; For CIFAR-10, images are cropped from 32*32
to 30*30, and then rescaled back to 32*32.
2) Total Variance Minimization. We employ a special-
purpose solver based on the split Bregman method with
p = 2 and λT V = 0.03.
3) JPEG Compression. We perform JPEG compression at
quality level 85 (out of 100).
4) Bit-depth Reduction. We set depth = 4.
• RT: For MNIST, random resizing layer: (28 ∗ 28) →
(rnd∗rnd) and random padding layer: (rnd∗rnd) → (31∗31)
where rnd is a random integer between 28 and 31 from a
uniform distribution; For CIFAR-10, random resizing layer:
(32 ∗ 32) → (rnd ∗ rnd) and random padding layer: (rnd ∗
rnd) → (36 ∗ 36) where rnd is a random integer between 32
and 36 from a uniform distribution.
• PD: For MNIST, the BP D of its PixelCNN model is
set to 0.8836 and the defense parameter def end is 0.3; For
CIFAR-10, the BP D of its PixelCNN model is set to 3.0847
and the defense parameter def end is 0.0627.
• TE: For MNIST, the TE-based model use 16 level dis-
cretization and adversarially trained with the LS-PGA attack
( = 0.3, ξ = 0.01 and 40 steps); For CIFAR-10, the TE-based
model use 16 level discretization and adversarially trained with
the LS-PGA attack ( = 0.031, ξ = 0.01 and 7 steps).
• RC: We sample 1000 data points from the hypercube,
i.e., m = 1000. For MNIST, the length r of hypercube is set
to be 0.3; For CIFAR-10, r is set to be 0.02.
• LID: For MNIST, we train a logistic regression classiﬁer
where the training set consists of a positive set and a negative
set. Particularly, the positive set is the set of AEs generated
by FGSM with  = 0.3; the negative set consists of normal
testing examples and their corresponding noisy examples with
L2 Gaussian noise. For CIFAR-10, we also train a logistic
regression classiﬁer with the similar training set, but the  of
FGSM is set to 0.1. As for both classiﬁers, we set k = 20 and
minibatch = 100 in the LID algorithm.
• FS: For MNIST, we ﬁrst employ two squeezers: Bit
Depth (1bit) and Median Smoothing (2×2), and then train the
classiﬁer whose FPR is controlled at around 4%; For CIFAR-
10, we employ three squeezers: Bit Depth (5bit), Median
Smoothing (2×2) and Non-local Means (13-3-2), and then
train the classiﬁer with about 4% FPR.
• MagNet: For MNIST, we employ two detectors: recon-
struction error-based detectors that use the L1 and L2 norm,
and then train the classiﬁer whose FPR is controlled at around
4%; For CIFAR-10, we employ three detectors: reconstruction
L1 error-based detector and two probability divergence-based
detectors with temperature T of 10 and 40, respectively; Also,
we control the FPR of classiﬁer at around 4%.
X. SUPPLEMENTARY EVALUATION RESULTS
In this part, we provide more evaluation results of MNIST
for Section IV. We provide the utility evaluation results of
existing attacks in Table XIV. In Table XV, we report the
classiﬁcation performance of all complete defenses against
existing attacks. In Table XVI, we also report the detection per-
formance of detection-only defenses against existing attacks.
XI. SUPPLEMENTARY RESULTS OF CASE STUDIES
In this part, we provide more results of MNIST for Sec-
tion V. In Table XVII, we report
the transferability per-
formance of all attacks. We also provide the classiﬁcation
performance of different ensembles in Table XVIII.
(cid:23)(cid:25)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:30 UTC from IEEE Xplore.  Restrictions apply. 
s
t
e
s
a
t
a
D
UA/
TA
Objec-
tive
Attack
L∞
 = 0.3
UAs
T
S
I
N
M
TAs
L2
L∞
 = 0.3
L0
L2
UTILITY EVALUATION RESULTS OF ALL ATTACKS ON MNIST
TABLE XIV
Misclassiﬁcation
ACAC ACTC
MR
0.065
0.762
30.4%
0.071
0.705
44.8%
0.073
0.766
34.2%
0.004
0.995
75.6%
0.996
0.004
82.4%
0.008
0.989
70.4%
0.089
30.3%
0.757
0.405
100.0% 0.543
0.048
100.0% 0.834
0.062
0.683
5.6%
4.0%
0.651
0.090
0.012
0.865
59.4%
0.028
0.851
86.4%
0.169
76.4%
0.605
0.200
100.0% 0.677
0.318
0.326
99.7%
0.001
0.995
97.4%
100%
0.361
0.322
0.312
0.371
100%
L0
0.398
0.382
0.540
0.740
0.825
0.658
0.745
0.359
0.214
0.320
0.534
0.757
0.672
0.052
0.373
0.342
0.393
0.200
0.189
ALDp
Imperceptibility
ASS
0.554
0.350
0.553
0.572
0.564
0.534
0.456
0.927
0.795
0.519
0.437
0.572
0.524
0.768
0.910
0.925
0.772
0.933
0.934
L∞
0.300
0.500
0.300
0.300
0.300
0.300
0.300
0.492
0.693
0.300
0.300
0.300
0.300
1.000
0.536
0.528
0.842
0.620
0.657
L2
4.887
7.795
4.866
4.527
4.918
5.343