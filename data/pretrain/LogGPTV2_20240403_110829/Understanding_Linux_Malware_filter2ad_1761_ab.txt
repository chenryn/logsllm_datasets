new analysis modules and designed new techniques to address
the problem. Our framework was also designed to keep track
of which version of each module was responsible for the
extraction of any given piece of information, thus allowing
us to dynamically update and improve each analysis routine
without the need to re-start each time the experiments from
scratch.
Our ﬁnal analysis pipeline included a collection of exist-
ing state-of-the-art solutions (such as AVClass [5], IDA Pro,
radare2 [6], and Nucleus [7]) as well as completely new tools
we explicitly designed for this paper. Due to space limitations
we cannot present each component
in
the rest of this section we brieﬂy summarize some of the
techniques we used in our experiments, organized in three
different groups: File and Metadata Analysis, Static Analysis,
and Dynamic Analysis components.
in details. Instead,
A. Data Collection
To retrieve data for our study we used the VirusTotal
intelligence API to fetch the reports of every ELF ﬁle submitted
163
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:40 UTC from IEEE Xplore.  Restrictions apply. 













 



Fig. 1. Overview of our analysis pipeline.
between November 2016 and November 2017. Based on the
content of the reports, we downloaded 200 candidate samples
per day. Our selection criteria were designed to minimize non-
Linux binaries and to select at least one sample for each family
observed during the day. We also split our selection in two
groups: 140 samples taken from those with more than ﬁve AV
positive matches, and 60 samples with an AV score between
one and ﬁve.
B. File & Metadata Analysis
The ﬁrst phase of our analysis focuses on the ﬁle itself.
Certain ﬁelds contained in the ELF ﬁle format are required
at runtime by the operating system, and therefore need to
provide reliable information about the architecture on which
the application is supposed to run and the type of code
(e.g., executable or shared object) contained in the ﬁle. We
implemented our custom parser for the ELF format because
the existing ones (as explained in Section V-A) were often
unable to cope with malformed ﬁelds, unexpected values, or
missing information.
We use the data extracted from each ﬁle for two purposes.
First, to ﬁlter out ﬁles that were not relevant for our analysis.
For instance, shared libraries, core dumps, corrupted ﬁles, or
executables designed for other operating systems (e.g., when
a sample imported an Android library). Second, we use the
information to identify any anomalous ﬁle structure that, while
not preventing the sample to run, could still be used as anti-
analysis routine and prevent existing tools to correctly process
the ﬁle (see Section V-A for more details about our ﬁndings).
Finally, as part of this ﬁrst phase of our pipeline, we also
extract from the VirusTotal reports the AV labels for each
sample and fed them to the AVClass tool to obtain a normalized
name for the malware family. AVClass, recently proposed by
Sebasti´an et al. [5], implements a state-of-the-art technique to
normalize, remove generic tokens, and detect aliases among
a set of AV labels assigned to a malware sample. Therefore,
whenever it is able to output a name, it means that there was
a general consensus among different antivirus on the class
(family) the malware belongs to.
C. Static Analysis
Our static analysis phase includes two tasks: binary code
task relied on a
analysis and packing detection. The ﬁrst
number of custom IDA Pro scripts to extract several code
metrics—including the number of functions, their size and
cyclomatic complexity, their overall coverage (i.e., the fractions
of the .text section and PT_LOAD segments covered by the
recognized functions), the presence of overlapping instructions
and other assembly tricks, the direct invocation of system
calls, and the number of direct/indirect branch instructions. In
this phase we also computed aggregated metrics, such as the
distribution of opcodes, or a rolling entropy of the different
code and data sections. This information is used for statistical
purposes, but also integrated in other analysis components, for
instance to identify anti-analysis behaviors or packed samples.
The second task of the static analysis phase consists of
combining the information extracted so far from the ELF
headers and the binary code analysis to identify likely packed
applications (see Section V-E for more details). Binaries that
could be statically unpacked (e.g., in the common case of UPX)
were processed at this stage and the result fed back to be
statically analyzed again. Samples that we could not unpack
statically were marked in the database for a subsequent more
ﬁne-grained dynamic attempt.
D. Dynamic Analysis
We performed two types of dynamic analysis in our study:
a ﬁve-minute execution inside an instrumented emulator, and
a custom packing analysis and unpacking attempt. For the
emulation, we implemented two types of dynamic sandboxes:
a KVM-based virtualized sandbox with hardware support for
x86 and x86-64 architectures, and a set of QEMU-based
emulated sandboxes for ARM 32-bit little-endian, MIPS 32-
bit big-endian, and PowerPC 32-bit. These ﬁve sandboxes
were nested inside an outer VM dedicated to dispatch each
sample depending on its architecture. Our system also main-
tained several snapshots of all VMs, each corresponding to a
different conﬁgurations to choose from (e.g., execution under
user or root accounts and glibc or uClibc setup). All VMs
were equipped with additional libraries, the list of which was
collected during the static analysis phase, as well as popular
loaders (such as the uClibc commonly used in embedded
systems).
For the instrumentation we relied on SystemTap [8] to
implement kernel probes (kprobes) and user probes (uprobes).
164
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:40 UTC from IEEE Xplore.  Restrictions apply. 
While, according to its documentation, SystemTap should be
supported on a variety of different architectures (such as x86,
x86-64, ARM, aarch64, MIPS, and PowerPC), in practice we
needed to patch its code to support ARM and MIPS with
o32 ABI. Our patches include ﬁxes on syscall numbers, CPU
registers naming and offsets, and the routines required to
extract the syscall arguments from the stack. We designed our
SystemTap probes to collect every system call, along with its
arguments and return value, and the instruction pointer from
which the syscall was invoked. We also recompiled the glibc
to add uprobes designed to collect, when possible, additional
information on string and memory manipulation functions.
the execution of the sample,
At the end of the execution, each sandbox returns a text
ﬁle containing the full trace of system calls and userspace
functions. This trace is then immediately parsed to identify
useful feedback information for the sandbox. For example, this
preliminary analysis can identify missing components (such as
libraries and loaders) or detect if a sample tested its user per-
missions or attempted to perform an action that failed because
of insufﬁcient permissions. In this case, our system would
immediately repeat
this time
with root privileges. As explained in Section V-D, we later
compare the two traces collected with different users as part of
our differential analysis to identify how the sample behavior
was affected by the privilege level. Finally, the preliminary
trace analysis can also report to the analyst any error that
prevented the sample to run in our system. As an example of
these warnings, we encountered a number of ARM samples
that crashed because of a four-byte misalignment between
the physical and virtual address of their LOAD segments.
These samples were probably designed to infect an ARM-
based system whose kernel would memory map segments by
considering their physical address, something that does not
happen in common desktop Linux distributions. We extended
our system with a component designed to identify these cases
by looking at the ELF headers and ﬁx the data alignment before
passing them to the dynamic analysis stage.
To avoid hindering the execution and miss important code
paths, we gave samples partial network access, while mon-
itoring the trafﬁc for signs of abuse. Although not an ideal
solution, a similar approach has been previously adopted in
other behavioral analysis experiments [4], [9] as it is the only
way to observe the full behavior of a sample.
Our system also record PCAP ﬁles of the network trafﬁc,
due to space limitations we will not discuss their analysis
as this is the only aspect of Linux-based malware that was
already partially studied in previous works [4]. Finally, to
dynamically unpack unknown UPX variants we developed a
tool based on Unicorn [10]. The system emulates instructions
on multiple architectures and behaves like a tiny kernel that
exports the limited set of system calls used by UPX during
unpacking (supporting a combination of different system call
tables and system call ABIs). As we explain in Section V-E,
this approach allowed us to automatically unpack all but three
malware samples in our dataset.
DISTRIBUTION OF THE 10,548 DOWNLOADED SAMPLES ACROSS
TABLE I
ARCHITECTURES
Architecture
X86-64
MIPS I
PowerPC
Motorola 68000
Sparc
Intel 80386
ARM 32-bit
Hitachi SH
AArch64 (ARM 64-bit)
others
Samples
Percentage
3018
2120
1569
1216
1170
720
555
130
47
3
28.61%
20.10%
14.87%
11.53%
11.09%
6.83%
5.26%
1.23%
0.45%
0.03%
IV. DATASET
Our ﬁnal dataset, after the ﬁltering stage, consisted of 10,548
ELF executables, covering more than ten different architectures
(see Table I for a breakdown of the collected samples). Note
again how the distribution differs from other datasets collected
only by using honeypots: x86, ARM 32-bit, and MIPS 32-bit
covered 75% of the data used by Antonakakis et al. [4] on the
Mirai botnet, but only account for 32% of our samples.
We report detailed statistics about the distribution of samples
in our dataset in Appendix. Here we just want to focus on
their broad variety and on the large differences that exist
among all features we extracted in our database. For example,
our set of Linux-based malware vary considerably in size,
from a minimum of 134 bytes (a simple backdoor) to a
maximum of 14.8 megabytes (a botnet coded in Go). IDA
Pro was able to recognize (in dynamically linked binaries)
from a minimum of zero (in two samples) to a maximum of
5685 unique functions. Moreover, we extracted from the ELF
header of dynamically linked malware the symbols imported
from external libraries—which can give an idea of the most
commonly used functionalities. Most samples import between
10 and 100 symbols. Interestingly, there are more than 10% of
the samples that use malloc but never use free. And while
socket is one of the most common functions (conﬁrming the
importance that interconnected devices have nowadays) less
than 50% of the binaries requests ﬁle-based routines (such as
fopen). Finally, entropy plays an important role to identify
potential packers or encrypted binary blobs. The vast majority
of the binaries in our dataset has entropy around six, a common
value for compiled but not packed code. However, one sample
had entropy of only 0.98, due to large blocks of null bytes
inserted in the data segment.
A. Malware Families
The AVClass tool was able to associate a family (108 in
total) to 83% of the samples in our dataset. As expected, bot-
nets, often dedicated to run DDoS attacks, dominate the Linux-
based malware landscape—accounting for 69% of our samples
spread over more than 25 families. One of the reasons for this
prevalence is that attackers often harvest poorly protected IoT
devices to join large remotely controlled botnets. This task is
165
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:40 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II
ELF HEADER MANIPULATION
ELF SAMPLES THAT CANNOT BE PROPERLY PARSED BY KNOWN TOOLS
TABLE III
Technique
Segment header table pointing beyond ﬁle data
Overlapping ELF header/segment
Wrong string table index (e_shstrndx)
Section header table pointing beyond ﬁle data
Total Corrupted
Samples
Percentage
1
2
60
178
211
0.01%
0.02%
0.57%
1.69%
2.00%
Program
readelf 2.26.1
GDB 7.11.1
pyelftools 0.24
IDA Pro 7
Errors on Malformed Samples
166 / 211
157 / 211
107 / 211
/ 211
-
greatly simpliﬁed by the availability of online services like
Shodan [11] or scanning tools like ZMap [12] that can be
used to quickly locate possible targets. Moreover, while it may
be difﬁcult to monetize the compromise of small embedded
devices that do not contain any relevant data, it is still easy to
combine their limited power to run large-scale denial of service
attacks. Another possible explanation for the large number of
botnet samples in our dataset is that the source code of some
of these malware family is publicly available—resulting in a
large number of variations and copycat software.
Despite their extreme popularity, botnets are not the only
form of Linux-based malware. In fact, our dataset contains also
thousands of samples belonging to other categories, including
backdoors, ransomware, cryptocurrency miners, bankers, tradi-
tional ﬁle infectors, privilege escalation tools, rootkits, mailers,
worms, RAT programs used in APT campaigns, and even CGI-
based binary webshells. While these malware dominates the
number of families in our dataset, many of them exist in a
single variant, thus resulting in a lower number of samples.
While we may discuss particular families when we present
our analysis results, in the rest of the paper we prefer to
aggregate ﬁgures by counting individual samples. This is
because even though samples in the same family may share
a common goal and overall structure, they can be very diverse
in the individual low-level techniques and tricks they employ
(e.g., to achieve persistence or obfuscate the program code).
We will return to this aspect of Linux malware and discuss its
implications in Section VI.
V. UNDER THE HOOD
is not
In this section we present a detailed overview of a number
of interesting behaviors we have identiﬁed in Linux malware
and, when possible, we provide detailed statistics about the