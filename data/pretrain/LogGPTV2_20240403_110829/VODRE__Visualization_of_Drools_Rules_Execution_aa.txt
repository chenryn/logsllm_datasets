VODRE: Visualisation of Drools Rules Execution
Maxim Lapaev, Maxim Kolchin 
Saint Petersburg National Research University of Information Technologies, Mechanics and Optics 
Saint-Petersburg, Russia 
PI:EMAIL, kolchinmax@niuitmo.ruAbstract—Knowledge-based Systems and Expert Systems, in particular, are expensive to build and difficult to validate and debug because of their complexity and dynamism. Therefore, it is not easy for knowledge engineer and domain expert to identify the gaps and mistakes in knowledge base. Unit testing is unable to cover validation process at all stages, in many cases manual thorough review of decision process is needed. In this paper we spot main approaches to validation and verification issue and describe a component that helps to debug a knowledge base by visualising execution of rules that derive a particular result. This component is developed for Knowledge-based Systems built on Drools Platform1and we demonstrate application of this component in a knowledge-based engineering system for structural optical design.I. INTRODUCTIONThe standard of engineering when a decision could be made only with a help of reference book, pencil and calcu-lations is far behind. Today’s industry requires efficient on-the-fly solutions and decisions. Sometimes not only effective decision is important but the time to produce the solution, as well. Nowadays the majority of knowledge-based systems are complex artificial products which are able to take the place of a real expert in a particular knowledge domain. Expert systems (ES) became an indispensable part of industry and reached almost all fields of modern life: finances, cartography, military, industry, medicine, science and so forth [1], [2], [3], [4]. Not only do expert systems simplify the process, they make it more reliable and qualitative. However, ESs are aimed not at replacing an expert but at becoming an assistant. Need for urgent solutions requiring time-consuming calculations and analysis and lack of highly-qualified domain experts make ES development to become a perspective trend.Although quality and efficiency of ES has improved dra-matically over last decades, knowledge-based system engineers still face difficulties. On the one hand, ES must be reliable and produce right and optimal solutions quickly, on the other hand, test and debug toolkit still leaves much to be desired. A wide range of testing frameworks is available for developers of conventional system, but only a few of them are suitable for ES testing, validation and debugging. For example, JUnit2is one of the most distributed and recognised testing frameworks among Java programmers, but as to consider knowledge-based engineering, its functionality narrows to test cases related with code base only and leaves knowledge base unattended. Any1Drools Platform, URL: http://drools.org 2JUnit, URL:http://junit.org
expert system is at least a combination of user input-output interface, knowledge base, rule base and decision system (code base). It is obvious that regular test frameworks are suitable for code base testing and debugging only. The same disadvantage is peculiar to all testing frameworks aimed at testing code-base and algorithms. Therefore, researches on evaluation in knowledge-based engineering are made over last years.Correctness of an expert system assumes that both the right system was built and the system was built right [5]. These stages are referred to as validation and verification, respectively. Using a system not thoroughly tested (unreliable system) may cause a disastrous result, especially when a failure is concerned not with material costs, but with security or human life. Proper validation of an expert system must ensure that both code base and knowledge base produce correct solution. Domain rules and reasoning processes are to be tested, as well. Prototyping is not suitable for testing large-scaled systems as it is impossible to anticipate all possible findings and decisions. Functionality of prototype is limited to key aspects. Fine testing and debugging strategy includes visualisation of reasoning. A coloured progress bar that is popular in unit testing is not enough for inspection of test cases and reasoning process as it is intended to signalise whether the test failed or succeeded without deep investigation of intermediate stages. But not-easy-to-find bugs, which are hard to analyse without depicted work-flow, are often encountered in all subsystems of ES as well as the rule base.II. PROBLEM STATEMENT
In the context of this paper we focus on the validation and visualisation process of knowledge-based engineering system for structural optical design[6]. We use the Drools platform developed by Red Hat company as a rule engine. The idea is to produce a sufficient way to depict the reasoning process in a manner which is suitable for testing by a person slightly related with development process and may become a part of explanation subsystem in future.Many of debug techniques do not support a possibility of sufficient manual review. However, thorough reasoning and decision testing process is usually related with manual review by an expert in subject area. This often includes a careful analysis of large blocks of hard-to-display-on-the-screen data. Scrolling distracts the attention of the expert from investiga-tion. Furthermore, a domain expert is not necessarily supposed to be familiar with the system and specialised software, the same situation is with our OSYST optical design system.Thus, visualisation charts must contain as little information and blocks as possible but enough for inspection. Demonstrative and readable charts and diagrams make it easier to analyse work-flow and solution derivation and speed up the process of testing. Decision-support system visualisation must be a flexible, powerful tool. Moreover, a well-designed visualisation system for validation and debugging may become a part of explanation subsystem as well. Thus, a thorough overview of related works must be conducted and a not-time-consuming-to-cope-with visualisation mechanism must be produced.The rest of the paper is organised as follows: Section 3 briefly overviews widely-used approaches in expert system de-velopment, validation and verification and other works related to expert system debug and test tools. Section 4 focuses on description of OSYST system and its components, its imple-mentation and the improvements made for the convenience of validation process and system’s feasibility in general and validation and visualisation techniques, in particular, as well as experimental evaluation of introduced component.III.RELATED WORK
A. Validation and Verification Overview
The topic is not new to knowledge-based engineering. ES testing has been an object of attention as long as decision-support systems exist. As soon as first expert systems were developed, validation, testing and debugging became a dis-cussed research subject. Studies on unit testing can be found in [7]. But all of them take into consideration only validness of final solution and sidestep deep analysis of work-flow and rule implementation by a domain expert.Development of a knowledge-based system is a continuous process, including many stages. Thus, validation and verifi-cation is to be applied not when the system is completed, but throughout the whole expert system development cycle. Vanthiene, Mues and Aerts[8] focus on validation from the very beginning of development cycle, particularly at modelling stage. They sum up investigation, stating that a lot of anomaly types can easily be prevented or detected, and, consequently also corrected in an early stage of development. But the approach is not acceptable or not of current importance, when validation was omitted at modelling stage and applied later on further stages of development.Preece[9] provides a critical assessment of current state of the practice in knowledge-based system validation and verification, including an overview of available evidence of the efficiency of various validation and verification methods in real-world knowledge base development projects. The author offers recommendations for the use of validation and veri-fication methods and presents overview of other validation technique studies (the Minnesota study, the SRI study, the Concordia study, the SAIC study, the Savoie study) and concludes that the collective knowledge on efficient validation and visualisation techniques is very limited and is not suitable for every knowledge-based system.Further studies concentrate on methods and tools for decision-process visualisation at the stage of empirical testing [5], [10].
Baumeister[5] suggests DDTree (derivation/dialog tree) - apowerful tool for ES validation and visualisation of reasoning. DDTrees are able to present both final and intermediate solutions in an easy-to-read intuitive way. Successful test cases are coloured in green, erroneous cases are red. New test cases are shadowed until test is launched. Tree-like diagram may be printed and inspected by an expert in subject area. Branched structure of chart allows analysing the reason of failure based on incoming findings. DDTree is a part of KnowWe[11] platform which is used for building knowledge based systems. But derivation trees are used only for static analysis. They do not have a timeline to track order of execution.Another visualisation method is proposed by Tavana[10]. He offers PNs (Petri Nets) for dynamic system representation and rule derivation. It overcomes the drawback of derivation trees and allows analysing system in dynamics.
B. Main Approaches to Validation and VerificationNowadays knowledge-base engineers mark out a number of approaches to knowledge-base system validation and verifi-cation. B. J. Wielinga, A. Th. Schreiber and J. A. Breuker[12] introduce a so-called KADS approach. In KADS (Knowledge Analysis and Documentation System), the development cycle of a knowledge-based system (KBS) is treated as a modelling process. A KBS is not considered to be a box filled with expert knowledge, but an operational model which displays a desirable behaviour in terms of domain area. Authors give an overview of activities undertaken by engineers to produce an expert system and illustrate it with examples in the domain of troubleshooting audio equipment.KADS was further developed into CommonKADS: a comprehensive methodology for KBS development. Com-monKADS postulates are:
1)
2)
3) knowledge engineering is not some kind of ‘mining from the expert’s head’, but consists of constructing different aspect models of human knowledge; 
the knowledge-level principle: in knowledge mod-elling, first concentrate on the conceptual structure of knowledge, and leave the programming details for later;knowledge has a stable internal structure analysable by distinguishing specific knowledge types and roles.
A paper by Prat, Akoka and Comyn-Wattiau[13] is concerned with MDA (Model-driven architecture) approach to knowledge engineering centred on the CommonKADS knowledge model. They start by grouping elements of the CommonKADS knowl-edge models into a so-called ”inference groups”, propose and demonstrate an algorithm that defines these inference groups automatically and propose a comprehensive CommonKADS knowledge metamodel.Another approach to knowledge-based systems’ design and development is described by Cairo and Guardati[14]. They introduce a KAMET (Knowledge-acquisition methodology) II approach, which states that knowledge acquisition (KA) process is not ”mining from the expert’s head” and produc-ing rules for building KBS as it used to be 20 years ago when modern engineering toolkit did not exist and knowledge acquisition was confused with knowledge elicitation activity. Nowadays knowledge acquisition process must involve bothdynamic modelling and knowledge generation activities. The paper presents attempts to build a new KA approach, that includes all of these ideas. KAMET II brings a number of new to KBS development processes and tends to transform tacit knowledge into explicit knowledge.However, all stated above approaches are largely academic and theoretical and may cause challenges, especially for those who have not developed an expert system before. A step-by-step approach described by Freiling, Alexande, Messick, Rehfuss and Shulman[15] helps to overcome these challenges at the beginning of design stage and through the development process. The authors make two fundamental assumptions:1) 
2) knowledge is more valuable than inference strategies; a knowledge engineering project must provide ad-equate documentation of its progress; at any stage in the process knowledge engineers must be able to show the results of their work.
To reduce the risk of inconsistency of a developed system authors recommend to follow 6 steps to an expert system prototype (Fig. 1).Fig. 1. 	Six steps to an expert system prototype
One of the keystones stated by authors is choosing the right tool. A tool is concerned not only with design process, but with all stages of development lifecycle, including validation and verification, thus, they mark out four requirements for a knowledge engineering methodology:
1) 
2) 
3) 
4) the methodology must be simple; 
the methodology must be gradual;the methodology must be gradual; 
the methodology must aim at getting the knowledge; the methodology must provide measurable mile-stones.However, all steps implemented do not guarantee that the sys-tem is consistent. Proper testing is to be done to ensure that the system is built right and the right system is built. They suggest that engineers use testing tools as well as visualisation tools (CHECKA and PIKA, respectively, in their case). Authors conclude that the collection of tools and components supports a step-by-step approach to knowledge engineering, providing a way to keep making progress on the problem at hand and using all possible tools is a good practice to fulfil a proper development and testing cycle.IV.THE OSYST SYSTEM IMPLEMENTATION AND
IMPROVEMENT
A. Subject Area Overview
The investigations implemented in this work are concen-trated on knowledge-based optical design system OSYST3. Main issues of optical systems’ (OS) composition are clas-sification of elements in OS and analysis of their applicability in cases concerned. All elements, by their function, are divided into four groups: basic (B), corrective (C), high-aperture (T) and wide-angular (Y) elements. The derivation of element sequence to result the specific optical characteristic is referred to as structural synthesis. Structural synthesis is the first stage of automated optical system design.Since a large number of similar and differing structural schemas often meets the same technical requirements, a pro-cess of structural synthesis does not have any determined solu-tion algorithm. An expert in optics relies on her/his experience and knowledge in subject area. The more experienced domain expert is, the more optimal schema is produced.A great experience and knowledge in domain area, de-scribed by Rusinov and Livshits allows formalising the process and, consequently, building up a basis for automated structural synthesis and OSYST system development. The optical system calculation brings to ability of engineer to arrange elements of optical scheme so that an optimal sequence is produced in order to be able to drive the system to better image quality without exceeding established geometrical constraints.Optical system synthesis starts with analysis of techni-cal requirements which allow to define applicability criteria. According to requirements an optical schematic diagram is produced (Fig. 2).
Fig. 2. 	An example of optical schematic diagram produced by OSYST with its structural formula
Starting point selection is the determinative stage of design as final outcome of synthesis becomes less time-consuming as3OSYST repository, URL: https://github.com/ailabitmo/OSYST
a result of better convergence of optical system optimisation process. Starting point misselection brings to running over a great number of possible combinations of free parameters of the system causing a tiny possibility of optimum solution to be ever found. In practice, it results in using trial method, which is time-consuming for both expert and computer. In most cases such unproductive calculations are unsuccessful. Thus, a failure in optical system synthesis by an expert system causes waste of time and overcosts. A rapt attention must be paid to expert system reliability.B. Rule Engine ChoiceDrools production rule system, using an enhanced im-plementation of the Rete algorithm, was chosen as a rule engine. Drools supports the JSR-94 standard for its business rule engine and enterprise framework for the construction, maintenance, and enforcement of business policies in an or-ganisation, application, or service. Drools is considered to be one of the most developed and supported platforms. It has a number of knowledge representation ways. The main and the most wide-spread of them is a decision representation language (DRL), which is used in production system development. DRL is tightly integrated with Java language. Furthermore, the platform enables to write DSL constructions to make rules more vivid and easy-to-understand for domain experts. A detailed description of Drools is redundant as the platform is well-documented, thus, only features significant for the OSYST system are stated below.Drools has an advanced decision engine that supports both forward and backward chaining that allows wider range of abilities at design stage (a forward chaining is used in our expert system as it is acceptable when an object is to be syn-thesised based on the facts). The last but not the least, Drools platform has database design toolkit referred to as Guvnor, which is not included in most of other platforms. Guvnor combines all essential tools for knowledge-based engineering, such as rule editor, rule storage, test tools, decision tables and so forth. Furthermore, the described platform has a user-friendly web-interface. Drools is cross-platform, its installation process is not time-consuming, knowledge bases can be easily exported and imported, which results in better portability. All facts considered, Drools platform has many advantages over the other platforms and meets our needs.C. System architectureThe OSYST expert system consists of four fundamen-tal components: a knowledge base, implemented on Drools platform, which is described before in this paper; a server component developed using Play! Framework4; a client com-ponent, represented by a browser user interface and a database to store user accounts and saved work (Fig. 3). Logging for visualisation process takes place on server side, logging process is described further in details. Knowledge- and rule bases are developed, using built-in tools of Guvnor. The platform offers a fine versioning mechanism which is very desirable, especially during development and testing stages. Rules set the correspondence between technical and general characteristics. The example of such rule in DRL language4Play! Framework, URL:http://www.playframework.com
is represented in Alg. 1. It sets the correspondence between”technical” focal length and ”generalised” or ”formalised” F.
Fig. 3. 	The OSYST system architecture. Logging for VODRE tool is indicated by curvy line.
Algorithm 1 An example of rule in DRL language
rule F1 
when
class : Classification()
	Requirements(focalLength > 50 < 100) then$class.setF(1); 
end
Drools Guvnor publishes a web-service that is used as a RESTful interface for connection to knowledge base. As it was mentioned before, Drools platform is tightly integrated with Java language (in fact it is developed using Java language), therefore, Java platform for server application was chosen. Server component is intended to accept data inserted by user, process it according to knowledge base stored in Guvnor and give the result back to user by client’s request using Ajax, which results in quicker response (reaction) of the system.The choice of server framework is concerned with time consumption. Play framework allows developing soft-ware quickly, following the Convention over Configuration paradigm, that tends to minimise the number of decisions made by developer by simplifying configuration process, granting finished modules and so forth. Furthermore, it supports MVC (Model-View-Control) pattern that allows developing a server and a client component in the same development cycle.Client pages are developed, using standard and widely-spread tools and languages (HTML, CSS, JavaScript). All structural synthesis drawing functions, including visualisation, are implemented with a help of KineticJS Canvas JavaScript5
5KineticJS, URL:http://kineticjs.com
framework that includes all basic primitives and canvas func-tions. User accounts are stored in MySQL database.D. Validation and VerificationA variety of tools were used for expert system validation and verification: unit testing, integrational testing, systems testing and database testing. Unit testing was applied to all components of the system in client application as well as in server (Jasmine6and JUnit. A manual alpha-testing was conducted by potential users of the system to check appli-cation consistence. However, till now all manual tests were conducted by comparing schema synthesised based on inserted parameters with expected schema visually. A component for rule execution visualisation was developed to simplify the process of manual testing. Data about facts inserted and rules executed is collected by AgendaEventListener and Working MemoryEventListener from Knowledge API7. Collected logs are received by client, then analysed and represented in debug (before this investigation) and in visualisation (now) windows, which lets an alpha-tester have both schema and rule execution order for analysis in front of his/her eyes (Fig. 4). Visualisation process is described in details in next subsection.Fig. 4. 	Testing tools after visualisation component introduction
E. Visualisation Mechanism and Diagram Elements
Visualisation process requires data about facts provided and rules being triggered in working memory as well as the order of rule invocation. For that purpose a logging mechanism for connection between rule engine and server was developed based on standard JBoss knowledge tools. After data insertion at client side a request is sent to server and synthesis process listened by visualisation (rule invocation) logger starts. A diagram of rule invocation logger is displayed in Fig. 5.6Jasmine Framework, URL:http://jasmine.github.io 
7JBoss Knowledge API, URL:http://docs.jboss.org/jbpm/v5.1/javadocs
RuleRunner class handles a stateless session with knowl-edge base, which is listened by WorkingMemoryEventListener. Thus, listening process is parallel to optical schema generation, and logs received include all steps of synthesis. Listener class implements methods for entity insertion, update and retrac-tion (objectInserted(), objectUpdated() and objectRetracted() respectively) which handle information on events in working memory. As soon as knowledge session is finished, synthesised schema formulae are returned to client together with synthesis logs.Fig. 5. A class diagram of rule invocation logger (only logger package classes are displayed, others are omitted for the reason of diagram complexity)
All logs received are parsed on client side and visualised. Log parsing is accomplished by parseRules() function writ-ten in JavaScript synthesis module. Generated schemas are presented to user and two windows (debug and visualisation) are displayed. Windows are used for debug log output and visualisation chart drawn on canvas, respectively.Two types of identities are used in reasoning process of the synthesis: these are rules and facts. Both rules and facts can be added to working memory, removed from it or changed (updated). A fact (or a set of facts) make rules to be fired. Based on the above, a set of visualisation diagram elements was worked out. All diagram elements are represented in Fig. 6. Rules are represented by parallelograms (a) with a name of the rule inside; facts are represented by rectangles (b), containing facts’ names (values); operations on facts are displayed by horizontal arrows directed to left side (c), right side (d) and both directions (e) for adding, removing or changing a rule in working memory, respectively; vertical bent arrows (g) are used between rules and facts, operated by the rule. Elements are aligned along a timeline (f), represented by a vertical line, from top to bottom.Thus, a validation process after introduction of visualisa-tion component should look as follows:
1) 
2) 
3) an alpha-tester provides system with input data; as soon as input is finished, a request is sent to server; schemas are synthesised on the server, logs of rules’invocation are collected in parallel;
4) 
5) 
6) 
7) optical formulae of synthesised schemas and logs are returned from the server;schemas are drawn in web-browser client of OSYST; synthesis process visualisation diagram is built based on rule invocation logs; 
rules and rule execution order is analysed with a help of visualisation chart (a more time-consuming manual comparation of synthesised schema with expected schema, which had to be calculated in advance, was required before).