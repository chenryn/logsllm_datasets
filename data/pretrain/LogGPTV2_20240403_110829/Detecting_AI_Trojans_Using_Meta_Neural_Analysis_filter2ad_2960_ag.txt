arXiv preprint arXiv:1611.03814, 2016.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:09 UTC from IEEE Xplore.  Restrictions apply. 
116
[47] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov,
and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear
bottlenecks. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pages 4510–4520, 2018.
[48] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.
Membership inference attacks against machine learning models. In IEEE
Symposium on Security and Privacy (SP), pages 3–18. IEEE, 2017.
[49] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre,
George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
Veda Panneershelvam, Marc Lanctot, et al. Mastering the game of go
with deep neural networks and tree search. Nature, 529(7587):484, 2016.
[50] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew
Rabinovich. Going deeper with convolutions.
In Proceedings of the
IEEE conference on computer vision and pattern recognition, pages 1–
9, 2015.
[51] Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf.
Deepface: Closing the gap to human-level performance in face veri-
ﬁcation. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 1701–1708, 2014.
[52] Brandon Tran, Jerry Li, and Aleksander Madry. Spectral signatures
In Advances in Neural Information Processing
in backdoor attacks.
Systems, pages 8000–8010, 2018.
[53] Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath,
Haitao Zheng, and Ben Y Zhao. Neural cleanse: Identifying and
mitigating backdoor attacks in neural networks.
In Neural Cleanse:
Identifying and Mitigating Backdoor Attacks in Neural Networks, page 0.
IEEE, 2019.
[54] Pete Warden. Speech commands: A dataset for limited-vocabulary
speech recognition. arXiv preprint arXiv:1804.03209, 2018.
[55] Pete Warden.
https:
//ai.googleblog.com/2017/08/launching-speech-commands-dataset.html,
2019. Accessed: 2019-05-11.
Launching the speech commands dataset.
[56] Chaofei Yang, Qing Wu, Hai Li, and Yiran Chen.
poisoning attack method against neural networks.
arXiv:1703.01340, 2017.
Generative
arXiv preprint
[57] Yuanshun Yao, Huiying Li, Haitao Zheng, and Ben Y Zhao. Latent
backdoor attacks on deep neural networks. In Proceedings of the 2019
ACM SIGSAC Conference on Computer and Communications Security,
pages 2041–2055, 2019.
APPENDIX
A. Detailed Discussion on Existing Detection Approaches
We ﬁnd that existing approaches have different assump-
tions on the defender and detection capabilities. For example,
dataset-level works require access to the training set and
cannot detect model manipulation attacks which do not poison
the dataset; works inspired by anomaly detection cannot detect
all-to-all attacks where all the labels suffer from the same
level of attack so that there is no anomaly. In the following
we introduce the assumptions and capabilities of existing
detection approaches.
Neural Cleanse(NC) [53] and DeepInspect(DI) [13] work
on the same level with us. NC observes that in a Trojaned
model, there exists a short-cut modiﬁcation (i.e. the trigger
pattern) to change any input to be predicted as the Trojan
label. Therefore, it calculates such modiﬁcation for each label
and checks if there exists a short-cut which is much smaller in
size than the modiﬁcations of other labels. DI improves upon
the approach by using model inversion to get some training
data. Then they use GAN to generate the modiﬁcations and
apply the same algorithm to check short-cut as in NC. Both
approaches cannot be applied to detect all-to-all attack where
the pattern itself cannot lead to certain Trojan label, so the
short-cut no longer exists. They cannot be applied to detect
Fig. 7: An illustration of the idea of one-class SVM.
Trojans in binary classiﬁcation tasks because their short-cut
check algorithm requires at least three classes. In addition,
NC performs not well in detecting large-size triggers [13].
Activation Clustering (AC) [12] and Spectral Signature [52]
work on the dataset-level detection. AC performs a two-
class clustering over the feature vector of the training data
to separate benign data and Trojaned data (if exists). Spectral
calculates a signature score for each data in the training set
to remove the ones which possibly contain a Trojan trigger.
These approaches perform detection on the dataset level, so
they need access to the training data and cannot be applied
to detect model manipulation attacks which do not poison the
dataset. AC also requires white-box access to calculate the
feature vector.
STRIP [21] and SentiNet [16] detects Trojans on the input
level. STRIP adds up the input with other clean data. The
network will give a conﬁdent answer on the mixed input if
it contains the Trojan pattern; otherwise the network will be
confused. SentiNet uses computer vision techniques to ﬁnd
salient parts in the image, which are possibly the Trojan trigger
pattern. It then copies the parts to other images to check if it
can change the output of other images. Both approaches need
a set of clean data to detect Trojans. STRIP cannot detect all-
to-all attacks where the model cannot give a conﬁdent answer
even if it sees the trigger pattern on the blended input. SentiNet
requires white-box access to detect salient part and cannot
detect large-size trigger via saliency check.
B. One-Class SVM
In Figure 7, we illustrate an example of the one-class SVM
model. The model is only provided with a set of training
data in one class, and tries to ﬁnd the decision boundary that
captures all the training data tightly. The test set consists of
data in the class and data outside the class, and the goal is to
distinguish between the two classes.
C. Dataset Details and Network Structures
Computer Vision. We use the standard MNIST [33] and
CIFAR10 [31] datasets for computer vision tasks. MNIST
contains 70,000 handwritten digits with 60,000 samples used
for training and 10,000 samples for testing. Each data sample
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:09 UTC from IEEE Xplore.  Restrictions apply. 
117
TABLE X: The model structure for each dataset in our evaluation.
Each convolutional layer and linear layer are followed by a ReLU
activation function except the last linear layer.
MNIST
Conv (16 × 5 × 5, pad=0)
Conv (32 × 5 × 5, pad=0)
MaxPool (2 × 2)
MaxPool (2 × 2)
Linear (512)
Linear(10)
CIFAR10
Conv (32 × 3 × 3, pad=1)
Conv (32 × 3 × 3, pad=1)
Conv (64 × 3 × 3, pad=1)
Conv (64 × 3 × 3, pad=1)
MaxPool (2 × 2)
MaxPool (2 × 2)
Linear (256)
Linear (256)
Dropout (0.5)
Linear (10)
MR
Word Embedding (300)
Conv (100 × {3, 4, 5} ×300)
Concatenation
Dropout (0.5)
Linear(1)
LSTM (100, layer=2)
Irish
Attention
Linear (1)
SC
MelSpectrogram Extraction
LSTM (100, layer=2)
Attention
Linear (10)
is a 28x28 grayscale image. CIFAR10 consists of 60,000
32x32 RGB images in 10 classes, with 50,000 images for
training and 10,000 images for testing. For MNIST, we adopt
the same CNN structure as in [23]. For CIFAR10, we use the
same CNN structure as in [10].
Speech. We use the SpeechCommand dataset (SC) ver-
sion v0.02 [54] for the speech task. The SC dataset consists
of 65,000 audio ﬁles, each of which is a one-second audio
ﬁle belonging to one of 35 commands. We use the ﬁles of ten
classes (“yes”, “no”, “up”, “down”, “left”, “right”, “on”, “off”,
“stop”, “go”) as [55] does and it gives 30,769 training samples
and 4,074 testing samples. Given the audio signal ﬁles, we ﬁrst
extract the mel-spectrogram of each ﬁle with 40 mel-bands.
Then we train an Long-Short-Term-Memory (LSTM) network
over all the mel-spectrograms.
Tabular Records. We use the Smart Meter Electricity Trial
data in Ireland dataset (Irish) [2] for tabular data tasks. The
Irish dataset consists of the electricity consumption of 4,710
users in 76 weeks. Each record has 25,536 columns with each
column being the electricity consumption (in kWh) of users
during 30 minute intervals. Each user is labeled as residential
or SME (Small to Medium Enterprise). We split the dataset to
have 3,768 users (80% of all users) in the training set and 942
(20%) in the test set. For the training set we use the data in
the ﬁrst 46 weeks (60% of the total time length) while for the
test set we use the data in the last 30 weeks (40%). We use
the electricity consumption in each week as the feature vector
and view the vectors of all the weeks as a time series. Then
we train an LSTM model to predict whether a given electricity
consumption record belongs to a residential user or an SME.
Natural Language. We use the same Rotten Tomatoes
movie review dataset (MR) as Kim [29] for natural language
processing tasks. The MR dataset consists of 10,662 movie
review sentences. The task is to determine whether a movie
Fig. 8: The detection ROC curve of different approaches on MNIST-
M (left) and CIFAR10-M (right).
review is positive or negative. Following the convention of
the previous work [29], we use 90% of the data for training
and the rest for testing. We use the same model structure as
Kim [29] except that we use a pretrained and ﬁxed Gensim
model as the word embedding layer. A pretrained embedding
layer provides a better performance given the limited training
data we use.
For reproduction, the model structures for the evaluation on
each dataset are presented in Table X. The hyperparameters
of the layers are shown in the parenthesis following the layer
name. For convolutional layers, the number of ﬁlters, ﬁlter
width and ﬁlter height, as well as the padding are listed. For
linear layers, we omit the input size and only show the output
size.
D. Defense on Discrete Data
On the MR task, the input words are in discrete token
space. Therefore, we cannot use gradient-based approach to
do query-tuning. However, for most neural networks with
discrete input space, the input will ﬁrst be mapped to some
continuous embedding space (e.g., word2vec in NLP). Thus,
we will optimize the “query set” over the embedding space
to in the same way as before. During inference, we directly
feed the tuned embedding vectors to the target model to get
predictions. The trade-off is that under this setting, we need
white-box access to the embedding layer of the target model.
We adopt this setting in the NLP tasks.
E. Detection Baselines Implementation Details
At the time of writing, only the source code of NC is
released. Moreover, all the baselines only evaluate with CNN
models on computer vision datasets in their work, except for
AC where CNN models on NLP dataset are also evaluated. To
compare our approaches with these baselines, we re-implement
them with Pytorch.
Since AC and Spectral are dataset-level detection and STRIP
is input-level detection, we will tailor them to detect model-
level Trojans to compare them with our pipeline. AC works on
the dataset level and uses an ExRe score to indicate whether
the dataset is Trojaned. We use this score to indicate the Trojan
score for the model. Spectral assigns a score to each training
sample. We use the average score of all the training data to
indicate the score of the model being Trojaned. STRIP predicts
whether an input data is Trojaned, we use their approach to
calculate a score for each training sample and take the average
to indicate the likelihood of a Trojaned model.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:09 UTC from IEEE Xplore.  Restrictions apply. 
118
Fig. 9: The comparison of detection AUC with and without query tuning. -M stands for modiﬁcation attack and -B stands for blending
attack.
(a) Test patterns.
(b) Examples of training patterns.
Fig. 11: The unforeseen trigger pattern used in evaluation (left) and
examples of the trigger patterns used in jumbo training (right) on
MNIST and CIFAR.
TABLE XI: The detection AUC of jumbo MNTD on Trojaned
models with unforeseen trigger pattern.
MNIST
100.00%
CIFAR10
96.97%
SC
Irish
MR
93.21% 100.00% 94.32%
bution. In particular, we modify one pixel at each of the four
corners and use it as the trigger pattern for vision tasks (see
Figure 11a). For SC, we modify the signal value in the ﬁrst
0.25 second, middle 0.5 second and last 0.25 second to be
0.1. For Irish, we modify the usage from 9:00 am to 10:00
am on every weekday to be 0. For MR, we add a “yes” at the
beginning and an “oh” at the end of the sentence.
The results are shown in Table XI. We see that the meta-
classiﬁer achieves the similar performance as when detecting
the triggers that we have seen. This shows that the trained
meta-classiﬁer generalizes well even if the trigger patterns are
not considered in the training process.
G. Label mapping of TinyImageNet
The classes we choose in TinyImageNet which correspond
to the labels in CIFAR-10 are shown in Table XII. Note that,
the ‘airplane’ class corresponds to the images of rockets and
‘horse’ corresponds to the images of camels, since the Tiny-
ImageNet does not contain images of airplanes and horses.
(a) Jumbo
(b) One-class
Fig. 10: Example of tuned-queries in MNIST. To make the pattern
more clear, we magnify the contrast of the jumbo query by 5 times.
F. Other Experiment Results
ROC Curve of detection We show the ROC curve of the
detection performance for different approaches on MNIST-M
and CIFAR10-M as in Figure 8.
Effectiveness of Query Tuning
We compare the results of Jumbo MNTD with and without
query tuning in Figure 9. The results show that query tuning is
highly effective; the AUC scores drop as much as 30% in the
worst case if we use untuned queries instead. We can interpret
the improvement by an analogy to feature engineering: we
would like to obtain shadow model features with the most
distinguishability for the meta-model to do classiﬁcation. In
query-tuning the feature engineering is done by tuning the
queries.
it
We show some of the tuned queries on the MNIST-M task in
Figure 10. We observe that the tuned query in jumbo learning
focuses more on local patterns, while the tuned query in one-
class learning contains more global and digit-like pattern.
We speculate that
is because most Trojaned models in
jumbo learning use small local pattern, so this query can
help distinguish between benign model and jumbo Trojaned
models. On the other hand, the one-class learning needs to ﬁt
the benign models best, so the query looks like normal benign
input.
In the jumbo distribu-
Generalization on Trigger Patterns
tion we assume that the trigger patterns are all consecutive
patterns (e.g., one square pattern in vision task). Now we will
evaluate the meta-classiﬁer using Trojans with non-consecutive
patterns. These patterns will never appear in the jumbo distri-
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:09 UTC from IEEE Xplore.  Restrictions apply. 
119
TABLE XII: The classes in CIFAR-10 and corresponding class
picked in TinyImageNet.
class in CIFAR-10
class in TinyImageNet
n04008634
n02814533
n02002724
n02123045
n02423022
n02085620
n01641577
n02437312
n03662601
n03796401
airplane
automobile
bird
cat
deer
dog
frog
horse
ship
truck
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:09 UTC from IEEE Xplore.  Restrictions apply. 
120