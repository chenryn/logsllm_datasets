iterations, and in each iteration, every node gathers (copy)
data from their incoming edges, applies some computation to
the data, and then scatters (copy) the result to their outgoing
edges. Viewing each vertex as a CPU or by assigning multiple
vertices to each CPU, the apply phase which computes the
main functionality, is easily parallelized. [18, 19] constructed
frameworks for securely computing graph-parallel algorithms.
They did this by designing a nicely parallelizable circuit for
the gather and scatter phases.
2.2 MPC with differentially private leakage
The security deﬁnition for secure computation is built around
the notion of protocol simulation in an ideal world execution
[8]. In the ideal world, a trusted functionality takes the inputs,
performs the agreed upon computation, and returns the result.
We say the protocol is secure if a simulator can simulate the
adversary’s protocol view in this ideal world, drawing from
a distribution that is indistinguishable from the adversary’s
view in the real world execution. The simulator can interact
with the adversary, but is otherwise given nothing but the
output computed by the ideal functionality.3
In prior work, Mazloom and Gordon [16] proposed a relax-
ation to this deﬁnition in which the simulator is additionally
given the output of some leakage function, L, applied to all
inputs, but L is proven to preserve differential privacy of the
3This brushes over some of the important technical details, but we refer
the reader to a formal treatment of security in Goldreich’s book [8].
USENIX Association
29th USENIX Security Symposium    2489
(cid:110)
(cid:110)
(cid:111)
(cid:111)
input. They deﬁne several varying security models. Here we
focus on one variant, which supports more efﬁcient proto-
col design. We assume that thousands of clients have secret
shared their inputs with 4 computation servers, and we use
E to denote the full set of inputs. We denote the set of secret
shares received by server i as Ei. We denote the input of party
j as e j. Note that the servers learn the input size of each client.
Formally, the security deﬁnition is as follows.
Deﬁnition 1 [16] Let F be some functionality, and let π be
an interactive protocol for computing F , while making calls
to an ideal functionality G. π is said to securely compute F
in the G-hybrid model with L leakage, known input sizes, and
(κ,ε,δ)-security if L is (ε,δ)-differentially private, and, for
every PPT, malicious, non-uniform adversary A corrupting a
party in the G-hybrid model, there exists a PPT, non-uniform
adversary S corrupting the same party in the ideal model,
such that, on any valid input shares, E1,E2,E3,E4
HYBRIDG
π,A(z) (E1,E2,E3,E4,κ)
c≡
z∈{0,1}∗,κ∈N
IDEALF ,S (z,L(V ),∀ j:|e j|)(E1,E2,E3,E4,κ)
z∈{0,1}∗,κ∈N (1)
Mazloom and Gordon construct a protocol for securely
performing graph-parallel computations with differentially
private leakage. In their protocol, the data is secret shared
throughout each iteration: when the Apply phase is executed
at each graph node, it is computed securely on secret shared
data, with both input and output in the form of secret shares.
The leakage is purely in the form of access patterns to mem-
ory: as data moves from edge to neighboring node and back
again, during the Gather and Scatter phases, the protocol al-
lows some information to leak about the structure of the graph.
To minimize and bound this leakage, two additional actions
are taken: 1) The edges are obliviously shufﬂed in between
when the data is gathered at the left vertex, and when it is gath-
ered at the right vertex. This breaks the connections between
the left and right neighboring nodes, and reduces the graph
structure leakage to a simple degree count of each node. 2)
"Dummy" edges are created at the beginning of the protocol,
and shufﬂed in with the real edges. These dummy edges en-
sure that the degree counts are noisy. When the dummy edges
are sampled from an appropriate distribution, the leakage can
be shown to preserve differential privacy. Note that when the
input size of each party is known, the degree count of certain
nodes may not need to be hidden, allowing for better perfor-
mance. For example, if the data elements owned by user u are
weighted edges of the form (u,v,data), it is essential that the
degree of node v remain private, as its degree leaks the edge
structure of the graph, but the degree of node u is implied by
the input size of user u. The implications of this are discussed
more fully in their work.
Neighboring graphs: We represent multi-sets over a set V
by a |V| dimensional vector of natural numbers: D ∈ N|V|. We
refer to the ith element of this vector by D(i). We deﬁne a
metric on these multi-sets in the natural way: |D1 − D2| =
|V|
i=1|D1(i)− D2(i)|.
∑
Applying this to graphs, for each v ∈ V , we let in−deg(v)
denote the in-degree of node v, and we deﬁne the in-
degree proﬁle of a graph G as the multi-set Din(G) =
{in−deg(v1), . . . , in−deg(vn)}. Then, we have the following
deﬁnition.
Deﬁnition 2 We say two graphs G and G(cid:48) have distance at
most d if they have in-degree proﬁles of distance at most d: |
Din(G)− Din(G(cid:48)) |≤ d. We say that G and G(cid:48) are neighboring
if they have distance 1.
Deﬁnition 3 A randomized algorithm L : G → RL is (ε,δ)-
edge private if for all neighboring graphs, G1,G2 ∈ G, we
have:
Pr[L(G1) ∈ T ] ≤ eε Pr[L(G2) ∈ T ] + δ
4-party computation protocol
2.3
We use the secure computation protocol by Gordon et al. for
four parties, tolerating one malicious corruption [10]. We pro-
vide an overview of the construction here. The four parties
are split into two groups, and each group will perform an eval-
uation of the circuit to be computed. The invariant throughout
each evaluation is that both evaluating parties hold x + λx and
y + λy, where x and y are inputs to a circuit gate, and λx,λy
are random mask values from the ring. After communicating,
both parties hold z + λz, where z is the result of evaluating
the gate on x and y, and λz is another uniformly chosen mask.
To maintain this invariant, the evaluating parties need secret
shares of λx,λy,λxλy and λz. Securely generating these shares
in the face of malicious behavior is typically quite expensive,
but, relying on the assumption that only one party is corrupt,
it becomes quite simple. Each pair of parties generates the
shares for the other pair, and, to ensure that the shares are cor-
rectly formed, the pair sends duplicates to each recipient: if
any party does not receive identical copies of their shares,
they simply abort the protocol.
During the evaluation of the circuit, it is possible for a
cheating party to perform an incorrect multiplication, vio-
lating the invariant. To prevent this, the two pairs securely
compare their evaluations against one another. For wire value
z, one pair should hold z +λz, and the other should hold z +λ(cid:48)
z.
Since the ﬁrst pair knows λ(cid:48)
z and the second pair knows λz,
each pair can compute z +λz +λ(cid:48)
z. They compare these values
with the other pair, verifying equality. Some subtleties arise
in reducing the communication in this comparison; we allow
the interested reader to read the original result.
2.4 Notation
Additive Shares: We denote the 2-out-of-2 additive shares
of a value x between two parties P1 and P2 to be [x]1 and [x]2,
2490    29th USENIX Security Symposium
USENIX Association
and between two parties P3 and P4 to be [x]3 and [x]4 (x =
[x]1 + [x]2 = [x]3 + [x]4). When it is clear, we use [x] instead
of [x]i to denote the share of x held by the ith party. Additive
secret shares are used in all steps of the graph computation
model except for the Apply phase. In Apply phase, data is
converted from additive secret shares to masked values and
back.
Function inputs Our protocol includes many function calls
in which P1 and P2 either provide additive shares of some
input, or they each provide duplicates of the same input. The
same is true for P3 and P4. We therefore denote inputs to func-
tionalities and protocols as a pair: the ﬁrst element denotes
the input of P1 and P2, and the second denotes that of P3 and
P4. When P1 and P2 each provide an additive share of some
value E, we simply denote the input by [E]. For example, the
input to FMAC is denoted by (([X],α), [X]): P1 and P2 submit
additive shares of X, and each separately provide a copy of α.
P3 and P4 provide a different additive sharing of X.
Masked Values: For a value x ∈ Z2k, its masked value is
deﬁned as mx ≡ x +λx, where λx ∈ Z2k+s is sampled uniformly
at random. In our four party computation model, for a value
x, P1 and P2 hold the same masked value x + λx and P3 and
P4 hold the same x + λ(cid:48)
x. λx is provided by P3 and P4 while P1
and P2 hold shares of λx. Similarly, λ(cid:48)
x is provided by P1 and
P2 while P3 and P4 hold shares of λ(cid:48)
x.
Doubly Masked Values: Four players can locally compute
the same doubly masked value for x from their masked values,
deﬁned as dx ≡ x + λx + λ(cid:48)
Share or Masked Value of a Vector: When X is
a vector of data, i.e, X = {x1, ...,xn}, we deﬁne [X] ≡
{[x1], ..., [xn]}, λX ≡ {λx1, ...,λxn}, mX ≡ {mx1, ...,mxn} and
dX ≡ {dx1, ...,dxn}.
Fixed Point Representation: All inputs, intermediate values,
and outputs are k-bit ﬁxed-point numbers, in which the least d
signiﬁcant bits are used for the fractional part. We represent a
ﬁxed-point number x by using a ring element in Z2k+s, where
s denotes our statistical security parameter.
x = mx + λ(cid:48)
x = m(cid:48)
x + λx.
MAC Representation: We adapt the technique used in
SPDZ2k [5] for authenticating ring elements. For a value
x ∈ Z2k and for a MAC key α ∈ Z2s, the MAC on value x is de-
ﬁned as MACα(x) ≡ αx ∈ Z2k+s. In our framework, MACα(x)
is always kept in the form of additive secret shares. 4
We note that in our framework, all the values, the additive
shares, and the masked values are represented as elements in
the ring Z2k+s. However, the range of the data is in Z2k, and
the MAC key is in Z2s.
4Technically, calling this a MAC is an abuse of terminology, since it
is not a secure authentication code if αx is ever revealed. However, when
computing on secret shared data, it is common to use shares of αx to prevent
any incorrect manipulation of the data.
3 Building blocks
In this section, we explain the details of each small component
and building block in graph operations, present their real vs.
ideal world functionalities, and provide the security proofs
for each of them, under a single malicious corruption. We
partition the 4 parties into 2 groups, with the ﬁrst consisting
of P1 and P2, and the second P3 and P4. For ease of explanation,
we name the parties in the ﬁrst group, Alice and Bob, and
parties in the second group, Charlotte and David.
3.1 MAC Computation and Veriﬁcation
One of the main challenges we face in constructing a mali-
cious secure version of the graph operations is that we have
to authenticate the values before each operation begins, and
then verify correctness of the results after the operation is
done. This is simple in a Field, but we choose to compute in
a ring to help support ﬁxed point operations. We adapt the
MAC computation and Veriﬁcation technique proposed in
SPDZ2k [5]. In this part, we describe the ideal functional-
ity and the real world protocol to generate MAC values for
additive secret shares over a ring.
FUNCTIONALITY FMAC
Inputs: P1, P2: [X] = {[x1], . . . , [xn]}, MAC key α.
P3, P4: [X].
Functionality:
• Verify that X = [X]1 + [X]2 = [X]3 + [X]4. If the
check does not pass, send abort to all parties.
• If P1, P2 submit different values of α, send abort to
all parties.
• Compute Y = αX.
Outputs: P1, P2 receive nothing.
P3, P4 receive [Y ].
Figure 1: MAC computation ideal functionality
Theorem 1 The MAC computation protocol ΠMAC (Figure
2) securely realizes the ideal functionality FMAC (Figure 1)
with abort, under a single malicious corruption.
3.2 Share-Mask Conversion
We construct a method for securely converting the shared, au-
thenticated values which was used in the Shuﬄe and Gather
phases, into the "masked" ring values required for our four-
party computation of the Apply phase.
Theorem 2 The
protocol
Πsharemask(Π[x]→mx )
the
ideal functionality Fsharemask(F[x]→mx ) (Figure 3) with abort,
under a single malicious corruption.
conversion
securely realizes
share-mask
(Figure 4)
USENIX Association
29th USENIX Security Symposium    2491
PROTOCOL ΠMAC
PROTOCOL Πsharemask(Π[x]→mx )
Inputs: P1, P2: [X], MAC key α.
P3, P4: [X]. F is a PRF.
Protocol:
1. P1, P2 sample a random PRF key k, by making a call
to Fcoin.
2. P1 sends [Y (1)] = {α[Xi] + Fk(i)|i = 1, ...,n} to P3.
3. P2 sends [Y (1)] = {α[Xi]− Fk(i)|i = 1, ...,n} to P4.
4. Four parties make a call to Fmult(α, [X]3,4).
P3, P4 receive [α] and [Y ] ← [αX].
P1, P2 receive nothing.
5. P3, P4 compute [Z] = [Y −Y (1)] and verify Z = 0 by
making a call to FcheckZero([Z]). If the functional-
ity returns false, they send abort to P1 and P2 and
terminate.
Outputs: P1, P2 output nothing.
P3, P4 output [Y ].
Figure 2: MAC computation protocol
FUNCTIONALITY Fsharemask(F[x]→mx )
Inputs: P1, P2: [β], [X], [Y ](Y ≡ βX).
P3, P4: β.
Functionality:
• Reconstruct β, X, and Y from P1 and P2. Verify that
P3 and P4 have sent shares of the same β.
• Verify that Y = βX. If the check fails, send abort to
all parties.
• Compute mX = X + λX and m(cid:48)
• Sample shares [λX ]1, [λX ]2, [λ(cid:48)
X ]1, [λ(cid:48)
X ]2 uniformly
at random, then reconstruct λX and λ(cid:48)
X .
X = X + λ(cid:48)
X .
X , [λX ]1), P2 (mX ,λ(cid:48)