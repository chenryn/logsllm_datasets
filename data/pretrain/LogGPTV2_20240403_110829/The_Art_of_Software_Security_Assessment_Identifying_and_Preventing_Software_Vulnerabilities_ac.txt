Windows track (Chapters 5(? [????.])8(? [????.]), 11(? [????.])13(? [????.])) 
This track starts off similarly to the UNIX track, by covering platform-neutral 
security problems. Then two chapters specifically address Windows APIs and 
their related vulnerabilities. Finally, this track finishes with coverage of 
common synchronization vulnerabilities. 
Web track (Chapters 8(? [????.]), 13(? [????.]), 17(? [????.]), 18(? [????.])) 
Web auditing requires understanding common security vulnerabilities as well 
as Web-based frameworks and languages. This track discusses the common 
vulnerability classes that pertain to Web-based languages, and then finishes 
off with the Web-specific chapters. Although the UNIX and Windows chapters 
aren't listed here, reading them might be necessary depending on the Web 
application's deployment environment. 
Network application track (Chapters 5(? [????.])8(? [????.]), 13(? [????.]), 
16(? [????.])) This sequence of chapters best addresses the types of 
vulnerabilities you're likely to encounter with network client/server 
applications. Notice that even though Chapter 16(? [????.]) is targeted at 
selected application protocols, it has a section for generic application protocol 
auditing methods. Like the previous track, UNIX or Windows chapters might 
also be relevant, depending on the deployment environment. 
Network analysis track (Chapters 5(? [????.])8(? [????.]), 13(? [????.])16(? 
[????.])) This track is aimed at analyzing network analysis applications, such 
as firewalls, IPSs, sniffers, routing software, and so on. Coverage includes 
standard vulnerability classes along with popular network-based technologies 
and the common vulnerabilities in these products. Again, the UNIX and 
Windows chapters would be a good addition to this track, if applicable. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
18 
5. Acknowledgments 
Mark: To my family, friends, and colleagues, for supporting me and providing 
encouragement throughout this endeavor. 
John: To my girlfriend Jess, my family and friends, Neohapsis, Vincent Howard, Dave 
Aitel, David Leblanc, Thomas Lopatic, and Howard Kirk. 
Justin: To my wife Cat, my coworkers at Neohapsis, my family and friends, and 
everyone at a three-letter agency who kept me out of trouble. 
We would collectively like to thank reviewers, friends, and colleagues who have given 
invaluable feedback, suggestions, and comments that helped shape this book into the 
finished product you see today. In particular, we would like to acknowledge Neel 
Mehta, Halvar Flake, John Viega, and Nishad Herath for their tireless efforts in 
reviewing and helping to give us technical and organizational direction. We'd also like 
to thank the entire publishing team at Addison-Wesley for working with us to ensure 
the highest-quality finished product possible. 
6. Part I:  Introduction to Software 
Security Assessment 
Part I: Introduction to Software Security 
Assessment 
6.1 Chapter 1.  Software Vulnerability Fundamentals 
Chapter 1. Software Vulnerability Fundamentals 
"Any sufficiently advanced technology is indistinguishable from magic." 
Arthur C. Clarke 
6.1.1 Introduction 
The average person tends to think of software as a form of technological wizardry 
simply beyond understanding. A piece of software might have complexity that rivals 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
19 
any physical hardware, but most people never see its wheels spin, hear the hum of its 
engine, or take apart the nuts and bolts to see what makes it tick. Yet computer 
software has become such an integral part of society that it affects almost every 
aspect of people's daily lives. This wide-reaching effect inevitably raises questions 
about the security of systems that people have become so dependent on. You can't 
help but wonder whether the software you use is really secure. How can you verify 
that it is? What are the implications of a failure in software security? 
Over the course of this book, you'll learn about the tools you need to understand and 
assess software security. You'll see how to apply the theory and practice of code 
auditing; this process includes learning how to dissect an application, discover 
security vulnerabilities, and assess the danger each vulnerability presents. You also 
learn how to maximize your time, focusing on the most security-relevant elements of 
an application and prioritizing your efforts to help identify the most critical 
vulnerabilities first. This knowledge provides the foundation you need to perform a 
comprehensive security assessment of an application. 
This chapter introduces the elements of a software vulnerability and explains what it 
means to violate the security of a software system. You also learn about the elements 
of software assessment, including motivation, types of auditing, and how an audit fits 
in with the development process. Finally, some distinctions are pointed out to help 
you classify software vulnerabilities and address the common causes of these security 
issues. 
6.1.2 Vulnerabilities 
There's almost an air of magic when you first see a modern remote software exploit 
deployed. It's amazing to think that a complex program, written by a team of experts 
and deployed around the world for more than a decade, can suddenly be co-opted by 
attackers for their own means. At first glance, it's easy to consider the process as 
some form of digital voodoo because it simply shouldn't be possible. Like any magic 
trick, however, this sense of wonder fades when you peek behind the curtain and see 
how it works. After all, software vulnerabilities are simply weaknesses in a system 
that attackers can leverage to their advantage. In the context of software security, 
vulnerabilities are specific flaws or oversights in a piece of software that allow 
attackers to do something maliciousexpose or alter sensitive information, disrupt or 
destroy a system, or take control of a computer system or program. 
You're no doubt familiar with software bugs; they are errors, mistakes, or oversights 
in programs that result in unexpected and typically undesirable behavior. Almost 
every computer user has lost an important piece of work because of a software bug. 
In general, software vulnerabilities can be thought of as a subset of the larger 
phenomenon of software bugs. Security vulnerabilities are bugs that pack an extra 
hidden surprise: A malicious user can leverage them to launch attacks against the 
software and supporting systems. Almost all security vulnerabilities are software 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
20 
bugs, but only some software bugs turn out to be security vulnerabilities. A bug must 
have some security-relevant impact or properties to be considered a security issue; in 
other words, it has to allow attackers to do something they normally wouldn't be able 
to do. (This topic is revisited in later chapters, as it's a common mistake to 
mischaracterize a major security flaw as an innocuous bug.) 
There's a common saying that security is a subset of reliability. This saying might not 
pass muster as a universal truth, but it does draw a useful comparison. A reliable 
program is one that's relatively free of software bugs: It rarely fails on users, and it 
handles exceptional conditions gracefully. It's written "defensively" so that it can 
handle uncertain execution environments and malformed inputs. A secure program is 
similar to a robust program: It can repel a focused attack by intruders who are 
attempting to manipulate its environment and input so that they can leverage it to 
achieve some nefarious end. Software security and reliability also share similar goals, 
in that they both necessitate development strategies that focus on exterminating 
software bugs. 
Note 
Although the comparison of security flaws to software bugs is useful, some 
vulnerabilities don't map so cleanly. For example, a program that allows you to edit a 
critical system file you shouldn't have access to might be operating completely 
correctly according to its specifications and design. So it probably wouldn't fall under 
most people's definition of a software bug, but it's definitely a security vulnerability. 
The process of attacking a vulnerability in a program is called exploiting. Attackers 
might exploit a vulnerability by running the program in a clever way, altering or 
monitoring the program's environment while it runs, or if the program is inherently 
insecure, simply using the program for its intended purpose. When attackers use an 
external program or script to perform an attack, this attacking program is often called 
an exploit or exploit script. 
Security Policies 
As mentioned, attackers can exploit a vulnerability to violate the security of a system. 
One useful way to conceptualize the "security of a system" is to think of a system's 
security as being defined by a security policy. From this perspective, a violation of a 
software system's security occurs when the system's security policy is violated. 
Note 
Matt Bishop, a computer science professor at University of CaliforniaDavis, is an 
accomplished security researcher who has been researching and studying computer 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
21 
vulnerabilities for many years. Needless to say, he's put a lot of thought into 
computer security from a formal academic perspective as well as a technical 
perspective. If these topics interest you, check out his book, Computer Security: Art 
and Science (Addison-Wesley, 2003(? [????.])), and the resources at his home page: 
http://nob.cs.ucdavis.edu/~bishop/. 
For a system composed of software, users, and resources, you have a security 
policy, which is simply a list of what's allowed and what's forbidden. This policy might 
state, for example, "Unauthenticated users are forbidden from using the calendar 
service on the staging machine." A problem that allows unauthenticated users to 
access the staging machine's calendar service would clearly violate the security 
policy. 
Every software system can be considered to have a security policy. It might be a 
formal policy consisting of written documents, or it might be an informal loose 
collection of expectations that the software's users have about what constitutes 
reasonable behavior for that system. For most software systems, people usually 
understand what behavior constitutes a violation of security, even if it hasn't been 
stated explicitly. Therefore, the term "security policy" often means the user 
community's consensus on what system behavior is allowed and what system 
behavior is forbidden. This policy could take a few different forms, as described in the 
following list: 
For a particularly sensitive and tightly scoped system, a security policy could 
be a formal specification of constraints that can be verified against the 
program code by mathematical proof. This approach is often expensive and 
applicable only to an extremely controlled software environment. You would 
hope that embedded systems in devices such as traffic lights, elevators, 
airplanes, and life support equipment go through this kind of verification. 
Unfortunately, this approach is prohibitively expensive or unwieldy, even for 
many of those applications. 
A security policy could be a formal, written document with clauses such as 
"C.2. Credit card information (A.1.13) should never be disclosed to a third 
party (as defined in A.1.3) or transferred across any transmission media 
without sufficient encryption, as specified in Addendum Q." This clause could 
come from a policy written about the software, perhaps one created during the 
development process. It could also come from policies related to resources the 
software uses, such as a site security policy, an operating system (OS) policy, 
or a database security policy. 
The security policy could be composed solely of an informal, slightly 
ambiguous collection of people's expectations of reasonable program security 
behavior, such as "Yeah, giving a criminal organization access to our credit 
card database is probably bad." 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
22 
Note 
The Java Virtual Machine (JVM) and .NET Common Language Runtime (CLR) have 
varying degrees of code access security (CAS). CAS provides a means of extensively 
validating a package at both load time and runtime. These validations include the 
integrity of the bytecode, the software's originator, and the application of code access 
restrictions. The most obvious applications of these technologies include the sandbox 
environments for Java applets and .NET-managed browser controls. 
Although CAS can be used as a platform for a rigidly formalized security model, some 
important caveats are associated with it. The first concern is that most developers 
don't thoroughly understand its application and function, so it's rarely leveraged in 
commercial software. The second concern is that the security provided by CAS 
depends entirely on the security of underlying components. Both the Java VM and 
the .NET CLR have been victims of vulnerabilities that could allow an application to 
escape the virtual machine sandbox and run arbitrary code. 
In practice, a software system's security policy is likely to be mostly informal and 
made up of people's expectations. However, it often borrows from formal 
documentation from the development process and references site and resource 
security policies. This definition of a system security policy helps clarify the concept of 
"system security." The bottom line is that security is in the eye of the beholder, and 
it boils down to end users' requirements and expectations. 
Security Expectations 
Considering the possible expectations people have about software security helps 
determine which issues they consider to be security violations. Security is often 
described as resting on three components: confidentiality, integrity, and availability. 
The following sections consider possible expectations for software security from the 
perspective of these cornerstones. 
Confidentiality 
Confidentiality requires that information be kept private. This includes any situation 
where software is expected to hide information or hide the existence of information. 
Software systems often deal with data that contains secrets, ranging from nation- or 
state-level intelligence secrets to company trade secrets or even sensitive personal 
information. 
Businesses and other organizations have plenty of secrets residing in their software. 
Financial information is generally expected to be kept confidential. Information about 
plans and performance could have strategic importance and is potentially useful for 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
23 
an unlawful competitive advantage or for criminal activities, such as insider trading. 
So businesses expect that data to be kept confidential as well. Data involving 
business relationships, contracts, lawsuits, or any other sensitive content carries an 
expectation of confidentiality. 
If a software system maintains information about people, expectations about the 
confidentiality of that data are often high. Because of privacy concerns, 
organizations and users expect a software system to carefully control who can view 
details related to people. If the information contains financial details or medical 
records, improper disclosure of the data might involve liability issues. Software is 
often expected to keep personal user information secret, such as personal files, 
e-mail, activity histories, and accounts and passwords. 
In many types of software, the actual program code constitutes a secret. It could be 
a trade secret, such as code for evaluating a potential transaction in a commodities 
market or a new 3D graphics engine. Even if it's not a trade secret, it could still be 
sensitive, such as code for evaluating credit risks of potential loan applicants or the 
algorithm behind an online videogame's combat system. 
Software is often expected to compartmentalize information and ensure that only 
authenticated parties are allowed to see information for which they're authorized. 
These requirements mean that software is often expected to use access control 
technology to authenticate users and to check their authorization when accessing 
data. Encryption is also used to maintain the confidentiality of data when it's 
transferred or stored. 
Integrity 
Integrity is the trustworthiness and correctness of data. It refers to expectations 
that people have about software's capability to prevent data from being altered. 
Integrity refers not only to the contents of a piece of data, but also to the source of 
that data. Software can maintain integrity by preventing unauthorized changes to 
data sources. Other software might detect changes to data integrity by making note 
of a change in a piece of data or an alteration of the data's origins. 
Software integrity often involves compartmentalization of information, in which the 
software uses access control technology to authenticate users and check their 
authorization before they're allowed to modify data. Authentication is also an 
important component of software that's expected to preserve the integrity of the 
data's source because it tells the software definitively who the user is. 
Typically, users hold similar expectations for integrity as they do for confidentiality. 
Any issue that allows attackers to modify information they wouldn't otherwise be 
permitted to modify is considered a security flaw. Any issue that allows users to 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
24 
masquerade as other users and manipulate data is also considered a breach of data 
integrity. 
Software vulnerabilities can be particularly devastating in breaches of integrity, as 
the modification of data can often be leveraged to further an attackers' access into a 
software system and the computing resources that host the software. 
Availability 
Availability is the capability to use information and resources. Generally, it refers to 
expectations users have about a system's availability and its resilience to 
denial-of-service (DoS) attacks. 
An issue that allows users to easily crash or disrupt a piece of software would likely be 
considered a vulnerability that violates users' expectations of availability. This issue 
generally includes attacks that use specific inputs or environmental disruptions to 
disable a program as well as attacks centered on exhausting software system 
resources, such as CPU, disk, or network bandwidth. 
6.1.3 The Necessity of Auditing 
Most people expect vendors to provide some degree of assurance about the integrity 
of their software. The sad truth is that vendors offer few guarantees of quality for any 
software. If you doubt this, just read the end user license agreement (EULA) that 
accompanies almost every piece of commercial software. However, it's in a 
company's best interests to keep clients happy; so most vendors implement their own 
quality assurance measures. These measures usually focus on marketable concerns, 
such as features, availability, and general stability; this focus has historically left 
security haphazardly applied or occasionally ignored entirely. 
Note 
Some industries do impose their own security requirements and standards, but they 
typically involve regulatory interests and apply only to certain specialized 
environments and applications. This practice is changing, however, as high-profile 
incidents are moving regulators and industry standards bodies toward more proactive 
security requirements. 
The good news is that attitudes toward security have been changing recently, and 
many vendors are adopting business processes for more rigorous security testing. 
Many approaches are becoming commonplace, including automated code analysis, 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
25 
security unit testing, and manual code audits. As you can tell from the title, this book 
focuses on manual code audits. 
Auditing an application is the process of analyzing application code (in source or 
binary form) to uncover vulnerabilities that attackers might exploit. By going through 
this process, you can identify and close security holes that would otherwise put 
sensitive data and business resources at unnecessary risk. 
In addition to the obvious case of a company developing in-house software, code 
auditing makes sense in several other situations. Table 1-1 summarizes the most 
common ones. 
Table 1-1. Code-Auditing Situations 
Situation 
Description 
Advantage 
In-house 
software audit 
(prerelease) 
A software company 
performs code audits 
of a new product 
before its release. 
Design and implementation flaws can be 
identified and remedied before the product 
goes to market, saving money in developing 
and deploying updates. It also saves the 
company from potential embarrassment. 
In-house 
software audit 
(postrelease) 
A software company 
performs code audits 
of a product after its 
release. 
Security vulnerabilities can be found and 
fixed before malicious parties discover the 
flaws. This process allows time to perform 
testing and other checks as opposed to 