The key advantage of this formulation is that we can now
leverage the observations O1; : : : Oz+1 being independent
given a choice of initiator. Thus we have that:
P (I = ijO1; : : : ; Oz+1) =
j=1 P (OjjI = i) (cid:1) P (I = i)
(cid:5)j=z+1
p=h
P (O1; : : : ; Oz+1)
j=1 P (OjjI = i) (cid:1) P (I = i)
(cid:5)j=z+1
P
p=1 P (O1; : : : ; Oz+1jI = p) (cid:1) P (I = p)
P
j=1 P (OjjI = i) (cid:1) P (I = i)
(cid:5)j=z+1
p=h
p=1 (cid:5)j=z+1
j=1 P (OjjI = p) (cid:1) P (I = p)
=
=
(19)
Finally, assuming a uniform prior over all possible initia-
tors, we have that:
P (I = ijO1; : : : ; Oz+1) =
P
j=1 P (OjjI = i)
(cid:5)j=z+1
p=h
p=1 (cid:5)j=z+1
j=1 P (OjjI = p)
(20)
Figure 12 depicts the expected anonymity as a function of
number of communication rounds. We can see that the en-
tropy provided by Pisces outperforms conventional random
walks by more than a factor of two (in bits) after 100 com-
munication rounds (the anonymity set size is increased by a
factor of 16).
5 Limitations and Future Work
While Pisces is the ﬁrst decentralized design that can
both scalably leverage social network trust relationships and
mitigate route capture attacks, its architecture has some lim-
itations.
Figure 12. Anonymity degradation over mul(cid:173)
tiple communication rounds, Facebook wall
graph, 10 Sybils/attack edge
First, Pisces assumes the existence of Sybil defense
mechanisms to bound the number of malicious entities in
the network, and to prevent blacklisted malicious entities
from re-joining the network (with a different pseudonym).
Without mechanisms to mitigate Sybil attacks, all dis-
tributed anonymity systems including the Tor network are
vulnerable.
Second, Pisces requires users’ social contacts to partici-
pate in the system, and to be online. For example, if none
of a user’s social contacts are online, then it would be un-
able to build anonymous circuits. To improve the usability
of the system, in future work, we will investigate the fea-
sibility of leveraging a user’s two-hop social neighborhood
in the random walk process (similar to techniques proposed
by Vasserman et al [61]).
Third, Pisces by itself does not preserve the privacy of
users’ social contacts. Recent work by Mittal et al. [42]
describes techniques to preserve the privacy of users’ social
contacts while enabling the design of social network based
anonymity systems like Pisces.
Fourth, users who are not well connected in the social
network topology may not beneﬁt from using Pisces. This is
because random walks starting from those nodes may take
a very long time to converge to the stationary probability
distribution (which provides optimal anonymity).
Fifth, Pisces does not defend against targeted attacks on
an individual, in which the adversary aims to massively in-
ﬁltrate or compromise the user’s social circle for increasing
the probability of circuit compromise. We note that the im-
pact of such an attack is localized to the targeted individual.
Sixth, circuit establishment in Pisces has higher latency
than existing systems, since random walks in Pisces tend to
be longer. However, we note that circuits can be established
pre-emptively, such that this latency does not affect the user.
In fact, deployed systems such as Tor already build circuits
pre-emptively.
Finally, Pisces currently does not support important con-
straints such as bandwidth-based load balancing and exit
policies. The focus of our architecture was to secure
the peer discovery process in unstructured social network
topologies, and we will consider the incorporation of these
constraints in future work.
6 Conclusion
In this paper, we propose a mechanism for decentral-
ized anonymous communication that can securely lever-
age a user’s trust relationships against a Byzantine adver-
sary. Our key contribution is to show that appearance of
nodes in each other’s neighbor lists can be made reciprocal
in a secure and efﬁcient manner. Using theoretical analy-
sis and experiments on real world social network topolo-
gies, we demonstrate that Pisces substantially reduces the
probability of active attacks on circuit constructions. We
ﬁnd that Pisces signiﬁcantly outperforms approaches that
do not leverage trust relationships, and provides up to six
bits higher entropy than ShadowWalker (5 bits higher en-
tropy than Tor) in a single communication round. Also,
compared with the naive strategy of using conventional ran-
dom walks over social networks (as in the Drac system),
Pisces provides twice the number of bits of entropy over 100
communication rounds. In conclusion, we argue that the in-
corporation of social trust will likely be an important con-
sideration in the design of the next generation of deployed
anonymity systems.
Acknowledgment
We would like to thank the attendees of HotPETs 2010
and USENIX HotSec 2010 for helpful comments. In par-
ticular, this work beneﬁted from conversations with George
Danezis, Aaron Johnson, and Paul Syverson. We are also
grateful to our shepherd Jun Li, and the anonymous re-
viewers for helping to improve the paper presentation. This
work is sponsored in part by NSF CAREER Award, number
CNS-0954133, and by award number CNS-1117866. Any
opinions, ﬁndings and conclusions or recommendations ex-
pressed in this material are those of the author(s) and do
not necessarily reﬂect those of the National Science Foun-
dation.
References
[1] Tor blog. https://blog.torproject.org/blog/tor-project-
infrastructure-updates.
[2] Pisces: Trustworthy anonymity using social networks.
Technical report, 2012.
[3] D. Aldous and J. A. Fill. Reversible Markov chains
and random walks on graphs. http://www.stat.
berkeley.edu/˜aldous/RWG/book.html.
[4] O. Berthold, H. Federrath, and S. K¨opsell. Web mixes:
a system for anonymous and unobservable internet ac-
cess. In International workshop on Designing privacy
enhancing technologies: design issues in anonymity
and unobservability, 2001.
[5] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda. All
your contacts are belong to us: automated identity
theft attacks on social networks. In WWW, 2009.
[6] N. Borisov, G. Danezis, P. Mittal, and P. Tabriz. Denial
of service or denial of security? ACM CCS, 2007.
[7] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ri-
peanu. The socialbot network: when bots socialize for
fame and money. In ACSAC, 2011.
[8] P. Boucher, A. Shostack, and I. Goldberg. Freedom
systems 2.0 architecture. White paper, Zero Knowl-
edge Systems, Inc., 2000.
[9] J. Boyan. The anonymizer: Protecting user privacy on
the web. Computer-Mediated Communication Maga-
zine, 4(9), 1997.
[10] G. Danezis, C. Diaz, C. Troncoso, and B. Laurie.
an architecture for anonymous low-volume
Drac:
communications. In PETS, 2010.
[11] G. Danezis, C. Lesniewski-Laas, M. F. Kaashoek, and
In ES-
R. Anderson. Sybil-resistant DHT routing.
ORICS, 2005.
[12] G. Danezis and P. Mittal. Sybilinfer: Detecting Sybil
nodes using social networks. In NDSS, 2009.
[13] C. Diaz, S. Seys, J. Claessens, and B. Preneel. To-
wards measuring anonymity. In PETS, 2002.
[14] R. Dingledine, N. Mathewson, and P. Syverson. Tor:
The second-generation onion router. In USENIX Se-
curity, 2004.
[15] J. Douceur. The Sybil Attack. In IPTPS, 2002.
[16] H. Federrath. Project: An.on - anonymity.online: Pro-
tection of privacy on the internet. http://anon.
inf.tu-dresden.de/index_en.html.
[17] M. J. Freedman and R. Morris. Tarzan: A peer-to-peer
anonymizing network layer. ACM CCS, 2002.
[18] E. Gilbert and K. Karahalios. Predicting tie strength
with social media. In CHI, 2009.
[19] D. Goodin. Tor at heart of embassy passwords leak.
The Register, September 10 2007.
[20] W. K. Hastings. Monte carlo sampling methods us-
ing markov chains and their applications. Biometrika,
57(1), 1970.
[21] C.-Y. Hong, C.-C. Lin, and M. Caesar. Clockscalpel:
Understanding root causes of Internet clock synchro-
nization inaccuracy. In PAM, 2011.
[22] A. Houmansadr, N. Kiyavash, and N. Borisov. Rain-
bow: A robust and invisible non-blind watermark for
network ﬂows. In NDSS, 2009.
[23] I2P. I2P anonymous network. http://www.i2p2.
de/index.html, 2003.
[24] D. Irani, M. Balduzzi, D. Balzarotti, E. Kirda, and
C. Pu. Reverse social engineering attacks in online
social networks. In DIMVA, 2011.
[25] A. Johnson and P. Syverson. More anonymous onion
routing through trust. In IEEE CSF, 2009.
[26] A. Johnson, P. F. Syverson, R. Dingledine, and
N. Mathewson. Trust-based anonymous communi-
cation: adversary models and routing algorithms. In
ACM CCS, 2011.
[27] R. Kannan, S. Vempala, and A. Vetta. On clusterings:
Good, bad and spectral. J. ACM, 51(3), 2004.
[28] J. B. Kowalski.
Tor network status.
torstatus.blutmagie.de/.
http://
[29] C. Lesniewski-Laas and M. F. Kaashoek. Whanaun-
In
gatanga: A Sybil-proof distributed hash table.
NSDI, 2010.
[30] R. Levien and A. Aiken. Attack-resistant trust met-
rics for public key certiﬁcation. In USENIX Security,
1998.
[31] B. N. Levine, M. Reiter, C. Wang, and M. Wright.
Timing analysis in low-latency mix systems. In FC,
2004.
[32] J. L. Massey. Guessing and entropy.
1994.
In IEEE ISIT,
[33] J. McLachlan, A. Tran, N. Hopper, and Y. Kim. Scal-
able onion routing with torsk. ACM CCS, 2009.
[34] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth,
A. H. Teller, and E. Teller. Equation of state calcu-
lations by fast computing machines. The Journal of
Chemical Physics, 21(6), 1953.
[35] D. L. Mills. Computer Network Time Synchronization:
The Network Time Protocol. CRC Press, 2006.
[36] A. Mislove, G. Oberoi, A. Post, C. Reis, P. Druschel,
and D. S. Wallach. AP3: Cooperative, decentrialized
anonymous communication. ACM SIGOPS European
Workshop, 2004.
[37] P. Mittal and N. Borisov.
Infomation leaks in struc-
tured peer-to-peer anonymous communication sys-
tems. ACM CCS, 2008.
[38] P. Mittal and N. Borisov.
Shadowwalker: Peer-
to-peer anonymous communication using redundant
structured topologies. ACM CCS, 2009.
[39] P. Mittal, N. Borisov, C. Troncoso, and A. Rial. Scal-
able anonymous communication with provable secu-
rity. In USENIX HotSec, 2010.
[40] P. Mittal, M. Caesar, and N. Borisov. X-vine: Secure
and pseudonymous routing using social networks. In
NDSS, 2012.
[41] P. Mittal, F. Olumoﬁn, C. Troncoso, N. Borisov, and
I. Goldberg. PIR-Tor: Scalable anonymous communi-
cation using private information retrieval. In USENIX
Security, 2011.
[42] P. Mittal, C. Papamanthou, and D. Song. Preserv-
ing link privacy in social network based systems. In
NDSS, 2013.
[43] A. Mohaisen, A. Yun, and Y. Kim. Measuring the mix-
ing time of social graphs. In IMC, 2010.
[44] S. Nagaraja. Anonymity in the wild: mixes on un-
structured networks. In PETS, 2007.
[45] A. Nambiar and M. Wright. Salsa: A structured ap-
proach to large-scale anonymity. ACM CCS, 2006.
[46] A. Panchenko, S. Richter, and A. Rache. NISAN:
Network information service for anonymization net-
works. ACM CCS, 2009.
[47] A. Pﬁtzmann and M. Hansen.
unlinkability,
A terminol-
talking about privacy by data min-
unde-
pseudonymity,
http://dud.inf.tu-
ogy for
imization:
tectability,
and
dresden.de/literatur/Anon Terminology v0.34.pdf,
Aug. 2010. v0.34.
Anonymity,
unobservability,
identity management.
[48] M. Reiter and A. Rubin. Crowds: Anonymity for web
transactions. ACM TISSEC, 1(1), June 1998.
[49] M. Rennhard and B. Plattner. Introducing MorphMix:
Peer-to-peer based anonymous internet usage with
collusion detection. WPES, 2002.
[50] A. Rowstron and P. Druschel. Pastry: scalable, de-
centralized object location and routing for large-scale
peer-to-peer systems. In MIDDLEWARE, 2001.
[60] The Tor Project. Who uses Tor. http://www.
torproject.org/about/torusers.html.
en.
[51] M. Schuchard, A. W. Dean, V. Heorhiadi, N. Hopper,
and Y. Kim. Balancing the shadows. In WPES, 2010.
[52] A. Serjantov and G. Danezis. Towards an information
theoretic metric for anonymity. In PETS, 2002.
[53] V. Shmatikov and M.-H. Wang. Measuring relation-
In ACM WPES,
ship anonymity in mix networks.
2006.
[54] I. Stoica, R. Morris, D. Liben-Nowell, D. R. Karger,
M. F. Kaashoek, F. Dabek, and H. Balakrishnan.
Chord: A scalable peer-to-peer
lookup protocol
IEEE/ACM Trans. Netw.,
for Internet applications.
11(1):17–32, 2003.
[55] P. Syverson, G. Tsudik, M. Reed, and C. Landwehr.
Towards an analysis of onion routing security. Work-
shop on Design Issues in Anonymity and Unobservail-
ity, 2000.
[56] P. F. Syverson, D. M. Goldschlag, and M. G. Reed.
Anonymous connections and onion routing. Security
& Privacy, IEEE, 4-7, 1997.
[57] P. Tabriz and N. Borisov. Breaking the collusion de-
tection mechanism of MorphMix. In PETS, 2006.
[58] The
Tor metrics
portal.
Tor
Project.
http://metrics.torproject.org/.
[59] The Tor Project. Tor metrics portal: Users. https:
//metrics.torproject.org/users.html.
[61] E. Vasserman, R. Jansen, J. Tyra, N. Hopper, and
Y. Kim. Membership-concealing overlay networks. In
CCS, 2009.
[62] B. Viswanath, A. Mislove, M. Cha, and K. P. Gum-
madi. On the evolution of user interaction in Face-
book. In WOSN, 2009.
[63] B. Viswanath, A. Post, K. P. Gummadi, and A. Mis-
love. An analysis of social network-based sybil de-
fenses. In SIGCOMM, 2010.
[64] Q. Wang, P. Mittal, and N. Borisov. In search of an
anonymous and secure lookup. In ACM CCS, 2010.
[65] X. Wang, S. Chen, and S. Jajodia. Tracking anony-
mous peer-to-peer VoIP calls on the Internet. In ACM
CCS, 2005.
[66] C. Wilson, B. Boe, A. Sala, K. P. Puttaswamy, and
B. Y. Zhao. User interactions in social networks and
their implications. In Eurosys, 2009.
[67] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao.
Sybillimit: A near-optimal social network defense
against Sybil attacks. In IEEE S&P, 2008.
[68] H. Yu, M. Kaminsky, P. Gibbons, and A. Flaxman.
SybilGuard: Defending against Sybil attacks via so-
cial networks. In SIGCOMM, 2006.
[69] W. Yu, X. Fu, S. Graham, D. Xuan, and W. Zhao.
DSSS-based ﬂow marking technique for invisible
traceback. In IEEE S&P, 2007.