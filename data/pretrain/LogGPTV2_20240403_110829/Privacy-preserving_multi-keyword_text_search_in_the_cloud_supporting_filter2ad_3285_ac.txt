f
o
r
e
b
m
u
N
0
−0.2
−0.1
0
Similarity score
0.1
0.2
0
−0.1
−0.05
0
0.05
Similarity score
0.1
0.15
(a)
(b)
Figure 5: Distribution of similarity score for key-
word “network” with diﬀerent standard deviations,
3500 documents, only one keyword “network” in the
query, in our enhanced scheme. (a) σ = 0.05. (b)
σ = 0.03.
Security Analysis We analyze EMTS again with respect
to the aforementioned search privacy requirements.
1) Index conﬁdentiality and Query conﬁdentiality:
EMTS can protect index conﬁdentiality and query conﬁden-
tiality in both the known ciphertext model and the known
background model, which is inherited from BMTS.
2) Query unlinkability: The introduction of randomly
generated εi,j will allow EMTS to produce diﬀerent simi-
larity scores even for the same search request. The value
of εi,j can be adjusted to control the level of variance thus
the level of unlinkability. It is worth noting that this query-
side randomization technique signiﬁcantly diﬀers from [5],
where randomization occurs on the index vector side and is
not possible to be tweaked as an eﬀective privacy-preserving
parameter for users. Query unlinkability is thus much en-
hanced compared with BMTS to the extent that there is no
easy way for the attacker to link the queries. However, since
we do not intend to protect access pattern for eﬃciency rea-
sons, the returned results from the same request will always
bear some similarity which could be exploited with powerful
statistical analysis by the very motivated cloud server. This
is a trade-oﬀ that one has to make between eﬃciency and
privacy.
3) Keyword privacy: At level i, the number of the index
vectors is denoted as li. On one hand, to render separate
εi,j of this level the diﬀerent values for one search re-
εi,j for
quest, we set (
the same Dd,i is diﬀerent with multiple search requests, s-
ince εi,j is generated uniformly at random upon each search
request. The cloud server cannot eliminate the impact of
these phantom terms from the ﬁnal similarity scores with-
out the exact values of them. Furthermore, every εi,j follows
the same uniform distribution M (μ(cid:4) − c, μ(cid:4)
+ c), where the
(cid:6)
(cid:6)
and the variance as σ(cid:4)2
mean is μ(cid:4)
is c2/3. According to the
(cid:6)
εi,j follows the Nor-
j∈ ¯Vi
i∈w
central limit theorem, the
(cid:6)
i∈w Viμ(cid:4)
mal distribution N (μ, σ2), where the mean as μ is
(cid:6)
i∈w Vic2/3. Therefore, we may
and the variance as σ2 is
generate εi,j with the value of μ(cid:4)
i∈w Vi and the val-
i∈w Vi · σ. As shown in Fig. 5, with larger σ
ue of c as
selected by the user, it is more diﬃcult for the cloud server
to infer the corresponding statistical information, and fur-
Vi ) ≥ li. On the other hand,
(cid:6)
j∈ ¯Vi
(cid:6)
j∈ ¯Vi
as μ/
Ui
(cid:5)
(cid:6)
3/
j∈ ¯V1
(cid:6)
ther reverse-engineer the keyword, from the well-obfuscated
distribution of the similarity score. However, it does not suf-
ﬁce to protect keyword privacy. For simplicity, we assume
that there are 2 levels, i.e., only one keyword t at level 1 and
ε1,j
two or more other keywords at level 2. At level 1,
does not follow the Normal distribution with σ selected by
2 as
the user, in that with the smaller V1, the value of σ1
V1c2/3 is smaller than the value of σ2 as (V1 + V2)c2/3. It is
possible that σ1 is too small to obfuscate the distribution of
the similarity score, so that the cloud server may identify the
keyword t at level 1. For better protecting keyword privacy,
the user chooses an appropriate σ1, i.e., large enough to ob-
fuscate the distribution, to generate ε1,j accordingly, while σ
remains as the overall search parameter. Hence, the variance
2 and ε2,j is generated
σ2
ε1,j and
accordingly, as the normal random variables
ε2,j are independent to each other. Finally, keyword
privacy can be well protected by these phantom keywords.
Remarks Recently Yao et al. [32] ﬁnd that this underlying
encryption method [31] is susceptible to chosen plaintext at-
tack. However, it is not applicable under our deﬁned threat
models, since in order to launch such attack, the cloud serv-
er has to acquire plaintext query information, i.e., the nor-
malized IDF weights, which are only possessed by the data
owner and protected by BMTS and EMTS.
2 for level 2 can be set as σ2 − σ1
(cid:6)
j∈ ¯V2
(cid:6)
j∈ ¯V1
4. EFFICIENCY OF THE TREE-BASED
SEARCH ALGORITHM
In the plaintext information retrieval community, many
well-developed techniques have been adopted to accelerate
the search process, e.g., inverted index [18], B-tree [9], etc.
However,
in the ciphertext scenario, they cannot be im-
plemented in a straightforward manner. In [10, 28, 29, 34],
the inverted index based search methods are employed to
achieve an extremely eﬃcient search process. However, these
schemes are only designed for single keyword search. Eﬃ-
cient range search in database [17] can be realized by using
B+-tree, but it is not applicable to the text search scenari-
o. The similarity score in our scheme is a value depend-
ing on the query and has to be evaluated in the runtime,
which makes the ﬁxed tree structures, such as B-tree or
B+-tree, not suitable here.
In this paper, we propose a
tree-based search algorithm, which is adapted from MDB-
tree based MD-algorithm, to enable eﬃcient multi-keyword
ranked search.
In what follows, we brieﬂy introduce our
tree-based search algorithm and present some experimental
results from our implementation of the proposed tree-based
search algorithm on a real-world document set: the recent
ten years’ INFOCOM publications. We identify key factors
that aﬀect the search eﬃciency and propose strategies in
building the index tree that eﬀectively speed up the search
process.
4.1 Tree-based Search Algorithm
The MD-algorithm is originally designed for plaintext database
search.
In the case of privacy-preserving similarity-based
multi-keyword ranked text search, it cannot be applied in a
straightforward manner. Instead of a numerical “attribute
value” for each attribute in the MDB-tree, our index tree
structure has to be built on vectors. The secure index scheme
described in section 3 is for this purpose and it enables the
76Baseline
Strategy 1
Strategy 1 + Strategy 2
Strategy 1 + Strategy 2 + Strategy 3
Table 1: Impact of prediction threshold
ˆPi Time (ms) # of accessed nodes Precision Rank privacy
1
33
32
28
11
17007
15012
14326
6410
100%
100%
90.3%
10.6%
0%
0%
6.5%
87.2%
)
s
m
(
e
m
i
t
h
c
r
a
e
S
120
100
80
60
40
20
0
5
0.05
0.02
0.01
30
35
10
15
20
25
Number of documents (× 102)
Figure 6: Comparison of search eﬃciency with dif-
ferent eﬃciency-improving strategies
search algorithm to take the inputs of the encrypted search-
able index tree and the encrypted query, and ensures that
the search algorithm is conducted in a secure way to protect
important search privacy in the whole search process.
Another remarkable diﬀerence between our search algo-
rithm and MD-algorithm is that we cannot set ˆPi to Pi as
running the MD-algorithm in database scenario, since Pi
varies for queries in our scenario and has to be securely e-
valuated (as described in section 3) in the runtime. The
pseudo code for our tree-based search algorithm is present-
ed in Appendix.
4.2 Impact of Prediction Threshold Value
An important factor that aﬀects the search eﬃciency is
the prediction threshold value ˆPi at each level i. To ensure
the search precision, ˆPi ≥ Pi should hold where Pi is the
maximum similarity score at level i. As shown in Tab. 1,
the tighter the prediction value of ˆPi, the higher the search
eﬃciency. The reason is that the search process can be ter-
minated earlier without going into unnecessary nodes. On
the other hand, when ˆPi < Pi, the search precision (a quan-
titative measure for search accuracy, cf.
section 5) drops
below 100% while the rank privacy (a privacy measure. cf.
section 5) increases.
Strategy 1 Based on this observation, our ﬁrst eﬃciency
enhancement aims to produce a better estimation of ˆPi that
approximates to its ideal value Pi. We propose the follow-
ing strategy to achieve this. During the index tree genera-
tion phase, the data owner retains a vector Ei for each level
i. This vector consists of the maximum values at each di-
mension among all the indexes at this level. Subsequently,
during the query generation phase, ˆPi is equal to the inner
product of Ei and Qi, and ˆPi will be set to 1 if it is greater
than 1, thus Pi ≤ ˆPi ≤ 1. ˆPi can be taken as an additional
search parameter to be sent with (cid:3)Qi to the cloud server. As
εi,j from Qi to ˆPi,
for EMTS, we add the maximum
and refer to this sum as the ﬁnal prediction threshold value.
In Fig. 6, it is shown that the search eﬃciency is improved
with this strategy, compared to the baseline search, in which
ˆPi is always set to 1, the upper bound of cosine function.
(cid:6)
j∈ ¯Vi
4.3 Impact of Intended Keyword Position
Another factor we observed that aﬀects the search eﬃcien-
cy is the position of the search keywords on the index tree.
As shown in Tab. 2, the higher level the intended keywords
Table 2: Impact of keyword position
Keyword position Time (ms) # of accessed nodes
1st
15th
30th
50th
5
32
33
36
491
13304
23844
49001
Table 3: Impact of clustering
Ed Time (ms) # of accessed nodes Precision Rank privacy
0.02
0.05
100%
97.00%
0%
2.1%
7062
6728
7.4
6.24
reside, the higher the search eﬃciency. This is very diﬀerent
from using the MD-algorithm in database scenario where all
the attributes are involved in searching the relevant objects.
In the text search scenario, people are likely to complete a
search with a query only comprising ﬁve keywords or less [1].
Consequently, the search algorithm needs to go through a
larger number of nodes to evaluate an intended keyword if
it resides at a lower level.
Strategy 2 The insight from this observation is that the
average search time can be improved by strategically arrang-
ing keyword position in the index tree – the most frequently
searched keywords on the top levels.
In our experiment,
we collected a set of 100 search requests from the volun-
teering users of this prototype secure search system. We
then build the index tree where keywords are re-ordered by
their search popularity. In practice, the information on the
search keyword distribution can be extracted from the us-
er search history. As shown in Fig. 6, the eﬃciency of the
search algorithm is ameliorated signiﬁcantly when applying
this strategy.
4.4 Impact of Index Vector Clustering
Another idea for improving the search eﬃciency is to clus-
ter “similar” index vectors, as shown in Tab. 3. The im-
proved eﬃciency comes from the reduced number of accessed
nodes in the index tree, but at the expense of lower search
precision. The bigger each cluster is, the higher the search
eﬃciency, but the lower the search precision.
Strategy 3 To maximize the possibility of clustering, the
length of the index vector at each level should be as short
as possible (but at least achieve 80-bit symmetric key secu-
rity [31]) in order to group the “similar” indexes. Inspired
by the k-means method, which is the most widely used clus-
tering technique in the data mining community [21], we use
Euclidean distance (Ed) as a metric to cluster “close enough”
vectors, e.g., when Ed < 1. For EMTS, we may ﬁrst cluster
original index vectors, and then execute dimension exten-
sion. The time cost for the search scheme after combining all
the three eﬃciency-improving strategies, where Ed = 0.02,
is shown in Fig. 6 as well.
Remarks The original combination of the MD-algorithm
77)
%
i
(
n
o
s
c
e
r
P
i
100
90
80
70
60
50
50
50
40
30
20
10
)
%
(