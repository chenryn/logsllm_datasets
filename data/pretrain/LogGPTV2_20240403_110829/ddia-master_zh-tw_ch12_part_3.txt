在维护衍生资料时，批处理和流处理都是有用的。流处理允许将输入中的变化以低延迟反映在衍生检视中，而批处理允许重新处理大量累积的历史资料以便将新检视汇出到现有资料集上。
特别是，重新处理现有资料为维护系统、演化并支援新功能和需求变更提供了一个良好的机制（请参阅 [第四章](ch4.md)）。没有重新进行处理，模式演化将仅限于简单的变化，例如向记录中新增新的可选栏位或新增新型别的记录。无论是在写时模式还是在读时模式中都是如此（请参阅 “[文件模型中的模式灵活性](ch2.md#文件模型中的模式灵活性)”）。另一方面，透过重新处理，可以将资料集重组为一个完全不同的模型，以便更好地满足新的要求。
> ### 铁路上的模式迁移
>
> 大规模的 “模式迁移” 也发生在非计算机系统中。例如，在 19 世纪英国铁路建设初期，轨距（两轨之间的距离）就有了各种各样的竞争标准。为一种轨距而建的列车不能在另一种轨距的轨道上执行，这限制了火车网路中可能的相互连线【9】。
>
> 在 1846 年最终确定了一个标准轨距之后，其他轨距的轨道必须转换 —— 但是如何在不停运火车线路的情况下进行数月甚至数年的迁移？解决的办法是首先透过新增第三条轨道将轨道转换为 **双轨距（dual guage）** 或 **混合轨距**。这种转换可以逐渐完成，当完成时，两种轨距的列车都可以线上路上跑，使用三条轨道中的两条。事实上，一旦所有的列车都转换成标准轨距，那么可以移除提供非标准轨距的轨道。
>
> 以这种方式 “再加工” 现有的轨道，让新旧版本并存，可以在几年的时间内逐渐改变轨距。然而，这是一项昂贵的事业，这就是今天非标准轨距仍然存在的原因。例如，旧金山湾区的 BART 系统使用了与美国大部分地区不同的轨距。
衍生检视允许 **渐进演化（gradual evolution）**。如果你想重新构建资料集，不需要执行突然切换式的迁移。取而代之的是，你可以将旧架构和新架构并排维护为相同基础资料上的两个独立衍生检视。然后可以开始将少量使用者转移到新检视，以测试其效能并发现任何错误，而大多数使用者仍然会被路由到旧检视。你可以逐渐地增加访问新检视的使用者比例，最终可以删除旧检视【10】。
这种逐渐迁移的美妙之处在于，如果出现问题，每个阶段的过程都很容易逆转：你始终有一个可以回滚的可用系统。透过降低不可逆损害的风险，你能对继续前进更有信心，从而更快地改善系统【11】。
#### Lambda架构
如果批处理用于重新处理历史资料，而流处理用于处理最近的更新，那么如何将这两者结合起来？Lambda 架构【12】是这方面的一个建议，引起了很多关注。
Lambda 架构的核心思想是透过将不可变事件附加到不断增长的资料集来记录传入资料，这类似于事件溯源（请参阅 “[事件溯源](ch11.md#事件溯源)”）。为了从这些事件中衍生出读取最佳化的检视，Lambda 架构建议并行执行两个不同的系统：批处理系统（如 Hadoop MapReduce）和独立的流处理系统（如 Storm）。
在 Lambda 方法中，流处理器消耗事件并快速生成对检视的近似更新；批处理器稍后将使用同一组事件并生成衍生检视的更正版本。这个设计背后的原因是批处理更简单，因此不易出错，而流处理器被认为是不太可靠和难以容错的（请参阅 “[容错](ch11.md#容错)”）。而且，流处理可以使用快速近似演算法，而批处理使用较慢的精确演算法。
Lambda 架构是一种有影响力的想法，它将资料系统的设计变得更好，尤其是透过推广这样的原则：在不可变事件流上建立衍生检视，并在需要时重新处理事件。但是我也认为它有一些实际问题：
* 在批处理和流处理框架中维护相同的逻辑是很显著的额外工作。虽然像 Summingbird【13】这样的库提供了一种可以在批处理和流处理的上下文中执行的计算抽象。除错、调整和维护两个不同系统的操作复杂性依然存在【14】。
* 由于流管道和批处理管道产生独立的输出，因此需要合并它们以响应使用者请求。如果计算是基于滚动视窗的简单聚合，则合并相当容易，但如果检视基于更复杂的操作（例如连线和会话化）而汇出，或者输出不是时间序列，则会变得非常困难。
* 尽管有能力重新处理整个历史资料集是很好的，但在大型资料集上这样做经常会开销巨大。因此，批处理流水线通常需要设定为处理增量批处理（例如，在每小时结束时处理一小时的资料），而不是重新处理所有内容。这引发了 “[时间推理](ch11.md#时间推理)” 中讨论的问题，例如处理滞留事件和处理跨批次边界的视窗。增量化批处理计算会增加复杂性，使其更类似于流式传输层，这与保持批处理层尽可能简单的目标背道而驰。
#### 统一批处理和流处理
最近的工作使得 Lambda 架构的优点在没有其缺点的情况下得以实现，允许批处理计算（重新处理历史资料）和流计算（在事件到达时即处理）在同一个系统中实现【15】。
在一个系统中统一批处理和流处理需要以下功能，这些功能也正在越来越广泛地被提供：
* 透过处理最近事件流的相同处理引擎来重播历史事件的能力。例如，基于日志的讯息代理可以重播讯息（请参阅 “[重播旧讯息](ch11.md#重播旧讯息)”），某些流处理器可以从 HDFS 等分散式档案系统读取输入。
* 对于流处理器来说，恰好一次语义 —— 即确保输出与未发生故障的输出相同，即使事实上发生故障（请参阅 “[容错](ch11.md#容错)”）。与批处理一样，这需要丢弃任何失败任务的部分输出。
* 按事件时间进行视窗化的工具，而不是按处理时间进行视窗化，因为处理历史事件时，处理时间毫无意义（请参阅 “[时间推理](ch11.md#时间推理)”）。例如，Apache Beam 提供了用于表达这种计算的 API，可以在 Apache Flink 或 Google Cloud Dataflow 使用。
## 分拆资料库
在最抽象的层面上，资料库，Hadoop 和作业系统都发挥相同的功能：它们储存一些资料，并允许你处理和查询这些资料【16】。资料库将资料储存为特定资料模型的记录（表中的行、文件、图中的顶点等），而作业系统的档案系统则将资料储存在档案中 —— 但其核心都是 “资讯管理” 系统【17】。正如我们在 [第十章](ch10.md) 中看到的，Hadoop 生态系统有点像 Unix 的分散式版本。
当然，有很多实际的差异。例如，许多档案系统都不能很好地处理包含 1000 万个小档案的目录，而包含 1000 万个小记录的资料库完全是寻常而不起眼的。无论如何，作业系统和资料库之间的相似之处和差异值得探讨。
Unix 和关系资料库以非常不同的哲学来处理资讯管理问题。Unix 认为它的目的是为程式设计师提供一种相当低层次的硬体的逻辑抽象，而关系资料库则希望为应用程式设计师提供一种高层次的抽象，以隐藏磁碟上资料结构的复杂性、并发性、崩溃恢复等等。Unix 发展出的管道和档案只是位元组序列，而资料库则发展出了 SQL 和事务。
哪种方法更好？当然这取决于你想要的是什么。Unix 是 “简单的”，因为它是对硬体资源相当薄的包装；关系资料库是 “更简单” 的，因为一个简短的宣告性查询可以利用很多强大的基础设施（查询最佳化、索引、连线方法、并发控制、复制等），而不需要查询的作者理解其实现细节。
这些哲学之间的矛盾已经持续了几十年（Unix 和关系模型都出现在 70 年代初），仍然没有解决。例如，我将 NoSQL 运动解释为，希望将类 Unix 的低级别抽象方法应用于分散式 OLTP 资料储存的领域。
在这一部分我将试图调和这两个哲学，希望我们能各取其美。