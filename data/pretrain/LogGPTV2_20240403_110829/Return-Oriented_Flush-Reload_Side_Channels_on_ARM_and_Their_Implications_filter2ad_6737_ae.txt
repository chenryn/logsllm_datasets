[20] R. Delgado. Arm-based servers: The next evolution of
the cloud?
http://www.cloudcomputing-news.net/news/2015/
apr/17/arm-based-servers-next-evolution-cloud/.
[21] W. Diao, X. Liu, Z. Li, and K. Zhang. No pardon for
the interruption: New inference attacks on android
through interrupt timing analysis. In 37th IEEE
Symposium on Security and Privacy, 2016.
[22] D. Gruss, R. Spreitzer, and S. Mangard. Cache
template attacks: Automating attacks on inclusive
last-level caches. In 24th USENIX Security
Symposium, 2015.
[23] D. Gullasch, E. Bangerter, and S. Krenn. Cache games
– bringing access-based cache attacks on AES to
practice. In 32nd IEEE Symposium on Security and
Privacy, 2011.
[24] R. Hund, C. Willems, and T. Holz. Practical timing
side channel attacks against kernel space ASLR. In
34th IEEE Symposium on Security and Privacy, 2013.
[25] M. S. Inci, B. Gulmezoglu, G. Irazoqui, T. Eisenbarth,
and B. Sunar. Seriously, get oﬀ my cloud! cross-vm
rsa key recovery in a public cloud. Cryptology ePrint
Archive, Report 2015/898, 2015.
http://eprint.iacr.org/.
[26] G. Irazoqui, T. Eisenbarth, and B. Sunar. S$A: A
shared cache attack that works across cores and deﬁes
VM sandboxing—and its application to AES. In 36th
IEEE Symposium on Security and Privacy, 2015.
[27] G. Irazoqui, T. Eisenbarth, and B. Sunar. Cross
processor cache attacks. In 11th ACM Asia Conference
on Computer and Communications Security, 2016.
[28] G. Irazoqui, M. S. Inci, T. Eisenbarth, , and B. Sunar.
Wait a minute! a fast, cross-vm attack on AES. In
17th International Symposium Research in Attacks,
Intrusions and Defenses, 2014.
[29] A. Jaleel, E. Borch, M. Bhandaru, S. C. Steely Jr.,
and J. Emer. Achieving non-inclusive cache
performance with inclusive caches: Temporal locality
aware (tla) cache management policies. In 43rd
Annual IEEE/ACM International Symposium on
Microarchitecture.
[30] S. Jana and V. Shmatikov. Memento: Learning secrets
from process footprints. In 33rd IEEE Symposium on
Security and Privacy, 2012.
[31] C.-C. Lin, H. Li, X. Zhou, and X. Wang. Screenmilker:
How to milk your Android screen for secrets. In 21st
ISOC Network and Distributed System Security
Symposium, 2014.
[32] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and
S. Mangard. ARMageddon: Cache attacks on mobile
devices. In 25th USENIX Security Symposium, 2016.
[33] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee.
Last-level cache side-channel attacks are practical. In
36th IEEE Symposium on Security and Privacy, 2015.
[34] Y. Michalevsky, D. Boneh, and G. Nakibly.
Gyrophone: Recognizing speech from gyroscope
signals. In 23rd USENIX Security Symposium, 2014.
[35] M. Neve and J.-P. Seifert. Advances on access-driven
cache attacks on AES. In 13th international
conference on selected areas in cryptography, 2007.
[36] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and
A. D. Keromytis. The spy in the sandbox: Practical
cache attacks in javascript and their implications. In
86822nd ACM SIGSAC Conference on Computer and
Communications Security, 2015.
[37] D. A. Osvik, A. Shamir, and E. Tromer. Cache attacks
and countermeasures: the case of AES. In 6th
Cryptographers’ track at the RSA conference on
Topics in Cryptology, 2006.
[38] C. Percival. Cache missing for fun and proﬁt. In 2005
BSDCan, 2005.
[39] Z. Qian, Z. M. Mao, and Y. Xie. Collaborative TCP
sequence number inference attack: How to crack
sequence number under a second. In 19th ACM
Conference on Computer and Communications
Security, 2012.
[40] H. Rydberg. Multi-touch (mt) protocol. Linux kernel
documentation. https://www.kernel.org/doc/
Documentation/input/multi-touch-protocol.txt.
[41] H. Shacham. The geometry of innocent ﬂesh on the
bone: Return-into-libc without function calls (on the
x86). In 14th ACM Conference on Computer and
Communications Security, 2007.
[42] A. L. Shimpi. Answered by the experts: Arm’s cortex
a53 lead architect, peter greenhalgh.
http://www.anandtech.com/show/7591/
answered-by-the-experts-arms-cortex-a53-lead-architect
-peter-greenhalgh.
[43] R. Spreitzer and B. G´erard. Towards more practical
time-driven cache attacks. In 8th IFIP International
Workshop on Information Security Theory and
Practice, Securing the Internet of Things, 2014.
[44] R. Spreitzer and T. Plos. In 4th International
Workshop on Constructive Side-Channel Analysis and
Secure Design, 2013.
[45] R. Spreitzer and T. Plos. On the applicability of
time-driven cache attacks on mobile devices. In 7th
International Conference on Network and System
Security, 2013.
[46] E. Tromer, D. A. Osvik, and A. Shamir. Eﬃcient
cache attacks on AES, and countermeasures. J.
Cryptol., 23(2):37–71, Jan. 2010.
[47] M. Weiß, B. Heinz, and F. Stumpf. A cache timing
attack on AES in virtualization environments. In 16th
International Conference on Financial Cryptography
and Data Security, 2012.
[48] J. C. Wray. An analysis of covert timing channels. In
1991 IEEE Computer Society Symposium on Research
in Security and Privacy, 1991.
[49] Y. Yarom and N. Benger. Recovering OpenSSL
ECDSA nonces using the FLUSH+RELOAD cache
side-channel attack. In Cryptology ePrint Archive,
2014.
[50] Y. Yarom and K. E. Falkner. FLUSH+RELOAD: A
high resolution, low noise, L3 cache side-channel
attack. In 23rd USENIX Security Symposium, 2014.
[51] N. Zhang, K. Yuan, M. Naveed, X. Zhou, and
X. Wang. Leave me alone: App-level protection
against runtime information gathering on android. In
36th IEEE Symposium on Security and Privacy, 2015.
[52] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-VM side channels and their use to extract
private keys. In 19th ACM Conference on Computer
and Communications Security, 2012.
[53] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-tenant side-channel attacks in PaaS clouds. In
21st ACM Conference on Computer and
Communications Security, 2014.
[54] X. Zhou, S. Demetriou, D. He, M. Naveed, X. Pan,
X. Wang, C. A. Gunter, and K. Nahrstedt. Identity,
location, disease and more: Inferring your secrets from
Android public resources. In 20th ACM Conference on
Computer and Communications Security, 2013.
[55] Z. Zhou, M. K. Reiter, and Y. Zhang. A software
approach to defeating side channels in last-level
caches. In 23rd ACM Conference on Computer and
Communications Security, 2016.
APPENDIX
A. DISSECTING CACHE DIMENSIONS
The ARM speciﬁcation only speciﬁes the size of cache
lines, leaving the number of cache ways and cache sets cho-
sen by the processor manufacturers. The ARM manufac-
turers, however, usually do not reveal such implementation
details. Moreover, unlike their x86 counterparts, ARM does
not provide unprivileged cpuid instructions to determine
cache dimensions at runtime. We develop methods to pro-
grammatically determine the cache dimensions, which are
useful information for Appendix B and Appendix C. Spe-
cially, a cache’s dimension can be uniquely characterized by
its cache line size L, the number of cache ways W and the
number of cache sets S . The total cache size C is given by
C = L × W × S .
We develop a technique to determine W and S of L1 data
cache, L1 instruction cache and the uniﬁed L2 cache by only
using timing information involved in memory accesses. Spe-
cially, our method is a series of hypothesis tests. The null
hypotheses are W = n, where n is some integer. In each test
for the L1 data cache and the L2 cache, we ﬁrst allocate a
physically consecutive memory buﬀer that has twice the size
of the cache under testing, 2C . Then we access (by loading)
2n memory addresses m1 , m2 , m3 ,··· , m2n , so that mi −
mi−1 = k, where k takes value from {L, 2L, 4L,··· , C /n,···}.
The tests for the L1 instruction cache are similar except that
by loading the memory we are executing a dummy function
that implements short instruction sequences starting at ad-
dresses mi which jumps to address mi+1 after execution.
We measure the total execution time of loading (or execut-
ing) the set of memory 1000 times (the memory is preloaded
to eliminate the impact of page faults and TLB misses). We
accept the null hypothesis for each value of n if the 1000
memory access latency is much higher when k = C /n than
others. Otherwise we reject the null hypothesis. This is be-
cause When W = n and k = C /n, mi − mi−1 = L × S .
Hence, the 2n memory accesses land in the same cache
set, and on average n cache miss will take place in each
loop. Therefore, the total execution time is longer because
of 1000n cache misses.
In other cases, these memory ac-
cesses do not land in the same cache set, so no cache miss
will be observed. We calibrate the L1 data cache, L1 instruc-
tion and the L2 cache in separate tests. We repeated each
run 20 times for statistical signiﬁcance. Fig. 7a, Fig. 7b and
Fig. 7c show the memory access latency in the tests where
we correctly guessed W . It is clear in such cases k = C /W
leads to high access latency.
869(a) L1 data cache
(b) L1 instruction cache
Figure 7: Cache dimension test
(c) L2 cache
B. CLEANSING CACHES
In this section, we describe techniques we developed to
completely clease L2 caches on ARM. These techniques are
used in Sec. 3.2, Sec. 3.3 and Appendix C.
Cleansing caches by fetching data. We start by allocat-
ing a memory buﬀer from which we select N cache-line-sized
memory blocks that all map to the same cache set. These N
memory blocks consist the eviction set. We then from the
same buﬀer select a disjunct set of 5 memory blocks that
also map to the same cache set. We call this set of 5 blocks
the test set. An eviction strategy deﬁnes the size of the evic-
tion set, N , and the order of accessing its memory blocks.
To test the eﬀectiveness of each strategy in cleansing the L2
cache, we ﬁrst access the eviction set using the underlying
strategy and then immediately afterwards load k (where k
ranges from 1 to 5) memory blocks from the test set. The
above process is repeated 1000 times and the average execu-
tion time of each loop is measured, denoted Tk. The cache
set is completely evicted using the tested eviction strategy
if Ti − Ti−1 are similar in magnitude for i = 2, 3, 4, 5 and are
comparable to the time required for a cache miss.
Cleansing caches by executing instructions. To cleanse
L2 cache by code execution, both the eviction set and the
test set need to be ﬁlled with binary code that will transfer
the control ﬂows from one memory block to another, follow-
ing speciﬁc order. Successfully doing so requires some engi-
neering eﬀorts. Particularly, we need to place the instruc-
tions in N discontinuous cache-line-aligned memory blocks
that map to the same cache set, and then in each memory
block calculate the virtual address of the next memory block
and jump to the target to fetch the instruction into the L2
cache and L1 instruction cache.
Finding the best cleansing strategies. Each eviction
strategy we explore can be uniquely identiﬁed by the size
of the eviction set, N , the shift oﬀset between two mem-
ory access sequences, A, and the number of continuously
visited blocks in each memory access sequence, D (similar
to [32]). The total memory accesses in each eviction strategy
is its cost. Our goal is to ﬁnd an eviction strategy that com-
pletely evicts a cache set but at the same time has the lowest
cost. In our experiments, we used a brute-force approach to
search the optimal eviction scheme10. The strategies listed
in Table 5, although not optimal, can already cleanse the
entire L2 cache with relatively low costs. We used these
strategies in Sec. 3.2, Sec. 3.3 and Appendix C.
10
Due to implementation complexity to arbitrarily adjust A and D,
we ﬁx them both as 1 in the instruction-based L2 cleansing tests.
Smartphone
Nexus 6
Samsung S5 (A15)
Samsung S5 (A7)
Samsung S6 (A57)
Samsung S6 (A53)
Cache
L2
2MB
8-way
2MB
16-way
512KB
8-way
2MB
16-way
256KB
16-way
d-Strategy
i-Strategy
N A D N A D
10
17
10
17
20
1
2
1
2
2
3
3
2
5
4
16
24
16
24
24
1
1
1
1
1
1
1
1
1
1
Table 5: Cache cleansing strategy.
C. EXCLUSIVE VS. NON-INCLUSIVE
CACHES
Once the inclusiveness of the L2 cache has been precluded
using methods described in Sec. 3.3, one could conduct the
following experiments (using the same shared native library
and dummy function described in Sec. 3.2) to determine if
it is exclusive or non-inclusive to the L1 data cache.
First, the function code is read as data a few times to load
it into the L1 data cache. Then the same app executes the
function to measure its execution time, T1. The measure-
ment is compared with the results of the second experiment,
in which the L2 cache is cleansed from the instruction side
(see Appendix B) before executing it to ensure L2 cache
misses. The time to execute the function in this case is de-
If T1 (cid:28) T2, T1 is measured with L2 cache
noted as T2.
hits, which suggests reading the function code also brings
the function body into the L2 cache. In this case, the L2
cache is non-inclusive to L1 the data cache; otherwise it is
exclusive to the L1 data cache.
To run the same tests for the instruction cache, we ﬁrst
execute function a few times to make sure it was loaded
into the L1 instruction cache. Then in the same program,
immediately afterwards, we read the function body as data
and measured the time for loading, denoted T1. In a second
test, the L2 cache is ﬁrst cleansed from the data side (see
Appendix B) and then the time needed to read the same
function is measured as T2. Essentially, T2 reﬂects the time
needed to read the function with L2 misses. If T1 (cid:28) T2, T1
is measured with L2 cache hits, which suggests executing the
function brings the function body into the L2 cache. In this
case, the L2 cache is non-inclusive to L1 instruction cache;
otherwise it is exclusive to L1 instruction cache.
2565121K2K4K8K16Kk050000100000150000200000250000Time for 1000 loops (ns)Nexus 6 (C=16K W=4)S5-A15 (C=32K W=4)S5-A7 (C=32K W=4)S6-A57 (C=32K W=4)S6-A53 (C=32K W=4)2565121K2K4K8K16Kk050000100000150000200000250000300000350000Time for 1000 loops (ns)Nexus 6 (C=16K W=4)S5-A15 (C=32K W=4)S5-A7 (C=32K W=4)S6-A57 (C=32K W=4)S6-A53 (C=32K W=4)5121K2K4K8K16K32K64K128K256Kk0100000020000003000000400000050000006000000Time for 1000 loops (ns)Nexus 6 (C=2M W=8)S5-A15 (C=2M W=16)S5-A7 (C=512K W=8)S6-A57 (C=2M W=16)S6-A53 (C=256K W=16)870