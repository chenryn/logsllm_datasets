speciﬁes certain sequences of security operations that lead
(a) An FSA describing Property 3
// Here ruid=x (a normal user), euid=0 (root)
execl(“/bin/sh”, “sh”, NULL);
(b) A segment from a setuid-root program that violates
Property 3. The user will receive a shell with full root
access, which may not have been intended. Probably
the programmer should have called seteuid(x) to drop
privilege before spawning the shell.
Figure 3: An FSA illustrating Property 3 (execl()
must not be called in privileged state) and a pro-
gram violating it
function drop privilege drops privilege, but the path [d0d1]
fails to do so. So the path [m1d0d2d3d4m2m3] satisﬁes Prop-
erty 3, but the path [m1d0d1m2m3] violates it. These types
of path-dependent errors are common in programs, but such
interprocedural errors are diﬃcult to discover with testing or
manual review, especially if the caller and callee are in dif-
ferent source ﬁles. As a result, we conclude that automated
tools to help with this task are needed.
In this paper, we describe an automated approach to help
examine security-related temporal safety properties (abbre-
viated as security properties henceforth) in software. We
have built MOPS 2, a program analysis tool that allows us
to make these properties explicit and to verify whether they
are properly respected by the source code of some applica-
tion.
MOPS determines at compile time whether there is any
execution path through a program that may violate a se-
curity property. Since it is infeasible to traverse every exe-
cution path because there are prohibitively many paths, we
use techniques from model checking and program analysis
to structure the analysis. We model the security property
as a Finite State Automaton (FSA) and the program as a
Pushdown Automaton (PDA). We then use model checking
to determine whether certain states representing violation of
the security property in the FSA are reachable in the PDA.
Our approach may be viewed as an application of lightweight
formal methods to an interesting class of security properties.
MOPS is distinguished from other related tools in the
following aspects. First, since it is based on a solid for-
mal foundation, i.e., model checking, it can take advantage
2MOdel Checking Programs for Security properties
unprivnoexec  privnoexecseteuid(0)seteuid(!0)otherotherunpriv  exec  priv  execexecl( )otherexecl( )execl( )seteuid(0)to potential security violations and that should be avoided.
The problem is to determine if there exists any execution
path through the program that contain such a sequence of
operations.
2.2 The Formal Framework
We start with a highly abstract model. Let Σ be the set
of security-relevant operations. Let B ⊆ Σ∗ be all sequences
of security operations that violate the security property (B
stands for bad ). A trace t ∈ Σ∗ will represent a sequence of
operations executed by a path p through the program, and
we say that t is a feasible trace if p is a possible execution
path through the program. Let T ⊆ Σ∗ denote the set of
all feasible traces, extracted from all execution paths of the
program (T stands for trace). The problem is to decide if
T ∩ B is empty. If so, then the security property is satisﬁed.
If not, then some execution path in the program violates the
security property.
In the above model, B and T are arbitrary languages.
Since in general T is an uncomputable set, deciding whether
T ∩ B = ∅ is an undecidable problem. To make the problem
decidable, we specialize the problem by restricting the form
of B and T .
First, we assume that B, the set of sequences of security
operations that violate the security property, is a regular
language. Our experiences show that most temporal safety
properties can be described by regular languages (see Sec-
tions 3 and 5 for examples). Since B is a regular language,
there exists a Finite State Automaton (FSA) M that ac-
cepts B (M stands for model ); in other words, B = L(M ).
We will usually identify the security property with its rep-
resentation as an FSA.
Although we assume that B is a regular language, it is
not suﬃcient to assume that T , the set of all feasible traces,
will always be a regular language. The problem is that a
regular language cannot describe the execution paths that
cross function calls very well. In the case of a function call, a
stack is needed to record the return address in the caller, and
the language generated with a stack is context free rather
than regular. Therefore, in this paper we model the set T
of feasible traces as a context free language. It follows that
there exists a Pushdown Automaton (PDA) P that accepts
T (P stands for program). A PDA consists of a set of states,
stack symbols, input symbols, and transitions. A snapshot
of the PDA, called a conﬁguration, consists of its current
state and all the symbols on the stack. A transition speciﬁes
that the PDA moves from one conﬁguration to another upon
receiving a certain input symbol. With these specializations
of B and T , the original problem becomes deciding if L(M )∩
L(P ) is empty.
To solve the problem, ﬁrst we need to compute L(M ) ∩
L(P ). Since C = L(M ) ∩ L(P ) is the intersection of a reg-
ular language (L(M )) and a context free language (L(P )),
C is a context free language. It also follows that C is ac-
cepted by the PDA that is the intersection of M and P .
Second, we need to determine if the language C is empty.
According to automata theory, there are eﬃcient algorithms
to compute the intersection of a PDA and an FSA and to
determine if the language accepted by a PDA is empty [13,
§6.2 and §6.3]. Hence we obtain a means to verify whether
the security property is satisﬁed by the program.
Using a context free language to model the set of feasi-
ble traces does introduce some imprecision. In general we
have T ⊆ L(P ): the PDA P will indeed accept all feasi-
ble traces, yet it might also accept some additional, spuri-
ous traces that are in fact infeasible due to the presence of
other eﬀects (such as data ﬂow) not modeled in our frame-
work. Nonetheless, since T ⊆ L(P ), we are guaranteed that
T ∩ B ⊆ L(P ) ∩ L(M ). Consequently, if L(M ) ∩ L(P ) is
empty, we can conclude that T ∩ B is also empty, hence the
program deﬁnitely satisﬁes the security property; in con-
trast, if L(M ) ∩ L(P ) is non-empty, then we can only say
that T ∩ B may or may not be empty, hence the program
might not satisfy the security property, but there are no
guarantees in this case.
This means that our analysis is sound : it may make mis-
takes by giving false alarms (warnings that do not corre-
spond to an actual security vulnerability), but it will not
overlook a real violation of the security property. This lim-
itation is unavoidable. Since the general problem is unde-
cidable, no algorithm can both avoid false alarms and avoid
overlooking real bugs. Our experience is that false alarms
are tolerable enough in practice that the approach is still
useful despite occasional bogus warning messages.
2.3 A Concrete Example
To illustrate the formal framework, let us work through a
concrete example. The problem is to check if the program in
Figure 4 violates the security property that a process should
not make the execl system call while it is in the privileged
state (Figure 3(a))
In this problem, the set of security operations is Σ =
{execl(), seteuid(0), seteuid(!0)}, where the last element rep-
resents any call to seteuid with a non-zero parameter (rep-
resenting a non-root user ID). The set B ⊆ Σ∗, the se-
quences of security-relevant operations that violate the se-
curity property, is accepted by the FSA M shown in Fig-
ure 3(a). The set T ⊆ Σ∗, the feasible traces of the program
in Figure 4, is T = {[seteuid(!0), execl()], [execl()]}. Since
this is a setuid-root program, the initial state in the FSA
M is (priv, noexec). According to Figure 3(a), although the
path [seteuid(!0), execl()] in T is not accepted by M , the
path [execl()] in T is accepted by M . Therefore, we ﬁnd
that T ∩ L(M ) 6= ∅, or in other words, an execution path in
the program violates the security property. This indicates
the presence of a security vulnerability.
3.
IMPLEMENTATION OF FORMAL MOD-
ELS
In this section, we describe how to construct formal mod-
els from security properties and programs.
3.1 Modeling Security Properties
We call an FSA that describes a security property a secu-
rity model. A transition in the FSA represents an execution
of a security-relevant operation. All sequences of operations
that violate the property end in the ﬁnal states of the FSA.
So the ﬁnal states might also be thought of as risky states
and are shown in double circles in the ﬁgures. The FSAs
describing Properties 1, 2, and 3 in Section 1 are shown in
Figures 1(a), 2(a), and 3(a) respectively. Note that in these
ﬁgures each transition labeled other is a special transition,
which is taken when no other transition from the same state
can be taken.
3.1.1 Modularization
(a) A model of process privilege.
(b) A model of risky system calls.
(c) A composite model describing the property that
a process should not make risky system calls while it
is in the privileged state. The model is automatically
constructed as the product of 5(a) and 5(b). Note that
the outgoing transitions from the ﬁnal state (priv, exec)
are omitted for clarity.
Figure 5: Building a complex model from simpler
models.
One important feature of MOPS is that it allows complex
security properties to be decomposed into simpler security
models which are easier to describe. MOPS is able to com-
bine these simpler models into a complex model on the ﬂy 3.
For example, consider the property that a process should
not make a risky system call such as execl while it is in
the privileged state. This property can be decomposed into
two simpler models: the ﬁrst one describes the transition
of a process between the privilege state and the unprivi-
leged state (Figure 5(a)) and the second one describes the
execution of a risky system call (Figure 5(b)). MOPS auto-
matically combines the two simpler FSAs into the product
automaton shown in Figure 5(c). Checking the program in
Figure 4 against this security model shows that the risky
state is reachable at the program point m3.
Modularization also makes it possible to reuse existing
3The complex model is a product automaton of the au-
tomata of the simple models
models. Suppose we have already built the model of process
privilege (Figure 5(a)) and we want to build the model for
the property that a process should not make risky system
calls in the privileged state (Figure 5(c)). Instead of building
it from scratch, we only need to build the model describing
risky system calls (Figure 5(b)) and then plug in the ex-
isting model of process privilege (Figure 5(a)). This allows
the construction of a model library which supplies building
blocks for new models.
Enabling modularity is very important for practical use.
For ease of presentation, we have so far described only se-
curity properties that have concise representations as small
FSAs, but in practice our security models may be very com-
plex. For instance, our model of user IDs in Linux has dozens
of states and many more transitions. If we had to re-specify
this every time we wanted to check some security property
that involves privileges, the result would be too unwieldy for
practical use. Modularity comes to the rescue here: it lets
us build a few base models once, then we can compose and
extend them in many interesting ways.
3.1.2 Pattern Variables
MOPS is control ﬂow and path sensitive but data ﬂow
insensitive. In other words, we ignore most data ﬂow: for
instance, when processing an if-then-else statement, we
conservatively assume that either branch could be taken,
and we do not try to analyze whether the condition to the
if statement is true or not. We make this choice for the
following reasons. First, we conjecture that many security
properties do not require the analysis of data ﬂow. Second,
analysis of data ﬂow is expensive and will severely limit the
scalability of MOPS. Third, we can do rudimentary data
ﬂow analysis by encoding data values into a security model.
For example, if we want to analyze the value of a boolean
variable b, then we can split each state si in the security
model into two states si,0 and si,1, where si,0 represents
when b is true and si,1 represents when b is false.
MOPS supports a special form of data ﬂow analysis via
pattern variables. A pattern variable used in an FSA may
be bound to any expression that satisﬁes context constraints
in a program. For example, if x is a pattern variable in the
FSA in Figure 6(a), then x can be bound to the expression
either a or b in the program in Figure 6(b). In other words,
pattern variables enable syntactic matching.
3.2 Modeling Programs
Since we only care about all feasible paths in a program
and the statements executed on these paths, we can model
the execution of the program by a pointer and a stack. The
pointer points to the program position of the next statement
to be executed, and the stack records the return addresses
of all unﬁnished function calls. Therefore, the value of the
pointer and the values on the stack uniquely identify a snap-
shot of the program in execution. If we merge the pointer
and the stack by regarding the pointer as the top element
on the stack, we get a Pushdown Automaton(PDA). The
control ﬂow in the program determines the transitions in
the PDA. An algorithm that constructs the PDA from the
program is described elsewhere [7].
Once we have an FSA describing a security property and
a PDA representing a program, our goal is to check if any
risky state in the FSA is reachable at any program point
in the PDA. To answer this question, MOPS composes the
unprivprivseteuid(0)seteuid(!0)otherothernoexecexecexecl()otherotherexecl()unprivnoexec  privnoexecseteuid(0)seteuid(!0)otherotherunpriv  exec  priv  execexecl( )otherexecl( )execl( )seteuid(0)(a) An example of a security property using pattern
variables.
int main()