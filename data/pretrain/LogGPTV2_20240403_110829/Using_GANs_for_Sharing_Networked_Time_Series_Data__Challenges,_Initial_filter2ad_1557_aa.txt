# Title: Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions

## Authors:
- Zinan Lin
- Alankar Jain (IBM, New York, NY)
- Chen Wang (Carnegie Mellon University, Pittsburgh, PA)
- Giulia C. Fanti (Carnegie Mellon University, Pittsburgh, PA)
- Vyas Sekar (Carnegie Mellon University, Pittsburgh, PA)

## Abstract
Limited data access has long been a barrier to data-driven research and development in the networked systems community. In this work, we explore the potential of generative adversarial networks (GANs) to incentivize data sharing by enabling a generic framework for generating synthetic datasets with minimal expert knowledge. Our focus is on time series datasets with metadata, such as packet loss rate measurements with corresponding ISPs. We identify key challenges in existing GAN approaches, including fidelity (e.g., long-term dependencies, complex multidimensional relationships, mode collapse) and privacy (i.e., poorly understood guarantees that can sacrifice fidelity). To address these, we design a custom workflow called DoppelGANger (DG), which achieves up to 43% better fidelity than baseline models across diverse real-world datasets and use cases. While we do not fully resolve the privacy problem, we highlight fundamental challenges and suggest a roadmap for future research. Our work aims to rekindle the conversation on workflows for data sharing.

## CCS Concepts
- Networks → Network simulations
- Computing methodologies → Knowledge representation and reasoning

## Keywords
- Synthetic data generation
- Time series
- Generative adversarial networks
- Privacy

## ACM Reference Format
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar. 2020. Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions. In ACM Internet Measurement Conference (IMC '20), October 27–29, 2020, Virtual Event, USA. ACM, New York, NY, USA, 20 pages. https://doi.org/10.1145/3419394.3423643

## 1. Introduction
Data-driven techniques are central to networking and systems research, allowing network operators and system designers to make empirical-based decisions. However, the benefits of data-driven research are often limited to those who possess the data. Collaborating stakeholders, such as ISPs and equipment vendors, are reluctant to share datasets due to concerns about revealing business secrets and violating user privacy. One alternative is to create and share synthetic datasets modeled from real traces. While there have been some successes in this area, these approaches typically require significant human expertise and do not easily generalize across different workloads and use cases.

The overarching question of our work is whether we can create high-fidelity, easily generalizable synthetic datasets for networking applications with minimal human expertise. This paper explores the use of generative adversarial networks (GANs) to achieve this goal. GANs offer the ability to learn high-fidelity representations of high-dimensional relationships in datasets and allow users to flexibly tune generation, making them a promising tool for data sharing.

We focus on an important class of networking/systems datasets: time series measurements associated with multi-dimensional metadata, such as physical network properties and datacenter usage. We identify key challenges in using GANs for this task, including capturing complex correlations and long-term dependencies, and ensuring privacy. Our primary contribution is the design of DoppelGANger (DG), a practical workflow that addresses these challenges. DG outperforms baseline models in terms of fidelity and downstream tasks. Additionally, we explore the privacy trade-offs of GANs and provide insights into mitigating membership inference attacks and differential privacy guarantees.

## 2. Motivation and Related Work
### 2.1 Use Cases and Requirements
There are many scenarios where data sharing is beneficial, such as collaboration between network operators and equipment vendors, and reproducible open research. We consider three representative tasks:
1. **Structural Characterization:** Understanding temporal and geographic trends in systems.
2. **Predictive Modeling:** Learning predictive models for tasks like resource allocation.
3. **Algorithm Evaluation:** Evaluating the performance of algorithms on generated data.

Our focus is on multi-dimensional time series datasets, common in networking and systems applications. Examples include web traffic traces, network measurements, and cluster usage metrics. We require techniques that can accurately capture dataset and use case diversity, achieving high fidelity without requiring significant human expertise.

### 2.2 Related Work and Limitations
Prior work in the networking domain falls into three categories: simulation models, expert-driven models, and machine-learned models.

#### Simulation Models
These generate data by building simulators that mimic real systems or networks. While they can be highly accurate if well-configured, it is challenging to ensure the simulator closely matches the real system. Moreover, they do not generalize well across different datasets and use cases.

#### Expert-Driven Models
These involve capturing data using mathematical models determined by domain experts. While they can achieve high fidelity, they require significant human expertise and do not generalize well.

#### Machine-Learned Models
These are general parametric models that can be learned from data. They offer the potential for generalization but may struggle with capturing complex relationships and long-term dependencies.

## 3. Background and Challenges
### 3.1 Background on GANs
Generative adversarial networks (GANs) consist of a generator and a discriminator. The generator creates synthetic data, while the discriminator evaluates its authenticity. GANs have shown promise in generating high-fidelity data, but they face challenges in capturing complex relationships and ensuring privacy.

### 3.2 Challenges in Using GANs for Time Series Data
#### Fidelity
- **Complex Correlations:** Capturing the intricate relationships between measurements and their metadata.
- **Long-Term Dependencies:** Handling long-term temporal correlations, such as diurnal patterns.
- **Mode Collapse:** GANs may generate data that only covers a few modes of the distribution, ignoring others.

#### Privacy
- **Poorly Understood Guarantees:** The privacy properties of GANs are not well understood.
- **Potential Memorization:** GANs may inadvertently reveal proprietary information or suffer from deanonymization attacks.
- **Privacy-Preserving Techniques:** Existing techniques may sacrifice the utility of the data.

## 4. Design of DoppelGANger (DG)
DoppelGANger (DG) is a practical workflow designed to address the challenges of using GANs for time series data. The key components of DG include:

### 4.1 Decoupled Metadata Generation
To model correlations between measurements and their metadata, DG decouples the generation of metadata from time series. Metadata is fed to the time series generator at each time step, and an auxiliary discriminator is introduced for metadata generation. This contrasts with conventional approaches where metadata and time series are generated jointly.

### 4.2 Addressing Mode Collapse
To tackle mode collapse, DG generates randomized maximum and minimum limits and a normalized time series, which can then be rescaled to the realistic range. This approach helps cover a broader range of data samples.

### 4.3 Capturing Temporal Correlations
DG outputs batched samples rather than singletons to capture temporal correlations. This idea, while used in Markov modeling, is relatively new in GANs and has not been extensively studied in the context of time series generation.

## 5. Evaluation
We evaluate DG across multiple datasets and use cases, including bandwidth measurements, cluster requests, and web sessions. Our results show that DG:
- Learns structural microbenchmarks of each dataset better than baseline approaches.
- Consistently outperforms baseline algorithms on downstream tasks, such as training prediction algorithms, with test accuracies up to 43% higher.

## 6. Privacy Trade-offs
We explore the privacy trade-offs of GANs, which is an open challenge in the ML community. We empirically confirm that membership inference attacks can be mitigated by training DG on larger datasets. We also highlight that the decoupled generation architecture of DG can enable data holders to hide certain attributes of interest. However, recent proposals for GAN training with differential privacy guarantees destroy temporal correlations even for moderate privacy levels, highlighting the need for further research.

## 7. Conclusion
In this work, we have explored the potential of GANs for generating high-fidelity, easily generalizable synthetic datasets for networking applications. Our custom workflow, DoppelGANger (DG), addresses key challenges in fidelity and provides insights into privacy trade-offs. By shedding light on the promise and challenges, we hope to rekindle the conversation on workflows for data sharing.

## Acknowledgments
We thank [acknowledge any support, funding, or contributions].

## References
[References listed here]