title:Using GANs for Sharing Networked Time Series Data: Challenges, Initial
Promise, and Open Questions
author:Zinan Lin and
Alankar Jain and
Chen Wang and
Giulia C. Fanti and
Vyas Sekar
Using GANs for Sharing Networked Time Series Data:
Challenges, Initial Promise, and Open Questions
Zinan Lin
Chen Wang
Alankar Jain
IBM
New York, NY
PI:EMAIL
Carnegie Mellon University
Pittsburgh, PA
PI:EMAIL
Carnegie Mellon University
Pittsburgh, PA
PI:EMAIL
Giulia Fanti
Carnegie Mellon University
Pittsburgh, PA
PI:EMAIL
Vyas Sekar
Carnegie Mellon University
Pittsburgh, PA
PI:EMAIL
ABSTRACT
Limited data access is a longstanding barrier to data-driven re-
search and development in the networked systems community.
In this work, we explore if and how generative adversarial net-
works (GANs) can be used to incentivize data sharing by enabling
a generic framework for sharing synthetic datasets with minimal
expert knowledge. As a specific target, our focus in this paper is
on time series datasets with metadata (e.g., packet loss rate mea-
surements with corresponding ISPs). We identify key challenges
of existing GAN approaches for such workloads with respect to
fidelity (e.g., long-term dependencies, complex multidimensional
relationships, mode collapse) and privacy (i.e., existing guarantees
are poorly understood and can sacrifice fidelity). To improve fi-
delity, we design a custom workflow called DoppelGANger (DG)
and demonstrate that across diverse real-world datasets (e.g., band-
width measurements, cluster requests, web sessions) and use cases
(e.g., structural characterization, predictive modeling, algorithm
comparison), DG achieves up to 43% better fidelity than baseline
models. Although we do not resolve the privacy problem in this
work, we identify fundamental challenges with both classical no-
tions of privacy and recent advances to improve the privacy prop-
erties of GANs, and suggest a potential roadmap for addressing
these challenges. By shedding light on the promise and challenges,
we hope our work can rekindle the conversation on workflows for
data sharing.
CCS CONCEPTS
• Networks → Network simulations; • Computing method-
ologies → Knowledge representation and reasoning.
KEYWORDS
synthetic data generation, time series, generative adversarial net-
works, privacy
This work is licensed under a Creative Commons Attribution International 4.0 License
 IMC ’20, October 27–29, 2020, Virtual Event, USA 
© 2020 Copyright held by the owner/author(s). 
ACM ISBN 978-1-4503-8138-3/20/10.
https://doi.org/10.1145/3419394.3423643
464
ACM Reference Format:
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar. 2020.
Using GANs for Sharing Networked Time Series Data: Challenges, Initial
Promise, and Open Questions. In ACM Internet Measurement Conference
(IMC ’20), October 27–29, 2020, Virtual Event, USA. ACM, New York, NY, USA,
20 pages. https://doi.org/10.1145/3419394.3423643
1 INTRODUCTION
Data-driven techniques [51] are central to networking and systems
research (e.g., [11, 16, 23, 48, 60, 60, 71, 74, 83, 104]). This approach
allows network operators and system designers to explore design
choices driven by empirical needs, and enable new data-driven
management decisions. However, in practice, the benefits of data-
driven research are restricted to those who possess data. Even when
collaborating stakeholders have plenty to gain (e.g., an ISP may
need workload-specific optimizations from an equipment vendor),
they are reluctant to share datasets for fear of revealing business
secrets and/or violating user privacy. Notable exceptions aside (e.g.,
[2, 77]), the issue of data access continues to be a substantial concern
in the networking and systems communities.
One alternative is for data holders to create and share synthetic
datasets modeled from real traces. There have been specific suc-
cesses in our community where experts identify the key factors
of specific traces that impact downstream applications and create
generative models using statistical toolkits [5, 29, 31, 43, 64, 68, 78–
81, 97, 98, 109, 110, 115]. Unfortunately, this approach requires
significant human expertise and does not easily generalize across
workloads and use cases.
The overarching question for our work is: Can we create high-
fidelity, easily generalizable synthetic datasets for networking ap-
plications that require minimal (if any) human expertise regarding
workload characteristics and downstream tasks? Such a toolkit
could enhance the potential of data-driven techniques by making
it easier to obtain and share data.
This paper explores if and how we can leverage recent advances
in generative adversarial networks (GANs) [46]. The primary bene-
fit GANs offer is the ability to learn high fidelity representations
of high-dimensional relationships in datasets; e.g., as evidenced
by the excitement in generating photorealistic images [65], among
other applications. A secondary benefit is that GANs allow users to
flexibly tune generation (e.g., augment anomalous or sparse events),
which would not be possible with raw/anonymized datasets.
IMC ’20, October 27–29, 2020, Virtual Event, USA
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar
To scope our work, we consider an important and broad class of
networking/systems datasets—time series measurements, associated
with multi-dimensional metadata; e.g., measurements of physical
network properties [11, 12] and datacenter/compute cluster usage
measurements [15, 54, 90].
We identify key disconnects between existing GAN approaches
and our use case on two fronts:
• With respect to fidelity, we observe key challenges for existing
GAN techniques to capture: (a) complex correlations between
measurements and their associated metadata and (b) long-term
correlations within time series, such as diurnal patterns, which
are qualitatively different from those found in images. Further-
more, on datasets with a highly variable dynamic range GANs
exhibit severe mode collapse [6, 50, 70, 101], wherein the GAN
generated data only covers a few classes of data samples and
ignores other modes of the distribution.
• Second, in terms of privacy, we observe that the privacy prop-
erties of GANs are poorly understood. This is especially im-
portant as practitioners are often worried that GANs may be
“memorizing” the data and inadvertently reveal proprietary
information or suffer from deanonymization attacks [8, 67,
85, 89, 94, 103, 105]. Furthermore, existing privacy-preserving
training techniques may sacrifice the utility of the data [3, 14,
35, 40, 112, 113], and it is not clear if they apply in our context.
Our primary contribution is the design of a practical workflow
called DoppelGANger (DG) that synthesizes domain-specific in-
sights and concurrent advances in the GAN literature to tackle the
fidelity challenges. First, to model correlations between measure-
ments and their metadata (e.g., ISP name or location), DG decouples
the generation of metadata from time series and feeds metadata to
the time series generator at each time step, and also introduces an
auxiliary discriminator for the metadata generation. This contrasts
with conventional approaches where these are generated jointly.
Second, to tackle mode collapse, our GAN architecture separately
generates randomized max and min limits and a normalized time se-
ries, which can then be rescaled back to the realistic range. Third, to
capture temporal correlations, DG outputs batched samples rather
than singletons. While this idea has been used in Markov mod-
eling [44], its use in GANs is relatively preliminary [70, 92] and
not studied in the context of time series generation. Across mul-
tiple datasets and use cases, we find that DG: (1) is able to learn
structural microbenchmarks of each dataset better than baseline
approaches and (2) consistently outperforms baseline algorithms
on downstream tasks, such as training prediction algorithms (e.g.,
predictors trained on DG generated data have test accuracies up to
43% higher).
Our secondary contribution is an exploration of privacy trade-
offs of GANs, which is an open challenge in the ML community
as well [62]. Resolving these tradeoffs is beyond the scope of this
work. However, we empirically confirm that an important class of
membership inference attacks on privacy can be mitigated by train-
ing DG on larger datasets. This may run counter to conventional
release practices, which advocate releasing smaller datasets to avoid
leaking user data [91]. A second positive result is that we highlight
that the decoupled generation architecture of DG workflow can
enable data holders to hide certain attributes of interest (e.g., some
specific metadata may be proprietary). On the flip side, however,
we empirically evaluate recent proposals for GAN training with
differential privacy guarantees [3, 14, 35, 40, 112, 113] and show
that these methods destroy temporal correlations even for moderate
privacy guarantees, highlighting the need for further research on
the privacy front.
Roadmap: In the rest of the paper, we begin by discussing use
cases and prior work in §2.2. We provide background on GANs and
challenges in §3. We describe the design of DG in §4 and evaluate it
in §5. We analyze privacy tradeoffs in §6, before concluding in §7.
2 MOTIVATION AND RELATED WORK
In this section, we discuss motivating scenarios and why existing
solutions fail to achieve our goals.
2.1 Use cases and Requirements
While there are many scenarios for data sharing, we consider two
illustrative examples: (1) Collaboration across stakeholders: Consider
a network operator collaborating with an equipment vendor to
design custom workload optimizations. Enterprises often impose
restrictions on data access between their own divisions and/or with
external vendors due to privacy concerns; and (2) Reproducible,
open research: Many research proposals rely on datasets to test and
develop ideas. However, policies and business considerations may
preclude datasets from being shared, thus stymieing reproducibility.
In such scenarios, we consider three representative tasks:
(1) Structural characterization: Many system designers also need
to understand temporal and/or geographic trends in systems; e.g.,
to understand the shortcomings in existing systems and explore
remedial solutions [11, 16, 60, 104]. In this case, generated data
should preserve trends and distributions well enough to reveal such
structural insights.
(2) Predictive modeling: A second use case is to learn predictive
models, especially for tasks like resource allocation [42, 61, 69].
For these models to be useful, they should have enough fidelity
that a predictor trained on generated data should make meaningful
predictions on real data.
(3) Algorithm evaluation: The design of resource allocation algo-
rithms for cluster scheduling and transport protocol design (e.g., [23,
48, 60, 71, 74, 83]) often needs workload data to tune control pa-
rameters. A key property for generated data is that if algorithm A
performs better than algorithm B on the real data, the same should
hold on the generated data.
Scope and goals: Our focus is on multi-dimensional time series
datasets, common in networking and systems applications. Exam-
ples include: 1. Web traffic traces of webpage views with metadata
of URLs, which can be used to predict future views, page corre-
lations [102], or generate recommendations [37, 86]; 2. Network
measurements of packet loss rate, bandwidth, delay with metadata
such as location or device type that are useful for network man-
agement [61]; or 3. Cluster usage measurements of metrics such as
CPU/memory usage associated with metadata (e.g., server and job
type) that can inform resource provisioning [21] and job scheduling
[75]. At a high level, each example consists of time series samples
(e.g., bandwidth measurements) with high-dimensional data points
and associated metadata that can be either numeric or categorical
465
Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions
IMC ’20, October 27–29, 2020, Virtual Event, USA
(e.g., IP address, location). Notably, we do not handle stateful in-
teractions between agents; e.g., generating full TCP session packet
captures.
Across these use cases and datasets, we require techniques that
can accurately capture two sources of diversity: (1) Dataset diversity:
For example, predicting CPU usage is very different from predict-
ing network traffic volumes. (2) Use case diversity: For example,
given a website page view dataset, website category prediction
focuses on the dependency between the number of page views and
its category, whereas page view modeling only needs the temporal
characteristics of page views. Manually designing generative mod-
els for each use case and dataset is time consuming and requires
significant human expertise. Ideally, we need generative techniques
that are general across diverse datasets and use cases and achieve
high fidelity.
2.2 Related work and limitations
In this section, we focus on non-GAN-based approaches, and defer
GAN-based approaches to §3.3.1. Most prior work from the net-
working domain falls in two categories: simulation models and
expert-driven models. A third approach involves machine learned
models (not using GANs).
Simulation models: These generate data by building a simulator
that mimics a real system or network [30, 59, 73, 84, 95, 98, 99].
For example, ns-2 [59] is a widely used simulator for networks and
GloudSim [30] is a distributed cloud simulator for generating cloud
workload and traces. In terms of fidelity, this class of models is good
if the simulator is very close to real systems. However, in reality,
it is often hard to configure the parameters to simulate a given
target dataset. Though some data-driven ways of configuring the
parameters have been proposed [30, 73, 84, 95], it is still difficult to
ensure that the simulator itself is close to the real system. Moreover,
they do not generalize across datasets and use cases, because a new
simulator is needed for each scenario.
Expert-driven models: These entail capturing the data using
a mathematical model instead of using a simulation. Specifically,
domain expects determine which parameters are important and
which parametric model we should use. Given a model, the pa-
rameters can be manually configured [1, 27, 107] or learned from
data [5, 29, 31, 43, 64, 68, 78–81, 97, 98, 109, 110, 115]. For exam-
ple, the Hierarchical Bundling Model models inter-arrival times of
datacenter jobs better than the widely-used Poisson process [64].
Swing [109] extracts statistics of user/app/flow/link (e.g., packet
loss rate, inter-session times) from data, and then generate traffic
by sampling from the extracted distributions. In practice, it is chal-
lenging to come up with models and parameters that achieve high
fidelity. For example, BURSE [115] explicitly models the burstiness
and self-similarity in cloud computing workloads, but does not con-
sider e.g. nonstationary and long-term correlations [19]. Similarly,
work in cloud job modeling [64, 115] characterizes inter-arrival
times, but does not model the correlation between job metadata
and inter-arrival times. Such models struggle to generalize because
different datasets and use cases require different models.
Machine-learned models: These are general parametric models,