多线程模型中最简单的一种是生产者/消费者的模型，启动多个线程来共同消费一个队列就行了。新建`lib/threads.py`
    import threading
    import time
    def exception_handled_function(thread_function, args=()):
        try:
            thread_function(*args)
        except KeyboardInterrupt:
            raise
        except Exception as ex:
            print("thread {0}: {1}".format(threading.currentThread().getName(), str(ex)))
    def run_threads(num_threads, thread_function, args: tuple = ()):
        threads = []
        # 启动多个线程
        for num_threads in range(num_threads):
            thread = threading.Thread(target=exception_handled_function, name=str(num_threads),
                                      args=(thread_function, args))
            thread.setDaemon(True)
            try:
                thread.start()
            except Exception as ex:
                err_msg = "error occurred while starting new thread ('{0}')".format(str(ex))
                print(err_msg)
                break
            threads.append(thread)
        # 等待所有线程完毕
        alive = True
        while alive:
            alive = False
            for thread in threads:
                if thread.isAlive():
                    alive = True
                    time.sleep(0.1)
值得注意的一点是，我们并没有使用Python线程中推荐的`join()`来阻塞线程，因为使用`join()`的话，python将无法响应用户输入的消息了，会导致Ctrl+C退出时没有任何响应，所以以while循环的方式来阻塞线程。
接着将主程序改造成多线程的模式，将原`start()`中的"消费者"提取出来，单独用作一个函数，用队列接收数据即可。如下
    def worker():
        if not WORKER.empty():
            arg, poc = WORKER.get()
            try:
                ret = poc.verify(arg)
            except Exception as e:
                ret = None
                print(e)
            if ret:
                print(ret)
    def start(config: dict):
        url_list = config.get("url", [])
        # 生产
        for arg in url_list:
            for poc in POCS:
                WORKER.put((arg, poc))
        # 消费
        run_threads(10, worker)
另外，线程数量是我们可配置的，我们将它改成从配置中读取。
    run_threads(config.get("thread_num", 10), worker)
再次运行，会发现比以前快很多！
## 统一网络请求
这是我们整个框架的最后一个部分，如何来统一网络请求。有时我们需要让我们的PoC框架发出的网络请求中统一一下代理，UA头等等的设置，这需要我们框架进行统一的处理。在实现我们的目的之前，我们还需要在框架里做一个约定，约定我们的网络请求都需要统一使用`requests`来进行发包。开始时我们说到，我们会尽量不使用第三方模块，但是`requests`模块实在太好用了，我们将它排除在外...
Python语言动态的机制，我们可以很容易在使用一个函数之前Hook它，将它原始的方法重定向到我们自定义的方法中，这是我们能够统一网络请求的一个前提。
    def hello(arg):
        return "hello " + arg
    def hook(arg):
        arg = arg.upper()
        return "hello " + arg
    hello = hook
    print(hello("aa"))
通过hook一个函数来达到我们自己的目的。
像sqlmap这类工具，基于python内置的`urllib`模块，但是有大量的代码都在处理在了网络请求方面，甚至为了处理`chunked`发包的问题，hook重写了更底层的`httplib`库。
pocsuite为了统一调度网络请求，hook了`requests`模块的相关方法。我们可以具体参考其中的代码。
`pocsuite3/lib/request/patch/__init__.py`代码很清晰的说明了hook的函数
    from .remove_ssl_verify import remove_ssl_verify
    from .remove_warnings import disable_warnings
    from .hook_request import patch_session
    from .add_httpraw import patch_addraw
    from .hook_request_redirect import patch_redirect
    def patch_all():
        disable_warnings() # 禁用了warning提示
        remove_ssl_verify() # 禁用ssl验证
        patch_session() # hook seesion函数
        patch_addraw() # 添加raw原生发包支持
        patch_redirect() # hook 重定向函数
如果你看过requests的源码，会知道这里面的重点是看它如何hook seesion函数的。
`pocsuite3/lib/request/patch/hook_request.py`
    from pocsuite3.lib.core.data import conf
    from requests.models import Request
    from requests.sessions import Session
    from requests.sessions import merge_setting, merge_cookies
    from requests.cookies import RequestsCookieJar
    from requests.utils import get_encodings_from_content
    def session_request(self, method, url,
                        params=None, data=None, headers=None, cookies=None, files=None, auth=None,
                        timeout=conf.timeout if 'timeout' in conf else None,
                        allow_redirects=True, proxies=None, hooks=None, stream=None, verify=False, cert=None, json=None):
        # Create the Request
        merged_cookies = merge_cookies(merge_cookies(RequestsCookieJar(), self.cookies),
                                       cookies or (conf.cookie if 'cookie' in conf else None))
        req = Request(
            method=method.upper(),
            url=url,
            headers=merge_setting(headers, conf.http_headers if 'http_headers' in conf else {}),
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=merged_cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
        proxies = proxies or (conf.proxies if 'proxies' in conf else {})
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
        resp = self.send(prep, **send_kwargs)
        if resp.encoding == 'ISO-8859-1':
            encodings = get_encodings_from_content(resp.text)
            if encodings:
                encoding = encodings[0]
            else:
                encoding = resp.apparent_encoding
            resp.encoding = encoding
        return resp
    def patch_session():
        Session.request = session_request
它重写了`session_request`函数的方法，让其中可以自定义我们自定义的文件头等信息。上述代码可能需要你看过requests才会对他有所理解，不过没关系，我们还是以拿来主义的精神直接用即可。
为了达到此目的以及更好的优化框架结构，我们还需要做一些小调整。
新建`lib/requests.py`
    from lib.data import CONF
    from requests.models import Request
    from requests.sessions import Session
    from requests.sessions import merge_setting, merge_cookies
    from requests.cookies import RequestsCookieJar
    from requests.utils import get_encodings_from_content
    def session_request(self, method, url,
                        params=None, data=None, headers=None, cookies=None, files=None, auth=None,
                        timeout=None,
                        allow_redirects=True, proxies=None, hooks=None, stream=None, verify=False, cert=None, json=None):
        # Create the Request.
        conf = CONF.get("requests", {})
        if timeout is None and "timeout" in conf:
            timeout = conf["timeout"]
        merged_cookies = merge_cookies(merge_cookies(RequestsCookieJar(), self.cookies),
                                       cookies or (conf.cookie if 'cookie' in conf else None))
        req = Request(
            method=method.upper(),
            url=url,
            headers=merge_setting(headers, conf["headers"] if 'headers' in conf else {}),
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=merged_cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
        proxies = proxies or (conf["proxies"] if 'proxies' in conf else {})
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
        resp = self.send(prep, **send_kwargs)
        if resp.encoding == 'ISO-8859-1':
            encodings = get_encodings_from_content(resp.text)
            if encodings:
                encoding = encodings[0]
            else:
                encoding = resp.apparent_encoding
            resp.encoding = encoding
        return resp
    def patch_session():
        Session.request = session_request
同时在config中预留requests的接口
以及init的时候执行我们的hook。
我们新编写一个PoC，用这个网站测试一下 最后的效果 
`pocs/poc.py`
    import requests
    def verify(arg, **kwargs):
        r = requests.get(arg)
        if r.status_code == 200:
            return {"url": arg, "text": r.text}
效果很好，但是如果加上https的网站，就有一个警告信息。
同样参考Pocsuite的方法禁用掉warning信息
    from urllib3 import disable_warnings
    disable_warnings()
最后有仪式感的将版本号变更为`0.1`，AirPoc的框架部分大体完成了。
## 最后
AirPoc的很多结构思想都来源于Pocsuite，如果直接阅读Pocsuite，也许能收获很多东西。目前AirPoc
v0.1基础框架已经差不多完成了，已经可以从本地加载一个或多个PoC，进行批量测试。后面我们再尝试些更好玩的，如何验证无回显的情况，如何生成shellcode，以及如何操作回连的shell，敬请期待下节《功能篇》~。
AirPoc下载：
* * *