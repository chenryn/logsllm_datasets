bandwidth cost. Each edge in Gr has multiple weights due
to Monte Carlo simulations, and the number of which can be
over tens of thousands. Speciﬁcally, if a ﬂoating point num-
ber with 4-byte is used to denote the edge weight, each edge
will cost 160KB for 40K simulations. For example, the Gr
for benchmark circuit b18 shown later in Section 6.2 roughly
contains 600 edges and the bandwidth cost is nearly 1Gb.
For practical concerns, we design a bandwidth reduction al-
gorithm by transforming Gr to an equivalent timing graph
G(cid:48)
r with even fewer edges.
Observations on intermediate result reduction. The
key observation is that: many primes paths share the same
sub longest paths and their starting or ending vertices can
be used for graph transformation. Figure 5 illustrates our
idea explicitly. There exists a number mn of prime paths
{Pi,j}mn in Gr, where every boundary vertex from vi+1 to
vi+1vi+2vi+mvj+1vj+2vj+nvi+1vi+2vi+mvj+1vj+2vj+nvk242src and Qk
overlap is allowed, the intersection will be processed redun-
dantly over diﬀerent bridge vertices. For the implementa-
tion, Qk
sink are used to store the source and sink
vertices for vk. Qsrc and Qsink are used to store the source
and sink vertices that the bridge vertices already have for
the overlap checking. Our design is heuristic rather than
optimized, but it still performs well in the practical experi-
ment later. We also note that such saving is usually design
dependent. The more prime paths with share vertices, the
more saving will be gained.
4.5 Integration
Upon receiving the reduced timing graph Gr, LS inte-
grates Gr with Gc to compute the longest path distribution.
For the graph integration, the vertex indexes are ﬁrstly re-
covered by the reserved mapping information. Then the
adjacent list for each boundary vertex in Gc and Gr are
combined together. As CS computes the boundary-vertex
pairwise longest paths for each simulation, Gi is equivalent
to G except the outsourced paths are replaced by edges with
pre-computed weights. Therefore, the state-of-the-art tim-
ing analysis algorithm can be used to obtain the longest path
delay distribution as before, i.e., LS does not need to modify
the algorithm design and implementation. As the compu-
tation related to critical timing graph is performed at LS,
the path delays of critical IP blocks and the IC longest path
delay distribution are privacy preserving.
Note that the computation cost is proportional to the size
of critical IP blocks. The reason is that the sampling process
dominates the total runtime of timing analysis and Gr will
not introduce new vertices in Gi comparing Gc. Even Gi has
more edges than Gc, the runtime of graph traversal is negli-
gible to the sampling which will be demonstrated in Section
6. And the new boundary vertices after bandwidth reduc-
tion will not introduce too much overhead either, because
those vertices are not the boundary ones at the beginning
and their delay sampling process is already completed.
4.6 Discussions
Our proposed mechanism and system can be extended to
other EDA applications such as design veriﬁcations and op-
timizations. Design data can be partitioned according to
the criticality. However, we note that our design only works
for applications involving public and sensitive data and the
eﬀectiveness depends on the portion of sensitive data.
In
timing analysis, the more critical IP blocks a circuit con-
tains, the less saving will be gained from our system.
If
almost all the design data is sensitive, our design will be-
come ineﬀective. Even so, our design can still be widely
adopted, since many applications in most real-life scenarios
comprise both public and private data [27].
More generally, our design can be applied to graph-based
applications related on web graphs, social networks, trans-
portation networks and so on, as long as they contains sen-
sitive contents. For example, path recommendation in navi-
gation or location-based services can split the computation.
Paths that are close to user’s private locations (e.g., home,
school and hospital) are kept at user’s local device. Com-
putation related to the private information can be carried
out at local after the computation over public data at the
cloud side. For social graph-based services, the private rela-
tionship can be maintained at user’s local side., e.g., friend
discovery can generate the ﬁnal recommendation list after
ﬁltering the intermediate results from public graphs.
5. SECURITY ANALYSIS
In this section, we demonstrate that our system protects
the gate-level design and the functionalities of critical IP
blocks as stated in Section 3. Recall that our system ex-
tracts and always keeps the critical IP gate-level design at
the local private server, including the sensitive timing char-
acteristics and related timing analysis results. Under such
design, cloud has no access to the critical IP gate-level de-
sign. However, it wants to infer the critical IP functional-
ity through the aforementioned I/O pattern analysis. I/O
pattern analysis refers to the widely recognized reverse en-
gineering technique [21, 24], which tries to build the truth
table of IP functionality by observing deduced output bit
sequences from a suﬃcient number of random input bit se-
quences. Recent works on IC camouﬂage and IC obfusca-
tion [20, 21] evaluate their protection eﬀectiveness against
such I/O pattern analysis, and quantify the security strength
via the Hamming distance between correct and corrupted
outputs.
In our design, cloud wants to infer the possible I/O ver-
tices of the critical IPs from the boundary vertices of non-
critical IPs and then launch the I/O pattern analysis. To
quantify the security strength of IP functionality protection,
we follow the security framework from [20, 21]. Explicitly,
we also use the Hamming distance to measure the hardness
of reverse engineering. The larger the Hamming distance
between the guessed and the correct outputs is, the less in-
formation on IP functionality is considered to be disclosed.
And for each input sequence, such Hamming distance should
be larger than some given threshold.
Formally, we consider that some certain IP block has y
bit output, and λ is the security parameter, where λ < y.
For a suﬃcient number of c random inputs, if the Hamming
distance between the correct and guessed outputs is less or
equal than λ for each input, the reverse engineering suc-
ceeds. If the Hamming distance is larger than threshold λ,
we consider our IP functionality protection is secure. Note
that since the gate-level design of critical IP blocks is kept lo-
cally and fully unknown to cloud, cloud can only guess the
outputs randomly for each input sequence. For the given
y, λ and c, such successful probability P is the following:
(cid:0)y
k
(cid:1)/2y)c.
P = ((cid:80)
λ<k≤y
As the parameter settings suggested by the existing works [20,
21], a suﬃcient large c can range from a few hundred to a
few thousand, and λ as y/2 for high obscureness. Thus, the
security strength is considered acceptable when at least 50%
guessed output bits are diﬀerent from correct ones for each of
(cid:1)/2y)c =
(cid:0)y
(cid:1))/2y+1)c. The above derivation is because of
(cid:1) ≥
(cid:1) = 2y. Given the upper bound [16] that (cid:0)y
c input sequences. In this setting, P = ((cid:80)
((2y −(cid:0) y
(cid:0)y
(cid:80)
(cid:1) ≥ ( y
k )k, for 1 ≤ k ≤ n, we have(cid:0) y
y/2<k≤y
0≤k≤y
2 − 1
y
( n
2 . There-
fore, P ≤ ( 1
2y/2+1 )c. Here, P is negligible when applying
a suﬃcient large number of random input sequences, e.g.,
c = 1000. It demonstrates that IP functionality is hardly to
be inferred from the number of I/O only.
y/2 )y/2 = 2
y/2
y/2
k
k
k
Further, we can carefully design the critical IP blocks ex-
traction algorithm, which could introduce a number of ad-
ditional boundary vertices to further obfuscate the I/Os of
243Table 1: Performance Evaluation of Privacy-preserving Timing Analysis System
Benchmark
Timing evaluation at LS
Critical Public Extract
Name
b18
b19
leon3mp
netcard
leon2
leon3
#E
#V
|E|
|V |
114K 217K
232K 439K
546K 112K
725K 1316K
781K 1476K
900K 1865K
|Vi|
|V |
9%
10%
11%
10%
9%
11%
|Vi|
1-
|V |
91%
90%
89%
90%
91%
89%
Integrate Baseline
ti(s)
1.4K
3.3K
8.8K
9.9K
10.6K
13.9K
t(s)
14K
30K
73K
95K
104K
120K
Saving
1 − ti
t
91%
89%
88%
90%
90%
88%
te(s)
1.8
3.6
10.1
11.5
12.4
17.2
Per inst. at CS
Compute
to(s)
0.6K
0.9K
7K
9K
11K
13K
the critical IP blocks, e.g., by introducing more I/O vertices
shared between multiple IP blocks or including non-critical
I/O vertices in the critical IP blocks. Such methodology
could further harden the security strength of our critical IP
block protection.
6. EXPERIMENTAL EVALUATIONS
In this section, we evaluate our proposed privacy-preserving
timing analysis system on large benchmark circuits. The
results demonstrate that our system saves a considerable
computation time at LS. Then, we quantify the overhead
of our privacy-preserving design through the computation
cost at both LS and CS, and the bandwidth cost between
local and cloud. Finally, we estimate the capital on real-
world cloud services to show that the beneﬁt of shortening
overall system response time overwhelms the investment on
outsourcing computation to CS.
6.1 Experiment Setup
Benchmarks and critical IP simulation. We derive
the experimental circuits from IC benchmark IWLS 2005 [3].
Benchmark circuits with over one hundred thousand gates
are selected. The largest circuit contains nearly one mil-
lion gates. We adopt the famous canonical ﬁrst-order de-
lay model [7] to generate the deterministic gate delay for
each simulation (See Appendix). We assume the delay is
Gaussian distributed and we sample Gaussian numbers in-
dependently for various device parameters. For simplicity,
we assign the mean of each gate delay as its outgoing edge
number, and ignore the interconnect delays. We note that
such treatment will not aﬀect our design correctness. Af-
terwards, the number of simulations is set to 40k, i.e., the
golden number of Monte Carlo simulation [11], which leads
to a conﬁdent estimation error interval within 1%.
We use the circuit partition tool hMETIS 5 to create vir-
tual critical and non-critical IP blocks. hMETIS is a widely
adopted tool to package IP blocks, which can successfully
partition the circuit while minimizing the number of inter-
connects between blocks. Since our objective is mainly on
the performance evaluation, we omit the identiﬁcation of
critical IP blocks on benchmark circuits. Based on the re-
cent surveys [5, 14], the total number of IP blocks in a full
circuit is around 80 on average. Thus, we partition each
benchmark circuit into 80 blocks, where the size of each
block is slightly diﬀerent. Those surveys also report that
the newly designed IP blocks are around 10% in a full cir-
5hMETIS: the Hypergraph & Circuit Partitioning tool,
online
http://glaros.dtc.umn.edu/gkhome/metis/
hmetis/overview
at
cuit. And in the experiment, we treat those newly designed
IP blocks as critical ones. Regarding the estimated ratio,
around 10% blocks are selected randomly as virtual critical
ones. We note that such ratio could vary in practice. Later,
we will analyze that the smaller ratio of critical IP blocks,
the more computation saving will be gained.
Implementation. Our system is implemented in c++
with gcc O2 optimization. A commodity computer with
Intel i7 CPU and 8GB RAM is used at LS. Compute are
running on remote servers with 144 Intel Xeon E5 CPU
threads and 128GB RAM to simulate the environment of
cloud servers. The distributed high throughput computing
framework HTCondor6 is used to execute 100 Compute in-
stances parallelly, where each runs 400 simulations, satis-
fying 40K rule of thumb Monte Carlo simulations [11]. In
our experiment, 7 device parameters are set for the delay
model [11], so the Gaussian random number generator will
be invoked by 7 times to output a deterministic gate delay.
Random number generation is more expensive than arith-
metic operations and graph traversal, and dominates the
cost of Monte Carlo based timing analysis. Basically, there
are two typical approaches to generate random numbers in
simulations. One is to generate random numbers on-the-ﬂy
within each simulation. The other is to pre-compute and
cache the random numbers to reuse them. The latter ap-
proach demands a large amount of storage or memory for
caching a large amount of random numbers. Thus, we adopt
the former approach to generate random gate delays.
6.2 Performance Analysis
Computation cost evaluation.
In Table 1, the columns
under “Benchmark” summarize the benchmark circuit size,
the critical IP block ratio (Critical) and the non-critical IP
block ratio (Public) in a full circuit. The computation cost
is reported for both LS and CS. te, ti, and to are the time
performance of Extract, Integrate and Compute on each com-
puting instances respectively. We also run the state-of-the-
art timing analysis (i.e., PERT) at LS to obtain the baseline
t for comparison.
The time of Monte Carlo timing analysis is roughly pro-
portional to the number of vertices according to baseline t.
In Table 1, if LS runs PERT based timing analysis, it takes
roughly 120, 000 seconds, i.e., 34 hours, for the circuit with
nearly 1 million of gates, which is quite expensive. Using
our system, LS now only runs PERT over critical IP blocks
for around 3.8 hours. The local saving is 88%, roughly equal
to the ratio of outsourced public IP blocks 89%. We note
6HTCondor: the open source distributed computing soft-
ware, online at http://research.cs.wisc.edu/htcondor/
244Table 2: System Overhead and Runtime Speedup Evaluation
System overhead
System response time
Total time
m ∗ to + ti(ks)
Response time
to + ti(ks)
64.2
96.6
708.8
909.9
1110.6
1313.9