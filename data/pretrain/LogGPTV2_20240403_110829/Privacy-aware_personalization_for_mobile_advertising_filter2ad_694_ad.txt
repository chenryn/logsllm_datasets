and R(M(cid:48)(LU\(Pm∪{p})), LPm∪{p}) are
and LPm∪{p}, i.e., VP (cid:48)
identically distributed.
m
m
The deﬁnition considers the view of a (non-)participant p. This
view contains messages sent and received by any participant col-
luding with p, denoted by P (cid:48)
In case p is not malicious P (cid:48)
m.
is {p}. Privacy means that this view can be simulated from an
m
output that preserves probabilistic differential privacy of the users
who are not malicious. This output is generated by some algo-
rithm M(cid:48) from the users’ input that are neither malicious nor equal
to p (LU\(Pm∪{p})). We do not attempt to protect the privacy of
malicious participants. This is indeed impossible, since the adver-
sary controlling them could always send a message containing LPm
which breaches their privacy. Moreover, we do not protect p’s pri-
vacy against herself. The simulation takes this output as well as
the input from all malicious participants to produce the same view.
The second input is necessary for a simulation to be possible at all.
A central building block of our protocol is a procedure for com-
667Protocol 1 Robust, distributed count computing a privacy-
preserving version of the sum over all private user bits bi.
Count(σ2, t)
1. Each user i with bit bi samples ki ∈ {0, . . . , p − 1} i.i.d.
2. Each user i samples ri from N (σ2/((1 − t)N − 1)).
3. Each user i uses 2-Phase-Commit to atomically send ki to
4. The proxy sums up all incoming messages mi. It forwards
the server and mi=bi+(cid:98)ri(cid:99)+ki mod p to the proxy.
s =(cid:80) mi mod p to the server.
mod p) it received and releases the result(cid:80) bi + ri.
5. The server subtracts from s the random numbers ki (
puting a sum over user values. We will use it to compute how many
users clicked on an ad a in context c.
4.2 A Privacy-Preserving, Distributed Count
4.2.1 Our counting protocol
Protocol 1 describes our protocol Count(t, σ2). Each user ui
for i = 1, . . . , N holds a bit bi. The protocol computes a noisy
version of the sum(cid:80) bi. The parameter p is a sufﬁciently large
prime number, t is an upper bound on the fraction of malicious
or unavailable users, and σ2 is the amount of noise. If more than t
fraction of users turn out to be malicious or unavailable, the privacy
guarantee degrades and/or the protocol needs to be aborted before
Step 4 and restarted (with a larger value for t). As t increases, the
share of noise each participant adds to his or her bit increases.
Efﬁciency. The number of messages exchanged in Count is linear
in the number of users, as in the most efﬁcient previous solutions [1,
37, 40]. Messages across Count computations can be batched.
Robustness. Unlike previous protocols [37, 40], Count success-
fully terminates as long as at least (1 − t)N users send messages
to server and proxy. Unlike these previous protocols, our proto-
col does not expect the secrets of participating users to add up to
a predeﬁned constant. Rather, it lets users independently choose
their own secrets ki (Step 1) and uses secrets of only the users who
have participated throughout the entire protocol. Unlike [1], our
protocol can tolerate failures of users during its execution. When
Count is executed multiple times, it sufﬁces that for each execu-
tion, at least (1 − t)N possibly different users participate. Thus,
our protocol can deal with unavailable users much more efﬁciently
than previous protocols.
4.3 Privacy
Following Deﬁnition 1, the protocol preserves privacy.3
THEOREM 4.1. For users with real values b(1)
col Count(σ2, t) can be used repeatedly to compute(cid:80) b(1)
of(cid:80) b(1)
with noise added to protect privacy. Let s denote the L2-sensitivity
. Consider  ≤ 1 and σ2 ≥ 2s2 ln(4/δ)/2.
The protocol guarantees (, δ)-probabilistic differential privacy in
the presence of up to a fraction of t unavailable or malicious users.
, . . . ,(cid:80) b(d)
i Proto-
, . . . , b(d)
, . . . ,(cid:80) b(d)
i
i
i
i
i
The proof relies on Gaussian noise to protect the privacy. In the
case of a trusted server, it is well know that adding Gaussian noise
protects privacy. In particular, we can sanitize the output of any
real-valued function f : ad logs → Rd by adding Gaussian noise
3Our protocol can also guarantee -differential privacy if Laplace
noise is generated in a distributed way, following techniques de-
scribed in [1].
Figure 2: Hierarchy H over contexts.
to f (L). The standard deviation of the noise depends on the L2-
sensitivity of f which describes how much the value of the function
can change if a single user’s data is deleted from the input. This
change is measured by the L2-norm.
PROPOSITION 4.2. For  ≤ 1 and σ2 ≥ s22 ln(4/δ)/2, adding
Gaussian noise with variance σ2 to a function f with L2-sensitivity
s gives (, δ)-probabilistic differential privacy.
This theorem has been established for δ-approximate -indistin-
guishability [12] and extends to our deﬁnition, which is stronger [19].
Now, when we consider all the participants of the protocol we use
the addition of Gaussian noise as M(cid:48) in Deﬁnition 1 and show that
their view can be generated from it. Details can be found in [18].
Additional Guarantees. Our protocol also provides some guaran-
tees in case either server or proxy (but not both) are corrupted by
an adversary (but not colluding with any user or the other server).
If the proxy is corrupted by an adversary, we guarantee that the
adversary will not be able to learn information that breaches pri-
vacy. This guarantee holds since the proxy sends only the very
last message of the protocol upon which no further action is taken.
Similarly, if the server is corrupted we guarantee that the adversary
will not be able to learn information that breaches privacy. The
adversary may send any value to the proxy from which(cid:80) ki will
be subtracted. The output will be random in case the value is not
a sum that contains exactly one term for each received message
mi. In this case privacy is trivially preserved. Otherwise the value
contains sufﬁcient noise to preserve privacy. These guarantees are
meaningful with regard to adversaries who want to learn private
information. We do not guarantee that a malicious adversary can-
not breach privacy: an adversary corrupting the proxy could release
the keys, which would allow the honest-but-curious server to learn
bi + ri, which would breach privacy.
4.4 Employing Count to compute CTRs
Given Count, the above statistics can be estimated well for con-
texts with a lot of user data (e.g., clicks). However, for a large
number of contexts sufﬁcient click data may not be available. For
such rare or new contexts, the estimates can be noisy or not even
be deﬁned. We suggest estimating Pr[c] and CTR(a|c) for a rare
context c based on contexts similar to c for which we have enough
click data. Coming back to our example from Section 2, if we do
not have enough click data for users who were skating in Central
Park, we might use clicks from users in close-by locations who
were doing some sort of physical activity (˜c) to estimate the statis-
tics for the context c. This helps us increase coverage of targeted
ads, albeit at the possible cost of lower quality ads. To deﬁne simi-
larity over contexts, we reuse the hierarchies over which users gen-
eralize their context attributes. The context hierarchy is built by
merging various attribute hierarchies; a concrete example will be
shown in Section 5.1. This hierarchy tells us, for each general-
Count ≥ min_support Count   min_support then
for each child w of v do
return TopDown(ad log, w , λ, min_support)
clicksa
clicked (or only viewed) a. The results of this computation is re-
ferred to as clicksa,v (no_clicksa,v, resp.). The estimated click-
through-rate is then simply (cid:91)CTR(a|v) =
.
clicksa,v +no_clicksa,v
TopDown also computes the total number of times a descendant
of v appears in the ad log and adds noise to this count. If the count
is above min_support then the algorithm recurses on v’s children,
otherwise all descendants are pruned. We note that the accuracy
of Estimates can be further improved by using the post-processing
techniques of Hay et al. to make sure the counts of all children add
up to the parent’s count [24]. To bound the sensitivity and to guar-
antee differential privacy, we limit the number of entries per user
in the ad log. Estimates deletes from the ad log all but m random
entries per user and then calls TopDown.
We now analyze the privacy and efﬁciency of our algorithm.
Let a denote the maximum number of ads bidding on the same
context. We denote by height(H) the height of the hierarchy and
by branch(H) the maximum number of children for a node in H.
Estimates makes O(a+branch(H))·height(H)·N·m/min_support)
calls to Count with high probability and is thus independent of the
number of contexts. Moreover, when we use Count in Estimates
we can batch all the messages in one level in the hierarchy.
In Estimates we employ Count to obtain noisy estimates of
clicksa,v, no_clicksa,v, and countv.
ized context, which attribute to generalize next.4 Given some rare
context, we can generalize it until we have a sufﬁcient number of
clicks for the generalized context. With these clicks we estimate
the CTRs. The parameter min_support speciﬁes how many clicks
are sufﬁcient for robust estimates. Figure 2 shows a hierarchy H
over contexts with leaf nodes being exact contexts and intermediate
nodes being generalized contexts. It shows a cut-off through the hi-
erarchy so that all (generalized) contexts above the cut-off have at
least min_support many clicks in the training data for descendant
contexts. The contexts below the threshold need to be generalized
before estimating their CTRs.5
Possible Solutions. One possible way to employ Count to ob-
tain privacy-preserving statistics for various contexts is to compute
noisy counts for all possible contexts and all possible ads. Another
alternative approach, with better utility, would be to use multi-
dimensional histograms [43, 23]. However, all these approaches
have a running time at least linear in the number of possible con-
texts, rendering them infeasible. Moreover, a large part of the
computation is wasteful, since, as mentioned before, statistics com-
puted for rare contexts are almost meaningless.
To address this problem, we opt for a simple top-down approach
that can efﬁciently deal with sparse data by identifying and pruning
the computations for rare contexts. The solution requires using a
context hierarchy that speciﬁes similarity of contexts. Such a top-
down algorithm has been used recently to ﬁnd frequent signatures
by gradually expanding the preﬁx of signatures with high noisy
counts [33]. We adapt it to compute CTRs over a context hierarchy.
A Top-Down Algorithm. To compute privacy-preserving CTRs
for the generalized contexts in the hierarchy H, algorithm TopDown
starts at the root and moves down the hierarchy. For each traversed
node v and for each ad a, it estimates CTR(a|v) by calling Count
to compute how often users in a descendant context of v have
4It is recommend but not required that users generalize the contexts
they send to the server to a node in the hierarchy.
5Note that there are other ways to deﬁne similarity, for example
using the lattice structure imposed by the attributes’ hierarchies.
Our experimental results show only a minor effect on quality when
using a ﬁxed combined hierarchy as opposed to a lattice structure.
COROLLARY 4.3
(PRIVACY). Consider any  ≤ 1. Let σ2 be
at least 6· height(H)· m2 · log(4/δ)/2. When Estimates employs
Count(t, σ2) as a subroutine for counting clicksa,v, no_clicksa,v,
countv, it guarantees (, δ)-probabilistic differential privacy. A
fraction of t unavailable or malicious users during each call of
Count(t, σ2) can be tolerated.
A proof and a utility analysis can be found in Appendices A.1, A.2.
This completes our discussion of the statistics gathering in our
framework. Next, we illustrate with an example, how it ﬁts together
with the online component of ad targeting described in Section 3.
EXAMPLE 4.4. The server has a list of all users, all contexts
c, a hierarchy of these contexts, and all ads a. It periodically es-
timates the values of Pr[c] and (cid:91)CTR(a|c), for all c and a, by exe-
cuting the Estimates algorithm. While doing so, it walks top-down
through the context hierarchy. Whenever Count is invoked, it asks
all users to submit their counts (either views or clicks of a in v or
simply appearances of v) to the proxy. The proxy does not need to
know (but may know) what is being counted. Note that Estimates
might not be able to compute (cid:91)CTR(a|c), for all c → ˆc. Some
contexts, like skating in Central Park, might be to sparse in which
case they we will be substituted by the lowest ancestor for which an