This is scrapy's default `Dupefilter` class method `request_seen`
    class RFPDupeFilter(BaseDupeFilter):
        def request_seen(self, request):
            fp = self.request_fingerprint(request)
            if fp in self.fingerprints:
                return True
            self.fingerprints.add(fp)
            if self.file:
                self.file.write(fp + os.linesep)
While implementing a custom dupefilter. i cannot retrieve the `spider` object
from this class unlike other scrapy middleware
Is there any way i can know which `spider` object this is? so i can customize
it via a spider on spider basis?
Also i cannot just implement a middleware which reads urls and puts it into a
list & checks duplicates instead of a custom dupefilter. This is because i
need to pause/resume crawls and need scrapy to store the request fingerprint
by default using the `JOBDIR` setting