title:Definition and Specification of Accrual Failure Detectors
author:Xavier D&apos;efago and
P&apos;eter Urb&apos;an and
Naohiro Hayashibara and
Takuya Katayama
See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/4156666
Deﬁnition and speciﬁcation of accrual failure detectors
READS
134
Naohiro Hayashibara
Kyoto Sangyo University
95 PUBLICATIONS   809 CITATIONS   
SEE PROFILE
Conference Paper · January 2005
DOI: 10.1109/DSN.2005.37 · Source: IEEE Xplore
CITATIONS
39
4 authors, including:
Xavier Défago
Tokyo Institute of Technology
146 PUBLICATIONS   2,872 CITATIONS   
SEE PROFILE
Takuya Katayama
Japan Advanced Institute of Science and Technology
142 PUBLICATIONS   1,240 CITATIONS   
SEE PROFILE
Some of the authors of this publication are also working on these related projects:
Accrual Failure Detectors View project
Mobile Robots View project
All content following this page was uploaded by Takuya Katayama on 04 June 2014.
The user has requested enhancement of the downloaded file.
Deﬁnition and Speciﬁcation of
Accrual Failure Detectors
Xavier Défago1,2, Péter Urbán1, Naohiro Hayashibara1, Takuya Katayama1
1School of Information Science, Japan Advanced Institute of Science and Technology (JAIST)
2PRESTO, Japan Science and Technology Agency (JST)
March 22, 2005
IS-RR-2005-004
Japan Advanced Institute of Science and Technology (JAIST)
School of Information Science
1-1 Asahidai, Nomi, Ishikawa 923-1292, Japan
http://www.jaist.ac.jp/
ISSN 0918-7553
Deﬁnition and Speciﬁcation of Accrual Failure Detectors∗
Xavier D´efago(a,b), P´eter Urb´an(a), Naohiro Hayashibara(a),Takuya Katayama(a)
(a)School of Information Science,
Japan Advanced Institute of Science and Technology (JAIST),
1-1 Asahidai, Nomi, Ishikawa 923-1292, Japan.
(b)PRESTO, Japan Science and Technology Agency (JST).
Email: {defago,urban,nao-haya,katayama}@jaist.ac.jp
Abstract
For many years, people have been advocating the development of failure detection as a basic
service, but, unfortunately, without meeting much success so far. We believe that this comes from
the fact that important system engineering issues have not yet been addressed adequately, thus pre-
venting the deﬁnition of a truly generic service. Ultimately, our goal is to deﬁne a service that is
both simple and expressive, yet powerful enough to support the requirements of many distributed
applications.
To this end, we consider an alternative interaction model between the service and the applica-
tions, called accrual failure detectors. Roughly, an accrual failure detector associates to each process
a real value representing a suspicion level, instead of the traditional binary information (i.e., trust
vs. suspect). In this paper, we provide a rigorous deﬁnition for accrual failure detectors, demon-
strate that changing the interaction model leads to no loss in computational power, discuss quality
of service issues, and present several possible implementations.
1
Introduction
Failure detection is an essential component for building reliable distributed systems. As such, it was
proposed many times that failure detection ought to be provided as a generic service, shared among
distributed applications (e.g., [13, 16, 29]). In spite of many ground-breaking advances made on failure
detection, such a service still remains at a distant horizon.
We contend that the current obstacles to provide failure detection as a generic system service—in
sharp contrast with the success of NTP for time synchronization—are due to the fact that several impor-
tant architectural and engineering issues have been overlooked until now. To be genuinely ubiquitous,
a failure detection service must be able to satisfy the requirements of a large variety of application
classes without introducing unnecessary limitations. To this end, the following two major issues must
be addressed properly. Firstly, at any time, the service must be able to provide various levels of quality
of service (QoS) in order to meet the requirements of independent applications that may run simul-
taneously. Secondly, the service must support all reasonably common usage patterns as smoothly as
possible.
Although the computational aspects of failure detectors are now well-established and several efﬁ-
cient implementations have been proposed, only few studies have been looking at the issues mentioned
above. This paper addresses these issues by deﬁning accrual failure detectors, a concept that allows for
∗Part of this research was conducted for the program “Fostering Talent in Emergent Research Fields” in Special Coor-
dination Funds for Promoting Science and Technology by the Japan Ministry of Education, Culture, Sports, Science and
Technology; the Japan Society for the Promotion of Science; a Grant-in-Aid for JSPS Fellows from the Japan Ministry of
Education, Culture, Sports, Science and Technology; and the Swiss National Science Foundation.
1
a cleaner decomposition of the behavior of the underlying system and the quality of service provided
to the applications. In recent work, we have proposed a possible implementation of an accrual failure
detector, called the ϕ failure detector [23].
This paper deﬁnes the generic notion of accrual failure detectors, and makes the link with the com-
putational aspects of failure detection. More speciﬁcally, this paper complements our earlier work by
(1) providing a precise deﬁnition for the concept of accrual failure detection, (2) establishing important
properties of such failure detectors, and (3) presenting the characteristics of several useful implementa-
tions.
1.1 Failure detectors
In their seminal paper, Chandra and Toueg [7] have established the theoretical foundation of failure de-
tection. Many important results stem from their work, such as minimal conditions, equivalences, trans-
formations, metrics (e.g., [6, 8, 9, 15, 24, 28, 25, 26]). These studies concentrate on the computational
power of failure detectors from an algorithmic perspective. Other studies have been aimed at imple-
menting such failure detectors over small-scale (e.g., [8, 3]) and large-scale networks (e.g., [29, 4]).
However, most failure detectors proposed in the literature are based on a binary interaction model,1
whereby a monitored process is either trusted or suspected.2
1.2 Limitations of the binary model
The binary model has some limitations when it comes to providing failure detection as a generic service.
First, a binary interaction model makes it difﬁcult to support several applications running simultane-
ously. To see this, one must realize that there is an inherent tradeoff between conservative (i.e., slow and
accurate) and aggressive (i.e., fast but inaccurate) failure detection. Different applications are likely to
have different requirements with respect to the QoS of the failure detection. Moreover, several levels of
QoS can be useful even within the same application. For instance, an application can take precautionary
measures against catastrophic failure when the conﬁdence in a suspicion reaches a given level, and then
take more drastic actions once the conﬁdence raises above a second (much higher) level.
Second, although binary failure detectors are well-adapted to meet the needs of many algorithms,
their interaction model cannot easily cope with some usage patterns that arise in practice. The simple
example below illustrates two such usage patterns.
1.3 Illustration: BoT computations
To further illustrate our point, we present a simple example taken from the execution of Bag-of-Tasks (BoT)
computations in the OurGrid platform [10] (kindly suggested to us by Francisco V. Brasileiro). This ex-
ample is particularly helpful as it shows two interesting usage patterns of failure detectors.
Consider a simpliﬁed environment with one master process and a collection of worker processes.
The master holds a list of independent tasks that need to be executed, dispatches these tasks to available
workers, and gathers results. For simplicity, assume that the master never fails but that some of the
workers may crash. Clearly, the master must be able to detect the crash of a worker and reassign the
tasks of the worker, or else the computation may never complete. Consider the following two situations,
where the master needs to use information about the possible failure of workers.
First, when assigning tasks to the workers, the master must avoid sending them to workers that
have crashed. Hence, the master needs to be able to sort workers according to how likely they are still
operational.3
1Some notable exceptions (e.g., [18, 28]) are discussed in Section 6.
2This includes the eventual leader oracle, that can be expressed in terms of trust and suspect [6].
3Of course, other parameters, such as the load on the workers, may be equally important when assigning tasks to workers.
2
Figure 1: Binary failure detectors: monitoring and
interpretation are combined.
Figure 2: Accrual failure detectors: monitoring
and interpretation are decoupled.
Second, when a task is being executed by a worker, the crash of this worker must be detected and
the task restarted. However, let us consider the cost of making a wrong decision: if a task is wrongly
aborted, all CPU cycles that were spent computing the task are wasted. Note that the cost of aborting
the task due to a wrong suspicion increases as time passes.
The two situations described above are difﬁcult to handle with binary failure detectors. While ad-hoc
solutions certainly exist, a more suitable abstraction can simplify the design and thus improve the quality
of the system. We know of one attempt at deﬁning such an abstraction, called slowness oracles [28],
that cope with the ﬁrst situation by ordering processes according to their perceived speed. However,
slowness oracles do not cope well with the second situation.
1.4 Accrual failure detectors
To cope with the situations described above, we advocate a more ﬂexible interaction model for failure
detectors, on top of which binary and other kinds of failure detectors can be constructed. More speciﬁ-
cally, we deﬁne a family of failure detectors, called accrual failure detectors, whereby each monitoring
process associates, to each of the monitored processes, a real number that changes over time. The value
represents a suspicion level, where zero means that the process is not suspected at all, and the larger the
value, the stronger the suspicion. Roughly speaking, accrual failure detectors ensure that the suspicion
level associated with a monitored process p (1) accrues toward inﬁnity if p is faulty, and (2) is bounded
if p is correct.
1.5 Architectural issues
Failure detection can be decomposed into three basic tasks. Monitoring allows the failure detector to
gather information about other hosts and their processes. This is usually done through the network, by
sampling heartbeat arrivals or query-response delays. Interpretation is necessary to make sense of the
information obtained through monitoring. With binary failure detectors, this is often done by setting
some timeout and generating suspicions. QoS parameters intervene at this stage. Actions are executed
as a response to triggered suspicions. This is most often done within the applications.
For a service, one of the major advantages of providing an accrual failure detector over a binary one
is that the former allows for a complete4 decoupling between monitoring and interpretation. Indeed,
binary failure detectors combine these two roles (see Fig. 1), and thus provide applications only with
information that is already interpreted. Applications are left with how to react to suspicions. Unfor-
tunately, suspicion tradeoffs largely depend on the nature of the triggered action, as well as its cost in
terms of performance or resource usage.
4Notice that a common misconception considers heartbeat intervals as a parameter for setting the QoS of failure detectors.
In practice, while heartbeat intervals indeed have an effect on the overall QoS, the parameter is actually imposed by the
underlying system (i.e., its behavior as well as its administration). Refer to [23] for a more detailed argumentation on this
issue.
3
MonitoringInterpretationActionActionActionFailureDetectorApplications,ProtocolssuspicionsFailureDetectorMonitoringInterpretationActionInterpretationActionParametricActionApplications,Protocolssuspicion levelsuspicionssuspicionsIn contrast, accrual failure detectors leave the task of interpreting the suspicion level to applications
(see Fig. 2). Thus, different applications can set different thresholds to suspect processes according to
their needs, or even directly use the suspicion level as a parameter to their actions. Note that this is
an architectural consideration: a library can still provide the interface of a binary failure detector to
applications that prefer that interaction model. However, there will be one interpretation module per
application, not one interpretation module shared among all applications within the failure detector.
1.6 Contribution & structure
The main contribution of this paper is to provide a rigorous deﬁnition for accrual failure detectors.
In particular, we focus on a class of accrual failure detectors that is computationally equivalent to an
unreliable failure detector of class ♦P (i.e., one that stops making mistakes after some time). We
identify important properties of accrual failure detectors in relation with the quality of service of failure
detectors. Finally, we discuss several possible implementations of accrual failure detectors and explain
how they are related.
The rest of the paper is structured as follows. Section 2 describes our system model, as well as some
basic deﬁnitions. Section 3 deﬁnes accrual failure detectors and their basic properties. Section 4 states
several important theorems related to particular classes of accrual failure detectors. Section 5 outlines
several possible implementations of accrual failure detectors. Section 6 discusses how accrual failure
detectors are related to previous work. Finally, Section 7 concludes the paper.
2 System model & deﬁnitions
System model. We consider a distributed system consisting of a set of processes Π = {p1, . . . , pn}.
We assume the existence of some global time, unbeknownst to processes, the domain of which,
denoted by T, is an inﬁnitely countable subset of real numbers with no upper bound. We assume that
processes always make progress, and that at least δ > 0 time units elapse between consecutive steps
(the purpose of the latter is to exclude the case where processes take an inﬁnite number of steps in ﬁnite
time).
Failures. The failure model considered in this paper is based on the model of Chandra and Toueg [7].
A process can be correct or faulty. A process is faulty if its behavior deviates from its speciﬁcation, and
a process is correct if it is not faulty. We say that a process fails when its behavior starts deviating from
its speciﬁcation. Faulty processes never recover.
A failure pattern is a function F : T 7→ 2Π, where F (t) is the set of processes that have failed before
or at time t. The function correct(F ) denotes the set of correct processes (processes that never belong
to failure pattern F ) while faulty(F ) = Π − correct(F ) denotes the set of faulty processes.