b,j) in response.
(Encode, (sid, A, b, j), x(cid:48)) to Fencode and receives (Output, (sid, A, b, j),(cid:74)x(cid:48)(cid:75)A
Alice sends
(cid:74)x(cid:48)(cid:75)A
b,j ⊕(cid:74)x(cid:48)(cid:75)B
b,p
for y ∈ Y ,
to Bob. Let E denote the nµ encodings that Alice sends.
(b) [Bob’s Common Mask] Similarly,
let b, p be the bin index and posi-
tion that y(cid:48) was placed in during Step 2b to represent y. For j ∈ [µ], Bob sends
b,j) in response.
(Encode, (sid, B, b, j), y(cid:48)) to Fencode and receives (Output, (sid, B, b, j),(cid:74)y(cid:48)(cid:75)B
Bob outputs(cid:110)
(cid:111)
b,j ∈ E, where (b, y(cid:48)) = phaseh,m(y)
(cid:12)(cid:12)(cid:12) ∃j ∈ [µ] :(cid:74)y(cid:48)(cid:75)A
b,p ⊕(cid:74)y(cid:48)(cid:75)B
y ∈ Y
Figure 4: Our malicious-secure Dual Execution PSI protocol.
in each bin. (It is for this reason that we still must perform exactly µ oblivious encoding steps per
bin.) However, it is safe to leak the fact that Alice has n items total. By aggregating encodings
across all bins we are able to use this common knowledge. Bob now sees a single collection of nµ
encodings, but does not know which bins they correspond to.
After making this change, Bob is comparing each of his nµ non-dummy encodings to each of
Alice’s nµ encodings. Without this optimization, he only compares encodings within each bin.
With more comparisons made among the common encodings, the probability of spurious collisions
increases. We must therefore increase the length of these encodings. A similar argument to the
previous section shows that if the encodings have length λ + 2 log(nµ), then the overall probability
of a spurious collision is 2−λ.
12
6.3 Dual Execution Protocol Details & Security
The formal details of our dual execution protocol are given in Figure 4. The protocol follows the
high-level outline developed in this section. We use the following notation:
b,p denotes an encoding of value x, in an instance of Fencode where Alice is sender, cor-
responding to position p in bin b. Each bin stores a maximum of µ items, so there are µ
positions.
• (cid:74)x(cid:75)A
• We write (b, x(cid:48)) = phaseh,m(x) to denote the phasing operation (Section 6.1), where to store
item x we place representative x(cid:48) in bin b.
Theorem 2. The protocol in Figure 4 is UC-secure in the Fencode-hybrid model. The resulting
protocol has cost O(Cn log n), where C ≈ κ is the cost of one Fencode call on a σ − log n length bit
string.
Proof. We start with the case of a corrupt Bob. The simulator must extract Bob’s input, and
simulate the messages in the protocol. We ﬁrst describe the simulator:
The simulator plays the role of the ideal Fencode functionality. The simulator does nothing
in Step 2 and Step 3a (steps where Bob receives no output). To extract Bob’s set, the
simulator observes all of Bob’s Fencode messages (Encode, (sid, A, b, p), y(cid:48)
b,p) in Step 3b. The
simulator computes Y = {phase−1
b,p) | b ∈ [m], p ∈ [µ]} and sends it to the ideal FPSI
functionality which responds with the intersection Z = X ∩ Y .
Set Z∗ to be equal to Z along with arbitrary dummy items not in Y , so that |Z∗| = n. For
each z ∈ Z∗, compute (b, z(cid:48)) = phasem,h(z) and insert z(cid:48) into a random unused position bin
BX [b]. For z ∈ Z∗ in random order, and j ∈ [µ], compute (b, z(cid:48)) = phasem,h(z) and send
(cid:74)z(cid:48)(cid:75)A
b,p ⊕(cid:74)z(cid:48)(cid:75)B
b,j to Bob, where these encodings are obtained by playing the role of Fencode.
h,m(b, y(cid:48)
To show that this is a valid simulation, we consider a series of hybrids.
Hybrid 0 The ﬁrst hybrid is the real interaction as speciﬁed in Figure 3 where Alice honestly uses
her input X, and Fencode is implemented honestly.
Observe Bob’s commands to Fencode of the form (Encode, (sid, A, b, p), y(cid:48)
on these, deﬁne the set ˜Y = {phase−1
b,p) | b ∈ [m], p ∈ [µ]}.
h,m(b, y(cid:48)
b,p) in Step 3b. Based
Hybrid 1 In this hybrid, we modify Alice to send dummy values to Fencode in Step 2a. Then
we further modify Alice to perform the hashing at the last possible moment in Step 4. The
simulation can obtain the appropriate encodings directly from the simulated Fencode. The hybrid
is indistinguishable by the properties of Fencode.
(cid:74)x(cid:48)(cid:75)A
b,j ⊕(cid:74)x(cid:48)(cid:75)B
struction of ˜Y , Bob never obtained an encoding of the form(cid:74)x(cid:48)(cid:75)A
Hybrid 2 In Step 4a, for each x ∈ X the simulated Alice sends common encodings of the form
b,p, for some position p, where (b, x(cid:48)) = phaseh,m(x). Suppose x (cid:54)∈ ˜Y . By con-
b,j. This encoding is therefore
distributed independent of everything else in the simulation. In particular, the common encod-
ings corresponding to this x are distributed independently of the choice of (b, x(cid:48)) and hence the
choice of x.
We therefore modify the hybrid in the following way. Before Alice adds the items of X to her
hash table in Step 4a, she replaces all items in X \ ˜Y (i.e., all items not in X ∩ ˜Y ) with ﬁxed
dummy values not in Y . By the above argument, the adversary’s view is identically distributed
in this modiﬁed hybrid.
13
The ﬁnal hybrid works as follows. A simulator interacts with the adversary and determines a set
˜Y , without using Alice’s actual input X. Then it computes X ∩ ˜Y and simulates Alice’s message
in Step 4a using only X ∩ ˜Y . Hence, this hybrid corresponds to our ﬁnal simulator, where we send
˜Y to the ideal FPSI functionality and receive X ∩ ˜Y in response.
We now turn our attention to a corrupt Alice. In this case the simulator must simply extract
Alice’s eﬀective input (Alice receives no output from FPSI). The simulator is deﬁned as follows:
The simulator plays the role of the ideal Fencode functionality. The simulator does noth-
In Step 3a, the simulator intercepts Alice’s commands of
ing in Step 2 and Step 3b.
the form (Encode, (sid, B, b, p), x(cid:48)
b,p). The simulator computes a set of candidates ˜X =
{phase−1
b,p) | b ∈ [m], p ∈ [µ]} and for x ∈ ˜X let c(x) denote the number of times that
phase−1
b,p) = x for b ∈ [m], p ∈ [µ].
The simulator computes a hash table B as follows. For x ∈ ˜X and i ∈ c(x), the simulator
computes (b, x(cid:48)) = phaseh,m(x) and places x(cid:48) in a random unused position in bin B[b].
Although | ˜X| may be as large as mµ, by construction no bin will have more than µ items.
For each such x, let p(x) denote the set of positions of x in its bin.
h,m(b, x(cid:48)
h,m(b, x(cid:48)
Let E denote the set of values sent by Alice in Step 4a. The simulator computes
X∗ =(cid:8)x ∈ ˜X | ∃j ∈ [µ], p ∈ p(x) :
(cid:74)x(cid:48)(cid:75)A
b,j ⊕(cid:74)x(cid:48)(cid:75)B
∧ (b, x(cid:48)) = phaseh,m(x)(cid:9)
b,p ∈ E
(1)
where the encodings are obtained by playing the role of Fencode. The simulator sends X∗ to
the FPSI functionality.
Hybrid 0 The ﬁrst hybrid is the real interaction as speciﬁed in Figure 3 where Bob honestly uses
his input X, and Fencode is implemented honestly.
Observe Alice’s commands to Fencode of the form (Encode, (sid, B, b, p), x(cid:48)
on these, deﬁne ˜X = {phase−1
b,p) | b ∈ [m], p ∈ [µ]}.
h,m(b, x(cid:48)
b,p) in Step 3a. Based
Hybrid 1 In this hybrid, we modify Bob to send the zero string to Fencode in Step 2b. The
simulation can obtain all required encodings directly from the simulated Fencode. We also have
Bob perform his hashing not in Step 2b but at the last possible moment in Step 4b. The hybrid
is indistinguishable by the properties of Fencode.
Hybrid 2 The hybrid computes the output as speciﬁed in Step 4b. We then modify it to immedi-
ately remove all from this output which is not in ˜X. The hybrids diﬀer only in the event that
simulated Bob computes an output in Step 4b that includes an item y (cid:54)∈ ˜X. This happens only
b,p ∈ E, where (b, y(cid:48)) = phaseh,m(y) and Bob places y(cid:48) in position p. Since y (cid:54)∈ ˜X,
b,p is distributed uniformly. The length of encodings is chosen so that
the overall probability of this event (across all choices of y (cid:54)∈ ˜X) is at most 2−λ. Hence the
modiﬁcation is indistinguishable.
if(cid:74)y(cid:48)(cid:75)A
however, the encoding(cid:74)y(cid:48)(cid:75)B
b,j ⊕(cid:74)y(cid:48)(cid:75)B
Hybrid 3 We modify the hybrid in the following way. When building the hash table in Step 4b,
the simulated Bob uses ˜X instead of his actual input Y . Each x ∈ ˜X is inserted c(x) times.
Then he computes the protocol output as speciﬁed in Step 4b; call it X∗. This is not what the
simulator gives as output — rather, it gives X∗ ∩ Y as output instead.
14
The hashing process is diﬀerent only in the fact that items of Y \ ˜X are excluded and replaced
in the hash table with items of ˜X \ Y (i.e., items in Y ∩ ˜X are treated exactly the same way).
Note that the deﬁnition of ˜X ensures that the hash table can hold all of these items without
overﬂowing. Also, this change is local to Step 4b, where the only thing that happens is Bob
computing his output. However, by the restriction added in Hybrid 2 , items in Y \ ˜X can never
be included in X∗. Similarly, by the step added in this hybrid, items in ˜X \ Y can never be
included in the simulator’s output. So this change has no eﬀect on the adversary’s view (which
includes this ﬁnal output).
The ﬁnal hybrid works as follows. A simulator interacts with the adversary and at some point
computes a set X∗, without the use of Y . Then the simulated Bob’s output is computed as
X∗ ∩ Y . Hence, this hybrid corresponds to our ﬁnal simulator, where we send X∗ to the ideal FPSI
functionality, which sends output X∗ ∩ Y to ideal Bob.
Set Size for Malicious Parties As the ideal PSI functionality in Figure 1 indicates, our protocol
realized a slightly relaxed variant of traditional PSI that does not strictly enforce the size of a corrupt
party’s input set. The functionality allows an honest party to provide an input set of size n, but a
corrupt party to provide a set of size n(cid:48) > n. We now analyze why this is the case and what is the
exact relationship between n and n(cid:48).
Let us ﬁrst consider the case of a malicious Bob who learns the intersection. The simulator
extracts a set based on the commands Bob gave when acting as Fencode receiver. Bob is given
mµ = O(n) opportunities to act as Fencode receiver, and therefore the simulator extracts a set of
size at most n(cid:48) = mµ = O(n). Concretely, when λ = 40, n = 220 and m = n/ log2 n, the optimal
bin size is µ = 68 and Bob’s maximum set size is n(cid:48) < 4n.
The situation for a malicious Alice is similar. As above, the simulator computes a set ˜X based
on commands Alice gives to Fencode when acting as receiver. The size of ˜X is therefore at most
mµ = O(n). The simulator ﬁnally extracts Alice’s input as X∗, a subset of ˜X. Hence her input has
size at most n(cid:48) = mµ.
However, the situation is likely slightly better than this strict upper bound. Looking closer,
Alice can only send a set E of nµ (not mµ) common encodings in the ﬁnal step of the protocol.
Each item x ∈ ˜X is associated with µc(x) common encodings, i.e. µ for each time she sends x in
a Fencode command as the receiver. So Alice is in the situation where if she wants more than n
items to be represented in the set E, then at least one item must have one of its possible encodings
excluded from E. This lowers the probability of that item being included in the ﬁnal extracted
input X∗.
(cid:80)
In general, suppose for each x ∈ ˜X, Alice includes ki(x) encodings in her set E that are
i∈[c(x)] ki(x) ≤ nµ.
Inspecting the simulation, we see that the probability a particular x ∈ ˜X survives to be included
associated with the ith time she acted as Fencode receiver with x. Hence(cid:80)
in X∗ is Pr[x ∈ ˜X ⇒ x ∈ X∗] = 1−(cid:81)∈[c(x)](1− ki(x))/µ or simply k1(x)/µ in the case c(x) = 1 (it
the expected size of X∗ is(cid:80)
happens only if the simulator happens to place x in a favorable position in the hash table). Hence,
x∈ ˜X
(cid:80)
i∈[c(x)] ki(x)/(µc(x)) ≤ n.
x∈ ˜X
6.4 Encode-Commit Protocol
We now turn our attention to the encode-commit style PSI protocol described in Section 5.3 and
outline how the optimizations of Section 6.1, 6.2 can be applied to it. Recall that the encode-commit
protocol instructs Bob to encode his items as Fencode receiver while Alice must send commitments
of her items. The ﬁnal step of this protocol is for Alice to send decommitments of her values
15
encrypted under the corresponding Fencode encodings.
Comm(y; r),{(cid:74)y(cid:48)(cid:75)A
It is straight forward to see that the hashing to bins technique of Section 6.1 is compatible
with the encode-commit style PSI. When the optimization of aggregating masks across bins from
Section 6.2 is applied, we observe that the situation becomes more complicated. Let us assume
that Alice now sends the commitment to her value y together with the decommitment r encrypted
b,p | p ∈ [µ]} where (b, y(cid:48)) = phaseh,m(y). That is, for a random order of
y ∈ Y , Alice sends
under the encodings {(cid:74)y(cid:48)(cid:75)A
b,p(x)⊕r)⊕(cid:74)x(cid:48)(cid:75)A
value ((cid:74)y(cid:48)(cid:75)A
Speciﬁcally, we will use the Fencode encodings to derive two values, (cid:74)v(cid:75)tag
and (cid:74)v(cid:75)enc
b,p = PRF((cid:74)v(cid:75)A
to Bob. For each x ∈ X, Bob must trial decommit to all such Comm(y; r) with the decommitment
b(x),p(x). This would result in Bob performing O(n2) trial decommitments,
eliminating any performance beneﬁts of hashing. This overhead can be reduced by requiring Alice
to send additional information that allows Bob to quickly identify which decommitment to try.
b,p, tag)
b,p,
both values can be derived, but without the encoding the two values appear pseudo-random and
independent. We now have Alice send
b,p, enc). The important property here is that given the encoding (cid:74)v(cid:75)A
Comm(y; r),{(cid:74)y(cid:48)(cid:75)tag
b,p = PRF((cid:74)v(cid:75)A
Bob can now construct a hash table mapping(cid:74)x(cid:48)(cid:75)tag
a match is found, Bob will add the associated x to the intersection if the associated(cid:74)x(cid:48)(cid:75)enc
b,p , x). Upon receiving a commitment
and the associated tagged decommitments, Bob can query each of Alice’s tags in the hash table. If
b,p value
b,p to ((cid:74)x(cid:48)(cid:75)enc
is successfully used to decommits Comm(y; r).
b,p ⊕ r | p ∈ [µ]}
b,p || ((cid:74)y(cid:48)(cid:75)enc
b,p ⊕ r) | p ∈ [µ]}
6.5 Encode-Commit Protocol Details & Security
In particular, we do not require equivocability.
We give a formal description of the protocol in Figure 9. The protocol requires a non-interactive
commitment scheme. In Section A we discuss the security properties required of the commitment
scheme. At a high level, we require an extractable commitment scheme with a standard (standalone)
hiding requirement.
In the non-programmable
random oracle, the standard scheme H(x(cid:107)r) satisﬁes our required properties.
Theorem 3. The protocol in Figure 9 is UC-secure in the Fencode-hybrid model, when the underlying
commitment scheme satisﬁes Deﬁnition 4. The resulting protocol has cost O(Cn log n), where C ≈ κ
is the cost of one (sender) Fencode call on a σ − log n length bit string.
Proof. Due to the similarity to the previous proof we defer giving hybrids and simply describe the
simulators. We start with the case of a corrupt Bob. The simulator must extract Bob’s input,
and simulate the messages in the protocol. The simulator is nearly the same as in the previous
protocol:
b,p) in Step 3. The simulator computes Y = {phase−1
The simulator plays the role of the ideal Fencode functionality. The simulator does noth-
ing in Step 2. To extract Bob’s set, the simulator observes all of Bob’s Fencode messages
b,p) | b ∈
(Encode, (sid, A, b, p), y(cid:48)
[m], p ∈ [µ]} and sends it to the ideal FPSI functionality which responds with the intersection
Z = X ∩ Y .
Set Z∗ to be equal to Z along with arbitrary dummy items not in Y , so that |Z∗| = n.
For each z ∈ Z∗, compute (b, z(cid:48)) = phasem,h(z) and insert z(cid:48) into bin BX [b] at a random
unused position p ∈ [µ]. For z ∈ Z∗ in random order, compute (b, z(cid:48)) = phasem,h(z) and
h,m(b, y(cid:48)
16
send Comm(z; rz),{(cid:74)z(cid:48)(cid:75)tag
playing the role of Fencode.
b,p ||(cid:74)z(cid:48)(cid:75)enc
b,p ⊕ rz} to Bob, where these encodings are obtained by
Importantly, the simulator extracts Bob’s input in step 3 and thus knows the protocol output before
step 4. It can therefore send appropriate commitments and use dummy commitments for those that
are guaranteed not to be openable by Bob (those commitments whose decommitment values are
perfectly masked by random encodings). Security follows from standard standalone hiding of the
commitment scheme.
receives no output from FPSI). The simulator is deﬁned as follows:
In the case of a corrupt Alice the simulator must simply extract Alice’s eﬀective input (Alice
The simulator plays the role of the ideal Fencode functionality and initializes the commit-
ment scheme in extraction mode (i.e., ﬁxes the coin tossing in step 1 to generate simulated