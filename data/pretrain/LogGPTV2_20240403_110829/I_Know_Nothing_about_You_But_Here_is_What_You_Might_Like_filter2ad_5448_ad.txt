F (N +1))−( N
≈ F , which is an upper-bound. At the same
( N +1
F N)
( N +1
F (N +1))
time, the old choices remain among the previous N users and
the contribution of each old choice decreases due to the fact
that v joins. The ratio of each contribution before v joins and
after v joins is upper-bounded by
1−F . The two
upper-bounds provide the exact inequality result we require:
( N
F N)
( N +1
F (N +1))
≤ 1
P r(Bu ∈ T ) ≤ 1
1 − F
· P r(Bu(v) ∈ T ) + F
independent of the distributions which Bu and Bu(v) may
follow respectively.
VI. EVALUATION
We now evaluate X-REC’s ability to preserve privacy while
providing fast recommendations with good quality on real-
world traces.
A. Experimental Setup
Experimental platform. Our server is an Apache Tomcat
server with an in-memory database. We use a Supermicro dual-
socket server with 2 Processors Intel(R) Xeon(R) 10-core CPU
E5-2680 v2 @ 2.80GHz to evaluate the server. This Xeon
platform has 20 hardware cores (with hyperthreading enabled)
to assess the scalability of X-REC. The user machine is an
Intel(R) Core(TM) i7-3632QM CPU @ 2.20GHz laptop.
Datasets. We use two sets of real-world traces: Movielens
(ML) [6] and FilmTrust (FT) [7] datasets. Table II provides the
details of these datasets. The datasets are replayed based on the
associated (sorted) timestamps. The training set contains the
ﬁrst 80% of the ratings while the test set contains the remaining
20%. The evaluation goal is to compare the predictions against
the test set. Additionally, we use a larger version of Movielens
(ML-Large) to empirically analyze the scalability of X-REC
in § VI-E. ML-Large is a popular benchmark dataset used
to evaluate the scalability of different recommenders like
CLUSTKNN [36]. These datasets have different characteristics
with respect to density (Table II). Density is the fraction of
provided ratings among all possible ratings (when each user
rated all items).
Dataset
ML
Density(%)
#Users
#Items
1682
3,706
2071
#Ratings
100,000
1,000,209
35,497
6.31
4.46
1.14
ML − Large
FilmTrust
943
6,040
1508
TABLE II: Dataset characteristics.
Evaluation metrics. We evaluate X-REC along three com-
plementary metrics:
the quality of the recommendation as
perceived by the user, the latency in X-REC to compute the
recommendations, which is also the latency as perceived by
the user as well as the speedup attained by X-REC on multiple
cores.
Quality. We evaluate the prediction quality using the Mean
(cid:3)n
Absolute Error (MAE) metric. Given that the predicted rating
for an item i is pi and the actual rating is ri, the MAE for a
test dataset, with N ratings, is computed as follows: M AE =
i=1 |pi − ri|/N .
Latency. This assessment metric evaluates the total time for
X-REC to provide recommendations to a user. We compute
the prediction updates for a user once per user log-in session
and denote this time as the prediction update time. We denote
the actual latency observed by the user as the end-user latency
446
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:11 UTC from IEEE Xplore.  Restrictions apply. 
Fraction (F)
Latency (LT)
LTA(h)
LTN
0.1
0.3
0.5
0.7
0.99
2
3.69
5.24
6.71
10.89
0.19
0.365
0.53
0
1
Movielens
Leakage (, δ)
A, δA
0.105, 0.1
0.357, 0.3
0.693, 0.5
1.204, 0.7
4.605, 0.99
N , δN
0, 0
0.056, 0.225
0.131, 0.449
0.244, 0.674
1,1
Error (MAE)
M AEA M AEN
U
Latency (LT)
LTA(h)
LTN
0.859
0.846
0.841
0.834
0.823
0.639
0.5
0.306
1
0
0.333
0.320
0.382
0.429
0.666
2.54
4.67
7.18
10.54
15.22
0.168
0.365
0.631
0
1
FilmTrust
Leakage (, δ)
A, δA
0.105, 0.1
0.357, 0.3
0.693, 0.5
1.204, 0.7
4.605,0.99
N , δN
0, 0
0.056, 0.225
0.131, 0.449
0.244, 0.674
1, 1
Error (MAE)
1
M AEA M AEN
0.7395
0.733
0.731
0.726
0.721
0.649
0.54
0.27
0
U
0.333
0.316
0.396
0.450
0.666
TABLE III: Fraction determination using utility function (U).
which involves the post-processing on the x-client. Mostly, X-
REC requires a few milliseconds for recommending the items
not yet seen by the user leveraging sorted predictions stored
locally on the x-client [19]. For the following experiments, we
only measure the prediction update time (requires participation
of the x-server) and end-user latency.
Speedup. We measure the speedup in terms of the time required
for a sequential execution (T1) and the time required for a
parallel execution with p processors (Tp). The speedup (Sp) is
measured based on Amdahl’s law as: Sp = T1/Tp
System parameters. We set the item sampling parameter L to
10 and the user sampling parameter F to 0.3. Whenever a user
rates an item, the x-client updates 10 items on the x-server,
the current item and 9 randomly selected items (rated or non-
rated), to add noise to the proﬁle as mentioned in § V-A. The
x-server randomly samples 30% of all users to compute the
predictions for an active user. The value of the user fraction
for sampling is determined by a utility function (U) as there is
a tradeoff between prediction update time (LT ), leakage (, δ)
and error (M AE). Better utility (U) is achieved with lower
latency, less leakage and less error.
(w1 · LTN + w21 · N + w22 · δN + w4 · M AEN )
FU = argmin
w∈(0,1)
For any arbitrary parameter a, the min-max normalized value
of a is denoted by aN . Table III shows the values at F = 0.1,
0.3, 0.5, 0.7 and 0.99. Among these values, we get FU as
0.3 for both datasets when all the three factors have equal
weightage (w1= 0.333, w21= 0.166, w22= 0.166 and w3=
0.333).
Finally, the threshold (T ) for determining similar users
is selected as 0.06 for Movielens and 0.05 for FilmTrust.
These values are selected based on lowest MAE at a given
threshold. 16 Figure 3 demonstrates that the MAE in the CF
approach is inversely proportional to the similarity threshold
until the 0.06 mark for Movielens (0.05 for FilmTrust), when
it starts to increase as we move to higher threshold values. 17
This behaviour is due to the fact that as the threshold increases
beyond some value, the number of good neighbors, contribut-
ing to the predictions, decreases leading to higher MAE.
Movielens
FilmTrust
 0.85
 0.84
 0.83
 0.82
 0.81
E
A
M
 0.75
 0.74
 0.73
 0.72
 0.71
E
A
M
-0.2 -0.1
 0
 0.1  0.2
-0.2 -0.1
 0
 0.1  0.2
Adjusted cosine
Fig. 3: Threshold determination.
Adjusted cosine
16F is set to 0.99 to ignore user sampling while determining the optimal
threshold value for selecting good neighbors.
17The parameters are determined using 5% of the training set as a
validation set.
E
A
M
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
359
q
In our evaluation, we set the X-HE parameter q to 2199 and
w to 2179. Our integers belong to Z q
w and ciphertexts belong
. In the encryption, we use errors uniformly distributed
to Z
between 0 and 2140−1. As we show in § VI-F, these parameters
give a reasonable level of hardness to the LWE problem and
offer a reasonable level of security to X-HE.
B. Recommendation Quality
The goal here is to assess the impact of guaranteeing
privacy on the quality of the recommendations. We compare
X-REC against the following systems (which do not provide
any privacy guarantee): USER-BASED-KNN [1] (k = 30) with
Pearson correlation, ITEM-BASED-KNN [20] (k = 30) with
Pearson correlation, FUNKSVD [21], KOREN-MF [22], and
SLOPEONE [23].
Figure 4 displays the MAE of the various alternatives on
the Movielens and FilmTrust datasets. The results show that
despite a slight average drop of 7% in the MAE, X-REC
sustains a good recommendation quality of the non-private
approaches.
ITEM-BASED-KNN
KOREN-MF
SLOPEONE
USER-BASED-KNN
FUNKSVD
X-REC
(a) Movielens
(b) FilmTrust
Fig. 4: MAE comparison with real-world recommenders.
C. Ofﬂine Computation
X-REC performs a periodic ofﬂine processing, similar to
systems like Netﬂix [28]. During this ofﬂine processing, the
x-server performs the periodic computation (after every 1,000
new ratings) needed for each user, to identify the similar users,
among the sampled users, using our neighbor selection pro-
tocol (X-NN) over encrypted data. The ofﬂine computations
in X-REC are highly scalable as depicted in Figure 5. More
precisely, Figure 5 demonstrates that speedup for ofﬂine pro-
cessing, corresponding to Movielens and FilmTrust datasets,
scales up to 7.5× on 20 hardware cores (with hyperthreading
enabled). Additionally, X-REC performs the prediction updates
ofﬂine and provides the new predictions in the next
log-
in session for the corresponding user as mentioned in § V.
Figure 6 analyses this prediction update time for both the
Movielens and FilmTrust datasets on a multi-core machine.
Note that X-REC provides a prediction update once per
user logged-in session and the end-user latency is only around
4 seconds for both the datasets where during every prediction,
the x-server computes new predictions for 500 random items
(not updated in the last prediction).
447
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:11 UTC from IEEE Xplore.  Restrictions apply. 
Movielens
FilmTrust
p