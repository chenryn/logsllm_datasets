title:In-network caching assisted wireless AP storage management: challenges
and algorithms
author:Zhongxing Ming and
Mingwei Xu and
Dan Wang
In-network Caching Assisted Wireless AP Storage
Management: Challenges and Algorithms
Zhongxing Ming
Tsinghua University
Mingwei Xu
Tsinghua University
The Hong Kong Polytechnic
Dan Wang
University
4-104 FIT Building, Haidian,
4-104 FIT Building, Haidian,
Beijing, 100084
PI:EMAIL
Beijing, 100084
PI:EMAIL
Hung Hom, KL, Hong Kong
PI:EMAIL
Categories and Subject Descriptors
C.2.1 [Computer-Communication Networks]: Network
Architecture and Design—Wireless communication
General Terms
Algorithms, Design
Keywords
Wireless caching, algorithm, information-centric networking
1.
INTRODUCTION
Wireless mobile data traﬃc is expected to increase by a
factor of 40 over the next ﬁve years [2]. Due to the scarcity
of resources, wireless data network has started to pose un-
acceptable delays to end users. The delays experienced by
end users have important economic consequences. Zona Re-
search reported that the potential losses in 2001 due to un-
acceptably slow response times are estimated to be over $25
billion [2].
Caching of objects near clients is a commonly used ap-
proach to overcome such challenges. Many studies suggest
caching at mobile devices. Such approaches often have high
diﬃculty in motivating the participants’ incentives to share
their batteries and limited bandwidth. Another approach is
caching at wireless access points (APs), which relieves the
limitations of handsets. However, AP caching often faces
the challenge of limited storage capacity.
Recently we see the emergence of Information-Centric Net-
working (ICN). One of the major features of ICN is the uni-
versal in-network caching, which enables routers to cache
contents along the path. A recent trace-driven analysis
found that beyond the beneﬁts of traditional edge caching,
a further 21% of requests can be served within only a sin-
gle AS hop by enabling in-network caching [5]. In-network
caching has attracted much research attention (e.g., DONA
[3]), and vendors (e.g., Huawei) are developing routers with
caching capability.
Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage, and that copies
bear this notice and the full citation on the ﬁrst page. Copyrights for third-
party components of this work must be honored. For all other uses, contact
the owner/author(s). Copyright is held by the author/owner(s).
SIGCOMM’13, August 12–16, 2013, Hong Kong, China.
ACM 978-1-4503-2056-6/13/08.
The goal of this paper is to improve wireless AP caching
by leveraging in-network caching. We observe that by treat-
ing routers as an in-network storage extension, we can re-
lieve the storage limitation of APs. The unique challenge
is that APs and routers cannot have a full collaboration,
which makes the problem diﬀerent from traditional coop-
erative caching problems. This is because, ﬁrst, the scale
of the Internet is too large for APs and routers to glob-
ally collaborate. Second, there are potential marketing, pol-
icy, security and privacy concerns that prevent in-network
caches from making decisions on behalf of edge APs. How-
ever, in spite of lacking full collaboration, APs can indeed
get some caching information from in-network caches. Many
ICN proposals support the dissemination of caching status.
For example, [1] provides an Event Notiﬁcation Service that
notiﬁes all Subscribers of the stored contents. As a result,
we study how APs can optimize caching decisions by using
in-network caching information without controlling routers.
We prove that the problem is NP-complete. We show that
in the ideal situation that global in-network caching infor-
mation is known, we can develop a 2-competitive polynomial
oﬄine algorithm. We also show that no online algorithm can
achieve a constant competitive ratio against the oﬄine algo-
rithm. We ﬁnally develop an in-network cache assisted AP
caching algorithm (ICA) for the practical situation that part
of in-network caching information is known. ICA adaptively
leverage diﬀerent levels of these information.
2.
IN-NETWORK CACHE ASSISTED WIRE-
LESS AP CACHING FRAMEWORK
Figure 1 provides an overview of the framework. Upon
receiving a request for information object, an AP responds
to the mobile node if it ﬁnds the object in a local cache,
otherwise it sends the request to the network. APs leverage
routers’ caching information to make caching decision but
do not control routers. The equation for maximizing delay
reduction can be represented as:
BF =
M(cid:2)
N(cid:2)
i=1
j=1
xij BVj (ci) =
M(cid:2)
N(cid:2)
i=1
j=1
xij × dj (ci) × pj (ci)
(1)
where ci denotes content i, si denotes i’s size, Bj denotes
APj’s storage capacity, dj(ci) denote the delay incurred when
transferring ci to APj, pj(ci) denote the popularity of ci at
APj. The 0-1 decision variable xij indicates whether ci is
stored in APj. Given the existence of in-network caches, we
study how to specify xij to maximize Eq.(1) subject to AP
storage capacity Bj.
521)
s
m
(
y
a
e
D
l
120
100
80
60
40
20
0
Single mobile cache
Coordinate mobile cache
ICA
80
60
40
20
No cache
AP cache only
ICA
)
s
m
(
y
a
e
D
l
2000
4000
6000
# of contents
8000
0
0
20
40
60
80
100
Simulation time (min)
(a) ICA vs.
Caching
Handset
(b) ICA vs. AP Caching
Figure 2: Preliminary Results
4. EVALUATION
We have conducted a trace-based evaluation, where sim-
ulations were conducted in an event-driven C simulator.
The trace was captured from a commercial website dur-
ing a six-month-period from 2011 to 2012, which totaled
824,741 URL-requests sent by 420,324 users. We treated
each URL as an information object. The simulation was run
on the topology of CERNET2, which is the world’s largest
IPv6 network. We set each router connected by 1,000 APs.
According to the trace, each AP received content requests
with the intensity of 0.1 req/s under Poisson distribution.
We compared ICA to pure AP caching and handset caching
by running the simulation for 100 minutes, which was long
enough to get a stable result. Qian et al.
[4] performed a
comprehensive network-wide study on handset caching and
found that the Least Recently Used (LRU) algorithm was
the most widely used replacement policy for commercial
smartphones. As a result we set handsets use LRU. We
also used LRU for traditional AP caching. We measured
the system performance using average system delay which
was calculated by Eq.(2).
We see that ICA signiﬁcantly outperformed handset caching.
When content number=6,000, ICA reduced the delay of sin-
gle and cooperative handset caching by 60% and 33%, re-
spectively. We also see that ICA achieves more delay reduc-
tion that pure AP caching. Throughout the simulation, ICA
improved the delay reduction of pure AP caching by 58% on
average.
(cid:2)N
(cid:2)M
j=1
i=1 delay f or objecti at APj
M N
(2)
5. REFERENCES
[1] A. Eriksson, B. Ohlman, and K. A. Persson. What are
the services of an information-centric network, and who
provides them? In IEEE AP2PS, 2012.
[2] N. Golrezaei, G. A. Dimakis, and M. F. A. Wireless
device-to-device communications with distributed
caching. In ISIT, 2012.
[3] T. Koponen, B. Chawla, A. Emolinskiy, H. Kim,
S. Shenker, and I. Stoica. A data-oriented (and beyond)
network architecture. In ACM SIGCOMM, 2007.
[4] F. Qian, K. S. Quah, J. Huang, J. Erman, A. Gerber,
Z. M. Mao, S. Sen, and O. Spatscheck. Web caching on
smartphones: Ideal vs. reality. In ACM MobiSys, 2012.
[5] G. Tyson, S. Kaune, S. Miles, Y. El-khatib, A. Mauthe,
and A. Taweel. Trace-driven analysis of caching in
content-centric networks. In IEEE ICCCN, 2012.
Figure 1: The network model with simpliﬁed 3G archi-
tecture
3. PRELIMINARY FINDINGS
We ﬁrst analyze the diﬃculty of the problem.
Theorem 1 : The problem of ﬁnding the optimal conﬁg-
uration of Eq.(1) is NP-complete.
The intuition of the theorem’s proof is that we can reduce
N independent 0-1 knapsack problems to the problem de-
ﬁned by Eq.(1). We then report our preliminary ﬁndings by
three perspectives.
1) Oﬄine strategy : This is the ideal case that APs have
perfect knowledge of in-network caches. We propose the
following 2-competitive oﬄine algorithm for this case. We
use the oﬄine strategy as a performance bound for further
analysis.
Algorithm 1 Oﬄine Greedy
Each time when an object ci which is not currently cached
arrives, calculate its unit beneﬁt value, which is deﬁned
as dj(ci)pj(ci)/s(ci). If ci has a higher unit beneﬁt value
than the object with the minimum unit beneﬁt value that
is current stored, then replace the object with ci.
2) Online strategy : This is the worst case that APs do
not have any in-network caching information. We show that
although it is diﬃcult to get an optimal solution, APs may
make bad decisions if they are unaware of in-network caching
information. The intuition is that online algorithms may
perform poorly when APs always select contents which are
cached by nearby routers.
Theorem 2 : No online algorithm can achieve a constant
competitive ratio as opposed to the oﬄine algorithm in term
of total delay reduction.
3) In-network caching assisted strategy (ICA): We
then study the practical case that APs can get part of in-
network caching information. We propose a simple yet eﬃ-
cient ICA algorithm which works as follows. Deﬁne BVj(ci) =
dj(ci)pj(ci)/s(ci) if APj has cj’s in-network caching knowl-
edge, and BVj(ci) =∞ otherwise. When content ci arrives
at APj, APj performs LRU algorithm if the ci has already
been cached. If ci is not cached, APj checks if ci’s in-network
caching information is known. If yes, APj ﬁrst places ci to
the head of the LRU queue and then evicts the item (includ-
ing ci) with the minimum BV . If not, APj sets ci the head
of the queue and performs either of the following operation
1) evict the the tail of the queue if BVj(ctail of queue) =∞
or 2) evict the object with the minimum beneﬁt value if
BVj(ctail of queue) (cid:3)= ∞.
522