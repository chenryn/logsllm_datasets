·Imply组合套件（ImplyAnalyticsPlatform）：imply.io/download，该套件包含了稳定
。官网安装包：druid.io/downloads.html，包含Druid部署运行的最基本组件。
安装准备
持组件等，目的是为了更加方便、快速地部署搭建基于Druid的数据分析应用产品。
版本的Druid组件、实时数据写入支持服务、图形化展示查询WebUI和SQL查询支
储），或者是加人支持特定查询部分的优化补丁等。
考虑，比如结合实际生产环境中的周边依赖（如依赖特定的Hadoop版本做持久化存
---
## Page 83
4.1.2
第4章
·Java7或者更高版本（推荐使用Java8）。
以 Imply组合套件安装包为例，安装基本条件如下。
·quickstart-
本章以安装包imply-1.3.1.tar.gz为例，解压缩后的安装包目录如下。
·4GB以上内存。
·Linux或者类 UNIX操作系统，不支持Windows系统。
·NodeJS4.x以上版本（PlyQL、Pivot依赖）。
·dist—
.conf-quickstart-
·conf-
.bin-
安装环境
应用平台。
推荐采用这种方式来安装部署Druid，利用组合套件可以方便、快捷地构建数据分析
安装与配置
说明：安装包dist中的Druid不包含实时节点。在老版本的Druid中，实时节点
（比如利用HDFS作为Druid的数据文件持久化存储层）。
一方面可用于Druid的运行和维护；另一方面又可作为数据存储的使用账户
备注：建议生产环境部署Druid服务时单独申请一个特定的系统账号。该账号
关于实时节点的内容本章不再阐述。
采用push的方式写入数据）替代实时节点在实时数据摄人方面的工作，因此
存在单点故障等问题，故官方推荐改用索引服务（即统治节点+中间管理者
采用pull的方式实时地从消息队列如Kafka中拉取数据写人Druid，但是由于
—包含相关软件包（druid、pivot、tranquility-server和 zookeeper）。
一包含运行相关组件的脚本程序。
一包含生产环境集群配置文件。
一包含单机测试版快速上手相关文件。
一包含单机测试版配置文件。
59
---
## Page 84
4.1.3
9
（如生产等）
大规模集群
（如PoC等）
小规模集群
Druid服务外部依赖模块示意图如图4-1所示。
·MetadataStorage（元数据库）：负责存储和管理整个系统的配置记录信息，比如Druid
·Deep Storage（数据文件存储库）：负责存储和加载Druid的数据文件（Segment），
以上是运行Druid服务的基本条件，在生产环境中搭建Druid集群的推荐硬件配置如下。
服务来完成。
管理并同步各个节点的状态信息，
ZooKeeper（集群状态管理服务）：由于Druid采用多节点、多角色的分布式设计，因此
PostgreSQL。
中各个数据源、
HDFS、S3，当然Druid 也支持其他存储组件如 Cassandra等。
在生产环境中由 Deep Storage 层保障 Druid 数据文件的安全性和可用性。推荐使用
Druid 外部依赖
应用场景
中间管理者
统治节点
实时节点
历史节点
查询节点
协调节点
所有Druid节点
、数据文件信息，数据的加载与失效规则等。推荐使用MySQL或者
32核，2.50GHz
4核，2.50GHz
16～32核，2.50GHz
16~32核，2.50GHz
16～32核，2.50GHz
4核，2.50GHz
16核，2.50GHz
CPU
以及新增节点时的服务发现功能则交给ZooKeeper
64~244GB
15.0GB
32
2
32~244GB
15.0GB
32GB
内存
2~244GB
~244GB
Druid实时大数据分析原理与实践
20GB
20GB
100GB
200GB
20GB
20GB
500GB
硬盘
推荐使用
推荐使用
推荐使用
推荐使用
SSD
---
## Page 85
tar-xzf imply-1.3.1.tar.gz
curl -0 https://static.imply.io/release/imply-1.3.1.tar.gz
4.2.1服务运行
下几点。
4.2
第4章安装与配置
（1）服务安装与启动
·Zookeeper-> Imply安装包自带的 zk服务
本节以imply-1.3.1.tar.gz（Druid版本为0.9.1.1）为例，外部依赖采用默认配置。
本节将以一个简单的例子作为Druid的入门简介，并希望通过该示例可以了解到以
.Metadata Storage -> Derby
·DeepStorage->本地存储
·Druid实时数据的摄人方式
·Druid离线数据的摄人方式
·Druid数据查询方式
简单示例
Data
图4-1Druid服务外部依赖模块示意图
external dependencies
 drid components
Client
9
---
## Page 86
bin/post-index-task --file quickstart/wikiticker-index.json
们尝试将这些待分析的日志数据导人到Druid中，代码如下。
4.2.2
sv）。查询quickstart.log 日
bin/service--restart${服务名称}
bin/service--down
nohup bin/supervise-c conf/supervise/quickstart.conf> quickstart.log&
cd imply-1.3.1
9
tranquility-server
pivot
middleManager
overlord
historical
broker
coordinator
zookeeper
服务
离线导人与查询
本示例中定义的数据源名称为wikiticker（数据源类似于数据库中表的概念）。首先，我
·quickstart/wikiticker-index.json文件为离线写人任务的描述文件，其用JSON格式组织
·quickstart/wikiticker-2016-06-27-sampled.json文件包含了维基百科网站一段时间内收
（2）服务停止与重启
数据说明如下。
和定义了写人任务的数据源、时间信息、维度信息、指标信息等。
集到的日志数据（每条记录以一行JSON字符串组织）。
数据导人与查询
实时写人服务，HTTP协议
数据查询WebUI
中间管理者，负责写数据处理
统治节点，
历史节点，
查询节点，
协调节点，管理集群状态
分布式协调服务
简介
日志文件可知运行bin/supervise命令分别启动了以下服务。
管理数据写人任务
管理历史数据
处理查询请求
http://localhost:8090/console.html
http://localhost:8200/v1/post/datasource
http://localhost:9095
http://localhost:8083/druid/v2
http://localhost:8082/druid/v2
http://localhost:8081
访问地址
Druid实时大数据分析原理与实践
---
## Page 87
Curl -L-H'Content-Type: application/json'-xPOST --data-binary @quickstart/wikiticker-
ticker的TopN查询语句Schema定义信息。HTTP查询命令如下。
Task index_hadoop_wikiticker_2016-07-02T13:04:17.042Z still running..
Tasklog:
Task started:index_hadoop_wikiticker_2016-07-02T13:04:17.042Z
第4章安装与配置
Task finished with status: SUCCESS
Task
Task
Task
Task index_hadoop_wikiticker_2016-07-02T13:04:17.042Zstill running..
Task status:http://localhost:8090/druid/indexer/v1/task/index_hadoop_wikiticker_2016
-07-02T13:04:17.042Z/status
top-pages.json http://localhost:8082/druid/v2/?pretty
通过HTTPPOST请求查询，quickstart/wikiticker-top-pages.json文件包含了数据源wiki-
通过 Pivot 页面查询，浏览器访问地址http:/localhost:9095，如图4-2所示。
index_hadoop_wikiticker_2016-07-02T13:04:17.042Z still running..
-07-02T13:04:17.042Z/l0g
成功写人数据后查询方式如下。
index_hadoop_wikiticker_2016-07-02T13:04:17.0427still running..
index_hadoop_wikiticker_2016-07-02T13:04:17.0427 still running..
运行结果如下。
Bucket
http://localhost:8090/druid/indexer/v1/task/index_hadoop_wikiticker_2016
k26J27.3
24.4k
图4-2
11.5m
Pivot查询示例
11.8m
AMESPACE
AGE
---
## Page 88
HTTP协议访问接口供其他应用程序将一条或者一小批数据通过HTTPPOST方式实时导
bin/plyql --host localhost:8082 -v -q "SELECT page, SUM(count) AS Edits FROM wikiticker
9
人Druid中。
Wikipedia:Administrator intervention against vandalism
2016WimbledonChampionships-Men'sSingles
Wikipedia:Administrators'noticeboard/Incidents
User:Cyde/List of candidates for speedy deletion/Subpage
Copa America Centenario
page
"result":[
"timestamp"
本示例中实时数据的导人需要借助 tranquility-server 服务，
实时导人与查询
PlyQL 查询结果如下。
page ORDER BY Edits DESC LIMIT 5"
WHERE'2016-06-27T00:00:00′ data.log &
middleManager bin/run-druid middleManager conf
historical bin/run-druid historical conf
:verify bin/verify-java
viconf/supervise/data,conf
nohup bin/supervise -C conf/supervise/master-with-query.conf > master-with-query.log &
!p80overlord bin/run-druid overlord conf
coordinator bin/run-druid coordinator conf
pivot bin/run-pivot conf
historical bin/run-druid historical conf
broker bin/run-druid broker conf
:verify bin/verify-node