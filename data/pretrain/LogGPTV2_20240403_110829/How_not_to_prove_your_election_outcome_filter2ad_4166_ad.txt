The Bayer-Groth proof uses a generalisation of Pedersen
commitments with multiple generators H,G1,G2, . . .Gn. They
describe the scheme as “computationally binding under the
discrete logarithm assumption,” (p.5). This phrasing is slightly
confusing to the naive reader—it would be clearer to say
that the scheme is a trapdoor commitment scheme. Trapdoor
commitment schemes have various uses in cryptography (see
[15] for an excellent survey), because they are binding only
on the assumption that certain secrets (the “trapdoors”) are not
know to the committer.
The crucial point for the shufﬂe proof is to guarantee that no
one can learn the discrete logarithm of any generator H or Gi
to base G j (or of any non-trivial product of other generators). If
someone knows the discrete log of Giw.r.tG j, they can create
a commitment that they can open in multiple ways.
The system should prove, and the veriﬁers should check,
that the generators are selected properly, i.e., with no way for
anyone to learn a trapdoor except by computing discrete logs.
In the Scytl-Swisspost code, the commitment parameters are
just randomly generated without a proof of how they arose.
Indeed, each mixer generates its own commitment parameters
as shown in Figure 2.
came
from.
elements without
random group
they
The implementation of getVectorRandomElement
proving
gathers
Even more worryingly,
where
getVectorRandomElement calls getRandomElement,
which proceeds as shown in Figure 3—it simply generates
a random exponent and raises g to that value. This
randomExponent is precisely the trapdoor that is needed
to break the binding property of the commitment scheme.
As a result, the binding property completely relies on the
expectation that randomExponent is properly erased from
the memory. These commitment parameters are eventually
used to build the shufﬂe proof.
In summary: the implementation does not provide a proof,
and the veriﬁer cannot check, that the important assumption
of discrete log hardness made by Bayer and Groth is valid
here. It is possible for a malicious authority to generate the
perfectly random G1,G2, . . . in a way that gives it a trapdoor
that falsiﬁes an assumption that is central to the security of the
Bayer-Groth mixnet construction.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:54 UTC from IEEE Xplore.  Restrictions apply. 
651
public CommitmentParams(final ZpSubgroup group, final int n) {
this.group = group;
this.h = GroupTools.getRandomElement(group);
this.commitmentlength = n;
this.g = GroupTools.getVectorRandomElement(group, this.commitmentlength);
}
Fig. 2. Code for generating commitment parameters.
Exponent randomExponent = ExponentTools.getRandomExponent(group.getQ());
return group.getGenerator().exponentiate(randomExponent);
Fig. 3. Code for generating a random group element. Note that the exponent is explicitly used in its computation, so the discrete log of the output is known.
We will show how this can be used to produce a proof of a
shufﬂe that passes veriﬁcation but actually manipulates votes.
1) Details about the commitment scheme: The commitment
scheme works over a group G of prime order q. The authority
is supposed to choose n + 1 commitment parameters ck =
H,G1,G2, . . . ,Gn at random from G. To commit to n values
a1,a2, . . . ,an, it chooses a random exponent r and computes
comck((cid:2)a;r) = HrΠn
i=1Gai
i
.
Commitment opening consists simply of reporting (cid:2)a and r.
The binding property of the commitment scheme depends on
the hardness of computing discrete logs in the group. It’s quite
obvious that this assumption is necessary. For example, suppose
that a cheating authority generates commitment parameters
ck = H,He1,He2 . . . ,Hen for some H. That is, Gi = Hei for i =
1..n. Then it can open commitments arbitrarily. A commitment
comck((cid:2)a;r) can be opened as comck((cid:2)b;r
ei(ai − bi)
(cid:4)) by setting
(cid:4) = r +
(1)
r
n∑
i=1
because comck((cid:2)a;r) = HrΠn
i=1Gai
i
= HrΠn
i=1Haiei
(ai−bi)eiΠn
= Hr+∑n
(cid:4)Πn
i=1Gbi
= Hr
i
(cid:4)).
= comck((cid:2)b;r
i=1
i=1Hbiei
Details of how to leverage this into a complete false shufﬂe
proof are contained in Appendix A.
C. Discussion
Ease of exploiting the problem: The ﬁrst attack requires
knowing the randomness used to generate the vote ciphertexts
that will be manipulated. There are several ways this could
be achieved. For example, an attacker could compromise the
clients used for voting. Weak randomness generation (such
as that which affected the Norwegian e-voting system) would
allow the attack to be performed without explicit collusion.
The second attack does not require any extra information at
all, though it does rely on the election parameters having been
set up in a particular way. An easily-computed example set of
trapdoored parameters is in Appendix B.
How can there be a trapdoor when the system has been
formally proven secure?: Any formal proof of correctness for
any system makes some assumptions that become axioms in
the formal proof. Scytl’s proof of security [10] simply models
the mixnet as sound, based on an informal interpretation of
Bayer and Groth’s security proof. It does not model the proper
generation of commitment parameters. We do not see any
reason to believe there is an error in Scytl’s proof, but when
the axioms are mistaken the conclusions are not valid.
Source of the problem: Nothing in our analysis suggests
that this problem was introduced deliberately. It is entirely
consistent with a naive implementation of a complex cryp-
tographic protocol by well-intentioned people who lacked
a full understanding of its security assumptions and other
important details. Of course, if someone did want to introduce
an opportunity for manipulation, the best method would be one
that could be explained away as an accident if it was found.
We simply do not see any evidence either way.
Summary of the problem: This mixnet has a trapdoor—a
malicious administrator or software provider for the mix could
manipulate votes but produce a proof transcript that passes
veriﬁcation. Thus complete veriﬁability fails.
Fixing the problem: The issue needs to be corrected
by ensuring that the commitment parameters are generated
in a way that prevents any entity from knowing the discrete
logs—concrete suggestions are contained in Section VIII. Every
veriﬁer then needs to check the generation of the commitment
parameters as well as the rest of the proof transcript.
Current status of
the problem: We understand that
SwissPost and Scytl have corrected the issue by generating
the commitment parameters according to NIST FIPS 186-4,
Appendix 2.3. Although we have not seen the implementation,
we consider this approach to be appropriate for generating the
commitment parameters. However, generating the commitment
parameters properly might not completely resolve the problem.
The FIPS standard should also be used to generate the group
parameters p,q and g. This issue and the correction require
further public scrutiny.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:54 UTC from IEEE Xplore.  Restrictions apply. 
652
VII. UNIVERSAL VERIFIABILITY FAILURES FROM THE
WEAK FIAT-SHAMIR TRANSFORM
In this section, we show that the error in the implementation
of the Fiat-Shamir heuristic (already described in Section III)
allows a cheating authority to produce a proof of proper
decryption, which passes veriﬁcation, but declares something
other than the true plaintext.
The proof of proper decryption of a ciphertext (C0,C1) does
not hash C0. This allows a cheating prover to compute a valid
proof, then choose a statement as a function of that proof,
which breaks the soundness of the proof.
Just like the previous section, this voids the arguments
that the sVote audit offers complete veriﬁability: since the
veriﬁcation procedure is based on an assumption that we show
to be false, no conclusion can be made from its successful
completion.
In order to demonstrate one possible impact of the lack of
soundness of this decryption proof, we exhibit an exploit in
which a malicious authority (e.g., the CCM1 of the system)
modiﬁes selected votes during the (partial) decryption proce-
dure and forges decryption proofs that are indistinguishable
from valid ones, and would therefore pass veriﬁcation. This
speciﬁc exploit has two limitations, but we do not rule out that
there are other and possibly more dangerous ways of exploiting
the same weakness.
1) In order to fake the decryption proof and also complete a
valid proof of shufﬂe, the cheating CCM needs to know
the randomness used to encrypt the votes that it wants to
modify. This can be accomplished by corrupting a voting
client, or by a poor random number generator.
2) The cheating authority cannot declare an arbitrary false
plaintext while also making the shufﬂe proof work. But it
can, for any ciphertext, prove that it decrypts to something
other than the truth. The exploit produces an output vote
that will probably be nonsense rather than a valid vote.4
This exploit could then be used to political advantage to
nullify only those votes with which the cheater disagreed.
We have provided two examples of decryption proofs
that pass veriﬁcation but change the plaintext. We have not
implemented the inclusion of the fake decryption proof into
the sVote mixing and decryption sequence (Section VII-B3).
A. Is this detectable or attributable to the cheating prover?
Because of these invalid votes, this exploit will probably
leave evidence that something went wrong. According to the
sVote audit speciﬁcation [12, Section 5, Step 2, p.57], the
invalid votes are stored in a auditableVotes.csv ﬁle,
and the audit veriﬁes that all the ballots included in that ﬁle are
invalid indeed. So, the ballots for which fake decryption proofs
have been produced will be written in that ﬁle and, according
to the audit speciﬁcation, the veriﬁcation will formally pass.
If someone wishes to push investigations further, one may
wonder how invalid ballots were accepted in the ballot box and
4Note that we are not sure whether this is also true for other elections, such
as New South Wales, that express votes differently from Switzerland.
tallied. The sVote spec [7, p.117] states, “Usually these errors
should not happen since the value encrypted by the voting
client is the product of valid prime numbers included in the
ballot.” It is not clear what “usually” means, or what would
be inferred if these errors happened.
For regular (i.e., non write-in) votes, it appears that this
should just not happen under the proposed trust model. The
zero knowledge proofs of valid vote construction [7, Section
5.4.1], produced in the voting client, are expected to prove some
internal consistency in the ballots (even if they do not include a
proof that the vote is the product of the prime numbers it should
be). However, there is another step [7, Section 5.4.4, Step 1] in
which the Vote Veriﬁcation Context derives the Choice Return
Codes, and that step would normally fail if the vote is not the
product of the expected primes. As a result, it seems that our
exploit would put the system in an “impossible state”, which
would make it difﬁcult to deﬁne a meaningful investigation
process. If the possibility that the cryptographic algorithms
are broken is considered (but possibly without really knowing
which ones), then it might eventually be possible to identify the
cheater by requiring the CCM’s to release their secret key. It is
certainly unclear how to run such an exceptional investigation
without breaking the privacy of some votes.
For write-in votes, the individual veriﬁability mechanisms do
not offer any guarantee that the submitted write-ins make any
sense (this would be complicated, since these can essentially be
anything). So, our exploit would offer a way to transform valid
write-ins into senseless votes, and such a situation would be
consistent with a voter willing to express a senseless write-in,
or with a corrupted voting client.
Formally, veriﬁcation would pass. Informally, it would be
apparent there was a problem. But, if the weakness that we
identiﬁed in the Fiat-Shamir transform were not known, the
path towards a proper diagnosis of this problem would be quite
difﬁcult to execute, in particular without violating the privacy
of some votes.
B. Producing a false decryption proof
Remember that an ElGamal encryption of message m with
public key pk is a pair (C0,C1) = (gr,m(pk)r). A proof of
proper decryption—that the ciphertext (C0,C1) decrypts to
message m—can be constructed by anyone who knows the
secret key x s.t. pk = gx mod p. It consists of a proof that
dlogg pk = dlogC0
(cid:4)
1), where C
(cid:4)
1 = C1/m.
(C
(2)
1) The Chaum-Pedersen proof: sVote’s Decryption proof
[7, Section 9.1.8] is very similar to the exponentiation proof
described in Section III-A3. It uses a well-known proof method
due to Chaum and Pedersen [11] to prove Equation 2.
Like the exponentiation proof, the Fiat Shamir heuristic is
implemented incorrectly, with hash inputs that do not include
C0 (or g). Thus a cheating prover can choose C0 after generating
the rest of the proof. This allows it to produce a proof (c,z)
(cid:4)
that passes veriﬁcation as a decryption proof that (g, pk,C0,C
)
(cid:4)
1
) actually decrypts to a
satisfy Equation 2 although (C0,C
1
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:54 UTC from IEEE Xplore.  Restrictions apply. 
653
random value (not 1). The details are very similar to the
exponentiation proof forgery, and are contained in Appendix C.
2) Transforming to a set of fake decryption proofs that pass
veriﬁcation: A decryption proof [7, Section 9.1.8] proceeds by
stating a ciphertext (C0,C1), declaring a plaintext P1 and then
performing a Chaum-Pedersen proof on (g, pk,C0,C1/P1). But
there is nothing that forces a malicious prover to do things in
that order.
For instance, we can start from a cheating Chaum-Pedersen
to produce a set of cheating
proof as above and use it
decryption proof transcripts: given a forged proof (c,z) and the
(cid:4)
(cid:4)
corresponding pair (C0,C
1P and declare
1
it to be a valid encryption of P. Whether this is true or not,
the fake proof will support it.
), simply set C1 = C
3) Incorporating a fake decryption proof into the sVote
mixing and decryption sequence: An attacker can exploit the
ﬂaw in the Chaum-Pedersen protocol described above, because
sVote has a very speciﬁc feature: each mixer performs a shufﬂe