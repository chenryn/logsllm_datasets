title:Statistical bandwidth sharing: a study of congestion at flow level
author:Slim Ben Fredj and
Thomas Bonald and
Alexandre Proutière and
G. R&apos;egni&apos;e and
James W. Roberts
Statistical Bandwidth Sharing: A Study of Congestion
at Flow Level
S. Ben Fredj, T. Bonald, A. Proutiere, G. R´egni´e, J.W. Roberts
France Telecom R&_D
38 rue du G´en´eral Leclerc
{slim.benfredj,thomas.bonald,alexandre.proutiere,gwenael.regnie,james.roberts}@francetelecom.com
92794 Issy les Moulineaux, France
ABSTRACT
In this paper we study the statistics of the realized through-
put of elastic document transfers, accounting for the way
network bandwidth is shared dynamically between the ran-
domly varying number of concurrent ﬂows. We ﬁrst dis-
cuss the way TCP realizes statistical bandwidth sharing,
illustrating essential properties by means of packet level
simulations. Mathematical ﬂow level models based on the
theory of stochastic networks are then proposed to explain
the observed behavior. A notable result is that ﬁrst order
performance (e.g., mean throughput) is insensitive with re-
spect both to the ﬂow size distribution and the ﬂow arrival
process, as long as “sessions” arrive according to a Poisson
process. Perceived performance is shown to depend most
signiﬁcantly on whether demand at ﬂow level is less than or
greater than available capacity. The models provide a key
to understanding the eﬀectiveness of techniques for conges-
tion management and service diﬀerentiation.
1.
INTRODUCTION
The great majority of current Internet traﬃc is contained
in TCP connections generated by applications requiring the
transfer of some kind of digital document. This traﬃc is
elastic and network quality of service is experienced mainly
through the variable throughout achieved by the congestion
control algorithms of TCP. Since this depends on the num-
bers of connections currently sharing the links of the net-
work path, which vary as new ﬂows begin and existing ﬂows
end, throughput performance can only be measured in sta-
tistical terms. In this paper we investigate how throughput
performance depends on available capacity and the volume
and characteristics of oﬀered traﬃc. The ultimate objective
is to derive provisioning rules and traﬃc controls accounting
for the way performance depends on demand and available
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGCOMM’01, August 27-31, 2001, San Diego, California, USA..
Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.
capacity. In the interests of simplicity, we ignore the impact
of non-responsive ﬂows and assume all traﬃc is elastic.
Characteristics of IP traﬃc at packet level are notoriously
complex (see [17], for example). Arguably, however, these
characteristics are less an exogenous expression of user de-
mand than a result of the closed loop control implemented
by TCP. A study of throughput performance more natu-
rally calls for a characterization of traﬃc at the level of the
documents whose transfer is necessary to accomplish the
underlying applications (Web page, FTP ﬁle, e-mail,...).
The present study focuses therefore on evaluating through-
put performance as a function of the arrival process and
size statistics of ﬂows corresponding to individual document
transfers.
We coin the term “statistical bandwidth sharing” to de-
note a form of statistical multiplexing where the rate of
concurrent traﬃc streams is adjusted automatically to make
optimal use of available bandwidth. Such sharing is achieved
with a certain degree of fairness when all users implement
TCP. The evaluation of statistical bandwidth sharing per-
formance provides insight into the nature of congestion at
ﬂow level and clariﬁes the scope for quality of service dif-
ferentiation. Understanding the relation between perfor-
mance, capacity and traﬃc demand is also necessary for
the development of performance-related network provision-
ing procedures.
There is relatively little work in the literature on the eval-
uation of throughput performance under statistical traﬃc
assumptions. Heyman et al [12] consider the performance of
a bottleneck link shared by a ﬁxed number of homogeneous
sources alternately emitting documents and remaining in-
active during a random think-time. Their results conﬁrm
that TCP shares link bandwidth fairly and they derive an
analytical model which accurately predicts throughput per-
formance. A notable result is that expected performance
depends only on the means of the document size and think-
time and not on their precise distributions. Berger and Ko-
gan [4] have further explored this model in an asymptotic
heavy traﬃc regime.
Massouli´e and Roberts [25] propose a model similar to
that of Heyman where however the ﬂow arrival process is
Poisson. They identify the underlying ﬂuid ﬂow model as
an M/G/1 processor sharing queue. The Poisson arrival as-
sumption is more appropriate when the considered link re-
ceives traﬃc from a very large population of users. Kherani
111and Kumar [21] have studied the statistical bandwidth shar-
ing performance realized by TCP and conﬁrm that the pro-
cessor sharing model provides accurate estimates when con-
nection arrivals are Poisson. Bu and Towsley [8] incorporate
a discriminatory processor sharing model in their study of
TCP performance with ﬁnite size ﬂows.
De Veciana et al [11] consider statistical bandwidth shar-
ing in a network setting assuming Poisson ﬂow arrivals.
They notably highlight the potential for a form of conges-
tion collapse when demand on any link exceeds capacity. A
recent study by Fayolle et al [13] illustrates the diﬃculty
of evaluating statistical throughput performance on a path
containing multiple bottlenecks. Bonald and Massouli´e [6]
have further explored statistical bandwidth sharing in a net-
work, notably illustrating the impact on stability of certain
service diﬀerentiation mechanisms.
The main contribution of the present paper is to show
that previous results, derived using simpliﬁed traﬃc mod-
els, are in fact valid under very general and realistic assump-
tions. The latter consist in supposing ﬂows are grouped in
user “sessions” whose starting times constitute a Poisson
process. Session structure, including the number of ﬂows,
their size and any correlation in successive ﬂow and think-
time statistics, can be perfectly general. To prove this we
apply theorems from the theory of stochastic networks not
hitherto employed in the study of bandwidth sharing perfor-
mance. While the mathematics necessary to demonstrate
the generality of the derived performance results is quite so-
phisticated, it should be emphasized that the results them-
selves have a simple expression and provide clear insights
into the nature of congestion and its impact on quality of
service. We also provide an interpretation of these results
in terms of bandwidth provisioning criteria and examine
the important issue of performance under overload.
We begin by summarizing known characteristics of IP
traﬃc at packet, ﬂow and session levels. Detailed packet
level simulations are then used to demonstrate how the slow
start and congestion avoidance algorithms of TCP realize
bandwidth sharing on a single bottleneck link. We then
recall results for analytical ﬂuid ﬂow models derived un-
der the assumption of Poisson arrivals and demonstate that
these accurately predict the simulation results. It is in the
following section that we apply results from the theory of
stochastic networks to show how these models can be ex-
tended to account for very general and realistic ﬂow arrival
processes. Application of these models to deduce end-to-
end performance is then discussed. Finally, we consider
statistical bandwidth sharing on an overloaded link, eval-
uating the broad impact of user impatience and reattempt
behavior on realized ﬂow throughput and link goodput.
2. TRAFFIC CHARACTERISTICS
In this section we recall the known statistical characteris-
tics of elastic traﬃc. Following a discussion on stationarity
we present traﬃc characteristics in terms of packets, ﬂows
and sessions, respectively.
2.1 A stationary process
Traﬃc on network links averaged over a period of 5 to 10
minutes typically exhibit systematic variations as depicted
in Figure 1. Intensity variations follow a certain daily pat-
tern with a clearly identiﬁable busy period. During this
period which can last several hours traﬃc intensity mea-
sured in bits/sec is approximately constant.
In the following sections we model traﬃc as a stationary
stochastic process. This means we assume that traﬃc inten-
sity remains constant for an indeﬁnite period allowing the
estimation of performance criteria as expected values. This
is a classical approximation for which the main justiﬁca-
tion is the “eyeball” constancy of busy period traﬃc levels.
We expect average performance measures derived under the
stationarity assumption to be good approximations for the
performance actually realized during a particular busy pe-
riod.
Traﬃc intensity may be interpreted as the product of a
packet arrival rate and the average packet size or in terms
of higher level entities such as ﬂows or sessions, as discussed
below. The stationarity assumption applies equally to the
arrival process of packets, ﬂows and sessions.
Figure 1: Weekly and daily utilization of a 155
Mbit/s link (both directions)
2.2 Packet level characteristics
It is now well known that Internet traﬃc at packet level
is extremely variable over a wide range of time scales. This
variability is manifested by asymptotic self-similarity and
multi-fractal behavior at time scales smaller than that of
the round trip time. A plausible expanation for self-similarity
is the heavy-tailed nature of the size distribution of trans-
ferred documents while multifractal behavior appears to be
a manifestation of the burstiness induced by TCP conges-
tion control [17, 16].
The complexity of the packet arrival process is such that
it proves very diﬃcult to derive a packet level traﬃc char-
acterization which is useful for performance modeling. We
note further that most performance measures of interest for
elastic traﬃc invoke higher level entities like the ﬂow or the
session such that it is more important to be able to describe
traﬃc in these terms.
2.3 Flow level characteristics
A ﬂow in the Internet is a loosely deﬁned object repre-
senting a stream of packets having some criteria in com-
mon (IP addresses, port numbers,...). We use the term
somewhat more restrictively to represent the packets cor-
responding to the transfer of a particular document. The
document in question might be a Web page, an in-line ob-
ject, a data ﬁle or an MP3 track. The deﬁning feature is
that the ﬂow is manifested by a more or less continuous
stream of packets using a considered network link or path.
The ﬂow may be realized by several overlapping TCP con-
nections pertaining to the same document or by one period
of activity of a sporadically used long-term TCP connec-
tion. It is characterized by its starting time and its size in
bits. It may additionally be qualiﬁed by parameters such
as the round trip time (RTT) or other external factors af-
fecting the bandwidth it obtains on a shared link.
Measurements of the size of documents such as Web pages
and FTP ﬁles show that their distribution has a heavy tail
[10, 28]. The precise distribution clearly depends on the
type of document considered. A reasonable ﬁt to the form
of the heavy tail is provided by the Pareto distribution:
, for x ≥ k,
Pr[size ≤ x] = 1 − k
xβ
(1)
with 1 < β ≤ 2, this distribution having a ﬁnite mean and
inﬁnite variance. The distribution has the property that a
majority of ﬂows are very small while most of the traﬃc
in bytes is contained in large ﬂows. We adopt the familiar
shorthand of referring to very short ﬂows as “mice” and to
very long ﬂows as “elephants”.
In many cases ﬂows are generated within sessions. The
ﬂow arrival process thus tends to be bursty and has indeed
been shown to be self-similar in certain cases [28, 15], a
plausible explanation being that the number of ﬂows per
session has a heavy-tailed distribution. It may nevertheless
be appropriate in certain circumstances to suppose ﬂows
arrive according to a Poisson process. This would be the
case, for example, when ﬂows correspond to a large number
of independent sessions and the spacing of ﬂows within a
session is large compared to the average inter-ﬂow interval.
2.4 Poisson session arrivals
As for ﬂows, it is not immediately obvious how one can
unambiguously deﬁne a session. Sometimes the session can
be identiﬁed with an ISP modem call [16] or an FTP ses-
sion [28]. Some authors have arbitrarily deﬁned a session
by partitioning a set of ﬂows according to the inter-ﬂow
interval: a new session is assumed to start when this inter-
val exceeds a certain threshold [27]. In all cases it is noted
that session arrivals in any period where the traﬃc inten-
sity is approximately constant are accurately modeled by a
Poisson process. This observation is not surprising since a
Poisson process is known to result from the superposition
of a large number of independent user processes each of low
relative intensity.
For present purposes, we consider a session to be com-
posed of a set of ﬂows whose statistical properties (arrival
time, size,...) are independent of those of ﬂows of any other
session. We also assume that users generate sessions in-
dependently. If traﬃc intensity is constant and no single
user contributes an excessive amount of traﬃc, the latter
independence assumption will naturally lead to a station-
ary Poisson session arrival process whenever the number of
users is large. The structure of a session is highly complex
and varies depending on the underlying applications (Web,
e-mail, FTP, etc.). Generically, it is composed of a succes-
sion of ﬂows separated by an interval of inactivity which we
call “think-time”.
In the next two sections we evaluate statistical bandwidth
sharing on an isolated link assuming Poisson ﬂow arrivals.
This assumption simpliﬁes analysis and provides useful in-
sight.
In the following section it is shown that most re-
sults derived for Poisson ﬂow arrivals are also true with the
weaker assumption of Poisson session arrivals.
3. BANDWIDTH SHARING REALIZED BY
TCP
To gain insight into the way TCP realizes bandwidth
sharing in statistical traﬃc, we have conducted a number
of simulation experiments using the ns2 simulator 1. These
simulations illustrate the impact of packet level dynamics
on the performance of bandwidth sharing at ﬂow level, each
ﬂow being here assimilated to a TCP connection.
3.1 Simulation model
The simulated model is very simple consisting of just one
bottleneck link handling packets from a certain number of
TCP connections delivered to the link via a droptail buﬀer
with a capacity of 50 packets. All packets are 1000 bytes
long and the connections have a maximum receive window
of 40 packets.
Statistical traﬃc variations result from an assumed Pois-
son connection arrival process and a Pareto size distribution
(1) with parameters β = 1.5 and k = 15 packets. We have
conﬁrmed by other non-reported experiments that the ex-
clusion of very small ﬂows (less than 15 packets) does not
aﬀect the accuracy of reported results.
3.2 Slow start and the response time of “mice”
The response time of very small ﬂows is constrained by
TCP slow start. Even if the ﬂow were alone on the link
its throughput could not increase faster than allowed by a
doubling of the congestion window every RTT. Assume the
RTT is ﬁxed and equal to rtt and that the transmission
time of one packet is tr. Denote by P the bandwidth-delay
product rtt/tr and by W the advertised receive window.
Assume packets are acknowledged individually and that
none are lost.
Let R(n) be the time necessary to transfer and acknowl-
edge n packets. R(n) ﬁrst increases geometrically until ei-
ther the receive window is attained or the link is saturated
and then increases at constant rate. Consideration of the
schedule of packet emissions yields the following relations
for R(n). For n < n(cid:2) = 2
(cid:1)log2 min{W,P}(cid:4)+1,
n(cid:7) + 1) rtt + (n − 2
R(n) = ((cid:6)log2
(cid:5)log2 n(cid:6)
)tr.
(2)
1http://www.isi.edu/nsnam/ns/
For n ≥ n(cid:2),
(cid:1)
R(n) =
R(n − W ) + rtt,
R(n − 1) + tr,
if W < P
if W ≥ P
(3)
The throughput n/R(n) thus increases like n/ log2
n be-
fore ﬂattening oﬀ and tending to the limit min{W/rtt, 1/tr}
as n → ∞.
3.3 Congestion avoidance and the throughput
of “elephants”
The response time of very large ﬂows, or elephants, de-
pends more on TCP congestion avoidance than on the ini-
tial slow start phase. As long as the packet loss rate p is
not too high and the receive window is not limiting, the
throughput B achieved by a permanent ﬂow is given by the
approximate relation:
B(p) ≈ K
√
rtt
p