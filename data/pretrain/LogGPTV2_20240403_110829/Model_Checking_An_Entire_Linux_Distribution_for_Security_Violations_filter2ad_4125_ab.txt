The amount of human effort that was spent auditing the er-
ror groups is roughly proportional to the total number of
groups. We spent about 100 person-hours auditing error
reports from the TOCTTOU property, 50 person-hours for
the temporary ﬁle property, and less for the other properties.
Several of us were undergraduate students who had no prior
experience with MOPS prior to joining this project.
3 Checking Security Properties
We developed six security properties. Table 1 shows a
summary of the bugs discovered. For each property, the ta-
ble shows the number of warnings reported by MOPS, the
number of real bugs, and the section that describes detailed
ﬁndings on this property. We will describe four properties in
detail, explain the model checking results, and show repre-
sentative bugs and vulnerabilities that we discovered in this
section. The other two are discussed in the full version.
Race condition attacks have perennially plagued secure
systems. One common mistake is that a program checks the
access permission of an object and, if the check succeeds,
makes a privileged system call on the object. For exam-
ple, one notorious error involves the access() and open()
system calls. Consider a program running as root (e.g., se-
tuid root, or executed by root) executing the following code
fragment:
if (access(pathname, R_OK) == 0)
fd = open(pathname, O_RDONLY);
The programmer is attempting to enforce a stricter security
policy than the operating system. However, the kernel does
not execute this sequence of system calls atomically— so if
there is a context switch between the two calls or if the pro-
gram is running on a multiprocessor system, another pro-
gram may change the permission of the object. When the
above program resumes its execution, it then blindly per-
forms open() even though the user should no longer have
access permission to the object.
Another example comes from UNIX folklore. It is well
known that the root user should not recursively remove ﬁles
inside directories that may be writable by other users. For
example, “rm -rf /tmp” is a dangerous command, even if
root has veriﬁed that the directory /tmp contains no symlink
to other parts of the ﬁle system. The reason is that after rm
veriﬁes that a directory is not a symlink but before it enters
the directory to delete the ﬁles within, an adversary may
replace the directory with a symlink to another part of the
ﬁle system, therefore tricking rm into deleting that part of
the ﬁle system.
Many of the vulnerabilities that we found are exploitable
when two users share access to some portion of the ﬁle sys-
tem, and one user is operating on the shared portion while
the other mounts an attack by replacing symbolic links. Al-
though programs commonly attempt to ensure that they do
not follow symbolic links before doing dangerous opera-
tions like unlink(), they often check it incorrectly and are
susceptible to TOCTTOU attacks as a result.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:43 UTC from IEEE Xplore.  Restrictions apply. 
Check(f)
Use(f)
Check(f) = {stat(f), lstat(f), access(f),
readlink(f), statfs(f)}.
Use(f) = {basename(f), bindtextdomain(f),
catopen(f), chown(f), dirname(f), dlopen(f),
freopen(f), ftw(f), mkfifo(f), nftw(f),
opendir(f), pathconf(f), realpath(f),
setmntent(f), utmpname(f), chdir(f), chmod(f),
chroot(f), creat(f), execv(f), execve(f),
execl(f), execlp(f), execvp(f), execle(f),
lchown(f), mkdir(f), fopen(f), remove(f),
tempnam(f), mknod(f), open(f), quotactl(f),
rmdir(f), truncate(f), umount(f), unlink(f),
uselib(f), utime(f), utimes(f), link(f), mount(f),
rename(f), symlink(f)}.
Non-ﬁlename arguments are omitted.
Figure 1. A reﬁned FSA for ﬁnding TOCTTOU
(ﬁle system race condition) vulnerabilities.
We have experimented with several different FSAs to
capture these types of vulnerabilities. In our ﬁrst attempt,
we chose an FSA that had two transitions—one from the
start state to an intermediate state, and the other from the
intermediate state to the accepting state. Both transitions
were deﬁned on the union of the ﬁle system calls that ac-
cess the ﬁle system using a pathname argument. How-
ever, we found that this naive property results in too many
false positives—for example, chdir(".") followed by a
chdir(".") would trigger a false positive. Typically these
situations arise when a single system call is located inside of
a loop, and both transitions in the FSA are made as a result
of executing the same line of code. Since these are obvi-
ously not security holes, we decided to separate out the ﬁle
system calls that can be classiﬁed as “checks” from those
that are “uses”.
We reﬁned the property by dividing the ﬁle system calls
into two distinct sets. Figure 1 shows the general structure
of the FSA. We assume here, and in subsequent illustra-
tions, that there is an implicit other transition from every
state back to itself; if none of the normal outgoing tran-
sitions match, the other transition is taken, and the FSA
stays in the same state. The intuition is as follows: a call
to Check(f) is probably intended to establish an invariant
(e.g., “f is not a symlink”), and a call to Use(f) might rely
on this invariant. Of course, these invariants might be vio-
lated in an attack, so Check(f) followed by Use(f) may in-
dicate a TOCTTOU vulnerability. This reﬁned property is
much more manageable and ﬁnds most of the bugs we are
interested in. However, the more general property is capa-
ble of ﬁnding some bugs which the narrower TOCTTOU
cannot—for example, creat(f) followed by chmod(f).
The types of vulnerabilities we have found can be clas-
siﬁed under the following categories:
1. [Access Checks] A check is performed—often by a
program running as root—on ﬁle access permissions.
The result of the check is then used to determine
whether a resource can be used. The access(f) and
open(f) race at the beginning of this section illus-
trates this class of bugs.
2. [OwnershipStealing] A program may stat() a ﬁle to
make sure it does not exist, then open() the ﬁle for
writing. If the O EXCL ﬂag is not used, an attacker may
create the ﬁle after the stat() is performed, and the
program will then write to a ﬁle owned by the attacker.
We consider this a vulnerability, because the program
may disclose sensitive information.
3. [Symlinks] Vulnerabilities due to symbolic links arise
when two users share the same portion of the ﬁle sys-
tem. One user can change a ﬁle to a symlink to trick
the other user to mistakenly operate on an unexpected
ﬁle. The method of such an attack depends on whether
the system call follows symlinks. Broadly, there are
two classes of system calls:
(a) [Syscalls that follow symlinks] Many system
calls will follow symbolic links that occur any-
where in the pathname passed to them. These
present no barrier to attack.
(b) [Syscallsthat don’tfollow symlinks] Other sys-
tem calls avoid following symbolic links if they
occur in the last component of their pathname
argument. For instance, if c is a symbolic link
to d, calling unlink("/a/b/c") will delete the
symbolic link itself rather than the target of the
link:
it deletes /a/b/c, not /a/b/d. How-
ever, many programmers do not realize that these
calls will gladly follow any symlinks that oc-
cur in earlier components of the pathname. For
example,
then
unlink("/a/b/passwd") will delete the pass-
word ﬁle /etc/passwd. Consequently, to attack
this second class of system calls, it sufﬁces for
the attacker to tamper with one of the intermedi-
ate components of the path.
if b is a symlink to ../etc,
Many bugs we found were not previously known. Some
were previously reported (but apparently not yet ﬁxed and
not known to us at the time of our experiments). To illustrate
the kinds of bugs we found with MOPS, we will show three
representative examples of TOCTTOU bugs.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:13:43 UTC from IEEE Xplore.  Restrictions apply. 
# binutils-2.13.90.0.18-9 :: ar #
exists = lstat (to, &s) == 0;
/* Use rename only if TO is not a symbolic
link and has only one hard link. */
if (! exists || (!S_ISLNK (s.st_mode)
&& s.st_nlink == 1)) {
ret = rename (from, to);
if (ret == 0) {
if (exists) {
chmod (to, s.st_mode & 0777);
if (chown (to, s.st_uid,
s.st_gid) >= 0) {
chmod (to, s.st_mode & 07777);
}
...
In our ﬁrst example, the program ar executes the code
fragment above to replace an archive ﬁle with one of the
same name. It calls lstat on the destination ﬁle and then
checks if the ﬁle is a symbolic link. If it is not, ar calls
rename on the ﬁle and then sets the mode of the ﬁle. This
code, however, is unsafe. An adversary may change the
ﬁle to be a symbolic link after ar checks for symbolic links.
Then, ar will happily change the mode of whatever the sym-
bolic link points to—assuming the user running ar has per-
mission to do so. The attack is applicable when two users
have write access to the directory of the archive ﬁle.
# initscripts-7.14-1 :: minilogd #
/* Get stat info on /dev/log so we can later
check to make sure we still own it... */
if (stat(_PATH_LOG,&s1) != 0) {
memset(&s1, ’\0’, sizeof(struct stat));
}
...
if ( (stat(_PATH_LOG,&s2)!=0) ||
(s1.st_ino != s2.st_ino ) ||
(s1.st_ctime != s2.st_ctime) ||
(s1.st_mtime != s2.st_mtime) ||
(s1.st_atime != s2.st_atime) ) {
done = 1;
we_own_log = 0;
}
/* If we own the log, unlink it before trying
to free our buffer. Otherwise, sending the
buffer to /dev/log doesn’t make much sense */
if (we_own_log) {
perror("wol");
unlink(_PATH_LOG);
}
it thinks it exclusively owns the ﬁle. It compares the times-
tamps on the ﬁle at two different times in the execution of
the program and, if they are equal, decides that it exclu-
sively owns the ﬁle and then removes the ﬁle. However,
even if another program modiﬁes the ﬁle after minilogd
checks the timestampes, minilogd will still unlink it, pos-
sibly corrupting other programs. An additional vulnera-
bility exists when user programs can write to the log ﬁle;
for instance, if _PATH_LOG is deﬁned as something like
/home/alice/log instead.
In this case, Alice can trick
minilogd into removing anything on the ﬁle system. We
have found many vulnerabilities that are similar to the lat-
ter case.
It is important that these ﬁlename constants be
checked very carefully when these programs are built, since
it may not be obvious to users that deﬁning _PATH_LOG to a
user-writable ﬁle can result in a total compromise of the ﬁle
system.
# zip-2.3-16 :: zip #
d_exists = (LSTAT(d, &t) == 0);
if (d_exists) {
/* respect existing soft and hard links! */
if (t.st_nlink>1 ||
(t.st_mode&S_IFMT)==S_IFLNK)
copy = 1;
else if (unlink(d))
return ZE_CREAT;
}
The ﬁnal code snippet comes from the widely-used pro-
gram zip. If the destination ﬁle already exists, zip will move
the ﬁle to a new location, unlink the old copy, and write
the new copy. The program veriﬁes that the ﬁle is not a
link before calling unlink on it. The attack is applicable
when two users share a portion of the ﬁle system and one
user is running zip to write a new ﬁle to the shared space.
If the other user is malicious, after zip calls stat, the user
can change the ﬁle to be a symbolic link that points to an-
other part of the ﬁle system. Since unlink will not fol-
low the last component of a pathname, the attacker would
have to change one of the components in the middle of the
pathname to a symbolic link. For instance, if Alice is us-
ing zip to write a ﬁle to /shared/alice/afile2, Bob can
change /shared/alice to be a symbolic link that points to
/home/alice. Then the zip program running on behalf of
Alice will remove /home/alice/afile. Most users will
not be aware that using a shared directory enables such at-
tacks, so it seems unfair to blame Alice for doing so. In
this case, zip does try to do the right thing by checking for
symbolic links; it just happens to get the check wrong.
The second code fragment is taken from the program