as the number of times the customer has previously visited
the current station. In the present context we use the class
to specify just the distribution of the customer’s current
service requirement and, either the fact that it leaves the
network when it ﬁnishes that service, or the class it will
acquire at the next station to be visited. In general, the
customer changes class when it changes station.
Recall that the considered bottleneck or transparent back-
bone links have the property that, if customer arrivals are
Poisson, the distribution of the number of customers present
is insensitive to the form of the distribution of service re-
quirements. The station representing the think-time also
has this insensitivity property.
In the terminology intro-
duced by Kelly, all network stations are “symmetric queues”
[19, Chapter 3].
The latter property coupled with the assumed class mech-
anism and Poisson customer arrivals from outside allows us
to deduce that Theorems 3.7 and 3.10 in [19] apply to the
considered network. Among other results, these theorems
state that the distribution of the number of customers at
each station is distributed as if all customer arrivals, in-
cluding repeated visits, constitute a Poisson process. The
implication for statistical bandwidth sharing performance is
that as long as session arrivals are Poisson, the distribution
of the number of ﬂows in progress is given by (5), (7) or (9)
for any ﬂow arrival process which can be represented by the
assumed class mechanism. This mechanism is suﬃciently
versatile to reproduce most of the observed characteristics
of IP traﬃc at ﬂow level, as explained below.
5.2 A general ¤ow arrival process
The set of classes is typically very large and may, in gen-
eral, be countably inﬁnite. It is natural, for example, to use
distinct classes to represent diﬀerent types of session (Web,
FTP, e-mail,...). To distinguish successive ﬂows within a
session it is further necessary to attribute a new distinct
class for each visit to a given station.
The class mechanism can be used to account for a par-
ticular distribution of the number of ﬂows per session. Let
λ be the overall arrival intensity of a particular type of ses-
sion and denote by p(i), for i ≥ 1, the probability a session
contains i ﬂows. We deﬁne a distinct class cij, for i ≥ 1 and
j  0 implies
r(cid:8)l xrBr = Cl, it may
readily be veriﬁed by applying the Kuhn-Tucker theorem
that the allocation satisfying (13) is the unique solution to
optimization problem (12) with α = 2 and wr = 1/rtt2
r
(see [30] for further discussion on the type of bandwidth
sharing realized by TCP).
6.2 Statistical bandwidth sharing
Assume now that ﬂows on route r arrive at rate λr and
have mean size σr. Let ρl =
r(cid:8)l λrσr/Cl denote the load
oﬀered to link l. We assume bandwidth is instantaneously
allocated to solve (12) as the xr change. A ﬁrst question of
interest is that of stability. Not surprisingly, as shown in [6],
the number of ﬂows on each route remains ﬁnite provided
the usual traﬃc condition ρl  1, the number of ﬂows in progress
tends to increase and their throughput tends to zero since
the arrival rate λ is greater than the average rate of ﬂow
completion. This behavior is illustrated in Figure 11 which
shows results from an ns simulation of a 10 Mbit/s link un-
der 20% overload. The link is empty at time zero and ﬂow
sizes have a Pareto distribution. The dots represent the
throughput realized by ﬂows at the instant of their comple-
tion.
Figure 11: Bandwidth sharing performance during
transient overload
It is interesting to note that the rate of increase in the
number of ﬂows actually depends signiﬁcantly on the form
of the size distribution [18]. The rate of increase is smaller
as the proportion of mice is greater. The latter manage to
complete although their throughput continues to decrese,
while the response time of elephants tends rapidly to inﬁn-