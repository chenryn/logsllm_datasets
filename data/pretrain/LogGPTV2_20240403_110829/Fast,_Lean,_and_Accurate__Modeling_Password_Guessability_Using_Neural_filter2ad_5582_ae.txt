b
m
u
N
s
s
e
u
G
n
M
>1e20
>1e16
>1e12
>1e8
>1e4
>1e0
i
0
0
0
0
0
10
0
28
236
721
791
196
Weak
0
18
0
65
1
173
96
196
177
96
156
6
Weakest Weaker
Strong
Yahoo Meter Strength 
(c) Yahoo!
27
18
7
8
2
0
Stronger
Figure 10: Client-side guess numbers compared to the minimum guess number of all server-side methods. The number in
the bin represents the number of passwords in that bin. For example, neural networks rated 358 passwords as being guessed with
between 100 and 104 guesses, while server-side approaches rate them as taking between 104 and 108 guesses. The test passwords
are our 1class8 set. The Yahoo! meter does not provide guess numbers and, as such, has a different x-axis. Overestimates of strength
are shown in shades of red, underestimates in shades of purple, and accurate estimates in shades of green. Color intensity rises with
the number of passwords in a bin.
Pipeline stage
Original JSON format
Quantization
Fixed point
ZigZag encoding
Removing spaces
Size
6.9M
4.1M
3.1M
3.0M
2.4M
gzip-ed Size
2.4M
716K
668K
664K
640K
Table 1: The effect of different pipeline stages on model size.
This table shows the small model that targets the 1class8 pass-
word policy, with 682,851 parameters. Each stage includes the
previous stage, e.g., the ﬁxed-point stage includes the quanti-
zation stage. We use gzip at the highest compression level.
8 Neural Network
s
s
a
l
c
1
s
s
a
l
c
4
zxcvbn
Yahoo!
zxcvbn
Yahoo!
8 Neural Network
Total Unsafe
164
1311
1331
270
984
1900
115
1826
231
1853
1328
647
Table 2: The number of total and unsafe misclassiﬁcations
for different client-side meters. Because the Yahoo! meter
provides different binning, we pre-process its output for fairer
comparison, as described in Section 5.3.
We perform both tests on a laptop running OSX with a
2.7 GHz i7 processor and using the Chrome web browser
(version 48). We randomly selected a subset of 500 pass-
words from our 1class8 training set for these tests. In the
semi-cached test, the average time to compute a guess
number is 17 ms (stdev: 4 ms); in the full-password test,
the average time is 124 ms (stdev: 48 ms). However,
both the semi-cached test and the uncached test perform
fast enough to give quick feedback to users.
Comparison to Other Password Meters We com-
pared the accuracy of our client-side neural network im-
plementation to other client-side password-strength es-
timators. Approximations of password strength can be
under- or overestimates. We call overestimates of pass-
word strength unsafe errors, since they represent pass-
words as harder to guess than they actually are. We show
that our meter can more precisely measure passwords’
resistance to guessing with up to half as many unsafe er-
rors as existing client-side models, which are based on
heuristics. Our ground truth for this section is the ideal-
ized MinGuess method, described in Section 5.2.
Prior work found nearly all proactive password-
strength estimators to be inconsistent and to poorly es-
timate passwords’ resistance to guessing [33]. The
most promising estimator was Dropbox’s zxcvbn me-
ter [94, 95], which relies on hand-crafted heuristics, sta-
tistical methods, and plaintext dictionaries as training
data to estimate guess numbers. Notably, these plain-
text dictionaries are not the same as those used for our
training data, limiting our ability to fully generalize from
these comparisons. Exploring other ways of conﬁgur-
ing zxcvbn is beyond the scope of this evaluation. We
compare our results to both zxcvbn and the Yahoo! me-
ter, which is an example of using far less sophisticated
heuristics to estimate password strength.
The Yahoo! meter does not produce guess numbers
but bins passwords as weakest, weaker, weak, strong,
and stronger. We ignore the semantic values of the bin
names, and examine the accuracy with which the me-
ter classiﬁed passwords with different guess numbers (as
computed by the MinGuess of all guessing methods) into
the ﬁve bins. To compare the Yahoo! meter to our mini-
mum guess number (Table 2), we take the median actual
guess number of each bin (e.g., the “weaker” bin) and
then map the minimum guess number for each password
to the bin that it is closest to on a log scale. For exam-
ple, in the Yahoo! meter, the guess number of 5.4· 104
is the median of the “weaker” bin; any password closer
to 5.4 · 104 than to the medians of other bins on a log
scale we consider as belonging in the “weaker” bin. We
intend for this to be an overestimate of the accuracy of
USENIX Association  
25th USENIX Security Symposium  187
13
90%
60%
30%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
0%
100%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
75%
50%
25%
0%
75%
50%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
25%
0%
101 104 107101010131016101910221025
Guesses
(a) 1class8 passwords
MinGuess
Neural
Markov
PCFG
Hashcat
JTR
MinGuess
Neural
Markov
PCFG
JTR
Hashcat
101 104 107101010131016101910221025
Guesses
(b) 4class8 passwords
MinGuess
Neural
Markov
PCFG
Hashcat
JTR
101 104 107 101010131016101910221025
Guesses
(c) 1class16 passwords
Figure 7: Guessability of our password sets for different
guessing methods using the PGS++ data set. MinGuess
stands for the minimum number of guesses for any approach.
the Yahoo! meter. Nonetheless, both our work and prior
work [33] ﬁnd the Yahoo! meter to be less accurate than
other approaches, including the zxcvbn meter.
We ﬁnd that our client-side neural network approach
is more accurate than the other approaches we test, with
up to two times fewer unsafe errors and comparable safe
errors, as shown in Figure 10 and Table 2. Here, we used
our neural network meter implementation with the tun-
ing described in Section 3.4. We performed the 1class8
75%
50%
25%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
0%
100%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
75%
50%
25%
0%
MinGuess
Neural
Markov
PCFG
JTR
Hashcat
101 104 107 101010131016101910221025
Guesses
(a) 3class12 passwords
MinGuess
Neural
Markov
PCFG
Hashcat
JTR
101 104 107101010131016101910221025
Guesses
(b) Webhost passwords
Figure 8: Guessability of our password sets for different
guessing methods using the PGS++ data set (continued).
test with the client-side Bloom ﬁlter, described in Sec-
tion 3.3.1, while the 4class8 test did not use the Bloom
ﬁlter because it did not signiﬁcantly impact accuracy.
Both tests scale the network output down by a factor
of 300 and ignore case to give more conservative guess
numbers. We chose the scaling factor to tune the net-
work to make about as many safe errors as zxcvbn. In
addition, we ﬁnd that, compared to our neural network
implementation, the zxcvbn meter’s errors are often at
very low guess numbers, which can be particularly un-
safe. For example, for the 10,000 most likely passwords,
zxcvbn makes 84 unsafe errors, while our neural net-
work only makes 11 unsafe errors.
Besides being more accurate, we believe the neural
network approach is easier to apply to other password
policies. The best existing meter, zxcvbn, is hand-
crafted to target one speciﬁc password policy. On the
other hand, neural networks enable easy retargeting to
other policies simply by retraining.
188  25th USENIX Security Symposium 
USENIX Association
14
d
e
s
s
e
u
g
t
n
e
c
r
e
P
100%
75%
50%
25%
0%
Server
Browser
References
[1] CSDN password leak. http://thepasswordproject.com/
leaked password lists and dictionaries.
[2] Faith writer
leak.
https://wiki.skullsecurity.org/
Passwords#Leaked passwords.
101 104 107 101010131016101910221025
Guesses
Figure 9: Compressed browser neural network with weight
and curve quantization compared an unquantized network.
Browser is our browser network with weight and curve quanti-
zation. Server is the same small neural network without weight
and curve quantization.
6 Conclusion
This paper describes how to use neural networks to
model human-chosen passwords and measure pass-
word strength. We show how to build and train neu-
ral networks that outperform state-of-the-art password-
guessing approaches in efﬁciency and effectiveness, par-
ticularly for non-traditional password policies and at
guess numbers above 1010. We also demonstrate how to
compress neural network password models so that they
can be downloaded as part of a web page. This makes
it possible to build client-side password meters that pro-
vide a good measure of password strength.
Tuning neural networks for password guessing and de-
veloping accurate client-side password-strength metrics
both remain fertile research grounds. Prior work has used
neural networks to learn the output of a larger ensemble
of models [24] and obtained better results than our net-
work tutoring (Section 5.1). Other work achieves higher
compression ratios for neural networks than we do by
using matrix factorization or specialized training meth-
ods [51, 96]. Further experiments on leveraging natural