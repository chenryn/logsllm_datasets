vehicle and lane widths in the U.S., and the required success
time is determined using commonly-used average driver reac-
tion time to road hazards, which is detailed in Appendix A.
Targeted scenario: Free-ﬂow driving. Our study targets
the most common driving scenario for using ALC systems:
free-ﬂow driving scenarios [32], in which a vehicle has at least
5–9 seconds clear headway [33] and thus can drive freely
without considering the front vehicle [32].
Safety implications. The attack goal above can directly
cause various safety hazards in the real world: (1) Driving
off road, which is a direct violation of trafﬁc rules [34] and
can cause various safety hazards such as hitting road curbs
or falling down the highway cliff. (2) Vehicle collisions, e.g.,
with vehicles parked on the road side, or driving in adjacent
or opposite trafﬁc lanes on a local road or a two-lane undi-
vided highway. Even with obstacle or collision avoidance,
these collisions are still possible for two reasons. First, to-
day’s obstacle and collision avoidance systems are not perfect.
For example, a recent study shows that the AEB (Automatic
Emergency Braking) systems in popular vehicle models today
fail to avoid crashes 60% of the time [35]. Second, even if
they can successfully perform emergency stop, they cannot
prevent the victim from being hit by other vehicles that fail to
yield on time. Later in §7, we evaluate the safety impacts of
our attack with a simulator and a real vehicle.
3.2 Threat Model
We assume that the attacker can obtain the same ALC system
as the one used by the victim to get a full knowledge of its
implementation details. This can be done through purchasing
or renting the victim vehicle model and reverse engineering
it, which has already been demonstrated possible on Tesla
Autopilot [6]. Moreover, there exist production ALC systems
that are open sourced [8]. We also assume that the attacker
can obtain a motion model [36] of the victim vehicle, which
will be used in our attack generation process (§4.2). This
is a realistic assumption since the most widely-used motion
model (used by us in §4.2) only needs vehicle parameters such
as steering ratio and wheelbase as input [36], which can be
directly found from vehicle model speciﬁcations. We assume
the victim drives at the speed limit of the target road, which
is the most common case for free-ﬂow driving. In the attack
preparation time, we assume that the attacker can collect the
ALC inputs (e.g., camera frames) of the target road by driving
USENIX Association
30th USENIX Security Symposium    3311
Lane DetectionCameraFrameCurve FittingLane Line CurvesLateralControlVehicle ActuationSteering Angle DecisionPIDMPC…DNNVehicle Statethe victim vehicle model there with the ALC system on.
3.3 Design Challenges
Compared to prior works on physical-world adversarial at-
tacks on DNNs, we face 3 unique design challenges:
C1. Lack of legitimately-deployable attack vector in
the physical world. To affect the camera input of an ALC
system, it is ideal if the malicious perturbations can appear
legitimately around trafﬁc lane regions in the physical world.
To achieve high legitimacy, such perturbations also must not
change the original human-perceived lane information. Prior
works use small stickers or grafﬁti in physical-world adversar-
ial attacks [4–6]. However, directly performing such activities
to trafﬁc lanes in public is illegal [37]. In our problem setting,
the attacker needs to operate in the middle of the road when
deploying the attack on trafﬁc lanes. Thus, if the attack vector
cannot be disguised as legitimate activities, it becomes highly
difﬁcult to deploy the attack in practice.
C2. Camera frame inter-dependency due to attack-
inﬂuenced vehicle actuation. In real-world ALC systems,
a successful attack on one single frame can barely cause any
meaningful lateral deviations due to the steering angle change
limit at the vehicle actuation step (§2.1). For example, for the
vehicle models with 0.25◦ angle change limit per control loop
(§2.1), even if a successful attack on a single frame causes a
very large steering angle decision at MPC output (e.g., 90◦), it
can only cause at most 1.25◦ actuated steering angle changes
before the next frame comes, which can only cause up to
0.3-millimeter lateral deviations at 45 mph (∼72 km/h). More
detailed explanations are in our extended version [38].
Thus, to achieve our attack goal in §3.1, the attack must be
continuously effective on sequential camera frames to increas-
ingly reach larger actuated steering angles and thus larger
lateral deviations per frame. In this process, due to the dy-
namic vehicle actuation applied by the ALC system, the attack
effectiveness for later frames are directly dependent on that
for earlier frames. For example, if the attack successfully devi-
ates the detected lane to the right in a frame, the ALC system
will steer the vehicle to the right accordingly. This causes the
following frames to capture road areas more to the right, and
thus directly affect their attack generation. There are prior
works considering attack robustness across sequential frames,
e.g., using EoT [29, 30] and universal perturbation [39], but
none of them consider frame inter-dependencies due to attack-
inﬂuenced vehicle actuation in our problem setting.
C3. Lack of differentiable objective function design
for LD models. To systematically generate adversarial in-
puts, prior works predominately adopt optimization-based
approaches, which have shown both high efﬁciency and effec-
tiveness [4, 26]. However, the objective function designs in
these prior works are mainly for image classiﬁcation [4,30] or
object detection [4, 5] models, which thus aim at decreasing
class or bounding box probabilities. However, as introduced
in §2.1, LD models output detected lane line curves, and thus
to achieve our attack goal the objective function needs to aim
at changing the shape of such curves. This is substantially
different from decreasing probability values, and thus none
of these existing designs can directly apply.
Closer to our problem, prior works that attack end-to-end
autonomous driving models [40–43] directly design their ob-
jective function to change the ﬁnal steering angle decisions.
However, as described in §2.1, state-of-the-art LD models
do not directly output steering angle decisions. Instead, they
output lane line curves and rely on the lateral control step to
compute the ﬁnal steering angle decisions. However, many
steps in the lateral control module, e.g., the desired driving
patch calculation and the MPC framework, are generally not
differentiable to the LD model input (i.e., camera frames),
which makes it difﬁcult to effectively optimize.
4 Dirty Road Patch Attack Design
In this paper, we are the ﬁrst to systematically address the
design challenges above by designing a novel physical-world
attack method on ALC, called Dirty Road Patch (DRP) attack.
4.1 Design Overview
To address the 3 design challenges in §3.3, our DRP attack
method has the following novel design components:
Dirty road patch: Domain-speciﬁc & stealthy physical-
world attack vector. To address challenge C1, we are the ﬁrst
to identify dirty road patch as an attack vector in physical-
world adversarial attacks. This design has 2 unique advan-
tages. First, road patches can appear to be legitimately de-
ployed on trafﬁc lanes in the physical world, e.g., for ﬁxing
road cracks. Today, deploying them is made easy with adhe-
sive designs [44] as shown in Fig. 2. The attacker can thus
take time to prepare the attack in house by carefully printing
the malicious input perturbations on top of such adhesive
road patches, and then pretend to be road workers like those
in Fig. 2 to quickly deploy it when the target road is the most
vacant, e.g., in late night, to avoid drawing too much attention.
Second, since it is common for real-world roads to have dirt
or white stains such as those in Fig. 2, using similar dirty pat-
terns as the input perturbations can allow the malicious road
patch to appear more normal and thus stealthier. To mimic
the normal dirty patterns, our design only allows color per-
turbations on the gray scale, i.e., black-and-white. To avoid
changing the lane information as discussed in §3.3, in our
design we (1) require the original lane lines to appear ex-
actly the same way on the malicious patch, if covered by the
patch, and (2) restrict the brightness of the perturbations to
be strictly lower than that of the original lane lines. To further
improve stealthiness, we also design parameters to adjust the
perturbation size and pattern, which are detailed in §4.3.3.
So far, none of the popular production ALC systems today
such as Tesla, GM, etc. [7, 45] identify roads with such dirty
road patches as driving scenarios that they do not handle,
which can thus further beneﬁt the attack stealthiness.
Motion model based input generation. To address the
strong inter-dependencies among the camera frames (C2),
3312    30th USENIX Security Symposium
USENIX Association
Figure 2: Illustration of our novel and domain-speciﬁc attack
vector: Dirty Road Patch (DRP).
we need to dynamically update the content of later camera
frames according to the vehicle actuation decisions applied at
earlier ones in the attack generation process. Since adversarial
attack generation typically takes thousands of optimization
iterations [46, 47], it is practically highly difﬁcult, if not im-
possible, to drive real vehicles on the target road to obtain
such dynamic frame update in every optimization iteration.
Another idea is to use vehicle simulators [48, 49], but it re-
quires the attacker to ﬁrst create a high-deﬁnition 3D scene of
the target road in the real world, which requires a signiﬁcant
amount of hardware resource and engineering efforts. Also,
launching a vehicle simulator in each optimization iteration
can greatly harm the attack generation speed.
To efﬁciently and effectively address this challenge, we
combine vehicle motion model [36] and perspective transfor-
mation [50] to dynamically synthesize camera frame updates
according to a driving trajectory simulated in a lightweight
way. This method is inspired by Google Street View that syn-
thesizes 360◦ views from a limited number of photos utilizing
perspective transformation. Our method only requires one
trace of the ALC system inputs (i.e., camera frames) from the
target road without attack, which can be easily obtained by
the attacker (§3.2).
Optimization-based DRP generation. To systemati-
cally generate effective malicious patches, we adopt an
optimization-based approach similar to prior works [4, 26].
To address challenge C3, we design a novel lane-bending
objective function as a differentiable surrogate that aims at
changing the derivatives of the desired driving path before
the lateral control module, which is equivalent to change the
steering angle decisions at the lateral control design level. Be-
sides this, we also have other domain-speciﬁc designs in the
optimization problem formulation, e.g., for a differentiable
construction of the curve ﬁtting process, malicious road patch
robustness, stealthiness, and physical-world realizability.
Fig. 3 shows an overview of the malicious road patch gen-
eration process, which is detailed in the following sections.
4.2 Motion Model based Input Generation
In Fig. 3, step 1(cid:13)– 7(cid:13) belong to the motion model based input
generation component. As described earlier in §4.1, the input
to this component is a trace of ALC system inputs such as
camera frames from driving on the target road without attack.
In 1(cid:13), we apply perspective transformation, a widely-used
Figure 3: Overview of our DRP (Dirty Road Patch) attack
method. ROI: Region of Interest; BEV: Bird’s Eye View.
computer vision technique that can project an image view
from a 3D coordinate system to a 2D plane [50, 51]. Specif-
ically, we apply it to the original camera frames from the
driver’s view to obtain their Bird’s Eye View (BEV) images.
This transformation is highly beneﬁcial since it makes our
later patch placement and attack-inﬂuenced camera frame
updates much more natural and thus convenient. We denote
this as Vt := BEV(It ), where It and Vt are the original camera
input and its BEV view respectively at frame t. This process
is inversible, i.e., we can also obtain It with BEV−1(Vt ).
Next, in 2(cid:13), we obtain the generated malicious road patch
image P from the optimization-based DRP generation step
(§4.3) and place it on Vt to obtain the BEV image with the
patch, denoted as(cid:98)Vt := Λ(Vt ,P). To achieve consistent patch
placements in the world coordinate across frames, we calcu-
late the pixel-meter relationship, i.e., the number of pixels per
meter, in BEV images based on the driving trace of the target
road. With this, we can place the patch in each frame precisely
based on the driving trajectory changes across frames.
t − So
t and So
Next, we compute the vehicle moving trajectory changes
caused by the placed malicious road patch, and reﬂect such
changes in the camera frames. We represent the vehicle
moving trajectory as a sequence of vehicle states St :=
[xt ,yt ,βt ,vt ], (t = 1, ...,T ), where xt ,yt ,βt ,vt are the vehicle’s
2D position, heading angle, and speed at frame t, and T is the
total number of frames in the driving trace. Thus, the trajec-
tory change at frame t is δt := Sa
t , where Sa
t are
vehicle states with and without attack respectively.
To calculate δt caused by the attack effect at the frame t−1,
we need to know the attack-inﬂuenced vehicle state Sa
t . To
achieve that, we use a vehicle motion model to simulate the
vehicle state Sa
t by feeding the steering angle decision τt−1
from the lateral control step in the ALC system (§2.1) given
the attacked frame at t − 1 and the previous vehicle state Sa
t−1,
denoted as Sa
t−1,τt−1). A vehicle motion model is
a set of parameterized mathematical equations representing
the vehicle dynamics and can be used to simulate its driving
trajectory given the speed and actuation commands. In this
t := MM(Sa
USENIX Association
30th USENIX Security Symposium    3313
Real-World Road PatchAttacker can pretend to be road workers to deploy the attack using adhesive road patch [51].Dirty Patterns⑦Feed toALCMotion ModelCamera Frames (𝐼!)BEV Images+ Patch (𝑉!#)TransformedCamera Frames     Model Input (𝑋!")AutomatedLane Centering①Transform camera images to BEV images②Place patch ⑤Transform back tocamera view⑥ROI filtering③Simulate vehiclemotion⑧Calculate gradients & update patch④Applytrajectory change(𝐼%!")𝑉"!"𝜏!#$Motion Model BasedInput Generation(  4.2)Patch Image (𝑃)Optimization-Based DRP Generation(  4.3)§§t
process, we set the vehicle speed as the speed limit of the
target road as described in our threat model (§3.2). In our
design, we adopt the kinematic bicycle model [52], which is
the most widely-used motion model for vehicles [52, 53].
BEV image(cid:98)Vt to obtain the attack-inﬂuenced one(cid:98)V a
With δt, in 4(cid:13) we then apply afﬁne transformations on the
:= T ((cid:98)Vt ,δt ). Fig. 4 shows an example of the shifting
as(cid:98)V a
t , denoted
and rotation T (·) in the BEV, which synthesizes a camera
frame with the vehicle position shifted by 1 meter and rotated
by 10◦ to the right. Although it causes some distortion and
missing areas on the edge, the ROI area (red rectangle), i.e.,
the LD model input, is still complete and thus sufﬁcient for
our purpose. Since the ROI area is typically focused on the
center and much smaller than the raw camera frame (§2.1),
our method can successfully synthesize multiple complete
LD model inputs from only 1 ALC system input trace.
Next, in 5(cid:13), we obtain the attack-inﬂuenced camera frame
t := BEV−1((cid:98)V a
t , i.e., the direct input to ALC, by pro-
t ). Next, in 6(cid:13), the ROI
t ). X a
t
t are then fed to ALC system in 7(cid:13) to obtain
t ,Sa
t ).
t+2, ...
one after one until all the original frames are updated to reﬂect
the moving trajectory changes caused by P. These updated
attack-inﬂuenced inputs are then fed to the optimization-based
DRP generation component, which is detailed next.
4.3 Optimization-Based DRP Generation
In Fig. 3, step 8(cid:13) belongs to the optimization-based road
path generation component. In this step, we design a domain-