[30] LIU, K., AND TERZI, E. Towards identity anonymization on
graphs. In Proc. of SIGMOD (2008).
[31] MAHADEVAN, P., KRIOUKOV, D., FALL, K., , AND
VAHDAT, A. Systematic topology analysis and generation
using degree correlations. In Proc. of SIGCOMM (2006).
[32] MCSHERRY, F., AND MAHAJAN, R. Differentially-private
network trace analysis. In Proc. of SIGCOMM (October
2010).
optimal k-anonymity. In Proc. of PODS (2004).
estimator. In Proc. of ICDMW ’09. (December 2009),
pp. 122 –129.
de-anonymization of large sparse datasets. In Proc. of IEEE
S&P (2008).
[36] NARAYANAN, A., AND SHMATIKOV, V. De-anonymizing
social networks. In Proc. of IEEE S&P (2009).
[37] NISSIM, K., RASKHODNIKOVA, S., AND SMITH, A.
Smooth sensitivity and sampling in private data analysis. In
Proc. of STOC (2007).
[38] OLIVEIRA, R. V., ZHANG, B., AND ZHANG, L. Observing
the evolution of internet as topology. In Proc. of SIGCOMM
(2007).
[39] PUTTASWAMY, K. P. N., SALA, A., AND ZHAO, B. Y.
Starclique: Guaranteeing user privacy in social networks
against intersection attacks. In Proc. of ACM CoNEXT
(2009).
aggregation of distributed time-series with transformation
and encryption. In Proc. of SIGMOD (2010).
B. Y. Measurement-calibrated graph models for social
network experiments. In Proc. of WWW (2010).
[33] MEYERSON, A., AND WILLIAMS, R. On the complexity of
[34] MIR, D., AND WRIGHT, R. A differentially private graph
[41] SALA, A., CAO, L., WILSON, C., ZHENG, H., AND ZHAO,
[40] RASTOGI, V., AND NATH, S. Differentially private
[35] NARAYANAN, A., AND SHMATIKOV, V. Robust
93[42] SWEENEY, L. k-anonymity: A model for protecting privacy.
Int. J. Uncertain. Fuzziness Knowl.-Based Syst. 10 (2002),
557–570.
[43] WILSON, C., BOE, B., SALA, A., PUTTASWAMY, K. P. N.,
AND ZHAO, B. Y. User interactions in social networks and
their implications. In Proc. of EuroSys (2009).
privacy via wavelet transforms. IEEE Trans. on Knowledge
and Data Engineering (2010).
[45] ZHELEVA, E., AND GETOOR, L. Preserving the privacy of
sensitive relationships in graph data. In Proc. of PinKDD
(2008), pp. 153–171.
[44] XIAO, X., WANG, G., AND GEHRKE, J. Differential
[46] ZHOU, B., AND PEI, J. Preserving privacy in social
[48] ZOU, L., CHEN, L., AND OZSU, M. T. K-automorphism: A
[47] ZIMMER, M. Facebook data of 1.2 million users from 2005
networks against neighborhood attacks. In Proc. of ICDE
(2008).
released: Limited exposure, but very problematic. Blog,
February 2011. http://michaelzimmer.org.
general framework for privacy preserving network
publication. In Proc. of VLDB (2009).
94Summary Review Documentation for 
“Sharing Graphs Using Differentially Private Graph 
Models” 
Authors: A. Sala, X. Zhao, C. Wilson, H. Zheng, B. Zhao 
Reviewer #1 
Strengths:  Focuses  on  the  important  and  timely  problem  of 
privacy-preserving  graph  anonymization.  This  is  a  very  general 
and interesting problem. The paper proposes a novel approach to 
apply  differential-privacy  concepts  on  graphs.  It  produces 
anonymized  graphs  with  specific  privacy  guarantees.  The 
proposed method is thoroughly analyzed and evaluated. The paper 
is very well written. 
Weaknesses: The evaluation results show that proposed method 
produces  accurate  graphs  mainly  for  weak  privacy  guarantees 
(large \epsilon). 
Comments  to  Authors:  Without  perturbation,  the  output  of  a 
query is the dk-2 distribution. This hides some information about 
the  original  graph,  which  the  presented  approach  ignores.  I 
wonder how much information it hides? Is it possible to quantify 
this? and/or take it into account in the anonymization procedure? 
I understand that in the context of graph an edge corresponds to a 
database record. Should edges not be independent? Edges in real 
graphs are not created independently. The paper is not very clear 
about this point. 
The  paper  misses  perhaps 
(X. 
Dimitropoulos  et  al,  “Graph  Annotations  in  Modeling  Complex 
Network  Topologies”  ACM  Transactions  on  Modeling  and 
Computer Simulation, vol. 19(4), Sep. 2009). This work distills an 
original  graph  to  a  2K-series  representation,  creates  empirical 
models  of  the  2K-series  profile  (unlike  [30]),  generates  a  new 
random  2K-series  statistical  profile  from  the  modeled  2K-
distributions  (effectively  adding  noise),  and  synthesizes  a  graph. 
Combining  the  dk-series  framework  for  graph  anonymization 
makes  sense.  The  original  dk-series  framework  [30]  produces 
synthetic  graphs  that  are  too  similar  to  the  original  graph.  This 
property is useful for privacy-preserving graph publishing. 
I  found  the  notation  in  the  product  of  Theorem  1  somewhat 
cryptic, could not fully parse it. 
The  values  of  \epsilon  for  which  the  authors  get  good  results  in 
Section 5 are very high. 
It  is  not  clear  which  query  model  the  paper  assumes.  Is  the 
interactive query model supported? 
Reviewer #2 
Strengths:  Important  problem,  and  a  good,  first  stab  at  the 
problem (where the problem is sharing graphs in a manner that is 
related  study 
the  most 
goal 
is 
to 
hide 
natural 
another 
private  and  supports  arbitrary  queries,  rather  than  a  few  select 
queries). 
Weaknesses:  1.  The  paper  assumes  that  edges  in  the  graph  is 
what  needs  to  be  private  and  the  methods  do  not  work  if  we 
wanted information about nodes to be private. This assumption is 
fundamental  to  the  work  and,  worse,  it  is  implicit.  There  is  no 
discussion  in  the  paper  why  this  definition  of  privacy  is  an 
appropriate one. 
2.  The  experiments  are  not  stressing  the  scheme  and  should  be 
done differently. Details below. 
Comments  to  Authors:  Let  me  expand  on  the  two  complaints 
above.  
1.  First,  you  are  (implicitly)  assuming  that  what  needs  to  be 
hidden is whether an edge is present or absent in the graph. This is 
a  good  goal,  but  not  the  only  (or  the  most  private)  one.  For 
instance, 
the 
presence/absence/properties of nodes in the graph. Your methods 
do  not  protect  against  attacks  on  node  properties.  To  protect 
against  node-level  attacks,  the  neighboring  graph  would  be  one 
with an extra node added or deleted. It should be apparent that this 
change has way more sensitivity than adding or deleting an edge. 
It would be good to make this point clear in your paper; I believe 
it to be an important distinction. This does not detract from your 
paper but makes it more precise; I think what you are doing is a 
great first step. At the same time, please discuss why you believe 
edge-level privacy to be an appropriate definition. 
2.  Second,  I  thought  several  aspects  of  your  experiments  should 
be done differently: 
 -  The  choices  of  \epsilon  values  are  strange.  What  are  they 
motivated by? My understanding is that \epsilon~10 is considered 
weak, but the lowest you go is 5. It is fine to study higher \epsilon 
values, but you need to study values for the more private end of 
the spectrum as well. 
 - I would like to see results in Sec. 5 for dK-PA as well. Does the 
poor  performance  that  you  show  in  earlier  sections  hinder  it  for 
the metrics in Sec. 5. After all, per measures in Sec. 3 and 4, even 
LDRC is orders of magnitude further away from the ideal. 
- I disagree with how you summarize your experimental findings 
in  Section  5.3.  You  basically  blame  dK-2  series  for  most  of  the 
loss in fidelity that you observe. But it is pretty clear from Figure 
9,  and  to  some  extent  Figure  8,  that  dK  is  not  the  fundamental 
bottleneck.  dK-2  series  itself  is  pretty  close,  but  end-to-end 
measures come close only with very high \epsilon values (100). It 
means that it is the perturbation process that is responsible. 
95this 
is  entirely  due 
than 
\epsilon=100.  If 
That  said,  I  do  like  the  fact  that  in  your  experiments  you  study 
applications that are not perfect matches for LDRC. You should 
just draw the right conclusions from them. 
How  do  you  compute  the  sub-series  in  your  scheme?  What  if 
there are multiple partitions that satisfy your constraints? 
Why  do  you  see  a  non-monotonic  behavior  with  respect  to 
\epsilon  in  Fig.  6a?  The  error  from  the  original  is  greater  for 
\epsilon=10 
to 
randomization,  you  should  be  conducting  multiple  experiments 
and plotting error bars. 
Reflecting  on  DRC  at  a  higher-level,  I  find  it  intriguing  on  two 
counts. First, the trick of partitioning the data and independently 
adding  noise  seems  general  and  might  find  use  in  other  places. 
You may consider highlighting this aspect.  Second, it is also a bit 
counter-intuitive to me. I would have thought that considering the 
entire series would let one add lower noise than adding noise to 
individual  subsets.  This  was  essentially  the  observation  in  [39]. 
But  you  are  going  in  the  opposite  direction.  The  difference 
perhaps  is  that  you  are  able  to  find  “natural”  partitions  of  data. 
But it also suggests to me that better perturbation mechanisms can 
be designed, which treat the whole series together. 
Reviewer #3 
Strengths: Interesting idea.  Seems fairly complete. 
Weaknesses: Impact on end-to-end metrics is not clear.  Unclear 
whether the contributions are only theoretical. Some sloppiness in 
the  techniques.  The  authors  show  that  repeat  queries  cannot  be 
handled  very  well  with  diffPriv.    It  is  unclear  that  distributing 
graphs with noise fits the diffPriv use case, which is more about 
answering some queries than shipping the dataset. 
Comments  to  Authors:  There  is  a  mismatch  between  what 
differential  privacy  provides  -  the  ability  to  respond  to  queries 
without  revealing  anonymity  versus  the  canonical  use  case  with 
measurement datasets which involves releasing the dataset. I did 
not see a way of reconciling that in this paper. 
DiffPriv  also  has  a  problem  dealing  with  succession  of  queries.  
They  typically  operate  with  a  privacy  budget,  each  answered 
query uses up part of it. Once budget is depleted, no more queries 
can be supported on the dataset without leaking information. How 
does the use case here work around this concern? 
I  see  that  theoretically  the  amount  of  noise  injected  is  lower 
O(d_max^4/\epsilon^2) to about O(d_max^3 / \epsilon^2) but I do 
not see the impact on stats that matter. For example, the results in 
Section 5 do not compare with dk-PA, the technique that injects 
noise as per standard diffPriv. For Fig. 4, I cannot really tell why 
'distance' is a good metric.  Employ something that users may care 
about, and show how the accuracy of that maps onto 'distance'. 
The  required  amount  of  privacy  parameter,  \epsilon,  impacts 
results. \epsilon=100 is great, others not so good.  In Fig. 5, the 
distributions are far even when the X axes is on a log scale.  How 
does a user choose \epsilon?  How exactly is an \epsilon = 5 better 
in terms of privacy than \epsilon = 100?  The loss in accuracy is 
clear but the gains in terms of privacy not. 
What about the AS graph makes it much harder to keep accurate? 
for e.g.,  at \epsilon=100, the accuracy is quite poor. 
dK-Graph  model:  For  network  topology  aspects,  this  is  a  good 
model.    Is  there  nothing  in  the  social  graph  that  goes  beyond 
topology  of  the  friend  graph?  Metadata?  Group  memberships?  
Activity?  (When  is  she  online  more  often?  Does  he  play 
farmville?) Correlation in activity?   
Theorem 1 seems more of a sufficient than a necessary condition.  
\sigma is not E[Lap(...)] which by definition is zero.  
Error  analysis,  the  lower  bound  seems  impossible,  i.e.,  the 
minimum value of 1.  
It is unclear if the L2 minimization works across partitions, as it 
does in the vanilla case.  
Sec. 5: it is not clear until the end of Sec. 5.1 that by dK you mean 
dK-2, which loses a lot of fidelity (Fig. 7). Use dK-3 instead? 
Reviewer #4 
Strengths:  Anonymization  is  a  useful  tool.  We  lack  as  many 
datasets  in  this  domain  as  we  would  like  because  commercial 
interests prevent them being shared. 
Weaknesses: The obsession of graph theorists with node degree 
is really damaging to networking research. It is not clear that node 
degree sequences really tell us anything we need to know about 
data networks, or that the node-degree sequence approach really 
does what it claims to do. 
Comments to Authors: A lot of this paper is based on statements 
in [30]. I never found that that paper convincingly showed that the 
ensemble  of  graphs  it  generated  were  (i)  meaningfully  different 
from  the  graphs  that  they  came  from  (two  graphs  that  differ  by 
two  edits  can  easily  be  homomorphic  -  are  they  then  usefully 
different); and (ii) showed that the resulting graphs were similar in 
any sense except those related to node degree.   
It  may  naively  seem  that  both  problems  cannot  be  true,  because 
they are almost the opposite problem. However, the problems can 
be different for different instantiations. For instance, for either the 
clique, or graph with no edges, all possible graphs with identical 
node  degree  distribution  are  the  same.  On  the  other  hand,  we 
know from the work of Willinger et al that graphs with identical 
degree  distributions  can  be  quite  different  in  nature.  Adding 
higher order degree sequences does not fix this. So we could have 
a mapping that for some graphs just creates what are effectively 
homomorphisms, and for others, creates a range of graphs that are 
in no useful sense similar to the original.  
What is the worst case for this algorithm in both senses? Does it 
fail to anonymise for some cases, and fail to produce meaningful 
information  in  others?  Limiting  to  dK-2  introduces  similar 
questions. Adding noise complicates the matter further. 
The graph datasets lack the types of labels that would make them 
interesting  for  many  practical  problems,  e.g.,  link  capacity, 
policies  and  so  on.  Most  of  the  graph  datasets  have  substantial 
errors. What is the effect of errors in the initial measurements? 
As the framework is defined in terms of a particular set of queries, 
why not just distribute the results of the query on the graph? We 
do not know that the technique will work for other queries, so we 
96cannot just blindly apply them when we come to another graph. If 
the dK sequence is so important, why generate alternative graphs 
at all: just give people the dK sequence and let them work with it. 
Reviewer #5 
Strengths:  -  Addresses  an  important  and  difficult  problem  with 
some novel angle and non-trivial observation.  
-  combines  design  with  concrete  validation  that  provides  more 
ground (even if it does not close the topic). 
Weaknesses: - The reader should be ready to accept semi-proof 
and  lack  of  complete  rigorous  formal  model  and  proof,  for  the 
sake of exposition of interesting observations. 
- Limitations are severe (only releasing k=2 reduces the k series to 
its  single  most  expression:  assortativity).  The  extension  is 
conceptually  interesting  but  far  from  being  as  attainable  as  the 
authors say. 
-  The  levels  of  privacy  proposed  are  not  ready  for  prime  time. 
Most  \epsilon-differential  privacy  work  recommends  \epsilon  at 
most 0.1 this paper considers the parameter between 5 and 100! 
Comments to Authors: I think this is an interesting candidate for 
publication. The use of dk series seems promising to address the 
need to manipulate realistic graphs, this paper is making one step 
for it. This has potential to impact an important problem.  
We are far from a contribution solidly written in the marble given 
the choices made by the authors in terms of high \epsilon and a 
rather poor exposition of the methods, which seem to follow more 
high-level intuition than precise first principles. Nevertheless the 
point that partitioning improves sensitivity and brings guarantee is 
a good catch, and the paper makes the case serious. 
p.1 “We take a different approach to address the above question, 
by making the observation” the current claim of ownership of this 
observation is strange. This tension is the very much at the core of 
much research including k-anonymity, differential privacy. 
The  limitation  of  k=2  might  appear  a  bit  hard  to  swallow  after 
such  a  grand  claim.  I  still  think  it  is  an  interesting  step  because 
that is the way to go. Who knows how sensitivity behave for k=3 
and if any partitioning make sense. 
“In  contrast,  our  goal  is  to  inject  changes  into  all  aspects  of  the 
graph  topology,  instead  of  focusing  on  a  single  graph  metric.” 
You do not reproduce all aspects, and you will likely never. You 
propose  to  recover  what  the  dk  series  can  obtain,  starting  with 
k=2. It does already make your approach original (and promising) 
but stating it so broadly is a countersense. 
“Unfortunately, the author asserts there are incorrect results in the 
paper 1.” This is perhaps unfortunate but it does not explain how 
your  method  is  intrinsically  better.  It  would  much  stronger  to 
highlight the difference first and then mention this point. 
Lemma  1  is  a  partial  result.  You  only  provide  an  upper  bound, 
which does not prove that the real sensitivity is necessarily high. 
The statement of error measure is very vague. How does random 
noise alter the actual structure of the graph? 
Please  clarify  what  happens  between  clusters?  Are  the  data  lost 
with some forms of random generation of links between them? 
Have you ever seen a single paper advocating \epsilon between 5 
and 100? You are essentially saying the users “Do not worry, your 
chance  of  being  identified  by  joining  the  database  are  only 
multiplied  between  148  and  about  10^43”.  What  kind  of 
guarantee is that? 
Response from the Authors  
We  thank  the  reviewers  for  their  insightful  comments.    Several 
comments were results of ambiguous text in the paper, which we 
have  addressed  by  clarifying  our  claims  and  assumptions  and 
providing deeper explanations of our findings.  In particular, we 
explain  that  the  omission  of  the  dK-PA  was  simply  because  it 
generated so much noise that the dK-generator failed to generate 
matching  graphs.    Two  additional  key  points  stood  out  in  the 
comments, and we address them in detail below. 
First, on the issue of dK-2 as a graph statistical representation, we 
modified  text  to  more  clearly  explain  the  advantages  and  the 
limitations of our choice.  We explain that we require a statistical 
representation  of  a  graph  that  can  be  converted  to  and  from  an 
unique  graph.  The  dK-series  is  ideal  for  this.    We  use  the  dK-2 
series,  because  it  is  the  most  detailed  dK-series  that  has  a 
corresponding  graph  generator  (e.g.  there  is  currently  no  known 
dK-3  series  graph  generator  that  works  on  large  graphs).  While 
the choice of dK-2 limits the accuracy of our current model, our 
methodology  is  general,  and  can  be  used  with  higher  order  dK-
series when their generators are discovered (e.g. we are currently 
working on developing a scalable dK-3 generator).  It is possible 
that  providing  privacy  on  higher  order  dK-series  may  require 
more severe noise, which could consequently destroy their higher 
accuracy. Therefore, our conclusion is that higher order dK-series 
will  become  a  practical  solution  only  if  we  are  able  to  preserve 
their  accuracy  through  the  perturbation  process  and  when  a 
generator will be invented. 
Second,  we  address  via  text  edits  questions  on  the  choice  of 
\epsilon:  smaller  \epsilon  indicates  stronger  privacy.  We  use 
moderate to high values of \epsilon in our tests for two reasons. 
One, we wanted to find the \epsilon value that contributes to the 
smallest noise such that it produces a graph statistically similar to 
the synthetic dK-2 graph with no privacy. Thus we can indirectly 
quantify the level of privacy inherent in a synthetic graph without 
additional  privacy  constraints.  We  show  that  this  property  is 
achieved  when  \epsilon  is  equal  to  $100$.  In  addition,  the  dK-2 
series is a very sensitive function and naturally requires high level 
of  noise  to  guarantee  strong  privacy.  Our  primary  goal  was  to 
identify  the  feasibility  of  this  approach,  and  leave  further 
optimizations  to  achieve  high  fidelity  graphs  for  lower  \epsilon 
values as goals for future work. 
97