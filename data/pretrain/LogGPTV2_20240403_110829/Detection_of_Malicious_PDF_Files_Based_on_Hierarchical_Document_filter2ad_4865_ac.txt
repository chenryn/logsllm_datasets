### Nonlinear Transformation and Support Vector Machines (SVMs)

Support Vector Machines (SVMs) utilize a nonlinear transformation to map input data into a feature space with special properties, known as the Reproducing Kernel Hilbert Space (RKHS). The elegance of SVMs lies in their ability to perform this transformation implicitly through the selection of an appropriate nonlinear kernel function \( k(x_1, x_2) \), which compares two examples \( x_1 \) and \( x_2 \).

The solution \(\alpha\) to the dual SVM learning problem, equivalent to the primal solution \( w \), can be used to define a nonlinear decision function. This function is expressed as a comparison of an unknown example \( x \) with selected examples \( x_i \) from the training data, known as "support vectors" (highlighted with black circles in Figure 4):

\[ y(x) = \sum_{i \in SV} \alpha_i k(x, x_i) - \rho \]

**Figure 4. Linear and Nonlinear SVM**

Efficient implementations of SVM learning are available in various machine learning packages, including WEKA and SHOGUN. In our experiments, we used the well-known stand-alone SVM implementation, LibSVM.

### 5. Experimental Evaluation

#### 5.1 Experimental Dataset

The quality of the dataset is crucial for inferring meaningful models and for a robust evaluation of any data-driven approach. For our evaluation, we collected a total of 658,763 benign and malicious PDF files (approximately 595 GB). The dataset was sourced from Google and VIRUSTOTAL, an online service that scans uploaded files for viruses using multiple antivirus programs. Our dataset includes the following six datasets:

- **D1: VIRUSTOTAL Malicious (March 2012)**: 38,207 (1.4 GB) malicious PDF files, labeled by at least 5 antiviruses.
- **D2: VIRUSTOTAL Malicious (May-June 2012)**: 11,409 (527 MB) malicious PDF files, labeled by at least 5 antiviruses.
- **D3: VIRUSTOTAL Benign (March 2012)**: 79,200 (75 GB) benign PDF files, labeled by all antiviruses.
- **D4: Google Benign (February 2007 - July 2012)**: 90,384 (73 GB) benign PDF files, obtained from 1,000 Google searches.
- **D5: Operational Malicious (July-October 2012)**: 32,526 (2.7 GB) malicious PDF files, labeled by at least 5 antiviruses.
- **D6: Operational Benign (July-October 2012)**: 407,037 (443 GB) benign PDF files, labeled by all antiviruses.

The VIRUSTOTAL data includes PDF files used globally, providing a realistic representation of private PDF data. The benign VIRUSTOTAL data is slightly biased towards being suspicious, as users typically upload files they find dubious. The Google-sourced data reduces this bias and aims to capture the characteristics of an average benign PDF file on the internet.

We consider a VIRUSTOTAL file to be malicious only if it was labeled as such by at least 5 antiviruses. Files labeled malicious by 1 to 4 AVs were excluded due to low confidence in their labeling.

#### 5.2 Experimental Protocol

Two types of experiments were conducted to evaluate the detection performance of our method: laboratory and operational experiments.

**Laboratory Experiments:**
- **Standard Experiment**: Evaluates overall effectiveness using D1 (malicious) and D4 (benign).
- **Suspicious Experiment**: Evaluates performance on files that users do not trust, using D1 (malicious) and D3 (benign).
- **WithJS Experiment**: Compares our method to PJSCAN using a subset of D1 and D4 containing JavaScript-embedded files.

**Operational Experiments:**
- **Novel Experiment**: Evaluates performance on new malicious threats using models trained on D1 and tested on D2.
- **10Weeks Experiment**: Evaluates real-world performance over 14 weeks, retraining models weekly on recent data.

#### 5.3 Experimental Results

Both the decision tree learning algorithm and SVM were evaluated in the laboratory experiments. For the SVM, we used the radial basis function (RBF) kernel with \(\gamma = 0.0025\) and cost parameter \( C = 12 \).

**5.3.1 Standard Experiment**

Table 1 shows the aggregated results of the Standard experiment, including confusion matrices and performance indicators.

| Metric | Decision Tree | SVM |
|--------|---------------|-----|
| True Positives | 38,102 | 38,163 |
| False Positives | 51 | 10 |
| True Negatives | 90,783 | 90,824 |
| False Negatives | 105 | 44 |
| True Positive Rate | 0.99725 | 0.99885 |
| False Positive Rate | 0.00056 | 0.00011 |
| Detection Accuracy | 0.99879 | 0.99958 |

**5.3.2 Suspicious Experiment**

Table 2 shows the aggregated results of the Suspicious experiment, indicating a slight decrease in performance compared to the Standard experiment.

| Metric | Decision Tree | SVM |
|--------|---------------|-----|
| True Positives | 38,118 | 38,163 |
| False Positives | 68 | 27 |
| True Negatives | 79,132 | 79,173 |
| False Negatives | 89 | 44 |
| True Positive Rate | 0.99767 | 0.99885 |
| False Positive Rate | 0.00086 | 0.00034 |
| Detection Accuracy | 0.99866 | 0.99939 |

**Figure 5. Comparison of Our Method to Commercial Antivirus Engines**

Our method, using both decision trees and SVM, outperformed 43 commercial antivirus engines in terms of true positive rates. Up to 30 antivirus engines missed at least 15% of the threats.

This comprehensive evaluation demonstrates the effectiveness and operational applicability of our proposed method under real-world conditions.