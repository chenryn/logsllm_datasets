title:On the feasibility of inference attacks by third-party extensions
to social network systems
author:Seyed Hossein Ahmadinejad and
Philip W. L. Fong
On the Feasibility of Inference Attacks by Third-Party
Extensions to Social Network Systems
Seyed Hossein Ahmadinejad
Department of Computer Science
University of Calgary
Calgary, Alberta, Canada
PI:EMAIL
Philip W. L. Fong
Department of Computer Science
University of Calgary
Calgary, Alberta, Canada
PI:EMAIL
ABSTRACT
Social Network Systems (SNSs) providers allow third-party
extensions to access users’ information through an Applica-
tion Programming Interface (API). Once an extension has
been authorized by a user to access data in a user’s pro-
ﬁle, there is no more control on how that extension uses the
data. This raises serious concerns about user privacy be-
cause a malicious extension may infer some private informa-
tion based on the legitimately accessible information. This
information leakage is called an inference attack. In addi-
tion, inference attacks are not only a privacy violation, they
could also be used as the building blocks for more danger-
ous security attacks, such as identity theft. In this work, we
conduct a comprehensive empirical study to assess the fea-
sibility and accuracy of inference attacks that are launched
from the extension API of SNSs. We also discuss an attack
scenario in which inference attacks are employed as building
blocks. The signiﬁcance of this work is in thoroughly dis-
cussing how inference attacks could happen in practice via
the extension API of SNSs, and highlighting the clear and
present danger of even the naively crafted inference attacks.
Categories and Subject Descriptors
K.4.1 [Computers and Society]: Public Policy Issues—
Privacy; K.6.5 [Management of Computing and In-
formation Systems]: Security and Protection—Invasive
software
Keywords
Social networks; Privacy; Inference attacks
1.
INTRODUCTION
Third-party applications are a popular feature of SNSs.
For instance, there are applications with more than 50M
monthly active users on the Facebook platform. Third-party
developers host their Facebook applications on their own
(untrusted) servers. Such applications then interact with
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIA CCS’13, May 8–10, 2013, Hangzhou, China.
Copyright 2013 ACM 978-1-4503-1767-2/13/05 ...$15.00.
users and access their personal information through an API.
Every access request sent by an application via an API call is
guarded by a permission check. If the permission is granted
by the user, the data will be sent to the application.
Problem deﬁnition.
Not all third-party applications are benign. For example,
a malicious application may sell user information to mar-
keting companies. As a result, delivering user data via the
extension API to such applications puts the data at risk.
While this problem has to do with the misuse of legitimately
accessible information, this work is instead about a more
challenging problem: i.e., through the extension API, mali-
cious applications may gain access to private information for
which they are not authorized. The following is an example.
Example 1. In a Facebook user proﬁle is a “ wall” on which
the user or her friends may post status updates, photos, mes-
sages, etc. Now, a malicious third-party application asks for
the permission to access the wall. Say the permission is
granted by the user. The application accesses the user’s wall
through the extension API, and then scans the wall for a
day when a considerable number of birthday greetings were
posted. The application can thus infer the user’s birthday.
In the above example, if the individual considers her birth-
day as private information (and thus should be inaccessible),
then the malicious application has eﬀectively inferred some
supposedly inaccessible information about the user from the
information that is accessible through the extension API.
Note that an application may also have access to some in-
formation about an individual outside the SNS. So it might
utilize such information in inferring the individual’s inacces-
sible information. We use the term SNS API inference
attacks to refer to the inference of inaccessible information
from both accessible information and background informa-
tion. The term highlights the fact that this work focuses on
inference attacks that are launched by extensions to SNSs
through the extension API. Our emphasis on the role of
third-party extensions in launching inference attacks diﬀer-
entiates us from other related work on generic inference at-
tacks over social network data sets [6, 5, 3].
Signiﬁcance of the problem.
A naive interlocutor may argue that the above issue has
already been addressed by the permission-based access con-
trol mechanism, in that third-party extensions cannot access
user information without seeking the required permissions.
If a user does not trust a third-party application, then she
shall not authorize it. This argument presumes that ordi-
nary users have the necessary information and expertise to
judge whether the applications they subscribe to are benign.
In reality, most of the third-party applications are developed
by developers who are not widely known to the user commu-
nity. It is therefore not always possible for a user to assess
if she can trust an application.
One may also claim that SNS API inference attacks are
but another minor privacy violation. We disagree for two
reasons. First, analyzing the threats of any security concern
must be accompanied by assessing the number of potential
victims. When the number of potential victims reaches, for
example, 50M, then we are facing a trouble with costly con-
sequences. Popular Facebook applications have 50M monthly
users, implying that an inference attack with a meagre suc-
cess rate of 10% leads to privacy violations of 5M victims.
Second, SNS API inference attacks can be employed as
building blocks for conducting more dangerous security at-
tacks. For instance, an alternative authentication mecha-
nism is to ask users security questions (e.g., “what is the
name of your youngest sibling?”). Answers to these secu-
rity questions can usually be harvested systematically by
launching SNS API inference attacks. The ability to an-
swer a victim’s security questions is the ﬁrst step of identity
theft. Therefore, inference attacks could be an initial step
in the launching more dangerous attacks. Now, who is best
positioned to launch covert inference attacks? The answer
is third-party extension developers.
Contributions.
The speciﬁc contributions of this work are the following:
• By way of a comprehensive empirical study (Section
3), we develop deep insight into the problem of SNS
API inference attacks, and demonstrate the growing
threat of such attacks to user privacy.
• We devised an analytical framework for evaluating the
risk of SNS API inference attacks. A key component of
our framework is the classiﬁcation of user proﬁles into
four categories from the perspective of an adversary
(Section 4). Based on this classiﬁcation, we devised a
scoring technique for assessing the success rate of in-
ference algorithms (Section 6). The insights we gained
can inform the design of protection mechanisms for
mitigating the threat of SNS API inference attacks.
Our analytical methodology can be applied for ana-
lyzing SNS API inference attacks not covered in this
work.
• Eight (8) realistic inference algorithms are devised for
our empirical study, covering a wide variety of infer-
ence techniques and inference channels. This diversity
of inference techniques improves our understanding of
the threat of SNS API inference attacks (Section 5).
• We examine a scenario, namely, identity theft, in which
SNS API inference attacks are used as building blocks
of more dangerous security attacks (Section 7). We
formally model the success rate of this attack, with
the success rates of the component SNS API inference
attack algorithms as model parameters. We then feed
our empirical data into the model to obtain the suc-
cess rate of the identity theft attack. This modelling
exercise oﬀers an innovative means for demonstrating
the threat of SNS API inference attacks.
In this work, we mainly focus on Facebook, the most popular
SNS. However, our observations regarding Facebook third-
party applications also apply to other extensible SNSs (e.g.,
OpenSocial).
2. SNS API INFERENCE ATTACKS
In a typical SNS, every user owns a proﬁle consisting
of attributes such as birthdate, education information, etc.
Permission-based authorization schemes allow users to re-
strict access to their attributes. Therefore, a third-party
application that needs to access a user’s attributes needs to
request the user for granting the required permissions.
A user can also permit an application to access certain in-
formation that she does not own. Speciﬁcally, given that the
required conditions are satisﬁed, a user can allow an applica-
tion to access her friend’s photo albums. In such cases, the
user who runs the application assumes the role of a proxy
through whom the application accesses the friend’s proﬁle.
An application can access the friend’s information if the fol-
lowing conditions are met: (i) the proxy user grants indirect
access to the application; (ii) the friend grants permissions
to the proxy user for accessing the requested information;
(iii) the friend explicitly allows her information to be acces-
sible by applications through proxy users.
Suppose a user u subscribes to a third-party application
π in an SNS. As a result, in her interactions with π, the
SNS makes some information accessible to π (aka accessi-
ble information), given that the required permissions are
granted. Such accessible information may contain informa-
tion about users other than u (e.g., u’s friends). Moreover,
there might be some personal information about u (aka in-
accessible information) that she intends not to share with
π. Such an intention is sometimes declared explicitly in her
privacy settings, but sometimes implicitly willed by her. π
may also have some background information regarding
u. Now a successful SNS API inference attack launched by
π against u is deﬁned as follows: π infers some inaccessible
information about u from its background information as well
the accessible information it could obtain in its interaction
with u from the SNS API. The inferred information must
not be inferable solely from π’s background information.
As we want to focus on the role of third-party extensions
in launching inference attacks, we give the above deﬁnition
to emphasize that the user’s accessible information through
the SNS API must be utilized for inferring information. Note
also that π complies with the protection mechanisms of the
target SNS, by accessing nothing but the legitimately ac-
cessible information. Yet, the protection mechanisms fail to
prevent inference of inaccessible information.
The deﬁnition above does not cover inference attacks that
infer information about friends of the user who runs the ap-
plication. Our goal is to show that, even by considering only
such limited attacks, the damages can still be signiﬁcant.
3. EMPIRICAL STUDY: DESIGN
This section reports the design of an empirical study we
conducted to assess the feasibility of SNS API inference at-
tacks. For the purpose of this study, we identiﬁed eight
sample inference tasks and devised an inference algorithm
for each task. Each inference algorithm takes as input some
accessible information, carries some background information
that it employs for inference, and infers some targeted in-
accessible information. As mentioned previously, inference
attacks can be employed as building blocks for other at-
tacks such as identity theft. We therefore evaluated the
success rate of these inference algorithms with this appli-
cation in mind. Speciﬁcally, an attacker is usually allowed
to make some α attempts for each security question, before
the authentication mechanism blocks oﬀ the attacker (where
α > 1). Therefore, each of our algorithms will return α an-
swers, corresponding to the number of attempts the attacker
is allowed to make. We set α = 4 in our study.
A third-party Facebook application (coded in JavaScript)
was developed as an environment for simulation and data
collection. Embedded in the application are our inference
algorithms that were executed on the participants’ proﬁles.
To achieve 95% conﬁdence level and 5% margin of error, we
recruited 424 participants (according to [4], 384 participants
are required) from 150 universities across North America.
An execution of this application involves the following
steps. First, the participant selects a subset of the eight
sample inference algorithms to be included in the simula-
tion. Then, the application asks the participant to grant the
permissions needed for setting up the accessible information
of the selected inference algorithms. The application sim-
ulates the accessing of the accessible information, and the
running of the inference algorithms. Each algorithm infers
up to α answers for each of the inference tasks. Next, for
each selected inference task, if the corresponding inference
algorithm is able to infer at least one answer, then the an-
swers is presented to the participant, in the order of con-
ﬁdence of the algorithm. The participants are to conﬁrm
which answer is the right answer, or to declare that none
of the answers is correct. In summary, the execution of an
inference algorithm could lead to three possible outcomes:
1) no answer is returned, 2) none of the returned answers
is correct, or 3) one of the returned answers is correct. The
ﬁrst two outcomes simply mean algorithm failure.
that a friend grants to the user running the applica-
tion, as well as the permissions that friends can specify
regarding which attributes can be accessed by applica-
tions through proxy users1.
We specify below a scheme for classifying user proﬁles.
Corresponding to each class of user proﬁles is a predicate.
Deﬁnition 1. A user proﬁle j is type-1 accessible to
algorithm i (accessible1 (i, j) = 1) iﬀ the type-1 permissions
requested by algorithm i have been granted by user j.
Deﬁnition 2. A user proﬁle j is type-2 accessible to al-
gorithm i (accessible2 (i, j) = 1) iﬀ accessible1 (i, j) = 1 and
the type-2 permissions required by algorithm i are granted by
at least one of the friends of user j.
For example, suppose algorithm i, executing on user j’s
proﬁle, needs to access user j’s friends’ photo albums. User
j’s proﬁle is type-2 accessible for algorithm i if photo albums
of at least one of her friends is accessible to algorithm i.
Deﬁnition 3. A user proﬁle j is available to algorithm i
(available(i, j) = 1) iﬀ accessible2 (i, j) = 1 and algorithm
i could at least return one answer when it is executed on
user proﬁle j. In other words, the required data for making
a guess is both accessible and available.
Deﬁnition 4. A user proﬁle j is applicable for algorithm
i (applicable(i, j) = 1) iﬀ available(i, j) = 1 and the infor-
mation algorithm i attempts to infer is logically deﬁned for
user j. That is, it is not a logical impossibility for algorithm
i to infer the target information from the user j’s proﬁle.
For instance, if an individual is single, then it is a logi-
cal impossibility for an inference algorithm to infer his/her
spouse’s name. So this individual’s proﬁle is not applicable
for this speciﬁc algorithm.
We deﬁne below a predicate pertinent to the success scor-
4. ANALYTICAL FRAMEWORK
ing of an inference algorithm.
In this section, we describe our analytical framework based
on which we analyze the behaviour of our inference algo-
rithms. When we assess the success rate of inference algo-
rithms, there is more than one reason for an algorithm to
fail. For example, sometimes the data needed by an algo-
rithm to make inference is not available, and at other times
the data is available but the algorithm cannot gain access
to that data. For each inference algorithm, we classify user
proﬁles based on the level of availability of the information
that the algorithm needs to extract from the proﬁle in order
to make correct inference. In essence, this classiﬁcation cor-
responds to the diﬀerent reasons for inference failure. For
each algorithm, we will deﬁne a diﬀerent success rate when
each of the failure conditions is ruled out.
In Facebook, there are two types of access permissions
involved in user-application interactions:
1. Type-1 permissions: These are permissions that are
granted or denied by the user who is running the ap-
plication. They include the permissions to access the
user’s attributes, as well as the permissions to access
the attributes of the user’s friends.
• succeed (i, j, α): This binary predicate evaluates to 1
iﬀ, when algorithm i is executed on user proﬁle j, the
correct answer of the inference task is among the ﬁrst
α candidate answers returned by algorithm i.
We propose here four diﬀerent success rates for evaluat-
ing the eﬀectiveness of an inference algorithm in target-
ing the diﬀerent classes of user proﬁles. Table 1 shows
the formulas for the success rates of algorithm i. Here,
N is the total number of user proﬁles on which algorithm
i was executed. For every proﬁle class and for every α,
we deﬁne a diﬀerent success rate. For example, P i
ava(α)
is the ratio of available proﬁles for which algorithm i suc-
cessfully returned the right answer in at most α attempts.
Note that the four success rates are totally ordered:
i.e.
P i
app (α). Note also that
the success rates in Table 1 are conditional probabilities.
acc1 (α) ≤ P i
acc2 (α) ≤ P i
ava (α) ≤ P i
5.
INFERENCE ALGORITHMS
This section presents a brief description of the inference
strategy in the eight sample inference algorithms. In all of
2. Type-2 permissions: These are permissions that are
granted or denied by the friends of the user who is
running the application. They include the permissions
1Recall from Section 2 that when an application accesses
a friend attribute, both type-1 and type-2 permissions are
needed.
Success rate
Formula
Type-1 Accessibility
Type-2 Accessibility
Availability
Applicability
acc1 (α) = PN
j=1 succeed (i, j, α)
P i
PN
j=1 accessible1 (i, j)
acc2 (α) = PN
j=1 succeed (i, j, α)
P i
PN
j=1 accessible2 (i, j)