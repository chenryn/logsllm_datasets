On another side, some distributed systems are made up
of computers that communicate through a network of at-
tached disks. These disks constitute a storage area network
(SAN) that implements a shared memory abstraction. As
commodity disks are cheaper than computers, such archi-
tectures are becoming more and more attractive for achiev-
ing fault-tolerance. The (cid:0) algorithms presented in this pa-
per are suited to such systems [9].
Related work As far as we know, a single shared
memory (cid:0) algorithm has been proposed so far [13]. This
algorithm considers that the underlying system satisﬁes the
there is a time (cid:0) after
following behavioral assumption:
which there are a lower bound and an upper bound for
any process to execute a local step, or a shared memory
access. This assumption deﬁnes an eventually synchronous
shared memory system. It is easy to see that it is a stronger
assumption than the assumption previously deﬁned here.
bounds on process speeds and message transfer delays, but
these bounds are not known and hold only after some ﬁnite
but unknown time. The algorithms implementing (cid:0) in such
“augmented” asynchronous systems are based on timeouts
(e.g., [1, 19]). They use successive approximations to even-
tually provide each process with an upper bound on trans-
fer delays and processing speed. They differ mainly on the
“quantity” of additional synchrony they consider, and on the
message cost they require after a leader has been elected.
Among the protocols based on this approach, a protocol
presented in [1] is particularly attractive, as it considers a
relatively weak additional synchrony requirement. Let t be
an upper bound on the number of processes that may crash
( (cid:3) t (cid:1) n, where n is the total number of processes). This
assumption is the following: the underlying asynchronous
system, which can have fair lossy channels, is required to
have a correct process p that is a t-source. This means
that p has t output channels that are eventually timely: there
is a time after which the transfer delays of all the messages
sent on such a channel are bounded (let us notice that this
is trivially satisﬁed if the receiver has crashed). Notice that
such a t-source is not known in advance and may never
be explicitly known. It is also shown in [1] that there is no
leader protocol if the system has only (cid:1)t (cid:4) (cid:2)-sources. A
versatile adaptive timer-based approach has been developed
in [21].
The message pattern-based approach, introduced in [22],
does not assume eventual bounds on process and communi-
cation delays. It considers that there is a correct process p
and a set Q of t processes (with p (cid:2) Q, moreover Q can
contain crashed processes) such that, each time a process
q  Q broadcasts a query, it receives a response from p
among the ﬁrst (cid:1)n (cid:4) t(cid:2) corresponding responses (such a re-
sponse is called a winning response). It is easy to see that
this assumption does not prevent message delays to always
increase without bound. Hence, it is incomparable with the
synchrony-related t-source assumption. This approach
has been applied to the construction of an (cid:0) algorithm in
[24].
A hybrid algorithm that combines both types of assump-
tion is developed in [25]. More precisely, this algorithm
considers that each channel eventually is timely or satisﬁes
the message pattern, without knowing in advance which as-
sumption it will satisfy during a particular run. The aim
of this approach is to increase the assumption coverage,
thereby improving fault-tolerance [26].
The implementation of (cid:0) in asynchronous message-
passing systems is an active research area. Two main ap-
proaches have been been investigated: the timer-based ap-
proach and the message pattern-based approach.
The timer-based approach relies on the addition of tim-
ing assumptions [5]. Basically, it assumes that there are
Roadmap The paper is made up of 5 sections. Section
2 presents the system model and the additional behavioral
assumption. Then, Sections 3 and 4 present in an incremen-
tal way the two algorithms implementing an (cid:0) oracle, and
show they are optimal with respect to the number of pro-
cesses that have to write or read the shared memory. Finally,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:55 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Section 5 provides concluding remarks.
Due to page limitation, the proofs of some lemmas and
theorems are omitted. The reader can ﬁnd them in [6].
2 Base Model, Eventual Leader and
Additional Behavioral Assumption
2.1 Base asynchronous shared memory model
The system consists of n, n (cid:3) , processes denoted
p(cid:4) (cid:5) (cid:5) (cid:5) (cid:4) pn. The integer i denotes the identity of pi. (Some-
times a process is also denoted p, q or r.) A process can
fail by crashing, i.e., prematurely halting. Until it possi-
bly crashes, a process behaves according to its speciﬁcation,
namely, it executes a sequence of steps as deﬁned by its al-
gorithm. After it has crashed, a process executes no more
steps. By deﬁnition, a process is faulty during a run if it
crashes during that run; otherwise it is correct in that run.
There is no assumption on the maximum number t of pro-
cesses that may crash, which means that up to n (cid:4)  process
may crash in a run.
The processes communicate by reading and writing
a memory made up of atomic registers (also called
shared variables in the following). Each register is one-
writer/multi-reader (1WnR). “1WnR” means that a single
process can write into it, but all the processes can read it.
(Let us observe that using 1WnR atomic registers is par-
ticularly suited for cached-based distributed shared mem-
ory.) The only process allowed to write an atomic register is
called its owner. Atomic means that, although read and write
operations on the same register may overlap, each (read or
write) operation appears to take effect instantaneously at
some point of the time line between its invocation and re-
turn events (this is called the linearization point of the op-
eration) [17]. Uppercase letters are used for the identiﬁers
of the shared registers. These registers are structured into
arrays. As an example, PROGRESS (cid:6)i(cid:7) denotes a shared
register that can be written only by pi, and read by any pro-
cess.
Some shared registers are critical, while other shared
registers are not. A critical register is a an atomic register on
which some constraint can be imposed by the additional as-
sumptions that allow implementing an eventual leader. This
attribute allows restricting the set of registers involved in
these assumptions.
A process can have local variables. They are denoted
with lowercase letters, with the process identity appearing
as a subscript. As an example, candidatesi denotes a local
variable of pi.
This base model is characterized by the fact that there is
no assumption on the execution speed of one process with
respect to another. This is the classical asynchronous crash
prone shared memory model. It is denoted AS n(cid:6)(cid:6)(cid:7) in the
following.
2.2 Eventual leader service
The notion of eventual leader oracle has been informally
presented in the introduction. It is an entity that provides
each process with a primitive leader(cid:1)(cid:2) that returns a process
identity each time it is invoked. A unique correct leader is
eventually elected but there is no knowledge of when the
leader is elected. Several leaders can coexist during an ar-
bitrarily long period of time, and there is no way for the
processes to learn when this “anarchy” period is over. The
leader oracle, denoted (cid:0), satisﬁes the following property
[4]:
(cid:1) Validity: The value returned by a leader(cid:1)(cid:2) invocation
is a process identity.
(cid:1) Eventual Leadership3: There is a ﬁnite time and
a correct process pi such that, after that time, every
leader(cid:1)(cid:2) invocation returns i.
(cid:1) Termination: Any leader(cid:1)(cid:2) invocation issued by a cor-
rect process terminates.
The (cid:0) leader abstraction has been introduced and for-
mally developed in [4] where it is shown to be the weakest,
in terms of information about failures, to solve consensus
in asynchronous systems prone to process crashes (assum-
ing a majority of correct processes). Several (cid:0)-based con-
sensus protocols have been proposed (e.g., [11, 18, 23] for
message-passing systems, and [8] for shared memory sys-
tems)4.
2.3 Additional behavioral assumption
Underlying intuition As already indicated, (cid:0) cannot
be implemented in pure asynchronous systems such as
AS n(cid:6)(cid:6)(cid:7). So, we consider the system is no longer fully asyn-
chronous: its runs satisfy the following assumption denoted
AWB (for asymptotically well-behaved). The resulting sys-
tem is consequently denoted AS n(cid:6)AWB(cid:7).
Each process pi is equipped with a timer denoted timeri.
The intuition that underlies AWB is that, once a process p(cid:0)
is deﬁned as being the current leader, it should not to be
demoted by a process pi that believes p(cid:0) has crashed. To that
end, constraints have to be deﬁned on the behavior of both
p(cid:0) and pi. The constraint on p(cid:0) is to force it to “regularly”
inform the other processes that it is still alive. The constraint
on a process pi is to prevent it to falsely suspect that p(cid:0) has
crashed.
There are several ways to deﬁne runs satisfying the pre-
vious constraints. As an example, restricting the runs to
3This property refers to a notion of global time. This notion is not
accessible to the processes.
4It is important to notice that, albeit it can be rewritten using (cid:0) (ﬁrst
introduced in 1992), the original version of Paxos, that dates back to 1989,
was not explicitly deﬁned with this formalism. The ﬁrst paper where Paxos
is explained as an (cid:0)-based algorithm is [2].
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:55 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007be “eventually synchronous” would work but is much more
constraining than what is necessary. The aim of the AWB
additional assumption is to state constraints that are “as
weak as possible”5. It appears that requiring the timers to
be eventually monotonous is stronger than necessary (as we
are about to see, this is a particular case of the AWB as-
sumption). The AWB assumption is made up of two parts
AWB  and AWB  that we present now. AWB  is on the
existence of a process whose behavior has to satisfy a syn-
chrony property. AWB  is on the timers of the other pro-
cesses. AWB  and AWB  are “matching” properties.
The assumption AWB  The AWB  assumption requires
that eventually a process does not behave in a fully asyn-
chronous way. It is deﬁned as follows.
AWB : There are a time (cid:0) , a bound (cid:3), and a
correct process p(cid:0) ((cid:0) , (cid:3) and p(cid:0) may be never
explicitly known) such that, after (cid:0) , any two
consecutive write accesses issued by p(cid:0) to (its
own) critical registers, are completed in at most
(cid:3) time units.
This property means that, after some arbitrary (but ﬁnite)
time, the speed of p(cid:0) is lower-bounded, i.e., its behavior
is partially synchronous (let us notice that, while there is a
lower bound, no upper bound is required on the speed of p(cid:0),
except the fact that it is not (cid:8)).
The assumption AWB 
In order to deﬁne AWB , we
ﬁrst introduce a function f (cid:1)(cid:2) with monotonicity properties
that will be used to deﬁne an asymptotic behavior. That
function takes two parameters, a time (cid:0) and a duration x,
and returns a duration. It is deﬁned as follows. There are
two (possibly unknown) bounded values xf and (cid:0)f such
that:
(cid:1) (f1) (cid:0)(cid:4) (cid:0) (cid:9) (cid:0) (cid:9) (cid:0) (cid:9) (cid:0)f , x(cid:4) x (cid:9) x (cid:9) x (cid:9) xf :
f (cid:1)(cid:0)(cid:4) x(cid:2) (cid:9) f (cid:1)(cid:0)(cid:4) x(cid:2). (After some point, f (cid:1)(cid:2) is not
decreasing with respect to (cid:0) and x).
(cid:1) (f2) limx(cid:0)(cid:3) f (cid:1)(cid:0)f (cid:4) x(cid:2) (cid:4) (cid:8). (Eventually, f (cid:1)(cid:2) al-
ways increases6.)
We are now in order to deﬁne the notion of asymptoti-
cally well-behaved timer. Considering the timer timeri of