# An Experimental Evaluation to Determine if Port Scans are Precursors to an Attack

**Authors:**
- Susmit Panjwani
- Stephanie Tan
- Keith M. Jarrin
- Michel Cukier

**Affiliation:**
Center for Risk and Reliability, Department of Mechanical Engineering, University of Maryland, College Park, MD 20742, USA

**Emails:**
- {spanjwan, sjt, kmj, mcukier}@umd.edu

## Abstract

This paper presents an experimental approach to determine the correlation between port scans and subsequent attacks. The security community often posits that port scans should be considered precursors to attacks, but few studies have quantitatively validated this hypothesis. In this study, attack data were collected using a dedicated test-bed for monitoring attackers. The data included port scans, ICMP scans, vulnerability scans, successful attacks, and management traffic. Two experiments were conducted to validate the hypothesis by linking port scans and vulnerability scans to the number of packets observed per connection. Customized scripts were developed to filter and group the collected data based on scans and attacks between source and destination IP address pairs. The correlation of the filtered data groups was then assessed. The analyzed data encompassed forty-eight days of data collection from two target computers on a heavily utilized subnet.

## 1. Introduction

Traditional approaches to security validation have not been quantitative, focusing instead on specifying procedures to be followed during system design (e.g., the Security Evaluation Criteria [1, 2]). When quantitative methods have been used, they have typically been very formal (e.g., [3]), aiming to prove that certain security properties hold given a specified set of assumptions, or quite informal, using a team of experts (often called a “red team,” [4]) skilled in the practice of security and with complete knowledge of the system being studied.

An alternative approach, which has received less attention, is to quantify the behavior of an attacker and their impact on the system's ability to provide security-related properties. Goseva-Popstojanova et al. [5] presented a model of an intrusion-tolerant system using a state transition diagram. Jha et al. [6] combined modeling, formal logic, and a Bayesian analysis approach. Ortalo et al. [7] modeled the system as a privilege graph, similar to the scenario graph in [6]. By combining the privilege graph with assumptions about attacker behavior, the authors obtained an attack state graph. A variable called "effort" was introduced to characterize the ease or difficulty of reaching a given privilege level, and the mean effort to security failure (METF) was estimated based on experimental data.

This paper focuses on assessing a specific attacker behavior based on experimental data. Specifically, it estimates the correlation between a port scan and an attack. Such estimates can be used in one of the previously mentioned models for quantifying security. We describe a test-bed using target computers for monitoring attackers and collecting attack data. Various scripts were developed to filter and analyze the data. Each step taken to filter the original traffic (consisting of management and malicious activity) into various scans and attacks directed at the target computers is described. The classification into scans and attacks is based on the number of packets per connection. Two experiments were conducted to indicate the relevance of such classification. The correlation between scans and attacks was studied by first focusing on the scans and identifying if attacks followed them, and then analyzing the attacks and identifying those preceded by a scan.

The paper is organized as follows. Section 2 defines the different types of scans considered: port scans, ICMP scans, and vulnerability scans. Section 3 reviews the literature on port scan characterization and filtering. Section 4 describes the test-bed used for the experiment. Section 5 details additional experiments to better characterize two types of scans. Section 6 covers the filtering and analysis of the collected data. Finally, Section 7 presents the results on the correlation between scans and attacks.

## 2. Definitions

In the introduction, we used the term "port scan" as a general term for "checking for an exploitable target." Here, we present more precise definitions of the different scans discussed in this paper. A scan is a reconnaissance technique where the attacker tries to determine information about the target host, such as whether the host is alive, what services are running, the operating system, and the presence of exploitable vulnerabilities. The types of scans considered in this paper are ICMP scans, port scans, and vulnerability scans.

- **ICMP Scan:** Used to check the availability of a target machine and to fingerprint the target operating system. It uses ICMP control messages and provides less information compared to port or vulnerability scans.
- **Port Scan:** Used to check for open or closed ports and for used or unused services. The services may or may not have a vulnerability that the attacker could exploit. The implementation of the TCP/IP stack is operating system dependent, allowing the attacker to use this information to fingerprint the target operating system.
- **Vulnerability Scan:** Used to fingerprint the presence or absence of an exploitable vulnerability. Since vulnerabilities differ, techniques to fingerprint them will also differ, making it difficult to develop a generic algorithm to detect them.

## 3. Related Work

Most related work on port scans focuses on characterizing and filtering them from network traffic. Intrusion detection systems like Snort [9] and BRO [10] detect port scans based on models that look for IP addresses making more than X connections in Y seconds. NSM [11] uses a similar algorithm that checks for source IP addresses making connections to more than fifteen other hosts. GrIDS [12] creates activity graphs representing aggregated network activity, where nodes represent hosts and edges represent connections or traffic. GrIDS analyzes these graphs to detect large-scale attacks. Anomaly-based approaches, such as Emerald [13], construct statistical profiles for subjects and match short-term weighted profiles to long-term weighted profiles. Port scans are detected as a sudden increase in SYN traffic from a single source IP address. Ertoz et al. [14] use a heuristic-based approach to develop algorithms and techniques to determine source IP addresses of port scans with fewer false positives.

Apart from port scan detection, some work exists on characterizing the distribution of scan types in traffic generated on a production sub-network [15] and in radiated traffic (i.e., sent to non-existent IP addresses) [16]. Lee et al. [15] classified port scans based on the number of hosts and ports scanned by the source host in a given amount of time.

Some case studies analyzing attacks and scans are available in [17, 18]. These case studies focused on specific exploits, detailing how the vulnerability was probed and exploited by describing the different steps of the attack. These examples are based on forensics to understand step-by-step how the target computers were compromised.

## 4. Experimental Setup

The experimental test-bed is based on target computers built solely for the purpose of being attacked. Other computers closely monitor these target computers, but attackers do not notice that they are observed. This architecture allows for:

1. Collecting data at the host, application, and network levels.
2. Filtering user traffic from attacker traffic.
3. Correlating data collected at the host and network level.
4. Controlling the target computers from an isolated monitoring network.

Since there are no real users on the target computers, there is no concern associated with filtering user traffic from attack traffic. This approach also avoids the issue of storing large amounts of data since no user traffic data is collected.

This architecture is similar to the one developed by the Honeynet project [18], but we use different tools for data collection and monitoring. For example, we use Ethereal instead of tcpdumps due to its better graphical and analysis capabilities, correlation scripts instead of the honeynet management console, and Snort for event alerting. Additionally, a data filtering module, an image control module, and a data correlation module have been developed. The experimental results provided in this paper are based on the test-bed shown in Figure 1, consisting of two target computers.

### Functional Descriptions of Components

- **Access Control:** This module restricts the propagation of attacks from the target computers by using a reverse firewall, where outbound connections are monitored instead of inbound connections. Customized firewall scripts were developed to limit attackers from initiating outbound connections while allowing the data collection engine to send data securely to the management network. The scripts were developed on the IPTables firewall running on Linux RedHat 9.
- **Data Collection:** This module collects real-time data at the network, host, and application levels. Data in the format of tcpdumps are collected using Ethereal [20]. The data are uploaded every six hours to a database located on the test-bed, using MySQL version 4 as a buffer for temporary data storage. These data are then uploaded daily to a centralized database running Oracle 9i. Customized Perl scripts were developed to parse the data into the Oracle database.
- **Event Logging:** This sub-module aids data storage by collecting and storing system, application, and security logs. Syslog data are collected using 'syslogd' running on Fedora Core 1. As with the data collected in the data collection module, these logs are uploaded every six hours to a database using MySQL version 4. Finally, these data are uploaded each day to a centralized database using Oracle 9i.
- **Event Alerting:** This module alerts the research team about any attacker activity and system failures, requiring immediate administrative response. These alerts can also be used for forensic purposes to understand data and event interactions in sequence. We use Swatch [21] to monitor syslog data and allow for Snort [9] alerts in real-time. Swatch runs on RedHat 9 and uses sendmail.
- **Image Control:** This module controls the deployment and maintenance of current versions of operating systems, applications, and patches on the target machines. It also allows re-imaging the target computers in case of corruption. We use Ghost Enterprise version 8 developed by Symantec [22].
- **Data Filtering:** This module filters out management traffic generated on the network from the collected traffic. The resulting traffic thus only consists of malicious activity. The filtering is done at multiple stages in the data collection and analysis process and is detailed in Section 6.
- **Data Correlation:** This module analyzes the filtered data to produce the results given in Sections 6 and 7 using Perl and PL/SQL scripts on an Oracle database.

## 5. Port Scans and Vulnerability Scans

As mentioned in Section 4, the data collected consists of management traffic and malicious activity, as no "normal" user was using either of the two target computers. The malicious traffic includes port scans, vulnerability scans, and attacks. To improve data analysis, we conducted two experiments to better characterize port scans and vulnerability scans.

### 5.1 Characterization of Port Scans

According to [8], three packets are sufficient to finish a TCP handshake and establish a connection. Information about open ports and services can be gathered using as few as two packets. To corroborate these specifications experimentally and to evaluate the distribution of port scans, we developed an experiment based on a well-known network scanner.

Specifically, we used an isolated network consisting of two computers. On one computer, we ran the network scanner Nmap version 3.75 for Windows [23]. On the other computer, we recorded all the packets going through the network using the network protocol analyzer Ethereal version 0.10.7 [20]. We ran all the different basic types of port scans available in Nmap and used Ethereal to capture, measure, and group the connections based on the number of packets. The results of the number of packets per connection and the number of connections associated with a given number of packets when running Nmap are provided in Figure 2. Note that we did not observe any connection with some specific number of packets (e.g., 5, 6, 10, 11). From Figure 2, over 19,946 (i.e., 99.76%) port scans consist of two packets per connection, 19,961 (i.e., 99.83%) port scans consist of three or fewer packets per connection, and 19,971 (i.e., 99.88%) port scans consist of four or fewer packets per connection. These results show that five packets per connection can be used as a threshold to characterize port scans. This threshold is confirmed in theory since full TCP handshakes consist of three packets, and a fourth packet is included as a possible reset packet.

| No. of Packets in Connection | No. of Connections | Percentage of Connections |
|-----------------------------|--------------------|---------------------------|
| 2                           | 19,946             | 99.76%                    |
| 3                           | 15                 | 0.075%                    |
| 4                           | 10                 | 0.05%                     |
| 7                           | 2                  | 0.01%                     |
| 8                           | 4                  | 0.02%                     |
| 9                           | 10                 | 0.05%                     |
| 12                          | 1                  | 0.005%                    |
| 17                          | 1                  | 0.005%                    |
| 18                          | 1                  | 0.005%                    |
| 21                          | 1                  | 0.005%                    |
| 33                          | 3                  | 0.015%                    |
| Total                       | 19,994             | 100%                      |

### 5.2 Characterization of Vulnerability Scans

Since the collected traffic data include attacks and vulnerability scans besides ICMP and port scans, we analyzed vulnerability scans to see if the number of packets could also be used for characterization. Therefore, we ran NeWT 2.1 [24], a Windows version of Nessus, to generate CSV files containing the scan results. The analysis of these scans will be detailed in the following sections.