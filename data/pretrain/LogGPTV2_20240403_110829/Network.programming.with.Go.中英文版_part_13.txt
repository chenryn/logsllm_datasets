The encoding extends to strings of characters. A word-length even parity encoding
of "ABC" might be 10000000 (parity bit in high byte) 0100000011 (C) 01000010 (B)
01000001 (A in low byte). The comments about the importance of an encoding apply
equally strongly to strings, where the rules may be different.
把字符编码扩展到字符串。一个字节宽、带有奇偶校验的“ABC”编码为10000000（高位奇偶校验）
0100000011（C）01000010（B）01000001（A 在低位）。对于编码在字符串上的讨论也很重要，
虽然编码规则可能不同。
Transport encoding
编码传输
A character encoding will suffice for handling characters within a single application.
However, once you start sending text between applications, then there is the further
issue of how the bytes, shorts or words are put on the wire. An encoding can be based
on space-and hence bandwidth-saving techniques such as zip'ping the text. Or it could
be reduced to a 7-bit format to allow a parity checking bit, such asbase64.
某个应用程序的字符编码只要内部能处理字符串就足够了。然而，一旦你需要在不同应用程序之间交
互，那怎么编码可就成了需要进一步讨论问题了：字节、字符、字是怎么传输的。字符编码可能有很
多空白字符（待商议），从而可以使用如zip算法对文本进行压缩，从而节省带宽。或者，它可以减
少到7 位字节，奇偶校验位，使用 base64编码来代替。
If we do know the character and transport encoding, then it is a matter of programming
to manage characters and strings. If we don't know the character or transport encoding
then it is a matter of guesswork as to what to do with any particular string. There
is no convention for files to signal the character encoding.
如果我们知道的字符编码和传输编码，那么问题就成了如何通过编程处理字符和字符串；如果我们不
知道字符编码和传输编码，那么如何猜到某个特定字符串的编码方式就是大问题。因为没有约定发送
文件的字符编码
There is however a convention for signalling encoding in text transmitted across
the internet. It is simple: the header of a text message contains information about
the encoding. For example, an HTTP header can contain lines such as
不过，在互联网上传输文本的编码是有约定的。很简单：文本消息头包含的编码信息。例如，HTTP
报头可以包含这么几行，如
Content-Type: text/html; charset=ISO-8859-4
Content-Encoding: gzip
which says that the character set is ISO 8859-4 (corresponding to certain countries
in Europe) with the default encoding, but then gziped. The second part - content
encoding - is what we are referring to as "transfer encoding" (IETF RFC 2130).
上面是说，将字符集是ISO 8859-4（对应到欧洲的某些国家）作为默认编码，然后用 gzip压缩。
内容类型的第二部分就是我们指的是“传输编码”（IETF RFC2130）。
But how do you read this information? Isn't it encoded? Don't we have a chicken and
egg situation? Well, no. The convention is that such information is given in ASCII
(to be precise, US ASCII) so that a program can read the headers and then adjust
its encoding for the rest of the document.
但是，怎么读懂这个信息呢？它没有编码？这不就是先有鸡还是先有蛋的问题么？嗯，不是的。按照
惯例，这样的信息使用ASCII 编码（准确地说，美国ASCII），所以程序可以读取headers，然后
适配其文档的其余部分的编码。
6.3 ASCII ASCII 编码
ASCII has the repertoire of the English characters plus digits, punctuation and some
control characters. The code points for ASCII are given by the familiar table
ASCII 字符集包含的英文字符、数字，标点符号和一些控制字符。 下面这张熟悉的表给出了ASCII
字符编码值
Oct Dec Hex Char Oct Dec Hex Char
------------------------------------------------------------
000 0 00 NUL '\0' 100 64 40 @
001 1 01 SOH 101 65 41 A
002 2 02 STX 102 66 42 B
003 3 03 ETX 103 67 43 C
004 4 04 EOT 104 68 44 D
005 5 05 ENQ 105 69 45 E
006 6 06 ACK 106 70 46 F
007 7 07 BEL '\a' 107 71 47 G
010 8 08 BS '\b' 110 72 48 H
011 9 09 HT '\t' 111 73 49 I
012 10 0A LF '\n' 112 74 4A J
013 11 0B VT '\v' 113 75 4B K
014 12 0C FF '\f' 114 76 4C L
015 13 0D CR '\r' 115 77 4D M
016 14 0E SO 116 78 4E N
017 15 0F SI 117 79 4F O
020 16 10 DLE 120 80 50 P
021 17 11 DC1 121 81 51 Q
022 18 12 DC2 122 82 52 R
023 19 13 DC3 123 83 53 S
024 20 14 DC4 124 84 54 T
025 21 15 NAK 125 85 55 U
026 22 16 SYN 126 86 56 V
027 23 17 ETB 127 87 57 W
030 24 18 CAN 130 88 58 X
031 25 19 EM 131 89 59 Y
032 26 1A SUB 132 90 5A Z
033 27 1B ESC 133 91 5B [
034 28 1C FS 134 92 5C \ '\\'
035 29 1D GS 135 93 5D ]
036 30 1E RS 136 94 5E ^
037 31 1F US 137 95 5F _
040 32 20 SPACE 140 96 60 `
041 33 21 ! 141 97 61 a
042 34 22 " 142 98 62 b
043 35 23 # 143 99 63 c
044 36 24 $ 144 100 64 d
045 37 25 % 145 101 65 e
046 38 26 & 146 102 66 f
047 39 27 ' 147 103 67 g
050 40 28 ( 150 104 68 h
051 41 29 ) 151 105 69 i
052 42 2A * 152 106 6A j
053 43 2B + 153 107 6B k
054 44 2C , 154 108 6C l
055 45 2D - 155 109 6D m
056 46 2E . 156 110 6E n
057 47 2F / 157 111 6F o
060 48 30 0 160 112 70 p
061 49 31 1 161 113 71 q
062 50 32 2 162 114 72 r
063 51 33 3 163 115 73 s
064 52 34 4 164 116 74 t
065 53 35 5 165 117 75 u
066 54 36 6 166 118 76 v
067 55 37 7 167 119 77 w
070 56 38 8 170 120 78 x
071 57 39 9 171 121 79 y
072 58 3A : 172 122 7A z
073 59 3B ; 173 123 7B {
074 60 3C  176 126 7E ~
077 63 3F ? 177 127 7F DEL
The most common encoding for ASCII uses the code points as 7-bit bytes, so that the
encoding of 'A' for example is 65.
最常见的ASCII 编码使用7 位字节，所以A 的码是 65。
This set is actually US ASCII. Due to European desires for accented characters, some
punctuation characters are omitted to form a minimal set, ISO 646, while there are
"national variants" with suitable European characters. The
page http://www.cs.tut.fi/~jkorpela/chars.html by Jukka Korpela has more
information for those interested. We shall not need these variants though.
这个字符集是实际的美国ASCII。鉴于欧洲需要处理重音字符，于是省略一些标点字符，形成一个最
小的字符集，ISO 646，同时有合适的欧洲本国字符的“国家变种字符集”。有兴趣的可以看看 Jukka
Korpel 的这个网页http://www.cs.tut.fi/〜jkorpela/ chars.html。当然我们并不需要这些
变种。
6.4 ISO 8859 ISO 8859 字符集
Octets are now the standard size for bytes. This allows 128 extra code points for
extensions to ASCII. A number of different code sets to capture the repertoires of
various subsets of European languages are the ISO 8859 series. ISO 8859-1 is also
known as Latin-1 and covers many languages in western Europe, while others in this
series cover the rest of Europe and even Hebrew, Arabic and Thai. For example, ISO
8859-5 includes the Cyrillic characters of countries such as Russia, while ISO 8859-8
includes the Hebrew alphabet.
8 进制是字节的标准长度。这使得 ASCII 可以有128 个额外的编码。 ISO 8859 系列的字符集可以
包含众多的欧洲语言字符集。。 ISO 8859-1 也被称为Latin-1，覆盖了许多在西欧国家的语言，
同时这一系列的其他字符集包括欧洲其他国家，甚至希伯来语，阿拉伯语和泰语。例如，ISO 8859-5
包括使用斯拉夫语字符的俄罗斯等，而ISO 8859-8 则包含希伯来文字母。
The standard encoding for these character sets is to use their code point as an 8-bit
value. For example, the character 'Á' in ISO 8859-1 has the code point 193 and is
encoded as 193. All of the ISO 8859 series have the bottom 128 values identical to
ASCII, so that the ASCII characters are the same in all of these sets.
这些字符集使用8 进制作为标准的编码格式。例如，在ISO 8859-1 字符' 'Á'的字符编码为193，
同时被编码为193。所有的ISO 8859 系列前128 个保持和ASCII 相同的值，所以，ASCII字符在
所有这些集合都是相同的。
The HTML specifications used to recommend the ISO 8859-1 character set. HTML 3.2
was the last one to do so, and after that HTML 4.0 recommended Unicode. In 2010 Google
made an estimate that of the pages it sees, about 20% were still in ISO 8859 format
while 20% were still in ASCII ("Unicode nearing 50% of the web"
http://googleblog.blogspot.com/2010/01/unicode-nearing-50-of-web.html).
HTML 语言规范曾经推荐ISO 8859-1 字符集，不过HTML3.2 之后的规范就不再推荐，4.0 开始推荐
Unicode 编码。2010 年 Google 通过它抓取的网页做出了一个估算，20%的网页使用ISO 8859 编码，
20%使用ASCII（unicode 接近50%，
http://googleblog.blogspot.com/2010/01/unicode-nearing-50-of-web.html）
6.5 Unicode Unicode 编码
Neither ASCII nor ISO 8859 cover the languages based on hieroglyphs. Chinese is
estimated to have about 20,000 separate characters, with about 5,000 in common use.
These need more than a byte, and typically two bytes has been used. There have been
many of these two-byte character sets: Big5, EUC-TW, GB2312 and GBK/GBX for Chinese,
JIS X 0208 for Japanese, and so on. These encodings are generally not mutually
compatable.
ASCII 和ISO 8859 都不能覆盖象形文字。中文大约有 20000 个独立的字符，其中5000 个常用字符。
这些字符需要不知一个字节，基本上双字节都会被用上。也有一些多字节的编码：中文的Big5,
EUC-TW, GB2312 和GBK/GBX，日文的 JIS X 0208，等等。这些编码通常是不兼容的
Unicode is an embracing standard character set intended to cover all major character
sets in use. It includes European, Asian, Indian and many more. It is now up to version
5.2 and has over 107,000 characters. The number of code points now exceeds 65,536,
that is. more than 2^16. This has implications for character encodings.
Unincode 是一个受到拥护的字符集编码标准，旨在统一主要使用的编码。它包含了欧洲文字、亚洲
文字和印度文字等。现在Unicode已经到了5.2的版本，包含107,0000个字符。编码字符超过65536，
也就是2^16。这已经覆盖了整个编码。
The first 256 code points correspond to ISO 8859-1, with US ASCII as the first 128.
There is thus a backward compatability with these major character sets, as the code
points for ISO 8859-1 and ASCII are exactly the same in Unicode. The same is not
true for other character sets: for example, while most of the Big5 characters are
also in Unicode, the code points are not the same. The page
http://moztw.org/docs/big5/table/unicode1.1-obsolete.txt contains one example of
a (large) table mapping from Big5 to Unicode.
(Unicode 编码)前256 个编码对应 ISO 8859-1，同时前128 个也是美式ASCII 编码。所以主流的
编码都是相互兼容的，ISO 8859-1、ASCII 和Unicode 是一样的。对其他字符集则不一定正确：例
如，虽然Big5 编码也在Unicode 中，但他们的编码值并不相同。
http://moztw.org/docs/big5/table/unicode1.1-obsolete.txt 这个页面就是证明：一张
Big5 到Unicode 的大的映射表。
To represent Unicode characters in a computer system, an encoding must be used. The
encoding UCS is a two-byte encoding using the code point values of the Unicode
characters. However, since there are now too many characters in Unicode to fit them
all into 2 bytes, this encoding is obsolete and no longer used. Instead there are:
为了在计算机系统中表示Unicode 字符，必须使用一个编码方案。UCS 编码使用两个字节来编码一
个字符值。然而，Unicode 现在有太多的字符需要对应到双字节的编码。以下方案是替代原来陈旧的
编码方案的：
 UTF-32 is a 4-byte encoding, but is not commonly used, and HTML 5 warns
explicitly against using it
 UTF-16 encodes the most common characters into 2 bytes with a further 2 bytes
for the "overflow", with ASCII and ISO 8859-1 having the usual values
 UTF-8 uses between 1 and 4 bytes per character, with ASCII having the usual
values (but not ISO 8859-1)
 UTF-7 is used sometimes, but is not common
 UTF-32 使用4 个字节编码，但是已经不在推荐，HTML5 甚至严重警告反对使用
 UTF-16 是最常见的，它通过溢出两个字节来处理ASCII 和ISO 8859-1 外的字符
 UTF-8 每个字符使用1 到4 个字节，所以ASCII 值不变，但ISO 8859-1的值会变化
 UTF-7 有时会用到，但不常见
6.6 UTF-8, Go and runes UTF-8, Go 语言和 runes
UTF-8 is the most commonly used encoding. Google estimates that 50% of the pages
that it sees are encoded in UTF-8. The ASCII set has the same encoding values in
UTF-8, so a UTF-8 reader can read text consisting of just ASCII characters as well
as text from the full Unicode set.
UTF - 8 是最常用的编码。谷歌估计它抓取的网页有 50%使用UTF-8 编码。ASCII 字符集具有相同
的在UTF-8 中编码值相同，所以UTF-8 的读取方法可以用Unicode 字符集读取一个ASCII 字符组成
的网页。
Go uses UTF-8 encoded characters in its strings. Each character is of type rune.
This is a alias for int32 as a Unicode character can be 1, 2 or 4 bytes in UTF-8
encoding. In terms of characters, a string is an array of runes.
Go 语言使用UTF-8 编码字符串。每个字符类型都是rune。rune是 int32的一个别名，因为 Unicode
编码可以是1,2 或4 个字节。字符和字符串其实都是一个 runes 的数组
A string is also an array of bytes, but you have to be careful: only for the ASCII
subset is a byte equal to a character. All other characters occupy two, three or
four bytes. This means that the length of a string in characters (runes) is generally
not the same as the length of its byte array. They are only equal when the string
consists of ASCII characters only.
Unicode 中一个字符串其实是一个字节数组，但是你要注意：只有 ASCII 这个字符集是一个字节等
于一个字符。所有其他字符占用2 个，三个或四个字节。这意味着，一个字符串的长度（runes）通
常是不一样的长度的字节数组。他们只有在全是ASCII 字符是才相同。
The following program fragment illustrates this. If we take a UTF-8 string and test
its length, you get the length of the underlying byte array. But if you cast the
string to an array of runes []rune then you get an array of the Unicode code points
which is generally the number of characters:
下面的程序片段可以说明这些。如果我们使用utf-8 来检验它的长度，你只会得到它字符层面的长
度。但如果你把字符串转换成rues 数组[]rune，你就等到一个Unicode 编码的数组：
str := "百度一下，你就知道"
println("String length", len([]rune(str)))
println("Byte length", len(str))
prints
输出为
String length 9
Byte length 27
UTF-8 client and server
UTF-8 编码的客户端和服务端
Possibly surprisingly, you need do nothing special to handle UTF-8 text in either
the client or the server. The underlying data type for a UTF-8 string in Go is a
byte array, and as we saw just above, Go looks after encoding the string into 1,
2, 3 or 4 bytes as needed. The length of the string is the length of the byte array,
so you write any UTF-8 string by writing the byte array.
可能令人惊讶的是，无论是客户端或服务器你不需要对utf-8 的文本做任何特殊的处理。UTF-8 字
符串的数据类型是一个字节数组，如上所示。Go 语言自动处理编码后的字符串是 1，2，3 或4 个字
节。所以utf-8 的字符串你可以随便写。
Similarly to read a string, you just read into a byte array and then cast the array
to a string using string([]byte). If Go cannot properly decode bytes into Unicode
characters, then it gives the Unicode Replacement Character \uFFFD. The length of
the resulting byte array is the length of the legal portion of the string.
类似于读取字符串，只要读入一个字节数组，然后使用string([]byte)将数组转换成一个字符串。
如果Go 语言不能正确解码，将字节转换为Unicode 字符，那么它给使用Unicode 替换字符\uFFFD。
生成的字节数组的长度是有效字符串的长度。
So the clients and servers given in earlier chapters work perfectly well with UTF-8
encoded text.
所以前面章节中提到的客户端和服务端使用uft-8 编码表现的很好
ASCII client and server
ASCII 编码的客户端和服务器
The ASCII characters have the same encoding in ASCII and in UTF-8. So ordinary UTF-8
character handling works fine for ASCII characters. No special handling need to be
done.
ASCII 字符的ASCII 编码和UTF-8 编码的值相同，所以普通的UTF-8 字符能正常处理ASCII字符，
不需要做任何特殊的处理。
6.7 UTF-16 and Go Go 语言和 utf-16
UTF-16 deals with arrays of short 16-bit unsigned integers. The package utf16 is
designed to manage such arrays. To convert a normal Go string, that is a UTF-8 string,
into UTF-16, you first extract the code points by coercing it into a []rune and then
use utf16.Encode to produce an array of type uint16.
utf-16 编码可以用16 位字节无符号整形数组处理。 utf16 包就是用来处理这样的字串的。将一个
Go 语言的utf-8 正常编码的字串转换 utf-16 的编码，你应先将字串转换成[]runerune 数组，然后
使用 utf16.Encode 生成一个 uint16类型的数组。
Similarly, to decode an array of unsigned short UTF-16 values into a Go string, you
use utf16.Decode to convert it into code points as type []rune and then to a string.
The following code fragment illustrates this
同样，解码一个无符号短整型的 utf-16 数组成一个Go 字符串，你需要 utf16.Decode将编码转换成
[]rune ，然后才能改成一个字符串。如下面的代码所示：
str := "百度一下，你就知道"
runes := utf16.Encode([]rune(str))
ints := utf16.Decode(runes)
str = string(ints)
These type conversions need to be applied by clients or servers as appropriate, to
read and write 16-bit short integers, as shown below.
类型转换需要客户端和服务器在合适的时机读取和写入16 位的整数，如下图所示。（……图呢？）
Little-endian and big-endian
Little-endian 和big-endian
Unfortunately, there is a little devil lurking behind UTF-16. It is basically an
encoding of characters into 16-bit short integers. The big question is: for each
short, how is it written as two bytes? The top one first, or the top one second?
Either way is fine, as long as the receiver uses the same convention as the sender.
然而，UTF-16 编码潜藏着一个小的恶魔。它基本上是一个16 字节字符编码。最大的问题是：每一
个短字，是如何拼写的？高位在前还是高位在后？无论哪种方式，只要是发生器和接收器约定好就可
以。
Unicode has addressed this with a special character known as the BOM (byte order
marker). This is a zero-width non-printing character, so you never see it in text.
But its value 0xfffe is chosen so that you can tell the byte-order:
Unicode 通过一个特殊字节标记了寻址方式，这个字节就被称为BOM（字节顺序标记）。这是一个零
宽度非打印字符，所以你永远不会在文本中看到它。但是它通过0xFFFE 的值，可以告诉你编码的顺
序
 In a big-endian system it is FF FE
 In a little-endian system it is FE FF
 在big-endian 系统中，它是FF FE
 在little-endian 系统中，它是FE FF
Text will sometimes place the BOM as the first character in the text. The reader
can then examine these two bytes to determine what endian-ness has been used.
有时BOM 会位于文本的第一个字符。文本被读入是可以检查，以确定使用的是那种系统。
UTF-16 client and server
UTF-16 编码的客户端和服务器
Using the BOM convention, we can write a server that prepends a BOM and writes a
string in UTF-16 as
根据BOM 的约定，服务器可以预先设置BOM 来表示utf-16,如下
/* UTF16 Server
*/
package main
import (
"fmt"
"net"
"os"
"unicode/utf16"
)
const BOM = '\ufffe'
func main() {
service := "0.0.0.0:1210"
tcpAddr, err := net.ResolveTCPAddr("tcp", service)
checkError(err)
listener, err := net.ListenTCP("tcp", tcpAddr)
checkError(err)
for {