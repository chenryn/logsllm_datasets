We now discuss how our linearization design yields oblivious
code and data access traces. For code accesses, PC-security follows
by CFL construction, as we removed conditional branches, loops
see a fixed number of iterations (we discuss wrong trip count pre-
dictions later), and IR normalization handles abort-like sequences.
For data accesses, we wrapped load and store operations with DFL
machinery that strides portions of every abstract (i.e., by alloca-
tion site) object that the operation may access, independently of the
incoming pointer value. For dynamic storage, for any two secrets,
the program will see identical object collections to maintain at run-
time: the composition of the lists can vary during the execution,
but identically so for both secrets. Finally, for virtual registers that
are spilled to memory by the backend, the CPU reads and writes
them with the same instructions regardless of the current taken
predicate value, so those accesses are also oblivious.
Security Properties. We build on the obliviousness claims above
to show that both passive attacks (attackers only monitoring mi-
croarchitectural events) and active attacks (attackers also arbitrarily
tampering with the microarchitectural state) are unsuccessful.
No instruction latency variance from secret-dependent operand
values is possible, since we replace and sanitize instructions such as
division (§4.2.5). Memory accesses may have variable latencies, but,
thanks to the DFL indirection, those will only depend on non-secret
code/data and external factors. Moreover, DFL wrappers do not leak
secrets and do not introduce decoy paths side channels in terms of
decoy data flows or exceptions. In §4.3.1, we explained how load
and store helpers stride objects using safe [20, 53] cmov or SIMD
instructions. As for decoy paths, taken can conditionally assign an
incoming pointer with ⊥: the adversary would need access to CPU
registers or memory contents to leak the nature of a path (outside
the threat model). Finally, helpers are memory-safe as points-to
analysis is sound and we track object lifetimes.
Finally, an active attacker may perturb the execution to attempt
Flush+Reload, Prime+Probe, and other microarchitectural attacks to
observe cache line-sized or even word-sized victim accesses. With
vulnerable code, they could alter for instance the access timing for a
specific portion of memory, and observe timing differences to detect
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea723matching victim accesses. However, thanks to the obliviousness
property of our approach, leaking victim accesses will have no value
for the attacker, because we access all the possible secret-dependent
code/data locations every time.
Residual Attack Surface. We now discuss the residual attack sur-
face for Constantine. Design considerations aside, the correctness
and obliviousness of the final instrumented binary are also subject
to the correctness of our Constantine implementation. Any im-
plementation bug may introduce an attack surface. To mitigate this
concern, we have validated our correctness claims experimentally
by running extensive benchmarks and test suites for the programs
we considered in our evaluation. We have also validated our oblivi-
ousness claims experimentally by means of a verifier, as detailed
later. Overall, our implementation has a relatively small trusted
computing base (TCB) of around 11 KLOC (631 LOC for our profiler,
955 LOC for CFL, 2561 for DFL, and 7259 LOC for normalization
and optimization passes), which provides confidence it is possible
to attain correctness and obliviousness in practice.
Constantine’s residual attack surface is also subject to the
correctness of the required oracle information. The static points-to
analysis we build on [68] is sound by design and our refinements
preserve this property—barring again implementation bugs. Our
information-flow tracking profiler, on the other hand, relies on the
completeness of the original profiling suite to eliminate any attack
surface. While this is a fundamental limitation of dynamic analysis,
we found straightforward to obtain the required coverage for a
target secret-dependent computation, especially in cryptographic
software. Implementation bugs or limitations such as implicit flows
(§4.4.1) also apply here. A way to produce a more sound-by-design
oracle is to adopt static information-flow tracking, but this also
introduces overtainting and hence higher overheads [53].
An incomplete suite might also underestimate a secret-dependent
loop bound. Thanks to just-in-time linearization correctness is not
affected, but every time the trip count is mispredicted (i.e., real-path
loop execution yields a higher count than the oracle), the adversary
may observe a one-off perturbation (given that the instrumentation
quickly adapts the padding). This is insufficient to leak any kind
of high-entropy secret, but one can always envision pathological
cases. Similar considerations can be applied to recursive functions.
In principle, other than statically unbound secret-dependent
control flows, one can also envision statically unbound secret-
dependent data flows such as a secret-dependent heap-allocated
object size. We have not encountered such cases in practice, but they
can also be handled using just-in-time (data-flow) linearization—
i.e., padding to the maximum allocation size encountered thus far
during profiling/production runs with similar characteristics.
Part of the residual attack surface are all the code/data accesses
fundamentally incompatible with linearization and constant-time
programming in general. For instance, on the CFL front, one cannot
linearize imbalanced if-else constructs that invoke system calls, or
more generally secret-dependent code paths executing arbitrary li-
brary/system calls. Their execution must remain conditional. A way
to reduce the attack surface is to allow linearization of idempotent
library/system calls or even to include some external library/system
code in the instrumentation. On the DFL front, one cannot similarly
linearize secret-dependent data accesses with external side effects,
for instance those to a volatile data structure backed by a memory
mapped I/O region (e.g., a user-level ION region [71]). Again, we
have not encountered any of these pathological cases in practice.
Similarly, Constantine shares the general limitations of constant-
time programming on the compiler and microarchitectural opti-
mization front. Specifically, without specific provisions, a com-
piler backend may operate optimizations that inadvertently break
constant-time invariants at the source (classic constant-time pro-
gramming) or IR (automated solutions like Constantine) level.
Analogously, advanced microarchitectural optimizations may in-
advertently re-introduce leaky patterns that break constant-time
semantics. Some (e.g., hardware store elimination [26]) may origi-
nate new instructions with secret-dependent latencies and require
additional wrappers (and overhead). Others (e.g., speculative execu-
tion [39]) are more fundamental and require orthogonal mitigations.
6 PERFORMANCE EVALUATION
This section evaluates Constantine with classic benchmarks from
prior work to answer the following questions:
(1) What is the impact of our techniques on compilation time?
(2) How is binary size affected by linearization?
(3) What are the run-time overheads induced by CFL and DFL?
Methodology. We implemented Constantine on top of LLVM 9.0
and SVF 1.9 and tested it on a machine with an Intel i7-7800X CPU
(Skylake X) and 16 GB of RAM running Ubuntu 18.04. We discuss
two striding configurations to conceal memory access patterns with
DFL: word size (λ = 4), reflecting (core colocation) scenarios where
recent intra cache level attacks like MemJam [48] are possible, and
cache line size (λ = 64), reflecting the common (cache attack) threat
model of real-wold constant-time crypto implementations and also
Constantine’s default configuration. We use AVX512 instructions
to stride over large objects. Complete experimental results when
using AVX2 and the λ = 1 configuration (presently out of reach for
attackers) are further detailed in Appendix G. We study:
• 23 realistic crypto modules manually extracted by the au-
thors of SC-Eliminator [80] from a 19-KLOC codebase (SCE
suite), used also in the evaluation of Soares et al. [62];
• 6 microbenchmarks used in the evaluation of Raccoon [53]
(Raccoon suite)—all we could recover from the source code
of prior efforts [42, 43]—using the same input sizes;
• 8 targets used in constant-time verification works: 5 modules
of the pycrypto suite analyzed in [78] and 3 leaky functions
of BearSSL and OpenSSL studied in Binsec/Rel [21].
For profiling, we divide an input space of 32K elements in 128
equal partitions and pick a random instance from each, producing a
profiling input set of 256 inputs. We build both the baseline and the
instrumented version of each program at (-O3). Table 1 presents
our full experimental datasets with the SCE suite (first five blocks)
and the Raccoon, pycrypto, and Binsec/Rel suites (one block each).
Validation. We validated the implementation for PC-security
and memory access obliviousness with two verifiers. For code ac-
cesses, we use hardware counters for their total number and a
cycle-accurate software simulation in GEM5. For data accesses, we
use cachegrind for cache line accesses and write a DBI [22] tool to
track what locations an instruction accesses, including predicated
cmov ones visible at the microarchitectural level. We repeatedly
tested the instrumented programs in our datasets with random
Session 3A: Side Channel CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea724performance
IR constructs (sensitive/total)
s
o
n
o
r
h
c
program
aes
des
des3
anubis
cast5
cast6
fcrypt
khazad
p aes_core
cast-ssl
aes
cast128
des
kasumi
seed
twofish
n
a
t
o
b
c
-
s
r 3way
Table 1: Benchmark characteristics and overheads.
binary size
λ = 64 λ = 4 λ = 64
1.16x
1.08x 1.16x
1.73x
1.14x 1.37x
2.84x
1.36x 1.92x
1.27x
1.12x 1.27x
1.06x 1.16x
1.16x
1.01x
1.08x 1.01x
1.01x
1.03x 1.01x
1.15x
1.09x 1.15x
1.22x
1.06x 1.22x
1.24x
1.10x 1.24x
1.72x
1.03x 1.36x
1.16x
1.01x 1.16x
1.01x 1.16x
1.16x
1.57x
1.01x 1.29x
1.18x
1.01x 1.18x
2.42x
1.12x 1.45x
1.00x
1.00x 1.00x
1.45x
1.09x 1.23x
1.02x
1.43x 1.02x
1.01x
1.01x 1.01x
1.06x 1.29x
1.85x
1.22x
1.10x 1.22x
2.24x
1.92x 1.43x
1.01x
1.18x 1.01x
1.01x
1.51x 1.01x
1.00x
1.00x 1.00x
1.01x
1.68x 1.01x
1.00x
1.00x 1.00x
1.84x 1.30x
1.30x
1.19x
1.06x 1.19x
1.01x
1.03x 1.01x
1.01x
3.17x 1.01x
1.37x
1.04x 1.37x
1.01x
1.04x 1.01x
1.02x
1.01x 1.02x
1.29x
1.01x 1.29x
1.02x 1.29x
1.29x
1.35x
1.11x 1.22x
1.05x
1.33x 1.05x
1.10x
1.30x 1.10x
1.19x
1.01x 1.19x
1.16x 1.17x
1.25x
branches
0/1
0/1
0/3
0/1
0/1
-
-
-
-
0/1
0/12
0/2
0/1
0/7
0/6
1/8
0/4
2/10
16/76
-
0/2
0/4
-
1/4
3/15
0/2
0/2
0/5
0/9
0/11
0/3
0/16
0/29
0/5
l tls-rempad-luk13 4/17
0/45
0/50
-
-
-
-
-
writes λ = 4
1.13x
0/68
1.19x
0/36
1.49x
0/89
1.29x
0/87
0/36
1.13x
1.13x
0/4
1.04x
0/18