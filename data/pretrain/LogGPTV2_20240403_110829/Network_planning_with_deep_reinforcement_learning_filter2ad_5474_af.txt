scale problems.
Figure 13: Impact of relax factor α . The cost results are nor-
malized with those of First-stage on each topology.
Deep learning for networking and systems. Deep learning is
an emerging tool to be used for solving networking and systems
problems. NeuroCuts [34] uses Deep RL to generate packet classifi-
cation tree with smaller depth and less memory footprint. AuTO [9]
scales deep RL for datacenter-scale automatic traffic optimization.
Pensieve [38] learns adaptive bitrate algorithms for better video
quality. Metis [41] provides interpretability for deep learning-based
networking systems. Valadarsky et al. [62] uses deep RL for bet-
ter routing configurations. Yeo et al. [62] utilizes deep learning
to reduce the dependency for delivering high-quality video. Deep
learning is also used for congestion control [24], data layouts in big
data systems [72], cache admission policy in content delivery net-
works [30], network resource management [57, 75, 76], scheduling
algorithms [17, 39], concurrency control [67] and verification of
distributed protocols [73]. NeuroPlan applies deep RL and combines
it with GNNs to solve the network planning problem.
8 CONCLUSION
We present NeuroPlan, a deep RL approach to solve the network
planning problem. NeuroPlan uses a GNN and a domain-specific
node-link transformation for state encoding, and leverages a two-
stage hybrid approach to find the optimal solution. The evaluation
results show it can reduce the network planning cost by up to 17%
compared with hand-tuned heuristics. Meanwhile, it avoids heavy
human efforts to trade-off between optimality and tractability, and
is easy to incorporate other heuristics.
Self-driving networks are an emerging trend. NeuroPlan makes
a concrete step towards this goal by bringing AI techniques to an
important network management taskÐnetwork planning. We hope
NeuroPlan can inspire more work of applying AI techniques to
network automation.
This work does not raise any ethical issues.
Acknowledgments. We thank our shepherd Ratul Mahajan and
the anonymous reviewers for their valuable feedback on this paper.
Xin Jin (PI:EMAIL) is the corresponding author. Xin
Jin is with the Key Laboratory of High Confidence Software Tech-
nologies (Peking University), Ministry of Education. This work is
supported in part by NSF grants CNS-1813487 and CCF-1918757,
and Project 2020BD007 from PKU-Baidu Fund.
269
A-0A-0.5A-1Network topology0.00.51.01.5Normalized cost141605001000Number of epochs−0.2−0.10.0Epoch reward1416ABCDENetwork toplogy0.000.250.500.751.00Normalized cost11.251.5Network Planning with Deep Reinforcement Learning
SIGCOMM ’21, August 23–28, 2021, Virtual Event, Netherlands
REFERENCES
[1] AlphaFold.
https://deepmind.com/blog/article/
alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology.
[2] Global
state of
the WAN Report, 2020.
https://info.aryaka.com/
state-of-the-wan-report-2020.html.
[3] D. Bahdanau, P. Brakel, K. Xu, A. Goyal, R. Lowe, J. Pineau, A. Courville, and
Y. Bengio. An actor-critic algorithm for sequence prediction. arXiv preprint
arXiv:1607.07086, 2016.
[4] I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio. Neural combinatorial
optimization with reinforcement learning. arXiv preprint arXiv:1611.09940, 2016.
[5] Y. Bengio, A. Lodi, and A. Prouvost. Machine learning for combinatorial op-
timization: a methodological tour d’horizon. European Journal of Operational
Research, 2020.
[6] J. A. Bondy, U. S. R. Murty, et al. Graph theory with applications. Macmillan
London, 1976.
[7] Q. Cappart, T. Moisan, L.-M. Rousseau, I. Prémont-Schwarz, and A. Cire. Com-
bining reinforcement learning and constraint programming for combinatorial
optimization. arXiv preprint arXiv:2006.01610, 2020.
[8] Y. Chang, S. Rao, and M. Tawarmalani. Robust validation of network designs
under uncertain demands and failures. In USENIX NSDI, 2017.
[9] L. Chen, J. Lingys, K. Chen, and F. Liu. Auto: Scaling deep reinforcement learning
for datacenter-scale automatic traffic optimization. In ACM SIGCOMM, 2018.
[10] X. Chen and Y. Tian. Learning to perform local rewriting for combinatorial
optimization. Advances in Neural Information Processing Systems, 2019.
[11] CPLEX Optimizer. https://www.ibm.com/analytics/cplex-optimizer.
[12] D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. Gómez-Bombarelli,
T. Hirzel, A. Aspuru-Guzik, and R. P. Adams. Convolutional networks on graphs
for learning molecular fingerprints. arXiv preprint arXiv:1509.09292, 2015.
[13] M. Fey and J. E. Lenssen. Fast graph representation learning with pytorch
geometric. arXiv preprint arXiv:1903.02428, 2019.
[14] B. Fortz and M. Thorup. Internet traffic engineering by optimizing OSPF weights.
In IEEE INFOCOM, 2000.
[15] O. Gerstel, C. Filsfils, T. Telkamp, M. Gunkel, M. Horneffer, V. Lopez, and A. May-
oral. Multi-layer capacity planning for ip-optical networks. IEEE Communications
Magazine, 2014.
[16] A. Graves. Generating sequences with recurrent neural networks. arXiv preprint
arXiv:1308.0850, 2013.
[17] L. Gu, D. Zeng, W. Li, S. Guo, A. Y. Zomaya, and H. Jin. Intelligent vnf orchestra-
tion and flow scheduling via model-assisted deep reinforcement learning. IEEE
Journal on Selected Areas in Communications, 2019.
[18] P. Gupta, M. Gasse, E. B. Khalil, M. P. Kumar, A. Lodi, and Y. Bengio. Hybrid
models for learning to branch. arXiv preprint arXiv:2006.15212, 2020.
[19] Gurobi solver. https://www.gurobi.com/.
[20] R. Hartert, S. Vissicchio, P. Schaus, O. Bonaventure, C. Filsfils, T. Telkamp, and
P. Francois. A declarative and expressive approach to control forwarding paths
in carrier-grade networks. In ACM SIGCOMM, 2015.
[21] P. Henderson, R. Islam, P. Bachman, J. Pineau, D. Precup, and D. Meger. Deep
reinforcement learning that matters. In Proceedings of the AAAI Conference on
Artificial Intelligence, 2018.
[22] Q. Huang, A. Haj-Ali, W. Moses, J. Xiang, I. Stoica, K. Asanovic, and J. Wawrzynek.
Autophase: Juggling hls phase orderings in random forests with deep reinforce-
ment learning. arXiv preprint arXiv:2003.00671, 2020.
[23] S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S. Venkata, J. Wan-
derer, J. Zhou, M. Zhu, et al. B4: Experience with a globally-deployed software
defined wan. In ACM SIGCOMM, 2013.
[24] N. Jay, N. Rotman, B. Godfrey, M. Schapira, and A. Tamar. A deep reinforcement
learning perspective on internet congestion control. In International Conference
on Machine Learning, 2019.
[25] Z. Jia, M. Zaharia, and A. Aiken. Beyond data and model parallelism for deep
neural networks. arXiv preprint arXiv:1807.05358, 2018.
[26] J. M. Kahn and K.-P. Ho. Spectral efficiency limits and modulation/detection tech-
niques for dwdm systems. IEEE Journal of Selected Topics in Quantum Electronics,
2004.
[27] S. M. Kakade. A natural policy gradient. Advances in Neural Information Processing
Systems, 2001.
[28] E. Khalil, H. Dai, Y. Zhang, B. Dilkina, and L. Song. Learning combinatorial
optimization algorithms over graphs. Advances in Neural Information Processing
Systems, 2017.
[29] T. N. Kipf and M. Welling. Semi-supervised classification with graph convolu-
tional networks. arXiv preprint arXiv:1609.02907, 2016.
[30] V. Kirilin, A. Sundarrajan, S. Gorinsky, and R. K. Sitaraman. Rl-cache: Learning-
based cache admission for content delivery. IEEE Journal on Selected Areas in
Communications, 2020.
[31] V. R. Konda and J. N. Tsitsiklis. Actor-critic algorithms. In Advances in Neural
Information Processing Systems, 2000.
[32] W. Kool, H. Van Hoof, and M. Welling. Attention, learn to solve routing problems!
arXiv preprint arXiv:1803.08475, 2018.
[33] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel. Gated graph sequence neural
networks. arXiv preprint arXiv:1511.05493, 2015.
[34] E. Liang, H. Zhu, X. Jin, and I. Stoica. Neural packet classification.
In ACM
SIGCOMM. 2019.
[35] C. Liu, B. Zoph, M. Neumann, J. Shlens, W. Hua, L.-J. Li, L. Fei-Fei, A. Yuille,
J. Huang, and K. Murphy. Progressive neural architecture search. In Proceedings
of the European Conference on Computer Vision (ECCV), 2018.
[36] H. H. Liu, Y. Zhu, J. Padhye, J. Cao, S. Tallapragada, N. P. Lopes, A. Rybalchenko,
G. Lu, and L. Yuan. CrystalNet: Faithfully emulating large production networks.
In ACM SOSP, 2017.
[37] Y. Liu, H. Zhang, W. Gongt, and D. Towsley. On the interaction between overlay
routing and underlay routing. In IEEE INFOCOM, 2005.
[38] H. Mao, R. Netravali, and M. Alizadeh. Neural adaptive video streaming with
pensieve. In ACM SIGCOMM, 2017.
[39] H. Mao, M. Schwarzkopf, S. B. Venkatakrishnan, Z. Meng, and M. Alizadeh.
Learning scheduling algorithms for data processing clusters. In ACM SIGCOMM,
2019.
[40] N. Mazyavkina, S. Sviridov, S. Ivanov, and E. Burnaev. Reinforcement learning
for combinatorial optimization: A survey. arXiv preprint arXiv:2003.03600, 2020.
[41] Z. Meng, M. Wang, J. Bai, M. Xu, H. Mao, and H. Hu. Interpreting deep learning-
based networking systems. In ACM SIGCOMM, 2020.
[42] Mininet. http://mininet.org.
[43] A. Mirhoseini, A. Goldie, M. Yazgan, J. Jiang, E. Songhori, S. Wang, Y.-J. Lee,
E. Johnson, O. Pathak, S. Bae, et al. Chip placement with deep reinforcement
learning. arXiv preprint arXiv:2004.10746, 2020.
[44] J. E. Mitchell. Branch-and-cut algorithms for combinatorial optimization prob-
lems. Handbook of applied optimization, 2002.
[45] A. Mittal, A. Dhawan, S. Manchanda, S. Medya, S. Ranu, and A. Singh. Learning
heuristics over large graphs via deep reinforcement learning. arXiv preprint
arXiv:1903.03332, 2019.
[46] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and
M. Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.
[47] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare,
A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, S. Petersen, C. Beat-
tie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and
D. Hassabis. Human-level control through deep reinforcement learning. Nature,
2015.
[48] T. Nishizeki and N. Chiba. Planar graphs: Theory and algorithms. Elsevier, 1988.
[49] NS-3 network simulator. https://www.nsnam.org/.
[50] M. Padberg and G. Rinaldi. A branch-and-cut algorithm for the resolution of
large-scale symmetric traveling salesman problems. SIAM review, 1991.
[51] H. Peng, J. Li, Y. He, Y. Liu, M. Bao, L. Wang, Y. Song, and Q. Yang. Large-scale
hierarchical text classification with recursively regularized deep graph-cnn. In
WWW, 2018.
[52] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph
neural network model. IEEE Transactions on Neural Networks, 2008.
[53] J. Schulman, P. Moritz, S. Levine, M. Jordan, and P. Abbeel. High-dimensional
continuous control using generalized advantage estimation. arXiv preprint
arXiv:1506.02438, 2015.
[54] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hu-
bert, L. Baker, M. Lai, A. Bolton, Y. Chen, T. Lillicrap, F. Hui, L. Sifre, G. v. d.
Driessche, T. Graepel, and D. Hassabis. Mastering the game of go without human
knowledge. Nature, 2017.
[55] OpenAI Spinning Up. https://spinningup.openai.com/en/latest/.
[56] J. Suárez-Varela, A. Mestres, J. Yu, L. Kuang, H. Feng, A. Cabellos-Aparicio, and
P. Barlet-Ros. Routing in optical transport networks with deep reinforcement
learning. IEEE/OSA Journal of Optical Communications and Networking, 2019.
[57] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos. Learning to
optimize: Training deep neural networks for wireless resource management.
In IEEE 18th International Workshop on Signal Processing Advances in Wireless
Communications (SPAWC), 2017.
[58] Y. Tang, S. Agrawal, and Y. Faenza. Reinforcement learning for integer pro-
gramming: Learning to cut. In International Conference on Machine Learning,
2020.
[59] Y. Tian, J. Ma, Q. Gong, S. Sengupta, Z. Chen, J. Pinkerton, and C. L. Zitnick. Elf
opengo: An analysis and open reimplementation of alphazero. arXiv preprint
arXiv:1902.04522, 2019.
[60] M. Tornatore, G. Maier, and A. Pattavina. Wdm network design by ilp models
based on flow aggregation. IEEE/ACM Transactions on Networking, 2007.
[61] M. Trofin, Y. Qian, E. Brevdo, Z. Lin, K. Choromanski, and D. Li. Mlgo: a
machine learning guided compiler optimizations framework. arXiv preprint
arXiv:2101.04808, 2021.
[62] A. Valadarsky, M. Schapira, D. Shahaf, and A. Tamar. Learning to route with
deep rl. In NIPS Deep Reinforcement Learning Symposium, 2017.
[63] K. G. Vamvoudakis and F. L. Lewis. Online actorścritic algorithm to solve the
continuous-time infinite horizon optimal control problem. Automatica, 2010.
270
SIGCOMM ’21, August 23–28, 2021, Virtual Event, Netherlands
Hang Zhu, Varun Gupta, Satyajeet Singh Ahuja,
Yuandong Tian, Ying Zhang, Xin Jin
[64] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio. Graph
Management of Data, 2020.
attention networks. arXiv preprint arXiv:1710.10903, 2017.
[73] J. Yao, R. Tao, R. Gu, J. Nieh, S. Jana, and G. Ryan. Distai: Data-driven automated
[65] S. Verdú. Spectral efficiency in the wideband regime.
IEEE Transactions on
invariant learning for distributed protocols. In USENIX OSDI, 2021.
Information Theory, 2002.
[66] S. Verdú and S. Shamai. Spectral efficiency of cdma with random spreading. IEEE
Transactions on Information Theory, 1999.
[67] J. Wang, D. Ding, H. Wang, C. Christensen, Z. Wang, H. Chen, and J. Li. Polyjuice:
In USENIX
High-performance transactions via learned concurrency control.
OSDI, 2021.
[68] P. J. Winzer. High-spectral-efficiency optical modulation formats. Journal of
Lightwave Technology, 2012.
[69] Y. Wu and Y. Tian. Training agent for first-person shooter game with actor-critic
curriculum learning. In ICLR, 2016.
[70] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip. A comprehensive
survey on graph neural networks. IEEE Transactions on Neural Networks and
Learning Systems, 2020.
[71] K. Xu, W. Hu, J. Leskovec, and S. Jegelka. How powerful are graph neural
networks? arXiv preprint arXiv:1810.00826, 2018.
[72] Z. Yang, B. Chandramouli, C. Wang, J. Gehrke, Y. Li, U. F. Minhas, P.-Å. Larson,
D. Kossmann, and R. Acharya. Qd-tree: Learning data layouts for big data
analytics. In Proceedings of the 2020 ACM SIGMOD International Conference on
[74] J. You, B. Liu, Z. Ying, V. Pande, and J. Leskovec. Graph convolutional policy
network for goal-directed molecular graph generation. In Advances in Neural
Information Processing Systems, 2018.
[75] D. Zeng, L. Gu, S. Pan, J. Cai, and S. Guo. Resource management at the network
edge: A deep reinforcement learning approach. IEEE Network, 2019.
[76] C. Zhang, P. Patras, and H. Haddadi. Deep learning in mobile and wireless
networking: A survey. IEEE Communications surveys & tutorials, 2019.
[77] C. Zhang, D. Song, C. Huang, A. Swami, and N. V. Chawla. Heterogeneous graph
neural network. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, 2019.
[78] J. Zhou, G. Cui, Z. Zhang, C. Yang, Z. Liu, and M. Sun. Graph neural networks: A
review of methods and applications. arXiv preprint arXiv:1812.08434, 2018.
[79] D. Zhuo, M. Ghobadi, R. Mahajan, A. Phanishayee, X. K. Zou, H. Guan, A. Krish-
namurthy, and T. Anderson. RAIL: A case for redundant arrays of inexpensive
links in data center networks. In USENIX NSDI, 2017.
[80] B. Zoph and Q. V. Le. Neural architecture search with reinforcement learning.
arXiv preprint arXiv:1611.01578, 2016.
271