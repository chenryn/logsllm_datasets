provides several orders of magnitude improvement over a generic
implementation of the original conversion algorithm from [11],
which requires a full group multiplication and PRF evaluation per
step.
In this section, we describe two simple modifications that allow
us to further improve over this method. In the context of RMS
multiplications, the improvement is by at least a factor of 16.
4.1.1
Separating Distinguished Points. The first optimization
ensures that an actual failure happens in the computation if and
only if the two parties raise a flag. This is done simply by declar-
ing any point in the danger zone (which corresponds to M points
forward for the first party, and M points backward for the second
party, where M is the payload bound) to be non-distinguished if
it is located less than 2M steps after a distinguished point. This
modification has only a marginal impact on the running time as it
only affects the start of the Convert algorithm, where the parties
search for distinguished points in the danger zone. Before starting
the conversion, we also let both parties multiply their local share
by дM (this avoids having to compute inversions when looking for
distinguished points backward). This is to be compared with [13],
where roughly half of the distinguished points are immediately
followed by another distinguished point (this happens if the bit fol-
lowing the 0d pattern is 0). Hence, the event of two parties raising
a flag was highly correlated with the event of the first party raising
a flag, even when the actual payload is 0 (which corresponds to a
case where no actual failure can occur).
2
4.1.2 Changing the Pattern. We suggest a second, seemingly
trivial, modification of the Convert algorithm: searching for the
pattern 10d instead of 0d. We explain below how this improves the
construction.
First, recall that the conversion algorithm proceeds by looking
for the first distinguished point in a sequence stream defined by the
most significant bits of the group elements h, hд, hд
, . . .. Searching
for the modified pattern is almost the same: as before, we search for
the first occurrence of 0d in the sequence; when this sub-sequence
is found, it necessarily holds that the bit that precedes it is 1. The
only actual change is in the initial check, which ignores an initial
sequence of 0’s and searches the danger zone for the pattern 10m
(instead of 0m) when deciding whether to raise a potential error flag.
Changing the pattern 0d to 10d improves the failure probability by
a factor of 2 (since it reduces the probability of a distinguished point
in the danger zone by a factor of 2) without significantly changing
the running time. Thus, it effectively reduces the expected running
time required for achieving a given failure probability by a factor
of 2.
algorithm that incorporates the above two modifications.
We now formally describe and analyze the optimized conversion
Referring by “failure” to the event of both parties outputting ⊥,
we can therefore state the following lemma, which corresponds to a
factor-(2M/z) improvement over the conversion algorithm of [13]
for a payload z and payload bound M:
Convert∗ ({z} , M, d ) (cid:55)→ ⟨z⟩. Let Convert∗ denote the Convert
algorithm from [13] (see Section 3.2) modified as follows: given a
payload bound M and failure parameter d, the algorithm searches
for the pattern 10d instead of 0d, and points in the danger zone
within 2M steps backward of a distinguished point are considered
to be non-distinguished.
Lemma 4.1. If Convert∗ is run on a random stream with payload
z, payload bound M, and failure parameter d, the expected number
of steps performed by each party is T ≤ 2d +1 + 2M and the failure
probability is ε ≤ z · 2−(d +1).
A proof of Lemma 4.1 is given in the full version.For comparison,
in the Las Vegas variant of the optimized conversion algorithm
from [13], the expected running time is the same, whereas the
failure probability bound is ε ≤ M · 2−d.
Note that our heuristic assumption that stream is uniformly ran-
dom has no impact on security, it only affects efficiency and has been
empirically validated by our implementation. Given Lemma 4.1,
and denoting Mult∗ the Mult algorithm using Convert∗ instead
of Convert, we can now bound the failure probability in an RMS
multiplication:
Lemma 4.2. If Mult∗ is run with base B, length s for the secret
key c, payload bound M, and outputs y, the expected number of
conversion steps performed by each party is T ≤ (s + 1) · 2d +1, the
failure probability ε, expected over the randomness of the secret key c,
satisfies
(cid:19)2
(cid:18) s + 1
2d +1
.
ε ≤ y · 1 + s (B−1)2
2d +1
+
)
A proof of Lemma 4.2 is given in the full version.Note that the
payload in the first Convert∗ algorithm is y and the average pay-
load in the s last Convert∗ invocations is (B − 1)y/2; the failure
probability is also taken over the random choice of the secret key.
4.1.3 Randomizing the Conversion of Bit Inputs. Using the above
method, the two parties raise a flag if a failure actually occurs or
if both parties raise a flag in different executions of Convert∗; the
latter situation occurs only with quadratically smaller probability
((s + 1)/2d +1
2. In addition, let z be a payload used in a conversion
step with failure parameter δ. Observe that the actual probability of
a failure occurring is δz. In [11], the failure probability was analyzed
by using a bound on the maximal size of the shared value. A typical
conversion occurs after a pairing between an encryption of a value
x ·ci, where x is an input and ci is a component of the secret key (in
some base B), and a level 2 share of a value y; in most applications, x
and y are bits (this corresponds to using memory bound MRMS = 1
for the RMS program), hence the maximum value of xyci is B−1. As
the secret key is random, we previously observed that the average
size of ci is (B − 1)/2.
In addition, we will show in this section that we can randomize
the conversion algorithm, so as to ensure that each of x and y is
equal to 0 with probability 1/2. This ensures that the average size
of z = xyci in a typical conversion step is (B − 1)/8, hence that the
event of a failure occurring is on average δ (B − 1)/8, independently
of the actual distribution of the inputs. Because of our previous
optimization, which ensures that a failure occurs if and only if
Session J1:  OutsourcingCCS’17, October 30-November 3, 2017, Dallas, TX, USA2110two flags are raised, this allows to set the parameter δ to be 8
times bigger to reach a fixed failure probability, effectively reducing
the number of steps in a conversion algorithm by a factor of 8.
Therefore, cumulated with the previous optimization, this improves
the computational efficiency of conversions in most applications
by a factor 16.
We now describe our randomization technique. First, we modify
the key generation algorithm as follows: we set the evaluation keys
(ek0, ek1) to be (⟨ci⟩)i ≤s (the parties hold shares of each bit of c over
the integers, rather than holding integer shares of c). Second, we
assume that the parties have access to a stream of common random
bits (which can be heuristically produced by a PRG), and that they
hold level 2 shares of each input bit. In the case of secret key HSS,
these level two shares can be part of the encryption algorithm of
the HSS; for public key HSS, they can be computed (with some
failure probability) from level 1 shares and the shares of the secret
key. Let PairConv∗ be the PairConv algorithm modified to use the
Functionality: RandMult(pk, [[[x]]]c ,⎷x⌄c ,⎷y⌄c , δ, b0, b1) (cid:55)→
new Convert∗ algorithm.
⎷xy⌄c
Description: Parse [[[x]]]c as ((cid:74)x(cid:75)c , ((cid:74)xci(cid:75)c )i ≤s ), and use the
(cid:74)b0 ⊕ x(cid:75)c , ((cid:74)(b0 ⊕ x )ci(cid:75)c )i ≤s ,⎷b1 ⊕ y⌄c .
((cid:74)(b0 ⊕ x )ci(cid:75)c ,⎷b1 ⊕ y⌄c , δ ),
which returns(cid:10)(b0 ⊕ x )(b1 ⊕ y)ci
(cid:11). Compute
(cid:10)xyci
(cid:11) ← (−1)b0+b1 ((cid:10)(b0 ⊕ x )(b1 ⊕ y)ci
(cid:11)
− b0b1 ⟨ci⟩ − b0 (−1)b1(cid:10)yci
(cid:11) − b1(−1)b0 ⟨xci⟩).
Reconstruct⎷xy⌄c ← ((cid:10)xyc0(cid:11) ,(cid:80)
i 2i−1(cid:10)xyci
(cid:11)).
public values (b0, b1) to compute
Let c0 = 1. For i = 0 to s, call
The correctness immediately follows from the fact that b0⊕x and
b1 ⊕ y are uniform over {0, 1} if (b0, b1) are random bits. Therefore,
we get the following corollary to Lemma 4.2:
PairConv∗
Corollary 4.3. The (Las Vegas) probability ε of a failure event
occurring in an RMS multiplication on bit inputs using base B and
length s for the secret key is
ε ≤ 1 + s (B−1)2
2d +3
+
(cid:19)2
(cid:18) s + 1
2d +1
.
Remark 4.4. The above method should be avoided when there
is an a-priori knowledge that the RMS values are biased towards 0
(or 1). In this case, one can gain better error reduction by applying
our optimized conversion directly without any randomization. We
also note that the above method does not generalize immediately
to MRMS > 1: while xoring with a public value can be done homo-
morphically in the case MRMS = 1, this does not extend to general
modular addition. However, a weaker version of the result can be
$← {0,· · · , MRMS − 1}2 and randomizing
achieved, using (r0, r1)
(x, y) as (x′, y′) = (x − r0, y − r1). While (x′, y′) are not uniformly
distributed and belong to a larger set {1− MRMS,· · · , MRMS − 1}, we
can lower bound the probability of x′y′ = 0 as
MRMS − 1
MRMS
′ = 0] ≥ 1 −
(cid:33)2
Pr[x
′
y
(cid:32)
,
which is sufficient to improve over the basic Convert algorithm.
4.2 Distributed Protocols
In this section, we suggest new protocols to improve the key gener-
ation, and to distributively generate level 2 shares of inputs under
a shared key. The former protocol allows to save a factor two com-
pared to the solution outlined in [13], while the latter is extremely
useful for computation of degree-two polynomials (intuitively, this
allows to avoid encoding each input with a number of group el-
ements proportional to the size of the secret key – see e.g. Sec-
tion 5.3.1).
4.2.1 Distributed Key Generation. When using HSS within se-
cure computation applications, the parties must generate an HSS
public key in a secure distributed fashion. Applying general-purpose
secure computation to do so has poor concrete efficiency and re-
quires non-black-box access to the underlying group. A targeted
group-based key generation protocol was given in [13], where each
party samples an independent ElGamal key, and the system key is
generated homomorphically in a threshold ElGamal fashion. How-
ever, a negative side-effect of this procedure is that encryptions
of key bits from different parties combine to encrypted values in
{0, 1, 2} instead of {0, 1} (since homomorphism is over Zq, not Z2),
and these larger payloads incur a factor of 2 greater runtime in
homomorphic multiplications to maintain the same failure proba-
bility.
We present an alternative distributed key generation procedure
which avoids this factor of 2 overhead, while maintaining black-box
use of the group, at the expense of slightly greater (one-time) setup
computation and communication. We focus here on the primary
challenge of generating encryptions of the bits of a shared ElGamal
secret key c. We use a binary basis for concreteness, but the protocol
can be easily generalized to an arbitrary basis. Roughly the idea is to
run an underlying (standard) secure protocol to sample exponents
of the desired ElGamal ciphertext group elements, but which reveals
the exponents masked by a random value (ai or bi) generated by
the other party. The parties then exchange дai and дbi , which
enables each to locally reconstruct the ElGamal ciphertext, while
computationally hiding the final exponents. Most importantly, the
resulting protocol requires only black-box operations in the group.
Proposition 4.5. The protocol ΠGen in Figure 1 securely evaluates
the group-based HSS Gen algorithm (from Section 3.3).
Proof Sketch. By construction (and correctness of the under-
lying 2PC), both parties will correctly output ElGamal ciphertexts
(дri , дxi )i∈[s] of each bit ci of the generated secret key, as desired.
Regarding security, the view of each party consists of a collection
of random group elements (received from the other party) together
with the exponent offsets from each value and its target. This can
be directly simulated given freshly sampled target ciphertexts, by
choosing a random offset and computing the group elements in the
first step accordingly.
□
Observe that it is immediate to modify the protocol ΠGen to
additionally output additive shares (cA, cB ) of the secret key c.
Comparison to [13]. ΠGen requires the additional 2PC execution
and 2s additional exponentiations per party (from Step 3) over
Session J1:  OutsourcingCCS’17, October 30-November 3, 2017, Dallas, TX, USA2111HSS Distributed Key Generation ΠGen
i
i to B; B samples
$← Zq, sends дai , дa′
Let c =(cid:80)s
i to A.
i )i∈[s]. B inputs (bi , b′
(1) For each i ∈ [s]:
A samples ai , a′
i
bi , b′
$← Zq, sends дbi , дb′
(2) Execute secure 2PC for (randomized) functionality:
Input: A inputs (ai , a′
i )i∈[s].
Compute:
Sample s random key bits: ∀i ∈ [s], ci ← {0, 1}.
i =1 2i−1
For each i ∈ [s]:
(a) Sample encryption randomness ri ← Zq.
(b) Compute xi = ric + ci ∈ Zq.
Output: A receives (ri − bi , xi − b′
(3) A outputs (cid:16)
(ri − ai , xi − a′
(cid:16)
i )д(xi−b′
i∈[s].
i )i∈[s].
i )д(xi−a′
(дai )д(ri−ai ), (дa′
(дbi )д(ri−bi ), (дb′
ci ∈ Zq.
i )(cid:17)
i )(cid:17)
i )i∈[s]; B receives
i∈[s], B outputs
Figure 1: 2-party protocol ΠGen for distributed HSS public
key generation.
the [13] solution. The 2PC is composed of s linear operations over
Z2, and s multiplications and 2s additions over Zq. In exchange,
ΠGen guarantees the encrypted system key bits ci remain in {0, 1},
whereas in [13] the corresponding terms ci will take values in
{0, 1, 2}, yielding x2 speedup in homomorphic evaluation of RMS
multiplications.
We remark that while one may be able to effectively address
this larger payload in specific cases (e.g., leveraging that the value
ci ∈ {0, 1, 2} is 1 with probability 1/2), such fixes will not extend
to general usage settings, or when implementing further HSS opti-