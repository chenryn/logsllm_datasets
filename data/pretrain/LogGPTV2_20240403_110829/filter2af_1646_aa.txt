# 预备知识
## 不同版本的HTTP的区别
| 显著特点 | 支持的请求方法 | 性能优化 | 泛用程度  
---|---|---|---|---  
HTTP0.9 | 不支持请求头响应头，纯文本 | GET |  | 已过时  
HTTP1.0 | 支持请求头响应头，超文本 | GET、HEAD、POST | 短链接，无优化 | 仍有少量使用  
HTTP1.1 | 性能优化，增加请求方法 | 增加了OPTIONS,PUT, DELETE, TRACE, CONNECT方法 | 增加Keep-Alive和chunked分块传输，请求流水线等 | 目前使用最广泛  
HTTP2.0 | 增加了二进制分帧 | 无变化 | 增加了二进制分帧层用与多路复用，通信在一个链接上进行，ServerPush | 目前应用较少  
## 关于HTTP1.1
这个版本的HTTP是现如今使用最为广泛的HTTP协议，所以对于这个版本我们可以进一步分析一下
这个版本增加了`Keep-alive`特性，那么这个特性是啥呢？
所谓`Keep-Alive`，就是在HTTP请求中增加一个特殊的请求头`Connection: Keep-Alive`，告诉服务器，接收完这次HTTP请求后，不要关闭TCP链接，后面对相同目标服务器的HTTP请求，重用这一个TCP链接，这样只需要进行一次TCP握手的过程，可以减少服务器的开销，节约资源，还能加快访问速度。当然，这个特性在`HTTP1.1`中是默认开启的。
有了`Keep-Alive`之后，后续就有了`Pipeline`，在这里呢，客户端可以像流水线一样发送自己的HTTP请求，而不需要等待服务器的响应，服务器那边接收到请求后，需要遵循先入先出机制，将请求和响应严格对应起来，再将响应发送给客户端。
现如今，浏览器默认是不启用`Pipeline`的，但是一般的服务器都提供了对`Pipleline`的支持。
## 关于Content-Length
这个简单些，我们放到后面讲。
## 关于Transfer-Encoding
Transfer-Encoding 是一种被设计用来支持 7-bit 传输服务安全传输二进制数据的字段，有点类似于 MIME (Multipurpose
Internet Mail Extensions) Header 中的 Content-Transfer-Encoding
。在HTTP的情况下，Transfer-Encoding 的主要用来以指定的编码形式编码 payload body
安全地传输给用户，并将仅用于传输效率或安全性的有效负载编码与所选资源的特征区分开来。在 HTTP/1.1 中引入，在 HTTP/2 中取消。引入了一个名为
`TE` 的头部用来协商采用何种传输编码。但是最新的 HTTP 规范里，只定义了一种传输编码：分块编码（chunked）。
分块编码相当简单，在头部加入 `Transfer-Encoding: chunked`
之后，就代表这个报文采用了分块编码。这时，报文中的实体需要改为用一系列分块来传输。每个分块包含十六进制的长度值和数据，长度值独占一行，长度不包括它结尾的
CRLF（\r\n），也不包括分块数据结尾的 CRLF。最后一个分块长度值必须为 0，对应的分块数据没有内容，表示实体结束。
    require('net').createServer(function(sock) {
        sock.on('data', function(data) {
            sock.write('HTTP/1.1 200 OK\r\n');
            sock.write('Transfer-Encoding: chunked\r\n');
            sock.write('\r\n');
            sock.write('b\r\n');
            sock.write('01234567890\r\n');
            sock.write('5\r\n');
            sock.write('12345\r\n');
            sock.write('0\r\n');
            sock.write('\r\n');
        });
    }).listen(9090, '127.0.0.1');
上面的代码中，响应头中表明接下来的实体会采用分块编码，然后输出了 11 字节的分块，接着又输出了 5 字节的分块，最后用一个 0
长度的分块表明数据已经传完了。用浏览器访问这个服务，可以得到正确结果。
当Content-Encoding 和 Transfer-Encoding
二者结合来用，其实就是针对进行了内容编码（压缩）的内容再进行传输编码（分块）。下面是我用 telnet 请求测试页面得到的响应，可以看到对 gzip
（压缩）内容进行的分块：
    HTTP/1.1 200 OK
    Server: nginx
    Date: Sun, 11 Sep 2022 14:44:23 GMT
    Content-Type: text/html
    Transfer-Encoding: chunked
    Connection: keep-alive
    Content-Encoding: gzip
    1f
    HW(/IJ
    0
这样的属性在MDN中还有列举
    chunked | compress | deflate | gzip | identity
chunk传输数据格式如下，其中size的值由16进制表示。
    [chunk size][\r\n][chunk data][\r\n][chunk size][\r\n][chunk data][\r\n][chunk size = 0][\r\n][\r\n]
其实也就是
    [chunk size][\r\n]
    [chunk data][\r\n]
    [chunk size][\r\n]
    [chunk data][\r\n]
    [chunk size = 0][\r\n][\r\n]
举个例子（这里我没做成功，在小皮里面写了个脚本本地包bp抓不到，各种方法都不管用，我也不知道哪里出问题了。。。。这里看v0w师傅的案例吧）
假设我们想通过POST传输这样的信息
正常请求是这样的：
通过增加`Transfer-Encoding: chunked`的headers，我们可以这样传输：
    POST /index.php HTTP/1.1
    Host: localhost
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36
    Connection: keep-alive
    Content-Type: application/x-www-form-urlencoded
    Content-Length: 29
    Transfer-Encoding: chunked
    2\r\n
    na\r\n
    c\r\n
    me=V0WKeeper\r\n
    0\r\n
    \r\n
  * 第一个分块：`\r\n`是CRLF，所以这里的`\r\n`是两个字节；第一个数字 2 表示`chunked-size`,是指接下来会有 2 个字节的数据(这个数字是16进制的)，也就是 `na` 这 2 个字母，然后按照 RFC 文档标准，字母 `na` 部分后面需要跟\r\n表示这个na是 `chunk-data`部分
  * 第二个分块：16进制的数字 c 后面表示`chunk-size`部分，是十六进制数表示这个分块的`chunk-data`是12字节，即`me=V0WKeeper`，之后`\r\n`表明这是`chunk-data`部分
  * 最后有一个`0\r\n\r\n`表示分块传输结束。
师傅已经说的很明白了，没有必要过多赘述了。
## CL&TE优先级
CL表示Content-Length，TE表示Transfer-Encoding。那么现在有一个问题：对于 CL & TE 解析是否存在优先级顺序？
在RFC中规定如果接收到带有 Transfer-Encoding 和 Content-Length 头字段的消息，则 Transfer-Encoding
会覆盖 Content-Length。这样的消息可能表明尝试执行请求走私（第 9.5 节）或响应拆分（第 9.4
节），应该作为错误处理。发送者必须在向下游转发这样的消息之前删除接收到的 Content-Length 字段。
这里指出了 TE 优先于 CL ，但是我们仍然可以通过一些方式绕过，又或者说，那个中间件的也没有依照这个 RFC 标准规范实现，这就导致了差异性的存在。
# 基础知识
## HTTP请求夹带是什么？
HTTP请求夹带（HTTP request
smuggling）又名HTTP请求走私，是一种干扰网站处理从一个或多个用户接受的请求的一种攻击技术。通俗地理解就是：攻击者发送一个语句模糊的请求，就有可能被解析为两个不同的HTTP请求，第二请求就会“逃过”正常的安全设备的检测，使攻击者可以绕过安全控制，未经授权访问敏感数据并直接危害其他应用程序用户。
攻击者部分前端请求被后端服务器解释为下一个请求的开始。实际上优先于下一个正常请求，因此会干扰应用程序处理正常请求的方式。。  
## 如何实现HTTP请求夹带？
HTTP请求走私漏洞的产生于：前端的反向代理服务器和后端的Web服务器，对同一个请求的理解不一致。
今天的Web应用程序经常在用户和最终应用程序逻辑之间使用HTTP服务器链。
用户将请求发送到前端服务器（有时称为负载平衡器或反向代理），此服务器将请求转发给一个或多个后端服务器。
在现代基于云的应用程序中，这种类型的体系结构越来越常见，并且在某些情况下是不可避免的。
当前端服务器将HTTP请求转发到后端服务器时，它通常通过相同的后端网络连接发送多个请求，因为这样做效率更高，性能更高。
协议非常简单：HTTP请求一个接一个地发送，接收服务器解析HTTP请求标头以确定一个请求结束的位置和下一个请求的开始：
此时，Front-End前端服务器和Back-End后端服务器关于多个请求之间的边界问题的一致性是非常重要的！否则，攻击者可能发送一个模糊的请求，若前端服务器和后端服务器之前对请求的边界没有严格定义好，就会对这个请求执行不用的解析处理方式，从而产生不同的相应结果，请求夹带攻击也就由此产生。
在这里，攻击者将后端服务器的部分前端请求解释为下一个请求的开始。它有效地预先附加到下一个请求，因此可能会干扰应用程序处理请求的方式。
根据破坏请求的方式不同，一般将HTTP走私分为几种不同的情形（CL:Content-Length, TE:Transfer-Encoding）：
  * CL!=0
  * CL-CL
  * CL-TE
  * TE-CL
  * TE-TE
## 漏洞产生原因
### 标准数据包结束的标头标志
#### Content-Length（简称为CL）
`Content-Length`, 是HTTP消息长度, 用 **十进制数字** 表示的 **八位字节的数目** 。`Content-Length`首部指示出报文中实体主体的字节大小. 这个大小是包含了所有内容编码的, 比如, 对文本文件进行了`gzip`压缩的话, `Content-Length`首部指的就是压缩后的大小而不是原始大小。
这个就简单易懂，它以字节为单位指定消息体的长度。
报文长度数经常出问题，建议使用Burp插件HTTP Request Smuggler自动处理。  
最方便的方法是：将报文完整粘贴到`Sublime Text文本编辑器`中如果末尾有空行别忘了补充上。选中可直接查看字符数。
这里不同平台还是有一定区别的
win平台：换行用0d0a，`2`个字节表示  
linux和mac：换行分别用0a和0d,`1`个字节表示
    POST /search HTTP/1.1
    Host: normal-website.com
    Content-Type: application/x-www-form-urlencoded
    Content-Length: 13
    q=smuggling
#### Transfer-Encoding(简称为TE)
用于指定消息体使用分块编码（Chunked Encode），也就是说消息报文由一个或多个数据块组成，每个数据块大小以字节为单位（十六进制表示）
衡量，后跟换行符，然后是块内容。
最重要的是：整个消息体以大小为0的块结束，也就是说解析遇到0数据块就结束。
    POST /search HTTP/1.1
    Host: normal-website.com
    Content-Type: application/x-www-form-urlencoded
    Transfer-Encoding: chunked
    b             （16进制6，代表每一块chunck长11位）
    q=smuggling    （字符串11字节长，不要加2哈，与CL不同）、
    0               （遇0 chunck结束）
由于HTTP规范提供了以上两种不同方法来指定HTTP消息体的长度，因此单个消息可以同时使用这两种方法，这种情况下，它们就会发生相互冲突。HTTP规范试图通过声明来防止此问题的发生，即：如果Content-Length和Transfer-Encoding标头同时出现在一个请求中，则应忽略Content-Length标头。这种规范在一台服务器接收请求时可以避免出现歧义，但在两台或多台服务器链接收请求时可能会出现问题。
为啥数量一多就会出问题呢？有俩原因
某些服务器不支持请求中的Transfer-Encoding标头；
如果攻击者把标头以某种方式进行模糊构造，则可能会导致某些支持Transfer-Encoding标头的服务器不会处理部份消息内容，而把这些内容当成是下一个请求的起始。
这样一来，前端服务器和后端服务器对模糊构造的Transfer-Encoding标头解析结果不同，相互之间对请求的边界不能形成共识，就会导致请求夹带漏洞的产生。
# 漏洞解析
HTTP请求夹带攻击需要将Content-Length头和Transfer-Encodeing头放入单个请求中，并操控使得前端和后端服务器以不同方式处理请求，这种攻击取决于前端和后端两台服务器对标头的处理方式：
CL!=0 :Content-length不为零
CL.CL：前端服务器使用Content-length，后端服务器使用Content-length头部。
CL.TE：前端服务器使用Content-length，后端服务器使用Transfer-Encoding头部。
TE.CL：前端服务器使用Transfer-Encodin头部，后端服务器使用Content-length头部。
TE.TE：前端和后端服务器都支持Transfer-Encodin报头，但可以通过以某种方式混淆报头来诱导其中一个服务器不处理它。  
## CL!=0
如果前端代理服务器允许GET携带请求体，而后端服务器不允许GET携带请求体，后端服务器就会直接忽略掉GET请求中的Content-Length头，这就有可能导致请求走私。
其实在这里，影响到的并不仅仅是GET请求，所有不携带请求体的HTTP请求都有可能受此影响，只因为GET比较典型。
在`RFC2616`中，没有对GET请求像POST请求那样携带请求体做出规定，在最新的`RFC7231`的4.3.1节中也仅仅提了一句。
    在 GET 请求上发送有效负载正文可能会导致某些现有实现拒绝该请求
举个例子
    GET / HTTP/1.1\r\n
    Host: example.com\r\n
    Content-Length: 43\r\n
    GET / admin HTTP/1.1\r\n
    Host: example.com\r\n
    \r\n
在前端服务器看来它是一个请求，但是在后端服务器来看它就是：
第一个请求
    GET / HTTP/1.1\r\n
    Host: example.com\r\n
第二个请求
    GET / admin HTTP/1.1\r\n
    Host: example.com\r\n
可导致请求走私
## CL.CL漏洞
在RFC7230的第3.3.3节中的第四条中，规定当服务器收到的请求中包含两个Content-Length，而且两者的值不同时，需要返回400错误。
但是很明显这并非是强制的，如果服务器不遵守安全规定在服务器收到多个CL不相同的请求时不返回400错误，那么就可能会导致请求走私。
假设中间的代理服务器和后端的源站服务器在收到类似的请求时，都不会返回400错误，但是中间代理服务器按照第一个`Content-Length`的值对请求进行处理，而后端源站服务器按照第二个`Content-Length`的值进行处理。
构造一个特殊的请求
    POST / HTTP/1.1\r\n
    Host: example.com\r\n
    Content-Length: 8\r\n
    Content-Length: 7\r\n
    12345\r\n
    a
中间代理服务器看到的第一个CL长度为8，此时代码的567行字符总数正好为8，代理服务器觉得没啥问题，就直接向后端的源站服务器原封不动的发包。
但此时后端服务器看到的第一个 CL长度为7，当他读完前七个字符之后，还剩缓冲区中的最后一个a没有读，那么此时的a对于后端服务器来说就是下一个请求的一部分
就在此时，有个倒霉蛋对服务器进行了请求，假设请求是
    GET /index.html HTTP/1.1\r\n
    Host: example.com\r\n
从前面我们也知道了，代理服务器与源站服务器之间一般会重用TCP连接。  