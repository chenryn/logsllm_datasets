for different vulnerability classes. Their entropy anal-
ysis applies also to other second-generation ASR tech-
niques, and, similarly, to our technique, which, how-
ever, provides additional entropy thanks to internal lay-
out randomization and live rerandomization. Their anal-
ysis, however, is mostly useful in evaluating the effec-
tiveness of ASR techniques against guessing and brute-
force attacks. As discussed earlier, these attacks are far
less attractive inside the operating system. In contrast,
information leakage dominates the scene.
For this reason, we explore another direction in our
analysis, answering the question: “How much informa-
Vulnerability
Ar
Ar
Ar
Ar
Buffer overﬂows
Format string bugs
Use-after-free
Uninitialized reads
Arbitrary memory R|W
Ar
Ar
Controlled code injection
Ar
Return-into-libc/text
Return-oriented programming Ar
Effect
ASR1 ASR2 ASR3
Ro
Ro
Ro
Ro
Re
Re
Re
Re
Ao
Ao
N · Ao
N · Ao
Ae
Ae
N · Ao
-
Ar = Known region address
Ao = Known object address
Ae = Known element address
Ro = Known relative distance/alignment between objects
Re = Known relative distance/alignment between elements
Table 2: Comparison of ASR techniques.
tion does the attacker need to acquire for successful ex-
ploitation?”. In this respect, Table 2 compares our ASR
technique (ASR3) with ﬁrst-generation techniques like
PaX [68] and comprehensive second-generation tech-
niques like the one presented in [14]. Most attacks re-
quire at least some knowledge of a memory area to cor-
rupt and of another target area to achieve the intended
effect (missing kernel pointer checks and non control
data attacks are examples of exceptions in the two cases).
Table 2 shows that ﬁrst-generation techniques only re-
quire the attacker to learn the address of a memory re-
gion (e.g., stack) to locate the target correctly. Second-
generation techniques, in turn, allow the attacker to cor-
rupt the right memory location by learning the relative
distance/alignment between two memory objects.
In this respect, our internal layout randomization pro-
vides better protection, forcing the attacker to learn the
relative distance/alignment between two memory ele-
ments in the general case. For example, if the attacker
learns the relative alignment between two heap-allocated
data structures S1 and S2 and wants to exploit a vulnera-
ble dangling pointer to hijack a write intended for a mem-
ber of S1 to a member of S2, he still needs to acquire
information on the relative positioning of the members.
Similarly, our technique constraints attacks based on
arbitrary memory reads/writes to learn the address of
the target element. In contrast, second-generation tech-
niques only require knowledge of the target memory
object. This is easier to acquire, because individual
objects can be exposed by symbol information (e.g.,
/proc/kallsyms) and are generally more likely to have
their address taken (and leaked) than interior elements.
Controlled code injection shows similar differences—
spraying attacks are normally “Ar”, in contrast. Return-
only useful in the current rerandomization window. In
particular, let us assume the duration of every round to
be distributed according to some probability distribution
p(t) (e.g., computed from the probabilities given in [14]).
Hence, the time to complete an n-round probing phase is
distributed according to the convolution of the individ-
ual pi(t). Assuming the same pi(t) in every round for
simplicity, it can be shown that the expected time before
the attacker can complete the probing phase in a single
rerandomization window (and thus the attack) is:
(cid:18)(cid:90) T
0
(cid:19)−1
,
Tattack = T ·
p∗n(τ)dτ
where T is the size (ms) of the rerandomization window,
n is the number of probing rounds, and p∗n(t) is the n-
fold convolution power of p(t). Since the convolution
power decreases rapidly with the number of targets n, the
attack can quickly become impractical. Given a vulner-
ability and an attack model characterized by some p(t),
this formula gives a practical way to evaluate the impact
of a given rerandomization frequency on attack preven-
tion. When a new vulnerability is discovered, this for-
mula can also be used to retune the rerandomization fre-
quency (perhaps accepting a performance penalty) and
make the attack immediately impractical, even before an
appropriate patch is developed and made available. This
property suggests that our ASR design can also be used
as the ﬁrst “live-workaround” system for security vulner-
abilities, similar, in spirit, to other systems that provide
immediate workarounds to bypass races at runtime [71].
8 Related work
Randomization. Prior work on ASR focuses on ran-
domizing the memory layout of user programs, with
solutions based on kernel support [39, 1, 68], linker
support [73], compiler-based techniques [12, 14, 72],
and binary rewriting [39, 15]. A number of studies
have investigated attacks against poorly-randomized pro-
grams, including brute forcing [67], partial pointer over-
writes [23], and return-oriented programming [64, 61].
Our ASR design is more ﬁne-grained than existing tech-
niques and robust against these attacks and information
leakage.
In addition, none of the existing approaches
can support stateful live rerandomization. The general
idea of randomization has also been applied to instruc-
tion sets (to thwart code injection attacks) [38, 58, 34],
data representation (to protect noncontrol data) [13], data
structures (to mitigate rootkits) [46], memory allocators
(to protect against heap exploits) [53]. Our struct layout
randomization is similar to the one presented in [46], but
our ASR design generalizes this strategy to the internal
layout of any memory object (including code) and also
Figure 7: The probability that state-of-the-art
tech-
niques [64] can successfully generate ROP payloads to
call linked functions or perform attacker-controlled arbi-
trary memory writes. The (ﬁtted) distribution is plotted
against the number of known functions in the program.
into-libc/text, in turn, requires the attacker to learn the
location of N chosen functions in both cases, because
our function layout randomization has no effect.
Things are different in more general ROP-based at-
tacks. Our strategy completely hinders these attacks by
making the location of the gadgets inside a function un-
predictable. Given that individual gadgets cannot have
their address taken and function pointer arithmetic is
generally disallowed in a program, the location of a gad-
get cannot be explicitly leaked. This makes informa-
tion leakage attacks ineffective in acquiring any useful
knowledge for ROP-based exploitation. In contrast, prior
techniques only require the attacker to learn the address
of any N functions with useful gadgets to mount a suc-
cessful ROP-based attack. To estimate N, we made an
analysis on GNU coreutils (v7.4), building on the re-
sults presented in [64]. Figure 7 correlates the number
of program functions with the probability of locating all
the necessary ROP gadgets, and shows, for example, that
learning 16 function addresses is sufﬁcient to carry out
an attack in more than 80% of the cases.
Another interesting question is: “How fast can the
attacker acquire the required information?”. Our live
rerandomization technique can periodically invalidate
the knowledge acquired by an attacker probing the
system (e.g., using an arbitrary kernel memory read).
Shacham et al. [67] have shown that rerandomization
slows down single-target probing attacks by only a fac-
tor of 2. As shown in Table 2, however, many attacks
require knowledge of multiple targets when ﬁne-grained
ASR is in place. In addition, other attacks (e.g., Heap
Feng Shui) may require multiple probing rounds to as-
sert intermediate system states. When multiple rounds
are required, the attacker is greatly limited by our reran-
domization strategy because any knowledge acquired is
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 4 8 16 32 64 128 0 20 40 60 80 100 120 140P(ROP Payload)Average Source File Size (KBytes)Number of Functions P(ROP Payload) - Call/Store Average Source File Sizeallows live layout rerandomization. Finally, randomiza-
tion as a general form of diversiﬁcation [26] has been
proposed to execute multiple program variants in parallel
and detect attacks from divergent behavior [20, 62, 63].
Operating system defenses. Prior work on OS de-
fenses against memory exploits focuses on control-ﬂow
attacks. SecVisor [65] is a hypervisor-based solution
which uses memory virtualization to enforce W⊕X pro-
tection and prevent code injection attacks. Similarly,
NICKLE [60] is a VMM-based solution which stores au-
thenticated kernel code in guest-isolated shadow mem-
ory regions and transparently redirects execution to these
regions at runtime. Unlike SecVisor, NICKLE can sup-
port unmodiﬁed OSes and seamlessly handle mixed ker-
nel pages with code and data. hvmHarvard [28] is a
hypervisor-based solution similar to NICKLE, but im-
proves its performance with a more efﬁcient instruction
fetch redirection strategy at the page level. The idea of
memory shadowing is also explored in HookSafe [69], a
hypervisor-based solution which relocates kernel hooks
to dedicated memory pages and employs a hook indi-
rection layer to disallow unauthorized overrides. Other
techniques to defend against kernel hook hijacking have
suggested dynamic monitoring strategies [74, 57] and
compiler-based indirection mechanisms [44]. Finally,
Dalton et al. [21] present a buffer overﬂow detection
technique based on dynamic information ﬂow tracking
and demonstrate its practical applicability to the Linux
kernel. None of the techniques discussed here provides
a comprehensive solution to OS-level attacks. Remark-
ably, none of them protects noncontrol data, a common
target of attacks in local exploitation scenarios.
Live rerandomization. Unlike our solution, none of
the existing ASR techniques can support live rerandom-
ization with no state loss. Prior work that comes closest
to our live rerandomization technique is in the general
area of dynamic software updating. Many solutions have
been proposed to apply run-time updates to user pro-
grams [51, 47, 8, 19] and operating systems [48, 10, 9].
Our rerandomization technique shares with these solu-
tions the ability to modify code and data of a running sys-
tem without service interruption. The fundamental dif-
ference is that these solutions apply run-time changes in
place, essentially assuming a ﬁxed memory layout where
any state transformation is completely delegated to the
programmer. Our solution, in contrast, is generic and
automated, and can seamlessly support arbitrary mem-
ory layout transformations between variants at runtime.
Other solutions have proposed process-level run-time up-
dates to release some of the assumptions on the memory
layout [30, 31], but they still delegate the state transfer
process completely to the programmer. This completely
hinders their applicability in live rerandomization scenar-
ios where arbitrary layout transformations are allowed.
9 Conclusion
In this paper, we introduced the ﬁrst ASR design for op-
erating systems. To fully explore the design space, we
presented an analysis of the different constraints and at-
tack models inside the OS, while highlighting the chal-
lenges of OS-level ASR. Our analysis reveals a funda-
mental gap with long-standing assumptions in existing
application-level solutions. For example, we show that
information leakage, traditionally dismissed as a rela-
tively rare event, becomes a major concern inside the OS.
Building on these observations, our design takes the ﬁrst
step towards truly ﬁne-grained ASR for OSes. While our
prototype system is targeted towards component-based
OS architectures, the principles and the techniques pre-
sented are of much more general applicability. Our tech-
nique can also be applied to generic user programs, im-
proving existing application-level techniques in terms of
both performance and security, and opening up opportu-
nities for third-generation ASR systems. The key to good
performance (and no impact on the distribution model)
is our link-time ASR strategy used in combination with
live rerandomization. In addition, this strategy is more
portable and much safer than existing techniques, which
either rely on complex binary rewriting or require a sub-
stantial amount of untrusted code exposed to the runtime.
In our technique, the complex rerandomization code runs
completely sandboxed and any unexpected run-time er-
ror has no impact on normal execution. The key to good
security is the better randomization granularity combined
with periodic live rerandomization. Unlike existing tech-
niques, we can (re)randomize the internal layout of mem-
ory objects and periodically rerandomize the system with
no service interruption or state loss. These properties are
critical to counter information leakage attacks and truly
maximize the unobservability of the system.
10 Acknowledgments
We would like to thank the anonymous reviewers for
their insightful comments. This work has been supported
by European Research Council under grant ERC Ad-
vanced Grant 2008 - R3S3.
References
[1] ASLR:
leopard
versus
http://blog.
laconicsecurity.com/2008/01/aslr-leopard-versus-
vista.html.