regression line. The ﬁgure shows the standard deviation
logically varies depending on the fraction of clusters used.
That is, increasing the number of points used to compute
the ﬁt decreases the number of clusters left for value
estimation, making estimation errors more noticeable for
smaller clusters. However, although for some clusters of
links the traﬃc prediction estimates can be oﬀ by a large
margin (e.g., predicting traﬃc to be 5MB when it was
close to 1MB yields an error of 500%), the ﬁgure shows
that the mean value remains relatively stable around 0.5,
indicating that, on average, the median estimated traﬃc (in
megabytes) diﬀers from the cluster’s real value by ≈50%.
While we acknowledge that order of magnitude is a coarse
approximation, we argue this is a valuable ﬁrst step at
inferring traﬃc volumes that are not directly measurable
at scale or without access to a collection of proprietary data
(e.g., Arbor Network’s collection of inter-domain traﬃc data
from some 110 commercial networks [33]). For instance, the
approximate nature of alternative methods that formulate
inter-domain traﬃc estimation as a matrix completion prob-
lem [24] is largely unknown.
0.050.100.150.200.250.300.35(Connectivity)1/450100150200250(Trafﬁc)1/4r=0.889,r2=0.789−3−2−1012log10(ControlValue)50100150200250(Trafﬁc)1/4r=0.871,r2=0.7590.000.050.100.150.200.250.300.35(GlobalChoice)1/450100150200250(Trafﬁc)1/4r=0.808,r2=0.65345678910Radius2Integration50100150200250(Trafﬁc)1/4r=0.909,r2=0.8260123456(ALTP-frequency)1/450100150200250(Trafﬁc)1/4r=0.982,r2=0.9650.050.100.150.200.250.300.35(Connectivity)1/450100150200250300(Trafﬁc)1/4r=0.954,r2=0.911−3−2−1012log10(ControlValue)50100150200250(Trafﬁc)1/4r=0.866,r2=0.7500.050.100.150.200.250.300.35(GlobalChoice)1/4100150200250(Trafﬁc)1/4r=0.950,r2=0.903345678910Radius2Integration50100150200250300(Trafﬁc)1/4r=0.793,r2=0.6290123456(ALTP-frequency)1/450100150200250300(Trafﬁc)1/4r=0.979,r2=0.9588traceroute dataset and rank those links a second time, based
on the selected Network Syntax metric. As before, to reduce
the potential noise introduced by the ranking of individual
AS-links, we cluster them in equal-sized groups (ten in this
case). For each group, we compute its ranking for both the
relative Network Syntax metric and carried traﬃc, as the
average of the individual rankings of the AS-links within the
group. Given the strong correlation between the diﬀerent
Network Syntax metrics and traﬃc volume, potentially any
of the metrics could be used to rank the links. For this
analysis we select the two metrics with the highest degree of
correlation: connectivity and ALTP-frequency, and compare
their results.
Figures 15 and 16 show the correlation between traﬃc-
based ranking and connectivity or ALTP-frequency respec-
tively, for both IXP and IXP . The ﬁgures show strong r2
for all four dataset using both Network Syntax metrics.
However ALTP-frequency r2 values are slightly higher than
their connectivity counterpart, with values as high as 0.95 in
the case of ISP and 0.75 in the case of IXP . Regardless, the
results from this analysis show that using Network Syntax
metrics to rank AS-links can be eﬀectively used to rank links
based on the amount of traﬃc they carry.
7. DISCUSSION
In this section, we elaborate on three critical issues: (i)
wether the application of Network Syntax analysis to AS-
level connectivity graphs derived from BGP data works as
intended, (iii) the robustness of the approach to the known
pitfalls of IP-to-AS level mapping for AS topology inference
when using traceroute datasets, and (iii) the impact of
diﬀerent traceroute dataset characteristics on the results
from Network Syntax metrics.
7.1 BGP-derived connectivity-graphs
As we discussed in Section 3.2, Network Syntax can not be
applied to just any AS-level connectivity graph but depends
on the information embedded in the graph inferred from
traceroute datasets. To illustrate this we apply Network
Syntax to the connectivity graph for ISP derived from
the subset of AS-level paths contained in the public BGP
view [5] for April 2011. Speciﬁcally, we extract all the
BGP announcements that contain the AS number for ISP ,
derive their corresponding AS-level paths, and generate the
connectivity-graph. We then compute the diﬀerent Network
Syntax metrics and evaluate our ﬁndings in the context
of the ground-truth traﬃc data for ISP for same time
period. As in Section 5, we ﬁrst rank the links based on the
corresponding metric and create clusters of ten links before
examining the correlation.
Figure 17 shows the results of our analysis for the subset
of 2,016 links identiﬁed in the dataset for the connectivity,
control value, global choice and integration metrics. Since
this analysis is based on AS-level paths extracted from
BGP announcements, no traceroute probes were available
to compute the ALTP-frequency metric.
The ﬁgure shows that, as anticipated, none of the met-
rics are strongly correlated with traﬃc volume.
In most
cases, links are clustered together either on the lower left
side of the plot (corresponding to low traﬃc volume and
nearly identical Network Syntax metric) as is the case in
Figures 17c, 17b and 17c, or mostly grouped on the right
lower side of the plot (which corresponds to high Network
Figure 12: Correlation between ALTP-frequency and traﬃc
volume for ISP for April 2013 with clusters of size 5.
Figure 13: Traﬃc prediction using ALTP frequency.
Figure 14: Traﬃc prediction using ALTP frequency.
6.2 Ranking AS-Links based on Trafﬁc Vol-
ume
As our second use case, we show that ranking AS-links
based on diﬀerent Network Syntax metrics can be used as a
proxy for the traﬃc-volume based ranking of those links.
For this analysis, we start by ranking the AS-links based
on the amount of traﬃc they carry using our ground-truth
traﬃc. We then select the subset of links identiﬁed on our
0123456(ALTP-frequency)1/450100150200250300350(Trafﬁc)1/4r=0.909,r2=0.827012Orderofmagnitudedifference(actual/predicted)02040608010072.727.30.072.627.40.074.825.20.074.825.20.075.724.30.0657075808560657075808590pctclusterstocomputeﬁt0.00.20.40.60.81.0meandeviationfromrealvalue9(a) IXP April 2011
(b) IXP April 2013
(c) ISP April 2011
(d) ISP April 2013
Figure 15: Ranking based on connectivity and traﬃc volume.
(a) IXP April 2011
(b) IXP April 2013
(c) ISP April 2011
(d) ISP April 2013
Figure 16: Ranking based on ALTP-frequency and traﬃc volume.
(a) Connectivity
(b) Control Value
(c) Global Choice
(d) Integration
Figure 17: Correlation between Network Syntax metrics and traﬃc volume (BGP dataset) for ISP April 2011.
Syntax metric and low traﬃc volume) in the case of 17d.
The seemingly moderately strong r2 values are mostly driven
by a few outliers, but it is apparently clear from the ﬁgures
that the cluster of links are not cleanly distributed around
the regression line (in contrast to Figures 10 and 11). This
analysis shows that it is the data-plane and not the control-
plane perspective that is relevant for Network Syntax.
7.2 Errors in traceroute-to-AS mappings
The pitfalls of IP-to-AS level mapping for AS topology
inference are well-known. The common approach of using
longest preﬁx matching to map the routers’ IP addresses of a
traceroute to AS numbers is known to generate potentially
false AS links [49]. Several previous research eﬀorts have
studied these pitfalls [15,17,29,36,37] and identiﬁed common
causes for the mismatch which range from the incomplete-
ness of IP-to-AS mappings gathered from publicly available
BGP feeds, to the constraints inherent to the traceroute
measurement itself (e.g., routers silently dropping probes or
not altering packets’ TTL). We correct our datasets to avoid
these pitfalls, as described in Section 4.2.
In this section we explore the robustness of Network
Syntax when applied to traceroute datasets with some of
these well known problems. We do this by computing the
diﬀerent Network Syntax metrics on the un-corrected April
−1012345Degreepathranking×10+3010002000300040005000Trafﬁcrankingr=0.810,r2=0.656−101234Degreepathranking×10+301000200030004000Trafﬁcrankingr=0.709,r2=0.502−0.50.00.51.01.52.02.53.0Degreepathranking×10+2050100150200250Trafﬁcrankingr=0.964,r2=0.9300.00.51.01.5Degreepathranking×10+220406080100120140Trafﬁcrankingr=0.949,r2=0.900−10123456AS-levelpathranking×10+30100020003000400050006000Trafﬁcrankingr=0.866,r2=0.750−1012345AS-levelpathranking×10+3010002000300040005000Trafﬁcrankingr=0.812,r2=0.6590.00.51.01.52.02.53.0AS-levelpathranking×10+2050100150200250300Trafﬁcrankingr=0.987,r2=0.9750.00.51.01.5AS-levelpathranking×10+220406080100120140Trafﬁcrankingr=0.987,r2=0.9740.050.100.150.200.250.30(Connectivity)1/4050100150200250(Trafﬁc)1/4r=0.632,r2=0.399−4−202log10(ControlValue)050100150200(Trafﬁc)1/4r=0.792,r2=0.627−0.10.00.10.20.30.4(GlobalChoice)1/4050100150200250(Trafﬁc)1/4r=0.681,r2=0.46489101112Radius2Integration050100150200(Trafﬁc)1/4r=0.336,r2=0.11310(a) Connectivity
(b) Control Value
(c) Global Choice
(d) Integration
(e) ALTP-frequency
Figure 18: Correlation between connectivity, control value, global choice , local integration metric (integration radius 2) and
ALTP-frequency with traﬃc volume for ISP for April 2011 using the CAIDA traceroute dataset.
(a) IXP April 2011
(b) IXP April 2013
(c) ISP April 2011
(d) ISP April 2013
Figure 19: Correlation between ALTP-frequency and traﬃc volume for IXP and ISP using CAIDA datasets.
False AS links problems
Internet eXchange Points (IXPs)
Sibling ASes
Unannounced IP addresses
Using outgoing interface IPs
Private peering interface IPs
Table 3: Summary of problems within traceroute-inferred
AS-level paths addressed by the ﬁltering heuristics proposed
in [17].
Ono April 2011
1. Repeated Hop
2. Unk Hop in Path
3. Unk Src or Dst ASN
4. Path too Short
19%
47%
5%
30%
Table 4: Percentage of probes dropped by each of the
extraction rules.
2011 traceroute dataset for ISP and comparing the resulting
correlation with the corrected version.
To generate this alternative dataset we apply the same
basic traceroute sanitation process described in Section 4.2
but stop before the application of the correction heuristics
described in [17], wich we summarize in Table 3. The
basic sanitation process conservatively discards ≈61% of our
initial dataset and reduces the number of probes to 12.9M.
Table 4 presents a summary of the fraction of traceroutes
dropped by each of our basic sanitation rules.
Un-corrected Corrected
Connectivity
Control Value
Global Choice
Integration
ALTP-frequency
0.759
0.708
0.314
0.749
0.919
0.789
0.759
0.653
0.826
0.965
Table 5: r2 values of the diﬀerent metrics for ISP using the
April 2011 dataset.
Table 5 presents a comparison of the r2 values for the
diﬀerent metrics when Network Syntax is applied to the
connectivity graphs that result from both the un-corrected
and corrected versions of the dataset. The results show that
the application of the diﬀerent correction heuristics does
improve correlation between traﬃc volume an the diﬀerent
metrics, but most metrics (with the exception of global
choice) still show signiﬁcant r2 values when computed using
the un-corrected dataset.
When comparing both the corrected and un-corrected
datasets, we note that the amount of traceroutes modiﬁed
by the diﬀerent correction heuristics accounts for ≈16% of
the probes; which ultimately map to approximately 6% of
the end-to-end AS-level in the dataset. The results from
Table 5 highlight the robustness of Network Syntax when
identifying popular AS-links in the presence of mis-mapped
paths in the underlaying connectivity-graph.
0.10.20.30.40.5(Connectivity)1/450100150200250(Trafﬁc)1/4r=0.844,r2=0.713−3−2−1012log10(ControlValue)406080100120140160180(Trafﬁc)1/4r=0.848,r2=0.7190.00.10.20.30.40.5(GlobalChoice)1/450100150200(Trafﬁc)1/4r=0.889,r2=0.791456789Radius2Integration406080100120140160180(Trafﬁc)1/4r=0.858,r2=0.737012345(ALTP-frequency)1/4050100150200250(Trafﬁc)1/4r=0.910,r2=0.829−0.50.00.51.01.52.0AS-levelpathranking×10+3050010001500Trafﬁcrankingr=0.717,r2=0.514−0.50.00.51.01.52.0AS-levelpathranking×10+32004006008001000120014001600Trafﬁcrankingr=0.634,r2=0.402−10123456AS-levelpathranking×10+20100200300400500600Trafﬁcrankingr=0.819,r2=0.671−202468AS-levelpathranking×10+20100200300400500600700Trafﬁcrankingr=0.855,r2=0.731117.3 Other datasets
We have shown that applying Network Syntax metrics
to AS-level connectivity graphs using paths extracted from
massive traceroute datasets reveals a strong correlation
between traﬃc volume and the diﬀerent metrics. We
now apply the same technique to a diﬀerent dataset, one
collected from CAIDA’s Ark monitors for the same time
periods. This tracerotue dataset consist of probes launched
towards randomly selected IP addresses from CAIDA’s Ark
monitors [12] which probe IP addresses from every routable
IPv4 /24 preﬁx in cycles of approximately 48 hours. For
this analysis, we combined data from three diﬀerent probing
cycles completed by diﬀerent sets of Ark monitors between
April 1-7, 2011 and April 1-7, 2013.
Figure 18 shows a comparison of the correlation between
traﬃc volume and the diﬀerent Network Syntax metrics for
the CAIDA 2011 dataset for ISP 7. The observed trends
are similar to those seen in Section 5.2, where the amount
of traﬃc carried by the clustered links strongly correlates
with the diﬀerent Network Syntax metrics. Additionally,
Figure 19 shows a comparison of the correlation of AS-link
ranking based on traﬃc volume versus ranking based on
ALTP-frequency, using the CAIDA dataset for both IXP
and ISP . The same trends as those seen in Section 6.2 can
be observed for both network entities, with clusters of links
carrying larger amounts of traﬃc corresponding to higher
ALTP-frequency links.
Even though in both cases the correlations can still be
observed, the r2 values are smaller than their Ono-dataset
counterpart. We argue that this is due to a fundamental
diﬀerence on how the underlaying traceroutes were collected.
As Table 6 shows, although the tracerotues of both the
Ono and CAIDA datasets contain millions of traceroutes
launched against a large number of diﬀerent destination
ASes; there is a 2-order of magnitude diﬀerence in the
number of source ASes from where the probes were launched.
Even though the correlation is still present, the r2 values
are smaller than their Ono-dataset counterpart. We argue
that this is due to a fundamental diﬀerence on how the
underlaying traceroutes were collected. As Table 6 shows,
although the tracerotues of both the Ono and CAIDA
datasets contain millions of traceroutes launched against a
large number of diﬀerent destination ASes; there is a 2-order
of magnitude diﬀerence in the number of source ASes from
where the probes were launched.
As discussed in [34], one consequence of taking measure-