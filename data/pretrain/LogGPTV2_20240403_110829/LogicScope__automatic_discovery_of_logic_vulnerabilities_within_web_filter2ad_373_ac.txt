Phase III: Testing
Trace Collector
(WebScarab Proxy)
Web Server
Session Inspector
Session Exporter
Spec Analzyer
Symbolizer
FSM Analyzer
TestSpec Generator
SessionProfile
RequestProfile
TemplateProfile
DriverSpec
TestSpec
Testing Engine
Web Server
State Driver
Testing Controller
Symbolizer
Session Inspector
Session Exporter
LoginProfile
InputProfile
Output 
Evaluator
Request Generator
Login Helper
Figure 4: Prototype System Architecture
Testing Engine instantiates test input vectors into con-
crete web requests (i.e, Request Generator ), feed them into
the application and evaluate the corresponding web responses
for vulnerability identiﬁcation (i.e., Output Evaluator ). In
particular, Testing Controller is in charge of the entire test-
ing procedure. State Driver computes the path leading to
the target test state by feeding a sequence of input sym-
bols to trigger the state transition step by step. When Re-
quest Generator instantiates input symbols, it is aware of
the parameter value type and leverages pre-loaded Input-
Proﬁle and Login Helper to generate meaningful parameter
values.
5. EVALUATION
We select six real-world PHP web applications to evaluate
our prototype system LogicScope. We deploy all web appli-
cations on a 2.13GHz Core 2 Linux server with 2GB RAM,
running Ubuntu 10.10, Apache web server (version 2.2.16)
and PHP (version 5.3.3). To facilitate trace collection, we
developed user emulators for each application based on Sele-
nium WebDriver. The user emulator will initiate a browser
instance and automate the procedure of operating the web
application, through performing a sequence of actions by
following navigation links.
LogicScope ﬁrst collects traces with the help of user em-
ulators and performs speciﬁcation inference. Table 1 shows
the statistics of collected traces and inferred FSM, including
the number of ﬁles, collected web requests, web responses,
session variables, states, input and output symbols. Then,
LogicScope launches the testing process against each appli-
cation and also gives concrete attack vectors and evidences
for manual inspection. We manually analyze the reported
vulnerabilities and classify them into either true vulnerabil-
ity or false positive. Table 2 shows the testing results, in-
cluding the number of test input vectors generated by each
method (FB for forceful browsing; PM for parameter manip-
ulation), reported attack instances, real attack vectors and
485false positives (i.e., FP). We also compare the discovered
vulnerabilities with the known vulnerabilities from public
sources and report the false negatives (i.e., FN). In sum-
mary, we generate 233 test input vectors for all the appli-
cations and get 25 attack instances reported, among which,
18 are real attack vectors and 7 are false positives. Detailed
results can be found in the technical report version [8].
Table 1: Summary of Traces and Inferred FSM (#)
Application Files Web
req.
1348
2104
1290
21
52
37
Scarf
Wackopicko
Events
Lister
Bloggit
openInvoice
OpenIT
24
25
25
2657
1138
1462
Web
resp.
1346
1650
1287
2645
1083
1453
Session
var.
3
1
2
State Input
symb.
31
18
25
3
2
2
Output
symb.
15
7
11
1
5
5
2
5
5
18
73
16
23
11
6
App
Scarf
Table 2: Summary of Testing Results (FB: forceful
browsing, PM: parameter manipulation)
Real
attack
0
8
2
0
0
Method Test
input
5
44
5
16
0
FB
PM
Wackopicko FB
PM
FB
Flagged
attack
1
9
2
0
0
FP FN
Events
Lister
1
1
0
0
0
0
0
1
0
0
Bloggit
PM
FB
PM
openInvoice FB
PM
FB
PM
OpenIT
Summary
25
6
20
19
28
3
62
233
4
2
0
4
0
3
0
25
2
0
0
4
0
2
0
18
2
2
0
0
0
1
0
7
0
0
1
0
0
0
0
2
6. RELATED WORKS
The key issue to address web application logic ﬂaws is to
infer the application logic speciﬁcation. Waler [4] and Sun
et al.
[12] require application source code for analysis or
instrumentation. In contrast, our approach is source code
free. Second, Waler [4] can only identity violations of value-
related invariants and NoTamper [1] only models the ap-
plication logic behind form processing and validation. Our
approach characterizes the application logic in a more gen-
eral manner and can deal with a broader range of logic ﬂaws.
Furthermore, Swaddler [3], BLOCK [7] and SENTINEL [9]
directly leverage the speciﬁcation to detect attacks at run-
time, while we have to construct testing cases for vulnera-
bility exploitation in addition to speciﬁcation inference.
Our work is also related to an array of fuzing testing
works (FLAX [11], DART [5], SAGE [6], Kudzu [10]), which
aim to achieve better coverage for discovering vulnerabili-
ties through guided/directed test input generation. All of
the above works require application source code, while our
test input generation is based on a speciﬁcation inferred in
a black-box manner.
7. SUMMARY
In this paper, we present a systematic black-box approach
to identifying logic ﬂaws within web applications, implement
and evaluate a prototype system LogicScope to demonstrate
the eﬀectiveness of our approach. We also would like to point
out several limitations. First, LogicScope can not handle
AJAX web applications. Second, LogicScope has limited ca-
pability in handling complex relationships/constraints within
the database.
8. ACKNOWLEDGMENTS
This work was supported by NSF TRUST (The Team
for Research in Ubiquitous Secure Technology) Science and
Technology Center (CCF-0424422).
9. REFERENCES
[1] P. Bisht, T. Hinrichs, N. Skrupsky, R. Bobrowicz, and
V. N. Venkatakrishnan. NoTamper: automatic
blackbox detection of parameter tampering
opportunities in web applications. In CCS’10, pages
607–618, 2010.
[2] Citigroup credit card information leakage in 2011.
http://www.wired.com/threatlevel/2011/06/citibank-
hacked/.
[3] M. Cova, D. Balzarotti, V. Felmetsger, and G. Vigna.
Swaddler: An Approach for the Anomaly-based
Detection of State Violations in Web Applications. In
RAID’07, pages 63–86, 2007.
[4] V. Felmetsger, L. Cavedon, C. Kruegel, and G. Vigna.
Toward Automated Detection of Logic Vulnerabilities
in Web Applications. In USENIX’10, pages 143–160,
2010.
[5] P. Godefroid, N. Klarlund, and K. Sen. Dart: directed
automated random testing. In PLDI’05, pages
213–223, 2005.
[6] P. Godefroid, M. Y. Levin, and D. A. Molnar.
Automated whitebox fuzz testing. In NDSS’08, 2008.
[7] X. Li and Y. Xue. BLOCK: A Black-box Approach for
Detection of State Violation Attacks Towards Web
Applications. In ACSAC’11, pages 247–256, 2011.
[8] X. Li and Y. Xue. LogicScope: Automatic Discovery
of Logic Vulnerabilities within Web Applications.
Technical report, Vanderbilt University ISIS, 2012.
[9] X. Li, W. Yan, and Y. Xue. SENTINEL: securing
database from logic ﬂaws in web applications. In
CODASPY ’12, pages 25–36, 2012.
[10] P. Saxena, D. Akhawe, S. Hanna, F. Mao,
S. McCamant, and D. Song. A symbolic execution
framework for javascript. In Oakland’10, pages
513–528, 2010.
[11] P. Saxena, S. Hanna, P. Poosankam, and D. Song.
FLAX: Systematic Discovery of Client-side Validation
Vulnerabilities in Rich Web Applications. In NDSS’10,
2010.
[12] F. Sun, L. Xu, and Z. Su. Static Detection of Access
Control Vulnerabilities in Web Applications. In
USENIX’11, pages 11–11, 2011.
486