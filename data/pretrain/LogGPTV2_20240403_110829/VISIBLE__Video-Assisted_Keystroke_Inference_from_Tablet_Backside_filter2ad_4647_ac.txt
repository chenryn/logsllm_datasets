|aij|2 ,
i=1
j=1
which is the square root of the squared sum of the
matrix elements.
Pearson correlation. The Pearson correlation measures
the correlation of the motion vectors of different
AOIs during the same typing process. For two motion
vectors Vi and Vj of two AOIs i and j, respectively,
the Pearson correlation is deﬁned as
cov(Vi, Vj)
Pij =
,
σiσj
n(cid:88)
j=1
(cid:118)(cid:117)(cid:117)(cid:116) m(cid:88)
n(cid:88)
where cov(Vi, Vj) is the covariance between Vi and
Vj, and σi and σj are the standard deviation of Vi
and Vj, respectively.
G. Classiﬁer Training
To train a classiﬁer, we ﬁrst reconstruct the attack scenario
from the images taken in the video recording phase using
standard distance and angle estimation algorithms such as [29].
We then let multiple attackers type on every key position of
the soft keyboard for multiple times, during which we record
the videos of the tablet backside as well as the typed keys.
We ﬁnally obtain the training data set consisting of N KM
samples, where N is the number of attackers that mimic the
victim, K is the number of keys on the soft keyboard, and M
is the number of times each key is typed by each attacker.
(a) One-hop and two-hop neighbors of letters "a" and "j".
(b) One-hop neighbors of keys 1 and 8.
Fig. 8. Examples of one and two-hop neighbors on alphabetical and PIN keyboards.
5. What are the impacts of environmental factors (e.g.,
the light conditions, the angle between the tablet and
the camcorders, and the imperfect reconstruction of
attack scenario) on keystroke inference accuracy?
A. Experiment Design
In our experiment, we used two commercial off-the-shelf
(COTS) camcorders to video-record the tablet backside during
the victim’s typing process. One camcorder is a Panasonic HC-
V700 with 21× zoom lens, which can record 1080p60 HD
videos and feature an intelligent zoom function that supports
up to 46× zoom. The second camcorder is a Sony FDR-AX100
with 10× zoom lens, which can record 4Kp302 or 1080p60
HD videos and support up to 160× zoom.
We placed an Apple iPad 2 tablet with iOS 8 on a holder as
shown in Fig. 4(b) and two camcorders 1.8 meters away from
the tablet. The distance between the attacker’s camcorders and
the victim’s tablet can be increased as long as the attacker
is equipped with more advanced lens (e.g., telephoto lens)
to video-record the tablet backside at a distance. The angle
between each camcorder and the tablet was 90 degree by
default, and we evaluated the impact of different angles as well.
The two camcorders focused on the left-half and right-half
of the tablet backside, respectively. We simultaneously used
two camcorders because one camcorder cannot simultaneously
include all the AOIs and have sufﬁciently high resolution for
each AOI.
Let Ωh(i) be key i’s h-hop neighborhood, including key i
itself. As two examples, Fig. 8(a) shows the one-hop and two-
hop neighbors of letters "a" and "j", where the orange and
yellow keys (marked by triangle and square) are the one-hop
and two-hop neighbors, respectively. Fig. 8(b) shows the one-
hop neighbors of keys 1 and 8, where the green and orange
keys (marked by triangle and rectangle) are the neighbors of
key 1 and key 8, respectively.
We use the following two metrics to evaluate the inference
accuracy of VISIBLE.
•
•
Pinpoint accuracy Pi. The probability that a key i
typed by the victim is correctly inferred as i.
h-hop accuracy P h
by the victim is inferred as some key in Ωh(i).
i . The probability that a key i typed
By letting Ω0(i) = {i}, we can see that the pinpoint accuracy
is a special case of h-hop accuracy, as Pi = P 0
i . We consider
24Kp30 denotes that the camcorder can take 3840 × 2160 video at a rate
of 30 frames per second.
Fig. 9.
Impact of the training set size.
both pinpoint and h-hop accuracies for two reasons. First, the
capability of narrowing down a typed key to a small area
still poses a serious threat to user privacy, as the attacker
can still learn sensitive information. Second, considering the
neighborhood of a key instead of only the key itself is
particularly important for word and sentence inference, as we
will see shortly. In this paper, we consider h = 0, 1, 2, and 3
for alphabetical keyboard and h = 0 and 1 for PIN keyboard.
B. Alphabetical Keyboard Experiment
We ﬁrst report the performance of VISIBLE on the alpha-
betical keyboard of an iPad 2 tablet with iOS 8, on which
keystroke inference is challenging for two reasons. First, the
distance between two adjacent keys is very small, while we
need to distinguish at least 26 different keys. Second, the
alphabetical keyboard is usually located at the bottom of the
touchscreen which makes the motions caused by keystrokes
less noticeable.
In this experiment, we involved four participants and let
each participant type each English letter 20 times and collected
20 × 26 × 4 = 2080 keystrokes in total. We selected a portion
of data from the collected dataset as a training set and used
the rest of the collected data as a test set. We trained a multi-
class SVM classiﬁer using the training set and then tested it
using the test set. We used 10-fold cross-validation to test the
performance of the key inference of VISIBLE.
Table I compares the pinpoint and h-hop accuracies of
VISIBLE and random guess for each English letter on the
alphabetical keyboard. We can see that the pinpoint accuracy
8
1425709810%30%50%70%90%0.00.20.40.60.81.0Inference accuracyTraining set size Pinpoint accuracy One-hop accuracy Two-hop accuracy Three-hop accuracyTABLE I.
KEY INFERENCE RESULTS FOR ALPHABETICAL KEYBOARD, WHERE VIS AND RG DENOTE VISIBLE AND RANDOM GUESS, RESPECTIVELY.
Key
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
Avg.
Pi
VIS
RG
33.8% 3.84%
36.3% 3.84%
52.5% 3.84%
21.3% 3.84%
22.5% 3.84%
27.5% 3.84%
25.0% 3.84%
16.3% 3.84%
21.3% 3.84%
20.0% 3.84%
22.5% 3.84%
42.5% 3.84%
50.0% 3.84%
31.3% 3.84%
41.3% 3.84%
47.5% 3.84%
30.0% 3.84%
40.0% 3.84%
28.8% 3.84%
30.0% 3.84%
51.3% 3.84%
45.0% 3.84%
31.3% 3.84%
41.3% 3.84%
27.5% 3.84%
77.5% 3.84%
36.2% 3.84%
|Ω1(i)|
5
5
5
8
6
8
8
8
6
8
7
5
4
5
5
3
4
6
8
6
6
6
6
6
6
4
5.9
P 1
i
VIS
RG
78.8% 19.2%
78.8% 19.2%
71.3% 19.2%
91.3% 30.7%
70.0% 23.0%
91.3% 30.7%
88.8% 30.7%
95.0% 30.7%
85.0% 23.0%
83.8% 30.7%
88.8% 26.9%
85.0% 19.2%
80.0% 15.4%
77.5% 19.2%
88.8% 19.2%
81.3% 11.5%
70.0% 15.4%
80.0% 23.0%
76.3% 30.7%
86.3% 23.0%
97.5% 23.0%
83.8% 23.0%
72.5% 23.0%
92.5% 23.0%
81.3% 23.0%
98.8% 15.4%
83.6% 22.7%
|Ω2(i)|
8
14
14
14
14
14
14
14
11
13
11
9
11
13
8
7
8
14
11
14
13
12
11
11
12
9
11.7
P 2
i
VIS
RG
95.0% 30.7%
98.8% 53.8%
93.8% 53.8%
98.8% 53.8%
98.8% 53.8%
98.8% 53.8%
98.8% 53.8%
100% 53.8%
100% 42.2%
98.8% 49.9%
98.8% 42.2%
100% 34.6%
98.8% 42.2%
97.5% 49.9%
98.8% 30.7%
98.8% 26.9%
90.0% 30.7%
95.0% 53.8%
95.0% 42.2%
97.5% 53.8%
100% 49.9%
98.8% 46.1%
95.0% 42.2%
100% 42.2%
98.8% 46.1%
100% 34.6%
97.9% 44.9%
|Ω3(i)|
11
18
18
17
17
20
20
19
14
17
14
12
15
17
11
8
11
20
14
20
17
19
14
15