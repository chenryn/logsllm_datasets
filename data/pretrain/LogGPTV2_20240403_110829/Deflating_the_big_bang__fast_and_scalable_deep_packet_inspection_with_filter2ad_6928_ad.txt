state
38.67
21.48
15.91
12.35
5.20
10.48
ctrs
gen/imp
8/38
10/21
0/15
0/12
0/3
0/10
Inst/
state
4.18
1.59
1.24
2.65
0.34
0.69
Rule set
Snort FTP
Snort SMTP
Snort HTTP
Cisco FTP
Cisco SMTP
Cisco HTTP
bits
8
11
172
11
8
13
ctrs
8/38
10/21
0/15
0/12
0/3
0/10
bits
8
6
171
10
8
12
ctrs
2/2
4/6
0/6
0/3
0/2
0/2
Rule set
Snort FTP
Snort SMTP
Snort HTTP
Cisco FTP
Cisco SMTP
Cisco HTTP
Inst/State
max
7
21
16
7
9
8
avg max
5
0.81
0.73
21
11
1.09
4
0.46
7
0.33
0.55
7
Inst/State
avg
0.66
0.69
1.03
0.33
0.28
0.42
(a) Opt 1: Exploit runtime information
(b) Opt 2: Coalesce independ. vars
(c) Opt 3: Instruction merging
Table 2: Consecutively applying optimizations 1, 2, and 3.
instruction 3 cannot move left because bit 4’s value is used
by instruction 2. Second, merged instructions should com-
bine bits belonging to the same word only. Thus, the task
is to move and merge as many instructions as possible while
satisfying both conditions.
In practice, we use a simple greedy heuristic that identiﬁes
many opportunities for merging. The heuristic ﬁrst identi-
ﬁes all bit assignment instructions that belong to the same
word. Next, it looks for data hazards between neighboring
pairs of assignments. When a pair with a hazard-free move-
ment direction is found, the instruction is moved along this
direction to its neighbor. The process repeats until no more
moves are performed. For each word, the optimizer merges
adjacent bits, constructs the mask, and replaces the instruc-
tions with a single bit mask instruction. This optimization
is performed last of all, after the dataﬂow analysis.
6. EXPERIMENTAL EVALUATION
6.1 Test sets and Optimizations
We evaluated XFAs on FTP, SMTP, and HTTP signa-
tures from Snort [28] and Cisco Systems. We ﬁrst produced
individual state-based XFAs from regular expressions using
the techniques described earlier. We then combined the sig-
natures in each set using Algorithm 1. Combination is fast;
the Snort HTTP set took the most time to combine at just
over seven minutes whereas all other sets required less than a
minute to combine. For comparison purposes, we built stan-
dard DFAs for each of the regular expressions and combined
these per protocol as well.
Table 1 summarizes properties of the combined XFAs. In
each test set, the top row describes the automaton before any
optimizations are performed. Columns 3 and 4 give the num-
ber of states in the combined DFA and XFA, respectively,
and illustrate the magnitude of the savings when state-space
explosion is eliminated. In some cases, the combined DFA
size may be a gross underestimate: Cisco FTP, for example,
exhausted memory after only 23 DFAs were combined. Col-
umns 5 and 6 show the number of variables used by each
test set, Columns 7 and 8 give the maximum and average
number of instructions per state, and Columns 9 and 10 give
the amount of auxiliary memory needed for storing mutable
variables and immutable programs. We used two-byte coun-
ters when computing the variable memory requirements.
We applied the three optimizations in Section 5 in con-
secutive order and show relevant results in Tables 2a, 2b,
and 2c.
In Table 2a and all subsequent tables, we use a
forward slash to separate generic and implicit counters. As
the table shows, a large fraction of generic counters were
converted to an implicit form. Since these new counters re-
quire no explicit decrement instruction, the average number
of instructions per state is considerably reduced as shown in
Columns 3 and 5. Table 2b shows the eﬀect of the analy-
ses for coalescing independent variables. In most datasets,
the analysis discovers that a signiﬁcant percentage of generic
and implicit counters can be coalesced. Note that variables
must have the same type to be considered. For example,
generic counters can be coalesced with other generic coun-
ters but not with implicit counters. For bits, the reduction
opportunities are more modest. We believe that improved
results can be obtained with a more reﬁned analysis. Finally,
Table 2c reports the results of code motion and instruction
merging applied to bit instructions. Not surprisingly, the
largest reductions come from the sets with the most bits.
Table 1 summarizes the cumulative eﬀect of the optimiza-
tions in the bottom row of each set. Figure 8 shows his-
tograms of the number of instructions per state for Snort
HTTP before and after optimization. Note the log scale on
the y-axis. After optimization, just over half of all states
have no instructions, and all remaining states have 11 or
fewer instructions. Histograms for other sets are similar.
6.2 Memory Usage and Performance
In the second set of experiments we analyze the memory
and runtime performance of XFAs when applied to traces
of live traﬃc. We wrote a translator that converts instruc-
tions on states to C source code (with a distinct function for
each state) and compiled the code to a shared library whose
Snort FTP
Snort SMTP
Snort HTTP
Multiple DFAs
D2FAs
XFAs
Multiple DFAs
D2FAs
XFAs
1e+09
1e+08
1e+07
1e+06
1e+05
)
e
l
a
c
s
g
o
l
s
e
t
y
b
(
e
g
a
s
u
y
r
o
m
e
M
10000
DFA Exec
100
1000
10000
Processing time (cycles/byte logscale)
Cisco SMTP
Multiple DFAs
D2FAs
XFAs
1e+09
1e+08
1e+07
1e+06
1e+05
)
e
l
a
c
s
g
o
l
s
e
t
y
b
(
e
g
a
s
u
y
r
o
m
e
M
10000
10
DFA Exec
100
1000
10000
10
Processing time (cycles/byte logscale)
Cisco FTP
Multiple DFAs
D2FAs
XFAs
1e+09
1e+08
1e+07
1e+06
1e+05
)
e
l
a
c
s
g
o
l
s
e
t
y
b
(
e
g
a
s
u
y
r
o
m
e
M
1e+09
1e+08
1e+07
1e+06
1e+05
)
e
l
a
c
s
g
o
l
s
e
t
y
b
(
e
g
a
s
u
y
r
o
m
e
M
Multiple DFAs
D2FAs
XFAs
DFA Exec
100
1000
10000
Processing time (cycles/byte logscale)
Cisco HTTP
Multiple DFAs
D2FAs
XFAs
1e+09
1e+08
1e+07
1e+06
1e+05
)
e
l
a
c
s
g
o
l
s
e
t
y
b
(
e
g
a
s
u
y
r
o
m
e
M
10000
10
1e+09
)
e
l
a
c
s
g
o
l
s
e
t
y
b
(
e
g
a
s
u
y
r
o
m
e
M
1e+08
1e+07
1e+06
1e+05
10000
DFA Exec
10
100
1000
10000
Processing time (cycles/byte logscale)
10000
10
DFA Exec
100
1000
10000
Processing time (cycles/byte logscale)
10000
10
DFA Exec
100
1000
10000
Processing time (cycles/byte logscale)
Figure 9: Memory versus run-time trade-oﬀs for mDFAs, D2FAs, and XFAs.
10000
1000
s
e
t
a
t
S
#
100
10
1
10000
1000
s
e
t
a
t
S
#
100
10
1
0
2
4
6
8
10 12 14 16 18 20 22 24 26 28 30 32
Instructions per State
0
2
4
6
8
10 12 14 16 18 20 22 24 26 28 30 32
Instructions per State
Figure 8: Instructions per state for Snort HTTP,
before (top) and after (bottom) optimization.
functions are linked to the appropriate state during initial-
ization. During inspection, programs are executed after the
input symbol is read and the state transition is complete.
Support for runtime information, as is used in optimization
1, is compiled into the library as well.