when network does not work well. A naive solution is to
build sketches in different sizes for the same network traffic.
For example, one can build two sketches S1, S2 with the
memory size of M and M/2, and then we can send S2 to the
collector when the available bandwidth is small. A better
solution is to build only S1, and quickly compress it into
a half. It is not hard for the compressed S1 to achieve the
same accuracy with S2. However, it is challenging for the
compressed S1 to achieve much higher accuracy than S2,
which is one design goal of this paper.
Second, it is challenging to make the processing speed
adaptive to the packet rate, which could vary drastically
during congestion or attack. Existing sketches often have
constant processing speed, but require several or even more
than 10 memory access for processing one packet. The design
goal is 2 memory accesses for processing each packet when
packet rate is low, and 1 memory access when packet rate is
high. However, it is challenging to keep high accuracy when
using only one memory access.
Third, in real network traffic, the flow size distribution is
skewed and variable. ‚ÄúSkewed‚Äù means most flows are mouse
flows [34], while a few flows are elephant flows [4, 22, 35].
To achieve memory efficiency, one can manage to separate
elephant flows from mouse flows. As elephant flows are
often more important than mouse flows, it is desirable to
assign appropriate memory size for the elephant flows. Un-
fortunately, the number of elephant flows is not known in
advance and hard to predict [39]. Therefore, it is challenging
to dynamically allocate more memory for the elephant flows.
2.2 Generic Method for Measurements
We focus on the following network measurement tasks those
have been extensively studied.
Flow Size Estimation: estimating the flow size for any flow
ID. A flow ID can be any combinations of the 5-tuple, such
as source IP address and source port, or only protocol. In this
paper, we consider the number of packets of a flow as the
flow size. This can be also used for estimating the number
of bytes for each flow: assuming the minimal packet is 64
bytes, given an incoming packet with 120 bytes, we consider
it as ‚åà 120
Heavy Hitter Detection: reporting flows whose sizes are
larger than a predefined threshold.
Heavy Change Detection: reporting flows whose sizes in
two adjacent time windows increase or decrease beyond a
predefined threshold, to detect anomalous traffic.
Flow size Distribution Estimation: estimating the distri-
bution of flow sizes.
Entropy Estimation: estimating the entropy of flow sizes.
Cardinality Estimation: estimating the number of flows.
Generic solutions can use one data structure to support
all these measurement tasks. If the IDs and sizes of all the
flows are recorded, then we can process these tasks, but
recording all flow IDs is difficult and needs high memory
usage[4, 12]. We observe that flow IDs of mouse flows are not
necessary for these tasks. As most flows are mouse flows,
discarding IDs of mouse flows can significantly save memory
and bandwidth of transmission. For this, we need to separate
elephant flows from mouse flows. To address this problem,
we leverage the spirit of Ostracism, and propose a fast and
accurate separation algorithm. Finally, our sketch is both
generic and memory efficient.
64 ‚åâ = 2 packets.
Another meaning of generic is that the algorithm can be
implemented on various platforms. For small companies, the
traffic speed may be not high, and measurement on CPU is a
good choice. For large companies, the traffic speed could be
very high, and then hardware platforms should be used for
measurements to catch up with the high speed. Therefore,
the measurement solution should be generic, and can make
good performance trade-off on different platforms.
2.3 Network Measurements Systems
Recently, well-known systems for measurements in-
clude UnivMon [2], Trumpet [40], OpenSketch [11],
FlowRadar [18], SketchVisor [12], Marple[41], Pingmesh[42],
and DREAM[43]. Among them, FlowRadar and UnivMon
are generic, and thus are the most related work to this paper.
FlowRadar [18] records all flow IDs and flow sizes in a
Bloom filter [44] and an Invertible Bloom Lookup Table
(IBLT) [45]. To reduce memory usage, the authors propose an
elegant solution of network-wide decoding. However, com-
pared with sketches, its memory usage is still much higher.
UnivMon[2] is based on a key method named universal
streaming [46]. Accuracy is guaranteed thanks to the the-
ory of universal streaming. UnivMon is the first work to be
generic, and achieves good performance. However, it does
not handle the problem of variable traffic characteristics.
To the best of our knowledge, our sketch is the first work
that relies on a single data structure which is adaptive to
bandwidth, packet rate, and flow size distribution.
3 ELASTIC SKETCHES
3.1 Basic Version
Rationale: As mentioned above, we need to separate ele-
phant flows from mouse flows. We simplify the separation to
the following problem: given a high-speed network stream,
how to use only one bucket to select the largest flow? As the
memory size is too small, it is impossible to achieve the ex-
actly correct result, thus our goal is to achieve high accuracy.
Our technique is similar in spirit to Ostracism (Greek: ostrak-
ismos, where any citizen could be voted to be evicted from
Athens for ten years). Specifically, each bucket stores three
fields: flow ID, positive votes, and negative votes. Given an
incoming packet with flow ID f1, if it is the same as the flow
in the bucket, we increment the positive votes. Otherwise,
we increment the negative votes, and if #ne–¥ative votes
‚©æ Œª,
#positive votes
where Œª is a predefined threshold, we expel the flow from
the bucket, and insert f1 into it.
3.1.1 Data Structure and Operations.
Data structure: As shown in Figure 1, the data structure
consists of two parts: a ‚Äúheavy‚Äù part recording elephant flows
and a ‚Äúlight‚Äù part recording mouse flows. The heavy partH is
a hash table associated with a hash function h(.). Each bucket
Figure 1: Basic version of Elastic. To insert f9, after in-
crementing votes‚àí, vote‚àí
vote + ‚©æ Œª = 8, hence f4 is evicted
from the heavy part and inserted into the light part.
of the heavy part records the information of a flow: flow ID
(key), positive votes (vote+), negative votes (vote‚àí), and flag.
Vote+ records the number of packets belonging to this flow
(flow size). Vote‚àí records the number of other packets. The
flag indicates whether the light part may contain positive
votes for this flow.
The light part is a CM sketch. A CM sketch [10] consists
of d arrays (L1, L2, ..., Ld). Each array is associated with
one hash function, and is composed of w counters. Given an
incoming packet, the CM sketch extracts the flow ID, com-
putes d hash functions to locate one counter per array, and
increments the d counters (we call them d hashed counters)
by 1. The query is similar to the insertion: after obtaining
the d hashed counters, it reports the minimum one.
Insertion:2 Given an incoming packet with flow ID f , we
hash it to the bucket H[h(f )%B], where B is the number
of buckets in the heavy part. Suppose the bucket stores
(f1, vote +, f la–¥1, vote‚àí). Similar to Ostracism, if f matches
f1, we increment vote +. Otherwise, we increment vote‚àí and
decide whether to evict f1 according to the two votes. Specif-
ically, there are four cases:
Case 1: The bucket is empty. We insert (f , 1, F, 0) into it,
where F means no eviction has happened in the bucket. The
insertion ends.
Case 4: f (cid:44) f1, and vote‚àí
Case 2: f = f1. We just increment vote+ by 1.
Case 3: f (cid:44) f1, and vote‚àí
vote + < Œª after incrementing vote‚àí by
1 (Œª is a predefined threshold, e.g., Œª = 8)3. We insert (f , 1)
into the CM sketch: increment the hashed counters by 1.
vote + ‚©æ Œª after incrementing vote‚àí
by 1. We ‚Äúelect‚Äù flow f by setting the bucket to (f , 1,T , 1),
and evict flow f1 to the CM sketch: increment the mapped
counters by vote +. Note that in this case the flag is set to T
2During insertions, we follow one principle: the insertion operations must
be one-directional, because it is hard to perform back-tracking operations
on hardware platforms.
3According to our experimental results on different datasets, we find when
Œª ‚àà [4, 128], the accuracy is optimal and has little difference, and we choose
Œª = 8. More detailed reason are provided in Section B.8 of our technical
report [47].
f1h(.)(f1,5,T,15)492170(key, vote+, flag, vote-)Heavy partLight part(f3,12,F,11)f5h(.)f8h(.)f1,6,T,15f5,1,F,0(f4,7,F,55)11++f9h(.)f9,1,T,0. . .. . .f42+7vote+: positive votesvote-: negative votesfreqùúÜ=8, 55+1‚â•7‚àóùúÜf8+1g2(.)+7+1CM sketch61387010freq(true), because some votes of flow f may be inserted into
the light part before f is elected.
Query: For any flow not in the heavy part, the light part
(the CM sketch) reports its size. For any flow f in the heavy
part, there are two cases: 1) The flag of f is false. Its size is
the corresponding vote+ with no error; 2) The flag of f is
true. We need to add the corresponding vote+ and the query
result of the CM sketch.
3.1.2 Accuracy Analysis.
The estimated value of a flow in the Elastic sketch has the
following error bound, and the detailed proof is provided in
our technical report [47].
Theorem 3.1. Let vector f = (f1, f2, ..., fn) denote the size
vector for a stream, where fi denotes the size of the i-th flow.
œµ ‚åâ (e is Euler‚Äôs number)
Given two parameters œµ and Œ¥, let w = ‚åà e
and d = ‚åàln 1
Œ¥ ‚åâ. Let Elastic with d (d is the number of counter
arrays) and w (w is the number of counters in each array)
records the stream with f. The reported size ÀÜfi by Elastic for
flow i is bounded by
ÀÜfi ‚©Ω fi + œµ‚à•fl ‚à•1
(1)
with probability at least 1‚àí Œ¥, where fL denotes the size vector
of the sub-stream recorded by the light part.
< fi + œµ‚à•f‚à•1
4
According to Theorem 3.1, the estimation error of Elastic is
bounded by ‚à•fl ‚à•1, instead of ‚à•f‚à•1 in Count-Min. In practice,
often, most packets of a stream are recorded in the heavy
part, ‚à•fL‚à•1 is usually significantly smaller than ‚à•f‚à•1. Thus
Elastic has a much tighter error bound than Count-Min when
the parameters (d and w) are the same.
The accuracy of Elastic is high in most cases, owing to
the separation of elephant flows and mice flows. 1) There is
no error in the heavy part: for the flows with flag of false,
the recorded vote+ is the flow size with no error; for flows
with flag of true, the recorded vote+ is one part of the flow
size still with no error, while the other part is recorded in
the light with error. 2) In the light part, we do not record
the flow ID, and only record the sizes of mice flows, and
thus can use many small counters (e.g., 8-bit counters), while
traditional sketch needs to use a few large counters (e.g., 32-
bit counters) to accommodate the elephant flows. Therefore,
our light part can be very accurate. In summary, the accuracy
of both elephant and mice flows is high.
The accuracy of Elastic drops in the worst case ‚Äì elephant
collisions: when two or more elephant flows are mapped
into the same bucket, some elephant flows are evicted to the
light part and could make some mouse flows significantly
over-estimated.
Elephant collision rate: defined as the number of buckets
mapped by more than one elephant flows divided by the total
4‚à•x‚à•1 is the first moment of vector x, i.e., ‚à•x‚à•1 = xi .
number of buckets. It is proved that the number of elephant
flows that mapped to each bucket follows a Binomial distri-
bution in the literature [48]. We show only the following
formula of the elephant collision rate Phc, and the detailed
proof is provided in Section A.1 of our technical report [47].
(cid:19)
(cid:18) H
w
e
‚àí H
w
Phc = 1 ‚àí
+ 1
(2)
where H is the number of elephant flows and w is the num-
ber of buckets. For example, when H/w = 0.1 or 0.01, the
elephant collision rate is 0.0046 and 0.00005, respectively.
Solutions for elephant collisions: Obviously, reducing
the hash collision rate can reduce the elephant collision rate.
Thus, we use two classic methods [49‚Äì57]: 1) by using multi-
ple sub-tables (see Section 4.2); 2) by using multiple key-value
pairs in one bucket (see Section 4.3).
3.2 Adaptivity to Available Bandwidth
To adapt to the available bandwidth, we propose to compress
the sketches before sending them. Most flows are mouse
flows, thus the memory size of the light part is often much
larger than that of the heavy part. In this section, we will
show how to compress and merge the light part - CM sketch.
To the best of our knowledge, this is the first effort to com-
press sketches.
3.2.1 Compression of Sketches.
Figure 2: The Equal Division Compression algorithm.