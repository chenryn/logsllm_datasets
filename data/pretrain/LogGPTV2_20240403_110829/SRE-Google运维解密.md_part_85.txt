在下次DiRT练习中进行连锁故障演习
利用fuxcapacitor在多个集群中均衡负载
故障的指示
更新运维手册（Playbook），加入有关应对连锁
待办事项
待办事项：
将更新过的搜索排序子系统部署到生产环境
持正常
给莎士比亚搜索服务增加流量抛弃功能
调查是否可以持续性地进行索引更新
监控与警报方案。
特定问题过度优化的问题，在更可靠的方案（类似单元测试）可以预防的情况下还增加了过于具体的
·服务器日志中包括了指出文件描述符耗尽问题导致崩溃的栈跟踪
·莎士比亚迷的邮件列表里刚好有一份新的韵文文本
检验。
应激反射类的AI通常太极端，
）对连锁故障的处理不够熟练
致死请求（query-of-death）通过推送新的索引关键词就解决了
在所有集群中快速更新了ShakespeareCorpus
监控系统在大量HTTP500（接近100%）的情况下快速发出了紧急警报
错误预算数个数量级
由于这次大幅度的流量增长（几乎全部请求都失败了），导致我们超过了可用性
附录D事后总结示范
注3
实现成本太高，
决策需要在更高的范围内进行。
预防
缓解
其他
类型
预防
流程
docbrown
clarac
agoogler
docbrown
jennifer
负责人
jennifer
agoogler
jennifer
martym
n/aTODO
n/a DONE
Bug 5554827 TODO
Bug 5554826TODO
Bug5554825DONE
Bug 5554824 TODO
n/aTODO
Bug 5554823TODO
n/aDONE
Bug
而且，
还存在对某
---
## Page 463
2015-10-21（所有时区都是UTC）
时间线注5
?
这里收集了事故的全过程，用应急事故管理文档中的时间线来填充事后总结的时间线，另外再加入一
14：51新闻报道新的莎士比亚韵文在一辆Delorean车的杂物箱中发现。
其他相关的记录。
开始在#shakespeare频道进行协调，将jennifer任命为事故总负责人
14:57所有的莎士比亚搜索请求都在失败：见http://monitor/shakespeare？endtime
14：55docbrown收到了大量紧急警报，所有集群都在汇报ManyHttp500s
15:25martym开始将新的索引复制到其他集群
15：18clarac在日志中发现了文件描述符耗尽这个问题，确认了如果搜索词不存
15：12 docbrown 联系了clarac& agoogler（莎士比亚搜索开发团队），帮助检查
15：06docbrown发现崩溃现象在所有集群的所有任务中都一样，根据应用程序
15：02 某人意外发送了一封邮件给Shakespeare-discuss@邮件列表，讨论新的
15:01应急故障管理开始，docbrown宣布事故#465开始，目前处于连锁故障状态，
14：58docbrown开始调查问题，发现后端任务崩溃速度很快
14：54事故开始，搜索后端在高负载情况下崩溃
15：32jennifer将负载均衡调整回正常，将流量导向了其他集群
15：28docbrown开始将集群实例数量扩展为2倍
15：23docbrown将所有流量导向了USA-2集群，允许其他集群增加副本数量
15：20martym的索引MapReduce任务完成
在则会导致文件描述符泄露
15：10martym将新的韵文加入，开始进行索引任务
15：07martym找到了文档，开始进行Corpus更新的准备工作
日志进行进一步调查
15：04martym找到了新的韵文全文，同时开始寻找更新索引的文档
15：03jennifer注意到了事故中的 Shakespeare-discuss@邮件列表
韵文，这封邮件刚好出现在martym的收件箱顶端
=20151021T145700
该文章）
亚搜索引擎是找到新韵文的好地方，流量提升了88倍（这时候我们还没有收录
14：53／r/shakespeare（指Reddit.com，美国新闻网站）的一篇文章指出莎士比
从而使它们可以在崩溃重启之前处理更多工作
15：21jennifer和docbrown决定大幅提升实例数量，以便降低每个实例的负载，
代码中的潜在问题
事后总结示范
|421
注6有用的信息、文档链接、日志、屏幕截图、图表、IRC记录、IM记录等。
监控页面，http://monitor/shakespeare？end_time=20151021T160000&duration=7200
其他支持信息注6
422
·16：30应急事故管理结束，30分钟内恢复正常运行，已经达到了退出条件
·16：00故障结束，所有流量重新分布于所有集群中
●15：39docbrown启动了第二批副本数量更新，提升到了10倍容量
·15：36故障缓解，更新过的索引复制到了全部集群
·15：36jennifer将负载均衡重新调整为USA-2，准备再增加5倍全球容量（总计
·15：34发现了白板计算中关于实例副本实例增加的一个数量级错误
●15：33其他集群的任务开始崩溃，出现了同样症状
?
15：41jennifer将1%流量重新分布在所有集群中
15：5030%流量重新分配
15：47其他集群的HTTP500稳定在SLO范围内，没有任务故障发生
15：45jennifer将10%流量重新分布在所有集群中
15：43其他集群的HTTP500保持稳定，任务崩溃率很低
10倍）
15：5550%流量重新分配
附录D事后总结示范
---
## Page 465
系统可靠性与灾难恢复
流量预估、
物理机与数据中心
架构
这是Google最初的发布协调检查列表，写于2005年，有简单修改。
·当下列情况发生时，服务会怎么样：
·物理机数量与带宽数量，数据中心，N+2度，网络QoS
·对每种需要联系其他服务器（后端）的服务器来说：
●存储容量
·HTTP流量与带宽预估，发布时的峰值，流量的组成，6个月的预测
·新的域名，DNS负载均衡
·编程性客户端的请求
·架构草图，服务器类型，客户端请求类型
一如何在不影响客户端和用户的情况下重启服务器
一如何检测后端故障，后端故障如何处理
一两个数据中心之间的网络故障
一物理机故障，机柜故障，集群故障
对其他我们关注的服务的影响
压力测试，端到端测试，每个数据中心最高延迟下的容量
容量以及性能
发布协调检查列表
附录E
423
<493
494
---
## Page 466
495
424
发布时间与发布计划
外部依赖
增长问题
自动化与人工任务
安全
监控与服务器管理
·不可改变的截止日期，外部事件，星期一或者星期五
●空余容量，10倍增长，增长型的警报
·不要在代码中给自己发送海量邮件，会导致邮件服务器崩溃
·数据备份/恢复，灾难恢复
该服务标准的运维流程，
安全设计评审，安全代码评审，
在集群环境下运行服务的技巧
发布流程，可重复的构建过程，金丝雀测试，分阶段发布
更新服务器、数据，配置文件的方式和变更管理
监控内部状态，
与合作伙伴、邮件系统，以及Google内部服务良好对接
优雅降级，如何避免意外对第三方服务造成过载
第三方系统，监控，网络条件，流量配比，
缓存，数据分片／重新分片
扩展性的瓶颈，线性扩展，与硬件性能的同步扩展，所需要的变更
发布之前的可见／可访问性控制，各种类型的黑名单
有关财务的警报和日志
监控监控系统
附录E发布协调检查列表
负载均衡，速度限制，超时，重试，以及错误处理
监控端到端行为，警报的管理
，以及其他服务的运维流程
垃圾邮件风险，验证，SSL
，发布时的流量峰值
---
## Page 467
事故回顾
之前的待办事项评审
公告