an observable correlation between the attack app’s operation
and that of the principal, which can be used to detect such a
suspicious activity. Speciﬁcally, the Guardian app continues to
monitor untrusted apps within the Ward mode, closing those
that use CPU resources intensively and also comparing their
behaviors with what have been seen outside the mode. An app is
considered to be stalking the principal if its operations are found
to be correlated to the principal’s activities. This correlation is
established through a statistical test on the activities of both
the principal and the suspect, as elaborated below.
Speciﬁcally, we use Pearson correlation coefﬁcient (r) to
measure the correlation between two random variables X (the
scheduling rate of the principal) and Y (the SR of the suspicious
process). Several samples of X and Y are required to compute
their correlation coefﬁcient, which means that we need several
instances of the suspicious app running side-by-side with the
principal, with an elevated scheduling rate, while standing down
once the principal stops. For realistic protection the number of
samples should be very low (< 10). Actually, the number of
samples for computing the coefﬁcient depends on the value of
the correlation coefﬁcient r, power of the test 1 − β (β is the
probability of type II error) and the signiﬁcance level α (α is
the probability of type I error). In the case that the correlation
is strong (e.g., 0.9 or even close to 1), which is needed for
the adversary to closely monitor the principal, the number of
samples required for detecting such a correlation (at a given
power and signiﬁcant pair) can be very small (e.g., 4 times for
the coefﬁcient ≥ 0.98), as shown in Table II.
4In Android, a background process has a low priority, with little ﬂexibility
in adjusting its timeslice.
Once enough samples are observed and as a result, the
correlation has been established, Guardian kills the suspicious
923924
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:07 UTC from IEEE Xplore.  Restrictions apply. 
α
0.05
0.05
0.05
0.05
0.05
1 − β
0.8
0.8
0.8
0.8
0.8
r
0.90
0.95
0.98
0.9993
1
n
7
5
4
3
3
TABLE II: Required number of samples for different values
of correlation coefﬁcient assuming 5% signiﬁcance level (two
sided) and 80% power of the test
app each time right before the system gets into the Ward mode,
even when the app does not run aggressively (over the SR
threshold). Also, our app alerts the presence of the suspect to
the phone user. With her consent, the suspicious app can be
uploaded to the server, which runs static and dynamic analyses
on the program to ﬁnd out whether it indeed aggressively
accesses the principal’s side channel information, for example,
read from its proc ﬁles.
Collusion. If the adversary manages to get more than one
malicious apps onto the victim’s device, he might try to play
a collusion game to make these apps look less suspicious.
For example, in the phone tapping attack, a pair of apps, one
with the RECORD_AUDIO permission and the other having
READ_PHONE_STATE, can collude to make each of them less
conspicuous. Of course, this trick does not work on Guardian,
since it always terminates the app with RECORD_AUDIO
whenever the AudioIn_X thread is observed. The situation
becomes more complicated in the case of side-channel attacks,
where two colluding apps could sample at a lower rate each but
still collect sufﬁcient information from the principal. The most
effective way to mitigate this threat is to identify the relation
between different apps. Such a relation can be captured by the
referrals made between the apps, an approach the adversary
needs to use to install more than one of his programs on the
victim’s device.
Speciﬁcally, Guardian automatically groups the apps signed
with the same certiﬁcate and those whose installations are
triggered by other apps: whenever an untrusted app invokes a
marketplace app (e.g., Google Play, Amazon Appstore, SlideMe,
etc.), which can be discovered by checking the app’s activity
stack, it is automatically linked to the new app installed from
the marketplace. This approach was found to be very effective,
never causing any false positive in our research. To circumvent
the detection, the adversary could make a referral less obvious,
for example, requiring the user to download the second app
from a website. What we can do in this case is asking the
user: as soon as an untrusted app is being installed, Guardian
is notiﬁed through action.PACKAGE_ADDED and responds
by popping up a view for the user to indicate whether the new
app is recommended by an existing one; if so, an app list is
provided for a convenient identiﬁcation of the referrer. In this
way, our approach can keep track of related apps installed after
it starts running on the target device.
Also, Guardian operates a mechanism to detect colluding
apps during their runtime. Actually, unrelated apps rarely use the
CPU resources in an aggressive way together for an extended
period of time. In our research, we selected 114 most popular
free apps from Google Play and installed them on our Nexus 5.
Among them, 68 were automatically invoked after the system
rebooted. We further ran our monitoring app on the device to
check these 68 apps’ SRs every 5 minutes, for 40 hours. Only
15 app pairs, out of the total 1431 combinations, were observed
to have combined SRs above 1 per 3 seconds (a threshold we
set) over at least 10% of our monitoring period, while their
individual SRs were below the threshold. A close look at these
15 pairs showed that the problem was actually caused by two
apps jp.naver.line.android and com.groupon with
a low privilege (7 to 9). Once they were suspended, none of
the app pairs were found to have a collective SR above the
threshold over 10% of the period. This indicates that we can
temporarily suspend a selected app of an app pair once they
are found to use the CPU resources together in an aggressive
way for a while, without causing much utility trouble.
IV. EVALUATION AND ANALYSIS
In this section, we report our analysis of App Guardian, in
terms of its effectiveness in fending off known attacks, impacts
on the utility of legitimate apps and the overheads it introduces
during the operation.
A. Effectiveness
To understand the effectiveness of our App Guardian system,
we evaluated our prototype against 12 RIG attacks, including
those reported by prior research [1]–[5], [7], [20] and the new
threats to Android-controlled IoT, as described in Section II-B.
The study shows that our technique is capable of defeating all
these attacks, at low cost most of time. Particularly, for the
side-channel attacks, we show that using the scheduling rate
to identify suspicious apps, Guardian effectively reduces the
amount of information a RIG app can get from the principal.
This result is illustrated in Figure 5. Also, the protection level
can be balanced with the number of apps that need to be killed,
which was also studied in our research (Section IV-B). Table III
presents all the attacks evaluated or analyzed in our study. All
the experiments were performed on a Google Nexus 5 (2.3G
CPU, 2G memory). Following we report our ﬁndings.
No.
RIG Attacks
Defeat
1
2
3
4
5
6
7
8
9
10
11
12
Audio Recording
Bluetooth Data Stealing
Alarm Blocking
Motion Detection On
WebMD: inferring disease condi-
tions
Twitter: inferring identities
Web Page Inference
Driving Route Inference
Keylogger 1: TouchLogger
Keylogger 2: Screenmilker
Voice eavesdropping
UI inference
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes5
Yes5
Attack Success Rate
(SR)
N/A
N/A
Fail (2/s)
Fail (1/3s)
RG (1/2s)
RG (end-to-end)
RG (10/s)
Fail (1/s)
≤ 1/3s (1/3s)
≤ 1/3s (1/3s)
Fail (1/3s)
Fail (1/3s)
TABLE III: Effectiveness in defending against RIG attacks.
Here RG represents random guess. Keyloggers’ success rate
cannot go above 1 key per 3 seconds, given an SR of once per
3 seconds.
Audio recording and Bluetooth data stealing. We ﬁrst put
our system to the test against the data-stealing attacks. In
the case of audio recording, we ran an attack app with
both RECORD_AUDIO and READ_PHONE_STATE permis-
sions. Whenever a phone call came in, the app started recording
5Our approach can defeat the attacks based upon the parameters given by
their papers [2], [7].
924925
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:04:07 UTC from IEEE Xplore.  Restrictions apply. 
in the background. In the presence of App Guardian, however,
this attempt was completely thwarted: as soon as the recording
thread was spawned, the suspicious activity was immediately
detected and the attack app was killed instantly. As a result,
nothing was found to be recorded.
The Bluetooth attack was performed on iThermometer [28],
a Bluetooth medical device also used in prior research [6]. Our
attack app was successful in getting data from the device, right
before its ofﬁcial app connected to it. However, this attempt
no longer went through when the ofﬁcial app was protected
by Guardian: as soon as the principal (the ofﬁcial app) was
launched, Guardian detected the use of the Bluetooth service
and the presence of a Bluetooth-capable app, and immediately
terminated the app. This left the adversary no chance to collect
any data from the the body thermometer.
IoT attacks. We further used our Guardian app to protect the
ofﬁcial apps of NetCam and Nest Protect (Section II-B) against
the RIG attacks on them. For NetCam, we found that the chance
for identifying the click on the “save clips” switch, which turns
on or off its motion detector, decreases substantially with the
attack app’s SR: as shown in Table III, when its SR reduced
to once every 1.5 seconds, the probability of correct detection
goes down to 10%. This is because many packets (for unrelated
purposes) actually all have similar sizes as the one for turning
on the switch. The attack was successful because the packet is
the only one that comes alone: no other packets show up in
about one second since it arrives. When the attack process can
only sample very slowly (1 per 3 seconds), this approach no
longer works (which failed every time in our experiment) and
actually the increment (tcp_snd) the adversary sees is very
likely to involve multiple packets.
The “alarm blocking” attack (muting the sound for the alarm
notiﬁcation) is even more dependent on the attack app’s SR: as
soon as the GCM notiﬁcation is discovered from its increments,
the attacker is supposed to turn off the sound immediately, to
prevent the recipient of the message from arousing the user’s
attention through an alert sound. We found that this can only
be done when the app samples at least 20 times per second.
What App Guardian does is to simply register with notiﬁcation
listener service, so that it is always informed whenever the
ofﬁcial app posts a notiﬁcation. When this happens, our app
stops all untrusted apps that ran at SR of 20 times per second
before the notiﬁcation came and further checks the speaker
status. If it is muted, Guardian unmutes it and further reposts
the message, which produces the sound the adversary wants to
avoid. Finally, the video watching part is hard to cover, due to
the presence of a large volume of inbound trafﬁc. To hide the
information completely from the adversary, we can take the
blind termination strategy, stopping all untrusted apps.
WebMD and Twitter. Similar to those IoT devices, WebMD
and Twitter apps are also vulnerable to the RIG attacks that
exploit their network-data usages [1] (also see Section II-A).
Prior research shows that by monitoring detailed increments in
their tcp_snd and tcp_rcv elements (at the packet level),
the adversary can ﬁgure out the disease conditions the user
checks through WebMD and the moment when the user tweets,
which can be further used to recover her identity. In our research,
we implemented the attacks described in the prior work [1] and
then protected the targets of these attacks (WebMD, Twitter)
(a) WebMD and Twitter
(b) Google Navigation and Web Pages
Fig. 5: Effectiveness of RIG attacks under different scheduling
rates. Here dash lines represent the success rate of a random
guess.
with our App Guardian to understand the effectiveness of our
technique. Here we report what we found.
Compared with the versions described in the prior re-
search [1], both the WebMD and Twitter apps used in our
study have been signiﬁcantly modiﬁed. For WebMD, clicking
a disease condition will generate a sequence of packets. Most
of them change slightly (in 20 bytes) when the same condition
is checked multiple times, while a few vary signiﬁcantly in
size, due to their inclusion of different advertising content. In
our study, we randomly selected 10 disease conditions, and
measured the range of the payload length for each packet
associated with each condition. In this way, every selected
condition here is ﬁngerprinted with a sequence of payload-
length ranges, as did in the prior work [1]. Using these
ﬁngerprints, we found that without protection, these conditions
can still be uniquely identiﬁed from their payload-length
sequences. However, once Guardian is in place, the side-channel
attack becomes much more difﬁcult to succeed. Speciﬁcally,
when the SR of the attack app goes down to once every
two seconds, all it observes is just an accumulated length
of all packets related to one condition. In the presence of the
randomness in packet sizes, the ranges of different conditions’
accumulated lengths signiﬁcantly overlap with each other. As
a result, in all 25 random trials (each involving a click on one