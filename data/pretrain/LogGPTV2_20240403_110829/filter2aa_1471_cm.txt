incremental logging. Normally, cells in a hive file can be in four different
states:
■    Clean The cell’s data is in the hive’s primary file and has not been
modified.
■    Dirty The cell’s data has been modified but resides only in memory.
■    Unreconciled The cell’s data has been modified and correctly written
to a log file but isn’t in the primary file yet.
■    Dirty and Unreconciled After the cell has been written to the log
file, it has been modified again. Only the first modification is on the
log file, whereas the last one resides in memory only.
The original pre-Windows 8.1 synchronization algorithm was executing
five seconds after one or more cells were modified. The algorithm can be
summarized in four steps:
1. 
The configuration manager writes all the modified cells signaled by
the dirty vector in a single entry in the log file.
2. 
It invalidates the hive’s base block (by setting only one sequence
number with an incremented value than the other one).
3. 
It writes all the modified data on the primary hive’s file.
4. 
It performs the validation of the primary hive (the validation sets the
two sequence numbers with an identical value in the primary hive
file).
To maintain the integrity and the recoverability of the hive, the algorithm
should emit a flush operation to the file system driver after each phase;
otherwise, corruption could happen. Flush operations on random access data
can be very expensive (especially on standard rotation disks).
Incremental logging solved the performance problem. In the legacy
algorithm, one single log entry was written containing all the dirty data
between multiple hive validations; the incremental model broke this
assumption. The new synchronization algorithm writes a single log entry
every time the lazy flusher executes, which, as discussed previously,
invalidates the primary hive’s base block only in the first time it executes.
Subsequent flushes continue to write new log entries without touching the
hive’s primary file. Every hour, or if the space in the log exhausts, the
Reconciler writes all the data stored in the log entries to the primary hive’s
file without performing the validation phase. In this way, space in the log file
is reclaimed while maintaining the recoverability of the hive. If the system
crashes at this stage, the log contains original entries that will be reapplied at
hive loading time; otherwise, new entries are reapplied at the beginning of
the log, and, in case the system crashes later, at hive load time only the new
entries in the log are applied.
Figure 10-6 shows the possible crash situations and how they are managed
by the incremental logging scheme. In case A, the system has written new
data to the hive in memory, and the lazy flusher has written the
corresponding entries in the log (but no reconciliation happened). When the
system restarts, the recovery procedure applies all the log entries to the
primary hive and validates the hive file again. In case B, the reconciler has
already written the data stored in the log entries to the primary hive before
the crash (no hive validation happened). At system reboot, the recovery
procedure reapplies the existing log entries, but no modification in the
primary hive file are made. Case C shows a similar situation of case B but
where a new entry has been written to the log after the reconciliation. In this
case, the recovery procedure writes only the last modification that is not in
the primary file.
Figure 10-6 Consequences of possible system crashes in different times.
The hive’s validation is performed only in certain (rare) cases. When a
hive is unloaded, the system performs reconciliation and then validates the
hive’s primary file. At the end of the validation, it sets the two sequence
numbers of the hive’s primary file to a new identical value and emits the last
file system flush request before unloading the hive from memory. When the
system restarts, the hive load’s code detects that the hive primary is in a clean
state (thanks to the two sequence numbers having the same value) and does
not start any form of the hive’s recovery procedure. Thanks to the new
incremental synchronization protocol, the operating system does not suffer
any longer for the performance penalties brought by the old legacy logging
protocol.
 Note
Loading a hive created by Windows 8.1 or a newer operating system in
older machines is problematic in case the hive’s primary file is in a non-
clean state. The old OS (Windows 7, for example) has no idea how to
process the new log files. For this reason, Microsoft created the
RegHiveRecovery minifilter driver, which is distributed through the
Windows Assessment and Deployment Kit (ADK). The RegHiveRecovery
driver uses Registry callbacks, which intercept “hive load” requests from
the system and determine whether the hive’s primary file needs recovery
and uses incremental logs. If so, it performs the recovery and fixes the
hive’s primary file before the system has a chance to read it.
Registry filtering
The configuration manager in the Windows kernel implements a powerful
model of registry filtering, which allows for monitoring of registry activity by
tools such as Process Monitor. When a driver uses the callback mechanism, it
registers a callback function with the configuration manager. The
configuration manager executes the driver’s callback function before and
after the execution of registry system services so that the driver has full
visibility and control over registry accesses. Antivirus products that scan
registry data for viruses or prevent unauthorized processes from modifying
the registry are other users of the callback mechanism.
Registry callbacks are also associated with the concept of altitudes.
Altitudes are a way for different vendors to register a “height” on the registry
filtering stack so that the order in which the system calls each callback
routine can be deterministic and correct. This avoids a scenario in which an
antivirus product would scan encrypted keys before an encryption product
would run its own callback to decrypt them. With the Windows registry
callback model, both types of tools are assigned a base altitude corresponding
to the type of filtering they are doing—in this case, encryption versus
scanning. Secondly, companies that create these types of tools must register
with Microsoft so that within their own group, they will not collide with
similar or competing products.
The filtering model also includes the ability to either completely take over
the processing of the registry operation (bypassing the configuration manager
and preventing it from handling the request) or redirect the operation to a
different operation (such as WoW64’s registry redirection). Additionally, it is
also possible to modify the output parameters as well as the return value of a
registry operation.
Finally, drivers can assign and tag per-key or per-operation driver-defined
information for their own purposes. A driver can create and assign this
context data during a create or open operation, which the configuration
manager remembers and returns during each subsequent operation on the
key.
Registry virtualization
Windows 10 Anniversary Update (RS1) introduced registry virtualization for
Argon and Helium containers and the possibility to load differencing hives,
which adhere to the new hive version 1.6. Registry virtualization is provided
by both the configuration manager and the VReg driver (integrated in the
Windows kernel). The two components provide the following services:
■    Namespace redirection An application can redirect the content of a
virtual key to a real one in the host. The application can also redirect a
virtual key to a key belonging to a differencing hive, which is merged
to a root key in the host.
■    Registry merging Differencing hives are interpreted as a set of
differences from a base hive. The base hive represents the Base Layer,
which contains the Immutable registry view. Keys in a differencing
hive can be an addition to the base one or a subtraction. The latter are
called thumbstone keys.
The configuration manager, at phase 1 of the OS initialization, creates the
VRegDriver device object (with a proper security descriptor that allows only
SYSTEM and Administrator access) and the VRegConfigurationContext
object type, which represents the Silo context used for tracking the
namespace redirection and hive merging, which belongs to the container.
Server silos have been covered already in Chapter 3, “Processes and jobs,” of
Part 1.
Namespace redirection
Registry namespace redirection can be enabled only in a Silo container (both
Server and applications silos). An application, after it has created the silo (but
before starting it), sends an initialization IOCTL to the VReg device object,
passing the handle to the silo. The VReg driver creates an empty
configuration context and attaches it to the Silo object. It then creates a single
namespace node, which remaps the \Registry\WC root key of the container to
the host key because all containers share the same view of it. The
\Registry\WC root key is created for mounting all the hives that are
virtualized for the silo containers.
The VReg driver is a registry filter driver that uses the registry callbacks
mechanism for properly implementing the namespace redirection. At the first
time an application initializes a namespace redirection, the VReg driver
registers its main RegistryCallback notification routine (through an internal
API similar to CmRegisterCallbackEx). To properly add namespace
redirection to a root key, the application sends a Create Namespace Node
IOCTL to the VReg’s device and specifies the virtual key path (which will be
seen by the container), the real host key path, and the container’s job handle.
As a response, the VReg driver creates a new namespace node (a small data
structure that contains the key’s data and some flags) and adds it to the silo’s
configuration context.
After the application has finished configuring all the registry redirections
for the container, it attaches its own process (or a new spawned process) to
the silo object (using AssignProcessToJobObject—see Chapter 3 in Part 1 for
more details). From this point forward, each registry I/O emitted by the
containerized process will be intercepted by the VReg registry minifilter.
Let’s illustrate how namespace redirection works through an example.
Let’s assume that the modern application framework has set multiple
registry namespace redirections for a Centennial application. In particular,
one of the redirection nodes redirect keys from HKCU to the host
\Registry\WC\ a20834ea-8f46-c05f-46e2-a1b71f9f2f9cuser_sid key. At a
certain point in time, the Centennial application wants to create a new key
named AppA in the HKCU\Software\Microsoft parent key. When the process
calls the RegCreateKeyEx API, the Vreg registry callback intercepts the
request and gets the job’s configuration context. It then searches in the
context the closest namespace node to the key’s path specified by the caller.
If it does not find anything, it returns an object not found error: Operating on
nonvirtualized paths is not allowed for a container. Assuming that a
namespace node describing the root HKCU key exists in the context, and the
node is a parent of the HKCU\Software\Microsoft subkey, the VReg driver
replaces the relative path of the original virtual key with the parent host key
name and forwards the request to the configuration manager. So, in this case
the configuration manager really sees a request to create
\Registry\WC\a20834ea-8f46-c05f-46e2-
a1b71f9f2f9cuser_sid\Software\Microsoft\ AppA and succeeds. The
containerized application does not really detect any difference. From the
application side, the registry key is in the host HKCU.
Differencing hives
While namespace redirection is implemented in the VReg driver and is
available only in containerized environments, registry merging can also work
globally and is implemented mainly in the configuration manager itself.
(However, the VReg driver is still used as an entry-point, allowing the
mounting of differencing hives to base keys.) As stated in the previous
section, differencing hives use hive version 1.6, which is very similar to
version 1.5 but supports metadata for the differencing keys. Increasing the
hive version also prevents the possibility of mounting the hive in systems that
do not support registry virtualization.
An application can create a differencing hive and mount it globally in the
system or in a silo container by sending IOCTLs to the VReg device. The
Backup and Restore privileges are needed, though, so only administrative
applications can manage differencing hives. To mount a differencing hive,
the application fills a data structure with the name of the base key (called the
base layer; a base layer is the root key from which all the subkeys and values
contained in the differencing hive applies), the path of the differencing hive,
and a mount point. It then sends the data structure to the VReg driver through
the VR_LOAD_DIFFERENCING_HIVE control code. The mount point
contains a merge of the data contained in the differencing hive and the data
contained in the base layer.
The VReg driver maintains a list of all the loaded differencing hives in a
hash table. This allows the VReg driver to mount a differencing hive in
multiple mount points. As introduced previously, the Modern Application
Model uses random GUIDs in the \Registry\WC root key with the goal to
mount independent Centennial applications’ differencing hives. After an
entry in the hash table is created, the VReg driver simply forwards the
request to the CmLoadDifferencingKey internal configuration manager’s
function. The latter performs the majority of the work. It calls the registry
callbacks and loads the differencing hive. The creation of the hive proceeds
in a similar way as for a normal hive. After the hive is created by the lower
layer of the configuration manager, a key control block data structure is also
created. The new key control block is linked to the base layer key control
block.
When a request is directed to open or read values located in the key used
as a mount point, or in a child of it, the configuration manager knows that the
associated key control block represents a differencing hive. So, the parsing
procedure starts from the differencing hive. If the configuration manager
encounters a subkey in the differencing hive, it stops the parsing procedure
and yields the keys and data stored in the differencing hive. Otherwise, in
case no data is found in the differencing hive, the configuration manager
restarts the parsing procedure from the base hive. Another case verifies
whether a thumbstone key is found in the differencing hive: the configuration
manager hides the searched key and returns no data (or an error). Thumb
stones are indeed used to mark a key as deleted in the base hive.
The system supports three kinds of differencing hives:
■    Mutable hives can be written and updated. All the write requests
directed to the mount point (or to its children keys) are stored in the
differencing hive.
■    Immutable hives can’t be modified. This means that all the
modifications requested on a key that is located in the differencing
hive will fail.
■    Write-through hives represent differencing hives that are immutable,
but write requests directed to the mount point (or its children keys)
are redirected to the base layer (which is not immutable anymore).
The NT kernel and applications can also mount a differencing hive and
then apply namespace redirection on the top of its mount point, which allows
the implementation of complex virtualized configurations like the one
employed for Centennial applications (shown in Figure 10-7). The Modern
Application Model and the architecture of Centennial applications are
covered in Chapter 8.
Figure 10-7 Registry virtualization of the software hive in the Modern
Application Model for Centennial applications.
Registry optimizations
The configuration manager makes a few noteworthy performance
optimizations. First, virtually every registry key has a security descriptor that
protects access to the key. However, storing a unique security descriptor copy
for every key in a hive would be highly inefficient because the same security
settings often apply to entire subtrees of the registry. When the system
applies security to a key, the configuration manager checks a pool of the
unique security descriptors used within the same hive as the key to which
new security is being applied, and it shares any existing descriptor for the
key, ensuring that there is at most one copy of every unique security
descriptor in a hive.
The configuration manager also optimizes the way it stores key and value
names in a hive. Although the registry is fully Unicode-capable and specifies
all names using the Unicode convention, if a name contains only ASCII
characters, the configuration manager stores the name in ASCII form in the
hive. When the configuration manager reads the name (such as when
performing name lookups), it converts the name into Unicode form in
memory. Storing the name in ASCII form can significantly reduce the size of
a hive.
To minimize memory usage, key control blocks don’t store full key
registry path names. Instead, they reference only a key’s name. For example,
a key control block that refers to \Registry\System\Control would refer to the
name Control rather than to the full path. A further memory optimization is
that the configuration manager uses key name control blocks to store key
names, and all key control blocks for keys with the same name share the
same key name control block. To optimize performance, the configuration
manager stores the key control block names in a hash table for quick lookups.
To provide fast access to key control blocks, the configuration manager
stores frequently accessed key control blocks in the cache table, which is
configured as a hash table. When the configuration manager needs to look up
a key control block, it first checks the cache table. Finally, the configuration
manager has another cache, the delayed close table, that stores key control
blocks that applications close so that an application can quickly reopen a key
it has recently closed. To optimize lookups, these cache tables are stored for
each hive. The configuration manager removes the oldest key control blocks
from the delayed close table because it adds the most recently closed blocks
to the table.
Windows services
Almost every operating system has a mechanism to start processes at system
startup time not tied to an interactive user. In Windows, such processes are
called services or Windows services. Services are similar to UNIX daemon
processes and often implement the server side of client/server applications.
An example of a Windows service might be a web server because it must be
running regardless of whether anyone is logged on to the computer, and it
must start running when the system starts so that an administrator doesn’t
have to remember, or even be present, to start it.
Windows services consist of three components: a service application, a
service control program (SCP), and the Service Control Manager (SCM).
First, we describe service applications, service accounts, user and packaged
services, and all the operations of the SCM. Then we explain how autostart
services are started during the system boot. We also cover the steps the SCM
takes when a service fails during its startup and the way the SCM shuts down
services. We end with the description of the Shared service process and how
protected services are managed by the system.
Service applications
Service applications, such as web servers, consist of at least one executable
that runs as a Windows service. A user who wants to start, stop, or configure
a service uses a SCP. Although Windows supplies built-in SCPs (the most
common are the command-line tool sc.exe and the user interface provided by
the services.msc MMC snap-in) that provide generic start, stop, pause, and
continue functionality, some service applications include their own SCP that
allows administrators to specify configuration settings particular to the
service they manage.
Service applications are simply Windows executables (GUI or console)
with additional code to receive commands from the SCM as well as to
communicate the application’s status back to the SCM. Because most
services don’t have a user interface, they are built as console programs.
When you install an application that includes a service, the application’s
setup program (which usually acts as an SCP too) must register the service
with the system. To register the service, the setup program calls the Windows
CreateService function, a services-related function exported in Advapi32.dll
(%SystemRoot%\System32\ Advapi32.dll). Advapi32, the Advanced API
DLL, implements only a small portion of the client-side SCM APIs. All the
most important SCM client APIs are implemented in another DLL,
Sechost.dll, which is the host library for SCM and LSA client APIs. All the
SCM APIs not implemented in Advapi32.dll are simply forwarded to
Sechost.dll. Most of the SCM client APIs communicate with the Service
Control Manager through RPC. SCM is implemented in the Services.exe
binary. More details are described later in the “Service Control Manager”
section.
When a setup program registers a service by calling CreateService, an
RPC call is made to the SCM instance running on the target machine. The
SCM then creates a registry key for the service under
HKLM\SYSTEM\CurrentControlSet\Services. The Services key is the
nonvolatile representation of the SCM’s database. The individual keys for
each service define the path of the executable image that contains the service
as well as parameters and configuration options.
After creating a service, an installation or management application can
start the service via the StartService function. Because some service-based
applications also must initialize during the boot process to function, it’s not
unusual for a setup program to register a service as an autostart service, ask
the user to reboot the system to complete an installation, and let the SCM
start the service as the system boots.
When a program calls CreateService, it must specify a number of
parameters describing the service’s characteristics. The characteristics
include the service’s type (whether it’s a service that runs in its own process
rather than a service that shares a process with other services), the location of
the service’s executable image file, an optional display name, an optional
account name and password used to start the service in a particular account’s
security context, a start type that indicates whether the service starts
automatically when the system boots or manually under the direction of an
SCP, an error code that indicates how the system should react if the service
detects an error when starting, and, if the service starts automatically,
optional information that specifies when the service starts relative to other
services. While delay-loaded services are supported since Windows Vista,
Windows 7 introduced support for Triggered services, which are started or
stopped when one or more specific events are verified. An SCP can specify
trigger event information through the ChangeServiceConfig2 API.
A service application runs in a service process. A service process can host
one or more service applications. When the SCM starts a service process, the
process must immediately invoke the StartServiceCtrlDispatcher function
(before a well-defined timeout expires—see the “Service logon” section for
more details). StartServiceCtrlDispatcher accepts a list of entry points into
services, with one entry point for each service in the process. Each entry
point is identified by the name of the service the entry point corresponds to.
After making a local RPC (ALPC) communications connection to the SCM
(which acts as a pipe), StartServiceCtrlDispatcher waits in a loop for
commands to come through the pipe from the SCM. Note that the handle of