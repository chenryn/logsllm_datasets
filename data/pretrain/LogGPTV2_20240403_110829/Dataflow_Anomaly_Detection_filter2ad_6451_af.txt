ered to be lossless if their constant parameters do not con-
tain wild-card patterns such as “?” and “*”. For instance,
X isWithinDir Y is lossless iff X = Y s, where the con-
stant parameter s does not contain any wild-card pattern.
On the other hand, relation hasSameDirAs is lossy because
only the common directory name is retained, but the rest of
argument information is lost.
Figure 8 shows the average branching factor for our
models without argument learning, learning unary relations
alone, and learning unary and binary relations that do not
lose signiﬁcant information as mentioned above. The table
shows that the use of binary relations leads to major im-
provements in branching factor.
We point out that the average branching factor of our
technique cannot be directly compared to that of other tech-
niques unless they too use an FSA-based control model.
For this reason, we do not directly compare our results with
those reported by [14].
5.4. Performance Overheads
Model Sizes. Figure 7 shows the programs used in our ex-
periments, along with their model sizes in terms of number
of states/transitions and relations in the models. The mod-
els are relatively small as compared to the size of programs
involved.
Time for Learning Models. We studied the performance
of the learning algorithm. Three programs were considered,
httpd, ftpd and sshd. The training traces were between
100MB and 300MB, consisting of 1.5 to 4 million system
calls. The learning algorithm took between 5 to 25 minutes
to process these traces.
Overhead for Intrusion Detection. Our current imple-
mentation uses ptrace for system call interception, which
itself introduces high runtime overheads for interception
that can exceed 100% for some programs. To obtain better
performance, an in-kernel interceptor can be used. Over-
heads for system call interception, including the costs of
retrieving the PC, have been reported to be around 6% for
a kernel implementation [9]. In addition to this, intrusion
detection requires veriﬁcation of binary relations, and the
cost of making realpath calls for ﬁle names. We have
measured these overheads individually, using our user level
implementation, and shown it in Figure 9. We remark that
find represents perhaps the worst-case scenario in terms
of overheads because it performs a very large number of
system calls involving ﬁle names, each of which incurs the
overhead of a realpath call, and the overhead of verifying
relationships on ﬁle names. An in-kernel implementation
of realpath would likely have lower overheads, but the
overhead numbers for relationship veriﬁcation are unlikely
to change.
6. Related Work
6.1. Static Analysis Techniques
A number of static analysis techniques have been devel-
oped for building intrusion detection models. A source-
code analysis is used in [30, 19], while binary analysis is
used in [14].
[14, 19] can also extract system call argu-
ments that appear as immediate constants in the program.
Binary analysis based approach of [12] additionally asso-
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply. 
ciates calling context of the extracted static data using data
ﬂow analysis. They also incorporate environment depen-
dency in the program models. However, this dependency
needs to be speciﬁed manually in their approach. In con-
trast, our approach learns these dependencies automatically.
The primary beneﬁt of static analysis based techniques
is that they eliminate false alarms. This is because these
models are conservative, capturing a superset of all possi-
ble behaviors that can be exhibited by a program. But the
conservative nature also limits attack detection ability: only
attacks that cause a program’s runtime behavior to deviate
from its code are detected. This means that a variety of at-
tacks, such as input validation errors, race conditions, and
so on, cannot be detected, as the erroneous behaviors do
represent possible behaviors of the victim program. As a
result, most attacks discussed in this paper can’t be detected
by these methods. Moreover, capturing accurate informa-
tion about data values is quite challenging, given the com-
plexities of a language such as C, which allows arbitrary
type casts and pointer arithmetic.
6.2. Learning-Based Approaches
Intrusion Detection. A number of techniques to learn
control-ﬂow behaviors for intrusion detection have already
been discussed before, so we focus our attention to tech-
niques for learning argument information.
In this regard,
[18] describes techniques for learning statistical informa-
tion about system call arguments for anomaly detection.
The statistical information includes properties of string ar-
guments such as its length and distribution of its characters.
Furthermore, structural inferences are made over string ar-
guments to learn a regular grammar that describes all of its
normal values.
[27] proposes another host-based anomaly detection sys-
tem that uses a rule-learning algorithm to model system call
behaviors incorporating argument information.
It uses a
rule-based learning algorithm that captures a ﬁxed number
of distinct values of frequently occurring arguments.
In our terminology, both of the above two approaches are
focused on unary relations, whereas the primary strength of
our approach is that of learning the more complex binary
relations. Moreover, our approach is able to utilize control-
ﬂow context to improve the precision of dataﬂow relation-
ships, whereas the above approaches don’t do that.
[1] describes a tech-
Hypothesizing Program Properties.
nique for automatically extracting likely program proper-
ties from execution traces. However, it relies on humans to
specify regions within a trace where such property extrac-
tion will be attempted. This contrasts with our technique,
which is fully automated. [22] has similar goals as [1], but is
fully automated. The primary difference with our technique
is that they focus on invariant properties, whereas our algo-
rithm is focused on temporal properties on traces. Techni-
cally, the two problems are quite different, requiring differ-
ent techniques to be employed. For instance, algorithms for
learning invariants can be speeded up by exploiting transi-
tivity, i.e., if p holds and p → q, then we need not explicitly
verify q. Unfortunately, this is not true for trace properties.
In [26], we described models sim-
Mobile Code Security.
ilar to those of this paper. The goal of [26] was to pro-
vide a overall view of the model-carrying code approach for
mobile code security, and hence that paper provides only
a superﬁcial treatment of models. The results presented
in this paper improves over [26] in many important ways.
First, we develop a formal treatment of dataﬂow properties
in this paper. Second, we show how control ﬂow contexts
from different control-ﬂow models can be utilized to im-
prove precision of dataﬂow relationships, whereas [26] is
limited to FSA method. Third, we develop an efﬁcient algo-
rithm for learning relationships and analyzing its complex-
ity. Fourth, we show how to parameterize the model by in-
corporating dependence on program’s environment, includ-
ing command-line argument, environment variables, open
ﬁle descriptors, and so on. Finally, and most importantly,
we provide a detailed evaluation of our technique for in-
trusion detection in this paper, whereas [26] was concerned
with mobile code security.
7. Conclusion
In this paper, we presented an approach for enhancing the
accuracy of host-based intrusion detection models by cap-
turing dataﬂow information. This approach can be layered
over existing techniques for learning control-ﬂows. We pre-
sented a formal treatment of data ﬂow properties of traces,
and presented an efﬁcient learning algorithm that is param-
eterized with respect to relations of interest. Through exper-
imental evaluation, we showed that the approach was effec-
tive in detecting sophisticated attacks on which most pre-
vious techniques fail. We also established that the models
are compact and produce low false alarm rates. An impor-
tant beneﬁt of our approach is that it enables formal reason-
ing about the security guarantees that can be provided when
these models are used for intrusion detection.
Acknowledgments
We thank Diptikalyan Saha for his invaluable help with ver-
iﬁcation, and Zhenkai Liang for his support with system
call interposition environment for model extraction. We
would also like to thank Shabbir Dahodwala, Daniel C. Du-
Varney, Yow-Jian Lin and C.R. Ramakrishnan for several
discussions on model extraction and veriﬁcation. Finally,
we thank the anonymous reviewers for their insightful com-
ments and suggestions.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply. 
[20] K. Lhee and S. J. Chapin. Detection of ﬁle-based race con-
ditions. International Journal of Information Security (IJIS),
4(1-2):105–119, 2005.
[21] C. C. Michael and A. Ghosh. Simple, state based approaches
to program-based anomaly detection. In ACM Transactions
on Information and System Security (TISSEC), 2002.
[22] J. Perkins and M. Ernst. Efﬁcient incremental algorithms for
dynamic detection of likely invariants. In ACM International
Symposium on Foundations of Software Engineering (FSE),
Newport Beach, CA, USA, November 2004.
Improving host security with system call poli-
In USENIX Security Symposium, Washington, DC,
[23] N. Provos.
cies.
USA, August 2003.
[24] W. Purczynski. GNU ﬁleutils - recursive directory removal
race condition, March 2002. Bugtraq-ﬁleutils mailing list.
[25] R. Sekar, M. Bendre, P. Bollineni, and D. Dhurjati. A fast
automaton-based approach for detecting anomalous program
In IEEE Symposium on Security and Privacy,
behaviors.
2001.
[26] R. Sekar, V. Venkatakrishnan, S. Basu, S. Bhatkar, and D. C.
DuVarney. Model-carrying code: A practical approach for
safe execution of untrusted applications. In ACM Symposium
on Operating Systems Principles (SOSP), Bolton Landing,
New York, October 2003.
[27] G. Tandon and P. Chan. Learning rules from system call
arguments and sequences for anomaly detection. In ICDM
Workshop on Data Mining for Computer Security (DMSEC),
pages 20–29, 2003.
[28] E. Tsyrklevich and B. Yee. Dynamic detection and preven-
tion of race conditions in ﬁle accesses. In USENIX Security
Symposium, Washington, DC, USA, August 2003.
[29] P. Uppuluri, A. Ray, and U. Joshi. Preventing race condition
In (ACM) Symposium on Applied
attacks on ﬁle systems.
Computing (SAC), 2005.
[30] D. Wagner and D. Dean. Intrusion detection via static anal-
ysis. In IEEE Symposium on Security and Privacy, Oakland,
CA, May 2001.
[31] D. Wagner and P. Soto. Mimicry attacks on host based in-
trusion detection systems. In ACM conference on Computer
and Communications Security (CCS), 2002.
[32] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting intru-
sions using system calls: Alternative data models. In IEEE
Symposium on Security and Privacy, pages 133–145, 1999.
[33] A. Wespi, M. Dacier, and H. Debar. Intrusion detection using
variable-length audit trail patterns. In Recent Advances in In-
trusion Detection (RAID), Toulouse, France, October 2000.
[34] Wikipedia. http://en.wikipedia.org/wiki/Trie.
[35] XSB. The XSB logic programming system v2.3, 2001.
Available from http://www.cs.sunysb.edu/˜sbprolog.
References
[1] G. Ammons, R. Bodik, and J. Larus. Mining speciﬁca-
In ACM Symposium on Principles of Programming
tions.
Languages (POPL), January 2002.
[2] M. Bishop and M. Dilger. Checking for race conditions in
ﬁle accesses. Computing Systems, 9(2):131–152, 1996.
[3] CERT CC. CERT Advisory CA-2001-33 Multiple Vulnera-
bilities in WU-FTPD, 2001.
[4] H. Chen, D. Dean, and D. Wagner. Model checking one
million lines of C code. In Network and Distributed System
Security Symposium, San Diego, CA, February 2004.
[5] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. Iyer. Non-
control-data attacks are realistic threats. In USENIX Security
Symposium, Baltimore, MD, August 2005.
[6] H. Feng, J. Gifﬁn, Y. Huang, S. Jha, W. Lee, and B. P. Miller.
Formalizing sensitivity in static analysis for intrusion detec-
tion. In IEEE Symposium on Security and Privacy, 2004.
[7] H. Feng, O. Kolesnikov, P. Folga, W. Lee, and W. Gong.
In IEEE
Anomaly detection using call stack information.
Symposium on Security and Privacy, May 2003.
[8] Common
trix v2.0.
http://www.tripwire.com/ﬁles/literature/poster
/Tripwire exploit poster.pdf, 2002.
vulnerability ma-
Published on World-Wide Web at URL
[9] D. Gao, M. K. Reiter, and D. Song. Gray-box extraction
In ACM con-
of execution graphs for anomaly detection.
ference on Computer and Communications Security (CCS),
pages 318–329, Washington, DC, October 2004.
security
exploit
and
[10] D. Gao, M. K. Reiter, and D. Song. On gray-box program
tracking for anomaly detection. In USENIX Security Sympo-
sium, pages 103–118, San Diego, CA, USA, August 2004.
[11] A. Ghosh and A. Schwartzbard. A study in using neural net-
works for anomaly and misuse detection. In USENIX Secu-
rity Symposium, Washington, DC, August 1999.
[12] J. T. Gifﬁn, D. Dagon, S. Jha, W. Lee, and B. P. Miller.
In Recent Ad-
Environment-sensitive intrusion detection.
vances in Intrusion Detection (RAID), September 2005.
[13] J. T. Gifﬁn, S. Jha, and B. P. Miller. Detecting manipulated
remote call streams. In USENIX Security Symposium, San
Francisco, CA, August 2002.
[14] J. T. Gifﬁn, S. Jha, and B. P. Miller. Efﬁcient context-
In Network and Distributed
sensitive intrusion detection.
System Security Symposium, San Diego, CA, February 2004.
[15] S. A. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion detec-
tion using sequences of system calls. Journal of Computer
Security (JCS), 6(3):151–180, 1998.
[16] C. Ko, G. Fink, and K. Levitt. Automated detection of vul-
nerabilities in privileged programs by execution monitoring.
In Annual Computer Security Applications Conference (AC-
SAC), December 1994.
[17] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna.
Automating mimicry attacks using static binary analysis. In
USENIX Security Symposium, Baltimore, MD, August 2005.
[18] C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the de-
In European
tection of anomalous system call arguments.
Symposium on Research in Computer Security, Gjøvik, Nor-
way, October 2003.
[19] L. C. Lam and T. Chiueh. Automatic extraction of accurate
application-speciﬁc sandboxing policy. In Recent Advances
in Intrusion Detection (RAID), Sophia Antipolis, French
Riviera, France, September 2004.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply.