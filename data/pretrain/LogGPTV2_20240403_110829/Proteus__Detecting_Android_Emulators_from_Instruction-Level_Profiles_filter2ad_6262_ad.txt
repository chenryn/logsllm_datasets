5.4 Improving the Fidelity of QEMU
With the capabilities of Proteus for identifying and classifying divergences in
instruction-level behavior, in this section, we show the feasibility of eliminating
the sources of discrepancies to improve QEMU’s ﬁdelity.
We have modiﬁed the QEMU source code of
the SDK emulator to eliminate the top 3 detec-
tion methods in Table 2 based on incomplete san-
itization of opcodes for Undefined encodings.
Speciﬁcally, based on the ARM ISA speciﬁcation
[4], we ﬁxed the decoding logic of QEMU to ver-
ify all opcode ﬁelds for these 3 cases and trigger
an illegal instruction exception for the Undefined
encodings.
These ﬁxes eliminated 1190 divergent cases
in Table 2. Using various CPU benchmarks from
MiBench suite [16], in Fig. 5, we veriﬁed that the
minimal extra code needed to perform additional opcode checks does not intro-
duce any measurable performance overhead. We acknowledge, however, that
addressing the alignment check and endianness support in QEMU will require
more comprehensive changes than the missing opcode checks for Undefined
encodings.
Fig. 5. Overhead evaluation of
ﬁdelity enhancements.
6 Discussion and Limitations
Countermeasures: One possible defense against the CPU semantic attacks
demonstrated in this work is to, as evaluated in Sect. 5.4, ﬁx the root causes of
instruction-level discrepancies in QEMU. We believe enhancing the ﬁdelity of
QEMU is crucial considering the critical role of emulators for Android malware
analysis and the growing number of malicious apps that seek to leverage evasion
tactics. As a ﬁrst step towards this objective, we are disclosing our root cause
ﬁndings and, in fact, have already shared a patch with the QEMU’s maintainers.
As Proteus enumerates a set of divergent instructions, similar to prior work
that inspects x86 binaries to detect evasion [13], we can scan Android apps for
the presence of divergent instructions. Such analysis can be adopted by malware
20
O. Sahin et al.
analyzers (e.g., Google’s Bouncer [23]) to discover evasive malware that leverages
these detection heuristics and prevent them from infecting the Android users.
Another potential countermeasure against the evasive malware that leverages
low-level CPU discrepancies is to use real hardware for dynamic analysis instead
of emulators [22]. Such a fundamentally diﬀerent approach can eliminate CPU-
level discrepancies. However, practical limitations such as cost, scalability and
maintenance inhibits wide-spread adoption of such approaches. In addition, the
instrumentation required for analyzing applications on physical devices intro-
duces artifacts itself which allows for ﬁngerprinting [27]. Thus, malware analysis
systems for Android will continue to rely on emulators [23,28,30].
Limitations: Proteus uncovers several classes of observable artifacts in ARM
CPU implementations between emulator and real devices. However, there could
be other instruction-level discrepancies in current Android emulators that our
system could not identify as our scope in this work was limited in several direc-
tions. This section discusses these limitations and describes the open-problems.
We demonstrated the capabilities of Proteus on the ARMv7 architecture
and for the instructions in ARM mode. Recent Android devices also use the
latest 64-bit ARMv8 variant of the ISA. Since ARMv8 provides compatibility
with ARMv7, as evaluated in Sect. 5.3, the discrepancies we have discovered in
this work also apply to ARMv8 CPUs. Discovering ARMv8-speciﬁc discrepancies
using Proteus simply requires acquiring a Fast Model for an ARMv8 CPU (e.g.,
Cortex-A53) and repeating the experiments. Our present work did not explore
instructions executing in Thumb mode which provides improved code density
via 16-bit instructions with limited functionality. Finally, this work focuses on
the ARM registers and did not explore potential discrepancies in the extension
registers used by VFP/SIMD instructions. Expanding our system to include
Thumb instructions and extension registers is part of our immediate future work.
Our present study also does not fully address data-dependent divergences
(e.g., depending on the input values from registers or memory). Such limitation
is common to fuzzing approaches as exhaustively exploring all possible inputs
is computationally infeasible. One approach to improve Proteus in this regard
would be to repeat the same test cases with several randomized inputs as well
as corner cases (e.g., min/max values) as in prior work [21,27].
As discussed in Sects. 5.2 and 5.3, some of the divergences found by Proteus
are due to Unpredictable instructions and do not correspond to an implemen-
tation ﬂaw. This is particularly the case as the ARMv7 speciﬁcation written
in SML [15], which we used to check Unpredictable instructions, does not
cover all Unpredictable instruction encodings. A signiﬁcant contribution of our
analysis is that we discovered deterministic CPU-level discrepancies even in the
presence of some Unpredictable instructions in our test cases. Recently, ARM
has released an oﬃcial machine readable ISA speciﬁcation written in a domain-
speciﬁc language named ASL [5]. Unfortunately, the lack of oﬃcial documen-
tation and tools to work with ASL prevents us from relying on this resource.
However, we ﬁnd ASL speciﬁcations a promising future solution for enumerating
Unpredictable encodings and improving our overall testing methodology.
Proteus: Detecting Android Emulators from Instruction-Level Proﬁles
21
7 Related Work
This sections overviews prior work on discovering emulation detection methods
and explains how Proteus distinguishes from or complements them. We also
discuss existing defense approaches against evasive malware.
Finding Discrepancies of Emulation Environments: Jing et al. [17] iden-
tify a large number of detection heuristics based on the diﬀerences in ﬁle sys-
tem entries and return values of Android API calls. For instance, presence of
“/proc/sys/net/ipv4/tcp_syncookies” ﬁle or a False return value from the
“isTetheringSupported()” API implies emulation. Such discrepancies can be
easily concealed by editing Android’s system images and API implementations
to fake real device view [12,19]. Petsas et al. detect QEMU-based emulation by
observing the side eﬀects of caching and scheduling on QEMU [25]. Other work
leverages performance side channel due to low graphics performance on emula-
tors to ﬁngerprint emulation [29]. These techniques, however, have practical lim-
itations as they require many repeated trial and observations which increases the
detection risk of malware. Our work systematically uncovers observable diﬀer-
ences in instruction semantics, which achieve deterministic emulation detection
through execution of a single CPU instruction.
Similar to our approach, other works also aim at discovering discrepancies
of emulators at instruction granularity. Various techniques [21,24] execute ran-
domized instructions on emulator and real hardware to identify the discrepancies
of x86 emulators. To ensure coverage of a wide set of instructions, other work
[27] carefully constructs tests cases with unique instructions based on manual
analysis of the x86 ISA manual while our technique is fully automated. In addi-
tion, the analysis and ﬁndings of these studies are limited to x86 instruction
set only while the vast majority of mobile devices are powered by ARM CPUs.
In addition, these studies classify divergences based on instructions (e.g., using
mnemonic, opcodes) which oversees the fact that even diﬀerent instructions (e.g.,
LDM and STM) can diverge due to the same root cause (e.g., missing alignment
check). Our study points to the unique root causes in the implementation of
CPU emulators. Thus, as we show in Sect. 5.4, our ﬁndings are readily use-
ful for improving the ﬁdelity of QEMU. Finally, as reliance on physical CPUs
practically limits the number of test cases (e.g., instructions, register/memory
operands, system register settings), we propose a novel scalable system which
uses accurate functional models of ARM CPUs (i.e., Fast Models).
Martingoni et al. [20] used symbolic execution traces from a high-ﬁdelity
emulator to construct test cases that would achieve high coverage while testing
a low-ﬁdelity emulator. Unavailability of such high-ﬁdelity emulator for Android,
however, limits the applicability of this technique for our use.
Defense Against Evasive Malware: Several work proposes to detect diver-
gent behavior in malware as a defense mechanism. Balzorotti et al. [11] detect
divergent behavior due to instruction semantics by replaying applications on
emulators with the system call sequences gathered from real devices and compar-
ing the runtime behavior. Lindorfer et al. [18] propose a more generic methodol-
22
O. Sahin et al.
ogy for detecting evasive malware based on the similarity of execution behaviors
collected from a set of virtual machines. These approaches do not systematically
expose potential causes of divergences that a future malware can use. Our work
addresses the problem of proactively ﬁnding these instruction-level discrepancies
and opens the possibility of pre-emptively ﬁxing them.
Speciﬁcally for Android, other works [12,19] systematically remove observ-
able diﬀerences from API calls, ﬁle system and properties of emulator devices
and demonstrate resistance against evasion. Such approaches, however, require
enumeration of root causes of discrepancies. Our Proteus system aids these
approaches by enumerating the divergent cases between emulator and real CPUs.
8 Conclusion
Scalable dynamic analysis of Android malware relies on emulators. Due to pres-
ence of observable discrepancies between emulated and real systems, however, a
malware can detect emulation-based analysis and alter behavior to evade detec-
tion. Restoring the eﬀectiveness of Android malware analysis requires systematic
approaches to proactively identify potential detection tactics that can be used by
malicious authors. This work presented the ﬁrst systematic study of diﬀerences in
instruction-level behavior of emulated and real ARM CPUs that power the vast
majority of Android devices. We presented the Proteus system for large-scale
exploration of CPU semantic attacks against Android emulators. Proteus auto-
matically analyzed detailed instruction-level traces collected from QEMU and
accurate software models of ARM CPUs and revealed several major root causes
for instruction-level discrepancies in QEMU. We demonstrated the feasibility of
enhancing the ﬁdelity of QEMU by ﬁxing the root causes of divergences without
any performance impact. We are disclosing our ﬁndings and submitted patches to
QEMU as a step towards improving QEMU’s resiliency against evasive malware.
Acknowledgement. This work was supported by the Oﬃce of Naval Research under
grants N00014-15-1-2948 and N00014-17-1-2011. We would also like to thank Arm
for providing us access to the Fast Models used in this work. Any opinions, ﬁndings,
conclusions, or recommendations expressed in this material are those of the authors
and do not necessarily reﬂect those of the sponsor.
References
1. Analyzing Xavier: An Information-Stealing Ad Library on Android. https://blog.
trendmicro.com/trendlabs-security-intelligence/analyzing-xavier-information-
stealing-ad-library-android/
2. Android Native Development Kit (NDK). https://developer.android.com/ndk/
3. ARM Fast Models. https://developer.arm.com/products/system-design/fast-
guides/index.html
models
4. ARMv7-A/R Architecture Reference Manual. http://infocenter.arm.com/help/
index.jsp?topic=/com.arm.doc.ddi0406c/index.html
Proteus: Detecting Android Emulators from Instruction-Level Proﬁles
23
5. Exploration Tools, A-Proﬁle Architectures. https://developer.arm.com/products/
architecture/a-proﬁle/exploration-tools
6. Google has 2 billion users on Android. https://techcrunch.com/2017/05/17/
google-has-2-billion-users-on-android-500m-on-google-photos/
7. Grabos Malware.
https://securingtomorrow.mcafee.com/consumer/consumer-
threat-notices/grabos-malware/
8. NetWinder Floating Point Notes. http://netwinder.osuosl.org/users/s/scottb/
public_html/notes/FP-Notes-all.html
9. Number of Android applications. https://www.appbrain.com/stats/number-of-
android-apps
qemudetect.pdf
10. QEMU emulation detection. https://wiki.koeln.ccc.de/images/d/d5/Openchaos_
11. Balzarotti, D., Cova, M., Karlberger, C., Kruegel, C., Kirda, E., Vigna, G.: Eﬃcient
detection of split personalities in malware. In: NDSS (2010). http://www.eurecom.
fr/publication/3022
12. Bordoni, L., Conti, M., Spolaor, R.: Mirage: toward a stealthier and modular mal-
ware analysis sandbox for android. In: Foley, S.N., Gollmann, D., Snekkenes, E.
(eds.) ESORICS 2017. LNCS, vol. 10492, pp. 278–296. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-66402-6_17
13. Branco, R.R., Barbosa, G.N., Neto, P.D.: Scientiﬁc but not academical overview of
malware anti-debugging, anti-disassembly and Anti-VM technologies. In: BlackHat
(2012)
14. Egele, M., Scholte, T., Kirda, E., Kruegel, C.: A survey on automated dynamic
malware-analysis techniques and tools. ACM Comput. Surv. (CSUR) 44(2), 6:1–
6:42 (2008). https://doi.org/10.1145/2089125.2089126
15. Fox, A.: Directions in ISA speciﬁcation. In: Beringer, L., Felty, A. (eds.) ITP 2012.
LNCS, vol. 7406, pp. 338–344. Springer, Heidelberg (2012). https://doi.org/10.
1007/978-3-642-32347-8_23
16. Guthaus, M.R., Ringenberg, J.S., Ernst, D., Austin, T.M., Mudge, T., Brown,
R.B.: MiBench: a free, commercially representative embedded benchmark suite.
In: IEEE International Workshop on Workload Characterization (IISWC) (2001)
17. Jing, Y., Zhao, Z., Ahn, G.J., Hu, H.: Morpheus: automatically generating heuris-
tics to detect android mulators. In: Proceedings of the 30th Annual Computer
Security Applications Conference (ACSAC), pp. 216–225. ACM (2014). https://
doi.org/10.1145/2664243.2664250
18. Lindorfer, M., Kolbitsch, C., Milani Comparetti, P.: Detecting environment-
sensitive malware. In: Sommer, R., Balzarotti, D., Maier, G. (eds.) RAID 2011.
LNCS, vol. 6961, pp. 338–357. Springer, Heidelberg (2011). https://doi.org/10.
1007/978-3-642-23644-0_18
19. Liu, L., Gu, Y., Li, Q., Su, P.: RealDroid: large-scale evasive malware detection
on “real devices”. In: 26th International Conference on Computer Communication
and Networks (ICCCN), pp. 1–8, July 2017. https://doi.org/10.1109/ICCCN.2017.
8038419
20. Martignoni, L., McCamant, S., Poosankam, P., Song, D., Maniatis, P.: Path-
exploration lifting: hi-ﬁ tests for lo-ﬁ emulators. In: International Conference on
Architectural Support for Programming Languages and Operating Systems (ASP-
LOS), pp. 337–348. ACM, New York (2012). https://doi.org/10.1145/2150976.
2151012
21. Martignoni, L., Paleari, R., Roglia, G.F., Bruschi, D.: Testing CPU emulators.
In: International Symposium on Software Testing and Analysis (ISSTA) (2009).
https://doi.org/10.1145/1572272.1572303
24
O. Sahin et al.
22. Mutti, S., et al.: Baredroid: large-scale analysis of android apps on real devices. In:
Annual Computer Security Applications Conference, ACSAC (2015). https://doi.
org/10.1145/2818000.2818036
23. Oberheide, J., Miller, C.: Dissecting the android bouncer. In: SummerCon (2012)
24. Paleari, R., Martignoni, L., Roglia, G.F., Bruschi, D.: A ﬁstful of red-pills: how
to automatically generate procedures to detect CPU emulators. In: Proceedings of
the 3rd USENIX Conference on Oﬀensive Technologies (WOOT) (2009)
25. Petsas, T., Voyatzis, G., Athanasopoulos, E., Polychronakis, M., Ioannidis, S.: Rage
against the virtual machine: hindering dynamic analysis of android malware. In:
European Workshop on System Security (EuroSec), pp. 5:1–5:6 (2014). https://
doi.org/10.1145/2592791.2592796
26. Poeplau, S., Fratantonio, Y., Bianchi, A., Kruegel, C., Vigna, G.: Execute this!
Analyzing Unsafe and Malicious Dynamic Code Loading in Android Applications.
In: Network and Distributed System Security Symposium (NDSS) (2014)
27. Shi, H., Alwabel, A., Mirkovic, J.: Cardinal pill testing of system virtual machines.
In: 23rd USENIX Conference on Security Symposium (2014)
28. Tam, K., Khan, S.J., Fattori, A., Cavallaro, L.: Copperdroid: Automatic recon-
struction of android malware behaviors. In: NDSS (2015)
29. Vidas, T., Christin, N.: Evading android runtime analysis via sandbox detection.
In: Proceedings of the 9th ACM Symposium on Information, Computer and Com-
munications Security (ASIA CCS), pp. 447–458. ACM (2014). https://doi.org/10.
1145/2590296.2590325
30. Yan, L.K., Yin, H.: DroidScope: seamlessly reconstructing the OS and Dalvik
semantic views for dynamic android malware analysis. In: 21st USENIX Security
Symposium, Bellevue, WA, pp. 569–584. USENIX (2012). https://www.usenix.
org/conference/usenixsecurity12/technical-sessions/presentation/yan