the most expensive phase of any searchable encryption scheme.
Our index generation performance measurements include en-
cryption of documents and all other operations except the
cost of plaintext index generation. Plaintext index generation
performance is orthogonal to our contributions, doesn’t reﬂect
the performance of our system and is ignored by all prior work.
Figure 10 shows our index generation performance on the
email dataset. Our performance is much better when compared
to that of [18], which takes 52 seconds to process 16MB of
data. Our scheme can process 256MB (16 times more data)
in about 35s. [18] extrapolates this to to 16GB of text e-
mails without any attachments and, since the time for index
generation scales roughly linearly with data, estimates that
their index generation would take 15 hours; in contrast, it
would take only 41 minutes in our scheme.
This matches our conclusion from the micro-benchmarks
evaluation, that our index generation operation is at least an
order of magnitude faster than that of [18].
Figure 11 shows the performance of our scheme on the
document dataset.
Fig. 10: SSE.indexgen performance on email dataset with 99%
conﬁdence intervals: SKE stands for Symmetric Key Encryption and
is the time required to encrypt the documents. All SKE costs are
non-zero but some are very small.
Fig. 9: File/Keyword pair versus amortized time for SSE.indexgen.
Time per ﬁle/keyword pair tends to 1.58µs, much better than the 35µs
reported in [18] in a similar dataset.
B. Full evaluation
Each data point for Index Generation is the average of 5
runs of SSE.indexgen. Each data point for the Search is the
average of 5 runs using the most frequent English word "the".
Each data point for addition is the average of at least 5 runs.
1) Parameters Used: The parameters used for the experi-
ments guarantee perr ≤ 2−80 (recall that perr is the probability
of the scheme aborting and measures the security “error”) if
less than 1/8 of the total blocks in D are ﬁlled and guarantee
perr ≤ 2−40 if less than 1/4 of the total blocks in D are ﬁlled.
We set κ = 80 and α = 4, block size of D to 256 bytes, the
total number of blocks in D to nD = 224.
Fig. 11: SSE.indexgen on the document dataset with 99% conﬁdence
intervals
Communication costs. The communication cost of initial index
upload depends upon the parameters used for Blind-Storage,
and speciﬁcally, the size of the array D. As mentioned above,
in Section VII-B1, the size of D was set to 1GB (224 blocks of
256 bytes each) in our experiments. In comparison, the actual
amount of index data for the 256MB subset of the email dataset
consisted of 20,694,991 ﬁle-keyword pairs, which, using 4-
byte ﬁelds for document IDs, translates to about 78MB of data.
Given the small size of some of the index ﬁles, on formatting
this data into 256-byte blocks for the Blind-Storage scheme,
this resulted in about 178MB data. For our choice of κ and α,
γ = 4 is sufﬁcient to bring perr below 2−40. That is, it would
652
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:56 UTC from IEEE Xplore.  Restrictions apply. 
be sufﬁcient to use about 712MB as the size of D. Hence
the choice of 1GB as the size of D in our experiments leaves
abundant room to add more documents later.
For the document dataset, there are only 1,371,656 ﬁle-
keyword pairs, which translates to a plaintext index size of
5MB (with 4-byte document IDs). Thus the size of D could be
as low as 20MB. Note that the document collection itself is of
size 1GB in this case. For rich data formats, it will typically be
the case that the communication overhead due to SSE.indexgen
would be only a fraction of the communication requirement for
the documents themselves.
3) Search: Figure 12 shows the search performance of
our scheme excluding the ﬁnal decryption of the documents.
Figure 12 does include overhead incurred at search time to
handle lazy delete. We searched for the most frequent English
word “the” and it was present in almost all the documents.
(The exact query word is not mentioned in the previous work
we are comparing against, so we chose a worst-case scenario
for our experiments.) Our scheme performed better than [18]
for all data sizes. Their scheme needs 17 ms, 34 ms and
53 ms for 4MB, 11MB and 16MB subsets of the Enron
dataset respectively. Our scheme consumed 5 ms, 11 ms and
25 ms for 4MB, 8MB and 16MB subsets of the Enron dataset
respectively. The search time grows proportionately to the size
of the response. Figure 13 shows the search performance on
the document dataset.
Fig. 12: Search performance on the email dataset with 99% conﬁ-
dence intervals
Fig. 14: Communication needed for searching on the email dataset.
The graph shows the size of the retrieved documents themselves
alongside the extra communication incurred by our scheme.
As it turns out (and as was experimentally conﬁrmed), the
overhead for searches does not signiﬁcantly vary depending on
whether the search operation involved a lazy deletion or not.
This is because all search operations use the update mechanism
of the underlying Blind-Storage scheme and the clear storage
scheme. The efﬁciency of the update mechanism itself does not
depend signiﬁcantly on whether the ﬁle was modiﬁed or not.
Indeed, in the case of Blind-Storage updates, it is important
for the security that it must not be revealed to the server if a
lazy deletion was involved or not.16
Communication costs. As our scheme does not
involve
any server-side computation, we download slightly more data
compared to [18]. But as shown in Figure 14, for the email
dataset, the communication overhead is negligible compared
to the size of the documents retrieved. The document dataset
is much richer and contains much fewer keywords compared
to the email dataset of the same size (1GB of documents in
our dataset contains only 70MB of text), and therefore the
overhead would be even lower for it.
4) Add: As opposed to [18] and other prior work, per-
formance of our add operation does not depend upon the
amount of data (i.e. the number of ﬁle-keyword pairs) already
present in the searchable encryption system. Figure 15 shows
the performance of addition of ﬁles of speciﬁed size when
256MB of data was initially indexed into the system.
Fig. 13: Search performance on the document dataset with 99%
conﬁdence intervals
Note that our scheme uses a lazy deletion strategy to
handle removals. This lazy delete mechanism allows us to
obtain vastly improved security guarantees by limiting the
information leaked to the server (only for ﬁles uploaded during
initial index generation). One might ask if this leads to any
efﬁciency degradation during subsequent searches, since the
actual updates to the index take place when a keyword that
was contained in a deleted document is searched for later.
Fig. 15: Add performance on email dataset with 99% conﬁdence
intervals. SKE costs are non-zero but very small.
Communication costs. We only need, on average, to download
three blocks and upload two blocks per unique keyword in
the document that is being added. (If the server supports an
16We remark that our security model does not consider timing attacks.
Depending on the implementation, we do not rule out a small dependence
between the time taken and the extent of lazy delete computations involved. A
serious implementation should take this into account. Since our SSE scheme is
a relatively thin wrapper around the Blind-Storage mechanism, timing attacks
can be effectively mitigated with relative ease.
653
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:56 UTC from IEEE Xplore.  Restrictions apply. 
(SHARPS), and NSF CNS 09-64392 (EBAM). The views
expressed are those of the authors only.
REFERENCES
“Crypto++,” http://www.cryptopp.com/.
“Enron dataset,” https://www.cs.cmu.edu/~enron/.
[1]
[2]
[3] P. Brudenall, B. Treacy, and P. Castle, “Outsourcing to the cloud:
data security and privacy risks,” Financier Worldwide and Hunton &
Williams, 2010.
[4] R. Canetti, “Universally composable security: A new paradigm for
cryptographic protocols,” Electronic Colloquium on Computational
Complexity (ECCC) TR01-016, 2001, previous version “A uniﬁed
framework for analyzing security of protocols” available at the ECCC
archive TR01-016. Extended abstract in FOCS 2001.
[5] D. Cash, J. Jaeger, S. Jarecki, C. Jutla, H. Krawczyk, M. Ro¸su, and
M. Steiner, “Dynamic searchable encryption in very large databases:
Data structures and implementation,” 2014.
[6] D. Cash, S. Jarecki, C. Jutla, H. Krawczyk, M. Rosu, and M. Steiner,
“Highly-scalable searchable symmetric encryption with support for
boolean queries,” in CRYPTO, 2013.
[7] Y.-C. Chang and M. Mitzenmacher, “Privacy preserving keyword
searches on remote encrypted data.” in ACNS, 2005, pp. 442–455.
[8] M. Chase and S. Kamara, “Structured encryption and controlled disclo-
sure,” in ASIACRYPT, 2010, pp. 577–594.
[9] R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky, “Searchable
symmetric encryption: Improved deﬁnitions and efﬁcient constructions,”
Journal of Computer Security, vol. 19, no. 5, pp. 895–934, 2011.
[10] R. Curtmola, J. A. Garay, S. Kamara, and R. Ostrovsky, “Searchable
symmetric encryption: improved deﬁnitions and efﬁcient constructions,”
in CCS, 2006, pp. 79–88.
[11] E.-J. Goh, “Secure indexes,” Cryptology ePrint Archive, Report
2003/216, 2003, http://eprint.iacr.org/2003/216/.
[12] O. Goldreich, Foundations of Cryptography: Basic Applications. Cam-
bridge University Press, 2004.
[13] O. Goldreich and R. Ostrovsky, “Software protection and simulation on
oblivious RAMs,” J. ACM, vol. 43, no. 3, pp. 431–473, 1996.
[14] P. Golle, J. Staddon, and B. R. Waters, “Secure conjunctive keyword
search over encrypted data.” in ACNS, 2004, pp. 31–45.
[15] W. Jansen and T. Grance, “Guidelines on security and privacy in public
cloud computing,” NIST special publication, pp. 800–144, 2011.
[16] S. Jarecki, C. Jutla, H. Krawczyk, M. Rosu, and M. Steiner, “Outsourced
symmetric private information retrieval,” in CCS. ACM, 2013, pp.
875–888.
[17] S. Kamara and C. Papamanthou, “Parallel and dynamic searchable
symmetric encryption,” in Financial Cryptography and Data Security,
FC (2013), 2013.
[18] S. Kamara, C. Papamanthou, and T. Roeder, “Dynamic searchable
symmetric encryption,” in CCS, 2012, pp. 965–976.
[19] K. Kurosawa and Y. Ohtaki, “UC-secure searchable symmetric encryp-
tion,” in Financial Cryptography and Data Security (FC), 2012.
[20] R. Ostrovsky, “Efﬁcient computation on oblivious RAMs,” in STOC,
1990, pp. 514–523.
[21] S. Paquette, P. T. Jaeger, and S. C. Wilson, “Identifying the security risks
associated with governmental use of cloud computing,” Government
Information Quarterly, vol. 27, no. 3, pp. 245 – 253, 2010.
[22] B. Pinkas and T. Reinman, “Oblivious RAM revisited,” in CRYPTO,
2010, pp. 502–519.
[23] D. X. Song, D. Wagner, and A. Perrig, “Practical techniques for searches
on encrypted data.” in IEEE S&P, 2000, pp. 44–55.
[24] E. Stefanov, C. Papamanthou, and E. Shi, “Practical dynamic searchable
encryption with small leakage,” 2014.
[25] E. Stefanov and E. Shi, “Oblivistore: High performance oblivious cloud
storage,” in IEEE S&P, 2013, pp. 253–267.
[26] E. Stefanov, E. Shi, and D. Song, “Towards practical oblivious RAM,”
in NDSS, 2012.
[27] P. van Liesdonk, S. Sedghi, J. Doumen, P. H. Hartel, and W. Jonker,
“Computationally efﬁcient searchable symmetric encryption,” in Work-
shop on Secure Data Management (SDM), 2010, pp. 87–100.
Fig. 16: Add performance on document dataset with 99% conﬁdence
intervals: SKE costs are non-zero but very small.
append operation that allows to append data to existing ﬁles
on the server, we do not need to download any data during
Add.)
5) Remove: The communication and computation cost of
removing a document is virtually negligible, since it uses a
lazy deletion strategy. Removal of a document in our scheme
only requires the client to send a command to the server to
delete the document from its ﬁle-system, and does not need
any update to the searchable encryption index.
C. Summary
Evaluation of our scheme shows that it is more efﬁcient,
scalable and practical than prior schemes. Index generation in
our scheme is more than 20 times faster than that of [18].
Search operations are 2-3 times faster, in our experiments.
Further, unlike [18], our addition and removal
times are
independent of the total number of ﬁle-keyword pairs, and
is much more scalable. Removal in our scheme has virtually
zero cost. We stress that several possible optimizations have
not been implemented in this prototype.
VIII. CONCLUSION
In this work, we introduced a new cryptographic construct
called Blind Storage, and implemented it using a novel, yet
light-weight protocol SCATTERSTORE. We also showed how a
dynamic SSE scheme can be constructed using Blind Storage,
in a relatively simple manner. The resulting scheme is more
computationally efﬁcient, require simpler infrastructure, and is
more secure than the existing schemes.
Important future directions include making the scheme
secure against actively corrupt servers, and allowing secure
searches involving multiple keywords. The core idea of using
pseudorandom subsets in SCATTERSTORE is amenable to these
extensions, as is being explored in on going work.
ACKNOWLEDGMENT
We thank Igors Svecs for collaboration in the early stages
of the project. We are grateful to Seny Kamara for helping us
with evaluation datasets and Elaine Shi for useful discussions.
We also thank Ravinder Shankesi for help in debugging the
code and Fahad Ullah for help in collecting documents for the
document dataset.
This work was supported by NSF 07-47027, NSF 12-
28856, NSF CNS 13-30491 (ThaW), HHS 90TR0003-01
654
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:56 UTC from IEEE Xplore.  Restrictions apply.