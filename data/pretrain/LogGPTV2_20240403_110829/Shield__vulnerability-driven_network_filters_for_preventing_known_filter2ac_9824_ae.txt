ther a misunderstanding of the protocol state machine or the
diﬀerential treatment of an exploit in the application. In this
section, we evaluate the false positve nature of our Shield-
LSP implementation. We focus our attention on the Shield
we designed for Slammer [40], which exploits the SSRP pro-
tocol of SQL Server 2000.
We obtained a stress test suite for SSRP from the vendor.
SSRP is a very simple protocol with only 12 message types.
The test suite contains a total of 36 test cases for exhaustive
testing of SSRP requests of various forms. Running this
test suite against our Shield, we did not observe any false
positives. Of course, this example does not prove that Shield
is false positive-free.
9. RELATED WORK
The onsets of CodeRed [7], Slammer [40], and MSBlast [24]
in the past few years have provoked great interest in worm
defense research. Many [23, 42, 22, 45] have characterized
and analyzed the fast- and wide-spreading nature and po-
tential [47, 6] of modern-day worms.
Most worm attacks today exploit software defects, such as
buﬀer overruns on stacks or heaps, for remote code execu-
tion. Static checkers that perform data ﬂow analysis [3, 44]
over source code have been eﬀective in ﬁnding software de-
fects systematically before software releases. However, such
tools are not false negative-free. Mitigation techniques, such
as Stackguard [9] and non-executable stacks or heaps, raise
the bar for software defect exploitation, but attackers can
cross the bar with new exploitation techniques [28, 49, 19].
Attack prevention techniques address attacks against known
vulnerabilities. These techniques make use of well-deﬁned
invariants, namely the known vulnerabilities. Both software
patching and Shield fall into this category. Section 1 gives
detailed comparisons between the two.
2535455565758595101520501001502005001000# of ClientsCPU Usage (%)No Shield, No LSPLSP, No ShieldLSP and Shield3003504004505005506006500100200300400500# of ClientsThroughput (Mbps)No Shield, No LSPLSP, No ShieldLSP and ShieldWorm containment techniques are typically used for con-
taining known worms. Firewalls can be used for this pur-
pose, by, for example, blocking a port that is under attack.
Firewalls have a function similar to Shield, but work in
a much cruder way — rarely customized in response to a
particular vulnerability, for instance. They are usually not
deployed on the end host, and thus vulnerable to evasion
opportunities [32] for attackers. Moreover, ﬁrewalls are un-
aware of most application-level protocols (and may not even
have access to them — if, for example, traﬃc is encrypted).
Exploit signature-based Network Intrusion Prevention sys-
tems (NIPS), such as Snort-based Hogwash [41], ﬁlter out
malicious traﬃc according to attack signatures. The signa-
tures are typically in the form of regular expressions. Traf-
ﬁc blocking is based on packet-level inspection and pattern
matching, which can be easily manipulated by attackers
to cause false negatives and false positives, since applica-
tion messages can be scattered over multiple packets [32].
These systems require fast signature extraction algorithms
(e.g., EarlyBird [39], Autograph [5]) for them to be worm-
containing. The biggest challenge these algorithms face is
polymorphic or metamorphic worms.
Rate-limiting [48] is another containment method that
throttles the sending rate at an infected end host. The con-
tainment method — blocking the detected scanning activity
of compromised nodes [46] — has also been explored as a
weapon against scanning worms. Rate-limiting and scan-
ning worm containment are mostly useful for fast-spreading
worms, rather than the “stealthy” kind.
Network Intrusion Detection Systems (NIDS), exempliﬁed
by Bro [27] and Snort [41], monitor network traﬃc and de-
tect attacks of known exploits. NIDS are usually more cus-
tomized by application than ﬁrewalls, but deal with known
exploits rather than known vulnerabilities. Unlike Shield,
NIDS are not on the traﬃc forwarding path. Moreover, they
focus on detection rather than attack prevention. For more
reliable attack detection, “traﬃc normalizers” [37, 14] or
“protocol scrubbers” [20] have been proposed to protect the
forwarding path by eliminating potential ambiguities before
the traﬃc is seen by the monitor, thus removing evasion
opportunities.
In addition to evasion, NIDS systems face
the issue of a high false postive rate, which complicates the
reaction process.
Another interesting attack detection and signature extrac-
tion mechanism is the deployment of “honeypots” that cover
“dark” or unused IP address space. Some examples are
Backscatter [23], honeyd [31], HoneyComb [18], and Hon-
eyStat [10]. Any unsolicited outgoing traﬃc from the hon-
eypots reveals the ocurrence of some attack.
10. CONCLUSIONS AND FURTHER WORK
We have shown that network-based vulnerability-speciﬁc
ﬁlters are feasible to implement, with low false positive rates,
manageable scalability, and broad applicability across proto-
cols. There are, however, still a number of natural directions
for future research on Shield:
• Further experience writing shields for speciﬁc vulner-
abilities will better indicate the range of Shield’s ap-
plicability and the adequacy of the Shield policy lan-
guage. It may also be possible to develop automated
tools to ease Shield policy generation.
For example, writing a shield policy currently requires
a fairly deep understanding of the protocol over which
the vulnerability is exploited. For protocols described
in a standard, formalized format, however, it should
be possible to build an automated tool that generates
most of the protocol-parsing portion of a shield policy.
The rest of the task of writing the policy would still
be manual, but it is often relatively easy, since the
vulnerability-exploiting portion of the incoming traﬃc
— say, an overly long ﬁeld that causes a buﬀer overrun
— is often easy to identify once the traﬃc has been
parsed.
• Shield needs not necessarily be implemented at the
end host. It may be preferable in some cases, from an
administration or performance point of view, to de-
ploy Shield in a ﬁrewall or router, or even in a special-
purpose box. However, these alternate deployment op-
tions have yet to be explored.
• One of the advantages of Shield is that shields can in
principle be tested in a relatively simple way, verifying
that some collection of traﬃc (test suites or real-world
traces) is not interfered with. Automating this process
would make the shield release process even easier.
• Ensuring the secure, reliable and expeditious distri-
bution of Shields is crucial. While releasing a patch
enables attackers to reverse-engineer the patch to un-
derstand its corresponding vulnerability, and thus to
exploit it, Shield makes reverse-engineering even eas-
ier since vulnerability signatures are spelled out in
Shield policies. Therefore, Shield distribution and in-
stallation is in an even tighter race with the exploit-
designing hacker.
• It is possible that Shield’s design might prove useful
when applied to the virus problem, since some viruses
exploit a vulnerability in the application that is in-
voked when an infected ﬁle is opened. Today, most
anti-virus software is signature-based, identifying spe-
ciﬁc exploits rather than vulnerabilities. Incorporating
shield-like technology into anti-virus systems might al-
low them to protect against generic classes of viruses
that use a particular infection method.
11. ACKNOWLEDGEMENT
Jon Pincus has given us insightful and constant advice
since the idea formation stage of the Shield project. Jay
Lorch gave us many thoughtful critiques on the ﬁrst draft
of this paper. Many Microsoft employees from the product
side have graciously helped us with understanding various
aspects of many vulnerabilities from Microsoft Security Bul-
letins and using stress test suites for a number of applica-
tion level protocols. Andrew Begel and Zhe Yang oﬀered us
helpful discussions on our policy language design and inter-
preter implementation. This work also beneﬁted from our
discussions with Nikita Borisov, David Brumley, Hao Chen,
John Dunagan, Jason Garms, Jon Howell, Yih-Chun Hu,
Jitu Padhye, Vern Paxson, Stefan Savage, Dawn Song, Nick
Weaver, and Brian Zill. The ﬁnal version of this paper is
much inﬂuenced by the anonymous SIGCOMM reviewers,
Nikita Borisov, and our shepherd, Paul Barford. We are
grateful for everyone’s help.
12. REFERENCES
[1] W. A. Arbaugh, W. L. Fithen, and J. McHugh. Windows of
Vulnerability: a Case Study Analysis. IEEE Computer,
2000.
[2] Steve Beattie, Seth Arnold, Crispin Cowan, Perry Wagle,
[26] Vern Paxson. Flex - a scanner generator - Table of
and Chris Wright. Timing the application of security
patches for optimal uptime. In LISA XVI, November 2002.
[3] William Bush, Jonathan D. Pincus, and David J. Sielaﬀ. A
Static Analyzer for Finding Dynamic Programming Errors.
Software-Practice and Experience (SP&E), 2000.
[4] Byacc. http://dickey.his.com/byacc/byacc.html.
[5] H. Chen and B. Karp. Autograph: Toward automated,
distributed worm signature detection. In Proceedings of the
13th Usenix Security Symposium, 2004.
[6] Z. Chen, L. Gao, and K. Kwiat. Modeling the Spread of
Active Worms. In Proceedings of IEEE Infocom, 2003.
[7] Microsoft Security Bulletin MS01-033, November 2003.
http://www.microsoft.com/technet/treeview/
default.asp?url=/technet/security/bulletin/MS01-033.asp.
[8] Microsoft Corp. URLScan Security Tool.
http://www.microsoft.com/technet/security/URLScan.asp.
[9] Crispin Cowan, Calton Pu, Dave Maier, Heather Hintony,
Jonathan Walpole, Peat Bakke, Steve Beattie, Aaron Grier,
Perry Wagle, and Qian Zhang. StackGuard: Automatic
Adaptive Detection and Prevention of Buﬀer-Overﬂow
Attacks. In Proceedings of 7th USENIX Security
Conference, 1998.
Contents. http://www.gnu.org/software/ﬂex/manual/.
[27] Vern Paxson. Bro: A System for Detecting Network
Intruders in Real-Time. In Computer Networks, Dec 1999.
[28] Jonathan Pincus and Brandon Baker. Mitigations for
Low-level Coding Vulnerabilities: Incomparability and
Limitations.
http://research.microsoft.com/users/jpincus/mitigations.pdf,
2004.
[29] J. Postel and J. Reynolds. Telnet Protocol Speciﬁcation
(RFC 854), May 1983.
[30] J. Postel and J. Reynolds. RFC 765 - File Transfer
Protocol (FTP), October 1985.
[31] Niels Provos. A Virtual Honeypot Framework. Technical
Report CITI-03-1, Center for Information Technology
Integration, University of Michigan, October 2003.
[32] Thomas H. Ptacek and Timothy N. Newsham. Insertion,
evasion, and denial of service: Eluding network intrusion
detection, January 1998.
http://www.insecure.org/stf/secnet ids/secnet ids.html.
[33] Eric Rescorla. Security holes... Who cares? In Proceedings
of USENIX Security Symposium, August 2003.
[34] DCE 1.1: Remote Procedure Call.
[10] David Dagon, Xinzhou Qin, Guofei Gu, Wenke Lee, Julian
http://www.opengroup.org/onlinepubs/9629399/.
Grizzard, John Levine, and Henry Owen. HoneyStat:
LocalWorm Detection Using Honeypots. In RAID, 2004.
[11] O. Dubuisson. ASN.1 - Communication Between
Heterogeneous Systems. Morgan Kaufmann Publishers,
2000.
[12] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter,
P. Leach, and T. Berners-Lee. Hypertext Transfer Protocol
– HTTP/1.1 (RFC 2616), June 1999.
[13] Alan O. Freier, Philip Karlton, and Paul C. Kocher. The
SSL Protocol Version 3.0.
http://wp.netscape.com/eng/ssl3/ssl-toc.html.
[35] W32.Sasser.Worm, April 2004.
http://securityresponse.symantec.com/avcenter/
venc/data/w32.sasser.worm.html.
[36] H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson.
RTP: A Transport Protocol for Real-Time Applications
(RFC 1889), January 1996.
[37] Umesh Shankar and Vern Paxson. Active Mapping:
Resisting NIDS Evasion Without Altering Traﬃc. In
Proceedings of IEEE Symposium on Security and Privacy,
May 2003.
[38] Richard Sharpe. Server message block.
[14] Mark Handley, Vern Paxson, and Christian Kreibich.
http://samba.anu.edu.au/cifs/docs/what-is-smb.html.
Network Intrusion Detection: Evasion, Traﬃc
Normalization, and End-to-End Protocol Semantics. In
Proceedings of USENIX Security Symposium, August 2001.
[15] Hung-Yun Hsieh and Raghupathy Sivakumar. A transport
layer approach for achieving aggregate bandwidths on
multi-homed mobile hosts. In ACM Mobicom, September
2002.
[39] Sumeet Singh, Cristian Estan, George Varghese, and Stefan
Savage. The EarlyBird System for Real-time Detection of
Unknown Worms. Technical Report CS2003-0761,
University of California at San Diego, 2003.
[40] Microsoft security bulletin ms02-039, January 2003.
http://www.microsoft.com/technet/treeview/
default.asp?url=/technet/security/bulletin/MS02-039.asp.
[16] Anthony Jones and Jim Ohlund. Network Programming for
[41] The Open Source Network Intrusion Detection System.
Microsoft Windows. Microsoft Publishing, 2002.
[17] J. Klensin. Simple Mail Transfer Protocol (RFC 2821),
April 2001.
[18] C. Kreibich and J. Crowcroft. Honeycomb: Creating
Intrusion Detection Signatures Using Honeypots. In
HotNets-II, 2003.
[19] David Litchﬁeld. Defeating the stack based buﬀer overﬂow
prevention mechanism of microsoft windows 2003 server.
http://www.nextgenss.com/papers.htm, September 2003.
[20] G. Robert Malan, David Watson, and Farnam Jahanian.
Transport and application protocol scrubbing. In
Proceedings of IEEE Infocom, 2000.
[21] P. J. McCann and S. Chandra. PacketTypes: Abstract
Speciﬁcation of Network Protocol Messages. In Proceedings
of ACM SIGCOMM, 2000.
[22] David Moore, Vern Paxson, Stefan Savage, Colleen
Shannon, Stuart Staniford, and Nicholas Weaver. Inside the
Slammer Worm.
http://www.computer.org/security/v1n4/j4wea.htm, 2003.
[23] David Moore, Colleen Shannon, and Jeﬀery Brown.
Code-Red: a case study on the spread and victims of an
Internet worm. In ACM Internet Measurement Workshop
(IMW), 2002.
[24] Microsoft Security Bulletin MS03-026, September 2003.
http://www.microsoft.com/technet/treeview/
default.asp?url=/technet/security/bulletin/MS03-026.asp.
[25] S. W. O’Malley, T. A. Proebsting, and A. B. Montz. USC:
A Universal Stub Compiler. In Proceedings of ACM
SIGCOMM, 1994.
http://www.snort.org/.
[42] Stuart Staniford, Vern Paxson, and Nicholas Weaver. How
to 0wn the Internet in Your Spare Time. In Proceedings of
the 11th USENIX Security Symposium, August 2002.
[43] Peter Szor and Peter Ferrie. Hunting for Metamorphic.
Symantec Security Response.
[44] David Wagner, Jeﬀrey S. Foster, Eric A. Brewer, and
Alexander Aiken. A First Step Towards Automated
Detection of Buﬀer Overrun Vulnerabilities. In NDSS, 2000.
[45] Nicholas Weaver, Vern Paxson, Stuart Staniford, and
Robert Cunningham. Large Scale Malicious Code: A
Research Agenda. http://www.cs.berkeley.edu/˜nweaver/
large scale malicious code.pdf, 2003.
[46] Nicholas Weaver, Stuart Staniford, and Vern Paxson. Very
Fast Containment of Scanning Worms, 2004.
http://www.icsi.berkeley.edu/ nweaver/containment/.
[47] Nick Weaver. The potential for very fast internet plagues.
http://www.cs.berkeley.edu/˜nweaver/warhol.html.
[48] Matthew M. Williamson. Throttling viruses: Restricting
propagation to defeat malicious mobile code. Technical
Report HPL-2002-172, HP Labs Bristol, 2002.
[49] Rafal Wojtczuk. Defeating Solar Designer’s Non-executable
Stack Patch. http://www.insecure.org/sploits/non-
executable.stack.problems.html, January
1998.