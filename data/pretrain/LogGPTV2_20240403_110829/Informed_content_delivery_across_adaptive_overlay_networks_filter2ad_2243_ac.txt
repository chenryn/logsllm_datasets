check whether all hi(x) are set to 1. If not, then clearly x is not
a member of S. If all hi(x) are set to 1, we assume that x is in
S, although we are wrong with some probability. Hence a Bloom
ﬁlter may yield a false positive, where it suggests that an element
x is in S even though it is not. The probability of a false positive f
depends on the number of bits used per item m/n and the number
of hash functions k according to the following equation: f = (1 −
−kn/m)k.
e
For an approximate reconciliation solution, peer A sends a Bloom
ﬁlter FA of SA; peer B would then check for each element of SB in
FA. When a false positive occurs, peer B assumes that peer A has
a symbol that it does not have, and so peer B fails to send a symbol
that would have been useful. However, the Bloom ﬁlter does not
cause peer B to ever mistakenly send peer A a symbol that is not
useful. As we have argued, if the set difference is large, the failure
to send some useful symbols is not a signiﬁcant problem.
The number of bits per element can be kept small while still achiev-
ing high accuracy. For example, using just four bits per element and
three hash functions yields an accuracy of 85.3%; using eight bits
per element and ﬁve hash functions yields an accuracy of 97.8%.
Using four bits per element, we can create ﬁlters for 10,000 symbols
using just 40,000 bits, which can ﬁt into ﬁve 1 KB packets. Further
improvements can be had by using the recently introduced com-
pressed Bloom ﬁlter, which reduces the number of bits transmitted
between peers at the cost of using more bits to store the Bloom ﬁlter
at the end-systems and requiring compression and decompression
at the peers [23]. For simplicity, we use only standard Bloom ﬁlters
in the experiments in this paper. For computation time, O(|SA|)
preprocessing is required to set up the Bloom ﬁlter, and O(|SB|)
work is required to ﬁnd the set difference.
The requirement for O(|SA|) preprocessing time and O(|SA|) bits
to be sent may seem excessive for large |SA|, especially when far
fewer than |SA| packets will be sent along a given connection.
There are several possibilities for scaling this approach up to larger
numbers of packets. For example, for large |SA| or |SB|, peer A
can create a Bloom ﬁlter only for elements of SA that are equal to
β modulo γ for some appropriate β and γ. Peer B can then only use
the ﬁlter to determine elements in SB − SA equal to β modulo γ
(still a relatively large set of elements). The Bloom ﬁlter approach
can then be pipelined by incrementally providing additional ﬁlters
for differing values of β as needed.
5.3 Approximate Reconciliation Trees
(a)
14 15
16
28
29
40 72
(c)
47
H1 = (3x+5) mod |M|
4
40
43 27
25
1
H2 = (6x+7) mod h
47
1
4
40
43 27
25
33
13
31
55
9 41
29
Randomization for tree balancing
Breaking spatial correlation
(b)
{1,4,25,27,40,43,47}
(d)
13+31+29+41+55+9+33
{1,4,25,27}
{40,43,47}
13+31+29+41
55+9+33
{1,4}
{25,27}
{40,43}
47
13+31
29+41
55+9
33
1
4
25
27
43
40
Comparison tree
13
31
29
41
9
55
A.R.T. (+ = XOR)
(e)
13+31+29+41+55+9+33
13+31+29+41
55+9+33
13+31
29+41
55+9
33
13
31
29
55
9
41
100000110100001...10101
00101000000101...100000
Internal Bloom filter
Leaf Bloom filter
Figure 3: Example of creation and Bloom ﬁltering of an approxi-
mate reconciliation tree. (M is O(poly |SA|); in this case, M =
|SA|2 = 49, h is 64, and example permutation functions are as
shown.
Bloom ﬁlters are the preferred data structures when the working
sets of the two peers have small resemblance. However, our overlay
approach can be useful even when the resemblance is large, and
less than 1% of the symbols at peer B might be useful to peer A
(this difference may still be hundreds of symbols). For this case we
suggest a potentially faster approach, using a new data structure we
have developed called approximate reconciliation trees.
Our approximate reconciliation trees use Bloom ﬁlters on top of a
tree structure that is similar in spirit to Merkle trees, which are used
in cryptographic settings to minimize the amount of data transmit-
ted for veriﬁcation [20]. We limit ourselves here to an introductory
description focused on our applications here; other useful proper-
ties and applications will be detailed in a subsequent paper.
Our tree structure is most easily understood by considering the fol-
lowing construction. Peer A (implicitly) constructs a binary tree of
depth log u. The root corresponds to the whole working set SA.
The children correspond to the subsets of SA in each half of U;
that is, the left child is SA ∩ [0, u/2 − 1] and the right child is
SA ∩ [u/2, u − 1]. The rest of the tree is similar; the jth child at
depth k corresponds to the set SA ∩ [(j − 1) · u/2k, j · u/2k − 1].
Similarly, peer B constructs a similar tree for elements in SB. Now
suppose nodes in the tree can be compared in constant time, and
peer A sends its tree to peer B. If the root of peer A matches the
root of peer B, then there are no differences between the sets. Oth-
erwise, there is a discrepancy. Peer B then recursively considers the
children of the root. If x ∈ SB − SA, eventually peer B determines
7
53that the leaf corresponding to x in its tree is not in the tree for peer
A. Hence peer B can ﬁnd any x ∈ SB − SA. The total work for
peer B to ﬁnd all of SB − SA is O(d log u), since each discrepancy
may cause peer B to trace a path of depth log u.
The above tree has Θ(u) nodes and depth Θ(log u), which is un-
suitable when the universe is large. However, almost all the nodes in
the tree correspond to the same sets. In fact there are only O(|SA|)
non-trivial nodes. The tree can be collapsed by removing edges be-
tween nodes that correspond to the same set, leaving only Θ(|SA|)
nodes. Unfortunately, the worst-case depth may still be Ω(|SA|). To
solve this problem we hash each element initially before inserting
it into the virtual tree, as shown in Figure 3(a,b). The range of the
hash function should be at least poly(|SA|) to avoid collisions. We
assume that this hash function appears random, so that for any set
of values, the resulting hash values appear random. In this case, the
depth of the collapsed tree can easily be shown to be Θ(log |SA|)
with high probability. This collapsed tree is what is actually main-
tained by peers A and B.
As seen in Figure 3(b), each node can represent a set of Θ(n) el-
ements, which would make comparing nodes in constant time dif-
ﬁcult. We solve this problem again with hashing, so that each set
of elements corresponds to a value. The hash associated with each
internal node of the tree is the XOR of the values of its children,
as shown in Figure 3(d). Unfortunately, the high order bits of the
ﬁrst hash values of adjacent leaves in the tree are highly correlated,
since this ﬁrst hash determines placement in the tree. Therefore, we
hash each leaf element again into a universe U(cid:6)
= [1, h) to avoid
this correlation. It is these second hash values that are used when
computing the XOR of hashes in a bottom-up fashion up the tree.
Checking if two nodes are equal can be done in constant time by
checking the associated values, with a small chance of a false pos-
itive due to the hashing. As with Bloom ﬁlters, false positives may
cause peer B to miss some nodes in the set difference SB − SA.
The advantage of the tree over a Bloom ﬁlter is that it allows for
faster search of elements in the difference, when the difference is
small; the time is O(d log |SB|) using the tree instead of O(|SB|)
for the Bloom ﬁlter. To avoid some space overhead in sending an
explicit representation of the tree, we instead summarize the hashes
of the tree in a Bloom ﬁlter. For peer B to see if a node is matched
by an appropriate node from peer A, peer B can simply check the
Bloom ﬁlter for the corresponding hash. This use of a Bloom ﬁlter
introduces false positives but allows a small constant number of bits
per element to be used while maintaining reasonable accuracy.
A false positive from the Bloom ﬁlter prematurely cuts off the
search for elements in the difference SB − SA along a path in
the tree. If the false positive rate is high, the searching algorithm
may never follow a path completely to the leaf. We can amelio-
rate this weakness by not terminating a search at the ﬁrst match
between nodes. Instead, we add a correction level c correspond-
ing to the number of consecutive matches allowed without pruning
the search, i.e. setting c = 0 terminates the search at the ﬁrst match
found, while setting c = 1 terminates the search only when matches
are identiﬁed both at an internal node and a child of that node, and
so on. If the correction level is greater than d, then any node in the
bottom d levels of the tree is at greater risk of leading to a false pos-
itive. To cope with this problem, we use separate Bloom ﬁlters for
internal hashes and leaf hashes, giving ﬁner control over the overall
false positive probability.
Figure 4 shows the results of experiments using approximate rec-
onciliation trees. These experiments used sets of 10, 000 elements
with 100 differences. For larger sets, keeping the bits per element
constant will cause the error rate to increase slowly due to the tree
traversals - we note that only Ω(log log ") bits per element are
needed to avoid this for " elements. Figure 4(a) demonstrates both
the tradeoff involved when changing the number of bits used for the
internal nodes and leaves while keeping the total constant and the
beneﬁts of using more levels of correction. The ﬁgure shows that
using more correction levels and protecting the leaf hashes with a
large number of bits per element signiﬁcantly improves the frac-
tion of differences found. For example, at c = 5, internal nodes
are well protected against false positives, so the best performance
is achieved when nearly 6 of the 8 available bits per element are
allocated to the leaf ﬁlters.
Table 4(b) shows the accuracy for various numbers of bits per ele-
ment and levels of correction using the optimal distribution of bits
between the ﬁlters for leaves and interior nodes. The accuracy is
roughly 62% when using 4 bits per element and over 90% with 8
bits per element.
Finally, the main tradeoffs between optimized Bloom ﬁlters and ap-
proximate reconciliation trees are presented in Figure 4(c). With 8
bits per element, both data structures have over 90% accuracy, but
the search time on the Bloom ﬁlter scales linearly with the size of
the set, not the set difference.
5.4 Recoded Content
The ﬁnal technique we describe is recoding, a technique which can
be applied only when encoded content is employed (sketches and
approximate reconciliation methods can be employed whether or
not erasure correcting codes are used). Recoding is best applied
when collaborating peers are known to have correlated working sets
but do not yet know what elements are shared, i.e. in conjunction
with coarse-grained reconciliation. One obvious possibility is for
peers to send random encoding symbols, but this leads to a large
amount of useless data being transmitted in many circumstances.
For example, if the containment of B in A is 0.8, then sending a
random symbol will be useless 80% of the time. On the other hand,
as we explain more clearly below, sending a combination (using
XOR) of 9 distinct output symbols is useless with probability only
0.89 ≈ 14%. To describe recoding, we begin by providing rele-
vant details for erasure correcting codes in Section 5.4.1. We then
introduce recoding functionality in Section 5.4.2.
5.4.1
Sparse Parity Check Codes
To describe the recoding techniques we employ, we must ﬁrst pro-
vide some additional details and terminology of sparse parity-check
codes now advocated for error-correction and erasure resilience,
and used in constructions which approximate an idealized digital
fountain. Detailed performance evaluation of these codes in net-
working applications is detailed in [8]. A piece of content is di-
vided into a collection of " ﬁxed-length blocks x1, . . . , x(cid:12), each of
size suitable for packetization. For convenience, we refer to these
as input symbols. An encoder produces a potentially unbounded
sequence of output symbols, or encoding packets, y1, y2, . . . from
the set of input symbols. With parity-check codes, each symbol is
8
541
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
d
n
u
o
f
s
e
c
n
e
r
e
f
f
i
d
f
o
n
o
i
t
c
a
r
f
0
0
correction = 5
correction = 4
correction = 3
correction = 2
correction = 1
correction = 0
1
2
3
4
5
6
7
8
bits per element in leaf bloom filters
(a) Accuracy tradeoffs at 8 bits per element
Correction
Bits per Element
2
0.0000
0.0063
0.0530
0.1323
0.2029
0.2677
4
0.0087
0.1615
0.3492
0.4800
0.5538
0.6165
6
0.0997
0.3950
0.6243
0.7424
0.7966
0.8239
8
0.2540
0.6246
0.8109
0.8679
0.9061
0.9234
0
1
2
3
4
5
(b) Accuracy of approximate reconciliation trees
Size in bits Accuracy
Data Structure
Bloom ﬁlters
A.R.T. (c = 5)
8|SA|
8|SA|
98%
92%
Speed