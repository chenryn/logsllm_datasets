become unavailable in the enhanced settings. Meanwhile, the En-
terprise classifier achieves a similar performance as that under the
regular setting (AUC 0.982). For example, when the FPR = 0.6%, the
TPR = 85.8%), as it does not rely on subjects. Even though some of
the sender profiling features could not be built due to the unavail-
ability of delivery path information in the enhanced setting, they
are complemented well by other robust enterprise features. For the
All classifier, it is particularly interesting to see that, even though
the effectiveness of header features is significantly reduced in the
enhanced setting, the prediction accuracy of the combined features
is still close to that under the regular setting (AUC = 0.984), due to
the stable performance of enterprise features. For example, with
FPR = 0.6%, the TPR = 95.2%.
We further zoom-in to a particular setting where the discrimi-
nate threshold is 0.5, and report the prediction performance of all
classifiers under this setting in Table 7. Among the three classifiers,
the All classifier always achieves the best prediction accuracy.
Setting
Classifier
Regular
Enhanced
Enterprise
Header (baseline)
All
Enterprise
Header (baseline)
All
TPR
0.957
0.888
0.952
0.954
0.893
0.953
FPR
0.008
0.035
0.003
0.010
0.100
0.005
AUC
0.974
0.926
0.974
0.972
0.896
0.974
Table 7: Prediction performance of different classifiers (dis-
criminate threshold = 0.5)
With only header and enterprise features but not contents, the
accuracy of CADUE is a bit lower than that of the existing tech-
niques that utilize content features, which reflects the inherent
challenge that E2EE imposes on unwanted email detection. In prac-
tice, CADUE can be tuned for appropriate tradeoff between true
positives and false positives, depending on the use case. For exam-
ple, under the regular setting, with a false positive rate of 0.02%,
CADUE could still achieve close to 87.3% true positive rate. Even
under the more restrictive enhanced setting, with the same low
false positive rate, 78.4% true positive rate could be achieved.
6.5 Concept Drift
Class
Benign
Unwanted
Training (1-14)
Ep. 17-19
Ep. 20-22
Ep. 23-25
7499
298
2217
211
2182
171
1123
169
Table 8: Training and epoch test sets
Concept drift refers to the phenomenon that the data tends to
change over time in unpredictable manner. As a result, predictions
of the models trained in the past may become less accurate as time
passes. Similar to many cybersecurity problems, due to concept
drift, CADUE is likely to experience performance dropping when
the trained model becomes older. To evaluate the concept drift, as
shown in Figure 8, we re-split our 25-day ground truth data into a
training dataset and 3-day epoch testing sets. The training dataset
includes the first 14 days (day one through day 14), the first testing
epoch includes days 17-19, the second testing epoch includes days
20-22, and the third testing epoch includes days 23-25. Figure 7 (c)
shows the performance of the All classifier (in the regular setting)
using the three testing epochs, with each data point averaged over
100 runs. As expected, the figure shows that the performance degen-
erates as we move further from the training window. However, the
degeneration in performance is marginal as shown by the figure and
the particular settings depicted in Table 9 (when the discriminate
threshold is 0.5). This indicates that CADUE continues to perform
well even after 10 days from its training time. Unfortunately, as we
only have access to the email logs for a 25-day period, we could not
conduct thorough experiments to study this problem over longer
time windows and hence determine the appropriate rate for re-
training to deal with more significant concept drifting, including
major changes to organizational structures. The All classifier under
the enhanced setting has a similar trend to that under the regular
setting, the detail of which is thus omitted due to space limit.
Epoch
17-19
20-22
23-25
Setting
Regular
Enhanced
Regular
Enhanced
Regular
Enhanced
TPR
0.987
0.977
0.965
0.964
0.913
0.919
FPR
0.003
0.003
0.005
0.004
0.006
0.007
AUC
0.992
0.987
0.980
0.980
0.953
0.956
Table 9: Prediction performance of different epoch test sets
with all features (discriminate threshold = 0.5)
215RAID ’21, October 6–8, 2021, San Sebastian, Spain
Mohamed Nabeel, Enes Altinisik, Haipei Sun, Issa Khalil, Hui (Wendy) Wang, and Ting Yu
6.6 Emails from “Fresh” Senders
Existing profiling based approaches could not handle emails from
senders never seen before, as these senders’ profile features do not
exist (e.g., [18]). In ours, if the email from the new sender is sent to
multiple internal users in the enterprise, we could still rely on the
enterprise graph features to detect it as unwanted or not. Even if a
spammer may change his email address frequently, through enter-
prise graph features, we could still observe the unusual recipient
features and effectively detect unwanted emails. On the other hand,
if fresh emails are sent to a usual group of recipients, they are more
likely to be marked as benign. When the new sender’s email is only
sent to a single recipient, while the enterprise graph features are
not applicable, our approach can still detect unwanted emails using
Header features. We breakdown the classification results consider-
ing only fresh emails. Our model achieves a high accuracy of 97.84%
with a FPR of 2.0% for fresh emails.
6.7 Comparison with Gascon et al.
As mentioned before, the approach proposed by Gascon et al. [18]
targets at spearphishing emails which pretends to be sent by previ-
ous known senders. In practice, spearphishing emails are rare and
only account for a very smaller portion of unwanted emails. In fact,
none of the senders of the unwanted emails in our dataset have
ever sent benign emails before. Hence, Gascon et al. ’s approach
will not detect any of the unwanted emails in our dataset.
We evaluate the FPs of Gascon et al. ’s approach over our benign
dataset. Following the procedure stated in [18], we build a new
benign email dataset that comprises the emails of each sender who
has more than 5 emails (10510 emails from 495 senders). For each
sender, we use the first 5 emails to build its profile, and use the
remaining emails for testing. We follow the implementation of [18],
after excluding those features that would not be available under
E2EE (e.g., "text-quoted" and "quoted-printable", which rely
on email contents). If an email in the testing set is correctly mapped
to its sender profile, we count it as a TN; otherwise, we count it
as a FP. For the experiment, we got a TNR of 87.1% and a FPR of
12.9%. These results support our earlier observation that Gascon et
al. ’s approach is not a complete content-agnostic approach, and its
performance could be greatly affected when the content-dependent
features are unavailable.
7 DISCUSSION AND LIMITATIONS
Feature Robustness. Recall that our approach uses header fea-
tures, sender profiling features, and enterprise graph features. All
the header features are under the control of the email sender, and
hence can be manipulated by adversaries to evade filtering [11].
Furthermore, header features from the subject group (Table 10)
may not be available if the subject is encrypted. On the other hand,
without prior infiltration (as stated in our attack model), the sender
profiling features and the enterprise features are out of control
of the adversary, and hence cannot be easily manipulated. As the
experiments show above, our approach performs well when trained
with only sender profiling features and enterprise graph features,
and hence is robust against adversarial manipulation of subject
features. Furthermore, most existing email filtering solutions rely
on email contents and header information, both of which are under
the control of the adversaries, and hence could be carefully crafted
to evade filtering. Our approach not only has the capability to filter
emails without having access to content or header information but,
more importantly, is more robust against adversarial manipulation.
Meanwhile, attackers who have compromised the enterprise
email server or learned about enterprise users relationships through
external sources such as social media networks may mimic some
of the enterprise features in order to evade detection. We leave
the problem of detecting unwanted emails with attackers having
partial knowledge on the enterprise graphs as a future direction.
Updates of enterprise graph. Due to the dynamics of emails,
the structure of the enterprise graph may change over time. Such
change arises the need for model retraining, which is in fact quite
efficient to perform using our automated pipeline compared to
deep learning models. One may further improve the performance
by incrementally updating the enterprise graphs instead of building
from scratch each time. In order to gain the optimal classifier perfor-
mance without incurring heavy computational cost, we recommend
retraining the classifier regularly with a moving window of training
data. We leave the problem of identifying the optimal window for
training as future work since it requires a larger dataset.
Fresh Senders. We show in Section 6.6, our approach can de-
tect unwanted emails from fresh senders at a relatively high perfor-
mance metrics as our enterprise features help distinguish those send
emails to more than one recipient by using the features derived
from the co-recipient relationship. However, if the fresh sender
emails are either sent to only one recipient or well crafted to avoid
header features, our model may not be able to detect those un-
wanted emails with high performance. In a real-world deployment,
we recommend to exercise a more conservative decision making
(e.g. mark suspicious) for fresh emails under the E2EE setting. As
additional emails are received from the same sender, one may obtain
more confident decisions from our detection model.
8 CONCLUSION
In this paper, we investigate techniques for enterprise to detect
and filter unwanted incoming emails when email contents are not
accessible due to the adoption of end-to-end email encryption. Be-
sides email header features, we propose a set of novel enterprise
features, including sender profiling features and enterprise graph
features, based on the observation that historical email communi-
cation patterns in an enterprise contain rich and distinguishing
information that could help tell unwanted emails from legitimate
ones. We then design a content-agnostic classifier that combines
enterprise features with traditional header features. Through ex-
tensive experiments over a real email dataset collected from a large
local enterprise, we show that our classifier achieves high detection
accuracy without utilizing any email content information.
Recently the research community pays increasing attention to
analyzing encrypted network traffic for a variety of purposes, in-
cluding classifying web access under anonymous communication,
and identifying network/mobile applications under https. In the
context of enterprise email filtering, built on top of our current tech-
niques, it would be interesting future work to investigate whether
certain features could be extracted from encrypted email contents
to further improve the accuracy of email filtering. The challenge is
that existing research on analyzing encrypted traffic mostly targets
applications/protocols with clear traffic patterns, even when they
are encrypted. Email contents, on the other hand, are unstructured.
216CADUE: Content-Agnostic Detection of Unwanted Emails for Enterprise Security
RAID ’21, October 6–8, 2021, San Sebastian, Spain
REFERENCES
[1] [n.d.]. SpamHaus IP Blocklist. http://www.spamhaus.org.
[2] 2003. SpamAssassin. https://spamassassin.apache.org/.
[3] 2003. SpamAssassin Tests Performed. https://bit.ly/3gz1nm5.
[4] 2017. https://techconnecto.com/end-to-end-encryption-gmail/.
[5] 2017. https://blog.mailfence.com/end-to-end-email-encryption/.
[6] 2017. E2EE Emails. https://bit.ly/3qKvz2s.
[7] 2020. https://gdpr.eu/email-encryption/.
[8] 2020. OpenPGP. https://www.openpgp.org/.
[9] 2021. DMARC Adoption Rate. https://www.dmarc360.com/.
[10] A. Almomani, T. Wan, A. Altaher, A. Manasrah, E. ALmomani, M. Anbar, E.
ALomari, and S. Ramadass. 2012. Evolving fuzzy neural network for phishing
emails detection. JSC 8, 7 (2012), 1099.
[11] B. Barnes. 2002. E-Mail Impersonators. https://bit.ly/3gw9sIq.
[12] Leo Breiman. 2001. Random forests. Machine learning 45, 1 (2001), 5–32.
[13] N. Cao, C. Wang, M. Li, K. Ren, and W. Lou. 2014. Privacy-Preserving Multi-
Keyword Ranked Search over Encrypted Cloud Data. IEEE TPDS 25, 1 (2014),
222–233.
[14] T. Hansen D. Crocker and M. Kucheraw. 2020. DomainKeys Identified Mail
(DKIM) Signatures. https://tools.ietf.org/html/rfc6376.
[15] Nicolas Desmoulins, Pierre-Alain Fouque, Cristina Onete, and Olivier Sanders.
2018. Pattern Matching on Encrypted Streams. In Advances in Cryptology – ASI-
ACRYPT 2018, Thomas Peyrin and Steven Galbraith (Eds.). Springer International
Publishing, Cham, 121–148.
[16] Sevtap Duman, Kubra Kalkan-Cakmakci, Manuel Egele, William K. Robertson,
and Engin Kirda. 2016. EmailProfiler: Spearphishing Filtering with Header and
Stylometric Features of Emails. In 40th IEEE Annual Computer Software and
Applications Conference, COMPSAC 2016, Atlanta, GA, USA, June 10-14, 2016.
408–416.
[17] Simon Garfinkel. 1995. Pretty Good Privacy.
[18] H. Gascon, S. Ullrich, B. Stritter, and K. Rieck. 2018. Reading Between the Lines:
Content-Agnostic Detection of Spear-Phishing Emails. In Research in Attacks,
Intrusions, and Defenses. Cham, 69–91.
[19] P. Golle, J. Staddon, and B. Waters. 2004. Secure Conjunctive Keyword Search
over Encrypted Data. In Applied Cryptography and Network Security. Berlin,
Heidelberg, 31–45.
[20] Shuang Hao, Nadeem Ahmed Syed, Nick Feamster, Alexander G. Gray, and Sven
Krasser. 2009. Detecting Spammers with SNARE: Spatio-Temporal Network-Level
Automatic Reputation Engine. In Proceedings of the 18th Conference on USENIX
Security Symposium (Montreal, Canada) (SSYM’09). USENIX Association, USA,
101–118.
[21] T. Hastie, R. Tibshirani, and J. Friedman. 2009. The elements of statistical learning:
data mining, inference, and prediction. Springer Science & Business Media. 367–
368 pages.
[22] Grant Ho, Asaf Cidon, Lior Gavish, Marco Schweighauser, Vern Paxson, Stefan
Savage, Geoffrey M. Voelker, and David Wagner. 2019. Detecting and Char-
acterizing Lateral Phishing at Scale. In Proceedings of the 28th USENIX Con-
ference on Security Symposium (Santa Clara, CA, USA) (SEC’19). 1273–1290.
http://dl.acm.org/citation.cfm?id=3361338.3361427
[23] G. Ho, A. Sharma, M. Javed, V. Paxson, and D. Wagner. 2017. Detecting Credential
Spearphishing Attacks in Enterprise Settings. In USENIX (Vancouver, BC, Canada).
469–485.
[24] S. A. Khamis, C. F. M. Foozy, M. F. Ab Aziz, and N Rahim. 2020. Header Based Email
Spam Detection Framework Using Support Vector Machine (SVM) Technique. In
ICSCDM. Springer, 57–65.