in September 2014, three of the exploit kits used the exact
same code to check for certain system ﬁles belonging to
AV solutions. If such solutions are discovered, the exploit
2Note that for some of the kits, while a Java exploit was present,
no version checking was conducted by the kit, thus determining the
speciﬁc CVE is diﬃcult if not impossible.
3http://blog.spiderlabs.com/
4http://malware.dontneedcoffee.com/
kits eﬀectively stop the attack to avoid detection. Figure 5
shows how one of these kits, Nuclear, experienced near-
constant updates during the time period of our study,
making it a good subject for studying malware evolution.
While other kits exist, relatively few are prominent and in
active development at a given time, and we consider these
representative of the broader population.
A. Exploit Kit Structure
Exploit kits are comprised of several components or-
ganized into layers (Figure 3), that typically include an
unpacker, a plugin and AV detector, an eval/execution
trigger, and, at least one malicious payload.
Fig. 3: Structure and components of a typical EK.
An exploit kit usually incorporates a range of CVEs that
it attempts to exploit, which target a variety of operating
systems, plugins and browsers. In the following, we discuss
these components, showing how they evolve over time.
Unpackers: The outer-most layer of this onion is typically
used to ensure that a security analyst or a web site admin-
istrator cannot eﬀortlessly determine the inner workings
of the exploit kit. This can either be achieved by packing
the underlying pieces or by at least applying obfuscation
techniques such as string encoding.
Figure 4 shows samples of packers from the RIG and
Nuclear explot kits, highlighting the diﬀerences between
families. While Nuclear relies on an encryption key that
is used when unpacking the malicious payload, RIG uses a
buﬀer which is dynamically ﬁlled during runtime with the
ASCII codes for the payload, intermixed with a delimiter.
We found that this delimiter is randomized between diﬀer-
ent versions of the kit. In contrast, the encryption key —
and therefore the encrypted payload — for the Nuclear
exploit kit diﬀers in every response, highlighting the fact
that it is diﬃcult to pattern-match on obfuscated code.
Malicious payload: The actual payload typically targets
a set of known vulnerabilities in the browser or plugins. As
can be seen from the Exploit Pack Table5, 5–7 CVEs per
kit is fairly typical. The payload is often interleaved with
plugin detection code, e.g., an HTML element is added to
the DOM pointing to a malicious ﬂash ﬁle if a vulnerable
version was detected previously.
Eval trigger: After the malware is fully unfolded, there
is usually a short trigger that starts the EK execution
process. Examples of these triggers are shown on line 19
of Figure 4(a) and lines 23–25 of Figure 4(b).
5http://contagiodump.blogspot.com/2010/06/
overview-of-exploit-packs-update.html
unpackereval triggerplugin detectorpayload1 var buffer = " " ;
2 var delim = " y6 " ;
3
4 f u n c t i o n collect ( text ) {
5
6 }
7
8 collect ( " 47 y 6 4 2 y 6 1 0 0 y 6 " ) ;
9 collect ( " 102 y 6 1 0 3 y 6 1 0 4 .. " ) ;
buffer += text ;
10
11 pieces = buffer . split ( delim ) ;
12
13 screlem = d o c u m e n t . c r e a t e E l e m e n t ( " script " ) ;
14
15 for ( var i =0; i [3 E / sP :O < D7 * yz | m + Z ; JBf )
hX9Gw L0CF % KN } ,& YaMHj =] W " ;
return a ;
10 ...
11
12 getter = f u n c t i o n ( a ) {
13
14 };
15
16 t h i s c o p y = this ;
17 doc = t h i s c o p y [ t h i s c o p y [ " getter " ]( " d o c u m e n t " ) ]
18 bgc = doc [ t h i s c o p y [ " getter " ]( " bgColor " ) ];
19
20 evl = t h i s c o p y [ " getter " ]( " ev #333366 al " )
21 win = t h i s c o p y [ " getter " ]( " win #333366 dow " )
22
23 t h i s c o p y
24
25
[ win [ " replace " ]( bgc , " " ) ]
[ evl [ " replace " ]( bgc , " " ) ]( payload ) ;
(b) Nuclear exploit kit
Fig. 4: Two typical code unpackers from exploit kits.
B. Evolution of an Exploit Kit
To understand how EK components evolve in the wild,
we captured samples of Nuclear over the course of three
months and tracked changes to the kit. We summarize
some of the mutation approaches below.
Changing the packer: Figure 5 illustrates speciﬁc
changes that were made to packer and payload in the kit
to avoid AV detection on a time line. Many of the changes
were very local, changing the way that the kit obscured
calls to eval. For example, between 6/1 and 6/14, the
attacker changed ev#FFFFFFal to e#FFFFFFFval. Over
the course of the three months, we see a total of 13 small
syntactic changes in this category. Only one of these packer
changes (on 8/12) changed the semantics of the packer.
Appending new exploits: We observed changes to the
other components of the kit, i.e., plug-in detection and
payload, occur much less frequently. On 7/29, AV detec-
tion was added to the plug-in detector, and on 8/27 a
new CVE was added. Nothing was removed from either
the plug-in detector or the payload over this period. This
supports our claim that EKs change their outer layer
frequently to avoid AV detection, but typically modify
their inner components by appending to them and even
then only infrequently.
Code borrowing: A noteworthy fact in this instance
is that in June, Nuclear exploit kit did not utilize
any code aiming at detecting AV software running on the
victim’s machine. We initially observed this behavior in
the RIG exploit kit starting in May. The exact code we
had observed for RIG was used in Nuclear from August,
apparently having been copied from the rivaling kit.
While we use Nuclear exploit kit as a speciﬁc ex-
ample here, we observed similar changes in all the exploit
kits we studied. In summary, we observe that kits typically
change in three ways, namely changing the unpacker
(frequent), appending new exploits (infrequent), and
borrowing code from other kits (infrequent).
C. Adversarial Cycle
Exploit kit authors are in a constant arms race with
anti-virus companies as well as rivaling kits’ authors.
While on the one hand, the kits try to avoid detection
by anti-virus engines, their revenue stream is dependent
on the amount of machines they can infect. Therefore,
kit authors always try to include multiple exploits, and
if one kit includes a new exploit, we observed that these
exploits are quickly incorporated into other kits as well.
As we have seen in the example of the Nuclear exploit
kit above, kit authors attempt to avoid detection by anti-
virus engines by modifying the code, whereas in turn
AV analysts try to create new signatures matching the
modiﬁed variants. This process can be abstracted to the
adversarial cycle shown in Figure 1.
Initially, an exploit kit is not detected by AV, which
presents a very challenging problem for an analyst. First
they have to ﬁnd examples of the undetected variant and
then need to create a new signature which matches this
undetected variant, trading oﬀ precision and recall – i.e.,
the signature has to be able to catch all occurrences of
the exploit kit while not blocking benign components.
Naturally this takes time and eﬀort and despite this cost,
AV engines update their signatures frequently to keep pace
with the malware writers. After an analyst is satisﬁed they
have a precise and unique signature, they deploy it.
At this point, the attacker responds, determining that
his kit is now detected by deployed AV signatures. For
the attacker, this can be learned automatically, e.g., by
submitting a URL containing his kit to an AV scanner.
Once this step has occurred (left-hand side of the ﬁgure),
he takes measures to counter detection, such as slight mod-
iﬁcation to the part of the code that would be suspicious
(e.g., calls to eval), or, in more drastic cases we observed
in the wild, exchanging entire pieces, such as the unpacker.
Depending on the type of change, this task can be easily
accomplished within minutes — and more importantly, an
attacker can scan his code with an AV solution to deter-
mine if it now passes detection, giving him an advantage
over vendors, who need to ﬁnd ways to detect the new
variant of the kit. This shows the imbalance between the
Fig. 5: Evolution of the Nuclear exploit kit over a three-month period in 2014. In this timeline, packer changes are shown above the axis and payload
changes below the axis. The lion’s share of changes are superﬁcial changes to the packer.
of Kizzle include abstracting the samples into token se-
quences, clustering the samples, labeling the clusters, and
generating signatures for malicious clusters.
Main driver: The processing starts with a new collection
of samples, whereas a sample consists of a complete HTML
document, including all inline script elements. The main
routine breaks the new samples into a set of clusters,
labels each cluster either as benign or corresponding to
a known kit, and if the cluster is malicious, generates a
new signature for that cluster based on the samples in it.
We consider each of the parts of the task in turn in the
subsections below.
A. Clustering Samples
The process of clustering the input samples is com-
putationally expensive, and as a result, beneﬁts from
parallelization across a set of machines. The ﬁrst stage
in our process is to randomly partition the samples across
a cluster of machines.
For each partition, the samples are tokenized from the
concrete JavaScript source code represented as Unicode
to a sequence of abstract JavaScript tokens that include
Keyword, Identifier, Punctuation, and String. Fig-
ure 8 gives an example of tokenization in action.
We cluster the samples based on these token strings in
order to eliminate artiﬁcial noise created by an attacker in
the form of randomized variable names, etc. We apply a
hierarchical clustering algorithm, using the edit distance
between token strings as a means of determining the
distance between any two samples.
As an algorithm, we use the DBSCAN clustering algo-
rithm [11]. We experimentally determined that a threshold
of 0.10 is suﬃcient to generate a reasonably small number
of clusters, while not generating clusters that are too
generic, i.e., contain samples that do not belong to the
same family of malware (or snippets of benign code). In the
reduction phase, the clusters determined by each partition
are combined in a ﬁnal step.
Next, we consider each distinct cluster, selecting a single
prototype sample from the cluster, unpacking it (if it is
packed) and then attempting to label it. This unpacking
step can be conducted by hooking into the eval loop of
the JavaScript engine [7]. For our work, which focuses on
Fig. 6: Window of vulnerability for Angler in August, 2014 for a com-
mercial AV engine. The window starts around August 13th and continues
to roughly August 19th.
involved parties, i.e., the eﬀort and reaction time of the
kit author is much lower than that of the AV vendors.
Example 1 Angler in August Figure 6 shows false
negatives for the Angler exploit kit in the month of
August 2014 for a widely used commercial AV engine6.
By observing the changes to the kit over this time, we
understand what happened. Before August, 13th, the
exploit kit contained an HTML snippet that included a
Java exploit with a speciﬁc unique string on which the
AV signature matched. On August, 13th, the string on
which the signature matched was incorporated into the
obfuscated body of kit and only written to the document
if a vulnerable version of Java was installed on the system.
This change resulted in a window of time when variants
of the kits were undetected. 
III. Techniques
In this section, we describe the implementation of Kiz-
zle, which is illustrated at a high level in Figure 7. For
a more detailed discussion on the algorithms, we refer
the reader to our accompanying technical report [38]. The
input to Kizzle is a set of new samples and a set of existing
unpacked malware samples which correspond to exploit
kits Kizzle is aiming to detect. The algorithmic elements
6We anonymize the exact engine for two reasons: ﬁrst, we believe
that all engines exhibit the same behavior despite constant eﬀorts
by the analysts to keep them current, and second because EULA
agreements typically prevent disclosing such comparisons.
6/1/20148/31/20146/8/20146/15/20146/22/20146/29/20147/6/20147/13/20147/20/20147/27/20148/3/20148/10/20148/17/20148/24/20148/19/2014eher_vam#6/18/2014eva#FFFFFFl7/20/2014e3fwrwg4#7/11/2014e~##...~#v~#a~#l7/17/2014e3X@@#v..8/12/2014Semantic change6/24/2014"ev" + var8/27/2014CVE 2013-0074 (SL)6/1/2014ev#FFFFFFal8/22/2014efber443#8/17/2014esa1asv6/14/2014e#FFFFFFval7/29/2014AV detection6/30/2014e~v~#...~a~l8/26/2014eUluN#7/9/2014e~#...~v~a~lPacker changesPayload changessignature released0%10%20%30%40%50%60%1-Aug3-Aug5-Aug7-Aug9-Aug11-Aug13-Aug15-Aug17-Aug19-Aug21-Aug23-Aug25-Aug27-Aug29-Aug31-AugAV FN %Kizzle FN %Fig. 7: Architecture of Kizzle.
Token