if |exact| > 0 and SAMEIDS(exact) then
else if |candidates| > 0 and SAMEIDS(candidates) then
else
return candidates[0].id
return GENERATENEWID()
end if
end function
SAMEIDS is a function that, given a list of candidates, returns true
if all of them share the same id, else false.
The order in which rules are applied is important for
performance purposes: we ordered them from the most to
least discriminating. The ﬁrst rules discard many candidates,
reducing the total number of comparisons. In order to link
fu to a ﬁngerprint fk, we apply the rules to each known
ﬁngerprint taken from F . As soon as a rule is not matched,
the known ﬁngerprint is discarded and we move onto the next.
If a ﬁngerprint matches all the rules, then it is added to a
list of potential candidates, candidates. Moreover, in case
ﬁngerprints fk and fu are identical, we add it to the list of
exact matching candidates, exact. Once the rule veriﬁcation
process is completed, we look at the two lists of candidates. If
exact is not empty, we check if there is only one candidate or if
all the candidates come from the same browser instance. If it is
the case, then we link fu with this browser instance, otherwise
we assign a new id to fu. In case no exact candidate is found,
we look at candidates and apply the same technique as for
exact. We summarize the rule-based approach in Algorithm 1.
On a side-note, we established the rules using a simple
univariate statistical analysis to study attribute stability (see
Table II), as well as some objective (e.g., rule 1) and other sub-
jective (e.g., rule 4) decisions. Due to the difﬁculty in making
complex yet effective rules, the next subsection presents the
use of machine learning to craft a more effective algorithm.
C. Hybrid Linking Algorithm
The second variant of FP-STALKER mixes the rule-based
algorithm with machine learning to produce a hybrid algo-
rithm. It reuses the ﬁrst three rules of the previous algorithm,
since we consider them as constraints that should not be
violated between two ﬁngerprints of a same browser instance.
However, for the last four rules, the situation is more fuzzy.
Indeed,
is not as clear when to allow attributes to be
different, how many of them can be different, and with what
dissimilarity. Instead of manually crafting rules for each of
these attributes, we propose to use machine learning to dis-
cover them. The interest of combining both rules and machine
it
learning approaches is that rules are faster than machine
learning, but machine learning tends to be more precise. Thus,
by applying the rules ﬁrst, it helps keep only a subset of
ﬁngerprints on which to apply the machine learning algorithm.
1) Approach Description: The ﬁrst step of this algorithm
is to apply rules 1, 2 and 3 on fu and all fk ∈ F . We keep
the subset of browser ﬁngerprints fksub that verify these rules.
If, during this process, we found any browser ﬁngerprints that
exactly match fu, then we add them to exact. In case exact is
not empty and all of its candidates are from the same browser
instance, we stop here and link fu with the browser instance
in exact. Otherwise, if there are multiple exact candidates but
from different browser instances, then we assign a new browser
id to fu. In the case where the set of exact candidates is
empty, we continue with a second step that leverages machine
learning. In this step, for each ﬁngerprint fk ∈ fksub, we
compute the probability that fk and fu come from the same
browser instance using a random forest model. We keep a set
of ﬁngerprint candidates whose probability is greater than a
λ threshold parameter. If the set of candidates is empty, we
assign a new id to fu. Otherwise, we keep the set of candidates
with the highest and second highest probabilities, ch1 and ch2.
Then, we check if ch1 contains only one candidate or if all
of the candidates come from the same browser instance. If
it is not the case, we check that either the probability ph1
associated with candidates of ch1 is greater than the probability
ph2 associated with candidates of ch2 + dif f, or that ch2 and
ch1 contains only candidates from the same browser instance.
Algorithm 2 summarizes the hybrid approach.
2) Machine Learning: Computing the probability that two
ﬁngerprints fu and fk originate from the same browser in-
stance can be modeled as a binary classiﬁcation problem where
the two classes to predict are same browser instance
and different browser instance. We use the ran-
dom forest algorithm [6] to solve this binary classiﬁcation
problem. A random forest is an ensemble learning method
for classiﬁcation that operates by constructing a multitude
of decision trees at training time and outputting the class
of the individual trees. In the case of FP-STALKER, each
decision tree makes a prediction and votes if the two browser
ﬁngerprints come from the same browser instance. The result
of the majority vote is chosen. Our main motivation to adopt a
random forest instead of other classiﬁers is because it provides
a good tradeoff between precision and the interpretation of
the model. In particular, the notion of feature importance in
random forests allows FP-STALKER to interpret the importance
of each attribute in the decision process.
In summary, given two ﬁngerprints, fu /∈ F and fk ∈ F ,
whose representation is reduced to a single feature vector of
M features X = (cid:3)x1, x2, ..., xM(cid:4), where the feature xn is
the comparison of the attribute n for both ﬁngerprints (the
process of transforming two ﬁngerprints into a feature vector
is presented after). Our random forest model computes the
probability P (fu.id = fk.id | (x1, x2, ..., xM )) that fu and fk
belong to the same browser instance.
a) Input Feature Vector: To solve the binary classiﬁca-
tion problem, we provide an input vector X = (cid:3)x1, x2, ..., xM(cid:4)
of M features to the random forest classiﬁer. The features
are mostly pairwise comparisons between the values of the
attributes of both ﬁngerprints (e.g., Canvas, User agent).
733
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:32:59 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 2 Hybrid matching algorithm
function FINGERPRINTMATCHING(F, fu, λ)
rules = {rule1, rule2, rule3}
exact ← ∅
Fksub ← ∅
for fk ∈ F do
if VERIFYRULES(fk, fu, rules) then
if nbDif f = 0 then
exact ← exact ∪ (cid:6)fk(cid:7)
Fksub ← Fksub ∪ (cid:6)fk(cid:7)
else
end if
end if
end for
if |exact| > 0 then
if SAMEIDS(exact) then
return exact[0].id
return GENERATENEWID()
else
end if
end if
candidates ← ∅
for fk ∈ Fksub do
(cid:6)x1, x2, ..., xM(cid:7) = FEATUREVECTOR(fu, fk)
p ← P (fu.id = fk.id | (cid:6)x1, x2, ..., xM(cid:7))
if p ≥ λ then
candidates ← candidates ∪ (cid:6)fk, p(cid:7)
end if
end for
if |candidates| > 0 then
ch1, ph1 ← GETCANDIDATESRANK(candidates, 1)
ch2, ph2 ← GETCANDIDATESRANK(candidates, 2)
if SAMEIDS(ch1) and ph1 > ph2 + dif f then
return candidates[0].id
end if
if SAMEIDS(ch1 ∪ ch2) then
return candidates[0].id
end if
end if
return GENERATENEWID()
end function
GETCANDIDATESRANK is a function that given a list of candidates
and an rank i, returns a list of candidates with the ith greatest
probability, and this probability.
Most of these features are binary values (0 or 1) corresponding
to the equality or inequality of an attribute, or similarity
ratios between these attributes. We also include a number
of changes feature that corresponds to the total number of
different attributes between fu and fk, as well as the time
difference between the two ﬁngerprints.
In order to choose which attributes constitute the feature
vector we made a feature selection. Indeed, having too many
features does not necessarily ensure better results. It may lead
to overﬁtting—i.e., our algorithm correctly ﬁts our training
data, but does not correctly predict on the test set. Moreover,
having too many features also has a negative impact on
performance. For the feature selection, we started with a model
using all of the attributes in a ﬁngerprint. Then, we looked at
feature importance, as deﬁned by [15], to determine the most
discriminating features. In our case, feature importance is a
combination of uniqueness, stability, and predictability (the
possibility to anticipate how an attribute might evolve over
time). We removed all the components of our feature vector
734
TABLE III: Feature importances of the random forest model
calculated from the ﬁngerprint train set.
Rank
Feature
1
2
3
4
5
6
7
8
9
Number of changes
Languages HTTP
User agent HTTP
Canvas
Time difference
Plugins
Fonts
Renderer
Resolution
Importance
0.350
0.270
0.180
0.090
0.083
0.010
0.008
0.004
0.003
that had a negligible impact (feature importance < 0.002).
Finally, we obtained a feature vector composed of the attributes
presented in Table III. We see that the most important feature
is the number of differences between two ﬁngerprints, and the
second most discriminating attribute is the list of languages.
Although this may seem surprising since the list of languages
does not have high entropy, it does remain stable over time,
as shown in Table II, which means that if two ﬁngerprints
have different languages, this often means that they do not
belong to the same browser instance. In comparison, screen
resolution also has low entropy but it changes more often than
the list of languages, leading to low feature importance. This is
mostly caused by the fact that since screen resolution changes
frequently, having two ﬁngerprints with a different resolution
doesn’t add a lot of information to determine whether or not
they are from the same browser instance. Finally, we see a
high drop in feature importance after rank 5 (from 0.083 to
0.010), which means that most of the information required for
the classiﬁcation is contained in the ﬁrst ﬁve features.
b) Training Random Forests: This phase trains the
random forest classiﬁer to estimate the probability that two
ﬁngerprints belong to the same browser instance. To do so, we
split the input dataset introduced in Section III chronologically
into two sets: a training set and a test set. The training set is
composed of the ﬁrst 40 % of ﬁngerprints in our input dataset,
and the test set of the last 60 %. The random forest detects
ﬁngerprint evolutions by computing the evolutions between
ﬁngerprints as feature vectors. During the training phase, it
needs to learn about correct evolutions by computing relevant
feature vectors from the training set. Algorithm 3 describes
this training phase, which is split into two steps.
Algorithm 3 Compute input feature vectors for training
function BUILDTRAININGVECTORS(ID,F ,δ,ν)
T ← ∅
for id ∈ ID do
Fid ← BROWSERFINGERPRINTS(id, F )
for ft ∈ Fid do
T ← T ∪ FEATUREVECTOR(ft, ft−1)
end for
end for
for f ∈ F do
fr ← RANDOM(F )
if f.id (cid:9)= fr.id then
end if
T ← T ∪ FEATUREVECTOR(f, fr)
(cid:5) Step 1
(cid:5) Step 2
end for
return T
end function
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:32:59 UTC from IEEE Xplore.  Restrictions apply. 
In Step 1,
instance (id) of
for every browser
the
training set, we compare each of its ﬁngerprints (ft ∈
BROWSERFINGERPRINTS(id, F )) present in the training set
(F ) with the previous one (ft−1). By doing so, FP-STALKER
captures the atomic evolutions that occur between two consec-
utive ﬁngerprints from the same browser instance. We apply
BUILDTRAININGVECTORS() for different collect frequencies
(time difference between t and t−1) to teach our model to link
ﬁngerprints even when they are not equally spaced in time.
While Step 1 teaches the random forest
to identify
ﬁngerprints that belong to the same browser instance, it is also
necessary to identify when they do not. Step 2 compares
ﬁngerprints from different browser instances. Since the num-
ber of ﬁngerprints from different browser instances is much
larger than the number of ﬁngerprints from the same browser
instance, we limit
the number of comparisons to one for
each ﬁngerprint. This technique is called undersampling [16]
and it reduces overﬁtting by adjusting the ratio of input data
labeled as true—i.e., 2 ﬁngerprints belong to the same browser
instance—against the number of data labeled as false—i.e., 2
ﬁngerprints are from different browser instances. Otherwise,
the algorithm would tend to simply predict false.
trees of the random forest,
c) Random forest hyperparameters.: Concerning the
there is a tradeoff
number of
between precision and execution time. Adding trees does
obtain better results but follows the law of diminishing returns
and increases training and prediction times. Our goal is to
balance precision and execution time. The number of features
plays a role during the tree induction process. At each split, Nf
features are randomly selected, among which the best split is
chosen [4]. Usually, its default value is set to the square root of
the length of the feature vector. The diff parameter enables the
classiﬁer to avoid selecting browser instances with very similar
probabilities as the origin of the ﬁngerprint; we would rather
create a new browser instance than choose the wrong one. It
is not directly related to random forest hyperparameters but
rather to the speciﬁcities of our approach. In order to optimize
the hyperparameters number of trees and number of features,
as well as the diff parameter, we deﬁne several possible values
for each and run a grid search to optimize the accuracy. This
results in setting the hyperparameters to 10 trees and 3 features,
and the diff value to 0.10.
After training our random forest classiﬁer, we obtain a
forest of decision trees that predict the probability that two
ﬁngerprints belong to the same browser instance. Figure 5 il-
lustrates the ﬁrst three levels of one of the decision trees. These
levels rely on the languages, the number of changes
and the user agent to take a decision. If an attribute has a
value below its threshold, the decision path goes to the left
child node, otherwise it goes to the right child node. The
process is repeated until we reach a leaf of the tree. The
prediction corresponds to the class (same/different browser
instance) that has the most instances over all the leaf nodes.
d) Lambda threshold parameter: For each browser
ﬁngerprint
in the test set, we compare it with its previ-
ous browser ﬁngerprint and with another random ﬁngerprint
from a different browser, and compute the probability that
it belongs to the same browser instance using our random
forest classiﬁer with the parameters determined previously.
Using these probabilities and the true labels, we choose the λ
languages HTTP <= 0.978
True
False
number of changes <= 4.5
number of changes <= 5.5