1
1
-
1
1
1
-
-
0
0
0
-
8
0
8
Table 4. Object creation statistics for the online shopping application
Acunetix Acunetix Use Case Guided Extended Stateful
Fuzzing Fuzzing Fuzzing
1
2
1
1
1
1
1
1
1
1
1
1
1
2
3
1
1
1
1
1
1
1
21
1
-
-
-
1
-
-
-
-
3
5
11
1
2
7
5
2
2
1
2
2
3
5
96
1
Object
Class
OrderItem
AddressBook
PhoneNumber
Contact
CreditCardDetail
OrderStatus
OrderPayment
Order
Cart
CartItem
Comment
User
#1
-
-
-
1
-
-
-
-
2
2
-
1
#2
-
-
-
-
-
-
-
-
1
1
-
-
application. As a result, both tools failed to reach and correctly ﬁll out the form
that allows to change the contact information of a user. This form contained
eight stored XSS vulnerabilities, since none of the entered input was checked
by the application for malicious values. However, the server checked the phone
number and email address for their validity and would reject the complete form
whenever one of the two values was incorrect.
In contrast to the existing tools, guided fuzzing was able to analyze a large
part of the application, including the login form and the user data form. Thus,
this approach reported a total of nine vulnerable entry points. In this experi-
ment, we can also observe the advantages of stateful fuzzing. With extended,
guided fuzzing, the fuzzing step interferes with the proper replay of the use case
(because the fuzzer logs itself out and deletes all items from the shopping cart).
The stateful fuzzer, on the other hand, allows to explore a broad range of entry
points, and, using the snapshot mechanism, keeps the ability to replay the test
Leveraging User Interactions for In-Depth Testing of Web Applications
207
case. The number of database objects created by the diﬀerent approaches (as
shown in Table 4) also conﬁrms the ability of our techniques to create a large
variety of diﬀerent, valid objects, a result of analyzing large portions of the
application.
Discussion. All vulnerabilities that we found in our experiments were previously
unknown, and we reported them to the developers of the web applications. Our
results show that our fuzzing techniques consistently ﬁnd more (or, at least,
the same amount) of bugs than other open-source and commercial scanners.
Moreover, it can be seen that the diﬀerent approaches carry out meaningful
interactions with the web applications, visiting many locations and creating a
large variety of database objects. Finally, the diﬀerent techniques exhibit diﬀer-
ent strengths. For example, stateful fuzzing becomes useful especially when the
tested application is more complex and sensitive to the fuzzing steps.
6 Related Work
Concepts such as vulnerability testing, test case generation, and fuzzing are
well-known concepts in software engineering and vulnerability analysis [3, 4, 11].
When analyzing web applications for vulnerabilities, black-box fuzzing tools [1,
5, 31] are most popular. However, as shown by our experiments, they suﬀer from
the problem of test coverage. Especially for applications that require complex
interactions or expect speciﬁc input values to proceed, black-box tools often fail
to ﬁll out forms properly. As a result, they can scan only a small portion of the
application. This is also true for SecuBat [16], a web vulnerability scanner that
we developed previously. SecuBat can detect reﬂected XSS and SQL injection
vulnerabilities. However, it cannot ﬁll out forms and, thus, was not included in
our experiments.
In addition to web-speciﬁc scanners, there exist a large body of more gen-
eral vulnerability detection and security assessment tools. Most of these tools
(e.g., Nikto [19], Nessus [29]) rely on a repository of known vulnerabilities that
are tested. Our tool, in contrast, aims to discover unknown vulnerabilities in
the application under analysis. Besides application-level vulnerability scanners,
there are also tools that work at the network level, e.g., nmap [14]. These tools
can determine the availability of hosts and accessible services. However, they are
not concerned with higher-level vulnerability analysis. Other well-known web
vulnerability detection and mitigation approaches in literature are Scott and
Sharp’s application-level ﬁrewall [25] and Huang et al.’s [13] vulnerability de-
tection tool that automatically executes SQL injection attacks. Moreover, there
are a large number of static source code analysis tools [15, 27, 32] that aim to
identify vulnerabilities.
A ﬁeld that is closely related to our work is automated test case generation.
The methods used to generate test cases can be generally summarized as random,
speciﬁcation-based [20, 22], and model-based [21] approaches. Fuzzing falls into
the category of random test case generation. By introducing use cases and guided
fuzzing, we improve the eﬀectiveness of random tests by providing some inputs
208
S. McAllister, E. Kirda, and C. Kruegel
that are likely valid and thus, allow the scanner to reach “deeper” into the
application.
A well-known application testing tool, called WinRunner, allows a human tester
to record user actions (e.g., input, mouse clicks, etc.) and then to replay these ac-
tions while testing. This could be seen similar to guided fuzzing, where inputs are
recorded based on observing real user interaction. However, the testing with Win-
Runner is not fully-automated. The developer needs to write scripts and create
check points to compare the expected and actual outcomes from the test runs.
By adding automated, random fuzzing to a guided execution approach, we com-
bine the advantages provided by a tool such as WinRunner with black-box fuzzers.
Moreover, we provide techniques to generalize from a recorded use case.
Finally, a number of approaches [6, 12, 18] were presented in the past that
aim to explore the alternative execution paths of an application to increase the
analysis and test coverage of dynamic techniques. The work we present in this
paper is analogous in the sense that the techniques aim to identify more code to
test. The diﬀerence is the way in which the diﬀerent approaches are realized, as
well as their corresponding properties. When exploring multiple execution paths,
the system has to track constraints over inputs, which are solved at branching
points to determine alternative paths. Our system, instead, leverages known,
valid input to directly reach a large part of an application. Then, a black-box
fuzzer is started to ﬁnd vulnerabilities. This provides better scalability, allowing
us to quickly examine large parts of the application and expose it to black-box
tests.
7 Conclusions
In this paper, we presented a web application testing tool to detect reﬂected
and stored cross-site scripting (XSS) vulnerabilities in web applications. The
core of our system is a black-box vulnerability scanner. Unfortunately, black-
box testing tools often fail to test a substantial fraction of a web application’s
logic, especially when this logic is invoked from pages that can only be reached
after ﬁlling out complex forms that aggressively check the correctness of the
provided values. To allow our scanner to reach “deeper” into the application,
we introduce a number of techniques to create more comprehensive test cases.
One technique, called guided fuzzing, leverages previously recorded user input
to ﬁll out forms with values that are likely valid. This technique can be further
extended by using each step in the replay process as a starting point for the fuzzer
to explore a program more comprehensively. When feedback from the application
is available, we can reuse the recorded user input for diﬀerent forms during this
process. Finally, we introduce stateful fuzzing as a way to mitigate potentially
undesirable side-eﬀects of the fuzzing step that could interfere with the replay
of use cases during extended, guided fuzzing. We have implemented our use-
case-driven testing techniques and analyzed three real-world web applications.
Our experimental results demonstrate that our approach is able to identify more
bugs than several open-source and commercial web vulnerability scanners.
Leveraging User Interactions for In-Depth Testing of Web Applications
209
Acknowledgments
This work has been supported by the Austrian Science Foundation (FWF) under
grant P-18764, the FIT-IT project SECoverer (Detection of Application Logic Er-
rors in Web Applications), and the Secure Business Austria Competence Center.
References
[1] Acunetix. Acunetix Web Vulnerability Scanner (2008),
http://www.acunetix.com/
[2] Balzarotti, D., Cova, M., Felmetsger, V., Jovanov, N., Kirda, E., Kruegel, C., Vi-
gna, G.: Saner: Composing Static and Dynamic Analysis to Validate Sanitization
in Web Applications. In: IEEE Security and Privacy Symposium (2008)
[3] Beizer, B.: Software System Testing and Quality Assurance. Van Nostrand Rein-
hold (1984)
[4] Beizer, B.: Software Testing Techniques. Van Nostrand Reinhold (1990)
[5] Spider, B.: Web Application Security (2008), http://portswigger.net/spider/
[6] Cadar, C., Ganesh, V., Pawlowski, P., Dill, D., Engler, D.: EXE: Automatically
Generating Inputs of Death. In: ACM Conference on Computer and Communica-
tion Security (2006)
[7] Hannson, D.: Ruby on Rails (2008), http://www.rubyonrails.org/
[8] Django. The Web Framework for Professionals with Deadlines
(2008),
http://www.djangoproject.com/
[9] Basic Django Blog Application,
http://code.google.com/p/django-basic-blog/
[10] Endler, D.: The Evolution of Cross Site Scripting Attacks. Technical report, iDE-
FENSE Labs (2002)
[11] Ghezzi, C., Jazayeri, M., Mandrioli, D.: Fundamentals of Software Engineering.
Prentice-Hall International, Englewood Cliﬀs (1994)
[12] Godefroid, P., Klarlund, N., Sen, K.: DART. In: Programming Language Design
and Implementation (PLDI) (2005)
[13] Huang, Y., Huang, S., Lin, T.: Web Application Security Assessment by Fault
Injection and Behavior Monitoring. In: 12th World Wide Web Conference (2003)
[14] Insecure.org. NMap Network Scanner (2008), http://www.insecure.org/nmap/
[15] Jovanovic, N., Kruegel, C., Kirda, E.: Pixy: A Static Analysis Tool for Detecting
Web Application Vulnerabilities (Short Paper). In: IEEE Symposium on Security
and Privacy (2006)
[16] Kals, S., Kirda, E., Kruegel, C., Jovanovic, N.: SecuBat: A Web Vulnerability
Scanner. In: World Wide Web Conference (2006)
[17] Mitre. Common Vulnerabilities and Exposures, http://cve.mitre.org/
[18] Moser, A., Kruegel, C., Kirda, E.: Exploring Multiple Execution Paths for Mal-
ware Analysis. In: IEEE Symposium on Security and Privacy (2007)
[19] Nikto. Web Server Scanner (2008), http://www.cirt.net/code/nikto.shtml
[20] Oﬀutt, J., Abdurazik, A.: Generating Tests from UML Speciﬁcations. In: Second
International Conference on the Uniﬁed Modeling Language (1999)
[21] Oﬀutt, J., Abdurazik, A.: Using UML Collaboration Diagrams for Static Checking
and Test Generation. In: Evans, A., Kent, S., Selic, B. (eds.) UML 2000. LNCS,
vol. 1939, pp. 383–395. Springer, Heidelberg (2000)
210
S. McAllister, E. Kirda, and C. Kruegel
[22] Oﬀutt, J., Liu, S., Abdurazik, A., Ammann, P.: Generating Test Data from State-
based Speciﬁcations. In: Journal of Software Testing, Veriﬁcation and Reliability
(2003)
[23] Poulton, R.: Django Forum Component,
http://code.google.com/p/django-forum/
[24] Satchmo, http://www.satchmoproject.com/
[25] Scott, D., Sharp, R.: Abstracting Application-level Web Security. In: 11th World
Wide Web Conference (2002)
[26] WhiteHat Security. Web Application Security 101 (2005),
http://www.whitehatsec.com/articles/webappsec101.pdf
[27] Su, Z., Wassermann, G.: The Essence of Command Injection Attacks in Web
Applications. In: Symposium on Principles of Programming Languages (2006)
[28] Sun. Java Servlets (2008), http://java.sun.com/products/servlet/
[29] Tenable Network Security. Nessus Open Source Vulnerability Scanner Project
(2008), http://www.nessus.org/
[30] Twill. Twill: A Simple Scripting Language for Web Browsing (2008),
http://twill.idyll.org/
[31] Web Application Attack and Audit Framework,
http://w3af.sourceforge.net/
[32] Xie, Y., Aiken, A.: Static Detection of Security Vulnerabilities in Scripting Lan-
guages. In: 15th USENIX Security Symposium (2006)