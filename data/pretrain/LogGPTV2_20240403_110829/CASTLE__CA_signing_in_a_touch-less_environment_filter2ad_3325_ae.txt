250
200
150
100
50
)
s
(
e
m
T
i
0
0
1
2
512-bit
1024-bit
6
7
8
3
4
5
Number of admins
)
s
(
e
m
T
i
18
16
14
12
10
8
6
4
2
0
Key Assembly
Signature
Total
Figure 6: Running time for attestation and signature functions.
Key assembly corresponds to the time required to calculate the
private key description according to PKCS#1 [11].
)
s
(
e
m
T
i
18
17.5
17
16.5
16
15.5
15
0
1
2
3
4
5
6
7
8
Number of admins
Figure 7: PAL run times for initialization given the number
of participating administrators. The error bars are standard
error.
comparing lines of code does not necessarily denote an advantage
of CASTLE over EJBCA (in particular, EJBCA is implemented in
Java while CASTLE is implemented in C), but unless EJBCA is
used in conjunction with an HSM, it cannot offer similar protection
for its operations and private signing keys as CASTLE does.
8.2 PAL performance
To evaluate the performance of the Flicker sessions, we mea-
sured the running time of the attestation, signature, and initializa-
tion processes. For each PAL function, we measured 10 runs of
execution. For the attestation and signature, we used a single ad-
ministrator but measured the relative times of the key assembly and
the creation of the attestation or signature, respectively. For ini-
tialization and state generation, we measured the effect of admin-
istrators on the running time. Figure 6 shows the results for the
attestation and signature functions, Figure 7 shows the results for
initialization, and Figure 8 shows the results for state generation.
Attestation took longer than signature on average, likely due to
the extra operation of creating the session BLOB. We also observe
that the majority of execution time consists of key assembly (cal-
culating large helper numbers) along with the attestation signature
or certiﬁcate signature. This indicates that the overhead of starting
and ending the Flicker sessions and the remainder of the PAL logic
is a small portion of the run time (around 2.5s for each mode). In
Figure 8: PAL run times for state generation given the number
of participating administrators and the key size. State genera-
tion for 2048-bit keys took around 40 minutes and are thus not
shown here. The error bars are standard error.
initialization, we observed that there was a small effect of the num-
ber of administrators on the running time. In state generation, we
observed that the number of administrators has no signiﬁcant effect
on the running time. This is due in part to the fact that state gen-
eration, which must obtain randomness from the TPM to generate
three RSA public keys, has a running time on the order of minutes
as opposed to seconds for the other operations.
We acknowledge that the duration of the Flicker sessions are
long compared to standard signature processes, sometimes taking
longer than 15 seconds. We could reduce the running time of the
PAL by storing the private key descriptions in PKCS #1 format in
S, eliminating the key assembly overhead, and by optimizing the
mbed TLS library for performance, reducing the time required for
an attestation or certiﬁcate signature. However, we emphasize that
the system is already usable in its current instantiation, and the few
seconds of waiting time are acceptable for conscripted CAs, who
issue certiﬁcates at a much lower volume than commercial CAs.
8.3 Signature Session Performance
To estimate the running time of a signature session with trained
administrators, we performed several signature sessions. In a cer-
tiﬁcate signing session, an administrator must scan a QR code at
the request, attestation, authorization, and signature steps. Thus
each administrator scans or displays a total of 4 QR codes over the
course of a session. However, there are k administrators for each
session, and QR codes must be scanned sequentially to or from the
signer. Thus a total of 4k QR codes are exchanged between the
signer and administrators.
At the request step (and in each step where sequential scanning
of QR codes is required), sequentially scanning QR codes took ap-
proximately 5 seconds per administrator on average, and as shown
above, attestation took about 15 seconds on average. During autho-
rization, ﬁnding the hidden digit and authenticating took 1.5 min-
utes on average, assuming careful checking of the CSR contents.
Finally, the signature took about 14 seconds on average.
Scanning the certiﬁcate signature and exporting the certiﬁcate
took 30 seconds on average. Thus a full signature procedure took
an average of approximately 150 + 20k seconds. Even with careful
checking in a production environment, we do not expect a full ses-
sion to take more than 5 minutes. For high-value certiﬁcates, we
argue that such a latency is reasonable, considering that EV certiﬁ-
cates require an in-person meeting and can take days.
8.4 Cost
The physical construction of the machine, monitor, webcam, and
glass box was around US$2000, where the manufacturing of the
555glass box accounts for roughly $1000. We anticipate that these
costs can be reduced in a larger-scale production, but even so, a
cost of $2000 should be within CA means, given that purchasing a
certiﬁcate costs on the order of $1000.
We anticipate that the majority of the cost of deploying CASTLE
will stem from the training and salary of administrators. Due to
the low volume of certiﬁcate issuances we expect from conscripted
CAs, existing administrators could take on signing session duties in
CASTLE. We note that the protocol requires at least two (and ide-
ally three) administrators to secure the signature and management
operations against a single misbehaving administrator.
9. DISCUSSION
In this section, we brieﬂy discuss several important aspects of
CASTLE. In particular, we address several design alternatives for
CASTLE in practice. We then acknowledge limitations of CAS-
TLE and outline our future work.
Certiﬁcate Revocation. The current version of CASTLE does not
handle certiﬁcate revocation. CASTLE can support various revo-
cation systems such as CRLs [2] or OCSP [20], but the use of an
air-gapped signer would limit the frequency of interactions with
the signer machine to authorize a revocation. We leave the detailed
design and implementation of such a mechanism to future work.
Limitations. One limitation of CASTLE is that BLOBs and log
entries can be modiﬁed (in encrypted form) or destroyed (though
detectably so). To address this weakness, we could add an extra
step to each signature operation that requires the administrator to
conﬁrm that other administrators have received a record of the sig-
nature before the ﬁnal certiﬁcate signature is provided. Another
limitation is the lack of formal veriﬁcation of our protocols. We
plan to address this limitation in future work.
Deploying CASTLE. In future work, we plan to conduct additional
work to assess and improve the operation of CASTLE in practice.
In particular, we plan to carry out a survey among both full-time
and conscripted CAs to determine the relative costs of adminis-
trators, types of hardware and software, security of their physical
facilities, and history of certiﬁcate misissuance. The results of this
survey would provide us with an overview of the causes of certiﬁ-
cate misissuance at both full-time and conscripted CAs, and pro-
vide us with a realistic estimate of the cost of deploying CASTLE
in a conscripted CAs.
We also plan to conduct a comprehensive usability test of the
CASTLE software with domain experts (i.e., administrators at con-
scripted CAs). This testing will allow us to improve the ease of
use of CASTLE for administrators, and we anticipate that such im-
provements will lead to fewer operational errors on the administra-
tors’ part. Finally, we plan to perform further optimizations in the
code to improve performance and security. In particular, we plan to
harden the QR code and certiﬁcate processing libraries, which are
critical pieces of our current signer prototype.
Related Work. Little related work on hardware-secured CA sign-
ing exists besides HSMs, though some proposals leverage trusted
computing for authentication [4, 12], key management [25], and
replay protection [18]. These offer similar functionality to that of
CASTLE, but often with a larger TCB. For example, KISS [25]
uses devices carried by administrators similar to veriﬁers, but all of
these devices must be trusted. Other work has attempted to simplify
the PKI signing process [6], but for end-users rather than CAs.
Several open-source projects offer code for different CA func-
tionality. For example, OpenCA3 offers code for an OCSP respon-
der called OCSPD, while PrimeKey’s EJBCA [19] offers a full CA
application. EJBCA can be run in a virtual machine or make use
of an HSM. EJBCA includes a CA, validation authority (to vali-
date certiﬁcates), and an OCSP responder. However, while EJBCA
offers the ability to use secure hardware such as HSMs and smart
cards, CAs must still purchase the secure hardware and design their
administrative processes.
10. CONCLUSION
Our layered defense-in-depth design for CASTLE shows that we
can leverage a diverse arsenal of defenses to secure certiﬁcate sign-
ing and management for low-volume conscripted CAs. CASTLE
is easy to use for entities who can follow operating procedures and
provide physical security, and thus provides a much-needed step
towards improving security, ease of use, and economic operation
for conscripted CAs.
Acknowledgments
The research leading to these results has received funding from the
European Research Council under the European Union’s Seventh
Framework Programme (FP7/2007-2013), ERC grant agreement
617605, and the National Science Foundation, Grant DGS1252522.
We also gratefully acknowledge support from ETH Zurich and from
the Zurich Information Security and Privacy Center (ZISC).
We graciously thank Magnetron Labs Merz for production of
the glass box prototype. We also thank David Barrera and Daniele
Asoni, who provided feedback on drafts of the paper, and the anony-
mous reviewers, whose feedback helped to improve the paper.
11. REFERENCES
[1] TPM main speciﬁcation level 2 version 1.2, revision 116.
Trusted Computing Group (March 2011)
[2] Cooper, D., Santesson, S., Farrell, S., Boeyen, S., Housley,
R., Polk, T.: Internet X.509 public key infrastructure
certiﬁcate and certiﬁcate revocation list (CRL) proﬁle. RFC
5280 (May 2008)
[3] Dillow, C.: An order of seven global cyber-guardians now
hold keys to the Internet. http:
//www.popsci.com/technology/article/2010-07/order-seven-
cyber-guardians-around-world-now-hold-keys-internet (July
2010)
[4] Gajek, S., Löhr, H., Sadeghi, A.R., Winandy, M.: Truwallet:
trustworthy and migratable wallet-based web authentication.
In: ACM Workshop on Scalable Trusted Computing (STC).
pp. 19–28. ACM (2009)
[5] Greene, J.: Intel trusted execution technology. White paper
(2012)
[6] Gutmann, P.: Plug-and-play PKI: A PKI your mother can
use. In: 12th USENIX Security Symposium. USENIX
(2003)
[7] Haber, S., Stornetta, W.: How to time-stamp a digital
document. Journal of Cryptology 3(2), 99–111 (1991),
http://dx.doi.org/10.1007/BF00196791
[8] Hoekstra, M.: Intel SGX for dummies (Intel SGX design
objectives). https://software.intel.com/en-us/blogs/2013/09/
26/protecting-application-secrets-with-intel-sgx (September
2013)
[9] Hoogstraaten, H., Prins, R., Niggebrugge, D., Heppener, D.,
Groenewegen, F., Wettink, J., Strooy, K., Arends, P., Pols, P.,
Kouprie, R., Moorrees, S., van Pelt, X., Hu, Y.Z.: Black
Tulip: Report of the investigation into the DigiNotar
3https://www.openca.org/
556certiﬁcate authority breach.
www.rijksoverheid.nl/bestanden/documenten-en-
publicaties/rapporten/2012/08/13/black-tulip-update/black-
tulip-update.pdf (August 2012)
[10] Jacobson, V., Smetters, D.K., Thornton, J.D., Plass, M.F.,
Briggs, N.H., Braynard, R.L.: Networking named content.
In: ACM CoNEXT (December 2009)
[11] Jonsson, J., Kaliski, B.: PKCS #1: RSA cryptography
speciﬁcations version 2.1. RFC 3447 (February 2003)
[12] Kostiainen, K., Ekberg, J.E., Asokan, N., Rantala, A.:
On-board credentials with open provisioning. In: 4th
International Symposium on Information, Computer, and
Communications Security (ASIACCA). pp. 104–115. ACM
(2009)
[13] Langley, A.: Enhancing digital certiﬁcate security.
http://googleonlinesecurity.blogspot.ch/2013/01/enhancing-
digital-certiﬁcate-security.html (January 2013)
[14] Langley, A.: Maintaining digital certiﬁcate security.
http://googleonlinesecurity.blogspot.co.uk/2015/03/
maintaining-digital-certiﬁcate-security.html (March 2015)
[15] McCune, J.M., Parno, B.J., Perrig, A., Reiter, M.K., Isozaki,
H.: Flicker: An execution infrastructure for TCB
minimization. In: ACM SIGOPS Operating Systems Review.
vol. 42, pp. 315–328. ACM (2008)
[16] Naylor, D., Mukerjee, M.K., Agyapong, P., Grandl, R., Kang,
R., Machado, M.: XIA: Architecting a more trustworthy and
evolvable Internet. In: ACM SIGCOMM Computer
Communication Review (CCR). vol. 44. ACM (July 2014)
[17] Nystrom, M., Kaliski, B.: PKCS #10: Certiﬁcation request
syntax speciﬁcation. RFC 2986 (November 2000)
[18] Parno, B., Lorch, J.R., Douceur, J.R., Mickens, J., McCune,
J.M.: Memoir: Practical state continuity for protected
modules. In: IEEE Symposium on Security and Privacy (SP).
pp. 379–394. IEEE (2011)
[19] PKI, P.: EJBCA PKI CA. https://www.ejbca.org/ (June 2015)
[20] Santesson, S., Myers, M., Ankney, R., Malpani, A., Galperin,
S., Adams, C.: X.509 Internet public key infrastructure
online certiﬁcate status protocol - OCSP. RFC 6960 (June
2013)
[21] Sara Dickinson, R.v.R.: HSM buyers’ guide. https://wiki.
opendnssec.org/display/DOCREF/HSM+Buyers%27+Guide
(August 2012)
[22] Sleevi, R.: Sustaining digital certiﬁcate security.
https://googleonlinesecurity.blogspot.com/2015/10/
sustaining-digital-certiﬁcate-security.html (October 2015)
[23] Zetter, K.: PIN crackers nab holy grail of bank card security.
http://www.wired.com/2009/04/pins/ (April 2009)
[24] Zhang, X., Hsiao, H.C., Hasker, G., Chan, H., Perrig, A.,
Andersen, D.G.: SCION: Scalability, control, and isolation
on next-generation networks. In: Security and Privacy (SP),
2011 IEEE Symposium on. pp. 212–227. IEEE (May 2011)
[25] Zhou, Z., Han, J., Lin, Y.H., Perrig, A., Gligor, V.: KISS:
“Key It Simple and Secure” corporate key management. In:
Trust and Trustworthy Computing, pp. 1–18. Springer (2013)
557