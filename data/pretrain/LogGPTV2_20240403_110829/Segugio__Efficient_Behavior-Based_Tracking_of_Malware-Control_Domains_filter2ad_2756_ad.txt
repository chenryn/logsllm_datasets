### Control Domains
Figure 9 illustrates a subset of the domains that were classified as false positives. The effective second-level domains (e2LDs) are highlighted in bold.

- **thaisqz.sites.uol.com.br**
- **jkishii.sites.uol.com.br**
- **sjhsjh333.egloos.com**
- **ivoryzwei.egloos.com**
- **dat007.xtgem.com**
- **vk144.narod.ru**
- **jhooli10.freehostia.com**
- **7171.freehostia.com**
- **cr0s.interfree.it**
- **cr0k.interfree.it**
- **id11870.luxup.ru**
- **id23166.luxup.ru**

**Fig. 9: Example set of domains that were counted as false positives. The effective 2LDs are highlighted in bold.**

### Analysis of False Positives
We provide a detailed breakdown of the false positives generated by Segugio during the three different cross-day and cross-network tests reported in Section IV-A and in Figure 6 (a), (b), and (c). Table III summarizes these results.

For instance, experiment (a) produced 724 distinct false positive fully qualified domains (FQDs) with a detection threshold set to produce at most 0.05% FPs and > 90% true positives (TPs). Many of these false positive domains shared the same e2LD. In fact, there were only 401 distinct e2LDs. The top 10 e2LDs contributed 32% of all false positives.

**Table III: Analysis of Segugio’s False Positives**

| Test Experiment | Absolute number of false positives for overall 0.05% FPs and > 90% TPs | Fully qualified domains (FQDs) | Effective second-level domains (e2LDs) | Contribution of top 10 e2LDs | Feature Contributions |
|-----------------|-------------------------------------------------------------|--------------------------------|----------------------------------------|------------------------------|-----------------------|
| (a) ISP1 cross-day | 724 | 401 | 230 (32%) | 73% | 86% |
| (b) ISP2 cross-day | 807 | 410 | 21% | 23% | 247 (31%) |
| (c) ISP1-ISP2 cross-network | 786 | 451 | 55% | 80% | 27% |

- **Domains queried by malware:** 73%
- **Past abused IPs:** 86%
- **Active for ≤ 3 days:** 26%
- **Evidence of Malware Communications (sandbox traces):** 21%

Table III also shows that 73% of all false positive domains were queried by a group of machines, of which more than 90% were known to be infected. Additionally, 86% of the false positive domains resolved to previously abused IP addresses, and 26% of them were active for less than three days. Using a separate large database of malware network traces obtained by executing malware samples in a sandbox, we found that 21% of the domains that we counted towards the false positives had been contacted by known malware samples.

### Summary
Our experiments show that Segugio’s false positive rate is low (e.g., ≤ 0.05% FPs at a TP rate ≥ 90%) and may even be somewhat overestimated. Generally, Segugio yields much lower false positives than previously proposed systems for detecting malicious domains (see Section V for a comparison to Notos [3]). Even so, some false positives are essentially inevitable for statistical detection systems like Segugio. Therefore, additional vetting processes should be implemented before deploying the discovered domains to block malware-control communications.

### Experiments with Public Blacklists
To demonstrate that Segugio’s results are not critically dependent on the specific commercial malware C&C blacklist used as ground truth, we conducted experiments using public blacklist information.

#### Cross-day Tests
We repeated the cross-day experiment on machine-domain graphs labeled using exclusively known malware-control domains collected from public blacklists. Specifically, we collected domains labeled as malware C&C (excluding other types of non-C&C malicious domains) from the following sources:
- spyeyetracker.abuse.ch
- zeustracker.abuse.ch
- malwaredomains.com
- malwaredomainlist.com

Overall, our public C&C domain blacklist consisted of 4,125 distinct domain names. We then used this blacklist to label the malware nodes in the machine-domain graph and performed all other steps to conduct cross-day experiments using the same procedure described in Section IV-A (the only change was the blacklist).

**Figure 10** reports the results on traffic from ISP2 (results for the other ISP network and different days of traffic are very similar). Segugio achieved over 94% true positives at a false positive rate of 0.1%.

**Fig. 10: Cross-day results using only public blacklists**

#### Cross-Blacklist Tests
To further demonstrate Segugio’s ability to discover new malware-control domains, we conducted another experiment by using our commercial C&C blacklist (described in Section III) for training purposes and then testing Segugio to see if it could detect new malware-control domains that appeared in the public blacklists but were not in our commercial blacklist.

By inspecting a day of traffic from ISP2, we observed 260 malware-control domains that matched our public blacklist. However, 207 of these domains already existed in our commercial blacklist. Therefore, we used only the remaining 53 new domains that matched the public blacklist (but not the commercial blacklist) to compute Segugio’s true positives. We found that Segugio could achieve the following trade-offs between true and false positives:
- (TPs=57%, FPs=0.1%)
- (TPs=74%, FPs=0.5%)
- (TPs=77%, FPs=0.9%)

While the TP rate looks somewhat lower than in other tests, this is likely due to the limited test set size (only 53 domains) and noise. Manual inspection revealed that some domains in the public blacklists were highly likely benign or not related to malware-control activities.

### Early Detection of Malware-Control Domains
We performed experiments to measure how early Segugio can detect malware-control domains compared to malware domain blacklists. We selected four consecutive days of data from either of the two ISP networks (8 days of traffic, overall). For each day, we trained Segugio and set the detection threshold to obtain ≤ 0.1% false positives. We then tested the classifier on all domains that on that day were still labeled as unknown and checked if the newly detected malware-control domains appeared in our blacklists in the following 35 days.

During the four days of monitoring, we found 38 domains that later appeared in the blacklist. A large fraction of these newly discovered domains were added to the blacklist many days after they were detected by Segugio, as shown in **Figure 11**.

**Fig. 11: Early detection results: histogram of the time gap between Segugio’s discovery of new malware-control domains and the time when they first appeared on the blacklist.**

### Segugio’s Performance (Efficiency)
Segugio efficiently learns the behavior-based classifier from an entire day of ISP-level DNS traffic and can classify all (yet unknown) domains seen in a network in a matter of a few minutes. On average, the learning phase took about 60 minutes, including building the graph, annotating and labeling the nodes, pruning the graph, and training the behavior-based classifier. The feature measurement and testing of all unknown domains required only about 3 minutes.

### Comparison with Notos
In this section, we compare our Segugio system to Notos [3], a recently proposed domain reputation system. While Notos aims to detect malicious domains in general, including phishing and spam domains, we focus on a behavior-based approach for accurately detecting malware-control domains, specifically "malware-only" domains through which attackers provide control functionalities to already infected machines.

#### Experimental Setup
We obtained access to a version of Notos built by the original authors. The version of Notos available to us was trained using a very large blacklist of malicious domains and a whitelist consisting of the top 100K most popular domains according to Alexa. We verified that the blacklist used to train Notos was a proper superset of the blacklist of malware-control domains we used to train Segugio. We trained Segugio using only the top 100K Alexa domains, as done by Notos, to allow for a balanced comparison.

To compute the false positives, we used the whitelist detailed in Section III, from which we removed the top 100K Alexa domains used during the training of Notos and Segugio. The version of Notos we used was trained on October 8, 2013 (ttrain). We trained Segugio on traffic from the same day and labeled malware domains using our blacklist updated until ttrain. Both systems were trained using only ground truth gathered before ttrain. We tested both Notos and Segugio on the two ISP networks, using one entire day of traffic from November 1, 2013 (ttest). To compute the true positives, we considered as ground truth only those new confirmed malware-control domains that were added to our blacklist between (ttrain + 1) and ttest. Overall, during that period, we had 44 and 36 new blacklisted malware-control domains that appeared in ISP1 and ISP2, respectively.

#### Results
**Figure 12** shows the detection results for the two systems. **Figure 12a** indicates that the detection threshold on Notos’s output score needs to be increased significantly before the new malware-control domains (blacklisted after ttrain) are detected. This causes a high false positive rate (16.23% and 21.11%, respectively, for ISP1 and ISP2). Additionally, only less than 56% of the newly blacklisted domains are detected in the best case (ISP1 in Figure 12a). The version of Notos given to us employed a "reject option" whereby the system may avoid classifying an input domain if not enough historic evidence about its reputation could be collected.

According to **Figure 12b** (where FPs are in [0, 0.03]), Segugio detected 90.9% and 75% of new malware-control domains with less than 0.7% false positives in ISP1 and ISP2, respectively. This shows that Segugio outperforms Notos, even considering the 24-day gap between the training and test phases.

**Fig. 12: Comparison between Notos and Segugio (notice that the range of FPs for Notos is [0, 1.0], while for Segugio FPs are in [0, 0.03])**

#### Breaking Down the False Positives
To better understand why Notos produced a high false positive rate, we investigated the possible reasons why many of our whitelisted domains were assigned a low reputation (see Table IV). After adjusting the detection threshold, we found that many of the false positives were due to the presence of benign domains in the public blacklists and the limited historical evidence available for some domains.