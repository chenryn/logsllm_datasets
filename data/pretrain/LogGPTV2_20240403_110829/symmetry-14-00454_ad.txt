| 12 |4 |3 |0.9596 |0.9634 |0.9615 |
| 12 |4 |4 |0.9649 |0.9586 |0.9618 |
| 12 |5 |2 |0.9609 |0.9634 |0.9621 |
| 12 |5 |3 |0.9648 |0.9616 |0.9632 |
| 12 |5 |4 |0.9664 |0.9561 |0.9612 |
| 12 |6 |2 |0.9646 |0.9442 |0.9543 |
| 12 |6 |3 |0.9653 |0.9372 |0.9511 || 12 |6 |3 |0.9653 |0.9372 |0.9511 |
| 12 |6 |4 |0.9664 |0.9333 |0.9495 |
| 13 |4 |2 |0.9586 |0.9856 |0.9719 |
| 13 |4 |3 |0.9624 |0.9630 |0.9627 |
| 13 |4 |4 |0.9678 |0.9582 |0.9630 |
| 13 |5 |2 |0.9637 |0.9630 |0.9634 |
| 13 |5 |3 |0.9677 |0.9612 |0.9644 |
| 13 |5 |4 |0.9693 |0.9555 |0.9623 |
| 13 |6 |2 |0.9675 |0.9438 |0.9555 |
| 13 |6 |3 |0.9683 |0.9368 |0.9523 |
| 13 |6 |4 |0.9693 |0.9325 |0.9506 || 13 |6 |4 |0.9693 |0.9325 |0.9506 |
| 14 |4 |2 |0.9602 |0.9778 |0.9689 |
| 14 |4 |3 |0.9640 |0.9553 |0.9596 |
| 14 |4 |4 |0.9694 |0.9473 |0.9583 |
| 14 |5 |2 |0.9654 |0.9553 |0.9603 |
| 14 |5 |3 |0.9694 |0.9531 |0.9612 |
| 14 |5 |4 |0.9709 |0.9446 |0.9576 |
| 14 |6 |2 |0.9693 |0.9361 |0.9524 |
| 14 |6 |3 |0.9699 |0.9258 |0.9473 |
| 14 |6 |4 |0.9710 |0.9212 |0.9454 |
(a) 	(b)
Figure 10. Cont.(a) 	(b)
Figure 10. Cont.
Symmetry 2022, 14, 454 17 of 21
(c) 	(d)
Figure 10. LogLS performance with different parameters. (a) Window size: h. (b) Number of epochs:
E. (c) Number of layers: L. (d) Number of memory units: S.
5. Online Update and Training of LogLSAlthough the method in this paper has achieved good performance in the HDFS log anomaly detection experiment, problems may occur when dealing with more irregular logs (such as system logs). Many log keys only appear in a certain period, so the training set may not contain all the normal log keys, which will cause false predictions. The model update module can effectively solve this problem, which adjusts the weight parameters of the model in real time based on the online false-positive results. This section sets up a comparative experiment of model updates to verify its effectiveness.The model update method adopts incremental update, and only uses false positives to update the model. Suppose h = 3, the input historical sequence is {k1, k2, k3}, and LogLS predicts that the next log key is k2 with probability 1, and the log key in the actual sequence is k3, then the model marks it as an anomaly. However, after manual detection, it is known that this is a false positive. LogLS can use {k1, k2, k3 → k3} to update the weights of its model, therefore learning this new log pattern. The next time enter {k1, k2, k3}, LogLS can output both k2 and k3 with updated probabilities. This method does not need to re-update LogLS from scratch. Updating the model with new experimental data. The weights of model are adjusted by minimizing the error between experimental output and actual observations from false-positive cases.The log dataset selected in this experiment is the system log of the 708 M Blue Gene/L supercomputer [40], also known as the BGL log. This log is different from the HDFS log and is chosen because many logs in this dataset only appear in specific events, so the training set may not contain all the normal execution paths and log keys.The log dataset contains 4,747,963 logs, of which 348,460 are marked as anomalies, including alarm and nonalarm messages identified by alarm category tags. In the first column of the log, “-” means nonalarm messages, while others are alarm messages. The label information facilitates alarm detection and prediction research. It has been used in many studies, such as log parsing, anomaly detection and failure prediction.When using BGL to generate a log sequence, it is different from the HDFS method. For this type of log without a unique identifier, we use a sliding window to obtain the log sequence. In this experiment, we set the sliding window size to 40 and obtained 214,475 normal BGL log sequences and 20,657 abnormal BGL log sequences. We take 1% of normal BGL log entries as the training set, the remaining 1/3 as the validation set (if needed), and 2/3 as the test set. The model update uses the trained model to detect anomalies. Whenever the detected result is found to be a false positive, the input and output sequence of the result is used to update the model. Due to the characteristics of the BGL log, the settings onSymmetry 2022, 14, 454 18 of 21
some parameters continue to use the values in the DeepLog method. In this experiment, g1 = 10, g2 = 4, g3 = 2, h = 3, L = 1, S = 64 and E = 300.According to Table 11 and Figure 11, we have proved the effectiveness of the model update algorithm through experiments. After the model update, the detection accuracy of the model is improved. The model updating mechanism improves the detected F1 measure value from 29.89% to 80.94%, and the accuracy is also improved by 50.57%. This shows that updating the model can solve the situation where the training set cannot cover all normal execution paths.Table 11. Evaluation on Blue Gene/L Log.
|  | No Update Model | Update Model |
|---|---|---|
| FP |64,440 |6416 |
| FN |31 |47 |
| Precision |17.58% |68.15% |
| Recall |99.78% |99.66% |
| F1-measure |29.89% |80.94% |
Figure 11. Evaluation on Blue Gene/L Log.
6. ConclusionsThis paper proposes a system log anomaly detection method based on dual LSTM, which makes full use of the context of log events in log sequences. Referring to the Spell log parsing method, a filtering operation is added to obtain the log event template list more accurately, effectively solving the problem of inconsistent log structure in the traditional anomaly detection method. According to the log event context and latent symmetry information, we build two LSTM models from these two perspectives and make them cooperate with each other to detect log anomalies. To solve the problem that the LSTM model cannot handle unknown logs, we also added an updated model mechanism to improve the performance of the model in detecting new log rules. For logs with unique identifiers, such as HDFS logs, we can form log sequences based on unique identifiers. For logs without unique identifiers, such as BGL logs, we can select fixed windows to form log sequences. The experimental results show that the proposed method performs well on HDFS large log datasets, and the accuracy, recall rate and F1-measure are better than the current cutting-edge log anomaly detection methods. In addition, this paper fully analyzes the influence of parameter changes on the model performance, and verifies the effectiveness of the model update strategy, which has significant performance in system log anomalySymmetry 2022, 14, 454 19 of 21
detection, and is of great significance to system anomaly detection and optimization of
model parameters.
In future work, the model will be improved to make it suitable not only for anomaly
detection in the execution mode of the system log, but also for detection for each parameter
in the log. We find a better way to solve the problem that the LSTM model cannot predictthe log execution path that does not appear.
Author Contributions: Conceptualization, Y.C. and N.L.; methodology, Y.C., N.L. and D.L.; writing—
original draft preparation, Y.C.; writing—review and editing, Y.C. and D.L.; project administration,
N.L.; funding acquisition, N.L. All authors read and agreed to the published version of the manuscript.
Funding: This work was supported in part by the Innovation Environment Construction SpecialProject of Xinjiang Uygur Autonomous Region under Grant PT1811, and in part by the Key Grant
Project of the National Social Science Fund of China(NSFC) under Grant 20&ZD293.
Institutional Review Board Statement: Not applicable.