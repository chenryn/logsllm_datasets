R3_S4_P3SS2SS100123
R2_S1_P01S2S012
R3_S4_P3SS2SS1032103210
R2_S1_P2SS10012
R5_S1_P0S12012
alternating pointer-chase
alternating pointer-chase
Cycles
1 332
1 255
1 074
1 694
1 266
1 149
1 221
1 517
1 216
3 708
2 970
2 750
5.1 Last-Level Cache (LLC)
Main Idea. The key idea of our solution to Challenge-LLC relies
on property 2 . Assume the scope line S to be the first line in the set
(line 0). Then, the Prime patterns comprise accesses to ùëä congruent
lines, like other prime strategies, but accesses to lines 1 to ùëä ‚àí 1
are interleaved with accesses to S. Due to its frequent usage, S is
always served from L1, so it keeps its insertion age in the LLC. The
other lines, in contrast, evict each other from L1, and when they are
read from the LLC, their age decreases, making them progressively
younger. As soon as all other lines become younger than S, the
latter is the EVC in the LLC without ever leaving the L1 cache.
Prime Properties. For each candidate Prime pattern, we assess
the eviction rate (EVr), i.e., the fraction of successful evictions of the
target line. More importantly, we also record the eviction candidate
rate (EVCr), i.e., the fraction of attempts where the target line is
evicted, and the line that will be evicted next is the intended S, and
it is still in L1. Finally, we also record the duration, i.e., the number
of cycles to complete the accesses indicated by the pattern.
It is clear that ùê∏ùëâùê∂ùëü ‚â§ ùê∏ùëâ ùëü. While the EVr is the success rate of
preparing the cache set for Prime+Probe, the EVCr is the success
rate of preparing S for a continuous Scope. Understandably, prior
efficient patterns for Prime+Probe typically have a low EVCr, be-
cause these patterns are oblivious to the EVC. Hence, good Prime
patterns for Prime+Scope differ from those in prior work.
Methodology of PrimeTime. The high-level description of Prime-
Time is shown in Algorithm 1. It starts with known access pattern
templates, e.g., [24], and mutates them according to given direc-
tives. Mutations consist of repeated access to certain (sub-)patterns,
permuting access orders, or interleaving accesses to S.
To limit execution time, PrimeTime tests patterns in stages, gradu-
ally becoming more restrictive on the patterns that pass to the next
stage, both in EVCr and cycle count. In the first stage, we test each
pattern with 10 000 repetitions, with loosely defined success criteria.
Later stages perform up to a million repetitions, while filtering for
the best-performing patterns. A run for a specific microarchitecture
takes approximately one hour under our configuration, but this can
be scaled in either direction (i.e., speed vs. accuracy). Furthermore,
PrimeTime can be extended to cover a larger search space.
PrimeTime on Various Processor Generations. As shown in Table 1,
PrimeTime is able to construct effective Prime access patterns on
all tested generations of Intel CPUs, though their duration differs
across microarchitectures. For each CPU, we indicate the target
cache and one top-ranking pattern. To select this pattern, we con-
sider EVCr, worst-case durations (99th percentile), and whether vari-
ants of the pattern are also successful. All patterns shown achieve
> 99.9% EVCr. In fact, many patterns exist with similar EVCr.
For Sandy Bridge (2011), the necessary conditions for Prime+
Scope still hold, but the Prime patterns we have found are less
efficient. We hypothesize that this is because this generation of
processors uses the MRU replacement policy in the LLC [2], for
which the insertion age is already young to begin with (and the
PrimeTime strategy works best when the insertion age is old).
Serialization. PrimeTime avoids processor-specific (reverse-) en-
gineering work. As an alternative to PrimeTime, one can obtain
Prime patterns by handcrafting patterns (e.g., [10, 11, 64]) that
leverage on the knowledge of the exact cache replacement policy,
and the interaction between cache levels. In the end, such a strat-
egy may lead to efficient primes with minimal memory accesses.
. . .
Algorithm 1 PrimeTime
Output: Prime patterns with high EVCr and low cycle count
1: Patterns ‚Üê GenerateAccessPatterns()
2: Patterns ‚Üê Mutate(Patterns, with Repeated Access)
3: Patterns ‚Üê Mutate(Patterns, with interleaved S Accesses)
4: Measurements ‚Üê TestEviction(Patterns, 10 000 times)
5: Patterns ‚Üê Filter(Patterns, Measurements, Highest EVCr 7 000 )
6: Patterns ‚Üê Filter(Patterns, Measurements, Fastest 5 000 )
7: Measurements ‚Üê TestEviction(Patterns, 1 000 000 times)
8: Patterns ‚Üê Filter(Patterns, Measurements, Highest EVCr 150 )
9: Patterns ‚Üê Filter(Patterns, Measurements, Fastest 100 )
10: return Patterns
. . .
Session 11A: Attestation and Firmware Security CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2911However, such handcrafted patterns generally need to serialize
accesses [11, 64] to prevent out-of-order execution from destroy-
ing the intended effects. Such serialization is implemented with
pointer-chasing or memory fences, rendering the Prime patterns
slower. PrimeTime avoids serialization by executing on the target
architecture to incorporate hard-to-predict runtime effects directly.
Still, there may exist handcrafted patterns that are more effective
than the unordered patterns found by PrimeTime. However, the
patterns obtained with PrimeTime are sufficient for Prime+Scope.
5.2 Coherence Directory (CD)
To enable Prime+Scope on the coherence directory, we again need
a suitable Prime pattern. Unfortunately, Yan et al. [65] showed that
achieving a high eviction rate with known eviction patterns is hard,
especially when limited to ùëä addresses. For instance, they report
that repeated accesses to ùëä = 12 congruent lines require more than
10 iterations to fully prime the CD. This is Challenge-CD.
Slow Prime patterns, consisting of many accesses, are not a fun-
damental problem for Prime+Scope, as the ultimate time resolution
is decoupled from the duration of the Prime (cf. Section 3.2). How-
ever, our PrimeTime tool indicates that such patterns fail to fix the
EVC with high accuracy (Rùêµ), prohibiting Prime+Scope.
On the bright side, non-inclusive Intel caches have the advantage
that lines in the CD always reside in one of the lower-level caches,
satisfying Rùê∂ by design. Thus, what remains is to find a pattern that
installs the desired eviction candidate in the CD (Rùêµ). We first cover
a slow but universal solution. Then, we discuss our hypothesis for
why traditional patterns do not work well on the CD, leading to a
more efficient Prime pattern that leverages this information.
Fill-Flush-Fill. Prior work has used a fill-flush-fill approach to re-
set and simplify the replacement policy state [2, 11, 59]. Transposed
to the CD, it would first fill the CD set, e.g., through many repe-
titions of an inefficient eviction pattern [65], flush all lines of the
eviction set, and finally load them again in order. We confirm that
such patterns successfully prime the CD set (with EVCr > 99.9%),
provided that the initial set filling is successful. However, such pat-
terns are relatively slow. Moreover, the clflush instruction may
not be available in restricted environments (cf. Section 4.1).
CD Replacement Policy. We believe that the poor performance of
traditional eviction patterns on the CD is caused by property 2 .
The reason why this effect is more pronounced for the CD than for
inclusive LLCs is the large associativity of private caches in current
non-inclusive Intel hierarchies, and that lines in the CD are also
cached in L1 and/or L2 [65]. If reading such lines does not influence
the replacement state of the CD, many accesses are required for
every attacker line to become younger than the lines to be evicted.
Thus, for many access patterns, the CD behaves like a first-in-first-
out (FIFO) queue, irrespective of the actual replacement policy.
Based on this hypothesis, a straightforward way to prime the
CD is to access ùëä congruent lines that are currently not in the CD.
Indeed, we find such an access pattern to simultaneously achieve a
near-perfect EVr and EVCr (the first element of the set being the
scope line S), making it a suitable Prime pattern for Prime+Scope.
On all non-inclusive platforms under consideration, our successive
Primes alternate between two eviction sets of ùëä addresses. As FIFO
function() {
...
before
operation(secret);
after
...
function() {
...
load(array[secret*1024]);
... // other operations
load(array[!secret*1024]);
...
after (data or instruction)
before (data or instruction)
1
2
function
array[0]
1
2
(i) Variable-Time Operation
(ii) Variable-Time Access
Figure 5: Uses of differential time:
2 -
1
is very sensitive to ordering, and insensitive to repeated accesses,
we enforce serialization by using a pointer-chasing approach [55].
6 CASE STUDIES
Micro-benchmarks. Prime+Scope bypasses the observer effect
of the cache contention side channel, and reduces the cache mea-
surement to a single memory access. Consequently, Prime+Scope
is able to monitor victim behavior with high temporal precision,
even asynchronously, without having to cope with missed accesses.
Section 6.1 quantifies this precision and compares it to other tech-
niques, and Section 6.2 characterizes the influence of noise.
Differential Time. By scoping multiple sets simultaneously, Prime+
Scope can estimate the temporal separation between two (or more)
events with fine precision. Figure 5 shows two classes of timing
leaks for which Prime+Scope is particularly well-suited.
The first class is that of variable-time operations, where the dura-
tion of an operation depends on a secret value. Such a code pattern
encodes the secret in the time difference between memory accesses
before and after operation, as in Figure 5i. Several attacks exploit
leakage of this kind, e.g., for a secret-dependent number of loop
iterations (e.g., [15]), or non-constant-time arithmetic (e.g., modular
reduction [4, 21]). Cache attacks can only decode the secret if their
precision is sufficient to detect the secret-dependent time difference
of operation. Often, however, the resolution is too low, prompting
the use of performance degradation of the victim [3, 4, 21].
The second class is that of variable-time accesses, where memory
accesses occur at a secret-dependent time (or, as a special case, in
a secret-dependent order [7]). In Figure 5ii, the elements of array
are always accessed, but the time relative to the start of function
depends on a (binary) secret. Again, the attack needs sufficient
precision to detect the secret-dependent time differences.
In this paper, we focus on variable-time access leakage. Section 6.3
demonstrates a high-capacity covert channel that works with such
temporal encoding of the data. In Section 6.4, we show that AES
T-tables, a well-studied cache attack target, also exhibits variable-
time access leakage. Too fine-grained to be properly harnessed by
prior techniques, with Prime+Scope, we exploit it to significantly
reduce the number of traces needed for the attack.
Congruence Detection. The repeatable measurement of a single
cache line is also useful to determine congruence in the target
cache. In Section 6.5, we demonstrate this capability with a simple,
efficient and portable eviction set construction methodology.
Session 11A: Attestation and Firmware Security CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2912(i) Precision on LLC (Core i5-7500, Kaby Lake)
(ii) Precision on CD (Xeon Platinum 8280, Cascade Lake)
Prepare
Measure
clflush T
R1_S1_P0
R3_S1_P012012
Resmin Res95
Tech. WL
4 350
FR
‚úó
2 500
PPwA
‚úó
4 350
PPwB
‚úó
300
FF
‚úì /
390
‚úì /
PPc
PS
70
‚úì /
(iii) Techniques (LLC). WL denotes windowless; Resùëöùëñùëõ and Res95
denote max. resolution and resolution for 95% accuracy (cycles)
load T
R1_S1_P0
R1_S1_P0
clflush T
R1_S1_P0
load EVC
420
580
790
300
390
70
clflush T
load T
Prepare
Measure
simple ptr-chase
clflush T
Resmin Res95
Tech. WL
5 000
FR
‚úó
PPw
300
‚úó
1 600
FF
‚úó
‚úì /
PPc
210
PS
80
‚úì /
(iv) Techniques (CD). WL denotes windowless; Resùëöùëñùëõ and Res95
denote max. resolution and resolution for 95% accuracy (cycles)
simple ptr-chase
load EVC
simple ptr-chase
clflush T
440
300
430
210
80
Figure 6: Accuracy and resolution as function of window size
6.1 Temporal Precision
We now quantify the time resolution of Prime+Scope (PS) to detect
cross-core asynchronous events for an inclusive LLC and CD. For
reference, we include the most prominent techniques; Prime+Probe
(PP) for cache contention, i.e., the most comparable technique, and
Flush+Reload (FR) and Flush+Flush (FF) for shared memory.
For Prime+Probe, the experiment includes windowed (PPw)
and windowless (PPc) variants, where we consider two windowed
versions for the LLC (PPwA and PPwB), as in Figure 6iii. For the CD,
we use the accurate eviction patterns as discovered in Section 5.2,
though they were unknown prior to this work.
On our non-inclusive processors, the Flush+Flush side channel
also exists although inverted, i.e., lines present in the hierarchy have
lower flush latency than those that do not. Moreover, the difference
is quite large (200 vs. 330 cycles), unlike the subtle difference on our
inclusive testbed. Prior work [13] reports that flushing an uncached
line on multi-socket Intel systems triggers an access to memory for
cross-socket coherence, which would clarify this behavior.
The measurement thresholds are calibrated dynamically and in-
dividually for every technique, based on timing histograms and the
threshold selection regime with the best results. We note that some
techniques (e.g., Flush+Reload, Prime+Scope) are less sensitive
to the specific threshold value than others (e.g., Prime+Probe).
Methodology. We consider the following micro-benchmark for
detecting asynchronous events. The event to be detected is an access
to a specific cache line, by a process pinned to another core. To
model an asynchronous event, the process first yields the CPU