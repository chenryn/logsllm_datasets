this automated approach can easily scale to large collections of program models.
Acknowledgments. We thank the anonymous reviewers and the members of the WiSA
project at Wisconsin for their helpful comments that improved the quality of the paper.
This work was supported in part by Ofﬁce of Naval Research grant N00014-01-1-
0708, NSF grant CCR-0133629, and Department of Energy grant DE-FG02-93ER25176.
Jonathon T. Gifﬁn was partially supported by a Cisco Systems Distinguished Graduate
Fellowship. Somesh Jha was partially supported by NSF Career grant CNS-0448476. The
U.S. Government is authorized to reproduce and distribute reprints for governmental pur-
poses, notwithstanding any copyright notices afﬁxed hereon. The views and conclusions
contained herein are those of the authors and should not be interpreted as necessarily rep-
resenting the ofﬁcial policies or endorsements, either expressed or implied, of the above
government agencies or the U.S. Government.
References
[1] T. Ball and S. K. Rajamani. Bebop: A symbolic model checker for boolean programs. In
7th International SPIN Workshop on Model Checking of Software, Stanford, California,
Aug./Sep. 2000.
[2] F. Besson, T. Jensen, D. L. M´etayer, and T. Thorn. Model checking security properties of
control-ﬂow graphs. Journal of Computer Security, 9:217–250, 2001.
[3] H. Chen and D. Wagner. MOPS: An infrastructure for examining security properties of
In 9th ACM Conference on Computer and Communications Security (CCS),
software.
Washington, DC, Nov. 2002.
[4] E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. The MIT Press, 2000.
[5] J. Esparza, D. Hansel, P. Rossmanith, and S. Schwoon. Efﬁcient algorithms for model
In Computer Aided Veriﬁcation (CAV), Chicago, Illinois,
checking pushdown systems.
July 2000.
[6] H. H. Feng, J. T. Gifﬁn, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing sensitivity
In IEEE Symposium on Security and Privacy,
[7] S. Forrest. Data sets—synthetic FTP. http://www.cs.unm.edu/∼immsec/data/FTP/UNM/-
in static analysis for intrusion detection.
Oakland, California, May 2004.
normal/synth/, 1998.
[8] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff. A sense of self for UNIX
processes. In IEEE Symposium on Security and Privacy, Oakland, California, May 1996.
[9] D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly detection.
In USENIX Security Symposium, San Diego, California, Aug. 2004.
[10] J. T. Gifﬁn, D. Dagon, S. Jha, W. Lee, and B. P. Miller. Environment-sensitive intrusion
In 8th International Symposium on Recent Advances in Intrusion Detection
detection.
(RAID), Seattle, Washington, Sept. 2005.
60
J.T. Gifﬁn, S. Jha, and B.P. Miller
[11] J. T. Gifﬁn, S. Jha, and B. P. Miller. Detecting manipulated remote call streams. In 11th
USENIX Security Symposium, San Francisco, California, Aug. 2002.
[12] R. Gopalakrishna, E. H. Spafford, and J. Vitek. Efﬁcient intrusion detection using automa-
ton inlining. In IEEE Symposium on Security and Privacy, Oakland, California, May 2005.
[13] J. D. Guttman, A. L. Herzog, J. D. Ramsdell, and C. W. Skorupka. Verifying information
ﬂow goals in Security-Enhanced Linux. Journal of Computer Security, 13:115–134, 2005.
[14] L.-c. Lam and T.-c. Chiueh. Automatic extraction of accurate application-speciﬁc sandbox-
ing policy. In Recent Advances in Intrusion Detection (RAID), Sophia Antipolis, French
Riveria, France, Sept. 2004.
[15] C. R. Ramakrishnan and R. Sekar. Model-based vulnerability analysis of computer systems.
In 2nd International Workshop on Veriﬁcation, Model Checking and Abstract Interpreta-
tion, Pisa, Italy, Sept. 1998.
[16] F. B. Schneider. Enforceable security policies. ACM Transactions on Information and
System Security, 3(1):30–50, Feb. 2000.
[17] S. Schwoon. Model-Checking Pushdown Systems. Ph.D. dissertation, Technische Univer-
sit¨at M¨unchen, June 2002.
[18] S. Schwoon. Moped—a model-checker for pushdown systems.
http://www.fmi.uni-
stuttgart.de/szs/tools/moped/, 2006.
[19] R. Sekar, M. Bendre, P. Bollineni, and D. Dhurjati. A fast automaton-based method for
In IEEE Symposium on Security and Privacy,
detecting anomalous program behaviors.
Oakland, California, May 2001.
[20] K. Tan, K. S. Killourhy, and R. A. Maxion. Undermining an anomaly-based intrusion de-
tection system using common exploits. In Recent Advances in Intrusion Detection (RAID),
Z¨urich, Switzerland, Oct. 2002.
[21] K. Tan and R. A. Maxion. “Why 6?” Deﬁning the operational limits of stide, an anomaly
based intrusion detector. In IEEE Symposium on Security and Privacy, Oakland, California,
May 2002.
[22] K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal to the nor-
mal and beyond. In 5th International Workshop on Information Hiding, Noordwijkerhout,
Netherlands, Oct. 2002.
[23] D. Wagner and D. Dean. Intrusion detection via static analysis. In IEEE Symposium on
Security and Privacy, Oakland, California, May 2001.
[24] D. Wagner and P. Soto. Mimicry attacks on host based intrusion detection systems.
In
9th ACM Conference on Computer and Communications Security, Washington, DC, Nov.
2002.
[25] B. J. Walker, R. A. Kemmerer, and G. J. Popek. Speciﬁcation and veriﬁcation of the UCLA
Unix security kernel. Communications of the ACM, 23(2), Feb. 1980.
Allergy Attack Against Automatic Signature
Generation
Simon P. Chung and Aloysius K. Mok(cid:7)
University of Texas at Austin, Austin TX 78712, USA
Department of Computer Sciences,
{phchung, mok}@cs.utexas.edu
Abstract. Research in systems that automatically generate signatures
to ﬁlter out zero-day worm instances at perimeter defense has received
a lot of attention recently. While a well known problem with these sys-
tems is that the signatures generated are usually not very useful against
polymorphic worms, we shall in this paper investigate a diﬀerent, and
potentially more serious problem facing automatic signature generation
systems: attacks that manipulate the signature generation system and
turn it into an active agent for DoS attack against the protected system.
We call this new attack the “allergy attack”. This type of attack should
be anticipated and has in fact been an issue in the context of “detraining”
in machine learning. However, we have not seen a demonstration of its
practical impact in real intrusion detection/prevention systems. In this
paper, we shall demonstrate the practical impact of “allergy attacks”.
Keywords: Automatic Signature Generation, Adaptive Response, In-
trusion Prevention.
1 Introduction
With the proliferation of worms propagating at speed too fast for human inter-
vention, automatic worm containment is increasingly looked upon as a solution.
An important line of work in this area is the automatic signature generation
(ASG) systems, which generate signatures to ﬁlter worm instances at perime-
ter defense. Similar to [3,8,10], our work focuses on certain weakness common
to many ASG systems. In particular, we focused on a type of attack against
many proposed ASG systems that we call the “allergy attack”. While worm
polymorphism renders ASG systems ineﬀective [3,8], the allergy attack allows
attackers to easily turn the ASG systems (as well as the perimeter defense) into
their agents for inﬂicting harm on the protected network by manipulating the
ASG system so that traﬃc of their choice will be ﬁltered at the perimeter de-
fense of the target network. A vulnerability that turns ASG systems from an
imperfect, but nonetheless harmless defense mechanism into an active threat to
the protected network, is just as damaging to the usability of ASG systems as
(cid:2) The research reported here is supported partially by a grant from the Oﬃce of Naval
Research under contract number N00014-03-1-0705.
D. Zamboni and C. Kruegel (Eds.): RAID 2006, LNCS 4219, pp. 61–80, 2006.
c(cid:1) Springer-Verlag Berlin Heidelberg 2006
62
S.P. Chung and A.K. Mok
compared to the very well addressed issues of worm polymorphism. The scope of
the threat from allergy attacks is also much wider. For worm polymorphism, the
problem is mostly limited to systems that use a single contiguous byte sequence
from worm packets as signatures, and we are starting to see solutions to this
problem. However, allergy attacks are found to be possible against ASG systems
that employ other kinds of signature as well (e.g. [6]).
We note that the problem with allergy attack is similar to the “causative,
indiscriminate availability” attack mentioned in [1]. However, the work in [1]
focuses on the much higher level problem of attacking machine-learning based
security mechanisms in a theoretical setting. While the authors of [1] have pro-
posed many diﬀerent means of abusing a machine-learning based system (e.g.
inducing high false positives, evading detection), our study of allergy attacks is
more speciﬁc on one particular issue, the viability of inducing high false positives
in an ASG system in practice. To demonstrate the practicality of allergy attacks,
we have experimented with one publicly available ASG system, and analyzed the
algorithms of another 8 systems 1. Our work, as presented in this paper comple-
ments the work in [1] by our experimental validation of allergy attacks. Another
subtle diﬀerence between the work in [1] and ours is that while machine learning
algorithms generate classiﬁcation schemes based on a given set of features, ASG
systems generally need to identify these features before applying any machine-
learning technique. As our work and the work in [10] show, the feature extraction
mechanism is an important avenue for attacking ASG systems that’s not found
in purely machine-learning based systems.
With the exception of the study in [1], our literature survey shows that the
threat from allergy attack has received limited attention from the research com-
munity. As far as we can determine from the open literature, resilience against
allergy attack is never a design objective for any published ASG systems. Yet we
believe very strong guarantee on such resilience will be necessary if ASG systems
are to be of any practical use. Our contributions in this paper are two-folded:
1. By deﬁning allergy attack and demonstrating the attack against a typical
ASG system (Autograph), we hope to draw attention to the threat posed by
this type of attack.
2. By presenting our insight on what caused this vulnerability, we wish to help
the design of future ASG systems to be resilient against allergy attacks. An
understanding of what facilitates exploitations of the vulnerability will also
help devising remedies for existing ASG systems.
In the next section, we will deﬁne what an allergy attack is. Then we will
present some related work in Sect. 3. Our demonstration of allergy attack against
Autograph will follow in Sect. 4. We will then describe a more sophisticated kind
1 Courtesy of Professor Wenke Lee, we came upon the paper [1] that has just been
presented on March 21-24, 2006. This paper anticipates theoretically our allergy
attack but does not provide any empirical evidence of the viability of such attacks.
We are also aware that the detraining of machine learning systems has been a serious
concern to designers of military systems.
Allergy Attack Against Automatic Signature Generation
63
of allergy attack, the type II allergy attack in Sect. 5. We believe the type II
attack allows us to defeat many simple defenses against allergy attacks. In Sect.
6, we will present our initial theory on the root of the vulnerability against allergy
attacks, and factors that ease the exploitation of the vulnerability. Finally, we
will conclude in Sect. 7.
2 Deﬁning Allergy Attack
We start our discussions on allergy attack by deﬁning it as follow:
An allergy attack is a denial of service (DoS) attack achieved through
inducing ASG systems into generating signatures that match normal
traﬃc. Thus, when the signatures generated are applied to the perimeter
defense, the target normal traﬃc will be blocked and result in the desired
DoS.
In this work, we focus on the allergy attack against valid requests for services
provided by the attacked network. Upon a successful attack, the signatures gen-
erated will block all instances of the target requests at the perimeter defense,
and make the corresponding service unavailable to the outside world. As will be
seen, it is also possible for the attacker to have very ﬁne grain control over what
services to be attacked (e.g., instead of blocking access to the entire web-site,
the attacker may choose to make only particular pages unavailable).
Since all existing ASG systems work by observing traﬃc on the network, the
only way for the attacker to manipulate vulnerable systems is by presenting them
crafted packets. Packets crafted for an allergy attack should have the following
properties:
1. The packets will be classiﬁed by the vulnerable system as suspicious, and
will be used for signature generation.
2. The packets, when used for signature generation, will result in the desired
signatures being generated.
We note that although it might appear that the problem can be easily solved
by checking new signatures against some corpus of normal traﬃc, this turns
out to be a non-trivial task to be done correctly and eﬃciently. First of all, the
amount of memory needed for a corpus of normal traﬃc can be impractically
high. The time needed to compare a signature against the corpus also makes
this method infeasible. In fact, the experiments in [8] illustrates this point very
well: with a corpus containing 5 days’ worth of HTTP traﬃc, the signature
generation process for a relatively small suspicious pool is reported as “under
ten minutes”. Furthermore, even though many ASG systems employ ways to
eliminate false positives using normal traﬃc observed, most of these systems
remain vulnerable to allergy attack (as we will show in Sect. 6). This is mainly
because the mechanisms employed are designed to tackle “naturally occurring”
false positives, not those intentionally produced by the attackers. Finally, as we
will show in Sect. 5, there is a special kind of allergy attack that evades many
corpus-based countermeasures, including the one mentioned above.
64
S.P. Chung and A.K. Mok
3 Related Work
In this section, we present some mainstream approaches for building ASG sys-
tems. Further details about particular ASG systems will be given in Sect. 4 and
Sect. 6 when we illustrate how to attack those systems.
3.1 String-Matching ASG Systems
Among the proposed ASG systems, many employ simple byte sequence(s) as
signatures [4,5,7,8,11,13,14]. Incoming traﬃc containing the byte sequences (or
a large portion of it) will be considered malicious and dropped. The work of a
string-based ASG system can generally be divided into two parts: ﬁrst, worm
packets are identiﬁed in the monitored traﬃc by some heuristic based approach,
then invariant byte sequences are extracted from these suspicious packets as
worm signatures.
3.2 Other ASG Systems
As many have noted [3,8], instances of polymorphic worms may not have in-
variant byte sequences long enough to be used as reliable signatures. In order
to tackle this problem, some have proposed using other properties of suspicious
packets as signatures. For example, the work in [12] used byte-frequency distri-
bution for contiguous bytes in worm packets as signature. Krugel et al in [6] try
to identify executable payload in worm packets, and extract common properties
in their control-ﬂow graph as worm signatures. Finally, Vigilante [2] extracts pro-
tocol frame values necessary for control hijacking to identify all worms exploiting
the same vulnerability.
3.3 Allergy-Type Attack in the Literature
Even though the allergy attack has not been demonstrated in real systems in
practice, we have found several brief mentioning of this type of attack in the fol-
lowing work [4,11,14]. The most detailed documentation of this potential problem
can be found in [11]. We quote from Singh et al in [11]:
Moreover, automated containment also provokes the issue of attackers
purposely trying to trigger a worm defense - thereby causing denial-of-
service on legitimate traﬃc also carrying the string.
In fact, the work in [11] is the only one that has explicitly mentioned the
possibility of denial-of-service resulting from an allergy-type attack. In [4], the
problem is referred to as “attackers deliberately submit innocuous traﬃc to the
system”, while Yegneswaran et al used the term “intentional data pollution”
in [14]. More importantly, no practical solution has been proposed so far. The
authors of [11] suggested “comparing signatures with existing traﬃc corpus - to
understand the impact of ﬁltering such traﬃc before we do so”, which is infea-
sible due to the amount of time and memory required. Kim et al [4] proposed
Allergy Attack Against Automatic Signature Generation
65
“vetting candidate signatures for false positives among many distributed moni-
tors”, which can be defeated if all the participating sites are attacked in parallel
(a similar approach is used in [13]. We shall present more details of these systems
as well as the corresponding allergy attack in Sect. 6). Finally, Yegneswaran et
al [14] resorts to human sanity check for the signatures, which basically defeats
the purpose of speeding up the signature generation by avoiding human inter-
vention. Furthermore, such sanity check may be infeasible when a large number
of signatures are involved, and signatures resulting from an allergy attack are
mixed with real worm signatures. Also, experience shows that real-world system
administrators will simply turn oﬀ the ASG system if a manual check is required
everytime a signature is generated.
4 Attacking Autograph: A Demonstration
In this section, we shall demonstrate the allergy attack against a real ASG sys-
tem: Autograph. Both the design of our attack against Autograph and the results
of our experiments will be presented. We use Autograph for our experiments be-
cause it is one of the very few ASG systems that we can work on. For other
ASG systems, we either don’t have access to them, or are incapable of collect-
ing a normal traﬃc corpus necessary for their experimentation, due to privacy
issues. Nonetheless, we ﬁnd that Autograph has many properties typical in ASG
systems vulnerable to allergy attacks (e.g. semantic-free signature generation,
purely network-based “worm” detection, etc), and thus is suﬃcient for demon-
strating the feasibility of allergy attacks. We understand that Autograph is a
relatively old system, so we also outline the allergy attacks against some more
recent ASG systems in Sect. 6. To give some background about how Autograph
works, a brief description of Autograph is given in the Appendix.
4.1 Attacking Autograph
Our attack against Autograph is divided into two steps. In the ﬁrst step, we
induce Autograph into classifying the machines we control (our “drones”) as
scanners. In the second step, we simply use the drones to connect to machines in
the protected network, and populate Autograph’s suspicious pool for the target
port with our attack packets. These packets are crafted such that the desired
signatures will be generated when they are used for signature generation. To
ease our discussion in this and the next section, we assume the target traﬃc
to be an HTTP request for a protected web server. We stress once again that
other types of traﬃc can also be targeted, and HTTP requests are chosen only
because it appears to be the most direct way to inﬂict loss to the attacked
organization.
Due to the simple heuristics used by Autograph, the ﬁrst step can be easily
achieved by requesting connections with many random IP addresses. For some
networks, an easier and faster method is available; we can send out TCP con-
nection requests with a combination of ﬂags that never appears in normal traﬃc
66