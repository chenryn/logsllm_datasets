# TLB 缓存延迟刷新漏洞 CVE-2018-18281 解析
|
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
author: [PI:EMAIL](mailto:PI:EMAIL) of IceSword
Lab , Qihoo 360
## 简介
最近, 业内发现了一批内存管理系统的漏洞, project 0 的 [Jann Horn](https://twitter.com/tehjh)
放出了其中一个漏洞 [CVE-2018-18281](https://bugs.chromium.org/p/project-zero/issues/detail?id=1695) 的
[writeup](https://googleprojectzero.blogspot.com/2019/01/taking-page-from-kernels-book-tlb-issue.html), CVE-2018-18281 是一个 linux kernel 的通用漏洞,
这个漏洞的模式比较罕见, 不同于常规的内存溢出类漏洞, 也不是常见的 UAF 漏洞, 它是由内存管理系统的底层逻辑错误导致的, 根本原因是 TLB
缓存没有及时刷新造成虚拟地址复用, 可以实现较为稳定的提权利用.
## TLB
linux 内核通过 [多级页表](https://en.wikipedia.org/wiki/Page_table) 实现虚拟内存机制,
为了提高访问速度, 一些映射信息会被缓存在
[TLB](https://en.wikipedia.org/wiki/Translation_lookaside_buffer) 里, cpu
在访问一个虚拟地址的时候, 会先查找 TLB , 如果没有命中, 才去遍历主存里的多级页表, 并将查找到的映射关系填入 TLB
反过来, 如果某个映射关系要解除, 除了在主存里的相关表项要删除, 还需要对多个cpu core 同步执行 TLB 刷新, 使得在所有 TLB
缓存里该映射关系消除, 否则就会出现不一致.
上述关于 TLB 和内存映射的说明只是简化版本, 用于简单理解这个漏洞的原因, 真正的实现不同操作系统, 不同体系架构, 都不一样. 可以查阅芯片手册, 如
[TLBs, Paging-Structure Caches, and Their
Invalidation](http://kib.kiev.ua/x86docs/SDMs/317080-002.pdf) 和一些分析, 如
[Reverse Engineering Hardware Page Table
Caches](https://www.cs.vu.nl/~herbertb/download/papers/revanc_ir-cs-77.pdf)
## 漏洞
先看两个系统调用
  * [mremap](http://man7.org/linux/man-pages/man2/mremap.2.html) 系统调用用来改变虚拟内存的映射区域
  * [ftruncate](https://linux.die.net/man/2/ftruncate) 系统调用用来改变文件的大小到指定大小
这两个系统调用表面上看八竿子打不着, 但在 linux 内核的实现里, 他们的调用链条会出现一个竞态条件异常
    1) sys_mremap() -> mremap_to()->move_vma()->move_page_tables(). 
    move_page_tables() first calls move_ptes() in a loop, 
    then performs a TLB flush with flush_tlb_range().
    2) sys_ftruncate()->do_sys_ftruncate()->do_truncate()->notify_change()
    ->shmem_setattr()->unmap_mapping_range()->unmap_mapping_range_tree()
    ->unmap_mapping_range_vma() ->zap_page_range_single()->unmap_single_vma()
    ->unmap_page_range()->zap_pud_range()->zap_pmd_range()->zap_pte_range()
    can concurrently access the page tables of a process that is in move_page_tables(), 
    between the move_ptes() loop and the TLB flush.
mremap 底层实现主要是 move_ptes 函数
    89 static void move_ptes(struct vm_area_struct *vma, pmd_t *old_pmd,
    90                 unsigned long old_addr, unsigned long old_end,
    91                 struct vm_area_struct *new_vma, pmd_t *new_pmd,
    92                 unsigned long new_addr, bool need_rmap_locks)
    93 {
    94         struct address_space *mapping = NULL;
    95         struct anon_vma *anon_vma = NULL;
    96         struct mm_struct *mm = vma->vm_mm;
    97         pte_t *old_pte, *new_pte, pte;
    98         spinlock_t *old_ptl, *new_ptl;
    ======================== skip ======================
    133         old_pte = pte_offset_map_lock(mm, old_pmd, old_addr, &old_ptl);
    134         new_pte = pte_offset_map(new_pmd, new_addr);
    135         new_ptl = pte_lockptr(mm, new_pmd);
    136         if (new_ptl != old_ptl)
    137                 spin_lock_nested(new_ptl, SINGLE_DEPTH_NESTING);
    138         arch_enter_lazy_mmu_mode();
    139 
    140         for (; old_addr vm_page_prot, old_addr, new_addr);
    146                 pte = move_soft_dirty_pte(pte);
    147                 set_pte_at(mm, new_addr, new_pte, pte);
    148         }
    149 
    150         arch_leave_lazy_mmu_mode();
    151         if (new_ptl != old_ptl)
    152                 spin_unlock(new_ptl);
    153         pte_unmap(new_pte - 1);
    154         pte_unmap_unlock(old_pte - 1, old_ptl);
    155         if (anon_vma)
    156                 anon_vma_unlock_write(anon_vma);
    157         if (mapping)
    158                 i_mmap_unlock_write(mapping);
    159 }
结合上面代码, 有两点需要注意
  * 锁, 133 ~ 137 这几行目的是获取 pmd (pmd 指针指向一个存满了 pte 结构的页面) 的锁 (包括旧的和新的), 151 ~ 154 这几行是释放 pmd 锁
  * ptes 拷贝, 对一个 pmd 里的所有 pte 执行拷贝操作, 144 这一行调用 ptep_get_and_clear 将 old_pte 的值赋值给临时变量 pte 并清空旧的页表项, 147 这一行调用 set_pte_at 将刚刚的 pte 赋值给 new_pte 指针
简单而言, move_ptes 将旧的 pmd 页的值 ( ptes ) 拷贝到了新的 pmd 页, 这就是 mremap 函数在底层的实现,
它并不需要删除旧地址对应的 pages, 只需要将旧地址关联到的 ptes 拷贝到新地址关联的页表, 这种拷贝是按照 pmd 为单位进行的, 每处理完一个
pmd, 对应的 pmd lock 就会释放.
ftruncate 函数将文件大小变为指定的大小, 如果新的值比旧的值小, 则需要将文件在内存的虚存空间变小, 这需要调用到 zap_pte_range
函数
    1107 static unsigned long zap_pte_range(struct mmu_gather *tlb,
    1108                                 struct vm_area_struct *vma, pmd_t *pmd,
    1109                                 unsigned long addr, unsigned long end,
    1110                                 struct zap_details *details)
    1111 {          
    1112         struct mm_struct *mm = tlb->mm;
    1113         int force_flush = 0;
    1114         int rss[NR_MM_COUNTERS];
    1115         spinlock_t *ptl;
    1116         pte_t *start_pte;
    1117         pte_t *pte;
    1118         swp_entry_t entry;
    1119 
    1120 again:
    1121         init_rss_vec(rss);
    1122         start_pte = pte_offset_map_lock(mm, pmd, addr, &ptl);
    1123         pte = start_pte;
    1124         flush_tlb_batched_pending(mm);
    1125         arch_enter_lazy_mmu_mode();
    1126         do {
    1127                 pte_t ptent = *pte;
    ========================== skip ==========================
    1146                         ptent = ptep_get_and_clear_full(mm, addr, pte,
    1147                                                         tlb->fullmm);
    1148                         tlb_remove_tlb_entry(tlb, pte, addr);
    ========================== skip ==========================
    1176                 entry = pte_to_swp_entry(ptent);
    ========================== skip ==========================
    1185                 if (unlikely(!free_swap_and_cache(entry)))
    1186                         print_bad_pte(vma, addr, ptent, NULL);
    1187                 pte_clear_not_present_full(mm, addr, pte, tlb->fullmm);
    1188         } while (pte++, addr += PAGE_SIZE, addr != end);
    1189 
    1190         add_mm_rss_vec(mm, rss);
    1191         arch_leave_lazy_mmu_mode();
    1192 
    1193         /* Do the actual TLB flush before dropping ptl */
    1194         if (force_flush)
    1195                 tlb_flush_mmu_tlbonly(tlb);
    1196         pte_unmap_unlock(start_pte, ptl);
    ========================== skip ==========================
    1212         return addr;
    1213 }
结合上面代码, 有三点需要注意,
  * 锁, 1122 行获取了 pmd 的锁, 1196 行释放了 pmd 的锁, 这里的 pmd 锁跟 move_ptes 函数里的是同一个东西
  * pte, 1146 行清空了页表项
  * page, 1185 行调用函数 free_swap_and_cache 释放了 pte 对应的 page cache, 将物理页面释放, 这是与 move_ptes 不同的地方
将上述两个函数的流程放到一起分析, 假设下面这种情况:
假设一个进程有 A,B,C 三个线程:
  * 1) A 映射一个文件 a 到地址 X, 映射条件为: PROT_READ , MAP_SHARED