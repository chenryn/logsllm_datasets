with 2x trust? Should we deterministically choose the object
with the most votes, or use randomized recommendation
where the probability is proportional to the number of votes?
Should we take negative votes into account?
The challenge. The above numerous (and subtle) design
alternatives are not simply different “trade-offs”: Because
the end user Alice has only a single objective (minimizing
loss), different designs indeed have different “goodness.”
However, it is simply impossible to exhaustively enumerate
and compare them all. Thus we aim to directly design
a defense with optimal loss. Doing so will answer all
the design questions once and for all. This is also a key
difference between our approach and previous trust-based
recommendation systems [20, 32, 34, 36, 40, 46, 49], where
it is always unclear whether there exist better designs. The
key challenge now, of course, is to design a defense whose
loss is optimal. In the rest of this paper, we will not
extensively explore other design alternatives, though one
should keep in mind that we will prove that no alternatives
are (asymptotically) better.
5. DSybil Recommendation Algorithm
The main component of DSybil’s defense is its optimal
and elegant recommendation algorithm. The algorithm can
be run either by individual users (independent of whether
other users are using DSybil), or by a central server making
recommendations to individual users (where the server will
run different instances for different users). We will later show
that some natural alternatives (or “optimizations”/“tweaks”)
to our algorithm will easily break its optimality. This implies
that achieving the optimality is far from trivial—many of the
design choices in our algorithm are not arbitrary and in fact,
may be necessary for optimality.
We describe the algorithm below in a progressive fashion.
Section 5.1 ﬁrst discusses an algorithm that assumes i) the
total number of sybil identities is M; ii) the values of M,
N0, and D f are known; iii) DSybil recommends, and Alice
consumes, only one object from each round; and iv) Alice
has the same taste as the critical guides. Next, Section 5.2
improves the algorithm so that it can tolerate an unlimited
number of sybil identities, as long as the number of sybil
voters on any given object is bounded within M. Furthermore,
the improved algorithm no longer needs to know M, N0, or
D f . Finally, Section 5.3 shows that the remaining assumptions
can be naturally relaxed as well. For simplicity, our proofs
will assume that if the f -fractional dimension of U is D f ,
then in every round, f fraction of the good objects are guided
(i.e., covered by at least one of the D f critical guides). It is
not difﬁcult to extend our results to weaker but less concise
conditions.
5.1. At Most M Sybil Identities Total
Algorithm description. Our recommendation algorithm
(Figure 2) maintains a real-valued trust, initialized to some
288
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
Figure 1. An example execution of the algorithm in Figure 2 with S = 0.2, c = 1, α = 5, and β = 0. The top two objects in
each round are good, and the bottom two are bad. There are 2 honest identities E and F, and 2 sybil identities G and H. The
ﬁgure annotates which identities vote for which objects, and the trust of those identities. Shaded objects are overwhelming.
Objects pointed to by arrows are recommended objects, consumed by Alice. A random object is recommended in rounds 1–3.
An arbitrary overwhelming object is recommended in rounds 4 and 5.
Make recommendation:
determine which objects are overwhelming;
return an arbitrary overwhelming object if there is one;
otherwise return a uniformly random non-overwhelming obj;
After Alice’s feedback on the recommended object O:
if O is good and if O is non-overwhelming
multiply the trust of all voters for O by α;
if O is bad
multiply the trust of all voters for O by β ;
Figure 2. Recommendation algorithm executed in each round.
Each identity starts with S trust. The parameters satisfy 0  1, and 0 ≤ β  0, for each identity. The algorithm is with
respect to Alice—different Alices will run different instances
of the algorithm and thus have different trust for the same
identity. An object is overwhelming if the total trust of the
identities voting for the object is at least some constant c,
where c > S. If a round has overwhelming objects (called an
overwhelming round), the algorithm simply recommends an
arbitrary overwhelming object; otherwise it recommends a
uniformly random non-overwhelming object. Here “arbitrary”
means that the overwhelming object can be chosen in some
arbitrary way (even adversarially).6 Notice that our (optimal)
algorithm does not further distinguish different overwhelming
objects or different non-overwhelming objects.
Alice then consumes the object and provides feedback. If
the object is good and if the object is non-overwhelming,
the algorithm multiplies the trust of all identities voting
for that object by some constant α > 1. If the object is
bad, the algorithm multiplies the trust by some constant β
where 0 ≤ β 
0, α > 1, and 0 ≤ β < 1. See Corollary 4 for possible values.
Solving the above equations yields the desired results. 2
The above theorem guarantees Alice’s expected loss, where
the expectation is taken over the random coin ﬂips in the
algorithm. It is also possible to prove a high probability
guarantee on the loss, via standard Chernoff bounds [45] on
Gn and (Bn + Gn). We omit the details for space limitations.
We will take β = 0.5 to accommodate guides with non-
exact taste as Alice (Section 5.3). It is possible to ﬁnd the
optimal values for α, S, c. For simplicity, however, we use
α = 2 and S/c = D f /(2M + 2N0), which is sufﬁcient to
achieve the best result asymptotically. Notice that here we
need to know N0, M, and D f in order to properly set S/c.
Corollary 2: Setting α = 2, β = 0.5, and S/c = D f /(2M +
2N0), we have
(cid:18)4(M + N0)
(cid:19)(cid:25)
log2
D f
(2)
(cid:24)
O(cid:0)D f log(M/D f )(cid:1) asymptotically.
E[L] ≤ D f + D f
1 + p
p f
For p and f constants bounded away from 0, this becomes
5.2. At Most M Sybil Voters on Each Object
Algorithm description. Figure 3 presents the improved
algorithm that can tolerate an unlimited number of sybil
identities, as long as the number of sybil identities voting
for any given object is at most M. The part for making
recommendations is the same as in Figure 2 and thus is not
shown. Different from earlier, here each identity starts with
0 trust. If Alice consumes a good non-overwhelming object,
then if there are x voters with 0 trust voting for that object,7
each such voter will be given a seed trust of SΣ/x. Here SΣ
is some positive constant. Notice that our optimal algorithm
does not use any “trial period” for new identities.
Algorithm intuition. Having identities start with 0 trust
is critical for dealing with an unlimited number of sybil
identities (over time), because otherwise even the seed
trust assigned to sybil identities will grow unbounded. The
intuition for giving out seed trust only when Alice consumes
a good non-overwhelming object is similar as before. Namely,
7. When β = 0, a voter with 0 trust may either be an uninitialized voter,
or can be a voter that voted on a bad object. We do not need to distinguish
the two cases.
290
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:54 UTC from IEEE Xplore.  Restrictions apply. 
if the object is overwhelming, then Alice is already getting
“enough help.” Same as before, such design is unavoidably a
double-edged sword, and can prevent guides from obtaining
seed trust.
We will still be able to show that the number of good
non-overwhelming objects consumed (i.e., Gn) is limited.
Thus, the total seed trust given out to sybil identities will
also be limited. Instead of giving each identity the same seed
trust, the algorithm simply enforces a limit SΣ on the total
seed trust given out each time. How exactly to distribute SΣ
to the various voters for the object can be rather ﬂexible. All
we need to ensure is that each critical guide receives some
seed trust that is not too small (without knowing who they
are). Our algorithm in Figure 3 distributes SΣ evenly to all
voters with 0 trust, which ensures that the seed trust of a
critical guide is at least SΣ/(W + M). Here W ≤ N + N0 is
the maximum number of honest users voting on any object.
Notice that by doing so, the algorithm no longer needs to
know the values of N, N0, M, or D f .
Guarantees against the worst-case attack. The guarantees
of the algorithm in Figure 3 can be proved using similar