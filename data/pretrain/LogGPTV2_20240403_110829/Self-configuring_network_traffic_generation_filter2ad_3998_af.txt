6.3 Implications
It is clear that precisely controlled traﬃc streams are use-
ful for Internet RFC conformance testing and for subjecting
network systems to extreme conditions along certain dimen-
sions. However, our experiments demonstrate that a work-
load based on measured characteristics of real Internet traf-
ﬁc generates a fundamentally diﬀerent and more variable
load on routers. Our results suggest ranges of behaviors
that can be expected for given average loads. These ranges
could be used to tune constant bit rate streams to explore an
appropriate operational space. Finally, the subsystem load
variability imposed by Harpoon should provide insights to
system designers on the stresses that these systems might
be subjected to under real operating conditions. This could
inform the allocation of resources in future system designs.
7. CONCLUSIONS AND FUTURE WORK
Harpoon is a new tool for generating representative IP
traﬃc based on eight distributional characteristics of TCP
and UDP ﬂows. Parameters for these distributions can be
automatically extracted from NetFlow data collected from
a live router. These characteristics enable Harpoon to gen-
erate statistically representative traﬃc workloads that are
independent of any speciﬁc application. We are not aware of
any other workload generation tool with this capability. We
implemented Harpoon as a client-server application that can
be used in testbed environments. We parameterized Har-
poon using data collected from a NetFlow trace and from
a set of packet traces and veriﬁed in controlled laboratory
tests that Harpoon generates traﬃc that is qualitatively the
same as the input data.
We demonstrated Harpoon’s utility beyond simple back-
ground traﬃc generation through a series of throughput
tests conducted on a Cisco 6509 router. We compared and
contrasted the workload generated by Harpoon with the con-
stant bit rate workloads recommended for standard tests.
We found that Harpoon generated similar results for overall
throughput, but that the stresses placed on router subsys-
tems by Harpoon during these tests were signiﬁcantly dif-
ferent. These results suggest that (in addition to the back-
ground traﬃc generation) Harpoon could be useful as a tool
for providing network hardware designers and network oper-
ators insight into how systems might behave under realistic
traﬃc conditions.
An area for future work is to extend our parameterization
tools and model to accommodate sampled ﬂow records and
the absence of TCP ﬂags. We also intend to augment the
UDP traﬃc model to enable a broader set of UDP traﬃc
(a) Packet forwarding rate time series for
Harpoon and the constant spacing packet
generator.
(b) Average forwarding rates using diﬀer-
ent burst sizes for the constant spacing traf-
ﬁc generator. Conﬁguration is 215 entries
in forwarding table and high oﬀered load.
Harpoon results for 215 forwarding table en-
tries and high oﬀered load shown for com-
parison. Vertical bars span one standard
deviation above and below the mean.
(c) Average forwarding rates using diﬀer-
ent packet sizes for constant spacing packet
Conﬁguration is 215 entries
generator.
in forwarding table and high oﬀered load.
Harpoon results for 215 forwarding table en-
tries and high oﬀered load shown for com-
parison. Vertical bars span one standard
deviation above and below the mean.
Figure 12: Qualitative contrast of forwarding rates between Harpoon and the constant spacing traﬃc gener-
ator, and comparisons of forwarding rates between Harpoon and the constant spacing traﬃc generator using
diﬀerent burst lengths and packet sizes.
(a) Low Oﬀered Load
(b) High Oﬀered Load
Figure 13: Average forwarding rates for Harpoon and the constant spacing traﬃc generator for diﬀerent
router forwarding table sizes. Vertical bars span one standard deviation above and below the mean.
characteristics. Finally, Harpoon assumes all sources are
well behaved, which is far from the case in the Internet. We
intend to pursue creation of traﬃc anomaly models that can
be incorporated into the Harpoon framework.
8. ACKNOWLEDGMENTS
Thanks to Dave Plonka at the University of Wisconsin for
helpful discussions regarding Netﬂow, and to Spirent Com-
munications for use of the AX/4000 system. We also thank
the anonymous reviewers and our shepherd, Anja Feldmann,
for constructive criticism.
This material is based upon work supported by the Na-
tional Science Foundation under Grant No. 0335234 and by
support from Cisco Systems. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this material
are those of the authors and do not necessarily reﬂect the
views of the National Science Foundation or Cisco Systems.
9. REFERENCES
[1] Catalyst 6500 series switches. http://www.cisco.com/univer-
cd/cc/td/doc/product/lan/cat6000/index.htm. Accessed
August 2004.
[2] Cisco’s IOS Netﬂow feature.
http://www.cisco.com/warp/public/732/netﬂow. Accessed
August 2004.
[3] CoralReef: Passive network traﬃc monitoring and statistics
collection. http://www.caida.org/tools/measurement/coralreef.
Accessed August 2004.
[4] Endace measurement systems. http://www.endace.com/.
Accessed August 2004.
[5] The eXpat XML parser. http://expat.sourceforge.net. Accessed
August 2004.
[6] The iperf TCP/UDP Bandwidth Measurement Tool.
http://dast.nlanr.net/Projects/Iperf. Accessed August 2004.
[7] Netﬂow services solutions guide (Netﬂow white paper).
http://www.cisco.com/univercd/cc/td/doc/cisintwk/-
intsolns/netﬂsol/nfwhite.htm. Accessed August
2004.
[8] Spirent Communications Inc. Adtech AX/4000 broadband test
system. http://www.spirentcom.com/analysis/pro-
duct line.cfm?pl=1&WS=173&wt=2. Accessed August
2004.
[9] SSFnet network simulator. http://www.ssfnet.org. Accessed
August 2004.
[10] The University of New Hampshire Interoperability Laboratory.
http://www.iol.unh.edu. Accessed August 2004.
[11] The Wisconsin Advanced Internet Laboratory.
http://wail.cs.wisc.edu. Accessed August 2004.
[12] UCB/LBNL/VINT Network Simulator - ns (version 2).
http://www.isi.edu/nsnam/ns. Accessed August 2004.
[13] Web polygraph. http://www.web-polygraph.org. Accessed
August 2004.
[14] Workshop on models, methods and tools for reproducible
network research. http://www.acm.org/sigs/-
sigcomm/sigcomm2003/workshop/mometools, 2003.
[15] XML-RPC home page. http://www.xmlrpc.org. Accessed
August 2004.
[16] P. Abry and D. Veitch. Wavelet analysis of long range
dependent traﬃc. IEEE Transactions on Information Theory,
44(1):2–15, 1998.
800Mbps600Mbps400Mbps 0 300 600 900 1200 1500 1800avg bits per second (bps)time (seconds)HarpoonConstant Spacing Generator1Gbps800Mbps600Mbps9306974651forwarding rate (bits per second)burst size (packets)HarpoonConstant Spacing Generator1Gbps800Mbps600Mbps40 bytemultiple1500 byteforwarding rate (bits per second)generated packet sizesHarpoonConstant Spacing Generator1Gbps800Mbps600Mbps6553632768102432forwarding rate (bits per second)routing table sizeHarpoonConstant Spacing Generator1Gbps800Mbps600Mbps6553632768102432forwarding rate (bits per second)routing table sizeHarpoonConstant Spacing Generator(a) Packet Loss Rate
(b) Output Channel Fabric Utilization
Figure 14: Packet loss rates and switch fabric utilization using 215 forwarding table entries and high oﬀered
load. Results shown for Harpoon, constant spacing generator with uniformly spaced packets of 1500 bytes,
bursts of 697 packets of 1500 bytes, and uniformly spaced packets of 40 bytes.
[17] C. Barakat, P. Thiran, G. Iannaccone, C. Diot, and
P. Owezarski. Modeling Internet backbone traﬃc at the ﬂow
level. IEEE Transactions on Signal Processing (Special Issue
on Networking), August 2003.
[18] P. Barford and M. Crovella. Generating representative
workloads for network and server performance evaluation. In
Proceedings of ACM SIGMETRICS ’98, pages 151–160,
Madison, WI, June 1998.
[19] P. Barford and M. Crovella. A performance evaluation of hyper
text transfer protocols. In Proceedings of ACM SIGMETRICS
’99, Atlanta, GA, May 1999.
[20] S. Bradner. Benchmarking terminology for network
interconnect devices. IETF RFC 1242, July 1991.
[21] S. Bradner and J. McQuaid. Benchmarking methodology for
network interconnect devices. IETF RFC 2544, March 1999.
[22] T. Bu and D. Towsley. Fixed point approximation for TCP
behavior in an AQM network. In Proceedings of ACM
SIGMETRICS ’01, San Diego, CA, June 2001.
[23] Y.-C. Cheng, U. H¨olzle, N. Cardwell, S. Savage, and G. M.
Voelker. Monkey see, monkey do: A tool for TCP tracing and
replaying. In Proceedings of the USENIX 2004 Conference,
June 2004.
[24] K. Claﬀy, G. Polyzos, and H.-W. Braun. Internet traﬃc ﬂow
proﬁling. Technical Report TR-CS93-328, University of
California San Diego, November 1989.
[25] W. Cleveland, D. Lin, and D.Sun. IP packet generation:
Statistical models for TCP start times based on connection rate
superposition. In Proceedings of ACM SIGMETRICS ’00,
Santa Clara, CA, June 2000.
[26] M. Crovella and A. Bestavros. Self-similarity in World Wide
Web traﬃc: Evidence and possible causes. IEEE/ACM
Transactions on Networking, 5(6):835–846, December 1997.
[27] N. Duﬃeld, C. Lund, and M. Thorup. Estimating ﬂow
distributions from sampled ﬂow statistics. In Proceedings of
ACM SIGCOMM ’03, Karlsruhe, Germany, August 2003.
[28] A. Feldmann, A. Gilbert, P. Huang, and W. Willinger.
Dynamics of IP traﬃc: A study of the role of variability and
the impact of control. In Proceedings of ACM SIGCOMM ’99,
Boston, MA, August 1999.
[29] A. Feldmann, A. Gilbert, and W. Willinger. Data networks as
cascades: Investigating the multifractal nature of Internet WAN
traﬃc. In Proceedings of ACM SIGCOMM ’98, August 1998.
[30] S. Floyd and E. Kohler. Internet research needs better models.
In Hotnets-I, Princeton, NJ, October 2002.
[31] S. Floyd and V. Paxson. Diﬃculties in simulating the Internet.
IEEE/ACM Transactions on Networking, 9(4), August 2001.
[32] M. Fomenkov, K. Keys, D. Moore, and K. Claﬀy. Longitudinal
study of Internet traﬃc from 1998-2001: a view from 20 high
performance sites. Technical report, Cooperative Association
for Internet Data Analysis (CAIDA), 2002.
[33] N. L. for Applied Network Research.
http://moat.nlanr.net/Datacube. Accessed August 2004.
[34] C. Fraleigh, S. Moon, B. Lyles, C. Cotton, M. Khan, D. Moll,
R. Rockell, T. Seely, and C. Diot. Packet-level traﬃc
measurements from the Sprint IP backbone. IEEE Network,
2003.
[35] S. Fredj, T. Bonald, A. Proutiere, G. Regnie, and J. Roberts.
Statistical bandwidth sharing: A study of congestion at ﬂow
level. In Proceedings of ACM SIGCOMM ’01, San Diego, CA,
August 2001.
[36] M. Fullmer and S. Romig. The OSU ﬂow-tools package and
Cisco NetFlow logs. In Proceedings of the USENIX Fourteenth
System Administration Conference LISA XIV, New Orleans,
LA, December 2000.
[37] S. Jin and A. Bestavros. GISMO: Generator of Streaming
Media Objects and Workloads. Performance Evaluation
Review, 29(3), 2001.
[38] W. Leland, M. Taqqu, W. Willinger, and D. Wilson. On the
self-similar nature of Ethernet traﬃc (extended version).
IEEE/ACM Transactions on Networking, pages 2:1–15, 1994.
[39] R. Mandeville. Benchmarking terminology for LAN switching
devices. IETF RFC 2285, February 1998.
[40] R. Mandeville and J. Perser. Benchmarking methodology for
LAN switching devices. IETF RFC 2889, August 2000.
[41] D. Newman, G. Chagnot, and J. Perser. Internet core router
test. http://www.lightreading.com/document.asp?site=test-
ing&doc id=4009, March 2001. Accessed August
2004.
[42] K. Park and W. Willinger. Self-Similar Network Traﬃc and
Performance Evaluation. Wiley Interscience, 2000.
[43] V. Paxson. Measurements and Analysis of End-to-End
Internet Dynamics. PhD thesis, University of California
Berkeley, 1997.
[44] V. Paxson and S. Floyd. Wide-area traﬃc: The failure of
poisson modeling. IEEE/ACM Transactions on Networking,
3(3):226–244, June 1995.
[45] D. Plonka. Flowscan: A network traﬃc ﬂow reporting and
visualization tool. In Proceedings of the USENIX Fourteenth
System Administration Conference LISA XIV, New Orleans,
LA, December 2000.
[46] A. Turner. tcpreplay. http://tcpreplay.sourceforge.net/.
Accessed August 2004.
[47] S. Uhlig. Simulating interdomain traﬃc at the ﬂow level.
Technical Report Infonet-TR-2001-11, University of Namur,
Institut d’ Informatique, 2001.
[48] A. Vahdat, K. Yocum, K. Walsh, P. Mahadevan, D. Kostic,
J. Chase, and D. Becker. Scalability and accuracy in a
large-scale network emulator. In Proceedings of 5th Symposium
on Operating Systems Design and Implementation (OSDI),
Boston, MA, December 2002.
[49] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad,
M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An
integrated experimental environment for distributed systems
and networks. In Proceedings of 5th Symposium on Operating
Systems Design and Implementation (OSDI), Boston, MA,
December 2002.
[50] W. Willinger, M. Taqqu, R. Sherman, and D. Wilson.
Self-similarity through high-variability: Statistical analysis of
Ethernet LAN traﬃc at the source level. IEEE/ACM
Transactions on Networking, 5(1):71–86, February 1997.
[51] M. Yajnik, S. Moon, J. Kurose, and D. Towsley. Measurement
and modeling of temporal dependence in packet loss. In
Proceedings of IEEE INFOCOM ’99, New York, NY, March
1999.
 0 5 10 15 20 25 0 60 120 180 240 300packet loss rate (%)time (seconds)HarpoonConstant Spacing Generator (1500 byte packets)Constant Spacing Generator (697 pkt bursts)Constant Spacing Generator (40 byte packets) 0 5 10 15 20 25 0 60 120 180 240 300switch fabric utilization (%)time (seconds)HarpoonConstant Spacing Generator (1500 byte packets)Constant Spacing Generator (697 pkt bursts)Constant Spacing Generator (40 byte packets)