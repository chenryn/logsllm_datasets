# Understanding Precision in Host-Based Intrusion Detection: Formal Analysis and Practical Models

**Authors:**  
Monirul I. Sharif, Kapil Singh, Jonathon T. Giffin, and Wenke Lee  
School of Computer Science, Georgia Institute of Technology  
{msharif, ksingh, giffin, wenke}@cc.gatech.edu

## Abstract
Many host-based anomaly detection systems monitor process execution at the granularity of system calls. Recently, alternative schemes have been proposed to verify the destinations of control-flow transfers, thereby preventing the execution of attack code. This paper formally analyzes and compares real systems based on these two anomaly detection philosophies in terms of their attack detection capabilities. We prove that for any system-call sequence model, there always exists a more precise control-flow sequence based model under the same (static or dynamic) program analysis technique. While hybrid approaches combining system calls and control flows intuitively seem advantageous, especially when binary analysis constructs incomplete models, we prove that they have no fundamental advantage over simpler control-flow models. Finally, we utilize our framework to make external monitoring feasible at the precise control-flow level. Our experiments show that external control-flow monitoring imposes performance overhead comparable to previous system call-based approaches while detecting synthetic and real-world attacks as effectively as an inlined monitor.

**Keywords:** Anomaly detection, formal analysis, program models.

## 1. Introduction
Over the years, researchers have developed numerous host-based intrusion detection systems (IDSs) utilizing a variety of mechanisms. Most systems, such as [11, 29, 9, 10, 17, 16, 12, 27], model an application’s normal system call usage and use run-time monitoring to detect attacks that deviate from this model. Although useful attacks typically require system calls, they provide only a coarse view of a process' execution. Mimicry attacks [32, 21] can cloak an attack by generating valid system call sequences, demonstrating that attackers may exploit this coarseness. System-call-based detectors also detect attacks well after execution is diverted—at best at the next system call invocation. Monitors verifying system call usage are often implemented as external processes, which simplifies implementation, debugging, and data protection.

Recently, alternative schemes have been proposed that detect attacks when they divert control flow. Control Flow Integrity (CFI) [5], a static analysis-based system, efficiently verifies dynamically computed control-flow targets in the program. CFI guarantees [6] that the execution path will be restricted to the statically generated control flow graph (CFG) of the program, thus detecting and stopping attacks involving illegal control transfers. Unlike external monitors that verify a process’ system call use, CFI inlines its checks into the existing code of a program. While inlining complicates monitor development, debugging, and application to arbitrary binary code, it offers exceptional performance when verifying fine-grained control flow operations.

Speculation about these systems’ designs leads to several intuitive conclusions:
- Control-flow-based models can provide better attack detection than system-call-based models.
- A hybrid model combining control-flow and system-call operations better detects attacks than a control-flow-based model alone, particularly if static program analysis incompletely identifies control-flows requiring verification code.
- An external monitor cannot efficiently verify control-flow operations.

In this paper, we formally prove the first intuition, disprove the second, and provide experimental evidence against the third. Our goal is to provide clarity to host-based intrusion detection systems research.

To understand the strengths and weaknesses of these anomaly detection schemes, we provide a formal framework to analyze their precision in terms of how closely they can model a program’s normal execution. We first show that for any given system-call sequence model derived from any program analysis technique (static vs. dynamic), there always exists a more precise control-flow sequence based model. Such a control-flow-based model can precisely match the normal execution behavior of the program, significantly limiting mimicry attacks that plagued system-call-based intrusion detectors.

Control-flow sequence-based intrusion detectors require the identification of security-critical control flows in a program. A system using static program analysis to identify such control flows may incompletely analyze the program’s code due to undecidable problems in static analysis [25]. As a result, a program may contain unchecked control flows. System-call sequence-based intrusion detectors face no such shortcomings, as they can completely mediate the system call interface without complete program analysis. Intuitively, we expect hybrid systems combining control flow verification with system call verification, such as PAID [23], to provide better security than control-flow-based systems alone. If an attacker breaks out of control-flow checks due to a missed control flow, they can still be detected by the system call checks. Using our framework, we prove that even if static analysis is incomplete, hybrid models are not more precise than control-flow models. With appropriate control-flow checks in place, system call checks are redundant and could be removed for model simplification and improved performance.

Finally, we provide experimental evidence against the intuition that efficient enforcement of fine-grained control-flow models can only occur with an inlined monitor. For a fair comparison between the performance overhead of system call and control-flow-based approaches, we have implemented an efficient external control-flow-based IDS. Using principles developed in our analysis of system-call and control-flow-based systems, we apply program transformation to reduce the number of control-flow events exposed to the monitor and improve performance without sacrificing precision. The performance overhead introduced by our detection system, ranging from 1% to 23%, is comparable to previous external system call monitoring. The results also show that our external control-flow monitor can detect a wide range of synthetic and real attacks.

Our current formal framework considers the sequence in which control flows and system calls are executed. As future work, our analysis will incorporate the notion of data to cover approaches that can detect data-only attacks such as program variable or system-call argument manipulation.

## 2. Related Work
The search for defensive techniques to detect application-level attacks has led to a rich research area. We consider examples of host-based anomaly detection systems that characterize normal program execution with a language of allowed event sequences. System calls predominantly form the basis of these events, although recent work has developed new models based on finer-grained control-flow information. Since a primary aim of this paper is to provide illumination of the differences among these model types, we also review previous work in formal analysis of sequence-based models.

Numerous prior systems detect application-level attacks by observing process execution at the granularity of system calls [9, 14, 15, 20, 26, 30, 31, 16, 13, 27]. Rather than directly detecting the execution of malicious code, these tools attempt to detect attacks through the secondary effect of the malicious code or inputs upon the system call sequences executed by the process. By allowing attack code to execute, these secondary detectors provide attackers with opportunities to evade detection. Mimicry attacks [32, 28, 18] succeed by appearing normal to a system-call sequence-based detector. System call models have grown in complexity to address mimicry attacks but remain vulnerable because they allow invalid control flows to execute [21]. We note that our paper does not consider non-sequence aspects of system call models, such as characterizations of expected argument values [7, 22].

Control-flow-based techniques [5, 34] detect various code execution attacks by verifying the destinations of control-flow transfers. Abadi et al. [5] developed Control Flow Integrity (CFI), a recent implementation of control-flow verification. CFI constrains allowed process execution to a model of valid control-flow transfers defined by the program’s static control-flow graph (CFG). CFI uses binary rewriting to place instructions immediately before dynamically computed control-flow instructions for inlined verification of the destination of the transfer. An attacker cannot escape the inlined checks [6] because the static source code analysis or hinted binary analysis can completely identify the set of control transfer points in the program. In this paper, we generalize the idea of CFI to any control-flow-based model, including models constructed from training, containing path sensitivity, or resulting from incomplete binary analysis.

Given two different classes of sequence-based models, those using system calls and those using control flows, we aim to reason about their attack detection ability. Formal analysis has been previously applied to host-based intrusion detection. Wagner and Dean developed a precision metric called average branching factor (ABF) [31], but this metric is specific to system-call models and cannot be adapted to models of control flow. Chen and Wagner [8] and Giffin et al. [18] use model-checking to find allowed sequences of events in system-call models that execute attack behavior. As with ABF, those tools cannot be adapted to also reason about control-flow models. Gao et al. [12] provided a systematic way of comparing various system call models by organizing them in three axes of design space. This establishes a relation between dynamically and statically constructed system call models but provides no mechanism to compare system call models with control-flow models. Our formalization not only provides the means to directly compare system-call models with control-flow models but also provides insight into what affects the precision of control-flow models.

Although the primary intent of this paper is to provide a comparative analysis of system-call and control-flow-based models, we additionally consider environments where a hybrid model containing both sets of events may be advantageous. Xu et al. [33] insert waypoints into program code, but these waypoints are not used to verify all computed transfers. PAID [23] inserts notify system calls before indirect function calls so that the monitor can correctly follow indirect control flows. Recent improvements [24] apply this technique to binaries and also incorporate return address checking. We show that hybrid approaches do not provide fundamentally more attack detection capability than control-flow-based approaches, even in the case of incomplete program analysis. We also implement an external monitoring-based control-flow intrusion detection. We generate the events visible to an external monitor via insertion of null system calls or software interrupts. The Dyck model [17] uses similar code instrumentation techniques. However, the monitor enforcing a Dyck model uses null call events to improve efficiency, not security. In this paper, we use a mechanism similar to null calls for secure exposure of a process’ control-flow behavior.

## 3. Formal Framework for Analyzing Precision
The intrusion detection capability of an IDS is limited by the set of program-generated events visible to it for modeling and monitoring. To compare the attack detection capabilities, it is worthwhile to analyze the relative abilities of recent approaches in terms of how precisely they can represent the underlying normal behavior of the program they try to enforce. Although our framework enables formal analysis of models comprising any event, we focus on system calls and control-flow transfers. We develop definitions so that they can be applied to both statically and dynamically generated models. We present a control-flow sequence-based IDS model, which is more precise than any system call sequence-based model representing the same valid program execution behavior. This model can precisely represent a program’s execution but requires the exposure of all control-flow events in a program. In Section 4, simplified derivations of this model are used to analyze the precision of practical control-flow-based approaches.

### 3.1. Abstract Model of Execution Sequences
Our abstract model considers the sequence in which code is executed. The smallest unit of executed code is a machine instruction, which can be uniquely identified by its address in memory. Therefore, an execution sequence can be represented as a sequence of addresses from where instructions are executed. Without loss of generality, we consider a coarser basic block unit of execution. A basic block is an ordered set of instructions that are executed in sequence as a unit; execution enters only at the start of the block and exits only at the end. The address of the first instruction uniquely identifies a basic block in memory. Basic blocks can also be used to represent high-level statements, making our analysis applicable in the context of both source code and binaries.

Our abstract models of execution are built on sequences of basic blocks executed by a running program. For a program \( P \), let \( B_v \) denote the complete set of basic blocks in \( P \) that can be executed during some valid execution. We use the term "valid" and "normal" interchangeably throughout the paper because, from the point of view of an anomaly detector, anything deemed normal is considered valid. Figure 1 lists an example program and the basic blocks in its set \( B_v \). Let \( B_f \) be the set of all basic blocks that may be feasibly executed in any run of the program. Note that feasible execution differs from valid execution and includes blocks belonging to the program, unknown blocks containing code maliciously introduced into \( P \)'s address space, and blocks generated by disassembling from the middle of instructions belonging to the program. Clearly, \( B_v \subseteq B_f \). We next present the abstract models of valid and feasible execution, which are languages over the sets of program points \( B_v \) and \( B_f \), respectively.

#### The Language of Valid Execution
The language of valid execution \( E_v \subseteq B_v^* \) contains all sequences of basic blocks from \( B_v \) that denote valid execution behavior of \( P \). The actual sequences contained in \( E_v \) depend upon the algorithms used to compute a program’s valid behavior; our framework is general and suitable for any algorithm able to generate \( E_v \). For example, static and dynamic analysis each produce differing characterizations of valid behavior \( E_v \). In the domain of static analysis, different approaches produce models having different sensitivities to program behavior [9]. Dynamic analysis approaches may consider paths that seem valid from the program’s static view as invalid. Our framework derives control-flow and system-call sequences from any given \( E_v \). Therefore, our method of comparing precision is orthogonal to the choice of method used to generate the abstract model of valid execution \( E_v \).

Figure 2 shows two different languages \( E_v \) constructed from typical static analysis and dynamic analysis of the example program. The shaded boxes highlight where the sequences differ. Note that the example program has correlated execution between the direction of the if branch in main and the target of the indirect jump at \( B_7 \). The \( E_v \) constructed from context-sensitive static analysis has four possible execution sequences and fails to characterize the correlated execution. However, the dynamically constructed model contains only two sequences because the correlation occurring in actual execution carries over to the observed execution sequences.

#### The Language of Feasible Execution
The language \( E_f \subseteq B_f^* \) represents all feasible execution sequences of code in \( B_f \) that \( P \)'s execution can generate. Again, feasible execution need not be valid execution.