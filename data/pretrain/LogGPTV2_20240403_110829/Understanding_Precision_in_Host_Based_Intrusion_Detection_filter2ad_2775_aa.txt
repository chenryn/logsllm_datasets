title:Understanding Precision in Host Based Intrusion Detection
author:Monirul I. Sharif and
Kapil Singh and
Jonathon T. Giffin and
Wenke Lee
Understanding Precision in Host Based Intrusion
Detection
Formal Analysis and Practical Models
Monirul Sharif, Kapil Singh, Jonathon Gifﬁn, and Wenke Lee
School of Computer Science, Georgia Institute of Technology
{msharif,ksingh,giffin,wenke}@cc.gatech.edu
Abstract. Many host-based anomaly detection systems monitor process execu-
tion at the granularity of system calls. Other recently proposed schemes instead
verify the destinations of control-ﬂow transfers to prevent the execution of attack
code. This paper formally analyzes and compares real systems based on these
two anomaly detection philosophies in terms of their attack detection capabilities,
and proves and disproves several intuitions. We prove that for any system-call se-
quence model, under the same (static or dynamic) program analysis technique,
there always exists a more precise control-ﬂow sequence based model. While hy-
brid approaches combining system calls and control ﬂows intuitively seem advan-
tageous, especially when binary analysis constructs incomplete models, we prove
that they have no fundamental advantage over simpler control-ﬂow models. Fi-
nally, we utilize the ideas in our framework to make external monitoring feasible
at the precise control-ﬂow level. Our experiments show that external control-ﬂow
monitoring imposes performance overhead comparable to previous system call
based approaches while detecting synthetic and real world attacks as effectively
as an inlined monitor.
Keywords: Anomaly detection, Formal analysis, Program models.
1 Introduction
Over the years, researchers have developed an abundance of host-based intrusion detec-
tion systems, utilizing a variety of mechanisms. Most systems, e.g. [11,29,9,10,17,16,
12,27], model an application’s normal system call usage and use run-time monitoring to
detect attacks that cause behavior deviating from the model. While useful attacks typi-
cally require system calls, they provide only a coarse view of a process’ execution. The
existence of mimicry attacks [32,21] that cloak an attack by generating valid sequences
demonstrates that attackers may exploit this coarse view. System-call based detectors
have another drawback in that they detect attacks well after execution is diverted—at
best at the next system call invocation. Monitors verifying system call usage are often
implemented as an external process, which eases implementation, debugging, and data
protection.
Recently proposed schemes take an alternative approach that detects attacks when
they divert control ﬂow. CFI [5], a static analysis based system, efﬁciently veriﬁes dy-
namically computed control-ﬂow targets in the program. It guarantees [6] that the exe-
cution path will be restricted to the statically generated control ﬂow graph (CFG) of the
program, and it can thus detect and stop attacks involving illegal control transfers. In
C. Kruegel, R. Lippmann, and A. Clark (Eds.): RAID 2007, LNCS 4637, pp. 21–41, 2007.
c(cid:2) Springer-Verlag Berlin Heidelberg 2007
22
M. Sharif et al.
contrast to external monitors verifying a process’ system call use, CFI inlines its checks
into the existing code of a program. While inlining complicates monitor development,
debugging, and application to arbitrary binary code, it offers exceptional performance
when verifying ﬁne-grained control ﬂow operations.
Speculation about these systems’ designs leads to several intuitive conclusions:
– Control-ﬂow based models can provide better attack detection than system-call
based models.
– A hybrid model combining control-ﬂow operations and system-call operations bet-
ter detects attacks than a control-ﬂow based model alone, particularly in the event
that static program analysis incompletely identiﬁes control-ﬂows requiring veriﬁ-
cation code.
– An external monitor cannot efﬁciently verify control-ﬂow operations.
In this paper, we formally prove the ﬁrst intuition, disprove the second, and provide
experimental evidence against the third. Our goal is to provide clarity to host-based
intrusion detection systems research.
In order to understand the strengths and weaknesses or limitations of these anomaly
detection schemes, we provide a formal framework to analyze their precision in terms
of how close they can model a program’s normal execution. We ﬁrst show that for any
given system-call sequence based model derived from any program analysis technique
(static vs dynamic), there always exists a more precise control-ﬂow sequence based
model. Such a control-ﬂow based model can precisely match the normal execution be-
havior of the program from which it was derived, considerably limiting mimicry attacks
that plagued system-call based intrusion detectors.
Control-ﬂow sequence based intrusion detectors require the identiﬁcation of
security-critical control ﬂows in a program. A system using static program analysis to
identify such control ﬂows may incompletely analyze the program’s code due to unde-
cidable problems in static analysis [25]. As a result, a program may contain unchecked
control ﬂows. System-call sequence based intrusion detectors face no such shortcom-
ing, as they can completely mediate the system call interface without complete program
analysis. Intuitively, we expect hybrid systems combining control ﬂow veriﬁcation with
system call veriﬁcation, such as PAID [23] to provide better security than control-ﬂow
based systems alone. If an attacker breaks out of control-ﬂow checks due to a missed
control ﬂow, they can still be detected by the system call checks. Using our framework,
we prove that even if static analysis is incomplete, hybrid models are not more pre-
cise than control-ﬂow models. With appropriate control-ﬂow checks in place, system
call checks are redundant and could be removed for model simpliﬁcation and improved
performance.
Finally, we provide experimental evidence against the intuition that efﬁcient enforce-
ment of ﬁne-grained control-ﬂow models can only occur with an inlined monitor. For
a fair comparison between the performance overhead of system call and control-ﬂow
based approaches, we have implemented an efﬁcient external control-ﬂow based IDS.
Using principles developed in our analysis of system-call and control-ﬂow based sys-
tems, we apply program transformation to reduce the number of control-ﬂows events
exposed to the monitor and improve performance without sacriﬁcing precision. The
performance overhead introduced by our detection system, ranging from 1% to 23%, is
comparable to previous external system call monitoring. The results also show that our
external control-ﬂow monitor can detect a wide range of synthetic and real attacks.
Understanding Precision in Host Based Intrusion Detection
23
Our current formal framework considers the sequence in which control ﬂows and
system calls are executed. As future work, our analysis will incorporate the notion of
data in order to cover approaches that can detect data-only attacks such as program
variable or system-call argument manipulation.
2 Related Work
The search for defensive techniques that can detect application-level attacks has led to a
rich research area. We consider examples of host-based anomaly detection systems that
characterize normal program execution with a language of allowed event sequences.
System calls predominantly form the basis of these events, although recent work has
developed new models based upon ﬁner-grained control-ﬂow information. Since a pri-
mary aim of this paper is to provide illumination of the differences among these model
types, we also review previous work in formal analysis of sequence-based models.
Numerous prior systems detect application-level attacks by observing process ex-
ecution at the granularity of system calls [9, 14, 15, 20, 26, 30, 31, 16, 13, 27]. Rather
than directly detecting the execution of malicious code, these tools attempt to detect
attacks through the secondary effect of the malicious code or inputs upon the system
call sequences executed by the process. By allowing attack code to execute, these sec-
ondary detectors provide attackers with opportunities to evade detection. Mimicry at-
tacks [32,28,18] succeed by appearing normal to a system-call sequence based detector.
System call models have grown in complexity to address mimicry attacks, but remain
vulnerable because they allow invalid control ﬂows to execute [21]. We note that our
paper does not consider non-sequence aspects of system call models, such as character-
izations of expected argument values [7, 22].
Control-ﬂow based techniques [5, 34] detect various code execution attacks by ver-
ifying destinations of control-ﬂow transfers. Abadi et al. [5] developed Control Flow
Integrity (CFI), a recent implementation of control-ﬂow veriﬁcation. CFI constrains
allowed process execution to a model of valid control-ﬂow transfers deﬁned by the pro-
gram’s static control-ﬂow graph (CFG). CFI uses binary rewriting to place instructions
immediately before dynamically computed control-ﬂow instructions for inlined veriﬁ-
cation of the destination of the transfer. An attacker cannot escape the inlined checks [6]
because the static source code analysis or hinted binary analysis can completely identify
the set of control transfer points in the program. In this paper, we generalize the idea
of CFI to any control-ﬂow based model, including models constructed from training,
containing path sensitivity or resulting from incomplete binary analysis.
Given two different classes of sequence-based models, those using system calls and
those using control ﬂows, we aim to reason about their attack detection ability. For-
mal analysis has been previously applied to host-based intrusion detection. Wagner and
Dean developed a precision metric called average branching factor (ABF) [31], but this
metric is speciﬁc to system-call models and cannot be adapted to models of control
ﬂow. Chen and Wagner [8] and Gifﬁn et al. [18] use model-checking to ﬁnd allowed
sequences of events in system-call models that execute attack behavior. As with ABF,
those tools cannot be adapted to also reason about control-ﬂow models. Gao et al. [12]
provided a systematic way of comparing various system call models by organizing them
in three axes of design space. This establishes a relation between dynamically and sta-
tically constructed system call models, but provides no mechanism to compare system
24
M. Sharif et al.
call models with control-ﬂow models. Our formalization not only provides the means
to directly compare system-call models with control-ﬂow models, but also provides
insight into what effects the precision of control-ﬂow models.
Although the primary intent of this paper is to provide a comparative analysis of
system-call and control-ﬂow based models, we additionally consider environments
where a hybrid model containing both sets of events may be advantageous. Xu et al. [33]
insert waypoints into program code, but these waypoints are not used to verify all com-
puted transfers. PAID [23] inserts notify system calls before indirect function calls so
that the monitor can correctly follow indirect control ﬂows. Recent improvements [24]
apply this technique to binaries and also incorporate return address checking. We show
that hybrid approaches do not provide fundamentally more attack detection capability
than control-ﬂow based approaches even in the case of incomplete program analysis.
We also implement an external monitoring based control-ﬂow intrusion detection.
We generate the events visible to an external monitor via insertion of null system calls
or software interrupts. The Dyck model [17] uses similar code instrumentation tech-
niques. However, the monitor enforcing a Dyck model uses null call events to improve
efﬁciency, not security. In this paper, we use a mechanism similar to null calls for secure
exposure of a process’ control-ﬂow behavior.
3 Formal Framework for Analyzing Precision
The intrusion detection capability of an IDS is limited by the set of program generated
events visible to it for modeling and monitoring. In order to compare the attack detec-
tion capabilities, it is worthwhile to analyze the relative abilities of recent approaches
in terms of how precisely they can represent the underlying normal behavior of the pro-
gram they try to enforce. Although our framework enables formal analysis of models
comprising any event, we focus on system calls and control-ﬂow transfers. We develop
deﬁnitions so that they can be applied to both statically and dynamically generated mod-
els. We present a control-ﬂow sequence based IDS model, which is more precise than
any system call sequence based model representing the same valid program execution
behavior. This model can precisely represent a program’s execution, but requires the
exposure of all control-ﬂow events in a program. In Section 4, simpliﬁed derivations of
this model is used to analyze the precision of practical control-ﬂow based approaches.
Section 3.1 begins with an abstract model of program execution from which we de-
rive all sequence-based models used for intrusion detection. Section 3.2 deﬁnes our
approach of comparing the precision of different models. We derive system-call based
models in Section 3.3 and show that it imprecisely characterizes valid program execu-
tion. In Section 3.4, we derive control-ﬂow based models that precisely describe valid
execution and consider mimicry attacks in Section 3.5.
3.1 Abstract Model of Execution Sequences
Our abstract model considers the sequence in which code is executed. The smallest unit
of executed code is a machine instruction, which can be uniquely identiﬁed by its ad-
dress in memory. Therefore, an execution sequence can be represented as a sequence of
addresses from where instructions are executed. Without loss of generality, we consider
a coarser basic block unit of execution. A basic block is an ordered set of instructions
that are executed in sequence as a unit; execution enters only at the start of the block
Understanding Precision in Host Based Intrusion Detection
25
Fig. 1. An example program to illustrate control ﬂow
and system call based models. The vulnerable func-
tion has not been shown.
Fig. 2. The language of valid execution
sequences Ev as constructed by a static
or dynamic analyzer
and exits only at the end. The address of the ﬁrst instruction uniquely identiﬁes a ba-
sic block in memory. Basic blocks can also be used to represent high-level statements,
making our analysis applicable in the context of both source code and binaries.
Our abstract models of execution are built on sequences of basic blocks executed by
a running program. For a program P r, let Bv denote the complete set of basic blocks in
P r that can be executed during some valid execution. We use the term valid and normal
interchangeably throughout the paper because from the point of view of an anomaly
detector, anything that is deemed normal is considered valid. Figure 1 lists an example
program and the basic blocks in its set Bv. Let Bf be the set of all basic blocks that
may be feasibly executed in any run of the program. Note that feasible execution differs
from valid execution and includes blocks belonging to the program, unknown blocks
containing code maliciously introduced into P r’s address space, and blocks generated
by disassembling from the middle of instructions belonging to the program. Clearly
Bv ⊆ Bf . We next present the abstract models of valid and feasible execution, which
are languages over the sets of program points Bv and Bf , respectively.
The Language of Valid Execution. The language of valid execution Ev ⊆ Bv
con-
tains all sequences of basic blocks from Bv that denote valid execution behavior of P r.
The actual sequences contained in Ev depend upon the algorithms used to compute a
program’s valid behavior; our framework is general and suitable for any algorithm able
to generate Ev. For example, static and dynamic analysis each produce differing char-
acterizations of valid behavior Ev. In the domain of static analysis, different approaches
produce models having different sensitivities to program behavior [9]. Dynamic analy-
sis approaches may consider paths that seem valid from the program’s static view as
invalid. Our framework derives control-ﬂow and system-call sequences from any given
Ev. Therefore, our method of comparing precision is orthogonal to the choice of method
used to generate abstract model of valid execution Ev.
Figure 2 shows two different languages Ev constructed from typical static analysis
and dynamic analysis of the example program. The shaded boxes highlight where the
sequences differ. Note that the example program has correlated execution between the
direction of the if branch in main and the target of the indirect jump at B7. The Ev
constructed from context sensitive static analysis has four possible execution sequences
and fails to characterize the correlated execution. However, the dynamically constructed
model contains only two sequences because the correlation occurring actual execution
carries over to the observed execution sequences.
∗
26
M. Sharif et al.
The Language of Feasible Execution. The language Ef ⊆ Bf
represents all feasible
execution sequences of code in Bf that P r’s execution can generate. Again, feasible
execution need not be valid execution.
∗