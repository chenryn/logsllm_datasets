some keywords through the search engine, and ﬁnally
receiving the labels. Note that this process requires rich
experience on IoT recognition. The second dataset con-
sists of 6.9 million IoT devices that our application col-
lects on the Internet. Because the number of devices is
vast, we apply the same random algorithm to sample 50
IoT devices iteratively for 20 times. In total, the second
dataset contains 1,000 devices across 10 device types and
77 vendors.
5.2 Performance
Number of Rules. We ﬁrst compare the labeling perfor-
mance between ARE and Nmap. Nmap [8] is an open-
source tool for network discovery and security scanning.
The number of rules in the Nmap library has been in-
Table 3: Precision and coverage of rules on the dataset.
The ﬁrst dataset
The second dataset
Precision
95.7%
97.5%
Coverage
94.9%
—
Table 4: Rules generated by ARE.
Category
Num
Percentage %
(device type, vendor, product)
(device type, vendor, null)
107,627
8,352
92.8
7.2
creasing for two decades, from the initial version V3.40
to the latest version V7.60. The latest version of Nmap
has 6,504 rules [9] for four application protocols (HTTP,
FTP, RTSP, and TELNET). Figure 6 compares the time
cost in rule generation between ARE and Nmap, where
the Y-axis is the number of rules and X-axis is the time
cost in the logarithmic scale (log10). ARE is able to gen-
erate 115,979 rules in one week. While the number of
rules generated by ARE is almost 20 times larger than
that of Nmap, the ARE’s time cost is negligible com-
pared to Nmap’s, The reason is that the rule generation of
Nmap requires the professional background/experience
to write a rule manually, which is a long-term process.
By contrast, ARE automates the rule generation process.
Precision of Rules. We further evaluate the perfor-
mance of ARE rules by using precision. The precision is
equal to |T P|/|FP+T P|, where T P is the number of true
positives and FP is the number of false positives. Table 3
lists the precision of ARE rules. In the ﬁrst dataset, the
precision of rules is 95.7%. In the second dataset, the
ARE rules can achieve a 97.5% precision.
Coverage of Rules. Table 3 also lists the coverage of
ARE rules. The coverage is |T P|/|FP + FN|, where FN
is the number of false negatives. For the ﬁrst dataset, the
336    27th USENIX Security Symposium
USENIX Association
Table 5: Average time cost of one ARE rule generation.
Stage
Latency (second)
Application layer data
Response packet partition
Web crawler
Apriori algorithm
0.5022
0.0017
0.4236
0.1166
coverage of rules is 94.9%. For the second dataset, the
coverage is unknown, because we cannot determine the
number of false negatives in device annotation. Further,
Table 4 lists the detailed results of the rules generated by
ARE. There are 92.8% of rules that can completely label
IoT devices in the form of (device type, vendor, product).
Only 7.2% of rules just label device type and vendor. As
a comparison, Nmap only has about 30% of rules with a
ﬁne-grained annotation.
We use the hash algorithm to calculate MD5 check-
sums of the application-layer packets from Censys [25],
and then remove the duplicated packets. Based on these
response packets, we use both ARE and Nmap rules for
device identiﬁcation. Figure 7 shows the performance
of device identiﬁcation along with the number of the
application-layer packets. Given the same number of
response packets, ARE achieves a larger coverage than
Nmap. When the number of application-layer packets
increases, ARE can ﬁnd even more devices than Nmap.
Note that the distribution of IoT devices on the Internet
is a typical long tail rather than uniform distribution on
the Internet. This implies that some rules can ﬁnd much
more devices than other rules. For popular IoT prod-
ucts, ARE rules can classify them with robust labels. For
little-known IoT products, ARE rules can still classify
them because we generate rules based on the embedded
information.
Dynamic Rule Learning. We also conduct experi-
ments to evaluate the learning capacity of ARE. Figure 8
shows that the number of rules is increasing as ARE
learns with the increase of network space. The rule miner
can learn new rules when ARE is deployed into different
networks (e.g., residential/enterprise networks). Thus,
ARE has the capability for dynamic rule learning.
Overhead of ARE. Finally, we conduct experiments
to measure the time cost of ARE. Our ARE prototype
is running on a commercial desktop computer (Windows
10, 4vCPU, 16GB of memory, 64-bit OS), indicating that
CPU and memory costs of ARE can be easily met. The
ARE process is running in a single thread. Table 5 lists
the average time cost of individual components of ARE
for one rule generation. The acquisition of application-
layer data takes 0.5022 seconds, and the web crawling
takes 0.4236 seconds. Those components require the
message transmissions, and the time cost is dependent
Device Type
Number (%)
Zte
Table 6: Automatic Internet-wide identiﬁcation.
Number (%)
641,982 (9.3)
352,498 (5.1)
325,751 (4.7)
279,146 (4.0)
215,122 (3.1)
153,627 (2.2)
106,327 (1.5)
101,061 (1.5)
Vendor
1,249,765 (18.3) Mikrotik
785,810 (11.3)
644,813 (9.3)
466,286 (6.7)
379,755 (5.5)
180,121 (2.6)
127,532 (1.8)
35,976 (0.5)
Router
NVR
DVR
Modem
Camera
Switch
Gateway
Diskstation
Tp-link
Sonicwall
D-link
Dahua
Hp
Asus
upon the network conditions. As comparison, the packet
partition and the apriori algorithm induce little time cost.
Overall, the time cost of ARE for automatic rule gener-
ation is low in practice, and we could further reduce the
time cost by running ARE in multiple threads.
6 ARE-based Applications
In this section, we present the experimental results ob-
tained from three ARE-based applications, which further
demonstrate the effectiveness of ARE.
Internet-wide Device Measurement
6.1
IoT devices are usually deployed across many different
places, such as homes, infrastructure facilities, and trans-
portation systems. Traditionally IoT devices are behind
a broadband router with NAT/PAT/Firewall, but many of
them are now directly exposed on the Internet. Thus, it
is necessary to conduct an Internet-wide measurement of
IoT devices to have a deep understanding of their deploy-
ment and usage on the Internet. Previous Internet-wide
measurements have focused on network topology [22],
websites [27], and end hosts [31, 33]), but few has been
done on IoT devices. ARE greatly facilitates such an
Internet-wide measurement to infer, characterize, and an-
alyze online IoT devices.
In the IDM application, we use three application-layer
datasets from Censys [25], including HTTP, FTP, and
Telnet. Additionally, we deploy the collection module
on the Amazon EC2 [20] with 2 vCPU, 8GB of memory,
and 450Mbps of bandwidth, which collects the RTSP
application-layer response data. Overall, we found 6.9
million IoT devices, including 3.9 million from HTTP,
1.5 million from FTP, 1 million from Telnet, and 0.5 mil-
lion from RTSP. Using ARE rules, the IDM application
can give an annotation to every IoT device. Furthermore,
we use MaxMind’s GEOIP [34] database to ﬁnd the loca-
tion of an IoT device, which has a relationship between
IP address and the city-level location label.
USENIX Association
27th USENIX Security Symposium    337
Table 7: Geographic distribution.
District
Percentage (%)
20.26
6.73
6.39
4.29
4.18
3.94
3.69
3.45
2.95
2.88
United States
China
Brazil
India
Mexico
Taiwan
Republic of Korea
Russia
Egypt
Vietnam
Number
1,403,786
466,007
442,781
297,446
289,976
273,024
255,924
239,236
204,237
199,415
Discovery. Based on the analysis of millions of IoT
devices, we have three discoveries.
(1) Although a
large portion of IoT devices may be behind ﬁrewalls
in home/enterprise networks, the number of visible and
reachable IoT devices on the Internet is still very large.
Even if only 0.01% of IoT devices are accessible to the
external networks, considering the sheer size of active
IoT devices (billions), the absolute number of exposed
devices will reach the level of millions. (2) The long-tail
distribution is common for IoT devices, including device
types, vendors, and locations. Table 6 lists the distribu-
tion of the top 10 device types and vendors. We observe
that nearly 31% of IoT devices are from the top 10 de-
vice vendors. The location distribution of IoT devices is
a typical long-tail, as shown in Table 7. The top 10 coun-
tries (127 countries in total) occupy nearly half of the
IoT devices. (3) Many devices should not be visible or
reachable from the external networks. It is common for
routers, gateways, switches, and modems to be visible
and reachable on the Internet. However, the monitoring
devices, such as camera and DVR, should not be directly
exposed to the external networks. Unfortunately, there
are more than two million of those types of IoT devices
accessible on the Internet, as shown in Table 6.
6.2 Compromised Device Detection
Our detection of compromised IoT devices is based on
the capture of malicious IoT trafﬁc behaviors. A recent
work [21] leverages honeypot trafﬁc to detect the Miria
botnet infections based on unique packet content signa-
tures. After the collection of suspicious IPs, the Nmap
identiﬁcation rules [9] are used to obtain the device type.
Similarly, we develop the CDD application to discover
compromised devices.
In particular, we deploy seven honeypots as vantage
points for monitoring trafﬁc on the Internet, across four
countries (Brazil, China, India, and Ukraine) and six
cities, including Fuzhou, Kharkiv, Kunming (2 honey-
Figure 9: Compromised IoT device distribution.
pots), Maharashtra, Sao Paulo, and Shanghai. The mon-
itoring duration is nearly two months. We use the open-
source Cowrie SSH/Telnet Honeypot [6] in the CDD. Ev-
ery honeypot is conﬁgured with weak SSH/Telnet cre-
dentials and instructed to forward trafﬁc functions to the
CDD application. If a honeypot captures one IP address
that attempts to connect to our honeypot with SSH or Tel-
net, we will leave this IP into the Kafka queue [2]. The
CDD runs on Amazon EC2, and sends a request to each
IP address in the Kafka queue for receiving a response
data. Then ARE rules are used to identify IoT devices
from the response data. The rationale behind such a de-
sign lies in the fact that a normal IoT device should never
access honeypots. If an IoT device accesses our honey-
pot, there are only two reasons: it is misconﬁgured or
compromised.
Discovery. Figure 9 shows the number of compro-
mised devices captured by the CDD application. We can
capture about 50 different compromised IoT devices ev-
ery day. In total, we detect nearly 2,000 compromised
IoT devices among 12,928 IP addresses attempting to
connect to our honeypots. Many compromised IoT de-
vices attempt to brute force the SSH/TELNET creden-
tials of our honeypots. After mounting a successful
brute-force attack, the devices will execute some com-
mands on one of our honeypots, indicating that these IoT
devices are compromised and they try to compromise
more devices. Table 8 lists the distribution of the top 5
device types and vendors for compromised devices. We
can see that among different device types, DVR has by
far the largest number of compromised devices, followed
by network attached storage device (NAS) and router. In
addition, we also observe that a few smart TV boxes are
compromised and exhibit malicious behaviors.
6.3 Vulnerable Device Analysis
The disclosure of underlying vulnerable devices is also
valuable to the security community. From the defensive
338    27th USENIX Security Symposium
USENIX Association
Table 8: Device type and vendor for compromised de-
vices.
Device Type
DVR
NAS
Router
Webcam
Media device
Num
1168
189
173
92
83
(%)
67.7
10.9
10.0
5.3
4.8
Vendor
Hikvision
Dahua
Qnap
Mikrotik
TVT
Num
231
216
189
81
79
(%)
13.4
12.5
10.9