computes the challenged indices using Equation (1), based on pk and s, and computing elements of u as necessary. Then
verify that all challenged segments carry a valid Merkle proof.
Figure 1: A simple POR lottery.
Figure 3 and deﬁned in Figure 4. Next we describe the mod-
iﬁcations needed to achieve the non-outsourceable property.
Adjustments to the basic FPS scheme. Based on the basic
scheme in Figure 4, we make the following modiﬁcations to
ensure non-outsourceability, i.e., to ensure that the server can
make the (k + 1)-th signature with high probability if it can
successfully sign the ﬁrst k messages during the scratch-off.
Particularly, for the (k + 1)-th message, we allow the server
(cid:3) randomly chosen un-
(cid:3) out of 4q
(i.e., signer) to reveal any q
used leaves to produce a valid signature.
Lemma 1. Let q denote the number of leaves revealed for
the ﬁrst k signatures. For the (k + 1)-th signature, suppose
(cid:3) leaves must be revealed. Let the number of
that q
leaves L = 2kq + 8q
(cid:3) out of 4q
(cid:3).
Suppose that the client reveals L/2 or more leaves to the
server. Then, 1) the server can sign the (k + 1)-th message
except with negligible probability; and 2) anyone else with-
out knowledge of the leaves cannot forge a valid (k + 1)-th
signature for a different message (except with negligible prob-
ability).
(cid:3) un-
Proof. (sketch.) For the ﬁnal, (k + 1)-th message, 4q
used leaves are drawn randomly as a challenge using the hash
(cid:3) of these
function, and the server is allowed to select any q
(cid:3) leaves, the server in
to reveal. We know that among the 4q
(cid:3) of them, since it knows half of the leaves.
expectation has 2q
It is not hard to show using a Chernoff-like bound that the
server can successfully produce the ﬁnal signature (contain-
(cid:3) signatures). Based on this argument, for the
ing q
server to succeed in signing during scratch-off with any non-
negligible probability, it must know enough of the leaves to
(cid:3) out of 4q
be able to sign the (k + 1)-th message with overwhelming
probability.
It is not hard to show that the probability the (k + 1)-th
signature happens to be a valid signature for any other given
= O(λ).
message is negligible in the security parameter if q
In particular, to compute the probability for the (k + 1)-th
signature to be a valid signature for a different message, con-
(cid:3) leaves out of
sider the probability that a randomly chosen 4q
(cid:3) speciﬁc leaves contained in the (k + 1)-th sig-
8q
nature. This probability is
) for some
appropriate constant c > 0.
(cid:4) ∝ exp(−cq
(cid:3) contains q
(cid:4)
/
8q(cid:2)
3q(cid:2)
(cid:3)
(cid:3)
8q(cid:2)
4q(cid:2)
(cid:3)
(cid:3)
(cid:3)
(cid:3), q = O(λ) and q
Parameterizations and security. In order for this to be a se-
cure, unforgeable signature scheme for all k+1 messages, we
= O(λ). The proof
can set L = 2kq + 8q
of this is standard and deferred to our online full version. [16]
However, we observe that the ﬁrst k signatures (performed
during scratch off) actually need not be unforgeable signa-
tures. In fact, due to the above Lemma 1, we just have to set
our parameters such that any rational user will store at least
L/2 leaves on the server.
(cid:3)
Therefore, in practice, we can set q = 1 for all the inter-
nal signatures during scratch off. However, for the (k + 1)-th
(cid:3)
= O(λ), and the signer must choose 4q
signature, we set q
(cid:3) of them. In this case, if the client
leaves and reveal any q
withholds L/2 leaves from the server, the server must in ex-
pectation contact the client k/2 times during the scratch-off
attempt – in Section 5, we show that the cost of transmitting
even small packets of data greatly exceeds the cost of simply
computing scratch-off iterations locally. Therefore, a rational
user would not outsource its computation yet withhold L/2
or more leaves.
480
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:14 UTC from IEEE Xplore.  Restrictions apply. 
• Setup. Let r > 1 denote a constant. Suppose that the original dataset F0 contains f segments.
First, apply a maximum-distance-separable code and encode the dataset F0 into F containing n = rf segments, such
that any f segments of F sufﬁce to reconstruct F0. Then, proceed with the Setup algorithm of Figure 1.
• Scratch-off. For a scratch-off attempt seeded by an arbitrary string s chosen by the user, compute the following:
σ0 := 0
r1 := u[H(puz||pk||s) mod (cid:3)]
For i = 1, 2, . . . , k :
hi = H(puz||pk||σi−1||F[ri])
ri+1 := H(puz||pk||σi) mod (cid:3)
σi := signsk(hi)
(∗)
The ticket is deﬁned as:
ticket := (pk, s, {F[ri], σi, πri
}∀i=1,2,...,k)
where πri is the Merkle proof of F[ri].
• Verify. Given ticket := (pk, s, {F[ri], σi, πri
}∀i=1,2,...,k), veriﬁcation is essentially a replay of the scratch-off, where
the signing is replaced with signature veriﬁcation. This way, a veriﬁer can check whether all iterations of the scratch-off
were performed correctly.
Figure 2: Local-POR lottery.
5 To Outsource or Not to Outsource
As mentioned earlier, since we tie possession of newly minted
coins to a user’s private key in Permacoin, we assume that a
substantial fraction of users will not entrust their private keys
to a service provider and risk theft of their coins.
A user j who only stores her private key skj locally can
choose between two ways of storing her assigned blocks of
F : a local storage device or outsourced storage leased from
a remote cloud storage service. (A combination of the two is
also possible.) We now analyze the storage choice of rational
participants, those seeking to maximize their return on mining
by achieving the lowest expected cost per SOP. We argue that
rational users will choose local storage to drive down their
resource costs.
In both the local storage and outsourced storage scenarios,
the user locally provisions a basic computational resource (in-
curring the hardware costs of a motherboard, CPU, and RAM
and power costs, but not of a substantial storage medium).
The cost differences for the two storage scenarios—again, fa-
voring local storage—stem from the following:
Cost of Storage and I/O: In the local scenario, a client’s
costs are its investment in storage equipment for mining,
speciﬁcally, for the purchase of RAM or SSD. (These costs
may be characterized in terms of equipment depreciation.)
In the outsourced scenario, a client’s costs include the: 1)
Cost of storage and disk I/O charged by the service provider;
2) Cost of network bandwidth, including that of the network
link provided by an ISP, and the cost per GB of network trans-
fer charged by a service provider. In our setting, storage of the
ﬁle F can be amortized across multiple users, so we assume
the storage cost and disk I/O cost are close to zero. What
remains is the cost of network I/O.
We show that based on typical market prices today, the
costs of storage and I/O are signiﬁcantly cheaper for the local
storage option.
Latency: By design, our SOP sequentially accesses blocks
in F in a random (pseudorandom) order. The resulting, un-
predictable fetches penalize outsourced storage, as they intro-
duce substantial latency: a single round-trip for every fetched
block, which is vastly larger than disk I/O latency. This la-
tency overhead reduces a miner’s chance of ﬁnding a valid
puzzle solution and winning the reward when the number k
of outsourced fetches is large.
If each block fetch incurs roundtrip latency τ, then for large
k, the total incurred latency kτ may be quite large. For ex-
ample, with k = 6000, one iteration parameter we analyze
below, and a 45ms roundtrip latency, typical for regional in-
ternet accesses, kτ would be 4.5 minutes—almost half the
length of an epoch. Boosting to k > 13, 333 would render kτ
larger than an average epoch, making outsourcing infeasible.
Of course, if kτ is small enough, a client can parallelize
fetches across SOP guesses. It is helpful to quantify formally
the value of time, and penalties associated with latency, as we
do now.
5.1 Stochastic model
We now present a stochastic model that offers a quantitative
comparison of the economics of local vs. outsourced storage.
The notation used for the parameters of our scheme are sum-
marized in Table 1.
We consider a stochastic process in which a single-
threaded mining process is trying to ﬁnd a ticket. This min-
481
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:14 UTC from IEEE Xplore.  Restrictions apply. 
• KeyGen(y, (cid:3)): Let L denote the number of Merkle leaves. Pick {σ1, . . . , σL} at random from {0, 1}O(λ). Construct a
Merkle tree on top of the L leaves {σ1, . . . , σL}, and let digest denote the root’s digest.
The secret key is sk := {σ1, . . . , σL}, and the public key is pk := digest. The signer and veriﬁer’s initial states are
Ωs = Ωv := ∅ (denoting the set of leaves revealed so far).
• Sign(sk, Ωs, m): Compute H(m) where H is a hash function modelled as a random oracle. Use the value H(m) to
select a set I := sk − Ωs of q unrevealed leaves. The signature is
σ := {(σi, πi)}i∈I in sorted order of i
where πi is the Merkle proof for the i-th leaf. Update signer’s state Ωs := Ωs ∪ σ.
• Verify(pk, Ωv, m, σ): Use H(m) to select an unused set I of leaves, of size q. Parse σ := {(σi, πi)}i∈I (in sorted order
of i). Verify that each πi is a correct Merkle proof for the i-th leaf node σi where i ∈ I. Output 1 if all veriﬁcations pass.
Otherwise output 0.
Finally, update veriﬁer’s state Ωv := Ωv ∪ σ.
Figure 4: An FPS signature scheme.
Table 1: Notation used for system parameters
# segments necessary for recovery
f
m total # segments stored by good users during recovery
n
(cid:3)
k
B # size of each block (bytes)
total # encoded segments
# segments assigned to each identity
# iterations per puzzle
ing thread will keep computing the iterations sequentially as
described in Figure 2. At any time, if another user in the net-
work ﬁnds a winning ticket ﬁrst, the current epoch ends, and
the mining thread aborts the current scratch-off attempt and
starts a new attempt for the new epoch.
We consider the following cost metric: expected cost in-
vested until a user succeeds in ﬁnding one ticket. Every time a
user ﬁnds a ticket (before anyone else ﬁnds a winning ticket),
the user has a certain probability of having found a winning
ticket, and hence being rewarded.
Game with a giant. We can think of this stochastic process
as a user playing a game against a giant. The giant models
the rest of the network, which produces winning tickets at a
certain rate. The stochastic process in which the giant pro-
duces winning tickets is a memoryless process. At any time,
the remaining time T it takes for the giant to ﬁnd a winning
ticket follows an exponential distribution. The expectation of
T is also the expected epoch length. In Bitcoin, as noted, the
difﬁculty of its SOP is periodically adjusted with respect to
the computational power of the network to keep the expected
epoch length at about 10 minutes.
If the giant generates a puzzle solution, it is immediately
communicated to the user, who aborts her current attempt.
Thus the stochastic process can be modeled as a Markov
chain as follows:
• Every iteration takes t time, and costs c.
• If k iterations are ﬁnished (before the giant wins), a
user ﬁnds a ticket (which may or may not be a winning
ticket).
In this case the user gets a positive reward in
expectation.
• Let si denote the state in which the user has ﬁnished
computing the i-th iteration of the puzzle.
• If i < k − 1: with probability p, the giant does not
win in the current iteration, and the state goes from si
to si+1. With probability 1 − p, the giant wins, and the
state goes back to s0, i.e., the current epoch ends, and a
new scratch-off attempt is started. Suppose that the ex-
pected epoch length is T ; then it is not hard to see that
p = 1−t/T given that the stochastic process of the giant
winning is memoryless.
• In state sk−1, with probability 1, the state goes back to
s0. Furthermore, in state sk−1, with probability p, the
user will ﬁnish computing all k iterations — in which
case another random coin is drawn to decide if the ticket
wins.
1
1 − p
1 − p
1 − p
s0
s1
p
p
s2
. . .
p
sk−1
p
Figure 5: Markov chain model for a sequential mining pro-
cess that resets if the epoch ends during an iteration.
We analyze the stationary distribution of the above Markov
chain. Let πk−1 denote the probability that it is in state sk−1.
482
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:14 UTC from IEEE Xplore.  Restrictions apply. 
It is not hard to derive that πk−1 = (1 − p)pk−1/(1 − pk).
Therefore, in expectation, 1/πk−1 time is spent between two
visits to the state sk−1. Every time the state sk−1 is visited,
there is a p probability that the user will ﬁnish all k iterations
of the puzzle. Therefore, in expectation, 1/(πk−1p) time (in
terms of number of iterations) is spent before the user ﬁnds a
ticket before the giant does. If a user ﬁnds a ticket before the
giant does, we call this a “success”. Hence, we have that
E[expected cost per success] =
c(1 − pk)