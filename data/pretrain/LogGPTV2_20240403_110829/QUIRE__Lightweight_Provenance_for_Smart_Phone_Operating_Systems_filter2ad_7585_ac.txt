3.2 Authority management
The Authority Manager discussed in Section 2 is imple-
mented as a system service that runs within the operating
system’s reserved user-id space. The interface exposed
by the service allows userspace applications to request
a shared secret, submit a statement for veriﬁcation, or
request the resolution of the principal included in a state-
ment into an externally meaningful form.
When an application requests a key from the authority
manager, the Authority Manager maintains a table map-
ping user-id / process-id tuples to the key. It is important
to note that a subsequent request from the same applica-
tion will prompt the Authority Manager to create a new
key for the calling application and replace the previous
stored key in the lookup table. This prevents attacks that
might try to exploit the reuse of user-ids and process-ids
as applications come and go over time. Needless to say,
the Authority Manager is a system service that must be
trusted and separated from other apps.
3.3 Veriﬁable statements
Section 2.3 introduced the idea of attaching an OS veri-
ﬁable statement to an object in order to allow principals
later in a call-chain to verify the authenticity and integrity
of a received object.
Our implementation of this abstract concept involves
a parcelable statement object that consists of a principal
identiﬁer as well as an authentication token. When this
statement object is attached to a parcelable object, the an-
notated object contains all the information necessary for
the Authority Manager service to validate the authentica-
tion token contained within the statement. Therefore the
annotated object can be sent over Android’s IPC chan-
nels and later delivered to the Quire Authority Manger
for veriﬁcation by the OS.
Quire’s veriﬁable statement
implementation estab-
lishes the authenticity of message with HMAC-SHA1,
which proved to be exceptionally eﬃcient for our needs,
while still providing the authentication and integrity se-
mantics required by Quire.
Even with HMAC-SHA1, speed still matters. In prac-
tice, doing HMAC-SHA1 in pure Java was still slow
enough to be an issue. We resolved this by using a native
C implementation from OpenSSL and exposing it to Java
code as a Dalvik VM intrinsic function, rather than a JNI
native method. This eliminated unnecessary copying and
runs at full native speed (see Section 5.2.1).
3.4 Code generator
The key to the stack inspection semantics that Quire pro-
vides is an extension to the Android Interface Deﬁnition
Language (AIDL) code generator. This piece of software
is responsible for taking in a generalized interface deﬁni-
tion and creating stub and proxy code to facilitate Binder
IPC communication over the interface as deﬁned in the
AIDL ﬁle.
The Quire code generator diﬀers from the stock An-
droid code generator in that it adds directives to the mar-
shaling and unmarshaling phase of the stubs that pulls
the call-chain context from the calling app and attaches
it to the outgoing IPC message for the callee to retrieve.
These directives allow for the “quoting” semantics that
form the basis of a stack inspection based policy system.
Our prototype implementation of the Quire AIDL
code generator requires that an application developer
specify that an AIDL method become “Quire aware”
by deﬁning the method with a reserved auth ﬂag in the
AIDL input ﬁle. This ﬂag informs the Quire code gen-
erator to produce additional proxy and stub code for the
given method that enables the propagation and delivery
of the call-chain context to the speciﬁed method. A pro-
duction implementation would pass this information im-
plicitly on all IPC calls.
In addition to enabling quoting semantics, the mod-
iﬁed code generator also exposes helper functions that
wrap the generation (and storage) of a shared secret with
the OS Authority Manager and the creation and trans-
mission of a veriﬁable statement to a communicating IPC
endpoint.
4 Applications
We built two diﬀerent applications to demonstrate the
beneﬁts of Quire’s infrastructure.
4.1 Click fraud prevention
Current Android-based advertising systems, such as Ad-
Mob, are deployed as a library that an app includes as
part of its distribution. So far as the Android OS is con-
cerned, the app and its ads are operating within single do-
main, indistinguishable from one another. Furthermore,
because advertisement services need to report their ac-
tivity to a network service, any ad-supported app must
request network privileges, even if the app, by itself,
doesn’t need them.
From a security perspective, mashing these two dis-
tinct security domains together into a single app creates
a variety of problems. In addition to requiring network-
access privileges, the lack of isolation between the adver-
tisement code and its host creates all kinds of opportuni-
ties for fraud. The hosting app might modify the adver-
tisement library to generate fake clicks and real revenue.
This sort of click fraud is also a serious issue on the
web, and it’s typically addressed by placing the adver-
tisements within an iframe, creating a separate protec-
tion domain and providing some mutual protection. To
achieve something similar with Quire, we needed to ex-
tend Android’s UI layer and leverage Quire’s features to
authenticate indirect messages, such as UI events, dele-
gated from the parent app to the child advertisement app.
Design challenges. Fundamentally, our design re-
quires two separate apps to be stacked (see Figure 2),
with the primary application on top, and opening a trans-
parent hole through which the subordinate advertising
application can be seen by the user. This immediately
raises two challenges. First, how can the advertising app
know that it’s actually visible to the user, versus being
obscured by the application? And second, how can the
advertising app know that the clicks and other UI events
it receives were legitimately generated by the user, versus
being synthesized or replayed by the primary application.
Figure 2: The host and advertisement apps.
Stacking the apps. This was straightforward to im-
plement. The hosting application implements a translu-
cent theme (Theme.Translucent), making the background
activity visible. When an activity containing an ad-
vertisement is started or resumed, we modiﬁed the ac-
tivity launch logic system to ensure that the advertise-
ment activity is placed below the associated host activ-
ities. When a user event is delivered to the AppFrame
view, it sends the event along with the current location of
AppFrame in the window to the an advertisement event
service. This allows our prototype to correctly display
the two apps together.
Visibility. Android allows an app to continue running,
even when it’s not on the screen. Assuming our ad ser-
vice is built around payments per click, rather than per
view, we’re primarily interested in knowing, at the mo-
ment that a click occurred, that the advertisement was
actually visible. Android 2.3 added a new feature where
motion events contain an “obscured” ﬂag that tells us
precisely the necessary information. The only challenge
is knowing that the MotionEvent we received was legiti-
mate and fresh.
Figure 3: Secure event delivery from host app to adver-
tisement app.
We modiﬁed the event system to augment every Mo-
tionEvent (as many as 60 per second) with one of our
MAC-based signatures. This means we don’t have to
worry about tampering or other corruption in the event
system. Instead, once an event arrives at the advertise-
ment app, it ﬁrst validates the statement, then validates
that it’s not obscured, and ﬁnally validates the timestamp
in the event, to make sure the click is fresh. This process
is summarized in Figure 3.
At this point, the local advertising application can now
be satisﬁed that the click was legitimate and that the ad
was visible when the click occurred and it can communi-
cate that fact over the Internet, unspoofably, with Quire’s
RPC service.
All said and done, we added around 500 lines of Java
code for modifying the activity launch process, plus a
modest amount of C code to generate the signatures.
While our implementation does not deal with every pos-
sible scenario (e.g., changes in orientation, killing of the
advertisement app due to low memory, and other such
things) it still demonstrates the feasibility of hosting of
advertisement in separate processes and defeating click
fraud attacks.
4.2 PayBuddy
Verifying events. With our stacked app design, motion
events are delivered to the host app, on top of the stack.
The host app then recognizes when an event occurs in the
advertisement’s region and passes the event along. To
complicate matters, Android 2.3 reengineered the event
system to lower the latency, a feature desired by game
designers. Events are now transmitted through shared
memory buﬀers, below the Java layer.
In our design, we leverage Quire’s signed statements.
To demonstrate the usefulness of Quire for RPCs, we
implemented a micropayment application called Pay-
Buddy: a standalone Android application which exposes
an activity to other applications on the device to allow
those applications to request payments.
This is a scenario which requires a high degree of co-
operation between many parties, but at the same time in-
volves a high degree of mutual distrust. The user may
not trust the application not to steal his banking infor-
AdBuy! Cool! Stuff!Sample App(transparent, so ad is visible)UserspaceDelegate(e)Sample AppVerifyMAC(e)Ad View AppOperating SystemkEM        “E.M.”Auth ManagerClickEvent e = {  Time t  Position x,y  ... }MACkEM(e)Event Managerand was not tampered with by the PayBuddy appli-
cation.
• The PayBuddy application approved the request
(which means that the user gave their explicit con-
sent to the purchase order).
At the end of this, if PayBuddy.com accepts the trans-
action, it can take whatever action accompanies the suc-
cessful payment (e.g., returning a transaction ID that
ExampleApp might send to its home server in order to
download a new level for a game).
Security analysis. Our design has several curious
properties. Most notably, the ExampleApp and the Pay-
Buddy app are mutually distrusting of each other.
The PayBuddy app doesn’t trust the payment request
to be legitimate, so it can present an “okay/cancel” dialog
to the user. In that dialog, it can include the cost as well
as the ExampleApp name, which it received through the
Quire call chain. Since ExampleApp is the direct caller,
its name cannot be forged. The PayBuddy app will only
communicate with the PayBuddy.com server if the user
approves the transaction.
Similarly, ExampleApp has only a limited amount of
trust in the PayBuddy app. By signing its purchase or-
der, and including a unique order number of some sort,
a compromised PayBuddy app cannot modify or replay
the message. Because the OS’s net provider is trusted to
speak on behalf of both the ExampleApp and the Pay-
Buddy app, the remote PayBuddy.com server gets am-
ple context to understand what happened on the phone
and deal with cases where a user later tries to repudiate a
payment.
Lastly, the user’s PayBuddy credentials are never vis-
ible to ExampleApp in any way. Once the PayBuddy
app is bound, at install time, to the user’s matching ac-
count on PayBuddy.com, there will be no subsequent
username/password dialogs. All the user will see is an
okay/cancel dialog. This will reduce the number of user-
name/password dialogs that the user sees in normal us-
age, which will make entering username and password
an exceptional situation. Once users are accustomed to
this, they may be more likely to react with skepticism
when presented with a phishing attack that demands their
PayBuddy credentials.
(A phishing attack that’s com-
pletely faithful to the proper PayBuddy user interface
would only present an okay/cancel dialog, which yields
no useful information for the attacker.)
Figure 4: Message ﬂow in the PayBuddy system.
mation, while the application may not trust the user to
faithfully make the required payment. Similarly, the ap-
plication may not trust that the PayBuddy application on
the phone is legitimate, while the PayBuddy application
may not trust that the user has been accurately notiﬁed of
the proper amount to be charged. Finally, the service side
of PayBuddy may not trust that the legitimate PayBuddy
application is the application that is submitting the pay-
ment request. We designed PayBuddy to consider all of
these sources of distrust.
To demonstrate how PayBuddy works, consider the
example shown in Figure 4. Application ExampleApp
wishes to allow the user to make an in-app purchase.
To do this, ExampleApp creates and serializes a pur-
chase order object and signs it with its MAC key kA.
It then sends the signed object to the PayBuddy appli-
cation, which can then prompt the user to conﬁrm their
intent to make the payment. After this, PayBuddy passes
the purchase order along to the operating system’s Net-
work Provider. At this point, the Network Provider can
verify the signature on the purchase order, and also that
the request came from the PayBuddy application. It then
sends the request to the PayBuddy.com server over a
client-authenticated HTTPS connection. The contents of
ExampleApp’s purchase order are included in an HTTP
header, as is the call chain (“ExampleApp, PayBuddy”).
At the end of this, PayBuddy.com knows the follow-
ing:
• The request came from a particular device with a
given certiﬁcate.
• The purchase order originated from ExampleApp
Google’s in-app billing. After we implemented Pay-
Buddy, Google released their own micropayment sys-
tem. Their system leverages a private key shared be-
tween Google and each application developer to enable
UserspaceMAC Key: kAPurchaseOrder po {    Cost c    Payee p ...}MACkA(po)ExampleAppMAC Key: kPBRPCPayBuddy.com(...)PayBuddyOperating SystemkA          “ExampleApp”kPB        “PayBuddy”Auth Manager“ExampleApp says ...”“PayBuddy says ...”Net ProviderPayBuddy.comthe on-phone application to verify that conﬁrmations are
coming from Google’s Market servers. However, unlike
PayBuddy, the messages from the Market application to
the server do not contain OS-signed statements from the
requesting application and the Market app. If the Market
app were tampered by an attacker, this could allow for a
variety of compromises that Quire would defeat.
Also, while Google’s in-app billing is built on Google-
speciﬁc infrastructure, like its Market app, Quire’s de-
sign provides general-purpose infrastructure that can be
used by PayBuddy or any other app.
One last diﬀerence: PayBuddy returns a transaction
ID to the app which requested payment. The app must
then make a new RPC to the payment server or to its
own server to validate the transaction ID against the orig-
inal request. Google returns a statement that is digitally
signed by the Market server which can be veriﬁed by
a public key that would be embedded within the app.
Google’s approach avoids an additional network round
trip, but they recommend code obfuscation and other
measures to protect the app from external tampering3.
5 Performance evaluation
5.1 Experimental methodology