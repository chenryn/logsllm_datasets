## Bug
Using libtorch causes memory leaks. but i think that it is very strange.
because i only define `torch::DeiviceType` , then got **bug1**
### bug1
    still reachable: 884,654 bytes in 13,927 blocks of which reachable via heuristic: stdstring :436062 bytes in 5832 blocks
### bug2
    possibly lost: 3104 bytes in 22 blocks
    still reachable: 1231592 bytes in 14005 blocks of which reachable via heuristic: stdstring :436062 bytes in 5832 blocks
## To Reproduce
### bug1
    int main()
    {
     torch::DeviceType device_type;
    }
### bug2
    int main()
    {
     torch::DeviceType device_type;
    if(torch::cuda::is_available())
    {
    device_type = torch::kCUDA;
    }
    else
    {
    device_type = torch::kCPU;
    }
    torch::Device device(device_type)
    }
## Environment
  * PyTorch Version : 1.4
  * libtorch Version: 1.4
  * OS (e.g., Linux): Ubuntu 14.04
  * How you installed PyTorch (`conda`, `pip`, source): pip
  * Python version: 3.5
  * CUDA/cuDNN version: 10