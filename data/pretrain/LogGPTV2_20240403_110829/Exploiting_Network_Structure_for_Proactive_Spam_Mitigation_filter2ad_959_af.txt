c
a
r
F
0.8
0.6
0.4
0.2
0
0
Greedy
α = 0.1
α = 0.5
0.2
0.4
0.6
Goodput−Ratios
0.8
1
(b) Overload-Factor 4: CDF of goodput-ratios for all
policies
100% 
)
%
(
s
r
u
o
h
f
o
n
o
i
t
c
a
r
F
80% 
60% 
40% 
20% 
overload = 5
overload = 4
overload = 3
overload = 2
overload = 1
0%
100% 
150% 
200% 
Goodput Factor
250% 
300% 
(c) Goodput factor
Figure 8: (a) and (b): CDF of the goodput-ratios for two
different overload-factors.
(c): Performance improve-
ment (goodput-factor) for the 10-policy for various over-
load factors
Overload Greedy α = 0.1 α = 0.5
Factor
5
4
3
2
1
20.3
26.8
39.5
61.7
93.7
63
64.3
70.7
84.4
96
63.6
64.5
68.6
79.6
96.7
Table 1: Server Goodput (average, in %).
USENIX Association
16th USENIX Security Symposium
163
Overload Greedy α = 0.1 α = 0.5
Factor
31.6
39.1
51.6
71.4
95.2
16.6
17
24.1
65.8
93.9
5
4
3
2
1
16.8
17
22.1
51.3
95
Table 2: Server throughput (average, in %).
Overload Greedy α = 0.1 α = 0.5
Factor
5
4
3
2
1
32
39.5
52
71.7
95.2
14.9
15.1
15.2
50.2
94.9
Table 3: Spam accepted (average, in %).
14.8
15.1
20.1
65.2
93.8
ous capacities of the server. At overload-factor 1, when
the greedy algorithm achieves an average throughput of
95%, the history-based policy algorithm achieves an av-
erage throughput of 93%. However, even at this point,
the history-based policies accept a little more legitimate
mail (on average) than the greedy policy. Note that by de-
sign, the history-based policies guarantee that when the
server receives no more than 75% of its maximum load
capacity, its performance is no different from normal.
Impact on Spam: We also explored the effect of
the history-based policies on the number of spam mes-
sages accepted. Table 3 shows the average fraction
of spam messages accepted by the policies under var-
ious overload factors. We see with an overload-factor
of 1, the history-based policies accept only 0.3 − 1%
less spam than the greedy algorithm. As the overload-
factor increases and the history-based policies grow more
and more conservative in accepting suspected spam, the
amount of spam accepted will decrease. For example, at
a overload-factor of 2, this drops to 50.2% − 65.5% for
the history-based policies. When the overload-factor in-
creases to 4, the history-based policies accept less than
1/2 of the amount of spam accepted by the greedy pol-
icy. This suggests that if the server receives much more
workload than it can process, the spam is affected much
more than the legitimate mail. Therefore, the spammer
would not have an incentive to increase the workload sig-
niﬁcantly, since it is the spam that gets most affected.
Thus, we have shown that our history-based policies
achieve a signiﬁcant and consistent performance im-
provement over the greedy policy when the server is
under overload: we have seen this with multiple met-
rics of the goodput ratio. We have also seen that the
history-based policies do not impact the performance of
the server too much when the server is not under over-
load. Finally, we have seen that the the spam is indeed
affected when the server is signiﬁcantly overloaded; this
is precisely the behaviour we want to induce.
5 Related Work
Since spam is so pervasive, much effort has been ex-
pended in developing techniques that mitigate spam, and
studies that understand various characteristics of spam-
mers.
In this section, we brieﬂy survey some of the
most related work. We ﬁrst describe spam mitigation ap-
proaches and how they may relate to our work on the
server overload problem. Then we discuss measurement
studies that are related and complementary to our mea-
surement work.
Traditionally, the two primary approaches to spam
mitigation have used content-based spam-ﬁltering and
DNS blacklists.
Content-based spam-ﬁltering soft-
ware [3, 1] is typically applied at the end of the mail pro-
cessing queue, and there has been a lot of research [20,
17, 7, 16] in techniques for content-based analysis and
understanding its limits. Agarwal et al. [6] propose
content-based analysis to rate-limit spam at the router;
this also reduces the load on the mail server, but is not
useful for our situation as it may be too computationally
expensive.
DNS blacklists [4, 5] are another popular way to re-
duce spam. Studies on DNS blacklists[14] have shown
that over 90% of the spamming IP addresses were present
in at least one blacklist at their time of appearance. Our
approach is complementary to traditional blacklisting,
and the more recent greylisting [13] techniques – we aim
to prioritize the legitimate mail, and use the history of IP
addresses to identify potential spammers.
Perhaps the closest in spirit to our work in mitigating
server overload are those of Twining et al. [23] and Tang
et al. [21]. Twining et al. describe a prioritization mech-
anism that delays spam more than it delays legitimate
mail. However, their problem is different, as they eventu-
ally accept all email, but just delay the spam. Such an ap-
proach would not work when all the mail simply cannot
be accepted. While Tang et al. [21] do not consider the
problem of server overload, they describe a mechanism
to assign trust to and classify IP addresses using SVMs.
Our work differs in the way it gets the historical reputa-
tions – rather than using a blackbox learning algorithm,
it uses the IP addresses and network-aware clusters, thus
directly utilizing the structure of the network.
There has also been interest in using reputation mech-
anisms for identifying spam. There are a few commer-
cial IP-based reputation systems (e.g., SenderBase [2],
TrustedSource [22]). A general reputation system for
internet defense has been proposed in [9]. There has
164
16th USENIX Security Symposium
USENIX Association
been work on using social network information for
designing reputation-granting mechanisms to mitigate
spam [10, 11, 8]. Prakash et al. [18] propose community-
based ﬁlters trained with classiﬁers to identify spam. Our
work differs from these reputation systems as it demon-
strates the potential of using network-aware clusters to
assign reputations to IP addresses for prioritizing legiti-
mate mail.
Recently, there have been studies on characterizing
spammers, legitimate senders and mail trafﬁc, and we
only discuss the most closely related work here. Ra-
machandran and Feamster [19] present a detailed anal-
ysis of the network-level characteristics of spammers.
By contrast, our work focuses on the comparison be-
tween legitimate mail and spam and explores the stabil-
ity of legitimate mail. We also use network-aware clus-
ters to probabilistically distinguish the bulk of the legit-
imate mail from the spam. Gomes et al. [12] study the
e-mail arrivals, size distributions and temporal locality
that distinguish spam trafﬁc from non-spam trafﬁc; these
are interesting features that distinguish spam and legiti-
mate trafﬁc patterns and provide general insights into be-
haviour. Our measurement study differs as it focuses on
understanding the historical behaviour of mail servers at
the network level that can be exploited to practical spam
mitigation.
6 Conclusion
In this paper, we have focused on using IP addresses as a
computationally-efﬁcient tool for spam mitigation in sit-
uations when the distinction need not be perfectly accu-
rate. We performed an extensive analysis of IP addresses
and network-aware clusters to identify properties that can
distinguish the bulk of the legitimate mail and spam. Our
analysis of IP addresses indicated that the bulk of the le-
gitimate mail comes from long-lived IP addresses, while
the analysis of network-aware clusters indicated that the
bulk of the spam comes from clusters that are relatively
long-lived. With these insights, we proposed and simu-
lated a history-based reputation mechanism for prioritiz-
ing legitimate mail when the mail server is overloaded.
Our simulations show that the history and the structure
of the IP addresses can be used to substantially reduce
the adverse impact of mail server overload on legitimate
mail, by up to a factor of 3.
7 Acknowledgements
This research was supported in part by CyLab at
Carnegie Mellon under grant DAAD19-02-1-0389 from
the Army Research Ofﬁce. The views and conclusions
contained here are those of the authors and should not be
interpreted as necessarily representing the ofﬁcial poli-
cies or endorsements, either express or implied, of ARO,
CMU, or the U.S. Government or any of its agencies.
This material is also based upon work partially supported
through the U.S. Army Research Ofﬁce under the Cyber-
TA Research Grant No. W911NF-06-1-0316, and by the
National Science Foundation under Grants No. 0433540,
0448452 and CCF-0424422. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this ma-
terial are those of the author(s) and do not necessarily
reﬂect the views of the ARO or the National Science
Foundation. We thank Avrim Blum, Vyas Sekar and
Elaine Shi for useful discussions and comments. We also
thank the anonymous reviewers and our shepherd, David
Dagon, for helpful comments on earlier versions of this
paper.
References
[1] Brightmail. http://www.brightmail.com.
[2] SenderBase. http://www.senderbase.org.
[3] SpamAssassin. http://www.spamassassin.org.
[4] SpamCop. http://www.spamcop.net.
[5] SpamHaus. http://www.spamhaus.net.
[6] AGARWAL, B., KUMAR, N., AND MOLLE, M. Controlling
In IEEE International Conference
spam e-mails at the routers.
on Communications (ICC) (2005).
[7] ANDROUTSOPOULOS, I., KOUTSIAS, J., CHANDRINOS, K.,
PALIOURAS, G., AND SPYROPOULOS, C. Spam ﬁltering with
Naive Bayes - which Naive Bayes? In Third Conference on Email
and Anti-Spam (2006).
[8] BOYKIN, P. O., AND ROYCHOWDHURY, V. P. Leveraging social
networks to ﬁght spam. Computer 38, 4 (2005), 61–68.
[9] BRUMLEY, D., AND SONG, D. Towards attack-agnostic de-
In Proceedings of the First Workshop on Hot Topics in
fenses.
Security (HOTSEC) (2006).
[10] GARISS, S., KAMISKY, M., FREEDMAN, M., KARP, B.,
MAZIERES, D., AND YU, H. Re: Reliable email. In Proceedings
of NSDI (2006).
[11] GOLBECK, J., AND HENDLER, J. Reputation network analysis
for e-mail ﬁltering. In First Conference on E-mail and Antispam
(2004).
[12] GOMES, L. H., CAZITA, C., ALMEIDA, J. M., ALMEIDA, V.,
AND WAGNER MEIRA, J. Characterizing a spam trafﬁc. In Pro-
ceedings of Internet Measurement Conference (IMC) (2004).
[13] HARRIS, E. The next step in the spam control war: Greylisting.
http://projects.puremagic.com/greylisting/.
[14] JUNG, J., AND SIT, E. An empirical study of spam trafﬁc and the
use of DNS black lists. In Proceedings of Internet Measurement
Conference (IMC) (2004).
[15] KRISHNAMURTHY, B., AND WANG, J. On network-aware clus-
tering of web clients. In Proceedings of ACM SIGCOMM (2000).
[16] LOWD, D., AND MEEK, C. Good word attacks on statistical
In Second Conference on Email and Anti-Spam
spam ﬁlters.
(2005).
[17] MEDLOCK, B. An adaptive, semi-structured language model ap-
proach to spam ﬁltering on a new corpus. In Third Conference on
Email and Anti-Spam (2006).
USENIX Association
16th USENIX Security Symposium
165
[18] PRAKASH, V. V., AND O’DONNELL, A. Fighting spam with
reputation systems. Queue 3, 9 (2005), 36–41.
[19] RAMACHANDRAN, A., AND FEAMSTER, N. Understanding the
In Proceedings of ACM
network-level behavior of spammers.
SIGCOMM (2006).
[20] SAHAMI, M., DUMAIS, S., HECKERMAN, D., AND HORVITZ,
In Learning
E. A Bayesian approach to ﬁltering junk E-mail.
for Text Categorization: Papers from the 1998 Workshop (1998),
AAAI Technical Report WS-98-05.
[21] TANG, Y., KRASSER, S., AND JUDGE, P. Fast and effective
spam sender detection with granular SVM on highly imbalanced
server behavior data. In 2nd International Conference on Collab-
orative Computing: Networking, Applications and Worksharing
(2006).
[22] TRUSTEDSOURCE. http://www.trustedsource.org.
[23] TWINING, D., WILLIAMSON, M. M., MOWBRAY, M., AND
RAHMOUNI, M. Email prioritization: Reducing delays on le-
gitimate mail caused by junk mail. In USENIX Annual Technical
Conference (2004).
A Appendix
We present here the details of the policy used in Phase 1.
for the history-based policies. In detail, the policy is the
following: If the load is less than 75% of its capacity, the
policy accepts all SMTP connections requests, regardless
of the reputation of the IP address. If the load is greater
than 75% of the capacity, the policy starts considering
the reputation of the IP address and the legitimate mail
that it expects to have to process in the near future.
For this purpose, it uses a distribution of the number of
emails expected in the next t time units from reputation
value at most k (for multiple k values), that is calculated
based on the history of the distribution of mail arrival.
Since our reputation function is the lifetime spam-ratio,
a low reputation value is a good reputation, and a high
reputation value is a bad reputation. Then it does the fol-
lowing: (a) given the current load, it computes the small-
est k0 such that all expected mail with reputations with
k ≤ k0 can be processed on the server (b) it looks up
the reputation of the IP address, and checks if it is higher
than k0. (If the IP address does not have a known rep-
utation value, and it does not belong to a cluster with a
known reputation, then the IP address is assigned a rel-
atively higher k0 value. If k0 ≤ k, then the connection
request of IP address is accepted, otherwise, it is rejected.
166
16th USENIX Security Symposium
USENIX Association