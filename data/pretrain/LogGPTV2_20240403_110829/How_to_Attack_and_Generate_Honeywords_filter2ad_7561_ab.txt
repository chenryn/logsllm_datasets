all fail to achieve the claimed security in a large part: When
allowed one guess, A’s success rate can be 29.29%∼32.62%,
but not the expected 5%. To ﬁnd potential countermeasures,
they preliminarily show that existing password models (e.g.,
Markov [40] and PCFG [58]) each has its own inherent
defects and cannot be readily used to generate honeywords.
Accordingly,
they propose to combine different password
models together to overcome the defects in each individual
model. However, all their experiments/proposals are still ad
hoc: Whether (and when) they are optimal
is unknown.
Wang et al. only brieﬂy introduced one honeyword-generation
method under trawling attackers, and as shown in Sec. IV, their
proposal is not optimal for their intended type of attackers, but
desirable for another type of attackers that is not considered
in [53]. Besides, they did not provide any human-attacker
evaluation for their honeyword-generation method.
that
At 2019, Akshima et al. [6] used heuristic arguments to
point out
the primary honeyword methods by Juels-
Rivest [35] and Chakraborty-Mondal [21] all fail to achieve
the claimed security. Further,
they proposed three ad hoc
honeyword-generation methods, two for legacy-UI and one for
modiﬁed-UI. We show in Appendix B that their two legacy-UI
methods are still subject to critical security issues.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
967
to evaluate the goodness (ﬂatness) of a generation method,
answering the open question left by Juels and Rivest [35].
• Generation methods. We develop four novel and efﬁcient
honeyword-generation methods based on various existing
probabilistic password-cracking models (e.g., Markov [40],
PCFG [58] and TarGuess PCFG [56]). The use of these pass-
word models requires signiﬁcant, novel and creative efforts,
and we show this by a series of exploratory investigations.
Our constructions not only resolve Juels-Rivest’s question
[35], but also give a way to retool cracking models to build
ﬂat honeywords, enabling future improvements of cracking
models to be easily incorporated into honeyword methods.
• An intensive evaluation. We implement our new meth-
ods and show their effectiveness by performing extensive
experiments under four kinds of attackers (A1∼A4), each
based on a different combination of info available to A:
public datasets, user PII and registration order. Our exper-
iments build on 11 large-scale datasets, including 105.44
million real-world passwords. To see how they perform
under semantic-aware humans, we further conduct a user
study of 11 trained human attackers. Results indicate that our
methods can survive both automated and human attackers.
• Some insights. We obtain a number of insights, some
expected and some surprising, from our theories and ex-
periments. Our attacking theories show that the “chafﬁng-
by-tweaking” category of methods is inherently problematic,
and all such methods are far from ﬂat (distinguishable). This
is opposed to the common belief in [35], is corroborated
by the empirical results in [53] and necessitates the design
of password-model based methods. As expected, password
models can be used to build ﬂat honeywords, but somewhat
surprisingly, the adaptive List model (not the expected PCFG
or Markov [40]) can generate nearly ﬂat honeywords under
the basic attacker who is with only public datasets.
A. System model
II. PRELIMINARIES
As shown in Fig. 1, four entities are involved in the honey-
word system: a user Ui, an authentication server S, a honey-
checker, and the attacker A. User Ui ﬁrst creates an account
(IDi, PWi) at the server S. Some PII may also be provided
to S, and this enables S to employ PII-aware honeyword
methods. Besides the normal procedures for user registration,
S carries out a command Gen(k; PWi): S generates a list
of k-1 distinct, decoy passwords (called honeywords) to store
along with Ui’s real password PWi, where k=20 as suggested
in [35]. PWi and its k-1 honeywords are called k sweetwords.
Generally, honeyword-generation methods can be classiﬁed
into two broad categories: password-model based (see Sec. IV)
and random replacement based (i.e., chafﬁng-by-tweaking in
[35]). Generally, random replacement based methods are also
real-password related: They generate honeywords explicitly re-
lating to the real password (e.g., tweaking-tail [35]); password-
model based methods are real-password unrelated, i.e., they
generate honeywords independent of the real password (e.g.,
Honeyindex [24] and all the four new methods in this work).
Fig. 1. Password (PW) authentication with honeywords. For better illustration,
here passwords are shown in plain-text, while in reality they are stored in
salted hash. The bottom of the ﬁgure shows some personal info about the
victim Ui, and exempliﬁes two sets of 13(=k-1) honeywords generated for
Ui’s password “tiger81” by two different methods: one by the hybrid method
[35] and one by our TarList method (see Sec. IV).
Note that, the honeyword system is essentially a bit similar
to distributed password storage (e.g., [5], [18]) that cryp-
tographically splits passwords across two or more servers.
While the former involves relatively few changes to the
server side and no changes to the client side,
the latter
necessitates substantial changes to both sides. In addition,
memory-hard functions (e.g., [10], [11]), which slow down
(but cannot eliminate) password guessing, are recommended to
pre-process passwords/honeywords before storage [12], [53].
In all, most prior art [6], [21], [24], [35] on honeywords
mainly employs an ad hoc approach to design and evaluate
new/existing methods. Particularly, little progress has been
made towards the key question of how best to generate and
evaluate honeywords when various types of info and varied
password models are available to A. What’s more, none of the
existing honeyword proposals (including [53]) have considered
an attacker with user-registration order and/or the victim’s PII.
C. Our contributions
Based on prior art [6], [21], [24], [35], here we take a
principled approach to honeyword research. We ﬁrst rigorously
address the problem of how best to attack a given honeyword
method under varied kinds of capabilities available to an
attacker (i.e., understanding the “sword”), and then forge the
“shield”—design the corresponding honeyword method based
on leading password models. Our underlying rationale is that,
only when one knows what’s A’s best attacking strategy, one
can ﬁgure out how to design the most effective countermea-
sures. In all, we make the following key contributions:
• Attacking theories. To characterize the attackers’ best
strategies, we, for the ﬁrst time, propose a series of theoretic
models based on varied kinds of capabilities available to an
attacker. Particularly, we are the ﬁrst to consider the realistic
attackers that exploit each victim’s personal information and
know the order of user registration. These models enable
us to design effective experiments with real-world datasets
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
968
Without loss of generality, we use Juels and Rivest’s ﬁrst
method [35], i.e. “Tweaking by tail” [35], as a representative
of non-password-model based methods. This method “tweaks”
the selected character positions of the real password PWi to
generate the k − 1 honeywords. Let t (e.g., t = 2 or 3) denote
the desired number of positions to tweak. Each character in the
last t positions of PWi is substituted by a randomly-selected
character of the same type: A digit is substituted by a digit, a
letter by a letter, and a symbol by a symbol. For example, if
PWi is loveu1, k=4 and t=2, then the sweetword list SWi
for Ui might be {lovea0, lovex7, lovee0, lovey3}.
B. Security model
Honeyword distinguishing attacker. The essential security
goal of any honeyword method is, when given user Ui’s
account, to generate a set of k-1 honeywords such that they
are indistinguishable from Ui’s real password PWi. This goal
is deﬁned against the honeyword distinguishing attacker A as
shown in Fig. 1, who has obtained the sweetword ﬁle, ofﬂine
guessed all the users’ sweetwords and employed S as an online
querying oracle. A’s honeyword online querying attempts will
be detected by the honeychecker, if A uses a honeyword to
log in. If the number of honeyword login exceeds the per-user
threshold T1 (e.g., 3), A will raise the alarm on Ui’s account.
A will also cause the system-wide alarm to be raised if A’s
honeyword login attempts exceed the system-wide threshold
T2 (e.g., 104). Thus, to avoid being detected, A shall try
honeywords as few as possible. Note that, the exact values of
T1 and T2 depend on the target system’s risk analysis results,
and are out of our scope. This explains why they have not
been discussed in the existing literature. Still, since the system
has to balance honeyword-distinguishing attacks and denial-of-
service (DoS) attacks, T2 should not be too small or too large,
and without loss of generality, we set T2=104 as with [53].
Attacker capabilities. As shown in Table I, we assume that
A has somehow already got access to the server S’s password
hash ﬁle, and knows all public info such as leaked password
lists, password policy and the honeyword method used by S
to generate honeywords. As hundreds of sites have leaked
their passwords (see [1]), A may also know some info about
the password distribution of the target system. This kind of
attacker (i.e., type-A1) is the basic attacker, and it has been
(implicitly) made in existing studies [6], [18], [24], [35]. To
make our attacking models more realistic, we also investigate
the scenario where some sweetwords are unknown to A.
As users love to build passwords using their own PII, a
practical method should not overlook this information. In
addition, users’ registration order is also useful for A. This
info is especially useful for A against adaptive password-
model based honeyword-generation methods. In such adaptive
methods, the underlying password-model keeps updating with
newly registered passwords, and newly generated honeywords
will only depend on existing passwords but not the future
passwords (similar to Honeyindex [24] and Akshima et al.’s
methods [6], which are analyzed in Appendix B). Therefore, A
can attack in the same order as the user registration order. As
ATTACKER CAPABILITIES CONSIDERED IN THIS WORK.
Attacker type
Distinguishing
attacker
PW
ﬁle
A1 X
A2 X
A3 X
A4 X
Public
info1
X
X
X
X
TABLE I
Personally
identiﬁable
info2
X
X
User reg-
istration
order
X
X
[6], [24], [35], [53]
Existing
literature
[53]3
None
None
1 Typical public info includes the various leaked password lists, password
policy and all the cryptographic algorithms (e.g., hash methods and the
honeyword-generation methods).
2 Such as name, birthday, gender, email, education and hobbies.
3 In [53], PII is only considered for attacking, but not for defense.
mentioned in Sec. I, this piece of info is often not considered
sensitive and can be obtained/inferred in a number of ways.
Other attackers. As discussed in [6], [24], [35], [53], other
threats against honeywords, such as multi-system intersection
attacks, DoS attacks and honeychecker-related attacks, are also
practical concerns. Fortunately, most of them can be well
mitigated. For example, multi-system intersection attacks arise
because users tend to reuse passwords across different ser-
vices, and they can be thwarted by cryptographic means [57].
To resist DoS attacks (that deliberately login with honeywords
to raise alarms), we can focus on producing ﬂat honeywords
in the generation phase, and the server S can take proper
measures (without sacriﬁcing too much security/usability) in
the authentication phase. For example, S can employ stricter
rate-limiting policies and Captcha schemes to thwart malicious
login attempts, and set customized alarm policies to give more
weight to strong honeywords than weak ones (as it would be
more difﬁcult to guess strong honeywords correctly [6]). Also
note that ﬂatter password-model based honeyword methods
might be easier to DoS attacks, because popular passwords are
now more likely to be selected as honeywords. Thus, S can
further employ blocklists and password strength meters (PSM,
like fuzzyPSM [54] and Zxcvbn [59] as suggested in [28]) to
reduce the use of weak passwords during user registration, and
in this case, weak honeywords shall similarly be blocked.
C. Evaluation metrics
This work adopts the two evaluation metrics proposed in
[53] to measure the advantages of a distinguishing attacker,
or equally the goodness of a honeyword method.
Flatness graph plots the chance y of ﬁnding the real password
by making x login attempts per user, where y ∈[0, 1] and
x≤k (actually, x≤T1). This metric measures the average-
case performance of a honeyword method. The ϵ-ﬂat metric
introduced in [35] is just the ﬁrst data point (x=1, ϵ=y|x=1)
on the ﬂatness graph, i.e., the ϵ-ﬂat metric is incorporated.
Success-number graph plots the number y of successfully
identiﬁed real passwords, when the attacker A has made a
total of x honeyword login attempts, where x≤T2. To ﬁnd
more real passwords, the best strategy for A is to ﬁrst try
these most probable passwords. Thus, this metric measures
the worst-case performance of a method.
D. Probabilistic password models
We introduce six representative probabilistic password mod-
els our new methods build on: PCFG [58], Markov [40], List
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:19:56 UTC from IEEE Xplore.  Restrictions apply. 
969
[53], and their corresponding targeted versions converted by
using the PII type-based tags [56]. They all require a training
set. We do not consider the neural-network-based model,
because it is ineffective when A’s guess number is small (e.g.,
≤T2) [43] and thus unsuitable for honeyword settings.
PCFG. This model was ﬁrst introduced by Weir et al. [58], and
it has been established to be one of state-of-the-art password
cracking algorithms by recent research (e.g., [40], [42], [56]).
This model treats passwords as a combination of segments.
For example, “wanglei@123” is divided into the L segment
“wanglei”, S segment “@” and D segment “123”, and its base
structure is L7S1D3. The probability of “wanglei@123”
Pr(wanglei@123) is the product of Pr(L7S1D3), Pr(L7 →
wanglei), Pr(S1 → @) and Pr(D3 → 123).
Markov. Unlike the PCFG-based model, there is a parameter
determining the Markov-based model [40]—the order of the
Markov chains. A Markov chain of order d, where d is a
positive integer, is a process with a Markov assumption:
Pr(ci|c1c2 ··· ci−2ci−1) = Pr(ci|ci−d ··· ci−1).
Count(ci−d ··· ci−1ci)
Count(ci−d ··· ci−1ci−1)
where Count(ci−d,··· , ci−1, ci) denotes the number of oc-
currences of the string ci−d ··· ci−1ci in the training set. That
is, the probability of the next character in a string is based
on a preﬁx of length d. Then, the probability of a string
s=c1c2 ··· cn is:
n∏
Pr(s) = Pr(c1) Pr(c2|c1)··· Pr(cn|cn−1ci−2 ··· c1)
=
.
=
Pr(ci|ci−1 ··· ci−d).
i=1
|D|
List is a simple yet useful model: ∀s ∈ D, PD(s) = Count(s)
,
where D is a multi-set (e.g., a leaked password dataset) and
Count(s) is the occurrences of password s in D.
TarPCFG. This model was ﬁrst proposed in [56] and also
called TarGuess-I. Besides the L, D, S tags originally deﬁned
in PCFG [58], TarPCFG deﬁnes a series of new type-based
PII tags (e.g., N1∼N7 and B1∼B10). For a type-based PII tag,
its subscript number denotes a particular sub-type of one kind
of PII usages but not the length matched, contrary to the L, D,
S tags. For instance, N stands for all kinds of name usages,
where N1 for full name (e.g., wang lei) and N2 for family
name (e.g., wang); B stands for all kinds of birthday usages,
and B1 for full birthday in YMD format, etc. Each PII tag can
then be operated in the same way with L/D/S tags. TarPCFG
outperforms PCFG by 412%∼740% within 100 guesses.
TarMarkov. As shown in [56], to convert a traditional Markov
model into a PII-enriched Markov model, one only needs to
include the type-based PII tags {N1, . . . , N7; B1, . . . , B10; . . .}
into the alphabet (cid:6) (e.g., (cid:6) = {95 printable ASCII characters}
in [40]) of the Markov n-gram model, and all operations for
these PII tags are the same with the atomic characters in (cid:6).
TarList. As the List model can be essentially seen as a PCFG
without the L, D and S tags, it can be similarly converted into
a targeted model with that of PCFG.