â€¢ Parse the hint â„ as(cid:0)(sk1, . . . , skğ‘‡ ), (ğ‘ƒ1, . . . , ğ‘ƒğ‘‡ )(cid:1).
â€¢ Let ğ‘¡ âˆˆ [ğ‘‡] be a value such that ğ‘– âˆˆ Eval(skğ‘¡).
(If no such value ğ‘¡ exists, abort.)
â€¢ Sample sknew â† GenWith(ğ‘›, ğ‘–).
â€¢ Compute:
ğ‘†ğ‘¡ â† Eval(skğ‘¡)
ğ‘Ÿ1 â†R ğ‘†ğ‘¡ (cid:114){ğ‘–}
skp1 â† Punc(skğ‘¡ , ğ‘–)
ğ‘1 â† (skp1, ğ‘Ÿ1).
ğ‘†new â† Eval(sknew)
ğ‘Ÿ0 â†R ğ‘†new (cid:114){ğ‘–}
skp0 â† Punc(sknew, ğ‘–)
ğ‘0 â† (skp0, ğ‘Ÿ0)
â€¢ Set st(cid:48) â† (ğ‘¡, sknew).
â€¢ Return (st(cid:48), ğ‘0, ğ‘1).
QueryRare(ğ‘–) â†’ (st(cid:48), ğ‘0, ğ‘1).
// The client asks each server for the parity of the database
ğ‘›âˆ’1
// records indexed by a freshly sampled random set of
// indices such that the symmetric diï¬€erence between the
// two sets contains ğ‘– and one other random index ğ‘Ÿğ›¾.
// The client also asks server ğ›¾ for the record at index ğ‘Ÿğ›¾.
â€¢ Sample a random bit ğ›¾ â†R {0, 1}.
â€¢ Sample sknew â† GenWith(ğ‘›, ğ‘–).
â€¢ Compute:
âˆš
ğ‘†new â† Eval(sknew)
ğ‘Ÿğ›¾ â†R ğ‘†new (cid:114){ğ‘–}
skp ğ›¾ â† Punc(sknew, ğ‘–)
ğ‘ğ›¾ â† (skp ğ›¾, ğ‘Ÿğ›¾)
ğ‘Ÿ Â¯ğ›¾ â†R ğ‘†new (cid:114){ğ‘Ÿğ›¾}
skp Â¯ğ›¾ â† Punc(sknew, ğ‘Ÿğ›¾)
ğ‘ Â¯ğ›¾ â† (skp Â¯ğ›¾, ğ‘Ÿ Â¯ğ›¾).
â€¢ Set st(cid:48) â† ğ›¾.
â€¢ Return (st(cid:48), ğ‘0, ğ‘1).
â€¢ If ğ›½ = 1:
// Rare case
â€“ Parse the state st(cid:48) as ğ›¾ âˆˆ {0, 1}
â€“ Set ğ·ğ‘– â† ğ‘Š0 âŠ• ğ‘Š1 âŠ• ğ‘‰ğ›¾.
â€“ Set â„(cid:48) â† â„.
â€¢ Return (â„(cid:48), ğ·ğ‘–).
// The hint is unmodiï¬ed.
880    30th USENIX Security Symposium
USENIX Association
fetch a record from the database. We set the probability of
each case such that the overall probability distribution of the
clientâ€™s queries hides the indices the client is interested in.
We now describe this in more detail.
Common case. Recall that at the start of the oï¬„ine phase, the
client holds the hint it received in the oï¬„ine phase, which
consists of a seed for a pseudorandom generator and a set
of ğ‘‡ hint words (ğ‘ƒ1, . . . , ğ‘ƒğ‘‡ ). The clientâ€™s ï¬rst task is to
expand the seed into a set of puncturable pseudorandom set
keys sk1, . . . , skğ‘‡ . (These are the same keys that the server
generated in the oï¬„ine phase.) Next the client searches for
a key skğ‘¡ âˆˆ {sk1, . . . , skğ‘‡ } such that the index of the clientâ€™s
desired record ğ‘– âˆˆ Eval(skğ‘¡).
âˆš
ğ‘›,
which contains the clientâ€™s desired index ğ‘–. The client also
holds the parity word ğ‘ƒğ‘¡ âˆˆ {0, 1}â„“ of the database records
indexed by ğ‘†ğ‘¡. The client sends the set ğ‘†ğ‘¡ (cid:114){ğ‘–} to the second
server. (To save communication, the client compresses this
set using puncturable pseudorandom sets.) The server returns
the parity word ğ‘Š1 of the database records indexed by this set
ğ‘†ğ‘¡ (cid:114){ğ‘–}. The client recovers its record of interest as:
At this point, the client holds a set ğ‘†ğ‘¡ = Eval(skğ‘¡) of size
(cid:16)âŠ• ğ‘—âˆˆğ‘†ğ‘¡
(cid:17) âŠ•(cid:16)âŠ• ğ‘—âˆˆğ‘†ğ‘¡(cid:114){ğ‘–} ğ· ğ‘—
(cid:17)
ğ· ğ‘—
ğ‘ƒğ‘¡ âŠ• ğ‘Š1 =
= ğ·ğ‘–.
âˆš
For security, it is critical that each server â€œseesâ€ each set
only once. Therefore, the client must not reuse the set ğ‘†ğ‘¡
for any future queries. Therefore, the client also samples a
ğ‘› indices in [ğ‘›], one of which is ğ‘–.
replacement set ğ‘†new of
The client then sends ğ‘†new (cid:114){ğ‘–} to the ï¬rst server (again,
compressed using puncturable pseudorandom sets), and the
ï¬rst server responds with the parity word ğ‘Š0 of the database
records indexed by this set. The client then replaces the set ğ‘†ğ‘¡
in its hint with the new set ğ‘†new and updates the corresponding
parity hint word to ğ‘ƒnew â† ğ‘Š0 âŠ• ğ·ğ‘–.
In this ï¬rst case, the sets that the client sends to the two
servers never contain the index ğ‘– of the clientâ€™s desired database
record. If the client would always use this query strategy, the
deï¬nitely not querying, eï¬€ectively leaking â‰ˆ 1/(âˆš
servers would learn which database records the client is
ğ‘› ln 2) bits
of information about ğ‘–. The next case prevents this leakage.
Rare case. With a small probability (roughly 2/âˆš
ğ‘›), the client
must send a set containing its desired index ğ‘– to each server.
ğ‘› values in [ğ‘›],
The client samples a random set ğ‘†new of
one of which is ğ‘–. The client chooses a server ğ›¾ â†R {0, 1} at
random and sends it ğ‘†new (cid:114){ğ‘–} (again, compressed), along
with the index of a random element ğ‘Ÿğ›¾ â†R ğ‘†new (cid:114){ğ‘–}. To the
other server Â¯ğ›¾ (cid:66) 1 âˆ’ ğ›¾, the client sends ğ‘†new (cid:114){ğ‘Ÿğ›¾} and, to
hide which server plays which role, a dummy value ğ‘Ÿ Â¯ğ›¾.
Each server replies with the parity word ğ‘Š of the database
records indexed by the set it has received. It also sends the
value of the database record ğ·ğ‘Ÿ. Now, the client can recover its
record of interest as: ğ·ğ‘– = ğ‘Š0 âŠ• ğ‘Š1 âŠ• ğ·ğ‘Ÿğ›¾, since âˆ€ğ›¾ âˆˆ {0, 1},
this sum is equal to
(cid:16)âŠ• ğ‘—âˆˆğ‘†new(cid:114){ğ‘–} ğ· ğ‘—
(cid:17) âŠ•(cid:16)âŠ• ğ‘—âˆˆğ‘†new(cid:114){ğ‘Ÿğ›¾} ğ· ğ‘—
(cid:17) âŠ• ğ·ğ‘Ÿğ›¾ = ğ·ğ‘–.
âˆš
To hide whether the client is in the â€œcommon caseâ€ or â€œrare
case,â€ the client sends dummy indices ğ‘Ÿ0, ğ‘Ÿ1 to the servers in
the common case to mimic its behavior in the rare case.
Remark (Pipelined queries). When a client makes many PIR
queries in sequence, it may want to issue a new query to the
servers before receiving the serversâ€™ response to its previous
query. Our scheme (Construction 1) allows the client to have
any number of queries in ï¬‚ight at once, while still using
only a single hint. The key observation is that the client can
generate the replacement set sknew as soon as it issues a query.
The client can thus issue a second query immediately after
issuing the ï¬rst, and a third query immediately after issuing the
secondâ€”the client just has to receive the serverâ€™s responses
in the order in which it issued its queries.
Remark. The clientâ€™s expected online query time in our con-
struction is linear in the size of the database, since the client
has to expand its set keys one by one in a random order, until
it ï¬nds a key of a set that contains the index of interest ğ‘–.
As in prior oï¬„ine/online PIR schemes [27], a client can use
a data structure to reduce the query time at the cost of in-
creasing its storage. Checklist uses a simple data structure
that has size linear in the database size ğ‘› but that supports
âˆš
constant-time queries. That is, the client stores a hash table
mapping database indices ğ‘– âˆˆ [ğ‘›] to â€œset pointersâ€ ğ‘— âˆˆ [ğœ†
ğ‘›]
such that ğ‘– âˆˆ Eval(sk ğ‘—). The client lazily populates this map
whenever it evaluates set keys and invalidates entries when-
ever it discards set keys. As a compromise between storage
and query time, the map contains at most one set pointer for
each database index. Therefore, discarding a set may leave
some database indices without valid set pointers, even though
other sets in the clientâ€™s hint may still contain those indices.
At query time, if the client fails to ï¬nd a set pointer for the
desired database index in the map, it falls back to exhaustively
searching through the hint. As it iterates through the hint, the
client â€œopportunisticallyâ€ adds set pointers to the map.
5 Oï¬„ine/online PIR
for dynamic dictionaries
PIR protocols typically treat the database as a static array of ğ‘›
records. To fetch a record, a PIR client must then specify the
index ğ‘– âˆˆ [ğ‘›] of the record. Our scheme of Section 4 follows
this approach as well. In contrast, Checklist, like many other
applications of PIR, needs to support dynamic databases and
key-value-style lookups. Speciï¬cally, we would like to view the
database as a list of key-value pairs ((ğ¾1, ğ‘‰1), . . . , (ğ¾ğ‘›, ğ‘‰ğ‘›)),
where ğ¾ğ‘– âˆˆ {0, 1}ğ‘˜ are the keys, and ğ‘‰ğ‘– âˆˆ {0, 1}â„“ are their
corresponding values. In Checklist, (i) a client should be able
to look up a value ğ‘‰ by its key ğ¾; and (ii) a server should be
able to insert, modify, and delete key-value pairs.
USENIX Association
30th USENIX Security Symposium    881
Bucket 0:
Bucket 1:
Bucket 2:
Bucket 3:
h0
h0
h1
h1
h2
h2
h3
[insertion]
[insertion]
h0
h1
h0
h2
h1
h2
h2
h3
(After 1 insertion.)
h0
h0
h1
h1
h2
h2
h3
[insertion]
h(cid:48)
h0
0
h1
h1
h2
h2
h3
(After 2 insertions.)
[insertion]
h(cid:48)
h0
0
h1
h1
h2
h2
h3
(After 3 insertions.)
(After 4 insertions.)
Figure 1: The database in our PIR scheme consists of many buckets, where the ğ‘–th bucket can hold 2ğ‘– database rows. The client holds a hint (hğ‘–)
corresponding to each non-empty bucket ğ‘–. The smaller buckets change frequently, but these hints are inexpensive to recompute. The larger
buckets change infrequently, and these hints are expensive to recompute.
5.1 Existing tool: PIR by keywords
Previous work has shown how to modify standard PIR
schemes to support key-value-style databases. Speciï¬cally,
Chor, Gilboa, and Naor [23] showed that it is possible to con-
struct so-called â€œPIR-by-keywordsâ€ schemes from traditional
PIR-by-index schemes in a black-box way. Modern PIR con-
structions [15] support PIR-by-keywords directly. The cost of
such schemes, both in communication and server-side compu-
tation, matches the cost of standard PIR, up to low-order terms.
The black-box PIR-by-keywords techniques [23] directly ap-
ply to oï¬„ine/online PIR schemes as well. Speciï¬cally, our
implementation of Checklist uses a simple PIR-by-keywords
technique, which is tailored at the preexisting design of the
Safe Browsing system. We describe this scheme in Section 6.3.
5.2 Handling changes with waterfall updates
Standard online-only PIR schemes do not need any special
machinery to meet handle database updates, since their clients
hold no state that depends on the database contents. The
servers in online-only PIR schemes can thus simply process
any changes to the database locally as they happen, and then
answer each query using the latest version of the database. In
contrast, clients in oï¬„ine/online PIR schemes hold prepro-
cessed â€œhintsâ€ about the database, and every change in the
database invalidates these hints.
The simple solution works poorly. The simplest way to
handle database updates is to have the servers compute a new
hint relative to the latest database state after every update. The
servers then send this updated hint to the client. The problem
is that if the rate of updates is relatively high, the cost of
regenerating these hints will be prohibitive.
Speciï¬cally, if the database changes at roughly the same
rate as the client makes queries (e.g., once per hour), the client
will have to download a new hint before making each query.
In this case, the server-side costs of generating these hints will
be so large as to negate the beneï¬t of using an oï¬„ine/online
PIR scheme in the ï¬rst place.
Our approach: Waterfall updates. Instead of paying the
hint-generation cost for the full database on each change, we
design a tiered update scheme, which is much more eï¬ƒcient.
Speciï¬cally, if there is a single database update between
our scheme is still ğ‘‚(âˆš
each pair of client queries, the asymptotic online cost of
ğ‘›)â€”the same cost as if the database
had not changed. As the frequency of updates increases, the
performance of our scheme gracefully degrades. Our design
builds on a classic idea for converting static data structures into
dynamic structures [10]. Cryptographic constructions using
this idea to handle data updates include oblivious RAMs [41],
proofs of retrievability [20, 77], searchable encryption [81],
and accumulators [68].
Our strategy is to have the servers store the database as an
array of ğµ = log ğ‘› sub-databases, which we call â€œbuckets.â€
(Here, we assume for simplicity that the number of records ğ‘›
is a power of two.) The ğ‘th bucket will contain at most 2ğ‘ key-
value pairs. In addition, the servers maintain a last-modiï¬ed
timestamp for each bucket. Initially, the servers store the entire
database in the bottom (biggest) bucket, and all other buckets
start out empty. As the database changes, the contents of the
buckets change as well.
When a client joins the system, it fetches a hint for each
bucket. Before making a query, the client updates its locally
stored hints. To do this, the client sends to the ï¬rst server the
timestamp ğœ at which it received its last hint. The server then
generates a fresh hint for each bucket that was modiï¬ed after ğœ,
and sends these new hints back to the client. To ï¬nd the value
associated with key ğ¾, the client then queries each of the ğµ
buckets in parallel for key ğ¾. If several buckets contain key ğ¾,
the client uses the value ğ‘‰ from the smallest bucket (i.e., the
bucket that was updated most recently).
Since the underlying oï¬„ine/online PIR-by-keywords
scheme supports only static databases, each time a bucket
changes, the server must regenerate from scratch a hint for this
bucket for every client. The key to achieving our cost savings
is that, as the database changes, the contents of the smallest
buckets will change frequently, but it is relatively inexpensive
for the servers to regenerate the hints for these buckets. The
contents of the larger bucketsâ€”for which hint generation is
expensiveâ€”will change relatively infrequently.
It remains to describe how the servers update the contents
of the buckets upon database changes. Let us ï¬rst consider
database insertions. When the servers want to add a new
pair (ğ¾, ğ‘‰) to the database, the servers insert that pair into
the topmost (smallest) bucket. Such an update can cause a
bucket ğ‘ to â€œï¬ll upâ€â€”to contain more than 2ğ‘ entries. When
this happens, the servers â€œï¬‚ushâ€ the contents of bucket ğ‘
down to bucket ğ‘ + 1. If this ï¬‚ush causes bucket ğ‘ + 1 to
882    30th USENIX Security Symposium
USENIX Association
ï¬ll up, the servers continue ï¬‚ushing buckets until all buckets
are below their maximum capacity. If the bottommost bucket
overï¬‚ows, the servers create a new bucket, twice the size
of the previous one. The two servers execute this process in
lockstep to ensure that their views of the database state remain
consistent throughout.
To remap an existing key ğ¾ to a new value ğ‘‰(cid:48), the servers
add the updated record (ğ¾, ğ‘‰(cid:48)) to the topmost bucket. When,
as a result of ï¬‚ushing, multiple pairs with the same key end