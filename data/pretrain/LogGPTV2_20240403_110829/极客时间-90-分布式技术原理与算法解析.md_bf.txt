# 特别放送 \| 那些你不能错过的分布式系统论文>  > 你好，我是聂鹏程。> > >>>  > 古人云"以史为鉴，可以知兴替。"说的就是追本溯源的力量。通过学习和思考技术的发展和演进，我们方能更好地把握未来。而对分布式技术追本溯源的方式，无疑就是精读相关经典轮文了。> > >>>  > 为此，今天我特地邀请了我的朋友刘梦馨，来与你系统分享下分布式系统领域的经典论文。你有时间和耐力的话，可以逐一阅读、学习下这些论文。> > >>>  > 刘梦馨是灵雀云容器平台高级研发工程师，负责容器平台的架构、容器网络方案的设计和实现，也是开源> Kubernetes 网络插件 Kube-OVN> 作者。他平时非常喜欢阅读论文，也总结了很多高效阅读论文的方法。> > >>>  > 话不多说，我们来看刘梦馨的分享吧。> > >你好，我是刘梦馨。 分布式系统领域有着最令人费解的理论，全链路的不确定性堪比物理中的量子力学。同时，分布式系统领域又有着当代最宏伟的计算机系统，Google、Facebook、亚马逊遍布全球的系统支撑着我们的信息生活。 显然，能够征服分布式系统的，都是理论和实践两手抓两手都要硬的强者。然而，分布式系统领域还有着最高的上手门槛，没有大规模的基础设施、没有潮水般的流量，分布式领域幽灵般的问题并不会浮出水面。 那么，我们应该**如何开启征服分布式系统的征程**呢？ 好在这条路上我们并不孤独。学术大牛们在五十年前就开始探索各方面理论上的问题，全球规模的互联网公司也有着丰富的实践和经验。而这些分布式领域人类的智慧，最终都沉淀为了一篇篇的经典论文。 和普通的技术文章相比，论文的发表有着极为严格的要求，随之而来的也是极高的质量。通过阅读分布式领域的经典问题，我们可以快速吸收前人的智慧，领略大型系统的风采，并收获最为宝贵的实战经验。 现在，就让我们从一篇篇经典论文开始，踏上征战分布式系统的征程吧！ 我**按照从理论到实践的顺序**，将经典的分布式系统论文分成了分布式理论基础、分布式一致性算法、分布式数据结构和分布式系统实战四类，帮助你快速找到自己需要的论文。 这些论文我都给到了标题，你可以直接去 Google学术里搜索。 分布式理论基础分布式理论基础部分的论文，主要从宏观的角度介绍分布式系统中最为基本的问题，从理论上证明分布式系统的不确定、不完美，以及相互间的制约条件。研读这部分论文，你可以了解经典的CAP 定理、BASE理论、拜占庭将军问题的由来及其底层原理。 有了这些理论基础，你就可以明白分布式系统复杂的根源。当再碰到一些疑难杂症，其他人不得其解时，你可以从理论高度上指明方向。 以下就是分布式理论基础部分的论文： 1.  Time, Clocks, and the Ordering of Events in a Distributed    System    2.  The Byzantine Generals    Problem    3.  Brewer's Conjecture and the Feasibility of Consistent, Available,    Partition-Tolerant Web    Services    4.  CAP Twelve Years Later: How the "Rules" Have    Changed    5.  BASE: An Acid    Alternative        6.  A Simple Totally Ordered Broadcast    Protocol    7.  Virtual Time and Global States of Distributed    Systems    分布式一致性算法只要脱离了单机系统，就会存在多机之间不一致的问题。因此，分布式一致性算法，就成了分布式系统的基石。 在分布式一致性算法这一部分，我将与你推荐 2PC、Paxos、Raft 和 ZAB等最知名的一致性算法。分布式算法的复杂度比普通算法要高出几个数量级，所以这部分论文是最为烧脑的一部分。 搞明白这部分论文，你的空间想象力和统筹规划能力都会得到质的提升。 1.  A Brief History of Consensus, 2PC and Transaction    Commit    2.  Paxos Made Simple        3.  Paxos Made Practical        4.  Paxos Made Live: An Engineering    Perspective        5.  Raft: In Search of an Understandable Consensus    Algorithm        6.  ZooKeeper: Wait-Free Coordination for Internet-Scale    Systems    7.  Using Paxos to Build a Scalable, Consistent, and Highly Available    Datastore        8.  Impossibility of Distributed Consensus With One Faulty    Process    9.  Consensus in the Presence of Partial    Synchrony        分布式数据结构分布式数据结构部分的论文，将与你介绍管理分布式存储问题的知名数据结构原理。通过它们，你可以构建自己的分布式系统应用。 这部分论文的涵盖范围大致包括两部分：一是，分布式哈希的四个著名算法Chord、Pastry、CAN 和 Kademlia；二是，Ceph 中使用的 CRUSH、LSM-Tree 和Tango 算法。 和分布式一致性算法类似，分布式数据结构也极其考验空间想象力和统筹规划能力。不过，在经过分布式一致性算法的锻炼后，相信这些对你来说已经不再是问题了。 1.  Chord: A Scalable Peer-to-Peer Lookup Service for Internet    Applications        2.  Pastry: Scalable, Distributed Object Location, and Routing for    Large-Scale Peer-to-Peer    Systems    3.  Kademlia: A Peer-to-Peer Information System Based on the XOR    Metric    4.  A Scalable Content-Addressable    Network    5.  Ceph: A Scalable, High-Performance Distributed File    System    6.  The    Log-Structured-Merge-Tree        7.  HBase: A NoSQL Database        8.  Tango: Distributed Data Structure over a Shared    Log    分布式系统实战分布式系统实战部分的论文，将介绍大量互联网公司在分布式领域的实践、系统的架构，以及经验教训。 Google的新老三驾马车，Facebook、Twitter、LinkedIn、微软、亚马逊等大公司的知名系统都会在这一部分登场。你将会领会到这些全球最大规模的分布式系统是如何设计、如何实现的，以及它们在工程上又碰到了哪些挑战。 1.  The Google File System        2.  BigTable: A Distributed Storage System for Structured    Data    3.  The Chubby Lock Service for Loosely-Coupled Distributed    Systems    4.  Finding a Needle in Haystack: Facebook's Photo    Storage    5.  Windows Azure Storage: A Highly Available Cloud Storage Service    with Strong Consistency        6.  Resilient Distributed Datasets: A Fault-Tolerant Abstraction for    In-Memory Cluster Computing        7.  Scaling Distributed Machine Learning with the Parameter    Server    8.  Dremel: Interactive Analysis of Web-Scale    Datasets    9.  Pregel: A System for Large-Scale Graph    Processing        10. Spanner: Google's Globally-Distributed    Database    11. Dynamo: Amazon's Highly Available Key-value    Store    12. S4: Distributed Stream Computing    Platform    13. Storm \@Twitter        14. Large-scale Cluster Management at Google with    Borg    15. F1 - The Fault-Tolerant Distributed RDBMS Supporting Google's Ad    Business    16. Cassandra: A Decentralized Structured Storage    System    17. MegaStore: Providing Scalable, Highly Available Storage for    Interactive Services        18. Dapper, a Large-Scale Distributed Systems Tracing    Infrastructure        19. Kafka: A distributed Messaging System for Log    Processing        20. Amazon Aurora: Design Considerations for High Throughput    Cloud-Native Relational    Databases        以上就是我为你准备的分布式系统经典论文清单了。这个清单里的每一篇论文，都是经典中的经典。很多论文对之后的工业界及学术界产生了翻天覆地的影响，开创了一个又一个火热的产业。 希望你没有被这个清单吓到，当你翻开这些论文后，就会发现它们的内容并不是高高在上，包含了很多很实际、很具体的问题。认真读下去，你甚至会有掌握了屠龙之技的快感，一发而不可收拾。 为了帮助你高效阅读这些论文，并汲取其中的精华，我再和你说说我阅读论文的一些心法吧。 如何高效地阅读论文？一般来说，单篇论文大概会有 15 到 20页的内容，**如果你是第一次读论文可以把重点放在前面的背景介绍、相关工作和概要设计上**。好的论文通常会很仔细地介绍背景知识，帮助你从宏观上先对整个问题有一个初步认识，了解当前现状。 接下来，你可以再**根据自己的兴趣，选择是否仔细阅读论文涉及的详细原理和设计**。这一部分，通常是论文中最精华的部分，包含了最具创新的理念和做法，内容通常也会比较长，需要花费较多的时间和精力去研究。这时，你可以根据自己的情况，选择一批论文重点突破。 论文最后通常是评测和数据展示部分。这部分内容对我们最大的参考价值在于，**学习作者的评测方法、用到的测试工具和测试样例**，以便将其运用到工作中。 阅读完一篇论文后，如果你觉得内容还不错的话，可以通过 Google学术去搜索相关的文章，找到所有引用这篇论文的新作品。这样一来，你就可以通过一篇经典论文不断深入，全面掌握一个领域。 最后，我希望你可以通过经典论文的助力，迅速建立起自己的知识武器库，来攻克日常工作中的难题。 ![](Images/c191f391e2aab7575517a886bbd7a681.png)savepage-src="https://static001.geekbang.org/resource/image/a4/8c/a42a16601611a1a72599ecfca434508c.jpg"}
# 28 \| 分布式高可靠之负载均衡：不患寡，而患不均你好！我是聂鹏程。今天，我来继续带你打卡分布式核心技术。到目前为止，我已经为你介绍了分布式起源、分布式协调与同步、分布式资源管理与负载调度、分布式计算技术、分布式通信技术和分布式数据存储。可以说，掌握了这些内容，基本上就掌握了分布式的关键技术。然而，只有可靠的分布式系统才能真正应用起来。那么，分布式系统的可靠性又是如何实现的呢？不要着急，接下来几篇文章，我会和你一起学习分布式可靠性相关的知识，包括负载均衡、流量控制、故障隔离和故障恢复。在这其中，负载均衡是分布式可靠性中非常关键的一个问题或技术，在一定程度上反映了分布式系统对业务处理的能力。比如，早期的电商抢购活动，当流量过大时，你可能就会发现有些地区可以购买，而有些地区因为服务崩溃而不能抢购。这，其实就是系统的负载均衡出现了问题。接下来，我们就一起来打卡分布式高可靠之负载均衡。什么是负载均衡？先举个例子吧。以超市收银为例，假设现在只有一个窗口、一个收银员：1.  一般情况下，收银员平均 2 分钟服务一位顾客，10 分钟可以服务 5    位顾客；        2.  到周末高峰期时，收银员加快收银，平均 1 分钟服务一位顾客，10    分钟最多服务 10 位顾客，也就是说一个顾客最多等待 10    分钟；    3.  逢年过节，顾客数量激增，一下增加到 30    位顾客，如果仍然只有一个窗口和一个收银员，那么所有顾客就只能排队等候了，一个顾客最多需要等待    30    分钟。这样购物体验，就非常差了。        那有没有解决办法呢？当然有。那就是新开一个收银窗口，每个收银窗口服务 15个顾客，这样最长等待时间从 30 分钟缩短到 15分钟。但如果，这两个窗口的排队顾客数严重不均衡，比如一个窗口有 5个顾客排队，另一个窗口却有 25个顾客排队，就不能最大化地提升顾客的购物体验。所以，尽可能使得每个收银窗口排队的顾客一样多，才能最大程度地减少顾客的最长排队时间，提高用户体验。看完这个例子，你是不是想到了一句话"不患寡，而患不均"？这，其实就是负载均衡的基本原理。通常情况下，**负载均衡可以分为两种**：1.  一种是请求负载均衡，即将用户的请求均衡地分发到不同的服务器进行处理；        2.  另一种是数据负载均衡，即将用户更新的数据分发到不同的存储服务器。        我在 [第 25篇文章  slate-object="inline"分享数据分布方法时，提到：数据分布算法很重要的一个衡量标准，就是均匀分布。可见，哈希和一致性哈希等，其实就是数据负载均衡的常用方法。那么今天，**我就与你着重说说服务请求的负载均衡技术吧。**分布式系统中，服务请求的负载均衡是指，当处理大量用户请求时，请求应尽量均衡地分配到多台服务器进行处理，每台服务器处理其中一部分而不是所有的用户请求，以完成高并发的请求处理，避免因单机处理能力的上限，导致系统崩溃而无法提供服务的问题。比如，有 N 个请求、M 个节点，负载均衡就是将 N 个请求，均衡地转发到这M 个节点进行处理。服务请求的负载均衡方法通常情况下，计算机领域中，在不同层有不同的负载均衡方法。比如，从网络层的角度，通常有基于DNS、IP报文等的负载均衡方法；在中间件层（也就是我们专栏主要讲的分布式系统层），常见的负载均衡策略主要包括轮询策略、随机策略、哈希和一致性哈希等策略。今天，我着重与你分析的就是，中间件层所涉及的负载均衡策略。接下来，我们就具体看看吧。轮询策略轮询策略是一种实现简单，却很常用的负载均衡策略，核心思想是服务器轮流处理用户请求，以尽可能使每个服务器处理的请求数相同。生活中也有很多类似的场景，比如，学校宿舍里，学生每周轮流打扫卫生，就是一个典型的轮询策略。**在负载均衡领域中，轮询策略主要包括顺序轮询和加权轮询两种方式**。首先，我们一起看看**顺序轮询**。假设有 6 个请求，编号为请求 1\~6，有 3台服务器可以处理请求，编号为服务器1\~3，如果采用顺序轮询策略，则会按照服务器 1、2、3的顺序轮流进行请求。如表所示，将 6 个请求当成 6个步骤： 1.       请求 1 由服务器 1 处理；        2.       请求 2 由服务器 2    进行处理。        3.       以此类推，直到处理完这 6    个请求。        ![](Images/7e63fe8d7cb530d7853ff8b44cf493e6.png)savepage-src="https://static001.geekbang.org/resource/image/fc/ee/fcaab73150188671e7ec789041019eee.jpg"}最终的处理结果是，服务器 1 处理请求 1 和请求 4，服务器 2 处理请求 2和请求 5，服务器 3 处理请求 3 和请求6。 接下来，我们看一下**加权轮询**。加权轮询为每个服务器设置了优先级，每次请求过来时会挑选优先级最高的服务器进行处理。比如服务器1\~3 分配了优先级{4，1，1}，这 6 个请求到来时，还当成 6个步骤，如表所示。1.       请求 1 由优先级最高的服务器 1 处理，服务器 1 的优先级相应减    1，此时各服务器优先级为{3，1，1}；        2.       请求 2 由目前优先级最高的服务器 1 进行处理，服务器 1 优先级相应减    1，此时各服务器优先级为{2，1，1}。        3.       以此类推，直到处理完这 6    个请求。每个请求处理完后，相应服务器的优先级会减    1。    ![](Images/b9ebf53b030b52b5aac9c7e1f8c00d68.png)savepage-src="https://static001.geekbang.org/resource/image/82/46/8255a6acab7187c77397fecafdefd846.jpg"}最终的处理结果是，服务器 1 处理请求 1\~4，服务器 2 处理请求 5，服务器3 会处理请求 6。以上就是顺序轮询和加权轮询的核心原理了。轮询策略的应用比较广泛，比如 **Nginx默认的负载均衡策略就是一种改进的加权轮询策略。**我们具体看看它的核心原理吧。首先，我来解释下 Nginx轮询策略需要用到的变量吧。1.  weight：配置文件中为每个服务节点设置的服务节点权重，固定不变。        2.  effective_weight：服务节点的有效权重，初始值为 weight。 在 Nginx    的源码中有一个最大失败数的变量    max_fails，当服务发生异常时，则减少相应服务节点的有效权重，公式为    effective_weight = effective_weight - weight /    max_fails；之后再次选取本节点，若服务调用成功，则增加有效权重，effective_weight    ++ ，直至恢复到 weight。        3.  current_weight：服务节点当前权重，初始值均为    0，之后会根据系统运行情况动态变化。        假设，各服务器的优先级是{4，1，1}，我还是将 6 个请求分为 6步来进行讲解，如表所示：1.       遍历集群中所有服务节点，使用 current_weight = current_weight +    effective_weight，计算此时每个服务节点的 current_weight，得到    current_weight 为{4，1，1}，total 为 4+1+1=6。选出 current_weight    值最大的服务节点即服务器 1 来处理请求，随后服务器 1 对应的    current_weight 减去此时的 total 值，即 4 - 6，变为了 -2    。    2.       按照上述步骤执行，首先遍历，按照 current_weight =    current_weight + effective_weight 计算每个服务节点 current_weight    的值，结果为{2，2，2}，total 为 6，选出 current_weight    值最大的服务节点。current_weight    最大值有多个服务节点时，直接选择第一个节点即可，在这里选择服务器 1    来处理请求，随后服务器 1 对应的 current_weight 值减去此时的    total，即 2 - 6，结果为    -4。    3.       以此类推，直到处理完这 6    个请求。        ![](Images/a4c68f5143b114ec355db0362025991e.png)savepage-src="https://static001.geekbang.org/resource/image/e7/56/e7e9d3e908bccd34fc4d5e9c9d3bcc56.jpg"}最终的处理结果为，服务器 1 处理请求 1、2、4、6，服务器 2 处理请求3，服务器 3 会处理请求 5。可以看到，与普通的加权轮询策略相比，这种轮询策略的优势在于，**当部分请求到来时，不会集中落在优先级较高的那个服务节点。**还是上面的例子，假设只有 4个请求，按照普通的加权轮询策略，会全部由服务器 1进行处理，即{1,1,1,1}；而按照这种平滑的加权轮询策略的话，会由服务器 1 和2 共同进行处理，即{1,1,2,1}。**轮询策略的优点**就是，实现简单，且对于请求所需开销差不多时，负载均衡效果比较明显，同时加权轮询策略还考虑了服务器节点的异构性，即可以让性能更好的服务器具有更高的优先级，从而可以处理更多的请求，使得分布更加均衡。但**轮询策略的缺点**是，每次请求到达的目的节点不确定，不适用于有状态请求的场景。并且，轮询策略主要强调请求数的均衡性，所以不适用于处理请求所需开销不同的场景。比如，有两个服务器（节点 A 和节点 B）性能相同，CPU个数和内存均相等，有 4 个请求需要处理，其中请求 1 和请求 3 需要 1 个CPU，请求 2 和请求 4 需要 2 个 CPU。根据轮询策略，请求 1 和请求 3 由节点A、请求 2 和请求 4 由节点 B 处理。由此可见，节点 A 和节点 B 关于 CPU的负载分别是 2 和4，从这个角度来看，两个节点的负载并不均衡。综上所述，**轮询策略适用于用户请求所需资源比较接近的场景**。随机策略随机策略也比较容易理解，指的就是当用户请求到来时，会随机发到某个服务节点进行处理，可以采用随机函数实现。这里，随机函数的作用就是，让请求尽可能分散到不同节点，防止所有请求放到同一节点或少量几个节点上。如图所示，假设有 5 台服务器 Server 1\~5可以处理用户请求，每次请求到来时，都会先调用一个随机函数来计算出处理节点。这里，随机函数的结果只能是{1,2,3,4,5}这五个值，然后再根据计算结果分发到相应的服务器进行处理。比如，图中随机函数计算结果为2，因此该请求会由 Server2处理。 ![](Images/7c513af9400977f9e3dabc2779a16a20.png)savepage-src="https://static001.geekbang.org/resource/image/be/3e/be9136621188cec945c0aadf19be133e.png"}这种方式的优点是，实现简单，但缺点也很明显，与轮询策略一样，每次请求到达的目的节点不确定，不适用于有状态的场景，而且没有考虑到处理请求所需开销。除此之外，随机策略也没有考虑服务器节点的异构性，即性能差距较大的服务器可能处理的请求差不多。因此，随机策略适用于，集群中服务器节点处理能力相差不大，用户请求所需资源比较接近的场景。比如，我在第 19 篇文章中提到的 RPC 框架Dubbo，当注册中心将服务提供方地址列表返回给调用方时，调用方会通过负载均衡算法选择其中一个服务提供方进行远程调用。关于负载均衡算法，Dubbo提供了随机策略、轮询策略等。哈希和一致性哈希策略无论是轮询还是随机策略，对于一个客户端的多次请求，每次落到的服务器很大可能是不同的，如果这是一台缓存服务器，就会对缓存同步带来很大挑战。尤其是系统繁忙时，主从延迟带来的同步缓慢，可能会造成同一客户端两次访问得到不同的结果。解决方案就是，利用哈希算法定位到对应的服务器。哈希和一致性哈希，是数据负载均衡的常用算法。我在 [第 25篇文章  slate-object="inline"介绍哈希与一致性哈希时，提到过：数据分布算法的均匀性，一方面指数据的存储均匀，另一方面也指数据请求的均匀。数据请求就是用户请求的一种，哈希、一致性哈希、带有限负载的一致性哈希和带虚拟节点的一致性哈希算法，同样适用于请求负载均衡。所以，**哈希与一致性策略的优点**是，哈希函数设置合理的话，负载会比较均衡。而且，相同 key的请求会落在同一个服务节点上，可以用于有状态请求的场景。除此之外，带虚拟节点的一致性哈希策略还可以解决服务器节点异构的问题。但其**缺点是**，当某个节点出现故障时，采用哈希策略会出现数据大规模迁移的情况，采用一致性哈希策略可能会造成一定的数据倾斜问题。同样的，这两种策略也没考虑请求开销不同造成的不均衡问题。应用哈希和一致性哈希策略的框架有很多，比如Redis、Memcached、Cassandra等，你可以再回顾下第 25 篇文章slate-object="inline"中的相关内容。除了以上这些策略，还有一些负载均衡策略比较常用。比如，根据服务节点中的资源信息（CPU，内存等）进行判断，服务节点资源越多，就越有可能处理下一个请求；再比如，根据请求的特定需求，如请求需要使用GPU 资源，那就需要由具有 GPU资源的节点进行处理等。对比分析以上，就是轮询策略、随机策略、哈希和一致性哈希策略的主要内容了。接下来，我再通过一个表格对比下这三种方法，以便于你学习和查阅。![](Images/b5d024569f83eee97dcd1773240bb888.png)savepage-src="https://static001.geekbang.org/resource/image/5c/29/5c9708fcd30753cfa2dc8ebd1acd6329.jpg"}知识扩展：如果要考虑请求所需资源不同的话，应该如何设计负载均衡策略呢？上面提到的轮询策略、随机策略，以及哈希和一致性哈希策略，主要考虑的是请求数的均衡，并未考虑请求所需资源不同造成的不均衡问题。那么，如何设计负载均衡策略，才能解决这个问题呢？其实，这个问题的解决方案有很多，常见的思路主要是对请求所需资源与服务器空闲资源进行匹配，也称调度。关于调度，不知你是否还记得第 11 篇文章slate-object="inline"所讲的单体调度？我们可以**使用单体调度的思路**，让集群选举一个主节点，每个从节点会向主节点汇报自己的空闲资源；当请求到来时，主节点通过资源调度算法选择一个合适的从节点来处理该请求。在这篇文章中，我提到了最差匹配和最佳匹配算法。这两种算法各有利弊，最差匹配算法可以尽量将请求分配到不同机器，但可能会造成资源碎片问题；而最佳匹配算法，虽然可以留出一些"空"机器来处理开销很大的请求，但会造成负载不均的问题。因此，它们适用于不同的场景，你可以再回顾下第 11 篇文章slate-object="inline"中的相关内容。除此之外，**一致性哈希策略**也可以解决这个问题：让请求所需的资源和服务器节点的空闲资源，与哈希函数挂钩，即通过将资源作为自变量，带入哈希函数进行计算，从而映射到哈希环中。比如，我们设置的哈希函数结果与资源正相关，这样就可以让资源开销大的请求由空闲资源多的服务器进行处理，以实现负载均衡。但这种方式也有个缺点，即哈希环上的节点资源变化后，需要进行哈希环的更新。总结今天，我主要带你学习了分布式高可靠技术中的负载均衡。首先，我以超市收银为例，与你介绍了什么是负载均衡。负载均衡包括数据负载均衡和请求负载均衡，我在第 25 篇文章slate-object="inline"中介绍的数据分布其实就是数据的负载均衡，所以我今天重点与你分享的是请求的负载均衡。然后，我与你介绍了常见的负载均衡策略，包括轮询策略、随机策略、哈希和一致性哈希策略。其中，轮询策略和随机策略，因为每次请求到达的目的节点不确定，只适用于无状态请求的场景；而哈希和一致性哈希策略，因为相同key的请求会落在同一个服务节点上，所以可以用于有状态请求的场景。最后，我再通过一张思维导图来归纳一下今天的核心知识点吧。![](Images/91adc614e6107c71a25725d888540060.png)savepage-src="https://static001.geekbang.org/resource/image/05/be/05ab2dc9bc1fa38073ef7044b6c6b3be.png"}加油，相信通过本讲的学习，你对分布式系统中的负载均衡有了一定的理解，也可以进一步对电商系统、火车票系统等涉及的请求负载均衡的问题进行分析了。加油，行动起来吧！思考题在分布式系统中，负载均衡技术除了各节点共同分担请求外，还有什么好处呢？我是聂鹏程，感谢你的收听，欢迎你在评论区给我留言分享你的观点，也欢迎你把这篇文章分享给更多的朋友一起阅读。我们下期再会！![](Images/c191f391e2aab7575517a886bbd7a681.png)savepage-src="https://static001.geekbang.org/resource/image/a4/8c/a42a16601611a1a72599ecfca434508c.jpg"}
# 29 \| 分布式高可靠之流量控制：大禹治水，在疏不在堵你好！我是聂鹏程。今天，我来继续带你打卡分布式核心技术。 在上一篇文章中，我带你学习了分布式高可靠中的负载均衡。负载均衡的核心在于，将用户请求均匀分配到多个处理服务器处理，以解决单个服务器的单点瓶颈问题。但，如果用户请求数非常多的话，即便实现了负载均衡，服务器能力达到上限，还是无法处理所有的用户请求。 比如，类似双十一、双十二的秒杀场景，用户流量突增时，即使做了负载均衡，我们仍然会感受到点击抢购时，需要等待较长的时间。这背后的原理是什么呢？ 你是不是想到了，这是因为系统控制了用户的请求量呢？没错，这就是今天我们要一起打卡的流量控制技术。 什么是流量控制？说到流量控制，如果你学过计算机网络的话，第一反应肯定是网络传输中的流量控制。网络传输中的流量控制，就是让发送方发送数据的速率不要太快，让接收方来得及接收数据，具体的实现方法就是滑动窗口。 简单来讲，滑动窗口指的是，在任意时刻，发送方都维持一个连续的允许发送的数据大小，称为发送窗口；接收方也会维持一个连续的允许接收的数据大小，称为接收窗口。每次发送方给接收方发送数据后，必须收到接收方返回的确认消息，发送窗口才可向后移动，发送新的数据。 接下来，我们通过一个简单的例子，来看看滑动窗口在网络流量控制中，是如何发挥作用的吧。如图所示，发送窗口和接收窗口大小均为1，发送方发送数据 D1 后，只有接收到来自接收方的确认消息ACK，发送窗口才可向后移动，即发送方才可以发送后续数据D2。 ![](Images/fefeb5a21cbca03df0cc7f26574b07ee.png)savepage-src="https://static001.geekbang.org/resource/image/c9/44/c9eecdcf84f654a1ec95cf611f50a244.png"}这是网络传输中的流量控制，那么**具体到分布式系统中，流量控制又是什么呢**？ 在前面提到的双十一、双十二秒杀场景中，用户流量突增，在这种高并发、大流量的情况下，服务器的处理能力成为电商系统的瓶颈，处理不好就会导致系统崩溃，服务不可用。而分布式系统中的流量控制，就是解决这类问题的一种关键技术。 通俗地说，分布式流量控制就是在分布式系统下，控制每个服务器接收的请求数，以保证服务器来得及处理这些请求，也就是说尽可能保证用户请求持续地被处理，而不是让大量的用户请求"阻塞"在服务器中，等待被执行。这就好比"大禹治水，在疏不在堵"。 接下来，我们就一起学习下分布式系统常用的流量控制策略吧。 分布式系统流量控制策略还记得 [第 21篇文章  slate-object="inline"中讲到的消息队列吗？消息队列就是实现流量控制的一种方法，通过一个消息队列来存放用户的消息，然后服务器到消息队列中逐个消费，就可以避免消息过多时服务器处理不过来的情况。 除此之外，分布式系统的流量控制策略还有很多，常用的主要包括两种：漏桶策略和令牌桶策略。 漏桶策略相信你看到"漏桶"两个字，头脑里应该已经有了一个漏桶的样子。确实，名字就已经很形象地说明了这种策略的含义。 如下图所示，有一个固定容量的水桶，桶底有一个小洞，水桶可以接收任意速率的水流，但无论水桶里有多少水，水从小洞流出的速率始终不变，桶里的水满了之后，水就会溢出。 ![](Images/33647cca181c36159309489632ec2e83.png)savepage-src="https://static001.geekbang.org/resource/image/46/fb/46199df7adfecb93498361d1e747b5fb.png"}漏桶策略借鉴上述原理，无论用户请求有多少，无论请求速率有多大，"漏桶"都会接收下来，但从漏桶里出来的请求是固定速率的，保证服务器可以处理得游刃有余。当"漏桶"因为容量限制放不下更多的请求时，就会选择丢弃部分请求。这种思路其实就是一种"宽进严出"的策略。 比如，在某段时间内，系统每秒会有 10个用户发出请求，但这些请求经过漏桶后，每秒始终只流出 2个请求，也就是说服务器每秒最多处理 2个请求。这样的话，无论请求速率有多大，都能达到限流的目的，避免服务器在短暂时间内需要处理大量请求，但由于处理能力受限导致系统崩溃，从而保证了系统的高可靠。 这种策略的好处是，做到了流量整形，即无论流量多大，即便是突发的大流量，输出依旧是一个稳定的流量。但其缺点是，对于突发流量的情况，因为服务器处理速度与正常流量的处理速度一致，会丢弃比较多的请求。但是，当突发大流量到来时，服务器最好能够更快地处理用户请求，这也是分布式系统大多数情况下想要达到的效果。 所以说，**漏桶策略适用于间隔性突发流量且流量不用即时处理的场景**，即可以在流量较小时的"空闲期"，处理大流量时流入漏桶的流量；不适合流量需要即时处理的场景，即突发流量时可以放入桶中，但缺乏效率，始终以固定速率进行处理。 目前，漏桶算法已经用于很多框架了，比如阿里开源的流量控制框架 Sentinel中的匀速排队限流策略，就采用了漏桶算法；分布式追踪系统 Jaeger中，有一种采集策略是速率限制类型，内部使用的也是漏桶算法等。 令牌桶策略令牌桶策略，也是一个很形象的名字，指的是桶里放着很多令牌，请求只有拿到令牌才能被服务器处理。 如图所示，有一个固定容量的存放令牌的桶，我们以固定速率向桶里放入令牌，桶满时会丢弃多出的令牌。每当请求到来时，必须先到桶里取一个令牌才可被服务器处理，也就是说只有拿到了令牌的请求才会被服务器处理。所以，你可以将令牌理解为门卡，只有拿到了门卡才能顺利进入房间。 ![](Images/4d6c6540455f07baf82ac6853303e56e.png)savepage-src="https://static001.geekbang.org/resource/image/31/88/31e10a5be4b2a45f60c929af19cedc88.png"}同样的，我们通过一个具体的例子，来加深对令牌桶策略的理解吧。 假设，令牌以每秒 3 个的速率放入到令牌桶中，桶的容量为10。通常情况下， 每秒会有 2个用户请求，请求到来时就会到桶里取一个令牌，由于请求的速率低于放令牌的速率，因此令牌桶里令牌会逐渐增多，直到达到桶的容量。超过桶容量后，令牌会被丢弃。 当大流量到来时，比如某个时刻来了 10 个请求，此时桶里有 10个令牌，因此，请求都会被服务器处理；但如果来的请求数不止 10个，令牌会被取完，多余的请求取不到令牌，也就没办法及时被服务器处理，需要等待令牌。 通过上述的例子，就能看出这种策略的好处：当有突发大流量时，只要令牌桶里有足够多的令牌，请求就会被迅速执行。通常情况下，令牌桶容量的设置，可以接近服务器处理的极限，这样就可以有效利用服务器的资源。因此，这种策略**适用于有突发特性的流量，且流量需要即时处理的场景**。 在实际使用中，令牌桶算法也很常见。比如，Google 开源工具包 Guava提供的限流工具类RateLimiter，就是基于令牌桶算法来完成限流的。 两种策略对比以上就是漏桶策略和令牌桶策略的核心原理了，接下来我们通过一张表格对比下这两种策略吧。 ![](Images/b6f8da2091d7ae6f0b395e760f4a760d.png)savepage-src="https://static001.geekbang.org/resource/image/7f/5e/7fd88d2b5ae52e0ca2eff1c4d957b65e.jpg"}Sentinel 流量控制工作原理我们都知道阿里的流量控制做得很好，特别是双十一、抢购等情况下。接下来，我以阿里开源的流量控制框架Sentinel为例，与你进一步介绍流量控制的工作原理。 Sentinel 的核心是，监控应用的并发线程数或 QPS（请求数 /每秒）指标，当达到系统设定的阈值时，Sentinel可以采取一定的策略对流量进行控制，以避免应用被瞬时高流量击垮，从而保证应用高可靠。 为此，在 Sentinel中，关于流量控制有两种方式：一种是通过并发线程数进行流量控制，另一种是通过QPS 指标进行流量控制。 **首先，我们看一下通过并发线程数进行流量控制。** 要理解这种限流方式，我需要先带你搞清楚什么是线程池。 我们知道，过多的线程会消耗非常多的系统资源，包括线程资源消耗、线程调度消耗等。为了解决这个问题，我们引入了线程池。线程池维护了多个启动着的线程，随时等待着去执行系统分配的任务，即系统每次需要处理任务时，可以直接从线程池中取线程，从而避免了创建和销毁线程的时间和资源等消耗。 同一时刻每个线程只能执行一个任务或请求，因此，可以通过并发线程数进行流量控制。我们看一个案例吧。 如图所示，假设现在线程池中有 3 个线程也就是说，最大并发处理数为3，现在有 2 个请求 Q1 和 Q2到来，由于请求数少于线程数，因此请求可以被并发执行。线程池中启动着的线程1 和线程 2会进行相应的处理，而不会创建新线程，除此之外，线程处理完请求后也不会被销毁，而是回到线程池中继续等待新的请求。 但如果现在同时有 4 个请求到来，那么只有 3个请求可以被并发处理，而剩下的一个请求要么丢弃，要么等待空闲线程。 ![](Images/baeba381e0943a67bd3520c1d0b616c6.png)savepage-src="https://static001.geekbang.org/resource/image/db/33/db6768e99d0fb5fb78a3b588f4b6ef33.png"}在分布式系统中，每个请求都会由一个线程去进行处理。当请求太多系统处理不过来时，意味着线程池可能已经被耗尽（线程池中无空闲线程），因此当请求过多时，执行请求的并发线程数自然会随之增加，当超过一定的阈值（比如线程池中线程总数）时，需要采取一定的策略来进行流量控制。 在 Sentinel中，就采用了直接拒绝的方式，即新来的请求会直接拒绝。 **然后，我们再看一下通过 QPS指标进行流量控制吧。** QPS 是指每秒的请求数，大流量也就意味着 QPS 大。当 QPS达到阈值时，Sentinel 提供了三种流量控制策略，分别是直接拒绝、预热（WarmUp）和匀速排队。 **直接拒绝，是最直接也是最暴力的方式**，与并发线程数流量控制采取的方式一致，就是当 QPS达到系统设定的阈值时，直接拒绝新来的请求。 这种策略乍一听起来确实不是很好，但对于系统处理能力确切已知的情况（即阈值设定为每秒能接受的最大处理请求数），却非常实用。当请求超出阈值时，可以直接拒绝，因为系统已经没有更多的能力来处理多余的请求了。因此，该策略适用于对系统处理能力确切已知的场景。 接下来，我们看看**预热**。当系统的 QPS长期处于一个较低水平时，一旦发生流量骤增，如果直接让系统每秒处理大量的请求，可能会因为服务器处理能力不足，导致系统崩溃。因此，Sentinel提供了一种"预热"机制，让系统的 QPS缓慢增加，在一定的时间内逐渐增加到上限。 下面以一个例子为例，带你进一步理解预热的原理。如下图所示，假设通常情况下系统每秒处理3 个请求，即QPS=3，当用户请求增加时，系统每秒处理的请求数相应增加，但不会一下子提高很多。比如，每秒增加1 个处理请求，逐步达到 QPS=10的处理上限，并不再继续增加，从而避免大流量一下子导致系统故障。 ![](Images/15f0f115293f244b3e908c7e4a318e60.png)savepage-src="https://static001.geekbang.org/resource/image/b1/15/b1202d83009b9821cdd8552c935c5a15.png"}可以看出，预热这种策略有点像是一种特殊的令牌桶：放令牌的速率通常保持在一个较低的水平，当流量突增时，放令牌的速率不会一下子提高到最高水平，而是会慢慢增加，直到增加到最大速率则不可再增加。因此，该策略与令牌桶策略的适用场景类似，即适用于具有突发特性的流量，且流量可以即时处理的场景。 **匀速排队**的思想，其实本质就是漏桶策略。它会严格控制系统每秒处理的请求数，请求数很多时，请求之间的间隔也会保持一致。 如图所示，当 QPS=5 时，每隔 200ms才允许服务器处理下一个请求。假设请求队列中有 10个请求瞬间到达，服务器不会一下子全处理完，而是按照请求的顺序，每 200ms处理一个请求，直到处理完所有请求。这时，处理的请求就像是在匀速排队，因此得名。 ![](Images/471bb95e1e6d93028d7621523f1def05.png)savepage-src="https://static001.geekbang.org/resource/image/17/ac/1762aebb4c415ef80f73593873f7f8ac.png"}该策略中，系统会设定一个时间间隔 T，假设最大排队时长设置为6T，上次请求通过的时刻为 t1。当新的请求在 t2时刻到来的话，则进行判断，首先查看是否还有其他请求在排队。如果没有请求在排队，分两种情况： 1.  当 t2 - t1 的值大于或等于时间间隔    T，请求可以通过；        2.  当 t2 - t1 的值小于 T 时，需要等待，直到 t2 - t1 的值达到时间间隔    T 时，才可以让请求通过。        而如果新请求到来时，已经有请求在排队，就需要计算该新请求的预期通过时间。比如，有3 个请求在排队，则该新请求预期通过时间为t1+4T，因为需要等到在该请求前面的请求都通过后该请求才可通过，且两个请求通过的时间间隔必须达到T 才可以。 另外，若排队的请求过多，新来的请求预期等待时间超出最大排队时长，即等待时间超过6T 时，则直接拒接这个请求。 现在我想你应该理解了为什么说匀速排队策略本质就是漏桶策略了吧。因此，匀速排队的适用场景与漏桶策略类似，即适用于间隔性突发流量且流量不用即时处理的场景。 知识扩展：什么是拥塞控制？它与流量控制的区别是什么？其实，在分布式领域拥塞控制与流量控制的区别还是蛮大的。为什么这么说呢？ 今天，我们讲述的流量控制，主要是指业务上的流量，即用户请求。而拥塞控制通常针对的是网络上传输的数据，即网络上数据传输出现拥塞时应当如何控制。所以，这两个概念不是一回事儿。 但是，**对于网络上数据的传输而言，流量控制与拥塞控制非常容易混淆。** 网络数据传输中，流量控制是指控制发送方和接收方的传输和接收速率在双方都可以接受的范围，通常使用的方法是滑动窗口；而拥塞控制是通过检测网络状况，随时疏通网络，避免网络中过多数据堆积，导致无法传输数据，包括慢启动与拥塞避免方法。如果你想深入了解拥塞控制的相关内容，可以自行查阅计算机网络的相关书籍。 总结今天，我主要带你学习了分布式高可靠技术中的流量控制。 首先，我以网络传输中的流量控制和电商系统的例子，和你引入了分布式系统中的流量控制，即控制每个服务器的请求数，以保证处理请求所需计算能力在服务器处理能力的上限之内，从而避免系统崩溃。 然后，我为你介绍了常见的流量控制策略，包括漏桶策略和令牌桶策略。其中，漏桶策略的核心是"宽进严出"，发送给服务器进行处理的请求速率固定，以避免超过服务器处理能力上限，导致系统崩溃，但这种方式不适合突发流量增加的场景。令牌桶策略的核心是，只要桶里有令牌，请求就可以被处理，只要在服务器处理能力内即可，所以适用于处理及时且处理速率非固定的场景。 最后，我和你分享了阿里开源的 Sentinel流量控制，并介绍了通过并发线程数和通过 QPS指标进行流量控制的两种方式。 最后，我再通过一张思维导图来归纳一下今天的核心知识点吧。 ![](Images/e459d4b7a6e69b3da707d9098b9248b4.png)savepage-src="https://static001.geekbang.org/resource/image/1f/e7/1f4cb85a61786d8a2080e8a59768eae7.png"}加油，相信通过本讲的学习，你对分布式系统中的流量控制有了一定的理解，也可以进一步对电商系统中抢购、秒杀中的流量控制问题进行分析了。加油，行动起来吧！ 思考题除了漏桶策略和令牌桶策略，你还知道哪些流量控制策略吗？它们的原理是什么呢？ 我是聂鹏程，感谢你的收听，欢迎你在评论区给我留言分享你的观点，也欢迎你把这篇文章分享给更多的朋友一起阅读。我们下期再会！ ![](Images/c191f391e2aab7575517a886bbd7a681.png)savepage-src="https://static001.geekbang.org/resource/image/a4/8c/a42a16601611a1a72599ecfca434508c.jpg"}