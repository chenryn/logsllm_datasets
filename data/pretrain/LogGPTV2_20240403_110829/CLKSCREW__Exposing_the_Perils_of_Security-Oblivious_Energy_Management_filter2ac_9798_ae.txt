feat_cache1, tracks the length of the second spike minus
a constant k1. The second feature, feat_cache2, tracks
the cumulative total of g after the second spike, until the
g > k2. We use a value of k1 = 140 and k2 = 15 for
our experiments. By continuously monitoring values of
g after the second spike, the timing anchor is conﬁgured
to be the point when g > k2.
To evaluate the use of this timing anchor, we need a
means to assess when and how the speciﬁc invocation of
the FLIPENDIANNESS is faulted. First, we observe that
the memory buffer used to store Nrev is hard-coded to an
address 0x0FC8952C within Trustzone, and this buffer is
not zeroed out after the validation of each certiﬁcate. We
downgrade the ﬁrmware version to MMB29Q (Feb, 2016),
so that we can leverage a Trustzone memory safety viola-
tion vulnerability [17] to access the contents of Nrev after
the fourth certiﬁcate in the chain has been validated16.
Note that this does not affect the normal operation of the
chain validation because the relevant code sections for
these operations is identical across version MMB29Q (Feb,
2016) and MOB31S (Jan, 2017).
With this timing anchor, we perform a grid search for
the faulting parameters, Ffreq_hi, Fdur and Fpdelay that can
best induce faults in FLIPENDIANNESS. The parame-
ters Ffreq_hi = 3.99GHz and Fdur = 1 are observed to be
able to induce faults in FLIPENDIANNESS reliably. The
value of the pre-fault delay parameter Fpdelay is crucial
in controlling the type of byte(s) corruption in the tar-
get memory buffer Nrev. With different values of Fpdelay,
we plot the observed faults and failed attempts based on
the values of feat_cache1 and feat_cache2 in Figure 12.
16We are solely using this vulnerability to speed up the search for
the faulting parameters. They can be replaced by more accurate and
precise side-channel-based proﬁling techniques.
Each faulting attempt is considered a success if any bytes
within Nrev are corrupted during the fault.
Adaptive pre-delay. While we see faults within the tar-
get buffer, there is some variability in the position of the
fault induced within the buffer. In Figure 13, each value
of Fpdelay is observed to induce faults across all parts of
the buffer. To increase the precision in faulting, we mod-
ify the fault to be delivered based on an adaptive Fpdelay.
5.4 Fault Model
Based on the independent variables feat_cache1 and
feat_cache2, we build linear regression models to predict
Fpdelay that can best target a fault at an intended posi-
tion within the Nrev buffer. During each faulting attempt,
Fpdelay is computed only when the timing anchor is de-
tected. To evaluate the efﬁcacy of the regression models,
we collect all observed faults with the goal of injecting a
fault at byte position 141. Figure 14 shows a signiﬁcant
clustering of faults around positions 140 - 148.
More than 80% of the faults result in 1-3 bytes be-
ing corrupted within the Nrev buffer. Many of the faulted
values suggest that instructions are skipped when the
fault occurs. An example of a fault within a segment of
the buffer is having corrupted the original byte sequence
from 0xa777511b to 0xa7777777.
5.5 Putting it together
We use the following faulting parameters to target faults
to speciﬁc positions within the buffer: Fθ , RSA = {Fvolt =
1.055V, Fpdelay = adaptive, Ffreq_hi = 3.99GHz, Fdur =
1, Ffreq_lo = 2.61GHz}.
Factorizable modulus NA. About 20% of faulting at-
tempts (1153 out of 6000) result in a successful fault
within the target Nrev buffer. This set of faulted N values
consists of 805 unique values, of which 38 (4.72%) are
factorizable based on the algorithm described in § 5.2.
For our attack, we select one of the factorizable NA,
USENIX Association
26th USENIX Security Symposium    1069
180190200210220230feat_cache2203040506070feat_cache1fault failurefault success2.02.53.03.54.04.55.05.56.06.5pre-fault delay loops, Fpdelay1e4050100150200250position of first glitched byte230235240245250255260265270(feat_cache1 + feat_cache2)extends even to cloud computing providers. Since 2015,
Amazon AWS offers EC2 VM instances [16] where
power management controls are exposed within the vir-
tualized environment. In particular, EC2 users can ﬁne-
tune the processor’s performance using P-state and C-
state controls [8]. This warrants further research to as-
sess the security ramiﬁcations of such user-exposed en-
ergy management controls in the cloud environment.
Figure 14: Histogram of observed faults and where the
faults occur. The intended faulted position is 141.
6.2 Hardware-Level Defenses
where two bytes at positions 141 and 142 are corrupted.
We show an example of this faulted and factorizable
modulus in Appendix A.4.
Actual attack. Using the above selected NA, we embed
(cid:48)
A into the widevine trustlet. Then
our attack signature S
we conduct our CLKSCREW faulting attempts while in-
voking the self-signed app. On average, we observe one
instance of the desired fault in 65 attempts.
6 Discussion and Related Works
6.1 Applicability to other Platforms
Several highlighted attack enablers in preceding sections
apply to other leading architectures.
In particular, the
entire industry is increasingly moving or has moved to
ﬁne-grained energy management designs that separate
voltage/frequency domains for the cores. We leave the
exploration of these architectures to future research.
Intel.
Intel’s recent processors are designed with the
base clock separated from the other clock domains for
more scope of energy consumption optimization [32,35].
This opens up possibilities of overclocking on Intel pro-
cessors [23]. Given these trends in energy management
design on Intel hardware and the growing prevalence
of Intel’s Secure Enclave SGX [34], a closer look at
whether the security guarantees still hold is warranted.
ARMv8.
the ARM
big.LITTLE design that uses non-symmetric cores (such
as the “big” Cortex-A15 cores, and the “LITTLE”
Cortex-A7 cores) in same system [36]. Since these cores
are of different architectures, they exhibit different en-
ergy consumption characteristics. It is thus essential that
they have separate voltage/frequency domains. The use
of separate domains, like in the 32-bit ARMv7 architec-
ture explored in this work, expose the 64-bit ARMv8
devices to similar potential dangers from the software-
exposed energy management mechanisms.
Cloud computing providers. The need to improve en-
ergy consumption does not just apply to user devices; this
The ARMv8 devices adopt
Operating limits in hardware. CLKSCREW requires
the hardware regulators to be able to push voltage/fre-
quency past the operating limits. To address this, hard
limits can be enforced within the regulators in the form
of additional limit-checking logic or e-fuses [55]. How-
ever, this can be complicated by three reasons. First,
adding such enforcement logic in the regulators requires
making these design decisions very early in the hardware
design process. However, the operational limits can only
be typically derived through rigorous electrical testing in
the post-manufacturing process. Second, manufacturing
process variations can change operational limits even for
chips of the same designs fabricated on the same wafer.
Third, these hardware regulators are designed to work
across a wide range of SoC processors. Imposing a one-
size-ﬁts-all range of limits is challenging because SoC-
speciﬁc limits hinder the portability of these regulators
across multiple SoC. For example, the PMIC found on
the Nexus 6 is also deployed on the Galaxy Note 4.
Separate cross-boundary regulators. Another mitiga-
tion is to maintain different power domains across secu-
rity boundaries. This entails using a separate regulator
when the isolated environment is active. This has two
issues. First, while trusted execution technologies like
Trustzone and SGX separate execution modes for secu-
rity, the different modes continue to operate on the same
core. Maintaining separate regulators physically when
the execution mode switches can be expensive. Sec-
ond, DVFS components typically span across the system
stack. If the trusted execution uses dedicated regulators,
this implies that a similar cross-stack power manage-
ment solution needs to be implemented within the trusted
mode to optimize energy consumption. Such an imple-
mentation can impact the runtime of the trusted mode
and increase the complexity of the trusted code.
Redundancy/checks/randomization. To mitigate the
effects of erroneous computations due to induced faults,
researchers propose redesigning the application core chip
with additional logic and timing redundancy [13], as well
as recovery mechanisms [33]. Also, Bar-El et al. suggest
building duplicate microarchitectural units and encrypt-
ing memory bus operations for attacks that target mem-
1070    26th USENIX Security Symposium
USENIX Association
050100150200250Position of first faulted byte in the Nrev buffer051015202530Frequency of faultsory operations [13]. Luo et al. present a clock glitch
detection technique that monitors the system clock sig-
nal using another higher frequency clock signal [41].
While many of these works are demonstrated on FP-
GAs [58] and ASICs [54], it is unclear how feasible it
is on commodity devices and how much chip area and
runtime overhead it adds. Besides adding redundancy,
recent work proposes adding randomization using recon-
ﬁgurable hardware as a mitigation strategy [59].
6.3 Software-Level Defenses
Randomization. Since CLKSCREW requires some de-
gree of timing precision in delivering the faults, one
mitigation strategy is to introduce randomization (via
no-op loops) to the runtime execution of the code to
be protected. However, we note that while this miti-
gates against attacks without a timing anchor (AES at-
tack in § 4), it may have limited protection against at-
tacks that use forms of runtime proﬁling for the timing
guidance (RSA attack in § 5).
Redundancy and checks. Several software-only de-
fenses propose compiling code with checksum integrity
veriﬁcation and execution redundancy (executing sensi-
tive code multiple times) [13, 15]. While these defenses
may be deployed on systems requiring high dependabil-
ity, they are not typically deployed on commodity de-
vices like phones because they impact energy efﬁciency.
6.4 Subverting Cryptography with Faults
Boneh et al. offer the ﬁrst DFA theoretical model to
breaking various cryptographic schemes using injected
hardware faults [22]. Subsequently, many researchers
demonstrate physical fault attacks using a range of so-
phisticated fault injection equipment like laser [24, 25]
and heat [29]. Compared to these attacks including all
known undervolting [14,45] and overclocking [20] ones,
CLKSCREW does not need physical access to the tar-
get devices, since it is initiated entirely from software.
CLKSCREW is also the ﬁrst to demonstrate such at-
tacks on a commodity device. We emphasize that while
CLKSCREW shows how faults can break cryptographic
schemes, it does so to highlight the dangers of hard-
ware regulators exposing software-access interfaces, es-
pecially across security trust boundaries.
6.5 Relation to Rowhammer Faults
Kim et al. ﬁrst present reliability issues with DRAM
memory [37] (dubbed the “Rowhammer” problem).
Since then, many works use the Rowhammer
is-
sue to demonstrate the dangers of such software-
induced hardware-based transient bit-ﬂips in practical
scenarios ranging from browsers [30], virtualized en-
vironments [50], privilege escalation on Linux ker-
nel [52] and from Android apps [57]. Like Rowham-
mer, CLKSCREW is equally pervasive.
However,
CLKSCREW is the manifestation of a different at-
tack vector relying on software-exposed energy man-
agement mechanisms. The complexity of these cross-
stack mechanisms makes any potential mitigation against
CLKSCREW more complicated and challenging. Fur-
thermore, unlike Rowhammer that corrupts DRAM
memory, CLKSCREW targets microarchitectural oper-
ations. While we use CLKSCREW to induce faults in
memory contents, CLKSCREW can conceivably affect a
wider range of computation in microarchitectural units
other than memory (such as caches, branch prediction
units, arithmetic logic units and ﬂoating point units).
7 Conclusions
As researchers and practitioners embark upon increas-
ingly aggressive cooperative hardware-software mecha-
nisms with the aim of improving energy efﬁciency, this
work shows, for the ﬁrst time, that doing so may create
serious security vulnerabilities. With only publicly avail-
able information, we have shown that the sophisticated
energy management mechanisms used in state-of-the-art
mobile SoCs are vulnerable to conﬁdentiality, integrity
and availability attacks. Our CLKSCREW attack is able
to subvert even hardware-enforced security isolation and
does not require physical access, further increasing the
risk and danger of this attack vector.
While we offer proof of attackability in this paper, the
attack can be improved, extended and combined with
other attacks in a number of ways. For instance, using
faults to induce speciﬁc values at exact times (as opposed
to random values at approximate times) can substan-
tially increase the power of this technique. Furthermore,
CLKSCREW is the tip of the iceberg: more security vul-
nerabilities are likely to surface in emerging energy opti-
mization techniques, such as ﬁner-grained controls, dis-
tributed control of voltage and frequency islands, and
near/sub-threshold optimizations.
Our analysis suggests that there is unlikely to be a
single, simple ﬁx, or even a piecemeal ﬁx, that can en-
tirely prevent CLKSCREW style attacks. Many of the
design decisions that contribute to the success of the at-
tack are supported by practical engineering concerns. In
other words, the root cause is not a speciﬁc hardware or
software bug but rather a series of well-thought-out, nev-
ertheless security-oblivious, design decisions. To pre-
vent these problems, a coordinated full system response
is likely needed, along with accepting the fact that some
modest cost increases may be necessary to harden en-
ergy management systems. This demands research in a
USENIX Association
26th USENIX Security Symposium    1071
number of areas such as better Computer Aided Design
(CAD) tools for analyzing timing violations, better val-
idation and veriﬁcation methodology in the presence of
DVFS, architectural approaches for DVFS isolation, and
authenticated mechanisms for accessing voltage and fre-
quency regulators. As system designers work to invent
and implement these protections, security researchers
can complement these efforts by creating newer and ex-
citing attacks on these protections.
Acknowledgments
We thank the anonymous reviewers for their feedback
on this work. We thank Yuan Kang for his feedback,
especially on the case studies. This work is supported by
a fellowship from the Alfred P. Sloan Foundation.
References
[1] Firmware update for Nexus 6 (shamu). https://dl.goo
gle.com/dl/android/aosp/shamu- mob31s- fac
tory-c73a35ef.zip. Factory Images for Nexus and Pixel
Devices.
[2] MSM Subsystem Power Manager (spm-v2). https://andr
oid.googlesource.com/kernel/msm.git/+/andr
oid-msm-shamu-3.10-lollipop-mr1/Documentat
ion/devicetree/bindings/arm/msm/spm-v2.txt.