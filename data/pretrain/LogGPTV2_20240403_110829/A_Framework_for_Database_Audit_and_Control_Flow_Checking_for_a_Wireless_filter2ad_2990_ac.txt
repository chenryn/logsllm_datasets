from 8% to  14%. In  fact,  as the error rate  increases  above 
the  audit  frequency,  the  percentage  of  escaped  errors  in- 
creases slowly. These results show that the database audit is 
useful  in  removing  data errors and  preventing  error propa- 
gation  under  different  error rates  and  that  it does not  break 
down, even  when  the error rate  is high. The curve shows a 
gradual  change instead  of an  abrupt jump as the error inter- 
arrival  time  crosses the audit period;  this indicates  continu- 
ity in the performance of audit. 
Table 2: Experiment Parameters 
Total number of injected errors 
= 3000 
Number of errors escaped from au- 
dits and affecting application 
Number of errors caught by audits 
Other (number of errors escaped 
from audits but having no effect on 
application) 
Average call setup time (msec) 
Without 
Audits 
With Audits 
1884  (63%) 
402(13%) 
N/A 
2543  ( 8 5 % )  
1 I  16  (37%) 
55  (2%) 
I60 
270 
Table 4: Breakdown of Inserted and Detected Errors 
T 
T  Oi6 
0.14  In - - 
a 
0.12  U" 
U 
0.1 
0 In 
0 
5 
- 
m n 
0.08 
0.06 
0.04 
0.02 
0 4  
I 
I  P 
0 
2 
4 
8 
10 
16 
6 
Fault Inter-Arrival Time (seconds) 
12 
14 
18 
20 
Figure 3: Escaped Errors under Different Error Rates 
In  the region  for  fault/error  inter-arrival  time  less  than  four 
seconds (in  Figure  3), there is a seeming  contradiction:  the 
number of escapes increases, but  the percentage  of escapes 
decreases.  This  happens  because,  although  the  number  of 
errors in the database  at these error rates is high, escapes as 
a  percentage  are  relatively  low.  This is  not  an  acceptable 
situation,  however,  because  each failure  resulting  from  the 
escapes  may  need  to  be  recovered,  resulting  in  significant 
overhead, i.e., lower availability. 
230 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
5.2  Overhead in Database API 
Figure  4  shows  the  average  running  times  of  the  database 
API  functions  that  have  been  modified  to  support  various 
audit functionalities  (see Table  I).  The results  are obtained 
by executing each function in its original and modified  form 
200 times on  a Sun UltraSPARC-2  workstation  running  So- 
lark 2.7. The lighter portion  of  each bar indicates the  aver- 
age  execution  time  of  the  original  version,  and  the  darker 
portion  shows the time  overhead  introduced  by  the  modifi- 
cations made to each function. The average running times of 
individual  functions  are on  the order of tens  or hundreds  of 
microseconds,  and  the  overhead  ranges  from  6.5%  (for 
DBinit)  to  45%  (for  DBwrite-rec).  In  the  latter  case,  the 
major  contributor  to the  overhead  is  the  time  necessary  to 
notify  the  audit  process  that  a  database  client  performed  a 
write operation. Recall  that this notification  is used  to initi- 
ate  event-triggered  audit.  Using  periodic  audit  eliminates 
this source of overhead. 
Im  Original  DE-API 
Modified DI  4PI 
- 
500 
600 
700 
300 
microseconds 
400 
DBwrite-rec 
DBwrite_lld 
DBread-rec 
DBread-lld 
DBmove 
DBclase 
DBinit 
0 
100 
ZOO 
Figure 4: Run-Time Overhead of Modified DB-API 
The preceding  results  show that  13% of  errors in  the data- 
base  propagate  to  the  client,  i.e.,  the  client  accesses  and 
subsequently  operates  on  incorrect  data.  This can  make  it 
impossible  to  set  up  the  new  incoming  call,  or  the  call- 
processing  application  may  crash  losing  all  calls  in  pro- 
gress.  In  this  scenario,  hardwarekoftware-based  recovery 
might be required  to restore system operation. The question 
is:  to what extent does client  misbehavior  cause  corruption 
to the database, potentially  leading  to the same failure sce- 
nario described above? The next  section attempts to answer 
this question. 
6 
Joint Assessment of Data Audit and Control 
Flow Checking Applied to Call-Processing 
In  this  section,  we  briefly  describe  a  new  control  flow 
checking  technique to preemptively  (i.e.,  before  an applica- 
tion  crash) detect  control  flow errors that  impact  the  appli- 
cation (see [2] for details). We then provide details of error 
injection  based  evaluation of ( I )  the impact of control  flow 
errors in  the  client  on  the  database  and  (2) the joint  effec- 
tiveness  of  preemptive  control  flow  checking  and  data  au- 
dits  in  preventing  error  propagation,  application  crashes, 
and hangs. 
6.1  Preemptive Checking Principle 
To protect  the  control  flow of  the  application,  we  propose 
the rregmptive _Control Signatures (PECOS) technique  [2]. 
PECOS  monitors  the runtime  control  path  taken  by  an  ap- 
plication  and compares this  with  the set of expected  control 
paths to  validate  the  application  behavior.  The scheme can 
handle situations  in  which  the  control  paths  are either  stati- 
cally or dynamically (i.e., at runtime) determined. 
The  application 
is  decomposed  into  branch-free  basic 
blocks  at  the  assembly  level;  a  Control  Flow  Instruction 
(CFI) terminates  each basic  block.  A  group of  PECOS in- 
structions  (an Assertion  Block) is embedded in  the instruc- 
tion  stream  before  each  CFI  instruction.  The  Assertion 
Block contains  ( I )   the  set  of  valid  target  addresses (or  ad- 
dress offsets) the application  may jump to, which  are deter- 
mined  either at compile  time  or at runtime, and  (2) code to 
determine  the runtime  target  address. The determination  of 
the  runtime  target  address  and  its  comparison  against  the 
valid addresses is done before the jump to the target address 
is made, i.e., preemptively.  In case of an error, the Assertion 
Block  raises  a  divide-by-zero exception, which  IS  handled 
by  the  PECOS  signal  handler.  The  signal  handler  checks 
whether  the  problem  was  caused  by  a  control  flow error, 
and  if  so takes  a  recovery  action, e.g.,  terminates  the  mal- 
functioning thread  of execution. 
6.1.1  PECOS Instrumentation 
To automate  the  instrumentation,  we  developed  a  PECOS 
parser,  which embeds assertions  into the application  assem- 
bly code. The current parser is implemented  for the SPARC 
architecture.  At compile time,  the  PECOS tool  instruments 
the  application  assembly  code with  Assertion  Blocks.  Note 
that  the Assertion  Block  itself does not  introduce additional 
CFIs.  Since  we  are  trying  to  protect  a  CFI,  it  defeats the 
purpose to have the Assertion Block insert any further CFIs. 
The task  of  the  Assertion  Block can  be  broken  down  into 
two subtasks: 
1.  Determine  the  runtime  target  address  of  the  CFI  (re- 
ferred to as x,,, in the following discussion). 
2.  Compare the runtime  target  address with  the  valid  tar- 
get  addresses determined  by  a compile-time  analysis or 
runtime  computation.  In  general,  the  number  of  valid 
target  addresses  can  be  one  (jump),  two  (branch), or 
many  (calls or returns). For two valid  target  addresses, 
X I  and X 2 ,  the resulting control  decision  implemented 
by  the Assertion Block  is shown in Figure 5 .  The com- 
parison  is designed so that an impending  illegal control 
flow will cause a divide-by-zero  exception  in the calcu- 
lation of the variable ID, indicating an error. 
1. Determine the r u n t i m e  target address  [= X,,,,] 
2. Extract  the list of  valid  target addresses  [= ( X  1 . X 2 ) ]  
3. Calculate ID  := X,,,  *  I/P, 
where, P  =  ![(X,,,,-X  1 )   *  (X,,,,-X2)1 
Figure 5: Control Decision in the Assertion Block 
23 1 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
6.1.2  Error Injection Setup 
To  evaluate  the  effectiveness  of  PECOS  in  protecting  the 
database  client,  a  set  of  error injection  experiments is  per- 
formed.  The  system  configuration  is  analogous  to  the  one 
presented  in Figure  1 with PECOS embedded into the client 
code.  We define four sets of error injection  campaigns:  ( 1 )  
without  PECOS,  without  Audit,  (2) without  PECOS,  with 
Audit,  (3) with  PECOS,  without  Audit,  and  (4) with  PE- 
COS,  with  Audit.  For  each  campaign,  the  call-processing 
client  is the target  of error  injection.  Table 5 provides  error 
models used in the error injection campaigns. 
Address line error resulting in execution of a different 
Table 5: Error Models 
These error models  are based  on the  extensive  experiments 
reported  by  Kanawati et al.  [7], adding random memory er- 
rors  (DATAInF).  For  the  first  set of  campaigns, injections 
are done into instructions randomly selected  from call proc- 
essing application  instruction stream. For the second set, in- 
jections are performed  only to the control  flow instructions 
in the text segment. 
A  breakpoint  is  the  trigger  for  the  error  injection,  and  in 
each run only one error is injected.  Among the multiple  in- 
structions  that  satisfy  the  criteria  for  the  injections  target, 
one  is  chosen  at  random.  However,  interestingly,  a  single 
error  injection  may affect multiple client threads. Since call 
processing  is a multi-threaded  application, if an error is  in- 
jected  into  even  a  single  instruction,  it  is  possible  that  an- 
other thread  may execute the same erroneous instruction. In 
the  error  injection  methodology  followed,  once  a  thread 
reaches  a  breakpoint,  the  error  is  injected,  the  thread  is 
made to execute  the erroneous instruction,  and then  the  er- 
ror  is  removed.  But,  in  the  time  interval  between  reaching 
the  breakpoint  and  restoring  the  correct  instruction,  other 
thread(s)  may  come  and  execute the  erroneous instruction. 
Therefore, cases of  multiple  errors being  activated  are  ob- 
served. 
6.1.3  Outcome Classification 
The classification  of  outcomes from error injection experi- 
ments  is given  in  Table 6. A  run  is considered  to  be  in  the 
“Error  Activated  but  Not Manifested”  category  if  the  erro- 
neous instruction is executed, none of the detection schemes 
flags an error, the comparison  of the database records by the 
client  prior  to  termination  of  the  thread  does  not  detect  a 
mismatch,  and  the  client  prints  the  message  indicating  it 
completed  successfully. If neither PECOS detection nor sys- 
tem detection flags an error, the final comparison  of  golden 
and  runtime  records  by  the  client  does  not  detect  a  mis- 
match,  but  the  client  does  NOT  print  the  message  that  it 
completed  successfully, it is taken to be a case of  “Applica- 
tion Hang.” If the comparison by the client of the records in 
the database and the records that it wrote to the database de- 
tects  a  mismatch,  this  is  taken  as  a  case  of  “Fail-Silence 
Violation.”  The rationale behind  this  is that  an error in  the 
client process  has resulted  in the writing of a corrupt record 
to the database. Since this database is shared  among all the 
call-processing  threads,  the  writing  of  a  corrupt  record  to 
the database can lead to error propagation. 
vated 
trol flow of the application. These runs are dis- 
(NE) 
PECOS Detec- 
tion (PD) 
Audit Detection 
System Detec- 
tion (SD) 
Client Hang 
Fail-Silence 
plication exhibits correct behavior. 
PECOS Assertion Blocks detect the error prior to 
any other detection technique or any other result. 
One of the audit mechanisms detects an error in the 
database 
The operating system detects the error by raising a 
signal (e.g., SIGBUS) and as a result the database 
client crashes. 
The client gets into a deadlock or livelock and does 
not make an 
The client writes an incorrect data to the database: 
ro  ress. 
Table 6: Outcome Categories of Error Injection Runs 
6.1.4  Results and Discussion 
Table 7 and Table 8 present, respectively,  a summary of re- 
sults from the directed  injection  to control  flow instructions 
and  random  injection  to the  instruction  stream.  The values 
in  the  two  tables  are  percentages  of  runs  resulting  in  each 
possible  outcome  (listed  in  the  first  column)  followed  by 
95% confidence intervals3. The last row gives the number of 
runs used in the error injection campaigns4. 
Combined  use  of  audits and  PECOS  is effective  in  re- 
ducing the proportion  of system detection  (66% to 39% for 
random injections, and 52% to  19% for directed  injections). 
Preventing 
the  application  crash  allows  for  graceful 
termination  of  offending  thread(s)  without  affecting  other 
calls  being  currently  processed  and  thus  guarantees  high 
availability of the overall system. 
Although  the  number  of  observed  client hangs  is small, the 
results  indicate  that  audits and  PECOS are  efficient  in  de- 
tecting  these  failures.  Usually  mechanisms  for  detecting 
hangs  use  a  timeout  to determine whether  a process/thread 
is  making  progress.  Arbitrary/static  assumptions  on  what 