### Intuitive and Safe Navigation
Navigation and related functionalities are generally intuitive and safe to use. However, their effectiveness is somewhat diminished by the requirement to disable all plug-ins whenever the sandbox attribute is used. This is because frameworks like Flash or Java do not respect the sandbox attribute, allowing embedded applets to bypass the newly added browser checks. Unfortunately, the three most common use cases for sandboxed frames—embedded advertisements, videos, and games—rely heavily on Flash, thereby reducing the utility of this security mechanism.

### Synthetic Origins
The concept of synthetic origins, the last mechanism on our list, is more problematic and may be misguided. It is primarily designed to allow untrusted documents, such as HTML-based emails in a webmail interface, to be served alongside the rest of the application while preventing these documents from accessing sensitive data.

Unfortunately, synthetic origins create more problems than they solve. If the URL of the embedded document is predictable, an attacker can navigate directly to it in a new browser window, bypassing the sandbox attribute entirely. To address this, the specification authors proposed using a specialized MIME type (text/html-sandboxed) for content meant to be shown only in a sandboxed frame. The idea is that browsers will not recognize this MIME type and will not display it inline, with a special case created in the handling code. However, as discussed in Chapter 13, this defense is inadequate, as some browsers and plug-ins will still render text/html-sandboxed responses inline or interpret the returned data in problematic ways (e.g., as crossdomain.xml).

Synthetic origins also pose challenges due to the fragmentation of origin- or domain-level security mechanisms in typical browsers. For example, password managers must be explicitly prevented from autocompleting login forms in sandboxed documents, and special logic must be added to security prompts, such as those associated with the geolocation API. While the WebKit implementation has resolved many of these issues on a case-by-case basis, future implementations are likely to face similar challenges, especially since the HTML5 specification does not provide clear guidance on the required behavior.

**Note:** Removing synthetic origins can also lead to issues. If a user clicks on a same-site link in a sandboxed advertisement and that link opens in a new window, the browser should prevent the unrestricted scripts in the new window from traversing the opener object to perform actions that its parent is prohibited from performing on its own.

### Strict Transport Security (HSTS)
One of the most significant weaknesses in HTTPS design is that users often begin navigation by typing a protocol-less URL into the address bar (e.g., bankofamerica.com instead of https://www.bankofamerica.com). In such cases, the browser defaults to HTTP and sends the initial request in plaintext. Even if the site immediately redirects to HTTPS, an active attacker on the victim’s network can intercept and modify the initial response, preventing the user from upgrading to a secure protocol. The absence of a lock icon in the browser UI can easily go unnoticed.

To address this, Jeff Hodges and other researchers drafted a proposal for HTTP Strict Transport Security (HSTS). This approach, currently supported in WebKit and Firefox, allows any site to instruct the browser that all future requests to a particular hostname or domain should always use HTTPS, and any HTTP traffic should be automatically upgraded and submitted over HTTPS.

The reasoning behind HSTS is that the user’s first interaction with a domain is unlikely to occur over a compromised connection, but the risk increases as the user navigates open wireless networks. HSTS is an imperfect defense but is generally effective in practice.

An HSTS opt-in header might look like this:
```
Strict-Transport-Security: max-age=3000000; includeSubDomains
```

**Note:** For HSTS to offer reasonable protection, the `max-age` (the number of seconds the STS record is stored in the browser) must be set to a value substantially higher than the usual worst-case time between visits to the site. Website owners may choose a smaller `max-age` to minimize disruption when something goes wrong, leading to a potential conflict of interest.

The negative security consequences of HSTS are relatively minor. There is a slightly elevated risk of DoS attacks, as an attacker could inject the response header into a domain not fully HTTPS-enabled. Additionally, unique HSTS settings for decoy hostnames could be used for browser tracking, though neither concern is particularly pronounced.

### Private Browsing Modes
Private browsing, colloquially known as "porn mode," is a non-standardized feature available in most modern browsers. It creates a non-persistent browsing sandbox, isolated from the main browser session, which is discarded when the last private browsing window is closed. This mechanism can be seen as a form of content isolation added to existing browser security paradigms.

Most browser vendors, except Chrome, do not accurately explain the security assurances associated with private browsing. The intuitive understanding of the term differs significantly from what browsers can actually deliver. A private browsing session is expected to be perfectly anonymous, with no data persisting on the system. However, this goal is nearly impossible to achieve due to constraints imposed by networking stacks, memory management practices, and stateful browser mechanisms. Anonymity is also undermined by the ability of scripts to uniquely fingerprint systems based on characteristics such as installed plug-ins, fonts, screen resolutions, and clock drift.

In the end, private browsing mode is suitable only for preventing casual data disclosure to other non-technical users of the same machine, and even that goal is sometimes difficult to achieve.

### Other Developments

#### In-Browser HTML Sanitizers
XSS vulnerabilities are the most common security issue in modern web applications. Few proposed security frameworks comprehensively address this problem. CSP is a strong contender but requires significant changes in how web applications are written. Sandboxed frames, while useful, are too resource-intensive and awkward for displaying short snippets of user-supplied data.

A potential solution would be a method for web frameworks to provide the browser with a parsed, unambiguous, binary DOM tree, eliminating issues with template escaping and HTML sanitization. A more practical alternative might be a robust tool for web developers to mark the boundaries of an attacker-supplied string and restrict its behavior or appearance without needing to escape or sanitize it. For example:
```html
...any unsanitized text or HTML...
```
Such a tool would prevent attackers from escaping the sandbox and removing scripting restrictions without guessing the correct value of a randomly generated token boundary.

However, this proposal is unlikely to become part of HTML5 or be implemented in browsers due to fundamental incompatibility with XML. XML already offers a similar method of encapsulating arbitrary data inside a `<CDATA>` block, but without a token-based guard, this sandbox can be easily escaped during XSS exploitation.

On the client side, it is easier to restrict the privileges of HTML generated by scripts. Microsoft's `toStaticHTML(...)` API, available in Internet Explorer 8 and later, removes JavaScript from HTML passed to it. The output is designed to be safe to assign to the `innerHTML` property. However, this API has suffered from bypass vulnerabilities, often related to CSS handling.

Microsoft's proposal is fine but does not address the common task of safely displaying server-supplied documents. A more sensible approach would be to allow content sanitization only upon assignment to `innerHTML`. WebKit engineers briefly discussed such an API (alternately named `innerStaticHTML` or `safeInnerHTML`), but the effort seems to have been abandoned.

#### XSS Filtering
Reducing the incidence of XSS vulnerabilities is challenging, leading some researchers to focus on detecting and stopping their exploitation. In 2008, David Ross of Microsoft announced the inclusion of XSS-detection logic in Internet Explorer 8, and Adam Barth implemented a similar feature in WebKit. These implementations compare portions of the current URL with strings on the page or passed to APIs like `document.write(...)` and `innerHTML`. If the comparison reveals that a portion of JavaScript may have originated from an improperly escaped URL parameter, the relevant portion of the page is substituted with a harmless string.

Unfortunately, this approach causes serious problems. False positives can disrupt user experience, and the filter can be manipulated to create new XSS vectors. More fundamentally, selectively disabling attacker-selected script blocks can put the client-side code in an inconsistent or dangerous state. For example, in an online document editor, removing a step that loads the current version of the document can overwrite the server-stored document with a blank copy.

This problem could have been avoided by simply refusing to render the document in suspected XSS attacks, but the high incidence of false positives prevented this. Microsoft eventually offered a "strict" blocking mode on an opt-in basis, toggled by a response header:
```
XSS-Protection: 1; mode=block
```

**Note:** XSS filters are prone to false negatives and cannot detect stored XSS vulnerabilities. The growing use of `location.hash` or `pushState` for storing application state further complicates accurate URL parsing.

### Security Engineering Cheat Sheet

- **Cross-domain XMLHttpRequest (CORS):** Fairly safe, but easy to misuse. Avoid non-simple requests and do not permit arbitrary headers or methods. Consider stripping `Cookie` headers on incoming CORS requests with non-whitelisted `Origin` values to minimize the risk of sharing user-specific data. Reject HTTPS `Origin` values on plain HTTP requests to minimize mixed-content bugs.
- **XDomainRequest:** Safe to use. Restrict access to HTTP APIs from HTTPS origins to reduce mixed-content bugs.
- **Content Security Policy (CSP):** Safe to use as a defense in depth. Review interactions among `script-src`, `object-src`, and the dangers of permitting `data:` origins. Always specify protocols in rulesets and ensure they match the protocol the requesting page is served over.
- **Sandboxed frames:** Safe to use for embedding gadgets from other origins but will fail in non-compliant browsers. Do not sandbox same-origin documents.
- **Strict Transport Security (HSTS):** Safe to use as a defense in depth. Mark all relevant cookies as secure and prepare for the possibility of cookie injection via spoofed, non-STS locations in your domain. Use `includeSubDomains` where feasible to mitigate this risk.
- **toStaticHTML(...):** Safe to use where available, but difficult to substitute in non-compliant browsers. Bypass vulnerabilities have a higher chance of recurring due to the design of the filter.
- **Private browsing:** Do not rely on this mechanism for security purposes.
- **XSS filtering:** Do not rely on this mechanism for security purposes. Explicitly specify `XSS-Protection: 1; mode=block` or `XSS-Protection: 0` in HTTP responses. The default is fairly unsafe.

### Other Browser Mechanisms of Note

To conclude, we briefly enumerate some recently implemented or planned APIs that, although not designed for security, may substantially change the security landscape in the coming years. These features alter the types of data web applications can access or how the browser communicates with the outside world.

#### URL- and Protocol-Level Proposals
These features aim to change the behavior of links, the address bar, and data exchange over the wire.

- **Protocol registration:** Web applications often handle URL schemes previously reserved for desktop software. For example, the `mailto:` protocol, originally intended for standalone mail applications, is now often routed to webmail interfaces. Mozilla proposed and WebKit embraced the `navigator.registerProtocolHandler(...)` API. When invoked, the user is presented with a security prompt, and if approved, a URL-based handler is associated with a particular scheme. As of today, the associated prompts are vulnerable to manipulation.