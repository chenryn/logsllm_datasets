and navigation—are fairly intuitive and safe to use. Their value is diminished
only by the need to also disable all plug-ins whenever the sandbox attribute is
used, because frameworks such as Flash or Java do not honor the extension
and would allow any embedded applets to bypass the newly added browser
checks. Unfortunately, the three most obvious use cases for sandboxed
frames—embedded advertisements, videos, and games—rely heavily on
Flash, thus rendering this security mechanism much less useful than it
mightotherwise be.
Synthetic Origins
The last mechanism on the list, synthetic origins, is far more problematic and
is likely misguided. It is envisioned primarily as a way to make it possible for
untrusted documents (such as incoming HTML-based emails in a webmail
interface) to be served as is, along with the rest of the application, while pre-
venting these untrusted documents from accessing sensitive data.
Unfortunately, the concept of synthetic origins creates more problems
than it solves. For one, unless the URL of the embedded document is unpre-
dictable, the attacker may simply navigate to it directly in a new browser win-
dow, in which case the browser will not see the sandbox attribute at all.
As an attempt to work around this problem, the authors of the specification
eventually proposed the use of a specialized MIME type (text/html-sandboxed)
for content meant to be shown only in a sandboxed frame. Their reasoning
isthat browsers will normally not recognize this MIME type and will not dis-
play it inline and that a special case may be created in the  handling
code. Of course, as should be clear from Chapter 13, such a defense is inade-
quate, because some browsers and plug-ins will render text/html-sandboxed
responses inline or interpret the returned data in other troubling ways (say,
as crossdomain.xml).
The concept of synthetic origins is also highly problematic given the
fragmentation of origin- or domain-level security mechanisms in a typical
browser. For example, dangerous interactions are possible with password
managers, which must be explicitly prevented from autocompleting login
forms in the sandboxed documents. Also, special logic must be added to
security prompts, such as the one associated with the geolocation API.
After some trial and error, the implementation currently available in
WebKit resolved many of these issues on a case-by-case basis. That said, future
implementations are likely to fall for this trap repeatedly, especially since the
HTML5 specification considers the behavior of these features to be out of
scope and does not specify the required behavior in any way.
NOTE Removing synthetic origins leads to trouble, too: If the user clicks on a same-site link in
a sandboxed advertisement and that link opens in a new window, the browser probably
should prevent the unrestricted scripts in the new window from traversing the opener
object to perform actions that its parent is prohibited from performing on its own.
New and Upcoming Security Features 247
Strict Transport Security
One of the most significant weaknesses in the design of HTTPS is that users
often begin navigation by typing in a protocol-less URL in the address bar
(such as bankofamerica.com rather than https://www.bankofamerica.com), in
which case the browser will presume HTTP and send the initial request in
plaintext. Even if the site immediately redirects this traffic to HTTPS, any
active attacker on the victim’s network may intercept and modify that initial
response, preventing the user from ever upgrading to a secure protocol. In
such case, the absence of a tiny lock icon in the browser UI will be very easy
to miss.
This problem, as well as several peripheral issues related to mixed con-
tent and cookie scoping, prompted Jeff Hodges and several other research-
ers to draft a proposal for HTTP Strict Transport Security (HSTS, or STS for
short).12 Their approach (currently supported in WebKit and Firefox) allows
any site on the Internet to instruct the browser that all future requests made
to a particular hostname or domain should always use HTTPS and that any
HTTP traffic should be automatically upgraded and submitted only over
HTTPS.
The reasoning behind the design of HSTS is that the user’s first inter-
action with a particular domain is unlikely to occur over a connection that is
being actively tampered with—but that, over time, as the user roams on open
wireless networks, the chances of encountering an attacker increase rapidly.
HSTS is, therefore, an imperfect defense, but in practice it is usually good
enough.
The HSTS opt-in header may appear in HTTPS responses, looking some-
thing like this:
Strict-Transport-Security: max-age=3000000; includeSubDomains
NOTE For HSTS to offer reasonable protection, max-age (the number of seconds that the STS
record may be stored in the browser) must be set to a value substantially higher than the
usual worst-case time between visits to the site. Because there is no easy way to disable or
override HSTS when something goes wrong with the HTTPS site, website owners will be
tempted to choose a value small enough to minimize disruption when they mess some-
thing up and have to revert. It is not clear whether this conflict of interests will lead web
programmers to make optimal choices.
The negative security consequences of this design are fairly unremarkable:
There is a slightly elevated risk of DoS attacks, because an attacker could inject
this response header into a domain that is not fully HTTPS enabled. There is
also the possibility of using a unique combination of HSTS settings for sev-
eral decoy hostnames to tag a particular instance of a browser, offering yet
another alternative to cookie-based user tracking. Neither of these concerns
is particularly pronounced, however.
248 Chapter 16
Unfortunately, as with other restriction-adding frameworks discussed in
this section of the book, the mechanism sounds great in principle, but it’s
difficult to fully account for how it may interact with other legacy code. In
particular, unless the includeSubDomains flag is used, HSTS offers unexpect-
edly little protection for HTTP cookies: Cookies not marked as secure may still
be intercepted simply by inventing a nonexistent subdomain and intercept-
ing the HTTP request made to that destination.* (Even secure cookies could
be clobbered in a similar fashion, just not read back.)
In a similar vein, the enforcement of HSTS on requests originating from
plug-in-based content is unlikely to work well.
Private Browsing Modes
Private browsing, colloquially known as the “porn mode,” is a nonstandard-
ized feature available in most up-to-date browsers. It is meant to create a non-
persistent browsing sandbox, isolated from the main browser session, which
is completely discarded as soon as the last private browsing window is closed.
In a sense, this mechanism can be considered a form of content isolation
added on top of the existing browser security paradigms, so it seems fitting to
briefly mention it now.
With the exception of Chrome, most browser vendors do not accurately
explain the security assurances associated with private browsing. Unfortu-
nately, the intuitive understanding of the term is quite different from what
browsers can actually deliver.
Arguably, the most straightforward interpretation of the feature is that a
private browsing session should be perfectly anonymous and that no data about
the user’s activity will persist on the system. These two assumptions are already
partly undermined by the constraints imposed by the networking stacks and
the memory management practices of modern operating systems. But even
within the browser itself, the goal of reasonable anonymity is nearly impossi-
ble to achieve. Almost every stateful browser mechanism, from geolocation or
pop-up permissions to Strict Transport Security to form autocompletion to
plug-in-based persistent data storage, must be modified in order to properly
account for the distinction between the two browsing modes, and for each
vendor, achieving that goal is an uphill battle. Perhaps more frustratingly,
anonymity is also undermined by the ability of scripts to uniquely fingerprint
any given system simply by examining its characteristics—such as the set of
installed plug-ins, fonts, screen resolutions, window sizes, clock drift, or even
the behavior of noncryptographically secure PRNGs.13
In the end, despite appearances to the contrary, private browsing mode
is suitable only for preventing casual data disclosure to other nontechnical
users of the same machine, and even that goal is sometimes difficult to
achieve.
* Recall from Chapter 9 that host-scoped cookies are fairly tricky to create in some browsers and
outright impossible to have in Internet Explorer.
New and Upcoming Security Features 249
Other Developments
The security features discussed previously in this chapter aim to shift the
boundaries between web applications and change the way sites interact with
each other. Another group of proposed mechanisms escapes this simple clas-
sification yet is important or mature enough to briefly mention here. We’ll
review some of them now.
In-Browser HTML Sanitizers
XSS vulnerabilities are by far the most common security issue encountered
in modern web applications. It must be surprising, then, that so few of the
proposed security frameworks aim to address the problem in a comprehen-
sive way. True, CSP is a strong contender, but it requires a radical change in
how web applications are written, and it can’t be deployed particularly gradu-
ally or selectively. Sandboxed frames, on the other hand, are probably too
resource-intensive and too awkward to use for the most common task of dis-
playing hundreds of individual, short snippets of user-supplied data.
Perhaps the best solution to many XSS woes would be a method for web
frameworks to provide the browser with a parsed, unambiguous, binary DOM
tree. Such a solution would eliminate many of the issues associated with tem-
plate escaping and HTML sanitization. A more down-to-earth alternative
might be to equip web developers with a robust tool to mark the boundaries
of an attacker-supplied string and restrict the behavior or appearance of the
embedded payload without having to escape or sanitize it. One might think
of syntax such as this:
...any unsanitized text or HTML...
Were such a tool to be used, the attacker would be unable to escape such
a sandbox and remove the restriction on scripting without guessing the cor-
rect value of the randomly generated token boundary.
Sadly, such a proposal is unlikely to become a part of HTML5 or to ship
in any browser, because this serialization is fundamentally incompatible with
XML, and revising XML itself to allow an obscure use case in HTML is a dif-
ficult act to pull off. Depressingly, XML already offers a similar method of
encapsulating arbitrary data inside a  block, but absent a token-
based guard, this sandbox can be escaped easily when exploiting XSS.
On the flip side, it is considerably easier to restrict the privileges of
anyHTML generated by scripts on the client side. Beginning with Internet
Explorer 8, Microsoft offers a simple and somewhat inflexible toStaticHTML(...)
API,14 which promises to remove JavaScript from any fully qualified bit of
HTML passed to it as a parameter. The output of this method is designed to
be safe to assign to the innerHTML property somewhere in the existing DOM.*
* Amusingly, the HTML parser in Internet Explorer is apparently so obtuse that even the authors
of toStaticHTML(...) had some trouble following it. Since its introduction, the API has suffered
from a fair number of bypass vulnerabilities, most frequently related to the handling of CSS data.
250 Chapter 16
Microsoft’s proposal is fine, but it dances around the most common and
problematic task of safely displaying server-supplied documents. And its API has
a minor but entirely unnecessary weakness: It makes it unexpectedly danger-
ous to trim or concatenate the sanitized toStaticHTML(...) output after the call
but before the innerHTML assignment, a practice that many web developers
will probably attempt. A more sensible approach would be to allow content
sanitization only upon assignment to innerHTML. In fact, WebKit engineers
briefly discussed a proposal for such an API (alternately named innerStaticHTML
or safeInnerHTML), but the effort seems to have fizzled out long ago.
XSS Filtering
Reducing the incidence of cross-site vulnerabilities is difficult, and so is
limiting their impact. Because of this, some researchers have concluded that
detecting and stopping the exploitation of such flaws may be a better choice.
And so, around 2008, David Ross of Microsoft announced the inclusion of
XSS-detection logic in the upcoming release of Internet Explorer 8;15 several
months later, Adam Barth implemented a similar feature in WebKit. The
implementations compare portions of the current URL with any strings
appearing on the retrieved page or passed to APIs such as document.write(...)
and innerHTML. If that comparison reveals that a portion of JavaScript present
on the page may have originated with an improperly escaped URL parameter,
the relevant portion of the page may be substituted with a harmless string.
Sadly, this seemingly elegant idea is known to cause serious problems. Acci-
dental false positives aside (users of Internet Explorer 8 will have unexpected
trouble visiting http://www.google.com/search?q=), the filter may also be
tripped for ill purposes by appending a legitimate portion of the page as a non-
functional parameter in the URL. In one extreme and now resolved case, this
behavior was leveraged to create XSS vectors where none had existed before,
simply by tricking the browser into haphazardly rearranging the markup.16
But more fundamentally, it’s risky for any complex web application to selec-
tively disable attacker-selected script blocks, even if the structure of the page
is otherwise correctly preserved, and such a tweak may easily put the client-
side code inan inconsistent or dangerous state. For example, consider an
online document editor that implements each of the following in a separate
block:
1. Initializes the internal state of the editor and creates the UI with an
empty starting document.
2. Loads the current version of the document requested by the user in a URL
parameter with error checking to catch any potential network problems.
3. If no errors are detected, enters an interactive editing mode and auto-
matically saves the current state of the document every 30 seconds under
the URL-derived ID.
In this not entirely unreasonable design, the ability to remove step two
can be disastrous because the next step could overwrite the existing, server-
stored document with a blank copy. D’oh.
New and Upcoming Security Features 251
This problem could have been avoided by using much simpler design
whereby any suspected XSS attacks would result in the browser simply refus-
ing to render the document. Alas, the relatively high incidence of accidental
false positives prevented the authors from taking this route. Only after some
debate did Microsoft decide to offer a “strict” blocking mode on an opt-in
basis, toggled by a response header such as this:
XSS-Protection: 1; mode=block
NOTE In addition to the risk of false positives, XSS filters are also prone to false negatives,
asituation that probably can’t be improved by much. By design, these filters will never
be able to detect the arguably more dangerous stored XSS vulnerabilities, where incor-
rectly escaped data comes from a source other than the followed link. But even beyond
that, the multitude of (often implicit) input escaping schemes and the growing use of
location.hash or pushState (Chapter 17) as a method to store application state make
it difficult to formulate an accurate connection between what the browser sees in the
address bar and what the application makes of the received URL.
252 Chapter 16
Security Engineering Cheat Sheet
Approach experimental browser security features with care, particularly when dealing with
mechanisms that create finer-grained security boundaries. Ensure that any application lever-
aging these mechanisms will degrade safely in a noncompliant browser.
 Cross-domain XMLHttpRequest (CORS): Fairly safe, but easy to misuse. Avoid non-simple
requests and do not permit arbitrary headers or methods. If you have control over the
server-side application framework, consider automatically stripping Cookie headers on
incoming CORS requests with nonwhitelisted Origin values to minimize the risk of acci-
dentally sharing user-specific data. To minimize the incidence of mixed-content bugs,
consider rejecting HTTPS Origin values on any requests received over plain HTTP.
Be wary of Access-Control-Allow-Origin: *, and if you need to use it, make sure it is only
returned for the location you intend to share.
 XDomainRequest: This is safe to use. As with XMLHttpRequest, restricting access to HTTP
APIs from HTTPS origins may be a good way to stamp out mixed-content bugs.
 Content Security Policy: This is safe to use as defense in depth. Review the caveats related
to the interactions among script-src, object-src, and so on, and the dangers of permitting
data: origins. Do not accidentally allow mixed content: Always specify protocols in the
rulesets and make sure they match the protocol the requesting page is served over.
 Sandboxed frames: This is safe to use as a way to embed gadgets from other origins, but
the mechanism will fail dramatically in noncompliant browsers. You should not sandbox
same-origin documents.
 Strict Transport Security: This is safe to use as defense in depth. Be sure to mark all rele-
vant cookies as secure and be prepared for the possibility of cookie injection via spoofed,
non-STS locations in your domain. Use includeSubDomains where feasible to mitigate
thisrisk.
 toStaticHTML(...): This is safe to use where available, but it is difficult to substitute on
theclient side in noncompliant browsers. Bypass vulnerabilities have an above-average
chance of recurring in the API due to the design of the filter.
 Private browsing: Do not rely on this mechanism for security purposes.
 XSS filtering: Do not rely on this mechanism for security purposes. Always explicitly spec-
ify XSS-Protection: 1; mode=block or XSS-Protection: 0 in HTTP responses. The default is fairly
unsafe.
New and Upcoming Security Features 253
O T H E R B R O W S E R
M E C H A N I S M S O F N O T E
To conclude the third part of the book, we briefly enu-
merate some of the recently implemented or simply
planned APIs that, although not designed for security
purposes, may substantially change the security land-
scape in the coming years. For example, some change
the types of data that web applications have access to
or alter the way the browser communicates with the
outside world.
The following list is necessarily incomplete: New, reasonably plausible
designs are drafted every week, and old approaches are scrapped at a moment’s
notice, often long before shipping in an actual browser. Still, this chapter
should serve as an interesting snapshot of what the future may bring.
URL- and Protocol-Level Proposals
These features seek to change the processes surrounding the behavior of
links, the address bar, and the exchange of data over the wire.
Protocol registration
Web applications commonly assume the handling of URL schemes pre-
viously reserved for “real” desktop software. One prime example of this
may be the mailto: protocol, which was originally meant to instantiate a
stand-alone mail application but which is often more sensibly routed to
webmail interfaces today. To this end, Mozilla proposed and WebKit
embraced a simple navigator.registerProtocolHandler(...) API.1 When this
API is invoked, the user is presented with a simple security prompt, and
if the action is approved, a URL-based handler is associated with a par-
ticular scheme. As of today, the associated prompts are vulnerable to