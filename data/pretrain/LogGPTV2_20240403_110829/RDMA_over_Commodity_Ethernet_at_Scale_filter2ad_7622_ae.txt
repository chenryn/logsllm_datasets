### 优化后的文本

#### 更快且更先进的传输协议和前向纠错算法直接集成于通用硬件中，从而减轻了RoCEv2对无损网络的依赖。

#### 7. 相关工作
本文主要探讨如何在大规模环境中安全部署RoCEv2。除了RoCEv2之外，还有两种其他的RDMA技术：InfiniBand [6] 和 iWarp [30]。

**InfiniBand** 是一个完整的网络协议套件，包含从第1层到第7层的所有协议。InfiniBand 网络由多个通过 InfiniBand 路由器连接的子网组成。在一个子网内，服务器通过 InfiniBand 交换机相连。然而，据我们所知，目前尚无投入生产的 InfiniBand 路由器。因此，InfiniBand 无法满足我们的可扩展性要求。此外，InfiniBand 与以太网不兼容，而后者是数据中心中最主流的网络技术。

**iWarp** 在 TCP/IP 协议上运行 RDMA，并将 TCP/IP 协议卸载到 NIC 上。由于 TCP 即使在网络丢包的情况下也能保证可靠的数据传输，iWarp 并不需要无损网络。相比 RoCE，iWarp 的一个优势在于它可以用于数据中心间的通信。但由于 iWarp 使用 TCP 进行数据包传输，它同样面临着因数据包丢失和重传超时导致的高延迟问题。正如我们在第6.3节讨论的那样，随着新硬件技术的发展，未来可能会出现不同于 InfiniBand 传输和 TCP 的新型传输协议。

死锁在文献中得到了广泛研究，已知循环缓冲区依赖是死锁发生的必要条件 [12, 18, 22, 33, 36]。由于 Clos 网络拓扑结构的特殊性，我们一度认为该网络应不存在死锁，因为它没有循环缓冲区依赖。然而，PFC 和以太网数据包泛洪的“合谋”表明，在 Clos 网络中仍然可能发生死锁。

关于 TCP 性能问题的研究，如 TCP incast [35, 38, 39] 和长尾延迟 [41] 已经非常深入。这些解决方案仍在现有的 TCP 框架内进行。它们要么调整重传定时器（如 [35]），要么控制 TCP 接收窗口（如 [39]），要么调整 ECN 参数（如 [38]）。相比之下，RDMA 提供了一种不同的方法。相比于仍使用 TCP 的 [41]，RDMA 绕过了操作系统内核，消除了内核引入的延迟。我们的研究表明，RDMA 可以在大规模的内部数据中心通信中安全地部署。如图5.4所示，与 TCP 相比，RDMA 显著降低了高百分位延迟。

RDMA 已被用于构建包括存储、键值存储和分布式事务系统在内的多种系统 [17, 26, 28, 37]。大多数这些系统使用 InfiniBand 或 RoCE，并且规模通常在几十台服务器。本文展示了我们可以利用 RoCEv2 将 RDMA 扩展到更大的网络中，从而在未来能够构建更大规模的内存系统。

#### 8. 结论
本文介绍了我们在 Microsoft 数据中心大规模安全部署 RoCEv2 的实践和经验。我们的实践包括引入基于 DSCP 的 PFC，将 RoCEv2 从第2层 VLAN 扩展到第3层 IP，以及逐步上线和部署过程。我们的经验包括发现并解决 RDMA 传输活锁、RDMA 死锁、NIC PFC 风暴和慢接收者症状等问题。通过 RDMA 管理和监控系统的实施，我们的一些高可靠性、低延迟服务已经稳定运行 RDMA 超过一年半的时间。

#### 8.1 未来工作
下一步有几个方向可以探索。PFC 的逐跳距离限制为 300 米，因此 RoCEv2 仅适用于同一 Spine 交换机层下的服务器。在这方面，RoCEv2 不如 TCP 通用。我们需要新的想法来扩展 RDMA 以支持数据中心间通信。

我们的测量显示 ECMP 只能达到 60% 的网络利用率。对于尽力而为网络中的 TCP，有 MPTCP [29] 和每包路由 [10] 等方法来提高网络利用率。如何使这些设计在无损网络环境中适用于 RDMA 将是一个有趣的挑战。

本文中发现的死锁提醒我们，数据中心中的死锁可能值得更系统的研究。尽管 Clos 网络中的上下路由可以防止死锁，但像 F10 [23] 这样的设计可能会通过引入局部重路由打破这一假设。许多其他网络拓扑 [20] 甚至不具备上下路由的特性。如何在这些设计中避免死锁？

最后但同样重要的是，我们展示了 RDMA 通过消除操作系统内核的数据包处理开销并依赖无损网络提供了低延迟和高吞吐量。然而，无损网络并不保证低延迟。当网络拥塞发生时，队列会累积，PFC 暂停帧也可能生成。队列和 PFC 暂停帧都会增加网络延迟。如何同时实现低网络延迟和高网络吞吐量仍然是一个开放的问题。

#### 9. 致谢
Firestone 在项目的早期阶段参与了 RDMA 项目。Yibo Zhu 帮助我们进行了 RDMA 传输活锁实验。我们得到了 Azure Networking 团队的多位成员的支持。我们与 Charlie Gu、Sorabh Hamirwasia、Madhav Pandya、Passaree Pasarj、Veselin Petrov、Xin Qian、Junhua Wang 和 Chenyu Yan 密切合作，为 Microsoft 的几个关键在线服务启用了 RDMA。我们还收到了 Arista Networks、Broadcom、Cisco、Dell 和 Mellanox 的工程师的技术支持。我们的指导 Nandita Dukkipati 和匿名的 SIGCOMM 评审人员为我们提供了许多建设性的反馈和建议，极大地改进了本文的内容和呈现方式。我们感谢他们所有人的帮助。

#### 10. 参考文献
[略]

---

希望以上优化后的文本更加清晰、连贯和专业。如果有任何进一步的需求或修改，请随时告知。