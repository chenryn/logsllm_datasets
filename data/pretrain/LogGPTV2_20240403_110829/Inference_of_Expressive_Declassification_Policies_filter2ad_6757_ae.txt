Program
Chat
Password Manager
Access control
Battleship
Go Fish
Mental Poker
.
r
p
x
e
)
c
e
s
(
t
u
p
n
i
e
m
i
t
e
s
i
c
e
r
P
s
i
s
y
l
a
n
a
C
o
L
f
i
J
s
n
o
i
t
a
t
o
n
n
a
e
p
y
t
f
i
J
<1
<1
<1
14
5
15
∼195
337
3253 ∼1175
one in Java (for which we inferred policies), and subse-
quently one in Jif. For the programs with Jif versions, we
include the number of lines of code for the Jif version, and
the approximate number of Jif type annotations.
The fourth and ﬁfth columns of the table describe the
time taken to perform, respectively, the inference analysis,
and the precise input expression analysis (used to determine
when program expressions are equivalent to a precise input
expression). Times are averaged over ﬁve executions, all
performed on a Mac Pro dual 2.26 GHz quad-core Intel
Xeon with 8 GB of RAM. All analyses used a 2-full-
object-sensitive pointer analysis with a heap context depth
of 1 [15, 20] except for Battleship (3-object sensitivity) and
Mental Poker (context insensitive). All pointer analyses took
less than 1 second to complete.
E. Library classes
A. Go Fish
We provide signatures for standard Java library classes.
We must provide signatures for all analyses our tool per-
forms, including pointer analysis, the analysis to remove
of spurious exceptions (discussed in Section IV-C), and the
information ﬂow analyses—a single signature sufﬁces for
both the inference of security policies, and the analysis to
determine what program expressions are equal to precise
input expressions (discussed in Section IV-B).
The use of signatures improves the performance of the
tool, since we do not need to analyze the standard Java
library code. It also avoids difﬁculties analyzing the numer-
ous native methods in the standard Java library. However,
the signatures are a potential source of both unsoundness
and imprecision, as there is no guarantee that the signatures
accurately reﬂect the behavior of the library code.
V. CASE STUDIES
We have used the Java tool for inference of security poli-
cies on several Java programs. All the programs are of mod-
est size, the largest having 1,400 non-comment non-blank
lines of code. However, all have interesting information-
security requirements. Two of the programs have equivalent
versions written in the Jif programming language [19, 13],
an extension of Java with information-security types.
In this section we report on our experiences using the
tool, including useful idioms for annotating code, and the
security policies the tool was able to infer.
Table I summarizes the programs we used, and the
time taken to perform the analysis. Four are programs we
wrote ourselves. We ﬁrst wrote pure Java code, debugged
our implementations, and then added annotations, which
occasionally required minor refactoring of the code. The
Battleship program is a Jif program bundled with the Jif
distribution. We removed the Jif type annotations to obtain
a Java program. The Mental Poker program was written by
Askarov and Sabelfeld [8], who implemented two versions,
This program is a card game in which a human player
competes with a computer player. Each player is dealt cards
from the deck, holds a secret hand of cards, and requests
cards from the other player. Once we annotated the program,
the inferred security policies show that the implementation
of the computer player does not cheat: the computer player’s
decision of which cards to request does not depend on the
human’s cards, or the undealt part of the deck.
This program required the most annotations of all case
study programs. A key use of annotations indicates when
information is declassiﬁed and “relabels” the declassiﬁed
data. For example, the code below shows the relabeling of
a card drawn from the deck.
computerPlayer.receiveCard(
@input ‘‘Computer drawn card’’ deck.drawOne());
The expression deck.drawOne() has a security policy that
indicates it contains information about the undrawn portion
of the deck. Relabeling loses this information, and is thus
a potentially dangerous annotation, possibly resulting in
misleading (but semantically correct) security policies. The
beneﬁt of relabeling is that is allows intentionally declassi-
ﬁed information be described and tracked separately from
the high-security information from which it is derived.
We arrived at the conclusion that relabeling is useful, but
dangerous. Outputting the relabeled information mitigates
some of the danger, as it means analysis will indicate what
information is being relabeled. For example, the following
code outputs deck.drawOne() before relabeling it.
computerPlayer.receiveCard(
@input ‘‘Computer drawn card’’
@output ‘‘Computer drawn card’’ deck.drawOne());
We provide syntactic sugar for this common pattern; and the
previous expression can be rewritten as follows.
computerPlayer.receiveCard(
@relabel ‘‘Computer drawn card’’ deck.drawOne());
191
The corresponding inferred policy states,
. . . Reveal( Computers drawn cards[0+] . . . )
Computer’s Choices (cid:55)→
Computer drawn cards (cid:55)→
. . . Reveal( The Deck[0+] . . . ),
indicating that the computer’s moves depend on undealt part
of the deck only via the cards drawn. (For concise exposition
we elided other permissible ﬂows.)
Design Pattern Output and relabel declassiﬁed
information. After intentionally declassifying data,
use input annotations to identify the newly de-
classiﬁed information. Output the declassiﬁed data
ﬁrst to show ﬂows into the new label.
In Go Fish, both the human and computer player are
implemented as subclasses of the same class and share
common code. Object sensitivity allows the analysis to
distinguish data belonging to these two distinct objects.
B. Password Manager
The Password Manager program implements a simple
password wallet that stores passwords protected by a master
password. The user interacts with the password manager in
a read-eval-print loop; he may issue commands to store and
retrieve passwords, and to reset the master password. Pass-
words are stored encrypted with the master password, and
retrieval requires decryption. We use symbolic encryption
for debugging purposes in this program.
We added three annotations in total
to the Password
Manager. All output to the screen occurs through a single
method that calls System.out.println. We added a single
output annotation to that method, as shown below.
public void writeLine(String s) {
System.out.println( @output ‘‘stdout’’ s); }
We add an input annotation for the user’s password input
only after we have validated that the input is non-null.
String p = env. util .readLine();
if (p == null) throw new CommandFailed();
p = @input ‘‘password’’ p;
Intuitively, if readLine() returns null then no password was
read and the system contains no new sensitive data. Input
annotations of this form constitute a useful design pattern.
Design Pattern Apply annotations to valid infor-
mation, not to buffers or invalid information.
This design pattern leads to clearer policy maps and more
precise inference.
The third annotation is on the result of the method
canDecrypt(c, master), which returns true only if ciphertext
c can be decrypted with the master password entered by
the user. We add an additional @suppress annotation to
indicate that
then doDecrypt
cannot throw any exceptions.
if canDecrypt returns true,
public static String decrypt(String s,
if (@relabel ‘‘decrypt ok’’ canDecrypt(s,masterpwd)){
return @suppress Exception
String masterpwd) {
doDecrypt(s, masterpwd);
}
return null;
}
The decrypt ok annotation is useful as it both gives a name
to the implicit information ﬂow stemming from decryption
success or failure, and also allows for inference of a precise
conditional policy.
Design Pattern Annotate the decision to release
information so that policies describe ﬂows infor-
matively.
With these annotations our tool infers the informative, yet
concise policy,
output stdout (cid:55)→ if (decryption ok[0]) then
Reveal(password[0+])
This indicates that the passwords are revealed to the user
only if the passwords can be successfully decrypted using
the master password entered by the user.
C. Chatbot
The Chatbot converses with the user, sometimes repeating
user input in the style of the Eliza2 program. The inferred
security policy indicates that user input is always prop-
erly sanitized before being printed as output. The sanitize
method is annotated with a @track annotation.
static String sanitize (String tainted ) @track {
// Strip dangerous characters from tainted
// return the result .
return ...; }
The Chatbot satisﬁes this policy,
output (cid:55)→ if -executed (ChatBot.sanitize(String)) then
Reveal(input[0+])
and is an example of the following design pattern.
Design Pattern Use @track annotations on data
sanitizers, redaction methods, and trusted declas-
siﬁers, to ensure that these methods are involved
with all release of sensitive data.
D. Access control
In this example, we built an access-controlled key-value
store. Both users and stored values are associated with secu-
rity levels, and a reference monitor ensures that read requests
do not violate security-level constraints. Annotations for this
program are broadly similar to those used in the Password
Manager, and the analysis infers the following policy map.
out (cid:55)→ if (authorizationCheckOk[0]) then
Reveal(secret[0+], authorizationCheckOk[1+])
2http://en.wikipedia.org/wiki/ELIZA
192
This policy map indicates that the release of secret data
requires a successful access-control check, ensuring that the
reference monitor completely mediates data access.
E. Battleship
Battleship is a two player game, where each player places
tokens, representing ships, on his own secret board. The
players then take turns guessing where ships are located
on their opponent’s board. The ﬁrst player to locate all his
opponent’s ships wins.
The Jif implementation of Battleship is broadly similar
to Go Fish. As with Go Fish, both players have private
information—their boards—but unlike Go Fish, there is no
card deck causing these secrets to be correlated. We used
annotations similar to the Go Fish annotations to show that
a computer player did not cheat; its guesses are based on
information available according to the rules of Battleship.
More precisely we annotate the guesses of Player 2 (the
computer) with @output ‘‘p2Query’’ and the secret board of
Player 1 (the human) with @input ‘‘p1Board’’. Other names
(p2QueryOk, p2Hit?, p1HitP2?) are relabelings of legitimate
transfers of information from Player 1 to Player 2. Given
these annotations, our tool infers the policy
output p2Query (cid:55)→if (p2QueryOk[0]) then
Reveal(p2QueryOk[1+], p2Hit?[0+],
p1HitP2?[0+]) } .
Critically, Player 2’s queries are independent of Player 1’s
board, p1Board, meaning that the computer is not using
information about
the other player’s board to determine
where to guess.
F. Mental Poker
Askarov and Sabelfeld [8] implemented two versions of
a mental poker protocol, ﬁrst in Java, and then in Jif. These
programs allow two principals to play a fair game of poker
without relying on a trusted third party to manage a deck
of cards. All randomness and adherence to the game rules
is enforced via cryptographic protocols. We annotated and
analyzed their Java version.
Both players generate key pairs to digitally sign messages.
We verify that the private key is only used to sign messages
and is not disclosed. In the implementation, players commu-