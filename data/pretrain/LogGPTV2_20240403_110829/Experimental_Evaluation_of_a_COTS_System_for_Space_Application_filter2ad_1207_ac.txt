the effects of application damage.
The error propagation for OS and application faults is
the OS faults
the
quite different. While only 1.0% of
propagate to the other processes (P1 and P2),
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:24:52 UTC from IEEE Xplore.  Restrictions apply. 
is 4.4%.
percentage observed for application faults
Manual
inspection of these faults has shown different
error propagation scenarios, but most of them consist of
faults injected in the memory (to simulate cache faults)
and faults that have corrupted parameter of OS calls. Most
of the propagated errors were detected by the other
applications or by the OS. Only 3 out of 975 application
faults and 6 out of 1038 OS faults escaped detection and
caused the other applications (P2 and P3) to produce
incorrect results.
60%
50%
40%
30%
20%
10%
0%
Kerne l mo de (1038 faults )
57.3% 51.0%
Us e r mo de (975 faults )
43.4%
29.5%
12.3%
1.2% 1.0%
4.4%
S ys tem
cras h
Erro r
Applic atio n
No impa ct
pro pa gatio n
dama ge
Figure 6 – Impact of faults injected while P1 was
scheduled considering error propagation.
Error propagation detail
Other application crash
Errors detected in other application (P2 or P3)
Wrong results in other applications (P2 or P3)
2
2
6
Number of faults
Kernel mode User mode
4
36
3
# faults
11
5
2
18
Details on the most important type of errors
Memory corruption
Application level
OS level
SIGTRAP ' (trace mode)
SIGPIPE (write + no pipe read)
SIGSYS (bad arg. to system call)
Table 5 – Error propagation details.
Application damage details Kernel mode
(1038 faults)
User mode
(975 faults)
Application hang
Wrong results
Errors detected
1.0%
1.8%
9.5%
0.6%
6.0%
36.8%
Table 6 – Application damage details.
The percentage of faults whose damage was confined
to P1 is very high for the application faults (43.4%). This
means that LynxOS does a good job in confining the
errors to the application that is directly affected by the
fault. Furthermore, as most of these faults have been
detected (36.8%), it suggests that these kind of faults can
be recovered effectively using a SIFT approach.
3.2. Workload termination and correctness of
application results: experiments with the realistic
workloads
The goal of the following experiments is to analyze the
faults on application termination and the
impact of
correctness of the application results. To achieve this we
used realistic workloads and injected faults following a
uniform distribution over time and processor location, as
this is the best way to emulate the effects of SEU faults.
Workload
Gravity
PI
Matmult
Number of faults
User mode
36 (5.7%)
626 (99.6%)
1277 (99.3%)
Kernel mode
589 (94.3%)
3 (0.4%)
9 (0.7%)
Total
625
629
1286
Table 7 – Percentage of faults injected in the workloads.
The experiments with the different applications are
independent one from each other. Table 7 shows the
percentages of the faults injected in each workload. The
profile of the applications plays an important role on the
fault distribution. Faults injected when the application is
computing results tend to affect application code while
fault injected during I/O periods tend to affect operating
system code (mainly open, write, and read functions).
Execution time (sec.)
Workload
Gravity
PI
Matmult
Calculations
~1
~17
~22
Storing results Size of results
24
Neglected
~2
1.01 Mbytes
53 bytes
24.04 Kbytes
Table 8 – Key features of the workloads profile.
Table 8 shows the key aspects of the profile of the
applications. As we can see, the profile of the Gravity
application is very different from the other applications,
as this application spends most of the time writing the
results into disk. This is why most of the faults (94%)
have been injected in OS code. The patterns for the other
applications are very different, especially for
the PI
application where the I/O activity is negligible.
60%
50%
40%
30%
20%
10%
0%
PI
Gravity
Matmult
54.1%
50.4%
37.8%
37.5%
22.4%
17.1%
18.4%
18.4%
3.3%
0.5%
0.0%
7.9%
1.9%
System crash Application
Abnormal
hang
app.
termination
27.0%
3.2%
Correct
results
Wrong results
Figure 7 – Failure modes with realistic applications.
The most evident observation from Figure 7 is that the
results vary a lot with the application, possibly due to the
different application profiles. The program PI does not
execute many system calls and spend nearly all of its time
doing calculations. The percentage of wrong results in
this case is very high (50.4%), which clearly shows that
some applications can be very prone to producing wrong
results. The Matmult application also shows a high
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:24:52 UTC from IEEE Xplore.  Restrictions apply. 
percentage of wrong results (27.0%). This suggests that
computation intensive applications must be protected with
application based error detection techniques.
Future work will include the analysis of the results
obtained for faults already injected but that could not be
included in this paper for space reasons..
in
the
that
faults
observed
The percentages of
termination
that caused abnormal
application
realistic
applications are lower than the ones in the synthetic
application. This is partially due to the fact
the
synthetic application also includes the test of the memory
structures and code of the application, which does not
exist in the realistic applications (error detections force an
abnormal termination in the synthetic application).
4. Conclusions
to processor
In this paper we evaluated the impact of faults in a
COTS system for scientific data processing in space
applications. The faults were distributed in a uniform way
with respect
location. Both uniform
distribution over time and faults in specific locations of
the OS code are used. Two types of workloads have been
used: a synthetic workload to exercise core functions of
the operating system such as the ones related to processes,
memory, and input/output, and three realistic programs
similar to simple scientific space applications.
The following observations are particularly relevant:
  OS faults are the easies to deal with, since they tend
to crash the system or cause no visible impact at all.
Since SIFT systems are designed for crash recovery,
this result supports the idea that most of these faults
can be handled by SIFT techniques.
  Applications fault results imply that assumptions of
fail silent used by many researchers are inadequate.
More research is needed into application-based
acceptance checking to achieve coverage consistent
with highly dependable systems
  Applications with intensive calculations and few OS
calls are more likely to produce wrong results in the
presence of faults than applications that use OS calls
in an intensive way.
  The LynxOS is quite effective in confining the errors
to the process directly affected by the fault. However,
small percentages of propagated errors have been
observed (from 1% to 4.4%). The higher percentages
of error propagation happened for application faults,
which suggests that improved application based error
detection is necessary.
  For most of the faults that caused error propagation,
the propagated errors were detected in the other
applications, which suggests that these kind of faults
could be recovered using SIFT techniques.
  The LynxOS seems fairly robust, as most of the
faults that cased erroneous parameters in OS calls
have been detected by the OS. However, a small
percentage of these faults were not detected, which
shows that additional wrappers could improve even
further the robustness of LynxOS.
5. References
[1] R. R. Some and D. C. Ngo, “REE: A COTS-Based Fault
Tolerant Parallel Processing Supercomputer
for Spacecraft
Onboard Scientific Data Analysis,” Proc. of the Digital Avionics
System Conference, vol.2, pp.B3-1-7 -B3-1-12,1999.
[2] K. Whisnant, R. Iyer, D. Rennels, and R. Some, “An
Experimental Evaluation of the REE SIFT Environment for
Spaceborne Applications”, paper accepted at the International
Performance and Dependability Symposium, Washington, DC,
June 23rd - 26th, 2002.
[3] Critical Software, S.A., “Xception: Professional Fault
Injection”, White Paper, http://www.criticalsoftware.com, 2000.
[4] J. Carreira, H. Madeira, and J. G. Silva, “Xception: Software
Fault Injection and Monitoring in Processor Functional Units",
IEEE Transactions on Software Engineering, vol. 24, no. 2,
February 1998.
[5] J. Arlat, A. Costes, Y. Crouzet, J.-C. Laprie and D. Powell,
“Fault Injection and Dependability Evaluation of Fault-Tolerant
Systems”,
IEEE Trans. on Computers, 42 (8), pp.913-23,
August 1993.
[6] J. Karlsson, P. Folkesson, J. Arlat, Y. Crouzet, G. Leber, J.
Reisinger, “Application of Three Physical Fault
Injection
Techniques to the Experimental Assessment of the MARS
Architecture”, Proc. 5th IFIP Working Conf. on Dependable
Computing for Critical App.: DCCA-5, Urbana-Champaign, IL,
USA, Sept. 1995.
[7] H. Madeira and J.G. Silva, “Experimental Evaluation of the
Fail-Silent Behavior in Computers Without Error Masking,”
Proc. 24th Int'l Symp. Fault Tolerant Computing Systems,
Austin-Texas, 1994,
[8] D. P. Siewiorek, J. J. Hudak, B.-H. Suh and Z. Segall,
“Development of a Benchmark to Measure System Robustness”,
in Proc. 23rd Int. Symp. on Fault-Tolerant Computing, FTCS-2,
Toulouse, France, 1993.
[9] P. J. Koopman, J. Sung, C. Dingman, D. P. Siewiorek and
T. Marz, “Comparing Operating Systems using Robustness
Benchmarks”, in Proc. 16th Int. Symp. on Reliable Distributed
Systems, SRDS-16, Durham, NC, USA, 1997.
[10]
F. Salles, M. Rodríguez, J.-C. Fabre and J. Arlat,
“Metakernels and Fault Containment Wrappers”, in Proc. 29th
IEEE Int. Symp. on Fault-Tolerant Computing (FTCS-29),
Madison, WI, USA, 1999.
[11] J.-C. Fabre, F. Salles, M. Rodríguez Moreno and J. Arlat,
“Assessment of COTS Microkernels by Fault Injection”,
in
Proc. 7th IFIP Working Conf. on Dependable Computing for
Critical Applications: DCCA-7, San Jose, CA, USA, Jan. 1999.
Acknowledgements
Funding for this paper was provided, in part, by Portuguese
Government/European Union through R&D Unit 326/94
(CISUC) and by DBench project, IST 2000 - 25425 DBENCH,
funded by the European Union.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:24:52 UTC from IEEE Xplore.  Restrictions apply.