𝑈𝑟 such that this simulated transcript is indistinguishable from a
real transcript to any efficient distinguisher with access to 𝑈𝑠 and
𝑈𝑟 ’s secret keys.
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1498Substituting in a weaker assumption on the messaging scheme
would just result in the same weakened guarantee for the overall
system, so using this approach means that we can guarantee a
source-tracking scheme preserves the offline deniability of any
messaging scheme it is built on top of.
Following the approach of [31], we additionally show that in
addition to universal deniability, where the forger has access to an
arbitrary third party user and the discerning party has access to
the long-term keys of all involved users, our schemes also satisfy
platform-compromise deniability, which gives the forger and dis-
cerning party additional access to the platform’s keys. This second
form of deniability ensures that even in the event that the platform
was compromised and its secret keys exposed, deniability can be
preserved.
While not required in our definition for deniable source-tracking
schemes, it is worth noting that our scheme constructions provide
strong deniability protections for reporters of malicious messages,
regardless of the deniability guarantees of the underlying messaging
scheme. Neither scheme makes use of the messaging oracles or
users’ secret keys while making a report, and additionally anyone
with knowledge of the forwarding data for a particular message
can report it even if they themselves did not receive it, meaning
that the pool of users who could have reported a message is not
restricted to the users on the forwarding path of the message in
question.
We present two security games to address each of these types of
deniability: 𝑈 𝑛𝑖𝑣𝐷𝐸𝑁 and 𝑃𝑙𝑎𝑡𝐷𝑒𝑛 (Figure 8). Each game accepts
the corresponding forgery algorithm that simulates a forwarding
path’s transcripts as a parameter. The games get access to a chal-
lenge oracle Chal(·, ·, ·, 𝑡𝑦𝑝𝑒), where the value of 𝑡𝑦𝑝𝑒 is either u
(universal) or p (platform) depending on the type of game, as well
as the ability to create new users of their choice.
The deniability challenge consists of the adversary presenting a
query that consists of a message 𝑚, a path of users 𝑝, a forging user
𝑈𝐷, and a list of metadata mds. The challenge will either output
the actual transcripts (𝑇𝑟𝑟 , 𝑇𝑟 𝑓 , and 𝑇𝑟𝑟𝑒𝑝) and forwarding data
resulting from sending the message along the path and then being
reported by the last user, or a forged version constructed by in-
putting the query into the forgery algorithm, which is given access
to the sending and receiving capabilities of 𝑈𝐷 and a simulator
for the underlying messaging scheme, SimE. The functions of this
oracle are presented in Figure 8 as interactive protocols where F is
the portion of the interaction that the forger can control.
B SECURITY PROOFS FOR TREE-LINKABLE
SOURCE-TRACKING
B.1 Confidentiality – Proof of Theorem 4.1
Proof. The proof of this statement follows immediately from
combining the results of Lemmas B.1 and B.2, which prove user
and platform confidentiality, respectively.
□
Proof. We construct a series of hybrid games to show that
𝑙𝑈𝐶𝑂𝑁 𝐹 1 is indistinguishable from 𝑙𝑈𝐶𝑂𝑁 𝐹 0 to any efficient ad-
versary. This proves that the scheme satisfies tree-linkable user
confidentiality.
G0: This game is identical to the standard 𝑈𝐶𝑂𝑁 𝐹 game when
𝑏 = 0.
G1: We modify goodAuth (oracle function for authoring a mes-
sage between two honest users) and malSend (oracle func-
tion for sending a message from a malicious user) so that
the 𝑠𝑟𝑐 the platform computes and includes in the platform
data is an encryption of some default user and metadata
𝑈𝐷||md𝐷 rather than the actual author of the message (the
default data can, for example, be an all-zero string). Because
the adversary does not have the secret key, and this value is
never decrypted by the platform, this version of the game is
indistinguishable from Game 0 by the CPA-security of the
platform’s encryption scheme, P.
G2: We modify goodFwd (oracle function for forwarding a mes-
sage between two honest users) to immediately abort if the
user provides an 𝑚𝑖𝑑 ∈ 𝑇𝑟𝑒𝑐 such that the signature or com-
mitment included in the forwarding data for the associated
message is invalid. By the definition of the scheme, any mes-
sage stored in 𝑇𝑟𝑒𝑐 that’s associated with an honest receiver
was received successfully by that honest user who checked
the correctly formed signature and commitment, so this will
never happen, and this game is indistinguishable from Game
1.
G3: We again modify goodFwd so that after checking that
the users associated with the given 𝑚𝑖𝑑 are correct and
that 𝑚𝑖𝑑 ∈ 𝑇𝑟𝑒𝑐, if 𝑚, fd, 𝑡𝑖𝑑 is the data associated with
the provided 𝑚𝑖𝑑, the oracle doesn’t actually forward the
message but instead just adds a new entry 𝑇𝑟𝑒𝑐[𝑚𝑖𝑑′] =
(𝑈𝑠, 𝑈𝑟 , 𝑚, fd, 𝑡𝑖𝑑) to the table. By definition of the scheme,
the resulting entry in 𝑇𝑟𝑒𝑐 is identical to the entry if the
message had actually been forwarded, and so this game is
indistinguishable from Game 2 as the oracle does not modify
any other persistent state outside of the table 𝑇𝑟𝑒𝑐.
We note that after these modifications, the output of malRec
(oracle function for forwarding a message to a malicious receiver,
the function gets two potential forwards and uses the value of 𝑏 to
determine which one the adversary sees), which is the only oracle
function that uses 𝑏 to decide what to output, no longer depends on
𝑏 because the forwarding data of all honestly sent messages have
the same contents. This means that applying and identical series of
hybrid steps to those described in G0 to G3 starting at 𝑙𝑈𝐶𝑂𝑁 𝐹 1
instead of 𝑙𝑈𝐶𝑂𝑁 𝐹 0 gets us to a game identical to Game 3 that is
indistinguishable from 𝑙𝑈𝐶𝑂𝑁 𝐹 1 to an efficient adversary.
Thus we have shown that we can go from 𝑙𝑈𝐶𝑂𝑁 𝐹 0 to 𝑙𝑈𝐶𝑂𝑁 𝐹 1
through a series of indistinguishable hybrids, and we can con-
clude that any adversary’s advantage against the 𝑙𝑈𝐶𝑂𝑁 𝐹 game
for Scheme 1 must be negligible.
□
Lemma B.1. Assuming that P is CPA-secure, and the commitment
and signatures schemes C and S are correct, the advantage of any
efficient adversary against the 𝑙𝑈𝐶𝑂𝑁 𝐹 game for Scheme 1 is negli-
gible.
Lemma B.2. Assuming that the commitment scheme is hiding and
the messaging encryption scheme E is AE-secure, the advantage of
any efficient adversary A against the 𝑃𝐶𝑂𝑁 𝐹 game for Scheme 1 is
negligible.
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1499𝑆𝑇 ,E,UForge
𝑈 𝑛𝑖𝑣𝐷𝐸𝑁 A,𝑏
(pk, sk) ←R KGen(𝑝𝑎𝑟𝑎𝑚𝑠)
𝑏′ ← AOu (pk)
return 𝑏′
Chal(𝑝𝑎𝑡ℎ, 𝑈𝐷, 𝑚, mds, 𝑡𝑦𝑝𝑒)
𝑆𝑇 ,E,PForge
𝑃𝑙𝑎𝑡𝐷𝐸𝑁 A,𝑏
(pk, sk) ←R KGen(𝑝𝑎𝑟𝑎𝑚𝑠)
𝑏′ ← AOp (pk, sk)
return 𝑏′
//Construct path
(𝑈0, ..., 𝑈𝑘) ← 𝑝𝑎𝑡ℎ
if 𝑈𝐷, 𝑈0, ..., 𝑈𝑘 ∉ U :
return ⊥
ad ← 𝑇𝑎𝑢𝑡ℎ[𝑈0], 𝑚𝑠𝑔 ← (𝑚, ad)
(ad′, 𝑝𝑑, 𝑒) ← ⟨𝑈𝑎𝑢𝑡ℎ(𝑚𝑠𝑔), 𝑃𝑠𝑒𝑛𝑑 (sk, mds[0])⟩(𝑈0, 𝑈1, pk)
(𝑚, fd,𝑇 𝑟𝑟) ← ⟨𝑈𝑟𝑒𝑐, 𝑃𝑟𝑒𝑐 (sk, 𝑝𝑑)⟩(𝑈0, 𝑈1, 𝑒, pk)
𝑜𝑢𝑡𝑝𝑢𝑡0.𝑎𝑝𝑝𝑒𝑛𝑑((𝑇 𝑟𝑟 , fd)),𝑇𝑎𝑢𝑡ℎ[𝑈0] ← ad′
for 𝑖 = 1, ..., 𝑘 − 1 :
𝑚𝑠𝑔 ← (𝑚, fd)
(fd′, 𝑝𝑑, 𝑒,𝑇 𝑟 𝑓 ) ← ⟨𝑈𝑓 𝑤𝑑 (𝑚𝑠𝑔), 𝑃𝑠𝑒𝑛𝑑 (sk, mds[𝑖])⟩(𝑈𝑖, 𝑈𝑖+1, pk)
(𝑚, fd,𝑇 𝑟𝑟) ← ⟨𝑈𝑟𝑒𝑐, 𝑃𝑟𝑒𝑐 (sk, 𝑝𝑑)⟩(𝑈𝑖, 𝑈𝑖+1, 𝑒, pk)
𝑜𝑢𝑡𝑝𝑢𝑡0.𝑎𝑝𝑝𝑒𝑛𝑑(𝑇 𝑟 𝑓 , fd′,𝑇 𝑟𝑟 , fd)
((𝑠𝑟𝑐, md),𝑇 𝑟𝑟𝑒𝑝) ← ⟨𝑈𝑟𝑒𝑝 (fd), 𝑃𝑟𝑒𝑝 (sk)⟩(𝑚, pk)
𝑜𝑢𝑡𝑝𝑢𝑡0.𝑎𝑝𝑝𝑒𝑛𝑑(𝑇 𝑟𝑟𝑒𝑝, (𝑠𝑟𝑐, md))
//construct forgery
if 𝑡 𝑦𝑝𝑒 = u :
if 𝑡 𝑦𝑝𝑒 = p :
return 𝑜𝑢𝑡𝑝𝑢𝑡𝑏
𝑜𝑢𝑡𝑝𝑢𝑡1 ← UForgeO(𝑈𝐷 ) (𝑝𝑎𝑡ℎ, 𝑚, mds, pk)
𝑜𝑢𝑡𝑝𝑢𝑡1 ← PForgeO(𝑈𝐷 ) (𝑝𝑎𝑡ℎ, 𝑚, mds, pk, sk)
return ⊥
getUser(𝑈)
if 𝑈 ∈ U :
(ad, U′) ← ⟨𝑈𝑛𝑒𝑤, 𝑃𝑛𝑒𝑤 (U, sk)⟩(𝑈 , pk)
𝑇𝑎𝑢𝑡ℎ[𝑈 ] ← ad, U.𝑎𝑑𝑑(𝑈)
return ad
ForgeSend(𝑈𝑟 , md)
(𝑝𝑑, 𝑒) ← ⟨F, 𝑃𝑠𝑒𝑛𝑑 (sk, md)⟩(𝑈𝐷, 𝑈𝑟 , pk)
if 𝑈𝑟 ≠ 𝑈𝐷 : return
⟨F, 𝑃𝑟𝑒𝑐 (sk, 𝑝𝑑)⟩(𝑈𝐷, 𝑈𝐷, 𝑒, pk)
Report(𝑚)
⟨F, 𝑃𝑟𝑒𝑝 (sk)⟩(𝑚, pk)
𝑒 ← SimE(𝑈𝑠, 𝑈𝑟 , 𝑚)
Oracle functions O(·) for forgery algorithms. SimE
simulates a transcript of the messaging scheme using
the simulator guaranteed to exist by the deniability of
the messaging scheme.
Figure 8: Deniability games and oracle functions. Oracles O𝑡 𝑦𝑝𝑒 for 𝑡 𝑦𝑝𝑒 = u or p give the adversary access to the functions getUser(·, ·),
Chal(·, ·, ·, ·, 𝑡 𝑦𝑝𝑒), and send(·, 𝑈 , ·) and receive(·, ·, 𝑈) oracles for the underlying messaging scheme for all users 𝑈 ∈ U. Oracle O(𝑈𝐷)
gives the forgery algorithms access to the Send and Report functions.
Note that the lemma requires that the messaging scheme guar-
antee authenticated encryption. This sort of guarantee is common
among most encrypted messaging schemes, such as Signal’s Double
Ratchet Protocol [23].
Proof. We first present a series of hybrid games that show an
adversary cannot gain advantage by tampering with messages be-
tween honest users. By definition of the scheme, the platform is
tasked with passing on the platform data (𝜎, 𝑠𝑟𝑐) to the receiving
user, and the security game additionally gives the option for the
platform to choose the message identifier 𝑒 that the receiver gets
as input. The platform could stray from the correct protocol by
calling goodRec (oracle function for receiving a message between
honest users) with an 𝑒 that wasn’t the same as the one outputted
by the sending interaction associated with the 𝑚𝑖𝑑, or by signing
a value other than the 𝑠𝑟𝑐 value chosen by the platform and the
commitment presented by the sender.
G0: This initial game is identical to 𝑃𝐶𝑂𝑁 𝐹 A,0
𝑆𝑇 ,E, the game when
G1: We add the additional condition to goodRec to abort imme-
diately if the inputted 𝑒 value has never been outputted by
the sender 𝑈𝑠 as part of a message to the receiver 𝑈𝑟 at any
𝑏 = 0.
point in the game. By definition, this can only happen dur-
ing a call to goodSend because 𝑈𝑠 and 𝑈𝑟 are honest. This
is indistinguishable from G0 because finding a valid 𝑒 that
was not sent from 𝑈𝑠 to 𝑈𝑟 contradicts the authenticated
encryption properties of the messaging scheme, specifically
its ciphertext integrity, and can therefore happen with only
negligible probability.
We note that if the adversary presents a different 𝑒 but the
game does not abort due to the above condition, 𝑒 must have
resulted from a call to goodSend between 𝑈𝑠 and 𝑈𝑟 earlier
in the game, and so there exists some 𝑚𝑖𝑑′′ in 𝑇𝑠𝑒𝑛𝑑 that
stores 𝑒. The only difference between calling goodRec with
the correct pair (𝑚𝑖𝑑′′, 𝑒) instead of (𝑚𝑖𝑑, 𝑒) is that the 𝑡𝑖𝑑
will always be ⊥, which only weakens the adversary’s power
because it can no longer see the message contents by having
the message reported and so we can assume that 𝑒 = 𝑒′ in
all other cases.
In this game, if during goodRec the platform presents an
honest user with platform data (𝜎, 𝑠𝑟𝑐) and a message iden-
tifier 𝑒 such that 𝜎 is a signature on the pair (𝑐𝑚, 𝑠𝑟𝑐), but
(𝑐𝑚, 𝑒) was never sent by the sending user, the game aborts.
By the properties of Game 1, we know that the 𝑒 must have
G2:
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1500been created by the sending user and so contains an encryp-
tion of the commitment 𝑐𝑚 that the sender linked to 𝑒, and
therefore the receipt of the message will fail when the re-
ceiving user compares the commitment that is signed by the
platform to the value encrypted in 𝑒. Therefore, this game is
indistinguishable from Game 3 because an adversary cannot
create an otherwise valid message that fails for this reason.
Similarly, the 𝑠𝑟𝑐 value is chosen by the platform and sent
over in the clear, so the platform gains no advantage by
signing a value other than the correct 𝑠𝑟𝑐, because it already
knows it will cause the signature verification to fail.
We conclude that a platform gains no advantage by passing a
receiver something other than the platform data and message iden-
tifier outputted by following the honest protocol. We now present
two hybrids that show forwarded messages are indistinguishable
from authored messages.
G3: Game 3 is identical to Game 2, except that during goodSend,
a forwarded message 𝑚 with forwarding data 𝜎, 𝑠𝑟𝑐, 𝑐𝑚, 𝑟
that would normally be forwarded as 𝑒, 𝑐⊥ where 𝑐⊥ is a
commitment to ⊥ is instead forwarded with 𝑒, 𝑐′
𝑚 where 𝑐′
𝑚
is a new commitment to 𝑚. The honest receiver evaluates the
message as if 𝑐′