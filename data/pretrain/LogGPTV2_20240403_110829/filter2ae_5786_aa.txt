本文作者：那我就随便唱两句，本文发表于‘小米安全中心’，
    原文地址：https://sec.xiaomi.com/article/15
#### 乱谈Python并发
说实话，我一直觉得PHP真的是最好的语言，不仅养活了一大批PHP程序员，同时还为安全人员提供了大量的就业机会。然而，令人唏嘘的是，安全界很多人其实是吃着Python的饭，操着PHP的心。此外，大量的安全研究工具也都是使用Python开发，比如我始终不习惯的mitmproxy，又或者一个循环语句400行的sqlmap、一抓一大把的爬虫框架以及subprocess满天飞的命令行应用包装库。
干活要吃饭，吃饭要带碗。既然这样，要进入互联网安全领域，无论是小白还是高手，多少是要了解点Python的。虽然笔者只是个安全太白，连小白都够不上，但我Python比你专业啊。我看过一些安全人员写的代码，不可否认，功能是有的，代码是渣的，这我非常理解，毕竟术业有专攻，要我去挖洞我也麻瓜，挖个坑倒可以。
其实，Python可以谈的话题很多，比如Python2还是Python3，比如WSGI，比如编码，比如扩展，比如JIT，比如框架和常用库等等，而我们今天要说的则是异步/并发问题，代码运行快一点，就能有更多时间找女朋友了。
#### 进程
众所周知，CPython存在GIL（全局解释锁）问题，用来保护全局的解释器和环境状态变量，社区有过几次去GIL的尝试，都以失败告终，因为发现即使去了GIL，性能好像提高也不是那么明显嘛，还搞那么复杂。注意，这里说的是CPython，Python语言本身是没说要必须有GIL的，例如基于JVM的Jython。而GIL的结果就是Python多线程无法利用多CPU，你128核又如何，我就逮着一只羊薅羊毛了。所以，如果功能是CPU密集型的，这时候Python的进程就派上用场了，除此之外，利用C扩展也是可以绕过GIL的，这是后话。
进程模型算是一种比较古老的并发模型。Python中的进程基本是对系统原生进程的包装，比如Linux上的fork。在Python标准库中，主要是multiprocessing包，多么直白的名字。其中常用的也就是pool，queue模块以及synchronize模块中的一些同步原语（Lock、Condition、Semaphore、Event等）。如果需要更高级的功能，可以考虑下managers模块，该模块用来管理同步进程，大致的实现原理是在内部起了一个server，进程都与这个server交互，进行变量共享...目瞪狗呆有没有，这个模块笔者也只用过两三次，如需对进程进行高级管理，请移步此处。
另外，multiprocessing中有个dummpy子模块，重新实现了一遍多进程模块中的API，然而，它是多线程的，就这么乱入，目的是方便你的代码在多线程和多进程之间无障碍切换，很贴心有没有，而且异常低调，低调到官方文档就一句话，17个单词。
如果你的代码需要大量的CPU运算，多进程是一个比较好的选择。对于安全领域的来说，这种场景貌似不是很多，什么？需要大量加密解密？都到自己要实现这么高深算法的程度了，别挣扎了，用C吧，写个扩展更好。
所以，如非必须，我是不太推荐用多进程的，容易出错，不好控制，而且，有更省心的选择，谁会和自己过不去呢。
#### 线程
与进程一样，Python中的线程也是对系统原生线程的包装。其实现在的Linux上，线程和进程的差别不是很大，以此推知，Linux平台下，Python中的线程和进程开销差别也不会太大，但终归进程是要开销大点的，创建也会慢一点。相比于进程，我是更倾向使用线程的，尤其是IO密集型程序，能用线程解决的问题，尽量不用进程。
另外，如果要在进程之间共享数据，确实比较头疼一点，要用到Queue、Pipe、SyncManager或者类似redis这种外部依赖，而线程之间共享数据就方便很多，毕竟大家都是一个爹生的，家里东西一起用吧。有人可能会觉得，线程能共享数据，但是也会在修改数据时互相影响，导致各种难以排查的BUG，这个问题提的好，之所以有这种问题，还不是因为代码写的烂，多练练就好了。如果既想要方便的共享数据，还要能随意的隔离数据，threading.local()可以帮你，创建的变量属于线程隔离的，线程之间互不影响，上帝的归上帝，恺撒的归恺撒。说到ThreadLocal变，我们熟知的Flask中每个请求上下文都是ThreadLocal的，以便请求隔离，这个是题外话。
Python中的线程主要是在threading模块里，这个模块是对更底层的_thread的封装，提供了更友好的接口。该模块中用到比较多的也是Queue、Pool、Lock、Event等，这些就不展开了，有机会再一一细说。Python
3.2后还引入了一个比较有意思的新类，叫Barrier，顾名思义，就是设置个障碍（设置数目n），等大家都到齐了（每个线程调用下wait，直到有n个线程调用），再一起出发。Python
3.3也在进程中引入了对应的此模块。此外，还有Timer可以用来处理各种超时情况，比如终结subprocess创建的进程。
创建多线程有两种方式：一种是继承threading.Thread类，然后实现run方法，在其中实现功能逻辑；另一种就是直接threading.Thread(target=xxx)的方式来实现，与进程模块大同小异。具体使用可以参考官方文档，这里就不赘述了。
#### 协程
前面我们提到了，Python的线程（包括进程）其实都是对系统原生内核级线程的包装，切换时，需要在内核与用户态空间来来回回，开销明显会大很多，而且多个线程完全由系统来调度，什么时候执行哪个线程是无法预知的。相比而言，协程就轻量级很多，是对线程的一种模拟，原理与内核级线程类似，只不过切换时，上下文环境保存在用户态的堆栈里，协程“挂起”的时候入栈，“唤醒”的时候出栈，所以其调度是可以人为控制的，这也是“协程”名字的来由，大伙协作着来，别总抢来抢去的，伤感情。
实际上，协程本身并不是真正的并发，任何时候只有一个协程在执行，只是当需要耗时操作时，比如I/O，我们就让它挂起，执行别的协程，而不是一直干等着什么也做不了，I/O完毕了我们再切换来继续执行，这样可以大大提高效率，而且不用再费心费力去考虑同步问题，简单高效。与传统线程、进程模型相比，协程配上事件循环（告诉协程什么时候挂起，什么时候唤醒），简直完美。Python里的协程也是后来才逐渐加入的，基本分三个阶段，过程比较坎坷，与”携程“差不多，时不时被骂几句。
#### yield/send
这算是第一个阶段，其实yield主要是用来做生成器的，不要告我不知道什么叫生成器，这多尴尬。Python
2.5时，yield变成了表达式（之前只是个语句），这样就有了值，同时PEP
342引入了send，yield可以暂停函数执行，send通知函数继续往下执行，并提供给yield值。仔细一看，好巧啊，这么像协程，于是屁颠屁颠的把生成器用来实现协程，虽然是半吊子工程，不过还不错的样子，总比没有的好，自此我们也可以号称是一门有协程的现代高级编程语言了。
可以这么说，对于不考虑yield返回值情形，我们就把它当作普通的生成器，对于考虑yield返回值的，我们就可以把它看作是协程了。
但是，生成器干协程的活，总归不是那么专业。虽然生成器这货能模拟协程，但是模拟终归是模拟，不能return，不能跨堆栈，局限性很大。说到这里，连不起眼的Lua都不屑于和我们多说话，Go则在Goroutine（说白了还不是类协程）的道上一路狂奔，头都不回，而Erlang轻轻抚摸了下Python的头，说句：孙子诶。
既然Python 2.x中的yield不争气，索性我们来改造下咯，于是Python 3.3（别老抱着Python