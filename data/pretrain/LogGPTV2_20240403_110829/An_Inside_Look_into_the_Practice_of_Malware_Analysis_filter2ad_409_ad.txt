normal user
.net, MSVC
runtimes
Table 3: General environment features: For the participants who strive to create a general dynamic analysis environment, a
check (!) signifies that the participant sets the corresponding configuration in their environment.
ID Timezone Language
Filenames
Browser
History
Populate
Files
!
!
!
!
!
!
P2
P4
P5
P13
P19
Table 4: Specific environment features: For the participants
who configure specialized environments for running indi-
vidual malware samples, a check (!) signifies that the par-
ticipant configures the corresponding environment feature
for individual samples.
!
!
Some malware rely on features in the environment to complete
malicious actions. An example of this is phishing emails with mali-
cious documents attached. The environment must have Microsoft
Office installed to run the commands that are embedded in the file.
Therefore, to see some of the behaviors of the sample, the dynamic
analysis environment must be configured in a certain way. One
method, described by 10 participants, for analyzing such samples is
to configure a general environment that can analyze many samples
without modifying the environment. For example, P13 said that
"scattering a couple files and some basic software [...] is slightly
more than bare minimal," which was also confirmed in the follow-
up survey. This is especially true when samples are being executed
for the first time because the analysts do not know what environ-
ment the sample requires until they do a more in-depth analysis.
After the first execution in a general environment, the analysts will
then decide whether they want to continue testing out different
dynamic analysis configurations or utilize static analysis.
When the participants decide to continue using dynamic analy-
sis, 5 participants configure their environments either to replicate
the target of specific samples or to avoid evasion techniques. Specif-
ically, some samples will evade analysis by checking the values of
environment variables such as the language or time zone and not
performing malicious tasks if it is not running on its targeted sys-
tem. Such evasive malware pose additional challenges that analysts
must decide how to handle. These participants choose to handle
evasive malware by configuring the analysis environment specif-
ically for a sample. For example, P1 stated that he runs malware
samples in a "similar operating system to what [his] customers
were running" in order to emulate, as closely as possible, the mal-
ware’s target environment. This creates an analysis environment
that the malware is more likely to attack, allowing the analyst to
observe more of the sample’s malicious behavior. Table 4 shows
the features that these participants set for individual samples. Each
feature can be tied to a different evasion technique seen in malware
samples. For example, malware samples may target a specific geo-
graphic region. P2 executes samples in "different regions around the
world and he runs that same url or that same payload through each
region looking for different characteristics" because he does not
know "what the attacker is looking for or who they are targeting."
Similarly, malware that exfiltrates data may only take specific files,
so if these files are not present during the analysis, the real behavior
of the sample will not be captured.
A surprising result is that although tier 3 participants look at
specific malware samples, they do not spend as much time or ef-
fort customizing their environment. As P19 described, "I probably
wouldn’t bother. It would be interesting, but at that point [...] I
would just statically analyze and reverse engineer it." However, in
the follow-up survey, P19 clarified that he occasionally sets the
browser history and populates files.
Another approach that 2 participants discussed for setting up dy-
namic analysis systems is to use an automatic script that randomizes
the features of a general, realistic environment that were previously
mentioned. This approach not only reduces the setup time, but can
also help prevent malware from fingerprinting the analysis system.
Due to the randomness of the environment, malware cannot iden-
tify specific characteristics of the analysis environment to search
later to identify that they are being analyzed.
6.4 Configuring Network Communication
The next consideration of a dynamic analysis environment is how
to configure the network connection. 17 participants believe that
capturing the network behavior of malware when it is allowed to
connect to the real Internet provides insights that are beneficial
in conducting their analysis. These participants are aware of the
potential risks of malware samples causing harm to other Internet
users and take the necessary precautions to avoid causing serious
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3061harm. The precautions that participants take are similar to what
previous work has taken, such as blocking outbound communica-
tion from specific protocols commonly used for denial-of-service
attacks [20, 24, 32, 41, 64, 65].
In contrast, 2 participants from incident response and threat
intelligence teams are concerned that malware may trace them
back to their company. One possible solution for this problem is to
analyze the malware through VPNs that appear to originate in a lo-
cation other than where the analysts currently are. However, these
participants argue that this technique does not protect against the
attackers tracing the analysts back to their company. For example,
P12 states that "If it’s part of an incident response engagement,
we don’t do that because we don’t want to tip off the threat actor
that we are investigating." An alternative option is network emula-
tion, which allows incident responders to send synthetic network
responses to the malware and analyze some network behavior with-
out anything escaping their analysis environment and alerting the
attackers that their malware is being analyzed. This technique can
also be helpful when a C2 server is down and analysts want to
observe how the malware would communicate with it.
6.5 Dynamic Analysis Execution Time
When performing dynamic analysis, participants must decide how
long to run each malware sample. Through our interviews, we
discovered that 15 participants run samples for a short time period
(less than 5 minutes) because executing a sample requires resources,
which are limited. To run all the samples that tier 1 and tier 2
participants collect, the time allocated to each must be small. Also,
participants like P18 argue that "a low execution time limits the
amount of damage that can [be] done."
However, there are exceptions to this short execution time. 4
participants in tiers 2 and 3 tend to run their samples for multiple
hours. One reason that participants prefer longer execution time is
that changing the flow of time gives malware an artifact that they
can use to evade the analysis system. Therefore, to observe the true
behavior of the malware, these participants state that they do not
alter the time. Finally, in tier 3, 3 participants perform longitudinal
studies of malware, lasting for months. A long-term analysis allows
these participants to understand the motivation and tactics behind
the attack. Finally, 2 participants try to create tools that allow them
to monitor an attacker’s C2 infrastructure and gain first hand access
to malware being distributed by the attacker. This allows them to
be proactive by enhancing defensive security measures to protect
against new techniques and avoid being compromised when these
techniques are eventually deployed. P18 stated that their system
"can tell within minutes if any spam campaign is sent or if they
updated the configuration."
6.6 Overcoming Evasion
The last component of the dynamic analysis workflow we investi-
gated was how analysts handle evasive malware samples. 16 par-
ticipants in tiers 2 and 3 utilize techniques such as debugging and
patching malware to get evasive malware to reveal its malicious
behavior during dynamic analysis. For example, P17 stated that
"the debugger can be used to bypass the evasion checks that are
anti-virtualization." Once the participants identify the evasion tech-
niques with signatures such as Yara, they can use a debugger to
manually skip over them and execute the malicious behavior. This
process has been partially automated by tools such as CAPE Sand-
box [1]. Similarly, 4 participants choose to patch the malware, com-
pletely removing evasive checks.
A different approach for handling evasive malware mentioned
by a few participants is to utilize existing open-source solutions
such as Al-Khaser [3]. Al-Khaser is a tool that runs in a sandbox and
provides a list of evasion techniques that the sandbox is susceptible
to. Our interviews also confirm that practitioners and researchers
manipulate the system time to bypass time-based evasive checks
as extensively studied in past work [38, 39, 63, 81].
7 DISCUSSION
After examining how the participants perform malware analysis
in practice, we identified challenging steps in their workflows. We
believe that these challenges faced by practitioners can be ame-
liorated by the malware analysis research community. First, we
identify previous research that has not yet fully transitioned into
practice. Second, we highlight remaining research questions and
propose future directions that leverage the expert domain knowl-
edge gained in this study to help answer these questions. Third, we
present recommendations for improving the usability of malware
analysis systems.
7.1 Transitioning Research to Practice
In this section, we identify research that has the potential to ease
some of the challenges our participants face in practice. As previ-
ously discussed, one of the most common challenges with dynamic
malware analysis is determining how to get a malware sample to
reveal its malicious behavior. P13 said that one of the biggest chal-
lenges is "probably if it doesn’t run, trying to figure out why it
doesn’t run. It seems that dynamic analysis for the things that run
tend to do a pretty good job, but if it doesn’t run or produce any
output; that rabbit hole you have to go on." While analysts have
ways to handle a variety of evasion techniques, there is no single
solution to get a sample to execute its malicious instructions. One
technique that participants use to avoid being evaded is by creating
an environment that is appealing to the malware. Another strategy
to avoid evasion that has been explored in research is to analyze
the malware in more transparent environments. A considerable
amount of research in this area could be transitioned into prac-
tice [39, 52, 71, 83, 84]. These methods try to defeat fingerprinting
by removing artifacts in the analysis environment that malware can
associate with the analysis system. If these methods could be tran-
sitioned into practice, practitioners could analyze their malware in
these environments and, due to the increased transparency, mal-
ware samples would be less likely to evade analysis. This method
could allow analysts to capture more of the sample’s malicious be-
havior. Although these are promising analysis techniques, their use
in practice may not be straightforward. As P21 said, "I read a bunch
of academic papers, but what I often found was that a lot of them
were in a lab scenario where you control the inputs and outputs.
Extrapolating that into something that I can use is difficult." The
transparency of these methods prevents malware from detecting
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3062that it is being run in a controlled environment however, they do
not analyze the malware in its targeted environment. This study
has shown that configuring the analysis environment to mimic its
targeted environment is critical to get some malware samples to
reveal their malicious behavior. In the next section, we propose
future research that has the potential to address these remaining
challenges.
Determining whether a sample is a variant of a previously ana-
lyzed sample is a common task that most malware analysts have to
perform to avoid conducting an in-depth analysis of a known sam-
ple. From the interviews, 14 participants stated that this remains
a challenging process. For example, when asked what strategies
P2 uses to identify malware variants, he replied, "I’m going to say
there are no good tools or resources, at least in the free space, that
help in that arena." Although this remains a challenge in practice, it
is important to note that there has been a considerable amount of
research to address this problem, including methods that leverage
dynamic features [24, 27, 68], static features [42], or a combina-
tion of the two [44]. These features are used to classify or cluster
malware samples into their respective families automatically. By
combining these techniques with the large amount of malware sam-
ples that practitioners have access to, analysts could build clusters
that divide samples into different families. These clusters could then
be used later to determine whether an unknown sample fits into a
known malware family. By adopting these techniques, practition-
ers could reduce the amount of time spent determining whether
samples are variants, and instead focus on analyzing the novel
samples.
Additionally, 8 of the participants stated that the task of deter-
mining whether two malware functions are similar is one of the
more time-consuming tasks they need to perform. As P21 stated,
"Figuring out if two binaries have the same function is a really, re-
ally hard problem that I worked on to get something close to right.
Being able to say that these are reliable results and putting a stamp
[saying that those] two match is difficult." There has been past re-
search that addresses the problem of function similarity [59, 62, 77].
Some of these solutions propose a hybrid method with dynamic
and static analysis, while others use machine learning based ap-
proaches to identify similar functions. The algorithms proposed in
these papers could be implemented as a new analysis feature as a
first step towards addressing malware function similarity.
Another challenging task identified in practice is distinguishing
between malicious and benign behaviors found in dynamic analysis
execution outputs. As P6 said, "To use a sandbox you need to have a
good idea of what is baseline behavior. [...] You can’t just put it in a
sandbox and take all the results. You need to be able to look at it and
say that’s regular windows and adobe behavior. That’s something
that can trick people a lot." One approach to address this problem is
to compare the system calls generated by a malware sample to the
system calls generated by benign applications when executed in
a dynamic analysis system. Christodorescu [35] provides such an
algorithm that practitioners could use to compute the differences
between these system traces, and automatically separate malicious
behavior from normal system behavior.
The last time-consuming process that we identified could bene-
fit from past research is unpacking malware samples. Unpacking
malware samples is a task that 7 participants not only describe
as time-consuming, but 3 participants also state that the effort of
unpacking does not provide them any useful information about
the malware. In fact, they would rather spend their time on more
valuable tasks such as analyzing the functions of a malware sample.
There are many research systems that address various types of un-
packing. Such systems include PolyUnpack [69], Rambo [74], and
BinUnpack [34]. These systems focus on automating the process of
unpacking and have the potential to help analysts in practice.
7.2 Future Research Directions
In addition to the challenges discussed in subsection 7.1, we identi-
fied additional challenges that participants faced, which potentially
pose new research questions. In this section, informed by the exper-
tise of our participants, we define some future research directions
that may help fill existing gaps in these areas.
How to configure a dynamic analysis environment that repli-
cates a malware’s targeted environment. As seen in section 6,
configuring the dynamic analysis environment to match the mal-
ware sample’s targeted environment can be crucial to observe a
sample’s full, malicious behavior. Although previous work done by
Brumley et. al. [30] identifies the triggering events that cause a mal-
ware sample to execute its malicious behavior, it is still unclear how
to automatically configure the runtime environment of a dynamic
analysis system such that it is an appealing target for the sample.
In practice, we found that many participants use static analysis
to determine what features are required in the dynamic analysis
environment to trigger the malicious behavior. One potentially im-
pactful research direction is building an integrated hybrid analysis
system to empower analysts. It could leverage previous research
such as GoldenEye [79], which proposed a method to identify the
targeted victim’s environment. This system first uses taint analysis
combined with manual analysis to identify conditional statements
that are sensitive to the environment. Next, it executes the mal-
ware in multiple environments, one for each possible return value
of the APIs that query the environment. Although this method is
more efficient compared to its predecessor, X-Force [67], it requires
significant memory to run a sample on multiple environments in
parallel.
The exploration of concurrent use of both static and dynamic
analysis in an integrated environment could be promising. First,
static analysis would automatically search the malware for condi-
tional checks of the targeted system. Then, symbolic analysis could
be applied to solve for the environmental conditions of the mal-
ware’s targeted system. After finding the necessary environmental
conditions, this system would suggest and set the corresponding
values in the dynamic analysis environment and re-run the mal-
ware sample. In contrast to GoldenEye [79], this system would only
execute the sample in a single environment, which would reduce
the amount of memory and computational resources required for
the analysis. Additionally, by incorporating feedback from malware
analysts, better predictions of the targeted environment could be
made over time, leading to faster analysis times. If a malware sam-
ple was packed, this tool would have to apply currently available
unpackers [34, 69, 74] to obtain a sample that can be statically
analyzed.
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3063How to automatically analyze multistage malware. Some par-
ticipants who use workflow 3a, seen in Figure 4a, need to analyze
multi-stage malware attacks. However, participants explain that
getting a sample to execute all of its stages at once can be quite
challenging. Running each stage independently is not effective be-
cause there can be dependencies between the different stages that
must be taken into consideration. Our study participants analyze
these campaigns by using dynamic analysis to run each stage and
static analysis to step through the process of downloading the next
stage and determining how it injects the payloads to ensure that
each stage runs as intended. A promising technique to address this
challenge is concolic execution, which uses a combination of both
symbolic and concrete analysis. Symbolic analysis could automate
the process of determining what inputs and settings each stage
requires to run as intended. Then, the concrete part of the analysis
could use the newly found inputs to properly execute the malware