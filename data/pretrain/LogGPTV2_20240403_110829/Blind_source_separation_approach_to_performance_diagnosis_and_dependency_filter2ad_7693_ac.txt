bottlenecks it is practically 100% accurate. An intuitive explana-
tion of such results versus the correlation measure is that accuracy
measure only penalizes incorrect binary decisions about the depen-
dency matrix values that result from thresholding, being more le-
nient than correlation measure about comparing real values.
Varying sparsity parameters. Next, we varied the parameter sX
that imposes sparsity on X. sX was varied from 0.1 to 0.95 for
H-NMF algorithm. We ﬁxed the noise level σ to a low value of
0.01, leaving the parameter sA imposing sparsity on A at the same
value of 0.5 as before. Figures 1c and 1d show the results for the
reconstruction of delay and dependency matrices respectively, sug-
gesting that higher sparsity over delay matrix generally improves
the reconstruction of both matrices, although for the delay matrix,
it might be better to avoid extremely high values, e.g. for sX > 0.9
performance starts to degrade. As before, delay matrix reconstruc-
tion is more sensitive to both sparsity and number of bottlenecks
than the dependency matrix reconstruction, and the accuracy results
for dependency matrix are quickly getting to practically 100% for
higher sparsities.
Finally, we performed the same set of experiments with varying
the second sparsity parameter, sA that imposes sparsity on A, while
keeping ﬁxed sX = 0.5, and observed quite similar behavior in
Figures 1e and 1f.
5. EXPERIMENTS: REAL TRAFFIC
We also evaluated our method on a real network trafﬁc collected
in a controlled environment. We used a small test lab containing
six routers (Cisco and Juniper) and six links, where end-to-end de-
lays were measured using probes such as SAA/rtr on Cisco routers
and RPM on Juniper routers. Note that here we focus on recon-
struction of link (rather than ’node’) delays. Only four probes were
necessary to ensure identiﬁability of a single link problem. The
topology of the network, and the corresponding dependency ma-
trix are shown in Figure 2a, where each probe name (e.g., 312)
describes the path of that probe through the routers. We performed
a controlled experiment, stressing a particular link (or a combina-
tion of links) with 30K 1400-byte ECHO_REQUEST packets in
order to induce performance bottlenecks10. Particularly, we ﬁrst
induced a bottleneck on link 16 that only affected the two probes
going through that link, 4216 and 4316 (Figure 2b shows the probe
delay data averaged over one-minute intervals). Then, we stressed
10Note that in our controlled environment we can measure not only
the end-to-end probe delays, but also all individual link delays,
which is hard to do in real, uncontrolled network environments,
and is a common challenge when evaluating approaches to link de-
lay inference from end-to-end measurements.
00.10.20.30.40.50.600.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays(sparsity on both A and X is 0.5)                     NoiseCorrelation  Bottlenecks 1Bottlenecks 5Bottlenecks 10Bottlenecks 15Bottlenecks 2000.20.40.60.8100.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays(sparsity on A is 0.5, noise is 0.01)                 Sparsity on XCorrelation  Bottlenecks 1Bottlenecks 5Bottlenecks 10Bottlenecks 15Bottlenecks 2000.20.40.60.8100.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays(sparsity on X is 0.5, noise is 0.01)                 Sparsity on ACorrelation  Bottlenecks 1Bottlenecks 5Bottlenecks 10Bottlenecks 15Bottlenecks 2000.10.20.30.40.50.600.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy(sparsity on both A and X is 0.5)NoiseAccuracy  Bottlenecks 1Bottlenecks 5Bottlenecks 10Bottlenecks 15Bottlenecks 2000.20.40.60.8100.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy(sparsity on A is 0.5, noise is 0.01)Sparsity on XAccuracy  Bottlenecks 1Bottlenecks 5Bottlenecks 10Bottlenecks 15Bottlenecks 2000.20.40.60.8100.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy(sparsity on X is 0.5, noise is 0.01)Sparsity on AAccuracy  Bottlenecks 1Bottlenecks 5Bottlenecks 10Bottlenecks 15Bottlenecks 20simultaneously two links, 12 and 13, and observed performance
degradation of probes 1249 and 312.
Results. We used the real data produced in our lab setting. Figures
2c-f show the reconstruction results for the link delays and the de-
pendency matrix in our lab setting, as a function of the sparsity on
the delay and dependency matrices in H-NMF algorithm, averaged
over 50 runs. Particularly, Figure 2c shows for each link (each
column in the true dependency matrix in Figure 2a) the correla-
tion between the true link delay corresponding to row in the known
true delay matrix XG and its best-matching (most correlated) row
in the reconstructed delay matrix X, as a function of varying H-
NMF sparsity parameter on X; Figure 2d shows the accuracy (as
measured before) of reconstructing the dependency-matrix column
corresponding to that link. Similarly, Figures 2e and 2f, show the
correlation and accuracy results as functions of varying sparsity on
the dependency matrix A. Note that the highest correlation (up to
0.65) is observed for the two links (12 and 13) that were stressed
(and thus ”revealed” themselves) for a prolonged period of time;
the link 16 which was also stressed but just for a short time period
comes next achieving the correlation of about 0.3. The remain-
ing unstressed links have lower correlations; note that increasing
sparsity parameters sometimes improves and sometimes hurts the
correlation, depending on a particular link. It is interesting to note
that the highest correlation between the true and reconstructed de-
lay (e.g., for links 12 and 13) does not necessarily imply the best
reconstruction accuracy in dependency matrix. Indeed, the most
accurate dependency reconstruction (around 80%) is achieved for
the link 49 corresponding to the last column in dependency matrix;
note that this link was not stressed and thus did not had a chance
to ”reveal” itself as a bottleneck, however, it appears on the path
of a single probe 1249 which may simplify its reconstruction. In-
terestingly, the reconstruction accuracy does not change much with
varying the sparsity parameters. The next best dependency recon-
struction results are achieved for the bottleneck links 13 and 16, as
well as for 34 (also on the path of only one probe); for those links,
accuracy does change with varying sparsity, but the effects of spar-
sity can be opposite for those links (higher sparsity on both X and
A helps 34 but hurts 13 and 16).
Since the accuracy and especially correlation values were less
impressive in real setting as compared with the Gnutella simula-
tions, we decided to perform the simulated trafﬁc experiment as
well, in order to better understand the sources of inaccuracies. (see
Figure 3). While simulations results, as expected, are somewhat
more accurate then the real experiment, they are still much less ac-
curate (both in terms of delay correlation and dependency matrix
reconstruction accuracy) than the corresponding results for a much
larger Gnutella network. This effect may be particularly due the ra-
tio between the number of bottlenecks and the network size, which
yields a much higher sparsity in large networks; on the contrary,
just two bottlenecks in our lab environment already constitute 1/3
of all links. We conjecture that our method works better in larger
networks with a small number of bottlenecks. However, other prop-
erties of both ”ground truth” dependency and link delay matrices
may also affect the reconstruction quality and require further in-
vestigation.
6. CONCLUSIONS AND OPEN ISSUES
This paper proposes a novel approach to the challenging problem
of the network bottleneck/delay diagnosis in the absence of depen-
dency/routing information. On the Gnutella an INET topologies,
we can conclude that reconstruction quality of our approach was
quite impressive and exceeded our expectations. We learned that
using nonnegative constraint on BSS approach, with sufﬁciently
high sparsity imposed on both dependency and node delay matri-
ces, is important for obtaining an accurate reconstruction. Clearly,
results deteriorate with increasing noise which might be an issue
in realistic scenarios. Preliminary results on real versus simulated
trafﬁc in small lab settings were somewhat less impressive; how-
ever, since even the simulation results in the same setting were
much less accurate than for larger networks, we conjecture that in-
dication that our approach should be more applicable in larger net-
works with reasonably small number of (more clearly ”pronounced”)
bottlenecks. Further investigation of our approach on real trafﬁc in
large-scale networks is the direction of our ongoing work. Another
interesting directions for future work include investigation of iden-
tiﬁability and uniqueness conditions for the proposed approaches in
practical scenarios, and applying this approach to other end-to-end
measures, besides the delays, such as jitter (variability), which is
particularly important in VoIP networks. Finally, we plan to extend
our approach to a ”semi-blind” source separation that can incorpo-
rate some partial dependency (routing) information.
7. REFERENCES
[1] R. Castro, M. Coates, G. Liang, R. Nowak, and B. Yu. Network
Tomography: Recent Developments. Statistical Science,
19(3):499–517, 2004.
[2] G. Chandalia and I. Rish. Blind source separation approach in
distributed systems management. IBM Technical Report, 2007.
[3] A. Cichocki, R. Zdunek, and S. Amari. New algorithms for
non-negative matrix factorization in applications to blind source
separation. In IEEE International Conference on Acoustics, Speech
and Signal Processing, volume 5, pages V–621–V–624, 2006.
[4] Patrik O. Hoyer. Non-negative matrix factorization with sparseness
constraints. J. of Machine Learning Research, 5:1457–1469, 2004.
[5] S. Kliger, S. Yemini, Y. Yemini, D. Ohsie, and S. Stolfo. A coding
approach to event correlation. In Proc. 4th International Symposium
on Integrated Network Management (IFIP/IEEE), Santa Barbara,
CA, USA, pages 266–277, 1997.
[6] F. LoPresti, N. G. Dufﬁeld, J. Horowitz, and D. Towsley.
Multicast-based inference of network-internal delay distributions.
IEEE/ACM Transactions on Networking, 10:761–775, 2002.
[7] A. Medina, N. Taft, S. Battacharya, C. Diot, and K. Salamatian.
Trafﬁc matrix estimation: Existing techniques and new directions. In
ACM SIGCOMM-02, 2002.
[8] M. Rabbat, M. Figueiredo, and R. Nowak. Inferring network
structure from co-occurrences. In Neural Information Processing
Systems (NIPS’06), 2006.
[9] I. Rish, M. Brodie, S. Ma, N. Odintsova, A. Beygelzimer,
G. Grabarnik, and K. Hernandez. Adaptive diagnosis in distributed
systems. IEEE Transactions on Neural Networks (special issue on
Adaptive Learning Systems in Communication Networks),
16(5):1088–1109, 2005.
[10] H. Song, L. Qiu, and Y. Zhang. NetQuest: A Flexible Framework for
Large-Scale Network Measurement. In ACM SIGMETRICS, 2006.
[11] H. Tian and H. Shen. Multicast-based inference for topology and
network-internal loss performance from end-to-end measurements.
Computer Communications, 11(29):1936–1947, 2006.
[12] Y. Tsang, M.J. Coates, and R. Nowak. Network delay tomography.
IEEE Trans. Signal Process., 51:2125–2136, 2003.
[13] Y. Vardi. Network tomography: Estimating source-destination trafﬁc
intensities from link data. J. Amer. Statist. Assoc., 91:365–377, 1996.
[14] J. Winick and S. Jamin. Inet-3.0: Internet topology generator.
Technical Report CSE-TR-456-02, University of Michigan, 2002.
[15] Y. Zhang, M. Roughan, N. Dufﬁeld, and A. Greenberg. Fast accurate
computation of large-scale ip trafﬁc matrices from link loads. In
ACM SIGMETRICS-03, 2003.
[16] Y. Zhang, M. Roughan, C. Lund, and D. Donoho. An
information-theoretic approach to trafﬁc matrix estimation. In ACM
SIGCOMM-03, 2003.
(a)
(b)
(a)
(b)
(c)
(d)
Figure 2: Results in the real lab environment.
(c)
(d)
Figure 3: Results for simulated trafﬁc on the lab network from Figure 2a.
(e)
(f)
(e)
(f)
1010010000110101100011014216431631212491 21 31 62 43 44 9Links	
Probes00.20.40.60.8100.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays(0.5 sparsity on A, 50 runs per point)                Sparsity on XCorrelation  12131624344900.20.40.60.8100.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays(0.5 sparsity on X, 50 runs per point)                Sparsity on ACorrelation  12131624344990500100015002000250030003500400045000.511.522.53x 104  probe 312probe 1249Stressing link (1,6) has no effect here as expected0500100015002000250030003500400045000.511.522.53x 104  probe 4216probe 4316Stress test 2:  Links (1,2) and (1,3) are pinged with 30K 1400-byte ECHO_REQUEST packets eachLinks (1,2) and (1,3) are stressed by pinging with 30K 1400-byte ECHO_REQUEST packets eachLink (1,6) is stressed by pinging it with 30K 1400-byte ECHO_REQUEST packetsNormal behavior (~30 minutes)	
		
Normal behavior (~30 minutes)00.20.40.60.8100.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy(0.5 sparsity on A, 50 runs per point)   Sparsity on XAccuracy  12131624344900.20.40.60.8100.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy(0.5 sparsity on X, 50 runs per point)   Sparsity on AAccuracy  12131624344900.10.20.30.40.50.600.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays (sparsity on both A and X is 0.5)NoiseCorrelation  Bottlenecks 1Bottlenecks 2Bottlenecks 3Bottlenecks 400.20.40.60.8100.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays (sparsity on A is 0.5, noise is 0.01)Sparsity on XCorrelation  Bottlenecks 1Bottlenecks 2Bottlenecks 3Bottlenecks 400.20.40.60.8100.10.20.30.40.50.60.70.80.91Correlation between reconstructed and true node delays (sparsity on X is 0.5, noise is 0.01)Sparsity on ACorrelation  Bottlenecks 1Bottlenecks 2Bottlenecks 3Bottlenecks 400.10.20.30.40.50.600.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy (sparsity on both A and X is 0.5)NoiseAccuracy  Bottlenecks 1Bottlenecks 2Bottlenecks 3Bottlenecks 400.20.40.60.8100.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy (sparsity on A is 0.5, noise is 0.01)Sparsity on XAccuracy  Bottlenecks 1Bottlenecks 2Bottlenecks 3Bottlenecks 400.20.40.60.8100.10.20.30.40.50.60.70.80.91Dependency matrix reconstruction accuracy (sparsity on X is 0.5, noise is 0.01)Sparsity on AAccuracy  Bottlenecks 1Bottlenecks 2Bottlenecks 3Bottlenecks 4