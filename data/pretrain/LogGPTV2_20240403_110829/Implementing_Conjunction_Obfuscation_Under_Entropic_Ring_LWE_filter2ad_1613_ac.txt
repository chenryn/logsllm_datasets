and improved and implemented in [62] has a high computa-
tional complexity for an arbitrary modulus (the SampleG oper-
primitive operations as compared
ation requires O
to O (n log q) for a power-of-two modulus). Moreover, both
variants of the algorithm have high storage requirements for a
Cholesky decomposition matrix (computed for each trapdoor
pair and used in perturbation sampling) composed of a large
number of multiprecision ﬂoating-point numbers. The above
implies that this prior Gaussian sampling approach is not prac-
tical for our implementation of the conjunction obfuscation
construction dealing with non-power-of-two moduli and m
calls to SampleG for each encoding matrix.
We implement a much more efﬁcient approach based on the
trapdoor sampling algorithms recently proposed in [61]. The
SampleG algorithm developed in [61] has O (n log q) com-
plexity for arbitrary moduli (same as for power-of-two moduli
in [44], [62]). The perturbation sampling method proposed in
[61] works with a Cholesky decomposition matrix implicitly
and does not require additional storage. Our trapdoor sampling
implementation is described in the rest of this section.
B. Trapdoor Construction and G-Lattice Representation
The concrete value of dimension m is determined by the
ring trapdoor construction chosen for the implementation. It
is common to write m = ¯m + k, where ¯m is a security
dimension and k denotes the dimension of (binary) gadget
matrix. Two ring constructions were suggested in [44] and
further developed in [62]. The ﬁrst one, where ¯m = 2 and,
therefore, m = 2 + k, is generated by drawing k samples
(a, aˆri + ˆei), where i ∈ [k], from Ring-LWE distribution. The
second construction uses ¯m uniformly random polynomials,
where ¯m is usually set to at least k. As the second construction
requires that m be at least 2k, the Ring-LWE construction
deals with a smaller dimension and is thus preferred for our
implementation.
Note that a different type of ring trapdoor construction was
proposed in [63] based on a non-standard NTRU assumption.
This construction cannot be applied to the conjunction obfus-
cator because the generated samples have a large distribution
, which prevents one from using the
parameter, i.e., Θ
samples for multiplying the encodings without invalidating the
correctness.
(cid:5)√
(cid:6)
q
As another major optimization of this work, we introduce
a generalized version of the Ring-LWE construction in [62],
[44]. In our implementation m = 2+κ, where κ = (cid:8)k/ log2 t(cid:9)
and t is the base for the gadget lattice Gn (t was set to 2 in
[62]). The use of base t higher than 2 reduces the dimension
of encoding matrices, which dramatically improves all main
performance metrics of the conjunction obfuscator, as shown
in Section V. The algorithmic idea of using an arbitrary base
t was originally suggested in [44] but has not been explored
in implementations based on polynomial rings.
The pseudocode for the Ring-LWE trapdoor construction
is depicted in Algorithm 1. In the pseudocode, ˆr and ˆe
are the row vectors of secret trapdoor polynomials generated
using discrete Gaussian distribution, A is the public key, and
gT = {g1, g2, . . . , gκ} is the gadget row vector corresponding
to the gadget lattice Gn. The latter is often denoted as simply
G because it is an orthogonal sum of n copies of a low-
dimensional lattice G.
Algorithm 1 Trapdoor generation using Ring-LWE for G
lattice of base t
function TRAPGEN(1λ)
a ← Uq ∈ Rq
ˆr := [ˆr1, . . . , ˆrκ] ← DR,σ ∈ R1×κ
ˆe := [ˆe1, . . . , ˆeκ] ← DR,σ ∈ R1×κ
A := [a, 1, g1 − (aˆr1 + ˆe1), . . . , gκ − (aˆrκ + ˆeκ)] ∈
q
q
R1×(2+κ)
q
return (A, (ˆr, ˆe))
end function
Although the trapdoor T in the general deﬁnition in Section
III-B has dimensions m × κ, for this construction we can
perform all computations with a compact
T =
(ˆr, ˆe) ∈ Rq
2×κ, as explained in Section IV-E.
C. High-Level Trapdoor Sampling Algorithm
trapdoor (cid:7)
The high-level preimage sampling algorithm adapted for our
lattice trapdoor construction is listed in Algorithm 2. It is based
on the general approach proposed in [44]. Note that we use
the distribution parameter σt, which depends on the base t of
G-lattice. The vector p is the perturbation vector required to
produce spherical samples.
Sections IV-D and IV-E describe in more detail the proce-
dures SampleG and SamplePZ, respectively.
D. Sampling G-lattices
The G-lattice sampling problem is deﬁned as the problem
of sampling the discrete Gaussian distribution on a lattice
359
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:30 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 2 Gaussian preimage sampling
(cid:7)
(cid:12)
function GAUSSSAMP(A,
for i = 0..m − 1 do
T, b, σt, s)
(cid:13)
(cid:7)
p ← SamplePZ
n, q, s, σt,
T
z ← SampleG(σt, bi − Ap, q)
Convert z ∈ Zκ×n to ˆz ∈ Rκ
xi := [p1 + ˆeˆz, p2 + ˆrˆz, p3 + ˆz1, . . . , pm + ˆzκ]
∈ Rm
q
q
(cid:6)
m×m
end function
end for
return x ∈ Rq
(cid:17)
(cid:5)
, where q ≤
⊥
coset Λ
tκ, v ∈ Z and g =
v
. The G-sampling
problem is formulated here for a single integer v rather than
a n-dimensional lattice because each of the n integers can be
sampled in parallel. Our implementation of G-sampling works
with a n-dimensional lattice.
(cid:5)
(cid:6)
z ∈ Zκ : gT z = v mod q
1, t, t2, . . . , tκ−1
(cid:18)
gT
=
(cid:5)
(cid:6)
We implement a variation of the G-sampling algorithm
developed in [61], which supports arbitrary bases for G-
lattice. Our variation (depicted in Algorithm 3 of Appendix
A) relies on continuous Gaussian sampling in the internal
perturbation sampling step (in contrast to discrete Gaussian
sampling in Figure 2 of [61]), reduces the number of calls to
polynomial CRT operations, and increases opportunities for
parallel execution.
gT
Algorithm 3 has complexity O (n log q) for an arbitrary
modulus. The main idea of the algorithm is not to sample
⊥
directly, but to express the lattice basis Bq = TD
Λ
v
as the image (using a transformation T) of a matrix D
with a sparse, triangular structure. This technique requires
adding a perturbation with a complementary covariance to
obtain a spherical Gaussian distribution, as in the case of the
GaussSamp procedure described in Algorithm 2. In this prior
work the authors select an appropriate instantiation of D that
is sparse and triangular, and has a complementary covariance
matrix with simple Cholesky decomposition Σ2 = L · L
T ,
where L is an upper triangular matrix, and ﬁnd the entries of
the L matrix in closed form.
E. Perturbation sampling
t
T I
(cid:19)
(cid:19)
TT , I
(cid:20)T .
(cid:20)T·(cid:19)
(cid:20)
The lattice preimage sampling algorithm developed in [44]
requires the generation of nm-dimensional Gaussian perturba-
tion vectors p with covariance Σp := s2·I−σ2
TT I
,
where T ∈ Z2n×nκ is a matrix with small entries serving as
a lattice trapdoor, s is the upper bound on the spectral norm
of σt
be compactly represented by a matrix (cid:7)
(Algorithm 1), the trapdoor (cid:7)
When working with algebraic lattices, the trapdoor T can
, where n
denotes the rank (dimension) of the ring Rn. In our case, this
corresponds to the cyclotomic ring of order ˆm = 2n. For the
Ring-LWE trapdoor construction used in our implementation
T is computed as (ˆr, ˆe). The
main challenge with the perturbation sampling techniques
developed in [62], [44] is the direct computation of a Cholesky
T ∈ R2×κ
n
decomposition of Σp that destroys the ring structure of the
compact trapdoor and operates on matrices over R.
Genise and Micciancio [61] propose an algorithm that lever-
ages the ring structure of Rn and performs all computations
either in cyclotomic rings or ﬁelds over Φ2n(x) = xn + 1.
The algorithm does not require any preprocessing/storage
and runs with time and space complexity quasi-linear in n.
The perturbation sampling algorithm can be summarized in a
modular way as a combination of three steps [61]:
1) The problem of sampling a n(2 + κ)-dimensional Gaus-
sian perturbation vector with covariance Σp is reduced to
the problem of sampling a 2n-dimensional integer vector
with covariance expressed by a 2 × 2 matrix over Rn.
2) The problem of sampling with covariance in R2×2
is
reduced to sampling two n-dimensional vectors with
covariance in Rn.
3) The sampling problem with covariance in Rn is reduced
to sampling n-dimensional perturbation with covariance
expressed by a 2 × 2 matrix over the smaller ring Rn/2
using an FFT-like approach.
n
We implement a variation of the perturbation generation
algorithm developed in [61]. Our variation (depicted in Algo-
rithm 4 of Appendix A) reduces the number of calls to CRT
operations and increases opportunities for parallel execution.
F. Integer Gaussian Sampling
Our implementations of G-sampling and perturbation sam-
pling procedures require generating integers with Gaussian
distribution for
large distribution parameters and varying
centers. For instance, the optimal values of base t lead to
distribution parameters up to 220 for G-sampling and even
larger values for perturbation generation. This implies that
conventional Gaussian sampling techniques such as the in-
version sampling developed in [64] and rejection sampling
proposed in section 4.1 of [65] are not practical for trapdoor
sampling, as described in detail in [46].
To this end, we implement two recently proposed generic
samplers: Karney’s rejection sampler [45] and constant-time
sampler [46].
The rejection sampler [45] provides a relatively low rejec-
tion rate (roughly 0.5) vs. a much higher rate in the case
of rejection sampling [65], and has no additional storage
requirements, at least when it is not separated into ofﬂine and
online stages. However, it has a relatively signiﬁcant variability
in sampling time making it prone to timing attacks.
The generic sampler [46], on the other hand, uses a constant-
time algorithm that breaks down sampling for large distribu-
tion parameters into multiple runs for much smaller distri-
bution parameters. It also utilizes multiple cosets to support
varying-center requirements, with the number of cosets being
an adjustable parameter. At
this generic
sampler depends on the implementation of a base sampler for a
small distribution parameter and ﬁxed center, which can be re-
alized using efﬁcient Cumulative Distribution Function (CDF)
inversion [64] or Knuth-Yao [66] methods. This algorithm has
signiﬁcant memory requirements to store precomputed lookup
the lowest
level,
360
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:37:30 UTC from IEEE Xplore.  Restrictions apply. 
tables/trees for the base sampler but the storage requirements
can be adjusted at the expense of increased sampling runtime.
The choice of a speciﬁc generic sampler in our experiments
is determined by minimizing the obfuscation runtime.
V. SETTING THE PARAMETERS
A. Distribution Parameters
the smoothing parameter σ estimated as σ ≈(cid:21)
1) Distribution Parameter for Ring-LWE Trapdoor Con-
struction: The trapdoor secret polynomials are generated using
ln(2nm/)/π,
where nm is the maximum ring dimension and  is the
bound on the statistical error introduced by each randomized-
rounding operation [44]. For nm ≤ 214 and  ≤ 2
−80, we
choose a value of σ ≈ 4.578.
2) Short Ring Elements in Directed Encoding: For short
ring elements si,b, ri,b, we use ternary uniformly random ring
elements, which are sampled over {−1, 0, 1}n. This implies
that we rely on small-secret Ring-LWE for directed encoding.
3) Distribution Parameters for Directed Encoding: To en-
code ternary random elements, we use the smoothing param-
eter σ (for the noise polynomials) deﬁned in Section V-A1.
To encode a product of ternary random ring elements
√
under the Ring-LWE assumption, we need to sample noise
polynomials using σ
nσ (Section 4.3 of [1]).
The term ω (log λ) guarantees that DR,
nσ+σ(cid:3) is “smudged”
by Lemma 2.4 of [1] to DR,σ(cid:3). In our implementation, we use
a concrete estimate σ
√
nσ.
= ω (log λ)
= k
√
4) Distribution Parameter
for G-Sampling: Our G-
sampling procedure requires that σt = (t + 1)σ. This guar-
antees that all integer sampling operations inside G-sampling
use at least the smoothing parameter σ, which is sufﬁcient
to approximate the continuous Gaussian distribution with a
negligible error.
5) Spectral norm s: Parameter s is the spectral norm
used in computing the Cholesky decomposition matrix (it
guarantees that the perturbation covariance matrix is well-
deﬁned). To bound s, we use inequality s > s1 (X) σt, where
X is a sub-Gaussian random matrix with parameter σ [44].
≤
that
is a constant and
[44]
states
, where C0
√
2.9
2n + C1
(cid:5)√
Lemma
(cid:6)
of
(cid:8)
(cid:8)
(cid:5)√
s1 (X)
√
2n + 4.7
(cid:6)
nκ +
C0σ
C1 is at most 4.7.
We can now rewrite s as s > C0σσt
.
In our experiments we used C0 = 1.3, which was found
empirically.
nκ +
The correctness constraint for a conjunction pattern with L
B. Conjunction Obfuscator Correctness
words (L ≥ 2) is expressed as
q > 192σ