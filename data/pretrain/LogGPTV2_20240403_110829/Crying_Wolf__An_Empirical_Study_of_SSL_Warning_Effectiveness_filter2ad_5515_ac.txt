µ = 0.99 Experts
σ = 1.42 Non-Experts
µ = 0.47 Experts
σ = 1.02 Non-Experts
69% 44%
63% 48%
52% 13%
47% 41%
42% 33%
36% 31%
χ2
2 = 12.37
p < 0.002
31%
31%
10%
31%
29%
29%
χ2
2 = 11.42
p < 0.003
Table 4: Percentage of experts and non-experts who said they would continue past the warnings. The ﬁrst
column shows respondents’ average tech scores.
the alternative information source. Finally, we gave
users an exit survey to gauge their understanding of
and reaction to the warnings.
responses were not used to screen participants (e.g.
“How often do you use Amazon.com?”), to further
obfuscate the study purpose.
4.1.1 Recruitment
4.1.2 Conditions
We recruited participants by posting our study on the
experiment list of the Center for Behavioral Research
at CMU. We also hung posters around the CMU cam-
pus. Participants were paid $10–20 for their partic-
ipation.7 All recruits were given an online screen-
ing survey, and only online banking customers of our
chosen bank were allowed to participate. The sur-
vey included a range of demographic questions and
questions about general Internet use.
In total, 261 users completed our screening survey
and 100 users qualiﬁed and showed up to participate
in our study. We randomly assigned 20 users to each
condition. Half the users in each condition were given
the bank task ﬁrst and half were given the library task
ﬁrst. Participants took 15–35 minutes to complete
the study including the exit survey.
We tried to ensure that participants were not
primed to think about security. The study was pre-
sented not as a security study, but as a “usability of
information sources study.” Our recruitment post-
ings solicited people who were “CMU faculty staﬀ
or students” and had “used online banking in the
last year.” However, we also required that partic-
ipants have “purchased an item online in the last
year” and “used a search engine” to avoid focusing
potential participants on the banking tasks. Finally,
our screening survey asked a series of questions whose
7Initially participants were paid $10, but we raised the pay-
ment to $20 to reach our recruiting goals.
The FF2 warning, displayed in Figure 2(a), is typi-
cal of invalid certiﬁcate warnings prior to 2006. This
warning has a number of design ﬂaws. The text con-
tains jargon such as, “the website’s certiﬁcate is in-
complete due to a server misconﬁguration.” The look
and feel of the warning, a grey dialog box with a set
of radio buttons, is similar to a lot of other trivial
dialogs that users typically ignore, such as “you are
sending information unencrypted over the internet.”
The default selection is to accept the certiﬁcate tem-
porarily. This is an unsafe default for many websites,
including the online banking application in our study.
A more subtle problem with the FF2 warning, and
those like it, is that it asks users a question that they
cannot answer. The warning asks the user to de-
termine if the certiﬁcate problem is the result of a
server/browser conﬁguration problem or a legitimate
security concern. Since users are not capable of mak-
ing this determination, the dialog is, in the words of
Firefox project co-founder Blake Ross, “a dilemma
to users.” Ross calls on browser designers to do ev-
erything possible to make decisions for their users.
When designers have to ask questions of their users,
they should ask questions that users can answer [16].
The FF3 warning should be more noticeable to
users than its predecessor because it takes over the
entire page and forces users to make a decision. Ad-
ditionally, it takes four steps to navigate past the
warning to the page with the invalid certiﬁcate. First
(a) Firefox 2
(b) Internet Explorer 7
Figure 2: Screenshots of the FF2 and IE7 warnings.
the user has to click a link, mysteriously labeled “or
you can add an exception. . . ” (Figure 3), then click a
button that opens a dialog requiring two more button
clicks. The ﬁrst version of the FF3 warning required
11 steps.8 This clearly represented a decision by Fire-
fox developers that all invalid certiﬁcates are unsafe.
They made the original version of the warning so dif-
ﬁcult for users to override, that only an expert would
be likely to ﬁgure out how to do it. While FF3 was in
alpha and beta testing, many users erroneously be-
lieved the browser was in error when they could not
visit websites that they believed to be legitimate.9
The IE7 warning, shown in Figure 2(b), occupies
the middle ground between the FF2 and FF3 warn-
ings. It takes over the entire page and has no default
option, but diﬀers from the FF3 warning because it
Figure 3: Screenshot of the initial FF3 warning.
can be overridden with a single click on a link labeled
“Continue to this website.” It has a slightly scarier
look and feel than the FF2 warning: the background
color has a red tint and a large X in a red shield
dominates the page. The warning also explicitly rec-
ommends against continuing. Finally, when viewing
this warning the background of the address bar is
red and continues to be red after one overrides the
warning.
We designed two warnings using techniques from
the warning literature and guided by results from
our survey. Our multi-page warning ﬁrst asks the
user a question, displayed in Figure 4(a), and then,
depending on the response, delivers the user either
to the severe warning page shown in Figure 4(b) or
to the requested website. The second version of the
warning shows only the severe warning (Figure 4(b)).
Both versions were implemented in IE7. We used the
resourcemodify tool10 to replace the HTML ﬁle of the
native warning in an IE DLL with our HTML ﬁles.
The second version of our warning serves two pur-
poses. First, it attempts to see how users react to a
simple, clear, but scary warning. The warning bor-
rows its look and feel from the FF3 phishing warn-
ing. It is red and contains the most severe version of
Larry the Firefox “passport oﬃcer.”11 The title of
the page is clear and harsh: “High Risk of Security
Compromise.” The other context is similarly blunt
(e.g. “an attacker is attempting to steal information
that you are sending to domain name.”). Even the
8https://bugzilla.mozilla.org/show bug.cgi?id=399275
9https://bugzilla.mozilla.org/show bug.cgi?id=398915
10http://deletethis.net/dave/xml-source-view/httperror.
html
11http://news.cnet.com/8301-10789 3-9970606-57.html
and “I don’t know.” If users selected the ﬁrst two op-
tions, they saw the severe warning that discouraged
them from continuing. We tested this question as
a prototype for leveraging user-provided information
to improve security warnings.
It is not a complete
solution as our question neglects many other types of
websites that may collect sensitive information. We
decided to show the secondary warning on bank web-
sites and online stores because these are the most
frequently attacked websites [15].
4.1.3 Experimental Setup
All studies were conducted in our laboratory on the
same model of laptop. Participants interacted with
the laptop within a virtual machine (VM). We reset
the VM to a snapshot after each participant ﬁnished
the study to destroy any sensitive data entered by
the participant (e.g. bank password). This process
also ensured that all browser and operating system
settings were exactly the same for every participant.
Finally, experimenters read instructions to partici-
pants from a script and experimenters did not help
particiants complete the tasks.
4.1.4 Tasks
After participants signed IRB consent forms, the ex-
perimenter handed them an instruction sheet and
read this sheet aloud. Participants were reminded
that they would be “visiting real websites and call-
ing real organizations” and therefore should go about
“each task in the way you would if you were complet-
ing it with the computer you usually use.” Partici-
pants were also instructed to “think aloud and tell
us what you are thinking and doing as you complete
each task,” in order to give us qualitative reactions to
the warnings. The experimenter took notes through-
out the study. The study was recorded (audio only),
which allowed experimenters to retrieve details that
were missed during note taking.
After the instructions were read and digested, the
instruction sheets for each task were handed to the
participant and read aloud by the experimenter one
by one. The next task was not revealed until all pre-
vious tasks had been completed. The ﬁrst task asked
(a) Page 1
(b) Page 2
Figure 4: Screenshot of redesigned warning.
default button, labeled “Get me out of here!” signi-
ﬁes danger. The only way for a user to continue is
to click the tiny link labeled “Ignore this warning” in
the bottom right corner. The second purpose of the
single page warning is to help us interpret the results
from our multi-page warning. We compare the multi-
page results to the single-page results to see how the
question aﬀects user actions independent of the the
scary second page.
The original FF3 warning aimed to avoid asking
users questions, and instead decided on users’ behalf
that invalid certiﬁcates are unsafe. However, even
the Firefox designers eventually realized this could
not work in the real world because too many legit-
imate websites use invalid certiﬁcates. Instead, our
warning aims to ask the users a question that they
can answer and will allow us to assess the risk level.
Our question is, “What type of website are you trying
to reach?” Users were required to select from one of
four responses: “bank or other ﬁnancial institution,”
“online store or other e-commerce website,” “other,”
participants to ﬁnd the total area of Italy in square
kilometers using Google or Ask.com as an alternative.
The second task was to look up the last two digits of
the participant’s bank account balance using the on-
line banking application or using phone banking. The
third task was to locate the price of the hardcover
edition of the book Freakonomics using Amazon.com
or the Barnes and Noble website. Finally, the fourth
task was to use the CMU online library catalog or al-
ternatively the library phone number to retrieve the
call number of the book Richistan (i.e. no personal
information was transmitted).
The ﬁrst and third tasks were “dummy tasks,”
since the bookstore and search engine revealed no
warnings.
Instead, they reinforced to participants
that the goal of the study was information sources,
not security. Half the participants in each condi-
tion had the second and fourth tasks—the warning
tasks—swapped so that we could control for the or-
dering of the warnings.
Researchers have found that study participants are
highly motivated to complete assigned tasks. Partic-
ipants want to please the experimenter and do not
want to “fail” so they sometimes exert extreme eﬀort
to complete the task [12]. A closely related study [17]
was criticized for not taking into account this “task
focus” phenomenon [14]. Critics worried that partici-
pants were ignoring the warnings in the study because
of task focus and not because this is what they would
do in a more natural environment.
Our study design mitigates participants’ task fo-
cus by presenting an alternate method for each task
so that participants could “pass the test” without ig-
noring the warnings. We instructed participants to
“try the suggested information source ﬁrst,” to en-
sure that participants would only call the library or
bank as a reaction to the warning. As there were
no obstacles to completing the dummy tasks using
the suggested information source, none of the par-
ticipants used the alternate method to perform the
dummy tasks.
4.1.5 Exit Survey
After completing all four study tasks, participants
were directed to an online exit survey hosted by Sur-
veyMonkey. The exit survey asked 45 questions in
six categories. The ﬁrst set of questions asked about
their understanding of and reaction to the bank warn-
ing in the study. The second question asked the same
questions about the library warning. The third set
asked questions to gauge their general understand-
ing of certiﬁcates and invalid certiﬁcate warnings.
The fourth set gauged participants’ prior exposure
to identity theft and other cyberthreats. The ﬁfth
set, which were also asked in the online SSL survey,
asked them about their technical experience, includ-
ing their experience with computer security. Finally,
the sixth set asked general demographic questions like
age, gender and education level.
4.2 Results and Analysis
The primary goal of any SSL warning should be to
prevent users from transmitting sensitive informa-
tion to suspicious websites. A secondary—but still
important—goal is to allow users to continue in the
event of a false positive (i.e. when a certiﬁcate error
is unlikely to result in a security compromise). In our
study we examined these goals by observing whether
participants discontinued visiting the bank website
while continuing to the library website. These re-
sults from our laboratory experiment are displayed
in Table 5. Participants who saw our single-page
or multi-page warnings were more likely to heed the
warnings than participants who saw the FF2 or IE7
warnings, but not the FF3 warning. In contrast, par-
ticipants who saw our multi-page warning were more
likely to visit the library website than participants
who saw the FF3 warning.
In the rest of this sec-
tion we discuss demographics, present more detailed
comparisons of the conditions and tasks, and present
interesting qualitative results from our exit survey.
4.2.1 Participant Characteristics
We did not ﬁnd any statistically signiﬁcant demo-
graphic imbalances between participants in our ran-
domly assigned conditions. The factors we tested
were gender, nationality, age, technical sophistica-
tion, and a metric we call “cyberthreat exposure”
designed to measure participants’ prior experiences
Bank
Library
18
19
FF2
(90%)
(95%)
FF3
(55%)
(60%)
11
12
IE7
(90%)
(100%)
18
20
Single-Page
(45%)
(80%)
9
16
Multi-Page
(60%)
(95%)
12
19
Table 5: Number (and percentage) of participants in each condition who ignored the warning and used the
website to complete the library and bank tasks.
with information theft and fraud. Most demographic