encoding). If the adversary knows the technique used to build the fin-
gerprints (e.g., dual Hamming or Tardos codes), a collusion of mali-
cious buyers can retrieve the mutant bits of their secret fingerprints.
Session 6: Privacy 1ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea213Algorithm DBBuy(bi ,V,W, Pos, Rec)
Data: The sanitized view and fingerprint parameters
Result: The personalized view of the database
// Select a codeword in W not in Rec
ωi ← W
Vi ← V
// The watermarking process
for j = 1 to l do
else
// Let tj be the jth tuple in Pos
if ωi[j] = 1 then
Vi ← Vi ∪ {tj}
Vi ← Vi \ {tj}
return Rec ∪ {(bi , ωi )}
return the view Vi to the buyer bi
Algorithm 2: This buying algorithm personalizes the
sanitized view of the database by inserting a codeword
identifying uniquely a buyer.
one malicious buyer responsible for this leak with a high probability.
This buyer may not be solely responsible of this infringement as he
can be a member of a collusion. Unfortunately, the other members
may not be traceable (e.g., the counterfeit copy may depend almost
solely on the copy of one member of the collusion). This algorithm
begins by determining whether or not the marking tuples in Pos
are in V∗. The final step is the accusation process IdentifyCulprit.
Algorithm DBAccuse (V∗,W, Pos, Rec)
Data: The counterfeit view and fingerprinting parameters
Result: The identity of a potential culprit
// Extract the codeword
ω∗[j] ← 0, for all j
for j = 1 to l do
// Let tj be the jth tuple in Pos
if tj ∈ V∗ then
ω∗[j] ← 1
// Accusation process
ScoresList = {}
for (bi , ωi ) ∈ Rec do
Si ← ComputeScore(ω∗, ωi )
ScoresList ← ScoresList ∪ {(bi , Si )}
return IdentifyCulprit(W, ScoresList ).
Algorithm 3: This accusation algorithm is used to iden-
tify the potential malicious buyers responsible for the
release of a counterfeit view of the proprietary database.
Figure 1: Comparison of the query estimators on the sani-
tized view and the true query values on the discretized data-
base for counting queries on two or three attributes. The
mean square error and the mean absolute percentage error of
the estimators are approximatively 104 and 16%, respectively.
This may enable them to infer information on their invariants bits
and help them to forge a fingerprint combining the invariant bits
and their selected mutant bits (e.g., these latter bits can all be set
to 0-bit) [5, 21]. To avoid this type of attacks, the fingerprinting
codewords can be encrypted with a secret one-time pad random
mask. This prevents the colluders from (1) determining whether a
mutant bit is in fact a 0-bit or a 1-bit of the underlying code for a
given colluder, and (2) inferring some of their invariant bits. Such a
protection is important for deterministic fingerprinting codes such
as the dual Hamming codes but less critical for randomized ones
like Tardos codes. Hereafter, we assume that the fingerprints have
been randomized to avoid this type of attacks.
DBBuy. The DBBuy is used by the merchant to personalize the
sanitized database for a buyer. Only one sanitized view is produced
by the DBSetup algorithm for all the potential n buyers as described
in the DBSetup algorithm. The personalization process consists in
inserting a unique codeword from W by using the secret marking
tuples in Pos. The presence or the absence of these tuples are used
to encode a 1-bit or a 0-bit of the codeword, respectively. Once the
view has been constructed for the buyer bi, the transaction is added
to the history of recorded transactions Rec.
Remark 4 (watermarking technique). The novel watermarking
technique that we propose is one of the main contribution of this
paper and is totally in line with the sanitization step. As we will see
in the next section, the personalization process simply adds a very
limited number of false tuples comparatively to the sanitization
process. Thus, it does not significantly impact the utility of the
resulting view. Furthermore, it is totally indistinguishable from the
sanitization process as it relies on the same approach, which inserts
false tuples.
DBAccuse. If a potential leak of a legitimate (or counterfeit)
view of the database has been observed, the merchant extracts the
associated fingerprint from the view. As mentioned previously in
such a situation, the objective of the merchant is to identify at least
Session 6: Privacy 1ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea214Remark that the accusation step is the only one specific to the
fingerprinting scheme used. For instance, for dual Hamming codes
the accusation process is relatively simple as it directly relates to
the decoding process of the dual Hamming codes [7]. First, the
Hamming distances dH between ω∗ and all codewords in Rec are
computed. Then, the accused buyer is the buyer bι who has the
minimum Hamming distance such that:
ι = arg min{dH (ωi , ω∗)|ωi ∈ W}.
The accusation process of the Tardos codes is more complex. For
the full details of this process, we refer to the paper of Tardos [27] for
the asymmetric accusation process, which relies only on the 1-bit
of the counterfeit fingerprint. Note that the Tardos construction is
fundamentally symmetric. An equivalent accusation process could
have been designed only on the 0-bit of the fingerprints. Such an
approach would be very useful in the next section. A more efficient
accusation process has been proposed by Škorić, Katzenbeisser
and Celik [23]. This version is symmetric and uses all the bits of
the counterfeit fingerprint. It can use shorter codes for the given
parameters c and ϵ. It is interesting to point out that this approach
relies on the original probabilistic code construction.
In a nutshell, the accusation process computes a score for each
buyer and the buyer having the highest score is accused:
ι = arg max{Scores (ωi , ω∗)|(bi , ωi ) ∈ Rec}.
In this latter case, a minimum threshold has to be defined as oth-
erwise an innocent buyer may be falsely accused of having re-
distributed the illegitimate copy. On the other hand, a maximum
threshold with respect to the non-colluding buyers may be defined
to accuse multiple malicious buyers.
Remark 5 (parameters of the fingerprinting schemes). For dual
Hamming codes with parameter k ≥ 3, the codebook Wk can
contain 2k − 1 fingerprints of length 2k. As mentioned earlier, this
scheme can support any collusion of at most three buyers [7]. This
simple case is very efficient when the number of buyers is small as
up to 127 buyers can be supported with 128-bit fingerprints.
For Tardos codes, in order to determine the length of codes, the
merchant needs to define the bounds on the size of the maximum
collusion that can be tolerated, and on the maximum error probabil-
ity ϵ to falsely accuse an innocent buyer. The original constructions
propose codes with length at most 100c2 ln 1
ϵ bits [27], while the
improved symmetric solutions propose codes with length at most
2π 2c2 ln( 1
ϵ ) [23]. This latter bound can be further improved if some
assumptions on the distributions of the accusations are made. In
practice, this bound is independent of the number of buyers.
c
Tardos
Škorić et al.
3
12,434
2,454
5
34,538
6,818
10
138,155
27,271
15
311,000
61,400
Table 1: Table comparing the lengths of the codes for the
original construction and the improved one. The error prob-
ability bound has been set to ϵ = 10−6.
5 SECURITY PROPERTIES
In this section, we show that our solution fulfills all the require-
ments defined in Section 3. In particular, two important issues must
be considered. The first one is to ensure the privacy of the released
views of the database as well as their utility. It is important to show
that the personalization process does not have any major impact
of these aspects. Intuitively, adding false tuples into the sanitized
views may significantly threaten their utility.
The second aspect is to ensure the traceability of a malicious
buyer (alone or as a member of a small collusion) who has illegally
released a counterfeit view of a database. Obviously, a malicious
buyer may easily redistribute an untraceable view of the database,
simply by adding and deleting enough tuples from the view. How-
ever, one can expect that the resulting view would not be useful
to anyone who wants to obtain meaningful information from that
database. Thus, such a trivial case would be henceforth discarded.
5.1 Privacy and utility analysis
Let us assume that the tuple-independent adversary has an a pri-
ori knowledge on the tuples of the database bounded by d and a
posteriori knowledge bounded by γ.
Consider a view V of the proprietary database DB built by
the proper (α, β )-sanitization algorithm in DBSetup, in which the
parameters α and β abide to the inequalities given by Equations 1
and 2. This view is therefore (d, γ )-private by construction [18].
The fundamental issue is now to determine whether or not the
personalization process alters the privacy and the utility of the view.
For the privacy property, consider the unrealistic scenario in which
all the n buyers collude and share their views V = {V1,· · · ,Vn}.
In such a case, the buyers would be able to remove easily all traces
of the personalization. Obviously, this is the worst case scenario
against privacy and would not be allowed in the next section for
the traitor-tracing analysis of the solution.
Theorem 1 (SaPData’s Privacy ). Let V be the set of all the
personalized instances {V1,· · · ,Vn} of a sanitized view V of the
database DB produced by SaPData and distributed to the buyers. Any
(d, γ )-tuple-independent adversary should not be able to reconstruct
a large portion of DB from V. Thus, the personalization process
preserves the (d, γ )-privacy property.
Proof. The personalization process in DBBuy would add more
false tuples in the personalized views, thus reinforcing individually
the privacy of views. In the sanitization step, the l false tuples in Pos
would have been selected with probability β – thus, β ·l false tuples.
In the watermarking step, these false tuples would be replaced by
the tuples corresponding to the 1-bit of the codewords. For dual
Hamming codes, this is exactly l
2. In the case of the Tardos codes,
this is l
2 on average (see the Appendix).
The problem comes when an adversary could get all the views
in V. In the worst case, he might identify all the marking tuples in
Pos according to the Marking Assumption. Hence, the adversary
would be able to reconstruct the original view V without β · l of
its original false tuples.
In the (α, β )-sanitization algorithm, the privacy depends on the
fact that α ≤ 1 − d
, for
some large constant f and that the inequality given by Equation 2
γ−dγ α. Assume that l ≤ |D\DB|
γ and β ≥ d−dγ
f
Session 6: Privacy 1ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea215d−dγ
is strengthened to have β ≥ f
γ−dγ α. Thus, an adversary that is
f −1
able to remove β · l false tuples would obtain a cleaner view with
less false tuples on average:
α · |DB| + β (|D \ DB| − l ) > α · |DB| + β
|D \ DB|.
f − 1
f
f −1
f
Let β′ be defined as β
. This parameter is greater than or equal to
d−dγ
γ−dγ α. Thus, the cleaner resulting view should contain on average
α·|DB|+β′|D\DB| tuples, respecting the constraint of Equation 2.
This view is therefore still (d, γ )-private.
□
The next step is to ensure that the personalized views are still
useful for buyers. The objective is to see whether or not the person-
alization process, which adds false tuples to a view, has any major
impact on the utility the view.
Theorem 2 (SaPData’s Utility). Let Vi be a personalized in-
stance of a sanitized view V of the database DB produced by the
algorithm SaPData. If the length of the embedded fingerprint l is such
that l ≤ |D\DB|
, for some large constant f , the personalization
process preserves the (ρ, ϵ )-usefulness property.
f
Proof. As mentioned in the previous proof, the number of false
tuples embedded during the watermarking process is l
2 (on average
for Tardos codes). A legitimate buyer would therefore receive a
personalized view that has more false tuples than the original view
V. In the (α,β)-sanitization algorithm, the utility of the resulting
γ . Since l ≤ |D\DB|
2 and β ≤ d
view depends on the fact that α ≥ 1
,
the inequality given in Equation 2 can be strengthened to have
2f ≥ β. In such a case, the personalized view Vi should have
γ − 1
d
(cid:19)
(cid:18) 1
the following number of tuples in average:
f
(cid:33)
α · |DB| + β · |D \ DB| +
(cid:32)
α · |DB| +
β + 1
2f
l <
− β
2
|D \ DB|
Let β′ be defined as β + 1
2f . In this case, the personalized view should
contain on average α|DB| + β′|D \ DB|, respecting the initial
constraint of Equation 2. Thus, if the value of 1
is small compared
2f
to d
□
γ , the personalized view would be in fact (ρ, ϵ )-useful.