and we then explain the slight diﬀerences for our two-
phase algorithm.
The important observation in analyzing the expected
running time of the message reconstruction algorithm is
that, since the checksum cords are statistically random,
we can view the mapping of messages to checksum in-
dices as a random hash function. Thus, the number of
collisions among legitimate messages should be small.
Of course, the adversary might construct lots of fake
messages and then construct lots of collisions with these
messages, but let us ignore this possibility for the time
being (we will revisit this possibility shortly).
We begin with the reconstruction algorithm for our
single-phase scheme. Let N denote the number of dis-
tinct packets the victim has received and let n denote
the number of routers in the attack tree. Since there
are l pieces to each message and each one has a c-bit
checksum cord that is statistically random, the proba-
bility that two random packets have the same fragment
index i and cord C is 1/(l2c). In addition, the probabil-
ity that two router-sent packets have the same fragment
index i and cord C is at most 1/2c, since any router
wishing to send a message will send a packet with each
i-index for the checksum cord C it is using. Thus, the
expected number of packets with the same fragment in-
dex i and cord C is at most (cid:4)N/(l2c) + n/2c(cid:5). For any
given cord C, then, the running time for computing all
combinatorial combinations of blocks with this cord is
proportional to Z = Z0Z1 ··· Zl−1, where Zi is a ran-
122dom variable corresponding to the number of packets
with fragment index i (for this checksum cord C). Since
these Zi’s refer to diﬀerent fragment indices, they are
independent; hence, the expected value of their product
is equal to the product of their expected values. That is,
the expected running time for checking all the combina-
tions for a given checksum cord C is (cid:4)(N + ln)/(l2c)(cid:5)l.
Summing this expectation over the at most N possible
cord values, we see that the expected number of check-
sum tests in the message reconstruction phase is
(cid:18) N
l (cid:19)(cid:24) N + ln
l2c (cid:25)
l
,
where the N/l bound comes from the fact that we have
to have at least l diﬀerent fragments for a given check-
sum cord before we will have to perform an actual check-
sum test. So, for example, if N = 80000, l = 8, n =
1000, and c = 14, then the expected number of check-
sum tests the victim must make is only 10,000. Thus,
if the adversary acts in a completely random fashion,
there is little additional work that he can create for us
in our single-phase algorithm.
The adversary has little advantage in our two-phase
algorithm, as well, although the total number of pack-
ets needed in this case is somewhat greater than in the
single-phase approach. Speciﬁcally, in the two-phase al-
gorithm, each router sends a total of lm fragments. The
victim ﬁrst assembles these as m-length subwords, and
then assembles the l words produced from this recon-
struction. If the ﬁrst phase uses c1-bit checksum cords
and the second phase uses c2-bit checksum cords, then
the expected number of checksum tests for the two-phase
algorithm is
m(cid:19)(cid:24) N + nlm
(cid:18) N
m2c1 (cid:25)
m
+(cid:18) N
lm(cid:19)(cid:24) N + nlm
lm2c2 (cid:25)
l
.
The arguments justifying this bound are similar to those
above, but applied twice. So, for example, if N = 80000,
l = 8, m = 4, n = 250, c1 = 14, and c2 = 12, then
the expected number of checksum tests the victim must
make is 10,000.
Of course, the adversary may deliberately send false
messages to us that have valid checksum cords accord-
ing to our scheme. But the number of such messages is
limited, for the adversary must be limited to the same
coupon collector bounds as the legitimate routers in T .
To estimate the number of such false messages, let us
conservatively assume that the probability that a packet
arrives unchanged from the adversary is equal to the
probability that the victim receives a packet marked by
a router. Thus, the maximum number of false messages
the adversary can send is bounded by n, the number
of legitimate routers in the attack tree. Still, the adver-
sary may not only try to send us false message with valid
checksum cords. He may also send lots of extra packets
that have checksum cords that deliberately collide with
each other, so as to make us do extra wasteful work try-
ing in vain to ﬁnd a combination of these word fragments
that have a checksum equal to this cord. Fortunately,
as we show in the next subsection, we can apply a prob-
abilistic packet ﬁltering strategy to our algorithm that
signiﬁcantly limits the amount of extra work the ad-
versary can force us to do in combining colliding word
fragments.
3.3 High Probability Packet Filtering
In this subsection, we derive a high-probability upper
bound on the running time of the message reconstruc-
tion algorithm, which is useful for identifying improba-
bly large numbers of collisions that are most likely de-
liberately sent by the adversary in an attempt to slow
down our traceback algorithm. Armed with this high-
probability bound, we can safely discard packets that
deﬁne an improbably large number of collisions in re-
constructing the blocks for a speciﬁc cord C. We derive
this upper bound somewhat indirectly, as it is easier to
derive bounds on summations of random variables than
it is on their products. Let us ﬁx a checksum cord C,
and let Y = Z0 + Z1 + ··· + Zl−1, where Zi denotes
the number of distinct blocks with fragment index i and
cord C. We will bound Y and thereby derive a bound on
Z = Z0Z1 ··· Zl−1. We will utilize the following Cher-
noﬀ bound (e.g., see Motwani and Raghavan [14]):
Theorem 1 (Chernoﬀ Bound Theorem): Let Y be
the sum of independent indicator (0/1) random vari-
ables, and let µ denote the expected value of Y . Then,
Pr(Y > (1 + δ)µ)  µ,
Pr(Y > k)  lx)  x
l
)  lx the odds that Z > xl. So, for example, if l =
8, c = 15, x = 3, n = 210, and N = 218, then the
probability that Y > 24 is less than 1/248, which is
a very small number. Thus, in this example, we may
safely discard the packets for any index C that have
more than 24 packets. That is, we may safely discard
any subproblems that would cause us to perform more
than 38 = 6561 checksum tests. With high probability,
such a subproblem will not occur at random, so it most
123Frag.
scheme
2
3
2 + 2
3 + 2
3 + 3
9
56
104
188
380
760
Number, c, of Checksum Bits
10
14
36
52
64
96
88
168
200
344
688
400
13
40
72
108
236
472
11
48
88
148
308
616
12
44
80
128
272
544
15
32
56
68
164
328
Table 1: Message sizes for the given fragmentation
schemes and checksum lengths, assuming b = 25 is the
bit length of individual blocks. A fragment scheme iden-
tiﬁed by ”x” indicates a scheme with x number of bits
used to index fragments. A fragment scheme identiﬁed
by “x + y” indicates a two-phase fragmentation scheme
where the ﬁrst round uses x bits for the fragment index
and the second round uses y bits for the fragment index.
We index the checksum needs in the two-phase schemes
by c1, since we can set c2 = c1−(cid:4)log l(cid:5) and get the same
conﬁdence bound.
Frag.
scheme
3
2 + 2
3 + 2
3 + 3
Number, c, of Checksum Bits
8
48
80
160
320
9
40
60
124
248
11
24
20
52
104
10
32
40
88
176
Table 2: Message sizes for the given fragmentation
schemes and checksum lengths, assuming b = 17 is the
bit length of individual blocks.
likely was sent to us by the adversary in an attempt to
make us do extra unnecessary work in our single-phase
traceback algorithm. A similar analysis can be done for
the two-phase algorithm, which we omit here.
3.4 Trading-Off Message and Cord Size
As we observed above, increasing the checksum size
leads to higher security. A large checksum makes the
space of possible messages addresses large, which in turn
makes it that much more diﬃcult for the adversary to
interject false messages that collide with legitimate ones.
Of course, this increased security has a cost. Namely, as
the checksum becomes larger, the bits left over for the
message must go down. Even so, there are still several
strong choices for checksum lengths and fragmentation
schemes that allow for message sizes long enough to do
authenticated IP traceback. We show in Table 1 the
maximum message size for various randomize-and-link
fragmentation schemes, assuming b = 25, and we show
similar information for b = 17 in Table 2.
3.5 Sufﬁcient Packet Volume
We have described the randomize-and-link strategy in
a general way, so as to allow for several possible message
sizes. But we should also recognize that reconstructing
large messages requires more packets. Moreover, the
number of needed packets also increases with the num-
ber of routers in the attack tree. In order to keep the
reconstruction algorithm fast, we prefer that expected
number of collisions between a given packet and any
other packet be less than 2. The randomize-and-link
algorithm will still work for higher expectations, but it
Frag.
scheme
2
3
2 + 2
3 + 1
2 + 3
3 + 2
3 + 3
Number, n, of Routers in Attack Tree
50
1176
2628
5810
5810
12729
12729
27675
100
2628
5810
12729
12729
27675
27675
59785
250
7486
16357
35486
35486
76516
76516
164122
500
16357
35486
76516
76516
164122
164122
350424
1000
35486
76516
164122
164122
350424
350424
745208
Table 3: Expected upper bounds on N , the number
of packets that need to be received for various frag-
mentation schemes and number of routers, n, in the at-
tack tree. The volumes given are the expected number