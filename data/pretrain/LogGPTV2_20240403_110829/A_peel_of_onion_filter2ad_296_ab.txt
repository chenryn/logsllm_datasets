●  Plus, as a word, it has a good meaning in 
German (door/gate/portal) and Turkish (fine-
meshed net) 
Aside: Why is it called ‘Tor’ and 
what does ‘Tor’ mean? 
●  We foolishly called the first Tor paper “Tor: 
the second generation onion router” 
●  But this was very confusing 
• 
‘Tor’ stands for “The onion routing” or “Tor’s onion 
routing”. It does not stand for “the onion router” 
•  The paper is about the whole system, not just the 
onion routers 
•  Tor is not the second generation 
Aside: Why is it called ‘Tor’ and 
what does ‘Tor’ mean? 
Aside: Why is it called ‘Tor’ and 
what does ‘Tor’ mean? 
●  Tor:   A (class of) onion routing design created 
at NRL starting c. 2001-2. 
●  Tor:   A U.S. 501(c)3 nonprofit organization 
formed in 2006. 
●  Tor:   A client software program that connects 
your computer to the Tor network. 
●  Tor:  A volunteer network comprised of c. 5000 
nodes serving c. 4 GiB/s data for c. 1M users 
(see metrics.torproject.org ) 
●  Any amorphous combination of the above or 
other users 
Onion routing origins: Generation 0 
●  Fixed-length five-node circuits 
●  Integrated configuration 
●  Static topology 
●  Loose-source routing 
  Partial active adversary 
●  Rendezvous servers and reply onions 
Onion routing, the next generation 
   Running a client separated from running an OR 
●  Variable length circuits (up to 11 hops per onion---or 
tunnel for more) 
●  Application independent proxies (SOCKS) plus 
redirector 
  Entry policies and exit policies 
●  Dynamic network state, flat distribution of state info 
●  Multiplexing of multiple application connections in 
single onion routing circuit 
●  Mixing of cells from different circuits 
●  Padding and bandwidth limiting 
Third-generation onion routing 
(Tor)  
  Onion skins, not onions: Diffie-Hellman based 
circuit building 
●  Fixed-length three-hop circuits 
●  Rendezvous circuits and hidden servers 
●  Directory servers, caching (evolved w/in Tor) 
●  Most application specific proxies no longer 
needed (still need e.g. for DNS) 
●  Congestion control 
●  End-to-end integrity checking 
●  No mixing and no padding 
Circuit setup 
KA,R5  (cid:15492) "
KA,R2  R5 
KA,R1  R2 
●  NRL v0 and v1 onion routing and also ZKS 
Freedom network used onions to build circuits 
•  Lacked Forward Secrecy 
•  Required storing record of onions against replay 
●  Tor (NRL v2) uses one layer “onion skins”  
•  ephemeral Diffie-Hellman yields forward secrecy 
•  No need to record processed onions against replay 
•  From suggestion out of Zack Brown’s Cebolla 
Tor Circuit Setup (Create) 
Client chooses first node, establishes session key over TLS connection 
 "
, Hash(          )	
Onion Router	
Client	
Initiator	
TLS connection 
Tor Circuit Setup (Create) 
Client chooses first node, establishes session key over TLS connection 
 "
Client	
Initiator	
, Hash(          )	
Onion Router	
Tor Circuit Setup (Extend) 
Client chooses first node, establishes session key over TLS connection 
 "
OR2, 
Client 
Initiator 
, Hash(      ) 
OR1	
, Hash(      ) 
OR2 
Tor Circuit Setup (Begin) and 
Data Flow 
Slight simplification of actual protocol 
 "
Client 
Initiator 
Connect 
Reply 
OR2 
OR1 
Reply 
Web server 
How do we know where to build a 
circuit? Network discovery. 
●  Flat flooding of network state: complex, 
tricky, scales in principal but ?  
●  Tor has a directory system 
●  Originally a single directory signing 
information about network nodes. Then a 
multiple redundant directory with mirrors. 
Then a majority vote system. Then a 
consensus document system. Then separate 
things that need to be signed and updated 
frequently. Then... 
Onion routing was invented to 
separate identification from routing 
●  What if onion-routing-network-user is the 
identification you want to avoid? 
●  Bridges are proxies into the Tor network that are 
not publicly listed. 
●  Tricky to get bridge info out to potential users 
without giving it to the network blockers. 
●  Flash Proxy plugin on volunteer’s browser 
connects to both censored client and Tor relay 
●  Can also use obfuscated transport to hide Tor 
protocols from DPI.   
What if adversary owns a botnet 
or has nation level resources? 
●  Consumer Alice, abuse/disease victim Alice, 
local law enforcement Alice, etc. probably OK 
●  Intelligence analyst Alice, DoD road warrior 
Alice, etc. ? 
Network diversity environment 
•  Government comms sometimes must use public 
internet 
•  Open source intelligence gathering 
•  Traveling employees communicating back home 
• 
Interacting with untrusted/semitrusted parties 
•  Need a network with diversely run infrastructure 
•  Economic and usage feasibility implies a free-
to-use network with infrastructure open to any 
contributors 
•  Cannot preclude adversaries running a 
significant portion of your network 
First-Last Correlation Problem 
What? 
●  Adversary observes first and last routers. 
●  Traffic patterns link first and last routers. 
Why? 
●  Attack completely breaks anon regardless of number of users. 
●  Attack possible with moderate resources. 
–  17MB/s compromises random 1% of current Tor users                     
(100 or so home Internet accounts needed for attack) 
●  Padding, etc. too expensive and will never work anyway. 
Key Idea: Trust 
●  Users may know how likely a router is to be 
under observation. 
Tor Routers with Possible Trust Factors 
Name 
Hostname 
Bandwidth  Uptime  Location 
Tor version  OS 
moria 
nexico.ediscom.de 
4 KB/s 
67 days  Germany 
0.2.1.26 
Linux 
Republic 
xvm-107.mit.edu 
121 KB/s 
49 days  USA 
0.2.1.29 
Linux 
Unnamed  static-
ip-166-154-142-114.
rev.dyxnet.com 
58 KB/s 
58 days  Hong 
Kong 
0.2.1.29 
Windows 
Server 
2003 SP2 
Source: http://torstatus.blutmagie.de, 10/12/2011 
Basic Adversary Model 
 Routers R 
 Users 
Destinations 
Adversary A 
Basic Trust Model 
 Routers R 
 Users 
Destinations 
0
1
Probability of Compromise: c  
Adversary A 
Trust Model 1: Limited Adversary 
 Routers R 
 Users 
Destinations 
0
1
Probability of Compromise: c 
Adversary A 
A⊆R, |A|≤k 
Trust Model 1: Limited Adversary 
 Routers R 
 Users 
Destinations 
0
1
Probability of Compromise: c 
Adversary A 
A⊆R, |A|≤k 
Trust Model 2: Per-User Adversary 
 Routers R 
 User u 
Naïve 
users N 
Destinations 
0
1
Probability of Compromise: c 
Adversary AN 
The Man 
Trust Model 2: Per-User Adversary 
 Routers R 
 User u 
Naïve 
users N 
Destinations 
0
1
Probability of Compromise: c 
Adversary AN 
Trust Model 2: Per-User Adversary 
 Routers R 
 User u 
Naïve 
users N 
Destinations 
0
1
Probability of Compromise: c 
Adversary Au 
Adversary AN 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
metric. 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
1 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
1 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
2 
1 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
2 
1 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
3 
2 
1 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Randomly select among routers with trust ≥ λi 
Downhill Algorithm 
Key idea: Blend in with the naïve users. 
3 
2 
1 
1.  Set path length l and trust levels λ1,…, λl to optimize anonymity 
2.  For 1 ≤ i ≤ l, 
metric. 
 Create circuit through selected routers to the destination. 
 Randomly select among routers with trust ≥ λi 
3.  For each connection, 
Anonymity Analysis of Downhill Algorithm 
Metric: Posterior probability of actual source of a given 
connection. 
Expected anonymity  Downhill  Most trusted  Random  Lower bound 
Many @ medium trust  0.0274 
Many @ low trust 
0.0550 
0.2519 
0.1751 
0.1088 
0.4763 
0.01 
0.001 
Anonymity Analysis 
Metric: Posterior probability of actual source of a given 
connection. 
Expected anonymity  Downhill  Most trusted  Random  Lower bound 
Many @ medium trust  0.0274 
Many @ low trust 
0.0550 
0.2519 
0.1751 
0.1088 
0.4763 
0.01 
0.001 
Scenario 1: User has some limited information.  
c=.01 
5 routers 
c=.1 
c=.9 
10 routers 
1000 routers 
Anonymity Analysis 
Metric: Posterior probability of actual source of a given 
connection. 
Expected anonymity  Downhill  Most trusted  Random  Lower bound 
Many @ medium trust  0.0274 
Many @ low trust 
0.0550 
0.2519 
0.1751 
0.1088 
0.4763 
0.01 
0.001 
Scenario 2: User and friends run routers. Adversary is strong.  
c=.001 
5 routers 
c=.05 
c=.5 
50 routers 
1000 routers 
Tor: Actual path selection 
Alice 
R1 
R4 
R2 
R5 
Bobs 
R3 
Tor: Actual path selection 
Alice 
R1 
R4 
R2 
R5 
Bobs 
R3 
Tor: Actual path selection 
Alice 
R1 
R4 
R2 
R5 
Bobs 
R3 
Tor: Actual path selection 
Relay choice is weighted by bandwidth & depends on uptime 
Alice 
R1 
R4 
R2 
R5 
Bobs 
R3 
Users get routed 
(ACM CCS’13 NRL/Georgetown collaboration) 
●   80% of all types of users may be 
deanonymized by moderate Tor-relay adversary 
within 6 months 
First-Last Correlation Problem 
What? 
●  Adversary observes first and last routers. 
●  Traffic patterns link first and last routers. 
Onion Routers (Relays/Nodes): 
Overlay network 
R1 
R4 
R2 
R5 
R3 
Users get routed 
(ACM CCS’13 NRL/Georgetown collaboration) 
●   80% of all types of users may be 
deanonymized by moderate Tor-relay adversary 
within 6 months 
●  Against a single-AS adversary roughly 100% of 
users in some common locations are 
deanonymized within three months 
●  (or 95% in 3 months for a single IXP) 
●  2-AS adversary reduces median time to the first 
client deanonymization by an order of 
magnitude:  
–  from over 3 months to only 1 day for typical web user 
–  from over 3 months to c. 1 month for a BitTorrent user  
Using Trust is first approach to 
protect traffic even if adversary 
owns a large chunk of the 
network. 
Not yet (or much) mentioned/future work: 
●  Datagram transport 
●  Links 
●  Performance/congestion/throttling/incentives 
●  Hidden services 
●  Trust propagation 
●  Better security models 
Questions?