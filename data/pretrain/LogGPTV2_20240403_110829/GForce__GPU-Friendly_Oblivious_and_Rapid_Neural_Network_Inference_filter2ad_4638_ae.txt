∗2354
666555...111333
[7.05]
Ofﬂine
54.35
Online
16.79
67.40
269.54
712.35
∗883.42
2125
15.01
111...888777
220
∗196.74
222444...555
Note: (cid:96) is the bit length of the input in plaintext. [·] denotes the standard deviation.
Figures with ∗ are based on estimation. Falcon’s ﬁgures are quoted from its paper.
Gazelle’s ﬁgures come from our reproduced experiments.
Table 4: (Non-approximated) ReLU Layer Benchmarks
#input
Framework
10000
40000
218
Gazelle
Falcon
GForce
Gazelle
Falcon
GForce
Gazelle
Falcon
GForce
(cid:96)
20
30
20
20
30
20
20
30
20
Comp. (ms)
Comm. (MB)
Ofﬂine
485.60
[8.18]
365.50
30807
[97.59]
1828
[17.57]
∗1462
43739
[147.70]
13681
[95.69]
∗9580
195783
[644.99]
Online
115.6
[6.45]
181.90
222000...111111
[0.96]
397.8
[14.25]
∗727.6
222555...888888
[2.38]
2950
[42.99]
∗4768
888888...000222
[10.74]
Ofﬂine
38.99
Online
14.27
68.20
534.54
155.98
∗272.80
799.65
1022
∗1787
3185.5
15.02
111...444000
57.08
∗60.08
555...666111
374.00
∗393.74
333666...777555
Note: (cid:96) is the bit length of the input in plaintext. Figures with ∗ are based on estimation.
[·] denotes the standard deviation. Comp.: Computation; Comm.: Communication.
Table 5: Maxpool (2× 2) Layers Benchmarks
Falcon only provided their runtime for 1000 or 10000 in-
puts. The latter grows up by a ratio of 9.6× over the former,
so we treat their ﬁxed runtime cost amortized. According to
our estimation of their performance on 217 inputs3 by linearly
scaling its runtime for 10000 inputs, we outperform Gazelle
by 27× and Falcon by 36× in the online runtime. The larger
speed-up ratio indicates that GForce can handle a large batch
of inputs better than prior arts. We also outperform by at least
7× in the online communication cost.
Maxpool Layers. Table 5 shows the runtime and commu-
nication costs of maxpool layers of window size 2× 2. For
10000 inputs, we outperform Gazelle and Falcon by 6× and
9× for the online runtime and by 10× and 11× for the online
communication cost, respectively. Falcon did not provide the
ﬁgures for 40000 and 218 inputs, so we estimate by scaling
its runtime linearly, similar to the case for ReLU. For 40000-
inputs, we reduce the online runtime of Gazelle and Falcon
by 15× and 28×, respectively. For input size up to 218, we
reduce the online runtime by 34× and 54×, respectively.
While we just quote the ﬁgure from the paper of Fal-
3Gazelle’s implementation is too memory-consuming. We failed to bench-
mark it on a larger batch for ReLU but managed to do 218 for maxpool.
Architecture
Dataset
Nearest
Naïve
90.88% 90.08% 10.62%
CIFAR-10
93.11% 83.92% 10.06%
CIFAR-100
73.14% 64.83%
1.03%
[·] denotes the standard deviation: Nearest/Floor is deterministic. Naïve’s are omitted.
Stocha. (GForce)
90.82%[0.069%]
93.22%[0.076%]
72.83%[0.075%]
A-MT
VGG-16
VGG-16
Floor
Table 6: Accuracy of Different Rounding Methods
con [13], we believe its performance would not change dra-
matically since then, since it also adopts GC for non-linear
layer as Gazelle, and Gazelle’s performance reproduced in our
platform is similar to the reported ﬁgures. Note also that the
main technical contribution of Falcon lies in its linear layer.
The baseline is, our ﬁgures are order-of-magnitude better.
SRT Layers. Figure 5 shows the online runtime of the
truncation layers. It illustrates a pattern similar to other non-
linear layers in that the ﬁxed cost dominates the runtime for
small input size. Nevertheless, truncation layers can ﬁnish the
computation in less than 10ms for small inputs (whose size is
less than 105). Compared to the layers built on top of DGK,
truncation layers are faster by an order of magnitude.
Table 6 shows that our SRT layers are both efﬁcient and
accurate. We implement several rounding methods in our trun-
cation layers and test them with CIFAR-10/100 datasets over
A-MT and VGG architectures (see Section 4.2 for their de-
scription). Stochastic rounding can attain an accuracy similar
to the nearest rounding. Nearest rounding and ﬂoor rounding
could be realized by DGK, but with the runtime increased by
an order of magnitude. Naïvely truncating the least signiﬁcant
bits of each additive share is adopted by Delphi [18], but it
would make the model almost useless. We suspect the tight
plaintext space is a reason (our 22-bit vs. Delphi’s 32-bit,
resulting in a 210× increase in the error probability).
While the usage of clip() in SWALP’s quantization (men-
tioned in Section 3.7) appears to be helpful, our experimental
results in Tables 7-8 show that it has a very mild impact on
the accuracy: SWALP [28] reports their VGG-16 can attain
93.3% and 73.3% accuracy on CIARF-10/100, respectively,
while the accuracy of GForce over VGG-16 without clip()
drops by less than 0.5pp. We suspect that SWALP-trained
neural networks have already optimized the parameters so
that the intermediate values rarely exceed the range.
Runtime w.r.t. Input Sizes. Figure 5 sheds light on how
the online runtimes of our comparison-based layers grow with
the input size. For small (<105) input sizes, they grow very
slowly, indicating the runtime is dominated by the ﬁxed costs,
including the constant latency of transferring data between
CPU and GPU and over the network. For larger input sizes, the
runtime grows linearly. It also explains why we outperform
Falcon and Gazelle the most when the input size is large. The
maxpool layers have shorter online runtime than ReLU layers
and the basic DGK protocol for the same input size because
the total number of comparisons that maxpool layers invoke is
2156    30th USENIX Security Symposium
USENIX Association
Architecture
A
A-MT
BC5
BatN-CNN
ResNet-18
VGG-16
Comp. (ms)
Comm. (MB)
Framework Accuracy
MiniONN
Gazelle
Falcon
Delphi
Delphi
Delphi
GForce
XONN
SHE
SHE
GForce
Ofﬂine
81.61% 472000
9340
-
7200
81.61%
41900
83.33%
87.21%
44444
87.77% 101904
249304
90.82%
[0.069%]
[567.25]
88.00%
92.54%
94.62%
999333...111222%
[0.076%]
900007
[14106]
3046
940
265
159
247
3319
4698
Online Ofﬂine Online
6226
72000
296
3560
1459
2880
7.5
380
11
640
7742
281
111444777...222666
31.43
[5.21]
41
123940
160
2258000
160
12041000
352.75
50.46