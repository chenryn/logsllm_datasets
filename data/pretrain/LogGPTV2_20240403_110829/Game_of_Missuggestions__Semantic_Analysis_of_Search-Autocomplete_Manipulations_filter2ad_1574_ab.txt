ﬁnd out
the lemma (i.e., organize) for each word (e.g.,
“organizes”, and “organizing”). The state-of-the-art algorithm
(e.g., WordNetLemmatizer) can achieve 95% of accuracy [35].
Adversary model. In our research, we consider that an
adversary is capable of forging a large number of queries,
through various sources/locations, to promote illicit, unwanted
or unrelated content. It renders the detection approach based
upon IP identiﬁers less effective. Also, we do not assume the
availability of query logs since they are hard to get (except
for search service providers), hard to share (due to privacy
concerns) and hard to analyze (given the massive amount of
data they contain). Also, the techniques designed for this setting
are meant to provide the end user immediately protection, even
before the search engines start acting on the threat. On the
other hand, we assume that it is difﬁcult for the adversary to
produce a large amount of web content, distribute it across
many reputable websites to be indexed by search engines. This
certainly needs more resources than faking queries.
3
III. UNDERSTANDING MISSUGGESTIONS
In this section, we ﬁrst present an autocomplete ma-
nipulation ecosystem to explicate how missuggestions are
produced. Then, we elaborate on our analysis of a set of known
missuggestions and the features identiﬁed for differentiating
benign suggestions and those manipulated ones. These features
are utilized to build a scanner, Scacbuche, for detecting other
autocomplete manipulations.
A. How is Autocomplete Manipulated: An Example
Autocomplete manipulation has been extensively used by
miscreants for illicit activities. To understand how it works,
we describe the ecosystem of this emerging SEO business
discovered in our study, through purchasing from and interacting
with the service providers. Figure 2 presents a high-level view
about how such services operate, and how the different entities
involved interact with each other. First, a manipulation service
client (a.k.a., promoted site owner) sends a request to a service
provider (). Such a request includes the trigger, the suggestion
and the promotion period. Then, the provider creates a query
task for promoting the missuggestion (trigger+suggestion) and
distributes it to his crowd-sourcing operators (), or directly
generates queries to search for the targeted suggestion (). Once
the missuggestion successfully gets into the search engine, a
user who follows the search results of the suggestion () and
visits the promoted site () could be redirected to a phishing
site (). Accordingly, the manipulation service provider will
get the commission from the promoted site owner, while the
promoted site also gain trafﬁc that can be monetized.
As an example, iXiala [24] is an autocomplete manipulation
system, which provides manipulation service on 19 different
platforms (web and mobile), including search engines (Baidu,
Sogou, 360), C2C (Taobao) and B2C (Tmall, JD) platforms.
To change autocomplete results and display desired phrases, a
user can simply add a block of JavaScript onto his website.
The script creates a large number of iframes on the website.
Whenever the site is visited, these iframes automatically fetch
suggestion phrases from the iXiala platform, and submit great
amount of suggestions to the search engines. When searching
for the websites containing such promotional JavaScript code
on PublicWWW [31], a public website source code database,
we found around 10K websites such as by91.com, ael920.com,
and dytbj.com using such a script.
From the suggestions promoted by the iXiala, such as “fresh
air puriﬁcation system ﬁltech” and “Sanya hotels recommen-
dation - liba.com”, we found that the clients try to advertise
their speciﬁc but rarely known products, which are less in line
with the trigger’s semantics than the benign suggestions are
supposed to be. Accordingly, the search results of manipulated
suggestions focus on such promoted products, which are often
semantically inconsistent with the trigger.
These ﬁndings indicate that missuggestion has distinctive
features, particularly semantic inconsistency between trigger
terms and suggestions, and inconsistency in the search results
Fig. 2: Operational steps of an autocomplete manipulation
ecosystem. First, a client sent manipulation request to the
manipulation service provider (); Then, the service provider
distributed the query task to his crowd-sourcing operators () to
search for the targeted suggestion (); Once a victim searched
the manipulated suggestion () and visited the promoted site
(), he will be redirected to a phishing site ().
TABLE I: Summary results of the datasets.
# of
suggestions
# of linked
triggers
Badset
Goodset
Unkown set
150
300
114,275,000
145
298
1,000,900
# of result
pages
295
593
1,607,951
of trigger terms (without suggestions) and those for missugges-
tions. These features were utilized in our research for detecting
the manipulated autocomplete.
B. Features of Missuggestions
In our study, we identiﬁed a set of features that uniquely
characterize missuggestions. Here we describe the high-level
idea of utilizing the features to capture the manipulations.
Data collection. We ﬁrst collected a set of conﬁrmed mis-
suggestions (called badset) and legitimate suggestions (called
goodset) as well as their related search results, which are
illustrated in Table I. Here we describe them in details.
• Badset. The badset includes 150 manipulated suggestion
phrases and their corresponding trigger phrases posted online
by autocomplete manipulation companies (such as Affordable
Reputation Management[13] and yincmarketing[37]) to promote
their services. We further validated them through manual
inspections (e.g., looking for illicit content in search result
pages) to ensure that they were indeed bad and live.
• Goodset. The good suggestions were gathered using 1,000
trigger, which were randomly chosen from 1 million most
popular keywords reported by MFA [10]. The triggers cover a
wide range of search interests, over ten categories (technology,
education, ﬁnancial service, etc.). For each trigger, we took
its top 3 suggestions from the search engines. From all these
3,000 search terms (trigger+suggestion), we further selected
300 that were manually conﬁrmed to be legitimate, using the
validation criteria elaborated in Section V.
4
Search Result Inconsistency. In addition to the semantic
inconsistency features, we found that the search results of
the missuggestions often show a remarkable inconsistency with
their corresponding triggers, while the good ones will be in line
with those triggers. This is because a manipulated suggestion
is meant to affect the way the search engine prioritizes search
results, making promoted content more prominent in the results.
Figure 4 illustrated the search result inconsistency of the
missuggestion and the benign suggestion. For the search result
of the benign suggestion “norton online backup free download”,
they were similar to those of the trigger “online backup free
download” (e.g., the second search result), while none of the
search results of the missuggestion “strongvault online backup
free download” appeared in trigger’s top 20 search results.
Speciﬁcally, we measure the similarity of two ranked
domains lists, one retrieved from the search engine under the
trigger alone and the other under the whole query term (the
trigger and a suggestion). The similarity is calculated by Rank-
Biased Overlap (RBO) function [59], which was designed
to weigh high-ranking items more heavily than those down
the lists, handle nonconjointness and be monotonic with the
increasing depth (i.e., ranks) [59] (see Section IV-C for details).
Figure 3(b) compares the CDF of the domain list similarity
between the search result pages of the badset and goodset. As
we can see from the ﬁgure, missuggestions tend to have a lower
search result page similarity than benign ones in term of the
domains in search result pages: the average similarity is 0.08
for the missuggestions and 0.33 for the legitimate ones.
In our research, we characterize the semantic inconsistency
and search result inconsistency in multiple perspectives, besides
the sentence similarity and search result’s domain list similarity.
Such inconsistencies, fundamentally, are introduced by the
attackers who tend to promote less popular products than the
autocomplete service expects, making the promoted content
more prominent in the results. Therefore, the inconsistencies
are inherent to the attack strategies and can be hard to change.
IV. THE DESIGN OF SACABUCHE FRAMEWORK
In this section, we elaborate the technique we used to detect
missuggestions, starting with an overview of the idea behind
Sacabuche, which is followed by its design and implementation
details, and our evaluation of the implementation.
A. Overview
To catch manipulated suggestions, our idea is to exploit
the gap between the semantics of legitimate and manipulated
predictions in a scalable way. Such a gap can be immediately
observed from the semantic inconsistency and other semantic
features of some trigger-suggestion pairs, without even looking
at their query results. In the meantime, the results provide
further evidence for the presence of inconsistency: e.g., the
prediction term supposed to be popular vs. the actual small
number of search results reported for the term. Leveraging
these observations, we build an efﬁcient two-step detection:
ﬁrst ﬁltering out the vast majority of the legitimate predictions
having no signs of semantic inconsistency, without performing
expensive search queries, and then analyzing the search results
of a relatively small set of suspicious trigger-suggestion pairs
to identify the manipulated ones.
(a) Cumulative distribution of sen-
tence similarity per trigger/sugges-
tion pair.
(b) Cumulative distribution of
search result similarity per trig-
ger/suggestion pair.
Fig. 3: Discriminative features of missuggestions and benign
suggestions.
• Suggestion related search results. We collected search results
using the search engine API (e.g., Google Search API), with
both aforementioned trigger phrases and their search terms as
inputs. For each query (either a trigger or a search term with
both a trigger and a suggestion), its top 20 results indexed by
the search engine were recorded, including the titles, urls and
the descriptions.
Semantic inconsistency. Our key observation is that a trigger
and its suggestion are often less related when the autocomplete
has been manipulated, presumably due to the fact that a
missuggestion tends to promote a speciﬁc and rarely known
product, which is less relevant to the corresponding trigger. For
example, “play free bingo online now at moonbingo.com” and
“free bingo sites for us players” are both suggestions for the
trigger “bingo sites play free”. However, the former, which is
manipulated, is more speciﬁc (promoting moonbingo.com, a
bingo site), and therefore less similar to the trigger.
Such a semantic gap is leveraged by Sacabuche to differ-
entiate legitimate suggestions from manipulated ones. More
speciﬁcally, we utilize the Word2Vec technique to compare
the semantic meanings of a trigger and its suggestion (which
can have several words and a sentence-like structure), in
terms of sentence similarity Fss. Given two sentences sa and
st, we convert them into two phrase lists pl(sa) and pl(st)
through dependency analysis. Each phrase is identiﬁed from
the dependency tree [4] representation of a sentence, which
describes the grammatical relations among different words in a
sentence. Over the tree, we search for the directed paths with
a length of two, which connect two non-preposition and non-
article words together. All such phrases are extracted from each
sentence to form its phrase list. The phrase lists of the trigger
and the suggestion are then compared using the sentence kernel
SK deﬁned over a phrase kernel PK, which is further built
on a word embedding based word kernel WK. We detail the
sentence-level semantic inconsistency features in Section IV-B.
Such a semantic inconsistency feature was found to be
discriminative in our research. Figure 3(a) compares the cu-
mulative distribution function (CDF) of the sentence similarity
between the badset and goodset. As we can see from the
ﬁgures, missuggestions tend to have lower sentence similarity
than benign ones: the average sentence similarity is 0.56 for
the missuggestions and 0.67 for the legitimate ones.
5
0.00.20.40.60.81.0Sentence Similarity0.20.40.60.81.0ProbabilityBadset Goodset0.00.20.40.60.81.0Search Result Similarity0.20.40.60.81.0ProbabilityBadset Goodset(a) “online backup free download”.
(b) “strongvault online backup free download”.
(c) “norton online backup free download”.
Fig. 4: “strongvault” appears in (b) but rarely in (a), while “norton” appear both in (a) and (c).
Architecture. Figure 5 illustrates the architecture of Sacabuche,
including Prediction Finder (PF), Search Term Analyzer (STA)
and Search Result Analyzer (SRA). PF is designed to discover
a large number of autosuggestions: in particular, it iteratively
queries the search engines with depth limit to 3, starting from
a set of seed triggers (Section V-A) as the inputs, to derive a
great number of autocompletes. These suggestions are further
analyzed by STA, which looks at a set of semantic features
to identify suspicious terms (Section IV-B). Such suspicious
terms are then queried against the search engines by SRA, and
their results are inspected, based upon their content features,
to capture manipulated predictions (Section IV-C).
Example. Here we use an example to explain how Sacabuche
works. From a seed trigger “online backup free”, our approach
discovers its suggestion terms “online backup free mac”, “online
backup free download” (x), etc., which are further used as
triggers to ﬁnd more suggestions “best online backup free mac”
(y), “norton online backup free download” (z),“strongvault
online backup free download” ({), etc., as showed in Figure 4.
Among these suggestions, z and { are considered to be
suspicious by STA, since there is quite a semantic distance
between the triggers and their corresponding suggestions
(“norton” and “strongvault” does not seem to be semantically
related with the trigger x and also these suggestions are speciﬁc.
Both terms are then further queried on search engines like
Google. From their search results, SRA determines, through
a trained classiﬁer, that indeed there are evidences to believe
that { is a manipulated term: particularly, under the trigger x,
the presumably popular prediction “norton” appears frequently
in the top 20 search results, while “strongvault” does not even
show up among top 100 search results of the trigger. As a
result, this term is reported as problematic.
B. Semantics-based Search Term Screening
As mentioned earlier, Sacabuche ﬁrst analyzes the semantics
of individual query terms to identify those suspicious. These
terms are discovered by PF and pre-processed at this step,
before they are inspected by STA. The inspection involves
extraction of a set of semantic features from the terms and
running of a classiﬁer to ﬁnd suspicious ones based upon
the features. Here we elaborate these two steps, particularly
individual features utilized by STA.
Suggestion discovery and pre-processing. The autocomplete
predictions generated by search engines can be directly obtained
from them, e.g., from the suggestion lists triggered by the
input to their search boxes. A popular search engine typically
provides an API for collecting its complete suggestions with
regard to a given trigger term. In our research, we utilized
over 1 million popular search keywords (see Section V-A)
as “seed” triggers and ran PF to iteratively query the search
engine, with all the suggestions discovered in a round serving
as the triggers for the queries in the next round. In this way,
our approach is able to expand these seed terms and ﬁnd out
not only their suggestions but those of their related terms:
for example, from “free online games casino”, we can get
other terms in the gambling category, such as “slot machine”,
“roulette”, “blackjack”, and their suggestions.
The discovered suggestions and their corresponding triggers
form search terms. Before handing them over STA, they
need to be pre-processed to remove noise and further identify
meaningful semantic tokens, as follows:
URL formatting. From each trigger and suggestion, our ap-
proach identiﬁes the URLs in it and tokenizes the URLs. For
examples, the link https://www.subdomain.example.com/path1/
path2?q1=v1&q2=v2 is converted into the following tokens:
https www subdomain example com path1 path2 q1 v1 q2 v2.
Content sanitization. All tokens within a query term (a trigger-
suggestion pair) are then inspected to remove those less
useful for the follow-up semantic analysis. We remove special
words and phrases such as numbers, locations and stop words
(extremely common terms such as “the”). These tokens (words
or phrases) introduce noise to our semantic analysis, since