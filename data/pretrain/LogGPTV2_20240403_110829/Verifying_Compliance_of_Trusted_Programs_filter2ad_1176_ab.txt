### SELinux Trusted Program Package

#### SELinux Policy Module and Application Files
- **SELinux Policy Module**: This module is a set of rules that define the security policy for a specific application.
- **Application Files**: These are the files required for the application to run, including executables, configuration files, and data files.

#### Compliance Evaluation
1. **Tamper Protection**:
   - The system must protect the application from unauthorized modifications.
2. **Program Access Control**:
   - The application must enforce the system's access control policies.

#### Package Installation
1. **Policy Integration**:
   - The policy module is integrated into the SELinux system policy.
2. **File Installation**:
   - The application files are installed in the appropriate directories.

**Figure 1: Deployment and Installation of a Trusted Package**
- First, we check two compliance goals: (1) the system protects the application, and (2) the application enforces system goals.
- Second, the package is installed: the policy module is integrated into the system policy, and the application files are installed.

### 2.3 Program Enforcement

To justify a system’s trust, any trusted program must enforce a policy that complies with the system’s security goals. The reference monitor concept [1] has been the guide for determining whether a system enforces its security goals, and we leverage this concept in defining compliance. A reference monitor requires three guarantees:

1. **Complete Mediation**:
   - All security-sensitive operations must be authorized.
2. **Tamperproof**:
   - The reference monitor must be tamperproof to enforce its policy correctly.
3. **Simplicity**:
   - The reference monitor must be simple enough to verify enforcement of security goals.

While the reference monitor concept is most identified with operating system security, a trusted program must also satisfy these guarantees to ensure that a system’s security goal is enforced. Therefore, we define that a program enforces a system’s security goals if it satisfies the reference monitor guarantees in its deployment on that system.

In prior work, we developed a verification method that partially fulfilled these requirements. We developed a service called SIESTA, which compares program policies against SELinux system policies and only executes programs whose policies permit information flows authorized in the system policy [13]. This work considered two of the reference monitor guarantees:

1. **Complete Mediation**:
   - We used the SIESTA service to verify trust in the Jif STL implementation of the logrotate program. Since the Jif compiler guarantees enforcement of the associated program policy, this version of logrotate provides complete mediation, modulo the Java Virtual Machine.
2. **Compliance**:
   - SIESTA performs a policy analysis to ensure that the program policy complies with system security goals (i.e., the SELinux MLS policy). Compliance was defined as requiring that the logrotate policy only authorized an operation if the SELinux MLS policy also permitted that operation. Thus, SIESTA is capable of verifying a program’s enforcement of system security goals.

We find two limitations to this work:

1. **Ad Hoc Policy Construction**:
   - We had to construct the program access control policy relating system and program objects in an ad hoc manner. The resultant program policy specified the union of the system and program policy requirements, making it more complex than envisioned. It is difficult to design a compliant program access control policy, and such a policy may only apply to a small number of target environments. As discussed in Section 2.1, program policies should depend on system policies, particularly for trusted programs expected to enforce the system’s policy, making them non-portable unless carefully designed.
2. **Lack of Tamper Protection**:
   - This view of compliance does not protect the trusted program from tampering. Untrusted programs could obtain access to the trusted program’s files after the package is installed if the integrated SELinux system policy authorizes it. For example, if an untrusted program has write access to the /etc directory where configuration files are installed, as demonstrated in Section 2.2, SIESTA will not detect that such changes are possible.

**Figure 1: Summary of Requirements**
- For any system deployment of a trusted program, automatically construct a program policy that is compliant with the system security goals, thus satisfying the reference monitor guarantee of being simple enough to verify.
- For any system deployment of a trusted program, verify, in a mostly-automated way, that the system policy does not permit tampering of the trusted program by any untrusted program, thus satisfying the reference monitor guarantee of being tamperproof.

The typical number of verification errors must be small, and there must be a set of manageable resolutions to any such errors. In the remainder of the paper, we present a single approach that solves both of these requirements.

### 3. Policy Compliance

Verification of these two trusted program requirements results in the same conceptual problem, which we call policy compliance problems. Figure 2 shows these two problems:

1. **Information-Flow Compliance**:
   - Verify that the program policy only authorizes operations permitted by the system’s security goal policy.
2. **Tamperproof Compliance**:
   - Verify that the system policy, including the program contribution (e.g., SELinux policy module), enforces the tamperproofing goals of the program.

In this section, we define the formal model for verifying policy compliance suitable for both problems. However, as can be seen from Figure 2, the challenge is to develop system security goals, program policies, and tamperproof goals in a mostly-automated fashion that will encourage successful compliance. The PIDSI approach in Section 4 provides such guidance.

#### 3.1 Policy Compliance Model

We specify system-wide information-flow goals as a security lattice \( L \). We assume that elements of \( L \) have both an integrity and a confidentiality component: this is the case for both MLS labels in SELinux [11] and labels from the DLM [25]. Let \( \text{Integrity}(l) \) and \( \text{Conf}(l) \) be the integrity and confidentiality projections of a label \( l \in L \), respectively. Let the lattice \( L \) have both a top element \( \top \) and a bottom element \( \bot \). We use \( \text{high} = \text{Integrity}(\bot) \) and \( \text{low} = \text{Integrity}(\top) \) to denote high and low integrity and write \( \text{high} \rightarrow \text{low} \) to indicate that high integrity data can flow to a low integrity security label, but not the reverse.

An information-flow graph is a directed graph \( G = (V, E) \) where \( V \) is the set of vertices, each associated with a label from a security lattice \( L \). We write \( V(G) \) for the vertices of \( G \) and \( E(G) \) for the edges of \( G \), and for \( v \in V(G) \) we write \( \text{Type}(v) \) for the label on the vertex \( v \). Both subjects (e.g., processes and users) and objects (e.g., files and sockets) are assigned labels from the same security lattice \( L \). The edges in \( G \) describe the information flows that a policy permits.

We now formally define the concept of compliance between a graph \( G \) and a security lattice \( L \). For \( u, v \in V(G) \), we write \( u \rightarrow v \) if there is a path between vertices \( u \) and \( v \) in the graph \( G \). An information-flow graph \( G \) is compliant with a security lattice \( L \) if all paths through the combined information-flow graph imply that there is a flow in \( L \) between the types of the elements in the graph.

**Definition 3.1 (Policy Compliance)**: An information-flow graph \( G \) is compliant with a security lattice \( L \) if for each \( u, v \in V(G) \) such that \( u \rightarrow v \), then \( \text{Type}(u) \rightarrow \text{Type}(v) \) in the security lattice \( L \).

With respect to MAC policies, a positive result of the compliance test implies that the information-flow graph for a policy does not permit any operations that violate the information-flow goals as encoded in the lattice \( L \). If \( G \) is the information flow graph of a trusted program together with the system policy, then a compliance test verifies that the trusted program only permits information flows allowed by the operating system, as we desire.

#### 3.2 Difficulty of Compliance Testing

The main difficulty in compliance testing is in automatically constructing the program, system, and goal policies shown in Figure 2. Further, we prefer design constructions that will be likely to yield successful compliance. The two particularly difficult cases are the program policies (i.e., upper left in the figure) and the tamper-proof goal policy (i.e., lower right in the figure). The program policy and tamper-proof goal policies require program requirements to be integrated with system requirements, whereas the system policy and system security goals are largely (although not necessarily completely) independent of the program policy.

For example, while the system policy must include information flows for the program, the SELinux system includes policy modules for the logrotate and other trusted programs that can be combined directly.

1. **Program Policies**:
   - It is necessary for program policies to manage system objects, but often program policy and system policy are written with disjoint label sets. Thus, some mapping from program labels to system labels is necessary to construct a system-aware program policy before the information flow goals encoded in \( L \) can be evaluated. Let \( P \) be an information-flow graph relating the program subjects and objects, and \( S \) be an information-flow graph relating the system subjects and objects. Let \( P \oplus S \) be the policy that arises from combining \( P \) and \( S \) to form one information-flow graph through some sound combination operator \( \oplus \); that is, if there is a runtime flow in the policy \( S \) where the program \( P \) has been deployed, then there is a flow in the information flow graph \( P \oplus S \). Currently, there are no automatic ways to combine such program and system graphs into a system-aware program policy, meaning that \( \oplus \) is implemented in a manual fashion. A manual mapping was used in previous work on compliance [13].

2. **Tamperproof Goal Policy**:
   - The tamperproof goal policy derives from the program’s integrity requirements for its objects. Historically, such requirements are not explicitly specified, so it is unclear which program labels imply high integrity and which files should be assigned those high integrity labels. With the use of packages and program policy modules, the program files and labels are identified, but we still lack information about what defines tamperproofing for the program. Also, some program files may be created at installation time, rather than provided in packages, so the integrity of these files needs to be determined as well. We need a way to derive tamperproof goals automatically from packages and policy modules.

### 4. PIDSI Approach

We propose the PIDSI approach (Program Integrity Dominates System Integrity), where the trusted program objects (i.e., package files and files labeled using the labels defined by the module policy) are labeled such that their integrity is relative to all system objects. The information flows between the system and the trusted program can then be inferred from this relationship. We have found that almost all trusted program objects are higher integrity than system objects (i.e., system data should not flow to trusted program objects). One exception that we have found is that both trusted and untrusted programs are authorized to write to some log files. However, a trusted program should not depend on the data in a log file. While general cases may eventually be identified automatically as low integrity, at present we may have a small number of cases where the integrity level must be set manually.

Our approach takes advantage of a distinction between the protection of the trusted program and protection of the data to which it is applied. Trusted program packages contain the files necessary to execute the program, and the integrity of the program’s execution requires protection of these files. On the other hand, the program is typically applied to data whose protection requirements are defined by the system.

#### 4.1 PIDSI Definition

By using the PIDSI approach between the trusted program and the system, we can deploy that trusted program on different systems, ensuring compliance. Figure 3 demonstrates this approach. First, the program defines its own set of labels, which are designed either as high or low integrity. When the program is deployed, the system labels are placed in between the program’s high and low integrity labels. This allows an easy check of whether a program is compliant with the system’s policy, regardless of the specific mappings from system inputs and outputs to program inputs and outputs.

In the event that the trusted program allows data at a low integrity label to flow to a high label, then this approach can trick the system into trusting low integrity data. To eliminate this possibility, we automatically verify that no such flows are present in the program policy.

For confidentiality, we found that the data stored by most trusted programs was intended to be low secrecy. The only exception to this rule that we found in the trusted program core of SELinux was sshd; this program managed SSH keys at type `sshd_key_t`, which needed to be kept secret. We note that if program data is low secrecy as well as high integrity, the same information flows result, system data may not flow to program data, so no change is required to the PIDSI approach. Because of this, we primarily evaluate the PIDSI approach with respect to integrity.

In this context, the compliance problem requires checking that the system’s policy, when added to the program, does not allow any new illegal flows. We construct the composed program policy \( P' \) from \( P \) and \( S \). To compose \( P \) and \( S \) into \( P' = P \oplus S \), first, split \( P \) into subgraphs \( H \) and \( L \) as follows: if \( u \in P \) is such that \( \text{Integrity}(\text{Type}(u)) = \text{high} \), then \( u \in H \), and if \( u \in P \) is such that \( \text{Integrity}(\text{Type}(u)) = \text{low} \), then \( u \in L \).