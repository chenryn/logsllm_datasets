# 三、智能运维实践探索 {#三智能运维实践探索 .list-paragraph}
## 方案的孵化过程
目前业界主流的两种建设思路：
+-------------------+--------------------------+----------------------+
| **方案类型**      | **优点**                 | **缺点**             |
+-------------------+--------------------------+----------------------+
| A：               | 1、故障定位清晰          | 1、实施前置要        |
| 端到端，横向模式  |                          | 求高，改造日志或者智 |
|                   |                          | 能化撮合成本都比较高 |
|                   |                          |                      |
|                   |                          | 2、                  |
|                   |                          | 可以关联展现的指标少 |
+-------------------+--------------------------+----------------------+
| B：               | 1、实施推广相对容易，    | 1、短期很            |
| 服务树，纵向模式  | 不依赖庞大的上下级关系； | 难收集大量关键指标， |
|                   |                          | 项目初期成效不明显； |
|                   | 2、                      |                      |
|                   | 迭代方便，以指标项为单位 | 2、指标的时序化转换  |
|                   | ，可以小量多次追加指标项 | ，需要一定的实施经验 |
|                   |                          |                      |
|                   | 3、易分权管控            |                      |
+-------------------+--------------------------+----------------------+
> 以业务管理的视角审视运维支撑体系建设时，我们首先尝试端到端的横向模式，即构建基于用户真实访问行为的端到端智能化运维分析平台，通过数据关系，勾画上下依赖关系，预期对运维工作的全生命周期实现全闭环管理。
>
> 基于这样的思考，我们选择徽赢APP业务进行试点，在业务的各个环节都布控数据采集，进行日志输出改造，实验过程中，使用智能撮合技术，将相似度最高的请求/应答数据包进行智能化关联，以期实现数据上下级的自动化关联。
![](media/image1.png){width="5.768055555555556in"
height="3.009027777777778in"}
然而该方案在实际实施过程中遇到以下问题：
1.  改造成本太高，导致改造业务系统的数据输出内容极端困难，因此所有的分析必须依赖现有的环境数据；
2.  时间窗口与长耗时事件会导致多条事件之间的闭合窗口期太长，计算耗时可能会超出管理预期；
3.  系统数据差异性大造成批量化推广困难，找不到性价比合适的实施路线。
试点不顺利，我们对端到端的横向模式进行反思：智能化运维到底要如何建设？面临的最核心的问题诉求是什么？是否要依赖人工去梳理运维环境的网络架构和业务系统架构？当业务升级或变更时，是否需要人工更新架构图？当发生故障时，是否能够快速判断哪个业务系统模块或接口出现了问题，是否能够快速判断故障影响范围？
带着端到端无法有效推广的实战经验和心得，我们开始尝试不依赖业务流程关系、不依赖强CMDB关系的纵向服务树模式，即通过收集指标，配置数据关系，建立纵向继承的建设方案。该模式不需要提前梳理逐级关系，而只需了解上下级包含即可，大大简化了运维人员对数据的梳理过程。
## 智能运维落地方案
纵向服务树模式方案围绕"提升科技核心能力、促进科技赋能业务、优化科技服务机制"三大目标，加强"数字化、平台化、智能化"战略部署，从长远视角做好顶层设计。
目前华安证券已经建设日志平台、网络监控平台、系统监控平台，这些平台定位于系统、网络、应用等监控报警作用，并主要满足归档检索、检查监控的需求，辅助进行运维监控和运维分析等功能。
在新的服务树模式下，我们提出"一湖一总线三个能力平台"架构方案：
一湖：运维数据的规范化、集中化管理、存储及全生命周期的管理
一总线：运维数据的清洗、预计算、分发以及主题治理
智能分析平台：计算及模型管理
能力开放平台：数据共享及编排管理
![](media/image2.png){width="5.854861111111111in"
height="4.054166666666666in"}可视化平台：报表、拓扑、仪表盘等展现管理
**运维总线**
运维总线提供28种数据类型的异构计算、分发，涵盖大部分常规的运维数据场景，通过向导化配置，拖拽式完成数据分发思维的落地。运维数据总线提供数据主题管理、数据路由、时间标准化、字典表翻译、元数据标准化处理等数据操作，并支持断点续传、增量传输等数据完整性机制。
![](media/image3.jpeg){width="5.590972222222222in"
height="3.0618055555555554in"}
**运维数据湖**
运维数据湖采用完全自研的国产技术实现数据全生命周期的管理，通过标签化方便运维人员使用。
目前已采集的数据基本可以满足建设数字化运维第一阶段的要素:数据实时统一汇聚到大数据存储区，而下一阶段需要建立数字化运维数据模型,厘清各个数据源的数据模型，以保证这些模型能够被数字化运维的用例所识别，进而评估出不同模型间的直接交互和预期结果；第三阶段则在第二阶段对于现有数据模型分析中能够自动化并扩展与修正自己的数字化运维方案与模型，进行不断地论证与评估，真正地分析的信息是否真正有用；其趋势判断的结果是否可行以及更改的影响等。\
在角色上，IT
运维人员需要从一般"从业者"转换为"审计者"运营人员，跳出固守了十多年的对于设备完全掌控的观念，将目光投到业务数据的分析上，提高主动运维能力。
## 智能运维推进思路
首先，从核心业务场景开始，通过专业运维数据库平台对应用系统的 IT
数据源及业务数据源进行统一数据采集、指标提取和数据存储；
其次，针对业务的特点及业务部门的需求，进行指标管理体系咨询、调研，对IT数据和业务数据进行指标梳理和方案建设，形成指标规范与实施制度；然后，结合指标规范与实施制度进行指标体系管理；
最终以功能模块及平台模式的方式完成该银行指标管理体系的建设。同时，根据日常运维场景，在指标管理体系平台的上层应用中实现工作台、可视化管控和AIOps等功能模块的落地。具体阐述如下：
### **1、打破壁垒，建立全司统一的数字化监控指标体系**
建立全司统一的数字化监控指标体系，要将全司各个监控、巡检、原系统等平台，产生的事件、性能等数据，全部时序数字化，建立数字化运维指标。
指标体系的推进，需要从业务视角切入，以业务场景为主题、以业务连续性为宗旨，通过直面业务场景、正向梳理业务下辖的IT对象，逆向接入业务辖内的各种数据源，最终构建了一套具备概览所有业务场景健康度、俯瞰多维立体化
IT 指标等能力的指标管理体系。
### **2、借鉴经典，实现数据与算法的最佳适配**
异常检测的算法，业界已经相对成熟，ARIMA模型以数据平稳性为前提，可捕捉线性关系，不适用于数据波动性大的指标场景；例如Holt-winter及ETS簇模型可捕获数据的周期性、趋势性、季节性特征，但在非周期性数据上效果不佳；LSTM模型为循环神经网络的特殊形式，可拟合复杂的非线性特征，但算法训练耗时长，难以适用于海量指标数据场景。
成熟的算法往往很难直接运用在运维行业产生收益较高的运维场景，难点在于算法与数据的有效结合。华安证券利用对自身运维数据的了解和时效指标库的建设成果，反向梳理运维数据可能存在的几种特征，依据历史数据特征进行波形聚类，形成三大类数据：变化趋势具有明显相似性的"周期型"数据、区间内数据相对平稳的"阶梯型"数据及无规律的随机"波动型"数据。之后再对时序数据进行自动划分，形成异常检测pipeline。
针对"周期型"数据，重点检测当前数据与历史同期相比是否存在异常。数据按分钟分组，以箱形图统计每组数据的正常阈值范围，判别超越阈值的异常；
针对"阶梯型"数据，重点检测拐点的变化幅度及拐点之后数据的波动范围。计算全局及临近数据的波动方差，判别突升突降的异常拐点；使用四分位方法计算波动阈值，判别拐点之后数据持续性超越阈值的异常；
针对"波动型"数据，重点检测离群点，使用四分位方法，计算历史数据正常的波动阈值，判别超越阈值的异常。
### **3、技术中台化，解决海量指标的批量化推广问题**
以低代码开发语言SPL、消息队列Kafka、流计算引擎Flink等相关技术，构建我司的技术中台。
**a、指标自训练、异常自检测**
利用低代码工具实时构建时序指标数据，减少总编码量，降低开发难度。Flink实时从kafka中消费指标数据处理后更新至Beaver，训练子系统实时监测指标的历史数据量值，当数据持续而且量积累到10000个数据点时，平台自动开始模型识别的训练工作，自动化模式解决指标上量之后的应用生效问题。
**b、算法自优选**
评分引擎内嵌了线性回归、随机森林、KNN等AI算法，自动学习各个算法对指标最终分数的贡献权重，无需专家通过运维经验进行测试与配置，并提高异常检测分数的精确度。算法优选不仅提升了智能运维的管理能力，也大幅降低了对研发资源、运维资源的依赖。
评分引擎访问Beaver获取指标实时状态进行评分。评分服务从后端服务订阅评分队列，访问MySQL与Redis进行算法得分判定，评分结果回写至kafka中。相较于流处理方式，评分程序无需等待指标采集上报，访问Redis获取的指标即为最新数据，从而极大的提升了计算效率。
通过对每一个算法应用到数据集的得分情况，自动优选得分高的算法进行实时检测。
考虑智能算法的后端复杂程度和可能出现的得分偏离情况，方案也提供人工方式，强行选择某个算法应用于某种数据集，可通过可视化界面进行个性定制，快速构建与精细调整评分模型，动态刷新保存后实时生效。
### **4、态势剖析，业务视角的多维呈现**
业务系统的健康度，以0-100百分制分数实时刻画不同类型指标的运行状态，将原本需要专家判断的运维经验内嵌固化，形成标准化故障判定规则，对齐各方对故障的定义，减少沟通与理解成本。