c
F
$
h
o
2
a
o
o
li
s
g
E
E
j
a
l
o
d
a
C
m
D
M
T
g
m
s
V
P
Q
is
O
a
t
e
y
r
h
iv
p
c
R
y
h
y
r
S
n
e
e
l
o
a
l
o
n
H
P
w
tr
a
riv
k
t
o
e
rt
y
r
C
g
i
e
o
h
0
m
m
a
i
n
0
e
s
8
0
2
o
t
B
a
...
g
i
e
e
8
...
a
n
8
...
s
4
cl
u
D
u
0
4
m
0
a
s
c
k
A
1
4
b
4
2
4
8
E
h
i
n
a
y
d
e
d
o
m
0
5
2
e
Tor relays
(c)
m
n
g
D
F
H
P
B
C
g
h
m
p
j
a
l
o
ix
y
r
n
p
y
n
ix
a
l
o
a
t
e
b
l
u
t
m
r
e
l
o
y
a
i
e
...
g
i
e
o
O
P
o
o
e
B
R
riv
c
h
s
t
o
b
a
a
S
u
N
C
o
o
tr
o
tt
u
u
r
a
n
o
t
n
a
m
b
l
e
s
e
2
m
p
n
S
U
C
ci
R
e
u
k
1
o
m
0
x
p
S
ci
n
s
e
r
v
e
r
d
e
d
c
u
D
E
o
3
T
m
m
1
0
2
4
Tor relays
(b)
Figure 7: Number of times a particular relay was detected as a bottleneck, with guard relay (a) Fooligans,
with observed capacity 82 KBps, (b) jalopy, with observed capacity 5.8 MBps, (c) trusted, with observed
capacity 17.4 MBps, as of February 2011.
experiments, our attack was able to infer the identity of the
guard relays, since they appeared in the anonymity set with
the highest frequencies.
Observe that accounting for the fact that Tor clients use
3 guard relays by default (as compared to one in our exper-
iments) would reduce the frequency of them being detected
as a bottleneck relay by a factor of 3. However, note that
our results are conservative since we selected relays from a
limited pool of only 25 Tor relays. The current Tor net-
work size is about 2 000 relays; application of this attack on
the full Tor network would result in orders of magnitude re-
duction in the selection probability of relays which are not
the guard relay, correspondingly reducing their frequency of
being detected as a bottleneck relay. Thus in the full Tor
network, even with 3 guard relays, we can expect the fre-
quency of the guards being detected as the bottleneck relay
to be much higher than a random relay in the network.
Finally, we note that our attack was able to identify the
guard relay irrespective of its observed capacity. As the Tor
network is heavily used by a large number of users, even high
capacity relays become congested and cannot ensure enough
throughput to all the ﬂows. This causes them to aﬀect ﬂows’
throughput in a way that can be detected through our one-
hop relay identiﬁcation attack. As the guard relay has a
direct connection with the client, the severity of this attack
is much higher than an attack that identiﬁes the middle
relays.
3.5 De-anonymizing Tor Relays Offering
Location Hidden Service
In this section, we attempt to identify Tor relays that also
oﬀer location hidden services. The main purpose of a lo-
cation hidden service is to remain anonymous while serving
its clients. However, we show that when a Tor relay oﬀers
a location hidden service, it becomes susceptible to attacks.
The observation that enables de-anonymization of location
hidden servers is similar to our attack on guard relays, in
that the location hidden service is likely to have the highest
frequency of being part of the anonymity set of bottleneck
relays for circuits connecting to that location hidden service.
In order to assess the eﬀectiveness of this attack, we set up
our own Tor relay and advertised its existence to the Tor
network. We also conﬁgured this machine to oﬀer a location
hidden service. We setup a target ﬂow from a client ma-
chine to the location hidden service, and measured the ﬂow
throughput. While this target ﬂow was active, we probed
our Tor relay using a one-hop circuit as we did in Section 3.3.
We ran this experiment 100 times and computed the correla-
tion between the throughput of the target ﬂow and the probe
ﬂows. Using a correlation threshold of 0.4, and window sizes
of 300 and 400 seconds, we found that 15% and 9% of the
target ﬂows and the corresponding probe ﬂows were highly
correlated. Relating this observation with the observations
from Section 3.3, we can conclude that our Tor relay will
be placed in the anonymity set for bottleneck relays with
a much higher probability than any other relay. Moreover,
as there are usually 8 diﬀerent relays/nodes including the
server itself (the other seven relays comprise of three relays
each for the client’s circuit as well as the server’s circuit, and
a common meeting point for these circuits, called the ren-
dezvous relay) in the path between the client and the server,
each of them can become the bottleneck with 12.5% prob-
ability. Results from our experiment closely matches this
222value by identifying our Tor relay with roughly the same
probability (9%-15%).
3.6 Applicability to Interactive Trafﬁc
So far, we used bulk traﬃc in our experiments. We now in-
vestigate the accuracy of our attacks with interactive traﬃc
(characterized by bursts of traﬃc followed by periods of in-
activity). To evaluate our attacks, we ﬁrst built a model for
interactive traﬃc by collecting real packet level traces from
a fast Tor guard relay at various times from April 24 through
April 27. To preserve user privacy, we ﬁrst used Mittal et
al.’s [35] anonymizing framework to process the pcap traces;
for each observed packet, the output of the framework was
an anonymized client IP address, packet timestamp, and
packet length. We performed the above data anonymiza-
tion and minimization steps on the guard relay itself. The
original pcap traces were deleted immediately afterwards5.
Next, we analyzed the properties of the processed data.
In total over the three days we observed 19 478 ﬂows with
17 911 of these ﬂows containing between one to ten pack-
ets. We surmise that these correspond to either preemptive
circuits which were never actually used by Tor or failed cir-
cuit creation attempts. For the remaining ﬂows, we break
them up into ten-minute intervals and then calculate the
fraction of 5 second sub-intervals where any traﬃc was ob-
served. We next classify them into three categories based on
the fraction of time they were observed sending data. We
found 424 ﬂows that transferred traﬃc for more than 90% of
the time (non-interactive ﬁle downloads), 347 ﬂows with be-
tween 50% and 90% utilization (interactive ﬂows with mod-
erate utilization), and 796 ﬂows with less than 50% utiliza-
tion (interactive ﬂows with low utilization). We select only
the ﬂows comprising interactive traﬃc with moderate uti-
lization, and use the distribution of their average burst sizes
and gap times as a model for interactive traﬃc in our ex-
periments. After computing the distribution of burst sizes
and gap times, all intermediate data from previous steps was
discarded to maintain the privacy of Tor users.
Next, we performed two experiments over the live Tor
network, with 100 measurements each for the Scenarios All-
Common and None-Common. In both experiments, we set
up a bulk transfer ﬂow (the attacker) and an interactive ﬂow
(the victim). For the interactive transfer, the TCP server
was conﬁgured to send data to the victim in bursts where
each burst was followed by a gap period. Both the burst
size and the gap times were sampled from the observed dis-
tribution computed using real data. For both experiments,
we computed the correlation in throughput of the attacker
ﬂow and the victim ﬂow for those time intervals where the
victim ﬂow was active. We are interested in the fraction
of measurements where the correlation was greater than a
threshold. This metric corresponds to true positives for the
Scenario All-Common, and false positives for the Scenario
None-Common. The correlation threshold determines the
trade oﬀ between the true positives and the false positives.
Figure 8 depicts the ROC curve for our experiments. We
found that for an estimated false positive rate of 0 (95% con-
ﬁdence interval is less than 3.5%), the true positive rate is
s
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.2
 0.4
 0.6
 0.8
 1
False positives
Figure 8: Attack on interactive traﬃc: ROC curve.
Alice
R1
R2
R3
Eve1
Eve2
Figure 9: Stream ﬁngerprinting attack: breaking
unlinkability by exploiting stream throughput char-
acteristics.
greater than 0.5. Our analysis demonstrates the applicabil-
ity of our attacks on interactive traﬃc, though the accuracy
in this case is lower than that of bulk traﬃc.
4. STREAM FINGERPRINTING
Circuits in Tor typically carry multiple streams, which
correspond to individual TCP connections. By default, all
streams created by a client within a 10 minute period are
carried over the same circuit.6 Tor uses a diﬀerent schedul-
ing mechanism to share bandwidth between streams than
it does between circuits, providing an opportunity for new
attacks that correlate streams. In particular, we will show
that packet scheduling of streams that use the same circuit
creates special characteristics that can easily be recognized
by a completely passive attacker; this can be used to link the
streams as belonging to the same user and thus compromise
some of the unlinkability protections provided by Tor.7
4.1 Stream Throughput at Different Time Scales
Consider the scenario in Figure 9: Alice is communicating
simultaneously with Eve1 and Eve2. Alice’s Tor client mul-
tiplexes both streams over the same circuit, in this case con-
sisting of Tor relays R1, R2, R3. Eve1 and Eve2 can see that
both their connections are coming from the same exit node,
and would like to learn if they are both communicating with
the same person. We would expect that, since the streams
share the same path through the network, they should ex-
hibit similar throughput characteristics. Indeed, we ﬁnd a
very strong correlation between such streams; Figure 10(a)
shows the results of one experiment, with a correlation of
0.93. However, as shown in Section 3, a high correlation is
common among unrelated circuits that share the same bot-
tleneck node, e.g., if R3 is the bottleneck for both streams.
However, there is a second eﬀect that can be used to dis-
tinguish streams that share one or more common relays.
5In future work, we will enhance the anonymizing frame-
work to perform the data minimization and anonymization
steps in memory, in order to further minimize risk in case
the guard relay is compromised during the data processing
phase.
6This is governed by the Max_Circuit_Dirtiness parameter
in Tor.
7It should be noted that exit relays can already perform such