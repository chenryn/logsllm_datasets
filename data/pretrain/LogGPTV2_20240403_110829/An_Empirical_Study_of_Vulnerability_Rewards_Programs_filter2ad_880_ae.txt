need for a concerted effort at reducing this.
4.4.2 Independent discovery
Using the Chromium release blog, we manually coded
an additional variable independent. This variable
represents the number of times a vulnerability was inde-
pendently discovered. We coded it using the text of the
credit variable, which mentions “independent discov-
ery” of a vulnerability in the case of multiple independent
discoveries.
Our Chrome dataset indicates when a vulnerability was
independently discovered by multiple parties, identiﬁes
the parties, and in some cases, gives an upper bound
on the time between discovery and rediscovery. Of the
668 vulnerabilities in our Chrome VRP dataset, ﬁfteen
(2.25\%) of them had at least two independent discoveries,
and two of these had three independent discoveries. This
is a lower bound on the number of independent discover-
ies of these vulnerabilities, since it represents only those
known to the vendor.
Figure 11 displays the independent rediscovery rates
for individuals. Each dot represents an individual contrib-
utor in our dataset. Its x-value gives the number of vul-
nerabilities discovered by this individual, and its y-value
gives the number of these vulnerabilities independently
rediscovered by another contributor in our dataset. Of
those individuals who reported ﬁve or more vulnerabili-
ties, the highest rediscovery rate is 25\% and the mean is
284  22nd USENIX Security Symposium 
USENIX Association
12
5
e
s
e
l
e
n
o
e
m
o
s
y
b
4
d
e
t
r
o
p
e
r
y
l
t
3
n
e
d
n
e
p
e
d
n
i
s
e
2
i
t
i
l
i
b
a
r
e
n
u
v
f
l
1
o
r
e
b
m
u
N
0
0
20
40
Number of vulnerabilities reported
60
80
100
Figure 11: Independent vulnerability discoveries within the
Chrome VRP dataset. Each dot represents an individual con-
tributor in our dataset. Its x-value gives the number of vulnera-
bilities contributed by this individual, and its y-value gives the
number of these contributions that were independently discov-
ered by another contributor in our dataset.
4.6\%.
Our Firefox dataset does not indicate independent re-
discovery, but we have limited data from personal com-
munication with a Firefox security engineer [56]. He
indicated that there had been at least 4–7 vulnerabilities
reported through the VRP for which there had been two
independent discoveries, a rate of 2.7% to 4.7%, which is
consistent with what we see in our Chrome dataset.
Discussion Independent rediscovery rates can have im-
plications for estimating the number of latent bugs in
software [29] as well as understanding the expected decay
rate of a stash of zero-day vulnerabilities.
A zero-day loses its value when the vendor becomes
aware of it, which happens via independent discovery of
the vulnerability. Thus, a stash of zero-days will decay at
some rate. From the limited data available to us via our
study, we hypothesize that:
Hypothesis 7 The decay rate of a stash of zero-day vul-
nerabilities is low enough to be inconsequential as a result
of relatively low empirical independent rediscovery rates.
We encourage future studies that aim to conﬁrm or refute
this hypothesis using larger, more appropriate datasets.
5 Discussion and recommendations
In this section, we synthesize what we have learned and
present concrete recommendations for software vendors
based on our data analysis.
5.1 Mozilla Firefox vs. Google Chrome
Despite costing approximately the same as the Mozilla
program, the Chrome VRP has identiﬁed more than three
times as many bugs, is more popular and shows simi-
lar participation from repeat and ﬁrst-time participants.
There is a stark difference between the levels of external
participation in the two VRPs (Figure 2).
Despite having the oldest bounty program, external
contributions lag far behind internal contributions to Fire-
fox’s security advisories. In contrast, external contribu-
tions to Chrome’s security advisories closely rival internal
contributions. Investigating further, we ﬁnd three key dif-
ferences between the two programs:
Tiered structure with large special rewards Mozilla’s
program has a ﬁxed payout of $3,000, which is approxi-
mately equal to the normal maximum payout for Chrome
($3,1337). Nonetheless, Chrome’s tiered structure, with
even higher payouts (e.g., $10,000) possible for clever
bugs and special cases appears to be far more effective
in encouraging participation. This makes sense with an
understanding of incentives in lotteries: the larger the po-
tential prize amount, the more willing participants are to
accept a lower expected return, which, for VRPs, means
the program can expect more participants [5].
Time to patch We see a far higher variance in the
time-to-release-patch metric for critical vulnerabilities in
Mozilla Firefox. It is generally accepted that the viability
of responsible disclosure depends on a reasonable vendor
response time [50]. Thus, the high variance in Mozilla’s
response time could affect responsible disclosure through
the VRP.
Higher proﬁle Chrome’s VRP has a higher proﬁle, with
annual competitions like Pwnium providing particularly
high rewards (up to $150,000). Chrome authors also
provide extra reward top-ups for “interesting” bugs. We
believe this sort of “gamiﬁcation” leads to a higher proﬁle
for the Chrome VRP, which may help encourage partici-
pation, particularly from researchers interested in wider
recognition.
Our methodology does not provide insight into the mo-
tivations of security researchers and the impact of VRP
designs on the same—a topic we leave for future work.
Nevertheless, we hypothesize that these three factors com-
bined explain the disparity in participation between the
Firefox and Chrome VRPs. Accordingly, we recommend
Mozilla change their reward structure to a tiered system
like that of Chrome. We urge Mozilla to do whatever it
takes to continue to reduce the variance in time to release
a patch for critical vulnerabilities, though we also realize
the difﬁculty involved in doing so. Ongoing attempts at
privilege separation might enable reducing the variance in
time to patch critical vulnerabilities [17, 36, 39]. Mozilla
can also consider holding its own annual competitions or
otherwise increasing the PR surrounding its VRP.
USENIX Association  
22nd USENIX Security Symposium  285
13
5.2 Recommendations for vendors
Our study of the Chrome and Firefox VRPs yield a num-
ber of observations that we believe can guide vendors
interested in launching or evolving their own VRPs.
We ﬁnd that VRPs appear to provide an economically
efﬁcient mechanism for ﬁnding vulnerabilities, with a rea-
sonable cost/beneﬁt trade-off (Sections 4.1.1 and 4.1.6).
In particular, they appear to be 2-100 times more cost-
effective than hiring expert security researchers to ﬁnd
vulnerabilities. We therefore recommend that more ven-
dors consider using them to their (and their users’) advan-
tage. The cost/beneﬁt trade-off may vary for other types
of (i.e., non-browser) software vendors; in particular, the
less costly a security incident is for a vendor, the less
useful we can expect a VRP to be. Additionally, we ex-
pect that the higher-proﬁle the software project is (among
developers and security researchers), the more effective a
VRP will be.
Response time, especially for critical vulnerabilities,
is important (Section 4.4.1). High variance in time-to-
patch is not appreciated by the security community. It can
reasonably be expected to reduce participation because it
makes responsible disclosure through the VRP a less at-
tractive option than the other options available to security
researchers.
VRP incentive design is important and should be care-
fully considered. Chrome’s tiered incentive structure ap-
pears more effective at encouraging community participa-
tion than Firefox’s ﬁxed-amount incentive structure (Sec-
tion 4.2.1). Additionally, both Chrome and Firefox have
increased their rewards over time. Doing so increases
publicity, entices participants, and signals that a vendor
is betting that their product has become more secure over
time.
Our analysis demonstrates the impact of privilege sep-
aration on the Chrome VRP (Section 4.1.2). Privilege
separation also provides ﬂexibility to the Chrome team.
For example, a simple way for Chrome to cut costs while
still increasing participation could be to reduce reward
amounts for high-severity vulnerabilities and increase re-
ward amounts for critical-severity vulnerabilities. Mozilla
does not have this ﬂexibility. Vendors should consider
using their security architecture to their advantage.
6 Related Work
Mein and Evans share our motivation and present
Google’s experience with its vulnerability rewards
programs [35]. In contrast, our focus is on understanding
and comparing two popular VRPs run by competing
browser vendors. We also perform a number of analyses
not performed by the previous work as well as make
our data available for other researchers. We also
independently conﬁrm that, for both Google and Mozilla,
VRPs are cost-effective mechanisms for ﬁnding security
vulnerabilities.
Development lifecycle datasets Many authors have
looked to large datasets, including code repositories, bug
trackers, and vulnerability databases, to gather and ana-
lyze data in an effort to better understand some aspect of
the development lifecycle. Rescorla gathered data from
NIST’s ICAT database (which has since been updated and
renamed to NVD [44]) to analyze whether vulnerability
rates tend to decrease over time [49]. He found no evi-
dence that it is in fact worthwhile for software vendors
to attempt to ﬁnd vulnerabilities in their own software
because there is no evidence that such efforts are reducing
vulnerability rates.
Ozment and Schechter used the OpenBSD CVS reposi-
tory to ask and answer similar questions as Rescorla [47].
They ﬁnd that the rate of discovery of what they call
foundational vulnerabilities—those present since the be-
ginning of the study period—had decreased over the study
period.
Neuhaus and Plattner use vulnerability reports for
Mozilla, Apache httpd, and Apache Tomcat to evalu-
ate whether vulnerability ﬁx rates have changed over
time [42]. They conclude that the supply of vulnerabili-
ties is not declining, and therefore that attackers and/or
vulnerability researchers have not hit diminishing returns
in looking for vulnerabilities.
Neuhaus et al. use a dataset of Firefox security advi-
sories in combination with the Firefox codebase to map
vulnerabilities to software components and predict which
components are likely to contain vulnerabilities [43].
Scholte et al. use the NVD to evaluate how cross-site
scripting and SQL injection vulnerabilities have evolved
over time [52]. They ﬁnd that the complexity of such vul-
nerabilities does not appear to have changed over time and
that many foundational cross-site scripting vulnerabilities
are still being discovered.
Evaluating vulnerability-ﬁnding techniques Other
work has focused speciﬁcally on evaluating the many
available techniques for ﬁnding vulnerabilities, though
we are unaware of any previous work that has considered
public-facing VRPs as one such technique.
Austin and Williams evaluated four different tech-
niques for vulnerability discovery on two health record
systems: “systematic and exploratory manual penetration
testing, static analysis, and automated penetration test-
ing” [2], ﬁnding that very few vulnerabilities are in fact
found by multiple techniques and that automated penetra-
tion testing is the most effective in terms of vulnerabilities
found per hour.
Finifter and Wagner compared manual source code
analysis to automated penetration testing on a web appli-
cation, with similar ﬁndings: the techniques are comple-
mentary, and manual analysis found more vulnerabilities,
286  22nd USENIX Security Symposium 
USENIX Association
14
but took much more time than automated penetration test-
ing [24].
Edmundson et al. found that different reviewers tend
to ﬁnd different vulnerabilities and, even in a small code-
base, it takes many reviewers to spot all or even a sig-
niﬁcant fraction of the vulnerabilities present [18]. This
is consistent with our ﬁndings about the effectiveness of
crowdsourced VRPs.
A large body of work investigates defect prediction
using empirical techniques; we refer the reader to a survey
by Catal et al. [10].
7 Conclusion and future work
We examined the characteristics of well-known vulner-
ability rewards programs (VRPs) by studying two such
VRPs. Both programs appear economically efﬁcient, com-
paring favorably to the cost of hiring full-time security
researchers. The Chrome VRP features low expected pay-
outs accompanied by high potential payouts, a strategy
that appears to be effective in engaging a broad commu-
nity of vulnerability researchers.
We hope that our study of these two VRPs serves as a
valuable reference for software vendors aiming to evolve
an existing VRP or start a new one. Potential future work
on understanding VRPs includes economic modeling of
VRPs; identifying typical patterns, trajectories, or phases
in a VRP; and studying failed or unsuccessful VRPs to
get a better sense of possible pitfalls in VRP development.
Gathering and analyzing data from more VRPs will surely
paint a more complete picture of their potential costs and
beneﬁts.
Acknowledgments
We are particularly grateful to Chris Evans and Dan Veditz
for their help, encouragement, and feedback throughout
the research. We also thank Chris Hofmann, Parisa Tabriz,
Vern Paxson, Adrienne Felt, the anonymous reviewers,
and our shepherd, Sam King, for their feedback on drafts
of the paper.
security/2010/07/15/refresh/.
[2] AUSTIN, A., AND WILLIAMS, L. One technique is not enough:
A comparison of vulnerability discovery techniques. In Empirical
Software Engineering and Measurement (ESEM), 2011 Interna-
tional Symposium on (2011), IEEE, pp. 97–106.
[3] BARRETT, M. PayPal “Bug Bounty” Program for Security
Researchers, June 2012. https://www.thepaypalblog.
com/2012/06/paypal-bug-bounty-program/.
[4] BARTH, A., JACKSON, C., REIS, C., AND TEAM, T. G. C.
The Security Architecture of the Chromium Browser. Tech. rep.,
Stanford University, 2008.
[5] BHATTACHARYYA, N., AND GARRETT, T. A. Why People
Choose Negative Expected Return Assets - An Empirical Examina-
tion of a Utility Theoretic Explanation. Federal Reserve Bank of St.
Louis Working Paper Series (March 2006). http://research.
stlouisfed.org/wp/2006/2006-014.pdf.
[6] BLINDU, E. Vulnerabilities reward programs, July 2012.
http://www.testalways.com/2012/07/13/
vulnerabilities-reward-programs/.
[7] BUCHANAN, K., EVANS, C., REIS, C., AND SEPEZ, T. A Tale
of Two Pwnies (Part 2), June 2012. http://blog.chromium.
org/2012/06/tale-of-two-pwnies-part-2.html.
[8] BUCHANAN, K., EVANS, C., REIS, C., AND SEPEZ, T. Show
off Your Security Skills: Pwn2Own and Pwnium 3, January 2013.
http://blog.chromium.org/2013/01/
show-off-your-security-skills-
pwn2own.html.
[9] CARETTONI, L.
“No More Free Bugs” Initiative, Octo-
ber 2011. http://blog.nibblesec.org/2011/10/
no-more-free-bugs-initiatives.html.
[10] CATAL, C., AND DIRI, B. A systematic review of software fault
prediction studies. Expert Systems with Applications 36, 4 (2009),
7346–7354.
[11] Chromium Development Calendar and Release Info. http://
www.chromium.org/developers/calendar.
[12] Severity Guidelines
for Security
Issues.
https:
//sites.google.com/a/chromium.org/dev/
developers/severity-guidelines.
[13] Chromium Bug Tracker, 2013. http://crbug.com.
[14] Security: Pwnium 2 tcmalloc proﬁle bug, 2012. http://crbug.
com/154983.
[15] DAVIS, N. Secure Software Development Life Cycle Processes,
July 2012. https://buildsecurityin.us-cert.gov/
bsi/articles/knowledge/sdlc/326-BSI.html.
[16] Defense in Depth. http://www.nsa.gov/ia/_files/
support/defenseindepth.pdf.
[17] MozillaWiki: Electrolysis, April 2011.
mozilla.org/Electrolysis.
https://wiki.
[18] EDMUNDSON, A., HOLTKAMP, B., RIVERA, E., FINIFTER, M.,
METTLER, A., AND WAGNER, D. An Empirical Study on the
Effectiveness of Security Code Review. In Proceedings of the
International Symposium on Engineering Secure Software and
Systems (March 2013).
[19] EVANS, C. Celebrating Six Months of Chromium Security Re-
wards, July 2010. http://blog.chromium.org/2010/
07/celebrating-six-months-of-chromium.html.
[20] EVANS, C. Bug bounties vs. black (& grey) markets, May
2011. http://scarybeastsecurity.blogspot.com/
2011/05/bug-bounties-vs-black-grey-markets.
html.
This work was supported by Intel through the ISTC for
Secure Computing; by the National Science Foundation
under a Graduate Research Fellowship and grant numbers
CCF-0424422, 0842695, and 0831501-CT-L; by the Air
Force Ofﬁce of Scientiﬁc Research under MURI awards
FA9550-08-1-0352, FA9550-09-1-0539, and FA9550-12-
1-0040; and by the Ofﬁce of Naval Research under MURI
grant no. N000140911081. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this ma-
terial are those of the author(s) and do not necessarily
reﬂect the views of the NSF, the AFOSR, the ONR, or
Intel.
References
[1] ADAMSKI, L. Refresh of the Mozilla Security Bug Bounty
https://blog.mozilla.org/
Program, July 2010.
USENIX Association  
22nd USENIX Security Symposium  287
15
[41] Netscape announces ”netscape bugs bounty” with release of
netscape navigator 2.0 beta. The Internet Archive. http:
//web.archive.org/web/19970501041756/www101.
netscape.com/newsref/pr/newsrelease48.html.
[42] NEUHAUS, S., AND PLATTNER, B. Software security economics:
Theory, in practice. In WEIS (2012).
[43] NEUHAUS, S., ZIMMERMANN, T., HOLLER, C., AND ZELLER,
A. Predicting vulnerable software components. In Proceedings
of the 14th ACM conference on Computer and communications
security (2007), ACM, pp. 529–540.
[44] National Vulnerability Database. http://nvd.nist.gov/.
[45] OBES, J. L., AND SCHUH, J. A Tale of Two Pwnies (Part
1), May 2012. http://blog.chromium.org/2012/05/
tale-of-two-pwnies-part-1.html.
[46] Understanding Operational Security.
http://www.
cisco.com/web/about/security/intelligence/
opsecurity.html.
[47] OZMENT, A., AND SCHECHTER, S. E. Milk or wine: does soft-
ware security improve with age. In In USENIX-SS06: Proceedings
of the 15th conference on USENIX Security Symposium (2006),
USENIX Association.
[48] RAYMOND, E. S. The Cathedral and the Bazaar, 1st ed. O’Reilly
& Associates, Inc., Sebastopol, CA, USA, 1999.
[49] RESCORLA, E.
Is ﬁnding security holes a good idea? IEEE
Security & Privacy 3, 1 (2005), 14–19.
[50] CERT/CC Vulnerability Disclosure Policy, November 2012.
https://www.cert.org/kb/vul_disclosure.
html.
[51] Chromium bug tracker: Sandbox bypasses found in review, 2013.
http://goo.gl/13ZlR.
[52] SCHOLTE, T., BALZAROTTI, D., AND KIRDA, E. Quo vadis? a
study of the evolution of input validation vulnerabilities in web
applications. Financial Cryptography and Data Security (2012),
284–298.
[53] Secunia Vulnerability Coordination Reward Program (SVCRP).
https://secunia.com/community/research/
svcrp/.
[54] THE BLUEHAT TEAM. Microsoft Security Bounty Programs.
http://www.microsoft.com/security/msrc/report/
bountyprograms.aspx, June 2013.
[55] THE CHROMIUM AUTHORS. Vulnerability Rewards Program:
Rewards FAQ, 2010. http://goo.gl/m1MdV.
[56] VEDITZ, D. Personal Communication, February 2013.
[57] Vulnerability Remediation, September 2010. https://www.
cert.org/vuls/remediation.html.
[21] EVANS, C. Personal Communication, March 2013.
[22] EVANS, C., GROSSE, E., MEHTA, N., MOORE, M., ORMANDY,
T., TINNES, J., ZALEWSKI, M., AND TEAM, G. S. Rebooting
Responsible Disclosure: a focus on protecting end users, July
2010. http://googleonlinesecurity.
blogspot.com/2010/07/rebooting-
responsible-disclosure-focus.html.
[23] EVANS, C., AND SCHUH, J. Pwnium: rewards for exploits,
February 2012. http://blog.chromium.org/2012/02/
pwnium-rewards-for-exploits.html.
[24] FINIFTER, M., AND WAGNER, D. Exploring the relationship be-
tween web application development tools and security. In USENIX
conference on Web application development (2011).
[25] MozillaWiki: RapidRelease/Calendar, January 2013. https:
//wiki.mozilla.org/RapidRelease/Calendar.
[26] FISHER, D. Microsoft Says No to Paying Bug Bounties, July
2010. http://threatpost.com/
microsoft-says-no-paying-bug-
bounties-072210/.
[27] Chrome Releases:
Stable Updates.
http://
googlechromereleases.blogspot.com/search/
label/Stable%20updates.
[28] GORENC, B.
Pwn2Own 2013, January 2013.
http:
//dvlabs.tippingpoint.com/blog/2013/01/17/
pwn2own-2013.
L.
Total
Num-
Inspections.
[29] HATTON,
of
Faults
the
ber
Code
http://www.leshatton.org/2005/05/
total-number-of-faults-using-
parallel-code-inspections/, May 2005.
Predicting
Parallel
Using
[30] HOFMANN, C. Personal Communication, March 2013.
[31] HOLLER, C. Trying new code analysis techniques, January 2012.
https://blog.
mozilla.org/decoder/2012/01/27/
trying-new-code-analysis-
techniques/.
[32] Creating a Computer Security Incident Response Team: A Pro-
cess for Getting Started, February 2006. https://www.cert.
org/csirts/Creating-A-CSIRT.html.
[33] MATTHEW FINIFTER AND DEVDATTA AKHAWE AND
Chrome and Firefox VRP datasets,
https://gist.github.com/devd/
DAVID WAGNER.
June
a62f2afae9f1c93397f5.
2013.
[34] The MEGA Vulnerability Reward Program, February 2013.
https://mega.co.nz/#blog_6.
[35] MEIN, A., AND EVANS, C. Dosh4Vulns: Google’s Vulnerability
Reward Programs”, March 2011.
[36] MELVEN, I. MozillaWiki: Features/Security/Low rights Firefox,
August 2012. https://wiki.mozilla.org/Features/
Security/Low_rights_Firefox.
[37] MILLER, C. The legitimate vulnerability market: the secretive
world of 0-day exploit sales. In WEIS (2007).
[38] MILLS, E. Facebook launches bug bounty program, July 2011.
http://news.cnet.com/8301-27080 3-
20085163-245/facebook-launches-
bug-bounty-program/.
[39] MOZILLA BUGZILLA. Bug 790923: Content process sandboxing
via seccomp ﬁlter. https://bugzil.la/790923.
[40] MOZILLA FOUNDATION. Mozilla Foundation Security Ad-
https://www.mozilla.org/
visories, January 2013.
security/announce/.
16
288  22nd USENIX Security Symposium 
USENIX Association