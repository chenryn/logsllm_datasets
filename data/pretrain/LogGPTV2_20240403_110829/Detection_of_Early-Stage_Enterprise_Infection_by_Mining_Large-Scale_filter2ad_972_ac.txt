six features, the only one with low signiﬁcance was AutoHosts,
which is highly correlated with NoHosts and we decide to
omit it. The most relevant features found by the model are
DomAge and RareUA. DomAge is the only one negatively
correlated with reported domains (as they are in general more
recently registered than legitimate ones), but all other features
are positively correlated.
Based on the trained model, we select a threshold for
domain scores above which a domain is considered poten-
tial command-and-control. The graph in Figure 4 shows the
difference between the scores of automated domains reported
by VirusTotal and legitimate ones on the training set. For
instance, selecting a threshold of 0.4 for labeling an automated
domain suspicious results in 57.18% of reported domains being
correctly predicted on the training set (at the cost of 10% false
positive rate among legitimate domains). Similar results are
obtained on the testing set. Our ﬁnal goal is not identifying
all automated domains reported by VirusTotal, but rather most
suspicious ones to bootstrap the BP algorithm.
Thus we implement function Detect C&C from Algorithm
1 as returning 1 if the domain score is above the threshold
selected during training and 0 otherwise. We emphasize that
the selection of feature weights and threshold on domain score
is customized to each enterprise during the training stage.
D. Domain similarity
With the goal of capturing infection patterns from Figure 1,
we consider a number of features when computing similarity
of a domain D with a set of domains S labeled malicious in
previous iterations of BP.
Domain connectivity. We use the domain connectivity as
deﬁned above.
Timing correlations. Second, we consider features related to
the time when the domain D was visited by internal hosts.
During initial infection stage of a campaign, we suspect that a
host visits several domains under the attacker’s control within
a relatively short time period (as explained in Section II-A).
We thus consider the minimum timing difference between a
host visit to domain D and other malicious domains in set S.
The shorter this interval, the more suspicious D is.
5050
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:58:29 UTC from IEEE Xplore.  Restrictions apply. 
IP space proximity. Third, we consider proximity in IP space
between D and domains in set S. Proximity in the IP /24
and /16 subnets is denoted by IP24 and IP16 respectively. The
intuition here is that attackers host a large number of malicious
domains under a small number of IP subnets [19], [26].
We provide measurement of the timing and IP proximity
features on the LANL dataset in Section V-B.
Finally,
the domain similarity score is tailored to the
particular enterprise during the training stage. To obtain a list
of (non-automated) rare domains and their features, we start
from a set of compromised hosts (contacting C&C domains
conﬁrmed by VirusTotal). We include each rare domain con-
tacted by at least one host in this set, extract its features,
query VirusTotal to get an indication of its status (reported
or legitimate), and divide the data into training and testing set,
covering the ﬁrst and last two weeks of February, respectively.
We apply again linear regression on the training set to
determine feature weights and signiﬁcance. Among the eight
features described above, the only one with low signiﬁcance
was IP16, as it’s highly correlated with IP24. The most relevant
features identiﬁed by the model are RareUA, DomInterval, IP24
and DomAge. The threshold for domain score similarity is
selected based on the balance between true positive and false
positives (we omit the score PDF due to space limitations).
We implement function Compute SimScore from Algo-
rithm 1 as returning 1 if the domain similarity score is above
the chosen threshold and 0 otherwise.
E. Putting it all together
Our system for detecting early-stage enterprise infection
consists of two main phases: training (during a one-month
bootstrapping period) and operation (daily after the training
period). An overview diagram is presented in Figure 5.
Training. During the training period a benchmark of normal
activity for a particular enterprise is created. It consists of
several steps.
(1) Data normalization and reduction: The ﬁrst stage processes
the raw log data (either HTTP or DNS logs) used for training
and applies normalization and reduction techniques.
(2) Proﬁling: Starting from normalized data, the system pro-
ﬁles the activity of internal hosts. It builds histories of external
destinations visited by internal hosts as well as user-agent
(UA) strings used in HTTP requests (when available). These
histories are maintained and incrementally updated during the
operation stage when new data is available.
(3) Customizing the C&C detector: The detector of C&C
communication is customized to the particular enterprise.
(4) Customizing the domain similarity score: The domain sim-
ilarity score used during belief propagation is also customized
to the enterprise during the training phase.
Operation. After the initial training period, the system enters
into daily operation mode. Several stages are performed daily:
(1) Data normalization and reduction: The system performs
normalization and reduction for new log data.
Case
Description
From one hint host detect the
contacted malicious domains.
1
2
3
4
Dates
3/2, 3/3, 3/4,
3/9, 3/10
Hint Hosts
One per day
From a set of hint hosts detect
the contacted malicious domains.
3/5, 3/6, 3/7, 3/8,
3/11, 3/12, 3/13
Three or four
per day
From one hint host detect the
contacted malicious domains and
other compromised hosts.
3/14, 3/15, 3/17,
3/18, 3/19, 3/20,
3/21
Detect malicious domains and
compromised hosts without hint.
3/22
One per day
No hints
TABLE I: The four cases in LANL challenge problem.
(2) Proﬁle comparison and update: New data is compared with
historical proﬁles, and rare destinations, as well as rare UAs
(used by a small number of hosts) are identiﬁed. Histories are
updated with new data, to capture drift in normal behavior.
(3) C&C detector: The C&C detector is run daily, and scores
of automated domains are computed with weights determined
during training. Automated domains with scores above a
threshold are labeled as potential C&C domains.
(4) Belief propagation: The belief propagation algorithm is
run in either of two modes. The output is an ordered list of
suspicious domains presented to SOC for further investigation.
V. EVALUATION ON THE LANL DATASET
We start by describing the LANL challenge and then we
show how we adapted our techniques to the anonymized LANL
dataset. Still, using fewer features we demonstrate that our
belief propagation framework achieves excellent results on the
LANL challenge.
A. The LANL Challenge Problem
The LANL dataset includes attack traces from 20 indepen-
dent infection campaigns simulated by LANL domain experts.
Each simulation is an instance of the initial ﬁrst-day infection
stage of an independent campaign. LANL issued the APT
Infection Discovery Challenge to the community requesting
novel methods for the detection of malicious domains and
compromised hosts involved in these attacks [14]. Each of the
simulated attacks belongs to one of four cases in increasing
order of difﬁculty, described in Table I. Cases 1-3 include
“hints” about the identity of one or multiple compromised
hosts, while no hint is given in case 4. Answers (i.e., the
malicious domains) in each attack are provided for validation.
B. Parameter selection
When selecting various parameters for our algorithms, we
separate the 20 simulated attacks into two equal-size sets, and
use one for training, and the other for testing. We try to include
attacks from each case in both training and testing sets, with
the only exception of case 4, simulated only on one day. We
deliberately add this most challenging attack (in which no hint
is provided) to the testing set. We use the training set for
selecting parameters needed for different components of the
algorithm. We show that parameters chosen according to the
training set perform well on the testing set.
Thresholds for dynamic histograms. As described in Sec-
tion IV-C the dynamic histogram method can be conﬁgured
with two parameters: bin width (W ), and the threshold (JT )
5151
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:58:29 UTC from IEEE Xplore.  Restrictions apply. 
Training (one month) 
Normalization 
Reduction 
1 
HTTP/  
DNS  
Training
Data 
WHOIS 
Operation (daily) 
Normalization 
Reduction 
1 
New data 
     Host        
2 
      Profiling         
Histories 
Update 
   Profile    
2 
     comparison 
       C&C Communication 
3 
Model 
       Domain similarity 
4 
scoring 
Feature 
weights 
Feature 
weights 
   C&C     
3 
       Detector 
SOC 
seeds 
Belief       
4 
    propagation 
No-hint 
Suspicious 
domains 
SOC hints 
Suspicious 
domains 
Fig. 5: Overview of training and operation stages in our system for detecting enterprise infection. Training stage is on the left
and operation on the right. Input data is shown in red, processing steps in blue and various outputs in black.
 1
 0.8
 0.6
 0.4
 0.2
 0
s
r
i
a
p
n
i
a
m
o
d
f
o
n
o
i
t
c
a
r
F
Malicious and Malicious
Malicious and Legitimate
 0
 200
 400
 600
 800  1000  1200  1400  1600  1800  2000
Interval (Seconds)
Fig. 6: CDFs of time interval between connection to two
malicious domains and a malicious and legitimate domain by
same host.
the larger W and JT ,
denoting the maximum Jeffrey distance between the two
histograms. A connection with histogram at distance less than
JT from the periodic histogram is considered automated.
the more resilience the
Intuitively,
method provides against randomization and outliers, but more
legitimate connections are labeled automated. We choose W
at 10 seconds and JT at 0.06 in order to capture all malicious
pairs in the training set, while labeling fewest
legitimate
connections automated. Detailed results are included in the
full version [29].
Timing and IP Features. We measure the relevance of the
timing and IP similarity features among malicious domains.
For compromised hosts in the training set, we extract the
timestamp of their ﬁrst connection to every rare domain visited.
We plot in Figure 6 CDFs of the distributions of the time
difference between visits to malicious domains and a legitimate
and malicious domain by the same host. The graph conﬁrms
that connection intervals between two malicious domains are
much shorter than between a malicious and a legitimate
domain. For example, 56% of visits to two malicious domains
happen at intervals smaller than 160 seconds, while only 3.8%
of malicious-to-legitimate connection intervals are below this
threshold (similar results are observed on testing dataset).
Next we measure similarity in IP space for malicious
and legitimate domains in the training set. We found that 7
malicious domain pairs are in the same /24 subnet, while
18 share a /16 subnet. We observed few cases of legitimate
domains residing in the same subnet with malicious ones. With
the exception of 3/7, when more than 2000 pairs of malicious
and legitimate domains share the same /24 or /16 subnet (due
5252
to a single malicious domain belonging to a popular service),
the rest of days we observe 20 pairs in the same /24 subnet
and 155 pairs in the same /16 subnet.
Domain scoring. Since domain names in the LANL dataset
are anonymized and the data contains only DNS requests,
we have access to a smaller number of features than in the
AC web proxy dataset. We thus apply simple heuristics for
domain scoring. We label an automated domain as C&C if it
is contacted by at least 2 hosts at similar time periods (within
10 seconds). For computing domain similarity, we employ a
simple additive function of three features: domain connectivity,
timing correlation with a known malicious domain (value 1 if
the domain is contacted close in time to a malicious domain
and 0 otherwise), proximity in the IP space with malicious
domains (value 2 if same /24 subnet with a malicious domain,
1 if same /16 subnet with a malicious domain and 0 otherwise).
C. Results
The summary of our results on the four cases of the LANL
challenge are given in Table II. We use standard metrics from
machine learning literature: precision is the fraction of true
positives among all detected domains, false positive rate (FPR)
is the fraction of false positives among benign domains; and
false negative rate (FNR) is the fraction of malicious domains
labeled as legitimate by our detector. Overall, we achieve a
precision of 98.33% (97.06% on the testing set), with an FPR
of 3.72·10−5% over all 2.7M domains (5.76·10−5% over 1.7M
domains in the testing set) and an FNR of 6.35% (2.94% on
the testing set).
Interestingly, the BP algorithm trained on case 3 delivered
very good results on case 4, where we did not have an
opportunity for training (case 4 was simulated only on one
day). All the ﬁve domains identiﬁed by BP were conﬁrmed
malicious, and the algorithm did not have any false positives.
Case Malicious
domains
True Positives
Train
Test
False Positives
Train
Test
False Negatives
Train
Test
1
2
3
4
Total
12
22
24
5
63
6
8
12
-
26
4
12
12
5
33
0
0