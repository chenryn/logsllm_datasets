ior inside the domain. If there is any loss for the guar-
anteed trafﬁc class and if the loss ratios of other trafﬁc
classes exceed certain levels, an SLA violation is ﬂagged.
This loss can be caused by some ﬂows consuming band-
width beyond their SLA. Bandwidth theft is checked by
comparing the total bandwidth achieved by a user against
the user’s SLA for bandwidth. The misbehaving ﬂows are
controlled at the ingress routers.
To detect DoS attacks, set of links L with high loss are
identiﬁed. For each congested link, l(vi; vj) 2 L; the
tree is divided into two subtrees: one formed by leaves
descendant from vi and the other from the leaves descen-
dant from vj. The ﬁrst subtree has egress routers as leaves
through which high aggregate bandwidth ﬂows are leav-
ing. If many exiting ﬂows have the same destination IP
preﬁx, we can infer that either this is a DoS attack or the
trafﬁc is a going to a popular site [15]. Decision can be
taken with consulting the destination entity.
If it is an
attack, we can stop it by triggering ﬁlters at the ingress
routers that are leaves of the other subtree.
We illustrate a scenario of detecting and controlling
DoS attack using Figure 3. Suppose, the victim’s do-
main D is connected to the edge router E6. The mon-
itor observes that links C3 ! C4 and link C4 ! E6
are congested for a time duration (cid:1)t sec. From both
congested links, we obtain the egress router E6 through
which most of these ﬂows are leaving. The destination
IP preﬁx matching at E6 reveals that an excess amount
of trafﬁc is heading towards the domain D connected to
E6. To control the attack, the monitor needs to ﬁgure out
through which ingress routers the suspected ﬂows are en-
tering into the domain. The algorithm to identify these
ingress routers is discussed in [12]. The monitor activates
ﬁlters at these ingress routers to regulate the ﬂows that are
destined to D.
The advantage of the monitoring-based attack detection
is that the neighbor domains of the victim can detect the
attack early by observing the violation of SLA parameters.
By consulting with the potential victim, these domains can
Symbol Description
Psch
Csch
M
N
F
P
p
(cid:18)
h
s
fs
fd
(cid:11)1
(cid:11)2
(cid:11)3
Processing overhead for scheme sch
Communication overhead for scheme sch
Number of edge routers
Number of core routers
Number of ﬂows entering through each edge router
Number of packets per ﬂow
Probability to mark a packet
Percentage of misbehaving ﬂows
Path length inside a domain or hop count
Length of a stripe
Frequency of stripe per unit time in stripe-based monitoring
Frequency of probes per unit time in distributed monitoring
Processing overhead for ﬁltering
Processing overhead for marking
Processing overhead for monitoring
Values used in comparison
–
–
[10 – 20]
12
100,000
10
[0 – 0.20]
[0 – 20%]
4, 6
3
20
30
–
–
–
Table 1. Symbols used in the comparison and their values.
regulate the intensity of the attack and even an early detec-
tion can thwart the attack. For each violation, the monitor
takes actions such as throttling a particular user’s trafﬁc
using a ﬂow control mechanism.
4. Comparative Evaluation
In this section, we conduct a quantitative analysis of
the overhead imposed by different schemes to detect and
prevent DoS attacks. The objective of this compari-
son is to show the characteristics of each scheme and
how they behave when different conﬁguration parame-
ters of a domain are changed. We do not emphasize on
numeric overhead value of any speciﬁc scheme, rather,
we draw a relative comparison among them. The com-
parison provides guidelines for selecting the appropriate
scheme, or a combination of schemes, based on the re-
quirements and how much overhead can be tolerated. The
schemes we compare here are: Ingress Filtering (Ingf),
route-based packet ﬁltering (Route), traceback with prob-
abilistic packet marking (PPM), core-based network mon-
itoring (Core), stripe-based monitoring (Stripe), and dis-
tributed monitoring (Distributed).
4.1. Setup
For each scheme, we calculate two different overheads:
processing and communication. The processing overhead
is due to extra processing required at all routers of a do-
main per unit time. The communication overhead is due
to extra packets injected into a domain. The communica-
tion overhead is computed as the number of extra bytes
(not packets) injected per unit time. For processing over-
head, the extra processing at routers may contain: more
address lookups, changing some header ﬁelds, checksum
re-computation, and any CPU processing needed by the
scheme. For example, ﬁlters need to check the source
IP address to verify whether a packet is coming from a
valid source. This requires one extra address lookup (to
check the source IP address) for each packet. The mon-
itoring schemes inject probe packets into the network.
Each router inside a domain requires processing such as
address lookup, TTL ﬁeld decrement, checksum compu-
tation for each probe packet. For simplicity, we charge the
ﬁltering scheme (cid:11)1 processing units, the marking scheme
(cid:11)2 processing units, and the monitoring schemes (cid:11)3 pro-
cessing units for each packet processed. We express the
processing overhead in terms of (cid:11)1; (cid:11)2; and (cid:11)3 (process-
ing units), and the communication overhead in terms of
the total kilobytes (KB) injected in the domain.
We consider a domain D with M edge routers and N
core routers. We assume there are F ﬂows traversing
through each edge router and each ﬂow has P packets
on average. We deﬁne (cid:18) as the percentage of misbehav-
ing ﬂows that may cause DoS attacks. We denote Csch as
the communication overhead and Psch as the processing
overhead respectively for scheme sch. Table 1 lists the
variables used in the comparison and their values.
4.2. Overhead Calculation
Filtering and marking techniques do not incur any
communication overhead. The monitoring schemes have
both processing and communication overhead.
Ingress ﬁltering. The processing overhead of ingress
ﬁltering depends on the number of packets entering a
domain.
It requires one processing unit to check the
source IP address of every packet. For our domain D,
the total entering packets is M (cid:2) F (cid:2) P . Thus, the total
processing overhead of ingress ﬁltering is given by:
and the processing overhead is given by:
PIngf = M (cid:2) F (cid:2) P (cid:2) (cid:11)1:
(1)
Route-based ﬁltering. We need to deploy ingress ﬁlters
in every domain in the Internet to effectively stop all possi-
ble attacks. The route-based ﬁltering scheme, on the other
hand, does not require every single domain to have a ﬁlter.
Park et al. show that placing this ﬁlter at approximately
20% of all autonomous systems can prevent DoS to a great
extent [18]. For a domain that deploys a router-based ﬁl-
ter, the overhead is the same as the ingress ﬁlter. Globally
speaking, the overhead of route-based ﬁltering is one ﬁfth
of the overhead of ingress ﬁltering on the average. In our
comparison, we use
PCore = (2M + N ) (cid:2) max(1;
F (cid:2) (cid:18) (cid:2) d
packet size
) (cid:2) h (cid:2) (cid:11)3;
(5)
where packet size is a conﬁgurable parameter.
Stripe-based monitoring.
In the stripe-based moni-
toring scheme, a stripe of s packets is sent from the
monitor to every egress router pairs. For the network
domain D,
the total number of probing packets is
s (cid:2) (M (cid:0) 1) (cid:2) (M (cid:0) 2) (cid:2) fs; where fs is the frequency
by which we need to send stripes per unit time. The
communication overhead and the processing overhead are
shown in equation (6) and equation (7) respectively.
PRoute = 0:2 (cid:2) PIngf :
(2)
CStripe = s(cid:2)(M (cid:0)1)(cid:2)(M (cid:0)2)(cid:2)fs (cid:2)packet size; (6)
Probabilistic packet marking (PPM). PPM does not in-
cur any communication overhead but adds extra (cid:11)2 pro-
cessing units for every packet that gets marked at an inter-
mediary router. PPM might need sophisticated operation
such as taking hash of certain IP ﬁelds. The traceback with
PPM marks packets with a probability p at each router on
the path to the victim. If a packet passes through h hops,
on the average, in the network domain D, the processing
overhead is computed as:
PP P M = M (cid:2) F (cid:2) P (cid:2) p (cid:2) h (cid:2) (cid:11)2
(3)
Core-based monitoring. The monitoring schemes inject
probe trafﬁc into the network and add processing over-
heads as well. The total number of injected probes and the
size of each probe packet are used to calculate the commu-
nication overheads in terms of bytes. The Core scheme
depends on the number of packets that core routers send
to the monitor to report drop history. The drop history
at each core router depends on the ﬂows traversing the
network domain and the percentage of these ﬂows that
are violating their SLAs at a particular time. For the do-
main D, if d bytes are required to record the drop in-
formation of each ﬂow, then each core needs to send
packet size ) control packets to the monitor.
C = max(1;
The packet size is the size of a control packet, which de-
pends on the MTU of the network. To obtain loss ratio,
the monitor queries all edges for packet count informa-
tion of the misbehaving ﬂows. Every edge replies to this
query. The total number of packets exchanged among all
edge routers and the monitor is (2M + N ) (cid:2) C packets.
Therefore, the communication overhead is given by:
F (cid:2)(cid:18)(cid:2)d
CCore = (2M +N )(cid:2)max(1;
F (cid:2) (cid:18) (cid:2) d
packet size
)(cid:2)packet size;
(4)
PStripe = s (cid:2) (M (cid:0) 1) (cid:2) (M (cid:0) 2) (cid:2) fs (cid:2) h (cid:2) (cid:11)3: (7)
Distributed monitoring. For the distributed monitoring,
each edge router probes its left and right neighbors. If it
requires fd probes per unit time, the communication over-
head is:
CDistributed = 2 (cid:2) M (cid:2) fd (cid:2) packet size:
(8)
On the average, each probe packet traverses h hops and
thus the processing overhead can be calculated as:
PDistributed = 2 (cid:2) M (cid:2) fd (cid:2) h (cid:2) (cid:11)2
(9)
4.3. Results and Analysis
To visualize the differences among all schemes, we plot
the processing and communication overhead for one of the
domain shown in Figure 1. Usually, DoS attacks are di-
rected towards a particular host or a set of hosts connected
to a relatively small size domain. In the example, Figure
1, the DoS attack is directed towards domain D4 and the
attack trafﬁc is coming from various other domains. For
our comparison, we use the parameters’ values shown in
Table 1 for domain D. We use sec as unit time in all com-
parisons.
Figure 4 (a) shows the processing overhead in terms of
(cid:11)1 for ingress ﬁltering, route-based ﬁltering, and PPM
when packet marking probability is varied along the X-
axis. The route-based ﬁltering requires less processing
than marking scheme for p (cid:21) 0:07 because this ﬁltering
scheme does not need to be deployed at all routers of all
domains. Savage et al. use marking probability p = 0:04
d
a
e
h
r
e
v
O
g
n
s
s
e
c
o
r
P
i
108
107
106
105
104
0
108
107
106
d
a
e
h
r
e
v
O
g
n
s
s
e
c
o
r
P
i
Route
Ingf
PPM, h=4
PPM, h=6
0.05
0.1
Packet Marking Probability
0.15
0.2
105
10
12
Route
Ingf
PPM, h=4
PPM, h=6
18
20
14
16
Number of Edge Routers
(a) Effect of varying the marking probability on the processing
overhead.
(b) Effect of varying the number of edge routers on the process-
ing overhead.
Figure 4. The processing overhead per unit time for ﬁlters and probabilistic packet marking (PPM)
schemes. Marking scheme has less processing overhead than ﬁltering scheme if the marking proba-
bility is not too high (e.g., p (cid:20) 0:07).
d
a
e
h
r
e
v
O
g
n
s
s
e
c
o
r
P
i
105
104
103
102
0
Core
Stripe
Distributed
105
104
103
102
s
e
t
y
B
K
n
i
d
a
e
h
r
e
v
O
n
o
i
t
i
a
c