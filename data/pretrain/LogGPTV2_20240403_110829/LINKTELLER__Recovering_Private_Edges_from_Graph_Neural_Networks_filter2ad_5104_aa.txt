title:LINKTELLER: Recovering Private Edges from Graph Neural Networks
via Influence Analysis
author:Fan Wu and
Yunhui Long and
Ce Zhang and
Bo Li
2022 IEEE Symposium on Security and Privacy (SP)
LINKTELLER: Recovering Private Edges from
Graph Neural Networks via Inﬂuence Analysis
Fan Wu1
Yunhui Long1
Ce Zhang2
Bo Li1
1University of Illinois at Urbana-Champaign
2ETH Z¨urich
{fanw6,ylong4,lbo}@illinois.edu
PI:EMAIL
6
0
8
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
Abstract—Graph structured data have enabled several success-
ful applications such as recommendation systems and trafﬁc pre-
diction, given the rich node features and edges information. How-
ever, these high-dimensional features and high-order adjacency
information are usually heterogeneous and held by different
data holders in practice. Given such vertical data partition (e.g.,
one data holder will only own either the node features or edge
information), different data holders have to develop efﬁcient joint
training protocols rather than directly transferring data to each
other due to privacy concerns. In this paper, we focus on the edge
privacy, and consider a training scenario where the data holder
Bob with node features will ﬁrst send training node features to
Alice who owns the adjacency information. Alice will then train
a graph neural network (GNN) with the joint information and
provide an inference API to Bob. During inference time, Bob is
able to provide test node features and query the API to obtain
the predictions for test nodes. Under this setting, we ﬁrst propose
a privacy attack LINKTELLER via inﬂuence analysis to infer the
private edge information held by Alice via designing adversarial
queries for Bob. We then empirically show that LINKTELLER is
able to recover a signiﬁcant amount of private edges in different
settings, both including inductive (8 datasets) and transductive
(3 datasets), under different graph densities, signiﬁcantly outper-
forming existing baselines. To further evaluate the privacy leak-
age for edges, we adapt an existing algorithm for differentially
private graph convolutional network (DP GCN) training as well
as propose a new DP GCN mechanism LAPGRAPH based on
Laplacian mechanism to evaluate LINKTELLER. We show that
these DP GCN mechanisms are not always resilient against LINK-
TELLER empirically under mild privacy guarantees (ε > 5). Our
studies will shed light on future research towards designing more
resilient privacy-preserving GCN models; in the meantime, pro-
vide an in-depth understanding about the tradeoff between GCN
model utility and robustness against potential privacy attacks.
Index Terms—Graph Neural Networks, Edge Privacy Attack
I. INTRODUCTION
Graph neural networks (GNNs) have been widely applied
to different domains owing to their ability of modeling the
high-dimensional feature and high-order adjacency informa-
tion on both homogeneous and heterogeneous graph struc-
tured data [1]–[3]. The high-quality graph structured data have
enabled a range of successful applications, including trafﬁc
prediction [4], recommendation systems [5], and abnormal
access detection [6]. As these applications are becoming more
and more prevalent, privacy concerns in these applications are
non-negligible given the sensitive information in the graph
data. Thus, undesirable outcomes may arise due to lack of
understanding of the models and application scenarios.
Fig. 1: Vertically partitioned graph data for different data holders.
In this paper, we aim at understanding the edge privacy
in applications of GNN models. We focus on one speciﬁc
scenario as training/serving GNN models in a vertically parti-
tioned graph setting. As illustrated in Figure 1, in this setting,
node features and adjacency information (edges) are isolated
or hosted by different data holders. Our interest in this setting
is inspired not only by recent academic research (e.g., Zhou et
al. [3] proposed a privacy-preserving GNN (PPGNN) mecha-
nism via homomorphic encryption under this setting) but also a
real-world industrial example we see and the potential privacy
risks it incurs. In such an example, an international Internet
company hopes to train a single GNN model jointly using
data collected by two of its subdivisions (namely, data holder
Alice and Bob). Because these subdivisions focus on different
products, their data are heterogeneous in nature. Speciﬁcally,
in this example, Alice collects user interaction (social network)
data (i.e., adjacency information), and Bob collects user be-
havior data (i.e., node features). Noticing the potential beneﬁt
of integrating user interaction data into its predictive model,
Bob hopes to enrich the model using data collected by Alice.
Although they belong to the same company, directly copying
the user interaction data from Alice to Bob is not allowed due
to privacy concerns. Thus, Bob will ﬁrst send training data
containing node features and labels to Alice, and Alice will
train a GNN model jointly with her edge information. Then
Alice will release an inference API to Bob. During inference,
Bob would send a new set of test nodes with their features to
query the API and obtain corresponding predictions. Different
users can query the API to enjoy the service from Alice. For
instance, in practice there are several ML/AI service platforms
that provide similar interactions—taking the training data from
users to train an ML model and providing inference APIs for
users to make queries with their test data—such as Vertex
AI [7] from Google Cloud, ParlAI platform [8] from Face-
book, and InfoSphere Virtual Data Pipeline [9] from IBM.
During this type of interaction, the fundamental question
is to understand the risks of edge privacy (mainly for data
© 2022, Fan Wu. Under license to IEEE.
DOI 10.1109/SP46214.2022.00031
2005
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:20:38 UTC from IEEE Xplore.  Restrictions apply. 
1010AAAB6nicbVDLSgNBEOz1GeMr6lGRwSB4CruC6DHoxWOC5gFJCLOT3mTI7OwyMyuEJUePXjwo4tWPyHd48xv8CSePgyYWNBRV3XR3+bHg2rjul7O0vLK6tp7ZyG5ube/s5vb2qzpKFMMKi0Sk6j7VKLjEiuFGYD1WSENfYM3v34z92gMqzSN5bwYxtkLalTzgjBor3QVtr53LuwV3ArJIvBnJF49G5e/H41GpnftsdiKWhCgNE1TrhufGppVSZTgTOMw2E40xZX3axYalkoaoW+nk1CE5tUqHBJGyJQ2ZqL8nUhpqPQh92xlS09Pz3lj8z2skJrhqpVzGiUHJpouCRBATkfHfpMMVMiMGllCmuL2VsB5VlBmbTtaG4M2/vEiq5wXvouCWbRrXMEUGDuEEzsCDSyjCLZSgAgy68AQv8OoI59l5c96nrUvObOYA/sD5+AHehpE5f11011AAAB6nicbVDLSgNBEOyNrxhfUY+KDAbBU9gNiB6DXjwmaB6QLGF2MpsMmZldZmaFsOTo0YsHRbz6EfkOb36DP+HkcdDEgoaiqpvuriDmTBvX/XIyK6tr6xvZzdzW9s7uXn7/oK6jRBFaIxGPVDPAmnImac0ww2kzVhSLgNNGMLiZ+I0HqjSL5L0ZxtQXuCdZyAg2VroLO6VOvuAW3SnQMvHmpFA+Hle/H0/GlU7+s92NSCKoNIRjrVueGxs/xcowwuko1040jTEZ4B5tWSqxoNpPp6eO0JlVuiiMlC1p0FT9PZFiofVQBLZTYNPXi95E/M9rJSa88lMm48RQSWaLwoQjE6HJ36jLFCWGDy3BRDF7KyJ9rDAxNp2cDcFbfHmZ1EtF76LoVm0a1zBDFo7gFM7Bg0sowy1UoAYEevAEL/DqcOfZeXPeZ60ZZz5zCH/gfPwA4AqROg==f20111AAAB6nicbVDLSgNBEOyNrxhfUY+KDAbBU9hVRI9BLx4TNA9IljA7mU2GzMwuM7NCWHL06MWDIl79iHyHN7/Bn3DyOGhiQUNR1U13VxBzpo3rfjmZpeWV1bXsem5jc2t7J7+7V9NRogitkohHqhFgTTmTtGqY4bQRK4pFwGk96N+M/foDVZpF8t4MYuoL3JUsZAQbK92F7fN2vuAW3QnQIvFmpFA6HFW+H49G5Xb+s9WJSCKoNIRjrZueGxs/xcowwukw10o0jTHp4y5tWiqxoNpPJ6cO0YlVOiiMlC1p0ET9PZFiofVABLZTYNPT895Y/M9rJia88lMm48RQSaaLwoQjE6Hx36jDFCWGDyzBRDF7KyI9rDAxNp2cDcGbf3mR1M6K3kXRrdg0rmGKLBzAMZyCB5dQglsoQxUIdOEJXuDV4c6z8+a8T1szzmxmH/7A+fgB4Y6ROw==f3AAAB6nicbVDLSgNBEOyNrxhfUY+KDAbBU9gVRY9BLx4TNA9IljA7mU2GzMwuM7NCWHL06MWDIl79iHyHN7/Bn3DyOGhiQUNR1U13VxBzpo3rfjmZpeWV1bXsem5jc2t7J7+7V9NRogitkohHqhFgTTmTtGqY4bQRK4pFwGk96N+M/foDVZpF8t4MYuoL3JUsZAQbK92F7fN2vuAW3QnQIvFmpFA6HFW+H49G5Xb+s9WJSCKoNIRjrZueGxs/xcowwukw10o0jTHp4y5tWiqxoNpPJ6cO0YlVOiiMlC1p0ET9PZFiofVABLZTYNPT895Y/M9rJia88lMm48RQSaaLwoQjE6Hx36jDFCWGDyzBRDF7KyI9rDAxNp2cDcGbf3mR1M6K3kXRrdg0rmGKLBzAMZyCB5dQglsoQxUIdOEJXuDV4c6z8+a8T1szzmxmH/7A+fgB4xKRPA==f4AAAB6nicbVDLSgNBEOyNrxhfUY+KDAbBU9gVgh6DXjwmaB6QLGF2MpsMmZldZmaFsOTo0YsHRbz6EfkOb36DP+HkcdDEgoaiqpvuriDmTBvX/XIyK6tr6xvZzdzW9s7uXn7/oK6jRBFaIxGPVDPAmnImac0ww2kzVhSLgNNGMLiZ+I0HqjSL5L0ZxtQXuCdZyAg2VroLO6VOvuAW3SnQMvHmpFA+Hle/H0/GlU7+s92NSCKoNIRjrVueGxs/xcowwuko1040jTEZ4B5tWSqxoNpPp6eO0JlVuiiMlC1p0FT9PZFiofVQBLZTYNPXi95E/M9rJSa88lMm48RQSWaLwoQjE6HJ36jLFCWGDy3BRDF7KyJ9rDAxNp2cDcFbfHmZ1C+KXqnoVm0a1zBDFo7gFM7Bg0sowy1UoAYEevAEL/DqcOfZeXPeZ60ZZz5zCH/gfPwA5JaRPQ==f501101000AAAB6nicbVC7SgNBFL0bXzG+ooKNzWAQrMKuELQMsbFM0DwgWcLsZDYZMjuzzMwGwpJPsLFQxNbWv/AL7Gz8FiePQhMPXDiccy/33hPEnGnjul9OZm19Y3Mru53b2d3bP8gfHjW0TBShdSK5VK0Aa8qZoHXDDKetWFEcBZw2g+HN1G+OqNJMinszjqkf4b5gISPYWOlu1C118wW36M6AVom3IIXySe2bvVc+qt38Z6cnSRJRYQjHWrc9NzZ+ipVhhNNJrpNoGmMyxH3atlTgiGo/nZ06QedW6aFQKlvCoJn6eyLFkdbjKLCdETYDvexNxf+8dmLCaz9lIk4MFWS+KEw4MhJN/0Y9pigxfGwJJorZWxEZYIWJsenkbAje8surpHFZ9EpFt2bTqMAcWTiFM7gAD66gDLdQhToQ6MMDPMGzw51H58V5nbdmnMXMMfyB8/YD7p+RQw==v5AAAB6nicbVC7SgNBFL0TXzG+ooKNzWAQrMKuIlqG2FgmaB6QLGF2MpsMmZ1dZmYDYckn2FgoYmvrX/gFdjZ+i5NHoYkHLhzOuZd77/FjwbVxnC+UWVldW9/Ibua2tnd29/L7B3UdJYqyGo1EpJo+0UxwyWqGG8GasWIk9AVr+IObid8YMqV5JO/NKGZeSHqSB5wSY6W7Yeeiky84RWcKvEzcOSmUjqrf/L38UenkP9vdiCYhk4YKonXLdWLjpUQZTgUb59qJZjGhA9JjLUslCZn20umpY3xqlS4OImVLGjxVf0+kJNR6FPq2MySmrxe9ifif10pMcO2lXMaJYZLOFgWJwCbCk79xlytGjRhZQqji9lZM+0QRamw6ORuCu/jyMqmfF93LolO1aZRhhiwcwwmcgQtXUIJbqEANKPTgAZ7gGQn0iF7Q66w1g+Yzh/AH6O0H65eRQQ==v3AAAB6nicbVC7SgNBFL0bXzG+ooKNzWAQrMJuQLQMsbFM0DwgWcLsZDYZMjuzzMwGwpJPsLFQxNbWv/AL7Gz8FiePQhMPXDiccy/33hPEnGnjul9OZm19Y3Mru53b2d3bP8gfHjW0TBShdSK5VK0Aa8qZoHXDDKetWFEcBZw2g+HN1G+OqNJMinszjqkf4b5gISPYWOlu1C118wW36M6AVom3IIXySe2bvVc+qt38Z6cnSRJRYQjHWrc9NzZ+ipVhhNNJrpNoGmMyxH3atlTgiGo/nZ06QedW6aFQKlvCoJn6eyLFkdbjKLCdETYDvexNxf+8dmLCaz9lIk4MFWS+KEw4MhJN/0Y9pigxfGwJJorZWxEZYIWJsenkbAje8surpFEqepdFt2bTqMAcWTiFM7gAD66gDLdQhToQ6MMDPMGzw51H58V5nbdmnMXMMfyB8/YD6hORQA==v2AAAB6nicbVDLSgNBEOz1GeMrKnjxMhgET2FXED2GePGYoHlAEsLspDcZMju7zMwGwpJP8OJBEa9e/Qu/wJsXv8XJ46CJBQ1FVTfdXX4suDau++WsrK6tb2xmtrLbO7t7+7mDw5qOEsWwyiIRqYZPNQousWq4EdiIFdLQF1j3BzcTvz5EpXkk780oxnZIe5IHnFFjpbthx+vk8m7BnYIsE29O8sXjyjd/L32UO7nPVjdiSYjSMEG1bnpubNopVYYzgeNsK9EYUzagPWxaKmmIup1OTx2TM6t0SRApW9KQqfp7IqWh1qPQt50hNX296E3E/7xmYoLrdsplnBiUbLYoSAQxEZn8TbpcITNiZAllittbCetTRZmx6WRtCN7iy8ukdlHwLgtuxaZRghkycAKncA4eXEERbqEMVWDQgwd4gmdHOI/Oi/M6a11x5jNH8AfO2w/oj5E/v1AAAB6nicbVC7SgNBFL0TXzG+ooKNzWAQrMKuKFqG2FgmaB6QLGF2MpsMmZ1dZmYDYckn2FgoYmvrX/gFdjZ+i5NHoYkHLhzOuZd77/FjwbVxnC+UWVldW9/Ibua2tnd29/L7B3UdJYqyGo1EpJo+0UxwyWqGG8GasWIk9AVr+IObid8YMqV5JO/NKGZeSHqSB5wSY6W7Yeeiky84RWcKvEzcOSmUjqrf/L38UenkP9vdiCYhk4YKonXLdWLjpUQZTgUb59qJZjGhA9JjLUslCZn20umpY3xqlS4OImVLGjxVf0+kJNR6FPq2MySmrxe9ifif10pMcO2lXMaJYZLOFgWJwCbCk79xlytGjRhZQqji9lZM+0QRamw6ORuCu/jyMqmfF93LolO1aZRhhiwcwwmcgQtXUIJbqEANKPTgAZ7gGQn0iF7Q66w1g+Yzh/AH6O0H7RuRQg==v4AAAB6nicbVC7SgNBFL0bXzG+ooKNzWAQrMKuELQMsbFM0DwgWcLsZDYZMjuzzMwGwpJPsLFQxNbWv/AL7Gz8FiePQhMPXDiccy/33hPEnGnjul9OZm19Y3Mru53b2d3bP8gfHjW0TBShdSK5VK0Aa8qZoHXDDKetWFEcBZw2g+HN1G+OqNJMinszjqkf4b5gISPYWOlu1C118wW36M6AVom3IIXySe2bvVc+qt38Z6cnSRJRYQjHWrc9NzZ+ipVhhNNJrpNoGmMyxH3atlTgiGo/nZ06QedW6aFQKlvCoJn6eyLFkdbjKLCdETYDvexNxf+8dmLCaz9lIk4MFWS+KEw4MhJN/0Y9pigxfGwJJorZWxEZYIWJsenkbAje8surpHFZ9EpFt2bTqMAcWTiFM7gAD66gDLdQhToQ6MMDPMGzw51H58V5nbdmnMXMMfyB8/YD7p+RQw==v5AAAB6nicbVC7SgNBFL0TXzG+ooKNzWAQrMKuIlqG2FgmaB6QLGF2MpsMmZ1dZmYDYckn2FgoYmvrX/gFdjZ+i5NHoYkHLhzOuZd77/FjwbVxnC+UWVldW9/Ibua2tnd29/L7B3UdJYqyGo1EpJo+0UxwyWqGG8GasWIk9AVr+IObid8YMqV5JO/NKGZeSHqSB5wSY6W7Yeeiky84RWcKvEzcOSmUjqrf/L38UenkP9vdiCYhk4YKonXLdWLjpUQZTgUb59qJZjGhA9JjLUslCZn20umpY3xqlS4OImVLGjxVf0+kJNR6FPq2MySmrxe9ifif10pMcO2lXMaJYZLOFgWJwCbCk79xlytGjRhZQqji9lZM+0QRamw6ORuCu/jyMqmfF93LolO1aZRhhiwcwwmcgQtXUIJbqEANKPTgAZ7gGQn0iF7Q66w1g+Yzh/AH6O0H65eRQQ==v3AAAB6nicbVC7SgNBFL0bXzG+ooKNzWAQrMJuQLQMsbFM0DwgWcLsZDYZMjuzzMwGwpJPsLFQxNbWv/AL7Gz8FiePQhMPXDiccy/33hPEnGnjul9OZm19Y3Mru53b2d3bP8gfHjW0TBShdSK5VK0Aa8qZoHXDDKetWFEcBZw2g+HN1G+OqNJMinszjqkf4b5gISPYWOlu1C118wW36M6AVom3IIXySe2bvVc+qt38Z6cnSRJRYQjHWrc9NzZ+ipVhhNNJrpNoGmMyxH3atlTgiGo/nZ06QedW6aFQKlvCoJn6eyLFkdbjKLCdETYDvexNxf+8dmLCaz9lIk4MFWS+KEw4MhJN/0Y9pigxfGwJJorZWxEZYIWJsenkbAje8surpFEqepdFt2bTqMAcWTiFM7gAD66gDLdQhToQ6MMDPMGzw51H58V5nbdmnMXMMfyB8/YD6hORQA==v2AAAB6nicbVDLSgNBEOz1GeMrKnjxMhgET2FXED2GePGYoHlAEsLspDcZMju7zMwGwpJP8OJBEa9e/Qu/wJsXv8XJ46CJBQ1FVTfdXX4suDau++WsrK6tb2xmtrLbO7t7+7mDw5qOEsWwyiIRqYZPNQousWq4EdiIFdLQF1j3BzcTvz5EpXkk780oxnZIe5IHnFFjpbthx+vk8m7BnYIsE29O8sXjyjd/L32UO7nPVjdiSYjSMEG1bnpubNopVYYzgeNsK9EYUzagPWxaKmmIup1OTx2TM6t0SRApW9KQqfp7IqWh1qPQt50hNX296E3E/7xmYoLrdsplnBiUbLYoSAQxEZn8TbpcITNiZAllittbCetTRZmx6WRtCN7iy8ukdlHwLgtuxaZRghkycAKncA4eXEERbqEMVWDQgwd4gmdHOI/Oi/M6a11x5jNH8AfO2w/oj5E/v1AAAB6nicbVC7SgNBFL0TXzG+ooKNzWAQrMKuKFqG2FgmaB6QLGF2MpsMmZ1dZmYDYckn2FgoYmvrX/gFdjZ+i5NHoYkHLhzOuZd77/FjwbVxnC+UWVldW9/Ibua2tnd29/L7B3UdJYqyGo1EpJo+0UxwyWqGG8GasWIk9AVr+IObid8YMqV5JO/NKGZeSHqSB5wSY6W7Yeeiky84RWcKvEzcOSmUjqrf/L38UenkP9vdiCYhk4YKonXLdWLjpUQZTgUb59qJZjGhA9JjLUslCZn20umpY3xqlS4OImVLGjxVf0+kJNR6FPq2MySmrxe9ifif10pMcO2lXMaJYZLOFgWJwCbCk79xlytGjRhZQqji9lZM+0QRamw6ORuCu/jyMqmfF93LolO1aZRhhiwcwwmcgQtXUIJbqEANKPTgAZ7gGQn0iF7Q66w1g+Yzh/AH6O0H7RuRQg==v4Data Holder AliceData Holder Bobqueriespredictionsholder Alice) for training and releasing a GNN inference API
on graph data, as well as possible ways to amortise such risks.
Challenges and Problem Formulation. The main motiva-
tion and challenge of the problem attributes to the hetero-
geneity of data—one data holder owns the features of users
(i.e., node features), while the other holds the “connections”
or “interactions” among users (i.e., adjacency information) as
shown in Figure 1. Inspired by this real-world example, we
abstract it into the following technical problem. Let there be n
users and A ∈ {0, 1}n×n be the adjacency information. Data
holder Alice has full access to adjacency information A while
it is kept secret from the data holder Bob. Bob interacts with
Alice during both training and inference stages.
1) Training: During training, Bob (or some other users) col-
lects (training) node features and labels for a subset of
users, forming a feature matrix X with label vector y, and
sends them to Alice. Alice then trains a GNN model using
all the node features from Bob and her collected adjacency
information A, and releases an inference API to Bob.
2) Inference: During inference, Bob collects features for an-
other (test) subset of users X(cid:48), and sends them to Alice via
the inference API, who will run inference using the trained
GNN model, and return corresponding predictions.
Given this interaction model, we aim to ask: Whether the
inference API will leak private information of the adjacency
information to a potentially malicious user Bob indirectly?
How can we better protect the adjacency information from
privacy leakage while preserving high model utility?
Apart from this speciﬁc case, there have been similar con-
cerns from different real-world cases. For instance, the adver-
tisement department of Facebook would usually hold certain
public features of individuals (i.e., node features), and needs
to query the predictions from another department that holds
the social network connection information which is private.
Thus, how to protect the edge privacy in this setting is critical.
However, directly conducting such privacy attacks is challeng-
ing. For instance, given a large graph, naively comparing the
similarities between nodes to infer their connections is clearly
not enough. On the other hand, it is known that the trained
GNN is based on the node inﬂuence propagation [10]: If two
nodes are connected, there is a high chance that changing the
features of one would affect the prediction of the other. Thus,
we hope to address the research question: Is it possible to
design an effective edge re-identiﬁcation attack against GNNs
based on the node inﬂuence information?
Different from existing work [11] which collects node pairs
with and without connections to train a model to infer the exis-
tence of an edge, in this paper, we aim to analyze and leverage
the node inﬂuence to predict potential edge connections. In
particular, we ﬁrst propose an attack strategy LINKTELLER
under such a vertically data partitioned setting based on the
node inﬂuence analysis, and explore how much the private
adjacency information could be revealed from Alice via an-
swering queries from Bob. Then we will evaluate the proposed
LINKTELLER attack against both an existing and a proposed
differentially private graph convolutional network (DP GCN)
mechanisms to analyze whether the LINKTELLER could fur-
ther attack the privacy preserving GCN models. In addition,
we explore what is the safe privacy budget to choose in order
to protect the trained GCN models from being attacked by
privacy attacks such as LINKTELLER on different datasets via
extensive empirical evaluation.
Technical Contributions.
In this paper, we focus on under-
standing the edge privacy risk and the strength of the privacy
protection mechanisms (e.g., DP) for vertically partitioned
graph learning. Speciﬁcally, we make following contributions.
1) We propose the ﬁrst query based edge re-identiﬁcation
attack LINKTELLER against GNN models by considering
the inﬂuence propagation in GNN training. We show that
it is possible to re-identify private edges effectively in a
vertically partitioned graph learning setting.