title:Harvesting verifiable challenges from oblivious online sources
author:J. Alex Halderman and
Brent Waters
Harvesting Veriﬁable Challenges from
Oblivious Online Sources
J. Alex Halderman
Princeton University
PI:EMAIL
∗
Brent Waters
SRI International
PI:EMAIL
ABSTRACT
Several important security protocols require parties to per-
form computations based on random challenges. Tradition-
ally, proving that the challenges were randomly chosen has
required interactive communication among the parties or the
existence of a trusted server. We oﬀer an alternative solu-
tion where challenges are harvested from oblivious servers
on the Internet. This paper describes a framework for de-
riving “harvested challenges” by mixing data from various
pre-existing online sources. While individual sources may
become predictable or fall under adversarial control, we pro-
vide a policy language that allows application developers
to specify combinations of sources that meet their security
needs. Participants can then convince each other that their
challenges were formed freshly and in accordance with the
policy. We present Combine, an open source implementa-
tion of our framework, and show how it can be applied to
a variety of applications, including remote storage auditing
and non-interactive client puzzles.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—
Security and protection (e.g., ﬁrewalls); E.3 [Data]: Data
Encryption
General Terms
Design, Security
1.
INTRODUCTION
In many distributed systems we want to verify claims
made by remote parties. For example, in remote storage
applications such as SafeStore [14], a client will pay remote
∗This work was supported by the Department of Home-
land Security Contract No. HSHQDC-07-C-00006, the U.S.
Army Research Oﬃce Grant No. W911NF-06-1-0316, NSF
CNS-0524252 and the US Army Research Oﬃce under the
CyberTA Grant No. W911NF-06-1-0316.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010...$5.00.
servers to maintain a backup storage of his data. Such a
client will want to check that servers that collect storage
fees are actually using their resources to store his data. Else-
where, in a peer-to-peer (P2P) systems, it is typically desir-
able that a malicious machine not be able to create several
virtual identities and launch a Sybil attack. Thus, clients
will want to verify that no machine owns several nodes.
Verifying such claims with certainty is often extremely
costly or even impossible. For instance, if a remote server
stores 100GB of data for a client, it is prohibitively expensive
for the server to send all the stored data over the network
each time the client wishes to audit the server. Fortunately,
in practice it is often suﬃcient for a user to perform a prob-
abilistic check of system claims.
In a storage system one
could query the server to send a randomly selected k blocks
of data. A cheating server that only stored half of a client’s
data would have a vanishingly small (2−k) probability of
avoiding detection.1 Similarly, a proof of work or client puz-
zle [10, 2, 12] used in a P2P system can be thought of a
probabilistic “proof” that a certain amount of computational
eﬀort was spent by a machine solving the puzzle.
At the heart of these probabilistic checks is the idea that
a random challenge is given to the party making a claim.
The party will then need to create a response to this chal-
lenge such a returning a set of data or solving a client puzzle.
In distributed systems we will usually want two properties
from such a challenge/response mechanism. First, we want
the challenge to be fresh such that the responder could not
have predicted the response long in advance. Otherwise, a
cheating server might only store the challenge blocks of data
or a machine might pre-compute the solution to a client puz-
zle. Second, it is desirable that one response can be veriﬁed
by several receivers. That is, the responder should not need
to interact with and respond to each veriﬁer independently.
This property is important, for example, if several users in
a P2P system want to verify a client puzzle, but we do not
want to burden the puzzle solver with performing a separate
computation for each of them. In addition, we would like
to support systems where there isn’t two way interaction
between the veriﬁer and responder, or where the identity of
the veriﬁers isn’t known in advance.
When prior, interactive communication with the veriﬁer is
not possible, the most straightforward solution is to deploy
a set of trusted servers dedicated to generating challenges,
but this approach has disadvantages of its own. Maintaining
a secure dedicated server can be expensive, especially when
1Using redundant encoding, a user can expect that all of his
data will be recoverable if such tests are met.
330the number of participants in a system becomes large. While
it would be convenient to rely on volunteer or peer-to-peer
servers, it may be diﬃcult to verify their legitimacy. An-
other risk is that dedicated random challenge servers might
become targets of denial-of-service attacks. They may also
be subjected to legal takedown measures if some of the sys-
tem’s users engage in illicit or politically sensitive activities.
Our Approach.
Rather than relying on dedicated trusted servers, we pro-
pose deriving what we call “harvested challenges” by mixing
content from a variety of pre-existing online data sources,
which can range from large news and stock quote providers
to personal blogs. Using pre-existing data sources has sev-
eral beneﬁts. No new servers need to be deployed to provide
challenges. The data providers that are harvested likely have
infrastructure to handle large volumes of content requests,
and since the primary purpose of their servers is unrelated
to challenge generation, their removal for legal or political
reasons would be much less likely.
While using existing content providers has advantages, our
approach also presents a unique set of challenges. One prob-
lem is that we need a consistent method for deriving chal-
lenges from widely dissimilar types of content, none of which
are tailored to our application. Another issue is that web-
sites often modify or remove content after a period of time
(for instance, many newspaper sites remove old stories). Fi-
nally, our scheme needs to be resilient against an attacker
who can inject his own input as part of the challenge; for
example, the adversary might post his own entry to a blog
or alter the data on a compromised website.
Our solution to these problems is a general framework
for deriving harvested challenges from Internet sources and
an implementation of this framework called Combine (pro-
nounced like the name of the harvesting machine, with the
accent on the ﬁrst syllable). Our system lets application
developers decide how data from many sources should be
combined to form challenges with an adequate level of trust
for a particular use. Veriﬁers can later test that a challenge
was properly derived in accordance with the application’s
policy by checking a subset of the original sources.
For example, an application’s policy might require that
challenges be generated by hashing together fresh content
from six particular sites, and that veriﬁers must be able
to conﬁrm that the content of at least four of the sites was
included in the challenge. This means the challenge will con-
tinue to be acceptable if any two of the sites modify their
content or become unavailable. An attacker would need to
compromise or predict four of the sources in order to pre-
compute puzzle solutions based on this challenge.
Our framework is ﬂexible in the types of sources that are
harvested. For instance, certain client puzzle applications
need to guarantee that challenges are derived from fresh
content, a task for which many popular RSS feeds are well
suited. On the other hand, cryptographic signature applica-
tions might be able to cope with less precise freshness but
require that content be available for veriﬁcation long after
challenges are constructed. Policies might incorporate his-
torical stock market data for this purpose.
Which combinations of sites to trust, how to balance be-
tween security and robustness, and the proper levels of fresh-
ness and long term stability are decisions that individual
application developers will make to suit their particular re-
quirements. Our framework allows systems that answer
these questions in many diﬀerent ways to create suitable
challenges using a single tool, such as Combine.
Outline.
We begin in Section 2 by presenting an overview of our
model and arguing about its security. In Section 3 we discuss
how our approach can be applied to diﬀerent security appli-
cations. Section 4 describes our harvested challenge frame-
work, including our language for specifying data sources and
policies. In Section 5 we introduce Combine, our implemen-
tation of the framework, and describe an email client puzzle
application that we created to demonstrate its capabilities.
Section 6 presents a study of RSS feeds that we conducted
to evaluate the feasibility of our approach. We review sev-
eral areas of related work in Section 7. Finally, we conclude
and present ideas for future directions in Section 8.
2. HARVESTING CHALLENGES
In our setting there are two parties, which we will call the
deriver and the veriﬁer (see Figure 1). Our system attempts
to achieve correctness and security properties with respect
to these parties:
Correctness A properly behaving deriver is able to con-
vince a veriﬁer that the harvested challenge he presents
was well formed in accordance with the application’s
policy. The system should be robust to some of the
Internet sources becoming unavailable or removing or
modifying their content.
Security Intuitively, for our system to be secure, we must
prevent a corrupt deriver from being able to choose the
derived challenge himself without the veriﬁer detecting
this. In addition, a deriver should not be able to lever-
age any precomputation he performed long before the
challenge was derived.
We assume that the deriver and veriﬁer both have access
to Internet servers that will be used as sources of randomness.
These sources may be unreliable, and fresh data might ap-
pear on them at irregular intervals. The deriver and veriﬁer
share a policy describing how challenges will be harvested
and veriﬁed. In general, the policy will be chosen by the ap-
plication developer and delivered along with the application.
We assume that policies are known to potential attackers.
To construct a harvested challenge, the deriver ﬁrst con-
tacts n Internet sources speciﬁed by the policy and download
some content from each. He then hashes each piece of con-
tent with a hash function H to produce outputs h1, . . . , hn.
Next, the deriver hashes the concatenation of all of these
hashes to produce the harvested challenge u. The values
h1, . . . , hn form a derivation for the challenge, which is com-
municated to the veriﬁer.
Upon receiving the challenge and derivation, the veriﬁer
retrieves the content from the sources and veriﬁes that their
hashes match at least k of those given in the derivation,
where k is a parameter that is given as part of the policy.
Essentially, the veriﬁer requires at least k of the sources to
match the derivation and is willing to tolerate an error in the
deriver’s claim for the rest. By only requiring that a certain
threshold of the sources match, the system is robust to the
unavailability of some sources or the modiﬁcation between
derivation and veriﬁcation of the content that they hold.
details for how such a storage system might be built using
our scheme.
In a remote storage system a server will store data for
a set of clients. The clients will want to periodically audit
the server to verify that it continues to store their data. To
respond3 to an audit requirement, the server will derive a
harvested challenge that speciﬁes a random set of k blocks
of data each of size b. The server responds by creating a
message consisting of those k blocks along with the deriva-
tion sketch from our system.
If a verifying client locally
has a copy of the data that is backed up by the server the
client can simply verify the derivation sketch and check the
response blocks against his storage. In the case where the
client does not maintain an independent copy of the data,
we can apply a signature scheme to ensure integrity. When
the data is originally created each block of data (along with
its block number) will be signed by the data creator. The
responses can then be modiﬁed to include the signatures on
the challenge blocks.
If signatures are of size s, then the
extra storage overhead is s/b and the communication of a
response is k(s+b); this shows a trade oﬀ in storage eﬃciency
and response eﬃciency in terms of the block size b.
Suppose that a storage server maintains a fraction x of
the blocks data where x < 1. Then if the challenge set
is of size k the server will have at most xk chance of being
able to respond to a particular challenge. For any signiﬁcant
data loss, the server’s ability to respond correctly will decay
exponentially in k. Data can be redundantly encoded such
that only a fraction of the stored data needs to be recovered
in order for the original data to be reconstructed.
If we
encoded the data such that half the stored data was required
for reconstruction, then the system will detect unrecoverable
loss of the original data with probability 1 − (1/2)k.
One way a server might try to cheat is to derive multiple
random challenges until it ﬁnds one that it can satisfy. Sup-
pose that the server derived r challenges, then by the union
bound his probability of success is at most r · xk.
In the
random oracle model we can bound r by the number of calls
made to the random oracle.
There are several other applications of using harvested
challenges for auditing systems. For example, if a system
was required to perform several database operations, a har-
vested challenge might be used to require that the transac-
tion receipt be given for a certain set of them. One intriguing
idea is to use harvested challenges in physical systems such
as voting systems. For instance, we might use a harvested
challenge to specify a certain group of precincts to perform
a manual hand recount. Of course voting is an application
of several subtleties and further analysis is required to de-
termine the suitability of an approach like this.
Mitigating Sybil Attacks in P2P Networks.
Some of the most troublesome attacks to mitigate on peer-
to-peer (P2P) networks are so-called Sybil attacks [9]. The
survival of a P2P system often depends upon correct behav-
ior of a majority of the participating nodes. In a Sybil at-
tack, one machine will try to disrupt the system by claiming
a large number of virtual identities. It will often be diﬃcult
to prevent this type of attack where there is no authoritative
registration of users.
3A response might be to an implicit request. For example,
the server might be required to periodically broadcast a stor-
age proof.
Figure 1: Our model involves an interaction between
two parties, the deriver (blue/dotted lines) and the ver-
iﬁer (orange/dashed lines).
Intuitively, a larger k value will give a greater degree of
security at the cost of making the system’s correctness less
robust to missing content. By selecting the kinds of sources
and the values of n and k, application developers can create
policies that strike a balance between the correctness and
security requirements. Our framework also allows the con-
struction of more complex policies, as described in Section 4.
Of course, unless the veriﬁer can check that all of the con-
tent included in the derivation matches the content provided
by the sources, a dishonest deriver will be able to replace
some parts of the derivation with arbitrary values he selects.
This turns out not to be problem for the applications we con-
sider as long as the derivation still contains suﬃcient fresh
entropy, since the harvested challenge is taken from the hash
of the derivation.
For our purposes we will model H as an ideal hash func-
tion in the random oracle model [4]. Let x be the the number
of sources that were both checked by the veriﬁer and uncor-
rupted by a deriver. In addition, let t be the earliest time at
which any of the content used from any of these sources was
created and s be the amount of entropy from these x sources.
Then if a corrupt deriver wishes to create a challenge u, he
must create it by calling a random function that has as part
of its input s bits of entropy out of his control. Therefore, if
s is suﬃciently large, say 80 bits2, then the attacker needs
to derive u by calling the ideal hash function. No amount
of pre-computation before time t will help due to the fresh
s bits of entropy.
3. APPLICATIONS
In this section we describe three application areas that can