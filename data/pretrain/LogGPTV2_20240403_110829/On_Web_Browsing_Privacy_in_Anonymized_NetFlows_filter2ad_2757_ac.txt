width of these distributions is calculated as described
previously, except that for the ﬂow size and cumulative
size dimensions, we take the average standard deviation
across all index values as the bandwidth. Furthermore,
we bound the bandwidth in each dimension such that it
is always
variability.
≥ 1 to allow for some minimum amount of
To evaluate an anonymized physical server session on
a particular KDE model, we simply evaluate each point
in the path for that physical server session using Eqn. 1,
and calculate the total probability of the given physical
server session, t, as:
m−1(cid:2)
j=0
P (t) =
P (tj)
(2)
where tj is the jth
point in the physical server session
t, and m is the number of ﬂows in t. For classiﬁca-
tion, we consider any physical server session whose path
has a non-zero probability (from Eqn. 2) under the given
model to be a mapping between the logical server repre-
sented by the model and the physical server session be-
ing evaluated. Of course, it may be possible for physical
server session t to follow a path that matches portions
of several disjoint paths in the KDE model without ex-
actly matching any paths in their entirety. Consequently,
the path would achieve a non-zero probability despite the
fact that it is not similar to any of the paths in the model.
To prevent such situations from occurring, we apply lin-
ear interpolation to each pair of points representing con-
secutive ﬂow indices on a path to create sample points at
half index intervals.
The use of path probabilities alone, however, is insuf-
ﬁcient in uniquely describing the behavior of the logical
server. To see why, consider the case where we have
a model for a logical server which typically contains
ten or more total ﬂows. It may be possible for a much
smaller physical server session with one or two ﬂows to
achieve a non-zero probability despite the fact that there
clearly was not an adequate amount of data transferred.
To address this, we also create a KDE model for the ﬁ-
nal points in each sample path during training, denoted
as end points. These end points indicate the requisite cu-
mulative size and number of ﬂows for a complete session
with the given logical server. As before, we create distri-
butions around each sample end point, and calculate the
344
16th USENIX Security Symposium
USENIX Association
probability of the physical server session’s end point by
applying Eqn. 1. Any anonymized physical server ses-
sion which has a non-zero probability on both their path
and their end points for a given logical server model is
mapped to that logical server.
Automatically Building Logical Server KDE Models
To create our logical server models, we use two heuris-
tics to group physical servers into logical server groups.
First, if two physical servers in our training data use the
same hostname and serve the exact same HTTP URL,
we can assume they are the same logical server and their
sample points can be merged into a single KDE model.
Since we are in control of our training data, we can col-
lect packet traces to ﬁnd URL and hostname information
before converting the data to NetFlow format to create
the paths that will make up our KDE models. It is of-
ten the case, however, that different hostnames are used
among physical servers in the same logical server group,
and this may prevent some of the physical servers in our
training data from being placed into the correct logical
server groups.
To address this, we apply a second heuristic that
merges these remaining physical servers by examining
the behavior exhibited by their KDE models. If a ran-
domly selected path and its end point from a given phys-
ical server’s training data achieves non-zero probability
on the KDE model of another physical server, then those
two physical servers can be merged into a single logical
server. The combination of these two heuristics allow us
to reliably create KDE models that represent the logical
servers found in the web browsing session. By applying
the points found in an anonymized physical server ses-
sion to each of the KDE models for a given web page,
we can create candidate mappings from the anonymized
physical server to the logical servers for the target web
page.
4.2 Binary Bayes Belief Networks
As discussed earlier, we formalize the constraints on
the logical servers using a binary Bayes belief network
(BBN). In a typical Bayes network, nodes represent
events and are inter-connected by directed edges which
depict causal relations. The likelihood that a given event
occurs is given by the node’s probability, and is based on
the conditional probability of its ancestors. In the binary
Bayes belief network variant we apply here, we simply
use a binary belief network where events have boolean
values and the causal edges are derived from these val-
ues [20].
An example of a binary belief network is given in Fig-
ure 5, where the probability of event y is conditioned
¬x. One way of thinking of this network is
upon event
x
false
true
y
. . .
false true
z
. . .
false true
. . .
is-present?
causal 
relationships
relative sizes
Figure 5: Example BBN
as a strategy for the game of “20 Questions” where the
player attempts to identify an object or person by asking
questions that can only be answered with ‘Yes’ or ‘No’
responses. Our binary belief network is simply a formal-
ization of this concept (though we are not limited to ask
20 questions), where the answer to any question dictates
the best strategy for asking future questions.
To create the belief network, we ﬁrst decide upon a
set of questions (or events) that we would like to evalu-
ate within the data. In the context of web privacy, these
events relate to the existence of logical servers, their
causal relationships, and cumulative size. The belief net-
work can be created automatically by ﬁrst examining all
possible existence and ordering events that occur within
the training data. Next, from this set of events, we can
simply select the event whose probability of being True
in the training data is highest among all events. Having
done so, the training data can then be partitioned into two
groups: one group whose data has the value True for the
selected event, and another whose value is False for
that event. The selected event is then removed from the
set of possible events and each partition of training data
now selects another event from the remaining set whose
probability on their respective data is highest.
This partitioning process is repeated recursively, al-
lowing each branch to grow independently. A given
branch halts its recursion when its conditional proba-
bility for an event is < . The conditional probability
threshold, , indicates the percentage of the training data
that remains at a given leaf node, and therefore we stop
our recursion before the tree becomes overﬁtted to our
training data. Any leaf node that halts recursion with
some amount of training data remaining is considered as
an accepting node, and all other leaf nodes are labeled
as rejecting nodes. Accepting nodes implement one ad-
ditional check to ensure that the total size of all ﬂows
±10% of the total
in the web browsing session is within
sizes observed during training.
USENIX Association
16th USENIX Security Symposium
345
5 A Closed-world Evaluation
§
6.
To gauge the threat posed by the our web page identiﬁca-
tion techniques—and to place our results in context with
prior work—we ﬁrst provide an evaluation under a clean,
closed world testing model. Prior work on this topic also
focuses on the evaluation of identiﬁcation techniques
based on a controlled network environment, browsing
a set of target web pages across an encrypted tunnel
[32], through a proxy server [18], or within anonymized
packet traces [14]. Each of these works, with the excep-
tion of [14], also assume that the web browsing session
can be easily parsed from the stream of packets crossing
the encrypted tunnel or proxy server. In what follows, we
also adopt this assumption for this particular evaluation,
though we will re-visit the inherent challenges with web
browsing delineation in
In short, our initial evaluation is considered under con-
trolled environments similar to past work, but with two
notable differences. First, in the scenarios we exam-
ine, there is substantially less data available to us than
at the packet trace level; recall that NetFlows aggre-
gate all packets in a ﬂow into a single record. Second,
rather than assuming that the client’s browser cache is
turned off, we attempt to simulate the use of caching in
browsers in our training and testing data. The simula-
tion of browser caching behavior was implemented by
enabling the default caching and cookie policies within
Mozilla FirefoxTM, and browsing to the sites in our target
set at random. Of course, this method of cache simula-
tion is not entirely realistic, as the probability of a cache
hit is directly proportional to the frequency with which
the user browses that web site. However, in lieu of mak-
ing any assumptions on the distribution of web brows-
ing for a given user, we argue that for the comparison at
hand, the uniform random web browsing behavior pro-
vides an adequate approximation.
Data Collection The data for our closed world eval-
uation was collected with the use of an automated
script that used Firefox to randomly visit selected web
pages from a set of target pages (with Adobe Flash and
Javascript enabled). The web browser was set to the de-
fault caching and cookie policies to ensure the most re-
alistic behavior possible in such a closed world environ-
ment. Speciﬁcally, the script ﬁrst initiated a new Fire-
fox instance, and opened new tabs within the single Fire-
fox instance for each new web page visited. While these
web pages were not loaded in parallel, several web sites
automatically refresh themselves at given intervals, thus
adding noise to our data whenever they appeared among
one of the tabs of the active Firefox instance. Once four
web pages were opened in the current Firefox instance,
the browser was closed gracefully to allow the cache to
ﬂush to disk, and a new Firefox instance was loaded to
continue the random browsing. For each visit to a web
page, we captured the packets for that web browsing ses-
sion and recorded it to a separate trace. The packet cap-
tures were then converted into NetFlow logs by creat-
ing single ﬂow records for each TCP connection in the
session. Notice that the use of an automated browsing
script allowed us to cleanly delineate between browsing
sessions, as well as to simulate cache behavior through
random browsing.
Our target pages were the front pages of the top 50
most popular sites as ranked by alexa.com. Addition-
ally, we also collected information about the front pages
of sites ranked 51-100 on the alexa.com list for use in
providing robust evaluation of the false detection rates of
our technique. Though we have chosen to evaluate our
techniques on the top 100 sites, there is nothing inherent
in their structure that differentiates them from other web
pages. In fact, the same techniques are equally applica-
ble in targeting any web page of the attacker’s choosing.
The web pages were retrieved by running the auto-
mated browsing script on a host within the Johns Hop-
kins University network for a total of four weeks, cre-
ating a total of 18,525 web browsing sessions across all
100 web pages in our list of web pages. From this data,
we select the ﬁrst 90 web browsing sessions of our target
web pages (i.e., those within the top 50 of the alexa.com
ranking) as the training data for the creation of the ker-
nel density estimate (see
4.1) and binary Bayes belief
network models (see
4.2) that make up the proﬁles for
each target web page. The remaining sessions are used
as test data and are anonymized by replacing IP ad-
dresses within the NetFlow data with preﬁx-preserving
pseudonyms according to the techniques described by
[23]. Notice that since we assume that the web browsing
sessions are easily parsed, we can simply use each web
browsing session in our test data directly to determine
if that web browsing session can be identiﬁed as any of
the 50 web pages in our target set using the techniques
described in
3.
§
§
§
Results The results for this evaluation are given in Ta-
ble 1. The analysis shows that our web page identiﬁ-
cation method performs reasonably well in the closed
world environment. Though the overall true detection
rate is only 48%, its associated false detection rate is
exceptionally low at only 0.18% across all web pages.
For comparison, using random guessing to identify web
pages would yield an overall true detection rate of only
2%. Moreover, keep in mind that under the goals of net-
work data anonymization, no inference of browsing be-
havior should be possible.
For ease of exposition, we also partition the 50 target
web pages into canonical categories based on the primary
346
16th USENIX Security Symposium
USENIX Association
Category
Other
Examples
passport.net, statcounter.com
match.com, myspace.com
Social Networking and Dating
Search Engines and Web Portals msn.com, google.com
imdb.com, wikipedia.org
ﬂickr.com, youtube.com
microsoft.com, apple.com
amazon.com, ebay.com
cnn.com, nytimes.com
monster.com, careerbuilder.com
foxsports.net, mlb.com
Job Search
News
Reference
Media
Corporate
Shopping
Sports
Overall
TD (%)
95.33
64.59
60.42
54.17
52.82
48.95
39.22
28.74
26.73
20.74
48.89
FD (%)
0.16
0.11
0.16
0.02
0.42
0.15
0.00
0.06
0.00
0.00
0.18
Table 1: True and false detection rates for canonical categories in closed world test
function of the web site. Notice that the performance of
the canonical classes varies based on the dynamism of
the contents in the web page. For instance, some of the
more difﬁcult categories in terms of true detection are
those whose front page content changes frequently, e.g,
cnn.com. Conversely, pages with simple, static content,
like passport.net or google.com, can be identiﬁed reason-
ably well. Moreover, those web sites with simple lay-
outs and little supporting infrastructure also tend to fare
worst with respect to false detections, while complex,
dynamic sites have few, if any, false detections. These
initial results hint at the fact that the ability to reliably
identify web pages is connected with the complexity and
dynamism of the web page. In what follows, we examine
whether these results hold under a more realistic exami-
nation based on real world browsing.
6 Considerations for the Real World
The closed world evaluation in the previous section made
several assumptions about the attacker’s ability to parse
web sessions and simulate caching behavior. Moreover,
since both the training and testing data were collected at
the same location, the effects of locality on the effective-
ness of the identiﬁcation techniques were not accounted
for. These assumptions lead to a disconnect between the
results of our closed world testing and those that can be