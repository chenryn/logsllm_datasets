title:Investigating System Operators' Perspective on Security Misconfigurations
author:Constanze Dietrich and
Katharina Krombholz and
Kevin Borgolte and
Tobias Fiebig
Investigating System Operators’
Perspective on Security Misconfigurations
Constanze Dietrich
Berliner Hochschule für Technik*
PI:EMAIL
Katharina Krombholz
CISPA Helmholtz Center (i.G.)y
krombholz@cispa.saarland
Kevin Borgolte
Princeton Universityz
PI:EMAIL
Tobias Fiebig
TU Delft§
PI:EMAIL
ABSTRACT
Nowadays, security incidents have become a familiar “nuisance,”
and they regularly lead to the exposure of private and sensitive data.
The root causes for such incidents are rarely complex attacks. In-
stead,theyareenabledbysimplemisconfigurations,suchasauthen-
tication not being required, or security updates not being installed.
For example, the leak of over 140 million Americans’ private data
from Equifax’s systems is among most severe misconfigurations in
recent history: The underlying vulnerability was long known, and a
security patch had been available for months, but was never applied.
Ultimately,Equifaxblamedanemployeeforforgettingtoupdatethe
affected system, highlighting his personal responsibility.
In this paper, we investigate the operators’ perspective on secu-
rity misconfigurations to approach the human component of this
class of security issues. We focus our analysis on system operators,
whohavenotreceivedsignificantattentionbypriorresearch.Hence,
we investigate their perspective with an inductive approach and ap-
ply a multi-step empirical methodology: (i) a qualitative study to
understand how to approach the target group and measure the mis-
configuration phenomenon, and (ii) a quantitative survey rooted in
the qualitative data. We then provide the first analysis of system
operators’ perspective on security misconfigurations, and we deter-
mine the factors that operators perceive as the root causes. Based
on our findings, we provide practical recommendations on how to
reduce security misconfigurations’ frequency and impact.
CCS CONCEPTS
• Security and privacy → Social aspects of security and pri-
vacy; Usability in security and privacy; • Social and professional
topics → Employment issues; Computing occupations;
KEYWORDS
Computer systems; system operations; operators; administrators;
security; misconfigurations; vulnerabilities; human factors.
ACM Reference Format:
ConstanzeDietrich,KatharinaKrombholz,KevinBorgolte,andTobiasFiebig.
2018. Investigating System Operators’ Perspective on Security Misconfigu-
rations. In 2018 ACM SIGSAC Conference on Computer and Communications
Security (CCS ’18), October 15–19, 2018, Toronto, ON, Canada.ACM,NewYork,
NY, USA, 18 pages. https://doi.org/10.1145/3243734.3243794
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise,
or republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee. Request permissions from permissions@acm.org.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5693-0/18/10…$15.00
https://doi.org/10.1145/3243734.3243794
1 INTRODUCTION
Security incidents and vulnerabilities in today’s Internet are often
believed to be caused by programming errors, such as faulty input
validation, race conditions, or buffer overflows, that are exploited
to disrupt services without the vulnerability being publicly known
and before a patch is available (0 days). However, when investigat-
ingrecentsecurityincidents,suchasthoseofEquifax[2,3],wefinda
different picture. The vulnerability exploited in the primary Equifax
incident,inwhichpersonallyidentifiableinformationof143million
customers were inadvertently disclosed and which sparked a con-
gressional inquiry, was clearly a programming mistake. However,
while a patch to address the bug was released months prior, it was
simply not yet deployed to the production environment.
Of course, not applying (security) patches can have its cause in
countless reasons, such as technical debt accumulated over time, or
availability and functionality requirements. Yet, when investigat-
ing the Equifax incident, such complex reasons are not the breach’s
cause. In the end, Equifax blamed the entire incident on a single
operator for forgetting to install security patches in time [4].
Broadening the scope, incidents that have their root cause in hu-
man error can be found all over the Internet, from basic infrastruc-
ture to applications [5, 6]. For example, in early 2015, over 40,000
MongoDBinstanceswerepubliclyaccessiblefromtheInternet,with-
out authentication and authorization, and, in turn, allowed anyone
to retrieve the stored data [7], which might have been confiden-
tial or possibly would have even required governmental security
clearances. In fact, one of these MongoDB instances contained mil-
lions of voting records from Mexican citizens, and, in turn, it leaked
them online [8]. Other database systems, like Redis or memcached,
are not spared from similar human error: hundreds of thousands of
systems were discovered to be unprotected [6]. The configuration
of Transport Layer Security (TLS) for web application servers are
often similarly vulnerable to misconfigurations due to human er-
ror [9]. Ultimately, misconfigurations can also lead to other vulner-
abilities, such as servers becoming vulnerable to denial-of-service
attacks [10, 11], or websites turning malicious [12] or being defaced
to embarrass the systems’ operators [13, 14].
The overarching aspect of these incidents is that the mistake lead-
ing to the incident occurred during the operation of the affected sys-
tem instead of its development (as it is the case for software vulner-
abilities). These mistakes do not need to be complex, but they can
even be comparatively simple errors, such as missing or incorrect
(cid:3)We use “Berliner Hochschule für Technik” instead of “Beuth Hochschule für
Technik Berlin” because of Peter Christian Wilhelm Beuth’s antisemitic views [1].
We stand for a diverse and inclusive scientific community, and we do not want to
perpetuate the name of a researcher who did not.
†Research partially performed while at SBA Research.
zResearch performed while at UC Santa Barbara.
§Research partially performed while at TU Berlin.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
Constanze Dietrich, Katharina Krombholz, Kevin Borgolte, and Tobias Fiebig
firewall rules, faulty or missing authentication, or software depen-
dencies, for which security updates were not installed. Following,
we use misconfiguration as the covering term for such (human) er-
rors in the operation of systems, and we use security misconfigura-
tion when such an error allows an attacker to impact the confiden-
tiality, integrity, or availability of a system (i.e., its security). The
corresponding actors are called operators (also called administra-
tors, or admins, sometimes prefixed with the type of system that
they operate, for example, network operator or system administra-
tor), and they are responsible for configuring systems to fit them to
an organization’s specific needs.
In this paper, we investigate the operators’ perspective on secu-
rity misconfigurations. Specifically, we aim to answer the following
questions:
(1) Do security misconfigurations (regularly) occur in practice?
(2) If security misconfigurations occur commonly, what are the
reasons as to why they occur?
(3) Do security misconfigurations lead to security incidents?
(4) If security misconfigurations led to security incidents, were
the misconfigurations known and addressable?
(5) If security misconfigurations were known and could have
been addressed, what caused them not to be addressed?
To do so, we use a multi-step empirical approach, first approach-
ing the target group with a qualitative study to lay the foundation
for a subsequent quantitative evaluation. We investigate the subject
matter in an explorative, open-minded way, to elicit a picture on op-
erators’perceptions,withoutbeingbiasedbyseeminglyestablished
concepts and beliefs within the research community. Hence, we con-
tribute the first empirical analysis from the operators’ perspective,
collecting a data set that can serve as the foundation and point for
comparison in future work.
We make the following major contributions:
(cid:15) We present the first qualitative and quantitative study that
investigates operators’ perceptions of factors leading to se-
curity misconfigurations.
(cid:15) Our results indicate that the majority of security misconfig-
urations have not (yet) led to security incidents, which sug-
gests that countless undiscovered issues may be present in
Internet-connected systems.
(cid:15) We identify social (communication), structural, and, institu-
tional factors to be major facilitators for bad security posture
based on our analysis of the operators’ perspectives on mis-
configuration facilitators.
(cid:15) We find that structural and procedural mitigations already
existthatwouldpreventmostsecuritymisconfigurationsthat
our participants encountered, but that these procedures are
often not in place for various reasons.
(cid:15) Weprovidepracticalrecommendationsonhowtoreduceand
the frequency and impact of security misconfigurations.
Outline. First, we describe our ethical considerations (Section 2).
Next, we detail the methodology of our qualitative approach (Sec-
tion 3), which is followed by our qualitative results (Section 4). We
then discuss the methodology of our quantitative study (Section 5)
and analyze the collected quantitative data (Section 6). Finally, we
compare to related work (Section 7), discuss the limitations of our
work (Section 8), and summarize our key findings (Section 9).
2 ETHICAL CONSIDERATIONS
For the research of this paper, we conducted interviews and surveys
that involve human subjects, and we collected data about their ex-
perience. Furthermore, our subjects might be inclined to talk about
past behavior. As such, the nature of our research renders it inher-
ently challenging yet critically important to execute it ethically. At
the time the research was conducted none of the then relevant host
institutions had an Institutional Review Board (IRB) or a similar
committee advising on potential ethical issues. Hence, we indepen-
dently followed the guidelines set out by the Menlo Report by the
U.S. Department of Homeland Security [15, 16].
Theparticipantsofbothstudieswereinformedaboutthepurpose
of the studies and gave their consent to using the data for research
purposes. For the interviews, participants had the option to review
and redact the transcripts for confidential information before we
entered them into our research pipeline (including anonymization)
and they were also allowed to opt out and withdraw from our study
at any point. Particularly the option to redact and withdraw from
the study is crucial because pre-studies indicated that participants
may be overly cautious if these options are not provided, due to
being concerned about accidentally violating non-disclosure agree-
ments or private data. We did not question or deny any requests for
redaction, and we did not require any justification.
To preserve the anonymity of participants, we anonymized all
items that constitute Personally Identifiable Information (PII) prior
to analyzing the data. Furthermore, given that we are analyzing re-
sponses of individuals online, we consider their aliases/nicknames
as PII. Correspondingly, for our quantitative study, we collected
minimal PII in aggregated form only (e.g., a participant’s age was
collected in range bins), and we did not collect other PII at all, such
as gender, nationality, etc. Instead, we focused our survey on pro-
fessional information of the subjects, while ensuring that this infor-
mation cannot reveal the participants’ identities.
3 QUALITATIVE METHODOLOGY
The literary body on misconfigurations and their security impact is
still sparse, which is why we followed an inductive approach [17]
and used a qualitative study as a starting point for our quantitative
study.Following,wedetailourstudydesign,recruitmentprocedure,
and target population.
3.1 Interview Study Design
To better assess the respondents’ perceptions and opinions on se-
curity misconfigurations, we opted for semi-structured interviews
with specific, yet open-ended questions. Our goal is to get a broader
overviewofsystemicinfluencesbylettingparticipantsdigresswhen
answering,whichmighthappenbecauseoperatorstendtobeenthu-
siastic about their work (judging from our initial experience).
We started each interview with a brief introduction of ourselves,
the study, and its research goals. Furthermore, we encouraged par-
ticipants to provide technical and in-depth explanations of opera-
tions related topics. Subsequently, we engaged in three preset ques-
tions, which we selected based on the initial encounter:
(1) Whichsecurity-relatedmisconfigurationshaveyouen-
countered?
This question aims to investigate the types of misconfigura-
tions that can emerge during operations, and the systems
2
Investigating System Operators’ Perspective on Security Misconfigurations
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
that might be misconfigured easily or often. We also asked
how the interviewee discovered the mistakes, to understand
what reveals security misconfigurations. We then inquired
whether the security misconfigurations led to security inci-
dents, and how they think that the misconfigurations could
have been prevented.
(2) How do you think misconfigurations occurred?
This question allows operators to conjecture on possible fac-
tors that facilitate misconfigurations. We did not restrict an-
swers to specific incidents, and also allow participants to in-
clude perceived factors.
(3) Howdidmisconfigurationsaffectyouandthewayyour
company approaches and handles security?
This question aims at understanding if the personal work at-
titude or habits have changed in response to a security mis-
configuration, or if there were sanctions or changes in con-
figuration procedure after an incident took place.
3.2 Data Analysis
To analyze the interviews, we collected anonymized Internet Relay
Chat (IRC) log files. In a first round, we analyze the anonymized in-
terviews with QDA Miner [18], and gradually generate categories
while keeping the underlying codes rather specific to not generalize
them prematurely. Subsequently, we perform inductive coding [19–
24],whichiscommonlyusedtoconstructmodelsandtheoriesbased
on qualitative data in social sciences and usable security [9, 25].
We then use Strauss and Corbin’s descriptive, axial coding [23]
and selective coding to group our data into categories and models.
We first code, then iteratively refine our research questions, with an
emphasis on the different stages of coding.
We use one coder to construct the code book, which is deemed
acceptable in social sciences, especially when the analysis is inter-
pretative and exploratory [26]. An additional researcher, who had
not been involved in the data collection, then uses the codebook to
assess the frequency of codes in the interviews. We pay special at-
tention to cases in which the participants exhibit strong opinions,
whichappeartobethemostchallengingtasks,andhowtheyexplain
misconfiguration facilitators in conjunction with the underlying
root causes. Due to our community-driven approach (Section 3.3),
mostinterviewswereinGerman.Theseinterviewsareanalyzedbya
German native speaker. We pay special attention to preserve mean-
ing, tone, and, context when translating them into English. In the
case of English-speaking participants, we do not correct typograph-
ical or grammatical mistakes.
3.3 Operators as a Target Group
Operators are personnel who are tasked with configuring and main-
taining complex systems. Therefore, they constitute an ideal start-
ing point for an investigation of multi-domain causes for security
misconfigurations. However, operators are, like developers [27], a
vocationally enclosed group, or as Halprin phrased it: “The average
system administrator’s day consists of so many complimentary and
contradictory tasks that they often find it difficult to describe to other
people what it is that they do.” [28]. Furthermore, they perform “[…]
such a wide variety of tasks each and every day, that it is often dif-
ficult to remember what they did before lunch.” [28]. Even though
Halprin’s observations stem from 1998, they remain valid today. In
3
general, operators tend to be highly restricted in their time commit-
ments [29]. Therefore, any additional tasks, such as participating in
a research study, must be sufficiently incentivized. Unfortunately,
traditional recruitment methods, that is, monetary incentives, are
not applicable: Operators are generally well compensated and more
concerned about committing their time than receiving additional
pay [29]. Correspondingly, we did not compensate interviewees.
Additionally, typical recruitment strategies, such as (mass) mail-
ing campaigns, are also problematic: Operators are skeptical about
unsolicited mail, due to being regularly confronted with spam and
phishing at work [30]. Furthermore, there is no central database of
system operators’ contact addresses that could be used to launch a
campaign for recruitment, contrary to, for example, Android Devel-
opers [31]. Therefore, we opted for a community-driven approach
to contact the target population.
Recruitment. In the context of our study, the operators are do-
main experts. However, the topic of our study bears a primarily
negative connotation and operators might be embarrassed to admit
misconfigurations. To address this problem, we aimed to create a
safe environment in which they felt comfortable to disclose miscon-
figurations, also knowing that their data was treated confidentially.
During our initial engagement, several operators expressed that the
best place to recruit participants would be via IRC.
We used the channel of the German Network Operators Group
(DENOG) to recruit participants, which means that the operators
of our study are members of an online community. Note that, for a
lot of operators, IRC is usually running in the background (“idling”)
and used to share news and ask specific questions. Similarly, oper-
ators seek leisure time in IRC, discussing various topics with peo-
ple in their community. Therefore, in conjunction with earlier ob-
servations on time pressure and commitments, we framed our in-
terview about misconfigurations as a way to find leisure and to re-
lax. Overall, we conducted interviews with 6 participants online via
IRC for our qualitative study, which did not reach theoretical satu-
ration [32]. However, the potential lack of saturation is alleviated
as our qualitative analysis is only used as a first step for our quanti-
tative study. Additionally, the target population is diverse with re-
spect to different (demographic) aspects, such as their relationship
to the organization ranging from freelancer consulting for compa-
nies of various sizes to administrators from non-governmental or-
ganizations (NGO) to medium to large organizations. Furthermore,
administrators are diverse with respect to their role within a team
(e.g., team lead, administrator, engineer, or consultant) and their ed-
ucation and previous work experience.
4 QUALITATIVE RESULTS
In this section, we discuss the results from our qualitative evalua-
tion. For eased readability, we use pseudonyms for all participants
instead of IDs. Following, we group the results of our qualitative
research steps into six major categories (Table 2), from which we
derive theories that we test through our subsequent quantitative
investigation.
4.1 Background and Demographics
Due to the nature of our target group and the focus on their per-
ceptions of misconfigurations, we did not request in-depth informa-
tion about the participants’ employers. Especially in the context of
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
Constanze Dietrich, Katharina Krombholz, Kevin Borgolte, and Tobias Fiebig
Pseudonym