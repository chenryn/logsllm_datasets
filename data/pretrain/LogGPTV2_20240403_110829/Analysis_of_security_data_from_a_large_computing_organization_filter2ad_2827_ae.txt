20
10
0
Atack Phases 
Figure 5: Incident Types versus Attack Phases 
C. 
Incident Severity  
A  reason  to categorize  incidents  based  on  severity  is  to 
determine  whether  monitors  are  catching  harmful  incidents 
as opposed  to  mere  low-impact compromises.  Severity  is  a 
qualitative  measure  that  expresses  the  effect  on  loss  of 
integrity,  availability,  and  confidentiality  in  the  system, 
application, services, and data. Analysis of incident severity 
allows determining whether security monitors are capable of 
detecting  high  profile 
low-impact 
violations.  Table  V  provides  definitions  of  the  various 
incidents  or  mere 
degrees  of  severity  along  with  the  distribution  of  the 
analyzed incidents across the severity categories. 
Incident Phase and Severity. Out of incidents detected in 
the attack-relay/misuse (last) phase, only about 30% were of 
medium-to-high-severity. While one expects a high-level of 
correlation between high detection latency and high severity 
(the  longer  the  attacker  stays  in  the  system,  the  more 
potential there is for him to do damage) - this is not true from 
our data. This is because many of the high severity incidents 
are detected at an early stage. 62% (23/37) of high-severity 
incidents  were  caught  in  the  breach  phase,  having  already 
resulted  in  significant  damage,  e.g.,  attackers  were  already 
able  to  gain  access  to  the  system  using  stolen  credentials. 
Such attacks cannot be detected (even with profiling of user 
behavior) until an attacker uses the stolen credentials to gain 
access to the system. 
How early detection can help. An early detection can still 
limit  the  extent  of  the  damage  caused  by  the  attack.  For 
instance, for incident three (credential compromise) in Table 
II,  an  early  detection  could  have  prevented  unsuspecting 
users  from  exposing  their  credentials  on  a  host  with  a 
trojaned  ssh  server  and  a  rootkit.  Ideally,  File  Integrity 
Monitors 
should 
of 
legitimate  SSH  software  gets 
/usr/sbin/sshd  when 
replaced with the trojaned version.  
change/modification 
preempt 
the 
TABLE V.  
INCIDENT SEVERITY 
Severity 
Very High 
(Catastrophic) 
High 
(Very serious) 
Medium 
(Limited) 
Low  
(Little or no 
effect) 
Incident Impact 
A vast majority of users are affected due to 
the breach with successful root escalations 
Production and administrative systems. 
Credentials compromise and application 
compromise (OpenSSL exploits, X-server 
key stroke logging) that allow attacker to 
obtain root level privileges on the systems 
Users and small cluster systems (affects 
entire research group); application level 
compromise (VNC, XP_Cmdshell mssql 
exploit), web server (Phpmyadmin, Php 
Horde), malware hosting.  
Non-production systems (affects an 
individual); brute force SSH, infected 
systems, spam/phishing. 
# 
1 
37 
24 
62 
In  summary,  the  top  five  alerts,  which  account  for 
detection of approximately 54% (67/124) incidents, include 
TopN  (18  incidents,  5  types),  IRC  (15  incidents,  4  types), 
Watchlist  (11  incidents,  6  types),  login  and  command 
anomaly (14 incidents, 4 types), HTTP and FTP analyzer (9 
incidents,  4  types).  Again  observe,  in  Fig.4,  that  each  alert 
detects multiple incident types.   
Login  and  command  anomaly  alerts  have  the  highest 
success rates of all alerts in catching high-severity incidents 
30%  (11/37).  However,  these  alerts  are  triggered  after  the 
fact, when the attacker is already in the system. 
IX.  MISSED INCIDENTS 
Because of monitor imperfections, there are usually false 
negatives  and  false  positives  associated  with  the  detection 
system.  In  this  section,  we  discuss  false  negatives,  i.e., 
incidents  missed  by  the  security  monitors.    In  our  analysis 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:24 UTC from IEEE Xplore.  Restrictions apply. 
515there are 34 (27%) missed/undetected incidents. All incidents 
missed by the monitoring system are discovered because of 
notifications  by  external  sources  (third  party,  mailing  lists, 
peers,  users  or  administrator).  Upon  notification  from  an 
external source, relevant logs are parsed to look for the signs 
of the incidents. Once confirmed, proper response actions are 
taken to address the incident.  
Table  VI  summarizes  the  specific  causes  of  missed 
incidents.  Analysis  of  data  on  missed  incidents  reveals 
inherent limitations in current security monitoring setup: (i) 
inability  to  automatically  produce  a  context  of  what  is 
normal  and  abnormal  in  the  observed  events,  (ii)  limited 
ability  for  automated  collection  and  analysis  of  attack 
pertinent information, and (iii) inability to cope with a large 
spectrum  of  attacks,  malware,  and  network  traffic.  The 
following  discussion 
limitations  using 
examples of incidents missed by the monitoring system. 
illustrates 
these 
TABLE VI.  
CAUSES OF MISSED INCIDENTS 
Cause of missed incidents 
Increased sophistication in 
attacks 
Lack of signatures 
Admin misconfiguration 
Inability to distinguish traffic 
anomalies in the network 
Misconfiguration of security 
monitoring tools 
Inability to distinguish true 
positives from false positives 
Inability to run monitors on 
all hosts and file systems due 
to large administrative and 
performance costs 
Examples 
A peer site gets compromised and 
an attacker logs-in with stolen 
credentials; zero-day exploits 
Exploit of VNC null string 
authentication vulnerability 
Web share world writable access 
or root login to accept any 
password 
Web defacement or use of web 
server to host malware; bot 
command and control traffic  
Routers stop exporting the flows 
to central collector which 
prevents alerting 
Human error 
Limited deployment of file 
integrity monitors on non-critical 
systems 
# 
6 
7 
5 
10 
1 
2 
3 
Inability to produce information on what is normal and 
abnormal  in  a  stream  of  observed  events.  About  26.5%  of 
the  missed  incidents  are  credential  compromises  (a  high 
impact category). For detection of incidents in this category, 
monitors rely on alerts which are based on detection of: (i) 
deviation in the user behavior as compared with the known 
user  profile  (using  syslog),  (ii)  malicious  code  download 
(using  IDS),  and  (iii)  unexpected  system  file  manipulation 
(using  file  integrity  monitor).  A  combination of  these three 
tools  should  allow  high  detection  coverage  to  be  achieved. 
However,  detecting  a  multi-step  attack,  which  uses  stolen 
credentials, requires comprehensive runtime traffic analysis, 
including  correlation  of  different  events  and  accurate 
determination  of  what  is  normal  and  abnormal  in  the 
observed traffic.  
In the current setup of the monitoring system: (i) syslogs 
are limited in detecting user profile anomalies since attackers 
masquerade as regular users while logging in to the system; 
(ii) IDS does not raise alerts when attackers do not download 
malware from a known source and often there is no built-in 
signature  for  a  given  exploit  available;  (iii)  due  to  high 
operational costs associated with file integrity monitors, they 
are  not  installed  on  administrator  systems  targeted  by  the 
attackers.  
Limited ability  for automated  collection and  analysis of 
attack  relevant  information:  In  a  credential  stealing  attack 
one  of  the  actions  the  attacker  takes  is  to  download  the 
malware/exploit  on  the  system.  Assuming  that  IDS  is 
updated  with  a  signature  of  this  malware  (or  exploit  code), 
IDS  should  generate  an  alert.  However,  due  to  lack  of  a 
context,  it  is  difficult  to  determine  what  user  account  was 
used  to  download  this  malware.  Furthermore,  the  attacker 
often deletes the  malware  from  the  directory,  which  makes 
things  even  harder  to  trace.    Ideally,  correlation  of  file 
integrity  monitor  data,  IDS,  and  syslogs  should  suffice  to 
construct an accurate event timeline. Currently, the incident 
response tools lack this capability.  
Inability  to  cope  with  a  large  spectrum  of  attacks, 
malware and network: About 9% of the missed incidents are 
application compromises. The limited detection coverage is 
due to the lack of timely available signatures and emergence 
of new zero-day exploits. For instance, detection signatures 
for  compromises  due  to  VNC  null  string  authentication 
bypass  vulnerability  (CVE-2006-2369),  OpenSSL  SSL-Get-
Shared-Ciphers  Buffer  overflow  (CVE-2006-3738)  exploits 
were unavailable at the time of the attack, thus each of these 
attacks went unnoticed. 
to  virus  propagation  or 
Infected  hosts  incidents  (about  15%)  are  mostly  due 
either 
to  a  user  accidently 
downloading malware and installing it on the system. A user 
who accidentally downloads and installs malware may have 
a very small footprint for generating alerts based on syslogs 
or  file  integrity  monitors.  Therefore,  the  detection  of  such 
incidents  mostly  relies  on  IDS  and  netflows.  Ideally,  good 
antivirus software running on the host system should be able 
to catch infection. However, often even in the presence of the 
antivirus  software  and  updated  signature  databases,  these 
detection mechanisms can be easily bypassed by an attacker, 
e.g., using social engineering attacks (i.e., tricking the user to 
click on a link or open email attachments) and/or exploiting 
browser  vulnerabilities.  Also,  malware 
is  designed 
specifically  to  evade  anti-virus  or  other  detection  utilities. 
Putting  additional  restrictions  on  some  legitimate  user 
actions  to  prevent  social  engineering  attacks  is  impractical 
because  it  affects  system  usability  and  degrades  user 
productivity.  
the  past  when  web  compromises  were  due 
Web  compromises  constitute  about  23.5%  of  incidents 
missed  by  the  monitoring  system.  Most  of  the  web 
compromises  are  caused  by  exploitation  of 
the  web 
application software, e.g., exploitation of PHP vulnerabilities 
that allow an attacker to execute commands remotely (unlike 
in 
to 
vulnerabilities in the web servers).  These compromises are 
hard to flag since there is no distinct behavior of the system 
post-attack,  especially  when  attackers  are  uploading  static 
content (e.g., spam pages, redirections or links, and web page 
defacements). Although HTTP content monitoring tools can 
flag such content traversing through the network, these deep 
packet  content  monitoring  rules  are  expensive  to  run  and 
keep up to date. For example, in one instance attackers used 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:24 UTC from IEEE Xplore.  Restrictions apply. 
516the web server to host malware, while no observable change 
in  the  system  was  noticed.  This  reveals  the  need  for 
monitoring outgoing network traffic. 
X.  CONCLUSIONS AND FUTURE WORK 
In  this  paper  we  study  security  compromises  that  have 
occurred over a period of 5 years at the University of Illinois 
NCSA  network.  Our observations  from  the  analysis  can be 
summarized as follows: 
IDS and NetFlows monitors detected 31% and 26% 
• 
of incidents, respectively. 27% of incidents went undetected 
by any alert.  
Alerts  are  not  uniform  in  their  ability  to  detect 
• 
attacks. The same alert can be triggered by different attacks. 
This  is  because  different  incidents  share  common  attack 
paths,  i.e.,  the  basic  steps  followed  by  different  attacks  in 
penetrating  the  system  are  often  similar  regardless  of  the 
vulnerability exploited.  
Anomaly-based  detectors  are  seven  times  more 
• 
likely  to  capture  an  incident  than  are  signature-based 
detectors.  This  is  because  the  signatures  are  specialized  to 
detect  the  presence  (or  download)  of  a  known  malicious 
binary. Consequently, they can be subverted. The signature-
based detectors (due to their specialization) have fewer false 
positives  compared  to  the  anomaly-based  detectors.  (This 
study does not quantify the false positive rates of the alerts.) 
Nearly 39% of the incidents are detected in the last 
• 
stage of the attack, i.e., attack-relay/misuse phase. This kind 
of  detection  often  comes  too  late,  since  the  damage  to  the 
system has already occurred.  
There  is  no  indication  of  high-level  correlation 
• 
between  the  attack  phase  when  an  incident  is  detected  and 
the  incident’s  severity,  e.g.,  incidents  detected  in  the  last 
stage (long latency detection) of an attack are not necessarily 
high severity incidents.  
Alerts detecting the most incidents may not be the 
• 
most efficient alerts, e.g., TopN detects 15% (18/124) of the 
incidents  of  low  to  medium  severity,  but  it  exhibits  a  33% 
false positive rate. 
While 14 incidents were detected based on reports 
• 
from  external,  unrelated  sources, one  incident  was reported 
by a user (which turned out to be a false positive) showing 
that users are not trained to identify a security breaches.  
While  in  this  analysis  we  consider  only  alert  types  that 
were triggered by the incidents included in this study, there 
are  other  warning  mechanisms  present  in  the  system  that 
never detected incidents. These detection capabilities should 
be  reexamined  to  understand  why  these  detectors  are 
inactive.  Such  analysis  would  enable  restructuring  the 
monitoring  system  and  adapting  detection  capabilities  to 
changes  in  the  underlying  infrastructure  and  the  growing 
sophistication of attackers. 
XI.  ACKNOWLEDGMENT 
This work was supported in part by NSF grants CNS-05-
51665  (Trusted  Illiac)  and  CNS  10-18503  CISE,  the 
Department  of  Energy  under  Award  Number  DE-
OE0000097,  IBM  Corporation  as  part  of  OCR  (Open 
Collaboration Research), and Boeing Corporation as part of 
ITI Boeing Trusted Software Center. 
[1]  Singer,  A.,  “Life  Without  Firewalls,”  The  Usenix  Magazine,  28(6), 
2003.  
REFERENCES 
[2]  Allman  M.,  Kreibich  C.,  Paxson  V.,  Sommer,  R.,  Weaver  N.: 
“Principles  for  Developing  Comprehensive  Network  Visibility,” 
USENIX Workshop on Hot Topics in Security, USENIX, 2008. 
[3]  Bellovin,  S.  R.,  Cheswick,  B.:  Firewalls  and  Internet  Security: 
Repelling the Wily Hacker. Addison-Wesley Publishing, 1994. 
[4]  Chen S., Kalbarczyk Z., Xu J., Iyer R. K., “A data-driven finite state 
Int’l 
for  analyzing  security  vulnerabilities,” 
machine  model 
Conference on Dependable Systems and Networks, 2003. 
the 
Superhighway. John Wiley & Sons, New York (1995). 
[5]  Cohen,  F.  B.:  Protection  and  Security  on 
Information 
[6]  Cukier, M., Berthier, R, Panjwani, S., Tan, S.: A statistical analysis of 
attack data to separate attacks. Proc. Int’l Conference on Dependable 
Systems and Networks, (2006). 
[7]  Cutts Jr. et al, United States Patent 5,193,175, March 9, 1993 
[8]  DOE  M-205:  Cyber  Security 
Incident  Management  Manual. 
Department of Energy (2010). 
[9]  Gregorio-de  Souza  I.,  Berk,  V.  H.,  Giani  A.,  et  al.,  “Detection  of 
Complex Cyber Attacks,” SPIE  6201, 2006. 
[10]  Zhou  J.,  Heckman  M.,  Reynolds  B.,  Carlson  A.,  and  Bishop  M., 
“Modeling  Network  Intrusion  Detection  Alerts  for  Correlation,” 
ACM Trans. on Info. and Sys. Security 10(1), 2007. 
[11]  Kendall K., Smith A. C., “A Database of Computer Attacks for the 
Evaluation  of  Intrusion  Detection  Systems,”  MIT,  Electrical  and 
Computer Engineering. Cambridge 1999. 
[12]  Kumar,  S,  Spafford,  E.,  An  application  of  pattern  matching  in 
intrusion  detection.  Purdue  University,  Tech.  Rep,  Department  of 
Computer Sciences (1994). 
[13]  Kumar, S. “Classification of intrusions,” Purdue University, 1995. 
[14]  Landwehr,  C.  et  al.,  “A  Taxonomy  of  Computer  Security  Flaws,” 
ACM Computing Surveys, 26(3), 1994. 
[15]  Ning  P.  and  Xu  D.,  “Learning  Attack  Strategies  from  Intrusion 
Alerts,”  10th  ACM  Conference  on  Computer  and  Communications 
Security, 2003. 
[16]  Paxson V., “Bro: A System for Detecting Network Intruders in Real-
Time,” Computer Networks, 1999. 
[17]  Ruiu  D.,  “Cautionary  Tales:  Stealth  Coordinated  Attack  HOWTO,” 
http://althing.cs.dartmouth.edu/secref/local/stealth-co-ordinated-
attack.txt (1999). 
[18]  Vaarandi  R.,  “SEC  -  A  Lightweight  Event  Correlation  Tool,” 
Workshop on IP Operations and Management,  2002. 
[19]  Sung M., Haas M, Xu J. “Analysis of DoS attack traffic data,” FIRST 
Conference, Hawaii, 2002. 
[20]  Sharma A., Kalbarcyzk Z., Barlow J., Iyer R., “Analysis of Credential 
in  an  Open  Networked  Environment,”  4th 
Stealing  Attacks 
International Conference on Network and System Security, 2010. 
[21]  Tidwell  T.,  Larson  R.,  Fitch  K.,  and  Hale  J.,  “Modeling  Internet 
Attacks,” Workshop on Information Assurance and Security, 2001. 
[22]  Templeton S.J., Levitt K., “A Requires/provides Model for Computer 
Attacks,” New Security Paradigm Workshop (2000). 
[23]  Treinen  J.,  Thurimella  R.  “A  framework  for  the  Application  of 
Association  Rule  Mining 
Intrusion  Detection 
Infrastructures,”  9th  Int’l  Symposium  on  Recent  Advances  in 
Intrusion Detection, 4219 (2006). 
in  Large 
[24]  Verizon  Business  Risk  Team:  2010  Data  Breach  Investigations 
Report,  http://www.verizonbusiness.com/resources/reports/rp_2010-
data-breach-report_en_xg.pdf  
[25]  Howard J. D., “An analysis of security incidents on the Internet 1989-
1995,” Carnegie Mellon University, Pittsburgh, PA, 1998 
[26]  Eckmann S.T., G. Vigna, and R.A. Kemmerer, “STATL: An Attack 
Language  for  State-based  Intrusion  Detection,”  Workshop  on 
Intrusion Detection Systems, Athens, Greece, 2000. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:24 UTC from IEEE Xplore.  Restrictions apply. 
517