Distributed-trust anonymizing systems need to prevent at-
tackers from adding too many servers and thus compromising
user paths. Tor relies on a small set of well-known directory
servers, run by independent parties, to decide which nodes
can join. Tarzan and MorphMix allow unknown users to run
servers, and use a limited resource (like IP addresses) to pre-
vent an attacker from controlling too much of the network.
Crowds suggests requiring written, notarized requests from
potential crowd members.
Anonymous communication is essential for censorship-
resistant systems like Eternity [2], Free Haven [19], Pub-
lius [53], and Tangler [52]. Tor’s rendezvous points enable
connections between mutually anonymous entities; they are a
building block for location-hidden servers, which are needed
by Eternity and Free Haven.
3 Design goals and assumptions
Goals
Like other low-latency anonymity designs, Tor seeks to frus-
trate attackers from linking communication partners, or from
linking multiple communications to or from a single user.
Within this main goal, however, several considerations have
directed Tor’s evolution.
Deployability: The design must be deployed and used in
the real world. Thus it must not be expensive to run (for
example, by requiring more bandwidth than volunteers are
willing to provide); must not place a heavy liability burden
on operators (for example, by allowing attackers to implicate
onion routers in illegal activities); and must not be difﬁcult
or expensive to implement (for example, by requiring kernel
patches, or separate proxies for every protocol). We also can-
not require non-anonymous parties (such as websites) to run
our software. (Our rendezvous point design does not meet
this goal for non-anonymous users talking to hidden servers,
however; see Section 5.)
Usability: A hard-to-use system has fewer users—and be-
cause anonymity systems hide users among users, a system
with fewer users provides less anonymity. Usability is thus
not only a convenience: it is a security requirement [1, 5].
Tor should therefore not require modifying familiar applica-
tions; should not introduce prohibitive delays; and should re-
quire as few conﬁguration decisions as possible. Finally, Tor
should be easily implementable on all common platforms; we
cannot require users to change their operating system to be
anonymous. (Tor currently runs on Win32, Linux, Solaris,
BSD-style Unix, MacOS X, and probably others.)
Flexibility: The protocol must be ﬂexible and well-
speciﬁed, so Tor can serve as a test-bed for future research.
Many of the open problems in low-latency anonymity net-
works, such as generating dummy trafﬁc or preventing Sybil
attacks [22], may be solvable independently from the issues
solved by Tor. Hopefully future systems will not need to rein-
vent Tor’s design.
Simple design: The protocol’s design and security param-
eters must be well-understood. Additional features impose
implementation and complexity costs; adding unproven
techniques to the design threatens deployability, readability,
and ease of security analysis. Tor aims to deploy a simple and
stable system that integrates the best accepted approaches to
protecting anonymity.
Non-goals
In favoring simple, deployable designs, we have explicitly de-
ferred several possible goals, either because they are solved
elsewhere, or because they are not yet solved.
Not peer-to-peer: Tarzan and MorphMix aim to scale
to completely decentralized peer-to-peer environments with
thousands of short-lived servers, many of which may be con-
trolled by an adversary. This approach is appealing, but still
has many open problems [24, 43].
Not secure against end-to-end attacks: Tor does not
claim to completely solve end-to-end timing or intersection
attacks. Some approaches, such as having users run their own
onion routers, may help; see Section 9 for more discussion.
No protocol normalization: Tor does not provide proto-
col normalization like Privoxy or the Anonymizer. If senders
want anonymity from responders while using complex and
variable protocols like HTTP, Tor must be layered with a
ﬁltering proxy such as Privoxy to hide differences between
clients, and expunge protocol features that leak identity. Note
that by this separation Tor can also provide services that are
anonymous to the network yet authenticated to the responder,
like SSH. Similarly, Tor does not integrate tunneling for non-
stream-based protocols like UDP; this must be provided by
an external service if appropriate.
Not steganographic: Tor does not try to conceal who is
connected to the network.
3.1 Threat Model
A global passive adversary is the most commonly assumed
threat when analyzing theoretical anonymity designs. But
like all practical low-latency systems, Tor does not protect
against such a strong adversary. Instead, we assume an adver-
sary who can observe some fraction of network trafﬁc; who
can generate, modify, delete, or delay trafﬁc; who can oper-
ate onion routers of his own; and who can compromise some
fraction of the onion routers.
In low-latency anonymity systems that use layered encryp-
tion, the adversary’s typical goal is to observe both the ini-
tiator and the responder. By observing both ends, passive at-
tackers can conﬁrm a suspicion that Alice is talking to Bob if
the timing and volume patterns of the trafﬁc on the connec-
tion are distinct enough; active attackers can induce timing
signatures on the trafﬁc to force distinct patterns. Rather than
focusing on these trafﬁc conﬁrmation attacks, we aim to pre-
vent trafﬁc analysis attacks, where the adversary uses trafﬁc
patterns to learn which points in the network he should attack.
Our adversary might try to link an initiator Alice with her
communication partners, or try to build a proﬁle of Alice’s
behavior. He might mount passive attacks by observing the
network edges and correlating trafﬁc entering and leaving the
network—by relationships in packet timing, volume, or ex-
ternally visible user-selected options. The adversary can also
mount active attacks by compromising routers or keys; by re-
playing trafﬁc; by selectively denying service to trustworthy
routers to move users to compromised routers, or denying ser-
vice to users to see if trafﬁc elsewhere in the network stops; or
by introducing patterns into trafﬁc that can later be detected.
The adversary might subvert the directory servers to give
users differing views of network state. Additionally, he can
try to decrease the network’s reliability by attacking nodes
or by performing antisocial activities from reliable nodes and
trying to get them taken down—making the network unre-
liable ﬂushes users to other less anonymous systems, where
they may be easier to attack. We summarize in Section 7 how
well the Tor design defends against each of these attacks.
4 The Tor Design
The Tor network is an overlay network; each onion router
(OR) runs as a normal user-level process without any special
privileges. Each onion router maintains a TLS [17] connec-
tion to every other onion router. Each user runs local software
called an onion proxy (OP) to fetch directories, establish cir-
cuits across the network, and handle connections from user
applications. These onion proxies accept TCP streams and
multiplex them across the circuits. The onion router on the
other side of the circuit connects to the requested destinations
and relays data.
Each onion router maintains a long-term identity key and
a short-term onion key. The identity key is used to sign TLS
certiﬁcates, to sign the OR’s router descriptor (a summary of
its keys, address, bandwidth, exit policy, and so on), and (by
directory servers) to sign directories. The onion key is used
to decrypt requests from users to set up a circuit and negotiate
ephemeral keys. The TLS protocol also establishes a short-
term link key when communicating between ORs. Short-term
keys are rotated periodically and independently, to limit the
impact of key compromise.
Section 4.1 presents the ﬁxed-size cells that are the unit
of communication in Tor. We describe in Section 4.2 how
circuits are built, extended, truncated, and destroyed. Sec-
tion 4.3 describes how TCP streams are routed through the
network. We address integrity checking in Section 4.4, and
resource limiting in Section 4.5. Finally, Section 4.6 talks
about congestion control and fairness issues.
4.1 Cells
Onion routers communicate with one another, and with users’
OPs, via TLS connections with ephemeral keys. Using TLS
conceals the data on the connection with perfect forward se-
crecy, and prevents an attacker from modifying data on the
wire or impersonating an OR.
Trafﬁc passes along these connections in ﬁxed-size cells.
Each cell is 512 bytes, and consists of a header and a pay-
load. The header includes a circuit identiﬁer (circID) that
speciﬁes which circuit the cell refers to (many circuits can
be multiplexed over the single TLS connection), and a com-
mand to describe what to do with the cell’s payload. (Circuit
identiﬁers are connection-speciﬁc: each circuit has a differ-
ent circID on each OP/OR or OR/OR connection it traverses.)
Based on their command, cells are either control cells, which
are always interpreted by the node that receives them, or re-
lay cells, which carry end-to-end stream data. The control
cell commands are: padding (currently used for keepalive,
but also usable for link padding); create or created (used to
set up a new circuit); and destroy (to tear down a circuit).
Relay cells have an additional header (the relay header) at
the front of the payload, containing a streamID (stream iden-
tiﬁer: many streams can be multiplexed over a circuit); an
end-to-end checksum for integrity checking; the length of the
relay payload; and a relay command. The entire contents of
the relay header and the relay cell payload are encrypted or
decrypted together as the relay cell moves along the circuit,
using the 128-bit AES cipher in counter mode to generate a
cipher stream. The relay commands are: relay data (for data
ﬂowing down the stream), relay begin (to open a stream), re-
lay end (to close a stream cleanly), relay teardown (to close a
broken stream), relay connected (to notify the OP that a relay
begin has succeeded), relay extend and relay extended (to ex-
tend the circuit by a hop, and to acknowledge), relay truncate
and relay truncated (to tear down only part of the circuit, and
to acknowledge), relay sendme (used for congestion control),
and relay drop (used to implement long-range dummies). We
give a visual overview of cell structure plus the details of re-
lay cell structure, and then describe each of these cell types
and commands in more detail below.
4.2 Circuits and streams
Onion Routing originally built one circuit for each TCP
stream. Because building a circuit can take several tenths
of a second (due to public-key cryptography and network la-
tency), this design imposed high costs on applications like
web browsing that open many TCP streams.
In Tor, each circuit can be shared by many TCP streams.
To avoid delays, users construct circuits preemptively. To
limit linkability among their streams, users’ OPs build a new
circuit periodically if the previous ones have been used, and
expire old used circuits that no longer have any open streams.
OPs consider rotating to a new circuit once a minute: thus
even heavy users spend negligible time building circuits, but
a limited number of requests can be linked to each other
through a given exit node. Also, because circuits are built in
the background, OPs can recover from failed circuit creation
without harming user experience.
Figure 1: Alice builds a two-hop circuit and begins fetching
a web page.
Constructing a circuit
A user’s OP constructs circuits incrementally, negotiating a
symmetric key with each OR on the circuit, one hop at a time.
To begin creating a new circuit, the OP (call her Alice) sends
a create cell to the ﬁrst node in her chosen path (call him
Bob). (She chooses a new circID CAB not currently used on
the connection from her to Bob.) The create cell’s payload
contains the ﬁrst half of the Difﬁe-Hellman handshake (gx),
encrypted to the onion key of the OR (call him Bob). Bob
responds with a created cell containing gy along with a hash
of the negotiated key K = gxy.
Once the circuit has been established, Alice and Bob can
send one another relay cells encrypted with the negotiated
CircID2RelayStreamIDDigestLenDATACircIDCMD21DATA2CMD1509 bytes126498OR  1AliceOR  2"HTTP GET...". . .. . .. . .(TCP handshake)website{X}−−AES encryptionE(x)−−RSA encryptionLegend:(link is TLS−encrypted)Relay c1{Extend, OR2, E(g^x2)}Relay c1{{Begin :80}}Relay c1{Extended, g^y2, H(K2)}Relay c2{Begin :80}Relay c1{{Connected}}Relay c2{Connected}Relay c1{{Data, "HTTP GET..."}}Relay c2{Data, "HTTP GET..."}(link is TLS−encryped)(unencrypted)cN−−a circIDRelay c1{{Data, (response)}}(response)Relay c2{Data, (response)}Created c2, g^y2, H(K2)Create c2, E(g^x2)Create c1, E(g^x1)Created c1, g^y1, H(K1)key.1 More detail is given in the next section.
To extend the circuit further, Alice sends a relay extend cell
to Bob, specifying the address of the next OR (call her Carol),
and an encrypted gx2 for her. Bob copies the half-handshake
into a create cell, and passes it to Carol to extend the cir-
cuit. (Bob chooses a new circID CBC not currently used on
the connection between him and Carol. Alice never needs to
know this circID; only Bob associates CAB on his connec-
tion with Alice to CBC on his connection with Carol.) When
Carol responds with a created cell, Bob wraps the payload
into a relay extended cell and passes it back to Alice. Now
the circuit is extended to Carol, and Alice and Carol share a
common key K2 = gx2y2.
To extend the circuit to a third node or beyond, Alice pro-
ceeds as above, always telling the last node in the circuit to
extend one hop further.
This circuit-level handshake protocol achieves unilateral
entity authentication (Alice knows she’s handshaking with
the OR, but the OR doesn’t care who is opening the circuit—
Alice uses no public key and remains anonymous) and unilat-
eral key authentication (Alice and the OR agree on a key, and
Alice knows only the OR learns it). It also achieves forward
secrecy and key freshness. More formally, the protocol is as
follows (where EP KBob(·) is encryption with Bob’s public
key, H is a secure hash function, and | is concatenation):
Alice → Bob : EP KBob(gx)
Bob → Alice : gy, H(K|“handshake”)
In the second step, Bob proves that it was he who received
gx, and who chose y. We use PK encryption in the ﬁrst step
(rather than, say, using the ﬁrst two steps of STS, which has
a signature in the second step) because a single cell is too
small to hold both a public key and a signature. Preliminary
analysis with the NRL protocol analyzer [35] shows this
protocol to be secure (including perfect forward secrecy)
under the traditional Dolev-Yao model.
Relay cells
Once Alice has established the circuit (so she shares keys with
each OR on the circuit), she can send relay cells. Upon re-
ceiving a relay cell, an OR looks up the corresponding circuit,
and decrypts the relay header and payload with the session
key for that circuit. If the cell is headed away from Alice the
OR then checks whether the decrypted cell has a valid digest
(as an optimization, the ﬁrst two bytes of the integrity check
are zero, so in most cases we can avoid computing the hash).
If valid, it accepts the relay cell and processes it as described
below. Otherwise, the OR looks up the circID and OR for the
next step in the circuit, replaces the circID as appropriate, and
sends the decrypted relay cell to the next OR. (If the OR at
the end of the circuit receives an unrecognized relay cell, an
error has occurred, and the circuit is torn down.)
OPs treat incoming relay cells similarly: they iteratively
unwrap the relay header and payload with the session keys
shared with each OR on the circuit, from the closest to far-
thest. If at any stage the digest is valid, the cell must have
originated at the OR whose encryption has just been removed.
To construct a relay cell addressed to a given OR, Alice as-
signs the digest, and then iteratively encrypts the cell payload
(that is, the relay header and payload) with the symmetric key
of each hop up to that OR. Because the digest is encrypted to
a different value at each step, only at the targeted OR will
it have a meaningful value.2 This leaky pipe circuit topol-
ogy allows Alice’s streams to exit at different ORs on a sin-
gle circuit. Alice may choose different exit points because of
their exit policies, or to keep the ORs from knowing that two