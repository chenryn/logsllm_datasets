title:Paint It Black: Evaluating the Effectiveness of Malware Blacklists
author:Marc K&quot;uhrer and
Christian Rossow and
Thorsten Holz
Paint It Black: Evaluating the Eﬀectiveness
of Malware Blacklists
Marc K¨uhrer, Christian Rossow, and Thorsten Holz
Horst G¨ortz Institute for IT-Security, Ruhr-University Bochum, Germany
{firstname.lastname}@ruhr-uni-bochum.de
Abstract. Blacklists are commonly used to protect computer systems
against the tremendous number of malware threats. These lists include
abusive hosts such as malware sites or botnet Command & Control and
dropzone servers to raise alerts if suspicious hosts are contacted. Up to
now, though, little is known about the eﬀectiveness of malware blacklists.
In this paper, we empirically analyze 15 public malware blacklists and
4 blacklists operated by antivirus (AV) vendors. We aim to categorize the
blacklist content to understand the nature of the listed domains and IP
addresses. First, we propose a mechanism to identify parked domains in
blacklists, which we ﬁnd to constitute a substantial number of blacklist
entries. Second, we develop a graph-based approach to identify sinkholes
in the blacklists, i.e., servers that host malicious domains which are con-
trolled by security organizations. In a thorough evaluation of blacklist
eﬀectiveness, we show to what extent real-world malware domains are
actually covered by blacklists. We ﬁnd that the union of all 15 public
blacklists includes less than 20% of the malicious domains for a major-
ity of prevalent malware families and most AV vendor blacklists fail to
protect against malware that utilizes Domain Generation Algorithms.
Keywords: Blacklist Evaluation, Sinkholing Servers, Parking Domains.
1
Introduction
The security community needs to deal with an increasing number of malware
samples that infect computer systems world-wide. Many countermeasures have
been proposed to combat the ubiquitous presence of malware [1–4]. Most notably,
researchers progressively explored network-based detection methods to comple-
ment existing host-based malware protection systems. One prominent example
are endpoint reputation systems. The typical approach is to assemble a blacklist
of endpoints that have been observed to be involved in malicious operations. For
example, blacklists can contain domains of Command & Control (C&C) servers
of botnets, dropzone servers, and malware download sites [5]. Such blacklists can
then be queried by an intrusion detection system (IDS) to determine if a previ-
ously unknown endpoint (such as a domain) is known for suspicious behavior.
Up to now, though, little is known about the eﬀectiveness of malware black-
lists. To the best of our knowledge, the completeness and accuracy of malware
A. Stavrou et al. (Eds.): RAID 2014, LNCS 8688, pp. 1–21, 2014.
c(cid:2) Springer International Publishing Switzerland 2014
2
M. K¨uhrer, C. Rossow, and T. Holz
blacklists was never examined in detail. Completeness is important as users oth-
erwise risk to miss notiﬁcations about malicious but unlisted hosts. Similarly,
blacklists may become outdated if entries are not frequently revisited by the
providers. While an endpoint may have had a bad reputation in the past, this
might change in the future (e.g., due to shared hosting).
In this paper, we analyze the eﬀectiveness of 15 public and 4 anti-virus (AV)
vendor malware blacklists. That is, we aim to categorize the blacklist content
to understand the nature of the listed entries. Our analysis consists of multiple
steps. First, we propose a mechanism to identify parked domains, which we ﬁnd
to constitute a substantial number of blacklist entries. Second, we develop a
graph-based approach to identify sinkholed entries, i.e., malicious domains that
are mitigated and now controlled by security organizations. Last, we show to
what extent real-world malware domains are actually covered by the blacklists.
In the analyzed blacklist data we identiﬁed 106 previously unknown sinkhole
servers, revealing 27 sinkholing organizations. In addition, we found between
40 - 85% of the blacklisted domains to be unregistered for more than half of the
analyzed blacklists and up to 10.9% of the blacklist entries to be parked. The
results of analyzing the remaining blacklist entries show that the coverage and
completeness of most blacklists is insuﬃcient. For example, we ﬁnd public black-
lists to be impractical when it comes to protecting against prevalent malware
families as they fail to include domains for the variety of families or list malicious
endpoints with reaction times of 30 days or higher.
Fortunately, the performance of three AV vendor blacklists is signiﬁcantly
better. However, we also identify shortcomings of these lists: only a single black-
list suﬃciently protects against malware using Domain Generation Algorithms
(DGAs) [3], while the other AV vendor blacklists include a negligible number
of DGA-based domains only. Our thorough evaluation can help to improve the
eﬀectiveness of malware blacklists in the future.
To summarize, our contributions are as follows:
– We propose a method to identify parked domains by training an SVM clas-
siﬁer on seven inherent features we identiﬁed for parked web sites.
– We introduce a mechanism based on blacklist content and graph analysis to
eﬀectively identify malware sinkholes without a priori knowledge.
– We evaluate the eﬀectiveness of 19 malware blacklists and show that most
public blacklists have an insuﬃcient coverage of malicious domains for a ma-
jority of popular malware families, leaving the end hosts fairly unprotected.
While we ﬁnd blacklists operated by AV vendors to have a signiﬁcantly higher
coverage, up to 26.5% of the domains were still missed for the majority of the
malware families, revealing severe deﬁciencies of current reputation systems.
2 Overview of Malware Blacklists
Various malware blacklists operated by security organizations can be used to
identify malicious activities. These blacklists include domains and IP addresses,
which have been observed in a suspicious context, i.e., hosts of a particular
Paint It Black: Evaluating the Eﬀectiveness of Malware Blacklists
3
Table 1. Observed content of the analyzed malware blacklists (‡ denotes C&C blacklists)
Domains (in #)
Blacklist
Current Historical
Observ.
(days)
Blacklist
Current Historical
Domains (in #)
Observ.
(days)
‡
‡
0
AMaDa [8]
‡
Citadel [7]
4,634
Cybercrime [9]
1,070
0
Exposure [4]
2,121
Malc0de [10]
1,653
MDL Hosts [11]
‡
12
MDL ZeuS [11]
MW-Domains [12] 23,396
1,494
0
0
107,183
20,135
11,996
1,675
37,490
267
66
121
559
832
832
829
832
‡
Palevo Tracker [8]
‡
Shadowserver [13]
Shallalist [14]
SpyEye Tracker [8]
UrlBlacklist [15]
Virustracker [16]
‡
ZeuS Tracker [8]
‡
35
0
20,677
123
127,745
12,066
759
147
0
48
956
281
56,269
8,042
542
832
320
832
824
196
832
type such as C&C servers or—less restrictive—endpoints associated to malware
in general. Table 1 introduces the 15 public malware blacklists that we have
monitored for the past two years [6]. For the majority of blacklists, we repeatedly
obtained a copy every 3 hours (if permitted). The columns Current state the
number of entries that were listed at the end of our monitoring period. The
columns Historical summarize the entries that were once listed in a blacklist,
but became delisted during our monitoring period. For reasons of brevity, we
have omitted the number of listed IP addresses per blacklist, as we mainly focus
on the blacklisted domains in our analyses. For all listed domains, we resolved
the IP addresses and stored the name server (NS) DNS records. If blacklists
contained URLs, we used the domain part of the URLs for our analysis.
Four blacklists are provided by Abuse.ch, of which three speciﬁcally list hosts
related to the Palevo worm and the banking trojans SpyEye and ZeuS. The
Virustracker project lists domains generated by DGAs, and the Citadel list in-
cludes domains utilized by the Citadel malware (that was seized by Microsoft in
2013 [7]). UrlBlacklist combines user submissions and other blacklists, covering
domains and IPs of various categories, whereas we focus on the malware-related
content. The Exposure [4] blacklist included domains that were ﬂagged as mali-
cious by employing passive DNS (pDNS) analysis. The Abuse.ch AMaDa and the
Exposure lists were discontinued, yet we leverage the collected historical data.
Besides these public blacklists, we have requested information from four anti-
virus (AV) vendors, namely Bitdefender TraﬃcLight [17], Browserdefender [18],
McAfee Siteadvisor [19], and Norton SafeWeb [20]. These blacklists cannot be
downloaded, but we can query if a domain is listed. We thus do not know the
overall size of these blacklists and omit the numbers in Table 1.
Datasets. We divide the 15 public blacklists into three overlapping datasets.
The ﬁrst dataset, referred to as SC&C , consists of domains taken from the sources
primarily listing endpoints associated to C&C servers, denoted by ‡ in Table 1.
We extend SC&C with the IP addresses to which any of these domains at some
point resolved to. The second, coarse-grained dataset SMal includes the domains
that were at any time listed in any of the 15 blacklists (including SC&C) and
the resolved IPs. Last, we generate a third dataset SIP s, covering all currently
listed IP addresses by any of the 15 public blacklists (i.e., 196,173 IPs in total).
This dataset will help us to verify if blacklists contain IPs of sinkholing servers.
4
M. K¨uhrer, C. Rossow, and T. Holz
Paper Outline. Motivated by the fact that blacklists contain thousands of do-
mains, we aim to understand the nature of these listings. We group the entries in
four main categories: domains are either i) unregistered, ii) controlled by park-
ing providers, iii) assigned to sinkholes, or iv) serve actual content. Unregistered
domains can easily be identiﬁed using DNS. However, it is non-trivial to detect
parked or sinkholed domains. We thus propose detection mechanisms for these
two types in Section 3 (parking domains) and Section 4 (sinkholed domains). In
Section 5, we classify the blacklist content and analyze to what extent blacklists
help to protect against real malware. Note that a longer version of this paper
with more technical details is available as a technical report [21].
3 Parking Domains
Parking domains make up the ﬁrst prominent class of blacklist entries. They are
mainly registered for the purpose of displaying web advertisements, so called
ads. Typically no other, real content is placed on these domains. As domains
associated with malicious activities tend to be parked to monetize the malicious
traﬃc [22], we expect parked domains to constitute a substantial number of
blacklist entries. Unfortunately, parking services have diverging page templates
to present the sponsored ads. As such, it is not straightforward to identify these
sites, e.g., with pattern-matching algorithms. In order to identify parking do-
mains in the blacklists, we thus introduce a generic method to detect parked
domains that can cope with the diversity of parking providers.
3.1 Datasets
We ﬁrst assemble a labeled dataset by manually creating patterns and apply-
ing pattern-matching algorithms [23, 24]. Note that these patterns are far from
complete due to the high diversity of page templates. We leverage the resulting
dataset as ground truth to evaluate our generic detection model for parked do-
main names later on. We generate the labels based on Li et al.’s [22] observation
that parking providers either modify the authoritative NS sections of a domain
to point to dedicated parking NS or employ web-based (i.e., HTTP-, HTML-,
or JavaScript-based) redirections to forward users to the ﬁnal parking content.
Based on our recorded DNS information, we ﬁrst label domains following the
DNS-based type of redirection. That is, we analyze the 233,772 distinct name
servers aggregated while processing the blacklist data. We split the NS hostnames
into tokens and searched for terms indicating parking such as park, sell, and
expired and labeled NS whose hostnames match one of these terms as potential
parking name servers. We monitored a fraction of parked domains that switched
their authoritative NS to a diﬀerent parking provider. As a result, we extracted
the domains that used the parking NS identiﬁed in the previous step from the
aggregated DNS data, requested latest NS records for each domain, and inspected
the most frequently used NS. In addition, we consulted the DNS DB [25], a pas-
sive DNS (pDNS) database. That is, for each identiﬁed parking NS, we requested
Paint It Black: Evaluating the Eﬀectiveness of Malware Blacklists
5
50,000 randomly selected domains the NS was authoritative for, obtained cur-
rent NS records for each domain, and again checked the NS hostnames against
terms indicating parking behavior. Overall, using these techniques and manual
inspection, we identiﬁed 204 NS operated by 53 parking providers.
A minority of parking services employ web-based techniques to redirect users
to the actual parking content. The DNS-based methods discussed so far did not
detect these providers. However, we identiﬁed parked domains that are often
transferred between providers, thus we assume that some domains found in pDNS
data of the previously identiﬁed parking NS at some point have relocated to
providers utilizing web-based redirection techniques. To identify these services,
we extracted 10,000 randomly chosen domains from the pDNS data of each
parking NS, analyzed the domain redirection chains, and identiﬁed 14 patterns of
landing pages [21] to which users are redirected to when visiting parked domains.
These landing pages belong to parking, domain, and hosting providers.
Finally, we use the parking NS and landing pages to manually extract 47
descriptive strings, in the following referred to as identiﬁers (IDs) [21]. These
IDs can be found in the HTTP responses of many parked domains (e.g., <frame
src="http://ww[0-9]{1,2} and landingparent). We use these IDs to create
the parked domains dataset P that consists of 5,000 randomly chosen domains
from the pDNS database we ﬁnd to utilize a veriﬁed parking NS or include at
least one identiﬁer. We further create a dataset B of benign (i.e., non-parked) do-
mains. We utilize the Top 5,000 domains taken from the Alexa Top Ranking [26]
and verify that none of these domains trigger a landing page or ID match.
3.2 Feature Selection and Classiﬁcation
Pattern matching allowed us to identify a subset of all parking services. How-
ever, we seek to identify intrinsic characteristics of parking websites that are
more generic than the manually assembled classiﬁcation described above. We
thus studied subsets of our benign and parked domain sets and identiﬁed two,
respectively, ﬁve generic features based on HTTP and HTML behavior.
The ﬁrst HTTP-based feature is determined by the redirection behavior when