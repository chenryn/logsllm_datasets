0.86
Accuracy
Recall
49
G1. All posts with three selected features
G2. Top 200 posts with two selected features
G3. Randomly selected 100 posts with two features
G4. Top 200 posts with only one feature
G5. Top 100 posts without features
Note that G1, G2, and G3 are insecure posts discovered by Dicos
(i.e., for measuring TP and FP); G4 and G5 are posts that Dicos
determined to be safe (i.e., for measuring TN and FN). We man-
ually verified the discovery results; the manual verification was
performed by two researchers with the ability to determine whether
a code snippet is insecure by reviewing the post and its change
history, which took ten days. The accuracy measurement results
are presented in Table 3 (for C/C++), Table 4 (for Android), and
Table 5 (for both languages).
We confirmed that Dicos showed 91% precision, 93% recall,
and 89% accuracy for insecure posts discovery (see Table 5); in par-
ticular, Dicos showed 93% precision, 94% recall, and 90% accuracy
for C/C++ insecure posts discovery (see Table 3), and 86% precision,
89% recall, and 86% accuracy for Android insecure posts discovery
(see Table 4). The accuracy measurement results of C/C++ and An-
droid showed comparable patterns in the groups from G2 to G5, but
there was a big difference in the verification results for G1. Note
that changes of security-sensitive APIs predominantly appeared in
Android posts while control flow changes hardly occurred. Conse-
quently, the number of posts contained in G1 was small in Android
cases, and most of the posts belonging to G1 are TPs (i.e., insecure),
201Dicos: Discovering Insecure Code Snippets from Stack Overflow Posts by Leveraging User Discussions
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 5:
C++, and Android posts.
Integrated accuracy measurement results for C,
ID
G1
G2
G3
G4
G5
Total
#Total Posts
788
400
200
400
200
1,988
#TP
757
346
162
n/a
n/a
1,265
#FP
31
54
38
n/a
n/a
123
Precision
Recall
Accuracy
#TN #FN
n/a
n/a
n/a
n/a
n/a
n/a
82
318
185
15
97
503
0.91
0.93
0.89
Table 6: Comparison results of insecure posts discovery of
Dicos, Tand [7], and Tcpp [23].
Android posts
(up to Mar. 2016)
Tand [7]
Dicos
(up to Sep. 2018)
Dicos
C/C++ posts
Tcpp [23]
Category
#Discovered insecure posts
2,454
278
7,241
#Discovered insecure posts (containing change history)
2,454
62
7,241
#Commonly discovered insecure posts
50
22
69
36
Coverage of the other tool’s results (containing change history)
0.81
(50/62)
0.02
(50/2,454)
0.61
(22/36)
0.003
(22/7,241)
thus C/C++ cases showed slightly better accuracy than Android
cases.
Although Dicos precisely discovered insecure posts in most
cases, it reported several false results. We found that the main
reasons for FPs are variable name changes in the conditional state-
ments, and comments that incorrectly reported that a code snippet
was insecure (e.g., the comment of post #27368416 contained the
following message: “you have a memory leak ... my apologies, I
am mistaken.”). The cause of FNs is when a security patch pattern
other than the selected features is discovered in the code snippet
(e.g., a type-casting-related vulnerability), without mentioning any
security-related keywords. In addition, when the security issue was
resolved by changing only the data flows, Dicos produced false
negatives. Strict feature selection to reduce FPs will increase FNs,
and selecting more features to reduce FNs will cause more FPs.
We believe that the features used by Dicos work effectively and
maintains a good balance in terms of precision and recall.
5.3 Comparison with the existing approach
In this part, we compared the insecure code snippet discovery re-
sults of Dicos with those of existing approaches [7, 23], to demon-
strate the effectiveness of Dicos.
Tool selection. We reviewed several approaches that discovered
insecure code snippets from Stack Overflow [5, 7, 8, 23, 32, 34]. For
the in-depth comparison, we should be able to use their tools or
experimental results. Thus, we excluded existing approaches that
do not publicly provide tools or experimental results [5, 32, 34]
(despite our requests). Finally, we decided to compare the discovery
results of Dicos to that of the following approaches: Fischer et al. [7]
(Tand), which attempted to discover Android insecure posts, and
Verdi et al. [23] (Tcpp), which attempted to discover C++ insecure
posts from Stack Overflow.
Methodology. We first examine the total number of insecure
posts discovered by each approach (i.e., Dicos, Tand, and Tcpp).
Then, we investigate the coverage of Dicos to their discovery re-
sults (i.e., the number of commonly discovered insecure posts); here
we only consider the posts to which the methodology of Dicos
6https://stackoverflow.com/questions/2736841
can be applied (i.e., the posts should contain at least one change
history). The experimental results are presented in Table 6.
Comparison results (Android). Tand [7] examined 1,165,350
Android answer posts in Stack Overflow (datasets up to March
2016), and then discovered 420 insecure code snippets from 278
unique posts of which 62 posts containing change history. When
we applied Dicos to the same dataset, Dicos discovered 2,454
insecure posts, which is 9 times more than reported by Tand.
Among the 62 insecure posts containing change history discov-
ered by Tand, Dicos discovered 50 out of 62 posts (81%) as insecure;
it is worth noting that Tand covered only 2% of the Dicos discovery
results. The 12 posts that Dicos did not discover are either the latest
revision of the post remains in a vulnerable state (i.e., there is no
security patch in the change history) or only one feature is detected
(i.e., security-sensitive APIs) in the post.
Because Tand only utilizes security-sensitive APIs while Dicos
additionally considers security-related keywords and control flow
changes along with the security-sensitive APIs, there was a con-
siderable difference in the number of discovered insecure posts.
The comparison results affirmed that the approach of Dicos, which
considers the combination of three effective features, could discover
more insecure posts in a wider range than the existing approach
considering only security-sensitive APIs.
Comparison results (C/C++). Tcpp [23] reviewed 72,483 C++
code snippets in Stack Overflow (datasets up to September 2018),
and then discovered 99 insecure code snippets from 69 unique
posts of which 36 posts containing change history. We confirmed
that Dicos discovered 7,241 insecure posts in the same dataset,
which is 105 times more than discovered by Tcpp.
When Tcpp attempted to discover insecure code snippets, they
manually analyzed code snippets based on the selected CWE types,
such as CWE-476 (i.e., null pointer dereference). Because their ap-
proach relied on manual analysis and considered only a few CWE
types, they failed to discover many insecure code snippets that are
actually prevalent on Stack Overflow.
In contrast, Dicos showed substantially better discovery cover-
age than the existing approach. Among the 36 posts with change
history discovered by Tcpp, we confirmed that Dicos could discover
22 of them (61%) as insecure posts. The 14 posts that Dicos failed to
202ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Hyunji Hong, Seunghoon Woo, and Heejo Lee
discover did not show a specific pattern that could be determined
as insecure posts, similar to the cause of FNs of Dicos, as men-
tioned in subsection 5.2. The results demonstrated that Dicos, an
effective feature-based insecure code snippet discovery approach,
can discover insecure code snippets more widely and accurately
than the existing approach.
5.4 Effectiveness of the utilized techniques
In subsection 4.1, we introduced the code snippet pairing technique
utilized in Dicos, which pairs the most similar two code snippets
between two post revisions.
To demonstrate its effectiveness, we compared the result of our
proposed pairing technique with the result of simple pairing tech-
nique based on the code snippet number; notably, sequential num-
bers were assigned to all code snippets in each post of the collected
dataset. Hence, we assume that the simple pairing technique pairs
the code snippets with the same number between two post revi-
sions. We randomly selected 2,000 C/C++ insecure posts, and then
measured the similarity scores using the Jaccard index [26] between
code snippet pairs detected by each technique, respectively. The
results are illustrated in Figure 5.
needed to extract the change history from a post, check whether the
three selected features are contained in the change history of the
collected 668,520 posts, and determine whether a post is insecure.
On average, Dicos took approximately 1.4 s to determine whether
a post contains an insecure code snippet, which is sufficient to
discover insecure code snippets using a large-scale dataset.
6 FINDINGS
From our experiments, we confirmed Dicos discovered 14,719 inse-
cure code snippets from 12,458 posts. In this section, we provide
the analysis results related to the following four questions:
Q1. Are older posts more likely to provide insecure code snippets?
(subsection 6.1)
Q2. Are accepted answer posts more secure than non-accepted
posts? (subsection 6.2)
Q3. What types of insecure code snippets were discovered? (sub-
section 6.3)
Q4. What is the status of reusing insecure code snippets in popular
open-source software? (subsection 6.4)
6.1 Creation time of a post and vulnerabilities
To answer the first question, we analyzed the correlation between
the post creation time and the security of the post. In particular, we
examined the year distribution of secure and insecure posts from
2008 to 2020. The results are depicted in Figure 6.
Figure 5: Similarity scores measured by (1) our proposed
code snippet pairing method and (2) simple method based
on the assigned sequential numbers of code snippets.
It is worth noting that the similarity scores detected by our pro-
posed pairing technique showed a much higher similarity score
than that of the simple sequential number-based pairing technique.
For 222 posts, both techniques provided the same similarity score.
However, for the remaining 1,778 posts, our pairing technique
provided greater similarity scores than that of the simple pairing
technique. This suggests that, even though there are more similar
code snippet pairs, pairings can be made between completely dif-
ferent code snippets if they are simply paired based on a sequential
number. In conclusion, our pairing method, which pairs the two
code snippets with the highest similarity, is effective in the situation
that the order and number of code snippets are frequently changed
during the post update process.
5.5 Performance of Dicos
In our setup, it took a total of 20 hours to download the Google
BigQuery dataset, select posts with change history, and extract
the oldest and latest revision of each post. In addition, it took a
total of ten days to discover insecure posts; this includes the time
Figure 6: Year distributions of secure and insecure posts dis-
covered by Dicos (logarithmic scale).
Interestingly, we confirmed that the proportion of insecure posts
accounted for approximately 2% each year regardless of how old or
new the post is. In other words, our experimental results implies
that there is no clear correlation between post creation time and
security. Incidentally, the fact that insecure posts are constantly
being uploaded to Stack Overflow suggests the need for an auto-
mated approach that can accurately discover insecure posts on
Stack Overflow, such as Dicos.
6.2 Acceptance of a post and security
In general, users are more likely to think that accepted answers
are more reliable (e.g., secure) than non-accepted answers [29].
To answer such a common thought, we investigated the relations
between the acceptance of an answer post and its security. Figure 7
illustrates the results.
From the results, we confirmed that the ratio of insecure posts
was almost the same between accepted (1.67%) and non-accepted
(1.99%) posts. This, presumably, occurred because the security of
203Dicos: Discovering Insecure Code Snippets from Stack Overflow Posts by Leveraging User Discussions
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
(ranked by the number of stars), including OS (e.g., Linux), databases
(e.g., Redis), and media (e.g., FFmpeg) related projects in May 2021.
We decided to leverage the existing large-gap code clone detection
technique (i.e., SourcererCC [21]); this is because we decided that a
large-gap code clone detector would be effective as many parts of
the insecure code snippets (e.g., variable names) could be changed
during the code reuse process. However, as SourcererCC is a code
clone detection technique, not for the vulnerable code clones, it can
report several false results [11]. Therefore, we manually analyzed
the primary detection results and only considered the case where
the insecure code snippet is actually propagated to popular OSS
projects. We applied the same experimental setting for SourcererCC
that used in their paper (i.e., the θ is selected as 0.8).
Detection result. Consequently, we confirmed that 27 insecure
code snippets, discovered by Dicos, were reused in the latest ver-
sions of 151 popular OSS projects (8%). Of these, the most notable
example related to insecure code snippet reuse is the Linux kernel
case, which is introduced in subsection 2.2. For the cases of discov-
ered dangerous code snippets that can affect the security of the
entire software, we have reported to the corresponding vendors7.
Our experimental results indicate that: (1) code snippets are actually
reused in various OSS projects, and (2) a considerable number of
insecure code snippets are included in the latest version of popular
OSS projects. Reusing insecure code snippets can open up an attack
vector in the affected software. As the first step in the prevention of
such undesirable situations, we can apply Dicos for more attentive
insecure code snippet detection.
7 RELATED WORKS
In this section, we introduce a number of related works.
Discovering insecure code snippets. Fischer et al. [7] provided
a security analysis for security-related Android code snippets. They
manually checked whether the code snippet was insecure, and
demonstrated the impact of the use of insecure code snippets in real-
world Android applications. Yanfang et al. [32] proposed ICSD, a