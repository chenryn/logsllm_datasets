title:Covert computation: hiding code in code for obfuscation purposes
author:Sebastian Schrittwieser and
Stefan Katzenbeisser and
Peter Kieseberg and
Markus Huber and
Manuel Leithner and
Martin Mulazzani and
Edgar R. Weippl
Covert Computation
Hiding Code in Code for Obfuscation Purposes
Sebastian Schrittwieser∗, Stefan Katzenbeisser‡, Peter Kieseberg†, Markus Huber†,
Manuel Leithner†, Martin Mulazzani†, Edgar Weippl†
Vienna University of Technology∗
PI:EMAIL
SBA Research†
Darmstadt University of Technology‡
PI:EMAIL
{pkieseberg, mhuber, mleithner, mmulazzani, eweippl}@sba-research.org
ABSTRACT
As malicious software gets increasingly sophisticated and re-
silient to detection, new concepts for the identiﬁcation of
malicious behavior are developed by academia and industry
alike. While today’s malware detectors primarily focus on
syntactical analysis (i.e., signatures of malware samples), the
concept of semantic-aware malware detection has recently
been proposed. Here, the classiﬁcation is based on models
that represent the underlying machine and map the eﬀects of
instructions on the hardware. In this paper, we demonstrate
the incompleteness of these models and highlight the threat
of malware, which exploits the gap between model and ma-
chine to stay undetectable. To this end, we introduce a
novel concept we call covert computation, which implements
functionality in side eﬀects of microprocessors. For instance,
the ﬂags register can be used to calculate basic arithmetical
and logical operations. Our paper shows how this technique
could be used by malware authors to hide malicious code in
a harmless-looking program. Furthermore, we demonstrate
the resilience of covert computation against semantic-aware
malware scanners.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General-
Security and protection
Keywords
code obfuscation; side eﬀects; malware detection
1.
INTRODUCTION
Malware detection is an important research problem in
computer security that strives to spot malicious routines in
software.
In recent years, the threat of malware, viruses,
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIA CCS’13, May 8–10, 2013, Hangzhou, China.
Copyright 2013 ACM 978-1-4503-1767-2/13/05 ...$15.00.
spyware, and trojans has dramatically increased and re-
sulted in a cat-and-mouse game between malware authors
and developers of anti-malware software. The ultimate goal
of malware detectors (commonly known as virus scanners) is
to determine whether a program includes malicious routines
or not. Since the early days of malware defense, this was
done by matching a signature of known malware against the
software to be analyzed [2]. With the increasing amount of
malicious software, the extraction of signatures from mal-
ware samples as the sole detection technique became ineﬃ-
cient as well as insuﬃcient. Over time, other identiﬁcation
methods were developed and used in combination with mal-
ware signatures, which are still widely used by anti-malware
software [9]. Heuristic-based malware detection identiﬁes
malicious code by statistically analyzing its structure and
behavior without depending on prior knowledge of the mal-
ware. However, this approach suﬀers from false positives as
well as false negatives as decisions are based on statistical
models for maliciousness. Furthermore, the rise of concepts
such as polymorphism and metamorphism lead to an entirely
new class of malware, which is resistant against signature-
based detectors, as these focus exclusively on malware syn-
tax and ignore malware semantics. The idea of semantic-
aware malware detection was introduced by Christodorescu
et al. in 2005 [3]. Their approach is based on the deﬁnition
of templates for malicious behavior and is more resistant to
simple obfuscation techniques such as garbage insertions [5]
and equivalent instruction replacement [7] as the semantics
of the code are analyzed.
In this paper, we demonstrate that today’s static mal-
ware detection approaches ignore fundamental knowledge of
the underlying hardware and thus are ineﬀective against our
novel covert computation obfuscation method. Static anal-
ysis techniques for binary code are based on a speciﬁc ma-
chine model in order to understand the functionality of the
analyzed program. Such a model describes how code is in-
terpreted by the machine, i.e., how a speciﬁc instruction
inﬂuences the state of the microprocessor. Based on the en-
tirety of eﬀects that a sequence of instructions has on the
model, its maliciousness is evaluated by the malware detec-
tion software. This model, however, is a simpliﬁed, abstract
representation of the real machine. This simpliﬁcation poses
a problem for model-based code analysis, as abstract mod-
els are not strong enough to entirely simulate the eﬀects of
529the code running on real hardware. It is possible to reﬁne
machine models and make them more expressive, but this
results in a tradeoﬀ between correctness and complexity.
In a malware detection context, the complexity of testing
whether a given code matches a model for malicious behav-
ior has to be low enough for the problem to be decidable
in real time. The fundamental dilemma of static malware
detection is that, on the one hand, code can be made arbi-
trarily complex with acceptable performance losses, while,
on the other hand, a model strong enough to perform a
complete evaluation of code semantics would reach an im-
practical level of complexity for real-life applications.
As main contributions of this paper we introduce a novel
approach for code obfuscation called covert computation,
based upon side eﬀects in today’s microprocessor architec-
tures. We further show feasibility of our concept based on
instruction side eﬀects in the ﬂags register as well as LOOP
and string instructions. We ﬁnally demonstrate how our ap-
proach fundamentally raises the bar for semantic-aware code
analysis.
2. RELATED WORK
The use of code obfuscation to prevent reverse engineering
of any given software is a well-studied ﬁeld [4, 17]. A formal
concept of code obfuscation has been deﬁned by Barak et
al. [1]. Although this work shows that a universal obfuscator
for any type of software does not exist and perfectly secure
software obfuscation is not possible, various types of code
obfuscation are still used by today’s malware to “raise the
bar” for detection.
Various malware obfuscation approaches presented in the
literature follow the concept of polymorphism [13], which
hides malicious code by packing or encrypting it as data that
cannot be interpreted by the analysis machine. Thus, an un-
packing routine has to be used to turn this data back into
machine-interpretable code. A number of approaches have
been suggested to defeat this obfuscation technique, such as
detecting malicious code with model checking [11] or sym-
bolic execution [6]. Today’s malware detection systems eval-
uate the maliciousness of a program based on structural and
behavioral patterns [10]. Christodorescu et al. [3] ﬁrst in-
troduced the concept of semantic-aware malware detection.
In their paper, the authors deﬁne formal semantics for the
maliciousness of programs and a semantic-aware matching
algorithm for malware detection based on them. Templates
for malicious behavior are deﬁned and matched against the
potential malware. If both have the same eﬀect on memory,
the binary is identiﬁed as malicious. This approach can deal
with simple forms of obfuscation but does not recognize in-
struction replacements based on patterns completely. The
concept was further formalized by Preda et al. in 2007 [14]
and 2008 [15].
Recently, Wu et al. [18] introduced the concept of mimi-
morphism, which aims at obfuscating malicious code against
both static and statistical detection systems. In the area of
code obfuscation, various approaches for hiding a program’s
semantics can be found. In recent literature on code obfus-
cation, several authors have proposed the removal of instruc-
tion patterns in order to increase de-obfuscation complexity.
Recent work by De Sutter et al. [7] on avoiding characteristic
instruction patterns normalizes the distribution of instruc-
tions used in a program by replacing rare ones with semanti-
cally equivalent blocks of more frequently used instructions
with equivalent blocks of less frequently used instructions.
The drawback to this approach is, however, that an equal
distribution of instructions used by a program is statistically
unlikely and therefore easily detectable for a code analyst.
Furthermore, semantic-aware detection approaches such as
described in [3] can implement the replacement patterns in
their templates for malicious behavior.
Giacobazzi [8] ﬁrst theoretically discussed the idea of mak-
ing code analysis more diﬃcult by forcing the detection sys-
tem to become incomplete. However, no practical approach
of this idea was given in the paper. Moser et al. [12] dis-
cussed the question whether static analysis alone allows re-
liable malware detection.
3. APPROACH
All semantic-aware malware identiﬁcation techniques fol-
low the same basic approach. The classiﬁcation of malicious-
ness is based on a model of the underlying system (i.e., the
microprocessor), which describes how a speciﬁc instruction
modiﬁes the system’s state. The quality and completeness
of the model are crucial for a high identiﬁcation rate. An
incomplete model is not able to map all eﬀects that an in-
struction has on the hardware and thus cannot evaluate its
impact on the system and the system’s state after execut-
ing the instruction. Current models for malware detection
are focused on the instruction layer but do not fully map all
eﬀects of an instruction on the model. Today’s microproces-
sors are highly complex systems with hundreds of diﬀerent
instructions that inﬂuence the processor’s state.
In general terms, there are two types of models for us
to consider. First, a human analyst deﬁnes his or her own
model of the machine when trying to understand the mean-
ing of a program’s code. Given that the analyst knows the
purpose of a speciﬁc instruction, he or she can perceive the
code’s meaning on a semantic layer and draw conclusions
concerning the functionality of a sequence of instructions.
However, it is drastically more diﬃcult to keep the program’s
entire state, which is modiﬁed constantly while executing in-
structions, in mind. Thus, the human model of a machine
can be described as a very basic semantic representation.
The second model that has to be considered is the one of an
automatic analysis tool, which makes a decision regarding
the maliciousness of a program based on predeﬁned tem-
plates and patterns. If side eﬀects are not implemented in
this model, its impact cannot be evaluated and is missed by
the analysis tool.
In order to hide the implementation of a speciﬁc func-
tionality of a program, we identiﬁed the possibility of im-
plementing it based on features of the processor that are
not described by its model and thus not evaluated. Ana-
lyzing such code on the semantic layer would not identify