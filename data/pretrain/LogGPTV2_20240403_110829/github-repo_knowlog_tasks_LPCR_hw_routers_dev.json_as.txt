 ],
 [
  "LDP/6/LDP_SOURCE_TRACE_EVENT: Source tracing for packet loss on the LDP LSP was performed. (ComponentName = [ComponentName], Inlabel = [Inlabel], Info = [Statistic_info]) In VS mode, this log is supported only by the admin VS. In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nThe local device received a request for source tracing for packet loss on the LDP LSP."
 ],
 [
  "IPSEC/2/hwIPSecPkiCrlExpired_active: the crl is nearly expired. (CrlStartTime=[CrlStartTime], CrlFinishTime=[CrlFinishTime], CrlIssuer=[CrlIssuer]) In LS mode, this log is supported by both the admin LS and service LSs.",  "Possible Causes\nThe CRL is to expire."
 ],
 [
  "OPSA/6/SCRIPT_LOG: OPS: [STRING1] (user=\"[STRING2]\", session=[ULONG]).",  "Diagnostic log information is recorded when commands are delivered before a certificate is activated."
 ],
 [
  "LSPM/3/GTSMMSGSENDFAIL:Failed to send GTSM policy.(Protocol=[STRING], Flag=[STRING], Address=[STRING])",  "Internal causes of system malfunctions."
 ],
 [
  "PIM/4/PIM_ROUTE_THRESHOLD_clear: The number of existed routing entries falls below the global lower threshold.(LimitType=[LimitType], AddressFamily=[AddressFamily], CurrentCount=[CurrentCount], LimitCount=[LimitCount], ThresholdCount=[ThresholdCount], ReasonType=[ReasonType]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\n\u00b7Cause 3:The percentage ratio of created PIM entries on the device to the specified limit fell below the alarm clear threshold.\n\u00b7Cause 4:The percentage ratio of created PIM entries on the device to the specified limit fell below the alarm clear threshold."
 ],
 [
  "DOT1X/4/CONFIGURATE_DOT1X_URL_FAILED: Failed to configure dot1x url.([STRING])",  "The authentication redirection URL usingdot1x urlurl-stringbelongs to the functions delivered globally, and is not supported on SA series boards."
 ],
 [
  "FIB/4/hwBoardFwdResThresholdExceed_active: The board forwarding engine resources exceeded the threshold. (EntityPhysicalIndex=[EntiyPhysicalindex], EntPhysicalIndex=[EntPhysicalindex], EntPhysicalName=[EntPhysicalName], Slot=[SlotStr], ReasonId=[ReasonId], ReasonDescription=[Reason]) In VS mode, this log is supported only by the admin VS. In LS mode, this log is supported only by the service LSs.",  "Possible Causes\n\u00b7Cause 15: The percentage of ND indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 16: The percentage of tunnel indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 17: The percentage of BFD indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 18: The percentage of VPLS LearnIDs exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 19: The percentage of VSI indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 20: The percentage of NS indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 21: The percentage of ring indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 99: The number of tokens on the board exceeds the threshold of the forwarding engine specification.\n\u00b7Cause 103: The percentage of AT indexes exceeded the upper threshold supported by the forwarding engine.\n\u00b7Cause 325: The number of resources in the IPv4 GRE tunnel decapsulation table exceeded 95% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 326: The number of resources in the IPv6 GRE tunnel decapsulation table exceeded 95% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 375: The number of TM pool-0 SQ resources usage has exceeded 90%.\n\u00b7Cause 376: The number of TM pool-1 SQ resources usage has exceeded 90%.\n\u00b7Cause 377: The number of slot pool-0 SQ resources usage has exceeded 90%.\n\u00b7Cause 378: The number of slot pool-1 SQ resources usage has exceeded 90%.\n\u00b7Cause 379: The number of TM pool-0 GQ resources usage has exceeded 90%.\n\u00b7Cause 380: The number of TM pool-1 GQ resources usage has exceeded 90%.\n\u00b7Cause 399: The number of resources in the IPv4 VXLAN tunnel decapsulation table exceeded 90% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 410: The number of VNI*peer resources exceeded 90% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 577: The number of MAC accounting statistics entries exceeds 90% of the specification of the forwarding engine.\n\u00b7Cause 608: The number of resources in the 4over6 tunnel decapsulation table exceeded 95% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 609: The number of resources in the IPv6 address table exceeded 95% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 664: The number of NHRP peer tables exceeds 95% of the forwarding engine specification.\n\u00b7Cause 666: The number of dynamic NHRP peer statistical entries exceeds 95% of the forwarding engine specification.\n\u00b7Cause 668: The number of used resources in the TNL6_OTNLINFO table exceeded 95% of the upper limit supported by the forwarding engine.\n\u00b7Cause 700: The number of dual-device hot-backup state indexes for multicast exceeded 95% of the forwarding engine resource specification.\n\u00b7Cause 711: IPv4 Layer 3 multicast Mre Stat resources useage exceeded 95% of the specification of the forwarding resources.\n\u00b7Cause 712: IPv6 Layer 3 multicast Mre Stat resources useage exceeded 95% of the specification of the forwarding resources.\n\u00b7Cause 713: The number of IPv4 multicast MreExt table exceeded 95% of the forwarding engine resources.\n\u00b7Cause 714: The number of IPv6 multicast MreExt table exceeded 95% of the forwarding engine resources.\n\u00b7Cause 718: The number of the applied virtual user-queue resources exceeded 90% of the specifications supported by the forwarding engine of a board.\n\u00b7Cause 719: The number of the applied virtual user-group-queue resources exceeded 90% of the specifications supported by the forwarding engine of a board.\n\u00b7Cause 720: The number of the applied virtual sub-port-queue resources exceeded 90% of the specifications supported by the forwarding engine of a board.\n\u00b7Cause 723: The number of used IPv6 Layer 3 unicast SRv6 table exceeds 95% of the forwarding engine of the board.\n\u00b7Cause 724: The number of used IPv4 Layer 3 unicast DSVPN table resources exceeds 95% of the forwarding engine specification of an interface board.\n\u00b7Cause 732: The number of MRE statistics table resources for the IPv4 Layer 3 multicast source clone service exceeds 95% of the upper limit.\n\u00b7Cause 733: The number of IP traffic statistics resources exceeds 95% of the specification of the forwarding engine resources.\n\u00b7Cause 736: The number of multicast leaf nodes exceeds 95% of 4096.\n\u00b7Cause 771: The number of BIER VPN forwarding tables in the system exceeded 95% of the forwarding engine resource specification.\n\u00b7Cause 774: The number of BIFT entries exceeded 95% of the upper limit allowed by the board.\n\u00b7Cause 777: The number of L3VPN instances on the board exceeded 95% of the forwarding engine resource specification.\n\u00b7Cause 780: The number of MPLS-in-UDP address verification services exceeded 95% of the threshold supported by the forwarding engine.\n\u00b7Cause 781: The number of resources in the discoverflow table exceeded 90% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 782: The number of resources in the esqm table exceeded 90% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 832: The number of LocalArpv6 entries exceeds 95% of the forwarding engine specification.\n\u00b7Cause 835: The number of local SID tables for SRv6 tunnels exceeded 95% of the forwarding engine specification.\n\u00b7Cause 837: The number of remote sid entries exceeds 95% of the forwarding engine specification.\n\u00b7Cause 839: The number of SCAN tables used to store traffic statistics collected through SRv6 TE Policy telemetry at an interval of 30s exceeds 95% of the upper threshold.\n\u00b7Cause 841: The number of SCAN tables used to store traffic statistics collected through SRv6 TE Policy telemetry at an interval of 1s exceeds 95% of the upper threshold.\n\u00b7Cause 843: The number of RE entries regarding the service that redirects public network traffic to SRv6 Policies exceeds 95% of the maximum number of entries supported.\n\u00b7Cause 845: The number of Segment list entries exceeds 95% of the upper threshold.\n\u00b7Cause 847: The number of statistical entries of SRv6 TE Policies exceeds 95% of the upper threshold.\n\u00b7Cause 849: The number of resources in the IPv6 VXLAN tunnel decapsulation table exceeded 95% of the maximum number of resources allowed by the forwarding engine.\n\u00b7Cause 851: The number of SRv6 SFC Layer 3 forwarding RE entries exceeds 95% of the upper threshold.\n\u00b7Cause 853: The number of SRv6 SFC Layer 2 forwarding RE entries exceeds 95% of the upper threshold.\n\u00b7Cause 860: The number of slot inbound 8queue mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 861: The number of slot inbound 8queue-enhance mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 862: The number of TM inbound 8queue mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 863: The number of TM inbound 8queue-enhance mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 864: The number of slot outbound 4queue mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 865: The number of slot outbound 8queue mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 866: The number of slot outbound 8queue-enhance mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 867: The number of TM outbound 4queue mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 868: The number of TM outbound 8queue mode user-queue resources usage has exceeded 90%.\n\u00b7Cause 869: The number of TM outbound 8queue-enhance mode user-queue resources usage has exceeded 90%."
 ],
 [
  "LACP/2/hwLacpPDUChange_clear: The LACP member interface's status changed from unselected to selected. (TrunkIndex=[TrunkIndex], PortIfIndex=[PortIfIndex], TrunkId=[TrunkId], TrunkName=[TrunkName], PortName=[PortName])",  "Cause 1:Actor system ID changed in the received PDUCause 2:Actor system priority changed in the received PDUCause 3:Actor key changed in the received PDUCause 4:Actor port priority in the received PDUCause 5:Actor port number changed in the received PDUCause 6:Actor state's aggregation bit in the received PDUCause 7:Actor aggregation delay changed in the received PDUCause 8:Actor state's synchronization bit in the received PDUCause 9:Actor state's expire bit in the received PDUCause 10:Partner system ID changed in the received PDUCause 11:Partner system priority changed in the received PDUCause 12:Partner key changed in the received PDUCause 13:Partner port number changed in the received PDUCause 14:Partner port priority changed in the received PDUCause 15:Partner state's aggregation bit changed in the received PDU"
 ],
 [
  "SPR/4/LINKPATH_DELETE: The user chooses [STRING] when determining whether to delete link-path all.",  "The user determines whether to delete all link paths. If the user selects yes, all link paths will be deleted. If the user selects no, link paths will not be deleted."
 ],
 [
  "VFSTRAP/4/STORAGE_DEVICE_SUCC :OID [OID] Copy successfully.(Serialnumber=[INTEGER], Source file = [STRING1], Destination file = [STRING2])",  "A trap message is sent when the instance createdby huaweiFlhOpTable is finished."
 ],
 [
  "LSPM/6/NOTIFYLSPMDSTEEVT:Notified LSPM of TE-Class change event. (Event=[STRING])",  "The TE-Class mapping table was changed."
 ],
 [
  "CLI/5/CLIEVENTRECORD: Recorded cli event information. (Task=[Task], Ip=[Ip], VpnName=[VpnName], User=[User], AuthenticationMethod=\"[AuthenticationMethod]\", Command=\"[Command]\", Result=[Result].)",  "The command entered by a user matched the command event defined by the user."
 ],
 [
  "LDP/6/NOTIGRSTART:The system notified L2VPN and other features that LDP system-level GR processing startedafter LDP GR was enabled.",  "LDP notified the GR event to the L2VPN."
 ],
 [
  "ENTITYTRAP/1/POWERUNUSEABLE:OID [oid] Power change to unusable status.(Index=[INTEGER1], EntityPhysicalIndex=[INTEGER2], PhysicalName=\"[OCTET]\", EntityTrapFaultID=[INTEGER3])",  "Cause 1: The device's power cable was removed.Cause 2: A power module was faulty."
 ],
 [
  "LSPM/2/MPLSLSPTOTALCOUNTEXCEED:OID [oid] The lsp countreaches the upper limit.(hwMplsLspProtocol=[integer], hwMplsLspTotalCount=[integer])",  "The number of the current hwMplsLspProtocol LSPsreached the upper limit."
 ],
 [
  "NATPT/4/INVALID_CMD:Invalid command.",  "The command word was invalid."
 ],
 [
  "ISIS/6/ROUTE_BE_DELETED_BY_PURGE_CLEAR: OID [oid] IS-IS routes advertised by the local device were not deleted by another device. (SysInstance=[integer], HostName=[string], HostIpAddress=[string], SystemID=[opaque], SysLevel=[integer])",  "The IS-IS LSPs advertised by the local device are no longer purged by another device."
 ],
 [
  "L2VPN/3/hwL2vpnOamMismerge_active: OAM reported a Mismerge alarm. (ServiceType=[ServiceType], ProtocolType=[ProtocolType], VcID=[VcID], VcType=[VcType], PeerAddr=[PeerAddr], IfIndex=[IfIndex], PwMaster=[PwMaster], RmtSiteID=[RmtSiteID], InLabel=[InLabel], OutLabel=[OutLabel], IfName=[IfName], VsiName=[VsiName]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nCause 1: MPLS OAM configurations were incorrect.\nCause 2: The PW detected by OAM became faulty."
 ],
 [
  "GTL/4/EMERGENCYSTOP: OID [OID] License emergency isstopped after 7 days",  "The validity period of the emergency state expires."
 ],
 [
  "FEI_L2/4/hwModeChannelBandwidthAlarm_active: The total bandwidth of the channelized sub-interfaces on the same physical interface has exceeded the maximum available bandwidth of the physical interface.(Interface=[IfIndex], Bandwidth=[Bandwidth], SubIfBandwidthSum=[SubIfBandwidthSum], InterfaceName=[InterfaceName]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nThe total bandwidth of the channelized sub-interfaces on the same physical interface has exceeded the maximum available bandwidth of the physical interface."
 ],
 [
  "DEV/4/ENT_OVA_UNINSTALL: Succeeded in uninstalling [STRING] Container.",  "An APP has been uninstalled from the container successfully."
 ],
 [
  "TCP/4/SOCKET_TCP6_RCV_KC_AUTHEN_FAIL: Receive TCP6 KeyChain authentication failed. (tcpConnLocalAddress=[tcpConnLocalAddress], tcpConnLocalPort=[tcpConnLocalPort], tcpConnRemAddress=[tcpConnRemAddress], tcpConnRemPort=[tcpConnRemPort], hwTCPProtocol=[hwTCPProtocol], hwTCPVrfName=[hwTCPVrfName])",  "Keychain authentication failed on the packets received for TCP6 connection setup."
 ],
 [
  "OSPF/6/RECV_DIFF_GRACE_LSA: OSPF [ProcessId] receives a grace LSA different from the one in LSDB on interface [IfName].",  "When GR was being performed on the restarter, the helper received a GR request from the restarter."
 ],
 [
  "WLAN/6/STA_OFFLINE: Station went offline from the AP. (StaMAC=[OPAQUE], SSID=[STRING], ApMAC=[OPAQUE])",  "An STA went offline from the AP."
 ],
 [
  "VRRP/5/STATECHANGECHECK: The check failed when theVRRP state changed from Backup to Master. (Interface=[Interface],VrId=[VrId], InetType=[InetType], Reason=[Reason])",  "When the status of the VRRP backup group changed fromBackup to Master, the system found that services were not restoredand did not allow the VRRP backup group to perform a status switchback."
 ],
 [
  "OSPF/3/GR_EXIT_GR_UNSU:OSPF [process-id] exited GR Unsuccessfully.",  "The OSPF process failed to exit from GR."
 ],
 [
  "ISIS/6/RCV_RPRMSG:The RPR message was received from RM. (MessageType=[ULONG], IfnetIndex=[STRING], NodeNumber=[ULONG])",  "Received an RPR message from the RM, which was helpful for locating problems between modules."
 ],
 [
  "GTL/4/FEATURECHECKFAIL: License can't be verified, change for authentic license before time exhaust.",  "A license file is damaged.The license file and the device mode do not match."
 ],
 [
  "MPLS_LSPM/2/hwMplsOamMisMerge_active: The tunnel receives a MisMerge alarm. (SessionTunnelId=[SessionTunnelId], LocalLspId=[LocalLspId], IngressLsrId=[IngressLsrId], EgressLsrId=[EgressLsrId], TunnelName=[TunnelName], SignalingProtocol=[SgnlPrtcl], SignalledTunnelName=[SignalledTunnelName]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nBoth correct and incorrect packets are received in three consecutive periods."
 ],
 [
  "DEVM/4/hwBootloaderPwdEmpty_active: The password of bootloader is empty. (EntPhysicalIndex=[EntPhysicalIndex], EntPhysicalName=[EntPhysicalName], EntityType=[EntityType])",  "The password of bootloader is empty."
 ],
 [
  "LINE/4/LOCK_IP: The IP address of request message was locked because authentication failed. (SourceIPType=[STRING], SourceIP=[STRING])",  "The Telnet, STelnet, or SFTP service was enabled on the device, and the client failed to be authenticated."
 ],
 [
  "CSPF/3/IGP_NWLSA_INFONULL: Received a Network-LSA with null information from IGP [IgpName].",  "Network LSA event does not contain any network lsa information."
 ],
 [
  "OSPF/2/OSPF_ROUTE_BE_DEL_BY_PURGE_INEXACT_active: OSPF routes advertised by the local device were deleted by another device, and the possibly faulty device did not support OSPF flush LSA source trace. Log in to the possibly faulty device. If the device is deleting routes, reset or isolate it from the network. Otherwise, check other devices. Neither of the devices displayed in the display ospf flush-source-trace analysis-info command output is the faulty device. (SysProcessId=[hwOspfv2ProcessIdIndex], HostName=[hwOspfv2PurgeHostName], HostIpAddress=[hwOspfv2PurgeIpAddress], RouterID=[hwOspfv2PurgeRouterId], Area=[hwOspfv2AreaId], FlushLsaNum=[hwOspfv2FlushLsaNum], AffectedNodeNum=[hwOspfv2AffectedNodeNum], TotalNodeNum=[hwOspfv2TotalNodeNum], RuledOutDeviceNum=[hwOspfv2RuledOutDeviceNum], Interval=[hwOspfv2PurgeStatPeriod]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nThe OSPF LSAs advertised by the local device were flushed by a remote device, and possibly faulty devices do not support OSPF flush LSA source tracing."
 ],
 [
  "MSTP/1/TOPOLOGY_CHANGE: Bridge topology changed.",  "Cause 1: The network topology changed because a new link was added into the network topology. Cause 2: The network topology changed because interfaces went Up or Down. Cause 3: A fault occurred on the network."
 ],
 [
  "L2VPN/4/hwPWVcSwitchWtoPNoTrap: The status of the PWE3 VC turned protecting from working. (VcId=[VcId], VcType=[VcType],PeerAddress=[PeerAddress], CtrlWord=[CtrlWord], SecondaryPwId=[SecondaryPwId], HWL2VpnStateChangeReason=[HWL2VpnStateChangeReason], InterfaceName=[InterfaceName], StateChgTime=[StateChgTime]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nThe PWE3 VC status changed from working to protection."
 ],
 [
  "RSVP/6/DISABLE_MPLS:RSVP was disabled successfully in the MPLS view.",  "Succeeded in disabling RSVP in the MPLS view."
 ],
 [
  "ISIS/6/JOIN_L1_ADDR_FAIL:ISIS [process-id] failed to join all Level-1 multicast group for the interface [interface-name].",  "Failed to join a multicast group."
 ],
 [
  "PKI/4/BUILTINCA_IMPORT_OK: Importing BUILTINCA certificatefile ([string]) succeeded.",  "The SSL decryption certificate succeededto be imported."
 ],
 [
  "PKI/4/hwPKIUpdateLocalCertSucCmp_active: Updating the local certificate through CMPv2 succeeded. (LocalCertIssuer=[LocalCertIssuer], LocalCertSubject=[LocalCertSubject], NewLocalCertStartTime=[NewLocalCertStartTime], NewLocalCertFinishTime=[NewLocalCertFinishTime]).",  "After the CMPv2-based automatic certificate update function was enabled, the switch successfully updated the local certificate when the update time arrived."
 ],
 [
  "LSPM/3/MPLSTUNOBKDOWN:OID [oid] The ordinary LSP ofthe tunnel changes to Down. (SessionTunnelId=[INTEGER], TunnelInstIndex=[integer],IngressLsrId=[integer], EgressLsrId=[integer], mplsTunnelIfName=[octet], hwMplsTunnelDownReason=[integer], hwMplsTunnelDownLSRId=[binary],hwMplsTunnelDownIfAddrType=[integer], hwMplsTunnelDownIfAddr=[binary])",  "Cause 1: The interface went Up.Cause 2: Theconfiguration of the tunnel was deleted.Cause 3: The link wasfaulty.Cause 4: An LSP with higher priority became Up."
 ],
 [
  "OSPF/6/SMB_NSR_PROC_INFO: The SMB notified the AMB to activate or free process [process-id]. (InstanceId=[USHORT])",  "The OSPF process was restarted during NSR."
 ],
 [
  "AM/4/hwUsedIPExhaust_clear: The number of IP addresses in the IP pool is under the exhaust. (PoolIndex=[PoolIndex],PoolName=[PoolName]) In LS mode, this log is supported only by the service LSs.",  "Possible Causes\nAfter some IP addresses in the address pool were reclaimed, the number of IP addresses in the address pool fell below 90% of the threshold."
 ],
 [
  "LSPM/3/MPLSTUNNELHSBSWITCH:OID [oid] Main LSP of Tunnelswitches to backup LSP in HSB.(SessionTunnelId=[integer], LocalLspId=[integer], IngressLsrId=[integer], EgressLsrId=[integer],MplsTunnelAdminStatus=[integer], MplsTunnelOperStatus=[integer])",  "The primary LSP was Down and the backup LSP wasin use. The backup mode was HSB."
 ],