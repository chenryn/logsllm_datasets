the fast timing attack is necessary.
We found 4175 gadgets in the Apache executable, although none
of them has access to a system call or a sensitive function. We used
20 of these gadgets to implement the ROP loop. The actual ROP
loop is illustrated in Figure 10 in the appendix. It implements a loop
with the number of iterations equal to 500,000 times the pointed
value. By redirecting the loop iterator into libc and estimating
the bytes, we determine how it is shifted.
The ROP gadgets in the Apache executable, however, are not
enough to build a practical payload (e.g. an uploader) because they
do not have access to a system call. Since the location of libc
linked to Apache is unknown, the attacker does not have access to
system calls within libc either. Normally, the attacker needs an-
other vulnerability for memory disclosure to locate libc or system
calls within libc to build the complete attack. We demonstrate
how just this one vulnerability can be used for both purposes, i.e.,
leaking instructions within libc and hijacking control using the
actual payload. This is in spite of the fact that the vulnerability is
a buffer-over-ﬂow vulnerability, not a buffer-over-read one. Once
we ﬁnd the offset of libc, we will then use the same vulnerability
to inject a ROP payload that accesses the system calls in libc to
achieve the malicious behavior.
In our measurement, we ﬁrst measured 20 bytes at the chosen
location. In fact, the bytes were not enough to uniquely identify
the location in libc as two locations matched those 20 bytes. By
inspecting the 21st and 22nd bytes at those two locations in our lo-
cal copy of libc, we realized that since the 22nd byte has very
different values at those two locations, measuring two more bytes
would uniquely identify the location. By measuring the two subse-
quent bytes, we determined that the location is indeed the 49th byte
in the __argp_fmtstream_putc function. Figures 9 shows
the actual bytes in that location and the estimated bytes over wire-
less and wired networks. Since we know from our local copy of
libc that the 24921st byte after that is a system call (located in
the __lll_lock_wait_private function), we used it to cre-
ate the uploader which was the original attack goal.
Our measurement illustrates the strength of timing attacks as
only 22 noisy bytes were enough to uniquely ﬁnd the location in
libc, a library of more than 1.3 MB. Note that in fact we were a
little unlucky in our attack since for the majority of the cases only
13 bytes are enough. Since the gadgets in the Apache executable
are already known, this attack takes about 30.58 sec (22×1.39 sec).
6.4 Medium-Grained ASLR
Function permutation such as the one implemented by ASLP
[26] is a medium-grained form of ASLR in which function loca-
tions are also randomized within a library.
In this case, we still need to ﬁnd a system call, but since the
Apache executable itself is also randomized, we do not have access
to the ROP loop gadgets. Our technique for attacking function per-
mutation is as follows. We redirect the vulnerable loop iterator to a
chosen location to measure a number of bytes using the slow tim-
ing attack. We measure enough bytes to ﬁngerprint the function.
We know from our undiversiﬁed copy which functions contain a
system call and which ones do not. If the function contains the sys-
tem call, we are done. If it does not, we skip enough bytes to pass
that function and start to measure the next function. We repeat this
process until we ﬁnd a system call.
The amount of measurement necessary for attacking medium-
grained ASLR is the expected number of measured bytes needed
to determine what function some piece of code is (13 bytes), mul-
tiplied by the expected number of functions we need to discover
before ﬁnding one that has a system call gadget. We determine this
latter value to be the number of functions in libc (3309), divided
by the number of system call gadgets (60). Therefore the expected
number of measured bytes needed is 717.
We performed this attack with different function permutations
four times. The number of bytes measured before we found the
system call for the four experiments were 303, 2661, 806, and 441
which is consistent with our expected number of measures. Since
this attack on average requires 717 bytes with slow timing attack,
it takes about 8.6 hours to complete on the LAN (717 × 43.2 sec).
6.5 Fine-Grained ASLR
Fine-grained form of ASLR can randomize code at the granu-
larity of basic blocks. One such implementation is Binary Stir-
ring [45]. Since basic blocks can be very small in nature, we con-
servatively estimate that every instruction in the basic block would
need to be measured. As there are 218930 instructions in libc,
we estimate that 3649 libc instructions would need to be measured
before ﬁnding a system call. Furthermore, since the expected size
of an instruction is 3.8 bytes, we expect 13866 measured bytes are
needed to ﬁnd a system call.
An alternative approach would be to try to ﬁnd enough gadgets
in Apache to build a ROP loop again. Note that since ﬁne-grained
ASLR also randomizes the basic blocks in the executable, the ROP
loop we constructed for coarse-grained ASLR is not available to
us because we no longer know the location of its gadgets. The
most difﬁcult gadget to ﬁnd is the conditional jump gadget neces-
sary for building the loop. A convenient way of building the con-
ditional jump is by using instructions that use the carry ﬂag as an
input which are: ADC (add with carry), SBB (subtract with bor-
row), RCR, and LCR (right and left rotations with carry) in x86.
Unfortunately there are only 27 instances of these instructions in
Apache. Since Apache’s binary is 831168 bytes, the expected num-
ber of measured bytes before we are able to construct the ROP loop
is 30784 in this alternative approach. This is more than what is
needed to ﬁnd a system call using slow timing attack only (13866
bytes), so in our experiments we use the slow timing approach.
We performed this attack with different basic block randomiza-
tion twice. The number of bytes measured before we found the
system call for the two experiments were 7049 and 22942 which is
consistent with our expected number of measurements.
Since this attack on average requires 13866 bytes with slow tim-
ing attack, it takes about a week to complete on the LAN (13866 ×
43.2 sec). This time may look long, but the strength of this attack
over brute-force or other memory disclosure attacks may justify its
usage for an attacker. First, this attack does not rely on the weak-
nesses of speciﬁc ﬁne-grained ASLR implementations. Second, it
does not required a JIT environment such as the one used in JIT-
ROP [36]. Third, it does not require an additional memory disclo-
sure vulnerability. Fourth, it does not require a forking server and
does not introduce numerous crashes such as the BROP attack [6].
6.6 NOP Insertion
If NOP insertion is used to diversify the code, we can ﬁrst mea-
sure a sample of instructions to discover at what rate NOPs are
inserted. For this experiment, we have setup the multicompiler de-
veloped by Jackson et al. [23] to perform our measurements. Our
measurements show that after estimating about 30 instructions, the
NOP insertion rate can be determined accurately. Since the ex-
pected size of an instruction is 3.8 bytes, the NOP insertion rate
can be determined after estimating 114 bytes on average.
After the NOP insertion-rate is determined, the approximate lo-
cation of every other instruction is known by the following formula:
Diversif ied Loc. ≈ U ndiversif ied Loc. +
(U ndiversif ied Of f set × N OP Insertion Rate)
As a result, we can directly jump to the system call in function
__lll_lock_wait_private. To account for the error in the
location because of the random NOP insertion, we scan 10 instruc-
tions before and after the diversiﬁed location to align correctly (76
bytes on average). Since this attack on average requires 190 bytes
with slow timing attack, it takes about 2.2 hours to complete on the
LAN (190 × 43.2 sec).
Note that the ﬁne-grained ASLR achieves the best protection
against this attack, because by leaking a number of bytes at a mem-
ory location, one cannot learn about any other part of memory. If
the code has more dependencies (e.g. pointers from some locations
to the others), the attack can succeed with fewer bytes.
7. POSSIBLE DEFENSES
Complete memory safety can mitigate the impact of the timing
and fault analysis attacks. Note that attacks such as the Crafted In-
put timing attack can still leak information about the code, but such
information will have little value in building a payload. However,
complete memory safety with temporal and spatial safety proper-
ties incurs a very high performance overhead (often multiple times
slowdown) which makes it impractical for many applications [39].
Previous work has suggested re-randomizing code pages dur-
ing execution as a way to mitigate information leaks, as an exploit
could be rendered ineffective by re-randomizing before it gets the
opportunity to actually execute [36].
Weaker forms of memory defenses can mitigate certain types
of timing and fault analysis attacks with lower performance over-
head. However, the problems of weaker memory defenses include
still relatively high performance overhead, false positive/negatives,
source/binary compatibility, and modularity support [39]. Exam-
ples include data integrity techniques such as WIT [3], which stop
the Overwrite Data/Code Pointer attacks, and control ﬂow integrity
[1], which stop Overwriting Code Pointer attacks.
Some weaker memory defenses, similar to code diversiﬁcation,
rely on randomization and secrets to be kept. Data Space Ran-
domization [4] can help mitigate the Overwrite Data/Code Pointer
and Overwrite Data attacks.
Instruction set randomization [25]
can help mitigate Overwriting Data Pointer as the attacker will
only learn the encrypted code. Note that these defenses can them-
selves be attacked using the same side channel attacks described in
this paper. For example, an attacker could conduct an Overwrite
Data Pointer attack and an Overwrite Code Pointer attack on in-
struction set randomization, this would reveal both the encrypted
and decrypted code, and then if the encryption scheme is a sim-
ple XOR [25, 37], the attacker can learn the secret key. However,
since these defenses are not widely deployed in today’s computing
systems, we leave a systematic analysis to future work.
Both Crafted Input and Overwrite Data timing attacks rely on
inserted or changed instructions increasing execution time. A pos-
sible defense then is to insert code that does not affect execution
time. For example, inserting dead code that cannot be executed
without hijacking control ﬂow [18] can cause an attacker to mis-
judge the location of gadgets.
Side channels are often mitigated by causing every measurement
to be the same, thus destroying the measurement’s distinctiveness.
For example, cryptographic timing side channels can be mitigated
by causing every execution to take the exact same amount of time.
Code diversiﬁcation techniques currently do not explicitly attempt
to mitigate side channels, although some diversiﬁcation techniques
can affect them. For example, NOP insertion [23] will affect the
size and timing of functions. Although, NOP insertion or similar
techniques do not try to make all functions have the same size and
timing measurements and currently do not mitigate side channels,
it is possible to conjecture about potential defenses based on this
idea. However, deciding NOP locations based on timing charac-
teristics to mitigate timing side channels will make NOP insertion
more predictable which, in fact, defeats the original purpose.
Note that just adding random delays to the execution of the code
cannot effectively mitigate side channel attacks [13].
8. CONCLUSION
Code diversity relies on the assumption that since an attacker can
not read the code, he cannot reliably exploit the code. In this paper,
we show that this assumption can be broken by applying side chan-
nel attacks that allow an attacker to leak information about the code
by simply executing the code. We have demonstrated how a mem-
ory corruption vulnerability can facilitate fault analysis and timing
attacks on diversiﬁed code. We have also shown through analysis
on real code that discerning how code has been diversiﬁed can be
easily achieved. Our results reveal that while code diversity raises
the bar for attackers, it is not a panacea for memory corruption
vulnerabilities. We believe that as more randomization techniques
are deployed in practice, attackers will rely more on side channel
attacks to leak enough information to actually exploit the code.
We leave the evaluation of side channel attacks against other
code bases and the analysis of exploiting multiple side channel at-
tacks with the same payload to future work.
9. REFERENCES
[1] ABADI, M., BUDIU, M., ERLINGSSON, U., AND LIGATTI,
J. Control-ﬂow integrity. In Computer and Communications
Security (CCS) (2005).
[2] ACIIÇMEZ, O., BRUMLEY, B. B., AND GRABHER, P. New
results on instruction cache attacks. In CHES (2010).
[3] AKRITIDIS, P., CADAR, C., RAICIU, C., COSTA, M., AND
CASTRO, M. Preventing Memory Error Exploits with WIT.
In Security and Privacy (2008).
[4] BHATKAR, S., AND SEKAR, R. Data space randomization.
In DIMVA (2008).
[5] BIHAM, E., AND SHAMIR, A. Differential fault analysis of
secret key cryptosystems. In CRYPTO (1997).
[6] BITTAU, A., BELAY, A., MASHTIZADEH, A., MAZIERES,
D., AND BONEH, D. Hacking blind. In Security and Privacy
(2014).
[7] BLAZAKIS, D. Leaking addresses with vulnerabilities that
can’t read good. SummerCon ’13.
http://www.trapbit.com/talks/Summerc0n2013-GCWoah.pdf.
[8] BONNEAU, J., AND MIRONOV, I. Cache-collision timing
attacks against AES. In CHES (2006).
[9] BRUMLEY, B. B., AND TUVERI, N. Remote timing attacks
are still practical. In ESORICS (2011).
[10] BRUMLEY, D., AND BONEH, D. Remote timing attacks are
practical. In USENIX Security Symposium (2003).
[11] CHECKOWAY, S., DAVI, L., DMITRIENKO, A., SADEGHI,
A.-R., SHACHAM, H., AND WINANDY, M. Return-oriented
programming without returns. In CCS (2010).
[12] CROSBY, S. A., WALLACH, D. S., AND RIEDI, R. H.
Opportunities and limits of remote timing attacks. ACM
Transactions on Information and System Security 12, 3 (Jan.
2009), 17:1–17:29.
[13] DURVAUX, F., RENAULD, M., STANDAERT, F.-X., VAN
OLDENEEL TOT OLDENZEEL, L., AND
VEYRAT-CHARVILLON, N. Efﬁcient removal of random
delays from embedded software implementations using
hidden markov models. vol. 7771 of Lecture Notes in
Computer Science. 2013, pp. 123–140.
[14] DUSART, P., LETOURNEUX, G., AND VIVOLO, O.
Differential fault analysis on AES. In ACNS (2003).
[15] FORREST, S., SOMAYAJI, A., AND ACKLEY, D. Building
diverse computer systems. In HotOS (1997).
[16] FRANZ, M., BRUNTHALER, S., LARSEN, P., HOMESCU,
A., AND NEISIUS, S. Proﬁle-guided automated software
diversity. In the 2013 IEEE/ACM International Symposium
on Code Generation and Optimization (CGO) (2013).
[17] GENKIN, D., SHAMIR, A., AND TROMER, E. RSA key
extraction via low-bandwidth acoustic cryptanalysis. Tech.
rep., 2013.
[18] GIUFFRIDA, C., KUIJSTEN, A., AND TANENBAUM, A. S.
Enhanced operating system security through efﬁcient and
ﬁne-grained address space randomization. In the 21st
USENIX Security Symposium (2012).
[19] HISER, J., NGUYEN-TUONG, A., CO, M., HALL, M., AND
DAVIDSON, J. W. ILR: Where’d my gadgets go? In Security
and Privacy (2012).
[20] HOCH, J. J., AND SHAMIR, A. Fault analysis of stream
ciphers. In CHES (2004), Springer, pp. 240–253.
[21] HOMESCU, A., BRUNTHALER, S., LARSEN, P., AND
FRANZ, M. librando: Transparent code randomization for
just-in-time compilers. In CCS (2013).
[22] HUND, R., WILLEMS, C., AND HOLZ, T. Practical timing
side channel attacks against kernel space aslr. In Security and
Privacy (2013).
[23] JACKSON, T., HOMESCU, A., CRANE, S., LARSEN, P.,
BRUNTHALER, S., AND FRANZ, M. Diversifying the
software stack using randomized nop insertion. Moving
Target Defense II: Application of Game Theory and
Adversarial Modeling 100 (2013), 151–174.
[24] JOYE, M., PAILLIER, P., AND SCHOENMAKERS, B. On
second-order differential power analysis. In CHES (2005).
[25] KC, G. S., KEROMYTIS, A. D., AND PREVELAKIS, V.
Countering code-injection attacks with instruction-set
randomization. In CCS (2003).
[26] KIL, C., JUN, J., BOOKHOLT, C., XU, J., AND NING, P.
Address Space Layout Permutation (ASLP): Towards
Fine-Grained Randomization of Commodity Software. In
ACSAC (2006).
[27] KOCHER, P. C. Timing attacks on implementations of
Difﬁe-Hellman, RSA, DSS, and other systems. In CRYPTO
(1996).
[28] KOCHER, P. C., JAFFE, J., AND JUN, B. Differential power
analysis. In CRYPTO (1999).
[29] ONARLIOGLU, K., BILGE, L., LANZI, A., BALZAROTTI,
APPENDIX
D., AND KIRDA, E. G-free: Defeating return-oriented
programming through gadget-less binaries. In ACSAC’10
(2010).
[30] OSWALD, D., RICHTER, B., AND PAAR, C. Side-channel
attacks on the Yubikey 2 one-time password generator. In
Research in Attacks, Intrusions, and Defenses (RAID). 2013.
[31] PAPPAS, V., POLYCHRONAKIS, M., AND KEROMYTIS,
A. D. Smashing the gadgets: Hindering return-oriented
programming using in-place code randomization. In Security
and Privacy (2012).
[32] PROUFF, E., RIVAIN, M., AND BÉVAN, R. Statistical
analysis of second order differential power analysis. IEEE
Transactions on Computers 58, 6 (2009), 799–811.
[33] SHACHAM, H. The geometry of innocent ﬂesh on the bone:
return-into-libc without function calls (on the x86). In CCS
(2007).
[34] SHACHAM, H., PAGE, M., PFAFF, B., GOH, E.-J.,
MODADUGU, N., AND BONEH, D. On the effectiveness of
address-space randomization. In CCS (2004).
[35] SKOWYRA, R., CASTEEL, K., OKHRAVI, H., ZELDOVICH,
N., AND STREILEIN, W. Systematic analysis of defenses
against return-oriented programming. In RAID. 2013.
[36] SNOW, K. Z., MONROSE, F., DAVI, L., DMITRIENKO, A.,
LIEBCHEN, C., AND SADEGHI, A.-R. Just-in-time code
reuse: On the effectiveness of ﬁne-grained address space
layout randomization. In Security and Privacy (2013).
[37] SOVAREL, A. N., EVANS, D., AND PAUL, N. Where’s the
feeb? the effectiveness of instruction set randomization. In
the 14th conference on USENIX Security Symposium (2005).
[38] STRACKX, R., YOUNAN, Y., PHILIPPAERTS, P., PIESSENS,
F., LACHMUND, S., AND WALTER, T. Breaking the
memory secrecy assumption. In EUROSEC (2009).
[39] SZEKERES, L., PAYER, M., WEI, T., AND SONG, D. Sok:
Eternal war in memory. In Security and Privacy (2013).
[40] THE PAX TEAM. Address space layout randomization.
http://pax.grsecurity.net/docs/aslr.txt.
[41] TROMER, E., OSVIK, D. A., AND SHAMIR, A. Efﬁcient
cache attacks on AES, and countermeasures. Journal of
Cryptology 23, 2 (Jan. 2010), 37–71.
[42] TROMER, E., AND SHAMIR, A. Acoustic cryptanalysis : on
nosy people and noisy machines. In Eurocrypt Rump Session
(2004).
[43] TUNSTALL, M., MUKHOPADHYAY, D., AND ALI, S.
Differential fault analysis of the advanced encryption
standard using a single fault. In the International Conference
on Information Security Theory and Practice (WISTP)
(2011).
[44] WANG, Z., AND LEE, R. B. New cache designs for
thwarting software cache-based side channel attacks. In the
34th Annual International Symposium on Computer
Architecture (ISCA) (2007).
[45] WARTELL, R., MOHAN, V., HAMLEN, K. W., AND LIN, Z.
Binary stirring: self-randomizing instruction addresses of
legacy x86 binary code. In CCS (2012).
[46] ZHANG, Y., JUELS, A., REITER, M. K., AND
RISTENPART, T. Cross-vm side channels and their use to
extract private keys. In CCS (2012).
A. ROP TIMING ATTACK PAYLOAD
Figure 10: ROP payload used for the timing attack