regexp.MustCompile(`(?i)hash`),
regexp.MustCompile(`(?i)ccnum`),
regexp.MustCompile(`(?i)card`),
regexp.MustCompile(`(?i)security`),
regexp.MustCompile(`(?i)key`),
}
}
/* Extranneous code omitted for brevity */
Listing 7-8: Database miner implementation (/ch-7/db/dbminer/dbminer.go)
The code begins by defining an interface named
DatabaseMiner ❶. A single method, called GetSchema(), is required
for any types that implement the interface. Because each
backend database may have specific logic to retrieve the
database schema, the expectation is that each specific utility
can implement the logic in a way that’s unique to the backend
database and driver in use.
Next, you define a Schema type, which is composed of a few
subtypes also defined here ❷. You’ll use the Schema type to
logically represent the database schema—that is, databases,
tables, and columns. You might have noticed that your
GetSchema() function, within the interface definition, expects
implementations to return a *Schema.
Now, you define a single function, called Search(), which
contains the bulk of the logic. The Search() function expects a
DatabaseMiner instance to be passed to it during the function call,
and stores the miner value in a variable named m ❸. The
function starts by calling m.GetSchema() to retrieve the schema
❹. The function then loops through the entire schema,
searching against a list of regular expression (regex) values for
column names that match ❺. If it finds a match, the database
schema and matching field are printed to the screen.
Lastly, define a function named getRegex() ❻. This function
compiles regex strings by using Go’s regexp package and
returns a slice of these values. The regex list consists of case-
insensitive strings that match against common or interesting
field names such as ccnum, ssn, and password.
With your database miner’s interface in hand, you can
create utility-specific implementations. Let’s start with the
MongoDB database miner.
Implementing a MongoDB Database Miner
The MongoDB utility program in Listing 7-9 implements the
interface defined in Listing 7-8 while also integrating the
database connectivity code you built in Listing 7-6.
package main
import (
"os"
❶ "github.com/bhg/ch-7/db/dbminer"
"gopkg.in/mgo.v2"
"gopkg.in/mgo.v2/bson"
)
❷ type MongoMiner struct {
Host string
session *mgo.Session
}
❸ func New(host string) (*MongoMiner, error) {
m := MongoMiner{Host: host}
err := m.connect()
if err != nil {
return nil, err
}
return &m, nil
}
❹ func (m *MongoMiner) connect() error {
s, err := mgo.Dial(m.Host)
if err != nil {
return err
}
m.session = s
return nil
}
❺ func (m *MongoMiner) GetSchema() (*dbminer.Schema, error) {
var s = new(dbminer.Schema)
dbnames, err := m.session.DatabaseNames()❻
if err != nil {
return nil, err
}
for _, dbname := range dbnames {
db := dbminer.Database{Name: dbname, Tables: []dbminer.Table{}}
collections, err := m.session.DB(dbname).CollectionNames()❼
if err != nil {
return nil, err
}
for _, collection := range collections {
table := dbminer.Table{Name: collection, Columns: []string{}}
var docRaw bson.Raw
err := m.session.DB(dbname).C(collection).Find(nil).One(&docRaw)❽
if err != nil {
return nil, err
}
var doc bson.RawD
if err := docRaw.Unmarshal(&doc); err != nil {❾
if err != nil {
return nil, err
}
}
for _, f := range doc {
table.Columns = append(table.Columns, f.Name)
}
db.Tables = append(db.Tables, table)
}
s.Databases = append(s.Databases, db)
}
return s, nil
}
func main() {
mm, err := New(os.Args[1])
if err != nil {
panic(err)
}
❿ if err := dbminer.Search(mm); err != nil {
panic(err)
}
}
Listing 7-9: Creating a MongoDB database miner (/ch-7/db/mongo/main.go)
You start by importing the dbminer package that defines your
DatabaseMiner interface ❶. Then you define a MongoMiner type
that will be used to implement the interface ❷. For
convenience, you define a New() function that creates a new
instance of your MongoMiner type ❸, calling a method named
connect() that establishes a connection to the database ❹. The
entirety of this logic essentially bootstraps your code,
connecting to the database in a fashion similar to that
discussed in Listing 7-6.
The most interesting portion of the code is your
implementation of the GetSchema() interface method ❺. Unlike
in the previous MongoDB sample code in Listing 7-6, you are
now inspecting the MongoDB metadata, first retrieving
database names ❻ and then looping over those databases to
retrieve each database’s collection names ❼. Lastly, the
function retrieves the raw document that, unlike a typical
MongoDB query, uses lazy unmarshaling ❽. This allows you
to explicitly unmarshal the record into a generic structure so
that you can inspect field names ❾. If not for lazy
unmarshaling, you would have to define an explicit type,
likely using bson tag attributes, in order to instruct your code
how to unmarshal the data into a struct you defined. In this
case, you don’t know (or care) about the field types or
structure—you just want the field names (not the data)—so
this is how you can unmarshal structured data without needing
to know the structure of that data beforehand.
Your main() function expects the IP address of your
MongoDB instance as its lone argument, calls your New()
function to bootstrap everything, and then calls dbminer.Search(),
passing to it your MongoMiner instance ❿. Recall that
dbminer.Search() calls GetSchema() on the received DatabaseMiner
instance; this calls your MongoMiner implementation of the
function, which results in the creation of dbminer.Schema that is
then searched against the regex list in Listing 7-8.
When you run your utility, you are blessed with the
following output:
$ go run main.go 127.0.0.1
[DB] = store
[TABLE] = transactions
[COL] = _id
[COL] = ccnum
[COL] = date
[COL] = amount
[COL] = cvv
[COL] = exp
[+] HIT: ccnum
You found a match! It may not look pretty, but it gets the
job done—successfully locating the database collection that
has a field named ccnum.
With your MongoDB implementation built, in the next
section, you’ll do the same for a MySQL backend database.
Implementing a MySQL Database Miner
To make your MySQL implementation work, you’ll inspect
the information_schema.columns table. This table maintains metadata
about all the databases and their structures, including table and
column names. To make the data the simplest to consume, use
the following SQL query, which removes information about
some of the built-in MySQL databases that are of no
consequence to your pillaging efforts:
SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME FROM
columns
WHERE TABLE_SCHEMA NOT IN ('mysql', 'information_schema',
'performance_schema', 'sys')
ORDER BY TABLE_SCHEMA, TABLE_NAME
The query produces results resembling the following:
+--------------+--------------+-------------+
| TABLE_SCHEMA | TABLE_NAME | COLUMN_NAME |
+--------------+--------------+-------------+
| store | transactions | ccnum |
| store | transactions | date |
| store | transactions | amount |
| store | transactions | cvv |
| store | transactions | exp |
--snip--
Although using that query to retrieve schema information is
pretty straightforward, the complexity in your code comes
from logically trying to differentiate and categorize each row
while defining your GetSchema() function. For example,
consecutive rows of output may or may not belong to the same
database or table, so associating the rows to the correct
dbminer.Database and dbminer.Table instances becomes a somewhat
tricky endeavor.
Listing 7-10 defines the implementation.
type MySQLMiner struct {
Host string
Db sql.DB
}
func New(host string) (*MySQLMiner, error) {
m := MySQLMiner{Host: host}
err := m.connect()
if err != nil {
return nil, err
}
return &m, nil
}
func (m *MySQLMiner) connect() error {
db, err := sql.Open(
"mysql",
❶ fmt.Sprintf("root:password@tcp(%s:3306)/information_schema", m.Host))
if err != nil {
log.Panicln(err)
}
m.Db = *db
return nil
}
func (m *MySQLMiner) GetSchema() (*dbminer.Schema, error) {
var s = new(dbminer.Schema)
❷ sql := `SELECT TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME
FROM columns
WHERE TABLE_SCHEMA NOT IN
('mysql', 'information_schema', 'performance_schema', 'sys')
ORDER BY TABLE_SCHEMA, TABLE_NAME`
schemarows, err := m.Db.Query(sql)
if err != nil {
return nil, err
}
defer schemarows.Close()
var prevschema, prevtable string
var db dbminer.Database
var table dbminer.Table
❸ for schemarows.Next() {
var currschema, currtable, currcol string
if err := schemarows.Scan(&currschema, &currtable, &currcol); err != nil {
return nil, err
}
❹ if currschema != prevschema {
if prevschema != "" {
db.Tables = append(db.Tables, table)
s.Databases = append(s.Databases, db)
}
db = dbminer.Database{Name: currschema, Tables: []dbminer.Table{}}
prevschema = currschema
prevtable = ""
}
❺ if currtable != prevtable {
if prevtable != "" {
db.Tables = append(db.Tables, table)
}
table = dbminer.Table{Name: currtable, Columns: []string{}}
prevtable = currtable
}
❻ table.Columns = append(table.Columns, currcol)
}
db.Tables = append(db.Tables, table)
s.Databases = append(s.Databases, db)
if err := schemarows.Err(); err != nil {
return nil, err
}
return s, nil
}
func main() {
mm, err := New(os.Args[1])
if err != nil {
panic(err)
}
defer mm.Db.Close()
if err := dbminer.Search(mm); err != nil {
panic(err)
}
}
Listing 7-10: Creating a MySQL database miner (/ch-7/db/mysql/main.go/)
A quick glance at the code and you’ll probably realize that
much of it is very, very similar to the MongoDB example in
the preceding section. As a matter of fact, the main() function is
identical.
The bootstrapping functions are also similar—you just
change the logic to interact with MySQL rather than
MongoDB. Notice that this logic connects to your
information_schema database ❶, so that you can inspect the
database schema.
Much of the code’s complexity resides within the
GetSchema() implementation. Although you are able to retrieve
the schema information by using a single database query ❷,
you then have to loop over the results ❸, inspecting each row
so you can determine what databases exist, what tables exist in
each database, and what columns exist for each table. Unlike
in your MongoDB implementation, you don’t have the luxury
of JSON/BSON with attribute tags to marshal and unmarshal
data into complex structures; you maintain variables to track
the information in your current row and compare it with the
data from the previous row, in order to determine whether
you’ve encountered a new database or table. Not the most
elegant solution, but it gets the job done.
Next, you check whether the database name for your
current row differs from your previous row ❹. If so, you
create a new miner.Database instance. If it isn’t your first iteration
of the loop, add the table and database to your miner.Schema
instance. You use similar logic to track and add miner.Table
instances to your current miner.Database ❺. Lastly, add each of
the columns to our miner.Table ❻.
Now, run the program against your Docker MySQL
instance to confirm that it works properly, as shown here:
$ go run main.go 127.0.0.1
[DB] = store
[TABLE] = transactions
[COL] = ccnum
[COL] = date
[COL] = amount
[COL] = cvv
[COL] = exp
[+] HIT: ccnum
The output should be almost indiscernible from your
MongoDB output. This is because your dbminer.Schema isn’t
producing any output—the dbminer.Search() function is. This is
the power of using interfaces. You can have specific
implementations of key features, yet still utilize a single,
standard function to process your data in a predictable, usable
manner.
In the next section, you’ll step away from databases and
instead focus on pillaging filesystems.
PILLAGING A FILESYSTEM
In this section, you’ll build a utility that walks a user-supplied
filesystem path recursively, matching against a list of
interesting filenames that you would deem useful as part of a
post-exploitation exercise. These files may contain, among
other things, personally identifiable information, usernames,
passwords, system logins, and password database files.
The utility looks specifically at filenames rather than file
contents, and the script is made much simpler by the fact that
Go contains standard functionality in its path/filepath package
that you can use to easily walk a directory structure. You can
see the utility in Listing 7-11.
package main
import (
"fmt"
"log"
"os"
"path/filepath"
"regexp"
)
❶ var regexes = []*regexp.Regexp{
regexp.MustCompile(`(?i)user`),
regexp.MustCompile(`(?i)password`),
regexp.MustCompile(`(?i)kdb`),
regexp.MustCompile(`(?i)login`),
}
❷ func walkFn(path string, f os.FileInfo, err error) error {
for _, r := range regexes {
❸ if r.MatchString(path) {
fmt.Printf("[+] HIT: %s\n", path)
}
}
return nil
}
func main() {
root := os.Args[1]
❹ if err := filepath.Walk(root, walkFn); err != nil {
log.Panicln(err)
}
}
Listing 7-11: Walking and searching a filesystem (/ch-7/filesystem/main.go)
In contrast to your database-mining implementations, the
filesystem pillaging setup and logic might seem a little too
simple. Similar to the way you created your database
implementations, you define a regex list for identifying
interesting filenames ❶. To keep the code minimal, we
limited the list to just a handful of items, but you can expand
the list to accommodate more practical usage.
Next, you define a function, named walkFn(), that accepts a
file path and some additional parameters ❷. The function
loops over your regular expression list and checks for matches
❸, displaying them to stdout. The walkFn() function ❹ is used
in the main() function, and passed as a parameter to filepath.Walk().
The Walk() function expects two parameters—a root path and a
function (in this case, walkFn())—and recursively walks the
directory structure starting at the value supplied as the root
path, calling walkFn() for every directory and file it encounters.
With your utility complete, navigate to your desktop and
create the following directory structure:
$ tree targetpath/
targetpath/
--- anotherpath
- --- nothing.txt
- --- users.csv