### The Value of Strings Received from an Attacker-Controlled Web Service

The battery monitor app can either read battery levels and send them to a remote service or snoop on lock PIN codes and transmit them via SMS to the attacker. This attack is stealthy and could allow the attacker to break into the home. For more details, see Appendix A.

### Leaking Events from Any Device

We enhanced our door lock PIN-code snooping attack using event leakage. As discussed in §IV, if an unprivileged app learns a 128-bit device identifier value, it can listen to all events from that device without acquiring the associated capabilities. We modified our disguised battery monitor app to use a 128-bit device identifier for the Z-Wave lock and verified that it can listen to `codeReport` events without even the battery capability.

A natural question is: how would an attacker retrieve the device identifier? The device identifier value is constant across all apps but changes if a device is removed from SmartThings and added again. There is no fixed pattern (such as an incrementing value or a predictable hash of known items) to the device identifier. We discuss two options below:

- **Colluding SmartApp**: The attacker could deploy a benign colluding SmartApp that reads the device identifiers for various devices and leaks them using the unrestricted communication abilities of SmartApps.
- **Exploiting Another SmartApp Remotely**: As shown earlier, WebService SmartApps can be exploited remotely. An attacker can exploit a WebService SmartApp and get it to output a list of device identifiers for all devices the WebService SmartApp is authorized to access.

Either technique will leak a device identifier for a target physical device. The attacker can then transmit the identifier to an installed malicious app. Our intent here is to show how a SmartApp can use the device identifier to escalate its privileges.

### Disabling Vacation Mode Attack

Vacation mode is a popular home automation feature that simulates turning off and on lights and other devices to make it look like a home is occupied when it is empty, thereby deterring potential vandals and burglars. We selected a SmartApp from our dataset that depends on the "mode" property of the location object. When the "mode" is set to a desired value, an event fires, and the SmartApp activates the occupancy simulation. When the "mode" is reset, the SmartApp stops the occupancy simulation.

Recall from §IV that SmartThings does not have any security controls around the `sendLocationEvent` API. We wrote an attack SmartApp that raises a false mode change event. The attack SmartApp interferes with the occupancy simulation SmartApp and makes it stop, thus disabling the protection set up for vacation mode. This attack required only one line of code and can be launched from any SmartApp without requiring specific capabilities.

### Fake Alarm Attack

We demonstrate how an unprivileged SmartApp can use spoofed physical device events to escalate its privileges and control devices it is not authorized to access. We downloaded an alarm panel SmartApp from the App Store. The alarm panel app requests the user to authorize carbon monoxide (CO) detectors, siren alarm devices, motion sensors, and water sensors. The alarm panel SmartApp can start a siren alarm if the CO detector is triggered. We wrote an attack SmartApp that raises a fake physical device event for the CO detector, causing the alarm panel app to sound the siren alarm. Therefore, the unprivileged attack SmartApp misuses the logic of the benign alarm panel app using a spoofed physical device event to control the siren alarm.

### Survey Study of SmartThings Users

Three of the attacks discussed above require users to install an attack SmartApp (PIN Code Snooping, Disabling Vacation Mode, Fake Alarm). Although several studies show that users have limited understanding of the security and privacy risks of installing Android apps, no similar studies are available for smart home applications. To assess whether our attack scenarios are realistic, we conducted a survey of SmartThings users, focusing on the following questions:

- Would SmartThings users install apps like the battery monitor app that request access to battery-powered devices?
- What is the set of security-critical household devices (e.g., door lock, security alarm) that users would like the battery monitor app to access?
- Do users understand the risks of authorizing security-critical household devices to the battery monitor app?
- What would users’ reactions be if they learn that the battery monitor app snooped on PIN codes of a door lock?

From October to November 2015, we recruited 22 participants through (1) a workplace mailing-list of home automation enthusiasts and (2) the SmartThings discussion forum on the web. Note that our participants are smart home enthusiasts, and their inclusion represents a sampling bias. However, this does not affect our study because if our attack tricks experienced participants, it further supports our thesis that the attack is realistic. All participants reported owning one or more SmartThings hubs. The number of devices participants reported having connected to their hub ranged from fewer than 10 to almost 100. On average, participants reported having 15 SmartApps installed. Upon completing the survey, we checked the responses and compensated participants with a $10 Amazon gift card or a $10 dining card for workplace restaurants. To capture participants' unbiased responses to an app installation request, we did not mention security and advertised the survey as a study on the SmartThings app installation experience. The survey was designed and conducted by researchers from our team who are at an institution that does not require review board approval. The rest of the team had restricted access to survey responses. We did not collect any private data except the email address for those who wanted to receive a gift card. The email address was deleted after sending the gift card.

In the first section of the survey, we introduced the battery monitor SmartApp. We asked participants to imagine that they had four battery-powered devices already set up with their SmartThings hubs and that they had the option of installing the battery monitor SmartApp. Then, the survey showed the screenshots of the SmartApp at all installation stages. In the device selection UI, the survey showed the following four devices: SmartThings motion sensor, SmartThings presence sensor, Schlage door lock, and FortrezZ siren strobe alarm. We then asked participants how interested they would be in installing the battery monitor SmartApp. We recorded responses using a Likert scale set of choices (1: not interested, 5: very interested). Following that, we asked for the set of devices the participants would like the battery monitor SmartApp to monitor.

We designed the next section of the survey to measure participants' understanding (or lack thereof) of the security and privacy risks of installing the battery monitor SmartApp. The survey first presented the following risks derived from SmartThings capabilities and asked participants to select all the actions they thought the battery monitor app could take without asking them first (besides monitoring battery level):

- Cause the FortrezZ alarm to beep occasionally
- Disable the FortrezZ alarm
- Send spam email using your SmartThings hub
- Download illegal material using your SmartThings hub
- Send out battery levels to a remote server
- Send out the SmartThings motion and presence sensors' events to a remote server
- Collect door access codes in the Schlage door lock and send them out to a remote server
- None of the above

Note that the battery monitor app could take any of the above actions if permitted access to relevant sensitive devices. The survey then asked participants how upset they would be if each risk were to occur. We recorded responses using a Likert scale set of choices (1: indifferent, 5: very upset). Finally, the survey asked questions about the participants' SmartThings deployment.

Table VI summarizes the responses from 22 participants. The results indicate that most participants would be interested in installing the battery monitor app and would like to give it access to door locks. This suggests that the attack scenario discussed in §VI-B is not unrealistic. Appendix C contains the survey questions and all responses.

Only 14% of participants seemed to be aware that the battery monitor app can spy on door lock codes and leak PIN codes to an attacker, while all participants would be concerned about the door lock snooping attack. Although it is a small-scale online survey, the results indicate that better safeguards in the SmartThings framework are desirable. However, we note that our study has limitations, and to improve ecological validity, a field study is needed to measure whether people would actually install a disguised battery monitor app in their hub and give it access to their door lock. We leave this for future work.

### Challenges and Opportunities

We discuss some lessons learned from the analysis of the SmartThings platform (§IV) that we believe to be broadly applicable to smart home programming framework design. We also highlight a few defense research directions.

**Lesson 1: Asymmetric Device Operations & Risk-based Capabilities**

An oven control capability exposing on and off operations makes functional sense. Similarly, a lock capability exposing lock and unlock makes functional sense. However, switching on an oven at random times can cause a fire, while switching an oven off may only result in uncooked food. Therefore, we observe that functionally similar operations are sometimes dissimilar in terms of their associated security risks. We learn that device operations are inherently asymmetric risk-wise, and a capability model needs to split such operations into equivalence classes.

A more secure design could group functionally similar device operations based on their risk. However, estimating risk is challenging—an on/off operation pair for a lightbulb is less risky than the same operation pair for an alarm. A possible first step is to adapt the user-study methodology of Felt et al., which was used for smartphone APIs [15], to include input from multiple stakeholders: users, device manufacturers, and the framework provider.

Splitting capabilities based on risk affects granularity. Furthermore, fine-granularity systems are known to be difficult for users to comprehend and use effectively. We surveyed the access control models of several competing smart home systems—AllJoyn, HomeKit, and Vera3—in addition to SmartThings. We observed a range of granularities, none of which are risk-based. At one end of the spectrum, HomeKit authorizes apps to devices at the "Home" level. That is, an app either gains access to all home-related devices or none at all. Vera3 has a similar granularity model. At the opposite end of the spectrum, AllJoyn provides ways to set up different ACLs per interface of an AllJoyn device or an AllJoyn app. However, there is no standard set of interfaces yet. A user must configure ACLs upon app installation—a usability barrier for regular users. We envision a second set of user studies that establish which granularity level is a good trade-off between usability and security.

**Lesson 2: Arbitrary Events & Identity Mechanisms**

We observed two problems with the SmartThings event subsystem: SmartApps cannot verify the identity of the source of an event, and SmartThings does not have a way of selectively disseminating sensitive event data. Any app with access to a device's ID can monitor all the events of that device. Furthermore, apps are susceptible to spoofed events. As discussed, events form the basis of the fundamental trigger-action programming paradigm. Therefore, we learn that secure event subsystem design is crucial for smart home platforms in general.

Providing a strong notion of app identity coupled with access control around raising events could be the basis for a more secure event architecture. Such a mechanism could enable apps to verify the origin of event data and could enable producers of events to selectively disseminate sensitive events. However, these mechanisms require changes on a fundamental level. AllJoyn [4] and HomeKit [5] were constructed from the ground up to have a strong notion of identity.

Android Intents are a close cousin to SmartThings events. Android and its apps use Intents as an IPC mechanism and a notification mechanism. For instance, the Android OS triggers a special kind of broadcast Intent whenever the battery level changes. However, unlike SmartThings, Intents build on kernel-enforced UIDs. This basis of strong identity enables an Intent receiver to determine provenance before acting on the information and allows senders to selectively disseminate an Intent. However, bugs in Intent usage can lead to circumventing access control checks and permitting spoofing [11]. A secure event mechanism for SmartThings can benefit from existing research on defending against Intent attacks on Android [22].

**Co-operating, Vetting App Stores**

As is the case for smartphone app stores, further research is needed on validating apps for smart homes. A language like Groovy provides some security benefits but also has features that can be misused, such as input strings being executed. We need techniques that will validate smart home apps against code injection attacks, overprivilege, and other more subtle security vulnerabilities (e.g., disguised source code).

Unfortunately, even if a programming framework provider like SmartThings does all this, other app validation challenges will remain because not all security vulnerabilities we found were due to flaws in the SmartThings apps themselves. One of the vulnerabilities reported in this paper was due to the secrets included in the related Android app that was used to control a SmartApp. That Android app clearly made it past Google's vetting process. It is unlikely that Google would have been in a position to discover such a vulnerability and assess its risks to a smart home user since the Groovy app was not even available to Google. Research is needed on ways for multiple store operators (for example, the SmartThings app store and the Google Play store) to cooperate to validate the entire ecosystem that pertains to the functionality of a smart home app.

Smart home devices and their associated programming platforms will continue to proliferate and will remain attractive to consumers because they provide powerful functionality. However, the findings in this paper suggest that caution is warranted—on the part of early adopters and on the part of framework designers. The risks are significant, and they are unlikely to be easily addressed via simple security patches alone.

### Conclusions

We performed an empirical security evaluation of the popular SmartThings framework for programmable smart homes. Analyzing SmartThings was challenging because all the apps run on a proprietary cloud platform, and the framework protects communication among major components such as hubs, cloud backend, and the smartphone companion app. We performed a market-scale overprivilege analysis of existing apps to determine how well the SmartThings capability model protects physical devices and associated data. We discovered:

- Over 55% of existing SmartApps did not use all the rights to device operations that their requested capabilities implied, largely due to coarse-grained capabilities provided by SmartThings.
- SmartThings grants a SmartApp full access to a device even if it only specifies needing limited access to the device.
- The SmartThings event subsystem has inadequate security controls.

We combined these design flaws with other common vulnerabilities that we discovered in SmartApps and were able to steal lock PIN codes, disable a vacation mode SmartApp, and cause fake fire alarms, all without requiring SmartApps to have capabilities to carry out these actions.