the value of the strings received from the attacker controlled
Web service, the battery monitor app can either read battery
levels and send them to a remote service, or snoop on lock
pin codes and transmit them via SMS to the attacker. This
attack is stealthy and could allow the attacker to break into
the home. See Appendix A for details.
Leaking Events from Any Device. We enhanced our door
lock pin-code snooping attack using event leakage. As dis-
cussed in §IV, if an unprivileged app learns a 128-bit device
identiﬁer value, it can listen to all events from that device
without acquiring the associated capabilities. We modiﬁed
our disguised battery monitor app to use a 128-bit device
identiﬁer for the ZWave lock and veriﬁed that it can listen
to codeReport events without even the battery capability.
A natural question is the following: how would an attacker
retrieve the device identiﬁer? The device identiﬁer value is
constant across all apps, but changes if a device is removed
from SmartThings and added again. There is no ﬁxed pattern
(like an incrementing value or predictable hash of known
items) to the device identiﬁer. We discuss two options below:
• Colluding SmartApp: The attacker could deploy a benign
colluding SmartApp that reads the device identiﬁers for
various devices and leak them using the unrestricted
communication abilities of SmartApps.
• Exploiting another SmartApp remotely: As shown earlier,
WebService SmartApps can be exploited remotely. An
attacker can exploit a WebService SmartApp and get it
to output a list of device identiﬁers for all devices the
WebService SmartApp is authorized.
Either technique will leak a device identiﬁer for a target
physical device. Then the attacker can transmit the identiﬁer
to an installed malicious app. We stress that our intent here
is to show how a SmartApp can use the device identiﬁer to
escalate its privileges.
C. Disabling Vacation Mode Attack
Vacation mode is a popular home automation experience
that simulates turning off and on lights and other devices
to make it look like a home is occupied, when in fact it is
empty, to dissuade potential vandals and burglars. We picked
a SmartApp from our dataset that depends on the “mode”
property of the location object. When the “mode” is set
to a desired value, an event ﬁres and the SmartApp activates
the
its occupancy simulation. When the “mode” is reset,
SmartApp stops occupancy simulation.
Recall from §IV that SmartThings does not have any se-
curity controls around the sendLocationEvent API. We
wrote an attack SmartApp that raises a false mode change
event. The attack SmartApp interferes with the occupancy
simulation SmartApp and makes it stop, therefore disabling the
protection set up for the vacation mode. This attack required
only one line of attack code and can be launched from any
SmartApp without requiring speciﬁc capabilities.
D. Fake Alarm Attack
We show how an unprivileged SmartApp can use spoofed
physical device events to escalate its privileges and control
devices it is not authorized to access. We downloaded an alarm
panel SmartApp from the App Store. The alarm panel app
requests the user to authorize carbon monoxide (CO) detectors,
siren alarm devices, motion sensors, and water sensors. The
alarm panel SmartApp can start a siren alarm if the CO
detector is triggered. We wrote an attack SmartApp that raises
a fake physical device event for the CO detector, causing
the alarm panel app to sound the siren alarm. Therefore, the
unprivileged attack SmartApp misuses the logic of the benign
alarm panel app using a spoofed physical device event to
control the siren alarm.
E. Survey Study of SmartThings Users
Three of the attacks discussed above require that users
can be convinced to install an attack SmartApp (Pin Code
Snooping, Disabling Vacation Mode, Fake Alarm). Although
a number of studies show that users have limited understanding
of security and privacy risks of installing Android apps (e.g.,
[16]), no similar studies are available on the users of smart
home applications. To assess whether our attack scenarios
are realistic, we conducted a survey of SmartThings users,
focusing on the following questions:
• Would SmartThings users install apps like the battery
monitor app that request access to battery-powered de-
vices?
• What is the set of security-critical household devices
(e.g., door lock, security alarm) that users would like the
battery monitor app to access?
• Do users understand the risks of authorizing security-
critical household devices to the battery monitor app?
• What would users’ reactions be if they learn that the
battery monitor app snooped on pin codes of a door lock?
From October to November 2015, we recruited 22 partici-
pants through (1) a workplace mailing-list of home automation
enthusiasts, and (2) the SmartThings discussion forum on the
Web.8 We note that our participants are smart home enthusi-
asts, and their inclusion represents a sampling bias. However,
8https://community.smartthings.com/
648648
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:33 UTC from IEEE Xplore.  Restrictions apply. 
this does not affect our study because if our attack tricks
experienced participants, then it further supports our thesis that
the attack is realistic. All participants reported owning one or
more SmartThings hubs. The number of devices participants
reported having connected to their hub ranged from fewer than
10 to almost 100. On average, participants reported having
15 SmartApps installed. Upon completing the survey, we
checked the responses and compensated participants with a
$10 Amazon gift card or a $10 dining card for workplace
restaurants. In order capture participants’ unbiased responses
to an app installation request, we did not mention security at
all and advertised the survey as a study on the SmartThings
app installation experience. The survey was designed and con-
ducted by researchers from our team who are at an institution
that does not require review board approval. The rest of the
team was given restricted access to survey responses. We did
not collect any private data except the email address for those
who would want to receive a gift card. The email address was
deleted after sending a gift card.
In the ﬁrst section of the survey, we introduced the battery
monitor SmartApp. We asked participants to imagine that they
had four battery-powered devices already set up with their
SmartThings hubs and that they had the option of installing
the battery monitor SmartApp. Then, the survey showed the
screenshots of the SmartApp at all installation stages. In the
device selection UI, the survey showed the following four
devices: SmartThings motion sensor, SmartThings presence
Sensor, Schlage door lock, and FortrezZ siren strobe alarm.
We then asked participants how interested they would be
in installing the battery monitor SmartApp. We recorded re-
sponses using a Likert scale set of choices (1: not interested, 5:
very interested). Following that, we asked for the set of devices
the participants would like the battery monitor SmartApp to
monitor.
We designed the next section of the survey to measure
participants’ understanding (or lack thereof) of security and
privacy risks of installing the battery monitor SmartApp. The
survey ﬁrst presented the following risks that we derived from
SmartThings capabilities and asked participants to select all
the actions they thought the battery monitor app could take
without asking them ﬁrst (besides monitoring battery level):
• Cause the FortrezZ alarm to beep occasionally
• Disable the FortrezZ alarm
• Send spam email using your SmartThings hub
• Download illegal material using your SmartThings hub
• Send out battery levels to a remote server
• Send out the SmartThings motion and presence sensors’
events to a remote server
• Collect door access codes in the Schlage door lock and
send them out to a remote server
• None of the above
Note that the battery monitor app could take any of the the
above actions if permitted access to relevant sensitive devices.
The survey then asked participants how upset they would be if
each risk were to occur. We recorded responses using a Likert
scale set of choices (1: indifferent, 5: very upset). Finally, the
SURVEY RESPONSES OF 22 SMARTTHINGS USERS
TABLE VI
Interest in installing battery monitor SmartApp:
Interested or very interested
Neutral
Not interested at all
Set of devices that participants would like the battery
monitor app to monitor:
17
4
1
12
11
8
5
5
3
3
77%
18%
5%
95%
91%
86%
64%
55%
50%
36%
23%
23%
14%
14%
22
100%
21
Selected motion Sensor
20
Selected Schlage door lock
Selected presence Sensor
19
Selected FortrezZ alarm 14
Participants’ understanding of security risks—# of
participants who think the battery monitor app can
perform the following:
Cause FortrezZ alarm to beep occasionally
Send battery levels to remote server
Send motion and presence sensor data to remote server
Disable FortrezZ alarm
Send spam email from hub
Download illegal material using hub
Send door access codes to remote server
Participants’ reported feelings if the battery monitor
app sent out door lock pin codes to a remote server:
Upset or very upset
survey asked questions about the participants’ SmartThings
deployment.
Table VI summarizes the responses from 22 participants.
The results indicate that most participants would be interested
in installing the battery monitor app and would like to give it
the access to door locks. This suggests that the attack scenario
discussed in §VI-B is not unrealistic. Appendix C contains the
survey questions and all responses.
Only 14% participants seemed to be aware that the battery
monitor app can spy on door lock codes and leak pin-codes
to an attacker while all participants would be concerned about
the door lock snooping attack. Although it is a small-scale
online survey, the results indicate that better safeguards in
the SmartThings framework are desirable. However, we note
that our study has limitations and to improve the ecological
validity, a ﬁeld study is needed that measures whether people
would actually install a disguised battery monitor app in their
hub and give it the access to their door lock. We leave it to
future work.
VII. CHALLENGES AND OPPORTUNITIES
We discuss some lessons learned from the analysis of the
SmartThings platform (§IV) that we believe to be broadly
applicable to smart home programming framework design. We
also highlight a few defense research directions.
Lesson 1: Asymmetric Device Operations & Risk-based
Capabilities. An oven control capability exposing on and
off operations makes sense functionally. Similarly, a lock
capability exposing lock and unlock makes functional sense.
However, switching on an oven at random times can cause a
ﬁre, while switching an oven off may only result in uncooked
food. Therefore, we observe that functionally similar oper-
ations are sometimes dissimilar in terms of their associated
649649
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:33 UTC from IEEE Xplore.  Restrictions apply. 
security risks. We learn that device operations are inherently
asymmetric risk-wise and a capability model needs to split
such operations into equivalence classes.
A more secure design could be to group functionally similar
device operations based on their risk. However, estimating risk
is challenging—an on/off operation pair for a lightbulb is less
risky than the same operation pair for an alarm. A possible
ﬁrst step is to adapt the user-study methodology of Felt et al.,
which was used for smartphone APIs [15], to include input
from multiple stakeholders: users, device manufacturers, and
the framework provider.
Splitting capabilities based on risk affects granularity. Fur-
thermore, ﬁne-granularity systems are known to be difﬁ-
cult for users to comprehend and use effectively. We sur-
veyed the access control models of several competing smart
home systems—AllJoyn, HomeKit, and Vera3—in addition to
SmartThings. We observed a range of granularities, none of
which are risk-based. At one end of the spectrum, HomeKit
authorizes apps to devices at the “Home” level. That is, an
app either gains access to all home-related devices, or none
at all. Vera3 has a similar granularity model. At the opposite
end of the spectrum, AllJoyn provides ways to setup different
ACLs per interface of an AllJoyn device or an AllJoyn app.
However, there is no standard set of interfaces yet. A user must
conﬁgure ACLs upon app installation—a usability barrier for
regular users. We envision a second set of user studies that
establish which granularity level is a good trade-off between
usability and security.
Lesson 2: Arbitrary Events & Identity Mechanisms. We
observed two problems with the SmartThings event subsystem:
SmartApps cannot verify the identity of the source of an event,
and SmartThings does not have a way of selectively dissemi-
nating sensitive event data. Any app with access to a device’s
ID can monitor all the events of that device. Furthermore,
apps are susceptible to spoofed events. As discussed, events
form the basis of the fundamental trigger-action programming
paradigm. Therefore, we learn that secure event subsystem
design is crucial for smart home platforms in general.
Providing a strong notion of app identity coupled with
access control around raising events could be the basis for
a more secure event architecture. Such a mechanism could
enable apps to verify the origin of event data and could enable
producers of events to selectively disseminate sensitive events.
However, these mechanisms require changes on a fundamental
level. AllJoyn [4], and HomeKit [5] were constructed from the
ground up to have a strong notion of identity.
Android Intents are a close cousin to SmartThings events.
Android and its apps use Intents as an IPC mechanism as well
as a notiﬁcation mechanism. For instance, the Android OS
triggers a special kind of broadcast Intent whenever the battery
level changes. However, differently from SmartThings, Intents
build on kernel-enforced UIDs. This basis of strong identity
enables an Intent receiver to determine provenance before
acting on the information, and allows senders to selectively
disseminate an Intent. However, bugs in Intent usage can lead
to circumventing access control checks as well as to permitting
spooﬁng [11]. A secure event mechanism for SmartThings
can beneﬁt from existing research on defending against Intent
attacks on Android [22].
Co-operating, Vetting App Stores. As is the case for smart-
phone app stores, further research is needed on validating
apps for smart homes. A language like Groovy provides some
security beneﬁts, but also has features that can be misused
such as input strings being executed. We need techniques that
will validate smart home apps against code injection attacks,
overprivilege, and other more subtle security vulnerabilities
(e.g., disguised source code).
Unfortunately, even if a programming framework provider
like SmartThings does all this, other app validation challenges
will remain because not all security vulnerabilities we found
were due to ﬂaws in the SmartThings apps themselves. One of
the vulnerabilities reported in this paper was due to the secrets
included in the related Android app that was used to control
a SmartApp. That Android app clearly made it past Google’s
vetting process. It is unlikely that Google would have been
in a position to discover such a vulnerability and assess its
risks to a smart home user, since the Groovy app was not
even available to Google. Research is needed on ways for
multiple store operators (for example, the SmartThings app
store and the Google Play store) to cooperate to validate the
entire ecosystem that pertains to the functionality of a smart
home app.
Smart home devices and their associated programming
platforms will continue to proliferate and will remain attractive
to consumers because they provide powerful functionality.
However, the ﬁndings in this paper suggest that caution is
warranted as well—on the part of early adopters, and on the
part of framework designers. The risks are signiﬁcant, and they
are unlikely to be easily addressed via simple security patches
alone.
VIII. CONCLUSIONS
We performed an empirical security evaluation of the pop-
ular SmartThings framework for programmable smart homes.
Analyzing SmartThings was challenging because all the apps
run on a proprietary cloud platform, and the framework
protects communication among major components such as
hubs, cloud backend, and the smartphone companion app. We
performed a market-scale overprivilege analysis of existing
apps to determine how well the SmartThings capability model
protects physical devices and associated data. We discovered
(a) over 55% of existing SmartApps did not use all
the
rights to device operations that their requested capabilities
implied, largely due to coarse-grained capabilities provided
by SmartThings; (b) SmartThings grants a SmartApp full
access to a device even if it only speciﬁes needing limited
access to the device; and (c) The SmartThings event subsystem
has inadequate security controls. We combined these design
ﬂaws with other common vulnerabilities that we discovered
in SmartApps and were able to steal lock pin-codes, disable
a vacation mode SmartApp, and cause fake ﬁre alarms, all
without requiring SmartApps to have capabilities to carry out
650650
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:33 UTC from IEEE Xplore.  Restrictions apply. 