the NMI is relatively low overall.
C. Instantaneous phase
Our device ﬁngerprinting approach centers on extracting
device-speciﬁc behaviors from the estimated instantaneous
phase sequence. Instantaneous phase exposes ﬁne-grained
timing behavior, revealing precisely when the subject clock
ticks relative to the reference clock. To compare different
devices however, φ must be computed using the same period
˙T because, as described in the next section, the φ form a
congruence class modulo ˙T .
˙T = 1
To demonstrate some of the diversity in clock behaviors,
Figure 4 shows the instantaneous phase of six devices from
two different classes: 60Hz (top row,
60) and 125Hz
(bottom row, ˙T = 1
125). Among the 60Hz devices, variations in
jitter are evident. Timing jitter is measured by the magnitude
of phase changes (|φi − φi−1|), which are generally greater
in Device B compared to Device A. The sawtooth pattern in
Device C suggests that the 60Hz clock is running slightly
fast, and indeed for this particular device the estimated subject
clock frequency is ˆf S = 60.00125Hz.
We observed instantaneous phase to be especially diversiﬁed
among 125Hz devices. This may be attributed to the USB host
controller running off of an independent clock from system
time reported by Date.now(). The phase of Device D
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:54 UTC from IEEE Xplore.  Restrictions apply. 
1024
59.99059.99560.00060.00560.010Frequency (Hz)Density60Hz Desktop Devices124.990124.995125.000125.005125.010Frequency (Hz)Density125Hz Desktop Devices59.99059.99560.00060.00560.010Frequency (Hz)Density60Hz Mobile Devices99.99099.995100.000100.005100.010Frequency (Hz)Density100Hz Mobile DevicesFig. 4.
Instantaneous phase sequences for three different 60Hz devices (top) and three different 125Hz devices (bottom).
oscillates between two values while Device E exhibits a similar
pattern albeit with greater variation. Finally,
the sawtooth
pattern in Device F is due to CS running slightly faster than
125Hz ( ˆf S = 125.04465Hz), similar to Device C.
V. DEVICE FINGERPRINTING METHODOLOGY
We form device ﬁngerprints by ﬁrst constructing a phase im-
age that contains modular residues (equivalent to instantaneous
phase) under many different hypothetical subject clocks. The
phase image captures a variety of clock behaviors, but like face
and actual ﬁngerprint images they are not directly comparable.
We deﬁne a neural network, FPNET, that embeds the phase
images in a low-dimensional feature space. This approach is
inspired by face recognition systems such as FaceNet [54].
Classiﬁcation tasks, including device identiﬁcation and veriﬁ-
cation, can then be performed with a simple Euclidean distance
metric in the feature space.
Using complex argument identity Arg(cid:0)zθ(cid:1) ≡ θ mod 2π,
where complex number z = rejθ and θ ∈ R, instantaneous
phase (Equation 10) can be rewritten as
A. Phase images
φi ≡ tR
i mod T S .
(11)
This implies the φi form a congruence class modulo T S. Thus,
comparing two different instantaneous phase sequences (from
either the same or different device) requires that the same
period be used to estimate φi. However, it may generally be
the case that different ˆT S are estimated for different devices
or even different samples coming from the same device.
To overcome this issue, we can choose some ˙T close to T S
and use this same modulus to calculate φ ˙T
i mod ˙T for
different samples. This places all φ ˙T
in the same congruence
i
class, enabling samples from different devices to be compared.
˙T will
However if
occur. An example of phase wrapping is shown in Figure 4
where Devices C and F both run slightly faster than the chosen
˙T is not close to T S, phase wrapping in φ
i ≡ tR
˙T . Points of phase wrapping are denoted speciﬁcally by the
ticks of CS and ˙C diverging, i.e., ∆ki either increases or
˙T occurs when the rate of
decreases. An aliasing effect in φ
phase wrapping exceeds the event rate, and if phase wrapping
occurs too often, aliasing prevents accurately measuring jitter
and other properties of CS. It is therefore necessary to choose
˙T close enough to T S such that a sufﬁcient number of events
are observed between points of phase wrapping.
Choice of ˙T depends partly on the inter-event times τ. Let
r = 1(cid:104)τ(cid:105) be the event rate. Note that r is both user dependent
(e.g., how fast someone types) and peripheral-dependent (e.g.,
sampling rate of the sensor). The expected number of events
between points of phase wrapping is given by n = r|∆f|. That
˙T .
is, n estimates the average length of unbroken segments in φ
The segment length provides guidance on how close ˙T should
be to T S, or alternatively, how large a frequency offset can be
tolerated in the instantaneous phase estimates. For example, to
achieve an expected segment length of 20 events with event
˙T should be chosen such that |∆f| ≤ 0.5Hz,
rate r = 10Hz,
i.e.,
should be within 0.5Hz of f S.
˙f = 1
˙T
Selecting ˙T to compare φ
˙T from different devices may be
appropriate for samples within the same device class, i.e., two
devices with the same fundamental frequency. However, we
observed a variety of fundamental frequencies among desktop
and mobile devices (see Section IV-A). This motivates the
construction of a phase image, obtained by stacking many rows
of φ
be the instantaneous
phase of event i determined with clock period Tm, where
i ∈ {1, . . . , N} and m ∈ {1, . . . , M}. The phase image Φ
is structured as
˙T for various choices of ˙T . Let φTm
i
(12)
φT1
1
φT2
1
...
φTM
1
Φ =
φT1
2
φT2
2
...
φTM
2
. . . φT1
N
. . . φT2
N
...
...
. . . φTM
N
where rows of φTm are concatenated together forming an
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:54 UTC from IEEE Xplore.  Restrictions apply. 
1025
020406080100Event051015Phase (ms)Device A020406080100Event051015Phase (ms)Device B020406080100Event051015Phase (ms)Device C020406080100Event02468Phase (ms)Device D020406080100Event02468Phase (ms)Device E020406080100Event02468Phase (ms)Device FM × N matrix. Since the same set of moduli are used
to calculate each image,
the phase images from different
samples are comparable: each row corresponds to a particular
congruence class.
The choices of Tm should span all possible subject clock
frequencies that may appear in the device population. The
above criteria for choosing ˙T based on event rate suggest that
the {T1, . . . , Tm} should be evenly spaced in the frequency
where
domain such that
n is the desired segment length. The average event rate in
the combined dataset is about 10Hz (i.e., 5 keystrokes/second,
and each keystroke emits keydown and keyup events). With
a 10Hz event rate, setting fm+1 − fm = 1Hz (i.e., 1Hz
spacing between fm) ensures that (cid:12)(cid:12)fm − f S(cid:12)(cid:12) ≤ 0.5Hz, thus
Tm
|fm−f S| ≥ n for at least one fm = 1
r
the expected segment length is n = 20 events.
With small enough spacing between the fm, the phase image
simultaneously captures dominant frequency, skew, and drift,
in addition to jitter. To see this, consider the phase image of
T S . The fundamental
a subject clock with frequency f S = 1
frequency is given by fm closest to f S and will correspond
to the row in Φ that appears most regular. With no timing
jitter and Tm = T S, then φTm would remain constant; with
fm slightly less or greater than f S, the phase would gradually
change due to drift.
i
Likewise, skew of the subject clock can be estimated from
the phase image. Considering fm closest to f S, a reﬁned
estimate of subject clock frequency (i.e., offset between f S and
fm) can be obtained from φTm. Let d be the slope of the line
formed by points {(ti, φTm
) : ∆ki = 0}, i.e., points at which
actual and intended subject clock ticks are equal which occur
between discontinuities in φTm. Then ˆf S is given by d
. A
Tm
more robust estimate of f S could be obtained by unwrapping
the instantaneous phases to remove discontinuities [55].
Figure 5 shows example phase images from four differ-
ent devices. The shape of each image is 481 × 600 × 1,
where dimensions correspond to 481 frequencies, 600 events,
and 1 channel. We consider only integer valued frequencies,
fm ∈ {20, . . . , 500} for several reasons. Timestamps were
obtained through Date.now() which provides a 1kHz ref-
erence clock, forcing the upper bound of 500Hz due to the
Nyquist Theorem. The lower bound of 20Hz was chosen to
avoid the measurement of user behavior, which occurs in the
range of 1-10Hz. Finally, spacing of 1Hz was chosen as this
provided adequate bounds on segment length given the average
event rates in both datasets, which is approximately 10Hz.
More importantly, integer-valued frequencies enable comput-
ing the phase image with primarily ﬁxed point arithmetic.
We found that ﬂoating point precision loss due to rounding
errors signiﬁcantly degraded the resulting device ﬁngerprints.
See Appendix B for implementation details on calculating
instantaneous phase with minimal precision loss.
B. FPNET
Similar to face images and other high-dimensional data,
a method is needed to extract representative features from
the phase images. We deﬁne a convolutional neural network
(CNN), FPNET, for this purpose. The architecture of FPNET
was developed speciﬁcally for phase images using techniques
inspired by face recognition [54]. Acting as a feature extractor,
FPNET consists of a function f (Φ) that produces a compact
embedding x ∈ R128 (128-dimension vector) from phase
image Φ. The model is trained with triplet loss to produce
embeddings that can be used for a variety of device ﬁnger-
printing tasks, such as device identiﬁcation and proﬁling.
importantly,
Phase images differ from face and other natural images
in several ways. Most
the axes of the phase
image have different units: rows correspond to the frequencies
used to calculate instantaneous phase, and columns correspond
to the event index. There is a natural ordering along both
dimensions, with time progressing along the columns and
frequency increasing along the rows. We considered several
different network architectures that have worked well for face
and natural images (e.g., [56]) and ultimately converged to
the structure in Appendix C (Table VII). The design choices
in FPNET were motivated by several factors.
One of the key strengths of convolutional networks is loca-
tion invariance, a result of having locally connected regions in
the convolutional layers. With phase images however, each row
corresponds to a difference congruence class. Characteristic
trends may occur along different rows, and these trends carry
a location dependence within the image. That is, depending on
the device class, one or more rows in the image may appear
“regular” (e.g., see Figure 4), the location of which depends on
the fundamental frequency. For this reason, FPNET is struc-
tured to achieve location sensitivity along rows and location
invariance along columns with several deﬁning characteristics:
• 1 × 2 pooling layers only. By pooling only along the
time axis, location sensitivity along the frequency axis
is achieved. This creates a rectangular receptive ﬁeld at
each layer, which widens over events and remains narrow
over frequency.
• 1× 3 convolutional layers followed by 3× 3 convolution
layers. The 1×3 kernels force early layers in the network
to focus on sequential patterns. It is not until halfway
through the network that 3 × 3 kernels begin to consider
phase from neighboring rows.
With this structure, receptive ﬁelds grow linearly along the
frequency dimension and exponentially along the event di-
mension, eventually spanning the image width.
C. Model training
FPNET is trained using triplet loss [57], a metric learning
technique in which triplets of images are presented to the
network and the distances between images are ranked. During
each iteration of training, the model is presented with three
examples: an anchor, a positive example, and a negative
example. The positive example shares the same class as the
anchor and the negative example comes from a different class.
The triplet loss function is given by
L (ΦA, ΦP, ΦN) = max{d(ΦA, ΦP) − d(ΦA, ΦN) + α, 0}
(13)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:54 UTC from IEEE Xplore.  Restrictions apply. 
1026
Fig. 5. Phase images from four different devices with dominant frequencies (left to right): 60Hz, 64Hz, 100Hz, 125Hz. Zoomed insets are centered on the
dominant frequency of each device showing regular patterns in different parts of the image. Pixel intensity represents instantaneous phase along each row.
where α is a margin and function d(·) is the Euclidean distance
between embedded images,
d(Φi, Φj) = (cid:107)f(Φi) − f(Φj)(cid:107)2 .
(14)
In this way, the model learns to rank distances. Within-class
distances are forced to be smaller than the margin α, and
between-class distances are forced to be larger than the margin.
We set the margin α = 1 for model training.
In addition to triplet loss, we use an online triplet mining
strategy [54]. Within each batch the losses from only semi-
hard triplets are considered. Semi-hard triplets are those for
which the negative example is further from the anchor than
the positive but still within the margin α. That is, only triplets
for which d(ΦA, ΦP)  1 in addition to rank-1 accuracy. With rank-n accuracy,
a query sample is correctly labeled if the true device template
is among the closest n templates to the query. We evaluate
device identiﬁcation using rank-1, rank-10, and rank-100 ac-
curacy with the population size reaching 100k devices. For
perspective, the ImageNet benchmark contains 1000 classes
and it is common practice to report both rank-1 and rank-5
accuracy [58].
Device veriﬁcation is a binary classiﬁcation problem in
which one must decide whether two different phase images
belong to the same device. We compare the distance between
two embedded vectors to a threshold: if the distance is below
the threshold, then the devices are matched; otherwise they are
labeled as a non-match. We evaluate veriﬁcation performance
by two different metrics. The equal error rate (EER) is the
point on the receiver operating characteristic (ROC) curve
where false positive rate (FPR) and false negative rate (FNR)
are equal. We also consider the true positive rate (TPR) at