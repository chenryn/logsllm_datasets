480
460
440
420
400
380
360
340
320
300
l
s
e
p
m
a
s
n
o
i
t
a
c
o
l
d
e
s
a
e
e
r
f
l
o
r
e
b
m
u
N
85
95
Relative weighted road coverage [%]
90
100
280
4:00pm
4:30pm
5:00pm
5:30pm
Time [min]
(a) Comparison
of Maximum TTC against
Weighted Road Coverage in High Density Sce-
nario (Uncertainty-aware privacy algorithm)
(a) Number of Released Location Samples in Peak
Time
55
50
45
40
35
30
25
20
15
10
5
]
n
m
i
i
[
n
o
s
u
f
n
o
c
o
t
e
m
i
t
m
u
m
x
a
M
i
0
45
Random sampling
Uncertainty−aware(reacq) (5min)
No privacy protection
Uncertainty−aware (Tout=5min, Uncertainty th=0.95)
Random sampling (p=0.8)
100
90
80
70
60
50
40
30
e
g
a
r
e
v
o
c
d
a
o
r
d
e
t
h
g
e
W
i
0.99
0.8
0.6
0.4
50
55
Relative weighted road coverage [%]
60
20
4:00pm
4:30pm
5:00pm
5:30pm
Time [min]
(b) Weighted Road Coverage in Peak Time
(b) Comparison of Maximum TTC against Weighted
Road Coverage in High Density Scenario ((with
reacquisition) Uncertainty-aware privacy algorithm)
Figure 10: Time-to-confusion advantages of uncertainty-aware
path cloaking become even more pronounced when compar-
ing algorithms with the trafﬁc-monitoring-speciﬁc (Relative)
Weighted Road Coverage data quality metric.
A priori knowledge. In this work, we have concentrated on data
mining and inference techniques that do not possess any a priori
knowledge about the individual drivers. Even if home identiﬁcation
and tracking in general remain difﬁcult, an analyst could infer sen-
sitive information by focusing on a select individual. For example,
given the home and work position of an individual, it is possible to
determine when the person left home and passed an accident site
because the tracking analysis a priori knows the destination of the
trip. The detailed analysis of this case also remains for future work.
Relaxing trust in location server. The described centralized al-
gorithm requires a trustworthy location server, since the algorithm
Figure 11: The Uncertainty-aware privacy algorithm removes
more samples in low density area, leading to enhanced QoS in
the high density regions, where trafﬁc monitoring information
is most valuable.
needs the full GPS traces of all vehicles. A fully distributed algo-
rithm poses a research challenge by itself, since clients would need
to monitor the positions of neighboring cars, which again raises pri-
vacy concerns. It also appears possible, though, to relax the trust
assumptions in the location server through a hybrid approach, with
additional in-vehicle disclosure control based on coarser informa-
tion about neighbors. Since data quality would only be marginally
affected by missing updates in low-density areas, one could devise
schemes to inform vehicle of the approximate probe density in their
area. Then vehicles could reduce location updates to the server in
the most sensitive low-density areas. To prevent spooﬁng of such
density information, further research could investigate data cross-
validation schemes or secure multi-party computation schemes to
compute density.
Dataset limitations. Finally, we need to point out that the track-
ing results can be affected by the choice of probe vehicles. In our
dataset, most drivers shared the same workplace. Thus, the work-
place acted as a place of confusion, where the tracking algorithms
failed. A random sample of the population would probably not
share such a common location, thus we would expect tracking per-
formance to improve. This would cause both our proposed algo-
rithms and the random sampling method to remove more samples
to meet the maximum TTC. The performance gap between them
might also change from what we have observed in our study. In
addition, our method of overlaying multiple datasets to create one
high-density scenario may not be entirely faithful in representing
true trafﬁc conditions. Due to this overlay, some of the vehicles
may also be driven by the same driver on similar routes, creating
a further bias towards reduced tracking performance. Nonetheless,
we believe our current results provide a valuable ﬁrst step towards
understanding tracking performance in probe vehicle scenarios.
7. RELATED WORK
The question of data anonymity has been studied for some time
(e.g., [38]) but a solution that achieves both strong privacy guaran-
tees and a high degree of data accuracy for time-series location
data remains elusive. Not surprisingly, recent analyses of GPS
traces [34, 28, 26] have shown that simply omitting obvious iden-
tiﬁers from a dataset does not guarantee anonymity. Thus, stronger
protection mechanisms are needed. Speciﬁcally, the k-anonymity
concept [38, 42] has been adapted for location-based services [24,
37, 22]. If user density is high, these solutions can provide suf-
ﬁcient accuracy for applications such as point-of-interest queries,
but as we have shown they do not achieve the high accuracy re-
quirements of trafﬁc monitoring applications with low penetration
rates.
Similarly, random perturbation approaches for privacy-aware data
mining [5, 4], which seek to modify a dataset to guarantee privacy
of data subjects while preserving utility of the data, are not appli-
cable in this context. Noise with large variance does not preserve
sufﬁcient data accuracy, while noise with small variance may be
ﬁltered by tracking algorithms due to the spatio-temporal nature
of the data (in addition to the general weaknesses pointed out by
Kargupta et al. [33]).
Thus, several best effort location data protection algorithms have
been suggested [7, 39, 36, 27, 8], which have in common that they
create areas of confusion where the traces from several users con-
verge. While these algorithms achieve better accuracy and provide
a deﬁned level of privacy in such an area of confusion, they cannot
provide overall privacy guarantees because these areas of confusion
might not occur in lower-density areas.
Anonymity has also been extensively studied in the networking
domain. Starting from Chaum’s anonymous communication [10]
work, researchers have developed MIX networks such as Onion
Routing [23] or Tor [17]. Privacy of location information has been
extensively investigated at the network-level. Network-level pri-
vacy techniques such as mixes and pseudonyms have been devel-
oped for cellular networks [19] and mobile IP [18]. The usage
of silent periods [25, 39, 36, 29], periods of no communication,
was proposed for wireless networks to reduce exposure to tracking.
Sharing a similar approach with swing & swap by Li et al. [36],
Jiang et al. combined three known concepts (silent period, pseudo-
nym update, and control of transmission) to maximize the size of
anonymity set in their work [31]. For sensor networks, two research
groups, Kamat et al. and Deng et al. [32, 15] develop routing al-
gorithms to protect the location of message senders or receivers
(i.e., base station). These approaches are largely complementary to
our work, they could be used in relaying (encrypted) GPS readings
to the trafﬁc monitoring service provider. The work on measuring
communication anonymity [40, 16] also inspired us to use entropy
in deﬁning time to confusion.
Another proposed approach builds on privacy policy languages [13]
and their location-oriented extensions [41] to allow users (or their
automated agents) to make more informed decisions about data
sharing. Such policies may be enforced through access control
mechanisms, such as [21, 45] for spatio-temporal data. Using these
approaches, data can only be shared if the data provider trusts the
data consumer.
8. CONCLUSIONS
In this paper, we have proposed a novel time-to-confusion metric
to characterize the degree of privacy in an anonymous set of loca-
tion traces. We then developed an uncertainty-aware privacy algo-
rithm, which can guarantee a deﬁned maximum time-to-confusion
for all vehicles, even those driving in low density areas. We showed
through experiments with real-world GPS traces that the algorithm
can effectively guarantee a maximum time-to-confusion, while a
random sampling baseline algorithm allows tracking time outliers
for vehicles in low density regions at the same data accuracy level.
APPENDIX
A. PROOF OF THEOREM
Theorem A. Given n non-zero probabilities p0, p1, . . . pn, let H(Si)
be the entropy calculated over the normalized probabilities of the
i ≤ n most probable hypotheses. Then, H(Si) ≤ H(Sn).
PROOF. Let us order the probabilities so that p1 ≥ p2 ≥ p3 ≥
... ≥ pn. We then refer to the set which includes the normalized
as Si.
probabilities from the ﬁrst to the ith one
The entropy of S1 is 0, since the event is certain, and thus S1 ≤
S2. More generally, we know from [12] that the following relation
holds between H(Si) and H(Si+1).
, . . .
p1(cid:2)
i pi
pi(cid:2)
i pi
αH(p1, p2, ..., pi) + H(α, 1 − α) = H(αp1, αp2, ..., αpi, 1 − α) (1)
Since we ordered the probabilities (descending) and (1−α) is the
(i + 1)th probability in Si+1, we also know that (1 − α) ≤ 1
i+1 .
≤ α ≤ 1 holds, given that α ≤ 1 as a probability.
Thus,
In terms of H(Si) and H(Si+1) equation 1 can be rewritten as
αH(Si) + H(α, 1 − α) = H(Si+1). Subtracting H(Si) from
both sides yields equation 2:
i+1
i
H(Si+1) − H(Si) = H(α, 1 − α) − (1 − α)H(Si)
(2)
We now show that this equation must be positive or zero to prove
our theorem. If α = 1 this obviously holds. Otherwise, the right
side of the equation 2 is minimized with the maximum value of
H(Si), which is log i and is obtained with all equal probabilities.
Thus, we now consider equation 3.
H(α, 1 − α) − (1 − α)H(Si) ≥ H(α, 1 − α) − (1 − α) log i
(3)
Since f (α) = H(α, 1 − α) − (1 − α) log i is a monotoni-
i+1 , its minimum is obtained
i+1 ) = (i + 1){log(i + 1) − log(i)} ≥ 0. Therefore,
cally increasing function and α ≥ i
at f ( i
H(Si) ≤ H(Si+1) and by induction H(Si) ≤ H(Sn) holds.
B. REFERENCES
[1] TeleNav. http://www.telenav.net/, 2004.
[2] Inrix. http://www.inrix.com/, 2006.
[3] Intellione. http://www.intellione.com/, 2006.
[4] D. Agrawal and C. C. Aggarwal. On the design and quantiﬁcation of
privacy preserving data mining algorithms. In Symposium on
Principles of Database Systems, 2001.
[5] R. Agrawal and R. Srikant. Privacy-preserving data mining. In Proc.
of the ACM SIGMOD Conference on Management of Data, pages
439–450. ACM Press, May 2000.
[6] A. Beresford and F. Stajano. Location privacy in pervasive
computing. IEEE Pervasive Computing, 2(1):46–55, 2003.
[7] A. Beresford and F. Stajano. Mix zones: User privacy in
location-aware services. In IEEE PerSec, 2004.
[8] C. Bettini, X. SeanWang, and S. Jajodia. Protecting privacy against
location-based personal identiﬁcation,. In 2nd VLDB Workshop
SDM, 2005.
[9] R. Cayford and T. Johnson. Operational parameters affecting use of
anonymous cell phone tracking for generating trafﬁc information.
Institute of transportation studies for the 82th TRB Annual Meeting,
1(3):03–3865, Jan 2003.
[10] D. Chaum. Untraceable electronic, mail return addresses, and digital
pseudonyms. Communications of the ACM, 1981.
[11] A. Civilis and S. Pakalnis. Techniques for efﬁcient
road-network-based tracking of moving objects. IEEE TKDE,
17(5):698–712, 2005. Senior Member-Christian S. Jensen.
[12] T. M. Cover and J. A. Thomas. Elements of information theory.
Wiley-Interscience, New York, NY, USA, 1991.
[13] L. Cranor, M. Langheinrich, M. Marchiori, and J. Reagle. The
platform for privacy preferences 1.0 (p3p1.0) speciﬁcation. W3C
Recommendation, Apr. 2002.
[14] X. Dai, M. Ferman, and R. Roesser. A simulation evaluation of a
real-time trafﬁc information system using probe vehicles. In
Proceedings of the IEEE Intelligent Transportation Systems, pages
475–480, 2003.
[15] J. Deng, R. Han, and S. Mishra. Countermeasures against trafﬁc
analysis attacks in wireless sensor networks. In Proceedings of the
IEEE/Create-Net SecureComm, Athens, Greece, September 2005.
[16] C. Diaz, S. Seys, J. Claessens, and B. Preneel. Towards measuring
anonymity. In 2nd Workshop on Privacy Enhancing Technologies,
2002.
[17] R. Dingledine, N. Mathewson, and P. F. Syverson. Tor: The
second-generation onion router. In USENIX Security Symposium,
pages 303–320, 2004.
[18] A. Escudero-Pascual, T. Holleboom, and S. Fischer-Hubner. Privacy
of location data in mobile networks. In Proceedings of the 7th
Nordic Workshop on Secure IT Systems (Nordsec 2002), 2002.
[19] H. Federrath, A. Jerichow, and A. Pﬁtzmann. Mixes in mobile
communication systems: Location management with privacy. In
Proceedings of the First International Workshop on Information
Hiding, pages 121–135, London, UK, 1996. Springer-Verlag.
[20] M. Ferman, D. Blumenfeld, and X. Dai. A simple analytical model
of a probe-based trafﬁc information system. In Proceedings of the
IEEE Intelligent Transportation Systems, pages 263–268, 2003.
[21] A. Gal and V. Atluri. An authorization model for temporal data. In
Proceedings of the 7th ACM CCS, pages 144–153, New York, NY,
USA, 2000. ACM Press.
[22] B. Gedik and L. Liu. Location privacy in mobile systems: A
personalized anonymization model. In Proceedings of the 25th IEEE
ICDCS 2005, pages 620–629, Washington, DC, USA, 2005.
[23] D. Goldschlag, M. Reed, and P. Syverson. Onion routing for
anonymous and private internet connections. Communications of the
ACM (USA), 42(2):39–41, 1999.
[24] M. Gruteser and D. Grunwald. Anonymous usage of location-based
services through spatial and temporal cloaking. In Proceedings of
the ACM MobiSys, 2003.
[25] M. Gruteser and D. Grunwald. Enhancing location privacy in
wireless lan through disposable interface identiﬁers: a quantitative
analysis. In Proceedings of the 1st ACM WMASH, pages 46–55.
ACM Press, 2003.
[26] M. Gruteser and B. Hoh. On the anonymity of periodic location
samples. In Proceedings of the Second International Conference on
Security in Pervasive Computing, 2005.
[27] B. Hoh and M. Gruteser. Protecting location privacy through path
confusion. In Proceedings of IEEE/Create-Net SecureComm,
Athens, Greece, September 2005.
[28] B. Hoh, M. Gruteser, H. Xiong, and A. Alrabady. Enhancing
security and privacy in trafﬁc-monitoring systems. IEEE Pervasive
Computing, 5(4):38–46, 2006.
[29] Y.-C. Hu and H. J. Wang. Location privacy in wireless networks. In
Proceedings of the ACM SIGCOMM Asia Workshop 2005, April
2005.
[30] B. Hull, V. Bychkovsky, Y. Zhang, K. Chen, M. Goraczko, A. K.
Miu, E. Shih, H. Balakrishnan, and S. Madden. CarTel: A
Distributed Mobile Sensor Computing System. In 4th ACM SenSys,
Boulder, CO, November 2006.
[31] T. Jiang, H. Wang, and Y.-C. Hu. Preserving location privacy in
wireless lans. In Proceedings of the 5th ACM MobiSys, New York,
NY, USA, 2007. ACM Press.
[32] P. Kamat, Y. Zhang, W. Trappe, and C. Ozturk. Enhancing
source-location privacy in sensor network routing. In Proceedings of
the 25th IEEE ICDCS’05, pages 599–608, Washington, DC, USA,
2005.
[33] H. Kargupta, S. Datta, Q. Wang, and K. Sivakumar. Random data
perturbation techniques and privacy preserving data mining. In IEEE
ICDM. IEEE Press, 2003.
[34] J. Krumm. Inference attacks on location tracks. In Proceedings of
the Pervasive 2007, May 2007.
[35] J. Krumm and E. Horvitz. Predestination: Inferring destinations
from partial trajectories. In Ubicomp, pages 243–260, 2006.
[36] M. Li, K. Sampigethaya, L. Huang, and R. Poovendran. Swing &
swap: user-centric approaches towards maximizing location privacy.
In Proceedings of the 5th ACM WPES ’06, pages 19–28, New York,
NY, USA, 2006. ACM Press.
[37] M. F. Mokbel, C.-Y. Chow, and W. G. Aref. The new casper: query
processing for location services without compromising privacy. In
Proceedings of the 32nd VLDB’2006, pages 763–774. VLDB
Endowment, 2006.
[38] P. Samarati and L. Sweeney. Protecting privacy when disclosing
information: k-anonymity and its enforcement through
generalization and suppression. In Proceedings of IEEE Symposium
on Research in Security and Privacy, 1998.
[39] K. Sampigethaya, L. Huang, M. Li, R. Poovendran, K. Matsuura,
and K. Sezaki. Caravan: Providing location privacy for vanet. In 3rd
workshop on Embedded Security in Cars (ESCAR2005), 2005.
[40] A. Serjantov and G. Danezis. Towards an information theoretic
metric for anonymity. In 2nd Workshop on Privacy Enhancing
Technologies, 2002.
[41] E. Snekkenes. Concepts for personal location privacy policies. In EC
’01: Proceedings of the 3rd ACM conference on Electronic
Commerce, pages 48–57, New York, NY, USA, 2001. ACM Press.
[42] L. Sweeney. Achieving k-Anonymity Privacy Protection Using
Generalization and Suppression. International Journal on
Uncertainty, Fuzziness and Knowledge-based Systems,
10(5):571–588, 2002.
[43] K. P. Tang, P. Keyani, J. Fogarty, and J. I. Hong. Putting people in
their place: an anonymous and privacy-sensitive approach to
collecting sensed data in location-based applications. In Proceedings
of CHI ’06, pages 93–102, 2006.
[44] J. M. Wozencraft and I. M. Jacobs. Principles of Communications
Engineering. John Wiley & Sons Inc, 1966.
[45] M. Youssef, V. Atluri, and N. R. Adam. Preserving mobile customer
privacy: an access control system for moving objects and customer
proﬁles. In Proceedings of the 6th MDM ’05, pages 67–76, New
York, NY, USA, 2005. ACM Press.