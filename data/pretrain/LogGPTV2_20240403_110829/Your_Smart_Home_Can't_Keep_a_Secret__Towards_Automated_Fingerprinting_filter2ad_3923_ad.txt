-Softmax layer. The hidden dense layer output is then fed into
the softmax layer for normalization. The output of softmax layer is
the probability distribution indicating how likely a sample belongs
to a category, which sums to one. For our task of multi-class classi-
fication, we select the category with the highest probability as the
final output.
Bidirectional LSTM. The basic LSTM model only looks into the
“past” of a packet when learning contextual information. Bidirec-
tional LSTM (BLSTM) is an extension to the basic LSTM, which
utilizes the information from “future”, by combining another LSTM
layer moving from the end of a sequence to its beginning [20]. In
areas like phoneme classification [22] and sequence tagging [26],
BLSTM significantly improves the performance compared to a tra-
ditional one. Since our model works on a traffic window which
consists of multiple adjacent packets, we can utilize the informa-
tion of the packets transmitted after the current packet to classify
it. The main change we apply on the LSTM layer is to concatenate
cell states of backward and forward LSTM layers and feed them to
the dense layer. Figure 6 shows the structure of the bidirectional
LSTM used in our work.
4 EVALUATION
In the evaluation, we want to understand how our models perform
under different network scenarios. In this section, we first introduce
the datasets we used for evaluation and our evaluation metrics.
Then we describe our three scenes and the corresponding results.
Finally we show several case studies.
As a quick overview of our results, we found LSTM-RNN models
can well handle packet identification tasks with an overall accu-
racy over 92.0% in NAPT and VPN configurations on IoT traffic.
Compared to basic LSTM, bidirectional LSTM performs better, sug-
gesting the packet dependency indeed reveals the patterns unique
to each individual IoT device.
5408710100000.384044311010000.9670.5e-25408710100000.3842.3e-45310100100.6845.1e-3dportprotocolpacket size timeinterval… ...packet 0packet 1packet 2packet n0101dirLSTMblockLSTMblockLSTMblockLSTMblockLSTMblockLSTMblockconcat…...…...…...concatconcatFCFCFC…...softmax…...softmaxsoftmaxInputs…...EmbeddinglayerEmbeddinglayerEmbeddinglayerConference’17, July 2017, Washington, DC, USA
Shuaike Dong, Zhou Li, Di Tang, Jiongyi Chen, Menghan Sun, and Kehuan Zhang
4.2 Pure-IoT Scenario
In this setting, there is only one active IoT device working during a
period of time. Therefore, we assess how HomeMole performs when
traffic is not merged. In practice, such scenario happens when the
rest IoT devices enter hibernation mode.
4.2.1 Baseline Model. We first evaluate the performance of our
baseline model, Random Forest. In this scenario, The purposes are
two-fold: (1) To explore the feasibility of classifying individual
packet without context; (2) To evaluate the effectiveness of features
we selected from packet’s metadata.
Experimental results. Table 4 shows the accuracy of random for-
est in NAPT and VPN configuration. As can be seen, with NAPT
configuration, the random forest can reach a high identification
accuracy on most IoT devices. Among them, smart plugs and net-
work cameras have the highest accuracy while voice assistants
have a lower accuracy ∼ 87%. Compared with NAPT, random forest
performs worse in VPN configuration with a 9.0% decline in overall
accuracy. Accuracy on voice assistant is affected most.
Result analysis. We first use the built-in API provided by scikit-
learn library to obtain feature importance. The results show that in
NAPT, dport, frame length, time interval and protocol hold
an importance factor of 55.5%, 22.8%, 12.8% and 8.0% separately.
In VPN, frame length and time interval take up around 54.9%
and 43.0% separately.
Compared with NAPT configuration, the obvious decline in VPN
mainly comes from the change of dport and protocol (dport
and protocol information is not preserved in the packet between
gateway and VPN server) and partial loss of frame length due to
padding by VPN client.
4.2.2 LSTM-RNN Models. We conjecture that the dependency of
packets can be used for device identification, and we model it
through LSTM-RNN models. Below we evaluate the two proposed
LSTM-RNN models on Dataset-Ind.
Experimental results. Table 4 also shows performance of basic
LSTM and bidirectional LSTM when the input traffic window
contains 100 consecutive packets. We can see that compared to the
baseline, both of the models have seen increase of accuracy on most
devices. The result also shows LSTM-RNN models can well handle
IoT devices producing large volume of traffic like voice assistant.
Impact of traffic window size. We compare the accuracy of LSTM-
RNN models with different window sizes: 20, 40 and 100. The result
is shown in Figure 8. From it we can see for both NAPT and VPN
configurations, LSTM-RNN models perform better when the traf-
fic window size grows. This result indicates the relation between
packets with long timing gap can still provide useful information
for our models. In the following sections, we take 100 as the default
size of our traffic window.
4.3 Noisy Scenario
In this section, we evaluate the impact of non-IoT device traffic on
our task.
4.3.1 Baseline Model. We first tested Random Forest using Dataset-
Noise to understand the impact of non-IoT traffic and traffic fusion.
Given the different traffic volume among devices, the packets we
collect are imbalanced, as Figure 4 shows.
Figure 7: Proportion of device combinations. (geq: greater
than or equal to 7)
4.1 Experiment Settings
Scenarios. We evaluate HomeMole in two scenarios – pure-IoT
(only one active IoT device) and noisy (multiple active IoT and
non-IoT devices). In each scenario, we evaluate HomeMole with two
different gateway configurations – NAPT and VPN.
Datasets. We constructed two datasets for the two scenarios. Each
dataset has an NAPT version and a VPN version. We split each
dataset with the training and testing ratio of 8:2 and conduct 5-fold
cross-validation on it. Below are the details of each dataset.
(1) Dataset-Ind. This dataset contains traffic representations
from 10 individual IoT devices. To facilitate the training pro-
cess of LSTM-RNN models, the dataset is organized into col-
lections of traffic windows, each traffic window only contains
packets from one certain device. To make the dataset
more balanced, we set a number threshold 5,000 for each
device. All IoT devices own 5,000 randomly-selected samples
except Xiaomi hub, tplink plug, orvibo plug and broadlink
plug, due to that they generate much fewer packets than oth-
ers. In total, Dataset-Ind contains 32,760 traffic windows.
(2) Dataset-Noise. This dataset is collected by keeping multi-
ple devices active in the same time period. As a result, the
traffic windows in this dataset are composed of packets from
more than one devices. In total, Dataset-Noise includes
114,989 traffic windows. Figure 7 shows the distribution of
device combinations. From it we can see, 2-device and 3-
device combinations are most common.
Metrics. Since HomeMole is able to classify individual packets, we
measure the effectiveness of HomeMole based on the probability
that the device is correctly identified per packet. We use overall
accuracy (similar to [36]) and category accuracy for our case. For
overall accuracy, we count N as all the packets and Pcorr ect as the
total number of correctly classified packets, and compute Pcor r ect
.
For category accuracy, we assess how HomeMole performs on each
device. For device A, we count N A as all packets belonging to A and
PAcorr ect as A’s packets correctly classified under A. The category
accuracy for A is PAcor r ect
. As an example, the diagonal cells on
the confusion matrix shown in Figure 13 describe the category
accuracy.
N A
N
Your Smart Home Can’t Keep a Secret:
Towards Automated Fingerprinting of IoT Traffic with Neural Networks
Conference’17, July 2017, Washington, DC, USA
config model
average
NAPT
VPN
RF
LSTM
BLSTM
RF
LSTM
BLSTM
92.2
97.3
99.2
83.2
92.4
97.7
echo
dot
89.0
98.5
97.0
76.1
89.7
96.6
google
home
85.9
91.6
99.2
81.2
89.7
96.8
tmall
assistant
xiaomi
hub
89.6
98.6
99.9
94.0
96.1
99.4
360
cam
99.0
99.9
99.9
83.2
95.9
98.5
tplink
plug
99.9
99.9
99.9
89.1
92.2
98.0
orvibo
plug
99.9
99.9
99.9
93.1
95.5
99.5
mitu
story
93.3
98.7
99.3
87.5
96.8
98.9
xiaobai
camera
98.5
99.9
99.9
90.5
94.7
99.7
broadlink
plug
99.3
99.9
99.9
99.0
95.7
96.7
86.9
93.9
99.8
74.7
75.4
94.7
Table 4: Accuracy of baseline model under pure-IoT scenario
(RF, LSTM and BLSTM stand for random forest, basic LSTM and bidirectional LSTM respectively).
Figure 8: The impact of traffic window size (pure-IoT).
Experimental results. Compared with pure-IoT scenario, Ran-
dom Forest has a prominent decline in the overall accuracy, reach-
ing 84.5% in NAPT and 67.6% in VPN. We also use confusion
matrix across devices to show the classification results by cate-
gory with non-IoT traffic in NAPT and VPN configuration (see
Figure 13 and Figure 14 in Appendix B). From them we can see,
voice assistants, like Echo Dot, Google Home and Tmall Assis-
tant, see larger performance drop compared to other IoTs, with a
∼ 25% decline in NAPT and a ∼ 50% decline in VPN configurations.
Result analysis. We manually check the mis-classified packets
and find that most of them are transmitted through ports 443 and
80. The primary reason is that those ports are likely to be used by
different IoT and non-Iot at the same time, so our model is more
likely to be confused.
4.3.2 LSTM-RNN Models. Experimental results. Figure 9 and
Figure 10 give the comparison results between three models in
NAPT and VPN configurations. The last group of columns (“aver-
age”) shows the overall accuracy. Bidirectional LSTM achieves the
highest accuracy of 92.1% in NAPT and 81.0% in VPN. Basic LSTM
reaches 87.1% and 74.1%. Figure 15 and Figure 16 of Appendix A
show the concrete classification results of bidirectional LSTM by
device categories in two configurations. From them we know: (1)
LSTM-RNN models are good at recognizing traffic in NAPT configu-
ration; (2) LSTM-RNN performs much worse in VPN configuration,
especially on IoT devices like smart plugs (BLSTM: 12.6% for Orvibo,
20.4% for Tplink and 15.9% for Broadlink in 5 cross validations).
Result analysis. From the above results we can see LSTM-RNN
models fail to classify traffic generated by smart plugs in VPN con-
figuration. We find this observation can be ascribed to the sparse
traffic generated by the devices. Due to the relative long time in-
tervals between packets and the low packet amount, the traffic
Figure 9: Performances of three models in NAPT environ-
ment.
Figure 10: Performances of three models in VPN environ-
ment.
generated by smart plugs can be easily “overwhelmed” by traffic
from others, leading to the original relation between packets being
impaired. In extreme cases, packets generated by smart plugs can
be “diluted” to less than 3% in a traffic window (3 in 100 packets).
The situation becomes worse when distinctive features like dport
and frame length are more likely to be confused. In Section 4.4
we show a case of orvibo plug.