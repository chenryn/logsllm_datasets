increases this number exponentially. Hence, an alternate and
more tractable reformulation is needed.
Our key insight is to formulate this as a self-supervised
learning problem. We are given a dataset of scan reports for m
entities over n scanners. Let p ∈ (0, 1) be a hyper-parameter.
Given a scan report Re for entity e of dimensionality n (one
entry per scanner), Mask Generator generates a binary mask
vector Me of dimensionality n where each component takes
the value of 1 with probability p. For example, if p = 0.1 and
n = 80, then we would expect 10% of the mask vector Me
to be 1. Given Me, Pretext Generator1 transforms the scan
report Re such that whenever Me[i] = 1, Re[i] is corrupted
by ‘swap noise’ – i.e., we replace it with the corresponding
entry from Re(cid:48)[i] where Re(cid:48) is a randomly chosen scan report
from the unlabeled dataset. Let Rc
e be the corrupted version
of Re based on Me. We design a pretext task that can output
the original scan report Re from the corrupted scan report
e. Note that we could generate virtually unlimited labeled
Rc
data by generating multiple corrupted versions for each scan
report Re. The learning is performed in two phases. First, we
e and Rt+δ
e
Pretext task 1 takes a single scan report Re and learns the
dependencies within them. The goal of pretext task 2 is to learn
are
the dependencies across time. Suppose that Rt
the scan reports for the same entity e for time t and t + δ.
e as input and produces
We design an SSL task that takes Rt
as output. In other words, we seek to predict the ‘future’
Rt+δ
scan report from the current report. This task is useful for
two reasons. First, while it is often challenging to determine
whether an entity e is malicious from an early scan report,
it is usually much easier after a certain period has elapsed
(dubbed the stabilization period) [8]. Second, this pretext task
results in the predictor learning both the scanner and label
dynamics. If a scanner often ﬂip-ﬂops or lags behind another,
it will be learned by the predictor. Once again, we use a two-
step process where we pass Rt
e that is
then passed to the predictor (Temporal Report Predictor) with
an expected output of Rt+δ
e to the encoder to get z2
δ is a hyper-parameter and depends on the domain at hand.
The granularity of δ could be in hours for fast moving domains
such as Phishing URLs while it could be in days for other
domains. One may obtain the value of δ by analyzing a
time series of scan reports and identifying the appropriate
periodicity that captures major inﬂection points. For example,
[8] ﬁnds that after a malware ﬁle is submitted to VirusTotal
for four weeks, the scanners’ labels become stable and do not
exhibit any hazardous ﬂips. Hence, the value of δ should be
much lower than four weeks. Similarly, works such as [9] and
our analysis for VirusTotal reports for URLs show a delay
∆ in updating VirusTotal labels due to its non-proactive pull
method. Hence, one should set δ ≥ ∆.
.
e
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:03:36 UTC from IEEE Xplore.  Restrictions apply. 
5511
C. Task 3: Temporal Prediction Consistency
VI. PUTTING IT ALL TOGETHER
e
e
Let Rt
, Rt+2δ
e, Rt+δ
, . . . be a time series of scan reports for
the same entity e. For example, these could be the reports for
the same entity taken every δ = 6 hours. Recall that pretext
task 1 learns the scanner dependencies, and pretext task 2 seeks
to predict the future scan report from the current one. A useful
additional constraint is to ensure that the embeddings for the
same entity across consecutive timestamps must be sufﬁciently
similar so that a predictor is likely to make the same prediction
for each of the scan reports in the time series. This constraint
is motivated by the fact that the benignness/maliciousness of
an entity does not change as long as δ is relatively small. If
the entity is malicious, we wish to learn embeddings such that
the predictor can provide consistent predictions for that entity
across the time series. Similarly, if the entity is benign, we
would expect the predictor to give the same label consistently
across the time series. By ensuring that the embeddings are
similar across time, the predictor that we train will be able
to provide accurate and early predictions. This is achieved
through consistency loss that penalizes two temporally con-
secutive embeddings for Rt+δ
based on their Euclidean
distance. Embeddings that are farther are penalized more than
those that are closer together.
D. Embedding Harmonization via Multi-Task Learning
, Rt+2δ
e
e
In a typical SSL setting, one designs a single pretext task
and uses the learned encoder for computing the embeddings.
However, the complexity of the cyber security domain in terms
of scanner dependencies and temporal dynamics precludes this
simple approach. Instead, as discussed before, we design three
inter-related pretext tasks, each of which focuses on different
yet relevant facets of the problem. Each of these tasks takes
a scan report Re as input and uses an encoder to output an
embedding ze that is used by the predictor of the individual
pretext task. This creates a new challenge of harmonization
where we strive to constrain the individual encoders to learn
embeddings that are useful across the tasks.
This is achieved through the use of multi-task self-
supervised learning. We seek to learn each of these three tasks
simultaneously and force the individual encoders to share the
knowledge across these tasks. Intuitively, we learn a shared
representation between the tasks enabling it to generalize bet-
ter by ignoring data-dependent noises. Even though the tasks
are sufﬁciently different, they also share several commonalities
that result in increased efﬁcacy of learning shared represen-
tations and thereby achieve superior prediction accuracy than
training task-speciﬁc models individually. We use the same
model architecture for the encoder for all three tasks. We
use soft parameter sharing where each of the encoders has
its own internal parameters. However, we try to minimize the
(cid:96)2 distance between the parameters to encourage them to be
similar. The parameters of the encoders are weakly tied based
on regularization so that they do not stray widely. Overall,
the self-supervised training is performed without any labeled
data resulting in a generic encoder that takes a scan report and
produces an embedding.
In Section IV, we propose a generative model that learns
the latent variables for each scanner. In Section V, we design
self-supervised learning tasks to learn effective embeddings. In
this section, we describe how to use these learned embeddings
to tackle various downstream problems. For the sake of
concreteness, we focus on the problem of malicious entity
detection. Given a scan report Re, our goal is to output whether
the entity e is malicious or benign as early as possible.
We focus on two key scenarios – one where there is
limited labeled data available, and another with no labeled
data available. Overall, our solution approach is based on the
pre-train and ﬁne-tune paradigm. We use the generative model
and the SSL tasks to learn a good encoder in the pretraining
step. In the ﬁne-tuning step, we leverage the encoder and its
embeddings for early and accurate detection.
A. Scenario 1: Limited Labeled Data
As we shall show in the experiments, it is possible to
reduce the required amount of labeled data using the proposed
embeddings as they encode some domain knowledge. We
consider a scenario with insufﬁcient labeled data to train a
fully supervised model either on the original scan reports or
their embedding counterparts. This falls under the realm of
semi-supervised learning, where the goal is to train a more
generalizable classiﬁer than one that is trained only on the
labeled data. Our proposed approach is based on [28].
e, m2
e , zc2
e , Rc2
e, . . . , mK
e , . . . , zcK
e , . . . , RcK
Let DL be the set of labeled data. Let Re ∈ DL be
a scan report, and ye be the corresponding label (such as
whether e is malicious or benign). For each Re ∈ DL, we
e using the mask generator
generate K masks m1
from pretext task 1 with p = 0.05 – in other words, 5%
of the mask vectors will have a value of 1 and will cause
corruption of Re. We corrupt Re using the masks to obtain
e }. Our key insight is that the label
Rc
e = {Rc1
for both Re and each of the corruptions have to be the same.
Hence, we pass the original and corrupted scan reports, Re
and Rc
e, to the encoder to get the respective embeddings ze
e }. We train a predictor by passing
and Zc
e = {zc1
ze and Zc
e with ye as the expected output for each of them.
Let the predictions be ˜ye and ˜Yc
e }. We
use cross entropy loss between the true label ye and the
predicted label ˜ye. We apply the consistency loss between ˜ye
and ˜Yc
e which penalizes when the predictions for the original
scan report and its corruptions diverge. We then update the
parameters of the predictor by back-propagating both the
supervised and consistency loss. This process is repeated for
each Re ∈ DL. In summary, our solution leverages both
the learned embeddings and the ﬁrst pretext task to learn a
supervised classiﬁer. We observe that our classiﬁer with as
little as 100 labeled data achieves the same performance as
a fully supervised classiﬁer requiring an order of magnitude
more data.
e = {yc1
e , . . . , ycK
e , yc2
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:03:36 UTC from IEEE Xplore.  Restrictions apply. 
6512
Let Rt
be the output
e be the current scan report while Rt+δ
e and zt+δ
be
of the predictor of the second pretext task. Let zt
their corresponding embeddings. Let ˜ze be the concatenated
vector [zt
]. As a pre-processing step, we compute the
concatenated embeddings ˜ze for all entities. Let Z be the set
of concatenated embeddings for all entities.
e, zt+δ
e
e
e
B. Scenario 2: No Labeled Data
This is a challenging scenario where we have to perform the
detection of malicious entities without any labeled data. We
rely on the following insight – while it is hard to predict the
maliciousness of an entity based on the early scan reports,
it is often much easier to predict them based on the scan
reports after the stabilization period [8]. In fact, one could
use relatively simple predictors to achieve high accuracy for
the late stage scan reports. While there have been a handful of
unsupervised models for detecting malicious URLs [10], [23],
they often do not achieve good results for early detection. We
address this conundrum through the predictor for the second
pretext task that can generate the future scan report.
Training an unsupervised model only based on Rt
e or zt
e
would result in sub-optimal performance. Instead, we follow
a three-step process for boosting knowledge transfer from
pretext tasks inspired by [30]. First, we cluster all the vectors
˜ze ∈ Z into two clusters that intuitively correspond to mali-
cious and benign, respectively. Let C1 and C2 be the cluster
centroids. Second, for each ˜ze, we assign it to one of the
clusters based on their proximity to C1 and C2. Finally, we
train a new predictor that takes embedding as input and outputs
the cluster assignment. Speciﬁcally, the model is trained over
e is the embedding of the current
e, ce)} where zt
the set {(zt
scan report Rt
e and ce is the cluster assignment. In other words,
we train a supervised model for predicting the cluster that an
embedding must belong to. Our experimental results and a
number of prior work including [30] show that this approach
works well in the presence of an appropriately trained encoder
which is the case in our setting. Once we obtain the two
clusters, we could identify the malicious cluster in one of two
ways. If one expects the number of benign entities to be larger
than that of malicious entities, then the larger cluster would
correspond to the benign entity cluster. Alternatively, we could
sample a small number of entities (such as 1-5) from either
of the clusters and verify them with some external repository
(such as PhishTank or URLhaus) or obtain the appropriate
label from the domain expert.
VII. EXPERIMENTS
We conduct extensive experiments to showcase the general-
ity and efﬁcacy of SIRAJ. The code for SIRAJ can be found
at https://github.com/qcri/SIRAJ.
A. Data Collection
In contrast to prior works that focus on a particular type
the generality of our approach enables us to
of entities,
conduct experiments over four types of entities – phishing
URLs, malware URLs, malware ﬁles, and blacklisted IPs. The
statistics of the datasets can be found in Table I. Recall that
an entity may have multiple scan reports corresponding to
different scanning time points.
Malware Files. We use the data collected from [8] for our
experiments. This data consists of two partitions. The ‘main’
dataset contains 14,423 ﬁles and their daily labels of 65
scanners from VirusTotal over a period of one year (unlabeled
main). The authors submitted ﬁles that were ‘fresh’ and were
submitted to VirusTotal for the ﬁrst
time. The ‘auxiliary’
dataset consists of 356 ﬁles collected that were manually
veriﬁed by the authors. We use the unlabeled main dataset
to train our generative and self-supervised models and use the
auxiliary dataset for ﬁne-tuning and evaluation.
Phishing and Malware URLs. We collect three different
datasets for pre-training, ﬁne-tuning and ﬁnal evaluation. Our
data collection process is inspired by the data collection
procedure in [8] for malware.
Pre-Training. Malicious URLs are often short lived as it is
economical to create new URLs [33]. Hence, it is important
to track the change in scan reports much more frequently.
Instead of using the 1-day granularity for malware collection,
we collect hourly scan reports for URLs. Our institution has
subscribed access to VirusTotal URL feed, which contains all
the URLs submitted to VirusTotal every day along with the