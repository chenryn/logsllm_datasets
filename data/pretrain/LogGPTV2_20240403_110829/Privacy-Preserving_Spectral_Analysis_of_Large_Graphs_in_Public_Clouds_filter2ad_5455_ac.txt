guish our method from previous studies [36] on privacy-
preserving graph publishing in several aspects. (1) Previous
studies aim to share data and models with curious parties
but preserve node and edge privacy. In contrast, we prevent
data and models sharing from curious parties. (2) Most
existing methods change the authenticity of graph data by
adding or removing nodes and edges. Our method will
completely preserve the authenticity of data as we add
edges only and the edges are encoded with indistinguish-
able E(0)s. (3) In our framework, data disguising is done
individually by each data contributor who only knows a lit-
tle bit of global information (i.e., a histogram of node degree
distribution generated from sample nodes and distributed
by the data owner). Many existing methods have to work
on the entire graph to determine the graph perturbation
scheme [36], which is impractical for big data hosting in
the cloud.
3.4.2 Sparse Encoding for Graph Matrices
We brieﬂy describe the sparse encoding method that pre-
serves the eigen-structure and allows the injections of en-
crypted zero entries. The following discussion will be spe-
ciﬁc to sparse Laplacian graph matrices (i.e., the L matrix
deﬁned earlier) for spectral clustering; other types of sparse
matrices may need different encoding methods.
We use the following transformation that preserves the
eigen-structure. Let H = I − L = D−1W . Let the top-
k eigenvectors of H be the eigenvectors corresponding to
1041-4347 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2018.2847662, IEEE
Transactions on Knowledge and Data Engineering
the largest k eigenvalues. Clearly, we have the following
Proposition.
Proposition 1. The top-k eigenvectors of H are the same as the
bottom-k eigenvectors of L.
It is easier for both the Lanczos and the Nystr¨om meth-
ods to obtain the top-k eigenvectors than the bottom-k ones.
Now, let Hi be the i-th row of H and its element hij , j =
1..N is
hij = (cid:26) 1/Dii
0
if Wij = 1 and i 6= j
otherwise
With integer conversion and sparse encoding, the entries
are encoded as (i, j, E(⌊γ/Dii⌋)), where γ is a large integer
to preserve the desired precision if the edges exist; other-
wise, with some probability pi (to be described) it outputs
(i, j, E(0)), i 6= j.
3.4.3 Bin-Based Differentially Private Graph Perturbation
Algorithm
We will ﬁrst describe the method to protecting node de-
grees and then discuss why it also protects edge existence.
Under the privacy assumption, the adversaries depend on
counting the submitted entries to estimate node degrees or
the existence of edges. The basic idea is to treat adversaries’
estimation on node degrees and edges as queries on the
encrypted matrix.
In the standard differential privacy deﬁnition, the goal
is to disguise any speciﬁc person among the entire set of
persons that are related to the database. Thus, the key
factor, the sensitivity of function, is applied to the whole
dataset, which, however, results in very large sensitivity
for functions related to node degree on graph datasets.
As a result, data contributors have to add many fake
items to achieve the desired differential privacy, which
seriously impairs sparsity. Speciﬁcally, let the query function
F () about node degree be quite general, say ﬁnding the
node degree ranked at k. Let A and A′ be the neighboring
graphs which differ by only one node. Thus, the sensitivity
∆ = max{F (A) − F (A′)} is the difference between the
largest and the smallest node degree. For a graph of N
nodes, this sensitivity can be up to N .
To achieve a better balance between privacy and sparsity,
we use a bin-based method to achieve weaker contributor
indistinguishability, which is reduced from the whole graph
to a subset of nodes in a bin. Speciﬁcally, we sort the
nodes by their node degrees and then partition the degree
distribution by bins. The contributors in the same bin select
the number of fake edges with the bin-speciﬁc parameter,
where the function sensitivity can be much smaller. The
node degree distribution can be estimated with the node
degrees of randomly sampled nodes. This can be achieved
by the data owner asking some randomly selected data
contributors to submit encrypted node degrees before them
submitting the graph data. The data owner can then build
a histogram to approximate the node degree distribution.
Apparently, this additional cost is quite low.
Speciﬁcally, we generate an equi-height histogram with
the sample node degrees, e.g., for a 100-bin histogram, each
bin contains about 1% of the nodes. The number of bins
is chosen so that each bin contains a moderate number of
7
nodes, for example, a value in (50, 100) to provide satis-
factory indistinguishability. Let Ui be the maximum node
degree in the i-th bin, and Li be the minimum degree in the
i-th bin. Now let A and A′ be the neighboring graphs which
differ from each other by only one node in the bin. We can
derive the sensitivity ∆i = max{F (A) − F (A′)} = Ui − Li,
which should be much smaller than N .
According to the noise design of differential privacy, we
derive that the parameter b of Laplace distribution Lap(0, b)
to be (Ui−Li)/ǫ. However, this noise can be negative, which
asks the contributor to remove some edges and thus destroy
the authenticity of data. To avoid this problem, we add an
offset to the noise to make it positive, which reduces the
overall sparsity but satisfactorily preserves both privacy and
authenticity. For a speciﬁc b, we can always identify the
bound p for P r(x  99%) positive. With such an
offset, the number of fake links, ki,j is chosen as follows
ki,j = |pi| + δi,j ,
(6)
where |pi| is the offset and δi,j is a random integer drawn
from Laplace(0, (Ui − Li)/ǫ) to make ki,j > 0. With such a
noise design, the nodes in the same bin satisfy ǫ-differential
privacy on node-degree based functions.
By preserving node-degree differential privacy, edge dif-
ferential privacy is also satisﬁed. We deﬁne A and A′ as
a pair of neighboring graphs, if they only differ by one
edge. The problem of checking the existence of an edge
can be transformed to an edge counting query function.
Let’s look at any arbitrary edge counting functions. Clearly,
the sensitivity of such a function is 1. Thus, Laplace(0, 1/ǫ)
is used to generate the noisy edges. Since the parameter
(Ui − Li)/ǫ used for disguising node degrees is no less than
1/ǫ, the fake links generated for protecting the privacy of
node degrees also protect edge privacy.
Algorithm 3 gives the details of our privacy preserving
sparse submission algorithm. Here, we only discuss two
types of functions for querying node degrees and edges
that are already used to design privacy attacks. However,
our result can be easily extended to other types of query
functions.
Algorithm 3 Privacy preserving sparse submission (H, ǫ,
di,j).
1: input: H: histogram provided by the data owner. ǫ: user
selected parameter for ǫ-differential privacy. di,j: the actual
node degree.
2: ﬁnd the bin that contains di,j, whose upper bound and
lower bound are Ui and Li, respectively;
3: b ← (Ui − Li)/ǫ;
4: p ← b ∗ 3.912;// for p ≈ 3.912 for b = 1 the p linearly scales
with b: p ≈ 3.912b;
5: draw a value δi,j from the distribution Laplace (0, b);
6: ki,j ← |p| + δi,j;
7: add the di,j real links to the list with the sparse encoding;
8: randomly choose ki,j edges from the rest N −di,j edges and
encode them as the encrypted zero entries;
9: submit the items with index (i, j) for j ≥ i if it is an
undirected graph, otherwise submit all di,j + kij items.
1041-4347 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2018.2847662, IEEE
Transactions on Knowledge and Data Engineering
3.4.4 Construction of AHE-Based Nystr¨om Method for
Sparse Matrix
Note that by using the Lanczos method, data owner does
not gain cost reduction from sparse representation, as the
{¯bi} and {A¯bi} vectors are always dense. We thus turn to
the Nystr¨om method to see whether it can beneﬁt from the
sparse representation.
Recall the key steps of the Nystr¨om method in Section
2. Under the cloud-centric framework, Cloud will do the
sampling step and the ﬁnal computation of CV , and Owner
will download E(W ) and decompose W . Typically, the size
of W should be much smaller than the whole matrix but still
incurs a signiﬁcant cost. In practice, m is often set to 0.1N ,
thus asymptotically still a parameter related to N . For this
reason, the Nystr¨om method does not really ﬁt the goal of
O(N ) complexity for data owner processing since W has
a size 0.01N 2. However, W might be much smaller with
sparse representations. Thus, we can assume that E(W ) can
be processed with a reasonable cost.
Challenges. Due to the large size C, N×m, it is expected
to compute DN ×k = CV in the cloud and return D. Since
k ≪ m, e.g., k = 10, this will save the communication and
computation cost signiﬁcantly. An cost-effective solution
seems to upload the matrix V in plaintext so that E(CV )
can be computed with pseudo homomorphic operations.
The challenge is to protect V , as V contains the eigenvectors
of W , which can be used to approximately reconstruct the
link structure of the corresponding nodes and thus does not
meet our security goal.
In the following, we describe the Nystr¨om algorithm that
meets our goals. The key idea of our privacy-preserving
Nystr¨om algorithm is a matrix masking method and the
corresponding protocol.
PrepareNy−AHE(m): Owner asks Cloud to randomly
select m columns as E(C) and from E(C) selects the m
rows for E(W ). Owner then decrypts E(W ) and eigen-
decomposes W to get V .
(P, Q) ← QueryNy−AHE(K, q, EGsparse): The query
q = ( ¯V , ∆) is generated as follows. First, Owner generates a
uniformly random matrix ∆m×k ∈ Zm×k
and an invertible
random matrix Rk×k ∈ Zm×k
. Then, V is masked by
p
p
¯V = (V + ∆)R mod p,
(7)
where p is a large non-secret integer, e.g., with 128 bits to
preserve both privacy and precision. Both ¯V and ∆ are
submitted to Cloud, who will compute both P = E(C ¯V )
and Q = E(C∆) and send them back to Owner. Owner then
recovers CV by CV = C ¯V R−1 − C∆ mod q. Algorithm 5
in Appendix shows the detailed steps.
This algorithm has a few important features. (1) The ex-
pensive matrix-matrix multiplications E(C ¯V ) and E(C∆)
of O(N mk) complexity are conducted in the cloud, which
can be easily parallelized with a framework like MapRe-
duce. (2) The computation by data owner involves much
smaller matrices: the sparse m × m W , and dense yet much
smaller m × k V and ∆. (3) The upload cost is small,
involving only the plaintext ¯V and ∆.
3.5 Security Analysis for AHE-based Constructions
Our security analysis focuses on ﬁnding a simulator S to
generate random queries (this is a bit confusing, calling the
random vectors queries) that an adversary cannot (compu-
tationally) tell from real queries. The proofs will be sketchy.
Figure 2 summarizes the interactions in these constructions
for easier understanding.
8
(a) AHE-based Lanczos
AHE)
(Lan-
(b) AHE-based Nystr¨om (Ny-
AHE)
Fig. 2: Interactions among cloud, data owner, and data
contributors for the AHE-based algorithms.
Security Analysis for Lan-AHE. In the Lan-AHE algo-
rithm, Clouds view includes the seed vectors {sj} and the
perturbed vectors { ˆbi}. As {sj} is a set of random vectors
that do not leak information, we want to show that each
ˆbi cannot be distinguished from any random vectors and
thus any query sequence q is no different from a randomly
generated one. Therefore, the desired simulator S can just
use any random vectors to simulate { ˆbi}.
Proposition 2. ¯bi, i = 0..t, cannot be computationally distin-
guished from uniformly random vectors by the curious cloud who
knows {sj, j = 1..h}.
Proof. We will prove the ¯b0 case, and other cases are sim-
ilar. Let ai = (αi1, . . . , αik)T be the random parameter
vector for the round i, and S = (s1, ..., sh) be the matrix
consisting of sj, j = 1..h, as the column vectors. We rep-
resent the Equation 4 with matrix operations for i = 0:
¯b0 = Sa0 + b0 mod q, with adversary-known S and ¯b0, and
unknown a0 and b0. If S, a0, and b0 are drawn uniformly
at random, the problem of distinguishing  from
uniformly random samples over ZN ×m
p is exactly the
decision version of the Learning with Errors (LWE) problem
[28]: it says that ¯b0 cannot be computationally distinguished
from any uniformly random vectors if b0 is a random vector
and a0 is secret [28]. Therefore, b0 is securely protected. The
same conclusion can be extended to the cases i ≥ 1 with
more unknowns included.
× ZN
p
The setting of h determines the security level of the
protocol. According to Regev [28], ﬁnding approximate
solutions for the LWE problem costs O(2h). Thus, we con-
sider h = 80 for providing roughly 80-bit security in our
experiments.
Security Analysis for Ny-AHE. As Owner’s query ex-
poses the masked matrix ¯V and the random matrix ∆ of
the masking ¯V = (V + ∆)R mod p to the cloud, we need
to show that the masking algorithm effectively preserves
the desired security of V . We can safely assume V 6= 0 for
practical cases. We address this problem from two aspects:
(1) since the matrix V contains the clustering structure of
W , we show that the masking will surely hide the clus-
tering structure; and (2) we show that it’s computationally
intractable to distinguish ¯V from a randomly generated one
of the same size. Therefore, we can conclude our desired
simulator S in the security model can simply produce
1041-4347 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2018.2847662, IEEE
Transactions on Knowledge and Data Engineering
randomly generated matrices of same size as ¯V as the view
of the adversary A.
First, let’s understand how the noise addition disguise
the clustering structure for the rows of V , in (V + ∆)R.
One of the key use of V is the clustering result of the V
rows indicating the clusters in the graph of W , which is the
basic idea of spectral clustering [32]. Consider each column
vector of V as sample values from a random variable.
Then, the signal (e.g., the distribution and the clustering
structure of V ) is covered by the noise if the noise’s strength
(the mean and variance) is large enough. Typically if the
signal-to-noise ratio is ≪ 1, the signal cannot be recovered.
As mentioned in Section 2.4, if we preserve 10 fractional
digits for normalized values in [−1, 1], the values in V are
represented with about 30 bits. In contrast, the values in
∆ are uniformly sampled from [0, q], which has a mean
q/2 and variance q2/12. q can be selected large enough,
e.g., 128 bits, to cover the information in V . In this case,
the signal-to-noise ratio based on variances is around the
scale (230/2128)2 ≪ 1. Thus, the distribution of V + ∆ is
dominated by ∆ and almost uniformly random, which is
not changed by a random transformation (V + ∆)R.
Second, we study the complexity of the attack that
distinguishes a uniformly random matrix from a normal ¯V .
The attack is to decide whether there is a valid pair (V, R)
that generates the given ¯V . There are two choices: either
enumerating R candidates or V candidates. For each possi-
ble R, notated by ˆR, the estimate of V is ˆV = ¯V ˆR−1 − ∆.
The attacker then checks the orthogonality of the column
vectors in ˆV to further screen the candidates. On the other
hand, given a valid orthogonal column matrix ˆV , the test is
done as follows. Let X = ˆV + ∆. To check whether there is
a R to ﬁt ¯V = XR, one can ﬁrst apply linear regression to
ﬁnd ˆR, i.e., ˆR = (X T X)−1X T ¯V . If X ˆR == ¯V , then the test
passes. The complexity of these attacks is determined by the
number of valid ˆR and ˆV . The following proposition shows
that this attack is computationally intractable.
Proposition 3. For values encoded in the h-bit ﬁnite ﬁeld, there
are O(2hk) candidate R or O(2hm) candidate V .
Proof. According to the theory of general linear group of
degree k in a ﬁnite ﬁeld Zp, where p is h-bit, the number
of k × k invertible matrices is Πk−1
i=0 (pk − pi) [11]. It follows
there are O(2hk) such matrices as the valid candidate ˆR to
be checked. Similarly, according to the theory of orthogonal
matrix group, there are O(pm) orthogonal matrices in Zm×m
[11]. Thus, for h-bit p, there are O(2nm) orthogonal matrices.
As V contains k of m orthogonal vectors, there are also
O(2nm) valid ˆV .
p
Clearly, for a sufﬁciently large h i.e., h = 128, the attacks
are computationally intractable.
3.6 SHE-based Constructions
We also consider the SHE-based schemes, as they have been
discussed as practical options for outsourced computation
[17], [24]. The purpose is to understand how they can be
used to construct the solutions and whether they have
advantages over the AHE-based solutions.
SHE-Based Lanczos Method. The core operation
E(bi) = E(Abi−1) can be implemented directly when both
9
A and bi−1 are encrypted with a SHE scheme with only
one-level of multiplication as we have shown in Section 2.
Due to the limited one-level multiplication, the data owner
needs to help recover the result of E(bi) = E(Abi−1) and
re-encrypt it for the next round. Algorithm 6 in Appendix