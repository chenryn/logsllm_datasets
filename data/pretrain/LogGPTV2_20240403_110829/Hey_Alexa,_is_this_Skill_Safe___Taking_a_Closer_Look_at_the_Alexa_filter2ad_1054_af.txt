server errors or unregistered domains; however, some skills
(30 such skills) point to homepages of websites, at times
totally unrelated to the skill.
We also analyzed whether the privacy polices address
the permissions requested. We contacted the authors of
PoliCheck [18] and obtained the source code of their tool
to measure ﬂow-to-policy consistency analysis. As PoliCheck
was designed to analyze data ﬂows, we convert the eight
permissions10 that grant access to privacy-sensitive data into a
set of ﬁrst-party data ﬂows based on a manually constructed
mapping, as shown in Table V. For example, the Postal
Code permission gives the skill access to the country, zip code,
and state. Using the notation from PoliCheck,11 we convert the
Postal Code permission request into the following three
data ﬂows that denote ﬁrst-party collection: (we, country),
(we, zip code), and (we, state). Further, since we are applying
PoliCheck to a new domain, we manually adapt their data type
ontology (shown in Figure 9 in Appendix D) to include the data
types covered by the Alexa permissions. We also performed
trivial modiﬁcations to their code that identiﬁes references to
ﬁrst-party entities within privacy policies by adding terms that
refer to Alexa skills (e.g., “skills”) and extending the synonym
list for a set of entities.
PoliCheck classiﬁes ﬂow-to-policy consistency into two
types of consistencies (i.e., clear, vague) and three types of
inconsistencies (i.e., ambiguous, incorrect, omitted). In our
case, we aim to measure whether the privacy policies disclose
the permissions requested (permission-to-policy consistency).
Therefore, after analysis with PoliCheck, we re-map the data
ﬂows and ﬂow-to-policy consistency results back to the skill’s
permission requests. As this process may result in multiple
consistency types being mapped back to the permission, we
abstract PoliCheck’s classiﬁcation at a higher-level to either
consistent or inconsistent for each data ﬂow. When mapping
back to permissions, we introduce the concept of partial
consistency, which represents cases where the privacy policy
only discloses a subset of the data types granted by a per-
mission request. For example, consider a skill that requests
the Postal Code permission, but only discloses they collect
the user’s country within the privacy policy. In this case, the
Postal Code permission would be partially consistent with
the policy, as it did not also disclose the collection of zip code
and state. Pseudo code for the permission-to-policy consistency
algorithm is provided in Appendix C.
Our initial dataset consists of 1,146 skills that request
one or more of the eight permissions that grant access to
privacy-sensitive data. We exclude 22 skills from the dataset
whose privacy policy link does not directly display a privacy
10Discarding ‘Reminder’ and ‘Notiﬁcation’ as they do not mandate a privacy
policy. We also ignore ‘List read/write’ access as skills typically access lists
created by themselves.
11PoliCheck[18] represents a data ﬂow as (e, d), where data type d is
ﬂowing to entity e. First-party data ﬂows are represented by setting e to “we.”
Fig. 8: Permission-to-policy consistency analysis results
policy. We deploy the modiﬁed version of PoliCheck on these
1,124 skills with 1,447 permission requests, which produce
4,384 ﬁrst-party data ﬂows for analysis. We manually validate
the consistency results from PoliCheck for the 4,384 data
ﬂows by using the validation methodology as documented
in PoliCheck [18]. After manual validation, we found that
PoliCheck correctly classiﬁed the data ﬂows as either con-
sistent or inconsistent with the privacy policy with an 83.3%
precision. During validation, we noticed that most errors arose
from the NER (Named-entity recognition) model not tagging
entities (e.g., skill names) or missing sentence patterns for
sentence classiﬁcation, which can be addressed in future work
with further domain adaption. Note that we corrected the
misclassiﬁed ﬂows during validation, so all results reported
in the following ﬁndings are validated and correctly classiﬁed.
Figure 8 shows the validated results of our permission-to-
policy consistency analysis. In total, only 76.7% (862/1,124) of
the privacy policies completely addressed all of their requested
permissions. Note that 100 skills produced 404 errors when
fetching the policy. We still included these in our analysis, as
the lack of an available policy is equivalent to no disclosures
at all. Surprisingly, 33.1% (41/124) of skills requesting the
Full Name permission did not disclose the collection of
such data in their privacy policy, which requires disclosure
according to various regulations (e.g., CCPA [48], GDPR [2]).
Several of these skills (B07MKPRVPB, B07RWWHK7W,
B07MQKDKMZ, B07MFQH176) requesting the Full Name
permission have privacy policies that explicitly state that they
do not collect information from the user. For a set of 16 skills
requesting the Postal Code and Device Address per-
missions (e.g., B072KL1S3G, B074PZQTXG, B07GKZ43J5),
we found similarly potentially deceptive statements within the
privacy policy (“We never collect or share personal data with
our skills”). These cases may denote a misunderstanding by
the developer on the purpose of providing a privacy policy and
what they are required to disclose when accessing PII.
Two skills that requested the Device Address per-
mission were marked as partially consistent (B076ZWH8ZL,
B07VWR9YX8). However, their privacy policies only discuss
requiring the state and country of the device, which may denote
either that their privacy policies are incomplete or these skills
are over-privileged and should request the more coarse-grained
Postal Code permission.
13
020406080100Percentage of Skills Requesting PermissionPostal Code (488)Device Address (429)Email Address (204)Full Name (124)Phone Number (76)First Name (50)Amazon Pay (29)Location Service (47)Permission (# of Skills)ConsistentPartialInconsistentFinding 9: Around 23.3% of the privacy policies are not
fully disclosing the data types associated with permissions
requested by the skill. Many skills (33.1%) accessing the
Full Name permission did not disclose the collection of
such data in their privacy policy.
We found that two widely-used privacy policy templates
were resulting in 74 permission-to-policy inconsistencies
across 46 skills. The BBB-Template was previously provided
by the Better Business Bureau as a sample privacy policy
template for websites.12 We found 35 skills using the BBB-
Template with 62 permission requests, such as Device
Address (17 skills), Email Address (17 skills), and
Full Name (15 skills). All 62 permission requests were
marked as inconsistent. While the BBB-Template does discuss
collection and sharing of data, it does not disclose the types or
categories of data collected. For example, the BBB-Template
includes overly broad statements, such as, “We are the sole
owners of the information collected on this site. We only have
access to/collect information that you voluntarily give us via
email or other direct contact from you. We will not sell or
rent this information to anyone.” Privacy policies that solely
discuss broad collection of “information” likely do not comply
with the speciﬁcity requirement of disclosures deﬁned by new
regulations (e.g., CCPA [48], GDPR [2]).
The FPP-Template is a checkbox-based privacy policy
generator provided by freeprivacypolicy.com. While the FPP-
Template allows for a conﬁgurable speciﬁcation of the data
collection practices, we found that it was also a source of
inconsistencies due to skills omitting data collection practices.
This omittance of information can likely be attributed to
developers not selecting all of the required checkboxes to cover
their skill’s behaviors or potential lack of expressibility by
the generator. In total, we found 22 skills that used the FPP-
Template requesting 31 permissions. In total, 12 permissions
were marked as inconsistent across 11 skills that used the FPP-
Template, such as Device Address (5 skills), Postal
Code (5 skills), and Phone Number (1 skill).
Finding 10: Privacy policy templates result in potential
regulatory non-compliance in 46 skills. The fact that devel-
opers are relying on these templates and they are resulting in
permission-to-policy inconsistencies highlights an inherent
ﬂaw with the current publishing model of app markets.
While developers are provided rich-APIs to develop their
skills and obtain easy access to PII of end users, there
does not appear to be any guidance to developers to create
proper privacy policies. In turn, this negatively impacts the
transparency of privacy risks placed on end users of these
skills. While prior work [17] demonstrates that privacy pol-
icy templates are negatively impacting the transparency of
privacy practices in the Android ecosystem, we demonstrate
that this problem is also reﬂected in the Amazon Alexa skill
ecosystem and is likely to be a problem in all application
markets that similarly have a low barrier to entry.
12The sample template is no longer available on the Better Business
Bureau’s website (https://www.bbb.org/losangelessiliconvalley/for-businesses/
understanding-privacy-policy/sample-privacy-policy-template/)
VIII. DISCUSSION
Summary. We perform a comprehensive broad analysis of
the Alexa skill ecosystem. This work advances the state-of-
the-art by providing the following insights: (1) we highlight
several gaps in the skill vetting process that can be exploited
by an adversary; (2) we showcase that while common skill
squatting techniques exist (we also found one new technique
which we termed word-spacing) and are effective, there is no
systematic abuse in the wild; (3) we show that 23.3% of the
skills requesting permission to access sensitive user data do not
fully disclose the data types associated with the permissions in
their privacy policies. We open source our data to the research
community to encourage further analysis in this domain [4].
A. Recommendations
Our analysis shows that while Amazon restricts access to
user data for skills and has put forth a number of rules, there is
still room for malicious actors to exploit or circumvent some
of these rules. Auto-enabling skills reduces the distinction
between native and third-party skills; however, users are still
in the dark regarding which skill is responding to their queries.
This can enable an attacker to exploit the trust they have
built with the system. Based on our analyses we propose the
following suggestions:
Skill-Type Indicator. Skill names and invocation phrases
are not required to be unique. This design decision was
made when skills required manual activation through the app,
where users could see the description and developer name.
Since Amazon introduced the auto-enable feature, users are
less likely to know about the skills they are interacting with
and how their data is being used. Alexa could, for example,
provide some form of visual or verbal indicator (e.g., light or
a different voice template) when interacting with a third-party
application. Further HCI research is required to evaluate how
voice assistants can ensure users are aware of what skills are
being enabled.
Validating Developers. We have shown that it is possible
to register accounts with any developer name, even those of
well-known companies. This can mislead users and even be
misused to launch phishing attacks. To improve the situation
Amazon could utilize developer information to validate or ﬂag
trademark infringements. Also, like Google Play store Amazon
can display developer details like contact email address or
website for higher transparency.
(Recurring) Backend Validation. Currently,
there is no
provision to verify if the backend code has changed. A
developer can push any code update once a skill has been
approved without any further veriﬁcation. While we do not
expect Amazon to fully solve this problem as backend code
may go through multiple rounds of updates, the threat needs to
be acknowledged and understood. Potentially random recurring
backend checks can be performed by Amazon.
Privacy Policy Template. Developers only need to provide a
(working) policy link to get certiﬁed and start collecting user
data. There is no check as to whether the policy link conveys
all (or any) of the necessary information that a user might
be interested in learning [22]. This issue can be addressed
14
by asking developers to ﬁll out a simple policy template that
will include what data is collected, for what purpose, for how
long the data is retained, and whether users can delete or
modify their data. Also, a valid contact address should be
provided. Most of these requirements align with the minimum
requirements imposed on companies/developers by GDPR and
CCPA.
B. Limitations and Future Work
Our analysis has a few limitations. First, while our collec-
tion of skill data is the largest to the best of our knowledge, it
is possible that we might have missed many skills. However,
given that we have collected over 90,194 unique skills which
exceeds the 80,000 reported by Amazon in 2019 [24], we do
not foresee any signiﬁcant difference in our reported numbers.
Second, we provide a conservative lower-bound approximation
to demonstrate the existence of skills bypassing the permission
APIs, a more comprehensive estimate could be possible by uti-
lizing more sophisticated NLP techniques. We plan to explore
this in the near future. Lastly, in determining the effectiveness
of different skill-squatting techniques, we tested a relatively
small number of random skills. An fully automated approach
would enable us to scale our test, signiﬁcantly. However,
developing such a fully automated approach is a challenging
problem.
IX. CONCLUSION
In this paper, we analyze skills, which are third-party
applications that are built on top of Alexa. While skills expand
Alexa’s capabilities and functionalities, it also creates new
security and privacy risks. Our study covers skill stores from
seven different countries with the goal to thoroughly analyze
the overall vetting process enforced by Amazon. We identify
several gaps in the current ecosystem that can be exploited by
an adversary to launch further attacks, including registration
of arbitrary developer name, bypassing of permission APIs,
and making backend code changes after approval to trigger
dormant
intents. We also identify common skill squatting
techniques, including one new technique. Moreover, we ﬁnd
that while certain skill-squatting techniques are more favorable,
there is no systematic abuse of skill squatting in the wild.
Lastly, we show that many skills requesting permissions do not
properly address the use of such permission-protected data in
their privacy policies. Based on our ﬁndings, we make several
recommendations to strengthen the overall skill ecosystem.
ACKNOWLEDGEMENT
We thank our anonymous reviewers for their feedback. This
material is based upon work supported in parts by the National
Science Foundation under grant number CNS-1849997 and by
the state of North Rhine-Westphalia. Any opinions, ﬁndings,
and conclusions or recommendations expressed in this material
are those of the authors and do not necessarily reﬂect the views
of the National Science Foundation or the state of North Rhine-
Westphalia.
REFERENCES
[1]
“COPPA: Children’s Online Privacy Protection Rule,” 2019. [On-
line]. Available: http://uscode.house.gov/view.xhtml?req=granuleid%
3AUSC-prelim-title15-section6501&edition=prelim
15
[2]
[3]
[4]
“EU’s General Data Protection Regulation,” 2019. [Online]. Available:
https://eugdpr.org/
“Invoked apps,” 2019. [Online]. Available: https://invokedapps.com/
“A privacy & security analysis of the Alexa skill ecosystem,” 2020.
[Online]. Available: https://www.alexa-skill-analysis.org/
[5] H. Abdullah, W. Garcia, C. Peeters, P. Traynor, K. R. B. Butler, and
J. Wilson, “Practical hidden voice attacks against speech and speaker
recognition systems,” in Proceedings of the 26th Annual Network and
Distributed System Security Symposium (NDSS), 2019.
[6] P. Agten, W. Joosen, F. Piessensand, and N. Nikiforakis, “Adversarial
attacks against automatic speech recognition systems via psychoacoustic
hiding,” in Proceedings of the 22nd Annual Network and Distributed
System Security Symposium (NDSS), 2015.
[7] A. Alexa, “Choose the invocation name for a custom skill,”
2019. [Online]. Available: https://developer.amazon.com/docs/custom-
skills/choose-the-invocation-name-for-a-custom-skill.html
[9]
[10]
[11]
Alexa,”
Amazon,
2019.
[Online].
[Online]. Available:
[Online]. Available:
[Online]. Available: https:
in Privacy Enhancing Technologies
things
Avail-
https://www.amazon.com/Amazon-Echo-And-Alexa-Devices/
[8] A. Alhadlaq, J. Tang, M. Almaymoni, and A. Korolova, “Privacy
in 10th Workshop
(HotPETs),
https://petsymposium.org/2017/papers/
in the Amazon Alexa Skills Ecosystem,”
on Hot Topics
2017.
hotpets/amazon-alexa-skills-ecosystem-privacy.pdf
“Alexa developer console,” Amazon, 2019.
https://developer.amazon.com/alexa/console/ask
“Alexa voice service,” Amazon, 2019.
//developer.amazon.com/alexa-voice-service
“All
able:
b?ie=UTF8&node=9818047011
“Understand
[Online]. Avail-