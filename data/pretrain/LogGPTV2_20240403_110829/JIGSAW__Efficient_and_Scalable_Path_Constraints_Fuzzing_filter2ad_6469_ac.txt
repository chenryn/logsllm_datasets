the constraint is satisfied, we will allow the input byte to be
mutated according to the gradient.
Handling Division and Remainder. During fuzzing, the
JIT’ed function may generate divide-by-zero exceptions. Instead
of capturing and recovering from such exceptions, we add a
check before each divide instruction to see whether the divisor
623
is zero and if so, we simply skip the execution of the current
input. Note that this handling will not prevent JIGSAW from
finding a satisfying solution, as a solution that will trigger
a divide-by-zero exception is not a satisfying solution. This
handling will not prevent the coverage-guided testing from
discovering divide-by-zero bugs either. To detect divide-by-
zero bugs in the PUT, the concolic executor needs to explicitly
check if divide-by-zero is possible (i.e., adding an assertion
for divisor ̸= 0) under the current path constraints.
E. Scaling
While the single thread design presented so far already
provides a much higher branch flipping rate than existing
fuzzers (e.g., AFL and Angora), another major design goal of
JIGSAW is to provide linear scalability to multiple cores. As
mentioned in §III, searching for a satisfying input with JIT’ed
path constraints should be highly scalable, as there are no
interdependencies between different solving threads. However,
constructing the solving task may become a bottleneck. In this
subsection, we discuss how we improve the scalability of task
construction.
Parallelized Solving. We scale the solving to multiple cores
using threads instead of processes, as communication through
shared memory is easier and more efficient. Moreover, two
properties of our JIT’ed functions allow us to do so. (1) They
have no side effects after the invocation, so we do not need
to clean up. (2) They do not have external dependencies, so
we do not need to worry about interference between different
threads. Finally, thanks to property (1), we can further avoid
the expense of creating threads by using a thread pool, because
once a side-effect-free solving task is done, the thread is ready
to handle another task.
Function Cache. While LLVM’s JIT engine is easy to adopt,
it is also much slower than other JIT engines like the TCG
(tiny code generator) from QEMU. Fortunately, many path
constraints collected during fuzzing are very similar (e.g.,
performing the same check over different input data). Based
on this observation, we designed a function cache to minimize
the invocation of the JIT engine. To further maximize the reuse
of compiled testing functions, we also treat all constants in
the constraints as input arguments to the testing function. By
doing so, constraints like a + b < 10 and c + d < 40 can now
reuse the same testing function.
Essentially, our function cache maps a partial AST (excluding
all leaf nodes) to a compiled function. To speed up the look-up
and tree comparison, we added a hash value to each AST node.
Since we treat both input bytes and constants as arguments to
the testing function, each leaf node has a hash value according
to the preorder traversal (i.e., the corresponding argument
index). For each non-leaf node, its hash is calculated using
its operator and the hash(es) of its operand(s) (i.e., hash(es)
of child node(s)). This is similar to a Merkle tree (except we
do not use a crypto hash function), so if the hash values of
two ASTs are different, we do not need to perform a more
expensive recursive equality comparison.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
Since it is important to maintain a high cache hit rate, we
use a global function cache instead of per-thread caches.
Avoiding Lock Contentions. We minimize the use of locks.
First, each task construction thread has its own LLVM JIT
engine to avoid sharing. Second, the dispatcher and solving
threads communicate with a lock-free queue. Third, we
implement the function cache with a lock-free hash table.
Finally, we minimize dynamic memory allocation and use the
TCMalloc [34] from Google to reduce contentions caused by
malloc and free.
V. IMPLEMENTATION
In this section, we provide some implementation details
of JIGSAW and additional components to support end-to-end
fuzzing.
JIGSAW. We implemented JIGSAW in C++ with about 4,800
lines of code. The gradient-guided search algorithm is a re-
implementation of Angora’s. We used the ORC JIT APIs
from LLVM for JIT compilation. We used the CTPL1 for
the thread pool, and an open-source implementation based on
linear probing2 for the hash table. For the heap allocator, we
used the TCMalloc from Google.
Constraint Collector. JIGSAW can support different symbolic
executors as the front-end constraint collector. In our evaluation,
we used our concolic execution engine based on the data-flow
sanitizer (DFSan)3. We chose this DFSan-based constraints
collector for a better comparison with Angora [17]. We re-
implemented QSYM’s dependency forest [77] to identify nested
branches. To support C++ programs, we used the instrumented
libc++ library.
Hybrid Fuzzer. JIGSAW itself acts as a solver. To perform end-
to-end coverage-guided test generation, we still need a fuzzing
driver to close the loop. For the evaluation, we implemented a
hybrid fuzzer based on Angora [17].
VI. EVALUATION
In this section, we evaluate our prototype JIGSAW, aiming
to answer the following research questions.
• RQ1: Does it improve the search throughput?
• RQ2: Can it improve the branch flipping rate?
• RQ3: Can it scale well with the increase of CPU cores?
• RQ4: Can it improve the performance of coverage-guide
testing?
Experiment Setup. All evaluation was done on a workstation
with two-socket, 48-core, 96-thread Intel Xeon Platinum 8168
processors. The workstation has 768G memory. The GPU is
Quadro P5000. To minimize the impact of I/O, we used four
Intel 512G Pro 7600 NVME SSD in a RAID-1 setup. The
operating system is Ubuntu 18.04 with kernel 5.4.0. The file
1https://github.com/vit-vit/ctpl
2https://github.com/cmuparlay/parlaylib/
3https://github.com/ChengyuSong/Kirenenko
TABLE III: Details of real-world applications used for evaluation.
Program Version #Constraints Program
objdump 2.33.1
2.33.1
size
2.33.1
nm
readelf
2.33.1
tiff2pdf 4.1.0
file
5.39
tcpdump 4.9.3
372,880 libpng
604,610 openssl-x509 b0593c0
1,000,000 libjpeg-turbo b0971e4
4c08dd4
1,000,000 mbedtls
803,036 libxml2
2.9.2
c1c2831
c78cbf2
Version #Constraints
626,480
1.2.56
1,000,000
494,695
377,542
942,240
47,387
769,548
1,000,000 vorbis
1,000,000 sqlite3
TABLE IV: Solving capability comparison. The timeout of JIGSAW
is set to one million iterations (JIGSAW-1M). The timeout of Z3
and Bitwuzla is set to 60 seconds (Z3-60s, baseline). The timeout
of Bitwuzla local search (LS) only mode is also set to 1M updates.
Nested means the percentage of solved nested branch constraints.
Single means the percentage of solved last branch constraints.
Solver
Nested vs. Z3-60s Single vs. Z3-60s
Z3-60s
50.07%
STP
49.04%
YICES2
49.07%
Bitwuzla-60s
50.17%
Bitwuzla-LS-1M 48.36%
JIGSAW-1M
46.96%
89.17%
89.13%
89.05%
89.13%
88.40%
87.97%
1.00
1.00
1.00
0.99
0.99
0.98
0.98
1.00
0.97
0.94
-
-
system is XFS. JIGSAW was compiled with LLVM 9.0.0 with
-O3. For Z3, we used version 4.8.7.
Dataset. We used two datasets in our evaluation. The first
dataset includes 14 real-world programs (Table III). We use
this dataset to answer RQ1, RQ2, and RQ3. To answer RQ4,
our main dataset is the Google Fuzzbench [37]. To compare
with fuzzers that are not supported by Fuzzbench, we use part
of our first dataset.
A. Constraint Solving Performance
To evaluate the solving performance, we collected about 10
million path constraints from 14 real-world programs (Table III).
We first use AFL to fuzz the target programs for 48 hours
(single instance, non-deterministic mode, no dictionary). Then
we ran our DFSan-base constraint collector over the corpora
generated by AFL and serialized path constraints required to
negate every branch to files. We chose to load the collected
constraints from files to minimize the impact of the constraint
collector (which will be evaluated in §VI-B). Because the
numbers of seeds found by AFL vary a lot across the programs,
to ensure we have enough constraints from every program,
we only applied a light filter when collecting the constraints,
which avoids duplicated constraints from the same seed. For
programs with more seeds, we cut off at 1 million. The collected
path constraints include both satisfiable and unsatisfiable ones,
reflecting the real scenario during hybrid fuzzing.
Solving Capability. Before evaluating the search throughput
and branch flipping rate, we first compared JIGSAW’s solving
capability with a set of SMT solvers that provide C/C++
bindings,
including Z3 [21], STP [29], Yices2 [22], and
Bitwuzla [48]. For Bitwuzla, we evaluated two different modes:
(1) the configuration that won the SMT-COMP 2021 [49]
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
724
Fig. 2: Constraints processing time distribution (in micro-seconds). Because of the large data set, we use boxenplot [38] for illustration. The
centerline indicates the median. The first two boxes surrounding the center line contain 50% of the data. Each successive level outward
contains half of the remaining data. We use award-winning configurations [49] for Bitwuzla. Bitwuzla-LS is Bitwuzla in local search only
mode.
(denoted as Bitwuzla), and (2) the configuration that only uses
local search without bit-blasting (denoted as Bitwuzla-LS).
Besides trying to understand the limitations of the gradient-
guided search heuristic, this evaluation also helps us to set
the proper timeout for the following experiments. For this
purpose, we used large timeout setups in this experiment: 1
million iterations for JIGSAW (denoted as JIGSAW-1M) and
Bitwuzla-LS, and 60 seconds for Z3 and Bitwuzla. For STP and
Yices2, we either did not find a timeout setting or the timeout
functionality did not work well, to avoid getting stuck in the
middle of the evaluation, we removed timeout constraints (using
Z3) from the dataset when evaluating these two tools. Note that
the version of Z3 we used (4.8.7) does not support timeout on
get_model(), the API to retrieve a satisfying assignment. So
we modified its source code to support a timeout. As a result,
there are cases where Z3 deems the constraints are satisfiable
but cannot return a model within the timeout. We consider
these cases as not solved.
The result is shown in Table IV. All the results returned by
JIGSAW were verified by Z3 to validate their correctness. At
1M iterations, JIGSAW was able to solve 93.8% of the nested
branch constraints Z3 can solve within 60 seconds. We also
evaluated last-branch constraints because, in QSYM [77], the
authors have demonstrated that inputs satisfying just the last
branch can also lead to new coverage in many cases. For last-
branch constraints (i.e., without nested dependencies), JIGSAW
was able to solve 98.65% of the constraints Z3 can solve
within 60 seconds. Based on the results, we conclude that
JIGSAW’s simple gradient-guided search algorithm (§IV-D) is
capable enough to solve most constraints, especially last branch
constraints.
To understand why certain constraints are not solved by
JIGSAW, we analyzed the distribution of the following factors
in the solved and unsolved constraints: (1) involved operations,
(2) AST size of a constraint, and (3) the number of nested
constraints. The result shows the two most important factors.
First, a large portion of constraints with udiv, urem, and xor are
not solved by JIGSAW, due to the loss of gradient. Specifically,
when estimating the gradient, the algorithm adds a small ϵ (±1)
to each input byte and then calculates the change of distance to
the objective (Table II). However, when the constraints include
division or bitwise masking, ±1 is usually too small to change
the distance, so the gradient estimation would fail. The second
factor is a well-known limitation of gradient-guided search:
when the constraints are not convex, the joint-optimization can
get stuck at a local minimum. On the contrary, the backtracing
strategy used by SMT solvers can avoid this. We want to
emphasize again that these are the limitations of the search
heuristic used in our prototype, but are not limitations of the
proposed methodology (i.e., using JIT’ed path constraints to
evaluate inputs); and our approach can be combined with other
search heuristics to overcome these limitations.
Solving Efficiency. Figure 2 shows the solving time distribu-
tion. For JIGSAW, solving time is the fuzzing time. For SMT
solvers, solving time includes checking for satisfiability and
retrieving the solution/model. As we can see, for satisfiable (sat)
constraints, JIGSAW is faster than all but Yices2. The biggest
difference between JIGSAW and other solvers is for unsolvable
(unsat) constraints. Because JIGSAW cannot tell if a set of
constraints are not satisfiable, it can only timeout. As a result,
unsat constraints will consume a lot of time if we set JIGSAW’s
timeout to a large number of iterations. On the contrary, SMT
solvers can tell whether a set of constraints are unsat rather
quickly. We also analyzed the most important factors that
would affect JIGSAW’s solving time using linear regression.
As expected, the top ones are the size of the constraint’s AST,
the number of nested constraints, and the presence of division
operations. We would like to point out again that lacking the
ability to answer unsat queries is not a fundamental limitation
of our methodology, but a limitation of our current prototype;
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:24:56 UTC from IEEE Xplore.  Restrictions apply. 
825
JIGSAWYices2BitwuzlaBitwuzla-LSSTPZ3101103105107JIGSAWYices2BitwuzlaBitwuzla-LSSTPZ3101103105107JIGSAWYices2BitwuzlaBitwuzla-LSSTPZ3101103105107JIGSAWYices2BitwuzlaBitwuzla-LSSTPZ3101103105107Nested Branch SAT queriesNested Branch UNSAT queriesSingle Branch SAT queriesSingle Branch UNSAT queriesand it can be addressed by incorporating more rewriting rules
and a bit-blasting solver similar to Bitwuzla.
Choosing Timeout Setups. To enable more fair comparisons
between different tools on the metric of branch flipping rate,
we need to select appropriate timeout setups. Specifically, the
branch flipping rate is calculated as:
number of satisfying solutions
branch flipping rate =
total process time
Therefore, (1) a too-short timeout will reduce both the numera-
tor (number of satisfying solutions) and the denominator (total
processing time), and (2) a too-long timeout will unnecessarily
increase the denominator. To address this issue, we can either
fix the numerator or fix the denominator. In the following
experiments, we decided to fix the numerator because we do
not know the distribution of easy, hard, and unsat constraints
in the dataset, so if different solvers are not solving the same
set of constraints, then the results could be biased. To this end,
we leveraged the experimental results in Figure 2 to determine
the timeout setups. Specifically, we set the timeout for JIGSAW
at 1,000 iterations (denoted as JIGSAW-1K), which can solve
93.8% of all the constraints that Z3 can solve within 60 seconds.
Similarly, we set the timeout at 50ms for Z3 (denoted as Z3-
50ms), at 6ms for Bitwuzla (denoted as Bitwuzla-6ms), and at
10,000 model updates for Bitwuzla-LS (denoted as Bitwuzla-
LS-100K), which can solve 94.0%, 92.5%, and 94.5% of Z3-
60s.
TABLE V: The throughput (number of tried inputs per second) of
JIGSAW (JIGSAW-1K) and Bitwuzla (BZLA-LS-100K) in a single-
threaded execution. The first half of the table shows the results of
nested branch constraints, and the second half shows the results of
single branch constraints.
Program
objdump
size
nm
readelf
libpng
tiff2pdf
file
tcpdump
openssl
sqlite3
vorbis
mbedtls
libxml2
libjpeg-turbo
Geomean
Nested Branch Constraints
JIGSAW BZLA-LS
Last Branch Constraints
BZLA-LS
JIGSAW
382.3 (±2.1)K 25.7 (±0.5)K 4.3 (±0.8)M 84.9 (±1.4)K
1995.5 (±31.2)K 42.3 (±0.5)K 6.7 (±0.8)M 67.1 (±0.3)K
4649.5 (±33.6)K 45.0 (±1.0)K 13.4 (±1.1)M 82.6 (±0.9)K
622.7 (±8.9)K 28.0 (±0.0)K 7.2 (±0.5)M 90.2 (±0.1)K
820.0 (±5.1)K 28.1 (±0.0)K 1.2 (±0.3)M 121.3 (±1.0)K
280.5 (±7.9)K 29.2 (±0.5)K 4.5 (±0.4)M 82.4 (±1.0)K
431.7 (±6.2)K 40.0 (±0.9)K 4.9 (±0.2)M 56.3 (±0.8)K
1396.9 (±18.4)K 41.3 (±0.9)K 1.7 (±0.1)M 82.0 (±0.9)K
270.2 (±40.4)K 57.4 (±0.1)K 4.2 (±0.1)M 102.5 (±0.5)K
3446.4 (±51.8)K 46.5 (±1.5)K 0.8 (±0.0)M 54.3 (±0.0)K
358.4 (±11.5)K 38.5 (±0.3)K 3.1 (±0.0)M 101.0 (±1.8)K
61.1 (±1.6)K 37.3 (±0.8)K 2.8 (±0.1)M 26.2 (±0.2)K
2629.4 (±13.5)K 21.0 (±0.0)K 2.4 (±0.1)M 69.1 (±0.0)K
110.6 (±4.1)K 6.9 (±0.0)K 0.9 (±3.5)M 42.9 (±0.1)K
71.2K
3.1M
637.2K
31.7K
Single-thread Search Throughput. Because our primary de-