### Permissions and Access Control

In this model, it was feasible to identify all subjects who had any form of access to a specified object, as well as to determine all objects to which each subject had a specified form of access. The concept of interprocess communication implied that subjects could also be viewed as objects. This led to the recognition of a subject as a domain-pair, where the domain included all attributes of the executing process (such as security, integrity, and privilege-state attributes). In a large system, it was tacitly assumed that the matrix \( M \) would be large and sparse. Therefore, implementation concerns suggested that \( M \) should either store its attributes in lists associated with subjects (capability lists) or with objects (access control lists).

Harrison, Ruzzo, and Ullman [10] demonstrated that discretionary access control (DAC), the form of access modeled in \( M \), had a degree of uncertainty equivalent to the Turing Halting Problem. The Anderson Study also resulted in the publication of a series of formal models addressing abstractions of military classifications and clearances, known as nondiscretionary access control (later termed mandatory access control or MAC). The most prominent of these models were those from Case Western Reserve University [26] and D. Elliott Bell and Leonard LaPadula [3]. At the time of their publication and refinement, these models were reputed to have formally provable security properties, although this was later questioned by John McLean [17] and others.

### Reference Monitor Concept

Central to the Anderson Study's framework is the elaboration of the reference monitor concept. Its implementation is a reference validation mechanism (RVM), often referred to as a "security kernel," a term introduced by Major Roger R. Schell at an early Stockton Gaines workshop. The study prescribed three requirements for the RVM:

1. **Tamper-Proof**: The reference validation mechanism must be tamper-proof.
2. **Always Invoked**: The reference validation mechanism must always be invoked.
3. **Analyzable and Testable**: The reference validation mechanism must be small enough to be subject to analysis and tests, ensuring the completeness of such analysis and testing.

The study elaborated on these requirements, emphasizing their significance. If the reference validation mechanism can be tampered with, its validity is destroyed, and any hope of achieving security through it is lost. The requirement that the reference validation mechanism must always be invoked ensures that no security checks are bypassed. The final requirement states that if the reference validation is suspended for some group of programs, those programs must be considered part of the security apparatus and subject to the same requirements. This ensures that the reference validation mechanism is the primary security mechanism in the system, and it must be possible to ascertain that it works correctly in all cases and is always invoked. If this cannot be achieved, there is no basis for certifying a system as secure [2, vol. I, p. 10].

### Operating System Considerations

The Anderson Report recognized that operating systems were larger and more complex than most programs, making exhaustive testing impractical. It called for modularization to support analysis and credible testing. There was also a discussion of the potential for research that would support formal, computer-aided verification assurances in the future.

Like the Ware Report, the Anderson Report recognized the importance of considering the system use environment and functional characteristics as part of the overall risk and vulnerability assessment. It considered secure transaction systems to be the least threatening and most achievable in the context of "open use" multiprogrammed systems. The next most risky category was the High-Order Language (HOL), which raised the possibility of breaking out of the confines of FORTRAN, though no explicit details on how this might be achieved were provided.

### Development Plans and Research

The report outlined several development plans for research and development needed to achieve secure open-use systems. Specific areas of focus included secure networks, security models, security software engineering, security surveillance, certification techniques, architecture research, data integrity and reliability, automatic classification, magnetic media, and computer-aided integrated design. The report also mentioned the possibility of internal encryption of computer programs and data, a technique that could be applied either as an appliqué or as an integral part of the design of computer systems [2, vol. II, p. 44].

### Security Perimeter and Kernel

From the Anderson Report and refined by subsequent working groups, the notion of the security perimeter emerged. This perimeter consisted exclusively of security-relevant code and the minimal subset of the operating system required to support it. The code within the security perimeter became known as the security kernel, the minimal body of code required to enforce the system security policy. Many in the research community claimed that if the "good guys" write the code inside the security perimeter, then the system will be secure, even if the adversary writes the remainder of the operating system and its utilities.

### Access Control Policy Considerations

Through the early 1970s, I worked closely with clients in both military and commercial sectors and became aware of the wide range of discretionary access controls requested by different user groups. Their requirements included:

- **Password-Protected Files**: Where knowledge of a password suffices to gain complete file access.
- **Time-Based Access Controls**: Where specific actions could only be performed on specified days and/or during identified time periods.
- **Group-Based Access Controls**: Where access modes are uniformly applied to users assigned membership in named groups.
- **Role-Based Access Controls**: Where, for example, persons acting in the role of salary administrator may only perform specified accesses and no others.
- **User-Specific Access Controls**: Associated with each user and each protected object, a set of specific modes of access that the user is permitted to have for the object.
- **Prohibited-Access Controls**: Sets of users for whom specific forms of access to objects are specifically prohibited.
- **Combinations of the Above**: For example, a specified user in a particular role at a given time from an administrator’s terminal may access a controlled object in only a specified set of modes.
- **Formularies**: A term coined by Lance Hoffman, where access to a specific object is computed by a specified, possibly ad hoc, function.

Discretionary access control was recognized as being much more complex than a simple label-based policy. The undecidability issues raised by Harrison, Ruzzo, and Ullman, along with additional implementation complexity, suggested that high-assurance systems could not be uniquely based on DAC mechanisms.

### Implementation Considerations

Early attempts at implementing robust, production-quality secure operating systems proved surprisingly difficult, despite the application of sound principles. This was partly due to the lack of experience in dealing with the problems of reducing theoretical objectives of layered architectures, least privilege, and least common mechanism to engineering practice within the framework of information flow confinement.

#### Multics

It has become common contemporary practice for scarcely tested and inadequately debugged software products to be sold commercially. Various vendors, notably Microsoft, have been accused of launching products that have never been subjected to beta testing. Disgruntled customers have complained and lampooned such companies and their programming staffs’ capabilities, not entirely without justification. Knowledge gained from penetration studies highlighted the importance of rigorous testing and debugging in the development of secure systems.