0.9940 0.9836 0.9887 0.9953 0.9514 0.9728
0.9737 0.9487 0.9610 0.9733 0.9481 0.9605
0.9760 0.9598 0.9678 0.9634 0.9634 0.9634
0.9961 0.9958 0.9960 0.9972 0.9955 0.9963
0.9902 0.9846 0.9874 0.9866 0.9826 0.9846
Fig. 11. SPEC 2006 results: Fortran programs
[22]), we only compare our results with them. Because we
tested with the same data set, we directly use the numbers
reported by them. In this ﬁgure (and following ones), “P”
denotes precision, while “R” denotes recall. Note that for each
architecture, every number (for P/R/F1) is a mean over the
corresponding 1032 binaries. To enable direct comparison with
machine learning systems, we followed their practice by using
an arithmetic mean5. The “error ratio” in the ﬁgure is deﬁned
as (1 − M AX(ByteW eight, N eural))/(1 − Ours) for each
column. Our technique reduces the error rate for boundary
identiﬁcation by a factor of 4.32, thus representing a major
improvement in accuracy.
The results for our second and third data sets are presented
in Fig. 9. We compare with the most recent work in this
ﬁeld, Nucleus [5], which is also based on static analysis. We
followed their way of summarizing results: using an average of
geometric means for all optimization levels. Our F1 scores for
this data set are consistently above 0.99, signiﬁcantly higher
than those of Nucleus (around 0.92). We omitted zooming into
each optimization level since our results are not sensitive to
them: the F1 score differences are within 0.01.
As shown in the last two lines of the ﬁgure, ours is the
ﬁrst work that evaluates with GLIBC. Despite the challenges
posed by PIC-code, hand-written assembly and other low-level
features, our techniques achieve an F1-score above 0.98.
VII-E. Detailed Evaluation
In this section, we present detailed evaluation for our second
data set: SPEC 2006 programs. For space reasons, we focus
on the most widely used optimization level: -O2. As shown in
Fig. 10 and Fig. 11, for a wide range of applications written in
three different languages (C, C++ and Fortran) and compiled
with two compilers (GCC and LLVM6), our overall F1-scores
are no lower than 0.9817 for function boundaries. Note that
overall metrics are computed by using the aggregated true
positives, false positives and false negatives over the selected
fraction of binaries. For many individual binaries, we have
achieved perfect (1.0000) precision and recall.
Distribution of Different Call Types. To understand how each
step of analyses contributes to the ﬁnally identiﬁed functions,
we list the corresponding results for SPEC 2006 programs
in Fig. 12. To conserve space, only GCC (-O2) compiled
programs for x86-32 architecture are shown. Note that x86-64
binaries have similar results to their x86-32 counterparts.
5When using geometric or harmonic mean to summarize our results, the
difference is less than 0.0006.
6LLVM does not have an ofﬁcial frontend for Fortran.
208
Binary
400.perlben.
401.bzip2
403.gcc
429.mcf
445.gobmk
456.hmmer
458.sjeng
462.libquan.
464.h264ref
433.milc
470.lbm
482.sphinx
471.omnet.
473.astar
483.Xalan
444.namd
447.dealII
450.soplex
453.povray
410.bwaves
416.gamess
434.zeusmp
435.gromacs
436.cactus.
437.leslie3d
454.calculix
459.Gems.
465.tonto
481.wrf
Overall
Indi-
Direct
jump (%)
Total
funcs.
1742
81
4653
34
2543
504
146
109
535
246
28
338
2036
98
Direct
call (%)
48.22
61.73
68.56
73.53
26.27
54.96
72.60
68.81
79.63
79.67
75.00
70.71
27.36
75.51
33.62
45.71
26.90
43.42
58.88
58.82
94.79
66.28
70.36
44.47
71.88
69.43
78.21
68.87
55.40
48.06
rect (%)
40.18
9.88
20.89
17.65
70.31
5.56
8.90
6.42
7.29
3.25
21.43
3.85
56.93
8.16
53.84
51.43
30.46
38.93
30.14
35.29
0.59
6.98
4.09
14.80
18.75
0.45
6.41
0.73
0.66
30.83
Fig. 12. Functions identiﬁed in each step
0.46
1.23
2.82
0.00
0.55
2.98
4.11
3.67
2.80
0.81
0.00
1.18
1.82
0.00
2.60
0.00
1.20
3.32
1.59
0.00
1.04
0.00
1.09
0.76
0.00
2.24
2.56
4.05
3.84
2.16
13525
105
7242
935
1639
17
2898
86
1100
1311
32
1338
78
3851
2888
50138
Unreach-
able (%)
11.14
27.16
7.57
8.82
2.87
36.31
14.38
21.10
10.28
16.26
3.57
24.26
13.36
16.33
9.18
2.86
37.21
11.98
6.47
5.88
3.49
25.58
24.36
39.97
9.38
26.83
10.26
24.51
39.89
17.70
Binary
400.perlben.
401.bzip2
403.gcc
429.mcf
445.gobmk
456.hmmer
458.sjeng
462.libquan.
464.h264ref
433.milc
470.lbm
482.sphinx
471.omnet.
473.astar
483.Xalan
444.namd
447.dealII
450.soplex
453.povray
410.bwaves
416.gamess
434.zeusmp
435.gromacs
436.cactus.
437.leslie3d
454.calculix
459.Gems.
465.tonto
481.wrf
Overall
argument
0
379
245
130
1
89
43
0
16
130
0
Total Control ﬂow checking (%) Data ﬂow checking (%)
exit
pruned entry
callee-save
91.60
1630
79.57
100.00 33.33
48
86.35
94.06
5845
0.00
0.00
61.48
89.18
81.63
89.80
44.62
99.23
0.00
0.00
73.03
89.89
97.67
88.37
0.00
0.00
31.25
31.25
76.92
72.31
0.00
0.00
65.55
46.03
50.00
0.00
18.10
65.80
75.44
84.65
38.76
91.39
0.00
0.00
56.99
79.18
0.00
50.00
87.50
84.44
80.59
95.48
100.00
0.00
87.36
75.09
76.39
80.56
90.74
88.90
93.71
77.45
77.44
73.32
3088
14
360
376
2
269
72
1631
572
21360
Fig. 13. Effects of each checking mechanism
internal
39.26
89.58
38.25
0.00
37.73
40.41
45.38
0.00
37.08
6.98
0.00
18.75
22.31
0.00
21.14
50.00
17.77
26.32
19.48
0.00
35.65
57.14
34.44
56.65
100.00
53.53
50.00
17.78
27.97
31.75
53.31
87.50
46.14
0.00
40.37
60.82
80.00
0.00
66.29
65.12
0.00
12.50
43.08
0.00
54.96
100.00
57.16
56.58
16.10
0.00
52.91
50.00
35.56
58.24
50.00
37.17
62.50
40.34
36.71
47.17
57.67
85.42
71.87
0.00
46.70
76.33
72.31
100.00
84.27
69.77