### 2. Databases Used

- **Compendex (CPX)**: Fully searched.
- **IEEE Xplore (IEEE)**: Fully searched.
- **ACM Digital Library (ACM)**: Partially searched to validate the completeness of the selected results. Specifically, the top 10% of the most relevant results, as ranked by the database's search engine, were examined.

These databases cover a majority of the journal and conference papers published in the field of software engineering. Technical reports and other documents without peer review were excluded due to the difficulty in assessing their quality and the large volume of results they would generate if included.

### 3. Search and Data Processing

After performing the search, we manually removed and resolved overlaps and duplicates from different sources. The first three databases were fully searched, while only the top 10% of the most relevant results from the ACM Digital Library were examined to check the completeness of the set of results. If a significant number of relevant results had not already been included, the search would have been expanded.

### 3.3. Search Criteria

The following search criterion was used on the title, abstract, and keywords fields:
```
(robust OR robustness) AND software
```

A start date of 1990 was set for the systematic review, aligning with the formal definition of robustness in software engineering introduced by the IEEE standard glossary [1]. This date was also chosen because important works published before 1990, such as [76, 23], have been referenced and further developed in studies published after 1990. Only papers in English were included.

Depending on the functionality provided by the database search engines, we excluded results outside the field of software and computers. This was necessary due to the wide use of the term "robustness" in unrelated fields such as mechanics and agriculture. Since papers related to both software and one of these fields are also categorized under software, excluding these results did not exclude any relevant studies.

Applying these criteria to the three initial databases yielded 9,193 non-unique results. Due to the large number of excluded papers based on titles, the results were exported to our reference management program after the title exclusion step. Therefore, the exact number of unique initial results is unknown, and we can only present the cumulative number of hits from the three databases.

Search results in the databases were sorted according to relevance. Our observations indicated that this criterion was accurate for our study, as the number of included results dropped rapidly when classified as less relevant by the databases.

### 3.4. Study Selection

We developed exclusion and inclusion criteria for the selection of studies, which are described below:

#### Exclusion Criteria Based on Title:
- Papers discussing fields other than software.
- Short papers under 5 pages.
- Papers where "robustness" is used as an adjective to describe something unrelated to software.

#### Exclusion Criteria Based on Abstract:
- Papers using "robustness" in a different meaning or claiming robustness without focusing on how and why it was achieved.
- Papers with a completely different focus than software robustness or software quality.

#### Exclusion Criteria Based on Full Text:
- Similar to the abstract criteria, but applied at the full-text level. Papers claiming robustness without elaboration on the process were excluded.

### 3.5. Data Extraction and Synthesis

Papers clearly not related to software robustness based on the title were excluded. In total, 753 studies were included. After the initial selection, the cumulative number of unique results after each search in the final database was 282, 561, and 601, indicating a high number of duplicates between the databases. These numbers are presented in Table 1.

| Database | ISI | CPX | IEEE | ACM | Total |
|----------|-----|-----|------|-----|-------|
| Search Date | 2010-12-31 | 2010-12-31 | 2010-12-31 | 2010-12-31 | 2010-12-31 |
| Total Hits | 2,264 | 3,976 | 2,953 | 3,645 | 9,193 |
| Title Filtering | 282 | 371 | 148 | - | 801 |
| Cumulative Unique | 282 | 561 | 601 | 601 | 601 |

In the second phase, the abstracts of the 601 included studies were reviewed. Sixteen more papers were excluded based on the title, 20 were excluded for being short papers, and 280 were excluded based on the abstracts. In the third phase, 134 more studies were excluded, leaving 144 studies for the next phase of the review. Statistics on the exclusion process are shown in Figure 1.

The final 144 selected papers were categorized based on the research questions. The categories used for each research question are presented in Table 2.

### 3.5.1. Selection and Extraction Validity

**Validity Control I:**
From the 601 papers that passed the initial title filtering, 60 (10%) were randomly selected and reviewed by the second author. There were six deviations between the judgments of the two authors. After reviewing these, two initially excluded papers were judged to be included, but they were eventually excluded in the full-text filtering step. This control suggests that 10% of the results showed 10% irregularity.

### Table 2: Categories for the Research Questions

| Category | Subcategories |
|----------|---------------|
| Phase Focus | Distributed and network, Requirement, design & implementation, Evaluation, Analysis, Verification and validation (V&V), General |
| System Focus | Web application, Real-time/safety critical, COTS, Operating systems, Embedded systems, General |
| Research Type | Philosophical paper, Solution proposal, Evaluation paper, Experience report, Review, Investigation, Call for research |
| Contribution | Tool, Method, Framework, Evaluation, Metrics, Model, Review |
| Evaluation | Academic lab/toy, Large academic, Open source systems, Small industrial, Large industrial, No evaluation |