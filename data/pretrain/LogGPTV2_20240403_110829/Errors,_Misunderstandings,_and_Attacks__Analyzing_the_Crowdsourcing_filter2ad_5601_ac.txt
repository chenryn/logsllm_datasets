average of days between submitting the report and correcting the
error, “SD” is the simple stander deviation of that periods.
than ten posts in the forums
• Senior Member: registered long-term users who have more
• Veteran: users determined by the forums administrators as
having made significant contributions to reporting errors. or
correcting bugs
• Developer: ad-block software developers
• Other List Editor: authors of other filter lists such as non-
English lists or privacy lists
We found that anonymous users have the highest contributions
in reporting errors. FP errors were particularly skewed towards
anonymous and new Members. FN errors were more evenly
divided among four of the user categories.
EasyList editors were more concerned about FP errors. This
was reflected by the fast response and standard deviation of solv-
ing the errors. However, the Editors’ responses were faster to the
anonymous FN reports than to the anonymous FP reports. The high
portion of contribution done by anonymous and the quick response
by the editors raise the concern about the credibility of the reports.
The individual contribution on reporting FP and FN errors varies.
From dataset D2A, we computed the number of reports submitted
by an individual user. Table 3 shows the average number and the
standard deviation of FP and FN error reports submitted by each
user in different user categories. We excluded the Anonymous
category because the anonymous users do not have “permanent”
profiles. Among all the groups, we found that the individual users
in the Veteran class have the highest activities on correcting FP
and FN errors. However, unlike other categories, the contribution
among individual users in the Developer class tends to correct more
FP errors than FN errors.
4.2 Websites Affected by FP and FN Errors
We studied the prevalence of FP and FN errors based on the set of the
websites referenced in our dataset. We focused on the popularity of
the websites to analyze two aspects: the estimated user population
impacted by the errors, and the crowdsourcing ability to detect the
errors in the websites of different ranks.
For this analysis, we need to
Website Popularity Ranking.
determine the popularity of a given website. To do so, we reference
web ranking services that rank website based on traffic volume
235
FP
Avg. Report\User
FN
1.97
6.24
8.25
Title
1.16
New Member
2.32
Senior Member
Developer
13.83
Other Lists Editor 24.12 11.67
25.90 17.00
Veteran
37.56 16.00
Editor
17.34 39.59
Avg.
SD.
FP
FN
4.61
0.50
18.47 2.02
17.40 11.69
96.39 12.52
42.68 21.28
57.99 17.22
10.33 10.87
Table 3: Average number of FP and FN error reports submitted
by each user in different categories of users: “Avg”. is the average
number of reports submitted by individual user, “SD” is the simple
stander deviation of the number of reports.
(i.e., number of visitors). Web ranking services such as Alexa [3],
Cisco Umbrella [28], Majestic [33], and Quantcast[63] serve the
same purpose, and yet, their rankings are not always consistent
with each other [58, 65]. In this paper, we chose to use Alexa’s
ranking for its coverage and the ability to access historical data.
More specifically, Alexa list covers more than one million websites
and provides access to the statistics for the past four years.
There are additional steps we took to improve the reliability of
our analysis. First, Alexa list might be impacted by weekly patterns
or daily changes [65]. As such, we utilized the premium API [5] to
obtain the 3-month average rank instead of the daily and weekly av-
erage. Second, the ranking might be changing over time. Although
we can obtain the past 4 years of data, our analysis covers the past
10 years. To this end, instead of looking at the specific ranking,
we focused on the higher level “ranking range”. We grouped the
websites ranks into more coarse-grained ranges so that the ranking
fluctuation would have a smaller impact on the overall conclusion.
Finally, to validate our conclusion, we used another ranking service
Umbrella [28] to generate another set of results for comparison.
The analysis is limited to Top 1 million domains, which is the limit
of Umbrella.
We first ranked the websites according to Alexa rank. Using that
rank, we classified the websites into seven classes. The first class
was the 500 top-ranked websites. The second class was called No
Rank (NR) class. It contains small websites that were not ranked in
Alexa because there was not enough traffic data to be analyzed by
Alexa. Between these two classes, we used two high classes, one
class was from 500 to 5K, and the other was from the 5K to 100K
top rank. We called them class 5K and class 100K, respectively. We
clustered the rest of the websites into three lower rank classes.
A glance at Figure 2 shows that the majority of the websites
indicated in FN error reports have high ranks. Over 53% of the
websites are ranked within the top 100K. A similar scenario happens
in FP cases when there are more than 57.8% of the websites ranked
in the top 100K. As a reference, if we used the Umbrella list, 30% of
FN error reports and 44% of FP error reports of the websites would
be ranked within the top 100K. However, this result does not mean
that the FN errors do not exist in less popular websites. Indeed, we
observed that class-NR websites (websites with no rank) also have
many FN and FP errors.
Analyzing the Crowdsourcing Process of Ad-blocking Systems
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Figure 2: The number of websites that were
indicated in FN and FP error reports.
Figure 3: Distribution of delay of reporting
FP errors classified by the website groups.
Figure 4: The frequency of four different
actions that caused FP errors in websites.
Likelihood Ratio
X-squared (Pearson)
P-value of X-squared
Pearson correlation
Anonymous New Member
147.03
121.6966
7.17E-24
-0.05275
35.49
33.30396
9.16E-06
-0.158028
Senior Member Developer Other Lists Editor Veteran
27.911
40.562
26.67788
43.27946
1.03E-07
0.000166
0.1041299 —
0.09673657
9.2607
10.02684
0.1235264
—
14.357
13.92682
0.030464
0.061129
Editor
11.097
12.03555
0.0611805
Table 4: Statistical results of Pearson’s Chi-squared test and likelihood-ratio chi-squared test of independence and Pearson’s correlation
coefficient test of the linear trend between type of error variable and website class variable among different type of reporters.
User Categories. We also investigated the association between
the error types and the website classes for each user category. We
performed two tests. First, we tested the independence between the
two variables. We used Pearson’s chi-squared test and likelihood-
ratio chi-squared test. Second, if the statistical tests show that there
was a dependency, we measured the linear trend or correlation
using Pearson’s correlation coefficient. The error type variable was
categorical (discrete), and the website class was ordinal. We labeled
website classes scores from 1 to 7, and we gave an FP error score of
1 and an FN error score of 2 to perform Pearson’s correlation test.
Table 4 illustrates statistical results of our tests. Our null hypoth-
esis says that the types of error and website ranks are indepen-
dent. We see that there is no evidence against the null hypothesis
for Editor and Other List Editor users. The Developer
class also provided weak evidence if we consider 0.01 as a signifi-
cance level instead of 0.05.
On the other hand, statistical evidence shows that among Anonymous,
New Member, Senior Member, and Veteran classes, the er-
ror type and website classes are not independent. The interesting
point is that Pearson’s correlation showed negative correlation in
Anonymous and New Member cases. This indicates that these
two types of users helped correct more FP errors than FN errors
for lower-rank websites. Expert users such as Senior Members
and Veterans showed the opposite.
4.3 Influence Time of FP Errors
Since this is the first work conducting a long-scale study on FP and
FN errors of ad-blocking systems, we aim to dispatch a message to
the industrial and research societies about how far these errors in
systems that are used by hundreds of millions of users go. In this
section, we try to answer the question of how long the websites
have suffered from FP errors. We do not have the data to measure
the delay of detecting FN errors and will focus on FP only.
236
In Section 3.2, we calculated the interval (i.e., error duration)
between the time when the element is blocked and the errors are
reported. Figure 3 shows the cumulative distribution function (CDF)
of the delay in reporting the errors by the crowd. As we see, 25%
of the websites had low error durations. Looking deeply into the
dataset, almost 15% of all the website classes had relatively small er-
ror durations of less than one day, and less than 25% of the websites
had error durations of less than four days. However, more than 50%
of the websites had error durations of more than one month. All the
website classes had the same trend over time. The same trend was
observed when we generated the result using the Umbrella rank
(omitted for brevity). The 100K class had the highest percentage in
the first 600 days whereas the NR class had the lowest percentage
after that interval. Finally, the NR group had the most extended
error duration.
4.4 Causes of FP Errors
Who is responsible for blocking legitimate contents of web pages
that are not ads? Is there an association between element types
and FP errors? What (hidden) factors are there that may cause FP
errors? The answers to these questions are the foundation of future
work that aims to improve the accuracy of ad-blocking systems or
prevent potential threats.
There are two possible reasons for FP errors. First, the errors
occur because EasyList adds bad filters (unintentionally) that cause
the blocking of non-ad content. Second, some website designers
may create non-ad elements that are already in the scope of Ea-
syList filters. Either way, ad-blocking software performs one of
two actions: blocking the HTTP GET request or hiding the page
element.
According to these observations, we break down the responsibil-
ities of FP errors in Table 5 using the dataset D2FP. Depending on
who introduced the elements first, the other party is the responsible
party. For example, if the website designers first used an element
Number Of Websites020040060080010001200False NegativeFalse Positive5000.5K−5K5K−100K100K −1M1M − 10M10M − 20MNo RankAlexa Rank0.000.250.500.751.00030060090012001500Delay in daysCDF Rank0.5K5K100K1M10M & 20MNR010305070Number of errorError ReasonEasyHideEDesHideEDesBlockREasyBlockR5000.5K−5K5K−100K100K −1M1M − 10M10M − 20MNo RankAlexa RankIMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Alrizah et al.
EasyList Action
Element Type
Hide Element
Block Request
Style Element
Embedded Content
Form
Interactive Element
Link Element
Section
% of Total
Document Metadata
Embedded Content
Links
Scripting
% of Total
% of Total FP Error
2
1
5
1
1
1
5K
20M
Designer’s Failure
100K
NR
3
1
2
1
Total
0.9%
0.5%
0.5%
0.4%
0.2%
1
6
4.2%
1.58% 1.93% 1.40% 1.75% 6.7%
1.4%
1
5.3%
10
9
11.1%
18
9.1%
6.67% 5.79% 7.02% 7.37% 26.8%
33.5%
4
12
18
6
1
4
32
5
2
4
4
23
4
9
5K
NR
10
13
7
23
25
20M
4
3
1
1
2
17
Ad-blocker’s Failure
100K
2
8