maintained table, e.g., the extended page table (EPT) [38]
in Intel processors, or the nested page table (NPT) [56] in
AMD processors. Using Intel’s EPT as an example, multiple
virtual CPUs (VCPU) within a guest VM will share the same
EPT. For instance, when the two VCPUs of a guest VM run
2These ﬂags are provided for use by memory-management software to
manage the transfer of pages into and out of physical memory. CPU is
responsible for setting these bits via the physical address directly.
Figure 2: An example of the thread-private memory mechanism.
P0 and P1 is thread-private memory page of Thread0 and Thread1,
respectively.
two threads of the same program, both the virtual CR3 reg-
isters point to the page table of the program, and both EPT
pointers (EPTPs) of VCPUs are pointing to a shared EPT.
To implement a thread-private memory, we can instead
make each EPTP to point to a separate EPT to maintain its
own thread-private memory. In such a scheme, each thread
will have its own private EPT. The physical pages mapped
in a thread’s private memory in other threads’ private EPTs
will be made inaccessible. Figure 2 depicts an example of
our thread-private memory scheme. When Thread1 tries to
access its thread-private memory page P1, the hardware will
walk both GPT and EPT1 to get the P3 successfully. But
when Thread0 tries to access P1, it will trigger an EPT vi-
olation exception when the hardware walking EPT0 and be
captured by the hypervisor.
In such a scheme, when a thread is scheduled on a VCPU,
the hypervisor will set EPTP to point to its own EPT. In ad-
dition, SafeHidden synchronizes the EPTs by tracking the
updates of the entries for the thread-local safe areas. For
example, when mapping a guest physical page, SafeHidden
needs to add the protection of all threads’ EPTs for this page.
The thread-private memory defeats Vector-3 completely.
When thread-local safe areas are stored in such thread-
private memory, spraying thread-local safe areas is no
longer useful for the attackers because it will spray many
prohibited areas that are similar to trap areas, called shielded
areas (e.g., P1 is Thread0’s shielded area in Figure 2), and
be captured more easily.
4.3 Thwarting Cache Side-Channel Attacks
As discussed in Section 2.2.2, a key step in the cache side-
channel attack by Gras et al. [22] is to force a PT walk when
an access to the safe area is triggered. Therefore, a necessary
condition for such an attack is to allow the attacker to induce
TLB misses in a safe area. SafeHidden mitigates such at-
tacks by intercepting TLB misses when accessing safe areas.
To only intercept the TLB miss occurred in safe areas,
1244    28th USENIX Security Symposium
USENIX Association
The view of Thread0’s Memory SpaceGuest Page TableGuestHypervisorP1Machine MemoryP1P2EPT0P3EPT1EPTPCR3Core 0EPTPCR3Core 1GuestPhysicalMemoryP0P0The view of Thread1’s Memory Space
Pc ith =
SafeHidden leverages a reserved bit in a PTE on X86 64 pro-
cessors. When the reserved bit is set, a page fault exception
with a speciﬁc error code will be triggered when the PTE
is missing in TLB. Using this mechanism, a TLB miss can
be intercepted and handled by the page fault handler. Safe-
Hidden sets the reserved bit in all of the PTEs for the safe
areas. Thus, when a TLB miss occurs, it is trapped into the
page fault handler and triggers the following actions: (1) It
performs one round of randomization for the safe area; (2) It
clears the reserved bit in the PTE of the faulting page; (3) It
loads the PTE (after re-randomization) of the faulting page
into the TLB; (4) It then sets the reserved bit of the PTE
again. It is worth noting that loading the TLB entry of the
faulting page is a key step. Without this step, the program’s
subsequent accesses to the safe area will cause TLB misses
again, which will trigger another randomization.
The re-randomization upon TLB miss effectively defeats
cache-based side-channel analysis. As mentioned in Section
2.2.2, a successful side-channel attack requires hundreds of
Prime+Probe or Evict+Time tests. However, as each test
triggers a TLB miss, the safe area is re-randomized after ev-
ery test. The PTEs used to translate the safe areas in each PT
levels are re-randomized. Thus, the cache entries mapped by
these PTEs are also re-randomized that completely defeating
cache-based side-channels [22].
Nevertheless, two issues may arise: First, the PTEs of a
safe area could be updated by OS (e.g., during a page mi-
gration or a reclamation), and thus clearing the reserved bits.
To avoid these unintended changes to the safe areas’ PTEs,
SafeHidden traps all updates to the corresponding PTEs to
maintain the correct values of the reserved bits. Second, as
the location of a safe area is changed after a randomization, it
will cause many TLB misses when the safe area is accessed
at the new location, which may trigger many false alarms
and re-randomizations. To address this problem, SafeHid-
den reloads the safe area’s PTEs that were already loaded in
the TLB back to the TLB after re-randomization. This, how-
ever, requires SafeHidden to know which PTEs were loaded
in the TLB before the re-randomization. To do so, Safe-
Hidden exploits an additional feature in Intel transactional
synchronization extensions (TSX), which is Intel’s imple-
mentation of hardware transactional memory [2]. During a
re-randomization, SafeHidden touches each page in the safe
area from inside of a TSX transaction.
If there is a TLB
miss, a page fault exception will occur because the reserved
bit of its PTE is set. But this exception will be suppressed by
a TSX transaction and handled by its abort handler. There-
fore, SafeHidden can quickly ﬁnd out all loaded PTEs before
the re-randomization and reload them for the new location in
the TLB without triggering any page fault exception.
Integrating SafeHidden with kernel page table isolation
(KPTI) [1] introduces additional challenges. KPTI is a de-
fault feature used in the most recent Linux kernels. It sep-
arates the kernel page tables from user-space page tables,
which renders the pre-loaded TLB entries of the safe areas
in kernel unusable by the user-space application. We will
detail our solution in section 5.
4.4 Security Analysis
SafeHidden by design completely blocks attacks through
Vector-1, Vector-3, and Vector-4. However, it only prob-
abilistically prevents attacks through Vector-2. As such, in
this section, we outline an analysis of SafeHidden’s security
guarantee. Speciﬁcally, we consider a defense system with
only one safe area hidden in the unmapped memory space.
We abstract the attackers’ behavior as a sequence of memory
probes, each of which triggers one re-randomization of the
safe area and creates a new trap area.
i−1
∏
j=1
(i· Pt )·
(M · Pt )· (
i f i ≤ M
(1− Ph − j· Pt )
M
(1− Ph − j· Pt ))· (1− Ph − M · Pt )i−1−M
∏
j=1
i f i > M
(1)
The probability of detecting probes. Let the probability
of detecting the attacks within N probes be Pc n. Then the
cumulative probability Pc n = ∑n
i=1 Pc ith, where Pc ith repre-
sents the probability that an attacker escapes all i−1 probes,
but is captured in the ith probe when it hits a trap area. An
escape means that the attacker’s probe is unsuccessful but re-
mains undetected. Pc ith is calculated in Equation (1), where
i denotes the number of probes, j denotes the number of ex-
isting trap areas, Ph denotes the probability that the attacker
hits the safe area in a probe, Pt represents the probability that
the attacker hits one of the trap areas in a probe, M denotes
the maximum number of trap areas. As an escape results in
one re-randomization and the creation of a trap area, we ap-
proximate the number of existing trap areas with the number
of escapes. But the number only increases up to M. So we
consider if i reaches M separately. In the equation, (i · Pt )
or (M · Pt ) represents the probability that the probes are de-
tected in the ith probe and (1−Ph− j·Pt ) or (1−Ph−M·Pt )
represents the probability of escaping the ith probe.
The attacker’s success probability. We denote the prob-
ability of the attacker’s successfully locating the safe area
within N probes as Ps n. Ps n = ∑n
i=1 Ps ith, where Ps ith rep-
resents the probability that the attacker escapes in the ﬁrst
i− 1 probes, but succeed in the ith probe. Ps ith is provided
in Equation (2).
Ps ith =
i−1
∏
(1− Ph − j· Pt )
j=1
M
(1− Ph − j· Pt ))· (1− Ph − M · Pt )i−1−M
∏
j=1
Ph ·
Ph · (
i f i ≤ M
i f i > M
(2)
USENIX Association
28th USENIX Security Symposium    1245
Figure 3: The probability of being captured by SafeHidden within
N probes (a) and the probability of locating the safe areas within N
probes successfully (b).
Discussion. When the size of the safe area is set to 8 MB,
and the maximum size of all trap areas is set to 1 TB, as
shown in Figure 3(a), Pc n increases as the number of probes
grows. When the number of probes reaches 15K, SafeHid-
den detects the attack with a probability of 99.9%; Pc n ap-
proaches 100% as the number of probes reaches 20K. Fig-
ure 3(b) suggests the value of Ps n increases as the number
of probes increases, too. But even if the attacker can es-
cape in 15K probes (which is very unlikely given Figure
3(a)), the probability of successfully locating the safe area
is still only 0.03% (shown in Figure 3(b)), which is the max-
imum that could ever be achieved by the attacker. Notice
that our abstract model favors the attackers, for example: (1)
no shielded areas are considered in the analysis; (2) ran-
domization triggered by applications’ normal activities and
TLB misses is ignored in the analysis. Obviously, in the
real world situation, the attacker’s success probability will
be even lower, and the attack will be caught much sooner.
5 System Implementation
SafeHidden is designed as a loadable kernel module. Users
could deploy SafeHidden by simply loading the kernel mod-
ule, and specifying, by passing parameters to the module,
which application needs to be protected and which registers
point to the safe area. No modiﬁcation of the existing de-
fenses or re-compiling the OS kernel is needed.
5.1 Architecture Overview of SafeHidden
As described in Section 4.2, SafeHidden needs the hardware
virtualization support. It can be implemented within a Vir-
tual Machine Monitor (VMM), such as Xen or KVM. How-
ever, the need for virtualization does not preclude its appli-
cation in non-virtualized systems. To demonstrate this, we
integrated a thin hypervisor into the kernel module for a non-
virtualized OS. The thin hypervisor virtualizes the running
OS as the guest without rebooting the system. The other
components inside the kernel module are collectively called
GuestKM, which runs in the guest kernel.
Figure 4: Architecture overview of SafeHidden.
After loading the SafeHidden module, it ﬁrst starts the
hypervisor and then triggers the initialization of GuestKM
to install hooks during the Initialization Phase. Figure 4
shows an overview of SafeHidden’s architecture. We can see
that SafeHidden is composed of two parts: the hypervisor
and the GuestKM. In the initialization phase, GuestKM in-
stalls hooks to intercept three kinds of guest events: context
switching, page fault exceptions, and certain system calls.
SafeHidden then starts to protect the safe areas by random-
izing their locations and isolating the thread-local safe ar-
eas during the Runtime Monitoring Phase. In the GuestKM,
the Syscall Interceptor and the #PF Interceptor modules
are used to intercept system calls and page fault exceptions.
When these two types of events are intercepted, they will re-
quest the Checker module to determine if SafeHidden needs
to raise a security alarm, or if it needs to notify the Random-
izer module to perform randomization. Meanwhile, Safe-
Hidden needs to maintain the thread-private EPT to isolate
the thread-local safe areas. The sync EPT module is used
to synchronize the protected threads’ page tables with their
EPTs. The switch EPT module will switch EPTs when a
protected thread is scheduled. Because both modules need
to operate EPTs, they are coordinated by the Hypercall Han-
dlers module. The EPT Violation Handler module is used to
monitor illegal accesses to the thread-local safe areas.
5.2
Initialization Phase
Task-1: starting hypervisor. When the kernel module is
launched, the hypervisor starts immediately.
It conﬁgures
the EPT paging structures, enables virtualization mode, and
places the execution of the non-virtualized OS into the vir-
tualized guest mode (non-root VMX mode). At this time, it
only needs to create a default EPT for guest. Because the
guest is a mirror of the current running system, the default
EPT stores a one-to-one mapping that maps each guest phys-
ical address to the same host physical address.
1246    28th USENIX Security Symposium
USENIX Association
05000100001500020000Timeofprobings0.00.20.40.60.81.0pcn0.110.380.660.850.950.99(a)Thecurveofpcn05000100001500020000Timeofprobings0.00.51.01.52.02.53.03.5psn×10−40.00010.00020.00030.00030.0003(b)ThecurveofpsnHardwareHypervisorOS KernelProtected APP’s thread0Other ApplicationsProtected APP’s thread1ProcessSchedRandomizerSyscallInterceptor#0#511. . .. . .Page Tables#0#511. . .. . .Extended page tablesEPTViolationHandlerHypercallHandlersCheckerKernel Module#PF InterceptorvmcallLinuxNotifierSafeHiddenFunctionModuleSwitch EPTSync EPTInterceptEventsInjectInterruptTask-2: installing hooks in guest kernel. When the guest
starts to run, GuestKM will be triggered to install hooks
to intercept three kinds of events: 1) To intercept the sys-
tem calls, GuestKM modiﬁes the system call table’s
entries and installs an alternative handler for each of
them; 2) To intercept the page fault exception, GuestKM
uses the ftrace framework in Linux kernel to hook the
do page fault function; 3) To intercept context switches,
GuestKM uses the standard preemption notiﬁer in Linux,
preempt notifier register, to install hooks. It can be
notiﬁed through two callbacks, the sched in() and the
sched out(), when a context switch occurs.
5.3 Runtime Monitoring Phase
Recognizing safe areas. GuestKM intercepts the execve()
system call to monitor the startup of the protected process.
Based on the user-speciﬁed dedicated register, GuestKM can
monitor the event of setting this register to obtain the value.
In Linux kernel, the memory layout of a process is stored in a
list structure, called vm area struct. GuestKM can obtain
the safe area by searching the link using this value. Accord-
ing to Table 1, there are two kinds of registers that store the
pointer of a safe area: 1) The 64-bit Linux kernel only al-
lows a user process to set the %gs or %fs segmentation regis-
ters through the arch prctl() system call 3. So, GuestKM
intercepts this system call to obtain the values of these reg-
isters; 2) All existing methods listed in Table 1 use %rsp
pointed safe area to protect the stack. So, GuestKM analyzes
the execution result of the execve() and the clone() sys-
tem calls to obtain the location of the safe area, i.e., the stack,
of the created thread or process. Once a safe area is recog-
nized, its PTEs will be set invalid by setting the reserved bits.
To determine whether a safe area is thread-local or not,
GuestKM monitors the event of setting the dedicated register
in child threads. If the register is set to point to a different
memory area, it means that the child thread has created its
thread-local safe area, and the original safe area belongs to
the parent. Until the child thread modiﬁes the register to
point to a different memory area, it shares the same safe area
with its parent.
Randomizing safe areas. As described in Section 4.1 and
4.3, when GuestKM needs to perform randomization, it in-
vokes the customized implementation of do mremap() func-
tion in the kernel with a randomly generated address (by
masking the output of the rdrand instruction with The
0x7ffffffff000) to change the locations of the safe ar-
If the generated address has been taken, the process
eas.
is repeated until a usable address is obtained.
It is worth
noting that GuestKM only changes the virtual address of