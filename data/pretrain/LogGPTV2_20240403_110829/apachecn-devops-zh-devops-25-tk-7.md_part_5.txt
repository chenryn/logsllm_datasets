 1  az aks disable-addons \
 2    -a monitoring \
 3    -n devops25-cluster \
 4    -g devops25-group
```
# 通过 Elasticsearch、Fluentd 和 Kibana 探索集中式日志记录
Elasticsearch 可能是最常用的内存数据库。至少，如果我们将范围缩小到自托管数据库。它是为许多其他场景设计的，它可以用来存储(几乎)任何类型的数据。因此，它几乎非常适合存储可能有多种不同格式的日志。鉴于其灵活性，一些人也将其用于衡量指标，因此，弹性搜索与普罗米修斯竞争。我们暂时将指标放在一边，只关注日志。
**EFK** ( **弹性搜索**、**fluent**、 **Kibana** )栈由三个组件组成。数据存储在 Elasticsearch 中，日志由 Fluentd 收集、转换并推送到 DB，Kibana 用作 UI，通过它我们可以探索存储在 Elasticsearch 中的数据。如果你习惯了 ELK(Logsstash 而不是 Fluentd)，接下来的设置应该很熟悉。
我们将安装的第一个组件是 Elasticsearch。没有它，Fluentd 就没有目的地来运送日志，Kibana 也就没有数据来源。
正如你可能已经猜到的，我们将继续使用 Helm，幸运的是，*elastic search Chart*([https://github . com/Helm/charts/tree/master/stable/elastic search](https://github.com/helm/charts/tree/master/stable/elasticsearch))已经在稳定频道提供。我相信你知道如何找到图表，并探索你可以使用的所有价值。所以，我们直接跳到我准备的价值观。它们是最小的，只包含`resources`。
```
 1  cat logging/es-values.yml
```
输出如下。
```
client:
  resources:
    limits:
      cpu: 1
      memory: 1500Mi
    requests:
      cpu: 25m
      memory: 750Mi
master:
  resources:
    limits:
      cpu: 1
      memory: 1500Mi
    requests:
      cpu: 25m
      memory: 750Mi
data:
  resources:
    limits:
      cpu: 1
      memory: 3Gi
    requests:
      cpu: 100m
      memory: 1500Mi
```
如您所见，有三个部分(`client`、`master`和`data`)与将要安装的弹性搜索组件相对应。我们所做的就是设置资源请求和限制，剩下的就交给图表的默认值了。
在我们继续之前，请注意，您不应该在生产中使用这些值。现在，您应该知道它们因情况而异，您应该根据您可以从`kubectl top`、普罗米修斯和其他工具中检索的实际使用情况来调整资源。
让我们安装弹性搜索。
```
 1  helm upgrade -i elasticsearch \
 2      stable/elasticsearch \
 3      --version 1.14.1 \
 4      --namespace logging \
 5      --values logging/es-values.yml
 6 
 7  kubectl -n logging \
 8    rollout status \
 9    deployment elasticsearch-client
```
可能需要一段时间才能创建所有资源。除此之外，如果您使用 GKE，可能需要创建新节点来容纳请求的资源。耐心点。
现在弹性搜索已经推出，我们可以将注意力转向 EFK 栈中的第二个组件。我们将安装 Fluentd。就像 Elasticsearch 一样，Fluentd 也可以在 Helm 的稳定频道中使用。
```
 1  helm upgrade -i fluentd \
 2      stable/fluentd-elasticsearch \
 3      --version 1.4.0 \
 4      --namespace logging \
 5      --values logging/fluentd-values.yml
 6
 7  kubectl -n logging \
 8      rollout status \
 9     ds fluentd-fluentd-elasticsearch
```
关于 Fluentd 没什么好说的。它以 DaemonSet 的形式运行，正如图表名称所示，它已经被预配置为与 Elasticsearch 一起工作。我甚至没有给你看值文件`logging/fluentd-values.yml`的内容，因为它只包含资源。
为了安全起见，我们将检查 Fluentd 的日志，以确认它已成功连接到 Elasticsearch。
```
 1  kubectl -n logging logs \
 2      -l app=fluentd-fluentd-elasticsearch
```
输出仅限于消息，如下所示。
```
... Connection opened to Elasticsearch cluster => {:host=>"elasticsearch-client", :port=>9200, :scheme=>"http"}
... Detected ES 6.x: ES 7.x will only accept `_doc` in type_name.
```
A note to Docker for Desktop users
You will likely see much more than the few log entries presented above. There will be a lot of warnings due to the differences in Docker for Desktop API when compared to other Kubernetes flavors. Feel free to ignore those warnings since they do not affect the examples we are about to explore and you are not going to use Docker for Desktop in production but only for practice and local development.
简单而美丽。唯一剩下的就是安装来自 EFK 的 K。
让我们看看我们将用于基巴纳图表的值文件。
```
 1  cat logging/kibana-values.yml
```
输出如下。
```
ingress:
  enabled: true
  hosts:
  - acme.com
env:
  ELASTICSEARCH_URL: http://elasticsearch-client:9200
resources:
  limits:
    cpu: 50m
    memory: 300Mi
  requests:
    cpu: 5m
    memory: 150Mi
```
同样，这是一组相对简单的值。这一次，我们不仅指定了资源，还指定了入口主机，以及环境变量`ELASTICSEARCH_URL`，它将告诉基巴纳在哪里可以找到弹性搜索。你可能已经猜到了，我事先不知道你的主机是什么，所以我们需要在运行时覆盖`hosts`。但是，在我们这样做之前，我们需要定义它。
```
 1  KIBANA_ADDR=kibana.$LB_IP.nip.io
```
我们继续安装 EFK 栈中的最后一个组件。
```
 1  helm upgrade -i kibana \
 2      stable/kibana \
 3      --version 0.20.0 \
 4      --namespace logging \
 5      --set ingress.hosts="{$KIBANA_ADDR}" \
 6     --values logging/kibana-values.yml
 7
 8  kubectl -n logging \
 9      rollout status \
10      deployment kibana
```
现在，我们终于可以打开基巴纳，确认所有三个 EFK 组件确实一起工作，并且它们正在实现我们的集中伐木目标。
```
 1  open "http://$KIBANA_ADDR"