# Web Timeouts and Their Implications

**Authors:**
- Zakaria Al-Qudah, Case Western Reserve University, Cleveland, Ohio 44106
- Michael Rabinovich, Case Western Reserve University, Cleveland, Ohio 44106
- Mark Allman, International Computer Science Institute, Berkeley, CA 94704

## Abstract
Timeouts play a crucial role in network protocols, governing various aspects of host behavior across different layers of the protocol stack. Previous research has documented a class of Denial of Service (DoS) attacks that exploit timeouts to force hosts to maintain state with minimal interaction from the attacker. This paper examines the vulnerability of operational web servers to such attacks by comparing the timeouts implemented in these servers with typical web activity patterns. Our findings indicate that the timeouts commonly used are significantly longer than necessary for normal web transactions. We propose a framework to enhance static timeouts by incorporating system measurements and specific policy decisions during high load conditions.

## 1. Introduction
A fundamental principle in networking, which has served the Internet well over the past three decades, is that system components should be both conservative and liberal. This means actions should only be taken when strictly necessary (conservative), while also being tolerant of a wide range of behaviors from other components (liberal). The passage of time is the only constant we can rely on, leading to the use of timeouts as a fallback mechanism to ensure robust operation.

However, this approach becomes problematic in the presence of malicious actors, who can exploit long timeouts to launch "claim-and-hold" DoS attacks. In such attacks, an attacker claims server resources without using them, thereby preventing the server from allocating these resources to legitimate users.

In this paper, we investigate the issue of timeouts in the context of the modern web. We conduct an empirical study to understand how timeouts are currently set on web servers and how these settings relate to normal user-driven web traffic. Our key finding is that timeout settings are overly conservative relative to actual traffic patterns, making web servers vulnerable to easy DoS attacks. While this suggests that servers could adopt more aggressive timeout policies, doing so would contradict the general principle of being conservative and liberal. Instead, we propose an adaptive approach where timeouts are reduced only during times of measured stress. We have observed a few web sites that already dynamically adjust their timeouts, and we believe that other sites, regardless of size, would benefit from similar adaptive strategies. Unfortunately, such adaptive timeout mechanisms are not natively available in popular web servers. As part of this project, we have implemented and made available a simplified adaptive mechanism as a modification to the Linux kernel and Apache web server.

## 2. Related Work
Previous studies have categorized DoS attacks into busy attacks and claim-and-hold attacks [13]. Web server administrators have reported encountering claim-and-hold attacks [7, 6], and server software vendors often recommend tuning web server timeouts [4, 8]. However, many web sites still use default timeout values. Barford et al. [5] observed the negative effects of excessive persistent connections on busy web servers and recommended an early close policy. Rabinovich et al. [14] suggested adaptive management of persistent connections, where a server closes idle connections once it runs out of connection slots. We argue for a similar but more general approach. Park et al. [12] proposed an independent component to filter and condition external connections for the web server. In contrast, we suggest an adaptive timeout strategy directly on the web server.

## 3. Timeout Measurements
In this section, we evaluate the timeout periods in operational web servers and compare them with the time required for web clients to perform corresponding activities. We probe two groups of web servers: (i) Alexa's top 500 sites, denoted as "high volume" sites, and (ii) 15,445 sites collected using the Link Harvester tool, denoted as "regular" sites. The list of these sites is available at [1].

### 3.1 TCP Timeout
The TCP timeout represents the duration a TCP implementation will attempt to retransmit data before giving up on an unresponsive host. We assess this by opening a TCP connection to a given server, sending an HTTP request, and then disappearingâ€”i.e., sending no further data, ACK, FIN, or RST packets. Some sites respond with an HTTP redirection and a FIN, which we exclude from further analysis. This reduces the number of sites to 437 high volume and 13,142 regular sites.

We monitor the server's retransmissions and find three distinct ways for connections to end: (i) implicitly with retransmissions eventually ceasing, (ii) explicitly with the server sending a FIN, or (iii) explicitly with the server sending a RST. We measure the TCP timeout as the interval between the first data transmission and the last retransmission or a packet with a FIN or RST bit set. Figure 1(a) shows the distribution of timeouts for each termination method for the high volume sites. For 61% of the servers, the observed timeout exceeds 100 seconds. These measurements represent a lower bound because there is no wire event indicating the server has dropped the connection. For 9% of the servers, the FIN transmission is likely triggered by the application, not TCP, representing another lower bound. For 30% of the servers, those sending a RST show the longest timeouts, likely the best representation of the TCP timeout.

### 3.2 Application Timeout
The application timeout is the time a server allows between completing the TCP connection establishment and receiving the first byte of an HTTP request. To measure this, we open a TCP connection to a server without sending an HTTP request using `nc` [11]. We then measure the time from the completion of the TCP connection establishment until the connection is closed by the server (giving up after 20 minutes). We use 492 high volume sites and 14,985 regular sites in this experiment. We find that 36% of sites in both groups do not end the connection after 20 minutes, potentially due to the use of the TCP DEFER ACCEPT option or having an application timeout longer than 20 minutes.

Figure 1(b) shows the distribution of measured application timeouts for the remaining 64% of sites. Significant modes are observed around 120s and 300s, the well-known defaults for IIS and Apache, respectively. High volume sites generally have shorter application timeouts, presumably for better resource management without disrupting users. A mode around 240s is mostly due to Google's sites, and a mode around 30s is due to Akamai-accelerated sites. Overall, 54% of high-volume sites and 74% of regular sites have application timeouts of over 100s.

### 3.3 Request Timeout
The request timeout is the time a web server allots for a request to completely arrive after the first byte of the request has arrived. To measure this, we drip a 1000-byte request over the network at a rate of one byte per second and note when (or if) the server terminates the connection. This experiment involves 492 high-volume and 15,033 regular sites.

Figure 1(c) shows the distribution of measured request timeouts. 58% of regular sites and 51% of high volume sites keep the connection open for the entire 1,000 seconds, suggesting no request timeout. Among the sites that do set a smaller request timeout, high volume sites generally have shorter timeouts. Overall, 93% of high volume sites and 96% of regular sites have a request timeout period of over 30 seconds.

To assess how long web clients normally take to transmit their requests, we measure the time between the first and last packets of HTTP requests in our trace. When the entire request fits in one packet, we report the time as zero.

## Conclusion
Our findings highlight that the timeouts commonly used in web servers are excessively long compared to normal web traffic patterns, making them vulnerable to DoS attacks. We propose an adaptive approach to reduce timeouts during high load conditions, which can help mitigate these vulnerabilities. Future work will involve implementing and testing this adaptive mechanism in real-world scenarios.

---

**References:**
1. [Link to the list of probed sites]
2. [Reference to previous work on TCP timeouts]
3. [Alexa's top 500 sites]
4. [Vendor recommendation on tuning timeouts]
5. [Barford et al. on persistent connections]
6. [Reported claim-and-hold attacks]
7. [Another reference on claim-and-hold attacks]
8. [Vendor recommendation on tuning timeouts]
9. [Keynote clients]
10. [nc tool]
11. [Link Harvester tool]
12. [Park et al. on filtering connections]
13. [Study on DoS attacks]
14. [Rabinovich et al. on adaptive management]
15. [ICSI packet trace]

---

This revised version aims to provide a clearer, more structured, and professional presentation of the original text.