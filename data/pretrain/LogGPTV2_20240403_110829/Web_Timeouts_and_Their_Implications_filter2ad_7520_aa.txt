title:Web Timeouts and Their Implications
author:Zakaria Al-Qudah and
Michael Rabinovich and
Mark Allman
Web Timeouts and Their Implications(cid:2)
Zakaria Al-Qudah1, Michael Rabinovich1, and Mark Allman2
1 Case Western Reserve University, Cleveland, Ohio 44106
2 International Computer Science Institute, Berkeley, CA 94704
Abstract. Timeouts play a fundamental role in network protocols, con-
trolling numerous aspects of host behavior at diﬀerent layers of the pro-
tocol stack. Previous work has documented a class of Denial of Service
(DoS) attacks that leverage timeouts to force a host to preserve state
with a bare minimum level of interactivity with the attacker. This paper
considers the vulnerability of operational Web servers to such attacks
by comparing timeouts implemented in servers with the normal Web
activity that informs our understanding as to the necessary length of
timeouts. We then use these two results—which generally show that the
timeouts in wide use are long relative to normal Web transactions—to
devise a framework to augment static timeouts with both measurements
of the system and particular policy decisions in times of high load.
1 Introduction
One of the historic tenets of networking that has served the Internet well over
the past 30 years is that components of the system should be both conservative
and liberal at the same time. That is, actions should only be taken as they are
strictly necessary—therefore acting conservatively. Furthermore, wide tolerance
for a range of behavior from other components in the system is also desirable—or
acting liberally. Another fundamental notion within the Internet is that the only
thing we can absolutely count on is the passage of time. This notion naturally
led to timeouts as a fundamental fallback mechanism to ensure robust operation.
Adhering to the above stated principles tends to make timeouts long such that we
can tolerate a range of behavior and the timer only expires when a gross anomaly
occurs as opposed to when some task simply happens slower than expected.
Unfortunately, the above narrative becomes muddled in the presence of ma-
licious actors as it creates an opening for the so-called claim-and-hold denial of
service attacks [13], where an attacker can claim server resources without us-
ing them thus preventing the server from utilizing these resources on legitimate
activities.
In this paper, we consider the issue of timeouts in the modern Internet within
the context of the Web. We conduct an empirical investigation that seeks to
understand (i) how timeouts are currently set on Web servers and (ii) how
those settings relate to normal user-driven Web traﬃc. Our key ﬁnding is that
(cid:2) This work is supported in part by NSF grants CNS-0615190 and CNS-0433702.
A. Krishnamurthy and B. Plattner (Eds.): PAM 2010, LNCS 6032, pp. 211–221, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
212
Z. Al-Qudah, M. Rabinovich, and M. Allman
timeout settings are extremely conservative relative to actual traﬃc patterns and
expose Web servers to easy DoS attacks. While this suggests that servers could
take a more aggressive posture with respect to timeouts, doing so would run
counter to the general tenet mentioned earlier (i.e., would result into dropping
legitimate anomalies even at times when enough resources are available to serve
them). Instead, we propose an adaptive approach whereby the timeouts are only
reduced at times of measured stress. In fact, we observed a small number of Web
sites that exhibit a behavior which indicates that they might be already varying
their timeouts dynamically. We believe other sites, large or small, would beneﬁt
from similar reactions in the face of claim-and-hold attacks. Unfortunately, such
timeout adaption is not available out-of-the-box in popular Web servers. As part
of this project we have implemented and make available a simpliﬁed adaptive
mechanism as a modiﬁcation of the Linux kernel and Apache Web server [1].
2 Related Work
[13] studied, veriﬁed, and classiﬁed DoS attacks into busy attacks
Qie, et.al.
and claim-and-hold attacks. Web server administrators have reported encoun-
tering claim-and-hold attacks [7,6] and server software vendors seem cognizant
of these attacks and typically recommend tuning Web server timeouts [4,8]. How-
ever, as we show in this paper, a large number of Web sites use default timeout
values. Barford et. al. observed the negative eﬀect of excessive persistent con-
nections on busy Web servers and recommended an early close policy whereby
Web clients close persistent connections after downloading a page and all its
embedded objects [5]. Rabinovich et. al. suggested adaptive management of per-
sistent connections at Web servers, where a server closes idle connections once
it runs out of the connection slots [14]. We argue for a similar but more general
approach in Section 4. Park, et.al. also point out the danger of inactive or slow
Web clients and propose an independent component to ﬁlter and condition ex-
ternal connections for the Web server [12]. In contrast, we suggest an adaptive
timeout strategy on the Web server itself.
3 Timeout Measurements
In this section, we assess timeout periods in operational Web servers and com-
pare them with the time needed by Web clients to perform the corresponding
activities that these timeout periods control. To this end, we probe two groups
of Web servers: (i) Alexa’s top 500 sites [3] denoted as “high volume” sites and
(ii) 15,445 sites collected using the Link Harvester tool [15] denoted as “regu-
lar” sites. The list of these sites is available from [1]. In the high volume group,
53% of sites reported some version of Apache Web server in the “Server:” re-
sponse header, 12% Microsoft-IIS, 10% GWS (Google), and the rest reported
some other server or nothing at all. Among the regular sites, 68% were Apache,
19% Microsoft-IIS, and the rest other/unknown. As described below, we actively
probe these sites for various timeouts. Inevitably for each experiment a small
1: Implicit
2: FIN
3: RST
F
D
C
F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 1
 0.8
 0.6
 0.4
 0.2
 0
 0.1
 1
 10
 100  1000  10000
timeout (sec)
(a) TCP timeout
 regular sites
top 500 sites
Web Timeouts and Their Implications
213
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
regular sites
top 500 sites
 0  100  200  300  400  500  600  700
timeout (sec)
(b) Application timeout
regular sites
top 500 sites
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 200  400  600  800  1000
timeout (sec)
 0
10-4
10-3
10-2
 1
10-1
101
timeout (sec)
102
103
(c) Request timeout
(d) Keep-Alive timeout
Fig. 1. Distribution of Web server timeouts
number of sites are unavailable and so the precise number of sites used varies
and is reported for each experiment.
To assess the time consumed by Web clients to perform various normal activ-
ities, we analyze a week long packet trace of Web traﬃc collected at the border
of International Computer Science Institute (ICSI) captured between August
11–18 2009. The trace contains nearly 1.6M HTTP connections involving nearly
14K servers and 25K clients. We note that Web clients in our trace are generally
well-connected. While it would be desirable to verify our results directly in a
qualitatively diﬀerent environment, we do not expect dial-up clients to aﬀect
our ﬁndings (as discussed later).
TCP Timeout: The TCP timeout represents the length of time a TCP imple-
mentation will attempt to retransmit data before giving up on an unresponsive
host. We assess this timeout by opening a TCP connection to a given server,
sending an HTTP request and disappearing—i.e., sending no further data, ACK,
FIN or RST packets. Some sites respond with an HTTP redirection and a FIN
(either with the data or closely thereafter). We exclude these sites from fur-
ther analysis because the timeout we experience in this case is the FIN WAIT
state timeout, not the retransmission timeout. This reduces the number of sites—
437 high volume and 13,142 regular sites—involved in this experiment compared
to other experiments.
214
Z. Al-Qudah, M. Rabinovich, and M. Allman
We monitor the server’s retransmissions and ﬁnd three distinct ways for con-
nections to end: (i) implicitly with the retransmissions eventually ceasing, (ii)
explicitly with the server sending a FIN or (iii) explicitly with a server sending a
RST. We measure the TCP timeout as the interval between the arrival of the ﬁrst
data transmission and the arrival of either the last retransmission or a packet
with a FIN or RST bit set (note, this FIN case is distinct from the redirection
case discussed above). Figure 1(a) shows the distribution of timeouts measured
for each termination method for the high volume sites (the regular sites are
omitted due to space constraints but show the same general behavior). In case
(i)—encompassing 61% of the servers in both sets—the observed timeout is over
100 seconds for two-thirds of the servers. Note that in this case there is no wire
event indicating the server has dropped a connection, and we expect that the
server waits for some time for an ACK after the last retransmission. Therefore,
the measurements represent a lower bound. In case (ii)—encompassing 9% of
the servers in each set—we believe the FIN transmission is generally triggered by
the overall application giving up on the connection rather than TCP terminat-
ing the connection itself. Therefore, at best these measurements also represent a
lower bound on the length of the TCP timeout, which is illustrated by the order
of magnitude diﬀerence between cases (i) and (ii) in Figure 1(a). In case (iii)—
encompassing 30% of the servers in each set—we observe that servers that send
a RST show the longest timeouts by a small margin over servers that silently
terminate. We believe this is likely the best representation of the TCP timeout as
it encompasses both the entire retransmission process and the additional waiting
time that goes unseen in case (i).
We contrast the above determined lower bounds with data from our previous
work [2]. In that work, we set up two servers: one conﬁgured with a normal
TCP timeout (default Linux timeout of 15 retransmissions, or ≈13–30 minutes)
and one with a quick TCP timeout (3 retransmissions or roughly 600 msec). We
then used 59 Keynote [9] clients around the world to download a 2 MB ﬁle from
each server every 15 minutes for over a week. Reduced retransmissions increased
dropped connections due to timeouts by 0.16%, suggesting that continuing to
retransmit for long periods of time is often futile.
In summary, while Figure 1(a) shows that—excluding cases where we do not
believe TCP terminated the connection—80% of the surveyed servers have TCP
timeouts exceeding 57 seconds, and nearly two-thirds of the servers have TCP
timeouts exceeding 100 seconds, our preliminary data indicates that most Web
interactions would succeed with a sub-second TCP timeout.
Application Timeout: The application timeout is the time a server allows
between completing the TCP connection establishment and the arrival of the
ﬁrst byte of an HTTP request. To measure the application timeout in opera-
tional Web sites, we open a TCP connection to a server without sending an
HTTP request using nc6 [11]. We then measure the time from the completion of
the TCP connection establishment until the connection is closed by the server
(giving up after 20min). We use 492 high volume sites and 14,985 regular sites
in this experiment. We ﬁnd that just under 36% of sites in both groups do
Web Timeouts and Their Implications
215
not end the connection after 20min. Potential reasons for this behavior include
sites using the TCP DEFER ACCEPT Linux TCP option [16] (or like option
on other systems). With this option, TCP does not promote a connection from
the SYN RCVD state to ESTABLISHED state—and thus hand it over to the
application—until data arrives on the connection. Therefore, the notion of ap-
plication timeout is not applicable for these sites. (Note however that these sites
can still accumulate pending connections in the SYN RCVD state, which may
present a diﬀerent attack vector.) Another explanation is these sites have an
application timeout which is longer than 20min.
Figure 1(b) shows the distribution of measured application timeouts for the
remaining ≈64% of sites in the two groups. The ﬁgure shows signiﬁcant modes in
both groups around 120s and 300s—the well-known defaults for IIS and Apache
respectively. We also observe that high volume sites generally have shorter appli-
cation timeouts than regular sites. Presumably these sites have determined that
shorter timeouts are better for resource management without disrupting users.
The ﬁgure also has a mode around 240s for the high volume sites which is mostly
due to Google’s sites (e.g., google.com, google.fr, google.co.uk, gmail.com, etc.).
Similarly, we ﬁnd that the high volume sites responsible for the mode around
30s to be mostly Akamai-accelerated sites. Finally, we ﬁnd a mode around 60s
which we cannot readily explain. Overall, around 54% of high-volume sites and
74% of regular sites have application timeouts of over 100s.
We now turn to our packet trace and measure the time between the last ACK
in TCP’s three-way handshake and the ﬁrst packet with the client’s HTTP
request. We ﬁnd that 99% of the requests were sent within one second of com-
pleting the TCP connection establishment. However, the longest time a client in
our trace took to start sending the request after completing the TCP connection
establishment is 586 seconds.
Request Timeout: The request timeout is the time a Web server allots to a
request to completely arrive at the server after the ﬁrst byte of the request has
arrived. To measure the request timeout we drip a 1000 byte request over the
network at a rate of one byte/sec and note when (or if) the server terminates the
connection. Transmitting the request at a byte/sec factors out a possible eﬀect
of another timeout commonly applied to poll()/select() calls—which is usually
greater than one second. This experiment involves 492 high-volume and 15,033
regular sites.
Figure 1(c) shows the distribution of the measured request timeouts. The plot
indicates that 58% of the regular sites and 51% of the high volume sites keep
the connection open for the entire 1,000 seconds it took our client to send its
request, suggesting that the server does not impose a request timeout. Among
the sites that do set a smaller request timeout, high volume sites have generally
shorter timeouts than regular sites. Overall, 93% of the high volume sites and
96% of the regular sites have a request timeout period of over 30 seconds.
To assess how long Web clients normally take to transmit their requests, we
measure the time between the ﬁrst and last packets of HTTP requests in our
trace. When the entire request ﬁts in one packet, we report the time as zero.
216
Z. Al-Qudah, M. Rabinovich, and M. Allman
Group Impose IIS with IIS without
Limit
limit
Top 500 24.1% 32.7%
Regular 23.5% 59.0%
limit
5.1%
7.2%
F