R2 Eating 71
R2 Enter home 52
R2 Leave home 68
R2 Meal preparation 184
R2 Personal hygiene 534
R2 Sleep 305
R2 Sleeping not in bed 2
R2 Wandering in room 5
R2 Watch TV 117
R2 Work 432
Totals 6477 3743
Table3 and Table4 show the breakdown of the data sets had been processed
byAlgorithm1.Notonlyweretheredifferencesinthenumberofactivityclasses,
buttherewaslargevariabilityinthenumberofinstancesrepresentingeachclass
(ranging from 1 to 2919).
Four different supervised learning methods were used to compare and con-
trast the utility of the four different representations of the sensor data. A Sup-
port Vector Machine (SVM) [8], decision tree (DT) [26], ensemble of decision
trees using bagging (Ensemble) [9], and the recent and popular extreme gradi-
ent boosting (XGBoost) framework [5]. All experiments were conducted using
Python’s scikit-learn and XGBoost packages on a laptop using a dual-core Intel
i5-2540M processor with 8GB memory running Ubuntu 20.04. The use of the
IR-Based Approach for Smart Home Activity Recognition 591
Python hyperopt1 package was used to fine-tune the learning parameters for all
algorithms. With the number of activity classes present in the data sets and
the obvious presence of class imbalance, created many challenges for supervised
machine learning techniques to accurately classify them. For this reason, the
results of five-fold cross validation was used to evaluate the performance of the
supervised learning models. Performance measures used were weighted Preci-
sion, Recall, and F1-Scores as there were more than two classes in each of the
data sets. The results are summarized in Tables5 and 6.
5 Results and Discussion
In terms of the suitability of our proposed framework to processing the smart
home data sets, it did generate quite different representations for training and
testing each of the four classifiers. We also expected that a classifier built using
Table 5. Classifier performance of the four Aruba data set variants.
Classifier Train Test
Precision Recall F1-Score Precision Recall F1-Score
Raw
SVM 0.9340 0.9376 0.9331 0.9255 0.9298 0.9241
DT 0.9850 0.9847 0.9848 0.9201 0.9244 0.9217
Ensemble 0.9822 0.9822 0.9820 0.9128 0.9252 0.9187
XGBoost 0.9787 0.9786 0.9785 0.9406 0.9452 0.9428
TF-IDF
SVM 0.9381 0.9359 0.9307 0.9340 0.9406 0.9368
DT 0.9848 0.9846 0.9846 0.9272 0.9190 0.9226
Ensemble 0.9822 0.9822 0.9817 0.9289 0.9352 0.9315
XGBoost 0.9739 0.9737 0.9737 0.9527 0.9522 0.9487
LogSig(TF-IDF)
SVM 0.9395 0.9386 0.9344 0.9263 0.9313 0.9271
DT 0.9828 0.9826 0.9827 0.9272 0.9236 0.9248
Ensemble 0.9808 0.9807 0.9803 0.9355 0.9355 0.9379
XGBoost 0.9789 0.9788 0.9787 0.9396 0.9506 0.9449
TanSig(TF-IDF)
SVM 0.9330 0.9375 0.9332 0.9249 0.9313 0.9256
DT 0.9816 0.9815 0.9815 0.9203 0.9174 0.9182
Ensemble 0.9826 0.9824 0.9821 0.9235 0.9313 0.9268
XGBoost 0.9818 0.9817 0.9816 0.9355 0.9452 0.9399
1 http://hyperopt.github.io/hyperopt/. Last accessed 30th September, 2020.
592 B. J. Woodford and A. Ghandour
the original SEFMatrix would perform comparatively poorly. To this end,
the results reported for the variants of the Aruba data set in Table5 suggest
that there is no one classifier that achieves the best training performance. All
classifiers exhibited good performance when assessed using the three perfor-
mance measures. The best training performance was split between the DT and
Ensemble classifiers but the testing performance was consistently better when
the XGBoost classifier was adopted. Finally, all classifiers benefited from the
TF-IDF representation of SEFMatrix but the performance of all four classi-
fiers degraded a little when trained and tested using the LogSig(TF-IDF) and
TanSig(TF-IDF) data sets.
Table 6. Classifier performance of the four Kyoto data set variants.
Classifier Train Test
Precision Recall F1-Score Precision Recall F1-Score
Raw
SVM 0.7269 0.7287 0.7110 0.6014 0.6101 0.5925
DT 0.9327 0.9318 0.9320 0.6240 0.6128 0.6131
Ensemble 0.9372 0.9369 0.9364 0.6693 0.6742 0.6634
XGBoost 0.9937 0.9947 0.9942 0.7569 0.7583 0.7490
TF-IDF
SVM 0.7292 0.7274 0.7120 0.6195 0.6395 0.6215
DT 0.9248 0.9245 0.9244 0.6412 0.6355 0.6348
Ensemble 0.9299 0.9292 0.9287 0.6786 0.6849 0.6766
XGBoost 0.9973 0.9977 0.9975 0.7566 0.7664 0.7589
LogSig(TF-IDF)
SVM 0.6980 0.7050 0.6877 0.6534 0.6689 0.6526
DT 0.9168 0.9151 0.9151 0.6361 0.6382 0.6352
Ensemble 0.9149 0.9131 0.9129 0.6759 0.6903 0.6772
XGBoost 0.9710 0.9719 0.9706 0.7085 0.7130 0.7023
TanSig(TF-IDF)
SVM 0.6858 0.6973 0.6798 0.6277 0.6489 0.6310
DT 0.9185 0.9161 0.9163 0.6266 0.6182 0.6191
Ensemble 0.9153 0.9135 0.9132 0.6922 0.7063 0.6935
XGBoost 0.9849 0.9846 0.9839 0.7356 0.7330 0.7277
Table6 suggests that there is more variability of classifier performance when
trained and tested on the four variants of the Kyoto data set. SVM perfor-
mancewaspooracrossalldatasetvariantswhencomparedwiththeotherthree
classifiers. Furthermore, although the DT, Ensemble, and XGBoost classifiers
exhibited good training performance, there was a marked decrease in testing
IR-Based Approach for Smart Home Activity Recognition 593
performance for these three classifiers possibly due to the number of classes
(Kyoto (25) vs. Aruba (11)). In general, however, the XGBoost classifier exhib-
ited consistently better performance when trained and tested on the TF-IDF
representation of the SEFMatrix and potentially be adopted subsequent to
judicious hyper-parameter tuning to improve the testing performance.
6 Conclusion
In this paper we have proposed a new framework for investigating smart home
sensor data with a view to discovering how sensor activation frequency and
duration relates to the various activities carried out by the residents of smart
homes. We employ a new algorithm as described in Algorithm 1 to generate
prototypicalactivitiesrepresentativeofmovementsofresidentsgoingabouttheir
daily lives. Unlike current state-of-the-art methods whose efforts are channelled
into on-line activity recognition, we were motivated by more off-line analyses
which would help to assist in identifying latent information contained in these
sensor activations which improve the recognition of the activity. Moreover, we
comprehensively assessed the overall performance of this representation and its
variants by using four popular supervised classifiers including the more recent
XGBoost classifier. Our overall conclusion is that there are benefits in adopting
the proposed IR-based representation for off-line analysis of smart home sensor
data.
Future work will be in the areas of extending the framework to better han-
dle uncertainties in the smart home environments themselves specifically those
activity recognition techniques which have been identified by [17] applying con-
cepts for an on-line rule-learning Type-2 fuzzy classifier originally proposed by
[3]andalsoinvestigating howmoreknowledge-basedalgorithms canbeadopted
based on the work of [20]. Finally, one other direction would be to consider how
the work of [25] who developed a method to recognize and model activities in
smart homes using both labelled and unlabelled data can be incorporated into
our framework.
References
1. Abidine, M.B., Fergani, L., Fergani, B., Fleury, A.: Improving human activity
recognition in smart homes. Int. J. E-Health Med. Commun. 6(3), 19–37 (2015).
https://doi.org/10.4018/IJEHMC.2015070102
2. Amiribesheli, M., Benmansour, A., Bouchachia, A.: A review of smart homes in
healthcare. J. Amb. Intell. Hum. Comput. 6(4), 495–517 (2015). https://doi.org/
10.1007/s12652-015-0270-2
3. Bouchachia,A.,Vanret,C.:GT2FC:anonlinegrowingintervaltype-2self-learning
fuzzy classifier. IEEE Trans. Fuzzy Syst. 22(4), 999–1018 (2014)
4. Chen,L.,Nugent,C.D.,Wang,H.:Aknowledge-drivenapproachtoactivityrecog-
nition in smart homes. IEEE Trans. Knowl. Data Eng. 24(6), 961–974 (2012)
594 B. J. Woodford and A. Ghandour
5. Chen,T.,Guestrin,C.:XGBoost:ascalabletreeboostingsystem.In:Proceedings
of 22nd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, KDD 2016, pp. 785–794. ACM, New York (2016)
6. Cook, D.J.: Learning setting-generalized activity models for smart spaces. IEEE
Intel. Syst. 27(1), 32–38 (2012)
7. Cook,D.J.,Schmitter-Edgecombe,M.:Assessingthequalityofactivitiesinasmart
environment. Method Inf. Med. 48(5), 480–485 (2009)
8. Cortes, C., Vapnik, V.: Support-vector networks. Mach. Learn. 20(3), 273–297
(1995)
9. Dietterich, T.G.: An experimental comparison of three methods for constructing
ensembles of decision trees: bagging, boosting, and randomization. Mach. Learn.
40(2), 139–157 (2000)
10. Duarte,J.,Gama,J.,Bifet,A.:Adaptivemodelrulesfromhigh-speeddatastreams.
ACM Trans. Knowl. Discov. Data 10(3), 30:1–30:22 (2016)
11. Gama, J., Zˇliobaite˙, I., Bifet, A., Pechenizkiy, M., Bouchachia, A.: A survey on
concept drift adaptation. ACM Comput. Surv. 46(4), 44:1–44:37 (2014)
12. Gu, T., Wu, Z., Tao, X., Pung, H.K., Lu, J.: epSICAR: an emerging patterns
based approach to sequential, interleaved and concurrent activity recognition. In:
Proceedings of 7th IEEE International Conference on Pervasive Computing and
Communications, pp. 1–9. IEEE (2009)
13. Guo, J., Mu, Y., Xiong, M., Liu, Y., Gu, J.: Activity feature solving based on
TF-IDF for activity recognition in smart homes. Complexity 37, 1–10 (2019)
14. Hoque,E.,Dickerson,R.F.,Preum,S.M.,Hanson,M.,Barth,A.,Stankovic,J.A.:
Holmes: a comprehensive anomaly detection system for daily in-home activities.
In: 2015 International Conference on Distributed Computing in Sensor Systems,
pp. 40–51. IEEE Press, June 2015
15. Jurek, A., Nugent, C., Bi, Y., Wu, S.: Clustering-Based Ensemble Learning for
Activity Recognition in Smart Homes. Sensors 14, 12285–12304 (2014)
16. Kim, E., Helal, S., Cook, D.: Human activity recognition and pattern discovery.
IEEE Perv. Comput. 9(1), 48–53 (2010)
17. Kim, E., Helal, S., Nugent, C., Beattie, M.: Analyzing activity recognition uncer-
taintiesinsmarthomeenvironments.ACMTrans.Intell.Syst.Technol.6(4),52:1–
52:28 (2015). https://doi.org/10.1145/2651445
18. Kondylidis, N., Tzelepi, M., Tefas, A.: Exploiting TF-IDF in deep convolutional
neural networks for content based image retrieval. Multimed. Tools Appl. 77(23),
30729–30748 (2018)
19. Krishnan, N.C., Cook, D.J.: Activity recognition on streaming sensor data. Perv.
Mob. Comput. 10(Part B), 138–154 (2014)
20. Lu¨hr, S., Lazarescu, M.: Incremental clustering of dynamic data streams using
connectivity-basedrepresentativepoints.IEEETrans.Knowl.DataEng.68,1–27
(2009)
21. Okeyo, G., Chen, L., Wang, H., Sterritt, R.: Dynamic sensor data segmentation
for real-time knowledge-driven activity recognition. Perv. Mob. Comput. 10(Part
B), 155–172 (2014)
22. Sagha,H.,Bayati,H.,Mill´an,J.D.R.,Chavarriaga,R.:On-lineanomalydetection
andresilienceinclassifierensembles.Patt.Recogn.Lett.34(15),1916–1927(2013)
23. Silva,J.A.,Faria,E.R.,Barros,R.C.,Hruschka,E.R.,Carvalho,A.C.D.,Gama,J.:
Data stream clustering: a survey. ACM Comput. Surv. 46(1), 13:1–13:31 (2013)
24. VanKasteren,T.,Noulas,A.,Englebienne,G.,Kr¨ose,B.:Accurateactivityrecog-
nitioninahomesetting.In:Proceedingsof10thInternationalConferenceonUbiq-
uitous Computing, pp. 1–9. ACM (2008)
IR-Based Approach for Smart Home Activity Recognition 595
25. Wen, J., Zhong, M.: Activity discovering and modelling with labelled and unla-
belled data in smart environments. Expert Syst. Appl. 42(14), 5800–5810 (2015)
26. Wu, X., et al.: Top 10 algorithms in data mining. Knowl. Inf. Syst. 14(1), 1–37
(2007)
27. Zhu,C.,Sheng,W.,Liu,M.:Wearablesensor-basedbehavioralanomalydetection
in smart assisted living systems. IEEE Trans. Autom. Sci. Eng. 12(4), 1225–1234
(2015)
Botnet Sizes: When Maths Meet Myths
B
Elisa Chiapponi1( ), Marc Dacier1, Massimiliano Todisco1, Onur Catakoglu2,
and Olivier Thonnard2
1 Eurecom, Biot, France
{elisa.chiapponi,marc.dacier,massimiliano.todisco}@eurecom.fr
2 Amadeus IT Group, Biot, France
{onur.catakoglu,olivier.thonnard}@amadeus.com
Abstract. This paper proposes a method and empirical pieces of evi-
dence to investigate the claim commonly made that proxy services used
by web scraping bots have millions of residential IPs at their disposal.
Using a real-world setup, we have had access to the logs of close to 20
heavilytargetedwebsitesandhavecarriedoutanexperimentoveratwo
months period. Based on the gathered empirical pieces of evidence, we
propose mathematical models that indicate that the amount of IPs is
likely 2 to 3 orders of magnitude smaller than the one claimed. This
finding suggests that an IP reputation-based blocking strategy could be
effective, contrary to what operators of these websites think today.
1 Introduction
This work has been realised in close collaboration with a major IT provider for
the airline industry which hosts several dozens of airline websites. These sites
areprotectedbyoneoftheleadingcommercialanti-botsservices,placedinfront
of them. This servicechecks the origin and the fingerprints associated with each
request against a large number of “signatures”1.
BotshavebeenaplaguefortheInternetformorethan20years.Earlywarn-
ings date back to the 2000s with the early DDoS attacks against major websites
[3].Sincethen,theyhavecontinuouslyevolvedfromrelativelyrudimentarypieces
of software to very sophisticated components such as the numerous “all in one
sneaker bots” (e.g., aiobot.com) that automate the buying process of luxury
goods in high demands. To increase their resilience, the bots take advantage of
proxy services publicly available on the web, for a fee. Thanks to these services,
the bots use temporarily IP addresses that are owned and used by legit users.
Thereare,supposedly,tensofmillionsofsuchIPsmadeavailabletobots.Would
the targeted websites decide to block each IP which is considered to behave like
abot,theywouldquicklydenyaccesstomillionsofIPs,someofthembelonging
to potential customers. Clearly, an IP blocking solution does not appear to be a
viable approach due to the, supposedly, sheer volume of IPs, available all over
the world.
1 This is a simplistic explanation. We refer the interested reader to [23] for more
information on such existing commercial offerings.
(cid:2)c SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.596–611,2021.
https://doi.org/10.1007/978-3-030-76352-7_52
Botnet Sizes: When Maths Meet Myths 597
In this paper, we use empirical evidence to investigate the conjecture that
such IP blocking strategy will always fail. We reach the conclusion that the
situation might not be as bleak as it might seem.
Inordertopresentourfindings,thepaperisstructuredasfollows.InSect.2,
we outline the problem faced and our contributions. Section3 presents the state
of the art on web scraping bots prevention. Section4 describes the experimen-
tal setup and the data it produced. Section5 briefly describes the raw results
obtained over a period of 56 days. Section6 assesses the credibility associated
withthebeliefthatthesebotnetshavemillionsofIPaddressesattheirdisposal.
Mathematical analysis confronted with the empirical pieces of evidence leads us
to adjudicate against that belief. In Sect.7, we gather additional information