solutions mitigate the torrent eﬀect?
What Is the Impact of P2P Traﬃc on Anomaly Detection?
13
Table 3. Mitigating P2P Eﬀect Using P2P Traﬃc Classiﬁers Based Traﬃc Filtering
(DR= Detection Rate; FP= False Positive; KPC= Karagiannis’ Payload Classiﬁer)
Rate Limiting TRW-CB MaxEnt NETAD
DR% FP% DR% FP% DR% FP% DR% FP%
50
No ﬁltering
OpenDPI[23] 56
60
KPC[24]
45
43
40
60
64
70
22
12
6
62
63
66
48
32
17
65
70
77
25
17
13
Table 4. Evaluation of OpenDPI and KPC on Encrypted P2P Traﬃc
Classiﬁed as p2p Classiﬁed as unknown Classiﬁed as non-p2p
OpenDPI
KPC
3.8%
64.7%
96.2%
35.2%
0%
0%
5.2 Can Existing Public p2p Traﬃc Classiﬁers Mitigate the Torrent
Eﬀect?
The p2p traﬃc classiﬁcation problem has been well investigated and signature-
and heuristic-based solutions exist. We, however, argue that many existing
heuristic-based solutions will also be subject to the overlapping feature limita-
tion.6 Therefore, it is important to choose approaches which use non-overlapping
heuristics. We now evaluate our proposed design on a popular DPI-based tech-
nology and on a hybrid scheme (signatures + heuristics).
We perform traﬃc ﬁltering using OpenDPI [23] (a signature based solution
with over 90 signatures) and Karagiannis’ Payload Classiﬁer(KPC) [24] (a hy-
brid solution with over 59 signatures); we refer interested readers to the orig-
inal papers for the details of OpenDPI and KPC. The results of evaluation of
the four anomaly detectors on ﬁltered traﬃc are shown in Table 3. Table 3
shows that KPC (unknown: 35.2%) provides remarkably better accuracy than
OpenDPI (unknown: 96.2%), mainly because OpenDPI is unable to detect any
encrypted p2p traﬃc. It can be clearly seen by comparing Table 3 and Table 4
that the improvements in anomaly detectors’ accuracies are dependent on the
traﬃc classiﬁer’s accuracy. One of the limiting factors in the accuracy of the
traﬃc classiﬁers is encrypted traﬃc.
We note from Table 3 that the current traﬃc classiﬁcation accuracies of the
DPI solutions are inadequate to induce a signiﬁcant improvement in anomaly
detection accuracy; detection rates after p2p traﬃc classiﬁcation range from 40-
70%, while false positives are between 6-40% for diﬀerent anomaly detectors.
Since the accuracies reported in Table 3 are impractical for commercial deploy-
ments, we conclude that public p2p traﬃc classiﬁcation solutions at present
cannot provide acceptable accuracies to induce an eﬀective accuracy improve-
ment in anomaly detection. While many commercial p2p traﬃc classiﬁcation
6 For example, the method in [20] uses failed connections as a feature and should not
be used in the present context.
14
I.U. Haq et al.
s
n
o
i
t
c
e
n
n
o
C
f
o
r
e
b
m
u
N
14
12
10
8
6
4
2
0
0
malicious−failure
malicious−successful
p2p−failure
p2p−successful
10
20
40
Elapsed time (seconds)
30
50
60
Fig. 6. Connection timeline for p2p and malicious (portscan attack) traﬃc
solutions are available, to the best of our knowledge, none of the p2p traﬃc clas-
siﬁers proposed by the research community have acceptable detection accuracies
for encrypted p2p traﬃc. Therefore, eﬃcient p2p traﬃc classiﬁcation remains an
open problem and a solution to this problem will beneﬁt the IDS community as
well as the traﬃc engineering community.
Until such a solution is developed, we need to identify non-overlapping (be-
tween malicious and p2p) traﬃc features that an anomaly detector can rely on.
As a preliminary, result, Figure 6 shows the connection timeline for the p2p and
malicious traﬃc. It can be seen that the sustained activity of maliciousness is
very diﬀerent from the sporadic p2p traﬃc activity. Therefore, p2p and mali-
cious traﬃc can be isolated if a notion of long-term statistics can be introduced
during anomaly detection. This is part of our ongoing research.
6 What Are the Open Problems in Designing Future
Anomaly Detectors?
The tremendous growth in p2p-based ﬁle sharing, VOIP and video streaming
traﬃc has revolutionized the Internet traﬃc characteristics. Our evaluations
showed that this change in traﬃc characteristics cannot be characterized by
existing anomaly detectors which rely on traﬃc features (e.g., rate, connection
failures, ports, etc.) that largely overlap with p2p traﬃc behavior. While we
proposed an adhoc solution which allows existing IDSs to work eﬀectively, a
question remains open regarding the scalability of this solution to future Inter-
net traﬃc. Recent projections of future attacks show that some of the greatest
threats in the future will be originating from ﬁle sharing networks [28]. In such
What Is the Impact of P2P Traﬃc on Anomaly Detection?
15
a threat landscape, a p2p traﬃc classiﬁcation based solution will simply allow
all malicious activities embedded within p2p traﬃc to go undetected.
While detection of malware delivered using p2p applications does not fall un-
der the scope of traﬃc anomaly detection, attacks originating from p2p networks
should be detected using these IDSs. One such attacks has already been proposed
in [27] where Naoumov and Ross designed a DDoS engine for ﬂooding a target
using the indexing and routing layers in a p2p systems. Similarly, IDSs should
be able to detect the exploits targeted at vulnerabilities which are a product of
the change to ﬁrewall rules for p2p traﬃc [29]. Finally, it is highly desirable to
detect the C&C channels of bots which also use p2p communication [30].
Given the premise that p2p traﬃc is here to stay, our work demonstrates
the need to rethink the classical anomaly detection design philosophy with a
focus on performing anomaly detection in the presence p2p traﬃc. We argue
that p2p traﬃc classiﬁcation will play a fundamental role in future IDSs as it
will facilitate detection of both the p2p and the non-p2p traﬃc anomalies, as
shown in Figure 5. In our proposed design, traditional non-p2p network attacks
will be detected using existing anomaly detectors, while an additional IDS that
specializes at detecting attacks within p2p traﬃc will also be deployed.
Design of a p2p-specialized IDS is still an open research problem that is part
of our ongoing research and that we also expect our peers to follow-up on. We
have made our dataset publicly available for performance benchmarking of such
future IDSs and p2p traﬃc classiﬁers.
Acknowledgments. We thank Dr. Hyun-chul Kim for providing Karagiannis’
Payload Classiﬁer.
References
1. Ipoque Internet Study Report 2008/2009,
http://www.ipoque.com/resources/internet-studies/
internet-study-2008 2009
2. Maier, G., Feldmann, A., Paxson, V., Allman, M.: On Dominant Characteristics
of Residential Broadband Internet Traﬃc. In: IMC (2009)
3. Erman, J., Gerber, A., Hajiaghayi, M.T., Pei, D., Spatscheck, O.: Network-Aware
Forward Caching. In: WWW (2009)
4. Labovitz, C., McPherson, D., Iekel-Johnson, S.: 2009 Internet Observatory Report.
In: NANGO: NANGO47 (2009)
5. Li, Z., Goyal, A., Chen, Y., Kuzmanovic, A.: Measurement and Diagnosis of Ad-
dress Misconﬁgured P2P Traﬃc. In: IEEE INFOCOM (2010)
6. Jung, J., Paxson, V., Berger, A.W., Balakrishnan, H.: Fast Portscan Detection
Using Sequential Hypothesis Testing. In: IEEE Symposium on Security and Privacy
(2004)
7. Schechter, S.E., Jung, J., Berger, W.: Fast Detection of Scanning Worm Infections.
In: Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, pp.
59–81. Springer, Heidelberg (2004)
8. Williamson, M.M.: Throttling Viruses: Restricting Propagation to Defeat Malicious
Mobile Code. In: ACSAC (2002)
16
I.U. Haq et al.
9. Twycross, J., Williamson, M.M.: Implementing and Testing a Virus Throttle. In:
Usenix Security (2003)
10. Gu, Y., McCullum, A., Towsley, D.: Detecting Anomalies in Network Traﬃc Using
Maximum Entropy Estimation. In: ACM IMC (2005)
11. Mahoney, M.V.: Network Traﬃc Anomaly Detection Based on Packet Bytes. In:
ACM Symposium on Applied Computing (2003)
12. Next-Generation Intrusion Detection Expert System (NIDES),
http://www.csl.sri.com/projects/nides/
13. Weaver, N., Staniford, S., Paxson, V.: Very Fast Containment of Scanning Worms.
In: Usenix Security (2004)
14. Lakhina, A., Crovella, M., Diot, C.: Diagnosing Network-wide Traﬃc Anomalies.
In: ACM SIGCOMM (2004)
15. Lakhina, A., Crovella, M., Diot, C.: Mining Anomalies Using Traﬃc Feature Dis-
tributions. In: ACM SIGCOMM (2005)
16. Patcha, A., Park, J.: An Overview of Anomaly Detection Techniques: Existing
Solutions and Latest Technological Trends. Elsevier Computer Networks (2007)
17. DARPA Intrusion Detection Data Sets,
http://www.ll.mit.edu/mission/communications/ist/corpora/ideval/
data/index.html
18. LBNL/ICSI Enterprise Tracing Project,
http://www.icir.org/enterprise-tracing/download.html
19. Endpoint Dataset, http://wisnet.seecs.edu.pk/projects/ENS/DataSets.html
20. Collins, M., Reiter, M.: Finding Peer-to-Peer File-Sharing Using Coarse Network
Behaviors. In: Gollmann, D., Meier, J., Sabelfeld, A. (eds.) ESORICS 2006. LNCS,
vol. 4189, pp. 1–17. Springer, Heidelberg (2006)
21. Bartlett, G., Heidemann, J., Papadopoulos, C.: Inherent Behaviors for On-line
Detection of Peer-to-Peer File Sharing. In: Proceedings of the 10th IEEE Global
Internet (2007)
22. Liu, Y., Guo, Y., Liang, C.: A Survey on Peer-to-Peer Video Streaming Systems.
In: Peer-to-peer Networking and Applications (2008)
23. OpenDPI, Ipoque’s DPI software’s Open Source Version,
http://www.opendpi.org/
24. Karagiannis, T., Broido, A., Brownlee, N., Claﬀy, K.C., Faloutsos, M.: Is P2P
Dying or Just Hiding? In: IEEE Globecom (2004)
25. Sun, X., Torres, R., Rao, S.: DDoS Attacks by Subverting Membership Manage-
ment in P2P Systems. In: 3rd IEEE Workshop on Secure Network Protocols (2007)
26. Athanasopoulos, E., Anagnostakis, K.G., Markatos, E.P.: Misusing Unstructured
P2P Systems to Perform DoS Attacks: The Network That Never Forgets. In: Zhou,
J., Yung, M., Bao, F. (eds.) ACNS 2006. LNCS, vol. 3989, pp. 130–145. Springer,
Heidelberg (2006)
27. Naoumov, N., Ross, K.: Exploiting P2P Systems for DDoS Attacks. In: INFOS-
CALE (2006)
28. 2010 Cyberthreat Forecast from Kaspersky Lab,
http://usa.kaspersky.com/about-us/
news-press-releases.php?smnr id=900000322
29. Chien, E.: Malicious Threats of Peer-to-Peer Networking. Whitepaper, Symantec
Security Response (2008)
30. McAfee Labs, Threat Predictions (2010),
http://www.mcafee.com/us/local content/white papers/
7985rpt labs threat predict 1209 v2.pdf
What Is the Impact of P2P Traﬃc on Anomaly Detection?
17
31. Arbor Peakﬂow: IP Traﬃc Flow Monitoring System,
http://www.arbornetworks.com/
index.php?option=com content&task=view&id=1465&Itemid=692
32. Allot Service Protector, DDoS Protection,
http://www.allot.com/Service_Protector.html#products
33. Sandvine: Network Protection,
http://www.sandvine.com/products/network_protection.asp
34. Ipoque Press Release: P2P Raid in Germany Shows Little Eﬀect,
http://www.ipoque.com/news-and-events/news/
pressemitteilung-ipoque-210606.html
35. Ashfaq, A.B., Robert, M.J., Mumtaz, A., Ali, M.Q., Sajjad, A., Khayam, S.A.:
A Comparative Analysis of Anomaly Detectors under Portscan Attacks. In: Lipp-
mann, R., Kirda, E., Trachtenberg, A. (eds.) RAID 2008. LNCS, vol. 5230, pp.
351–371. Springer, Heidelberg (2008)
36. Javed, M., Ashfaq, A.B., Shaﬁq, M.Z., Khayam, S.A.: On the Ineﬃcient Use of
Entropy for Anomaly Detection. In: RAID (2009)
A Centralized Monitoring Infrastructure for
Improving DNS Security
Manos Antonakakis, David Dagon, Xiapu Luo, Roberto Perdisci, Wenke Lee,
and Justin Bellmor
Georgia Institute of Technology, College of Computing,
{manos,dagon,csxpluo,perdisci,wenke}@cc.gatech.edu,
Atlanta, GA 30332, USA
PI:EMAIL
Abstract. Researchers have recently noted (14; 27) the potential of fast poi-
soning attacks against DNS servers, which allows attackers to easily manipulate
records in open recursive DNS resolvers. A vendor-wide upgrade mitigated but
did not eliminate this attack. Further, existing DNS protection systems, includ-
ing bailiwick-checking (12) and IDS-style ﬁltration, do not stop this type of DNS
poisoning. We therefore propose Anax, a DNS protection system that detects poi-
soned records in cache.
Our system can observe changes in cached DNS records, and applies machine
learning to classify these updates as malicious or benign. We describe our classi-
ﬁcation features and machine learning model selection process while noting that
the proposed approach is easily integrated into existing local network protection
systems. To evaluate Anax, we studied cache changes in a geographically diverse
set of 300,000 open recursive DNS servers (ORDNSs) over an eight month pe-
riod. Using hand-veriﬁed data as ground truth, evaluation of Anax showed a very
low false positive rate (0.6% of all new resource records) and a high detection
rate (91.9%).
Keywords: DNS Poisoning, Attack Detection, Local Network Protection.
1 Introduction
The Domain Name System, or DNS, maps domain names to IP addresses and other
records essential for email, web, and nearly every signiﬁcant network protocol. DNS se-
curity problems in turn affect numerous other services and critical resources. Recently,
the security community has identiﬁed fast poisoning techniques that allow the trivial
corruption of DNS records (23; 14). A poisoning attack allows an adversary to manip-
ulate resolution caches, usually through a “blind” off-path guessing of the transaction
components used for DNS message integrity.
Several secure DNS protocols have been proposed, including DNSSEC (6; 7) and
DNSCurve (9). DNSCurve provide link-level security while DNSSEC provide object-
based security of DNS messages using cryptographic means. However, the deployment
of DNSSEC has proven slow (26), and many hosts have on-path hardware that interferes
with DNSSEC’s larger packet sizes (8).
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 18–37, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
A Centralized Monitoring Infrastructure for Improving DNS Security
19
The delay in deploying secure DNS motivates the need for local networks to protect
their recursive DNS resolution infrastructure. Traditional solutions such as IDS and
packet-inspection tools provide limited protections against some classes of attacks, but
do not detect DNS poisonings. Indeed, poisoning attacks generally use valid, “RFC-
compliant” DNS messages that contain misleading answers (e.g., associating a domain
with the wrong IP address or nameserver—one under the control of an attacker).
For this reason, DNS security systems are generally concerned with records in cache
(or in the resolver), as opposed to in ﬂight (or on the wire). In this work, we focus on in
cache detection of DNS poisoning for similar reasons:
1. The in-line inspection of DNS trafﬁc can introduce latency. Some protocols are
tolerant of this delay, but for DNS, even adding a few tens of milliseconds delay
can have detrimental impact on other services (e.g., VoIP, DNSBL validation, etc.).
In extreme cases, adding such delays can result in SERVFAIL responses.
2. Several tools already detect classes of DNS attacks, such as packet format viola-
tions (e.g., name pointer loops (4)). These attacks are orthogonal to DNS poisoning,
and must be done on the wire data, as opposed to the cached data.
3. Some DNS attacks, such as out-of-bailiwick record injection (35), are already re-
jected by the DNS resolvers themselves. Such attacks are technically DNS poi-
soning, but have been addressed by RFC 2181 (19) (and related policies) and are
routinely dropped by recursive servers. (This is known as “answer validation” in
most DNS resolvers (12).) The DNS poisoning attacks we consider are in the newer
family of fast poisoning or “Kaminsky-class” attacks, which evade these forms of
basic RFC 2181 trustworthiness checks. Note that the answer validation phase is
usually opaque in a DNS resolver, and server logging of rejected records is often
infeasible, mainly due to system performance and volume of the logs.
For these reasons, we focus on the detection of DNS poisoning that is found in cache,
in order to identify attacks that have evaded all existing layers of protection. To detect
DNS poisoning that has evaded all other layers of ﬁltration, we need access to large,
busy recursive servers. In practice, such access is difﬁcult to obtain, because of the op-
erational risk it poses to a critical network component, and because of potential privacy
concerns in witnessing stub trafﬁc. We therefore decided to use data obtained from the
inspection of open recursive caches run by third parties on the Internet. Open recursive
resolvers (16) generally permit the inspection of their caches. Since we can success-
fully detect poisonous Resource Records (RR) in Internet scale measurements, we will
be able to do the same when we inspect a less diverse set of recursive DNS servers, e.g.,
those in a single organization.
We select 300,000 open recursive servers, in order to obtain a diversity of DNS re-
solvers based on geography, network size, and organizational type (e.g., corporate vs
university networks). The network properties of these hosts are discussed in Section 3.
Using this data source, we designed and evaluated a large-scale, centralized poisoning
detection system called Anax. Our implementation of Anax provides a scalable, central-