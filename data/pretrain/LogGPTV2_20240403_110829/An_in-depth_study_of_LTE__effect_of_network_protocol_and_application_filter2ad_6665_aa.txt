title:An in-depth study of LTE: effect of network protocol and application
behavior on performance
author:Junxian Huang and
Feng Qian and
Yihua Guo and
Yuanyuan Zhou and
Qiang Xu and
Zhuoqing Morley Mao and
Subhabrata Sen and
Oliver Spatscheck
An In-depth Study of LTE: Effect of Network Protocol and
Application Behavior on Performance
Junxian Huang∀
Yuanyuan Zhou∀
Feng Qian∃
Qiang Xu∀
Yihua Guo∀
Z. Morley Mao∀
Subhabrata Sen∃
∀University of Michigan
Oliver Spatscheck∃
∃AT&T Labs - Research
ABSTRACT
With lower latency and higher bandwidth than its predecessor 3G
networks, the latest cellular technology 4G LTE has been attracting
many new users. However, the interactions among applications,
network transport protocol, and the radio layer still remain unex-
plored. In this work, we conduct an in-depth study of these inter-
actions and their impact on performance, using a combination of
active and passive measurements. We observed that LTE has sig-
niﬁcantly shorter state promotion delays and lower RTTs than those
of 3G networks. We discovered various inefﬁciencies in TCP over
LTE such as undesired slow start. We further developed a novel
and lightweight passive bandwidth estimation technique for LTE
networks. Using this tool, we discovered that many TCP connec-
tions signiﬁcantly under-utilize the available bandwidth. On aver-
age, the actually used bandwidth is less than 50% of the available
bandwidth. This causes data downloads to be longer, and incur ad-
ditional energy overhead. We found that the under-utilization can
be caused by both application behavior and TCP parameter setting.
We found that 52.6% of all downlink TCP ﬂows have been throttled
by limited TCP receive window, and that data transfer patterns for
some popular applications are both energy and network unfriendly.
All these ﬁndings highlight the need to develop transport protocol
mechanisms and applications that are more LTE-friendly.
Categories and Subject Descriptors
C.2.1 [Network Architecture and Design]: wireless communi-
cation; C.4 [Performance of Systems]: measurement techniques,
performance attributes; D.2.8 [Metrics]: Performance measures
Keywords
LTE, 4G, bandwidth estimation, TCP performance, resource under-
utilization
1.
INTRODUCTION
4G LTE is the latest deployed cellular network technology that
provides high-speed data services for mobile devices with adver-
tised bandwidths matching and even exceeding the home broad-
Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for 
personal or classroom use is granted without fee provided that copies are not 
made or distributed for profit or commercial advantage and that copies bear 
this notice and the full citation on the first page. Copyrights for components of 
this  work  owned  by  others  than  ACM  must  be  honored.  Abstracting  with 
credit is permitted. To copy otherwise, or republish, to post on servers or to 
redistribute  to  lists,  requires  prior  specific  permission  and/or  a  fee.  Request 
permissions from permissions@acm.org. 
SIGCOMM’13, August 12–16, 2013, Hong Kong, China. 
Copyright © 2013 ACM  978-1-4503-2056-6/13/08…$15.00. 
band network speeds. Recent work [13] has demonstrated the power
model of the LTE network. Compared to 3G, LTE provides the
promise of higher energy efﬁciency as a result of a new resource
management policy and higher achievable throughput. However,
this new technology has not been extensively studied empirically in
a deployed commercial network setting to understand how network
resources are utilized across different protocol layers for real users.
It is important to evaluate the beneﬁts of increased bandwidth for
popular mobile applications and essential network protocols such
as TCP to identify their limitations for needed improvements. In-
tuitively, network protocol overheads can be signiﬁcant enough to
prevent efﬁcient usage of available network resources [37]. This
has been shown in network settings with high network capacity but
potentially unpredictable network conditions [32].
We are motivated by the fact that LTE uses unique backhaul and
radio network technologies, and has unique features distinguish-
ing it from other access technologies (e.g., much higher available
bandwidth and lower RTT), requiring some existing topics to be re-
visited. Also, the prevalence of these problems in commercial LTE
networks is very important for both academia and industry. In this
work, we evaluate the usage of LTE network resources by analyz-
ing an extensive data trace collected at a commercial LTE network.
As far as we know, this is the ﬁrst in-depth analysis of deployed
LTE technology in a commercial setting. We systematically com-
plement the data analysis with local experiments using controlled
trafﬁc patterns to conﬁrm or further investigate our observations
based on data traces. Given the prevalence of proxy deployment in
cellular networks for improving user perceived performance due to
inherently limited radio network resources, we also study the im-
pact of such middleboxes on performance. No previous work has
performed any detailed evaluation of such impact.
Our approach to characterizing the usage of a commercial LTE
network starts with a careful analysis of basic network character-
istics in terms of TCP ﬂow properties, network latency, followed
by the congestion control statistics of observed TCP ﬂows. To an-
swer the question whether application trafﬁc is effectively utilizing
available network resources, we devise a lightweight method to es-
timate the available network bandwidth based on the ﬁne-grained
TCP data packet and ACK packet exchange close in time, while
making use of the TCP Timestamps option. We validate the ac-
curacy of our bandwidth estimation algorithm using controlled ex-
periments. We expect this algorithm to be helpful in identifying
protocol level and application level inefﬁciencies even in the pres-
ence of sufﬁciently available network resources. Besides perfor-
mance overhead, network usage efﬁciency has direct impact on the
energy usage of mobile devices. We highlight the potential energy
waste due to ineffective use of available network resources. Given
the prevalence of video and audio applications in cellular networks
363and their signiﬁcant contribution to the network resource usage, we
perform a case study on popular multimedia applications from the
perspectives of network resource usage.
In summary, we make the following contributions:
• Using the TCP Timestamps option, we devise a passive method
to estimate the available bandwidth by observing the TCP
packet streams between the mobile device and the server.
• We develop a set of pragmatic techniques for passively cap-
turing TCP ﬂow characteristics such as ﬂow size, ﬂow dura-
tion, ﬂow rate, loss rate, queuing delay, LTE promotion delay
from a monitor placed between the LTE Radio Access Net-
work (RAN) and the Serving Gateway (SGW) or Packet Data
Network Gateway (PGW).
• To evaluate performance of TCP ﬂows, we design simple
heuristics to identify abnormal TCP behavior based on du-
plicate ACKs, out of order packets, and slow start through
the analysis of packet traces and congestion window size.
Besides these methodological contributions, we make the fol-
lowing insightful observations about LTE network usage.
• For large TCP ﬂows, queueing delay may increase RTT to a
few times the normal value. However, as TCP does not use
duplicate ACKs to update RTT estimation (thus the retrans-
mission timeout), undesired slow start may occur in the mid-
dle of a ﬂow upon a single packet loss, and this phenomenon
is observed for 12.3% of all large TCP ﬂows.
• We observe that 52.6% of all downlink TCP ﬂows have ex-
perienced full TCP receive window or even zero receive win-
dow, limiting the sending rate.
• Overall, with the bandwidth estimation algorithm, we ob-
serve that for 71.3% of the large ﬂows, the bandwidth uti-
lization ratio is below 50%. And on average, data transfer
takes 52.9% longer than if the bandwidth was fully utilized,
incurring additional radio energy overhead.
Based on these observations, we make several recommendations
on protocol and application design to more effectively take advan-
tage of the available network resources. We believe our ﬁndings
apply to other LTE networks given the extensive coverage of the
data set and independent controlled experiments carried out locally.
Here is the roadmap for the paper. §2 covers related work, fol-
lowed by §3 where we describe the data set studied and setup for
controlled experiments. We then characterize the LTE network
characteristics in §4 and discuss a newly identiﬁed TCP perfor-
mance issue in LTE networks in §5. We investigate the network
resource usage efﬁciency with a devised bandwidth estimation al-
gorithm in §6, and then explore the network application behaviors
that cause network inefﬁciency in §7, before concluding in §8.
2. RELATED WORK
We summarize three categories of work in understanding smart-
phones and mobile networks.
Characterizing Mobile Network Usage and Performance. Prior
efforts [8, 30, 23] deployed smartphone user studies and collected
data from tens to hundreds of participating users. Those stud-
ies investigated various aspects including the diversity of smart-
phone users, the popularity of mobile applications, and the effec-
tiveness of compression techniques on cellular trafﬁc etc.. The 3G
Test study [14] adopts another approach by publishing an app that
actively measures various network performance metrics on users’
handsets. Our study features a much larger user base of around
300K customers using the LTE networks whose characteristics are
Figure 1: Simpliﬁed network topology of the large LTE carrier
from which we obtained our measurement data.
far from being well understood. Some previous studies also per-
formed large-scale measurement of mobile networks and smart-
phones. Sommers et al. compared cellular and WiFi performance
using crowd-sourced data from speedtest.net covering 15 metro
areas, focusing on throughput and latency [31]. Xu et al. proﬁled
diverse usage behaviors of smartphone applications [34]. Qian et
al. performed network-wide measurement studies of cellular peri-
odic transfers [24]. In contrast, our investigated spectrum is more
diverse, covering trafﬁc characteristics, network performance, pro-
tocol interaction, bandwidth utilization, and application usage in
the increasingly popular LTE networks. We also compare our re-
sults with those presented in [14] and [31]. Some previous stud-
ies [9, 6] also examined mobile handsets using WiFi networks.
Cellular Resource Management and Cross-layer Interaction.
In cellular networks, there exists a radio resource control (RRC)
state machine that manages the handset radio interface. It is the
key coupling factor bridging the application trafﬁc patterns and the
lower-layer protocol behaviors. Previous studies [25] and [13] ex-
amine the RRC state machine and its interaction with cellular traf-
ﬁc, for 3G UMTS and 4G LTE networks, respectively. We study
for hundreds of thousands of users their state transition delay and
transport-layer idle time, two key factors incurring signaling load
and energy overhead, respectively, due to the LTE RRC state ma-
chine. Previous studies also examined the interplay between TCP
and cellular networks. For example, Liu et al. studied the physical
and MAC layers in 3G EvDO networks and their impact on TCP
performance [17]. Jiang et al. examined how large buffers in cellu-
lar networks contribute to signiﬁcant TCP queuing delay [16]. Our
study brings new insight into the complex interaction between LTE
and TCP, as detailed in §4.
Cellular Network Infrastructure. Xu et al. characterized 3G
data network infrastructures, leading to an observation that the rout-
ing of cellular data trafﬁc is quite restricted as trafﬁc must traverse
through a small number of gateway nodes [35]. Wang et al. un-
veiled cellular carriers’ NAT and ﬁrewall policies [33]. Balakrish-
nan et al. investigated IP address dynamics in 3G networks. They
found that cellular IPs embed much less geographical information
than wired IPs do [4]. In this work, characterizing LTE infrastruc-
tures is not our immediate focus, but we do have novel ﬁndings
that they highly affect our measurement methodology and results
as pinpointed in §4 and §6.
3. LTE DATA AND LOCAL TESTBED
We give an overview of the LTE network topology before de-
scribing our measurement data. We then describe how we perform
controlled experiments for validating our ﬁndings.
3.1 The LTE Measurement Data
As depicted in Figure 1, an LTE network consists of three sub-
systems: user equipment (UE), the radio access network (RAN),
eNBMonitorPEPSGW &PGWOther TrafficFirewallUERANCore Network (CN)Internet364and the core network (CN). UEs are essentially mobile handsets
carried by end users. The RAN allows connectivity between a UE
and the CN. It consists of multiple base stations called Evolved
Node B (eNB). The centralized CN is the backbone of the cellu-
lar network. It connects to the Internet. In Figure 1, within the CN,
“Monitor” is our data collection point. “SGW” and “PGW” refer to
the serving gateway and the packet data network gateway, respec-
tively. “PEP” corresponds to the performance enhancing proxy to
be described shortly. From the perspective of UEs, we deﬁne down-
link as the network path from the Internet to UEs, and uplink as the
path in the reverse direction. Similarly, we also use the terms down-
stream and upstream from the perspective of the Monitor to indi-
cate the relative locations of network elements, e.g., downstream
refers to the path between monitor and UEs.
The Performance Enhancing Proxy (PEP). The data collec-
tion point is located within the core network of the studied LTE
network. TCP trafﬁc from or to server port 80 or 8080 traverses the
PEP on the upstream side of the monitor. The PEP splits the end-
to-end TCP connection into two, one between the UE and the PEP
and the other between the PEP and the server. It can potentially
improve the Web performance by, for example, performing com-
pression and caching. Also the PEP makes the split transparent to
UEs by spooﬁng its IP address to be the server’s IP address.
Data Collection. Our measurement data is a large packet header
trace covering a ﬁxed set of 22 eNBs at a large metropolitan area
in the U.S. The data collection was started on October 12 2012 and
lasted for 240 hours. We record IP and transport-layer headers, as
well as a 64-bit timestamp for each packet. No payload data is
captured except for HTTP headers, the dominant application-layer
protocol for today’s smartphones [34]. No user, protocol, or ﬂow-
based sampling is performed. No personally identiﬁable informa-
tion was gathered or used in conducting this study. To the extent,
any data was used, it was anonymous and aggregated data. During
the 10 days, we obtained 3.8 billion packets, corresponding to 2.9
TB of LTE trafﬁc (324 GB of packet header data, including HTTP
headers). To our knowledge, this is the ﬁrst large real-world LTE
packet trace studied in the research community.
Subscriber Identiﬁcation. Due to concerns of user privacy, we
do not collect any subscriber ID or phone numbers. We instead
use private IP addresses (anonymized using a consistent hash func-
tion) as approximated subscriber IDs, since private IPs of the carrier
are very stable. They change only at the interval of several hours.