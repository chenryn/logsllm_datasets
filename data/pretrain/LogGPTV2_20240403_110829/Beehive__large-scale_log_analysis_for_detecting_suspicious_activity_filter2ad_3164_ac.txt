### Traffic Volume Anomalies

We define a **connection (or domain) spike** as a one-minute window during which a host generates more connections (or contacts more domains) than a predefined threshold. A **connection (or domain) burst** is a time interval in which every minute is a connection (or domain) spike.

To determine an appropriate threshold for "high" traffic volume, we analyzed all dedicated hosts over a one-week period, counting the number of connections and distinct domains each host generated per minute. Figure 3 shows the cumulative distribution of these values across all one-minute windows for all dedicated hosts. We found that 90% of the hosts generated fewer than 101 connections and contacted fewer than 17 distinct domains per minute. Therefore, we set the threshold for connection spikes and domain spikes to these values.

### Clustering

Given the lack of ground truth regarding which hosts are infected or behaving anomalously (a challenge discussed in Section 2.3), we use an unsupervised learning approach—clustering. Since employees in the enterprise perform specific job functions on the corporate network, and there are multiple employees in most departments, we expect to observe groups of hosts (belonging to users with similar roles) exhibiting similar behaviors. Misbehaving hosts with unique behavioral patterns will appear as outliers.

Each internal host is represented as a 15-dimensional vector, \( v = (v[1], v[2], \ldots, v[15]) \). However, the features may be related or dependent on one another; for example, a domain spike often triggers a connection spike. To remove such dependencies and reduce the dimensionality of the vectors, we apply Principal Component Analysis (PCA) [23].

PCA enables data reduction by projecting the original vectors onto a new set of axes (i.e., the principal components). Each principal component captures as much variance (and thus as much of the original information) in the data as possible. In Beehive, we select the top \( m \) principal components that capture at least 95% of the data variance.

After applying PCA, we use a clustering algorithm adapted from K-means, but it does not require the number of clusters to be specified in advance [25]. The steps are as follows:

1. Randomly select a vector as the first cluster hub. Assign all vectors to this cluster.
2. Select the vector furthest away from its hub as a new hub. Reassign every vector to the cluster with the closest hub.
3. Repeat step 2 until no vector is further away from its hub than half of the average hub-to-hub distance.

We compare vectors using L1 distance, i.e., for vectors \( v_1 \) and \( v_2 \), their distance is \( L1Dist(v_1, v_2) = \sum_{i=1}^{m} |v_1[i] - v_2[i]| \).

The clustering algorithm in Beehive is applied daily to the feature vectors of all active, dedicated hosts in the enterprise. On weekdays, we observe between 27,000 and 35,000 active hosts, and between 9,000 and 10,100 on weekends. After one iteration of the algorithm, the majority of hosts fall into one large cluster, while the remaining clusters consist of a few hosts whose behaviors deviate significantly from the norm (i.e., outliers). Beehive generates incidents for the top outlying hosts and reports them to the security analyst. If the algorithm is biased by extreme outliers, we reapply PCA and the clustering algorithm to the largest cluster until at least 50 outlying hosts are identified in a day.

### Burst Definition

For bursts, we slightly relax the definition so that the threshold for spikes within a burst is the 75th percentile of all one-minute windows across all hosts (see Figure 3). This value is 26 for connection spikes and 6 for domain spikes.

For each dedicated host, the traffic-based features include:
1. The number of connection spikes
2. The number of domain spikes
3. The duration of the longest connection burst
4. The duration of the longest domain burst

### Evaluation

We evaluated Beehive in a large enterprise, EMC, over two weeks from April 22 to May 5, 2013. During this period, Beehive generated 784 incidents, with an average of 56 incidents per day and a standard deviation of 6.88. Only eight of these incidents overlapped with alerts generated by the enterprise’s state-of-the-art security tools.

To evaluate Beehive in the absence of ground truth, we used a two-step process of manual investigation. We first examined and labeled all incidents generated by Beehive (Section 4.2). Incidents whose cause we could not identify were labeled as "suspicious" and presented to the enterprise’s Security Operations Center (SOC) for further analysis (Section 4.3).

### Clustering Context

Each Beehive incident includes contextual information about the cluster each host belongs to, such as the number of hosts in the cluster and the average value of the feature vectors. This information facilitates the manual investigation process by allowing the analyst to quickly identify the distinctive features in each cluster.

Figure 4 shows the normalized average feature vectors for all 15 outlying clusters generated on April 24th. The clusters are distinct, characterized by different subsets of features. Hosts in the same cluster exhibit very similar behaviors. For example, Cluster 3 is unique in its high numbers of blocked connections, connection spikes, and domain spikes, suggesting an automated process. During our investigation, hosts in this cluster were found to violate company policy by contacting blocked domains excessively. Cluster 6, on the other hand, contacted high numbers of new destinations and generated connection spikes to blocked and challenged domains, indicating infected hosts contacting dynamically generated domains (DGAs).

### Manual Labeling

Our manual investigation process began by identifying the distinctive features for the host’s cluster. We then attempted to identify the root cause using contextual information reported by Beehive and examining raw logs collected by the SIEM system. This involved looking up UA strings, HTTP status codes, web referers, timing patterns in connections, and the reputation of contacted domains (using McAfee SiteAdvisor and URLvoid) and when they were registered (using DomainTools).

Briefly, 25.25% of the Beehive incidents were either confirmed malware or "suspicious," 39.41% were violations of enterprise security policies, and 35.33% were associated with unrecognized (but noisy) software or services. Table 4 provides a breakdown of the categories of Beehive incidents.

| Category                          | # of incidents | Percentage |
|-----------------------------------|----------------|------------|
| Malware                           | 117            | 14.92%     |
| Suspicious                        | 81             | 10.33%     |
| Policy Violation - Tunneling      | 1              | 0.12%      |
| Policy Violation - File sharing   | 2              | 0.25%      |
| Policy Violation - Streaming      | 86             | 10.96%     |
| Policy Violation - IM             | 56             | 7.14%      |
| Policy Violation - Porn           | 6              | 0.76%      |
| Policy Violation - Gaming         | 13             | 1.65%      |
| Policy Violation - Proxy          | 4              | 0.51%      |
| Policy Violation - Remote access  | 8              | 1.02%      |
| Other - Uncategorized sites       | 133            | 16.96%     |
| Other - Browsing                  | 57             | 7.27%      |
| Other - Automated                 | 63             | 8.03%      |
| Other - Heavy traffic             | 157            | 20.02%     |

Many of the malware detected by Beehive contacted (or attempted to contact) domains created by domain-generation algorithms (DGAs). The destination-based features proved to be most useful in identifying such malware, as most DGA hosts sit in clusters with high numbers of new destinations. Among clusters from April 24th, all hosts in clusters 1, 6, and 8 were confirmed to be infected with DGA malware, none of which were previously detected by antivirus software or the enterprise SOC.

Beehive also detected violations of the enterprise’s network security policies, including substantive personal use of company computing resources, installation of unapproved software, access to offensive materials, and high consumption of bandwidth for non-business purposes. Our manual investigation found 16.96% of the incidents associated with heavy traffic to external destinations blocked due to business concerns or labeled as potentially unsafe (e.g., sites associated with freeware). 10.96% of incidents were caused by high-volume video streaming applications, often characterized by connection or domain spikes or numerous challenged connections. Other violations included file sharing, third-party instant messaging, online gaming, viewing adult content, and using tunneling or proxy services to bypass network security mechanisms.

In addition to malware and policy violations, Beehive detected unusual activities originating from possibly benign, but unrecognized and likely automated applications. For example, 20.02% of the incidents involved hosts making tens of thousands of connections a day to the same website, typically news, sports, or finance sites, but also including ad servers, online forums, and sites hosted on Google.