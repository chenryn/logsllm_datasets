by the amount of time when a host is generating abnormally
high volumes of traﬃc.
Speciﬁcally, we deﬁne a connection (or domain) spike as
a one-minute window when the host generates more con-
nections (or contacts more domains) than a threshold. A
connection (or domain) burst is a time interval in which ev-
ery minute is a connection (or domain) spike.
To identify an appropriate threshold for “high” traﬃc vol-
ume, we examine all dedicated hosts over a one-week in-
terval, and count the number of connections (and domains)
each host generates (or contacts) per minute. Figure 3 shows
the cumulative distribution across all one-minute windows
for all dedicated hosts. 90% of the hosts generated less
than 101 connections, and contacted less than 17 distinct
domains, per minute. We hence set the threshold for con-
nection spikes and domain spikes to these values.
3.3 Clustering
Lacking ground truth as to which hosts are infected or be-
having anomalously (a challenge we describe in Section 2.3),
we tackle the problem of detection through an unsupervised
learning approach – clustering. Since employees in the en-
terprise perform speciﬁc job functions on the corporate net-
work, and there are multiple employees in most departments,
we should be able to observe groups of hosts (belonging to
users with similar roles) exhibiting similar behaviors, while
misbehaving hosts with unique behavioral patterns appear
as outliers.
Given the 15 features described in Section 3.2, each inter-
nal host is represented as a 15-dimensional vector, v = (v[1],
v[2], ··· , v[15]). However, the features may be related or de-
pendent upon one another; e.g., a domain spike also triggers
a connection spike. To remove such dependencies between
the features and reduce the dimensionality of the vectors,
we apply Principal Component Analysis (PCA) [23].
Brieﬂy, PCA enables data reduction by projecting the
original vectors onto a new set of axes (i.e., the principal
components). Each principal component is chosen to cap-
ture as much of the variance (and thus the original infor-
mation) in the data as possible. Depending on how much
variance we want to capture from the original data, the top
m principal components are selected, permitting projection
of the original vectors down to dimensionality m. In Bee-
hive, we select the top m components that capture at least
95% of the data variance.
We apply a clustering algorithm to the projected vectors
after PCA. Our algorithm is an adaptation of the K-means
clustering algorithm, but does not require the number of
clusters to be speciﬁed in advance [25].
1. Randomly select a vector as the ﬁrst cluster hub. As-
sign all vectors to this cluster.
2. Select the vector furthest away from its hub as a new
hub. Reassign every vector to the cluster with the
closest hub.
3. Repeat step 2 until no vector is further away from its
hub than half of the average hub-to-hub distance.
We compare vectors via L1 distance, i.e., for vectors v1 and
v2, their distance is L1Dist(v1, v2) =
i=1 |v1[i] − v2[i]|.
(cid:2)m
The clustering algorithm in Beehive is applied daily on the
feature vectors for all active, dedicated hosts in the enter-
prise. (We observe between 27,000 and 35,000 hosts active
during weekdays, and between 9,000 and 10,100 hosts ac-
tive on weekends.) Interestingly, after one iteration of the
algorithm, the vast majority of hosts fall into one large clus-
ter, while the remaining clusters consist of few hosts whose
behaviors deviate signiﬁcantly from the norm (i.e., outliers).
Beehive generates incidents for the top outlying hosts, and
reports them to the security analyst. Note that the algo-
rithm forms clusters by iteratively identifying the node that
is furthest away from its cluster hub, and so the clusters
have an inherent ordering to them. In cases where the algo-
rithm is biased by extreme outliers (e.g., forming only two
clusters, one with a single node, and the other with all other
nodes), we apply PCA and the clustering algorithm again
to the largest cluster. This process is iterated until at least
50 outlying hosts are identiﬁed in a day.
Figure 3: CDF for number of web connections and
number of domains contacted by a host per one-
minute interval.
For bursts, we relax its deﬁnition slightly, so that the
threshold for spikes within a burst is the 75% percentile of
all one-minute windows across all hosts (see Figure 3). This
value is 26 for connection spikes, and 6 for domain spikes.
For each dedicated host, its traﬃc-based features include:
1) the number of connections spikes, 2) the number of do-
main spikes, 3) the duration of the longest connection burst,
and 4) the duration of the longest domain burst.
204
4. EVALUATION
We evaluated Beehive in a large enterprise, EMC, over a
period of two weeks, from April 22 to May 5, 2013. During
this period, Beehive generated 784 incidents, with an average
of 56 incidents per day and a standard deviation of 6.88.
Among these, only eight incidents overlap with the alerts
generated by the enterprise’s state-of-the-art security tools.
To evaluate Beehive in the absence of ground truth – in
the sense of accurate, existing classiﬁcation of identiﬁed in-
cidents – we resort to a two-step process of manual investi-
gation. We ﬁrst examine and label all incidents generated
by Beehive (see Section 4.2). Incidents whose cause we could
not identify are labeled as “suspicious” and presented to the
enterprise’s Security Operations Center (SOC) for further
analysis (see Section 4.3).
4.1 Clustering Context
In addition to the host and its feature vector, each Bee-
hive incident also includes contextual information about the
cluster each host belongs to, such as the number of hosts
in the cluster and the average value of the feature vectors.
This information facilitates the manual investigation process
described below, as it allows the analyst to quickly identify
the distinctive features in each cluster.
To give intuition about the types of activities captured
by the clustering, Figure 4 shows, for all 15 outlying clus-
ters generated on April 24th, the normalized average feature
vectors. That is, we ﬁrst compute the mean feature vector
of each cluster averaged over all vectors in that cluster, and
then normalize each vector component — i.e., feature value
– relative to the maximum across all mean feature vectors.
As shown in Figure 4, the clusters are distinct in that they
are characterized by diﬀerent (subsets of) features.
While clusters are distinct from one another, the hosts
in the same cluster exhibit very similar behaviors. Table 3
shows the actual feature vectors of hosts in two example
clusters (3 and 6) on April 24th. For instance, cluster 3 is
unique in its high numbers of blocked connections, connec-
tions spikes, and domain spikes — suggesting an automated
process is responsible for the activity. (Indeed, during our
investigation described in the next section, hosts in this clus-
ter are found to violate the company policy by contacting
blocked domains excessively.) As another example, hosts
in cluster 6 contacted high numbers of new destinations, as
well as generating connection spikes to blocked and chal-
lenged domains. Our investigation revealed that this cluster
is comprised solely of infected hosts that contact dynami-
cally generated domains (DGAs).
In the following, we detail our manual investigation pro-
cess and the suspicious activities detected by Beehive.
4.2 Manual Labeling
Our manual investigation process for a host began by iden-
tifying the feature(s) that were distinctive for the host’s clus-
ter. We then attempted to identify the root cause of this
distinction using contextual information reported by Beehive
and examining raw logs collected by the SIEM system about
the host. The latter involved looking up the UA strings,
HTTP status codes, web referers, and timing patterns in
connections from the host, as well as the reputation of con-
tacted domains (using McAfee SiteAdvisor and URLvoid 1)
and when they were registered (using DomainTools 2).
Brieﬂy, 25.25% of the Beehive incidents were either con-
ﬁrmed malware or “suspicious” (we give more details on “sus-
picious” incidents in Section 4.3), 39.41% were violations of
enterprise security policies, and 35.33% were associated with
unrecognized (but noisy) software or services. Table 4 lists
the number and percentage of incidents in each category.
Category
Malware
Suspicious
Policy Violation - Tunneling
Policy Violation - File sharing
Policy Violation - Streaming
Policy Violation - IM
Policy Violation - Porn
Policy Violation - Gaming
Policy Violation - Proxy
Policy Violation - Remote access
Policy Violation - Blocked sites
Other - Uncategorized sites
Other - Browsing
Other - Automated
# of incidents
117
81
1
2
86
56
6
13
4
8
133
57
63
157
14.92%
10.33%
0.12%
0.25%
10.96%
7.14%
0.76%
1.65%
0.51%
1.02%
16.96%
7.27%
8.03%
20.02%
Table 4: Breakdown of the categories of Beehive inci-
dents over two weeks from April 22 to May 5, 2013.
Many of the malware detected by Beehive contacted (or at-
tempted to contact) domains created by domain-generation
algorithms (DGAs). The destination-based features (see
Section 3.2) proved to be most useful in identifying such
malware, as most of the DGA hosts sit in clusters with high
numbers of new destinations. Among clusters from April
24th presented in Figure 4, all of the hosts in clusters 1, 6
and 8 were conﬁrmed to be infected with DGA malware.
None of these infections were previously detected by an-
tivirus software or by the enterprise SOC.
Beehive also detected violations of the enterprise’s network
security policies. As with many companies, these forbid sub-
stantive personal use of company computing resources, in-
stallation of software not explicitly approved by the com-
pany, access to oﬀensive materials (e.g. pornographic or
otherwise disparaging content), and injudiciously high con-
sumption of bandwidth for business purposes. Our manual
investigation found 16.96% of the incidents associated with
heavy traﬃc to external destinations blocked due to business
concerns or labeled as potentially unsafe (e.g., sites associ-
ated with freeware). 10.96% of incidents were caused by
high-volume video streaming applications, often character-
ized by connection or domain spikes or numerous challenged
connections. Others included ﬁle sharing, third-party in-
stant messaging, online gaming, viewing of adult content, or
using tunneling or proxy services to bypass network security
mechanisms (e.g., to access blocked websites).
In addition to malware and policy violations, Beehive also
detected unusual activities originating from possibly benign,
but unrecognized and likely automated applications. For
example, 20.02% of the incidents involved hosts that made
tens of thousands of connections a day to the same website.
These were typically news, sports, or ﬁnance sites, but in-
cluded ad servers, online forums, and sites hosted on Google
1http://www.urlvoid.com
2http://www.domaintools.com
205
Figure 4: Normalized average feature vectors for clusters generated on April 24, 2013.
Features
Cluster 3
Cluster 6
1
0
0
2
0
0
247
200
239
214
247
200
239
214
3
19
2
11
14
22
0
4
0.95
0.33
0.041
0.053
0.080
0
Maximum value
490
489
286
0.984
5
0
0
1
0
0
0
4
6
4
11
8
36
26
31
7
47833
25479
8
7
1
61
435
976
739
156
142
153
142
9
10
11
12
13
14
15
52
1
163
170
177
147
0
0
0
6
0
0
0
0
386
309
0
10
0
0
11
27
26
0
96
6