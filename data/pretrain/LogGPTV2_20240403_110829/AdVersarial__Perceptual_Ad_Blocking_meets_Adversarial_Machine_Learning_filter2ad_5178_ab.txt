ning in browsers at a high privilege level. They can be implemented
as browser extensions or integrated in the browser. We ignore DNS
ad-blockers (e.g., Pi-hole) as these cannot use perceptual signals. 2
The goal of ad-blockers is to identify and hide ads, while guard-
ing against website breakage [4] resulting from the removal of
functional content. As opposed to network-level filters, perceptual
signals only apply to downloaded Web content and are thus unsuit-
able for some secondary goals of ad-blockers, such as bandwidth
saving or blocking of user tracking and malvertising [46, 51, 68, 93].
Ad-blockers may strive to remove ads without being detected
by the publisher. For example, many websites try to detect ad-
blockers [58] and take according action (e.g., by asking users to
disable ad-blockers). As perceptual ad-blockers do not interfere with
web requests, they are undetectable by the web-server [81]. How-
ever, the publisher’s JavaScript code can try to detect ad-blockers
by observing changes in the DOM page when hiding ads.
Finally, perceptual ad-blockers have strict timing constraints,
and should process a web page and detect ads in close to real-time.
2.2.2 Algorithms for Visual Ad Classification. The identification of
ads or ad-disclosures can be achieved using a variety of computer
vision techniques. Below, we describe existing approaches.
• Template matching. Ad-Highlighter detects the AdChoices logo
by comparing each image in a page to a template using average
2While our work focuses on the desktop browser setting, perceptual ad-blocking
might also prove useful in the mobile domain. Current mobile ad-blockers are often
part of a custom browser, or act as web proxies—an insufficient approach for native
apps that prevent proxying using certificate pinning. Instead, a perceptual ad-blocker
(potentially with root access) could detects ads directly from app screenshots
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2007hashing: for each image, a hash is produced by resizing the
th bit in the hash to 1 if
image to a fixed size and setting the i
th pixel is above the mean pixel value. An image matches
the i
the template if their hashes have a small Hamming distance.
A more robust template matching algorithm is the Scale Invari-
ant Feature Transform (SIFT) [52], which creates an image hash
from detected “keypoints” (e.g., edges and corners).
• Optical Character Recognition. To detect the rendered text in-
side the AdChoices logo, Ad-Highlighter uses the open-source
Tesseract OCR system [6]. Tesseract splits an image into over-
lapping frames and transcribes this sequence using a neural
network. Ad-Highlighter matches images for which the OCR
output has an edit-distance with “AdChoices” below 5.
• Image Classification. Albeit not in an ad-blocking context, Hus-
sain et al. [40] have demonstrated that neural networks could be
trained to distinguish images of ads from non-ads (without the
presence of any explicit ad-disclosures). The Percival project
trained a similar neural network to classify image frames in
real-time within Chromium’s rendering pipeline [84].
• Object Detection. Sentinel [10] detects ads in rendered web pages
using an object detector network based on YOLOv3 [72]. The
network’s output encodes locations of ads in an image. The
YOLOv3 [72] model outputs bounding box coordinates and
confidence scores for B = 10,647 object predictions, and retains
those with confidence above a threshold τ = 0.5.
2.3 Threat Model and Adversaries
We adopt the terminology of adversarial ML [65], where the de-
fenders are users of a classifier (the ad-blocker) that its adversaries
(e.g., ad networks or publishers) are trying to subvert.
Publishers, ad networks, and advertisers have financial incen-
tives to evade or detect ad-blockers. We assume that publishers
and ad networks are rational attackers that abide by regulations
on online advertising, and also have incentives to avoid actively
harming users or disrupting their browsing experience. As shown
in prior work [67, 93], this assumption fails to hold for advertisers,
as some have abused ad-networks for distributing malware. We
assume that advertisers and content creators (e.g., a Facebook user)
may try to actively attack ad-block users or other parties.
As ad-blockers are client-side software, adversaries can down-
load and inspect their code offline. However, we assume that adver-
saries do not know a priori whether a user is running an ad-blocker.
Attacking ad-blockers. The primary adversarial goal of publish-
ers, ad-networks and advertisers is to evade the ad-blocker’s detec-
tion and display ads to users. These adversaries may modify the
structure and content of web pages or ads to fool the ad-detector.
Alternatively, the ad-blocker’s adversaries may try to detect its
presence, to display warnings or deny access to the user. A common
strategy (used by 30% of publishers in the Alexa top-10k) adds fake
ad-content (honeypots) to a page and uses JavaScript to check if the
ads were blocked [95]. This practice leads to an orthogonal arms
race on ad-block detection [57, 58, 60] (see Appendix A).
Adversaries may also try to abuse ad-blockers’ behaviors to
degrade their usability (e.g., by intentionally causing site-breakage
or slow performance). The viability of such attacks depends on the
adversary’s incentives to avoid disrupting ad-block users’ browsing
experience (e.g., Facebook adds honeypots to regular user posts to
cause site-breakage for ad-block users [88]).
Finally, attackers with no ties to the online advertisement ecosys-
tem may try to hijack an ad-blocker’s high privilege-level in other
users’ machines. Such attackers can act as advertisers or content
creators to upload malicious content that exploits an ad-blocker’s
vulnerabilities. Figure 1 shows one example of such an attack, where
a malicious Facebook user uploads content that tricks the ad-blocker
into hiding an honest user’s posts. We will also show how Face-
book users can exploit Ad-Highlighter’s behavioral ad-blocking to
trigger arbitrary web requests in other users’ browsers.
2.4 Adversarial Examples
The attacks presented in this paper combines techniques from Web
security and from adversarial machine learning. In particular, we
leverage adversarial examples [83] to fool perceptual ad-classifiers.
An adversarial example for an input x of a model f is an input
ˆx = x + δ, where δ is a “small” perturbation such that ˆx is misclas-
sified with high confidence. We will consider perturbations with
small ℓ2 norm (Euclidean) or ℓ∞ norm (maximum per-pixel change).
To cause a model f to misclassify x + δ we would minimize the
confidence of f (x + δ ) in the true class, while also keeping δ small.
This is often achieved by minimizing a differentiable loss function
L(x + δ ) that acts as a proxy for the adversarial goal.
An effective algorithm for finding adversarial examples is Pro-
jected Gradient Descent (PGD) [48, 53]. Given an allowable pertur-
bation set (e.g., ||δ||∞ ≤ ϵ), we repeatedly update δ in the gradient
direction −∇δ L(x + δ ) and project back onto the allowable set.
In some cases, we will want perturbations to be re-usable so
that an attack can scale to a large number of websites or ads. A
minimizing(cid:80)
perturbation that can be re-used for many different inputs is called
a universal adversarial example [56]. It is usually created by jointly
i L(x (i ) + δ ) over many inputs x (i ), for a common δ.
3 DESIGNING PERCEPTUAL AD-BLOCKERS
To analyze the security of perceptual ad-blockers, we first pro-
pose a unified architecture that incorporates and extends prior and
concurrent work (e.g., Ad-Highlighter [81], visual filter-lists [8],
Sentinel [10], and the recent Percival patch for Chromium’s ren-
dering engine). We explore different ways in which ad-blockers
can integrate perceptual signals, and identify a variety of computer
vision and ML techniques that can be used to visually identify ads.
To simplify exposition, we restrict our analysis to ad-blockers
that only rely on perceptual signals. In practice, these signals are
likely to be combined with existing filter lists (as in uBlock [88] or
Adblock Plus [8]) but the details of such integrations are orthogonal
to our work. We note that an ad-blocker that combines perceptual
signals with filter lists inherits the vulnerabilities of both, so our
security analysis applies to these hybrid approaches as well.
3.1 General Architecture
A perceptual ad-blocker is defined by a collection of offline and
online steps, with the goal of creating, maintaining and using a
classifier to detect ads. Figure 3 shows our unified architecture for
perceptual ad-blockers. The ad-blocker’s core visual classifier can
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2008Figure 3: The Architecture of a Perceptual Ad-Blocker. In the offline phase, an ad-classifier is trained on web data. In the online
phase, the ad-blocker segments visited pages (1), classifies individual elements (2), and renders the user’s ad-free viewport (3).
extracts all img tags from a page) or use custom filters as in Adblock
Plus’ image search [8] or Ublock’s Facebook filters [88].
range from classical computer vision as in Ad-Highlighter [82] to
large ML models as in Sentinel [10].
The classifier may be trained using labeled web data, the type and
amount of which varies by classifier. Due to continuous changes
in web markup, ad-blockers may need regular updates, which can
range from extending existing rules (e.g., for Ad-Highlighter [81,
82]) to re-training complex ML models such as Sentinel [10].
When deployed by a user, the ad-blocker analyzes data from vis-
ited pages to detect and block ads in real-time. Ad detection consists
of three main steps. (1) The ad-blocker optionally segments the web
page into smaller chunks. (2) A classifier labels each chunk as ad
or non-ad content. (3) The ad-blocker acts on the underlying web
page based on these predictions (e.g., to remove HTML elements
labeled as ads). For some ad-classifiers, the segmentation step may
be skipped. For example, Sentinel [10] uses an object-detection
network that directly processes full web page screenshots.
Ad-Highlighter’s use of behavioral signals (i.e., recognizing ad-
disclosures by the presence of a link to an ad-policy page) can be
seen as a special type of classifier that may interact with segmented
Web elements (e.g., by clicking and following a link).
For textual ad-disclosures (e.g., Facebook’s “Sponsored” tag) the
classification step involves trivial string matching. Facebook is thus
deploying HTML obfuscation that targets an ad-blocker’s ability
to find these tags [88]. This ongoing arms race calls for the use of
visual (markup-less) detection techniques. Ad-disclosure logos (e.g.,
the AdChoices icon) can be visually classified using template match-
ing. Yet, due to many small variations in ad-disclosures in use, exact
matching (as in Adblock Plus [8]) is likely insufficient [81]. Instead,
Ad-Highlighter uses perceptual hashing to match all img elements
against the AdChoices logo. Ad-Highlighter also uses supervised
ML—namely Optical Character Recognition (OCR)—to detect the
“AdChoices” text [82]. Once an ad-disclosure is identified, the asso-
ciated ad is found using custom rules (e.g., when Ad-Highlighter
finds an AdChoices logo, it blocks the parent iframe).
Storey et al. [81] further suggest to detect ads through behavioral
signals that capture the ways in which users can interact with them,
e.g., the presence of a link to an ad-policy page.
Frame-based Perceptual Ad-blocking. The above element-
3.2.2
based approaches require mapping elements in the DOM to ren-
dered content (to ensure that elements are visible, and to map
detected ad-identifiers to ads). As we show in Section 4.4, this step
is non-trivial and exploitable if ad-blockers do not closely emulate
the browser’s DOM rendering, a complex process that varies across
browsers. For instance, image fragmentation or spriting (see Fig-
ure 10) are simple obfuscation techniques that fool Ad-Highlighter,
and would engender another cat and mouse game. To avoid this, ad-
blockers can directly operate on rendered images of a page, which
many browsers (e.g., Chrome and Firefox) make available to exten-
sions. Instead of operating on an entire rendered web page (see
page-based ad-blockers below), DOM features can still be used to
segment a page into regions likely to contain ads. For example, seg-
menting a page into screenshots of each iframe is a good starting
point for detecting ads from external ad networks. The approach
of Percival is also frame-based but directly relies on image frames
produced during the browser’s rendering process [84].
We consider two ways to classify frames. The first searches for ad-
disclosures in rendered ads. Template-matching is insufficient due
to the variability of backgrounds that ad-disclosures are overlaid on.
Instead, we view this as an object-detection problem and address
it with supervised ML. The second approach is to train a visual
classifier to directly detect ad content. Hussain et al. [40] report
promising results for this task. Percival also relies on a lightweight
deep learning model to classify frames as ad content [84].
3.2 Approaches to Ad Detection
When online, a perceptual ad-blocker’s first action is the “Page
Segmentation” step that prepares inputs for the classifier. Figure 4
illustrates different possible segmentations. A cross-origin iframe
(red box 3) displays an ad and an AdChoices icon (purple box 2). An
additional textual ad-disclosure is added by the publisher outside
the iframe (purple box 1). Publishers may use iframes to display
native content such as videos (e.g., red box 4).
We distinguish three main perceptual ad-blocking designs that
vary in the granularity of their segmentation step, and in turn in
the choice of classifier and actions taken to block ads.
• Element-based perceptual ad-blockers, such as Ad-Highlighter,
search a page’s DOM tree for HTML elements that identify ads,
e.g., the AdChoices logo or other ad-disclosures.
• Page-based perceptual ad-blockers, e.g., Sentinel [10], ignore the
DOM and classify images of rendered web pages.
• Frame-based perceptual ad-blockers, e.g., Percival [84], classify
rendered content but pre-segment pages into smaller frames.
3.2.1 Element-based Perceptual Ad-blocking. These ad-blockers
segment pages into HTML elements that are likely to contain ad-
disclosures. The segmentation can be coarse (e.g., Ad-Highlighter
https://www.example.comAd	DisclosureData	Collection	and	Training(1)	Page	Segmentation(3)	ActionClassifierClassifierAd(2)	ClassificationThe attacks described in this section do not violate existing laws
or regulations on deceptive advertising, as the changes to the visual
content of a page are imperceptible to human users.
4.1 Evaluation Setup
4.1.1 Evaluated Approaches. We analyze a variety of techniques
to instantiate the different stages of the perceptual ad-blocking
pipeline. In particular, we evaluate seven distinct approaches to the
ad-blocker’s core visual ad-classification step (see Table 1). Three
are element-based, three frame-based, and one page-based. These
seven classifiers are taken from or inspired by prior work. They are:
Two computer vision algorithms used in Ad-Highlighter [81, 82]
(average hashing and OCR); two ad classifiers, one from Hus-
sain et al. [40] and one used in Percival [84]; a robust feature
matcher, SIFT [52]; and two object detector networks—with the
same YOLOv3 model [72] as Sentinel [10, 61]—which we trained to
detect either ad-disclosures in frames, or ads in a full web page.
For the two object detector models we built, we explicitly sepa-
rated (i.e., assigned to non-communicating authors) the tasks of (1)
data-collection, design and training; and (2) development of attacks,
to ensure fair evaluation results. Our first (frame-based) model was
trained to detect AdChoices logos that we overlaid in a dataset
of 6,320 ads collected by Hussain et al. [40]. We then classify an
iframe as an ad, if the model detects the AdChoices logo in it.
Our second model emulates the approach of the unreleased Sen-
tinel [10, 61] and was trained to detect ads in arbitrary news web-
sites. This broadens Sentinel’s original scope (which was limited
to Facebook)—a decision we made due to difficulties in collecting
sufficient training data [61]. One author trained YOLOv3 to locate
ads in screenshots of news websites from all G20 nations. To collect
a diverse dataset of labeled ads in web screenshots, we first locates
ads using a web-proxy based on filter lists, and then randomly re-
place ads with a larger variety of examples. More details about this
process, of independent interest, are in Appendix B. A video of our
model in action on five websites not seen during training is available
at https://github.com/ftramer/ad-versarial/blob/master/videos.
4.1.2 Evaluation Data. We use real website data to evaluate the
accuracy and robustness of the above seven ad-classifiers. We built
an evaluation set from the top ten news websites in the Alexa
ranking (see Table 3). For each website, we extract the following
data:
(1) All images smaller than 50KB in the DOM. This data is used to
evaluate element-based techniques. We collect 864 images, 41 of
which are AdChoices logos (17/41 logos contain the “AdChoices”
text in addition to the icon).
(2) A screenshot of each iframe in the DOM tree, to evaluate frame-
based models. We collect 59 frames. Of these, 39 are ads and 29
contain an AdChoices logo. Percival [84] only considers images
of dimension at least 100 × 100 px so we limit it to these.3
3Taking a screenshot of an iframe is an approximation of how Chromium’s render-
ing engine segments frames for Percival’s classifier. We verified that our attacks on
Percival’s network work when deployed inside the Chromium browser.
Figure 4: Perceptual Ad-Blocking Elements. An ad (box #1) is
displayed in an iframe, that contains an AdChoices icon (box
#2). A custom ad-disclosure from the publisher is outside the
iframe (box #3). Publishers can use iframes to display non-
ad content such as videos (box #4).