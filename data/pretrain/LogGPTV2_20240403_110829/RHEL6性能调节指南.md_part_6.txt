:::
::: section
::: titlepage
# [⁠]{#main-analyzeperf.html#s-analyzeperf-mrg}3.6. Red Hat Enterprise MRG {.title}
:::
::: para
Red Hat Enterprise MRG 的实时组件包括
[**Tuna**]{.application}，它是可让用户调整其系统的可调节参数值，并查看那些更改结果。虽然这个工具是为使用实时组件而开发，但它也可以用于调整标准红帽企业版
Linux 系统。
:::
::: para
使用 Tuna，您可以调整或者禁用不必要的系统活动，其中包括：
:::
::: {.itemizedlist xmlns:d="http://docbook.org/ns/docbook"}
-   ::: para
    与电源管理有关的 BIOS 参数、错误探测以及系统管理中断；
    :::
-   ::: para
    网络设置，比如中断结合以及 TCP 使用；
    :::
-   ::: para
    日志文件系统中的日志活动；
    :::
-   ::: para
    系统活动记录；
    :::
-   ::: para
    中断和用户进程是由具体 CPU 还是一组 CPU 处理；
    :::
-   ::: para
    是否使用 swap 空间；以及
    :::
-   ::: para
    如何处理内存不足的意外情况。
    :::
:::
::: para
有关使用 Tuna 界面调整 Red Hat Enterprise MRG
的概念性信息请参考*《实时调节指南》*中"常规系统调节"一章。有关使用 Tuna
界面的步骤请参考*《Tuna 用户指南》*。这两本指南的网址为
。
:::
:::
:::
[]{#main-cpu.html}
::: chapter
::: titlepage
# [⁠]{#main-cpu.html#main-cpu}第 4 章 CPU {.title}
:::
::: para
CPU
意为*中央处理单元*，对大多数系统来说这个名字并不恰当，因为[*中央*]{.emphasis}暗指[*一个*]{.emphasis}，而大多数现代系统有一个以上的处理单元或者核。通常
CPUs
是一个放在一个包装中附着在主板[*插槽*]{.emphasis}。主板的每个插槽可连接到其他
CPU
插槽、内存控制器、中断控制器以及其他外部设备。连接到操作系统的插槽是一个
CPU 及相关资源的逻辑分组。这个概念是我们要讨论的 CPU
调节中大多数问题的关键。
:::
::: para
红帽企业版 Linux 有大量关于系统 CPU
事件的统计。这些统计数据在计划调节策略以改进 CPU
性能时很有帮助。[第 4.1.2 节 "调节 CPU
性能"](#main-cpu.html#s-cpu-tuning){.xref}
中讨论了一些游泳的统计，在哪里可以找到它们以及如何就性能调节对其进行分析。
:::
## [⁠]{#main-cpu.html#idm140329747368176}拓扑
::: para
在旧的计算机系统中，每个系统只有几个
CPU，因此将其构架称为*对称多处理器*（SMP）。就是说系统中的每个 CPU
对可用内存有类似（或者对称）的访问。近年来，CPU
按插槽计数已完善到可以尝试对系统中的所有内存进行对称访问，但这项技术非常昂贵。大多数高
CPU 计数系统现在才有名为*非均匀内存访问*（NUMA）技术而不是 SMP。
:::
::: para
AMD 处理器很久以前就已经在其*超级传输*（HT）互联中采用此架构，同时 Intel
也已最其*快速通道互联*（QPI）设计中使用此架构。NUMA 和 SMP
调节方法各异，因为最为程序分配资源时要考虑此系统的[*拓扑*]{.emphasis}。
:::
## [⁠]{#main-cpu.html#idm140329763735216}线程
::: para
Linux 操作系统内部到执行单元被称为*线程*。线程有注册上下文、栈以及在 CPU
中运行到可执行代码片段。操作系统（OS）的任务时在可用 CPU
中调度这些线程。
:::
::: para
操作系统根据跨各个核到线程间到负载平衡最大化 CPU 使用。因为 OS
主要考虑的是要让 CPU
处于忙碌状态，它可能没有就程序性能作出最佳选择。将一个程序线程从一个 CPU
移动到其他插槽要比等待 CPU
对性能的影响更大，因为访问内存的操作在跨插槽时会变得非常缓慢。对于高性能程序，设计者最好可以决定要将其放在哪个线程中。[第 4.2 节
"CPU 调度"](#main-cpu.html#s-cpu-scheduler){.xref}
中讨论了如何以最佳方式分配 CPU 和内存以便最好地执行程序线程。
:::
## [⁠]{#main-cpu.html#idm140329763738672}中断
::: para
*中断*（在 Linux 中被称为
IRQ）是一个不易觉察（但仍很重要）的系统事件，它可以影响程序性能。这些事件由操作系统处理，并用于外部设备以通知数据到达或者操作完成，比如系统写入或者计时器事件。
:::
::: para
OS 或者 CPU
执行程序代码处理中断的方法不影响程序功能。但它可能影响程序的性能。本章还讨论了防止中断对程序性能产生负面影响。
:::
::: section
::: titlepage
# [⁠]{#main-cpu.html#idm140329763741504}4.1. CPU 拓扑 {.title}
:::
::: section
::: titlepage
## [⁠]{#main-cpu.html#s-cpu-numa-topology}4.1.1. CPU 和 NUMA 拓扑 {.title}
:::
::: para
第一台计算机处理器是[*单处理机*]{.emphasis}，就是说系统只有一个
CPU。让这个操作系统可以平行运行进程的幻想是希望它能够将一个 CPU
迅速从一个执行线程切换到另一个。为提高系统性能，设计者注意到采用提高时钟率提高指令执行速度的方法是有限的（通常受采用当前技术生成稳定时钟波形的限制）。在努力获得更好总体系统性能时，设计者在系统中添加了另一个
CPU，就可以让两个平行流同时运行。这个添加处理器的趋势一直延续至今。
:::
::: para
大多数早期的单处理机系统的设计为让每个 CPU
到每个内存位置都使用同一逻辑路径（一般是平行总线）。这样每次 CPU
访问任意位置的内存时与其他系统中的 CPU
对内存的访问消耗的时间是相同的。此类架构就是我们所说的同步多处理器（SMP）系统。SMP
适合 CPU 数较少的系统，但一旦 CPU 计数超过某一点（8 或者
16），要满足对内存的平等访问所需的平行 trace
数就会使用过多的板载资源，留给外设的空间就太少。
:::
::: para
有两个新概念整合在一起可以允许系统中有较多的 CPU：
:::
::: {.orderedlist xmlns:d="http://docbook.org/ns/docbook"}
1.  ::: para
    串行总线
    :::
2.  ::: para
    NUMA 拓扑
    :::
:::
::: para
串行总线是一个有很高时钟频率的单线通讯路径，以分组突发传送的方式传送数据。硬件设计者开始使用串行总线作为
CPU 之间、CPU
和内存控制器以及其他外设之间的高速互联。就是说不是要求在[*每个*]{.emphasis}
CPU 中都有 32 和 64 个板载 trace
连接到内存子系统，现在只要[*一个*]{.emphasis} trace
即可，明显减少了板载空间要求。
:::
::: para
同时，硬件设计者通过减小芯片尺寸在同样的空间中放置了更多晶体管。他们不是将独立
CPU
直接放到主板上，而是开始将其打包到处理器包中作为多核处理器。然后设计者不是为每个处理器包提供对等的内存访问，而是借助非均衡存储器访问（NUMA）策略，让每个包/插槽组合有一个或者多个专用内存区以便提供高速访问。每个插槽还有到另一个插槽的互联以便提供对其他插槽内存的低速访问。
:::
::: para
作为简单的 NUMA
示例，假设我们有一个双插槽主板，其中每个插槽都有四核。就是说该系统中的
CPU 总数为 8，每个插槽有 4 个。每个插槽还附带 4GB 内存条，内存总数为
8GB。在这个示例中 CPU 0-3 在插槽 0 中，CPU 4-7 在插槽 1
中。这个示例中的每个插槽都对应一个 NUMA 代码。
:::
::: para
CPU 0 访问内存条 0
大约需要三个时钟周期：一个周期是将地址发给内存控制器，一个周期是设置对该内存位置的访问，一个周期是读取或者写入到该位置。但
CPU 4 可能需要 6
个时钟周期方可访问内存的同一位置，因为它位于不同的插槽，必须经过两个内存控制器：插槽
1 中的本地内存控制器和插槽 0
中的远程内存控制器。如果在那个位置出现竞争（即如果有一个以上 CPU
同时尝试访问同一位置），内存控制器需要对该内存进行随机且连续的访问，所以内存访问所需时间会较长。添加缓存一致性（保证本地
CPU 缓存包含同一内存位置的相同数据）会让此过程更为复杂。
:::
::: para
最新高端处理器，比如 Intel 的 Xeon 和 AMD 的 Opteron 都有 NUMA 拓扑。AMD
处理器使用我们所说的超传输（或称 HT）互联，而 Intel
使用名为快速路径（或称
QPI）的互联。根据其物理连接到其他互联、内存或者外设的情况该互联有所不同，但实际上他们就是可允许从另一台连接的设备对一个连接的设备进行透明访问的开关。在这种情况下，透明指的是使用该互联没有特别的编程
API 要求，而不是"零成本"选项。
:::
::: para
因为系统架构千变万化，因此具体指定由于访问非本地内存所致性能代偿是不切实节的。我们可以说每个跨互联的[*中继段*]{.emphasis}多少会产生一些相对恒定的性能代偿，因此参考距当前
CPU 两个互联的内存位置时至少会产生 [*2N +
内存周期时间*]{.emphasis}单位访问时间，其中 N 是每个中继段的代偿。
:::
::: para
有这个性能代偿后，对性能敏感的程序应避免常规访问 NUMA
拓扑系统中的远程内存。应将程序设定为使用特定的节点，并从那个节点为其分配内存。
:::
::: para
要做到这一点，需要了解程序的一些情况：
:::
::: {.orderedlist xmlns:d="http://docbook.org/ns/docbook"}
1.  ::: para
    系统使用什么[*拓扑*]{.emphasis}？
    :::
2.  ::: para
    该程序目前在哪里执行？
    :::
3.  ::: para
    最近的内存条在哪里？
    :::
:::
:::
::: section
::: titlepage
## [⁠]{#main-cpu.html#s-cpu-tuning}4.1.2. 调节 CPU 性能 {.title}
:::
::: para
阅读本小节了解如何调整出更好的 CPU
性能，本小节中还介绍了几个用于此目的的工具。
:::
::: para
NUMA 最初是用于将单一处理器连接到多个内存条中。因为 CPU
制造商改进了其工艺并缩小了芯片尺寸，因此可在一个包装中包括多个 CPU
核。这些 CPU
核以集群形式寻租以便每个核都有相同的访问本地内存条的时间，同时可在核之间共享缓存。但每个核、内存以及缓存中跨互联的'中继段'都有一个小的性能代偿。
:::
::: para
[图 4.1 "NUMA
拓扑中的本地和远程内存访问"](#main-cpu.html#numa-topology-example){.xref}
中的示例系统包括两个 NUMA 节点。每个节点有 4 个
CPU，一个内存条和一个内存控制器，节点中的任意 CPU
都可以直接访问那个节点中的内存条。根据节点 1 中的箭头指示执行步骤如下：
:::
::: {.orderedlist xmlns:d="http://docbook.org/ns/docbook"}
1.  ::: para
    CPU（0-3）给出到本地内存控制器的内存地址。
    :::
2.  ::: para
    内存控制器设置对内存地址的访问。
    :::
3.  ::: para
    CPU 在那个内存地址执行读取或者写入操作。
    :::
:::
::: figure
[⁠]{#main-cpu.html#numa-topology-example}
::: figure-contents
::: mediaobject
![The CPU icon used in this image is part of the Nuvola 1.0 (KDE 3.x
icon set), and is held under the LGPL-2.1:
http://www.gnu.org/licenses/lgpl-2.1.html](images/bz639780-multicore3.png)
:::
:::
**图 4.1. NUMA 拓扑中的本地和远程内存访问**
:::
::: para
但如果一个节点中的 CPU 需要访问不同 NUMA
节点的内存条中的代码，则它要使用的路径就不那么直接：
:::
::: {.orderedlist xmlns:d="http://docbook.org/ns/docbook"}
1.  ::: para
    CPU（0-3）给出到本地内存控制器的远程地址。
    :::
    ::: orderedlist
    1.  ::: para
        会将对那个远程内存地址的 CPU
        请求传递给远程内存控制器，到该节点的本地控制器包含那个内存地址。
        :::
    :::
2.  ::: para
    远程内存控制器设置对远程内存地址的访问。
    :::
3.  ::: para
    CPU 在那个远程内存地址执行读取或者写入操作。
    :::
:::
::: para
每个动作都需要通过多个内存控制器，这样访问在尝试访问远程内存地址时时间会延长两倍以上。因此多核系统中主要性能考量是保证以最有效的方式进行信息传递，即通过最短最迅速的路径。
:::
::: para