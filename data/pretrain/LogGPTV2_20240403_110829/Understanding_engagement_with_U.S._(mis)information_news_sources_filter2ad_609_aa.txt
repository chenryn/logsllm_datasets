title:Understanding engagement with U.S. (mis)information news sources
on Facebook
author:Laura Edelson and
Minh-Kha Nguyen and
Ian Goldstein and
Oana Goga and
Damon McCoy and
Tobias Lauinger
Understanding Engagement with U.S. (Mis)Information News
Sources on Facebook
Laura Edelson∗
New York University
New York, NY, USA
PI:EMAIL
Oana Goga
Université Grenoble Alpes, CNRS,
Inria, Grenoble INP, LIG
Grenoble, France
Minh-Kha Nguyen∗
Université Grenoble Alpes
Grenoble, France
Damon McCoy
New York University
New York, NY, USA
Ian Goldstein
New York University
New York, NY, USA
Tobias Lauinger
New York University
New York, NY, USA
ABSTRACT
Facebook has become an important platform for news publishers
to promote their work and engage with their readers. Some news
pages on Facebook have a reputation for consistently low factual-
ness in their reporting, and there is concern that Facebook allows
their misinformation to reach large audiences. To date, there is
remarkably little empirical data about how often users “like,” com-
ment and share content from news pages on Facebook, how user
engagement compares between sources that have a reputation for
misinformation and those that do not, and how the political lean-
ing of the source impacts the equation. In this work, we propose a
methodology to generate a list of news publishers’ official Facebook
pages annotated with their partisanship and (mis)information status
based on third-party evaluations, and collect engagement data for
the 7.5 M posts that 2,551 U.S. news publishers made on their pages
during the 2020 U.S. presidential election. We propose three metrics
to study engagement (1) across the Facebook news ecosystem, (2) be-
tween (mis)information providers and their audiences, and (3) with
individual pieces of content from (mis)information providers. Our
results show that misinformation news sources receive widespread
engagement on Facebook, accounting for 68.1 % of all engagement
with far-right news providers, followed by 37.7 % on the far left.
Individual posts from misinformation news providers receive con-
sistently higher median engagement than non-misinformation in
every partisanship group. While most prevalent on the far right,
misinformation appears to be an issue across the political spectrum.
CCS CONCEPTS
• Security and privacy → Social aspects of security and pri-
vacy; • Information systems → Social networks.
∗Laura Edelson and Minh-Kha Nguyen contributed equally to this work.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’21, November 2–4, 2021, Virtual Event
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9129-0/21/11...$15.00
https://doi.org/10.1145/3487552.3487859
KEYWORDS
Facebook, news, misinformation, engagement, measurement.
ACM Reference Format:
Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon Mc-
Coy, and Tobias Lauinger. 2021. Understanding Engagement with U.S.
(Mis)Information News Sources on Facebook. In ACM Internet Measure-
ment Conference (IMC ’21), November 2–4, 2021, Virtual Event. ACM, New
York, NY, USA, 20 pages. https://doi.org/10.1145/3487552.3487859
1 INTRODUCTION
After the 2016 U.S. presidential election, there was broad public
concern [3, 14] about the impact that online misinformation might
have had on public confidence in the fairness of the American
electoral system. In response to scrutiny from lawmakers and their
users, Facebook announced several initiatives [22, 23] aimed at
reducing misinformation on its platforms.
To date, there is little public data about how widespread the
misinformation problem on Facebook is. Prior work about mis-
information on digital platforms has focused either on mecha-
nisms of spread [13, 18, 21], or on absolute measurements of fake
news [15, 19]. With few notable exceptions [34], research has not
widely studied the interplay of misinformation and partisanship on
digital platforms.
In this work, we aim to shed light on user engagement within
the news ecosystem on Facebook. To the best of our knowledge,
we are the first to characterize engagement based on the political
leaning and factualness of news sources. We explore engagement
with (mis)information news from three different perspectives:
(1) What share of overall engagement with U.S. news sources is
taken up by misinformation providers?
(2) How well do individual sources of misinformation news en-
gage with their audiences, compared to more factual outlets?
(3) How well do users engage with content from misinformation
sources when compared to other news content?
A major challenge to studying these questions is data availability.
We need lists of news publishers with good coverage of the ecosys-
tem. We also need partisanship and factualness attributes for each
publisher, that is, their political leaning or bias, and whether the
source has a reputation for regularly spreading fake news, conspir-
acy theories, or misinformation. Our proposed methodology derives
these attributes from lists of U.S. news publishers acquired from
two third-party data providers, NewsGuard and Media Bias/Fact
444
IMC ’21, November 2–4, 2021, Virtual Event
Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon McCoy, and Tobias Lauinger
Check. We use Facebook’s CrowdTangle tool to collect 7.5 M public
posts and engagement metadata from 2,551 official Facebook pages
associated with those sources during the 2020 U.S. presidential
election, from August 10th, 2020 to January 11th, 2021.
To answer our three research questions, we propose three metrics
based on the data available through CrowdTangle: (1) total engage-
ment across the ecosystem, (2) per-page engagement normalized by
followers, and (3) per-post engagement, where engagement is the
number of comments, shares, and reactions such as “like.” Notably
absent from CrowdTangle is impression data. We explore video
views as an alternative, but show that is not a good substitute.
Our results shed light on several aspects of how misinformation
compares to non-misinformation in the Facebook news ecosystem.
In all partisan categories, misinformation sources are able to gen-
erate higher median per-post engagement, and this difference is
statistically significant in all cases. Overall, posts from misinforma-
tion sources out-engage those from non-misinformation sources by
a factor of six. However, in absolute terms, content from misinfor-
mation sources makes up a majority of engagement only for the Far
Right, 1.23 B interactions compared to 575 M, or 68.1 %, followed
by the Far Left with 37.7 % of engagement coming from misinfor-
mation sources. This engagement with misinformation is driven
by 109 pages (41.4 %) on the Far Right, and only 16 pages (8.6 %)
on the Far Left. (In all other partisan categories, the percentage of
misinformation pages is below 6.1 %.) When we compare how much
engagement pages generate relative to their number of followers,
the picture is mixed. Far Left, Slightly Right, and Far Right misinfor-
mation sources out-perform their non-misinformation counterparts,
while the reverse is true for Slightly Left and Center pages.
The primary implication of our findings is that it is not only Far
Right misinformation that is of concern on Facebook. Misinforma-
tion appears to confer a per-post engagement advantage no matter
the political leaning of the misinformation source. It is an important
question for future research to study why this is the case.
Our work makes the following contributions:
(1) We propose a methodology for harmonizing multiple news
source lists and news quality evaluations.
(2) We introduce metrics for measuring user engagement with
(mis)information from three perspectives, which can serve
in the future to measure changes in the news ecosystem and
evaluate countermeasures.
(3) We measure the relative scale and scope of misinformation
within the larger context of news on Facebook, and show
that it often outperforms non-misinformation.
2 BACKGROUND
Facebook has become an important channel where news publishers
promote their content. To do so, news outlets set up a Facebook
page where they can publish various types of posts. In the context
of news publishers, such posts most commonly link to articles on
the web, such as the publishers’ own websites (e.g., Figure 11b in
the appendix). Posts can also contain images (such as memes) or
prerecorded or live video (Figure 11c).
Even though users could visit these publishers’ Facebook pages
manually to read their content, they typically encounter the pages’
posts on their own timeline when Facebook’s algorithms deem
445
them interesting to the user. Among many signals that determine
whether a post will be selected are the user “following” a page, how
“engaging” the post has been so far for other users, and Facebook’s
prediction of how engaging the post will be to the specific user.
Thus, in order to reach a wider audience, Facebook pages need to
publish content that is engaging.
Facebook users can engage with content in a range of ways. Users
can react to a post by clicking the “like” button or one of various
alternatives such as “angry” or “sad.” Users can also share a post
with their friends, and they can write comments. We collectively
refer to all three types of engagement as interactions.
We consider misinformation to be information that is false or
misleading [20], regardless of the intent of the author or distributor
of the information. We consider misinformation to include disin-
formation [33], which refers to false or misleading content that is
communicated with the intent to deceive. False information com-
municated in error or by ignorance also falls under the umbrella of
misinformation. Misinformation can have a partisan focus, such as
right-leaning stories casting doubt on the legitimacy of the 2020 U.S.
election, but it also exists in left-leaning or apolitical/center circles,
such as misinformation related to environmental causes or the effi-
cacy of vaccines. Figure 10 in the appendix shows misinformation
examples across the political spectrum.
3 METHODOLOGY
To study differences in how users engage with (mis)information
providers on Facebook, we first obtain manually curated lists of
U.S. news publishers. These lists also rate the typical news quality
or factualness and political leaning of each publisher. We then
discover these news publishers’ official Facebook pages, and extract
all public posts along with metadata showing how many Facebook
users interacted with these posts.
3.1 News Publishers
We obtained lists of news sources from Media Bias/Fact Check
(MB/FC) [6] and NewsGuard (NG) [24] in July 2020. Those two in-
dependent data providers have also been used in prior work [29, 34].
NewsGuard create detailed trust ratings for news websites that they
refer to as “nutritional labels.” These evaluations are available only
to paying customers. Media Bias/Fact Check consider themselves
an independent online media outlet “dedicated to educating the
public on media bias and deceptive news practices.” While their
evaluations of news sources are slightly less comprehensive than
NewsGuard’s, they are publicly available. Both lists assign various
attributes to each news source; for the purposes of this study, we
use the partisanship and factualness labels. Partisanship is the po-
litical leaning, or bias of the news source. Factualness is whether
the source has a reputation of regularly spreading misinformation
or conspiracy theories. While these evaluations are qualitative and
inherently subjective, both data sources follow public methodolo-
gies [7, 25] in their labelling and have broadly similar criteria for
these two attributes.
We extracted these news source evaluations once at the end
of the study period and consider them to be static. In line with
prior work [2, 13, 15, 16, 29, 34], we are using classifications at the
level of news publishers instead of individually fact-checked news
Understanding Engagement with U.S. (Mis)Information News Sources on Facebook
IMC ’21, November 2–4, 2021, Virtual Event
articles. For the purposes of this study, we are most interested in
the behavior of news publishers, rather than individual pieces of
content. In the Facebook ecosystem, the reputation of news sources
is most relevant since users follow the pages of news publishers
and Facebook’s algorithms use these follower relationships as a
basis to show articles to users. Furthermore, this approach is more
scalable and broader than considering only fact-checked articles.
We conservatively apply the misinformation label only to news
publishers that have a reputation for repeatedly posting misinforma-
tion, and aim to capture all user engagement with this news source.
Fact checkers typically focus their attention on high-engagement
and verifiable content [10, 27], thus it is likely that not all posts
of misinformation providers would be fact checked, and the set
of fact-checked articles would not be a representative sample of
articles containing misinformation.
In total, NewsGuard had evaluations for 4,660 news sources, and
we were able to collect another 2,860 evaluations for news sources
from the Media Bias/Fact Check website. Not all of these news
sources were relevant for our study, and some list entries were
lacking partisanship or factualness attributes, thus we filtered and
merged the two lists as follows.
3.1.1 U.S. Publishers. Countries have very different political sys-
tems with a different political spectrum or partisan divide. There-
fore, we restrict our analysis to a single country and discard 1,047
non-U.S. news sources from NG, and 342 from MB/FC.
Facebook Page. Our analysis is based on user engagement
3.1.2
with posts on the publishers’ official Facebook pages. The News-
Guard data set contains the primary Facebook page for some sources,
but not all of them, and in some cases, multiple list entries share
the same Facebook page. The Media Bias/Fact Check data does
not contain any references to Facebook pages at all. We combined
duplicate list entries with the same Facebook page in NG, which
resulted in the removal of 584 entries. To fill in missing Facebook
page information, we queried Facebook for domain-verified Face-
book pages having a domain name matching the primary Internet
domain name of the news publisher from the list. We had to remove
883 entries from NG and 795 from MB/FC because we were unable
to find matching Facebook pages.
3.1.3 Political Leaning. To study engagement with (mis)information
providers based on their political leaning, we need partisanship at-
tributes for each news source. While NG considers all news sources
without partisanship information as center, we discarded 89 entries
in MB/FC because they had no partisanship data. (Most of them
were labelled as pro-science or conspiracy-pseudoscience.)
Both lists classify partisanship into different categories. We trans-
late them into a common categorization of Far Left, Slightly Left,
Center, Slightly Right, and Far Right as detailed in Table 1. In the 701
cases where we had both a NG and MB/FC evaluation, we gave pref-
erence to the latter. In these cases, the two lists only agreed 49.35 %
of the time. However, most of the differences were slight. Just over
34.24 % of cases disagreed between center and either slightly left
or slightly right, and 10.41 % between slightly left and far left, or
slightly right and far right. Overall, neither NG nor MB/FC appear
to have a significant left-ward or right-ward skew compared to the
other in terms of the distribution of their partisanship evaluations.
Combined
Far Left
Slightly Left
Center
Slightly Right
Far Right
NewsGuard
Far Left
Slightly Left
N/A
Slightly Right
Far Right
Media Bias/Fact Check
Left, Far Left, Extreme Left
Left-Center
Center
Right-Center
Right, Far Right, Extr. Right
Table 1: Mapping of partisanship labels of the two news pub-
lisher lists to our harmonized political leaning attribute.
NewsGuard has a bias toward the center of the distribution, rating
79.7 % of news sources as Center, compared with 34.11 % for MB/FC.
(Mis)Information. For this study, we require a boolean mis-
3.1.4
information flag for each news publisher, representing whether the
publisher has a history of spreading misinformation, fake news, or
conspiracy theories. Both NG and MB/FC use different terms to cap-
ture the spectrum of misleading or questionable news practices, but
at the far end of the spectrum, the terms “Conspiracy,” “Fake News,”
or “Misinformation” were used by both data providers. NewsGuard
describes this information in the “Topics” column of their data file,
while MB/FC reports questionable news practices in the “Detailed”
section of the source evaluation on their website. If any of the three
terms above is used to describe a news publisher, we apply the
misinformation label to the publisher. NewsGuard and MB/FC were
in broad agreement about this measure; we had an evaluation from
both lists for 679 publishers, including only 33 disagreements where
we broke the tie by applying the misinformation label.
3.1.5 Minimum Page Follower and Interaction Thresholds. To avoid
a skew in our results that might come from news publishers with
minimal posting activity or reach of their Facebook pages, we re-
move pages that never reached 100 followers during the study
period, a total of 15 pages from NG, and 19 from MB/FC. We also
remove pages that average fewer than 100 interactions per week,
another 187 pages from NG and 343 from MB/FC.
3.2 Coverage of Publishers
After all filtering steps, our final data set of news publisher Facebook
pages consists of 1,944 pages originating from NG, and 1,272 from
MB/FC, or 2,551 unique pages in total. The low overlap of only
665 pages is in line with prior work comparing (mis)information
publisher lists [5] (although their study did not include NG).
The overall partisan composition and list provenance of our
final news publisher data set is shown in Figure 1. The x axis of
the upper row shows that most of the publishers are classified as
center, followed by slightly left. In terms of which news publisher
list contributed a Facebook page to our combined data set, as shown
on the y axis, NG has higher coverage than MB/FC, including at
least half of publishers for each political leaning except for the far
right, where NG contained only 47.1 %. NewsGuard contributed
most of the unique center publishers, whereas MB/FC contributed
a higher share of unique pages in all non-center political leanings,
especially among the more extreme pages on the two far ends of
the spectrum. In relative terms, overlap between the two lists was
lowest in the center, and larger in the two left leaning groups than
in the two right leaning groups, whereas in absolute terms, it was
highest in the center due to the large number of center pages overall.
446
IMC ’21, November 2–4, 2021, Virtual Event
Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon McCoy, and Tobias Lauinger
to the CrowdTangle API documentation [31], this includes the
number of top-level comments below the post on the publisher’s
page (excluding responses to comments), the number of times the
original post was shared publicly by users, and the number of
reactions, such as likes. The numbers only include interactions with
the original post on the publisher’s Facebook page. They do not
include interactions when posts are shared beyond the publisher’s
page. The metadata also include the page’s number of followers at
the time the post was published, where followers are defined as the
number of users who have chosen to receive updates from a page.
The API contains engagement metrics at various time steps
after a post was published. In order to allow for a fair comparison
between posts, we use engagement numbers at a two-week delay
since posting. Since social media content tends to be short-lived, we
expect that posts will not accrue substantial additional engagement
beyond those two weeks. Due to scheduling issues during parts
of our data collection, we made API requests too early for nearly
1.4 % of all posts and have slightly less than two weeks worth of
engagement for those posts, varying from 7 to 13 days. Overall, our
data set contains 7,504,050 posts and associated metadata.
3.3.1 Video Posts. Unfortunately, CrowdTangle does not contain
any data about post impressions, that is, how often a post was
shown to users. CrowdTangle does contain view counts for video
posts, defined as users having watched at least 3 seconds of the
video [8]. We extracted video view counts from the CrowdTangle
web portal because they are not available through the API. This
video data collection took place on 8 February 2021. We were able
to retrieve view count data for 597,844 video posts, missing data of
46 k video posts (7.1 %; see Section 3.3.2 for an explanation). We also
excluded 291 posts for scheduled live video because these posts can-
not have accumulated any video views yet. We note that 415 pages
did not publish any video content, and 1,267 pages published video
only intermittently but not regularly; only 869 pages published
video every week.
We analyze the video data set separately from the overall posts
data set. While the video posts are a subset of the overall posts
and were published during the same date range, the web portal
shows only the latest view count and engagement metrics. Unlike
the overall posts data set where we can analyze engagement after
a two-week delay since post publication, the time delay between
video post publication and observation of the metrics varies from 3
to 25 weeks due to the separate data collection. For this reason, the
video data set is not fully comparable to the overall posts data set.
CrowdTangle reports video views separately for the original
post, crossposts, and shares of the same video. In order to allow for
a fair comparison to the post-based post engagement metrics, we
only consider views from the original post. Similarly, we exclude
from consideration posts of external (e.g., YouTube) video since it
could have been promoted through third-party channels that do
not impact the engagement numbers of the Facebook post.
Impact of CrowdTangle Bugs. After completing our initial
3.3.2
analysis of the data for this paper, we became aware of at least two
bugs in CrowdTangle that affect our work. First, before September
2021, the CrowdTangle API failed to return a subset of posts even
though they were available on Facebook. After Facebook fixed the
issue [30], we recollected the posts data (Section 3.3) and merged
Figure 1: Composition of the filtered data set by political
leaning (horizontal, colored), and origin publisher list (ver-
tical, hatched). In the middle and bottom rows, news pub-
lisher pages are weighted by total interactions and followers,
respectively. In relative terms, overlap between the two lists
is smallest in the center and larger in the extremes. Overlap
increases when pages weighted by interactions or followers.
Weighting pages by total interactions or followers, as shown in the
middle and bottom rows of the figure, increases the share of the
overlapping pages in the extremes and center, but decreases lightly
for slightly left and slightly right pages. Weighting also increases
the impact of NG-only pages, especially for slightly right pages,
and decreases the impact of MB/FC-only pages. This suggests that
NG covers publishers with a larger reach than MB/FC.
Out of the total 2,551 pages, a vast majority (2,315 pages) are clas-
sified as non-misinformation pages. The proportions between NG
and MB/FC-sourced pages stay roughly similar to the proportions
for all pages. One exception is the far right when pages are weighted
by interactions or followers; in this case, pages only found in the
MB/FC list make up a much larger share, while pages from NG and
the list overlap decrease their share. Regarding the 236 misinfor-
mation pages, MB/FC contributes no unique misinformation pages
with a slightly left or slightly right leaning, whereas more than half
of center misinformation pages are unique to MB/FC. However,
these MB/FC-only pages make up only a small share of the total
interactions or followers of center pages. Compared to the overall
page provenance distribution, misinformation pages sourced from
NG or the list overlap still account for a majority of interactions
or followers in each political leaning group, but MB/FC-only pages
in the far left account for a larger share, and in the far right for a