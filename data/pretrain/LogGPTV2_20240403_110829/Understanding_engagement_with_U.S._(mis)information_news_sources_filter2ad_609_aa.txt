# Understanding Engagement with U.S. (Mis)Information News Sources on Facebook

## Authors
- Laura Edelson, New York University, New York, NY, USA
- Minh-Kha Nguyen, Université Grenoble Alpes, Grenoble, France
- Ian Goldstein, New York University, New York, NY, USA
- Oana Goga, Université Grenoble Alpes, CNRS, Inria, Grenoble INP, LIG, Grenoble, France
- Damon McCoy, New York University, New York, NY, USA
- Tobias Lauinger, New York University, New York, NY, USA

## Abstract
Facebook has become a crucial platform for news publishers to promote their content and engage with readers. However, some news pages on Facebook are known for consistently low factual reporting, raising concerns about the spread of misinformation. Despite these concerns, there is limited empirical data on user engagement with news content, especially regarding the comparison between sources that disseminate misinformation and those that do not. This study proposes a methodology to generate a list of news publishers' official Facebook pages, annotated with their partisanship and (mis)information status based on third-party evaluations. We collected engagement data for 7.5 million posts made by 2,551 U.S. news publishers during the 2020 U.S. presidential election. We introduce three metrics to study engagement: (1) across the Facebook news ecosystem, (2) between (mis)information providers and their audiences, and (3) with individual pieces of content from (mis)information providers. Our results show that misinformation news sources receive widespread engagement, accounting for 68.1% of all engagement with far-right news providers and 37.7% with far-left news providers. Individual posts from misinformation news providers consistently receive higher median engagement than non-misinformation in every partisanship group, although the issue of misinformation is prevalent across the political spectrum.

## Keywords
Facebook, news, misinformation, engagement, measurement.

## ACM Reference Format
Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon McCoy, and Tobias Lauinger. 2021. Understanding Engagement with U.S. (Mis)Information News Sources on Facebook. In ACM Internet Measurement Conference (IMC '21), November 2–4, 2021, Virtual Event. ACM, New York, NY, USA, 20 pages. https://doi.org/10.1145/3487552.3487859

## 1. Introduction
Following the 2016 U.S. presidential election, there was significant public concern about the impact of online misinformation on public confidence in the electoral system. In response, Facebook announced several initiatives aimed at reducing misinformation on its platforms. However, there is still limited public data on the extent of the misinformation problem on Facebook. Previous research has focused on mechanisms of spread or absolute measurements of fake news, with few studies examining the interplay between misinformation and partisanship.

In this work, we aim to shed light on user engagement within the news ecosystem on Facebook. To our knowledge, we are the first to characterize engagement based on the political leaning and factualness of news sources. We explore engagement with (mis)information news from three perspectives:
1. What share of overall engagement with U.S. news sources is taken up by misinformation providers?
2. How well do individual sources of misinformation news engage with their audiences compared to more factual outlets?
3. How well do users engage with content from misinformation sources compared to other news content?

A major challenge in studying these questions is data availability. We need comprehensive lists of news publishers and attributes such as partisanship and factualness. Our methodology derives these attributes from lists of U.S. news publishers acquired from two third-party data providers, NewsGuard and Media Bias/Fact Check. We use Facebook’s CrowdTangle tool to collect 7.5 million public posts and engagement metadata from 2,551 official Facebook pages associated with those sources during the 2020 U.S. presidential election, from August 10, 2020, to January 11, 2021.

To answer our research questions, we propose three metrics based on the data available through CrowdTangle: (1) total engagement across the ecosystem, (2) per-page engagement normalized by followers, and (3) per-post engagement, where engagement is the number of comments, shares, and reactions such as "like." Notably, impression data is absent from CrowdTangle, so we explored video views as an alternative but found it to be an inadequate substitute.

Our results reveal several aspects of how misinformation compares to non-misinformation in the Facebook news ecosystem. In all partisan categories, misinformation sources generate higher median per-post engagement, and this difference is statistically significant. Overall, posts from misinformation sources out-engage those from non-misinformation sources by a factor of six. However, in absolute terms, content from misinformation sources makes up a majority of engagement only for the Far Right, with 68.1% of interactions, followed by the Far Left with 37.7% of engagement coming from misinformation sources. This engagement is driven by 109 pages (41.4%) on the Far Right and only 16 pages (8.6%) on the Far Left. In all other partisan categories, the percentage of misinformation pages is below 6.1%.

When comparing engagement relative to the number of followers, the picture is mixed. Far Left, Slightly Right, and Far Right misinformation sources out-perform their non-misinformation counterparts, while the reverse is true for Slightly Left and Center pages.

The primary implication of our findings is that it is not only Far Right misinformation that is of concern on Facebook. Misinformation appears to confer a per-post engagement advantage regardless of the political leaning of the source. Future research should investigate why this is the case.

Our work makes the following contributions:
1. A methodology for harmonizing multiple news source lists and news quality evaluations.
2. Metrics for measuring user engagement with (mis)information from three perspectives, which can serve to measure changes in the news ecosystem and evaluate countermeasures.
3. Measurement of the relative scale and scope of misinformation within the larger context of news on Facebook, showing that it often outperforms non-misinformation.

## 2. Background
Facebook has become a key channel for news publishers to promote their content. News outlets set up Facebook pages where they can publish various types of posts, including links to articles, images, and videos. Users typically encounter these posts on their timelines when Facebook's algorithms deem them interesting. To reach a wider audience, Facebook pages need to publish engaging content.

Users can engage with content by reacting (e.g., liking, angry, sad), sharing, or commenting. We consider misinformation to be false or misleading information, regardless of the intent of the author or distributor. Misinformation includes disinformation, which is false or misleading content communicated with the intent to deceive. Misinformation can have a partisan focus, such as right-leaning stories casting doubt on the legitimacy of the 2020 U.S. election, but it also exists in left-leaning or apolitical/center circles, such as misinformation related to environmental causes or vaccine efficacy.

## 3. Methodology
To study differences in how users engage with (mis)information providers on Facebook, we first obtain manually curated lists of U.S. news publishers. These lists rate the typical news quality or factualness and political leaning of each publisher. We then discover these news publishers' official Facebook pages and extract all public posts along with metadata showing user interactions.

### 3.1. News Publishers
We obtained lists of news sources from Media Bias/Fact Check (MB/FC) and NewsGuard (NG) in July 2020. Both independent data providers have been used in prior research. NewsGuard creates detailed trust ratings for news websites, while MB/FC provides publicly available evaluations. Both lists assign partisanship and factualness labels to each news source. Partisanship is the political leaning of the news source, and factualness indicates whether the source has a reputation for regularly spreading misinformation or conspiracy theories.

We extracted these news source evaluations once at the end of the study period and considered them static. We are using classifications at the level of news publishers rather than individually fact-checked articles. This approach is more scalable and relevant in the Facebook ecosystem, where the reputation of news sources is most important since users follow the pages of news publishers, and Facebook's algorithms use these follower relationships to show articles to users.

In total, NewsGuard had evaluations for 4,660 news sources, and we collected another 2,860 evaluations from MB/FC. We filtered and merged the two lists as follows:

#### 3.1.1. U.S. Publishers
We restricted our analysis to U.S. news sources, discarding 1,047 non-U.S. news sources from NG and 342 from MB/FC.

#### 3.1.2. Facebook Page
Our analysis is based on user engagement with posts on the publishers' official Facebook pages. The NewsGuard dataset contains the primary Facebook page for some sources, but not all. We combined duplicate list entries with the same Facebook page, resulting in the removal of 584 entries. To fill in missing Facebook page information, we queried Facebook for domain-verified pages matching the primary Internet domain name of the news publisher. We removed 883 entries from NG and 795 from MB/FC because we were unable to find matching Facebook pages.

#### 3.1.3. Political Leaning
To study engagement with (mis)information providers based on their political leaning, we need partisanship attributes for each news source. While NG considers all news sources without partisanship information as center, we discarded 89 entries in MB/FC because they had no partisanship data. Both lists classify partisanship into different categories, which we translated into a common categorization of Far Left, Slightly Left, Center, Slightly Right, and Far Right. In the 701 cases where we had both NG and MB/FC evaluations, we gave preference to MB/FC. The two lists agreed 49.35% of the time, with most differences being slight.

#### 3.1.4. (Mis)Information
For this study, we require a boolean misinformation flag for each news publisher, representing whether the publisher has a history of spreading misinformation, fake news, or conspiracy theories. Both NG and MB/FC use different terms to capture the spectrum of misleading or questionable news practices, but at the far end of the spectrum, the terms "Conspiracy," "Fake News," or "Misinformation" were used by both. If any of these terms describe a news publisher, we apply the misinformation label. NG and MB/FC were in broad agreement, with only 33 disagreements among 679 publishers, where we broke the tie by applying the misinformation label.

#### 3.1.5. Minimum Page Follower and Interaction Thresholds
To avoid skewing our results due to news publishers with minimal posting activity or reach, we removed pages that never reached 100 followers during the study period and pages that averaged fewer than 100 interactions per week.

### 3.2. Coverage of Publishers
After filtering, our final dataset consists of 1,944 pages from NG and 1,272 from MB/FC, totaling 2,551 unique pages. The low overlap of only 665 pages is consistent with prior work. The overall partisan composition and list provenance of our final news publisher dataset are shown in Figure 1.

### 3.3. Data Collection
We used Facebook’s CrowdTangle tool to collect 7.5 million public posts and associated metadata from 2,551 official Facebook pages during the 2020 U.S. presidential election. According to the CrowdTangle API documentation, this includes the number of top-level comments, shares, and reactions. The metadata also include the page’s number of followers at the time the post was published.

We used engagement numbers at a two-week delay since posting, as social media content tends to be short-lived. Due to scheduling issues, we made API requests too early for nearly 1.4% of all posts, resulting in slightly less than two weeks of engagement data for those posts.

#### 3.3.1. Video Posts
CrowdTangle does not contain data about post impressions but includes view counts for video posts. We extracted view counts from the CrowdTangle web portal, retrieving data for 597,844 video posts. We excluded 291 posts for scheduled live video and noted that 415 pages did not publish any video content, and 1,267 pages published video intermittently. Only 869 pages published video every week.

We analyzed the video data set separately from the overall posts data set. Unlike the overall posts data set, the time delay between video post publication and observation of the metrics varies from 3 to 25 weeks. For a fair comparison, we only considered views from the original post and excluded posts of external videos.

#### 3.3.2. Impact of CrowdTangle Bugs
After completing our initial analysis, we became aware of bugs in CrowdTangle that affected our work. Before September 2021, the CrowdTangle API failed to return a subset of posts even though they were available on Facebook. After Facebook fixed the issue, we recollected the posts data and merged it with our existing dataset.

## 4. Results
Out of the total 2,551 pages, 2,315 pages are classified as non-misinformation pages. The proportions between NG and MB/FC-sourced pages remain similar to the proportions for all pages. One exception is the far right when pages are weighted by interactions or followers; in this case, pages only found in the MB/FC list make up a much larger share, while pages from NG and the list overlap decrease their share. Regarding the 236 misinformation pages, MB/FC contributes no unique misinformation pages with a slightly left or slightly right leaning, whereas more than half of center misinformation pages are unique to MB/FC. However, these MB/FC-only pages make up only a small share of the total interactions or followers of center pages. Compared to the overall page provenance distribution, misinformation pages sourced from NG or the list overlap still account for a majority of interactions or followers in each political leaning group, but MB/FC-only pages in the far left account for a larger share, and in the far right for a smaller share.