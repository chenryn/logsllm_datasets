digital signature schemes. Backward links are hashes en-
suring the immutability of the past with respect to any
valid release. An attacker can propose a release record
with incorrect back-links, but cannot produce a valid col-
lective signature on such a record without compromising a
threshold of witnesses, as honest witnesses verify the con-
sistency of new records against their view of history be-
fore cosigning. An attacker can attempt to create two dis-
tinct successors to the same prior release (a fork), but any
honest witness will cosign at most one of these branches.
If the cothority is conﬁgured with a two-thirds superma-
jority witness-threshold (tw (cid:21) 2nw + 1), forks are pre-
vented by the BFT-CoSi consensus mechanism.
Forward links are signatures that can be created only
once the (future) target blocks have been appended to
the skipchain. This requires that witnesses store the sign-
1280    26th USENIX Security Symposium
USENIX Association
ing keys associated with a given block, until all forward
links from that block onwards are generated. This longer
key-storage, gives the attacker more time to compromise
a threshold of keys. To mitigate this threat, we impose
an expiration date on signing keys (e.g., one year), after
which honest witnesses delete outdated keys uncondition-
ally, thereby imposing an effective distance limit on for-
ward links. Note that the key expiration-time should be
sufﬁciently long so that the direct forward links are al-
ways created to ensure secure trust delegation.
In summary, to manipulate the update timeline man-
aged by the update cothority, an attacker needs to com-
promise at least a threshold of tw witness servers. Note
that one purpose of the update timeline in CHAINIAC is to
ensure accountability so that even if the attacker manages
to slip a backdoor into a release, the corresponding source
code stays irrevocably available, enabling public scrutiny.
Update center. An adversary might also compromise
the software-update center to disseminate malicious bi-
naries, to mount freeze attacks that prevent clients from
updating, or to replay old packages with known security
vulnerabilities and force clients to downgrade.
Clients can detect that they have received a tampered
binary by verifying the associated signature using the pub-
lic key of the update cothority; the key can be retrieved se-
curely through CHAINIAC’s update timeline. The clients
will also never downgrade, as they only install packages
that are cryptographically linked to the currently installed
version through the release skipchain. Finally, assuming
the clients have a correct internal clock, they can detect
freeze and replay attacks by verifying timestamps and
package signatures, because an attacker cannot forge col-
lective signatures of the update cothority to create valid-
looking TIME blocks (see Section 5.6).
7 Prototype Implementation
We implemented CHAINIAC in Go [31] and made it pub-
licly available4, along with the instructions on how to re-
produce the evaluation experiments. We built on exist-
ing open-source code implementing CoSi [69] and BFT-
CoSi [42]. The new code implementing the CHAINIAC
prototype was about 1:8kLOC, whereas skipchains, net-
work communication, and BFT-CoSi were 1:2k, 1:5k, and
1:8k lines of code (LOC), respectively. Although the im-
plementation is not yet production quality, it is practical
and usable for experimental purposes.
We rely on Git for source-code control and use Git-
notes [30], tweaked with server hooks to be append-only,
for collecting developer approvals in the form of PGP
4https://github.com/dedis/paper_chainiac
signatures. For the build veriﬁers, we use Python to ex-
tract the information about the building environment of
the packages, and Docker [26] to reproduce it.
8 Experimental Evaluation
In this section, we experimentally evaluate our CHAINIAC
prototype. The main question we answer is whether
CHAINIAC is usable in practice without incurring large
overheads. We begin by measuring the cost of repro-
ducible builds using Debian packages as an example, and
we continue with the cost of witnesses who maintain an
update-timeline skipchain and the overhead of securing
multi-package projects.
8.1 Experimental Methodology
In the experiments of Sections 8.2, 8.3 and 8.4, we used
24-core Intel Xeons at 2.5 GHz with 256 GB of RAM and,
where applicable, ran up to 128 nodes on one server with
the network-delay set between any two nodes to 100ms
with the help of Mininet [54]. Because we had not yet
implemented a graceful handling of failing docker-builds,
we measured building time in a small grid of 4 nodes and
extrapolated this time to the bigger grids in Figure 6. In
Section 8.5, we simulated four collectively signing servers
on a computer with a 3.1 GHz Intel Core i7 processor and
16 GB of RAM and did not include any network-latencies,
as we measured only CPU-time and bandwidth.
To evaluate the witness cost of the long-term mainte-
nance of an update timeline, we used data from the De-
bian reproducible builds project [22] and the Debian snap-
shot archive [19]. The former provides checksums and de-
pendency information for reproducible packages. Unfor-
tunately, the information was not available for older pack-
age versions, therefore we always veriﬁed each package
against its newest version. We used the latter as an update
history to estimate average cost over time for maintaining
an individual update timeline and the overhead of running
an aggregate multi-package service. In Section 8.4, we
used real-life data from the PyPI package repository [17].
The data represented snapshots of the repository of about
58,000 packages. There were 11,000 snapshots over a pe-
riod of 30 days. Additionally, we had 1.5 million update-
requests from 400,000 clients during the same 30-day pe-
riod. Using this data, we implemented a simulation in
Ruby to compare different bandwidth usages.
8.2 Reproducing Debian Packages
To explore the feasibility of build transparency and to es-
timate the cost of it for witnesses, we ran an experiment
on automatic build reproducing. Using Docker contain-
ers, we generated a reproducible build environment for
USENIX Association
26th USENIX Security Symposium    1281
each package, measured the CPU time required to build
a binary and veriﬁed the obtained hash against a pre-
calculated hash from Debian.
We tested three sets of packages: (1) required is the set
of Debian required packages [21], 27 packages as of to-
day; (2) popular contains the 50 most installed Debian
packages [20] that are reproducible and do not appear in
required; (3) random is a set of 50 packages randomly
chosen from the full reproducible testing set [22]. Figure 5
demonstrates a CDF of the build time for each set.
10 packages from the random set, 8 from required and
2 from popular produced a hash value different from the
corresponding advertised hash. 90% of packages from
both the random and required sets were built in less than
three minutes, whereas the packages in the required-set
have a higher deviation. This is expected as, to ensure De-
bian’s correct functioning, the required packages tend to
be more security critical and complex.
Figure 6: CPU cost of adding a new block to a timeline
Figure 7: Communication cost for different frameworks
Figure 5: Reproducible build latency for Debian packages
8.3 End-to-End Witness Cost
In this experiment, we measured the cost for a witness of
adding a new release to an update timeline. We took a set
of six packages, measured the cost for each one individ-
ually and then calculated the average values over all the
packages. The build time was measured once and copied
to the other runs of the experiment, which enabled us to
test different conﬁgurations quickly and to break out re-
sults for each operation. The operations included veri-
fying developers’ signatures, reproducible builds, signing
off on the new release and generating a timestamp. The
witness cost was measured for an update cothorities com-
posed of 7, 31, and 127 nodes.
Figure 6 plots the costs in both CPU time and wall-
clock time used. The CPU time is higher than wall-clock
time for some metrics, due to the use of a multi-core pro-
cessor. The veriﬁcation and build times are constant per
node, whereas the time to sign and to generate the times-
tamp increases with the number of nodes, mostly due to
higher communication latency in a larger cothority tree.
As expected, the build time dominates the creation of
a new skipblock. Every witness spends between 5 and 30
CPU-minutes for each package. Current hosting schemes
offer simple servers for 10-US$ per month, enough to run
a node doing reproducible builds for the Debian-security
repository (about eight packages per day).
8.4 Skipchain Effect on PyPI Communica-
tion Cost
To evaluate the effect on communication cost of using
skipchains for update veriﬁcation, we compare it with two
other scenarios using data from the PyPI package reposi-
tory. The scenarios are as follows:
1. Linear update: When a client requests an update,
she downloads all the diffs between snapshots, starting
1282    26th USENIX Security Symposium
USENIX Association
12345678910Time (minutes)0102030405060708090100% of Packages BuiltAptitude: 13'Perl: 28'Debian package setsRequired (27)Random (50)Popular (50)315127Number of nodes10-310-210-1100101102103104105Time spent on each node per package (sec)Wall-total over all nodesCPU / WallDev-signature verificationCreating timestampCollective signingReproducible build1.010.0Time since start (days)100101102103104105106Consumed Bandwidth (MBytes)Linear updateDiplomat updateSkipchain S11 updateSkipchain S11Skipchain S75Skipchain S411Figure 8: CPU time on server for repository-update
Figure 9: Communication cost to get new repository state
from her last update to the most recent one. This way
she validates every step.
2. Diplomat: The client only downloads the diff between
her last update and the latest update available.
3. Skipchain S1
1: The scenario is as in Diplomat, but ev-
ery skipblock is also sent to prove the correctness of the
current update. The skipchains add security to the snap-
shots by signing it and by enabling users to efﬁciently
track changes in the signers.
The results over the 30-day data are presented in Fig-
ure 7. The straight lines correspond to the aforemen-
tioned scenarios. Linear updates increase the communi-
cation cost, because the cumulative updates between two
snapshots can contain different updates, which are only
transferred once, of the same package, as in the case of
Diplomat or skipchains. As it can be seen, the communi-
cation costs for Diplomat and skipchain are similar, even
in the worst case where a skipchain has height-1 only,
which corresponds to a simple double-linked list.
To further
investigate the best parameters of
the
skipchain, we plotted only the skipchain overhead using
the same data. In Figure 7, the dashed lines show the addi-
tional communication cost for different skipchain param-
eters. We observe that a skipchain with height > 1 can
reduce by a factor of 15 the communication cost for prov-
ing the validity of a snapshot. Using the base 5 for the
skipchain can further reduce the communication cost by
another factor of 2.
8.5 Cost of Securing Debian Distribution
In our ﬁnal experiment, we measured the cost of a wit-
ness server that deploys an aggregate-layer skipchain in a
multi-package project (Section 5.7) and a client who uses
it. . We took the list of all the packages from the snap-
shot archive of the Debian-testing repository and created
one skipchain per package over 1.5-year history, such that
each skipblock is one snapshot every ﬁve days. We then
formed the aggregate Debian-testing skipchain over the
same period.
In the ﬁrst experiment, a witness server receives a new
repository-state to validate, veriﬁes the signature for all
the packages, builds a Merkle tree from the heads of
the individual skipchains and signs its root, thus creating
a new aggregate skipblock. Figure 8 depicts the average
costs of the operations, over the whole history, against the
size of the repository. For a full repository of 52k pack-
ages, which corresponds to the actual Debian-testing sys-
tem, the overall CPU-cost is about 20 seconds per release.
This signiﬁes that CHAINIAC generates negligible over-
head on the servers that update a skipchain.
The second experiment evaluates the overhead that
CHAINIAC introduces to the client-side cost of download-
ing the latest update of all packages. In order to maintain
the security guarantees of CHAINIAC, the client down-
loads all package hashes and builds a full Merkle tree to
verify them, thereby not revealing packages of interest and
preserving her privacy. Figure 9 illustrates that CHAINIAC
introduces a constant overhead of 16% to the APT man-
ager. This modest overhead suggests CHAINIAC’s good
scalability and applicability.
9 Related Work
We organize the discussion topically and avoid redun-
dancy with the commentary in Section 2.
Software-update protection. The automatic detection
and installation of software updates is a common op-
eration in computer and mobile systems, and there are
many tools for this task, such as package- and library-
managers [18, 23, 33, 76], and various app stores. There
are several security studies [10, 15, 57] that reveal weak-
USENIX Association
26th USENIX Security Symposium    1283
1010010001000052000Number of packages in repository10-510-410-310-210-1100101102103104CPU time (seconds)Total for new snapshotMerkle tree buildingTree-root signingPackages signature-verification100316100031621000031623Total number of packages in repository0.010.101.0010.00Communication cost (MBytes)Apt-get updateApt-get update + Chainiacnesses in the design of software-update systems, and dif-
ferent solutions are proposed to address these weaknesses.
Solutions that reduce the trust that end users must have
in developers by involving independent intermediaries in
testing are shown [3, 4] to be beneﬁcial in open-source
projects and content repositories. Several systems, such
as Meteor [7], DroidRanger [77] and ThinAV [37], focus
on protecting the infrastructure for mobile applications
and on detecting malware in mobile markets. Other sys-
tems [38, 47, 58] use overlay and peer-to-peer networks
for efﬁcient dissemination of security patches, whereas
Updaticator [5] enables efﬁcient update distribution over
untrusted cache-enabled networks.
Certiﬁcate, key, and software transparency. Bring-
ing transparency to different security-critical domains has
been actively studied. Solutions for public-key validation
infrastructure are proposed in AKI [40], ARPKI [9] and
Certiﬁcate Transparency (CT) [45] in which all issued
public-key certiﬁcates are publicly logged and validated
by auditors. Public logs are also used in Keybase [39],
which enables users to manage their online accounts and
provides checking of name-to-key bindings by verifying
ownership of third-party accounts. This is achieved via
creating a public log of identity information that third-
parties can audit. EthIKS [12] provides stronger auditabil-
ity to CONIKS [51], an end-user key veriﬁcation service
based on a veriﬁable transparency log, by creating a Smart
Ethereum Contract [75] that guarantees that a hash chain
is not forked, as long as the ethereum system is stable
and correct. Application Transparency (AT) [27] employs
the idea of submitting information about mobile applica-
tions to a veriﬁable public log. Thus, users can verify that
a provided app is publicly available to everyone or that
a given version existed in the market, but was removed.
However, AT can protect only against targeted attacks but
leaves attacks against all the users outside of its scope. Fi-
nally, Baton [8] tries to address the problem of renewing
signing keys in Android by chaining them but this solution
does not help in the case of stolen signing keys.
Blockchains. The creation of Bitcoin [56] was ﬁrst per-
ceived as an evolution in the domain of ﬁnancial tech-
nology. Recently, however, there has been an increasing
interest in the data structure that enables the properties
of bitcoin, namely, the blockchain. There is active work
with blockchain in cryptocurrencies [13, 65], DNS alter-
natives [74] and even general-purpose decentralized com-
puting [75]. All of these systems secure clients in a dis-
tributed manner and with a timeline that can be tracked
by the clients. However, these systems force the clients
to track the full timeline, even if the clients are interested
in a very small subset of it, or to forfeit the security of
decentralization by trusting a full node.
10 Conclusion
In this work, we have presented CHAINIAC, a novel
software-update framework that decentralizes each step
of the software-update process to increase trustworthi-
ness and to eliminate single points of failure. The key
novel components of CHAINIAC’s design are multi-level
skipchains and veriﬁed builds. The distinct layers of
skipchains provide, while introducing minimal overhead
for the client, multiple functionalities such as (1) tamper-
evident and equivocation-resistant logging of the new up-
dates and (2) the secure evolution of signing keys for both
developers and the set of online witnesses. Veriﬁed builds
further unburden clients by delegating the actual repro-
ducible building process to a decentralized set of build
veriﬁers. The evaluation of our prototype has demon-
strated that the overhead of using CHAINIAC is accept-
able, both for the clients and for the decentralized group