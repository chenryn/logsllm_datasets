packages 567. Each of these selected repositories has more than two
authors and has a substantial amount of current users.
We used CodeQL 8, which is an open-source tool distributed and
maintained by GitHub. We checked out each commit in a given
repository and ran CodeQL. For each of these commits, we used
GitHub API 9 to extract commit metadata such as commit hash,
committed date, commit author’s name, commit author’s GitHub
username, and email. The static code analysis produces all the issues
that CodeQL has identified by analyzing each commit.
4https://cwe.mitre.org/
5https://www.npmjs.com/browse/depended
6https://gist.github.com/anvaka/8e8fa57c7ee1350e3491
7http://bit.ly/hackernoon-36
8https://securitylab.github.com/tools/codeql
9https://docs.github.com/en/rest
For our study, we define Intro Commit as the commit CodeQL
identifies a vulnerability for the first time in the code (a unique
combination of code file and line number). We define Fix Commit as
the commit responsible for fixing a given vulnerability. We define
Intro+Fix Commits an a commit that introduced a vulnerability
while fixing one. In Figure 1, since commit C1 ends the lifetime of
the vulnerability V1, C1 is the Fix commit for V1. C2 starts the V2’s
lifetime hence it is the Intro commit for V2. Since C3 is ending V3’s
lifetime as well as starting V4’s lifetime, C3 becomes a Intro+Fix
commit. Figure 1 depicts the above explained scenario.
Figure 1: A timeline graph representing Intro, Fix and In-
tro+Fix Commits
4 PRELIMINARY ANALYSIS
Our pipeline has discovered 80 unique security vulnerability types
among those 501K commits (from 130 JS projects). There were,
on average, 170 instances of security vulnerabilities found in each
project. The main focus of our study is to highlight the impor-
tance of source code analysis for understanding the effectiveness
of vulnerability remediation.
Prior research Alomar et al. found that many industry experts
are concerned about the lack of success in fixing bugs due to various
reasons such as lack of expertise, proper attention, and allocated
resources. To quantify issues in remediation, we used our novel
automated pipeline to filter commits that have fixed a vulnerability
and understand their success. Our analysis only counts the final
attempt that fixed the vulnerability, ignoring prior unsuccessful (or
half-successful) attempts. Hence the numbers we present could be
a lower bound of the issues we raise.
We found that in certain projects, as much as 7.15% of developers
are responsible for intro+fix commits introducing more vulnerabil-
ities. Out of all the intro+fix commits 54% of the time, the intro
commit and intro+fix commit that was supposed to fix the origi-
nal vulnerability were committed by the same developer. Among
the developers responsible for intro+fix commits, 7% of them have
committed to multiple repositories.
We compared the published data of CWEs and the vulnerability
introduction date. We found that 78% of the time, developers have
committed a publicly disclosed vulnerability to the code. We also
observed that, on average, projects have repeated 75% of vulner-
abilities. In addition, 2% of all intro+fix vulnerabilities discovered
showed that fixing an existing vulnerability introduced at least one
OWASP Top 10 vulnerabilities. We also found that 37% of the time,
developers committed a vulnerability fix while there were other
high severity vulnerabilities in the code. All of these could highlight
Session 8: Poster & Demo Session CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2448issues in organizational vulnerability management processes which
requires a separate study to understand the reasons.
5 VISUALIZING VULNERABILITY
DISTRIBUTION
The impact of the vulnerabilities will differ depending on the phase
where it is identified. The closer the identification is to the devel-
opment phase, the lower the cost of vulnerability remediation will
be. Due to the finite resources, developers cannot fix all the vul-
nerabilities identified in the code. To address this issue, we need
to identify which vulnerabilities need to be prioritized for fixing.
We developed a prioritization score that incorporates four different
metrics to give an overall score assigned to each vulnerable file.
Severity Score, Each detected vulnerability has a severity score
based on OWASP Top 10 list10.
Sibling Score, We also wanted to measure the density of vulnera-
bilities to figure out whether vulnerabilities are grouped within a
class or a method: higher density requires higher prioritization.
Intro+Fix Score, If new vulnerabilities are introduced upon fixing
existing vulnerabilities, it shows that the remediation process has
failed. To denote this, we give a score to each file that includes
Intro+Fix vulnerabilities.
Lifetime Score, Certain vulnerabilities remain in the code for a
long time without fixing. To measure this, we calculate the age of
the vulnerability that existed in the code in days and assigned a
higher score to the longest existing vulnerability.
We present our tool Sequza to aid developers in prioritizing the
vulnerabilities identified in the code. Sequza provides a visualiza-
tion metric where the developers and other stakeholders can view
the security posture of the project and view which files contain
vulnerabilities, and it helps in prioritizing which vulnerability to fix
at the earliest. This will help organizations to utilize the limited re-
sources in a meaningful manner. Sequza is comprised of (1) Sequza
Core, (2) Sequza API, (3) Sequza RQD, and (4) Sequza Dashboard.
Sequza Core handles all the analysis tasks and stores the results.
Sequza API provides access to analysis results. Sequza RQD is the
central dashboard where the Sequza Core instances are managed.
Sequza Dashboard is the user interface where a user can submit a
repository and obtain the results.
Figure 2 shows how the vulnerabilities are distributed among
the files in the repository. Upon hovering over the file names, the
users can view the prioritization score of the vulnerable files. The
intensity of the red color of each file is depended on the prioritiza-
tion score. The users can also view the identified vulnerabilities in
each file and utilize the side-by-side comparison for two commits.
Sequza provides the full breakdown view of the prioritization scores
in each file as illustrated in Figure 3.
6 DISCUSSION
We aim to understand the feasibility of using source code analysis to
answer the issues in remediation. Based on our preliminary results,
we show that issues in vulnerability remediation can be quantified.
In our study we present a novel automated analysis pipeline to iden-
tify Intro commits, Fix commits, and Intro+Fix commits. By utilizing
these, we can understand the issues in the vulnerability remediation
10https://owasp.org/www-project-top-ten/
Figure 2: Visualizing vulnerability distribution in Sequza
Figure 3: Prioritization score breakdown in Sequza
process. Combining this with our tool Sequza, we believe this can be
used to explore new research avenues in vulnerability remediation,
and it will help the organizations to be better at remediation and
prioritization. We have opened our analysis to the public through a
real-time dashboard11.
REFERENCES
[1] Noura Alomar, Primal Wijesekera, Edward Qiu, and Serge Egelman. 2020. "You’ve
Got Your Nice List of Bugs, Now What?" Vulnerability Discovery and Management
Processes in the Wild. In Sixteenth Symposium on Usable Privacy and Security
(SOUPS 2020). USENIX Association, 319–339. https://www.usenix.org/conference/
soups2020/presentation/alomar
[2] Vinuri Bandara, Thisura Rathnayake, Nipuna Weerasekara, Charitha Elvitigala,
Kenneth Thilakarathna, Primal Wijesekera, and Chamath Keppitiyagama. 2020.
Fix that Fix Commit: A real-world remediation analysis of JavaScript projects.
In 2020 IEEE 20th International Working Conference on Source Code Analysis and
Manipulation (SCAM). IEEE, 198–202.
[3] Stefan Frei, Martin May, Ulrich Fiedler, and Bernhard Plattner. 2006. Large-Scale
Vulnerability Analysis. In Proceedings of the 2006 SIGCOMM Workshop on Large-
Scale Attack Defense (Pisa, Italy) (LSAD ’06). Association for Computing Machinery,
New York, NY, USA, 131–138. https://doi.org/10.1145/1162666.1162671
[4] Kevin Hogan, Noel Warford, Robert Morrison, David Miller, Sean Malone, and
James Purtilo. 2019. The Challenges of Labeling Vulnerability-Contributing Com-
mits. In 2019 IEEE International Symposium on Software Reliability Engineering
Workshops (ISSREW). IEEE, 270–275.
[5] Frank Li and Vern Paxson. 2017. A large-scale empirical study of security patches.
In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communica-
tions Security. 2201–2215.
[6] Henning Perl, Sergej Dechand, Matthew Smith, Daniel Arp, Fabian Yamaguchi,
Konrad Rieck, Sascha Fahl, and Yasemin Acar. 2015. Vccfinder: Finding potential
vulnerabilities in open-source projects to assist code audits. In Proceedings of the
22nd ACM SIGSAC Conference on Computer and Communications Security. 426–437.
11https://sequza.io
Session 8: Poster & Demo Session CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2449