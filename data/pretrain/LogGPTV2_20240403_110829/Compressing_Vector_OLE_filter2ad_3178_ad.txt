coordinates, multiplication by a constant, summing two coordinates). A better heuristic
procedure (which achieves a better randomization with fewer steps) can be obtained
using a mixing strategy based on expander graphs, such as the approach developped
by Spielman in [Spi96].
4 MPFSS Constructions
An (n, t)-MPFSS for a multi-point function fS,y : [n] → G can be readily constructed using
t invocations to a DPF over G:
– MPFSS.Gen(1λ, fS,y): denoting s1,··· , st (an arbitrary ordering of) the elements of
S, for any i ≤ t, compute (Ki
R← DPF.Gen(1λ, fsi,yi), where fsi,yi is the point
function over G which evaluates to yi on si and to 0 otherwise. Output (K0, K1) ←
((Ki
0, Ki
1)
– MPFSS.Eval(σ, Kσ, x): parse Kσ as (Ki
σ, x).
As with DPF, we can enhance an MPFSS with a full domain evaluation algorithm
MPFSS.FullEval which, on input (σ, Kσ), outputs the vector (MPFSS.Eval(σ, Kσ, x))x∈[n].
Plugging the construction of Theorem 2 leads to an (n, t)-MPFSS with key size t ·
((cid:100)log n(cid:101)(λ + 2) + log2 |G|), where the computational cost of the evaluation algorithm is
dominated by t group operations and t(cid:100)log n(cid:101) evaluations of a PRG, and the cost of a full
domain evaluation is dominated by tn group operations and evaluations of a PRG.
i=1 DPF.Eval(σ, Ki
σ)i≤t and compute zσ ←(cid:80)t
0)i≤t, (Ki
1)i≤t).
4.1 Optimizing MPFSS Evaluation
The above simple reduction means that in MPFSS.FullEval the parties must make t passes
over the entire domain [n] for privately “writing” t entries (corresponding to the noisy co-
ordinates) in a shared size-n vector. Below, we show how to improve this asymptotically,
to writing a batch of t coordinates making a constant number of passes on the data. We
discuss two alternatives: a concretely eﬃcient approach which relies on a stronger (yet
well-established) assumption than LPN, namely, the regular syndrome decoding assump-
tion, and an asymptotically eﬃcient approach using batch codes [IKOS04] which relies
directly on LPN. Intuitively, the idea for the second approach is the following: evaluating
MPFSS.FullEval on a vector shared between two parties can be seen as writing t entries (the
noisy coordinates, known to the party who holds x) at secret locations (known to the other
party), on a database secretly shared between the parties. A naive writing strategy makes
t passes over the entire database, each pass writing a single entry at a secret position. Our
goal, therefore, is to write a batch of t entries at secret positions using only a constant
number of passes on the database.
A closely related problem involves secretly reading a batch of t secret entries from a
database shared between several servers. This problem has been studied at length (see [IKOS04]
and follow ups), and can be solved using a combinatorial object called batch codes. Our
solution essentially applies the same strategy, formulating the task as a private writing
problem, and shows that the same batch-code-based strategy can similarly be used for this
related task.
16
Elette Boyle, Geoﬀroy Couteau, Niv Gilboa, and Yuval Ishai
Optimized MPFSS Evaluation using Regular Syndrome Decoding (RSD) The
RSD assumption is a strengthening of the LPN assumption which was introduced in [AFS03]
as the assumption underlying the security of a candidate for the SHA-3 competition, and
which has been studied at length (see [HOSSV18] for a recent survey about the cryptanaly-
sis of the RSD assumption and a detailed discussion about its security). It states that LPN
remains hard, even if the sparse noise vector is regular, meaning that it is divided into t
blocks of size n/t each, each block containing a single random 1, and zeroes everywhere else.
Furthermore, there is a smooth tradeoﬀ between the underlying assumption (from LPN to
RSD) and the complexity (from tn to n operations): one can consider overlapping subsets
instead of disjoint subsets, with larger subsets leading to a longer MPFSS evaluation time
but a noise pattern closer to uniform (hence an assumption closest to plain LPN).
While the noise distribution obtained with this procedure is not uniform anymore, it
seems to resist all known attacks [HOSSV18]. In particular, note that it is not broken
by the attack of [AG10], (which, in particular, does not apply when we use random large
enough overlapping subsets instead of small non-overlapping subsets): the attack of [AG10]
requires at least a quadratic number of samples (note that for Gdual, the number of samples
is N + o(N ), where N = n(cid:48) − n is the dimension).
Using a regular noise pattern instead of a random noise pattern directly allows to reduce
MPFSS.FullEval to t calls to a DPF on length-n/t vectors, for a total cost of n operations
in the underlying ﬁeld F and at most n(1 + (cid:100)log |F|/(λ + 2)(cid:101)) PRG evaluations [BGI16].
However, this comes at the cost of relying on the stronger RSD assumption; below, we
outline an alternative strategy which also leads to an O(n) cost, without relying on RSD.
Batch Codes. We ﬁrst recall the deﬁnition of batch codes, from [IKOS04].
Deﬁnition 8 (Batch Code [IKOS04]). An (n, N, t, m)-batch code over an alphabet Σ
encodes any string x ∈ Σn into an m-tuple of strings (z1,··· , zm) ∈ Σ∗ (called buckets)
of total length N, such that any t-tuple of coordinates of x can be recovered by reading at
most a single entry from each bucket.
Speciﬁcally, we will rely on a combinatorial batch code (CBC) [IKOS04, SWP09], a
special type of batch code in which an encoding of a string x consists only of replicating
the coordinates of x over “buckets” (i.e., each bucket contains a subset of the coordinates
of x).
A CBC can be represented by a bipartite graph, with n left-nodes, m right-nodes, and
N edges. Each string zj, j ∈ [m] corresponds to the j-th right-node, where the value of zj
is set to the concatenation of (xi) for i ∈ [n] such that (i, j) is an edge (with some canonical
ordering). The CBC requirement states that any subset of t left-nodes has a matching to
the m right nodes. By Hall’s theorem, such a bipartite graph represents an (n, N, t, m)-
CBC if and only if it satisﬁes the following weak expansion property: each subset S of at
most t left-nodes has at least |S| neighbors on the right.
From CBC to Better MPFSS Assume for now that, for given parameters t and n =
O(ts) (for some constant expansion factor s), there is a (n, N = O(n), t, m = t1+ε)-CBC
(for some constant ε > 0).
Loosely speaking we use such a batch code to construct an eﬃcient MPFSS.FullEval
by the following steps. Instead of t instances of DPF with domain size n, we will use m
DPF instances, each with domain size |zj| (for j ∈ [m]). Namely, the multi-point function
over [n] maps n − t inputs to 0 and t values to group elements. Concatenating these n
values together we obtain a string x which can be batch-encoded into m strings z1, . . . , zm
Compressing Vector OLE
17
with total length N. By the property of batch codes the t points deﬁned by the multi-
point function can be recovered by reading one entry of each of the m strings. Therefore,
MPFSS.FullEval can be implemented by running DPF.FullEval m times, with the domain
size of the j-th invocation corresponding to the length of zj for a total length of O(N )
(instead of total length tn in the simple reduction of MPFSS.FullEval to DPF.FullEval). The
details follow.
Let T1,··· , Tm ⊂ [n] denote the left neighbors of each right-node of the graph associated
to the CBC. Let fS,y : [n] → F be a t-point function, with S = {s1,··· , st}. Let DPF =
(DPF.Gen, DPF.Eval, DPF.FullEval) be a function secret sharing for the class of all point
functions from |zj| to F.
– MPFSS.Gen(1λ, fS,y) : let I = {i1,··· , im} denote a size-m subset of [n] such that
ij ∈ Tj for any j ≤ m, and S ⊂ I (such a subset necessarily exists by deﬁnition
: [|zj|] → F to be the following function:
of a CBC). For j = 1 to m, deﬁne fj
if there exists (cid:96) such that s(cid:96) = ij, fj is the point function that outputs y(cid:96) on ij,
and 0 otherwise. Else, fj is the all-zero function, which is a point function with a 0
R← DPF.Gen(1λ, fj). Output
value deﬁned for the designated point. Compute (Kj
(K0, K1) ← ((Kj
0, Kj
1)
0)i≤m, (Kj
1)i≤m).
– MPFSS.FullEval(σ, Kσ) : parse Kσ as (Kj
σ)i≤m. Output
m(cid:88)
α =
DPF.FullEval(σ, Kj
σ).
j=1
The correctness of the above construction immediately follows from the CBC property.
Regarding eﬃciency, a key that MPFSS.Gen outputs is slightly longer compared to the
simple construction outlined in the beginning of this section (the length is O(t(λ(cid:100)log n(cid:101) +
log |G|)) in the simple construction and O(t1+ε(λ(cid:100)log n/t(cid:101) + log |G|)) in the batch-code
based construction). However, the computational cost of the simple construction is domi-
j=1 |zi|) =
nated by O(tn) PRG evaluations while the batch-code based method requires O((cid:80)m
O(n) PRG evaluations saving a factor of O(t) in computation.
Instantiating CBC. Unfortunately, known explicit constructions of (provable) expander
graphs fail to match our eﬃciency requirements. We outline below two standard ways of
getting around this issue.
– First, consider a random construction of the graph, as follows: pick any constant ε, set
d ← (1 + s) · ε + 1, and m ← t1+ε. For each left-node u, repeat the following d times:
pick a uniformly random right-node v, and add the edge (u, v) to the graph if it does
not already exist. By a standard union bound, with probability at least 1 − t−2(d−1),
the graph will satisfy the required expansion property. Note that this is a one-time
setup, which fails with a probability 1/tΩ(d) that can be made as small as we want,
and which is independent of both the running time of any adversary, and the number
of executions of the MPFSS algorithms.
– Second, one can consider a heuristic approach using some ﬁxed sequence of bits (say,
e.g., the digits of π) and interpreting it as the graph of a (n, N, k, m)-CBC under
some ﬁxed translation. Assuming that this heuristic leads to a graph with the required
expansion property can be viewed as a relatively weak combinatorial assumption, which
we refer to as the existence of explicit polynomially unbalanced bipartite expanders. This
assumption has been made (either explicitly or implicitly) in prior works on expander-
based cryptography [Gol00, IKOS08, App12, AL16, ADI+17].
18
Elette Boyle, Geoﬀroy Couteau, Niv Gilboa, and Yuval Ishai
Indeed, in the context of this work, this issue is in fact even less of a concern. Observe
that if the graph of the CBC fails to be suﬃciently expanding then the noise distribution
will slightly deviate from being uniform. However, the LPN assumption for such slightly
skewed noise distributions remains a very conservative assumption. Therefore, we get the
following guarantee: either a simple combinatorial assumption holds, and our VOLE gen-
erators are secure under the standard LPN assumption; or it fails, in which case our VOLE
generators remain secure assuming a plausible variant of LPN.
5 Eﬃciency of VOLE Generation
In this section, we discuss the asymptotic and concrete eﬃciency we can obtain with the
VOLE generators Gprimal and Gdual.
We start with asymptotic eﬃciency. Using an “LPN-friendly” code which is linear-time
encodable (alternatively, its dual is linear-time encodable for the dual construction), and
using the CBC-based MPFSS (alternatively, using the “regular noise” variant of LPN, as
in Section 4.1) our VOLE generators can be computed using O(n) arithmetic operations.
This is captured by the following theorem.
Theorem 9. Assume the existence of explicit constant-degree polynomially unbalanced bi-
partite expanders (see Section 4.1). Then the following holds.
– Primal. For any ε > 0 and 1  0 and c > 1, under the LPN(n/2, n, nε−1/c) assumption over F for
a code whose dual H is linear-time encodable, there exists a VOLE generator Gdual over
F with seed length n1/c ﬁeld elements and output length n.
In both cases, computation of G requires O(n) ﬁeld operations. Furthermore, using the
regular syndrome decoding assumption instead of LPN (with the same parameters) removes
the need for explicit expanders.
We note that the random local encoding of Alekhnovich or the code ensemble from [DI14]
(see [ADI+17] and Section 3.4) can be used to instantiate the linear-time LPN assumption.
5.1 Minimizing Seed Size
We turn to analyze the concrete eﬃciency of our VOLE generators, starting with a con-
crete optimization of the seed size. By the overview in Section 2.3, the three main attacks
that apply in our setting are the inverse syndrom decoding (ISD) attack, the Gaussian
elimination attack, and the low-weight parity-check attack. We represent on Table 1 and
Table 2 the optimal choices of parameters to minimize the size of the seed for a given
output size, for Gprimal and Gdual, under the constraint that the corresponding LPN prob-
lem requires 280 arithmetic operations to be solved with either low-weight parity check,
Gaussian elimination, or ISD. The corresponding seed size is counted as a number of ﬁeld
elements (bitsize divided by 128) to facilitate comparison with the trivial solution (directly
sharing the output vector-OLE). Ratio is n divided by the seed size (in ﬁeld elements); it
measures the gain in storage with respect to the trivial solution.
For Gprimal, the corresponding LPN instance is LPN(k, n, t), where n is the target output
size, t is the number of noisy coordinates, and k is the message length of the code. The seed
length is t· ((cid:100)log n(cid:101)(λ + 2)/ log2 |F| + λ) + t + k. Setting λ = log2 |F| = 128, the optimal seed
Compressing Vector OLE
19
size is obtained by solving a 2-dimensional optimization problem over the integers, with
constraints 0 ≤ k ≤ n, 0 ≤ t ≤ n, and the constraints given by the requirement that the
low-weight parity check attack, the Gaussian elimination attack, and the ISD attack, all
require at least 280. This is a highly non-convex constrained optimization problem, with a
very large number of local minima, making the estimation of the global minimum relatively
complex. We used extensive numerical analysis to compute (close to) minimal seed sizes
oﬀering 80 bits of security against each of the attacks; in Table 1, we report values (t, k)
at which a local minimum is attained, which is expected to be very close to the global
minimum.
For Gdual, the corresponding LPN instance is LPN(n(cid:48)−n, n(cid:48), t/n(cid:48)), where n is the target
output size, t is the number of noisy coordinates, and n(cid:48) is a parameter that can be set
arbitrarily. We let c ← n(cid:48)/n; the seed size is equal to (t·(cid:100)log2 n(cid:101)· (λ + 2) + λ)/ log2 |F| + 1.
We give in Table 2 the minimal value of t (the number of noisy coordinates), for ﬁxed n
and c = n(cid:48)/n, such that all three attacks (ISD, Gaussian, parity-check) require at least 280
operations with the above analysis. We arbitrarily set c = 4; higher values of c allow to
choose slightly smaller values for t, leading to slightly reduced seed sizes, but negatively
impact the computational eﬃciency.
Below, we provide formulas to upper-bound the cost of all three attacks in our setting.
We consider an LPN instance with dimension n0, number of queries n1, and number of
noisy coordinates t. The bounds for Gprimal are obtained by setting (n0, n1) ← (k, n). The
bounds for Gdual are obtained by setting (n0, n1) ← (n(cid:48) − n, n(cid:48)).
Gaussian Elimination. The Gaussian elimination attack requires on average (1/(1 −
t/n1))n0 iterations, where the adversary must invert an n0 × n0 matrix, which takes time
at least n2.8
0 using Strassen’s matrix multiplication algorithm (algorithms with a smaller
exponent perform less well in our range of parameters, due to their huge hidden constants).
The entry “Gaussian cost” in Table 1 and Table 2 provides a lower bound on the bit-security
of the LPN instance with respect to the Gaussian elimination attack, computed as
(cid:18)
(cid:18)
log2