Question: An online retailer has implemented a robots.txt file to manage which pages on their site should be indexed by search engines. However, they have noticed suspicious activity on pages that they attempted to disallow through the robots.txt file. Which of the following best explains why the robots.txt file did not prevent unauthorized access to sensitive pages?
"A": "The robots.txt file is designed to encrypt sensitive pages, but the encryption key was compromised.",
"B": "The robots.txt file is only a guideline for well-behaved web crawlers, and it does not prevent access by malicious bots or users.",
"C": "The server hosting the robots.txt file was down, leading to crawlers not being able to read the disallow directives.",
"D": "The robots.txt file increases the site's visibility to hackers by publicly listing sensitive URLs."
Answer: B