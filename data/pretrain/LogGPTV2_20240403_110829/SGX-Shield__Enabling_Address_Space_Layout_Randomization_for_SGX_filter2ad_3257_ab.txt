to allocate and manage system resources, such as EPC pages.
From a security standpoint, this initialization procedure relying
on an untrusted party seriously weakens the security of ASLR,
as page allocations and its virtual address mapping for an
enclave are all visible and thus known to attackers.
Specifically, in order to map a physical address of the EPC
region to a virtual address, SGX requires the untrusted kernel’s
collaboration —the kernel executes EADD, a privileged SGX
instruction, with the information on both physical and virtual
addresses to be mapped. This design decision is unavoidable and
rather natural, as the kernel should be involved in evicting some
EPC pages to non-EPC pages if EPC pages are oversubscribed.
However, this results in critical security issues from the
ASLR perspective—the untrusted kernel always knows about
the complete memory layout of an enclave application. More-
over, the base address and the size of an enclave are given to
ECREATE as parameters when creating the enclave. Using the
base address and the memory layout, the kernel can calculate
the exact location of the memory object that does not move
during the runtime (e.g., code objects).
This problem is more critical in another popular usage of
SGX: hostile cloud environment where people use SGX to
securely offload the computation. The current design of Intel
SGX always exposes the memory layouts of enclave programs
to adversaries, such as cloud providers, where they have full
control of underlying software stacks including the kernel,
firmware, and all the way down to the SMM program. Under
such a strong adversarial model, the greatest care should be
taken to design a secure ASLR scheme for SGX. In §VI, we
demonstrate that the kernel can succeed in an ROP attack
against a vulnerable enclave program with only a single trial
in the current Intel SGX SDKs.
C2. Limited memory space. The entropy of the ASLR
implementation is inherently limited by the SGX design; SGX
has not only a limited memory space overall (i.e., 128 MB
3
           C2. EPC pages < 128MB Trusted SGX CPU Enclave RAM C1. Page Table Code C3. RWX RW C4. SSA Frame User process Untrusted kernel Enclave Program EPC [29]), but also the allocated physical memory per enclave
is very limited (i.e., an order of 10 MB in typical usages). In
these situations, an attacker can easily bruteforce the entire
search space to bypass ASLR, as long as they can freely
try to mount an exploitation. As such, this limited memory
space would significantly reduce the entropy (i.e., the amount
of randomness) in enclave programs, compared to what we
typically expect in a non-SGX environment: for example, ASLR
in x86_64 can utilize the full virtual address space per process
(i.e., 48-bit). To address this issue, SGX-Shield takes a fine-
grained randomization approach to maximize the randomness
of memory layouts.
C3. Writable code pages. Dynamic relocation for ASLR
makes it difficult to utilize a powerful, comprehensive defense
mechanism against control-hijacking attacks: the No-eXecute
(NX) bit [41], which exclusively grants either an executable or
writable permission to individual memory pages. This feature is
effective in preventing code-injection attacks because attackers
cannot directly jump to execute (i.e., executable) the injected
code (i.e., writable).
However, there are some situations where both executable
and writable flags need to be set at the same time. Just-In-Time
(JIT) compilation is a notable exception, as it first writes the
compiled code to the memory and executes after that. A typical
way to handle this situation is to disable the NX bit for the
corresponding memory pages, which are the apparent target
for attackers to place the malicious code.
The key feature of SGX, integrity checking (attestation), has
a similar problem; it first has to load the code (i.e., writable)
and then execute after the measure (i.e., executable). For this
reason, the integrity measurement for SGX is only valid for
fixed code and data pages, and it cannot be easily extended to
support the dynamically changing pages. Specifically, before
launching an enclave (i.e., EENTER), the integrity measurement
should be finalized and cannot be changed after that. However,
implementing ASLR for an enclave program inherently requires
changing the permission bit (from writable to non-writable) of
code pages after the initial measurement, in particular, the code
sections that need to be relocated. Unfortunately, SGX prohibits
changing a permission bit after the initial measurement [30].
Therefore, code pages have to be both writable and executable
to perform a proper relocation for ASLR after the measurement:
the relocation takes place within an enclave after EINIT.
We confirm that some Windows enclave programs requiring
dynamic relocation contain writable and executable pages. In
fact, Intel already acknowledged this issue [27] and further
recommended that the enclave code contain no relocation (i.e.,
no code randomization after the initialization) to enable the
NX feature. To properly guarantee the security of ASLR in
SGX programs, we need to carefully rethink the design criteria
that are compliant with the SGX environment.
The TCS is initialized and loaded by the kernel through an
EADD instruction and contains information for executing an
SGX program, such as the entry point of the enclave, the base
addresses of FS/GS segments, the offset of SSA, etc. Since
TCS is critical for the security of enclave programs, SGX
prohibits an explicit access to the TCS after initialization. After
initialization, some fields of the TCS might be updated by the
CPU during execution (e.g., saving the execution context to
the SSA frame in Asynchronous Enclave Exit), and the fields
specifying the location of SSA (i.e., OSSA) cannot be updated.
In other words, the virtual address of SSA is always known
to the untrusted kernel, and the location of SSA cannot be
randomized after initialization.
This leaves potential opportunities for abuse. Let’s assume
two threads T1 and T2 are running concurrently in an enclave.
When T1 temporarily exits an enclave due to an interrupt, its
execution context, including all register and values, is saved into
the SSA. Then, using T2, an attacker can mount an arbitrary
memory write to overwrite the field for the instruction pointer
in the SSA frame, thereby hijacking control of the T1 thread.
Similarly, with an arbitrary memory read, attackers can infer
the complete address space layout by following the pointers
and instructions from the initial information found in the SSA
frame, similar to just-in-time code reuse [57]. In SGX-Shield,
we isolate all memory accesses to the known yet security-critical
data structures in an SGX program.
IV. DESIGN
In this section, we present the design of SGX-Shield, which
fortifies the security aspect of the ASLR scheme in an SGX
environment. In particular, we address all challenges highlighted
in §III.
• C1: Strong adversaries. SGX-Shield introduces the
concept of a multistage loader, which can hide ASLR-
related security decisions and operations from adversaries
(§IV-B).
• C2: Limited memory. SGX-Shield employs a form of
fine-grained randomization that is tailored to maximize its
entropy on the SGX environment (§IV-C).
• C3: Writable code pages. SGX-Shield implements a
software DEP to enforce W⊕X in an enclave’s code pages
(§IV-D).
• C4: Known address space. SGX-Shield incorporates
coarse-grained software-fault isolation (SFI) to protect
fixed, security-sensitive data structures from arbitrary
memory reads and writes (§IV-E).
C4. Known, fixed addresses. Worse yet, some data structures
in SGX do not allow relocation at all. For example, the State
Save Area (SSA) frame in SGX does not allow relocation to
arbitrary memory addresses; the SSA frame is dedicated to
storing the execution context when handling interrupts in SGX.
More precisely, the address of SSA Frame is determined by
an OSSA field, the offset from the base address of an enclave
to SSA, embedded in the Thread Control Structure (TCS).
For the rest of this section, we start by describing our
threat model (§IV-A), and then explain techniques to overcome
each challenge in the following subsections: §IV-B shows
our multistage loader; §IV-C describes the fine-grained ASLR
scheme for SGX; §IV-D explains software DEP; and §IV-E
shows our SFI scheme designed for SGX programs. In §IV-F,
we introduce performance optimization techniques that we
adopt.
4
Fig. 2: Overall workflow of SGX-Shield: 1) the preparation phase builds a SGX binary from the target program’s source code; 2) the
bootstrapping phase loads the secure in-enclave loader into code pages and the target SGX program into data pages; and 3) the secure in-enclave
loading phase finally loads the target SGX program.
A. Threat Model
SGX-Shield assumes the same attack model as SGX, as
our ASLR scheme is designed for SGX programs. Specifically,
we assume that only the CPU package with SGX support is
trusted and all other hardware components are not. A user
runs his or her own target program within an enclave, and all
other components in the software stack are not trusted (i.e.,
other processes, an operating system, and a hypervisor). Our
attack model consideration focuses on an attacker who wishes
to exploit a vulnerability, a memory corruption vulnerability in
particular, in the target program running in the enclave. While
completely addressing side-channel issues is not the primary
goal of this paper, SGX-Shield provides a barrier to guess the
memory layout of an enclave against the attack based on the
page fault side-channel (i.e., controlled side-channel) [61]. We
discuss the effectiveness of SGX-Shield against the controlled
side-channel attacks in §VI-A1 and §VII.
B. Multistage Loader
To prevent the untrusted kernel from learning the memory
layout of an enclave, SGX-Shield performs all ASLR operations
within the enclave, taking advantage of its isolated execution.
SGX-Shield consists of three phases, as shown in Figure 2:
preparation, bootstrapping, and secure in-enclave loading.
First, the preparation phase builds the target SGX program
that a user wants to deploy. This built executable contains a
secure in-enclave loader in its code section and the target SGX
program in its data section, where the secure in-enclave loader
will load the target SGX program later. This phase can be
carried out anytime before deployment and does not have to
be performed on the same SGX machine in which the target
program will be run.
visible to the non-trusted party in this phase, it is designed to
make as minimal decisions on resource provisioning as possible
and defer all security-sensitive decisions to the secure in-enclave
loader. This phase allocates two types of enclave data pages
with read and write permissions and code pages with read,
write, and execute permissions. The read/write permissions
granted to code pages enable the secure in-enclave loader
to write the target SGX program into an enclave memory
(performing the relocation as well) and then execute it. While
this design decision facilitates multistage loading, it ends up
having both writable and executable memory pages, similar to
the challenge C3 (§III). To address this issue, §IV-D presents
how SGX-Shield removes read and write permissions from
these pages using a software-level enforcement.
it
Finally, the secure in-enclave loader loads the target SGX
program into the memory space from its data pages. The
secure in-enclave loader randomly picks the base address using
the RDRAND instruction, which relies on the non-deterministic
on-processor entropy. Then,
loads each section of the
target program, where the address of each section is further
adjusted independently at random. Before finishing the loading,
SGX-Shield resolves all relocation information, which includes
global variables, static variables, and the destination of all
branches. As a last step, SGX-Shield wipes out the secure
in-enclave loader from the memory space, and then jumps to
the entry point of the target SGX program to hand over the
execution.
Because the target program is loaded within an enclave by
the secure in-enclave loader, SGX-Shield completely hides the
address space layout information from the untrusted kernel.
The random value is directly obtained from the CPU, and all
the following computations and decisions for ASLR of the
target program are performed inside the enclave.
Second, in the bootstrapping phase, SGX-Shield performs
the first part of multistage loading. The primary role of the
bootstrapping phase is to create an enclave and initialize the
secure in-enclave loader with the help of the untrusted kernel.
Because the memory layout of an enclave is assumed to be
It is worth noting that our multistage loading scheme is fully
compatible with SGX’s attestation scheme. At the moment a
measurement for an enclave is finalized by an EINIT instruction
(i.e., between the bootstrapping and secure in-enclave loading
phase), all required resources for SGX-Shield are finalized
5
Secure in-enclave loader Code pages (X) Data pages (RW) Runtime Data User process No permission SSA, TCS, Guard Code pages (RWX) Data pages (RW) Enclave User process 3. Secure in-enclave loading Enclave 2. Bootstrapping 1. Preparation Source code Source code Source code Multistage loading (§IV-B) Fine-grained  ASLR (§IV-C) Software-DEP (§IV-D) SFI  (§IV-E) Secure in-enclave loader Target SGX Program Secure in-enclave loader r15 (NRW boundary) SGX-Shield’s Compile toolchains (LLVM, static linker) SGX-Shield supports both Linux and Windows Fig. 3: Fine-grained ASLR scheme based on a randomization unit. jg A∗ and jmp c∗ represent the relocated instructions of jg A and jmp C,
respectively. The preparation phase instruments an unconditional branch (i.e., jmp C) next to a conditional branch (i.e., jg A). As a result, during
a secure in-enclave loading phase, the following unit (i.e., RU C) can be randomly placed independently to the location of the instrumented unit
(i.e., RU B) by resolving relocation.
and fully measured. Thus, from the perspective of performing
attestation, SGX-Shield is the same as typical SGX programs—
SGX-Shield simply runs code, the secure in-enclave loader,
with data, the target SGX program. Specifically, all memory
pages for SGX-Shield including the secure in-enclave loader
in code pages and the target SGX program in data pages are
added to EPC pages and extended for measurement through
EADD and EEXTEND, respectively.
C. Fine-grained Randomization for Enclaves
SGX-Shield
employs
fine-grained
randomization
schemes [13, 23, 24, 32, 45, 59] to maximize the ASLR
entropy. In the following, we describe how SGX-Shield is
designed to randomize the memory space layout across three
phases.
Preparation.
To enable fine-grained ASLR for code,
SGX-Shield relocates code at smaller granularity, called a
randomization unit. Randomization units are of fixed size that
can be configured. Our implementation supports 32- and 64-
byte units. SGX-Shield modifies commodity compilation and
linkage procedures because they support only simple module-
level (i.e., section-level) randomization. During the compilation,
SGX-Shield ensures that the terminating instructions of ran-
domization units are not fall-through cases. This is because
fall-through assumes that randomization units are placed
consecutively, which is not true when they are relocated for
ASLR. Thus, for each fall-through case, SGX-Shield appends
an unconditional branch instruction that points to the entry
point of the next randomization unit (i.e., the randomization
unit pointed to by the fall-through case).
For example, as shown in Figure 3, right after the condi-
tional branch instruction (i.e., jg A), an unconditional branch
instruction (i.e., jmp C) is added, allowing RU C to be randomly
relocated independently to the location of RU B. Note that this
instrumentation pass cannot be done naively at the intermediate
language (IR) level. Even when IR does not have conditional
branch instructions with fall-through features (e.g., LLVM IR),
the compiler backend may automatically introduce this. For
example, the Intel x86-64 architecture always uses fall-through
with conditional branch instructions.
Finally, the size of the randomization unit introduces a
trade-off between security and performance. When the size
of the randomization is small, there will be more candidate
slots to place the randomization unit, increasing the entropy of
6
ASLR at the cost of more frequent branching and decreased
spatial locality. We evaluate this trade-off in §VI.
Stage 1: Bootstrapping. We let the loading scheme in the
bootstrapping phase over-estimate the memory space required
to load the target program, as this size is directly related to
the ASLR entropy. Strong adversaries, including the untrusted
kernel, always know of ranges of truly active memory space.
Thus, unlike traditional ASLR settings where an attacker
needs to bruteforce the entire virtual address space, the strong
adversary needs to bruteforce only a small space based on
her/his prior-knowledge. To this end, we over-estimate both
code and data pages, where both are configured as 32 MB in
the current version of SGX-Shield.
Stage 2: Secure in-enclave loading. Using the target SGX
program in data pages, the secure in-enclave loader starts to
place each randomization unit into previously allocated memory
spaces. SGX-Shield fully utilizes over-estimated memory space,
reserved for loading the target program, to randomly scatter
each randomization unit, which in turn maximizes the ASLR
entropy. SGX-Shield randomizes all data objects as well,
which includes stack, heap, and global variables. Specifically,
SGX-Shield performs the following steps: (1) for a stack
area, SGX-Shield picks the random base address and reserves
continuous memory space from this base; (2) for a heap area,
it randomly picks k memory pools from the rest of the data
pages, where the size of each memory pool is configurable
(i.e., 1 MB in the current version of SGX-Shield); (3) global
and static variables are randomly placed into the rest of the
data pages.
Since SGX-Shield randomizes all code and data objects, all
references to memory objects including the absolute address
and the PC-relative address must be determined after placing
them. The secure in-enclave loader conducts the relocation
for all memory objects after loading them. For example, as
shown in Figure 3, instructions jg A and jmp C are relocated