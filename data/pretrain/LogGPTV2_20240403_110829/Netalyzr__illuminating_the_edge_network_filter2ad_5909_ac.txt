Otherwise, it could skew the analysis results or diminish the scientific value of the data. To address this, we conducted extensive calibration of the measurement results to ensure the coherence and meaningfulness of our data. A particular challenge in developing Netalyzr was ensuring its correct operation across a wide range of failure modes. While we put significant effort into anticipating these issues during development, subsequent calibration was crucial for validating our assumptions and understanding how the tests performed on a large scale. Additionally, it was highly beneficial to have an independent person (coauthor Nechaev) perform this task, as it helped avoid incorporating implicit assumptions present in the code.

Our calibration efforts were based on the BETA dataset, which we used to identify and rectify sources of errors before starting the RELEASE data collection. We individually assessed data consistency for each of the tests mentioned in § 3. Our focus was on identifying missing or ambiguous values, checking value ranges, investigating outliers, confirming the consistency of result variables (e.g., mutual exclusiveness and correct totals), ensuring that specific variable values met corresponding preconditions (e.g., the availability of raw UDP capability enabling certain DNS tests), and searching for systematic errors in the data.

Fortunately, this process did not uncover any major flaws in the codebase or the data. The most common issues we found were ambiguity (e.g., distinguishing silent test failures from cases where a test did not execute at all) and inaccuracies in importing the data into our session database. The RELEASE codebase differs from BETA primarily in providing more unambiguous and extensive result reporting, along with the addition of new tests.

### ISP and Geographic Diversity

We estimate the ISP and location of Netalyzr users by inspecting reverse (PTR) lookups of their public IP addresses, if available; otherwise, we use the final Start-of-Authority record in the DNS. These results were available for 96% of our sessions.

To extract meaningful organizational names, we used a database of "effective TLDs" to identify the relevant name preceding these TLDs. Using this approach, our dataset includes sessions from 6,884 organizations across 186 countries, as shown in Figure 3. Activity was dominated by users in the USA (46.1%), the EU (31.7%, with Germany accounting for 8.8% and Great Britain for 8.0%), and Canada (5.3%). Eleven countries contributed sessions from more than 1,000 addresses, 50 from more than 100, and 101 from more than 10.

**Figure 3: Global locations of Netalyzr runs.**

**Identified Measurement Biases:** A disadvantage of website-driven data collection is vulnerability to sudden referral surges from specific websites, especially if these entail a technologically biased user population that can skew our dataset. Additionally, our Java runtime requirement may discourage non-technical users whose systems do not have the runtime installed by default and precludes the use of Netalyzr on many smartphone platforms. We now analyze the extent to which our dataset contains such bias.

The five sites referring the most users to Netalyzr are: stumbleupon.com (30%), lifehacker.com (11%), slashdot.org (10%), google.com (7%), and heise.de (6%). The context of these referrals affects the number of sessions we record for various ISPs. For example, most users arriving from slashdot.org did so in the context of an article on alleged misbehavior by Comcast’s DNS servers, likely contributing to making their customers the largest share of our users (10.3% of our sessions originate from Comcast’s IP address ranges). Coverage in Germany via heise.de likely drove visits from customers of Deutsche Telekom, accounting for 2.4% of the sessions. A summary of the dominant ISPs in our dataset is provided in Table 3 below.

The technical nature of our service introduced a "geek bias" in our dataset, which we can partially assess using the User-Agent HTTP request headers of our users to infer browser type and operating system. Here we compare against published "typical" numbers [26, 27], which we give in parentheses. 37.4% (90%) of our users ran Windows, 7.9% (1.0%) used Linux, and 13.8% (5.9%) used MacOS. Firefox was over-represented with 59.9% (28.3%) of sessions, followed by 18.7% (59.2%) for Internet Explorer, 16.9% (4.5%) for Safari, and 2.9% (1.7%) for Opera. This bias also extends to the choice of DNS resolver, with 12% of users selecting OpenDNS as their DNS provider.

While such bias is undesirable, it can be difficult to avoid in a study requiring user participation. At least we can mitigate distortions because we can identify its presence. Its primary effect concerns our characterizations across ISPs, where we endeavor to normalize accordingly, as discussed below. We also note that technically savvy users may be more likely to select ISPs with fewer connectivity deficiencies, which would mean the prevalence of problems we observe may be underestimates.

### Data Analysis

We now turn to an assessment of the data gathered from Netalyzr measurements to date. In our discussion, we follow the presentation of the different types of tests, beginning with layer 3 measurements and then progressing to general service reachability and specifics regarding DNS and HTTP behavior.

#### Network-Layer Information

**Network Address Translation (NAT):** Unsurprisingly, NATs are very prevalent among Netalyzr users (90% of all sessions). 79% of these sessions used the 192.168/16 range, 15% used 10/8, and 4% used 172.16/12. 2% of the address-translated sessions employed some form of non-private address. We did not discern any particular pattern in these sessions or their addresses; some were quite bizarre.

**Port Sequencing Behavior:** Of 57,510 sessions examined, 30% exhibit port renumbering, where the NAT does not preserve the TCP source port number for connections. Of these, 8.3% appear random (using a Wald-Wolfowitz test with sequence threshold 4), while 90% renumber monotonically, most in a strictly incremental fashion. However, some exhibit jumps of varying size. Identifying the causes of these would enable us to estimate the level of multiplexing apparently present in the user’s access link.

**IPv6:** We found IPv6 support to be rare but non-negligible: 4.8% of sessions fetched the logo from ipv6.google.com. This represents an upper bound due to possible caching effects (as well as "geek bias").

**Fragmentation:** Overall, we find that fragmentation is not as reliable as desired [14, 23]. In the RELEASE, we found 8% of the sessions unable to send 2 KB UDP packets, and likewise 8% unable to receive them. We also found that 3% of the sessions which could send 2 KB packets could not send 1500 B packets. 87% of these sessions came from Linux systems, strongly suggesting the likely cause to be Linux’s arguably incorrect application of Path MTU discovery to UDP traffic. Java does not appear to retransmit in the face of ICMP feedback, instead raising an exception which Netalyzr reports as a failure.

From our server to the client, 79% of the sessions exhibited a path MTU of 1500 B, followed by 1492 B (16%), suggesting a prevalence of PPP over Ethernet (PPPoE). We also observed small clusters at 1480 B, 1476 B, 1460 B, and 1458 B, but these were rare. Only 2% reported an MTU less than 1450 bytes.

For sessions with an MTU < 1500 B, only 59% had a path that successfully sent a proper “fragmentation required” ICMP message back to our server, reinforcing that systems should avoid PMTU for UDP and provide robustness in the presence of MTU black holes [16].

**Latency and Bandwidth:** Figure 4 illustrates the balance of upstream vs. downstream capacities for countries and ISPs, while Figure 5 shows the distribution of download bandwidths for the three most prominent ISPs in our dataset: Comcast, RoadRunner, and Verizon. Two years after the study by Dischinger et al. [8], our results still partially match theirs, particularly for RoadRunner.

From the most aggregated perspective, we observed an average download bandwidth of 6.7 Mbps and, for upload, 2.7 Mbps. We found far more symmetric bandwidths for sessions that users self-reported as at work (10 Mbps/8.1 Mbps), and reported home connections exhibited far more asymmetry and lower bandwidth (6.2 Mbps/1.6 Mbps). Public networks exhibited less download bandwidth but more symmetry (3.5 Mbps/2.3 Mbps).

We saw less variation in the aggregate perspective for quiescent latency. Sessions reported as run at work had an average latency of 110 ms, while home networks experienced 120 ms and public networks 180 ms of latency.

**Network Uplink Buffering:** A known problem [8] confirmed by Netalyzr is the substantial over-buffering present in the network, especially in end-user access devices such as DSL or DOCSIS cable modems. This can cause significant problems since a single full-rate TCP flow can fill the bottleneck buffer, which, in the absence of advanced queue management, will induce substantial latency to all traffic through the bottleneck.

Netalyzr attempts to measure this by recording the amount of delay induced by the high-bandwidth burst of traffic once it exceeds the actual bandwidth obtained. We then infer the buffer capacity as equal to the sustained sending rate multiplied by the additional delay induced by this test. Since the test uses UDP, no back-off comes into play to keep the buffer from completely filling, though we note that Netalyzr cannot determine whether the buffer did indeed actually fill to capacity.

When plotting measured upload bandwidth vs. inferred upload buffer capacity, we observed a strong correlation, indicating that the buffer sizes are often proportional to the available bandwidth.