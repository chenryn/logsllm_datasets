erwise skew the analysis results or deﬂate the scientiﬁc value of
the data. Accordingly, we undertook extensive calibration of the
measurement results to build up conﬁdence in the coherence and
meaningfulness of our data. A particular challenge in realizing Ne-
talyzr has been that it must operate correctly in the presence of a
wide range of failure modes. While we put extensive effort into
anticipating these problems during development, subsequent cali-
bration served as a key technique to validate our assumptions and
learn how the tests actually work on a large scale. In addition, it
proved highly beneﬁcial to employ someone for this task who was
not involved in developing the tests (coauthor Nechaev), as doing
so avoided incorporating numerous assumptions implicitly present
in the code.
We based our calibration efforts on the BETA dataset, using it
to identify and remedy sources of errors before beginning the RE-
LEASE data collection. To do so, we assessed data-consistency in-
dividually for each of the tests mentioned in § 3. We emphasized
ﬁnding missing or ambiguous values in test results, checking value
ranges, investigating outliers, conﬁrming that each test’s set of re-
sult variables exhibited consistency (e.g., examining that mutual
exclusiveness was honored, or that fractions added up to a correct
total), ensuring that particular variable values complied with cor-
responding preconditions (e.g., availability of raw UDP capability
reliably enabling certain DNS tests), and searching for systematic
errors in the data.
To our relief, this process did not uncover any major ﬂaws in the
codebase or the data. The most common problems we uncovered
were ambiguity (for example, in distinguishing silent test failures
from cases when a test did not execute at all) and inaccuracies in
the process of importing the data into our session database. The
RELEASE codebase only differs from BETA in the presence of more
unambiguous and extensive result reporting (and the addition of
new tests).
251DE
GB
ES
HR IT
IL
KR
JP
US
SE
RO
HK
CA FI
TR
BG
NL
CZ
RU
LT
KE
AR
MX
BD
BR
IR
IN
GT
16Mb/s 
8Mb/s 
4Mb/s 
2Mb/s 
1Mb/s 
512Kb/s 
256Kb/s 
128Kb/s 
64Kb/s 
RS
SD
ID
LB
UG
i
t
h
d
w
d
n
a
B
d
a
o
n
w
o
D
l
64Kb/s
128Kb/s 256Kb/s 512Kb/s
1Mb/s
2Mb/s
4Mb/s
8Mb/s
Upload Bandwidth
cox.net
comcast.net
i
h
t
d
w
d
n
a
B
d
a
o
n
w
o
D
l
8Mb/s 
shawcable.net
rogers.com
virginmedia.com
optonline.net
verizon.net
alicedsl.de
rr.com
charter.com
bethere.co.uk
4Mb/s 
btcentralplus.com
telecomitalia.it
bellsouth.net
telefonica.es
arcor−ip.net
t−dialin.net
sbcglobal.net
qwest.net
2Mb/s 
256Kb/s 
pacbell.net
512Kb/s 
1Mb/s 
Upload Bandwidth
2Mb/s 
4Mb/s 
Figure 4: Average up/downstream bandwidths for countries
with ≥ 10 sessions (top) and the 20 most prevalent ISPs (bot-
tom). Circle areas are proportional to prevalence in the dataset;
diagonals mark symmetric up/download capacity.
5.1
ISP and Geographic Diversity
We estimate the ISP and location of Netalyzr users by inspecting
reverse (PTR) lookups of their public IP address, if available; or
else the ﬁnal Start-of-Authority record in the DNS when attempting
the PTR lookup. We found these results available for 96% of our
sessions.
To extract a meaningful organizational name, we started with a
database of “effective TLDs,” i.e., domains for which the parent is a
broad, undifferentiated domain such as gouv.fr [17], to identify
the relevant name preceding these TLDs. Given this approach, our
dataset consists of sessions from 6,884 organizations (see Table 3
below for the 15 most frequent) across 186 countries, as shown in
Figure 3. Activity however was dominated by users in the USA
(46.1%), the EU (31.7%, with Germany accounting for 8.8% and
Great Britain for 8.0%), and Canada (5.3%). 11 countries con-
tributed sessions from more than 1,000 addresses, 50 from more
than 100, and 101 from more than 10.
Figure 3: Global locations of Netalyzr runs.
Identiﬁed Measurement Biases. A disadvantage of website-
driven data collection is vulnerability to sudden referral surges from
speciﬁc websites—in particular if these entail a technologically bi-
ased user population that can skew our dataset. In addition, our Java
runtime requirement could discourage non-technical users whose
systems do not have the runtime installed by default. It also pre-
cludes the use of Netalyzr on many smartphone platforms. We now
analyze the extent to which our dataset contains such bias.
The ﬁve sites referring the most users to Netalyzr are: stum-
bleupon.com (30%), lifehacker.com (11%), slashdot.org (10%),
google.com (7%), and heise.de (6%). The context of these referrals
affects the number of sessions we record for various ISPs. For ex-
ample, most users arriving from slashdot.org did so in the context
of an article on alleged misbehavior by Comcast’s DNS servers,
likely contributing to making their customers the biggest share of
our users (10.3% of our sessions originate from Comcast’s IP ad-
dress ranges). Coverage in Germany via heise.de likely drove visits
from customers of Deutsche Telekom, accounting for 2.4% of the
sessions. We show a summary of the dominant ISPs in our dataset
in Table 3 below.
The technical nature of our service introduced a “geek bias”
in our dataset, which we can partially assess by using the
User-Agent HTTP request headers of our users to infer browser
type and operating system. Here we compare against published
“typical” numbers [26, 27], which we give in parentheses. 37.4%
(90%) of our users ran Windows, 7.9% (1.0%) used Linux, and
13.8% (5.9%) used MacOS. We ﬁnd Firefox over-represented with
59.9% (28.3%) of sessions, followed by 18.7% (59.2%) for Inter-
net Explorer, 16.9% (4.5%) for Safari, and 2.9% (1.7%) for Opera.
This bias also extends to the choice of DNS resolver, with 12% of
users selecting OpenDNS as their DNS provider.
While such bias is undesirable, it can be difﬁcult to avoid in a
study that requires user participation. We can at least ameliorate
distortions from it because we can identify its presence. Its pri-
mary effect concerns our characterizations across ISPs, where we
endeavor to normalize accordingly, as discussed below. We also
note that technically savvy users may be more likely to select ISPs
with fewer connectivity deﬁciencies, which would mean the preva-
lence of problems we observe may reﬂect underestimates.
5. DATA ANALYSIS
We now turn to an assessment of the data gathered from Netalyzr
measurements to date. In our discussion we follow the presentation
of the different types of tests above, beginning with layer 3 mea-
surements and then progressing to general service reachability and
speciﬁcs regarding DNS and HTTP behavior.
2525.2 Network-Layer Information
Network Address Translation. Unsurprisingly, we ﬁnd NATs
very prevalent among Netalyzr users (90% of all sessions). 79%
of these sessions used the 192.168/16 range, 15% used 10/8,
and 4% used 172.16/12. 2% of the address-translated sessions
employed some form of non-private address. We did not discern
any particular pattern in these sessions or their addresses; some
were quite bizarre.
Port sequencing behavior. Of 57,510 sessions examined, 30%
exhibit port renumbering, where the NAT does not preserve the
TCP source port number for connections. Of these, 8.3% appear
random (using a Wald-Wolfowitz test with sequence threshold 4),
while 90% renumber monotonically, most in a strictly incremental
fashion. However, some exhibit jumps of varying size. Identifying
the causes of these would then enable us to estimate the level of
multiplexing apparently present in the user’s access link.
IPv6. We found IPv6 support to be rare but non-negligible: 4.8%
of sessions fetched the logo from ipv6.google.com. This repre-
sents an upper bound due to possible caching effects (as well as
“geek bias”).
Fragmentation. Overall, we ﬁnd that fragmentation is not as
reliable as desired [14, 23]. In the RELEASE we found 8% of the
sessions unable to send 2 KB UDP packets, and likewise 8% unable
to receive them.
We also found that 3% of the sessions which could send 2 KB
packets could not send 1500 B packets. We ﬁnd that 87% of these
sessions come from Linux systems, strongly suggesting the likely
cause to be Linux’s arguably incorrect application of Path MTU
discovery to UDP trafﬁc. Java does not appear to retransmit in the
face of ICMP feedback, instead raising an exception which Net-
alyzr reports as a failure.
From our server to the client, 79% of the sessions exhibited a
path MTU of 1500 B, followed by 1492 B (16%) which suggests
a prevalence of PPP over Ethernet (PPPoE). We also observe small
clusters at 1480 B, 1476 B, 1460 B, and 1458 B, but these are rare.
Only 2% reported an MTU less than 1450 bytes.
For sessions with an MTU < 1500 B, only 59% had a path that
successfully sent a proper “fragmentation required” ICMP message
back to our server, reinforcing that systems should avoid PMTU
for UDP, and for TCP should provide robustness in the presence of
MTU black holes [16].
Latency and Bandwidth. Figure 4 illustrates the balance of
upstream vs. downstream capacities for countries and ISPs, while
Figure 5 shows the distribution of download bandwidths for the
three most prominent ISPs in our dataset: Comcast, RoadRunner,
and Verizon. Two years after the study by Dischinger et al. [8] our
results still partially match theirs, particularly for RoadRunner.
From the most aggregated perspective, we observed an aver-
age download bandwidth of 6.7 Mbps and, for upload, 2.7 Mbps.
We ﬁnd far more symmetric bandwidths for sessions that users
self-reported as at work (10 Mbps/8.1 Mbps), and reported home
connections exhibited far more asymmetry and lower bandwidth
(6.2 Mbps/1.6 Mbps). Public networks exhibited less download
bandwidth but more symmetry (3.5 Mbps/2.3 Mbps).
We saw less variation in the aggregate perspective for quiescent
latency. Sessions reported as run at work had an average latency
of 110 ms, while home networks experienced 120 ms and public
networks 180 ms of latency.
Network Uplink Buffering. A known problem [8] conﬁrmed by
Netalyzr is the substantial over-buffering present in the network, es-
pecially in end-user access devices such as DSL or DOCSIS cable
modems. This can cause signiﬁcant problems since a single full-
rate TCP ﬂow can ﬁll the bottleneck buffer, which, in the absence
Comcast
RoadRunner
Verizon
8
0
.
6
0
.
y
t
i
s
n
e
D
y
t
i
l
i
4
0
.
b
a
b
o
r
P
2
0
.
0
0
.
64Kb/s
256Kb/s
1Mb/s
4Mb/s
Download Bandwidth
16Mb/s
64Mb/s
Figure 5: PDF of download bandwidths for the three most
prominent ISPs in our dataset.
of advanced queue management, will induce substantial latency to
all trafﬁc through the bottleneck.7
Netalyzr attempts to measure this by recording the amount of de-
lay induced by the high-bandwidth burst of trafﬁc once it exceeds
the actual bandwidth obtained. We then infer the buffer capacity
as equal to the sustained sending rate multiplied by the additional
delay induced by this test. Since the test uses UDP, no back-off
comes into play to keep the buffer from completely ﬁlling, though
we note that Netalyzr cannot determine whether the buffer did in-
deed actually ﬁll to capacity.
When plotting measured upload bandwidth vs. inferred upload