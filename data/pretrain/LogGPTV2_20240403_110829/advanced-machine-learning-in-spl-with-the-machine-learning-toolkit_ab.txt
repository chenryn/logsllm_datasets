‚Ä¶ | apply petal_length_from_species
29
3029
30
apply: How It Works
1. 
2. 
3. 
4.
5. 
6. 
7. 
8. Load the learned model.
Discard fields that are null for all search results.
Discard non-numeric fields with >100 distinct values.
Convert non-numeric fields to binary indicator variables (i.e. ‚Äúdummy coding‚Äù).
Discard variables not in the learned model.
Fill missing fields with 0‚Äôs.
Convert to a numeric matrix and hand over to . Compute predictions for all search results.31
	apply: How It Works‚Ä¶ | apply fraud_model
| 4. | Convert non-numeric fields to binary indicator variables. | Convert non-numeric fields to binary indicator variables. | Convert non-numeric fields to binary indicator variables. | Convert non-numeric fields to binary indicator variables. | Convert non-numeric fields to binary indicator variables. | Convert non-numeric fields to binary indicator variables. |  ||---|---|---|---|---|---|---|---|
| 4. |Target |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ | |
|  | | |field_B |field_D=red |‚Ä¶=green |‚Ä¶=blue |‚Ä¶=yellow |
|  |ok | | |red |0 |0 |0 |
|  |ok | | |green |1 |0 |0 |
|  |FRAUD | | |blue |0 |1 |0 |
|  | | | |yellow |0 |0 |1 |
32
	apply: How It Works‚Ä¶ | apply fraud_model| 5. | Discard variables not in the learned model. | Discard variables not in the learned model. | Discard variables not in the learned model. | Discard variables not in the learned model. | Discard variables not in the learned model. |  |  |
|---|---|---|---|---|---|---|---|
| 5. |Target |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ | | ||  | | |field_B |field_D=red |‚Ä¶=green |‚Ä¶=blue | |
|  |ok | | |1 |0 |0 |  |
|  |ok | | |0 |1 |0 |  |
|  |FRAUD | | |0 |0 |1 |  |
|  | | | |0 |0 |0 |  |
33
	apply: How It Works‚Ä¶ | apply fraud_model
| 5. | Convert to a numeric matrix and hand over to . | Convert to a numeric matrix and hand over to . | Convert to a numeric matrix and hand over to . | Convert to a numeric matrix and hand over to . ||---|---|---|---|---|
| 5. |y = |[1, 1, 0, 1, ?] |X = |[[41, 1, 0, 0], |
| 5. |y = |[1, 1, 0, 1, ?] |X = |[32, 0, 1, 0], |
| 5. |[1, 0, 0, 1], |[1, 0, 0, 1], |[1, 0, 0, 1], |[1, 0, 0, 1], |
	[41, 0, 0, 0]] e.g. for Logistic Regression:
| ùë¶" =  | 1 | Compute ùë¶" using Œ∏ found by fit command. |
|---|---|---|
| ùë¶" =  |1 + ùëí((*+,) |Compute ùë¶" using Œ∏ found by fit command. |
34
	apply: How It Works‚Ä¶ | apply fraud_model| 7. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Compute predictions for all search results. | Prediction ||---|---|---|---|---|---|---|---|---|---|---|
| 7. |Target |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Explanatory Variables‚Ä¶ |Prediction |
|  |field_A |field_B |field_C |field_D |field_D |field_D |field_D |field_D |field_E |predicted(field_A) ||  |ok |41 |red |red |172.24.16.5 |172.24.16.5 |172.24.16.5 |172.24.16.5 |172.24.16.5 |ok |
|  |ok |32 |green |green |green |green |192.168.0.2 |192.168.0.2 |192.168.0.2 |ok |
|  |FRAUD |1 |blue |blue |blue |10.6.6.6 |10.6.6.6 |10.6.6.6 |10.6.6.6 |FRAUD |
|  |ok |43 |171.64.72.1 |171.64.72.1 |171.64.72.1 |171.64.72.1 |171.64.72.1 |171.64.72.1 |171.64.72.1 |ok ||  |41 |41 |yellow |yellow |yellow |yellow |yellow |192.168.0.2 |192.168.0.2 |ok |
|  | | | | | | | | | | |
35
apply: Properties
|  | Learned models can be applied to new, unseen data. | Learned models can be applied to new, unseen data. |
|---|---|---|
|  || fit |is to    | apply |
as
| 
 | | outputlookup | is to    | lookup |
|---|---|---||---|---|---|
|   |Resilient to missing values.   (but, again, be careful!)  Automatically handles categorical (e.g. non-numeric) fields. |Resilient to missing values.   (but, again, be careful!)  Automatically handles categorical (e.g. non-numeric) fields. |
36
apply: Scalability
 No limits.
When possible, executes at the Indexing tier.
‚Äì Fully parallelized; harness the CPU power of your Indexing Cluster.‚Äì Must set ‚Äústreaming_apply = true‚Äù in mlspl.conf.
37
ML-SPL Commands: summary
‚Ä¶ | summary 
Examples:
‚Ä¶ | summary temp_model
‚Ä¶ | summary user_behavior_clusters
‚Ä¶ | summary petal_length_from_species
38
39
ùë¶" =  1 
1 + ùëí((*+,)
40
Algorithms and Analytics in ML-SPL
Regression Algorithms 
(e.g. predict numeric fields)
 LinearRegression
‚Äì ‚Ä¶ including Lasso, Ridge, ElasticNet
 KernelRidgeKernelRidge 
DecisionTreeRegressor RandomForestRegressor SGDRegressor
All implemented with sklearn models.
Classification Algorithms 
(e.g. predict categorical fields)
 LogisticRegression 
DecisionTreeClassifier 
RandomForestClassifier 
SGDClassifier 
SVM 
Na√Øve Bayes
‚Äì Including BernoulliNB and GuassianNB
Clustering Algorithms 
(e.g. group like with like)
 KMeans 
DBSCAN 
BirchKMeans 
DBSCAN 
Birch 
SpectralClustering
Feature Engineering Algorithms 
(e.g. data pre-processing)
 TFIDF (term-frequency x inverse document-frequency)‚Äì Transform free-form text into numeric fields
StandardScaler (i.e. normalization)
FieldSelector (i.e. choose K best features for 
regression/classification)
 PCA and KernelPCA
‚ÄúPipeline‚Äù Multiple Algorithms
 Example: Text AnalyticsExample: Text Analytics
‚Äì TFIDF to transform free-form messages into numeric fields, 	followed by‚Ä¶
	√™ KMeans to group similar messages
√™ BernoulliNB to classify messages (e.g. according to sentiment) √™ PCA to visualize distribution of messages
|  | ‚Äì | ‚Ä¶ | fit TFIDF message | fit Kmeans message_tfidf_* | ... |
|---|---|---|
|  |Analogous to Pipeline concept from sklearn or Spark MLLib |Analogous to Pipeline concept from sklearn or Spark MLLib |46
47
48
‚ÄúPipeline‚Äù Multiple Algorithms
 ML-SPL analytics are stackable.
Very advanced ML use-cases are succinctly expressible.
49
Tips for Feature Engineering
Tips for Feature Engineering
 Work on aggregates, not raw events.
‚Äì DO NOT use fit on 1,000,000,000 events. DO use stats.
Use eval to compute new features.
Use streamstats to construct leading indicators.
‚Ä¶
Work on aggregates, not raw events‚Ä¶
Work on aggregates, not raw events
‚Ä¶ | fit KMeans k=10 
downloads purchases posts days_active visits_per_day into user_behavior_clusters
 Use stats and lookup tables to construct features:
index=activity_logs 
| stats count by action user_id 
| xyseries user_id action count | fillnull | lookup user_activity user_id 
	OUTPUT days_active visits_per_day | fit KMeans k=10 ‚Ä¶
Use eval to compute new featuresUse eval to compute new features
 Coerce numbers into categories by prepending a string:‚Äì ‚Ä¶ | eval region_id = ‚ÄúRegion ‚Äù + region_id | ‚Ä¶
Model interactions between features:
‚Äì ‚Ä¶ | eval X_factor = importance * urgency | ‚Ä¶
‚Äì Use + for categorical fields, * for numeric
 Make non-linear features out of numeric values:
‚Äì ‚Ä¶ | eval temperature = pow(temperature,2) | ‚Ä¶
‚Äì ‚Ä¶ | eval latency = log(latency) | ‚Ä¶‚Äì ‚Ä¶ | eval latency = log(latency) | ‚Ä¶
53
54
55
Use streamstats for leading indicators
index=application_log OR index=tickets 
| timechart span=1d count(failure) as FAILS, 
	count(‚ÄúChange Request‚Äù) as CHANGES 
| reverse 
| streamstats window=3 sum(FAILS) as FAILS_NEXT_3DAYS | reverse 
| fit LinearRegression FAILS_NEXT_3DAYS from CHANGES 	into FAILS_PREDICTION_MODEL
56
Wrap-up
What did we cover?56
Wrap-up
What did we cover?
 Machine Learning + Splunk 
ML-SPL: Machine Learning in SPL
‚Äì What it is
‚Äì How it works 
Overview of Algorithms and Analytics available in ML-SPL Tips for Feature Engineering in SPL
58
What Now? 
 Install the ML Toolkit from Splunkbase!
‚Äì http://tiny.cc/splunkmlapp 
Don‚Äôt miss Manish Sainani‚Äôs or Adam Oliner‚Äôs talks!Product Manager: Manish Sainani  Field Expert: Andrew Stein  
Me: Jacob Leverich 
59
THANK YOU
fit: Misc. details
 Multi-class classification problems typically modeled as‚Äúone-vs-rest‚Äù
Some algorithms do NOT support saved models, e.g.:‚Äì DBSCAN and SpectralClustering
61
ML-SPL Commands
 fit   from   into ‚Äì Fit (i.e. train) a model from search results
 apply 
‚Äì Apply a model to obtain predictions from (new) search results
 summary 
‚Äì Inspect the model inferred by  (e.g., display coefficients)
Slide Title