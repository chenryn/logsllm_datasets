[17] NICOLAS FALLIERE, LIAM O MURCHU, ERIC CHIEN.
W32. Stuxnet Dossier. http://www.bbc.com/news/
technology-36478650, 2011.
[18] PAXSON, V., AND FLOYD, S. Wide area trafﬁc: the
failure of poisson modeling. IEEE/ACM Transactions
on Networking (ToN) 3, 3 (1995), 226–244.
[19] PHAM, D. V., HALGAMUGE, M. N., SYED, A., AND
MENDIS, P. Optimizing windows security features to
block malware and hack tools on usb storage devices.
In Progress in electromagnetics research symposium
(2010), pp. 350–355.
[20] RICH, D. Authentication in transient storage device
attachments. Computer 40, 4 (2007).
[21] SCHUMILO, S., AND SPENNEBERG, R. Don’t trust
your usb! how to ﬁnd bugs in usb device drivers.
[22] SHIN, S., AND GU, G. Conﬁcker and beyond: a large-
scale empirical study. In Proceedings of the 26th Annual
Computer Security Applications Conference (2010),
ACM, pp. 151–160.
[23] TETMEYER, A., AND SAIEDIAN, H. Security threats
and mitigating risk for usb devices. IEEE Technology
and Society Magazine 29, 4 (2010), 44–49.
100          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association[24] TIAN, D. J., BATES, A., AND BUTLER, K. Defend-
ing against malicious usb ﬁrmware with goodusb. In
Proceedings of the 31st Annual Computer Security Ap-
plications Conference (2015), ACM, pp. 261–270.
[25] TIAN, D. J., BATES, A., BUTLER, K. R., AND RAN-
GASWAMI, R. Provusb: Block-level provenance-based
data protection for usb storage devices. In Proceedings
of the 2016 ACM SIGSAC Conference on Computer and
Communications Security (2016), CCS ’16, pp. 242–
253.
[26] TIAN, D. J., SCAIFE, N., BATES, A., BUTLER, K.,
AND TRAYNOR, P. Making usb great again with usbﬁl-
ter. In Proceedings of the USENIX Security Symposium
(2016).
[27] TIAN, J., SCAIFE, N., KUMAR, D., BAILEY, M.,
BATES, A., AND BUTLER, K. Sok: "plug & pray" today
- understanding usb insecurity in versions 1 through c.
In 2018 IEEE Symposium on Security and Privacy (SP),
vol. 00, pp. 613–628.
[28] TISCHER, M., DURUMERIC, Z., FOSTER, S., DUAN,
S., MORI, A., BURSZTEIN, E., AND BAILEY, M. Users
Really Do Plug in USB Drives They Find. In Proceed-
ings of the 37th IEEE Symposium on Security and Pri-
vacy (S&P ’16) (San Jose, California, USA, May 2016).
[29] WATSON, G. S., AND DURBIN, J. Exact tests of serial
correlation using noncircular statistics. The Annals of
Mathematical Statistics (1951), 446–451.
[30] YANG, B., QIN, Y., ZHANG, Y., WANG, W., AND
FENG, D. Tmsui: A trust management scheme of usb
storage devices for industrial control systems. In Interna-
tional Conference on Information and Communications
Security (2015), Springer, pp. 152–168.
[31] ZHUANG, L., AND DAI, H. Parameter optimization of
kernel-based one-class classiﬁer on imbalance learning.
Journal of Computers 1, 7 (2006), 32–40.
A Model Search Conﬁgurations
Table 6 represents all the possible conﬁgurations for training
the detection model.
Conﬁguration Setting
Error Upper Bound (ν)
Kernel Coefﬁcient (γ)
Degree of Polynomial
Kernel Functions
Total
Values
[0.01, 0.25, 0.5, 0.75, 1]
[0.1, 0.01, 0.001, 0.0001]
[1, 2, 3]
RBF, ν,γ
Sigmoid, ν,γ
Linear, ν
Polynomial, ν,γ, degree
#
–
–
–
20
20
5
60
105
Table 6: All combinations of parameters for any applicable ν, γ, and
degree settings for each kernel option. Deﬁning this parameter space
results in 105 parameter settings to apply to SVM instances.
B Case Studies
As mentioned earlier, an attacker has signiﬁcant freedom in
developing malicious code that can potentially bypass USBE-
SAFE. Therefore, as an end-point solution, it is quite useful
to study how the system responds to different levels of attack
sophistication. To this end, we ran each of the following at-
tacks, collected the corresponding USB traces, and measured
the percentage of USB packets in each attack that was novel
to the system based on the model learned on each machine.
Attack No. 1: Running a Malicious Payload By running
a malicious payload, we speciﬁcally focus on executing com-
mands to call a binary that downloads code from the Internet,
and installs malware. Note that this attack can be designed to
be as stealthy as possible. For example, the malicious code
can start when the user is logged off with the assumption that
the user is very likely not physically present.
Our analysis showed that this attack had an average novelty
score of 47.9% when tested with different learned models.
Our further investigation revealed that the USB packets re-
ceived a relatively high novelty score compared to the learned
model because the interarrival time values among URBs was
Machine
Machine6
Machine7
Machine8
Machine9
Machine10
Machine11
Machine12
Average
Attack1
Attack2
Attack3
63.2%
54.5%
49.8%
31.5%
41.2%
46.5%
49.1%
47.9%
58.2%
52.5%
40.8%
17.4%
42.8%
47.6%
49.3%
44.1%
37.3%
42.4%
19.2%
30.8%
30.6%
29.8%
33.6%
27.1%
Table 7: the novelty score of the evasion tests in the real-
world deployment. The novelty score of all the attacks are
signiﬁcantly higher than the threshold value (t = 13.2%).
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 101signiﬁcantly smaller than most of real user typing behaviors.
Furthermore, the 2-gram analysis shows that the average con-
tent histogram of the ﬁrst 103 request packets were more than
195 during the command injection which was signiﬁcantly
higher than the content of the USB packets in the benign
dataset.
Attack No. 2: Adding Artiﬁcial Delays A question that
arises is that in the previous attack, the malicious code
launched a list of commands immediately after the enumera-
tion phase. We updated the code to wait for a random period
of time similar to the stalling code in malware attacks [10,11],
and then open a terminal to run the commands. Our analysis
revealed that this attack could bypass the post-enumeration
feature by waiting for a random period of time before run-
ning the commands. As shown in Table 7, compared to attack
No. 1, the novelty score of the malicious code decreased in all
the machines. However, USBESAFE reported this attack as a
new observation as the interarrival of the packets was still too
small.
Attack No. 3: Manipulating the Interarrival Times We
enhanced the attack payload to be more stealthy by adding
delays among the injected commands in order to simulate
human typing patterns. The delays were injected such that the
arrivals of URBs followed Poisson distribution. We used Pois-
son distribution as we observed in Section 5 that the URBs’
interarrivals in our labeled dataset can be well-modeled us-
ing Poisson. While the novelty score of the USB trafﬁc in
attack 3 (see Table 7) is relatively lower than the novelty
score of the other attacks, the attack is still detected since
the novelty scores of the USB trafﬁc in all the traces are sig-
niﬁcantly higher than the pre-deﬁned threshold (t = 13.2%).
Further analysis suggests that injecting artiﬁcial delays with
Poisson distribution during the command injection phase is
not sufﬁcient to automatically generate very serious mimicry
attacks that perfectly resemble users’ typing patterns. In fact,
we empirically found that to successfully run such attacks,
the adversary needs a more precise mechanism to learn the
normal typing behavior of individual users. This makes craft-
ing mimicry attacks more complicated as the adversary has
to incorporate other techniques to reliably hook certain OS
functions in order to learn the typing pattern of each user.
This particular area has been studied extensively in malware
detection, i.e., spyware detection, and is out of the scope of
this paper.
C Benchmarks
Since USBESAFE is intended as an online monitoring sys-
tem, it may impact the performance of other applications or
the operating system. We expect USBESAFE’s performance
overhead to be overshadowed by I/O processing delays, but
in order to obtain measurable performance indicators and
characterize the overhead of USBESAFE, we ran experiments
that exercised the critical performance paths of USBESAFE.
Note that designing custom test cases and benchmarks require
careful consideration of factors that might inﬂuence our run-
time measurements. In these tests, we mainly focused on the
core parts of the USB device communication which were the
USB device enumeration and data transfer mechanisms. We
explain each of these benchmarks in more details below.
Device Enumeration In the ﬁrst experiment, we tested
whether USBESAFE introduces any noticeable performance
impact during the USB enumeration phase. The testing USB
device was a headset which had a HID interface. We manu-
ally plugged the headset into the host 20 times and compared
the results between USBESAFE-enhanced host and the stan-
dard machine. The average USB enumeration time was 37.4
ms for the standard system and 39.1 ms for the USBESAFE-
enhanced host respectively. Comparing to the standard host,
USBESAFE only introduced 4.5% or less than 2 ms. We cre-
ated the same benchmark using a mouse, and repeated it for
20 times. The system imposed 4.1% or 1.4 ms for device enu-
meration. The measurement results imply that USBESAFE
does not have a signiﬁcant impact on the enumeration of USB
devices. More details are provided in Table 8.
USB Packet Inspection In the second experiment, we cre-
ated a benchmark to characterize the performance overhead
of our system during a normal device use. To measure the
overhead of the detection model, we plugged in a USB optical
mouse and moved it around to generate USB trafﬁc. We then
measured the time used by USBESAFE to determine whether
the incoming USB packets should be ﬁltered or not. The re-
quired time is calculated from the time a URB is delivered
to the packet inspection subsystem to the time the packet is
analyzed by the protection engine. We tested the experiment
on the ﬁrst 2,000 URBs, and repeated the experiment 10 times
as shown in Table 8. As shown, the average cost per URB is
12.7 µs, including the time used by the benchmark to get the
timing and print the results.
File System We also created a benchmark to measure the
latency of ﬁle operations under the baseline and USBESAFE-
enabled machines. The goal of the experiment is to measure
the performance overhead of the system during normal usage
of a USB storage device, where users plug in ﬂash drives to
copy or edit ﬁles. We ran the experiments using a 16 GB USB
ﬂash drive and varied ﬁle sizes from 1 KB to 1 GB. Each test
was done 10 times and the average was calculated. As shown,
the throughput of USBESAFE is close to baseline when the
ﬁle size is less than 100 MB (approximately 3.9%). When
the mean ﬁle size becomes greater than 100 MB, USBESAFE
shows lower throughput compared to the standard machine
102          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationas a result of pattern monitoring on the bus. The results show
that USBESAFE imposes 7.2% and 11.4% overhead when
the mean ﬁle sizes are 100 MB and 1 GB respectively. For
example, if a user wants to copy 10 100 MB ﬁles, throughput
would drop from 8.9 MB/s to 8.26 MB/s when USBESAFE
is enabled on the user’s machine.
Experiment
Device
Standard
USBESAFE
Overhead
Enumeration
Overhead Mean
Event Inspection
Overhead Mean
(per packet)
Head Set
Mouse
Keyboard
Mass Storage
Mouse
Keyboard
37.4 ms
33.5 ms
34.2 ms
36.6 ms
35.4 ms
-
-
-
39.1 ms
34.9 ms
35.6 ms
38 ms
36.8 ms
12.3 µs
13.1 µs
12.7 µs
4.5%
4.1%
4.2%
3.9%
4.2%
-
-
-
Table 8: USBESAFE’s overhead on the USB communication
protocol. USBESAFE imposes on average 4.2% overhead
during the enumeration phase and 12.7 µs per packet during
USB packet inspection.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 103