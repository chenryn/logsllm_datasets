title:Dynamic provable data possession
author:C. Christopher Erway and
Alptekin K&quot;upç&quot;u and
Charalampos Papamanthou and
Roberto Tamassia
Dynamic Provable Data Possession
C. Chris Erway
Brown University
Alptekin Küpçü
Brown University
Charalampos Papamanthou
Brown University
Roberto Tamassia
Brown University
ABSTRACT
We consider the problem of efﬁciently proving the integrity of data
stored at untrusted servers. In the provable data possession (PDP)
model, the client preprocesses the data and then sends it to an un-
trusted server for storage, while keeping a small amount of meta-
data. The client later asks the server to prove that the stored data
has not been tampered with or deleted (without downloading the
actual data). However, the original PDP scheme applies only to
static (or append-only) ﬁles.
We present a deﬁnitional framework and efﬁcient constructions
for dynamic provable data possession (DPDP), which extends the
PDP model to support provable updates to stored data. We use a
new version of authenticated dictionaries based on rank informa-
tion. The price of dynamic updates is a performance change from
O(1) to O(log n) (or O(nǫ log n)), for a ﬁle consisting of n blocks,
while maintaining the same (or better, respectively) probability of
misbehavior detection. Our experiments show that this slowdown
is very low in practice (e.g., 415KB proof size and 30ms compu-
tational overhead for a 1GB ﬁle). We also show how to apply our
DPDP scheme to outsourced ﬁle systems and version control sys-
tems (e.g., CVS).
Categories and Subject Descriptors
C.2.4 [Communication Networks]: Distributed Systems; E.1
[Data Structures]; H.3.4 [Information Storage and Retrieval]:
Systems and Software
General Terms
Security, Algorithms, Theory, Veriﬁcation
Keywords
Authentication, Provable data possession, Skip list,
Integrity
checking, Outsourced storage, Proof of retrievability, authenticated
data structures
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’09, November 9–13, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-352-5/09/11 ...$10.00.
1.
INTRODUCTION
In cloud storage systems, the server (or peer) that stores the
client’s data is not necessarily trusted. Therefore, users would like
to check if their data has been tampered with or deleted. However,
it is inefﬁcient for the client to download all stored data in order to
validate its integrity, even when using authenticated data structures
solutions [31].
Ateniese et al. [2] have formalized a model called provable data
possession (PDP). In this model, data (often represented as a ﬁle
F ) is preprocessed by the client, and metadata used for veriﬁca-
tion purposes is produced. The ﬁle is then sent to an untrusted
server for storage, and the client may delete the local copy of the
ﬁle. The client keeps some (possibly secret) information to check
server’s responses later. The server proves the data has not been
tampered with by responding to challenges sent by the client. The
authors present several variations of their scheme under different
cryptographic assumptions. These schemes provide probabilistic
guarantees of possession, where the client checks a random subset
of stored blocks with each challenge.
However, PDP and related schemes [2, 7, 13, 30] apply only to
the case of static, archival storage, i.e., a ﬁle that is outsourced and
never changes (simultaneously with our work, Ateniese et al. [3]
present a scheme with somewhat limited dynamism, which is dis-
cussed in detail in the related work section). While the static
model ﬁts some application scenarios (e.g., libraries and scientiﬁc
datasets), it is crucial to consider the dynamic case, where the client
updates the outsourced data—by inserting, modifying, or deleting
stored blocks or ﬁles—while maintaining data possession guaran-
tees. Such a dynamic PDP scheme is essential in practical cloud
computing systems for ﬁle storage [14, 17], database services [18],
and peer-to-peer storage [15, 19].
In this paper, we introduce a framework and efﬁcient construc-
tions for dynamic provable data possession (DPDP), which extends
the PDP model to support provable updates on the stored data.
Given a ﬁle F consisting of n blocks, we deﬁne an update as either
insertion of a new block (anywhere in the ﬁle, not only append), or
modiﬁcation of an existing block, or deletion of any block. There-
fore our update operation describes the most general form of mod-
iﬁcations a client may wish to perform on a ﬁle.
Our DPDP solution is based on a new variant of authenticated
dictionaries, where we use rank information to organize dictionary
entries. Thus we are able to support efﬁcient authenticated oper-
ations on ﬁles at the block level, such as authenticated insert and
delete. We prove the security of our constructions using standard
assumptions.
We also show how to extend our construction to support data
possession guarantees of a hierarchical ﬁle system as well as ﬁle
data itself. To the best of our knowledge, this is the ﬁrst construc-
213Scheme
Server
computation
PDP [2]
O(1)
Scalable PDP [3] O(1)
DPDP I
DPDP II
Client
computation
O(1)
O(1)
O(log n)
O(log n)
O(nǫ log n) O(log n)
Communication Model
complexity
O(1)
O(1)
O(log n)
O(log n)
random oracle X
random oracle X∗
standard
X
standard
X
X∗
X
X
X∗
X
X
X
X
Block operations
insert
append modify
delete
Probability
of detection
1 − (1 − f )C
1 − (1 − f )C
1 − (1 − f )C
1 − (1 − f )Ω(log n)
Table 1: Comparison of PDP schemes: original PDP scheme [2]; Scalable PDP [3]; our scheme based on authenticated skip lists
(DPDP I); and our scheme based on RSA trees (DPDP II). A star (*) indicates that a certain operation can be performed only a
limited (pre-determined) number of times. We denote with n the number of the blocks of the ﬁle, with f the fraction of the corrupted
blocks, and with C a constant, i.e., independent of n. In all constructions, the storage space is O(1) at the client and O(n) at the
server.
tion of a provable storage system that enables efﬁcient proofs of a
whole ﬁle system, enabling veriﬁcation at different levels for differ-
ent users (e.g., every user can verify her own home directory) and at
the same time not having to download the whole data (as opposed
to [11]). Our scheme yields a provable outsourced versioning sys-
tem (e.g., CVS), which is evaluated in Section 8 by using traces of
CVS repositories of three well-known projects.
1.1 Contributions
The main contributions of this work are summarized as follows:
(1) We introduce a formal framework for dynamic provable data
possession (DPDP); (2) We provide the ﬁrst efﬁcient fully dynamic
PDP solution; (3) We present a rank-based authenticated dictio-
nary built over a skip list. This construction yields a DPDP scheme
with logarithmic computation and communication and the same de-
tection probability as the original PDP scheme (DPDP I); (4) We
give an alternative construction (Section 6) of a rank-based authen-
ticated dictionary using an RSA tree [25]. This construction results
in a DPDP scheme with improved detection probability but higher
server computation (DPDP II); (5) We present practical applica-
tions of our DPDP constructions to outsourced ﬁle systems and
versioning systems (e.g., CVS, with variable block size support);
(6) We perform an experimental evaluation of our skip list-based
scheme.
Now, we outline the performance of our schemes. Denote with
n the number of blocks. The server computation, i.e., the time
taken by the server to process an update or to compute a proof for
a block, is O(log n) for DPDP I and O(nǫ log n) for DPDP II;
the client computation, i.e., the time taken by the client to verify
a proof returned by the server, is O(log n) for both schemes; the
communication complexity, i.e., the size of the proof returned by
the server to the client, is O(log n) for both schemes; the client
storage, i.e., the size of the meta-data stored locally by the client,
is O(1) for both schemes; ﬁnally, the probability of detection, i.e.,
the probability of detecting server misbehavior, is 1 − (1 − f )C for
DPDP I and 1 − (1 − f )Ω(log n) for DPDP II, for ﬁxed logarithmic
communication complexity, where f is the ratio of corrupted blocks
and C is a constant, i.e., independent of n.
We observe that for DPDP I, we could use a dynamic Merkle tree
(e.g., [16, 20]) instead of a skip list to achieve the same asymptotic
performance. We have chosen the skip list due to its simple imple-
mentation and the fact that algorithms for updates in the two-party
model (where clients can access only a logarithmic-sized portion
of the data structure) have been previously studied in detail for au-
thenticated skip lists [24] but not for Merkle trees.
1.2 Related work
The PDP scheme by Ateniese et al. [2] provides an optimal pro-
tocol for the static case that achieves O(1) costs for all the com-
plexity measures listed above. They review previous work on pro-
tocols ﬁtting their model, but ﬁnd these approaches lacking: either
they require expensive server computation or communication over
the entire ﬁle [10, 22], linear storage for the client [29], or do not
provide security guarantees for data possession [28]. Note that us-
ing [2] in a dynamic scenario is insecure due to replay attacks. As
observed in [8], in order to avoid replay attacks, an authenticated
tree structure that incurs logarithmic costs must be employed and
thus constant costs are not feasible in a dynamic scenario.
Juels and Kaliski present proofs of retrievability (PORs) [13],
focusing on static archival storage of large ﬁles. Their scheme’s ef-
fectiveness rests largely on preprocessing steps the client conducts
before sending a ﬁle F to the server: “sentinel” blocks are ran-
domly inserted to detect corruption, F is encrypted to hide these
sentinels, and error-correcting codes are used to recover from cor-
ruption. As expected, the error-correcting codes improve the error-
resiliency of their system. Unfortunately, these operations prevent
any efﬁcient extension to support updates, beyond simply replac-
ing F with a new ﬁle F ′. Furthermore, the number of queries a
client can perform is limited, and ﬁxed a priori. Shacham and Wa-
ters have an improved version of this protocol called Compact POR
[30], but their solution is also static (see [7] for a summary of POR
schemes and related trade-offs).
Simultaneously with our work, Ateniese et al. have developed
a dynamic PDP solution called Scalable PDP [3]. Their idea is
to come up with all future challenges during setup and store pre-
computed answers as metadata (at the client, or at the server in an
authenticated and encrypted manner). Because of this approach,
the number of updates and challenges a client can perform is lim-
ited and ﬁxed a priori. Also, one cannot perform block inser-
tions anywhere (only append-type insertions are possible). Fur-
thermore, each update requires re-creating all the remaining chal-
lenges, which is problematic for large ﬁles. Under these limitations
(otherwise the lower bound of [8] would be violated), they provide
a protocol with optimal asymptotic complexity O(1) in all com-
plexity measures giving the same probabilistic guarantees as our
scheme. Lastly, their work is in the random oracle model whereas
our scheme is provably secure in the standard model (see Table 1
for full comparison).
Finally, our work is closely related to memory checking, for
which lower bounds are presented in [8, 21]. Speciﬁcally, in [8] it
is proved that all non-adaptive and deterministic checkers have read
and write query complexity summing up to Ω(log n/ log log n)
(necessary for sublinear client storage), justifying the O(log n)
cost in our scheme. Note that for schemes based on cryptographic
hashing, an Ω(log n) lower bound on the proof size has been
shown [6, 32]. Related bounds for other primitives have been
shown by Blum et al. [4].
2142. MODEL
We build on the PDP deﬁnitions from [2]. We begin by introduc-
ing a general DPDP scheme and then show how the original PDP
model is consistent with this deﬁnition.
DEFINITION 1
(DPDP SCHEME). In a DPDP scheme, there
are two parties. The client wants to off-load her ﬁles to the un-
trusted server. A complete deﬁnition of a DPDP scheme should
describe the following (possibly randomized) efﬁcient procedures:
• KeyGen(1k) → {sk, pk} is a probabilistic algorithm run by the
client. It takes as input a security parameter, and outputs a secret
key sk and a public key pk. The client stores the secret and public
keys, and sends the public key to the server;
• PrepareUpdate(sk, pk, F , info, Mc) → {e(F ), e(info), e(M )}
is an algorithm run by the client to prepare (a part of) the ﬁle
for untrusted storage. As input, it takes secret and public keys,
(a part of) the ﬁle F with the deﬁnition info of the update to
be performed (e.g., full re-write, modify block i, delete block i,
add a block after block i, etc.), and the previous metadata Mc.
The output is an “encoded” version of (a part of) the ﬁle e(F )
(e.g., by adding randomness, adding sentinels, encrypting for
conﬁdentiality, etc.), along with the information e(info) about
the update (changed to ﬁt the encoded version), and the new
metadata e(M ). The client sends e(F ), e(info), e(M ) to the
server;
c, PM ′
• PerformUpdate(pk, Fi−1, Mi−1, e(F ), e(info), e(M ))
→
c } is an algorithm run by the server in response
{Fi, Mi, M ′
to an update request from the client. The input contains the pub-
lic key pk, the previous version of the ﬁle Fi−1, the metadata
Mi−1 and the client-provided values e(F ), e(info), e(M ). Note
that the values e(F ), e(info), e(M ) are the values produced by
PrepareUpdate. The output is the new version of the ﬁle Fi and
the metadata Mi, along with the metadata to be sent to the client
c to the client;