### Recovery Process and Synchronization

The recovery process is designed to minimize the delay to ongoing computations. When a Voter-Driver, which can be either a Master or a Slave, detects an error, it initiates a recovery process and then returns to its normal operations. This ensures that the disruption to the system is minimal.

If the Voter-Driver is a Slave and finds that it agrees with the Master but another Slave disagrees, it takes the same action as the Master. This keeps the agreeing Slave in synchronization with the Master. It is important to note that the agreeing Master and Slave will command the disagreeing module to drop out immediately, and the system will continue with the remaining modules, maintaining tighter synchronization. Figure 3 illustrates this process under error-free conditions.

### Input Comparison

All Master and Slave modules execute the same inputs independently. However, due to slight differences in timing and potential variations in input values (e.g., from on-chip A/D converters), an exchange is necessary to achieve interactive consistency. The Master sends the value it received via the Master Channel, and the Slaves compare this value with their own. If the Master’s value is acceptably close to the value they obtained, the Slaves signal "agree" via the status channel; otherwise, they signal "disagree." If at least one Slave agrees with the Master, all Slaves use the Master’s input value.

### Recovery of Well-Behaved Errors

#### Single Slave Error
If a Slave disagrees during the comparison interval, the comparison result is unambiguous. If a Slave fails to respond, the Master waits until the end of its timeout interval to drop the compare request, which causes the statuses to be sampled by the error-free Slaves, forcing the completion of the comparison process. The Slave timeout counts are set longer than the Master's timeout to ensure this. The agreeing Master and Slave then command the non-agreeing module to drop out and schedule its reinitialization.

#### Master Error
In the case of a Master error, there will be no agreement. The Master may not request a comparison or may do so at an unexpected time. Here, the Slaves must detect the problem and quickly assign a new Master. This is done by the Slaves recognizing that they have all timed out, leading to the rapid selection of a new Master from among them by changing their Assignment Channel Vote.

### Recovery of Ill-Behaved Errors

The comparison approach described here is subject to complex error detection conditions. A module may signal false agreement or disagreement, and Byzantine errors are possible. Even if these errors occur infrequently, the large number of transient faults ensures that they will happen occasionally. Noise on a status line can cause the Master and Slaves to see different status symbols from the same module. Additionally, "falling-in-the-cracks" errors can occur where a faulty module's status value changes between the times it is sampled by other units, causing them to get a different view of the error state.

Our approach is that if any module does not see progress as part of an agreeing set, it drops out and sets its assignment channel symbol to "unavailable." This is supported by hardware that expects periodic heartbeat messages from an agreeing Master and Slave, and will force the module to drop out if these messages are not received.

After dropping out, each module runs a hardware diagnostic program and checks the consistency of the programs in its memory. If successful, the module sets its assignment channel symbol to "off-line" (indicating it is ready for use). It also checks the assignment channel at each Real-Time Interrupt (RTI) to see if there is still a Master with a Slave voting for it. If this is the case, the module waits to be configured and restarted by the Master. If not, the off-line module can signal via its assignment channel that it intends to become involved in a system restart. When two modules are found, they vote for one as a new Master and the other as a Slave, and the system is restarted.

### Node-Level Fault-Insertion Testing

Initial testing used a software filter as a real-time application program to provide a synthetic workload. The approach was to run the programs in a node without errors and record the inputs and outputs using the Testbed Control Computer and its digital acquisition boards. Then, the programs were re-run while faults were inserted into the various microcontroller modules.

The first fault-insertion tests were primarily for debugging. After getting multiple modules running redundantly within a node, specific error conditions were inserted to test key aspects of the design. For example, outputs were modified in a Master or Slave to cause a disagreement, while the program flow (and thus I/O timing between modules) was not disturbed. Modules were also prevented from generating an output to test the timeout mechanism. These faults identified some design, software, and wiring errors that were corrected over several months.

The second phase involved inserting single faults by: (1) halting the node by failing to issue an RTI, (2) modifying random data memory locations, and (3) restarting the RTI and observing the effects on program execution. An automated program was written to randomly insert errors in memory in Master and Slave modules and observe the effects on program execution by sampling the output results and the status and assignment channels of all modules. After inserting thousands of errors in triplicated and quad module nodes, only a small fraction (about 3%) affected the output results, likely due to the simplicity of the initial test program and the fact that many variables are recomputed at the beginning of each RTI.

### Conclusion

An architecture has been developed for fault-tolerant nodes, with fault-detection largely implemented by software, but special hardware protection is added to protect critical functions. The fault-tolerance approach depends on knowing that a Master and Slave are operating together and agreeing on their computations. Special timeout hardware is added to restart the system if software recovery techniques fail and the Master and Slave are no longer maintaining the computations.

This approach prioritizes availability, and the vast majority of recovery events will be caused by radiation-induced transient errors that can be cleared by roll-forwards of single modules and occasional system restarts. The strategy is to demonstrate the stability of the recovery algorithms.

A set of eight microcontroller modules were built and integrated into a testbed of the proposed architecture. System executive software has been developed to support foreground and background application processes on the nodes, and to schedule voting and recovery procedures. Voting and recovery algorithms have been implemented and have undergone preliminary testing in nodes of triplicated and quad microcontrollers. The results so far are highly encouraging, and an extensive fault-insertion campaign is planned.

We expect that the results will enable the use of a new class of ultra-low-cost fault-tolerant embedded systems and shed light on fault-tolerant design techniques where the individual components are highly-integrated systems-on-a-chip, and on the degree of resilience that can be achieved.