# Verification of Common 802.11 MAC Model Assumptions

**Authors:**
- David Malone
- Ian Dangerfield
- Doug Leith

**Institution:**
- Hamilton Institute, NUI Maynooth, Ireland

**Abstract:**
Analytic models of the 802.11 MAC layer have achieved significant success, often relying on a set of fundamental assumptions. This paper aims to validate these assumptions through meticulous measurements using an 802.11e testbed with commercial hardware. Our findings indicate that while some assumptions do not always hold, our measurements provide insights into why these models can still offer accurate predictions. To our knowledge, this is the first detailed attempt to compare 802.11 models and their underlying assumptions with experimental data from an 802.11 testbed. Additionally, our measurements allow us to verify if the basic MAC operations comply with the 802.11 standards.

## 1. Introduction
The analysis of the 802.11 CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance) contention mechanism has generated extensive literature. Two particularly successful approaches are the use of pure p-persistent modeling (e.g., [3]) and the per-station Markov chain technique (e.g., [2]). These models typically rely on certain assumptions. For instance, both models assume that transmission opportunities occur at discrete times, corresponding to the contention counter decrements of the stations. This results in an effective slotting of time, which is different from the time slotting used by the PHY (Physical Layer). Another key assumption is that, to a station observing the wireless medium, every slot is equally likely to herald the beginning of a transmission by one or more other stations, often manifesting as a constant transmission or collision probability.

In this paper, we present detailed measurements collected from an experimental testbed to study these assumptions. Our goal is to understand the predictive power of these models and to inform future modeling efforts. The contributions of this paper include the first published measurements of packet collision probabilities from an experimental testbed, their comparison with model predictions, and the first detailed comparison of measured and predicted throughputs under various conditions.

We are not the first to consider the impact of model assumptions. Specifically, the modeling of 802.11e has required special treatment of slots immediately after a transmission to accommodate differentiation based on AIFS (Arbitration Interframe Space) (e.g., [1, 9, 11, 6, 4]). In [13], the non-uniform nature of slots is used to motivate an 802.11e model that moves away from these assumptions.

## 2. Test Bed Setup
Our 802.11e wireless testbed is configured in infrastructure mode. It consists of:
- A desktop PC acting as an access point.
- 18 PC-based embedded Linux boxes based on the Soekris net4801 [7].
- One desktop PC acting as a client station, recording delay measurements and retry attempts for each packet but otherwise behaving as an ordinary client station.

All systems are equipped with an Atheros AR5215 802.11b/g PCI card with an external antenna. The Linux 2.6.8.1 kernel and a modified version of the MADWiFi [8] wireless driver are used to adjust 802.11e parameters such as CWmin, AIFS, and TXOP. Each system also has a 100 Mbps wired Ethernet port for testbed control. Specific vendor features, such as turbo mode, are disabled. All tests are performed using the 802.11b physical maximal data transmission rate of 11 Mbps, with RTS/CTS disabled and the channel number explicitly set. We confirmed that the hardware performance (especially the CPU) of the low-power embedded systems is not a bottleneck for wireless transmissions at the 11 Mbps PHY rate.

A desktop PC is used as a client to record per-packet measurements, including numbers of retries and MAC-level service time. This ensures ample disk space, RAM, and CPU resources, so that statistics collection does not impact packet transmission.

Several software tools are used within the testbed to generate network traffic and collect performance measurements. For generating wireless network traffic, we use mgen, often employing Poisson traffic, as many analytic models make independent or Markov assumptions about the system. While many network monitoring programs and wireless sniffers exist, no single tool provides all the required functionality. Therefore, we use a combination of common tools, including tcpdump. Network management and control of traffic sources are carried out using SSH over the wired network.

## 3. Collision Probability and Packet Timing Measurement
Our testbed uses standard commodity hardware. In [5], we developed a measurement technique that relies solely on the sender's clock to avoid synchronization issues. By requesting an interrupt after each successful transmission, we can determine the time the ACK is received. We also record the time the packet was added to the hardware queue and use the standard FIFO queueing recursion to determine the time the MAC spent processing the packet. This process is illustrated in Figure 1.

For the measurements reported here, we refined the technique described in [5] by using a timer in the Atheros card that timestamps the moment completed transmit descriptors are DMAed to host memory. This avoids inaccuracies caused by interrupt latency/jitter, allowing us to take measurements with microsecond-level timing accuracy.

To measure packet collision probabilities, we use the fact that the transmit descriptors report the number of retry attempts \( R_i \) for each packet. Using this, we can estimate the total number of retries \( R \) and the average collision probability \( \frac{R}{P + R} \), where \( P \) is the number of successful packet transmissions. We can also generalize this to get the collision probability at the \( n \)-th transmission attempt as:

\[
\text{Collision Probability} = \frac{\# \text{ packets with } R_i \geq n}{\# \text{ packets with } R_i = n + \# \text{ packets with } R_i \geq n}
\]

This assumes that retransmissions are only due to collisions and not errors. We can estimate the error rate by measuring retransmissions in a network with one station. In our environment, the error rate is < 0.1%.

## 4. Validation
All the models we study assume that the 802.11 backoff procedure is correctly followed. Recent work [12] has shown that some commercial 802.11 cards can significantly violate the standards, either by not using the correct range for choosing backoffs or by not backoff at all. We first verify that the cards we use perform basic backoffs correctly, examining CWmin (the range of the first backoff in slots), AIFS (how many slots to pause before the backoff counter may be decremented), and TXOP (how long to transmit for).

To do this, we measure the MAC access delay, which is the delay associated with the contention mechanism used in 802.11 WLANs. The MAC layer delay, i.e., the delay from a packet becoming eligible for transmission to final successful transmission, can range from a few hundred microseconds to hundreds of milliseconds, depending on network conditions. Unlike [12], which uses custom hardware, we exploit the fine-grained timing information available using the measurement technique described in the previous section to make access delay measurements with standard hardware.

To test the basic backoff behavior of the cards, we transmitted packets from a single station with high-rate arrivals and observed the MAC access delay for each packet. Figure 2(a) shows a histogram of these times to a resolution of 1 μs for over 900,000 packets. We can see 32 sharp peaks, each separated by the slot time of 20 μs, representing a CWmin of 32. This gives us confidence that the card is not subject to the more serious problems outlined in [12].

There is jitter, either in the backoff process or in our measurement technique. However, we can test the hypothesis that this is a uniform distribution by binning the data into buckets around each of the 32 peaks and applying the chi-squared test. The resulting statistic is within the 5% level of significance.

Figure 2(b) shows the results when CWmin is adjusted to 4, showing 4 clear peaks as expected. We also see a small number of packets with longer transmission times, which we believe are delayed by the transmission of a beacon frame.

Figure 3(a) shows the impact of increasing AIFS on MAC access time. In the simple situation of a single station, we expect increasing AIFS to increase MAC access times by the amount AIFS is increased by. Comparing Figure 2(a) and Figure 3(a) confirms this.

Similarly, we can use TXOP on the cards to transmit bursts of packets, only the first of which must contend for channel access. Figure 3(b) shows the distribution of transmission times when two-packet bursts are used. We see that half the packets are transmitted in a time almost 50 μs shorter than the first peak shown in Figure 2(b).

These measurements indicate that a single card’s timing is quite accurate and capable of delivering transmissions timed to within slot boundaries. In this paper, we do not verify if multiple cards synchronize sufficiently to fully validate the slotted time assumption.

## 5. Collision Probability vs Backoff Stage
Intuitively, the models we are considering are similar to mean-field models in physics. A complex set of interactions is replaced with a single simple interaction that should approximate the system’s behavior. For example, by using a constant collision probability given by \( p = 1 - (1 - \tau)^{n-1} \), where \( \tau \) is the probability that a station transmits in a given slot and \( n \) is the number of contending stations.