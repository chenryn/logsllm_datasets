put onto a number of different states is called discretization.
This process is required to keep the CPTs of the Bayesian
network manageable and to allow efﬁcient calculations of
the probabilities at the hypothesis nodes. As shown in Ta-
ble 1, model outputs close to zero indicate normal features
while outputs close to one indicate anomalous ones.
Anomaly Score Range Level
[0.00, 0.50)
[0.50, 0.75)
[0.75, 0.90)
[0.90, 0.95)
[0.95, 1.00]
Normal
Uncommon
Irregular
Suspicious
Very Suspicious
Table 1. Anomaly Score Intervals
The Bayesian network in Figure 3 shows the two model
dependencies that we have introduced for our intrusion de-
tection system. One dependency connects the node cor-
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:47:09 UTC from IEEE Xplore.  Restrictions apply. 
responding to the output of the string length model to the
quality of the character distribution (which is also inﬂu-
enced by the conﬁdence in the output of the character dis-
tribution). The mediating node ‘Char Distribution
Quality’ in our network expresses the idea that the qual-
ity of the anomaly score calculated by the character distri-
bution is not only dependent on the ‘a-priori’ conﬁdence of
the model in the quality of its proﬁle, but also on the length
of the string that is currently analyzed. When this string
is very short, the quality of the statistical test that assesses
the character distribution is signiﬁcantly reduced. This is
reﬂected by the conditional probability tables of the ‘Char
Distribution Quality’ node.
The other dependency is introduced between the nodes
representing the character distribution and the structure
model. The reason is that an ‘abnormal’ character distri-
bution is likely to be reﬂected in a structure that does not
conform to the learned grammar. This is an example of a
simple positive correlation of output values between mod-
els.
During the analysis phase, the output of the four mod-
els and their conﬁdences are entered as evidence into the
Bayesian network. Then, the probabilities of the two states
(normal, anomalous) associated with the root node (Clas-
sification) are calculated. When the probability that
an event is anomalous is high enough, an alarm is raised.
Note that the requirement that the probability value being
‘high enough’ to raise an alarm could be interpreted as
a threshold as well. However, the difference is that this
probability value directly expresses the probability that a
certain event is an attack, given the speciﬁc structure of
the Bayesian network. The sum of model outputs in a
threshold-based system, on the other hand, is not neces-
sarily proportional to the probability of an event being an
attack.
It is possible, due to the assumption of indepen-
dence of model outputs and the potential lack of conﬁdence
information in these systems, that the sum of the outputs
is increasing while the probability of an attack is, in fact,
decreasing.
Both the threshold in a traditional system and the no-
tion of a sufﬁciently high probability for raising an alarm in
the Bayesian approach can be utilized to tune the sensitiv-
ity of the intrusion detection system. However, the result of
the Bayesian network directly reports the probability that an
event is anomalous, given the model outputs and the struc-
ture of the network, while a simple summation of model
outputs is only an approximation of this probability. The
difference between the exact value and the approximation
is important, and accounts for a signiﬁcant number of false
alarms, as shown in Section 6.
5.4 Bayesian Network Library - Smile
We implemented the models as part of a C++ library and
utilized a Bayesian statistics library called Smile [20], de-
veloped by the Decision Systems Laboratory at the Uni-
versity of Pittsburgh, for our event classiﬁcation module.
Smile was the best choice among the available statistical
software given the requirements that the package must im-
plement actual Bayesian networks rather than performing
Bayesian statistical analysis and must provide a usable API
rather than solely a GUI.
A problem with Smile is the fact that the source is not
freely available, and that its licensing precludes one from
using it in any open source software. Therefore, we wrote
adapter classes to provide an abstraction layer between our
modules and Smile. This allows for Smile’s replacement
should the issues become too great a liability.
The problem of belief propagation – that is, the calcula-
tion of probabilities at the hypothesis nodes when evidence
is entered at information nodes – is, in general, NP-hard [9].
Despite this fact, Smile implements efﬁcient algorithms that
can solve almost all problems in a reasonable amount of
time. Note also that the NP-hard calculations need to be
done only once, given that the information and hypothesis
nodes do not change. In addition, these calculations can be
done off-line. The computational cost during run-time to
evaluate particular values is linear in the number of nodes
in the network. Our proposed solution takes advantage of
this fact as the sets of information and hypothesis nodes re-
main static. This allows our system to analyze a stream of
system calls in real-time without incurring noticeable com-
putational or memory overhead.
6 Evaluation
For the purposes of evaluating our approach, we used the
MIT Lincoln Labs 1999 data set [11]. This data set consists
of a series of network packet dumps and BSM system call
records which have been widely used for intrusion detection
system development and evaluation. We used data recorded
during two attack-free weeks to train our models and then
ran the system on the complete test data that was recorded
during the two following weeks. Although several aspects
of the Lincoln Labs data have been criticized, it still remains
the most used large-scale data set to evaluate intrusion de-
tection systems [12].
The truth ﬁle provided by MIT Lincoln Labs lists all at-
tacks carried out against the network installation during the
two week test period. When analyzing the attacks, it turned
out that many of these were reconnaissance attempts such
as network scans or port sweeps, which are only visible in
the network dumps, and do not not leave any traces at the
system call level. Therefore, we could not detect them with
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:47:09 UTC from IEEE Xplore.  Restrictions apply. 
s
e
v
i
t
i
s
o
P
e
u
r
T
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0
Bayesian
Threshold
0.001
0.002
0.003
0.004
0.005
0.006
False Positives
Figure 4. ROC Comparison between Bayesian Network and Threshold-based System
our approach, which is limited to the analysis of system call
parameters.
Another class of attacks are policy violations. This class
of attacks contains intrusions that do not exploit a weak-
ness of the system itself, but rather exploit a mistake that an
administrator made in setting up the access control mecha-
nism. These attacks are not visible to our system either, as
information is leaked by ‘normal’ but unintended use of the
system.
The most interesting class of attacks are those that ex-
ploit a vulnerability in a remote or local service and al-
low an intruder to elevate her privileges. The MIT Lincoln
Labs data contains several instances of attacks that try to
exploit vulnerabilities in four different programs: eject,
fbconfig, fdformat, and ps. Figure 4 shows the Re-
ceiver Operating Characteristic (ROC) curves for our sys-
tem when monitoring these applications. The ROC of a
classiﬁer shows its performance as a trade off between se-
lectivity and sensitivity; a curve of the false positive rate
versus the true positive rate is plotted, while a sensitivity
or threshold parameter is varied. Ideally, a classiﬁer has a
true positive rate of 1 and a false positive rate of 0. The
ROC curve for the Bayesian event classiﬁer is plotted by
varying the ‘anomalous’ probability value that is required
for an event to be reported as an attack. The ROC curve
for the threshold-based classiﬁer is determined by vary-
ing the threshold that is compared to the sum of outputs.
The graphs show that both classiﬁers output some false
alarms when all attacks are correctly detected. However,
the Bayesian approach consistently performs better – when
all attacks are correctly detected (i.e., the true positive rate
is 1), it only reports half as many false positives. Note that
the shapes of the curves are not a consequence of an insuf-
ﬁcient number of data points. The horizontal and vertical
lines contain intermediate points, reﬂecting changes in ei-
ther the false positive or the true positive rate alone.
When analyzing the false positives raised by both classi-
ﬁcation approaches, we observed that the Bayesian scheme
always reported a subset of the false alarms raised by the
threshold-based mechanism. The false positives common
to both mechanisms are caused by system call invocations
that have arguments which signiﬁcantly deviate from all ex-
amples encountered during the training phase. This is due
to the fact that the training data for these particular system
calls was very homogeneous, leading to proﬁles that were
very sensitive to changes. During the detection phase, le-
gitimate system calls with signiﬁcantly different arguments
were observed. This resulted in their incorrect classiﬁca-
tion.
The system calls that were reported as anomalous by the
threshold-based approach but correctly classiﬁed as normal
by the Bayesian scheme were instances with short string ar-
guments. As explained in Section 5.3, short strings can sig-
niﬁcantly inﬂuence the quality of the character distribution
model, causing it to report incorrect anomalies. This prob-
lem is addressed by the Bayesian network using the medi-
ating ‘Char Distribution Quality’ node (see Fig-
ure 3), correctly evaluating these system calls as normal.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:47:09 UTC from IEEE Xplore.  Restrictions apply. 
7 Conclusions
[9] F. Jensen.
Bayesian Networks and Decision Graphs.
In this paper, we presented a novel method for perform-
ing Bayesian classiﬁcation of input events for intrusion de-
tection. We have improved upon the na¨ıve threshold-based
schemes traditionally used to combine model outputs by
employing Bayesian networks. This allows us to naturally
incorporate model conﬁdence and dependencies between
models into the event classiﬁcation process. The exper-
imental results show that a signiﬁcant reduction of false
alerts was achieved. When all attacks in our test data set
are detected, the Bayesian event classiﬁcation reports only
half as many false alerts as the traditional approach, based
on the same model outputs.
Acknowledgments
This research was supported by the Army Research Of-
ﬁce, under agreement DAAD19-01-1-0484. The U.S. Gov-
ernment is authorized to reproduce and distribute reprints
for Governmental purposes notwithstanding any copyright
annotation thereon.
The views and conclusions contained herein are those
of the authors and should not be interpreted as necessar-
ily representing the ofﬁcial policies or endorsements, either
expressed or implied, of the Army Research Ofﬁce, or the
U.S. Government.
References
[1] S. Axelsson. The Base-Rate Fallacy and its Implications for
the Difﬁculty of Intrusion Detection. In 6th ACM Confer-
ence on Computer and Communications Security, 1999.
[2] P. Billingsley. Probability and Measure. Wiley-Interscience,
3 edition, April 1995.
[3] Basic Security Module Guide – SunSHIELD BSM. http:
//docs.sun.com/db/doc/802-5757.
[4] D. Denning. An Intrusion Detection Model. IEEE Transac-
tions on Software Engineering, 13(2):222–232, Feb. 1987.
[5] S. Forrest. A Sense of Self for UNIX Processes. In Proceed-
ings of the IEEE Symposium on Security and Privacy, pages
120–128, Oakland, CA, May 1996.
[6] R. Goldman. A Stochastic Model for Intrusions. In Sym-
posium on Recent Advances in Intrusion Detection (RAID),
2002.
[7] K. Ilgun. USTAT: A Real-time Intrusion Detection System
for UNIX. In Proceedings of the IEEE Symposium on Re-
search on Security and Privacy, Oakland, CA, May 1993.
[8] H. S. Javitz and A. Valdes. The SRI IDES Statistical
Anomaly Detector. In Proceedings of the IEEE Symposium
on Security and Privacy, May 1991.
Springer, New York, USA, 2001.
[10] C. Kruegel, T. Toth, and E. Kirda. Service Speciﬁc Anomaly
Detection for Network Intrusion Detection. In Symposium
on Applied Computing (SAC). ACM Scientiﬁc Press, March
2002.
[11] M. Lincoln Labs. DARPA Intrusion Detection Evaluation.
http://www.ll.mit.edu/IST/ideval, 1999.
[12] J. McHugh. Testing Intrusion Detection Systems: A Cri-
tique of the 1998 and 1999 DARPA Intrusion Detection
System Evalautions as Performed by Lincoln Laboratory.
ACM Transaction on Information and System Security, 3(4),
November 2000.
[13] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Net-
works of Plausible Inference. Morgan Kaufmann, 1997.
[14] P. Porras and P. Neumann. EMERALD: Event Monitoring
Enabling Responses to Anomalous Live Disturbances.
In
Proceedings of the 1997 National Information Systems Se-
curity Conference, October 1997.
[15] P. A. Porras and A. Valdes. Live trafﬁc analysis of TCP/IP
gateways. In Proceedings of the 1998 ISOC Symposium on
Network and Distributed System Security (NDSS’98), San
Diego, CA, 1998.
[16] R. Puttini, Z. Marrakchi, and L. Me. Bayesian Classiﬁca-
tion Model for Real-Time Intrusion Detection. In 22th In-
ternational Workshop on Bayesian Inference and Maximum
Entropy Methods in Science and Engineering, 2002.
[17] RealSecure.
http://www.iss.net/products_
services/enterprise_protection.
[18] M. Roesch. Snort - Lightweight Intrusion Detection for Net-
works. In USENIX Lisa 99, 1999.
[19] A. A. Sebyala, T. Olukemi, and L. Sacks. Active Platform
Security through Intrusion Detection Using Naive Bayesian
Network for Anomaly Detection.
In London Communica-
tions Symposium, 2002.
[20] Smile: Structural Modeling, Inference, and Learning En-
gine. http://www.sis.pitt.edu/˜genie/.
[21] SNARE - System iNtrusion Analysis and Reporting Envi-
ronment. http://www.intersectalliance.com/
projects/Snare.
[22] A. Stolcke and S. Omohundro. Inducing probabilistic gram-
mars by bayesian model merging. In International Confer-
ence on Grammatical Inference, 1994.
[23] Swatch:
Simple Watchdog.
http://swatch.
sourceforge.net.
[24] A. Valdes and K. Skinner. Adaptive, Model-based Moni-
toring for Cyber Attack Detection. In Proceedings of RAID
2000, Tolouse, France, October 2000.
[25] G. Vigna and R. A. Kemmerer. NetSTAT: A Network-based
Intrusion Detection System. Journal of Computer Security,
7(1):37–71, 1999.
[26] C. Warrender, S. Forrest, and B. Pearlmutter. Detecting in-
In
trusions using system calls: Alternative data models.
IEEE Symposium on Security and Privacy, pages 133–145,
1999.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:47:09 UTC from IEEE Xplore.  Restrictions apply.