Randomized response was first introduced by Warner [15]. The
purpose of the mechanism is to achieve plausible deniability by
changing one’s answer to some question with probability 𝑝 and
answer truthfully with probability 𝑞 = 1− 𝑝. We define randomized
response for a boolean value 𝑏 ∈ {0, 1} as follows:
(cid:40)1 − 𝑏 with probability 𝑝
𝑏
with probability 𝑞
RandResponse (𝑏, 𝑝) =
Universal Hashing. A hash family is a collection of functions H
mapping keys from a universe 𝑈 to a range 𝑅. A family H is called
universal, if each pair of different keys collides with probability at
most 1/|𝑅|, where the randomness is taken over the random choice
of ℎ ∈ H. A particularly efficient construction that uses 𝑂(log |𝑈 |)
bits and constant evaluation time is presented in [6].
3
Model of Computation. We use the 𝑤-bit word RAM model de-
fined by Hagerup [11] where 𝑤 = Θ(log(𝑑) + log(𝑢)). This model
allows constant time memory access and basic operations on 𝑤-bit
words. As such, we can store a 𝑘-sparse vector using 𝑂(𝑘 log(𝑑+𝑢))
bits with constant lookup time using a hash table. We assume that
the privacy parameters 𝜀 and 𝛿 can be represented in a single word.
Negative Values. In this paper, we consider vectors with non-
negative real values, but the mechanism can be generalized for
negative values using the following reduction. Let 𝑣 ∈ R𝑑 be a
real valued 𝑘-sparse vector. Construct 𝑥, 𝑦 ∈ R𝑑+ from 𝑣 such that
𝑥𝑖 = max(𝑣𝑖, 0) and 𝑦𝑖 = − min(𝑣𝑖, 0). By construction both 𝑥 and 𝑦
are 𝑘-sparse and the ℓ1-distance between vectors is preserved. We
can access elements in 𝑣 as 𝑣𝑖 = 𝑥𝑖 − 𝑦𝑖. As such, any differentially
private representation of 𝑥 and 𝑦 can be used as a differentially
private representation of 𝑣 with at most twice the error.
𝜀
3 RELATED WORK
Previous work on releasing differentially private sparse vectors
primarily focused on the special case of discrete vectors in the
context of releasing the histogram of a dataset.
Korolova, Kenthapadi, Mishra, and Ntoulas [13] first introduced
an approximately differentially private mechanism for the release
of a sparse histogram. A similar mechanism was later introduced
independently by Bun, Nissim, and Stemmer [3] in another con-
text. The mechanism adds noise to non-zero entries and removes
those with a noisy value below a threshold 𝑡 = 𝑂(cid:16) log(1/𝛿)
𝑂(cid:16) log(max(𝑘,1/𝛿))
mum error is 𝑂(cid:16) log(1/𝛿)
(cid:17). The
(cid:17). Since 𝛿 is usually chosen to be negligible in the
(cid:17). We discuss the per-entry error below.
threshold is chosen such that the probability of releasing an entry
with true value 1 is at most 𝛿. The expected maximum error is
input size, we assume that 𝛿 ≤ 1/𝑘. As such, the expected maxi-
𝜀
𝜀
𝜀
Their mechanism is designed to satisfy differential privacy for dis-
crete data. We extend their technique to real-valued data as part of
Section 5, where we combine it with our mechanism.
Cormode, Procopiuc, Srivastava, and Tran [5] introduced a dif-
ferentially private mechanism in their work on range queries for
sparse data. The mechanism adds noise to all entries and removes
those with a noisy value below a threshold 𝑡 = 𝑂(cid:16) log(𝑑)
(cid:17). Here the
threshold is used to reduce the expected output size. The number
of noisy entries above 𝑡 is 𝑂(𝑘) with high probability. The con-
struction time of a naive implementation of their technique scales
linearly in 𝑑. They improve on this by sampling from a binomial
distribution to determine the number of zero entries to store. They
show that their approach produces the same output distribution
as a naive implementation that adds noise to every entry. Their
mechanism works for real-valued data in a straightforward way.
Since the expected number of non-zero entries in the output
is 𝑂(𝑘) for both mechanisms above, their memory requirement
is 𝑂(𝑘 log(𝑑 + 𝑢)) bits using a hash table. An entry is accessed in
constant time. The expected per-entry error depends on the true
value of the entry. If the noisy value is above the threshold with
sufficiently high probability, the expected error is 𝑂(1/𝜀). However,
this does not hold for entries that are likely removed. Consider
for example an entry with a true value exactly at the threshold
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1225Algorithm
Dwork et al. [7]
Cormode et al. [5]
Balcer & Vadhan [2]
Space (bits)
𝑂(𝑑 log(𝑢))
𝑂(𝑘 log(𝑑 + 𝑢))
˜𝑂(cid:0) 𝑛
𝜀 log(𝑑)(cid:1)
𝑂(1)
𝑂(1)
˜𝑂(cid:0) 𝑛
(cid:1)
𝜀
Theorem 5.10 (this work)
Korolova et al. [13]
Theorem 5.11 (this work) 𝑂(𝑘(log(𝑑 + 𝑢) + log(1/𝛿))) 𝑂(log(1/𝛿))
𝑂(𝑘 log(𝑑 + 𝑢))
𝑂(𝑘 log(𝑑 + 𝑢))
𝑂(log(𝑑))
𝑂(1)
Access time Per-entry error Maximum error
𝜀
𝜀
𝑂(cid:16) 1
(cid:17)
𝑂(cid:16) log(𝑑)
(cid:17)
(cid:17)
𝑂(cid:16) 1
𝑂(cid:16) 1
(cid:17)
𝑂(cid:16) log(1/𝛿)
(cid:17)
𝑂(cid:16) 1
𝜀
𝜀
𝜀
𝜀
(cid:17)
𝜀
𝜀
(cid:17)
𝑂(cid:16) log(𝑑)
(cid:17)
𝑂(cid:16) log(𝑑)
(cid:17)
𝑂(cid:16) log(𝑑)
(cid:17)
𝑂(cid:16) log(𝑑)
𝑂(cid:16) log(1/𝛿)
𝑂(cid:16) log(1/𝛿)
𝜀
𝜀
𝜀
𝜀
(cid:17)
(cid:17)
Table 1: Comparison with previous work of expected values for worst-case input. The first four rows are results on
𝜀-differential privacy, and the last two are on (𝜀, 𝛿)-differential privacy. The ˜𝑂-notation suppresses logarithmic factors.
𝜀
(cid:17) and 𝑂(cid:16) log(𝑑)
𝑡. This entry is removed for any negative noise added. As such
the expected per-entry error is 𝑂(𝑡) for worst-case input, which is
𝑂(cid:16) log(1/𝛿)
they provided a lower bound of Ω(cid:16) min{log(𝑑), log(𝜀/𝛿), 𝑛}
(cid:17) for the two mechanisms, respectively.
(cid:17) for the
In their work on differential privacy on finite computers, Bal-
cer and Vadhan [2] introduced several algorithms including some
with similar utility as the mechanisms described above. Moreover,
𝜀
𝜀
𝜀
𝜀
expected per-entry error of any algorithm that always outputs a
sparse histogram. (See [2, Theorem 7.2] for the precise technical
statement.) Here 𝑛 is the number of rows in the dataset, i.e., the
sum of all entries of the histogram. This lower bound means that
an algorithm that always outputs a 𝑂(𝑘)-sparse histogram cannot
achieve 𝑂(1/𝜀) expected per-entry error for all input. They bypass
this bound by producing a compact representation of a dense his-
togram. Their representation has expected per-entry and maximum
error of 𝑂(1/𝜀) and 𝑂(cid:16) log(𝑑)
bits and an entry is accessed in time ˜𝑂(cid:0) 𝑛
(cid:17), respectively. It requires ˜𝑂(cid:0) 𝑛
𝜀 log(𝑑)(cid:1)
(cid:1). Note that their problem
setup differs from ours in that each entry is bounded only by 𝑛 such
that ∥𝑥∥∞ ≤ 𝑛. That is, 𝑛 serves a similar purpose as 𝑢 does in our
setup. We do not know how to extend their approach to our setup
with real-valued input.
In light of the results achieved in previous work, our motivation
is to design a mechanism that achieves three properties simulta-
neously: 𝑂(1/𝜀) expected per-entry error for arbitrary input, fast
access, and (asymptotically) optimal space. Previous approaches
only achieved at most two of these properties simultaneously. More-
over, we want the per-entry error to match the tail bounds of the
Laplace mechanism up to constant factors. We construct a compact
representation of a dense vector to bypass the lower bound for
sparse vectors by Balcer and Vadhan [2]. The access time of our
mechanism is 𝑂(log(𝑑)) and 𝑂(log(1/𝛿)) for pure and approximate
differential privacy, respectively. Table 1 summarizes the results of
previous work and our approach.
4 THE ALP MECHANISM
In this section, we introduce the Approximate Laplace Projection
(ALP) mechanism1 and give an upper bound on the expected per-
entry error. The ALP mechanism consists of two algorithms. The
first algorithm constructs a differentially private representation of
a 𝑘-sparse vector and the second estimates the value of an entry
based on its representation.
4.1 A 1-differentially private algorithm
We start by considering the special case of 𝜀 = 1 and later generalize
to all values of 𝜀 > 0. Moreover, the mechanism works well only
for entries bounded by a parameter 𝛽. In general, this would mean
that we had to set 𝛽 = 𝑢 if we only were to use the ALP mechanism.
However, in Section 5 we will discuss how to set 𝛽 smaller and still
perform well for all entries.
In the first step of the projection algorithm, we scale every non-
zero entry by a parameter of the algorithm and use random round-
ing to map each such entry to an integer. We then store the unary
representation of these integers in a two-dimensional bit-array
using a sequence of universal hash functions [4]. We call this bit-
array the embedding. Lastly, we apply randomized response on the
embedding to achieve privacy. The pseudocode of the algorithm is
given in Algorithm 2 and we discuss it next.
Figure 1 shows an example of an embedding before applying
randomized response. The input is a vector 𝑥 where the 𝑖th entry
𝑥𝑖 is the only non-zero value. The result of evaluating 𝑖 for each
hash function is shown in the table at the bottom and the 𝑚 = 8
bits representing the 𝑖th entry in the bit-array are highlighted.
In Step (1) of the algorithm, 𝑥𝑖 is scaled by 1/𝛼 and randomized
rounding is applied to the scaled value. This results in 𝑦𝑖 = 5. Using
the hash functions, we represent this value in unary encoding by
setting the first five bits to 1 in Step (2), where the 𝑗th bit is selected
by evaluating the hash function ℎ 𝑗 on 𝑖. The final three bits are
unaffected by the entry. Finally, we apply randomized response in
each cell of the bit-array. The bit-array after applying randomized
response is not shown here, but we present it later in Figure 2. Both
the bit-array and the hash functions are the differentially private
1The name is chosen to indicate that the error distribution is approximately like the
Laplace distribution, and that we project the sparse vector to a much lower-dimensional
representation. It also celebrates the mountains, whose silhouette plays a role in a
certain random walk considered in the analysis of the ALP mechanism.
4
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1226Algorithm 2: ALP1-projection
Parameters:𝛼, 𝛽 > 0, and 𝑠 ∈ N.
Input
:𝑘-sparse vector 𝑥 ∈ R𝑑+ where 𝑠 > 2𝑘.
Sequence of hash functions from domain [𝑑]
to [𝑠], ℎ = (ℎ1, . . . , ℎ𝑚), where 𝑚 =
:1-differentially private representation of 𝑥.
(cid:108) 𝛽
(cid:109).
non-zero entry of 𝑥 such that 𝑦𝑖 = RandRound(cid:0) 𝑥𝑖
(cid:1).
(cid:40)1, ∃𝑖 : 𝑏 ≤ 𝑦𝑖 and ℎ𝑏(𝑖) = 𝑎
(1) Apply random rounding to a scaled version of each
𝛼
(2) Construct 𝑧 ∈ {0, 1}𝑠×𝑚 by hashing the unary
representations of 𝑦 such that:
Output
𝛼
𝑧𝑎,𝑏 =
0,
otherwise
(3) Apply randomized response to each bit of 𝑧 such that
˜𝑧𝑎,𝑏 = RandResponse(cid:16)𝑧𝑎,𝑏,
(cid:17).
1
𝛼+2
(4) Release ℎ and ˜𝑧.
𝑖th entry. In this case, we start by assuming that only a single bit
of 𝑧 is affected by changing 𝑥 to 𝑥′ and that there are no hash
collisions. We then allow them to differ in several bits and include
hash collisions. Finally, we generalize to the case that they differ in
more than one entry.
Assume that 𝑧 differs only in a single bit for 𝑥 and 𝑥′. Let 𝑌
denote the event that the affected bit is set to one after running
1
the algorithm. Let 𝑝 =
𝛼+2 be the parameter of the randomized
response step and let 𝑞 = 1− 𝑝. Then the probability of 𝑌 occurring
𝛼 −
with input 𝑥 is Pr[𝑌 | 𝑥] = (1 − 𝑟) · 𝑝 + 𝑟 · 𝑞, where 𝑟 = 𝑥𝑖
(cid:107) denotes the probability of the bit being one before the
(cid:107). The minimum term is needed when max(𝑥𝑖, 𝑥′