that the update is from the legal participant and puts the
transaction in the transaction pool. Subsequently, selected
miners constitute a committee to verify all transactions in
the pool using Multi-KRUM [51,52], and accept legitimate
updates. After verifying the validity of the uploaded model,
the leader selected from miners will generate a new block
containing the uploaded ﬁle.
y A selected leader updates the model. A leader is selected
from a group of miners to update the model. Miners compete
for updating parameters to get the reward. Algorand uses
the Veriﬁable Random Functions (VRF) as a local and non-
interactive way to select a subset of users as the leader
candidates who form a committee (weighed by their coins)
and determine their priorities. A leader candidate with the
highest priority will become the leader to update the model
parameters. As each user is weighted by their coins, one
unit of coin can be regarded as a sub-user. A user with m
coins has m “sub-users”. Let τ be the expected number of
sub-users that the system desires to choose, and M be the
total mount of coins of all users. Then the probability p of
any coin being chosen can be set as τ /M. For a user u
with m units of currency, it will ﬁrst use its secret key to
generate a hash and proof via VRF. The interval [0, 1] is
divided into m + 1 sub-intervals, so that the number j of
selected sub-users for this user is determined by which sub-
interval hash/2hashlen falls in (hashlen denotes the length
of hash); i.e., j satisﬁes hash/2hashlen ∈ [(cid:80)j
p)m−k,(cid:80)j+1
(cid:1)pk(1 −
(cid:1)pk(1− p)m−k) (if hash/2hashlen = 1, then
(cid:0)m
(cid:0)m
k=0
k
j = m). Other users can use the proof to check that user u
indeed has j sub-users selected. The number of selected sub-
users is each user’s priority. The user with the highest priority
will become the leader. The selected leader is responsible for
aggregating models submitted by customers and uploading the
global model to the blockchain.
k=0
k
B. Incentive mechanism
To attract more customers to contribute to building the FL
model, we design an incentive mechanism. Because data in
home appliances contain customers’ conﬁdential information
5
This paper appears in IEEE Internet of Things Journal (IoT-J). Please feel free to contact us for questions or remarks.
and training consumes computing resources, some customers
are unwilling to participate in training the FL model. However,
with an incentive mechanism, customers will be rewarded
based on their contributions. Then, customers may trade
for services, such as the maintenance and upgrade services
for appliances, provided by manufacturers using rewards.
Speciﬁcally, by combining the Multi-KRUM [51,52] and the
reputation-based incentive protocols [53], an incentive mech-
anism is designed to prevent the poisoning attack as well as
reward contributors properly.
That is, after the local model is uploaded, veriﬁers calculate
the reputation using Multi-KRUM algorithm and eliminate un-
satisﬁed updates. The veriﬁers, selected based on the VRF [50]
from miners, will remove malicious updates by executing
Multi-KRUM algorithm on updates in the received pool and
accept the top majority of the updates received every global
epoch. The veriﬁer will add up Euclidean distances of each
customer i’s update to the closest R−f−2 updates and denote
the sum as each customer i’s score s(i). R means the number
of updates, and f means the number of Byzantine customers.
∆w means the model update. It is given by
(cid:107)∆wi − ∆wj(cid:107)2,
(1)
where i → j denotes the fact that ∆wj belongs to the R−f−2
closest updates to ∆wi. The R − f customers who obtain the
lowest scores will be chosen while rejecting the rest.
(cid:88)
s(i) =
i→j
The value of the reward is proportional to the customer’s
reputation. If a customer’s update is accepted by veriﬁers, the
value of reputation increases by 1; otherwise, it decreases by
1. Each participant is assigned with an initial reputation value
γ, and γ is an integer selected from the set(0, 1,··· , γM ax),
where γM ax denotes the highest reputation. h denotes the
average reputation of the whole customers. If a miner veriﬁes
a solution is correct and provides a positive evaluation, the
reputation of the participant will be increased and recorded in
the blockchain. Let a denote the evaluation function’s output.
a = H denotes a high evaluation result while a = L denotes
a low evaluation result. Therefore, the update rule of the
reputation γ is as follows:
min(γM ax, γ + 1),
γ − 1,
0,
γ + 1,
if a = H and γ ≥ h
if a = L and γ ≥ h + 1
if a = L and γ = h
if γ < h
(2)
where h denotes the threshold of the selected social strategy,
which is a method of using social norms (i.e., Multi-KRUM) to
control customers’ behaviours [53]. If a customer’s reputation
is h and she receives an L feedback after evaluation, her
reputation will fall to 0. The status of customers’ reputation
is recorded by the blockchain.
C. Normalization Technique
To protect the privacy of users’ update, we perturb extracted
features in the normialization layer. Now, we present
the
improvement for the normalization technique proposed in [45].
Although the CNN has many channels, our analysis below
focuses on one channel only for simplicity. For this channel,
γ =
while
k∈B
1
|B|
(cid:88)
(cid:101)Xi,j,k = 0,
(cid:88)
((cid:101)Xi,j,k)2 = 1.
(cid:101)Xi,j,k ∈ [−√
N − 1,
1
|B|
k∈B
suppose the output of the convolutional layers has dimension
Lf × Wf . Let the value at a position (cid:104)i, j(cid:105) for the feature of
image k be Xi,j,k. Given i and j, Jiang et al. [45] adopt the
batch normalization which transforms Xi,j,k to (cid:101)Xi,j,k, so that
for each batch B, the values (cid:101)Xi,j,k for k ∈ B have a mean of
0 and a variance of 1; i.e.,
√
√
N − 1]
From and |B| = N and the Cauchy–Schwarz inequality, [45]
bounds
of image k varies, the sensitivity of
for any i, j, k, so that if one value in the feature
(cid:8)Xi,j,k | i ∈ {1, 2, . . . , Lf} and j ∈ {1, 2, . . . , Wf}(cid:9)
(cid:8)(cid:101)Xi,j,k | i ∈ {1, 2, . . . , Lf} and j ∈ {1, 2, . . . , Wf}(cid:9)
N − 1(cid:14) is added to
each (cid:101)Xi,j,k for i ∈ {1, 2, . . . , Lf} and j ∈ {1, 2, . . . , Wf}
√
zero-mean Laplace noise with scale 2
Then, according to Laplace mechanism [9], the independent
is at most 2
N − 1.
N − 1,
N − 1],
ˆXi,j,k ∈ [−√
to protect Xi,j,k under -differential privacy. In our ap-
proach, we normalize Xi,j,k for i ∈ {1, 2, . . . , Lf} and
j ∈ {1, 2, . . . , Wf} as
so that if one value in the feature
of image k varies, the sensitivity of
(cid:8)Xi,j,k | i ∈ {1, 2, . . . , Lf} and j ∈ {1, 2, . . . , Wf}(cid:9)
(cid:8) ˆXi,j,k | i ∈ {1, 2, . . . , Lf} and j ∈ {1, 2, . . . , Wf}(cid:9)
N − 1(cid:14)
√
N − 1. Then, based on Laplace mechanism [9], the
√
is 2
independent zero-mean Laplace noise with scale 2
is added to each ˆXi,j,k for i ∈ {1, 2, . . . , Lf} and j ∈
{1, 2, . . . , Wf} to protect Xi,j,k under -differential privacy.
From the above discussions, batch normalization of [45]
√
N − 1]
√
N − 1,
but also the mean is
enforces not only(cid:101)Xi,j,k ∈ [−√
(cid:88)
(cid:101)Xi,j,k = 0
(cid:88)
((cid:101)Xi,j,k)2 = 1,
ˆXi,j,k ∈ [−√
and the variance is
N − 1,
1
|B|
1
|B|
k∈B
k∈B
√
while our normalization technique requires only
N − 1]
without any constraints on the mean and variance. Experiments
to be presented in Section VI show that our normalization
technique signiﬁcantly improves the learning accuracy over
that of [45].
Next, we explain why our normalization technique outper-
forms the batch normalization. Both Jiang et al.’s solution [45]
and our solution add the same zero-mean Laplace noise to
normalized layer inputs. When using batch normalization, the
mean of features µ = 0 and the variance σ = 1. For ease
of explanation, below we use a Gaussian distribution as an
example for the distribution of the features since Gaussian
6
This paper appears in IEEE Internet of Things Journal (IoT-J). Please feel free to contact us for questions or remarks.
√
√
N − 1,
distributions appear in many real-world applications. Note
that the actual distribution of the features may not follow
Gaussian. According to the three-sigma rule of Gaussian
distribution [54], about 99.73% values lie within three standard
deviations of the mean. Similarly, most feature values after
batch normalization lie in [−3σ, 3σ] which is [−3, 3] instead
of [−√
N − 1]. In contrast, feature values lie more
N − 1,
evenly in [−√
N − 1] when using our normalization
technique. Thus, features have smaller magnitudes when using
batch normalization than using our normalization technique.
Hence, when the same amount of Laplace noise is added, fea-
ture values using batch normalization will be perturbed more
easily than using our normalization technique. For example,
√
when the batch size N = 64 and scale of Laplace distribution
N − 1/, we calculate privacy parameter thresholds for
is 2
feature values (after batch normalization or our normalization
technique) to be “overwhelmed” by the noise as follows.
In the case of batch normalization, we have
√
2
√
=⇒ 2
N − 1

N − 1

=⇒  (cid:28) 16
3
(cid:29) 3σ,
(cid:29) 3,
≈ 5.33.
Thus, true feature values will be seriously perturbed by noise
when the privacy parameter  (cid:28) 5.33 using batch normaliza-
tion. However, when we use our normalization technique, we
obtain that
√
2
(cid:29) √
N − 1

=⇒  (cid:28) 2.
N − 1,
Hence, when the privacy parameter  (cid:28) 2, the true value will
be overwhelmed by the noise. The larger privacy parameter
means the less noise, so that feature values using batch
normalization are more vulnerable. Thus, our above example
implies that features will be perturbed more seriously when
using batch normalization than our normalization technique.
Summarizing above, the trained model with our normalization
technique will achieve a higher test accuracy than trained using
the batch normalization.
V. PROS AND CONS OF OUR FRAMEWORK
We discuss advantages and disadvantages of our framework
in this section.
A. Privacy and Security
Our system leverages differential privacy technique to pro-
tect the privacy of the extracted features. Thus, the system
keeps the participating customers’ data conﬁdential. Further-
more, the trained model is encrypted and signed by the sender
to prevent the attackers and imposters from stealing the model
or deriving original data through reverse-engineering.
B. Delay in Crowdsourcing
Assume there is a large number of customers, and the
system highly depends on customers’ training results to obtain
7