69
w
o
d
n
w
i
r
o
t
c
e
t
e
d
f
o
e
z
i
S
12
11
10
9
8
7
6
5
4
3
2
1
Detection Region
Successive Attack Modifications
Blind Region
1
2
4
3
8
Size of foreign−sequence anomaly
7
5
6
Fig. 2. The manifestation of each version of the traceroute exploit plotted on the
detector coverage map for stide, assuming that stide has been conﬁgured with a detector
window size of 6. Each version of the exploit can be detected by fewer and fewer
conﬁgurations of stide until the last is invisible.
blind spot. This shows that it is possible to exert control over a common exploit
so that its manifestation is moved from an anomaly detector’s detection region,
to its region of complete blindness. Such movement of an exploit’s manifestation
eﬀectively hides the exploit from the detector’s view.
8 Discussion
The results show that it is possible to hide the presence of the passwd and
traceroute common exploits from stide by modifying those exploits so that
they manifest only within stide’s detection blind spot. Achieving an attack’s
objectives is not aﬀected by the modiﬁcations to the exploit programs; neither
is the training data tampered with in order to render an anomaly detector blind
to the attacks. Note that, at present, these results can be said to be relevant
only to other anomaly-based intrusion detection systems that employ anomaly
detectors operating on sequences of categorical data. Although the results make
no claims about other families of anomaly detectors that, for example, employ
probabilistic concepts, it is possible that the methods described in this study
may be applicable to a broader range of anomaly detectors.
The results presented in this paper show that it is also possible to control
the manifestation of an attack so that the manifestation moves from an area of
70
K.M.C. Tan, K.S. Killourhy, and R.A. Maxion
detection blindness to an area of detection clarity for stide. Figure 2 shows the
results of modifying the manifestation of an exploit in controlled amounts until
the manifestation falls outside the anomaly detector’s detection range.
8.1
Implications for Anomaly Detector Development
By identifying the precise event and conditions that characterize the detection
blindness for stide and showing that real-world exploits can be modiﬁed to take
advantage of such weaknesses, one is forewarned not only that such weaknesses
exist, but also that they present a possible and tangible threat to the protected
system. It is now possible to mitigate this threat by, for example, combining
stide with another detector that could compensate for the problems inherent
in the stide detection algorithm. The variable sequence size model explored by
Marceau [11] seems to be a promising step toward addressing the weakness in
stide. Because detection coverage has been deﬁned in a way that is pertinent to
anomaly detectors, i.e., in terms of the kinds of anomalies that can be detected
by a given anomaly detector rather than in terms of intrusions, it is also possible
to compose anomaly detectors to eﬀect full coverage over the detection space.
It is interesting to note that the ease with which an attacker can introduce
sequences into the system call data suggests that sequences of system calls may
not be a suﬃciently expressive form of data to allow an anomaly detector to more
eﬀectively monitor and defend an information system. Increasing the number of
diﬀerent kinds of data analyzed, or changing the kind of data analyzed by an
anomaly detector, may make an impact on the eﬀectiveness of the intrusion-
detection capabilities of an anomaly detector.
8.2
Implications for Anomaly Detector Evaluation
There are a few beneﬁts of an anomaly-based evaluation method, an evalua-
tion method focused on how well anomaly detectors detect anomalies. First,
the results of an anomaly-based evaluation increases the scope of the results.
In other words, what was established to be true with respect to the anomaly-
detection performance of the anomaly detector on synthetic data will also be
true of the anomaly detector on real-world data sets. This cannot be said of
current evaluation procedures for anomaly detectors because current evaluation
schemes evaluate an anomaly detector in terms of how well it detects attacks.
This constrains the scope of the results to the data set used in the evaluation
because an attack that manifests as a speciﬁc kind of anomaly in one data set
may no longer do so in another data set due to changing normal behavior.
Second, the results of an anomaly-based evaluation can only contribute to
increasing the accuracy of anomaly detectors performing intrusion detection.
Current evaluation methods do not establish the detection capabilities of an
anomaly detector with regard to the detection of the anomalous manifestations
of attacks. The fact that attacks may manifest as diﬀerent types of anomalies
also means that diﬀerent types of anomaly detectors may be required to detect
them. If anomaly detectors are not evaluated on how well they detect anomalies,
Undermining an Anomaly-Based Intrusion Detection System
71
it is diﬃcult to determine which anomaly detector would best suit the task of
detecting a given type of attack. The events that anomaly detectors directly
detect are anomalies, but typically anomaly detectors are evaluated on how well
they detect attacks, the events that anomaly detectors do not detect except by
making the assumption that attacks manifests as those anomalies detected by
an anomaly detector.
9 Related Work
The concept of modifying an attack so that it successfully accomplishes its goal
while eluding detection is not a new one. Ptacek and Newsham [14] highlighted
a number of weaknesses that the network intrusion detection community needed
to address if they were to defeat a wily attacker using network signature-based
intrusion detection systems. Although the work presented in this paper diﬀers in
that it focuses on anomaly-based intrusion detection, it strongly reiterates the
concern that an unknown weakness in an intrusion detection system creates a
“dangerously false sense of security.” In the case of this work, it was shown that a
weakness in an anomaly detector could realistically be exploited to compromise
the system being protected by that detector.
Wagner and Dean [20] introduced a new class of attacks against intrusion
detection systems which they called the “mimicry attack”. A “mimicry attack”
is where an attacker is able to “develop malicious exploit code that mimics the
operation of the application, staying within the conﬁnes of the model and thereby
evading detection ...” Wagner and Dean studied this class of attack theoretically,
but until this present paper, no study has shown if it were possible to create and
deploy a mimicry attack in the real-world that truly aﬀected the performance of
an intrusion-detection system.
The present study conﬁrms that the class of mimicry attacks does pose a
serious threat to an anomaly-based intrusion detection system. By modifying
common real-world exploits to create examples of this class of attack, this study
also shows how mimicry attacks are able to undermine the protection oﬀered by
an anomaly-based intrusion detection system.
10 Conclusion
This study has shown how an anomaly-based intrusion detection system can be
eﬀectively undermined by modifying common real-world exploits. It presented
a method that identiﬁed weaknesses in an anomaly-based intrusion detector,
and showed how an attacker can eﬀectively modify common exploits to take
advantage of those weaknesses in order to craft an oﬀensive mechanism that
renders an anomaly-based intrusion detector blind to the on-going presence of
those attacks.
The results show that it is possible to hide the presence of the passwd and
traceroute common exploits from stide by modifying those exploits so that they
manifest only within stide’s detection blind spot. The results also show that it
72
K.M.C. Tan, K.S. Killourhy, and R.A. Maxion
is possible to control the manifestation of an attack such that the manifestation
moves from an area of detection clarity to one of detection blindness for stide.
References
1. Herve Debar, Marc Dacier, and Andreas Wespi. Towards a taxonomy of intrusion-
detection systems. Computer Networks, 31(8):805–822, April 1999.
2. Stephanie Forrest, Steven A. Hofmeyr, Anil Somayaji, and Thomas A. Longstaﬀ.
A sense of self for unix processes. In Proceedings of the 1996 IEEE Symposium on
Security and Privacy, 6–8 May 1996, Oakland, California, pages 120–128, IEEE
Computer Society Press, Los Alamitos, California, 1996.
3. Cristian Gafton. passwd(1). Included in passwd version 0.64.1-1 software package,
January 1998.
4. Anup K. Ghosh, Aaron Schwartzbard, and Michael Schatz. Learning program
behavior proﬁles for intrusion detection. In Proceedings of the 1st Workshop on
Intrusion Detection and Network Monitoring, 9–12 April 1999, Santa Clara, Cali-
fornia, pages 51–62, The USENIX Association, Berkeley, California, 1999.
5. Anup K. Ghosh, James Wanken, and Frank Charron. Detecting anomalous and
unknown intrusions against programs. In Proceedings of the 14th Annual Computer
Security Applications Conference, 7–11 December 1998, Phoenix, Arizona, pages
259–267, IEEE Computer Society Press, Los Alamitos, 1998.
6. Steven A. Hofmeyr, Stephanie Forrest, and Anil Somayaji.
Intrusion detection
using sequences of system calls. Journal of Computer Security, 6(3):151–180, 1998.
Included in traceroute version 1.4a5 software
7. Van Jacobson. Traceroute(8).
package, April 1997.
8. Michel “MaXX” Kaempf. Traceroot2: Local root exploit in LBNL traceroute. In-
ternet: http://packetstormsecurity.org/0011-exploits/traceroot2.c, March
2002.
9. Sandeep Kumar. Classiﬁcation and Detection of Computer Intrusions. PhD thesis,
Purdue University, West Lafayette, Indiana, August 1995.
10. Teresa Lunt. Automated audit trail analysis and intrusion detection: A survey. In
Proceedings of the 11th National Computer Security Conference, Baltimore, Mary-
land, pages 65–73, October 1988.
11. Carla Marceau. Characterizing the behavior of a program using multiple-length N-
grams. In New Security Paradigms Workshop, 18–22 September 2000, Ballycotton,
County Cork, Ireland, pages 101–110, ACM Press, New York, New York, 2001.
12. Roy A. Maxion and Kymie M. C. Tan. Anomaly detection in embedded systems.
IEEE Transactions on Computers, 51(2):108–120, February 2002.
13. Andrew P. Moore. CERT/CC vulnerability note VU#176888, July 2002. Internet:
http://www.kb.cert.org/vuls/id/176888.
14. Thomas H. Ptacek and Timothy N. Newsham. Insertion, evasion, and denial of ser-
vice: Eluding network intrusion detection. Secure Networks, Inc., Calgary, Alberta,
Canada, January 1998.
15. Wojciech Purczynski (original author) and “lst” (author of improvements). Epcs2:
Exploit for execve/ptrace race condition in Linux kernel up to 2.2.18. Internet:
http://www.securiteam.com/exploits/5NP061P4AW.html, March 2002.
16. SecurityFocus Vulnerability Archive. LBNL Traceroute Heap Corruption Vulnera-
bility, Bugtraq ID 1739. Internet: http://online.securityfocus.com/bid/1739,
March 2002.
Undermining an Anomaly-Based Intrusion Detection System
73
17. SecurityFocus Vulnerability Archive. Linux PTrace/Setuid Exec Vulnerability,
Bugtraq ID 3447. Internet: http://online.securityfocus.com/bid/3447, March
2002.
18. Anil Somayaji and Geoﬀrey Hunsicker. IMMSEC Kernel-level system call tracing
for Linux 2.2, Version 991117. Obtained through private communication. Previous
version available on the Internet:
http://www.cs.unm.edu/˜immsec/software/, March 2002.
19. Kymie M. C. Tan and Roy A. Maxion. “Why 6?” Deﬁning the operational limits
of stide, an anomaly-based intrusion detector. In Proceedings of the 2002 IEEE
Symposium on Security and Privacy, 12–15 May 2002, Berkeley, California, pages
188–201, IEEE Computer Society Press, Los Alamitos, California, 2002.
20. David Wagner and Drew Dean. Intrusion detection via static analysis. In Pro-
ceedings of the 2001 IEEE Symposium on Security and Privacy, 14–16 May 2001,
Berkeley, California, IEEE Computer Society Press, Los Alamitos, California, 2001.
21. Christina Warrender, Stephanie Forrest, and Barak Pearlmutter. Detecting intru-
sions using system calls: Alternative data models. In Proceedings of the 1999 IEEE
Symposium on Security and Privacy, 9–12 May 1999, Oakland, California, pages
133–145, IEEE Computer Society Press, Los Alamitos, California, 1999.