inside, and give it back to Bob without him noticing. In
other words, when Alice ﬁnally reveals the opening of
the commitment, Bob can be satisﬁed that those were
the values inside all along. We will use the notation
c = Com(m;r) to mean that c is a commitment to the
message m using some randomness r. (Note that there
are also some parameters involved, but that here and
in the primitives that follow we omit them for simplic-
ity.)
One more property we will require of our commitment
schemes is that they are additively homomorphic. This
means that there is an operation on commitments, call
it (cid:1), such that if c1 is a commitment to m1 and c2 is a
commitment to m2, then c1 (cid:1) c2 will be a commitment to
m1 + m2. This property can be achieved by a variety of
schemes; to best suit our purposes, we work with Fujisaki-
Okamoto commitments [18, 22], which rely on the Strong
RSA assumption for their security.
3.2 Zero-knowledge proofs
Our second primitive, zero-knowledge proofs [24, 25],
provides a way for someone to prove to someone else
that a certain statement is true without revealing anything
beyond the validity of the statement. For example, a user
of a protected system might want to prove the statement “I
have the password corresponding to this username” with-
out revealing the password itself. The two main prop-
erties of zero-knowledge proofs are soundness and zero
knowledge. Soundness guarantees that the veriﬁer will
not accept a proof for a statement that is false; in the
above example, this means that the system will accept the
proof only if the prover really does have the password.
Zero knowledge, on the other hand, protects the prover’s
privacy and guarantees that the system in our example
will not learn any information about the password itself,
but only that the statement is true. A non-interactive
zero-knowledge proof (NIZK for short) is a particularly
desirable type of proof because, as the name indicates,
it does not require any interaction between the prover
and the veriﬁer. For a given statement S, we will use the
notation π = NIZKProve(S) to mean a NIZK formed by
the prover for the statement S. Similarly, we will use
NIZKVerify(π,S) to mean the process run by the veriﬁer
to check, using π, that S is in fact true. In our system
we will need to prove only one type of statement, often
called a range proof, which proves that a secret value x
satisﬁes the inequality lo ≤ x < hi, where lo and hi are
both public. For this we can use Boudot range proofs
and their extensions [11, 34], which are secure in the
random oracle model [6] and assuming the Strong RSA
assumption.
3.3 Blind identity-based encryption
Finally, to maintain driver honesty even in the case of
possible collusions between drivers (as discussed in Sec-
tion 2), we use an additional cryptographic primitive:
identity-based encryption [10, 42]. Intuitively, identity-
based encryption (IBE for short) extends the notion of
standard public-key encryption by allowing a user’s pub-
lic key to be, rather than just a random collection of bits,
some meaningful information relevant to their identity;
e.g., their e-mail address. This is achieved through the
use of an authority, who possesses some master secret key
msk and can use it to provide secret keys corresponding
to given identities on request (provided, of course, that
the request comes from the right person). When we work
with IBE, we will use the syntax C = IBEnc(id;m) to
mean an identity-based encryption of the message m, in-
tended for the person speciﬁed in the identity id. We will
similarly use m = IBDec(skid;C) to mean the decryption
of C using the secret key for the identity id.
Because of how IBE is integrated into our system, we
will need the IBE to be augmented by a blind extraction
protocol: a protocol interaction between a user and the
authority at the end of which the user obtains the secret
key corresponding to some identity of her choice, but
the authority does not learn which identity was requested
(and also does not learn the secret key for that identity).
This process of getting the secret key will be denoted as
skid = BlindExtract(id), keeping in mind that the author-
ity learns neither id nor skid. As we show in Section 4,
this property (introduced by Green and Hohenberger [28])
is crucial for guaranteeing that drivers do not learn where
the TC has its cameras.
Furthermore, we would like our IBE to be anony-
mous [2], meaning that given a ciphertext C, a user cannot
tell which identity the ciphertext is meant for (so, in par-
ticular, they cannot check to see if a guess is correct).
Again, as we show in Section 4, this property is necessary
to ensure that the TSP cannot simply guess and check
where the driver was at a given time, and thus potentially
learn information about her whereabouts.
To the best of our knowledge, there are two blind and
anonymous IBEs in the cryptographic literature: the ﬁrst
due to Camenisch, Kohlweiss, Rial, and Sheedy [13]
and the second to Green [27]; both are blind variants on
the Boyen-Waters anonymous IBE [12]. While either of
these schemes would certainly work for our purposes,
we chose to come up with our own scheme in order to
maximize efﬁciency. Our starting point is the Boneh-
Franklin IBE [10], which is already anonymous [2, Sec-
tion 4.5]. We then introduce a blind key-extraction pro-
tocol for Boneh-Franklin, based on the Boldyreva blind
signature [9]. Finally, we “twin” the entire scheme to es-
sentially run two copies in parallel; this is just to facilitate
a “Twin Difﬁe-Hellman” style security proof [15]. We
give a full description of our scheme in the full version
of our paper [36], as well as a proof of its security in a
variant of the Green-Hohenberger security model. Our
IBE is conveniently efﬁcient, but we stress that the Milo
system could be instantiated with any provably secure
IBE that is both blind and anonymous (and in particular
the schemes of Camenisch et al. and Green which, while
not as efﬁcient as our scheme, have the attractive proper-
ties that they use signiﬁcantly weaker assumptions and do
not rely on random oracles in their proofs of security).
In the broadest sense, our blind IBE can be viewed
as a special case of a secure two-party computation be-
tween the OBU and the TC, at the end of which the TC
learns whether or not the driver paid honestly for a given
segment, and the driver learns nothing (and in particular
does not learn which segment the TC saw her in). As
such, any efﬁcient instantiation of this protocol as a se-
cure two-party computation would be sufﬁcient for our
purposes. One promising approach, suggested by an anoy-
mous reviewer, uses an oblivious pseudorandom function
(OPRF for short) as a building block. With an OPRF, a
user with access to a seed k for a PRF f and another user
with input x can securely evaluate fk(x) without the ﬁrst
user’s learning x or fk(x), and without the second user’s
learning the seed k; this can be directly applied to our set-
ting by treating the seed k as a value known by the OBU,
and the input x as the segment in which the TC saw the
driver. An efﬁcient OPRF was recently given by Jarecki
and Liu [32]. Compared to our approach, the OPRFs of
Jarecki and Liu may require increased interaction (which
has implications for concurrent security) and potentially
more computation than ours.
4 Our Construction
In this section, we describe the various protocols used
within our system and how they meet the security goals
described in Section 2.2; we note that only Algorithm 4.3
substantially differs from what is used in PrETP. There
are three main phases we consider: the initialization of
the OBU, the forming and verifying of the payments per-
formed by the OBU and the TSP respectively, and the
audit between the TC and the OBU. Below, we will detail
the functioning of each of these algorithms; ﬁrst, though,
we give some intuition for how our scheme works and
why the use of blind identity-based encryption means the
audit protocol does not leak the locations of spot-check
cameras to drivers.
In the audit protocol, the driver needs to show that her
actual driving is consistent with the fee she chose to pay.
To do this, she must upload her (claimed) driving history
to the TSP’s server; if she didn’t, the TSP would have
nothing to check the correctness of. Obviously, simply
uploading this history in the clear would provide no pri-
vacy. The VPriv system sidesteps this by having the driver
upload the segments anonymously (using an anonymizing
service such as Tor [20]), accompanied by a “tag” that
will allow her to claim them as her own. We instead fol-
low PrETP in having the driver upload a commitment
of sorts to each of her segments. In addition, the driver
commits to the cost associated with each segment using
the additively homomorphic commitment scheme. Check-
ing that the total payment is the sum of the fees for each
committed segment is now easy: using the homomorphic
operation (cid:1), the TSP can compute a commitment to the
sum of the committed fees; the driver then provides the
opening of this sum commitment, showing that its value
is the fee she paid.3
What remains is to prove that the committed segments
the driver uploaded to the server are in fact the segments
she drove, and that the committed fee she uploaded along-
side each is in fact the fee charged for driving it. Fol-
lowing VPriv, PrETP, and de Jonge and Jacobs’ system
(see Section 7), we rely on spot check cameras. The TC’s
cameras observed the driver at a few locations over the
course of the month. It now challenges the driver to show
that these locations are among the committed segments,
and that the corresponding committed fees are correct. If
the driver cannot show a commitment that opens to one of
these spot check locations, she has been caught cheating;
if the spot check locations are unpredictable then a simple
probability analysis (see Section 6.1) shows that a cheat-
ing driver will likely be caught. In PrETP, the spot check
has the TC sending to the driver the locations and times
where she was observed; the driver returns the index and
opening of the corresponding committed segments. This,
of course, leaks the spot check locations to the driver. To
get around this, we must somehow transmit the appro-
priate openings to the TC without the driver ﬁnding out
which commitments are being opened.
Identity-based encryption allows us to achieve exactly
the requirement above. Along with each of her commit-
ments, the driver encrypts the opening of the commitment
using IBE; the identity to which a commitment is en-
crypted is the segment location and time. She sends these
encrypted openings to the TC along with the commit-
ments themselves. (Note that it is crucial the ciphertext
not reveal the identity to which it was encrypted, since
otherwise the TSP and TC would learn the driver’s entire
driving history. This is why we require an anonymous
IBE.) Now, if the TC had the secret key for the identity
corresponding to the place and time where the driver was
spotted, it could decrypt the appropriate ciphertext, ob-
tain the commitment opening value, and check that the
3There is a technicality here: range proofs are needed to prevent the
driver from artiﬁcially reducing the amount she owes by committing to
a few negative values. See Section 4.2 for more on this.
corresponding commitment was properly formed. But
the TC can’t ask the driver for the secret key, since this
would also leak the spot-check location. Instead, it en-
gages with the driver in a blind key-extraction protocol.
The TC provides as input the location and time of the spot
check and obtains the corresponding secret key without
the driver learning which identity (i.e., location and time)
was requested. By undertaking the blind extraction proto-
col only a certain number of times, the driver limits the
number of spot checks the TC can perform.
Note that this is essentially an oblivious transfer proto-
col; our solution is in fact closely related to the oblivious
transfer protocol of Green and Hohenberger [28], who
introduced blind IBE.
Before any of the three phases can take place, the TC
ﬁrst decides on the segments used for payment and how
much each one actually costs. It starts by dividing each
road into segments of some appropriate length, for exam-
ple one city block in denser urban areas or one mile along
a highway in less congested areas. Because prices might
change according to time of day, the TC also decides on a
division of time into discrete quanta based on some “time
step” when a new segment must be recorded by the OBU
(even if the location endpoint has not yet been reached).
For example, if two location endpoints are set as Exit 17
and Exit 18 on a highway and the time step is set to be
a minute, then a driver traveling between these exits for
more than a minute will have segments with the same
location endpoints, but different time endpoints. In par-
ticular, if this driver starts at 22:00 and takes about three
minutes to get from one exit to the other, she will end up
with three segments:4
• (cid:0)(exit 17,exit 18), (22:00,22:01)(cid:1);
• (cid:0)(exit 17,exit 18), (22:01,22:02)(cid:1); and
• (cid:0)(exit 17,exit 18), (22:02,22:03)(cid:1).
Each segment is of the form(cid:0)(loc1,loc2), (time1,time2)(cid:1);
in the future, we denote these segments as (where,when),
where where represents the physical limits of the seg-
ment and when represents the particular time quantum
during which the driver was in the segment where. For
each of these segments, the TC will have assigned some
price; this can be thought of as a publicly available func-
: (where,when) → [0,M], where M is the maxi-
tion f
mum price assigned by the TC.
4.1
Before any payments can be made, there are a number of
parameters that need to be loaded onto the OBU. To start,
Initialization
4In practice, the segment information will of course be more detailed;
as a byproduct of using GPS anyway, each car will have access to precise
coordinate and time information (including date).
i=1, identiﬁer tag,
signing key sktag
Algorithm 4.1: Pay, run by the OBU
forall 1 ≤ i ≤ n do
Input: segments(cid:8)(wherei,wheni)(cid:9)n
Ci = IBEnc(cid:0)(wherei,wheni); (pi;ri;0λ )(cid:1)
openﬁnal =(cid:0)P
m =(cid:0)tag,openﬁnal,(cid:8)(ci,Ci,πi)(cid:9)n
pi = f (wherei,wheni)
ci = Com(pi;ri)
πi = NIZKProve(0 ≤ pi ≤ M)
i pi;P
i ri
(cid:1)
(cid:1)
i=1
1
2
3
4
5
6
7
8
9
the OBU will be given some unique value to identify itself
to the TSP; we refer to this value as tag. Because the OBU
will be signing all the messages it sends, it ﬁrst needs to
generate a signing keypair (vktag,sktag); the public veriﬁ-
cation key will need to be stored with both the TSP and
TC, while the signing key will be kept private. We will
also use an augmented version of the BlindExtract pro-
tocol (mentioned in Section 3.3) in which the OBU and
TC will sign their messages to each other, which means
the OBU will need to have the veriﬁcation key for the
TC stored as well (alternatively, they could just commu-
nicate using a secure channel such as TLS). In addition,
the OBU will need to generate parameters for an IBE
scheme in which it possesses the master secret key msk,
as well as to load the parameters for the commitment and
NIZK schemes (note that it is important the OBU does
not generate these latter parameters itself, as otherwise
the driver would be able to cheat). Finally, the OBU will
also need to have stored the function f used to deﬁne road
prices.
4.2 Payments
Once the OBU is set up with all the necessary parame-
ters, it can begin making payments. As the driver travels,
the GPS picks up location and time information, which
can then be matched to segments (where,when). For
each of these segments, the OBU ﬁrst computes the cost
for that segment as p = f (where,when). It then com-
putes a commitment c to this value p; we will refer to the
opening of this commitment as openc. Next, the OBU
computes an identity-based encryption C of the open-
ing openc along with a conﬁrmation value 0λ , using the
identity id = (where,when). Finally, the OBU computes
a non-interactive zero-knowledge proof π that the value
contained in c is in the range [0,M]. This process is then
repeated for every segment driven, so that by the end
of the month the OBU will end up with a set of tuples
i=1. In addition to this set, the OBU will also
need to compute the opening openﬁnal for the commit-
ment cﬁnal = c1 (cid:1) c2 (cid:1)··· (cid:1) cn; i.e., the opening for the
commitment to the sum of the prices, which effectively
reveals how much the driver owes. The OBU then cre-
(cid:8)(ci,Ci,πi)(cid:9)n
ates the ﬁnal message m =(cid:0)tag,openﬁnal,(cid:8)(ci,Ci,πi)(cid:9)
i
signs it to get a signature σm, and sends to the TSP the
tuple (m,σm). This payment process is summarized in
Algorithm 4.1. The parameter λ , set to 160 for 80-bit
security, is explained below.
(cid:1),
Once the TSP has received this tuple, it ﬁrst looks up
the veriﬁcation key for the signature using tag. If it is
satisﬁed that this message came from the right OBU, then
it performs several checks; if not, it aborts and alerts
the OBU that something went wrong (i.e., the message
was manipulated in transit) and it should resend the tuple.