### 5.2 Implementation Details

To generate the dispatcher code, we have extended the `edger8r` tool [25] accordingly. The sandbox dispatchers are generated in the files `Enclave_us.c` and `Enclave_us.h`, while the application dispatchers are located in `Enclave_u.c` and `Enclave_u.h`. Before processing, an enclave always copies arguments to its own memory. Similarly, our dispatcher code copies arguments to the application's memory before invoking an OCALL. This design prevents Time-Of-Check-Time-Of-Use (TOCTOU) vulnerabilities, such as double-fetch bugs [58].

ECALLs and OCALLs are routed between the application and the sandbox process via two distinct shared memory regions, one for each direction. The dispatchers synchronize ECALL/OCALL interactions using shared semaphores. This approach ensures that the processes (application and sandbox) do not consume CPU time while waiting for the other communication partner. For receiving OCALLs, the application installs a separate listener thread that only becomes active upon incoming OCALLs.

The selection of appropriate syscall filters is crucial for the security of SGXJail, as a malicious enclave can exploit a lax configuration (e.g., via rogue EEXIT attacks). It is advisable to restrict both the number and complexity of syscalls to minimize the attack surface. By choosing shared memory for inter-process communication, we avoid the need for additional syscalls, requiring only one syscall (futex) for synchronization. We configure seccomp [36] to allow only the necessary syscalls: `futex` for semaphores and `exit_group` for terminating the sandbox process. Thus, the shared memory approach results in only one additional whitelisted syscall beyond the required `exit_group` syscall. Unless these syscalls are buggy, they cannot cause a security violation when issued by a malicious enclave.

The SGX SDK passes OCALL function arguments from the enclave to the application via the application's stack. The enclave knows the application's stack location through the stack pointer (RSP register), which is preserved by the `EENTER` instruction. Therefore, it can allocate a stack frame on the host stack using the `sgx_ocalloc` function and store outgoing OCALL arguments there. To reduce SGXJail overhead, we can modify the RSP immediately before an `EENTER` to point to the shared memory, instructing the enclave to write OCALL arguments directly to the shared memory instead of the sandbox application's stack. Upon `EEXIT`, the original sandbox stack (RSP) is restored.

In our current implementation, the size of the shared memory is hard-coded to three pages for each direction. For ECALL/OCALL arguments exceeding the shared memory, the shared memory can be dynamically resized on demand. Although multithreaded enclaves are not currently supported, support can be easily added by installing separate semaphores and shared buffers for all enclave threads, enumerated in a public enclave XML configuration file. Support for nested calls (OCALLs issuing ECALLs) can also be added by adapting the synchronization mechanism appropriately.

An interesting question is whether SGXJail should be integrated with the SGX SDK without requiring recompilation of the application. This would allow system administrators to globally enforce SGXJail by simply installing corresponding shared libraries. Since the enclave’s EDL file is public and will be distributed alongside third-party enclaves, generating dispatcher code is straightforward. Additionally, one would need to hook the enclave API of the unmodified application binary and inject dispatcher code, which can be done by preloading SGX SDK libraries (in particular, `sgx_urts.so`).

**Table 2: ECALL and OCALL Latency in CPU Cycles of SGXJail Compared to the Unprotected Vanilla Version**

| Latency | Vanilla (± SD) | SGXJail (± SD) |
|---------|----------------|----------------|
| ECALL   | 15,624 (± 301) | 22,094 (± 814) |
| OCALL   | 13,438 (± 1,046) | 19,515 (± 1,360) |

### 5.3 Evaluation

SGXJail does not affect the runtime performance of host applications or enclaves in isolation. Performance overhead only occurs during ECALLs and OCALLs due to message passing via shared memory and the necessary synchronization between the application and sandbox process. To evaluate this effect, we present microbenchmarks for bare-metal ECALL and OCALL latency, followed by macrobenchmarks on more representative workloads.

**Test Setup:**
All evaluations were conducted on a commodity notebook featuring an Intel i5-6200U CPU, a Samsung SM951 SSD, and running Ubuntu 16.04 Desktop with SGX SDK version 2.4. For the benchmarks, we disabled the screen and network interfaces to reduce noise from screen redrawing and external interrupts. We also fixed the CPU frequency to its maximum (2.3 GHz) and pinned the benchmark to a single core. The benchmarks include a warm-up phase.

**Microbenchmarks:**
To measure the ECALL latency, we implemented a simple ECALL and measured its execution time from within the host application. The ECALL latency includes `EENTER`, `EEXIT`, all glue code for the enclave and host, as well as context switching and synchronization between the application and sandbox for SGXJail. To measure the OCALL latency, we performed one simple OCALL from within the ECALL and subtracted the ECALL latency. We repeated the measurement 500 times. The resulting latencies are shown in Table 2. The raw ECALL latency increases from 15.6·10^3 cycles to 22.1·10^3 cycles, while the OCALL latency increases from 13.4·10^3 cycles to 19.5·10^3 cycles. Despite these increases, the absolute latency remains small. Given that many practical usage scenarios of SGX involve complex computations inside the enclave, the actual runtime overhead is much lower than the pure ECALL/OCALL overhead.

**Macrobenchmarks:**
Quantifying the performance of enclaves is highly application-specific. Unfortunately, enclaves are not widely deployed yet, and standardized benchmarking suites are unavailable. A common approach is to port existing programs to an enclave [61]. However, this often introduces unnecessary OCALLs to the standard library, which well-designed enclaves would not perform (e.g., the `getpid` syscall in openVPN [61]).

Instead, we quantify the performance of SGXJail as follows:
1. We benchmark a synthetic workload under different OCALL frequencies. The results of this benchmark are generic and can be applied to any enclave for which the OCALL frequency can be determined.
2. We benchmark the storage of sensitive enclave data to disk via the Intel Protected Filesystem (PFS). The PFS is integrated within the SGX SDK and is likely to be used by a vast number of enclaves.

For our first benchmark, we observe that an enclave typically issues OCALLs to perform syscalls, such as writing to files. Our benchmarked OCALL performs a `close` syscall on an invalid file descriptor, providing an upper bound on the performance overhead since longer syscalls decrease the influence of the OCALL overhead. We repeated each measurement 100 times. The OCALL-to-enclave ratio (with respect to their runtime) and the overhead of SGXJail compared to unprotected Vanilla applications are given in Figure 3, with the standard deviation shown as the area under the curves.

We execute a fixed baseline workload inside the enclave, which corresponds to 2201.44 (± 25.67) ·10^6 cycles, or 0.96 (± 0.011) seconds on our 2.3 GHz CPU. As this workload runs within the enclave, we quantify it as enclave seconds (Esec). While keeping the enclave workload constant, we issue OCALLs at different frequencies and measure the additional OCALL work. This is shown as a ratio on the left axis of Figure 3, allowing us to decouple the OCALL overhead from the OCALL frequency, quantified as OCALLs/Esec.

Figure 3 shows that the overhead of SGXJail is virtually non-existent for low-frequency OCALLs, meaning that pure enclave execution is not impeded by SGXJail at all. Even for 10,000 OCALLs/Esec, the overhead is below 3%, and for a large number of 50,000 OCALLs/Esec, the overhead is only around 11%. To put these numbers into perspective, Netflix observed a maximum of 50,000 OCALLs/s across their systems [20]. For even higher OCALL frequencies, the OCALL workload starts to exceed the enclave workload in the vanilla version already. With SGXJail, enclaves can issue up to 113,000 OCALLs/Esec before OCALL processing exceeds actual enclave computations (ratio=1). For unprotected apps, this point is reached at 164,000 OCALLs/Esec. Such situations should be addressed in practice by redesigning the enclave API and reducing or removing unnecessary OCALLs. However, SGXJail only introduces around 20% overhead even in this extreme case.

Our first benchmark measures the raw OCALL performance but does not reflect the performance of copying OCALL arguments between the enclave and application. To evaluate the maximum overhead of a real-world scenario, we benchmark an enclave that only accesses files via the Intel Protected File System (PFS) library. PFS is shipped with the SGX SDK and is intended for sealing sensitive enclave data on the host filesystem for persisting state across reboots. To resemble a worst-case scenario of PFS, we implement and benchmark a single ECALL that opens a new file (`sgx_fopen_auto_key`), writes a fixed-size buffer (`sgx_fwrite`), and immediately closes the file again (`sgx_fclose`). We repeat the measurements 200 times. The results are shown in Figure 4, comparing the PFS runtime of SGXJail to unprotected Vanilla enclaves for different payload sizes.