used SNMP queries for the sysUpTime counter to validate four of
the six outage windows, and logged into two routers where the
counter was unable to validate because the counter had rolled over
after 497 days of uptime [35].
They had no reasonable way to confirm inferences prior to the
last reboot of the six routers we identified, with the exception
of one core router, where they validated two reboot events. The
routers were all internal to their network, and provided connectivity
to small subnets of the larger IPv6 address space. The operator
validated our inference that the routers were not a single point of
failure for the larger prefixes advertised in BGP. All of the previous
six reboot inferences were the last time the routers in question
had rebooted; the seventh reboot inference was validated through
personal knowledge of the operator.
US R&E backbone #1: We discussed five router reboot events
involving four routers with a US state-level R&E network backbone.
They explained that larger universities have two routers and redun-
dant connections to the R&E backbone, but the smaller members
have a single connection to a single router in the R&E backbone.
They used their trouble ticket system to provide validation and
context on the reboots we inferred.
For the first router, they reported their provider-edge router
within a University data center was down for more than two hours
as part of a data center-wide power outage. They confirmed the
reboot, and that the router was a single point of failure for a prefix
that their customer announced in BGP. However, because all but one
Routeviews peer withdrew the prefix, our system did not classify
the router as a single point of failure. During the outage window, the
single Routeviews peer periodically reported updates for the route,
though these updates could not have come from the provider-edge
router, as the router was powered off at the time.
For the second router, they confirmed a customer router that
was a single point of failure for one prefix likely rebooted within
the inferred outage window, as their BGP session with the router
restarted within the window. They reported the BGP session was
quickly re-established; while all 20 Routeviews peers withdrew the
prefix for at least some period of time, only three were without a
route for more than 30 seconds, and our system did not classify the
router as a single point of failure.
For the third router, they reported the router was within their
customer’s network, and they believed it was not a single point of
failure for any prefixes, which is congruent with the absence of BGP
activity during this time. However, they did not have information
that would allow them to validate the two reboots involving the
device. They were unable to provide any information about a fourth
router that rebooted more than two years prior, but that we were
correct in not inferring a single point of failure for any prefix.
US R&E backbone #2: We sent the operator of a second US R&E
backbone a list of 11 routers with interfaces using addresses from
within their BGP-announced prefixes. Due to the labor involved in
searching their systems for archived SNMP data, they only provided
feedback for four of the routers, three of which we inferred to be a
single point of failure in BGP for at least one prefix. While they did
not provide any comment on the inferred single points of failure,
they did provide feedback on router reboot events.
For the first router, they had no record of a reboot occurring
during the inferred window. They had a record for a crash four days
earlier, however we had not been probing the router during that
time. Nevertheless, the reboot was correlated with the complete
withdrawal of a prefix.
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
Matthew Luckie and Robert Beverly
(a) Complete Withdrawals
(b) Partial Withdrawals
Figure 10: CDF of minimum and maximum withdrawal durations, per router/prefix pair, for complete and partial durations.
For the second router, they reported that it was one of their
routers, and confirmed that they had an alert for the router during
the window, and that it had probably rebooted. They provided
three further events for the router; however, the router had stopped
responding to our probes before the subsequent events, so we were
not able to infer any behavior for the router.
For the third router, they reported the interface was on their
customer’s router, and that the link went down to the router during
the outage window. This event was correlated with the detected
complete withdrawal of a customer prefix.
For the fourth router, they confirmed the reboot we reported was
a known reboot event. They provided another eight other events
that might also have been reboot events, however the IPID sequence
from the router suggests they were not reboot events.
NZ R&E backbone: We discussed 32 reboot events across 8
routers with the operator of a New Zealand R&E backbone, and
approached two of their members for further elaboration. The oper-
ator confirmed they had BGP outages correlated with reboot events
archived in their monitoring infrastructure for four routers we in-
ferred as having rebooted once each. They were unable to help with
five events for two other routers, as the outages were in January
and April 2015 when they had a different network architecture.
We approached the operators of two other routers individually.
The seventh router had five reboots inferred; the operator had con-
figured external data-plane monitoring at five-minute intervals,
and the reboots correlated with four data-plane outages. The oper-
ator was unable to confirm the fifth outage because the monitoring
granularity was too wide. The operator confirmed the router was a
single point of failure for a more specific prefix they announced in
BGP using the backbone’s ASN. Even though there was a covering
prefix in BGP announced by the backbone, there was no reachability
to the addresses covered by the more specific.
The eighth router had 18 reboot events inferred across the 2.5
years of probing. However, the operator could only confirm the
final two reboots in 2017, as they had no data allowing them to
validate prior events. The router was a single point of failure in
BGP for a single prefix; however, we had not observed the router in
traceroute paths in 2017, so while we correctly inferred the reboots,
we had not inferred the router was a single point of failure.
Summary: In total (table 2), we validated 23 reboot events with
no false positives or false negatives, and 14 single point of failures
with four false negatives, owing to limitations discussed in §4.4.
5 RESULTS
In total, we inferred 749,451 reboots involving 59,175 (40%) of
149,560 responsive routers between January 18th 2015 and May
30th 2017. As discussed in §4, most of the detected router outages
were shorter than 2 hours (figure 3) and most routers that restarted
did so fewer than two times (figure 4). Importantly, we were only
able to correlate 2,385 routers – 4.0% of the routers that had out-
ages in our dataset – with a prefix being completely withdrawn,
after excluding more complex events involving multiple routers
overlapping in time (§5.5). Figure 8 shows that, where necessary,
BGP was able to converge on alternative paths for the majority
of router outages, and outages that caused a complete withdrawal
were confined to the edge of the network – either topologically
adjacent to the affected network, or within the affected network.
In our data, we inferred that 59% of all single points of failure were
the customer-edge border router, 8% were the provider-edge border
router, and 29% were within the destination AS itself. These prop-
erties are consistent with previously published work describing the
likely behavior of networks based on a first-principles approach that
included router-level topologies from two academic networks [31];
our work is the first to measure the actual impact of router outages
on the Internet’s BGP routing system at scale.
Among the 2,385 single point of failure routers, we used Max-
mind [34] to geolocate the ::1 address of the IPv6 prefixes involved
in these failures to 90 different countries. 25% of the prefixes geolo-
cate to the United States, 13% to Brazil, 8% to Great Britain, 6% to
India, and 2-3% each to Russia, Australia, Indonesia, Germany, and
Ukraine. This geodistribution largely mirrored the overall distribu-
tion of countries in our monitored dataset, implying that outages
were no more prevalent in any given country than another.
5.1 Prefix Withdrawal Duration
Figure 10a shows the distribution of complete prefix withdrawal
durations for each router/prefix pair. For each prefix that was with-
drawn, we computed the minimum and maximum duration the
prefix was withdrawn in BGP. 44% of the minimum durations were
less than 5 minutes in length, suggesting most router outages were
short lived, and likely caused by a router restart due to maintenance.
However, the tail is long, as 26% of prefixes were withdrawn for at
least 30 minutes.
Similarly, figure 10b shows the distribution of partial prefix with-
drawal durations for each router/prefix pair. As with the duration of
max 0.2 0.4 0.6 0.8 11min5min15min30min1hr2hr4hr8hr16hrCDFComplete Withdrawal Durationmin 0max 0.2 0.4 0.6 0.8 11min5min15min30min1hr2hr4hr8hr16hrPartial Withdrawal DurationCDFmin 0The Impact of Router Outages on the AS-level Internet
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
the full withdrawals, the partial withdrawals were short: 52% were
less than five minutes. As with the complete withdrawals, the tail is
long, and manual investigation of the longer withdrawal durations,
particularly when nearly all peers withdrew the prefix (figure 9)
revealed apparent bugs in BGP implementations. For example, we
confirmed with one R&E network operator that an inferred multi-
hour router outage was a single point of failure for their customer,
despite the fact that one Routeviews peer retained a route to the
prefix, and periodically reported updates for the route. However,
these updates could not have come from the provider-edge router,
as the router was powered off for data center maintenance.
5.2 Presence of Covering Prefixes
The 2,385 routers that we were able to correlate with a prefix with-
drawal were in paths toward 3,396 prefixes. Of these 3,396 with-
drawn prefixes, 1,022 (30%) were covered by a less specific prefix
that was not simultaneously withdrawn, suggesting that the more
specific prefix that was withdrawn could be present in the routing
table for traffic engineering purposes. Indeed, 699 (68%) of the more
specific prefixes had a covering prefix announced by the same AS.
The 2,374 prefixes that were not covered by a less specific prefix
when they were withdrawn were correlated with 1,726 routers that
had an outage – 2.9% of the routers that had outages in our dataset.
5.3 Impact on AS-level Reachability
The list of routers we probed was updated at the end of October
2016, coinciding with CAIDA’s probe list being updated, so for the
following analysis we used router outages inferred during Novem-
ber and December 2016, as we have traceroute paths for all IPv6
routed prefixes in October 2016. This allows us to correlate all an-
nounced prefixes with routers, rather than the subset probed before
October 2016. In total, we were able to infer prefix withdrawals cor-
related with router outages for 149 ASes during these two months;
82 of these ASes (55%) were completely unrouted in BGP during
these router outages. The routers were single points of failure for
these 82 ASes.
5.4 Impact of AS-level Multi-homing
To better understand where single points of failure reside, we used
a January 16, 2017 Routeviews RIB to construct the IPv6 AS-level
graph. We then found the degree of the ASes corresponding to
the IPv6 prefixes involved in the identified single points of failure.
Figure 11 shows the cumulative fraction of ASes originating pre-
fixes that represented single points of failure as a function of AS
degree. For context, we also plot the AS degree distribution for
the monitored population, which includes IPv6 router interfaces
that responded with fragment identifiers in the final 24 hours of
our dataset. Here, we use longest prefix matching against the same
Routeviews RIB to map each router interface to the AS originating
the corresponding IPv6 prefix.
As seen in Figure 11, 21% of the routers in the monitored popula-
tion belong to degree-one stub ASes, while 42% of the single points
of failure are in degree-one stub ASes. Although we intuitively
expect stub ASes to be less resilient to single router failures, it is in-
teresting to note that we observe single points of failure in non-stub
ASes. For instance, we found that 16% of the ASes that contained
Figure 11: Cumulative distribution of ASes as function de-
gree. While only 21% of the routers in the monitored popu-
lation belong to degree one ASes, 42% of the single points of
failure are in degree one ASes.
Figure 12: The effect of AS-level multi-homing on pre-
fix/router pairs. In our data, prefixes that were completely
withdrawn as a result of a router outage outside the network
(distances 1-3) were nearly exclusively propagated through
a single upstream AS.
routers representing single points of failure had degree-two – sug-
gesting that a single router peered with two different providers.
Further, while the fraction of high-degree ASes was small, the in-
stances of single points of failure we found in these ASes is likely
attributable to exchange points and other highly interconnected in-
frastructure. These findings underscore the fact that analyzing the
AS-level topology without the router-level interconnection context
is insufficient to show a network is resilient to failure.
Figure 12 shows the effect of AS-level multi-homing on pre-
fix/router pairs for our 2.5 years of router outage data. For each
router outage where the router was within three IP hops of the AS
announcing the prefix, we classified the BGP event type according
to whether the prefix was announced via a single upstream or via
multiple upstreams. In our data, prefixes that were completely with-
drawn as a result of a router outage outside the network (distances
1-3) were nearly exclusively propagated through a single upstream
 0 0.2 0.4 0.6 0.8 1 1 10 100 1000Cumulative Fraction of Rebooting ASesAS DegreeSingle Points of FailureMonitored PopulationRouter hopdistancePECE1−20−11Prefix announced through a single upstreamPrefix announced through multiple upstreams0.2023Fraction of Population0.40.60.8−3SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
Matthew Luckie and Robert Beverly
(a) Max number of peers concurrently withdrawing
(b) Number of peers sending an update
Figure 13: Correlating router outages with IPv4 prefix withdrawals and churn: distribution of the fraction of Routeviews peers
for the associated IPv4 prefix during versus outside the inferred outage window.
AS. A router outage at distance 1, the provider-edge (PE) router,
implied the connecting AS was single-homed to a single PE router.
Router outages at distance 0, the customer-edge (CE) router, usu-
ally (63.5% of outages) implied the prefix was announced through
a single upstream AS. However, the remaining 36.5% of outages
where a CE router experienced an outage were BGP-announced
through multiple upstream ASes, implying the same CE router was
used to connect through multiple upstreams. Even though the af-
fected ASes had provider diversity at the AS-level, our router-level
measurements still inferred their CE router to be a single point
of failure, further showing the benefit of synthesizing BGP and
router-level data when analyzing the resilience of ASes in BGP.
5.5 Overlapping Router Outages
In our data, some routers that were in the path towards the same
prefix had outages that overlapped in time, and we filtered these
events from our analysis of single points of failure. There are multi-
ple possible explanations for these events, including power outages
that impact multiple neighbors, and operator router maintenance
activities that overlap. Further, it is possible the two routers had
non-overlapping outages, but our probing granularity was not fine-
grained enough to capture this effect. Because router outages were
rarely correlated with a prefix withdrawal if they were more than
three hops from the AS announcing the prefix, we focused on
overlapping router outages no further than three hops from the
destination AS, as well as router outages within the destination
network. In total, we inferred 865 overlapping router outages that
we correlated with 619 prefixes.
We examined the adjacency of these routers using the distance
metric we described in §4.2. Only 15% of these events involved
routers the same distance from the edge of the destination AS: 30%
and 27% of impacted routers were separated by one and two hops,
respectively, implying a localized outage. We detected two routers
with overlapping outage windows in 64% of the events; 33% had
three separate routers involved. We emphasize the fraction of com-
plete withdrawal events containing overlapping outage windows
is a small fraction of the overall set, consistent with the relatively
small number of short events per day (figures 3 and 5).
5.6 Correlation with IPv4 Outages
As the IPv6 Internet matures, its topology grows increasingly con-
gruent with the IPv4 Internet [16]. To understand the extent to
which IPv6 router restarts impacted IPv4, we examined 28637 re-
boots experienced by 2665 IPv6 interfaces – a ∼ 5% sample of all
interfaces where we inferred at least one reboot. We associated IPv6
router interfaces with a set of IPv4 prefixes as follows. For each
IPv6 interface, we determined the origin AS of the IPv6 prefixes as-
sociated with that interface in §4.2. Using daily RIB snapshots from
Routeviews, we found all IPv4 prefixes announced by that origin
AS on that day. Using the method described in §4.3, we examined