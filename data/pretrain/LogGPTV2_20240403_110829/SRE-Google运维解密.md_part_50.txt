func exampleRpcCall(client pb.ExampleClient,request pb.Request) *pb.Response {
同时限制每个逻辑请求的RPC数量为10。如下面这段代码，使用Go语言与gRPC实现：
假设前端中的代码与后端通信时，已经实现了重试机制。该重试机制在遇到错误时重试，
重试
当评估和具体实施的时候，还需要考虑以下几点：
当我们评估流量抛弃或者优雅降级时，需要考虑以下几点：
//最多重试RPC20次
opts:= grpc.WithTimeout(5 *time.Second)
·优雅降级不应该经常被触发一
·确定具体采用哪个指标作为流量评估和优雅降级的决定性指标（如，CPU用量、
for attempts>0
attempts:=20
//将RPC超时设置为5s
问题，全部服务器同时都会受到影响）。
小部分的服务压力测试以便更多地触发这个模式，保证这个模式还能正常工作。
态下，优雅降级不会经常触发，意味着在这个模式下的运维经验很少，对这个模
记住，代码中平时不会使用的代码路径（通常来说）是不工作的。在稳定运行状
实现一种简单的关闭降级模式，或者是快速调节参数的方式。将这个配置文件存
复杂的流量抛弃和优雅降级系统本身就可能造成问题一
的情况下。
现了意料之外的负载转移。整个降级系统应该简单、易懂，尤其是在不经常使用
都实现，还是可以选择某个高层面的关键节点来实现？
流量抛弃或者优雅降级应该在服务的哪一层实现？是否需要在整个服务的每一层
当服务进入降级模式时，需要执行什么动作？
延迟、队列长度、线程数量、是否该服务可以自动进行降级，或者需要人工干预）。
if err !=nil{
conn, err := grpc.Dial(*serverAddr, opts...)
可以提高部署速度，但是同时也会增加整个系统的同步性风险（如果配置文件有
储在一个强一致性的存储系统（如Chubby）中，每个软件服务器都可以订阅改变，
导致软件服务器以外的服务进入降级模式运行，甚至进入反馈循环。设计时应该
监控系统应该在进入这种模式的软件服务器过多时报警。
式的问题也不够熟悉，这就会升高这种模式的危险性。我们可以通过定期针对
—通常触发条件显示了容量规划的失误，或者是出
防止软件服务器过载
—过于复杂的逻辑可能会
268
---
## Page 274
232
注4作为留给读者的练习：编写一个模拟器，观察在不同的负载限制值和重试次数下，后端所能完成的有
这里为了描述这个场景，简化了一些细节，注4但是这里很好地展现了重试是如何摧毁一
这个系统可能会造成如下的连锁故障：
5.如果后端任务无法处理连续增长的负载一
4.重试的量在增加：第一秒的100QPS，造成了第二秒的200QPS，造成了300
3.这些100QPS的失败请求会在MakeRequest中以1,000ms为周期重试，这些请
2.前端代码以固定的10,100QPS调用MakeRequest，使得后端过载100QPS，后端
1.假设后端服务每个任务的负载上限是10,000QPS，在超过这个上限之后，优雅降
grpclog.Fatalf(“ran out of attempts”)
价值工作的数量变化。
力重新分配到其他的后端任务上，进而造成这些任务的过载。
CPU时间等一
来越少。
QPS。越来越少的请求能够一次成功，也就是说，后端实际进行的有价值工作越
QPS-
求可能会成功。但是这些请求本身叠加上正常的请求，后端现在会接收到10,200
会将这些请求拒绝掉。
级系统会拒绝所有的额外请求。
return response
if err!=nil{
response,
client:=pb.NewBackendClient(conn)
//创建客户端，发送RPC
defer conn.close()
第22章
continue
attempts--
7/发送请求过程中出现问题，重试
continue
attempts--
//出现了问题，重试
-200QPS的请求会因为过载而失败。
处理连锁故障
err := client.MakeRequest(context.Background,request)
后端任务可能会在请求压力和重试下最终崩溃。这个崩溃会将压
一这些请求会消耗文件描述符、内存、
---
## Page 275
这个模式在多起连锁故障中出现，不管前端和后端是采用RPC消息模式通信，还是由客
的负载，直到重试停止，后端稳定为止。
如果上述任意一个情况属实，为了脱离这种循环，必须大幅减少甚至彻底消除前端产生
返回错误的成本大小，这个问题很可能不会消失。这里主要有两个因素：
就算MakeRequest的请求速率降低到系统崩溃前的级别（如9.000QPS），还取决于后端
个系统的。注意临时性的过载升高，或者使用量的缓慢增加都有可能造成这种情况。
当发送自动重试时，需要将如下部分考虑在内：
离线同步协议在错误情况下大量重试导致的。
户端运行的JavaScript代码发送XmLHttpRequest调用，并且重试，又或者是来自于某种
·大部分后端保护策略都适用于此。尤其是，
·如果后端使用大量的资源处理最终这些会失败的请求，那么重试造成的请求可能
一定要使用随机化的、指数型递增的重试周期。
同时优雅降级可以将重试对后端的影响降低。
后端服务器自身可能也不稳定。重试可以放大本章前面“服务器过载”
试错误和不可重试错误分开。不要在客户端代码里重试永久性错误或者异常请求
限制每个请求的重试次数。不要将请求无限重试。
（参见文献[Flo94]）。
故障（某个网络问题）就可能导致重试请求同时出现，这些请求可能会逐渐放大
章ExponentialBackoff and Jitter(http://www.awsarchitectureblog.com/2015/03/
到的效应。
仍然会将后端保持在过载状态中。
使用明确的返回代码，同时详细考虑每个错误模式应该如何处理。例如，将可重
数据库的64次请求（4）。在数据库由于过载返回错误时，这种重试只会加重问题。
JavaScript层各发送3次重试（总计4次请求），那么一个用户的动作可能会造成对
重试次数的乘积数量的请求。如果服务器由于过载不能提供服务，后端、前端、
避免同时在多个级别上重试导致的放大效应：高层的一个请求可能会造成各层
从多个视角重新审视该服务，决定是否需要在某个级别上进行重试。这里尤其要
丢弃，而不会造成全球性的连锁故障。
在全局范围内限制住重试造成的影响，容量规划失败可能只是会造成某些请求被
试预算耗尽，那么直接将这个请求标记为失败，而不真正发送它。这个策略可以
考虑使用一个全局重试预算。例如，每个进程每分钟只允许重试60次，如果重
backoff.html）。如果重试不是随机分布在重试窗口里的，那么系统出现的一个小
，对系统进行测试可以提前显现问题
。可参见文献[Bro15]中提到的文
防止软件服务器过载
一节中提
233
270
271
---
## Page 276
272
234
与其在发送RPC给后端服务器时自拟一个截止时间，不如让软件服务器采用截止时间传
截止时间传递
查是否还有足够剩余时间处理请求。
为解析请求阶段、发送后端请求阶段和处理阶段，那么可能在每个阶段开始之前都要检
器应该在每个阶段开始前检查截止时间，以避免做无用功。例如，如果一个请求被分解
如果处理请求的过程有多个阶段（例如，由一系列RPC和回调函数组成），该软件服务
了这个请求，不会再接收回复。
务器再继续处理这个请求是不明智的，因为这样无法产生任何价值一
从队列到线程池的时间需要11s。这时，客户端已经放弃了该请求。在多数情况下，服
假设一个RPC请求设置了10s的截止时间，由客户端设置。服务器目前过载严重，导致
作，回复已经被取消的RPC是没有意义的。
过客户端截止时间的请求。这样的结果是，服务器消耗大量资源没有做任何有价值的工
很多连锁故障场景下的一个常见问题是软件服务器正在消耗大量资源处理那些早已经超
超过截止时间
置，需要在多个限制条件中选择一个平衡点。
源。截止时间设置得太短可能会导致某些比较重型的请求持续失败。恰当的截止时间设
截止时间设置得太长可能会导致框架中的高层级部分由于低层级的问题而持续消耗资
常会导致某些短暂的、已经消失的问题继续消耗服务器资源，直到重启。
设置一个截止时间通常是明智的。不设置截止时间，或者设置一个非常长的截止时间通
选择截止时间
截止时间（deadline）定义了前端会等待多长时间，这限制了后端可以消耗的前端资源。
当某个前端任务发送RPC 给后端服务器时，前端需要消耗一定资源等待后端回复。RPC
请求延迟和截止时间
底消除重试请求。
么需要修复重试行为（这经常意味着更改代码），要么需要大幅降低负载，要么需要彻
程中，这可以被认为是容量不足的一个特殊情况。要注意的是，在这种情况下，我们要
以帮助识别重试行为，但是也可能会被当成一个故障现象，而不是故障原因。在处理过
在紧急情况下，可能很难确定某次事故是否是由于重试机制导致的。重试速率的图表可
一个详细的信息，这样客户端和其他层可以加大延时，甚至不再重试。
（malformed request），因为这两种请求都永远不可能成功。当服务过载时，返回
第22章
处理连锁故障
一客户端已经放弃
---
## Page 277
会导致初始RPC虽然无法继续处理，却继续消耗服务器资源直到超时。
但是底层之间的RPC只有短暂的截止时间，超时失败了。使用简单的截止时间传递可能
RPC取消的传递可以避免某些泄露情况，如果某个初始RPC设置了一个很长的截止时间，
这里有一些特例，某些服务器可能希望在截止时间过后继续处理该请求。例如，如果某
大量计算的请求）。
否则可能会导致某种特定类型的请求永远失败（如，带大量数据的请求，或者那些需要
应该考虑给发出的截止时间设置一个上限，我们可能想要对非关键性后端的等待时间
时间和客户端收到回复之后的处理时间考虑在内。
同时，我们可能还会将传递出去的截止时间减少一点（如几百毫秒），以便将网络传输
截止时间。
处理该请求，但是这些工作都是无用功，因为从服务器A到服务器B的请求已经超出了
的截止时间已经过了。但是在上述场景中，服务器C会认为仍有15s的时间，从而继续
如果服务器B采用了截止时间传递机制，服务器C应该立刻放弃处理该请求，因为2s
如果不采用这种传递机制，那么下列场景就可能出现
里面的所有服务器都采用同样的截止时间传递机制。
从B发向C的RPC就会有19s的截止时间，以此类推。理想情况下，在整个树状结构
B的RPC就会有23s的截止时间。如果服务器B处理请求花费4s，并且再向C发送请求，
用30s截止时间，然后花费7s时间处理请求，再发送RPC给服务器B，那么从A发向
初始请求触发的整个RPC树会设置同样的绝对截止时间。例如，如果服务器A选择使
可使用截止时间传递机制，截止时间在整个服务栈的高层设置（如，前端服务器）。
递和取消传递的策略。
不是在耗时操作完成之后立刻检查。
个服务器在处理某个请求时需要执行某种很耗时的状态更新工作，同时周期性地将状态
或者那些通常非常快的RPC请求设置限制。然而，要确保先清晰了解服务流量的组成，
4.服务器C在5s后才将请求从队列中取出。
3.如果服务器B使用截止时间传递机制，它应该设置2s的截止时间，但是这里假
2.服务器B等待了8s时间才开始处理请求，并且给服务器C发送了一个RPC。
1.服务器A给服务器B发送了一个RPC，用10s截止时间。
设它使用了一个在代码中写死的20s截止时间。
防止软件服务器过载