Coordinate Systems
In this section we demonstrate several attacks against the
Vivaldi coordinate system. Vivaldi was designed to tolerate
high-error, benign nodes, but it has no built-in mechanisms
to defend against malicious nodes.
Inﬂation and deﬂation attacks. We ﬁrst demonstrate
how a coalition of f=30% malicious nodes can target one par-
ticular victim node and conduct an inﬂation or a deﬂation
attack. Note that the actual number of attackers which di-
rectly inﬂuence the victim is the number of malicious nodes
that are selected to be in the reference set of the victim node.
Using the hypergeometric distribution, we can determine the
probability of having a given number of malicious reference
set members. If we let k represent the number of malicious
nodes in a reference set, N be the number of nodes in the
system, D is the total number of malicious nodes, and n is
the size of the reference set, then the probability of having
exactly k malicious nodes in a reference set is given by
(cid:161)D
(cid:162)
(cid:162)(cid:161)N−D
(cid:162)
(cid:161)N
n−k
f (k; N, D, n) =
k
(5)
n
By summing the discrete probability distributions for values
from 0 to k, we can determine the probability of having a
certain percentage of malicious nodes in reference set.
In
the King data set, given that 30% of the total nodes are
malicious, the probability that at least 30% of the nodes in
a reference set (about 20 nodes) are also malicious is only
about 35%.
Fig. 4 presents the location and associated prediction error
of a victim node under non-attack conditions and under the
two attacks. The correct location of the victim node is in the
upper left quadrant. For the deﬂation attack, note the circle
at the origin representing a victim node which did not move
to its correct position. In this scenario, the attackers send
the victim node coordinates that minimize the diﬀerence be-
tween the actual RTT and estimated RTT (the Euclidean
distance between the attacker and victim). As a result, the
victim stays at its current coordinate while believing it has
a very low perceived estimation error. Fig. 4(b) also depicts
an inﬂation attack, where the attackers send the victim node
chosen coordinates along with an artiﬁcially high RTT by
delaying query responses. Note the square in the upper right
quadrant representing the victim node forced to move away
from the origin and towards a location chosen by the at-
tacker. As can be seen in the Table 4(a), the attacks greatly
increase the prediction error of the victim node from 10ms
to 60ms for the deﬂation attack and to 70ms for the inﬂation
attack.
Attack
None
Deﬂation
Inﬂation
w/defense
Pred. Error
10 ms
60 ms
70 ms
11 ms
(a) Prediction Error
Figure 4: Victim node error and placement for a
deﬂation and inﬂation attack (King)
(b) Node Placement
Oscillation attacks. We demonstrate an oscillation at-
tack in Fig. 5. In this scenario, the attacker sends the victim
nodes erroneous random positions selected over the coordi-
nate space with a low error value, causing the victim nodes
 0 1 2 3 4 5 6 7 8 9 10 0 10 20 30 40 50System Prediction Error (ms)Simulation TimeNo Malicious Nodes10% Malicious Nodes20% Malicious Nodes30% Malicious Nodes 0 20 40 60 80 100 120 140 0 10 20 30 40 50System Prediction Error (ms)Simulation TimeNo Malicious Nodes10% Malicious Nodes20% Malicious Nodes30% Malicious Nodes 0 50 100 150 200 250 300 350 400 0 10 20 30 40 50System Prediction Error (ms)Simulation TimeNo Malicious Nodes10% Malicious Nodes20% Malicious Nodes30% Malicious Nodes 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 0 10 20 30 40 50Relative ErrorSimulation Time10% Malicious Nodes20% Malicious Nodes30% Malicious Nodes 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6 2.8 0 10 20 30 40 50Relative ErrorSimulation Time10% Malicious Nodes20% Malicious Nodes30% Malicious Nodes 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 0 10 20 30 40 50Relative ErrorSimulation Time10% Malicious Nodes20% Malicious Nodes30% Malicious Nodesto make multiple incorrect coordinate changes. As seen in
Fig. 5(a), the system under non-attack conditions has an
easily identiﬁable structure in which nodes with small RTTs
between them converge into clusters in the coordinate space.
When the system is under attack as seen in Fig. 5(b), the
virtual coordinate system loses its structure and hence also
loses its ability to yield a low error embedding. This at-
tack also exempliﬁes the epidemic nature of such attacks.
As correct nodes computing incorrect coordinates are later
used as reference nodes for other nodes, the entire system
destabilizes.
(a) No attack
(b) Oscillation attack
Figure 5: Virtual coordinate system node placement
under an oscillation attack (King)
Impact of percentage of malicious nodes. We in-
vestigate the eﬀect of the number of malicious nodes on
the accuracy of the system, by varying the percentage of
malicious nodes. Each queried malicious node returns er-
roneous metrics in the form of a random position selected
over the coordinates {(x, y)|x, y ∈ [−100000, 100000]} and a
low, non-zero error value. A malicious node also randomly
delays its response between 100ms and 1000ms in order to
induce greater variability in its responses in an attempt to
expand the coordinate space.
Fig. 2 presents the prediction error for the King data set
for several percentages of malicious nodes. Under non-attack
conditions, a node joining the coordinate system is initially
placed at the origin of the logical coordinate space. As time
passes, each node receives query responses from its reference
set and is able to reﬁne its position, allowing the system as
a whole to achieve lower prediction error. Once the system
stabilizes about halfway through the simulation, the sys-
tem prediction error remains roughly constant. After this
point, each of the nodes continues to reﬁne its position, but
the overall sum of these movements yields little change in
the prediction error. While the system under attack may
initially start with similar prediction errors since nodes are
initially placed at the origin, it is never able to eﬀectively
reﬁne its coordinates and achieve the desired low estimation
error found in the non-attack scenario. As the percentage of
attackers increases, the ability of the system to accurately
estimate latency signiﬁcantly degrades.
Similar trends are also evident in Fig. 3, where the sys-
tem can be seen to stabilize at a much higher relative error
than the baseline of one. Having even a small percentage of
attackers incurs double or triple the estimation error when
compared with the non-malicious scenario. Malicious nodes
have a greater negative impact on the lower error nodes, as
can been seen from the higher relative errors in Fig. 3(a) and
Fig. 3(b) than in Fig. 3(c). When a low error node moves
in response to malicious data, it is prone to make large, er-
roneous changes to its own position and experience a higher
estimation error.
Impact of attacks on diﬀerent network topologies.
We examine the impact of the attacks on diﬀerent network
topologies with diﬀerent sizes and variabilities by using three
representative data sets. Fig. 6 shows the relative error for
these data sets when f=30% of the nodes are malicious. Each
of the topologies is adversely eﬀected, with the King data
set (Fig. 6(a)) showing the greatest degradation in accuracy
due to the fact it has more variation in RTT and is prone to
excessive over and under estimation in response to an attack.
Meridian (Fig. 6(b)) shows less degradation due to the fact
it has less variation in its link latencies. AMP (Fig. 6(c))
shows more variability in the relative error due to its small
size and frequent, large-scale node coordinate changes.
4.3 Threshold Selection for Spatial-Temporal
Outlier Detection
An important aspect of our approach is selecting the tem-
poral and spatial thresholds that allow for the identiﬁcation
of potentially malicious query responses and eliminate them
from the coordinate computation process. We consider the
same attack scenario with a percentage of attackers as in
Section 4.2 to experimentally determine our outlier detec-
tion thresholds since this scenario is one of the most diﬃcult
in which to identify malicious responses. When a malicious
node selects a coordinate to respond with, this coordinate is
selected from an area in which many altruistic nodes reside.
The malicious nodes also report low but variable error inline
with low-error altruistic nodes. These factors help disguise
the malicious nodes actions and make them much harder to
detect.
We use a slightly modiﬁed version of the method proposed
in Section 3.2. Speciﬁcally, we do not use latency in the out-
lier detection due to the fact the latencies are predetermined
in the simulator and thus show little variability.
Temporal threshold selection. We used a threshold of
4.0 for our temporal outlier detection to allow for the four
features: remote error, local error, change in remote coordi-
nates, and change in local coordinates to vary at most one
standard deviation over each feature from their temporally
developed mean. The value was chosen based on the formula
of the simpliﬁed Mahalanobis distance as in [45].
Spatial threshold selection. The threshold for our
outlier detection can be mathematically derived as in [40,
37], assuming a multivariate Gaussian distribution for the
metrics vector. The contours of equal probability of this
distribution create a 2-dimensional ellipse and the outlier
threshold reﬂects the probability of a vector being within
the ellipse whose semi-axes are determined by k. The prob-
ability that a random vector lies within the ellipse increases
with the size of k. Thus, for a given value of k the probability
that a probed tuple lies within the ellipse can be computed
as:
P = 1 − e
−k2
2
(6)
We initially analytically selected a k of 1.5, in theory cre-
ating a threshold through which 53% of the coordinate up-
dates would successfully pass. Through empirical testing of
over 200,000 coordinate updates over multiple simulations,
we found an ellipse determined by this threshold will allow
approximately 79% of the updates to pass. This variation
from the mathematically derived value can be attributed to
the fact that the used metrics do not form a perfect normal-
ized distribution and have a smaller variance than assumed
in Equation 6. A node may select smaller spatial threshold
values for stronger security guarantees, with the drawback
(a) King
(b) Meridian
(c) AMP
Figure 6: Relative error under 30 percent malicious nodes for three real-life Internet latency data sets
that it may ﬁnd its coordinate less accurate due to discard-
ing valid updates.
Table 2: False Positive Rate (Percentage) and Me-
dian Prediction Error for Diﬀerent Spatial Outlier
Thresholds (King)
% Mal.
Nodes
0
10
20
30
Spatial Outlier Threshold
1.25
28, 16ms
17, 17ms
21, 18ms
27, 20ms
1.50
21, 16ms
13, 18ms
15, 21ms
11, 22ms
1.75
17, 16ms
10, 19ms
7, 23ms
10, 33ms
2.00
13, 16ms
5, 20ms
6, 26ms
9, 36ms
Fig. 7 presents the relative error for the King data set in
which the temporal outlier threshold was set to 4.0 and vari-
ous spatial outlier detection thresholds were tested. Table 2
presents corresponding false positive rate and median sys-
tem prediction error for the diﬀerent thresholds. Although
higher thresholds provide a smaller false positive rate, they
do induce a higher error rate. For example, as malicious
nodes are introduced into the system, a threshold of 2.00
maintains a low false positive rate with the trade-oﬀs that
the prediction error raises to 36ms, with 14ms more than
the threshold of 1.5 which maintains a prediction error of
22ms, when 30% of the nodes are malicious. We note that
virtual coordinate systems are designed to be long-running
services and hence the presence of a small percentage of false
positive will not hinder the system. Based on the results in
Fig. 7 and Table 2 we conclude that a spatial threshold of
1.5 worked well for diﬀerent percentages of attackers while
having an acceptable false positive rate.
4.4 Mitigating Attacks Against Virtual
Coordinate Systems
In this section we demonstrate the eﬀectiveness of our
defense mechanisms at mitigating the eﬀects of malicious
nodes and sustaining the usability of the system.
Inﬂation and deﬂation attacks. We begin by reex-
amining the inﬂation and deﬂation attacks against a victim
node, this time with a system using our defense mechanisms.
The victim node is able to identify and mitigate the eﬀect
of the malicious nodes, achieving a prediction error of 11ms,
as shown in Fig. 4. The error is similar to a system under
non-attack conditions (10ms), and nearly six times less than
the unprotected system.
Diﬀerent percentage of malicious nodes. Fig. 7
presents the relative error for the King data set for diﬀer-
ent percentages of malicious nodes. Note that for a spatial
threshold of 1.5, our solution mitigates the system instabil-
ity caused by the malicious nodes and even helps the sys-
tem to stabilize at a more accurate local minimum than the
initial protocol design to tolerate benign errors. While each
node may occasionally accept erroneous data from malicious
nodes due to a short temporal history or a skewed spatial
history with updates from only a few nodes (as can be seen
by the brief rise in error before coming back down), over
time the system is able to avoid many malicious updates.
Table 3: False Positive Rate (Percentage) and Me-
dian Prediction Error for Diﬀerent Data Sets Using
A Spatial Outlier Threshold of 1.5
Topology
Meridian
23, 30ms
13, 30ms
12, 32ms
11, 40ms
AMP
21, 18ms
15, 20ms
14, 25ms
12, 36ms
King
21, 16ms
13, 18ms
15, 21ms
11, 22ms
% Mal.
Nodes
0
10
20
30
Diﬀerent network topologies. Fig. 8 and Table 3 show
the results for the King, Meridian and AMP topologies with
and without outlier detection, where the attack scenario is
the same as the coalition attack in Section 4.2. Applying
the spatial threshold of 1.5 which was tested on the King
data set, we ﬁnd our solution is able to mitigate the sys-
tem instability in all three data sets. The King data set
(Fig. 8(a)) maintains a low relative error for various percent-
ages of the attackers. We also note it is able to maintain a
low system prediction error and low number of false positives
(Table 3). In Table 3, the less the system prediction error
increased with the number of attackers, the more resiliently
the system performed under attack. Similar trends can also
be observed for the Meridian data set (Fig. 8(b)). While