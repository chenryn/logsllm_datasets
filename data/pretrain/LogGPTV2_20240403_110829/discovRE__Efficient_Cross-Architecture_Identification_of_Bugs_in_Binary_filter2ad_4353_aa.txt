title:discovRE: Efficient Cross-Architecture Identification of Bugs in Binary
Code
author:Sebastian Eschweiler and
Khaled Yakdan and
Elmar Gerhards-Padilla
discovRE: Efﬁcient Cross-Architecture Identiﬁcation
of Bugs in Binary Code
Sebastian Eschweiler∗†, Khaled Yakdan∗†, Elmar Gerhards-Padilla†,
∗University of Bonn, Germany
{yakdan, eschweil}@cs.uni-bonn.de
Abstract—The identiﬁcation of security-critical vulnerabilities
is a key for protecting computer systems. Being able to perform
this process at the binary level
is very important given that
many software projects are closed-source. Even if the source
code is available, compilation may create a mismatch between
the source code and the binary code that is executed by the
processor, causing analyses that are performed on source code to
fail at detecting certain bugs and thus potential vulnerabilities.
Existing approaches to ﬁnd bugs in binary code 1) use dynamic
analysis, which is difﬁcult for ﬁrmware; 2) handle only a single
architecture; or 3) use semantic similarity, which is very slow
when analyzing large code bases.
In this paper, we present a new approach to efﬁciently
search for similar functions in binary code. We use this method
to identify known bugs in binaries as follows: starting with
a vulnerable binary function, we identify similar functions in
other binaries across different compilers, optimization levels,
operating systems, and CPU architectures. The main idea is to
compute similarity between functions based on the structure of
the corresponding control ﬂow graphs. To minimize this costly
computation, we employ an efﬁcient pre-ﬁlter based on numeric
features to quickly identify a small set of candidate functions.
This allows us to efﬁciently search for similar functions in large
code bases.
We have designed and implemented a prototype of our
approach, called discovRE, that supports four instruction set
architectures (x86, x64, ARM, MIPS). We show that discovRE is
four orders of magnitude faster than the state-of-the-art academic
approach for cross-architecture bug search in binaries. We also
show that we can identify Heartbleed and POODLE vulnerabilities
in an Android system image that contains over 130,000 native
ARM functions in about 80 milliseconds.
I.
INTRODUCTION
One key problem in computer security is the identiﬁcation
of bugs and security-critical vulnerabilities in software. Despite
intensive efforts by the research community and the industry,
vulnerabilities continue to emerge regularly in popular soft-
ware projects. Unfortunately, a single ﬂaw in program code,
such as the failure to check buffer boundaries or sanitize
input data, can render the whole program vulnerable, which
can have a huge security impact given that popular software
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’16, 21-24 February 2016, San Diego, CA, USA
Copyright 2016 Internet Society, ISBN 1-891562-41-X
http://dx.doi.org/10.14722/ndss.2016.23185
†Fraunhofer FKIE, Germany
PI:EMAIL
programs are used by millions of people on a daily basis.
Prominent recent examples of these cases include the Heart-
bleed vulnerability in the cryptographic library OpenSSL [5],
the “Shellshock” vulnerability in GNU Bash [8], and the
POODLE vulnerability in the SSLv3 protocol [7]. Given the
evolving nature of programs and the increasing complexity,
efﬁcient and accurate approaches to identify vulnerabilities in
large code bases are needed.
There has been an extensive research on identifying vul-
nerabilities at the source code level. Security research has
focused on ﬁnding speciﬁc types of vulnerabilities, such as
buffer overﬂows [66], integer-based vulnerabilities [17, 59],
insufﬁcient validation of input data [37], or type-confusion
vulnerabilities [42]. A similar line of research to our work
is identifying bugs in source code by searching for code
fragments similar to an already known venerability [27, 34,
35, 38, 63]. Unfortunately, performing bug search at
the
source level only is not sufﬁcient for two reasons: ﬁrst, many
prominent and popular software projects such as MS Ofﬁce,
Skype, and Adobe Flash Player are closed-source, and are
thus only available in the binary form. Second, compilation
optimizations may change some code properties, creating a
mismatch between the source code of a program and the
compiled binary code that is executed on the processor [15].
For example, zeroing a buffer containing sensitive information
before freeing it may be marked as useless code and thus
removed by the compiler since the written values are never
used at later stages. As a result, performing analysis on the
source code may fail to detect certain vulnerabilities. This
illustrates the importance of being able to perform bug search
at the binary level.
Bug search at the binary level is very challenging. Due to
the NP-complete nature of the compiler optimization problem
[12], even recompiling the same source code with the same
compiler and optimization options can potentially alter the
resulting binary. In many cases the same source code is com-
piled using different toolchains, i.e., compilers or optimization
levels. This can heavily alter the generated binary code, making
it extremely difﬁcult to identify the binary code fragments that
stemmed from the same source code fragment. This is even
further complicated by the fact the same source code can be
cross-compiled for different CPU architectures, which results
in binaries that differ, among others, in instruction sets, register
names, and function calling conventions.
Previous work to identify bugs in binary code either relied
on dynamic analysis [e.g., 23], supported a single architec-
ture [e.g., 26], or used semantic similarity [e.g., 53, 44]. Dy-
namic analysis relies on architecture-speciﬁc tools to execute
or emulate binaries. As a result, extending these approaches
to support other architectures would be tedious. Moreover,
code coverage is a fundamental shortcoming for any dynamic
approach, limiting the amount of code that can be searched
for bugs. Approaches based on semantic similarity provide the
most accurate results. However, SAT/SMT solvers which are
often used to measure semantic similarity are computationally
expensive. For example, the most recent and advanced method
to perform cross-architecture bug search in binary code needs
on average 286.1 minutes for each 10,000 basic blocks to
prepare a binary for search. This means that it would need
about one month to prepare a stock Android image that
contains about 1.4 million basic blocks. This motivated us
develop a new and efﬁcient bug search method that can be
used with realistically large code bases.
In this paper, we aim at improving the state of the art by
presenting a new approach for robust and efﬁcient search of
similar functions in binary code. We apply this approach to
identify already known bugs in binaries as follows: starting
with a known vulnerable binary function, we are searching for
binaries containing the same vulnerable function, which are
possibly compiled for different architectures and compiler opti-
mizations. To this end, we identify a set of code features that do
not vary a lot across different compilers, optimization options,
operating systems, and CPU architectures. These features can
be grouped in two categories: structural features and numeric
features. The structural features denote the structure of control-
ﬂow inside a binary represented by its CFG. Our experiments
show that structural information is a very robust feature for
function similarity. However, it is computationally expensive
and impractical for comparing a large number of functions.
To remedy this situation, we use the second type of features.
Numeric features represent meta information about a binary
function, e.g., the number of instructions and number of basic
blocks. We embed these numeric features in a vector space and
leverage techniques from machine learning to quickly identify
a set of candidates to be checked for structural similarity. We
implemented a prototype of our approach called discovRE.
Based on the implementation, we evaluate the correctness
of our method and show that it is four order of magnitude
faster than the state-of-the-art academic approach for cross-
architecture bug search in binary code. Also, based on a
vulnerable function extracted from x86 OpenSSL code, we
show that we can ﬁnd the Heartbleed vulnerability in an
Android system image that contains over 130,000 native ARM
functions in less than 80 milliseconds.
In summary, we make the following contributions:
• We present a novel, multistaged approach for efﬁcient
and robust search of binary functions in large code
bases. The key property of our approach is that it works
across different CPU architectures, operating systems, and
compiler optimization levels.
• We propose a set of robust numeric features that allow
for a fast similarity comparison between binary functions.
• We introduce a new metric to measure structural similarity
between two binary functions based on the maximum
common subgraph isomorphism (MCS). To reach efﬁ-
ciency, we use a very good approximate and efﬁcient
solution to the MCS problem.
• We implement a prototype of our approach called dis-
covRE, and evaluate its performance against state-of-the-
art approaches.
• We demonstrate the application of discovRE for cross-
architecture vulnerability search in real-world applica-
tions.
II. APPROACH OVERVIEW
We focus on a similar use case to the one presented by
Pewny et al. [53]. That is, we start from a known bug (vul-
nerable function) and then search for the same vulnerability in
other binaries by identifying similar functions in those binaries.
A high-level overview of discovRE is presented in Figure 1.
It takes as input a code base of known functions and a binary
function to be searched in the code base. We use IDA Pro [6]
to disassemble the binary code and then extract numeric and
structural features that we use to compute similarity. Examples
for numeric features are the number of instructions, size of
local variables, and number of basic blocks (§III-B). Structural
features include the function’s CFG and other features of its
basic blocks. Should the binary be obfuscated several methods
can be used to extract the binary code (e.g., [39], [60], or [65]).
For each function the code base stores the set of extracted
features.
The similarity computation comprises two ﬁlters: a numeric
ﬁlter, and a structural ﬁlter. These ﬁlters have increasing
precision, but also increasing computational complexity. For
this reason we have combined them in a pipeline so that we can
ﬁlter out dissimilar functions at an early stage. Thus, we use
the complex ﬁlter only on a small set of candidate functions.
Numeric ﬁlter. The numeric features of the searched function
serve as search pattern in the code base. We use the k-Nearest
Neighbors algorithm (kNN) to ﬁnd similar functions based
on these features. Here, we use the observation that numeric
features can be compared efﬁciently. To this end, we identiﬁed
a set of features that enables a reliable comparison of functions
across different architectures.
Structural similarity. This is the most precise yet most
complex ﬁlter. This ﬁlter checks the similarity of the CFG
of the target function against the set of candidates that passed
the previous two ﬁlters (§III-C). To this end, we present a
similarity metric based on the maximum common subgraph
isomorphism (MCS). Although the MCS problem is NP-
hard, there exist efﬁcient solutions that achieve a very good
approximation.
III. DISCOVRE
In this section we describe discovRE in details, focusing
on the techniques that it uses to ﬁnd similarities between
binary functions. In order to identify a robust set of features,
i.e., features that do not change or change only slightly over
different compilers, compilation options, operating systems
and CPU architectures, we need a code base that allows for
a substantial analysis. Hence, we start by describing the data
set that was used to derive robust features and several key
parameters.
2
Code Base
Vulnerable
Function
Feature Extraction
Similarity Computation
Numeric
Features
Structural
Features
Numeric
Filter
Structural
Similarity
Match
Fig. 1: discovRE architecture
A. Data Set
To derive robust features, we needed a large collection
of binaries that are compiled with a variety of compilers,
compilation options and for different CPU architectures and
operating systems. Further, in order to match functions from
different binaries, a ground truth is required at binary function
level. This is possible by keeping the symbolic information in
the binary. To the authors’ best knowledge, no such collection
exists, and we therefore created it ourselves. To this end, we
selected four widely used compilers, three CPU architectures,
and two operating systems. Seven well-known open source
projects were compiled with above combinations where feasi-
ble with a total of over 1,700 unique compiler options. In the
remainder of this section, we present the details of our data
base.
For personal computers and server systems,
the most
prevalent CPU architectures today are Intel-compatible x86
and x64 CPUs. In the world of mobile computing, the ARM
architecture is the most common one. The design philosophy
behind both CPUs is different. While Intel CPUs offer a rich
instruction set (CISC architecture), ARM CPUs are designed to
support a limited set of CPU instructions (RISC architecture).
A more detailed discussion about the differences is out of the
scope of this work. From various revisions, the ARM v7 CPU
was selected for its wide distribution in consumer hardware.
For x86 and x64, we allowed the compiler to utilize extended
instruction sets, such as MMX and SSE.
To cover a vast spectrum of compilers, we used four of the
most widely used compilers. Namely, the compilers GNU GCC
version 4.8.2 (GCC)[25], LLVM Clang version 3.3 (CL)[41],
Intel ICC version 14.0.1 (ICC)[31] and Microsoft Visual C++
version 16.00 (VC)[48] were chosen. All selected compilers
support the Intel x86 and x64 architectures. GCC and CL addi-
tionally support the ARM architecture. We compiled Windows
binaries with GCC (MinGW), ICC, and VC. Linux binaries
were compiled with GCC, ICC, and CL.
Regarding compiler optimization options, we only set one
explicit limit. We excluded the optimization function inlining.
Inlining replaces the function call to small functions by the
actual code of that function. Thus, the resulting binary lacks
a function call at this location for the beneﬁt of improved
runtime, however, at the cost of slightly larger binary size.
Function inlining would have interfered with establishing a
ground truth, as there would emerge a code overlap in the
corresponding function labels.
Windows
GCC CL
166
166
-
-
-
-
ICC VC
98
120
120
98
-
-
Linux
GCC CL
166
83
83
166
166
83
ICC
98
98
-
Intel x86
Intel x64
ARM v7
TABLE I: Number of compilation options per compiler and
CPU architecture
From the remaining compiler optimization options, we
selected a wide spectrum. Alongside standard compiler options
that have no special optimizations or optimize for speed
or size, options that aim at speciﬁc optimizations, such as
loop unrolling, were taken into account. Table I shows the
number of different compilation options per compiler and
CPU architecture. There are altogether 1,711 different compiler
options.
1) Open source projects: The evaluation requires the col-
lection of source code to meet several conditions: ﬁrstly,
the source code needs to be compiled on different operating
systems and CPU architectures, secondly, the source code has
to be compatible with the selected compilers.
We selected BitDHT [1], GnuPG [2], ImageMagick [30],
LAME [57], OpenCV [32], SQlite [3], and stunnel [4] for
our experiments. They contain a total number of over 31,000
functions that implement a wealth of different algorithms. All
libraries are widely used and hence serve well as testing body.
it has to be made sure that
When compiling for different operating systems or CPU
architectures,
the underlying
source code remains the same. During the compilation process,
the preprocessor checks for a set of deﬁnitions that aim at
distinguishing the corresponding operating system or CPU ar-
chitecture, e.g., #ifdef WIN32. The scrutinized open source
projects contain several code portions that are speciﬁc to a
certain operating system. These functions were removed from
the data set, as they implied changes of the source code
with inevitable changes in the resulting binary. We identiﬁed
and excluded 1,158 functions that contained such OS-speciﬁc
code. Additionally, some functions contain highly optimized
assembler code. Assembler code is not affected by compiler
optimizations and thus the resulting machine code remains the
same over all compiliation options. As the outcome of the
evaluation over these binary functions would be quite clear,
we decided to remove them.
3
We observed that some compilation options result in the
same binary code. To identify binary duplicates, it does not
sufﬁce to compare the binaries by their checksums, as some
compilers insert the compilation time stamp into the binary.