Defending Networks with Incomplete Information: A Machine Learning Approach 
DefCon 21 – 2013 
Page 1 
Defending Networks with Incomplete 
Information: A Machine Learning 
Approach 
Introduction and Abstract 
Let's face it: we may win some battles, but we are losing the war pretty badly. 
Regardless of the advances in malware and targeted attacks detection 
technologies, our top security practitioners can only do so much in a 24 hour 
day. Even less, if you consider they need to eat and sleep. On the other hand, 
there is a severe shortage of capable people to do "simple" security monitoring 
effectively, let alone complex incident detection and response. 
Enter the use of Machine Learning as a way to automatically prioritize and 
classify potential events and attacks as something can could potentially be 
blocked automatically, is clearly benign, or is really worth the time of your 
analyst.  
In this Whitepaper we will present publicly for the first time an actual 
implementation of those concepts, in the form of a free-to-use web service. It 
leverages OSINT sources and knowledge about the spatial distribution of the 
Internet to generate a fluid and constantly updated classifier that pinpoints areas 
of interest on submitted network traffic and security tool log sources. 
Whitepaper Topics: 
Introduction and Abstract .................................................................................................................. 1 
Security Monitoring: We are doing it wrong ............................................................................. 2 
Machine Learning and the Robot Uprising ................................................................................ 2 
More attacks = more data = better defenses ............................................................................. 5 
Designing a model to detect external agents with malicious behavior ........................ 6 
Data Collection .................................................................................................................................... 6 
Model Intuition ................................................................................................................................... 6 
Feature Engineering......................................................................................................................... 7 
Training the model ........................................................................................................................... 7 
Results .................................................................................................................................................... 8 
Future Direction and Improvements ............................................................................................ 9 
Acknowledgments and thanks ......................................................................................................... 9 
References .............................................................................................................................................. 10 
Defending Networks with Incomplete Information: A Machine Learning Approach 
DefCon 21 – 2013 
Page 2 
Security Monitoring: We are doing it wrong 
The amount of security log data that is being accumulated today, be it for 
compliance or for incident response reasons, is bigger than ever. Given the push 
on regulations such as PCI and HIPAA, even smallish and medium companies 
have a large quantity of machine-generated data stored in log management 
solutions no one is currently looking at. 
There is a clear a surplus of data and a shortage of professionals that are capable 
of analyzing this data and making sense of it. This is one of the main criticisms 
that compliance and "check-box security" practices receive, and, of course, it is 
legitimate criticism because no one is safer for just accumulating this data. 
Even when organizations have more advanced log management and SIEM 
solutions, there is a great difficulty in prioritizing what should be investigated as 
security events happen. These tools' functionality relies too deeply on very 
deterministic rules: if something happens in my network X amount of times, flag 
this as suspicious and or send me an alert. The problems arise from the fact that 
the somethings and the Xs vary widely between organizations and also evolve (or 
devolve) over time in an organization itself. It is truly a Sisyphean effort. 
But this is not exclusively a tool problem. There are a few really talented and 
experienced professionals that are able to configure one of these systems to 
perform. However, it usually takes a number of months or years and a couple of 
these SOC "supermen" working full-time to make this happen. And now we are 
adding Big Data to SIEM solutions? What chance do we have of finding a needle 
on a 1,000 times larger haystack? 
But how many of these mythical and magical people exist? The new "security 
analyst" must now understand not only the intricacy of attack and defense but 
also be an accomplished "data analyst" or "data scientist" in order to work 
through massive amounts of data. I am not sure where they are, but I can assure 
you they are not working 24x7, night or weekend shifts on your local or 
subcontracted monitoring team. 
We are doing it wrong. 
This project introduces the idea of using Machine Learning techniques to mine 
information like this and help companies make informed decisions based on this 
treasure trove of information they have available.  
The initial algorithms presented on this paper, by itself, may not yet outperform 
a (very well) trained analyst but:  
 it's certainly better than no action at all;  
 it can greatly enhance the analyst's productivity and effectiveness by letting 
him focus on the small percentage of data that is more likely to be 
meaningful. 
Machine Learning and the Robot Uprising 
Machine learning is designed to infer relationships from large volumes of data. In 
a way, you do not design the classifications routines or the specific algorithm you 
Defending Networks with Incomplete Information: A Machine Learning Approach 
DefCon 21 – 2013 
Page 3 
are using, but let the data itself shape how the program should behave. The 
terms learning and artificial intelligence are usually associated with these kinds 
of routines because these processes try to mimic the way the brain learns by 
association and repetition. Once you have seen enough chairs, you will know 
when you see a completely different chair even if it has a different shape, color or 
is made of a different material. 
Machine learning based systems are being used all around us:  
 In sales and marketing,  to serve us online ads, to suggest us products that are 
similar to the ones we or our friends have bought;  
 In financial systems, fueling high-frequency trading applications looking for 
patterns in penny stocks or opportunities for arbitrage; 
 In image processing, for example to convert an image of a text into a 
computer document (OCR). 
Alas, they are not perfect: we always see an online ad that does not make sense 
("what am I going to do with a carbon-fiber pogo stick?") or the market crashes 
on an algorithm bug, but the have a very good performance on problems that are 
otherwise intractable due to dataset sizes or response time necessary. 
There is a huge number of algorithms, techniques, sub-groups and quasi-
religious belief systems associated with Machine Learning, but for all intents and 
purposes we will limit our exploration to what are called "supervised learning" 
and "unsupervised learning" problems. The names are what they seem:  
 In Supervised Learning, you are telling the algorithm what to expect from the 
training data. In other words, you need to tell it what results it should aim for 
when it sees similar data points. This is the basis of neural networks and 
other predictive algorithms; 
Figure 1 - Supervised Learning (source:scikit-learn.github.io/scikit-learn-tutorial/general_concepts.html) 
Defending Networks with Incomplete Information: A Machine Learning Approach 
DefCon 21 – 2013 
Page 4 
 In Unsupervised Learning, the algorithm just receives the data and tries to 
infer relationships like similarity and proximity from the observations. This 
is more commonly used to either support anomaly detection (this data point 
is not like the others). It is also used to help figure out what is really relevant 
on the data set, on a process that is called "feature extraction". 
Figure 2 - Unsupervised learning (source: scikit-learn.github.io/scikit-learn-tutorial/general_concepts.html) 
The thesis is that we can apply machine learning to parameterize the somethings 
and the Xs I mentioned before with very little effort on the human side. We could 
use Unsupervised Learning to find patterns in data that could generate new rules 
and relationships between occurrences in our networks. Or we could use 
Supervised Learning with the humans providing examples of "good” and “bad” 
behavior in their networks, so that the algorithm can then sift through 
gargantuan amounts of data and suggest other instances that are likely to be 
relevant in the same way. 
There is actually a very good use case for Machine Learning in Information 
Security, which are spam filters. Nobody really talks about spam filters anymore, 
because, in a way, the problem has been satisfactory "solved", or actually 
reached an evolutional plateau. You still can't defeat actors that exploit the 
algorithm directly, such as sending a specially crafted phishing attack that looks 
like a regular e-mail. This is a more complicated problem, involving game theory 
and rational adversarial modeling [1]. 
Regardless, this is a neglected tool for Information Security by and large, and that 
is an odd choice, because it seems to be a good fit for the challenges we face day 
after day. 
Defending Networks with Incomplete Information: A Machine Learning Approach 
DefCon 21 – 2013 
Page 5 
More attacks = more data = better defenses 
The great advantage of Machine Learning over more traditional approaches for 
Security Monitoring is that the predictive capabilities of the algorithm improve 
as you provide more data to its training processes. As your number of 
observations gets much larger than the complexity of the model you are trying to 
predict (usually referred in ML terms as dimensionality or VC-dimension), it gets 
very efficient indeed. 
Let that sink in for a moment. The more you are attacked, the better your 
defenses can be. These categories of things have been deemed "Antifragile"[2], 
and they benefit from disorder and chaos. And disorder and chaos sound a lot 
like where we are today in Information Security monitoring.  
This is a generalization, of course. The model that you choose to be trained, the 
specific math of the algorithm you choose all have direct impact on its 
performance and efficiency, and you need to choose the right “features” of the 
data wisely. But once you have a reasonable result on a smallish dataset, 
expanding the amount of data it is able to process will improve its efficiency. 
Figure 3 - Theoretical description of expected Ein (classification error in training set of the model) 
and expected Eout (classification error on new data that is predicted using the model). Source: 
Caltech, Learning from Data Course materials 
Given the amount of log data I mentioned before that is just sitting inside the 
organizations, seems like a good deal to me. 
Defending Networks with Incomplete Information: A Machine Learning Approach 
DefCon 21 – 2013 
Page 6 
Designing a model to detect external agents with malicious 
behavior 
Data Collection 
As an example of these capabilities, we present an implementation of a 
supervised learning model that we created based on public summarized log 
information made available by the SANS Technology Institute[3], more 
specifically by the DShield Project API[4].  
The DShield project collects firewall logs from contributors all over the world 
and summarizes the blocked connections to pinpoint hosts that are engaging in 
vulnerability exploitation or port scanning in relation to these corporations. 
Also, the data volumes are impressive, as we can see on the bulk data made 
available that there is a daily average of 1 million relevant summarized events. 
Back-of-the-envelope calculations have us estimate these summaries come from 
30 million firewall blocks per day.  
SANS offers an open API that provides access summarized anonymous 
information from this sources including information or malicious IP addresses, 
domains, AS, and the such, where malicious has a definition as simple as "this IP 
address has been hammering closed ports on these firewalls for the longest time 
now". Low hanging fruit it seems, but simple and effective triage. 
Model Intuition 
This data is routinely used as an OSINT source for blacklisting IP addresses on 
some SIEM and Monitoring deployments. However, the effectiveness of this 
measure is debatable at best, because active attackers, and even scripted worms 