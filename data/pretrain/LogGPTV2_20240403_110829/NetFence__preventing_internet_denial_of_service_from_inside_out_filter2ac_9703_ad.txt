the packet loss rate to detect attacks, NetFence limits the damage
of this attack with a low loss detection threshold pth (§ 4.3.1).
On-off attacks: Attackers may attempt to launch on-off attacks. In
a macroscopic on-off attack, attackers may ﬂood the network again
after a congested router terminates a monitoring cycle. NetFence
uses a prolonged monitor cycle (§ 4.3.1) to mitigate this attack. In
a microscopic on-off attack, attackers may send trafﬁc bursts with
a short on-off cycle, attempting to congest the network with syn-
chronized bursts, yet maintaining average sending rates lower than
their rate limits. Our theoretical bound in § 3 and simulation results
in § 6.3.2 both show that the shape of attack trafﬁc cannot reduce
a legitimate user’s guaranteed bandwidth share, because a sender
cannot send faster than its rate limit at any time (§ 4.3.3), and Net-
Fence’s robust rate limit adjustment algorithm (§ 4.3.4) prevents a
sender from suddenly increasing its actual sending rate.
5.2.2 Malicious On-path Routers
A malicious router downstream to a congested link may attempt
to remove or modify the L↓ feedback stamped by a congested router
in order to hide upstream congestion. But such attempts will make
the feedback invalid, because the router does not know the original
tokennop value needed to compute a valid MAC (§ 4.4).
A malicious on-path router may discard packets to completely
disrupt end-to-end communications, duplicate packets, or increase
packet sizes to congest downstream links. It may also change the
request packet priority ﬁeld in a NetFence header to congest the
request channel on downstream links. Preventing such attacks re-
quires Byzantine tolerant routing [36], which is not NetFence’s de-
sign goal. Instead, we aim to make these attacks detectable. Pass-
port [26], the source authentication system NetFence uses, partially
protects the integrity of a packet and enables duplicate detection. It
includes a packet’s length and the ﬁrst 8 bytes of a packet’s trans-
port payload (which includes the TCP/UDP checksum) in its MAC
computation. We can further extend Passport’s MAC computation
to include NetFence’s request packet priority ﬁeld to protect it.
5.3 Incremental Deployment
NetFence can be incrementally deployed by end systems and
routers. Since the NetFence header is a shim layer between IP
2611xxx: request packet
0xxx: regular packet
00xx: regular packet w/ nop feedback
01xx: regular packet w/ mon feedback
xxx1: w/ returned feedback
VER(4) TYPE(4) PROTO(8) PRIORITY(8) FLAGS(8)
TIMESTAMP (32)
Common Header (64)
LINK-ID (32)
MAC (32)
Common Header (64)
LINK-ID (32)
MAC (32)
TOKEN-NOP (32)
MAC
return
(32)
LINK-ID
return
(32)
1xxxxxxx: the action is decr
x1xxxxxx: the returned action is decr
xxxxx1xx: LINK-IDreturn is present
xxxxxxYY: YY is the timestamp of the returned feedback
Common
Header
nop
Feedback
mon
Feedback
Returned
Feedback
May be omitted
FLAGS field:
Figure 6: The NetFence header format.
and upper layer protocols, legacy applications need not be modi-
ﬁed. Legacy routers can ignore the NetFence header and forward
packets using the IP header. Routers at congested links and ac-
cess routers need to be upgraded, but well-provisioned routers that
can withstand tens of Gbps attack trafﬁc may not need to upgrade.
The deployment can take a bump-in-the-wire approach, by placing
inline boxes that implement NetFence’s enforcement functions in
front of the routers that require upgrading. Middleboxes such as
ﬁrewalls need to be conﬁgured to permit NetFence trafﬁc.
NetFence provides deployment incentives to both end systems
and ASes, because legacy trafﬁc is treated by deployed ASes with
lower priority ( Figure 2). Deployed ASes can form a trusted over-
lay network and protect each other’s legitimate trafﬁc within their
networks. Their trafﬁc is not protected at undeployed networks, en-
couraging them to direct trafﬁc to other deployed ASes using BGP.
6.
IMPLEMENTATION AND EVALUATION
We have implemented NetFence prototypes in Linux and in the
ns-2 simulator. Next we evaluate the NetFence header and packet
processing overhead with our Linux implementation, and use ns-2
simulations to show how effective NetFence mitigates DoS attacks.
6.1 NetFence Header
Figure 6 shows the format of a NetFence header in our Linux im-
plementation. A full NetFence header from a sender to a receiver
includes a forward header and a return header. The forward header
includes the congestion policing feedback on the forward path from
the sender to the receiver, and the return header includes the reverse
path information from the receiver to the sender. Most ﬁelds are
self-explained. A NetFence header is implemented as a shim layer
between IP and an upper-layer protocol, and the PROTO ﬁeld de-
scribes the upper-layer protocol (e.g., TCP or UDP). The unit of a
timestamp is one second.
The return header may be omitted to reduce overhead if the sender
has previously returned the latest feedback to the receiver. Even
when the return header is present, it does not always include all the
ﬁelds. If the returned feedback is nop, the LINK-IDreturn ﬁeld
will be omitted because it is zero, and one bit in the FLAGS ﬁeld
indicates this omission.
A NetFence header only includes the last two bits of the returned
timestamp to save header space. In the subsequent packets from the
sender to the receiver, the sender’s access router will reconstruct
Packet
Type
Router
Type
request
regular
bottleneck
access
bottleneck
access
TVA+
Processing Overhead (ns/pkt)
NetFence
w/o attack: 0
w/ attack: 492
546
w/o attack: 0
w/ attack: 554
w/o attack: 781
w/ attack: 1267
389
791
Figure 7: NetFence implementation micro-benchmarking results.
the full timestamp from its local time and the returned two bits,
assuming that the timestamp is less than four seconds older than
its current time. With this implementation, a NetFence header is
20 bytes in the common case when the feedback is nop for both
the forward and return paths. In the worst case that the feedback is
mon for both paths, the header is 28 bytes long.
6.2 Micro-benchmarking
We have implemented NetFence in Linux using XORP [19] and
Click [24]. We modiﬁed XORP’s BGP module to establish the
pairwise symmetric keys shared between ASes. We added the data
packet processing logic into Click and ran Click routers in the ker-
nel space for packet forwarding. XORP communicates with Click
via the /click ﬁle system. We added a module between the IP and
transport layers on end-hosts to handle NetFence headers. This de-
sign keeps upper-layer TCP/UDP protocols and legacy applications
unmodiﬁed. We use AES-128 as a secure MAC function due to its
fast speed and available hardware support [20, 21].
We benchmark the Linux implementation on Deterlab [14] with
a three-node testbed. A source access router A and a destination C
are connected via a router B. The B—C link is the bottleneck with
a capacity of 5Mbps. Each node has two Intel Xeon 3GHz CPUs
and 2GB memory. To benchmark the processing overhead without
attacks, we send 100Kbps UDP request packets and 1Mbps UDP
regular packets from A to C respectively. To benchmark the over-
head in face of DoS attacks, we send 1Mbps UDP request packets
and 10Mbps UDP regular packets simultaneously.
The benchmarking results are shown in Figure 7. With Net-
Fence, when there is no attack, a request packet does not need any
extra processing on the bottleneck router B, but it introduces an av-
erage overhead of 546ns on the access router A because the router
must stamp the nop feedback into the packet. A regular packet does
not incur any extra processing overhead on the bottleneck router ei-
ther, but it takes the access router 781ns on average to validate the
returned feedback and generate a new one. When the bottleneck
link enters the mon state during attack times, the bottleneck router
takes 492ns to process a 92B request packet, or at most 554ns to
process a 1500B regular packet. The access router takes on aver-
age 1267ns to process a regular packet at attack times.
The performance of a capability system TVA+ [27] on the same
topology is also shown in Figure 7 for comparison. We can see
that the processing overhead introduced by NetFence is on par with
that of TVA+. Note that we do not show the result when TVA+
caches capabilities, because such caching requires per-ﬂow state
on routers, while NetFence does not have this requirement.
These results show that NetFence’s per-packet overhead is low.
The CPU-intensive operations are primarily AES computation. Since
there exists commercial hardware that can support AES operations
at 40Gbps [20], we expect that NetFence’s per-packet processing
will not become a performance bottleneck. We note that the bench-
marking results do not include the Passport overhead, as a Passport
header can be updated by inline boxes near an AS’s ingress and
egress border routers [26].
262 10
i
)
s
(
e
m
T
r
e
f
s
n
a
r
T
e
l
i
F
 8
 6
 4
 2
 0
FQ
NetFence
TVA+
StopIt
25K
50K
Number of Simulated Senders
100K
200K
Figure 8: The average transfer time of a 20KB ﬁle when the targeted
victim can identify and wish to remove the attack trafﬁc. The ﬁle trans-
fer completion ratio is 100% in all simulated systems.
6.3 Mitigating DoS Flooding Attacks
Next we evaluate how well NetFence mitigates various DoS ﬂood-
ing attacks using ns-2 simulations. We also compare NetFence with
three other representative DoS mitigation schemes:
TVA+ : TVA+ [48, 27] is a network architecture that uses network
capabilities and per-host fair queuing to defend against DoS ﬂood-
ing attacks. TVA+ uses hierarchical queuing (ﬁrst based on the
source AS and then based on the source IP address) at congested
links to mitigate request packet ﬂooding attacks, and per-receiver
fair queuing to mitigate authorized trafﬁc ﬂooding attacks in case
(colluding or incompetent) receivers fail to stop attack trafﬁc.
StopIt : StopIt [27] is a ﬁlter and fair queuing based DoS defense
system. A targeted victim can install network ﬁlters to stop un-
wanted trafﬁc. Similar to TVA+, in case receivers fail to install
ﬁlters, StopIt uses hierarchical queuing (ﬁrst based on the source
AS and then based on the source IP address) at congested links to
separate legitimate trafﬁc from attack trafﬁc.
Fair Queuing (FQ) : Per-sender fair queuing at every link provides
a sender its fair share of the link’s bandwidth. We use fair queuing
to represent a DoS defense mechanism that aims to throttle attack
trafﬁc to consume no more than its fair share of bandwidth.
We have implemented TVA+ and StopIt as described in [27, 48].
We use the Deﬁcit Round Robin (DRR) algorithm [39] to imple-
ment fair queuing because it has O(1) per packet operation over-
head. In our simulations, attackers do not spoof source addresses
because NetFence uses Passport [26] to prevent spooﬁng. Thus,
routers could queue attack trafﬁc separately from legitimate trafﬁc.
6.3.1 Unwanted Trafﬁc Flooding Attacks
We ﬁrst simulate the attack scenario where the attackers directly
ﬂood a victim, but the victim can classify the attack trafﬁc, and
uses the provided DoS defense mechanism: capabilities in TVA+,
secure congestion policing feedback in NetFence, and ﬁlters in Sto-
pIt, to block the unwanted trafﬁc.
We desire to simulate attacks in which thousands to millions of
attackers ﬂood a well provisioned link. However, we are currently
unable to scale our simulations to support beyond several thousand
nodes. To address this limitation, we adopt the evaluation approach
in [48]. We ﬁx the number of nodes, but scale down the bottleneck
link capacity proportionally to simulate the case where the bottle-
neck link capacity is ﬁxed, but the number of attackers increases.