### GZip Compression and Network Efficiency

GZip compression significantly reduces the size of a single event on the wire, typically to an average of 3–4 bytes, as indicated in columns 8–9. This compression is particularly effective in highly interactive benchmarks, such as speed typing, where it often reduces the number of required network packets to just one. However, current web browsers do not support automatic compression of HTTP requests, only HTTP responses. This limitation necessitates integrating compression into Volta's tier splitting, which is part of future work.

### 4.1.2 Memory Overhead in the Emulator

When multiple replicas run alongside the server, they can consume a significant amount of additional memory. However, the emulator is considerably less memory-intensive than running a full-featured browser.

To demonstrate this, we conducted an experiment with the Shopping Cart application, both with and without RIPLEY enabled, using Internet Explorer and Firefox on the client side. The results, summarized in Figure 9, show the range of memory utilization (in megabytes) for supporting a single client. In most cases, more memory was allocated as the application progressed. We used Internet Explorer version 7.0.6001 and Firefox version 2.0.0.16 on Windows Vista for these measurements. Adding RIPLEY increased server memory utilization by approximately 5 MB. This increase was consistent across three trials. This overhead is an order of magnitude lower than the 50+ MB memory footprint of a full-featured browser.

To further investigate, we modified the server to create more client replicas, simulating multiple simultaneous client connections. Figure 10 shows the server memory usage as the number of replicas increases to 100. Due to DLL sharing across different APPDOMAINs, the marginal cost of an additional replica is only about 1.3 MB, compared to the initial 5 MB. For context, Microsoft Sharepoint, a sophisticated Web 2.0 application, suggests capacity planning for 100–190 concurrent users per machine. At 1.3 MB per user, this would require 130–247 MB of extra memory per server, which is a reasonable overhead.

### 4.1.3 CPU Overhead

RIPLEY introduces CPU overhead on both the server and the client. Running the replica on the server consumes CPU resources, although the emulator described in Section 3.4 makes this process faster.

As shown in columns 2–4 of Figure 11, RIPLEY checking on the server introduces some latency for regular requests. The server runs an ASP.NET application on a dual-core 3-GHz machine with 4 GB of RAM and Microsoft Vista. We measured the time each client-side request spends waiting for the replica to generate and verify the corresponding request. The primary overhead comes from the replica catching up with the actual client, as it receives event information in batches. For example, in the Shopping Cart and Sudoku applications, the maximum overhead occurs when events are sent to the replica just before the checkout and finishgame RPCs. For other applications, the maximum overhead is observed during the initialization phase, involving application-specific I/O operations. Despite this, the overhead is generally negligible, with minimum times being fractions of milliseconds.

Client-side instrumentation for capturing and serializing event information to the server adds execution overhead in the browser. As shown in columns 5–8 of Figure 11, this overhead is typically around a few milliseconds on average. The high extremes are believed to be statistical anomalies, with a median overhead of 1 ms, which is imperceptible for interactive GUI applications. Moving event capture to the browser, as discussed in Section 5, is likely to reduce the client-side CPU overhead even further.

### 4.2 Hotmail Experiments: Overhead Macro-measurements

Our previous experiments focused on small Volta applications. To estimate how RIPLEY ideas might extend to a large-scale Web 2.0 AJAX application, we conducted a series of experiments replicating the client-side state of Hotmail manually, without RIPLEY's automatic deployment.

### 4.2.1 Hotmail Experimental Setup

The Hotmail mailbox in our setup contained 32 email messages, half of which were HTML-heavy. The entire application download, with a clean browser cache, consisted of 793 KB of code and data, uncompressed, with 703 KB being JavaScript. When pretty-printed, the JavaScript added up to 31,178 lines. The DOM representing the mail application UI is partially downloaded from the server and partially created on the client through JavaScript and XmlHttpRequest calls.

### 4.2.2 Network Overhead

To measure the network overhead of event capture, we loaded a Hotmail inbox window and waited for network activity to stabilize. The mailbox contained 8 unread and several dozen read messages. We used Hotmail for 5 minutes, performing various actions such as reading, replying, deleting spam, cleaning the junk mail folder, and searching for and removing large HTML emails.

This experiment produced 491 keyboard and mouse events, captured using a key logger. The event trace, saved to disk, was 8,673 bytes or 2,889 bytes when compressed with GZip. We also examined the traffic between Hotmail servers and the browser, excluding external requests. The total request size was 617,297 bytes, and the response size was 3,045,249 bytes. The extra network traffic due to event capture is negligible, constituting 1.4% if uncompressed and 0.4% if compressed.

### 4.2.3 Memory Footprint

The client-side state consists of three major components: the DOM, non-DOM client-side data structures, and JavaScript code. The DOM representation within the emulator, after parsing the 20 KB HTML document, is 349 KB with frequent garbage collection and 434 KB otherwise. The JavaScript heap, instrumented in Mozilla Firefox, showed that even an empty browser allocates 3.1 MB. For Hotmail, the JavaScript heap size does not exceed 1.3 MB, and combined with the DOM state, the total is under 1.75 MB per connected client.

### 4.2.4 CPU Overhead

Measuring the CPU overhead for replicating Hotmail is challenging due to the browser's many activities. JavaScript execution is not the dominant part of client-side application execution, with CSS, layout, rendering, DOM manipulation, and data marshalling taking 75% of the time. The headless emulator does not need to handle these issues, so we do not expect significant CPU load on the server.

### 4.2.5 Summary

In summary, while Hotmail is a complex AJAX application with over 31,000 lines of code, the overhead imposed by replication is acceptable. The network overhead is 0.4%, and the memory overhead is around 1.75 MB per concurrently connected client, which is manageable given typical capacity planning requirements. The CPU overhead is reduced by the headless browser, making RIPLEY feasible for large-scale applications.

### 5. Discussion

#### 5.1 Difficulties of Faithful Replication

Volta's narrow, browser-independent interface to the DOM makes faithful replication relatively easy. Disallowing direct innerHTML assignments helps mediate access to the DOM. The main challenge is handling non-determinism, such as random number generation and time measurement. To address this, we can instrument the client-side code to block on Math.Random and Date objects, ensuring that the same values are used on both the client and the replica.