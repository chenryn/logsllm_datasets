89%
27%
49.6%
84%
49%
49.6%
99%
1%
49.6%
71%
83%
50%
81%
20%
e 2,722,586
e 6,356,793
e 5,107,460
e 7,868,793
e 2,330,346
e 5,717,647
69.7%
62%
68%
69.7%
88%
22%
69.7%
87%
26%
69.7%
98%
5%
69.7%
84%
36%
71%
75%
26%
e 8,081,496
e 13,954,723
e 13,379,473
e 16,193,353
e 11,774,757 e 11,672,400
59.6%
57%
95%
e 540,849
55.7%
57%
83%
BLACK-BOX WITH DATA
59.6%
76%
74%
59.6%
89%
38%
59.6%
99%
1%
59.6%
45%
97%
59.5%
94%
7%
e 1,764,979
e 1,108,691
e 2,357,735
e 408,383
e 2,145,080
55.7%
88%
33%
55.7%
78%
59%
55.7%
100%
1%
55.7%
65%
77%
56%
82%
20%
e 3,330,573
e 7,079,843
e 5,391,816
e 8,852,717
e 3,132,262
e 6,694,115
59.7%
59%
66%
59.7%
87%
24%
59.7%
83%
34%
59.7%
98%
4%
59.7%
78%
45%
60%
75%
30%
e 6,329,751
e 11,646,219
e 10,498,652
e 13,775,411
e 8,651,346
e 9,504,000
56.8%
65%
92%
e 697,747
60.5%
52%
93%
GREY-BOX
56.8%
84%
63%
56.8%
88%
40%
56.8%
100%
1%
e 1,687,563
e 1,413,702
e 2,261,085
60.5%
85%
40%
60.5%
73%
70%
60.5%
100%
0%
41.7%
64%
91%
e 500,553
42.2%
78%
49%
e 2,778,662
e 7,370,974
e 5,427,974
e 9,652,461
e 3,739,336
68.6%
65%
66%
68.6%
93%
17%
68.6%
93%
20%
68.6%
100%
0%
63.6%
90%
28%
e 8,268,764
e 14,634,344
e 14,062,925
e 16,412,751
e 11,777,417
-
-
-
-
-
-
-
-
-
-
-
-
39.3%
100%
0%
WHITE-BOX
59.4%
100%
0%
68.3%
100%
0%
99.5%
100%
0%
30.2%
100%
0%
97.3%
100%
0%
e 1,575,986
e 2,534,932
e 2,378,945
e 3,986,408
e 1,198,900
e 3,892,000
31.2%
100%
0%
69,1%
100%
0%
57.0%
100%
0%
99%
100%
0%
31.7%
100%
0%
22%
100%
0%
e 4,978,737
e 10,923,554
e 9,126,239
e 15,830,758
e 5,059,850
e 3,520,000
32.2%
100%
0%
78.2%
100%
0%
73.2%
100%
0%
96.7%
100%
0%
27.8%
100%
0%
22%
100%
0%
e 7,697,218
e 18,237,258
e 17,567,217
e 23,195,258
e 6,647,723
e 5,280,000
294    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
and 3, signiﬁcantly reduces the losses of the bank. The results
show that the increase in the degree of knowledge of the at-
tacker does not lead to signiﬁcant improvements in attack per-
formance. For example, in the attacks against model B2 based
on Neural Network, we have an evasion rate of 85-89-88% for
the Black-Box setting in Scenarios 1, 2, and 3, respectively
and 88-85-93% in the Gray-Box one. The injection rate and
the evasion rate are dependent on the classiﬁcation threshold
used by the Oracle to determine if a transaction is a fraud or
legitimate and, therefore, to determine if the attacker has to
carry out the transaction. The stolen money depends both on
the injection rate and on the evasion rate and therefore gives
us a basis for comparing the different attacks. Even looking at
the stolen money, we do not notice excessive improvements
in the attacks in which the attacker has a higher degree of
knowledge of the system. So, we can state that the isolated
knowledge of the dataset and the knowledge of the feature
extraction method does not bring signiﬁcant advantages in
conducting an attack following our approach. However, if the
attacker has both pieces of knowledge and also knows the ma-
chine learning algorithm employed by the fraud detector, he
can perform a White-Box attack that instead manages to hide
perfectly the frauds. The experiments also show that the bank
would lose a signiﬁcant amount of money if many fraudsters
were using this method, but we must take into account that
this attack is not easily deployable in the real world because
there are signiﬁcant obstacles. First of all, the attacker needs
a banking dataset, which is very difﬁcult to obtain because
the banks keep their data very carefully and do not release
them. Besides, this approach is perilous for the attacker, in
the case of Black-Box the model based on random forest (B1)
has an attack detection rate higher than 68%, this means that
an attacker has about 32% chance of performing an entire
attack without being detected and then prosecuted by law
for the crime committed. One last important consideration
concerns fraud detectors: the results show that if the attack is
performed on a simple fraud detector, with low performance
(e.g., Logistic Regression, B4) also the Black-Box attack gets
excellent results: with an attack detection rate of 0% in the
case of the ﬁrst scenario, 1% in the second and 5% in the case
of the third scenario. A similar consideration can be made
on the system currently deployed by the banking institution
we collaborated with (i.e., Banksealer, B6). Very different is
the case of the fraud detector based on Random Forest (B1),
which is much more robust detecting 93% of the attacks in
the ﬁrst scenario, 84% in the second and 68% in the third. So
we can state that the choice of the fraud detector is crucial for
a bank to reduce money losses. In our experiments, the fraud
detector based on Random Forest has a bound of money loss
(determined by White-Box tests) of about one-third of the one
we have with the fraud detector based on Logistic Regression.
7 Limitations and Future Works
Besides the assumptions made in Section 5, there are few
more thing that needs to be clariﬁed. Even if we had two
real datasets provided by a banking group, we had to rely
on domain experts (bank operators) to enrich our datasets
with synthetic frauds and compensate for the lack of labels.
This represents only a partial limitation; although we did
not have real fraud ﬂagged, we accurately modeled synthetic
frauds, and the standard behavior of users was real and legit.
A possible limitation regards the source of datasets. Both
datasets used in the experiments belong to the same bank but
in different periods. Therefore, we were able to evaluate only
the transferability of an attack in the same domain. Also, this
limited data source partially affects the representativeness
of the experiment and may underestimate real-world fraud
detection mechanisms’ effectiveness. Financial institutions
have signiﬁcantly more ﬂexibility with training data to build
effective models and re-train them periodically. Interesting
future works can use heterogeneous datasets that span over
a longer time frame, perhaps from two or more banks, to
compare its performance results with the one presented in this
work, also evaluating the impact of the training dataset on the
effectiveness of the approach.
Unlike the current approach that models the spending be-
havior of each user, future works may investigate the possibil-
ity for an adversary to cluster banking customers to generate
a generic model per cluster. This could generalize the results
better and theoretically reduce some of the costs associated
with the attacks. Also, an extension of the present work, which
was focused on study how well the detector performed when
being attacked by evasion attacks, may consist in an evalua-
tion of the impact of the false positives of the different fraud
detection systems employed by banks. Even if some detection
systems are less susceptible to evasion attacks, they may be
characterized by high false-positive rates, thus costing money
in terms of analysis time and might be less likely adopted
by ﬁnancial institutions. Finally, we believe that a promis-
ing future work may explore how the behavior of users can
change over time: in the long term, the change can derive
from variation in the purchasing power of the user, in the
short term there may instead be extraordinary expenses such
as the purchase of a car. This phenomenon is called “concept
drift” and must be taken into account by the fraud detection
system. To manage concept drift, often, the bank adopts an
online-training technique. The model is re-trained with the
last transactions after ensured that these are not frauds. An
attacker could then exploit the Oracle approach to perform a
data poisoning attack. He or she can conceal frauds and con-
sequently shift in his favor the classiﬁcation boundary of the
fraud detector, creating the opportunities for new frauds. So it
would be interesting to deepen the study of a data poisoning
attack based on our Oracle approach.
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    295
8 Conclusions
In this paper, we developed a novel approach to perform eva-
sion attacks by overcoming the issues we found in the ap-
plication of AML techniques to the ﬁeld of banking fraud
detection. We validate this approach by simulating an attacker
that performs the attack against state-of-the-art fraud detection
systems under different conditions. Our approach assumes
that the attacker has a banking dataset at his disposal and can
control the transactions of his victims. The results of the exper-
iments show that a reasonable evasion rate is reachable even
in the case of a Black-Box attack, in which the attacker does
not have any information on the target fraud detection system.
These results are strictly dependent on the fraud detector and
range from the 60% of evasion rate in the case of a fraud
detector based on Random Forest to the 100% in the case of
a fraud detector based on Logistic Regression. A daunting
fact for a real attacker is that the probability that the attack is
detected after a certain number of successful frauds is about
66% in the case of fraud detectors based on Random Forest,
so it is very inconvenient to use the approach to execute a real
attack. An interesting future challenge would be the study of
a data poisoning attack based on our approach. Since many
fraud detectors use online training (i.e., they retrain regularly
using the transactions that have been classiﬁed as legitimate),
it may be possible to apply our approach to conceal frauds and
study how to drift the classiﬁcation threshold of the detector
in order to compromise the detection performance.
References
[1] Alejandro Correa Bahnsen, Djamila Aouada, Aleksan-
dar Stojanovic, and Bjorn Ottersten. Feature engineering
strategies for credit card fraud detection. Expert Systems
with Applications, 51:134–142, 2016.
[2] Siddhartha Bhattacharyya, Sanjeev
Jha, Kurian
Tharakunnel, and J Christopher Westland. Data mining
for credit card fraud: A comparative study. Decision
Support Systems, 50(3):602–613, 2011.
[3] Battista Biggio, Igino Corona, Davide Maiorca, Blaine
Nelson, Nedim Šrndi´c, Pavel Laskov, Giorgio Giacinto,
and Fabio Roli. Evasion attacks against machine learn-
ing at test time. In Joint European conference on ma-
chine learning and knowledge discovery in databases,
pages 387–402. Springer, 2013.