2) Design of controlled experiments: To test the properties
of ad explanations, we launch ad campaigns where we control
the targeting attributes and collect the explanations Facebook
provides. Our goal is to investigate how the targeting attributes
that we select are represented in the explanations users receive.
The primary challenge in designing these controlled ex-
periments is to collect the explanations corresponding to our
ad campaigns. Therefore we launch ad campaigns that try to
target the people that installed our browser extension. Since the
number of users that installed our browser extension (called
monitored users) is limited, we employ several strategies to
7
increase the likelihood that the monitored users receive the
ads so that we can collect the ad explanations:
Selection of targeting attributes: For the monitored users we
gather the targeting attributes that appear in their Facebook Ad
Preferences Page [5]. Depending on the type of the experiment,
we either use the most common attributes across our monitored
users to target ads, or unique attributes that can single out a
user.
High bid: To ensure that our ads would be delivered effectively,
we placed bids that were higher than the value suggested by
Facebook. For most of the experiments, our bid was 25e per
1,000 impressions, while the suggested bid by Facebook was
typically 7–8e per 1,000 impressions.
Campaign objective: We created campaigns that optimized
for “Reach.” According to Facebook, this particular campaign
objective, when selected, shows the ads to the maximum
number of people (rather than showing the ad to people that
are the most likely to click on the ad).
Location: Since most of the users using our browser extension
live in the same city (of about 150K inhabitants), we targeted
this city in our ad campaigns to narrow the audience and have
a higher chance to collect the ad explanation.
Custom list: In some of our experiments, to narrow our audi-
ence even more, we used three custom lists: one comprising
of 900 public U.S. voter records, one comprising of 9,350
public U.S. voter records from North Carolina [8], and one
comprising of 10,000 public French mobile phone numbers.
To each of these lists, we also added our monitored users.
We used each custom list for the appropriate experiments in
order to maximize the probability that the ads would reach
the monitored users; we observed that if the audience reach is
less than 20, the campaign often fails. Thus, we always tried
to achieve an audience reach that was larger than 20 for every
possible combination of targeting attributes that we attempted.
Finally, to ensure that we can identify explanations cor-
responding to different ad campaigns, each ad had unique
text, which in combination with the advertiser identity, made
them uniquely identiﬁable. Our ads were generic with neutral
content. They made use of stock photos provided by Facebook,
and the accompanying text was suggesting users to spend their
vacation in Saarbr¨ucken, Germany, or Nice, France (e.g., “This
spring, the number one destination is Saarbr¨ucken!”). We did
not include any links or track conversions for any ad.
In total, we performed 135 different ad campaigns. Out of
the 135 experiments, 96 reached at least one monitored user
and 65 reached more than one user. In total, we gathered 254 ad
explanations for our own ads from 14 unique monitored users
that were targeted for these experiments. In the remainder of
the section, whenever we refer to controlled experiments, we
only consider the 96 successful experiments.
3) Impact of the small/biased dataset: The goal of our
controlled experiments is to test whether Facebook explana-
tions satisfy the properties we deﬁned, such as completeness
or correctness. The key to design such experiments is to
be able to both target an account and collect the respective
explanation. The number of users we monitor only affects the
probability that we can observe the corresponding explanation.
Even with a small number of users, we were able to observe
the corresponding explanations of most of our ad campaigns.
While our users are not representative of the Facebook
population as a whole, they are spread across 3 countries in
Europe as well as the U.S. While proving that explanations
always satisfy certain properties is likely impossible even with
a much larger user base, proving that explanations fail to
satisfy certain properties only requires one example.
4) Ethics: All experiments and data collection presented
in this paper were reviewed by the Ethical Review Board
of the University of Saarland and approved; they were also
reviewed and approved by the Institutional Review Board of
Northeastern University. We limited our data collection to just
what was necessary to measure the ad explanations and did
not record other user behavior (e.g., the browser extension
was only active when the users were browsing Facebook, and
only uploaded information about the ads they were shown).
Moreover, our extension did not fetch any additional ads that
the user would not have otherwise been shown or click on any
ads; thus, we did not affect advertisers in any way.
Our data collection is compliant with Facebook’s Terms of
Service (https://www.facebook.com/legal/terms). Under Pro-
tecting People’s rights (5th section, 7th point) “If you collect
information from users, you will: obtain their consent, make
it clear you (and not Facebook) are the one collecting their
information, and post a privacy policy explaining what infor-
mation you collect and how you will use it.” We did all of the
above.
D. Evaluation of Facebook’s ad explanations
Using the data described above, we now study the proper-
ties of the explanations provided by Facebook.
1) Overview: Recall that Facebook’s ad explanations typ-
ically have two parts: the ﬁrst part starts with “One reason
you’re seeing this ad ...” or “You’re seeing this ad because ...”,
and the second part starts with “There may be other reasons
you’re seeing this ad ...”.
The ﬁrst part of the ad explanations varies greatly across
all of the ad explanations we observed. If we focus only on
the ﬁrst part of the ad explanations for the ad explanations that
have both parts, we can group (the ﬁrst part of) explanations
based on their underlying pattern and attribute type. Table III
shows the different explanation types we identiﬁed together
with typical examples for each type; overall, we observed 10
different structures for the ﬁrst part of the explanations.
In contrast, the second part of the explanations always
contains age, location, and gender information, and has the
format:
There may be other reasons why you’re seeing
this ad, including that [advertiser] wants to reach
[gender] aged [age range] who live or have recently
been in [location]. This is information based on your
Facebook proﬁle and where you’ve connected to the
Internet.
8
TABLE III: Examples of the ﬁrst part of ad explanations provided by Facebook (we underlined the sources of data Facebook
mentions as well as emphasizing the variable text that changes from explanation to explanation depending on the ad).
Explanation type
LANGUAGE
DEMOGRAPHICS
BEHAVIORS
INTERESTS
DATA BROKERS
Example of explanations
One reason why you’re seeing this ad is that BOREDOM THERAPY wants to reach people who SPEAK ”ENGLISH (US)”. This is based on information
from sources such as your Facebook proﬁle.
One of the reasons why you’re seeing this ad is because we think that you may be in the ”MILLENNIALS” audience. This is based on
what you do on Facebook.
One of the reasons why you’re seeing this ad is because we think that you may be in the ”GMAIL USERS” audience. This is based on
what you do on Facebook.
One reason why you’re seeing this ad is that ACER wants to reach people interested in ELECTRONIC MUSIC, based on activity such as liking pages
or clicking on ads.
One reason you’re seeing this ad is that CANAL FRANCE wants to reach people who are part of an audience created based on data provided by
ACXIOM. Facebook works with data providers to help businesses ﬁnd the right audiences for their ads.
PII-BASED TARGETING One reason you’re seeing this ad is that AAAS - THE AMERICAN ASSOCIATION FOR THE ADVANCEMENT OF SCIENCE wants to reach
people who have visited their website or used one of their apps. This is based on customer information provided by AAAS - THE AMERICAN
ASSOCIATION FOR THE ADVANCEMENT OF SCIENCE.
One reason you’re seeing this ad is that ACTIMEL added you to a list of people they want to reach on Facebook. They were able to reach you
because you’re on their customer list or you’ve provided them with your contact information off of Facebook.
One reason you’re seeing this ad is that ABOUT YOU added you to an audience of people they want to reach on Facebook. This is based on activity
such as watching their Facebook videos, sharing links to their website on Facebook and interacting with their Facebook content.
One reason you’re seeing this ad is that SHAUN T wants to reach people who like their page.
One reason you’re seeing this ad is that AEGEAN AIRLINES wants to reach people with RELATIONSHIP STATUS ”ENGAGED” on their
Facebook proﬁles.
One reason why you’re seeing this ad is that EY CAREERS wants to reach people with THE SCHOOL/UNIVERSITY UNIVERSIT ¨AT DES SAARLANDES
- SAARLAND UNIVERSITY listed on their Facebook proﬁles.
One reason you’re seeing this ad is that ATENAO - TRANSLATION agency wants to reach people with THE EDUCATION LEVEL ”DOCTORATE
DEGREE” listed on their Facebook proﬁles.
PROFILE DATA
LOOKALIKE AUDIENCE One reason why you’re seeing this ad is that AUTODESK STUDENTS wants to reach people who may be similar to their customers.
MOBILE DATA
One reason why you’re seeing this ad is that CDU SAARBR ¨UCKEN-SCHEIDT wants to reach people WHO WERE RECENTLY NEAR THEIR BUSINESS.
This is based on information from your Facebook proﬁle and your mobile device.
SOCIAL NEIGHBORHOOD One reason why you’re seeing this ad is that CARTIER wants to reach people whose friends like their Page.
Count
404
149
239
4,621
78
696
144
1,314
142
188
Note that the value of the gender ﬁeld can be either “men”,
“women”, or “people”, as Facebook allows advertisers to target
“All” genders as shown in Figure 2.
Looking closely at
the examples in Table III, we can
see that the ad explanations often provide information about
who the advertiser is, what
targeting attributes they used,
and what the underlying source for these targeting attributes
is. The underlying data sources mentioned are very diverse,
including “your Facebook proﬁle”, “where you’ve connected
to the internet”, “liking pages”, “clicking on ads”, and “what
you do on Facebook”, among others.
We now turn to examine whether the explanations match
the properties described in Section III-B.
2) Traditional Facebook targeting: We ﬁrst examine ads
placed using only targeting attributes that are provided by
Facebook. After examining these explanations, we then look
at explanations for data broker targeting and ﬁnally advertiser
PII targeting.
a) Personalization:
In the AD-DATASET, there exist
10,936 unique ads that provide different explanations for
at least two users. This suggests that explanations are per-
sonalized. In order to verify this, we performed controlled
experiments where we created a targeting audience A = (a1
OR a2) where a1 and a2 were interest-based attributes.8 We
picked the interests so that there are two users that installed
8For clarity, we omit from A the location or custom list, however, all our
experiments in this section use these targeting options to narrow the audience,
see Section III-C2.
our browser extension, where one had a1 but not a2 and one
had a2 but not a1. We performed two such ad campaigns. In all
campaigns the ad reached both users, and the ad explanation
for each user was different, showing in each case only the
interest attribute that each user had. Thus, ad explanations on
Facebook are personalized.
b) Completeness: In all ad explanations collected in the
AD-DATASET, there is at most one attribute that appears in the
(ﬁrst part of the) ad explanation. This raises questions about
the completeness of the ad explanations given the fact that the
Facebook advertiser interface allows advertisers to use multiple
attributes, and it is unlikely that all advertisers in our dataset
only used one targeting attribute.
To verify that only one attribute is shown even if multiple
attributes are speciﬁed by the advertiser, we conducted 28
controlled experiments that target three attributes A = (a1 AND
a2 AND a3) and 51 that target two attributes A = (a1 AND a2).
We varied the precise attributes targeted in each ad campaign.
In all explanations provided by Facebook across all monitored
users, only one attribute was ever shown, while all users had all
attributes. Thus, we observe that Facebook’s ad explanations
are incomplete.
This incompleteness of explanations raises several ques-
tions regarding whether there is a strategy behind which
attribute appears in the explanation. Due to practical limitations
on the number of monitored users and controlled experiments
we could perform, we cannot provide deﬁnite answers as to
which attribute is selected; however, we test the impact of
several parameters on the explanations:
9
(1) Does the order of selected attributes affect the shown
attribute? We performed four experiments with two pairs of
interest-based attributes where, for each pair, we tried both
orderings of attributes A1 = (a1 AND a2) and A2 = (a2 AND
a1). The order did not affect the ad explanation shown.
(2) Does the rarity of the attributes affect the shown attribute?
We conducted 23 controlled experiments where Ai = (a1 AND
a2) and where both a1 and a2 are of the same type (behavior-,
demographic- or interest-based), and where a1 was more com-
mon than a2. In all 52 ad explanations we collected from all
users, the attribute that was the most common always appeared
in the ad explanation. For example, for targeting “Video games
(915M users) AND Time (823M)” and “Video games (915M)
AND Photography (659M)”, “Video Games” would be chosen.
This result suggests (but does not conclusively prove) that
Facebook chooses the most common attribute to include in the
ad explanation. If this is in fact the case, this choice opens the
door for malicious advertisers to obfuscate their true targeting
attributes by always including a very popular attribute (e.g.,
“Facebook access (mobile): all mobile devices (2B)”) in their
targeting attributes.
(3) Does the type of the attributes affect the shown attribute?
While our experiments suggest
that for attributes of the
same type (behavior-, demographic- or interest-based), rarity
is the factor that decides which attribute will be shown in
the explanation, this does not apply when the attributes are
of different types. We performed 37 controlled experiments
Ai = (a1 AND a2) where a1 and a2 are of different types (e.g.,
a1 is demographic- and a2 is behavior-based) as well as 24
experiments Ai = (a1 AND a2 AND a3), where a1, a2, a3 are of
at least two different types. We tested demographic-, behavior-
, interest-, and PII-based targeting attributes. Table IV shows
all the pairs of attributes that were used in our experiments,
the type of the attribute that appears in the ad explanation, and
the number of experiments for each pair.
As we can observe in the table, the order appears to be
deterministic. We observe that: DEMOGRAPHIC > INTEREST
> PII-BASED > BEHAVIOR. That is, our results suggest that
whenever the advertiser uses one demographic-based attribute
in addition to other attributes in its targeting, the demographic-
based attribute will be the one in the explanation. If this is
in fact the case, this choice is potentially impactful to users
as previous research shows that users often consider behavior
attributes more sensitive than the demographic ones [37].
(4) Do logical operators affect the shown attribute? Despite
the fact that advertisers can include negation when selecting
attributes, we observe no ad explanation in the AD-DATASET
that contains a negation. To validate that negated attributes do
not appear in ad explanations, we conducted three controlled
experiments using the NOT operator with interest-, behavior-
and demographic-based attributes. In none of the experiments
did we see the respective attribute in the explanation. Instead,
the explanations included a custom list explanation, which was
our non-negated attribute in the experiments.
c) Consistency: In our controlled experiments, for the
65 ads that reached more than one of the monitored users,
the explanations were the same for 61 users. The rest of four
correspond to explanations that are personalized (i.e., the users
10
TABLE IV: Dominance of attribute types.
Attribute types selected
Demographic AND Behavior
Demographic AND Behavior AND PII-Based
Demographic AND PII-Based
Demographic AND Demographic AND PII-Based
Interest AND Demographic
Interest AND Demographic AND PII-Based
Interest AND Behavior
Interest AND Behavior AND PII-Based
Interest AND PII-Based
Interest AND Interest AND PII-Based
Behavior AND Behavior AND PII-Based
Behavior AND PII-Based
Shown in expla-
nation
Demographic
Demographic
Demographic
Demographic
Demographic
Demographic
Interest