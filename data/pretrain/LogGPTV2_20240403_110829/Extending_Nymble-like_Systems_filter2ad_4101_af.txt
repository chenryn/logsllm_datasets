### Figure 5: Non-Membership Proof Comparison for Large Blacklists

This figure compares the performance of our proposed non-membership proof against two existing approaches in the literature: BLAC [32]–[34] and PEREA [33]. The timing measurements for BLAC and PEREA were taken directly from their original papers, while the timing information for our approach was measured empirically. Therefore, the coefficients on each line are only approximations of the actual performance. Nevertheless, the graphs capture the asymptotic behavior of each approach. Error bars are omitted for two reasons: 
1. The error range for our approach is too small to be visible.
2. The measurements for BLAC and PEREA are based on data from their respective papers rather than experimental measurements.

---

### Preventing Exit Node Operators from Using Services

To prevent exit node operators from using their services even when they do not route their connections through Tor, and to address the issue where users behind a firewall that censors access to Tor and VIs (Verification Issuers) are unable to obtain a verinym and thus cannot use the system, we propose the following solutions:

#### A. Verinym Acquisition for Tor Exit Relays

Service Providers (SPs) cannot distinguish connections originating at a Tor exit relay from those made over Tor and routed through that exit relay. Consequently, SPs that block access from Tor also block access from Tor exit relay operators, even when their connections are not coming through Tor. Previous Nymble-like systems provided a viable solution for regular Tor users but did not address the needs of Tor exit relay operators.

Fortunately, Tor implements a public key infrastructure (PKI) among its relays. Each Tor relay has a long-term public signing key called an identity key [11]. Thus, VIs can demand a Zero-Knowledge Proof (ZKP) of knowledge of the secret portion of an exit relay’s identity key at the start of the Verinym Acquisition Protocol. This prevents unauthorized users from obtaining nymbles under the guise of an exit relay, while allowing the operator of that exit relay to obtain nymbles for their own use.

Suppose E is an exit node operator who wishes to connect to an SP using a Nymble-like system for anonymous authentication. The additional proof required from E is outlined below. Let S be a set of t VIs and z be E’s IP address.

**E does the following:**
1. E connects directly to each VIij ∈ S.

**VIij does the following:**
2. VIij checks z against the directory list of Tor exit relays.
3. If z is not on the list, VIij proceeds as usual for the Verinym Acquisition Protocol; otherwise, VIij chooses a random challenge c and sends it to E.

**E does the following:**
4. E receives the challenge c and prepares the standard request R for a verinym.
5. E computes a signature ψR on (c || R) using their private identity key.
6. E transmits the tuple (R, ψR) to VIij.

**VIij does the following:**
7. VIij receives ψR and verifies the signature. If ψR is incorrect, VIij aborts; otherwise, VIij proceeds as usual for the Verinym Acquisition Protocol.

#### B. Verinym Acquisition for Censored Users

Access to Tor is restricted in several countries due to government censorship (e.g., the ‘Great Firewall of China’). To solve this problem, the Tor network uses bridges [10]. A bridge is essentially a regular Tor relay that is not listed in the directory. Censored users can obtain portions of the list of bridge relays, thereby finding an entry point into the Tor network. However, obtaining the entire list is intentionally very difficult, making it infeasible for an adversary to block all bridge relays.

This solves the availability problem for Tor, allowing censored users to still access the Tor network by using bridges. However, if the entire Tor network is blocked, the VIs will also be blocked, preventing censored users from obtaining a verinym in the usual way. We need a Nymble-like system analog of bridges.

We envision a set of simple volunteer-run entities called Identity Verifiers (IVs). IVs are simple servers (e.g., an Apache module running on volunteer machines) distributed throughout the Internet. Each IV possesses a public-private key pair for signature generation. The list of IP addresses and public keys for all available IVs is known to the VIs. Ideally, no single VI will possess the entire list, lest that VI be compromised; instead, each VI may have approximately (1/s)th of the list.

It should be difficult for an attacker to gain access to large portions of the IV list. Bridge relays could double as IVs, making the problem of obtaining the lists of bridges and IVs equivalent. Alternatively, the list of bridge relays and IVs could be linked in such a way as to make the task of obtaining large portions of each list equivalent. Further development of these considerations is left to future work.

**The IVs offer the following functionality:**
Upon receiving a challenge bit string c from a user U with IP address z, an IV responds with a signature on hash(c || z). The additional part of the protocol works as follows:

**U does the following:**
1. U connects to an arbitrary bridge relay B and builds a circuit and SSL connection to VIij through B; U sends her claimed IP address z to VIij through this connection.

**VIij does the following:**
2. VIij receives z from U and replies with a random challenge c and the IP address of an IV selected by VIij. (The method of selection can be arbitrary: random, the IV most trusted by the VI, etc.)

**U does the following:**
3. U receives the challenge c and IP address of an IV from VIij; she connects to the IV and sends c.

**The IV does the following:**
4. The IV receives c and determines z empirically from the IP connection header. It replies by sending ψz, which is a signature on hash(c || z).

**U does the following:**
5. U receives ψz from the IV and forwards it to VIij.

**VIij does the following:**
6. VIij receives ψz and checks the signature. If ψz is incorrect, VIij aborts; otherwise, VIij proceeds as usual for the Verinym Acquisition Protocol.

The naive protocol just described is susceptible to the following attack: a malicious U chooses a random IP address and initiates the protocol with that as their self-reported address. In the unlikely event that U receives the address of a colluding IV, she obtains a signature on the fake IP address, thereby convincing the VI to issue a share of a verinym. Otherwise, U chooses a new random IP address and tries again. To protect against this attack, we can require:
- The VIs somehow trust the IVs.
- The VIs choose multiple IVs and require U to obtain a signature from each.
- A combination of these approaches.

---

### Objective Blacklisting

Schwartz et al. proposed contract-based revocation [18] in their Contractual Anonymity papers [28]–[30], whereby U enters into an anonymity contract with the SP. This contract assures U of their anonymity as long as they do not violate the contract. If U violates the contract, a Group Manager (GM) can revoke their anonymity. Schwartz et al. use ideas from trusted computing to construct a contract-based revocation system based on group signatures. In their scheme, U uses remote attestation to verify that the software running on the GM will only deanonymize them if they do indeed violate the contract.

In [22], Lin and Hopper describe an objective blacklisting extension for Jack. Their approach uses the label field in Camenisch and Shoup’s verifiable encryption scheme [7] to force the PE (Pseudonym Extractor) to include a contract in its trapdoor computation. The idea is that if the provided contract is incorrect, the trapdoor computation will fail. While any added security offered by this approach may be illusory, a similar mechanism can be incorporated into the nymble constructions of other Nymble-like systems as outlined below. Because different Nymble-like systems do not necessarily share a common trapdoor function, we propose to use a hash c of the contract as an input parameter to the one-way function used to compute the subsequent nymbles in a sequence. When incorporated into Nymble and Nymbler, this idea works as follows:

- **Nymble:** Use c as the HMAC key for the ‘top’ chain (see Figure 1).
- **Nymbler:** Replace Rabin’s function f(z) = z² mod n with f(z, c) = c · z² mod n.

This ensures that the given contract is enforced on U, meaning different users may have different rights in their contracts without partitioning the anonymity set.

As in [22], this solution requires the following additional trust assumptions:
- U must trust the PE to verify that they did indeed violate the contract.
- The PE must trust the SP to not forge proofs of contract violations.
- The SP must trust the PE not to divulge any potentially sensitive information it witnesses while verifying that misbehavior has occurred.

Constructing an objective blacklisting solution that does not require additional trust assumptions or reliance on trusted computing remains an open problem.

---

### Conclusion

We have presented several extensions to the Nymble framework, including a new threshold Verinym Issuer construction, an efficient way to achieve inter-window revocation and blacklist transferability, alternative verinym acquisition techniques for Tor exit relays and censored users, and contract-based revocation. These extensions improve the liveness, security, and functionality of Nymble-like schemes built from the extended framework, and solve several open problems identified in the future work sections of papers on particular Nymble-like systems [19]–[22].

Nonetheless, there are still several open problems identified in those papers that constitute exciting directions for future research. For example, system-wide banning of cheaters [20], NAT-aware IP blocking [20], and banning of entire subnets without reducing privacy [20], [21]. Additionally, investigating the use of other unique identifiers in place of IP addresses would likely have broader implications for protecting against Sybil attacks [12]. Finally, as stated in §V, designing an objective blacklisting mechanism that does not require trusted hardware remains an open problem.

**Acknowledgements:**
We thank Aniket Kate and the anonymous reviewers for their helpful comments. This work was supported by NSERC, MITACS, and a David R. Cheriton Graduate Scholarship.

**References:**
[1] M. Bellare, J. A. Garay, and T. Rabin, “Fast Batch Verification for Modular Exponentiation and Digital Signatures,” in Proceedings of EUROCRYPT 1998, Espoo, Finland, May 1998.
[2] S. Brands, “Restrictive Blinding of Secret-Key Certificates,” in Proceedings of EUROCRYPT 1995, Saint-Malo, France, May 1995.
[3] S. A. Brands, Rethinking Public Key Infrastructures and Digital Certificates: Building in Privacy. MIT Press, 2000.
[4] S. A. Brands, L. Demuynck, and B. D. Decker, “A Practical System for Globally Revoking the Unlinkable Pseudonyms of Unknown Users.” Department of Computer Science, K.U.Leuven, Technical Report CW472, 2006.
[5] S. A. Brands, L. Demuynck, and B. D. Decker, “A Practical System for Globally Revoking the Unlinkable Pseudonyms of Unknown Users,” in Proceedings of ACISP 2007, Townsville, Australia, July 2007.
[6] E. Brickell and J. Li, “Enhanced Privacy ID: A Direct Anonymous Attestation Scheme with Enhanced Revocation Capabilities,” in Proceedings of WPES 2007, Alexandria, VA, October 2007.
[7] J. Camenisch and V. Shoup, “Practical Verifiable Encryption and Decryption of Discrete Logarithms,” in Proceedings of CRYPTO 2003, Santa Barbara, CA, August 2003.
[8] J. Camenisch and M. Stadler, “Efficient Group Signature Schemes for Large Groups (Extended Abstract),” in Proceedings of CRYPTO 1997, Santa Barbara, CA, August 1997.
[9] I. Damgård and M. Koprowski, “Practical Threshold RSA Signatures without a Trusted Dealer,” in Proceedings of EUROCRYPT 2001, Innsbruck, Austria, May 2001.
[10] R. Dingledine and N. Mathewson, “Design of a Blocking-Resistant Anonymity System.” The Tor Project, Technical Report, 2006.
[11] R. Dingledine, N. Mathewson, and P. F. Syverson, “Tor: The Second-Generation Onion Router,” in Proceedings of USENIX Security 2004, San Diego, CA, August 2004.
[12] J. R. Douceur, “The Sybil Attack,” in Proceedings of IPTPS 2002, Cambridge, MA, March 2002.
[13] P. Feldman, “A Practical Scheme for Non-interactive Verifiable Secret Sharing,” in Proceedings of FOCS 1987, Los Angeles, CA, October 1987.
[14] P.-A. Fouque and J. Stern, “Fully Distributed Threshold RSA under Standard Assumptions,” in Proceedings of ASIACRYPT 2001, Gold Coast, Australia, December 2001.
[15] Y. Frankel, P. D. MacKenzie, and M. Yung, “Robust Efficient Distributed RSA-Key Generation,” in Proceedings of STOC 1998, Dallas, TX, May 1998.
[16] I. Goldberg, “A Pseudonymous Communications Infrastructure for the Internet,” Ph.D. dissertation, UC Berkeley, 2000.
[17] S. Goldwasser, S. Micali, and R. L. Rivest, “A Digital Signature Scheme Secure Against Adaptive Chosen-Message Attacks,” SIAM Journal on Computing (SICOMP), vol. 17, no. 2, pp. 281–308, April 1988.
[18] R. Henry and I. Goldberg, “Formalizing Anonymous Blacklisting Systems,” in Proceedings of IEEE S&P 2011, Oakland, CA, May 2011.
[19] R. Henry, K. Henry, and I. Goldberg, “Making a Nymbler Nymble using VERBS,” in Proceedings of PETS 2010, Berlin, Germany, July 2010.
[20] R. Henry, K. Henry, and I. Goldberg, “Making a Nymbler Nymble using VERBS (Extended Version).” Centre for Applied Cryptographic Research, UWaterloo, Technical Report CACR 2010-05, 2010.
[21] P. C. Johnson, A. Kapadia, P. P. Tsang, and S. W. Smith, “Nymble: Anonymous IP-Address Blocking,” in Proceedings of PETS 2007, Ottawa, ON, June 2007.
[22] Z. Lin and N. Hopper, “Jack: Scalable Accumulator-based Nymble System,” in Proceedings of WPES 2010, Chicago, IL, October 2010.
[23] P. Lofgren and N. Hopper, “BNymble (A Short Paper): More Anonymous Blacklisting at Almost No Cost,” in Proceedings of FC 2011, St. Lucia, February 2011.
[24] A. Lysyanskaya, “Signature Schemes and Applications to Cryptographic Protocols,” Ph.D. dissertation, Department of Electrical Engineering and Computer Science, MIT, 2002.
[25] A. Menezes, P. C. van Oorschot, and S. A. Vanstone, Handbook of Applied Cryptography. CRC Press, 1996, fifth Printing (August 2001).
[26] T. P. Pedersen, “Non-Interactive and Information-Theoretic Secure Verifiable Secret Sharing,” in Proceedings of CRYPTO 1991, Santa Barbara, CA, August 1991.
[27] K. Peng, C. Boyd, and E. Dawson, “Batch Zero-Knowledge Proof and Verification and Its Applications,” ACM Transactions on Information and System Security (TISSEC), vol. 10, no. 2, May 2007, Article No. 39.
[28] E. J. Schwartz, “Contractual Anonymity,” Master’s thesis, Information Networking Institute, Carnegie Mellon, 2009.
[29] E. J. Schwartz, D. Brumley, and J. M. McCune, “Contractual Anonymity.” School of Computer Science, Carnegie Melon, Technical Report CMU-CS-09-144, 2009.
[30] E. J. Schwartz, D. Brumley, and J. M. McCune, “A Contractual Anonymity System,” in Proceedings of NDSS 2010, San Diego, CA, February 2010.
[31] V. Shoup, “Practical Threshold Signatures,” in Proceedings of EUROCRYPT 2000, Bruges, Belgium, May 2000.
[32] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith, “Blacklistable Anonymous Credentials: Blocking Misbehaving Users Without TTPs,” in Proceedings of CCS 2007, Alexandria, VA, October 2007.
[33] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith, “PEREA: Towards Practical TTP-free Revocation in Anonymous Authentication,” in Proceedings of CCS 2008, Alexandria, VA, October 2008.
[34] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith, “BLAC: Revoking Repeatedly Misbehaving Anonymous Users without Relying on TTPs,” ACM Transactions on Information and System Security (TISSEC), vol. 13, no. 4, October 2010, Article No. 39.
[35] P. P. Tsang, A. Kapadia, and S. W. Smith, “Anonymous IP-address Blocking in Tor with Trusted Computing (Short Paper: Work in Progress),” in Proceedings of WATC 2006 (Fall), Tokyo, Japan, November 2006.
[36] Wikimedia Foundation, “Wikipedia:Blocking policy — the free encyclopedia.” [Online]. Available: Wikipedia, http://en.wikipedia.org/wiki/Wikipedia:Blocking_policy