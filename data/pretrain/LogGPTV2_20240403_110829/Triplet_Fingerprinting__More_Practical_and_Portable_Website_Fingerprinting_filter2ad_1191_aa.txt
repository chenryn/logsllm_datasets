title:Triplet Fingerprinting: More Practical and Portable Website Fingerprinting
with N-shot Learning
author:Payap Sirinam and
Nate Mathews and
Mohammad Saidur Rahman and
Matthew Wright
Triplet Fingerprinting: More Practical and Portable Website
Fingerprinting with N-shot Learning
Payap Sirinam
Nate Mathews
Navaminda Kasatriyadhiraj Royal Air Force Academy
Rochester Institute of Technology
Bangkok, Thailand
PI:EMAIL
Mohammad Saidur Rahman
Rochester Institute of Technology
Rochester, New York
PI:EMAIL
Rochester, New York
PI:EMAIL
Matthew Wright
Rochester Institute of Technology
Rochester, New York
PI:EMAIL
ABSTRACT
Website Fingerprinting (WF) attacks pose a serious threat to users’
online privacy, including for users of the Tor anonymity system.
By exploiting recent advances in deep learning, WF attacks like
Deep Fingerprinting (DF) have reached up to 98% accuracy. The DF
attack, however, requires large amounts of training data that needs
to be updated regularly, making it less practical for the weaker
attacker model typically assumed in WF. Moreover, research on
WF attacks has been criticized for not demonstrating attack effec-
tiveness under more realistic and more challenging scenarios. Most
research on WF attacks assumes that the testing and training data
have similar distributions and are collected from the same type of
network at about the same time. In this paper, we examine how
an attacker could leverage N-shot learningÐa machine learning
technique requiring just a few training samples to identify a given
classÐto reduce the effort of gathering and training with a large
WF dataset as well as mitigate the adverse effects of dealing with
different network conditions. In particular, we propose a new WF
attack called Triplet Fingerprinting (TF) that uses triplet networks
for N-shot learning. We evaluate this attack in challenging settings
such as where the training and testing data are collected multiple
years apart on different networks, and we find that the TF attack
remains effective in such settings with 85% accuracy or better. We
also show that the TF attack is also effective in the open world
and outperforms traditional transfer learning. On top of that, the
attack requires only five examples to recognize a website, making
it dangerous in a wide variety of scenarios where gathering and
training on a complete dataset would be impractical.
CCS CONCEPTS
• Security and privacy → Privacy-preserving protocols; • Net-
works → Network privacy and anonymity.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’19, November 11ś15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11. . . $15.00
https://doi.org/10.1145/3319535.3354217
KEYWORDS
Tor; privacy; website fingerprinting; deep learning; n-shot learning;
triplet networks
ACM Reference Format:
Payap Sirinam, Nate Mathews, Mohammad Saidur Rahman, and Matthew
Wright. 2019. Triplet Fingerprinting: More Practical and Portable Website
Fingerprinting with N-shot Learning. In 2019 ACM SIGSAC Conference on
Computer and Communications Security (CCS ’19), November 11ś15, 2019,
London, United Kingdom. ACM, New York, NY, USA, 18 pages. https://doi.
org/10.1145/3319535.3354217
1 INTRODUCTION
The Tor anonymity system provides privacy to eight million users
a day [3, 18], but it has been shown to be vulnerable to a traffic
analysis attack called website fingerprinting (WF). WF exploits the
fact that the network traffic of each website has its own unique
pattern, and these patterns can be learned by a machine learning
classifier. The attacker must train the classifier by collecting a large
body of network traces between his client and the Tor network
from his own visits to websites of interest (monitored websites) and
other websites that users might visit (unmonitored websites). With
the trained classifier in hand, the attacker then intercepts traffic in
an encrypted connection between the victim and the first Tor node
and uses the classifier to determine whether or not she visited a
monitored site and if so, which website she visited. This allows a
local and passive network adversary as depicted in Figure 1, such
as the victim’s Internet service provider (ISP), someone sniffing the
wireless connection, or a compromised home router, to link the
user with her websites and break the anonymity provided by Tor.
When compared to the alternative end-to-end traffic confirmation
attack1, a weak WF attacker needs to be at only the client end of
the communication steam.
Previous work in WF attacks [5, 6, 10, 20, 21, 24, 33] demonstrated
effective performance in both the closed-world setting, in which
the user is assumed to only visit sites in the monitored set, and
the more realistic open-world setting, in which the user might visit
any website, whether monitored or not. The state-of-the-art WF
attack, Deep Fingerprinting (DF), uses a deep learning classifier to
achieve over 98% accuracy in the closed world and over 0.9 for both
1An end-to-end confirmation attack allows an attacker to associate a Tor client with
their destination by capturing on both ends of the circuit [19, 28, 38], andÐunlike the
WF attackÐis outside Tor’s protection guarantees.
2.2 WF Attack Assumptions
In this section, we summarize and categorize the current assump-
tions that have been made in the WF literature. This allows us to
identify which attacker constraints have been appropriately evalu-
ated and which have not.
Table 1: Impact on attack accuracy when training and testing
with different TBB versions. Data from Juarez at al. [13].
TBB Version
2.4.7 (Train)
3.5 (Train)
3.5.2.1 (Train)
2.4.7 (Test)
62.70 ± 2.80
16.28 ± 4.51
6.51 ± 1.15
3.5 (Test)
29.93 ± 2.54
76.38 ± 4.97
66.75 ± 3.68
3.5.2.1 (Test)
12.30 ± 1.47
72.43 ± 3.22
79.58 ± 2.45
2.2.1 Closed- vs Open-world Scenario. WF attacks are evaluated
under two possible scenarios: closed world and open world. The
closed world assumes that there are only k websites that the client
can visit, where k is far smaller than the number of websites avail-
able in the real world. Despite being criticized as unrealistic [13],
the closed-world evaluation is still used as a metric to evaluate the
quality of the attacks and feature sets used in attacks. Subsequent
work also considers the open-world scenario to measure the at-
tack efficacy in a realistic setting. Here, we examine two additional
constraints when designing an open-world experiment:
• Size of the open world. Researchers have increased the number
of unmonitored websites in open-world datasets to evaluate
the ability of the WF classifier to distinguish between mon-
itored and unmonitored sites [10, 21, 24, 27, 33]. The size of
the unmonitored set has reached up to 400,000 websites in the
dataset of Rimmer et al. [24]. While even larger sets would be
more representative, given that the victim could be visiting any
page on any site in the world, there are diminishing returns
above a certain size. Further, it is likely that sites have widely
varying popularity for Tor users, so capturing the extended
tail of the distribution may not be meaningful in practice. In
this paper, we do not attempt to address the question of the
most appropriate size of the unmonitored set.
• Open-world evaluation model. There are two models used to
evaluate the performance of WF classifiers in open world: the
Standard model and the AWF model [24]. Under the Standard
model, samples from the unmonitored set are included in the
training data as an additional label. Researchers assume that
doing so will help the classifier to better distinguish between
the monitored and unmonitored websites. This model was used
by the majority of prior works [10, 21, 27, 33]. On the other
hand, the AWF model does not include unmonitored websites
in the training data set. The classifier instead uses a confidence
threshold based on the cross-entropy loss function to identify
unmonitored sites. Rimmer et al. [24] argue that even if the
attacker may gain benefit from including the unmonitored
websites, the size of the unmonitored set is still not represen-
tative of the actual size of the world of websites. The choice
of which model is best is an interesting point to consider, but
we stick with the more popular Standard model for this paper
and leave the question for future work.
2.2.2 Users’ Browsing Behavior. Most prior work [10, 21, 24, 27, 33]
assumes that Tor clients follow a rather specific behavior: they use
Tor to browse websites sequentially, and they use only a single tab
at a time so that website visits do not overlap. This is, of course, not
representative of real world behavior of a Tor client. As Tor con-
nections are slow, it is likely that clients will open several browser
tabs and visit sites concurrently [1, 31, 35]. The effects of multi-tab
browsing have been explored in prior work [13, 34], and we do not
further examine them in this paper.
2.2.3 Traffic Parsing and Background Traffic. In WF attacks, we
assume that the attacker can collect all the traffic generated by a
site and can effectively distinguish this traffic from other traffic
connections [13]. This assumption is guaranteed to be true only
when the attacker performs the attack at the guard node, which
allows him to extract the specific traffic by using the Tor circuit ID.
In the case that the attacker performs the attack as an eavesdropper
between the client and the guard node, all Tor traffic is multiplexed
in the TLS connection. Recent work has developed techniques to
effectively discriminate the Tor traffic from multiplexed TLS traf-
fic and split it into corresponding encrypted connections to each
website [34]. Thus, this assumption has been already handled and
is not the focus of our study.
3 ATTACKER GOALS
In this section, we identify elements of WF attacks that may be
improved to better suit realistic adversaries. Prior work on attack
design has largely discounted these requirements.
3.1 Generalizability
Previous research assumes that a WF attacker can train his classifier
under the same conditions as the victim, effectively making it a
targeted attack. Given this assumption, the attacker can replicate
the victim’s network conditions, Tor-browser-bundle (TBB) version,
and settings, and these can impact the attack’s performance [13].
Alternatively, the attacker may be interested to attack more than
one victim, i.e. to perform a untargeted attack. In this case, the at-
tacker should be prepared for users with different types of network
connections, TBB versions, and settings. This constraint makes WF
more difficult as the adversary’s classifier must remain effective
even when using such a diverse data set. Juarez et al. show [13]
that if the attacker had trained the WF classifier based on one TBB
version and tested with another, the accuracy of the attack drops
drastically as shown in Table 1.
Recent WF attack research [10, 21, 24, 27, 33] assumes that the
attacker performs a targeted attack by crawling a single data set
using similar machines under the same network conditions. This
data set is then used in both the training and testing phases, which
gives the attacker an unrealistic advantage for any untargeted at-
tack, as the distribution of traces would be more heterogeneous in
the real world. In this work, we investigate how a WF attack can
be crafted to avoid this assumption.
Table 2: Bootstrap time to create a WF classifier (AWF [24]).
The crawling rate is approx. 2,000 instances/day/computer
and 500,000 instances are required for training.
attacker obtains an older dataset, it will be too stale to help in their
approach. Our model, on the other hand, can use a years-old dataset
to build the pre-trained model.
No. of
PCs
1
4
8
12
24
Crawling
Time
250 days
63 days
32 days
21 days
11 days
Training Time
(w/GPU)
<1 hour
<1 hour
<1 hour
<1 hour
<1 hour
Bootstrap
Time
250 days
63 days
32 days
21 days
11 days
3.2 Bootstrap Time
To perform WF attacks, the attacker needs to train the classifier
to predict the unknown traffic captured from the client. This does
not, however, capture the bootstrap time, the total amount of time
required for the attacker to produce a ready-to-use classifier. This
time includes both the time required to crawl a training data set and
to train the classifier. It is important to note that the traffic traces
used for training the classifier tends to be dynamic and changes over
time due to many factors, such as changes in the website, changes
in network conditions, and changes in Tor. Thus, the attacker needs
to collect new network traffic frequently to avoid this mismatch
between the testing and training data.
To the best of our knowledge, there is no WF research that
comprehensively considers the bootstrap time. Prior work makes
the assumption that the dataset used to test the classifier is from the
same distribution that is used for training. However, in a realistic
scenario, the gap time between the training and testing phases
may be large enough to cause potential data mismatch issues which
would negatively affect performance. This concern has been studied
in prior work. Juarez et al. found that attack accuracy for k-NN
dropped from 80% to 30% within 10 days [13], while Rimmer et
al. found a drop in accuracy from 95% to 81% after 28 days using
an SDAE classifier [24]. Therefore, we can infer that the trained
classifier will only remain effective for a few weeks at best after
the classifier is initially trained.
The need to frequently re-train the classifier raises the question
in regards to the computing resources and time required for the
attacker to collect the new data. The longer the time used to collect
the new data, the higher the chance of the dataset’s staleness by
the time the attack is deployed. Table 2 shows the time required for
crawling the data (with typical PCs on a fast network connection)
used for training the classifier for AWF model [24]. Even when the
attacker uses two dozen computers for crawling, nearly two weeks
are needed to collect the large data set.
Unique to the literature so far, Wang and Goldberg examined the
issues of bootstrap time and data freshness for the k-NN attack [34].
They find that k-NN trained on as few as 31 instances per site is
nearly as effective as using 85 instances per site, with 0.77 TPR and
0.003 FPR. For five instances per site, however, they report a TPR of
just 0.253. Additionally, they still need to collect thousands of traces