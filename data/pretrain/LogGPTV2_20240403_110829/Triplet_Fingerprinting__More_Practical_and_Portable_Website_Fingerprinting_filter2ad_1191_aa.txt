# Title: Triplet Fingerprinting: More Practical and Portable Website Fingerprinting with N-shot Learning

## Authors:
- Payap Sirinam, Navaminda Kasatriyadhiraj Royal Air Force Academy, Bangkok, Thailand
- Nate Mathews, Rochester Institute of Technology, Rochester, New York
- Mohammad Saidur Rahman, Rochester Institute of Technology, Rochester, New York
- Matthew Wright, Rochester Institute of Technology, Rochester, New York

## Abstract
Website Fingerprinting (WF) attacks pose a significant threat to users' online privacy, including for those using the Tor anonymity system. Recent advances in deep learning, such as Deep Fingerprinting (DF), have achieved up to 98% accuracy. However, DF requires large amounts of training data that need regular updates, making it less practical for weaker attackers. Additionally, WF research has been criticized for not demonstrating effectiveness under more realistic and challenging scenarios. Most studies assume similar distributions and collection times for training and testing data.

In this paper, we explore how an attacker can use N-shot learning, a machine learning technique requiring only a few training samples, to reduce the effort of gathering and training on large WF datasets and mitigate the adverse effects of different network conditions. We propose a new WF attack called Triplet Fingerprinting (TF) that uses triplet networks for N-shot learning. Our evaluation in challenging settings, where training and testing data are collected years apart on different networks, shows that TF remains effective with 85% or better accuracy. We also demonstrate that TF outperforms traditional transfer learning in open-world scenarios, requiring only five examples to recognize a website. This makes TF dangerous in various scenarios where collecting and training on a complete dataset would be impractical.

## CCS Concepts
- **Security and Privacy** → Privacy-preserving protocols
- **Networks** → Network privacy and anonymity

## Keywords
Tor, privacy, website fingerprinting, deep learning, N-shot learning, triplet networks

## ACM Reference Format
Payap Sirinam, Nate Mathews, Mohammad Saidur Rahman, and Matthew Wright. 2019. Triplet Fingerprinting: More Practical and Portable Website Fingerprinting with N-shot Learning. In 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11–15, 2019, London, United Kingdom. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/3319535.3354217

## 1 Introduction
The Tor anonymity system provides privacy to eight million users daily [3, 18], but it is vulnerable to website fingerprinting (WF) attacks. WF exploits the unique patterns in the network traffic of each website, which can be learned by a machine learning classifier. The attacker must train the classifier by collecting a large body of network traces from visits to monitored and unmonitored websites. With the trained classifier, the attacker intercepts encrypted traffic between the victim and the first Tor node to determine if the victim visited a monitored site and, if so, which one. This allows a local and passive network adversary, such as the victim's Internet service provider (ISP), to break the anonymity provided by Tor.

Previous WF attacks [5, 6, 10, 20, 21, 24, 33] have shown effective performance in both closed-world and open-world settings. The state-of-the-art WF attack, Deep Fingerprinting (DF), achieves over 98% accuracy in the closed world and over 0.9 in the open world. However, DF requires large amounts of training data and regular updates, making it less practical for weaker attackers.

## 2.2 WF Attack Assumptions
We summarize and categorize the current assumptions in WF literature to identify which attacker constraints have been appropriately evaluated.

### Table 1: Impact on Attack Accuracy with Different TBB Versions
| TBB Version (Train) | TBB Version (Test) | Accuracy |
|---------------------|--------------------|----------|
| 2.4.7               | 2.4.7              | 62.70 ± 2.80 |
| 2.4.7               | 3.5                | 29.93 ± 2.54 |
| 2.4.7               | 3.5.2.1            | 12.30 ± 1.47 |
| 3.5                 | 2.4.7              | 16.28 ± 4.51 |
| 3.5                 | 3.5                | 76.38 ± 4.97 |
| 3.5                 | 3.5.2.1            | 72.43 ± 3.22 |
| 3.5.2.1             | 2.4.7              | 6.51 ± 1.15 |
| 3.5.2.1             | 3.5                | 66.75 ± 3.68 |
| 3.5.2.1             | 3.5.2.1            | 79.58 ± 2.45 |

### 2.2.1 Closed- vs Open-World Scenario
WF attacks are evaluated in two scenarios: closed-world and open-world. The closed-world scenario assumes a limited number of websites, while the open-world scenario considers a more realistic setting. We examine two additional constraints in open-world experiments:
- **Size of the open world**: Researchers have increased the number of unmonitored websites to evaluate the classifier's ability to distinguish between monitored and unmonitored sites. While larger sets are more representative, there are diminishing returns above a certain size.
- **Open-world evaluation model**: Two models are used: the Standard model, which includes unmonitored websites in the training data, and the AWF model, which does not. We use the Standard model in this paper.

### 2.2.2 Users’ Browsing Behavior
Most prior work assumes that Tor clients browse sequentially and use a single tab at a time. This is not representative of real-world behavior, as clients often open multiple tabs. We do not further examine multi-tab browsing in this paper.

### 2.2.3 Traffic Parsing and Background Traffic
We assume the attacker can collect all traffic generated by a site and distinguish it from other traffic. This assumption is true when the attacker performs the attack at the guard node. Recent work has developed techniques to discriminate Tor traffic from multiplexed TLS traffic, so this assumption is already handled.

## 3 Attacker Goals
We identify elements of WF attacks that may be improved to better suit realistic adversaries.

### 3.1 Generalizability
Previous research assumes a targeted attack, where the attacker trains the classifier under the same conditions as the victim. For untargeted attacks, the classifier must remain effective across diverse data sets. Juarez et al. [13] show that changing TBB versions significantly reduces attack accuracy.

### 3.2 Bootstrap Time
To perform WF attacks, the attacker needs to train the classifier, which includes crawling a training data set and training the classifier. The traffic traces used for training are dynamic and change over time, requiring frequent re-training. Prior work assumes the training and testing data are from the same distribution, but in reality, the gap between training and testing phases can cause data mismatch issues. Wang and Goldberg [34] found that k-NN trained on as few as 31 instances per site is nearly as effective as using 85 instances, but still requires thousands of traces.