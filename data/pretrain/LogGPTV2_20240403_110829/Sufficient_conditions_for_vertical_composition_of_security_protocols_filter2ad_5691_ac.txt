static analysis. As a rule of thumb, very large, coarse over-
approximations make computations easier, but also increase
the risk of false positives, i.e., protocols that do not satisfy
our suﬃcient conditions even though they are composable.
In our case, a coarse over-approximation can lead to false
positives, since we will later assume that the intruder gets
all payloads MC,D whenever the receiver D is dishonest or
secrecy of the payload is not a goal (and C is honest). Sup-
pose we had in the example protocol instead of the hash
h(N ) directly the nonce N ; this would mean that the in-
truder knows [N,·]2 for every N ∈ TΣ, i.e., then with MC,i
he initially knows every term, trivially giving us false posi-
tives. In such a case, we would need to resort to a full-ﬂedged
static-analysis approach—in this example, intuitively, using
the fact that the intruder learns only nonces N that he him-
self sent earlier. As the entire approach is already quite
complex, we chose not to consider this complication in this
paper.
Deﬁnition 8. (Static Vertical Composition P P2
1 ) Let P1
be a channel protocol for κ(A, B) and P2 an application
protocol for the channel κ(C, D), and let MC,D be the set
of ground messages that C can transmit over the channel
κ(C, D) in any run of the protocol P2. The static verti-
cal composition P P2
is the protocol that results from P1 by
replacing payload(A, B) when it is ﬁrst sent by A with a
non-deterministically chosen element of MC,D, and all the
following occurrences of payload(A, B) must be the same el-
ement of MC,D.
1
An example is given in Figure 1, where we write mA,B to
denote an arbitrary message, non-deterministically chosen,
from the set MA,B.
The protocol P P2
represents a certain “concretization” of
P1 with “random” payload messages from P2.6 This notion
is valuable because it indeed allows us to divide the compo-
sition problem into two aspects, a logical and a static one:
1
Deﬁnition 9. (Static Vertical Composability) Given an ab-
stract channel protocol P1 and an application protocol P2 as
in the deﬁnitions above, we say that P1 and P2 are statically
vertically composable if the following implication holds: if P1
(cid:107) P2 is secure.
and P2 are secure in isolation, then also P P2
These notions are used in [27] to show the following compo-
sitionality result:
1
Theorem 1
([27]). If channel protocol P1 and applica-
tion protocol P2 are secure protocols in isolation and they
6[27] instead uses the notion P ∗
1 , which, however, may be
confusing here as it does not denote the protocol from which
the payloads come.
are both statically vertically composable and composable in
parallel, then P2[P1] is secure.
In this paper, we call this result the logical aspect of the
problem, because it proves that the deﬁnitions of channels
as assumption and as goals have “compatible” behavior, and
what remains to show is static vertical composability.
It
turns out that the static aspect is in fact quite intricate and
solving this open problem is the main contribution of this
paper: the rest of this paper will concentrate on giving con-
ditions that can be easily checked syntactically and proving
that they are suﬃcient for a pair of protocols to be statically
vertically composable, i.e., satisfying Deﬁnition 9.
As a result, we can check in isolation, with any proto-
col veriﬁcation method, a channel protocol P1 with abstract
payload as well as an application protocol P2 that uses the
respective channel type. If this channel type is part of the
ones deﬁned in [27] and the suﬃcient conditions of this paper
are satisﬁed for P1 and P2, then we can combine Theorem 1
with our Theorem 2 (given below) to infer that P2[P1] is
secure.
3.3 The Static Aspect of Vertical Protocol
Composition
We are now ready for our main result, namely that the
seven conditions that we will deﬁne in Section 4 are suﬃcient
for static vertical composability, i.e., if P1 and P2 are secure,
(cid:107) P2. Or, in other words, that we can reduce
then so is P P2
(cid:107) P2 to an attack against one of the
an attack against P P2
1
component protocols.
1
Theorem 2. Consider two protocols P1 and P2 that sat-
isfy all the seven conditions deﬁned in Section 4. If there is
(cid:107) P2, then there is an attack against
an attack against P P2
P1 or against P2.
1
Since we lack space to give the proof of this theorem (the
proof is given in [28] and spans several pages), let us at least
give a proof sketch, and then illustrate the proof by means of
a detailed example, which also provides further motivation
for the conditions themselves, which we will formalize in the
next section.
Proof Sketch. In the proof, we employ the constraint
reduction technique that we refer to as the lazy intruder
(see, e.g., [6, 9, 25, 29]). While this technique is originally
a veriﬁcation technique (for a bounded number of sessions),
we use it here for a proof argument for our compositionality
result (for an unbounded number of sessions). The key idea
of the lazy intruder is to model “symbolic executions” where
variables in the messages that honest agents receive from
the insecure network (i.e., from the intruder) are left un-
instantiated. We use intruder constraints of the form
IK (cid:96) t
where t is a (symbolic) term that an agent is able to receive
and the set IK of messages is the current intruder knowl-
edge. We use the fact that we can check satisﬁability of such
constraints using the lazy intruder calculus, and that we can
reduce insecurity to satisﬁability of lazy intruder constraints.
We thus assume we are given lazy intruder constraints for
an attack against the composition P P2
for any channel pro-
tocol P1 and application protocol P2 that satisfy our seven
conditions. We then show that over all reductions with the
1
440lazy intruder calculus, the seven conditions and some further
invariants are preserved, in particular, that the attack never
requires a confusion between P1 and P2 messages. This is
because the lazy intruder technique never instantiates vari-
ables whose concrete value is irrelevant for the attack (this
is why we call it lazy in the ﬁrst place); these still admit “ill-
typed” instantiations (confusing P1 and P2), but they always
also admit well-typed instantiations. As a consequence, we
can show that there exists an attack against P1 in isolation
or against P2 in isolation.
3.4 Illustration
We illustrate the proof at hand of a concrete example.
Let us turn again to the example protocols P1, P2, P P2
and P2[P1] from Figure 1, and let us now consider a slight
variant of the protocol P1 in which we deliberately insert
an authentication vulnerability. This allows us to illustrate
the diﬀerent steps in the construction of the proof—that an
attack against P2[P1] can be reduced to an attack against
either P1 or P2. Moreover, it also helps to illustrate and
motivate the conditions that we introduce below.
1
Note that the message in P1 mentions both the sender and
the intended receiver as part of the signature. Let us now
consider a variant without these two names:
P1 :
A
A
→ B :
•→• B :
{{[p, payload(A, B)]2}privk(pk(A))}pubk(pk(B))
payload(A, B)
that also gives accordingly the following variants of the com-
positions P P2
and P2[P1]:
1
P P2
1
:
A
A
P2[P1] :
D
C
C
→ B :
•→• B : mA,B
{{[p, mA,B ]2}privk(pk(A))}pubk(pk(B))
→ C :
→ D :
•→• D : M
[N , C , D]3
{{[p, [h(N ), M ]2 ]2}privk(pk(C ))}pubk(pk(D))
As we already remarked above, it turns out that, for our
proof, a symbolic representation of traces is very useful to
make the arguments about intruder actions concise. This
representation is often used in model checking, sometimes
brieﬂy referred to as the lazy intruder technique, but our
results are of course independent of any such technology. A
symbolic trace of a protocol consists of a sequence of send
and receive actions of the honest agents, in which we have
variables for each subterm of a received message where the
agent is willing to accept an arbitrary value; this variable
can then occur in subsequent sending actions. Although we
do not note it explicitly here, every sent message is directly
added to the intruder knowledge, and every received mes-
sage must be constructed by the intruder. For instance, the
following is one symbolic trace for the protocol P2[P1]:
d sends m1 = [n, c, d]3
c receives m(cid:48)
2 = {{[p, [h(N ), m]2]2}privk(pk(c))}pubk(pk(D))
c sends m(cid:48)
d receives m2 = {{[p, [h(n), M ]2]2}privk(pk(c))}pubk(pk(d))
1 = [N, c, D]3
where the constants n and m are the concrete nonces that
d and c created for N and M , respectively. When c receives
m(cid:48)
1, every value for nonce N and for the claimed sender D is
possible, and the answer m(cid:48)
2 that c sends depends on these
two variables. In contrast, when d receives m2, it must be
encrypted for d and contain the nonce n sent earlier. A
requirement for such a trace to exist is that the intruder can
indeed construct all the messages that are received, using
what he learned. For this symbolic trace, we thus have the
constraints
IK 0 ∪ {m1} (cid:96) m(cid:48)
1 ∧ IK 0 ∪ {m1, m(cid:48)
2} (cid:96) m2 ,
Here, IK 0 is the set of initially known messages: it includes
all public constants, i.e., all agent names, public keys, the
private keys of the dishonest agents (like privk(pk(i))), as
well as the payloads for dishonest receivers, i.e., MC,D =
{[h(N ), M ]2 | N ∈ TΣ, M ∈ MC,D} for honest C and dis-
honest D and where MC,D is the subset of nonces that C
freshly creates for D. Thus, from IK 0 the intruder can de-
rive h(t) for every term t, and he can derive all nonces that
honest agents will create for him, but this does not include
n and m since these are created for honest agents. (How-
ever n is derivable from the ﬁrst message m1.) Note that the
symbolic representation with the constraints corresponds ex-
actly to the set of ground traces that are possible.
The core of the lazy intruder is a constraint reduction
technique to ﬁnd (a ﬁnite representation of) all solutions of
the constraints. In this case, we have, for instance, the solu-
tion D = d, N = n, M = m that corresponds to one normal
execution of the protocol between two honest agents c and d
with the intruder as a “network node” simply forwarding all
messages. We can, however, also express that the symbolic
trace violates authentication, namely if c and d at the end
do not agree on the concrete values of the (relevant) proto-
col variables, namely whenever M (cid:54)= m or D (cid:54)= d (the nonce
N itself is not part of any authentication goals). There is
indeed such a solution: D = i, M = m, and N = n. This
means that the intruder started a session with c, playing un-
der his real name in role D and using the nonce n from the
other session with the honest d. The intruder can then de-
crypt the message m(cid:48)
2 (since it is encrypted with his public
key) and re-encrypt it with the public key of d, completing
the attack.
The logical part of the composition problem (i.e., what is
proved in [27]) shows that such an attack on P2[P1] can be
(cid:107) P2. For our example, the
transformed into one on P P2
transformed symbolic attack would look like this (annotat-
ing for each step which of the protocols it belongs to):
1
P2 : d sends m1 = [n, c, d]3
P2 : c receives m(cid:48)
P2 : c sends on a secure channel c •→• D :
[h(N ), m]2
: c sends m(cid:48)
P P2
: d receives m2 = {{[p, X]2}privk(pk(c))}pubk(pk(d))
P P2
P2 : D receives on a secure channel c •→• D :
1 = [N, c, D]3
2 = {{[p, [h(N ), m]2]2}privk(pk(c))}pubk(pk(D))
[h(N ), m]2
1
1
Here, the abstract channel of P2 runs in parallel with a cor-
responding step from P P2
1 with exactly the same payload
message (which is possible since in P P2
the agent c non-
deterministically picks a message from the set of all payload
messages Mc,D). Also note that d receiving m2 in P P2
1 does
not require a particular form of payload anymore (in con-
trast to the message m2 in the P2[P1] trace).
1
The intruder deduction constraints for the received mes-
sages are again the same (modulo the said change of m2).
The requirement for the attack is also similar: D (cid:54)= d or
441X (cid:54)= [h(N ), m]2, and we have again the attack for the solu-
tion D = i (and X = [h(N ), m]2 with N arbitrary).
(cid:107) P2
attack can indeed be reduced to an attack against P1 in
isolation or against P2 in isolation.
Now the goal of this paper to show that such a P P2
1
To that end, we look at how the lazy intruder technique
would check the satisﬁability of the constraints
IK 0 ∪ {m1} (cid:96) m(cid:48)
(D (cid:54)= i ∨ M (cid:54)= m) .
1 ∧ IK 0 ∪ {m1, m(cid:48)
2} (cid:96) m2 ∧
The point for using the lazy intruder here is that the tech-
nique is complete, i.e., if the constraints have a solution,
then the reduction rules ﬁnd a solution, and that the lazi-
ness precludes making any instantiations of variables that
are not required for solving the constraints.
One reduction rule is uniﬁcation: for constraint IK (cid:96) t1,
if there is a term t2 ∈ IK that is uniﬁable with t1 under
the most general uniﬁer σ, then we can solve this constraint
and apply σ to all remaining constraints. However at this
point we are lazy: we do not apply the uniﬁcation rule if
t1 or t2 is a variable; we do not make a choice when any
value t1 is ﬁne, and do not analyze any value t2 that the
intruder himself created earlier. One of the conditions be-