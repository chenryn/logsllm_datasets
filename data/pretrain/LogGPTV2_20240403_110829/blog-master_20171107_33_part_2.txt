TIMES=300  
export PGHOST=$PGDATA  
export PGPORT=1999  
export PGUSER=postgres  
export PGPASSWORD=postgres  
export PGDATABASE=postgres  
pgbench -M prepared -n -r -f ./test1.sql -P 5 -c $CONNECTS -j $CONNECTS -T $TIMES  
```  
### 7、测试  
1、高吞吐写入测试，100万个传感器，每批1000条。  
```  
transaction type: ./test.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 28  
number of threads: 28  
duration: 300 s  
number of transactions actually processed: 540118  
latency average = 15.552 ms  
latency stddev = 6.859 ms  
tps = 1800.096277 (including connections establishing)  
tps = 1800.211896 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set sid random(1,1000000)  
        15.550  select ins_batch(:sid, 1000);  
```  
2、高吞吐消费测试，100万个传感器，每批1000条。  
```  
transaction type: ./test1.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 28  
number of threads: 28  
duration: 300 s  
number of transactions actually processed: 437481  
latency average = 19.200 ms  
latency stddev = 8.386 ms  
tps = 1458.154052 (including connections establishing)  
tps = 1458.224625 (excluding connections establishing)  
script statistics:  
 - statement latencies in milliseconds:  
         0.002  \set sid random(1,1000000)  
        19.201  select consume_batch(:sid, 1000);  
```  
3、压测过程中，收到一些函数式处理的异步消息：  
```  
LISTEN  
Asynchronous notification "channel_1" with payload "reason:xxx::::{"sid":462454,"info":{"k": "abc", "v": 9999.96403697878},"crt_time":"2017-11-16T19:36:56.164613"}" received from server process with PID 31075.  
postgres=# listen channel_1;  
LISTEN  
Asynchronous notification "channel_1" with payload "reason:xxx::::{"sid":462454,"info":{"k": "abc", "v": 9999.96403697878},"crt_time":"2017-11-16T19:36:56.164613"}" received from server process with PID 31083.  
postgres=# listen channel_1;  
LISTEN  
postgres=# listen channel_1;  
LISTEN  
Asynchronous notification "channel_1" with payload "reason:xxx::::{"sid":252209,"info":{"k": "abc", "v": 9999.39551576972},"crt_time":"2017-11-16T19:36:53.424862"}" received from server process with PID 31081.  
```  
#### 一、 TPS  
同时压测写入和消费，使用JSONB作为内容输入，消费时加上处理函数，吞吐如下：  
##### 1、数据写入速度： 180万 行/s。  
##### 2、数据消费速度： 145.8万 行/s。  
#### 二、 平均响应时间  
同时压测写入和消费，使用JSONB作为内容输入，消费时加上处理函数，吞吐如下：  
##### 1、数据写入速度：  15.5 毫秒。  
##### 2、数据消费速度： 19 毫秒。  
加入函数式计算后，消费速度会有所下降，在权重上，可以分配多一些资源给消费。不过即便如此，消费速度也有145.9万行每秒。  
函数计算可利用的数据库编程能力：  
```
plpython
pljava
plv8
plpgsql
C
plr, plperl, pltcl, .....
```
## 参考  
[《PostgreSQL、Greenplum 应用案例宝典《如来神掌》 - 目录》](../201706/20170601_02.md)  
[《数据库选型之 - 大象十八摸 - 致 架构师、开发者》](../201702/20170209_01.md)  
[《PostgreSQL 使用 pgbench 测试 sysbench 相关case》](../201610/20161031_02.md)  
[《数据库界的华山论剑 tpc.org》](../201701/20170125_01.md)  
https://www.postgresql.org/docs/10/static/pgbench.html  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")