title:SHIELD: A Framework for Efficient and Secure Machine Learning
Classification in Constrained Environments
author:Jan Henrik Ziegeldorf and
Jan Metzke and
Klaus Wehrle
SHIELD: A Framework for Eicient and Secure Machine
Learning Classification in Constrained Environments
Jan Henrik Ziegeldorf, Jan Metzke, Klaus Wehrle
Communication and Distributed Systems (COMSYS), RWTH Aachen University, Germany
{ziegeldorf,metzke,wehrle}@comsys.rwth-aachen.de
ABSTRACT
Machine learning classication has enabled many innovative ser-
vices, e.g., in medicine, biometrics, and nance. Current practices
of sharing sensitive input data or classication models, however,
causes privacy concerns among the users and business risk among
the providers. In this work, we resolve the conict between privacy
and business interests using Secure Two-Party Computation. Con-
cretely, we propose SHIELD, a framework for ecient, and accurate
machine learning classication with security in the semi-honest
model. Building on SHIELD, we realize several widely used classi-
ers and real-world use cases that compare favorably against related
work. Departing denitively from prior works, all of SHIELD’s pro-
tocols are designed from the ground up to enable secure outsourcing
to untrusted computation clouds enabling even constrained devices
to handle our most complex use cases in (milli)seconds.
ACM Reference Format:
Jan Henrik Ziegeldorf, Jan Metzke, Klaus Wehrle. 2018. SHIELD: A Frame-
work for Ecient and Secure Machine Learning Classication in Con-
strained Environments. In 2018 Annual Computer Security Applications Con-
ference (ACSAC ’18), December 3–7, 2018, San Juan, PR, USA. ACM, New
York, NY, USA, 16 pages. https://doi.org/10.1145/3274694.3274716
1 INTRODUCTION
With “data [...] the oil of the 21st century economy” [53], a growing
number of services employ machine learning classication to rene
it: Speech and handwriting recognition, biometric identication, or
medical diagnosis are only a few examples. These applications are
often deployed as-a-service in the cloud with access conveniently
integrated into users’ devices and applications. Users are required to
send their data to the service providers who perform classications
using proprietary models, neglecting that users’ inputs are often
highly sensitive and must be protected. Speech recognition, e.g., not
only reveals the user’s searches to the service provider but allows
creating voice proles to impersonate users [59, 84].
A simple solution would be to perform classications locally on
the user’s device (if it is has enough resources). Machine learning
models are, however, expensive to train and their quality creates
competitive edge. Service providers hence treat and protect them
as their intellectual property. Data protection legislation presents
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prot or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specic permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6569-7/18/12...$15.00
https://doi.org/10.1145/3274694.3274716
355
a second reason why handing out models is not a viable solution.
E.g., models for a genetic disease testing service may be trained
over condential patient records and residual risk remains that
the learned models still leak information about individual patients
[31] – sharing such models could be unlawful, e.g., according to the
U.S. Health Insurance Portability and Accountability Act of 1996.
Hence, classication services–especially those involving highly
sensitive data–face a conict of business interests, regulatory issues,
and privacy concerns. A promising solution is Secure Two-Party
Computation (STC), which allows a user and service provider to
compute classications under strong security and privacy guar-
antees such that neither party is able to learn the other party’s
input [85]. First yet very specialized eorts in this direction have
been made for Naive Bayes [75], Support Vector Machines (SVMs)
[81], linear classiers [39], face recognition [34, 70] and logistic
regression [19]. Bost et al. [20] presented a rst general framework
for secure classication supporting hyperplane classiers, Naive
Bayes, and decision trees. Due to the success of deep learning, se-
cure evaluation of Articial Neural Networks (ANNs) has been the
focus of related works [29, 52, 66, 68], while others [4, 36, 86] tackle
secure pattern recognition with Hidden Markov Models (HMMs).
From these works, we identify three dicult challenges when de-
signing STC protocols for classication. i) Eciency: STC involves
large numbers of cryptographic and interactive operations that may
cause infeasible overheads in real-world applications. ii) Accuracy:
many classication algorithms entail computations over very small
probabilities that cause numerical instabilities [64]–the fact that all
established STC approaches build on cryptographic primitives de-
ned over discrete algebraic structures renders numerical accuracy
even more challenging. iii) Mobility: traditional STC approaches
assume high-powered hosts connected over stable, high-bandwidth,
low-latency networks–mobile scenarios, however, typically involve
resource-constrained devices and networks.
The main thrust of previous works has been to optimize e-
ciency while maintaining accuracy–none of them considers the out-
lined challenges posed by mobile usage scenarios such as resource
constraints, network dynamics, and connectivity. In this paper, we
introduce the SHIELD framework that allows two mutually dis-
trustful parties to securely, eciently, and accurately compute or
outsource classications using a range of state-of-the-art classiers.
SHIELD thereby enables Secure Classication as a Service, conceptu-
ally complementing existing Machine Learning as a Service cloud
oers [6, 38, 54] that typically violate both the user’s and the service
provider’s privacy. The following are our main contributions:
Framework for Secure Classication. We analyze core build-
ing blocks of classication algorithms and propose ecient hybrid
STC protocols. Our building blocks provide tunable accuracy and
are exibly composable which we demonstrate by realizing a range
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Ziegeldorf et al.
of established classiers with distinctly dierent characteristics, i.e.,
linear classiers such as SVMs, Bayesian classiers with discrete
and continuous features, ANNs with arbitrary activation functions,
and the Viterbi algorithm on dierent HMM architectures.
Performance Evaluation. We evaluate SHIELD on dierent
datasets and real-world use cases, e.g., bioinformatics sequence
alignments and indoor localization. Our evaluation shows that
SHIELD accurately handles large classication problems and, de-
spite being designed for wide applicability, provides competitive
performance even when compared to specialized approaches.
Secure Outsourcing. Departing signicantly from related work,
all of SHIELD’s protocols are designed from the ground up to allow
securely outsourcing protocol execution to untrusted computation
clouds to cope with common resource limitations and challenges
in mobile scenarios. Our evaluation shows that overheads for out-
sourcing range only in the order of milliseconds of processing and
kilobytes of communication, rendering SHIELD applicable even for
very constrained and challenged deployment scenarios.
2 PROBLEM STATEMENT
2.1 Scenario and Requirements
We consider two parties, a service provider S who holds a trained
classication model M and a user U who holds a feature vector Æx.
Together, U and S want to compute F(M, Æx), i.e., classify Æx using the
model M. Due to privacy concerns, business interests, regulatory or
legal requirements, neither party is willing to share her inputs with
the other or any third party. In this paper, we thus show how U and
S can compute F(M, Æx) using STC without learning each other’s
inputs. This problem scenario is ubiquitous in dierent application
areas of classication and pattern recognition, e.g., genetic disease
testing [37], speech recognition [59, 72], biometric authentication
[34, 58, 70], and localization [87]. Surveying these and further re-
lated works, we distill core requirements and design goals for secure
classication and pattern recognition in the following.
Eciency. Eciency is generally of high importance in the
surveyed applications. In user-centric applications, such as speech
recognition [64] or localization [87], low latency, i.e., the time it
takes to classify a single data record, is paramount. Data mining ap-
plications [29], in contrast, require high throughput to classify large
batches of data records eciently. While optimizing for latency
automatically increases throughput the opposite is not necessar-
ily true, e.g., when using Single-Instruction-Multiple-Data opera-
tions [29]. To ensure the wide applicability of secure classication,
we thus priorize latency over throughput where necessary.
Accuracy. Secure classication protocols should ideally com-
pute results identical to their insecure counterparts. In practice,
certain degrees of inaccuracy are tolerable, e.g., in speech recogni-
tion where one is only interested in the best matching word but
not the exact probabilities [58, 64]. Since the required numerical
accuracy depends on the actual use case, secure classication pro-
tocols should allow trading accuracy against performance, ideally
without the need to modify classication models or feature spaces.
Mobile Users and Constrained Environments. The increas-
ing number of mobile users, e.g., using speech-to-text services, poses
additional challenges to secure classication. Due to limited pro-
cessing, communication, and energy resources, mobile users may
not be able to execute STC protocols themselves. One of the most
promising solutions to cater to such constrained deployment and
operation scenarios is the outsourcing of costly computations from
constrained user devices to more capable (cloud) peers. Without
precluding other approaches, we hence pay special attention to the
support for outsourcing in our analysis of related work as well as
in the design of our SHIELD framework.
Security. We dene the capabilities of the user, service provider,
and potential cloud peers to attack the computation by the semi-
honest model [51]. Shortly put, a semi-honest attacker correctly
follows the protocol but may try to infer additional information
from the transcript. Semi-honest behavior is not only the standard
choice in the related literature [20, 28, 66]. It is also a widely used
security model for outsourcing, arguing that cloud computation
providers must preserve their reputation and thus have a strong
interest in executing outsourced computations correctly [2, 44, 60].
Compared to security against stronger malicious adversaries, the
semi-honest model allows for much more ecient protocols while
still protecting against insiders and outsiders.
2.2 Analysis of Related Work
We analyze to which extent prior works address the stated require-
ments. We rst present related work on secure classication and
pattern recognition then briey discuss orthogonal works. A quan-
titative evaluation and comparison against related work is provided
separately for each classier in Sections 5.1, 6.1, 7.1, and 8.1.
Secure Classication. Vaidya and Clifton [75] present a secure
Naive Bayes classier based on Homomorphic Encryption (HE) but
evaluate neither performance nor accuracy. Yu et al. [81] present
HE-based protocols for SVMs which is restricted to binary features
and not evaluated. Graepel et al. [39] present an outsourcable secure
Fisher’s linear discriminant classier based on Somewhat Homo-
morphic Encryption (SWHE). Dierent to our problem scenario,
their approach requires that the user holds all inputs and most
overheads are due to encryption on the user’s side and cannot be
outsourced. Bost et al. [20] present secure and ecient hyperplane
classiers, discrete Naive Bayes, and decision tree based on a com-
bination of dierent HE schemes. Chandran et al. [24] improve
upon Bost et al. using a combination of Garbled Circuits (GCs)
and Additive Secret Sharings (ASSs). Our secure hyperplane and
Naive Bayes classiers are improvements on these works w.r.t.
performance (up to two orders of magnitude faster), functional-
ity (e.g., continuous feature spaces), and outsourcing. A particular
focus among related works has been on secure classication us-
ing ANNs: Dowlin et al. [29] present a rst Fully Homomorphic
Encryption (FHE)-based approach that is outsourceable and e-
cient for batched classications. Following, Chandran et al. [24],
Liu et al. [52], and Riazi et al. [66] propose hybrid protocols (com-
bining GCs, Goldreich-Micali-Wigderson (GMW), and ASS) that
greatly reduce computation and communication overheads also
for single classications and conceptually lend themselves to out-
sourcing. Rouhani et al. [68] present a fully GC-based protocol and
an outsourcing scheme based on Boolean secret sharing. Albeit
being designed for wide applicability, SHIELD shows competitive
performance on ANNs compared to these specialized approaches.
Using an intricate combination of FHE and GCs, Juvekar et al.’s
356
SHIELD: Eicient and Secure Machine Learning Classification
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
approach [43] achieves another reduction of classication latency
by one order of magnitude but cannot be outsourced. Finally, Mo-
hassel and Zhang [55] provide GC and ASS-based protocols for the
secure learning of ANNs.
Secure Pattern Recognition. Smaragdis et al. [72] followed
by Pathak et al. [57, 59] rst considered secure HMM computa-
tions in the context of speech recognition. Their approaches are
based on HE which causes prohibitive overheads and numerical
inaccuracies for all but very small models and requires plaintext
knowledge for certain operations which prevents outsourcing. To
tackle the challenge of numerical accuracy in secure computation
over non-integers, Aliasgari et al. [5], Kamm et al. [45], and Demm-
ler et al. [27] propose secure oating-point primitives. While these