# SHIELD: A Framework for Efficient and Secure Machine Learning Classification in Constrained Environments

**Authors:**
- Jan Henrik Ziegeldorf
- Jan Metzke
- Klaus Wehrle

**Affiliation:**
Communication and Distributed Systems (COMSYS), RWTH Aachen University, Germany
- Email: {ziegeldorf, metzke, wehrle}@comsys.rwth-aachen.de

**Abstract:**
Machine learning classification has enabled numerous innovative services in fields such as medicine, biometrics, and finance. However, the current practice of sharing sensitive input data or classification models raises privacy concerns among users and business risks for providers. In this work, we address these conflicts using Secure Two-Party Computation (STC). Specifically, we introduce SHIELD, a framework for efficient and accurate machine learning classification with security guarantees in the semi-honest model. Leveraging SHIELD, we implement several widely used classifiers and real-world use cases, demonstrating superior performance compared to related work. Unlike prior approaches, all of SHIELD’s protocols are designed to enable secure outsourcing to untrusted computation clouds, allowing even resource-constrained devices to handle complex use cases in (milli)seconds.

**ACM Reference Format:**
Jan Henrik Ziegeldorf, Jan Metzke, Klaus Wehrle. 2018. SHIELD: A Framework for Efficient and Secure Machine Learning Classification in Constrained Environments. In 2018 Annual Computer Security Applications Conference (ACSAC '18), December 3–7, 2018, San Juan, PR, USA. ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3274694.3274716

## 1. Introduction
With "data [being] the oil of the 21st century economy" [53], an increasing number of services employ machine learning classification to refine it. Examples include speech and handwriting recognition, biometric identification, and medical diagnosis. These applications are often deployed as cloud-based services, integrated into users' devices and applications. Users must send their data to service providers who perform classifications using proprietary models, often neglecting the sensitivity of the input data. For instance, speech recognition not only reveals user searches but also allows the creation of voice profiles that can be used to impersonate users [59, 84].

A straightforward solution would be to perform classifications locally on the user's device, provided it has sufficient resources. However, machine learning models are expensive to train and represent a competitive advantage, leading service providers to protect them as intellectual property. Additionally, data protection legislation presents another reason why sharing models is not viable. For example, models for genetic disease testing may be trained on confidential patient records, and there is a residual risk that the learned models could still leak information about individual patients [31]. Sharing such models could violate laws like the U.S. Health Insurance Portability and Accountability Act of 1996.

Thus, classification services, especially those involving highly sensitive data, face a conflict between business interests, regulatory issues, and privacy concerns. Secure Two-Party Computation (STC) offers a promising solution by allowing a user and service provider to compute classifications under strong security and privacy guarantees, ensuring neither party learns the other's input [85]. Initial specialized efforts have been made for Naive Bayes [75], Support Vector Machines (SVMs) [81], linear classifiers [39], face recognition [34, 70], and logistic regression [19]. Bost et al. [20] introduced a general framework for secure classification supporting hyperplane classifiers, Naive Bayes, and decision trees. Due to the success of deep learning, secure evaluation of Artificial Neural Networks (ANNs) has been a focus in related works [29, 52, 66, 68], while others [4, 36, 86] tackle secure pattern recognition with Hidden Markov Models (HMMs).

From these works, we identify three key challenges in designing STC protocols for classification:
1. **Efficiency**: STC involves a large number of cryptographic and interactive operations, which can cause infeasible overheads in real-world applications.
2. **Accuracy**: Many classification algorithms involve computations over very small probabilities, leading to numerical instabilities [64]. The fact that established STC approaches build on cryptographic primitives defined over discrete algebraic structures further complicates numerical accuracy.
3. **Mobility**: Traditional STC approaches assume high-powered hosts connected over stable, high-bandwidth, low-latency networks. Mobile scenarios, however, typically involve resource-constrained devices and networks.

Previous works have focused on optimizing efficiency while maintaining accuracy, but none have addressed the challenges posed by mobile usage scenarios, such as resource constraints, network dynamics, and connectivity. In this paper, we introduce the SHIELD framework, which allows two mutually distrustful parties to securely, efficiently, and accurately compute or outsource classifications using a range of state-of-the-art classifiers. SHIELD enables Secure Classification as a Service, complementing existing Machine Learning as a Service (MLaaS) offerings [6, 38, 54] that often violate both the user's and the service provider's privacy. Our main contributions are:

- **Framework for Secure Classification**: We analyze core building blocks of classification algorithms and propose efficient hybrid STC protocols. Our building blocks provide tunable accuracy and are flexibly composable, as demonstrated by realizing a range of established classifiers with distinct characteristics, including linear classifiers (e.g., SVMs), Bayesian classifiers with discrete and continuous features, ANNs with arbitrary activation functions, and the Viterbi algorithm on different HMM architectures.
- **Performance Evaluation**: We evaluate SHIELD on various datasets and real-world use cases, such as bioinformatics sequence alignments and indoor localization. Our evaluation shows that SHIELD accurately handles large classification problems and, despite being designed for wide applicability, provides competitive performance even when compared to specialized approaches.
- **Secure Outsourcing**: Unlike related work, all of SHIELD’s protocols are designed from the ground up to allow secure outsourcing to untrusted computation clouds, addressing common resource limitations and challenges in mobile scenarios. Our evaluation shows that the overheads for outsourcing are minimal, ranging from milliseconds of processing to kilobytes of communication, making SHIELD applicable even for very constrained and challenged deployment scenarios.

## 2. Problem Statement

### 2.1 Scenario and Requirements
We consider two parties: a service provider \( S \) who holds a trained classification model \( M \) and a user \( U \) who holds a feature vector \( \mathbf{x} \). Together, \( U \) and \( S \) want to compute \( F(M, \mathbf{x}) \), i.e., classify \( \mathbf{x} \) using the model \( M \). Due to privacy concerns, business interests, and regulatory or legal requirements, neither party is willing to share their inputs with the other or any third party. In this paper, we show how \( U \) and \( S \) can compute \( F(M, \mathbf{x}) \) using STC without learning each other’s inputs. This problem scenario is common in various application areas of classification and pattern recognition, such as genetic disease testing [37], speech recognition [59, 72], biometric authentication [34, 58, 70], and localization [87]. Surveying these and other related works, we distill the following core requirements and design goals for secure classification and pattern recognition:

- **Efficiency**: Efficiency is crucial in the surveyed applications. In user-centric applications like speech recognition [64] or localization [87], low latency (the time to classify a single data record) is paramount. Data mining applications [29], on the other hand, require high throughput to classify large batches of data records efficiently. While optimizing for latency automatically increases throughput, the opposite is not necessarily true, e.g., when using Single-Instruction-Multiple-Data (SIMD) operations [29]. To ensure wide applicability, we prioritize latency over throughput where necessary.
- **Accuracy**: Secure classification protocols should ideally produce results identical to their insecure counterparts. In practice, some degree of inaccuracy is tolerable, such as in speech recognition where the best matching word is of interest rather than exact probabilities [58, 64]. Since the required numerical accuracy depends on the use case, secure classification protocols should allow trading accuracy for performance, ideally without modifying the classification models or feature spaces.
- **Mobile Users and Constrained Environments**: The growing number of mobile users, such as those using speech-to-text services, poses additional challenges for secure classification. Limited processing, communication, and energy resources mean that mobile users may not be able to execute STC protocols themselves. One promising solution is to outsource costly computations from constrained user devices to more capable (cloud) peers. We pay special attention to supporting outsourcing in our analysis of related work and in the design of the SHIELD framework.
- **Security**: We define the capabilities of the user, service provider, and potential cloud peers to attack the computation using the semi-honest model [51]. A semi-honest attacker follows the protocol correctly but may try to infer additional information from the transcript. This model is standard in the literature [20, 28, 66] and is widely used for outsourcing, as cloud providers must maintain their reputation and thus have a strong incentive to execute outsourced computations correctly [2, 44, 60]. Compared to stronger malicious adversaries, the semi-honest model allows for more efficient protocols while still protecting against insiders and outsiders.

### 2.2 Analysis of Related Work
We analyze the extent to which prior works address the stated requirements. We first present related work on secure classification and pattern recognition, then briefly discuss orthogonal works. A quantitative evaluation and comparison against related work are provided separately for each classifier in Sections 5.1, 6.1, 7.1, and 8.1.

- **Secure Classification**: Vaidya and Clifton [75] present a secure Naive Bayes classifier based on Homomorphic Encryption (HE) but do not evaluate performance or accuracy. Yu et al. [81] present HE-based protocols for SVMs, restricted to binary features and not evaluated. Graepel et al. [39] present an outsourcable secure Fisher’s linear discriminant classifier based on Somewhat Homomorphic Encryption (SWHE). Their approach requires the user to hold all inputs, and most overheads are due to encryption on the user’s side, which cannot be outsourced. Bost et al. [20] present secure and efficient hyperplane classifiers, discrete Naive Bayes, and decision trees using a combination of different HE schemes. Chandran et al. [24] improve upon Bost et al. using a combination of Garbled Circuits (GCs) and Additive Secret Sharings (ASSs). Our secure hyperplane and Naive Bayes classifiers offer improvements in performance (up to two orders of magnitude faster), functionality (e.g., continuous feature spaces), and outsourcing. A particular focus among related works has been on secure classification using ANNs: Dowlin et al. [29] present a Fully Homomorphic Encryption (FHE)-based approach that is outsourceable and efficient for batched classifications. Following, Chandran et al. [24], Liu et al. [52], and Riazi et al. [66] propose hybrid protocols (combining GCs, Goldreich-Micali-Wigderson (GMW), and ASS) that greatly reduce computation and communication overheads, even for single classifications, and conceptually lend themselves to outsourcing. Rouhani et al. [68] present a fully GC-based protocol and an outsourcing scheme based on Boolean secret sharing. Although designed for wide applicability, SHIELD shows competitive performance on ANNs compared to these specialized approaches. Juvekar et al. [43] achieve another reduction in classification latency by one order of magnitude using a combination of FHE and GCs, but their approach cannot be outsourced. Finally, Mohassel and Zhang [55] provide GC and ASS-based protocols for the secure learning of ANNs.
- **Secure Pattern Recognition**: Smaragdis et al. [72], followed by Pathak et al. [57, 59], first considered secure HMM computations in the context of speech recognition. Their approaches are based on HE, which causes prohibitive overheads and numerical inaccuracies for all but very small models and requires plaintext knowledge for certain operations, preventing outsourcing. To address the challenge of numerical accuracy in secure computation over non-integers, Aliasgari et al. [5], Kamm et al. [45], and Demmler et al. [27] propose secure floating-point primitives. While these