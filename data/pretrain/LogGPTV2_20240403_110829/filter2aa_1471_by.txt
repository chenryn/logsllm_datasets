The VID driver also includes the virtualization stack memory manager. In
the previous section, we described the hypervisor memory manager, which
manages the physical and virtual memory of the hypervisor itself. The guest
physical memory of a VM is allocated and managed by the virtualization
stack’s memory manager. When a VM is started, the spawned VM Worker
process (VMWP.exe) invokes the services of the memory manager (defined
in the IMemoryManager COM interface) for constructing the guest VM’s
RAM. Allocating memory for a VM is a two-step process:
1. 
The VM Worker process obtains a report of the global system’s
memory state (by using services from the Memory Balancer in the
VMMS process), and, based on the available system memory,
determines the size of the physical memory blocks to request to the
VID driver (through the VID_RESERVE IOCTL. Sizes of the block
vary from 64 MB up to 4 GB). The blocks are allocated by the VID
driver using MDL management functions
(MmAllocatePartitionNodePagesForMdlEx in particular). For
performance reasons, and to avoid memory fragmentation, the VID
driver implements a best-effort algorithm to allocate huge and large
physical pages (1 GB and 2 MB) before relying on standard small
pages. After the memory blocks are allocated, their pages are
deposited to an internal “reserve” bucket maintained by the VID
driver. The bucket contains page lists ordered in an array based on
their quality of service (QOS). The QOS is determined based on the
page type (huge, large, and small) and the NUMA node they belong
to. This process in the VID nomenclature is called “reserving physical
memory” (not to be confused with the term “reserving virtual
memory,” a concept of the NT memory manager).
2. 
From the virtualization stack perspective, physical memory
commitment is the process of emptying the reserved pages in the
bucket and moving them in a VID memory block
(VSMM_MEMORY_BLOCK data structure), which is created and
owned by the VM Worker process using the VID driver’s services. In
the process of creating a memory block, the VID driver first deposits
additional physical pages in the hypervisor (through the Winhvr
driver and the HvDepositMemory hypercall). The additional pages are
needed for creating the SLAT table page hierarchy of the VM. The
VID driver then requests to the hypervisor to map the physical pages
describing the entire guest partition’s RAM. The hypervisor inserts
valid entries in the SLAT table and sets their proper permissions. The
guest physical address space of the partition is created. The GPA
range is inserted in a list belonging to the VID partition. The VID
memory block is owned by the VM Worker process. It’s also used for
tracking guest memory and in DAX file-backed memory blocks. (See
Chapter 11, “Caching and file system support,” for more details about
DAX volumes and PMEM.) The VM Worker process can later use
the memory block for multiple purposes—for example, to access
some pages while managing emulated devices.
The birth of a Virtual Machine (VM)
The process of starting up a virtual machine is managed primarily by the
VMMS and VMWP process. When a request to start a VM (internally
identified by a GUID) is delivered to the VMMS service (through PowerShell
or the Hyper-V Manager GUI application), the VMMS service begins the
starting process by reading the VM’s configuration from the data store
repository, which includes the VM’s GUID and the list of all the virtual
devices (VDEVs) comprising its virtual hardware. It then verifies that the
path containing the VHD (or VHDX) representing the VM’s virtual hard disk
has the correct access control list (ACL, more details provided later). In case
the ACL is not correct, if specified by the VM configuration, the VMMS
service (which runs under a SYSTEM account) rewrites a new one, which is
compatible with the new VMWP process instance. The VMMS uses COM
services to communicate with the Host Compute Service to spawn a new
VMWP process instance.
The Host Compute Service gets the path of the VM Worker process by
querying its COM registration data located in the Windows registry
(HKCU\CLSID\{f33463e0-7d59-11d9-9916-0008744f51f3} key). It then
creates the new process using a well-defined access token, which is built
using the virtual machine SID as the owner. Indeed, the NT Authority of the
Windows Security model defines a well-known subauthority value (83) to
identify VMs (more information on system security components are available
in Part 1, Chapter 7, “Security”). The Host Compute Service waits for the
VMWP process to complete its initialization (in this way the exposed COM
interfaces become ready). The execution returns to the VMMS service, which
can finally request the starting of the VM to the VMWP process (through the
exposed IVirtualMachine COM interface).
As shown in Figure 9-24, the VM Worker process performs a “cold start”
state transition for the VM. In the VM Worker process, the entire VM is
managed through services exposed by the “Virtual Motherboard.” The
Virtual Motherboard emulates an Intel i440BX motherboard on Generation 1
VMs, whereas on Generation 2, it emulates a proprietary motherboard. It
manages and maintains the list of virtual devices and performs the state
transitions for each of them. As covered in the next section, each virtual
device is implemented as a COM object (exposing the IVirtualDevice
interface) in a DLL. The Virtual Motherboard enumerates each virtual device
from the VM’s configuration and loads the relative COM object representing
the device.
Figure 9-24 The VM Worker process and its interface for performing a
“cold start” of a VM.
The VM Worker process begins the startup procedure by reserving the
resources needed by each virtual device. It then constructs the VM guest
physical address space (virtual RAM) by allocating physical memory from
the root partition through the VID driver. At this stage, it can power up the
virtual motherboard, which will cycle between each VDEV and power it up.
The power-up procedure is different for each device: for example, synthetic
devices usually communicate with their own Virtualization Service Provider
(VSP) for the initial setup.
One virtual device that deserves a deeper discussion is the virtual BIOS
(implemented in the Vmchipset.dll library). Its power-up method allows the
VM to include the initial firmware executed when the bootstrap VP is started.
The BIOS VDEV extracts the correct firmware for the VM (legacy BIOS in
the case of Generation 1 VMs; UEFI otherwise) from the resource section of
its own backing library, builds the volatile configuration part of the firmware
(like the ACPI and the SRAT table), and injects it in the proper guest
physical memory by using services provided by the VID driver. The VID
driver is indeed able to map memory ranges described by the VID memory
block in user mode memory, accessible by the VM Worker process (this
procedure is internally called “memory aperture creation”).
After all the virtual devices have been successfully powered up, the VM
Worker process can start the bootstrap virtual processor of the VM by
sending a proper IOCTL to the VID driver, which will start the VP and its
message pump (used for exchanging messages between the VID driver and
the VM Worker process).
EXPERIMENT: Understanding the security of the VM
Worker process and the virtual hard disk files
In the previous section, we discussed how the VM Worker process
is launched by the Host Compute service (Vmcompute.exe) when a
request to start a VM is delivered to the VMMS process (through
WMI). Before communicating with the Host Compute Service, the
VMMS generates a security token for the new Worker process
instance.
Three new entities have been added to the Windows security
model to properly support virtual machines (the Windows Security
model has been extensively discussed in Chapter 7 of Part 1):
■    A “virtual machines” security group, identified with the S-
1-5-83-0 security identifier.
■    A virtual machine security identifier (SID), based on the
VM’s unique identifier (GUID). The VM SID becomes the
owner of the security token generated for the VM Worker
process.
■    A VM Worker process security capability used to give
applications running in AppContainers access to Hyper-V
services required by the VM Worker process.
In this experiment, you will create a new virtual machine
through the Hyper-V manager in a location that’s accessible only to
the current user and to the administrators group, and you will check
how the security of the VM files and the VM Worker process
change accordingly.
First, open an administrative command prompt and create a
folder in one of the workstation’s volumes (in the example we used
C:\TestVm), using the following command:
md c:\TestVm
Then you need to strip off all the inherited ACEs (Access control
entries; see Chapter 7 of Part 1 for further details) and add full
access ACEs for the administrators group and the current logged-
on user. The following commands perform the described actions
(you need to replace C:\TestVm with the path of your directory and
 with your currently logged-on user name):
Click here to view code image
icacls c:\TestVm /inheritance:r
icacls c:\TestVm /grant Administrators:(CI)(OI)F
icacls c:\TestVm /grant :(CI)(OI)F
To verify that the folder has the correct ACL, you should open
File Explorer (by pressing Win+E on your keyboard), right-click
the folder, select Properties, and finally click the Security tab. You
should see a window like the following one:
Open the Hyper-V Manager, create a VM (and its relative virtual
disk), and store it in the newly created folder (procedure available
at the following page: https://docs.microsoft.com/en-
us/virtualization/hyper-v-on-windows/quick-start/create-virtual-
machine). For this experiment, you don’t really need to install an
OS on the VM. After the New Virtual Machine Wizard ends, you
should start your VM (in the example, the VM is VM1).
Open a Process Explorer as administrator and locate the
vmwp.exe process. Right-click it and select Properties. As
expected, you can see that the parent process is vmcompute.exe
(Host Compute Service). If you click the Security tab, you should
see that the VM SID is set as the owner of the process, and the
token belongs to the Virtual Machines group:
The SID is composed by reflecting the VM GUID. In the
example, the VM’s GUID is {F156B42C-4AE6-4291-8AD6-
EDFE0960A1CE}. (You can verify it also by using PowerShell, as
explained in the “Playing with the Root scheduler” experiment
earlier in this chapter). A GUID is a sequence of 16-bytes,
organized as one 32-bit (4 bytes) integer, two 16-bit (2 bytes)
integers, and 8 final bytes. The GUID in the example is organized
as:
■    0xF156B42C as the first 32-bit integer, which, in decimal,
is 4048991276.
■    0x4AE6 and 0x4291 as the two 16-bit integers, which,
combined as one 32-bit value, is 0x42914AE6, or
1116818150 in decimal (remember that the system is little
endian, so the less significant byte is located at the lower
address).
■    The final byte sequence is 0x8A, 0xD6, 0xED, 0xFE, 0x09,
0x60, 0xA1 and 0xCE (the third part of the shown human
readable GUID, 8AD6, is a byte sequence, and not a 16-bit
value), which, combined as two 32-bit values is
0xFEEDD68A and 0xCEA16009, or 4276999818 and
3466682377 in decimal.
If you combine all the calculated decimal numbers with a
general SID identifier emitted by the NT authority (S-1-5) and the
VM base RID (83), you should obtain the same SID shown in
Process Explorer (in the example, S-1-5-83-4048991276-
1116818150-4276999818-3466682377).
As you can see from Process Explorer, the VMWP process’s
security token does not include the Administrators group, and it
hasn’t been created on behalf of the logged-on user. So how is it
possible that the VM Worker process can access the virtual hard
disk and the VM configuration files?
The answer resides in the VMMS process, which, at VM
creation time, scans each component of the VM’s path and
modifies the DACL of the needed folders and files. In particular,
the root folder of the VM (the root folder has the same name of the
VM, so you should find a subfolder in the created directory with
the same name of your VM) is accessible thanks to the added
virtual machines security group ACE. The virtual hard disk file is
instead accessible thanks to an access-allowed ACE targeting the
virtual machine’s SID.
You can verify this by using File Explorer: Open the VM’s
virtual hard disk folder (called Virtual Hard Disks and located in
the VM root folder), right-click the VHDX (or VHD) file, select
Properties, and then click the Security page. You should see two
new ACEs other than the one set initially. (One is the virtual
machine ACE; the other one is the VmWorker process Capability
for AppContainers.)
If you stop the VM and you try to delete the virtual machine
ACE from the file, you will see that the VM is not able to start
anymore. For restoring the correct ACL for the virtual hard disk,
you can run a PowerShell script available at
https://gallery.technet.microsoft.com/Hyper-V-Restore-ACL-
e64dee58.
VMBus
VMBus is the mechanism exposed by the Hyper-V virtualization stack to
provide interpartition communication between VMs. It is a virtual bus device
that sets up channels between the guest and the host. These channels provide
the capability to share data between partitions and set up paravirtualized (also
known as synthetic) devices.
The root partition hosts Virtualization Service Providers (VSPs) that
communicate over VMBus to handle device requests from child partitions.
On the other end, child partitions (or guests) use Virtualization Service
Consumers (VSCs) to redirect device requests to the VSP over VMBus.
Child partitions require VMBus and VSC drivers to use the paravirtualized
device stacks (more details on virtual hardware support are provided later in
this chapter in the ”Virtual hardware support” section). VMBus channels
allow VSCs and VSPs to transfer data primarily through two ring buffers:
upstream and downstream. These ring buffers are mapped into both partitions
thanks to the hypervisor, which, as discussed in the previous section, also
provides interpartition communication services through the SynIC.
One of the first virtual devices (VDEV) that the Worker process starts
while powering up a VM is the VMBus VDEV (implemented in
Vmbusvdev.dll). Its power-on routine connects the VM Worker process to
the VMBus root driver (Vmbusr.sys) by sending VMBUS_VDEV_SETUP
IOCTL to the VMBus root device (named \Device\RootVmBus). The
VMBus root driver orchestrates the parent endpoint of the bidirectional
communication to the child VM. Its initial setup routine, which is invoked at
the time the target VM isn’t still powered on, has the important role to create
an XPartition data structure, which is used to represent the VMBus instance
of the child VM and to connect the needed SynIC synthetic interrupt sources
(also known as SINT, see the “Synthetic Interrupt Controller” section earlier
in this chapter for more details). In the root partition, VMBus uses two
synthetic interrupt sources: one for the initial message handshaking (which
happens before the channel is created) and another one for the synthetic
events signaled by the ring buffers. Child partitions use only one SINT,
though. The setup routine allocates the main message port in the child VM
and the corresponding connection in the root, and, for each virtual processor
belonging to the VM, allocates an event port and its connection (used for
receiving synthetic events from the child VM).
The two synthetic interrupt sources are mapped using two ISR routines,
named KiVmbusInterrupt0 and KiVmbusInterrupt1. Thanks to these two
routines, the root partition is ready to receive synthetic interrupts and
messages from the child VM. When a message (or event) is received, the ISR
queues a deferred procedure call (DPC), which checks whether the message
is valid; if so, it queues a work item, which will be processed later by the
system running at passive IRQL level (which has further implications on the
message queue).
Once VMBus in the root partition is ready, each VSP driver in the root can
use the services exposed by the VMBus kernel mode client library to allocate
and offer a VMBus channel to the child VM. The VMBus kernel mode client
library (abbreviated as KMCL) represents a VMBus channel through an
opaque KMODE_CLIENT_CONTEXT data structure, which is allocated and
initialized at channel creation time (when a VSP calls the
VmbChannelAllocate API). The root VSP then normally offers the channel to
the child VM by calling the VmbChannelEnabled API (this function in the
child establishes the actual connection to the root by opening the channel).
KMCL is implemented in two drivers: one running in the root partition
(Vmbkmclr.sys) and one loaded in child partitions (Vmbkmcl.sys).
Offering a channel in the root is a relatively complex operation that
involves the following steps:
1. 
The KMCL driver communicates with the VMBus root driver through
the file object initialized in the VDEV power-up routine. The VMBus
driver obtains the XPartition data structure representing the child
partition and starts the channel offering process.
2. 
Lower-level services provided by the VMBus driver allocate and
initialize a LOCAL_OFFER data structure representing a single
“channel offer” and preallocate some SynIC predefined messages.
VMBus then creates the synthetic event port in the root, from which
the child can connect to signal events after writing data to the ring
buffer. The LOCAL_OFFER data structure representing the offered
channel is added to an internal server channels list.
3. 
After VMBus has created the channel, it tries to send the
OfferChannel message to the child with the goal to inform it of the
new channel. However, at this stage, VMBus fails because the other
end (the child VM) is not ready yet and has not started the initial
message handshake.
After all the VSPs have completed the channel offering, and all the VDEV
have been powered up (see the previous section for details), the VM Worker
process starts the VM. For channels to be completely initialized, and their
relative connections to be started, the guest partition should load and start the
VMBus child driver (Vmbus.sys).
Initial VMBus message handshaking
In Windows, the VMBus child driver is a WDF bus driver enumerated and
started by the Pnp manager and located in the ACPI root enumerator.
(Another version of the VMBus child driver is also available for Linux.
VMBus for Linux is not covered in this book, though.) When the NT kernel
starts in the child VM, the VMBus driver begins its execution by initializing
its own internal state (which means allocating the needed data structure and
work items) and by creating the \Device\VmBus root functional device object
(FDO). The Pnp manager then calls the VMBus’s resource assignment
handler routine. The latter configures the correct SINT source (by emitting a
HvSetVpRegisters hypercall on one of the HvRegisterSint registers, with the
help of the WinHv driver) and connects it to the KiVmbusInterrupt2 ISR.
Furthermore, it obtains the SIMP page, used for sending and receiving
synthetic messages to and from the root partition (see the “Synthetic Interrupt
Controller” section earlier in this chapter for more details), and creates the
XPartition data structure representing the parent (root) partition.
When the request of starting the VMBus’ FDO comes from the Pnp
manager, the VMBus driver starts the initial message handshaking. At this
stage, each message is sent by emitting the HvPostMessage hypercall (with
the help of the WinHv driver), which allows the hypervisor to inject a
synthetic interrupt to a target partition (in this case, the target is the partition).
The receiver acquires the message by simply reading from the SIMP page;
the receiver signals that the message has been read from the queue by setting
the new message type to MessageTypeNone. (See the hypervisor TLFS for
more details.) The reader can think of the initial message handshake, which is
represented in Figure 9-25, as a process divided in two phases.
Figure 9-25 VMBus initial message handshake.
The first phase is represented by the Initiate Contact message, which is
delivered once in the lifetime of the VM. This message is sent from the child
VM to the root with the goal to negotiate the VMBus protocol version
supported by both sides. At the time of this writing, there are five main
VMBus protocol versions, with some additional slight variations. The root
partition parses the message, asks the hypervisor to map the monitor pages
allocated by the client (if supported by the protocol), and replies by accepting
the proposed protocol version. Note that if this is not the case (which happens
when the Windows version running in the root partition is lower than the one
running in the child VM), the child VM restarts the process by downgrading
the VMBus protocol version until a compatible version is established. At this
point, the child is ready to send the Request Offers message, which causes the
root partition to send the list of all the channels already offered by the VSPs.
This allows the child partition to open the channels later in the handshaking
protocol.
Figure 9-25 highlights the different synthetic messages delivered through
the hypervisor for setting up the VMBus channel or channels. The root
partition walks the list of the offered channels located in the Server Channels
list (LOCAL_OFFER data structure, as discussed previously), and, for each
of them, sends an Offer Channel message to the child VM. The message is
the same as the one sent at the final stage of the channel offering protocol,
which we discussed previously in the “VMBus” section. So, while the first
phase of the initial message handshake happens only once per lifetime of the
VM, the second phase can start any time when a channel is offered. The
Offer Channel message includes important data used to uniquely identify the
channel, like the channel type and instance GUIDs. For VDEV channels,
these two GUIDs are used by the Pnp Manager to properly identify the
associated virtual device.
The child responds to the message by allocating the client
LOCAL_OFFER data structure representing the channel and the relative
XInterrupt object, and by determining whether the channel requires a
physical device object (PDO) to be created, which is usually always true for