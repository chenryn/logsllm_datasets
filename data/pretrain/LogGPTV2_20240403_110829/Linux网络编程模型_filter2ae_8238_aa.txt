# Linux网络编程模型
|
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
因为最近在找开源网络组件的漏洞，将自己遇到的linux网络编程问题做个总结，也巩固一下自己的网络基础知识，我做的就是总结和归纳，很多知识都是直接使用参考链接中的代码和描述，感觉描述不清楚的，建议直接看参考链接中大佬的文章，描述不正确的，直接可以联系我，我做改正。
写这个文章看了很多大佬的文章，大佬的文章，基本有3个特点
    1. 全部理论介绍，理论特别详细，但是没有具体实现代码，有的可能也只是伪码
    2. 是基本全是代码，理论基本没有，但是代码又不全，看不到效果
    3. 形象比喻，各种绘声绘影的描述网络模型，但是代码一行没有
本文主旨是`show me the
code`，废话不多，能用代码描述的尽力不多bb，每个模型，我都简要的做了描述，之后使用简单的代码来做指导，并且代码可以使用，[开源代码](https://github.com/xinali/LinuxNetworkModel)，你可以编译执行，观察效果，之后再结合一点理论，自然而然也就大概理解了。等你了解了，这些基础，再去使用什么`libev/libuv`的库，相对来说也就简单多了。  
这单纯的只是一个基础，没有涉及到网络组件漏洞挖掘，大佬勿喷
`Linux`的`5`种网络模型(`I/O`模型)
    1) 阻塞I/O blocking I/O
    2) 非阻塞I/O nonblocking I/O
    3) 复用I/O I/O multiplexing (select/poll/epoll) (主用于TCP)
    4) 信号驱动I/O signal driven I/O (主用于UDP)
    5) 异步I/O asynchronous I/O
我尽我所能的把上面的每个模型，包括其中每个利用点，都说一下，除了目前业界实现不完全的异步I/O
## 阻塞模型
这是最基础，最简单的linux网络模型, 下面利用简单的一幅图描述网络阻塞模型的原理
                                            server
                                               |
                                              bind
                                               |
                                             listen
                                               |
                                             accept
                                               |
                                          阻塞直到客户端连接
                                               |
            client                             |
               |                               |
            connect ----建立连接完成3次握手---->  |
               |                               |
             write   --------数据(请求)------> read
               |                               |
               |                             处理请求
               |                               |
             read    |  connfd  |
                ^             +----------+
                |                  |
                |                  | fork 子进程处理
                |                  |
                |             +----------+
                |             | listenfd |
                |             |          |
                +------------ |  connfd  |
                              +----------+
这种模型，客户端感受不到，只需要更改服务器端代码即可
    do
    {
        struct sockaddr_in server_addr, client_addr;
        unsigned char client_host[256];
        memset((void *)client_host, 0, sizeof(client_host));
        server_fd = socket(AF_INET, SOCK_STREAM, 0);
        if (server_fd == -1)
        {
            handle_error("socket");
            break;
        }
        memset((void *)&server_addr, 0, sizeof(struct sockaddr_in));
        server_addr.sin_family = AF_INET;   /* ipv4 tcp packet */
        server_addr.sin_port = htons(SERVER_PORT); /* convert to network byte order */
        server_addr.sin_addr.s_addr = htonl(INADDR_ANY);
        if (bind(server_fd, (SA *)&server_addr, sizeof(struct sockaddr_in)) == -1)
        {
            handle_error("bind");
            break;
        }
        if (listen(server_fd, LISTEN_BACKLOG) == -1)
        {
            handle_error("listen");
            break;
        }
        for (;;)
        {
            printf("waiting for connect to server...n");
            int client_fd;
            int client_addr_len = sizeof(struct sockaddr_in);
            if ((client_fd = accept(server_fd, (struct sockaddr *)&client_addr,
                                        (socklen_t *)&client_addr_len)) == -1)
            {
                handle_error("accept");
                break;
            }
            printf("connection from %s, port %dn",
                    inet_ntoa(client_addr.sin_addr),
                    ntohs(client_addr.sin_port));
            // child process to handle client_fd
            if (0 == fork())
            {
                close(server_fd); /* child process close listening server_fd */
                write(client_fd, SEND_2_CLIENT_MSG, sizeof(SEND_2_CLIENT_MSG));
                close(client_fd); /* child process close client_fd */
                exit(0);
            }
            else /* parent process close client_fd */
                close(client_fd);
        }
    } while (0);
多次启动客户端，服务器端，大概是这样
    ➜  LinuxNetwork ./block_server_fork
    waiting for connect to server...
    connection from 127.0.0.1, port 41458
    waiting for connect to server...
    connection from 127.0.0.1, port 41459
    waiting for connect to server...
即使使用`fork`来提升效率，但是`fork`模式，依然有两个致命的缺点
    1）用 fork() 的问题在于每一个 Connection 进来时的成本太高,如果同时接入的并发连接数太多容易进程数量很多,进程之间的切换开销会很大,同时对于老的内核(Linux)会产生雪崩效应。 
    2）用 Multi-thread 的问题在于 Thread-safe 与 Deadlock 问题难以解决，另外有 Memory-leak 的问题要处理,这个问题对于很多程序员来说无异于恶梦,尤其是对于连续服务器的服务器程序更是不可以接受。
所以为了提高效率，又提出了以下的非阻塞模型
## 非阻塞模型
直接单独使用这种模型很少用到，因为基本上是一个线程只能同时处理一个`socket`，效率低下，  
很多都是结合了下面的`I/O`复用来使用，  
所以大概了解一下代码，知道原理即可，借用`UNIX`网络编程书中的一句话
    进程把一个套接字设置成非阻塞是在通知内核：
    当所有请求的I/Ocaozuo非得吧本进程投入睡眠才能完成时，不要把本进程投入睡眠，而是返回一个错误
样例代码
`standard_no_block_server.c`
    do
    {
        if ((server_fd = socket(AF_INET, SOCK_STREAM, 0)) == -1)
        {
            handle_error("socket");
            break;
        }
        last_fd = server_fd;
        server_addr.sin_family = AF_INET; 
        server_addr.sin_port = htons(SERVER_PORT);
        server_addr.sin_addr.s_addr = INADDR_ANY;
        bzero(&(server_addr.sin_zero), 8); 
        if (bind(server_fd, (SA *)&server_addr, sizeof(SA)) == -1)
        {
            handle_error("bind");
            break;
        }
        if (listen(server_fd, LISTEN_BACKLOG) == -1)
        {
            handle_error("listen");
            break;
        }
        if ((client_fd = accept(server_fd, 
                            (SA *)&client_addr,
                                (socklen_t*)&sin_size)) == -1)
        {
            handle_error("accept");
            break;
        }
        fcntl(last_fd, F_SETFL, O_NONBLOCK); 
        fcntl(client_fd, F_SETFL, O_NONBLOCK);  
        for (; ;)
        {
            for (int i = server_fd; i <= last_fd; i++)
            {
                printf("Round number %dn", i);
                if (i == server_fd)
                {
                    sin_size = sizeof(struct sockaddr_in);
                    if ((client_fd = accept(server_fd, (SA *)&client_addr,
                                        (socklen_t*)&sin_size)) == -1)
                    {
                        handle_error("accept");
                        continue;
                    }
                    printf("server: got connection from %sn",
                            inet_ntoa(client_addr.sin_addr));
                    fcntl(client_fd, F_SETFL, O_NONBLOCK);
                    last_fd = client_fd;
                }
                else
                {
                    ssize_t recv_size = read(client_fd, buf_read, READ_MAX_SIZE);
                    if (recv_size < 0)
                    {
                        handle_error("recv");
                        break;
                    }
                    if (recv_size == 0)
                    {
                        close(client_fd);
                        continue;
                    }
                    else
                    {
                        buf_read[recv_size] = '';
                        printf("The string is: %s n", buf_read);
                        if (write(client_fd, SEND_2_CLIENT_MSG, strlen(SEND_2_CLIENT_MSG)) == -1)
                        {
                            handle_error("send");
                            continue;
                        }
                    }
                }
            }
        }
    } while (0);
缺点就是使用大量的`CPU`轮询时间，浪费了大量的宝贵的服务器`CPU`资源
## I/O复用
无论是阻塞还是单纯的非阻塞模型，最致命的缺点就是效率低，在处理大量请求时，无法满足使用需求  
所以就需要用到接下来介绍的各种`I/O`复用方式了
###  select
`select`方式简单点来说就是一个用户线程，一次监控多个`socket`，显然要比简单的单线程单`socket`速度要快很多很多。  