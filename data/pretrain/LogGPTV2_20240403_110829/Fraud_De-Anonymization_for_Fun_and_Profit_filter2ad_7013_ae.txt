### Precision and Recall Metrics

The following table presents the precision and recall values for the evaluated model:

| Metric  | Value   |
|---------|---------|
| Precision | 96.40%  |
| Recall    | 96.30%  |
| ...     | ...     |
| Recall    | 85.92%  |

### Figure 5: Distribution of Seed and DDA-Attributed Accounts

- **Top Panel**: The distribution of seed and DDA-attributed accounts across 23 fraudulent workers. DDA attributed 3,547 accounts to these fraudsters, which is 3.7 times more than the size of the seed set.
- **Bottom Panel**: The percentage of newly attributed accounts suspected of self-plagiarism. For 13 out of the 23 fraud workers, at least 90% of the newly attributed accounts have self-plagiarized reviews.

### Methodology

We analyzed the review histories of all accounts in the test set (TT). We fixed the parameters \( b_1 = 10 \) and \( b_2 = 15 \) (determined through a grid search) across all workers. For each account \( u \) in TT, we selected the worker whose partition maximizes the function in Equation (4). This function was evaluated 23 times, once for each worker, and the account \( u \) was attributed to the worker that maximized it.

To evaluate the function, we used \( P_i \), the popularity volume of all subjects in each \( \Omega_i \), calculated as:
\[ P_i = \epsilon \sum_{s_j \in \Omega_i} R(s_j) \]
where \( R(s_j) \) is the number of reviews that subject \( s_j \) received from fraudster accounts in the ground truth (GT) set, and \( \epsilon \) was set to mimic a probability distribution on \( S \). We tested multiple values for \( \epsilon \) and found \( \epsilon = 10^{-6} \) to be the best performer.

### Table 1: Comparison of UODA and DDA Results

After 10 different random GT/TT splits, DDA achieved an F1 measure of 94.5%, outperforming UODA’s top 1 choice. UODA’s performance improved significantly when allowed to make mistakes: 
- Top 2 UODA: Average F1 of 91.11%
- Top 3 UODA: Average F1 of 93.57%

### Fraud Attribution in the Wild

We further trained DDA on all ground truth information (both GT and TT sets) and applied it to 3,681 accounts that appeared in at least one seed cluster but never in an unknown cluster of the 640 suspicious apps. Figure 5 (top) shows the distribution of 3,547 of these accounts attributed to the 23 fraud workers, with only 134 accounts not assigned to any fraud worker.

To validate the results, we computed the Jaccard similarity between each newly attributed account and all seed accounts using the k-shingle representation of reviews (k = 3, with reviews having at least 10 characters). Figure 5 (bottom) shows that 13 out of 23 fraud workers have around 90% of their newly attributed accounts with similar reviews to those written by their seed accounts. Additionally, 22 out of 23 fraudsters have at least 50% of their accounts with similar reviews, confirming DDA’s outcome and previous work on crowdsourced review manipulation.

### Co-Ownership Predictor Evaluation

We evaluated the performance of the co-ownership predictor (cowPred) and compared it against Elsiedet's state-of-the-art solution [87]. The training data was built by creating complete graphs from seed-attributed accounts in clusters across the product space, generating positive and negative links based on whether accounts were controlled by the same or different fraudsters. Our training set consisted of 17,695 pairs of user accounts, 79.5% of which were controlled by the same fraudster.

We trained several supervised learning algorithms (GBM, RF, SVM, RLR, NB) and selected the top performer. The no sampling and oversampling strategies outperformed the undersampling strategy. GBM and RF achieved the best overall results, with cowPred significantly outperforming Elsiedet (F1-measure of 96.67% vs. 84.13%).

### Feature Insights via Regularized Logistic Regression

To understand the impact of cowPred features, we trained a regularized logistic regression model on the entire dataset. Figure 6 shows the relative importance of statistically significant variables. Key insights include:
- Co-review and co-cluster features have a strong positive effect on the probability of two accounts being controlled by the same worker.
- The unique lockstep feature has a negative effect, suggesting that larger values indicate lower likelihood of common ownership.
- Rating features have the least significant effect, implying that most workers post either positive or negative reviews.

### Pseudonymous Fraudster Discovery

We applied the cowPred predictor to 279,431 links from 5,690 unattributed user accounts that reviewed 640 suspicious apps. The resulting co-ownership graph consists of 5,548 user accounts and 97,448 edges, with 129 components identified, each potentially controlled by a different fraudster. Manual inspection of reviews revealed many suspicious behaviors, including singular coincidence and template-based reviews.

### Discussion and Limitations

- **Underground Fraud Markets**: If successful, our approach may drive fraudsters to underground markets, which aligns with our goal of degrading fraudster capabilities.
- **Evasion Strategies**: Fraudsters can try to evade detection by minimizing account reuse, but this reduces their operational efficiency.
- **Importance of Seed Data**: Detego requires seed ground truth information about known fraudsters. Future work could explore cross-site identity linking attacks to link detected Sybil communities to public profiles.
- **Informed Consent**: Recruitment for user studies may be challenging due to factors like deserted accounts and lack of interest. Future work could investigate the use of IRB-approved deception to improve recruitment and accuracy.
- **Fraud Account Memorability**: Participants in our study were able to correctly detect controlled and non-controlled accounts, but future work should determine the maximum number of questions before fatigue impacts honesty and accuracy.
- **I.i.d. Assumption**: UODA assumes the review history of a fraudulent account is independent and identically distributed. Future work could explore a Markovian review-posting model.