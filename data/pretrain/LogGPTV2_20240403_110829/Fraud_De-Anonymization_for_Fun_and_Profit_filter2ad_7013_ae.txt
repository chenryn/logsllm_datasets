Precision Recall
96.40%
96.30%
93.75%
93.72%
88.44%
82.41%
96.94% 96.67%
96.65%
97.01%
94.54%
95.34%
94.07%
94.42%
95.66%
91.91%
84.13%
85.92%
Figure 5: (Top) Distribution of seed and DDA attributed ac-
counts across the 23 fraudulent workers. DDA attributed
3,547 accounts to these fraudsters, 3.7 times more than the
size of the seed set. (Bottom) Per worker percentage of newly
attributed accounts suspected of self-plagiarism. Almost all
(≥ 90%) of the newly attributed accounts for 13 out of 23
fraud workers have self-plagiarized reviews.
the review histories of all accounts in TT . We fix the same b1 = 10
and b2 = 15 (obtained through a grid search) across all the workers.
Then, given an account u in TT , we select as candidate the worker
whose partition maximizes the function in Equation (4), i.e., we
evaluate such function 23 times (one for each worker) and attribute
u to the worker that maximizes it. Note that to evaluate the function,
we need Pi: the popularity volume of all the subjects in each Ωi.
sj ∈Ωi R(sj ) where R(sj ) is the number
of reviews that subject sj received from fraudster accounts in the
GT set and ϵ was set to mimic a probability distribution on S.
In practice, we have evaluated multiple values for ϵ, and chose
ϵ = 10−6 as best performer.
We approximate Pi = ϵ(cid:80)
Table 1 compares UODA and DDA results after 10 different
random GT /TT splits. We observe that DDA achieves an F1 measure
of 94.5%, outperforming UODA’s top 1 choice. UODA’s performance,
however, significantly increases when allowed to make mistakes.
Specifically, Top 2 UODA achieves an average F1 of 91.11% while
Top 3 UODA achieves an average F1 of 93.57%.
Fraud Attribution in the Wild. We have further trained DDA on
all the ground truth information (both GT and TT sets). We then
applied the trained DDA to 3,681 accounts that appeared in at least
one seed cluster but never appeared in an unknown cluster of the
640 suspicious apps (§ 11.1). Figure 5 (top) shows the distribution
of 3,547 of these accounts attributed to the 23 fraud workers. Only
134 accounts were not assigned to any fraud worker. To validate
this result, we computed the review’s Jaccard similarity between
each newly attributed ˆUl account and all seed Ul accounts, using
the review’s k−shingle representation as defined in [19].
Figure 5 (bottom) shows the proportion of newly assigned ac-
counts u ∈ ˆUl that have at least one review similar (J (R ˆu , Ru ) ≥
0.5) to those of accounts in its respective seed set. We have set k = 3
and considered only reviews with at least 10 characters in length.
We observe that 13 out of 23 fraud workers have around 90% of their
new attributed accounts with similar reviews to the ones written by
its seed accounts. Likewise, 22 out of 23 fraudsters have at least 50%
of their accounts with similar reviews. These results confirm DDA’s
outcome and previous work on crowdsourced review manipulation,
e.g., [36].
11.4 Co-Ownership Predictor
We evaluate the performance of the co-ownership predictor cowPred
of Section 5, and compare it against Elsiedet’s state-of-the-art so-
lution [87]. For this, we build training data as follows. First, create
complete graphs from among seed attributed accounts found in clus-
ters across all the product space, i.e., create a link (u, v) for u, v ∈ Cj
where Cj is a cluster in product j. Then, using the 942 accounts of
§ 11.1, generate “positive” links (class 1) when both accounts in the
link are known to be controlled by the same fraudster and “negative”
links (class 0) when controlled by different fraudsters. Finally, for
each link (u, v), extract the 16 features described in Section 6 and
append its class. Our training set consists of 17,695 pairs of user
accounts, 79.5% of which are controlled by the same fraudster.
We use this data to train several supervised learning algorithms
and select the top performer as the co-ownership predictor. Specifi-
cally, we used several sampling strategies and supervised learning
algorithms that train on the features of the co-ownership predictor:
Gradient Boosting Machine (GBM), Random Forests (RF), Support
Vector Machine (SVM), Regularized Logistic Regression (RLR), and
Naive Bayes (NB). We also set aside 20% of the 17,695 links as a
test set to assess the quality of the co-ownership predictor after
training with 10-fold CV. Further, to evaluate the impact of class
imbalance, we compared the no sampling strategy against strategies
of undersampling and oversampling. For the undersampling strategy,
we created a 50-50 training set with 2,901 links for each class. For
the oversampling strategy, we used the SMOTE algorithm [21] and
created synthetic data along the line segments joining any or all
of the k minority class nearest neighbors. cowPred’s results were
very similar for the no sampling and oversampling strategies, out-
performing the undersampling strategy. Thus, in the following we
present results only for the no sampling strategy.
The ELSIEDET co-ownership predictor. We compare cowPred
against the state-of-the-art Elsiedet’s Sybil social link builder [87].
Elsiedet builds social links between Sybil user accounts based on
their similarity: (i) whether their reviews were posted for the same
app, (ii) within a fixed time window ∆T , and (iii) were either 1-star
or 5-star. Accounts u and v are considered to form a Sybil social
link iff sim(u, v) ≥ β, where β and ∆T are parameters. Zheng et
03006009000%25%50%75%100%1234567891011121314151617181920212223Worker indexNumber of Accounts% Similar AccountsAttributedSeedFigure 6: Relative importance (shown as siдn(y) ∗ loд(1 +
abs (y))) for statistically significant features in the co-
ownership predictor using logistic regression. Co-review and
co-cluster have the highest positive impact, while the mean
date difference on Lij and the unique lockstep uij have the
largest negative weight.
al. [87] manually tuned these parameters, as they observed that
several supervised learning techniques were not sensitive to differ-
ent thresholds employed. We have improved on this manual tuning
process, by implementing a grid search to obtain the best param-
eters ∆T∗, β∗, using the same training set used for our cowPred
predictor. We compute performance for Elsiedet based on whether
links (u, v) were predicted to be controlled by the same worker.
Comparison results. Table 2 compares cowPred’s performance
on the test set, for the best performing supervised learning algo-
rithms evaluated, against Elsiedet’s Sybil social link builder, with
best parameters ∆T∗ = 30 and β∗ = 0.01. For cowPred, GBM and
RF achieved the best overall results. cowPred significantly outper-
formed Elsiedet, with an F1-measure of 96.67% vs. 84.13%. While
Elsiedet was designed for a different type of social network (i.e.,
Dianping, Yelp), and a different adversary type (elite reviewer), we
believe that cowPred’s advantage stems from its use of features ex-
tracted from common review behaviors exhibited by Sybil accounts.
We note that we were not able to compare cowPred against other
related solutions, e.g., Kumar et al.’s sockpuppet pair detection ap-
proach [40], as they leverage features not available in Google Play,
such as community features (downvotes and upvotes).
Feature Insights via Regularized Logistic Regression. In order
to understand the impact of and confirm the intuition behind the
cowPred features (see § 5.2), we train cowPred on the entire data
set (17,695 links) using a regularized logistic regression model [29].
Figure 6 shows the relative importance of the statistically signifi-
cant variables after applying Wald Chi-Squared test. We measure
importance as the value of the coefficients corresponding to the
trained model.
We observe that the co-review and co-cluster features have a
strong positive effect on the probability of two accounts being
controlled by the same worker. The higher their values the more
likely it is that two accounts are owned by the same underlying
worker. Similarly, a positive weight for mode (Lij ) and min(Lij )
(see § 5.2) suggests that if a long period of time between reviews
is repeated across most of the commonly reviewed apps then it is
more likely that the two accounts are handled by the same worker.
However, the unique lockstep feature uL shows a negative effect,
Figure 7: Co-ownership (co-w) graph over 5,548 user ac-
counts who reviewed 640 apps involved in fraud. Two ac-
counts are connected if they were predicted to be controlled
by the same fraudster. Partition algorithm identified 129
user account components, each potentially controlled by a
different fraudster. The largest cluster has 962 nodes and 54
components have more than 10 nodes.
i.e., the larger its value, the less likely it is that both accounts
belong to the same worker. Equivalently, contrary to the burstiness
assumption, the time difference for all reviews in common are rarely
similar. The sign effects of mean(Lij ) and SD(Lij ) are less intuitive.
We conjecture these sign effects are the result of existing correlation
across all variables. Further, mean(LRi j ) impacts negatively the
probability of co-ownership. Hence, accounts controlled by the
same worker tend to award similar star rating to their commonly
reviewed apps. However, we notice that rating features have the
least significant effect. This observation implies that most workers
post either positive or negative reviews.
11.5 Pseudonymous Fraudster Discovery
We applied the cowPred predictor with no sampling strategy and
GBM with Bernoulli loss function. We used 279,431 links from
5,690 unknown (un-attributed) user accounts that reviewed 640
suspicious apps. These accounts occurred in clusters without seed
accounts (unknown clusters). The resulting co-ownership graph
consists of 5,548 user accounts and 97,448 edges. Figure 7 shows
129 components identified by PFD. We conjecture that each of
these dense components is controlled by a different fraudster. In
the following, we validate this conjecture.
Result Validation. We use orthogonal evidence of fraud to validate
the dense components of Figure 7. Specifically, we inspect reviews’
text written by accounts in each cluster. Upon manual investigation,
we found many suspicious behaviors, including singular coinci-
dence: The review “this game is Really cute and awesome. I think
this is so addicting cause when my kid play this game; i can’t resist
her to playing it." was posted from three different accounts in the
same component for three different apps on the same date; the
−1012mean(Lij)uLmean(LRij)max(LRij)min(LRij)SD(Lij)mode(Lij)min(Lij)coclustercoreviewFeaturesRelative Importanceincludes worker expertise, developer reputation verifications, and
payment mechanisms. When underground fraud markets become
accessible to regular developers, they will also be accessible to re-
searchers, who can exploit the same vulnerabilities for ground truth
collection and fraud de-anonymization validation purposes.
Evasion strategies. Fraudsters can try to game the Detego system.
For instance, a fraudster can use multiple sets of disjoint accounts
and never use them while reviewing the same app. We observe
however that Detego introduces a tradeoff between the fraud op-
eration’s efficiency and its detectability. Decreasing account reuse
decreases profits, as reputable accounts are often preferred in search
rank fraud jobs [22, 68, 87]. Increasing account reuse exposes the
fraud operation to Detego detection and attribution. Thus, Detego
forces fraudsters to minimize account reuse and reduces review
fraud incentives.
Further, an adversarial developer who wants to boost the average
rating of her app, needs to commission a number of fake reviews
that is linear in the number of the app’s honest reviews [55]. Such
behavior however affects the temporal distribution of the app’s
reviews [55], which makes it detectable, i.e., through the inter-
review-time and rating-difference features of Detego.
Importance of seed fraud data. Detego can effectively provide
fraud de-anonymization only in the presence of seed ground truth
information about accounts controlled by known fraudsters. Fu-
ture work may explore the ability of cross-site identity linking
attacks [15, 16, 34, 62, 86] (see § 13) to e.g., link reviews of detected
Sybil communities to public profiles of crowdsourcing accounts.
Informed consent. To recruit 16 participants for the user study
of Section 10, we have contacted 320 fraud workers. This small
turnout may be due to a combination of factors, that include de-
serted accounts, lack of interest, and the online consent form used
as part of our IRB approved validation process. We note that the
16 participants were honest (a single “I don’t remember” among
80 test accounts). Future work may investigate the use of IRB ap-
proved deception to evaluate the impact of the consent form on the
number of participants, their honesty, and the precision of fraud
de-anonymization algorithms.
We believe that realization of consequences will not be a major
factor in the recruitment process. Our results suggest that reward
driven participation is enough for certain fraudsters. Proofs of
expertise are normal in crowdsourcing sites, where they enable
developers gain confidence when hiring workers. Thus, Detego’s
data collection (or variations) can blend in with regular recruitment
of fraud. Further, the use of deception may increase the probability
of successful recruiting.
Fraud account memorability. Search rank fraud workers can
control hundreds of accounts in the online system, which can im-
pact memorability. However, in our study, participants were able
to correctly detect ground truth controlled and non-controlled ac-
counts. The caveat is that we only presented participants with 5
test accounts. Future work should determine the maximum number
of questions that we can ask participants, before factors like fatigue
and boredom impact their honesty and accuracy.
I.i.d. assumption. UODA assumes that the review history of a
fraudulent user account is independent and identically distributed,
i.e., that an element in the sequence of reviews is independent of
Figure 8: Scatterplot for 71 fraudster communities (shown as
dots) discovered by PFD: the percentage of users who wrote
reviews that are at least 50% Jaccard similar to other reviews
(x axis) vs. the number of review pairs (in log scale) in each
component (y axis). 15 communities have at least 80% of
their user accounts suspected of plagiarism.
enthusiastic reviewer: A user account posted the review: “Try
it guys for who never use this app.. I’m enjoy and love app...thanks
very much.. because i really enjoy with this app...” for 40 apps in two
days; and the lazy high-level editors: We found 12 accounts in
one component that used the review “[App Name] It is very exciting.
I like it Nice app! Beautiful screenshot. Very interesting It is useful.
I like it so much” as a template to post reviews for 8 apps. The
fraudster would tailor this template by adding the name of the app
as a prefix.
In addition, similar to the validation in § 11.3, we have com-
puted the Jaccard similarity for every pair of reviews using their
text’s k-shingle representation with k = 3. We performed this cal-
culation over each of the 71 detected components with at least 6
accounts. This experiment generated a total of 1.1 billion Jaccard
pairs from 118,281 reviews belonging to 5,364 accounts. Moreover,
we evaluate the possibility that accounts responsible for reviews
with low similarity are generated by accounts not engaged in re-
view manipulation. Specifically, we first computed, a, the number
of user accounts in a component that posted reviews with Jaccard
similarity at least 0.5 to other reviews in that component. Next, we
computed, b, the total number of accounts for each of the selected
components. Finally, we computed the ratio a/b. Figure 8 highlights
fifteen components (1967 users) with ratio greater than 0.8. Very
few components have a ratio below 0.3. This result suggests that,
even for large components, users that generated very dissimilar
reviews are in fact also engaged in review manipulation that reuse
high amounts of text.
12 DISCUSSION AND LIMITATIONS
Underground fraud markets. If successful, the fraud de-anony-
mization approach proposed in this paper may drive fraudsters to
underground markets. This is however compatible with our objec-
tives, to degrade fraudster capabilities and real-life impact. Further,
we observe that Detego’s ground truth collection and solution vali-
dation approach, identifies and leverages intrinsic vulnerabilities in
the developer-to-fraudster interactions, i.e., developers need to ver-
ify claimed fraudster expertise and fraudsters need to make a profit.
Even underground markets need to provide basic functionality that
1021041061080.00.20.40.60.81.0RatioNumber of Pairs250500750Accountsthe element that came before it. A possible future work is to explore
UODA assuming a Markovian review-posting model.