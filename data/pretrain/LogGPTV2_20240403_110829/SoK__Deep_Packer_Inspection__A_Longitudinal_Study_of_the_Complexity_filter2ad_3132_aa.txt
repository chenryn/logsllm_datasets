title:SoK: Deep Packer Inspection: A Longitudinal Study of the Complexity
of Run-Time Packers
author:Xabier Ugarte-Pedrero and
Davide Balzarotti and
Igor Santos and
Pablo Garc&apos;ıa Bringas
2015 IEEE Symposium on Security and Privacy
SoK: Deep Packer Inspection: A Longitudinal
Study of the Complexity of Run-Time Packers
Xabier Ugarte-Pedrero∗, Davide Balzarotti†, Igor Santos∗, Pablo G. Bringas∗
∗ DeustoTech, University of Deusto
{xabier.ugarte, isantos, pablo.garcia.bringas}@deusto.es
Bilbao, Spain
† Eurecom
Sophia Antipolis, France
{davide.balzarotti}@eurecom.fr
Abstract—Run-time packers are often used by malware-writers
to obfuscate their code and hinder static analysis. The packer
problem has been widely studied, and several solutions have
been proposed in order to generically unpack protected binaries.
Nevertheless, these solutions commonly rely on a number of
assumptions that may not necessarily reﬂect the reality of the
packers used in the wild. Moreover, previous solutions fail to
provide useful information about the structure of the packer or
its complexity. In this paper, we describe a framework for packer
analysis and we propose a taxonomy to measure the runtime
complexity of packers.
We evaluated our dynamic analysis system on two datasets,
composed of both off-the-shelf packers and custom packed
binaries. Based on the results of our experiments, we present
several statistics about the packers complexity and their evolution
over time.
I. INTRODUCTION
Binary analysis is a time consuming task that requires a
considerable amount of effort even for experts in the ﬁeld.
Malware analysts need to deal with different obfuscation
techniques that are commonly employed to hinder static and
dynamic analysis, delay the reverse-engineering of the sam-
ples, and complicate their detection and classiﬁcation. Run-
time packers, originally designed to reduce the size of exe-
cutables, rapidly became one of the most common obfuscation
techniques adopted by malware authors. They are now used by
the vast majority of malicious samples to protect and encrypt
their data and code sections – which are then restored at run-
time by a dedicated unpacking routine.
Run-time packers have been thoroughly studied in the
literature, and several solutions have been proposed for their
analysis and unpacking [1]–[6]. Most of these solutions are
based on the dynamic execution of the sample (e.g., by an
emulator or a debugger) and rely on different heuristics to
detect the end of the unpacking routine, and therefore the
correct moment to dump the content of the process memory.
Other solutions [7] have proposed static analysis techniques
to extract the unpacking code. Nearly all antivirus software
adopt a more or less sophisticated form of these techniques
to provide some form of generic unpacking before applying
their signatures and heuristics.
Given the early success of these efforts, the research com-
munity quickly moved on – turning its attention to other
forms of code protection. For instance, several recent studies
have focused on virtualization-based protectors [8], [9], which
involve a new set of challenges, and stand as a completely
separate and still unsolved problem.
Unfortunately, traditional packers are still used by the vast
majority of the malware in the wild – and the problem of
how to perform runtime unpacking of their code is far from
being solved. In fact, traditional solutions rely on a number
of assumptions that are not necessarily met by common run-
time packers. In particular, they often assume that (i) there
is a moment in time in which the entire original code is
unpacked in memory, (ii) if a sample contains multiple layers
of packing, these are unpacked in sequence and the original
application code is the one decoded in the last layer, (iii)
the execution of the packer and the original application are
not mangled together (i.e., there is a precise point in time
in which the packer transfers the control to the original entry
point), and (iv) the unpacking code and the original code run in
the same process with no inter-process communication. These
simpliﬁcations make previous approaches unsuitable to handle
the real challenges encountered in complex run-time packers.
Moreover, while there are several tools and on-line services
available for malware analysis, there are no equivalent tools for
the analysis of run-time packers. Available generic unpackers
rely on heuristics that can be easily evaded, and are often
tailored to work only for a speciﬁc packer family and version.
This brings us to the ﬁrst of two sets of questions we want
to address in this paper. To begin with, we are interested in
understanding the level of complexity of the existing packers
that are used to protect malware. How many of them satisfy
the simple assumptions made by existing unpacking tools and
techniques? What is the maximum level of sophistication that
is observed in the wild? And how many malware families are
at this end of the spectrum?
To achieve this goal we present a new ﬁne-grained dynamic
analysis system designed to collect a large amount of infor-
mation from the execution of packed binaries. The collected
data is then analyzed and used to build an unpacking graph
and a number of indicators that summarize the features and
internal characteristics of the packer.
Our experiments with this tool lead to the second open
© 2015, Xabier Ugarte-Pedrero. Under license to IEEE.
DOI 10.1109/SP.2015.46
659
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:03:07 UTC from IEEE Xplore.  Restrictions apply. 
question we address in this paper. It is well known that the
malware writer often relies on off-the-shelf packers to protect
and obfuscate the code. Tools like Armadillo, ASProtect, and
Yodas are well known both in the underground market and
by malware analysts. We used our framework to help us un-
derstanding the level of sophistication of these tools, covering
over 580 different packer conﬁgurations in our experiments.
However, there is another side of dynamic unpacking that
has never been studied before. In fact, malware writers often
decide to avoid existing tools, and implement instead their own
custom packing routines.
Recent reports [10] claim that new protection engines are
discovered every day. Furthermore, 35% of packed malware
is protected with routines designed and coded by the author,
avoiding commercial (and thus well-known) packers [11], [12].
How widespread are these custom packing routines? How
sophisticated are they compared to the ones adopted by off-
the-shelf packers? And ﬁnally, how is the packing landscape
changing and evolving over the years? Are they becoming
more diversiﬁed? More complex?
To answer this second set of questions we performed
the ﬁrst longitudinal study of malware packing. Using real
malware collected over a period of 7 years, from mid-2007
to mid-2014, we performed a comprehensive evaluation of the
complexity of known and custom packers. Our results outline
for the ﬁrst time the evolution and trends of packed malware
across the last decade.
To summarize, this paper makes the following contributions:
• We propose a taxonomy for run-time packers to measure
their structural complexity.
• We develop a complete framework to analyze the com-
plexity of run-time packers.
• We perform a thorough study of the complexity of both
off-the-shelf packers and custom packed malware submit-
ted to the Anubis on-line sandbox covering a period of 7
years.
The rest of the paper is organized as follows. Section II
presents our taxonomy of packer characteristics and the tech-
nique we designed to analyze and model their complexity.
Section III presents the technical
implementation of our
framework, that allows to measure the different complexity
aspects covered by our taxonomy. Section IV describes several
interesting packers we found during this research. Section V
describes the longitudinal experiments we performed with our
tool to collect information about thousands of custom and off-
the-shelf packers. Section VI discusses the results obtained
and the implications of our ﬁndings. Section VII describes the
related work on this topic, and ﬁnally, Section VIII concludes
the paper.
II. A PACKER TAXONOMY
The most simple form of run-time packer consists of a small
routine executed at the beginning of a program to overwrite a
certain memory range with either the decompressed, deobfus-
cated, or decrypted code of the original application. After the
unpacking routine has terminated, the execution is redirected
to the original entry point (OEP) located in the unpacked
region (an operation often called “tail jump”).
More complex packers often involve several layers of un-
packing routines, in which the ﬁrst layer unpacks the second
one, which in turn unpacks another routine, until the original
code is reconstructed at the end of the chain. Others employ
several parallel processes, they interleave the execution of
unpacking code with the original code, or even incrementally
unpack and re-pack the code on-demand before and after its
execution.
To model this entire spectrum of different behaviors, we
propose a number of features designed to capture the different
aspects of an unpacking process. All these metrics are then
combined in a single taxonomy that classiﬁes packers into six
classes of incremental complexity.
Unpacking Layers
Previous approaches [2]–[4] have proposed different models
to capture the self-modifying behavior that is typical of a
runtime packer. All models are generally built around the
concept of unpacking layers. A layer is, intuitively, a set of
memory addresses that are executed after being written by
code in another layer. When the binary starts its execution,
the instructions loaded from its image ﬁle belong to the layer
L0. Later on, if an address written by any of those instructions
is executed, it will be marked as part of the next layer (in this
case layer L1). The concept of layer, under different names,
was already used by some of the generic unpackers proposed
in the past (e.g., Renovo [4]), but
it was not formalized
until Debray et al. [13] ﬁrst (under the name of execution
phases), and Guizani et al. [14] later (with the name of code
waves). Unfortunately, execution phases and code waves were
designed to model simple packers, and fail to summarize some
of the packer properties present in a large fraction of packers
used by malware writers. For instance, an instruction-based
shifting-decode packer (see the Code Visibility section for real
examples of this category) would generate a different “wave”
for each instruction of the application.
For this reason, our concept of layers is more conservative
than the previous deﬁnitions, and it is designed to only capture
how “deep” a sequence of instructions is into the unpacking
process. More formally, we deﬁne an execution layer Li as a
tuple (Xi,Wi), where Xi is the set of instructions executed at
that layer, and Wi represents the memory addresses modiﬁed
by those instructions. During the execution of a binary, we
maintain a set L = {L0,L1,L2, ...,Lmaxl} where maxl is the
innermost execution layer (i.e., the deepest unpacked layer) of
the binary. When the program is loaded into memory, there
is one single execution layer in L: L0(∅,∅). Intuitively, if
an instruction is located at a memory address that has been
modiﬁed by a different layer, its layer is determined by the
highest layer (not necessarily the latest) that modiﬁed that
area of memory. This may seem counter-intuitive at ﬁrst. In
fact, suppose that a region of memory, before being executed,
is ﬁrst written by layer L4 and then overwritten again from
660
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:03:07 UTC from IEEE Xplore.  Restrictions apply. 
layer L2. This behavior is not rare, especially in multi-layer
packers. For instance, every layer may unpack the next one,
and then transfer the control back to a previous layer (L2
in our example) that is responsible for ﬁxing some details in
the code or for applying a ﬁnal de-obfuscation pass. For this
reason, we place this new area of memory at layer L5 and not
at layer L3.
Parallel Unpackers
Many packers employ several processes in order to unpack
the original code. Some packers take the form of droppers and
create a ﬁle that is afterwards executed, while others create a
separate process and then inject the unpacked code into it.
in our model we monitor all
However, it is important to differentiate between processes
involved in the unpacking operation, and processes that are
part of the payload (i.e., the original code) of the protected
binary. For this reason,
the
processes involved in the execution of a binary, but we only
consider that those processes are part of the packer if we
observe an interaction among them – if they write to one
another address space. In Section III we explain how this
interaction can be performed, and how we monitor different
system events to capture it.
later in this section,
We also record the number of threads created for every
monitored process. As we detail
the
parallel execution of threads has an impact over the complexity
of the packer.
Transition Model
A transition between two layers occurs when an instruction
at layer Li is followed by an instruction at layer Lj with i(cid:54)=j.
In particular, forward transitions (j > i) bring the execution to
a higher layer, while backward transitions (j < i) jump back
to a previously unpacked layer.
In the simplest case, there is only one transition from each
layer (typically at the end of the unpacking routine) to the
next one (the beginning of the following unpacking routine
or the original entry point of the application). In this case, if
a packer has N execution layers, there are obviously N − 1
layer transitions. In our taxonomy, we refer to this behavior as
a linear transition model. In case a packer does not satisfy this
deﬁnition, and therefore contains backward transitions from a
layer to one of its predecessors, we say that it has a cyclic
transition model.
An important aspect that can affect the transition model
is the scheduling of the operating system. For instance, a
packer can create two threads which execute in parallel code
located in different layers, one for the original code and one
for monitoring the execution and introducing anti-debugging
routines. In this scenario, we would observe a layer transition
for each thread context switch. We classify these types of
packers as cyclic, since different layers are indeed interleaved
in the ﬁnal execution (intentionally or not).
Packer Isolation
This feature measures the interaction between the unpacking
code and the original program. Simple packers ﬁrst execute
all the packer code, and once the original application has
been recovered, the execution is redirected to it. For these
cases, a tail transition exists to separate the two independent
executions. Note that in some complex cases the execution
of the packer and the application code are isolated, even
though the line that separates the two is located inside a
single layer. For instance a packer may eventually unpack a
snippet of bootstrap code which resides at the same layer of
the original code, and the jump to the original entry point
might take place between these two regions located in the
same layer. However, since the bootstrap code does not modify
the unpacked code (otherwise they would reside in different
layers) the last transition can be considered a tail transition
without losing any generality.
If a packer does not meet the previous deﬁnition we consider
its execution model as interleaved. In an interleaved packer,
the execution of certain parts of the unpacking routine is
mixed with the original application code. In some cases, this
is achieved by hooking the Import Address Table to point
to routines in the packer code. This approach can be used to
obfuscate the use of API functions by redirecting them through
the unpacking code. It is also used by parallel packers to
implement anti-debugging and anti-tampering techniques that
get regularly executed even during the execution of the original
code. Finally, interleaved layers are the basic blocks required
to implement multi-frame unpackers.
Unpacking Frames
One form of interaction between the protected code and the
unpacking routine can lead to a situation in which part of the
code (either the unpacking routine or the original binary) is
written at different times. To model this behavior, we introduce
the concept of Frame. Intuitively, an unpacking frame is a