The exploitation of memory corruption bugs often re-
quires knowledge of addresses of speciﬁc data.
In or-
der to impede such attacks, address space layout ran-
domization (ASLR) has been introduced as well as non-
executable stacks and stack canaries. To protect the
kernel, kernel ASLR (KASLR) randomizes the offsets
where drivers are located on every boot, making attacks
harder as they now require to guess the location of kernel
data structures. However, side-channel attacks allow to
detect the exact location of kernel data structures [21, 29,
37] or derandomize ASLR in JavaScript [16]. A com-
bination of a software bug and the knowledge of these
addresses can lead to privileged code execution.
2.3 Cache Attacks
In order to speed-up memory accesses and address trans-
lation, the CPU contains small memory buffers, called
caches, that store frequently used data. CPU caches hide
slow memory access latencies by buffering frequently
used data in smaller and faster internal memory. Mod-
ern CPUs have multiple levels of caches that are either
private per core or shared among them. Address space
translation tables are also stored in memory and, thus,
also cached in the regular caches.
Cache side-channel attacks exploit timing differences
that are introduced by the caches. Different cache attack
techniques have been proposed and demonstrated in the
past, including Evict+Time [55], Prime+Probe [55, 56],
and Flush+Reload [63]. Flush+Reload attacks work on
a single cache line granularity. These attacks exploit the
shared, inclusive last-level cache. An attacker frequently
ﬂushes a targeted memory location using the clflush
instruction. By measuring the time it takes to reload the
data, the attacker determines whether data was loaded
into the cache by another process in the meantime. The
Flush+Reload attack has been used for attacks on various
computations, e.g., cryptographic algorithms [63, 36, 4],
web server function calls [65], user input [23, 47, 58],
and kernel addressing information [21].
A special use case of a side-channel attack is a covert
channel. Here the attacker controls both, the part that in-
duces the side effect, and the part that measures the side
effect. This can be used to leak information from one
security domain to another, while bypassing any bound-
aries existing on the architectural level or above. Both
Prime+Probe and Flush+Reload have been used in high-
performance covert channels [48, 52, 22].
3 A Toy Example
In this section, we start with a toy example, i.e., a simple
code snippet, to illustrate that out-of-order execution can
change the microarchitectural state in a way that leaks
information. However, despite its simplicity, it is used as
a basis for Section 4 and Section 5, where we show how
this change in state can be exploited for an attack.
Listing 1 shows a simple code snippet ﬁrst raising an
(unhandled) exception and then accessing an array. The
property of an exception is that the control ﬂow does not
continue with the code after the exception, but jumps to
an exception handler in the operating system. Regardless
976    27th USENIX Security Symposium
USENIX Association
Physicalmemory0maxUser0247Kernel−247−11 raise_exception();
2 // the line below is never reached
3 access(probe_array[data * 4096]);
Listing 1: A toy example to illustrate side-effects of out-
of-order execution.
Figure 3: If an executed instruction causes an exception,
diverting the control ﬂow to an exception handler, the
subsequent instruction must not be executed. Due to out-
of-order execution, the subsequent instructions may al-
ready have been partially executed, but not retired. How-
ever, architectural effects of the execution are discarded.
of whether this exception is raised due to a memory ac-
cess, e.g., by accessing an invalid address, or due to any
other CPU exception, e.g., a division by zero, the control
ﬂow continues in the kernel and not with the next user
space instruction.
Thus, our toy example cannot access the array in the-
ory, as the exception immediately traps to the kernel and
terminates the application. However, due to the out-of-
order execution, the CPU might have already executed
the following instructions as there is no dependency on
the instruction triggering the exception. This is illus-
trated in Figure 3. Due to the exception, the instructions
executed out of order are not retired and, thus, never have
architectural effects.
Although the instructions executed out of order do not
have any visible architectural effect on registers or mem-
ory, they have microarchitectural side effects. During the
out-of-order execution, the referenced memory is fetched
into a register and also stored in the cache. If the out-
of-order execution has to be discarded, the register and
memory contents are never committed. Nevertheless, the
cached memory contents are kept in the cache. We can
leverage a microarchitectural side-channel attack such
as Flush+Reload [63], which detects whether a speciﬁc
memory location is cached, to make this microarchitec-
tural state visible. Other side channels can also detect
whether a speciﬁc memory location is cached, including
Prime+Probe [55, 48, 52], Evict+Reload [47], or Flush+
Flush [22]. As Flush+Reload is the most accurate known
cache side channel and is simple to implement, we do not
consider any other side channel for this example.
Figure 4: Even if a memory location is only accessed
during out-of-order execution, it remains cached. Iterat-
ing over the 256 pages of probe array shows one cache
hit, exactly on the page that was accessed during the out-
of-order execution.
Based on the value of data in this example, a different
part of the cache is accessed when executing the memory
access out of order. As data is multiplied by 4096, data
accesses to probe array are scattered over the array
with a distance of 4 KB (assuming an 1 B data type for
probe array). Thus, there is an injective mapping from
the value of data to a memory page, i.e., different values
for data never result in an access to the same page. Con-
sequently, if a cache line of a page is cached, we know
the value of data. The spreading over pages eliminates
false positives due to the prefetcher, as the prefetcher
cannot access data across page boundaries [32].
Figure 4 shows the result of a Flush+Reload measure-
ment iterating over all pages, after executing the out-of-
order snippet with data = 84. Although the array ac-
cess should not have happened due to the exception, we
can clearly see that the index which would have been ac-
cessed is cached.
Iterating over all pages (e.g., in the
exception handler) shows only a cache hit for page 84
This shows that even instructions which are never actu-
ally executed, change the microarchitectural state of the
CPU. Section 4 modiﬁes this toy example not to read a
value but to leak an inaccessible secret.
4 Building Blocks of the Attack
The toy example in Section 3 illustrated that side-effects
of out-of-order execution can modify the microarchitec-
tural state to leak information. While the code snippet
reveals the data value passed to a cache-side channel, we
want to show how this technique can be leveraged to leak
otherwise inaccessible secrets. In this section, we want
to generalize and discuss the necessary building blocks
to exploit out-of-order execution for an attack.
The adversary targets a secret value that is kept some-
where in physical memory. Note that register contents
are also stored in memory upon context switches, i.e.,
they are also stored in physical memory. As described in
Section 2.2, the address space of every process typically
includes the entire user space, as well as the entire kernel
USENIX Association
27th USENIX Security Symposium    977
...[Exception]EXECUTEDEXECUTEDOUTOFORDEREXCEPTIONHANDLER[Terminate]050100150200250200300400500PageAccesstime[cycles]building blocks to run a transient instruction sequence
with a dependency on a secret value.
The second building block of Meltdown is to transfer
the microarchitectural side effect of the transient instruc-
tion sequence to an architectural state to further process
the leaked secret. Thus, the second building described
in Section 4.2 describes building blocks to transfer a mi-
croarchitectural side effect to an architectural state using
a covert channel.
4.1 Executing Transient Instructions
The ﬁrst building block of Meltdown is the execution
of transient instructions. Transient instructions occur all
the time, as the CPU continuously runs ahead of the
current instruction to minimize the experienced latency
and, thus, to maximize the performance (cf. Section 2.1).
Transient instructions introduce an exploitable side chan-
nel if their operation depends on a secret value. We focus
on addresses that are mapped within the attacker’s pro-
cess, i.e., the user-accessible user space addresses as well
as the user-inaccessible kernel space addresses. Note that
attacks targeting code that is executed within the context
(i.e., address space) of another process are possible [40],
but out of scope in this work, since all physical memory
(including the memory of other processes) can be read
through the kernel address space regardless.
Accessing user-inaccessible pages, such as kernel
pages, triggers an exception which generally terminates
the application. If the attacker targets a secret at a user-
inaccessible address, the attacker has to cope with this
exception. We propose two approaches: With excep-
tion handling, we catch the exception effectively occur-
ring after executing the transient instruction sequence,
and with exception suppression, we prevent the excep-
tion from occurring at all and instead redirect the control
ﬂow after executing the transient instruction sequence.
We discuss these approaches in detail in the following.
Exception handling. A trivial approach is to fork the
attacking application before accessing the invalid mem-
ory location that terminates the process and only access
the invalid memory location in the child process. The
CPU executes the transient instruction sequence in the
child process before crashing. The parent process can
then recover the secret by observing the microarchitec-
tural state, e.g., through a side-channel.
It is also possible to install a signal handler that is exe-
cuted when a certain exception occurs, e.g., a segmenta-
tion fault. This allows the attacker to issue the instruction
sequence and prevent the application from crashing, re-
ducing the overhead as no new process has to be created.
Figure 5: The Meltdown attack uses exception handling
or suppression, e.g., TSX, to run a series of transient in-
structions. These transient instructions obtain a (persis-
tent) secret value and change the microarchitectural state
of the processor based on this secret value. This forms
the sending part of a microarchitectural covert chan-
nel. The receiving side reads the microarchitectural state,
making it architectural and recovers the secret value.
space, which typically also has all physical memory (in-
use) mapped. However, these memory regions are only
accessible in privileged mode (cf. Section 2.2).
In this work, we demonstrate leaking secrets by by-
passing the privileged-mode isolation, giving an attacker
full read access to the entire kernel space, including
any physical memory mapped and, thus, the physical
memory of any other process and the kernel. Note that
Kocher et al. [40] pursue an orthogonal approach, called
Spectre Attacks, which trick speculatively executed in-
structions into leaking information that the victim pro-
cess is authorized to access. As a result, Spectre Attacks
lack the privilege escalation aspect of Meltdown and re-
quire tailoring to the victim process’s software environ-
ment, but apply more broadly to CPUs that support spec-
ulative execution and are not prevented by KAISER.
The full Meltdown attack consists of two building
blocks, as illustrated in Figure 5. The ﬁrst building block
of Meltdown is to make the CPU execute one or more
instructions that would never occur in the executed path.
In the toy example (cf. Section 3), this is an access to
an array, which would normally never be executed, as
the previous instruction always raises an exception. We
call such an instruction, which is executed out of order
and leaving measurable side effects, a transient instruc-
tion. Furthermore, we call any sequence of instructions
containing at least one transient instruction a transient
instruction sequence.
In order to leverage transient instructions for an attack,
the transient instruction sequence must utilize a secret
value that an attacker wants to leak. Section 4.1 describes
978    27th USENIX Security Symposium
USENIX Association
ExceptionHandling/SuppressionTransientInstructionsSecretMicroarchitecturalStateChangeSection4.1ArchitecturalStateTransfer(CovertChannel)RecoveredSecretRecoveryLeakedAccessedSection4.2Exception suppression. A different approach to deal
with exceptions is to prevent them from being raised in
the ﬁrst place. Transactional memory allows to group
memory accesses into one seemingly atomic operation,
giving the option to roll-back to a previous state if an er-
ror occurs. If an exception occurs within the transaction,
the architectural state is reset, and the program execution
continues without disruption.
Furthermore, speculative execution issues instructions
that might not occur on the executed code path due to
a branch misprediction. Such instructions depending on
a preceding conditional branch can be speculatively ex-
ecuted. Thus, the invalid memory access is put within
a speculative instruction sequence that is only executed
if a prior branch condition evaluates to true. By making
sure that the condition never evaluates to true in the ex-
ecuted code path, we can suppress the occurring excep-
tion as the memory access is only executed speculatively.
This technique may require sophisticated training of the
branch predictor. Kocher et al. [40] pursue this approach
in orthogonal work, since this construct can frequently
be found in code of other processes.
4.2 Building a Covert Channel
The second building block of Meltdown is the transfer
of the microarchitectural state, which was changed by
the transient instruction sequence, into an architectural
state (cf. Figure 5). The transient instruction sequence
can be seen as the sending end of a microarchitectural
covert channel. The receiving end of the covert channel
receives the microarchitectural state change and deduces
the secret from the state. Note that the receiver is not
part of the transient instruction sequence and can be a
different thread or even a different process e.g., the parent
process in the fork-and-crash approach.
We leverage techniques from cache attacks, as the
cache state is a microarchitectural state which can be re-
liably transferred into an architectural state using vari-
ous techniques [55, 63, 22]. Speciﬁcally, we use Flush+
Reload [63], as it allows to build a fast and low-noise
covert channel. Thus, depending on the secret value, the
transient instruction sequence (cf. Section 4.1) performs
a regular memory access, e.g., as it does in the toy exam-
ple (cf. Section 3).
After the transient instruction sequence accessed an
accessible address, i.e., this is the sender of the covert
channel; the address is cached for subsequent accesses.
The receiver can then monitor whether the address has
been loaded into the cache by measuring the access time
to the address. Thus, the sender can transmit a ‘1’-bit by
accessing an address which is loaded into the monitored
cache, and a ‘0’-bit by not accessing such an address.
Using multiple different cache lines, as in our toy ex-
ample in Section 3, allows to transmit multiple bits at
once. For every of the 256 different byte values, the
sender accesses a different cache line. By performing
a Flush+Reload attack on all of the 256 possible cache
lines, the receiver can recover a full byte instead of just
one bit. However, since the Flush+Reload attack takes
much longer (typically several hundred cycles) than the
transient instruction sequence, transmitting only a single
bit at once is more efﬁcient. The attacker can simply do
that by shifting and masking the secret value accordingly.
Note that the covert channel is not limited to microar-
chitectural states which rely on the cache. Any microar-
chitectural state which can be inﬂuenced by an instruc-
tion (sequence) and is observable through a side channel
can be used to build the sending end of a covert channel.
The sender could, for example, issue an instruction (se-
quence) which occupies a certain execution port such as
the ALU to send a ‘1’-bit. The receiver measures the la-
tency when executing an instruction (sequence) on the
same execution port. A high latency implies that the
sender sends a ‘1’-bit, whereas a low latency implies
that sender sends a ‘0’-bit. The advantage of the Flush+
Reload cache covert channel is the noise resistance and
the high transmission rate [22]. Furthermore, the leakage
can be observed from any CPU core [63], i.e., reschedul-
ing events do not signiﬁcantly affect the covert channel.
5 Meltdown
In this section, we present Meltdown, a powerful at-
tack allowing to read arbitrary physical memory from
an unprivileged user program, comprised of the build-
ing blocks presented in Section 4. First, we discuss the
attack setting to emphasize the wide applicability of this
attack. Second, we present an attack overview, show-
ing how Meltdown can be mounted on both Windows
and Linux on personal computers, on Android on mo-
bile phones as well as in the cloud. Finally, we discuss a
concrete implementation of Meltdown allowing to dump