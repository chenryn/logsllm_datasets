ther increases the congestion window linearly (diff  β ), or leaves it unchanged.
Compound TCP [39] combines ideas from Reno and Vegas:
when packet losses occur, it uses Reno’s adaptation, while react-
ing to delay variations using ideas from Vegas. Compound TCP is
more complicated than a straightforward hybrid of Reno and Ve-
gas; for example, the delay-based window adjustment uses a bino-
mial algorithm [6]. Compound TCP uses the delay-based window
to identify the absence of congestion rather than its onset, which is
a key difference from Vegas.
Rhee and Xu’s Cubic algorithm is an improvement over their pre-
vious work on BIC [45]. Cubic’s growth is independent of the RTT
(like H-TCP [29]), and depends only on the packet loss rate, in-
crementing as a cubic function of “real” time. Cubic is known to
achieve high throughput and fairness independent of RTT, but it
also aggressively increases its window size, inﬂating queues and
bloating RTTs (see §5).
Other schemes developed in the literature include equation-
based congestion control [16], binomial control [6], FastTCP [42],
HSTCP, and TCP Westwood [30].
End-to-end control may be improved with explicit router par-
ticipation, as in Explicit Congestion Notiﬁcation (ECN) [15],
VCP [44], active queue management schemes like RED [17],
BLUE [14], CHOKe [35], AVQ [27], and CoDel [33] fair queue-
ing, and explicit methods such as XCP [24] and RCP [38]. AQM
schemes aim to prevent persistent queues, and have largely focused
on reacting to growing queues by marking packets with ECN or
dropping them even before the queue is full. CoDel changes the
model from reacting to speciﬁc average queue lengths to reacting
when the delays measured over some duration are too long, sug-
gesting a persistent queue. Scheduling algorithms isolate ﬂows or
groups of ﬂows from each other, and provide weighted fairness be-
tween them. In XCP and RCP, routers place information in packet
headers to help the senders determine their window (or rate). One
limitation of XCP is that it needs to know the bandwidth of the out-
going link, which is difﬁcult to obtain accurately for a time-varying
wireless channel.
In §5, we compare Remy’s generated algorithm with XCP and
with end-to-end schemes running through a gateway with the CoDel
AQM and stochastic fair queueing (sfqCoDel).
TCP congestion control was not designed with an explicit opti-
mization goal in mind, but instead allows overall network behav-
ior to emerge from its rules. Kelly et al. present an interpretation
of various TCP congestion-control variants in terms of the implicit
goals they attempt to optimize [25]. This line of work has become
known as Network Utility Maximization (NUM); more recent work
has modeled stochastic NUM problems [46], in which ﬂows enter
and leave the network. Remy may be viewed as combining the de-
sire for practical distributed endpoint algorithms with the explicit
utility-maximization ethos of stochastic NUM.
We note that TCP stacks have adapted in some respects to the
changing Internet; for example, increasing bandwidth-delay prod-
ucts have produced efforts to increase the initial congestion win-
dow [13, 11], including recent proposals [3, 40] for this quantity to
automatically increase on the timescale of months or years. What
we propose in this paper is an automated means by which TCP’s en-
tire congestion-control algorithm, not just its initial window, could
adapt in response to empirical variations in underlying networks.
3. MODELING THE CONGESTION-CONTROL
PROBLEM
We treat congestion control as a problem of distributed decision-
making under uncertainty. Each endpoint that has pending data
must decide for itself at every instant: send a packet, or don’t send
a packet.
If all nodes knew in advance the network topology and capacity,
and the schedule of each node’s present and future offered load,
such decisions could in principle be made perfectly, to achieve a
desired allocation of throughput on shared links.
In practice, however, endpoints receive observations that only
hint at this information. These include feedback from receivers con-
cerning the timing of packets that arrived and detection of packets
that didn’t, and sometimes signals, such as ECN marks, from within
the network itself. Nodes then make sending decisions based on this
partial information about the network.
Our approach hinges on being able to evaluate quantitatively the
merit of any particular congestion control algorithm, and search for
the best algorithm for a given network model and objective func-
tion. We discuss here our models of the network and cross trafﬁc,
and how we ultimately calculate a ﬁgure of merit for an arbitrary
congestion control algorithm.
3.1 Expressing prior assumptions about the network
From a node’s perspective, we treat the network as having been
drawn from a stochastic generative process. We assume the network
is Markovian, meaning that it is described by some state (e.g. the
packets in each queue) and its future evolution will depend only on
the current state.
Currently, we typically parametrize networks on three axes: the
speed of bottleneck links, the propagation delay of the network
paths, and the degree of multiplexing, i.e., the number of senders
125contending for each bottleneck link. We assume that senders have
no control over the paths taken by their packets to the receiver.
Depending on the range of networks over which the protocol
is intended to be used, a node may have more or less uncertainty
about the network’s key parameters. For example, in a data center,
the topology, link speeds, and minimum round-trip times may be
known in advance, but the degree of multiplexing could vary over a
large range. A virtual private network between “clouds” may have
more uncertainty about the link speed. A wireless network path
may experience less multiplexing, but a large range of transmission
rates and round-trip times.
As one might expect, we have observed a tradeoff between gen-
erality and performance; a protocol designed for a broad range of
networks may be beaten by a protocol that has been supplied with
more speciﬁc and accurate prior knowledge. Our approach allows
protocol designers to measure this tradeoff and choose an appropri-
ate design range for their applications.
3.2 Trafﬁc model
Remy models the offered load as a stochastic process that
switches unicast ﬂows between sender-receivers pairs on or off. In
a simple model, each endpoint has trafﬁc independent of the other
endpoints. The sender is “off” for some number of seconds, drawn
from an exponential distribution. Then it switches on for some
number of bytes to be transmitted, drawn from an empirical distri-
bution of ﬂow sizes or a closed-form distribution (e.g. heavy-tailed
Pareto). While “on,” we assume that the sender will not stall until
it completes its transfer.
In trafﬁc models characteristic of data center usage, the off-to-on
switches of contending ﬂows may cluster near one another in time,
leading to incast. We also model the case where senders are “on”
for some amount of time (as opposed to bytes) and seek maximum
throughput, as in the case of videoconferences or similar real-time
trafﬁc.
3.3 Objective function
Resource-allocation theories of congestion control have tradi-
tionally employed the alpha-fairness metric to evaluate allocations
of throughput on shared links [37]. A ﬂow that receives steady-state
1−α . As α → 1, in
throughput of x is assigned a score of Uα (x) = x1−α
the limit U1(x) becomes logx.
Because Uα (x) is concave for α > 0 and monotonically increas-
ing, an allocation that maximizes the total score will prefer to divide
the throughput of a bottleneck link equally between ﬂows. When
this is impossible, the parameter α sets the tradeoff between fair-
ness and efﬁciency. For example, α = 0 assigns no value to fairness
and simply measures total throughput. α = 1 is known as propor-
tional fairness, because it will cut one user’s allocation in half as
long as another user’s can be more than doubled. α = 2 corre-
sponds to minimum potential delay fairness, where the score goes
as the negative inverse of throughput; this metric seeks to minimize
the total time of ﬁxed-length ﬁle transfers. As α → ∞, maximizing
the total Uα (x) achieves max-min fairness, where all that matters is
the minimum resource allocations in bottom-up order [37].
Because the overall score is simply a sum of monotonically in-
creasing functions of throughput, an algorithm that maximizes this
total is Pareto-efﬁcient for any value of α; i.e., the metric will al-
ways prefer an allocation that helps one user and leaves all other
users the same or better. Tan et al. [28] proved that, subject to the
requirement of Pareto-efﬁciency, alpha-fairness is the metric that
places the greatest emphasis on fairness for a particular α.
Kelly et al. [25] and further analyses showed that TCP approxi-
mately maximizes minimum potential delay fairness asymptotically
in steady state, if all losses are congestive and link speeds are ﬁxed.
We extend this model to cover dynamic trafﬁc and network con-
ditions. Given a network trace, we calculate the average throughput
x of each ﬂow, deﬁned as the total number of bytes received divided
by the time that the sender was “on.” We calculate the average
round-trip delay y of the connection.
The ﬂow’s score is then
Uα (x)− δ ·Uβ (y),
(1)
where α and β express the fairness-vs.-efﬁciency tradeoffs in
throughput and delay, respectively, and δ expresses the relative im-
portance of delay vs. throughput.
We emphasize that the purpose of the objective function is to sup-
ply a quantitative goal from a protocol-design perspective. It need
not (indeed, does not) precisely represent users’ “true” preferences
or utilities.
In real usage, different users may have different ob-
jectives; a videoconference may not beneﬁt from more throughput,
or some packets may be more important than others. We have not
yet addressed the problem of how to accommodate diverse objec-
tives or how endpoints might learn about the differing preferences
of other endpoints.
4. HOW REMY PRODUCES A CONGESTION-
CONTROL ALGORITHM
The above model may be viewed as a cooperative game that end-
points play. Given packets to transmit (offered load) at an endpoint,
the endpoint must decide when to send packets in order to maximize
its own objective function. With a particular congestion-control al-
gorithm running on each endpoint, we can calculate each endpoint’s
expected score.
In the traditional game-theoretic framework, an endpoint’s deci-
sion to send or abstain can be evaluated after ﬁxing the behavior
of all other endpoints. An endpoint makes a “rational” decision to
send if doing so would improve its expected score, compared with
abstaining.
Unfortunately, when greater individual throughput is the desired
objective, on a best-effort packet-switched network like the Inter-
net, it is always advantageous to send a packet. In this setting, if
every endpoint acted rationally in its own self-interest, the resulting
Nash equilibrium would be congestion collapse!1 This answer is
unsatisfactory from a protocol-design perspective, when endpoints
have the freedom to send packets when they choose, but the de-
signer wishes to achieve an efﬁcient and equitable allocation of net-
work capacity.
Instead, we believe the appropriate framework is that of superra-
tionality [20]. Instead of ﬁxing the other endpoints’ actions before
deciding how to maximize one endpoint’s expected score, what is
ﬁxed is the common (but as-yet unknown) algorithm run by all end-
points. As in traditional game theory, the endpoint’s goal remains
maximizing its own self-interest, but with the knowledge that other
endpoints are reasoning the same way and will therefore arrive at
the same algorithm.
Remy’s job is to ﬁnd what that algorithm should be. We refer
to a particular Remy-designed congestion-control algorithm as a
“RemyCC,” which we then implant into an existing sender as part
of TCP, DCCP [26], congestion manager [5], or another module
1Other researchers have grappled with this problem; for example,
Akella et al. [1] studied a restricted game, in which players are
forced to obey the same particular ﬂavor of TCP, but with the free-
dom to choose their additive-increase and multiplicative-decrease
coefﬁcients. Even with this constraint, the authors found that the
Nash equilibrium is inefﬁcient, unless the endpoints are restricted
to run TCP Reno over a drop-tail buffer, in which case the equilib-
rium is unfair but not inefﬁcient.
126running congestion control. The receiver is unchanged (as of now;
this may change in the future), but is expected to send periodic ACK
feedback.
Formally, we treat the problem of ﬁnding the best RemyCC under
uncertain network conditions as a search for the best policy for a de-
centralized partially-observable Markov decision process, or Dec-
POMDP [34]. This model originated from operations research and
artiﬁcial intelligence, in settings where independent agents work
cooperatively to achieve some goal. In the case of end-to-end con-
gestion control, endpoints are connected to a shared network that
evolves in Markovian fashion. At every time step, the agents must
choose between the actions of “sending” or “abstaining,” using ob-
servables from their receiver or from network infrastructure.
4.1 Compactly representing the sender’s state
In principle,
for any given network,
there is an optimal
congestion-control scheme that maximizes the expected total of the
endpoints’ objective functions. Such an algorithm would relate (1)
the entire history of observations seen thus far (e.g. the contents
and timing of every ACK) and (2) the entire history of packets al-
ready sent, to the best action at any given moment between sending
a new packet or abstaining. However, the search for such an algo-
rithm is likely intractable; on a general Dec-POMDP it is NEXP-
complete [8].
Instead, we approximate the solution by greatly abridging the
sender’s state. A RemyCC tracks just three state variables, which it
updates each time it receives a new acknowledgment:
1. An exponentially-weighted moving average (EWMA) of the
interarrival time between new acknowledgments received
(ack_ewma).
2. An exponentially-weighted moving average of the time be-
tween TCP sender timestamps reﬂected in those acknowledg-
ments (send_ewma). A weight of 1/8 is given to the new
sample in both EWMAs.
3. The ratio between the most recent RTT and the minimum
RTT seen during the current connection (rtt_ratio).
Together, we call these three variables the RemyCC memory. It is
worth reﬂecting on these variables, which are the “congestion sig-
nals” used by any RemyCC. We narrowed the memory to this set
after examining and discarding quantities like the most-recent RTT
sample, the smoothed RTT estimate, and the difference between the
long-term EWMA and short-term EWMA of the observed packet
rate or RTT. In our experiments, adding extra state variables didn’t
improve the performance of the resulting protocol, and each ad-
ditional dimension slows down the design procedure considerably.
But we don’t claim that Remy’s three state variables are the only
set that works, or that they are necessarily optimal for all situations
a protocol might encounter. We expect that any group of estimates
that roughly summarizes the recent history could form the basis of
a workable congestion-control scheme.
We note that a RemyCC’s memory does not include the two fac-
tors that traditional TCP congestion-control schemes use: packet
loss and RTT. This omission is intentional: a RemyCC that func-
tions well will see few congestive losses, because its objective func-