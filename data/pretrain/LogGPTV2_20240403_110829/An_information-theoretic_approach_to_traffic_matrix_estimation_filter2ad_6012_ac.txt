pected to be error-reducing, providing it is performed appropriately
(as here). Based on the experience of statisticians with shrinkage
estimation, it seems that we can expect this procedure to provide
at least some improvement in mean-squared error even though the
gravity model assumption may not be valid.
If the noise level in the data is small, of course, then the solu-
tion will not be allowed to be very close to the gravity model. In
the limit, as the noise level goes to zero, we obtain the solution by
minimizing K(p(s, d)||p(s)p(d)) subject to the constraints (13). In
effect we are looking for the most nearly independent version of
p(s, d) subject to generating the observed trafﬁc statistics.
3.5 Inter-domain Routing
3.5.1 Zero Transit Trafﬁc
The above algorithm assumes that independence of source and
destination is a reasonable starting model. However, there are good
reasons we may want to modify this starting model. In real back-
bone ISPs, routing is typically asymmetric due to hot-potato rout-
ing — trafﬁc from the customer edge to peers will be sent to the
“nearest” exit point, while trafﬁc in peer networks will do likewise
resulting in a different pattern for trafﬁc from peering to customers.
Also there should be no trafﬁc transiting the network from peer to
peer [28]. Both factors demand departures from pure independence.
Suppose we assume there is zero transit trafﬁc. We suggest that
conditional independence of source and destination, given appropri-
ate side information, will be more accurate than pure independence.
More speciﬁcally, suppose we have available as side information,
the source and destination class (access or peering). We would then
model the probabilities of a packet (bit) arriving at s and depart-
ing at d as conditionally independent given the class of arrival and
destination link. In Appendix A we show that this results in the fol-
lowing model, assuming A and P are the sets of access and peering
links, respectively.
pD (d)
pS (s)
pS (A)
pD (A)(1 − pS(P ) − pD(P )),
for s ∈ A, d ∈ A,
for s ∈ P, d ∈ A,
for s ∈ A, d ∈ P,
for s ∈ P, d ∈ P.
pS(s) pD (d)
pD (A) ,
pS (s)
pS (A) pD(d),
0,
(28)
pS,D(s, d) =
8>>>>>>>>>:
to which we can naturally adapt the algorithm above (by modifying
gi). We note that the algorithm is then ‘shrinking’ the observed
data in the direction, not of a pure gravity model, but a realistic
modiﬁcation of it.
(27)
3.5.2 Point to Multipoint
Note that in all these optimization problems, there are additional
constraints (on any probability distribution) such as non-negativity,
normalization, and (14) and (15). We leave all these implicit.
3.4 Algorithm
The problem we attack in this paper is the BR-to-BR trafﬁc ma-
trix. While this problem is an order of magnitude more complex
than a PoP-to-PoP trafﬁc matrix, a router-to-router trafﬁc matrix is
absolutely necessary for many network engineering tasks. A PoP-
to-PoP trafﬁc matrix is useful when designing a network from scratch,
but typically, in a real network changes are incremental, and so we
need to see how these changes affect trafﬁc at the router level. We
use techniques from [28] to reduce the size of the problem initially,
by removing redundant information, and a large number of trafﬁc
matrix elements that we know to be zero from routing information.
This processing does not improve accuracy, but does speed up later
computations.
To make the exact formulation explicit, we deﬁne
where
xi = N (si, di),
yj = trafﬁc counts = T (lj),
gi = N (si)N (di),
N = total trafﬁc in network
N (si) = total trafﬁc originating at si
N (di) = total trafﬁc departing at di
(21)
(22)
(23)
(24)
(25)
(26)
and we deﬁne the column vectors x, and y with elements xi and yi,
respectively. Our formulation is
minx||y − Ax||2 + λ
subject to xi ≥ 0.
2 Xi: gi>0
xi
N
log(cid:18) xi
gi(cid:19)
Note that gi = 0 if and only if the trafﬁc at the source or destination
is zero, and so xi = 0. The additional constraints on the marginal
distributions are satisﬁed by supplementing the routing matrix, and
measurements to ensure that they include these constraints.
This penalized least-squares formulation has been used in solv-
ing many other ill-posed problems, and so there exist publicly avail-
able software in Matlab (such as routine MaxEnt in Per Christian
Hansen’s Inverse Problems Toolbox [9, 10]) to solve small-scale
variants of such problems. Our problems are, however, large in scale
and not suited to such basic implementations. The problem of solv-
ing such large-scale trafﬁc matrices is only possible if we can exploit
one of the main properties of routing matrices: they are very sparse
— the proportion of exact zero entries in each column and row is
overwhelming. Accordingly, we use PDSCO [5], a MATLAB pack-
age developed by Michael Saunders of Stanford University, which
has been highly optimized to solve problems with sparse matrices
A. PDSCO has been used (see e.g. [5]) to solve problems of the
order 16,000 by 256,000 efﬁciently. We have found that its perfor-
mance is very good (taking no more than a few seconds) even on the
largest problems we consider here.
In principle, the choice of λ depends on the noise level in the
measurements, but in our results below we show that the results are
insensitive to this parameter, and so its exact choice isn’t important.
An interesting point is that if one were to have additional infor-
mation such as used in the choice model of [16] then this could
also be incorporated by conditioning the initial model PS,D(s, d)
on this information (for an example of this type see Section 3.5).
This would amount to a kind of shrinkage, this time not towards the
gravity model, but instead towards a model incorporating more side
information. Alternatively, such information could be included in
the constraints underlying the optimization (as shown in Section 7).
As noted in the introduction a point-to-point trafﬁc matrix is not
suitable for all applications. Sometimes we need a point-to-multipoint
demand matrix, for instance, when we want to answer questions
about the impact of link failures outside the backbone, e.g. “would
a peering link failure cause an overload on any backbone links?” In
this case, trafﬁc would reroute to an alternate exit point, changing
the point-to-point trafﬁc matrix in an unknown way. However, the
point-to-multipoint demand matrix would remain constant.
Ideally such a matrix would be at the preﬁx level, but a number
of operational realities make an approximation to router level useful
for many engineering tasks. The ﬁrst such reality is that backbone
networks that exchange large trafﬁc volumes are connected by pri-
vate peering links as opposed to Internet Exchange Points. This al-
lows us to see the proportion of trafﬁc going to each individual peer
using only SNMP link measurements, so we can partition trafﬁc per
peer. The second such reality is that the BGP policies across a set
of peering links to a single peer are typically the same. Therefore,
the decision as to which peering link to use as the exit point is made
on the basis of shortest IGP distance. This distance is computed
at the link level, as opposed to BGP policies, which can act at the
preﬁx level. While we cannot test that this property is true for all
large ISPs (and in general it is not always true even on the network
from which we have measurements), the methodology above does
not need this, because the algorithm above only uses this as a prior,
to be corrected through the use of link (and other) information.
The step required to generate a point-to-multipoint demand ma-
trix requires consideration of the control ISPs have over interdomain
routing. Interdomain routing gives an ISP little control over where
trafﬁc enters their network, so we shall not make any changes to
(28) for access-to-access, and peering-to-access trafﬁc. However, a
provider has considerable control over where trafﬁc will leave their
network across the peering edge. Trafﬁc destined for a particular
peer may be sent on any of the links to that peer.
The result is that we must modify (28) for access-to-peer trafﬁc.
We do so by not specifying which link d in the set of links to peer
i (i.e. Pi) is used for trafﬁc leaving the network to peer i. We can
do this formally by not specifying pS,D(s, d) for s ∈ A, d ∈ P but
rather pS,D(s, Pi) for all peers i. This simple point-to-multipoint
model can then be used in the estimation through using
pS(s)
pS(A)
pD(Pi),
pS,D(s, Pi) =
(29)
for s ∈ A, in place of the access-to-peering equation from (28).
We do not determine the exit point in the estimates. The algorithm
can then proceed by minimizing the mutual information of the ﬁnal
distribution with respect to (28) and (29). The exit points are im-
plicit in the routing matrix used in the optimization (27), but are left
undetermined in the estimate, and can therefore be ﬁxed only when
applied to a particular problem.
We should also note that this is a quite general extension. We use
it here on sets of peering links Pi, but in a network with different
policies, we can partition the peering links in some different fash-
ion (even through a non-disjoint partition) to reﬂect some particular
idiosyncrasies in routing policy.
3.6 Relationship to Previous Algorithms
The work in this paper presents a general framework, within which
we can place a number of alternative methods for estimating IP traf-
ﬁc matrices. For instance, by taking a linear approximation to the
log function in the Kullback-Leibler information distance informa-
tion and exploiting the fact thatx[f (x) − g(x)] = 0 we get
K(f||g) ≈ Xx
(cid:21) −Xx
[f (x) − g(x)]
2
g(x)
f (x)(cid:20) f (x) − g(x)
= Xx " f (x) − g(x)
#
g(x)
.
(30)
From this we can see that the MMI solution may be approximated
by using a quadratic distance metric (with square root weights) as
was applied in [28]. This explains the success of that approach, as
well as the need to use square root weights for best performance.
The conditional independence of Section 3.5 explains the use of the
generalized gravity model as an initial condition in [28].
The quadratic optimization is convenient, because it can be sim-
ply solved using the Singular Value Decomposition (SVD) [28],
with non-negativity enforced by a second step using Iterative Pro-
portional Fitting (IPF) [3]. In this paper we will compare the perfor-
mance of the pure MMI approach, its quadratic approximation, and
the previous method (referred to here as SVD-IPF), and we see that
the approximation works well in the cases considered. We defer the
comparison with maximum likelihood approaches ([24, 3, 16]) to
future work, because scaling these methods to the size of problem
described here requires additional techniques (for instance see [4,
27]) that have only recently been developed.
The point of interest here is that the MMI principle above pro-
duces (an approximation of) the algorithm previously derived from
an initial gravity model solution. However in the case of the MMI
solution, the principle precedes practice — that is, the decision to
regularize with respect to a prior is not an arbitrary decision, but a
standard step in ill-posed estimation problems. The close approxi-
mation has a practical impact in that we can use the fact that [28] al-
ready demonstrated that the conditional independence of Section 3.5
to be a better prior than complete independence. We use this fact
here by using (28) and (29) in the remainder of the paper.
4. EVALUATION METHODOLOGY
In this paper, we apply the trafﬁc matrix benchmarking method-
ology developed in [28] to real Internet data to validate different
algorithms. One major advantage of the methodology in [28] is that
it can provide a consistent data set that is as realistic as practically
possible. Below we provide an overview of this methodology, fol-
lowed by a summary of the performance metrics we use.
4.1 Validation Methodology
The approach of [28] used sampled ﬂow level data, and topology
and routing information as derived from [7]. Flow level data con-
tains details of numbers of packets and bytes transferred between
source and destination IP addresses, and also gives information such
as the interface at which the trafﬁc entered our network. Combining
these datasets one may derive a trafﬁc matrix [8].
The resulting trafﬁc matrix in our experiments covers around 80%
of the real network trafﬁc (including all the peering trafﬁc) on the
real topology of a large operational tier-1 ISP. Following [28], we
compute the trafﬁc matrices on one hour time scales to deal with
some limitations of the measurements. Given these trafﬁc matrices
and the network topology and routing information, we only need a
consistent set of link load measurements to proceed.
[28] solves the problem of providing a consistent set of trafﬁc,
topology and link measurement data as follows. Simulate the net-
work routing using the available topology and routing information.
From this we may compute a routing matrix A, and then derive a
set of link measurements y from (8). Thus the trafﬁc matrix x, the
routing matrix A and the measured link loads y are all consistent.
We can then perform the estimation procedure to compute ˆx, the
trafﬁc matrix estimate.
Part of the goal of this paper is to extend understanding of pre-
vious methods, and so we apply the pre-existing methodology for
testing trafﬁc matrices. However, this method does not explicitly
validate point-to-multipoint trafﬁc matrices. We compute the point-
to-multipoint trafﬁc matrix, and then collapse this down to a point-
to-point trafﬁc matrix for comparison with the real trafﬁc matrix.
The result is an implicit validation of the multipoint estimates.
The validation approach allows us to work with a problem for
which we know the “ground truth” — the real trafﬁc matrix. It can
also be extended in several different ways. For example, it allows
one to take a trafﬁc matrix and apply it on an arbitrary topology, for
instance a simulated network such as a star, or a measured topology
such as those produced by Rocketfuel [21, 14]. Thus we can gain
insight into the effect of different topologies on the performance
of the algorithm. We may also introduce controlled measurement
errors to assess the algorithm’s robustness, or simulate alternative
measurements to see their impact in a rigorous manner.
4.2 Performance Metrics
In this paper we use two basic methods for assessing and compar-
ing the results. The ﬁrst method is to estimate the relative error (that
is, the average of the absolute value of the errors, relative to the
average trafﬁc matrix element). The second method is to plot the
Cumulative Distribution Function (CDF) of the errors relative to the
average trafﬁc matrix element. However, many elements of a router
to router trafﬁc matrix are zero due to routing constraints, and these
constrained elements are easy to estimate. This results in a large
number of entries to the trafﬁc matrix with near zero error. To more
accurately indicate the errors on the positive elements we separate
the zero and non-zero elements and compute their errors separately.
The errors on the zero elements are very small (99% of the errors
are below 1%), and so we shall not display these separately here.
We shall report the relative errors of the positive elements.
5. PERFORMANCE
In this section, we ﬁrst examine the algorithm’s sensitivity to the
choice of λ, and then compare the accuracy of different algorithms.
5.1 Sensitivity to the Choice of λ
The choice of the parameter λ determines how much weight is
given to independence, versus the routing constraint equations. In
(a) quadratic optimization (specific case)
(c) quadratic optimization (average over all data)
error= 0%
error= 1%
error= 5%
error=10%
70
60
50
40
30
20
10
)
%
(
r
o
r
r
e
e
v
i
t
l
a
e