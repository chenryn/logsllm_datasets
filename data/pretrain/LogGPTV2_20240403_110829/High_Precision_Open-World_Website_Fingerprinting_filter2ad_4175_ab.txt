N(cid:48)
RT P
T P
N
P
· R(cid:48)
F P
π =
=
≈
TABLE II: Notation used in this paper.
NP , NN
NT P , NW P , NF P
RT P , RW P , RF P
Above variables, primed
r
πr
PO Method to improve WF precision
# of positives, negatives
# of true, wrong, false positives
True, wrong, false positive rates
Real values (not experimental parameters)
Base ratio, equal to NN /NP
precision for base ratio r
Recall
P
C
Equal to RT P
A packet sequence
A class
a client would visit. In a realistic setting, clients may have
different values of r representing how often each client visits
sensitive pages. Alternatively, r can also represent the same
ratio for a given set of clients, or the set of all clients. (We
will present some values of r extracted from real users in
Section V-B.) r is not a ﬁxed value, nor is it estimated or
determined by the attacker. A correct analysis of the precision
of a WF classiﬁer should include experiments on various
explicit values of r.
We can also see that RW P and RF P contribute differently
to πr, as only the latter is magniﬁed by r. This is why we do
not consider wrong positives to be false positives. Doing so
would cause us to underestimate precision.
C. Does precision trump recall?
In the classical formulation of WF, the effectiveness of an
attack is measured with its recall (TPR). We present three
arguments to convince the reader that it is more important to
optimize the precision of WF attacks than their recall.
Base rate fallacy. The base rate fallacy tells us that a WF
classiﬁer can be ineffective no matter how high its recall is.
“The boy who cried wolf” tells us that a high-recall, low-
precision classiﬁer is useless in a low base rate scenario. This
is because the attacker cannot use the classiﬁer’s information
in any way unless the attacker is conﬁdent that the classiﬁer’s
positive classiﬁcations are true: that is to say, precision is high.
The base rate fallacy highlights the epistemological deﬁciency
of recall in the open world; it does not tell us anything about
open-world effectiveness.
Chilling effect. Web-browsing clients using anonymity net-
works are sensitive to privacy and do not want the attacker to
capture any of their browsing behavior. When WF precision
is high, even a moderate recall may trouble privacy-sensitive
users. For example, a whistleblower who would suffer a 10%
recall — a 10% chance of revealing each sensitive page access
to any eavesdroppers — may instead choose to self-censor
rather than incur signiﬁcant personal risk.
Repeated visits. Browsing patterns are often consistent and
self-repeating, and users visit the same websites frequently. A
low-recall, high-precision attacker would eventually be able
to determine if the client is interested in particular sensitive
pages. A high recall is unnecessary in this scenario. Repeated
visits cause a gradual decay in privacy.
There are situations where both recall and precision are
important. If the attacker wants to determine the rate at which
low recall
clients visit a page on an anonymity network,
would distort
the count as much as low precision. There
are also scenarios where, due to side information or other
preconditions, the possible set of pages the client visited is
small, better represented by a closed-world scenario. This is
the case for hidden services, which have recently been found
to consist a relatively small ecosystem [10]. Nevertheless, in
the general open-world case, the above arguments explain
why a low-recall, high-precision attacker is more threatening
than a high-recall, low-precision attacker. For this reason, we
focus entirely on optimizing precision rather than recall or a
combined metric such as F -measure or G-measure.
D. Experimental setup
Data set. We collected our data set between February and
April 2019 with Tor Browser 8.5a7 on Tor 0.4.0.1-alpha, using
one machine on a university network. We focus exclusively on
Tor because it is both popular and resilient. Furthermore, it is
the most difﬁcult for WF out of currently usable anonymity
networks [8], and WF attacks designed to succeed in the Tor
scenario also tend to succeed against other privacy technolo-
gies [28]. The data set includes both HTTP/1.1 and HTTP/2
web pages.
We collected a set of sensitive (monitored) pages and non-
sensitive (non-monitored) pages. We chose the top 100 pages
on Alexa as the sensitive set, visiting each of them 200 times,
and the next 80,000 pages on Alexa as the non-sensitive set,
visiting each of them once. We decided that the sensitive pages
should be top sites to ensure reproducibility. Some previous
work has instead chosen politically sensitive pages [29], but
this made the scientiﬁc results unreproducible, because most
of those web pages have become unavailable in only a few
years. We gave each page up to 90 seconds to load, collecting
all cells. Some other pages (not counted in the above) had
failed to load; we ﬁltered them away.
For each web page, we collected the times, sizes, and
directions of all packets, from which Tor cells can be de-
rived [30], representing a local, passive attacker’s information.
Some attacks called for TCP packets, for which we directly
used the above raw traces; others called for Tor cells, for which
we processed the TCP packets to extract Tor cells. We did not
intentionally include any noise.
For convenience, we may describe a subset of our full data
set using the numeric notation 50x100+20, which denotes that
the subset has 50 monitored pages, 100 instances of each page,
and 20 non-monitored pages (non-monitored pages always
have one instance each). It is necessary to conduct certain
experiments on a subset of the data due to computation and
memory limitations.
Our experimental setup is the same as all works studying
open-world WF. We are allowed to perform data collection
on one computer speciﬁcally because Tor Browser preserves
anonymity by refusing to allow clients to customize it, and
Tor’s random circuit construction ensures that our attacker will
not train on the same circuits as the client. To our knowledge,
there is no work showing that this setup skews results unfairly.
Precision and recall. Our objective is to maximize r-precision
(πr) for WF attacks. In our experiments, we present results for
r = 20 and r = 1000, representing respectively an easy and
hard classiﬁcation setting. Note that r describes the total base
ratio of all sensitive pages (we consider 100 sensitive pages
in our work). For example, if the attacker wants to monitor
100 sensitive pages and the client has a 1/100,000 chance of
visiting each sensitive page, the attacker’s precision would be
correctly captured by our π1000 scenario.
The objective of this work is to optimize precision, which
may sometimes entail sacriﬁcing recall. This is informed by
our argument that a low-recall, high-precision attacker is more
threatening to privacy than a high-recall, low-precision at-
tacker. So that our POs will not produce completely inaccurate
classiﬁers, we set a minimum recall in this work of 0.2. We
chose 0.2 so that the classiﬁer would still be threatening to
people who visit sensitive pages only once; they could not be
sure that they would escape detection. Our approach to OWF
is novel compared to previous work; we maximize r-precision
while ensuring the recall is acceptable, while previous works
maximize recall [3], [19], [20], [28]–[30].
Presentation of results. In this work, we measure the 95%
conﬁdence interval of a statistic ˆx by taking:
(cid:114)
ˆx(1 − ˆx)
n
C(ˆx) = 1.96
This is the conﬁdence interval of the mean for the normal
distribution using the Wald method, and we apply it to TPR,
WPR, and FPR. We then write ˆx±C(ˆx) to show the conﬁdence
interval of ˆx. We are able to use the Wald method as our n is
large (usually 80,000). However, the above does not apply to
r-precision. Recall that the deﬁnition of r-precision is:
πr =
RT P + RW P + r · RF P
RT P
F P
Rmin
πmax
r
T P = RT P + C(RT P ), and Rmin
T P = RT P −
Let us denote Rmax
C(RT P ), and correspondingly for RW P and RF P . We take
a na¨ıve 95% conﬁdence interval by computing the maximum
πr:
Rmax
T P
W P + r · Rmin
T P + Rmin
=
r −πr and show the conﬁdence interval
We take C(πr) = πmax
as πr ± C(πr).2 When r is large (as in our experiments),
precision is dominated by the r·Rmin
F P term in the denominator.
When πr is high, C(πr), its conﬁdence interval, is unstable.
This is because a high r-precision indicates a very small
number of false positives, especially in the r = 1000 scenario.
For example, consider an experiment with NP = 20000 and
NN = 80000 where we ﬁnd that RT P = 0.45, RW P =
0, RF P = 0.00005. This gives π1000 = 0.9. But the number of
false positive events is very small, with NF P = RF P · NN =
4 < 10. This violates a general rule of thumb: there must
be more than ten occurrences of an event to use the Wald
2This C(πr) is larger than an alternative C(cid:48)(πr) = πr − πmin
, so the
r
estimation is cautious.
method as the conﬁdence interval. In such cases, we calculate
the maximum FPR using the Wilson method (which better
suits the extremely small rate RF P ), with z = 1.96 for the
95% conﬁdence interval:
RF P + z2
2NN
+ z
Rmax
F P =
(cid:113) RF P (1−RF P )
NN
1 + z2
NN
+ z2
4N 2
N
Then, we take the minimum precision as
πmin
r =
Rmin
T P
W P + r · Rmax
T P + Rmax
F P
Rmax
Finally, we express the precision with its lower bound of πr ≥
. We present no value for the upper bound of precision
πmin
r
as it cannot be accurately measured. Continuing the above
example, we ﬁnd Rmin
W P = 0,
F P = 0.00010, so we would write π1000 ≥ 0.76, not
and Rmax
π1000 = 0.9. We use the Wilson method for π1000 whenever
NF P < 10.
T P = 0.367, Rmax
T P = 0.353, Rmax
III. PRECISION OPTIMIZERS
We modify closed-world classiﬁers to achieve high r-
precision for OWF using Precision Optimizers (POs). Our POs
teach the underlying classiﬁer to be conservative, such that it
would assign a packet sequence to the negative class (non-
sensitive web page) if it is not certain about its classiﬁcation.
This reduces FPR, thus increasing r-precision.
To optimize r-precision, we ﬁrst ask the closed-world
classiﬁer to classify the element as usual. If it is a negative
classiﬁcation, we do not apply PO. Otherwise, if the classiﬁer
decides the element should be classiﬁed as a sensitive page (we
refer to that class as the assumed class), we ask a PO whether
or not we should reject classiﬁcation of the assumed class.
The PO may agree with the assumed class, or it may reject
the assumed class and instead classify the element as non-
sensitive. (Our POs do not change a sensitive classiﬁcation to
another sensitive classiﬁcation.) This is shown in Figure 1.
This strategy is conceptually similar to the Classify-Verify
strategy described in Juarez et al.’s previous work [11].
Our POs are designed to be classiﬁer-agnostic: they treat
the classiﬁer as a black box and they can be applied to all
classiﬁers. Some POs are also parametrically tuneable to allow
maximization of r-precision.
We start this section by motivating our work with an exper-
iment on the baseline r-precision of WF classiﬁers without
any POs (Section III-A). Then, we present three types of
POs: conﬁdence-based POs (Section III-B), distance-based
POs (Section III-C), and ensemble POs (Section III-D). Our
techniques are inspired by techniques used in clustering and
ensemble learning.
We will describe in detail how each type of PO improves
the precision of known attacks in the following sections, but
ﬁrst we front-load our presentation with Figure 2 showing our
precision optimization in the r = 20 and r = 1000 scenarios.
In each bar, the lighter area show the original precision without
POs, the darker area show how much we increased precision
Fig. 1: Flowchart describing how we classify an element. Our
Precision Optimizers (POs) modify classiﬁcation to improve
precision as represented by the dotted box.
using our POs, and an arrow (if any) indicates use of the
more conservative Wilson method to obtain a lower bound for
precision. These graphs clearly show that we can signiﬁcantly
increase precision in both scenarios and all attacks, with
Ha-kFP and the ensemble method performing especially well
in for r = 1000. We will describe each PO in detail in the
following.
A. Baseline precision
We ﬁrst present
the precision of previous work, non-
optimized, as a comparative basis. We experimented on the
classiﬁers in Table III, using the experimental setup and
methodology described in Section II-D. We tested two strate-
gies seen in previous work, the non-monitored class strategy
and the k-neighbors strategy.
Non-monitored class strategy. This strategy adds an extra
“non-monitored class” that includes all non-sensitive pages. In
our case, there would be 100 sensitive (positive) classes and
1 non-sensitive (negative) class. The classiﬁer is then asked
to determine to which of the 101 classes each testing element
should be assigned. We present the best results for 20-precision
and 1000-precision in Table III.
Besides the six attacks we will optimize, we also include
the Deep Fingerprinting attack (Si-DF) by Sirinam et al. [25],
the current state of the art in website ﬁngerprinting. We do not
optimize Si-DF because our POs do not apply to its neural