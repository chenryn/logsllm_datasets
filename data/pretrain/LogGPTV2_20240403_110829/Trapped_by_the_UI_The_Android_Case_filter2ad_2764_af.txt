MD5 hash values. Contrary to the patterns, the text-based passwords use a
salt which is stored in the /data/system/locksettings.db. Clearly, due to
the location where these ﬁles are stored, users and applications cannot access
them neither for reading nor for writing them. Therefore, attacks to recover the
unlocking code are focused either to cases where one has access to the stor-
age and manipulates it to e.g. remove the protection mechanism or to sniﬀ the
password by side channel attacks [13,40,42].
While the user is not allowed to read nor modify the content of the two
aforementioned ﬁles, an application is able to determine which is the locking
modality that is used. To achieve it, the application must simply request the ﬁle
size of the two ﬁles. Obviously, the ﬁle whose size is a positive number indicates
which of the two modalities is used, as both ﬁles exist in the ﬁlesystem regardless
of which modality the user prefers.
To replicate the lock screen’s UI, one also needs to collect the user’s wallpaper.
Notably, in Android, all applications are allowed to access device’s wallpaper
by requesting the getDrawable property without the need for declaring any
dangerous permission, as reported by the Authors, in Security Issue 219663.
This choice can be considered rather dubious as users would most often use
personal photos as their wallpaper. Clearly, apart from the use described in our
attack, this feature also enables apps to proﬁle users since the content of the
Trapped by the UI: The Android Case
345
wallpaper could reveal social connections, religious and political beliefs or even
sexual preferences.
Combining the above information we are able to prepare the screen that is
be presented to the user when he wants to unlock the phone, since the device’s
secure lock background image is almost always the blurred version of the user’s
wallpaper. The malicious application is seemingly harmless and can consist of
several activities. Obviously, the fake lock screen functions as the real one, yet
it records all touch events, which are stored and transmitted to the adversary to
recover the unlocking code. The interface and steps of our attack for the case of
pattern locked smartphone are illustrated in Figs. 2a and b.
To accomplish an attack that will result in sniﬃng a user’s lock screen pin or
pattern, our approach requires the implementation of a BroadcastReceiver class
that will be capable of listening for screen-oﬀ events, (ACTION SCREEN OFF), while
our app is running on the foreground. In other words, the actual initialization
of our attack is triggered by the user, not when she tries to unlock her mobile
phone by using the power button, but on the contrary when she locks her phone
so that she will subsequently unlock it for the next use. As a result, our fake
lock screen will be brought to the foreground after the screen-oﬀ event and will
remain there invisible until the moment the user tries to unlock her smartphone.
However, due to Android OS’s restrictions for security reasons, this “special”
kind of broadcast receiver cannot be registered in the app’s manifest but only
programmatically on runtime, nor can it be associated with a diﬀerent activity
than the one that registered the receiver. To overcome these restrictions our app
registers the broadcast receiver programmatically through a “dummy” activity
and most importantly the same activity is also used to create the fake lock
screen. We accomplish this “transformation” of the dummy activity into the
desired one by hiding all the views that were used in it and by replacing them
with visible ones that where previously hidden, which comprise the “desired” fake
lock screen activity. Of course, the device’s specs are “welcomed” by attackers
in order to “ﬁne tune” the attack, such as screen size and screen fonts, and thus
produce a “convincing” result. In order to force our fake lock screen precede
the real lock screen when the victim presses the power button, some special
ﬂags are used, such as the FLAG SHOW WHEN LOCKED parameter. Finally, while
the user interacts with our fake lock screen we manage to create a simple path
data structure where each (X,Y) coordinate regarding touch screen events and
movements is recorded, ACTION DOWN, ACTION UP and ACTION MOVE. Obviously,
analysing this data structure can straightforwardly reveal a victim’s lock screen
pattern. Certainly, producing a fake lock screen that consists of UI controls to
capture a 4 digit screen lock is simpler.
3.5 Inferring Foreground Application
For obvious security and privacy reasons, Android prevents applications from
inferring which application is on the foreground. Nonetheless, it allows applica-
tions to know, without requesting any dangerous permission, which applications
are installed in the device, as well as which ones are currently running; the latter
346
E. Alepis and C. Patsakis
only applies for all Android versions prior to Nougat. While these permissions
and restrictions are performed in the SDK, one may dig into the OS layer to
retrieve this information.
Android is practically a Linux system and as most of the Unix-like systems
it follows the same approach for handling its ﬁlesystems. One well-known, yet
special ﬁlesystem is procfs which is utilised to store the information of the
processes that are executed by the operating system. While accessing the infor-
mation in this ﬁlesystem is well protected, in terms of reading and altering the
stored information this does not actually prevent side leakages. In principle, in
Android these mechanisms are more strict as each application is a separate user,
and as such, each application is prevented from accessing the “internals” of the
other. Nonetheless, some metadata are publicly available to all applications.
Special concern should be paid to the oom adj score ﬁle. To understand
the importance of this parameter we will discuss some Android speciﬁc fea-
tures of process management. In principle, Android runs is mobile devices which
have constrained resources, whereas many reﬁnements have been introduced by
Google in order to allow Android to perform resource allocation and release.
Since the device has limited memory, Android performs the following steps to
achieve stability. If there is memory free, Android uses Zygote to launch a new
VM. However, if there is not any free memory, it has to close the last user appli-
cation. In this regard, each application is given a oom adj score, stored under
/proc/[pid]/. By monitoring the aforementioned ﬁles, and pruning all the sys-
tem applications, one can easily determine which is the application which is less
probable to be killed, which eventually, is the foreground app.
4 Use Cases and Implemented Attacks
To demonstrate our attacks and highlight their importance, we have prepared a
set of diﬀerent attack scenarios that reveal diﬀerent exposures from the Android
UI. Some representative interfaces of the attacks that we launched are illustrated
in Fig. 2. In these screenshots we have deliberately created a sloppy interface
for most of the attacks so that the reader can easily determine the overlayed
activity as well as the exposed functionality. As discussed in the previous section,
an adversary can easily present either transparent or sized activities on top of
the benign ones to provide the necessary look and feel and trick the user into
performing illegal actions and/or sniﬀ input data.
While one could argue that the activities and their resources must be declared
in the manifest, one can easily bypass this restriction by simply using webviews
that cover the whole activity. In this regard, an adversary can load dynami-
cally any interface he wants. Note that the adversary through his malicious app
already knows which apps are installed in the victim’s device, also illustrated in
Fig. 2, so he can easily prepare the appropriate interface and load it dynamically
when deemed necessary. Therefore, in what follows, we consider the creation and
delivery of the forged interface as a trivial part of the attack that is made mostly
through Firebase.
Trapped by the UI: The Android Case
347
.
n
e
e
r
c
s
e
m
o
h
e
h
t
n
i
t
u
c
t
r
o
h
s
.
s
p
p
a
e
t
a
m
i
t
i
g
.
l
l
a
c
.
n
r
e
t
t
a
p
d
n
a
n
o
i
t
a
c
ﬁ
i
t
o
n
e
k
a
F
)
e
(
-
e
l
g
n
i
r
e
v
o
h
n
i
g
o
l
e
k
a
F
)
d
(
e
n
o
h
p
a
g
n
i
h
c
n
u
a
L
)
c
(
s
’
r
e
s
u
e
h
t
i
g
n
d
r
o
c
e
R
)
b
(
.
n
e
e
r
c
s
k
c
o
l
d
e
g
r
o
F
)
a
(
g
n
i
k
c
a
j
p
a
t
d
e
s
i
v
e
R
)
j
(
-
d
a
e
c
i
v
e
d
i
g
n
m
o
c
e
B
)
i
(
-
n
i
e
g
a
k
c
a
p
g
n
i
h
c
n
u
a
L
)
h
(
s
’
r
e
s
u
g
n
i
t
p
e
c
r
e
t
n
I
)
g
(
s
a
n
o
i
t
a
c
ﬁ
i
t
o
n
e
k
a
F
)
f
(
.
d
i
r
g
a
h
g
u
o
r
h
t
.
r
o
t
a
r
t
s
i
n
m
i
.
r
e
l
l
a
t
s
m
o
r
f
t
u
p
n
i
d
r
a
o
b
y
e
k
n
o
i
t
a
c
ﬁ
i
t
o
n
e
h
t
n
i
.
p
p
a
s
t
a
h
W
n
e
e
s
.
r
a
b
.
s
k
c
a
t
t
a
g
n
i
s
s
e
r
d
e
r
I
U
s
u
o
i
r
a
V
.
2
.
g
i
F
348
E. Alepis and C. Patsakis
The lifecycle of our attacks is the following. Initially, Malory, the adversary,
uploads the malicious app in Google Play; as already reported our apps bypass
Bouncer’s ﬁlters, and the user is tricked into downloading the app and installing
it since it requires no special permissions. Then, the app sends through Firebase
all the necessary input from the victim’s phone. Next, Malory delivers all her
payload for the attacks through Firebase. Depending on the installed apps and
Android version, the malicious app either timely launches a forged activity or
overlays a benign app.
Starting a phone call: While an application needs to have a dangerous per-
mission granted to start a call, any application can use an intent to launch the
“Phone” application with an arbitrary number to call. For obvious reasons this
call will not be made unless the user presses the call button. Exploiting the UI
features described in the previous section, an adversary can easily create a set
of activities to cover the screen, leaving a small part of the call button and trick
the user in pressing it. A draft example of this approach is illustrated in Fig. 2c.
Another similar and perhaps more stealth attack would involve sending SMSs
to premium numbers.
Sniﬃng private data from legitimate apps: In this case there are two diﬀer-
ent attack scenarios. For devices running Android prior to Nougat, an adversary
is able to determine which the foreground app is, as presented in the previous
section. Should the adversary determine that a speciﬁc app would provide him
with valuable data e.g. credentials, he presents the user with a customised ﬂoat-
ing activity which covers the legitimate app, requesting private user input. As
shown in Fig. 2d, the user has no means to determine that the presented activ-
ity (shown as a common app dialog) does not belong to the legitimate app. In
fact in the illustrated example, Google Maps continues to function in the back-
ground as expected, since the ﬂoating activity occupies only a speciﬁc part of
the screen leaving the other parts of the screen unaﬀected. Considering devices
running on Nougat, while the adversary cannot determine which the foreground
application is, he can easily trick the user with other methods such as injecting
fake notiﬁcations or creating fake shortcuts, all mimicking legitimate ones.
Intercepting sensitive input: Should the adversary know which is the fore-
ground application via side channel information, as discussed in the previous
section, he can present the user a transparent activity. A typical example is
illustrated in Fig. 2g where the transparent activity accompanied by a keyboard
allows the user to type her message to one of the most widely used messen-
ger applications, Whatsapp. Having intercepted the input, the malicious app
displays a message that something went wrong to smoothly return to normal
execution.
Fake notiﬁcations: Based on the latter restriction in Nougat, about determin-
ing the foreground app, we tried a diﬀerent approach: force the user to open a
desired application. To achieve this, we exploited the fake notiﬁcation mecha-
nism, discussed in the previous section. Therefore, we created a malicious app
Trapped by the UI: The Android Case
349
that downloads dynamically both the notiﬁcation icons and the notiﬁcation mes-
sage. Since the adversary knows which the installed apps are, he can easily create
a forged notiﬁcation for one of the victim’s apps. In Figs. 2e and f we illustrate
this in Nougat using PayPal as the target app. As shown in these screenshots,
the user has no means to determine that the foreground activity does not belong
to PayPal. As already discussed, the notiﬁcation in Fig. 2f may not contain the
app name, yet the user most probably will not notice it. Clearly, in Marshmal-
low, since the name restriction does not apply, the user cannot tell the actual
diﬀerence, as the forged notiﬁcation will be identical to the real one. Finally, it
should be noted that notiﬁcations are used as shortcuts, so the user does not
spend much time in trying to determine whether there is a name or not; in the
case of Nougat, he will trust the icon.
Fake shortcuts: Another approach to trick the user into launching the forged
activity of the malicious app is to create a fake shortcut on the mobile’s home
screen. While Android has its application menu locked so that applications can-
not add more icons, the same does not apply for the home screen. There, any
application using the normal permission INSTALL SHORTCUT can create a shortcut
with the icon and name of a legitimate and installed application, as described in
the previous section. However, the shortcut actually launches the forged activity
from the malicious app and not the legitimate one.
Installing applications: Further to performing actions within the scope of the
installed applications, an adversary could also trick the user into performing
actions within the scope of the operating system per se. For obvious reasons,
one would expect that an application would not be allowed to cover activities
over them, nonetheless, this is not the case. A profound example is the case of
the install manager. Notably, an adversary could download an application from
the Internet, by simply using an intent to the browser, or by other means such as
utilizing Google Drive, using local ﬁles, etc. Practically, using the “Intent” way
means that the app does not request Internet permission. Once the download
of the APK is ﬁnished, the Package Manager is automatically invoked and the
malicious app presents the user an activity as in Fig. 2h, to trick him and install
another app. In the less sinister scenario, the adversary manages to raise his
stats, while in the more sinister, the adversary tricks the user into installing an
application which has more dangerous payload and the user would have never
downloaded from Google Play.
Becoming administrator: In Android 2.2 [3], Google introduced a mechanism
that allows users to grant device administration features to speciﬁc applications
in order to facilitate enterprise applications and to provide them means to apply
stricter policies and device management. To this end, an application which is
granted this permission can among other features restart the device or wipe its
data. To facilitate the installation procedure, Android provides a shortcut so
that the application requesting this permission can present the user with this
screen. While one would expect that this activity would not be accessible and
no one would be able to interact with it once it loses focus, this restriction
350
E. Alepis and C. Patsakis
does not apply. As illustrated in Fig. 2i an adversary can cover the activity with
the techniques described in the previous section to trick the user into granting
some of the most dangerous permissions. Notwithstanding this deceit, the same
security gap is present is other highly dangerous activities, e.g. installing custom
certiﬁcates, granting access to user’s notiﬁcations to name a few. Apparently, the
user can be easily tricked into being blocked from his own device, wiping his own
data or even giving full remote access to his data.
Tapjacking revisited: The basic concept of most tapjacking attacks in the
literature is to create a transparent overlay which exploits a vulnerability in
Android’s UI to catch the event of user tapping the screen and then passing it
to the underlying application. To the best of our knowledge all of these attacks
are now obsolete as of Marshmallow. A diﬀerent approach however is to exploit
the grid concept with many sized transparent activities of Fig. 1b. The twist
in this approach is that we do not try to pass the event to the underlying
application, but we exploit the size of users’ ﬁngers, as well as the fact that
a “sized” activity can even have a surface of a few pixels. Since the activities
can also be transparent and can overlay any application, the malicious app can
sense where the user’s ﬁnger is and derive the user’s input. Eventually, if the
screen is covered by many small transparent activities, touch events will be
sensed by the grid, while the interaction with the underlying application will
also exist. Notably, in this scenario, the adversary does not need to know the
foreground app, as the malicious app logs almost all user tapping so he can later
infer sensitive application such as PINs, credentials, keyboard typing etc. To
demonstrate the applicability of this attack we created a proof of concept, yet
to facilitate the reader, the sized activities are marked red in Fig. 2j, but in the
original, they are transparent.
5 Conclusions
User interfaces are tightly entwined with user experience, especially regarding
user-smartphone interaction. However, the eﬀorts in improving user interfaces
may hinder OS security, as app lifecycles are more complex. All the reported
attacks, accompanied with the corresponding proof of concept have been already
communicated to Google. In some cases, the Android Security team has already
responded and provided corresponding software patches, yet other issues are still
under investigation.
Considering the notiﬁcations and the shortcuts related issues we believe that
both users and developers cannot eﬃciently protect themselves, unless actions
in the side of the operating system are taken. Such actions include enforcing the
creation of notiﬁcations and shortcuts to pass strictly through resource bound
parameters. This way, software systems that statically analyse apps installation
packages would be able to detect malicious content, such as duplicated third
party logos and potentially harmful string values. When Android OS is abused for
either tricking users into making e.g. unwanted calls, or for escalating malicious
apps privileges, we believe that all the involved in these actions activities must
Trapped by the UI: The Android Case
351
be reviewed to handle events when they lose focus and they are overlaid, so
that users are notiﬁed accordingly. Notably, this mechanism has been partially
deployed e.g. in Marshmallow’s dangerous run-time permissions dialogs. Another
alternative would be to disable all OS activity controls when other UI elements
appear in front of them. The latter is done in Google Play app, where the
presence of a front layer disables some “dangerous” choices, such as the pressing
of the “install” app button. The diversity of the two approaches signiﬁes that
the problem is known to Google, yet not to its entity, as the patches were applied
per case and not generically.
Unfortunately, the aforementioned countermeasures do not apply for the
cases of third party apps, therefore the OS could consider adopting them only
for the cases where OS activities are involved. That is because many applica-
tions provide “ﬂoats” in the front most UI screen layer and users ﬁnd them very
usefull, such as the “chatheads” dialogs that are quite common in chatting apps.
Implementing the aforementioned solutions could either cause malfunctioning
in a large number of applications or continuous annoying alerts, which would
negatively aﬀect UX. Subsequently, this raises the need for alternate counter-
measures for the third party apps. Towards this direction, a plausible incitement
would be to face these security problems diﬀerently and enable apps to protect
themselves from malicious software. All Android activities are able to “detect”
even the slightest changes in their interaction with the user UI, utilizing the
Android activities’ lifecycle states. That is, overriding the appropriate methods
(e.g. onPause method for detecting dialogs, or onStop method when the activ-
ities are fully covered by other UI elements) and act accordingly, like disabling
or hiding their “sensitive” UI elements, or even alerting their users.
It is also worth noticing that while intents are extremely helpful in providing
intercommunication between Android applications, they can be considered a
covert channel in terms of permissions, as they provide an out of the loop way
of using data and device resources. This is rather important as in static code
analysis, one cannot trace this through the corresponding manifest ﬁle or the
low level API calls, as intents do not map to the framework’s methods. This
way, they bypass security checks, increasing the complexity to approaches such
as Backes et al. [15] as it requires to determine interdependencies between apps.
Concluding, we may state that due to the lack of visible resources that would
allow users to determine which the “actual” foremost app is, users have imme-
diate and absolute trust to their OS that the presented apps are the ones they
claim to be. It is the authors’ strong belief that by providing some more rules
and permissions in the Android’s UI handling mechanisms in combination with
improving security concerns in app development by developers themselves, would
lead to the elimination of the majority of the Android UI related security issues
raised in this work.
Acknowledgments. This work was supported by the European Commission under
the Horizon 2020 Programme (H2020), as part of the OPERANDO project (Grant
Agreement no. 653704) and is based upon work from COST Action CRYPTACUS,
supported by COST (European Cooperation in Science and Technology). The authors
352
E. Alepis and C. Patsakis
would like to thank ElevenPaths for their valuable feedback and granting them access
to Tacyt.
References
1. AlJarrah, A., Shehab, M.: Maintaining user interface integrity on android. In: 2016
IEEE 40th Annual Computer Software and Applications Conference (COMPSAC),
vol. 1, pp. 449–458. IEEE (2016)
2. Android Developer: ActivityManager – getRunningTasks. https://developer.
android.com/reference/android/app/ActivityManager.html#getRunning
Tasks(int). Accessed 28 Mar 2017
3. Android Developer: Device administration. https://developer.android.com/guide/
topics/admin/device-admin.html. Accessed 28 Mar 2017
4. Android Developer:
Intent. https://developer.android.com/reference/android/
content/Intent.html. Accessed 28 Mar 2017
5. Android Developer: Intents and intent ﬁlters. https://developer.android.com/
guide/components/intents-ﬁlters.html. Accessed 28 Mar 2017
6. Android Developer: Manifest.permission – READ EXTERNAL STORAGE.
https://developer.android.com/reference/android/Manifest.permission.html#
READ EXTERNAL STORAGE. Accessed 28 Mar 2017
7. Android Developer: Manifest.permission – SYSTEM ALERT WINDOW. https://
developer.android.com/reference/android/Manifest.permission.html#SYSTEM
ALERT WINDOW. Accessed 28 Mar 2017
8. Android Developer: Multi-window support. https://developer.android.com/guide/
topics/ui/multi-window.html. Accessed 28 Mar 2017
9. Android Developer: Notiﬁcation.builder. https://developer.android.com/reference/
android/app/Notiﬁcation.Builder.html. Accessed 28 Mar 2017
10. Android Developer: PackageManager
–
getInstalledApplications. https://
developer.android.com/reference/android/content/pm/PackageManager.html#
getInstalledApplications. Accessed 28 Mar 2017
11. Android Developer: Settings. https://developer.android.com/reference/android/
provider/Settings.html#ACTION MANAGE OVERLAY PERMISSION.
Accessed 28 Mar 2017
12. Android Developer: WindowManager. https://developer.android.com/reference/
android/view/WindowManager.html. Accessed 28 Mar 2017
13. Aviv, A.J., Gibson, K., Mossop, E., Blaze, M., Smith, J.M.: Smudge attacks on
smartphone touch screens. In: Proceedings of the 4th USENIX Conference on
Oﬀensive technologies, pp. 1–7. USENIX Association (2010)
14. Aviv, A.J., Sapp, B., Blaze, M., Smith, J.M.: Practicality of accelerometer side
channels on smartphones. In: Proceedings of the 28th Annual Computer Security
Applications Conference, pp. 41–50. ACM (2012)
15. Backes, M., Bugiel, S., Derr, E., McDaniel, P., Octeau, D., Weisgerber, S.: On
demystifying the android application framework: re-visiting android permission
speciﬁcation analysis. In: 25th USENIX Security Symposium (USENIX Security
2016), pp. 1101–1118. USENIX Association, Austin (2016)
16. Bianchi, A., Corbetta, J., Invernizzi, L., Fratantonio, Y., Kruegel, C., Vigna, G.:
What the app is that? Deception and countermeasures in the android user interface.
In: Proceedings of the 2015 IEEE Symposium on Security and Privacy, pp. 931–
948. IEEE Computer Society (2015)
Trapped by the UI: The Android Case
353
17. Chen, J., Chen, H., Bauman, E., Lin, Z., Zang, B., Guan, H.: You shouldn’t collect
my secrets: thwarting sensitive keystroke leakage in mobile IME apps. In: 24th
USENIX Security Symposium (USENIX Security 2015), pp. 657–690. USENIX
Association, Washington, D.C. (2015)
18. Chen, Q.A., Qian, Z., Mao, Z.M.: Peeking into your app without actually seeing
it: UI state inference and novel android attacks. In: 23rd USENIX Security Sym-
posium (USENIX Security 2014), pp. 1037–1052. USENIX Association, San Diego
(2014)
19. Faruki, P., Bharmal, A., Laxmi, V., Ganmoor, V., Gaur, M.S., Conti, M., Rajara-
jan, M.: Android security: a survey of issues, malware penetration, and defenses.
IEEE Commun. Surv. Tutorials 17(2), 998–1022 (2015)
20. Felt, A.P., Finifter, M., Chin, E., Hanna, S., Wagner, D.: A survey of mobile
malware in the wild. In: Proceedings of the 1st ACM Workshop on Security and
Privacy in Smartphones and Mobile Devices, pp. 3–14. ACM (2011)
21. Fernandes, E., Chen, Q.A., Paupore, J., Essl, G., Halderman, J.A., Mao, Z.M.,
Prakash, A.: Android UI deception revisited: attacks and defenses. In: Grossklags,
J., Preneel, B. (eds.) FC 2016. LNCS, vol. 9603, pp. 41–59. Springer, Heidelberg
(2017). doi:10.1007/978-3-662-54970-4 3
22. Johnson, K.: Revisiting android tapjacking (2011). https://nvisium.com/blog/
2011/05/26/revisiting-android-tapjacking/
23. Kartaltepe, E.J., Morales, J.A., Xu, S., Sandhu, R.: Social network-based botnet
command-and-control: emerging threats and countermeasures. In: Zhou, J., Yung,
M. (eds.) ACNS 2010. LNCS, vol. 6123, pp. 511–528. Springer, Heidelberg (2010).
doi:10.1007/978-3-642-13708-2 30
24. Lipp, M., Gruss, D., Spreitzer, R., Maurice, C., Mangard, S.: Armageddon: cache
attacks on mobile devices. In: 25th USENIX Security Symposium (USENIX Secu-
rity 2016), pp. 549–564. USENIX Association, Austin (2016)
25. Liu, J., Wang, Y., Kar, G., Chen, Y., Yang, J., Gruteser, M.: Snooping key-
strokes with mm-level audio ranging on a single phone. In: Proceedings of the
21st Annual International Conference on Mobile Computing and Networking, pp.
142–154. ACM (2015)
26. Liu, X., Zhou, Z., Diao, W., Li, Z., Zhang, K.: When good becomes evil: keystroke
inference with smartwatch. In: Proceedings of the 22nd ACM SIGSAC Conference
on Computer and Communications Security, pp. 1273–1285. ACM (2015)
27. Lockheimer, H.: Android and security. http://googlemobile.blogspot.com/2012/
02/android-and-security.html. Accessed 28 Mar 2017
28. Malisa, L., Kostiainen, K., Och, M., Capkun, S.: Mobile application impersonation
detection using dynamic user interface extraction. In: Askoxylakis, I., Ioannidis, S.,
Katsikas, S., Meadows, C. (eds.) ESORICS 2016. LNCS, vol. 9878, pp. 217–237.
Springer, Cham (2016). doi:10.1007/978-3-319-45744-4 11
29. Marforio, C., Masti, R.J., Soriente, C., Kostiainen, K., Capkun, S.: Hardened setup
of personalized security indicators to counter phishing attacks in mobile banking.
In: Proceedings of the 6th Workshop on Security and Privacy in Smartphones and
Mobile Devices, pp. 83–92. ACM (2016)
30. Niemietz, M., Schwenk, J.: UI redressing attacks on android devices, blackHat Abu
Dhabi (2012)
31. Oberheide, J., Miller, C.: Dissecting the android bouncer. In: SummerCon (2012)
32. Richardson, D.: Android tapjacking vulnerability (2010). https://blog.lookout.
com/look-10-007-tapjacking/
354
E. Alepis and C. Patsakis
33. Shukla, D., Kumar, R., Serwadda, A., Phoha, V.V.: Beware, your hands reveal
your secrets! In: Proceedings of the 2014 ACM SIGSAC Conference on Computer
and Communications Security, CCS 2014, pp. 904–917. ACM, New York (2014)
34. Simon, L., Anderson, R.: Pin skimmer: inferring pins through the camera and
microphone. In: Proceedings of the Third ACM Workshop on Security and Privacy
in Smartphones and Mobile Devices, pp. 67–78. ACM (2013)
35. Van Bruggen, D.: Studying the impact of security awareness eﬀorts on user behav-
ior. Ph.D. thesis, University of Notre Dame (2014)
36. Vidas, T., Votipka, D., Christin, N.: All your droid are belong to us: a survey
of current android attacks. In: Proceedings of the 5th USENIX Conference on
Oﬀensive Technologies, p. 10. USENIX Association (2011)
37. Wu, L., Brandt, B., Du, X., Ji, B.: Analysis of clickjacking attacks and an eﬀective
defense scheme for android devices. In: IEEE Conference on Communications and
Network Security. IEEE (2016)
38. Wu, L., Du, X., Wu, J.: Eﬀective defense schemes for phishing attacks on mobile
computing platforms. IEEE Trans. Veh. Technol. 65(8), 6678–6691 (2016)
39. Xu, Z., Bai, K., Zhu, S.: Taplogger: inferring user inputs on smartphone touch-
screens using on-board motion sensors. In: Proceedings of the Fifth ACM Confer-
ence on Security and Privacy in Wireless and Mobile Networks, pp. 113–124. ACM
(2012)
40. Ye, G., Tang, Z., Fang, D., Chen, X., Kim, K.I., Taylor, B., Wang, Z.: Cracking
android pattern lock in ﬁve attempts (2017)
41. Ying, L., Cheng, Y., Lu, Y., Gu, Y., Su, P., Feng, D.: Attacks and defence on
android free ﬂoating windows. In: Proceedings of the 11th ACM on Asia Conference
on Computer and Communications Security, pp. 759–770. ACM (2016)
42. Zhang, J., Zheng, X., Tang, Z., Xing, T., Chen, X., Fang, D., Li, R., Gong,
X., Chen, F.: Privacy leakage in mobile sensing: your unlock passwords can be
leaked through wireless hotspot functionality. Mobile Inf. Syst. 2016, 8793025:1–
8793025:14 (2016)