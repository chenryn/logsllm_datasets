### MD5 Hash Values and Password Security

MD5 hash values are used for text-based passwords, which also incorporate a salt. This salt is stored in the `/data/system/locksettings.db` file. Given the location of these files, they are inaccessible to both users and applications for reading or writing. Consequently, attacks aimed at recovering the unlocking code typically involve either gaining access to the storage and manipulating it (e.g., removing the protection mechanism) or using side-channel attacks [13, 40, 42].

### Access Control and File Size Analysis

While users and applications cannot read or modify the content of the two mentioned files, an application can determine the locking modality by requesting the file size of each. The file with a positive size indicates the active modality, as both files exist in the filesystem regardless of the user's preference.

### Replicating the Lock Screen UI

To replicate the lock screen's user interface (UI), one must also collect the user's wallpaper. In Android, all applications can access the device's wallpaper by requesting the `getDrawable` property without needing any dangerous permissions, as noted in Security Issue 219663. This feature raises privacy concerns, as users often use personal photos as wallpapers, potentially revealing social connections, religious and political beliefs, or even sexual preferences.

### Creating a Fake Lock Screen

Combining the above information, we can prepare a screen that mimics the one presented to the user when they attempt to unlock their phone. The secure lock background image is usually a blurred version of the user's wallpaper. The malicious application appears harmless but records all touch events, which are then transmitted to the adversary to recover the unlocking code. For pattern-locked smartphones, the attack process is illustrated in Figures 2a and 2b.

### Triggering the Attack

To execute the attack, the malicious application implements a `BroadcastReceiver` class that listens for screen-off events (`ACTION_SCREEN_OFF`). The attack is triggered when the user locks their phone, not when they try to unlock it. After the screen-off event, the fake lock screen is brought to the foreground and remains invisible until the user attempts to unlock their smartphone. Due to Android's security restrictions, this special broadcast receiver must be registered programmatically at runtime and cannot be associated with a different activity. The app registers the broadcast receiver through a "dummy" activity, which is then transformed into the fake lock screen by hiding its views and replacing them with visible ones. The device's specifications, such as screen size and fonts, are used to fine-tune the attack and make it more convincing. Special flags, like `FLAG_SHOW_WHEN_LOCKED`, are used to ensure the fake lock screen precedes the real one. The touch events (ACTION_DOWN, ACTION_UP, ACTION_MOVE) are recorded to reveal the user's lock screen pattern.

### Inferring the Foreground Application

For security and privacy reasons, Android prevents applications from determining which application is in the foreground. However, applications can know which apps are installed and which are currently running, though the latter only applies to versions prior to Nougat. By digging into the OS layer, one can retrieve this information. Android, being a Linux system, uses the `procfs` filesystem to store process information. While access to this information is protected, some metadata are publicly available. The `oom_adj_score` file is particularly useful for inferring the foreground app, as it indicates which app is least likely to be killed due to memory constraints.

### Use Cases and Implemented Attacks

To demonstrate the attacks, we have prepared several scenarios that highlight different vulnerabilities in the Android UI. Some representative interfaces are shown in Figure 2. An adversary can easily present transparent or sized activities on top of benign ones to trick the user into performing illegal actions or snifffing input data. The creation and delivery of the forged interface are trivial parts of the attack, often facilitated through Firebase.

### Lifecycle of the Attacks

The lifecycle of our attacks is as follows:
1. The adversary, Malory, uploads the malicious app to Google Play.
2. The app bypasses Bouncerâ€™s filters and tricks the user into downloading and installing it, as it requires no special permissions.
3. The app sends necessary input from the victim's phone through Firebase.
4. Malory delivers the payload for the attacks through Firebase.
5. Depending on the installed apps and Android version, the malicious app launches a forged activity or overlays a benign app.

### Specific Attack Scenarios

1. **Starting a Phone Call**: An application can use an intent to launch the "Phone" app with an arbitrary number, tricking the user into pressing the call button.
2. **Sniffing Private Data from Legitimate Apps**: For devices running Android prior to Nougat, an adversary can determine the foreground app and present a customized floating activity to request private user input. For Nougat, other methods like injecting fake notifications or creating fake shortcuts are used.
3. **Intercepting Sensitive Input**: If the adversary knows the foreground application, they can present a transparent activity to intercept the user's input.
4. **Fake Notifications**: A malicious app can create a forged notification for a target app, tricking the user into believing it is legitimate.
5. **Fake Shortcuts**: An application can create a shortcut on the home screen that launches a forged activity instead of the legitimate one.
6. **Installing Applications**: The malicious app can trick the user into installing another app, either to boost the adversary's stats or to install a more dangerous payload.
7. **Becoming Administrator**: The adversary can cover the device administration screen to trick the user into granting dangerous permissions.
8. **Tapjacking Revisited**: A grid of small, transparent activities can sense the user's finger movements and log touch events, allowing the adversary to infer sensitive information like PINs and credentials.

### Conclusions

User interfaces are crucial for user experience, but efforts to improve them may compromise OS security. The reported attacks, along with corresponding proofs of concept, have been communicated to Google. Some issues have been addressed, while others are still under investigation. To protect users and developers, the OS should enforce stricter controls on the creation of notifications and shortcuts, and handle events when activities lose focus and are overlaid. Additionally, applications should be able to detect and respond to changes in their interaction with the user UI, such as disabling sensitive elements or alerting users.

### Acknowledgments

This work was supported by the European Commission under the Horizon 2020 Programme (H2020), as part of the OPERANDO project (Grant Agreement no. 653704) and is based upon work from COST Action CRYPTACUS, supported by COST (European Cooperation in Science and Technology). The authors thank ElevenPaths for their valuable feedback and access to Tacyt.

### References

[References remain the same as provided in the original text]