Thus, the white box attacker is characterized by the knowl-
edge of (ùëì , ùë§). With that information, the attacker could ei-
ther run a basic exhaustive search, basic optimization strate-
gies, or more sophisticated approaches (especially solutions
that use the gradient signal from the attacked model).
‚Ä¢ Black box (
,
), the attacker is aware of the general
detection scheme, but unaware of internal variables, architec-
ture and exact thresholds used in the classification. We note
that our black box attacker is different from the one defined
in [6], ( ÀÜùëì , ÀÜùë§). Our attacker does not require the knowledge
of ùëì or its approximation ÀÜùëì . In our case, the nature of the
environment imposes that the attacker cannot query the
system even in a black box manner to get feedback on the
provided labels or confidence scores (this is done for example
in [12, 14, 56, 61]), as this would mean potentially raising
the alarm. Thus, we consider that the only assumption of
the attacker concerning ùëì is that Deep Learning techniques
are used for detection.
Given this taxonomy, the attacker can be classified for example,
as unconstrained white box.
3.3 Example Constraint Scenarios
We argue our Constrained and Unconstrained attacks represent
a realistic threat model in the ICS setting and fit the taxonomy
of attacks in the AML literature. In particular, practical ICS are
typically composed of multiple stages, and each stage is controlled
by a different PLC (i.e., different brands/models). Moreover, the ICS
can be deployed in a physically distributed manner. For example,
in the case of water distribution networks, pumping stations are
typically located kilometers away from the water reservoir. In this
heterogeneous setting, an attacker can either gain control over a
limited set of resources as practically demonstrated in [17], or the
ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=full,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,AAÀÜfZÀÜwAttacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=full,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,AAÀÜfZÀÜwAttacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=full,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,AAÀÜfZÀÜwAttacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=full,ACSAC2020,December7‚Äì11,2020,Austin,USAA.Erbaetal.Table1:Classificationofourattackermodelsbasedontrainingdataandfeatures,Datatuple(D,X)andalgorithmknowledgeandparameters.Access:(cid:32)=full,(cid:71)(cid:35)=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,(AAÀÜf,ZÀÜw).Attacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,=partial.Forallwhiteboxattacks,theDefensetupleis(f,w),forallblackboxattacks,AAÀÜfZÀÜwAttacker‚ÄôsXConstraintsDReadWriteUnconstrained¬ß5.4(cid:32)(cid:32)(cid:32)XPartially¬ß5.5(cid:32)(cid:32)(cid:71)(cid:35)XFully¬ß5.5(cid:32)(cid:71)(cid:35)(cid:71)(cid:35)D¬ß5.5(cid:71)(cid:35)(cid:32)(cid:32)theadversarialattackhastofindaperturbation(cid:174)Œ¥tominimizethereconstructionerrorbetweentheinput(cid:174)x+Œ¥andoutputÀÜ(cid:174)xoftheReconstruction-baseddetector.PleaserefertoSection4.1forfur-therdetailsonthetargetmodel.Inamathematicalnotation,itcanbewrittenasthefollowingconstrainedoptimizationprobleminEquation1:minimizeMSE=1nni=1(ÀÜxi‚àí(xi+Œ¥i))2s.t.(cid:174)Œ¥‚ààconstraintspace(Section3.2.2)real-timeconstraintsimposedbyCPSy((cid:174)x+(cid:174)Œ¥)=‚Äòsafe‚Äô(1)Wenotethattheattackswedemonstratearenotnecessarilyop-timal,astheconstraintsaresatisfiedwithnonuniquesolutions.Theattacksareconductedinreal-time(i.e.,inmillisecondspertimestep),notaposteriori(i.e.,appliedretrospectivelytoalongerse-quenceofsensorreadingsaftertheattackerfullyreceivesthem).3.2.2AttackerKnowledge.UsingtheadversariallearningnotationintroducedinSection2,aconcealmentattackischaracterizedbytheknowledgeoftheattackeraboutthetrainingdatasetD,featuresetX,learningalgorithmf,andtrainedparametersw.IntheICSsetting,theattackercanbecharacterizeddifferentlyaccordingtohisknowledgeoftheattackedsystem.Inordertoexplainourattackermodel,wesplitthetuple(D,X,f,w)intotwo:theDatatuple(D,X)andDefensetuple(f,w).Weassumetheattackertobeunconstrainedorconstrainedw.r.t.theDatatuple,i.e.,thesensorreadingsXthatshecanobserveandmanipulateandthedataDthatsheeavesdrops.Moreover,weclassifyattackersaswhitebox,blackbox,w.r.t.theDefensetuple,i.e.,theknowledgeoflearningalgorithmf,andtrainedparametersw.Table1,providesanoverviewoftheattacker‚Äôsconstraintsconsideredinthiswork.ConstraintsoverDataTuple.AccordingtotheDatatuple(D,X),weclassifytheattackeras:‚Ä¢Unconstrained(D,X),inwhichtheattackercanmanipulateallnfeaturesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetobeatmostn.‚Ä¢FeaturesPartiallyConstrained(D,ÀÜX),weassumethattheattackerisconstrainedtoperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢FeaturesFully-Constrained(D,ÀÜX),weassumethattheat-tackerisconstrainedtoobserveandperturbasubsetofkoutofnvariablesin(cid:174)x,andherperturbationsarelimitedintermsofL0distancetonotexceeddistancek.‚Ä¢DataConstrained(ÀÜD,X),weassumethattheattackerisconstrainedtoeavesdropalimitedquantityofprocessdatathatareusedfortrainingitsattacks.SelectionofConstrainedFeaturesThesubsetoffeaturesthatcanbemodifiedishighlyuse-casedependent(i.e.,whichlinkisattacked,whichdevicewascompromised).Todemonstratethegeneralityofourfindings,weexploredtwotypesofconstraints:abest-casescenarioandatopology-basedscenario.Forthebest-casescenario,weassumethattheselectionofthekoutofnmanipulatedfeaturescanbemadebytheattackertomaximizetheattackimpact.Thisarguablyrepresentsabest-casescenariofortheconstrainedattacker(i.e.,anattackerconstrainedtofeaturesthathappentoberelativelyidealfortheattacker).Forthesecondscenario,constraintsarederivedfromthenetworktopology.Weassumethattheattackercancompromiseasinglesubstation(orPLC)inthenetwork,andtheselectionofkoutofnfeaturesisbasedonwhichsensorsareinterconnectedtothecompromisedsubstation.KnowledgeofDefenseTuple.WeclassifytheattackeraccordingtotheirknowledgeoftheDefensetuple(f,w),as:‚Ä¢Whitebox(f,w),theattackerknowstheexactsystemmodelanditsvariables(suchasthecurrentlyestimatedsystemstate),andtheexactthresholdsoftheclassificationsystem.Thus,thewhiteboxattackerischaracterizedbytheknowl-edgeof(f,w).Withthatinformation,theattackercouldei-therrunabasicexhaustivesearch,basicoptimizationstrate-gies,ormoresophisticatedapproaches(especiallysolutionsthatusethegradientsignalfromtheattackedmodel).‚Ä¢Blackbox(AAÀÜf,ZÀÜw),theattackerisawareofthegeneralde-tectionscheme,butunawareofinternalvariables,architec-tureandexactthresholdsusedintheclassification.Wenotethatourblackboxattackerisdifferentfromtheonedefinedin[6],(ÀÜf,ÀÜw).OurattackerdoesnotrequiretheknowledgeofforitsapproximationÀÜf.Inourcase,thenatureoftheenvironmentimposesthattheattackercannotquerythesystemeveninablackboxmannertogetfeedbackontheprovidedlabelsorconfidencescores(thisisdoneforexamplein[12,14,56,61]),asthiswouldmeanpotentiallyraisingthealarm.Thus,weconsiderthattheonlyassumptionoftheattackerconcerningfisthatDeepLearningtechniquesareusedfordetection.Giventhistaxonomy,theattackercanbeclassifiedforexample,asunconstrainedwhitebox.3.3ExampleConstraintScenariosWeargueourConstrainedandUnconstrainedattacksrepresentarealisticthreatmodelintheICSsettingandfitthetaxonomyofattacksintheAMLliterature.Inparticular,practicalICSaretypicallycomposedofmultiplestages,andeachstageiscontrolledbyadifferentPLC(i.e.,differentbrands/models).Moreover,theICScanbedeployedinaphysicallydistributedmanner.Forexample,Constrained Concealment Attacks against Reconstruction-based detectors in ICS
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
whole plant (by compromising the network or central SCADA). We
capture those different capabilities of the attacker in the following
three scenarios:
‚Ä¢ The Unconstrained Attacker can read and write any features
arbitrarily, e.g., by compromising the SCADA system, as
modeled by Mo et al. [39].
‚Ä¢ The Partially Constrained attacker can read all traffic received
by the SCADA system (for example by a passive wiretap [55]
or by leveraging access control misconfigurations), but she is
only able to spoof sensor readings from a specific substation,
exploiting specific vulnerabilities of the substation or its
protocol to the SCADA (e.g., lack of authentication).
‚Ä¢ The Fully Constrained attacker relates to a scenario where an
attacker compromised a specific substation, giving him read
and write access to features from this substation only [1, 17].
Similar assumptions were also considered in the BATADAL
dataset [53], where the attacker was assumed to perform con-
strained replay attacks to reduce the confidence of anomaly de-
tectors. In our contribution, we perform a concealment attack in a
systematic way to assess their impact over the anomaly detector.
A similar intuition is also used in the FAIL attacker model [49] for
AML. In particular, FAIL proposes to characterize attacker knowl-
edge over 4 dimension: Feature, Algorithm, Instance, Leverage.
While the first three have a counterpart in systematization by Big-
gio et al. [6], Leverage stands for the subset of features that the
adversary can modify (just like our constrained attacker). Thus,
our Unconstrained and Constrained attacks represent attacks with
full and limited Leverage.
3.4 Our Framework for Attack Computation
For both the white box and black box case, the attacker is assumed
to intercept and manipulate a Constrained or Unconstrained set of
sensor readings in real-time.
In the white box setting, we propose an iterative attack, able
to interactively query a classification oracle to determine which
features to manipulate, and the value to assign to those features. We
propose to compute the manipulations using an iterative algorithm.
This algorithm calculates solutions that are ‚Äòsafe‚Äô from the detector
perspective. The algorithm is tunable, i.e., the attacker can act on
some algorithm parameters that impact over time the computation
and, consequently, the concealment efficacy. Again, this speeds up
computation but can impact the solution quality.
In the black box setting, we propose the use of a learning based
attack, specifically a Deep Neural Network that is capable of out-
putting concealed sensor readings, without the oracle‚Äôs feedback.
The attacker is adversarially training the neural network to learn
how the detector expects the ICS to behave. This trained neural
network then receives the traffic coming from the PLC. While the
attacker creates an anomaly over the physical process, the neural
network adjusts the anomalous data to resemble ‚Äòsafe‚Äô data. This
manipulated version of sensor data is sent to the SCADA.
In order to avoid confusion, we point out explicitly that our iter-
ative attack can operate under the attacker white box assumption
as it requires to query an oracle of the anomaly detector, while the
learning based attack can operate under the black box assumption
as no query access is required to compute the adversarial sensor
readings. We compare iterative and learning based approaches with
replay attacks, as proposed in literature [39]. The attacker that
performs a replay attack can be categorized as black box.
4 DESIGN OF CONCEALMENT ATTACKS
We now present a detailed design for the three attacks that we
consider. We start with details on the (prior work) Reconstruction-
based attack detector, then introduce the replay attack (proposed
by [39]). We provide details on the iterative attack (white box knowl-
edge). We then conclude with the learning based approach (black
box knowledge), which leverages an online concealment method
without any prior knowledge about the physical process that gen-
erates the sensor readings and the detection scheme. Given these
premises, we note that, while adversarial examples found using the
iterative approach depend on the internal structure of the attacked
anomaly detector, examples crafted through the learning based
approach are independent from the addressed detection scheme
(see Section 5.6).
4.1 Background: Reconstruction-based Attack
Detector
In this work, we target anomaly detection systems proposed in
prior works [20, 32, 51], which share the same underlying idea,
reconstruction-based anomaly detection.
The anomaly detector consists of two parts, namely a Deep
Learning autoencoder model (with ùëö √ó ùëõ features as input and ùëõ
output) trained over the normal operation sensor readings of an
ICS to optimize Mean Squared Error Loss, and a classifier function.
The idea is that the deep model has learned to reproduce the system
behavior under normal operating conditions with a low reconstruc-
tion error, so it reproduces a higher reconstruction error when
fed with anomalous sensor readings. The comparison between the
input and output of the deep model is used to decide if the system
is ‚Äòsafe‚Äô or ‚Äòunder attack‚Äô. Reconstruction based classifiers represent
the state of the art for anomaly detection in ICS on a multi-fold
basis. First, they can overcome the problem of shortage of ‚Äòunder
attack‚Äô samples that are hard to be gathered from the system with-
out damaging the plant. Second, they can capture interdependence
between sensor signals that helps localization of anomalies. Third,
they guarantee a low time of detection, which is a fundamental
property for ICS anomaly detectors.
As reference implementation, we use the general Autoencoder-
based anomaly detector framework proposed in [51] and available
as open source [46]. Moreover, we explore transferability of our
black box attack between different Deep Architectures (DA) in Sec-
tion 5. In particular we tested Long Short Term Memory (LSTM) [25]
as proposed in [20] and Convolutional Neural Networks (CNN) [33]
as proposed in [32]. The input to the DA is ùëã = [ (cid:174)ùë†ùë°‚àíùëö, . . . , (cid:174)ùë†ùë°],
representing ùëö + 1 time-steps of (cid:174)ùë† = [ùëü1, ùëü2, . . . , ùëüùëõ], which is an
ùëõ-dimensional vector of sensor readings. DA‚Äôs goal is to find ùúô
parameters that minimize following the Mean-Squared Error opti-
mization problem:
E(ùëã , (cid:174)ùë†ùë°)‚àºD(cid:2)‚à•ùê∑ùê¥(ùúô, ùëã), (cid:174)ùë†ùë° ‚à•2
2(cid:3)
min
ùúô
(2)
where DA outputs an n-dimensional vector (cid:174)ùëú = [ùë£1, ùë£2, ..., ùë£ùëõ],
and ùë£ùëñ ùë†.ùë° . ùëñ ‚àà {1, ..., ùëõ} represents the reconstructed value w.r.t. the
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
A. Erba et al.
input reading ùëüùë°