# 查看下一个月违约率的情况next_month = data['default.payment.next.month'].value_counts()print(next_month)df = pd.DataFrame({'default.payment.next.month': next_month.index,'values': next_month.values})plt.rcParams['font.sans-serif']=['SimHei'] 
# 用来正常显示中文标签plt.figure(figsize = (6,6))plt.title('信用卡违约率客户\n (违约：1，守约：0)')sns.set_color_codes("pastel")sns.barplot(x = 'default.payment.next.month', y="values", data=df)locs, labels = plt.xticks()plt.show()
# 特征选择，去掉 ID 字段、最后一个结果字段即可data.drop(['ID'], inplace=True, axis =1) #ID 这个字段没有用target = data['default.payment.next.month'].valuescolumns = data.columns.tolist()columns.remove('default.payment.next.month')features = data[columns].values
# 30% 作为测试集，其余作为训练集train_x, test_x, train_y, test_y = train_test_split(features, target, test_size=0.30, stratify = target, random_state = 1)    
# 构造各种分类器classifiers = [    SVC(random_state = 1, kernel = 'rbf'),        DecisionTreeClassifier(random_state = 1, criterion = 'gini'),    RandomForestClassifier(random_state = 1, criterion = 'gini'),    KNeighborsClassifier(metric = 'minkowski'),]
# 分类器名称classifier_names = [            'svc',             'decisiontreeclassifier',            'randomforestclassifier',            'kneighborsclassifier',]
# 分类器参数classifier_param_grid = [            {'svc__C':[1], 'svc__gamma':[0.01]},            {'decisiontreeclassifier__max_depth':[6,9,11]},            {'randomforestclassifier__n_estimators':[3,5,6]} ,            {'kneighborsclassifier__n_neighbors':[4,6,8]},] 
# 对具体的分类器进行 GridSearchCV 参数调优def GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, param_grid, score = 'accuracy'):    response = {}    gridsearch = GridSearchCV(estimator = pipeline, param_grid = param_grid, scoring = score)    
# 寻找最优的参数 和最优的准确率分数    search = gridsearch.fit(train_x, train_y)    print("GridSearch 最优参数：", search.best_params_)    print("GridSearch 最优分数： %0.4lf" %search.best_score_)predict_y = gridsearch.predict(test_x)    print(" 准确率 %0.4lf" %accuracy_score(test_y, predict_y))    response['predict_y'] = predict_y    response['accuracy_score'] = accuracy_score(test_y,predict_y)    return response for model, model_name, model_param_grid in zip(classifiers, classifier_names, classifier_param_grid):    pipeline = Pipeline([            ('scaler', StandardScaler()),            (model_name, model)    ])    result = GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, model_param_grid , score = 'accuracy')    运行结果：(30000, 25)                 ID             ...              default.payment.next.monthcount  30000.000000             ...                            30000.000000mean   15000.500000             ...                                0.221200std     8660.398374             ...                                0.415062min        1.000000             ...                                0.00000025%     7500.750000             ...                                0.00000050%    15000.500000             ...                                0.00000075%    22500.250000             ...                                0.000000max    30000.000000             ...                                1.000000 [8 rows x 25 columns] GridSearch 最优参数： {'svc__C': 1, 'svc__gamma': 0.01}GridSearch 最优分数： 0.8174准确率 0.8172GridSearch 最优参数： {'decisiontreeclassifier__max_depth': 6}GridSearch 最优分数： 0.8186准确率 0.8113GridSearch 最优参数： {'randomforestclassifier__n_estimators': 6}GridSearch 最优分数： 0.7998准确率 0.7994GridSearch 最优参数： {'kneighborsclassifier__n_neighbors': 8}GridSearch 最优分数： 0.8040准确率 0.8036![](Images/a3d863c2561d190cd8cb47d1e87780c6.png){savepage-src="https://static001.geekbang.org/resource/image/18/72/187d0233d4fb5f07a9653e5ae4754372.png"}\从结果中，我们能看到 SVM 分类器的准确率最高，测试准确率为 0.8172。在决策树分类中，我设置了 3 种最大深度，当最大深度 =6时结果最优，测试准确率为 0.8113；在随机森林分类中，我设置了 3个决策树个数的取值，取值为 6 时结果最优，测试准确率为 0.7994；在 KNN分类中，我设置了 3 个 n 的取值，取值为 8 时结果最优，测试准确率为0.8036。
## 总结今天我给你讲了随机森林的概念及工具的使用，另外针对数据挖掘算法中经常采用的参数调优，也介绍了GridSearchCV工具这个利器。并将这两者结合起来，在信用卡违约分析这个项目中进行了使用。很多时候，我们不知道该采用哪种分类算法更适合。即便是对于一种分类算法，也有很多参数可以调优，每个参数都有一定的取值范围。我们可以把想要采用的分类器，以及这些参数的取值范围都设置到数组里，然后使用GridSearchCV 工具进行调优。![](Images/a754b4c6c9827207dfa1a8fdbc874ac0.png){savepage-src="https://static001.geekbang.org/resource/image/14/16/14f9cddc17d6cceb0b8cbc4381c65216.png"}\今天我们讲了如何使用 GridSearchCV做参数调优，你可以说说你的理解，如果有使用的经验也可以分享下。另外针对信用卡违约率分析这个项目，我们使用了 SVM、决策树、随机森林和 KNN分类器，你能不能编写代码使用 AdaBoost 分类器做分类呢？其中 n_estimators的取值有 10、50、100 三种可能，你可以使用 GridSearchCV运行看看最优参数是多少，测试准确率是多少？欢迎你在评论区与我分享你的答案，如果有问题也可以写在评论区。如果你觉得这篇文章有价值，欢迎把它分享给你的朋友或者同事。![](Images/8b75105190797b2e4f7be2536b6543db.png){savepage-src="https://static001.geekbang.org/resource/image/48/96/48cb89aa8c4858bbc18df3b3ac414496.jpg"}
# 40丨数据挖掘实战（2）：信用卡诈骗分析上一篇文章中，我们用随机森林以及之前讲过的 SVM、决策树和 KNN分类器对信用卡违约数据进行了分析，这节课我们来研究下信用卡欺诈。相比于信用卡违约的比例，信用卡欺诈的比例更小，但是危害极大。如何通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷风险是我们这次项目的目标。通过今天的学习，你需要掌握以下几个方面：1.  了解逻辑回归分类，以及如何在 sklearn 中使用它；2.  信用卡欺诈属于二分类问题，欺诈交易在所有交易中的比例很小，对于这种数据不平衡的情况，到底采用什么样的模型评估标准会更准确；3.  完成信用卡欺诈分析的实战项目，并通过数据可视化对数据探索和模型结果评估进一步加强了解。