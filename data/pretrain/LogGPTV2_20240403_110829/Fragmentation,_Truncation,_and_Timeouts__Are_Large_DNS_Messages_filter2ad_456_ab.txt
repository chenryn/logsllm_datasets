599
Then, we proceed to analyze the number of DNS/UDP fragmented responses
per authoritative server and IP version. Figure 2 shows a timeseries of these
1 We also see that the response sizes almost doubled for NS3 from 2019 to 2020,
although the NS3 operator conﬁrmed they have not changed minimal response sizes
or ENDS buﬀer sizes in the period.
Fragmentation, Truncation, and Timeouts: Are Large DNS
465
responses. We see very few occur: fewer than 10k/day, compared to a total
of 2.2B/day. Notice that NS1 has no fragmented responses in 2020, which is
probably due to the reduction on the response sizes in 2020 (Table 2).
Fig. 2. UDP fragmented queries for .nl authoritative servers.
Still, even if there are few fragmented queries, why do they occur? First, we
see most fragmented queries are from NS3 (Fig. 2), given NS3 does not return
minimal responses (Sect. 3.1), which inﬂates responses2.
But the resolvers have their own share of responsibility. We single out these
DNS/UDP fragmented responses, and analyzed the announced EDNS0 buﬀer
sizes. Figure 3 shows the results for July 2020, for both IPv4 and IPv6. We see
that most fragmented queries are smaller than 2048 bytes, but we see that most
of these resolvers announced a large EDNS0 buﬀer size – most equal to 4096
bytes, which is the default value on BIND (up to version 9.16.6)3,4 [24]. So while
our vantage point does not allow to tell if clients experience fragmentation on
their side, it shows that authoritative servers very rarely fragment responses.
Packets Larger Than Path MTU: Since we collect traﬃc only at the author-
itative servers, we cannot directly know if there was IPv4 fragmentation along
the path. However, we can still use the ICMP protocol to determine if some of
the DNS responses exceed the path MTU.
The routers along the path have a standard way of handling IP packets larger
than their MTU, both using ICMP. If it is an IPv4 packet, and the fragmented
ﬂag (DF) is set, then the router should discard the packet and send a ICMP
Type 3, code 4 packet as a response (“Fragmentation Needed and Don’t Frag-
ment was Set” [38]) back to the authoritative server. If the DF ﬂag is oﬀ, then
2 The advantage of having minimal responses disabled is that it can reduce the total
number of queries, given resolvers already receive extra information.
3 BIND9 uses a dynamic EDNS value: when it ﬁrst contacts a server, it uses 512 bytes.
From that point on, it uses the conﬁgured value – 4096 by default. If it receives no
responses, it will lower it to 1432, 1232 and 512 bytes. See edns-udp-size in [24].
4 Unbound changed the default buﬀer size to 1232 on 29 sept. 2020 [55], and so did
BIND on version 9.16.8.
466
G. C. M. Moura et al.
Fig. 3. Fragmented Queries July 2020: response sizes and EDNS0 buﬀer sizes.
the router can fragment the packet – and no ICMP signaling is sent back to
the authoritative server. Last, IPv6 packets cannot be fragmented by routers,
and routers facing them should send an ICMPv6 Type 2 message (“packet too
big” [26]) back to the authoritative server.
In our setup, only the DNS provider of NS3 provides us with ICMP traﬃc.
We analyze the ICMP traﬃc and show in Table 3 distribution of ICMP error
messages associated with large packets, and see there are only few ICMP packets.
In the worst case scenario, these large DNS/UDP would be discarded by
routers and both client and servers would not know about it, which could, in
theory lead to unreachability. However, previous research has shown that, in the
wild, DNS resolvers have built-in a series of fail-tolerance features, and will retry
multiple times the same server and or switch from server/IP version, to the point
of “hammering” the authoritative severs, in order to obtain responses [33,35].
In this scenario, even if one authoritative server becomes “unresponsive” – from
the point-of-view of the resolver – having multiple authoritative servers (deﬁned
by distinct NS records), running on dissimilar networks, should minimize the
probabilities of unreachability.
Network Issues with Large Responses: Our vantage point does not allow to
know if clients received their large DNS/UDP responses. To determine if clients
indeed receive large responses, we resort to Ripe Atlas probes and NS3, and
evaluate 1M queries from roughly 8500 probes, over a period of one day. We
show in Sect. A.1 that 2.5% of small (221 bytes) DNS/UDP responses time-
out. For large responses (1744 bytes), this value is 6.9% – only considering a
single DNS/UDP query without TCP fallback. Comparing to server-side frag-
mentation, we show that it is far more likely to happen on the network. Similar
numbers were reported by Huston [22], who measured 7% drop with a similar
response size on IPv6 and Van den Broek et al. [51] have shown that even up to
10% of all resolvers might be unable to handle fragments.
3.3 DNS Truncation: How and When?
Table 1 shows that 2.93–7.15% of all evaluated queries were truncated. Next we
investigate why this happens. For each truncated response, we fetch its response
Fragmentation, Truncation, and Timeouts: Are Large DNS
467
size and its respective query’ EDNS0 buﬀer size. Figure 4 shows the CDF for
these values for July 2020, for NS1 (Sect. A shows NS3 for 2020 and the 2019
results for NS1 and NS3). We see that most DNS/UDP responses are truncated
to values under 512 bytes, independently IP version (Response line).
Fig. 4. NS1: CDF of DNS/UDP TC responses for .nl: July 2020
Small or no EDNS0 values lead to truncation: we see that most EDNS buﬀer
sizes are equal to 512, which is rather too small for many queries (but the initial
value by BIND when it ﬁrst contact a server [24]). As such, if resolvers would
advertise larger buﬀers, that would probably reduce truncated responses.
Oddly, we also see that only NS1 receives 13% of queries that are truncated
with no EDNS0 extension, but not the other servers or IP version (shown as
EDNS0=1 in Fig. 4). We found that this is due to an anomaly from two ASes
(AS2637 – Georgia Tech and AS61207 – Ilait AB). Resolvers from these ASes
have a “sticky” behavior [35], sending queries only to NS1 over IPv4. Both ASes
send most queries without EDNS0 UDP buﬀer value (1 in the graph), and that
is why Fig. 4a is skewed.
Large EDNS0 values are no insurance against truncation: We also see that
even if clients announce large EDNS0 buﬀers, they still receive truncated
responses. Even though 4096 bytes is enough to ﬁt most responses (§3.1),
the authoritative server can truncate responses based on its local MTU or
max-udp-size.
3.4 Do Resolvers Fall Back to TCP?
Upon receiving a DNS/UDP truncated response, DNS resolvers should resend
the query over TCP – what is know as TCP fall back [10]. In July 2020 (Table 1),
we see 7.15% DNS/UDP TC queries over IPv6. However, we see only 5.37% of
TCP queries over IPv6 – suggesting 1.78% were not followed by DNS/TCP
queries. We next investigate this behavior.
Figure 5 shows how many UDP responses with TC ﬂag are followed by a
TCP query, within 60 s from the same IP address. The majority, 80% in IPv4
468
G. C. M. Moura et al.
Fig. 5. TC replies with TCP retries
Fig. 6. Time until ﬁrst TCP fall back
and 75% in IPv6 of these replies are retried via TCP within this time frame per
day in July 2020 (on median). For zones where responses often are larger than
1232 bytes this means that after the Flag Day, they will see an increase in TCP
connections.
If a resolver retries a query via TCP, then this query is sent usually within
less than 100 ms. Figure 6 shows the time between the name server received the
initial UDP query and the TCP retry on July 1 2020. 80% of all retries are sent
within 100 ms and 90% within one 1 s. Retries from IPv6 addresses reach our
authoritative servers slightly faster.
Missing TCP Queries: there are multiple reasons why truncated queries may
not be followed by TCP ones. For example, queries from non-resolvers, such as
crawlers, or malware. Also, as we discuss in Sect. 2, our datasets do not include
data from NS2, the other anycast authoritative server for .nl. Given resolvers
may switch from server to server [35], our dataset misses those5. Resolver farms
may be partially to blame – the TCP query may be sent from adjacent IP
addresses6. Dual-stacked resolvers may only send a TCP query over one (the
ﬁrst) IP version response arriving7. Altogether, we estimate that we miss up to
4.8% of retries in our initial measurement.
This still leaves 15–21% of TC replies without a TCP retry. We found that,
for July 1st 2020, 47% of these queries without TCP retries were from Google
(AS15169), a well-known large public resolver operator [16] that employs a com-
plex, multi-layered resolver architecture spread across diﬀerent IP ranges [34].
5 We see 1.9% of TC IPv4 queries switching between NS1 and NS3 on July 1st, 2020,
and 3.2% of IPv6 TC queries.
6 For July 1 2020, we measure, how many TCP retries are ﬁrst issued from a diﬀerent
resolver than the resolver of the original UDP query, but located in the same subnet
(/24 subnet for IPv4 and /48 subnet for IPv6). There, 1.6% of retries via IPv4 and
0.1% via IPv6 are sent from a diﬀerent resolver, likely belonging to the same farm.
7 Of a sample of 3M queries that trigger a TC response, 4% were likely issued by
those kind of resolvers. 58% then sent their TCP retry via both interfaces, leaving
42% of the TC replies without a TCP retry. Extrapolating these numbers to our
measurements we can assume that around 1.3% of TC replies are not retried via
TCP because of dual stacked resolvers.
Fragmentation, Truncation, and Timeouts: Are Large DNS
469
Given their large infrastructure, one could hypothesize that Google could use a
diﬀerent resolver to send the TCP fallback query. To evaluate if that is the case,
we extend our query matching criteria for TCP fallback: for each DNS/UDP TC
reply, we evaluate if any IP address from Google (AS15169) sent a TCP query
within 60 s after the sending of the TC reply. By doing this, we ﬁnd that, in
fact, Google resolvers almost always fallback to TCP, by having 99% of UDP
TC queries being followed up by a TCP query. This shows how dynamic and
complex a large DNS service can be.
4 Resolver EDNS0 Buﬀer Sizes
Next we analyze the EDNS0 buﬀer sizes for all resolvers we seen in our
datasets (Table 1). For 2020, we see in Fig. 7a that roughly 30% of all resolvers
announce 512 bytes EDNS0 buﬀer sizes or less, and 48.86% announce 1232 or
less. The majority announce 4096 bytes: 33%. For ASes, we have a more even
distribution: 20% announce 512 bytes or less, and 71% announce up to 1232 or
less. Taking altogether, we can conclude that most resolvers announce a 4096
ENDS0 buﬀer size value (which is BIND9 default value up to version 9.16.7) are
to blame partially for DNS/UDP fragmentation.
Fig. 7. EDNS0 per resolver and values: July 2020
Figure 7b shows he number of unique EDNS0 buﬀer sizes announced per
resolver for the month of July 2020. We can see that more than 60% of resolvers
announce only one EDNS0 value over the period. Only 5% of the resolvers showed
3 or more EDNS0 values in the period – maybe due to dynamic ENDS values [24]
or conﬁguration changes. Finally, 7% of resolvers (not shown in the ﬁgure), have
no EDNS0 support – likely from old, non compliant clients.
470
G. C. M. Moura et al.
4.1 DNS Flag Day 2020: What Was the Uptake?
The DNS Flag Day 2020 was proposed by members of the DNS community in
order to avoid IP fragmentation on DNS/UDP, by not allowing UDP queries
larger than 1232 bytes. This value was chosen based on a MTU of 1280 bytes
– the minimum required by IPv6 [9] – minus 48 bytes of IPv6/UDP headers.
The chosen date (2020-10-01) was a suggestion for operators to change their
authoritative DNS servers and DNS resolvers.
To determine the Flag Day uptake, we compare the EDNS0 values from
resolvers from July 2020 to October 2020, from Table 1, for UDP queries. The
former we used it as a baseline, and the observed diﬀerences in the latter deter-
mine the uptake. Table 4a summarizes this data. We see in total 1.85M resolvers
active on both datasets, and they sent 117.5B queries in the period.
Table 4. DNS Flag day datasets and changing resolvers
Resolvers
∩
UDP Queries
∩
July 2020 October 2020
3.78M
3.84M
1.85 M
60.3B
62.81B
117.54 B
(a) Before and After Datasets
Resolvers
11338
7881
from 4096 bytes
1807
from 1680 bytes
1252
from 512 bytes
398
rest
958
ASes
3.01B
Queries
(b) EDNS0 1232 resolvers
Figure 8 shows the CDF of resolvers’ EDNS0 buﬀer sizes. We see hardly
any changes in the resolver EDNS behavior (if the resolver had multiple EDNS
values, we picked the most frequent, also to remove BIND9 512 byte at the ﬁrst
try). On July 2020, we see 14.6% of the resolvers using EDNS0 buﬀers smaller
or equal to 1232 bytes, and on October 2020, this value went to 16.0%. For
both months, however, the most popular EDNS0 buﬀer value is 4096 bytes, with
roughly 53% of the resolvers using it.
Resolvers that Adopted the DNS Flag Day Value: We identiﬁed 11338 resolvers
that changed their EDNS0 value to 1232 bytes, as can be seen in Table 4. There
resolvers were responsible for 3.01B queries, out of the 117.54B. They belonged
to 958 diﬀerent ASes, but most of them (6240) belonged to only two ASes – one
in Taiwan and the other in Poland.
Looking Back to 1.5 Years: The Flag Day 2020 was originally proposed in Oct.
2019. Given some operators may deploy it before the Flag Day chosen date
(Oct. 1 2020), we analyze the proportion resolvers we see over more than 1.5
years (May 2019-December 2020). Figure 9 shows the percentage of unique IP
addresses announcing diﬀerent buﬀer sizes per day. From May 2019 to Oct. 2020,
we see that despite the increase of resolvers using EDNS0 1232, they winded up
Fragmentation, Truncation, and Timeouts: Are Large DNS
471
Fig. 8. CDF EDNS0 resolvers
Fig. 9. Daily EDNS buﬀer distribution
by resolvers (y axis in log-2 scale).
accounting for only 4.4% of the total resolvers. 4096 byte resolvers reduced from
50% to 40%. Since November 2020 the number of resolvers announcing 1232 bytes
is growing faster and has reached 6.5% by the end of December 2020. Despite
the latest increase, these results show that a large population of resolvers still
needs to be reconﬁgured to use EDNS0 1232 bytes.
5 Related Work
IP Fragmentation:
the problems related with IP fragmentation are well
known [5]: it has problems with “middleboxes” (such as network address transla-
tion (NAT) devices, with stateless ﬁrewalls), by being expensive and error prone
and may lead to unreachability [4,5,8,14]. It has also security vulnerabilities – it
has been used DNS for cache poisoning attacks on DNS [17,50], and to compro-
mise CAs based on it. Besides, there are several well-know attacks that exploit
fragmentation [13,25,30,57]. Given these series of problems, IP fragmentation is
considered fragile and should be avoided, also in DNS [5,12,58].