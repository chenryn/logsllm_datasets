in a decision tree based on Apache web server’s access control
implementation.
The IF-THEN structure of DT can also effectively encode rules
with regular expressions. For example, a rule that allows access to
“/proj/*/1.htm” can be encoded as:
1 IF ( $prefix1 is "/proj") THEN
2
3
IF ( $prefix2 is "1. htm") THEN
ALLOW
Time-Changing Decision Tree (TCDT). One key limitation of
the traditional decision tree is that it cannot work with time-series
data where policies change over time, and thus cannot represent
access control policy changes. As a result, P-DIFF cannot be built
using traditional DT techniques.
IF $prefix1 == "/proj"TrueIF $method == "GET"TrueFalseFalse...Policy InferenceTime-Changing Decision Tree (TCDT)Access logsT1, PUT, /proj/1.html DENYT2, GET, /proj/2.html DENYT3, GET, /proj/3.html DENYT4, GET, /proj/4.html ALLOWT5, GET, /proj/5.html ALLOWT6, PUT, /proj/6.html DENY... Change validation:Detect new policy changesForensics:Diagnose accesses of interestSysadminALLOWDENYTimestampStatusT2T3T4T5ALLOWDENYTimestampStatusT1T6Figure 5: An example of access-control policies in configu-
ration files, access logs, and a decision tree. T1-T6 are the
timestamps.
In order to maintain the evolution history of access control poli-
cies, we design TCDT. A TCDT has a similar exterior structure as a
traditional DT. Differently, TCDT makes each leaf node encodes a
time series T :
T = ((τ1, r1),(τ2, r2),· · · ,(τn, rn))
(1)
which represents the result values during the time period (ri repre-
sents the result value of the interval [τi , τi +1]).
Figure 6 shows a TCDT generated from access logs in Figure 4
and compares it with a traditional DT generated from the same logs.
We can see that with the time series in each leaf node, historical rule
changes can be easily represented. For applications like continuous
access control monitoring, the precision can be largely improved by
learning from recent results instead of aggregating all the results,
as shown in our evaluation result in §10.4. Note that the application
of TCDT is not limited to access control monitoring and forensics.
The TCDT data structure and the TCDT learning algorithm can
be used in other works that need to infer rules from continuously
changing time-series data.
TCDT is fundamentally different from Time-Series Decision
Tree in machine learning literature [72]. A time-series decision tree
classifies a sequence (attributes of a period) into different categories.
However, TCDT classifies a “point” (attributes at a single time) into
different categories. We position TCDT in the machine learning
literature and discuss the related work in detail in §12.
Unknown attributes and values. The attributes and values in
both DT and TCDT are limited to the one observed in the access
logs. However, when a decision-tree is adopted to classify the access
result of a new-coming access, the related attributes and values may
not be seen before. In a traditional decision tree, classification will
be done with the probability in a leaf node of the False branches.
This may cause false classifications and thus miss changes. We
address this problem by adjusting our TCDT to explicitly classify
such an access as UNKNOWN. When an access is detected as UNKNOWN,
P-DIFF will conservatively notify system admins to validate if there
is a change. Then P-DIFF will build a new TCDT so that those
unknown attributes and values can be encoded. We show in §10.6
that building a new TCDT is efficient. It takes 19 minutes to build a
TCDT from 320 million log entries collected from the Wikipedia
website (cf. Figure 12 in §10.7).
Figure 6: A traditional decision tree and a Time-Changing
Decision Tree (TCDT) generated from the logs in Figure 4.
Both decision trees have the same internal nodes; however,
in a traditional decision tree, the leaf nodes are associated
with proportional results; in a TCDT, the leaf nodes are as-
sociated with the time-series results which can be used to
represent policy changes.
7 POLICY INFERENCE
This section describes the algorithms and mechanisms for inferring
access control policies from access logs. Note that we do not con-
sider policy changes in this section and thus do not differentiate a
traditional decision tree versus a TCDT. We discuss policy change
management in §8.
7.1 Parsing Access Logs
P-DIFF parses logs based on sysadmins’ annotations on the log
format. To reduce the manual work and to make it general, P-DIFF
does not require detailed annotation of each field’s semantics, such
as URL, IP, user and group etc. Instead, P-DIFF abstracts fields into
five types: timestamp, hierarchical features, normal features, access
results, and other non-related fields. Table 3 shows the meaning of
each type. P-DIFF recognizes the timestamp for time-series ordering
and access results as a label of each access. P-DIFF differentiates
hierarchical features and normal features to further exploit the
inherent hierarchical namespace of access rules (cf. §7.3).
7.2 Policy Learning Algorithm
P-DIFF uses a classic decision tree learning algorithm [47] to build
the tree structure based on the access logs, described in Algorithm 1.
Before starting the algorithm, the access log needs to be transformed
into the algorithm’s input format
L = {(xi1 , . . . , xin , y)|i ∈ [1, m]}
(2)
where (xi1 , . . . , xin) is the feature vector generated from the access
attributes (subject, object, action), y is the prediction label from ac-
cess result r, and m is the number of log entries. Each subject, object
and action attribute could have more than one feature, respectively
and each feature is transformed into a unique field in (xi1 , . . . , xin).
For instance, a subject can have features of both username and
group, so two fields are created in the feature vector. P-DIFF ex-
pands the hierarchical features using the methods described in §7.3
Access logsT1, GET, /proj/1.htm ALLOWT2, PUT, /proj/2.htm DENYT3, GET, /proj/3.htm ALLOWT4, PUT, /proj/4.htm DENYT5, GET, /proj/5.htm ALLOWT6, PUT, /proj/6.htm DENY... IF $prefix1== "/proj"IF $method== "GET"100% DENYTrueFalseDecision Tree RepresentationConfiguration  AllowMethods GET...100% ALLOWTrueFalseIF $method == "GET"Traditional Decision Tree Representation50% ALLOW50% DENYTrueFalseIF $method == "GET"Time-Changing Decision Tree RepresentationTrueFalseALLOWDENYTimestampStatusT2T3T4T5......IF $prefix1 == "/proj"TrueIF $prefix1 == "/proj"TrueFalseFalse......Annotation Semantics
Algorithm 1 Decision Tree Learning
Field
Timestamp
Hierarchical
feature
%t
%h(*)
Timestamp of each access
Features with hierarchical names-
pace, such as IP address, URL, etc. *
is a delimiter character.
Non-hierarchical features
%n
Normal
feature
Access re-
sult
Irrelevant
Table 3: Annotations of the log format. P-DIFF requires
users to annotate the access log format, which is a one-time
effort for a given system.
ALLOW or DENY
Irrelevant fields
%l
%o
and transforms the expanded features into a feature vector with
one-hot encoding [66].
Algorithm 1 takes L as input and grows the tree recursively. In
each recursive step, the algorithm splits one node into two child
nodes, by selecting a feature j and its value xij that split L into two
subsets with the purest labels, i.e. subsets with as large proportion
of ALLOW or DENY as possible. The two generated subsets are
Ll = {(xk1 , . . . , xkn , y)|k ∈ [1, m] ∧ xkj
= xij }
(3)
Lr = L − Ll
(4)
To find the feature j and its value xij , a metric function is adopted to
measure the label purity of a set. Traditional DT learning algorithms
use either entropy or Gini Impurity [10, 47] as the metric. We will
show that those metrics cannot handle policy changes in §8, and
the new metric we design for P-DIFF to learn TCDTs.
7.3 Namespace Inference
Decision trees inherently have the capability of representing hi-
erarchical namespaces in access-control rules. Unfortunately, tra-
ditional decision tree learning algorithms (e.g., Algorithm 1) do
not recognize hierarchical features well and thus cannot generate
the inherent hierarchical structure. For instance, given a file path
as a feature, such as "/projects/proj1.html", it is treated as
a single string; therefore, a node may be generated with a condi-
tion "path==/proj/1.html" but not with "prefix1==/proj".
To extend that, P-DIFF generates rules not only for the path, but
also for its parent directory "/proj".
P-DIFF makes two efforts to generate hierarchical rules. First,
P-DIFF adopts Quinlan-encoding [3] to expand the hierarchical
features. P-DIFF takes the annotations of hierarchical features (Ta-
ble 3) with a delimiter and expands a string with all its prefixes.
In the case of file path, once the feature is annotated as hierarchi-
cal and delimited with "/", then prefix features will be generated,
such as "prefix0==/" and "prefix1==/projects". Note that
the annotation is a one-time effort.
Second, P-DIFF adopts a hierarchy-aware mechanism [77] for
the best-split step (Algorithm 1, Line 3) in the decision tree learning.
Specifically, P-DIFF follows a hierarchical order to choose a feature
that best-splits the input data. Let us assume that there exist three
1: function DTL(L) a
root ← treenode()
2:
i, xij ← best_split(L) b
3:
Ll , Lr ← split(L, i, xij) c
4:
mд ← metric_gain(L, Ll , Lr) d
5:
if mд! = 0 then
6:
7:
8:
9:
aL = {(xi1, . . . , xin , y)|i ∈ [1, m]}, the training data.
bFind the feature j and its value xij that split L into two purest subsets, i.e.
subsets with as large proportion of ALLOW or DENY as possible.
cSplit L into Ll = {(xk1, . . . , xkn , y)|k ∈ [i, m] ∧ xkj
Lr = L − Ll .
dCalculate metric(Ll )+metric(Lr )-metric(L), where metric is a function measures
the label purity of a set, e.g. entropy or Gini Impurity.
root.left ← DTL(Ll)
root.right ← DTL(Lr)
return root
= xij } and
attributes ["user","method", "file path"]. P-DIFF first ex-
pands the three attributes to five features in the feature vector:
["user","method","prefix0", "prefix1","file name"].
P-DIFF then tries to choose a best-splitting feature from ["user",
"method","prefix0"] and if no feature results in change reduc-
tion, it tries ["prefix1"] and ["file name"] in order. Once
P-DIFF finds a feature with metric gain, it ensures that features at
a higher level of the hierarchy are considered before features at a
lower level.
8 POLICY CHANGE MANAGEMENT
8.1 Algorithm
Algorithm 1 and the other traditional decision tree (DT) learning
algorithms cannot deal with policy changes for two reasons. First,
traditional DTs cannot encode changes over time. P-DIFF addresses
this by using TCDT (§6).
Moreover, traditional algorithms (e.g., CART, ID3 and C4.5 [10,
47, 48]) cannot directly work with TCDT. This is because the split-
ting metrics (Gini Impurity and entropy) employed by traditional
algorithms do not consider rule changes over time—both Gini Impu-
rity and entropy are calculated based on the aggregated results and
fail to take the time information into account. Figure 7 shows two
cases that the splitting metrics in traditional DT learning cannot
decide whether to split or not in Algorithm 1’s split step, because
all the “purity metrics” are same before and after the split (Row
3). On the other hand, the correct split decision can be made if the
“time series” information is taken into account (Row 4).
L = ((τ1, x11 . . . x1n , y1), . . . ,(τm, xm1 . . . xmn , ym))
Therefore, we design a TCDT learning algorithm. Learning a
TCDT requires different training input and splitting metric from
Algorithm 1. For TCDT, the training input is a time-series sequence:
(5)
where τi < τj for i < j, xi1 , . . . , xin is the feature vector generated
from timestamped access attributes denoted as(timestamp, subject,
object, action), and yi ∈ {0, 1} is the prediction label from the ac-
cess result r. For splitting metric, we propose a new metric, change-
count, to effectively differentiate multiple unchanged rules from
one changed rule only based on logs, as shown in Figure 7.
Figure 7: Examples that demonstrate splitting events in TCDT-based policy learning (cf. §8). Case 1 does not require splitting,
while Case 2 does due to the condition: if prefix2=="/proj/1.htm". Traditional splitting metrics cannot decide whether
to split if a change is involved, because the possibility of ALLOW or DENY is always 0.5 in each subset (Gini Impurity: 1 −
(pallow)2 −(pdeny)2 = 0.5, Entropy: −pallow log(pallow)−pdenylog(pdeny) = 1). The time-series change counts differ in the subsets
and can guide correct splitting events.
Intuitively, the change-count of a time-series sequence is how
many times the end result is changed. Mathematically, for the time
series L, the change-count is defined as:
CC(L) =
|yi +1 − yi|
(6)
When splitting L into two sequences Ll and Lr , the algorithm
tries to find the feature j and its value xij in the way:
i =1
n−1

i, j =
argmax
i∈[1,m], j∈[1,n]
(CC(L) −
Lk ∈split(L, j,xij )
CC(Lk))
(7)
j
where split(L, j, xij) is a function that splits a sequence L by ex-
amining whether xi′
= xij , where i′ ∈ [1, m].
We set the splitting goal to be generating the least changes
possible—generating a new rule should reduce the total change-
count as many as possible. The goal can effectively decide when to
split in both cases of a single rule change and multiple rule changes,
as shown in Figure 7. Also, in the case that there is no rule change,
the goal can also make the correct splitting so that different rules
are generated, as shown in Figure 8.
8.2 Optimizations
Calculating change-counts, CC(L), defined in Equation (6) has a
significant impact on the training time for model generation, as
it needs to be calculated many times for every feature j and value
xii in Equation (7). Note that the change-counts are different for
different features and values, and the results cannot be directly
reused. Therefore, without an efficient implementation of change-
counts, P-DIFF cannot build the model in a short amount of time for
large volumes of access logs (e.g., the Wikipedia dataset evaluated
in §10 has more than 300 million log entries).
Our initial change-count implementation is to loop through the
entire access result array that stores the access result (with 0 to
represent ALLOW and 1 to represent DENY), as shown in Figure 9.
However, we find that this straightforward implementation is in-
efficient. It takes 51 minutes to train a model from 20 million log
entries, and more than 2 hours for 40 million log entries. Hence, it
cannot work with datasets at the similar scales of our Wikipedia
dataset (369 million entries).
To accelerate the training time, we design and implement the
following two optimizations as illustrated in Figure 9:
(1) We observed that in typical cases, ALLOW is much more
frequent than DENY. Therefore, looping through the entire
access result array is unnecessary. To improve it, our first
optimization only loops through all the DENYs and checks
for possible changes next to each DENY. Note that given
that the change-count needs to be calculated many times, we
generate an index of all the 1 values after the first change-
count calculation and use the index in the subsequent ones.
(2) We further adopt discrete convolution [50] to calculate the
sum of every two adjacent result numbers: if the sum is 1,
there is a change. We use the implementation of discrete
convolution as efficient vectorized operations in the Numpy
library [40].
With these two optimizations, our implementation of P-DIFF