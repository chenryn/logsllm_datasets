DRIVER_WRITE
FLOWRULE_WRITE
FLOWRULE_WRITE
FLOWRULE_WRITE
FLOWRULE_WRITE
Attacker’s capabilities if source data have been compromised by attacker
Attacker modifies the app ID to remove all flows with a given app ID
Attacker modifies the app ID to make an app run for leader election in a different
ONOS topic (i.e., an app using ONOS’s distributed primitives)
Attacker modifies the app ID to associate an app with a particular group handler
Attacker modifies the app ID to misapply a BGP configuration
Attacker modifies the app ID to misapply an SDN-IP encapsulation configuration
Attacker misallocates bandwidth resources based on a connectivity ID
Attacker misconfigures driver setup for a device (i.e., switch)
Attacker misconfigures flow rules based on a device ID
Attacker misconfigures flow rules based on a host with a particular MAC address
Attacker injects or modifies an incoming packet to poison a flow rule
Attacker injects or modifies an incoming packet to poison a flow rule
the accessing app’s role but also on the history of how data were
generated, a practitioner can limit the extent to which apps are
able to influence other apps while still maintaining the flexibility
afforded by a shared state design.
6 INFORMATION FLOW CONTROL POLICIES
We consider information flow control (IFC) policies as they relate
to detecting and preventing CAP attacks. We use a “floating label”
approach based on Myers and Liskov’s decentralized IFC model [53]
and on previous IFC policies that use data provenance [66, 77]. In
our policy model, a practitioner labels apps with integrity tags,
resulting in each app’s having its own integrity label composed of
a subset of integrity tags. We assume that apps’ label assignments
cannot be modified by any actions that the apps take themselves,
but that they can be changed out-of-band by practitioners as needed.
Our IFC policy model for shared SDN control plane state integrity,
denoted by I = (A,T , L, Ch, Re), consists of:
• A set of apps8, denoted by A = {a1, a2, . . . , ax}.
• A set of integrity tags, denoted by T = {τ1, τ2, . . . , τt}.
• Integrity labels that map apps to a subset of integrity tags,
denoted by L : A → P(T ), where P(T ) is the power set of T .
• An enforcement check policy on when to check for viola-
tions, denoted by Ch ∈ {READS, WRITES}.
• A response to perform when information flow is violated,
denoted by Re ∈ {BLOCK, WARN, NONE}.
An app’s integrity label that is a superset relative to another
app’s integrity label has higher integrity; that is, if L(ai ) ⊇ L(aj ),
then ai has integrity at least as high as that of aj for ai , aj ∈ A and
L(ai ), L(aj ) ∈ P(T ). We define an object’s integrity level, denoted
by I (o) for o ∈ O, as the intersection of all integrity labels of apps
that have helped generate that object. Formally, I (o) =
L(ai )
for some set of apps AN = {a1, a2, . . . , an} used in producing o.
This means that the object’s integrity level is as high as that of the
lowest-integrity app that helped generate it.
7 ProvSDN
We now present our defense, ProvSDN. ProvSDN hooks all of the
controller’s API interfaces to collect provenance from apps, builds
n(cid:84)
i
8For reasons explained in Section 7.1, we count switches as “apps.”
8
a provenance graph, and serves as an online reference monitor by
checking API requests against the IFC policy I. This allows us to
prevent both known and unknown CAP attacks based on policy.
7.1 Data Provenance Model
Data provenance refers to the process of tracing and recording the
origins of data and their movement. Provenance has been used to
understand the flow of data in databases [2, 13, 22, 28, 86], operating
systems [8, 45, 52, 67], mobile phones [3, 16], and browsers [40, 44].
Provenance can be used not just for IFC but also for information
tracing, accountability, transparency, and compliance [51, 79].
We use the W3C PROV data model [47, 51], which defines prove-
nance as a directed acyclic graph (DAG) that encodes the relation-
ships between three elements (i.e., vertices): entities are data objects
processed by a system, activities are dynamic actions in the system,
and agents are the principals that control system actions. Relations
(i.e., edges) describe the interactions between system elements. En-
titities are used or generated by activities; activities are associated
with agents; and activities may be informed by other activities. An
advantage of storing provenance graphically is that it allows for
efficient relational querying [7, 8, 27]. (See Table 4 in Appendix C
for a visual representation of provenance objects and relations.)
7.1.1 Entities. We define entities as the objects from Section 6,
which include the control plane’s shared data structures that are
being processed or generated by the SDN apps and controller. For
ONOS, we define entities at the “data class” granularity as described
in Section 5, since that definition captures fine-grained information
about switches, hosts, and the network topology as well as flow
rules, packets being processed, and OpenFlow messages sent or
received. ProvSDN can also flexibly specify additional metadata to
collect (e.g., traffic match fields for a flow entry), as needed.
7.1.2 Activities. We define activities as the API calls and call-
backs between SDN apps and the controller. For instance, these
calls enable apps to process flow rules and OpenFlow messages.
7.1.3 Agents. We define agents as the principal identities of the
apps, the switches, and the controller9. We treat switches as princi-
pal identities because, like apps that interact with the controller via
9Internal controller services can interact with the shared SDN control plane state
through event updates. We represent each internal controller service with its own
agent; each of those agents performs operations on behalf of the controller agent.
Cross-App Poisoning in Software-Defined Networking
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
the policy I against 1) the label of the requesting app L(ar ) and
n(cid:84)
2) the labels of the apps that the object previously encountered, or
L(ai ). Finally, we apply the response Re, which can block the
i
read request, warn the practitioner that the read request occurred,
or do nothing. If a policy is violated and the response Re in the
policy I is BLOCK, the relationship is removed10 and the action is
disallowed. Otherwise, the relationship is permanently added to
the provenance graph.
7.2.3 Provenance graph. ProvSDN’s provenance graph database
enables online policy checking via the reference monitor, as well
as offline investigation of previous events for network forensics.
7.3 Implementation
We implemented ProvSDN with ONOS v1.10.0. We describe our
implementation details below.
7.3.1 NB API. We found that the ONOS NB API was not well-
defined and thus was subject to questions about whether apps could
bypass provenance collection. To fix that, we used Doxygen [83]
to identify all publicly accessible classes in ONOS by counting the
number of references in the codebase to each of these classes; any
class referenced by more than three other classes was deemed to be
part of the NB API and properly exposed to SDN apps. Our static
analysis identified 63 classes with 721 methods that we used as
ONOS’s NB API (e.g., switch, host, link, and flow rule management).
It also identified 194 classes with 1,405 methods that are internal
to ONOS and should not be part of the NB API (e.g., distributed
storage primitives, and raw OpenFlow message handlers).
To prevent apps from bypassing provenance collection, we en-
force internal method checking (step 2 of Figure 6). If an internal
method call originates in another internal method, it is allowed; if
it originates in an app, it is blocked. This forces apps to use the NB
API through methods that capture provenance.
7.3.2 Provenance capture. The choice of programming language
is important to ensure that access to controller internals is possible
only through instrumented API calls. (See Appendix D for the
challenges of implementing provenance on other controllers.) We
found Java to work well in this regard by enforcing private or
public access modifiers. By default, Java’s controls are insufficient,
because it is possible to override the declared access modifiers by
using the Reflection API. Fortunately, static analysis can detect
reflection use if apps are checked prior to being loaded.
7.3.3 Processing and storage. We implemented the ProvSDN
provenance collector and online reference monitor in approximately
1,350 lines of Java code. We embedded approximately 420 prove-
nance hooks throughout the ONOS codebase to call ProvSDN’s
provenance collector. Upon initialization, the collector imports the
IFC policy I that the online reference monitor references when new
provenance relations have been added. We stored provenance data
in an internal JGraphT [56] graph structure for optimized graph
search (i.e., path existence) performance.
10To maintain an audit record, the relationship can remain in the provenance graph
but be marked as not existing for the purpose of online graph queries.
9
Figure 6: ProvSDN architecture showing an app calling the
NB API. 1: An app makes a NB API request. 2: The NB API
tentatively retrieves or inserts data related to the request.
3: The collector processes the call information. 4: The col-
lector writes the provenance data to the provenance graph.
5: The online reference monitor checks the provenance
graph for violations according to the IFC policy. 6: The IFC
policy’s response is returned to the NB API. 7: Depending on
the response, the data may be returned to the app or may be
written to the shared SDN control plane state .
the NB API, switches interact with the controller via the SB API.
We attribute all activities (i.e., API calls) to the agents that requested
them, effectively identifying all activities of apps and switches that
interact with the shared SDN control plane state.
7.2 System Components
Figure 6 shows the ProvSDN architecture. We assume that the
provenance components are trusted and adequately secured.
7.2.1 Provenance collector. The provenance collector captures
the API call information, such as which method was called, who
called it, what data were used, and what data were subsequently
generated. The collector also identifies relations and the agents,
activities, and entities involved. From there, the collector converts
the data into a W3C PROV-compliant graph. ProvSDN also collects
information from SB API calls, given that some NB API calls cause
packets in the data plane to be sent to the controller. ProvSDN
hooks the SB API functions responsible for sending flow rules
and processing incoming packets. That allows for association of
incoming OpenFlow packets with the flow rules that caused them
to be sent to the controller and ensures that the provenance graph
correctly represents that association.
7.2.2 Online reference monitor. The online reference monitor
checks the current provenance graph in real time against the IFC
policy I. For instance, suppose that the enforcement check policy
Ch is READS. First, when data cross the API boundary for read
requests, we consider that to be the equivalent to an attempt by
a requesting app ar to read object o. Next, we determine AN by
checking for the existence of paths from o to ∀a ∈ A. We check
SwitchSwitchExternalAppsSDN ControllerCoreInternal appmodulesInternal appInternal app…External appExternal appNB APICore methodsSwitchCONTROL PLANE…SB APIData storesForwarding DevicesNorthbound APIDATA PLANE…End hostEnd hostEnd host…APPLICATION PLANESouthbound APIAPPLICATION PLANEEnd HostsPROVSDNCollectorOnline reference monitorIFC policyProvenance graphProtected    access1345627CCS ’18, October 15–19, 2018, Toronto, ON, Canada
B. Ujcich et al.
Table 2: ProvSDN Micro-Benchmark Latencies.
Operation
Average time
per operation
Number of
operations
Collect
Write
IFC check
Internal check
155.66 µs
11.15 µs
98.50 µs
44.67 µs
23 067
57 948
544
5 692 315
Percent of
total time
1.38%
0.25%
0.02%
98.34%
(b) IFC enforced on reads.
(a) IFC enforced on writes.
Figure 7: Provenance graphs generated from example CAP
attack described in Section 5. Dashed nodes and edges repre-
sent attempted actions blocked (but recorded) by ProvSDN.
7.4 Attack Evaluation
We evaluated ProvSDN’s IFC capabilities using the attack described
in Section 5.3. We prevent information flow from the triggering
app (trigger) to the reactive forwarding app (fwd) by assigning
different integrity tags to the apps. We set our IFC policy I as T =
{τ1, τ2}, L(trigger) = {τ1}, L(fwd) = {τ1, τ2}, and Re = BLOCK. Since
L(fwd) ⊃ L(trigger), fwd has higher integrity than trigger and is
prevented from reading data generated by trigger. Packets sent from
trigger and read by fwd, represented as PacketContext entities, have
integrity levels I (packet) = {τ1}; ProvSDN computes I (packet) by
checking path connectivity between entities and agents.
Figure 7 shows parts of the provenance graphs generated from
the information flow attempts. If Ch = WRITES, IFC is enforced
during write attempts, resulting in the process shown in Figure 7a.
Similarly, if Ch = READS, IFC is enforced during read attempts,
resulting in the process shown in Figure 7b. In both scenarios,
the desired goal of the attacker (i.e., to insert a corrupted flow
rule) is blocked, albeit at different stages of the processing pipeline
(depending on practitioner preference).
Suppose that the attack described in Section 5.3 had not been
blocked and was allowed to occur. If the log files were verbose
enough, a practitioner analyzing them might eventually be able to
reconstruct the events that occurred. However, ProvSDN’s prove-
nance collection would make the investigation simpler even if IFC
policies were not initially enforced. The practitioner issues a query
to ProvSDN requesting information about the ForwardingObjec-
tive flow rule entity and receives the relevant ancestry (shown in
Figure 7a). The graphical representation lets the practitioner start
at the ForwardingObjective entity and trace back what data were
used in generating the flow rule to see that trigger modified the
original PacketContext entity. To prevent future occurrences, the
practitioner installs the IFC policy described earlier.
7.5 Performance Evaluation
We evaluated ProvSDN’s performance in an emulated environment
running Open vSwitch 2.7.0 [24] software switches, which are