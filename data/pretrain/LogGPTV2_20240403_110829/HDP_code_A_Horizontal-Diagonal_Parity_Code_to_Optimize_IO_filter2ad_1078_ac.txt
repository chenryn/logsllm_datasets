Algorithm1:ReconstructionAlgorithmofHDPCodeStep1:Identifythedoublefailurecolumns:f1andf2(f1<f2).Step2:Startreconstructionprocessandrecoverthelostdataandparityelements.switch0≤f1<f2≤p−2doStep2-A:Computetwostartingpoints(Cp−1−f2+f1,f1andCf2−f1−1,f2)oftherecoverychainsbasedonEquations6to8.Step2-B:Recoverthelostdataelementsinthetworecoverychains.Twocasesstartsynchronously:casestartingpointisCp−1−f2+f1,f1repeat(1)Computethenextlostdataelement(incolomnf2)intherecoverychainbasedonEquation5;(2)Thencomputethenextlostdataelement(incolomnf1)intherecoverychainbasedonEquations6to8.untilattheendpointoftherecoverychain:Cf2,f2.casestartingpointisCf2−f1−1,f2repeat(1)Computethenextlostdataelement(incolomnf1)intherecoverychainbasedonEquation5;(2)Thencomputethenextlostdataelement(incolomnf2)intherecoverychainbasedonEquations6to8.untilattheendpointoftherecoverychain:Cf1,f1.117.780.8732.5731.324.733.498.460.7807142128351K2K4K8K16K32K64K128KRequest Size (Bytes)Percentage(%)TABLE III
50 RANDOM INTEGER NUMBERS
DIFFERENT L VALUE IN HORIZONTAL CODES
TABLE IV
221
32
18
706
822
811
800
76
297
301
706
969
136
50
430
753
346
303
824
558
34
889
175
324
954
862
335
71
212
100
353
361
427
404
884
428
209
143
199
410
99
609
870
11
604
502
11
855
56
253
Code
RDP
EVENODD
HDP
Uniform SW requests
2p − 4 + 1
p−1
2p − 2
Uniform CW requests
3p
2 − 5
2 + 1
2p − 3
2p−2
1
1
at the end of a stripe, the data element at the beginning of the
stripe will be written5.
Based on the description of ideal sequence, for HDP Code
shown in Figure 5 (which has (p − 3) ∗ (p − 1) total data
elements in a stripe), the ideal sequence of CW requests to
(p−3)∗(p−1) data elements is: C0,1C0,2, C0,2C0,3, C0,3C0,4,
and so on, ······ , the last partial stripe write in this sequence
is Cp−2,p−3C0,0.
We also select two access patterns combined with different
types of read/write requests:
• Uniform access. Each request occurs only once, so
for read requests, each data element is read once; for
write reqeusts, each data element is written once; for
continuous write requests, each data element is written
twice.
• Random access. Since the number of total data elements
in a stripe is less than 49 when p = 5 and p = 7,
we use 50 random numbers (ranging from 1 to 1000)
generated by a random integer generator [29] as the
frequencies of partial stripe writes in the sequence one
after another. These 50 random numbers are shown in
Table III. For example, in HDP Code, the ﬁrst number in
the table,“221” is used as the frequency of a CW request
to elements C0,1C0,2.
For uniform access in HDP Code, Omax is equal to Omin.
According to Equation 11,
L =
Omax
Omin
= 1
(12)
B. Numerical Results
In this subsection, we give the numerical results of HDP
Code compared to other typical codes using above metrics.
First, we calculate the metric of load balancing (L values)
for different codes6 with various p shown in Figure 9 and
Figure 10. The results show that HDP Code has the lowest L
value and thus the best balanced I/O compared to the other
codes.
Second, to discover the trend of unbalanced I/O in hori-
zontal codes, especially for uniform write requests, we also
calculate the L value in RDP, EVENODD and HDP.
For HDP Code, which is well balanced as calculated in
Equation 12 for any uniform request. For RDP and EVEN-
ODD codes, based on their layout, the maximum number of
I/O operations appears in their diagonal parity disk and the
minimum number of I/O operations appears in their data disk.
By this method, we can get different L according to various
values of p. For example, for uniform SW requests in RDP
code,
We deﬁne Oj(Ci,j) as the number of I/O operations in
column j, which is caused by a request to data element(s)
with beginning element Ci,j. And we use O(j) to delegate
the total number of I/O operations of requests to column j in
a stripe, which can be calculated by,
(cid:88)
O(j) =
Oj(Ci,j)
(9)
We use Omax and Omin to delegate maximum/minimum
number of I/O operations among all columns, obviously,
Omax = max O(j), Omin = min O(j)
(10)
We evaluate HDP Code and other codes in terms of the
following metrics. We deﬁne “metric of load balancing (L)”
to evaluate the ratio between the columns with the highest I/O
Omax and the lowest I/O Omin. The smaller value of L is,
the better load balancing is. L can be calculated by,
L =
Omax
Omin
(11)
5For continuous write mode.
L =
Omax
Omin
=
2(p − 1)2 + 2(p − 2)2
2(p − 1)
= 2p−4+
(13)
1
p − 1
We summarize the results in Table IV and give the trend
of L in horizontal codes with different p values in Figure
11 and 12. With the increasing number of disks (p becomes
larger), RDP and EVENODD suffer extremely unbalanced I/O
while HDP code gets well balanced I/O in the write-intensive
environment.
V. RELIABILITY ANALYSIS
By using special horizontal-diagonal and anti-diagonal par-
ities, HDP Code also provides high reliability in terms of fast
recovery on single disk and parallel recovery on double disks.
A. Fast Recovery on Single Disk
As discussed in Section II-B, some MDS codes like RDP
can be optimized to reduce the recovery time when single
disk fails. This approach also can be used for HDP Code to
get higher reliability. For example, as shown in Figure 13,
6In the following ﬁgures, because there is no I/O in parity disks, the
minimum I/O Omin = 0 thus L = ∞.
Fig. 9. Metric of load balancing L under various codes (p = 5).
Fig. 10. Metric of load balancing L under various codes (p = 7).
Fig. 11. Metric of load balancing L under uniform SW requests with different
p in various horizontal codes.
Fig. 12. Metric of load balancing L under uniform CW requests with different
p in various horizontal codes.
when column 0 fails, not all elements need to be read for
recovery. Because there are some elements like C0,4 can be
shared to recover two failed elements in different parities. By
this approach, when p = 7, HDP Code reduces up to 37%
read operations and 26% total I/O per stripe to recover single
disk, which can decrease the recovery time thus increase the
reliability of the disk array.
We summarize the reduced read I/O and total I/O in different
codes in Table V. We can see that HDP achieves highest gain
on reduced I/O compard to RDP and X-Code. Based on the
layout of HDP Code, we also keep well balanced read I/O
when one disk fails. For example, as shown in Figure 14, the
remaining disks all 4 read operations, which is well balanced.
B. Parallel Recovery on Double Disks
According to Figures 6 and 7, HDP Code can be recovered
by two recovery chains all the time. It means that HDP Code
can be reconstructed in parallel when any two disks fail, which
111112.81.21.21.31.2∞875.35.6∞9.85.86.54.9∞6.35.14.22.6∞9.69.16.47.30246810Uniform-RUniform-SWUniform-CWUniform-50R50SWUniform-50R50CWRandom-RRandom-SWRandom-CWRandom-50R50SWRandom-50R50CWLHDP CodeEVENODDRDP111111.81.81.21.71.2∞121188.8∞22.119.114.815.1∞10.28.16.86.5∞13.69.99.17.81.52.32.31.822.62.92.52.22.20510152025Uniform-RUniform-SWUniform-CWUniform-50R50SWUniform-50R50CWRandom-RRandom-SWRandom-CWRandom-50R50SWRandom-50R50CWLHDP CodeEVENODDRDPP-Code08162432405711131719LRDPEVENODDHDPP08162432405711131719LRDPEVENODDHDPPREDUCED I/O OF SINGLE DISK FAILURE IN DIFFERENT CODES
TABLE V
Code
Optimized RDP (p = 5)
Optimized X-Code (p = 5)
Optimized HDP (p = 5)
Optimized RDP (p = 7)
Optimized X-Code (p = 7)
Optimized HDP (p = 7)
Reduced Read I/O
25%
13%
33%
25%
19%
37%
Reduced Total I/O
16.7%
12%
20%
19%
14%
26%
RECOVERY TIME OF ANY TWO DISK FAILURES IN HDP CODE (p = 5)
TABLE VI
failed columns
0, 1
6Rt
0, 2
6Rt
0, 3
4Rt
1, 2
4Rt
1, 3
6Rt
2, 3
6Rt
total recovered
elements
8*6=48
It means that HDP can recover 50% or 43% more elements
during the same time interval. It also shows that our HDP
Code reduces 33% or 31% total recovery time compared to
most RAID-6 codes with single recovery chain as RDP [8],
Cyclic [6] and P-Code [23].
VI. RELATED WORK
A. MDS Codes in RAID 6
Reliability has been a critical issue for storage systems
since data are extremely important for today’s information
business. Among many solutions to provide storage reliability,
RAID-6 is known to be able to tolerate concurrent failures
of any two disks. Researchers have presented many RAID-6
implementations based on various erasure coding technologies,
including Reed-Solomon code [30], Cauchy Reed-Solomon
code [5], EVENODD code [3], RDP code [8], Blaum-Roth
code [4], Liberation code [28], Liber8tion code [27], Cyclic
code [6], B-Code [41], X-Code [42], and P-Code [23]. These
codes are Maximum Distance Separable (MDS) codes, which
offer protection against disk failures with given amount of
redundancy [6]. RSL-Code [10], RL-Code [11] and STAR
[21] are MDS codes tolerating concurrent failures of three
disks. In addition to MDS codes, some non-MDS codes, such
as WEAVER [16], HoVer [17], MEL code [39], Pyramid
code [20], Flat XOR-Code [13] and Code-M [36], also offer
resistance to concurrent failures of any two disks, but they
have higher storage overhead. And there are some approaches
to improve the efﬁciency of different codes [35][38][40][24].
In this paper, we focus on MDS codes in RAID-6, which can
be further divided into two categories: horizontal codes and
vertical codes.
1) Horizontal MDS Codes: Reed-Solomon code [30] is
based on addition and multiply operations over certain ﬁnite
ﬁelds GF (2µ). The addition in Reed-Solomon code can be
implemented by XOR operation, but the multiply is much
more complex. Due to high computational complexity, Reed-
Solomon code is not very practical. Cauchy Reed-Solomon
code [5] addresses this problem and improves Reed-Solomon
code by changing the multiply operations over GF (2µ) into
additional XOR operations.
Fig. 13.
Single disk recovery in HDP Code when column 0 fails (the
corresponding data or parity elements to recover the failed elements are signed
with the same character, e.g., element C0,4 signed with “AD” is used to
recover the elements A and D).
Fig. 14. Single disk recovery in HDP Code when column 0 fails (each remain
column has 4 read operations to keep load balancing well. Data elements A,
C and F are recovered by their horizontal-diagonal parity while B, D and E
are recovered by their anti-diagonal parity).
can reduce the recovery time of double disks failure thus
improve the reliability of the disk array. To efﬁciently evaluate
the effect of parallel recovery, we assume that Rt is the average
time to recover a data/parity element, then we can get the
parallel recovery time of any two disks as shown in Table VI
when p = 5. Suppose Rp delegates the average number of
elements can be recovered in a time interval Rt, the larger
of Rp value is, the better parallel recovery on double disks
and the lower recovery time will be. And we can calculate Rp
value by the results shown in Table VI,
Rp =
48
6 + 6 + 4 + 4 + 6 + 6