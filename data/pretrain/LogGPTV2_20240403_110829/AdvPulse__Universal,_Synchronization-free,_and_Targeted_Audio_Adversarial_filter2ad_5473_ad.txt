performance is studied in Section 5.3. The total number of available
audio samples per class for speaker recognition model and speech
command recognition model are 47 and 100, respectively. For each
class, we split the data into training and testing sets with a ratio of
4 to 1. We used a segment of bird singing, as shown in Figure 14, as
the environmental sound template because this resembles phone’s
notification sound (e.g., Twitter’s notification sound), and therefore
can be used to help to launch the attack in various environments
without alerting the victim.
Attack Test Datasets. Our two target models and their data
settings are presented in Section 3.3, and each model has ten classes.
For each model, we ran our attack to craft a specific adversarial
perturbation for each actual-target label pair, resulting in a total
number of 90 subsecond adversarial perturbations. To verify the
synchronization-free property of the generated adversarial per-
turbation, we varied the delay τ from 0 seconds to the maximum
possible value for each audio input (i.e., the difference between the
duration of the original speech and the adversarial perturbation)
with a step of 0.001 seconds and generated adversarial examples by
mixing each test utterance and the delayed perturbation. In total,
we generated a very large attack test dataset containing 1,125,000
and 900,000 adversarial examples (i.e., speech inputs mixed with de-
layed perturbations) for speaker recognition and speech command
recognition modules, respectively.
Evaluation Metrics. (1) Attack Success Rate: This represents
the number of succeeded attacks over the total number of attack
attempts. Since this is a targeted attack, we only reported a success
if the predicted class matches the desired target class. (2) Confusion
Matrix: Each row represents the actual class uttered by the speaker
and each column shows the target class it is classified as by the
system. Each cell in the matrix corresponds to the fraction of class
in the row that is classified as the class in the column. (3) Signal-to-
noise Ratio (SNR): The generated adversarial perturbation and the
original environmental sound template are compared using SNR:
SN R = 10loд10( Px
), where Px and Pp are the average power of the
Pp
signal and the perturbation, respectively. Larger SNR values indicate
that the adversarial perturbation is closer to the environmental
sound template and therefore harder to be noticed.
5.2 Attack Performance
Speaker Recognition Model. Figure 4 illustrates the detailed
class-wise evaluation result on the speaker recognition model.
Specifically, each cell shows the average attack success rate of
applying the adversarial perturbation on all testing audio samples
with varying delays. As we can see, AdvPulse can achieve a high
attack success rate on the speaker recognition model: only 6 out of
90 combinations have average attack success rates under 90%, with
the lowest attack success rate being 83.2%, and the overall average
attack success rate is 96.9%. The average SNR of all adversarial
perturbations is 8.3 dB.
Speech Command Recognition Model. Figure 5 shows the
class-wise result of the attack on the speech command recognition
model. Only 4 out of 90 combinations have attack success rates
spk 0spk 1spk 2spk 3spk 4spk 5spk 6spk 7spk 8spk 9Target Speakerspk 0spk 1spk 2spk 3spk 4spk 5spk 6spk 7spk 8spk 9Actual Speaker093.198.894.410092.210010092.999.886.4099.596.499.499.195.791.497.88810084.2010010010010099.398.296.79996.293.9097.510010096.910098.298.998.397.899.8099.799.783.296.997.998.298.896.999.697.1093.483.610010098.292.897.710093.5100096.610099.994.795.797.196.296.197.399.6095.895.496.993.599.41009510093.483.8010098.899.997.610099.910010095.799.90020406080100yesnoupdownleftrightonoffstopgoTarget Speech CommandyesnoupdownleftrightonoffstopgoActual Speech Command099.898.298.999.298.289.596.694.894.297.2010099.899.210094.695.197.899.295.795.3096.597.598.898.696.596.696.193.395.895.3090.397.897.591.69698.296.599.810099.8010099.598.198.999.797.110098.898100091.889.59298.496.99899.499.697.210009386.199.993.392.898.696.997.19997.5093.494.899.799.799.410099.810099.297.5098.693.299.791.696.793.398.294.189.393.20020406080100Figure 6: Attack success rate with different perturbation du-
ration.
below 90%, with the lowest being 86.1%, which occurs when at-
tempting to make all “stop” commands be mis-recognized as “on”.
The overall average attack success rate is 96.8%, and the average
SNR of all adversarial perturbations from all actual-target class
pairs is 13.7 dB.
These results show that our generated adversarial perturbation
has good generality over unseen data and do not require synchro-
nization, making it possible to attack streaming audio inputs (e.g.,
live human speech). Additionally, the calculated SNR shows that
the generated adversarial perturbation is very much close to our
situational environmental sound template, potentially concealing
the perturbation in the environment from being noticed.
5.3 Impact of Perturbation Duration
The choice of the adversarial perturbation duration is crucial. Short
durations make the attack more flexible and also less noticeable but
decrease performance, while long durations guarantee high attack
success rate but also place a stricter timing requirement. To study
this trade-off impact, we evaluated the attack with different dura-
tions of the adversarial perturbation (0.1 to 0.6 seconds with a step
of 0.02 seconds) for both speaker and speech command recognition
models. For each specific duration, we selected 20 test samples from
the same original class and applied iterative gradient descent to
generate adversarial perturbation by solving Equation 5. We then
added the perturbations with varying delays to the test samples.
Figure 6 shows the average success rate with various perturbation
durations. We can see that despite some random errors caused by
SGD, a clear trend can be observed where the attack success rate
increases drastically with the increase of the perturbation duration
and achieves high performance (over 90%) if the duration is greater
than 0.2 seconds. However, we conservatively chose to use 0.5
seconds as the default perturbation duration to guarantee a better
performance in practical over-the-air scenarios.
6 EVALUATION OF PHYSICAL
OVER-THE-AIR ATTACK
6.1 Experimental Methodology
Adversarial Perturbation Generation. We used the same attack
configuration as our digital attack presented in Section 5.1. Un-
like the digital attack that relies on Equation 5, to improve the
robustness of adversarial perturbations for over-the-air attack, we
generated subsecond (0.5 seconds) adversarial perturbations accord-
ing to Equation 8. The average SNRs of adversarial perturbations
generated for speaker and speech command recognition models are
Figure 7: Illustration of of-
fice and apartment setups.
Figure 8: Illustration of the
inside-vehicle setup.
4.7 dB and 6.0 dB, respectively. It is worth noting that the adver-
sarial perturbations were trained on several generic RIR datasets
(i.e., the REVERB challenge database [29], the RWCP sound scene
database [34], the Aachen impulse response database [26]) and a
generic noise dataset (i.e., isotropic noise samples from the RWCP
sound scene database [34]) instead of a well-suited one for each
particular scenario. However, it’s possible to utilize a customized
RIR/noise dataset to further improve the attack performance under
certain scenarios (e.g., using engine noise dataset to improve the
performance in inside-vehicle scenarios).
Setup: Office and Apartment Scenarios. Figure 7 illustrates
the environmental setup in two in-door scenarios: an office and a
bedroom of an apartment. The office size is approximately 7.5 m ×
3.7 m and the main noise sources are the fans of multiple desktop
computers and AC. The apartment is about 4.3 m × 3.6 m and the
main ambient noises are distant speeches from neighbors and bird
singing outside of the window. The ambient noises of the office
and the bed room were 41.0 dBSPL and 38.8 dBSPL, respectively,
both of which were measured using a noise meter (i.e., RISEPRO
decibel meter). The office scenario (Figure 7(a)) has two setups: In
setup 1, the victim and the adversarial loudspeaker are located at
two adjacent desks on the same side of the office, where the target
intelligent audio system is placed at the center of the office. The
distances between the victim and the adversarial loudspeaker to the
intelligent audio system are 2.6 m and 2.7 m, respectively. Setup 2
depicts a scenario where the victim and the adversarial loudspeaker
are located at two different sides of the room, and their distances
to the intelligent audio system are 3.0 m and 2.6 m, respectively. In
the apartment setup (Figure 7(b)), the intelligent audio system is
placed on the shelf by the window, and the victim sits in a chair
near the intelligent audio system while the adversarial loudspeaker
is placed at the desk. The distances from the victim and the adver-
sarial loudspeaker to the system are 1.6 m and 2.7 m, respectively.
We used a TKGOU omnidirectional conference microphone as the
receiving device of the intelligent audio system. For better con-
trol and repeatability, the victim (participant) was asked to hold
a loudspeaker (i.e., Edifier R980T) for playing streaming speech
(i.e., victim speaker’s utterances or speech commands in our test
dataset) and the adversarial loudspeaker (i.e., Edifier R980T) was
used to play the generated adversarial perturbations with varying
delays, attempting to attack the system. The utterances played by
the loudspeaker held by the victim are not involved in the training
and played in a streaming manner, which is sufficient to evaluate
our attack in the streaming-speech scenario. We further demon-
strated the feasibility of attacking live human speech on intelligent
audio systems in Section 6.3.
0.10.20.30.40.50.6Duration (s)5060708090100Attack Success Rate (%)Speaker RecognitionSpeech Command RecognitionVictim of setup iIntelligent audio systemAdversarial loudspeaker of setup iii(a) Office3.7 m7.5 m(b) Apartment113.6 m4.3 m1212Phone for RecordingLaptop to Control Perturbation PlaybackSpeaker forPlaying SpeechTo Car Aux InputTo SpeakerCar Speaker forPlaying PerturbationTable 1: Attack success rates in indoor scenarios under dif-
ferent setups.
Table 2: Attack success rates in inside-vehicle scenario under
different statuses.
Setup
Office
(Setup 1)
Office
(Setup 2)
Apartment
Speaker
Recognition
82.7% (186/225)
Speech Command
Recognition
91.1% (205/225)
92.4% (208/225)
92.9% (209/225)
92.0% (207/225)
86.7% (195/225)
Ambient Noise Level
41.0 dBSPL
38.8 dBSPL
State
Engine Off
Engine On
(Idling)
Engine On
(Cruising)
Speaker
Recognition
96% (48/50)
96% (48/50)
74% (37/50)
Speech Command
Recognition
100% (50/50)
98% (49/50)
78% (39/50)
Ambient Noise Level
35.9 (34.0 − 37.5) dBSPL
42.8 (41.9 − 44.2) dBSPL
64.7 (62.8 − 67.0) dBSPL
Setup: Inside-vehicle Scenario. Figure 8 shows the setup for
inside-vehicle scenario in a 2013 Honda Civic Sedan. The perturba-
tion was played through car speakers and the speech was played
through a loudspeaker (i.e., Bose SoundLink Mini II) held at the
driver’s speaking position using a Y-adapter. We used a smartphone
(i.e., iPhone XS Max) as the receiving device of the intelligent audio
system, and measured the ambient noise leveling using a noise
meter (i.e., RISEPRO decibel meter). We evaluated our attack under
three states: (1) Engine Off : the car was parked with the electric
power on and the engine turned off, with an average ambient noise
level of 35.9 dBSPL (ranging from 34.0 to 37.5 dBSPL); (2) Engine
On (Idling): the car was parked with the engine turned on, with
an average ambient noise level of 42.8 dBSPL (ranging from 41.9
to 44.2 dBSPL); and (3) Engine On (Cruising): the car was cursing
with an average speed around 30 − 40 mph, and the main sources
of noise are engine noise, wind noise, and road noise. The average
ambient noise level was 64.7 dBSPL, with the maximum noise level
reaching 67.0 dBSPL.
Evaluation Metrics. (1) Attack Success Rate: The same metric as
described in Section 5.1. (2) Baseline Accuracy: The system accuracy
of the Android implementation of the speech command recognition
model used in Section 6.3 to evaluate live human attack. It is the
ratio of correctly recognized speech commands over total number
of speech commands the user spoke.
6.2 Attack Performance
Indoor Scenarios. Table 1 shows the results of the indoor scenario.
For each model, we evaluated our attack in each setup by randomly
choosing 5 pairs of actual-target classes. For each pair, we ran-
domly selected 3 test audio samples from the actual class. During
the playback of each test audio sample, we played the generated
perturbation 15 times with uncontrolled varying delays. This gave
us a total number of 225 recordings for each model in each setup.
The perturbations were played at a similar volume of a regular
phone notification sound (50 − 55 dBSPL), which is much quieter
comparing to speech (∼ 60 dBSPL). As we can see from Table 1, our
attack can retain a high attack success rate in all the representative
indoor setups, with an average attack success rate of 89.3% against
speaker recognition systems and 89.9% against speech command
recognition systems.
Inside-vehicle Scenario. Table 2 presents the experiment re-
sults of the inside-vehicle scenario. In each vehicle state, we ran-
domly selected 5 pairs of the actual-target classes for each model.
For each pair, we randomly selected 1 test audio sample from the
actual class and played the generated perturbation 10 times with un-
controlled varying delays, resulting in a total number of 50 record-
ings for each model in each status. The perturbations were played
through built-in speakers at the same level of loudness of a regular
Table 3: Attack success rates with different level of adversar-
ial perturbation loudness.
Adversarial Perturbation
45
50
Loudness (dBSPL)
Attack Success Rate
64% (32/50)
94% (47/50)
100% (50/50)
100% (50/50)
55
60
car radio (55 − 60 dBSPL), which is quieter than road noises (∼ 65
dBSPL). As shown in Table 2, our attack can achieve a high attack
success rate when the engine is turned off or idling (only failed 4
times against speaker recognition model and 1 time against speech
command recognition model out of 100 trials). This shows that
our attack is resilient to severe reverberation during playing the
adversarial example in the narrow cabin. Even when the vehicle is
cruising with a loud wind/road noise, our attack can still achieve a
relatively high success rate (over 74% against both systems).
6.3 Attacking Live Human Speech
Due to the strict dependency on speaker identity and the lack of
training data on the speaker recognition model, we only validated
our attack against live human speech on the speech command recog-
nition system. Specifically, we implemented an Android app of our
target speech recognition model based on Tensorflow Lite and in-
stalled it on a smartphone (i.e., Google Pixel). As shown in Figure 9,
we evaluated the live human attack in two scenarios: (1) Laptop:
The victim speaks into the smartphone while the adversarial pertur-
bation is played from a nearby laptop. This represents the scenario
where the adversary remotely launches the attack by broadcast-
ing adversarial perturbations through online media (e.g., Youtube
Channel). (2) Loudspeaker: The victim speaks into the smartphone
while the adversarial perturbation is played from a loudspeaker at
a distance of 1 m. This is possible when the adversary launches the
attack through an adversary-controlled loudspeaker (e.g., built-in