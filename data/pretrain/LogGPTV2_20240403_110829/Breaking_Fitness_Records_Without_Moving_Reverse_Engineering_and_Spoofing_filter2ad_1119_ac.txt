were able to communicate with MCU as shown in Fig. 11. We extracted the entire
ﬁrmware image since memory readout protection was not activated. There are
three levels of memory protection in the STM32L micro-controller: (i) level 0:
no readout protection, (ii) level 1: memory readout protection, the Flash memory
cannot be read from or written to, and (iii) level 2: chip readout protection, debug
features and boot in RAM selection are disabled (JTAG fuse). We discovered that
in the Fitbit Flex and the Fitbit One, memory protection was set to level 0, which
means there is no memory readout protection. This enabled us to extract the
contents of the diﬀerent memory banks (e.g., FLASH, SRAM, ROM, EEPROM)
for further analysis.
Note that it is also possible to extract the complete ﬁrmware via the MITM
setup during an upgrade process (if the tracker ﬁrmware does not use encryp-
tion). In general, sniﬃng is easier to perform, but does not reveal the memory
layout and temporal storage contents. Moreover, hardware access allows us to
change memory contents at runtime.
Device Key Extraction: We initially sniﬀed communications between the
Fitbit tracker and the Fitbit server to see whether a key exchange protocol is
performed, which was not the case. Therefore, we expected pre-shared keys on
the Fitbit trackers we connected to, including two diﬀerent Fitbit One and three
diﬀerent Fitbit Flex devices. We read out their EEPROM and discovered that
the device encryption key is stored in their EEPROM. Exploring the memory
content, we found the exact memory addresses where the 6-byte serial ID and
16-byte encryption key are stored, as shown in Fig. 13. We conﬁrm that each
device has a device-speciﬁc key which likely is programmed into the device during
manufacturing [12].
64
H. Fereidooni et al.
Disabling the Device Encryption: By analyzing the device memory content,
we discovered that by ﬂipping one byte at a particular address in EEPROM, we
were able to force the tracker to operate in unencrypted mode and disable the
encryption. Even trackers previously communicating in encrypted mode switched
to plaintext after modifying the encryption ﬂag (byte). Figure 13 illustrates how
to ﬂip the byte, such that the tracker sends all sync messages in plaintext format
(Base64 encoded) disabling encryption.
Fig. 13. Device key extraction and disabling encryption.
Injecting Fabricated Data Activities: We investigated the EEPROM and
SRAM content to ﬁnd the exact memory addresses where the total step count
and other data ﬁelds are stored. Based on our packet format knowledge and
previously sniﬀed megadumps, we found that the activity records were stored in
the EEPROM in the same format. Even encrypted frames are generated based
on the EEPROM plaintext records. Therefore, oblivious falsiﬁed data can be
injected, even with the newest ﬁrmware having encryption enabled. As it can
be seen in Fig. 14a and b, we managed to successfully inject 0X00FFFFFF steps
equal to 16 777 215 in decimal into Fitbit server by modifying the corresponding
address ﬁeld in the EEPROM and subsequently synchronising the tracker with
the server.
6 Discussion
In this section we give a set of implementation guidelines for ﬁtness trackers.
While Fitbit is currently the only manufacturer that puts eﬀort into securing
trackers [15], our guidelines also apply to other health-related IoT devices. We
intend to transfer the lessons learned into open security and privacy standards
that are being developed.4
4 See https://www.thedigitalstandard.org.
Breaking Fitness Records Without Moving
65
Fig. 14. The results of injecting fabricated data. (a) shows the Fitbit app screenshot,
and (b) demonstrates the Fitbit web interface.
False data injection as described in the previous sections is made possible
by a combination of some of the design choices in the implementation of the
Fitbit trackers and in the communication protocol utilized between the track-
ers and Fitbit application servers. These design choices relate to how encryption
techniques have been applied, the design of the protocol messages, and the imple-
mentation of the hardware itself. To overcome such weaknesses in future system
designs, we propose the following mitigation techniques.
Application of encryption techniques: The examined trackers support full
end-to-end encryption, but do not enforce its use consistently.5 This allows us to
perform an in-depth analysis of the data synchronization protocol and ultimately
fabricate messages with false activity data, which were accepted as genuine by
the Fitbit servers.
Suggestion 1. End-to-end encryption between trackers and remote servers
should be consistently enforced, if supported by device ﬁrmware.
Protocol message design: Generating valid protocol messages (without a clear
understanding of the CRC in use) is enabled by the fact that the server responds
to invalid messages with information about the expected CRC values, instead of
a simple “invalid CRC”, or a more general “invalid message” response.
Suggestion 2. Error and status notiﬁcations should not include additional
information related to the contents of actual protocol messages.
5 During discussions we had with Fitbit, the company stressed that models launched
after 2015 consistently enforce encryption in the communications between the tracker
and server.
66
H. Fereidooni et al.
CRCs do not protect against message forgery, once the scheme is known. For
authentication, there is already a scheme in place to generate subkeys from the
device key [12]. Such a key could also be used for message protection.
Suggestion 3. Messages should be signed with an individual signature subkey
which is derived from the device key.
Hardware implementation: The microcontroller hardware used by both ana-
lyzed trackers provides memory readout protection mechanisms, but were not
enabled in the analyzed devices. This opens an attack vector for gaining access
to tracker memory and allows us to circumvent even the relatively robust pro-
tection provided by end-to-end message encryption as we were able to modify
activity data directly in the tracker memory. Since reproducing such hardware
attacks given the necessary background information is not particularly expen-
sive, the available hardware-supported memory protection measures should be
applied by default.
Suggestion 4. Hardware-supported memory readout protection should be
applied.
Speciﬁcally, on the MCUs of the investigated tracking devices, the memory of
the hardware should be protected by enabling chip readout protection level 2.
Fraud detection measures: In our experiments we were able to inject fabri-
cated activity data with clearly unreasonably high performance values (e.g. more
than 16 million steps during a single day). This suggests that data should be
monitored more closely by the servers before accepting activity updates.
Suggestion 5. Fraud detection measures should be applied in order to screen
for data resulting from malicious modiﬁcations or malfunctioning hardware.
For example, accounts with unusual or abnormal activity proﬁles should be
ﬂagged and potentially disqualiﬁed, if obvious irregularities are detected.
7 Related Work
Researchers at the University of Toronto [18] have investigated transmission
security, data integrity, and Bluetooth privacy of eight ﬁtness trackers including
Fitbit Charge HR. They focused on transmission security, speciﬁcally at whether
or not personal data is encrypted when transmitted over the Internet in order
to protect conﬁdentiality. They also examined data integrity concentrating on
whether or not ﬁtness data can be considered authentic records of activity that
have not been tampered with. They did not attempt to reverse engineer the
proprietary encoding or encryption used for transmitting data.
In 2013, Rahman et al. [9] studied the communication between Fitbit Ultra
and its base station as well as the associated web servers. According to Rahman
et al., Fitbit users could readily upload sensor data from their Fitbit device onto
Breaking Fitness Records Without Moving
67
the web server, which could then be viewed by others online. They observed two
critical vulnerabilities in the communication between the Fitbit device’s base
station, and the web server. They claimed that these vulnerabilities could be
used to violate the security and privacy of the user. Speciﬁcally, the identiﬁed
vulnerabilities consisted of the use of plaintext login information and plaintext
HTTP data processing. Rahman et al. then proposed FitLock as a solution to
the identiﬁed vulnerabilities. These vulnerabilities have been patched by Fitbit
and no longer exist on contemporary Fitbit devices. Zhou et al. [20] followed
up on Rahman’s work by identifying shortcomings in their proposed approach
named FitLock, but did not mention countermeasures to mitigate the vulnerabil-
ities that they found. In 2014, Rahman et al. published another paper detailing
weaknesses in Fitbit’s communication protocol, enabling them to inject falsiﬁed
data to both the remote web server and the ﬁtness tracker. The authors pro-
posed SensCrypt, a protocol for securing and managing low power ﬁtness track-
ers [21]. Note that Fitbit’s communication paradigm has changed considerably
since Fitbit Ultra, which uses ANT instead of Bluetooth, and is not supported
by smartphone applications, but only by a Windows program last updated in
2013. Neither the ANT-based ﬁrewalls FitLock nor SensCrypt would work on
recent Fitbit devices. Transferring their concept to a Bluetooth-based ﬁrewall
would not help against the attacks demonstrated in this paper, since hardware
attacks are one level below such ﬁrewalls, while our protocol attacks directly
target the Fitbit servers.
Cyr et al. [10] analyzed the Fitbit Flex ecosystem. They attempted to do a
hardware analysis of the Fitbit device but because of the diﬃculties associated
with debugging the device they decided to focus on other parts such as Bluetooth
LE, the associated Android app and network analysis. The authors explained the
data collected by Fitbit from its users, the data Fitbit provided to Fitbit users,
and methods of recovering data not made available to device owners.
In the report released by AV TEST [19], the authors tested nine ﬁtness
trackers including Fitbit Charge and evaluated their security and privacy. The
authors tried to ﬁnd out how easy it is to get the ﬁtness data from the ﬁtness
band through Bluetooth or by sniﬃng the connection to the cloud during the
synchronization process.
AV TEST reported some security issues in Fitbit Charge [11]. They dis-
covered that Fitbit Charge with ﬁrmware version 106 and lower allows non-
authenticated smartphones to be treated as authenticated if an authenticated
smartphone is in range or has been in range recently. Also, the ﬁrmware version
allowed attackers to replay the tracker synchronization process. Both issues have
been now ﬁxed by Fitbit.
In [12], the authors captured the ﬁrmware image of the Fitbit Charge HR
during a ﬁrmware update. They reversed engineer the cryptographic primitives
used by the Fitbit Charge HR activity tracker and recovered the authentica-
tion protocol. Moreover, they obtained the cryptographic key that is used in
the authentication protocol from the Fitbit Android application. The authors
found a backdoor in previous ﬁrmware versions and exploiting this backdoor they
68
H. Fereidooni et al.
extracted the device speciﬁc encryption key from the memory of the tracker using
Bluetooth interface. Memory readout has been ﬁxed in recent ﬁrmware versions.
Principled understanding of the Fitbit protocol remains open to investigation
as the open-source community continues to reverse-engineer message semantics
and server responses [16].
8 Conclusion
Trusting the authenticity and integrity of the data that ﬁtness trackers generate
is paramount, as the records they collect are being increasingly utilized as evi-
dence in critical scenarios such as court trials and the adjustment of healthcare
insurance premiums. In this paper, we conducted an in-depth security analysis of
two models of popular activity trackers commercialized by Fitbit, the market
leader, and we revealed serious security and privacy vulnerabilities present in
these devices. Additionally, we reverse engineered the primitives governing the
communication between these devices and cloud-based services, implemented an
open-source tool to extract sensitive personal information in human-readable for-
mat and demonstrated that malicious users could inject spoofed activity records
to obtain personal beneﬁts. To circumvent the end-to-end protocol encryption
mechanism present on the latest ﬁrmware, we performed hardware-based RE and
documented successful injection of falsiﬁed data that appears legitimate to the
Fitbit cloud. We believe more rigorous security controls should be enforced by
manufacturers to verify the authenticity of ﬁtness data. To this end, we provided
a set of guidelines to be followed to address the vulnerabilities identiﬁed.
Acknowledgments. Hossein Fereidooni is supported by the Deutsche Akademische
Austauschdienst (DAAD). Mauro Conti is supported by the EU TagItSmart! Project
(agreement H2020-ICT30-2015-688061) and IT-CNR/Taiwan-MOST 2016-17 “Veriﬁ-
able Data Structure Streaming”. This work has been co-funded by the DFG as part of
projects S1 and S2 within the CRC 1119 CROSSING, and by the BMBF within CRISP.
Paul Patras has been partially supported by the Scottish Informatics and Computer
Science Alliance (SICSA) through a PECE grant.
We thank the Fitbit Security Team for their professional collaboration with us, and
their availability to discuss our ﬁndings and address the vulnerabilities we identiﬁed.
References
1. Forbes. Wearable
2016.
tech market
2020,
https://www.forbes.com/sites/paullamkin/2016/02/17/
be worth
billion
$34
by
to
February
wearable-tech-market-to-be-worth-34-billion-by-2020
2. International Data Corporation. Worldwide quarterly wearable device tracker,
March 2017. https://www.idc.com/tracker/showproductinfo.jsp?prod_id=962
3. Mashable. Husband learns wife is pregnant from her Fitbit data, February 2016.
http://mashable.com/2016/02/10/ﬁtbit-pregnant/
4. The Wall Street Journal. Prosecutors
in
bing
prosecutors-say-ﬁtbit-device-exposed-ﬁbbing-in-rape-case/
case, April
2016.
rape
say Fitbit device
exposed ﬁb-
http://blogs.wsj.com/law/2016/04/21/
Breaking Fitness Records Without Moving
69
5. The Guardian. Court sets legal precedent with evidence from Fitbit health
tracker, November 2014. https://www.theguardian.com/technology/2014/nov/18/
court-accepts-data-ﬁtbit-health-tracker
6. VitalityHealth. https://www.vitality.co.uk/rewards/partners/activity-tracking/
7. AchieveMint. https://www.achievemint.com
8. StepBet. https://www.stepbet.com/
9. Rahman, M., Carbunar, B., Banik, M.: Fit and vulnerable: attacks and defenses for
a health monitoring device. In: Proceedings of the Privacy Enhancing Technologies
Symposium (PETS), Bloomington, IN, USA (2013)
10. Cyr, B., Horn, W., Miao, D., Specter, M.: Security Analysis of Wearable
Fitness Devices (Fitbit) (2014). https://courses.csail.mit.edu/6.857/2014/ﬁles/
17-cyrbritt-webbhorn-specter-dmiao-hacking-ﬁtbit.pdf
11. Clausing, E., Schiefer, M., Morgenstern, M.: AV TEST Analysis of Fitbit Vulner-
abilities (2016). https://www.av-test.org/ﬁleadmin/pdf/avtest_2016-04_ﬁtbit_
vulnerabilities.pdf
12. Schellevis, M., Jacobs, B., Meijer, C.: Security/privacy of wearable ﬁtness tracking
IoT devices. Radboud niversity. Bachelor thesis: Getting access to your own Fitbit
data, August 2016
13. Accenture. Digital trust in the IoT era (2015)
14. PwC 2016: Use of wearables in the workplace is halted by lack of trust. http://
www.pwc.co.uk/who-we-are/regional-sites/northern-ireland/press-releases/
use-of-wearables-in-the-workplace-is-halted-by-lack-of-trust-pwc-research.html
15. Fereidooni, H., Frassetto, T., Miettinen, M., Sadeghi, A.-R., Conti, M.: Fitness
Trackers: Fit for health but unﬁt for security and privacy. In: Proceedings of
the IEEE International Workshop on Safe, Energy-Aware, & Reliable Connected
Health (CHASE workshop: SEARCH 2017), in press, Philadelphia, Pennsylvania,
USA, July 17–19 (2017)
16. Galileo project. https://bitbucket.org/benallard/galileo/
17. Wireshark network protocol analyzer. https://www.wireshark.org/
18. Hilts, A., Parsons, C., Knockel, J.: Every Step You Fake: A Comparative Analy-
sis of Fitness Tracker Privacy and Security. Open Eﬀect Report (2016). https://
openeﬀect.ca/reports/Every_Step_You_Fake.pdf
19. Clausing, E., Schiefer, M., Morgenstern, M.: Internet of Things: Security Evalua-
tion of nine Fitness Trackers. AV TEST, The Independent IT-Security institute,
Magdeburg, Germany (2015)
20. Zhou, W., Piramuthu, S.: Security/privacy of wearable ﬁtness tracking IoT devices.
In: IEEE Iberian Conference on Information Systems and Technologies (2014)
21. Rahman, M., Carbunar, B., Topkara, U.: Secure management of low power ﬁtness
trackers. Published IEEE Trans. Mob. Comput. 15(2), 447–459 (2016)