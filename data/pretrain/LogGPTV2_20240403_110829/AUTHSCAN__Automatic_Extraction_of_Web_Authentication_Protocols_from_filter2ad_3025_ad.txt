step, AUTHSCAN internally generates new traces and keeps
them in a local trace pool (trP ool in Algorithm 1). These
traces are not fed back to the initial test harness, and are
used only during the blackbox and whitebox steps.
Eliminating Redundant Data. The goal of this step is
to identify HTTP data that do not contribute towards the
authentication protocol. In this step, we check each HTTP
data element by generating a probe message with this ele-
ment removed. If the probe message results in a success-
ful authentication, we remove the element and all of its oc-
currences in previous messages. AUTHSCAN performs this
operation iteratively for each request/response pairs starting
from the last pair and proceeding backwards in t.
Probe-based Inference. The main idea of this fuzzing
step is to mutate or remove the HTTP data in the request
messages of t, while keeping others unchanged. These
modiﬁed “probe” messages are sent to the protocol par-
ticipants and their responses are compared for differences.
In addition, to prevent the explosion of number of HTTP
traces, we capture at most three traces for each test user
account and at most 10 test user accounts for each web
site. AUTHSCAN identiﬁes the semantics of several types
of HTTP data: URLs, HTTP parameters, web addresses,
JSON data, JSON Web tokens, and web cookies. To do
this identiﬁcation, it uses simple pattern matching rules over
the values of the data. For instance, a string which has
sub-strings separated by “&”, with each segment as a key-
value pair separated by a “=”, is treated as an HTTP pa-
rameter list. Similar syntactic properties are used for com-
mon web objects such as JSONs, JWT, cookies and so on.
Once the HTTP data type is inferred, AUTHSCAN makes
use of the type information to speed up the fuzzing pro-
cess. For example, if AUTHSCAN infers that a string is
an HTTP parameter-value list, it mutates each key value
pair in this string separately. Similarly, if AUTHSCAN
infers that a string represents a user identity (like user-
names) or a web address, it mutates the value of this HTTP
data into another user’s ID or another web address, in-
stead of trying random modiﬁcations. AUTHSCAN also in-
corporates simple pattern-matching rules to identify if val-
ues are encoded using common encoding methods such
as URLEncode/URLDecode, Base64-encode, HexEncode,
HTMLEncode and JavaScript string literal encode, based
on the use of special characters. For an HTTP data with
completely unknown semantics, AUTHSCAN uses pattern-
matching techniques to label it as one of primitive types
(Integer, Bool, or String).
Once the basic types are identiﬁed, AUTHSCAN then in-
fers the TML terms and actions. From the traces in the local
trace pool, AUTHSCAN attempts to ﬁrst identify arithmetic
function terms, which in turn enables the modeling of weak
or guessable tokens. For Integer- or String- typed value
of an HTTP data parameter that change across sessions,
AUTHSCAN uses the following mechanism to check if it
is generated using a predictable arithmetic function. Given
such a string value (say str), AUTHSCAN ﬁrst conducts
a substring matching between its instances across various
traces and extracts the parts that are not common between
these instances. AUTHSCAN then checks if these values
form simple arithmetic sequences adding or subtracting a
constant.
If the function is identiﬁed, AUTHSCAN treats
it as a guessable token, and conﬁrms it by predicating its
value and probing the server (discussed in Section 5.3). We
plan to integrate more powerful off-the-shelf tools, such as
Wolfram Alpha, which take such value sequences as inputs
and output a closed form arithmetic expression to match
it [11]. AUTHSCAN also marks any data value which is
too short (L ≤ 4 characters by default and conﬁgurable) as
guessable short-length tokens, as these values may be sub-
ject to exhaustive search. For example, in the case where
L = 4, the search space is less than 2 million ((10 + 26)4),
assuming that the term only consists of case-insensitive
alpha-numeric characters; AUTHSCAN presently does not
actually generate these probes but models such values as
attacker’s knowledge (as detailed in Section 5.2), and gen-
erates security warnings.
Next, AUTHSCAN infers two kinds of associations using
techniques similar to those proposed by Wang et. al. [42].
One kind of association is among HTTP data. AUTHSCAN
replaces the value of an HTTP data x in message ai, while
keeping the rest unchanged. Then it sends this “probe” mes-
sage and compares the response message. If HTTP response
(cid:126)y changes, AUTHSCAN introduces an assoc(x, (cid:126)y). Other
kinds of association relations are between HTTP data and
a web principal or users. Similarly, AUTHSCAN identiﬁes
these associations by using differential analysis on multi-
ple traces. The HTTP data which remain constant among
the same user’s multiple sessions are inferred to be asso-
ciated to the user; those remaining constant among dif-
ferent users’ sessions are inferred to be associated with
a web principal (such as the SP or IDP). All remaining
HTTP data that change in all such probes are inferred to
be nonces (NewNonce), such as session IDs.
Identifying Association Principals. The S in NewAs-
soc(S,...) stands for the principals who share the knowledge
of the association terms. AUTHSCAN identiﬁes these prin-
cipals by observing which terms in an assoc appear in the
responses from the protocol participants. Then, it probes
these participants by replacing the associated terms with
random values. If a principal rejects the fuzzing message,
we infer that it knows how to compute the relationship, and
add a NewAssoc with these participants in S.
Non-Probe Based Inference. The non-probe based in-
ference infers three kinds of function symbols: crypto-
graphic functions, set functions and concatenation func-
tions. AUTHSCAN employs brute-force search to identify
cryptographic functions. It takes every combination of all
HTTP data elements and checks if they can be used as in-
puts to a standard cryptographic primitive to produce an-
other data element. We bound the function nesting depth
of terms to be less than 5. In our experiments, we ﬁnd that
this bound is reasonable since all our analyzed protocols
do not use no more than 4 levels of nesting cryptographic
constructions. This search strategy has been sufﬁcient in
practice for our experiments on real-world protocols. For
example, as discussed in our BrowserID case study (Sec-
tion 6), AUTHSCAN successfully identities that one HTTP
data element is signed by the IDP, and that the signed el-
ements are the ID and the user’s public key. AUTHSCAN
identiﬁes the concatenation functions by using a substring
search over all combinations of HTTP data elements. For
the set construction functions, if a single message contains
multiple data, AUTHSCAN assigns them to a set.
5 Protocol Analysis & Attack Conﬁrmation
After extracting a TML model, AUTHSCAN translates
it
to
into applied pi-calculus, which is taken as input
ProVerif [18] to check security properties against attack
models. Due to space constraints, we leave the details of
this process to Appendix C; and in this section, we discuss
the security properties, attacker models and how candidate
attacks are checked to conﬁrm security ﬂaws.
5.1 Security Properties
By default, AUTHSCAN checks the correctness of
two essential security properties in its applied pi-calculus
version, authentication of an authentication protocol [44]
and secrecy of credential tokens. A protocol achieves
authentication if each principal is sure about the identity
of the principal whom it is communicating with. Authen-
tication is checked using injective correspondence ((cid:32),
or injective agreement) [19, 20, 32, 44], which can check
whether two local protocols are executing in “lock-step”
fashion, i.e., whether there is an injective mapping between
the execution of two participant’s protocols. For instance,
in our running example, whenever ﬁnishing executing
EndRespond(i), SP S believes that SP C has executed the
protocol with him; thus, to guarantee authentication, SP C
must have executed BeginInit(j), i.e., EndRespond(i) (cid:32) Be-
ginInit(j)
(inj-event(EndRespond(i))==>inj-
event(BeginInit(j)) in applied pi-calculus). Au-
thentication is violated if SP S believes SP C has executed
the protocol with him, but actually it is Z who has.
Additionally, an authentication protocol may introduce
some credentials and thus secrecy of them needs to be guar-
anteed. Secrecy is deﬁned as querying a term from the at-
tacker Z’s knowledge set [44]. The secrecy of a term a is
speciﬁed as Z has a (query attacker(a) in applied
pi-calculus), which queries whether a is derivable by Z af-
ter the execution of the authentication protocols. If Z has a
after the protocol, the protocol fails to guarantee the secrecy
of a. By default, AUTHSCAN checks the secrecy of terms
used for authentication (such as the sessionID in the run-
ning example); the attack analyst can add more queries to
check the secrecy of other terms, for example, credentials
for resource access (such as OAuth token in OAuth 2.0). For
long-lived tokens, AUTHSCAN adds them to Z’s knowledge
In general, Z may know a
set before querying ProVerif.
long-lived token’s value (through external knowledge) even
if it is not sent on a public channel; AUTHSCAN conserva-
tively models this scenario and raises a security warning to
alert the analyst. For guessable tokens, AUTHSCAN adds
the outputs of the arithmetic operations to Z’s knowledge
set. In the attack conﬁrmation step, these guessable values
are computed and used as we detail in Section 5.3.
5.2 Attacker Models
In this work, we consider two different attacker models,
namely the network attacker [24] and the web attacker [15].
Previous work (e.g., [17]) has shown that these attackers
can be captured in ProVerif. Hence, we ignore the detailed
modeling and just give an overview in this section. For ex-
ample, attacker model in the running example is demon-
strated in Appendix C. Note that both the attacker models
are checked individually in AUTHSCAN, since ProVerif ter-
minates after ﬁnding a counterexample.
Network Attacker. We model the network attacker us-
ing the Dolev-Yao model [24], that is, an active network
attacker is able to eavesdrop all messages and control the
contents of unencrypted messages in the public network un-
der the constraints of cryptographic primitives. In TML, we
model HTTPS by assuming that the SSL certiﬁcate check-
ing and handshake are complete before the protocol starts;
we model the session key between the two communicating
principals x and y with a key function key(x, y)
(I2 in
Figure 3). In applied pi-calculus, we model HTTPS using
private channels, which are neither readable nor writable by
the attacker (shown in Appendix C). Note that modeling the
HTTP network attacker is available from ProVerif directly.
Web Attacker. We also reuse web attacker models de-
scribed in prior work [15, 17]. These models include mod-
eling the same-origin restrictions; for example, the fact that
client-side SP code cannot intercept IDP server’s messages
is implied in the applied pi-calculus semantics that the lo-
cal variables of a process are inaccessible by another pro-
cess. We model HTTP headers like Referrer which cor-
respond to the client-side code sending its identity in the
messages; of course, if the header is not checked by the
server, it will not be inferred in our speciﬁcation as it is re-
moved as a redundant element. We also model the seman-
tics of postMessage by encrypting all messages trans-
mitted through postMessage with a key (kB in IC4 and
SC4, Figure 3). If AUTHSCAN ﬁnds (by whitebox analysis)
that the receiver or sender origin ﬁelds are not checked,
it casts kB to the attacker such that the attacker is able
to read and write the postMessage channel. The anti-
CSRF tokens are not needed to be explicitly modeled in the
attacker model as they are observed in the HTTP network
messages and are inferred to be nonces if they are relevant
to the protocol (I4 and I5 in Figure 3). We assume that the
attacker has the ability to redirect the user agent to a ma-
licious web site. We do not model web attackers with the
ability to perform Cross-Site Scripting (XSS) attacks and
complex social-engineering attacks in this work.
5.3 Candidate Attack Conﬁrmation
AUTHSCAN conﬁrms candidate attacks generated by
ProVerif in this step. If a protocol fails to satisfy the secu-
rity properties, ProVerif generates a counterexample, which
consists of the attacker’s actions, the attacker’s input/output
and details the terms computed by Z at each step using it’s
knowledge set at that step. AUTHSCAN re-constructs the
candidate attack probe from this information. For all terms
computed at each step, AUTHSCAN substitutes the concrete
values for these terms. For guessable tokens that are com-
puted from arithmetic functions, AUTHSCAN evaluates the
function to calculate the next concrete value. For short-
size guessable tokens, AUTHSCAN only raises a security
warning. To map symbols and variables in ProVerif coun-
terexamples to concrete values observed in the HTTP traces,
AUTHSCAN maintains the mapping between the original
HTTP messages and the protocol statement generated dur-
ing the protocol extraction. Thus, AUTHSCAN maps back
a ProVerif action sequence and terms in the ProVerif coun-
terexample to the ProVerif input, which inturn is mapped
to the raw HTTP message. Once the messages are con-
structed, AUTHSCAN replays the candidate attack probe.
During this process, it queries the oracle provided by the
analyst to check whether the attack is successful.
Currently, AUTHSCAN automates conﬁrmation of at-
tacks over HTTP, over postmessage and via a web
attacker-controlled iframe. In cases which AUTHSCAN
cannot conﬁrm with concrete attack instances, it reports se-
curity warnings containing the communicated data it sus-
pects. Such cases include the use of long-lived token in au-
thentication, secrecy of which is not known in the inferred
protocol but conservatively modeled as discussed in Sec-
tion 5.2, and the use of guessable short-length tokens.
6 Evaluation
We have built an implementation of AUTHSCAN in ap-
proximately 5K lines of C# code, and 3K lines of JavaScript
code. The HTTP trace recording and blackbox fuzzing
functionalities are implemented in a Firefox add-on. The
JavaScript trace extraction is implemented by instrument-
ing the web browser to generate execution traces in a format
similar to JASIL [36]. We developed our own implementa-
tion of dynamic symbolic analysis for extracting the TML
terms from the execution traces.
6.1 Evaluation Subjects
To estimate the effectiveness of AUTHSCAN on real-
world protocols, we test several implementations of popu-
lar SSO protocols and standalone web sites that implement
their custom authentication logic. The inferred protocols
are presented in Appendix B.2. Our results are summarized
in Table 2.
BrowerID. BrowserID [2] is an SSO service proposed by
Mozilla, which is used by several Mozilla-based services
such as BugZilla and MDN, as well as some other service
providers. We test three different SP implementations of
BrowserID. Although BrowserID is open-source, most of
protocols do not provide the detailed implementation on the
server-side. To account for this, we only take into consid-
eration the client-side JavaScript code and HTTP messages
to make our analysis approach more general. AUTHSCAN
manages to infer the general protocol speciﬁcation from
these three implementations, ﬁnding only one crucial differ-
ence across the implementations (explained in Section 6.2).
Facebook Connect. Facebook Connect [3] is one of the