mechanisms,  such  as  signature  or  behavior  based 
intrusion prevention. 
introducing 
to 
4.1. The vulnerability timeline 
Figure 1 shows a timeline of events in the life cycle 
of  a 
is  not 
dissimilar  to  what  was  described  by  Schneier  as  the 
typical  vulnerability.  This 
timeline 
in 
this 
“window  of  exposure”  [16]  and  also  examined  by 
McHugh [10] and Frei, et al [6]. 
Distinctive  points  in  the  timeline  correspond  to 
different  awareness  states  and  potentially  different 
perceptions  of  risk  by  an  organization.  The  four 
important  points 
timeline  are  discovery, 
disclosure,  exploit,  and  patch  availability.  The 
discovery  point  is  when  only  the  individuals  who 
discovered the vulnerability know about it. The risk of 
exploit  after  the  discovery  is  present,  but  we  can 
assume  it  is  minimal  (or  more  targeted)  compared  to 
the  risks  after 
typical 
organization would probably be unaware of a particular 
threat at this stage of the lifecycle. 
the  public  disclosure.  A 
Disclosure T1 
Patch Available T4
Discover
Minus 
days exploit 
zero 
Public exploit code 
T2
Malware T5 
Signature 
Available T3 
Patch 
Deployed T6 
Cannot 
measure 
Only 
some 
groups aware, 
no public data  
Some 
public 
data 
A lot of public data 
Patching 
processes
Window of Exposure 
Figure 1. Vulnerability timeline1. 
threat 
At  the  time  of  disclosure,  it  is  then  that  the 
vulnerability  becomes  widely  known.  Usually,  this 
happens  when  vulnerability  information  is  published 
by  CERT  or  other  security  vendors,  later  resulting  in 
additional  security  advisory  by  the  vendor.  From  this 
point  in  time  the  risk  increases  considerably,  as  the 
vulnerability is analysed by hackers with exploit code 
potentially  appearing  quickly  afterwards.  We  assume 
that  soon  after  this  point,  e.g.  a  day  or  two,  an 
organization would note the vulnerability as part of its 
ongoing 
The 
organization  would  then  conduct  a  preliminary  risk 
assessment to determine if the vulnerability applies to 
its environment.  
programme. 
awareness 
availability  of  other 
The  time  of  patch  availability  is  the  earliest  date 
that  the  vendor  of  the  software  releases  a  patch 
providing  protection  against  the  exploitation  of  the 
vulnerability.  We  assume  that  the  organization  learns 
of the patch either the same day or with a delay that is 
negligible.  The 
security 
mitigations such as signatures for intrusion prevention 
systems or anti-virus tools we take as being a separate 
matter from patch release.  In our time line we assume 
that such mitigations are usually available earlier than 
1
 The sequencing of events in this timeline is not fixed; the aim is to 
illustrate the various stages in the vulnerability life cycle.    
the 
across 
patch.  That  being  said,  we  also  recognize  that  these 
mitigations are temporary stopgap measures and might 
not necessarily cover all disclosed vulnerabilities.  
deployed 
Once the organization receives a patch, the internal 
patch  management  process  starts  until  the  patch  is 
adequately 
production 
environment.  The  organizations  often  regard 
the 
exposure  window  as  closed  when  the  proportion  of 
systems  patched  is  somewhere  around  95%,  as  there 
will always be some number of systems that are either 
offline  or  unmanaged.  This  does  not  mean  that  risk 
goes to zero, since even one unpatched machine could 
present substantial exploitation risk, depending how it 
is positioned in the environment. However, to simplify 
our assumptions in the model, we regard the time when 
a patch is adequately deployed is when the window of 
exposure is closed: T6-T1. If an organization uses some 
type  of  early  mitigations  such  as  signatures  we  also 
regard  the  time  that  these  are  adequately  deployed  as 
the time that exposure is closed: T3-T1.  
4.2. The rate parameters of external events  
time, 
The  analysis  of  the  vulnerability  timeline  also 
highlights the events in external environment that have 
direct  affect  on  decisions  the  organizations  takes  on 
when to deploy security mitigations. The availability of 
an exploit poses a security threat to the organizations; 
at 
to  decide  on  an 
appropriate action before the patch is available. When 
the  patch  is  released,  the  organization  can  start  its 
patch  management  process,  finally  reducing  risk  of 
exploit  or  attack  when  the  patch  is  deployed.  The 
resulting exposure risk depends strongly on the timing 
and dynamics of those two external events.  
the  organization  has 
specifying 
In  our  model  we  need  to  describe  such  events 
stochastically, 
probability 
distribution  functions  that  these  events  occur  with. 
Based on the vulnerability data analysis done by Frei, 
et  al  [6]  and  data  published  by  Symantec  [17],  we 
chose to generalize on the following distributions. 
For exploit availability event after the vulnerability 
disclosure  (time 
that 
exploits  appear  at  a  constant  rate  of  5  days  after 
disclosure,  and  so  we  use  an  exponential  distribution 
with the following probability density function:  
interval  T2-T1)  we  assume 
the 
by 
fexploit_delay (texploit) = 5e-5texploit. 
For  patch  availability  event  (time  interval  T4-T1) 
similarly  we  assume  that  patches  are  released  by 
vendors at a constant rate of 23 days after disclosure, 
and so an exponential distribution, with λ=23, is used:  
fpatch_delay (tpatch) = 23e-23tpatch. 
2636
For malware arrival event2 (time interval T5-T1) we 
use an exponential distribution as well, but we will 
vary the rate with λ=10 and λ=25:  
fmalware_delay (tmalware) = 25e-25tmalware. 
We  acknowledge  that  our  assumptions  might  not 
apply across the whole set of disclosed vulnerabilities, 
and we believe that for highly critical vulnerabilities or 
for  different  software  vendors,  these  rates  might  be 
different.  However,  for  the  time  being,  we  have  not 
found enough data to contradict the rates chosen above.  
Since we aim to simulate how the internal security 
processes  in  an  organization  react  to  the  various 
vulnerabilities,  we also  need to take into account  that 
not  all  vulnerabilities  might  be  exploited  and  some 
might never have patches released. We decided to use 
the  latest  Symantec  Threat  Report  [21]  to  select  the 
appropriate proportions of vulnerabilities3:  
72% of vulnerabilities have exploits, 
3% of vulnerabilities have no patches released. 
Each  event  is  captured  as  a  separate  entity  in  our 
model.  We  define  certain  sequencing  between  the 
events, so that a patch is available only on or after the 
vulnerability  is  disclosed,  and,  for  simplification,  we 
also  define  that  vulnerability  exploit  and  malware 
appears after vulnerability has been disclosed as that is 
when  most  of  the  internal  mitigation  processes  also 
start. This sequencing of events is shown in figure 2. 
4.3. Internal processes for threat mitigation 
In  implementing  the  patch  management  processes  the 
organizations  use  guidelines  and  best  practices  as 
suggested  by  standard  bodies,  but  the  exact  details 
usually  differ  based  on 
internal  organizational 
requirements.  By  working  together  with  the  security 
operations and threat awareness teams, we have tried to 
identify the main decision points and patch deployment 
policies  that  we  believe  are  credibly  representative 
across many organizations. Figure 2 shows the activity 
based  diagram  of  a  typical  vulnerability  assessment 
and patch management process. 
2 We should note that, since we aim to explore the performance of 
patching  processes  in  our  model,  we  only  consider  vulnerabilities 
and exploits where patching is the primary mitigation. For example, 
we  don’t  take  into  account  malware  that  exploits  other  types  of 
vulnerabilities such as configuration errors. 
3  Again 
these  assumptions  are  made  across  generic  set  of 
vulnerabilities,  and  maybe  different  depending  on  the  type  of  the 
vulnerability. 
2737
Figure 2. Activity diagram of a typical 
vulnerability and patch management process. 
The  left  hand  side  of  Figure  2  shows  the  various 
decision points in the threat assessment process that is 
usually  triggered  by  the  public  disclosure  of  the 
vulnerability.  On  the  right  hand  side  of  this  diagram 
are the three types of patch deployment policies that an 
organization  might  decide  to  apply  depending  on  the 
criticality  of  the  vulnerability  determined  during  the 
threat  assessment.  Once  a  patch  is  published  by  the 
software  vendor  an  organization  usually  does  its  own 
patch preparation that consists of assessing and testing 
the  patch  within  its  own  environment.  This  usually 
takes around 15 to 30 days, and includes assessment of 
potential patch failure and might include waiting time 
for  a  second  round  of  patch  release  from  the  vendor. 
Sometimes,  the  patch  preparation  might  be  expedited 
together  with  the  patch  deployment.  However,  due  to 
high risk of failure when deploying patches that are not 
properly tested, the security team might be reluctant to 
expedite the patch testing, and so for the purpose of our 
model,  we  decided  to  assume  that  patch  preparation 
always takes the same time independent of the decision 
for patch deployment. 
The three types of patch deployment policies differ 
only  in  the  time  it  takes  for  a  patch  to  be  deployed 
across  all  vulnerable  systems  in  the  organization. 
Depending  on  the  size  of  an  organization  and  on  the 
prevalence of the  vulnerable  software the deployment 
stage up to the time that most systems are patched can 
take weeks or even months, as the security operations 
teams  have  to  negotiate  with  the  business  for  the 
specific periods of IT systems downtime.  Usually, the 
criticality and likelihood of vulnerability as determined 
during  threat  assessment  is  used  in  deciding  the 
to 
justifiable  level  of  disruption  to  the  business  from 
deploying a patch compared to exposure risk.   
For  its  threat  assessment  process  an  organization 
might have screening algorithm applied that is used to 
suggest which vulnerabilities require discussion. Often 
it is based on the criticality score that vulnerability has, 
applied  according 
the  Common  Vulnerability 
Scoring System (CVSS) version 2 standard [4], but the 
security team might apply its own algorithm on top of 
that.  The  security  team  has  also  to  determine  if  this 
vulnerability applies to the organization’s environment; 
if  the  vulnerable  software  is  actually  used  in  the  IT 
environment. Once the applicability is determined, the 
threat  assessment  team  reassesses  the  criticality  of 
vulnerability  and  identifies  if  any  prior  mitigations 
exist.  These  would  include  cases  when  a  newly 
disclosed vulnerability is covered by a previous patch, 
signature  based  mitigation,  such  as  antivirus,  or  any 
other type of solution that is employed before patching. 
We  observed  that  primary  trigger  for  deciding  on 
quicker  patch  deployment  are  the  reports  of  public 
exploits  of  the  vulnerability,  especially  exploits  with 
large  attack  surface  or  that  might  result  in  quick 
spreading. The organizations might be advised on such 
reports by security software vendors, or have their own 
intelligence 
tracking  hacker  community 
mailing lists. In rare cases, the threat assessment team 
might  decide  on  emergency  patching  based  on  the 
criticality  of  vulnerability  itself  without  there  being 
public  exploits  yet.  Based  on  the  impact  of  potential 
exploit  and  the  criticality  of  vulnerability,  either 
accelerated  or  emergency  patching  policy  is  then 
applied  instead  of  a  standard,  business  as  usual, 
patching. In cases, when at the time of public exploit, 
the  vendor  has  not  released  a  patch  the  security  team 
might  design  a  workaround,  which  could  be  firewall 
rule  changes,  shutting  down  of  certain  systems,  or 
other  measures  usually  resulting  in  more  drastic 
disruptions. 
through 
4.4. Internal parameters used for simulations  
patch 
For  our  simulations  we  have  captured  the  activity 
diagram  as  six  separate  processes:  vulnerability 
assessment,  threat  assessment,  mitigation  assessment 
and/or 
patch 
deployment,  and  workaround  deployment.  Here  we 
will specify the internal parameters that determine the 
sequencing of these processes and their execution.  
deployment, 
preparation, 
The  first  aim  with  our  simulations  is  to  estimate 
how long the exposure window is across a large set of 
vulnerabilities  with 
internal  processes 
applied  in  an  organization  with  around  100,000 
systems requiring patching at the same time, and based 
the  above 
on the probability distributions of external environment 
events as defined in section 4.2. In the first iteration of 
the  model  we decided to express the time it takes  for 
each  of  the  five  processes  to  finish  as  a  uniform 
distribution of time delay in terms of days, which will 
be represented here as U(days_min, days_max). 
Vulnerability  assessment  process  is  triggered  by 
vulnerability  disclosure  event.  In  our  representation 
this  process  is  characterized  by  delay,  with  minimum 
and maximum parameters of 0.5 and 1.5 days: 
fv_assessment_delay (tassess) = U (0.5, 1.5). 
in  deciding 
that:  (i) 
to 
Threat  assessment  happens  after  the  vulnerability 
assessment  and  is  triggered  by  an  exploit  availability 
event. This process is represented as resulting in a one 
the 
day  delay.  It  results 
vulnerability  does  not  present  high  risk 
the 
organization  and  can  be  mitigated  by  standard 
patching,  (ii)  existing  mitigations  cover  the  threat 
(standard patching would still be done), (iii) declaring 
either  accelerated  patching  or  emergency  patching  in 
case  of  reports  of  worm-type  exploit/malware.  By 
examining the past 2-3 years data of threat assessments 
and  of  the  vulnerability  CVSS  scores  as  published  in 
National  Vulnerability  Database  (NVD)  we  have 
selected  the  following  proportions  for  the  different 
decisions  that  would  be  taken  for  patching  the 
vulnerability: 
• 
• 
• 
• 
• 
• 
93% of vulnerabilities would be handled with 
standard patching, 
7 % of vulnerabilities would go through threat 
assessment; out of these: 
10%  of  vulnerabilities  would 
accelerated patching, 
for  40%  of  vulnerabilities  an  emergency 
patching would be needed, 
5% of vulnerabilities require workarounds, 
45% of vulnerabilities could be covered with 
signature-based mitigations. 