looks at events encompassing tens of minutes, these anoma-
lies, especially ones involving the Internet core, would show
up as the most strongly correlated because of the massive
route withdrawals and announcements. Some serious prob-
lems often do not result in sudden surges of BGP events
though. For things like persistent route oscillation or ﬂaky
link, the continuous events might be mistaken as BGP noise.
But if Stemming looks at events representing hours or days,
these anomalies even involving just a single preﬁx would
overwhelm other correlations and show up as the strongest
one.
3.3 Performance
Table 1 shows sample running times of the TAMP and
Stemming algorithms when applied on data from Berkeley
and ISP-Anon. Our implementation is in C++ and executed
on an Intel Pentium 4 machine with a 3.06 GHz CPU and
TAMP picture
No. routes
230k
115k
23k
Run time
1.8 sec
1.6 sec
0.5 sec
TAMP animation
No. events
1k
10k
100k
1000k
Timerange
423 sec
36 min
7.6 hrs
33.6 hrs
Run time
0.5 sec
1.1 sec
9 sec
78 sec
No. events
12k
57k
330k
Stemming
Timerange
189 sec
882 sec
16.3 min
Run time
8.6 sec
9.5 sec
17.3 sec
(a) Berkeley
TAMP picture
No. routes
1500k
750k
150k
Run time
7 sec
3.8 sec
1.5 sec
TAMP animation
No. events
1k
10k
100k
1000k
Timerange
226 sec
621 sec
2.3 hrs
20.5 hrs
Run time
1.0 sec
1.6 sec
9.4 sec
88.5 sec
No. events
214k
346k
791k
Stemming
Timerange
61.7 min
51.7 min
1.7 hrs
Run time
32.8 sec
34.1 sec
35.2 sec
(b) ISP-Anon
Table 1. Execution times of TAMP and Stemming algorithms.
1.5GB of memory. For the TAMP picture column, running
time denotes the time TAMP took to compute a picture rep-
resenting the listed number of routes and then pruned with
the default threshold. Under TAMP animation, timerange
is the actual time period encompassed by the listed num-
ber of events, i.e. the difference between the ﬁrst and last
event’s timestamp. For Stemming, each event group is an
actual event spike in the network associated with a real rout-
ing change or anomaly. Note that the timerange for similar
number of events is much shorter in ISP-Anon than Berke-
ley, as BGP is a lot chattier in an ISP because of its peerings
with other ISPs. Since Berkeley has fewer routes than ISP-
Anon, its running times are shorter for the same number of
events — the algorithm keeps track of signiﬁcantly smaller
BGP RIBs and topology data structures for Berkeley.
In
these measurements, we ran the algorithms starting at the
current state of the system. In other words, we do not in-
clude time to rebuild data structures to move to any random
point in time. This setup reﬂects how the algorithms would
be used in a real-time system.
4 Results from Real Networks
4.1 Load Balancing Unbalanced
Let us revisit Figure 2, a TAMP picture of Berkeley’s
BGP. Most of this picture is expected. However, when
we showed this picture to Berkeley’s network engineers,
they found a previously undiagnosed misconﬁguration. The
BGP edge router 128.32.1.3 is conﬁgured to carry commod-
ity Internet trafﬁc, and for load balancing purposes, Berke-
ley simply splits the preﬁx address space in half onto two
rate-limiting BGP Nexthops, 128.32.0.66 and 128.32.0.70.
There was an error during this split, and the division turned
out to be much skewed: 128.32.0.66 carried 78% of the to-
tal advertised preﬁxes, and 128.32.0.70 only 5%. It would
be hard to detect this misconﬁguration with a “show ip bgp”
output at the router. “One picture says a million routes” is
the power of TAMP.
4.2 Backdoor routes
Figure 2 also exposes two backdoor routes between
128.32.1.222 and AT&T, via the Nexthop 169.229.0.157.
Backdoor routes might have severe impact on a network.
It can create a security breach unbeknownst to network ad-
ministrators.
4.3 BGP Community Mis-tagging
The TAMP and Stemming techniques work well for
both simple tree-like topology of an university or enterprise
with relatively few BGP edge routers and a single provider,
and also for rich, forest-like topology of a Tier-1 service
provider with hundreds of core BGP routers peering with
most of the other Tier-1s and many customers. We applied
the techniques on Berkeley and ISP-Anon and present the
results in this section.
TAMP shows the large-scale structure of any set of
routes. One meaningful subset are routes tagged with a cer-
tain community. Many routing policies are tied to commu-
nity values: route ﬁltering, setting route preferences, route
scoping, etc. It is useful to see if a community tag really
means what documentation says it means. Figure 5 is a
TAMP visualization of routes tagged with the CENIC com-
munity 2152:65297, heard at Berkeley in December 2003.
CENIC attaches this value only to routes coming from the
Los Nettos peering via LAAP, not to the ones received from
customer links. We observe from Figure 5 that only 32% of
the preﬁxes with 2152:65297 were from Los Nettos, where
as 68% came from KDDI, a Japanese ISP. If this commu-
nity is used to set higher priority to Los Nettos routes based
on some agreement between Berkeley and Los Nettos, then
KDDI would have also been given preferential treatment.
We conﬁrmed with CENIC that this is indeed an error. This
mis-tagging was probably made during the consolidation of
multiple AS numbers into just AS2152. CENIC has ﬁxed
the problem since then.
UC Berkeley
12/15 18:35
Comm 2152:65297
1002 prefixes
100%
128.32.1.222
100%
137.164.23.29
100%
2152
cenic_dc
226
los_nettos
2 %
3
68%
2516
kddi
9 %
6 %
4%
4%
4
%
4732
dion
9824
athomej
7479
kdd_hk
7679
qtnet
10010
tokai
Figure 5. Mis-tagging of community.
4.4 Peer Leaking Routes
The “Loading balancing unbalanced”,
“Backdoor
routes” and “Community mis-tagging” incidents were man-
ually detected by examining TAMP pictures. We also
applied the Stemming technique to automatically analyze
BGP events and discover routing anomalies. The remain-
ing results were detected by Stemming and the animations
generated by TAMP.
In the Berkeley data, Stemming detected a handful ex-
port misconﬁguration incidents where leaked routes from
CalREN’s peers caused a signiﬁcant number of preﬁxes
to move over to a much longer path, and thereby affected
how Berkeley’s trafﬁc reached the Internet. The leaked
routes are preferred over the shorter paths because of Cal-
REN’s local preferences. Figure 6 contains a snapshot
of an animation showing one such incident (we encour-
age readers to visit [6] to see the actual animations men-
tioned in this paper). This is a 500,000 event incident where
30,000 preﬁxes moved over, twice, from CalRENN-Qwest
to Level3 via a AS-hop path consisting of Packet Clear-
ing House, Alpha NAP, San Diego Supercomputing Cen-
ter and CENIC. The (128.32.1.3-128.32.0.66-11423-209)
path has a gray shadow with a thin blue line which means
it is losing preﬁxes. The (11423-11422-10927-1909-195-
2152-3356) path is green which means it is gaining preﬁxes.
The (128.32.1.200-128.32.0.90) path remains black which
means the number of preﬁxes it carries is not changing. The
CalRENN-QWest edge is selected in these snapshots.
Peer leaking routes can lead to suboptimal routing in
the Internet. At Berkeley, the leaked routes, when inter-
acted with a BGP community policy, led to some unex-
pected and costly consequences. From Figure 6, we see
that whenever preﬁxes on the CalREN-QWest edge move
over to another path, the BGP edge router 128.32.1.3 also
stops announcing those preﬁxes. We know that an alter-
nate path does exist because 128.32.1.200 advertises it. We
conﬁrmed with Berkeley that the intended behavior would
be for 128.32.1.3 to advertise routes for the commodity
Internet, thereby making the two rate-limiters 128.32.0.66
and 128.32.0.70 on the primary path to the outside world.
However, since 128.32.1.3 is not announcing the alter-
nate path, effectively all commodity Internet trafﬁc ended
up going through 128.32.0.90 which is not rate-limited.
Berkeley does not rate-limit Internet2 trafﬁc that goes to-
ward Abilene. Thus 128.32.1.3, which uses the rate-limiter
BGP Nexthops 128.32.0.66 and 128.32.0.70, ﬁlters out all
routes except those for the commodity Internet. 128.32.1.3
uses BGP community from CalREN to distinguish between
commodity Internet routes and other routes such as those for
Internet2. When routes are not heard directly from QWest,
CalREN does not attach the ISP’s community on them. One
can argue this is the correct behavior from CalREN’s view-
point, even though the routes do come from a commercial
provider, Level3, at the end of the 6 AS-hop path. This
type of interaction between routing anomalies and intended
policy causing unexpected actual behavior is difﬁcult if not
impossible to diagnose without tools like Stemming and
TAMP.
4.5 Continuous Customer Route Flapping
The most serious problem Stemming detected at ISP-
Anon during our data collection does not constitute event
“spikes”. Instead, it shows up as low-grade BGP churn in
the “grass” of an event count versus time chart. The prob-
lem is a persistent route oscillation between ISP-Anon and