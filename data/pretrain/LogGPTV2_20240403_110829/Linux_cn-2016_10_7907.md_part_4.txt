### 找到误差标准
我们已经完成了训练数据表的生成，现在我们需要最后一步，生成预测。我们需要找到误差的标准，以及该如何评估我们的数据。在这种情况下，因为有很多的贷款没有被取消赎回权，所以根本不可能做到精确的计算。
我们需要读取训练数据，并且计算 `foreclosure_status` 列的计数，我们将得到如下信息：
```
import pandas as pd
import settings
train = pd.read_csv(os.path.join(settings.PROCESSED_DIR, "train.csv"))
train["foreclosure_status"].value_counts()
```
```
False    4635982
True        1585
Name: foreclosure_status, dtype: int64
```
因为只有很少的贷款被取消赎回权，只需要检查正确预测的标签的百分比就意味着我们可以创建一个机器学习模型，来为每一行预测 `False`，并能取得很高的精确度。相反，我们想要使用一个度量来考虑分类的不平衡，确保我们可以准确预测。我们要避免太多的误报率（预测贷款被取消赎回权，但是实际没有），也要避免太多的漏报率（预测贷款没有别取消赎回权，但是实际被取消了）。对于这两个来说，漏报率对于房利美来说成本更高，因为他们买的贷款可能是他们无法收回投资的贷款。
所以我们将定义一个漏报率，就是模型预测没有取消赎回权但是实际上取消了，这个数除以总的取消赎回权数。这是“缺失的”实际取消赎回权百分比的模型。下面看这个图表：
![](/data/attachment/album/201610/28/101602npfaaa3rjh2fjfos.jpg)
通过上面的图表，有 1 个贷款预测不会取消赎回权，但是实际上取消了。如果我们将这个数除以实际取消赎回权的总数 2，我们将得到漏报率 50%。 我们将使用这个误差标准，因此我们可以评估一下模型的行为。
### 设置机器学习分类器
我们使用交叉验证预测。通过交叉验证法，我们将数据分为3组。按照下面的方法来做：
* 用组 1 和组 2 训练模型，然后用该模型来预测组 3
* 用组 1 和组 3 训练模型，然后用该模型来预测组 2
* 用组 2 和组 3 训练模型，然后用该模型来预测组 1
将它们分割到不同的组，这意味着我们永远不会用相同的数据来为其预测训练模型。这样就避免了过拟合。如果过拟合，我们将错误地拉低了漏报率，这使得我们难以改进算法或者应用到现实生活中。
[Scikit-learn](http://scikit-learn.org/) 有一个叫做 [cross*val*predict](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_predict.html) ，它可以帮助我们理解交叉算法.
我们还需要一种算法来帮我们预测。我们还需要一个分类器来做[二元分类](https://en.wikipedia.org/wiki/Binary_classification)。目标变量 `foreclosure_status` 只有两个值， `True` 和 `False`。
这里我们用 [逻辑回归算法](https://en.wikipedia.org/wiki/Logistic_regression)，因为它能很好的进行二元分类，并且运行很快，占用内存很小。我们来说一下它是如何工作的：不使用像随机森林一样多树结构，也不像支持向量机一样做复杂的转换，逻辑回归算法涉及更少的步骤和更少的矩阵。
我们可以使用 scikit-learn 实现的[逻辑回归分类器](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)算法。我们唯一需要注意的是每个类的权重。如果我们使用等权重的类，算法将会预测每行都为 `false`，因为它总是试图最小化误差。不管怎样，我们重视有多少贷款要被取消赎回权而不是有多少不能被取消。因此，我们给[逻辑回归](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)类的 `class_weight` 关键字传递 `balanced` 参数，让算法可以为不同 counts 的每个类考虑不同的取消赎回权的权重。这将使我们的算法不会为每一行都预测 `false`，而是两个类的误差水平一致。
### 做出预测
既然完成了前期准备，我们可以开始准备做出预测了。我将创建一个名为 `predict.py` 的新文件，它会使用我们在最后一步创建的 `train.csv` 文件。下面的代码：
* 导入所需的库
* 创建一个名为 `cross_validate` 的函数：
	+ 使用正确的关键词参数创建逻辑回归分类器
	+ 创建用于训练模型的数据列的列表，移除 `id` 和 `foreclosure_status` 列
	+ 交叉验证 `train` DataFrame
	+ 返回预测结果
```
import os
import settings
import pandas as pd
from sklearn import cross_validation
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
def cross_validate(train):
    clf = LogisticRegression(random_state=1, class_weight="balanced")
    predictors = train.columns.tolist()
    predictors = [p for p in predictors if p not in settings.NON_PREDICTORS]
    predictions = cross_validation.cross_val_predict(clf, train[predictors], train[settings.TARGET], cv=settings.CV_FOLDS)
    return predictions
```
### 预测误差
现在，我们仅仅需要写一些函数来计算误差。下面的代码：
* 创建函数 `compute_error`：
	+ 使用 scikit-learn 计算一个简单的精确分数（与实际 `foreclosure_status` 值匹配的预测百分比）
* 创建函数 `compute_false_negatives`：
	+ 为了方便，将目标和预测结果合并到一个 DataFrame
	+ 查找漏报率
		- 找到原本应被预测模型取消赎回权，但实际没有取消的贷款数目
		- 除以没被取消赎回权的贷款总数目
```
def compute_error(target, predictions):
    return metrics.accuracy_score(target, predictions)
def compute_false_negatives(target, predictions):
    df = pd.DataFrame({"target": target, "predictions": predictions})
    return df[(df["target"] == 1) & (df["predictions"] == 0)].shape[0] / (df[(df["target"] == 1)].shape[0] + 1)
def compute_false_positives(target, predictions):
    df = pd.DataFrame({"target": target, "predictions": predictions})
    return df[(df["target"] == 0) & (df["predictions"] == 1)].shape[0] / (df[(df["target"] == 0)].shape[0] + 1)
```
### 聚合到一起
现在，我们可以把函数都放在 `predict.py`。下面的代码：
* 读取数据集
* 计算交叉验证预测
* 计算上面的 3 个误差
* 打印误差
```
def read():
    train = pd.read_csv(os.path.join(settings.PROCESSED_DIR, "train.csv"))
    return train
if __name__ == "__main__":
    train = read()
    predictions = cross_validate(train)
    error = compute_error(train[settings.TARGET], predictions)
    fn = compute_false_negatives(train[settings.TARGET], predictions)
    fp = compute_false_positives(train[settings.TARGET], predictions)
    print("Accuracy Score: {}".format(error))
    print("False Negatives: {}".format(fn))
    print("False Positives: {}".format(fp))
```
一旦你添加完代码，你可以运行 `python predict.py` 来产生预测结果。运行结果向我们展示漏报率为 `.26`，这意味着我们没能预测 `26%` 的取消贷款。这是一个好的开始，但仍有很多改善的地方！
你可以在[这里](https://github.com/dataquestio/loan-prediction/blob/master/predict.py)找到完整的 `predict.py` 文件。
你的文件树现在看起来像下面这样：
```
loan-prediction
├── data
│   ├── Acquisition_2012Q1.txt
│   ├── Acquisition_2012Q2.txt
│   ├── Performance_2012Q1.txt
│   ├── Performance_2012Q2.txt
│   └── ...
├── processed
│   ├── Acquisition.txt
│   ├── Performance.txt
│   ├── train.csv
├── .gitignore
├── annotate.py
├── assemble.py
├── predict.py
├── README.md
├── requirements.txt
├── settings.py
```
### 撰写 README
既然我们完成了端到端的项目，那么我们可以撰写 `README.md` 文件了，这样其他人便可以知道我们做的事，以及如何复制它。一个项目典型的 `README.md` 应该包括这些部分：
* 一个高水准的项目概览，并介绍项目目的
* 任何必需的数据和材料的下载地址
* 安装命令
	+ 如何安装要求依赖
* 使用命令
	+ 如何运行项目
	+ 每一步之后会看到的结果
* 如何为这个项目作贡献
	+ 扩展项目的下一步计划
[这里](https://github.com/dataquestio/loan-prediction/blob/master/README.md) 是这个项目的一个 `README.md` 样例。
### 下一步
恭喜你完成了端到端的机器学习项目！你可以在[这里](https://github.com/dataquestio/loan-prediction)找到一个完整的示例项目。一旦你完成了项目，把它上传到 [Github](https://www.github.com/) 是一个不错的主意，这样其他人也可以看到你的文件夹的部分项目。
这里仍有一些留待探索数据的角度。总的来说，我们可以把它们分割为 3 类： 扩展这个项目并使它更加精确，发现其他可以预测的列，并探索数据。这是其中一些想法：
* 在 `annotate.py` 中生成更多的特性
* 切换 `predict.py` 中的算法
* 尝试使用比我们发表在这里的更多的房利美数据
* 添加对未来数据进行预测的方法。如果我们添加更多数据，我们所写的代码仍然可以起作用，这样我们可以添加更多过去和未来的数据。
* 尝试看看是否你能预测一个银行原本是否应该发放贷款（相对地，房利美是否应该获得贷款）
	+ 移除 `train` 中银行在发放贷款时间的不知道的任何列
		- 当房利美购买贷款时，一些列是已知的，但之前是不知道的
	+ 做出预测
* 探索是否你可以预测除了 `foreclosure_status` 的其他列
	+ 你可以预测在销售时资产值是多少？
* 探索探索执行数据更新之间的细微差别
	+ 你能否预测借款人会逾期还款多少次?
	+ 你能否标出的典型贷款周期?
* 将数据按州或邮政编码标出
	+ 你看到一些有趣的模式了吗?
如果你建立了任何有趣的东西,请在评论中让我们知道!
如果你喜欢这篇文章，或许你也会喜欢阅读“构建你的数据科学作品集”系列的其他文章：
* [用数据讲故事](https://www.dataquest.io/blog/data-science-portfolio-project/)
* [如何搭建一个数据科学博客](https://www.dataquest.io/blog/how-to-setup-a-data-science-blog/)
* [构建一个可以帮你找到工作的数据科学作品集的关键](https://www.dataquest.io/blog/build-a-data-science-portfolio/)
* [找到数据科学用的数据集的 17 个地方](https://www.dataquest.io/blog/free-datasets-for-projects)
---
via: 
作者：[Vik Paruchuri](https://www.dataquest.io/blog) 译者：[kokialoves](https://github.com/kokialoves), [zky001](https://github.com/zky001), [vim-kakali](https://github.com/vim-kakali), [cposture](https://github.com/cposture), [ideas4u](https://github.com/ideas4u) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出