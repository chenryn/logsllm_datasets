29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
45:
46: end function
end if
end for
return (FX, LX, RX)
Sort YC by frequency
Sort YM by frequency
for i = 1 to x do
47: function FREQ-ANALYSIS(YC, YM, x)
48:
49:
50:
51:
52:
53:
end for
54:
return T ′
55:
56: end function
C ← i-th frequent ciphertext chunk
M ← i-th frequent plaintext chunk
Add (C, M ) to T ′
and returns the result set T of all inferred ciphertext-plaintext
chunk pairs. It ﬁrst calls the function COUNT to obtain the
following associative arrays: FC, which stores the frequencies
of all ciphertext chunks, as well as LC and RC, which store
the co-occurrence frequencies of the left and right neighbors of
all ciphertext chunks, respectively (Line 2); similarly, it obtains
the associative arrays FM, LM, and RM for the plaintext
chunks (Line 3). It then initializes the inferred set G, either
by obtaining u most frequent ciphertext-plaintext chunk pairs
from frequency analysis in ciphertext-only mode, or by adding
the set of leaked ciphertext-plaintext chunk pairs from the
latest backup in known-plaintext mode (Lines 4-8). It also
initializes T with G (Line 9).
In the main loop (Lines 10-22), the algorithm removes a
pair (C, M ) from G (Line 11) and uses it to infer additional
ciphertext-plaintext chunk pairs from the neighboring chunks
of C and M . It ﬁrst examines all left neighbors by running the
function FREQ-ANALYSIS on LC[C] and LM[M ], and stores v
most frequent ciphertext-plaintext chunk pairs in Tl (Line 12).
Similarly, it examines all right neighbors and stores the results
in Tr (Line 13). For each (C, M ) in Tl ∪ Tr, if (C, ∗) is not in
T (i.e., the ciphertext chunk C has not been inferred yet), we
add (C, M ) to T and also to G if G is not full (Lines 14-21).
The main loop iterates until G becomes empty. Finally, T is
returned.
Both the functions COUNT and FREQ-ANALYSIS are similar
to those in the basic attack (see Algorithm 1), with the
following extensions. For COUNT, in addition to constructing
the associative array FX (where X can be either C and M)
that holds the frequencies of all chunks, it also constructs the
associative arrays LX and RX that hold the co-occurrence
frequencies of the left and right neighbors of each chunk X,
respectively. For FREQ-ANALYSIS, it now performs frequency
analysis on the associative arrays YC and YM, in which YC
(resp. YM) refers to either FC (resp. FM) that holds the
frequency counts of all chunks, or LC[C] and RC[C] (resp.
LM[M ] and RM[M ]) that hold the frequency counts of all
ordered pairs of chunks associated with ciphertext chunk C
(resp. plaintext chunk M ). Also, FREQ-ANALYSIS only returns
x (where x can be either u or v) most frequent ciphertext-
plaintext chunk pairs.
Example: Figure 2 shows an example of how the locality-
based attack works. Here, we consider ciphertext-only mode.
Suppose that we have obtained the auxiliary information
M = hM1, M2, M1, M2, M3, M4, M2, M3, M4i of some prior
backup, and use it to infer the original plaintext chunks of C =
hC1, C2, C5, C2, C1, C2, C3, C4, C2, C3, C4, C4i of the latest
backup. We set u = v = 1, and w → ∞ (i.e., the inferred set
G is unbounded). We assume that the ground truth is that the
original plaintext chunk of the ciphertext chunk Ci is Mi for
i = 1, 2, 3, 4, while that of C5 is some new plaintext chunk
not in M (note that in reality, an adversary does not know the
ground truth).
We ﬁrst apply frequency analysis and ﬁnd that (C2, M2)
is the most frequent ciphertext-plaintext chunk pair, so we
initialize G = {(C2, M2)} and add it into T . We then remove
and operate on (C2, M2) from G, and ﬁnd that LC2 =
{C1, C4, C5}, LM2 = {M1, M4}, RC2 = {C1, C3, C5},
and RM2 = {M1, M3}. From LC2 and LM2 , we ﬁnd that
is bounded by w (see Section IV-B). Each time we remove
the ﬁrst ciphertext-plaintext chunk pair from the queue for
inferring more chunk pairs from the neighbors.
B. Datasets
We consider two types of datasets to drive our evaluation.
FSL: This is a real-world dataset collected by the File systems
and Storage Lab (FSL) at Stony Brook University [2], [44].
We focus on the Fslhomes dataset, which contains the daily
snapshots of users’ home directories on a shared ﬁle system.
Each snapshot is represented by a collection of 48-bit chunk
ﬁngerprints produced by variable-size chunking of different
average sizes. We pick the snapshots from January 22 to May
21 in 2013, and ﬁx the average size as 8KB for our evaluation.
We select six users (User4, User7, User12, User13, User15,
and User28) that have the complete daily snapshots over the
whole duration. We aggregate each user’s snapshots on a
monthly basis (on January 22, February 22, March 22, April
21, and May 21), and hence form ﬁve monthly full backups
per user. Our post-processed dataset covers a total of 2.69TB
of logical data before deduplication.
Synthetic: This dataset contains a sequence of synthetic
backup snapshots that are generated based on Lillibridge et
al.’s approach [29]. Speciﬁcally, we create an initial snapshot
from a Ubuntu 14.04 virtual disk image (originally with 1.1GB
of data) with a total of 4.28GB space. We create a sequence
of snapshots starting from the initial snapshot, such that each
snapshot is created from the previous one by randomly picking
2% of ﬁles and modifying 2.5% of their content, and also
adding 10MB of new data. Finally, we generate a sequence
of ten snapshots, each of which is treated as a backup.
Based on our choices of parameters, the resulting storage
saving is around 90% (see Experiment B.2 in Section VII-B);
equivalently, the deduplication ratio is around 10:1, which is
typical in real-life backup workloads [45]. Note that the initial
snapshot is publicly available. Later in our evaluation, we
study the effectiveness of the attacks by using it as public
auxiliary information.
C. Results
We present evaluation results. We quantify the severity of
an attack using the inference rate, deﬁned as the ratio of the
number of unique ciphertext chunks whose plaintext chunks
are successfully inferred over the total number of unique
ciphertext chunks in the latest backup; a higher inference rate
implies that the attack is more severe.
Experiment A.1 (Impact of parameters): We ﬁrst evaluate
the impact of parameters on the locality-based attack, in order
to justify our choices of parameters. Recall that the locality-
based attack is conﬁgured with three parameters: u, v, and w.
In this experiment, we use the FSL dataset, and focus on the
attack in ciphertext-only mode. We use the middle version of
the backup on March 22 as auxiliary information, and launch
the attack to infer the original plaintext chunks of the latest
backup on May 21. In each experiment, we ﬁx two out of the
Fig. 2. Example of the locality-based attack.
(C1, M1) is the most frequent ciphertext-plaintext chunk pair,
while from RC2 and RM2 , we ﬁnd (C3, M3). Thus, we
add both (C1, M1) and (C3, M3) into G and T . We repeat
the processing on (C1, M1) and (C3, M3), and we can infer
another pair (C4, M4) from the right neighbors of (C3, M3).
To summarize, the locality-based attack can successfully
infer the original plaintext chunks of all four ciphertext chunks
C1, C2, C3, and C4. It cannot infer the original plaintext chunk
of C5, as it does not appear in M.
V. ATTACK EVALUATION
In this section, we present trace-driven evaluation results
to show the severity of frequency analysis against encrypted
deduplication.
A. Implementation
We implement both the basic and locality-based attacks
in C++. We benchmark our current
implementation on a
Ubuntu 16.04 Linux machine with an AMD Athlon II X4 640
quad-core 3.0GHz CPU and 16GB RAM, and ﬁnd that the
locality-based attack takes around 15 hours to process an FSL
backup of size around 500GB (see Section V-B for dataset
details). In the following, we highlight the implementation
details of some data structures used by the attacks.
that
Associative arrays: Recall
there are three types of
associative arrays: (i) FC and FM, (ii) LC and LM, and (iii)
RC and RM (the latter two are only used by the locality-
based attack). We implement them as key-value stores using
LevelDB [19]. Each key-value store is keyed by the ﬁngerprint
of the ciphertext/plaintext chunk. For FC and FM, each entry
stores a frequency count; for LC, LM, RC, and RM, each
entry stores a sequential list of the ﬁngerprints of all the
left/right neighbors of the keyed chunk and the co-occurrence
frequency counts. For the latter, keeping neighboring chunks
sequentially simpliﬁes our implementation, but also increases
the search time of a particular neighbor (which dominates the
overall running time); we pose the optimization as future work.
Inferred set: We implement the inferred set G in the locality-
based attack as a ﬁrst-in-ﬁrst-out queue, whose maximum size
)
%
(
e
t
a
R
e
c
n
e
r
e
f
n
I
 15
 10
 5
 0
)
%
(
e
t
a
R
e
c
n
e
r
e
f
n
I
 15
 10
 5
 0
 5
 10
 15
 20
 10
 20
 30
 40
50,000 100,000 200,000 400,000
u
(a) Varying u
v
(b) Varying v
Fig. 3. Experiment A.1 (Impact of parameters).
)
%
(
e
t
a
R
e
c
n
e
r
e
f
n
I
 15
 10
 5
 0
)
%
(
e
t
a
R
e
c
n
e
r
e
f
n
I
 25
 20
 15
 10
 5
 0.0001
 0
Locality-based Attack
Basic Attack
Locality-based Attack
Basic Attack
)
%
(
e
t
a
R
e
c
n
e
r
e
f
n
I
 20
 15
 10
 5
 0.2
 0
w
(c) Varying w
FSL
Synthetic
)
%
(
e
t
a
R
e
c
n
e
r
e
f
n
I
 35
 30
 25