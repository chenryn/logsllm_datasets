### Optimized Text

An operator may be interested in evaluating the performance of a network's load balancing protocol. To address this, we demonstrate Speedlight's capability to answer such questions by comparing the performance characteristics of ECMP (Equal-Cost Multi-Path) and Flowlet load balancing algorithms under Hadoop, GraphX, and memcache workloads.

In theory, Flowlet forwarding should provide more balanced load distribution because it splits traffic at a finer granularity [20]. In practice, our understanding of the impact of flowlets on load balance is limited to metrics like average utilization, drop rate, flow completion time, and other carefully designed proxies for the property of interest.

In this experiment, we took a series of snapshots and computed the standard deviation of the Exponentially Weighted Moving Average (EWMA) of packet inter-arrival times across uplink ports. To account for workload variations, uplinks were compared only to other uplinks on the same switch. Figure 12 shows Cumulative Distribution Functions (CDFs) of the standard deviations for our Hadoop, GraphX, and memcache workloads, using both snapshots and traditional polling. The three workloads exhibit different behaviors:

- For Hadoop, polling shows little to no improvement with flowlets, whereas in reality, flowlets significantly enhance load balance.
- For GraphX, polling consistently underestimates the network imbalance.
- For Memcache, which has a very even distribution, polling overestimates the imbalance.

These experiments highlight an important point: for whole-network behavior measures, the issue is not just that polling might provide an incorrect view, but that it is difficult to quantify the inaccuracy.

**Figure 13: Pairwise Correlation Coefficients for Egress Ports While Running GraphX**
- The red boxes highlight port pairs on the same ECMP paths, which are expected to have high positive correlations.

### 8.4 Use Case: Synchronized Traffic
The second use case we explore is the detection of synchronized application traffic patterns to understand behavior or debug performance issues. For this experiment, we measured the EWMA of packet rates at the egress of all ports, taking 100 snapshots one second apart. We then calculated pairwise correlations between ports using Spearman tests [12].

**Figure 13** shows statistically significant (ρ < 0.1) correlation coefficients found while running GraphX. With snapshots, the Spearman test identified correlations for 43% more port pairs. To validate correctness, we analyzed the output for two ground truths related to the application and network topology:
1. No significant correlations between the port egressing to the master server (server 0) and any other port, as the master server did not participate in the distributed computation.
2. High correlations between possible ECMP next-hops.

Snapshots matched both expected ground truths. In contrast, polling failed to identify the positive correlations between ECMP ports. As shown by the red boxes in Figure 13, the correlations found with polling were either statistically insignificant or, worse, statistically significant but negative. Results were qualitatively similar for other applications and ρ values.

### 9 Related Work
Network measurement is a well-studied field, with many proposals for better and more expressive measurement tools [15, 22, 31, 42]. As networks grow, the need for effective monitoring and debugging tools becomes even more critical. To the best of our knowledge, our work is the first to demonstrate practical, synchronous, and consistent network-wide measurement. A large body of prior work has tackled related goals and solutions, which we discuss below.

**Hardware-assisted Measurement:** With the rise of programmable data and control planes, there has been increased interest in novel measurement applications [28, 29, 31, 32, 37, 40]. These approaches have explored the limits of feasible data collection, showcasing the expressiveness and utility of programmable switches. Our work complements these efforts by enabling network snapshots of any local state, including the statistics generated by these systems.

**Multi-device Measurement:** One method to move beyond single-component measurement is to leverage traffic to capture relevant state as it traverses the network [1, 2, 15, 22]. For example, packets could record the minimum queue depth at any intermediate switch. These techniques enforce causal consistency at the level of a single sample but still face challenges in comparing across samples and paths.

**Measurement Aggregation:** Another approach to understanding network-wide behavior is to aggregate measurements from individual devices or paths and build larger insights. Network tomography [11, 21, 26, 30] is a common example that uses statistics to infer interesting behavior from long-term traces of multiple devices. While useful, these approaches lack the granularity to address the types of questions discussed in the preceding section.

**Distributed Snapshots:** The literature on distributed snapshot algorithms is extensive. The original paper on the topic [10] inspired various improvements and refinements. Notably, piggybacking-based protocols like [24, 27] were originally designed for non-FIFO channels, and we adapt their techniques to handle packet drops while prohibiting out-of-order delivery for efficiency. Others have discussed the practicality of distributed snapshots in networks [18, 34], but in the control plane rather than the data plane.

### 10 Discussion
**Measuring Forwarding State:** In Section 2.2, we noted the potential value of snapshotting forwarding state. While ASIC data planes typically cannot record table entries directly, they can record version information. Specifically, the control plane can ensure every FIB rule and version tags passing packets with a unique ID, which is then stored back into processing unit state. A snapshot of this state would provide insights into the entire network's forwarding state.

**Partial Deployment:** Speedlight supports partial deployment. In this scenario, the snapshot would cover participating devices and the communication channels between them. For instance, in a data center, an operator might enable snapshots only for Top-of-Rack (ToR) switches or a specific cluster. For snapshots without channel state, the only requirement is that the snapshot header is appended and removed at the proper time. The simplest method is to append the header whenever an ingress processing unit encounters a packet without one and configure the remaining hosts to ignore IP options containing the snapshot header. If this is not possible (e.g., due to security concerns), the header should be removed at the last snapshot-enabled device in the packet's path. Causal consistency is maintained even when there are multiple paths between devices.

**Snapshots with Channel State:** Gathering channel state is slightly more complex. Devices must reduce communication to FIFO channels and tag packets with the physical path they take between snapshot-enabled devices. In the case of data centers and snapshot-enabled ToRs, this requires only minor modifications to the configuration of existing devices [33].

### 11 Conclusion
Synchronized Network Snapshots and its implementation, Speedlight, provide unprecedented visibility into the behavior of the network as a whole. Whether for evaluating a design, diagnosing an issue, or simply understanding an existing network, these techniques help answer critical questions. We demonstrate the practicality of this approach by implementing and deploying a working version of our system on a testbed, then using it to collect meaningful measurements of real workloads.

### Acknowledgements
We gratefully acknowledge Sameera Gajjarapu, our shepherd Aditya Akella, and the anonymous SIGCOMM reviewers for their invaluable help and thoughtful comments.

### References
[References remain unchanged]

---

This optimized text aims to improve clarity, coherence, and professionalism while maintaining the original content and intent.