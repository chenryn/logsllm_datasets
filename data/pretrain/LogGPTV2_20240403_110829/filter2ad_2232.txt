title:Anomaly and Specification Based Cognitive Approach for Mission-Level
Detection and Response
author:Paul Rubel and
Partha P. Pal and
Michael Atighetchi and
D. Paul Benjamin and
Franklin Webber
Anomaly and Speciﬁcation Based Cognitive
Approach for Mission-Level Detection and
Response(cid:2)
(Extended Abstract)
Paul Rubel1, Partha Pal1, Michael Atighetchi1, D. Paul Benjamin2,
and Franklin Webber1
1 BBN Technologies, Cambridge MA 21038, USA
PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL
2 Pace University, 1 Pace Plaza, New York NY 10038, USA
PI:EMAIL
Abstract. In 2005 a survivable system we built was subjected to red-
team evaluation. Analyzing, interpreting, and responding to the defense
mechanism reports took a room of developers. In May 2008 we took part
in another red-team exercise. During this exercise an autonomous reason-
ing engine took the place of the room of developers. Our reasoning engine
uses anomaly and speciﬁcation-based approaches to autonomously decide
if system and mission availability is in jeopardy, and take necessary cor-
rective actions. This extended abstract presents a brief summary of the
reasoning capability we developed: how it categorizes the data into an
internal representation and how it uses deductive and coherence based
reasoning to decide whether a response is warranted.
1 The Basic Idea
Requiring experts to manage a system’s defenses is an expensive undertaking,
even assuming that such operators can be found. With faster CPUs, more RAM,
faster and higher capacity networks we can transfer this tedious work to a rea-
soning engine. Our reasoning engine uses the mission concept (a model of how
the system functions in a particular context) and sensor inputs, generated while
the mission runs, to autonomously defend the system.
1.1 Challenges and Solution Approach
The main challenge is making sense of the low level observables reported by the
survivability architecture in the context of the current system and mission, and
then deciding what and when remedial actions should be taken. Additionally,
we want the reasoning to accommodate new systems and missions.
At the center of our reasoning engine is a general reasoner, bracketed by
system speciﬁc adapter logic. The input adapter takes alerts and turns them
into accusations. The general reasoner then uses these accusations to make
(cid:2) This research was funded by DARPA under Navy Contract No. N00178-07-C-2003.
R. Lippmann, E. Kirda, and A. Trachtenberg (Eds.): RAID 2008, LNCS 5230, pp. 408–410, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008
Anomaly and Speciﬁcation Based Cognitive Approach
409
hypotheses and passes claims and hypotheses to the output adapter where
they are evaluated in the mission context and may be acted upon.
Accusations are abstract alerts, expressive enough to enable a wide range
of responses while not overwhelming the reasoner with unnecessary distinctions.
Accusations come in ﬁve types: value (wrong data), omission, ﬂood, timing (right
message at the wrong time), and policy (not following a speciﬁcation). From
these accusations the reasoning engine generates four types of hypotheses, which
are potential explanations of the accusation: dead host, corrupt host, ﬂooded
host, or communication is broken between hosts. A single accusation may create
multiple hypotheses. For example, we assume that the sender may be corrupt
so accusing a host of not sending a reply creates a dead hypotheses about the
accused as well as a corrupt hypothesis about the accuser.
In order for a hypothesis to be acted upon, there needs to be suﬃcient sup-
port to turn that hypothesis into a claim. Claim selection relies upon four main
techniques: deductive reasoning, coherence search[1], mission knowledge, and
heuristic techniques. Deductive reasoning takes the current hypotheses and sys-
tem knowledge and attempts to logically prove hypotheses. Coherence search
takes multiple accusations, each supporting hypotheses, and aggregates the sup-
port. In this way a single source will likely not turn a hypothesis into a claim but
a collection of accusations may. Mission knowledge is used to include or exclude
some options. For example, if a host is corrupt but is critical to the mission a
reboot may initially be preferred to permanently blocking its network traﬃc.
Finally, we use heuristics to choose claims when the other techniques have failed
to come up with any workable claims but yet actions still need to be taken.
2 Evaluation
In May of 2008 our system was subjected to an external red-team evaluation. One
goal was to eﬀectively respond to 50% of attacks. Preliminary results delivered
immediately after the exercise showed 89% of the attacks were detected, and of
those detected, 69% were responded to eﬀectively. Additional analysis is ongoing.
3 Conclusion
Application of cognitive/knowledge based tools, especially in the area of spec-
iﬁcation and anomaly-based detection and response, at the mission level, is a
promising way to extend the reach of current intrusion detection technology and
enhance the overall accuracy of true detection. One issue, still left unresolved, is
the needed speed of cognitive processing component. Our goal was to respond
in 250ms. In some cases we achieved that target during evaluation, but in others
our reasoning took multiple seconds, a problem which needs further reﬁnement.
References
1. Freuder, E., Wallace, R.: Partial constraint satisfaction. Artiﬁcial Intelligence, spe-
cial issue on constraint-based reasoning 58(1-3), 21–70 (1992)