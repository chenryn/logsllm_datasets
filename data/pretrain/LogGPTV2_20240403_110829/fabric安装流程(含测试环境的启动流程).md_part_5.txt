KAFKA_ADVERTISED_HOST_NAME: kafka3
KAFKA_MIN_INSYNC_REPLICAS: 1
KAFKA_BROKER_ID: 3
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
KAFKA_MESSAGE_MAX_BYTES: 1048576
KAFKA_REPLICA_FETCH_MAX_BYTES: 1048576
KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE: \"false\"
KAFKA_LOG_RETENTION_MS: -1
KAFKA_ADVERTISED_PORT: 9092
KAFKA_ZOOKEEPER_CONNECT: kafka1:2181,kafka2:2181,kafka3:2181
volumes:
\- /opt/kafka/:/kafka
![](media/image54.png){width="7.25625in" height="1.0909722222222222in"}
restart :指定为always时，容器总是重新启动。
network_mode
：指定为host容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。
![](media/image55.png){width="7.261805555555555in"
height="2.9652777777777777in"}
如果启动不正常，请尝试以下措施：
1.  检查宿主机/etc/hosts 文件，此文件将被映射到容器里面，
2.  清空删除所有容器，重启宿主机docker，再执行第一步与第二步的的启动命令
    docker stop \$(docker ps -q) && docker rm \$(docker ps -qa)
    停止所有的容器，并删除
Kafka与zookeeper的关联：
前面zookeeper集群已启动，kafka与zookeeper的联系如下图：
![](media/image56.png){width="7.258333333333334in"
height="2.3381944444444445in"}
root@peer0:/opt/couchdb# find / -name \"default.ini\"
#容器中couchdb的配置文件
/opt/couchdb/etc/default.ini
root@zoo2:/zookeeper-3.4.9# find / -name \"zoo.cfg\"
/conf/zoo.cfg #容器中zoo的配置文件
root@zoo2:/conf# cat /data/myid #容器中zoo的myid文件
2
root@kafka3:/etc# find / -name \"server.properties\"
/opt/kafka/config/server.properties #容器中kafka的配置文件
## 第三步：启动orderer
启动:进入123的/etc/ansible目录执行如下命令
ansible-playbook fabric-orderer.yml
123上的/etc/ansible/fabric-orderer.yml文件内容如下：
\[root@localhost ansible\]# vim fabric-orderer.yml
\- hosts: peer0org1
remote_user: root
tasks:
\- name: mkdir ordererfile
file: state=directory path=/opt/app/fabric/orderer
\- name: mkdir peerfile
file: state=directory path=/opt/app/org1/peer
\- name: copy orderer File
copy: src=/opt/fabric-deploy/orderer.example.com/
dest=/opt/app/fabric/orderer/ mode=0755
\- name: bash orderer
shell: nohup ./orderer \>\> ./orderer.log 2\>&1 &
args:
chdir: /opt/app/fabric/orderer/
\- hosts: peer0org2
remote_user: root
tasks:
\- name: mkdir ordererfile
file: state=directory path=/opt/app/fabric/orderer
\- name: mkdir peerfile
file: state=directory path=/opt/app/{{item}}/peer
with_items:
\- org2
\- org3
\- name: copy orderer File
copy: src=/opt/fabric-deploy/orderer2.example.com/
dest=/opt/app/fabric/orderer/ mode=0755
\- name: bash orderer
shell: nohup ./orderer \>\> ./orderer.log 2\>&1 &
args:
chdir: /opt/app/fabric/orderer/
\- hosts: peer1org1
remote_user: root
tasks:
\- name: mkdir ordererfile
file: state=directory path=/opt/app/fabric/orderer
\- name: mkdir peerfile
file: state=directory path=/opt/app/{{item}}/peer
with_items:
\- org1
\- org2
\- org3
\- name: copy orderer File
copy: src=/opt/fabric-deploy/orderer3.example.com/
dest=/opt/app/fabric/orderer/ mode=0755
\- name: bash orderer
shell: nohup ./orderer \>\> ./orderer.log 2\>&1 &
args:
chdir: /opt/app/fabric/orderer/
由以上可知orderer情况为：
Peer0org1主机(107)上有：orderer.example.com org1目录
Peer0org2主机(100)上有：orderer2.example.com org2、org3目录
Peer1org1主机(104)上有：orderer3.example.com org1、org2、org3目录
Orderer端口为：
Peer0org1：192.168.10.107 orderer端口为：6050
Peer0org2：192.168.10.100 orderer2端口为：7050
Peer1org1：192.168.10.104 orderer3端口为：8050
## 第四步：启动peer
启动:进入123的/etc/ansible目录执行如下命令
ansible-playbook fabric-peer.yml
123上的/etc/ansible/fabric-peer.yml 文件内容如下：
\[root@localhost ansible\]# vim fabric-peer.yml
\- hosts: peer0org1
remote_user: root
tasks:
\- name: copy peer File
copy: src=/opt/fabric-deploy/peer0.org1.example.com/
dest=/opt/app/org1/peer/ mode=0755
\- name: bash peer
shell: nohup ./peer node start \>\> ./peer.log 2\>&1 &
args:
chdir: /opt/app/org1/peer/
\- hosts: peer0org2
remote_user: root
tasks:
\- name: copy org2 File
copy: src=/opt/fabric-deploy/peer0.org2.example.com/
dest=/opt/app/org2/peer/ mode=0755
\- name: bash peer
shell: nohup ./peer node start \>\> ./peer.log 2\>&1 &
args:
chdir: /opt/app/org2/peer/
\- name: copy org3 File
copy: src=/opt/fabric-deploy/peer0.org3.example.com/
dest=/opt/app/org3/peer/ mode=0755
\- name: bash peer
shell: nohup ./peer node start \>\> ./peer.log 2\>&1 &
args:
chdir: /opt/app/org3/peer/
\- hosts: peer1org1
remote_user: root
tasks:
\- name: copy org1 File
copy: src=/opt/fabric-deploy/peer1.org1.example.com/
dest=/opt/app/org1/peer/ mode=0755
\- name: bash peer
shell: nohup ./peer node start \>\> ./peer.log 2\>&1 &
args:
chdir: /opt/app/org1/peer/
\- name: copy org2 File
copy: src=/opt/fabric-deploy/peer1.org2.example.com/
dest=/opt/app/org2/peer/ mode=0755
\- name: bash peer
shell: nohup ./peer node start \>\> ./peer.log 2\>&1 &
args:
chdir: /opt/app/org2/peer/
\- name: copy org3 File
copy: src=/opt/fabric-deploy/peer1.org3.example.com/
dest=/opt/app/org3/peer/ mode=0755
\- name: bash peer
shell: nohup ./peer node start \>\> ./peer.log 2\>&1 &
args:
chdir: /opt/app/org3/peer/
由以上可知peer情况为：
Peer0org1主机(107)上有：peer0.org1.example.com
Peer0org2主机(100)上有：peer0.org2.example.com、peer0.org3.example.com
Peer1org1主机(104)上有：peer1.org1.example.com、peer1.org2.example.com、peer1.org3.example.com
## 服务端口汇总
peer0org1：192.168.10.232 （原环境的192.168.10.107）
couchdb：5984
zoo1：2181:3888
kafka1：9092
orderer.example.com：6050
peer0.org1.example.com：6051、chaincode:peer0.org1.example.com:6052
peer0org2：192.168.10.233 （原环境的192.168.10.100）
couchdb：5984
zoo3：2181:3888
kafka3：9092
orderer2.example.com：7050
peer0.org2.example.com：7051、chaincode:peer0.org2.example.com:7052
peer0.org3.example.com：8051、chaincode: peer0.org3.example.com:8052
peer1org1：192.168.10.234 （原环境的192.168.10.104）
couchdb：5984
zoo2：2181:3888
kafka2：9092
orderer3.example.com：8050
peer1.org1.example.com：6051、chaincode:peer1.org1.example.com:6052
peer1.org2.example.com：7051、chaincode: peer1.org2.example.com:7052
peer1.org3.example.com：8051、chaincode: peer1.org3.example.com:8052
在192.168.10.123上
## Explorer
/opt/postgresql/blockchain-explorer
![](media/image57.png){width="7.259722222222222in"
height="2.5395833333333333in"}
## Postgresql
本案例的
Postgresql配置：在/opt/postgresql/blockchain-explorer/app/explorerconfig.json
文件
![](media/image58.png){width="4.90625in" height="3.4166666666666665in"}
![](media/image59.png){width="7.261111111111111in"
height="3.3201388888888888in"}
\[root@localhost pgsql-9.6\]# pwd
/usr/pgsql-9.6
![](media/image60.png){width="7.258333333333334in" height="1.6in"}
![](media/image61.png){width="7.261111111111111in"
height="3.829861111111111in"}
### Postgresql命令：
安装完毕后，系统会创建一个数据库超级用户 postgres，密码为空。
psql -h \ -p\ -d \ -u \ #登陆数据库
\[root@localhost pgsql-9.6\]# su - postgres
-bash-4.2\$
-bash-4.2\$ psql -h 127.0.0.1 -U postgres
postgres=#
postgres=# \\q #退出pgsql
postgres=# select \* from current_user; #查看当前连接用户
postgres=# select user; #查看当前连接用户
postgres=# \\du #查看所有用户
postgres=# \\l #查看所有库 \\加上字母l,相当于mysql的，mysql\> show
databases;
postgres=# select pg_database_size(\'fabricexplorer\');
#查看fabricexplorer数据库大小
postgres=# select pg_database.datname,
pg_database_size(pg_database.datname) AS size from pg_database;
> #查看所有库大小
postgres=# \\c fabricexplorer #进入fabricexplorer库
fabricexplorer=# \\c owner ; #进入owner库
owner=# \\c fabricexplorer
fabricexplorer=# select \* from pg_tables where schemaname = \'public\';
#查看当前库所有的表
fabricexplorer=# \\d peer; #查看当前库中的peer表结构，相当于mysql的desc
peer;
fabricexplorer-# delete from channel where id=16;
#删除channel表中id=6的数据
fabricexplorer=# select \* from channel #删除之后查看数据，确认是否删除
fabricexplorer=# \\d #查看所有表包括sequence(序列)
fabricexplorer=# \\di #查看索引
fabricexplorer=# select spcname from pg_tablespace; #查看所有表空间
fabricexplorer=# select
pg_size_pretty(pg_tablespace_size(\'pg_default\'));
#查看pg_default表空间大小
fabricexplorer=# select
pg_size_pretty(pg_tablespace_size(\'pg_global\'));
#查看pg_global表空间大小
fabricexplorer=# select version(); #查看详细版本信息
fabricexplorer=# show server_version; #查看版本号
fabricexplorer=# SHOW server_version_num; #查看数字版本信息
fabricexplorer=# SELECT current_setting(\'server_version_num\');
#查看数字版本信息
fabricexplorer=# select \* from pg_stat_activity;
#查看PostgreSQL正在执行的SQL