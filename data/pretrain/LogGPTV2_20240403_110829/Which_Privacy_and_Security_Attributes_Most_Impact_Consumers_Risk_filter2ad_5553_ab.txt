devices [25]. They found that users’ lack of awareness impacts
their risk perception and they also observed a disparity between
risk perception and behaviors. Their ﬁndings are aligned with
other work in this space [19], [26].
B. Willingness to Purchase
Willingness to purchase is an indicator of actual purchase
behavior [27] and has been shown to have a high correlation
with it [28]–[30]. Researchers have identiﬁed a number of
factors impacting consumers’ purchase behavior including price,
features, perceived quality, brand, social media, word of mouth,
and usability [31]–[34].
Privacy is one of the concerns people have when participating
in e-commerce [35]–[37]. In a study by Tsai et al., availability
of accessible privacy information in search results encouraged
consumers to purchase from privacy-protective websites, despite
their higher prices [38]. Similarly, Kelly et al. found that
consumers will engage in more privacy-protective app-selection
behaviors when concise privacy information is available [39].
Labels are a common approach in contexts such as food [40]
and energy ratings [41], [42] to effectively communicate impor-
tant information to consumers. Despite their limitations [43],
[44], food nutrition labels have been shown to signiﬁcantly
inform consumers’ purchase decisions [45], [46]. In the privacy
context, Apple has recently required app developers to provide
information about the privacy practices of their apps. This
information is presented on a privacy label located in the app
store to help users make more informed app selection. [47]
Researchers have suggested that privacy and security labels
for smart devices could effectively inform consumers. Emami-
Naeini et al. conducted a small-scale qualitative study to explore
how IoT consumers would react to privacy and security labels
for smart devices. They found that consumers are generally
unable to ﬁnd privacy and security information for smart
devices they are considering purchasing and would be interested
in having privacy and security labels readily available [5].
Policymakers [7]–[10], [12], industry groups [48], [49], and
certiﬁcation bodies [50] have expressed interest in privacy and
security labels for IoT devices. However, there has been little
discussion of label format and content. Emami-Naeini et al.
took a ﬁrst step toward designing an informative IoT privacy
and security label by interviewing and surveying experts [13].
They speciﬁed 47 important factors and proposed a layered
label to present those factors.
In this study, we focused on consumers’ risk perception,
which often differs from that of experts [14]. We measured the
signiﬁcance of IoT privacy and security attributes identiﬁed
by Emami-Naeini et al. [13], along with factors previously
found to explain risk perception, including risk target [51]–
[53], familiarity with the technology [54], [55], and attitudes
and concerns [56], [57]. Speciﬁcally, we considered the device
recipient (e.g., purchase for self or for someone else) to evaluate
the risk target, checked whether participants owned that type
of device to gauge familiarity with the technology, and varied
the type of device to gauge the impact of concerns related to
the type of collected data.
III. METHOD
We conducted an online study in January 2020 on Amazon
Mechanical Turk (MTurk) with 1,710 participants (reduced
to 1,371 participants after ﬁltering the responses). In this
section, we discuss our study design, data analysis procedures,
and limitations. The study protocol was approved by our
Institutional Review Board (IRB).
A. Study Design
We designed our study with two between-subject factors—
the device type and the recipient of the device. We tested two
types of devices and three types of device recipients for a
total of six experimental conditions. Our within-subject factor
was the IoT-related privacy and security information conveyed
on the label. To mitigate survey fatigue [58] and keep the
completion time under 15 minutes, we randomly assigned each
participant to answer questions about only 3 of the 33 possible
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:26:35 UTC from IEEE Xplore.  Restrictions apply. 
520
pairs of attributes and their corresponding values, all associated
with one randomly assigned experimental condition. The survey
questions are provided in Appendix B.
1) Pilot Survey: Prior to launching the main study, we
piloted our survey on MTurk with 50 participants. We found
that more than half of the answers to open-ended questions
were irrelevant words such as “nice,” “good,” or “yes,” which
suggested that bots might be answering our survey [59]. We
signiﬁcantly improved the quality of the responses by adding
a Google reCAPTCHA question [60] at the beginning of the
survey to identify and eliminate bots.
2) Participant Recruitment and Compensation: We recruited
1,710 MTurk Master Workers from the United States who
were at least 18 years old and who had a HIT, i.e., Human
Intelligence Task, approval rate of at least 90%. We introduced
the survey as a study about behaviors and attitudes toward
smart devices. On average, it took participants 13 minutes to
answer the survey questions and we paid them each $2.50.
3) Survey Procedure: After presenting participants with
the consent form and CAPTCHA veriﬁcation, we asked
about participants’ concern level and purchase history for the
smart device that was assigned to their study condition. We
then presented each participant with three randomly assigned
hypothetical scenarios about the purchase of a smart device,
using the device type and recipient in their assigned condition.
Each purchase scenario included mention of a product label
with a single attribute-value pair, selected at random:
Imagine you are making a decision to purchase a
[device type] for [device recipient]. This device has
a [device sensor] that will [device data collection].
The price of the device is within your budget and
the features are all what you would expect from a
[device type]. On the package of the device, there is a
label that explains the privacy and security practices
of the [device type].
The label on the device indicates the following:
[attribute: value] (consumer explanation)
For each of the three scenarios, we asked participants how
the information on the label would change their risk perception
and their willingness to purchase, the reasons behind their
assessments, and a question to check whether they were paying
attention to the label. We then asked a question to capture
participants’ understanding of how their assigned smart device
collects data. We ended the survey with demographic questions.
4) Between-Subject Factors: We considered device type as
a between-subject factor and tested two types of devices. We
selected smart speakers (with a microphone that will listen and
respond to voice commands), which we hypothesized that most
participants would ﬁnd concerning [26], [61], and smart light
bulbs (with a presence sensor that detects whether someone is
present in the room to control the lighting automatically) that
we expected to be perceived as not concerning [5], [26].
Our other between-subject factor was the IoT device recipient.
We were interested in understanding whether participants have
different risk perceptions and desires to purchase based on
whom they are purchasing the device for. Hence, we tested
three conditions: Purchasing the device for oneself, gifting it
to a family member, or gifting it to a friend.
5) Concern Level and Purchase History: To test our
hypothesis on the assessed level of concern for the two tested
device types, we asked participants to specify how concerned
they were about the smart device collecting data and the reason
for their answer. If they currently have a smart device of that
type in their home, we then asked them when and how they
acquired their devices. If they did not have the smart device,
we asked them whether they had ever been in the market to
purchase it and if so, we asked them what made them decide
not to purchase it (see Appendix B-A).
6) Privacy and Security Label Attributes: Emami-Naeini
et al. speciﬁed 47 attributes to include on the label, of which
25 are directly related to privacy or security [13]. There were
two types of attributes on their label: 14 had enumerated
values and the rest had URL as their values. In our study,
we included 17 privacy and security attributes. We tested
the 14 proposed label attributes with enumerated values. In
addition, we selected 3 sub-attributes from Emami-Naeini et
al.’s proposed label [13] and combined them into an additional
“control” attribute. Finally, due to the importance of security
patches in IoT standards and guidelines [62]–[67], we also
included an attribute related to time-to-patch that was not part
of the proposed label.
Since Emami-Naeini et al. [13] did not enumerate all of
the attribute-values, we synthesized the possible values each
attribute might take from a review of IoT privacy and security
standards and guidelines. For each attribute, we identiﬁed
a value that we hypothesized to be perceived as the most
protective and one that we expected to be perceived as the
least protective to test in our study. For one of the attributes
(user controls), we considered three values; the proposed label
actually presents these as binary values associated with three
separate attributes (data stored on device, data stored on cloud,
and local data retention time). Out of these 33 attribute-value
pairs (shown in Table I), each participant answered questions
related to three randomly-selected attribute-value pairs, contex-
tualized with a hypothetical purchase scenario. We implemented
the scenario selection function so that participants’ assigned
attribute-value pairs would not include multiple pairs with the
same attribute. We provided a consumer-friendly explanation
next to each attribute-value pair (shown in Appendix C).
7) Questions About Each Scenario: To evaluate how well
participants believed that they understood the tested attribute-
value pairs and associated explanations, we asked them how
conﬁdent
the presented
information meant (see Appendix B-B).
they knew what
they were that
To understand participants’ risk perception, we asked them
to specify how the presented attribute-value changes the privacy
and security risks they associated with the device in question
(see Appendix B-B1). We then asked participants to explain
the reason behind their choice. We asked similar questions to
understand the impact of the privacy and security attributes on
changing participants’ willingness to purchase the device (see
Appendix B-B2).
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:26:35 UTC from IEEE Xplore.  Restrictions apply. 
521
Tested value
Most protective
Automatic
Multi-factor
authentication
Device function
None
None
None
None
Cloud data deletion
Device storage
Least protective
None
None
Monetization
Identiﬁed
Identiﬁed
Third parties
Third parties
Internal & external None
6 months
Layer Attribute
Security update
Access control
Purpose
Device storage
Cloud storage
Shared with
Sold to
Control over
y
r
a
m
i
r
P
y
r
a
d
n
o
c
e
S
Average time to patch 1 month
Security audit
Collection frequency On user demand
On user demand
Sharing frequency
None
Device retention
Cloud retention
None
None
Data linkage
Inference
None
Control over
Device retention
Continuous
Continuous
Indeﬁnite
Indeﬁnite
Internal & external
Characteristics and psychological traits,
attitudes and preferences,
aptitudes and abilities, and behaviors