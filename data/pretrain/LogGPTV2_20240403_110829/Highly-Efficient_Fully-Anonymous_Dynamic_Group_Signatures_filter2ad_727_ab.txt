Deﬁnition 10 (Correctness). A digital signature scheme Σ is correct, if for
all κ, all (sk, pk) ← KGen(1κ), and all m ∈ M it holds that Pr[Vrf(pk, m, Sign(sk,
m)) = 1] = 1.
Deﬁnition 11 (EUF-CMA). A digital signature scheme Σ is EUF-CMA secure,
if for all PPT adversaries A there is a negligible function (·) such that
(cid:21)
(cid:20) (sk, pk) ← KGen(1κ),
(m∗, σ∗) ← AOS(sk,·)
Pr
Vrf(pk, m∗, σ∗) = 1, ∧
m∗ /∈ QS
:
(pk)
≤ (κ) ,
where A has access to an oracle OS that allows to execute the Sign algorithm
and the environment keeps track of all message queried to OS via QS.
Public Key Encryption. We also require public key encryption, which we
recall below.
Deﬁnition 12 (Public Key Encryption). A public key encryption scheme Ω
consists of the following PPT algorithms:
KGen(1κ) : Takes a security parameter κ as input and outputs a secret decryption
key sk and a public encryption key pk (and we assume that the message space
M is implicit in pk).
Enc(pk, m) : Takes a public key pk and a message m ∈ M as input and outputs
a ciphertext c.
Dec(sk, c) : Takes a secret key sk and a ciphertext c as input and outputs a
message m ∈ M ∪ {⊥}.
We require a public key encryption scheme to be correct and IND-T secure.
Below we formally recall those notions.
Deﬁnition 13 (Correctness). A public key encryption scheme Ω is correct if
it holds for all κ, for all (sk, pk) ← KGen(1κ), and for all messages m ∈ M that
Pr[Dec(sk, Enc(pk, m)) = m] = 1.
Deﬁnition 14 (IND-T Security). Let T ∈ {CPA, CCA2}. A public key encryp-
tion scheme Ω is IND-T secure, if for all PPT adversaries A there exists a
negligible function (·) such that
(sk, pk) ← KGen(1κ),
(m0, m1, st) ← AOT(pk),
b ←R {0, 1}, c ← Enc(pk, mb),
b∗ ← AOT (c, st)
Pr
b = b∗ ∧
c /∈ QDec ∧ |m0| = |m1|
:
 ≤ 1/2 + (κ),
where the adversary runs in two stages, OT ← ∅ if T = CPA, and OT ←
{ODec(sk,·)} if T = CCA2. QDec denotes the list of queries to ODec and we set
QDec ← ∅ if T = CPA.
Non-Interactive Zero-Knowledge Proof Systems. Now, we recall a stan-
dard deﬁnition of non-interactive zero-knowledge proof systems. Therefore, let
LR be an NP-language with witness relation R : LR = {x | ∃ w : R(x, w) = 1}.
Deﬁnition 15 (Non-Interactive Zero-Knowledge Proof System). A non-
interactive proof system Π consists of the following PPT algorithms:
Setup(1κ) : Takes a security parameter κ as input, and outputs a common ref-
erence string crs.
Proof(crs, x, w) : Takes a common reference string crs, a statement x, and a
witness w as input, and outputs a proof π.
Vrf(crs, x, π) : Takes a common reference string crs, a statement x, and a proof
π as input, and outputs a bit b ∈ {0, 1}.
We require proof systems to be complete, sound, and zero-knowledge. Below, we
recall formal deﬁnition of those properties (adapted from [BGI14]).
Deﬁnition 16 (Completeness). A non-interactive proof system Π is com-
plete, if for every adversary A it holds that
(cid:20) crs ← Setup(1κ), (x, w) ← A(crs),
Pr
π ← Proof(crs, x, w)
(cid:21)
:
Vrf(crs, x, π) = 1
∨ (x, w) /∈ R
≈ 1.
Deﬁnition 17 (Soundness). A non-interactive proof system Π is sound, if for
every PPT adversary A there is a negligible function (·) such that
Pr(cid:2) crs ← Setup(1κ), (x, π) ← A(crs) : Vrf(crs, x, π) = 1 ∧ x /∈ LR
(cid:3) ≤ (κ).
If we quantify over all adversaries A and require  = 0, we have perfect soundness,
but we present the deﬁnition for computationally sound proofs (arguments).
Deﬁnition 18 (Adaptive Zero-Knowledge). A non-interactive proof system
Π is adaptively zero-knowledge, if there exists a PPT simulator S = (S1,S2)
such that for every PPT adversary A there is a negligible function (·) such that
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) Pr(cid:2)crs ← Setup(1κ) : AP(crs,·,·)(crs) = 1(cid:3) −
Pr(cid:2)(crs, τ ) ← S1(1κ) : AS(crs,τ,·,·)(crs) = 1(cid:3)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ (κ),
where, τ denotes a simulation trapdoor. Thereby, P and S return ⊥ if (x, w) /∈ R
or π ← Proof(crs, x, w) and π ← S2(crs, τ, x), respectively, otherwise.
Signatures of Knowledge. Below we recall signatures of knowledge (SoKs)
[CL06], where LR is as above. For the formal notions we follow [BCC+15]
and use a stronger generalization of the original extraction property termed
f -extractability. A signature of knowledge (SoK) for LR is deﬁned as follows.
Deﬁnition 19 (Signatures of Knowledge). A SoK consists of the following
PPT algorithms:
Setup(1κ) : Takes a security parameter κ as input and outputs a common refer-
ence string crs. The message space M is implicitly deﬁned by crs.
Sign(crs, x, w, m) : Takes a common reference string crs, a word x, a witness w,
and a message m as input and outputs a signature σ.
Vrf(crs, x, m, σ) : Takes a common reference string crs, a word x, a message m,
and a signature σ as input and outputs a bit b ∈ {0, 1}.
We require signatures of knowledge to be correct, simulatable and f -extractable.
We formally recall those notions below.
Deﬁnition 20 (Correctness). A SoK w.r.t. LR is correct, if there exists a
negligible function (·) such that for all x ∈ LR, for all w such that (x, w) ∈ R,
and for all m ∈ M it holds that
Pr(cid:2) crs ← Setup(1κ), σ ← Sign(crs, x, w, m) : Vrf(crs, x, m, σ) = 1(cid:3) ≥ 1 − (κ).
Deﬁnition 21 (Simulatability). A SoK w.r.t. LR is simulatable, if there ex-
ists a PPT simulator S = (SSetup, SimSign) such that for all PPT adversaries
A there exists a negligible function (·) such that it holds that
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) Pr(cid:2)crs ← Setup(1κ), ASign(crs,·,·,·)(crs) = 1(cid:3) −
Pr(cid:2)(crs, τ ) ← SSetup(1κ), ASim(crs,τ,·,·,·)(crs) = 1(cid:3)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ (κ),
where Sim(crs, τ, x, w, m) := SimSign(crs, τ, x, m) and Sim only responds if (x, w) ∈
R.
Deﬁnition 22 (f -Extractability). A SoK w.r.t. LR is f -extractable, if in ad-
dition to S there exists a PPT extractor Extract, such that for all PPT adver-
saries A there exists a negligible function (·) such that it holds that
 (crs, τ ) ← SSetup(1κ),
(x, m, σ) ← ASim(crs,τ,·,·,·)(crs),
y ← Extract(crs, τ, x, m, σ)
Pr
Vrf(crs, x, m, σ) = 0 ∨
(x, m, σ) ∈ QSim ∨
(∃ w : (x, w) ∈ R ∧
y = f (w))
:
 ≥ 1 − (κ),
where QSim denotes the queries (resp. answers) of Sim.
We note that, as illustrated in [BCC+15], this notion is a generalization of the
original extractability notion from [CL06] which implies the original extractabil-
ity notion if f is the identity. In this case, we simply call the f -extractability
property extractability. Analogous to [BCC+15], we require the used SoK to be
at the same time extractable and straight-line f -extractable with respect to some
f other than the identity, where straight-line as usual says that the extractor
runs without rewinding the adversary [Fis05].
3 Dynamic Group Signatures
Subsequently, we recall the established model for dynamic group signatures. We
follow Bellare et al. [BSZ05] (BSZ model), with the slight diﬀerence that we
relax the perfect correctness to only require computational correctness. Further-
more, we also present the weaker anonymity notion of CPA-full anonymity from
[BBS04] and the notion of opening soundness [SSE+12], which addresses issues
regarding hijacking of signatures by malicious group members. In particular, we
use the notion of weak opening soundness, where the opening authority is re-
quired to be honest, since we believe that this notion provides a good tradeoﬀ
between computational eﬃciency of potential instantiations and expected secu-
rity guarantees (even the authors of [SSE+12] say that weak opening soundness
already addresses the attacks they had in mind).
GKGen(1κ) : Takes a security parameter κ as input and outputs a triple (gpk, ik,
ok) containing the group public key gpk, the issuing key ik as well as the opening
key ok.
UKGen(1κ) : Takes a security parameter κ as input and outputs a user key pair
(uski, upki).
Join(gpk, uski, upki) : Takes the group public key gpk and the user’s key pair
(uski, upki) as input. It interacts with the Issue algorithm and outputs the
group signing key gski of user i on success.
Issue(gpk, ik, i, upki, reg) : Takes the group public key gpk, the issuing key ik, the
index i of a user, user i’s public key upki, and the registration table reg as
input. It interacts with the Join algorithm and adds an entry for user i in reg
on success. In the end, it returns reg.
Sign(gpk, gski, m) : Takes the group public key gpk, a group signing key gski,
and a message m as input and outputs a group signature σ.
Vrf(gpk, m, σ) : Takes the group public key gpk, a message m and a signature σ
as input and outputs a bit b ∈ {0, 1}.
Open(gpk, ok, reg, m, σ) : Takes the group public key gpk, the opening key ok,
the registration table reg, a message m, and a valid signature σ on m under
gpk as input. It extracts the identity of the signer and returns a pair (i, τ ),
where τ is a proof.
Judge(gpk, m, σ, i, upki, τ ) : Takes the group public key gpk, a message m, a valid
signature σ on m under gpk, an index i, user i’s public key upki, and a proof
τ . It returns a bit b ∈ {0, 1}.
Oracles. In the following we recall the deﬁnitions of the oracles required by the
security model. We assume that the keys (gpk, ik, ok) created in the experiments
are implicitly available to the oracles. Furthermore, the environment maintains
the sets HU, CU of honest and corrupted users, the set GS of message-signature
tuples returned by the challenge oracle, the lists upk, usk, gsk of user public keys,
user private keys, and group signing keys. The list upk is publicly readable and
the environment also maintains the registration table reg. Finally, SI represents
a list that ensures the consistency of subsequent calls to CrptU and SndToI. All
sets are initially empty and all list entries are initially set to ⊥. In the context
of lists, we use upki, uski, etc. as shorthand for upk[i], usk[i], etc.
AddU(i) : Takes an index i as input. If i ∈ CU ∪ HU it returns ⊥. Otherwise it
runs (uski, upki) ← UKGen(1κ) and (reg, gski) ←
(cid:104)Issue(gpk, ik, i, upki, reg) ↔ Join(gpk, uski, upki)(cid:105).
Finally, it sets HU ← HU ∪ {i} and returns upki.
CrptU(i, upkj) : Takes an index i and user public key upkj as input. If i ∈ CU∪HU
it returns ⊥. Otherwise it sets CU ← CU ∪ {i}, SI[i] ← (cid:62) and upki ← upkj.
SndToI(i) : Takes an index i as input. If SI[i] (cid:54)= (cid:62) it returns ⊥. Otherwise, it
plays the role of an honest issuer when interacting with the corrupted user i.
More precisely, it runs reg ← (cid:104)Issue(gpk, ik, i, upki, reg) ↔ A(cid:105). In the end it sets
SI[i] ← ⊥.
SndToU(i) : Takes an index i as input. If i /∈ HU it sets HU ← HU ∪ {i}, runs
(uski, upki) ← UKGen(1κ). Then it plays the role of the honest user i when
interacting with a corrupted issuer. More precisely, it runs gski ← (cid:104)A ↔
Join(gpk, uski, upki)(cid:105).
USK(i) : Takes an index i as input and returns (gski, uski).
RReg(i) : Takes an index i as input and returns regi.
WReg(i, ρ) : Takes an index i and a registration table entry ρ as input and sets
regi ← ρ.
GSig(i, m) : Takes an index i and a message m as input. If i /∈ HU or gski = ⊥ it
returns ⊥ and σ ← Sign(gpk, gski, m) otherwise.
Ch(b, i0, i1, m) : Takes a bit b, two indexes i0 and i1, and a message m as input.
If {i0, i1} (cid:54)⊆ HU ∨ gski0 = ⊥ ∨ gski1 = ⊥ it returns ⊥. Otherwise, it computes
σ ← Sign(gpk, gskib
Open(m, σ) : Takes a message m and a signature σ as input. If (m, σ) ∈ GS or
Vrf(gpk, m, σ) = 0 it returns ⊥. Otherwise, it returns (i, τ ) ← Open(gpk, ok,
reg, m, σ).
, m), sets GS ← GS ∪ {(m, σ)} and returns σ.
Security Notions. We require dynamic group signatures to be correct, anony-
mous, traceable, non-frameable, and weakly opening sound. Correctness, requires
that everything works correctly if everyone behaves honestly. Note that we relax
perfect correctness to computational correctness.
Deﬁnition 23 (Correctness). A GSS is correct, if for all PPT adversaries A
there is a negligible function (·) such that
(gpk, ik, ok) ← GKGen(1κ),
O ← {AddU(·), RReg(·)},
(i, m) ← AO(gpk),
σ ← Sign(gpk, gski, m),
(j, τ ) ← Open(gpk, ok, reg, m, σ)
Vrf(gpk, m, σ) = 1 ∧ i ∈ HU
∧ gski (cid:54)= ⊥ ∧ i = j ∧
Judge(gpk, m, σ, i, upki, τ ) = 1
:
 ≥ 1−(κ).
Anonymity captures the intuition that group signers remain anonymous for ev-
eryone except the opening authority. Thereby, the adversary can see arbitrary
key exposures. Furthermore, in the CCA2 case the adversary can even request
arbitrary openings of other group signatures.
Deﬁnition 24 (T-Full Anonymity). Let T ∈ {CPA, CCA2}. A GSS is T-fully
anonymous, if for all PPT adversaries A there is a negligible function (·) such
that
Pr
where
OT ←
b ←R {0, 1}, b∗ ← AOT (gpk, ik)
(cid:20) (gpk, ik, ok) ← GKGen(1κ),
: b = b∗(cid:21)
(cid:27)
(cid:26) Ch(b,·,·,·), SndToU(·), WReg(·,·),
(cid:27)
(cid:26) Ch(b,·,·,·), Open(·,·), SndToU(·),
WReg(·,·), USK(·), CrptU(·,·)
USK(·), CrptU(·,·)
≤ 1/2 + (κ),
if T = CPA, and
if T = CCA2.
Traceability models the requirement that, as long as the issuer behaves honestly
and its secret key remains secret, every valid signature can be traced back to a
user. This must even hold if the opening authority colludes with malicious users.
Pr
Pr
Deﬁnition 25 (Traceability). A GSS is traceable, if for all PPT adversaries
A there is a negligible function (·) such that
(gpk, ik, ok) ← GKGen(1κ),
O ← {SndToI(·), AddU(·),
RReg(·), USK(·), CrptU(·)},
(m, σ) ← AO(gpk, ok),
(i, τ ) ← Open(gpk, ok, reg, m, σ)
Vrf(gpk, m, σ) = 1 ∧
(i = ⊥ ∨
Judge(gpk, m, σ, i, upki, τ ) = 0)
:
 ≤ (κ).
Non-frameability requires that no one can forge signatures for honest users.
This must even hold if the issuing authority, the opening authority, and, other
malicious users collude.
Deﬁnition 26 (Non-Frameability). A GSS is non-frameable, if for all PPT
adversaries A there is a negligible function (·) such that
 (gpk, ik, ok) ← GKGen(1κ),
O ← {SndToU(·), WReg(·,·),
GSig(·,·), USK(·), CrptU(·)},
(m, σ, i, τ ) ← AO(gpk, ok, ik)
Pr
Vrf(gpk, m, σ) = 1 ∧
i ∈ HU ∧ gski (cid:54)= ⊥ ∧
i /∈ USK ∧ (i, m) /∈ SIG ∧
Judge(gpk, m, σ, i, upki, τ ) = 1
:
 ≤ (κ),
where USK and SIG denote the queries to the oracles USK and Sign, respectively.
Weak opening soundness [SSE+12] essentially requires that no malicious user
can claim ownership of a signature issued by an honest user, as long as the
opening authority behaves honestly.
Deﬁnition 27 (Weak Opening Soundness). A GSS is weakly opening sound,
if for all PPT adversaries A there is a negligible function (·) such that
Pr
(gpk, ik, ok) ← GKGen(1κ),
O ← {AddU(·)},
(m, i, j, st) ← AO(gpk),
σ ← Sign(gpk, gski, m),
τ ← AO(st, σ, gskj)
i (cid:54)= j ∧ {i, j} ⊆ HU ∧
Judge(gpk, m, σ, j, upkj, τ ) = 1
:
 ≤ (κ).
4 Construction
Our idea is inspired by [HS14], who use the “unlinkability” feature of SPS-EQ
signatures to construct anonymous credentials. Essentially, a credential in their
approach represents a signature for an equivalence class and to show a credential
they always present a newly re-randomized signature to a random representative
of this class. While, due to the intuitive relation of anonymous credentials and
group signatures, it might seem straightforward to map this idea to group sig-
natures, it turns out that there are various subtle, yet challenging issues which
we need to solve.
First, the anonymity notion is much stronger than the one of anonymous
credentials (see, e.g., [FHS18]) in that it does not put many restrictions on the
Ch and the USK oracles. In particular, Ch can be called an arbitrary number
of times and USK can be called for all users. Thus, the user secret keys must
be of a form so that it is possible to embed decision problem instances into
them upon simulation, while not inﬂuencing their distribution (as the adversary
sees those keys and would be able to detect the simulation otherwise). More
precisely, anonymity in our paradigm seems to require that the user keys contain
no Zp elements, which, in turn, renders the non-frameability proof more diﬃcult.
Second, if CCA2-full anonymity is required, the simulatability of the open oracle
needs to be ensured, while the reduction must not be aware of the opening
information (as otherwise the reduction could trivially break anonymity on its
own and would be meaningless). This seems to crucially require a proof system
providing rather strong extractability properties. To maintain eﬃciency, it is
important to ﬁnd the mildest possible requirement which still allows the security
proofs to work out. Third, the non-frameability adversary is given the issuing
key as well as the opening key. Thus, the reduction must be able to simulate
the whole join process without knowledge of a user secret key in a way that the
distribution change is not even detectable with the knowledge of these keys.
Now, before we present our full construction, we brieﬂy revisit our basic
idea. In our scheme, each group member chooses a secret vector (R, P ) ∈ (G∗
1)2
representing an equivalence class where the second component P is identical for
all users. When joining the group, a blinded version q · (R, P ) with q ←R Z∗
p of
this vector, i.e., another representative of the class, is signed by the issuer using
an SPS-EQ, and, by the re-randomization property of SPS-EQ and the feature to
publicly change representatives of classes, the user thus obtains a signature on
the unblinded key (R, P ) using ChgRepR with q−1. To provide a means to open
signatures, a user additionally has to provide an encryption of a value ˆR ∈ G2
such that e(R, ˆP ) = e(P, ˆR) on joining (and has to sign the ciphertext as an
identity proof). The group signing key of the user is then the pair consisting of
the vector (R, P ) and the SPS-EQ signature on this vector. A group member
can sign a message m on behalf of the group by randomizing its group signing
key and computing a signature of knowledge (SoK) to the message m proving
knowledge of the used randomizer.4 The group signature is then the randomized
group signing key and the SoK.
Very roughly, a signer remains anonymous since it is infeasible to distinguish
two randomized user secret keys under DDH in G1. The unforgeability of SPS-EQ
ensures that each valid signature can be opened. Furthermore, it is hard to forge
signatures of honest group members since it is hard to unblind a user secret key
under co-CDHI and the signature of knowledge essentially ensures that we can
extract such an unblinded user secret key from a successful adversary.
Detailed Construction. We require zero-knowledge proofs upon Join and
Open. The NP relation RJ corresponding to the proof carried out in Join is
deﬁned as