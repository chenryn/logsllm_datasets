### 代码提交状态及应对策略

- **Accepted**：表示用户提交的代码已被接受。这意味着代码能够正确运行，并且在以平台提供的测试数据作为输入时，其输出结果与标准输出完全一致。然而，需要注意的是，由于MapReduce编程框架的特点，尽管某些题目可以在Map或Reduce阶段独立完成，但这种做法未能充分利用MapReduce并行处理的优势。因此，即使代码被接受，用户也应检查其是否充分实现了并行化，以优化执行效率。

- **Compile Error**：表明用户代码存在语法错误，导致编译失败。用户可通过点击结果栏中的错误链接查看具体错误位置，并据此修改代码。此外，建议先在本地进行Java程序的编译测试，确保无误后再提交至平台。

- **MapReduce Error**：指代码在Hadoop环境中运行时遇到问题而无法产生预期输出。此类错误可能由多种因素引起，如常见的Java逻辑错误（数组越界、变量未初始化等）或MapReduce特有的逻辑问题（例如输入/输出类型不匹配）。面对这种情况，用户需仔细审查代码逻辑，定位并修正错误后重新尝试提交。

- **Wrong Answer**：意味着代码虽然能正常运行并生成输出，但该输出与期望的结果不符。此时，用户首先应该检查输出格式是否符合要求（比如顺序），然后确认结果完整性，最后排查是否存在逻辑上的缺陷。

- **Runtime Error**：表示代码执行超时，可能是由于死循环或系统负载过高所致。解决方法包括查找并移除潜在的无限循环，并选择系统资源较为充裕的时间段再次提交任务。

- **Memory Exceed**：说明程序运行期间消耗了过多内存资源。用户需要检查代码中是否有不必要的大量内存使用情况，特别是在主函数内；若是在MapReduce过程中出现类似问题，则会直接报错为“MapReduce Error”。

- **Evil Code**：检测到用户提交的代码中含有恶意行为，如试图调用系统命令或修改服务器配置。遇到此类警告时，务必彻底清理掉所有非必要的以及有害的代码片段。

- **Sim Code**：当提交的代码与其他已知样本高度相似时触发，暗示可能存在抄袭行为。平台将自动发送邮件通知相关方，并附带疑似雷同的两份代码供比对核实。

### 使用注意事项

- **主类命名规则**：为了保证一致性，所有Java程序的主类名必须设为`MyMapre`，以便通过统一的Shell脚本将其传递给Hadoop执行。
  
- **输入输出配置**：无论是采用旧API还是新API，都需要严格遵循指定的方式设置文件路径：
  - 旧API:
    ```java
    FileInputFormat.setInputPaths(conf, new Path(args[0]));
    FileOutputFormat.setOutputPath(conf, new Path(args[1]));
    ```
  - 新API:
    ```java
    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
    ```

- **单一源文件限制**：整个MapReduce应用程序必须封装在一个Java源文件内，不允许跨多个文件引用其他类定义。

- **并发任务数量控制**：鉴于系统资源有限，请避免同时提交多个作业以免造成过度占用。对于小规模数据处理任务，即使是简单的WordCount也可能耗时较长。

### Hadoop安装指南

#### JDK安装步骤

1. 从Oracle官网下载适用于Linux系统的JDK安装包。
2. 赋予下载文件执行权限并运行安装脚本。
3. 编辑环境变量配置文件`/etc/profile`，添加如下内容：
   ```bash
   # set Java Environment
   export JAVA_HOME=/usr/lib/jvm/jdk
   export CLASSPATH=".:$JAVA_HOME/lib:$CLASSPATH"
   export PATH="$JAVA_HOME/bin:$PATH"
   ```
4. 验证JDK版本信息，确保安装成功。
5. 将当前JDK设置为默认版本。

#### SSH服务安装

- 检查SSH服务状态，如果未安装则通过`apt-get`工具进行安装。
- 生成公钥并将其添加到授权密钥列表中，实现免密码登录功能。

#### Hadoop集群部署

- 单节点模式无需特别配置即可运行。
- 对于伪分布式模式，需调整几个核心配置文件（`hadoop-env.sh`, `core-site.xml`, `hdfs-site.xml`, `mapred-site.xml`），设定正确的主机名、端口号等参数。
- 构建多节点集群时还需额外设置每台机器间的信任关系，确保NameNode可以无阻碍地与DataNodes通信。