the average specified by the designer. This function is used when QoS estimates are
needed and no runtime QoS information is available. The second function calculates the
average of dimension Dim metrics for task t, based on all task t executions, independently
114
of the workflow that has executed it. The third function calculates the average of a task t
dimension Dim, based on all the times task t was executed in any instance from workflow
w. Finally, the last function (d) calculates the average of the dimensionD im of all the task
t executions, from instance i of workflow w. This scenario can only occur when loops
exist in a workflow, and they often do.
Table 3-2 – Designer, multi-workflow, workflow and instance average
Function Description
a) Designer Average (t) Average specified by the designer in the basic
Dim
class for dimension Dim.
b) Multi-Workflow Average (t) Computes the average of the dimension Dim of
Dim
all the executions of task t.
c) Workflow Average (t, w) Computes the average of the dimension Dim of
Dim
all the executions of task t in any instance of
workflow w.
d) Instance Average (t, w, i) Computes the average of the dimension Dim of
Dim
all the executions of task t in instances i of
workflow w.
Similar to the functions used to compute averages as shown in Table 3-2 we also
support functions to compute the minimum and maximum for QoS dimensions .
QoS Model Construction
The QoS Model Construction component uses the information computed in the statistical
computation component and applies the functions presented in Table 3-3 in order to re-
115
compute a QoS model for tasks. The weights wi are set manually, and they reflect the
j
degree of correlation between the workflow under analysis and other workflows for
which a set of common tasks is shared.
Table 3-3 – QoS dimensions re-computed at runtime
a) QoS (t) Designer Average (t)
Dim Dim
b) QoS (t) wi * Designer Average (t) + wi * Multi-Workflow
Dim 1 Dim 2
Average (t)
Dim
c) QoS (t, w) wi * Designer Average (t) + wi * Multi-Workflow
Dim 1 Dim 2
Average (t) + wi * Workflow Average (t, w)
Dim 3 Dim
d) QoS (t, w, i) wi * Designer Average (t) + wi * Multi-Workflow
Dim 1 Dim 2
Average (t) + wi * Workflow Average (t, w) + wi *
Dim 3 Dim 4
Instance Workflow Average (t, w, i)
Dim
Let us assume that we have an instance i of workflow w running, and we desire to
predict the QoS of task t˛ w. The following rules are used to choose which formula to
apply when predicting QoS. If task t has never been executed before, then formula a) is
chosen to predict the task QoS, since there is no other data available. If task t has been
executed previously, but in the context of workflow w , and w != w , then formula b) is
n n
chosen. In this case we assume that the execution of t in workflow w will give a good
n
indication of its behavior in workflow w. If task t has been previously executed in the
context of workflow w, but not from instance i, then formula c) is chosen. Finally, if task
thas been previously executed in the context of workflow w, and instance i, meaning that
a loop has been executed, then formula d) is used.
116
The method used to re-compute transitions’ probability follows the same lines as for
the method used to re-compute tasks’ QoS. When a workflow has never been executed,
the values for the transitions are obviously taken from initial designer specifications, the
only information available. When instances of a workfloww have already been executed,
then the data used to re-compute the probabilities come from initial designer
specifications for workflow w and from the executed instances.
Figure 3-6 shows the graphical user interface available to set the QoS functions and
their associated weights, and to visualize the QoS estimates automatically computed for
workflows, instances, tasks, and transitions. The QoS computation is carried out using the
SWR algorithm (see section 3.8).
117
Figure 3-6 – The GUI to calculate QoS estimates
118
3.5.4 WORKFLOW REPOSITORY SERVICE
Our workflow builder is coupled with a repository. The repository is responsible for
maintaining information about workflow definitions and asosciated workflow
applications. The repository tool allows users to retrieve, update, and store workflow
definitions (Song 2001). A user can browse the contents of the repository and find
already existing workflow definitions fragments (either sub-workflows or individual
tasks) to be incorporated into a workflow being created. The repository service is also
available to the enactment service; it provides the necessary information about a
workflow application to be started. The repository supplies a practical and efficient
access to workflow definitions, based on queries. In order to query and search the
repository based on QoS requirements the repository needs to be extended. This
functionality is useful since it allows users to find tasks with specific QoS metrics when
composing workflows with initial QoS requirements, such as low cost or high
availability. While we have not implemented this feature yet, we consider it indispensable
for QoS based workflow composition; and will support it in a future version of this
system.
3.6 WORKFLOW QOS ANALYSIS AND SIMULATION
Having made a graphical (abstract) representation of an organizational process model, a
workflow contains information which can be used as a basis for analysis. The analysis
focuses on workflow topology (tasks and transitions) and on the QoS metrics. Analyzing
workflows allows us to gather information about workflow QoS metrics, which include
processing time, delay time, cost, fidelity, and reliability. The QoS information makes
workflow structures more transparent and quantifiable, allowing inefficiencies and
performance problems such as bottlenecks, to be found.
We describe two methods that the builder can use to compute QoS metrics for a
given workflow process: mathematical modeling and simulation modeling. The selection
119
of the method is based on a tradeoff between time and the accuracy of results. The
mathematical method is computationally faster, but yields results which may not be as
accurate as the ones obtained with simulation. Workflow modeling is a continuous
activity, where processes are continuously improved to increase efficiency and meet
organizational goals and strategies.
3.6.1 MATHEMATICAL MODELING
Comprehensive solutions to the challenges encountered in synthesizing QoS for
composite services have been discussed in detail (Cardoso, Miller et al. 2002). We have
developed a stochastic workflow reduction algorithm (SWR) for step-by-step
computation of aggregate QoS properties. The code, examples, and documentation for the
algorithm can be found in Cardoso (2002). At each step a reduction rule is applied to
shrink the workflow. Also at each step, the response time (T), cost (C), fidelity (F) and
reliability (R) of the tasks involved is computed. Additional task metrics can also be
individually computed, such as task queuing time and setup time. The reduction process
is continued until only one atomic task (Kochut, Sheth et al. 1999) is left in a workflow.
When this state is reached, the remaining task contains the QoS metrics corresponding to
the workflow under analysis. The set of reduction rules that can be applied to a composite
service (i.e., workflow) corresponds to the set of inverse operations that can be used to
construct a workflow of services. We have decided to allow only the construction of
workflows based on a set of predefined construction rules to protect users from designing
invalid workflows. Invalid workflows contain design errors, such as non-termination,
deadlocks, and the split of instances (Aalst 1999). To compute QoS metrics, we use a set
of six distinct reduction rules: (1) sequential, (2) parallel, (3) conditional, (4) faul-t
tolerant, (5) loop, and (6) network. As an illustration, we will show how reduction works
for a parallel system of tasks.
120
Reduction of a Parallel System. Figure 3-7 illustrates how a system of parallel tasks t ,
1
t , …, t , an and-split task t , and an and-join task t can be reduced to a sequence of three
2 n a b
tasks t , t , and t . In this reduction the incoming transitions of t and the outgoing
a 1n b a
transitions of tasks t remain the same. The only outgoing transitions from task t and the
b a
only incoming transitions from task t are the ones shown in the figure. In a parallel
b
system, the probabilities of p , p ,…, p and p , p ,…, p are equal to 1.
a1 a2 1n 1b 2b nb
t
1 p
p 1b
a1
p p p p
t * a2 t 2b * t t 1n t b t
a 2 b a 1n b
p an p nb
t
n
(a) (b)
Figure 3-7 - Parallel system reduction
After applying the reduction, the QoS of tasks t and t remain unchanged, and
a b
p = p = 1. To compute the QoS for this reduction the following formulae are applied:
1n b
T(t 1n) = Max i˛ 1£ i£ n {T(t i)}
(cid:229)
C(t ) = C(t)
1n i
1£ i£ .n
(cid:213)
R(t ) = R(t)
1n i
1£ i£ .n
F(t ).a = f(F(t ), F(t ), …, F(t ))
1n r 1 2 n
When a workflow needs to be analyzed, the builder converts the workflow data
structure supported by the builder to one supported by the SWR algorithm. Once a
workflow is in a suitable data format and each task has their QoS metrics and transition
121
probabilities computed, it is transferred to the SWR algorithm. The algorithm outputs a
single atomic task which contains the QoS metrics corresponding to the input workflow .
3.6.2 SIMULATION MODELS
While mathematical methods can be effectively used, another alternative is to utilize
simulation analysis (Miller, Cardoso et al. 2002). Simulation can play an important role
in fine-tuning tuning the quality of service metrics of workflows, by exploring “wha-tif"
questions. When the need to adapt or to change a workflow is detected, deciding what
changes to carry out can be very difficult. Before a change is actually made, its possible
effects can be explored with simulation. To facilitate rapid feedback, the workflow
system and the simulation system need to interoperate. In particular, workflow
specification documents need to be translated into simulation model specification
documents so that the new model can be executed/animated on-the-fly.
In our project, these capabilities involve a loosely-coupled integration of the
METEOR WfMS and the JSIM simulation system (Nair, Miller et al. 1996; Miller, Nair
et al. 1997; Miller, Seila et al. 2000). Workflow is concerned with scheduling and
transformations that take place in tasks, while simulation is mainly concerned with
system performance. For modeling purposes, a workflow can be abstractly represented by
using directed graphs (e.g., one for control flow and one for data flow, or one for both).
Since both models are represented as directed graphs, interoperation is facilitated. In
order to carry out a simulation, the appropriate workflow model is retrieved from the
repository, and the distribution functions defined in the QoS distributional class (see
section 3.5.3.1) are used to create a JSIM simulation model specification. The simulaiton
model is displayed graphically and then executed/animated. Statistical results are
collected and displayed, indicating workflows QoS .
122
3.7 CONCLUSIONS
Organizations operating in global and competitive markets require a high level of quality
of service management. The use of workflow systems to automate, support, coordinate,
and manage business processes enables organizations to reduce costs and increase
efficiency. Workflow systems should be viewed as more than just automating or
mechanizing driving forces. They should be used to reshape and re-engineer the way
business is done. One way to achieve continuous process improvement is to view and
analyze processes from a QoS perspective. This allows workflows to be designed and
adapted according to quality of service constraints drawn from organizational goals and
strategies. A good management of QoS leads to the creation of quality products and
services, which in turn fulfills customer expectations and achieves customer satisfaction.
This becomes increasingly important when workflow systems are used in new
organizational and trading models, such as in virtual organizations and e-commerce
activities that span organizational boundaries.
While QoS management is of a high importance to organizations, current WfMSs
and workflow applications do not provide full solutions to support QoS. Two research
areas need to be explored. On one hand, a good theoretical QoS model is necessary to
formally specify, represent, and calculate QoS metrics. On the other hand, experimental
workflow systems need to be developed to identify the challenges and difficulties that the
implementation of QoS management faces. We have already developed a QoS theoretical
model, and in this paper we explain how the model was implemented in the METEOR
system.
The support of QoS management requires the modification and extension of most of
workflow system components. This includes the enactment system, the workflow builder
(or designer), the monitor, the code generator, the repository, the workflow model, and
the task model. Additionally, new components need to be implemented, such as a QoS
123
estimator module to create QoS estimates for tasks and probabilities for transitions. The
monitor needs an additional interface so that runtime tasks QoS metrics are propagated
and logged into a database for data processing purposes.
Algorithms and methods are necessary to predict overall workflow QoS metrics. For
this purpose, we present a mathematical model and explain how simulation can be used
to calculate and predict workflow QoS. Both approaches enable a predictive computation
of workflows QoS based on tasks QoS estimates. The mathematical method is
computationally faster, but yields results which may not be as precise as the ones
obtained with simulation. The choice of the method is based on a tradeoff between time
and the accuracy of results.
3.8 APPENDIX
The SWR (Stochastic Workflow Reduction) algorithm uses the set of reduction rules
presented in (Cardoso, Miller et al. 2002) to compute workflow QoS metrics. The
algorithm iteratively applies the reduction rules to a workflow until only one atomic task
remains. At each iteration, the response time (T), cost (C), reliability (R), and fidelity (F)
of the tasks involved is computed. Additional task metrics can also be computed, such as
task queue time and setup time. If at any point no more reduction rules can be applied and
the size of the workflow is greater than 1, then the initial workflow design was incorrect.
An outline of the algorithm is presented in Listing 3-1.
124
QoS SWR (workflow wf) begin
boolean changes = true;
while changes begin
changes = false;
forall task in wf and no changes begin
changes = applySequentialRule(wf, task);
if changes continue;
changes = applyParallelRule(wf, task);
if changes continue;
changes = applyConditionalRule(wf, task);
if changes continue;
change = applyBasicLoopRule(wf, task);
if changes continue;
change = applyDualLoopRule(wf, task);
if changes continue;
change = applyNetworkRule(wf, task);
if changes continue;
end forall
end while
if workflow_size(wf) > 1 then error(“invalid workflow schema”)
else begin
atomic _task = getAtomicTask(wf);
return atomic_task.QoS;
end
end function
Listing 3-1 – The SWR algorithm
To check if a reduction rule can be applied a set of conditions are tested. In Listing
3-2 we illustrate the applyConditionalRule function. From line 3 to line 22, several
conditions are tested to ensure that the conditional rule can be applied.