6B
02
A4
AD BA
EF DE
AD BE
EF 6B
02 A4
AD
BE EF DE
AD BE
EF 6B
02 A4
%esp
Figure 5: Leveraging the stack to increment the pointer to our
payload. In this example, the pointer value is initially 0xDEADBAEF
and is increased by 1024 to 0xDEADBEEF.
Since the register containing the address of the shellcode
is known, we can copy its pointer and add an oﬀset to reach
the encoded payload. Using only English-compatible ASCII
characters, the increment instruction inc is the most obvious
candidate for increasing a register’s value. However, this
one-byte instruction will only increase the value of a register
in increments of one, yielding no space for the decoder. Used
this way, the inc instruction is insuﬃcient.
However, a single inc instruction can be used to increase
a register value in increments of 256 after manipulating the
alignment of the stack. This process is depicted in Figure 5.
For instance, we can ﬁrst push the shellcode pointer onto
the stack and shift the stack pointer %esp by one byte. Once
shifted, the pop instruction places the three least-signiﬁcant
bytes of the shellcode pointer into a register where its value
is increased using inc multiple times.2 Afterwards, the value
of this register is pushed back onto the stack and the stack
is realigned. The top of the stack, which at ﬁrst contained
the shellcode pointer, now contains the same value increased
by increments of 256. By popping this value into a register,
we can use it to address the encoded payload.
Unpacking the decoder. To facilitate looping, instructions
that are not English compatible (e.g., the lods and add
instructions) are needed. However, to generate these, the
shellcode can manipulate its contents to patch in the re-
quired instructions. For example, an and instruction can
be used to create an add instruction. The opcode for and
is equivalent to the ASCII space character (0x20), which
2Respectively, we push and pop the shellcode pointer twice
in a row to avoid having an unpredictable byte (i.e., the
byte marked “-” in step 2 from Figure 5) in the register we
increment. This follows one of our more general principles
discussed in Section 5: avoid operations that may set ﬂags
in an unpredictable manner.
528is convenient because the space character is the most com-
mon character in English. The variant used in our proof-
of-concept is three bytes in length and takes the form “AND
r/m8, r8”. Its ﬁrst parameter, r/m8, addresses the bytes to
be modiﬁed, while the second speciﬁes one of the partial reg-
isters. The opcode for the add operations we create is 0x00.
This means that the partial register and the byte addressed
by the r/m8 operand must yield a value of zero when the
and operation is executed. Thus, the partial registers used
are chosen such that a zero byte is created at r/m8.
Decoder Loop
top:
sub $0x20,%al
jnz decode
    inc %edi
decode:
lods
add %ah,74(%edi)
jnz top
1:
2:
3:
4:
5:
6:
7:
8:
9:
Figure 6: Example decoder loop. Blocks of English words in the
payload are read by the decoder and transformed into arbitrary
executable machine code.
After patching, the add instructions further help build the
decoder by patching in the load string instruction, lods.
The load string instruction is used to read bytes from the
encoded payload.
It loads into %eax four bytes from the
address referenced by %esi (i.e., the encoded payload) and
afterwards, immediately increments the address by four.
Decoding. The decoder loop, shown in Figure 6, reads
blocks of English words from the encoded payload, decoding
the target shellcode byte-by-byte. For space eﬃciency, the
target shellcode overwrites the encoded payload as it is de-
coded. To facilitate this process, two pointers are initialized
to point to the encoded payload. The ﬁrst pointer, %esi, is
implicitly used to identify the current read position via the
lods instruction and the other pointer, an oﬀset from %edi,
marks the output position for the next decoded byte. As
described subsequently, the second pointer is also used as
an accumulator.
The decoder reads data from the encoded payload in con-
tiguous four-byte blocks. The ﬁrst two bytes of each block
are ignored. The value of the third byte in each block is
added to the value referenced by the output pointer, which
initially points to the ﬁrst character of the encoded shell-
code.
If the value of the fourth byte in a block is equiv-
alent to the space character, accumulation ends and the
output pointer is advanced. This process ultimately ter-
minates when accumulation yields the null character (0x00).
At its conclusion, the target shellcode is completely decoded
in memory, located in the same position that the encoded
payload originally resided.
The stop condition for both decoding individual bytes
and the decoder loop itself are controlled by the conditional
jumps shown at lines 3 and 9 of the assembly listing in Fig-
ure 6. Since the jump-if-not-zero instruction, jnz, is con-
trolled by the zero-ﬂag, the ﬁrst jump is inﬂuenced by the
outcome of the subtraction in the previous line (the zero-ﬂag
is set if the diﬀerence between its two operands, 0x20 and
%al, is zero). These two instructions are easily supported by
English-compatible characters: the subtraction instruction,
sub, has the same byte representation as a comma before a
space character (i.e., “, ”), while jnz is the English charac-
ter “u”. Similarly, the second jump is inﬂuenced by the add
operation that immediately precedes it and was patched in
by the decoder itself.
The decoder presented in this section is composed of byte
values that are particularly helpful in facilitating the cre-
ation of English shellcode. That said, there are many other
ways to accomplish the same task using other series of in-
structions. If a detection method is developed for one de-
coder in particular, it can trivially be replaced with another
that performs the same operations using diﬀerent instruc-
tions.
Initializing registers. To ease the aforementioned exposi-
tion, we omitted discussion on how registers are initialized.
At the same time that the address of the encoded shellcode
is moved to a register (before the decoder loop executes),
several other values are stored. Speciﬁcally, the popa in-
struction, whose opcode is equivalent to the character “a”,
allows us to set the contents of the registers used by the
and instruction (to create an add instruction) and the add
instruction (to create the lods instruction). The popa in-
struction pops 32 bytes from the stack into 8 registers. The
registers’ values are set by pushing the values on the stack
before popa executes. The two push operations we use push
either one or four bytes onto the stack and are equivalent
to the characters “j” and “h”, respectively. For example, the
word, “johnboat”, ﬁrst pushes “o” and then “nboa” onto the
stack.
5. AUTOMATIC GENERATION
Recall that the instructions used to implement the decoder
are selected speciﬁcally because their byte-representations
match those of characters used commonly in English-based
ASCII strings. Taken as-is, the custom decoder will have
common English characters, but will not have the appear-
ance of English text.
Intuitively, there are three general types of instructions
that give us the freedom to position the decoder instruc-
tions among English words and produce multiple variants of
English shellcode from the same payload. The ﬁrst type in-
cludes all English-compatible instructions that produce no
net execution eﬀect, i.e., nop. Second are operations that
may in general aﬀect machine state, but for our purposes
will not interfere with the operation of the decoder (or the
decoding process). The last type are those that in series may
intermediately aﬀect machine state in an undesirable man-
ner, but taken in sum, have the same net eﬀect on machine
state as the other two types, i.e., no eﬀect of consequence or
no eﬀect at all.
To generate an English-like decoder automatically, we use
techniques that draw heavily from the natural language pro-
cessing community, augmenting a statistical language gen-
eration algorithm with additional constraints. The language
generation architecture is inﬂuenced by statistical informa-
tion about the target language, i.e., English, by observing
its use in various settings. We use a corpus comprised of just
over ﬁfteen thousand Wikipedia articles and roughly 27, 000
books from the Project Gutenberg (see www.gutenberg.org)
to train a statistical model, termed a language model, which
contains counts of words and word sequences observed dur-
ing training.
529if (crash)
   discard;
else if (pass_level)
   score++;
... through the
SCORE: 12
door
(.009)
end
(.005)
night
(.004)
(cid:1)
(cid:2)
... through the door
SCORE: 13
... through the end
SCORE: 12
KEY
(cid:1)
(cid:2)
Level-up
Does not crash
Crash
Assessment function
Figure 7: An English version of the decoder is found by sampling
the language model for words that contribute to the achievement
of decoder operations. When sampling along a path produces an
instruction that prematurely halts execution, it is discarded in
favor of other paths. As paths are assessed, top scoring samples
are kept as decoder candidates.
Paragraphs are built by sampling words from the language
model based on their observed frequency. Each sentence is
generated from left to right such that words are added to a
sentence only when they have also been observed in the sam-
ple text following the combination of words already chosen
for the sentence. Retrospection is, however, limited. Since
we use an smoothed n-gram language model and our max-
imum n-gram length is 53, a candidate word w5 will only
follow w1w2w3w4 if w1w2w3w4w5 exists in the training cor-
pus. In more traditional language generation applications,
we might perform a random walk through the model, choos-
ing each candidate word at random based on its probability
(e.g., if w5 follows w1w2w3w4 with a probability of 0.9, then
it would be generated with a probability of 0.9).
While sampling a string from a language model, a tra-
ditional language generation application may only be in-
ﬂuenced by the probability distribution for each candidate
word. Since we are also interested in a word’s contribution
to execution, we seek a path through the model that max-
imizes English probability and correct execution behavior
simultaneously. To do so, we traverse the language model
using the Viterbi algorithm [24].
Viterbi is used to reconstruct the most probable sequence
of states in a hidden Markov model. A hidden Markov model
(HMM) is simply a Markov model in which each state is com-
prised of known parameters (e.g., a word) and unknown pa-
rameters (e.g., a word’s contribution to our execution goals).
Throughout this process, an objective assessment func-
tion scores candidate execution so that we can quantitatively
compare candidates. Each decoder instruction is assigned a
level number i such that 1 ≤ i ≤ n, whereby level i denotes
the ith instruction. For each sampled string, the score then
indicates the number of desirable instructions it achieves.
At the beginning of language generation, we say that the
(yet to be generated) instance has a score of zero. For each
candidate word, we concatenate it to the string along the
path of generation and then execute the string in a sandbox
(see Section 6). If the string fails execution (e.g., crashes the
simulator), it is discarded. If the addition of the candidate
completes the operation speciﬁed by the next level, its score
is incremented.
If execution does not crash or yield com-
3This value is chosen empirically and represents a trade-oﬀ
between sampling accuracy and the speed at which samples
are generated.
pletion of the desired operation, the score does not change.
Figure 7 illustrates this behavior.
We sample thousands of strings simultaneously and be-
tween each round of candidates, keep only the top m sam-
ples. Since we do not know the ideal relationship between
execution score and word probability at any intermediate
stage, we use a greedy algorithm that maximizes our exe-
cution goal ﬁrst. In other words, we always keep the best
m(= 20, 000) candidates by highest execution score and use
language probability to settle ties. The process continues un-
til a sample reaches the nth level, indicating that an English-
based decoder has been found.4
While objectives change regularly for the duration of the
generation process in response to the completion of prior
objectives, some conditions hold throughout. We discour-
age the selection of candidates that reverse desirable eﬀects
achieved previously, overwrite critical data, or execute privi-
leged instructions (i.e., crash) at any stage. Furthermore, we
refrain from selecting any candidates that use unpredictable
data or set ﬂags unpredictably. For instance, performing an
arithmetic operation with an operand whose value is un-
known can alter the EFLAGS register in way that cannot
be predicted a priori. Without these constraints, we would
waste eﬀort considering candidates that behave erratically,
fail to decode encoded payloads, or ultimately crash.
Once a potential decoder is identiﬁed, we can encode ar-
bitrary shellcode. After selecting a payload, we encode the
target shellcode by continuing to explore the Viterbi search
that generated the decoder. The process for encoding pay-
loads is almost identical to the process we describe in Sec-
tion 4.2 for ﬁnding an English decoder.
Instead of mon-
itoring the execution behavior of candidates at each step,
the objective assessment function now observes how many
target bytes are encoded by each candidate, favoring those
that encode more of the payload using fewer words. Interest-
ingly enough, encoding the payload places few restrictions
on language generation. This is because the encoded data
is non-executable and the ﬁrst two bytes of each four-byte
block are unconstrained (as well as the fourth block while
accumulation is incomplete).
Language Engine
LM
SHARED MEMORY
JNI
Candidate Decoders
Candidate Scores
64-bit Java
32-bit C
SCORE09
Scoring Engine
Figure 8: Candidate decoders are produced by a language engine
and stored in shared memory. Then, they are subsequently exe-
cuted and evaluated by a scoring engine. As scores are returned
to the language engine, candidates are ranked, inﬂuencing future
candidate selection.
Our implementation is divided into two distinct yet col-
laborative entities: a language engine and a scoring en-
4We note, however, that ﬁnding a solution with this tech-
nique is not guaranteed.
530gine. The language engine was constructed in the Java
programming language using the LingPipe API (see http:
//alias-i.com/lingpipe/). LingPipe is a natural language
processing and data mining toolkit that provides an eﬃcient
implementation of numerous algorithms and data structures
commonly used by computational linguistics applications.
We use the toolkit to rapidly build, train, and query our
language model.
Two tandem processes comprise the scoring engine. The
ﬁrst process (hereafter referred to as the “executor”) executes
each candidate decoder while the second (the “watcher”) is
responsible for controlling and monitoring said execution.
The monitor process evaluates candidate behavior (i.e., how
it aﬀects the state of the machine) through single-step ex-
ecution and is implemented using the Linux ptrace API.
Since our generation technique produces English from left
to right, the monitor process favors candidates that perform
operations in approximately the same order as our hand-
written decoder. This yields the natural scoring mechanism
described in Section 5. The scoring engine is also responsible
for discouraging the selection of candidates that misbehave,
crash, or produce undesirable eﬀects.
The language and scoring engines communicate using shared
memory. Communication is facilitated by the Java Native
Interface (JNI) as depicted in Figure 8. Before generation
commences, the JNI component performs a one-time initial-
ization that allocates two shared memory regions: one that
holds the potential solution and one that holds its execution
results. The JNI component also launches the scoring en-
gine’s monitor process. The scoring engine proceeds to eval-
uate candidates provided by the language engine. The JNI
component signals the scoring engine when each new candi-
date word has been copied into shared memory. Once the
signal is received, the scoring engine’s execution process ﬁlls
the stack with random values (to ensure that a solution us-
ing uncontrollable stack data is improbable), initializes other
registers, and reassigns its instruction pointer to address the
candidate decoder. Afterward, the monitor process begins
single-step evaluation for the new candidate and provides
the language engine with a report of each candidate’s score,
which helps inﬂuence the ongoing Viterbi search and its role
in selecting future candidates. This feedback loop ends once
the target shellcode has been successfully realized.
5.1 An optimized design
An obvious downside of the aforementioned architecture
is the use of ptrace to single-step the execution of each
candidate; indeed, using this approach took 12 hours, on
average, to generate a complete decoder. While utilizing
ptrace turned out to be invaluable in our quest towards
automatic generation, its use is ultimately far more ineﬃ-
cient than need be — primarily because it induces multiple
context switches between kernel and user space.
One viable alternative to ptrace is emulation. That is,
instead of using inter-process communication and ptrace,
we instead emulate the eﬀects of every instruction provided
by English as well as the eﬀect of each instruction created
by our framework. This is a particularly arduous task be-
cause it requires understanding the eﬀects that each English