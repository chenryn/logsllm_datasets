 **System information**
  * TensorFlow version (you are using): 1.12
  * Are you willing to contribute it (Yes/No): Yes
**Describe the feature and the current behavior/state.**  
Gradient Accumulation(GA) is a workaround to enable big batches on limited
memory GPUs which has been supported in Caffe and PyTorch. Instead of back-
propagating for every batch feed-forward; gradients across multiple batches
are accumulated. After multiple feed forwards, the accumulated gradient is
back-propagated through the network layer. It boosts performance with a couple
of percentages on our several workload (e.g., XLNet, Transformer) with
Distribution Strategy. Unfortunately, I am not aware of any official
documentation to use such feature in Tensorflow. `tf.contrib.opt.AGNOptimizer`
has a similar GA implementation but is not common for general distribution job
on DistributionStrategy. Besides it will introduces OOM for large
embeddings(#31637).  
**Will this change the current api? How?**  
Yes. Just need to add one new parameter `iter_size` to current strategy API,
which for example:
     # For MirroredStrategy, gradient accumulation is supported using iter_size parameter.
     distribution = tf.distribute.MirroredStrategy(num_gpus=2, iter_size=4)
     # For MultiWorkerMirroredStrategy:
     tf.distribute.experimental.MultiWorkerMirroredStrategy(..., iter_size=4)
**Who will benefit with this feature?**  
Anyone who use distribution strategy and want to enable big batches on limited
memory GPUs  
**Any Other info.**  
None.
We already have a concise implementation of GA on DistributionStrategy and are
willing to contribute. Thanks in advance for any feedback.