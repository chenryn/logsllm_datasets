### System Information
- **TensorFlow Version**: 1.12
- **Willing to Contribute**: Yes

### Feature Description and Current Behavior
Gradient Accumulation (GA) is a technique that enables the use of large batch sizes on GPUs with limited memory. This technique, which is supported in frameworks like Caffe and PyTorch, involves accumulating gradients across multiple forward passes before performing a single backward pass. This approach has been shown to improve performance by a few percentage points on various workloads, such as XLNet and Transformer, when used with TensorFlow's Distribution Strategy.

Currently, TensorFlow does not have official documentation or built-in support for gradient accumulation. The `tf.contrib.opt.AGNOptimizer` provides a similar implementation, but it is not suitable for general distribution jobs using `DistributionStrategy`. Additionally, it can lead to out-of-memory (OOM) errors for models with large embeddings, as reported in issue #31637.

### Proposed API Changes
To implement gradient accumulation, we propose adding a new parameter, `iter_size`, to the existing `DistributionStrategy` API. This parameter will specify the number of forward passes to accumulate gradients before performing a backward pass. Here are examples of how this parameter could be used:

- **For `MirroredStrategy`**:
  ```python
  distribution = tf.distribute.MirroredStrategy(num_gpus=2, iter_size=4)
  ```

- **For `MultiWorkerMirroredStrategy`**:
  ```python
  distribution = tf.distribute.experimental.MultiWorkerMirroredStrategy(..., iter_size=4)
  ```

### Beneficiaries
This feature will benefit users who employ TensorFlow's `DistributionStrategy` and wish to train models with large batch sizes on GPUs with limited memory.

### Additional Information
We have already developed a concise implementation of gradient accumulation for `DistributionStrategy` and are willing to contribute it to the TensorFlow project. We appreciate any feedback on this proposal.