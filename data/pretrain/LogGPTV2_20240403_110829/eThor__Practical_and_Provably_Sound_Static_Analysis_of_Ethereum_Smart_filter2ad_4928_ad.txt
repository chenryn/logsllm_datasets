state (program counter and active words set to 0, empty stack,
memory initialized to 0) when being initially called, it is sufficient
to check all executions of contract c that started in such a state.
Static assertion checking. The Solidity language supports the
insertion of assertions into source code. Assertions shall function
as pure sanity checks for developers and are enforced at runtime
by the compiler creating the corresponding checks on the bytecode
level and throwing an exception (using the INVALID opcode) in
case of an assertion violation [21]. However, adding these additional
checks creates a two-fold cost overhead: At create time a longer
bytecode needs to be deployed (the longer the bytecode the higher
the gas cost for creation) and at call time the additional checks need
to be executed which results in additional gas consumption. With
Accepted for ACM CCS, 2020
our static analysis technique, assertions can be statically checked
by querying for the reachability of the INVALID instructions. If no
such instruction is reachable, by the soundness of the analysis, the
code is proven to give the same guarantees as with the assertion
checks (up to gas) and those checks can safely be removed from the
code resulting in shorter and cheaper contracts.4 Formally, we can
characterize this property as the following reachability property:
Definition 3.3 (Static assertion checking). Let c be a contract and
(µ, ι, σ , η) regular execution states such that (µ, ι, σ , η) is strongly
consistent with c and µ = (д, 0, λx . 0, 0, ϵ) for some д ∈ N. Let Γ be
an arbitrary transaction environment and S be an arbitrary callstack.
Then a the static assertion check for c is defined as follows:
¬∃s, S . Γ ⊨ (µ, ι, σ, η)c :: S →∗ sc :: S′ ++ S ∧ code(c)[s .µ .pc] = INVALID
Intuitively this property says that during an execution of contract
c it should never be possible to execute an INVALID instruction.
Semi-automated verification of contract-specific properties.
As demonstrated by Hildebrandt et al. [29], reachability analysis
can be effectively used for Hoare-Logic-style reasoning. This holds
in particular for the analysis tool presented in this work: Let us
consider a Hoare Logic triple {P}C{Q} where P is the precondition
(operating on the execution state), C is the contract code and Q is
the postcondition that should be satisfied after executing code C in
an execution state satisfying P. Then we can intuitively check this
claim by checking that a state satisfying ¬Q can never be reached
when starting execution in a state satisfying P. More formally, we
can define Hoare triples as reachability properties as follows:
. Γ ⊨ sc∗ :: S →∗ s′
Definition 3.4 (Hoare triples). Let c∗ be a contract and let C be a
code fragment of c∗. Let P ∈ S → B be a predicate on execution
states (strongly consistent with c∗) that models execution right
at the start of C and similarly let Q ∈ S → B be a predicate on
execution states (strongly consistent with c∗) that models execution
right at the point after executing C. Then Hoare triples {P}C{Q}
can be characterized as follows:
{P }C{Q } := ∀s . P(s) =⇒ ¬∃s′
Hoare-Logic style reasoning can be used for the semi-automated
verification of smart contracts given that their behavior is speci-
fied in terms of pre- and postconditions. For now it still requires
a non-negligible amount of expertise to insert the corresponding
abstract conditions on the bytecode-level, but by a proper integra-
tion into the Solidity compiler the generation of the initialization
and reachability queries could be fully automated (cf. § C.1). We
want to stress that in contrast to existing approaches, our analysis
technique has the potential to provide fully automated pre- and
postcondition checking even in the presence of loops as it leverages
the fixed point engines of state-of-the-art SMT solvers [32].
c∗ :: S ∧ ¬Q(s′)
4 HORST: A STATIC ANALYSIS LANGUAGE
To facilitate the principled and robust development of static an-
alyzers based on Horn clause resolution, we designed HoRSt – a
framework consisting of a high-level specification language for
defining Horn-clause based abstractions and a compiler generating
optimized smt-lib encodings for SMT-solvers. The objective of
4The Solidity Docs [21] discuss exactly this future use of static analysis tools for
assertion checking.
9
Accepted for ACM CCS, 2020
Figure 9: Utilization of HoRSt for static analysis
HoRSt is to assist analysis designers in developing fast and robust
static analyzers from clean and readable logical specifications.
Many existing practical analyzers are built on top of modern
SMT-solvers such as z3. These solvers are highly optimized for
performance, which causes big performance deviations on differ-
ent problem instances and makes their internal workings (due to
the heavy use of heuristics) opaque to the user. Handcrafting logi-
cal specifications for such solvers in their low-level input format
smt-lib is hence not only cumbersome, error-prone, and requires
technical expertise, but is also very inflexible, since the performance
effects of different encodings may vary with the concrete problem
instance. For tackling this issue, HoRSt decouples the high-level
analysis design from the compilation to the input format: A high-
level specification format allows for clear, human-readable analysis
definitions while the translation process is handled by a stable and
streamlined backend. On top, it allows for easily applying and ex-
perimenting with different Horn-clause level optimizations that we
can show to enhance the performance of z3 substantially in our
problem domain. We will shortly illustrate the utilization of HoRSt
in the design process of our static analyzer and discuss the most
interesting optimizations performed by the HoRSt compiler. For an
introduction to the HoRSt language, we refer the reader to § A.1.
Designing static analyses using HoRSt. The HoRSt language al-
lows for writing math-like specifications of Horn clauses such as
those given in Figure 6. For parametrizing those clauses (e.g., by
the program counters of a specific contract) an interface with a
Java™ back-end can be specified that handles the domain specific
infrastructure, such as contract parsing. We overview the different
steps of the analysis design process in Figure 9.
The core of the analysis is the HoRSt specification. Using high-
level programming constructs such as algebraic data types, pat-
tern matching, and bounded iteration, a HoRSt specification de-
scribes Constrained Horn clauses over user-defined predicates.
Horn clauses can be parametrized by (families) of sets that are
specified in the parameter interface (e.g., the sets of all program
counters containing a certain bytecode instruction in a specific
contract). Given such a specification, the analysis designer needs
to provide infrastructure code written in Java™. In particular this
code needs to exhibit an implementation of those sets (or functions)
specified in the parameter interface. In the case of our analysis, the
environment code contains the infrastructure for contract parsing
and the parameter interface allows for accessing the assembled
contract information (code length, positions of opcodes, etc.) in
the analysis specification. The HoRSt compiler itself is utilized to
generate (optimized) smt-lib output given a HoRSt specification
and the parameter interface implementation: It unfolds the high-
level specification into separate Horn clauses over basic data types,
10
Clara Schneidewind, Ilya Grishchenko, Markus Scherer, and Matteo Maffei
(cid:41)
P1(x) ∧ y = x + 1 ⇒ P2(y)
P2(y) ∧ z = y ∗ 3 ⇒ P3(z)
P1(x) ∧ y = x + 1 ∧ z = y ∗ 3 ⇒ P3(z)
Figure 10: Unfolding of P2.
applying the interface implementation: To this end it also resolves
all high-level constructs, ensuring that the resulting Horn clauses
fall into the fragment that can be handled by z3. On top, the HoRSt
compiler (optionally) performs different optimizations and transfor-
mations on the resulting Horn clauses, before translating them into
the standardized SMT output format smt-lib. The most important
of these transformations are discussed in the following.
Low-level optimizations. One of the most effective optimizations
performed by HoRSt is the predicate elimination by unfolding Horn
clauses. This satisfiability preserving transformation has been long-
studied in the literature [17, 46] and showed beneficial for solving
Horn clauses in certain settings [16, 28]. In practice, however, the
exhaustive application of this transformation can lead to an expo-
nential blow-up in the number of Horn clauses and hence does
not necessarily yield the best results. For this reason HoRSt im-
plements different strategies for the (partial) application of this
transformation, which we call linear folding and exhaustive folding.
The idea behind the unfolding transformation is that a predicate
p can be eliminated from a set of Horn clauses Λ by unfolding the
occurrences of p in the premises according to the clauses that have
p as conclusion. An example is given in Figure 10. Here predicate P2
is eliminated by merging the two single execution steps (modeled
by the two clauses on the left) into a combined clause (on the right)
summarizing the steps.
This intuition serves as a starting point for the unfolding strategy
of linear folding. In linear folding, all clauses representing a basic
block of sequential execution steps are merged into a single clause.
More precisely, the unfolding transformation is only applied to
those predicates that are used linearly in Λ, meaning that p occurs
in the premises of exactly one clause in Λ and in the conclusion of
exactly one different clause in Λ. Linear folding has the advantage
that it runs linearly in the number of clauses in Λ and yields as
result a reduced set of clauses Λ′ such that |Λ′| ≤ |Λ|.
In contrast, applying the unfolding transformation exhaustively
on all predicates (with exception of those that are recursively used)
might yield an exponential blow-up in clauses (and hence also re-
sult in exponential runtime). In practice however, the set of clauses
Λ′ resulting from such a exhaustive folding is often of a reasonable
size. For mitigating the runtime overhead, however, it is crucial to
avoid unnecessary blow-ups in the intermediate clause sets pro-
duced during the transformation: To this end, for exhaustive folding
HoRSt applies linear folding first and only afterwards performs the
unfoldings that multiply existing clauses.
Finally, HoRSt supports constant folding for minimizing the
smt-lib output and value encoding to map custom data types into
primitive type encodings that are efficiently solvable by z3. We refer
to § A for further details on HoRSt internals and functionalities.
 SpecHoRStSmart ContractInternal Horn ClauseRepresentationHorn ClauseTransformationssmt-lib OutputContractParser CompilerHoRStParameterInterface𝑝(𝑥)∧𝑞(𝑦)⇒𝑟(𝑥,𝑦)eThor: Practical and Provably Sound Static Analysis
of Ethereum Smart Contracts
5 IMPLEMENTATION & EVALUATION
We use HoRSt to generate the analyzer eThor which implements the
static analysis defined in § 3. In the following, we shortly overview
the design of eThor and illustrate how eThor can enhance smart
contract security in practice. To this end we conduct a case study
on a widely used library contract, showing eThor’s capability of
verifying functional correctness properties and static assertion
checks. Furthermore, we validate eThor’s soundness and precision
on the official EVM testsuite and run a large-scale evaluation for the
single-entrancy property on a set of real-world contracts from the
Ethereum blockchain, comparing eThor with the state-of-the-art
analyzer ZEUS [34].
5.1 Static Analysis Tool
The mechanics of eThor are outlined in Figure 11: eThor takes as
input the smart contract to be analyzed in bytecode-format and a
HoRSt-specification parametrized by c∗ . For enhancing the perfor-
mance and precision of the tool, eThor performs a multi-staged anal-
ysis: First, it approximates the contract jump destinations (based
on a less precise abstract semantics) which helps the tool perfor-
mance as it decouples the control flow reconstruction (which can
be performed more efficiently with a less precise abstract semantics
as typically no computations on jump destinations are performed,
but just their flow during the stack needs to be modeled) from the
more evolved abstract semantics required for precisely analyzing
the properties discussed in § 3.5. As both used semantics are sound,
the soundness of the overall analysis is not affected. In a second
pre-processing step, eThor performs a simple partial execution of
atomic program blocks in order to statically determine fixed stack
values. This can be beneficial in order to, e.g., precompute hash
values and results of exponentiation which would otherwise need
to be over-approximated in the analysis due to the lacking support
for such operations by z3. The results from the pre-analysis steps
are incorporated into the analysis by a predefined interface in the
HoRSt-specification. The HoRSt compiler then – given the interface
implementation and the specification – creates an internal Horn
clause representation which, after optionally performing different
optimizations, is translated to an smt-lib file on which the SMT-
Solver z3 is invoked. The reconstructed control flow is obtained
by a Soufflé [33] program, which was created by manually trans-
lating a HoRSt specification. Soufflé is a high performance datalog
engine, which we plan to support as a compilation target for (a
subset of) HoRSt in the near future. Since the problem of control
flow reconstruction falls into the fragment supported by modern
datalog solvers, we found Soufflé more performant than using the
general-purpose solver z3 in this context 5. However, for reasoning
about more involved properties, the expressiveness of z3 is required
as we will illustrate in § 5.2.
5z3 also implements a standard datalog engine which is restricted to work with predi-
cates over finite domains. This constraint is used to ensure that the smt-lib-expressible
Horn clauses do not leave the classical datalog-solvable fragment. However, Soufflé
overcomes this restriction in favor of a more liberal characterization of the solvable
fragment which could also be incorporated into the HoRSt language - allowing for
compilation to Soufflé from this fragment.
Accepted for ACM CCS, 2020
Figure 11: Analysis outline.
5.2 Case Study: SafeMath Library
As a case study for functional correctness and assertion checking we
chose Solidity’s SafeMath library [4], a library implementing proper
exception behavior for standard arithmetic operations. This par-
ticularly encompasses exceptions in case of overflows in addition
and multiplications, underflows in subtractions, and division or
modulo by 0. The SafeMath library is special in that it is not a classical
library which is deployed as an own contract on the blockchain,
but its functions get inlined during the compilation of a contract
that uses them6. This specific behavior makes it particularly inter-
esting to analyze the individual library functions as their concrete
implementations may vary with changes in the compiler.
Functional Correctness. For our case study we compiled the func-
tions of the SafeMath library with a recent stable Solidity compiler
version (0.5.0) and verified that they expose the desired behavior.
In particular we showed that all functions 1) cannot return suc-
cessfully in the problematic corner cases. 2) can return successfully
with the correct result in the absence of corner cases. 3) if halting
successfully in the absence of corner cases, they can return nothing
but the correct result.
As these properties require to precisely relate different input
values over the execution (e.g., requiring that the sum of two input
values x and y exceeds 2256), we needed to slightly adapt our anal-
ysis by adding a corresponding representation of the initial input
(as word array) to the MState and the Halt predicates. This array
is accessed by the CALLDATALOAD operation which fetches the
input data. Additionally, we need to model return values by an own
predicate. For more details, we refer the reader to § C.2. Our analysis
manages to prove the corresponding functional properties for each
of the five functions within milliseconds, showcasing the effiency
of our analysis tool. Note that verifying meaningful functional cor-
rectness properties, like in this case study, requires to universally
quantify over potential inputs, hence making an analysis with a
datalog engine (such as Soufflé), which requires to explicitly list
finite initial relations, infeasible.
Static Assertion Checking. The following code snippet shows the
division function of the SafeMath library:
1 function div ( uint256 a , uint256 b , string memory errorMessage )
2
3
4
5
internal pure returns ( uint256 ) {
require (b > 0, errorMessage );
uint256 c = a / b;
// assert (a == b * c + a % b); // There is no case in which
this doesn 't hold
return c; }
6In Solidity, one always needs to provide definitions of the (library) contracts one is
interacting with. In case that a library is only containing pure internal functions, the
Solidity compiler inlines this functions instead of compiling them to DELEGATECALL
call instructions to an address at which the user specified the library to reside.
11
Smart ContractSpecCFG GenConstant AnalysisZ3ExhaustiveLinearSpecHorn Clause GenAccepted for ACM CCS, 2020
Clara Schneidewind, Ilya Grishchenko, Markus Scherer, and Matteo Maffei
It testifies that the function used to contain an assertion which was
deemed to be unnecessary and hence removed (probably to save
gas). We reinserted this assertion and indeed could prove that the
dynamic assertion check is obsolete as it can never be violated.
5.3 Large-scale Evaluation
We performed a series of experiments to assess the overall per-
formance of our tool. In particular, we systematically evaluated
eThor’s correctness and precision on the official EVM testsuite and
additionally conducted a large scale analysis for the single-entrancy
property, comparing eThor with the ZEUS [34] static analyzer, using
the real-world dataset introduced with the latter7.
Automated Testing. For making a principled assessment of its
correctness, we evaluated eThor against the virtual machine test
cases provided by the Ethereum Foundation8. Being formulated as
pre- and postconditions, these test cases fall in the class of properties
characterized in § 2.3 and we could automatically translate them
into Horn clauses and queries in HoRSt. The test suite defines 609
test cases, 604 of which specify properties that are relevant for a
single contract setting (see § C.3 for details).
Using a 1 second timeout, we were able to solve 85% (513) of the
test cases precisely with a termination rate of 99% (597).
Reentrancy. For the call unreachability property described in Def-
inition 3.2, we evaluated eThor against the the set of real-world
contracts presented in [34]. The authors extracted 22493 real-world
contracts from the Ethereum blockchain over a period of three
months and (after deduplication) made available a list of 1524 con-
tract addresses. Due to various problems of this dataset (as described