Eq. (13) for the surface distance E𝜃∼PurArc[𝜃] of the Purkayastha
distribution. To that end, we draw 1 million samples from each
distribution VMFMix(𝑛, 𝜅) and PurMix(𝑛, 𝜅), and compute the em-
pirical means of the corresponding Euclidean and angular distances.
We chose 𝑛 ∈ {2, 3, 25, 50, 100, 500} and 𝜅 ∈ {10𝑘 | −3 ≤ 𝑘 ≤ 3}.
We compare the thusly obtained empirical distances against the
results given by the analytical formula we implemented in Python.
Results. As we can observe in Fig. 10, our analytical solution
(marked by X’s) precisely predicts the empirical distances, even in
higher dimensions such as 𝑛 = 500. Moreover, given the same con-
centration parameter 𝜅, the Purkayastha distribution consistently
VMFMix(𝑛, 𝜅)[𝑡 ≤ 𝑇] =
∫ 𝑇
−1
= 𝐶′
VMF
2 and 𝑥 ≔ 𝑇+1
VMFMix(𝑛, 𝜅)[𝑡] d𝑡
(cid:0)1 − 𝑡2(cid:1)𝑛−3
∫ 𝑇
−1
2 𝑒𝜅𝑡 d𝑡 .
𝑇+1 yields an integral that we can express
Changing variables 𝑡 ↦→ 𝑡+1
as Humbert series according to Eq. (30), so we get
2 𝑒−𝜅
2𝑛−2𝑥
𝑛−1
2 (1 − 𝑥𝑡) 𝑛−3
𝑛−3
𝑒2𝜅𝑥𝑡 𝑡
2 d𝑡
Φ1(𝛼, 1 − 𝛼, 1 + 𝛼; 𝑥, 2𝜅𝑥)
= 𝐶′
·
∫ 𝑥
VMF
B(𝛼, 𝛼)𝑀(𝛼, 2𝛼, 2𝜅)
.
□
0
𝑥𝛼
𝛼
=
A.3.2 Proofs related to the Purkayastha distribution.
Proof of Theorem 19. Let 𝒙, 𝒚 ∈ S𝑛−1 be any fixed unit vec-
tors, and take any fixed set Z ⊆ S𝑛−1. For any z ∈ Z, we have
Pur(𝒙, 𝜖)[z]
Pur(𝒚, 𝜖)[z] =
𝐶Pur · exp(cid:0)−𝜖 · arccos(𝒙ᵀz)(cid:1)
= exp(cid:0)𝜖 · arccos(𝒚ᵀz) − arccos(𝒙ᵀz)(cid:1)
≤ exp(cid:0)𝜖 · arccos(𝒙ᵀ𝒚)(cid:1)
𝐶Pur · exp (−𝜖 · arccos(𝒚ᵀz))
= exp (𝜖 · 𝑑∡(𝒙, 𝒚)).
First, the normalization constants cancel out, and we can combine
the exponents; next, we apply the triangle inequality for the angular
(arccos) distance. By integrating over z ∈ Z, we obtain 𝜖𝑑∡-privacy.
□
Proof of Lemma 21. Note that for any ℓ ∈ Z,
T𝑘(ℓ𝜋) =
Therefore,
0
𝑎
(−1)ℓ+1
for 𝑘 < 𝑚,
for 𝑘 = 𝑚 and even 𝑛,
for 𝑘 = 𝑚 and odd 𝑛,
𝐸𝑛,𝑎(ℓ𝜋) = 𝑒𝑎ℓ𝜋C𝑚T𝑚(ℓ𝜋)
= 𝑒𝑎ℓ𝜋C𝑚
if 𝑛 is even,
if 𝑛 is odd,
and we obtain as special case the normalization constant
𝐹𝑛,𝑎(𝜋) = C𝑚
if 𝑛 is even,
if 𝑛 is odd. □
(−1)ℓ+1
(cid:40)𝑎
(cid:40)𝑎(𝑒𝑎𝜋 − 1)
(𝑒𝑎𝜋 + 1)
Proof of Theorem 22. The surface distance 𝜃 = 𝑑∡(x, 𝝁) fol-
lows the angular distribution 𝜃 ∼ PurArc(𝑛, 𝜅). Therefore, we have
[𝑑∡(x, 𝝁)] =
E
x∼Pur
∫ 𝜋
E
𝜃∼PurArc
= 𝐶′
Pur
0
[𝜃]
𝜃𝑒−𝜅𝜃 sin𝑛−2(𝜃) d𝜃 .
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1220Metric = 𝑑2 | 𝑛 = 2
Metric = 𝑑2 | 𝑛 = 3
Metric = 𝑑2 | 𝑛 = 10
Metric = 𝑑2 | 𝑛 = 25
Metric = 𝑑2 | 𝑛 = 100
Metric = 𝑑2 | 𝑛 = 500
e
c
n
a
t
s
i
d
d
e
t
c
e
p
x
E
e
c
n
a
t
s
i
d
d
e
t
c
e
p
x
E
1.5
1.0
0.5
0.0
1.5
1.0
0.5
0.0
Metric = 𝑑∡ | 𝑛 = 2
Metric = 𝑑∡ | 𝑛 = 3
Metric = 𝑑∡ | 𝑛 = 10
Metric = 𝑑∡ | 𝑛 = 25
Metric = 𝑑∡ | 𝑛 = 100
Metric = 𝑑∡ | 𝑛 = 500
10−2
102
Concentration 𝜅
100
10−2
102
Concentration 𝜅
100
10−2
102
Concentration 𝜅
100
10−2
102
Concentration 𝜅
100
10−2
102
Concentration 𝜅
100
Distrib.
VMF(𝑛, 𝜅)
Pur(𝑛, 𝜅)
Method
empiric
analytic
100
10−2
102
Concentration 𝜅
Figure 10: Expected 𝑑2 and 𝑑∡ distances for VMF and Purkayastha distributions in various settings. For comparison, we obtained
empirical averages (dotted lines) from 1M samples of each distribution and analytic solutions (X’s) from Eqs. (6) and (13).
Pur(𝑛, 𝜅) | 𝑛 = 2
Pur(𝑛, 𝜅) | 𝑛 = 3
Pur(𝑛, 𝜅) | 𝑛 = 10
Pur(𝑛, 𝜅) | 𝑛 = 25
Pur(𝑛, 𝜅) | 𝑛 = 100
Pur(𝑛, 𝜅) | 𝑛 = 500
]
𝜗
≤
𝜃
[
c
r
A
r
u
P
]
𝜗
≤
𝜃
[
c
r
A
F
M
V
1.00
0.75
0.50
0.25
0.00
1.00
0.75
0.50
0.25
0.00
Method
analytic
numeric
VMF(𝑛, 𝜅) | 𝑛 = 2
VMF(𝑛, 𝜅) | 𝑛 = 3
VMF(𝑛, 𝜅) | 𝑛 = 10
VMF(𝑛, 𝜅) | 𝑛 = 25
VMF(𝑛, 𝜅) | 𝑛 = 100
𝜅
0.001
0.01
0.1
1.0
10.0
100.0
1000.0
VMF(𝑛, 𝜅) | 𝑛 = 500
0
Angle upper bound 𝜗
2
0
Angle upper bound 𝜗
2
0
Angle upper bound 𝜗
2
0
Angle upper bound 𝜗
2
0
Angle upper bound 𝜗
2
0
Angle upper bound 𝜗
2
Figure 11: Angular CDFs, obtained via numerical integration (dotted) of the PDFs and analytically (X’s) via Eqs. (7) and (14).
has lower expected distance (or error) which indicates that it has a
generally more favorable privacy-utility trade-off.
B.1.2 Cumulative distribution functions. Secondly, we want to ver-
ify our formula for the CDFs VMFMix[𝑡 ≤ 𝑇] given in Eq. (7) as
well as PurArc[𝜃 ≤ 𝜗] given in Eq. (14). As reference values, we
numerically approximate the integrals over the probability density
functions using the quadrature routines provided by scipy.
Results. The results are presented in Fig. 11, where we vary 𝜅
and 𝑛 as in the previous section. Note that while we derived a
solution for the mixture CDF for the VMF distribution, we show
the angular CDFs for both distributions by means of the transfor-
mation VMFArc[𝜃 ≤ 𝜗] = 1 − VMFMix[𝑡 ≤ cos(𝜗)] for better
comparability and clarity of presentation. Again, we can observe
that our analytical solutions (marked by X’s) accurately predict
the numerical approximations (dotted lines). While the CDFs of
both distributions look similar for small 𝜅, PurArc[𝜃 ≤ 𝜗] grows
more rapidly than VMFArc[𝜃 ≤ 𝜗] as 𝜗 → 𝜋 for larger 𝜅, indi-
cating a higher concentration near the mode and hence a better
privacy-utility trade-off for directional privacy.
B.2 Additional plots for busyness experiments
For a different perspective than Fig. 8, Fig. 12 shows the averaged
EMD between daily busyness histograms with selected temporal
privacy levels ℓt in the columns and continuous spatial privacy level
ℓs in the abscissa.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1221Privacy level ℓt = 0.01
Privacy level ℓt = 0.0316
Privacy level ℓt = 0.1
Privacy level ℓt = 0.316
Privacy level ℓt = 1.0
Mechanism
Pur
WL+PL
10−2
100
102
Privacy level ℓs
10−2
100
102
Privacy level ℓs
10−2
100
102
Privacy level ℓs
10−2
100
102
Privacy level ℓs
10−2
100
102
Privacy level ℓs
3
D
M
E
2
1
Figure 12: Earth Movers Distance (EMD) over spatial and temporal privacy levels ℓs (abscissa) and ℓt (columns) with protection
radii 𝑟t ≡ 3 h and 𝑟s ≡ 10 m, respectively.
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1222