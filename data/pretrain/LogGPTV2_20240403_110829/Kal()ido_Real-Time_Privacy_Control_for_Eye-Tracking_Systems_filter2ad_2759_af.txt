b
(
1
F
1
0
0.5
1
0.5
0
1
0.5
0
0.5
0
1
w=2 s
0.5
1.5
ε
0.5
1.5
ε
Natural
3
3
1
0
0.5
1
0.5
0
1
0.5
0
0.5
0
1
w=0.5 s
0.5
1.5
ε
0.5
1.5
ε
Web page
1
0
0.5
1
0.5
0
1
0.5
0
0.5
0
1
Random guess
3
3
0.5
1.5
ε
0.5
1.5
ε
Human
3
3
Figure 11: F1 scores of outlier identiﬁcation among scan-
paths. At high privacy conﬁgurations (low values of e, rlarge,
and w = 2 s), Kaleido thwarts outlier identiﬁcation attacks
in all three datasets by reducing F1 scores to be close to the
random guess baseline (red dash lines).
Results. Similarity analysis.
In Figure 10, we compare
the measured similarity with two thresholds: (1) mean inter-
subject similarity score (“Inter-subject”) in each dataset, and
(2) the similarity of two randomly synthesized scanpaths pre-
sented in [20] (“Random scanpath”). Figure 10 shows a con-
sistent trend in all three image datasets: the scanpath similarity
decreases with higher privacy level (i.e., smaller e, larger w,
and larger r). Kaleido degrades the similarity score below the
inter-subject threshold, even though it perturbs the spatial data
only; at e = 0.5, Kaleido brings the similarity score close to
the random scanpath baseline.
Outlier identiﬁcation. As observed from Figure 11,
Kaleido degrades the effectiveness of outlier identiﬁcation
for all of the privacy settings. For the natural and human im-
age datasets, Kaleido reduces the attacker’s F1 scores to the
random guess using rlarge with e as high as 3. Although the
attacker’s F1 score remains relatively high in the web page
dataset, it is reduced signiﬁcantly for e = 0.5.
7.3.2 Biometric Inferences
Setup. We construct attacks that attempt to predict (1) users’
identities and (2) whether the users wore contact lenses for
vision correction (use of contact lenses leads to distinguishing
eye gaze patterns [63]).
For this experiment, we use the VR video dataset (last row
in Table 1). The associated classiﬁcation labels are provided
in the dataset. This attack uses aggregate statistics of ﬁxa-
tion/saccade features over several VR video sessions as train-
ing data and predicts users’ identities and vision conditions
for an unseen session. Speciﬁcally, each video session uses a
different VR context for the same user. Hence, the evaluation
of biometric inferences here assesses Kaleido’s effectiveness
against linkability attacks across different contexts (this has
been exploited in prior work [22]). We adopt the features
suggested by the Cluster Fix toolbox [44], which are then used
to train a discriminant analysis classiﬁer [19]. This evaluation
includes 11 users from the VR video dataset who comfortably
completed all 12 video sessions. Additionally, the training
and test sets correspond to the same privacy conﬁguration,
i.e., either raw gaze streams or noisy gaze streams. We report
the F1 scores for leave-one-out cross-validation.
w=2 s
w=0.5 s
Raw data
1
1
Random guess
1.5
ε
Identity
1.5
ε
0.5
3
Vision corr.
(a) rsmall
1.5
ε
Identity
1.5
ε
0.5
3
Vision corr.
(b) rlarge
Figure 12: F1 scores of predicting user identity and vision
correction. Kaleido reduces the F1 scores of biometric infer-
ences to be close to random guess baselines (red dash lines)
even for low privacy conﬁgurations (high values of e or rsmall).
Results. Figure 12 shows the F1 scores obtained from both
the raw and noisy gaze streams. For both classiﬁers (identity
and vision correction), the raw gaze streams enable accurate
classiﬁcation – the F1 score is close to 1 (“Raw data” in Fig-
ure 12) and is much higher than that of random guess. This
indicates that the attacker can successfully predict users’ iden-
tities and vision correction conditions, even across different
contexts. On the other hand, we observe that Kaleido signif-
icantly degrades the attacker’s classiﬁcation accuracy to be
1
1
1
F
0.5
0.5
0
0
0.5
1
0.5
0
3
1
0.5
0
3
1
F
0.5
0.5
0
0
0.5
close to the random baseline even for low privacy conﬁgura-
tions (high values of e or rsmall).
8 Discussion
Kaleido is a ﬁrst step toward designing real-time eye-tracking
systems that provide a formal privacy guarantee. Here, we
discuss several possible avenues for future research:
Support for more data formats and types. An eye-tracking
platform may offer eye-tracking data in various formats
such as 2D gaze positions and 3D gaze positions. Currently,
Kaleido is designed for 2D gaze streams and supports head-
and-eye gaze streams as well (discussed in Appendix A.2.2).
Extension to 3D gaze streams is possible and would involve
extending the PlanarLap mechanism (Algorithm 1 to 3D po-
sitions. Additionally, some eye-tracking cores collect data
including blink timing and pupil dilation. Kaleido’s scope of
privacy can be further broadened to address these data types.
Privacy guarantee for temporal information. Kaleido can
be extended to protect the temporal information of eye gaze
streams by interfering with the timeliness of gaze releases.
For example, for ﬁxation duration (a popular aggregate statis-
tic), Kaleido can decide on a predeﬁned threshold T based
on standard human gaze ﬁxations [34]. Next, stage I and II
from Algorithm 1 can be replaced by a sophisticated ﬁxation
detection approach such as online differentially private clus-
tering [43, 55], which (1) releases a single noisy position in
the ﬁrst T duration of a ﬁxation and (2) stops any further data
release for the given ﬁxation. This ensures that the duration
for all ﬁxation events in the noisy gaze stream is ﬁxed to T .
Optimization for long scenes. Although visual content in an
eye-tracking application is typically dynamic, it might remain
relatively static for long periods in some cases. Such long
scenes that span multiple windows may lead to a large pri-
vacy budget consumption. Techniques including noisy data
caching can be used to help address this issue. Speciﬁcally,
Kaleido can check online if the current ROI has been visited
previously, and it can reuse the corresponding noisy gazes
from recent history. Additionally, for applications where inter-
actions are sporadic, Kaleido can skip releasing new gazes for
scenes when the user is inactive to save the privacy budget.
Optimizations for context processing. One interesting fu-
ture direction can be optimizing Kaleido’s context processing
core. The overhead of Kaleido’s context processing can be re-
duced by sharing the detection module with other applications.
Kaleido can leverage other models for ROI detection, includ-
ing Selective Search [85] and Faster R-CNN [72], which
may be implemented by the platform already. For instance,
eye-tracking platforms, such as Hololens [59], provide certain
context information that Kaleido can use directly for perfor-
mance optimization. Additionally, smart calibration of the
frequency of key frame detection can also reduce the over-
head of context processing.
Optimizations for privacy budget allocation. In this paper,
the presented composition theorem (Theorem 2) is based
on the simple k-fold composition of the DP guarantee [21].
However, a tighter analysis might be possible via advanced
composition [21] and moment-based accounting [1].
Evaluation of other utility metrics. In this paper, we pri-
marily focus on qualitatively evaluating Kaleido’s utility for
the use case of a real-time game (as demonstrated in Section
7). However, as mentioned in Section 2.2, eye-tracking data
is used for diverse purposes. Hence, an important future direc-
tion is to investigate user perception for other online applica-
tions and quantitatively evaluate Kaleido’s utility for ofﬂine
gaze data analysis (Kaleido’s impact on ﬁxation saliency maps
is presented in Appendix A.2.3). Another direction could be
exploring application-speciﬁc utility optimizations. For in-
stance, data-smoothing techniques can be used to improve the
accuracy of the noisy gaze streams.
9 Conclusion
We have designed and implemented Kaleido, an eye gaze pro-
cessing system that (1) provides a formal privacy guarantee on
the spatial distribution of raw gaze positions, (2) seamlessly
integrates with existing eye-tracking ecosystems, and (3) is
capable of operating in real-time. Kaleido acts as an interme-
diary protection layer between the eye-tracking platform and
the applications. Our evaluation results show that users enjoy
a satisfactory level of utility while deploying Kaleido for an
interactive eye-tracking game. Additionally, it is successful in
thwarting real-world spatio-temporal attacks on gaze streams.
Acknowledgments
We thank our user study participants, the anonymous review-
ers, and the shepherd, Apu Kapadia, for their contributions
and valuable suggestions. This project is supported in part
by NSF under grants 1719336, 1845469, 1838733, 1942014,
2003129, and 1931364.
References
[1] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov,
K. Talwar, and L. Zhang. Deep learning with differential pri-
vacy. In ACM CCS, 2016.
[2] J. M. Abowd and I. M. Schmutte. An economic analysis of
privacy protection and statistical accuracy as social choices.
American Economic Review, 109(1):171–202, 2019.
[3] A. Açık, A. Sarwary, R. Schultze-Kraft, S. Onat, and P. König.
Developmental changes in natural viewing behavior: bottom-
up and top-down differences between children, young adults
and older adults. Frontiers in Psychology, 1:207, 2010.
[4] I. Agtzidis, M. Startsev, and M. Dorr. 360-degree video gaze
behaviour: A ground-truth data set and a classiﬁcation algo-
rithm for eye movements. In ACM MM, 2019.
[5] M. E. Andrés, N. E. Bordenabe, K. Chatzikokolakis, and
C. Palamidessi. Geo-indistinguishability: Differential privacy
for location-based systems. In ACM CCS, 2013.
[6] E. Arabadzhiyska, O. T. Tursun, K. Myszkowski, H. Seidel,
and P. Didyk. Saccade landing position prediction for gaze-
contingent rendering. ACM TOG, 36(4):1–12, 2017.
[7] K. Bannier, E. Jain, and O. Le Meur. Deepcomics: Saliency
estimation for comics. In ACM ETRA, 2018.
[8] W. Becker and A. F. Fuchs. Further properties of the human
saccadic system: eye movements and correction saccades with
and without visual ﬁxation points. Vision Research, 9(10):1247–
1258, 1969.
[9] S. A. Beedie, D. M. St. Clair, and P. J. Benson. Atypi-
cal scanpaths in schizophrenia: evidence of a trait-or state-
dependent phenomenon?
Journal of Psychiatry & Neuro-
science, 36(3):150, 2011.
[10] S. Berkovsky, R. Taib, I. Koprinska, E. Wang, Y. Zeng, J. Li,
and S. Kleitman. Detecting personality traits using eye-
tracking data. In ACM CHI, 2019.
[11] A. Borji, D. N. Sihite, and L. Itti. Quantitative analysis of
human-model agreement in visual saliency modeling: A com-
parative study. IEEE TIP, 22(1):55–69, 2012.
[12] E. Bozkir, O. Günlü, W. Fuhl, R. F. Schaefer, and E. Kasneci.
Differential privacy for eye tracking with temporal correlations.
arXiv:2002.08972, 2020.
[13] E. Bozkir, A. B. Ünal, M. Akgün, E. Kasneci, and N. Pfeifer.
Privacy preserving gaze estimation using synthetic images via
a randomized encoding based framework. arXiv:1911.07936,
2019.
[14] F. Broz, H. Lehmann, B. Mutlu, and Y. Nakano. Gaze in
Human-Robot Communication, volume 81. John Benjamins
Publishing Company, 2015.
[15] Z. Bylinskii, T. Judd, A. Oliva, A. Torralba, and F. Durand.