### 优化后的文本

#### 表4. 外包计算
**我们的私有云的工作负载**
| 参考序列 | Chr1 (3) | Chr22 (3) | 全基因组 (3) | Chr1 (6) | Chr22 (6) | 全基因组 (6) |
| --- | --- | --- | --- | --- | --- | --- |
| **哈希种子** (h:m:s, 1 核) | 0:1:3 | 0:1:4 | 0:1:8 | 0:6:33 | 0:5:26 | 0:6:1 |
| **扩展** (h:m:s, 1 核) | 0:1:16 | 0:0:38 | 0:10:41 | 0:12:22 | 0:4:9 | 2:37:27 |
| **内存 (GB)** | 1.85 | 1.47 | 6.92 | 3.71 | 3.13 | 8.97 |
| **上传 (GB)** | 0.72 | 0.72 | 0.72 | 5.07 | 5.07 | 5.07 |
| **下载 (MB)** | 11.18 | 11.11 | 17.83 | 74.93 | 74.96 | 120.71 |
| **工作负载** (h:m:s, 8 核/节点) | 0:31:10 (1 节点) | 0:3:52 (1 节点) | 0:14:1 (20 节点) | 0:59:23 (1 节点) | 0:13:29 (1 节点) | 0:26:43 (30 节点) |
| **上传 (GB)** | 0.81 | 0.81 | 0.81 | 0.81 | 0.81 | 0.81 |
| **下载 (MB)** | 11.32 | 11.52 | 15.16 | 998.06 | 402.46 | 1456.14 |
| **外包比例 (%)** (*估计值) | 99.1 | 94.5 | 99.5 * | 96.1 | 91.1 | 97.5 * |

#### 基准数据准备（一次性成本）
| 参考序列 | Chr22 (6) | 全基因组 (6) | Hash Reference |
| --- | --- | --- | --- |
| **排序哈希 l-mers** (h:m:s, 8 核/节点) | 0:6:54 (5 节点) | 0:2:12 (5 节点) | 0:23:53 (20 节点) |
| **生成 (GB)** | 5.7 | 0.9 | 79.6 |
| **播种** (h:m:s, 8 核/节点) | 0:5:29 (5 节点) | 0:5:22 (5 节点) | 0:6:12 (20 节点) |

#### 计算时间 (h:m:s)
| 参考序列 | Chr22 (6) | 全基因组 (6) | Hash Reference |
| --- | --- | --- | --- |
| **单核** | 0:3:33 | 0:0:29 | 1:1:13 |
| **8 核** | 0:51:48 | 0:10:11 | 11:20:7 |

#### 结果与讨论
在实验中，我们设置了Java虚拟机的最大堆内存大小为1.6GB，既用于运行CloudBurst的云实例，也用于我们方法中的播种任务。结果表明，我们的方法比CloudBurst消耗更少的内存，因为CloudBurst需要保留额外的信息用于扩展。

**扩展性能（每个数据集）**  
基于匹配种子或组合的扩展任务非常小，即使在全基因组和距离为6的情况下，我们的桌面计算机也仅用了约两个半小时完成扩展。为了了解我们的方法将多少工作负载外包到公共云，我们在桌面上尝试运行CloudBurst（使用8个核心）。对于Chr1和Chr22参考序列，至少91%的计算被外包，即使考虑到准备种子哈希值的时间。然而，在单台机器上运行整个基因组的CloudBurst是不可能的，因此我们查看了其在公共云上的性能。具体来说，对于距离为6的情况，CloudBurst在30个8核节点上花费了大约26分钟来映射所有1000万个读取，而我们的私有云仅用1个节点1个核心花费了163分钟，包括哈希种子的时间。因此，我们估计超过97%的工作负载被卸载到了公共云。

**通信开销（每个数据集）**  
我们发现我们的方法的通信开销非常小。上传到公共云的最大数据量为5.07 GB（包括1000万个读取的组合种子哈希值），这在我们的40 MBps链路上只需几分钟即可传输。从公共云下载的数据量仅为120.71 MB。相比之下，如果整个映射任务由CloudBurst在没有隐私保护的情况下在公共云上完成，则需上传约0.81 GB数据，并下载1.42 GB数据。需要注意的是，我们的方法只需要下载相对少量的匹配种子组合数据，而不是整个计算的结果。

**讨论**  
我们原型的整体计算时间（在公共云和私有云上花费的时间总和）对于距离为6的全基因组映射任务约为372 CPU小时，这大约是不进行任何隐私保护的情况下使用CloudBurst进行整个计算所需时间的3.5倍。现有的所有隐私保护技术[17, 18, 20, 33, 35]在读映射问题上的性能远不及此。在EC2上，这项计算仅需花费26美元（基于预留Cluster Compute EC2实例的价格估算[1]，其计算能力与我们使用的云节点相当）。在这种费用下，无需购买和维护一个240核集群，一台台式机就足以完成全部工作。

#### 相关工作
**安全外包基因组计算**  
大多数提出的基因组计算安全外包技术集中在新的密码原语[17, 21, 35]。例如，一种计算编辑距离的协议[17]通过同态加密和盲传输在多个服务器之间协作计算动态规划矩阵的每个元素。这种方法被发现需要5分半钟来计算大小为(25, 25)的实例[35]。另一个例子是针对DNA序列比对的优化SMC[35]，它利用动态规划的特殊特性来提高SMC的性能。与[17]相比，该方法效率更高，完成上述任务只需约14秒。进一步改进的SMC[33]可以在4秒内对齐两个100元素的序列。尽管如此，这些开销仍难以扩展到比较数百万个读取与数百万至数十亿个l-mer的规模。最近的研究进展包括无意识自动机评估[20]，它只需要O(n)次模幂运算来处理n个元素的序列。然而，这种性能仍然无法支持读映射的规模。另一种近期提案[14]试图通过打乱某些核苷酸来“伪装”DNA序列，从而产生多个版本的序列并让多个服务器对其进行计算。然后，客户端分析这些计算的结果以恢复序列与l-mer之间的编辑距离。这种方法的问题在于服务器需要在每次比对时与客户端通信，使其可扩展性存疑。

**其他安全外包技术**  
早期的安全外包研究主要集中在将密码操作（如模幂运算）委托给一组不可信的帮助者[31, 41]。最近的研究除了安全计算编辑距离外，还包括线性代数运算[16]和机器学习任务[24]。例如，Peer-for-Privacy将一类数据挖掘算法分解为向量加法步骤，并将其分布到云上的多个节点，通过特殊的秘密共享方案进行安全评估[24]。然而，这些方法可能不适合计算编辑距离，并且在计算过程中会产生大量的通信开销。

#### 结论
本文提出了一套新的技术，实现了混合云上的安全和可扩展读映射。我们的方法利用了读映射任务只关心小编辑距离的特点以及云计算擅长处理大量简单计算的特点。这些特点使我们能够根据种子扩展策略分割映射计算：播种阶段在大量密文上执行简单的计算（精确匹配），由公共云承担；扩展阶段涉及相对复杂的计算，但数据量非常小。

希望这些修改能使您的文档更加清晰、连贯和专业。如有进一步的需求，请随时告知。