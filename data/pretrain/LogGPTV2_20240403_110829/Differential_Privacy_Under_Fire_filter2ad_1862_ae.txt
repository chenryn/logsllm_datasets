8.4 Microbenchmarks
To get a better picture of what factors inﬂuence the per-
formance of our implementation, we added instrumenta-
tion in such a way that query time can be attributed to
one of the following ﬁve phases:
• P1: Computation performed by a microquery;
• P2: Waiting for the preemption when a microquery
completes early;
• P3: Preemption handling, storing results, restoring
checkpoints, and loading the next row;
• P4: Padding the time of the preemption handler to
∆a + ∆d; and
partition might contain all the N rows. Thus, functions
that operate on the partitions are padded to 3 · N times
the timeout, when in fact N times would be sufﬁcient.
This could be avoided by extending Fuzz with a suitable
operator, e.g., a GroupBy as in PINQ.
8.5 Adversarial queries
As explained in Section 5.4, Fuzz rules out state attacks
and privacy budget attacks by design, and it prevents tim-
ing attacks by enforcing that each microquery takes pre-
cisely the time speciﬁed by its timeout. This last point
cannot be perfectly achieved by a practical implementa-
tion running on real hardware; we need to quantify how
close our implementation comes to this goal.
To this end, we implemented ﬁve adversarial queries,
exploiting different variants of the attacks from Section 3
to try to vary the completion time based on whether or
not some speciﬁc individual is in the database:
• P5: Computation performed by the macroquery.
• weblog-delay adds an artiﬁcial delay in each micro-
Figure 6 shows our results (we omit the time P5 taken
by the macroquery because it was below 0.2% of the to-
tal for all queries). As already suggested by the previous
section, the majority of the time is spent in either the
waiting or the padding phase. This may seem rather con-
servative at ﬁrst, but recall that the completion time of
even a non-adversarial microquery can vary with the row
it is processing; the timeout needs to be sufﬁcient for the
longest query with high probability. Timeout handling,
deallocation, checkpointing, and storing the results takes
comparatively little time.
Note that the overhead for the kmeans query is con-
siderably higher than for the others. This is because
kmeans repeatedly uses split to partition the database –
speciﬁcally, to map each point to the nearest of the three
cluster centers. Since our proof-of-concept implementa-
tion is not keeping track of the fact that the union of the
three partitions contains exactly the N rows in the orig-
inal database, it must conservatively assume that each
query that ﬁnds a match;
• weblog-term adds an artiﬁcial delay except when a
microquery ﬁnds a match;
• weblog-mem consumes a lot of memory when a
matching individual is found;
• weblog-gc creates a lot of garbage on the heap by
repeatedly allocating and releasing memory;
• census-delay looks for a particular known person in
the database and adds a timing delay if their income
is above a speciﬁed threshold.
We ran each query on two versions of the corresponding
database: one that contains the individual (Hit) and an-
other that does not (Miss). To demonstrate the effective-
ness of these attacks on an unprotected system, we ﬁrst
performed the experiment with Fuzz runtime and then
repeated it with the original Caml Light runtime. This
gives us four conﬁgurations per query. We ran 100 trials
13
Query
Attack type
Garbage creation
weblog-mem Memory allocation
weblog-gc
weblog-delay Artiﬁcial delay
weblog-term
census-delay
Early termination
Artiﬁcial delay
Hit
Caml Light runtime (not protected)
|Hit−Miss|
1.644 s
1.249 s
1.303 s
0.006 s
1.271 s
Miss
0.317 s
0.318 s
0.318 s
26.384 s
0.897 s
1.961 s
1.567 s
1.621 s
26.378 s
2.168 s
Fuzz runtime (protected)
Hit
1.101 s
1.101 s
1.101 s
1.101 s
2.404 s
Miss
1.101 s
1.101 s
1.101 s
1.101 s
2.404 s
|Hit-Miss|
<1 µs
<1 µs
<1 µs
<1 µs
<1 µs
Table 4: Effect of various attacks without and with predictable transactions. Each adversarial query tries to vary
its completion time based on whether some speciﬁc individual is in the database. We show the total macroquery
processing times when the individual is present (hit) and absent (miss), as well as the differences.
for each conﬁguration, after a warm-up phase of two tri-
als to ensure that the Fuzz binary and the database were
in the ﬁle system caches.
Figure 7 shows how the completion times varied
across the 100 trials, using the weblog-delay query with
the Miss database as an example. With the original
runtime, the completion times varied by approximately
±150 µs around the median. With the Fuzz runtime,
the completion times are extremely stable: the difference
between maximum and minimum was <1 µs. The re-
sults for the other queries were similar, indicating that
Fuzz’s padding mechanism successfully masks internal
variations between trials. Hence, we only report median
values here.
Table 4 shows our results for the different conﬁgura-
tions. We make the following three observations. First,
the attacks are very effective when protections are dis-
abled. For four out of the ﬁve queries, the completion
times for the Hit cases were at least one second different
from the completion times for the Miss cases, so an ad-
versarial querier could easily have distinguished between
the two cases and thus learned with certainty whether or
not the individual was in the database. We could have
achieved even higher differences simply by changing the
queries. For weblog-term, the difference was only a
few milliseconds; the reason is that, in order to change
the completion time of the query by one second through
early termination, the adversary would have had to make
each microquery take at least one second, so the overall
query would have taken a conspicuously long time – in
this case, nearly three hours.
Second, the attacks cease to be effective in Fuzz. In
each case, the difference between Hit and Miss is so
small we could not even reliably measure it locally on
the machine (for comparison, handling a timer interrupt
requires about 3 µs, and one hundred of these are trig-
gered every second, limiting the achievable accuracy),
much less across a wide-area network, using the small
number of trials that the privacy budget allows.
Third, the completion times are higher when protec-
tions are enabled. This is consistent with our earlier ob-
servations from Section 8.3.
8.6 Summary
Our results show that Fuzz is effective: it eliminates state
and budget channels by design, and narrows the timing
channel to a point where it ceases to be useful to an ad-
versary. Query completion times remain practical but are
substantially higher than in an unprotected system.
9 Related Work
Differential privacy: There is a considerable body of
work on the theory of differential privacy [8–10] and
on differentially private data analysis [20, 26]. Except
for the papers on Airavat [26] and PINQ [20], none of
these papers discuss covert-channel attacks by adversar-
ial queriers. The PINQ paper brieﬂy mentions certain
security issues, such as exceptions and non-termination;
Airavat discusses timing channels, but, as we have shown
in Section 3.5, its defense is not fully effective. The
present paper complements existing work by providing
a practical defense against covert-channel attacks, which
could be applied to existing systems.
Covert channels: Covert channels have plagued sys-
tems for decades [18, 30], and they are notoriously hard
to avoid in general. Fuzz is a domain-speciﬁc solution;
it only addresses differentially private query processing,
but it can give strong assurances in this speciﬁc setting.
A variety of defenses against covert channels have
been suggested. Most related to this paper is the work
on external timing channels. The bandwidth of external
timing channels can be reduced, e.g., by adding random
delays [15, 16] or by time quantization [2]. However, to
guarantee differential privacy, the adversary must be pre-
vented from learning even a single bit of private infor-
mation with certainty, so a mere reduction in bandwidth
is not sufﬁcient in our setting. Fuzz avoids this problem
by converting the timing channel into a storage channel,
which in turn is handled by differential privacy.
Preventing timing channels seems hopeless in the gen-
eral case. Language-based designs can eliminate them
for certain types of programs [1], but only at the expense
of severely limiting the expressiveness of the program-
ming language. Shroff and Smith [27] show how to han-
dle more general computations but may have to abort
14
them, which can result in garbled data and/or leak in-
formation through a storage channel. In the context of a
differentially private query, however, aborting individual
microqueries is safe because the impact on the overall
result is known to be bounded by the sensitivity of the
query. As shown in Section 4.4, returning default val-
ues does not open a new storage channel or increase the
privacy cost of the query (though it may decrease its use-
fulness).
Side channels: Side channels can leak private informa-
tion, e.g., through electromagnetic radiation [13, 24] or
power consumption [17]. Many of these channels can
only be exploited if the adversary is physically close to
the machine that executes the queries, which is not per-
mitted by our threat model.
Real-time systems: Some real-time systems have pro-
visions for handling timer overrun problems in untrusted
code, such as preemption or partial admission [29]. In
our scenario, it would not be sufﬁcient to simply preempt
a microquery that has overshot its timeout—we must be
able to terminate it and clean up all of its side effects be-
fore the timeout expires. Another approach is inferring
the worst-case execution time [28], which is known to be
difﬁcult even for trusted code.
10 Conclusion
We have demonstrated that state-of-the-art systems for
differentially private data analysis are vulnerable to sev-
eral different kinds of covert-channel attacks from adver-
sarial queriers. Covert channels are particularly danger-
ous in this context because the leakage of even a single
bit of private, un-noised information completely destroys
the guarantees these systems are designed to provide. We
analyzed the space of potential solutions, and we pre-
sented the design of Fuzz, which represents one speciﬁc
solution from this space and relies on default values and
predictable transactions. Using a proof-of-concept im-
plementation based on Caml Light, we demonstrated that
Fuzz can be retroﬁtted into an existing language runtime.
Our evaluation shows that Fuzz is practical and expres-
sive enough to support realistic queries. Fuzz increases
query completion times compared to systems without
covert-channel defenses, but the increase does not seem
large enough to prevent practical applications.
Acknowledgments
We thank Jason Reed for his contributions to the early
stages of this project, and Frank McSherry, Vitaly
Shmatikov, Trent Jaeger, Helen Anderson, our shep-
herd Miguel Castro, and the anonymous reviewers for
their helpful comments. This research was supported
in part by ONR Grant N00014-09-1-0770 and by US
National Science Foundation grants CNS-1065060 and
CNS-1054229.
References
[1] J. Agat. Transforming out timing leaks.
In Proc. ACM POPL,
Jan. 2000.
[2] A. Askarov, D. Zhang, and A. C. Myers. Predictive black-box
mitigation of timing channels. In Proc. ACM CCS, Oct. 2010.
A face is exposed for
[3] M. Barbaro and T. Zeller.
AOL searcher No. 4417749.
The New York Times, Aug.
2006. http://select.nytimes.com/gst/abstract.html?
res=F10612FC345B0C7A8CDDA10894DE404482.
[4] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical pri-
vacy: the SuLQ framework. In Proc. PODS, June 2005.
[5] Caml Light website. http://caml.inria.fr/caml-light/
index.en.html.
[6] S. Chawla, C. Dwork, F. McSherry, A. Smith, and H. Wee. To-
ward privacy in public databases. In Proc. TCC, Feb. 2005.
[7] S. Crosby, D. Wallach, and R. Riedi. Opportunities and limits
of remote timing attacks. ACM Transactions on Information and
System Security, 12(3):1–29, 2009.
[8] C. Dwork. Differential privacy. In Proc. ICALP, July 2006.
[9] C. Dwork. Differential privacy: A survey of results. In Proc. 5th
Intl Conf. on Theory and Applic. of Models of Comp., 2008.
[10] C. Dwork. The differential privacy frontier (extended abstract).
In Proc. IACR TCC, Mar. 2009.
[11] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor.
Our data, ourselves: Privacy via distributed noise generation. In
Proc. EUROCRYPT, May 2006.
[12] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating
noise to sensitivity in private data analysis. In Proc. TCC, 2006.
[13] K. Gandolﬁ, C. Mourtel, and F. Olivier. Electromagnetic analysis:
Concrete results. In Proc. CHES, May 2001.
[14] S. Hettich and S. D. Bay. The UCI KDD archive. Univ. of
California Irvine, Dept. of Information and Computer Science,
http://kdd.ics.uci.edu/.
[15] W.-M. Hu. Reducing timing channels with fuzzy time. In IEEE
Symposium on Security and Privacy, May 1991.
[16] M. H. Kang, I. S. Moskowitz, and D. C. Lee. A network pump.
IEEE Trans. Softw. Eng., 22:329–338, May 1996.
[17] P. C. Kocher, J. Jaffe, and B. Jun. Differential power analysis. In
Proc. CRYPTO, 1999.
[18] B. W. Lampson. A note on the conﬁnement problem. Communi-
cations of the ACM, 16:613–615, Oct. 1973.
[19] X. Leroy. The ZINC experiment: An economical implementation
of the ML language. Technical Report 117, INRIA, 1990.
[20] F. McSherry. Privacy integrated queries. In Proc. ACM SIGMOD,
June 2009.
[21] F. McSherry and I. Mironov. Differentially private recommender
systems: Building privacy into the net. In Proc. ACM KDD, 2009.
[22] A. Narayanan and V. Shmatikov. Robust de-anonymization of
large sparse datasets. In Proc. IEEE S&P, May 2008.
[23] PINQ website. http://research.microsoft.com/en-us/
projects/pinq/.
[24] J.-J. Quisquater and D. Samyde. Electromagnetic analysis (ema):
In Proc. Intl.
Measures and counter-measures for smart cards.
Conf. on Research in Smart Cards (E-SMART), Sept. 2001.
[25] J. Reed and B. C. Pierce. Distance makes the types grow stronger:
A calculus for differential privacy. In Proc. ICFP, Sept. 2010.
[26] I. Roy, S. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat:
Security and privacy for MapReduce. In Proc. NSDI, 2010.
[27] P. Shroff and S. F. Smith. Securing timing channels at runtime.
Technical report, The Johns Hopkins University, July 2008.
[28] R. Wilhelm, J. Engblom, A. Ermedahl, N. Holsti, S. Thesing,
D. Whalley, G. Bernat, C. Ferdinand, R. Heckmann, T. Mitra,
F. Mueller, I. Puaut, P. Puschner, J. Staschulat, and P. Stenstr¨om.
The worst-case execution-time problem. ACM Trans. Embed.
Comput. Syst., 7(3):1–53, 2008.
[29] M. Wilson, R. Cytron, and J. Turner. Partial program admission.
In Proc. IEEE Symposium on Real-Time and Embedded Technol-
ogy and Applications (RTAS), Apr. 2009.
[30] J. C. Wray. An analysis of covert timing channels.
In IEEE
Symposium on Security and Privacy, May 1991.
15