### 8.4 Microbenchmarks

To better understand the factors that influence the performance of our implementation, we added instrumentation to attribute query time to one of the following five phases:

- **P1: Computation performed by a microquery.**
- **P2: Waiting for preemption when a microquery completes early.**
- **P3: Preemption handling, including storing results, restoring checkpoints, and loading the next row.**
- **P4: Padding the preemption handler's time to \(\Delta_a + \Delta_d\).**

In some cases, a partition might contain all \(N\) rows. Thus, functions operating on these partitions are padded to \(3 \times N\) times the timeout, although \(N\) times would be sufficient. This inefficiency could be mitigated by extending Fuzz with a suitable operator, such as a `GroupBy` function as in PINQ.

### 8.5 Adversarial Queries

As explained in Section 5.4, Fuzz is designed to prevent state attacks and privacy budget attacks, and it mitigates timing attacks by enforcing that each microquery takes exactly the time specified by its timeout. However, this goal cannot be perfectly achieved in a practical implementation running on real hardware. Therefore, we need to quantify how closely our implementation approaches this ideal.

To this end, we implemented five adversarial queries, exploiting different variants of the attacks described in Section 3, to try to vary the completion time based on whether or not a specific individual is in the database:

- **P5: Computation performed by the macroquery.**
- **weblog-delay**: Adds an artificial delay in each microquery.
- **weblog-term**: Adds an artificial delay except when a microquery finds a match.
- **weblog-mem**: Consumes a lot of memory when a matching individual is found.
- **weblog-gc**: Creates a lot of garbage on the heap by repeatedly allocating and releasing memory.
- **census-delay**: Looks for a particular known person in the database and adds a timing delay if their income is above a specified threshold.

We ran each query on two versions of the corresponding database: one containing the individual (Hit) and another without the individual (Miss). To demonstrate the effectiveness of these attacks on an unprotected system, we first performed the experiment using the Fuzz runtime and then repeated it with the original Caml Light runtime. This resulted in four configurations per query. We conducted 100 trials for each configuration after a warm-up phase of two trials to ensure that the Fuzz binary and the database were in the file system caches.

Figure 6 shows our results (we omit the time taken by the macroquery, P5, because it was below 0.2% of the total for all queries). As suggested by the previous section, most of the time is spent in either the waiting or padding phase. This may seem conservative, but recall that the completion time of even a non-adversarial microquery can vary depending on the row being processed. The timeout must be sufficient for the longest query with high probability. Timeout handling, deallocation, checkpointing, and storing results take comparatively little time.

Note that the overhead for the kmeans query is significantly higher than for the others. This is because kmeans repeatedly uses the `split` function to partition the database, specifically to map each point to the nearest of the three cluster centers. Since our proof-of-concept implementation does not track the fact that the union of the three partitions contains exactly the \(N\) rows in the original database, it must conservatively assume that each partition might contain all \(N\) rows, leading to excessive padding.

### 8.6 Summary

Our results show that Fuzz is effective: it eliminates state and budget channels by design and narrows the timing channel to a point where it ceases to be useful to an adversary. Query completion times remain practical but are substantially higher than in an unprotected system.

### 9 Related Work

**Differential Privacy:**
There is a significant body of work on the theory of differential privacy [8–10] and differentially private data analysis [20, 26]. Except for the papers on Airavat [26] and PINQ [20], none of these papers discuss covert-channel attacks by adversarial queriers. The PINQ paper briefly mentions certain security issues, such as exceptions and non-termination; Airavat discusses timing channels, but, as we have shown in Section 3.5, its defense is not fully effective. This paper complements existing work by providing a practical defense against covert-channel attacks, which could be applied to existing systems.

**Covert Channels:**
Covert channels have been a persistent problem in systems for decades [18, 30] and are notoriously difficult to avoid in general. Fuzz is a domain-specific solution; it only addresses differentially private query processing but provides strong assurances in this specific setting. Various defenses against covert channels have been suggested, most related to external timing channels. The bandwidth of external timing channels can be reduced, e.g., by adding random delays [15, 16] or by time quantization [2]. However, to guarantee differential privacy, the adversary must be prevented from learning even a single bit of private information with certainty, so a mere reduction in bandwidth is insufficient. Fuzz avoids this problem by converting the timing channel into a storage channel, which is handled by differential privacy.

**Preventing Timing Channels:**
It seems hopeless to prevent timing channels in the general case. Language-based designs can eliminate them for certain types of programs [1], but only at the expense of severely limiting the expressiveness of the programming language. Shroff and Smith [27] show how to handle more general computations but may have to abort them, which can result in garbled data and/or leak information through a storage channel. In the context of a differentially private query, however, aborting individual microqueries is safe because the impact on the overall result is known to be bounded by the sensitivity of the query. As shown in Section 4.4, returning default values does not open a new storage channel or increase the privacy cost of the query (though it may decrease its usefulness).

**Side Channels:**
Side channels can leak private information, e.g., through electromagnetic radiation [13, 24] or power consumption [17]. Many of these channels can only be exploited if the adversary is physically close to the machine executing the queries, which is not permitted by our threat model.

**Real-time Systems:**
Some real-time systems have provisions for handling timer overrun problems in untrusted code, such as preemption or partial admission [29]. In our scenario, it would not be sufficient to simply preempt a microquery that has overshot its timeout—we must be able to terminate it and clean up all of its side effects before the timeout expires. Another approach is inferring the worst-case execution time [28], which is known to be difficult even for trusted code.

### 10 Conclusion

We have demonstrated that state-of-the-art systems for differentially private data analysis are vulnerable to several different kinds of covert-channel attacks from adversarial queriers. Covert channels are particularly dangerous in this context because the leakage of even a single bit of private, un-noised information completely destroys the guarantees these systems are designed to provide. We analyzed the space of potential solutions and presented the design of Fuzz, which represents one specific solution and relies on default values and predictable transactions. Using a proof-of-concept implementation based on Caml Light, we demonstrated that Fuzz can be retrofitted into an existing language runtime. Our evaluation shows that Fuzz is practical and expressive enough to support realistic queries. Fuzz increases query completion times compared to systems without covert-channel defenses, but the increase does not seem large enough to prevent practical applications.

### Acknowledgments

We thank Jason Reed for his contributions to the early stages of this project, and Frank McSherry, Vitaly Shmatikov, Trent Jaeger, Helen Anderson, our shepherd Miguel Castro, and the anonymous reviewers for their helpful comments. This research was supported in part by ONR Grant N00014-09-1-0770 and by US National Science Foundation grants CNS-1065060 and CNS-1054229.

### References

[1] J. Agat. Transforming out timing leaks. In Proc. ACM POPL, Jan. 2000.

[2] A. Askarov, D. Zhang, and A. C. Myers. Predictive black-box mitigation of timing channels. In Proc. ACM CCS, Oct. 2010.

[3] M. Barbaro and T. Zeller. A face is exposed for AOL searcher No. 4417749. The New York Times, Aug. 2006. http://select.nytimes.com/gst/abstract.html?res=F10612FC345B0C7A8CDDA10894DE404482.

[4] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: the SuLQ framework. In Proc. PODS, June 2005.

[5] Caml Light website. http://caml.inria.fr/caml-light/index.en.html.

[6] S. Chawla, C. Dwork, F. McSherry, A. Smith, and H. Wee. Toward privacy in public databases. In Proc. TCC, Feb. 2005.

[7] S. Crosby, D. Wallach, and R. Riedi. Opportunities and limits of remote timing attacks. ACM Transactions on Information and System Security, 12(3):1–29, 2009.

[8] C. Dwork. Differential privacy. In Proc. ICALP, July 2006.

[9] C. Dwork. Differential privacy: A survey of results. In Proc. 5th Intl Conf. on Theory and Applic. of Models of Comp., 2008.

[10] C. Dwork. The differential privacy frontier (extended abstract). In Proc. IACR TCC, Mar. 2009.

[11] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy via distributed noise generation. In Proc. EUROCRYPT, May 2006.

[12] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis. In Proc. TCC, 2006.

[13] K. Gandolfi, C. Mourtel, and F. Olivier. Electromagnetic analysis: Concrete results. In Proc. CHES, May 2001.

[14] S. Hettich and S. D. Bay. The UCI KDD archive. Univ. of California Irvine, Dept. of Information and Computer Science, http://kdd.ics.uci.edu/.

[15] W.-M. Hu. Reducing timing channels with fuzzy time. In IEEE Symposium on Security and Privacy, May 1991.

[16] M. H. Kang, I. S. Moskowitz, and D. C. Lee. A network pump. IEEE Trans. Softw. Eng., 22:329–338, May 1996.

[17] P. C. Kocher, J. Jaffe, and B. Jun. Differential power analysis. In Proc. CRYPTO, 1999.

[18] B. W. Lampson. A note on the confinement problem. Communications of the ACM, 16:613–615, Oct. 1973.

[19] X. Leroy. The ZINC experiment: An economical implementation of the ML language. Technical Report 117, INRIA, 1990.

[20] F. McSherry. Privacy integrated queries. In Proc. ACM SIGMOD, June 2009.

[21] F. McSherry and I. Mironov. Differentially private recommender systems: Building privacy into the net. In Proc. ACM KDD, 2009.

[22] A. Narayanan and V. Shmatikov. Robust de-anonymization of large sparse datasets. In Proc. IEEE S&P, May 2008.

[23] PINQ website. http://research.microsoft.com/en-us/projects/pinq/.

[24] J.-J. Quisquater and D. Samyde. Electromagnetic analysis (EMA): Measures and counter-measures for smart cards. In Proc. Intl. Conf. on Research in Smart Cards (E-SMART), Sept. 2001.

[25] J. Reed and B. C. Pierce. Distance makes the types grow stronger: A calculus for differential privacy. In Proc. ICFP, Sept. 2010.

[26] I. Roy, S. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for MapReduce. In Proc. NSDI, 2010.

[27] P. Shroff and S. F. Smith. Securing timing channels at runtime. Technical report, The Johns Hopkins University, July 2008.

[28] R. Wilhelm, J. Engblom, A. Ermedahl, N. Holsti, S. Thesing, D. Whalley, G. Bernat, C. Ferdinand, R. Heckmann, T. Mitra, F. Mueller, I. Puaut, P. Puschner, J. Staschulat, and P. Stenström. The worst-case execution-time problem. ACM Trans. Embed. Comput. Syst., 7(3):1–53, 2008.

[29] M. Wilson, R. Cytron, and J. Turner. Partial program admission. In Proc. IEEE Symposium on Real-Time and Embedded Technology and Applications (RTAS), Apr. 2009.

[30] J. C. Wray. An analysis of covert timing channels. In IEEE Symposium on Security and Privacy, May 1991.