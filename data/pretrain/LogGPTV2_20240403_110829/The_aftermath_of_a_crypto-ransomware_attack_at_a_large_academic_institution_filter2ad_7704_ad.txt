ing’, especially being in ﬁrst-year. You just see people
frustrated. [Students] want to get in touch with the pro-
fessors but having no way, and did not know how else to
contact them. People were just losing their minds” (U9).
Interviewees also worried, “do they have any of my
personal information? Are they going to get employee
information?”
(S6). The uneasiness caused them to
avoid their ﬁnancial accounts because they were unsure
of the extent of the attack. For example, a student said,
“my dad sent me money at that time, but I was not able to
check my bank because I was really too scared to check
it. I didn’t even check it like after a week or so” (U2).
Our assessment was that most interviewees recovered
from the attack, and that the personal and social impact
was signiﬁcant but mostly temporary. A staff sums up:
S4: Looking back, at the end of the day, all the
stuff was really just anxiety based. I coincidently
had a doctor’s appointment around that time and
my blood pressure was really high. . . I was anx-
ious about the fact that I lost work and people
weren’t able to email me, then there was a whole
rush of people that needed to talk to me, and I was
anxious about [catching up].
In these data excerpts, interviewees recounting their
experiences by voicing anxieties, frustrations, and fears.
Interviewees shifted between talking about technological
effects, to describing incidental effects like loss of pro-
ductivity, then to talking about the emotional toll. Our
data suggests that effects of cyber-attacks on users are
complex, multifaceted, and difﬁcult to measure.
A sense of belonging to a community: The attack
caused resentment and damaged users’ relationship with
the university. Interviewees saw themselves as “belong-
ing to” and “a part of” a larger community (U9). How-
ever, with respect to this incident, participants felt that
they “didn’t have a role in the situation” (G1), and that
their opinions did not matter. “We weren’t asked about
how we felt about the situation”, a staff said (S6). It ap-
pears that most resentment came from a perceived lack
of transparency and clear communication about what had
happened. Many interviewees were dissatisﬁed that they
found out about the ransomware attack through rumours
and news reports instead of from the university directly.
A staff member argued,
S6: There’s nothing wrong with saying we’ve
been hijacked. Hearing it on [the news] before
you hear it from the campus higher-ups, it’s like
“why is there such a secrecy?”
Instead of feeling that the university community was
working together to solve the problem, interviewees felt
sidelined and kept in the dark. “It was kind of like we
didn’t have a role in this situation. We were just kind of
the people that were affected and [we should] stay out of
the way” (G1). Some believed that “each person should
be allowed to make the decision” about paying the ran-
som to recover his or her data (S7). A graduate student
resented how infected computers were handled.
G1: The IT guy from our department came in
after we had all left for the night, came in and
wiped every [infected] computer in the lab. To
our knowledge, there hadn’t been a resolution [at
USENIX Association
27th USENIX Security Symposium    1069
the time] about whether [the university] was go-
ing pay or not, and they just made the executive
decision to delete everything. We were upset be-
cause that made it ﬁnal, like we are never getting
these ﬁles back. They never gave us the choice.
They never gave us the option.
Clearly, affected interviewees were upset at being ex-
cluded from the decision-making process, and this dam-
aged their sense of belonging to the university commu-
nity. Data lost may have been inevitable, but this high-
lights how an organization’s handling of an incident can
impact its strong sense of community.
7.2 Security Practices
We noted many common misconceptions about security
best practices, suggesting a need for more proactive cy-
bersecurity training geared towards the university com-
munity and customized to the needs of different users.
As an example, we highlight discussion about backing
up data, which was particularly relevant to this incident.
One faculty detailed intentionally avoiding the univer-
sity’s network drives to save important ﬁles, believing
that their workstation’s local hard drive was safer, and
gave an interesting analogy to explain their reasoning:
F2: I had about sixty ﬁve reports [...], and the
safest place for me to keep them was on that drive,
on my own computer, because it’s supposed to be
password protected and have all the security [...]
So I kept it on there and it’s all gone.
If
somebody broke in [to the ofﬁce] and stole the
ﬁles in the old days, then the stuff was gone and
nobody would scream at them because they didn’t
make photocopies of them and take them home!
[...]
Several interviewees were rethinking their backup and
storage strategies. Some who were previously using
cloud services and automatic syncing were reconsider-
ing, while others decided that they would now be “vigi-
lant in getting various copies of everything that you need,
in different areas. Backing up everything like crazy.”
(S2). Others had lost conﬁdence in the university infras-
tructure and vowed to store data off-campus instead.
7.3 Communication
Many believed that the main cause of dissatisfaction and
frustration among faculty, staff, and students was not the
cyber-attack itself, but how the situation was communi-
cated. A staff explained, “everybody understands that
stuff happens, but communication is key.
if you’re not
telling people what is going on, that is creating a whole
other level of panic” (S11). A large part of interviewees’
retelling of their experiences revolved around communi-
cation, highlighting it as a critical.
7.3.1 Communicating during an incident
In the event of a cyber-attack, interviewees believed that
it is extremely important to notify the university com-
munity about the situation promptly and as accurately as
possible. Instead of being forthcoming, interviewees felt
the university “hid behind this terminology of ‘network
interruption’, which is not really accurate” (S8). Users
were instructed to “disconnect everything” and “shut ev-
erything down” (S3), but no details were provided about
why. A student recounted:
U4: On the ﬁrst day when I walked into the li-
brary and there was a sign saying, “Don’t use the
WI-FI – Don’t use the computers”; it didn’t say
why. I heard some people in front of me say “Oh
whatever, I’m still going to use the computer, I
don’t care”. I think if they had known it was be-
cause of malware they deﬁnitely wouldn’t have
wanted to use it. . . Maybe they didn’t want people
to panic or to worry, but if people are going to lis-
ten I think it’s important to give them that knowl-
edge so they understand why they don’t want you
to use it.
These accounts highlight the necessity of informing
people about the risks and vulnerabilities when instruct-
ing people what to do. Furthermore, providing users with
vague or inaccurate information may cause them to un-
dermine the seriousness of the problem. Others felt the
notiﬁcation came too late: “we’re working in the library
and then we’re told that we can’t go on to the WI-FI. I
had already been on the WI-FI. . . so I started to panic”
(U8). Another student recalled, “they told me not to log
in on the lab computers or log in to [the university] ser-
vices [...], but at that point, it was already too late because
I already did” (U3).
Interviewees thought that the little information pro-
vided by the university was “vague”, “cryptic”, and “un-
helpful”. The update “didn’t really tell a lot of useful
information,” that enabled people “to make decisions”
(S7). Employees wanted answers to questions such as
“can I turn my computer on?” or “can we work?” (S1).
Not having the information made people “very cautious”,
and they kept their computers shut-off longer than re-
quired (S10), adding to the loss of productivity.
While informing users about cyber-attacks, intervie-
wees identiﬁed that users should be provided with “a
standard set of procedures” (S12) to follow, and action-
able instructions about what they should do. For exam-
ple, a tutorial leader said, “I didn’t know if I should actu-
ally tell my students not to open their laptops. . . It was a
1070    27th USENIX Security Symposium
USENIX Association
blur, like I didn’t know what should I do and what should
I not do” (U1). A staff said, “we all received the very
bizarre coded messages from the central university that
never really explained what to do” (S10). Similarly, a
faculty recalled“getting directions at some point to not to
turn [her] computer on, but then was ‘told to go ahead
and go home and everything will be ﬁne’ . . . “All I knew
was it wasn’t working” she continued, and “it took a few
days before anybody told me if you do come in don’t
try to sign on. And again, that was pretty much word-
of-mouth” (F2).
Interviewees expected useful updates
at set intervals from the university. The updates should
keep the users “in the loop” (S8) about progress, how and
when the university will resolve the issue, what resources
are open, and what users should do. They also wanted to
know when life could return to normal:
G1: Still to this day to be honest, I don’t feel
like there was ever an end. There was [notiﬁca-
tions] like ‘we are working on the situation. We
are working on the situation. Ok you can connect
again’. It was never like ‘It’s over.’ So it’s all very
much like it’s never really ended.
7.3.2 Planning ahead
Interviewees voiced a need for a detailed cyber-response
plan that mapped out the ﬂow of communication from
the top administration to the school departments, and to
the members of the university community, including full-
time and part-time faculty, staff, and students. It is crit-
ical that the plan covers scenarios when all online and
network services are down. Some believed that a cyber-
response plan could be coordinated between computing
services and campus security to ensure immediate alter-
native lines of communication. The broader university
community should be aware of this plan so that they
know what to expect when an incident occurs.
7.4 Paying the ransom
The interviewees recognized that paying or not paying
the ransom is a moral, ethical, and pragmatic dilemma.
They showed deep sympathy for those who lost data. A
staff empathized, “I’m not a researcher and I don’t have
anything important on my desktop, but I would hate to
think that all of my lifelong work was lost and there
wouldn’t be some sort of accountability to the university
on doing whatever they can to provide it” (S9).
On a pragmatic level, some believed that the decision
to pay the ransom would be a matter of weighing the
costs, such as the cost of data, the cost of downtime, and
the cost of rebuilding. A staff explained:
S7: if you had a high reliability that if you paid
you would get your stuff back, then it becomes
simply a cost: the cost of paying to get it back
directly versus the cost of the money and energy
that has been spent in the interim trying to bring
things back and to ﬁx things. I ﬁgure I’ve proba-
bly effectively lost about three weeks of work in
terms of time spent either recovering stuff and not
being able to do my real job.
A graduate student further explained this rationale:
G1: When you look at the sum of money [the at-
tackers] were looking for, it doesn’t sound like a
lot to an organization. Yes, you are paying do-
mestic terrorists; yes, you are giving in to it, but
when you look at the amount of money that you
spent on getting this research done — the amount
of money you put into the research, the amount
of money in grants that the university has worked
hard to get, and that they’ve lost all that data and
all of that research. It seems counterproductive to
just not pay off the ransom.
Through explanations like this, some interviewees ar-
gued that the decision on whether to pay the ransom
could be based on a calculation of productivity costs
weighed against the ransom amount. Although this line
of thinking seemed practical, these participants also rec-
ognized that the decision to pay a ransom is much more
complex than a simple monetary transaction.
In the end, however, most interviewees agreed with
the university’s decision to not pay the ransom. Many
interviewees, particularly those who were not affected
by data loss, appeared to be convinced that the ethical
principles outweigh the pragmatic considerations. Many
believed it is ethically wrong to pay criminals, and that
paying would encourage more criminal activity because
it is a demonstration of weakness and sets precedence
for other attacks. Some described paying the ransom as a
“band-aid” solution because “giving in to these types of
demands doesn’t actually solve the problem” in the long
run (S13). Several compared their rationale to why gov-
ernments will not pay ransoms for hostages. Addition-
ally, most believed that criminals cannot be trusted, and
there is no guarantee that the data will be returned, un-
altered, and not copied for malicious use. The university
could also risk the attacker asking for a higher ransom.
Interview Summary
7.5
The attack signiﬁcantly hindered students, faculty, and
administrative staff’s ability to do work for several days
and the remnant of impact was felt for weeks after the
attack. However, the personal and social impact was
possibly more severe than the technological impact. In-
terestingly, the emotional toll on users was only par-
USENIX Association
27th USENIX Security Symposium    1071
tially caused by the direct effects of the ransomware at-
tack. Other variables, such as lack of communication and
transparency led to decreased morale, trust, and a feeling
of disconnectedness by the members of the university.