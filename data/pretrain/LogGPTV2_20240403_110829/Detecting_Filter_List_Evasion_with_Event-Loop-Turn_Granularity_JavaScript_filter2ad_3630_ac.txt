elements interacted with by Google Analytics.
security related events to consist solely of (i) storage events,10
because of their common use in tracking, and (ii) network
events,11 since identiﬁers need to be exﬁltrated at some point
for tracking to occur. We note that
there are other types
of events that could be considered here, such as browser
ﬁngerprinting-related APIs, but reserve those for future work.
As an example, Figure 3 shows a (simpliﬁed) subgraph of
the larger graph from Figure 1, depicting what the Google
Analytics script did during a single event loop turn: accessing
cookies several times (storage events), reading the browser
user-agent string, creating and modifying an  element
(and thus sending out network requests), etc.
At a high level, to extract event-loop signatures from a
PageGraph generated graph, we determined which JavaScript
operations occurred during the same event-loop turn by look-
ing for edges with sequential ids in the graph, all attached to
or descending from a single script unit. As a page executes,
control switches between different script units (or other actions
on the page); when one script yields its turn on the event
loop, and another script begins executing, the new edges in a
graph will no longer be attached to the ﬁrst script, but to the
newly executing one. Event-loop turns are therefore encoded
in the graph as subgraphs with sequential edges, all related
to the same script node. We discuss some limitations of this
approach, and why we nevertheless preferred it to possible
alternatives in SectionVI-E.
More formally, we build signatures of privacy-and-security
affecting JavaScript behavior using the following algorithm:12.
(i) Extract all edges in the graph representing a privacy-
effecting JavaScript operation (as noted in Table I).
(ii) Attribute each of these edges to the JavaScript unit
responsible. If no script is responsible (e.g., a network
request was induced by the parser), abort.
10i.e. cookies, localStorage, sessionStorage, IndexedDB
11both direct from script (e.g., AJAX, fetch) and indirect (e.g., )
12This description omits some implementation speciﬁc details and post-
processing techniques that are not fundamental to the approach. They are
fully documented and described in our shared source code [5]
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
1719
PageGraphSignaturescriptcookie jarDate.nowsetTimeoutNavigator.userAgentHTML Element(iii) Extract the maximum subgraph containing the relevant
edge and responsible JavaScript code unit comprising all
sequentially occurring nodes and edges. This is achieved
by looking for edges that neighbor the subgraph, and
which occurred immediately before (or after) the earliest
(or latest) occurring event in the subgraph. If an edge is
found, add it and the attached nodes to the subgraph.
(iv) Repeat step 3 until no more edges can be added to the
subgraph.
Once each subgraph is extracted, a hash representation
is generated by removing any edges that represent non-
deterministically ordered events (again, see Table I), chrono-
logically ordering the remaining edges and nodes, concatenat-
ing each elements’ type (but omitting other attributes), and
hashing the resulting value. This process yields a SHA-256
signature for the deterministic behavior of every event-loop
turn during which a JavaScript unit carried out at least one
privacy-relevant operation.
C. Privacy Behavior Ground Truth
Next, we need a ground truth set of privacy harming
signatures, to build a set of known privacy-harming JavaScript
behaviors. We then use this ground truth set of signatures
to look for instances where the same privacy-harming code
reoccurred in JavaScript code not blocked by current content
blockers, and thus evaded detection.
We used EasyList and EasyPrivacy to build a ground truth
determination of privacy-harming JavaScript behaviors. If a
script was identiﬁed by an EasyList or EasyPrivacy ﬁlter rule
for blocking, and was not excepted by another rule, then
we considered all the signatures generated from that code as
privacy-harming, and thus should be blocked. This measure
builds on the intuition that ﬁlter rules block known bad
behavior, but miss a great deal of additional unwanted behavior
(for the reasons described in Section II). Put differently, this
approach models ﬁlter lists as targeting behaviors in code units
(and that they target URLs as an implementation restriction),
and implicitly assumes that ﬁlter lists have high precision but
low (or, possibly just lower) recall in identifying privacy-and-
security harming behaviors.
To reduce the number of JavaScript behaviors falsely la-
beled as privacy harming, we removed a small number of
ﬁlter list network rules that blocked all script on a known-
malware domain. This type of rule does not target malicious
or unwanted resources, but all the resources (advertising and
tracking related, or otherwise) fetched by the domain. As these
rules end up blocking malicious and benign resources alike,
we excluded them from this work. An example of such a rule
is $script,domain=imx.to, taken from EasyList.
D. Determining Privacy-Harming Signatures
To generate a collection of signatures of privacy-harming
JavaScript behaviors on the web, we combine our algorithm
that extracts event-loop signatures (Section III-B), with the
ground truth of privacy-harming behaviors given by EL/EP
(Section III-C). Speciﬁcally, we produce this collection of
signatures by visiting the Alexa top 100K websites and
recording their graph representations (one graph per visited
website), using our PageGraph-enhanced browser. For each
visited website, we gather from its graph representation every
script unit executing on the page, including remote scripts,
inline scripts, script executing as JavaScript URLs, and scripts
deﬁned in HTML attributes. We then extracted signatures of
JavaScript behavior during each event loop turn, and recorded
any scripts that engaged in privacy-relevant behaviors.
Next, we omitted signatures that were too small
to be
highly identifying from further consideration. After an iterative
process of sampling and manually evaluating code bodies with
signature matches, we decided to only consider signatures that
consisted of at least 13 JavaScript actions (encoded as 13
edges), and interacting with at least 4 page elements (encoded
as nodes, each representing a DOM element, JavaScript builtin
or privacy-relevant Web API endpoint).
This minimal signature size was determined by starting with
an initial signature size of 5 edges and 4 nodes, and then
doing a manual evaluation of 25 randomly sampled matches
between signatures (i.e., cases where the same signature was
generated by a blocked and not-blocked script). We had our
domain-expert then examine each of the 25 randomly sampled
domains to determine whether the code units actually included
the same code and functionality. If the expert encountered a
false positive (i.e., the same signature was generated by code
that was by best judgement unrelated) the minimum graph
size was increased, and 25 new matches were sampled. This
process of manual evaluation was repeated until the expert did
not ﬁnd any false positives in the sampled matches, resulting
in a minimum graph size of 13 edges and 4 nodes.
Finally, for scripts that came from a URL, we noted whether
the script was associated with advertising and/or tracking,
as determined by EasyList and EasyPrivacy. We labeled all
signatures generated by known tracking or advertising scripts
as privacy-harming (and so should be blocked by a robust
content blocking tool). We treated signatures from scripts not
identiﬁed by EasyList or EasyPrivacy, but which matched a
signature from a script identiﬁed EasyList or EasyPrivacy,
as also being privacy-harming, and so evidence of ﬁlter list
evasion. The remaining signatures (those from non-blocked
scripts, that did not match a signature from a blocked script)
were treated as benign. The results of this measurement are
described in more detail in Section IV.
IV. RESULTS
In this section we report
the details of our web-scale
measurement of ﬁlter list evasion, generated by applying the
techniques described in Section III to the Alexa 100K. The
section proceeds by ﬁrst describing the raw website data
gathered during our crawl, then discusses the number and size
of signatures extracted from the crawl. The section follows
with measurements of how this evasion impacts browsing
(i.e., how often users encounter privacy-and-security harming
behaviors that are evading ﬁlter lists) and concludes with
measurements of what web parties engage in ﬁlter list evasion.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
1720
Measurement
Crawl starting date
Crawl ending date
Date of ﬁlter lists
Num domains crawled
Num domains responded
Num domains recorded
Value
Oct 23, 2019
Oct 24, 2019
Nov 2, 2019
100,000
88,035
87,941
TABLE II
STATISTICS REGARDING OUR CRAWL OF THE ALEXA 100K, TO BOTH
BUILD SIGNATURES OF KNOWN TRACKING CODE, AND TO USE THOSE
SIGNATURES TO IDENTIFY NEW TRACKING CODE.
We then ﬁltered the above set of generated raw event-loop
signatures to those matching the following criteria:
1) Contained at least one privacy-or-security relevant event
(deﬁned in Section III-B3)
2) Occurred at least once in a script blocked by EasyList or
EasyPrivacy (i.e., a blocked script)
3) Occurred at least once in a script not blocked by EasyList
and EasyPrivacy (i.e., an evaded script).
4) Have a minimum size of 13 edges and 4 nodes (see
Section III-D)
A. Initial Web Crawl Data
We began by using our PageGraph-enhanced browser to
crawl the Alexa 100K, which we treated as representative
of the web as a whole. We automated our crawl using a
puppeteer-based tool, along with extensions to PageGraph to
support the DevTools interface 13.
For each website in the Alexa 100K, our automated crawler
visited the domain’s landing page and rested for 60 seconds to
allow for sufﬁcient time for scripts on the page to execute. We
then retrieved the PageGraph generated graph-representation
of each page’s execution, encoded as a GraphML-format XML
ﬁle.
Table II presents the results of this crawl. From the Alexa
100K, we got a successful response from the server from
88,035 domains, and were able to generate the graph repre-
sentation for 87,941. We attribute not being able successfully
crawl 11,965 domains to a variety of factors, including bot
detection scripts [18], certain sites being only accessible
from some IPs [36], [6], and regular changes in website
availability among relatively unpopular domains. This number
of unreachable domains is similar to those found by other
automated crawl studies [32], [21]. A further 4,286 domains
could not be measured because they used browser features
that PageGraph currently does not correctly attribute (most
signiﬁcantly, module scripts).
B. Signature Extraction Results
Next, we run our signature generation algorithm (Sec-
tion III-B) on the graph representation of the 87,941 websites
that we crawled successfully from the Alexa top 100K. In total
this yielded 1,995,444 “raw” event-loop signatures from all the
encountered scripts (of these 1,995,444 generated signatures,
400,166 are unique; the same script can be included in multiple
websites and thus generate the same signatures for those
websites). Overall, the average number of signatures generated
for a website is 22.70, with a standard deviation of 22.92.
The maximum number of signatures generated for a website
is 368, while 6,281 out of the 87,941 crawled websites did not
generate signatures. On the other hand, the average number of
signatures generated from a single script unit is 2.54 (that is,
the average from scripts that did generate signatures), with
a standard deviation of 2.59. In our dataset, the maximum
number of signatures generated from a script is 302.
13https://chromedevtools.github.io/devtools-protocol/
This ﬁltering resulted in 2,001 unique signatures. We refer
to this set of signatures as ground truth signatures. Our goal
here is to focus only on the signatures of behaviors that are
identiﬁed by EasyList and EasyPrivacy as privacy-harming,
but also occur in other scripts not blocked by these ﬁlter lists.
Note that this ﬁltering implies that an evaded script is identiﬁed
as long as at least one of its event-loop signatures matches
one from the scripts blocked by EasyList and EasyPrivacy
(i.e., we do not need multiple signature matches to conﬁrm
an evaded script). Also, recall from Section III-D that we
impose a lower bound (13 edges and 4 nodes) on the signature
size determined manually by our domain expert in order to
reduce false positives (and hence the fourth requirement in
our ﬁltering criteria above). If we remove the restriction on
the minimum signature size, then the above ﬁltering would
give us a total of 5,473 unique signatures (i.e., 3,472 were
discarded as too small).
Table III summarizes the scripts from which our signature
generation algorithm (Section III-B) produced at least one
signature in our ground truth set, both in total and broken
down according to whether they are blocked by EasyList and
EasyPrivacy. For comparison, we also show the corresponding
statistics for the 3,472 signatures that we discarded as too
small. Not surprisingly, the discarded small signatures were
found in more scripts than our ground truth set. This is because
the speciﬁcity of a signature is proportional to the number
of script actions that it registers (e.g., a signature consisting
of only one storage write operation would be found in many
scripts that use the local storage API).
For our purposes we prefer precision over recall, by utilizing
expert domain knowledge to set a reasonable cut-off signature
size. Notice that our approach is optimized towards minimiz-
ing false positives, which means that the behavior of the script
needs to be expressive enough (have enough edges/nodes) to
indicate privacy-harming behavior (see §III-D). Small signa-
tures are less expressive, so they resulted in our experiments in
matching more scripts, which include both true/false positives.
Figure 4 shows the distribution of the number of unique
signatures in our ground truth set that were found in scripts
on each visited domain in our crawl of the Alexa top 100K
(56,390 domains have at least one script where signatures from
our ground truth set were found), as well as the distribution
of the number of unique ground truth signatures in each script
unit where such signatures were found. As we did in Table III,
for comparison here we also plot the same statistics for the
small signatures.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
1721
Scripts generating relevant signatures (unique)
Scripts blocked by EL/EP (total)
Scripts blocked by EL/EP (unique)
External scripts not blocked (total)
External scripts not blocked (unique)
Inline scripts not blocked
Total unique scripts not blocked (external + inline)
# Scripts Matched by
Ground Truth Signatures
14,801
68,278
11,212
11,546
3,091
498
3,589
# Scripts Matched
by Small Signatures
195,727
145,500
45,327
133,153
82,483
67,917
150,400
THE NUMBER OF SCRIPTS WHOSE BEHAVIORS MATCH SIGNATURES FROM OUR GROUND TRUTH SET, BOTH IN TOTAL AND BROKEN DOWN BY WHETHER
THEY ARE BLOCKED BY EL/EP. FOR COMPARISON WE ALSO SHOW THE SAME STATISTICS FOR THE DISCARDED SMALL SIGNATURES.
TABLE III
Fig. 4. Distribution of the number of signatures per domain and the number
of such signatures in each matched script unit for our ground truth dataset
and for the small signatures dataset.
In total, our ground truth signatures identiﬁed 3,091
new unique external script URLs (11,546 instances) hosting
known-harmful behavior, but missed by ﬁlter lists, an increase
in 27.57% identiﬁed harmful URLs (when measured against
the number of scripts only identiﬁed by ﬁlter lists and which
contain the ground truth signatures). These evading scripts
were hosted on 2,873 unique domains. In addition to these
evaded external scripts, our signatures also matched inline
scripts. Inline scripts are those whose JavaScript source is
contained entirely within the text content of a script tag,