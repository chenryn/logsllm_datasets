presented in Figure 3. For the sample collection, we query
both public and private repositories of malware and different
intelligence feeds as described in §III-A. We make a number
of sanity checks for each sample to ensure that we only feed
crypto-mining malware to our pipeline (see §III-B). We also
collect OSINT related to running botnets and relevant Indica-
tors of Compromise (IoCs) observed in malware samples.
A key phase in our pipeline is to analyze relevant samples
both statically and dynamically as described in §III-C (Binary,
Sandbox, and Network Analysis in Figure 3). The goal of this
multi-step phase is to extract the following information from
each miner: (i) the pool or address which the crypto-mining
malware connects to for mining, and the identiﬁer used to
authenticate themselves into this pool, (ii) the addresses of
the e-wallets where mined cryptocoins are paid to3, which
in most cases coincide with the identiﬁer, (iii) URLs where
the malware connects to or is seen at, and (iv) other metadata
obtained from intelligence feeds such as when the sample was
ﬁrst seen or related samples (e.g., dropped binaries).
The next step is to analyze the mining pools that the miners
work with. We decouple connections made to proxies (that in
turn connect to pools) from the connections to the actual pools.
We then look at the proﬁt reported by each of the wallets in a
pool. These two steps are described in §III-D and are referred
to as Proﬁt Analysis in Figure 3.
Finally, we aggregate related samples into campaigns and
analyze them separately in the Aggregation step as described
in §III-E. For this, we create a graph which interconnects
crypto-mining malware that: (i) share a common execution
ancestor (i.e., dropper) or are packed together, (ii) accumu-
late their earnings into the same wallet, (iii) share common
infrastructure (e.g., proxies or hosting servers), or (iv) relate
to the same IoC related with mining campaigns — gathered
both from OSINT reports and our own investigation. We then
enrich every interconnected sub-graph (campaign) to include
details about related infrastructure used in each campaign (i.e.,
stock mining software or Pay-Per-Install services).
A. Data Gathering
We collect malware samples, metadata and OSINT infor-
mation, and known mining tools from various sources.
Malware. We rely on public and private feeds from:
1) Virus Share. This is an online community that shares
torrents to malicious binaries. We use it to gather our
initial dataset of raw binaries.
2) Virus Total. This is an online service containing both
publicly and privately available services to the security
community through an API (Application Programming
Interface). This service is a subsidiary of Google that runs
multiple AntiVirus (AV) engines and offers an unbiased
access to resulting reports. We use the private API to
download malware binaries. We then query the public
3The terms address and wallet are used interchangeably in the literature.
4
Fig. 3: Overview of our processing pipeline and measurement methodology.
API to obtain relevant threat intelligence (which we refer
to as metadata in the paper). In particular, we collect
metadata from the samples obtained through queries
to Virus Total, but also from all the samples obtained
through other sources listed in this section.
3) Hybrid Analysis. This is an online community pro-
viding malicious binaries and threat intelligence obtained
from static and dynamic analysis of the samples. Thus, we
use this community to fetch readily available intelligence
when possible.
4) Other Sources. We have developed a crawler to fetch
samples from a variety of online communities such as
malc0de.com or vxvault.net. Our pipeline also aggregates
malware feeds from cybersecurity companies. For the
purpose of this paper, we have received feeds from Palo
Alto Networks with miners known to them.
Refer to Appendix C for details about the dataset overlaps.
Metadata. When available, we primarily rely on the following
metadata to put our study in context: (i) the ﬁrst time the
sample was seen in the wild, (ii) the URLs where the sample
was seen, (iii) the list of parents that are known to have
dropped the binary under analysis, and (iv) the list of contacted
domains.
Stock Mining Software. We also collect binaries from known
mining frameworks, such as xmrig4 or xmr-stak5, that are
hosted in various public repositories. While these binaries are
not badware per se, their usage is deemed malicious when run
by malware. Our assumption is that the usage of proprietary
software to mine is not the norm. Anecdotal evidence observed
during the course of a preliminary investigation has shown that
miscreants rely on legitimate — open-source — mining tools.
The modus operandi of the malware is to fetch one of these
tools (i.e., acting as a dropper) and run it in infected machines.
Mining is conﬁgured with the wallet of the miscreant, where
4https://github.com/xmrig/xmrig
5https://github.com/ﬁreice-uk/xmr-stak
5
the rewards are paid by the network. One of our goals then
is to understand if this assumption holds true and how many
campaigns are using stock mining software illicitly.
Summary. Our data collection registers over 4.5 million
samples (see §IV-A for a breakdown), which have been active
between early 2007 and early 2019. This includes about 1K
versions of known mining tools from 13 different frameworks.
Our initial data contains a wide-range of samples, many of
which are irrelevant to this study (e.g., web-based cryptojack-
ers). Thus, we next describe the rules we use to consolidate
the dataset where we report our ﬁndings with.
B. Sanity Checks
One important aspect when systematizing the analysis of
malware is properly curating the dataset [23]. We perform
the following sanity checks for each sample processed: (i) is
it malware? (ii) is it a miner?, and (iii) is it an executable
sample?
First, we rely on Virus Total reports to learn if a sample is
malware. Virus Total have been shown to perform remarkably
well when providing malware feeds according to a recent
comparative analysis of Threat Intelligence [24]. In particular,
Virus Total was able to detect 99.94% of the threats over one of
the largest non-targeted6 malware aggregators. We assume that
a sample is malware if at least 10 AV vendors ﬂag the sample
as malicious. While this is a common practice in other works
in the area [25], [26], [27], we acknowledge that having a solid
ground-truth is essential (see discussion in §VI). Thus, we use
a white-list with the hashes of known mining tools, to ensure
that they are not considered as malware samples in our study.
This white-list is compiled from binaries collected from var-
ious online open-source repositories. A wallet extracted from
a malware sample is considered an ‘illicit’ wallet throughout
6Meaning that they target malware threats to generic platforms. Other
targeted malware aggregators focus on threats that speciﬁcally target platforms
like Facebook and “that are not as relevant to most Virus Total users” [24].
AggregationBinaryAnalysisMalwarefeedsNetworkAnalysisSandboxAnalysisIs	Malware?Is	Miner?Is	Executable?•Wallets•PoolsMining PoolsCampaignAnalysisProfit	AnalysisMetadata•URLs•Parents•DomainsCampaigns	&	ProfitOSINTour dataset. Therefore, we exceptionally keep samples with
less than 10 AV positives when it contains an illicit wallet.
Second, we assume a malware is a crypto-mining tool when
there are IoCs that reveal activity related to mining, such
as connections made through the Stratum protocol or DNS
resolutions for web mining pools. To this end, we apply
publicly available YARA rules7 to our samples. Additionally,
we compare OSINT information related to known mining
campaigns with IoCs extracted from the samples (e.g., ﬁle
hashes or network data). We also use advanced queries from
Virus Total and Hybrid Analysis to look for malware that
meet the following criteria: (i) samples that contact domains
of known mining pools, (ii) communicate through the Stratum
protocol, and (iii) are labeled as “Miner” (or related variants)
by more than 10 AVs.
Finally, to understand whether a malware is executable, we
rely the magic number from its header, and consider only those
related to executables like PE, ELF or JARs. §VI provides
discussion of the limitations behind these assumptions.
C. Extraction of Pools and Wallets
With our dataset of crypto-mining malware, we rely on:
1) Static Analysis: we perform binary inspection to extract
evidences of mining activity embedded into the binary.
2) Dynamic Analysis: we then use environmental informa-
tion obtained from the execution of
the binary in a
sandbox. Speciﬁcally, we obtain the network trafﬁc, the
dropped ﬁles, processes opened, and command line pa-
rameters passed to the binaries. When available, we rely
on reports provided by Virus Total and Hybrid Analysis
through their API service.
In some cases we are able to ﬁnd identiﬁers (e.g., wallets or
emails) and pool names using static analysis. In other cases, we
rely on dynamic analysis to extract these identiﬁers from the
network activity or the command line processes. In both cases,
we process the output of these two analyses using heuristics
and regular expressions to extract the following information:
Cryptocurrency wallets. Miners connect to the pools using
the Stratum protocol [20]. Upon connection to the pool, they
send a request-for-work packet with the identiﬁer of the miner
in a ‘login’ parameter. This identiﬁer can be extracted from
the command line options passed to the mining tool or directly
from the network trafﬁc. We also process the type of wallet
to understand the cryptocurrency (e.g.: Monero, Bitcoin or
Ethereum) the malware is intending to mine.
Mining pools. We collect additional
information such as
domains and IPs of mining pools and proxies. Similarly to
wallet addresses, this information is typically extracted from
either the command line of the process invoking the mining
tool or from the network trafﬁc. Typically, miners connect to
a known pool.8 In some cases, the miner either uses a proxy
7https://github.com/Yara-Rules
8We consider known pools as those listed in public sources, e.g.: http:
//moneropools.com/ or http://www.blockchain.com/pools.
or mines against a private/unknown pool.9 We consider that
a miner is using a proxy if we record mining activity for the
corresponding wallet in a known pool (see §III-D).
D. Collecting Mining Activity
One of the main challenges when measuring the impact
of the malicious crypto-mining campaigns is the difﬁculty to
accurately estimate the proﬁts. In the case of browser-based
cryptojacking, recent works use estimations of the number
of visitors per hour for similar websites and the average
hashrate of a single visitor (victim) [9], [8], [28]. This is
highly inaccurate as evidenced by the variances reported by
concurrent related works (see §VII). In the case of crypto-
mining malware, the actual wallet which the mining reward
is paid to can be extracted. We leverage public information
obtained from mining pools (which include total reward paid
to wallets) to get a more approximate estimation of the proﬁts.
For all the extracted wallets, we queried the most prevalent
mining pools to collect activity associated with these wallets.
While the amount of information offered by each pool varies,
it always contains the timestamp of the last share, the current
(last) hashrate and the total amount of currency paid to the
wallet. Additionally, some pools also provide the historic
hashrate of the wallet and the list of payments done to the
wallet (including timestamp and amount). While the total paid
is always available, some pools only provide payment data
for the last period (e.g. a week or month). Since we are
interested on studying how the payments evolve across time,
we use public APIs to collect this information periodically for
a period of 10 months (July’18-April’19). As a single wallet
can use more than one mining pool, we queried all the wallets
against all the pools. Then, to estimate proﬁts, we aggregate
all the payments sent by the pools to the wallets. In general,
we report payments using XMR. To ease readability we also
report the equivalent in US dollars (USD). However, we note
that we do not have information about when the criminals
have cashed-out their earnings (if ever). Thus, it is hard to
extract an exact ﬁgure in USD (and other currencies) due
to the ﬂuctuations on the value of Monero. To approximate
this value, we dynamically extract the exchange rate between
XMR and USD of the date when the payments were made, if
available. We use the average exchange rate of 54 USD/XMR
in cases where historical payments are unavailable.
E. Campaign Analysis
Two major limitations in related works are: i) the simplicity
in which they analyze related mining campaigns, and ii) the
inability to study anonymous cryptocurrencies such as Monero
(as discussed in §XII). Thus,
in this work, we aggregate
samples into campaigns following a novel methodology that
leverages various characterizing features observed in the wild.
We emphasize that
the methodology we use to aggregate
samples into campaigns is novel. We also note that our
methodology admits a wide range of features.
9While the use of private pools is encouraged in certain underground
communities, we have observed few samples using private pools.
6
Spreading Infrastructure. We distinguish two types of infras-
tructure used to spread the malware: one that can be owned
and another one that belongs to a third-party and can be rented
(e.g., botnets that are monetized as PPI services and that are
used for mining). When available, we link samples to known
botnets by querying OSINT information with IoCs extracted
from the samples. We refrain from using these botnets to
aggregate samples as we detail later. However, we use them to
enrich the information of the campaigns in a post-aggregation
phase. This way, we can draw conclusions about the number
of campaigns using known third-party infrastructure. However,
since we rely on public intelligence feeds, a limitation of
this approach is that samples using unknown third-party in-
frastructure (e.g., offered in underground markets) might be
aggregated together in a single campaign. In these cases, we
can guarantee that the campaign runs on top of the same
infrastructure. This is relevant to law enforcement agencies
when devising take-downs strategies. Thus, our analysis con-
siders campaigns that are either from the same actor or a
group of actors that use the same infrastructure, independently
from the monetizing approach used by the operators of the
infrastructure that spreads the samples. Analyzing whether
proﬁts from a campaign are given to a single actor or a group
of actors is out of the scope of this paper.
Grouping Features. We rely on the following features to
group samples into campaigns:
Same identiﬁer: In order to get rewards from the mining pools,
workers must mine using a unique identiﬁer, which in most
cases corresponds with the wallet address to which payments
are made. In other cases, these are e-mails or other identiﬁers,
like user-generated names. If two samples contain the same
identiﬁer, it means that they are accumulating earnings in the
same wallet and thus they are grouped together. Some mining
tools contain donation wallets to reward the developer, which
is done by mining for a certain time (typically 2-5%) using the
donation wallet. While this is conﬁgurable and can be turned
off, we have observed a few samples doing donations. We note
that the CPU cycles donated are also hijacked from the victim
and therefore inﬂict harm to her. However we are primarily
interested in measuring the earnings of the miscreants, and
thus donation addresses are excluded from the aggregation.
For this reason, we create a white-list by manually extracting
donation wallets from known mining software repositories.
We also enrich our white-list using Google searches (e.g.,
looking for “Monero” and “donation”) and manually analysing
the results. We have white-listed 14 donation wallets directly
obtained from the developers’ sites. Due to limitations in
the manual extraction process, we could be missing dona-
tion wallets. This can result in the over-aggregation of two
independent campaigns as discussed in §VI. Non–white-listed
donation wallets display a characterizing pattern: the same
wallet (the donation wallet) appears together with different
wallets (from the miscreants) in multiple samples across our
dataset. However, we do not observe this pattern after white-
listing all donation wallets we account for. This suggest that
we have effectively white-listed all donation wallets.
Ancestors: In many cases, the same sample is used to down-
load additional malware. This is the case of droppers, which
adapt based on information gathered from the infected host,
e.g.: operating system or processor capabilities. Accordingly,
if a sample is parent of two samples with different wallets,
these are grouped together. Ancestors and other dropped
ﬁles that are not directly intended for mining are considered
auxiliary binaries and we refer to them as ancillaries.
This includes samples that do not have a wallet.
Hosting servers: We use metadata from the samples to extract
the URL from where the malware was downloaded. A com-
mon approach is to host the malware (or even stock mining
software) in public cloud storage sites such as Amazon Web
Services (AWS), Dropbox or Google Drive (see §IV-B). Thus,
we aggregate two samples if either they are downloaded from
the same IP address which does not resolve to a domain from
a public repository, or if they are downloaded from exactly the
same URL, e.g: hxxp://suicide.mouzze.had.su/gpu/amd1.exe.
We also include the parameters to avoid those cases where
a parameter is used to uniquely identify the resource being
hosted, e.g.hxxp://ﬁle8desktop.com/download/get56?p=19363.
This approach has as limitation that we are not aggregating
resources where a URL contains ephemeral information (e.g.,
timestamps or click-IDs), even when they point to the same
resource in the server. However, this limitation is partially
overcome due to other sources for aggregation.
Known mining campaigns: As mentioned, we collect IoCs
(e.g., domains or wallets) from mining operations reported
publicly. We look at IoCs that are known to belong to a
given mining operation, and look for matches against samples
in our dataset. We group two samples if they belong to the
same operation. In our analysis, we have collected IoC for the
following mining operations: Photominer [29], Adylkuzz [18],
Smominru [17], Xbooster [30], Jenkins [31] and Rocke [32].
However, our methodology is designed to easily include data
collected from new operations.
Domain aliases (CNAMEs): During our investigation, we
observed many samples using domain aliases (i.e., CNAMEs)
that resolve to known mining pools. In these cases, miscreants
create one or various subdomains for a domain under their
control, and set these subdomains to be aliases of known
mining pools. Since the resolution is done for the CNAME
rather than for the mining pool, they thwart defenses black-
listing mining pools (see §VI for a discussion on anti-analysis
techniques). To address this evasion method, we perform DNS
requests for all the domains extracted from our samples, and
look for responses pointing to known mining pools from
a CNAME. Since CNAMEs might have changed, we also
query a DNS history-resolution service provided by AlienVault
(https://www.threatcrowd.org) Accordingly, we aggregate sam-
ples using the same domain alias.
Mining proxies: Mining using a large number of machines
(i.e., more than 100) with the same wallet raises suspicion of
botnet usage, and mining pool operators might opt to ban the
7
miner. To prevent this situation, offenders use mining proxies
that gather all the shares from the different bots and forward
the aggregated to the pool. Thus, pool operators only receive
responses from a single machine, the proxy. As described
in §III-C, we identify various samples using proxies. We
aggregate together samples that use the same proxy.
Aggregation. To measure the number of related campaigns
and how they are structured, we build a graph where nodes are
elements of a given resource (e.g., malware samples, proxies,
or wallets) and the edges are determined by the relationships
mentioned above. We consider each connected component of
the graph as a single campaign, where the internal nodes of
the graph represent the crypto-mining malware together with
the infrastructure used by the campaign.
Enrichment. After the aggregation, we enrich each campaign
with samples related to known Pay Per Install (PPI) services,
and mining tools. We emphasize that these features are only
informative and they are not used to aggregate campaigns. We
next explain the rationale behind this.
Botnets and PPI: A common approach to spread malware is
through PPI services, where customers pay a fee to botnet