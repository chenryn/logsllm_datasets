of data points in D indexed by I[s] (Line 7). The update
function leverages a suitable optimizer implementing a variant
of gradient descent. T records the updated model Wt for every
k steps (Line 11), hence k is a parameter called checkpointing
interval and 1
k is then the checkpointing frequency. To ensure
that the PoL proof will be verified with the same data points
as it was trained on, T includes a signature of the training
data (Line 9) along with the data indices (Line 8).
D. PoL Verification
Algorithm 2 shows the PoL verification process. V first
checks if W0 was sampled from the required distribution
using a statistical test (Line 1). Once every epoch, V records
the distances between each two neighboring models in mag
(line 7-9); sort mag to find Q largest distances and verify the
corresponding models and data samples via verifyEpoch
(Line 12-13). Notice that there are at most (cid:4) S
each epoch, hence Q ≤(cid:4) S
(cid:5) distances in
In the verifyEpoch function, V first loads the batch of
indexes corresponding to the data points used to update the
model from Wt to Wt+k. Then, it attempts to reproduce Wt+k
by performing a series of k updates to arrive at W ′
t+k. Notice
t+k ̸= Wt+k due to the noise arising from the hardware
that W ′
and low-level libraries such as cuDNN [7]. The reproduction
error for the t-th model is defined as:
(cid:5).
k
k
εrepr (t) = d(Wt+k, W ′
t+k),
end
(cid:5)
S
return fail
return fail
if et = e + 1 then
et =(cid:4) t
if t mod k = 0 ∧ t ̸= 0 then
mag.append(d(W[t], W[t − k]))
idx ← sortedIndices(mag,↓)
if verifyEpoch(idx) = fail then
Algorithm 2: PoL Verification (taken from [12])
Input: P(T , fWT ), D, k, E, S, ζ
Output: success / fail
1 if verifyInitialization(W[0]) = fail then
2
3 end
4 e ← 0
5 mag ← {}
6 for t = 0 → T − 1 do
7
8
9
10
11
12
13
14
15
16
17
18 end
19 return success
20
21 function verifyEpoch(idx)
22
23
24
25
26
27
28
29
30
31
32
33
34 end
for q = 1 → Q do
t := idx[q − 1]
verifyDataSignature(H[t], D[I[t]])
t ← W[t]
W ′
for i = 0 → (k − 1) do
It+i ← I[t + i]
t+i+1 ← update(W ′
W ′
end
if d(W ′
t+k, W[t + k]) > δ then
end
e ← et, mag ← {}
t+i, D[I[t + i]])
return fail
end
end
end
maxt(εrepr (t)) ≪ dref ,
T , W 2
T and W 2
T ) is the distance between two models
where dref = d(W 1
T trained with the same architecture, dataset, and
W 1
initialization strategy, but with different batching strategies
and potentially different initial model weights. A verification
threshold δ that satisfies:
maxt(εrepr (t))  δ do
R ← zeros
← − ∂
▽W ′
L(fW ′
∂W ′
Dt−1 ← d(W ′
t−1 + η▽W ′
R ← R − η′▽RDt−1
t ← update(W ′
W ′
end
H.append(h(D[I[t − 1]]))
updateDataPoints(Wt−1, WT )
(X + R), y)
, Wt) + d(R, 0)
t−1, (X + R, y))
t−1, (X, y))
t−1
t−1
t−1
t−1
25
26
27
28
29
30 end
end
D[I[t − 1]] := (X + R, y)
(X + R) to fW ′
(line 25).
Next, A optimizes R by minimizing the following distance
(line 26-27):
and gets the gradients ▽W ′
t−1
t−1
Dt−1 ← d(W ′
t−1 + η▽W ′
t−1
, Wt) + d(R, 0).
This distance needs to be differentiable so that R can be
optimized using standard gradient-based methods2. Notice that
this optimization requires 2nd order derivatives. We assume
that fW is twice differentiable, which holds for most modern
machine learning models and tasks.
Clearly, the PoL spoof P(A, fWT ) = (W, I, H) generated
by Attack I can pass the verification process described in
Algorithm 2. It requires T ′ times of update (Line 21) plus
N times of adversarial optimization (Line 23-27) (where N
is the times that the while loop runs). Recall that our focus
is stochastic spoofing: the PoL proof generated by A is not
2Specificly, we use L-BFGS for adversarial optimization.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:51 UTC from IEEE Xplore.  Restrictions apply. 
1411
exactly the same as the one provided by T , but can pass the
verification. Therefore, we can use a T ′ that is much smaller
than T . However, N could be large and sometimes even cannot
converge. Next, we show how we optimize the attack so that a
small N is able to make the adversarial optimization converge.
B. Attack II
The intuition for accelerating adversarial optimization is to
sample the intermediate model weights in a way s.t.:
d(Wt, Wt−k) ≤ δ, ∀ 0  γ do
i , (X, y))
L(fW ′
i
i
i
(X + R), y)
i
end
D[I[i]] := (X + R, y)
28
29
30
31
32
33
34 end
end
i , (X + R, y))
Algorithm 4 shows Attack II. We highlight the key differ-
ences (compared to Attack I) in blue.
This time, A initializes W0 via initW0 (line 2), which en-
sures that W0 follows the given distribution ζ, and minimizes
d(W0, WT ) at the same time. It works as follows:
1) Suppose there are n elements in WT , A puts these
elements into a set S1. Then, A samples n elements:
v1, ..., vn from the given distribution ζ, and puts them
into another set V2.
2) A finds the largest elements w and v from S1 and S2
respectively. Then, A puts v into W0 according to w’s
indices in WT .
3) A removes (w, v) from (S1, S2), and repeats step 2) until
S1 and S2 are empty.
Our experimental results show that this process can initialize
a W0 that meets our requirements.
For other Wts (t > 0), A can initialize them by equally
dividing the distance between W0 and WT . If the number
of steps for spoofing (i.e., T ′) is large enough (i.e., there
are enough Wts), the condition “d(Wt, Wt−k) ≤ δ” can be
trivially satisfied.
Another major change in Attack II is that A optimizes the
noise R by minimizing the following distance (line 27):