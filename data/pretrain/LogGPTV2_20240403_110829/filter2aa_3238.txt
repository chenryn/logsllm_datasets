# Intelligent Fuzzing: Quantifying the Impact of Input Choice on Fuzzing Effectiveness
**Charles Miller, Independent Security Evaluators, August 3, 2007**

## Abstract
This paper explores the effectiveness of different fuzzing techniques, specifically comparing mutation-based and generation-based fuzzing. We aim to quantify the statement, "Intelligent fuzzing usually gives more results," as posited by Ilja van Sprundel, and to understand the importance of input selection in mutation-based fuzzing.

## Table of Contents
1. Introduction
2. Portable Network Graphics (PNG)
3. libpng
4. Mutation vs. Generation-Based Fuzzing
5. Conclusions

## 1. Introduction
- **Statement Analysis**: "Intelligent fuzzing usually gives more results" - Ilja van Sprundel.
- **Objective**: To quantify this statement and evaluate the significance of input choice in mutation-based fuzzing.

## 2. Fuzzing Overview
- **Definition**: Fuzzing involves generating test cases such as files, network traffic, command line arguments, and environment variables.
- **Purpose**: These test cases should be similar to real program inputs but contain anomalies to challenge programmer assumptions and uncover bugs.
- **Process**: Test cases are fed into the target application, which is monitored for faults.

## 3. Methods of Generating Test Cases
### 3.1. Mutation-Based Fuzzing (Dumb Fuzzing)
- **Description**: Modify existing valid inputs, such as files, by altering bytes, adding strings, or inserting special characters.
- **Advantages**: Easy and fast, no knowledge of the program or protocol required.
- **Disadvantages**: Dependent on the quality and variety of existing inputs.

### 3.2. Generation-Based Fuzzing (Intelligent Fuzzing)
- **Description**: Generate inputs based on protocol documentation (e.g., RFCs).
- **Process**: For each field, introduce anomalies like long strings, negative numbers, or special characters.
- **Advantages**: More thorough, covers all possible fields.
- **Disadvantages**: Time-consuming, requires complete knowledge of the program or protocol.

## 4. Portable Network Graphics (PNG)
- **Structure**: PNG files start with an 8-byte signature followed by chunks.
- **Chunk Structure**: Each chunk includes a 4-byte length field, a 4-byte type field, optional data, and a 4-byte CRC checksum.
- **Chunk Types**: 18 standard chunk types, 3 mandatory, and additional types defined in extensions (libpng recognizes 21 types).

### 4.1. Sample PNG File
- [Insert sample PNG file structure here]

### 4.2. Analysis of PNG Files from the Internet
- **Data Collection**: 1631 unique PNG files were collected.
- **Processing**: Recorded the chunk types present in each file.
- **Statistics**:
  - Mean number of chunk types per file: 4.9
  - Standard deviation: 1.3
  - Maximum: 9
  - Minimum: 3

### 4.3. Distribution of Chunks Found
- **Observations**:
  - On average, only five chunk types are present in a random file.
  - 9 out of 21 chunk types occurred in less than 5% of files.
  - 4 chunk types never occurred.
  - Mutation-based fuzzers will typically only test code from these five chunks and will not fuzz code in absent chunks.

## 5. libpng
- **Overview**: libpng is an open-source PNG decoder used in Firefox, Opera, and Safari.
- **Objective**: Verify that each chunk type has unique processing code.
- **Method**:
  - Generate PNGs containing the 3 mandatory and one additional chunk type.
  - Use gcov to record code coverage while processing fuzzed versions of these files (approximately 1000 files per type).

### 5.1. Code Coverage for Each Chunk Type
- **Results**:
  - Some chunk types require more code for processing.
  - The 4 chunk types not found in the wild represent 76% more code than a minimal PNG.
  - This code will not be fuzzed using a mutation-based method.

## 6. Experiments
### 6.1. Experiment 1: Mutation-Based Fuzzing
- **Setup**: Ran a mutation-based fuzzer starting from 3 PNGs with varying numbers of chunk types.
- **Test Cases**: 100,000 test cases per file.
- **Results**: Code coverage varies significantly based on the initial input.

### 6.2. Experiment 2: Correcting CRCs
- **Setup**: Used the same fuzzer and starting file as Experiment 1, but ensured CRCs were correct before testing.
- **Test Cases**: 100,000 test cases.
- **Results**: Improved code coverage compared to Experiment 1.

### 6.3. Experiment 3: Generation-Based Fuzzing
- **Setup**: Used SPIKEfile and the PNG specification to generate fuzzed PNGs.
- **Coverage**: Fuzzed all 21 chunk types and other fields.
- **Test Files**: 29,511 test files.
- **Results**: Significantly higher code coverage compared to mutation-based fuzzing.

## 7. Results
- **Comparison**:
  - Mutation-based fuzzing is highly dependent on the inputs being mutated.
  - Choosing the right inputs can double the amount of code executed.
  - Generation-based fuzzing is substantially better, executing 2-5 times more code.

## 8. Conclusions
- **Key Findings**:
  - Mutation-based fuzzing's effectiveness is heavily influenced by the initial inputs.
  - Generation-based fuzzing is more comprehensive and effective in this specific case.
- **Limitations**: Results are specific to the fuzzers and file type used.

## 9. Generalization
- **Open Question**: Does this generalize to other file types and protocols?
- **Related Information**:
  - In "Fuzzing: Brute Force Vulnerability Discovery," the authors examined 10,000 SWF files and found significant variation in version distribution.

## 10. Questions
- **Contact**: Please reach out to me at PI:EMAIL for further discussion.

---

**Â© 2005, Independent Security Evaluators**
**www.securityevaluators.com**