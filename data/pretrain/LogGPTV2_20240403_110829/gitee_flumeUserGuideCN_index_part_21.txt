## Log4J Appender直接写到Flume
使用log4j Appender输出日志到Flume Agent 的avro
source上。使用的时候log4j客户端必须要在classpath引入flume-ng-sdk（比如：flume-ng-sdk-1.9.0.jar）.
必需的参数已用 **粗体** 标明。
::: hint
::: title
Hint
:::
说白了就是用log4j直接将日志内容发送到Flume，省去了一般先写入到日志再由Flume收集的过程。
:::
  属性                    默认值   解释
  ----------------------- -------- -----------------------------------------------------------------
  **Hostname**            \--      远程运行着avro source的Flume Agent的hostname
  **Port**                \--      上面这个Flume Agent 的avro source监听的端口
  UnsafeMode              false    如果为true，log4j的appender在发送Event失败时不会抛出异常
  AvroReflectionEnabled   false    是否使用Avro反射来序列化log4j的Event（当log是字符串时不要开启）
  AvroSchemaUrl           \--      一个能检索到Avro结构的url
log4j.properties 文件配置范例：
``` properties
#...
log4j.appender.flume = org.apache.flume.clients.log4jappender.Log4jAppender
log4j.appender.flume.Hostname = example.com
log4j.appender.flume.Port = 41414
log4j.appender.flume.UnsafeMode = true
# 指定一个类的logger输出到Flume appender上
log4j.logger.org.example.MyClass = DEBUG,flume
#...
```
默认情况下，每一个Event都会通过调用
toString()方法或者log4j的layout（如果配置了的话）转换成一个字符串。
如果Event是 *org.apache.avro.generic.GenericRecord* 或
*org.apache.avro.specific.SpecificRecord* 的一个实例，又或者
*AvroReflectionEnabled* 属性设置为 `true`
，Event会使用Avro序列化器来序列化。
使用Avro序列化每个Event效率很低，因此最好提供一个avro
schema的URL，可以被 downstream sink（通常是HDFS
sink）从该URL检索schema。 如果未指定
*AvroSchemaUrl*，则schema将作为Flume header包含在内。
使用Avro序列化Event的log4j.properties配置范例：
``` properties
#...
log4j.appender.flume = org.apache.flume.clients.log4jappender.Log4jAppender
log4j.appender.flume.Hostname = example.com
log4j.appender.flume.Port = 41414
log4j.appender.flume.AvroReflectionEnabled = true
log4j.appender.flume.AvroSchemaUrl = hdfs://namenode/path/to/schema.avsc
# 指定一个类的logger输出到flume appender上
log4j.logger.org.example.MyClass = DEBUG,flume
#...
```
## 负载均衡的Log4J Appender
使用log4j Appender发送Event到多个运行着Avro Source的Flume
Agent上。使用的时候log4j客户端必须要在classpath引入flume-ng-sdk（比如：flume-ng-sdk-1.9.0.jar）。
这个appender支持轮询和随机的负载方式，它也支持配置一个退避时间，以便临时移除那些挂掉的Flume
Agent。 必需的参数已用 **粗体** 标明。
::: hint
::: title
Hint
:::
这是上面Log4j
Appender的升级版，支持多个Flume实例的负载均衡发送，配置也很类似。
:::
  属性                    默认值        解释
  ----------------------- ------------- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  **Hosts**               \--           host:port格式的Flume Agent（运行着Avro Source）地址列表，多个用空格分隔
  Selector                ROUND_ROBIN   appender向Flume Agent发送Event的选择机制。可选值有：`ROUND_ROBIN` （轮询）、 `RANDOM` （随机） 或者自定义选择器的全限定类名（自定义选择器必须继承自 *LoadBalancingSelector*）
  MaxBackoff              \--           一个long型数值，表示负载平衡客户端将无法发送Event的节点退避的最长时间（毫秒）。 默认不启用规避机制
  UnsafeMode              false         如果为true，log4j的appender在发送Event失败时不会抛出异常
  AvroReflectionEnabled   false         是否使用Avro反射来序列化log4j的Event（当log是字符串时不要开启）
  AvroSchemaUrl           \--           一个能检索到Avro结构的url
log4j.properties 文件配置范例：
``` properties
#...
log4j.appender.out2 = org.apache.flume.clients.log4jappender.LoadBalancingLog4jAppender
log4j.appender.out2.Hosts = localhost:25430 localhost:25431
# configure a class's logger to output to the flume appender
log4j.logger.org.example.MyClass = DEBUG,flume
#...
```
使用随机（`RANDOM` ）负载均衡方式的log4j.properties 文件配置范例：
``` properties
#...
log4j.appender.out2 = org.apache.flume.clients.log4jappender.LoadBalancingLog4jAppender
log4j.appender.out2.Hosts = localhost:25430 localhost:25431
log4j.appender.out2.Selector = RANDOM
# configure a class's logger to output to the flume appender
log4j.logger.org.example.MyClass = DEBUG,flume
#...
```
log4j使用“失败退避”方式的log4j.properties配置范例：
``` properties
#...
log4j.appender.out2 = org.apache.flume.clients.log4jappender.LoadBalancingLog4jAppender
log4j.appender.out2.Hosts = localhost:25430 localhost:25431 localhost:25432
log4j.appender.out2.Selector = ROUND_ROBIN
log4j.appender.out2.MaxBackoff = 30000   #最大的退避时长是30秒
# configure a class's logger to output to the flume appender
log4j.logger.org.example.MyClass = DEBUG,flume
#...
```
::: hint
::: title
Hint
:::
这种退避机制在其他组件中有过多次应用，比如：[Spooling Directory
Source](#spooling-directory-source) 中的 *maxBackoff*
属性的功能是一样的。
:::
## 安全
[HDFS Sink](#hdfs-sink) 、 [HBaseSinks](#hbasesinks) 、 [Thrift
Source](#thrift-source) 、 [Thrift Sink](#thrift-sink) 和 [Kite Dataset
Sink](#kite-dataset-sink) 都支持Kerberos认证。
请参考对应组件的文档来配置Kerberos认证的选项。
Flume Agent 会作为一个主体向kerberos
KDC认证，给需要kerberos认证的所有组件使用。 [HDFS Sink](#hdfs-sink) 、
[HBaseSinks](#hbasesinks) 、 [Thrift Source](#thrift-source) 、 [Thrift
Sink](#thrift-sink) 和 [Kite Dataset Sink](#kite-dataset-sink)
配置的主体和keytab 文件应该是相同的，否则组件无法启动。
## 监控
Flume的监控系统的完善仍在进行中，变化可能会比较频繁，有几个Flume组件会向JMX平台MBean服务器报告运行指标。
可以使用Jconsole查询这些指标数据。
### 当前可用的组件监控指标
下面表中列出了一些组件支持的监控数据，'x'代表支持该指标，空白的表示不支持。各个指标的具体含义可参阅源码。
::: hint
::: title
Hint
:::
Source 1 和Source 2
表格是的指标是一样的，分成两个表是因为全放在一个表里一屏显示不下。Sink1和Sink2同理。
:::
#### Sources 1
  -------------------------- ------ ------ ------ ----- ------- -------------------- --------
                             Avro   Exec   HTTP   JMS   Kafka   MultiportSyslogTCP   Scribe
  AppendAcceptedCount        x                                                       
  AppendBatchAcceptedCount   x             x      x                                  
  AppendBatchReceivedCount   x             x      x                                  
  AppendReceivedCount        x                                                       
  ChannelWriteFail           x             x      x     x       x                    x
  EventAcceptedCount         x      x      x      x     x       x                    x
  EventReadFail                            x      x     x       x                    x
  EventReceivedCount         x      x      x      x     x       x                    x
  GenericProcessingFail                    x                    x                    
  KafkaCommitTimer                                      x                            
  KafkaEmptyCount                                       x                            
  KafkaEventGetTimer                                    x                            
  OpenConnectionCount        x                                                       
  -------------------------- ------ ------ ------ ----- ------- -------------------- --------
#### Sources 2
  -------------------------- ------------------- ---------------- ----------- ----------- --------- --------
                             SequenceGenerator   SpoolDirectory   SyslogTcp   SyslogUDP   Taildir   Thrift
  AppendAcceptedCount                                                                               x
  AppendBatchAcceptedCount   x                   x                                        x         x
  AppendBatchReceivedCount                       x                                        x         x
  AppendReceivedCount                                                                               x
  ChannelWriteFail           x                   x                x           x           x         x
  EventAcceptedCount         x                   x                x           x           x         x
  EventReadFail                                  x                x           x           x         
  EventReceivedCount                             x                x           x           x         x
  GenericProcessingFail                          x                                        x         
  KafkaCommitTimer                                                                                  
  KafkaEmptyCount                                                                                   
  KafkaEventGetTimer                                                                                
  OpenConnectionCount                                                                               
  -------------------------- ------------------- ---------------- ----------- ----------- --------- --------
#### Sinks 1
  ------------------------ ------------- ------------ --------------- ------- --------
                           Avro/Thrift   AsyncHBase   ElasticSearch   HBase   HBase2
  BatchCompleteCount       x             x            x               x       x
  BatchEmptyCount          x             x            x               x       x
  BatchUnderflowCount      x             x            x               x       x
  ChannelReadFail          x                                                  x
  ConnectionClosedCount    x             x            x               x       x
  ConnectionCreatedCount   x             x            x               x       x
  ConnectionFailedCount    x             x            x               x       x
  EventDrainAttemptCount   x             x            x               x       x
  EventDrainSuccessCount   x             x            x               x       x
  EventWriteFail           x                                                  x