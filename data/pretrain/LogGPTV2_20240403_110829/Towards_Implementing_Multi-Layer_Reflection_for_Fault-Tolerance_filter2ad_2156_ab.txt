Active 
Fault assumptions  Tolerated 
faults
Replica 
Determinism 
Resource 
overhead 
Communication 
overhead 
Recovery overhead 
Fail-silent servers  Crash faults  Not required  1 active server  High (checkpoints) 
Fail-silent servers   Crash faults  Not required  2 active servers Low (no checkpoints)  Low (switch) 
Fail-uncontrolled   Value faults  Required 
3 active servers Low (no checkpoints)  Low (null) 
Medium (re-execute) 
Table 1. Assumptions and Key Characteristics of Well-Known Replication Strategies 
Passive replication  Entities 
Communication 
Execution  
requests / replies 
execution points 
State  
internal data, 
platform data 
Action 
send / receive 
activation / progress / 
termination 
change on internal 
data, interactions with 
the local platform 
Motivation 
Synchronization between replicas. 
Capture/ restore on-going requests in 
concurrent servers. 
Consistent state restoration, i.e. 
transparent recovery from the client 
point of view. 
Means 
Interception 
Interception 
Platform instrumentation
Memory dump 
Serialization 
Interactions journals 
Semi-active replication 
Communication 
Entities 
idem as passive
Actions 
idem as passive 
Execution  
State  
idem as passive + 
non-deterministic 
decision points 
idem as passive
idem as passive + non-
deterministic operations 
idem as passive
Motivation 
control over leader / follower 
notifications 
control over non-deterministic 
decisions 
Means 
idem as passive 
idem as passive 
control over platform interactions 
with non-deterministic results 
idem as passive
Active replication 
Communication 
Execution  
State  
Entities 
Actions 
idem as passive
Motivation 
reply validation & propagation
Means 
idem as passive
Not needed 
Not needed (cloning not considered) 
Table 2. Control and Observability Requirements for the considered Replications Strategies 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:40 UTC from IEEE Xplore.  Restrictions apply. 
Reflective features 
Reification 
Introspection 
Behavioral Intercession 
Communication 
RequestReception 
RequestSending 
ReplySending 
ReplyReception 
getRequestContent 
getReplyContent 
doSend 
doReceive 
Structural Intercession 
piggyBackDataOnMsg 
Execution 
ExecutionPointStart 
ExecutionPointEnd 
ExecutionPointReach 
NonDeterministicFlowChange 
getExecutionPoint 
createExecutionPoint 
setExecutionPoint 
forceResultOfFlowChange 
State 
NonDeterministicPlatformCall 
getServerState 
getPlatformState 
ForceResultOfPlatformCall 
setServerState 
setPlatformSate 
Table 3. Towards an Aggregate Meta-Model for Replication Strategies 
to 
communication 
in  §  3.3.  Interestingly,  according 
discussed 
the 
motivations of each reflective feature found in Table 3, the 
proposed  facets  (Communication,  Execution,  and  State)
can  be  related  to  two  different  concerns  of  replication 
strategies.  The 
the 
coordination  of  the  different  replicas  and  is  the  least 
intrusive. 
implemented  using  wrapping 
techniques  for  instance.  The  execution  and  state  facets 
relate to the control of consistency across replicas. Those 
facets  are  the  most  intrusive,  as  they  deal  with  internal 
non-determinism and state information. The key question 
is  now:  How  can  this  meta-model  be  implemented  on  a 
real platform?
It  can  be 
facet 
enables 
4. Introducing Multi-Layer Reflection 
As  previously  mentioned  in Section  2,  a  real  platform 
encompasses several abstraction levels that correspond to 
the  different  components  of  the  concrete  system.  Several 
reflective  architectures  have  been  proposed  for  fault-
tolerant systems [1, 6, 13], and have proved the interest of 
reflection in this context. All these reflective architectures, 
however,  use 
from  a  single 
abstraction level. Using a small example, we show in this 
section  that  the  meta-model obtained  in  Section 3  cannot 
be  implement  at  a  single  level  without  threatening  the 
interest  of  reflection  itself.  This  example  illustrates  the 
motivation  for  MLR  (Multi-Layer  Reflection  concepts 
previously introduced in [17]). 
reflective  capabilities 
in 
Consider  the  semi-active  replication  of  a  concurrent 
server  implemented  on  top  of  an  Object  Request  Broker 
(ORB),  used 
thread  pool  mode.  Most  ORB 
implementations  offer  such  a  concurrency  model  by 
spawning  a  fixed  number  of  threads  at  initialization,  and 
putting them in a "waiting state". When a request arrives, 
the ORB forwards the request to one of the threads of the 
pool,  and  this  thread  starts  processing  the  request.  The 
initial  size  of  the  thread  pool  (say  p)  determines  the 
highest  number  of  active  concurrent  requests.  How  a 
particular  thread  is  assigned  a  particular  request  is  ORB-
implementation dependent, and remains totally hidden (i.e. 
lower  communication 
non-deterministic) to the application2. In the same way, the 
ORB  doesn't  necessarily  follows  the  order  in  which  it 
receives  requests  from 
layers; 
requests may be delivered to the application objects in any 
order, even if they are received at lower layers through an 
atomic  multicast  protocol.  In  summary,  the  role  of  the 
ORB  is  two-fold:  (i)  dispatching  of  at  most  p  requests 
among  received  requests  to  the  application,  and  (ii) 
allocation of the selected requests to available pool-threads 
(at-most  p).  In  our  example,  we  further  assume  that  the 
application  itself  is  deterministic,  i.e.  that  the  results 
returned by the different requests only depend on the order 
in which request are processed by application objects. 
Consider  now  three  fault-tolerance  programmers  that 
must add a replication mechanism to this kind of server.  
• The first one has no access to any meta-information 
regarding the executive layers (black-box case).  
• The second can  control  all  OS-level  thread  related 
operations  (scheduling,  synchronization,  etc.)  through  a 
dedicated OS-level meta-model (mono-level reflection).  
• The  third  one  can  both  inspect  and  control  the  OS 
and the ORB through a multi-layer meta-model. 
4.1. The Black-Box Case 
This first programmer has only access to the application 
level,  all  underlying  executive  layers  being  black-boxes. 
This  approach  gives  him  no  control  whatsoever  on  the 
order  in  which  requests  are  delivered  to  the  application 
objects.  If  a  thread-pool-ORB  with  a  pool  size  of  two 
threads  simultaneously  receives  three  requests,  only  two 
out  of  the  three  requests  will  be  non-deterministically 
delivered to the application (the third one being queued). 
Consider three requests R, S, and T delivered in this order 
to  the  replicated  ORBs.  Assume  the  ORB  of  the  leader 
dispatches R and S to the two threads of its pool, and the 
leader chooses to serve R first and then S. If the ORB of 
the follower dispatches S and T to the application instead, 
2 The CORBA standard does not recommend any specific multi-threaded 
object implementation.  
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:40 UTC from IEEE Xplore.  Restrictions apply. 
the  follower  will  be  unable  to  follow  the  leader's  choice. 
Although  visible  at  the  application  level,  this  decision  is 
internal  to  the  ORB  and  so  cannot  be  controlled  in  this 
case.  This  problem  (called  PB1)  relates  to  ORB  internal 
messages  shuffling,  which  destroys  any 
total  order 
provided by an underlying atomic multicast protocol. 
A  possible  solution  to  this  problem  is  to  serialize 
incoming requests at the communication level before they 
are  delivered  to  the  ORB  (but  it  also  eliminates  the 
benefits of the thread-pool mode [12]).  
processing  of  R2.  In  other  words,  as  a  potential  causal 
dependency  exists  between  the  state  of  Y  after  R2 
(Y_after_R2_by_T1_after_R1),  and  the  state  of  X 
before  R1  (X_init),  the  application  may  reach  two 
different  states  (X,Y)  depending  on  the  dispatching 
decision. Figure 3-a traces the FT-programmer view of the 
computation as perceived at the OS level, and shows that 
two  possible  major  states  are  perceived  after  processing 
R2 (as shown in Figure 3-b). 
X_after_R1_by_T1_init
T1_after_R1_R2
4.2. The Mono-Layer Reflection Case 
low 
level  communication  primitives, 
Our  second  fault-tolerance  programmer  has  access  to 
the OS level only, the ORB remaining a back-box. In this 
case, 
thread 
scheduling and synchronization can be controlled. Forcing 
all  replicated  OS  to  schedule  threads  and  to  allocate 
mutexes in exactly the same way, ensures that requests are 
processed  in  the  same  order  by  all  object  replicas.  This 
approach  inhibits  ORB  message  shuffling  and  solves 
problem  PB1  under  our  assumptions  (deterministic 
application).  This  is  however  quite  complex  in  a  multi-
layer  architecture  and  not  optimal.  We  call  this  "non-
optimality" problem PB2. 
The reason is that, forcing threads to process requests in 
exactly  the  same  order  at  the  OS  level  enables  object 
replicas  to  reach  identical  states,  but  introduces  useless 
constraints. Indeed, different activation profiles can reach 
the  same  state,  even  when  threads  are  not  run  exactly  in 
the same order. An example is given in Figure 2. 
Consider  two  different  dispatchings  of  two  successive 
requests (R1 and R2) on a pool containing two threads (T1 
and  T2).  Request  R1  interacts  with  the  application  state 
variable  X  (potentially  shared),  whereas  request  R2 
interacts  with  the  state  variable  Y.  Request  processing  is 
represented  by  dashed  bars  and  interactions  by  dotted 
areas limited by double arrows.  
In Case 1, both requests are handled by T1. In Case 2, 
request R1 is processed by T1, request R2 is processed by 
T2.  Clearly,  having  full  visibility  of  the  thread  behavior 
leads  to  understand  that  the  final  states  after  both 
computation  profiles  are  identical.  However,  as  OS  level 
instrumentation  restricts  the  visibility  (and  thus  semantic 
understanding)  to  threads  and  mutex  actions  alone,  the 
fault-tolerance  programmer  cannot  easily  reach 
this 
conclusion. From his point of view, as only one thread T1 
is  used,  the  result  of  processing  R1  may  impact  the 
T1_after_R1
Request R2
Request R1
State Variable X
Thread T1
State Variable Y
Thread T2
Y_after_R2_by_T1_after_R1
State
Possible causal dependency
Case 1: T1 handles the two requests R1 and R2 
X_after_R1_by_T1_init
T1_after_R1
State Variable X
Thread T1
State Variable Y
Thread T2
Request R1
Request R2
T2_after_R2
Y_after_R2_by_T2_init
Case 2: T1 handles R1, T2 handles R2 
Figure 2: Request vs Thread using a Thread Pool 
In practice, one of these two computation profiles will 
be  imposed  to  both  leader  and  follower.  So,  the  non-
determinism problem PB1 is solved at the expense of blind 
forcing  of  thread  scheduling  at  both  replicas  (as  in  [7]). 
However, in a complex multi-layer architecture controlling 
all individual OS actions induces unacceptable overheads 
as middleware layers intensively use threading and mutex 
locks. The non-optimality of this solution is due to the lack 
of visibility and semantics of the computation in the ORB. 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:28:40 UTC from IEEE Xplore.  Restrictions apply. 
init