leverage this observation, TRW computes an ADS score by
applying the sequential hypothesis on a remote host’s con-
nection attempts. This ADS score is thresholded to deter-
mine whether or not a remote host is a scanner.
Packet Header Anomaly Detection (PHAD) [21]: PHAD
learns the normal range of values for all 33 ﬁelds in the
Ethernet, IP, TCP, UDP and ICMP headers. An anomaly
score is assigned to each packet header ﬁeld in the testing
phase and the ﬁelds’ scores are summed to obtain a packet’s
aggregate anomaly score. We evaluate PHAD-C32 [21] us-
ing the following packet header ﬁelds: source IP, destination
IP, source port, destination port, protocol type and TCP
ﬂags. The top n values are thresholded as anomalous.
3.3.2 Host ADSs
Sequence Time Delay Embedding (STIDE) [6]: STIDE de-
tects anomalous system calls by building a normal proﬁle
for a process using all unique contiguous sequences of pre-
determined and ﬁxed length. The sequence for test trace
are compared to sequences in normal database and if any
sequence is not found in database, it is called a mismatch.
A threshold value is applied on percentage mismatches to
classify anomalous behavior.
Support Vector Machines (SVMs) using Bags of System Calls
Approach [13]: Kang et al. propose a bag of system calls rep-
316s
t
e
k
c
a
P
0
0
5
x
25
20
15
10
5
0
0
Markov Chain
Observed
Kalman Filter
Holt−Winters
20
40
60
Seconds
80
100
s
l
l
a
C
m
e
t
s
y
S
16
14
12
10
8
6
4
2
0
0
Markov Chain
Observed
Kalman Filter
Holt−Winters
10
40
Real−Time Sequence
20
30
50
(a) LBNL background traﬃc
(b) UNM System Calls Sequence
Figure 1: Variations in an ADS’ input data characteristics; since packet rates in (a) are divided into equal-
sized bins of 500, 0 (on y-axis) represents packets rates between 0 and 499 packets/sec.
resentation for detection of intrusive system call sequences.
During a conversion, the ordering information between sys-
tem calls is lost and only the frequency of each input se-
quence is preserved. A feature is deﬁned as an ordered list
of the frequency of all the system calls in a given sequence.
SVMs are then used for classiﬁcation [3].
Kullback-Leibler (KL) Detector [18]: Relative Entropy or
Kullback-Leibler (KL) divergence measure is used to detect
anomalies proposed in system calls; this measure is also used
by [7] to detect anomalies in traﬃc. This detector maps
system calls into diﬀerent classes based on their numbers
to obtain a benign distribution. This distribution is then
compared with run-time distribution using KL divergence.
If the KL-based ADS score is more than a ﬁxed threshold,
it is classiﬁed as anomalous.
4. STATISTICAL ANALYSIS OF ANOMALY
SCORES
In this section, we evaluate statistical properties of an IDS’
anomaly scores that can be used to automatically model and
adapt its classiﬁcation threshold. Based on these statisti-
cal properties, the following section proposes an adaptive
thresholding algorithm that can accurately track the chang-
ing behavior of real-time traﬃc and/or OS measurements.
To put things in perspective, before proceeding with the sta-
tistical analysis, we emphasize our rationale and high-level
methodology for adaptive thresholding.
4.1 Motivation
An IDS’ accuracy is traditionally characterized on an ROC
plane by applying diﬀerent classiﬁcation thresholds to the
IDS’ anomaly scores. Points on the ROC plane are obtained
by computing the average detection rate (y-axis) versus the
average false alarm rate (x-axis) for each threshold value.
Steepness and height of the ROC curve quantiﬁes the accu-
racy that can be achieved by the IDS. While ROC evaluation
is useful to get a sense for the average-case accuracy of an
IDS, methods to achieve the best ROC accuracy points for
arbitrary (traﬃc or OS) data are not well-investigated.
In practice, an IDS will have to somehow learn a good clas-
siﬁcation threshold for an arbitrary benign behavior in real-
time. To make matters worse, raw data that are input to an
IDS typically show considerable variations. Traﬃc charac-
teristics vary across organizations and network deployment
points, and due to diurnal and other usage patterns. As
an example, consider the LBNL background traﬃc rates
shown in Fig. 1(a) (solid line).
It can be observed that
the traﬃc rates change from approximately 500 pkts/sec
to 10,000 pkts/sec within a few seconds. Similarly, host-
based anomaly detection metrics are a function of user be-
havior, applications being used, operating system, hardware,
etc. For instance, consider the benign system calls executed
shown in Fig. 1(b). It can be seen that system calls errat-
ically vary from 1 to 15 in the benign traces. It can be in-
tuitively argued that a ﬁxed (time- and behavior-invariant)
classiﬁcation threshold cannot possibly achieve good accu-
racy for such time-varying input.
Finally, as input data characteristics vary, determination
of a ﬁxed threshold requires repeated manual intervention.
In a typical operational scenario, a system/network adminis-
trator is responsible for adjusting the sensitivity of a network-
based anomaly detector when the number of false alarms
(i.e., traﬃc classiﬁed as malicious but which is in fact be-
nign) increases. Similarly, host-based IDSs expect a user to
adjust its sensitivity to cater for his/her security and behav-
ioral requirements. Such repeated manual input renders an
IDS less automated and more prone to conﬁguration errors.
Moreover, in a real-time system it is diﬃcult to ascertain if
a manually-conﬁgured threshold is yielding good accuracy.
4.2 General Methodology
We argue that an eﬀective IDS should automatically de-
tect varying input data patterns and adjust its classiﬁcation
threshold accordingly. If accurate, such an adaptive thresh-
olding mechanism will enable an IDS to achieve good opera-
tional points on the ROC plane. As a by-product, adaptive
thresholding will also reduce the need for human threshold
tuning, thereby making an IDS more automated.
We observed that signiﬁcant variations in input data char-
acteristics are diﬃcult to track. Instead, it is much easier
to track the anomaly score of an IDS before application of
the thresholding function. As an example, Fig. 2 shows
variations at the input and output of a host and a network
ADS. It can be observed from Fig. 2 (a) that, while the in-
put (system calls) vary frequently from 1 to 160, not much
variation is observed in the output (anomaly scores). Sim-
317(a) Kullback-Leibler Detector on UNM Dataset
(b) Maximum Entropy Detector on LBNL Dataset
Figure 2: Anomaly score variations with respect to variations in input (traﬃc or host) characteristics.
ilarly, Fig. 2 (b) shows signiﬁcant variations observed in
traﬃc characteristics, but such erratic variations are not re-
ﬂected in the anomaly scores. Hence, anomaly scores are
easier to track because they reduce the high-dimensional in-
put data to a relatively small set of scores. In addition to the
complexity advantage, since these scores are coherent with
input data characteristics, and as these scores comprise the
domain of the thresholding function, it is intuitively likely
that adaptively tracking anomaly scores yields better accu-
racy than direct tracking of input data. This thesis leads us
to the following rationale for the adaptive thresholding tech-
nique proposed in this paper: If we can accurately predict
the expected values of future anomaly scores under benign
conditions, the classiﬁcation threshold can be adapted as a
function of the predicted score.
Tracking an IDS’ anomaly scores requires a robust model
of scores observed under normal conditions. To develop such
a model, in the following sections we evaluate some pertinent
statistical properties of anomaly scores.
4.3 Temporal Dependence in Anomaly Scores
We analyzed a number of statistical properties of benign
traﬃc and OS scores. One relevant property that provided
us interesting insights into anomaly scores was the analy-
sis of their temporal dependence. It can be intuitively ar-
gued that, as long as an IDS’ input data are produced by
a benign source, the anomaly scores observed at the out-
put of an IDS should exhibit a certain level of temporal
dependence.
In case of an anomaly, perturbations in this
dependence structure are ﬂagged as anomalies. Therefore,
the level of temporal dependence can serve as an important
metric for modeling anomaly scores.
Autocorrelation measures the on-average temporal depen-
dence between the random variables in a stochastic process
at diﬀerent points in time. For a given lag k, the autocor-
relation function of a stochastic process Xn (where n is the
time index) is deﬁned as:
ρ[k] =
E{X0Xk} − E{X0}E{Xk}
σX0 σXk
,
(1)
where E{.} represents the expectation operation and σXk is
the standard deviation of the random variable at time lag k.
The value of the autocorrelation function lies in the range
[−1, 1], where ρ[k] = 1 means perfect correlation at lag k
(which is obviously true for k = 0) and ρ[k] = 0 means no
correlation at lag k.
Figs. 3(a) and (b) respectively show the autocorrelation
function plotted versus the lag for the network- and host-
based ADS’ scores. For all the ADSs, a high level of tem-
poral dependence can be easily observed at small lags. This
correlation decays in time and eventually drops down to a
negligible value. However, the correlation decay is not con-
sistent for all ADSs.
In the network-based ADSs, PHAD
shows the steepest correlation decay; i.e., one anomaly score
by PHAD is correlated only with few previous scores. This
can be explained by noting that PHAD’s anomaly detec-
tion algorithm is not dependent on traﬃc rate/volume or
frequency. Rather, PHAD classiﬁes every packet on its own
without borrowing any information from preceding packets.
Maximum-Entropy detector shows the slowest correlation
decay because its anomaly detection algorithm operates on
a port usage distribution. Port frequencies do not change
signiﬁcantly over time (as was also shown in [14],) and con-
sequently each anomaly score of the Maximum-Entropy de-
tector is inherently correlated with prior scores. Similar
trends are observed for the TRW ADS. Interestingly, how-
ever, TRW when evaluated at large lags shows a somewhat
periodic correlation structure in which the correlation, in-
stead of showing a consistently decaying trend, exhibits a
high-to-low repetitive trend. This periodicity in correlation
is because the TRW’s sequential hypothesis testing algo-
rithm builds a hypothesis slowly over time by borrowing
information from previous failed and successful connections.
Once the hypothesis is complete, the sequential hypothesis
computation logic is reset, subsequently resulting in a repet-
318t
i
n
e
c
i
f
f
e
o
C
n
o
i
t
l
a
e
r
r
o
C
o
u
A
t
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
0
Max−Entropy
PHAD
TRW
t
i
n
e
c
i
f
f
e
o
C
n
o
i
t
l
a
e
r
r
o
C
o
t
u
A
500
1000
Values
1500
2000
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
SVM
Stide
KLD
5
10
15
20
25
Values
(a) Network-based ADSs, LBNL Dataset
(b) Host-based ADSs, UNM Dataset
Figure 3: Autocorrelation coeﬃcient of the anomaly scores of ADSs; Maximum-Entropy ADS’ score is plotted
for port 80.
itive pattern. Similar trends can be observed in host-based
ADSs, where STIDE and SVM show the steepest decay be-
cause both ADSs operate on chunks of system calls without
borrowing much information from prior calls sequences. On
the other hand, the KL-based detector shows a slow decay
(high correlation with prior scores) because it operates on a
sliding window of system calls.
Based on the decaying correlation structure present in
anomaly scores, we argue that a stochastic model of a few
previous scores can be used to accurately predict future
scores. However, to constrain the complexity of threshold
adaptation, we must answer the following question: How
many past anomaly scores are needed to accurately predict
the next score? Interestingly, the following section shows
that the answer to this question also yields an accurate
stochastic model of anomaly scores which can in turn be
used for threshold prediction.
4.4 Modeling Temporal Dependence in
Anomaly Scores
It is well-known that a decaying temporal dependence
structure can be accurately modeled using Markov chains
[22]. Therefore, the question posed above can be rephrased
as: What is the order of the Markov chain model that should