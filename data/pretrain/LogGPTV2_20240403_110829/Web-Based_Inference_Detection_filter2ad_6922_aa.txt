title:Web-Based Inference Detection
author:Jessica Staddon and
Philippe Golle and
Bryce Zimny
Web-Based Inference Detection
Jessica Staddon1, Philippe Golle1,
Bryce Zimny2∗
1 Palo Alto Research Center
{staddon,pgolle}@parc.com
2 University of Waterloo
PI:EMAIL
Abstract
Newly published data, when combined with existing
public knowledge, allows for complex and sometimes
unintended inferences. We propose semi-automated
tools for detecting these inferences prior to releasing
data. Our tools give data owners a fuller understanding
of the implications of releasing data and help them ad-
just the amount of data they release to avoid unwanted
inferences.
Our tools ﬁrst extract salient keywords from the pri-
vate data intended for release. Then, they issue search
queries for documents that match subsets of these key-
words, within a reference corpus (such as the public
Web) that encapsulates as much of relevant public knowl-
edge as possible. Finally, our tools parse the documents
returned by the search queries for keywords not present
in the original private data. These additional keywords
allow us to automatically estimate the likelihood of cer-
tain inferences. Potentially dangerous inferences are
ﬂagged for manual review.
We call this new technology Web-based inference
control. The paper reports on two experiments which
demonstrate early successes of this technology. The ﬁrst
experiment shows the use of our tools to automatically
estimate the risk that an anonymous document allows
for re-identiﬁcation of its author. The second experiment
shows the use of our tools to detect the risk that a doc-
ument is linked to a sensitive topic. These experiments,
while simple, capture the full complexity of inference de-
tection and illustrate the power of our approach.
1
Introduction
Information has never been easier to ﬁnd. Search en-
gines allow easy access to the vast amounts of infor-
mation available on the Web. Online data repositories,
This work was done while a coop student at the Palo Alto Research
∗
Center.
newspapers, public records, personal webpages, blogs,
etc., make it easy and convenient to look up facts, keep
up with events and catch up with people.
On the ﬂip side, information has never been harder to
hide. With the help of a search engine or web informa-
tion integration tool [45], one can easily infer facts, re-
construct events and piece together identities from frag-
ments of information collected from disparate sources.
Protecting information requires hiding not only the in-
formation itself, but also the myriad of clues that might
indirectly lead to it. Doing so is notoriously difﬁcult, as
seemingly innocuous information may give away one’s
secret.
To illustrate the problem, consider a redacted biogra-
phy [8] (shown in the left-hand side of ﬁgure 6) that was
released by the FBI. Prior to publication, the biography
was redacted to protect the identity of the person whom
it describes. All directly identifying information, such as
ﬁrst and last names, was expunged from the biography.
The redacted biography contains only keywords that ap-
ply to many individuals, such as “half-brother”, “Saudi”,
“magnate” and “Yemen”. None of these keywords is par-
ticularly identifying on its own, but in aggregate they al-
low for near-certain identiﬁcation of Osama Bin Laden.
Indeed, a Google search for the query “Saudi magnate
half-brother” returns in the top 10 results, pages that are
all related to the Bin Laden family. This inference, as
well as potentially many others, should be anticipated
and countered in a thorough redaction process.
The need to protect secret information from unwanted
inferences extends far beyond the FBI. In addition to in-
telligence agencies and the military, numerous govern-
ment agencies, businesses and individuals face the prob-
lem of insulating their secrets from the information they
disclose publicly. In the litigation industry for example,
information protected by client-attorney privilege must
be redacted from documents prior to disclosure. In the
healthcare industry, it is common practice and mandated
by some US state laws, to redact sensitive information
USENIX Association
16th USENIX Security Symposium
71
(such as HIV status, drug or alcohol abuse and mental
health conditions) from medical records prior to releas-
ing them. Among individuals, anonymous bloggers are
a good example of people who seek to ensure that their
posts do not disclose their secret (their identity). This
is made challenging by the fact that in some cases very
little personal information may sufﬁce to infer the blog-
ger’s identity. For example, if the second author of this
paper were to reveal his ﬁrst name (Philippe) and men-
tion the ﬁrst name of his wife (Sanae), then his last name
(or at least, a strong candidate for his last name) can be
inferred from the ﬁrst hit returned by the Google query,
“Philippe Sanae wedding”.
In all these instances, the problem is not access con-
trol, but inference control. Assuming the existence of
mechanisms to control access to a subset of informa-
tion, the problem is to determine what information can
be released publicly without compromising certain se-
crets, and what subset of the information cannot be re-
leased. What makes this problem difﬁcult is the quantity
and complexity of inferences that arise when published
data is combined with, and interpreted against, the back-
drop of public knowledge and outside data.
This paper breaks new ground in considering the prob-
lem of inference detection not in a restricted setting (such
as, e.g., database tables), but in all its generality. We
propose the ﬁrst all-purpose approach to detecting un-
wanted inferences. Our approach is based on the ob-
servation that the combination of search engines and the
Web, which is so well suited to detect inferences, works
equally well defensively as offensively. The Web is an
excellent proxy for public knowledge, since it encapsu-
lates a large fraction of that knowledge (though certainly
not all). Furthermore, the dynamic nature of the Web
reﬂects the dynamic nature of human knowledge and
means that the inferences detected today may be different
from those drawn yesterday. The likelihood of certain in-
ferences can thus be estimated automatically, at any point
in time, by issuing search queries to the Web. Returning
to the example of the biography redacted by the FBI, a
simple search query could have ﬂagged the risk of re-
identiﬁcation coming from the keywords “Saudi”, “mag-
nate” and “half-brother”.
The Web is an ideal resource for identifying infer-
ences because keyword search allows for efﬁcient de-
tection of the information that is associated with an in-
dividual. Such associations can be just as important in
identifying someone as their personal attributes. As an
example, consider the fact that the top 2 hits returned by
the Google query, “pop singer vogueing”1 have nothing
to do with the singer Madonna, whereas the top 3 hits re-
turned by the Google query, “gay pop singer vogueing”2
all pertain to Madonna. The attribute “gay” helps to fo-
cus the results not because it is an attribute of Madonna
(at least not as it is used in the top 3 hits) but rather it
is an attribute associated with a large subset of her fan-
base. Similarly, the entire ﬁrst page of hits returned by
the query “naltrexone acamprosate” all pertain to alco-
holism, not because they are alcoholism symptoms or in
some other way part of the deﬁnition of alcoholism, but
rather they are associated with alcoholism because they
are drugs commonly used in its treatment.
We propose generic tools for detecting unwanted in-
ferences automatically using the Web. These tools ﬁrst
extract salient keywords from the private data intended
for release. Then, they issue search queries for docu-
ments that match subsets of these keywords, within a
reference corpus (such as the public Web) that encapsu-
lates as much of relevant public knowledge as possible.
Finally, our tools parse the documents returned by the
search queries for keywords not present in the original
private data. These additional keywords allow us to au-
tomatically estimate the likelihood of certain inferences.
Potentially dangerous inferences are ﬂagged for manual
review. We call this new technology Web-based infer-
ence control.
We demonstrate the success of our inference detection
tools with two experiments. The ﬁrst experiment shows
the use of our tools to automatically estimate the risk that
an anonymous document allows for re-identiﬁcation of
its author. The second experiment shows the use of our
tools to detect the risk that a document is linked to a sen-
sitive topic. These experiments, while simple, capture
the full complexity of inference detection and illustrate
the power of our approach.3
OVERVIEW. We discuss related work in section 2.
We deﬁne our models and tools, as well as our basic
algorithm for Web-assisted inference detection in sec-
tion 3. We list a number of potential applications of
Web-assisted inference control in section 4. Section 5
describes two experiments that demonstrate the success
of our inference control tools. Section 6 provides an ex-
ample using Web-based inference detection to improve
the redaction process. We conclude in section 7.
2 Related Work
Our work can be viewed both as a new technique for in-
ference detection and as a new way of leveraging Web
search to understand content. There is substantial exist-
ing work in both areas, but ours is the ﬁrst Web-based
approach to inference detection. We discuss the most
closely related work in these areas below.
INFERENCE DETECTION. Most of the previous work on
inference detection has focused on database content (see,
for example, [33, 21, 43, 19]). Work in this area takes
as input the database schema, the data themselves and,
72
16th USENIX Security Symposium
USENIX Association
sometimes, relations amongst the attributes of the data-
base that are meant to model the outside knowledge a
human may wield in order to infer sensitive information.
To the best of our understanding, no systematic method
has been demonstrated for integrating this outside knowl-
edge into an inference detection system. Our work seeks
to remedy this by demonstrating the use of the Web for
this purpose. When coupled with simple keyword extrac-
tion, this general technique allows us to detect inference
in a variety of unstructured documents.
A particular type of inference allows the identiﬁca-
tion of an individual. Sweeney looks for such inferences
using the Web in [35] where inferences are enabled by
numerical values and other attributes characterizable by
regular expressions such as SSNs, account numbers and
addresses. Sweeney does not consider inferences based
on English language words. We use the indexing power
of search engines to detect when words, taken together,
are closely associated with an individual.
The closely related problem of author identiﬁcation
has also been extensively studied by the machine learn-
ing community (see, for example, [25, 11, 24, 34, 20]).
The techniques developed generally rely on a training
corpus of documents and use speciﬁc attributes like self-
citations [20] or writing style [25] to identify authors.
Our work can be viewed as exploiting a previously un-
studied method of author identiﬁcation, using informa-
tion authors reveal about themselves to identify them.
Atallah, et al.
[2], describe how natural language
processing can potentially be used to sanitize sensi-
tive information when the sanitization rules are already
known. Our work is focused on using the Web to iden-
tify the sanitization rules.
WEB-ASSISTED QUERY INTERPRETATION. There is a
large body of work on using the Web to improve query
results (see, for example, [16, 32, 10]). One of the funda-
mental ideas that has come out of this area is to use over-
lap in query results to establish a connection between dis-
tinct queries. In contrast, we analyze the content of the
query results in order to detect connections between the
query terms and an individual or topic.
WEB-BASED SOCIAL NETWORK ANALYSIS. Recently,
the Web has been used to detect social networks (e.g.,
[1, 23]). A key idea in this work is using the Web to look
for co-occurences of names and using this to infer a link
in a social network. Our techniques can support this type
of analysis, when, for example, names in a network when
entered as a Web query, yield a name that is not already
in the network. However, our techniques are aimed at
a broader goal, that is, understanding all inferences that
can be drawn from a document.
WEB-ASSISTED CONTENT ANALYSIS AND ANNOTA-
TION. There is a large body of work on using the Web
to understand and analyze content. Nakov and Hearst
[30] have shown the power of using the Web as training
data for natural language analysis. Web-assistance for
extracting keywords for the purposes of content indexing
and annotation is studied in [12, 37, 26]. This work is fo-
cused on automated, Web-based tools for understanding
the meaning of the text as written, as opposed to the in-
ferences that can be drawn based on the text. That said,
in our work we use very simple content analysis tools,
and improvements to our approach could involve more
sophisticated content analysis tools including Web-based
tools such as those developed in these works.
WEB-BASED DATA AGGREGATION. Finally, we note
that the commercial world is beginning to offer Web-
based data aggregation tools (see, for example [14, 13,
31]) for the purposes of tracking competitor behavior,
doing market analysis and intelligence gathering. We are
not aware of support for pre-production inference control
in these offerings, as is the focus of this paper.
3 Model and Generic Algorithm
C
C
C
R
R
denote a private collection of documents that is
Let
being considered for public release, and let
denote a
collection of reference documents. For example, the col-
lection
may consist of the blog entries of a writer, and
the collection
may consist of all documents publicly
available on the Web.
Let K(C) denote all the knowledge that can be com-
. The set K(C) infor-
puted from the private collection
mally represents all the statements and facts that can be
logically derived from the information contained in the
. The set K(C) could in theory be computed
C
collection
with a complete and sound theorem prover given all the
C
axioms in
. In practice, such a computation is impos-
sible and we will instead rely on approximate represen-
tations of the set K(C). Similarly let K(R) denote all
the knowledge that can be computed from the reference
collection
Informally stated, the problem of inference control
comes from the fact that the knowledge that can be ex-
tracted from the union of the private and reference col-
lections K(C ∪ R) is typically greater than the union
K(C) ∪ K(R) of what can be extracted separately from
C
R
. The inference control problem is to understand
and
Diff(C,R) = K(C ∪ R) −(cid:16)K(C) ∪ K(R)(cid:17).
and control the difference:
R
.
C
Returning to the Osama Bin Laden example discussed
in the introduction, consider the case where the col-
lection
consists of the single declassiﬁed FBI docu-
ment [8], and where
consists of all information pub-
licly available on the Web. Let S denote the statement:
R
USENIX Association
16th USENIX Security Symposium
73
C
C
but not in
“The declassiﬁed FBI document is a biography of Osama
Bin Laden”. Since the identity of the person to whom the
document pertains has been redacted, it is impossible to
C
alone, and so S 6∈ K(C).
learn the statement S from
The statement S is clearly not in K(R) either since it is
R
impossible to compute from
alone a statement about
R
. It follows that S
a document that is in
does not belong to K(C) ∪ K(R). But, as shown ear-
lier, the statement S belongs to K(C ∪ R). Indeed, we