# Web-Based Inference Detection

**Authors:**
- Jessica Staddon<sup>1</sup>
- Philippe Golle<sup>1</sup>
- Bryce Zimny<sup>2*</sup>

**Affiliations:**
- <sup>1</sup>Palo Alto Research Center, {staddon, pgolle}@parc.com
- <sup>2</sup>University of Waterloo, bryce.zimny@uwaterloo.ca

**Abstract:**
The release of new data, when combined with existing public knowledge, can lead to complex and unintended inferences. We propose semi-automated tools to detect these inferences before the data is released. These tools provide data owners with a comprehensive understanding of the implications of releasing data and help them adjust the amount of data they release to avoid unwanted inferences.

Our tools first extract salient keywords from the private data intended for release. They then issue search queries for documents that match subsets of these keywords within a reference corpus (such as the public web) that encapsulates as much relevant public knowledge as possible. Finally, our tools parse the documents returned by the search queries for keywords not present in the original private data. These additional keywords allow us to automatically estimate the likelihood of certain inferences, which are flagged for manual review if they are potentially dangerous.

We term this new technology "Web-based inference control." This paper reports on two experiments demonstrating the early successes of this technology. The first experiment shows the use of our tools to automatically estimate the risk that an anonymous document allows for re-identification of its author. The second experiment demonstrates the use of our tools to detect the risk that a document is linked to a sensitive topic. These experiments, while simple, capture the full complexity of inference detection and illustrate the power of our approach.

## 1. Introduction

Information has never been easier to find. Search engines provide easy access to vast amounts of information available on the web. Online data repositories, newspapers, public records, personal webpages, blogs, and other sources make it convenient to look up facts, keep up with events, and stay connected with people.

On the flip side, information has never been harder to hide. With the help of search engines or web information integration tools, one can easily infer facts, reconstruct events, and piece together identities from fragments of information collected from disparate sources. Protecting information requires not only hiding the information itself but also the myriad clues that might indirectly lead to it. This is notoriously difficult, as seemingly innocuous information may give away one's secrets.

To illustrate, consider a redacted biography released by the FBI. Prior to publication, the biography was redacted to protect the identity of the person it describes. All directly identifying information, such as first and last names, was removed. The redacted biography contains only keywords that apply to many individuals, such as "half-brother," "Saudi," "magnate," and "Yemen." None of these keywords is particularly identifying on its own, but in aggregate, they allow for near-certain identification of Osama Bin Laden. A Google search for the query "Saudi magnate half-brother" returns pages in the top 10 results that are all related to the Bin Laden family. This inference, as well as potentially many others, should be anticipated and countered in a thorough redaction process.

The need to protect secret information from unwanted inferences extends far beyond the FBI. Intelligence agencies, the military, numerous government agencies, businesses, and individuals face the problem of insulating their secrets from the information they disclose publicly. For example, in the litigation industry, information protected by client-attorney privilege must be redacted from documents prior to disclosure. In the healthcare industry, it is common practice and mandated by some US state laws to redact sensitive information (such as HIV status, drug or alcohol abuse, and mental health conditions) from medical records before releasing them. Among individuals, anonymous bloggers seek to ensure that their posts do not disclose their identity, which is challenging because even a small amount of personal information may suffice to infer the bloggerâ€™s identity. For instance, if the second author of this paper were to reveal his first name (Philippe) and mention the first name of his wife (Sanae), then his last name (or at least a strong candidate for his last name) can be inferred from the first hit returned by the Google query "Philippe Sanae wedding."

In all these instances, the problem is not access control but inference control. Assuming the existence of mechanisms to control access to a subset of information, the challenge is to determine what information can be released publicly without compromising certain secrets and what subset of the information cannot be released. The difficulty lies in the quantity and complexity of inferences that arise when published data is combined with and interpreted against the backdrop of public knowledge and outside data.

This paper breaks new ground by considering the problem of inference detection in a general setting, rather than in a restricted one (such as database tables). We propose the first all-purpose approach to detecting unwanted inferences. Our approach is based on the observation that the combination of search engines and the web, which is so well suited to detect inferences, works equally well defensively. The web is an excellent proxy for public knowledge, as it encapsulates a large fraction of that knowledge. Furthermore, the dynamic nature of the web reflects the dynamic nature of human knowledge, meaning that the inferences detected today may differ from those drawn yesterday. The likelihood of certain inferences can thus be estimated automatically, at any point in time, by issuing search queries to the web. Returning to the example of the FBI-redacted biography, a simple search query could have flagged the risk of re-identification coming from the keywords "Saudi," "magnate," and "half-brother."

The web is an ideal resource for identifying inferences because keyword search allows for efficient detection of information associated with an individual. Such associations can be just as important in identifying someone as their personal attributes. For example, the top two hits returned by the Google query "pop singer vogueing" have nothing to do with Madonna, whereas the top three hits returned by the Google query "gay pop singer vogueing" all pertain to Madonna. The attribute "gay" helps focus the results not because it is an attribute of Madonna (at least not as used in the top three hits) but because it is an attribute associated with a large subset of her fanbase. Similarly, the entire first page of hits returned by the query "naltrexone acamprosate" all pertain to alcoholism, not because they are symptoms or part of the definition of alcoholism, but because they are drugs commonly used in its treatment.

We propose generic tools for automatically detecting unwanted inferences using the web. These tools first extract salient keywords from the private data intended for release. They then issue search queries for documents that match subsets of these keywords within a reference corpus (such as the public web) that encapsulates as much relevant public knowledge as possible. Finally, our tools parse the documents returned by the search queries for keywords not present in the original private data. These additional keywords allow us to automatically estimate the likelihood of certain inferences, which are flagged for manual review if they are potentially dangerous. We call this new technology "Web-based inference control."

We demonstrate the success of our inference detection tools with two experiments. The first experiment shows the use of our tools to automatically estimate the risk that an anonymous document allows for re-identification of its author. The second experiment shows the use of our tools to detect the risk that a document is linked to a sensitive topic. These experiments, while simple, capture the full complexity of inference detection and illustrate the power of our approach.

### Overview
- **Section 2:** Related Work
- **Section 3:** Model and Generic Algorithm
- **Section 4:** Potential Applications
- **Section 5:** Experiments
- **Section 6:** Example of Web-based Inference Detection in Redaction
- **Section 7:** Conclusion

## 2. Related Work

Our work can be viewed both as a new technique for inference detection and as a new way of leveraging web search to understand content. There is substantial existing work in both areas, but ours is the first web-based approach to inference detection. We discuss the most closely related work in these areas below.

### Inference Detection
Most previous work on inference detection has focused on database content (e.g., [33, 21, 43, 19]). This work takes as input the database schema, the data themselves, and sometimes relations among the attributes of the database that model the outside knowledge a human may use to infer sensitive information. To the best of our understanding, no systematic method has been demonstrated for integrating this outside knowledge into an inference detection system. Our work seeks to remedy this by demonstrating the use of the web for this purpose. When coupled with simple keyword extraction, this general technique allows us to detect inferences in a variety of unstructured documents.

A particular type of inference allows the identification of an individual. Sweeney looks for such inferences using the web in [35], where inferences are enabled by numerical values and other attributes characterizable by regular expressions such as SSNs, account numbers, and addresses. Sweeney does not consider inferences based on English language words. We use the indexing power of search engines to detect when words, taken together, are closely associated with an individual.

The closely related problem of author identification has also been extensively studied by the machine learning community (e.g., [25, 11, 24, 34, 20]). The techniques developed generally rely on a training corpus of documents and use specific attributes like self-citations [20] or writing style [25] to identify authors. Our work can be viewed as exploiting a previously unstudied method of author identification, using information authors reveal about themselves to identify them.

Atallah et al. [2] describe how natural language processing can potentially be used to sanitize sensitive information when the sanitization rules are already known. Our work is focused on using the web to identify the sanitization rules.

### Web-Assisted Query Interpretation
There is a large body of work on using the web to improve query results (e.g., [16, 32, 10]). One fundamental idea that has emerged from this area is to use overlap in query results to establish a connection between distinct queries. In contrast, we analyze the content of the query results to detect connections between the query terms and an individual or topic.

### Web-Based Social Network Analysis
Recently, the web has been used to detect social networks (e.g., [1, 23]). A key idea in this work is using the web to look for co-occurrences of names and using this to infer a link in a social network. Our techniques can support this type of analysis, for example, when names in a network, when entered as a web query, yield a name that is not already in the network. However, our techniques are aimed at a broader goal: understanding all inferences that can be drawn from a document.

### Web-Assisted Content Analysis and Annotation
There is a large body of work on using the web to understand and analyze content. Nakov and Hearst [30] have shown the power of using the web as training data for natural language analysis. Web-assistance for extracting keywords for the purposes of content indexing and annotation is studied in [12, 37, 26]. This work focuses on automated, web-based tools for understanding the meaning of the text as written, as opposed to the inferences that can be drawn based on the text. That said, in our work, we use very simple content analysis tools, and improvements to our approach could involve more sophisticated content analysis tools, including web-based tools such as those developed in these works.

### Web-Based Data Aggregation
Finally, we note that the commercial world is beginning to offer web-based data aggregation tools (e.g., [14, 13, 31]) for tracking competitor behavior, market analysis, and intelligence gathering. We are not aware of support for pre-production inference control in these offerings, which is the focus of this paper.

## 3. Model and Generic Algorithm

Let \( C \) denote a private collection of documents being considered for public release, and let \( R \) denote a collection of reference documents. For example, the collection \( C \) may consist of the blog entries of a writer, and the collection \( R \) may consist of all documents publicly available on the web.

Let \( K(C) \) denote all the knowledge that can be computed from the private collection \( C \). The set \( K(C) \) formally represents all the statements and facts that can be logically derived from the information contained in the collection \( C \). The set \( K(C) \) could, in theory, be computed with a complete and sound theorem prover given all the axioms in \( C \). In practice, such a computation is impossible, and we will instead rely on approximate representations of the set \( K(C) \). Similarly, let \( K(R) \) denote all the knowledge that can be computed from the reference collection \( R \).

Informally stated, the problem of inference control arises because the knowledge that can be extracted from the union of the private and reference collections \( K(C \cup R) \) is typically greater than the union \( K(C) \cup K(R) \) of what can be extracted separately from \( C \) and \( R \). The inference control problem is to understand and control the difference:
\[ \text{Diff}(C, R) = K(C \cup R) - (K(C) \cup K(R)) \]

Returning to the Osama Bin Laden example discussed in the introduction, consider the case where the collection \( C \) consists of the single declassified FBI document [8], and where \( R \) consists of all information publicly available on the web. Let \( S \) denote the statement: "The declassified FBI document is a biography of Osama Bin Laden." Since the identity of the person to whom the document pertains has been redacted, it is impossible to learn the statement \( S \) from \( C \) alone, and so \( S \notin K(C) \). The statement \( S \) is clearly not in \( K(R) \) either since it is impossible to compute from \( R \) alone a statement about a document that is in \( C \). It follows that \( S \) does not belong to \( K(C) \cup K(R) \). But, as shown earlier, the statement \( S \) belongs to \( K(C \cup R) \). Indeed, we can infer \( S \) by combining the information in \( C \) and \( R \).

This example illustrates the importance of our approach in detecting and controlling inferences that can be made by combining private and public data.