---
title: Monitor queued ingestion in Azure Data Explorer
description: Learn how to use Azure Data Explorer metrics to monitor queued ingestion to Azure Data Explorer in Azure portal.
ms.reviewer: tzviagt
ms.topic: how-to
ms.date: 07/18/2021
ms.custom: contperf-fy21q1
---
# Monitor queued ingestion with metrics
In the *queued ingestion* process, Azure Data Explorer optimizes [data ingestion](ingest-data-overview.md) for high throughput by batching incoming small chunks of data into batches based on a configurable [ingestion batching policy](kusto/management/batching-policy.md). The batching policy allows you to set the trigger conditions for sealing a batch (data size, number of blobs, or time passed). These batches are then optimally ingested for fast query results.
In this article, you will learn how to use metrics to monitor queued ingestion to Azure Data Explorer in Azure portal.
## Batching stages
The stages described in this section apply to all batching ingestions. For Azure Event Grid, Azure Event Hubs, Azure IoT Hub and Cosmos DB ingestions, before the data is queued for ingestion a *data connection* gets the data from external sources and performs an initial data rearrangement.
Queued ingestion occurs in stages:
1. The *Batching Manager* listens to the queue for ingestion messages and processes requests.
1. The *Batching Manager* optimizes the ingestion throughput by taking the small ingress data chunks that it receives and batching the URLs based on the ingestion batching policy.
1. The *Ingestion Manager* sends the ingestion commands to the *Azure Data Explorer Storage Engine*.
1. The *Azure Data Explorer Storage Engine* stores the ingested data, making it available for query.
Azure Data Explorer provides a set of Azure Monitor [ingestion metrics](using-metrics.md#ingestion-metrics) so that you can monitor your data ingestion across all the stages and components of the queued ingestion process.
The Azure Data Explorer ingestion metrics give you detailed information about:
* The result of the queued ingestion.
* The amount of ingested data.
* The latency of the queued ingestion and where it occurs.
* The batching process itself.
* For Event Hubs, Event Grid, and IoT Hub ingestions: The number of events received.
In this article, you'll learn how to use ingestion metrics in the Azure portal to monitor queued ingestion to Azure Data Explorer.
## Prerequisites
* An Azure subscription. Create a [free Azure account](https://azure.microsoft.com/free/).
* An Azure Data Explorer cluster and database. [Create a cluster and database](create-cluster-and-database.md).
* An active queued ingestion, such as [Event Hubs](ingest-data-event-hub-overview.md), [IoT Hub](ingest-data-iot-hub-overview.md), or [Event Grid](ingest-data-event-grid-overview.md).
## Create metric charts with Azure Monitor metrics explorer
The following is a general explanation of how to use the Azure Monitor metrics that will then be implemented in subsequent sections.
Use the following steps to create metric charts with the [Azure Monitor metrics explorer](/azure/azure-monitor/essentials/metrics-getting-started) in Azure portal:
1. Sign in to the [Azure portal](https://portal.azure.com/) and navigate to the overview page for your Azure Data Explorer cluster.
1. Select **Metrics** from the left-hand navigation bar to open the metrics pane.
1. Open the **time picker** panel at the top right of the metrics pane and change the **Time range** to the time you want to analyze. In this article, we're analyzing data ingestion to Azure Data Explorer during the last 48 hours.
1. Select a **Scope** and a **Metric Namespace**:
   * The **Scope** is the name of your Azure Data Explorer cluster. In the following example, we will use a cluster named *demo11*.
   * The **Metric Namespace** should be set to *Kusto Cluster standard metrics*. This is the namespace that contains the Azure Data Explorer metrics.
   :::image type="content" source="media/monitor-batching-ingestion/metrics-settings-selector.png" alt-text="Screenshot showing how to select settings for a metric in Azure portal." lightbox="media/monitor-batching-ingestion/metrics-settings-selector.png":::
1. Select the **Metric** name and the relevant **Aggregation** value.
For some examples in this article, we'll select **Add Filter** and **Apply Splitting** for metrics that have dimensions. We'll also use **Add metric** to plot other metrics in the same chart and **+ New chart** to see multiple charts in one view.
Each time you add a new metric, you'll repeat steps four and five.
> [!NOTE]
> To learn more about how to use metrics to monitor Azure Data Explorer in general and how to work with the metrics pane, see [Monitor Azure Data Explorer performance, health, and usage with metrics](using-metrics.md).
In this article, you'll learn which metrics can be used to track queued ingestion, and how to use these metrics.
## View the ingestion result
The **Ingestion result** metric provides information about the total number of sources that were successfully ingested and those that failed to be ingested.
In this example, we'll use this metric to view the result of our ingestion attempts and use the status information to help troubleshoot any failed attempts.
1. In the **Metrics** pane in Azure Monitor, select **Add Metric**.
1. Select *Ingestion result* as the **Metric** value and *Sum* as the **Aggregation** value. This selection shows you the ingestion results over time in one chart line.
1. Select the **Apply splitting** button above the chart and choose *Status* to segment your chart by the status of the ingestion results. After selecting the splitting values, click away from the split selector to close it.
Now the metric information is split by status, and we can see information about the status of the ingestion results split into three lines:
1. Blue for successful ingestion operations.
2. Orange for ingestion operations that failed because of *Entity not found*.
3. Purple for ingestion operations that failed because of *Bad request*.
:::image type="content" source="media/monitor-batching-ingestion/ingestion-result-by-status-chart.png" alt-text="Screenshot of the Metrics pane in Azure portal showing a chart of ingestion results aggregated by sum and split by status." lightbox="media/monitor-batching-ingestion/ingestion-result-by-status-chart.png":::
Consider the following when looking at the chart of ingestion results:
* When using event hub or IoT hub ingestion, there is an event pre-aggregation in the *Data connection component*. During this stage of ingestion, events are treated as a single source to be ingested. Therefore, a few events appear as a single ingestion result after pre-aggregation.
* Transient failures are retried internally in a limited number of attempts. Each transient failure is reported as a transient ingestion result. That's why a single ingestion may lead to more than one ingestion result.
* Ingestion errors in the chart are listed by the category of the error code. To see the full list of ingestion error codes by categories and try to better understand the possible error reason, see [Ingestion error codes in Azure Data Explorer](error-codes.md).
* To get more details on an ingestion error, you can set [failed ingestion diagnostic logs](using-diagnostic-logs.md#diagnostic-logs-schema). However, it's important to consider that generating logs results in the creation of extra resources, and therefore an increase in the COGS (cost of goods sold).
## View the amount of ingested data
The **Blobs Processed**, **Blobs Received**, and **Blobs Dropped** metrics provide information about the number of blobs that are processed, received, and dropped by the [ingestion components](#batching-stages) during the stages of queued ingestion.
In this example, we'll use these metrics to see how much data passed through the ingestion pipeline, how much data was received by the ingestion components, and how much data was dropped.
### Blobs Processed
1. In the **Metrics** pane in Azure Monitor, select **Add Metric**.
1. Select *Blobs Processed* as the **Metric** value and *Sum* as the **Aggregation** value.
1. Select the **Apply splitting** button and choose *Component Type* to segment the chart by the different ingestion components.
1. To focus on a specific database in your cluster, select the **Add filter** button above the chart and then choose which database values to include when plotting the chart. In this example, we filter on the blobs sent to the *GitHub* database by selecting *Database* as the **Property**, *=* as the **Operator**, and *GitHub* in the **Values** drop-down. After selecting the filter values, click away from the filter selector to close it.
Now the chart shows how many blobs that were sent to the *GitHub* database were processed at each of the ingestion components over time.
:::image type="content" source="media/monitor-batching-ingestion/blobs-processed-by-component-type-chart.png" alt-text="Screenshot of the Metrics pane in Azure portal showing a chart of blobs processed from the github database, aggregated by sum and split by component type." lightbox="media/monitor-batching-ingestion/blobs-processed-by-component-type-chart.png":::
* Notice that on February 13 there's a decrease in the number of blobs that were ingested to the *GitHub* database over time. Also, notice that the number of blobs that were processed at each of the components is similar, meaning that approximately all data processed in the *Data Connection* component was also processed successfully by the *Batching Manager*, *Ingestion Manager*, and *Azure Data Explorer Storage Engine* components. This data is ready for query.
### Blobs Received
To better understand the relation between the number of blobs that were received at each component and the number of blobs that were processed successfully at each component, we'll add a new chart:
1. Select **+ New chart**.
1. Choose the same values as above for **Scope**, **Metric Namespace**, and **Aggregation**, and select the *Blobs Received* metric.
1. Select the **Apply splitting** button and choose *Component Type* to split the *Blobs Received* metric by component type.
1. Select the **Add filter** button and set the same values as before to filter only the blobs sent to the *GitHub* database.
:::image type="content" source="media/monitor-batching-ingestion/blobs-received-and-processed-by-component-type-chart.png" alt-text="Screenshot of the Metrics pane in Azure portal showing charts of blobs processed and blobs received from the github database aggregated by sum and split by component type." lightbox="media/monitor-batching-ingestion/blobs-received-and-processed-by-component-type-chart.png":::
* Comparing the charts, notice that the number of blobs received by each component closely matches the number of blobs that were processed by each component. This comparison indicates that no blobs were dropped during ingestion.
### Blobs Dropped
To determine whether there are blobs that were dropped during ingestion, you should analyze the **Blobs Dropped** metric. This metric shows how many blobs were dropped during ingestion and helps you detect whether there is a problem in processing at a specific ingestion component. For each dropped blob, you will also get an [**Ingestion Result**](#view-the-ingestion-result) metric with more information about the reason for failure.
## View the ingestion latency
The metrics **Stage Latency** and **Discovery Latency** monitor latency in the ingestion process, and tell you if there are any long latencies occurring either in Azure Data Explorer, or before data arrives to Azure Data Explorer for ingestion.
* **Stage Latency** indicates the time span from when a message is discovered by Azure Data Explorer until its content is received by an ingestion component for processing.
* **Discovery Latency** is used for ingestion pipelines with data connections (such as event hub, IoT hub, and Event Grid). This metric gives information about the time span from data enqueue until discovery by Azure Data Explorer data connections. This time span is upstream to Azure Data Explorer, so it's not included in the **Stage Latency** metric that only measures the latency in Azure Data Explorer.