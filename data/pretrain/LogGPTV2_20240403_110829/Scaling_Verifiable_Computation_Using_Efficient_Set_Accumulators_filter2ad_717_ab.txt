Merkle tree [90]. To review, this is a binary tree that stores a
vector in the labels of its leaves; the label associated with an
internal node of this tree is the result of applying a collision-
resistant hash H to the concatenation of the children’s labels;
and the digest representing the collection is the label of the
root node.
A membership proof for the leaf at index i is a path through
the tree, i.e., the labels of the siblings of all nodes between
the purported leaf and the root. Verifying the proof requires
computing the node labels along the path and comparing the
ﬁnal value to the digest (the bits of i indicate whether each
node is the right or left child of its parent). Updating a leaf’s
label is closely related: given a membership proof for the old
value, the new digest is computed by swapping the old leaf
for the new one, then computing the hashes along the path.
Merkle trees do not support succinct non-membership proofs.
The cost of verifying k membership proofs for a vector
comprising 2m values is k· m evaluations of H. The cost of k
leaf updates is 2· k· m evaluations. Membership proofs and
updates cannot be batched for savings.
RSA accumulators. The RSA multiset accumulator [40,
81] represents a multiset S with the digest
(cid:74)S(cid:75) = g∏s∈S H(s) ∈ G,
where g is a ﬁxed member of an RSA quotient group G and
H is a division-intractable hash function (§2). Inserting a new
To prove membership of s ∈ S, the prover furnishes the
element s into S thus requires computing(cid:74)S(cid:75)H(s).
value π =(cid:74)S(cid:75)1/H(s), i.e., a H(s)’th root of(cid:74)S(cid:75). This proof is
veriﬁed by checking that πH(s) =(cid:74)S(cid:75).
Non-membership proofs are also possible [81], leveraging
the fact that s(cid:48) (cid:54)∈ S if and only if gcd(H(s(cid:48)),∏s∈S H(s)) =
1. This means that the Bézout coefﬁcients a,b, i.e., integers
satisfying
are a non-membership witness, since the above implies that
H(s) = 1
a· H(s(cid:48)) + b·∏
s∈S
(cid:74)S(cid:75)b · (ga)H(s(cid:48)) = g
Because a is large and b is small, the proof (ga,b) is succinct.
Insertions, membership proofs, and non-membership
proofs can all be batched [24] via Wesolowski proofs (§2). For
example, since(cid:74)S(cid:93){si}(cid:75) =(cid:74)S(cid:75)∏i si, computing an updated
digest directly requires an exponentiation by ∏i si. In contrast,
checking the corresponding proof only requires computing
and then exponentiating by ∏i si mod (cid:96), for (cid:96) a prime of less
than 200 bits. This means that the exponentiation (but not the
multiplication) to verify a batch proof has constant size.
2.2 Veriﬁable computation and SNARKs
Several lines of built systems [13, 15, 16, 21, 32, 47, 49, 61,
79, 96, 106–108, 112, 113, 124] enable the following high-
level model.2 A veriﬁer V asks a prover P to convince it that
y = Ψ(x), where Ψ is a program taking input x and returning
output y. To do so, P produces a short certiﬁcate that the
claimed output is correct. Completeness holds with εc = 0;
soundness holds as long as P is computationally bounded,
with εs negligible in a security parameter (§2).
Roughly speaking, these systems comprise two parts. In
the front-end, V compiles Ψ into a system of equations
C (X,Y,Z), where X,Y , and Z are (vectors of) formal variables.
V constructs C such that z satisfying C (X = x,Y = y,Z = z)
exists (that is, the formal variable X is bound to the value x,
and so on) if and only if y = Ψ(x). The back-end comprises
cryptographic and complexity-theoretic machinery by which
P convinces V that a witness z exists for X = x and Y = y.
This paper focuses on compilation in the front-end. We
target back-ends derived from GGPR [64] via Pinocchio [96]
(including [15, 16, 70]), which we brieﬂy describe below.
2The description in this section owes a textual and notational debt to the
description in Buffet [116], which works in the same model.
USENIX Association
29th USENIX Security Symposium    2077
Our work is also compatible with other back-ends, e.g., Za-
atar [106], Ligero [2], Bulletproofs [36], Sonic [85], and Au-
rora [14].3
GGPR, Pinocchio and their derivatives instantiate zero-
knowledge Succinct Non-interactive ARguments of Knowl-
edge with preprocessing (zkSNARKs), which are argument
protocols satisfying completeness, knowledge soundness, and
zero knowledge (§2),4 where knowledge soundness and zero
knowledge apply to the assignment to Z. In addition, these
protocols satisfy succinctness: informally, proof length and
veriﬁcation time are both sublinear in |C| (here, proofs are of
constant size, while V ’s work is O(|X| +|Y|)). These proto-
cols include a preprocessing phase, in which V (or someone
that V trusts) processes C to produce a structured reference
string (SRS), which is used by P to prove and V to verify.
The cost of the preprocessing phase and the length of the SRS
are O(|C|). The cost of the proving phase is O(|C|log|C|) in
time and O(|C|) in space (i.e., prover RAM).
The system of equations C (X,Y,Z) is a rank-1 constraint
system (R1CS) over a large ﬁnite ﬁeld Fp. An R1CS is deﬁned
by three matrices, A,B,C ∈ F|C|×(1+|X|+|Y|+|Z|)
. Its satisﬁabil-
ity is deﬁned as follows: for W the column vector of formal
(cid:124)
, C (X,Y,Z) is the system of |C| equa-
variables [1,X,Y,Z]
tions (A·W )◦ (B·W ) = C·W , where ◦ denotes the Hadamard
(element-wise) product. In other words, an R1CS C is a con-
junction of |C| constraints in |X| +|Y| +|Z| variables, where
each constraint has the form “linear combination times linear
combination equals linear combination.”
p
These facts outline a computational setting whose costs
differ signiﬁcantly from those of CPUs. On a CPU, bit oper-
ations are cheap and word-level arithmetic is slightly more
costly. In an R1CS, addition is free, word-level multiplication
has unit cost, and bitwise manipulation and many inequality
operations are expensive; details are given below.
Compiling programs to constraints. A large body of prior
work [13, 16, 32, 79, 96, 106–108, 115, 116] deals with
efﬁciently compiling from programming languages to con-
straints.
An important technique for non-arithmetic operations is
the use of advice, variables in Z whose values are provided
by the prover. For example, consider the program fragment
x != 0, which cannot be concisely expressed in terms of
rank-1 constraints. Since constraints are deﬁned over Fp, this
assertion might be rewritten as X p−1 = 1, which is true just
when X (cid:54)= 0 by Fermat’s little theorem. But this is costly: it
requires O(log p) multiplications. A less expensive way to
express this constraint is Z · X = 1; the satisfying assignment
3We do not target STARK [11] (which uses a different C representation)
or systems built on GKR [67] and CMT [47], e.g., vRAM [124], Hyrax [117],
and Libra [122] (which restrict C in ways this work does not comprehend).
4We do not target zero-knowledge applications in this work, but our
techniques may be applicable in that setting when combined with prior zero-
knowledge approaches for RSA accumulators [40]; this is future work.
to Z is X−1 ∈ Fp. Since every element of Fp other than 0 has
a multiplicative inverse, this is satisﬁable just when X (cid:54)= 0.
Comparisons, modular reductions, and bitwise operations
make heavy use of advice from P . For example, the program
fragment y = x1 & x2, where x1 and x2 have bit width b and
& is bitwise AND, is represented by the following constraints:
Z1,0 + 2· Z1,1 + . . . + 2b−1 · Z1,b−1 = X1
Z2,0 + 2· Z2,1 + . . . + 2b−1 · Z2,b−1 = X2
Z3,0 + 2· Z3,1 + . . . + 2b−1 · Z3,b−1 = Y
Z1,0 · (1− Z1,0) = 0
. . .
Z1,b−1 · (1− Z1,b−1) = 0
Z2,0 · (1− Z2,0) = 0
. . .
Z2,b−1 · (1− Z2,b−1) = 0
Z1,0 · Z2,0 = Z3,0
. . .
Z1,b−1 · Z2,b−1 = Z3,b−1
Here, the variables Z1,0 . . .Z1,b−1 contain a purported bitwise
expansion of X1, and likewise Z2,0 . . .Z2,b−1 and Z3,0 . . .Z3,b−1
for X2 and Y , respectively. The ﬁrst three constraints ensure
that the assignment to Z meets this requirement provided that
each Zi, j is assigned either 0 or 1; the remaining constraints
ensure the latter. This operation is known as bit splitting; its
cost for a b-bit value is b + 1, so the above program fragment
costs 3· b + 3 constraints in total. Comparisons and modular
reductions also require bit splitting.
Compiling conditionals to constraints requires expanding
all branches into their corresponding constraints and selecting
the correct result. Loops are similar; loop bounds must be
statically known. For example, the program fragment
if (x1 != 0) { y = x2 + 1 } else { y = x2 * 3 }
compiles to the constraints
Z1 · X1 = Z2
Z3 · (Z2 − 1) = 0
(1− Z3)· X1 = 0
(1− Z3)· (Y − X2 − 1) = 0
Z3 · (Y − 3· X2) = 0
(1)
(2)
(3)
(4)
(5)
1 by (1), and Y = 3· X2 by (5).
This works as follows: if X1 = 0, Z2 = 0 by (1), so Z3 = 0
by (2) and Y = X2 + 1 by (4). Otherwise, Z3 = 1 by (3), so
Z2 = 1 by (2), Z1 = X−1
Multiprecision arithmetic. xJsnark [79] describes tech-
niques for compiling multiprecision arithmetic to efﬁcient
constraint systems. In brief, large integers are represented as
a sequence of limbs in Fp. The limb width, bl, is deﬁned such
2078    29th USENIX Security Symposium
USENIX Association
that a b-bit number a is represented as η = (cid:100)b/bl(cid:101) limbs { ˆai},
where a = ∑η−1
i=0 ˆai · 2bl·i. For correctness, the compiler must
track the maximum value of each number and ensure that C
contains constraints that encode a sufﬁcient number of limbs.
Multiprecision operations rely heavily on advice from P .
At a high level, P supplies the result of a multiplication or
addition, and the compiler emits constraints to check that re-
sult. Subtractions and divisions are checked by verifying the
inverse addition or multiplication, respectively. xJsnark de-
scribes a range of optimizations that reduce the required num-
ber of constraints. We leave details to [79], because they are
not necessary to understand our further optimizations (§4.3).
Random-access memory
Programs that make use of RAM—in particular, programs
whose memory accesses depend on the input, and thus cannot
be statically analyzed—present a challenge for compiling to
constraints. Prior work demonstrates three solutions. We now
describe each, and compare costs and functionality below.
Linear scan. The most direct approach to emulating RAM
in constraints is to perform a linear scan [79, 96]. Concretely,
Y = LOAD(Z) compiles to a loop that scans through an array,
comparing the loop index to Z and, if they match, setting Y
to the corresponding value. (STORE is analogous.)
The Pantry approach.
In Pantry [32], the authors borrow a
technique from the memory-checking literature [20] based on
Merkle trees [90] (see also §2.1). In particular, Pantry stores
the contents of RAM in the leaves of a Merkle tree whose
root serves as ground truth for the state of memory.
For a LOAD, P furnishes advice comprising a purported
value from memory, plus a Merkle path authenticating that
value. The corresponding constraints encode veriﬁcation of
the Merkle path, i.e., a sequence of hash function invocations
and an equality check against the Merkle root. For a STORE,
P furnishes, and the constraints verify, the same values as
for a LOAD. In addition, the constraints encode a second
sequence of hash function invocations that compute a new
Merkle root corresponding to the updated memory state.
The BCGT approach. Ben-Sasson et al. [12] introduce,
and other work [13, 16, 79, 116] reﬁnes, an approach build-
ing on the observation [3] that one can check a sequence of
RAM operations using an address-ordered transcript, i.e.,
the sequence of RAM operations sorted by address accessed,
breaking ties by execution order. In such a transcript, each
LOAD is preceded either by the corresponding STORE or by
another LOAD from the same address; correctness of RAM
dictates that this LOAD should return the same value as the
preceding operation. (A LOAD from an address to which no
value was previously stored returns a default value, say, 0.)
Leveraging this observation, correctness of memory opera-
tions is compiled to constraints as follows. First, every access
to memory appends a tuple (IDXi, OPi, ADDRi, DATAi) to an
execution-ordered transcript; here, IDXi = i is the index of the
memory operation and OPi is either LOAD or STORE. Then
P furnishes a purported address-ordered transcript T , and
the constraints check its correctness by ensuring that (1) tran-
script T is a permutation of the execution-ordered transcript,
(2) each sequential pair of entries in transcript T is indeed