title:Extraction of statistically significant malware behaviors
author:Sirinda Palahan and
Domagoj Babic and
Swarat Chaudhuri and
Daniel Kifer
Extraction of Statistically Signiﬁcant Malware Behaviors
Sirinda Palahan
Penn State University
PI:EMAIL
Swarat Chaudhuri
Rice University
PI:EMAIL
ABSTRACT
Traditionally, analysis of malicious software is only a semi-
automated process, often requiring a skilled human analyst.
As new malware appears at an increasingly alarming rate —
now over 100 thousand new variants each day — there is a
need for automated techniques for identifying suspicious be-
havior in programs. In this paper, we propose a method for
extracting statistically signiﬁcant malicious behaviors from
a system call dependency graph (obtained by running a bi-
nary executable in a sandbox). Our approach is based on a
new method for measuring the statistical signiﬁcance of sub-
graphs. Given a training set of graphs from two classes (e.g.,
goodware and malware system call dependency graphs), our
method can assign p-values to subgraphs of new graph in-
stances even if those subgraphs have not appeared before in
the training data (thus possibly capturing new behaviors or
disguised versions of existing behaviors).
1.
INTRODUCTION
Signature-based detection has been a major technique in
commercial anti-virus software. However, that approach is
ineﬀective against code obfuscation techniques. To address
this problem, most of the current work, e.g., [1, 7, 12, 10],
has focused on behavior-based detection techniques because
the semantics of malware are unlikely to change even after
a series of syntactic code transformations.
To develop eﬀective behavior-based detection techniques,
it is important to understand how malware behaves. Pre-
vious studies (e.g., [14, 20]) typically used experts to con-
struct malware speciﬁcations that describe malicious behav-
iors. This requires deep expertise and is costly in terms of
time and eﬀort. To address the problem, Christodorescu, et
al. [7] and Fredrikson et al. [12] proposed methods to auto-
matically generate speciﬁcations of malicious activity from
samples of malicious and benign executables. These meth-
ods only recognize behaviors that appeared in the training
∗
This work was done while Domagoj was with UC Berkeley.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from Permissions@acm.org.
ACSAC ’13, December 09 - 13 2013, New Orleans, LA, USA
Copyright 2013 ACM 978-1-4503-2015-3/13/12 ...$15.00
http://dx.doi.org/10.1145/2523649.2523659 .
69
∗
PI:EMAIL
Domagoj Babi´c
Google, Inc.
Daniel Kifer
Penn State University
PI:EMAIL
data and they do not provide scores that indicate the statis-
tical conﬁdence that a (possibly new) behavior is malicious.
In this paper, we propose a new method for identifying
malicious behavior and assigning it a p-value (a measure of
statistical conﬁdence that the behavior is indeed malicious).
It requires a training set consisting of malware and good-
ware executables. Using dynamic program analysis tools,
we represent each executable as a graph. We then train a
linear classiﬁer to discriminate between malware and good-
ware; the parameters of this classiﬁer are crucial for our
statistical test. To evaluate a new executable, we can use
the linear classiﬁer to categorize it as goodware or malware.
To then identify its suspicious behaviors, we again represent
it as a graph and use a subgraph mining algorithm to ex-
tract a candidate subgraph. We assign conﬁdence scores to
this subgraph with statistical procedures that use the classi-
ﬁer weights obtained from the training phase; the statistical
procedures work for any subgraph, even if it did not appear
in the training data. The framework is simple and modu-
lar – one can plug in diﬀerent program analysis tools, linear
classiﬁers, and subgraph mining algorithms to take advan-
tage of progress in those areas. Our statistical tests work
with all of these options and are easy to implement.
It is important to note that the evaluation of malware
speciﬁcations is a challenging task. Manual construction
of malware speciﬁcations is labor-intensive and error-prone;
the resulting relatively small quantity of speciﬁcations will
often have high false positive rates [14]. Other work [7,
12] compared extracted malware behavior in the form of
graphs to textual descriptions provided by anti-virus com-
panies (apparently also manually).
In this paper we take
a more automated approach designed to reduce the risk of
experimenter bias. We use carefully designed experiments
to both validate the quality of the p-values and the quality
of the suspicious executable behaviors that were identiﬁed.
In summary, the contributions of this paper are:
1. A framework for identifying suspicious behavior in pro-
grams and assigning them statistical signiﬁcance scores.
The framework is modular, easy to implement, and
does not require the malware test set to exhibit the
same behaviors as the malware training set.
2. A careful empirical evaluation of the extracted behav-
iors. This includes an evaluation of p-values and some
initial experimental evidence for the identiﬁcation of
malicious behaviors not seen in the training data.
We discuss related work in Section 2. We present our
framework in Section 3. The framework includes a training
phase (Section 3.1) and a deployment phase (Section 3.2).
We then empirically evaluate our methods in Section 4.
2. RELATED WORK
2.1 Malware Speciﬁcation
Christodorescu, et al. [7] use contrast subgraph mining
to construct speciﬁcations by comparing syscall dependency
graphs of malware and goodware samples to obtain activ-
ities appearing only in malware. They assess speciﬁcation
quality by manual comparison to speciﬁcations produced by
an expert. This technique does not produce statistical sig-
niﬁcance scores for the speciﬁcations. Comparetti, et al. [8]
propose a novel method to ﬁnd dormant behaviors statically
in binaries, based on manually-provided behavior speciﬁca-
tions. Our work complements theirs, as our approach can
be used to identify statistically signiﬁcant behavior speciﬁca-
tions. Fredrikson, et al. [12] use LEAP [25] to extract behav-
iors that are synthesized by concept analysis and simulated
annealing to generate speciﬁcations. The authors evaluate
their speciﬁcations by manually comparing with behavior
reports from malware experts. Even though LEAP, a signif-
icant subgraph extraction algorithm, is used, no statistical
signiﬁcance value can be calculated for new executables.
2.2 Signiﬁcant Subgraph Extraction
There are relatively few algorithms that extract signiﬁ-
cant subgraphs. LEAP [25] ﬁnds signiﬁcant subgraphs that
are frequent in the positive dataset and rare in the negative
dataset and maximizes a user-deﬁned signiﬁcance function.
For malware detection, it is used to mine the system call
dependency graphs [12]. However, when such a system is
deployed for analyzing new executables, searching for exact
subgraphs could be a brittle approach – LEAP will not iden-
tify malicious behavior if it does not correspond to a graph it
has seen before (a slight change in the graph may be enough
to avoid detection). Our proposed method also mines sys-
tem call dependency graphs but is more ﬂexible and so
can identify signiﬁcant behaviors whose corresponding sub-
graphs have not appeared in the training data. Ranu and
Singh [18] propose GraphSig, a frequent subgraph mining
algorithm, to ﬁnd signiﬁcant subgraphs in large databases.
GraphSig prunes out the search space by testing the signif-
icance of a subgraph; the deﬁnition of signiﬁcance is based
on a subgraph’s frequency. GraphSig uses GraphRank [13]
for the statistical signiﬁcance testing. GraphRank trans-
forms subgraphs to feature vectors and calculates p-values
of vectors based on a binomial model. Note that frequent
subgraphs are not necessarily indicative of malicious behav-
ior encapsulated in system call dependency graphs.
Milo, et al. [16] propose an approach to mine network
motifs which are signiﬁcant subgraphs appearing more fre-
quently in a complex network than in random networks. The
authors generate random networks by permuting edges while
maintaining network properties, such as degree of nodes and
number of edges. The p-value of a subgraph is obtained
by counting random networks that contain the subgraph
with a support (i.e.
frequency) greater than or equal to
the observed support. Milo’s approach may not scale to
very large networks because of the complexity of subgraph
isomorphism. Scott, et al. [19] developed a method to ﬁnd
signiﬁcant protein interaction paths in a large scale protein
network data. A color coding approach is extended to ﬁnd
paths between two given nodes with the minimum sum of
edge weights. They adopt a randomization approach for sta-
tistical signiﬁcance testing – they compare scores of paths
they ﬁnd to scores of paths found in random networks whose
edges have been shuﬄed. Our approach uses randomization
for statistical testing but we carefully avoid comparisons to
random graphs (since they may not be plausible representa-
tions of system call dependency graphs).
3. THE STATISTICAL FRAMEWORK
We next describe the major components of our framework
for identifying statistically signiﬁcant malicious behaviors.
An overview of the framework is shown in Figure 1. There
are two phases: the training phase (where statistical infor-
mation about malware and goodware is collected) and the
deployment phase (for analyzing a new executable).
The training phase (Section 3.1) requires samples of good-
ware and malware executables. These executables are con-
verted into system call dependency graphs (SDG) using dy-
namic analysis (Section 3.1.1). We build a linear classiﬁer to
distinguish malware from goodware and we use its parame-
ters to obtain a function that assigns weights to edges (Sec-
tion 3.1.2); these weights are used by our statistical tests.
The deployment phase (Section 3.2) is used to analyze a
new executable for suspicious behavior. The linear classiﬁer
from the training phase can be used to classify it as mal-
ware or goodware. To extract suspicious behavior, we ﬁrst
build the SDG and assign edge weights based on the param-
eters of the linear classiﬁer. We then use a subgraph mining
algorithm to identify candidate subgraphs (Section 3.2.1);
any subgraph mining algorithm for weighted or unweighted
graphs can be used here as a black box. Then our statis-
tical tests (Section 3.2.2) assign signiﬁcance scores to the
behaviors associated with those subgraphs. These tests use
the edge weights to assign p-values and automatically cor-
rect for the multiple testing problem (explained in Section
3.2.2), which is an important concern in subgraph mining.
3.1 The Training Phase
System Call Dependency Graphs (SDGs)
We now describe the two components of the training phase:
building system call dependency graphs and building a linear
malware classiﬁer whose parameters will be used to assign
weights to edges in those graph.
3.1.1
Recent research (e.g., [23, 4]) shows that a program’s be-
havior can be inferred from its pattern of system calls. The
outputs produced by some system calls can aﬀect the inputs
of other system calls. Hence, it is natural and common to
represent a program’s behavior using a system call depen-
dency graph (SDG) whose nodes correspond to system call
invocations and whose directed edges represent data ﬂow be-
tween pairs of system calls. This abstraction converts pro-
gram analysis into a graph mining problem where subgraphs
correspond to program behaviors.
Definition 1
(SDG). A system call dependency graph
(SDG) is a directed graph G(E, V ) representing data-ﬂow
dependencies among system call invocations, where V is the
set of invoked system calls and E ⊂ V ×V is a set of directed
edges. The directed edge, (x, y) ∈ E , from vertex x to vertex
y indicates that the output of system call invocation x is
consumed by system call invocation y.
70
(a) Training phase
(b) Deployment phase
Figure 1: Framework overview – identifying statistically signiﬁcant malicious behavior
To create an SDG, we must execute a program in a sand-
box, trace its system calls, and infer dependencies between
the system call invocations. The most accurate method for
doing this is dynamic taint analysis [17], although our at-
tempts to reproduce existing work (such as [3]), show that
faster heuristic methods can work just as well. Our frame-
work can work with any SDG generator, however, our exper-
iments used WUSSTrace [24] (which injects a shared library
into the address space of a traced process) to generate pro-
gram execution traces and Pywuss [3] to parse these traces
to generate an approximate SDG. Pywuss creates a directed
edge between two system call invocations x and y, if x re-
turns a handle that is used as an input to y. An SDG is
created for each executable in the training set.
Note that disassembling and static analysis or statisti-
cal analysis of a binary can provide additional information
about a program. Incorporating this information into our
framework is a direction for future work.
3.1.2 Adding Weights with Linear Classiﬁers
Given a set of SDGs belonging to goodware and malware
executables, the next step is to build a malware classiﬁer
and use its parameters to assign weights to the edges of
those graphs. We convert each SDG into a feature vector
by generating one feature for each ordered pair (x, y); the
value of the feature is the number of times (x, y) appeared
in the SDG. Using these feature vectors, we then train a
linear classiﬁer (such as logistic regression) to discriminate
between malware and goodware. In this way, the linear clas-
siﬁer learns a weight w(x,y) for each ordered pair of system
calls (x, y); a positive value of w(x,y) indicates that (x, y) is
associated with malware and a negative value indicates it
is associated with goodware. The result is a weighted SDG
where each edge (x, y) has weight w(x,y). These weights will
be used for subgraph extraction and signiﬁcance testing.
3.2 The Deployment Phase
The deployment phase is used to analyze a new executable.
First, we obtain its SDG as in Section 3.1.1. We then assign
weights to the edges of the graph using the same weights
that were learned in the training phase (see Section 3.1.2).
The next steps are to use a subgraph mining algorithm to
identify candidate subgraphs that may correspond to suspi-
cious behaviors and then to assign them a statistical con-
ﬁdence score. We discuss subgraph extraction in Section
3.2.1. The mining algorithms can use the edge weights to
identify suspicious subgraphs. Since the weights are also
part of the statistical test, we must automatically account
for variations of the multiple testing problem. We address
this issue and present our statistical tests in Section 3.2.2.
3.2.1
A subgraph of an SDG corresponds to a behavior exhib-
ited by an executable. A subgraph can be deemed suspicious
when it contains many edges with positive weights, espe-
cially when the concentration of positively-weighted edges
in the subgraph is higher than in the rest of the SDG.
Subgraph Extraction
Any algorithm for ﬁnding (weighted) subgraphs can be
used as a black box in our framework. The goal of subgraph
mining here is to identify subgraphs with high concentra-
tions of positive weights (rather than speciﬁcally searching
for subgraphs or templates that previously appeared in the
training data). This corresponds to the hypothesis that sys-
tem calls which commonly participate in malicious behavior
are used together to achieve their purpose. In practice, the
SDG has many small connected components and so it makes
sense to return a subgraph consisting of several disjoint con-
nected components.
In our implementation, we use a variation Kruskal’s span-
ning tree algorithm [9] to ﬁnd subgraphs (not necessarily
trees) in each connected component of the SDG. The key
steps appear in Algorithm 2 (kMines). Initially, each node
u is its own temporary subgraph (which will later grow).
Graph(u) is the temporary subgraph containing u. The al-
gorithm considers each edge (u, v) in descending order by
weight. Let Edge(u, v) be the union of edges in Graph(u),
Graph(v), and the edges connecting them. Line 7 heuristi-
cally merges Graph(u) and Graph(v) (and the edges between
them) if the sum of weights of edges in Edge(u, v) is greater
than or equal to k times the maximum weight in Edge(u, v)
(where 0 < k ≤ 1).. The condition encourages the algo-
rithm to merge temporary subgraphs instead of returning
many small subgraphs (possibly with just one edge each)
These key steps are wrapped inside Algorithm 1 which
returns the ﬁnal subgraph B (possibly consisting of disjoint
connected components). Algorithm 1 applies Algorithm 2
(kMine) to each connected component g of the SDG. It then
orders the subgraphs returned by kMine in descending order
by average weight (lines 5-6) and iteratively adds them to
B. The algorithm keeps iterating until the addition of a
new subgraph to B increases sum of weights by less than
p%. Afterwards it returns B as the ﬁnal extracted subgraph
71
(lines 8-14) . Our implementation uses k = 0.5 and p = 5%,
which were chosen subjectively from a few data samples so
that the returned subgraphs were not too big (i.e. a large
fraction of the original graph) nor too small (a few edges).
Algorithm 1 Kruskal-based subgraph extraction
(cid:2)
kMine(g,k)
Input: G (a weighted SDG), p, k
Output: B, a collection of subgraphs
1: S ← ∅
2: for all connected components g in G do
S ← S
3:
4: end for
5: Sort components in S by decreasing average weight
6: B ← max{s|component s ∈ S}
7: S ← S \{B}
8: for each connected component s in S do
9:
if (sum weight(B,s) - sum weight(B))≥ p∗sum weight(B)
then
B ← B