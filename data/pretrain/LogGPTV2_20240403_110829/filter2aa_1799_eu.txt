$DATA stream
Before the
Next encryption
Cycle
$EfsBackup
Non-encrypted data
New clusters containing encrypted data
0 MB
2 MB
4 MB
6 MB
8 MB
10 MB
12 MB
16 MB
Encrypted
region
High watermark
Non-Encrypted
region
0 MB
2 MB
4 MB
6 MB
8 MB
10 MB
12 MB
16 MB
Encrypted
region
High watermark
Non-Encrypted
region
0 MB
2 MB
4 MB
6 MB
8 MB
10 MB
12 MB
16 MB
Encrypted
region
High watermark
Non-Encrypted
region
End of the
locked range
End of the
locked range
FIGURE 11-72 Example of an ongoing online encryption for a 16MB file. 
The new implementation allows NTFS to encrypt or decrypt in place, getting rid of temporary files 
(see the previous “Encrypting file data” section for more details). More importantly, it allows NTFS to 
perform file encryption and decryption while other applications can still use and modify the target file 
stream (the time spent with the exclusive lock hold is small and not perceptible by the application that 
is attempting to use the file).
Direct Access (DAX) disks
Persistent memory is an evolution of solid-state disk technology: a new kind of nonvolatile storage 
medium that has RAM-like performance characteristics (low latency and high bandwidth), resides on 
the memory bus (DDR), and can be used like a standard disk device.
Direct Access Disks (DAX) is the term used by the Windows operating system to refer to such persis-
tent memory technology (another common term used is storage class memory, abbreviated as SCM). A 
nonvolatile dual in-line memory module (NVDIMM), shown in Figure 11-73, is an example of this new type 
of storage. NVDIMM is a type of memory that retains its contents even when electrical power is removed. 
“Dual in-line” identifies the memory as using DIMM packaging. At the time of writing, there are three 
different types of NVDIMMs: NVIDIMM-F contains only flash storage; NVDIMM-N, the most common, is 
CHAPTER 11
Caching and file systems
721
produced by combining flash storage and traditional DRAM chips on the same module; and NVDIMM-P 
has persistent DRAM chips, which do not lose data in event of power failure.
One of the main characteristics of DAX, which is key to its fast performance, is the support of zero-
copy access to persistent memory. This means that many components, like the file system driver and 
memory manager, need to be updated to support DAX, which is a disruptive technology.
Windows Server 2016 was the first Windows operating system to supports DAX: the new storage 
model provides compatibility with most existing applications, which can run on DAX disks without any 
modification. For fastest performance, files and directories on a DAX volume need to be mapped in 
memory using memory-mapped APIs, and the volume needs to be formatted in a special DAX mode. 
At the time of this writing, only NTFS supports DAX volumes.
FIGURE 11-73 An NVDIMM, which has DRAM and Flash chips. An attached battery or on-board supercapacitors are 
needed for maintaining the data in the DRAM chips.
The following sections describe the way in which direct access disks operate and detail the archi-
tecture of the new driver model and the modification on the main components responsible for DAX 
volume support: the NTFS driver, memory manager, cache manager, and I/O manager. Additionally, 
inbox and third-party file system filter drivers (including mini filters) must also be individually updated 
to take full advantage of DAX.
DAX driver model
To support DAX volumes, Windows needed to introduce a brand-new storage driver model. The SCM 
Bus Driver (Scmbus.sys) is a new bus driver that enumerates physical and logical persistent memory 
(PM) devices on the system, which are attached to its memory bus (the enumeration is performed 
thanks to the NFIT ACPI table). The bus driver, which is not considered part of the I/O path, is a primary
bus driver managed by the ACPI enumerator, which is provided by the HAL (hardware abstraction 
layer) through the hardware database registry key (HKLM\SYSTEM\CurrentControlSet\Enum\ACPI). 
More details about Plug  Play Device enumeration are available in Chapter 6 of Part 1.
722
CHAPTER 11
Caching and file systems
Figure 11-74 shows the architecture of the SCM storage driver model. The SCM bus driver creates 
two different types of device objects:
I 
Physical device objects (PDOs) represent physical PM devices. A NVDIMM device is usually
composed of one or multiple interleaved NVDIMM-N modules. In the former case, the SCM bus
driver creates only one physical device object representing the NVDIMM unit. In the latter case,
it creates two distinct devices that represent each NVDIMM-N module. All the physical devices
are managed by the miniport driver, Nvdimm.sys, which controls a physical NVDIMM and is
responsible for monitoring its health.
I 
Functional device objects (FDOs) represent single DAX disks, which are managed by the persis-
tent memory driver, Pmem.sys. The driver controls any byte-addressable interleave sets and is
responsible for all I/O directed to a DAX volume. The persistent memory driver is the class driver
for each DAX disk. (It replaces Disk.sys in the classical storage stack.)
Both the SCM bus driver and the NVDIMM miniport driver expose some interfaces for communica-
tion with the PM class driver. Those interfaces are exposed through an IRP_MJ_PNP major function 
by using the IRP_MN_QUERY_INTERFACE request. When the request is received, the SCM bus driver 
knows that it should expose its communication interface because callers specify the {8de064ff-b630-
42e4-ea88-6f24c8641175} interface GUID. Similarly, the persistent memory driver requires communica-
tion interface to the NVDIMM devices through the {0079c21b-917e-405e-cea9-0732b5bbcebd} GUID.
Type specific 
NVDIMM drivers
Management 
status of the 
physical NVDIMM
Management 
status of the 
logical disk
I/O  
(block and DAX)
User mode
Kernel mode
ACPI.sys
nvdimm.sys
scmbus.sys
pmem.sys
nvdimm.sys
UAFI
Common PM 
disk driver
Does I/O directly 
to the NVDIMM
FIGURE 11-74 The SCM Storage driver model.
The new storage driver model implements a clear separation of responsibilities: The PM class driver man-
ages logical disk functionality (open, close, read, write, memory mapping, and so on), whereas NVDIMM 
drivers manage the physical device and its health. It will be easy in the future to add support for new types 
of NVDIMM by just updating the Nvdimm.sys driver. (Pmem.sys doesn’t need to change.)
DAX volumes
The DAX storage driver model introduces a new kind of volume: the DAX volumes. When a user first 
formats a partition through the Format tool, she can specify the /DAX argument to the command line. If 
the underlying medium is a DAX disk, and it’s partitioned using the GPT scheme, before creating the basic 
disk data structure needed for the NTFS file system, the tool writes the GPT_BASIC_DATA_ ATTRIBUTE_DAX
CHAPTER 11
Caching and file systems
723
flag in the target volume GPT partition entry (which corresponds to bit number 58). A good reference 
for the GUID partition table is available at https://en.wikipedia.org/wiki/GUID_Partition_Table.
When the NTFS driver then mounts the volume, it recognizes the flag and sends a STORAGE_
QUERY_PROPERTY control code to the underlying storage driver. The IOCTL is recognized by the SCM 
bus driver, which responds to the file system driver with another flag specifying that the underlying 
disk is a DAX disk. Only the SCM bus driver can set the flag. Once the two conditions are verified, and as 
long as DAX support is not disabled through the HKLM\System\CurrentControlSet \Control\FileSystem\
NtfsEnableDirectAccess registry value, NTFS enables DAX volume support.
DAX volumes are different from the standard volumes mainly because they support zero-copy ac-
cess to the persistent memory. Memory-mapped files provide applications with direct access to the un-
derlying hardware disk sectors (through a mapped view), meaning that no intermediary components 
will intercept any I/O. This characteristic provides extreme performance (but as mentioned earlier, can 
impact file system filter drivers, including minifilters).
When an application creates a memory-mapped section backed by a file that resides on a DAX vol-
ume, the memory manager asks the file system whether the section should be created in DAX mode, 
which is true only if the volume has been formatted in DAX mode, too. When the file is later mapped 
through the MapViewOfFile API, the memory manager asks the file system for the physical memory 
range of a given range of the file. The file system driver translates the requested file range in one or 
more volume relative extents (sector offset and length) and asks the PM disk class driver to translate 
the volume extents into physical memory ranges. The memory manager, after receiving the physical 
memory ranges, updates the target process page tables for the section to map directly to persistent 
storage. This is a truly zero-copy access to storage: an application has direct access to the persistent 
memory. No paging reads or paging writes will be generated. This is important; the cache manager is 
not involved in this case. We examine the implications of this later in the chapter.
Applications can recognize DAX volumes by using the GetVolumeInformation API. If the returned 
flags include FILE_DAX_VOLUME, the volume is formatted with a DAX-compatible file system (only 
NTFS at the time of this writing). In the same way, an application can identify whether a file resides on 
a DAX disk by using the GetVolumeInformationByHandle API.
Cached and noncached I/O in DAX volumes
Even though memory-mapped I/O for DAX volumes provide zero-copy access to the underlying stor-
age, DAX volumes still support I/O through standard means (via classic ReadFile and WriteFile APIs). 
As described at the beginning of the chapter, Windows supports two kinds of regular I/O: cached and 
noncached. Both types have significant differences when issued to DAX volumes.
Cached I/O still requires interaction from the cache manager, which, while creating a shared cache 
map for the file, requires the memory manager to create a section object that directly maps to the 
PM hardware. NTFS is able to communicate to the cache manager that the target file is in DAX-mode 
through the new CcInitializeCacheMapEx routine. The cache manager will then copy data from the user 
buffer to persistent memory: cached I/O has therefore one-copy access to persistent storage. Note that 
cached I/O is still coherent with other memory-mapped I/O (the cache manager uses the same section); 
724
CHAPTER 11
Caching and file systems
as in the memory-mapped I/O case, there are still no paging reads or paging writes, so the lazy writer 
thread and intelligent read-ahead are not enabled.
One implication of the direct-mapping is that the cache manager directly writes to the DAX disk as 
soon as the NtWriteFile function completes. This means that cached I/O is essentially noncached. For 
this reason, noncached I/O requests are directly converted by the file system to cached I/O such that 
the cache manager still copies directly between the user’s buffer and persistent memory. This kind of 
I/O is still coherent with cached and memory-mapped I/O.
NTFS continues to use standard I/O while processing updates to its metadata files. DAX mode I/O 
for each file is decided at stream creation time by setting a flag in the stream control block. If a file is 
a system metadata file, the attribute is never set, so the cache manager, when mapping such a file, 
creates a standard non-DAX file-backed section, which will use the standard storage stack for perform-
ing paging read or write I/Os. (Ultimately, each I/O is processed by the Pmem driver just like for block 
volumes, using the sector atomicity algorithm. See the “Block volumes” section for more details.) This 
behavior is needed for maintaining compatibility with write-ahead logging. Metadata must not be 
persisted to disk before the corresponding log is flushed. So, if a metadata file were DAX mapped, that 
write-ahead logging requirement would be broken.
Effects on file system functionality
The absence of regular paging I/O and the application’s ability to directly access persistent memory 
eliminate traditional hook points that the file systems and related filters use to implement various 
features. Multiple functionality cannot be supported on DAX-enabled volumes, like file encryption, 
compressed and sparse files, snapshots, and USN journal support.
In DAX mode, the file system no longer knows when a writable memory-mapped file is modified. 
When the memory section is first created, the NTFS file system driver updates the file’s modification 
and access times and marks the file as modified in the USN change journal. At the same time, it signals 
a directory change notification. DAX volumes are no longer compatible with any kind of legacy filter 
drivers and have a big impact on minifilters (filter manager clients). Components like BitLocker and 
the volume shadow copy driver (Volsnap.sys) don’t work with DAX volumes and are removed from the 
device stack. Because a minifilter no longer knows if a file has been modified, an antimalware file access 
scanner, such as one described earlier, can no longer know if it should scan a file for viruses. It needs 
to assume, on any handle close, that modification may have occurred. In turn, this significantly harms 
performance, so minifilters must manually opt-in to support DAX volumes.
Mapping of executable images
When the Windows loader maps an executable image into memory, it uses memory-mapping services 
provided by the memory manager. The loader creates a memory-mapped image section by supplying 
the SEC_IMAGE flag to the NtCreateSection API. The flag specifies to the loader to map the section as 
an image, applying all the necessary fixups. In DAX mode this mustn’t be allowed to happen; otherwise, 
all the relocations and fixups will be applied to the original image file on the PM disk. To correctly deal 
CHAPTER 11
Caching and file systems
725
with this problem, the memory manager applies the following strategies while mapping an executable 
image stored in a DAX mode volume:
I 
If there is already a control area that represents a data section for the binary file (meaning that
an application has opened the image for reading binary data), the memory manager creates an
empty memory-backed image section and copies the data from the existing data section to the
newly created image section; then it applies the necessary fixups.
I 
If there are no data sections for the file, the memory manager creates a regular non-DAX image
section, which creates standard invalid prototype PTEs (see Chapter 5 of Part 1 for more details).
In this case, the memory manager uses the standard read and write routines of the Pmem driver
to bring data in memory when a page fault for an invalid access on an address that belongs to
the image-backed section happens.
At the time of this writing, Windows 10 does not support execution in-place, meaning that the load-
er is not able to directly execute an image from DAX storage. This is not a problem, though, because 
DAX mode volumes have been originally designed to store data in a very performant way. Execution 
in-place for DAX volumes will be supported in future releases of Windows.
EXPERIMENT: Witnessing DAX I/O with Process Monitor
You can witness DAX I/Os using Process Monitor from SysInternals and the FsTool.exe application, 
which is available in this book’s downloadable resources. When an application reads or writes from 
a memory-mapped file that resides on a DAX-mode volume, the system does not generate any 
paging I/O, so nothing is visible to the NTFS driver or to the minifilters that are attached above or 
below it. To witness the described behavior, just open Process Monitor, and, assuming that you 
have two different volumes mounted as the P: and Q: drives, set the filters in a similar way as illus-
trated in the following figure (the Q: drive is the DAX-mode volume): 
EXPERIMENT: Witnessing DAX I/O with Process Monitor
You can witness DAX I/Os using Process Monitor from SysInternals and the FsTool.exe application,
which is available in this book’s downloadable resources. When an application reads or writes from
a memory-mapped file that resides on a DAX-mode volume, the system does not generate any
paging I/O, so nothing is visible to the NTFS driver or to the minifilters that are attached above or
below it. To witness the described behavior, just open Process Monitor, and, assuming that you
have two different volumes mounted as the P: and Q: drives, set the filters in a similar way as illus-
trated in the following figure (the Q: drive is the DAX-mode volume):
726
CHAPTER 11
Caching and file systems
For generating I/O on DAX-mode volumes, you need to simulate a DAX copy using the FsTool 
application. The following example copies an ISO image located in the P: DAX block-mode 
volume (even a standard volume created on the top of a regular disk is fine for the experiment) 
to the DAX-mode “Q:” drive:
P:\>fstool.exe /daxcopy p:\Big_image.iso q:\test.iso 
NTFS / ReFS Tool v0.1 
Copyright (C) 2018 Andrea Allievi (AaLl86) 
Starting DAX copy... 
   Source file path: p:\Big_image.iso. 
   Target file path: q:\test.iso. 
   Source Volume: p:\ - File system: NTFS - Is DAX Volume: False. 
   Target Volume: q:\ - File system: NTFS - Is DAX Volume: True. 
   Source file size: 4.34 GB 
Performing file copy... Success! 
   Total execution time: 8 Sec. 
   Copy Speed: 489.67 MB/Sec 
Press any key to exit...
Process Monitor has captured a trace of the DAX copy operation that confirms the 
expected results:
From the trace above, you can see that on the target file (Q:\test.iso), only the 
CreateFileMapping operation was intercepted: no WriteFile events are visible. While the copy 
was proceeding, only paging I/O on the source file was detected by Process Monitor. These 
paging I/Os were generated by the memory manager, which needed to read the data back from 
the source volume as the application was generating page faults while accessing the memory-
mapped file. 
For generating I/O on DAX-mode volumes, you need to simulate a DAX copy using the FsTool 
application. The following example copies an ISO image located in the P: DAX block-mode 