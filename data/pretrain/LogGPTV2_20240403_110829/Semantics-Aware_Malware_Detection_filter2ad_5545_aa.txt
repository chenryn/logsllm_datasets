title:Semantics-Aware Malware Detection
author:Mihai Christodorescu and
Somesh Jha and
Sanjit A. Seshia and
Dawn Xiaodong Song and
Randal E. Bryant
Semantics-Aware Malware Detection
Mihai Christodorescu∗ Somesh Jha∗
University of Wisconsin, Madison
{mihai, jha}@cs.wisc.edu
Sanjit A. Seshia† Dawn Song Randal E. Bryant†
{sanjit@cs., dawnsong@, bryant@cs.}cmu.edu
Carnegie Mellon University
Abstract
A malware detector is a system that attempts to de-
termine whether a program has malicious intent. In or-
der to evade detection, malware writers (hackers) fre-
quently use obfuscation to morph malware. Malware
detectors that use a pattern-matching approach (such
as commercial virus scanners) are susceptible to obfus-
cations used by hackers. The fundamental deﬁciency
in the pattern-matching approach to malware detection
is that it is purely syntactic and ignores the semantics
of instructions.
In this paper, we present a malware-
detection algorithm that addresses this deﬁciency by in-
corporating instruction semantics to detect malicious
program traits. Experimental evaluation demonstrates
that our malware-detection algorithm can detect vari-
ants of malware with a relatively low run-time over-
head. Moreover, our semantics-aware malware detec-
tion algorithm is resilient to common obfuscations used
by hackers.
1. Introduction
A malware instance is a program that has malicious
intent. Examples of such programs include viruses,
trojans, and worms. A classiﬁcation of malware with
respect to its propagation method and goal is given
in [29]. A malware detector is a system that attempts
to identify malware. A virus scanner uses signatures
and other heuristics to identify malware, and thus is an
example of a malware detector. Given the havoc that
can be caused by malware [18], malware detection is an
important goal.
∗This work was supported in part by the Ofﬁce of Naval Research
under contracts N00014-01-1-0796 and N00014-01-1-0708. The U.S.
Government is authorized to reproduce and distribute reprints for
Governmental purposes, notwithstanding any copyright notices af-
ﬁxed thereon.
The views and conclusions contained herein are those of the authors
and should not be interpreted as necessarily representing the ofﬁcial
policies or endorsements, either expressed or implied, of the above
government agencies or the U.S. Government.
†This work was supported in part by Army Research Ofﬁce grant
DAAD19-01-1-0485.
The goal of a malware writer (hacker) is to modify
or morph their malware to evade detection by a mal-
ware detector. A common technique used by malware
writers to evade detection is program obfuscation [30].
Polymorphism and metamorphism are two common ob-
fuscation techniques used by malware writers. For ex-
ample, in order to evade detection, a virus can morph
itself by encrypting its malicious payload and decrypt-
ing it during execution. A polymorphic virus obfus-
cates its decryption loop using several transformations,
such as nop-insertion, code transposition (changing the
order of instructions and placing jump instructions to
maintain the original semantics), and register reassign-
ment (permuting the register allocation). Metamor-
phic viruses attempt to evade detection by obfuscat-
ing the entire virus. When they replicate, these viruses
change their code in a variety of ways, such as code
transposition, substitution of equivalent instruction se-
quences, change of conditional jumps, and register re-
assignment [28, 35, 36].
Addition of new behaviors to existing malware is an-
other favorite technique used by malware writers. For
example, the Sobig.A through Sobig.F worm variants
(widespread during the summer of 2003) were devel-
oped iteratively, with each successive iteration adding
or changing small features [25–27]. Each new vari-
ant managed to evade detection either through the use
of obfuscations or by adding more behavior. The re-
cent recurrence of the Netsky and B[e]agle worms (both
active in the ﬁrst half of 2004) is also an example of
how adding new code or changing existing code creates
new undetectable and more malicious variants [9, 17].
For example, the B[e]agle worm shows a series of “up-
grades” from version A to version C that include the
addition of a backdoor, code to disable local security
mechanisms, and functionality to better hide the worm
within existing processes. A quote from [17] summa-
rizes the challenges worm families pose to detectors:
Arguably the most striking aspect of Beagle
is the dedication of the author or authors to
reﬁning the code. New pieces are tested, per-
fected, and then deployed with great fore-
thought as to how to evade antivirus scanners
and how to defeat network edge protection
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
devices.
Commercial malware detectors (such as virus scan-
ners) use a simple pattern matching approach to mal-
ware detection, i.e., a program is declared as malware
if it contains a sequence of instructions that is matched
by a regular expression. A recent study demonstrated
that such malware detectors can be easily defeated us-
ing simple program obfuscations [8], that are already
being used by hackers. The basic deﬁciency in the pat-
tern matching approach to malware detection is that they
ignore the semantics of instructions. Since the pattern-
matching algorithm is not resilient to slight variations,
these malware detectors must use different patterns for
detecting two malware instances that are slight varia-
tions of each other. This is the reason that the signature
database of a commercial virus scanner has to be fre-
quently updated. The goal of this paper is to design a
malware-detection algorithm that uses semantics of in-
structions. Such an algorithm will be resilient to minor
obfuscations and variations.
Suppose a program P is transformed by a compiler
phase (such as register allocation) to produce a program
(cid:1). The translation-validation problem is the prob-
P
(cid:1) “simulates” P [31, 32].
lem of determining whether P
Translation validation can be used to prove that vari-
ous compiler phases preserve the semantics of a spe-
ciﬁc program P . By viewing hacker obfuscations as
compiler phases, the malware-detection problem at the
surface seems similar to the translation-validation prob-
lem. However, there are fundamental differences be-
tween the two problems. Translation-validation tech-
niques determine whether the two programs are seman-
tically equivalent. However, variants of malware are
not equivalent because malware writers add additional
functionality between variants. Moreover, translation-
validation researchers make certain assumptions about
the transformed program. For example, Necula [31] as-
sumes that all branches in the target program must cor-
respond to branches in the source program. In the con-
text of malicious-code detection, such an assumption is
not valid: an adversary is free to transform the mali-
cious code as they wish. Although we use some ideas
from the translation-validation literature in the context
of malware detection (such as modeling semantics of
instructions and using decision procedures), our algo-
rithm is differs from those in the translation-validation
literature.
We use the observation that certain malicious behav-
iors (such as a decryption loop in a polymorphic virus
or a loop to search for email addresses in a user’s mail
folder) appear in all variants of a certain malware. The
problem is that the speciﬁed malicious behavior (such
as a decryption loop) appears in different guises in the
different variants. We formalize this problem and de-
scribe an algorithm for discovering speciﬁed malicious
behaviors in a given program. Since our algorithm is
semantic rather than purely syntactic, it is resistant to
common obfuscations used by hackers. Speciﬁcally,
this paper makes the following contributions:
• Formal semantics: We formally deﬁne the problem
of determining whether a program exhibits a speci-
ﬁed malicious behavior. In general, this problem is
undecidable. Our semantics is described in detail in
Section 2. We believe that the semantics presented in
Section 2 can be used as a “reference semantics” for
other researchers working on malware detection.
• A semantics-aware malware detection algorithm:
Since the problem of determining whether a program
exhibits a speciﬁed malicious behavior is undecid-
able, we cannot hope to have a algorithm for the
abovementioned problem.
In Section 3 we present
an algorithm for handling a limited set of transfor-
mations used by hackers. However, our evaluation
(in Section 4) shows that our algorithm is very effec-
tive in discovering malicious behavior, as it detects
multiple Netsky and B[e]agle variants with a single
template, and its resilience to obfuscation is better
than that of commercial virus scanners.
2. Semantics of malware detection
Before we present our formal semantics for malware
detection, we will provide an intuitive explanation of
the underlying ideas. We will use the example shown
in Figure 1 as a running example. Figure 1(a) shows
the control-ﬂow graph (CFG) of a speciﬁcation of ma-
licious behavior and Figure 1(b) shows the CFG of an
instruction sequence (which is a fragment of larger pro-
gram). Instructions in Figure 1 are in the intermediate
form (IR) used by our tool. The instructions in our IR
are intuitive, and we give a formal description of the IR
in Appendix B. We describe various components of our
semantics.
Specifying the malicious behavior. In our frame-
work, malicious behavior is described using templates,
which are instruction sequences where variables and
symbolic constants are used. Figure 1(a) describes
a malicious behavior that is a simpliﬁed version of a
decryption loop found in polymorphic worms. The
malware speciﬁcation described in Figure 1(a) de-
crypts memory starting from address const addr1 and
writes the decrypted data to memory starting at address
const addr2. The decryption function and the termina-
tion condition are denoted by the function f(·) and pred-
icate condition(·) respectively. By abstracting away the
names of speciﬁc registers and symbolic constants in
the speciﬁcation of the malicious behavior, our seman-
tics and algorithm are insensitive to simple obfusca-
tions, such as register renaming and changing the start-
ing address of a memory block.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
A = const_addr1
B = const_addr2
condition(A) ?
false
mem[B] = f(mem[A])
true
A = A + c
B = B + d
1
2
3
4
5
6
7
eax = 0x403000
ebx = 0x400000
edx = eax + 3
eax >= 0x406000 ?
true
false
mem[ebx] = mem[edx−3] << 2 + 1
eax = eax + 4
edx = edx + 4
ebx = ebx + 4
1
2
3
4
5
6
7
8
9
jump const_address2
jump 0x400000
const addr1 ← 0x403000
const addr2 ← 0x400000
condition(X) ← X≥0x406000
f(X) ← X(cid:3)2 + 1
c ← 4
d ← 4
(c) Execution context.
const addr1 : F(0)
const addr2 : F(0)
c : F(0)
d : F(0)
f : F(1)
condition : P(1)
(a) Template of malicious behavior.
(b) Malware instance.
(d) Symbolic constant types.
Figure 1. Malware instance (b) satisﬁes the template (a) according to our semantics.
When does an instruction sequence contain the
malicious behavior? Consider the instruction se-
quence shown in Figure 1(b). Assume the symbolic
constants in the template are assigned values shown
in Figure 1(c). If the template and the instruction se-
quence shown in Figure 1(a) and 1(b) are executed from
a state where the contents of the memory are the same,
then after both the executions the state of the memory
is the same. In other words, the template and the in-
struction sequence have the same effect on the mem-
ory. This is because whenever memory accesses are
performed the addresses in the two executions are the
same. Moreover, stores to memory locations are also
the same. Thus, there is an execution of instruction se-
quence shown in Figure 1(b) that exhibits the behavior
speciﬁed by the template given in Figure 1(a). In other
words, the malicious behavior speciﬁed by the template
is demonstrated by the instruction sequence. Note that
this intuitive notion of an instruction sequence demon-
strating a speciﬁed malicious behavior is not affected
by program transformations, such as register renaming,
inserting irrelevant instruction sequences, and changing
starting addresses of memory blocks.
2.1. Formal semantics
A template T = (IT , VT , CT ) is a 3-tuple, where
IT is a sequence of instructions and VT and CT are
the set of variables and symbolic constants that appear
in IT . There are two types of symbolic constants: an
n-ary function (denoted as F (n)) and an n-ary predi-
cate (denoted as P (n)). Notice that a simple symbolic
constant is 0-ary function or has type F (0). A con-
stant c of type τ is written as c : τ.
In the template
shown in Figure 1(a) the variables VT are {A, B} and
the symbolic constants CT are shown in Figure 1(d).
Let I be an instruction sequence or a program frag-
ment. An example instruction sequence is shown in Fig-
ure 1(b). Memory contents are represented as a function
M : Addr → V alues from the set of addresses Addr
to the set of values V alues, where M[a] denotes the
value stored at address a.
An execution context for a template T , with T =
(IT , VT , CT ), is an assignment of values of appropriate
types to the symbolic constants in the set CT . Formally,
an execution context ECT for a template T is a function
with domain CT , such that for all c ∈ CT the type of c
and ECT (c) are the same. An execution context for the
template shown in Figure 1(a) is shown in Figure 1(c).
Given an execution context ECT for a template T , let
ECT (T ) be the template obtained by replacing every
constant c ∈ CT by ECT (c).
A state sT for the template T is a 3-tuple denoted
(valT , pcT , memT ), where valT : VT → V alues is
an assignment of values to the variables in VT , pcT is a
value for the program counter, and memT : Addr →
V alues gives the memory content. We follow the con-
vention that a state and its component referring to the
template are superscripted by T . Given a template state
sT , val(sT ), pc(sT ) and mem(sT ) refer to the three
components of the state. Similarly, a state for the in-
struction sequence I is a 3-tuple (val, pc, mem), where
val : Reg → V alues is an assignment of values to
the set of registers Reg, pc is a value for the program
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
counter, and mem : Addr → V alues gives the mem-
ory contents. Let ST and S be the state space for the
template and the instruction sequence respectively.
Assume that we are given an execution context ECT
for a template T , and the template is in state sT . If we
execute an instruction i from the template ECT (T ) in
state sT , we transition to a new state sT
1 and generate a
system event e (in our context, events are usually sys-
tem calls or kernel traps). We denote a state change
e−→ sT
from sT to sT
1 .
For uniformity, if an instruction i does not generate a
system event, we say that it generates the null event,
or e(i) = null. For every initial template state sT
0 ,
executing the template T in an execution context ECT
generates a sequence as follows:
1 generating an event e as sT
i
eT
1−→ sT
eT
1−→ ··· ,
i
1
0
0 ) = sT
σ(T, ECT , sT
where for i ≥ 1, sT
is the state after executing the i-
th instruction from the template ECT (T ) and eT
is the
event generated by the (i − 1)-th instruction. Notice
that if the template does not terminate, σ(T, ECT , sT
0 )
can be inﬁnite. Similarly, σ(I, s0) denotes the sequence
when the instruction sequence I is executed from the
initial state s0.
Deﬁnition 1 We say that an instruction sequence I
contains a behavior speciﬁed by the template T =
(IT , VT , CT ) if there exists a program state s0, an ex-
ecution context ECT , and a template state sT
0 such
that mem(sT
0 ) = mem(s0) (the memory in the two