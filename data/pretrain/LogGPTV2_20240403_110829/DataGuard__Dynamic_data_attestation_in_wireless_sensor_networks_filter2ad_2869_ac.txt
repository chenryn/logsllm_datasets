att_addguard((char*)&(p->guard1));
att_addguard((char*)&(p->guard2));
strcpy(p->name, s);
att_reserveguard((char*)&guard3);
att_reserveguard((char*)&(p->guard1));
att_reserveguard((char*)&(p->guard2));
att_free(p);
return 0;
}
int main(int argc, char * argv[]){
int guard4;
char buf[10];
int guard5;
struct info person;
att_initialization(50);
att_addguard((char*)&guard0);
att_addguard((char*)&guard4);
att_addguard((char*)&guard5);
att_addguard((char*)&person.guard1);
att_addguard((char*)&person.guard2);
strcpy(person.name, "Alice");
foo(argv[1]);
att_reserveguard((char*)&guard0);
att_reserveguard((char*)&guard4);
att_reserveguard((char*)&guard5);
att_reserveguard((char*)&person.guard1);
att_reserveguard((char*)&person.guard2);
att_exit();
return 0;
}
Figure 3. Instrumented Program
Some library functions may manipulate a struct object
directly. For example, the memset and memcpy func-
tions may be used to set or copy the content of a struct.
In this case, the data guards inside the struct are changed or
copied to other place. It can either cause false positives or
exploited by attackers to restore the corrupted data guard.
Therefore, if a struct object is involved in a memset func-
tion, we instrument code before memset to store its data
guard values, and after memset to restore their values. If a
memcpy involves struct objects, we instrument code right
after memcpy to assign new data guard values inside the
destination struct object.
5 Evaluation
We have discussed that a wide range of attacks can be
captured by the data boundary integrity model in Section 3.
We have also crafted sample vulnerable programs and veri-
ﬁed its effectiveness on TelosB [12] sensor nodes. The main
purpose of the following experiment is to evaluate the efﬁ-
ciency of the scheme on resource restricted sensor nodes.
We have implemented our scheme using TinyOS [11]
and did experiments on TelosB sensor nodes. We use SHA1
as the hash function, and take the most signiﬁcant 32 bits
of the result as data guard values. Note that this is reason-
able since the possibility that two data guards have the same
value is still extremely small. Also, we did not instrument
attestation semantics to library functions.
5.1 Memory Overhead
Our scheme introduces both static and dynamic memory
overhead. For static memory, it introduces an additional at-
testation module for a sensor node which occupies around
1K memory in our implementation. The SHA1 module oc-
cupies 2K memory. The instrumented attestation code to a
program also increases the code size. In our experiment,
we measure the executable size for applications that have
different number of data guards, and the result is shown in
Table 1. The ﬁrst column is the number of local variables in
the program; the second column is the image size without
attestation scheme; the third column is the image size of the
program that integrates the attestation scheme. It includes
the instrumented attestation code, attestation module, and
the SHA1 module. It shows that the average memory in-
crease for 10 additional data guards is around 230 bytes.
For dynamic memory overhead, our scheme maintains
an adjustable list to record all data guards. Note that the
size of each item in the list is small. In our experiment, we
use only 7 bytes for each item: 4 bytes for data guard value,
and 3 bytes to store the data guard attributes such as mem-
ory address, offset, and state information. In other words,
1K memory can hold nearly 150 dynamic data guards. The
data guards also use stack or heap memory dynamically.
However, such memory cost is transient as they are released
after a function returns or a heap memory is released.
DataNumber OldSize NewSize
14608
14838
15056
15276
15716
11166
11166
11186
11186
11186
1
10
20
30
50
Table 1. Static Memory Overhead. DataNum-
ber refers to how many data variable is in the
application; OldSize is the application image
size without attestation scheme; NewSize is
the application image size with attestation
scheme, including the instrumented seman-
tics, attestation module, and SHA1 module.
5.2 Computation Overhead
The main computation cost of our scheme is the runtime
data guard value measurement. On average, we need one
read, two writes, and two hash calculation to assign a new
value to a data guard. Before returning from a function, we
also need to reserve its local data guard values. When the
data guard list becomes full, we also need to rearrange it,
i.e., reassign values to alive data guards.
The frequency of calculating new data guard values de-
pends on the program structure and runtime program behav-
ior, i.e., the execution path. Suppose an execution path has
m user-deﬁned function calls, and each function has n data
guards on average. Then there are m ∗ n data guards need
to be created at runtime. Also, there are m ∗ n data guards
need to be reserved in this process.
We did our experiment on all combinations of m and n
where m is in set {1, 2, 3, 4, 5, 10, 15, 20} and n is in set
{1, 2, 3, 4, 5, 8, 10}. The data guard list has a length of 30,
and the experimental result is shown in Figure 4. As we can
see, the time used to measure data guard values is almost
linear to the number of data guards. It takes around 0.01
seconds to add a new data guard to the list, calculate its
value, and save it to the list.
In real applications, we can further improve the compu-
tation cost. For example, we can use faster hash function,
or add data guards only to buffers instead of all program
data.
In addition, remember that our scheme introduces
small communication cost as discussed in Section 3. There-
fore, our attestation scheme is practical for sensor networks.
6 Other Related Work
Numerous techniques have been investigated to resist
buffer overﬂow or memory corruption attacks in host com-
puters based on memory access checking techniques. For
example, work in Purify [10] inserts checking logic on ev-
ery memory read and write operation to detect several types
#DataGuards/Function:1
2
3
4
5
8
10
 2.5
 2
 1.5
 1
 0.5
)
c
e
s
(
e
m
T
i
guards are added to a structure. This can be addressed by
using more powerful analysis method. For example, we can
translate the offset of a struct ﬁeld to correct values consid-
ering the size of data guards. Second, it does not support
ﬁne-grained data protection, such as protect array element
individually. However, we notice that such protection is of-
ten not necessary. Third, for malloc data, our method is
not precise since we treat the allocated memory block as a
single object.
8 Conclusions
 0
 2
 4
 6
 20
Figure 4. DataGuard Computation Overhead
 10
#Function
 18
 16
 12
 14
 8
of access errors such as writing to freed memory. Work
in [1] checks pointer and array access based on an ex-
tended safe pointer representation and program transforma-
tion techniques. Other dynamic monitor methods such as
[16, 17] are also proposed for runtime checking. However,
it is not clear whether they can be applied to resource lim-
ited sensor systems.
The data guard method is similar to StackGuard [4] that
uses a canary word to protect the return addresses in stack.
However, our view point is more generic than theirs. With
StackGuard, overﬂowing a buffer to manipulate the return
address will corrupt the canary word placed before the re-
turn address. The canary word can be checked when the
function returns. StackGuard cannot be directly applied to
guard other program data.
In addition, once the attacker
compromised the system, StackGuard provides no protec-
tion, and no one would know what happened in the system.
In our approach, we intend to protect all program data ob-
jects even if the attacker compromises the system. We offer
a way to tell whether a sensor system can be trusted.
7 Limitations
Note that our method can not detect attacks that do not
corrupt data guard values. One important type of such at-
tacks is format string where an external data can be used as
a format in printf family functions. Thus an attacker can
read or write any memory content directly but not neces-
sary to corrupt any boundary data guard. However, in sen-
sor network, the necessary of using printf family functions
is arguably rare. Moreover, format string vulnerability is
relatively easy to detect by audit, static analysis method, or
safer library [3]. Thus, they can be ﬁxed before sensor node
deployment. DataGuard also does not detect program er-
rors such as null or wild pointer deference as long as the
data boundary is not corrupted.
Our implementation also introduces some limitations.
First, it requires that struct ﬁelds must be accessed through
name instead of pointer and offset since additional data
In this paper, we propose dynamic data attestation in
wireless sensor networks based on data boundary integrity.
We present how to set up, measure, and manage the data
guards. We developed a prototype system and did experi-
ments on TelosB motes. The experimental result indicates
that our scheme is feasible and effective in practice. In the
future, we plan to improve our implementation and investi-
gate the integration of other techniques to address our limi-
tations.
Acknowledgment
The authors would like to thank the anonymous review-
ers for their valuable comments.
References
[1] T. M. Austin, S. E. Breach, and G. S. Sohi. Efﬁcient detec-
tion of all pointer and array access errors. SIGPLAN Not.,
29(6):290–301, 1994.
[2] H. Chan, A. Perrig, and D. Song. Random key predistribu-
tion schemes for sensor networks. In IEEE Symposium on
Security and Privacy (S&P), pages 197–213, May 2003.
[3] C. Cowan, M. Barringer, S. Beattie, G. Kroah-hartman,
M. Frantzen, and J. Lokier. FormatGuard: Automatic Pro-
In Pro-
tection From printf Format String Vulnerabilities.
ceedings of the 10th U SEN I X security symposium, 2001.
[4] C. Cowan, C. Pu, D. Maier, J. Walpole, P. Bakke, S. Beattie,
A. Grier, P. Wagle, and Q. Zhang. StackGuard: automatic
adaptive detection and prevention of buffer-overﬂow attacks.
In Proceedings of the 7th U SEN I X security symposium,
1998.
[5] M. D. Ernst, J. H. Perkins, P. J. Guo, S. McCamant,
C. Pacheco, M. S. Tschantz, and C. Xiao. The daikon sys-
tem for dynamic detection of likely invariants. In Science of
Computer Programming, 2007.
[6] L. Eschenauer and V. D. Gligor. A key-management scheme
for distributed sensor networks. In Proceedings of the 9th
ACM Conference on Computer and Communications Secu-
rity (CCS), pages 41–47, November 2002.
[7] A. Francillon and C. Castelluccia. Code injection attacks
on harvard-architecture devices. In Proceedings of the 15th
ACM conference on computer and communications security
(CCS), pages 15–26, 2008.
[23] C. Shuo, J. Xu, E. C. Sezer, P. Gauriar, and R. K. lyer. Non-
control-data attacks are realistic threats. In Proceedings of
the 14th conference on USENIX Security Symposium, 2005.
[24] Texas Instrument. MSP430 Microcontrollers.
[25] Y. Yang, X. Wang, S. Zhu, and G. Cao. Distributed software-
based attestation for node compromise detection in sensor
networks.
In Proceedings of the 26th IEEE International
Symposium on Reliable Distributed Systems, 2007.
[26] Y. Yang, S. Zhu, and G. Cao. Improving Sensor Network
Immunity under Worm Attacks: a Software Diversity Ap-
proach. In Proceedings of the Ninth ACM International Sym-
posium on Mobile Ad Hoc Networking and Computing (Mo-
biHoc ’08), 2008.
[8] D. Gay, P. Levis, R. von Behren, M. Welsh, E. Brewer, and
D. Culler. The nesc language: A holistic approach to net-
worked embedded systems. In Proceedings of Programming
Language Design and Implementation (PLDI), 2003.
[9] Q. Gu and R. Noorani. Towards self-propagate mal-packets
in sensor networks. In Proceedings of the ﬁrst ACM confer-
ence on Wireless network security (WiSec), pages 172–182,
2008.
[10] R. Hastings and B. Joyce. Purify: Fast detection of mem-
ory leaks and access errors.
In Proceedings of the Winter
USENIX Conference, pages 125–136, 1992.
[11] J. Hill, R. Szewczyk, A. Woo, S. Hollar, D. Culler, and
K. S. J. Pister. System architecture directions for networked
In Architectural Support for Programming Lan-
sensors.
guages and Operating Systems, pages 93–104, 2000.
[12] P. Joseph, S. Robert, and C. David. Telos: enabling ultra-
low power wireless research. In Proceedings of the 4th in-
ternational symposium on Information processing in sensor
networks (IPSN ’05), 2005.
[13] C. Kil, E. C. Sezer, A. M. Azab, P. Ning, and X. Zhang.
Remote attestation to dynamic system properties: Towards
providing complete system integrity evidence. In Proceed-
ings of the 39th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks (DSN), 2009.
[14] D. Liu and P. Ning. Establishing pairwise keys in distributed
sensor networks. In Proceedings of 10th ACM Conference
on Computer and Communications Security (CCS), pages
52–61, October 2003.
[15] Nergal. The advanced return-into-lib(c) exploits (PaX case
study). Phrack Magazine.
[16] J. Newsome and D. Song. Dynamic taint analysis for au-
tomatic detection, analysis, and signature generation of ex-
ploits on commodity software. In Proceedings of the 12th
Annual Network and Distributed System Security Sympo-
sium (NDSS), 2005.
[17] O. Ruwase and M. S. Lam. A practical dynamic buffer over-
ﬂow detector. In Proceedings of the 11th Annual Network
and Distributed System Security Symposium (NDSS), 2004.
[18] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. Pio-
neer: Verifying Code Integrity and Enforcing Untampered
Code Execution on Legacy Systems. In 20th ACM Sympo-
sium on Operating Systems Principles (SOSP), 2005.
[19] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla.
SWATT: Software-based ATTestation for Embedded De-
In IEEE Symposium on Security and Privacy, May
vices.
2004.
[20] H. Shacham. The geometry of innocent ﬂesh on the bone:
return-into-libc without function calls (on the x86). In Pro-
ceedings of the 14th ACM conference on computer and com-
munications security (CCS), 2007.
[21] M. Shaneck, K. Mahadevan, V. Kher, and Y. Kim. Remote
software-based attestation for wireless sensors. In Proceed-
ings of the 2nd European Workshop on Security and Privacy
in Ad Hoc and Sensor Networks, 2005.
[22] E. Shi, A. Perrig, and L. van Doorn. BIND: A Time-of-use
Attestation Service for Secure Distributed Systems.
In In
Proceedings of the IEEE Symposium on Security and Pri-
vacy, 2005.