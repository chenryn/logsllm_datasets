title:Decoupling Dynamic Information Flow Tracking with a dedicated coprocessor
author:Hari Kannan and
Michael Dalton and
Christos Kozyrakis
Decoupling Dynamic Information Flow Tracking with a Dedicated Coprocessor
Hari Kannan Michael Dalton Christos Kozyrakis
Computer Systems Laboratory
Stanford University
{hkannan, mwdalton, kozyraki}@stanford.edu
Abstract
Dynamic Information Flow Tracking (DIFT) is a promis-
ing security technique. With hardware support, DIFT pre-
vents a wide range of attacks on vulnerable software with
minimal performance impact. DIFT architectures, however,
require signiﬁcant changes in the processor pipeline that in-
crease design and veriﬁcation complexity and may affect clock
frequency. These complications deter hardware vendors from
supporting DIFT.
This paper makes hardware support for DIFT cost-effective
by decoupling DIFT functionality onto a simple, separate co-
processor. Decoupling is possible because DIFT operations
and regular computation need only synchronize on system
calls. The coprocessor is a small hardware engine that per-
forms logical operations and caches 4-bit tags. It introduces
no changes to the design or layout of the main processor’s
logic, pipeline, or caches, and can be combined with various
processors. Using a full-system hardware prototype and re-
alistic Linux workloads, we show that the DIFT coprocessor
provides the same security guarantees as current DIFT archi-
tectures with low runtime overheads.
Keywords: Software security, Semantic Vulnerabilities, Dynamic in-
formation ﬂow tracking, Processor architecture, Coprocessors
1
Introduction
Dynamic information ﬂow tracking (DIFT) [10, 19] is a
promising technique to detect security attacks on unmodi-
ﬁed binaries ranging from buffer overﬂows to SQL injec-
tions [8, 27]. The idea behind DIFT is to tag (taint) untrusted
data and track its propagation through the system. DIFT asso-
ciates a tag with every word of memory. Any new data derived
from untrusted data is also tainted using the tag bits. If tainted
data is used in a potentially unsafe manner, for instance as a
code pointer or as a SQL command, a security exception is
immediately raised.
The generality of the DIFT model has led to the develop-
ment of several implementations. To avoid the need for recom-
pilation [27], most software DIFT systems use dynamic bi-
nary translation, which introduces signiﬁcant overheads rang-
ing from 3x to 37x [18, 20]. Additionally, software DIFT does
not work safely with self-modifying and multithreaded pro-
grams [6]. Hardware DIFT systems have been proposed to
address these challenges [5, 7, 8, 24, 26]. They make DIFT
practical for all user or library executables, including multi-
threaded and self-modifying code, and even the operating sys-
tem itself [9].
Existing DIFT architectures follow two general ap-
proaches.
Integrated architectures provide DIFT support
within the main pipeline [5, 7, 8, 24]. While these archi-
tectures minimize runtime overhead, they require signiﬁcant
modiﬁcations to the processor design. All processor registers,
pipeline buffers, and internal buses must be widened to ac-
commodate tag bits. Storing tags requires either modiﬁcation
of processor caches, or introduction of an additional tag cache
that can be accessed in parallel to the ﬁrst-level cache. These
changes make it difﬁcult for processor vendors to adopt hard-
ware support for DIFT. First, invasive modiﬁcations to the pro-
cessor core increase the design and veriﬁcation time and may
have an impact on the clock frequency. Moreover, the design
changes for DIFT are not portable across designs, as DIFT
logic is interleaved with conventional logic in a ﬁne-grained
manner.
The second architectural approach is to leverage multi-core
chips [4]. One core captures a trace of the instructions ex-
ecuted by the application, while another core runs the DIFT
analysis on the trace. While this approach offers the ﬂexibility
of analysis in software, it introduces signiﬁcant overheads. It
requires a dedicated core to process the trace, which halves the
throughput of the overall system, or doubles the power con-
sumption due to the application. The hardware cost is further
increased by pipeline changes and custom hardware necessary
to produce, compress, and decompress the trace. Compres-
sion is necessary to avoid increased contention and power con-
sumption in the multi-core interconnect.
This paper builds upon the FlexiTaint design [26], which
implements DIFT similar to the DIVA architecture for relia-
bility checks [2].
It introduces two new stages prior to the
commit stage of an out-of-order (OOO) processor pipeline,
that accommodate DIFT state and logic. FlexiTaint relies on
the OOO structures to hide the latency of the extra stages.
By performing DIFT checks and propagation before each in-
struction commits, FlexiTaint synchronizes regular computa-
tion and DIFT on each instruction.
We observe that frequent synchronization performed by the
FlexiTaint model is overkill. To maintain the same security
model, it is sufﬁcient to synchronize regular computation and
DIFT operations at the granularity of system calls. System call
monitoring has been established as a well accepted technique
for detecting compromised applications [11, 13]. A compro-
mised application needs to be able to exploit system calls to
cause real damage, thus making this interface a great point for
detecting errors. Such coarse-grained synchronization allows
us to move all DIFT state and logic out of the main core, to
a small coprocessor located physically next to the processor
core. Our scheme requires no changes to the design or layout
of the processor’s logic, pipeline, or caches. Hence, it miti-
gates all risk factors for hardware vendors, as it eliminates the
impact of DIFT on the processor’s design time, veriﬁcation
time, and clock frequency. Moreover, it allows for portability,
as the coprocessor can selectively be paired with multiple pro-
cessor designs, even in-order cores such as Intel’s Atom and
Larrabee, and Sun’s Niagara.
We describe the coprocessor architecture and its inter-
face to the main core. We also present a prototype that at-
taches the coprocessor to a SPARC core. By mapping the
design to an FPGA board and running Linux, we create a
full-featured workstation. We demonstrate that the coproces-
sor provides the same security features as Raksha, the inte-
grated DIFT architecture that provides comprehensive protec-
tion against both memory corruption and high-level security
exploits [8, 9]. Speciﬁcally, the coprocessor supports multi-
ple and programmable security policies, protects all memory
regions (text, heap, stack), correctly handles all types of bina-
ries (dynamically generated, self-modifying, shared libraries,
OS, and device drivers), and supports inter-process informa-
tion ﬂow tracking.
The speciﬁc contributions of this work are:
• We describe an architecture that performs all DIFT oper-
ations in a small off-core, attached coprocessor. The co-
processor supports a strong DIFT-based security model
by synchronizing with the main core only on system
calls. No changes are necessary to the main proces-
sor’s pipeline, design, or layout. The proposed design
addresses the complexity, veriﬁcation time, power, area,
and clock frequency challenges of previous proposals for
DIFT hardware.
• Using a full-system prototype, we show that the decou-
pled coprocessor provides the same degree of security
as the most complete integrated DIFT architecture.
It
can protect real-world Linux applications from both low-
level and high-level security attacks.
• We show that the coprocessor has a small area footprint
(8% of a simple RISC core), and is signiﬁcantly sim-
pler than log compression and decompression hardware
needed for multi-core DIFT. Even with a small cache
for tags, the coprocessor introduces less than 1% run-
time overhead for the SPECint2000 applications. This
is similar to the performance of the integrated DIFT de-
signs and to that of FlexiTaint, despite running stronger
security analyses and without an OOO main core. It is
also a signiﬁcant improvement over the multi-core DIFT
designs that slow down applications by up to 36%.
Overall, the coprocessor provides a balanced approach for
DIFT in terms of performance, cost, complexity, and practi-
cality that is not possible with the known alternatives.
The remainder of the paper is organized as follows. Section
2 provides an overview of hardware DIFT systems. Section 3
presents the design of the DIFT coprocessor, while Section
4 describes the full-system prototype. Section 5 provides an
evaluation of the security features, performance, and cost. Fi-
nally, Section 6 concludes the paper.
2 Hardware Support for DIFT
Hardware support for DIFT provides a powerful platform
for security that can prevent information leaks [22, 25] and
protect unmodiﬁed binaries against attacks such as buffer
overﬂows and SQL injection [5, 7, 8, 9, 24, 26]. Hardware
DIFT systems have been shown to protect against both control
and non-control data attacks [9].
2.1 DIFT Background
Hardware DIFT systems logically extend each register and
word of memory by a small number of tag bits [5, 7, 8, 24].
The hardware propagates and checks tags transparently during
instruction execution. Tag propagation allows us to track the
ﬂow of untrusted data. During instruction execution, hardware
propagates the tags of the source operands to the tag of the
destination operand. For example, an add instruction with a
tainted source register will taint the destination register. Tag
checks ensure that the instruction does not perform a forbidden
operation using a tagged value, such as a data or code pointer
dereference. If the check fails, a security exception is raised
and control is transferred to a trusted security monitor. The
monitor may run in kernel mode [5, 7, 24] or user mode [8].
The latter approach makes DIFT applicable to the OS code
and allows software analysis to complement hardware checks
without high overheads [9].
There is no single propagation or check policy that can pre-
vent all attacks. Raksha, a recent DIFT architecture, provides
support for four hardware policies and allows software to man-
age them through conﬁguration registers [8]. This ﬂexibility is
necessary to prevent both high-level and low-level attacks, as
well as to adapt to future exploit techniques. Policies are spec-
iﬁed at the granularity of primitive operations such as move,
arithmetic, and logical operations.
ISA instructions are de-
composed into one or more of these operations before DIFT
propagation and checks are applied. This decomposition is
necessary to avoid security loopholes that could arise due to
the way certain ISAs package multiple operations into a sin-
gle instruction. Moreover, the decomposition allows propaga-
tion and check policies to be independent of the underlying
instruction set.
T
DIFT Tags
DIFT Logic
ICache
T
Decode
Reg
File
       ALU
   Main Core
Security 
Decode
Tag
Reg
File
   Tag          
ALU
DCache T
Core 1
(App)
capture
Cache
Core 2
(DIFT)
analysis
Cache
L2 Cache
DRAM
T
(a) In-core DIFT
compress
L2 Cache
Log buffer
DRAM
decompress
(b) Offloading DIFT
Figure 1: The three design alternatives for DIFT architectures.
DIFT Coprocessor
Main
Core
Cache
Tag 
Pipeline
Tag Cache
L2 Cache
DRAM
T
(c) Off-core DIFT
2.2 DIFT Design Alternatives
Figure 1 presents the three design alternatives for hardware
support for DIFT: (a) the integrated, in-core design; (b) the
multi-core based, ofﬂoading design; and (c) an off-core, co-
processor approach.
Most of the proposed DIFT systems follow the integrated
approach, which performs tag propagation and checks in the
processor pipeline in parallel with regular instruction execu-
tion [5, 7, 8, 24]. This approach does not require an addi-
tional core for DIFT functionality and introduces no overhead
for inter-core coordination. Overall, its performance impact in
terms of clock cycles over native execution is minimal. On the
other hand, the integrated approach requires signiﬁcant mod-
iﬁcations to the processor core. All pipeline stages must be
modiﬁed to buffer the tags associated with pending instruc-
tions. The register ﬁle and ﬁrst-level caches must be extended
to store the tags for data and instructions. Alternatively, a spe-
cialized register ﬁle or cache that only stores tags and is ac-
cessed in parallel with the regular blocks must be introduced
in the processor core. Overall, the changes to the processor
core are signiﬁcant and can have a negative impact on design
and veriﬁcation time. Depending on the constraints, the intro-
duction of DIFT may also affect the clock frequency. The high
upfront cost and inability to amortize the design complexity
over multiple processor designs can deter hardware vendors
from adopting this approach. Feedback from processor ven-
dors has impressed upon us that the extra effort required to
change the design and layout of a complex superscalar pro-
cessor to accommodate DIFT, and re-validate are enough to
prevent design teams from adopting DIFT [23].
FlexiTaint [26] uses the approach introduced by the DIVA
architecture [2] to push changes for DIFT to the back end of
the pipeline. It adds two pipeline stages prior to the ﬁnal com-
mit stage, which access a separate register ﬁle and a separate
cache for tags. FlexiTaint simpliﬁes DIFT hardware by requir-
ing few changes to the design of the out-of-order portion of the
processor. Nevertheless, the pipeline structure and the proces-
sor layout must be modiﬁed. To avoid any additional stalls due
to accesses to the DIFT tags, FlexiTaint modiﬁes the core to
generate prefetch requests for tags early in the pipeline. While
it separates regular computation from DIFT processing, it does
not fully decouple them. FlexiTaint synchronizes the two on
every instruction, as the DIFT operations for each instruction
must complete before the instruction commits. Due to the ﬁne-
grained synchronization, FlexiTaint requires an OOO core to
hide the latency of two extra pipeline stages.
An alternative approach is to ofﬂoad DIFT functionality to
another core in a multi-core chip [3, 4, 16]. The application
runs on one core, while a second general-purpose core runs
the DIFT analysis on the application trace. The advantage of
the ofﬂoading approach is that hardware does not need explicit
knowledge of DIFT tags or policies. It can also support other
types of analyses such as memory proﬁling and locksets [4].