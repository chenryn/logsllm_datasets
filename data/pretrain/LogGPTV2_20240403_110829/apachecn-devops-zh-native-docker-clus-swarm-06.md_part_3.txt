这是一个非常原始的演示。作为一个实验性的特性，Compose 中的支持特性仍未完全定义，但我们预计它将在未来发生变化(甚至根本改变)，以满足开发人员、Swarm 和 Compose 的需求。
# 另一款应用:Apache Spark
既然我们已经获得了一些使用服务的实践，我们就更上一层楼。我们将在 Swarm 上部署 Apache Spark。Spark 是来自 Apache 基金会的开源集群计算框架，主要用于数据处理。
火花可以(但不限于)用于事物，例如:
*   大数据分析(星火核心)
*   快速且可扩展的数据结构控制台(火花 SQL)
*   流分析(火花流)
*   图形处理(火花图形)
这里我们将主要关注 Swarm 的基础设施部分。如果你想详细学习如何编程或使用 Spark，请阅读 Packt 关于 Spark 的精选书籍。我们建议从*开始，用 Spark 2.0 -第三版*进行快速数据处理。
Spark 是 Hadoop 的一个简洁明了的替代方案，它是 Hadoop 复杂性和规模的一个更加敏捷和高效的替代品。
Spark 的理论拓扑是直接的，可以将 Swarm 模式应用于一个或多个领导集群操作的经理和一定数量的正在执行真实任务的工人。
至于管理器，Spark 可以使用自己的称为独立管理器的管理器(我们将在这里介绍)，或者使用 Hadoop YARN，甚至利用 Mesos 的特性。
然后，Spark 可以将存储委派给内部 HDFS (Hadoop 分布式文件系统)或外部存储服务，如亚马逊 S3、OpenStack Swift 或 Cassandra。Spark 使用存储来获取数据以进行详细说明，然后保存详细说明的结果。
## 为什么 Docker 会有火花
我们将向您展示如何在 Docker Swarm 集群上启动 Spark 集群，作为用虚拟机启动 Spark 的替代方案。本章中定义的示例可以从容器中获得许多好处:
*   启动容器要快得多
*   在宠物模型中缩放容器更直接
*   您可以获得 Spark 映像，而无需创建虚拟机、编写自定义脚本、改编 Ansible 行动手册。只是`docker pull`
*   您可以使用 Docker Networking 功能创建一个专用的覆盖网络，而不会在物理上影响或调用网络团队
## 不带蜂群的独立火花
让我们开始定义一个用经典 Docker 工具构建的小型 Apache Spark 集群，这些工具基本上是 Docker 主机上的 Docker 命令。在了解全局之前，我们需要开始熟悉 Swarm 的概念和领域术语。
在本章中，我们将使用`google_container`映像，特别是 Swarm 1 . 5 . 2 版本。2.0 版本中包含了许多改进，但这些映像被证明非常稳定和可靠。因此，我们可以从从谷歌存储库中为主数据库和工作数据库提取它们开始:
```
docker pull gcr.io/google_containers/spark-master
docker pull gcr.io/google_containers/spark-worker
```
Spark 可以运行在 shate、Mesos 或 Hadoop 之上。在下面的例子和章节中，我们将使用它的独立模式，因为它是最简单的，不需要额外的先决条件。在独立的 Spark 集群模式下，Spark 根据内核分配资源。默认情况下，应用将获取集群中的所有核心，因此我们将限制工作人员专用的资源。
我们的架构将非常简单:一个主节点负责管理集群，三个工作节点运行 Spark 作业。为了我们的目的，大师必须发布端口`8080`(为了方便起见，我们将使用网络用户界面)，我们将称之为火花大师。默认情况下，工作容器试图连接到网址`spark://spark-master:7077`，因此除了将它们链接到主容器之外，不需要进一步定制。
因此，让我们将它传递给实用部分，并用以下代码初始化一个 Spark 主文件:
```
docker run -d \
-p 8080:8080 \
--name spark-master \
-h spark-master \
gcr.io/google_containers/spark-master
```
这在守护程序模式(`-d`)下运行，它是来自`gcr.io/google_containers/spark-master`映像的容器，将名称(`--name` ) spark-master 分配给容器，并将其主机名(`-h`)配置给 spark-master。
我们现在可以在端口`8080,`将浏览器连接到 Docker 主机，以验证 Spark 是否启动并运行。
![Spark standalone without Swarm](img/image_06_020.jpg)
它仍然没有活着的工人，我们现在要去产卵。在记录火花主容器的标识之前，我们用以下命令启动工人:
```
docker run -d \
--link 7ff683727bbf \
-m 256 \
-p 8081:8081 \
--name worker-1 \
gcr.io/google_containers/spark-worker
```
这将在守护模式下启动一个容器，将其链接到主容器，将使用中的内存限制在最大 256M，将端口 8081 暴露给 web (worker)管理，并将其分配给容器名称`worker-1`。同样，我们开始另外两个工人:
```
docker run -d --link d3409a18fdc0 -m 256 -p 8082:8082 -m 256m -- 
    name worker-2 gcr.io/google_containers/spark-worker
docker run -d --link d3409a18fdc0 -m 256 -p 8083:8083 -m 256m --
    name worker-3 gcr.io/google_containers/spark-worker
```
我们可以检查主机是否一切正常:
![Spark standalone without Swarm](img/image_06_021.jpg)
## 蜂群上的独立火花
到目前为止，我们已经讨论了不太重要的部分。我们现在将把已经讨论过的概念转移到 Swarm 架构中，所以我们将把 Spark 主机和工人实例化为 Swarm 服务，而不是单个容器。我们将创建一个副本因子为 1 的架构，副本因子为 3 的架构。
### 火花拓扑
在这个例子中，我们将创建一个由一个主节点和三个工作节点组成的 Spark 集群。
### 储存
我们将在[第 7 章](07.html "Chapter 7. Scaling Up Your Platform")、S *升级您的平台*中定义一个真正的存储并开始一些真正的 Spark 任务。
### 先决条件
我们首先为 Spark 创建一个新的专用覆盖网络:
```
docker network create --driver overlay spark
```
然后，我们在节点上设置一些标签，以便以后进行过滤。我们希望在 Swarm 管理器(`node-1`)上托管 Spark 主节点，在 Swarm 工作器(节点-2、3 和 4)上托管 Spark 工作器:
```
docker node update --label-add type=sparkmaster node-1
docker node update --label-add type=sparkworker node-2
docker node update --label-add type=sparkworker node-3
docker node update --label-add type=sparkworker node-4
```
### 类型
我们在这里添加了“sparkworker”类型的标签，以达到极致的清晰度。只有两种变体，实际上可以编写相同的约束:
**-约束“node . labels . type = = sparkworker”**
或者:
**-约束“node.labels.type！= sparkmaster'**
## 在蜂群上启动火花
我们现在将在 Swarm 中定义我们的 Spark 服务，类似于我们在前面部分中为 Wordpress 所做的，但是这一次我们将通过以最大的精度定义从哪里启动 Spark 主服务器和 Spark 工作人员来推动调度策略。
我们从主文档开始，如图所示:
```
docker service create \
--container-label spark-master \
--network spark \
--constraint 'node.labels.type==sparkmaster' \
--publish 8080:8080 \
--publish 7077:7077 \
--publish 6066:6066 \
--name spark-master \
--replicas 1 \
--limit-memory 1024 \
gcr.io/google_containers/spark-master
```
Spark 主机公开端口`8080`(网络用户界面)，为了示例清晰起见，这里我们还公开了 Spark 工作人员用来连接主机和端口 6066(Spark API 端口)的端口`7077`。此外，我们将内存限制在 1G，内存有限。一旦 Spark 主服务器启动，我们就可以创建托管工作人员的服务，sparkworker:
```
docker service create \
--constraint 'node.labels.type==sparkworker' \
--network spark \
--name spark-worker \
--publish 8081:8081 \
--replicas 3 \
--limit-memory 256 \
gcr.io/google_containers/spark-worker
```
同样，我们公开了端口`8081`(工人网络用户界面)，但它是可选的。这里，所有的火花容器都被安排在火花工作节点上，正如我们前面定义的那样。将映像拖到主机上需要一些时间。因此，我们拥有最少的 Spark 基础架构:
![Start Spark on Swarm](img/image_06_022.jpg)
Spark 集群已经启动并运行，即使有一点需要补充:
![Start Spark on Swarm](img/image_06_023.jpg)
尽管我们将每个工作人员的内存限制为 256 兆字节，但在用户界面中，我们仍然可以看到 Spark 读取了 1024 兆字节。这是因为 Spark 内部默认配置。如果我们连接到其中一个工作人员正在运行的任何主机，并用`docker stats a7a2b5bb3024`命令检查其统计数据，我们会看到容器实际上是有限的:
![Start Spark on Swarm](img/image_06_024.jpg)
# 总结
在本章中，我们开始研究应用栈，并在 Swarm 上部署真实的东西。我们在定义 Swarm 服务方面做了一些实践，并推出了一个 nginx 集群，以及一个专用覆盖网络上的负载平衡 WordPress。然后，我们转向更真实的东西:Apache Spark。我们通过定义自己的调度策略，在 Swarm 上小规模部署了 Spark。我们将在[第 7 章](07.html "Chapter 7. Scaling Up Your Platform")，S *升级您的平台*中，扩展 Swarm 并将其扩展到更大的规模，提供更多真正的存储和网络选项。