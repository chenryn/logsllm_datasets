### Disclaimer
The views and opinions expressed in this document should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Army Research Laboratory, the U.S. Government, the U.K. Ministry of Defence, or the U.K. Government. The U.S. and U.K. Governments are authorized to reproduce and distribute reprints for government purposes, notwithstanding any copyright notation herein.

### Acknowledgments
We thank Roberto Tamassia for his valuable discussions.

### References
1. [OpenSSL HMAC Documentation](https://www.openssl.org/docs/crypto/hmac.html)
2. [LEDA Library](http://www.algorithmic-solutions.com/leda/index.htm)
3. [Discrete Optimization Challenge 9](http://www.dis.uniroma1.it/challenge9/)
4. Ajtai, M. (1996). Generating Hard Instances of Lattice Problems (extended abstract). In *STOC*, pp. 99–108.
5. Anagnostopoulos, A., Goodrich, M. T., & Tamassia, R. (2001). Persistent Authenticated Dictionaries and Their Applications. In *ISC*, pp. 379–393.
6. Battista, G. D., Eades, P., Tamassia, R., & Tollis, I. G. (1998). *Graph Drawing: Algorithms for the Visualization of Graphs*. Prentice Hall PTR, Upper Saddle River, NJ, USA.
7. Ben-Sasson, E., Chiesa, A., Genkin, D., Tromer, E., & Virza, M. (2013). SNARKs for C: Verifying Program Executions Succinctly and in Zero Knowledge. In *CRYPTO*, pp. 90–108.
8. Ben-Sasson, E., Chiesa, A., Tromer, E., & Virza, M. (2014). Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture. In *USENIX Security*.
9. Bitansky, N., Canetti, R., Chiesa, A., & Tromer, E. (2012). From Extractable Collision Resistance to Succinct Non-interactive Arguments of Knowledge, and Back Again. In *ITCS*, pp. 326–349.
10. Bitansky, N., Canetti, R., Chiesa, A., & Tromer, E. (2013). Recursive Composition and Bootstrapping for SNARKS and Proof-carrying Data. In *STOC*, pp. 111–120.
11. Bitansky, N., Chiesa, A., Ishai, Y., Ostrovsky, R., & Paneth, O. (2013). Succinct Non-interactive Arguments via Linear Interactive Proofs. In *TCC*, pp. 315–333.
12. Braun, B., Feldman, A. J., Ren, Z., Setty, S. T. V., Blumberg, A. J., & Walfish, M. (2013). Verifying Computations with State. In *SOSP*, pp. 341–357.
13. Catalano, D., & Fiore, D. (2013). Vector Commitments and Their Applications. In *PKC*, pp. 55–72.
14. Chung, K.-M., Kalai, Y. T., & Vadhan, S. P. (2010). Improved Delegation of Computation Using Fully Homomorphic Encryption. In *CRYPTO*, pp. 483–501.
15. Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). *Introduction to Algorithms* (Vol. 3.). MIT Press.
16. Fakcharoenphol, J. (2006). Planar Graphs, Negative Weight Edges, Shortest Paths, and Near Linear Time. In *Journal of Computer and System Sciences*, 72(5):868-889.
17. Fox-Epstein, E., Mozes, S., Phothilimthana, P. M., & Sommer, C. (2013). Short and Simple Cycle Separators in Planar Graphs. In *ALENEX*, pp. 26–40.
18. Gennaro, R., Gentry, C., & Parno, B. (2010). Non-interactive Verifiable Computing: Outsourcing Computation to Untrusted Workers. In *CRYPTO*, pp. 465–482.
19. Gennaro, R., Gentry, C., Parno, B., & Raykova, M. (2013). Quadratic Span Programs and Succinct NIZKs without PCPs. In *EUROCRYPT*, pp. 626–645.
20. Goodrich, M. T., Tamassia, R., & Triandopoulos, N. (2011). Efficient Authenticated Data Structures for Graph Connectivity and Geometric Search Problems. *Algorithmica*, 60(3):505–552.
21. Kosba, A. E., Papadopoulos, D., Papamanthou, C., Sayed, M. F., Shi, E., & Triandopoulos, N. (2014). TrueSet: Faster Verifiable Set Computations. In *USENIX Security*.
22. Lipton, R. J., & Tarjan, R. E. (1979). A Separator Theorem for Planar Graphs. *SIAM Journal on Applied Mathematics*, 36(2):177–189.
23. Merkle, R. C. (1990). A Certified Digital Signature. In *CRYPTO*, pp. 218–238.
24. Micali, S. (2000). Computationally Sound Proofs. *SIAM Journal on Computing*, 30(4):1253–1298.
25. Micciancio, D., & Peikert, C. (2013). Hardness of SIS and LWE with Small Parameters. In *CRYPTO*, pp. 21–39.
26. Micciancio, D., & Regev, O. (2009). Lattice-based Cryptography. In *Post-quantum cryptography*, pp. 147–191.
27. Papamanthou, C., Shi, E., Tamassia, R., & Yi, K. (2013). Streaming Authenticated Data Structures. In *EUROCRYPT*, pp. 353–370.
28. Papamanthou, C., & Tamassia, R. (2007). Time and Space Efficient Algorithms for Two-party Authenticated Data Structures. In *ICICS*, pp. 1–15.
29. Papamanthou, C., Tamassia, R., & Triandopoulos, N. (2011). Optimal Verification of Operations on Dynamic Sets. In *CRYPTO*, pp. 91–110.
30. Parno, B., Howell, J., Gentry, C., & Raykova, M. (2013). Pinocchio: Nearly Practical Verifiable Computation. In *SSP*, pp. 238–252.
31. McConnell, R. M., Mehlhorn, K., Näher, S., & Schweitzer, P. (2011). Certifying Algorithms. *Computer Science Review*, 5(2):119–161.
32. Setty, S. T. V., Braun, B., Vu, V., Blumberg, A. J., Parno, B., & Walfish, M. (2013). Resolving the Conflict Between Generality and Plausibility in Verified Computation. In *EUROSYS*, pp. 71–84.
33. Setty, S. T. V., McPherson, R., Blumberg, A. J., & Walfish, M. (2012). Making Argument Systems for Outsourced Computation Practical (sometimes). In *NDSS*.
34. Tamassia, R. (2003). Authenticated Data Structures. In *ESA*, pp. 2–5.
35. Tamassia, R., & Triandopoulos, N. (2010). Certification and Authentication of Data Structures. In *AMW*.
36. Vu, V., Setty, S. T. V., Blumberg, A. J., & Walfish, M. (2013). A Hybrid Architecture for Interactive Verifiable Computation. In *SSP*, pp. 223–237.
37. Yiu, M. L., Lin, Y., & Mouratidis, K. (2010). Efficient Verification of Shortest Path Search via Authenticated Hints. In *ICDE*, pp. 237–248.

### Figure 9: Language for Dynamic Updates
To support dynamic updates, we need to build a SNARK for the following language:
\[
\mathcal{L} = \left\{ (d_E, s, t, p) : \exists \{[e_i = (u_i, v_i), \pi_{e_i}], [d_{u_i}, \pi_{u_i}], [d_{v_i}, \pi_{v_i}]\}_{i=1}^m \text{ and } S, \text{dig such that:} \right.
\]
1. \( \text{VE}.verify(u_i + v_i, 1, \pi_{e_i}, d_E, pk) = 1 \) for \( i = 1, \ldots, m \);
2. \( V.digest(S, pk) = \text{dig} \);
3. \( V.verify(u_i, d_{u_i}, \pi_{u_i}, \text{dig}, pk) = 1 \) and \( V.verify(v_i, d_{v_i}, \pi_{v_i}, \text{dig}, pk) = 1 \) for \( i = 1, \ldots, m \);
4. \( S[s] = 0 \) and \( S[t] = |p| \);
5. \( S[v_i] \leq S[u_i] + 1 \) for \( i = 1, \ldots, m \).

### Appendix

#### Algorithm: \( \text{pk} \leftarrow \text{genkey}(1^k, M) \)
- Set \( N = M \cdot \text{max} \), where \(\text{max}\) is the maximum entry that can appear in vector \( S \).
- Call \( \{q, m\} \leftarrow \text{parameters}(1^k, N) \).
- Set \( \text{pk} = \{L, R, q\} \), where \( L, R \) are matrices picked uniformly at random from \( \mathbb{Z}_q^{k \times m} \).

#### Algorithm: \( \text{d}(S) \leftarrow \text{digest}(S, \text{pk}) \)
- Let \( T \) be a binary tree built on top of vector \( S \).
- For each node \( v \) of the tree, set \( \lambda(v) = \sum_{i \in \text{range}(v)} S[i] L_v(i) \), where \( L_v(i) \) is the partial label of node \( v \) with respect to \( i \) and \(\text{range}(v)\) is the range of node \( v \), both defined in [27].
- Finally, set \( \text{d}(S) = \lambda(\Lambda) \), where \( \Lambda \) is the root of \( T \).

#### Algorithm: \( \text{d}(S) \leftarrow \text{update}(\text{d}(S), i, \alpha, \text{pk}) \)
- Set \( \text{d}(S) = \text{d}(S) + L_\Lambda(i)(\alpha - S[i]) \), where \( L_\Lambda(i) \) is the partial label of the root \( \Lambda \) with respect to \( i \) (defined in [27]).

#### Algorithm: \( \{S[i], \Pi_i\} \leftarrow \text{query}(i, S, \text{pk}) \)
- Let \( v_\ell, \ldots, v_1 \) be the path in \( T \) from node \( i \) to the child \( v_1 \) of the root \( \Lambda \) of \( T \).
- Let also \( w_\ell, \ldots, w_1 \) be the sibling nodes of \( v_\ell, \ldots, v_1 \).
- The proof \( \Pi_i \) contains the ordered sequence of pairs \( \{(\lambda(v_\ell), \lambda(w_\ell)), (\lambda(v_{\ell-1}), \lambda(w_{\ell-1})), \ldots, (\lambda(v_1), \lambda(w_1))\} \).

#### Algorithm: \( \{1, 0\} \leftarrow \text{verify}(i, S[i], \Pi_i, \text{d}(S), \text{pk}) \)
- Parse proof \( \Pi_i \) as \( \{(\lambda(v_\ell), \lambda(w_\ell)), \ldots, (\lambda(v_1), \lambda(w_1))\} \).
- If \( \lambda(v_\ell) \neq S[i] \) or \( \lambda(v_\ell), \lambda(w_\ell) \notin [N]^m \), output 0.
- Otherwise, compute the values \( y_{\ell-1}, y_{\ell-2}, \ldots, y_0 \) as \( y_i = L \cdot \lambda(v_{i+1}) + R \cdot \lambda(w_{i+1}) \) (if \( v_{i+1} \) is \( v_i \)'s left child) or \( y_i = R \cdot \lambda(v_{i+1}) + L \cdot \lambda(w_{i+1}) \) (if \( v_{i+1} \) is \( v_i \)'s right child).
- For \( i = \ell-1, \ldots, 1 \), if \( f(\lambda(v_i)) \neq y_i \) or \( \lambda(v_i), \lambda(w_i) \notin [N]^m \), output 0.
- If \( f(\text{d}(S)) \neq y_0 \), output 0 (function \( f(.) \) takes as input a radix-2 representation and returns the respective number, see [27]).
- Output 1.

#### Algorithm: \( \{q, m\} \leftarrow \text{parameters}(1^k, N) \)
- Let \( q \) be a prime and \( k \in \mathbb{N} \).
- Find the smallest \( q \) and \( k \) such that \( q / \sqrt{\lceil \log q \rceil} \geq \sqrt{0.0086 \cdot k \log q} \) and \( 2k \log q < 2 \cdot N \cdot k^{0.50001} \).
- Set \( m = k \lceil \log q \rceil \).

### Definitions

**Definition 3.** A VC scheme for graphs \( V \) is correct if, for all graphs \( G \), for all \( k \in \mathbb{N} \), for all \( ek_G, vk_G \) output by algorithm genkey, for all queries \( q \) on \( G \) and for all \( \pi_q, \alpha \) output by algorithm compute(q, ekG), it holds that \( 1 \leftarrow \text{verify}(\pi_q, q, \alpha, vk_G) \).

A VC scheme \( V \) is secure if, for all graphs \( G \), for all \( k \in \mathbb{N} \), for all \( ek_G, vk_G \) output by algorithm genkey and for any PPT adversary Adv, the probability that
\[
\{q, \pi_q, \alpha\} \leftarrow \text{Adv}(ek_G, vk_G); \quad 1 \leftarrow \text{verify}(\pi_q, q, \alpha, vk_G); \quad \alpha \text{ is incorrect}
\]
is negligible in \( k \).

**Definition 4. (VECTOR COMMITMENT)** A vector commitment scheme \( V \) has five PPT algorithms:
1. \( \text{pk} \leftarrow \text{genkey}(1^k, M) \): On input the security parameter \( k \) and the vector size \( M \), it outputs the public key \( \text{pk} \).
2. \( \text{d}(S) \leftarrow \text{digest}(S, \text{pk}) \): On input vector \( S \) and \( \text{pk} \), it outputs the digest \( \text{d}(S) \).
3. \( \text{d}(S) \leftarrow \text{update}(\text{d}(S), i, \alpha, \text{pk}) \): On input vector \( S \), \( (i, \alpha) \) and \( \text{pk} \), it sets \( S[i] = \alpha \) and outputs the new digest \( \text{d}(S) \).
4. \( (S[i], \Pi_i) \leftarrow \text{query}(i, S, \text{pk}) \): On input an index \( i \) and \( \text{pk} \), it returns the value \( S[i] \), along with a proof \( \Pi_i \) (run by prover).
5. \( \{1, 0\} \leftarrow \text{verify}(i, S[i], \Pi_i, \text{d}(S), \text{pk}) \): On input an index \( i \), a value \( S[i] \), a proof \( \Pi_i \), a digest \( \text{d}(S) \) and \( \text{pk} \), it outputs either 1 or 0 (run by verifier).

A VCS scheme \( V \) is correct if, for all \( k, M \in \mathbb{N} \), for all \( \text{pk} \) output by genkey, for all \( S \) and for all \( \text{d}(S) \) output by algorithm digest(S, pk) (or update(d(S), i, α, pk)) and for all \( S[i], \Pi_i \) output by query(i, S, pk), it holds that \( 1 \leftarrow \text{verify}(i, S[i], \Pi_i, \text{d}(S), \text{pk}) \).

A VCS scheme is secure if, for all \( k, M \in \mathbb{N} \), for all \( \text{pk} \) output by algorithm genkey, for all \( S \) and for all \( \text{d}(S) \) output by algorithm digest(S, pk) (or algorithm update(d(S), i, α, pk)) and for any PPT adversary Adv, the probability that
\[
\{i, \Pi, \alpha\} \leftarrow \text{Adv}(1^k, \text{pk}); \quad 1 \leftarrow \text{verify}(i, \alpha, \Pi, \text{d}(S), \text{pk}); \quad S[i] \neq \alpha
\]
is negligible in \( k \).

**Definition 5.** A SNARK \( G \) is correct if, for all \( k \in \mathbb{N} \), for all NP languages \( L \), for all \( ek_L \) and \( vk_L \) output by genkey, for all \( x \in L \), it holds that \( 1 \leftarrow \text{verify}(\text{compute}(x, ek_L), x, vk_L) \).

A SNARK \( G \) is secure if, for all \( k \in \mathbb{N} \), for all NP languages \( L \), for all \( ek_L \) and \( vk_L \) output by algorithm genkey and for any PPT adversary Adv, for all \( x \in L \), the probability that
\[
\{\pi_x, x\} \leftarrow \text{Adv}(1^k, ek_L, vk_L); \quad 1 \leftarrow \text{verify}(\pi_x, x, vk_L); \quad x \notin L
\]
is negligible in \( k \).

A SNARK should also have an extractor: i.e., for any polynomial-sized prover Prv, there exists an extractor Ext such that for any statement \( x \), auxiliary information \( \mu \), the following holds:
\[
\{\pi_x, x\} \leftarrow \text{Adv}(1^k, ek_L, vk_L); \quad \pi_x \leftarrow \text{Prv}(ek_L, x, \mu); \quad 1 \leftarrow \text{verify}(\pi_x, x, vk_L); \quad w \leftarrow \text{Ext}(ek_L, vk_L, x, \pi_x)
\]
\[
\{ek_L, vk_L\} \leftarrow \text{genkey}(1^k, L) \quad \text{and} \quad w \notin R_L(x)
\]
with probabilities negligible in \( k \).

### Table 7: Proof-Computation Time (seconds)
| Method          | Size   |
|-----------------|--------|
| Strawman        | 10     |
|                 | 100    |
|                 | 1,000  |
|                 | 10,000 |
|                 | 100,000|
|                 | 200,000|
| PINOCCHIO       | 32.072 |
| BFS             | 21,000*|
|                 | 2,400,000*|
|                 | 240,000,000*|
|                 | 25,000,000,000*|
|                 | 98,000,000,000*|
| Certifying      | 0.044  |
| Algorithm       | 0.477  |
| Separator       | 5.502  |
| Planar          | 56.02  |
|                 | 560*   |
|                 | 1120*  |
|                 | 0.853  |
|                 | 4.616  |
|                 | 11.425 |
|                 | 22.223 |
|                 | 66.374 |
|                 | 93.853 |