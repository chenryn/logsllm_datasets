title:POSTER: A Hardware Fingerprint Using GPU Core Frequency Variations
author:Fengjun Li and
Xin Fu and
Bo Luo
POSTER: A Hardware Fingerprint Using GPU Core
Frequency Variations
Fengjun Li
Department of EECS
University of Kansas
ﬂPI:EMAIL
Xin Fu
Department of ECE
University of Houston
PI:EMAIL
Bo Luo
Department of EECS
University of Kansas
PI:EMAIL
ABSTRACT
Hardware primitives provide signiﬁcant promises to support
cryptographic primitives and security mechanisms against
various forms of compromises. In this work, we study the in-
trinsic hardware characteristics of modern graphics process-
ing units (GPUs) due to random manufacturing variations,
and exploits the inherent randomness to generate device-
speciﬁc signatures. In particular, we present a novel GPU-
based hardware ﬁngerprint scheme to generate a unique, sta-
ble, physically unclonable, unpredictable, and random bit
string from the inherent hardware features of a general pur-
pose GPU (GPGPU). The generated ﬁngerprint can be used
to implement a physically unclonable function (PUF), and
thus to create a trusted computing environment with GPUs
as the trust anchor.
1.
INTRODUCTION
Billions of electronic devices have been deployed at all
scales throughout our everyday life. When the mobile and
embedded devices become ubiquitous, the high inter-connectivity
makes them more accessible to adversaries and thus more
exposed to many attacks including invasive attacks, side-
channel attacks, and physical attacks. Classic cryptographic
primitives such as device identiﬁcation and authentication
are one of the fundamental enabling technologies for protec-
tion. A widely adopted approach is to associate secure oper-
ations with a device-speciﬁc secret and store the secret key
in non-volatile memory such as EEPROM to enable cryp-
tographic primitives such as encryption or digital signature.
Obviously the security of this type of approaches relies heav-
ily on the secrecy of the cryptographic key, which unfortu-
nately is diﬃcult to uphold when facing various attacks. For
instance, the leakage of secret keys from the remote HTTPS
web servers is the main cause of the Heartbleed incident
which was reported in April 2014. This problem leads to the
development of hardware primitives as a promising mecha-
nism to support secure operations.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the Owner/Author(s). Copyright is held by the
owner/author(s).
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
ACM 978-1-4503-3832-5/15/10.
DOI: http://dx.doi.org/10.1145/2810103.2810105.
As an innovative hardware primitive, a physically unclon-
able function (PUFs) derives a secret from physical charac-
teristics of a hardware and implements a function F to map
any external stimuli or challenge C to a response R. The se-
cret is volatile such that it is only available when the device
is running and using the secret, and thus is impossible for an
adversary to obtain or duplicate. Pappu et al.
introduced
the concept of PUF and presented an optical PUF design
based on illumination key pairs to generate authentication
tokens [5]. After that, various designs have been proposed
in many applications including device identiﬁcation and au-
thentication, IP protection and anti-counterfeiting, secrete
key generation, distribution and storage, etc.
In this project,we present a design based on a hardware
ﬁngerprint of commodity graphics processing units (GPUs).
Such PUFs supporting only a small subset of challenges
(or one in our case) are known as Physically Obfuscation
Keys (POKs). We study the intrinsic hardware character-
istics, i.e., the core frequency variations of modern GPUs,
and generate a unique, GPU-speciﬁc signature from the in-
herent randomness introduced by manufacturing variations.
The hardware ﬁngerprint is directly derived from and imple-
mented inseparably on the GPU of physical devices, which
is unique, uncloneable, and diﬃcult to read out by invasive
attacks. Since GPUs are recently widely used in many de-
vices such as workstations and personal computers, mobile
phones, embedded systems, game consoles, etc., the GPU-
enabled solution does not introduce additional hardware and
implementation costs, comparing with other common exam-
ples such as SRAM-PUF, Butterﬂy PUF and Coating PUF.
2. BACKGROUND
GPU Architecture. The key component of a typical GPU
is the in-order streaming multiprocessor (SMX). Each SMX
includes 192 single-precision CUDA cores, 64 double-precision
units (DP Unit), 32 special function units (SFU), and 32
load/store units (LD/ST). All these execution units will
be evenly distributed into four execution clusters.
In this
project, we study the NVIDIA GPU Kepler Architecture
which includes 15 SMX and applies CUDA programming
model. In CUDA, the GPU executes highly-parallel kernel
functions. The kernel is composed of a grid of light-weighted
threads; a grid is divided into a set of blocks; each block is
composed of hundreds of threads. Threads are distributed
to SMXs at the granularity of blocks.
Threads in the SMX execute on the single instruction mul-
tiple data (SIMD) model. A number of individual threads
(i.e. 32 threads in Nvidia GPU) from the same block are
1650grouped together, called warp.
In the pipeline, threads
within a warp execute the same instruction but with dif-
ferent data values. Each SMX interleaves multiple warps
at cycle-by-cycle basis. At every cycle, an instruction warp
that is ready for execution is selected and issued by a warp
scheduler, and all threads belonging to that warp start the
execution in an execution cluster simultaneously. The execu-
tion of a branch instruction in the warp may cause warp di-
vergence when some threads jump while others fall through
at the branch. Threads in a diverged warp have to exe-
cute in serial fashion which causes multiple lanes to be idle
in the SIMD pipeline. Each warp has its own stack in the
branch unit recording the reconvergence PC (RPC) and ac-
tive mask (used to describe the active threads in the warp)
to handle the warp divergence. The load/store instruction
may cause the oﬀ-chip memory access that can last hundreds
of cycles, and a long latency memory transaction from one
thread would stall all threads within a warp.
Process Variations. Process variations (PV) are a com-
bination of random eﬀects (e.g. due to random dopant ﬂuc-
tuations) and systematic eﬀects (e.g. due to lithographic
lens aberrations) that occur during transistor manufactur-
ing. Random variations refer to random ﬂuctuations in pa-
rameters from die to die and device to device. Systematic
variations refer to layout-dependent variations which cause
nearby devices to share similar parameters. Among the de-
sign parameters, eﬀective channel length (Lef f ) and thresh-
old voltage (Vth) are two key parameters subject to large
variations [9]. As process technology keeps scaling down,
the increasing process variations (PV) have become a grow-
ing threat to processor design and fabrication [6]. PV is the
divergence of device parameters from their nominal values,
which is caused by the challenging manufacture process at
very small feature technologies. PV induces delay variations
among circuit paths, and this impact is further exacerbated
in GPUs which contain tremendous amount of parallel crit-
ical paths [7, 4].
Generally, the random and systematic components have
equal variances for both Vth and Lef f [1, 3]. GPU contains
tremendous amount of parallel paths to deliver high com-
puting throughput, and is quite sensitive to process varia-
tions. In order to aﬀord a greater number of threads execut-
ing simultaneously in the SMX, the number of CUDA cores
continuously increases in recent GPU product generations.
For example, there are total 2880 CUDA cores in Nvidia’s
GPU Kepler architecture, therefore, they exhibit substan-
tial frequency variations.
In our preliminary experiments,
we observe that the ratio of frequencies between the fastest
and the slowest core in a GPU chip can reach as high as 2.2.
3. GPU FINGERPRINTING
We present a hardware ﬁngerprint from the physical fea-
tures of a GPU. This ﬁngerprint is a binary string of N
bits (in our initial design, N = 256), with the following fea-
tures: (1) unique and stable for each GPU, (2) physically
unclonable from hardware manufacturing perspective, (3)
unpredictable so that it could be used as a secret, (4) ran-
dom to provide maximum entropy. The entire ﬁngerprint
generation process, including core selection, frequency mea-
surement and digitalization, and ﬁngerprint assembling, is
completely performed within GPU using auxiliary circuits.
The area and power overhead of adding such auxiliary cir-
cuits is negligible to the entire GPU chip. In this section, we
introduce the design of a workable GPU ﬁngerprint: we ﬁrst
present the on-chip frequency measurement for each GPU
CUDA core, and then further convert it to binary digits, to
be used as the ﬁngerprint.
GPU Core Frequency Measurement. As the ﬁrst step
of this project, we perform the online GPU core frequency
measurement. Recently, time-to-digital converters (TDC)
has been widely used to for precise measurement of time in-
tervals or precise conversion of time interval to digital data
[2, 9, 10]. It can be integrated into each GPU CUDA core
during the chip fabrication to measure the core clock cycle
time, thus, the frequency at run time. There are various