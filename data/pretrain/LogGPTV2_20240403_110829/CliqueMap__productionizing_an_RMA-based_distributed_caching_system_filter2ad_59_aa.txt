title:CliqueMap: productionizing an RMA-based distributed caching system
author:Arjun Singhvi and
Aditya Akella and
Maggie Anderson and
Rob Cauble and
Harshad Deshmukh and
Dan Gibson and
Milo M. K. Martin and
Amanda Strominger and
Thomas F. Wenisch and
Amin Vahdat
CliqueMap: Productionizing an RMA-Based Distributed
Caching System
Arjun Singhvi‚Ä†‚Ä° Aditya Akella‚Ä†‚Ä° Maggie Anderson‚Ä° Rob Cauble‚Ä° Harshad Deshmukh‚Ä°
Dan Gibson‚Ä° Milo M. K. Martin‚Ä° Amanda Strominger‚Ä°
Thomas F. Wenisch‚Ä°
Amin Vahdat‚Ä°
‚Ä†University of Wisconsin - Madison
‚Ä°Google Inc
Abstract
Distributed in-memory caching is a key component of modern Inter-
net services. Such caches are often accessed via remote procedure
call (RPC), as RPC frameworks provide rich support for produc-
tionization, including protocol versioning, memory efficiency, auto-
scaling, and hitless upgrades. However, full-featured RPC limits per-
formance and scalability as it incurs high latencies and CPU over-
heads. Remote Memory Access (RMA) offers a promising alternative,
but meeting productionization requirements can be a significant
challenge with RMA-based systems due to limited programmability
and narrow RMA primitives.
This paper describes the design, implementation, and experi-
ence derived from CliqueMap, a hybrid RMA/RPC caching system.
CliqueMap has been in production use in Google‚Äôs datacenters
for over three years, currently serves more than 1PB of DRAM,
and underlies several end-user visible services. CliqueMap makes
use of performant and efficient RMAs on the critical serving path
and judiciously applies RPCs toward other functionality. The de-
sign embraces lightweight replication, client-based quoruming, self-
validating server responses, per-operation client-side retries, and
co-design with the network layers. These foci lead to a system re-
silient to the rigors of production and frequent post-deployment
evolution.
CCS Concepts
‚Ä¢ Computer systems organization ‚Üí Distributed Systems; Key-
Value Stores; ‚Ä¢ Networks ‚Üí Datacenter networks.
Keywords
Remote Memory Access; Remote Procedure Call; Key-Value
Caching System
ACM Reference Format:
Arjun Singhvi, Aditya Akella, Maggie Anderson, Rob Cauble, Harshad
Deshmukh, Dan Gibson, Milo M. K. Martin, Amanda Strominger, Thomas
F. Wenisch, Amin Vahdat. 2021. CliqueMap: Productionizing an RMA-
Based Distributed Caching System. In ACM SIGCOMM 2021 Conference
(SIGCOMM ‚Äô21), August 23‚Äì28, 2021, Virtual Event, USA. ACM, New York,
NY, USA, 13 pages. https://doi.org/10.1145/3452296.3472934
This work is licensed under a Creative Commons Attribution International 4.0 License.
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
¬© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8383-7/21/08.
https://doi.org/10.1145/3452296.3472934
Introduction
1
Remote Procedure Call (RPC) frameworks are the backbone of
modern Internet services as they provide a familiar programming
abstraction for building distributed systems. The production needs
of hyperscale distributed systems have layered requirements on RPC
frameworks including protocol versioning, memory management,
auto-scaling, logging, and support for binary upgrades. These fea-
tures entail considerable CPU overhead at both the client and server,
limiting operation (op) rate, bandwidth, and efficiency; at Google,
even an empty RPC often costs >50 CPU-ùúás in framework and
transport code across client and server. Per-RPC overheads easily
dominate remote operations with little server-side computation, such
as in-memory retrieval applications like distributed caches and key-
value stores.
To reduce CPU overheads and to increase peak op rate for such ap-
plications, recent efforts use remote memory access (RMA) technolo-
gies [17, 18, 23, 33, 36, 40]. RMA has become ubiquitous in high-
end networking; modern NICs natively support RMA [1, 3, 5, 34]
and software implementations [8, 31, 35] enable continuous inno-
vation in a hardware-independent manner. The essential element of
RMA is that no server-side application code needs to run to complete
an operation.
Whereas RMA raises distributed systems‚Äô performance and ef-
ficiency ceiling by using simple primitives, the features that make
RPC-based systems robust‚Äîbut sap CPU efficiency [25]‚Äîremain
critical to production operation (see Table 1 and ¬ß2). Hybrid sys-
tems [33, 35, 40] leverage the strengths of RMA and RPC through
the use of RMA-accessible data structures to accelerate performance-
critical communication, while using RPCs to ease programming
burden on less performance-critical paths. In practice, building such
hybrid systems faces two key challenges: (1) designing performant
data structures and protocols to accommodate concurrency between
RMA and server-side execution (RPC handlers), and (2) meeting pro-
ductionization expectations, such as availability, support for planned
maintenance, memory management/efficiency, evolution over time,
and software interoperability.
In this paper, we present the design, implementation, and expe-
riences derived from CliqueMap, a hybrid RMA/RPC in-memory
key-value caching system (KVCS) that overcomes the above two
challenges. Like MICA [29], CliqueMap uses an associative hash
table to enable remote access. Like Pilaf [33], each KV pair is
guarded by a checksum that is used to validate responses. The core
of CliqueMap‚Äôs design is centered around (1) providing performant
lookups, (2) a careful division of responsibilities between RPCs and
RMAs across dataplane, control, and management operations, and
93
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
A. Singhvi et al.
Challenge
1. Memory efficiency
2. Enable agile evolution
post deployment
3.
Increased
availability
with minimal overheads
Description
While RMA optimizes to reduce CPU cost, a KVCS must
aggressively optimize for memory footprint, too. The number
of backends and memory size per backend must grow/shrink
without disruption.
Production services undergo requirement changes and other
upgrades throughout their lifetimes and must be easy to
evolve to meet the new requirements.
Server failures should not lead to data unavailability or per-
formance drops. Systems must tolerate frequent planned and
unplanned restarts without loss of data.
4. Software
interoperability
5. Optimizing
to heterogeneous
networking hardware
Corpora stored in the KVCS must be accessible by any au-
thenticated production system, regardless of programming
language.
Our data centers operate across several generations of net-
working technology and RMA protocols, which vary over
two orders of magnitude in available bandwidth per host.
Solution
CliqueMap uses the server-side RPC handlers for memory
allocation/defragmentation and supports multiple eviction
algorithms based on client-side recording of RMA access.
CliqueMap leverages RPCs to introduce new features while
ensuring that clients are resilient to such additions by em-
bracing self-validating server responses and client retries.
CliqueMap uses an uncoordinated replication protocol with
a load-aware client-based quoruming approach leading
to increased availability with minimal performance over-
heads.
CliqueMap uses named pipes and sub-processes to provide
support for Go, Java, and Python.
CliqueMap operates over multiple RMA protocols, inte-
grates tightly with software-defined NIC Pony Express [31],
and provides WAN access via RPC.
Table 1: Productionization challenges and CliqueMap‚Äôs solutions.
(3) support for key productionization expectations, such as evolution
over time, high availability, interoperability, and ease of deployment.
CliqueMap accelerates the common-case read path via RMA
primitives and uses RPC for mutations [33], specifically optimiz-
ing for serving workloads where lookup (GET) performance is
critical and write (e.g., SET) performance is less so, a pattern
common in Google‚Äôs applications. An RMA-based read path sub-
stantially reduces CPU cost and increases peak op rate relative to
(fully) RPC-based systems. Nonetheless, RPCs significantly sim-
plify CliqueMap‚Äôs implementation, because state mutation, mutual
exclusion, and race resolution can all be solved with server-side code,
and thereby sidestep the challenges of data structures that tolerate
slow/racy RMA mutations [7]. To aggressively optimize server mem-
ory footprint, CliqueMap leverages server-side RPC handlers for
memory allocation/defragmentation, to trigger automatic memory
resizing, and to support various cache management algorithms.
To address production availability expectations, CliqueMap of-
fers several replication modes, including ‚ÄúR=3.2‚Äù, wherein each
key/value-pair is replicated across three server backends and ac-
cessed via a client-side quoruming scheme [19], delivering consistent
reads and writes at high performance and low overhead. Quoruming
offers performance benefits: (1) it automatically mitigates tail GET
latency, fetching data from the least loaded/nearest replica; and (2)
it resolves races among concurrent GETs and mutations, avoiding
distributed/global locking for replicated writes (see ¬ß5.3). During
weekly binary upgrades, CliqueMap bolsters availability through
explicit, proactive server data migration to warm spares.
CliqueMap combines the strengths of software datapaths, trans-
ports, and dataplanes in other ways (beyond simply leveraging
RPCs) to address key interoperability goals. Notably, CliqueMap
supports corpora accessed by systems (or a subset of their internal
components) written in several high-level languages, even though
these languages have no native support for RMA, by running a C++
CliqueMap client in a subprocess. By embracing the programmabil-
ity of software-defined NICs (Pony Express [31]), CliqueMap takes
advantage of RMA-like primitives that enable GET operations to
complete in fewer round-trips than when using hardware-supported
RMAs (¬ß3), delivering better efficiency (¬ß6.3) and overall latencies
in most cases (¬ß7). Lastly, by capitalizing client-side retries and
self-validating responses, we have seamlessly evolved CliqueMap
over time (¬ß6), including over a hundred changes to CliqueMap‚Äôs
protocol definitions of varying complexity.
CliqueMap has been in production for more than three years,
during which it has grown to serve more than 1PB of DRAM.
CliqueMap now underlies production stacks for end-user-facing
ads, maps, and other serving systems at Google, and is deployed
across some 50 production clusters distributed among 20 warehouse-
scale datacenters throughout the world. Use cases vary by corpus
size, key-value geometry, batching factors, and other considerations,
and comprise roughly 150M queries per second (QPS) globally.
Our experience with CliqueMap has highlighted several lessons
that we believe are valuable to the research community, including: (1)
the fundamental need to embrace RPCs even in performance-critical
systems; (2) considering multi-language interoperability in RMA,
a space that we see as open to exploration; (3) making memory
efficiency a strong requirement in RMA-based systems; and (4)
embracing software-based processing (e.g., programmable/software
NICs) in system design.
2 Background and Motivation
In-memory key-value caching systems (KVCS) are crucial to user-
facing services throughout the industry [10, 41]. As the name sug-
gests, a KVCS exposes a KV interface to the clients and typically
supports per-key operations such as GETs and mutations (e.g., SET
and ERASE).
While a KVCS should be performant and efficient (i.e., the data-
plane operations should be fast and have minimal CPU overhead),
these aspects alone do not make a KVCS viable in production. Ta-
ble 1 outlines key practical requirements that a production KVCS
should meet, pertaining to availability, memory efficiency, evolution,
and interoperability.
2.1 RPC or RMA?
System designers must address what network transport(s) to use in
their design, as this choice has a fundamental bearing on perfor-
mance and the requirements in Table 1.
94
CliqueMap: Productionizing an RMA-Based Distributed Caching System
SIGCOMM ‚Äô21, August 23‚Äì28, 2021, Virtual Event, USA
Figure 2: Sequence diagram of a 2√óR GET in CliqueMap.
3 Overview and Productionization Ideas
CliqueMap is Google‚Äôs production RMA/RPC hybrid KVCS, offer-
ing state-of-the-art performance and efficiency while meeting the
production requirements outlined in Table 1. We first describe the
basic design, then build on it in subsequent sections.
CliqueMap uses performant and CPU-efficient RMAs for
common-case GETs, but RPCs for mutations and other traffic,
thereby making it simpler to ensure consistency, enact subtle mem-
ory allocation and management techniques, and deliver new features
over time.
Self-Validating Responses. Inspired by Pilaf [33], each KV pair in
CliqueMap is guarded by a checksum across its key, value, and meta-
data. Since RMAs are not atomic, clients performing lookups always
verify this checksum end-to-end (per KV pair). Checksum validation
failures are attributed to torn reads, that is, an RMA read that ob-
serves intermediate state of a concurrent mutation of the underlying
datum on the server‚Äîsuch failures are rare, but normal. Augment-
ing the checksum, additional metadata accompanies responses that
ensures clients and servers agree on configuration, memory layout,
and version. Clients retry lookups that fail validation steps at an
appropriate level of the stack (¬ß9).
Backend Data Structure (Figure 1). To support wide-ranging key
and value sizes while handling key hash collisions, CliqueMap uses
an associative hash table [29]. The backend data structure is com-
posed of two logically-distinct RMA accessible regions‚Äîthe index