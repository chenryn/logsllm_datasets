experiment.
There are three key factors that determine the throughput
of a circuit: a) the capacity of the bottleneck relay, b) the
number of active TCP ﬂows between the bottleneck relay
and the next hops and c) the number of other active circuits
multiplexed over the TCP connection that carries the circuit
in question3:
throughput of
circuit i
=
bottleneck relay bandwidth
# of TCP ﬂows × # of circuits in
i’s TCP ﬂow
There are several reasons for the lack of perfect load bal-
ancing in the Tor network: a) the ﬁrst hop relay is chosen
from a ﬁxed set of three guard relays, b) the last hop is cho-
sen from the set of relays whose exit policy meets the client’s
requirements, c) the peak capacity advertised by a relay is
capped to an arbitrary threshold, d) the clients are not privy
to current levels of traﬃc in the network, and hence select
relays in a fully decentralized fashion, and e) the clients can-
not predict stream characteristics in advance when selecting
circuits for anonymous communication. We note that most
of these reasons are fundamental limitations for any secure
low-latency anonymity system.
3.2 Circuit-Based Bandwidth Fingerprinting
In this section, we describe an attack that determines
whether two circuits share a common sub-path by “ﬁnger-
printing” their communication. We do this by monitoring
their throughput and using a simple statistical test to de-
termine if their throughput is correlated. We consider three
representative experimental scenarios:
ﬁrst or third position, and those that can are underweighted
when selecting the middle relay.
3This formula makes the simplifying assumption that TCP
results in fair sharing of bandwidth between ﬂows. In real-
ity, TCP is only RTT-fair [41]; this diﬀerence, however, has
minimal impact on our analysis.
218R1
R2
R3
Client
Server1
Client
Attacker
Attacker
R1
R2
R3
Server2
R4
(a)
Server1
Client
Server2
Server1
R1
R2
R3
Attacker
Attacker
Attacker
(c)
R6
R5
(b)
Figure 2: Experimental scenarios for circuit-based throughput ﬁngerprinting: (a) All-Common: Two circuits
sharing all three Tor relays have similar throughput characteristics. (b) None-Common: Two circuits without
any common Tor relays do not have any similarity in their throughput characteristics. (c) One-Common:
Two circuits with one or two common Tor relays will have similar throughput characteristics but only for the
duration of time in which the common Tor relays are the bottleneck relays in the circuit.
All-Common (Figure 2(a)): If two Tor circuits have all re-
lays in common, then the circuit throughput will be highly
correlated. Since all three relays are common in both the
circuits, any variation in the number of TCP ﬂows or for-
warding capacity at a relay will aﬀect the throughput of
both circuits in a similar fashion.
None-Common (Figure 2(b)): If two Tor circuits do not
have any common relays, then the circuit throughput will
not be correlated.
One-Common (Figure 2(c)): If two Tor circuits have at
least one relay in common, but do not have all relays in
common, then there are two cases. If the shared relay is the
bottleneck in both the circuits (One-Common-a), then the
circuit throughput will be highly correlated. If the shared re-
lay is not the bottleneck in both the circuits (One-Common-
b), then changes in its number of TCP ﬂows or forwarding
capacity will not aﬀect the throughput of the two circuits,
and thus their throughput will depend on their respective
bottleneck relays.
We performed experiments on the live Tor network to ver-
ify these observations. We used two client nodes and two
server nodes, located in four separate geographical regions.
On the client machines, we ran the stable version of Tor as
of November 2010 (Version 0.2.1.26). We used the default
path selection in the Tor clients, but turned oﬀ the use of
entry guards (by setting UseEntryGuards=0), so that our
clients sample circuits from the space of all possible circuits.
For our experiments with all three common relays, we dis-
abled preemptive circuit setup on the Tor client at the at-
tacker’s machine (using __DisablePredictedCircuits=1).
We used two custom-built TCP programs to work as the
client and server in all of our experiments. The TCP client
is a C program that connects with the TCP server, reads
data sent by the server and computes the throughput of the
ﬂow periodically after a speciﬁc measurement interval.
It
uses the Tor SOCKS [31] interface to perform download via
Tor. The TCP server is a multithreaded server written in C
that waits for connection requests from clients and once con-
nected sends random bytes to the client as fast as possible.
The sending rate of the server is only limited by the TCP
congestion control algorithm. For simplicity of presentation,
our experiments in this section assume that a user is inter-
ested in bulk data transfer. Our attacks are also applicable
to interactive traﬃc; we demonstrate this in Section 3.6.
For each experiment, we set up a stream at the honest
client, recorded the circuit that the Tor client assigned to
that stream, and built the same circuit at the attacker’s
client. We used an upper bound of 30 seconds as the syn-
chronization delay, and after this delay, we set up a new
stream at the attacker’s client.
Results for All-Common (Figures 3(a) and 4(a)):
We next present experimental results for the scenario where
all three Tor relays are the same for both circuits. We per-
formed 700 runs of this experiment, between November and
December 2010. We found that the throughput values for
the two circuits were highly correlated, measured using the
Pearson product-moment correlation coeﬃcient. Figure 3(a)
illustrates an instance of this scenario, where correlation is
depicted as a function of time. We also compute the 95%
conﬁdence interval for correlation using Fisher’s Z trans-
form [21]. We can see that after a time duration of 300
seconds, even the lower bound for the conﬁdence interval is
higher than 0.7. Figure 4(a) depicts the fraction of experi-
ments where the correlation value is greater than a threshold
as a function of time. In about 92% of the cases, the corre-
lation was greater than a threshold value of 0.5 after a time
duration of 300 seconds. Moreover, we can also see that
correlation remains steady with time.
Results for None-Common (Figures 3(a) and 4(b)):
Next, we consider the scenario where two circuits are com-
pletely disjoint. We performed 532 runs of this experiment
in January 2011. In Figure 3(a), we can see that the correla-
tion quickly approaches zero when the two circuits are com-
prised of disjoint relays. Figure 4(b) shows the full results
for this scenario; we can see that in an overwhelming frac-
tion of cases, the correlation quickly drops to zero—only 12
instances out of 532 had a correlation value greater than 0.5
for a time interval of 300 seconds (false positive percentage of
only 2.2%). In our investigation of false positives, we found
that many of the false positive instances occurred due to the
geographic co-location of relays in the two circuits. For ex-
ample, in four instances, the two circuits shared a relay that
was part of the same subnet, like the blutmagie and blut-
magie4 relays. In one instance, the ﬁrst 16 bits of the IPv4
address of two relays was the same (ctor and cptnemo, both
located in Berlin), while in two other instances, IP geoloca-
tion databases indicate geographic closeness within tens of
miles. However, geographic colocation could not explain the
remaining ﬁve instances.
Results for One-Common-a (Figures 3(b) and 4(c)):
Finally, we consider the scenario where two circuits have
only a single common Tor relay. We build one-hop circuits
through each of the relays in a client circuit. We performed
190 runs of this experiment for this scenario between Novem-
ber 2010 and February 2011. Figure 3(b) depicts the cor-
relation as a function of time for two instances in this sce-
219n
o
i
t
l
a
e
r
r
o
C
 1
 0.5
 0
-0.5
-1
Scenario All-Common
Scenario None-Common
 0
 100
 200
 300
 400
 500
 600
Time
(a)
n
o
i
t
l
a
e
r
r
o
C
 1
 0.5
 0
-0.5
-1
 0
Scenario One-Common-a
Scenario  One-Common-b
 100
 200
 300
 400
 500
Time
(b)
Figure 3: (a) When the two circuits share all three relays (All-Common), the correlation is very high. When
the circuits share no common relays (None-Common ), the correlation is very low. (b) When the two circuits
share a single relay, and that relay is the bottleneck on both paths (One-Common-a), then the correlation is
high. If that relay is not the bottleneck on both paths (One-Common-b), then the correlation is low.
s
t
n
e
m
i
r
e
p
x
e
f
o
n
o
i
t
c
a
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0
 0.2
 0.4
 0.6
 0.8
Correlation threshold
(a) c
 600
 500
 400
 300
 200
Time (s)
 100
 1
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
s
t
n
e
m
i
r
e
p
x
e
f
o
n
o
i
t
c
a
r
F
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.2
 0.4
 0.6
 0.8
Correlation threshold
(b) c
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
s
t
n
e
m
i
r
e
p
x
e
f
o
n
o
i
t
c
a
r
F
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.2
 0.4
 0.6
 0.8
Correlation threshold
(c) c
 1
 0.8
 0.6
 0.4
 0.2
 0
 600
 500
 400
 300
Time (s)
 200
 1
 600
 500
 400
 300
 200
Time (s)
 100
 1
Figure 4: Eﬀect of correlation threshold on detection rate: (a) All-Common, (b) None-Common, (c) One-
Common-a.
nario. In scenario One-Common-a, the common relay was
the bottleneck relay for the full duration of 10 minutes, and
we can see that the correlation value is similar to that of
scenario All-Common. On the other hand, in scenario One-
Common-b, the common relay was not the bottleneck relay,
and we can see that the correlation is not statistically signif-
icant. When only a single relay is common between two cir-
cuits, we found that in many instances, correlation degrades
over time, since the common relay may be a bottleneck only
temporarily (not shown in Figure 3(b)). To address this is-
sue, we modiﬁed the correlation analysis to consider windows
(intervals) of time; for a particular size of the window, we
compute the maximum correlation in the data over all time
intervals greater than the window size (if the communica-
tion duration is smaller than the window size, we compute
correlation as before). We probed all three relays for a
client circuit in this experiment, but since only one of them
may be the bottleneck at a time, we computed the maximum
correlation amongst the three probes for diﬀerent commu-
nication duration values. Figure 4(c) depicts the fraction of
experiments that have correlation greater than a threshold
value for diﬀerent communication durations using a window
size of 200 seconds. We can see that while correlation is not
as high as the scenario where all three relays were common
between two circuits, over 90% and 80% of the experiments
still have correlation greater than 0.3 and 0.4 respectively
after 300 seconds of communication. Next, we will use this
observation to identify Tor relays.
Based on these experiments, we conclude that high cor-
relation between circuit throughput indicates the presence
of common Tor relay(s) in the two circuits. Note that the
converse is not necessarily true.
3.3 Identifying Tor Relays
Threat model: Next, we present an attack where we try
to identify one or more Tor relays being used by a particu-
lar ﬂow. We call this ﬂow the target ﬂow. This ﬂow can be
any ﬂow initiated by a Tor client over the Tor network to
access a resource present at a particular server. We assume
that the attacker can observe the throughput of the target
ﬂow. The attacker could have compromised the exit relay,
the target web server, or the ISP forwarding the data; note
that the attacker does not need to perform any modiﬁca-
tions to the ﬂow. The attacker tries to achieve its goal by
probing diﬀerent Tor relays; importantly, these probes can
be launched from diﬀerent vantage points than the target
server. It builds one-hop circuits through these relays (Fig-
ure 5) and computes correlations between the throughput of
the target ﬂow and the probe ﬂows. If the throughput of a
probe ﬂow is highly correlated with that of the target ﬂow,
then the server can assume that both the ﬂows are actually
traversing a common Tor relay. In this section, we show the
success of the attacker at identifying Tor relays by running
experiments over the live Tor network.
Experimental setup:
In an ideal setting, the attacker
will try to probe every relay in the Tor network and ﬁnd
220Client
Server1
R1
R2
R3
Attacker
Attacker
Attacker
Figure 5: Identifying Tor relays attack:
localizing
which Tor relays are on a path by exploiting circuit
throughput characteristics. Observe that the attack
cost scales as O(N ).
the correlation between the probe ﬂows and the target ﬂow.
However, in order to reduce the amount of resources required
to perform this attack, we used a smaller set of 25 Tor relays
for constructing circuits. To pick relays that are represen-
tative of the current Tor network, we selected relays with a
probability proportional to their bandwidth using the Tor
client. We performed our experiments during two diﬀer-
ent time period and used a diﬀerent set of 25 relays in each
period; we will refer to them as RELAY-SET-1 and RELAY-
SET-2 (the list of Tor relays is available in the full version
of this paper [34]).
Probe locations: We used 25 diﬀerent Emulab [18] ma-
chines at the University of Utah to run the probe ﬂows.4
They were used to probe all the 25 Tor relays simultane-
ously. All of the probe ﬂows originated from a single physical
location, but we expect that their throughput was neverthe-
less shaped by the Tor overlay, rather than the access link:
in a separate test, we were able to achieve 70 Mbps across
the access link, far above the throughput of ﬂows in the Tor
network.
Single circuit experiments:
In our ﬁrst experiment, we
set up a target ﬂow between a client and a malicious server