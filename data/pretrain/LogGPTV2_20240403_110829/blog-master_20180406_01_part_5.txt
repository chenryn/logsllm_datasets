                 ->  Subquery Scan on "*SELECT* 2"  (cost=586.03..586.15 rows=10 width=24) (actual time=0.577..0.581 rows=10 loops=10000)  
                       Output: "*SELECT* 2".c1, "*SELECT* 2".c2, "*SELECT* 2".c3, "*SELECT* 2".c4, "*SELECT* 2".t_max_c1  
                       Buffers: shared hit=5073859  
                       ->  Limit  (cost=586.03..586.05 rows=10 width=32) (actual time=0.576..0.578 rows=10 loops=10000)  
                             Output: tbl_6.c1, tbl_6.c2, tbl_6.c3, tbl_6.c4, tbl_5.c1, (random())  
                             Buffers: shared hit=5073859  
                             ->  Sort  (cost=586.03..587.28 rows=502 width=32) (actual time=0.576..0.577 rows=10 loops=10000)  
                                   Output: tbl_6.c1, tbl_6.c2, tbl_6.c3, tbl_6.c4, tbl_5.c1, (random())  
                                   Sort Key: (random())  
                                   Sort Method: quicksort  Memory: 25kB  
                                   Buffers: shared hit=5073859  
                                   ->  Nested Loop  (cost=0.88..575.18 rows=502 width=32) (actual time=0.032..0.553 rows=100 loops=10000)  
                                         Output: tbl_6.c1, tbl_6.c2, tbl_6.c3, tbl_6.c4, tbl_5.c1, random()  
                                         Buffers: shared hit=5073859  
                                         ->  Nested Loop  (cost=0.44..0.56 rows=1 width=8) (actual time=0.020..0.021 rows=1 loops=10000)  
                                               Output: skip_1.t_max_c1, tbl_5.c1  
                                               Buffers: shared hit=40011  
                                               ->  Limit  (cost=0.00..0.02 rows=1 width=4) (actual time=0.001..0.001 rows=1 loops=10000)  
                                                     Output: skip_1.t_max_c1  
                                                     ->  WorkTable Scan on skip skip_1  (cost=0.00..2.00 rows=100 width=4) (actual time=0.000..0.000 rows=1 loops=10000)  
                                                           Output: skip_1.t_max_c1  
                                               ->  Limit  (cost=0.44..0.51 rows=1 width=8) (actual time=0.019..0.019 rows=1 loops=10000)  
                                                     Output: tbl_5.c1, tbl_5.c3  
                                                     Buffers: shared hit=40011  
                                                     ->  Index Only Scan using idx_tbl_1 on public.tbl tbl_5  (cost=0.44..122423.77 rows=1682778 width=8) (actual time=0.019..0.019 rows=1 loops=10000)  
                                                           Output: tbl_5.c1, tbl_5.c3  
                                                           Index Cond: ((tbl_5.c3 = 1) AND (tbl_5.c1 > skip_1.t_max_c1))  
                                                           Heap Fetches: 9999  
                                                           Buffers: shared hit=40011  
                                         ->  Unique  (cost=0.44..563.32 rows=502 width=20) (actual time=0.011..0.508 rows=100 loops=9999)  
                                               Output: tbl_6.c1, tbl_6.c2, tbl_6.c3, tbl_6.c4  
                                               Buffers: shared hit=5033848  
                                               ->  Index Scan using idx_tbl_1 on public.tbl tbl_6  (cost=0.44..562.07 rows=502 width=20) (actual time=0.011..0.444 rows=500 loops=9999)  
                                                     Output: tbl_6.c1, tbl_6.c2, tbl_6.c3, tbl_6.c4  
                                                     Index Cond: ((tbl_6.c3 = 1) AND (tbl_6.c1 = skip_1.t_max_c1))  
                                                     Filter: (tbl_6.* IS NOT NULL)  
                                                     Buffers: shared hit=5033848  
         ->  CTE Scan on skip  (cost=0.00..2.20 rows=110 width=24) (actual time=0.655..5882.899 rows=100000 loops=1)  
               Output: skip.c1, skip.c2, skip.c3, skip.c4, skip.t_max_c1  
               Buffers: shared hit=5074144  
         ->  Subquery Scan on t3  (cost=586.04..586.17 rows=10 width=24) (actual time=0.339..0.344 rows=10 loops=1)  
               Output: t3.c1, t3.c2, t3.c3, t3.c4, t3.c1_1  
               Buffers: shared hit=275  
               ->  Limit  (cost=586.04..586.07 rows=10 width=32) (actual time=0.338..0.340 rows=10 loops=1)  
                     Output: tbl_1.c1, tbl_1.c2, tbl_1.c3, tbl_1.c4, tbl.c1, (random())  
                     Buffers: shared hit=275  
                     ->  Sort  (cost=586.04..587.30 rows=504 width=32) (actual time=0.337..0.338 rows=10 loops=1)  
                           Output: tbl_1.c1, tbl_1.c2, tbl_1.c3, tbl_1.c4, tbl.c1, (random())  
                           Sort Key: (random())  
                           Sort Method: top-N heapsort  Memory: 26kB  
                           Buffers: shared hit=275  
                           ->  Nested Loop  (cost=0.88..575.15 rows=504 width=32) (actual time=0.058..0.311 rows=93 loops=1)  
                                 Output: tbl_1.c1, tbl_1.c2, tbl_1.c3, tbl_1.c4, tbl.c1, random()  
                                 Buffers: shared hit=275  
                                 ->  Limit  (cost=0.44..0.48 rows=1 width=8) (actual time=0.041..0.041 rows=1 loops=1)  
                                       Output: tbl.c1, tbl.c3  
                                       Buffers: shared hit=4  
                                       ->  Index Only Scan Backward using idx_tbl_1 on public.tbl  (cost=0.44..180668.28 rows=5048333 width=8) (actual time=0.041..0.041 rows=1 loops=1)  
                                             Output: tbl.c1, tbl.c3  
                                             Index Cond: (tbl.c3 = 1)  
                                             Heap Fetches: 1  
                                             Buffers: shared hit=4  
                                 ->  Unique  (cost=0.44..563.33 rows=504 width=20) (actual time=0.014..0.246 rows=93 loops=1)  
                                       Output: tbl_1.c1, tbl_1.c2, tbl_1.c3, tbl_1.c4  
                                       Buffers: shared hit=271  
                                       ->  Index Scan using idx_tbl_1 on public.tbl tbl_1  (cost=0.44..562.07 rows=504 width=20) (actual time=0.013..0.201 rows=268 loops=1)  
                                             Output: tbl_1.c1, tbl_1.c2, tbl_1.c3, tbl_1.c4  
                                             Index Cond: ((tbl_1.c3 = 1) AND (tbl_1.c1 = tbl.c1))  
                                             Buffers: shared hit=271  
 Planning Time: 0.686 ms  
 Execution Time: 5913.352 ms  
(133 rows)  
```  
### UDF  
```  
create or replace function get_res() returns setof tbl as $$  
declare  
  v_c1 int;  
begin  
  -- 初始递归条件  
  select c1 into v_c1 from tbl where c3=1 order by c1 limit 1;  
  -- 初始语句  
  return query select * from (select distinct on (c1,c2) * from tbl where c3=1 and c1=v_c1 order by c1,c2) t order by random() limit 10;  
  loop  
    -- 递归条件  
    select c1 into v_c1 from tbl where c3=1 and c1>v_c1 order by c1 limit 1;  
    if not found then  
      return;  
    end if;  
    -- 返回加入递归条件后的结果  
    return query select * from (select distinct on (c1,c2) * from tbl where c3=1 and c1=v_c1 order by c1,c2) t order by random() limit 10;  
  end loop;  
end;  
$$ language plpgsql strict;  
```  
```  
postgres=# select count(*) from get_res();  
 count    
--------  
 100010  
(1 row)  
Time: 3888.789 ms (00:03.889)  
```  
### 窗口查询  
```  
select count(*) from  
(  
select c1,c2,c3,c4,row_number() over (partition by c1 order by random()) as rn from   
  (select c1,c2,c3,c4,row_number() over (partition by c1,c2) as rn from tbl where c3=1) t  
where t.rn=1   
) t  
where rn<=10;  
 count    
--------  
 100010  
(1 row)  
Time: 5723.719 ms (00:05.724)  
```  
## 性能总结  
case | 数据量 | 递归SQL耗时(毫秒) | UDF耗时(毫秒) | 窗口查询耗时(毫秒)  
---|---|---|---|---  
提取100个品牌的10个商品(不去重) | 5000万记录1万商品 | 6.5 | 8.5 | 68  
提取1万个品牌的10个商品(不去重) | 5000万记录1万商品 | 418 | 502 | 4473  
提取1万个品牌的10个商品(去重) | 5000万记录1万商品 | 726 | 772 | 4933  
提取1万个品牌的10个商品(去重且随机) | 5000万记录1万商品 | 4758 | 3888 | 5723  
## 小结  
使用递归，我们在5000万的品牌数据中，为每个品牌筛选10个商品，输出10万行记录，约283毫秒。每个分页1000条的话，分页响应速度约5毫秒。  
为了达到最佳的效果，目标是扫描最少的数据块，尽量使用最少的CPU过滤，尽量将多余的扫描降到最少。所以我们用了类似SKIP INDEX SCAN的思路。把SQL优化到了极致，每一次递归仅扫描了需要的记录。(适合在递归层较稀疏的数据，递归次数本例就是指的品牌数)    
[《PostgreSQL Oracle 兼容性之 - INDEX SKIP SCAN (递归查询变态优化) 非驱动列索引扫描优化》](../201803/20180323_03.md)    
类似的场景和优化方法还可以参考如下文档：   
[《PostgrSQL 递归SQL的几个应用 - 极客与正常人的思维》](../201705/20170519_01.md)  
## 参考  
[《PostgreSQL SELECT 的高级用法(CTE, LATERAL, ORDINALITY, WINDOW, SKIP LOCKED, DISTINCT, GROUPING SETS, ...)》](../201802/20180226_05.md)    
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")