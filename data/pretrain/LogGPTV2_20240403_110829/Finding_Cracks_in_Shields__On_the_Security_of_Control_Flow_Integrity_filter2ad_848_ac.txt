are some details worth mentioning when developing the test suite
CBench.
Session 6B: Exploitation and Defenses CCS '20, November 9–13, 2020, Virtual Event, USA1826Regarding the VTable reuse attacks, we not only test whether
an attacker can reuse other types of VTables, but also test whether
they can reuse VTables of base classes. Some fine-grained CFI
schemes use runtime information to predict targets. In order to
detect whether such CFI schemes (such as µCFI) can effectively
process runtime information in complicated scenarios, we still use
the VTable pointer of the same type of objects as the test target.
For other forward ICTs, we test whether they can jump to the
following types of targets: functions with the same function type,
functions with different return types, functions with different pa-
rameter types, functions with different (more or less) parameters,
code gadgets and instructions located after call instructions.
For backward ICTs, we test whether they can return to: address
on the same stack space, addresses within the same function as the
intended target, return addresses of different functions and different
stack spaces, addresses of function entries and code gadgets.
For setjmp/longjmp functions, some versions of their implemen-
tations (e.g., in MUSL libc) save a direct copy of contexts, e.g., RSP,
RBP, RIP in 64 bit programs, while some other implementations
(e.g., glibc) will encrypt the saved contexts. The former is more
likely to be tampered with. CBench therefore includes a test case
for this case.
6 Evaluation
With the proposed security evaluation metrics and correspond-
ing evaluation tools, we further evaluated a set of representative
CFI mechanisms, and demonstrated the evaluation results.
• Answer to RQ1: We firstly ran CScan to recognize all feasible
runtime targets of ICT instructions, which are protected by target
CFI mechanisms. From the evaluation results, we could identify the
real boundaries of each CFI mechanism, and then compare different
CFI mechanisms’ security guarantees head-to-head.
• Answer to RQ2: We also evaluated the claimed boundary of each
CFI mechanism, and presented the gap between claimed boundaries
and real boundaries.
• Answer to RQ3: We ran CBench to evaluate target CFI mecha-
nisms’ effectiveness against typical attacks, and proved whether
the unintended targets within the real boundary are realistic.
6.1 Selection of Target CFI Mechanisms
As aforementioned, we have analyzed 56 CFI solutions and com-
pared their evaluation methods. But most of these CFI solutions
either have not released the source code to the public, or only work
on specific platforms. So, it is infeasible to deploy our evaluation
framework to assess those CFI solutions in detail. To the best of
our efforts, we collected 12 open source CFI implementations for
detailed security analysis. These 12 implementations are representa-
tive solutions and cover the characteristics of most CFI mechanisms:
support for applications with or without source code, context sen-
sitive and insensitive policy, static and dynamic CFG, utilization of
hardware features, and so on.
More specifically, we evaluated (1) two modes of CFI solutions
shipped with the latest compiler Clang 9.0, (2) several classic type-
based CFI mechanism, including BinCFI [75], MCFI [40], Lock-
down [46], and πCFI [42], and (3) almost all open source CFI solu-
tions presented at top-tier conferences in the past years, including
OS-CFI [31], PARTS [34], µCFI [27] and CFI-LB [30]. Note that, all
CFI solutions presented in the four top-tier security conferences
since 2018, except Pittypat [19] that is not open source, are evalu-
ated in our experiment. We believe these CFI mechanisms can well
represent the progress of CFI research in past years.
Environment. We use the default configuration provided by
the open-source project or the recommended configuration in their
README files and the experimental environment declared in their
paper, and use their test cases (if any) to ensure the prototype
system works well. And the compilation environment of Clang 9.0
is Ubuntu 16.04.
Fairness vs Completeness. The compiler compatibility and
feature support is different among CFIs, thus subtle changes in con-
figuration lead to vastly different evaluation results. For fairness, in
CScan we only evaluate the major contribution of CFI, i.e. protec-
tion of forward edges. To fill the missing parts, we further simulate
realistic configurations in CBench for completeness. There are two
cases. (1) Backward ICT: most CFI solutions [19, 27, 30, 31, 46]
proposed in recent years focus on how to protect forward ICT in-
structions (e.g., indirect call and jump), and leave backward ICT
instructions (e.g., return) to shadow stack [67]. Considering that
the shadow stack mechanism is commonly used, we only evalu-
ate the number of feasible targets of forward ICT instructions in
CScan, but evaluate the classic ROP attack in CBench for com-
pleteness. (2) Tail call optimization: As claimed in the official code
repository,MCFI/πCFI have to turn off compilers’ tail call optimiza-
tion to get accurate call stack information. Considering that tail
calls could also affect other CFI implementations, we disable tail
call optimization for all of them in CScan, but add it back in CBench
due to its popularity in practical applications.
6.2 Number of Runtime Feasible Targets
6.2.1 Experiment Setup. Out of 12 CFI mechanisms, CScan is
only able to evaluate 9 of them. Three CFI mechanisms, i.e., µCFI,
BinCFI and PARTS, adopt special techniques to deploy CFI checks,
making it challenging to evaluate. We leave it as a future work to
support these special CFI mechanisms. µCFI uses a second process
for monitoring, which is asynchronous with the running program to
dynamically analyze the running program to speculate the unique
target. CScan will modify the run-time state of the running pro-
gram, which will affect the dynamic analysis of the monitoring
process. BinCFI employed an anti-debugging mechanism, prohibit-
ing CScan to modify runtime values. PARTS protects the integrity
of code pointers with cryptography signatures, and CScan cannot
effectively iterate all potential pointers with valid signatures. For
the similar reason, CScan currently cannot test CFI schemes with
encrypted pointers (e.g. CCFI [36]).
Benchmark. As CONFIRM [68] shows, existing CFI implemen-
tations have enormous unresolved challenges in terms of compat-
ibility. The effectiveness of these CFI implementations on most
real-world programs cannot be evaluated due to incompatibility.
To test real-world applications, we evaluate Nginx using the hello-
nginx test module, which is commonly used in CFI evaluation, as
the sample of the real-world programs. There are still compatibility
issues. Lockdown cannot make Nginx compiled by Clang work
properly (which we need), OS-CFI fails to compile Nginx.
To compare with existing evaluations [9], we also choose SPEC
CPU2006 as the benchmarks, and evaluate their forward ICT in-
structions. However, there are no forward ICTs in two benchmarks,
Session 6B: Exploitation and Defenses CCS '20, November 9–13, 2020, Virtual Event, USA1827Table 1: Number of runtime feasible targets for ICT instructions of SPEC CPU2006 benchmarks protected by CFI.
CFI Solution
MCFI
SPEC CPU
perlbench
xalancbmk
π CFI
Lockdown (x86)
OS-CFI
Clang-CFI-DSO
Clang-CFI
TSX-RTM
TSX-HLE
bzip2
gcc
gobmk
hmmer
sjeng
h264ref
omnetpp
astar
Benchmark & Nginx Mean Median Mean Median Mean Median Mean Median Mean Median Mean Median
-
5533
4
1
968
1
-
8 17565.51 17565.51
-
10851
17
1850
1
1
7
7
1122
1785 †1.67
1
-
8335
1
4237
1
1
46605
2
-
1.66
1206
1
1
4222
16
-
29104
2
1
6101
1
-
8903
3
5
1505
1
18.0
-
-
CFI-LB
Mean Median
Mean Median Mean Median
5.5
95741.81
-
5533.2
1
1
968
1
9
26.61
-
12
596.75k
-
10
10
1
7
7
7
†2
4
3.56
13.5
2076.3k
-
1
1
1
†8775k †11645k
-
2
2
40
1
†3096.6k †5972.0k
-
†2979.6k †5972.0k
1
5910.5k
4635.7k
-
5
5
5
- † 3098.64k
11
22.03
8
1
1
*3
*8.91
8 600.84
10
10
7
7
2
2.06
*3 *12.34
1
1
*7.19
*3
2
2
40
40
3.6
*2
*3
3.45
*3 *13.81
5
5
*28.0
28.49
23.27
3673
1
1901
7386
32.63
4480 605.51
10
2339
7
1945
2.06
2391
16.33
-
-
1
44.57
-
2
2036
40
-
38.15
-
2.14
-
14.31
-
2170
5
3091 483.16
22.27
5
1
1
12
27.46
32 602.18
1
10
7
7
1
2
10.90
1
1
1
17.33
2
1
2
16
40