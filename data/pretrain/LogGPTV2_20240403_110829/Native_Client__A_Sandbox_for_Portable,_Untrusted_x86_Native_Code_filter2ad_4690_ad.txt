9.2%
2.8%
32.3%
25.2%
50.2%
21.2%
32.6%
16.8%
Table 5: Code size for SPEC2000, in kilobytes.
aligning some instructions that are not indirect control ﬂow
targets, we hope to make incremental code size improvement
as we reﬁne our implementation. “NaCl” measurements are
for statically linked binaries, 32-byte block alignment, and
using the nacljmp instruction for indirect control ﬂow
transfers. To isolate the impact of these three constraints,
Figure 4 also shows performance for static linking only,
and for static linking and alignment. These comparisons
make it clear that alignment is the main factor in cases
where overhead is signiﬁcant. Impact from static linking and
sandboxing instruction overhead is small by comparison.
The impact of alignment
is not consistent across the
benchmark suite. In some cases, alignment appears to im-
prove performance, and in others it seems to make things
worse. We hypothesize that alignment of branch targets
to 32-byte boundaries sometimes interacts favorably with
caches,
instruction prefetch buffers, and other facets of
processor microarchitecture. These effects are curious but
not large enough to justify further investigation. In cases
where alignment makes performance worse, one possible
factor is code size, as mentioned above. Table 5 shows
that
increases in NaCl code size due to alignment can
be signiﬁcant, especially in benchmarks like gcc with a
large number of static call sites. Similarly, benchmarks
with a large amount of control ﬂow branching (e.g., crafty,
vortex) have a higher code size growth due to branch target
alignment. The incremental code size increase of sandboxing
with nacljmp is consistently small.
Overall, the performance impact of Native Client on these
this level,
benchmarks is on average less than 5%. At
overhead compares favorably to untrusted native execution.
4.2. Compute/Graphics Performance Tests
We implemented three simple compute+animation bench-
marks to test and evaluate our CPU performance for threaded
87
Sample
Voronoi
Earth
Life
Native Client
12.4
14.4
21.9
Linux Executable
13.9
12.6
19.4
Table 6: Compute/graphics performance tests. Times are user time
in seconds.
Executable
Native Client
Linux Binary
1 thread
42.16
46.29
2 threads
22.04
24.53
4 threads
12.4
13.9
Table 7: Voronoi
seconds.
thread performance. Times are user time in
code.3 They are:
• Earth: a ray-tracing workload, projecting a ﬂat image
of the earth onto a spinning globe
• Voronoi: a brute force Voronoi tessellation4
• Life: cellular automata simulation of Conway’s Game
of Life
These workloads have helped us reﬁne and evaluate our
thread implementation, in addition to providing a benchmark
against standard native compilation.
We used the Linux time command to launch and time
standalone vs. NaCl release build executables. All measure-
ments are for a Ubuntu Dapper Drake Linux system with
a 2.4GHz Intel Q6600 quad core processor. VSYNC was
disabled.5 The normal executables were built using g++
version 4.0.3, the NaCl versions with nacl-g++ version 4.2.2.
All three samples were built with -O3 -mfpmath=sse
-msse -fomit-frame-pointer.
Voronoi used four worker threads and ran for 1000 frames.
Earth ran with four worker threads for 1000 frames. Life
ran as a single thread, for 5000 frames. Table 6 shows the
average for three consecutive runs.
Voronoi ran faster as a NaCl application than as a normal
executable. The other two tests, Earth and Life, ran faster
as normal executables than their Native Client counterparts.
Overall these preliminary measurements suggest that, for
these simple test cases, the NaCl thread implementation
behaves reasonably compared to Linux. Table 7 shows a
comparison of threaded performance between Native Client
and a normal Linux executable, using the Voronoi demo.
Comparing Native Client to Linux, performance scales com-
parably with increased thread count.
4.3. H.264 Decoder
We ported an internal implementation of H.264 video
decoding to evaluate the difﬁculty of the porting effort.
3. These benchmarks will be included in our open source distribution.
4. See http://en.wikipedia.org/wiki/Voronoi
5. It
to disable VSYNC when benchmarking rendering
applications. If VSYNC is enabled, the application’s rendering thread may
be put to sleep until the next vertical sync occurs on the display.
is important
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply. 
The original application converted H.264 video into a raw
ﬁle format, implemented in about 11K lines of C for the
standard GCC environment on Linux. We modiﬁed it to play
video. The port required about twenty lines of additional C
code, more than half of which was error checking code.
Apart from rewriting the Makeﬁle, no other modiﬁcations
were required. This experience is consistent with our general
experience with Native Client; legacy Linux libraries that
don’t inherently require network and disk generally port
with minimal effort. Performance of the original and NaCl
versions were comparable and limited by video frame-rate.
4.4. Bullet
Bullet [8] is an open source physics simulation system.
It has accuracy and modeling features that make it appro-
priate for real-time applications like computer games. As
a complex, performance sensitive legacy code base it is
representative of a type of system that we would like to
support with Native Client.
The effort required to build Bullet for Native Client was
non-trivial but generally straightforward. We used Bullet
v2.66 for our experiments which is conﬁgurable via auto-
tools [5], allowing us specify use of the NaCl compiler. We
also had to build the Jam build system [35], as it is required
by the Bullet build. A few #deﬁnes also had to be adjusted
to eliminate unsupported proﬁling system calls and other OS
speciﬁc code. Overall it took a couple of hours of effort to
get the library to build for Native Client.
Our performance test used the HelloWorld demo program
from the Bullet source distribution, a simulation of a large
number of spheres falling and colliding on a ﬂat surface. We
compared two builds using GCC v4.2.2 capable of generat-
ing NaCl compliant binaries. Measuring 100,000 iterations,
we observed 36.5 seconds for the baseline build (-static) vs.
32-byte aligned blocks (as required by Native Client) at 36.1
seconds, or about a 1% speedup for alignment. Incorporating
the additional opcode constraints required by Native Client
results in runtime of 37.3 seconds, or about a 2% slowdown
overall. These numbers were obtained using a two processor
dual-core Opteron 8214 with 8GB of memory.
4.5. Quake
We proﬁled sdlquake-1.0.9 (from www.libsdl.org) using
the built-in “timedemo demo1” command. Quake was run
at 640x480 resolution on a Ubuntu Dapper Drake Linux
box with a 2.4GHz Intel Q6600 quad core CPU. The video
system’s vertical sync (VSYNC) was disabled. The Linux
executable was built using gcc version 4.0.3, and the Native
Client version with nacl-gcc version 4.2.2, both with -O2
optimization.
With Quake, the differences between Native Client and
the normal executable are, for practical purposes, indistin-
guishable. See Table 8 for the comparison. We observed
88
Run #
1
2
3
Average
Native Client
143.2
143.6
144.2
143.7
Linux Executable
142.9
143.4
143.5
143.3
Table 8: Quake performance comparison. Numbers are in frames
per second.
very little non-determinism between runs. The test plays the
same sequence of events regardless of frame rate. Slight
variances in frame rate can still occur due to the OS thread
scheduler and pressure applied to the shared caches from
other processes. Although Quake uses software rendering,
the performance of the ﬁnal bitmap transfer to the user’s
desktop may depend on how busy the video device is.
5. Discussion
As described above, Native Client has inner and outer
sandboxes, redundant barriers to protect native operating
system interfaces. Additional measures such as a CPU
blacklist and NaCl module blacklist will also be deployed,
and we may deploy whitelists if we determine they are
needed to secure the system. We have also considered more
elaborate measures, although as they are speculative and
unimplemented we don’t describe them here. We see public
discussion and open feedback as critical to hardening this
technology, and informing our decisions about what security
mechanisms to include in the system.
We expect Native Client to be well suited to simple,
computationally intensive extensions for web applications,
speciﬁcally in domains such as physical simulation, lan-
guage processing, and high-performance graphics rendering.
Over time, if we can provide convenient DOM access, we
hope to enable web-based applications that run primarily in
native code, with a thin JavaScript wrapper. There are also
applications of this technology outside of the browser; these
are beyond our current focus.
We have developed and tested Native Client on Ubuntu
Linux, MacOS and Microsoft Windows XP. Overall we
are satisﬁed with the interaction of Native Client with
these operating systems. That being said, there are a few
areas where operating system support might helpful. Popular
operating systems generally require all threads to use a ﬂat
addressing model in order to deliver exceptions correctly.
Use of segmented memory prevents these systems from
interpreting the stack pointer and other essential thread state.
Better segment support in the operating system might allow
us to resolve this problem and allow for better hardware
exception support in untrusted code. If the OS recognized
a distinguished thread to receive all exceptions, that would
allow Native Client to receive exceptions in a trusted thread.
Native Client would also beneﬁt from more consistent
enabling of LDT access across popular x86 operating sys-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply. 
tems. As an interesting alternative to maintaining system call
access as provided by most current systems, a system call
for mapping the LDT directly into user space would remove
a kernel system call from the path for NaCl thread creation,
relevant for modules with a large number of threads.
With respect to programming languages and language
implementations, we are encouraged by our initial experi-
ence with Native Client and the GNU tool chain, and are
looking at porting other compilers. We have also ported two
language interpreters, Lua and awk, and are aware of efforts
to port other popular interpreted languages. While it would
be challenging to support JITted languages such as Java,
we are hopeful that Native Client might someday allow
developers to use their language of choice in the browser
rather than being restricted to only JavaScript.
6. Related Work
Techniques for safely executing 3rd-party code generally
fall into three categories: system request moderation, fault
isolation (including virtualization), and trust with authenti-
cation.
6.1. System Request Moderation
Kernel-based mechanisms such as user-id based access
control, systrace [50] and ptrace [60] are familiar facilities
on Unix-like systems. Many previous projects have explored
use of these mechanisms for containing untrusted code [24],
[33], [34], [36], [52], most recently Android [9], [27] from
Google and Xax [17] from Microsoft Research. Android
uses a sandbox for running 3rd party applications. Each
Android application is run as a different Linux user, and
a containment system partitions system call activity into
permission groups such as “Network communication” and
“Your personal information”. User acknowledgment of re-
quired permissions is required prior to installing a 3rd party
application. User separation inherently denies potentially
useful intercommunication. To provide intercommunication,
Android formed a permissions model atop the Binder in-
terprocess communication mechanism, the Intent sytem and
ContentProvider data access model. [9]
Xax is perhaps the most similar work to Native Client
in terms of goals, although their implementation approach
is quite different, using system call interception based on
ptrace on Linux and a kernel device driver on Windows. We
considered such a kernel-based approach very early in our
work but rejected it as impractical due to concerns about
supportability. In particular we note that the Xax Windows
implementation requires a kernel-mode device driver that
must be updated for each supported Windows build, a
scheme we imagine onerous even if implemented by the
OS vendor themselves. There are known defects in ptrace
containment6 that Xax does not address. Although the Xax
authors do recognize one such issue in their paper, a simple
search at Mitre’s Common Vulnerabilities and Exposures
site7 documents forty-one different ptrace-related issues.
Because of its pure user-space inner sandbox, Native Client
is less vulnerable to these difﬁcult kernel issues. Xax is
also vulnerable to denial-of-service attacks based on x86
errata that can cause a machine to hang or reboot [31], [38].
Because Native Client examines every instruction and rejects
modules with instructions it ﬁnds suspect, it signiﬁcantly re-
duces the attack surface with respect to invalid instructions,
and further it includes relevant mechanism for defending
against new exploits should they be found.
Because the Xax sandbox functions at the process bound-
ary, it fails to isolate untrusted code when shared application
components such as DLLs are involuntarily injected by
the operating system, an issue both for security and for
portability of untrusted code. In contrast, the Native Client
inner sandbox creates a security sub-domain within a native
operating system process. Apart from these security differ-
ences we note that Xax does not support threading, which
we considered essential given the trend towards multicore
CPUs.
The Linux seccomp8 facility also constrains Linux pro-
cesses at the system call interface, allowing a process to
enter a mode where only exit(), read(), and write() system
calls are permitted.
6.2. Fault Isolation
Native Client applies concepts of software fault isolation
and proof-carrying code that have been extensively dis-
cussed in the research literature. Our data integrity scheme
is a straightforward application of segmented memory as
implemented in the Intel 80386 [14]. Our current control
ﬂow integrity technique builds on the seminal work by
Wahbe, Lucco, Anderson and Graham [62]. Like Wahbe et
al., Native Client expresses sandboxing constraints directly
in native machine instructions rather than using a virtual
machine or other ISA-portable representation. Native Client
extends this previous work with speciﬁc mechanisms to
achieve safety for the x86 [4], [14], [32] ring-3 instruc-
tion set architecture (ISA), using several techniques ﬁrst
described by McCamant and Morrisett [40]. Native Client
uses a static validator rather than a trusted compiler, similar
to validators described for other systems [19], [40], [41],
[49], applying the concept of proof-carrying code [46].
After the notion of software fault isolation was popu-
larized by Wahbe et al., researchers described complemen-
tary and alternative systems. A few [1], [19], [40], [41],
6. http://www.linuxhq.com/kernel/v2.4/36-rc1/Documentation/ptrace.txt
7. For example, see http://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=
ptrace
8. See linux/kernel/seccomp.c
89
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply. 
[49], [56] work directly with x86 machine code. Others
are based on intermediate program representations, such as
type-safe languages [28], [45], [47], [59], abstract virtual
machines [3], [20], [21], [39], or compiler intermediate
representations [53]. They use a portable representation,
allowing ISA portability but creating a performance obstacle
that we avoid by working directly with machine code.