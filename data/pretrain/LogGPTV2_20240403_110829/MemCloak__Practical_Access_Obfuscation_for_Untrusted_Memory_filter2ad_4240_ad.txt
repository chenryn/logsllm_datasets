copy to a dierent location. A straightforward way is associating
each block with the indices of newly selected hash functions. This
method is ineective due to two drawbacks. First, each block needs
to maintain the indices of up to c hash functions. This inates the
position map back to the giant traditional one. Second, the addresses
193
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Weixin Liang, Kai Bu, Ke Li, Jinhong Li, and Arya Tavakoli
a block can be mapped to is upper bounded by the number of avail-
able hash functions. If we expect that a block be evenly mapped
across the entire memory space, an impractically large number of
hash functions would be needed.
We propose an alias-based mapping technique to eciently up-
date the position map. As discussed in Section 3.3, we can use a
dierent address as an address’s mapping alias. That is, after an
address’s originally selected hash functions are all used, it can
direct to its alias’s entry and use the hash functions therein for
address mapping. After its alias’s hash functions are all used, it can
choose another alias. This makes each address uniformly mapped
across the entire memory space without cumbersome and insecure
re-selection of hash functions. Specically, the alias-based map-
ping introduces two aliases to each entry and one more counter
for each block in that entry. This way, all blocks in the same page
share same aliases but each of them has two propriety counters. One
counter tracks how many hash functions of the current alias is used.
The other counter tracks how many new copies are replenished
to addresses computed using the next alias and its hash functions.
Apparently, the current alias is initialized as an address per se. The
next alias to choose should have higher access frequency than that
of the current alias. Otherwise, replenished data may override some
unaccessed data. For pages with the highest access frequency, we
can leave some blank pages in memory for their aliasing. Further-
more, we can use well-designed caching/buering strategies of
the stash and caches to balance memory access frequency of each
page. That is, highly frequently accessed blocks usually stay in
cache. They thus may not impose too many real memory accesses
or position-map updates.
lpage
lblock
We now analyze the position-map size after integrating the alias-
based mapping technique. The overhead it introduces is two alias
(of size 2laddr) per page and one counter (of size log c) per block. Fol-
lowing the analysis of previous compression technique 3, the size of
the position map becomes (c log h +
log c)⇥
c / lpage
lblock . We consider the same settings of 64-bit physical addresses,
n
64-byte data blocks, 4 KB pages, 4 GB memory, h = 1, 024 hash
functions, and c = 16 copies per block on average as in previous
analysis. The position map then takes a size of 6.25 MB. It is com-
pressed over 100x than the traditional position map and can be
practically tted into a cache or buer.
log c +2laddr +
lpage
lblock
5 IMPLEMENTATION
As with related obfuscation solutions [5, 43], we implemented Mem-
Cloak using the gem5 simulator [7]. Gem5 is widely used for com-
puter architecture research. Its emulation encompasses CPU and
memory modules and supports tracing memory accesses, which are
exactly the operations MemCloak aims to protect. MemCloak im-
plementation aims to enforce the proposed obfuscation techniques
over the conventional memory accesses in gem5. As discussed in
Section 4, key components include the position map (including the
aggregation map), the address computation unit, the hash unit, and
the encryption/decryption unit.
Our modication over gem5 remains as a transparent layer be-
tween the last-level cache and memory. A memory request in gem5
is rst transmitted from the CPU to the rst-level cache. If it enjoys
194
a cache hit therein, the requested data is transmitted to the CPU.
Otherwise, the rst-level cache redirects the memory request to the
second-level cache. Upon a cache hit on the second-level cache, the
requested data is rst transmitted to the rst-level cache and then
transmitted to the CPU. Generally speaking, gem5 directs a data
block from the lowest-level cache where the data block is rst found
through all its higher-level caches to the CPU. Although this may
take a longer access time when the requested data block is found for
the rst time, caching it in some higher-level cache will save its sub-
sequent access time. If a requested data block cannot be found until
the last-level cache, the memory request will be eventually trans-
mitted to memory. A Cache class uses the CpuSidePort interface to
communicate with its higher-level cache (or the CPU if the Cache
class represents the rst-level cache) and uses the MemSidePort to
communicate with its lower-lever cache (or memory if the Cache
class represents the last-level cache). Since MemCloak intercepts
memory access requests from the last-level cache and may redirect
these requests to memory, we implement MemCloak by inheriting
from a Cache class in gem5. We use AES counter mode for the
encryption/decryption unit. We adopt the random function rand()
in the standard C library for designing the hash unit. In hardware,
such random number generators can be implemented using cir-
cuit white noise [21]. MemCloak performs address mapping before
sending a memory request to memory and address update before
forwarding a fetched data block to the last-level cache. Our modi-
cation accounts for 2,000+ lines of C/C++ code while the original
code base of gem5 contains over 250,000 lines.
To evaluate the performance of MemCloak, we run highly memory-
intensive workloads from MiBench [19]. MiBench is a representa-
tive benchmark suite for embedded systems. It collects multiple
benchmarks for six embedded application areas, that is, Automotive
and Industrial Control, Consumer Devices, Oce Automation, Net-
working, Security, and Telecommunications. As embedded systems
usually have memory restrictions, it is commonly used to validate
eciency and practicality of access obfuscation solutions [45, 46].
The three highly memory-intensive benchmarks we use are dijkstra,
susan, and jpeg encode from the areas of Networking, Automotive
and Industrial Control, and Consumer Devices.
6 EVALUATION
In this section, we evaluate security and eciency of MemCloak.
First, the security performance is measured by the randomness of
the address sequence accessed during the execution of a benchmark
[45]. The randomness is tested using the NIST Statistical Test Suite
[23]. Second, the eciency performance is measured by the exe-
cution time and memory usage of a benchmark on the emulated
computer architecture. The gem5 simulator tracks the number of
clock cycles taken by a benchmark. Then it estimates the execution
time by multiplying the number of clock cycles and the congured
clock period. The results demonstrate that MemCloak can signi-
cantly randomizes memory accesses with approximately 4% time
overhead and comparative memory overhead with that of ORAM.
Experiment setup. Since gem5 estimates the relative execution
time of a benchmark using the number of clock cycles taken in the
emulated computer architecture, the estimation is insensitive to the
running environment. We currently run our MemCloak prototype
MemCloak: Practical Access Obfuscation for Untrusted Memory
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Table 1: Comparison of memory access randomness of inse-
cure (without MemCloak) and secure (with MemCloak) exe-
cution. We test the access randomness using the NIST Sta-
tistical Test Suite [30] with 14 randomness analysis tools
supported. The tools corresponding to each row are Fre-
quency (Monobit) Test, Frequency Test within a Block, Cu-
mulative Sums (Cusum) Test 1, Cumulative Sums (Cusum)
Test 2, Runs Test, Test for the Longest Run of Ones in a
Block, Binary Matrix Rank Test, Discrete Fourier Transform
(Spectral) Test, Overlapping Template Matching Test, Mau-
rer’s “Universal Statistica” Test, Approximate Entropy Test,
Serial Test 1, Serial Test 2, and Linear Complexity Test [30].
dijkstra
susan
jpeg encode
Table 2: Comparison of execution time in seconds of inse-
cure (without MemCloak) and secure (with MemCloak) exe-
cution.
dijkstra
insecure
5.551
secure
5.778
susan
insecure
492.475
secure
509.718
jpeg encode
insecure
7.542
secure
7.843
measuring the access randomness, we rst collect the access se-
quence while running a selected benchmark and snooping on the
address bus. We then convert the access sequence into a bit stream
by concatenating all of the block addresses in the same order as
they are collected. We input the bit stream to the NIST Statistical
Test Suite. It will be divided into same-length bitstrings, each is
analyzed by all supported randomness analysis tools in the NIST
Statistical Test Suite. A higher randomness of the input bit stream
depends on the following two properties.
• For each randomness analysis tool, more bitstrings of the bit
stream can pass the test.
• For all randomness analysis tools, more of them can accept
most of the bitstrings of the bit stream.
We compare the access randomness of benchmark execution
with or without MemCloak obfuscation. Table 1 reports the com-
parison using benchmarks of dijkstra, susan, and jpeg encode; each
data block has 10 dierently-encrypted copies into the memory. In
each column, each row reports the randomness test result using
one of the 14 supported randomness analysis tools. For most of the
tools, the insecure execution without MemCloak obfuscation can
barely pass the test. In contrast, MemCloak signicantly random-
izes memory access in that most bitstrings can pass the randomness
test. Take, for example, the results of the dijkstra benchmark using
the Frequency (Monobit) Test tool (i.e., the two values on the top
0
283 = 0% of the bitstrings
left corner). Without access obfuscation,
of the bit stream corresponding to the access sequence can pass
the randomness test. Armed with access obfuscation by MemCloak,
249
528 = 47% of the bitstrings can pass the test. Note that MemCloak
induces more memory accesses because of dummy writes. As shown
in Table 1, MemCloak signicantly increases the access randomness
from below 30% to over 70% on average. Furthermore, MemCloak
outperforms the existing O(1)–communication-overhead access
obfuscation solution [45], in which the average randomness test
result ranges from 13% to 44%.
6.2 Execution Time
Table 2 reports the execution time corresponding to dierent bench-
mark executions in Table 1. Since protecting the access type neces-
sitates dummy writes, MemCloak requires more memory accesses
and therefore takes more time. The average time overhead is about
4%, estimated using the time measurements in the “insecure” and
“secure” columns as secure   insecure
6.3 Memory Usage
Finally, we evaluate how the number of copies per data block aects
memory usage and obfuscation randomness. Intuitively, the more
copies each data block has, the more memory space MemCloak
consumes. Given c copies per data block, the memory overhead
is upper bounded by c 1
c . Although we can aggregate
insecure
c = 1   1
.
insecure
0/283
0/283
0/283
0/283
0/283
1/283
281/283
20/283
264/283
0/283
0/283
1/283
26/283
273/283
secure
249/528
511/528
267/528
266/528
424/528
515/528
525/528
526/528
521/528
0/528
309/528
483/528
506/528
510/528
insecure
14/318
19/318
11/318
11/318
2/318
15/318
316/318
221/318
313/318
0/318
0/318
1/318
5/318
307/318
secure
162/397
381/397
167/397
169/397
272/397
371/397
389/397
392/397
386/397
0/397
150/397
391/397
395/397
385/397
average
insecure
112/1133
28/1133
28/1133
23/1133
11/1133
112/1133
1124/1133
279/1133
1116/1133
0/1133
0/1133
0/1133
329/1133
1107/1133
secure
1777/1813
1137/1813
1137/1813
1134/1813
1333/1813
1787/1813
1805/1813
1792/1813
1783/1813
0/1813
841/1813
1692/1813
1757/1813