o | 0 | 1 | 2 | 3 | 3 | 3 | 3  
n | 0 | 1 | 2 | 3 | 3 | 3 | 3  
然后从右下角进行回溯操作，若ai=bj，则走左上角；若ai≠bj，则到左上角、上边、左边中值最大的单元格，相同的话优先级按照左上角、上边、左边的顺序，直到左上角为止。最终按照如下规则写出表达式（_表示插入字符或者是删除字符操作）
  * 若走左上角单元格，A+=ai，B+=bi
  * 若走到上边单元格，A+=ai，B+=_
  * 若走到左边单元格，A+=_，B+=bi
多序列对比，实际上是LCS的扩展，采用引导树、非加权成对群算术平均法等来进行，非加权成对群算术平均法即UPGMA算法，这是一种聚类算法，在我们前面已经得到的距离的基础上进行操作，将距离最小的两个节点进行聚合，然后再次计算新的节点间的距离，最终生成演化树。
演化树（Phylogenetic
tree），在多序列对比中生成的树，其实就像是生物进化图那样，由根衍生出一个一个节点，如图所示为DNA系统的演化树，我们所要建立的演化树是关于协议的数据的，通过这种方式来寻找协议流量中的相似部分。
建树的方法主要有两大类，一类是基于距离的，一类的基于character的。我们上面提到的就是基于距离的建树方式，一般来讲，基于距离的方法将数据抽象为距离，从而有了较快的处理速度，但是其抽象过程中会有信息量的损失；而基于character的方法是在一个已有的模型上建立的，所以需要有一个靠谱的模型，但好处就是我们的信息不会丢失。
广义后缀树（Generalized Suffix
Tree），用来实现求解最大公共子串、匹配字符串、找重复串等等，这里说的最大公共子串就是我们平时理解的：连续的、相同的字符串。比如”modbus“和”m
od i c o n“，那么这俩的最大公共子串就是od而不是上面的”mod“。该技术常用于病毒的特征码提取。下面举个栗子来解释一下：
假设我们现在有modbus、modicon两个字符串,对于modbus，后缀有：
s  
us  
bus  
dbus  
obus  
modbus
我们将其按字典序排序，然后建立树，根节为空，每个字母为一个节点，从根到叶子就对应了一个单词，如图所示
我们还可以对单节点链条进行压缩，当然这个单词所有的链条都是单节点的……然后我们将modicon也按后缀，然后插入到这个树中，重合的部分即为公共子串（因为我不知道怎么画图，所以你们就自行想象一下吧）。
聚类（cluster），大白话就是分类，一是用来对流量进行粗略分类，二是用来对提取的字符串进行分类。具体涉及的包括了k紧邻算法、关键词树算法等等
以上是一些基础性的问题，有了以上的基础，我们可以大致将流量包的分析归为以下几步：
  * 粗略聚类，提取主要分析的流量，并将相似的流量首先分到一起
  * 采用各类算法来对字段进行划分
  * 根据某些字段再次进行聚类
  * 对一类的流量进行关系分析
###  Netzob划分数据
netzob是一种基于网络轨迹的逆向工具，目的就是为了分析未知协议，当然还有其他的一些，比如PI等等，我们这里就以netzob为例进行操作。
首先当然是要安装，netzob需要大量的前置包，安装很麻烦，很有可能遇到各种错误，因为和实际环境有关，所以我也没法全部列举出来，大家安装时自行尝试吧
    apt-get install python-dev      #提前需要安装的库
    apt-get install python-impacket
    apt-get install python-setuptools
    apt-get install libxml2-dev
    apt-get install libxslt-dev
    apt-get install gtk3
    apt-get install graphviz
    git clone https://github.com/netzob/netzob.git
    cd netzob
    python3 setup.py develop --user  #开发者友好模式
以上步骤完成后我们就可以在python3中import了
    from netzob.all import *
当然也可以python3 setup.py
install来安装友好的图形化界面，使用./netzob即可打开，但是在我的机器上出现了问题，大家可以自行尝试。如果实在是安装不成功的同学，官方也给了docker镜像
    docker pull netzob/netzob
    docker run --rm -it -v $(pwd):/data netzob/netzob  #pwd为当前位置，挂载到根目录下的data
搞定后我们就可以开始干活了
    m = PCAPImporter.readFile("modbus.pcap").values()
该条语句用来导入我们的流量包，我们可以查看一下它的说明
参数主要关注两个，一个是importLayer，这是指定我们要分析的data是在哪一层，以我们modbus来说，是基于tcp的，所以data就相当于是tcp往上一层，所以填5，如果是S7comm呢则要考虑你要分析哪一层再进行选择；另一个是bpfFilter（Berkeley
Packet Filter)，也即是伯克利包过滤的意思，这是一种语法，可以指定你要选择哪些流量，如下所示：
    host 0.0.0.0 and (port 138) #筛选出ip为0.0.0.0且端口为138的流量包
接着我们进行符号化，即筛选出所有相似的流量，这里就涉及到了我们之前提到的数学知识
    s = Symbol(messages = m)
可以看到提取出来的就是相似的流量就是我们流量包中的modbus部分，这一步就相当于我们上面提到的粗略聚类，Netzob将modbus部分的流量提取了出来，并将这些流量放到了一起。但是现在我们还是啥也看不出来，我们希望能够对data再次进行分析，对比得到哪些字符应该是一块的，哪些是分开的。
    Format.splitStatic(s)
该方法用来将我们的data根据相似性与静态分布规律，划分为几个Field，当然，我们也可以通过“肉眼观察法”使用splitDelimiter(symbol,ASCII(“Z”)来进行人工的划分。这一步相当于“采用各类算法来对字段进行划分”，也是核心部分，如图即为划分Field后的symbol
我们就以第一组为例，打开wireshark来检查一下分析的结果
真正的划分如下：
    'x00x00'  | 'x00x00' | 'x00x04'  | 'x00Z' | 'x00x02'
可以看到差距较大，观察流量包后发现，主要原因是因为modbus的前四个字段在该流量包中区分不太“明显“，以第一个字段举例，modbus用了两个字节表示事务标识符（即Transaction
identifier
），但在这些流量中最多最多就是x00x01，根本就没有用到低字节，所以在划分时被认为是两个字段了。同理，长度字段也是如此，该流量包中的length也没有用到低字节，所以也被划为了两个字段。
知道了情况我们就可以对症下药了，一是我们引入新的流量包，选取一些数据量较大、情况足够全面的流量，可以稍加完善；二是我们通过不断的尝试和日常积累进行手动划分，比如每种协议基本都有的length字段、标识字段等等进行手动划分。但是由于协议本身的规定与限制（比如，虽然给了两个字节，但是实际上并没有使用低字节，厂商只是为了扩展或者对齐），我们只可能完善，但绝不可能完美划分字段，不过仅仅是这样对我们的帮助已经很大了。
之后我们要进行的步骤为“根据某些字段再次进行聚类”，但是这里由于我们对于哪个是关键字段并不清楚，所以暂时放弃这一步。
接下来我们要做的工作就是要猜测字段的含义，当然我们通过这种方式绝对不可能“猜”出来“Z”是施耐德专用的功能码，我们能做的是推理这些字段之间的关系。
    for symbol in symbols.values():
        rels = RelationFinder.findOnSymbol(symbol)
        print("[+] Relations found: ")
        for rel in rels:
            print("  " + rel["relation_type"] + ", between '" + rel["x_attribute"] + "' of:")
            print("    " + str('-'.join([f.name for f in rel["x_fields"]])))
            p = [v.getValues()[:] for v in rel["x_fields"]]
            print("    " + str(p))
            print("  " + "and '" + rel["y_attribute"] + "' of:")
            print("    " + str('-'.join([f.name for f in rel["y_fields"]])))
            p = [v.getValues()[:] for v in rel["y_fields"]]
            print("    " + str(p))
RelationFinder为我们提供了不同的关系分析方法，这里我们选择使用基于符号的分析方法，也就是对我们之前进行过Field划分的符号进行分析。
当然，这只能探索符号内部的关系，像是我们的数据包，我们只能发现length字段，但是已经是非常大的进步。为我们之后进行测试、逆向程序都省下了不少功夫。
## 总结
虽然说了不少东西，但大多还是以理论为主，实际上代码就撩撩几行，当然这也是我们协议分析的第一步，在之后的文章中我们将基于这部分内容，继续进行探索。