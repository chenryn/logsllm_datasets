to the variations presented in [15] (which tested on an In-
tel i7-2600) for libdrag. We do not observe any mea-
surable timing variation in any add, multiply, or subtract
operations for single or double precision ﬂoating point.
We do observe notable timing differences based on argu-
ment values for single and double precision division and
square-root operations. The cross table results for dou-
ble precision division are shown in ﬁgure 14. Figure 12
summarizes the timing variations we observed.
For division, it appears that the numerator has no im-
USENIX Association
26th USENIX Security Symposium    77
pact on the running time of the computation. The de-
nominator shows variation based on if the signiﬁcand or
exponent is all zero bits. When either portion is zero in
the denominator computations run consistently faster in
both single and double precision ﬂoating point. Differ-
ences observed range from 2% to 5% in contrast to the
2500% differences observed in section 3.
Square root shows a similar behavior, where if either
the signiﬁcand or exponent is all 0 bits the computation
runs consistently faster. This matches the behavior seen
for many operations in scalar computations. (See ﬁgure
9)
An interesting outcome of this behavior is that subnor-
mal values cause a speedup under libdrag rather than
the slowdown observed under scalar operations.
We speculate that this is the result of fast paths in the
microcode handling for vector operations. Using perfor-
mance counters we determined that all vector operations
containing a subnormal value execute microcode rather
than hardwired logic on the FPU hardware. As all val-
ues with a zero signiﬁcand or exponent experienced a
speedup, we believe that the division and square root mi-
crocode handles these portions separately with a shortcut
in the case of zero. Intel did not release any details on the
cause of these timing effects when asked.
7.2.2 AMD Phenom II X2 550
Figure 13 summarizes our results on the AMD Phenom
II X2 550. As with the Intel i5-4460 we observe timing
variation in the AMD Phenom II X2 550. However, the
variation is now conﬁned to addition and subtraction with
subnormal values. By examining the cycle times for each
operation in the default and libdrag case we found
that the total cycle time for an escorted add or subtract is
approximately equal to the sum of the cycle counts for a
subnormal,subnormal operation and the test case. Thus,
we believe that the AMD Phenom II X2 550 is perform-
ing each operation sequentially and with the same hard-
ware or microcode as scalar operations for addition and
subtraction.
7.3 Escort compiled toy programs
For end-to-end tests we wrote toy programs that perform
a speciﬁed ﬂoating point operation an arbitrary number
of times, and compiled them under Escort and gcc. We
then use the Linux time utility to measure runtimes of
the entire program. We designed the test setup such that
each run of the test program performed the same value
parsing and setup steps regardless of the test values, with
only the values entering the computation differing be-
tween runs. We ran the target computation 160,000,000
times per execution, and ran each test 10 times. We see
the same effects as in our microbenchmarks. Figure 15
shows the crosstable for these results. Note that cells are
colorized if they differ by 2% rather than 1 cycle.
7.4 libdrag modiﬁed Firefox
We modiﬁed a build of Firefox 25 in consultation
with Rane et al [15] to match the version they tested.
Since multiply no longer shows any timing variation
in libdrag we are restricted to observing a potential
≤ 2% difference in only the divide, which occurs once
per pixel regardless of the kernel. Additionally, since the
denominator is the portion controlled by the attacker and
the secret value is the numerator, we are not able to up-
date the pixel stealing attack for the modiﬁed Firefox 25.
The modiﬁcations to Firefox 25 were conﬁned to hand
made changes to the feConvolveMatrix implemen-
tation targeted in [2]. We did not test other SVG ﬁlters
for vulnerability under the Escort/libdrag modiﬁca-
tions.
Given the observed timing variations in the AMD Phe-
nom II X2 550 in section 7.2.2 we believe that multiple
SVG ﬁlters would be timing side channel vulnerable un-
der Escort on that CPU.
7.5 Escort summary
Unfortunately our benchmarks consistently demon-
strated a small but detectable timing difference for
libdrag’s vector operations based on operand values.
For our test Intel CPUs it appears that div and mul
exhibit timing differences under Escort. For our AMD
CPUs we observed variation only for add/sub. Addi-
tionally, these differences are no more than 5% as com-
pared to the 500% or more differences observed in scalar
operations. We have made Rane, Lin and Tiwari aware
of these ﬁndings.
The ’escort’ mechanism can only serve as an effective
defense if vector operations are computed in parallel. In
all CPUs we tested the most likely explanation for the
observed timing difference is that vector operations are
executed serially when in microcode. As mentioned in
section 7.2.1 we know that any vector operation includ-
ing a subnormal argument is executed in microcode, and
all evidence supports the microcode executing vector op-
erations serially. Thus, absent substantial architectural
changes, we do not believe that the ’escort’ vector mech-
anism can close all ﬂoating point data timing channels.
8 GPU ﬂoating point performanace
In this section we discuss the results of GPU ﬂoating
point benchmarks, and the use of GPU acceleration in
SVG ﬁlters for Google Chrome.
8.1 Browser GPU support
All major browsers make use of GPU hardware accel-
eration to improve performance for various applications.
However, only two currently make use of GPUs for SVG
78    26th USENIX Security Symposium
USENIX Association
Dividend
0.0
1.0
1e10
1e+30
Divisor
1e-30
1e-41
1e-42
256
257
0.0
1.0
1e10
1e+30
1e-30
1e-41
1e-42
256
257
5.17
6.19
6.19
6.19
6.19
6.19
6.19
6.19
6.19
5.85
2.59
2.59
2.59
2.59
10.21
10.21
2.59
2.59
5.85
2.59
2.59
2.59
7.82
8.92
8.92
2.59
2.59
5.85
2.59
2.59
2.59
6.51
8.92
8.92
2.59
2.59
Cycle count
5.85
2.59
5.96
5.96
2.59
8.13
8.13
2.59
2.59
5.89
8.64
8.64
8.64
8.40
8.41
8.41
8.64
8.64
5.89
8.64
8.64
8.64
8.40
8.41
8.41
8.64
8.64
5.85
2.59
2.59
2.59
2.59
10.23
10.23
2.59
2.59
5.85
2.59
2.59
2.59
2.59
10.23
10.23
2.59
2.59
Figure 16: Division timing for single precision ﬂoats on Nvidia GeForce GT 430
and CSS transforms; Safari and Chrome. Currently, Sa-
fari only supports a subset of CSS transformations on the
GPU, and none of the SVG transforms. Chrome supports
a subset of the CSS and SVG ﬁlters on the GPU. Firefox
intends to port ﬁlters to the GPU, but there is currently
no support.
8.2 Performance
We performed a series of CUDA benchmarks on an
Nvidia GeForce GT 430 to determine the impact of sub-
normal values on computation time. The results for divi-
sion are shown in ﬁgure 16. All other results (add, sub,
mul) were constant time regardless of the inputs..
As ﬁgure 16 shows, subnormals induce signiﬁcant
slowdowns on divsion operations for single precision
ﬂoats. Unfortunately, no SVG ﬁlters implemented in
Chrome on the GPU perform tight division loops. Thus,
extracting timing differences from the occational divi-
sion they do perform is extremely difﬁcult.
If a ﬁlter were found to perform tight division loops, or
a GPU that has timing variation on non-division opera-
tions were found, the same attacks as in previous sections
could be ported to the GPU accelerated ﬁlters.
We believe that even without a speciﬁc attack, the
demonstration of timing variation based on operand val-
ues in GPUs should invalidate “move to the GPU” as a
defensive strategy.
9 Related work
Felten and Schneider were the ﬁrst to mount timing side-
channel attacks against browsers. They observed that re-
sources already present in the browser’s cache are loaded
faster than ones that must be requested from a server,
and that this can be used by malicious JavaScript to learn
what pages a user has visited [6]. Felten and Schneider’s
history snifﬁng attack was later reﬁned by Zalewski [18].
Because many sites load resources speciﬁc to a user’s ap-
proximate geographic location, cache timing can reveal
the user’s location, as shown by Jia et al. [10].
JavaScript can also ask the browser to make a cross-
origin request and then learn (via callback) how long the
response took to arrive and be processed. Timing chan-
nels can be introduced by the code that runs on the server
to generate the response; by the time it takes the response
to be transmitted over the network, which will depend on
how many bytes it contains; or by the browser code that
attempts to parse the response. These cross-site timing
attacks were introduced by Bortz, Boneh, and Nandy [3],
who showed they could be used to learn the number of
items in a user’s shopping cart. Evans [5] and, later, Gel-
ernter and Herzberg [7], showed they could be used to
conﬁrm the presence of a speciﬁc string in a user’s search
history or webmail mailbox. Van Goethem, Joosen, and
Nikiforakis [17] observed that callbacks introduced to
support HTML5 features allow attackers to time individ-
ual stages in the browser’s response-processing pipeline,
thereby learning response size more reliably than with
previous approaches.
The interaction of new browser features — TypedAr-
rays, which translate JavaScript variable references to
memory accesses more predictably, and nanosecond-
resolution clocks — allow attackers to learn whether spe-
ciﬁc lines have been evicted from the processor’s last-
level cache. Yossi Oren ﬁrst showed that such mi-
croarchitectural timing channels can be mounted from
JavaScript [14], and used them to learn gross system ac-
tivity. Recently, Gras et al. [8] extended Oren’s tech-
niques to learn where pages are mapped in the browser’s
virtual memory, defeating address-space layout random-
ization. In response, browsers rounded down the clocks
provided to JavaScript to 5 µs granularity. Kohlbren-
ner and Shacham [12] proposed a browser architecture
that degrades the clocks available to JavaScript in a more
principled way, drawing on ideas from the “fuzzy time”
mitigation [9] in the VAX VMM Security Kernel [11].
USENIX Association
26th USENIX Security Symposium    79
Browsers allow Web pages to apply SVG ﬁlters to
elements including cross-origin iframes.
If ﬁlter pro-
cessing time varies with the underlying pixel values,
those pixel values will leak. Paul Stone [16] and, in-
dependently, Kotcher et al. [13], showed that such pixel-
stealing attacks are feasible; the ﬁlters they exploited had
pixel-dependent branches. Andrysco et al. [2] showed
that pixel-stealing was feasible even when the ﬁlter exe-
cuted the same instruction trace regardless of pixel val-
ues, provided those instructions exhibit data-dependent
timing behavior, as ﬂoating-point instructions do. Rane,
Lin, and Tiwari [15] proposed program transformation
that allow the processor ﬂoating-point unit to be used
while eliminating data-dependent instruction timing, in
the hope of defeating Andrysco et al.’s attacks.
10 Conclusions and future work
We have extensively benchmarked ﬂoating point perfor-
mance on a range of CPUs under scalar operations, FTZ/-
DAZ FPU ﬂags, -ffast-math compiler options, and
Rane, Lin, and Tiwari’s Escort. We identiﬁed operand-
dependent timing differences on all tested platforms and
in all conﬁgurations; many of the timing differences we
identiﬁed were overlooked in previous work.
In the case of Escort, our data strongly suggests that
processors execute SIMD operations on subnormal val-
ues sequentially, not in parallel. If this is true, a redesign
of the vector processing unit would be required to make
Escort effective at closing all ﬂoating-point timing chan-
nels.
We have revisited browser implementations of SVG
ﬁlters, and found (and responsibly disclosed) exploitable
timing variations in the latest versions of Chrome, Fire-
fox, and Safari.
Finally, we have shown that modern GPUs exhibit
slowdowns in processing subnormal values, meaning
that the problem extends beyond x86 processors. We
are currently evaluating whether these slowdowns al-
low pixel stealing using SVG ﬁlters implemented on the
GPU.
We have uncovered enough variation in timing across
Intel and AMD microarchitectural revisions that we be-
lieve that comprehensive measurement on many differ-
ent processor families — in particular, ARM — will be
valuable. For the speciﬁc processors we studied, we be-
lieve we are in a position to identify speciﬁc ﬂags, spe-
ciﬁc operations, and speciﬁc operand sizes that run in
constant time. Perhaps the best one can hope for is an
architecture-aware library that could ensure no timing
variable ﬂoating point operations occur while preserving
as much of the IEEE-754 standard as possible.
Tools, proof-of-concept attacks, and additional bench-
mark data are available at https://cseweb.ucsd.e
du/~dkohlbre/floats.
We close with broader lessons from our work.
For software developers: We believe that ﬂoating
point operations as implemented by CPUs today are sim-
ply too unpredictable to be used in a timing-security sen-
sitive context. Only defensive measures that completely
remove either SSE ﬂoating point operations (ﬁxed-point
implementations) or remove the sensitive nature of the
computation are completely effective. Software that op-
erates on sensitive, non-integer values should use ﬁxed-
point math, for example by including Andrysco et al.’s
libfixedtimefixedpoint, which Almeida et al.
recently proved runs in constant time [1].
For browser vendors: Some browser vendors have
expended substantial effort in redesigning their SVG ﬁl-
ter code in the wake of the Andrysco et al. attacks. Even
so, we were able to ﬁnd (different) exploitable ﬂoating-
point timing differences in Chrome, Firefox, and Safari.
We believe that the attack surface is simply too large; as
new ﬁlters and features are added additional timing chan-
nels will inevitably open. We recommend that browser
vendors disallow cross-origin SVG ﬁlters and other com-
putation over cross-origin pixel data in the absence of
Cross-Origin Resource Sharing (CORS) authorization.
It is important that browser vendors also consider
patching individual timing side channels in SVG ﬁlters
as they are found. Even with a origin policy that blocks
the cross-origin pixel stealing, any timing side channel
allows an attacking page to run a history snifﬁng at-
tack. Thus, a comprehensive approach to SVG ﬁlters as a
threat to user privacy combines disallowing cross-origin
SVG ﬁlters and removes timing channels with constant
time coding techniques.
For processor vendors: Processor vendors have re-
sisted calls to document which of their instructions run
in constant time regardless of operands, even for opera-
tions as basic as integer multiplication. It is possible that
ﬂoating point instructions are unusual not because they
exhibit timing variation but because their operands have
meaningful algebraic structure, allowing intelligent ex-
ploration of the search space for timing variations; even
so, we identiﬁed timing variations that Andrysco et al.
overlooked. How much code that is conjectured to be
constant-time is in fact unsafe? Processor vendors should
document possible timing variations in at least those in-
structions commonly used in crypto software.
Acknowledgements
We thank Eric Rescorla and Jet Villegas for sharing their
insights about Firefox internals, and Philip Rogers, Joel
Weinberger, and Stephen White for sharing their insights
about Chrome internals.
We thank Eric Rescorla and Stefan Savage for helpful
discussions about this work.
80    26th USENIX Security Symposium
USENIX Association
We thank Ashay Rane for his assistance in obtaining
and testing the Escort compiler and libdrag library.
This material
is based upon work supported by
the National Science Foundation under Grants No.
1228967 and 1514435, and by a gift from Mozilla.
References
[1] J. B. Almeida, M. Barbosa, G. Barthe, F. Dupressoir, and
M. Emmi, “Verifying constant-time implementations,”
in Proceedings of USENIX Security 2016, T. Holz and
S. Savage, Eds. USENIX, Aug. 2016, pp. 53–70.
[2] M. Andrysco, D. Kohlbrenner, K. Mowery, R. Jhala,
S. Lerner, and H. Shacham, “On subnormal ﬂoating
point and abnormal timing,” in Proceedings of IEEE
Security and Privacy (“Oakland”) 2015, L. Bauer and
V. Shmatikov, Eds.
IEEE Computer Society, May 2015.
[3] A. Bortz, D. Boneh, and P. Nandy, “Exposing private in-
formation by timing Web applications,” in Proceedings
of WWW 2007, P. Patel-Schneider and P. Shenoy, Eds.
ACM Press, May 2007, pp. 621–28.
[4] L. De Moura and N. Bjørner, “Z3: An efﬁcient SMT
solver,” in International conference on Tools and Al-
gorithms for the Construction and Analysis of Systems.
Springer, 2008, pp. 337–340.
[5] C. Evans,
“Cross-domain search timing,” Online:
https://scarybeastsecurity.blogspot.com/2009/12/
cross-domain-search-timing.html, Dec. 2009.
[6] E. W. Felten and M. A. Schneider, “Timing attacks on
Web privacy,” in Proceedings of CCS 2000, S. Jajodia,
Ed. ACM Press, Nov. 2000, pp. 25–32.
[7] N. Gelernter and A. Herzberg, “Cross-site search attacks,”
in Proceedings of CCS 2015, C. Kruegel and N. Li, Eds.
ACM Press, Oct. 2015, pp. 1394–1405.
[8] B. Gras, K. Razavi, E. Bosman, H. Bos, and C. Giuffrida,
“ASLR on the line: Practical cache attacks on the MMU,”
in Proceedings of NDSS 2017, A. Juels, Ed.
Internet
Society, Feb. 2017.
[9] W.-M. Hu, “Reducing timing channels with fuzzy time,”
J. Computer Security, vol. 1, no. 3-4, pp. 233–54, 1992.
[10] Y. Jia, X. Dong, Z. Liang, and P. Saxena, “I know where
you’ve been: Geo-inference attacks via the browser
cache,” in Proceedings of W2SP 2014, L. Koved and
M. Fredrikson, Eds.
IEEE Computer Society, May 2014.
[11] P. A. Karger, M. E. Zurko, D. W. Bonin, A. H. Mason,
and C. E. Kahn, “A retrospective on the VAX VMM secu-
rity kernel,” IEEE Trans. Software Engineering, vol. 17,
no. 11, pp. 1147–65, Nov. 1991.
[12] D. Kohlbrenner and H. Shacham, “Trusted browsers for
uncertain times,” in Proceedings of USENIX Security
2016, T. Holz and S. Savage, Eds. USENIX, Aug. 2016,
pp. 463–80.
[13] R. Kotcher, Y. Pei, P. Jumde, and C. Jackson, “Cross-
origin pixel stealing: Timing attacks using CSS ﬁlters,” in
Proceedings of CCS 2013, V. Gligor and M. Yung, Eds.
ACM Press, Nov. 2013, pp. 1055–62.
[14] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D.
Keromytis, “The spy in the sandbox: Practical cache at-
tacks in JavaScript and their implications,” in Proceed-
ings of CCS 2015, C. Kruegel and N. Li, Eds. ACM
Press, Oct. 2015, pp. 1406–18.
[15] A. Rane, C. Lin, and M. Tiwari, “Secure, precise, and fast
ﬂoating-point operations on x86 processors,” in Proceed-
ings of USENIX Security 2016, T. Holz and S. Savage,
Eds. USENIX, Aug. 2016, pp. 71–86.
[16] P.
Stone,
“Pixel
perfect
attacks with
HTML5,” Presented at Black Hat 2013, Jul. 2013,
online:
https://www.contextis.com/documents/2/
Browser_Timing_Attacks.pdf.
timing
[17] T. Van Goethem, W. Joosen, and N. Nikiforakis, “The
clock is still ticking: Timing attacks in the modern web,”
in Proceedings of CCS 2015, C. Kruegel and N. Li, Eds.
ACM Press, Aug. 2015, pp. 1382–93.
[18] M. Zalewski, “Rapid history extraction through non-
destructive cache timing,” Online: http://lcamtuf.cored
ump.cx/cachetime/, Dec. 2011.
Notes
1https://skia.org/
USENIX Association
26th USENIX Security Symposium    81