a
r
u
c
c
A
n
o
i
t
a
c
ﬁ
i
s
s
a
l
C
t
c
e
r
r
o
C
100
80
60
40
20
0
1
2
3
4
5
6
7
8
9
10
n
100 programmers 8 training samples
100 programmers 1 training sample
600 programmers 8 training samples
600 programmers 1 training sample
Fig. 4: Reducing Suspect Set Size:
Top-n Relaxed Classiﬁcation
It is important to note from Figure 3 that, by using only
a single training sample in a 100-class classiﬁcation task, the
machine learning model can correctly classify new samples
with 75.0% accuracy. This is of particular interest to an analyst
or adversary who does not have a large amount of labeled
samples in her suspect set. Figure 3 shows that an analyst or
adversary can narrow down the suspect set size from 100 or
600 to a signiﬁcantly smaller set.
G. The feature set selected via dimensionality reduction
works and is validated across different sets of programmers.
In our earlier experiments, we trained the classiﬁer on the
same set of executable binaries that we used during feature
selection. The high number of starting features from which we
select our ﬁnal feature set via dimensionality reduction does
raise the potential concern of overﬁtting. To examine this, we
applied this ﬁnal feature set to a different set of programmers
and executable binaries. If we reach accuracies similar to what
we got earlier, we can conclude that these selected features do
generalize to other programmers and problems, and therefore
are not overﬁtting to the 100 programmers they were generated
from. This also suggests that the ﬁnal set of features in general
capture programmer style.
Recall that analyzing 900 executable binary samples of
the 100 programmers resulted in about 705,000 features, and
after dimensionality reduction, we are left with 53 important
features. We picked a different (non-overlapping) set of 100
programmers and performed another de-anonymization exper-
iment in which the feature selection step was omitted, using
instead the information gain and correlation based features
obtained from the original experiment. This resulted in very
similar accuracies: we de-anonymized programmers in the
validation set with 96% accuracy by using features selected
via the main development set, compared to the 95% de-
anonymization accuracy we achieve on the programmers of
the main development set. The ability of the ﬁnal reduced
set of 53 features to generalize beyond the dataset which
guided their selection strongly supports the assertion that these
features obtained from the main set of 100 programmers are
not overﬁtting, and they actually represent coding style in
executable binaries, and can be used across different datasets.
H. Large Scale De-anonymization: We can de-anonymize
600 programmers from their executable binaries.
We would like to see how well our method scales up to
600 users. An analyst with a large set of labeled samples might
100
99% 96%
92%
89%
85%
83% 83%
y
c
a
r
u
c
c
A
n
o
i
t
a
c
ﬁ
i
s
s
a
l
C
t
c
e
r
r
o
C
80
60
40
20
0
20
100
200
300
400
500
600
Number of Authors
Fig. 5: Large Scale Programmer De-anonymization
be interested in performing large scale de-anonymization. For
this experiment, we use 600 contestants from GCJ with 9
ﬁles. We only extract the reduced set of features from the
600 users. This decreases the amount of time required for
feature extraction. On the other hand, this experiment shows
how effectively overall programming style is represented after
dimensionality reduction. The results of large scale program-
mer de-anonymization in Figure 5, show that our method can
scale to larger datasets with the reduced set of features with a
surprisingly small drop on accuracy.
I. We advance the state of executable binary authorship
attribution.
Rosenblum et al. presented the largest scale evaluation of
executable binary authorship attribution on 191 programmers
each with at least 8 training samples [39]. We compare our
results with Rosenblum et al.’s in Table II to show how we
advance the state of the art both in accuracy and on larger
datasets. Rosenblum et al. use 1,900 coding style features
to represent coding style whereas we use 53 features, which
might suggest that our features are more powerful in repre-
senting coding style that is preserved in executable binaries.
On the other hand, we use less training samples as opposed
to Rosenblum et al., which makes our experiments more
challenging from a machine learning standpoint. Our accuracy
in authorship attribution is signiﬁcantly higher than Rosenblum
et al.’s, even when we use an SVM as our classiﬁer, showing
that our different approach is more powerful and robust for
de-anonymizing programmers. Rosenblum et al. suggest a
linear SVM is the appropriate classiﬁer for de-anonymizing
programmers but we show that our different set of techniques
and choice of random forests is leading to superior and larger
scale de-anonymization.
Related Work
Rosenblum [39]
This work
This work
Rosenblum [39]
This work
This work
Rosenblum [39]
This work
This work
This work
This work
Number of
Programmers
20
20
20
100
100
100
191
191
191
600
600
Number of
Training Samples
8-16
8
8
8-16
8
8
8-16
8
8
8
8
Accuracy Classiﬁer
SVM
77%
SVM
90%
99%
RF
61% SVM
84% SVM
96%
RF
51% SVM
81% SVM
92%
RF
71% SVM
83%
RF
TABLE II: Comparison to Previous Results
9
J. Programmer style is preserved in executable binaries.
We show throughout the results that it is possible to de-
anonymize programmers from their executable binaries with a
high accuracy. To quantify how stylistic features are preserved
in executable binaries, we calculated the correlation of stylistic
source code features and decompiled code features. We used
the stylistic source code features from previous work on de-
anonymizing programmers from their source code [16]. We
took the most important 150 features in coding style that
consist of AST node average depth, AST node TFIDF, and the
frequencies of AST nodes, AST node bigrams, word unigrams,
and C++ keywords. For each executable binary sample, we
have the corresponding source code sample. We extract 150
information gain features from the original source code. We
extract decompiled source code features from the decompiled
executable binaries. For each executable binary instance, we
set one corresponding information gain feature as the class
to predict and then we calculate the correlation between the
decompiled executable binary features and the class value. A
random forest classiﬁer with 500 trees predicts the class value
of each instance, and then Pearson’s correlation coefﬁcient
is calculated between the predicted and original values. The
correlation has a mean of 0.32 and ranges from -0.12 to 0.69
for the most important 150 features.
To see how well we can reconstruct the original source
code features from decompiled executable binary features,
we reconstructed the 900 instances with 150 features that
represent the highest information gain features by predicting
the original features from decompiled code features. We calcu-
lated the cosine similarity between the original 900 instances
and the reconstructed instances after normalizing the features
to unit distance. The cosine similarity for these instances is
in Figure 6, where a cosine similarity of 1 means the two
feature vectors are identical. The high values (average of 0.81)
in cosine similarity suggest that the reconstructed features
are similar to the original features. When we calculate the
cosine similarity between the feature vectors of the original
source code and the corresponding decompiled code’s feature
vectors (no predictions), the average cosine similarity is 0.35.
In summary, reconstructed features are much more similar to
original code than the raw features extracted from decompiled
code. 5% of the reconstructed features have less than 60%
similarity based on the cosine similarity between original and
decompiled source code features. At the same time, the de-
anonymization accuracy of 900 executable binaries is 95% by
using source code, assembly, CFG, and AST features. This
might indicate that some operations or code sequences cannot
be preserved after compilation followed by decompilation, due
to the nature of transformations during each process.
VI. REAL-WORLD SCENARIOS
A. Programmers of optimized executable binaries can be de-
anonymized.
In Section V, we discussed how we evaluated our approach
on a controlled and clean real-world dataset. Section V shows
how we advance over previous methods that were all evaluated
with clean datasets such as GCJ or homework assignments. In
this section, we investigate a complicated dataset which has
been optimized during compilation, where the executable bi-
nary samples have been normalized further during compilation.
y
t
i
r
a
l
i
m
S
i
e
n
i
s
o
C
1
0.8
0.6
0.4
0.2
0
Original vs. Reconstructed Feature Similarity
Original vs. Decompiled Feature Average Similarity
300
600
900
Reconstructed Feature Vectors
Fig. 6:
Feature Transformations: Each data point on the x-axis
is a different executable binary sample. Each y-axis value is the
cosine similarity between the feature vector extracted from the
original source code and the feature vector that tries to predict the
original features. The average value of these 900 cosine similarity
measurements is 0.81, suggesting that decompiled code preserves
transformed forms of the original source code features well enough
to reconstruct the original source code features.
Compiling with optimization tries to minimize or maxi-
mize some attributes of an executable program. The goal of
optimization is to minimize execution time or the amount of
memory a program occupies. The compiler applies optimizing
transformations which are algorithms that transform a program
to a semantically equivalent program that uses fewer resources.
GCC has predeﬁned optimization levels that turn on sets
of optimization ﬂags. Compilation with optimization level-1,
tries to reduce code size and execution time, takes more time
and much more memory for large functions than compilation