种形态的GPU。先说APU，其正式名称为A10-8700P APU，开发代号叫
CARRIZO，是LIano的后代，发布于2015年，是专门针对笔记本市场的
产品，被视为第一款符合HSA 1.0规范（见10.5节）的SoC。这个APU中
的CPU包含了4个核心，实现的是Excavator微架构。A10-8700P内的GPU
是Radeon R6，包含了6个计算单元（CU），实现的是第三代GCN微架
构。
另一个GPU在独立显卡中，型号为Radeon M340DX，配备的是代号
为HAINAN的GPU，实现的是第二代GCN微架构。
格友评点
10.2 Terascale微架构
2007年5月14日，AMD推出第一款基于R600 GPU的Radeon HD
2900 XT显卡，这是ATI被纳入AMD旗下后的第一款重量级产品，一推
出便备受关注，结果也不负众望。R600的内部设计采用的是第一代
Terascale微架构，本节就以它为例来介绍Terascale微架构。
10.2.1 总体结构
R600包含大约7亿个晶体管，芯片的晶体面积（die size）也比较
大，有420mm2[1]。占据芯片核心位置的是流处理器单元（Stream
Processing Unit）。R600内部包含320个流处理器，分为4组，每一组称
为一个SIMD核心。在图10-1所示的R600 GPU结构框图中，中央像四串
糖葫芦似的部分便是4组流处理器。每一组又细分为8行，以中轴为界，
左右各一小组，每一小组包含5个流处理器，这样一行有10个流处理
器，8行刚好有80个流处理器。值得说明的是，每一小组中5个流处理器
的能力是不一样的，只有一个可以执行特殊函数，因此图10-1中的5个
小矩形故意画得1大4小。
糖葫芦之语妙。
 老雷评点 
作文之法，意之曲折者，宜写之以浅显之词。理之浅显者，宜运之以曲折之笔。
值得说明的是，R600的指令手册把流处理器称为并行数据处理器
（Data-Parallel Processor，DPP），这可能是为了避免与G80使用同样的
术语。
图10-1 R600 GPU结构框图
除了通用的流处理器之外，R600还包含16个纹理单元（Texture
Unit）。这16个纹理单元也分为4组，与4个SIMD核心分别连接，协同
工作。
在R600中，还包含一个可编程的曲面细分器（tessellator）。曲面
细分（tessellation）是当时很新的3D图形技术，其核心思想是让GPU自
动产生三角形，更精细地描述3D物体，以提高3D画面的质量。ATI和
AMD投入很多力量研发和推广这项技术。后来终于被微软采纳，成为
DirectX 11中的最重要技术之一，大放异彩。
10.2.2 SIMD核心
对R600的总体结构有所了解后，我们再深入到每个SIMD核心的内
部。图10-2是SIMD核心的结构框图，来自Mike Houston在2008年
Siggraph大会上的演讲。Mike Houston在斯坦福大学读博时参与了包括
Brook（CUDA源头）在内的多个GPGPU项目，2007年加入AMD，后来
成为AMD的院士。
首先解释一下，图10-1和图10-2的画法不同，对于80个流处理器，
前者竖着画，后者横着画，就像把本来立着的糖葫芦放倒了。图10-2
中，画出了两个SIMD核心，每个包含四个部分，从左到右依次为：负
责调度的线程序列器（Thread Sequencer）、80个流处理器、本地共享
内存和纹理单元。这种结构的设计思想是纹理处理器从内存获取纹理数
据后，首先进行解压缩等预处理，然后再交给流处理器做更多运算。纹
理单元和流处理器可以通过本地共享内存快速通信与交换数据。
图10-2 SIMD核心的结构框图
图10-2这样由流处理器、纹理单元、共享内存和线程调度器组成的
SIMD核心就像是一个多兵种的战斗军团，可以联合起来对并行的数据
进行各种计算。这样的SIMD核心要比Nvidia的CUDA核“大”很多：不但
在晶体管数量上要大，而且在处理能力方面也要大。
10.2.3 VLIW
VLIW 的全拼是Very Long Instruction Word，直译便是非常长的指
令字，是通用芯片领域的一个术语。它用来指代一种指令集体系结构
（ISA）设计风格，表面上是说指令的长度很长，深层的含义是指通过
长指令一次执行一套功能很强大的操作，在指令层次上实现并行操作。
Terascale的指令集是典型的VLIW风格，上面描述的每个SIMD核心
有80个流处理器，每5个流处理器组成一个ALU，每个ALU中的5个流处
理器可以同时执行4或者5条以VLIW格式同时发射（co-issue）的操作
（op）。
因为VLIW指令是在编译期产生的，所以VLIW技术的实际效果是
依赖编译器的，需要编译器在编译时寻找到合适的并行机会。根据
AMD的分析，对于典型的3D游戏应用，大多时候只使用5个中的3或者4
个执行单元。为此，在后来版本的Terascale GPU中，AMD改进了设
计，把5个流处理器缩减为4个。这个变化简称为从VLIW5到VLIW4，
其中，5和4表示流处理器的个数从5个变为4个。较早使用这种GPU设计
的产品是A10-4600M，它属于APU产品。这样改进后，也可以降低GPU
占用的芯片面积，提高单位面积的性能（performance per mm²）。
10.2.4 四类指令
R600的指令分为四个大类：流程控制（contrl-flow，CF）指令、
ALU（算术逻辑单元）指令、纹理获取（texture-fetch）指令和顶点获取
（vertex-fetch）指令。前两种指令的长度均是64位（两个DWORD），
后两种指令的长度均是128位（4个DWORD）。
在R600中，有分句（clause）的概念，每个分句由相同类型的多条
指令组成。除了流程控制指令外，另三种指令都可以组成对应类型的分
句，因此有三种分句，即ALU分句、纹理获取分句和顶点获取分句。
每个R600程序都分两个节（section），前面一节是流程控制指令，
后面一节是子句，ALU子句在前，另两种子句在后。当CPU端的软件启
动R600程序时，会把每种子句的起始地址告诉R600。
流程控制指令又可以细分为如下几种子类型。
用于发起子句的指令。
输入和输出指令，前者用于把数据从各类缓冲区中加载到通用寄存
器（GPR），后者用于把数据从通用寄存器写到各类缓冲区。
与其他功能单元的通信和同步指令，比如EMIT_VERTEX指令指示
有顶点输出（写到缓冲区）。
条件执行指令。
分支和循环指令，除了各种形式的循环语句外，还有CALL和RET
这样的调用子过程的指令。
纵观R600的硬件结构和软件指令，可以看出它的很多设计都带着
3D烙印，有些概念直接来自DirectX这样的3D模型。所以，R600很适合
执行顶点、像素、几何变换等图形任务，满足了当时GPU的主要用途。
然而，从通用计算的角度看，它虽然比之前的固定硬件单元前进了一大
步，但无论硬件结构还是软件模型都不够通用，与G80的差距很大，有
待GCN微架构继续完成历史使命。
10.3 GCN微架构
2011年8月，在HPG11（High-Performance Graphics）大会上，AMD
的两位院士架构师Michael Mantor和Mike Houston一起介绍了新一代的
GPU微架构[2]，名字就叫“下一代图形核心”（Graphics Core Next，
GCN）。
从此，AMD大约以每年更新一次的速度向前推进GCN微架构，已
经发展了6代，其代号分别为Southern Islands（2011年）、Sea
Islands（2013年）、Volcanic Islands（2014年，GCN3）、Arctic
Islands（2016年）、Vega（2017年，GCN5）和Navi（计划2019年发
布）。
10.3.1 逻辑结构
与Terascale相比，GCN的首要目标是增加通用计算能力，不仅要很
好地支持传统的图形应用，还要支持新兴的通用计算（GPGPU）应
用。因此，GCN的改进重点是内部的通用计算单元。图10-3是来自Vega
ISA 手册的GCN5微架构逻辑框图。很容易看出，中间偏右的数据并行
处理器（Data-Parallel Processor，DPP）部分变化很大，DPP阵列外围的
部分变化不大。
虽然图10-3是逻辑图，省略了很多部件，但GCN的主要变化确实是
在DPP阵列上。为了提高通用计算能力，GCN对Terascale的SIMD核心
做了大刀阔斧的革新，并给新的核心取了一个新名字，称为计算单元
（Compute Unit），以突出其通用计算特征。
图10-3中，分四行画出了4个CU，但有省略符号表示可能有更多
CU。在每一个CU中，画了一组标量ALU（标量算术逻辑单元，
sALU）和标量寄存器（sGPR），还有四组向量ALU（向量算术逻辑单
元，vALU）和向量寄存器（vGPR）。
图10-3 GCN5微架构的逻辑框图
10.3.2 CU和波阵
下面介绍每个CU的内部结构。与SIMD核心的结构（见图10-2）相
比，CU的结构（见图10-4）变化很大。首先，每个CU包含了4个SIMD
单元，每个SIMD单元包含一个16路的向量算术逻辑单元（vALU）。除
了向量单元外，每个CU中还有1个标量单元，它包含一个整数类型的算
术逻辑单元（sALU）。sALU负责执行标量指令和流程控制指令，继承
了Terascale微架构中把流程控制逻辑独立出来的特征。概括一下，在每
个CU内部，有64个vALU，1个sALU。每个SIMD单元有64KB的寄存
器，称为vGPR。sALU有8KB的寄存器，称为sGPR。
图10-4中，左侧大约三分之一的部分称为CU前端（CU front-
end），它负责获取、解码和发射指令。为了提高vALU的利用率，每个
SIMD单元有自己的程序计数器和指令缓冲区，即图10-4中左侧4个标有
PC & IB的部分，PC和IB分别是程序计数器和指令缓冲区的缩写。每个
指令缓冲区可以容纳10个波阵（wavefront，有时简称为wave），4个指
令缓冲区共计容纳40个波阵。
图10-4 GCN微架构的CU
波阵是AMD定义的术语，相当于CUDA中的WARP，但容量大一
倍，可容纳64个线程。二者都是GPU调度线程和组织计算资源的基本单
位。从软件的角度来看，每个算核函数在多个并行的线程中同时执行，
每个线程处理自己的数据。对于硬件，一个一个地调度线程效率太低
了，解决方法是成批地调度和执行，批次多大呢？Nvidia选择了32个作
为一批，取名为Warp；AMD选择了64个作为一批，取名为波阵。
严格来讲，Warp和波阵是用来描述线程的，但是有时也用它们来
描述用以容纳调度和执行成批线程的硬件设施。比如在图10-4中，每个
PC & IB矩形中都标有10个波阵。其含义是每个指令缓冲区可以容纳 10
个波阵。指令缓冲单元不仅可以做取指和解码等准备工作，还可以执行
某些特殊指令，比如空指令（S_NOP）、同步指令（S_BARRIER）、
暂停指令（S_SETHALT）等。
可以把指令缓冲区看作一张大嘴，有了这张大嘴后，CU的吞吐能
力大大增加，可以一次吞入64×10×4 = 2560个线程。像巨蟒一样先把巨
大的食物吞到嘴里，再慢慢压进体内并消化。
按此计算，对于拥有32个CU的Radeon HD 7970显卡，同时可以运
行的线程数高达81 920个。不过，这样的线程与英特尔CPU的超线程概
念类似，虽然逻辑上有那么多个线程在解码和执行，但是它们共享后端
执行单元，实际执行速度肯定是要打折扣的。
对于每个CU，2560个逻辑线程共享内部的硬件资源。粗略计算，
内部的执行单元有不到100个（包括纹理单元），所以逻辑线程和执行
单元的比例是很悬殊的。从技术上讲，这样设计是为了提高后端执行单
元的利用率；从商业上讲，它便于产品宣传。
有趣的是，在市场宣传方面，AMD很少提及成千上万的逻辑线程
数。相反，还经常使用把每个计算单元称为一个核的方法。比如前面提
到过的Thinkpad笔记本电脑的键盘下面贴着三个徽标：AMD A10、10
Compute Cores 4 CPU + 6 GPU、RADEON dual Graphics。其中的“6
GPU”是指A10的GPU中包含6个CU核心。使用GPU-Z观察，会看到有
384个统一渲染器（Unified Shader），这与上面介绍的每个CU有64个
vALU是一致的。
10.3.3 内存层次结构
使用GPU做通用计算的典型场景是对大量的数据进行并行处理。在
计算时，需要让数量众多的计算单元可以快速访问到要计算的数据。为
此，GCN内部设计了多种类型和层次的缓存。图10-5是来自Vega指令手
册的GCN内存层次结构图，可以看到针对每个内存通道都有二级读写缓
存。在每个CU内部，设有针对纹理数据的一级读写缓存。
图10-5 GCN内存层次结构图
高速缓存可以加快GPU内部单元访问外部数据的速度。另一方面，
为了加快GPU内部各个计算单元之间的数据通信，GCN内部还配备了全
局数据存储器（Global Data Store，GDS），用于跨CU的数据交换。在
每个CU内部，配备了局部数据存储器（Local Data Store，LDS），供算
核函数中带有共享属性的变量使用，让CU内部的所有计算单元可以快
速同步数据。
10.3.4 工作组
在GCN中，多个波阵（wavefront）可以组成一个工作组
（workgroup，WP），要确保同一个工作组的波阵在同一个CU上运
行，以便于同步和共享数据。每个工作组最多包含16个波阵，也就是
16×64 = 1024个工作项（work-item）。对于同一个工作组中的多个波
阵，可以用S_BARRIER指令来同步多个波阵，当一个波阵先执行到这
条指令时，会等待其他波阵也执行到这条指令时再继续执行。图10-6形
象地描述了组织计算任务的多个单位的关系。该图来自HSA联盟（见
10.5节）发布的编程手册[3]。
图10-6 描述计算任务的多个单位
下面通过一个实例来理解工作组和GCN调度线程的基本方法。清单
10-1是通过ROCm-GDB调试器（见10.13节）观察到的某个工作组的状
态。
清单10-1 工作组状态