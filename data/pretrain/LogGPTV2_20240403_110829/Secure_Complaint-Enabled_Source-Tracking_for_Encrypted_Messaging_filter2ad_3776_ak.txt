openings of 𝐶𝐴 and 𝐶′
𝐹 are encrypted with the message plain-
text in 𝑒, and so the receive function will always fail when
the receiver checks the openings against the commitments
that the platform provides.
G2: Consider the contents of the platform data (𝐶𝐴, 𝑠𝑟𝑐, 𝐶′
We have ensured that the platform must act honestly and pass
the correct information between protocols. We now show that it
cannot act dishonestly during either of the interactive protocols
getUser or RecMsg.
G3: We modify G2 to immediately abort if the platform gives the
user an invalid MAC for the expected attributes in goodRec,
malSend, or getUser.
By the blind issuance properties of the MAC (with no hidden
attributes in the case of NewUser), the adversary can achieve
this and still create a correct issuance proof with only negli-
gible probability, and so this game is indistinguishable from
Game 2.
We’ve now ensured that the platform interacts with the user
according to the expected protocol.
G4: We modify Game 3 so that each 𝑒 sent between honest users
is just an encryption of a default value of all zeroes, and the
oracle passes the actual information between the two users.
Since the adversary has non of the secrete keys for these
interactions, this game is indistinguishable from Game 3 by
the authenticated encryption properties of E.
G5: We modify G4 so that during calls to goodSend and goodRec
on an unrevealable message, i.e. one with 𝑡𝑖𝑑 set to ⊥, we
replace the receiving proof output by redeem and the re-
randomization proof 𝜋𝑟 output by present with the outputs
of the zero-knowledge simulator for the proofs. By the zero-
knowledge properties of the proof system, this is indistin-
guishable from a real proof, and so the game is indistinguish-
able from G4.
G6: We alter each call to goodSend with 𝑡𝑖𝑑 = ⊥ to use the
authoring data for the currently sending user as the MAC
that gets presented to the platform when the message is sent
rather than the correct forwarding data for the message (if it
is a forward). The commitments 𝐶𝐴 and 𝐶′
𝐹 still commit to
the same values that would have been used in the standard
game. By the anonymity of the MAC, the platform cannot
distinguish between a presentation of the authoring data and
the forwarding data, because both are valid MACs. Therefore
this game is indistinguishable from G5.
G7: We modify the ciphertexts (𝐴1, 𝐴2), (𝐵1, 𝐵2), (𝐶1, 𝐶2) to just
be encryptions of the default values⊥, 𝐺⊥, 𝐺⊥ when goodRec
is called on a message with 𝑡𝑖𝑑 = ⊥. By the blind-issuance
property of the keyed-verification anonymous credentials
scheme [5], this is indistinguishable to the platform from
issuing a MAC on the expected values.
𝐹 in calls to goodSend with 𝑡𝑖𝑑 =
⊥ so that they commit to the default message ⊥ and default
source 𝐺⊥, 𝐺⊥. By the hiding properties of the commitment,
this is indistinguishable from commitments for the actual
message and source values.
G8: Finally, we change 𝐶𝐴 and 𝐶′
We now note that applying the same hybrids described in Games
1-8 starting from the 𝑃𝐶𝑂𝑁 𝐹 game where 𝑏 = 1 instead of 0 are
each indistinguishable by the same arguments, and result in a game
identically distributed to Game 8, because all message interactions
with 𝑡𝑖𝑑 ≠ ⊥ are identically distributed in both games by definition,
and we have altered the 𝑡𝑖𝑑 = ⊥ case to use the same authoring
data, commit to the same attributes, and receive a MAC on the
same values. Therefore we have shown that both 𝑃𝐶𝑂𝑁 𝐹 1
𝑆𝑇 ,E and
𝑃𝐶𝑂𝑁 𝐹 0
𝑆𝑇 ,E are indistinguishable from Game 8 to an efficient ad-
versary, and so they are also indistinguishable from each other.
This means an efficient adversary can gain at most negligible
advantage in the PCONF game, and so Scheme 2 satisfies platform
confidentiality.
□
C.2 Accountability – Proof of Theorem 5.2
Intuitively, because the receiver of a message has complete control
over what commitments and attributes it receives a MAC on, our
scheme satisfies perfect accountability.
Proof. As a reminder, the 𝑠𝑟𝑐𝐵𝐼 𝑁 𝐷 game challenges an adver-
sary with the ability to send messages with content of their choice
between any two users and completely control some set of malicious
users to create a message and associated content that is successfully
received by an honest user, but then cannot be reported.
The tree-unlinkable scheme’s definition of Report provides five
opportunities for failure. We list these in order of occurrence:
(1) The platform’s call to blindVf fails to verify the validity of 𝜋𝑝,
the proof that the reporter has a valid MAC for the message
that they are reporting.
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1503(2) The platform’s call to Vf fails to verify the validity of 𝜋𝑟 ,
the proof that the commitments provided by the reporter
contain correct re-randomizations of the original credentials.
𝑦2𝐸2).
In other words, the opening 𝑜 𝑓 is not a valid opening for the
commitment 𝐶′
(3) The first equality check fails (𝐶′
𝑓 ≠ (𝐺𝑧
𝑦1𝐸1, 𝐺𝑧
𝑦3𝐺𝑑
𝑑
, 𝐺𝑧
.
(4) The second equality check fails (𝑑 ≠ 𝑑′).
(5) The third and final equality check fails (𝑑 = ⊥).
We’ll show that assuming the platform and reporter honestly
received the message being reported, each of these failures can
happen with zero probability.
𝑓
𝜋𝑝 fails to verify. Because the platform and user honestly fol-
lowed the receipt protocol, a successful receipt guarantees that the
reporter has a valid MAC on the attributes being reported. If a user
was unable to create a valid presentation proof for this MAC, it
would contradict the correctness of the MAC presentation of [5].
We conclude that this failure happens with zero probability.
𝜋𝑟 fails to verify. All of the relationships proved in 𝜋𝑟 are con-
structed by the user during the present protocol. Because the user
is honest and follows the protocol, they ensure that all of these
relationships are valid, and so an incorrect proof would violate the
completeness of the proof scheme, so this failure also happens with
zero probability.
The opening to the commitment 𝐶′
𝑓 is invalid. By definition of
the scheme, the reporting user must have received a valid opening
(𝑧𝐹 , 𝑑, 𝐸1, 𝐸2) for 𝐶𝐹 , meaning that
𝐶𝐹 = (𝐶𝑑, 𝐶𝐸1, 𝐶𝐸2) = (𝐺𝑧𝐹
𝑦1 𝐸1, 𝐺𝑧𝐹
𝑦2𝐸2).
𝑑 , 𝐺𝑧𝐹
𝑦3𝐺𝑑
When the honest reporter follows the present protocol, 𝐶′
𝐹 and
𝑜𝐹 are computed as
𝐶′
𝑦3, 𝐶𝐸1𝐺𝑧′
𝐹 = (𝐶𝑑𝐺𝑧′
𝑑 𝐺𝑧′
= (𝐺𝑧𝐹
𝑦3, 𝐺𝑧𝐹
𝑦3𝐺𝑑
= (𝐺𝑧𝐹+𝑧′
𝑑 , 𝐺𝑧𝐹+𝑧′
𝑦3 𝐺𝑑
𝑦1
𝑦2𝑌 𝑟𝑛𝑑)
𝑦1𝐺𝑟𝑛𝑑, 𝐶𝐸2𝐺𝑧′
𝑦1 𝐸1𝐺𝑧′
𝑦1𝐺𝑟𝑛𝑑, 𝐺𝑧𝐹
𝐸1𝐺𝑟𝑛𝑑, 𝐺𝑧𝐹+𝑧′
𝑦2𝐸2𝐺𝑧′
𝑦2𝑌 𝑟𝑛𝑑)
𝐸2𝑌 𝑟𝑛𝑑)
𝑦2
and 𝑜𝐹 = (𝑧𝐹 + 𝑧′, 𝑑, (𝐸1𝐺𝑟𝑛𝑑, 𝐸2𝑌 𝑟𝑛𝑑)), so 𝑜𝐹 is guaranteed to be
the correct opening for 𝐶′
𝐹 , so this check fails with zero probability
because the reporter honestly follows the protocol and successfully
received the original commitment.
𝑑 ≠ 𝑑′. This condition only occurs if the reporter presents a cre-
dential for a message other than the one being reported. This will
never happen because the reporter is honest.
𝑑 = ⊥. During a message receipt, the user checks that the message
being received is not equal to ⊥, and aborts otherwise, so this will
never happen because the message being reported was successfully
received.
In conclusion, we’ve shown that assuming a message was re-
ceived successfully by an honest user, a report of that message can
fail with zero probability, so the scheme satisfies perfect account-
ability.
□
C.3 Unforgeability – Proof of Theorem 5.2
Proof. The unforgeability of our scheme will depend on the
extractability of the proofs used. Note that the blind issuance prop-
erties and unforgeability of the anonymous credentials used in [5]
assume that the system used for proofs of knowledge satisfies a
strong extractability property, in particular, that we can extract
the opening (𝑧, 𝑑, 𝐸1, 𝐸2) of the commitments 𝐶𝑑, 𝐶𝐸1, 𝐶𝐸2 used
in the MAC presentation proof 𝜋𝑝𝑟𝑒𝑠𝑒𝑛𝑡, which can be used to
re-compute the attributes of the MAC being presented. Since we
use their scheme, whose security relies on the random oracle and
generic group models, we inherit their use of these models in our
scheme. Other possibilities for instantiating such a proof system
are discussed in Appendix D of [4].
The proof is a bit long, so we will first lay out the high-level
intuition. Suppose an adversary wins the game and presents a report
to the platform on an (𝑚, 𝑈 , md) tuple that was never actually sent
by the honest user 𝑈 .
We have two possibilities. On one hand, the adversary could have
achieved this by acting dishonestly during the last report interaction
in order to report a message that it didn’t actually have forwarding
credentials for. On the other hand, the adversary may have correctly
followed the standard report protocol, but was able to succeed
because it had valid credentials that were created dishonestly earlier
in the game.
In this second case, we can then look at the point in time when
the adversary received these credentials earlier in the game. Once
again, these could have been obtained by the adversary acting
dishonestly to create credentials that it didn’t actually have, or this
receipt could have been performed honestly because the necessary
credentials were created earlier in the game.
In this way, we can trace back through the adversary’s interac-
tions with the oracle to identify the first interaction that resulted
in a set of forwarding credentials with an honest source user that
didn’t originate from a call to goodAuth.
We consider all the places where this could have happened, and
then in the actual proof, remove these opportunities in a series of
game hops:
(1) While the adversary was sending a message.
If the incorrect credentials are created when an adversary is
sending a message (i.e., during a call to malSend), this could
happen because either the adversary is able to prove owner-
ship of a MAC that was never created by the platform (ad-
dressed in G1 in the proof below), fake a proof that the new
commitments stored in 𝐶′
𝐹 are correct re-randomizations of
the original attributes (G3), or find an alternate opening of
the commitments it used to prove the validity of its forward-
ing credentials, 𝐶𝐹 and 𝐶′
If the incorrect credentials are created when an adversary re-
ceives a message, this means that either the adversary found
alternate openings to the commitments of the attributes it
can receive credentials from, 𝐶𝐹 and 𝐶𝐴 (Games G4 and G5,
respectively), it faked a proof that the attribute ciphertexts
were a valid re-randomization of 𝐶𝐴 or 𝐶𝐹 (G2), or it received
a valid MAC on different values by acting dishonestly during
the blind issuance protocol for the MAC (G1).
𝐹 (G4).
(2) While the adversary was receiving a message.
Session 5C: Messaging and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1504(3) While the adversary was reporting the message.
A valid report follows the same approach as a send, so it has
the same opportunities for dishonest action, which we cover
above.
(4) While the adversary was creating a new adversary-controlled
user.
The last potential place where incorrect credentials could
have been created is during a call to getUser. However, the
newUser function is non-interactive, so the adversary cannot