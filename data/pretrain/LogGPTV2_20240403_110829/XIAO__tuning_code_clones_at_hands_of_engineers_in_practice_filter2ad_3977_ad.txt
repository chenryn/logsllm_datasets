4.  VISUALIZATION AND REPORTING  
As  important  and  integral  components  of  XIAO,  the  clone 
visualization  and  reporting  mechanism  provides  a  rich  and 
interactive user experience for engineers to efficiently review the 
clone-analysis results and take corresponding actions. 
Clone reporting. We design a simple heuristic to define the level 
of difference between cloned snippets. In particular, it first filters 
out  all  those  exactly  the  same  cloned  snippets,  since  cloned 
snippets with slightly different logics would be more bug-prone. 
We use a metric (called bug likelihood) to rank clones to prioritize 
the  review  of  clones  to  identify  bugs.  We  also  design  a  simple 
heuristic to measure in what extent the cloned snippets are similar 
to each other and how easily they can be refactored (e.g., the exact 
same copies could be easier to be refactored than others). We call 
this metric as refactoring likelihood. To facilitate users to act on 
the reported clones, we have developed XIAO’s Clone Explorer, a 
component of clone reporting and exploration shown in Figure 4. 
It  organizes  clone  statistics  based  on  the  directory  hierarchy  of 
source files in order to enable quick and easy review at different 
source levels (Figure 4(cid:6917)). A drop-down list ((cid:6918)) is provided to 
allow pivoting the clone-analysis results around the bug likelihood 
((cid:6919)),  refactoring  likelihood,  and  clone  scope.  Clone  scope 
indicates whether cloned snippets are detected inside a file, cross-
file, or cross-folder. For a selected folder in the left pane, the right 
pane  ((cid:6920))  displays  the  list  of  clone  functions  (those  including 
cloned snippets), which could be sorted based on bug likelihood 
or  refactoring  likelihood  ((cid:6922)).  Filters  ((cid:6921))  on  the  clone  scope, 
bug  likelihood,  or  refactoring  likelihood  are  provided  to  enable 
easy selection of clones of interest. 
Clone  visualization.  Figure  5  shows  how  the  Clone-Visualizer 
component  visualizes  the  clone  pair  illustrated  in  Figure  1.  The 
key  to  clone  visualization  is  to  clearly  show  the  matched 
statement blocks and the block types. We categorize the matched 
blocks into the following types: exactly same (i.e., there are only 
possible formatting differences), similar-logic block (i.e., there are 
identifier  substitutions  between  the  two  blocks),  different  logic 
(i.e., the statements in the two blocks are not of the similar-logic 
type but are still similar), and extra logic (i.e., the statements of a 
block show up in one copy of the clone pair, but not in the other 
copy). In this way, users can quickly determine whether there is 
any  difference  between  the  two  cloned  snippets,  what  kind  of 
difference  it  is,  and  how  much  difference  there  is.  Blocks  are 
numbered for correspondence display (Figure 5 (cid:6917)), and different 
colorings are used to indicate different block types ((cid:6918)). The left 
and  right  source  panes  are  synchronized,  and navigation buttons 
are provided to navigate through source code by matched blocks 
instead of statements in order to improve review efficiency ((cid:6919)). 
Users can take an immediate action of filing a bug once a clone is 
confirmed to be a bug or a refactoring target ((cid:6921)), or copying the 
code out for more investigation ((cid:6920)). 
373
1
2
3
4
5
6
1. Clone navigation based on source tree hierarchy
2. Pivoting of folder level statistics
3. Folder level statistics
4. Clone function list in selected folder
5. Clone function filters
6. Sorting by bug or refactoring likelihood
7. Tagging
7
Immune
Bug
Refact
Refact
Figure 4. UI of Clone Explorer 
1
3
5
4
1. Block correspondence
2. Block types
3. Block navigation
4. Copying
5. Bug filing
Figure 5. Visualizing differences of a clone pair 
2
Tagging.  One  important  requirement  of  XIAO  is  to  help 
coordinate  joint  efforts  of  reviewing  code  clones  from  multiple 
engineers. We have designed a tagging mechanism for engineers 
to  easily  work  together.  One  clone  already  reviewed  by  an 
engineer  can  be  tagged  as  “immune”2,  “bug”,  or  “refactoring”. 
Then  the  other  reviewing  engineers  could  choose  to  easily  skip 
these  already  reviewed  clones.  Note  that  these  tags  need  to  be 
tracked  as  done  in  XIAO  when  a  new  version  of  codebase  is 
analyzed. Overall, a tagging mechanism (Figure 4 (cid:6923)) serves two 
main purposes. First, users can tag some  clones as “immune” at 
various  occasions.  For  example,  some  detected  clones  do  not 
include buggy code or become refactoring targets. Second, we can 
implicitly collect user feedback and evaluation results in order to 
keep improving our clone-analysis algorithms. 
5.  EMPIRICAL STUDIES 
In this section, we present the empirical results of applying XIAO 
on  commercial  codebases.  In  our  studies,  we  used  seven 
commercial  codebases  at  Microsoft.  In  the  seven  commercial 
2 An immune clone is one of no particular interest to engineers. 
codebases, six are in C/C++ and one is in C#; the numbers of lines 
of code vary between 1.9 million and 12 millions. 
The  environment  for  running  XIAO  was  a  workstation  running 
Windows 7  64 bits with  two  Intel  Xeon 2.0GHz processors  and 
12GB  memory.  We  relied  on  human  inspection  to  classify 
whether a detected clone is a real clone.   
5.1  Clone-Detection Effectiveness  
Figure  6  shows  the  distribution  of  the  types  of  code  clones 
detected by XIAO across the seven commercial codebases, when 
using the default settings: MinS = 10, α = 0.6, γ = 0.8. The figure 
shows  that  the  near-miss  clone  pairs  detected  by  XIAO  are  a 
significant portion of all the clone pairs, ranging from 63% to 93% 
for the commercial codebases.  
On  each  of  two  commercial  codebases  (out  of  the  seven)  at 
Microsoft,  one  of  its  Microsoft  engineers  (i.e.,  those  who 
developed  the  codebase  and  are  familiar  with  the  codebase) 
helped  evaluate  some  clone-analysis  results  generated  by  XIAO 
on  the  codebase.  We  named  these  two  engineers  as  Engineers  I 
and II. 
374
150%
100%
50%
0%
C1
C2
C3
C4
C5
C6
C7
Type III
Type II
Type I
Figure  6.  Distribution  of  clone  types  of  seven  commercial 
codebases (all in C/C++ except C1 in C#) detected by XIAO 
Engineer I reviewed 69 clone groups (each of which includes a set 
of  similar  clone  pairs)  with  184  functions  in  total.  All  reviewed 
// 14 identical statements omitted here  
::SendMessage(hwndCombo, CB_LIMITTEXT, GetMaxCharacters(), 
0); 
int iFlags = 0; 
if (!GetIsIMEAvailable()) 
iFlags |= SES_NOIME; 
if (iFlags) 
::SendMessage(hwndCombo, EM_SETEDITSTYLE, iFlags, iFlags); 
// 5 identical statements omitted here  
::SendMessage(hwndCombo, EM_SETCOMBOBOXSTYLE,  
SCB_NOAUTOCOMPLETEONSIZE, SCB_NOAUTOCOMPLETEONSIZE); 
// 2 identical statements omitted here  
Figure 7. A confirmed bug: extra statements for bug fixing 
were added (with the gray background) to one function but 
not to its cloned one. 
functions  are  of  non-zero  bug 
likelihood  and  refactoring 
likelihood.  Using  the  tagging  functionality  of  XIAO,  Engineer  I 
tagged 7 (10%) clone groups as potential bugs and 16 (23%) clone 
groups  as  refactoring  targets.  All  together  there  were  23  (33%) 
clone  groups  that  were  identified  as  actionable  (i.e.,  either 
potential bugs or refactoring targets). 
Engineer II evaluated a small set of  clones found by XIAO in a 
system component that consists of high-quality source code. The 
source code of this component has been stable with few changes 
for  a  number  of  years.  We  did  not  expect  to  find  clone-related 
bugs  in  this  case.  Instead,  we  were  interested  in  looking  for 
refactoring  targets  in  high-quality  code.  Engineer  II  reviewed  a 
total  of  39  clone  groups  with  102  functions.    The  numbers  of 
clones in these clone groups vary  from 2 to 7, except one clone 
group,  which  contains  20  clones.  All  these  20  clones  deal  with 
Windows  Event  operations  and  they  have  slight  differences  in 
code  logic.  Including  this  clone  group,  Engineer  II  tagged  8 
(16.3%) clone groups with 46 functions as refactoring targets. 
5.2  Runtime Cost and Scalability 
The  running  time  of  XIAO  against  a  large  codebase  (with  the 
default environment) varies depending on the used settings: from 
6 minutes (MinS = 20, α = 1, γ = 1) to 23 minutes (MinS = 10, α = 
0.4, γ = 0.8). Basically, increasing γ tends to linearly decrease the 
spent time; increasing MinS decreases the spent time; increasing α 
does  not  change  the  spent  time.  This  behavior  can  be  easily 
explained: increasing the value of γ leads to a smaller number of 
clone-candidate  functions  in  the  coarse-matching  step,  thus 
decreasing  the  time  spent  in  each  of  the  successive  steps; 
increasing  MinS  leads  to  a  smaller  number  of  snippets  to  be 
checked; α is used in the pruning step, which is the last step, and 
375
affects only the number of obtained clones but does not affect the 
spent time. 
Instead  of  using  the  default  environment,  we  evaluated  the 
scalability  of  our  XIAO  system  using  an  HPC  cluster  with  one 
master  node  and  four  computing  nodes  (a  high-performance 
computing environment that XIAO leverages to deal with a huge 
number of lines of code). The master node has four AMD Opteron 
880 Dual-core 2.4GHz CPUs and 32GB memory. Each of the four 
computing  nodes  has  two  Intel  E5335  Dual-core  2.0GHz  CPUs 
and  8GB  memory.  Both  the  master  and  computing  nodes  are 
running on Windows Server 2008 HPC Edition. 
Online  clone  search.  We  indexed  a  commercial  codebase  with 
about  130  million  lines  of  code  to  evaluate  the  scalability  of 
XIAO’s online clone-search engine. Code snippets with  three or 
more statements are accepted as valid input for clone search. The 
preprocessing  (including  source-code  parsing,  tokenization,  and 
indexing)  was  conducted  on  one  computing  node  and  it  took  3 
hours  and  42  minutes  to  finish.  Source  code  is  divided  into 
partitions  each  with  5MB  storage  size  and  these  partitions  are 
evenly distributed on the four computing nodes. Then 16 instances 