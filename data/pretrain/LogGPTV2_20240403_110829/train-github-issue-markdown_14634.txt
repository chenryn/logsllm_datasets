## üêõ Bug
I'm using rtx 3090 to create a simple float32 tensor in cuda. It's very weird
it would take too much time after importing huggingface transformers library.
However the same code below doesn't have any issues in 20-series cards.
## To Reproduce
The following code would reproduce the behavior:
    import torch
    import time
    import transformers
    if __name__ == '__main__':
        t = time.time()
        x = torch.zeros((50273,), dtype=torch.float32).cuda()
        print('took:', time.time() - t)
        print('done')
result:
    took: 137.26064133644104
    done
I think the size doesn't matter, any size could reproduce this result in 3090
cards. I don't have rtx 3080, therefore don't know if the issue would exist in
3080 card.
## Expected behavior
Here is the result after commenting the `import transformers`:
    took: 0.8175389766693115
    done
## Environment
The pytorch is built from the master branch of pytorch github. The transformer
library is 3.3.1.
    Collecting environment information...
    PyTorch version: 1.7.0a0+9d5607f
    Is debug build: True
    CUDA used to build PyTorch: 11.1
    ROCM used to build PyTorch: N/A
    OS: Ubuntu 20.04.1 LTS (x86_64)
    GCC version: (Ubuntu 9.3.0-10ubuntu2) 9.3.0
    Clang version: Could not collect
    CMake version: version 3.18.2
    Python version: 3.8 (64-bit runtime)
    Is CUDA available: True
    CUDA runtime version: Could not collect
    GPU models and configuration: GPU 0: GeForce RTX 3090
    Nvidia driver version: 455.23.05
    cuDNN version: Probably one of the following:
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn.so.8
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_train.so.8
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8
    /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_train.so.8
    HIP runtime version: N/A
    MIOpen runtime version: N/A
    Versions of relevant libraries:
    [pip3] numpy==1.19.1
    [pip3] numpydoc==1.1.0
    [pip3] pytorch-pretrained-bert==0.6.2
    [pip3] torch==1.7.0a0
    [conda] blas                      1.0                         mkl  
    [conda] cudatoolkit               10.2.89              hfd86e86_1  
    [conda] mkl                       2020.2                      256  
    [conda] mkl-include               2020.2                      256  
    [conda] mkl-service               2.3.0            py38he904b0f_0  
    [conda] mkl_fft                   1.1.0            py38h23d657b_0  
    [conda] mkl_random                1.1.1            py38h0573a6f_0  
    [conda] numpy                     1.18.5                   pypi_0    pypi
    [conda] numpy-base                1.19.1           py38hfa32c7d_0  
    [conda] numpydoc                  1.1.0                      py_0  
    [conda] pytorch-pretrained-bert   0.6.2                    pypi_0    pypi
    [conda] torch                     1.7.0a0                  pypi_0    pypi
## Additional context
I don't know the issue come from transformer library or pytorch. But since the
same code under same setting works in rtx 2080. I guess there is a higher
chance the problem come from pytorch itself. Thanks for any help.
cc @ngimel @csarofeen @ptrblck