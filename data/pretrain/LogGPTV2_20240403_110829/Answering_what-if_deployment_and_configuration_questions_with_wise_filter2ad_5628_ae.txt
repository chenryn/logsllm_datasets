vice environment using the Emulab testbed [7]. The environment
comprises a host running the Apache Web server as the backend or
BE, a host running the Squid Web proxy server as the frontend or
FE, and a host running a multi-threaded wget Web client that issues
request at an exponentially distributed inter-arrival time of 50 ms.
The setup also includes delay nodes that use dummynet to control
latency.
To emulate realistic conditions, we use a one-day trace from sev-
eral data centers in Google’s CDN that serve users in the USA. We
conﬁgured the resource size distribution on the BE, as well as to
emulate the wide area round-trip time on the delay node based on
this trace.
For each experiment we collect tcpdump data and process it to
extract a feature set similar to one described in Table 1. We do not
speciﬁcally emulate losses or retransmits because these occurred
for fewer than 1% of requests in the USA trace. We have con-
ducted two what-if scenario experiments in this environment; these
are described below.
Experiment 1: Changing the Resource Size: For this experi-
ment, we used just the backend server and the client machine, and
used the delay node to emulate wide area network delays. We ini-
tially collected data using the resource size distribution based on
the real trace for about two hours, and used this dataset as the train-
ing dataset. For the what-if scenario, we replaced all the resources
on the server with resources that are half the size, and collected the
test dataset for another two hours. We evaluated the test case with
WISE using the following speciﬁcation:
USE *
INTERVENE SET FIXED sB/=2
Figure 11(b) presents the response-time distribution for the orig-
inal page size (dashed), the observed response-time distribution
with halved page sizes (dotted), and the response-time distribution
for the what-if scenario predicted with WISE using the original page
size based dataset as input (solid). The maximum CDF distance in
this case is only 4.7%, which occurs around the 40th percentile.
3We could not use the relative error metric here because the re-
quests in the input distribution prepared with WISE for what-if sce-
nario cannot be pair-wise matched with ones in the ground-truth
distribution; maximum distribution difference is a common metric
used in statistical tests, such as Kolmogorov-Smirnov Goodness-
of-Fit Test.
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
F
D
C
0
0
100
200
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
F
D
C
Halved Page Size
Original Page Size
Predicted with WISE
400
300
700
Response Time(ms)
500
600
800
900 1000
0
0
1000
10% Cache Hit Ratio
50% Cache Hit Ratio
Predicted with WISE for 50%
2000
4000
Response Time (ms)
3000
5000
6000
(a) Controlled Experiment Setup
(b) Changing the Page Size
(c) Changing the Cache Hit Ratio
Figure 11: Controlled what-if scenarios on Emulab testbed: experiment setup and results.
Experiment 2: Changing the Cache Hit Ratio: For this exper-
iment, we introduced a host running a Squid proxy server to the
network and conﬁgured the proxy to cache 10% of the resources
uniformly at random. There is a delay node between the client
and the proxy as well as the proxy and the backend server, each
emulates trace driven latency as in the previous experiment. For
the what-if scenario, we conﬁgured the Squid proxy to cache 50%
of the resources uniformly at random. To evaluate this scenario,
we include binary variable b_cached for each entry in the dataset
that indicates whether the request was served by the caching proxy
server or not. We use about 3 hours of trace with 10% caching
as the training dataset, and use WISE to predict the response-time
distribution for the case with 50% caching by using the following
speciﬁcation:
USE *
INTERVENE SETDIST b_cached FILE 50pcdist.txt
The SETDIST directive tells WISE to update the b_cached vari-
able by randomly drawing from the empirical distribution speci-
ﬁed in the ﬁle, which in this case contains 50% 1s and 50% 0s.
Consequently, we intervene 50% of the requests to have a cached
response.
Figure 11(c) shows the response-time distribution for the 10%
cache-hit ratio (dashed), the response-time distribution with 50%
cache-hit ratio (dotted), and the response-time distribution for the
50% caching predicted with WISE using the original 10% cache-
hit ratio based dataset as input (solid). WISE predicts the response
time quite well for up to the 80th percentile, but there is some devi-
ation for the higher percentiles. This occurred because the training
dataset did not contain sufﬁcient data for some of the very large
resources or large network delays. The maximum CDF distance in
this case is 4.9%, which occurs around 79th percentile.
9. DISCUSSION
In this section, we discuss the limitations of and extensions to
WISE. First we discuss what can and what cannot be predicted
with WISE. We also describe issues related to parametric and non-
parametric techniques. Lastly we discuss how the framework can
be extended to other realms in networking.
What Can and Cannot Be Predicted: The class of what-if scenar-
ios that can be evaluated with WISE depends entirely on the dataset
that is available; in particular, WISE has two requirements:
First, WISE requires expressing the what-if scenario in terms of
(1) variables in the dataset and (2) manipulation of those variables.
At times, it is possible for dataset to capture the effect of the vari-
able without capturing the variable itself. In such cases, WISE can-
not evaluate any scenarios that require manipulation of that hidden
variable. For example, the dataset from Google, presented earlier,
does not include the TCP timeout variable even though this vari-
able has an effect on response time. Consequently, WISE cannot
evaluate a scenario that manipulates the TCP timeout.
Second, WISE also requires that the dataset contains values of
variables that are similar to the values that represent the what-if
scenario.
If the global dataset does not have sufﬁcient points in
the space where the manipulated values of the variables lie, the
prediction accuracy is affected, and WISE raises warnings during
scenario evaluation.
WISE also makes stability assumptions, i.e., the causal depen-
dencies remain unchanged under any values of intervention, and
the underlying behavior of the system that determines the response
times does not change. We believe that this assumption is reason-
able as long as the fundamental protocols and methods that are used
in the network do not change.
Parametric vs. Non-Parametric: WISE uses the assumption of
functional dependency among variables to update the values for the
variables during the statistical intervention evaluation process. In
the present implementation, WISE only relies on non-parametric
techniques for estimating this function but nothing in the WISE
framework prevents using parametric functions. If the dependen-
cies among some or all of the variables are parametric or determin-
istic, then we can improve WISE’s utility. Such a situation can in
some cases allow extrapolation to predict variable values outside
of what has been observed in the training dataset.
What-if Scenarios in other Realms of Networking: We believe
that our work on evaluating what-if scenarios can be extended to
incorporate other realms, such as routing, policy decisions, and se-
curity conﬁgurations by augmenting the reasoning systems with a
decision evaluation system, such as WISE.
Our ultimate goal is to evaluate what-if scenarios for high-level
goals, such as, “What if I deploy a new server at location X?”, or
better yet, “How should I conﬁgure my network to achieve certain
goal?”; we believe that WISE is an important step in this direction.
10. RELATED WORK
We are unaware of any technique that uses WISE’s approach of
answering what-if deployment questions, but WISE is similar to
previous work on TCP throughput prediction and the application of
Bayesian inference to networking problems.
A key component in response time for Web requests is TCP
transfer latency. There has been signiﬁcant work on TCP through-
put and latency prediction using TCP modeling [2,5,19]. Due to in-
herent complexity of TCP these models make simplifying assump-
tions to keep the analysis tractable; these assumptions may pro-
duce inaccurate results. Recently, there has been effort to embrace
the complexity and using past behavior to predict TCP through-
put. He et al. [12] evaluate predictability using short-term history,
and Mirza et al. [17] use machine-learning techniques to estimate
TCP throughput — these techniques tend to be more accurate. We
also use machine-learning and statistical inference in our work, but
techniques of [17] are not directly applicable because they rely on
estimating path properties immediately before making a prediction.
Further, they do not provide a framework for evaluating what-if
scenarios. The parametric techniques, as we show in Section 7.4,
unfortunately are not very accurate for predicting response-time.
A recent body of work has explored use of Bayesian inference
for fault and root-cause diagnosis. SCORE [15] uses spatial cor-
relation and shared risk group techniques to ﬁnd the best possi-
ble explanation for observed faults in the network. Shrink [14]
extends this model to a probabilistic setting, because the depen-
dencies among the nodes may not be deterministic due to incom-
plete information or noisy measurements. Sherlock [4] additionally
ﬁnds causes for poor performance and also models fail-over and
load-balancing dependencies. Rish et al. [21] combine dependency
graphs with active probing for fault-diagnosis. None of these work,
however, address evaluating what-if scenarios for networks.
11. CONCLUSION
Network designers must routinely answer questions about how
speciﬁc deployment scenarios affect the response time of a service.
Without a rigorous method for evaluating such scenarios, the net-
work designers must rely on ad hoc methods or resort to costly ﬁeld
deployments to test their ideas. This paper has presented WISE, a
tool for specifying and accurately evaluating what-if deployment
scenarios for content distribution networks. To our knowledge,
WISE is the ﬁrst tool to automatically derive causal relationships
from Web traces and apply statistical intervention to predict net-
worked service performance. Our evaluation demonstrates that
WISE is both fast and accurate: it can predict response time distri-
butions in “what if” scenarios to within a 11% error margin. WISE
is also easy to use: its scenario speciﬁcation language makes it easy
to specify complex conﬁgurations in just a few lines of code.
In the future, we plan to use similar techniques to explore how
causal inference can help network designers better understand the
dependencies that transcend beyond just performance related is-
sues in their networks. WISE represents an interesting point in the
design space because it leverages almost no domain knowledge to
derive causal dependencies; perhaps what-ifscenario evaluators in
other domains that rely almost exclusively on domain knowledge
(e.g., [8]) could also leverage statistical techniques to improve ac-
curacy and efﬁciency.
Acknowledgments
We would like to thank Andre Broido and Ben Helsley at Google,
and anonymous reviewers for the valuable feedback that helped im-
prove several aspects of our work. We would also like to thank Jeff
Mogul for sharing source code for the methods in [2].
12. REFERENCES
[1] Akamai Technologies. www.akamai.com
[2] M. Arlitt, B. Krishnamurthy, J. Mogul. Predicting
short-transfer latency from TCP arcana: A trace-based
validation. IMC’2005.
[3] L.A. Barroso, J. Dean, U. Holzle. Web Search for a Planet:
The Google Cluster Architecture. IEEE Micro. Vol. 23, No.
2. pp 22–28
[4] P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. Maltz, M.
Zhang. Towards Highly Reliable Enterprise Network
Services via Inference of Multi-level Dependencies. ACM
SIGCOMM 2007.
[5] N. Cardwell, S. Savage, T. Anderson. Modeling TCP
Latency. IEEE Infocomm 2000.
[6] G. Cooper. A Simple Constraint-Based Algorithm for
Efﬁciently Mining Observational Databases for Causal
Relationships. Data Mining and Knowledge Discovery 1,
203-224. 1997.
[7] Emulab Network Testbed. http://www.emulab.net
[8] N. Feamster and J. Rexford. Network-Wide Prediction of
BGP Routes. IEEE/ACM Transactions on Networking. Vol.
15. pp. 253–266
[9] M. Freedman, E. Freudenthal, D. Mazieres. Democratizing
Content Publication with Coral. USENIX NSDI 2004.
[10] A. Gray, A. Moore, ‘N -Body’ Problems in Statistical
Learning. Advances in Neural Information Processing
Systems 13. 2000.
[11] Lucene Hadoop. http://lucene.apache.org/hadoop/
[12] Q. He, C. Dovrolis, M. Ammar. On the Predictability of
Large Transfer TCP Throughput. ACM SIGCOMM 2006.
[13] A. Barbir, et al. Known Content Network Request Routing
Mechanisms. IETF RFC 3568. July 2003.
[14] S. Kandula, D. Katabi, J. Vasseur. Shrink: A Tool for Failure
Diagnosis in IP Networks. MineNet Workshop SIGCOMM
2005.
[15] R. Kompella, J. Yates, A. Greenberg, A. Snoeren. IP Fault
Localization Via Risk Modeling. USENIX NSDI 2005.
[16] J. Dean and S. Ghemawat. MapReduce: Simpliﬁed Data
Processing on Large Clusters. USENIX OSDI 2004.
[17] M. Mirza, J. Sommers, P. Barford, X. Zhu. A Machine
Learning Approach to TCP Throughput Prediction. ACM
SIGMETRICS 2007.
[18] Netezza http://www.netezza.com/
[19] J. Padhye, V. Firoiu, D. Towsley, and J. Kurose. Modeling
TCP Throughput: A Simple Model and its Empirical
Validation. IEEE/ACM Transactions on Networking. Vol 8.
pp. 135-145
[20] J. Pearl. Causality: Models, Reasoning, and Inference.
Cambridge University Press. 2003.
[21] I. Rish, M. Brodie, S. Ma. Efﬁcient Fault Diagnosis Using
Probing. AAAI Spring Symposium on DMDP. 2002.
[22] R. Pike, S. Dorward, R. Griesemer, and S. Quinlan.
Interpreting the Data: Parallel Analysis with Sawzall.
Scientiﬁc Programming Journal. Vol. 13. pp. 227–298.
[23] P. Sprites, C. Glymour. An Algorithm for fast recovery of
sparse causal graphs. Social Science Computer Review 9.
USENIX Symposium on Internet Technologies and Systems.
1997.
[24] M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, M. Ammar.
Answering “What-if” Deployment and Conﬁguration
Questions with WISE. Georgia Tech Technical Report
GT-CS-08-02. February 2008.
[25] L. Wasserman. All of Statistics: A Concise Course in
Statistical Inference. Springer Texts in Statistics. 2003.
[26] J. Wolberg. Data Analysis Using the Method of Least
Squares. Springer. Feb 2006.