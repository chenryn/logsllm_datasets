get instant feedback, and repeat the whole process. In a recent sur-
vey [35] on data science practitioners, top 3 preferred programming
languages for data scientists are, R, Python, and SQL. Furthermore,
only 9% of the data scientists in the survey use C/C++ for data anal-
ysis. One major reason behind this might be, easy data exploration
and visualization is often more important than writing the most
optimized solution.
2jne, jeq are assembly instructions for jumping based on zero flag.
We also observe that complex data analytics tasks can be ex-
pressed as basic matrix operations if the data is represented as a
matrix. In fact, entire language and analytical stacks, such as, Mat-
lab [5], Octave [4], NumPy [6], and Pandas [7], has been proposed
around matrix operations. Moreover, basic matrix operations, such
as, multiplication and transpose are by definition data oblivious.
In light of these observations, we propose an efficient and inter-
active framework to handle large encrypted datasets for generic
data analytics tasks by leveraging the Intel SGX instruction set. Our
main objective is to bring matrix based computation into secure
processing environment in a way that would allows us to perform
any matrix operation on large encrypted matrices. So we propose
BigMatrix Runtime, and at the core we have BigMatrix abstraction
that split a large matrix into a sequence of smaller ones and per-
forms individual matrix operations using smaller block. BigMatrix
handles the blocking and encryption of the small block automati-
cally and transparently. In addition, we add other key operations,
such as, sorting and selection, on top of BigMatrix abstraction to
support most data analytics computations.
3.1 Setup, Protocols, and Threat Model
In our framework, we consider a setup where a single participant
or multiple participants are connected to an Intel SGX enabled
server. The server is assumed to be controlled by an adversary, who
can observe the main memory (RAM) content and main memory
processor communications. Furthermore, the adversary can delete/-
modify the stored data, provide wrong data, and stop the execution
of the enclave. At the same time, due the capabilities of the Intel
SGX, we assume that the attacker cannot modify the code that is
running in the enclave.
Participants do not trust each other with their data but they want
to execute a program that will perform some data analytics task
over all the participants’ data. Also, we assume that the participants
are not sending invalid datasets or aborting the process abruptly.
In addition, each user has the capability to verify that the server
has loaded the proper code. If the server does not load the proper
code, participants will be able to detect the deviation. All the com-
munications between the server and the participants are done over
a secure communication channel, such as, Https. We also assume
that the owner of the server is not colluding with the participants.
In our framework, given the attacker capabilities, our goal is to
detect any tampering by the attacker and limit information leakage
during the data analytic task execution process. Furthermore, we
want to make the framework suitable for multi-user setting where
different parties can combine their data and build collaborative
model. To achieve these goals, our proposed secure data analytics
framework had three distinct phases: 1) Code agreement and load-
ing phase that allows multiple parties to agree on the common task
that will run on their joint data, 2) Input data and encryption key
provisioning phase that allows data encryption and key sharing, 3)
Result distribution phase that provides the computation result to
multiple users. We discuss these phases in detail in Appendix C.
3.2 Overview
BigMatrix Runtime has two major components: 1) BigMatrix Run-
time Client, where a user provides input data and tasks to perform
2. Matrix Operations. a) scalar(op, A, value): perform scalar
operation op on each element of input matrix A and return the out-
put, where op is a binary operation such as addition, multiplication,
and, or, etc., A is a BigMatrix and value is numeric value. b) ele-
ment_wise(op, A, B): perform element wise operation op on two
big matrices and return the result. c) multiply(A, B): perform ma-
trix multiplication of big matrices A and B. d) inverse(A): perform
inverse of big matrix A. e) transpose(A): create the transpose of
big matrix A.
3. Relational Algebra Operations. a) where(A, condition):
perform basic selection operation on A for a given condition and
return a 0-1 column matrix. b) sort(A, columns, direction):
sort the rows of matrix A using bitonic sort. c) join(A, B, condi-
tion, k): perform SQL like join of A and B based on condition. k
is a parameter to ensure obliviousness, which we discuss in Appen-
dix A.9. d) aggregation(A, commands, columns): perform basic
aggregation on A on columns. Allowed aggregation commands are
sum, average, count, min and max. We also implemented argmax(A,
columns) and argmin, which provide the index of highest and low-
est value row in the matrix.
4. Data generation operations. a) rand(m, n), zeros(m, n),
ones(m, n): generate a BigMatrix of size m × n containing uniform
random numbers, zeros and ones respectively. b) eye(n): generate
an identity matrix of n × n.
5. Statistical Operations. a) norm(A, p): compute p-norm of the
vector (n × 1 matrix) A. b) var(A): compute variance of the vector
A.
All the operations in our BigMatrix library also have pre-defined
trace, which is the amount of information leakage due to perform-
ing the operation. For example, the multiply operation leaks the
information about the size of the matrix A and B. We refer readers
to Appendix A for more internal details including trace and cost of
important BigMatrix operations.
3.4 Compiler and Execution Engine —
Programming Abstraction
As stated earlier, quick and secure data analytical development cycle
is a major target of the proposed framework. To that end, we define
a compiler and execution engine that can process and execute code,
which is written in a python-like language. The execution engine
is part of our trusted environment and can interpret assembly-like
instructions, such as, C = multiply(A, B). On the other hand, the
compiler resides outside the enclave and creates execution engine
compatible code from our custom language, which is inspired by
languages such as python and octave. The main reason behind such
a split architecture is to reduce the size of TCB (trusted comput-
ing base). There is no regular expression or context free grammar
functionality in SGX library. So if we want to support interactive
computation in any language we would need to bring in the com-
plete grammar processing library into the TCB, which increases the
risk of introducing potential vulnerability through bugs of these
libraries. On the other hand, we could build a parser that outputs
code into X86 assembly architecture and put more simplified execu-
tion engine. However, we avoided this option because traditional
assembly instruction set has complex branching instructions that
Figure 1: Framework Overview.
on the input data, 2) BigMatrix Runtime Server, which interprets
user’s commands and performs the requested tasks. Before going
into the details of each component, we first provide a top-level
overview of code execution in BigMatrix Runtime.
A user first makes sure that the server is started properly with se-
cure enclave code and provision the enclave with proper secret keys
using proposed protocols. Next, the user provides input program
and data to the BigMatrix Runtime client, which uses a compiler
to compile the program into execution engine compatible code and
perform error checking. The client also encrypts the data using the
proper key. Next, the client sends the code and encrypted data to
Service Manager. Service Manager next performs block size opti-
mization and loads encrypted data in the enclave with optimum
block size information. Then service manager starts the execution
engine that performs the user specified operations. Once the oper-
ation execution has been finished Service Manager sends enclave
generated data back to the client, which later displays the result
back to the user.
BigMatrix Runtime client consists of two components: a) Client
and b) Compiler. BigMatrix Runtime server consists of six logical
components: a) BigMatrix Library, b) Execution Engine, c) Compiler,
d) Block Cache, e) Block Size Optimizer, and f) Service Manager. In
the rest of this section, we explain each of these components.
3.3 Key Operations of BigMatrix Library
At the very bottom layer, we have BigMatrix library, which con-
tains sets of operations on our proposed BigMatrix abstraction. A
BigMatrix is essentially a matrix of smaller matrices. Basically, we
compute a specific block size that we can fit into SGX enclave and
split a large input matrix into smaller blocks and perform opera-
tions using these blocks. This abstraction is needed since SGX is a
memory constrained environment.
We have defined few basic functions in BigMatrix library, which
we later use to build more complex operations. Our defined func-
tions falls into the following five categories:
1. Data access operations. a) load(participant_id, mat_id):
load matrix with mat_id from the storage, which is encrypted
with session key of participant, participant_id. b) publish(A):
publish the matrix A for all the participants. c) Partial access op-
erations: get_row(A, i), set_row(A, i, r), get_column(A, j),
set_column(A, j, c), get_element(A, i, j), set_element(A,
i, j, v).
We defer the discussion of how we serialize, encrypt, store, and
load the BigMatrix in subsection 3.8, once we define other relevant
components of the system.
UntrustedTrustedCompilerBlock SizeOptimizerService ManagerBigMatrix LibraryIntel SGX SDKExecution EngineBlockCacheOCallsECallsCompilerBMRT ClientServerClientare very hard to convert to the equivalent data oblivious version.
Furthermore, the instruction set is highly restricted to a fixed set
of registers, which is not the case for our execution engine.
Our compiler is divided into five components: Lexical analyzer,
syntax analyzer, semantic analyzer, optimizer, and code generator.
Lexical analyzer takes the input file and outputs a stream of tokens.
Syntax analyzer takes the token streams and creates a syntax tree
representing the input source code. During syntax tree creation
syntax analyzer also lists any syntax errors. Semantic analyzer ana-
lyzes the syntax tree and checks for semantic mistakes. One of the
semantic tests that we perform is matrix conformability [32], where
we test operand matrices whether they have proper dimensions for
intended operations. In this stage, we also perform a sensitive data
leakage analysis, where we check if any sensitive information is
leaking as a side effect of some operations. For a given program,
we define the non-sensitive information as: (a) input size, and (b)
constants in the input program. On the other hand, we also know
the trace (set of values per operation that is disclosed) of all the op-
erations in the input program. Semantic analyzer checks for items
in the trace that is not non-sensitive and warns users of possible
information leakage. For example, our semantic analyzer will raise
error for the following input code.
path / to / X_Matrix )
X = load ( 0 ,
s = count ( where (X[ 1 ] >= 0 ) )
Y = z e r o s ( s ,
p u b l i s h ( Y )
1 )
Because, here the value of s is in the trace of function zeros but the
value is not in the non-sensitive data list. Next, optimizer performs
few compile time optimizations, such as basic query optimization
(detail in subsection 3.7), and matrix multiplication order optimiza-
tion. Finally, code generator takes the syntax tree and generates
execution engine compatible code. In addition, our compiler also
outputs complete trace of a input program so that programmers
can easily understand information leakage.
The execution engine can run in two modes: interactive and
non-interactive. In the interactive mode, a user loads the enclave,
verifies, starts a session, provides sequence of instructions, and
closes the session at will. So the system does not know all the
instructions to be executed. In this mode, the values of variables
are retained until user explicitly unset it. In non-interactive mode,
the user provides completed tasks to be executed and the compiler
generates necessary unset commands depending on the last used
instructions.
Our framework supports variables of types int32, int64, dou-
ble, BigMatrix of different types, and fixed length strings. The
language is not strictly typed, i.e., during initialization a user does
not have to specify the type of a variable. Our system can handle
fixed length loops and we are assuming that the number of loop
iterations can be leaked to the adversary (e.g., constant or some
known value, such as rows, columns, block_size). In addition, we
also protect intermediate data tampering. We keep an internal table
of matrix id and header MAC (message authentication code) of
matrices in a computation. So, if an operating system sends invalid
data (i.e., an active attack, or unintentional data corruption), our
execution engine will be able to detect it. We discuss our MAC
generation in subsection 3.8.
An Example. Now we provide an example on how our framework
could be used to execute fundamental data analytics tasks. Linear
Regression is an approach for modeling the relationship between
a scalar dependent variable y and one or more independent vari-
ables [37]. Let, m be the number of inputs, X be the training dataset,
Y be the output of training dataset, X(j) and Y(j) be the jth training
set and class respectively, Θ be the regression parameters, and ˆy be
the predicted class of test input x, then
ˆy = ΘT x
XT y . In our programming language, we can
where, Θ = (XT X)−1
compute the Θ using the following code snippet.
x = load ( 0 ,
y = load ( 0 ,
xt = t r a n s p o s e ( x )
t h e t a = i n v e r s e ( xt
p u b l i s h ( t h e t a )
path / to / X_Matrix )
path / to / Y_Matrix )
∗ xt
∗ x )
∗ y
Our compiler will convert the above code snippet into the follow-
ing sequence of instructions that can be executed by our execution
engine.
x = load ( 0 , X_Matrix_ID )
y = load ( 0 , Y_Matrix_ID )
xt = t r a n s p o s e ( x )
t 1 = m u l t i p l y ( xt , x )
unset ( x )
t 2 = i n v e r s e ( t 1 )
unset ( t 1 )
t 3 = m u l t i p l y ( t2 , xt )
unset ( xt )
unset ( t 2 )
t h e t a = m u l t i p l y ( t3 , y )
unset ( y )
unset ( t 3 )
p u b l i s h ( t h e t a )
Again if the code ran in the interactive mode, our compiler would
not generate the unset instructions. In this case, the leaked infor-
mation to adversary is the size of x and y matrices and sequence of
operations. 3
We also defined PageRank, Naive Bayes, and K-Means clustering
algorithm in our programming language. We refer readers to Ap-
pendix B for these examples.
3.5 Block Cache
Next we briefly describe a cache layer which caches the loaded