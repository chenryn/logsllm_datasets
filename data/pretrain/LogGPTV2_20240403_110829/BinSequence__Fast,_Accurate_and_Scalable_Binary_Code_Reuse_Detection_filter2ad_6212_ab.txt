2
3
4
5
6
7
8
n = num of operands(ins1)
score += IDENTICAL MNEMONIC SCORE
for i = 0; i < n; + + i do
if operand(ins1)[i] == operand(ins2)[i] then
if type(operand(ins1)[i]) ==
9
10
11
CONSTANTS then
score +=
IDENTICAL CONSTANT SCORE
else
score +=
IDENTICAL OPERAND SCORE
end
end
end
else
score = 0
end
return score
12
13
14
15
16
17
18
19 end
Instead of comparing original instructions, we choose to
compare the normalized instructions. The ﬁrst advantage
is more resistance to register reassignment, which is very
common in compiler optimization. Second, we want to do a
fuzzy matching. This is diﬀerent from what David and Ya-
hav did in [12], where they use exact matching when com-
paring operands. Besides, we allow partial matching. For
example, we give a score of 5 to instruction pair cmp [eax],0
and cmp ebx, 0, although they are two types of instructions.
The ﬁrst instruction is comparing an immediate value with
a memory reference while the second with an register. The
reason for allowing partial matching is that, even for the
same variable, compilers have the freedom to represent it as
a register variable or a memory variable. Allowing partial
matching can tolerate these diﬀerences.
3.3 Basic Block Comparison
We leverage the longest common subsequence (LCS) method
of dynamic programming [11] to compare two basic blocks.
The LCS problem is to ﬁnd the longest subsequence which
is common to both sequences. Note that a basic block is
also a sequence of assembly instructions. We then leverage
the LCS to calculate the similarity score of two basic blocks.
We consider every instruction as a letter and use the score
strategy presented in Algorithm 1 to obtain the matching
score. Notice that we do not draw any conclusion about
whether these two basic blocks are identical or should be
matched according to this score. Unlike the work in [12],
we just use the similarity score as a guide for later use. As
shown in Algorithm 2, the output is the largest similarity
score that these two basic blocks can achieve with respect
to the score strategy we are using. By backtracking the
memoization table, we can also obtain the mapping of in-
structions between this two basic blocks. Some literatures
such as [12] also denote this process of leveraging dynamic
programming to obtain the mapping, as “alignment”. Af-
ter this “alignment”, instructions that cannot be matched
can be jumped over. This jumping over instructions is our
fuzzy matching at the basic block level. However, for now
this mapping is of no interest to us, as we only need the
maximum similarity score. Note that there may be diﬀerent
mappings that give us the same maximum score, however,
the maximum score is unique. In our algorithm, it is always
in the last cell of the memoization table.
A special case is to use Algorithm 2 to compare a basic
block with itself. No doubt that the highest score will be
achieved only when every instruction is mapped to itself.
We deﬁne that score as the “self” score of that basic block.
Intuitively, this score can be used to measure the information
that a basic block carries. A large basic block results in a
high self score.
Algorithm 2: Calculate the similarity score of two
basic blocks
Input: Two basic blocks BB1, BB2
Output: The similarity score of two basic blocks
/* M: the memoization table
*/
1 Algorithm CompBBs(BB1, BB2)
M = InitTable(|BB1| + 1,|BB2| + 1)
2
for i = 1; i <= |BB1|; + + i do
3
for j = 1; j <= |BB2|; + + j do
4
5
6
7
8
9
10
11
12 end
end
return M [|BB1|,|BB2|]
end
M [i, j] = M ax(
CompIns(BB1[i], BB2[j]) + M [i − 1, j − 1],
M [i − 1, j],
M [i, j − 1])
3.4 Longest Path Generation
We have explained how to compare two basic blocks. For
every basic block pair, we can obtain a similarity score. The
larger the score, the more similar these two basic blocks
are. However, this score is derived from the assembly code
only, and is thus not suﬃcient. For example, for one target
basic block, we might ﬁnd multiple basic blocks that have
the same similarity score with it. Even worse, we may end
up matching it with a wrong basic block simply because its
assembly code is more similar to the target by chance.
Inspired by the recent work in [19], we realize that path
in the CFG is a robust feature, since path can record every
selection the execution ﬂow took when a branch is encoun-
tered, and one path represents one complete particular ex-
ecution. Notice that the functionality of one path is spread
across consisting nodes (basic blocks). If we succeed in ﬁnd-
ing two paths that are equivalent in terms of functionality, it
would be trivial to further match their nodes. Again, we can
treat the problem of ﬁnding matching nodes as an alignment
problem where dynamic programming can be applied. Intu-
itively, one short path does not carry as much information as
a long path. Besides, the longer the path, the more match-
ing nodes we could obtain by aligning it with its matching
path, which improves both the accuracy and eﬃciency of
neighborhood exploration process (Section 3.6). Thus, we
choose the longest path. We use depth ﬁrst search to tra-
verse the CFG, and then choose the path with the largest
number of nodes.
3.5 Path Exploration
After we obtained the longest path of the target func-
tion, the next step is to explore the reference function, to
try to ﬁnd the best match of that path in the reference
function. We adopt the approach in [19] to do the explo-
ration. In [19] Luo et al. used a breadth-ﬁrst search com-
bined with dynamic programming to compute the highest
score of longest common subsequence of semantically equiv-
alent basic blocks. In our case, we leveraged their algorithm
to ﬁnd the corresponding path which has the largest simi-
larity score based on Algorithm 2.
The algorithm for path exploration is similar to the com-
mon dynamic programming for computing the LCS of two
strings. Since a path is also a sequence of basic blocks, we
can treat every basic block as a letter and use the Algorithm
2 as our score strategy. However, there are two diﬀerences.
First, the length of a string is constant, thus when comput-
ing the LCS of two strings the length of the memoization
table is also ﬁxed. In path exploration, however, we do not
know the length of the memoization table in advance, so
we set the initial length to one (Line 2) and add more rows
on the run (Line 9). Second, the letters in a given string
are sequential; every previous letter has at most one letter
following it while a node in a CFG may have multiple succes-
sors. That is why we need to combine breadth-ﬁrst search
with the original dynamic programming.
We modiﬁed the algorithm in [19] to ﬁt our needs. Given
a longest path P from the target function and the CFG G of
the reference function, we always start from the head node
of G (Line 5). At the beginning of each iteration, we pop out
a node from the working queue Q as the current node (line
7). Then we add a new row to the memoization table δ and
update the table correspondingly using function LCS (Line
10).
It is worth noting that when comparing the current
node with every node in path P , we require them to have
the same in-degree and out-degree to be matched (Line 22).
Otherwise we do not allow them to match by giving them
a score of 0 (Line 25). The motivation is that we want to
quickly match the “skeleton” of the CFG ﬁrst. If we failed to
match some nodes whose in-degree or out-degree have been
changed, we can leave them to the next step, neighborhood
exploration. Also note that because of the complexity of
the CFG, there might be multiple paths that can lead the
execution ﬂow to a certain node. To improve the eﬃciency,
it is important to reduce the search space and prune the
unproﬁtable path. To this end, we use an array σ to store
the largest similarity score that we have achieved so far for
each node. Every time after updating the table δ for certain
node, we continue to compare the obtained new score with
the largest score stored in σ (Line 11). If the new score is
larger, we then update σ and insert every successor of this
node to our working queue Q. Otherwise we do not further
explore its successors. The algorithm terminates after Q is
empty. The output is the memoization table δ.
Algorithm 3: Path exploration
Input: P : the longest path from the target function,
G: the CFG of the reference function
Output: δ: The memoization table
/* σ: the array that stores the largest LCS
*/
score for every node in G
1 Function PathExploration(P ,G)
δ = InitTable(1, |P| + 1)
2
σ = InitArray(|G|)
3
Q = InitQueue()
4
Q.pushback(G1) //always start from the head node
5
6
while Q is not empty do
currN ode = Q.front()
7
Q.pop front()
8
δ.AddNewRow() //always add a new row to δ
9
LCS(currN ode,P ) //compare currN ode with
10
every node in P and update the table δ
if σ(currN ode) < δ(currN ode,|P|) then
σ(currN ode) = δ(currN ode,|P|)
for each successor s of currNode do
11
12
13
14
15
16
17
18
19 end
Q.pushback(s)
end
end
end
return δ
for each node v of P do
if SameDegree(u,v) then
sim = CompBB(u, v)
else
sim = 0
20 Function LCS(u,P )
21
22
23
24
25
26
27
28
29
30
31
32 end
end
end
δ(u, v) = M ax(
δ(parent(u), parent(v)) + sim,
δ(parent(u), v),
δ(u, parent(v)))
Figure 3 presents an example. Figure 3a shows two sim-
pliﬁed CFGs of two functions from open source projects; the
grey nodes denote the longest path we found in the target
CFG. These two functions are from the same source code.
However due to the noise introduced by the compiler, their
structures are not isomorphism. Basic block J in the target
function consists of one “JMP” instruction, directing the ex-
ecution ﬂow to the tail block “6”. Basic block 3 in the target
CFG modiﬁes the value of a local variable in the stack. As
can be seen from Figure 3a, basic block 3 does not have a
corresponding basic block in the reference CFG because the
compiler used the register “ESI” to represent this variable
in the reference function. Moreover, the reference CFG has
one more basic block R, that restores the original value of
“ESI”, and then directs the execution ﬂow to the tail. All
these changes are very common.
in the reference CFG has a corresponding node (node 4) in
the path P , the in-degrees of these two nodes are diﬀerent.
Thus, we give them a matching score of 0. Then we put the
successors of node 4 into Q. Now Q has two elements, node
5, and node R (parent is node 4). We visit node 5 ﬁrst, and
put its successor node R into Q. Now Q has two elements,
node R from node 4 (partial path “1→2→4→R”) and node R
from node 5 (partial path “1→2→4→5→R”). Both elements
will lead us to node 6, but with diﬀerent LCS scores. The
one from node 4 (complete path “1→2→4→R→6”) will have
a ﬁnal score of 3 while the one from node 5 (complete path
“1→2→4→5→R→6”) gives us a score of 4.
We can then backtrack the memoization table δ to get
the corresponding path that has the largest sum of simi-
larity score with the target longest path. However, during
our experiments we found that considering only the sum of
the similarity score may sometimes give undesirable results.