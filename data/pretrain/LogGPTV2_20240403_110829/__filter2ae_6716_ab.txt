            $record[$t]=1;
        }else{
            $record[$t]++;
        }
        echo $key." 1n";
    }
    unset($arr);
    $n=0;
    foreach ($record as $key => $value) {
    $n++;
        $key=addslashes($key);
        mysqli_query(
        $con, 
        "INSERT passtest(string,times) VALUES('{$key}', '{$value}')"
    );
    echo $n."   2n";
    }
    mysqli_close($con);
    ?>
**0x06 弱密码行为片段统计分析**
这里我们是定义了一些行为标准，然后按照标准来匹配的。
但是又不得不说的是，一个片段是否属于行为片段，是比较难通过简单的规则来判断的，因此这里的分析所展现的结果十分有限。比如一个数字是否是和用户相关的QQ账号，是不能简单的看数字的，还需要通过有效的关系库，进行更复杂的分析。
测试代码
     $value) {
        echo $key."n";
        foreach ($arr as $key1 => $value1) {
            if(preg_match($value1,$value))
                if(!$n[$key1])
                    $n[$key1]=1;
                else
                    $n[$key1]++;
        }
    }
    echo "Now writing...n";
    foreach ($n as $key => $value) {
        file_put_contents('xxx.new.txt',$key.'  '.$value."n",FILE_APPEND);
    }
    ?>
**0x07 修正工作**
其实细心的朋友应该考虑到了，在0x03中采用的是按照字符串类型来分割片段，这是有问题的，比如在处理如q1w2e3，hllsb，20082333，passw0rd这样的字符串，就容易显得心有余而力不足。
因此我在这里也使用了另一种方法来进行词频，无视字符串类型，不过依然不完美，主要的原理就是从所有密码中提取所有连续的m个字符，计算词频，然后提取所有的m-1个字符，计算词频……直到提取所有连续的3个字符，提取词频。
每次提取的连续字符数其实也就是我们说的 **粒度** 或者 **精度**
了，由于粒度本身很难正确控制，而一般而言粒度越小，带来的信息量往往越低，像abcd，不能把四个字母都单独作为片段，字符单独作为片段往往是用于不同类型字符的隔断，例如a123456，PI:EMAIL，而这时候的单个字符，我们使用0x03的方法是可以提取出来的。因此我们应当适度控制最小粒度。
因此，当粒度太小，排行第一的字符容易是一些无意义字符，粒度太大容易过滤掉一些片段，另一方面，由于原理的限制，这种方法提取非常耗计算资源。
在这里，我提取了前1w个密码作为分析。结果如下。
倒不是我刻意处理了字母和字符，而是提取出来的前1w密码的样本分析结果的确如此，其实这也符合0x04 0x05的统计结果。
不过这样的问题也很明显，字符串23456的使用频率和3456、456频率很接近，也就是说，实际上23456是出现最频繁片段，而3456
456脱离23456存在的情况并不多。因此还需要进一步再进行分析。
下面是我使用的代码，在处理大量数据的时候，下列代码就显得力不从心了，甚至容易出现内存不够的现象。
     $value) {
        $max=$max>=strlen($value)?$max:strlen($value);
    }
    // $m=$max;
    $m=10;
    $n=0;
    for (; $m>3 ; ) { //控制最小粒度
        foreach ($a as $key1 => $value1) {
            if($value1>=$m){
                $i=0;
                for(;$i+$m $value2) {
                        if(stripos($value2, $c)){
                            $n++;
                        }
                    }
                    $b[$c]=$n;
                            $n=0;
                            $i++;           
                        }
            }
            echo $m.'   '.$key1."n";
        }
        $m--;
        //echo $m."n";
    }
    arsort($b);
    // print_r($b);
    foreach ($b as $key => $value) {
        file_put_contents($file.'_new.txt', $value.'    '.$key."rn",FILE_APPEND);
    }
    ?>
**0x08 可能更好的解决方案**
****
廉价劳动力：可以使用一个较低的价格，雇人来将这些片段给分割出来，比如hllsb，让他在hll和sb之间加个回车，不过这显然需要一定的财力支撑。
免费劳动力：像是拥有大量用户的互联网公司，就可以玩这种游戏，“验证码1：中国是那一年建国的，验证码2：请将hllshabi分割成几个有意义的片段（如xxwoaini=xx|woaini），通过验证码1来判断2分割正确的概率”。不过如果真的应用的话，并不像我描述的这么简单。
可能略显简单的方法：直接定义一个预设表，预设一些常用的片段。
可能更智能的方案：
思考一下，我们为什么看到q1w2e3，passw0rd的时候会知道这不应该拆分，而看到hllsb，20082333这类却觉得应该拆分？
我认为是熟悉度的原因，qwe和123本身是一个比较眼熟的片段，在q1w2e3中，qwe和123本身间隔的不远，我们很容易从中提取出我们熟悉的这两个片段。
而对于passw0rd，对我们来说password是一个眼熟的片段，二者其实差别不大，可以看到其实只有一个字节被替换成了相近的0，其实就算被替换成了passw@rd，或者替换成其他类似的字符串，我们稍微思考一下也是可以理解它是由password演变而来的。
至于hllsb，20082333，这二者应该算是典型了，前者是因为我们知道sb这个片段，而hll又正好属于声母，h属于百家姓里的姓氏的声母，可以推测出hll为人名，这都是熟悉度的典型代表。同样的，2008匹配了公元纪年法且符合近、现代年份，2333匹配了网络用语。也就是说，熟悉度不仅仅是具体某个字符串，还可能是匹配某种格式。
因此如果要模拟大脑的思路，我们可以建立一个预设表，其中字段可以是：弱密码片段、常用类型、网络用语、英文常见单词、韵母表、百家姓……等等，然后将字符串进行一定的处理，然后与预设表进行匹配，如果可以高度匹配某个值或类型，那么就表示该字符串很可能是一个独立的片段，应该独立看待，如果匹配了多个值和类型，说明该字符串应该进行切割。
对字符串进行的处理主要体现在比如以下几个方面，以上述四个字符串为例：
以上四个都是直接匹配时无法高度匹配的，在这种情况下，应当处理后再次进行匹配。
**q1w2e3**
：对于这种两种类型的字符串交替过于频繁的，单类型字符串的单元太小，太小的单元往往意味着信息量低，因此对于类型交叉频繁的字符串，可以考虑提取单一类型，重新分割为qwe和123两个片段，然后分别查询预设表，如果二者中有一个高度匹配，那么整体就应当作为单一片段看待；
**passw0rd**
：对于这种，其实本身就与password高度匹配，可以直接查询。不过我们知道password本身是有意义的，这种方式可以通过尝试先建立一张替换表，尝试进行字符串替换，将替换的结果带入预设表查询。
**hllsb、20082333**
：可以进行逆向匹配，分析表中是否有某数据匹配了该字符串的一部分，是否又有数据匹配了字符串的剩余一部分，如果未匹配的部分较少，就可以将未匹配的部分丢弃了。
当然这个只是一个设想，实现起来还是有困难的。
**写在最后**
****
任何一个小的点，都可以继续深入下去，使之成为一门学问。
至少我认为，大众密码不仅是有单纯的弱口令问题，虽然目前也有所谓的社会工程学字典，但是字典的生成不该是单纯的信息重组，里面的信息还需要我们认真分析。除了本次的对于大众密码的简单分析，我们往往还需要针对不同群体和不同的个体进行针对性的密码分析，以分析出最接近可能的用户密码。