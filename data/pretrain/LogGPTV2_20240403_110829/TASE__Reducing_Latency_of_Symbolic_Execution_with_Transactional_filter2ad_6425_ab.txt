execution process upon reaching a symbolic branch, to allow
the parent and child to explore the two possibilities separately.
S2E uses QEMU and KLEE together to mix concrete and
native execution, and is the system most similar to TASE.
S2E uses the virtualization and emulation tools within QEMU
to perform symbolic execution across user space and kernel
space boundaries [18]. S2E also uses an emulated MMU
that checks each byte during access in concrete execution
mode to determine if control must transfer to the KLEE-based
interpreter [17]. While we build on their techniques for sharing
symbolic and concrete state, TASE is built to prioritize and
optimize native execution using new transactional machine
instructions and symbolic-state detection mechanisms detailed
in Sec. IV. For detecting symbolic state, TASE does not
solely rely on the bitmap lookup techniques used in EXE and
S2E, and TASE incurs no virtualization or dynamic binary
translation overheads when executing code natively.
B. Intel TSX
Intel’s Transactional Synchronization Instructions (TSX)
were originally introduced to speed up concurrency in mul-
tithreaded applications [28, Ch. 16]. However, TSX instruc-
tions have been repurposed for security defenses (e.g., [45],
[14]) and attacks [53], [22], as well. Similarly, TASE uses
the transactions enabled by TSX in an unorthodox way.
Speciﬁcally, TASE uses transactions to speculatively execute
regions of code natively during symbolic execution, aborting
the transaction if symbolic data is encountered. Key challenges
for implementing this strategy are presented in Sec. III-B.
III. BACKGROUND AND CHALLENGES
Our work to optimize symbolic execution for latency-
sensitive applications required us to build on research from
seemingly unrelated topics. In this section we brieﬂy cover
necessary background and key challenges that we address in
TASE, pertaining to executing concrete operations natively but
safely during symbolic execution (Sec. III-A) and leveraging
Intel TSX in this context (Sec. III-B).
A. Concrete Operations in Symbolic Execution
Past works (e.g., [25], [11], [18], [13]) have recognized the
signiﬁcance of enabling native execution for entirely concrete
computations in symbolic execution engines. However, the
overwhelming amount of such concrete operations present in
some of our target applications necessitate more aggressive
optimizations in TASE. For example, in Chi et al.’s veriﬁcation
of OpenSSL trafﬁc [16], which we explore as an application of
TASE in Sec. VI-B, fewer than 2.7% of instructions executed
operate on symbolic data, even after extensive protocol-speciﬁc
optimizations to eliminate unnecessary concrete operations
(described as the optimized conﬁguration in Sec. VI-B1). To
enable inline operation of this veriﬁer, it is thus necessary that
concrete operation be optimized as much as possible.
To do so, TASE speculatively executes regions of code
natively within transactions, optimistically assuming that no
operation in the transaction reads or overwrites symbolic
values. Transactions are atomic, and if any operation in a trans-
action reads or overwrites a symbolic value, TASE must abort
the transaction and resume execution within an interpreter—
in our case, a modiﬁed version of the KLEE interpreter. After
the transaction completes within the interpreter, TASE resumes
native execution if possible.
Separating concrete and symbolic execution into different
execution modes provided challenges for safely handling the
symbolic expressions the interpreter produces. In particular,
TASE tracks symbolic values by tainting them, speciﬁcally by
augmenting KLEE’s concrete/symbolic bitmaps with poison
tainting and tracking. This required the design and veriﬁcation
of invariants to guarantee that the transition between concrete
and symbolic execution does not unexpectedly overtaint or
undertaint the program’s execution with symbolic values, inva-
liding the resulting analysis. Moreover, because execution no
longer occurs entirely within an interpreter, there is a risk that
native execution might overwrite previously symbolic variables
with concrete data with no indication to the interpreter, forcing
us to adjust KLEE’s data structures to prevent such updates.
B. Implementing Transactions with TSX
A key contribution of our work is the use of Intel Transac-
tional Synchronization Instructions (TSX) to increase the speed
of symbolic execution. We focus speciﬁcally on the use of the
TSX Restricted Transactional Memory instructions xbegin
and xend.
Intel’s TSX instructions were originally released to pro-
vide a hardware-assisted tool for managing concurrency in a
process. A thread thd may speculatively attempt to acquire a
shared resource by using an xbegin prior to entering the
critical section. xbegin starts a transaction in which any
modiﬁcations to memory or registers made by thd are either
entirely committed at the end of the transaction (signiﬁed by
xend) or entirely discarded, at which time control for thd may
transfer to a fallback path with simpler locking primitives (e.g.,
a spin lock). In other words, the transaction is atomic.
Should another thread thd
(cid:48) attempt to enter the critical sec-
tion and modify the shared resource while thd is also altering
the resource in the transaction, one or both of the transactions
will abort and roll back [28, Ch. 16]. Transactions are rolled
3
back when conﬂicts over shared resources are detected between
(cid:48), potentially allowing
the read and write sets of thd and thd
both threads to operate in the critical section simultaneously
(cid:48) do not read or write the same shared data.
if thd and thd
(cid:48) are detected by
Conﬂicts in the read/write sets of thd and thd
the cache coherence protocol, and enabling concurrency with
TSX can potentially outperform other locking methods which
categorically prevent multiple threads from executing in the
critical section concurrently, even if no conﬂicting memory
accesses would have occurred [28, Ch. 16].
Intel’s transactional execution instructions provide the basis
for our speculative execution scheme. The application of the
transactions to create a fast path, while conceptually simple,
requires a large number of details to be addressed. First, as
noted by Shih et al. [45], forcing a program to execute entirely
within transactions introduces substantial challenges. Placing
each basic block from the program within a single transaction
introduces an overhead of roughly 8× native execution, and
transaction size is limited by cache size and associativity.
Further complicating matters, transactions may abort due to
asynchronous interrupts, are never guaranteed to commit, and
must be carefully started and committed to avoid nesting.
Second, our speculative native execution scheme requires
an efﬁcient mechanism to abort transactions that encounter
symbolic data. Ideally, individual bytes containing symbolic
values could be marked as inaccessible by the OS (e.g., via
page permissions) or a low-level hardware mechanism (e.g.,
via debug registers) so as to force any transaction accessing
the byte to roll back. Unfortunately, the large granularity of
page-level permissions and the scarcity of debug registers limit
the effectiveness of these solutions. Another option is to inject
instrumentation into the program to query a lookup table on
each byte access (cf., [11]); however this approach incurs a
performance penalty for additional read operations and com-
pare operations, may clobber the FLAGS register depending on
its implementation, and also impacts the number of operations
that may be placed within a single transaction. Sec. IV contains
our approach for overcoming these challenges.
IV. DESIGN
In this section, we outline the design of TASE. We begin by
describing the overall architecture of TASE, and follow with
descriptions of the system’s transactional execution; its poison
checking scheme for detecting memory accesses of symbolic
values; its method of interpretation; and its mechanisms for
managing state exploration.
A. Structure of TASE
In TASE, we provide a symbolic execution system designed
to rapidly symbolically execute user-space programs with
small amounts of symbolic data. At its core, TASE provides a
“fast path” and “slow path” for handling concrete and symbolic
operations, respectively, as it executes an application (hence-
forth referred to as the project). Fig. 1 shows a simpliﬁed
overview of these two primary components.
Fig. 1: High-level structure of TASE. TASE comprises compo-
nents labeled “TASE Compiler” and “TASE IR Generation”.
TASE generates a project executable containing native and
interpretable representations of the project source, and that
switches between these representations through a code trampo-
line to which control ﬂows after native execution of a project
basic block and after interpretation of a project basic block
that leaves no symbolic values in the emulated registers.
libraries it uses) produced by compiling the project’s source
code with our custom LLVM TASE compiler. Crucially, TASE
executes within this instrumented native execution path as the
rule rather than the exception. By instrumenting loads and
stores and inserting jumps to a code trampoline (cf., [32],
[45]) with transactional instructions around basic blocks, TASE
enables speculative native execution. TASE uses a poison (or
sentinel) value to mark bytes as containing symbolic values
while executing the project. While executing code natively
within a transaction, values read and overwritten are recorded
and checked en masse with SIMD instructions at the end of
a transaction. If the poison value was read or overwritten, the
transaction is aborted and all state changes performed during
the transaction are undone; details are provided in Sec. IV-B.
If TASE is unable to complete a transaction natively,
control transfers via a context switch from the trampoline to
the “slow path”, our KLEE-based interpreter. The interpreter
is responsible for executing the target binary until another
transactional entry point is reached, at which time the target’s
execution might begin again concretely. KLEE executes by in-
terpreting LLVM bitcode exclusively, whereas TASE switches
between instrumented native execution to efﬁciently execute
concrete operations and KLEE-style interpretation to handle
symbolic operations. Although KLEE normally runs on IR
generated directly from C code [10], TASE uses KLEE to
interpret through IR generated to represent x86 semantics;
more details on the mechanics of TASE’s interpretation are
provided in Sec. IV-D. Additionally, TASE differs from KLEE
in its use of processes (cf., [11]) to represent execution states
(see Sec. IV-E).
TASE requires C source code to execute a project, in-
cluding source code for any C libraries the project will use.
The “fast path” for native execution described earlier is an
instrumented, binary x86 version of the project (and any
Context switching between the interpreter and native ex-
ecution in TASE closely resembles that in S2E [18]. The
interpreter and native execution share a common address space,
and a context switch from native execution to the interpreter
4
LibrarySourceC Source Project jTASE CompilerInstrumented object filesProject and Library IRKLEE-Based InterpreterInterpreter StackInstrumented Project and Library CodeProject Native Execution StackConcrete/Symbolic Bitmap for Native ComponentsCode TrampolineProject ExecutableGlobalsHeapjTASE IR Generation0x0000000xffffffffNative ComponentsInterpreter ComponentsControl flowControl flowoccurs by snapshotting the current state of the general purpose
registers (GPRs). The interpreter then uses this snapshot to
model each x86 instruction’s effects on main memory and a
simulated copy of the GPRs, which is restored for concrete ex-
ecution after a transactional boundary is reached and symbolic
values no longer reside within the GPRs.
Symbolic data—including values used for altering control
ﬂow—are exclusively handled by the interpreter, which may
also fork state to explore new execution paths. Our forking
mechanism uses the native Unix fork system call to explore
execution paths, similar to the techniques used in EXE [11]; we
include more details in Sec. IV-E. We discuss the mechanisms
for detecting usage of symbolic data during native execution
in Sec. IV-C.
B. Transactional Execution
To mitigate the cost of interpreting instructions with con-
crete operands, TASE instead executes these instructions na-
tively within TSX transactions. Our strategy is to speculatively
execute the target program natively for as many transactions
as possible, and abort a transaction if an “unsafe” operation
occurs that requires special handling of symbolic data via
interpretation. TASE requires access to source code, and emits
instrumented machine code for the program along with the
symbolic execution components and interpreter in a single
executable.
In a previous work that executed software in transactions
for a different purpose, T-SGX [45] uses the Clang LLVM
back-end to conservatively estimate the read and write sets of
instructions and cache-way usage at compile time to efﬁciently
group together a large number of instructions in a single TSX
transaction. Their technique helps to maximize the number of
instructions in a transaction to amortize the overhead required
for setting up and committing or rolling back a transaction.
Unlike T-SGX, TASE does not statically determine the number
of instructions to place in a transaction. Our evaluation of
OpenSSL veriﬁcation (see Sec. VI-B) revealed the need to
efﬁciently instrument code that frequently included variable-
sized loops and function pointers, both of which make effective
compile-time instrumentation challenging. Using a custom
Clang LLVM back-end, TASE injects trampoline jumps around
basic blocks and dynamically determines the boundaries for
closing and opening a transaction at runtime.
For any transaction, let its stride denote the number of
basic blocks attempted within the transaction. In our present
implementation, we currently use a transactional batching
policy in which the stride of each transaction, by default, is
set to a constant smax; in our evaluation in Sec. VI, smax is
set to 16. If a transaction tx aborts, then one possibility would
be to trap to the interpreter and simply interpret through the
whole aborted transaction. However, a more reﬁned approach
that leverages the reason for the abort can optimize execution
considerably.