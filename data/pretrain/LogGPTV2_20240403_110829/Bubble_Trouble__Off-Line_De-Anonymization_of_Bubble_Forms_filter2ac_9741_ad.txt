evidence exists that these properties cannot still be dis-
tinguishing. In addition, an average might remove a re-
spondent’s intent, even when that intent may have been
clear to the scanner interpreting the form. Similar mit-
igation techniques involve blurring the image, reducing
the image resolution, or making the image strictly black
and white, all of which have similar disadvantages to av-
eraging colors.
One interesting approach comes from the facial image
recognition community. Newton et al. [23] describe a
method for generating k-anonymous facial images. This
technique replaces each face with a “distorted” image
that is k-anonymous with respect to faces in the input
set. The resulting k-anonymous image maintains the ex-
pected visual appearance, that of a human face. The ex-
act details are beyond the scope of this paper, but the
underlying technique reduces the dimensionality using
Principal Component Analysis and an algorithm for re-
moving the most distinctive features of each face [23].
Application of facial anonymization to bubbles is
straightforward. Taking marked and unmarked bubbles
from all ballots in a set, we can apply the techniques
of Newton et al. to each bubble, replacing it with its k-
anonymous counterpart. The result would roughly main-
tain the visual appearance of each bubble while removing
certain unique attributes. Unfortunately, this approach
is imperfect in this scenario. Replacement of an image
might hide a respondent’s otherwise obvious intent. In
addition, distinguishing trends might occur over multi-
ple bubbles on a form: for example, an individual might
mark bubbles differently near the end of forms (this is
also a problem for averaging the bubble colors). Fi-
nally, concerns exist over the guarantees provided by k-
anonymity [3], but the work may be extensible to achieve
other notions of privacy, such as differential privacy [9].
We caution that the value of these images for proving
the true contents of physical bubble forms is limited: an
adversary with access to the images, whether scrubbed
or not, could intentionally modify them to match a de-
sired result. These approaches are most useful where the
primary concern is unintentional error.
6 Related Work
Biometrics. Biometrics can be based on physical or
behavioral characteristics of an individual. Physical bio-
metrics are based on physical characteristics of a person,
such as ﬁngerprints, facial features, and iris patterns. Be-
havioral biometrics are based on behavioral characteris-
tics that tend to be stable and difﬁcult to replicate, such
as speech or handwriting/signature [15]. Bubble comple-
tion patterns are a form of behavioral biometric.
As a biometric, bubble completion patterns are simi-
lar to handwriting, though handwriting tends to rely on
a richer, less constrained set of available features. In ei-
ther case, analysis may occur on-line or off-line [21].
In an on-line process, the verifying party may monitor
characteristics like stroke speed and pressure. In an off-
line process, a verifying party only receives the resulting
data, such as a completed bubble. Handwriting-based
recognition sometimes occurs in an on-line setting. Be-
cause off-line recognition is more generally applicable,
our analysis occurred purely in an off-line manner.
In
some settings, such as authentication, on-line recogni-
tion would be possible and could yield stronger results.
Document re-identiﬁcation. Some work seeks to re-
identify a precise physical document for forgery and
counterfeiting detection (e.g., [7]). While the presence
of biometrics may assist in re-identiﬁcation, the prob-
lems discussed in this paper differ. We seek to discover
whether sets of marked bubbles were produced by the
same individual. Our work is agnostic towards whether
the sets come from the same form, different forms, or du-
plicates of forms. Nevertheless, our work and document
re-identiﬁcation provide complementary techniques. For
example, document re-identiﬁcation could help deter-
mine whether the bubble form (ballot, answer sheet, sur-
vey, etc.) provided to an individual matches the one
returned or detect the presence of fraudulently added
forms.
Cheating Detection. Existing work uses patterns in
answer choices themselves as evidence of cheating.
Myagkov et al. [20] uncover indicators of election fraud
using aggregate vote tallies, turnout, and historical data.
Similarly, analysis of answers on standardized tests can
be particularly useful in uncovering cheating [10, 17].
12
For example, if students in a class demonstrate mediocre
overall performance on a test yet all correctly answer a
series of difﬁcult questions, this may raise concerns of
cheating. The general strategy in this line of research is
to look for answers that are suspicious in the context of
either other answers or auxiliary data.
Bubble-based analysis is also complementary to these
anti-cheating measures. Each technique effectively iso-
lates sets of suspicious forms, and the combination of
the two would likely be more accurate than each inde-
pendently. Although our techniques alone do not exploit
contextual data, they have the advantage of being un-
biased by that data. If a student dramatically improves
her study habits, the resulting improvement in test scores
alone might be ﬂagged by other anti-cheating measures
but not our techniques.
7 Future Work
Although a variety of avenues for future work exist, we
focus primarily on possibilities for additional testing and
application-speciﬁc uses here.
Our sample surveys allowed a diverse set of tests, but
access to different datasets would enable additional use-
ful tests. We are particularly interested in obtaining and
using longitudinal studies—in which a common set of re-
spondents ﬁll out bubble forms multiple times over some
period—to evaluate our methods. While providing an
increased number of examples, this could also identify
how a respondent’s markings vary over time, establish
consistency over longer durations, and conﬁrm that our
results are not signiﬁcantly impacted by writing utensil.
Because bubble forms from longitudinal studies are not
widely available, this might entail collecting the data our-
selves.
While we tested our techniques using circular bubbles
with numbers inscribed, numerous other form styles ex-
ist.
In some cases, respondents instead ﬁll in ovals or
rectangles. In other cases, selection differs dramatically
from the traditional ﬁll-in-the-shape approach—for ex-
ample, the line-drawing approach discussed in Section 5
bears little similarity to our sample forms. Testing these
cases would not only explore the limits of our work but
could also help uncover mitigation strategies.
Section 4 discusses a number of applications of our
techniques. Adapting the techniques to work in these
scenarios is not always trivial. For example, Section 6
discusses existing anti-cheating techniques for standard-
ized tests. Combining the evidence provided by existing
techniques and ours would strengthen anti-cheating mea-
sures, but it would also require some care to process the
data quickly and merge results.
Use of bubble markings for authentication would re-
quire both additional testing and additional reﬁnement
of our techniques. Given a dataset containing on-line
information, such as writing instrument position, veloc-
ity, and pressure, we could add this data to our fea-
ture vectors and test the accuracy of our techniques with
these new features. This additional information could
increase identiﬁability considerably—signature veriﬁca-
tion is commonly done on-line due to the utility of this
data—and may yield an effective authentication system.
Depending on the application, a bubble-based authenti-
cation system would potentially need to work with a ﬁn-
ger rather than a pen or stylus. Because the task of ﬁll-
ing in a bubble is relatively constrained, this application
would require cautious testing to ensure that an adversary
cannot impersonate a legitimate user.
8 Conclusion
Marking a bubble is an extremely narrow task, but as
this work illustrates, the task provides sufﬁcient expres-
sive power for individuals to unintentionally distinguish
themselves. Using a dataset with 92 individuals, we
demonstrate how to re-identify a respondent’s survey
with over 50% accuracy.
In addition, we are able to
detect an unauthorized respondent with over 92% accu-
racy with a false positive rate below 10%. We achieve
these results while performing off-line analysis exclu-
sively, but on-line analysis has the potential to achieve
even higher rates of accuracy.
The implications of this study extend to any system
utilizing bubble forms to obtain user input, especially
cases for which protection or conﬁrmation of a respon-
dent’s identity is important. Additional tests can better
establish the threat (or beneﬁt) posed in real-world sce-
narios. Mitigating the amount of information conveyed
through marked bubbles is an open problem, and so-
lutions are dependent on the application. For privacy-
critical applications, such the publication of ballots, we
suggest that groups releasing data consider means of
masking respondents’ markings prior to publication.
Acknowledgements
We are grateful to Ian Davey, Deven Desai, Ari Feldman,
Adam Finkelstein, Joe Hall, Josh Kroll, Tim Lee, Szy-
mon Rusinkiewicz, Harlan Yu, and Bill Zeller for helpful
suggestions and assistance in conducting this research.
We thank Joel Trachtenberg, Jennifer Minsky, and Der-
rick Higgins for assistance in obtaining test data. We
thank Carolyn Crnich, Kevin Collins, and Mitch Tracht-
enberg of the Humboldt County Election Transparency
Project for discussing the implications of our work on
that project. We thank our anonymous reviewers and
shepherd, Claudia Diaz, for comments on the paper.
13
[21] NALWA, V. S. Automatic on-line signature veriﬁcation.
In
Proceedings of the Third Asian Conference on Computer Vision-
Volume I - Volume I (London, UK, 1997), ACCV ’98, Springer-
Verlag, pp. 10–15.
[22] NEW JERSEY LEGISLATURE. N.J.S.A. 19:4-13 (1976).
[23] NEWTON, E., SWEENEY, L., AND MALIN, B. Preserving pri-
IEEE Transactions on
vacy by de-identifying facial images.
Knowledge and Data Engineering 17 (2005), 232–243.
[24] PEURA, M., AND IIVARINEN, J. Efﬁciency of simple shape de-
scriptors. In In Aspects of Visual Form (1997), World Scientiﬁc,
pp. 443–451.
[25] PLATT, J. C. Sequential minimal optimization: A fast algorithm
for training support vector machines, 1998.
[26] U.S. DEPARTMENT OF HEALTH & HUMAN SERVICES.
guidebook. http://www.hhs.gov/ohrp/irb/irb guidebook.htm.
IRB
[27] VERIFIED VOTING
FOUNDATION.
http://www.veriﬁedvoting.org/veriﬁer/.
The
veriﬁer.
[28] WISCONSIN GOVERNMENT ACCOUNTABILITY BOARD.
http://gab.wi.gov/elections-
Spring 2011 election results.
voting/results/2011/spring.
References
[1] ALAMEDA
COUNTY,
Voting
CALIFORNIA.
County
http://www.acgov/org/rov/votingsystemdemo.htm.
System
Alameda
Demonstration.
[2] ASLAM, J. A., POPA, R. A., AND RIVEST, R. L. On esti-
In Proc.
mating the size and conﬁdence of a statistical audit.
2007 USENIX/ACCURATE Electronic Voting Technology Work-
shop (EVT ’07).
[3] BRICKELL, J., AND SHMATIKOV, V. The cost of privacy: De-
struction of data-mining utility in anonymized data publishing.
In Proc of the 14th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (August 2008).
[4] CALANDRINO, J. A., CLARKSON, W., AND FELTEN, E. W.
Some consequences of paper ﬁngerprinting for elections. In Pro-
ceedings of EVT/WOTE 2009 (Aug. 2009), D. Jefferson, J. L.
Hall, and T. Moran, Eds., USENIX/ACCURATE/IAVoSS.
[5] CALANDRINO, J. A., HALDERMAN, J. A., AND FELTEN,
In Proc. 2007
E. W. Machine-assisted election auditing.
USENIX/ACCURATE Electronic Voting Technology Workshop
(EVT ’07).
[6] CARBACK, R. How secret is your secret ballot? part 1 of 3: Pat-
tern voting. https://scantegrity.org/blog/2008/06/16/how-secret-
is-your-secret-ballot-part-1-of-3-pattern-voting/, June 16 2008.
[7] CLARKSON, W., WEYRICH,
FINKELSTEIN, A.,
HENINGER, N., HALDERMAN, J. A., AND FELTEN, E. W.
Fingerprinting blank paper using commodity scanners. In Proc
of IEEE Symposium on Security and Privacy (May 2009).
T.,
[8] COLLEGE
BOARD.
underscore
2010
importance
results
http://www.collegeboard.com/press/releases/213182.html.
college-bound
of
academic
seniors
rigor.
[9] DWORK, C. Differential privacy.
In Proc of the 33rd Inter-
national Colloquium on Automata, Language and Programming
(July 2006).
[10] GABRIEL, T. Cheaters ﬁnd an adversary in technology. New York
Times (December 27 2010).
[11] GABRIEL, T. Under pressure, teachers tamper with tests. New
York Times (June 10 2010).
[12] GARNER, S. R. Weka: The waikato environment for knowledge
analysis. In In Proc. of the New Zealand Computer Science Re-
search Students Conference (1995), pp. 57–64.
[13] GREENSON, T. Software glitch yields inaccurate election results.
Times-Standard (December 5 2008).
[14] HUMBOLDT COUNTY ELECTION TRANSPARENCY PROJECT.
http://www.humetp.org/.
[15] JAIN, A., HONG, L., AND PANKANTI, S. Biometric Identiﬁca-
tion. Communications of the ACM 43, 2 (February 2000), 91–98.
[16] JOLLIFFE, I. T. Principal Component Analysis, second ed.
Springer, October 2002.
[17] LEVITT, S. D., AND DUBNER, S. J. Freakonomics: A Rogue
Economist Explores the Hidden Side of Everything. Harper-
Collins, 2006.
[18] LOS
ANGELES
COUNTY
CLERK.
COUNTY
/
http://www.lavote.net/voter/pollworker/PDFS/INKAVOTE
PLUS HANDBOOK.pdf, 2011.
InkaVote
REGISTRAR-RECORDER
Plus Manual.
[19] MCCUTCHEON, C. Absentee voting fosters trickery, trend’s foes
say. Times Picayune (October 2006).
[20] MYAGKOV, M., ORDESHOOK, P. C., AND SHAKIN, D. The
Forensics of Election Fraud: Russia and Ukraine. Cambridge
University Press, 2009.
14