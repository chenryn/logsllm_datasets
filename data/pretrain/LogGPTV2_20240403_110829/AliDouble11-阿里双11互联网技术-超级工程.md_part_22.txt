1.以被动CDN方式从文件源下载文件并生成一组种子分块数据；
2.构造P2P网络并调度每个peer之间互传指定的分块数据。
Host上就存放着dfget，dfget的语法跟wget非常类似。主要功能包括文件下
载和P2P共享等。
在阿里内部我们可以用StarAgent来下发dfget指令，让一组机器同时下载文
188 > 9年双11：互联网技术超级工程
件，在某种场景下一组机器可能就是阿里所有的服务器，所以使用起来非常高效。除
了客户端外，蜻蜓还有Java SDK，可以让你将文件“PUSH”到一组服务器上。
下面这个图阐述了两个终端同时调用dfget，下载同一个文件时系统的交互示
意图：
蜻蜓P2P组网逻辑示意图
两个Host和CM会组成一个P2P网络，首先CM会查看本地是否有缓存，如
果没有，就会回源下载，文件当然会被分片，CM会多线程下载这些分片，同时会将
下载的分片提供给Host们下载，Host下载完一个分片后，同时会提供出来给peer
下载，如此类推，直到所有的Host全部下载完。
本地下载的时候会将下载分片的情况记录在metadata里，如果突然中断了下
载，再次执行dfget命令，会断点续传。
下载结束后，还会比对MD5，以确保下载的文件和源文件是完全一致的。蜻蜓
新基础  9年双11：互联网技术超级工程
1.传统模式随着客户端的增加，下载时长跟着增加，而dfget可以支撑到7000
客户端依然没变好。
2.传统模式到了1200客户端以后就没有数据了，因为数据源被打爆了。
从发布系统走向基础设施
2015年双11后，蜻蜓的下载次数就达到了12万/月，分发量4TB。当时在阿
里还有别的下载工具，如wget，curl，scp，ftp等等，也有自建的小规模文件分发
系统。我们除了全面覆盖自身发布系统外，也做了小规模的推广。到2016年双11
左右，我们的下载量就达到了1.4亿/月，分发量708TB，业务增长了近千倍。
2016年双11后我们提出了一个更高的目标，希望阿里大规模文件分发和大文
件分发90%的业务由蜻蜓来承担。
我希望通过这个目标锤炼出最好的P2P文件分发系统。此外也可以统一集团内
所有的文件分发系统。统一可以让更多的用户受益，但统一从来不是终极目标，统一
的目的是：1.减少重复建设；2.全局优化。
只要优化蜻蜓一个系统，全集团都能受益。比如我们发现系统文件是每天全网分
发的，而光这一个文件压缩的话就能给公司每天节省9TB网络流量。跨国带宽资源
尤其宝贵。而如果大家各用各的分发系统，类似这样的全局优化就无从谈起。
所以统一势在必行！
在大量数据分析基础上，我们得出全集团文件分发的量大概是3.5亿次/周，而
我们当时的占比只有10%不到。
经过半年努力，在2017年4月份，我们终于实现了这个目标，达到90%+的
业务占有率，业务量增长到3亿次/周（跟我们之前分析的数据基本吻合），分发量
977TB，这个数字比半年前一个月的量还大。
当然，不得不说这跟阿里容器化也是密不可分的，镜像分发流量大约占了一半。
下面我们就来介绍下蜻蜓是如何支持镜像分发的。在说镜像分发之前先说下阿里的容
器技术。
新基础  9年双11：互联网技术超级工程
需要注意的是：镜像层d2a0ecffe6fa中没有任何内容，也就是所谓的空镜像。
镜像是分层的，每层都有自己的ID和尺寸，这里有4个Layer，最终这个镜像
是由这些Layer组成。
Docker镜像是通过Dockerfile来构建，看一个简单的Dockerfile：
镜像构建过程如下图所示：
可以看到，新镜像是从base镜像一层一层叠加生成的。每安装一个软件，就在
现有镜像的基础上增加一层。
当容器启动时，一个可写层会被加载到镜像的顶层，这个可读可写层也被称为
“容器层”，容器层之下都是“镜像层”，都是只读的。
新基础  9年双11：互联网技术超级工程
以阿里云容器服务为例，传统的镜像传输如上图所示，当然这是最简化的一种架
构模式，实际的部署情况会复杂的多，还会考虑鉴权、安全、高可用等等。
从上图可以看出，镜像传输跟文件分发有类似的问题，当有一万个Host同时向
Registry请求时，Registry就会成为瓶颈，还有海外的Host访问国内Registry时
候也会存在带宽浪费、延时变长、成功率下降等问题。
下面介绍下Docker Pull的执行过程：
Docker镜像分层下载图
Docker Daemon调用Registry API得到镜像的Manifest，从Manifest中
能算出每层的URL，Daemon随后把所有镜像层从Registry并行下载到Host本
地仓库。
所以最终，镜像传输的问题变成了各镜像层文件的并行下载的问题。而蜻蜓擅长
的正是将每层镜像文件从Registry用P2P模式传输到本地仓库中。
那么具体又是如何做到的呢？
事实上我们会在Host上启动dfGet proxy，Docker/Pouch Engine的所有命
令请求都会通过这个proxy，我们看下图：
新基础  9年双11：互联网技术超级工程
2.不侵入容器技术内核（Docker Daemon， Registry）：也就是说不能改动容器
服务任何代码。
3.支持Docker，Pouch，Rocket ，Hyper等所有容器/虚拟机技术。
4.支持镜像预热：构建时就推送到蜻蜓集群CM。
5.支持大镜像文件：至少30GB。
6.安全
Native Docker V.S蜻蜓
我们一共做了两组实验：
实验一：1个客户端
1.测试镜像大小：50MB、200MB、500MB、1GB、5GB
2.镜像仓库带宽：15Gbps
3.客户端带宽：双百兆bit/s网络环境
4.测试规模：单次下载
单客户端不同模式对比图
新基础  9年双11：互联网技术超级工程
流量）的一个对比：
蜻蜓镜像分发出流量对比图