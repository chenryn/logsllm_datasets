taking place or not based only on its own information.
 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 50 100 150 200Feature AIterations-0.04-0.02 0 0.02 0.04 50 100 150 200Feature BIterationsWe use the classiﬁcation model as described in Section 4. To calculate the feature
set for the global case we take the median local error of each node in the system, i.e. for
1740 nodes in the simulation and for 500 nodes in the Internet PlanetLab testbed. The
acquired model is applied to three diﬀerent classiﬁers, namely the two decision trees,
SimpleCart [8] and C4.5 [29], and the support vector machines, LibSVM [1]. All ex-
periments for the simulator as well as for PlanetLab are evaluated using the Java source
code of weka [4]. We have tried all diﬀerent kernel functions and their correspond-
ing parameters for the LibSVM and because no signiﬁcant diﬀerences were relevant,
we decided to use the default values that come with this weka composant: C-SVC for
the kernel type, radial-basis kernel function, with the default values (degree in kernel
function was set to 3, gamma parameter to 0.5 and nu to 0.5).
To evaluate the results, we calculate the percentage of attack events that the classiﬁer
correctly classiﬁes, which we refer to as the true positive rate (TPR). We also calculate
the percentage of non-attack events that the classiﬁer incorrectly classiﬁes as attack
events, which we refer to as the false positive rate (FPR). We computed the TPR and
FPR using the well established 10-fold cross-validation scheme, where the system is
trained with randomly extracted 9
10 of the data. This
process is repeated 10 times for each classiﬁcation.
10 of the data, and tested with 1
5.1 Simulation Results
We conduct simulations using the King data set topology [18], as it is representative of
an Internet-wide deployment of a peer-to-peer system and has been used previously to
validate several other VCSes. The King data set consists of RTT measurements between
1740 nodes, of which the average RTT is 180ms. For each simulation, all nodes join in
a ﬂash-crowd sequence at the beginning of the simulation. The simulations last for 200
time units, where each time unit is 500 seconds. Each node independently chooses a
neighbor set of 64 nodes from which it receives coordinate updates.
Single Attack Strategies. We start by analyzing single attack scenarios, as deﬁned in
Section 3, where the following single attacks are classiﬁed: inﬂation, deﬂation, oscilla-
tion, frog-boiling, network-partition, and single-random. Table 1 shows the classiﬁca-
tion results. The data set consists of the ﬁrst 30% of the time where no attack occurs,
and the remaining 70% the attack does take place. This distribution of time intervals
was chosen because some amount of samples of normal data, without attacks, is needed
for training.
We note that for the decision trees, SimpleCart and C4.5, the TPR is, for all the
diﬀerent attacks, around 99%, and the FPR for the two classiﬁers is around 3%. This
means that these decision trees can classify correctly almost all entries. Furthermore,
while the number of attackers applying the given attack is increasing, the TPR remains
more or less the same, whereas the FPR increases most of the time. Out of this we see
that even though most attacks are still correctly classiﬁed, normal updates are classiﬁed
incorrectly more often. We also observe that in these cases support vector machines
perform badly, especially with regard to the FPR. In order to see to what degree decision
trees can detect a frog-boiling attack, we applied a ten-times slower frog-boiling attack
Table 1. p2psim - Single Attack Strategies - Classiﬁcation Results
Attack Strategy
Inﬂation
Deﬂation
Oscillation
Frog-Boiling
Network-Partition
Single-Random
C4.5
SimpleCart
LibSVM
TPR FPR TPR FPR TPR FPR
10% attackers 0.99 0.01 0.99 0.02 0.67 0.67
20% attackers 0.99 0.01 0.99 0.02 0.67 0.67
30% attackers 0.97 0.05 0.99 0.02 0.67 0.67
10% attackers 0.99 0.013 0.99 0.02 0.67 0.66
20% attackers 0.98 0.021 0.98 0.02 0.67 0.67
30% attackers 0.98 0.016 0.97 0.03 0.67 0.67
10% attackers 0.099 0.008 0.99 0.01 0.67 0.66
20% attackers 0.98 0.02 0.99 0.03 0.67 0.67
30% attackers 0.98 0.020 0.98 0.030 0.67 0.67
10% attackers 0.99 0.011 0.99 0.013 0.68 0.64
20% attackers 0.99 0.016 0.98 0.03 0.67 0.67
30% attackers 0.98 0.025 0.98 0.03 0.67 0.67
10% attackers 0.99 0.01 0.98 0.014 0.79 0.44
20% attackers 0.99 0.01 0.99 0.01 0.67 0.67
30% attackers 0.99 0.006 0.98 0.03 0.67 0.67
10% attackers 0.99 0.02 0.98 0.03 0.67 0.67
20% attackers 0.99 0.003 0.98 0.02 0.67 0.67
30% attackers 0.99 0.002 0.99 0.02 0.67 0.67
Table 2. p2psim - Complex Scenarios - Classiﬁcation Results
(a) Two Attack Scenario
Attack Strategy
C4.5
SimpleCart
LibSVM
TPR FPR TPR FPR TPR FPR
10% attackers 0.95 0.05 0.94 0.05 0.58 0.41
20% attackers 0.96 0.05 0.95 0.05 0.51 0.47
30% attackers 0.98 0.02 0.97 0.03 0.52 0.49
10% attackers 0.97 0.04 0.97 0.04 0.51 0.48
20% attackers 0.97 0.03 0.96 0.04 0.50 0.49
30% attackers 0.96 0.04 0.97 0.03 0.51 0.49
10% attackers 0.95 0.05 0.97 0.03 0.67 0.34
20% attackers 0.91 0.09 0.93 0.07 0.54 0.46
30% attackers 0.90 0.10 0.92 0.08 0.55 0.45
Deﬂation -
Boiling
Oscillation -
Inﬂation
Network-Partition -
Oscillation
C4.5
(b) Sequence Attack Scenario
SimpleCart
LibSVM
TPR FPR TPR FPR TPR FPR
A 0.93 0.43 0.94 0.42 0.93 0.86
B 0.96 0.48 0.97 0.33 0.95 0.76
C 0.97 0.08 0.97 0.05 0.79 0.72
D 0.97 0.05 0.98 0.02 0.73 0.73
E 0.98 0.02 0.99 0.02 0.53 0.46
F 0.97 0.04 0.98 0.02 0.7 0.3
as well as hundred-times and thousand times slower and evaluated. We obtained also
for this case a very good performance as result, for 10%, 20%, and 30% of malicious
peers we achieve always a true positive rate around 98% and a false positive rate around
2%.
Complex Attack Scenarios. We now investigate more complex sequences of attacks,
speciﬁcally the two attack and sequence attack scenarios as deﬁned in Section 3.2.
Table 2(a) describes the classiﬁcation results regarding the two attack scenario. It can be
seen that the TPR for both decision trees (i.e., SimpleCart and C4.5) is less than for the
single attack scenarios and the FPR is in comparison a bit higher. Overall, the decision
trees perform well, although the results are not as good as the single attack scenario. In
comparison, the support vector machine library seems to ameliorate, especially in the
context of the FPR for the “Network-Partition - Oscillation” attack sequence.
Furthermore, we produced diﬀerent sequence-examples with the assessed Markov
chain. Table 2(b) illustrates that all techniques have a very good TPR, whereas the
FPRs diﬀer signiﬁcantly. We ﬁnd that the diﬀerence lies in the amount of non-attacking
intervals that each sequence has. Sequences A and B are in the group with only a small
amount of non-attacking intervals - 10 and 15 intervals. The high FPR thus results due
to the classiﬁer not having enough training data for learning normal behavior. The two
other groups show better results, for example, as sequences C and D have 45 and 55
normal intervals, respectively. Sequences E and F have in this case a quite high value
of non-attacking intervals, both have 100 of them, so exactly half of the data set is
non-attacking. We can deduce then that having only 5% non-attacking training data is
deﬁnitely not enough, whereas 25% already shows good results. This outcome can be
explained by the need for an heterogeneous training set for the decision trees; thus if we
have less “No attack” time intervals, it is diﬃcult for the classiﬁer to learn what normal
behavior is.
Comparison with Outlier Detection. In previous sections we showed that our clas-
siﬁcation techniques work well when applied globally. Nevertheless, previous works
proposed mitigation techniques with respect to single nodes, even if only eﬀective for
inﬂation, deﬂation, and oscillation attacks. In particular, in the work from [37], each
node independently decides if an update should be considered malicious or not by using
spatial-temporal outlier detection. We compare our method, applied in a local manner
where each node will classify attacks based only on its local information, with the work
from [37], referred to as Outlier Detection in the remainder of the section. As this eval-
uation depends on the amount of updates those individual nodes receive, we observed
some variety in the classiﬁcation results. We illustrate the local classiﬁcation results
when there are 10% malicious nodes and for ﬁfty randomly chosen benign nodes since
this allows us to have a statistical overview over the whole data set. Based on these
ﬁfty nodes we create box-and-whisker diagrams, as those show the median values, the
25th and 75th percentiles, and the minimal and maximal value of each data set. These
diagrams are shown in Figure 6 and in Figure 7. We show results only for the C4.5
technique as it has a similar performance with SimpleCart, while being more relevant
in recent research, and it outperforms LibSVM.
With respect to Figure 6 we note that for all the diﬀerent cases of attack strategies
considered, the classiﬁcation technique performs better than Outlier Detection. In Fig-
ure 6(a), we see that Outlier Detection performs best for the inﬂation attack, and we see
that frog-boiling has worse results. This is due to the fact that Outlier Detection can not
handle frog-boiling as explained and shown in [10, 11]. Regarding Figure 7 we note
that for all the diﬀerent attack strategies, our classiﬁcation technique has much better
median FPRs than the Outlier Detection.
5.2 PlanetLab Results
To validate our ﬁndings over the real Internet, we implemented Vivaldi and deployed it
on PlanetLab. For our experiments we used 500 nodes, chosen from all over the world,
from which the average RTT is 164ms. Each experiment was run for 30 minutes, while
all other settings were the same as in the simulations. To ﬁnd the eﬀectiveness of our
techniques, we apply in our PlanetLab experiments the same attacks and sequences as
in the simulations on p2psim.
(a) OD - Single attacks
(b) OD - Two attacks
(c) OD - Sequences
(d) C4.5 - Single-attacks
(e) C4.5 - Two Attacks
(f) C4.5 - Sequences
Fig. 6. p2psim - Outlier Detection Comparison (OD) -TPR
(a) OD - Single attacks
(b) OD - Two attacks
(c) OD - Sequences
(d) C4.5 - Single-attacks
(e) C4.5 - Two Attacks
(f) C4.5 - Sequences
Fig. 7. p2psim - Outlier Detection Comparison (OD) -FPR
 0 0.2 0.4 0.6 0.8 1Boil.Defl.Osc.Infl.Part.Ran. 0 0.2 0.4 0.6 0.8 1Defl/BoilOsc/InflPart/Osc 0 0.2 0.4 0.6 0.8 1ABCDEF 0 0.2 0.4 0.6 0.8 1Boil.Defl.Osc.Infl.Part.Ran. 0 0.2 0.4 0.6 0.8 1Defl/BoilOsc/InflPart/Osc 0 0.2 0.4 0.6 0.8 1ABCDEF 0 0.2 0.4 0.6 0.8 1Boil.Defl.Osc.Infl.Part.Ran. 0 0.2 0.4 0.6 0.8 1Defl/BoilOsc/InflPart/Osc 0 0.2 0.4 0.6 0.8 1ABCDEF 0 0.2 0.4 0.6 0.8 1Boil.Defl.Osc.Infl.Part.Ran. 0 0.2 0.4 0.6 0.8 1Defl/BoilOsc/InflPart/Osc 0 0.2 0.4 0.6 0.8 1ABCDEFSingle Attack Strategies.
In Table 3 the results for the single attack scenarios are
illustrated, from which one can observe that for both decision trees the TPR and FPR
are very good, which is similar to the simulation results. However, in the PlanetLab
testbed we obtain much better results when applying the support vector machines.
Table 3. PlanetLab - Single Attack Strategies - Classiﬁcation Results
Attack Strategy
Inﬂation
Deﬂation
Oscillation
Frog-Boiling
Network-Partition
Single-Random
C4.5
SimpleCart
LibSVM
TPR FPR TPR FPR TPR FPR
10% attackers 0.97 0.04 0.97 0.03 0.90 0.20
20% attackers 0.95 0.08 0.95 0.08 0.91 0.17
30% attackers 0.97 0.05 0.99 0.01 0.93 0.14
10% attackers 0.99 0.02 0.98 0.2 0.90 0.21
20% attackers 0.96 0.05 0.95 0.07 0.92 0.16
30% attackers 0.97 0.05 0.98 0.03 0.93 0.13
10% attackers 0.99 0.02 0.99 0.01 0.95 0.10
20% attackers 0.99 0.02 0.99 0.02 0.95 0.11
30% attackers 0.99 0.02 0.99 0.02 0.95 0.09
10% attackers 0.96 0.05 0.97 0.04 0.80 0.21
20% attackers 0.97 0.04 0.98 0.03 0.85 0.15
30% attackers 0.97 0.05 0.98 0.04 0.86 0.15
10% attackers 0.93 0.10 0.93 0.07 0.83 0.17
20% attackers 0.96 0.04 0.97 0.03 0.79 0.21