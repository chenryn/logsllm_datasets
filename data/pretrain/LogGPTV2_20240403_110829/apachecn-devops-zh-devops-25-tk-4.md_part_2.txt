 1  ...
 2  var (
 3    histogram = prometheus.NewHistogramVec(prometheus.HistogramOpts{
 4      Subsystem: "http_server",
 5      Name:      "resp_time",
 6      Help:      "Request response time",
 7    }, []string{
 8      "service",
 9      "code",
10      "method",
11      "path",
12    })
13  )
14  ...
```
我们定义了一个包含普罗米修斯直方图向量的变量，它有几个选项。`Sybsystem`和`Name`构成基本度量`http_server_resp_time`。由于是直方图，最终的度量将通过添加`_bucket`、`_sum`和`_count`后缀来创建。
Please consult *histogram* ([https://prometheus.io/docs/concepts/metric_types/#histogram](https://prometheus.io/docs/concepts/metric_types/#histogram)) documentation for more info about that Prometheus' metric type.
最后一部分是一个字符串数组(`[]string`)，它定义了我们想要添加到度量中的所有标签。在我们的例子中，这些标签是`service`、`code`、`method`和`path`。标签可以是我们需要的任何东西，只要它们提供了我们在查询这些指标时可能需要的足够信息。
下一个兴趣点是`recordMetrics`功能。
```
 1  ...
 2  func recordMetrics(start time.Time, req *http.Request, code int) {
 3    duration := time.Since(start)
 4    histogram.With(
 5      prometheus.Labels{
 6        "service": serviceName,
 7        "code":    fmt.Sprintf("%d", code),
 8        "method":  req.Method,
 9        "path":    req.URL.Path,
10      },
11    ).Observe(duration.Seconds())
12  }
13  ...
```
我将它创建为一个助手函数，可以从代码中的不同位置调用。它接受`start`时间、`Request`和返回`code`作为参数。该函数本身通过用`start`时间减去当前`time`来计算`duration`。`duration`用于`Observe`功能中，并提供公制的值。还有一些标签可以帮助我们在以后微调我们的表达方式。
最后，我们来看一个调用`recordMetrics`的例子。
```
 1  ...
 2  func HelloServer(w http.ResponseWriter, req *http.Request) {
 3    start := time.Now()
 4    defer func() { recordMetrics(start, req, http.StatusOK) }()
 5    ...
 6  }
 7  ...
```
`HelloServer`功能是返回您已经多次看到的`hello, world!`响应的功能。该功能的细节并不重要。在这种情况下，唯一重要的部分是台词`defer func() { recordMetrics(start, req, http.StatusOK) }()`。在 Go 中，`defer`允许我们在函数的末尾执行它所驻留的东西。在我们的例子中，那就是调用`recordMetrics`函数来记录请求的持续时间。换句话说，在执行离开`HelloServer`功能之前，它将通过调用`recordMetrics`功能来记录持续时间。
我不会深入讨论包含插装的代码，因为这将假设您对 go 背后的复杂性感兴趣，并且我试图保持这本书的语言不可知。我会让你查阅你最喜欢的语言的文档和例子。相反，我们将看看`go-demo-5`仪表化的度量标准在起作用。
```
 1  kubectl -n metrics \
 2      run -it test \
 3      --image=appropriate/curl \
 4      --restart=Never \
 5      --rm \
 6      -- go-demo-5.go-demo-5:8080/metrics
```
我们基于`appropriate/curl`映像创建了一个 Pod，并使用地址`go-demo-5.go-demo-5:8080/metrics`通过服务发送了一个请求。第一个`go-demo-5`是服务的名称，第二个是它所在的名称空间。结果，我们得到了该应用中所有可用的测量指标的输出。我们不一一介绍，只介绍`http_server_resp_time`直方图创建的那些。
输出的相关部分如下。
```
...
# HELP http_server_resp_time Request response time
# TYPE http_server_resp_time histogram
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.005"} 931
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.01"} 931
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.025"} 931
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.05"} 931
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.1"} 934
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.25"} 935
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="0.5"} 935
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="1"} 936
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="2.5"} 936
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="5"} 937
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="10"} 942
http_server_resp_time_bucket{code="200",method="GET",path="/demo/hello",service="go-demo",le="+Inf"} 942
http_server_resp_time_sum{code="200",method="GET",path="/demo/hello",service="go-demo"} 38.87928942600006
http_server_resp_time_count{code="200",method="GET",path="/demo/hello",service="go-demo"} 942
...
```
我们可以看到，我们在应用代码中使用的 Go 库从`http_server_resp_time`直方图中创建了相当多的指标。十二个桶中的每一个都有一个(T1)，一个是持续时间的总和(T2)，一个是计数(T3)。如果我们提出具有不同标签的请求，我们会有更多。目前，这 14 个指标都来自于用 HTTP 代码`200`响应的请求，使用`GET`方法，发送到`/demo/hello`路径，并且来自于`go-demo`服务(应用)。如果我们用不同的方法(例如，`POST`)或不同的路径创建请求，度量的数量将会增加。类似地，如果我们在其他应用中实现相同的仪表化指标(但是使用不同的`service`标签)，我们将拥有具有相同关键字(`http_server_resp_time`)的指标，这些指标将提供对多个应用的洞察。这就提出了一个问题，即我们是否应该在所有应用中统一指标名称。
我更喜欢在所有应用中使用具有相同名称的相同类型的测量指标。比如所有收集响应时间的都可以称为`http_server_resp_time`。这简化了普罗米修斯中的数据查询。不是从每个单独的应用中学习仪表化度量，而是从一个应用中学习这些度量来提供关于所有应用的知识。另一方面，我赞成让每个团队完全控制他们的应用。这包括决定实现哪些指标，以及如何调用它们。
总而言之，这取决于团队的结构和职责。如果一个团队完全负责他们的应用，并且他们调试特定于他们的应用的问题，那么就没有内在的需求来标准化检测度量的名称。另一方面，如果监控是集中的，并且其他团队可能希望得到该领域专家的帮助，那么创建命名约定是必须的。否则，我们很容易得到成千上万个不同名称和类型的指标，即使它们中的大多数都提供了相同的信息。
对于本章的其余部分，我将假设我们确实同意在所有应用中使用`http_server_resp_time`直方图，如果适用的话。
现在，让我们看看如何告诉普罗米修斯，它应该从`go-demo-5`应用中提取指标。如果我们能告诉普罗米修斯从所有装有度量工具的应用中提取数据，那就更好了。实际上，现在当我考虑它的时候，我们还没有讨论普罗米修斯是如何在前一章找到节点导出器和库贝状态度量的。所以，让我们简单地回顾一下这个发现过程。
一个很好的起点是普罗米修斯的目标屏幕。
```
 1  open "http://$PROM_ADDR/targets"
```
最有趣的一组目标是`kubernetes-service-endpoints`。如果我们仔细看一下标签，我们会发现每个标签都有`kubernetes_name`，其中三个目标设定为`go-demo-5`。普罗米修斯不知何故发现我们有三个应用的副本，并且可以通过端口`8080`获得指标。如果我们看得更远，我们会注意到`prometheus-node-exporter`也在那里，集群中的每个节点都有一个。
`prometheus-kube-state-metrics`也是如此。那群人中可能还有其他人。
![](img/a36dd797-57ba-4cf7-bc6c-8da9161fd59c.png)
Figure 4-3: kubernetes-service-endpoints Prometheus' targets
普罗米修斯通过 Kubernetes 服务发现了所有目标。它从每个服务中提取端口，并假设数据可通过`/metrics`端点获得。因此，我们在集群中的每一个可以通过 Kubernetes 服务访问的应用都被自动添加到普罗米修斯目标的`kubernetes-service-endpoints`组中。我们没有必要篡改普罗米修斯的配置来增加 T2。它刚刚被发现。很整洁，不是吗？
In some cases, some of the metrics will not be accessible, and that target will be marked as red. As an example, `kube-dns` in minikube is not reachable from Prometheus. That's common, and it's not a reason to be alarmed, just as long as that's not one of the metric sources we do need.
接下来，我们将快速查看一些我们可以使用来自`go-demo-5`的工具化度量来编写的表达式。
```
 1  open "http://$PROM_ADDR/graph"
```
请输入下面的表达式，按下执行按钮，切换到*图形*选项卡。
```
 1  http_server_resp_time_count
```
我们可以看到三行对应`go-demo-5`的三个副本。这不足为奇，因为这些都是从应用的每个副本的检测度量中提取的。因为这些指标是只能增加的计数器，所以图表的线条在不断上升。
![](img/17add48b-f7c5-4e29-90e6-43dcf3919682.png)
Figure 4-4: The graph with the http_server_resp_time_count counter
那不是很有用。如果我们对请求计数的速率感兴趣，我们会将前面的表达式封装在`rate()`函数中。我们稍后再做。现在，我们将编写最简单的表达式，给出每个请求的平均响应时间。
请键入下面的表达式，然后按“执行”按钮。
```
 1  http_server_resp_time_sum{