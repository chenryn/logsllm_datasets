title:QoE Doctor: Diagnosing Mobile App QoE with Automated UI Control
and Cross-layer Analysis
author:Qi Alfred Chen and
Haokun Luo and
Sanae Rosen and
Zhuoqing Morley Mao and
Karthik Iyer and
Jie Hui and
Kranthi Sontineni and
Kevin Lau
QoE Doctor: Diagnosing Mobile App QoE with Automated
UI Control and Cross-layer Analysis
Qi Alfred Chen, Haokun Luo, Sanae Rosen, Z. Morley Mao,
Karthik Iyer†, Jie Hui†, Kranthi Sontineni†, Kevin Lau†
University of Michigan, †T-Mobile USA Inc.1
{alfchen,haokun,sanae,zmao}@umich.edu,
†{karthik.iyer,jie.hui,kranthi.sontineni1,kevin.lau}@t-mobile.com
ABSTRACT
1.
INTRODUCTION
Smartphones have become increasingly prevalent and important in
our daily lives. To meet users’ expectations about the Quality of
Experience (QoE) of mobile applications (apps), it is essential to
obtain a comprehensive understanding of app QoE and identify
the critical factors that affect
it. However, effectively and
systematically studying the QoE of popular mobile apps such as
Facebook and YouTube still remains a challenging task, largely
due to a lack of a controlled and reproducible measurement
methodology, and limited insight into the complex multi-layer
dynamics of the system and network stacks.
In this paper, we propose QoE Doctor, a tool that supports
accurate, systematic, and repeatable measurements and analysis of
mobile app QoE. QoE Doctor uses UI automation techniques to
replay QoE-related user behavior, and measures the user-perceived
latency directly from UI changes. To better understand and analyze
QoE problems involving complex multi-layer interactions, QoE
Doctor supports analysis across the application, transport, network,
and cellular radio link layers to help identify the root causes. We
implement QoE Doctor on Android, and systematically quantify
various factors that impact app QoE, including the cellular radio
link layer technology, carrier rate-limiting mechanisms, app design
choices and user-side conﬁguration options.
Categories and Subject Descriptors
C.4 [Performance of Systems]: [Measurement techniques]; C.2.1
[Computer-Communication Networks]: Network Architecture
and Design—Wireless communication
General Terms
Design, Measurement, Performance
Keywords
Quality of Experience (QoE); UI Automation; Cross-layer
Analysis; Mobile Applications; Cellular Network
1The views presented in this paper are as individuals and do not
necessarily reﬂect any position of T-Mobile.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’14, November 5–7, 2014, Vancouver, BC, Canada.
Copyright 2014 ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663726.
As smartphones become more prevalent, mobile applications
(apps) become increasingly important to our daily lives, providing
access to information, communication, and entertainment. Users
would like apps to respond quickly to their requests, consume
less mobile data to reduce their monthly bill, and consume less
energy to ensure sufﬁcient battery life. The degree to which apps
meet these user expectations is referred to as QoE (Quality of
Experience). Ensuring good QoE is crucial for app developers,
carriers, and phone manufacturers to sustain their revenue models;
thus it is essential to obtain a comprehensive understanding of app
QoE and the critical factors that affect QoE.
However,
it remains a challenging task to effectively and
systematically study the QoE of popular mobile apps, such as
Facebook and YouTube. Prior work were relied on user studies
or app logs to evaluate QoE through subjective metrics such as
user experience scores and user engagement [20, 24, 23, 18, 17],
but these experiments are either costly in human effort or less able
to control user behavior variations. To overcome these limitations,
Prometheus [15] measures objective QoE metrics, such as the video
rebuffering ratio, to eliminate the dependence on user behavior, but
it requires the application source code to log UI events, limiting
its applicability. Besides the methodology, another challenge is
that mobile app QoE is affected by factors at many layers of the
system and the network. For example, on cellular networks, the
radio link layer state machine transition delay can lead to longer
round-trip times, and thus increase user-perceived latency [35, 34].
These multi-layer dynamics and their inter-dependencies further
complicate QoE analysis.
To address these challenges, we design a tool called QoE Doctor
to support more accurate, systematic, and repeatable measurements
and analysis of mobile app QoE. QoE Doctor uses UI automation
techniques to replay user behavior such as posting a status on
Facebook, and at the same time measures the application-layer
user-perceived latency directly through UI changes on the screen.
Our tool does not require access to the application source code, or
modiﬁcations to the app logic or the underlying system, making
it applicable to QoE measurements of popular apps.
In addition
to QoE measurements, QoE Doctor supports cross-layer analysis
covering the application layer, transport layer, network layer, and
radio link layer, in order to understand the root causes of poor QoE
caused by network activities and device-speciﬁc operations.
We implement QoE Doctor on the Android platform, and
systematically measure and analyze various QoE metrics in popular
Android apps, including Facebook’s post upload time and pull-
to-update time, the initial loading time and rebuffering ratio in
YouTube videos, and the web page loading time in popular
Android browsers. We quantitatively evaluate the important factors
151impacting these QoE metrics, for example network conditions,
application and carrier. Some of our key ﬁndings are:
3G
• Network latency is not always on the critical path of the end-
to-end user-perceived latency, such as when posting a status
on Facebook.
• Changing one Facebook default conﬁguration can reduce
over 20% of mobile data and energy consumption.
• Carrier rate limiting policies can increase video loading time
by more than 30 seconds (15×) and increase the rebuffering
ratio from almost 0% to 50%.
• YouTube ads reduce the initial loading time of the main
video, but on cellular networks the total loading time is
doubled.
• The ListView version Facebook reduces device latency by
more than 67% (compared to the WebView version), network
latency by more than 30%, and downlink data consumption
by more than 77%.
• Simplifying the 3G RRC state machine can reduce web page
loading time by 22.8% for web browsing apps.
Our contributions in this paper are summarized as follows:
• To enable automated and repeated QoE data collection for
mobile apps, we design a QoE-aware UI controller, which is
able to replay QoE-related user interaction sequences on popular
Android apps and directly measure user-perceived latency through
UI changes.
• We design a multi-layer QoE analyzer, which provides
visibility across the application layer,
transport layer, network
layer, and radio link layer, helping us systematically diagnose QoE
problems and identify the root causes.
• We use QoE Doctor to measure QoE metrics in popular
Android apps, and quantify how various important factors impact
these QoE metrics.
For the rest of the paper, we ﬁrst provide background information
in §2 and a overview of QoE Doctor in §3.
In §4 and §5,
we describe two major parts of QoE Doctor: a QoE-aware UI
controller and a multi-layer QoE analyzer respectively, and §6
summarizes the current tool limitations. In §7 we use QoE Doctor
to systematically study various factors impacting mobile app QoE.
We summarize related work in §8, and conclude the paper in §9.
2. BACKGROUND
QoE (Quality of
Subjective and objective QoE metrics.
Experience) refers to the metrics end users use to judge the quality
of services they receive, such as web browsing, phone calls or
TV broadcasts. There is a strong incentive for these services to
maintain and improve QoE, as it is essential to their continued
ﬁnancial success. To assess the QoE perceived by the end users,
one approach is to ask users to score the service experience,
which we call a subjective QoE metric. Another approach is to
directly measure service performance metrics that are related to
user satisfaction, such as the number of stalls when watching a
video, which we call objective QoE metrics. Much of the previous
work in this area [20, 42, 17, 24, 18] has focused on subjective
metrics. However, subjective evaluations usually require user
studies that are hard to repeat and automate, and may be hard to
reproduce due to varying user behavior. Thus, in this paper we
focus on objective QoE metrics.
RRC/RLC. In order to understand the root causes of QoE problems
on mobile devices,
it is important to understand how various
performance problems in the network stack can affect app QoE. Of
particular interest are the RRC (Radio Resource Control) radio link
DCH
High Power
FACH
Med. Power
PCH
Low Power
LTE
Continuous
Reception
Short
DRX
Long
DRX
CONNECTED
(High Power)
IDLE_CAMPED
Low Power
Promotion
Demotion
Figure 1: 3G and LTE RRC state machine overview.
layer control plane messages used by the base station1 to coordinate
with the device. RRC state behavior has a signiﬁcant impact on app
performance and power consumption [22, 33, 40, 41].
Typically, 3G has three main RRC states: DCH, FACH and PCH;
and LTE has CONNECTED and IDLE_CAMPED as shown in
Fig. 1. DCH and CONNECTED are high-power, high-bandwidth
states with dedicated communication channels, and PCH and
IDLE_CAMPED are low-power states with no data-plane radio
communication. FACH is an intermediate state with a lower-
bandwidth shared communication channel. The device promotes
from a low-power state to a high-power state if there is a data
transfer, and demotes from high-power state to low-power state
when a demotion timer expires.
We also examine the layer 2 data plane protocol, RLC (Radio
Link Control) [14] . The smallest data transmission unit in RLC
is called a PDU (Protocol Data Unit). For 3G uplink trafﬁc, the
PDU payload size is ﬁxed at 40 bytes, while for 3G downlink trafﬁc
and all LTE trafﬁc the size is ﬂexible and usually greater than 40
bytes. As shown in Fig. 2, an ARQ (automatic repeat request)
mechanism is used for reliable data transmission, which is similar
to the TCP group acknowledgement mechanism but triggered by a
polling request piggybacked in the PDU header.
3. OVERVIEW
In this paper, we develop a tool named QoE Doctor to support
automated and repeated measurements of objective QoE metrics
for popular mobile apps directly from the user’s perspective, as
well as systematically study various factors inﬂuencing these QoE
metrics across multiple mobile system and network layers. In this
section, we ﬁrst introduce the target QoE metrics, and then provide
an overview of the tool design.
3.1 QoE Metrics
In this paper, we study three important objective mobile app QoE
metrics that directly inﬂuence user experience:
• User-perceived latency. This application-level QoE metric
is deﬁned as the time that users spend waiting for a UI response
from the app. This includes the web page loading time in web
browsers, the post upload time in social apps, and the stall time in
video streaming apps.
• Mobile Data consumption. On mobile platforms, cellular
network data can be expensive if a data limit is exceeded. Thus, for
end users mobile data consumption is an important component of
mobile app QoE [23].
• Energy consumption. Smartphones are energy-constrained
thus energy efﬁciency is a desired feature in mobile
devices,
1known as the Node B for 3G and the eNodeB for LTE
152Node B
Poll Request
STATUS PDU
UE
1
2
1
QoE-aware UI controller
Multi-layer QoE analyzer
UI
controller
App-specific
QoE-related
behavior
control
QoE-
related UI
logger
Network
logger
RRC/RLC
logger
Application layer
QoE analyzer
Cross-layer analyzer
Transport/network layer
QoE analyzer
Cross-layer analyzer
RRC/RLC layer
QoE analyzer
Re-signed
APK file
Control
configuration
Figure 2: RLC PDU transmission
with ARQ-based group acknowledg-
ment mechanism
Figure 3: QoE Doctor design overview
In particular, we focus on the network energy
apps [23].
consumption of mobile apps since it consumes a large share of the
total device energy [19] and it is strongly inﬂuenced by app design
choices [35, 32].
Among these 3 metrics, user-perceived latency is the most
direct way for mobile end users to judge app performance. Thus,
it is the main focus of this paper. Unlike previous work [39,
15, 47], our measurement approach (described in §4) directly
calculates the latency from user’s perspective — the UI layer,
without requiring application source code or any OS/application
logic instrumentation, which enables us to study this QoE metric
broadly on any popular mobile apps of interest.
The other
two QoE metrics, mobile data and energy
consumption, are more mobile platform speciﬁc. Unlike previous
work [43, 30, 35, 34], our analysis is driven by automatically
replaying user behavior from the application layer. This enables us
to study these QoE metrics from the user’s perspective, and repeat
experiments in a controlled manner.
3.2 Tool Design Overview
Fig. 3 shows the design of QoE Doctor.
It includes 2 major
components: a QoE-aware UI controller and a multi-layer QoE
analyzer.
QoE-aware UI controller. This component runs online on the
mobile device, and uses UI control techniques to drive Android
apps to automatically replay user behavior traces, while collecting
the corresponding QoE data at the application layer, the transport
layer, the network layer, and the cellular radio link layer. This
allows us to efﬁciently collect QoE data, and enables controlled
QoE measurements without depending on varying user behavior.
Unlike previous work [15], our UI control technique does not
require access to application source code. Thus, QoE Doctor is
able to support QoE analysis for popular Android apps such as
Facebook and YouTube. At the UI layer, to accurately collect user-
perceived latency data, our UI controller supports direct access to
the UI layout tree. UI layout tree describes the app UI on the screen
in real time and thus can be used to accurately record the time a UI
change is made. We use tcpdump to collect network data, and a
cellular radio link layer diagnosing tool from Qualcomm to collect
radio link layer control plane (RRC) and data plane (RLC) data.
Multi-layer QoE analyzer. The collected QoE data are processed
and analyzed ofﬂine in this component with multi-layer visibility.
At the UI layer, user-perceived latency is calculated using the
timestamps of each QoE-related UI event. At the transport and
network layers, TCP ﬂow analysis is used to separate network
behaviors from different apps based on DSN requests and TCP ﬂow
data content. TCP ﬂow analysis is also used to compute mobile
data consumption corresponding to the QoE-related user behavior
in the application layer. Mobile energy consumption is estimated
based on the cellular network behavior according to the RRC state
recorded in the radio link layer tool log. To more deeply analyze
the QoE measurement results, our analyzer supports cross-layer
mapping between the UI layer and the transport/network layer, and
between the transport/network layer and the RRC/RLC layer. This
allows us to better understand how user actions in the UI layer are
delayed by the network trafﬁc, and helps us identify the potential
bottleneck in the cellular radio link layer that limits the TCP/IP data
transmission speed.
4. QOE-AWARE UI CONTROLLER
In this section, we describe how QoE-related user behavior is
automatically replayed and how the corresponding data is collected
in QoE Doctor’s QoE-aware UI controller.
4.1 Application control
As shown in Fig. 3, the QoE data collection in QoE Doctor is
driven by a UI controller. This component initiates UI interactions
such as button clicks, and thus controls the app automatically to
perform user behaviors of interest. It eliminates human effort, and
allows the same set of standardized user interactions to be replayed
each time. In our implementation on Android, we control the app
UI through the InstrumentationTestCase API [2] provided by the
Android system for UI testing during app development. It allows
UI interaction events to be sent to the app during testing, and the
only requirement is to re-sign the binary APK ﬁle by our debugging
key. Our work is the ﬁrst to use the InstrumentationTestCase API
for the purpose of automated QoE analysis.
UI control paradigm. The UI control in QoE Doctor follows
a see-interact-wait paradigm. After launching the app, the see
component ﬁrst parses the app UI data shown on the screen, then
the interact component chooses a UI element to interact with (e.g.,
by clicking a button or scrolling a page). After the interaction,
the wait component waits for the corresponding UI response. This
paradigm follows natural user-app interaction behavior, allowing
us to replay real user behavior. Using the InstrumentationTestCase
API, the controller is launched in the same process as the controlled
app, allowing direct access to the UI data as needed for the see
and wait components. Unlike prior work which require system
instrumentation or Android UI dump tools [21, 26, 29, 36],
direct UI data sharing enables convenient and accurate latency
measurements (described next).
The Wait component and accurate user-perceived latency