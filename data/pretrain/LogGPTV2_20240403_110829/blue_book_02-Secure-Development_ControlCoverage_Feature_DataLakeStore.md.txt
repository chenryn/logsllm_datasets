## IMPORTANT: DevOps Kit (AzSK) is being sunset by end of FY21. More details [here](../../../ReleaseNotes/AzSKSunsetNotice.md)
----------------------------------------------
DataLakeStoreDescription & RationaleControlSeverityAutomatedFix ScriptAll users/applications are authenticated using Azure Active Directory (AAD) based credentialsUsing the native enterprise directory for authentication ensures that there is a built-in high level of assurance in the user identity established for subsequent access control. All Enterprise subscriptions are automatically associated with their enterprise directory (xxx.onmicrosoft.com) and users in the native directory are trusted for authentication to enterprise subscriptions.HighNoNoAll users/identities must be granted minimum required permissions using Role Based Access Control (RBAC)Granting minimum access by leveraging RBAC feature ensures that users are granted just enough permissions to perform their tasks. This minimizes exposure of the resources in case of user/service account compromise.MediumYesNoAccess to Data Lake Store file system must be limited by using appropriate Access Control List (ACL). The 'Other' group must not have any accessUsing appropriate ACLs ensures that data in ADLS is protected and accessible only to the entities with a legitimate need to access it.HighYesNoFirewall should be enabled on Data Lake StoreUsing the firewall feature ensures that access to the data or the service is restricted to a specific set/group of clients. While this may not be feasible in all scenarios, when it can be used, it provides an extra layer of access control protection for critical assets.MediumYesNoAdlCopy tool must be used securely while copying data from storage blobs to Data Lake StoreUse of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.ï¿½Incautious use of storage key inï¿½AdlCopy command may result into exposure of the key to unauthorized users.HighNoNoClients such as web jobs, standalone apps should use a service principal identity to access Data Lake StoreUsing a 'user' account should be avoided because, in general, a user account will likely have broader set of privileges to enterprise assets. Using a dedicated SPN ensures that the SPN does not have permissions beyond the ones specifically granted for the given scenario.HighNoNoSensitive data must be encrypted at restUsing this feature ensures that sensitive data is stored encrypted at rest. This minimizes the risk of data loss from physical theft and also helps meet regulatory compliance requirements.HighYesNoSensitive data must be encrypted in transitUse of HTTPS ensures server/service authentication and protects data in transit from network layer man-in-the-middle, eavesdropping, session-hijacking attacks.HighNoNoDiagnostics logs must be enabled with a retention period of at least 365 days.Logs should be retained for a long enough period so that activity trail can be recreated when investigations are required in the event of an incident or a compromise. A period of 1 year is typical for several compliance requirements as well.MediumYesNoDiagnostic logs for Data Lake Store should be reviewed periodicallyPeriodic reviews of diagnostics, activity and audit logs ensures that anomalous activity can be identified early enough instead of after a major compromise.MediumNoNoBackup and Disaster Recovery must be planned for Data Lake StoreData Lake Analytics does not offer features to cover backup/disaster recovery out-of-the-box. As a result, when processing critical workloads, a team must have adequate backups of the data.MediumNoNoData in Data Lake Store should be cleaned up using file retentionData should not be retained for periods longer than required for business use case scenarios. Purging/cleaning up data periodically minimizes risk from compromise while also helping limit the costs of maintaining it.MediumNoNo