DIRA: Automatic Detection, Identiﬁcation, and Repair of Control-Hijacking
Attacks
Alexey Smirnov
Tzi-cker Chiueh
Computer Science Department
State University of New York at Stony Brook
Stony Brook, NY 11794-4400
{alexey, chiueh}@cs.sunysb.edu
Abstract
Buffer overﬂow attacks are known to be the most com-
mon type of attacks that allow attackers to hijack a re-
mote system by sending a specially crafted packet to a
vulnerable network application running on it. A compre-
hensive defense strategy against such attacks should in-
clude (1) an attack detection component that determines
the fact that a program is compromised and prevents the
attack from further propagation, (2) an attack identiﬁca-
tion component that identiﬁes attack packets so that one
can block such packets in the future, and (3) an attack
repair component that restores the compromised applica-
tion’s state to that before the attack and allows it to con-
tinue running normally. Over the last decade, a signiﬁcant
amount of research has been vested in the systems that
can detect buffer overﬂow attacks either statically at com-
pile time or dynamically at run time. However, not much
effort is spent on automated attack packet identiﬁcation
or attack repair. In this paper we present a uniﬁed solu-
tion to the three problems mentioned above. We imple-
mented this solution as a GCC compiler extension called
DIRA that transforms a program’s source code so that
the resulting program can automatically detect any buffer
overﬂow attack against it, repair the memory damage left
by the attack, and identify the actual attack packet(s). We
used DIRA to compile several network applications with
known vulnerabilities and tested DIRA’s effectiveness by
attacking the transformed programs with publicly avail-
able exploit code. The DIRA-compiled programs were
always able to detect the attacks, identify the attack pack-
ets and most often repair themselves to continue normal
execution. The average run-time performance overhead
for attack detection and attack repair/identiﬁcation is 4%
and 25% respectively.
1.
Introduction
A control-hijacking attack overwrites some data struc-
tures in a victim program that affect its control ﬂow, and
eventually hijacks the control of the program and possibly
the underlying system. A data structure that can affect the
control ﬂow of a program is called a control-sensitive data
structure, examples of which include return address, func-
tion pointer, global offset table/import table, C++ virtual
functions table pointer, etc. Once an attacker grabs con-
trol of the victim program, she can invoke any operation
to which the victim program’s effective user is entitled.
Control-hijacking attacks are considered the most danger-
ous type of attacks because they exploit software bugs di-
rectly without requiring any user actions, and because ma-
licious computer worms use them as basic building blocks
to propagate themselves from one machine to another.
Over the last decade, a signiﬁcant amount of research
has been invested in the detection of control-hijacking at-
tacks. Some are based on program analysis techniques
[38, 12, 19, 26, 32, 37] that statically determine whether
a given program contains buffer overﬂow vulnerability.
Others use program transformation techniques [8, 11, 10,
14, 36, 9] to convert applications into a form that can ei-
ther detect control-hijacking attacks [8, 10, 14, 9] or pre-
vent control-sensitive data structures from being modiﬁed
at run time [11]. Still others develop operating system
mechanisms that ensure that it is not possible to execute
code injected into the victim program [34, 27]. Regardless
of their approach, most if not all of these efforts could only
determine whether a program is under a control-hijacking
attack, but could not actively repair a victim program af-
ter it has been compromised. Typically, upon detecting an
attack, they simply terminate the victim application, and
restart another instance if necessary. While terminating a
compromised application helps prevent further propaga-
tion of the attack, it may lead to a denial of service at-
tack. For network applications with a substantial amount
of state such as a DNS sever, it takes some time for them
D
I
R
Stackguard [10], RAD[8]
+
-
-
Buttercup [29], Autograph [21]
-
+
-
Flashback [33], IGOR [13]
-
-
+
DIRA
+
+
+
Table 1. Previous work addressing problems
of attack (D)etection, (I)dentiﬁcation, and
(R)epair.
to re-acquire the necessary state at start-up in order to pro-
vide the full service. For these applications, abrupt termi-
nation is not an acceptable attack recovery strategy. More-
over, because existing control-hijacking attack detection
systems cannot prevent the same attacks from taking place
again, vulnerable applications may be repeatedly victim-
ized and re-started in the presence of recurring attacks as
in the case of worms. In the mean time, these applications
cannot render any useful service to their intended users.
To address the limitations of existing systems that focus
only on detection of control-hijacking attacks, this project
aims to develop a program transformation system called
DIRA that can automatically transform an arbitrary appli-
cation into a form that
• Can detect a control-hijacking attack when the
control-sensitive data structure it tampers with is ac-
tivated,
• Can identify the network packets that lead to the
control-hijacking attack, and send these packets to
a front-end content ﬁlter to prevent the same attack
from compromising the application again, and
• Can repair itself by erasing all the side effects of the
attack packets as if it never received them.
To the best of our knowledge, attack detection, repair
and identiﬁcation have never been considered together
previously. Table 1 puts in perspective related projects
in each of these three areas. The main contribution of
this paper is the development of a uniﬁed solution to all
three problems. Even though on the surface attack detec-
tion, identiﬁcation, and recovery appear to be completely
orthogonal functions, a careful examination reveals that
they can actually be uniﬁed into a single implementation
framework that is based on memory update logging. To
repair a program’s memory state, all updates to its ad-
dress space should be logged so that these updates can
be reversed. To detect a control-hijacking attack, the be-
fore image of a control-sensitive data structure should be
stored away, and checked at the time of activation to see
if any tampering took place. To trace back the packets re-
sponsible for a detected attack, the backward slice of the
corrupted control-sensitive data structure needs to be ﬁrst
computed and then intersected with the incoming packets.
DIRA takes an application’s source code, and inserts ad-
ditional logging code so that the resulting application can
detect, identify, and recover from any control-hijacking
attacks in a way that is completely independent of the un-
derlying operating system and hardware.
The rest of this paper is organized as follows. Section
2 reviews previous research on detection and prevention
methods for control-hijacking attacks, as well as on pro-
gram rollback. Section 3 describes the logging algorithms
and data structures used in the DIRA compiler. In Section
4 we discuss the implementation details of the DIRA com-
piler. Section 5 presents the performance measurements
of a fully operational DIRA prototype and their analysis.
Section 6 concludes this paper with a summary of major
research contributions and a brief outline of the on-going
work.
2.
Related Work
Our work is based upon previous work in three broad
areas of systems research: buffer overﬂow attacks detec-
tion, malicious code identiﬁcation, and program rollback
and replay.
Approaches to detect buffer overﬂow attacks can be di-
vided into two groups: static techniques that detect po-
tential buffer overruns by examining program’s source
code and dynamic techniques that protect programs at run-
time. Wilander et. al. [39, 40] present a comprehensive
overview of tools of both types. Greiner [16] gives an
overview of manual code auditing techniques that help de-
tect potential vulnerabilities.
The real cause of buffer overﬂows is unchecked pointer
or array access. Jones and Kelly [20] and Austin et. al. [3]
propose to check each pointer access at run time to solve
this problem. This requires augmentation of the standard
pointer representation with additional ﬁelds such as the
extent of the memory region that the pointer is referring
to. Both systems are implemented as C compiler exten-
sions that instrument the source code of the program in
such a way that the modiﬁed program checks each pointer
access it performs at run-time. Purify [18] is a similar
tool that instruments program’s object code and therefore
does not require access to its source code. However, all
these tools suffer from a signiﬁcant performance overhead
which can be more than 500% in some cases. CRED [31]
is a project that aims to provide a comprehensive mem-
ory access bounds checking at a reasonable cost. Unlike
other bounds checking projects, CRED checks the access
correctness for pointers to character strings only assuming
that improper string manipulation is responsible for most
buffer overﬂow attacks. The reported overhead of CRED
is less than 26%. Such a moderately high overhead indi-
cates a need for more lightweight and inexpensive protec-
tion mechanisms.
The return address is the most common target of buffer
overﬂow attacks. Stackguard [10] is a system that pro-
tects the return address by placing a canary word on the
stack before the return address. It is based on the assump-
tion that overwriting the return address requires overwrit-
ing the part of the stack immediately preceding it. If the
canary word is found modiﬁed upon the function return
then an attack has taken place. RAD [8] takes a different
approach. It copies the return address to a buffer called
the return address repository which is protected from both
sides by applying mprotect() system call. Similarly, it
compares the return address on the stack with the saved
value and raises the red ﬂag if the two values are differ-
ent.
StackShield [36], ProPolice [11], and StackGhost
[14] are similar systems that protect other code pointers
such as function pointers and stack frame register in addi-
tion to the return address. FormatGuard [9] provides a set
of wrapper functions that protect a program from format
string attacks.
Another approach to buffer overﬂow prevention is pre-
sented by Baratloo et. al. [4]. They develop a dynamic
library called Libsafe that provides wrappers for common
libc functions that are prone to buffer overﬂows. This
library is transparently inserted at run-time between the
application being protected and libc using LD_PRELOAD
environment variable. The protection mechanism is based
on estimating the boundaries of the stack frame of the call-
ing function and assuming that no function can write be-
low that boundary.
A typical buffer overﬂow attack executes the injected
code on the stack.
Therefore, making stack non-
executable will prevent any stack-based attack. PaX [34]
and Openwall [27] are two Linux kernel patches that im-
plement non-executable stacks. This approach has some
limitations, however. First, attacks that inject their code
into data segment as well as return-into-libc attacks will
still work. Second, Linux signal handlers and some func-
tional languages such as LISP require the stack to be exe-
cutable.
Essentially, the problem of detecting a buffer overﬂow
attack relies on a mechanism to monitor a particular mem-
ory location (such as a return address). A similar problem
exists in software debugging in which case a dynamically
monitored memory location is called a watch-point. Ex-
isting solutions of this problem can be divided into run-
time dynamic checking techniques [17, 18] and hardware-
based techniques [25, 30, 41].
The problem of automatic identiﬁcation of malicious
code became increasingly important in the past few years
since worms epidemics started to happen more and more
frequently and at higher speeds. Given the speed of prop-
agation of the recent worms, it is hopeless to rely on a
human-based methods for signature generation as by the
time the proper signature is created and distributed among
computer users, the worm is likely to infect a signiﬁcant
number of computer systems. Autograph [21] is a system
that generates worm signatures automatically by detect-
ing common byte sequences in suspicious network ﬂows.
In this system, a network ﬂow is considered suspicious
if it comes from a host that is believed to perform port
scanning. Toth and Kruegel [35] propose a system that
detects malicious code in packet payloads by performing
abstract execution of the payload data. Buttercup [29] is
a system aimed at preventing polymorphic worms with
known signatures from entering the system. It identiﬁes
the ranges of possible return addresses for existing vul-
nerabilities and checks whether a network packet contains
such addresses.
Another approach to identifying malicious code is to
analyze the execution trace of a compromised program.
Given the address of the compromised control-sensitive
data structure, one can use dynamic slicing techniques
[24, 22, 23] to ﬁnd out all statements of the program that
affected the value of this data structure. This allows one to
trace back the origin of the malicious data that was written
to this data structure to the point where it ﬁrst appeared in
the program. Therefore, one can completely restore the
compromising network packet or user input. Agrawal and
Horgan [2] discuss several approaches for computing dy-
namic slices and introduce the notion of a dynamic depen-
dence graph.
Finally, yet another approach to malicious input iden-
tiﬁcation it to use a technique similar to Perl taint mode.
The idea is to assign different tags to all user inputs and
propagate these tags along through all memory operations.
Upon discovering a compromised data structure, one can
identify the origin of the malicious data by looking at the
tag currently associated with that memory location.
System support for rollback and reverse execution is an-
other related area of systems research. Although not re-
lated directly to post-attack recovery, these mechanisms
can be readily adapted to rollback a program to a pre-
attack state. Systems that have a rollback capability rely
on one of the following techniques: they either keep the
execution history [1] or do periodic state checkpointing
[13, 28, 33]. For example, Igor [13] is a system that saves
modiﬁed memory pages at each checkpoint. RECAP [28]
and Flashback [33] use copy-on-write fork() system call
to checkpoint their execution state. Spyder [1] is based on
the notion of execution history. During its normal execu-
tion, Spyder records the program counter and the old val-
ues of all variables that the current instruction will change.
All these systems require speciﬁc support from the under-
lying OS.
An alternative way of bringing a compromised system
to the normal state is a complete restart. Candera et. al.
[7, 6] develop the concept of micro-reboots. According to
this concept, a complex system comprised of many indi-
vidual components (such as a large Internet service) can
be efﬁciently repaired in case of a fault or an attack by
performing a micro reboot of a single failed component
rather than that of the whole system. If the problem cannot
be ﬁxed by micro-rebooting then it is deferred to human
operators.
3.
Attack Detection, Identiﬁcation, and Re-
pair
DIRA makes programs capable of attack detection,
identiﬁcation and repair by using a combination of static
and dynamic techniques. At compile time, the DIRA com-
piler instruments the source code of a program in a num-
ber of ways. First, it inserts proper memory updates log-
ging code that allows the program to keep track of every
memory update it performs. Second, the DIRA compiler
inserts the code that checks every control-sensitive data
structure before it is used. Finally, a number of special
functions that allow the program to identify attack pack-
ets and repair itself are added to the program. At run
time, the instrumented program generates a memory up-
dates log which can be used to identify attack packets and
repair the program once an attack is detected. The logged
information is also used to check the control-sensitive data
structures at run time when they are about to be used. If a
control-sensitive data structure is found compromised, the
attack identiﬁcation and repair functions are called.
The amount of logging information as well as the type
of information stored in the log depends on the mode in
which DIRA operates. There are three modes of oper-
ation: compilation to support attack detection only (D-
mode), compilation to support detection and identiﬁcation
(DI-mode) and ﬁnally compilation to support detection,
identiﬁcation, and repair (DIR-mode). Each successive
mode requires more information to be logged. In this sec-
tion we describe how memory update logging works and
how the logged information is used in attack detection,
identiﬁcation, and repair.
3.1.
Attack Detection
Most of the control-hijacking attacks modify some
control-sensitive data structures in the victim program,
such as a return address, a function pointer, or a jump ta-
ble, through buffer overﬂowing. Once the compromised
data structure is used in a control transfer, the attacker hi-
jacks the control of the application.
The approach to attack detection used by
DIRA is
similar to that developed in RAD project [8]. To detect
control-hijacking attacks at run time, the DIRA compiler
maintains the original image of every control-sensitive
data structure, and at the time of control transfer compares