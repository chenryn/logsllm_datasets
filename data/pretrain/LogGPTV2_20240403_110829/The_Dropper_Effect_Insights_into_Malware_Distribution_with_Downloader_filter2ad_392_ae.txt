### Table 7: Testing Classifier on the Unlabeled Influence Graphs
- 1093 (41%)
- 60 (0.5%)
- 1249 (43%)
- 38 (0.3%)
- 1041 (41%)
- 67 (0.6%)

### 5.6 Online Detection Experiment
In this experiment, we simulate the operational use of our classifier for real-time malware detection. We prepared a training set consisting of 21,543 malicious and 21,755 benign influence graphs (IGs) from data collected before 2014. For the testing set, we constructed IGs based on data from the year 2014, which includes 12,299 malicious and 12,594 benign IGs.

Given that the 2014 data may not have had sufficient time to accumulate prevalence information, we excluded prevalence features from the classification process. Prevalence is one of the top-performing features in our classification model. We trained the Random Forest Classifier (RFC) using the same parameters as in Section 5.4 and then applied it to the testing set. The results were as follows:
- True Positive (TP) rate: 99.8%
- False Positive (FP) rate: 1.9%
- False Negative (FN) rate: 0.2%
- F1-score: 99.0%

These results indicate that our features do not exhibit significant concept drift over time and demonstrate the potential for robust online malware detection.

### 6. Discussion
We now discuss the key insights and implications of our experiments, focusing on their impact on malware detection and attack attribution.

#### Opportunity for Improving Malware Detection
Our research provides an initial understanding of the properties of downloader graphs in the wild. We found that certain properties, such as large graph diameter, high growth intervals of influence graphs, and a large number of distinct droppers accessing a domain, are strong indicators of malicious activities. These insights can lead to deterministic detection techniques that enhance existing anti-virus products by blocking certain classes of malware early in their lifecycle.

The intuition behind these benefits is that the properties of downloader graphs can provide evidence of malicious activity before new malware samples are analyzed by the security community. Additionally, incorporating downloader graph features into probabilistic detection techniques, along with existing host-based and network-based features, can complement current approaches. This is because downloader graphs:
- Capture client-side activity of malware delivery networks.
- Reflect relationships among malware families.
- Help increase detection performance and reduce detection latency.

It is important to note that our techniques operate on end hosts. While network traffic analysis can indicate when downloading is in progress, it cannot determine which executable triggers the download, making it difficult to construct a complete downloader graph.

#### Blocking Malicious Droppers
Our findings raise the question: Should user approval be required for all downloads of executable programs? If an operating system or an anti-virus program quarantines every downloaded executable and asks for user approval, the operation of malicious downloaders would be severely impaired. However, this approach would also hinder the deployment of security patches, as manual or semi-automated software updating is less effective than silent updates, which install security patches without user interaction.

A more effective approach would be to require digital signatures for programs that download other executables, similar to the current practice for device drivers. This method is more efficient than attempting to whitelist all benign software, as only a few benign programs (87,906 in our dataset) download other executables.

#### Implications for Attack Attribution
Attack attribution, which aims to identify attackers, is challenging due to the various methods attackers use to conceal their identities, such as obfuscating binaries, changing URLs and domains, and launching attacks from geographically distributed compromised machines. However, 55.5% of malicious downloaders are signed, accounting for 73.8% of the malicious influence graphs. For example, one pay-per-install (PPI) provider consistently specifies "Amonetize LTD" in the publisher field of the digital signature. This suggests that attackers may distribute signed programs to remain undetected for longer periods, prioritizing stealth over thwarting attribution efforts.

Similarly, attackers may use common protocols like HTTP to transmit malicious payloads, which can bypass firewall restrictions. Our detection approach based on downloader graph analytics may force attackers to use stealthier techniques, such as custom ports and protocols, which are more likely to trigger alarms in firewalls and intrusion-prevention systems.

#### Limitations
Droppers with rootkit functionality can evade our technique. However, rootkits are typically used to hide more incriminating functionality, while our technique relies on tracking downloader-payload relationships. This provides a new signal complementary to current AV engines and can detect malware that existing AVs might miss.

### 7. Related Work
Several research efforts have focused on characterizing the properties of malware delivery networks and using these properties for detection. Provos et al. [20] described drive-by-download attacks and analyzed the tree-like structure of redirection paths leading to malware distribution sites. Li et al. [14] further analyzed URL redirection graphs and identified long-lived, topologically dedicated malicious hosts. Perdisci et al. [19] analyzed structural similarities in malicious HTTP traffic, including command and control, spam, and data exfiltration activities.

Inspired by these studies, several techniques have been proposed for detecting malware download events from network traffic [10, 30]. Unlike our work, these studies focus on the server side of malware distribution networks and cannot identify the triggering program or reconstruct complete downloader graphs.

Prior research on downloader behavior [3, 17, 23] has focused on executing malware droppers in lab environments to observe communication protocols and download payloads. For example, Caballero et al. [3] described pay-per-install infrastructures and provided an example of a download tree. Follow-up work reported that downloaders can remain active for over two years [23].

In contrast, we analyze malicious droppers that remain undetected for an average of 80.6 days in the wild. We compare the properties of malicious and benign downloader graphs to assess their impact on end-user security and the potential benefits of downloader graph analytics. This approach allows us to identify strong indicators of malicious behavior and train a generic classifier for malware detection using information extracted from downloader graphs.

Closest to our work are recent techniques for assigning reputation scores to executable files using belief propagation on bipartite graphs [5, 28]. Chau et al. [5] constructed a graph encoding the relationship between files and hosts, while Tamersoy et al. [28] constructed a graph encoding the relationship between different files on the same host. In our work, we construct graphs that encode the semantic relationship of file downloads, providing deeper insights into malware distribution activities.

There is a rich literature on graph mining techniques [4]. The Oddball approach [1], which extracts features from k-hop neighborhoods and analyzes outliers, is similar to our technique in Section 4. Graph analytics have also been used for analyzing function call graphs in malware samples [9, 11, 33], spamming operations [32, 34], and vote gaming attacks [22]. In contrast, we propose downloader graph analytics for analyzing malware delivery activities on the client side.

### 8. Conclusions
We analyzed downloader graphs in the wild and uncovered differences in growth patterns between benign and malicious graphs. Downloader graphs capture the relationships between downloaders and the supplementary executables they download, allowing us to identify large parts of malware download activity on each host. We identified deterministic techniques for detecting certain classes of malware based on properties such as growth rate, diameter, and domain diversity.

We also described a generic malware detection system that uses machine learning to automatically learn models of malicious download graphs. We evaluated our system on 19 million graphs and showed that it detects malware with high accuracy and earlier than existing anti-virus systems.

### Acknowledgments
We thank Amol Deshpande, Jonathan Katz, and Michel Cukier for early feedback. We also thank VirusTotal for access to their service and Symantec for access to WINE (the data analyzed in this paper corresponds to the reference dataset WINE-2015-002). This research was partially supported by the Maryland Procurement Office (contract H98230-14-C-0127) and the Department of Defense.

### References
[References listed as in the original text]

This optimized version enhances the clarity, coherence, and professionalism of the text, ensuring that the information is presented in a structured and easily understandable manner.