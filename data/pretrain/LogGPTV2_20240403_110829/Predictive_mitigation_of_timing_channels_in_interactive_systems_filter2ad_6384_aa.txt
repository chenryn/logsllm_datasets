title:Predictive mitigation of timing channels in interactive systems
author:Danfeng Zhang and
Aslan Askarov and
Andrew C. Myers
Predictive Mitigation of Timing Channels
in Interactive Systems
Danfeng Zhang
PI:EMAIL
Aslan Askarov
PI:EMAIL
Andrew C. Myers
PI:EMAIL
Department of Computer Science
Cornell University
Ithaca, NY 14853
Abstract
Timing channels remain a difﬁcult and important problem for in-
formation security. Recent work introduced predictive mitigation, a
new way to mitigating leakage through timing channels; this mech-
anism works by predicting timing from past behavior, and then en-
forcing the predictions. This paper generalizes predictive mitiga-
tion to a larger and important class of systems: systems that receive
input requests from multiple clients and deliver responses. The new
insight is that timing predictions may be a function of any public
information, rather than being a function simply of output events.
Based on this insight, a more general mechanism and theory of
predictive mitigation becomes possible. The result is that bounds
on timing leakage can be tightened, achieving asymptotically log-
arithmic leakage under reasonable assumptions. By applying it to
web applications, the generalized predictive mitigation mechanism
is shown to be effective in practice.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection
General Terms
Security
Keywords
Timing channels, mitigation, interactive systems, information ﬂow
1.
Introduction
The time at which a computing system performs some observ-
able action such as sending a network packet can in principle en-
code an unbounded amount of information about what is happening
inside the system, creating a timing channel [1]. An adversary able
to accurately measure this time may learn conﬁdential information
from this side channel (e.g.,
[2, 3, 4, 5]); an adversary able to
inﬂuence this time may additionally use it as a covert channel to
communicate conﬁdential information (e.g., [6, 7, 8]).
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
Though the recent work cited above demonstrates the threat of
timing channels, controlling them without compromising function-
ality is typically considered to be extremely challenging or even
infeasible [9, 10, 11]. Recent work on timing channels has focused
on quantitatively bounding what can be learned from timing chan-
nels rather than on blocking them entirely (e.g., [12, 13, 14]).
Recent work by Askarov et al.
introduced a new mechanism
called predictive mitigation for bounding information leakage via
timing channels [14]. Unlike work focusing on preventing leakage
of keys from cryptographic operations (such as [12, 13]), predictive
mitigation applies to any computing system, making few assump-
tions about the nature of the computation being performed. How-
ever, as we argue, the original predictive mitigation mechanism is
impractical for many real-world systems where timing channels
are of concern—especially networked servers such as web appli-
cations. Therefore, this paper generalizes predictive mitigation to
take advantage of more knowledge about the system whose timing
channels are being mitigated, signiﬁcantly improving the tradeoff
between security and performance.
Contributions. The contributions of this work are both theoret-
ical and practical. On the theoretical side, the theory of predictive
mitigation is extended in several ways:
• Inputs. The model of the mitigated system is extended to ac-
count for inputs to the system, so output timing can be predicted
from public (that is, nonconﬁdential) attributes of inputs such as
request time.
• Threads. In [14], the system being mitigated is a black box.
Here the system is modeled more concretely as containing multi-
ple threads which communicate with the outside over different out-
put channels. This more detailed modeling enables tighter leakage
bounds.
• Composition. In general, a system employing predictive mit-
igation may be composed of several communicating components,
each individually mitigated. The theory of composing predictive
mitigation is developed.
This new theory of predictive mitigation has been put into prac-
tice as in an implementation of predictive mitigation for web ap-
plications. For example, we implement a standardized server-side
wrapper that can mitigate timing leaks from any web application.
An important contribution of this paper is an empirical evalua-
tion of how predictive mitigation performs when applied to real ap-
plications with different characteristics. We examine its impact on
latency, throughput, and maximum timing leakage of wrapped web
applications. The results from this implementation suggest that the
generalized predictive mitigation mechanism appears to be practi-
cal and offers a signiﬁcant improvement on the original predictive
mitigation method.
563Figure 1: Predictive mitigation
Figure 2: Predictive mitigation of an interactive system
The rest of the paper is structured as follows. Section 2 intro-
duces the extended form of predictive mitigation in the context of
the prior work. Section 3 presents different ways to construct pre-
dictive mitigators depending on the concurrency model and on what
information is considered public. Section 4 analyzes information
leakage under various mitigation schemes and assumptions about
applications. Section 5 develops formal results on the composi-
tion of predictive mitigators. Experiments with applying predictive
mitigation to real applications are presented in 6. Related work is
discussed in Section 7; the paper concludes in Section 8.
2. Predictive mitigation
Timing channels can be divided into internal and external timing
channels [15]. Predictive timing mitigation is a general method for
limiting leakage through external channels: those in which the tim-
ing measurement is taken external to the system. Because measure-
ment is external, methods that control internal timing channels by
preventing effective timing measurement within the system (e.g.,
[16, 17, 18, 19]) cannot be applied.
Unlike timing mitigation methods that add random delays (e.g.,
[20, 16]), predictive mitigation bounds the amount of information
that leaks through the timing channel, by delaying events according
to a schedule that is predicted in advance.
2.1 Background
In the original predictive mitigation work, the system is modeled
abstractly as an event source connected to a timing mitigator, as
depicted in Figure 1. The timing of events produced by the event
source is in general inﬂuenced by conﬁdential information. Further,
the adversary may be able to affect how conﬁdential information
inﬂuences timing, enabling timing to be used as a covert channel.
For example, the adversary might install software onto the event
source to modulate the timing of generated events [7].
Events from the event source are delayed by the timing mitiga-
tor to reduce the bandwidth of the timing channel. The adversary
is assumed to be able to observe the timing of events leaving the
mitigator,1 but can affect the mitigator only via the input stream of
source events. Generating fake events does not help; the adversary
is assumed to be able to identify them.
At any point, the mitigator has a schedule describing when events
are supposed to be released. The schedule is a sequence of predic-
tions, each associated with a future point in time. As long as events
arrive according to (or ahead of) the schedule, leakage must be low
because the number of possible system behaviors observable by the
adversary is small.
The event source might fail to behave according to the schedule,
in which case the adversary may learn information. The mitiga-
tor responds to the misprediction by selecting a new schedule in a
way that ensures that total leakage through the timing channel is
1The adversary may also be able to partly observe the contents of
events leaving the mitigator, but this is a storage channel [1], the
control of which is orthogonal to the goals of this work.
bounded. The period during which the schedule correctly predicts
behavior is called an epoch. Schedules are chosen in such a way
that the number of epochs grows slowly with time.
For example, consider the following simple “fast doubling” mit-
igation scheme described by Askarov et al. [14]: initially, the mit-
igator has a schedule of predictions at evenly spaced intervals. If
the event source fails to deliver events quickly enough, the result-
ing misprediction causes the mitigator to generate a new schedule
in which the interval between predictions is doubled.
We can bound the amount of information that leaks through the
adversary’s observations through a combinatorial analysis of the
number of possible distinct observations the adversary can make.
An observation consists of a sequence of times at which events
are released by the mitigator. Because events are released in ac-
cordance with schedules, the number of possible observations is
limited; therefore, the information-theoretic entropy of the timing
channel is bounded. This in turn bounds the capacity of the timing
channel. In total time T , there can be no more than log(T + 1)
epochs,2 each of which leaks no more than log(T + 1) + 1 bits
of information. Therefore, this simple scheme releases no more
than (1 + ) log2 T bits of information, where  is small for large
T [14]. As this bound shows, it is possible to ensure leakage is
asymptotically sublinear over time.
Note that this argument is all about the capacity of the timing
channel, without any assumptions about how efﬁciently secrets are
encoded into this channel. The bound applies even if the adversary
is perfectly encoding secrets into event timing. But if the adversary
does not have this level of control, the bound is likely to be quite
conservative.
2.2 Generalizing predictive mitigation
The prior work on predictive mitigation assumes very little about
the event source, which means that it can be applied to a wide range
of systems. Predictive mitigation can address even difﬁcult low-
level timing channels such as those created by hardware contention
at the level of the processor or the bus, as long as the mitigator
is able to delay externally visible events to precisely the time pre-
dicted by the schedule.
However, the very generality of predictive mitigation can make
the leakage bounds conservative, and performance of the system
is then hurt because the mitigator excessively delays the release of
events. By reﬁning the system model, we can make more accurate
predictions and also bound timing leakage more accurately. The
result is a better tradeoff between security and performance.
Timing channels in network-based services are particularly of
interest for timing channel mitigation. These services are interac-
tive systems that accept input requests from a variety of clients and
send back responses. Figure 2 illustrates how we extend predictive
mitigation for such a system.
Here, the abstract event source used by the prior work is replaced
2All logarithms here use base 2.
eventsourcetimingmitigatorsourceeventssecretsdelayedeventsservicetimingmitigatoroutputeventssecretsmitigatedoutputrequestsinputrequestsnon-secretspredictorpublic informationrequest type564by a more concrete interactive system that accepts input messages
on multiple input channels and delivers output messages to corre-
sponding output channels. Output messages are passed through the
timing mitigator, as before, and released by the timing mitigator in
accordance with the prediction for that message. If a message ar-
rives early, the mitigator delays it until the predicted time. If it does
not arrive in time—a misprediction has happened—the mitigation
starts a new epoch and makes a new, more conservative prediction.
This scheme signiﬁcantly generalizes the original predictive mit-
igation scheme. First, the time to produce each event is predicted
separately, rather than requiring the mitigator to predict the entire
schedule in advance—which is rather difﬁcult for an interactive
system. Second, the prediction may be computed using any public
information in the system. This public information may be any-
thing deemed public (the “non-secrets” in the diagram), possibly
including some information about input requests. For example, the
mitigator may use the time at which a given input request arrives to
predict the time at which the corresponding output will be available
for release. The model also permits the content of input requests to
be partly public. Each request has an application-deﬁned request
type capturing what information about the request is public. If no
information in the request is public, all requests have the same re-
quest type.
To see why this generalizes the original predictive mitigation
scheme, consider what happens if the prior history of mitigator pre-
dictions is the only information considered public when predicting
the time of output events. In this case, all predictions within an
epoch can be generated at the start of the epoch, yielding a com-
pletely determined schedule for the epoch. By contrast, our gener-
alized predictive mitigation can make use of information that was
not known at the start of the epoch, such as input time. Therefore,
predictions can be made dynamically within an epoch.
2.3 Leakage measures
Two ways to measure information leakage have recently been
popular. The information-theoretic measure of mutual information
has a long history of use; it is advocated, for example, by Den-
ning [21], and has been used for the estimation of covert channel
capacity, including timing channel capacity, in much prior work (e.g.,
[22, 23, 24]). Recently, min-entropy leakage has become a popu-
lar measure, motivated by the observation that two systems with
the same leakage according to mutual information may have very
different security properties [25].
Prior work on timing channel mitigation has used one or both of
these measures. Fortunately, the style of analysis used here and in
prior work on predictive mitigation is sufﬁciently conservative that
it bounds both the mutual information and the min-entropy mea-
sures of leakage.
The information-theoretic (Shannon) entropy of a ﬁnite distribu-
tion X over its n possible values is written as H(X). It achieves
its maximal value of log(n) bits when all n possible values have
equal probability. Suppose that O is the distribution over n possi-
ble timing observations by the adversary, and S is the distribution
over possible secrets that the adversary wants to learn. The mu-
tual information between O and S, written I(O; S), is equal to
H(O) − H(O|S), where H(O|S) is the conditional entropy of O
on S—how much entropy remains in O once S is ﬁxed. In our
context, the conditional entropy describes how effectively the ad-
versary encodes the secrets S into the observations O. But since
conditional entropy is always positive, the mutual information be-
tween O and S is at most H(O), or log(n).
Smith argues [25] that the min-entropy of a distribution is a bet-
ter basis for assessing the vulnerability introduced by quantitative
leakage because it describes the chance that an adversary is able
to guess the value of the secret in one try. The min-entropy of a
distribution is deﬁned as H∞(O) = − log V (O) where V (O) is
the worst-case vulnerability of O to being guessed: the maximum