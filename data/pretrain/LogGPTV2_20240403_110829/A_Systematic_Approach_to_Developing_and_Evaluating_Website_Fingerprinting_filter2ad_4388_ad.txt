T D
outputs
(cid:104)
(cid:105)
A(t) = argmax
Pr[W = w] Pr
T D
w = t
w
If more than one w attains the maximum, then the attacker chooses
randomly among them.
Some privacy applications require good worst-case performance,
and some only require good average-case performance. This leads
to two security deﬁnitions for website ﬁngerprinting defenses:
DEFINITION 1. A ﬁngerprinting defense D is non-uniformly
-secure for W iff Pr(cid:2)A(T D
-secure for W if maxw Pr(cid:2)A(T D
W ) = W(cid:3) ≤ . Defense D is uniformly
w ) = w(cid:3) ≤ .
These are information-theoretic security deﬁnitions – A is the op-
timal attacker described above. The ﬁrst deﬁnition says that A’s
average success rate is less than , but it does not require that every
website be difﬁcult to recognize. The second deﬁnition requires all
websites to be at least  difﬁcult to recognize. All previous papers
on website ﬁngerprinting attacks and defenses have reported aver-
age attack success rates in the closed-world model, i.e. they have
reported non-uniform security measurements. We will do the same.
To deﬁne the bandwidth overhead of a defense system, let B(t)
be the total number of bytes transmitted in trace t. We deﬁne the
bandwidth ratio of defense D as
E(cid:2)B(cid:0)T D
W
(cid:1)(cid:3)
E [B (TW )]
BWRatioD(W ) =
(cid:104)
This deﬁnition captures the overall bandwidth ratio between a user
surﬁng the web while using defense D and a user visiting the same
websites with no defense.
5.1.2 Bandwidth Lower Bounds
In this section we derive an algorithm to compute, given web-
sites w1, . . . , wn, a lower bound for the bandwidth that any non-
uniformly -secure ﬁngerprinting defense can use in a closed-world
experiment using w1, . . . , wn.
To compute a lower bound on bandwidth, we consider an adver-
sary that looks only at the total number of bytes in a packet trace,
i.e. an attacker AS that always guesses
AS(t) = argmax
Pr
B(T D
w ) = B(t)
w
Any defense that is -secure against an arbitrary attacker must also
be at least -secure against AS. If we can derive a lower bound on
defenses that are -secure against AS, that lower bound will apply
to any -secure defense.
We make two simplifying assumptions in order to obtain an ef-
ﬁcient algorithm for computing lower bounds. First, we assume
that each website has a unique ﬁxed size, si. In our closed world
experiments, we found that, for just over half the web pages in our
dataset, their size had a normalized standard deviation of less than
0.11 across 20 loads, so we do not believe this assumption will
signiﬁcantly impact the results of our analysis. Second, we assume
that the defense mechanism does not compress or truncate the web-
site.
We prove the following theorem in Appendix A:
(cid:105)
THEOREM 1. Suppose n is an integer. Let W be a random
variable uniformly distributed over w1, . . . , wn, i.e. W represents
a closed-world experiment. Suppose D is a defense that is -non-
uniformly-secure against AS on distribution W . Then there exists
a monotonically increasing function f from S = {s1, . . . , sn} to
itself such that
• |f (S)| ≤ n.
i=1 f (si)/(cid:80)n
• (cid:80)n
i=1 si ≤ BWRatioD(W ).
i=1 f (si).
Intuitively, f represents a mapping from each website’s original
size (si) to the number of bytes that D transmits when loading web-
site wi.
This theorem enables us to efﬁciently compute a lower bound on
the overhead of any defense that is  uniformly or non-uniformly
secure in a closed world experiment on w1, . . . , wn. To get a lower
bound for non-uniformly -secure defenses, we just need to ﬁnd
a monotonically increasing function f : S → S that satisﬁes
|f (S)| ≤ n and minimizes(cid:80)n
ing k ≤ n and minimizing (cid:80)k
titions satisfy a recurrence relation.
non-uniformly k
non-uniformly k−1
fore the cost, C( k
Such an f is equivalent to a partition S1, . . . , Sk of S satisfy-
i=1 |Si| maxs∈Si s. These par-
If S1, . . . , Sk is an optimal
n -secure partition, then S1, . . . , Sk−1 is an optimal
n−|Sk| -secure partition of S1 ∪ ··· ∪ Sk−1. There-
n , n), of the optimal f satisﬁes the recurrence
if k = 1
otherwise.
, n − j) + jsn
 nsn
, n) =
k − 1
n − j
1≤j≤n−1
We can obtain a similar bound for uniformly -secure determin-
istic defenses. We say a defense is deterministic if, on each load of
website wi, it always transmits bi bytes. The following theorem is
proven in Appendix A.
min
k
n
C(
C(
THEOREM 2. Let W be uniformly distributed over w1, . . . , wn,
i.e. W represents a closed-world experiment. Suppose D is a de-
terministic defense that is uniformly -secure against AS on distri-
bution W . Then there exists a monotonically increasing function f
from S = {s1, . . . , sn} to itself such that
i=1 si ≤ BWRatioD(W ).
• mini |f−1(si)| ≥ 1/.
• (cid:80)n
i=1 f (si)/(cid:80)n
|Si| ≥ 1/ and minimizing (cid:80)k
As with the lower bound on non-uniformly secure defenses, such
an f corresponds to a partition S1, . . . , Sk of S satisfying mini
i=1 |Si| maxs∈Si s. These parti-
tions satisfy a slightly different recurrence. If S1, . . . , Sk is is an
optimal uniformly -secure partition of S, then S1, . . . , Sk−1 is an
optimal uniformly -secure partition on S1 ∪ ··· ∪ Sk−1. Thus the
cost, C(, n) of the optimal uniformly -secure partition satisﬁes
the recurrence relation:
if n ∈(cid:2) 1
if n < 1/
 , 2
otherwise.

(cid:1)
∞
nsn
1≤j≤ n−1
min

(cid:48)
C
(, n) =
(cid:48)
(, n − j) + jsn
C
Algorithm 1 shows a dynamic program for computing a lower
bound on the bandwidth of any defense that can achieve  non-
uniform security in a closed-world experiment on static websites
with sizes s1, . . . , sn in time O(n2). We use this algorithm to
compute the lower bounds reported in Section 6.2. The dynamic
program for computing uniform security lower bounds is similar.
5.2 From Closed to Open World
In this section, we show how to use closed-world experimental
results to compute open-world security of defenses and open-world
performance of attacks. This makes attack and defense evaluation
simpler: researchers need only perform closed-world experiments
to predict open-world performance.
In an open-world attack, the defender selects a website, W , ac-
cording to some probability distribution and generates a trace, T D
W ,
corresponding to a visit to that website using some defense, D.
The attacker’s goal is to determine whether W = w∗, where w∗ is
a particular website of interest. (It is easy to generalize this deﬁni-
tion to situations with multiple websites of interest).
In the open-world setting, the distribution of the random variable
W corresponds to the popularity of different websites among the
population of users being monitored in the attack. So, for example,
if the ﬁngerprinting attacker is a government monitoring citizens
Tor usage, then W would be distributed according to the popularity
of websites among that nation’s Tor users.
Any closed-world attack can be used to construct an open-world
attack by selecting websites w2, . . . , wn and building a closed-
world classiﬁer, A, on w∗, w2, . . . , wn. The open-world classiﬁer
is deﬁned as C(t) = 1 iff A(t) = w∗.
We can compute the false positive rate of this open-world attack
as follows. Let p∗ = Pr[W = w∗] and pi = Pr[W = wi] for i =
2, . . . , n. We can obtain estimates for p∗, p2, . . . , pn from public
sources, such as the Alexa Page-Views per Million database [1].
Let Rn be the average success rate of A in the closed world, i.e.
Pr[A(T D
w∗ ) = w∗] +
Pr[A(T D
wi ) = wi]
Rn =
Note that Rn is the standard performance metric used in closed-
world evaluations. For simplicity, we assume that Pr[A(T D
w∗ ) =
w∗] = Rn. We also assume that, whenever A misclassiﬁes a trace,
there is a 1/n chance that it misclassiﬁes the trace as w∗, i.e. that
W ) (cid:54)= W ] = 1/n. Essen-
Pr[A(T D
tially, these two assumptions are equivalent to assuming that w∗
is not particularly difﬁcult or easy for A to recognize. With these
assumptions, we can compute C’s false-positive rate:
W ) = w∗|W (cid:54)= w∗ ∧ A(T D
FPR(C) = Pr[C(T D
W ) = 1|W (cid:54)= w
Pr[W = w] Pr[C(T D
∗
]
w ) = 1]
n(cid:80)
i=2
n
Pr[W = w] Pr[A(T D
w ) = w∗]
Pr[W = wi] Pr[A(T D
wi ) = w∗]
1 − p∗
1 − p∗
1 − p∗
(cid:33)
w(cid:54)=w∗
(cid:88)
(cid:88)
n(cid:88)
(cid:32)
1 − n(cid:88)
w(cid:54)=w∗
i=2
i=2
1 − Rn
n(1 − p∗)
=
=
=
+
=
Pr[W = wi]
n(cid:88)
1
n(1 − p∗)
(cid:32)
1 − n(cid:88)
(cid:33)
pi
1
pi +
n(1 − p∗)
W ) = 1|W = w
∗
i=2
With the same assumptions, the true positive rate of C is
i=2
TPR(C) = Pr[C(T D
] = Rn
i=2
n(cid:80)
The choice of the websites w2, . . . , wn used to build A will af-
fect the performance of C in the open world. The choice of web-
sites affects the false-positive rate in two ways: (1) choosing less
popular websites tends to increase the false-positive rate since it
decreases
pi, and (2) choosing more similar websites increases
the false-positive rate by reducing Rn. The choice of websites af-
fects the true-positive rate only through Rn. Cai, et al., showed that
the Alexa top 100 websites were about as similar as 100 randomly
chosen websites [3], i.e. that the most popular websites are not par-
ticularly similar to eachother. Thus it is generally a good strategy
to choose w2, . . . , wn to be the most popular websites other than
w∗.
Similarly, the number, n, of websites used to build A affects the
false-positive rate in two ways: (1) increasing n tends to increase
the false positive rate by lowering Rn, and (2) increasing n tends to
n(cid:80)
i=2
pi. Increasing
decrease the false-positive rate since it increases
n can only decrease the true-positive rate.
Thus we can tune the false-positive and true-positive rates of C
by varying n. Small n will have large true- and false-positive rates.