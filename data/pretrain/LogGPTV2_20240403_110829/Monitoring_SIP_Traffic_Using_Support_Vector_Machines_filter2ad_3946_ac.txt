Linear
Polynomial
Sigmoid
RBF
Linear
RBF
Parameters Accuracy(%) Time(ms)
C = 1
C = 1;
γ = 1/38;
r = 0; d = 3
C = 1;
γ = 1/38;
r = 0
C = 1;
γ = 1/38
C = 2
C = 2;
γ = 0.5
99.79
79.09
93.83
98.24
99.83
99.83
196
570
994
668
157
294
parameters, exponential function bounded between 0 and 1). On the other hand,
linear and RBF kernels have comparable performance if the number of features
is signiﬁcantly higher than the number of instances or if both are to large [8].
Therefore, we have tested all kernels with their default parameters over our
dataset. The accuracy (deﬁned as the percentage of correctly classiﬁed messages
over all the test results) for 2-fold cross and machine dependent running time are
shown in Table 4. The last two lines of the table are for RBF and linear kernels
after parameter selection. Machine running time is given for comparison purpose
only and it is averaged over ten runs. RBF and linear kernels have clearly better
accuracy and execution time. We expect that RBF kernel will bypass linear
kernel performance when dealing with larger sets of data.
Size of SIP Slice Experiment
The analyzer window is an important parameter in the feature evaluation pro-
cess. The size of the slice can be ﬁxed or variable with respect to other moni-
toring parameters. In this experiment, we report the accuracy of our solution,
when changing the size of the analyzed slice. The results shown in Table 5 were
obtained using a 5-fold cross test using a RBF kernel and the default parameters.
The time the analyzer takes to process the packets is critical in online monitor-
ing. This is the reason why we show the analysis time of the overall trace: (note
that values are for comparison purpose). As expected, the accuracy improves
with larger window size, which incurs an increased analysis time.
Feature Selection
The 38 features are chosen based on domain speciﬁc knowledge and experience,
but other features might be also relevant. The selection of highly relevant features
is essential in our approach. In the following experiments, we rank these features
with respect to their relevance. We can thus reduce the number of features by
gradually excluding less important features from the analysis. In Table 6, the
Monitoring SIP Traﬃc Using Support Vector Machines
323
Table 5. Testing Results for Diﬀerent Kernels
120 150
Window size
95.4 99.32 99.30 99.67 99.63 100 100
Accuracy (%)
Analysis Time (min) 1.12 2.40 2.56 4.31 6.39 7.42 8.51
15
30
60
90
5
Table 6. Results for Decreasing Size of Features Set
# of features
99.30 99.39 98.90 98.65 98.22
Accuracy (%)
Machine Time (s) 1.85 1.59 1.42 1.28 0.57
38
31
18
12
7
results of a preliminary experiment, where we exclude one group of features at
each column in the following order: the distribution of ﬁnal state of dialogs, the
distribution of SIP requests, the distribution of SIP responses, and the Call-
Id based statistics are given. The last column of the table represents only the
general statistics group of features. Experiments use a 5-fold cross test over our
data set with RBF kernel and its default parameters. The test accuracy is the
percentage of correctly classiﬁed vectors over all the vectors in the test data set.
Although we notice a sudden jump between 12 and 7 features, the associated
accuracy is not strictly decreasing as a function of number of features used. It is
thus reasonable to inquire on the dependencies among the features.
Detection of Flooding Attacks
We have used the Inviteﬂood tool [2] to launch SIP ﬂooding attacks. We have
used INVITE ﬂooding with an invalid domain name (which is the most impacting
on the OpenSER server). We have generated ﬁve attacks at ﬁve diﬀerent rates,
where each attack lasts for one minute. After adaptation (we assume that one
machine of the real world platform is performing the attack), each one minute
attack period is injected into a normal trace of two hours duration. The time of
the attack is ﬁxed to ﬁve minutes after the start of the two hours period. Each
mixed trace is then analyzed and labeled properly (positively along the period
of attack and negatively in all the remaining time).
We have trained the system with the mixed trace (ﬂooding at 100 INVITE/s
- normal trace) in the learning stage. This means that 100 INVITE messages are
taken as a critical rate (the rate we consider as threshold to launch an alarm).
As shown in Fig. 7 (for simpliﬁcation and clarity sake a slice is sized to only
three packets), we take the period of attack and we calculate the correspond-
ing SVM estimation. The estimated probability is the average of the estimated
probabilities for the elementary slices composing the attack traﬃc. This granular
probability is given by the LibSVM tool and is useful for both the probability
estimate option in both learning and testing stages. We deﬁne the detection ac-
curacy as the percentage of vectors correctly classiﬁed as attack over all vectors
of the attack period. The results are in Table 7: the detection accuracy-1 is ob-
tained without a parameter selection (Default parameters : C = 1, γ = 1/38,
324
M. Nassar, R. State, and O. Festor
Fig. 7. Attack Detection in a Mixed Trace
Table 7. Attack Estimation for Diﬀerent Rates of Flooding
10
100 1000
Flooding Rate (INVITE/s) 0.5
0
5.47 67.57 97.36
Detection Accuracy-1 (%)
0 1.48 30.13 88.82 98.24
Detection Accuracy-2 (%)
0.96 0.95 0.73 0.24 0.07
Pr(Normal)
0.04 0.05 0.27 0.76 0.93
Pr(Attack)
1
0
training accuracy: 90.95), detection accuracy-2 and calculated probabilities are
after parameter selection (C = 32, γ = 0.5, training accuracy is of 93.93). We
tested the coherence of a period with respect to other periods. In Table 2, we
show the results of the same procedure for a period of 2-6 of Day 1 compared to
other periods of the same day.
Even though stealthy attacks cannot to be detected, the results show a promis-
ing opportunity to ﬁne-tune the defensive solution. The threshold rate can be
learnt by a dual trace : the ongoing normal/daily traﬃc and a stress condition
where the server was troubleshooted or was noticed to be under-operating. In
this way, SVM is promising for an adaptive online monitoring solution against
ﬂooding attacks.
Detection of SPIT Attacks
SPIT mitigation is one of the open issues in VoIP security today. Detection of
SPIT alone is not suﬃcient if it is not accompanied by a prevention system.
In-depth search in the suspicious traﬃc is needed to build a prevention system
to block the attack in the future. Elements like IP source and URI in the SIP
headers can be automatically extracted.
To generate SPIT calls, we used a well known tool which is the Spitter/
Asterisk tool [2]. Spitter is able to generate call instances described in a “.call” ﬁle
using the open source Asterisk PBX. The rate of simultaneous concurrent calls
can also be speciﬁed as an option of the attack. We proﬁled our programmable
bots to receive SPIT calls. Once an INVITE is received, the bot chooses randomly
between three diﬀerent responses :
Monitoring SIP Traﬃc Using Support Vector Machines
325
– the ﬁrst choice is to ring for a random time interval between one and six
seconds and then to pick up the phone. This emulates two cases : a voice
mail which is dumping a message or a human which is responding. The bot
then listens during a random time between ﬁve and ten seconds and hangs
up,
– the second choice is to respond with ‘Busy’,
– the last choice is to ring for some time and then to send a redirection response
informing the caller that the call has to be directed to another destination
(destination that we assume to not be served by this proxy). Other similar
scenarios like forking (by the proxy) or transferring (by the bot) can also be
supported.
We have performed two experiments with two diﬀerent hit rates. The former is
a partial SPIT: Spitter targets the proxy with hundred destinations and among
these only ten are actually registered bots. In this case the hit rate is just 10%.
This emulates the real world scenario where attackers are blindly trying a list of
extensions. The latter is a total SPIT: we assume that attackers knew already
the good extensions so the hit rate is 100%. This emulates the real world sce-
nario where attackers knew already the good extensions either by a previous
enumerating attack or from a web crawler.
In the partial SPIT experiment (SPIT not covering all the domain extensions,
hit rate < 100 %), we send four successive campaigns with respectively one, ten,
ﬁfty and hundred concurrent calls. In the ﬁrst campaign, Spitter does not start a
dialog before the previous dialog is ﬁnished. In the second campaign, ten dialogs
go on at the same time and only when a dialog is ﬁnished, a new dialog is started.
The four resulting traces (duration about two minutes each) are injected - after
adaptation (we assume that one agent of the real trace is performing the attack
against the hundred other agents) - in four diﬀerent normal traces (duration
of two hours each). The traces are then cut into slices of thirty messages and
analyzed. These are annotated positively for the period of attack and negatively
in all the remaining duration. The mixed trace with ﬁfty concurrent calls SPIT
is used in the training stage. The SVM prediction results are shown in Table 8.
True positives are the percentage of vectors correctly classiﬁed as attack over
all the vectors of the attack period. True negatives are the percentage of vectors
correctly classiﬁed as normal over all the vectors of the normal period. These
results should be considered under the larger umbrella of event correlation. For
instance, the example with ten concurrent calls:
– Most of the two hours traﬃc is normal and is correctly detected (47436
slices).
– 16 out of the 766 slices that compose the attack traﬃc are detected. This
means that we have ten correct events in a period of two minutes, because
the detection of one slice is highly relevant to all ongoing traﬃc around this
slice.
In addition, the attacks are partial since they target a small fraction of the users
of the VoIP server (more than 3000 users are identiﬁed in the two hours period).
326
M. Nassar, R. State, and O. Festor
Table 8. Detection of Partial SPIT in Four Mixed Traces With Diﬀerent Intensities
# of Concurrent Calls True Positives (%) True Negatives (%)
RBF; C= 1; γ = 1/38; Training accuracy = 99.0249
1
10
50
100
1
10
50
100
0 (0/3697)
1.30 (10/766)
10.01 (62/619)
18.31 (102/557)
Linear ; C=1 ; Training accuracy = 99.0197
0 (0/3697)
2.09 (16/766)
10.66 (66/619)
19.39 (108/557)
100
100
We agree that a stealthy SPIT of the magnitude of one concurrent call is never
detected, but in the case of hundred concurrent calls, one over ﬁve positives is
successfully detected when training was done using a half of this intensity attack.
With the help of a set of deterministic event correlation rules, our online
monitoring system is able to detect the attacks eﬃciently:
Predicate
10 distributed positives in a 2 minutes period
Multiple Series of 5 Successive Positives
Multiple Series of 10 Successive Positives
SPIT intensity
Low
Medium
High
Table 9. Detection of Full SPIT in Four Mixed Traces With Diﬀerent Intensities
# of Concurrent calls
100
RBF; C= 1; γ = 1/8; Training accuracy = 98.9057
10
50
1
True Positives
True Negatives
0.03
3.05
12.18
23.41