title:Rollback and Forking Detection for Trusted Execution Environments
Using Lightweight Collective Memory
author:Marcus Brandenburger and
Christian Cachin and
Matthias Lorenz and
R&quot;udiger Kapitza
2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Rollback and Forking Detection for Trusted
Execution Environments using Lightweight
Collective Memory
Marcus Brandenburger
IBM Research - Zurich
Christian Cachin
IBM Research - Zurich
Matthias Lorenz
TU Braunschweig
Rüdiger Kapitza
TU Braunschweig
Abstract—Novel hardware-aided trusted execution environ-
ments, as provided by Intel’s Software Guard Extensions (SGX),
enable to execute applications in a secure context that enforces
conﬁdentiality and integrity of the application state even when
the host system is misbehaving. While this paves the way towards
secure and trustworthy cloud computing, essential system support
to protect persistent application state against rollback and
forking attacks is missing.
In this paper we present LCM – a lightweight protocol to
establish a collective memory amongst all clients of a remote
application to detect integrity and consistency violations. LCM
enables the detection of rollback attacks against the remote
application, enforces the consistency notion of fork-linearizability
and notiﬁes clients about operation stability. The protocol exploits
the trusted execution environment, complements it with simple
client-side operations, and maintains only small, constant storage
at the clients. This simpliﬁes the solution compared to previous
approaches, where the clients had to verify all operations initiated
by other clients. We have implemented LCM and demonstrated
its advantages with a key-value store application. The evaluation
shows that it introduces low network and computation overhead;
in particular, a LCM-protected key-value store achieves 0.72x –
0.98x of an SGX-secured key-value store throughput.
I. INTRODUCTION
Despite numerous efforts by industry and academia cloud
computing suffers still from trust issues [24], [33]. This is
not surprising as companies possess limited control once their
applications and data enter the cloud. Users have to trust the
operating personal and a complex software stack composed
of management software, virtualization layers, as well as
commodity operating systems. On top, cloud providers are
typically reluctant to share their exact system details because
this information is critical for their business.
recently
[31]
released
technology of
Software Guard Extensions
The
(SGX)
Intel
is expected to make a
change, as it addresses trust issues that customer face when
outsourcing services to off-site locations and still gives
cloud providers the freedom to not disclose their system
details. SGX offers an instruction set extension that allows
to establish trusted execution contexts, called enclaves.
These enclaves might be tailored and comprise only a small
dedicated fraction of an application [21], [8] or can contain an
entire legacy application and the necessary operating system
support [4], [2]. Thereby, the plaintext of enclave-protected
data and code is only available for computation inside the
CPU, and encrypted as soon as it leaves the CPU package
again. In this way, enclave-residing data is even guarded
against unauthorized accesses by higher privileged code and
from attackers with administrative rights and physical access.
While SGX can be considered as a big step forward towards
trustworthy cloud computing, some attack vectors nevertheless
remain. One important open issue are rollback and forking
attacks on stateful applications that make use of persistent
storage. Whereas SGX provides mechanisms against main-
memory replay attacks, persistent storage is not under the
direct control of SGX and therefore harder to secure. The need
to handle system restarts, operating system crashes, and power
outages makes a completely secure solution for state continuity
difﬁcult to achieve. Baumann et al. [4] who pioneered the ﬁeld
by proposing application enclaves acknowledge this issue and
suggest to use a central external service that is contacted on
every request. However, this only delegates the problem to an
external entity, demands additional remote communication and
adds another single point of failure. Strackx and Piessens [38],
on the other hand, proposed abstractions on top of hardware-
based trusted counters. This and similar approaches [14], [26],
[32], [38] enable immediate detection of forking attacks but
suffer from bad performance, as writing and reading trusted
non-volatile counters for every request
is time-consuming.
Finally, there are a number of approaches that do not rely
on secure execution contexts, such as enclaves, but utilize
only plain resources of an untrusted provider [7], [10], [11],
[17], [30], [35]. These systems typically require cooperating
clients to verify each server response. In particular, this comes
with additional communication overhead between clients and
server, and requires costly cryptographic veriﬁcation.
In this paper we present Lightweight Collective Memory
(LCM) – a distributed protocol to establish a collective mem-
ory amongst all clients of a remote application to detect
integrity and consistency violations. By leveraging trusted
execution environments (TEEs), such as SGX, LCM keeps
client
interaction and service state conﬁdential. It ensures
fork-linearizability [30], which denotes the strongest consis-
tency notion among the clients that can be achieved in the
presence of rollback attacks without direct client-to-client
communication and in absence of trusted non-volatile memory.
Furthermore, LCM notiﬁes clients about operation stability.
This criteria refers to stable operations where a client can be
2158-3927/17 $31.00 © 2017 IEEE
DOI 10.1109/DSN.2017.45
157
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
Clients
Trusted execution environment (TEE)
invoke 
operations
Trusted execution context (T)
Server (S)
Protected 
memory (M)
load 
store
Stable 
storage
Persistent 
state
Fig. 1. System model comprising trusted clients, a potentially misbehaving
server S that hosts a trusted execution context T .
sure that its request has been acknowledged by a designated
number of other clients. A typical size would be the majority
of clients. Finally, compared to previous approaches that rely
on trusted counters, applications secured by LCM can be
migrated across physical TEEs and maintain their capability
to detect rollback attacks and to enforce fork-linearizability.
We implemented LCM as a Java and C++ framework and
demonstrate its advantage by securing a key-value store. We
evaluated the performance of the prototype by using the YCSB
benchmark and compare with native execution and SGX-
secured approaches. It turns out that a SGX-secured key-value
store achieves 0.3x – 0.76x performance of unprotected native
execution. However, the performance of LCM is 0.8x – 1.1x
of the SGX-secured key-value store throughput, while on top
enabling rollback and forking detection.
The remainder of the paper is structured as follows. Sec. II
provides a detailed problem description and outlines the neces-
sary background. In Sec. III, past solutions for state continuity
are discussed and the goals of LCM are stated. Next, the
overall architecture and the LCM protocol are introduced in
Sec. IV. Sec. V provides the details of our implementation
using SGX. Subsequently, Sec. VI explains the evaluation
results. Finally, Sec. VII outlines related approaches while
Sec. VIII concludes the paper.
II. PROBLEM DESCRIPTION
A. System model
We consider an asynchronous distributed system with n
clients C1, ..., Cn and a server S. The server contains a trusted
execution environment (TEE), which hosts a trusted execution
context T ; this is an isolated, protected container that runs an
application protocol and is trusted by the clients. A protocol P
speciﬁes the behavior of the clients, the server S, and the
trusted execution context T . All clients are correct, follow P ,
and mutually trust each other; clients and the server may
crash but are able to recover with the help of stable storage,
which they can access through load and store operations.
In contrast, T is correct but runs under the control of S as
explained in detail later; T does not have direct access to stable
storage and may lose its state. The server is either correct and
follows P or is Byzantine, deviating arbitrarily from P .
The clients and T interact by exchanging messages as
speciﬁed by P . They communicate indirectly through the
server which should forward messages among them. If S is
correct, then their communication is reliable and respects ﬁrst-
in ﬁrst-out (FIFO) semantics; otherwise, S may arbitrarily
interfere with their messages. Clients have limited communica-
tion capabilities beyond this and do not interact with each other
normally. The clients invoke a stateful application functional-
ity F , which provides a set of operations; F deﬁnes a response
and a state change for every operation. The operations are
executed by T inside the TEE and, therefore, the state of
F is protected from a potentially malicious S. We use the
standard notions of executions, histories, sequential histories,
real-time order, concurrency, and well-formed executions from
the distributed-computing literature [3]. In particular, every
operation execution is represented by an invocation event and a
response event. A operation is called complete when a client
receives a response event. Two operations are concurrent if
the invocation event of one of them occurs before the other
operation is complete.
B. Trusted execution context
A TEE provides a secure context for executing applications,
isolated from the server that hosts the TEE. It protects the
conﬁdentiality and integrity of code and data for the applica-
tion running inside the execution context. More speciﬁcally, a
trusted execution context T is instantiated with a protocol P ,
which deﬁnes the program code executed by T . After server S
has created some T , S may start, terminate, and restart T at
its discretion. Once T has been created, P running within T
cannot be modiﬁed anymore nor may any other protocol P (cid:2) be
executed in T . The server may also create and run multiple
instances of T concurrently. The time between instantiation
and termination of T is called an epoch. The entire lifetime
of a trusted execution context can span multiple epochs.
The TEE provides access to a secure random number
generator that allows to build cryptographic primitives, such as
key generation, encryption and digital signatures. The TEE op-
erates a cryptographic key-management infrastructure rooted
in a secret key protected by the TEE, which may provide
a program-speciﬁc key to a trusted execution context. That
is, a function get-keyT,P is available to T when it executes
protocol P and returns a secret key k that is speciﬁc to P
and the TEE. Another T (cid:2), which is also instantiated with P ,
obtains the same k, but any T running P (cid:2) (cid:2)= P or any other
TEE obtains a key different from k.
The clients can verify that a trusted execution context
has been instantiated with a certain protocol P and that P
is indeed running inside the TEE. This is essential for the
assumption that T is trusted. For this purpose clients leverage
a procedure called remote attestation [1]. In short, a client
with prior information about P sends a challenge to T and
in return receives a cryptographic proof φ that reﬂects P and
the underlying TEE. The client then veriﬁes φ and becomes
convinced that T runs P , based on the cryptographic protocol
and on its trust in the TEE.
Furthermore, T is equipped with a small protected memory
area M that can only be accessed by T . It holds the execution-
speciﬁc state as deﬁned by P . Neither the server nor any
other trusted execution context can access or modify M. The
protected memory is volatile, thus M is only accessible within
an epoch of T . In other words, when T stops, crashes, or
restarts, then M is lost. This is not an issue for stateless
158
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
protocols, but services without state are generally not very
useful; in realistic applications, where the server maintains
some state, M must be restored after T has been restarted.
For this reason M is stored externally on stable storage using
load and store, so that T can access state from another epoch.
C. Threats
Normally server S is correct, but it may become malicious
and behave incorrectly, when corrupted by an attacker or
affected by a software bug. A malicious server has full control
over the operating system, applications, and the data residing
in memory and stable storage, but it cannot tamper with code
and data in the trusted execution context. This means T is
correct and follows P even though S is malicious.
However, S controls every interaction of T with the envi-
ronment. A malicious server may intercept, modify, reorder,
discard, or replay messages to and from T . Although some
of those attacks can be prevented by establishing a secure
channel between a client and T , a malicious S may simply
discard their messages; such a denial-of-service (DoS) attack
is outside the scope of this work, however.
The trusted execution context must consider anything that it
receives as untrusted. In particular, this holds when T accesses
the stable storage through load and store, in order to persist
its state M. With a correct S, load always returns the state
that has been stored most recently. For protecting against a
malicious S, the trusted execution context uses encryption and
authentication to protect M before it leaves T . Yet, a malicious
server may still return a correctly protected but outdated state
to T . We call such a consistency violation a rollback attack.
In particular, a malicious server may restart T at any time and
load its memory from some state that T has stored earlier.
Furthermore, a malicious server may start multiple instances
of a trusted execution context and let the clients interact with
different instances over time. In this way, clients may be sepa-
rated so that they only see operations of other clients talking to
the same instance. Even if the TEE can run only a single T at
a time, S can multiplex different copies of the trusted context.
The malicious server might supply a different, but valid state to
each trusted execution context instance, similar to a rollback
attack. This clearly violates the consistency of the data, so
that the responses from different trusted execution contexts to
the clients diverge. We call this a forking attack; it is more
general than a rollback attack because multiple instances of T
answer concurrently to the clients. Note that with a single
instance of T a forking attack always involves at least one
rollback attack. It is well-known that clients cannot detect
rollback and forking attacks in asynchronous systems, unless
they communicate directly with each other [30].
III. PROTECTING AGAINST FORKING ATTACKS
A. Trusted monotonic counters
For defending an execution context T against a forking
attack, we need to assure state continuity, i.e., that the state
of T evolves continuously and is never rolled back. One might
think that T could simply maintain a cryptographic hash of M
159
inside the TEE whenever it stores M and verify that upon
a load operation. However, this does not work because the
memory of T and the TEE is volatile and disappears when
the epoch ends.
To overcome this, T will need non-volatile storage that
survives reboots. Such defenses have been proposed in the
form of an attested append-only memory (A2M) [15] or a
trusted incrementor (TrInc) [26]. These works demonstrate
that the functionality needed from the trusted non-volatile
storage can be reduced to a trusted monotonic counter (TMC).
In more detail, suppose T has access to a TMC that is
located in the TEE, the TMC uses a non-volatile storage
location that survives power loss, and the TMC’s state and
its communication with T are protected from S. Whenever T
stores M at the untrusted server, it increments the counter and
includes the counter value with the state. When T is restored,
e.g. after a reboot, it loads its state from S, extracts the
counter value, reads the TMC, and compares it to the extracted
counter. Since T protects all stored data cryptographically
with a key known only inside the TEE, the server cannot
tamper with the counter attached to M. This allows T to detect
rollback attacks. However, this approach suffers from several
disadvantages as we argue now.
it
First,
is not easy to tolerate concurrent crashes and
maintain liveness [32] at the same time; that is, when T
has incremented the TMC but the server crashes before the
counter value has been saved to the non-volatile trusted area,
then T might falsely accuse the correct server of performing a
rollback attack. The reason is T cannot differentiate between a
rollback attack and a server crash. In order to tolerate crashes,
one can resort to complex schemes that ensure state continuity,
which increment
the TMC, save it persistently, and write
state to disk atomically; they either need hardware modifac-
tions [36] or perform a variation of 2-phase commit [32], [38],
but the latter only works for deterministic operations, which
can be replayed by T and always give the same output.
Second, TMC-based solutions often suffer from limited
performance. Typically, TMCs are implemented using TPMs
which are well known to be slow [32]. The reason is that
in order to prevent a counter overﬂow, the TMC artiﬁcially
increases the time to increment the counter to several mil-
liseconds. Although a response time of a several milliseconds
is acceptable for, say, digital right management (DRM), this
has a negative impact on the throughput of a server application
that processes requests at a high rate.
Finally, the main disadvantage of any TMC-based approach
is the lack of location transparency. That is, the TMC is
normally bound to one trusted execution environment within