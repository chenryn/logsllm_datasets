title:ReDeBug: Finding Unpatched Code Clones in Entire OS Distributions
author:Jiyong Jang and
Abeer Agrawal and
David Brumley
2012 IEEE Symposium on Security and Privacy
ReDeBug: Finding Unpatched Code Clones in Entire OS Distributions
Jiyong Jang, Abeer Agrawal, and David Brumley
Carnegie Mellon University
{jiyongj, abeer, dbrumley}@cmu.edu
Pittsburgh, PA, USA
Abstract—Programmers should never ﬁx the same bug twice.
Unfortunately this often happens when patches to buggy code
are not propagated to all code clones. Unpatched code clones
represent latent bugs, and for security-critical problems, latent
vulnerabilities, thus are important to detect quickly.
In this paper we present ReDeBug, a system for quickly
ﬁnding unpatched code clones in OS-distribution scale code
bases. While there has been previous work on code clone
detection, ReDeBug represents a unique design point that uses
a quick, syntax-based approach that scales to OS distribution-
sized code bases that include code written in many different
languages. Compared to previous approaches, ReDeBug may
ﬁnd fewer code clones, but gains scale, speed, reduces the
false detection rate, and is language agnostic. We evaluated
ReDeBug by checking all code from all packages in the Debian
Lenny/Squeeze, Ubuntu Maverick/Oneiric, all SourceForge C
and C++ projects, and the Linux kernel for unpatched code
clones. ReDeBug processed over 2.1 billion lines of code at
700,000 LoC/min to build a source code database, then found
15,546 unpatched copies of known vulnerable code in currently
deployed code by checking 376 Debian/Ubuntu security-related
patches in 8 minutes on a commodity desktop machine. We
show the real world impact of ReDeBug by conﬁrming 145
real bugs in the latest version of Debian Squeeze packages.
Keywords-debug, unpatched code clone, scalability
I. INTRODUCTION
Patches to buggy code are often not propagated to code
clones in real OS distributions. For example, the following
patch was issued for Expat, a widely used XML parser to
ﬁx a bounds checking bug in August 2009.
{
-
+
const char *end,
POSITION *pos)
while (ptr != end) {
while (ptr < end) {
switch (BYTE_TYPE(enc, ptr)) {
#define LEAD_CASE(n) \
case BT_LEAD ## n: \
Listing 1: CVE-2009-3720
This bug, when exploited, causes a denial of service
to the victim [14]. While the above patch ﬁxed Expat in
2009, an additional 386 locations across various Debian,
Ubuntu, and SourceForge packages currently have clones
of the exact same buggy code, all of which are also likely
to be vulnerable. We call such bugs unpatched code clones.
© 2012, Jiyong Jang. Under license to IEEE.
DOI 10.1109/SP.2012.13
48
In this paper we present ReDeBug, a lightweight syntax-
based code clone detection system that identiﬁes unpatched
code clones at scale. We have used ReDeBug to analyze
entire OS distributions to understand the current situation of
unpatched code clones: 1) how much (potentially) vulnerable
code can an attacker identify when a patch is released, 2)
how responsive is the new version of an OS to known secu-
rity vulnerabilities, and 3) how many persisting unpatched
code clones are from the previous version of an OS to the
latest version of an OS.
Existing research has focused on methods for improving
the number of code clones detected, e.g., [21, 23–25]. While
advancements in ﬁnding more code clones is important,
current algorithms make several trade-offs:
• Scalability: To give a sense of the scale necessary to
ﬁnd all unpatched code clones, consider that Debian
Lenny currently contains over 210 million lines of non-
empty, non-comment lines of C code alone. Current
approaches focus on ﬁnding as many code clones as
possible, not scale. For example, Deckard [23] was
applied to the Linux kernel and JDK, but could not
scale to the entire Debian Lenny code base, and started
consuming more than 20GB of memory in less than 2
minutes. In big development houses one can use clus-
ters of computers to make the approaches scale [21].
However, solutions that can ﬁnd a competitive number
of code clones without requiring clusters are relevant
because they are cheaper to run (thus can be run more
often) and are applicable to the wider number of de-
velopers who don’t readily have distributed computing
resources.
• Lack of support for many different languages: Since
OS distributions include programs written in a variety
of languages such as C/C++, Java, Shell, Python, Perl,
Ruby, and PHP, we want techniques that are language
agnostic. Current research such as Deckard [23], CP-
Miner [25], CCFinder [24], and Deja Vu [21] ﬁrst parse
the program and use a variety of matching heuristics
based upon high-level code representations such as
CFGs and parse trees. However, implementing robust
parsers for many different languages is a very difﬁcult
problem [7].
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:03 UTC from IEEE Xplore.  Restrictions apply. 
• High false detection rate: The advanced heuristics
used to ﬁnd more code clones introduce a high false
detection rate, i.e., a large number of false code clones
are reported. For example, Deja Vu boasts the highest
accuracy we are aware of at 26-34%, meaning 66-74%
are false code clones. That’s 2 out of every 3 reports.
A considerable amount of resources would be wasted
to inspect all the reported cases.
ReDeBug tackles a new point in the design space where
we trade more expensive, yet thorough, pattern matching
algorithms for speed, scalability, and a language-agnostic
property:
• Scalability: ReDeBug uses a syntax-based pattern
matching approach that can be implemented using
extremely efﬁcient data structures which allow fast
querying for code clones when given a patch. ReDeBug
processed source code into a database at about 700,000
LoC/min on a commodity desktop. This database of
over 2.1 billion lines of code can then be queried in less
than 8 minutes. Therefore, ReDeBug can also be used
as part of the normal development and patch process
on hardware available to an average developer or user,
e.g., an average desktop.
• Language agnostic: Roughly speaking, ReDeBug per-
forms simple normalization where all whitespace is
removed and all characters are transformed to their
lower-case equivalent. Such simple normalization al-
lows ReDeBug to identify a variety of latent security
vulnerabilities in programs written in many different
languages. Interestingly, in our evaluation, Deckard –
a tree-based code clone detection technique – missed
6x more code clones than ReDeBug, not counting
languages handled by ReDeBug but not supported by
Deckard (§ IV-A).
• Lower false detection rate: ReDeBug focuses on de-
creasing false detection rate by using a close-to-exact
matching instead of fuzzier matching employed by pre-
vious code clone work. This means we may ﬁnd fewer
unpatched code clones, but that we will also have fewer
false positives due to mis-matches. ReDeBug has false
positives when vulnerable code is not detected as dead
code by the underlying compiler, and when a previously
identiﬁed vulnerable code segment is used in a way
that makes it non-exploitable. Deja Vu and similar
approaches have similar sources of false detection, plus
errors in the matching algorithms themselves [21, 23–
25]. As a result, Deja Vu had a false detection rate
of 66-74%, which is on the better end of similar code
clone detection mechanisms [21, 23–25]. ReDeBug has
zero errors due to matching, thus does not suffer from
the major source of false positives found in previous
work.
We have used ReDeBug to check for unpatched code
clones in Debian 6.0 Squeeze (348,754,939 LoC 1), De-
bian 5.0 Lenny (257,796,235 LoC), Ubuntu 11.10 Oneiric
(397,399,865 LoC), Ubuntu 10.10 Maverick (245,237,215
LoC), Linux Kernel
(8,968,871 LoC), and all C/C++
projects at SourceForge (922,424,743 LoC). So far, Re-
DeBug has found 15,546 unpatched code clones in the
total 2,180,581,868 LoC by checking 376 Debian/Ubuntu
security-related patches. The patches address a variety of
issues ranging from buffer overﬂows, to information dis-
closure vulnerabilities, to denial of service vulnerabilities.
Our measurements indicate that even though ReDeBug is
simpler, it actually ﬁnds a comparable number of code clones
to existing approaches (§ IV-A).
Previous work has shown that once a patch is released, an
attacker can use the patch to reverse engineer the bug and
automatically create an exploit in only a few minutes [10].
Our experiments indicate one security implication of ReDe-
Bug is an attacker, using a single laptop, could potentially
ﬁnd thousands of vulnerable applications among billions of
lines of code in only a few minutes once a patch is released,
assuming he has already preprocessed the code.
In addition to ﬁnding unpatched code clones, we have
conducted the ﬁrst study of the amount of code cloning in
the entire Debian Lenny source base. By performing pair-
wise comparison among functions, ReDeBug provides the
distribution of function pairs based upon their similarity (see
§ III-H)
Overall, our main contributions are:
• We analyze entire OS distributions to comprehend the
current trends of unpatched code clones. To the best
of our knowledge, ReDeBug is the ﬁrst tool to explore
over 2.1 billion lines of entire OS distributions to under-
stand unpatched code clone problems. We show that un-
patched code clones are a recurring problem in modern
distributions, and ﬁnd 15,546 unpatched code clones
from Debian Lenny/Squeeze, Ubuntu Maverick/Oneiric
distributions, the Linux kernel, and SourceForge. So far,
ReDeBug has conﬁrmed 145 real bugs.
• We describe ReDeBug, which suggests a new design
space for code clone detection in terms of scalability,
speed, and false detection rate. In particular, the design
point makes ReDeBug realistic for use by typical de-
velopers in everyday environments in order to improve
the security of their code by quickly querying known
vulnerabilities.
• We provide the ﬁrst empirical measurement of the
total amount of copied code in OS distributions. This
suggests that in the future, unpatched code clones will
continue to be important and relevant.
1We always count non-empty, non-comment lines.
49
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:03 UTC from IEEE Xplore.  Restrictions apply. 
A. The Core System
II. REDEBUG
Finding all unpatched code clones is tricky and involves
numerous considerations. For example, how many lines of
code need to be similar for a case to be reported? Is one
copied line enough, or are we only interested in multiple
line matches? Should whitespace matter? Should the order
of statements matter, and if so, should we only consider
some syntactic classes? Do we consider the syntactic text,
tokens, or the parse of ﬁles? For example, in C the order
of declarations likely does not matter, but
the order of
computation may. What if two segments are equivalent up
to variable naming? What about semantic equivalence, e.g.,
one code sequence multiples by 2 while the other performs
a logical left shift. Are these similar or different?
These questions all involve trade-offs between accuracy,
efﬁciency, and how easy it is to implement a robust algo-
rithm. For example, consider code that is the same up to
variable names and variable declaration order. A straight
string match of the ﬁles may ﬁnd virtually no commonality.
We could certainly address these problems by normalizing
declaration order, and parse code to determine variable name
equivalence (so-called α-equivalence) [11]. However, run-
ning such algorithms require we implement parsing engines
(which can be fragile) and run additional algorithms that
cost time, thus reducing overall throughput. If we are not
careful we may end up subtly analyzing a model of the
original program that is not right, e.g., declaration order
matters when looking for buggy code clones of incorrect
shadow variable declarations.
ReDeBug’s choices are motivated by the design space
goals of: (1) focusing on unpatched code clones, (2) scaling
to large and diverse code bases such as OS distributions, (3)
minimizing false detection, (4) being modular when possible
and offer a user choice of parameters, and (5) be language-
agnostic as much as possible so that we work with the wealth
of languages found within an OS distribution code base. The
core of the ReDeBug system accomplishes these goals using
the following steps:
1) ReDeBug normalizes each ﬁle. By default ReDeBug
removes typical language comments, removes all non-
ASCII characters, removes redundant whitespace ex-
cept new lines, and converts all characters to lower
case. We also ignore curly braces if the ﬁle is C, C++,
Java, or Perl (as identiﬁed by extension or the UNIX
file command).
Normalization is modularized so that the exact nor-
malization steps can easily be changed.
2) The normalized ﬁle is tokenized based upon new lines
and regex substrings.
3) ReDeBug slides a window of length n over the token
stream. Each n tokens are considered a unit of code
to compare.
4) Given two sets fa and fb of n-tokens, we compute the
amount of code in common. When ﬁnding unpatched
code clones, if fa is the original buggy code snippet
we calculate
CONTAINTMENT(fa, fb) =
(1)
|fa ∩ fb|
|fa|
When we want to measure the total amount of sim-
ilarity between ﬁles, we calculate the percentage of
tokens in common (i.e., the Jaccard index):
|fa ∩ fb|
|fa ∪ fb|
SIMILARITY(fa, fb) =
(2)
With either calculation it is common to only con-
sider cases where the similarity or containment
is
greater than or equal to some pre-determined threshold
θ. In our implementation, we also perform obvious
optimizations such as when θ = 1 only verifying
fa ⊆ fb instead of calculating an actual ratio for
CONTAINMENT.
5) ReDeBug performs an exact match test on the iden-
tiﬁed unpatched code clones to remove Bloom ﬁlter
errors. ReDeBug also uses the compiler to identify
when a code clone is dead code when possible.
For example, suppose we have two ﬁles A = t1t2t3t4
and B = t1t3t4t2 where each ti
is a token (note to-
kens are written in the order that
they appear in the
ﬁle). The tokenization is then A = {t1, t2, t3, t4} and
B = {t1, t3, t4, t2}. When n = 2, there are 3 2-token
strings in each set: fA = {(t1, t2), (t2, t3), (t3, t4)} and
fB = {(t1, t3), (t3, t4), (t4, t2)}. The similarity is 1/5 since
1 out of 5 2-token sets are shared, (t3, t4), even though the
shared token sequence appears at different places in the ﬁle.
As a result, ReDeBug works with reordering, insertions, and
deletions of up to n-tokens.
ReDeBug is parametrized in two ways: the number of
consecutive tokens to consider together, n, and the threshold,
θ. n determines the sensitivity for statement reordering,
e.g., if n = 1 then statement order does not matter at all,
n = 2 looks at statement pairs, and so on. θ acts as a
knob to tell us what is a signiﬁcant amount of copying.
When θ = 1, two ﬁles must have exactly the same n-tokens
(after normalization). When θ = 0, any match is considered
signiﬁcant. Values in between represent thresholds for the
amount of similarity of interest. There is no “right” value
for these parameters. In our experiments we show typical
values that produce meaningful results. For example, n = 4
works well with existing patches.
Design point comparison: Our approach is in stark contrast
with current research trends in code clone detection, such as
Deckard [23], CP-Miner [25], Deja Vu [21], and others [1,
24], that focus on minimizing missed code clones at the
expense of other factors. These approaches also normalize
the code, but then perform additional steps such as parsing
50
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:03 UTC from IEEE Xplore.  Restrictions apply. 
// Original buggy code
char buf[8];
strcpy(buf, input);
// Possible patch 1
char buf[8];
- strcpy(buf, input);
+ strncpy(buf, input, 8);
// Possible patch 2
char buf[8];
+ if(strlen(input) < 8)
strcpy(buf, input);
Figure 1: Buggy code example and two possible patches
Overall,
the code into high-level representations like parse trees and
control ﬂow graphs. They then employ advanced fuzzy
matching algorithms on the abstractions to ﬁnd additional
code clones that we may miss. On the other hand, they
may report more false code clones, which require signiﬁcant
human effort to inspect all the reported cases. Furthermore,
it is known to be very hard to implement good parsers [7].
the main difference is by employing simpler
techniques that is language agnostic, we can focus on ef-
ﬁcient data structures and algorithms and ultimately scale to
much larger code bases written in many different languages.
Our techniques may miss some clones, but minimize false
clone detection rate. This is important for at
two
reasons. First, by checking all code in a distribution quickly
we can make basic guarantees that at least syntactically
similar unpatched code clones do not exist. Second, we
can conservatively estimate the amount of code cloning in
existing large code bases. The more advanced algorithms in
the above work have not demonstrated they can make either
claim.
least
B. Unpatched Code Clone Detection
At a high level, there are two approaches to ﬁnd unpatched
code clones in OS distributions: (1) ﬁrst ﬁnd all code clones
among the source and then check if a patch applies to copies,
or (2) check for clones of only the patched code. Previous
work has focused on techniques for ﬁnding all clones such
as in (1). This makes sense when doing bug ﬁnding on
whole code bases is cheaper to do on unique code snippets.
ReDeBug takes approach (2) because we only want to ﬁnd
clones of the original unpatched buggy code.
ReDeBug looks for unpatched code clones where patches
are in UNIX uniﬁed diff format. Uniﬁed diffs are pop-
ular among open source kernel developers, OS distribution
maintainers, and are well-integrated into popular revision
control systems like Subversion [12].
A uniﬁed diff patch consists of a sequence of diff hunks.
Each hunk contains the changed ﬁlename, and a sequence of
additions and deletions. Added source code lines are preﬁxed
by a “+” symbol, and deletions are preﬁxed by a “-” symbol.
Line changes are represented as deleting the original line and
adding back the changed lines.
The original buggy code includes all code deleted by
the patch. However, simply looking for the lines that were
changed (by being deleted) is insufﬁcient: we must also
consider the surrounding context of the patch.
Consider the buggy code and two possible patch scenarios
shown in Figure 1. Patch 1 signiﬁes that strcpy is buggy
by deleting the line of code. The code is replaced with the
safe strncpy version. We can go looking for the deleted
line of code, and ﬂag it as buggy everywhere we see it.
However, patch 2 simply adds a check. Looking for the
missing check is not straightforward since we cannot directly
look for missing lines of code. Our approach is to look for
copies of the surrounding context tokens, c, for each changed
line and report clones of the context.
The overall steps used by ReDeBug to detect buggy code
clones, shown in Figure 2, are:
• Step 1: Pre-process the source. A user obtains all
source ﬁles used in their distribution. For Debian, this is
done using the apt tool. ReDeBug then automatically: