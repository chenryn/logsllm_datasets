execution takes 1654 seconds on average to process one input
(Fact 3). On the other hand, a fuzzer often retains much more
inputs than what concolic execution could handle (Fact 4). As
a result, the input corresponding to the speciﬁc branch that
block the fuzzing (i.e., the input that could lead execution
to the target place) only has a very small chance to be
picked up and processed by concolic execution. Therefore, the
Assumption 2 described above does not really hold in practice.
This conclusion can be further conﬁrmed by Fact 5 where the
3
Observations. To assess the performance of “optimal switch”,
we evaluate how MDPC works on the 118 binaries from the
CQE dataset for 12 hours and have 3 interesting observations.
TABLE I: Execution Time Comparison
Minimum
25% percentile
Median
Average
75% percentile
Maximum
Fuzzing
0.0007s
0.0013s
0.0019s
0.0024s
0.0056s
0.5000s
Concolic execution MDPC decision
0.16s
13s
65s
149s
213s
672s
18s
767s
1777s
1790s
2769s
3600s
(1) Table I shows the throughput gap among fuzzing, concolic
execution, and the optimal decision in MDPC. We can
observe that the optimal decisions is very expensive, which
is several thousand times larger than fuzzing.
(2) As MDPC makes optimal decision before exploring each
path, the overall analysis throughput is signiﬁcantly re-
duced, from 417 executions per second in pure fuzzing to
2.6 executions per second in MDPC.
(3) With the impact of reduced throughput, MDPC discov-
ers vulnerabilities only in 29 binaries, whereas the pure
fuzzing can discover vulnerabilities in 67 binaries.
As MDPC makes the optimal decision before exploring
the expensive optimal decision takes away the
each path,
 0204060801000100200300400500600700Percentage (%)Period of being stuck (seconds)     0204060801000100200300400500600700Percentage (%)Period of being stuck (seconds)0500100015002000135791113151719212325272931333537394143454749Number of inputsBinary ID# of inputs from thefuzzer# of inputs taken byconcolic execution0400800120016002000# of inputs taken byconcolic execution# of inputs from thefuzzeradvance of the high throughput of fuzzing. As an optimization,
we can move the optimal decision out, make it work in parallel
with fuzzing, and build a concurrent MDPC. That is, the
optimal decision in the concurrent MDPC does not interfere
the working progress of fuzzing, and it just collected coverage
statistics from fuzzing to calculate cost. From the evaluation
of this concurrent MDPC, we have another observation.
(4) Nearly all the missed paths are decided to be explored
by concolic execution in several seconds after the fuzzing
starts. By examining the coverage statistics, we observe
that the fuzzer is able to generate hundreds of test cases in
several seconds, which leads to a high cost for exploring a
missed path by fuzzing, based on the algorithm in MDPC.
On the contrary, the cost of concolic execution is smaller
even we assign the highest solving cost (50 as deﬁned [42])
to every path constraint.
Limitations. The aforementioned observations indicate that
the key limitation of the “optimal switch” strategy is that
estimating the cost for exploring a path by fuzzing and concolic
execution is heavyweight and inaccurate, which overshadows
the beneﬁt of making optimal solutions.
First, estimating the cost of concolic execution relies on
collecting path constraints and identifying the solving cost
for these constraints. As collecting path constraints requires
converting program statements into symbolic expressions, such
interpretation is also heavyweight, especially for program with
long paths. In addition, MDPC designs a greedy algorithm
for optimal decision. This algorithm depends on path-sensitive
program analysis. For programs with large states, the path-
sensitive analysis is also heavyweight.
Second, it is nontrivial to accurately estimate the cost for
exploring a given path by fuzzing and concolic execution.
MDPC estimates the solving cost based on the complexity
of path constraints, and estimates the cost of random testing
based on coverage statistics. These estimations are concerned
with the run-time throughput of fuzzing,
the performance
of the constraint solver, and the symbolic execution engine.
Each of them are different program analysis techniques in
nature. Therefore, it is challenging to deﬁne a uniﬁed metric
to evaluating the cost of different techniques.
III. PROBABILISTIC PATH PRIORITIZATION GUIDED BY
MONTE-CARLO
To address the aforementioned limitations of the current
hybrid fuzzing systems, we propose a novel “discriminative
dispatch” strategy to better combine fuzzing and concolic
execution.
A. Key Challenge
As discussed above, the key challenge of our strategy is
to quantify the difﬁculty of traversing a path for a fuzzer in
a lightweight fashion. There are solutions for quantifying the
difﬁculty of a path using expensive program analysis, such as
value analysis [45] and probabilistic symbolic execution [5].
However, these techniques do not solve our problem: if we
have already performed heavyweight analysis to quantify the
difﬁculty of a path, we might as well just solve the path
constraints and generate an input to traverse the path.
B. Monte Carlo Based Probabilistic Path Prioritization Model
In this study, we propose a novel Monte Carlo based
Probabilistic Path Prioritization Model (M CP 3 for short) to
deal with the challenge. In order to be lightweight, our model
applies the Monte Carlo method to calculate the probability of
a path to be explored by fuzzing. For the Monte Carlo method
to work effectively, two requirements need to be full-ﬁlled:
1). the sampling to the search space has to be random; 2).
a large number of random sampling is required to make the
estimations statistically meaningful. Since a fuzzer randomly
generates inputs for testing programs, our insight is to consider
the executions on these inputs as random samples to the whole
program state space, thus the ﬁrst requirement is satisﬁed.
Also, as fuzzing has a very high throughput to generate test
inputs and perform executions, the second requirement can also
be met. Therefore, by regarding fuzzing as a sampling process,
we can statistically estimate the probability in a lightweight
fashion with coverage statistics.
According to the Monte Carlo method, we can simply
estimate the probability of a path by statistically calculating
the ratio of executions traverse this path to all the executions.
However,
this intuitive approach is not practical, because
maintaining path coverage is a challenging and heavyweight
task. With this concern, most of the current fuzzing techniques
adopt a lightweight coverage metric such as block coverage
and branch coverage. For this challenge, we treat an execution
path as a Markov Chain of successive branches, inspired by a
previous technique [4]. Then, the probability of a path can be
calculated based on the probabilities of all the branches within
the path.
Probability for each branch. The probability of a branch
quantiﬁes the difﬁculty for a fuzzer to pass a condition
check and explore the branch. Equation 1 shows how M CP 3
calculates the probability of a branch.
(cid:40)
P (bri) =
cov(bri)
cov(bri)+cov(brj ) ,
cov(brj ) ,
3
cov (bri) (cid:54)= 0
cov (bri) = 0
(1)
In Equation 1, bri and brj are two branches that share the
same predecessor block, and cov(bri) and cov(brj) refer to
the coverage statistics of bri and brj, representing how many
times bri and brj are covered by the samples from a fuzzer
respectively.
When bri has been explored by fuzzing (cov(bri) is non-
zero), the probability for bri can be calculated as the coverage
statistics of bri divided by the total coverage statistics of bri
and brj.
When bri has never been explored before (cov(bri) is zero),
we deploy the rule of three in statistics [43] to calculate the
probability of bri. The rule of three states that if a certain
event did not occur in a sample with n subjects, the interval
from 0 to 3/n is a 95% conﬁdence interval for the rate of
occurrences in the population. When n is greater than 30, this
is a good approximation of results from more sensitive tests.
Following this rule, the probability of bri becomes 3/cov (brj)
4
Fig. 3: Overview of DigFuzz
if cov(brj) is larger than 30. If cov(brj) is less than 30, the
probability is not statistically meaningful. That is, we will not
calculate the probabilities until the coverage statistics is larger
than 30.
Probability for each path. To calculate the probability for a
path, we apply the Markov Chain model [19] by viewing a
path as continuous transitions among successive branches [4].
The probability for a fuzzer to explore a path is calculated as
Equation 2.
(cid:89){P (bri)|bri ∈ pathj}
P (pathj) =
(2)
The pathj in Equation 2 represents a path, bri refers to a
branch covered by the path and P (bri) refers the probability of
bri. The probability of pathj shown as P (pathj) is calculated
by multiplying the probabilities of all branches along the path
together.
C. M CP 3 based Execution Tree
In our “discriminative dispatch” strategy,
the key idea
is to infer and prioritize paths for concolic execution from
the runtime information of executions performed by fuzzing.
For this purpose, we construct and maintain a M CP 3 based
execution tree, which is deﬁned as follows:
Deﬁnition 1. An M CP 3 based execution tree is a directed
tree T = (V, E, α), where:
• Each element v in the set of vertices V corresponds to a
unique basic block in the program trace during an execution;
• Each element e in the set of edges E ⊆ V × V corresponds
to the a control ﬂow dependency between two vertices v and
w, where v , w ∈ V . One vertex can have two outgoing edges
if it contains a condition check;
• The labeling function α : E → Σ associates edges
with the labels of probabilities, where each label indicates the
probability for a fuzzer to pass through the branch.
IV. DESIGN AND IMPLEMENTATION
In this section, we present the system design and imple-
mentation details for DigFuzz.
5
A. System Overview
Figure 3 shows the overview of DigFuzz. It consists of
three major components: 1) a fuzzer; 2) the M CP 3 model;
and 3) a concolic executor.
Our system leverages a popular off-the-shelf fuzzer, Amer-
ican Fuzzy Lop (AFL) [47] as the fuzzing component, and
builds the concolic executor on top of angr [38], an open-
source symbolic execution engine, the same as Driller [39].
The most important component in DigFuzz is the M CP 3
model. This component performs execution sampling, con-
structs the M CP 3 based execution tree, prioritizes paths
based on the probability calculation, and eventually feeds the
prioritized paths to the concolic executor.
DigFuzz starts the testing by fuzzing with initial seed
inputs. As long as inputs are generated by the fuzzer, the
M CP 3 model performs execution sampling to collect cov-
erage statistics which indicate how many times each branch is
covered during the sampling. Simultaneously, it also constructs
the M CP 3 based execution tree through trace analysis and
labels the tree with the probabilities for all branches that
are calculated from the coverage statistics. Once the tree
is constructed and paths are labeled with probabilities, the
M CP 3 model prioritizes all the missed paths in the tree, and
identiﬁes the paths with the lowest probability for concolic
execution.
As concolic execution simultaneously executes programs
on both concrete and symbolic values for simplifying path
constraints, once a missed path is prioritized,
the M CP 3
model will also identiﬁes a corresponding input that can guide
the concolic execution to reach the missed path. That is, by
taking the input as a concrete value, the concolic executor
can execute the program along the preﬁx of the missed path,
generate and collect symbolic path constraints. When reaching
to the missed branch,
it can generate the constraints for
the missed path by conjoining the constraints for the path
preﬁx with the condition to this missed branch. Finally, the
concolic executor generates inputs for missed paths by solving
path constraints, and feeds the generated inputs back to the
fuzzer. Meanwhile, it also updates the execution tree with the
paths that have been explored during concolic execution. By
leveraging the new inputs from the concolic execution, the
fuzzer will be able to move deeper, extent code coverage and
update the execution tree.
FuzzingInitial inputExecution samplingConcolic executionPrioritized paths New inputsProbability based path prioritizationExecution tree constructionb4b1b2b3b6b8Probabilistic path prioritization model based on Monte CarloAlgorithm 2 Execution Tree Construction
1: CF G ← {Control ﬂow graph for the target binary.}
2: Setinputs ← {Inputs retained by the fuzzer}
3: HashM apCovStat ← {Output from Algorithm 1}
4: ExecT ree ← ∅
5:
6: for input ∈ Setinputs do
7:
8:
9:
10:
11: end for
12: for bri ∈ ExecT ree do
13:
14:
15:
16: end for
brj ← GetNeighbor(bri, CF G)
prob ← CalBranchProb(bri, brj, HashM apCovStat)
LabelProb(ExecT ree, bri, prob)
trace ← TraceAnalysis(input)
if trace /∈ ExecT ree then
ExecT ree ← ExecT ree ∪ trace
end if