direct authentication applications, usually around 100 bits of
responses are required. Therefore, the direct implementation
described so far would require C = 128.8K challenge bits.
This high ratio of challenge length to response length limits
its practical use in many scenarios when communication is
expensive.
B. Challenge Compression through Distributional Relaxation
We now describe the proposed strategy based on space-
efﬁcient LWE that overcomes the limitation on communica-
tion inefﬁciency. The LWE decryption function described in
Section IV-A requires a challenge c in the form c = (a, b) to
be sent from the server to the PUF. To represent vector a ∈ Zn
requires n log q bits while to represent scalar b ∈ Zq requires
only log q bits. Thus, the major cost of transmission lies in
sending a. We wish to avoid sending a directly and, instead,
to send a compressed (shorter) version of a and re-generate
its full-size version on the PUF. Our approach is enabled by
the recent results on the distributional behavior of a = AT x
[2] and the concept of space-efﬁcient LWE [15].
q
Recall that b is given by:
b = bT x + r(cid:98)q/2(cid:99)
= (As + e)T x + r(cid:98)q/2(cid:99)
= (AT x)T s + eT x + r(cid:98)q/2(cid:99).
First, we replace the component a = AT x by a∗ uniformly
randomly sampled from Zn
q . That allows us to represent
challenge c = (a, b):
(cid:40)
as c∗ = (a∗, b∗):(cid:40)
a = AT x
b = (AT x)T s + eT x + r(cid:98)q/2(cid:99)
a∗
b∗ = a∗T s + eT x + r(cid:98)q/2(cid:99)
.
   1000120014001600Secret Bits106105104103102101Decryption Error RateIn [2], it is proven that distribution of c∗ = (a∗, b∗) is statisti-
cally close to the original ciphertext distribution, therefore the
required security properties are preserved.
The advantage of the above approximation is that, as
shown by [15], several low-complexity PRNGs are capable of
producing an output string a(cid:48) suitably close to a∗ ∈ Zn
q within
the context of LWE cryptosystem. In particular, an LFSR
is an especially simple PRNG having the right properties.
Speciﬁcally, a vector a(cid:48) generated by an LFSR provides similar
concrete security guarantees against standard attacks on LWE,
such as CVP reduction, decoding, and basis reduction [15].
This is because LFSR-generated a(cid:48) maintains good properties
including:
• it is hard to ﬁnd “nice” bases for a lattice with basis from
• given an arbitrary vector in Zn
LFSR-generated a(cid:48);
q , it is hard to represent it
as a binary linear combination of LFSR-generated a(cid:48)’s;
• it is hard to ﬁnd a short vector w that is orthogonal to
LFSR-generated a(cid:48)’s.
The ability to rely on a simple PRNG to produce a(cid:48) allows
a dramatic reduction in challenge transfer cost. Now,
the
challenge c(cid:48) contains only a small seeda(cid:48) into the PRNG and
the corresponding b(cid:48) as
b(cid:48) = (a(cid:48))T s + eT x + r(cid:98)q/2(cid:99)
= LFSR (seeda(cid:48))T s + eT x + r(cid:98)q/2(cid:99).
Here LFSR(·) denotes the output generated by an LFSR.
With LWE parameters chosen as Section IV-A, using a
seed of length l = 256 is able to reduce the challenge
length from 1288 to 256 + 8 = 264 per one bit of response.
The improvement of efﬁciency becomes more pronounced for
generating multiple responses: This is because a(cid:48)
t can
be generated sequentially from the l-bit seed, so that only
t ∈ Zq are required to be sent to the
the seed and b(cid:48)
PUF side. 100 bits of responses now require only transmitting
256 + 100 × log 256 = 1056 bits for challenges.
C. Countermeasure for Active Attack
1, . . . , b(cid:48)
1 . . . a(cid:48)
The focus of the paper is a PUF secure against passive
attacks in which the observed challenges can be used to derive
an internal model of the PUF. However, the LWE decryption
function is vulnerable to an active attack that supplies arbitrary
input challenges. (As we show, this risk also carries into an
LFSR-based variant).
The attack is premised on the ability to supply arbitrary
challenges (ciphertexts) as inputs to the decryption function.
The attack proceeds as follows. The attacker ﬁxes a and
enumerates all possible b ∈ Zq for challenge c = (a, b). As
b increases from 0 to q − 1, the response r = Q(b − (cid:104)a, b(cid:105))
changes from Q(b − (cid:104)a, s(cid:105)) = 0 to Q(b + 1 − (cid:104)a, s(cid:105)) = 1
exactly when b satisﬁes
b − (cid:104)a, s(cid:105) = q/4.
We denote this speciﬁc value of b as ˆb. The exact value of
(cid:104)a, s(cid:105) can then be extracted by (cid:104)a, s(cid:105) = ˆb− q/4. By repeating
this procedure n times, the attacker is able to set up n linear
equations (without errors):
(cid:104)a0, s(cid:105) = ˆb0 − q/4,
(cid:104)a1, s(cid:105) = ˆb1 − q/4,
···
(cid:104)an−1, s(cid:105) = ˆbn−1 − q/4.
Gaussian elimination can then be used to solve for s. The
reason the attack succeeds is that attackers are able to ﬁx a
and use it for multiple values of b.
We overcome the risk of such an attack by adopting the
technique in [49]: we introduce a self-incrementing counter to
embed the counter value into a challenge seed. This makes the
attack impossible as the counter restricts the attacker’s ability
to completely control input challenges to the LWE decryption
function. As a result, the attacker cannot enumerate all values
of b while keeping a unchanged. As shown in Figure 1, the
concatenation of the challenger-provided seed and the counter
value t (i.e. seeda(cid:48)||t) is used as the seed for generating a.
The counter value is public and is incremented by 1 on each
response generation.
V. EXPERIMENTAL RESULTS
In this section, we build a behavior model simulator of the
constructed lattice PUF, in which the statistical model of raw
SRAM POKs follows from [32], [33] and other digital circuit
components are accurately emulated by Python. 1000 lattice
PUF instances are virtually manufactured (simulated) and their
CRPs are extracted to evaluate (1) statistical properties of the
lattice PUF, including uniformity, uniqueness, and reliability
with parameters chosen in Section IV, and (2) vulnerabil-
ity to state-of-the-art ML attacks. In order to quantize the
lightweightness, we implement the entire lattice PUF system
(except for the raw SRAM cells) on a Spartan 6 FPGA and
compare it with prior work.
A. Statistical Analysis
Uniformity of a PUF characterizes unbiasedness, namely,
the proportion of ‘0’s and ‘1’s in the output responses. For an
ideal PUF f, the proportion needs to be 50%. We adopt the
deﬁnition of uniformity in [35] based on the average Hamming
weight HW(f ) of responses r to randomly sampled challenges
c’s:
HW(f ) = IEc[HW(r)] = IEc[HW(f (c))].
Here IEX represents expectation over random variable X. Note
that c follows the ciphertext distribution rather than the usual
uniform distribution [35]. Figure 4 shows uniformity obtained
using 1000 randomly selected challenges. The distribution is
centered at 49.98%, the standard deviation is 1.58%.
Uniqueness measures the ability of a PUF to be uniquely
distinguished among a set of PUFs. Based on [35], we deﬁne
this metric to be the average inter-class HD of responses
(ri, rj) under the same challenges c for a randomly picked
PUF pair (fi, fj):
HD(fi, fj) = IEc[HD(ri, rj)] = IEc[HD(fi(c), fj(c))].
Fig. 4: Uniformity of lattice PUF output.
Fig. 6: ML attacks: Lattice PUF remains resistant
to all
attacks (DNNs, LR, SVM,1-NN). DNN ultimately succeeds
in modeling two other strong PUFs.
Fig. 5: Uniqueness and reliability of lattice PUF output.
For ideal PUFs, responses under the same challenges are or-
thogonal, namely, HD(fi, fj)’s are close to 50%. Uniqueness
is also evaluated under the ciphertext distribution.
Uniqueness is shown in Figure 5, evaluated for 1000 PUF
instances. The lattice PUF achieves near-optimal uniqueness:
inter-class HD is centered at 50.00%, its standard deviation is
1.58%.
Reliability of a PUF f is characterized by the average BER
of outputs with respect to their enrollment values:
BER = IEf(cid:48)[HD(f, f(cid:48))] = IEf(cid:48),c[HD(f (c), f(cid:48)(c))].
As discussed in Section IV, the overall BER of the lattice PUF
is due to two components: the failure rate of key reconstruction
and LWE decryption error rate. Intra-class HD in Figure 5
reﬂects the result of decryption errors by assuming a perfect
key reconstruction.
B. Empirical ML Resistance
While the ultimate promise of lattice PUF is due to its
theoretically-supported reliance on hard computational prob-
lems, testing its resilience to empirical ML attacks is important
and provides additional conﬁdence about the lattice PUF. We
Fig. 7: Lattice PUF is resistant to both traditional ML attacks
and DNNs.
evaluate the vulnerability of lattice PUF to a range of tradi-
tional (i.e., not based on deep learning) ML attack methods,
including SVM, LR, and single-layer NN (1-NN), as well as
a number of DNNs. We use the Python package scikit-learn
[40] to implement SVM and LR. The SVM uses a nonlinear
kernel with radial basis functions (RBF). The 1-NN model uses
only one hidden feed-forward layer composed of 100 neurons,
with the rectiﬁed linear unit (ReLU) as the activation function.
Training of 1-NNs and subsequent DNNs are implemented
using Keras [12] with TensorFlow [1] backend.
DNNs represent a more powerful class of binary classiﬁers.
DNNs contain multiple hidden layers that produce superior
modeling expressiveness compared to 1-NNs [18]. Impor-
tantly, DNNs have been recently shown to be very effective
in attacking known strong PUFs, including XOR APUFs and
IPUFs [43]. Our baseline DNN experiment (DNN-1) is based
on the same network parameters as in [43]. The network has
0.10.30.50.70.9Hamming Weight0510152025Fraction (%)=0.4998=0.01580.10.30.50.70.9Hamming Distance0102030405060Fraction of Intra-HD (%)=0.0126=0.0288=0.5000=0.01580510152025Fraction of Inter-HD (%)103104105106Number of CRPs0.010.11.00.5Prediction ErrorLattice PUF(4,4)-IPUF4-XOR APUFDNN-1DNN-2DNN-3DNN-4DNN-5  LRSVM1-NN103104105106Number of CRPs0.460.480.500.520.54Prediction ErrorDNN-1DNN-2DNN-3DNN-4DNN-5  LRSVM1-NNTABLE I: Various conﬁguration for DNN attacks.
Setup
DNN-1
DNN-2
DNN-3
DNN-4
DNN-5
Hidden
Layers
4
4
4
6
4
Neurons
per Layer
100
100
100
100
200
Challenge
Distribution
PRNG
PRNG
Ciphertext
PRNG
PRNG
Input
Format
Binary
Real
Binary
Binary
Binary
Prediction
Error
49.86%
49.84%
49.76%
49.80%
49.87%
TABLE II: Conﬁguration of error-correcting codes.
Raw BER
(%)
1
5
10
15
Error-Correcting Code
Outer code
Inner code
Raw POKs
[236, 128, 14]
[218, 128, 11]
[220, 128, 12]
[244, 128, 15]
N/A
[3, 1, 1]
[5, 1, 2]
[7, 1, 3]
2,360
6,540
11,000
17,080
4 hidden layers, each containing 100 neurons. It uses ReLU
as the non-linear operator.
In addition to the baseline conﬁguration, we explored
attacks using several other network architectures, hyper-
parameters, and numeric representations, as listed in Table
I. DNN-2 treats input as 161 integer numbers from 0 to
255, instead of 1288 binary bits. DNN-3 is different from
the baseline version in its CRP generation strategy (see more
below). DNN-4 and DNN-5 add more hidden layers and
more neurons per hidden layer respectively, compared to the
baseline DNN-1.
Figure 6 shows the results of the empirical attacks based
on the above ML algorithms. The ﬁgure shows the prediction
error of lattice PUF in response to these attacks with training
set size ranging from 1000 to 1 million and test set of size
200K. The Adam optimizer [27] terminates after 200 epochs,
and results in a prediction error of 49.86% for the proposed
lattice PUF, barely better than a random guess. The results
show that the prediction error of lattice PUF remains ﬂat
for all attempted attacks: across the range of attacks and
CRP training set sizes, there is no measurable deviation of
the error from 0.5. In contrast, a DNN (with a conﬁguration
corresponding to DNN-1) achieves less than 2% prediction
error for both 4-XOR APUF and (4, 4)-IPUF.
It is critical that the experiments also demonstrate that lattice
PUF design that utilizes the distributional relaxation of space-
efﬁcient LWE (described in Section IV-B) shows the same
empirical resistance to ML attacks as the design not based on
such a relaxation. In Table 1, all design/attack combinations
except for DNN-3 are based on the compact (relaxation-based)
design in which CRPs are generated via a PRNG. Finally, we
also provide an expanded view of the results of ML attacks
on lattice PUF in Figure 7 by zooming in Figure 6. While
run-to-run variations of the training optimizer are observable,
the prediction error remains close to 50%.
C. Hardware Implementation Results
We now present the details of lattice PUF implementation
and analyze its hardware efﬁciency. The entire design, except
TABLE III: (a) Area consumption and (b) runtime of our
reference lattice PUF implementation on Xilinx Spartan-6
FPGA.
Module
LFSR
LWEDec
Controller
Total
(a)
Size [slices]
27
2
16
45
(b)
Step
Seed seeda(cid:48)||t load for LFSR
1-bit decryption from LWEDec
Total @ 33 MHz
Time [µs]
8
44
52
TABLE IV: Hardware implementation costs of strong PUFs.
Design
POK+AES [7]
Controlled PUF [17]
CFE-based PUF [19], [21]
Lattice PUF