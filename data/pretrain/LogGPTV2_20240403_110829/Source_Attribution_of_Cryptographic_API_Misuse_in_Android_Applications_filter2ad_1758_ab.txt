se2
se3
se4
se5
Symbol Expression
invoke-direct Ljavax/crypto/spec/SecretKeySpec;->init( Ljavax/crypto/spec/SecretKeySpec;, [B, “AES” )
invoke-static Ljavax/crypto/Cipher;->getInstance( “AES/CBC/PKCS5Padding” )
invoke-direct Ljavax/crypto/spec/IvParameterSpec;->init( Ljavax/crypto/spec/IvParameterSpec;, [B )
invoke-virtual Ljavax/crypto/Cipher;->init( se2, 0x2, Ljavax/crypto/spec/SecretKeySpec;, Ljavax/crypto/spec/IvParameterSpec; )
invoke-virtual Ljavax/crypto/Cipher;->doFinal( se2, [B )
threshold. So the key is to set up a reference probability for
the threshold, which is computed based on the distribution of
probabilities of all unique API sequences used for training our
models. We currently use the 80% percentile as the threshold.
Once a sequence is detected as a misuse (i.e., lower than the
threshold), we shall identify the possible misuse locations. For
that, we deﬁne the probability of an API m used in a location
l of an API sequence s = m1, m2, m3, . . . , mT with l ≤ T as
the probability of the sequence obtained by replacing ml with
m:
P (m | s, l) = P (s[ml (cid:55)→ m])
These probabilities clearly can be used as the scores for all
the APIs such that we can sort all the APIs according to their
probabilities for any location of any sequence. Then based on
the sorting, we deﬁne the distance of an API m used in a
location l of a sequence s as the order in the corresponding
ordered list for l and s:
dis(m | s, l) = order({P (m(cid:48) | s, l) | m(cid:48) ∈ AP Is})
Generally, the misuse APIs would have a lower probability
and thus have a large distance. Accordingly, we identify the
misuse locations for a misuse sequence s as the ones that
have a top-k distance among all the locations of s, where k
is a small integer.
TABLE II
API SEQUENCES FROM APK DATASET
Dataset
Training
Validation
Testing
Positive
Num Min Max
23
8890
23
3381
3478
30
5
5
5
Negative
Num Min Max
41
17509
41
4747
5296
41
5
5
5
Avg
7.36
7.34
7.38
Avg
6.96
8.24
6.82
sequences that contain no error (resp, some errors) reported by
CogniCryptSAST, Num denotes the total number of sequences,
Min, Max, and Ave denote the minimum length, the maximum
length, and the average length for the extracted API sequences,
respectively.
In our experiments, we use the following performance
measures to quantitatively validate the experimental results.
Accuracy is the most intuitive performance measure and it
is simply a ratio of correctly predicted observation to the
total observations. Precision is the ratio of correctly pre-
dicted positive observations to the total predicted positive
observations, and Recall is the ratio of correctly predicted
positive observations to all observations in actual class. F1
score is the weighted average of Precision and Recall, that is,
(2·P recision·Recall)/(P recision+Recall). Intuitively, the
higher the measures above, the better the model.
III. EXPERIMENTS
B. Model Selection
This section presents the experimental results, including
model selection, API usage analysis, and comparison with
CogniCryptSAST.
A. Dataset and Evaluative Criteria
To create our dataset, we collect 87375 APKs from the
benign samples of AndroZoo [23], released from 2016 to 2019.
We currently focus on the libraries of “javax.crypto”. So we
perform a quick scan on the collected APKs to ﬁlter out that
have not used any API from the target libraries, and keep
the remaining 19766 ones for our dataset. Next, we extract
the API sequences from the selected APKs via the analysis
in Section II-A. Then we ﬁlter out the sequences of length
smaller than 5, which we think should not be a complete
usage, and identify the reported errors by CogniCryptSAST
among the remaining sequences, yielding the dataset for
crypto API usages. Moreover, among these selected APKs, we
take 11856 APKs as the training set, 3957 as the validation
set, and 3953 as the testing set. Table II lists some results
of the dataset, where Positive (resp, Negative) denotes the
As shown in Section II-B, there is a hyper-parameter K (i.e.,
the state number) for HMM that needed to be ﬁxed. For that,
we take the range [5, 15] as the candidate for K. This is due
to that the minimum length is 5 and that the average length
of the extracted API sequences ranges from 6 to 8. And for
each value in the candidate, we build a HMM taking it as the
state number K from the positive sequences4 in the training
set. After all the models are built, we then perform them on
the validation set and select a model according to the results.
The results for HMM with different state numbers on the
validation set are given in Table III, which show that the
performances of the models are quite close, although with
different state numbers. In particular, the HMM with 12 states
obtains the highest accuracy and the highest precision, while
the HMM with 8 states achieves the highest recall and the
highest F1 score. As a result, the HMM with 8 states is
selected.
4We take only the positives as we would like the models to capture the
correct usages.
RESULTS FOR HMM WITH DIFFERENT STATE NUMBERS
TABLE III
K
5
6
7
8
9
10
11
12
13
14
15
Accuracy
66.68%
66.60%
65.92%
67.23%
66.83%
66.70%
66.80%
67.45%
67.37%
67.37%
67.19%
F1
Recall
Precision
62.99%
68.17%
58.54%
62.98%
68.29%
58.44%
67.61%
62.27%
57.71%
68.58% 63.52%
59.15%
68.08%
63.06%
58.73%
63.02%
68.20%
58.57%
63.02%
58.72%
67.99%
59.51% 68.05%
63.50%
63.39%
67.90%
59.43%
59.40%
68.11%
63.46%
63.20%
67.73%
59.24%
RESULTS FOR NGM WITH DIFFERENT GRAM SIZES
TABLE IV
N
3
4
5
Accuracy
68.08%
69.68%
70.90%
F1
Precision
64.35%
60.09%
62.10%
65.62%
63.39% 71.10% 67.02%
Recall
69.26%
69.56%
Likewise, we need to ﬁx a hyper-parameter N (i.e., the
gram size) for NGM. The selection procedure is similar to
the above. We currently set the gram size ranges from 3 to
5. This is because (i) 3-gram, 4-gram, and 5-gram models,
as shown in [13], generated reasonable results; and (ii) the
average length of the extracted API sequences ranges from 6
to 8.
The results for NGM with different gram sizes on the
validation set are given in Table IV. From the results, we
can see that 5-gram model performs best in all the evaluative
criteria. Hence, 5-gram model is selected. Compared with
HMM, NGM performs slightly better on the validation set.
C. API Usage Analysis
Using the selected models, we perform experiments to
analyze the crypto API usages, including the usage detection
and the misuse location, on the testing set.
Usage Detection. The usage detection results are given in
the top half part of Table V, where Sym-HMM and Sym-
NGM denote our selected HMM and NGM, respectively; and
Baseline denotes the results of a random predictor wherein half
the positives and half the negatives are assumed to be predicted
correctly. The results indicate that both our models obtain a
better result than the baseline on the testing set. Compared
with Sym-NGM, Sym-HMM achieves (a better recall and) a
better F1 score.
In addition to the correct usages, we also concern about the
misuse usages. For that, we turn over the positives and the
negatives, and recompute the corresponding evaluative criteria
(marked with a superscript “T”), which is shown in Table V
as well. From the results, we can see that both our models
perform well in terms of all the evaluative criteria as well.
And Sym-NGM performs better than Sym-HMM.
Moreover, we also compare our models with the no-
symbolic-execution versions, namely, a variant of Nguyen et.
Fig. 3. API Misuse Location
al.’s approach [9] on crypto APIs (using HMM but no symbolic
execution, denoted as No-HMM) and a variant of Wang et. al.’s
approach [13] on crypto APIs (using n-gram model but no
symbolic execution, denoted as No-NGM). As our symbolic
analysis has already captured the dependences between the
objects in the libraries of “javax.crypto”, we drop off the
symbolic expressions in the API sequences of our dataset and
use them to build No-HMM and No-NGM in the same way
as shown in Section III-B.
The results are given in the bottom half part of Table V,
from which, we can see that No-HMM and No-NGM can
capture the correct usages as well, which is in accordance
with existing work [9], [13]. However, the usage information
they capture contains only the API dependence orders, such
that they are not good at detecting the misuse crypto APIs. As
shown in Table V, both the F1 scores of No-HMM and No-
NGM on the misuse detection are quite close to the random
baseline.
Compared with No-HMM (resp. No-NGM), Sym-HMM
(resp. Sym-NGM) performs 11.77% (resp. 16.82%) better on
the usage detection in term of F1 score. Moreover, our models
still perform well on the misuse detection, and can improve
35.35% and 28.29% in term fo F1 score for HMM and NGM,
respectively. This indicates that our approach is preferable
to crypto APIs, even to domain-speciﬁc API usage analysis,
because domain-speciﬁc APIs are sensitive to not only API
orders, but also their arguments.
Nevertheless, there are still some rooms for improvement
in our solution. For example, when creating an IvParameter-
Spec object, it needs to ensure that the byte array passed
to the object should be generated randomly. But
in our
symbolic analysis, the methods that are not in the libraries of
“javax.crypto” are abstracted, so that such methods for random
generation are lost. We can enhance our abstraction to address
this problem, which is left for future work.
Misuse Location. To evaluate our misuse location, we
performed it on the negatives in the testing set and checked
whether our reported top-k locations hit the ones reported by
CogniCryptSAST. The results are shown in Figure 3, which
demonstrated our location approach is effective. In detail, top-
1 can achieve about 78% accuracy for both Sym-HMM and
Sym-NGM. And the accuracy increases rapidly when k is not
larger than 3; after that, it goes slowly.
D. Comparison with CogniCryptSAST
Finally, we compare our models using top-1 as the misuse
location with a state-of-the-art tool CogniCryptSAST [6]. For
DETECTION RESULTS ON TESTING SET FOR DIFFERENT MODELS
TABLE V
Model
Sym-HMM
Sym-NGM
Baseline
No-HMM
No-NGM
Accuracy
70.38%
71.23%
50.00%
57.23%
57.67%
Precision
59.93%
61.60%
39.64%
47.68%
47.73%
F1
Recall
76.28% 67.12%
72.83% 66.75%
50.00% 44.22%
81.11% 60.05%
71.19% 57.14%
PrecisionT
81.02%
79.73%
60.36%
77.00%
72.06%
F1T
RecallT
66.50% 73.05%
70.19% 74.65%
50.00% 54.69%
41.54% 53.97%
48.79% 58.19%
TABLE VI
COMPARISON WITH COGNICRYPTSAST
Sym-HMM
Sym-NGM
for further analysis. Firstly, we found there are 88 errors in
common for all tools, and 2 more common errors reported by
both Sym-NGM and CogniCryptSAST. Secondly, among the
reported errors, 100, 99, and 132 ones are actual for Sym-
HMM, Sym-NGM, and CogniCryptSAST, respectively, that is,
the accuracies for the tools are 68.49%, 69.23%, and 95.65%,
respectively. One reason for this is that, in our models, an
API taking a misuse API as an argument could be reported
simultaneously, as it could have the same large distance as the
misuse one. We call this reason as argument passing. Clearly,
these errors caused by argument passing are duplicated. There
are 38 and 36 such kind of errors for Sym-HMM and Sym-
NGM, respectively. Setting these duplicated errors aside, the
accuracies of our models can reach 92.59% and 92.52%,
respectively, both of which are quite close to the one of
CogniCryptSAST. Finally, we also found that 12 (resp. 10)
actual errors reported by Sym-HMM (resp. Sym-NGM) are
not reported by CogniCryptSAST, most of which are due to
a wrong argument. Conversely, there are 44 (resp. 43) actual
errors reported by CogniCryptSAST are not reported by Sym-
HMM (resp. Sym-NGM), among which, 75.0% (resp. 88.9%)
are due to the abstraction as discussed in Section III-C.
IV. RELATED WORK
This section presents some recent related work on crypto
API usage analysis.
Android. Egele et al. [3] proposed a light-weight static tool
CryptoLint to identify misuses of crypto APIs for Android
applications, taking six rules as a guide. Later, Shao et al. [5]
proposed a systematic tool CMA, combining both static and
dynamic analysis, based on a manually built model of crypto
misuse vulnerabilities. And a similar analysis to Shao et
al.’s is presented by Chatzikonstantinou et al. [24] as well.
Ma et al. presented a tool CDRep for automatically repair-
ing crypto misuse defects in Android applications, wherein
CryptoLint [3] and CMA [5] is used in detection, and a
set of manually created patch templates is used in repairing.
Muslukhov et al. [25] developed a static tool BinSight to
attribute crypto APIs misusage to its source, wherein the rules
in CryptoLint [3] is used. Kr¨uger et al. [6] proposed a static
tool CogniCryptSAST to detect the crypto misuses in Android
applications, using a designed rule set rewritten in a deﬁnition
language CrySL from the Java Cryptography Architecture
documentation. Gao et al. [4] tried to infer crypto API usage
rules from the developer updates but obtained a negative result,
wherein CogniCryptSAST [6] is used to identity misusage.
*dictionary
APK
*runy
*Client
*collage
*Hero
*bonso
*Erudit
*client
*diner
*cake
*retro
*stock
*byapps
*game
*4791
*Apps
*diamond
*kingvip
*troll
*charles
*pvsh
*sytadin
*artkiss
*input
*scope
*ventura
*racks
*pushtan
*wallet
*newspapers
*babyplan
*share
*sounds
*travel eng
*awadcar
*white
*metro
*sogno
*compass
*monster
Total
N
0
0
2
1
0
0
10
8
6
0
0
6
0
0
2
6
4
7
6
1
1
1
0
11
6
8
12
4
4
6