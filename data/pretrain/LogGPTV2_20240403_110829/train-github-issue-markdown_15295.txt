When `np.array()` or `.asarray()` is used to go from a list of integers,
without specifying a dtype explicitly, it can pick default dtypes including
int64 & uint64. But there's a strange corner case where it defaults to float64
and loses precision, even though all the values could be uint64. Specfically,
this occurs when some but not all values can be int64:
    In [11]: max_int64 = np.iinfo(np.int64).max                                                                            
    In [12]: np.array([max_int64]).dtype                                                                                   
    Out[12]: dtype('int64')
    In [13]: np.array([max_int64 + 1]).dtype                                                                               
    Out[13]: dtype('uint64')
    In [14]: np.array([max_int64 + 1, max_int64]).dtype                                                                    
    Out[14]: dtype('float64')
It doesn't depend on the order they're in, and it's not a general consequence
of having two values rather than one - two values above this threshold get
`uint64` as I'd expect.
Tested on Numpy 1.18.4, Python 3.8.2.
Sorry if this has already been discussed; it's a tricky thing to search for.
This relates to an issue reported on h5py: h5py/h5py#1547 .