So we can compare the i-trees generated by human and Skill-
Explorer, and calculate the coverage c by c = |nh ∩ ns|/|nh|.
|nh| indicates the number of nodes in the i-tree explored by
humans. |nh∩ns| shows the number of nodes in both the i-tree
explored by humans and the i-tree explored by SkillExplorer.
In our evaluation, we randomly sample 50 skills from the 21
categories. Then we manually and extensively communicate
with them, trying to collect as many behaviors as possible,
which lasts for about 8 hours. 226 outputs from skills are
collected, including 28 Yes/No questions, 16 Instruction ques-
tions, 13 Selection questions, 17 Wh questions, and 53 Mix
questions. Further, we let SkillExplorer communicate with
the skills, and collect 203 different outputs. So the coverage
is 90% (=203 / 226). We further look into the 23 outputs
that are not covered by SkillExplorer and try to ﬁgure out
the reasons for missing. One reason is due to the problem
of NLP tools. 5 questions cannot be correctly parsed by the
tools (e.g., wrongly marked part of speech). Also due to the
carelessness of developers, some questions contain grammar
errors which cannot be correctly parsed. We also ﬁnd 11 ques-
tions require human expertise (e.g., “What SGLs do you want
to look up”) or use complex structures (e.g., “Okay, player
one tell me a name, by saying player one is, followed by the
name”), which are quite difﬁcult to answer even for human
users. More examples are shown in Appendix E.
Accuracy of answer generation. Regarding the accuracy, we
care about missed answers and incorrect answers. Missed an-
swers impact the coverage, which has already been evaluated
previously. So we evaluate incorrect answers here. Incorrect
answers cannot be accepted by skills, which may let SkillEx-
plorer waste time on unnecessary execution. We randomly
select 200 questions from each of the ﬁve categories classi-
ﬁed by SkillExplorer. In sum, 1,000 questions are analyzed
manually. We compare the two sets of answers and give the
error answer results in Table 4. On average, 6% of the answers
are wrong. Yes/no Question has the lowest ratio (0%), while
Mix Question is higher (9%). Note that the incorrect answers
impact neither the results of coverage nor the results of the
measurement. They only impose unnecessary analysis time
on the exploration of skills. The reasons for incorrect answers
are similar to those mentioned previously.
Performance. SkillExplorer has analyzed 28,904 skills
within 5,270 hours8 (using a machine with a 3.6GHz CPU,
8We registered 25 different Amazon developer accounts, and 2 Google
developer accounts for testing. 27 simulators were utilized (25 from Amazon
and 2 from Google).
USENIX Association
29th USENIX Security Symposium    2657
16GB memory, 1TB hard driver, and the Windows 10 operat-
ing system). Each skill costs about 627 seconds on average,
including the utterance question generation, question under-
standing, answer generation, and behavior exploration. The
median time of skill exploration is 428.5 seconds, ranging
from 36 seconds to 8,969 seconds. For different categories,
the time varies. It depends on the function and the branches
of the skill. A game skill always spends much more time
than a weather forecast skill because the game skill has more
branches for users to choose. By the way, the stability of net-
work connection matters as well. We also analyze the time of
Google actions, which is much smaller than Alexa’s, because
the test console of Google Assistant does not support all the
actions well and its robustness is not so good as Amazons’s,
making many actions unable to respond as they do in reality.
If we use the real smart speaker for evaluation, the time should
be much more. We also evaluate how much time could be
saved by our speedup mechanism (see Section 3.5). If this
mechanism is not used, the average time for each skill will be
885 seconds, which means that 29.2% (=258/885) of the time
could be saved by this mechanism.
4 Measurement
4.1 Landscape
Skills & Authors. We crawl 68,066 skills from the Ama-
zon market9, and 10,899 actions from the Google market.
Skills in Amazon have 21 different categories and the cat-
egory Games & Trivia has the largest number of skills (as
shown in Appendix F). Among these, 19.4% of them do not
have invocation names, which means that developers use the
pre-built model to build the skills. In other words, the devel-
opers cannot design their own questions, but use pre-designed
questions by the markets, which should not contain any mali-
cious questions. Thus, we do not measure these skills. Among
the rest 54,865 skills, we randomly sample 30,000 for the mea-
surement. However, some skills cannot be invoked due to that
Alexa only wakes up the more popular one or the previously
waked one if two skills have similar invocation names. So
in the end, 28,904 skills are measured. We also record the
developer names for the skills. In sum, 12,376 different devel-
oper names are recorded (a developer can register for different
accounts with different names). On average, one developer’s
name is in charge of 5.5 skills. Interestingly, the developer In-
foByVoice owns the most skills (i.e., 2,577 skills). All of them
are in the category Lifestyle. We check the interactive content
with them and ﬁnd that these skills provide organizations’
information. The developer Rhall owns 1,401 skills, and most
of them aim to explain some facts (e.g., a skill “California
9We crawled the skills from the America market from October 25, 2019
to November 12, 2019, where the number of skills is the largest in the world.
Different countries may access different numbers of skills according to the
policy of Amazon.
Facts” gives facts about California).
Structure of i-trees. We make a statistical analysis of i-trees.
We measure the number of branches in i-trees, depth of i-trees,
and the number of answers to a question. Figure 6 (a) shows
the distribution of the number of branches in i-trees. From
the ﬁgure, we can see that 90% of the skills have less than
15 branches. The average number of branches is 7.9. Some
skills have more than 50 branches (most of them are games or
Selection_SC questions with multiple choices), which are not
user-friendly to answer. Figure 6 (b) shows the distribution of
the depth of skills. The average depth is 3.6. From the ﬁgure,
the depth of 68% skills is less than 4, and the depth of 95%
skills is less than 10. It indicates that most skills do not interact
with users with deep conversation. We ﬁnd some skills are
with the depth of 40. They are story-tellers. We also look into
questions related to privacy. They are usually Wh questions,
with the depth less than 5. Skills can customize their services
from the requested information (e.g., assessing the value of
a house in a location). Figure 6 (c) shows the number of
answers to a question. The average number of answers is
2.9, which means that most questions only have about three
choices for users to answer. If there are too many answers in a
question, users may not be able to remember them to answer.
An interesting skill is Encyclopedia of dinosaurs. It contains
a question with 41 answers.
Popular questions and popular words. After analyzing
more than 160,000 questions in our measurement, we list
the top 5 questions in Appendix G. These questions are
mainly from the developers InfoByVoice and SkillSet. For
example, the question “say, service times, location, phone
number, or goodbye” is mentioned by 1,045 skills devel-
oped by InfoByVoice, and mentioned by 264 skills developed
by SkillSet. We also check the description of the skills on
the website of the two developers. Both of them mention
VoiceApps.com. Maybe the two developers have some con-
nections. We also count a question for only once if it appears
in different skills by the same developer. The most 10 pop-
ular words (we only count nouns in the constituency-based
parsing tree) are “skill”,“alexa”, “number”, “fact”, “help”,
“information”, “name”, “phone”, “location” and “service”.
Invocation names. Different from previous studies [26, 35]
on invocation names which mainly focus on the security prob-
lems of abnormal diversion (e.g., skill squatting, voice squat-
ting, voice masquerading), our study checks whether the in-
vocation names can meet Amazon’s requirements. As we
know, Amazon has strict requirements for designing invoca-
tion names [5]. Some sample rules are given in Appendix H.
We check whether all 57,139 skills having invocation
names10 are against the rules. We ﬁnd that 9,799 skills do not
meet the requirements. Among them, 120 skills do not follow
the rule (2): two-word names with article words (e.g., the, a,
10Some skills may not have invocation name which can be invoked through
implicit invocation.
2658    29th USENIX Security Symposium
USENIX Association
(a) number of branches
(b) depth of i-tree
(c) number of answers
Figure 6: Distribution of i-tree
Info Type
basic info
Keywords
full name, home address, email address, date
of birth, telephone number, etc.
Table 5: The words related to privacy
an). 377 invocation names are person or place names (e.g.,
bainbridge island), which violate the rule (3). 179 skills fail
to comply with the rule (4): using launch words (e.g., “open,”
“tell,” “load,”, etc.) or connecting words (e.g., “to,” “from,”
“in,”). Two invocation names contain “app” or “skill”. We
also ﬁnd that 2591 invocation names are used by 9,128 skills.
The most commonly used invocation name is how many days,
which is used by 153 skills.
4.2 Skills Conﬂicting with the Developer Spec-
iﬁcations
As we mentioned in Section 2, according to the rules of some
markets (e.g., Amazon), for some kinds of personal informa-
tion, developers are allowed to obtain them for better user
experience. Such information (shown in Table 5) includes a
user’s name, email address, phone number, etc. which should
be obtained by using speciﬁc APIs (e.g., Alexa customer pro-
ﬁle API) to conﬁgure permissions, and should be claimed
in the privacy policy of the skills [6]. For the permissions,
they can be seen on skills’ introduction pages. For the privacy
policy, the developers should clearly include what kinds of
personal information are collected, how and why to collect the
information. However, we ﬁnd some developers request such
information but do not claim in the privacy policy or conﬁg-
ure the corresponding permissions. Instead, they directly ask
users for private information. To detect the illegal collection
of information, we analyze them in the interactive content.
Note that we cannot directly compare the privacy words
in the Table 5 with the contents from skills. For example,
a skill may say “Our phone number is xxx-xxx-xxxx”. The
skill does not request such information from users. Instead,
it just gives information about the skill. To distinguish the
two situations, we leverage the dependency-based parse tree
where all the nodes are words. The links among words are
labeled by the syntactic function grammar tree. Particularly,
we use a two-step comparison. (1) We ﬁrst check whether
the words are used by skills with the correct part of speech.
Usually, the words are used as nouns. Sometimes, a skill may
use a different part of speech of the word. For example, in
the question “I can address the problem”, the word “address”
is used as a verb. To ﬁlter out such situations, we check the
part of speech of the privacy word and only identify those
used as nouns. (2) Then we check the ownership of the pri-
vacy words. We also leverage the dependency-based parse
tree, which shows the relationship of dependency between
words. For example, in Figure 7, the word name belongs to
your, whose connection can be extracted by the tags. In the
ﬁgure, nmod is used for nominal modiﬁers of nouns or clausal
predicates, while poss means possession modiﬁer. Their com-
bination nmod:poss is used for a nominal modiﬁer. However,
a counterexample is “Our phone number is xxx-xxx-xxxx”,
where the keyword phone number belongs to “our” (i.e., the
owners of the skill). We only check the privacy words belong-
ing to the users (e.g., using the word “your”). As developers
Figure 7: An example of dependency-based parse structure
may not directly request the privacy keywords to evade the
vetting process of markets, besides checking the keywords
themselves, we should also check their synonyms. So we
expend the privacy keywords using their synonyms.
After obtaining the privacy keywords that a skill requests
from users, we further determine whether the skill conﬂicts
with the development speciﬁcations. We ﬁrst check if these
keywords (including their synonyms) are declared in the
skill’s privacy policy. If not, the skill conﬂicts with the de-
veloper speciﬁcations. Otherwise, we should further check
whether the privacy keywords are clearly declared for request-
ing users’ information. If no such declaration is found, the
skill will be viewed as conﬂicting with the developer speciﬁ-
cations. However, in real situations, it is hard to check whether
the privacy keywords are used for requesting users’ data. An
example is “We collect users’ private data including their
USENIX Association
29th USENIX Security Symposium    2659
分支0.00.20.40.60.81.0020406080深度0.00.20.40.60.81.0010203040问题回答数0.00.20.40.60.81.0010203040name and email”, where the general term “personal data”
and the pronoun make the analysis difﬁcult. Fortunately, Pol-
icyLint [18] handles such situations. So we leverage Poli-
cyLint to solve this problem. Speciﬁcally, what makes the
situation complex is the general declaration which usually
contains three types of words to collect users’ information,
including a verb of collect information (e.g., collect, gather,
check), a general term (e.g., personal information, personal
data), and subsumptive relationships words (e.g., such as, in-
clude). Note that, due to the limited number of keywords used
by PolicyLint, it may not be enough to characterize all the
possible general declarations, especially for the diverse pri-
vacy policies given by various developers, and further causes
false positives. Thus, in our implementation, if any two of the
three types of words are in a declaration, we will view it as a
general declaration. Such an approach is very effective to ﬁnd
the declaration requesting users’ private data, which is then
compared with the contents in the skills to ensure whether the
skills conﬂict with privacy policies.
Results. We ﬁrst validate the accuracy of our approach. Af-
ter analyzing 30,801 skills (28,904 from Amazon and 1,897
from Google), SkillExploer ﬁnds 1,156 skills conﬂicting with
the developer speciﬁcations. Among these skills, 632 skills
neither state privacy keywords in privacy policies nor conﬁg-
ure corresponding permissions. 183 skills just conﬂict with
the claimed privacy policy, and 341 skills just do not con-
ﬁgure corresponding permissions. We manually check the
results of the comparison between the keywords and the pri-
vacy policies, and only ﬁnd 15 false positives which do not
conﬂict with privacy policies, mainly due to the following
two reasons. Firstly, the NLP tool (i.e., Stanford NLP Parser)
cannot correctly parse a sentence, for example, the tool will
label “username” as an adjective in the sentence “to use our
voice experiences users may provide us with their data such
as email, username and password to your service”. Secondly,
some declarations that explicitly state to collect users’ infor-
mation are not correctly caught by PolicyLint. For example,
“you may be asked to enter your zip code or other details to
help you with your experience.”.
After removing false positives, we ﬁnd 1,141 skills that
conﬂict with the developer speciﬁcations. We analyze the
keywords of these privacy contents. The most frequently re-
quested information is as follows: address, name, phone num-
ber, zip code , and email. Most of them are in the categories
of Lifestyle and Education & Reference. An interesting case
is the skill “WiﬁPassword”. It requests users’ wiﬁ name and
password and also asks them to ﬁnish the request through a
webpage popping up on users’ smartphones when such intent
is activated. Note that the skill never mentions this suspicious
request in its privacy policy list. We also check its reviews
on the market. Some users mentioned that “... after ﬁlling
out the form it gave me someone else’s network name and
password. What’s much worse is that that the name of the
wiﬁ network makes me believe that it’s very likely someone
near to my location, due to the name being a local refer-