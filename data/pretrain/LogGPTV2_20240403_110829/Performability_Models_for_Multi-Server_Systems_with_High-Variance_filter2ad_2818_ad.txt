10−1
0
M/2−Burst/1 Queue: ON=90, OFF=10, ν
S=2.0, α=1.4, T=5, θ=0.50
Analytic Result
Simulation M/2−Burst/1
Simulation Multi−processor
M/M/1 Queue
0.1
0.2
0.3
0.4
0.5
ρ
0.6
0.7
0.8
0.9
1
Figure 7. Simulation of a 2-server system: The plot
marked with circles shows that the effect of load indepen-
dence assumption can only be observed for short queue
lengths. The one marked by crosses corresponds to a simu-
lation of exactly the analytical model and is used to validate
our numerical results.
computed even without reduced state space representations,
we conclude this section by demonstrating that the blow-up
points in terms of tail probabilities of the queue-length dis-
tribution can be also clearly seen for larger N; in the case
of Figure 6 for N = 5, all ﬁve blow-up points are very
pronounced.
4. Simulation Experiments
With the analytic results as a baseline for comparison,
simulation experiments served two purposes: ﬁrst to evalu-
ate the effect of the load-independence assumption in the
analytic model, and second to explore our model under
more general assumptions.
In particular, we perform ex-
periments that simulate the failure handling strategies pre-
sented in Section 2.
Before we present these results, we discuss the difﬁcul-
ties inherent in creating simulations experiments that sam-
ple the TPT distribution.
As discussed in Section 2, the repair time distribution
can show power-tail like behavior over a wide range of
time-scales, but eventually the repair-time distribution is ex-
pected to drop off exponentially corresponding to a trun-
cated tail. Truncated tails can also be an artifact of the
ﬁniteness of sample sets in measurements or simulation
experiments. For instance, taking a large set of K sam-
ples from inter-arrival times of the TPT-DOWN model with
inﬁnite tail, corresponds to on average sampling L :=
K/(λE(U P + DOW N)) DOWN periods, or L power-tail
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007M/2−Burst/1 exp tasks, ν
s=2.0, ON=90, OFF=10, T=10, θ=0.2, α=1.4
Discard
Resume
Restart
95% Confidence Interval  (lower)
 Confidence Interval (upper)                 
Analytic
103
102
t
h
g
n
e
l
e
u
e
u
q
n
a
e
m
d
e
z
i
l
a
m
r
o
N
101
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
Utilization ρ
l
e
u
e
u
q
n
a
e
m
d
e
z
t
h
g
n
e
i
l
a
m
r
o
N
103
102
101
100
0
M/2−Burst/1 non−exp tasks, var=5.3, ν
s=2.0, ON=90, OFF=10, T=10, θ=0.2, α=1.4
Discard
Resume
Restart
0.1
0.2
0.3
0.4
Utilization ρ
0.5
0.6
0.7
0.8
Figure 8. Comparison between calculations from ana-
lytic model and simulation results: The latter show that
the failure handling strategies behave almost identically
with respect to mean queue length when task times are ex-
ponentially distributed. 95% The conﬁdence interval plot-
ted is for Discard.
samples. Since for high quality components the UP periods
can be very long (days to months), the number of power-
tail samples is rather small L := N · simultime/(U P +
DOW N). Simulation experiments would therefore require
immensely long simulated virtual time in order to assure
adequate sampling of the tails.
Figure 7 compares the exact analytic result of a M/2-
Burst/1 Queue with a simulation of the same system as well
as a simulation of the actual corresponding multi-processor
system. Since it is difﬁcult to obtain stable results for large
values of T , we limited our test case to T = 5. The main
difference of the multi-processor system is that i ≤ N op-
erational servers can only be fully utilized if at least i tasks
are at the queue. Hence, the service rate is not only modu-
lated by the number of active servers but also by the queue
length. This impact is however only visible for small queue
lengths, as Figure 7 shows.
In Figure 8, we compare the simulation results of the
three failure handling strategies for varying values of ρ
against the analytic computations. Each sample point in the
ﬁgure represents the mean of 10 indepedent runs that each
uses 2 × 105 UP/DOWN cycles. The results show that the
failure handling strategies behave almost identically, with
Restart being the worst and Discard the best. The choice
of parameter values for the UP and DOWN periods, namely
90 and 10, relative to that of the mean task service time 1,
was to allow us to obtain results within reasonable simula-
tion times. To improve the stability of the simulation results
and to provide for a more realistic choice of parameter val-
ues, the application of certain rare-event techniques, such
as importance sampling, may be investigated. Such a tech-
Figure 9. Simulation of M/2-Burst/1 system with hy-
perexponential task service times for varying fault han-
dling mechanisms.
nique, as applied to systems with heavy-tailed properties is,
however, still a subject of ongoing research [1].
Another variation that we considered is that of the task
service time being nonexponential. Intuitively, the Restart
strategy can be expected to be worst performing since a
restarted task’s duration is biased in that it must take at least
as long to execute as its elapsed execution duration when
the server failed. In fact, it is shown in [4] that the comple-
tion time of a restarted task exhibits power-tail behavior. In
Figure 9, we use a HYP-2 distribution with variance = 5.3 to
model the task service time distribution. The simulation re-
sults in that ﬁgure show that the ordering in which the strate-
gies perform holds, although the difference in mean queue
length has grown signiﬁcantly compared to that in Figure 8.
The blowup behavior, however, can still be observed for all
three variations. Other simulation experiments, not shown
here due to space limitations, show that for the Resume and
Restart recovery models, placing the interrupted task in the
back of the queue is better than placing it in the front.
5. Summary
This paper presents an analytic model of a cluster of
N nodes, which are subject to failure and repair. We for-
mulate the analytic model for general matrix-exponential
repair and failure times but then focus in the analysis on
high-variance repair times, due to their practical relevance.
Under certain assumptions, most of them can be easily re-
moved and also are shown to be not of major performance
inﬂuence, the cluster model can be expressed as a single
server M/MMPP/1 queue, which bears resemblance to ear-
lier teletrafﬁc models.
The analysis of performability metrics mainly focuses
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007on the mean queue length and on tail probabilities of the
queue-length distributions, since the latter can be mapped
to successful task completion probabilities under delay con-
straints. Parameter variations of any of the model parame-
ters, i.e. the number of server nodes N, the availability of
the server nodes, A, the degradation factor of service rate
during DOWN periods, δ, the service rate during UP, νp,
and the task arrival rate λ, can lead to a dramatic change
of all performance metrics, referred to as blowup-up points,
if high-variance repair time distributions are present. The
exact placement of the blowup boundaries in the parameter
space is obtained Section 3.
The analytic results are conﬁrmed by simulation experi-
ments which show that the main qualitative result, namely
the existence of the blow-up points for such systems, is ro-
bust to model variations, in particular the type of partici-
pating distributions, and the failure handling strategy em-
ployed.
ACKNOWLEDGEMENTS: This research was par-
tially supported by the EU IST FP6 project ’HIghly DE-
pendable ip-based NETworks and Services – HIDENETS’,
see www.hidenets.aau.dk. The authors would like to thank
the HIDENETS consortium, in particular Felicita Di Gian-
domenica, ISTI-CNR Italy, and Andrea Bondavalli, Univer-
sity of Florence, Italy, for their helpful comments. Further-
more, the authors would like to thank Michael Clark for the
implementation of the simulation, Lester Lipsky at the Uni-
versity of Connecticut for the discussions, and the anony-
mous reviewers for their helpful comments.
References
[1] Asmussen, S., Fuckerieder, P., Jobmann, M., Schwefel, H.-
P.: Large Deviations and Fast Simulation in the Presence of
Boundaries. Stochastic Processes and Applications, 102, pp.
1–23, 2002.
[2] Borst, S.C. Boxma, O.J., and Nunez-Queija, R.: Heavy Tails:
The Effect of the Service Discipline. Proceedings of Perfor-
mance Tools 2002, pp. 1–30, London, 2002.
[3] Crovella, M. and Bestavros, A.: Self-Similarity in World Wide
Web Trafﬁc: Evidence and Possible Causes. Proceedings of
the ACM Sigmetrics, pp.160–169, Philadelphia, PA, 1996.
[4] Fiorini, P., Sheahan, R., Lipsky, L., and Asmussen, S.:
On the Completion Time Distribution for Tasks that Must
Restart from the Beginning if a Failure Occurs. Proceedings
of SPECTS 2006, Calgary, Canada.
[5] Gaver, D. P., Jacobs, P. A., and Latouche, G.: Finite Birth-
and-Death Models in Randomly Changing Environments. Ad-
vances in Applied Probability, 16, pp. 715–731, 1984.
[6] Greiner, M., Jobmann, M., and Lipsky, L.: The Importance of
Power-tail Distributions for Telecommunication Trafﬁc Mod-
els. Operations Research, 47, No. 2, pp 313-326, March 1999.
[7] Krieger, U., and Naumov, V.: Analysis of a Delay-Loss System
with a Superimposed Markovian Arrival Process and State-
Dependent Service Times, Proceedings of MMB converence,
University Trier, September 1999.
[8] Kulkarni, V.G., Nicola, V.F., and Trivedi, K.S.: The Comple-
tion Time of a Job on Multimode Systems. Advances in Ap-
plied Probability, 19, No. 4, pp. 932–954, 1987.
[9] Latouche, G., and Ramaswami, V.:
INTRODUCTION TO
MATRIX ANALYTIC METHODS IN STOCHASTIC MODEL-
ING. ASA-SIAM Series on Statistics and Applied Probability,
5, 1999.
[10] Lipsky, L.: QUEUEING THEORY: A Linear Algebraic Ap-
proach. MacMillan Publishing Company, New York, 1992.
[11] Meier-Hellstern, K. and Fischer, W.: MMPP Cookbook. Per-
formance Evaluation 18, pp. 149–171, 1992.
[12] Mitrani, I.: Queues with Breakdowns. Performability Mod-
elling: Techniques and Tools, Haverkort, B.R., et al. (eds.).
Wiley, 2001.
[13] Palmer, J., and Mitrani, I.: Empirical and Analytical Evalu-
ation of Systems with Multiple Unreliable Servers. Technical
Report CS-TR-936, University of New Castle, 2005.
[14] van Moorsel, A., and Wolter, K., Analysis and Algorithms for
Restart. Proceedings of the First International Conference on
the Quantitative Evaluation of Systems (QEST), pp. 195–204,
2004.
[15] Neuts, M.: MATRIX-GEOMETRIC SOLUTIONS IN
STOCHASTIC MODELS. John Hopkins University Press,
London, 1981.
[16] Ost, A.,
and Haverkort, B., Evaluating Computer-
Communication Systems using Inﬁnite State Petri Nets. Pro-
ceedings of 3rd International Conference on Matrix Analytic
Methods, pp. 295–314, 2000.
[17] Schwefel, H.-P. and Lipsky, L.: Performance Results For An-
alytic Models of Trafﬁc In Telecommunication Systems, Based
on Multiple ON-OFF Sources with Self-Similar Behavior. In
P. Key and D. Smith (eds.), ‘Teletrafﬁc Engineering in a Com-
petitive World, Vol 3A’, pp. 55–66. Elsevier, 1999.
[18] Schwefel, H.P.: Performance Analysis of Intermediate Sys-
tems Serving Aggregated ON/OFF Trafﬁc with Long-Range
Dependent Properties. PhD Dissertation, Technische Univer-
sit¨at M¨unchen, 2000.
[19] Schwefel, H.-P. and Lipsky, L.: Impact of Aggregated, Self-
Similar ON/OFF Trafﬁc on Delay in Stationary Queueing
Models (extended version). Performance Evaluation, No. 41,
pp. 203–221, 2001.
[20] Schwefel, H.-P.: Behavior of TCP-like Elastic Trafﬁc at a
Buffered Bottleneck Router. Proceedings of IEEE Infocom,
2001.
[21] Schwefel, H.-P., Antonios, I., and Lipsky, L.: Performance-
Relevant Network Trafﬁc Correlation, submitted to ASMTA
2007, Prague, Czech Republic.
[22] Willinger, W., Taqqu, M., Sherman, R., and Wilson, D.: Self-
Similarity Through High-Variability: Statistical Analysis of
Ethernet LAN Trafﬁc at the Source Level (Extended Version).
Proceedings of the ACM Sigcomm, 1995.
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007