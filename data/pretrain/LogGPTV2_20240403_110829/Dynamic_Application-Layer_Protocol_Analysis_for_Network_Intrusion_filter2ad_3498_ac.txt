To enable dynamic analysis, including analysis based
on application-layer protocol identiﬁcation, the analyzer
tree changes over time. Initially, the analyzer tree of a
new connection only contains those analyzers deﬁnitely
needed. For example, if a ﬂow’s ﬁrst packet uses TCP for
transport, the tree will consist of an IP analyzer followed
by a TCP analyzer.
We delegate application-layer protocol identiﬁcation
to a protocol identiﬁcation analyzer (PIA ), which works
by applying a set of protocol detection heuristics to the
data it receives. We insert this analyzer into the tree
as a leaf-node after the TCP or UDP analyzer (see Fig-
ure 1(b)). Once the PIA detects a match for a protocol, it
instantiates a child analyzer to which it then forwards the
data it receives (see Figure 1(c)). However, the PIA also
continues applying its heuristics, and if it ﬁnds another
match it instantiates additional, or alternative, analyzers.
tree can be dynamically adjusted
throughout the entire lifetime of a connection by insert-
ing or removing analyzers. Each analyzer has the ability
to insert or remove other analyzers on its input and/or
output channel. Accordingly, the tree changes over time.
Initially the PIA inserts analyzers as it ﬁnds matching
protocols. Subsequently one of the analyzers may de-
cide that it requires support provided by a missing an-
alyzer and instantiates it; for instance, an IRC analyzer
that learns that the connection has a compressed payload
can insert a decompression analyzer as its predecessor.
The analyzer
If an analyzer provides data via its output channel, se-
lecting successors becomes more complicated, as not all
analyzers (including the TCP analyzer) have the capabil-
ity to determine the protocol to which their output data
conforms. In this case the analyzer can choose to instan-
tiate another PIA and delegate to it the task of further
inspecting the data. Otherwise it can simply instantiate
the appropriate analyzer; see Figure 1(d) for the example
of a connection using HTTP over SSL.
Finally, if an analyzer determines that it cannot cope
with the data it receives over its input channel (e.g., be-
cause the data does not conform to its protocol), it re-
moves its subtree from the tree.
This analyzer-tree design poses a number of technical
challenges, ranging from the semantics of “input chan-
nels”, to speciﬁcs of protocol analyzers, to performance
issues. We now address each in turn.
First, the semantics of “input channels” differ across
the network stack layers: some analyzers examine pack-
ets (e.g., IP, TCP, and protocols using UDP for trans-
port), while others require byte-streams (e.g., protocols
using TCP for transport). As the PIA can be inserted
into arbitrary locations in the tree, it must cope with both
types. To do so, we provide two separate input channels
for each analyzer, one for packet input and one for stream
input. Each analyzer implements the channel(s) suitable
for its semantics. For example, the TCP analyzer accepts
packet input and reassembles it into a payload stream,
which serves as input to subsequent stream-based ana-
lyzers. An RPC analyzer accepts both packet and stream
input, since RPC trafﬁc can arrive over both UDP packets
and TCP byte streams.
Another problem is the difﬁculty—or impossibility—
of starting a protocol analyzer in the middle of a con-
nection. For example, an HTTP analyzer cannot deter-
mine the correct HTTP state for such a partial connec-
tion. However, most non-port-based protocol detection
schemes can rarely identify the appropriate analyzer(s)
upon inspecting just the ﬁrst packet of a connection.
Therefore it is important that the PIA buffers the begin-
ning of each input stream, up to a conﬁgurable thresh-
If the PIA
old (default 4KB in our implementation).
decides to insert a child analyzer, it ﬁrst forwards the
data in the buffer to it before forwarding new data. This
gives the child analyzer a chance to receive the total pay-
load if detection occurred within the time provided by
the buffer. If instantiation occurs only after the buffer
has overﬂowed, the PIA only instantiates analyzers ca-
pable of resynchronizing to the data stream, i.e., those
with support for partial connections.
Finally,
for efﬁciency the PIA requires very
lightweight execution, as we instantiate at least one for
every ﬂow/connection. To avoid unnecessary resource
consumption, our design factors out the user conﬁgura-
USENIX Association
Security ’06: 15th USENIX Security Symposium
263
tion, tree manipulation interface, and functions requir-
ing permanent state (especially state independent of a
connection’s lifetime) into a single central management
component which also instantiates the initial analyzer
trees.
In summary, the approach of generalizing the process-
ing path to an analyzer tree provides numerous new pos-
sibilities while addressing the requirements. We can:
(i) readily plug in new protocol detection schemes via the
PIA; (ii) dynamically enable and disable analyzers at any
time (protocol semantics permitting); (iii) enable the user
to customize and control the processing via an interface
to the central manager; (iv) keep minimal the overhead
of passing data along the tree branches; (v) support pure
port-based analysis using a static analyzer tree installed
at connection initialization; and (vi) support modularity
by incorporating self-contained analyzers using a stan-
dardized API, which allows any protocol analyzer to also
serve as a protocol veriﬁer.
4.2 Implementation
We implemented our design within the open-source Bro
NIDS, leveraging both its already existing set of proto-
col decoders and its signature-matching engine. Like
other systems, Bro performs comprehensive protocol-
level analysis using a static data path, relying on port
numbers to identify application-layer protocols. How-
ever, its modular design encourages application-layer de-
coders to be mainly self-contained, making it feasible to
introduce a dynamic analyzer structure as discussed in
§4.1.
We implemented the PIA, the analyzer trees, and the
central manager, terming this modiﬁcation of Bro as
PIA-Bro; for details see [26]. We use signatures as our
primary protocol-detection heuristic (though see below),
equipping the PIA with an interface to Bro’s signature-
matching engine such that analyzers can add signatures
corresponding to their particular protocols. For efﬁ-
ciency, we restricted the signature matching to the data
buffered by the PIAs; previous work[36, 28] indicates
that for protocol detection it sufﬁces to examine at most
a few KB at the beginning of a connection. By skipping
the tails, we can avoid performing pattern matching on
the bulk of the total volume, exploiting the heavy-tailed
nature of network trafﬁc [32].
In addition to matching signatures, our implementa-
tion can incorporate other schemes for determining the
right analyzers to activate. First, the PIA can still ac-
tivate analyzers based on a user-conﬁgured list of well-
known ports.3
In addition, each protocol analyzer can
3This differs from the traditional Bro, where the set of well-known
ports is hard-coded.
register a speciﬁc detection function. The PIA then calls
this function for any new data chunk, allowing the use
of arbitrary heuristics to recognize the protocol. Finally,
leveraging the fact that the central manager can store
state, we also implemented a prediction table for storing
anticipated future connections along with a correspond-
ing analyzer. When the system eventually encounters
one of these connections, it inserts the designated ana-
lyzer into the tree. (See §5.2 below for using this mecha-
nism to inspect FTP data-transfer connections.) Together
these mechanisms provide the necessary ﬂexibility for
the connections requiring dynamic detection, as well as
good performance for the bulk of statically predictable
connections.
As Bro is a large and internally quite complex system,
we incrementally migrate its protocol analyzers to use
the new framework. Our design supports this by allowing
old-style and new-style data paths to coexist: for those
applications we have adapted, we gain the full power of
the new architecture, while the other applications remain
usable in the traditional (static ports) way.
For our initial transition of the analyzers we have con-
centrated on protocols running on top of TCP. The Bro
system already encapsulates its protocol decoders into
separate units; we redesigned the API of these units to
accommodate the dynamic analyzer structure. We have
converted four of the system’s existing application-layer
protocol decoders to the new API: FTP, HTTP, IRC, and
SMTP.4 The focus on TCP causes the initial analyzer
tree to always contain the IP and TCP analyzers. There-
fore we can leverage the existing static code and did not
yet have to adapt the IP and TCP logic to the new ana-
lyzer API. We have, however, already moved the TCP
stream reassembly code into a separate “Stream” ana-
lyzer. When we integrate UDP into the framework, we
will also adapt the IP and TCP components.
The Stream analyzer is one instance of a support ana-
lyzer which does not directly correspond to any speciﬁc
protocol. Other support analyzers provide functionality
such as splitting the payload-stream of text-based proto-
cols into lines, or expanding compressed data.5 We have
not yet experimented with pipelining protocol analyzers
such as those required for tunnel decapsulation, but in-
tend to adapt Bro’s SSL decoder next to enable us to ana-
lyze HTTPS and IMAPS in a pipelined fashion when we
provide the system with the corresponding secret key.
4Note that it does not require much effort to convert an existing
application-layer analyzer to the new API. For example, the SMTP an-
alyzer took us about an hour to adapt.
5Internally, these support analyzers are implemented via a slightly
different interface, see [26] for details.
264
Security ’06: 15th USENIX Security Symposium
USENIX Association
4.3 Trade-Offs
Using the PIA architecture raises some important trade-
offs to consider since protocol recognition/veriﬁcation
is now a multi-step process. First, the user must de-
cide what kinds of signatures to apply to detect poten-
tial application-layer protocols. Second, if a signature
matches it activates the appropriate protocol-speciﬁc an-
alyzer, at which point the system must cope with possi-
ble false positives; when and how does the analyzer fail
in this case? Finally, we must consider how an attacker
can exploit these trade-offs to subvert the analysis.
The ﬁrst trade-off involves choosing appropriate sig-
natures for the protocol detection. On the one hand, the
multi-step approach allows us to loosen the signatures
that initially detect protocol candidates. Signatures are
typically prone to false alerts, and thus when used to gen-
erate alerts need to be speciﬁed as tight as possible—
which in turn very often leads to false negatives, i.e.,
undetected protocols in this context. However, by rely-
ing on analyzers verifying protocol conformance after a
signature match, false positives become more affordable.
On the other hand, signatures should not be too lose: hav-
ing an analyzer inspect a connection is more expensive
than performing pure pattern matching. In addition, we
want to avoid enabling an attacker to trigger expensive
protocol processing by deliberately crafting bogus con-
nection payloads.
Towards these ends, our implementation uses bidirec-
tional signatures [38], which only match if both end-
points of a connection appear to participate in the proto-
col. If an attacker only controls one side (if they control
both, we are sunk in many different ways), they thus can-
not force activation of protocol analyzers by themselves.
In practice, we in fact go a step further: before assuming
that a connection uses a certain protocol, the correspond-
ing analyzer must also parse something meaningful for
both directions. This signiﬁcantly reduces the impact of
false positives. Figure 2 shows an example of the signa-
ture we currently use for activating the HTTP analyzer.
(We note that the point here is not about signature qual-
ity; for our system, signatures are just one part of the
NIDS’s conﬁguration to be adapted to the user’s require-
ments.)
Another trade-off to address is when to decide that a
connection uses a certain protocol. This is important
if the use of a certain application violates a site’s secu-
rity policy and should cause the NIDS to raise an alert.
A signature-match triggers the activation of an analyzer
that analyzes and veriﬁes the protocol usage. Therefore,
before alerting, the system waits until it sees that the an-
alyzer is capable of handling the connection’s payload.
In principle, it can only conﬁrm this with certainty once
the connection completes. In practice, doing so will de-
lay alerts signiﬁcantly for long-term connections. There-
fore our implementation assumes that if the analyzer can
parse the connection’s beginning, the rest of the payload
will also adhere to the same protocol. That is, our system
reports use of a protocol if the corresponding analyzer is
(still) active after the exchange of a given volume of pay-
load, or a given amount of time passes (both thresholds
are conﬁgurable).
Another trade-off stems from the question of protocol
veriﬁcation: at what point should an analyzer indicate
that it cannot cope with the payload of a given connec-
tion? Two extreme answers: (i) reject immediately when
something occurs not in accordance with the protocol’s
deﬁnition, or (ii) continue parsing come whatever may,
in the hope that eventually the analyzer can resynchro-
nize with the data stream. Neither extreme works well:
real-world network trafﬁc often stretches the bounds of
a protocol’s speciﬁcation, but trying to parse the entire
stream contradicts the goal of verifying the protocol. The
right balance between these extremes needs to be decided
on a per-protocol basis. So far, we have chosen to reject
connections if they violate basic protocol properties. For
example, the FTP analyzer complains if it does not ﬁnd
a numeric reply-code in the server’s response. However,
we anticipate needing to reﬁne this decision process for
instances where the distinction between clear noncom-
pliance versus perhaps-just-weird behavior is less crisp.
Finally, an attacker might exploit the speciﬁcs of a
particular analyzer, avoiding detection by crafting trafﬁc
in a manner that the analyzer believes reﬂects a proto-
col violation, while the connection’s other endpoint still
accepts or benignly ignores the data. This problem ap-
pears fundamental to protocol detection, and indeed is
an instance of the more general problem of evasion-by-
ambiguity [33, 18], and, for signatures, the vulnerability
of NIDS signatures to attack variants. To mitigate this
problem, we inserted indirection into the decision pro-
cess: in our implementation, an analyzer never disables
itself, even if it fails to parse its inputs. Instead, upon
severe protocol violations it generates Bro events that a
user-level policy script then acts upon. The default script
is fully customizable, capable of extension to implement-
ing arbitrary complex policies such as disabling the an-
alyzer only after repeated violations. This approach ﬁts
with the Kerkhoff-like principle used by the Bro system:
the code is open, yet sites code their speciﬁc policies in
user-level scripts which they strive to keep secret.
5 Applications
We now illustrate the increased detection capabilities that
stem from realizing the PIA architecture within Bro, us-
ing three powerful example applications: (i) reliable de-
tection of applications running on non-standard ports,
USENIX Association
Security ’06: 15th USENIX Security Symposium
265
signature http_server {
ip-proto == tcp
payload /ˆHTTP\/[0-9]/
tcp-state responder
requires-reverse-signature http_client # Require client-side signature as well.
enable "http"
# Server-side signature
# Examine TCP packets.
# Look for server response.
# Match responder-side of connection.
# Enable analyzer upon match.
}
signature http_client {
ip-proto == tcp
payload /ˆ[[:space:]]*GET[[:space:]]*/ # Look for requests [simplified]
tcp-state originator
# Match originator-side of connection.
# Client-side signature
# Examine TCP packets.
}
Figure 2: Bidirectional signature for HTTP.
(ii) payload inspection of FTP data transfers, and (iii) de-
tection of IRC-based bot clients and servers. All three
schemes run in day-to-day operations at UCB, MWN,
and LBNL (see §2), where they have already identiﬁed
a large number of compromised hosts which the sites’
traditional security monitoring could not directly detect.
5.1 Detecting Uses of Non-standard Ports
As pointed out earlier, a PIA architecture gives us the
powerful ability to verify protocol usage and extract
higher-level semantics. To take advantage of this capa-
bility, we extended the reporting of PIA-Bro’s analyz-
ers. Once the NIDS knows which protocol a connection
uses, it can leverage this to extract more semantic con-
text. For example, HTTP is used by a wide range of other
protocols as a transport protocol. Therefore, an alert
such as “connection uses HTTP on a non-standard port
21012”, while useful, does not tell the whole story; we
would like to know what that connection then does. We
extended PIA-Bro’s HTTP analysis to distinguish the
various protocols using HTTP for transport by analyzing
the HTTP dialog. Kazaa, for example, includes custom
headers lines that start with X-Kazaa. Thus, when this
string is present, the NIDS generates a message such as
“connection uses Kazaa on port 21021”. We added pat-
terns for detecting Kazaa, Gnutella, BitTorrent, Squid,
and SOAP applications running over HTTP. In addition,
the HTTP analyzer extracts the “Server” header from the
HTTP responses, giving an additional indication of the
underlying application.
We currently run the dynamic protocol detection for
FTP, HTTP, IRC, and SMTP on the border routers of all
three environments, though here we primarily report on
experiences at UCB and MWN. As we have particular in-
terest in the use of non-standard ports, and to reduce the
load on PIA-Bro, we exclude trafﬁc on the analyzers’
well-known ports6 from our analysis. (This setup pre-
vents PIA-Bro from ﬁnding some forms of port abuse,
6For “well-known” we consider those for which a traditional
Bro triggers application-layer analysis. These are port 21 for FTP,
ports 6667/6668 for IRC, 80/81/631/1080/3128/8000/8080/8888 for
HTTP (631 is IPP), and 25 for SMTP. We furthermore added
6665/6666/6668/6669/7000 for IRC, and 587 for SMTP as we encoun-
e.g., an IRC connection running on the HTTP port. We
postpone this issue to §6.)
At both UCB and MWN, our system quickly identi-
ﬁed many servers7 which had gone unnoticed. At UCB,
it found within a day 6 internal and 17 remote FTP
servers, 568/54830 HTTP servers (!), 2/33 IRC servers,
and 8/8 SMTP servers running on non-standard ports.
At MWN, during a similar period, we found 3/40 FTP,
108/18844 HTTP, 3/58 IRC, and 3/5 SMTP servers.
For FTP, IRC, and SMTP we manually checked
whether the internal hosts were indeed running the de-
tected protocol; for HTTP, we veriﬁed a subset. Among
the checked servers we found only one false positive:
PIA-Bro incorrectly ﬂagged one SMTP server due to
our choice regarding how to cope with false positives: as
discussed in §4.3, we choose to not wait until the end of
the connection before alerting. In this case, the SMTP
analyzer correctly reported a protocol violation for the
connection, but it did so only after our chosen maximal
interval of 30 seconds had already passed; the server’s
response took quite some time. In terms of connections,