7 LIMITATIONS
In our approach, all loads and stores to variables annotated as sen-
sitive are protected through encryption. Hence, without knowing
the secret key, attackers cannot write any desired values to sensi-
tive variables in their correct encrypted form. However, encryption
alone does not provide complete protection against attackers who
have the capability of performing arbitrary memory writes.
For instance, consider a sensitive variable is_admin related to
some authentication operation. Such variables are often checked
as part of the program logic by comparing against “not-zero” (e.g.,
is_admin != 0). In such scenarios, even if the variable is encrypted,
attackers can overwrite it with an arbitrary value, and achieve a
very high probability of the decrypted value being non-zero. A
possible way to address this limitation is to use a message authenti-
cation code (MAC) for authenticating writes to sensitive variables,
in order to guarantee that only authorized instructions can mod-
ify sensitive values. However, it is difficult to identify authorized
instructions, especially in case of complex data-only attacks. We
leave the exploration of more effective techniques for ensuring data
integrity as part of future work.
The dearth of efficient pointer analysis techniques directly im-
pacts the precision of our approach, and its applicability to larger
and more complex applications. Ideally, one would want to analyze
and transform all libraries that are used by the target application.
However, the analysis time depends on the size of the input source
code. In our current prototype, to keep the analysis time manage-
able (i.e., in the order of minutes instead of multiple hours), we
excluded Libc from our static analysis passes in order to limit the
size of the input source code. Thus, when sensitive arguments are
passed to a Libc function, we must first decrypt them.
Nevertheless, to minimize the exposure of decrypted sensitive
data to external functions, we turned to custom implementations
of commonly used Libc functions, such as memcpy, memcmp, strcpy,
and strlen. An immediate direction for future work is to explore
other pointer analysis techniques besides Andersen’s algorithm
(which has a complexity of O(n3)). One possibility is the more
efficient unification-based Steensgaard’s algorithm [79]. Unlike An-
dersen’s algorithm, however, there is no available implementation
(to the best of our knowledge) of Steensgaard’s algorithm that could
be easily incorporated into the SVF suite [80] or LLVM itself.1
It is prudent to note that precise and scalable pointer analysis is
an open problem, and other state-of-the-art memory isolation [45]
and control flow integrity [83] mechanisms have made similar
compromises by opting for overly conservative pointer analysis.
We use the best available techniques in a conservative way to avoid
false positive issues. We demonstrate that despite incurring a much
higher performance penalty than what would be possible with more
accurate pointer analysis, our approach still incurs a reasonable
performance overhead.
Lastly, because we do not implement runtime key rotation, one
can envision a scenario where an adversary can use a known plain-
text attack against the sensitive data. However, the data we are
trying to protect (i.e., private keys, session cookies) has sufficient
entropy to ensure that finding exact matches with 128 bits of known
plaintext is hard. Therefore, it is safe to use deterministic encryp-
tion under the assumed threat model and goals. Moreover, for this
type of attack to be successful, the attacker would require access to
an oracle, which falls outside of our threat model.
8 RELATED WORK
8.1 Memory Safety
Enforcing full memory safety to unsafe languages can, in the-
ory, block most memory corruption exploits. In practice, however,
the low-level nature of the C and C++ languages, which allow
unchecked array indexing, conflation of pointers and arrays, pointer
arithmetic, and type casting, makes retrofitting memory safety pro-
tections into existing programs a daunting task [63]. The overall
strategy for enforcing whole-program memory safety is to main-
tain bounds information either for each pointer [43, 64–66] or ob-
ject [13, 50, 75], and to check every pointer dereference against
the bounds associated with the target pointer or object. By trading
extra memory space for performance, baggy bounds checking [13]
is currently one of the most efficient object-based bounds checking
approaches, although its performance overhead is still prohibitively
high, at an average of 60% for the SPEC benchmarks.
That said, spatial safety in the form of bounds checking alone
still cannot prevent use-after-free and double-free vulnerabilities.
Approaches that combine both spatial and temporal safety achieve
better memory safety, but at an even higher cost. As a case in point,
when CETS [65] is coupled with SoftBound [64] to achieve full
memory safety, the composition results in an average overhead of
116% for the SPEC benchmarks [65].
Other approaches, such as Diehard [23], Dieharder [67], Cling [11],
Archipelago [57], FreeSentry [89], WIT [12], CPI [47], and the works
of Dhurjati et al. [33] and Byoungyoung et al. [51], opt for providing
weaker guarantees to achieve better performance and compatibility,
and thus do not offer complete protection. An alternative trade-off
1Although the LLVM compiler toolchain provides a CFL unification-based alias analysis
pass named CFL-Steens [5], because the pass performs alias analysis, it must be invoked
separately for each pair of memory operands. It then performs a graph search on each
query to resolve whether the two operands alias, instead of computing the full points-
to graph at once, like SVF. Due to these fundamental differences in the functionality
of SVF and CFL-Steens, we leave porting CFL-Steens to SVF as future work.
is made by DataShield [27], which opts to provide full memory
safety on only a subset of sensitive data annotated by developers.
Although promising, even for an I/O-heavy application such as
a TLS server, DataShield still incurs a considerable runtime over-
head of 35.7%. Selective data encryption provides a complementary
approach, but at a much lower cost.
8.2 Transformation of In-Memory Data
An alternative approach to memory safety is to apply a transfor-
mation to the data in the main memory. As long as the attacker
can not reverse this transformation, the original data can not be
recovered or modified, thus preserving confidentiality and integrity.
Data space randomization [20, 24] applies this principle to prevent
buffer overflow attacks, using a XOR operation to randomize the
in-memory representation of objects. Our work is inspired by this
approach to selectively transform sensitive data in memory, but
using stronger AES encryption instead.
Memory encryption using AES as a protection against cold boot
attacks was proposed by Papadopoulos et al. [68]. While their ap-
proach uses a similar decryption cache scheme as ours, we integrate
a more robust pointer and value flow analysis to ensure that ac-
cesses to sensitive data is always transformed correctly.
8.3 Data Flow Integrity
Similar to control flow integrity techniques, that protect against
control flow attacks, data flow integrity mechanisms can protect
against data-only attacks. Data Flow Integrity [28] precomputes a
valid data flow graph and, at runtime, validates all data flows against
it. However, this approach has a significant overhead of 104% for the
CPU-bound SPEC benchmarks. Recently, DFI-assisting hardware
extensions [78] were proposed to lower the runtime overhead.
8.4 Hardware Based Mechanisms
Hardware-based defenses such as TRESOR [62], PRIME [36], and
PixelVault [85] protect sensitive computation from an adversary
with physical access to the device. TRESOR and PRIME provide a
memory-less, CPU bound infrastructure for sensitive computation,
such as RSA encryption. Ginseng [90] protects against an untrusted
operating system, by storing sensitive stack variables, strictly in reg-
isters, and relies on a secure implementation of secure stack, and CFI,
in ARM TrustZone’s Trusted Execution Environment (TEE) [16].
Likewise, Intel’s Software Guard Extensions (SGX) [42] provides
a set of CPU instructions that can be used by user mode applica-
tions to create private regions, called “enclaves,” for sensitive code
and data. Various approaches have leveraged this (e.g., [17], [25],
[76], [82], [53]), but each involves major restructuring of the source
code, including changes to the compiler, OS support, and runtime
libraries. The same is true for TRESOR, PRIME, and PixelVault.
MemSentry [45] is a memory isolation framework that allows
users to create isolated memory regions by leveraging hardware
features. SP3 [88] and SeCage [55] use hypervisor support to isolate
sensitive data on a per-page basis. Compared to these systems,
we support a finer-grained separation between sensitive and non-
sensitive data, at the granularity of individual variables.
9 CONCLUSION
We presented a compiler-level defense that provides strong pro-
tection against the emerging threat of data leakage attacks. Our
approach allows developers to conveniently annotate program vari-
ables or data inputs as sensitive, and ensures that all sensitive data
is always kept encrypted when stored in memory.
Unlike existing memory safety or isolation approaches, our solu-
tion is geared toward protecting only a subset of a process’ data—a
design decision that allows for a radically different memory ac-
cess instrumentation strategy. Instead of instrumenting all memory
accesses in the most lightweight manner possible, our solution in-
struments only a fraction of all memory accesses, and thus enables
the use of more heavyweight encryption using AES. Our prototype
implementation aptly demonstrates the benefits of the proposed
approach, and also highlights important challenges in the area of
whole-program fine-grained pointer analysis that, once resolved,
will allow faster analysis of more complex applications, and will
enable protection against the full spectrum of data-only attacks, by
offering data integrity in addition to data confidentiality.
ACKNOWLEDGMENTS
We would like to thank R. Sekar and the anonymous reviewers for
their valuable feedback. This work was supported by the Office of
Naval Research (ONR) through award N00014-17-1-2891, the Na-
tional Science Foundation (NSF) through awards CNS-1749895 and
CNS-1617902, and the Defense Advanced Research Projects Agency
(DARPA) through award D18AP00045. Any opinions, findings, and
conclusions or recommendations expressed herein are those of the
authors and do not necessarily reflect the views of the ONR, NSF,
or DARPA.
REFERENCES
[1] 2003. Grsecurity. https://grsecurity.net/.
[2] 2006. SPEC CPU2006 Benchmark. http://www.spec.org/cpu2006.
[3] 2014. The Heartbleed Bug. http://heartbleed.com/.
[4] 2015. Control Flow Guard. https://msdn.microsoft.com/en-us/library/windows/
[5] 2016. CFL-based Unification-based Alias Analysis. https://github.com/llvm-
desktop/mt637065(v=vs.85).aspx.
mirror/llvm/blob/master/lib/Analysis/CFLSteensAliasAnalysis.cpp.
[6] 2016. Intel Streaming SIMD Extensions Technology. https://www.intel.com/
content/www/us/en/support/articles/000005779/processors.html.
[7] 2018. SSL Library mbed TLS. https://tls.mbed.org/.
[8] 2018. The Sodium crypto library (libsodium). https://www.gitbook.com/book/
jedisct1/libsodium/details.
[9] 2019.
Overview:
Intrinsics for Intel® Advanced Vector Extensions 2.
https://software.intel.com/en-us/cpp-compiler-developer-guide-and-
reference-overview-intrinsics-for-intel-advanced-vector-extensions-2-
intel-avx2-instructions.
[10] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. 2005. Control-flow
integrity. In Proceedings of the 12th ACM conference on Computer and Communi-
cations Security (CCS). 340–353.
[11] Periklis Akritidis. 2010. Cling: A Memory Allocator to Mitigate Dangling Pointers.
In Proceedings of the 19th USENIX Security Symposium.
[12] Periklis Akritidis, Cristian Cadar, Costin Raiciu, Manuel Costa, and Miguel Castro.
2008. Preventing Memory Error Exploits with WIT. In Proceedings of the IEEE
Symposium on Security & Privacy (S&P). 263–277.
[13] Periklis Akritidis, Manuel Costa, Miguel Castro, and Steven Hand. 2009. Baggy
Bounds Checking: An Efficient and Backwards-compatible Defense Against Out-
of-bounds Errors. In Proceedings of the 18th USENIX Security Symposium. 51–66.
[14] Lars Ole Andersen. 1994. Program analysis and specialization for the C program-
ming language. Ph.D. Dissertation. University of Cophenhagen.
[15] Brad Antoniewicz. 2013. Analysis of a Malware ROP Chain.
http://
blog.opensecurityresearch.com/2013/10/analysis-of-malware-rop-chain.html.
[16] ARM. 2010. ARM TrustZone. https://developer.arm.com/ip-products/security-
ip/trustzone.
CanSecWest.
[17] Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andre Martin,
Christian Priebe, Joshua Lind, Divya Muthukumaran, Dan O’Keeffe, Mark Still-
well, et al. 2016. SCONE: Secure Linux Containers with Intel SGX.. In Proceedings
of the 12th USENIX Conference on Operating Systems Design and Implementation
(OSDI). 689–703.
[18] George Balatsouras and Yannis Smaragdakis. 2016. Structure-sensitive points-
to analysis for C and C++. In Proceedings of the International Static Analysis
Symposium (SAS). 84–104.
[19] Andrew Baumann. 2017. Hardware is the new Software. In Proceedings of the
16th Workshop on Hot Topics in Operating Systems (HotOS).
[20] Brian Belleville, Joseph Michael Nash, Yeoul Na, Stijn Volckaert, Per Larsen,
Michael Franz, Hyungon Moon, Jangseop Shin, Dongil Hwang, Seonhwa Jung,
and Yunheung Paek. 2018. Hardware Assisted Randomization of Data. In Pro-
ceedings of the International Symposium on Research in Attacks, Intrusions and
Defenses (RAID).
[21] Eli Bendersky. 2015. Pure-python library for parsing ELF and DWARF. https:
//github.com/eliben/pyelftools.
[22] James Bennett, Yichong Lin, and Thoufique Haq. 2013. The Number of the Beast.
http://blog.fireeye.com/research/2013/02/the-number-of-the-beast.html.
[23] Emery D. Berger and Benjamin G. Zorn. 2006. DieHard: Probabilistic Memory
Safety for Unsafe Languages. In Proceedings of the 27th ACM SIGPLAN Conference
on Programming Language Design and Implementation (PLDI). 158–168.
[24] Sandeep Bhatkar and R. Sekar. 2008. Data Space Randomization. In Proceedings
of the 5th International Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment (DIMVA). 1–22.
[25] Stefan Brenner, Colin Wulf, David Goltzsche, Nico Weichbrodt, Matthias Lorenz,
Christof Fetzer, Peter Pietzuch, and Rüdiger Kapitza. 2016. SecureKeeper: con-
fidential ZooKeeper using intel SGX. In Proceedings of the 17th International
Middleware Conference. 14.
[26] David Brumley and Dawn Song. 2004. Privtrans: Automatically Partitioning
Programs for Privilege Separation. In Proceedings of the 13th USENIX Security
Symposium.
[27] Scott A. Carr and Mathias Payer. 2017. DataShield: Configurable Data Confiden-
tiality and Integrity. In Proceedings of the ACM Asia Conference on Computer and
Communications Security (AsiaCCS). 193–204.
[28] Miguel Castro, Manuel Costa, and Tim Harris. 2006. Securing Software by
Enforcing Data-flow Integrity. In Proceedings of the 7th Symposium on Operating
Systems Design and Implementation (OSDI). 147–160.
[29] Shuo Chen, Jun Xu, Emre C. Sezer, Prachi Gauriar, and Ravishankar K. Iyer.
2005. Non-Control-Data Attacks Are Realistic Threats. In Proceedings of the 14th
USENIX Security Symposium.
[30] Joan Daemen and Vincent Rijmen. 2013. The design of Rijndael: AES-the advanced
encryption standard. Springer Science & Business Media.
[31] Jamie Danielson. 2017.
ProcessMitigations 1.0.7.
//www.powershellgallery.com/packages/ProcessMitigations/1.0.7.
[32] Frank Denis. 2018. Minisign: A dead simple tool to sign files and verify digital
signatures. https://github.com/jedisct1/minisign.
[33] Dinakar Dhurjati, Sumant Kowshik, Vikram Adve, and Chris Lattner. 2003. Mem-
ory Safety Without Runtime Checks or Garbage Collection. In Proceedings of the
2003 ACM SIGPLAN Conference on Language, Compiler, and Tool for Embedded