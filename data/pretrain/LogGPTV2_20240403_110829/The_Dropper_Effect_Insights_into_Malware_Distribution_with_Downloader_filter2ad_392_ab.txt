telemetry, we extract information about 0.5 million portals.
3.2 Ground Truth Data For Executables
Our ground truth consists of a large number of known-malicious
and known-benign ﬁles, recorded in VirusTotal,
the National
Software Reference Library (NSRL), and an additional data set re-
ceived from Symantec.
VirusTotal. VirusTotal1 is a service that provides a public API for
scanning ﬁles with up to 54 different anti-virus (AV) products, and
for querying hashes to retrieve their previous analysis reports. We
query VirusTotal for each downloader in our data set to obtain its
ﬁrst-seen timestamp, the number of AV products that ﬂagged the
binary as malicious, the total number of AV products that scanned
the binary, and the corresponding ﬁle signer information. We then
compute the percentage rmal of products that ﬂagged the binary
as malicious. We consider that a ﬁle is malicious if rmal ≥ 30%;
because AV vendors are typically worried about false positives, we
believe that this represents a conservative threshold. We veriﬁed
that approximately 80% of the ﬁles above this threshold are also
labeled as malicious in the Symantec ground truth described below.
National Software Reference Library. NSRL2 is a project that
collects software installers from leading software vendors with the
purpose of creating a reference data set (RDS) of benign software.
RDS is a collection of digital signatures (mainly SHA1, MD5, and
other metadata) of known, traceable software applications. NSRL
releases the RDS four times per year. We used the RDS 2.47 ver-
sion that was released in December 2014. We treat all the down-
loaders with matching hashes in NSRL as benign.
Additional Ground Truth for Files. Due to the limitations impo-
sed by the VirusTotal API, we were unable to query all the 24 mi-
llion ﬁle hashes. We therefore complement our ground truth with
an additional ground truth maintained by Symantec. This step in-
creases the coverage of our ground truth.
After combining all these sources of ground truth, we identify
87,906 benign and 67,609 malicious downloaders; the rest of the
downloaders remain unlabeled.
3.3 Downloader Graph
In this section, we introduce the notion of downloader graph
(DG) and inﬂuence graph (IG). A DG is a directed graph, deﬁned
for each host machine, where a node represents a downloaded ﬁle
and an edge from downloader da to db indicates that da has down-
loaded db on the corresponding host machine. On the other hand,
an IG is deﬁned for each individual downloader (called root) on a
given host machine, and is a subgraph of the DG on that host. In-
ﬂuence graph captures the impact of its download root by encoding
the downloads (both direct and indirect) caused by the root.
Figure 1 illustrates an example of a DG and two IGs (in loo-
ped dotted lines) in it. In this example, the nodes are annotated
with their ﬁle names, and edges are annotated with the domains of
1
2
https://www.virustotal.com/
http://www.nsrl.nist.gov/
1120the download URLs. We discuss additional properties of the no-
des and edges of the downloader graph in Section 3.4. Note that
the downloader graph per machine could be disconnected, unlike a
connected one in this example. Another observation is that the in-
ﬂuence graph of a downloader could be contained in the inﬂuence
graph of another downloader; in particular, the inﬂuence graph of a
malicious dropper can be a part of the inﬂuence graph of a benign
downloader.
Now we provide the formal deﬁnition of the DG abstraction.
Considering V to be the set of all executables in our data set, and
M to be the set of all host machines, downloader graph Gi for ma-
chine Mi is deﬁned as Gi = (Vi, Ei, α, β), where:
• Vi ⊆ V denotes the set of executable ﬁles downloaded on ma-
chine Mi. Note that the same executable could be downloaded
across multiple machines.
• Ei ⊆ Vi X Vi denotes a set of directed edges that correspond to
the download relations between executables.
• α denotes a set of properties deﬁned on the nodes of the
downloader graphs. Node properties could be: (a) machine-
dependent (unique across all machines), and (b) machine-
independent (unique to a host machine) properties.
• β denotes a set of properties deﬁned on the edges of the down-
loader graphs.
Now, we deﬁne inﬂuence graph. The inﬂuence graph Ig(dMi )
of a download root d in machine Mi is deﬁned as the subgraph of
Gi which is reachable by traversing Gi starting at d. Note that, the
inﬂuence graphs are deﬁned for every downloader (i.e., an execu-
table that has downloaded at least one executable) in a DG, but not
for the other executables in a DG.
3.4 Constructing DGs and Labeling IGs
the
this
IPS telemetry data
In this section, we start by describing how we construct the DGs
for each machine using the data described in Section 3.1. Then
for each possible root of the DGs, we extract the IGs and label as
benign, malicious, or unlabeled using the ground truth data for the
individual downloaders.
Constructing Downloader Graphs. We start by extrac-
from the URL
ting the names of
the downloaded ﬁles
column of
(example
entry:
set
http://somedomain.com/file_name.exe);
corres-
ponds to the name of the ﬁle created on a disk. 95% of the URLs
from which users downloaded PE ﬁles include the name of the
ﬁle downloaded. We then search for these ﬁles in the binary
reputation data set, which reports ﬁle creation events and includes
the corresponding SHA2 hashes.
If a matching ﬁlename and
source domain appear in the binary reputation data set within ±2
days from the IPS event timestamp, we create a graph node for
the ﬁle, add the ﬁle hash as a node attribute, and add an incoming
edge from the portal reported in the IPS event. In consequence,
we may miss certain graph edges in some rare cases (e.g., the user
changes the ﬁlename, the malware renames itself), but the edges
we create correspond to genuine download events. We look 2 days
before or after the IPS event because server-side timestamps may
be affected by transmission delays and different submission orders
between the two data sets. We employ an approximate ﬁle name
matching algorithm by computing the edit distance between ﬁle
names and by accepting pairs with distance below 3 as matches.
This allows us to handle differences in the ﬁle name caused by
duplicate downloads (e.g., setup.exe and setup[1].exe). We
also extract the domain name from the URL and add it as an
attribute to the edge.
We also analyze the relationship between ﬁles and their parents
in the binary reputation data set.
If there exists a parent for the
downloaded ﬁle, we consider that the parent downloaded the ﬁle
and add a directed edge from the parent to the ﬁle; then we assign
the domain name extracted from the downloaded ﬁle’s source URL
as an attribute of the new edge. The step was motivated by our ob-
servation that many of the parents recorded in the binary reputation
data set are the same as the portals in the IPS telemetry.
of a downloader.
ble is downloaded on a host.
During the downloader graph construction, we add the following
properties to each node in the graph:
• Number of outgoing edges: This captures the download volume
• Number of incoming edges: This captures how often an executa-
• Time interval between a node and its out-neighbors: This captu-
res how quickly, on an average, a downloader tends to download
other executables after it was downloaded on a host.
• File score (based on digital signatures): We assign a ﬁle score in
the range 0–3 for every downloader in our data set based on their
digital signatures. Speciﬁcally, we take into account the availa-
bility of the following information: (a) signature, (b) publisher
information, and (c) reputation of the certiﬁcation authorities.
The executables without ﬁle signatures or records in VirusTotal
will be assigned with score 0. Otherwise, if the signature con-
tains information about the publisher, we assign score 1. Then,
if the certiﬁcate validation chain contains a certiﬁcate authority
among Comodo, VeriSign, Go Daddy, GlobalSign, and DigiCert,
we add 1 to the score. Finally, if the signature is valid, we also
add 1 to the score.
• Number of out-neighbors with score 0 or 1: This represents a ru-
dimentary quantiﬁcation of the malicious intent of a downloader.
We add the following properties to each edge in the graph:
download URL had a domain name or an IP address.
• URL has IP instead of domain: denotes if the corresponding
• URL is Localhost: denotes if the corresponding download URL
• URL is in Alexa top 1 million: denotes if the download URL is
was relative to a localhost address.
hosts it appears on, in the binary reputation data set.
in Alexa3 top 1 million websites.
We also extract some aggregated properties, which we will leve-
rage to derive some features of inﬂuence graphs:
• File prevalence (FP): For every ﬁle, we count the number of
• Number of unique downloaders accessing given URL (UDPL):
For every URL (domain), we count the number of unique down-
loaders that used the domain to download new executables,
aggregated across all machines.
• Number of unique downloads from a given URL (UDFL): For
every URL (domain), we count the number of unique executa-
bles downloaded from the domain, aggregated across all machi-
nes.
Figure 2 illustrates the distribution of nodes, edges, and life span
for our inﬂuence graphs. There are 3.66 nodes on average per in-
ﬂuence graph, with a minimum 2 nodes and a maximum of 66,573
nodes. Inﬂuence graphs have between 1–66572 edges, with an ave-
rage of 2.66 edges. These graphs have an average life span (diffe-
rence between the timestamps of the ﬁrst and the last node in the
graph) of 75.3 days, ranging from 0 to 2199.9 days. Because this
paper focuses on analyzing the properties of downloader graphs, in
the rest of our analysis we exclude the inﬂuence graphs with fewer
3
http://www.alexa.com/
1121Figure 2: Distributions of inﬂuence-graph properties: (a) Number of nodes, (b) Number of edges, (c) Life span.
than 3 nodes, which might not provide sufﬁcient insight for our
problem.
Labeling Inﬂuence Graphs. We label the inﬂuence graphs, using
the benign and malicious labels of downloaders, determined as des-
cribed in Section 3.2. We label only the IGs whose root downloader
is known to our ground truth. Speciﬁcally, we consider that an IG
is malicious if its root downloader is labeled as malicious. On the
other hand, we consider that an IG is benign if one of the following
three conditions is true: (1) the root is in NSRL, (2) the digital sig-
nature of the root is from a well known publisher and veriﬁed by
VirusTotal, or (3) the root is rmal = 0 and is benign in Symantec
ground truth, and the next two are also true: (1) none of the other
nodes in the IG have rmal > 0, (2) none of the inﬂuence graph no-
des is labeled as malicious in Symantec ground truth. This results
in 14,918,097 benign and 274,126 malicious inﬂuence graphs.
4.
INSIGHTS INTO INFLUENCE GRAPHS
We now present our insights into the ecosystem of benign and
malicious inﬂuence graphs. We ﬁrst investigate the ability of mali-
cious downloaders to stay under the radar of the security commu-
nity, while delivering malware. This allows us to assess the mag-
nitude of this threat and to create a data set of malicious download
graphs, unbiased by interference from anti-virus products, for fur-
ther empirical analysis. We then analyze the properties of inﬂuence
graphs that correspond to malicious and benign downloaders, and
identify properties that can be utilized in malware detection.
4.1 Unknown Droppers
The functionality of benign and malicious downloaders is simi-
lar: both retrieve software components from the Internet, someti-
mes in response to commands received from a remote server. We
therefore expect that it takes a while until the security community
recognizes that a downloader is involved in malicious activities.
For each downloader labeled as malicious in our data set, we
compute the earliest ﬁle timestamp in the binary reputation data
from WINE, which approximates the date when the sample appea-
red in the wild. We compare this timestamp with the time when
the ﬁle was ﬁrst submitted to VirusTotal, which approximates the
date when the malicious dropper became known to the security co-
mmunity. These are not perfect approximations. Antivirus com-
panies change their settings speciﬁcally for VirusTotal compared
to their commercial versions4, so we cannot conclude that the dro-
ppers it fails to label as malicious are undetectable. Similarly, be-
cause the dropper may be delivered initially to a host not covered
by WINE, the interval when the dropper remains unknown may be
under-estimated. However, given the large number of hosts where
data is collected (5 million) and the fact that several anti-virus pro-
ducts (up to 54) must agree, unanimously, that a downloader is not
known to be malicious, we believe that the structure of downloader
graphs analyzed in this section is representative of the way mali-
4
https://www.virustotal.com/en/faq/
Figure 3: Distribution of the interval between the earliest ﬁle
timestamp in WINE and the ﬁrst seen time from VirusTotal,
for all the malicious downloaders.
cious droppers operate in the wild before they become known to
the security community.
Figure 3 shows the distribution of the time interval between the
timestamp of the downloader on each host and the ﬁrst-seen times-
tamp in VirusTotal. Negative time intervals correspond to unknown
droppers. We identify 140,062 inﬂuence graphs rooted in unknown
malicious droppers. Among the 67,609 malicious downloaders,
36,801 appear at least once before VirusTotal ﬁrst seen timestamp.
In 27.1% of these cases, the dropper appears in the wild one day
before it is uploaded to VirusTotal, suggesting that many of these
malicious downloaders rouse suspicion. Nevertheless, the distribu-
tion has a long tail, with an average of 80.6 days (approximately
2.7 months) before discovery. This suggests that many downloa-
ders are able to deliver malware stealthily for several months.
These results illustrate the magnitude of the downloader threat
and the opportunities for improving malware detection. For the
empirical results presented in this section, we focus on malicious
graphs rooted in an unknown dropper, in order to minimize the
bias caused by anti-virus products that may block the growth of
the graphs.
4.2 Dynamics of Malware Delivery
Web browsers, updaters and instant messengers. To understand
how malware is delivered to end hosts, we ﬁrst analyze the pro-
grams responsible for most downloads in our data set. The top
downloaders are well-known programs, which appear in our benign
ground truth and which have valid digital signatures. For example,
we identify the top-3 browsers by searching the digital signatures
for the following  pairs: , , ; we also check that the ﬁle name contains
the keywords chrome, firefox or explore. In addition to brow-
sers, the top downloaders include software updaters and Skype (an
instant messaging program).
Who Drops the Droppers? By analyzing the incoming edges
for all the malicious droppers, we determine that 94.8% of them
are downloaded using the top-3 Web browsers. This illustrates the
# of Inﬂuence Graphs (Log Scale)1102104106Number of Nodes in the inﬂuence Graph (Log Scale)101102103104105# of Inﬂuence Graphs (Log Scale)1102104106Number of Edges in the inﬂuence Graph (Log Scale)1101102103104105# of Inﬂuence Graphs (Log Scale)1102104106Life Span (i.e., age) of the Inﬂuence Graphs (days)0500100015002000time difference (before VT)time difference (after VT)Number of Roots (Log Scale)102103104Time Difference (days)−100−500501001122Downloader ﬁle name
CSRSS.EXE
EXPLORER.EXE
JAVA.EXE
DAP.EXE
OPERAUPGRADER.EXE
SVCHOST.EXE
WMPLAYER.EXE
IDMAN.EXE
CBSIDLM-CBSI145-
SUBTITLESSYNCH-ORG-10445104.EXE
MODELMANAGERSTANDALONE.EXE
KMPLAYER.EXE
JAVAW.EXE
Payloads
14801
1717
892
749
584
547
247
237
209
187
140