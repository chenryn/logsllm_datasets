wrap0 and wrap1, respectively.
2: SP and CS invoke an instance of FMill, in which SP’s input is
(p − 1 − ⟨x⟩0) and CS’s input is (p − 1)/2 + ⟨x⟩1. After that SP
and CS learn lwrap0 and lwrap1, respectively.
3: SP and CS invoke an instance of FMill, in which SP’s input is
(p + (p − 1)/2 − ⟨x⟩0) and CS’s input is ⟨x⟩1. After that SP and
CS learn ⟨rwrap⟩0 and ⟨rwrap⟩1, respectively.
4: SP and CS invoke an instance of FAND, in which the inputs of
CS and SP are ⟨wrap⟩ and ⟨lwrap⟩, and learn ⟨zl⟩.
5: SP and CS invoke an instance of FAND, in which the inputs of
CS and SP are ⟨wrap⟩ and ⟨rwrap⟩, and learn ⟨zr⟩.
6: SP and CS output 1⊕⟨zl⟩0⊕⟨zr⟩0 and ⟨zl⟩1⊕⟨zr⟩1, respectively.
Similar to our validity checking setting, Gibbs et al. presented a
zero knowledge based input validation protocol (SNIP) [13], where
each party needs to generate a SNIP proof which will be used by
servers to validate the input. However, the SNIP does not work
in our SecureFL, since the proof generation on parties is time-
consuming especially with the large dimension of submission,
which runs counter to our goal of efficient protocols for parties.
Moreover, the result of validation is leaked in their protocol, but
rather our SecureFL provides full privacy protection including the
result of validity checking.
Cosine similarity computation. Benefiting from the matrix
multiplication shares generated in the preamble phase in Figure 2,
cosine similarity computations can be non-interactively performed
over secret-shared data without invoking heavy cryptographic
protocols like OT and PLHE.
• At the beginning of this step, CS holds δ generated in the
preamble phase, and we set ⟨cosi⟩1 = δ[i], ∀i ∈ [n]. Then,
SP computes temp = ⟨R⟩0дs + ⟨R⟩1дs − δ, and sets ⟨cosi⟩0 =
temp[i], ∀i ∈ [n]. As such, the cosine similarity ⟨cosi⟩ be-
tween the local gradient дi and the server gradient дs is
computed, since cosi = Rдs[i] = дT
i дs.
Note that an alternative to evaluate this step is to use the Beaver’s
multiplication technique. However, compared to our preprocessing-
based evaluation, for each cosine similarity computation it con-
sumes (|дi| + |дs|)-bits communication and about 6× more compu-
tation overhead during the online phase.
Trust score computation. In this step, the ReLU operation
and the boolean-integer multiplication are performed. Specifically,
we leverage the DReLU protocol in Algorithm 2 as the building
block to construct our ReLU protocol, as shown in Algorithm 3.
Besides, we develop an efficient boolean-integer product protocol
in Algorithm 4 based on COT techniques, which effectively reduces
the communication cost by half.
Algorithm 3 The protocol of ReLU
Input: SP and CS hold ⟨x⟩0 and ⟨x⟩1, respectively.
Output: SP and CS get ⟨ReLU(x)⟩0 and ⟨ReLU(x)⟩1
1: SP and CS invoke FDReLU with input ⟨x⟩ to learn output ⟨y⟩B.
2: SP and CS invoke FBmulA in Algorithm 4 with input ⟨x⟩ and
⟨y⟩B to learn output ⟨z⟩, and sets ⟨ReLU(x)⟩ = ⟨z⟩.
• SP and CS run the ReLU procedure for each i ∈ n, where
the inputs are ⟨cosi⟩0 and ⟨cosi⟩1, respectively. After that,
SP and CS learn ⟨ReLU(cosi)⟩0 and ⟨ReLU(cosi)⟩1.
• SP and CS run the boolean-integer multiplication procedure
to evaluate ⟨T Si⟩ = ⟨f laдi⟩B · ⟨ReLU(cosi)⟩. At the end of
the procedure, SP holds ⟨T Si⟩0 and CS holds ⟨T Si⟩1.
3: The parties run COT(f 1
0 ⟨a⟩0 + (1 − ⟨b⟩B
1 )⟨a⟩1, respectively.
2: The parties run COT(f 0
⟨b⟩B
⟨b⟩B
and SP obtains x while CS obtains y.
Algorithm 4 Secure Boolean-Integer Multiplication
Input: Additive shares of a ∈ Zp and boolean shares of b ∈ Z2
Output: Additive shares of c = ab ∈ Zp
1: SP and CS construct correlation functions f 0
cor(x) = x −
0 )⟨a⟩0 and f 1
cor(x) = x − ⟨b⟩B
1 ⟨a⟩1 + (1 −
cor , ⟨b⟩B
1 ) with SP acting as the sender,
cor , ⟨b⟩B
0 ) with CS acting as the sender,
0 ⟨a⟩0 − x + y′.
1 ⟨a⟩1 − x′ + y.
and CS obtains x′ while SP obtains y′.
4: SP sets ⟨c⟩0 = ⟨c⟩B
5: CS sets ⟨c⟩1 = ⟨c⟩B
Weighted aggregation. At the core of this step is a 2PC sub-
protocol for computing the weighted aggregation of the normalized
local gradients, i.e., evaluating scalar-vector product T Si · дi. The
challenge here is that previous methods evaluating T Si · дi require
2ld + 2l sent bits, where d is the dimension of each gradient and l is
the bit length of each component. To solve such challenge, as shown
in Figure 3, we develop a specialized scalar-vector product protocol,
inspired by Beaver’s triples in the matrix form [36]. The key idea
is that the same ai masking the local gradient дi in the validity
checking can be reused to hide the same дi in the scalar-vector
product evaluation. Its security is guaranteed by the security of the
multiplication triples in the matrix form [36]. For completeness,
we give a sketch of the security proof in Appendix B. Note that
Beaver’s triples cannot be used to mask дi’s in different iterations
for security. As a result, the bandwidth requirement of our solution
is 2l, an 2ld +2l
= d + 1 improvement. This reduction is nontrivial
especially for state-of-the-art neural networks such as ResNets [23],
where d is in the order of millions.
2l
• SP and CS run the Beaver’s multiplication procedure to eval-
uate ⟨T Siдi⟩. At the end of the procedure, SP holds ⟨T Siдi⟩0
and CS holds ⟨T Siдi⟩1.
• SP and CS compute ⟨i∈[n] T Siдi⟩0 and ⟨i∈[n] T Siдi⟩1, re-
spectively. After that, CS sends ⟨i∈[n] T Siдi⟩1 to SP, which
reconstructsi∈[n] T Siдi.
(1) Our SecureFL is robust to parties dropping out. In many FL
systems, participants are mainly composed of resource-constrained
Remark 2.
52Efficient, Private and Robust Federated Learning
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 2: The SecureFL Framework
Efficient,PrivateandRobustFederatedLearningACSAC’21,December6–10,2021,VirtualEvent,USATable2:TheSecureFLFrameworkPARAMETERS:•Numberofparties𝑛,dimensionofeachgradient𝑑.IdealprimitivesFMult,FBeaver,FDReLU,FReLU,FANDandFBmulA.INPUT:•Eachparty𝑃𝑖withlocaldatasetsD𝑖,𝑖∈[𝑛],SPwithseeddatasetD𝑠.PROTOCOL:I.Initialization://Partiesside.a.Allpartiesinitializethearchitecture𝐹andweights𝝎oftheglobalmodel.b.Eachpartygeneratesaprivateseedkey𝑘𝑠𝑒𝑒𝑑𝑖withCSviaexchangingDiffie-Hellmanpublickeysandengaginginakeyagreement.//Serversside.a.SPrunsPLHE.KeyGen(1𝑘)→(𝑝𝑘,𝑠𝑘)andsendsthepublickey𝑝𝑘toCS.b.SPandCSruntheBeaver’striplesgenerationprotocolFBeavertogenerateBeaver’smultiplicationtriples.II.Training:RepeatthestepsII-IVuntilthestoppingcriterion.//Partiesside.a.Eachparty𝑃𝑖runs𝑆𝐺𝐷(𝝎,D𝑖,𝑏)→𝒈𝑖,andcomputesthenormalizedlocalgradient𝒈𝑖←𝒈𝑖∥𝒈𝑖∥.b.Eachparty𝑃𝑖generates𝒓𝑖=PRG(𝑘𝑠𝑒𝑒𝑑𝑖),sets⟨𝒈𝑖⟩1=𝒓𝑖andcomputes⟨𝒈𝑖⟩0=𝒈𝑖−𝒓𝑖.//Serversside.a.SPruns𝑆𝐺𝐷(𝝎,D𝑠)→𝒈𝑠,andcomputesthenormalizedservergradient𝒈𝑠←𝒈𝑠∥𝒈𝑠∥.b.SPcomputes𝐸(𝒈𝑠)=PLHE.Enc(𝑝𝑘,𝒈𝑠)andsendsittoCS.c.CSgenerates⟨𝒈𝑖⟩1=PRG(𝑘𝑠𝑒𝑒𝑑𝑖),∀𝑖∈[𝑛],andsets⟨𝑅⟩1=(⟨𝒈1⟩1,⟨𝒈2⟩1,···,⟨𝒈𝑛⟩1)𝑇.d.CSsamplesarandomvector𝜹,performsPLHE.Eval(𝑝𝑘,𝐸(𝒈𝑠),⟨𝑅⟩1)→𝐸(𝑝𝑘,⟨𝑅⟩1𝒈𝑠−𝜹)usingthedevisedmatrixmultiplicationprocedure,andsends𝐸(𝑝𝑘,⟨𝑅⟩1𝒈𝑠−𝜹)toSP.Besides,CSsets⟨𝑐𝑜𝑠𝑖⟩1=𝜹[𝑖],∀𝑖∈[𝑛].e.SPdecryptstheaboveciphertextstoobtain⟨𝑅⟩1𝒈𝑠−𝜹.III.Aggregation://Partiesside.a.Eachparty𝑃𝑖shares⟨𝒈𝑖⟩0=𝒈𝑖−𝒓𝑖toSP.//Serversside.a.SPandCSinvokeaninstanceofFMultforeach𝑖∈[𝑛],whereSP’sinputis⟨𝒈𝑖⟩0andCS’sinputis⟨𝒈𝑖⟩1.SPandCSlearn⟨∥𝒈𝑖∥2⟩0and⟨∥𝒈𝑖∥2⟩1,respectively.b.SPandCSinvoketwoinstancesofFDReLUforeach𝑖∈[𝑛],wheretheinputsare⟨∥𝒈𝑖∥2+𝜖−1⟩and⟨𝜖+1−∥𝒈𝑖∥2⟩,respectively.SPandCSlearn⟨𝑓𝑙𝑎𝑔𝑖,0⟩𝐵and⟨𝑓𝑙𝑎𝑔𝑖,1⟩𝐵,respectively.c.SPandCSinvokeaninstanceofFANDforeach𝑖∈[𝑛],wheretheinputsare⟨𝑓𝑙𝑎𝑔𝑖,0⟩𝐵and⟨𝑓𝑙𝑎𝑔𝑖,1⟩𝐵,respectively.SPandCSlearn⟨𝑓𝑙𝑎𝑔𝑖⟩𝐵0and⟨𝑓𝑙𝑎𝑔𝑖⟩𝐵1,respectively.d.SPsets⟨𝑅⟩0=(⟨𝒈1⟩0,⟨𝒈2⟩0,···,⟨𝒈𝑛⟩0)𝑇,computes𝑡𝑒𝑚𝑝=⟨𝑅⟩0𝒈+⟨𝑅⟩1𝒈−𝜹,andsets⟨𝑐𝑜𝑠𝑖⟩0=𝑡𝑒𝑚𝑝[𝑖],∀𝑖∈[𝑛].e.SPandCSinvokeaninstanceofFReLUforeach𝑖∈[𝑛],wheretheinputsare⟨𝑐𝑜𝑠𝑖⟩0and⟨𝑐𝑜𝑠𝑖⟩1,respectively.SPandCSlearn⟨𝑅𝑒𝐿𝑈(𝑐𝑜𝑠𝑖)⟩0and⟨𝑅𝑒𝐿𝑈(𝑐𝑜𝑠𝑖)⟩1.f.SPandCSinvokeaninstanceofFBmulAforeach𝑖∈[𝑛],wheretheinputsare⟨𝑅𝑒𝐿𝑈(𝑐𝑜𝑠𝑖)⟩and⟨𝑓𝑙𝑎𝑔𝑖⟩𝐵,respectively.SPandCSlearn⟨𝑇𝑆𝑖⟩0and⟨𝑇𝑆𝑖⟩1.g.SPandCScompute⟨𝑇𝑆⟩=𝑛𝑖=1⟨𝑇𝑆𝑖⟩,locally.h.SPandCSinvokeaninstanceofFMultforeach𝑖∈[𝑛],wheretheinputsare⟨𝒈𝑖⟩and⟨𝑇𝑆𝑖⟩,respectively.SPandCSlearn⟨𝑇𝑆𝑖𝒈𝑖⟩0and⟨𝑇𝑆𝑖𝒈𝑖⟩1.i.SPandCScompute⟨𝒈⟩=𝑛𝑖=1⟨𝑇𝑆𝑖𝒈𝑖⟩locally.j.CSsends⟨𝑇𝑆⟩1and⟨𝒈⟩1toSP.Afterthat,SPreconstructs𝑇𝑆and𝒈,andcomputes𝒈𝑔𝑙𝑜𝑏𝑎𝑙=∥𝒈𝑠∥𝑇𝑆𝒈.IV.Broadcast://Serversside.a.SPupdatestheglobalweight𝝎←𝝎−𝜂𝒈𝑔𝑙𝑜𝑏𝑎𝑙,andbroadcastsittoallparties.//Partiesside.a.Eachparty𝑃𝑖updatesitslocalmodelbyutilizingtheglobalweight𝝎received.53ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Meng Hao, et al.
mobile devices, so they are likely to drop in each round of aggrega-
tion. However, CS non-interactively generates the sharing ⟨R⟩1 of
the local gradient matrix by using PRGs, assuming that all parties
are online. We resolve this problem by using a simple method, i.e.,
letting CS remove the corresponding rows in ⟨R⟩1 that are gener-
ated for dropped parties, to align with ⟨R⟩0. Note that as the number
of dropped parties increases, existing methods such as [10] cause a
quadratic communication overhead, but our approach to handling
dropped-out parties can actually reduce the overhead of CS and SP
(see our experimental results in Tables 4 and 5).
(2) SecureFL performs fixed-point arithmetic in finite fields. The
implementation of the FL gradient aggregation performs arithmetic
operations on floating-point numbers. We work around this by
using fixed-point representations of floating-point numbers and
embedding them in our finite fields, consistent with existing meth-
ods [29] [34]. Furthermore, to prevent values from overflowing due
to arithmetic operations, we use the truncation technique from [36].
This method simply truncates the extra LSBs of fixed-point values
even when the value is secretly shared, albeit at the cost of a 1-bit
error.
(3) SecureFL can be flexibly extended to support layer-wise robust
aggregation. The discussion so far assumes that the robust aggrega-
tion is performed over the entire gradient of each party. However,
for modern large-scale neural networks that even contain thou-
sands of layers, we may need to perform the robust aggregation
layer-wisely. Concretely, to compute the trust score of each party,
we can adaptively assign a weight to each layer (or a combina-
tion of several layers). After that, SecureFL is called iteratively for
each layer, and the overall trust score is calculated by performing
a weighted aggregation of each layer’s trust score. This has two
advantages: 1) mainly focusing on the more important layers for
large-scale models, and 2) preventing overflow when performing
the cosine similarity and the squared ℓ2 norm evaluations.
(4) The cryptographic recipes of SecureFL may be of general inter-
ests. Given that several recent byzantine-robust FL schemes [9] [16]
extensively utilize similarity measurements, our matrix multiplica-
tion pre-processing and ReLU-based comparison techniques can be
extended to empower the realization of privacy protection. More-
over, the use cases of the validity checking technique go beyond
byzantine-robust FL schemes, such as scientific computing [13] and
secure querying [12], where servers need to check whether values
uploaded by (malicious) users are well-formed in the ciphertext.
5.2 Security analysis
Theorem 2. The protocol in Table 2 is a cryptographic FL protocol
in the honest-but-curious setting, given the ideal primitives of the
Beaver’s multiplication procedure, ReLU/DReLU and packed linearly
homomorphic encryption.
Proof. We provide a hybrid argument proof in Appendix B that
relies on the simulators of the above ideal functionalities.
Theorem 3. Our SecureFL is byzantine-robust (i.e., can reject in-
correctly formatted and poisoned gradients), assuming the soundness
of the validity checking construction and the robustness property of
our crypto-friendly FL method (directly derived from FLTrust [11]).
Proof. We provide a brief sketch of the byzantine robustness
argument in Appendix B.
6 EVALUATION
We employ two distinct code bases for the implementation of Se-
cureFL. Cryptographic protocols are implemented in C++, relying
on the SEAL homomorphic encryption library5 for PLHE and CrypT-
Flow library6 for 2PC protocols. On the other hand, FL experiments
are developed in Python and experimental settings mainly follow
the previous work [11].
6.1 Experimental Setup
We describe the detailed experimental setup in this section.
Cryptographic setting: To purely measure our SecureFL’s
performance, we conduct simulations on a Linux machine with an
Intel Xeon(R) CPU E5-2620 v4 (2.10 GHz), 16 GB of RAM. Moreover,
we compare prior works with our SecureFL in a simulated LAN