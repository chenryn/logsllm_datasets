The task of pattern matching is as follows. P1 holds some
text T ∈ Σn and P2 holds a pattern p ∈ Σm for some alpha-
bet Σ. (We assume n and m are known by both parties.)
P2 should learn the indices i (if any) where p occurs as a
pattern in T . If we let Ti denote the m-character substring
of T starting at position i, then P2 should learn {i | Ti = p}.
Pattern matching can be reduced to keyword search3 by
having P1 process the text T to generate the “database”
D = {(Ti, i)}n−m+1
, and then having P1 and P2 compute
Fks using inputs D and p, respectively [9]. The primary
advantage of using our keyword-search protocol here is that
it naturally allows for keyword repeats, which in the present
context means that it automatically handles the case where
patterns may repeat in T (and so it may occur that Ti = Tj
for distinct i, j).
In contrast, Hazay and Lindell [9] need
to introduce additional modiﬁcations in order to deal with
such repeats in the text. As a consequence, our resulting
protocol for pattern matching makes only a single call to
the underlying sub-protocol for OPRF, whereas the Hazay-
Lindell protocol for pattern matching requires n−m+1 calls
to an underlying OPRF protocol.4
i=1
More generally, we can use keyword search for secure com-
putation of any text-processing task of the following form:
P1 holds a text T , and P2 holds a pattern p; the goal is for
P2 to learn {f (T, i) | Ti = p} for an arbitrary function f .
(Pattern matching is a special case where f (T, i) def= i.) This
can be done by having P1 process T to generate a database
D = {(Ti, f (T, i))}n−m+1
, and then having P1 and P2 com-
pute Fks using inputs D and p, respectively. Once again, it
is crucial that Fks be able to handle keyword repeats.
i=1
We list some applications of the above technique:
Checking for tandem repeats in DNA. A tandem repeat
in a DNA snippet T is a pattern that is repeated multiple
times in adjacent locations of T . Rephrasing, a given nu-
cleotide pattern p is said to occur as a tandem repeat in T
if p(cid:96) (for (cid:96) > 1) occurs as a substring of T . Say P1 holds a
DNA snippet T and P2 holds an m-character nucleotide pat-
tern p, and P2 wants to learn all locations i where p appears
3Recall we aim for one-sided security only. The reductions
described in this section do not suﬃce to achieve full security
against a malicious P1.
4Hazay and Lindell show that this overhead can be avoided
by using a speciﬁc OPRF protocol for a speciﬁc (number-
theoretic) PRF. We avoid any additional overhead while us-
ing OPRF as a black box.
in T and, for each such location i, the largest (cid:96) for which p(cid:96)
occurs as a substring beginning at position i. Letting Ti, as
always, denote the m-character substring beginning at posi-
tion i, this task can be done easily within our framework by
deﬁning the function f (T, i) = (i, (cid:96)max), where (cid:96)max is the
largest integer such that T (cid:96)max
appears as a substring in T
beginning at position i. (We remark that in this particular
case eﬃciency can be improved by using the fact that p(cid:96)
occurs at position i iﬀ p(cid:96)−1 occurs at position i + m.)
i
Text statistics. Our basic framework can also be used
for secure computation of various statistics about T . As
one example, consider the case where P2 wants to ﬁnd out
the number of occurrences of p in T (without learning the
locations of these occurrences). This can be done within our
framework by deﬁning f (T, i) = N , where N is the number
of times the m-character string Ti occurs in T .
In the case when f (T, i) = f(cid:48)(Ti, T ) for some function
f(cid:48) (as is the case in the preceding example), we can also
use a variant of the reduction given previously. Namely, P1
can exhaustively enumerate the space of possible patterns p
and, for each p that occurs as a substring of T , add the tuple
(p, f(cid:48)(p, T )) to its database D. As before, P1 and P2 then
compute Fks using inputs D and p, respectively. This vari-
ant approach has complexity O(|Σ|m), whereas the original
approach sketched earlier in this subsection has complexity
O(n − m). Depending on the relevant parameters, the vari-
ant approach might in some cases be preferred. (By way of
example, if T represents a DNA snippet and p is a nucleotide
pattern consisting of four base pairs, then m,|Σ| = 4 while
we might have T ≈ 500, 000; the variant approach just dis-
cussed would then be preferred.)
Non-numeric values. So far we focused on computing
numeric values, but clearly non-numeric values can be com-
puted as well. For example, suppose that P2 is interested
in searching T for all occurrences of a pattern p, and when-
ever the pattern is found P2 would like to learn the next t
characters. This is easily handled in our framework by set-
i+m, where T (cid:48)
ting f (T, i) = T (cid:48)
i denotes the substring of T of
length t starting at location i.
4. GENERAL TEXT PROCESSING
In this section we give a general protocol for secure text
processing by combining the keyword search functionality
(described in Section 3) and Yao’s garbled circuit approach.
The resulting protocol has two attractive features:
it can
compute a wide variety of functions on a text T and a pat-
tern p, and it does so using a number of circuits that is
linear in (an upper bound on) the number of occurrences of
p in T (rather than linear in |T|). We discuss applications
and extensions of this protocol in Section 5.
4.1 An Overview of the Protocol
As usual, P1 has a text T , and P2 has a pattern p.
In
addition, we now allow P2 to also have some private param-
eters y. We consider a general class of functionalities deﬁned
by two functions g and h known to both parties. Formally,
deﬁne a class of functionalities Fg,h as:
Fg,h(T, p, y) =
(2)
where, as usual, Ti is the substring of T of length m = |p|
starting at location i. (Also, we continue to assume that only
g(T, i), y
h
| Ti = p
,
(cid:110)
(cid:179)
(cid:180)
(cid:111)
489Protocol πtxt
Input to P1: A text T ∈ Σn.
Input to P2: A pattern p ∈ Σm (m < n) and parameters y ∈ {0, 1}k.
Common input: The input lengths n, m and an upper bound u on the number
of times p appears as a substring in T .
(cid:110)
(cid:179)
(cid:180)
(cid:111)
| Ti = p
.
Output: P2 learns
Let t = n − m + 1. The parties do:
g(T, i), y
h
1. P1 runs u invocations of Garble(1k, H) to obtain (gH1, (cid:126)X1, (cid:126)Y1),
(gHu, (cid:126)Xu, (cid:126)Yu).
. . . ,
2. P1 and P2 execute k (parallel) instances of OT. In the ith instance, the
u ), and
inputs of P1 are the two strings (Y i,0
the input of P2 is yi. At the end of this step, P2 holds (cid:126)Y1(y), . . . , (cid:126)Yu(y).
u ) and (Y i,1
, . . . , Y i,0
, . . . , Y i,1
1
1
3. P1 sets xi = g(T, i) for all i. Then P1 deﬁnes a database D as follows.
Choose a random permutation π of {1, . . . , u}. Then for i = 1, . . . , t do:
(a) Say this is the N th time Ti has been encountered as a substring in T .
(Note that 1 ≤ N ≤ u.) Let j = π(N ).
(cid:179)
(cid:179)
(cid:180)(cid:180)
(b) Add
Ti,
j, (cid:126)Xj (xi)
to D.
4. P1 and P2 compute functionality Fks using inputs D and p, respectively. As
a result, P2 obtains a set {(j, (cid:126)X(cid:48)
j )}j∈U for some U ⊆ {1, . . . , u}.
5. P1 sends gH1, . . . , gHu to P2.
6. Party P2 outputs
Eval
(cid:110)
(cid:179)
(cid:180)(cid:111)
gHj , (cid:126)X(cid:48)
j , (cid:126)Yj (y)
.
j∈U
Figure 3: A protocol for secure text processing.
P2 obtains output.) As described, Fg,h allows P2 to learn
a set of values, but in some applications it is desirable to
instead compute a single result based on these values (e.g.,
the example from the Introduction). In the following section
we describe how to apply our techniques to that case.
The idea behind our protocol is to compute Fg,h(T, p, y)
using keyword search and Yao’s garbled circuit. We moti-
vate how this is done, postponing discussion of several tech-
nical details to the following section. Let u denote a (known)
upper bound on the number of times any m-character pat-
tern repeats in T . At the beginning of the protocol P1 con-
structs u garbled circuits gH1, . . . , gHu from the circuit H
for the function h. We want P2 to be able to evaluate these
garbled circuits on P2’s input y, as well as the (at most u)
def= g(T, i) for which Ti = p. Note that P1 can com-
values xi
pute all the xi without any interaction with P2. Thus, all we
need to do is provide a way for P2 to learn the appropriate
input-wire labels.
It is easy for P2 to learn the labels of the wires corre-
sponding to its own input y using oblivious transfer.
In
fact, because P2’s input to each of the (garbled) circuits is
the same we can accomplish this using just |y| invocations
of (string) oblivious transfer. A further optimization would
be for P1 to use the same labels for the wires corresponding
to P2’s input, in each of the u circuits. (For simplicity, this
optimization is not applied in the following section.)
To enable P2 to learn the labels of the wires correspond-
ing to P1’s input(s) to the u garbled circuits, we rely on
keyword search as a sub-routine. Essentially (but omitting
some technical details), P1 prepares a database D with en-
tries of the form (Ti, (cid:126)Xj(xi)) where (cid:126)Xj denotes the labels
on the input wires of P1 in the jth garbled circuit. When
P1 and P2 then run keyword search (with P2 using p as its
keyword), P2 learns exactly the input-wire labels for those
indices i satisfying Ti = p. To complete the protocol, P2
needs only to evaluate each garbled circuit using the input-
wire labels it has obtained for that circuit.
4.2 The Protocol
(cid:180)
(cid:179)
g(T, i), y
Our protocol is described in Figure 3, where we use H to
denote a circuit for computing the function h. We remark
that the permutation π is used to hide the ordering in which
the results h
are computed; this ordering should
be hidden because the output of Fg,h (cf. Equation (2)) is an
unordered set. If we instead deﬁne the output of Fg,h to be
an ordered list, then this permutation would be unnecessary.
Note also that although our description of the protocol as-
sumes that g, h are deterministic it would not be diﬃcult to
modify the protocol to handle probabilistic functionalities:
g is anyway computed locally by P1, and P1 could hard-
wire (independent) randomness into each circuit H before
garbling it. (These ﬁxes apply when considering one-sided
security, but we note that they would not suﬃce to guaran-
tee full security against a malicious P1.)
Theorem 4.1. Fix (probabilistic) polynomial-time func-
tions g and h, and consider protocol πtxt from Figure 3. If
the sub-protocols for the parallel OT and Fks are each one-
sided secure, then πtxt is a one-sided secure protocol for the
functionality Fg,h.
Proof. We need to show that πtxt is private even against
a malicious P1, and fully secure against a malicious P2. Pri-
vacy when P1 is corrupted follows easily from the assumed
privacy of the sub-protocols used, since P2 sends no mes-
sages in πtxt other than the messages it sends during exe-
cutions of the OT and keyword-search sub-protocols. Next,