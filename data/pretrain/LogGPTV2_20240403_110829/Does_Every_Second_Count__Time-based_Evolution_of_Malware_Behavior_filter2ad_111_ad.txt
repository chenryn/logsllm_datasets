(43% of the samples belonged to the top nine families, which
covered instead only 29% of the entire dataset). Similarly,
67% of the benign samples that executed for less than one
minute showed signs of network operations. This is likely due
to droppers and installers.
Figure 3 shows the Absolute Code Coverage (on the Y
axis) reached by each sample at the end of its execution (on
the X axis). The plot conﬁrms once more how most of the
samples are either exiting in the ﬁrst two minutes, or executing
until the end of the 15 minutes window. It also shows that the
absolute code coverage does not change much among these two
8
Fig. 4: Relative Syscall and Code Coverage of a Malware
Sample
Fig. 6: Global evolution of syscalls and unique basic blocks
over time, only for samples that executed until the end of the
15 minutes time window
executed by all samples, to provide a view on the global
evolution of Rc and Rs. Once more, the orange line shows
the cumulative evolution of the Relative Syscall Coverage,
but this time for all samples together. The curve increases
rapidly for the ﬁrst two minutes, even when there are still more
samples running. After that, it continues with an almost perfect
linear growth that seems to suggest that, as far as samples are
running, the longer we execute them, the more behavioral data
we can collect.
However, the blue line shows a completely different pic-
ture. In fact,
the Relative Code Coverage for all samples
ﬂattens very fast, already reaching 97% in the ﬁrst minute
and 99% after three minutes. While 19% of the samples run
for more than ten minutes, between 10 and 15 minutes we
only observe a negligible 0.2% increase in the overall code
coverage – suggesting that a negligible amount of new behavior
is observed in this time window. In fact, by combining the two
lines, Figure 5 suggests that the fact that samples continue
to execute new system calls does not necessarily mean that
these system calls also capture new functionalities (this is
also conﬁrmed by the machine learning classiﬁer discussed in
Section VI). Instead, these calls are likely repetitions that are
executed from the same code (and therefore the same behavior)
that was already observed before.
One may argue that this aggregated result is skewed by
the fact that half of the samples terminate during the ﬁrst
minute. In other words, most of the basic blocks are observed
at the beginning because that is when most of the samples
are running. Even though this would not explain the linear
system call growth, further evidence against this hypothesis is
provided by Figure 6. This is the same graph we discussed
above, but this time plotted only for the samples that executed
until the end of the 15 minutes period. The system call line is
now perfectly diagonal, conﬁrming that its initial increase was
in fact due to more samples running during the ﬁrst minute of
experiment. However, the Relative Code Coverage line remains
almost unchanged. Therefore, also for those samples that kept
running until we stopped the sandbox, over 90% of the basic
blocks were already visited during the ﬁrst minute.
Fig. 5: Global evolution of syscalls and unique basic blocks
over time
extremes—ranging from 18.8% of the samples terminating in
the ﬁrst minute to 26.4% for those on the right side of the
graph. Similarly, benign samples reached an average Absolute
Code Coverage of 24% at the end of their execution.
C. Behavior evolution
Figure 4 synthesizes the main results of our study for one
random malware sample (our system generated one graph like
this for each sample in our dataset). It is interesting to note
the distance between the two lines, one showing the Relative
Syscall Coverage (i.e.,
the percentage of the system calls
observed at time t with respect to the total number observed
over the 15 minutes of our experiment) and one the Relative
Code Coverage (i.e., the percentage of unique basic blocks
observed over time). It is surprising that most of the basic
blocks were observed during the ﬁrst minute, while the number
of system calls grows more slowly for the entire duration of
the experiment. For instance, after three minutes Rc is over
90% while Rs is only 16%.
To look at the samples in a cumulative way, we plotted
Figure 5, over all basic blocks and syscalls that have been
9
of the sample and the code belonging to shared libraries or to
other processes the malware is infecting at runtime. However,
since this process is also potentially subject to errors, one more
conservative way would be to count all code, independently
from to whom it belongs to.
So far, we have presented results based on counting only
those basic blocks that are part of the malicious sample code.
In our opinion, this is the most appropriate way to look at
malware behavior. However, to account for the possibility of
measurement errors, it is important to show that our ﬁndings
would be the same also if using any of the other measurement
approaches. Figure 8 compares the different techniques. Note
that we use a logarithmic time scale to further emphasize the
differences, that would otherwise be compressed to a small
region of the graph.
The plot shows two important things. First of all, there is
practically no difference in the Relative Code Coverage metric
if we compute it by counting basic blocks or raw memory
regions (red and blue curves). The effect on the Absolute Code
Coverage (curves orange and purple) is more visible, and leads
to a total code coverage of 21.6% if we count disassembled
basic blocks or 23.8% if we look at memory regions.
Finally, the green line shows the Relative Code Coverage if
we include all code, including external libraries. Furthermore,
even in presence of errors in the process of dumping the
memory and determining the executable basic blocks or code
regions (e.g. due to packers that re-encrypt memory regions),
this line still contains the executed basic blocks and thus serves
as a lower bound for RC. At ﬁrst, this curve grows slower than
the ones computed before. For instance, after two minutes the
code coverage computed by including all code is 91%, while
by looking only at the code belonging to the malware sample
itself the value is 98.7%. This difference can be explained
by the fact
that a piece of malware code can invoke the
same library function twice but with different parameters, thus
resulting in different execution paths inside the library code
itself. In any case, at ten minutes the difference between the
two curves is already below 0.5%.
Impact of Stalling Code
As we already mentioned in Section III, when measuring
time we need to decide whether we want to fast forward
through sleep invocations or preserve the program pauses.
In our experiments, 14% of the malicious and 6% of the
benign samples called Sleep (or SleepEx) at least once—
accounting for a cumulative sleeping time of respectively
569, 310, 375 and 6, 097 minutes.
To assess the impact of stalling code on the amount of
time required to execute a sample, we compare in Figure 9 the
evolution of the Relative Syscall and Relative Code Coverage
metrics when the sleep time is preserved. Quite surprisingly,
sleep time seems to have an almost negligible effect on code
coverage and a 10% reduction to the cumulative number of
system calls collected over the 15-minute period.
Fig. 7: Global evolution of stable behaviors over time
Fig. 8: Impact of counting bytes vs basic blocks, and removing
or not library code
A different way to further investigate this is to look at
the number of samples that reach a stable behavior over
time. Figure 7 shows the percentage of samples for which we
observed respectively 100%, 90%, and 75% of the basic blocks
at a certain time within our 15 minutes timespan. Here, it is
interesting to observe the difference between the three curves
with respect to the termination line (in red). For instance,
after two minutes the 71% of the samples have terminated
their execution, but for more than 80% of them we have
already observed 100% of their relative code coverage—and
the two curves kept this 10% difference until the last minute of
experiments. This indicates that Rc does not reach 100% only
when the sample terminates. In some cases (that 10% in the
graph) samples still run for several minutes without triggering
any new line of code.
Comparison Among Different Code Coverage Metrics
As we explained in Section III-B, we can measure absolute
code coverage by counting either basic blocks or by measuring
the size of the executable memory—and both techniques are
subject
to different errors. Moreover, as we explained in
Section IV, our system is able to distinguish between the code
In fact, at a closer inspection, 75% of the 11,874 malware
samples that call sleep only stalled their execution for less
than one minute. Overall, 3.1% of our malicious samples slept
for more than three minutes and only 2.3% for more than
ten. This result provides an important ﬁgure for companies
10
Fig. 9: Impact of sleep time over the global evolution of
syscalls and code coverage.
Fig. 11: Code and Syscall coverage comparison between 3
families
D. Intra-Family Variability
So far, we always looked at aggregated values computed
over the entire dataset. However, it is interesting to see whether
our metrics tend to remain constant within a given malware
family. If so, the distribution of samples among families in the
dataset could have a huge impact on our results.
To answer this question, we re-plotted the two ﬁgures that
best summarized the results of our experiment (the scatterplot
of the absolute code coverage and the Rc and Rs curves),
but only with the samples of three families: sivis, mepaow,
and blackmoon. Figure 10 shows the three families by us-
ing different colors. The distribution of the points are very
different: all mepaow samples have the same code coverage,
but differ in their execution time; blackmoon samples are the
opposite, as they all run for a very short amount of time but
achieve different absolute code coverage; ﬁnally sivis’ points
are scattered everywhere, showing no clear pattern.
To explain these different behaviors we had to manually
look at the details of each family. Blackmoon is a banker
that
tries to inject code into other programs by calling
NtCreateSection and NtMapViewOfSection. Differ-
ent samples had different targets, and often more than one.
If none of the targets was found running in the machine,
which is our case, the malware terminates. This is a common
scenario, that shows what happens when a malware family
is analyzed in a sandbox that does not properly mimic the
expected environment. Mepaow is instead a trojan keylogger.
All samples in our dataset had exactly the same behavior,
which explains why we observe the same coverage. But
the malware calls many times NtWaitForSingleObject.
Sometimes the wait fails, and in that case the call blocks until
a timeout is reached. This explains why the execution time of
most samples varies between 12 and 15 minutes. Finally, sivis
is a ﬁle infector, and therefore the executables we analyzed
in our sandbox are in fact other programs infected by the
malware, thus explaining why both the execution time and
the Ac metric were so different from one sample to the other.
Figure 11 shows the Relative code and syscall coverage
lines. Different families have different trends but overall we
Fig. 10: Absolute Coverage comparison between 3 families
that use sandboxes that do not skip sleep time (the majority,
according to the experiment we discussed in Section II). Based
on our experiments, these companies can expect between two
and three percent of the samples they analyze to complete
evade their sandbox environment.
Impact of Code Injection
Code injection is a well-known technique applied by mal-
ware [18], [55]. Our sandbox only tracks processes that belong
to the same process tree of the malware. Therefore, code
injection could bypass our analysis if code is injected into
a process outside the sample’s process tree. To measure its
impact on our dataset, we analyzed the collected behavior for
signs of code injection techniques by identifying write-access
to memory regions of other processes. Our experiments show
that while in total 19% of all samples write to memory of other
processes, only 2% of all samples inject code into processes
outside their own process tree and are therefore able to partially
evade our data collection mechanism.
11
still observe a very steep exploration of basic blocks (a little
less pronounced for the ﬁle infector as its sample execute code
from the infected applications) and a more smooth progress of
the system calls.
To conclude, with these three examples, we illustrated how
different families can result in different behavioral proﬁles,
but in particular that it is often difﬁcult to predict how long
a sample would run and how much code it will trigger, even
within a single known family.
E. Analysis of long-time running samples
Since a large portion of malware in our dataset executed
for the whole duration of the 15 minutes time window, we
decided to manually investigate the nature of these samples.
In the following, all percentages are relative to the samples
that ran for the entire 15 minutes period.
The ﬁrst aspect we studied is the amount of network related
syscalls and the contacted IP addresses. More speciﬁcally, we
noticed that 22.45% of the samples executing for 15 minutes
were contacting remote servers for the entire time frame. We
further analyzed the invoked syscalls and the contacted IP
addresses and we dissected these samples into three minor
groups. The ﬁrst one, accounting for 10.45% of the long-
running samples, is represented by C&C samples that receive
a command from the remote server and show some patterns
which always repeat, such as opening and writing a ﬁle, or
setting a new entry in some registry. In contrast, the second
group (9.71%) are botnet samples that contact many more IP
addresses (from a minimum of 10 to a maximum of 820 dis-
tinct IPs), some of them belonging to infected hosts and some
others to machines under the attacker’s control. The last group
(2.29%) is composed of C&C samples as well, but this time
receiving only a small number of commands from the remote
server. Therefore, samples in this last group spent most of
their time in invocation of the NtWaitForSingleObject
/ NtWaitForMultipleObject system calls, i.e., sending
a request to the server and waiting for a response from it.
A second behavior that we could observe looking at the
last minutes of execution is related to ﬁlesystem accesses. In
particular, we retrieved the number of ﬁlesystem activities from
the system calls log, and we considered all the samples that
were still showing such behavior when they were interrupted
(i.e., when we reached 15 minutes). In total, 40.17% of the
samples kept repeating ﬁle operations (from a minimum of
10,000 operations) for their entire execution time. Because of
the shown behavior and after a manual analysis of some of
these samples, we categorized them as ﬁle infectors (which
was also conﬁrmed by the AVClass-labels of the samples).
Intuitively, we would have expected that a non-negligible
part of the long-time running samples consisted of malware
that spawn a GUI and spend 15 minutes waiting for a user
interaction. Detecting these samples at syscall level is not
trivial, because no direct mapping between the graphical API
and the internally invoked syscalls exists. Moreover, most of
the graphical operations are performed by means of IO control
messages sent to and from the dedicated device driver (by
means of NtDeviceIOControl) that do not allow to easily
recover the real meaning of the syscall. Hence, we tried to
estimate the number of malicious samples that implement a
GUI at API level, i.e., by fetching when a sample imports and
invokes methods such as MessageBox, MessageBoxEx,
etc. This way we were able to determine that 19.75% of long-
running malicious samples indeed used a graphical interface
to communicate with the user and to receive an input. This
percentage must be considered as a lower bound, because we
use the import address table (IAT) to resolve the calls and it
is well-known that the IAT can be obfuscated by packers.
Finally, we found that 11.19% of samples justify their