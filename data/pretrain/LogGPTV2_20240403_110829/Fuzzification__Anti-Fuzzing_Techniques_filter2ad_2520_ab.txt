BranchTrap, and AntiHybrid– to target each fuzzing tech-
nique discussed in §2.1. First, SpeedBump injects fine-
grained delay primitives into cold paths that fuzzed execu-
tions frequently touch but normal executions rarely use (§3).
Second, BranchTrap fabricates a number of input-sensitive
branches to induce the coverage-based fuzzers to waste their
efforts on fruitless paths (§4). Also, it intentionally saturates
the code coverage storage with frequent path collisions so
that the fuzzer cannot identify interesting inputs that trigger
new paths. Third, AntiHybrid transforms explicit data-flows
into implicit ones to prevent data-flow tracking through taint
analysis, and inserts a large number of spurious symbols to
trigger path explosion during the symbolic execution (§5).
Figure 3 shows an overview of our FUZZIFICATION sys-
tem. It takes the program source code, a set of commonly
used test cases, and an overhead budget as input and produces
a binary protected by FUZZIFICATION techniques. Note that
FUZZIFICATION relies on developers to determine the appro-
priate overhead budget, whatever they believe will create a
balance between the functionality and security of their pro-
duction. 1 We compile the program to generate a normal
binary and run it with the given normal test cases to collect
basic block frequencies. The frequency information tells us
which basic blocks are rarely used by normal executions. 2
Based on the profile, we apply three FUZZIFICATION tech-
niques to the program and generate a temporary protected
binary. 3 We measure the overhead of the temporary binary
with the given normal test cases again. If the overhead is
over the budget, we go back to step 2 to reduce the slow
down to the program, such as using shorter delay and adding
less instrumentation. If the overhead is far below the bud-
get, we increase the overhead accordingly. Otherwise, 4 we
generate the protected binary.
1916    28th USENIX Security Symposium
USENIX Association
❷ Fuzzification❸ Measure❶ Profiling BB freq profile   normalbinary ovrhdbudgetsourcecode testcases LLVM IRexecSpeedBumpBranchTrapAntiHybridexecin budget?protectedbinary ❹ Finish3 SpeedBump: Amplifying Delay in Fuzzing
We propose a technique called SpeedBump to slow the fuzzed
execution while minimizing the effect to normal executions.
Our observation is that the fuzzed execution frequently falls
into paths such as error-handling (e.g., wrong MAGIC bytes)
that the normal executions rarely visit. We call them the cold
paths. Injecting delays in cold paths will significantly slow
fuzzed executions but will not affect regular executions that
much. We first identify cold paths from normal executions
with the given test cases and then inject crafted delays into
least-executed code paths. Our tool automatically determines
the number of code paths to inject delays and the length of
each delay so that the protected binary has overhead under
the user-defined budget during normal executions.
Basic block frequency profiling. FUZZIFICATION gener-
ates a basic block frequency profile to identify cold paths. The
profiling process follows three steps. First, we instrument
the target programs to count visited basic blocks during the
execution and generate a binary for profiling. Second, with
the user-provided test cases, we run this binary and collect the
basic blocks visited by each input. Third, FUZZIFICATION
analyzes the collected information to identify basic blocks
that are rarely executed or never executed by valid inputs.
These blocks are treated as cold paths in delay injection.
Our profiling does not require the given test cases to cover
100% of all legitimate paths, but just to trigger the commonly
used functionalities. We believe this is a practical assumption,
as experienced developers should have a set of test cases
covering most of the functionalities (e.g., regression test-
suites). Optionally, if developers can provide a set of test
cases that trigger uncommon features, our profiling results
will be more accurate. For example, for applications parsing
well-known file formats (e.g., readelf parses ELF binaries),
collecting valid/invalid dataset is straightforward.
Configurable delay injection. We perform the following
two steps repeatedly to determine the set of code blocks to
inject delays and the length of each delay:
• We start by injecting a 30ms delay to 3% of the least-
executed basic blocks in the test executions. We find that
this setting is close enough to the final evaluation result.
• We measure the overhead of the generated binary. If it
does not exceed the user-defined overhead budget, we
go to the previous step to inject more delay into more
basic blocks. Otherwise, we use the delay in the previous
round as the final result.
Our SpeedBump technique is especially useful for developers
who generally have a good understanding of their applica-
tions, as well as the requirements for FUZZIFICATION. We
provide five options that developers can use to finely tune
SpeedBump’s effect. Specifically, MAX_OVERHEAD defines the
overhead budget. Developers can specify any value as long
as they feel comfortable with the overhead. DELAY_LENGTH
specifies the range of delays. We use 10ms to 300ms in the
s
k
c
o
l
b
.
u
r
t
s
n
i
f
o
%
12
10
8
6
4
2
0
(a) Max instru. ratio per delays
1
20
40
60
80
100
c
e
s
/
c
e
x
e
0
0
1
5
4
3
2
1
0
(b) Fuzzer performance
overhead < 1%
overhead < 3%
1
20
40
60
Delays(ms)
80
100
Figure 4: Protecting readelf with different overhead budgets.
While satisfying the overhead budget, (a) demonstrates the maxi-
mum ratio of instrumentation for each delay length, and (b) displays
the execution speed of AFL-QEMU on protected binaries.
evaluation. INCLUDE_INCORRECT determines whether or not
to inject delays to error-handling basic blocks (i.e., locations
that are only executed by invalid inputs), which is enabled
by default. INCLUDE_NON_EXEC and NON_EXEC_RATIO specify
whether to inject delays into how ever many basic blocks are
never executed during test execution. This is useful when
developers do not have a large set of test cases.
Figure 4 demonstrates the impact of different options on
protecting the readelf binary with SpeedBump. We collect
1,948 ELF files on the Debian system as valid test cases and
use 600 text and image files as invalid inputs. Figure 4(a)
shows the maximum ratio of basic blocks that we can inject
delay into while introducing overhead less than 1% and 3%.
For a 1ms delay, we can instrument 11% of the least-executed
basic blocks for a 1% overhead budget and 12% for 3% over-
head. For a 120ms delay, we cannot inject any blocks for
1% overhead and can inject only 2% of the cold paths for
3% overhead. Figure 4(b) shows the actual performance of
AFL-QEMU when it fuzzes SpeedBump-protected binaries.
The ratio of injected blocks is determined as in Figure 4(a).
The result shows that SpeedBump with a 30ms delay slows
the fuzzer by more than 50×. Therefore, we use 30ms and
the corresponding 3% instrumentation as the starting point.
3.1 Analysis-resistant Delay Primitives
As attackers may use program analysis to identify and re-
move simple delay primitives (e.g., calling sleep), we design
robust primitives that involve arithmetic operations and are
connected with the original code base. Our primitives are
based on CSmith [66], which can generate random and bug-
free code snippets with refined options. For example, CSmith
can generate a function that takes parameters, performs arith-
metic operations, and returns a specific type of value. We
modified CSmith to generate code that has data dependencies
and code dependencies to the original code. Specifically, we
pass a variable from the original code to the generated code
as an argument, make a reference from the generated code to
the original one, and use the return value to modify a global
variable of the original code. Figure 5 shows an example of
our delay primitives. It declares a local variable PASS_VAR
USENIX Association
28th USENIX Security Symposium    1917
int32_t *l0[1000];
GLOBAL_VAR1 = 0x4507L; // affect global var.
int32_t *l1 = &g8[1][0];
for (int i = 0; i < 1000; i++)
1 //Predefined global variables
2 int32_t GLOBAL_VAR1 = 1, GLOBAL_VAR2 = 2;
3 //Randomly generated code
4 int32_t * func(int32_t p6) {
5
6
7
8
9
10
11
12
13 }
14 //Inject above function for delay
15 int32_t PASS_VAR = 20;
16 GLOBAL_VAR2 = func(PASS_VAR);
Figure 5: Example delay primitive. Function func updates global
variables to build data-flow dependency with original program.
(*g7) = func2(g6++);
(*g5) |= ~(!func3(**g4 = ~0UL));
return l1;
l0[i] = p6;
// affect local var from argv.
// affect global var.
and modifies global variables GLOBAL_VAR1 and GLOBAL_VAR2.
In this way, we introduce data-flow dependency between the
original code and the injected code (line 6, 9 and 12), and
change the program state without affecting the original pro-
gram. Although the code is randomly generated, it is tightly
coupled with the original code via data-flow and control-flow
dependencies. Therefore, it is non-trivial for common binary
analysis techniques, like dead-code elimination, to distinguish
it from the original code. We repeatedly run the modified
CSmith to find appropriate code snippets that take a specific
time (e.g., 10ms) for delay injection.
Safety of delay primitives. We utilize the safety checks
from CSmith and FUZZIFICATION to guarantee that the gen-
erated code is bug-free. First, we use CSmith’s default safety
checks, which embed a collection of tests in the code, in-
cluding integer, type, pointer, effect, array, initialization, and
global variable. For example, CSmith conducts pointer anal-
ysis to detect any access to an out-of-scope stack variable
or null pointer dereference, uses explicit initialization to pre-
vent uninitialized usage, applies math wrapper to prevent
unexpected integer overflow, and analyzes qualifiers to avoid
any mismatch. Second, FUZZIFICATION also has a separate
step to help detect bad side effects (e.g., crashes) in delay
primitives. Specifically, we run the code 10 times with fixed
arguments and discard it if the execution shows any error. Fi-
nally, FUZZIFICATION embeds the generated primitives with
the same fixed argument to avoid errors.
Fuzzers aware of error-handling blocks. Recent fuzzing
proposals, like VUzzer [52] and T-Fuzz [48], identify error-
handling basic blocks through profiling and exclude them
from the code coverage calculation to avoid repetitive execu-
tions. This may affect the effectiveness of our SpeedBump
technique, which uses a similar profiling step to identify cold
paths. Fortunately, the cold paths from SpeedBump include
not only error-handling basic blocks, but also rarely executed
functional blocks. Further, we use similar methods to identify
error-handling blocks from the cold paths and provide de-
velopers the option to choose not to instrument these blocks.
Thus, our FUZZIFICATION will focus on instrumenting rarely
executed functional blocks to maximize its effectiveness.
4 BranchTrap: Blocking Coverage Feedback
Code coverage information is widely used by fuzzers to find
and prioritize interesting inputs [72, 37, 23]. We can make
these fuzzers diligent fools if we insert a large number of con-
ditional branches whose conditions are sensitive to slight in-
put changes. When the fuzzing process falls into these branch
traps, coverage-based fuzzers will waste their resources to ex-
plore (a huge number of) worthless paths. Therefore, we pro-
pose the technique of BranchTrap to deceive coverage-based
fuzzers by misleading or blocking the coverage feedback.
4.1 Fabricating Fake Paths on User Input
The first method of BranchTrap is to fabricate a large number
of conditional branches and indirect jumps, and inject them
into the original program. Each fabricated conditional branch
relies on some input bytes to determine to take the branch
or not, while indirect jumps calculate their targets based on
user input. Thus, the program will take different execution
paths even when the input slightly changes. Once a fuzzed
execution triggers the fabricated branch, the fuzzer will set a
higher priority to mutate that input, resulting in the detection
of more fake paths. In this way, the fuzzer will keep wasting
its resources (i.e., CPU and memory) to inspect fruitless but
bug-free fake paths.
To effectively induce the fuzzers focusing on fake branches,
we consider the following four design aspects.
First,
BranchTrap should fabricate a sufficient number of fake paths
to affect the fuzzing policy. Since the fuzzer generates various
variants from one interesting input, fake paths should provide
different coverage and be directly affected by the input so that
the fuzzer will keep unearthing the trap. Second, the injected
new paths introduce minimal overhead to regular executions.
Third, the paths in BranchTrap should be deterministic re-
garding user input, which means that the same input should
go through the same path. The reason is that some fuzzers
can detect and ignore non-deterministic paths (e.g., AFL ig-
nores one input if two executions with it take different paths).
Finally, BranchTrap cannot be easily identified or removed
by adversaries.
A trivial implementation of BranchTrap is to inject a jump
table and use some input bytes as the index to access the
table (i.e., different input values result in different jump tar-
gets). However, this approach can be easily nullified by sim-
ple adversarial analysis. We design and implement a robust
BranchTrap with code-reuse techniques, similar in concept
to the well-known return-oriented programming (ROP) [55].
4.1.1 BranchTrap with CFG Distortion
To harden BranchTrap, we diversify the return addresses of
each injected branch according to the user input. Our idea is
inspired by ROP, which reuses existing code for malicious at-
1918    28th USENIX Security Symposium
USENIX Association
4.2 Saturating Fuzzing State
The second method of BranchTrap is to saturate the fuzzing
state, which blocks the fuzzers from learning the progress in
the code coverage. Different from the first method, which
induces fuzzers focusing on fruitless inputs, our goal here
is to prevent the fuzzers from finding real interesting ones.
To achieve this, BranchTrap inserts a massive number of
branches to the program, and exploits the coverage repre-
sentation mechanism of each fuzzer to mask new findings.
BranchTrap is able to introduce an extensive number (e.g.,
10K to 100K) of deterministic branches to some rarely visited
basic blocks. Once the fuzzer reaches these basic blocks, its
coverage table will quickly fill up. In this way, most of the
newly discovered paths in the following executions will be
treated as visited, and thus the fuzzer will discard the input
that in fact explores interesting paths. For example, AFL
maintains a fixed-size bitmap (i.e., 64KB) to track edge cov-
erage. By inserting a large number of distinct branches, we
significantly increase the probability of bitmap collision and
thus reduce the coverage inaccuracy.
Figure 7(a) demonstrates the impact of bitmap saturation on
fuzzing readelf. Apparently, a more saturated bitmap leads
to fewer path discoveries. Starting from an empty bitmap,
AFL identifies over 1200 paths after 10 hours of fuzzing. For
the 40% saturation rate, it only finds around 950 paths. If the
initial bitmap is highly filled, such as 80% saturation, AFL
detects only 700 paths with the same fuzzing effort.
Fuzzers with collision mitigation. Recent fuzzers, like Col-
lAFL [19], propose to mitigate the coverage collision issue
by assigning a unique identifier to each path coverage (i.e.,
branch in case of CollAFL). However, we argue that these
techniques will not effectively undermine the strength of our
BranchTrap technique on saturating coverage storage for two
reasons. First, current collision mitigation techniques require
program source code to assign unique identifiers during the
linking time optimization [19]. In our threat model, attackers
cannot obtain the program source code or the original binary –
they only have a copy of the protected binary, which makes it
significantly more challenging to apply similar ID-assignment
algorithms. Second, these fuzzers still have to adopt a fixed
size storage of coverage because of the overhead of large
storage. Therefore, if we can saturate 90% of the storage, Col-
lAFL can only utilize the remaining 10% for ID-assignment;
thus the fuzzing performance will be significantly affected.
4.3 Design Factors of BranchTrap
We provide developers an interface to configure ROP-based
BranchTrap and coverage saturation for optimal protection.
First, the number of generated fake paths of ROP-based
BranchTrap is configurable. BranchTrap depends on the num-
ber of functions to make a distorted control-flow. Therefore,
injected BranchTrap is effective when the original program
Figure 6: BranchTrap by reusing the existing ROP gadgets in the
original binary. Among functionally equivalent gadgets, BranchTrap
picks the one based on function arguments.
tacks by chaining various small code snippets. Our approach
can heavily distort the program control-flow and makes nulli-
fying BranchTrap more challenging for adversaries. The im-
plementation follows three steps. First, BranchTrap collects
function epilogues from the program assembly (generated
during program compilation). Second, function epilogues
with the same instruction sequence are grouped into one jump
table. Third, we rewrite the assembly so that the function will
retrieve one of several equivalent epilogues from the corre-
sponding jump table to realize the original function return,
using some input bytes as the jump table index. As we re-
place the function epilogue with a functional equivalent, it
guarantees the identical operations as the original program.
Figure 6 depicts the internal of the BranchTrap implemen-
tation at runtime. For one function, BranchTrap 1 calculates
the XORed value of all arguments. BranchTrap uses this value
for indexing the jump table (i.e., candidates for epilogue ad-
dress). 2 BranchTrap uses this value as the index to visit the
jump table and obtains the concrete address of the epilogue.
To avoid out-of-bounds array access, BranchTrap divides the
XORed value by the length of the jump table and takes the
remainder as the index. 3 After determining the target jump
address, the control-flow is transferred to the gadget (e.g.,
the same pop rbp; pop r15; ret gadget). 4 Finally, the
execution returns to the original return address.
The ROP-based BranchTrap has three benefits:
• Effective: Control-flow is constantly and sensitively
changed together with the user input mutation; thus