### Bandwidth Performance of thttpd Web Server

We evaluated the bandwidth performance of the thttpd web server [31] serving static HTML pages. We configured ApacheBench to make 5000 requests using 25 simultaneous connections. Figure 2 illustrates the results for both the original SVA kernel and the SVA kernel with the new run-time checks described in Section 5. Each bar represents the average bandwidth of three runs, normalized to the performance of the original i386 Linux kernel.

**Figure 2: Web Server Bandwidth (Linux/i386 = 1.0)**

- **SVA Checks**: For small files (1 KB - 32 KB), the new run-time checks introduce a minor overhead, resulting in a 9% decrease in bandwidth compared to the SVA kernel.
- **SVA-OS Checks**: For larger file sizes (64 KB or more), the additional overhead from the SVA-OS checks is negligible.

### SSH Server Bandwidth Performance

We also measured the performance of sshd, a login server offering encrypted file transfer. The bandwidth of transferring several large files from the server to our test client is shown in Figure 3. For each file size, we first performed a priming run to bring file system data into the kernel’s buffer cache, followed by three file transfers. The mean receive bandwidth of the three runs is normalized to the mean receive bandwidth measured on the original i386 kernel.

**Figure 3: SSH Server Bandwidth (Linux/i386 = 1.0)**

- **SVA Checks**: There is no significant decrease in bandwidth due to the extra run-time checks added by the original SVA system or the new run-time checks.
- **SVA-OS Checks**: For large file sizes, the network becomes the bottleneck, and the overheads for basic system calls are only tens of microseconds.

### Application Latency

To understand the impact on end-user application performance, we conducted experiments on the client-side programs listed in Table 3. We tested bzip2 compressing a 64 MB file, the LAME MP3 encoder converting a 206 MB WAV file to MP3 format, and the Perl interpreter running the training input from the SPEC 2000 benchmark suite. For each test, we ran the program once to prime any caches within the operating system and then ran each program three times. Table 3 shows the average execution times of the three runs and the standard deviation.

**Table 3: Latency of Applications. Standard Deviation Shown in Parentheses.**

| Benchmark | i386 (s) | SVA (s) | SVA-OS (s) | % Increase from i386 to SVA-OS |
|-----------|----------|---------|------------|---------------------------------|
| bzip2     | 18.7 (0.47) | 18.3 (0.47) | 18.0 (0.00) | 0.0% |
| lame      | 133.3 (3.3) | 132 (0.82) | 126.0 (0.82) | -0.1% |
| perl      | 22.3 (0.47) | 22.3 (0.47) | 22.3 (0.47) | 0.0% |

### Microbenchmark Performance

To better understand the different performance behaviors of the applications, we used microbenchmarks to measure the overhead introduced by primitive kernel operations. For these experiments, we configured HBench-OS to run each test 50 times.

**Table 5: Latency of Kernel Operations. Standard Deviation Shown in Parentheses.**

| Benchmark | i386 ((μs)) | SVA ((μs)) | SVA-OS ((μs)) | % Increase from SVA to SVA-OS |
|-----------|-------------|------------|---------------|--------------------------------|
| getpid    | 0.16 (0.001) | 0.37 (0.000) | 0.37 (0.006) | 0.0% |
| open/close | 1.10 (0.009) | 11.1 (0.027) | 12.1 (0.076) | 9.0% |
| write     | 0.25 (0.001) | 1.87 (0.012) | 1.86 (0.010) | -0.4% |
| signal handler | 1.59 (0.006) | 6.88 (0.044) | 8.49 (0.074) | 23% |
| signal install | 0.34 (0.001) | 1.56 (0.019) | 1.95 (0.007) | 25% |
| pipe latency | 2.74 (0.014) | 30.5 (0.188) | 35.9 (0.267) | 18% |
| poll      | 1.16 (0.043) | 7.03 (0.014) | 7.59 (0.017) | 8.7% |
| select    | 6.47 (0.080) | 8.18 (0.133) | 8.81 (0.020) | 7.7% |

### File System Bandwidth

We also tested the file system bandwidth, as shown in Figure 4. The results indicate that the original SVA system reduces file system bandwidth by about 5-20% for small files, but the overhead for larger files is negligible. The additional checks for low-level kernel operations add no overhead.

**Figure 4: File System Bandwidth**

### Related Work

Previous work has explored several approaches to providing greater safety and reliability for operating system kernels. Some require complete OS re-design, such as capability-based operating systems [37, 38] and microkernels [1, 25]. Others use isolation (or "sandboxing") techniques, including device driver isolation within the OS [35, 44, 45, 51] or the hypervisor [17]. While effective at increasing system reliability, none of these approaches provide the same level of safety and performance as the SVA-OS checks.