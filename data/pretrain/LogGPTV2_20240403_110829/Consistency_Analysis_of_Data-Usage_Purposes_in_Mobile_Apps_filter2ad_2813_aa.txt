title:Consistency Analysis of Data-Usage Purposes in Mobile Apps
author:Duc Bui and
Yuan Yao and
Kang G. Shin and
Jong-Min Choi and
Junbum Shin
Consistency Analysis of Data-Usage Purposes in Mobile Apps
Duc Bui, Yuan Yao, Kang G. Shin
Junbum Shin∗
CryptoLab
Seoul, Republic of Korea
PI:EMAIL
University of Michigan
Ann Arbor, Michigan, USA
{ducbui,kelyao,kgshin}@umich.edu
Jong-Min Choi
Samsung Research
Seoul, Republic of Korea
PI:EMAIL
ABSTRACT
While privacy laws and regulations require apps and services to
disclose the purposes of their data collection to the users (i.e., why
do they collect my data?), the data usage in an app’s actual behavior
does not always comply with the purposes stated in its privacy
policy. Automated techniques have been proposed to analyze apps’
privacy policies and their execution behavior, but they often over-
looked the purposes of the apps’ data collection, use and sharing.
To mitigate this oversight, we propose PurPliance, an automated
system that detects the inconsistencies between the data-usage pur-
poses stated in a natural language privacy policy and those of the
actual execution behavior of an Android app. PurPliance analyzes
the predicate-argument structure of policy sentences and classifies
the extracted purpose clauses into a taxonomy of data purposes.
Purposes of actual data usage are inferred from network data traffic.
We propose a formal model to represent and verify the data usage
purposes in the extracted privacy statements and data flows to
detect policy contradictions in a privacy policy and flow-to-policy
inconsistencies between network data flows and privacy statements.
Our evaluation results of end-to-end contradiction detection have
shown PurPliance to improve detection precision from 19% to 95%
and recall from 10% to 50% compared to a state-of-the-art method.
Our analysis of 23.1k Android apps has also shown PurPliance
to detect contradictions in 18.14% of privacy policies and flow-to-
policy inconsistencies in 69.66% of apps, indicating the prevalence
of inconsistencies of data practices in mobile apps.
CCS CONCEPTS
• Security and privacy → Privacy protections.
KEYWORDS
Data-usage purposes; privacy policies; consistency analysis; data
flow; mobile apps
ACM Reference Format:
Duc Bui, Yuan Yao, Kang G. Shin, Jong-Min Choi, and Junbum Shin. 2021.
Consistency Analysis of Data-Usage Purposes in Mobile Apps. In Proceedings
of the 2021 ACM SIGSAC Conference on Computer and Communications
∗This work was done while the author was affiliated with Samsung Research prior to
joining CryptoLab.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484536
Security (CCS ’21), November 15–19, 2021, Virtual Event, Republic of Korea.
ACM, New York, NY, USA, 20 pages. https://doi.org/10.1145/3460120.3484536
1 INTRODUCTION
The Federal Trade Commission (FTC) has relied on privacy policies
written in natural language as a primary means to check and inform
users how and why apps collect, use and share user data [16]. Since
purposes of data collection and use/sharing are key factors for
users to decide whether to disclose their personal information or
not [42], it is important for apps to make the users aware of, and
consent to them. For example, users would more likely to agree to
provide their location for receiving an app’s services rather than
for advertising purposes. Moreover, while the purposes of data
collection, use and/or sharing are specified in the apps’ privacy
policies, the apps’ actual execution behavior may deviate from their
specifications in the policies.
Despite its importance, little has been done on checking the
consistency between the purposes stated in the privacy policies and
the actual execution behavior of apps. Prior studies [8, 7, 65, 70,
72, 75] overlooked the purposes and entities whose purposes were
served. Furthermore, the assumption that data sent to an entity is
always used for any of the receiver’s purposes may not hold when
the external service processes the data for the app’s purposes. For
example, the data sent to an analytic service should be used for
the app to analyze its usage trend, not for the analytic service’s
purposes such as delivering personalized advertisements.
A key question is then: Can we automatically check whether the
purposes of actual data usage comply with those stated in privacy
policies or not? The first challenge in answering this question is
to achieve a clear interpretation of the privacy policy and detect
contradictory privacy statements which, if exist, will make the dis-
closure of data flows ambiguous. The second challenge is to extract
the purposes of the actual data flows from the app behavior and
compare them with (potentially contradictory) privacy statements.
Analyzing fine-grained purposes of data usage yields a funda-
mentally different and more complete interpretation of privacy
policies than purpose-agnostic approaches, such as PolicyLint [7]
and PoliCheck [8]. Let us consider the following policy statement
from a popular app on Play Store with more than 1M installations.
Example 1: "We do not share personal information with third parties
for their own direct marketing purposes."
PurPliance interprets this example as third parties may collect
personal data but do not use it to deliver their own advertising,
which is part of marketing purposes. Therefore, PurPliance flags a
contradictory data-usage purpose in another statement stating that
the app "may share your personal data with third-party advertising
partners to serve personalized, relevant ads." Purpose-agnostic ap-
proaches [8, 7] narrowly interpret Example 1 as the app would not
share any personal data. Such approaches do not accurately detect
Session 10D: Applied Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2824We present PurPliance, an end-to-end fully automated system
that detects contradictory privacy statements and inconsistent app
behaviors. In the system workflow (depicted in Fig. 1), contradic-
tion/inconsistency analysis (right half) is fully automated while
ontology extraction (left half) is manual and performed only once.
Inspired by the soundness (i.e., no-false-positive) in software testing
with dynamic analysis [30, 31, 66], PurPliance is designed to maxi-
mize the precision of detection (i.e., a reported inconsistency should
always be true positive), as opposed to maximizing the recall rate.
PurPliance addresses the following three technical challenges.
TC1 (Purpose clause extraction): Purpose clauses are written in
lengthy and complex phrases, and hence it is difficult to determine
their start and end in a sentence. PurPliance leverages neural
Semantic Role Labeling (SRL) models [35, 62] that are capable of an-
alyzing many more grammatical variations than prior work [7], to
extract privacy statement parameters from the semantic arguments
of data-practice predicates. Finally, PurPliance extracts uncom-
pounded purposes from complex purpose clauses by analyzing
their semantic/syntactic structures and decomposing the clauses
into simpler predicate-object pairs and noun phrases. We orga-
nize the common purpose clauses extracted from a large collection
of privacy policies into a hierarchical taxonomy that defines the
relationships among different usage purposes.
TC2 (Data flow extraction): Extracting the purpose of data
flows to/from each app is very challenging because the flows take
place at a low data level and lack high-level semantics. PurPliance
leverages recently-developed datasets and dynamic analysis tech-
niques [33] to infer the purposes and the purpose-served entities of
network data traffic from the transferred data and its context. The
low-level purposes of data traffic are then mapped to higher-level
data-usage purposes in our taxonomy of data purposes.
the contradiction of the advertising usage purpose and generate
lots of false positives because the example would then contradict
any other statements about sharing of the user’s personal data.
TC3 (Automated consistency analysis): Automatic detection
of contradictory privacy policy statements and inconsistent net-
work data flows requires automated reasoning of these concepts.
We introduce the notion of data-usage purpose which comprises a
purpose-served entity and a usage purpose, and is separated from
data collection and sharing. We formalize privacy statements and
data flows, and formulate a consistency model to analyze and detect
policy contradictions and flow-to-policy inconsistencies.
The evaluation of our end-to-end contradiction detection demon-
strates that PurPliance is able to detect contradictory sentence
pairs in privacy policies with significantly higher precision and re-
call than PolicyLint [7], a state-of-the-art policy analysis technique.
An in-depth analysis shows two main sources of these improve-
ments: 1) semantic-argument analysis improves the extraction of
privacy statement tuples and 2) data-usage purpose analysis en-
hances the expressiveness of the privacy statement tuples to reflect
the policy sentences’ semantics more accurately. This paper makes
the following main contributions:
• Automatic extraction and classification of data usage purposes
in privacy policies. We developed automatic extraction of pur-
pose clauses based on semantic arguments of the data practice
predicates (Sections 3.1). We introduced predicate-object pairs to
extract simple purposes from a complex clause (Section 3.2). We
studied data usage purposes in a large privacy policy corpus to
construct a purpose taxonomy and develop automatic classifiers.
To the best of our knowledge, this is the first large-scale study
and classification of data usage purposes in privacy policies.
• Formalization and automatic extraction of privacy statements and
data flows with support for data-usage purposes. We developed
NLP-based automatic methods to extract privacy statements
with data-usage purposes from policy sentences (Section 4). We
adapted existing methods to extract data flows with data purposes
from network data traffic (Section 5).
• A formal consistency model with support for data-usage purposes.
We propose a formal model to detect contradictions in privacy
policies and flow-policy inconsistencies between privacy policies
and mobile apps’ data collection (Section 6).
• An end-to-end system (called PurPliance, open sourced at [18])
that detects inconsistencies between the privacy policy and actual
data collection of an app. A corpus of 108 privacy policies (publicly
available at [18]), containing 5.9k sentences and 189 contradic-
tory sentence pairs, was constructed to evaluate the end-to-end
contradiction detection. The results show that PurPliance im-
proves the precision from 19% to 95% and the recall from 10%
to 50% compared to PolicyLint. An in-depth analysis shows that
PurPliance extracts 88% more privacy statements in 45% more
sentences with 9% higher precision than PolicyLint.
• A large-scale study of policy contradictions and flow–policy incon-
sistencies in 23.1k Android apps (Section 8). PurPliance found
29,521 potential contradictions in 18.14% of the policies and 95,083
inconsistencies in 69.66% of the apps, indicating the prevalence
of inconsistencies of data-usage purposes in mobile apps.
2 RELATED WORK
Purpose Analysis in App Behavior. There has been a rich body
of work to extract semantics of app behavior to identify potential
leakage of sensitive information. Whyper [53], AutoCog [56] and
CHABADA [23] analyze and assess the risks of an app’s behavior
(e.g., permission and API usage) in comparison with the app’s de-
scription. FlowCog [52] extracts semantics of data flows from an
app’s GUI to analyze information leaks. NoMoATS [63] inspects the
URL and HTTP headers to detect mobile network requests engaged
in advertising and tracking. MobiPurpose [33] extracts and infers
personal data types and purposes of their data collection from net-
work traffic of Android apps, but it does not check whether the
data-collection purposes are legitimate or not.
Privacy Policy Analysis. NLP and ML have been widely used for
analyzing natural-language privacy policies. Privee [74] and Poli-
sis [27] analyze privacy policies at the document- and paragraph-
level to answer users’ questions. However, both are limited by their
coarse-grained analyses while our sentence- and phrase-level analy-
ses provide more detailed and comprehensive results. PolicyLint [7]
uses dependency parsing to extract privacy statements from policy
documents but does not analyze purposes of data collection.
Bhatia et al. [11] extract common patterns of purposive state-
ments from privacy policies and use semantic frames to analyze
the incompleteness of privacy goals, which include the purposes of
data practices [12]. Shvartzshnaider et al. [64] analyze information
Session 10D: Applied Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2825Figure 1: PurPliance system workflow. Dashed boxes indicate the system inputs.
Data Practice Verbs
Sharing
Collection
Use
disclose, distribute, exchange, give, lease, provide,
rent, release, report, sell, send, share, trade, transfer,
transmit
collect, gather, obtain, receive, record, store, solicit
access, analyze, check, combine, connect, keep, know,
process, save, use, utilize
Table 1: List of the SCoU verbs used by PurPliance.
flows in a limited set of privacy policies following the contextual
integrity framework [48]. However, these semi-automated methods
require the laborious manual efforts of experts or crowd workers.
Behavior-Policy Compliance Analysis of Mobile Apps. Analysis of
the (in)consistencies between the actual behavior of mobile apps
and their privacy policies has gained considerable interest in recent
years. Prior work tracks the collection of users’ personal data auto-
matically via Android API calls [65, 73, 75], or via user inputs on app
GUI [70]. PoliCheck [8] built upon PolicyLint [7] and the AppCen-
sus dataset [9] improves the accuracy of detecting non-compliances
in an app’s data flows by taking into account the recipients of the
personal data. However, PoliCheck does not consider the business
purposes of the data flows. Several researchers focus on narrow app
categories, such as paid apps [25] or apps targeting family users and
children [50, 59, 60]. They are limited to specialized app categories
while PurPliance is general and applicable to any type of apps.
Taxonomy of Privacy Purposes. OPP-115 dataset [71] includes 11
classes of data collection and sharing purposes that were manually
created in a top-down fashion by law experts. In contrast, we created
a hierarchical taxonomy of data-usage purposes by using neural text
clustering with contextualized word embeddings to group similar
purpose clauses in a large policy corpus. Despite a rich body of
work on text clustering [3, 44], we are not aware of any other work
that applies text clustering to the analysis of purposes in privacy
policies.
3 EXTRACTION OF DATA USAGE PURPOSES
3.1 Extraction of Data Usage Purpose Clauses
3.1.1 Extraction of Data Practice Predicates and Semantic Argu-
ments. PurPliance extracts the purposes of privacy practices by
analyzing patterns of semantic arguments, syntactic structures (i.e.,
parts of speech and dependency trees) and a lexicon of data prac-
tices. It first finds data practice predicates (i.e., verbs) that express
the action of a privacy practice event such as "collect" and "share".
PurPliance iterates through the tokens of the sentence and ex-
tracts those words whose part-of-speech tags are a verb and whose
lemmas are in a manually curated list of Sharing-Collection-or-Use
(SCoU) verbs as given in Table 1.
We empirically identified common verbs in randomly selected
privacy sentences to extend the SoC verbs in PolicyLint [7]. While
PolicyLint only distinguishes between collection and sharing of
data, we separate some use verbs. Although the use actions do not
explicitly construct personal data flows, they still provide valuable
information about data processing purposes. We added a verb to the
SCoU list by surveying its usage in randomly selected sentences in
our privacy policy corpus. Because every verb has multiple mean-
ings, some of which are unrelated to data collection/sharing/use,
there is a trade-off: naively adding verbs increases recall but reduces
precision. Therefore, we select verbs that are frequently used to
express data practices (i.e., in over 80% of 100 random sentences).
Given a data practice predicate, PurPliance analyzes its seman-
tic arguments which are phrases that fill the meaning slots of the
predicate and define its details. They answer questions such as
"who?", "did what?", "to whom?", and "for which purpose?" of an
event expressed by the predicate [35, 39]. Because arguments of the
same event are consistent across varying syntactic forms, parame-
ters of privacy statements (such as the receiver and data object) can
be extracted accurately even though the same data practice event is
expressed in multiple ways with varying grammars. An example of
semantic arguments in varying expressions is given in Appendix A.
PurPliance uses Semantic Role Labeling (SRL), also called shal-
low semantic parsing, to recover the latent predicate-argument struc-
tures of sentences. SRL models are trained on corpora called propo-
sition banks (PropBank) which contain labels of the semantic roles
of sentences. In the corpora, such as OntoNotes 5.0 [57], a specific
set of roles is specified for different senses of each verb. Some roles
are numbered rather than named to make them more general (e.g.,
Arg1 for object arguments) while many un-numbered modifier ar-
guments represent the modification or adjunct meanings [14]. The
definition of a role may vary with a verb’s senses. For example,
while Arg2 typically denotes the instrument of a predicate, Arg2 of
certain data usage verbs like use and store indicates their purposes.
3.1.2 Extraction of Purpose Clauses. We identified semantic argu-
ments that represent purposes based on their specifications in the