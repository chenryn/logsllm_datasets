terns and handle uncertainty in the correlation process. Sec-
ond, we apply statistical analysis to correlate attack steps
that have temporal and statistical patterns even though they
do not have obvious or direct relationship in terms of se-
curity and performance measures [24]. In particular, we ap-
ply Granger-Causality analysis [17] and some other time se-
ries analysis techniques to detect the “causal” relationship
between this type of alert pairs. This approach does not re-
quire the prior knowledge of attack scenario patterns in the
correlation process.
Alert correlation results in a set of correlated alerts that
comprise the attack scenarios. The alert processing de-
scribed earlier is usually conducted on aggregated raw alerts
and reﬂects localized or low-level attack scenarios, e.g., a
series of attacks against a department network. Low-level
alert correlation can leave some correlated alert sets that are
isolated from each other. Based on the attack scenarios re-
sulted from the prior alert aggregation, alert prioritization
and correlation, we further correlate isolated alert sets and
conduct high-level attack plan recognition and prediction,
which are the topics of this paper.
3
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:39:39 UTC from IEEE Xplore.  Restrictions apply. 
4. Models and Algorithms
In this section, we introduce our models and algorithms
for correlating isolated alert sets, attack plan recognition
and attack prediction.
4.1. Attack Tree Analysis
In security operations, security analysts usually pre-
deﬁne a set of attack plans or attack libraries that incorpo-
rate the domain knowledge of attacks or attack scenario pat-
terns, and the knowledge of the networks and systems under
protection. Attack plans or libraries are usually represented
by graphs (i.e., attack graphs) that show all paths through a
system that end in a state where an intruder can successfully
achieve his goal. Schneier [27] described attack tree anal-
ysis that quantiﬁes the security or vulnerability of a system
based on the goals of the attacker. When deﬁning the attack
trees, security analysts ﬁrst evaluate the vulnerabilities of
the systems and networks, then pretend to be attackers and
work out attack plans to achieve the intrusion goals. In this
process, an attack tree is extended and branches are built to
identify the different subgoals of the attacker and penetra-
tion points available to the attacker. The process continues
by decomposing or expanding the means of penetration to
the lowest level of intrusion, known as the leaves. An attack
tree can represent each opportunity for an attack against a
computer system or network. Computer systems and net-
works potentially contain numerous penetration points and
vulnerabilities. An attack forest is deﬁned as a consolida-
tion of numerous attack trees [27].
Figure 1(a) shows an example of an attack tree that in-
dicates attack methods to steal the data stored on a server
and export it to the external. In the Figure 1(a), the “OR”
node represents different ways to achieve the goals. In prac-
tice, in addition to the “OR” node, the “AND” node is also
always used in an attack tree to represent different steps to
achieve the intrusion goals.
Attack tree analysis can serve as a basis for intrusion de-
tection, defense, response and forensic analysis. However,
deﬁning attack trees is a very challenging task. It is usu-
ally done manually and is very time consuming. Recently,
Sheyner et. al [29] proposed a model checking-based tech-
nique to automatically construct attack graphs. Although it
helps facilitate the task of deﬁning attack graphs, the ap-
proach still has the limitation of scalability, in particular,
when deﬁning the attack graphs for a large network and
computer systems.
In our approach, we ﬁrst use attack trees to deﬁne attack
plan libraries to correlate isolated alert sets. We then convert
attack trees into causal networks on which we can assign
probability distribution by incorporating domain knowledge
to evaluate the likelihood of attack goals and predict future
attacks. Figure 1(b) shows an example of the causal net-
work converted from the attack tree as shown in Figure 1(a).
In deﬁning attack trees, instead of using various speciﬁc at-
tacks to deﬁne the nodes of an attack tree, we use the ab-
stract attack class or type to represent an attack approach.
For example, we use Exploit Server Vulnerability instead of
a speciﬁc buffer overﬂow attack to indicate the method to
break into a server to get the root access. The advantage of
using attack classes to represent attack tree nodes is that it
can reduce the computation complexity of probabilistic in-
ference on the causal network that is converted from attack
trees. It is well known that querying an arbitrary causal net-
work is an NP-hard problem [10]. Therefore, in practice,
a causal network is usually deﬁned in the form of causal
polytrees (i.e., singly-connected causal networks in which
no more than two paths exist between any two nodes) so
that the probabilistic reasoning can be conducted in polyno-
mial time [22].
4.2. The Causal Network and its Parameters
A causal network (or Bayesian network) is usually repre-
sented as a directed acyclic graph (DAG) where each node
represents a variable that has a certain set of states, and the
directed edges represent the causal or dependent relation-
ships among the variables. A Bayesian network consists of
several parameters, i.e., prior probability of parent node’s
states (i.e., P (parent state = i)), a set of conditional prob-
ability tables (CPT) associated with child nodes. CPT en-
codes the prior knowledge between child node and its parent
node. Speciﬁcally, an element of the CPT at a child node is
deﬁned by CP Tij = P (child state = j|parent state =
i).
In our study, we build the causal networks based on at-
tack trees and apply probabilistic inference. The root node
of a causal network represents the ﬁnal goal of an attack
plan, non-leaf nodes represent subgoals, and leaf nodes in-
dicate the nodes receiving evidence. We deﬁne each node of
the causal network to have a binary state, i.e., 1 or 0. The
value of 1 represents the goal is achieved for goal or sub-
goal nodes, while the value of 0 indicates the failure of the
goal or subgoals. When a leaf node has a state value of 1,
it indicates that the leaf node has received evidence. Other-
wise, the leaf node has a value of 0.
When converting attack trees to a causal network, we
can map “OR” nodes from an attack tree directly to the
causal network while keeping the “OR” logical relation-
ship. As “AND” nodes in an attack tree represent differ-
ent attack steps to reach a goal (“OR” nodes indicate dif-
ferent attack ways to achieve an attack goal), there always
exists an implicit dependent and sequential relationship be-
tween “AND” nodes in an attack tree. Therefore, we should
keep such “causal” order when constructing the causal net-
4
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:39:39 UTC from IEEE Xplore.  Restrictions apply. 
Steal_and_export_confidential_data
1. Get confidential data
1.1 Get data from Server directly (OR)
1.1.1 Get access to server
1.1.1.1 Get normal user privilege (OR)
1.1.1.1.1 Steal ID file and password file (OR)
1.1.1.1.2 Use Trojan program (OR)
1.1.1.1.3 Eavesdrop on the network
1.1.1.2 Get System Administrator’s (root) privilege
1.1.1.2.1 Exploit Server’s vulnerabilities
1.1.1.2.1.1 Identify Server’s OS and active ports (OR)
1.1.1.2.1.1.1 Inspect Server’s activeness
1.1.1.2.1.1.1.1 Identify Firewall access control policy
1.1.1.2.1.1.1.1.1 Identify Firewall IP address
1.1.1.2.2 Eavesdrop on the network (OR)
1.1.1.2.3 Brute force guess
1.2 Eavesdrop on the network
2. Export_confidential_data
2.1 Transfer data via normal method (OR)
2.2 Transfer data via covert channel 
2.2.1 Setup covert channel
Steal_and_export_confidential_data
Get_confidential_data
Export_confidential_data
Get_data_from_Server_directly
Transfer_data_via_normal_method
Transfer_data_via_covert_channel
Get_access_to_Server
Setup_covert_channel
Get_normal_user_privilege
Get_root_privilege
Steal_ID_and_password_file
Eavesdrop_on_the_network
Password_brute_force_guess
Exploit_system_vulnerabilities
Use_Torjan_program
Identify_Server_OS_and_active_ports
Inspect_Server_activeness
Identify_Firewall_access_policy
Identify_Firewall_IP_address
(a) An example of attack tree
(b) An example of causal network
Figure 1. Attack tree and causal network
work. For example, we can deﬁne an attack tree for getting
access to a server with the following attack steps which have
“AND” relationship, i.e., exploit vulnerability AND iden-
tify server OS AND identify Firewall access control policy
AND Identify Firewall IP address. In the causal network,
we can keep the implicit sequential order among the nodes,
i.e., identify IP address, identify ﬁrewall access control pol-
icy, identify server’s OS, exploit vulnerability in order of the
causal sequence.
When using a causal network (or Bayesian network) for
inference, we need to set up two types of parameters, i.e.,
prior probability of parent node’s states and CPT associated
with each child node.
The prior probability of parent node’s states (e.g.,
P (parent node state = 1)) used in the inference engine is
set based on the prior knowledge estimation of the possibil-
ity. We used domain-speciﬁc knowledge based on prior ex-
perience and empirical studies to estimate appropriate prob-
ability values. In particular, we computed the probability of
parent node’s states based on historical data.
In our approach, CPT values associated with each node
are adaptive to new evidence and therefore can be updated
accordingly. We apply an adaptive algorithm originally pro-
posed by [2]. The motivation of using an adaptive Bayesian
network is that we want to ﬁne-tune the parameters of the
model and adapt the model to the evidence to ﬁx the ini-
tial CPTs that may be pre-deﬁned inappropriately. The in-
tuition of the algorithms proposed by [2] is that we want
to adapt the new model by updating CPT parameters to ﬁt
the new data cases while balancing the extent that we move
away from the current model.
Speciﬁcally, we denote X as a node in a causal network,
and let U be the parent node of X. X can take values of
xk, where k = 1, ..., r and U has state values of uj, where
j = 1, ..., q. An entry of CPT of the node X can be de-
noted as: θjk = P (X = xk|U = uj). Given a set of new
data cases, denoted as D, D = y1, ..., yn, and assuming
there is no missing data in evidence vector of yt, where evi-
dence vector yt represents the evidence at the tth time, CPT
updating rules can be simpliﬁed to the following [8]:
jk = η + (1 − η)θt−1
θt
jk , f or P (uj|yt) = 1
and P (xk|yt) = 1.
jk = (1 − η)θt−1
θt
jk , f or P (uj|yt) = 1
and P (xk|yt) = 0.
jk = θt−1
θt
jk , otherwise.
(1)
(2)
(3)
The above updating rules are interpreted as follows.
Given the evidence vector yt, if the parent node of X is ob-
served in their jth conﬁguration, i.e., U = uj, and X equals
to its kth value, then we regard the evidence as support-
ing evidence and we then increase the corresponding CPT
value P (X = xk|U = uj), i.e., θjk, as shown in Eq. (1). If
5
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:39:39 UTC from IEEE Xplore.  Restrictions apply. 
node X does not equal its kth value but its parent node U
is in the jth conﬁguration, then we regard the evidence as
non-supporting evidence and then decrease the correspond-
ing CPT value, i.e., θjk, as shown in Eq. (2). The learning
rate η controls the rate of convergence of θ. η equaling 1
yields the fastest convergence, but also yields a larger vari-
ance. When η is smaller, the convergence is slower but even-
tually yields a solution to the true CPT parameter [8]. We
built our inference model based on updating rules of Eq. (1)
to Eq. (3).
We also need to point out that the adaptive capabil-
ity of the inference model does not mean that we can ig-
nore the accuracy of initial CPT values. If the initial val-
ues are set with a large variance to an appropriate value, it
will take time for the model to converge the CPT values to
the appropriate points. Therefore, this mechanism works for
ﬁne-tuning instead of changing CPT values dramatically. In
practice, the initial CPT values can be computed and esti-
mated using historical data.
4.3. Correlating Isolated Alert Sets
As discussed in Section 3, after processing raw alerts
with alert aggregation, prioritization and correlation, we can
reduce the large volume of raw alerts and correlate some of
related alerts into different sets (or scenarios). However, it is
possible that there exist some isolated correlated alert sets
after the raw alert correlation due to various reasons. For
example, for pattern-matching-based correlation approach,
if the security sensors fail to detect some intermediate at-
tacks in a series of coordinated attacks, the missing alerts
can result in the un-match between observed alert sequences
with known attack sequence patterns. The result is a set
of isolated attack scenarios that belong to the same attack
sequences. In addition, applying different correlation ap-
proaches together can also result in different correlation re-
sults due to the difference between correlation techniques.
In such a case, it is also necessary to integrate correlation
results output by different correlation engines and further