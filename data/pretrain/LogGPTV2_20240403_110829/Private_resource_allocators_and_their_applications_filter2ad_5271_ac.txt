The probability of at least one success is therefore:
i=1
which is non-negligible.
k(cid:88)
(cid:0)|P|
(cid:1)(cid:0)|Q|
(cid:1)
(cid:1) ≥ 1/βP
(cid:0)βP
k−i
i
k
RRA achieves privacy, liveness, and a utilization (Def. 4) of
|P|/βP when k ≤ |P|, which is a factor of βM/βP improvement
over SRA. However, it still requires a bound on the number of
concurrent processes (P). In the context of an MPM system, this
requirement essentially asks the user to pick a bound (e.g., βP =
20), and assume that the adversary will not compromise more
than, say, 18 of their friends, while simultaneously receiving
fewer than 3 calls from honest friends. Otherwise, the adversary
could simply flood the user with malicious calls and infer, via
an allocation-based side channel, that the user is talking to at
least one honest friend (§II). Although one could come up with
values of βP that are large enough to hold in practice (e.g.,
users in social media have on average hundreds of friends [79],
so βP = 100 might suffice), this only works in applications
where the adversary cannot commandeer an arbitrary number
of processes via a sybil attack [30]. In such cases, there might
not be a useful bound (e.g., βP = 280 certainly holds in practice,
but results in essentially 0 utilization).
The above limitation is fundamental and follows from our
impossibility result. In the next section, however, we show
that if one can tolerate a weaker privacy guarantee, there exist
allocators that require only a poly(λ) bound, βhon, on |Phon|.
The number of malicious processes (|Pmal|), and therefore the
number of total concurrent processes (|P|), can be unbounded.
C. Differentially private resource allocator
In this section we relax the privacy guarantees of PRAs and
require only that the leakage be at most inverse polynomial in
λ, rather than negligible. We define this guarantee in terms of
(ε, δ)-differential privacy [31].
Definition 5 (Differential privacy). An allocator RA is (ϵ, δ)-
differentially private [31] if in the security game of Section III,
given parameter λ, for all algorithms A and for all Umal:
Pr[C(b) returns Umal] ≤ eε · Pr[C(¯b) returns Umal] + δ
where Umal is the set of processes returned from C to A in
Step 6 of the security game, and C(b) means an instance of C
where the random bit is b; similarly for C(¯b) where ¯b = 1 − b.
The probability is over the random coins of C and RA.
We show that if there is a poly(λ) bound, βhon, for the
number of honest processes (|Phon|), then there is an RA
that achieves (ε, δ)-differential privacy and Liveness (Def. 3).
Before introducing our construction, we discuss a subtle
property of allocators that we have ignored thus far: symmetry.
Definition 6 (Symmetry). An allocator is symmetric if it does
not take into account the features, identities, or ordering of
processes when allocating resources. This is an adaptation of
symmetry in games [21, 35], in which the payoff of a player
depends only on the strategy it uses, and not on the player’s
identity. Concretely, given an ordered set of processes P where
the only difference between processes is their position in P, RA
is symmetric if Pr[RA(P, k, λ) = p] = Pr[RA(π(P), k, λ) = p],
for all p and all permutations π. This argument extends to
other identifying features (process id, permissions, time that a
process is created, how many times a process has retried, etc.).
6
For example, the (non-private) uniform allocator of Sec-
tion III-B and the private RRA (§IV-B) are symmetric: they
allocate resources without inspecting processes. On the other
hand, the (non-private) FIFO allocator of Section III-B and
the private SRA (§IV-A) are not symmetric; FIFO takes into
account the ordering of processes, and SRA requires computing
the function slot on each process. While symmetry places some
limits on what an allocator can do, in Section V-A we show
that many features (e.g., heterogeneous demands, priorities)
can still be implemented.
Construction. Recall from Section III that RA receives one of
two requests from C depending on the bit b that C samples. The
request is either Pmal or Pmal ∪ Phon. We can think of these sets
as two neighboring databases. Our concern is that the processes
in Pmal that are allocated the resource might convey too much
information about which of these two databases was given to
RA, and in turn reveal b. To characterize this leakage, we derive
the sensitivity of an RA that allocates resources uniformly.
Our key observation is that if RA is symmetric, then the only
useful information that the adversary gets is the number of
processes in Pmal that are allocated (i.e., |Umal|); the allocation
is independent of the particular processes in Pmal. If RA adds
no dummy processes and allocates resources uniformly, then
|Umal| = min(|Pmal|, k|Pmal|
|Pmal| ) when b = 0 and, in expectation,
k|Pmal|
min(|Pmal|,
|Pmal|+|Phon| ) when b = 1. By observing |Umal|,
the adversary learns the denominator in these fractions; the
sensitivity of this denominator—and of RA—is |Phon| ≤ βhon.
To limit the leakage, we design an allocator that samples
noise from an appropriate distribution and adds dummies based
on the sampled noise. We discuss the Laplace distribution here,
but other distributions (e.g., Poisson) would also work. The
Laplace distribution (Lap) with location parameter µ and scale
parameter s has the probability density function:
(cid:18)−|x − µ|
(cid:19)
s
Lap(x|µ, s) =
1
2s
exp
Let g(λ) and h(λ) be polynomial functions of the allocator’s
security parameter λ. These functions will control the tradeoff
between privacy and utilization: ε = 1/g(λ) bounds how much
information leaks (a larger value of g(λ) leads to better privacy
but worse utilization), and the ratio h(λ)/g(λ) (which impacts
δ) determines how often the bound holds (a larger ratio provides
a stronger guarantee, but leads to worse utilization). Given these
two functions, the allocator works as follows.
(ε, δ)-differentially private resource allocator DPRA:
• Inputs: P, k, λ
• µ ← βhon · h(λ)
• s ← βhon · g(λ)
• n ← ⌈max(0, Lap(µ, s))⌉
• t ← |P| + n
• Q ← set of dummy processes of size n
• π ← random permutation of P ∪ Q
• U ← first min(t, k) processes in π
• Output: U ∩ P
7
g(λ) and δ = 1
2 exp( 1−h(λ)
g(λ) ) if |Phon| ≤ βhon.
In short, the allocator receives a number of requests that is
either |Pmal| or |Pmal∪Phon|. It samples noise n from the Laplace
distribution, computes the noisy total number of processes
t = |P| + n, and allocates min(t, k) uniformly at random.
Lemma 6. DPRA is (ε, δ)-differentially private (Def. 5) for
ε = 1
Proof strategy. The proof that DPRA is differentially private
uses some of the ideas from the proof for the Laplace
mechanism by Dwork et al. [31]. A learns the total number
of processes in Pmal that are allocated, call it tmal. We show
that when the noise (n) is sufficiently large, for all ℓ ∈ [0, k],
Pr[tmal = ℓ|b = 0] is within a factor eε of Pr[tmal = ℓ|b = 1].
We then show that the noise fails to be sufficiently large with
probability ≤ δ. We give the full proof in Appendix C.
Corollary 7. If |Phon| ≤ βhon, the leakage or privacy loss that
results from observing the output of DPRA is bounded by
1/g(λ) with probability at least 1 − δ [32, Lemma 3.17].
In some cases, an adversary might interact with an allocator
multiple times, adapting Pmal in an attempt to learn more
information. We can reason about the leakage after i interactions
through differential privacy’s adaptive composition [33].
Lemma 8. DPRA is (ε′, iδ + δ′)-differentially private over i
interactions for δ′ > 0 and ε′ = ε(cid:112)2i ln(1/δ′) + iε(eε − 1).
Proof. The proof follows from [33, Theorem III.3]. An optimal,
albeit more complex, bound also exists [44, Theorem 3.3].
Lemma 9. DPRA provides liveness (Def. 3) if |Phon| ≤ βhon.
Proof. The expected value of Lap is βhon · h(λ) ≤ poly2(λ).
As a result, the number of dummy processes added by DPRA
is polynomial on average; at least one process in P is allocated
a resource with inverse polynomial probability.
DPRA is efficient in expectation since with high probability,
n does not exceed a small multiple of βhon·h(λ) (Lemma 9). To
bound DPRA’s worst-case time and space complexity, we can
truncate the Laplace distribution and bound n by exp(λ) without
much additional leakage. However, even if |P| ∈ poly(λ), the
noise (n), and thus the total number of processes (t) can all
be exp(λ). This would require DPRA to have access to exp(λ)
random bits to sample the dummy processes and to perform
the permutation; the running time and space complexity would
also be exponential. Fortunately, the generation of dummy
processes, the set union, and the permutation can all be avoided
(we introduced them only for simplicity). DPRA can compute
U directly from P, k, and t as follows.
U ← ∅
for i = 0 to min(t, k) − 1 do
1: function RANDOMALLOCATION(P, k, t)
2:
3:
4:
5:
6:
7:
8:
r ←R [0, 1]
if r < |P|/(t − i) then
return U
p ← Sample uniformly from P without replacement
U = U ∪ {p}
Finally, sampling m elements from P without replace-
ment is equivalent to generating the first m elements of a
random permutation of P on the fly, which can be done
with O(m log|P|) random bits in O(m log|P|) time and O(m)
space [18]. The same optimization (avoiding dummy processes
and permutations) applies to RRA (§IV-B) as well.
utility only if it receives all of its demand), or divisible (i.e., the
process derives positive utility even if it receives a fraction of
its demand). We describe two potential modifications to PRAs
that handle the divisible demands case and achieve different
notions of fairness; we leave a construction of PRAs for the
indivisible demands case to future work.
V. EXTENSIONS AND OTHER ALLOCATOR PROPERTIES
In addition to privacy and liveness, we ask whether PRAs
satisfy other properties that are often considered in resource
allocation settings. We study a few of them, listed below:
• Resource monotonicity If the capacity of the allocator
increases, the probability of any of the requesting processes
to receive service should not decrease.
• Population monotonicity When a process stops requesting
service, the probability of any of the remaining processes
to receive service should not decrease.
• Envy-freeness. A process should not prefer the allocation
probability of another process. This is our working definition
of fairness, though the notion of preference is quite subtle,
as we explain later.
• Strategy-proofness. A process should not benefit by lying
about how many units of a resource it needs.
Before stating which allocators meet which properties, we
first describe a few generalizations to PRAs.
A. Weighted allocators
Our resource allocators are egalitarian and select which
processes to allocate uniformly from all requesting processes.
However, they can be extended to prioritize some processes
over others with the use of weights. Briefly, each process is
associated with a weight, and allocation is done in proportion
that weight: a request from a process with half of the weight
of a different process is picked up half as often. To implement
weighted allocators, the poly(λ) bound on the number of
process (e.g., βP in RRA) now represents the bound on the sum
of weights across all concurrent processes (normalized by the
lowest weight of any of the processes), rather than the number
of processes; padding is done by adding dummy processes
until the normalized sum of their weights adds to the bound.
All of our privacy and liveness arguments carry over
straightforwardly to this setting. The only caveat
is that
processes can infer their own assigned weight over time; just
like the bounds, none of our allocators can keep this information
private. However, processes cannot infer the weight of other
processes beyond the trivial upper bound (i.e., the sum of the
weights of any potential set of concurrent processes is βP).
B. Non-binary demands
Thus far we have considered only allocators for processes
that demand a single unit of a resource. A natural extension
is to consider non-binary demands. For example, a client of a
cloud service might request 5 machines to run a task. These
demands could be indivisible (i.e., the process derives positive
Probability in proportion to demands. In the non-binary
setting, the input to the allocator is no longer just the set
of processes P, but also their corresponding demands D. A
desirable notion of fairness might be to allocate resources in
proportion to processes’ demands. For example, if process p1
demands 100 units, and p2 demands 2 units, an allocation of 50
units to p1 and 1 unit to p2 may be fair. Our PRAs can achieve
this type of fairness for integral units by treating each process
as a set of processes of binary demand (the cardinality of each
set is given by the corresponding non-binary demand). The
bounds are therefore based on the sum of processes’ demands
rather than the number of processes.
Probability independent of demands. Another possibility is
to allocate each unit of a resource to processes independently
of how many units they demand. For example, if p1 demands
100 units and p2 demands 1 unit, both processes are equally
likely to receive the first unit of the resource. If p2 does not
receive the first unit, both processes have an equal chance to
get the second unit, etc.
To achieve this definition with PRAs, we propose to change
the way that RRA and DPRA sample processes (i.e., Line 6 of
the RANDOMALLOCATION function given in Section IV-C).
Instead of sampling processes uniformly without replacement
and giving the chosen processes all of their demanded resources,
the allocator samples processes from P uniformly with infinite
replacement, and gives each sampled process one unit of the
resource on every iteration. The allocator then assigns to each
process pi the number of units sampled for pi at the end of the
algorithm or pi’s demand, whichever is lower. This mechanism
preserves the privacy of the allocation since it is equivalent to
hypothetically running a PRA with a resource of capacity 1
and the same set of binary-demand processes k times in a row.
A property of this definition is that the bounds on the number
of processes—βP in RRA (§IV-B) and βhon in DPRA (§IV-C)—
remain the same as in the binary-demand case (i.e., independent
of processes’ demands) since the allocator does not expose
the results of the intermediate k hypothetical runs. However,
the allocator assumes that processes have infinite demand
(and discards excess allocations at the end), which ensures
privacy but leads to worse utilization (based on the imbalance
of demands). A potentially less wasteful alternative is to do
the sampling with a bounded number of replacements (i.e., a
sampled process is not replaced if its demand has been met),
but we have not yet analyzed this case since it requires stateful
reasoning (it is a Markov process); to our knowledge sampling
with bounded replacement has not been previously studied.
8
C. Additional properties met by PRAs
All of our PRAs meet the first three properties listed earlier,
and SRA and RRA also meet strategy-proofness; our proofs are
in Appendix D, but we highlight the most interesting results.
We observe that privacy is intimately related to population
monotonicity. This is most evident in DPRA, since its dif-
ferential privacy definition states that changes in the set of