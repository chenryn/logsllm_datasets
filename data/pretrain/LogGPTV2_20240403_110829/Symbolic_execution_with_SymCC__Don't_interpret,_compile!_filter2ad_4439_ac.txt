we opted for the simpler implementation of on-demand allo-
cation.
4.3 Symbolic backend
We provide two different symbolic backends: Our own back-
end is a thin wrapper around Z3. It is bundled as a shared ob-
ject and linked into the instrumented target program. The com-
piler pass inserts calls to the backend, which then constructs
the required Z3 expressions and queries the SMT solver in
order to generate new program inputs.
However, since the backend is mostly independent from
the execution component and only communicates with it via
a simple interface, we can replace it without affecting the
execution component, our main contribution. We demonstrate
this ﬂexibility by integrating the QSYM backend, which can
optionally be used instead of our simple Z3 wrapper: We
compile a shared library from the portion of QSYM that han-
dles symbolic expressions, link it to our target program and
translate calls from the instrumented program into calls to the
QSYM code. The interface of our wrapper around the QSYM
code consists of a set of functions for expression creation (e.g.,
SymExpr _sym_build_add(SymExpr a, SymExpr b)), as
well as helper functions to communicate call context and path
constraints; adding a path constraint triggers the generation
of new inputs via Z3. Effectively, this means that we can
combine all the sophisticated expression handling from the
QSYM backend, including dependency tracking between ex-
pressions and back-off strategies for hot code paths [45], with
our own fast execution component.
4.4 Concreteness checks
In Section 3.4, we highlighted the importance of concreteness
checks: for good performance, we need to restrict symbolic
reasoning (i.e., the involvement of the symbolic backend) to
cases where it is necessary. In other words, when all operands
of a computation are concrete, we should avoid any call to
the symbolic backend. In our implementation, symbolic ex-
pressions are represented as pointers at run time, and the
expressions for concrete values are null pointers. Therefore,
checking the concreteness of a given expression during execu-
tion is a simple null-pointer check. Before each computation
in the bitcode, we insert a conditional jump that skips sym-
bolic handling altogether if all operands are concrete; if at
least one operand is symbolic, we create the symbolic ex-
pressions for the other operands as needed and call out to
the symbolic backend. Obviously, when the compiler can in-
fer that a value is a compile-time constant and thus never
symbolic at run time, we just omit the generation of code for
symbolic handling.
By accelerating concrete computations during symbolic
execution, we alleviate a common shortcoming of conven-
tional implementations. Typically, only a few computations
in a target program are symbolic, whereas the vast majority
of operations involve only concrete values. When symbolic
execution introduces a lot of overhead even for concrete com-
USENIX Association
29th USENIX Security Symposium    187
putations (as is the case with current implementations despite
their concreteness checks), the overall program execution is
slowed down considerably. Our approach, in contrast, allows
us to perform concrete computations at almost the same speed
as in uninstrumented programs, signiﬁcantly speeding up the
analysis. Section 5 shows measurements to support this claim.
Interacting with the environment
4.5
Most programs interact with their environment, e.g., by work-
ing with ﬁles, or communicating with the user or other pro-
cesses. Any implementation of symbolic execution needs
to either deﬁne a boundary between the analyzed program
and the (concrete) realm of the operating system, or execute
even the operating system symbolically (which is possible
in S2E [9]). QSYM [45], for example, sets the boundary at
the system call interface—any data crossing this boundary is
made concrete.
In principle, our approach does not dictate where to stop
symbolic handling, as long as all code can be compiled with
our custom compiler.3 However, for reasons of practicality
SYMCC does not assume that all code is available. Instead,
instrumented code can call into any uninstrumented code
at run time; the results will simply be treated as concrete
values. This enables us to degrade gracefully in the presence
of binary-only libraries or inline assembly, and it gives users
a very intuitive way to deliberately exclude portions of the
target from analysis—they just need to compile those parts
with a regular compiler. Additionally, we implement a special
strategy for the C standard library: we deﬁne wrappers around
some important functions (e.g., memset and memcpy) that
implement symbolic handling where necessary, so users of
SYMCC do not need to compile a symbolic version of libc. It
would be possible to compile the standard library (or relevant
portions of it) with our compiler and thus move the boundary
to the system call interface, similarly to KLEE and QSYM;
while this is an interesting technical challenge, it is orthogonal
to the approach we present in this paper.
4.6 Supporting additional source languages
Since SYMCC uses the compiler to instrument target pro-
grams, it is in principle applicable to programs written in any
compiled programming language. Our implementation builds
on top of the LLVM framework, which makes it particularly
easy to add support for programming languages with LLVM-
based compilers, such as C++ [40], Rust [41] and Go [15]. We
have implemented C++ support in SYMCC, and we use it as
an example for describing the generalized process of adding
support for a new source language. The procedure consists of
two steps, which we discuss in more detail below: loading our
LLVM pass into the compiler and compiling the language’s
run-time library.
3Our current implementation is restricted to user-space software.
4.6.1 Loading the pass
Any LLVM-based compiler eventually generates bitcode
and passes it to the LLVM backend for optimization and
code generation. In order to integrate SYMCC, we need
to instruct the compiler to load our compiler pass into the
LLVM backend. In the case of clang++, the LLVM project’s
C++ compiler, loading additional passes is possible via the
options -Xclang -load -Xclang /path/to/pass. There-
fore, a simple wrapper script around the compiler is all that is
needed. Note that the ability to load SYMCC’s compiler pass
is the only requirement for a basic analysis; however, without
instrumentation of the run-time library (detailed below), the
analysis loses track of symbolic expressions whenever data
passes through a function provided by the library.
4.6.2 Compiling the run-time library
Most programming languages provide a run-time library; it
often abstracts away the interaction with the operating system,
which typically requires calling C functions, and offers high-
level functionality. The result of compiling it with SYMCC
is an instrumented version of the library that allows SYMCC
to trace computations through library functions. In particular,
it allows the analysis to mark user input read via the source
language’s idiomatic mechanism as symbolic, an essential
requirement for concolic execution. C++ programs, for exam-
ple, typically use std::cin to read input; this object, deﬁned
by the C++ standard library, may rely on the C function getc
internally, but we need an instrumented version of std::cin
in order to trace the symbolic expressions returned by getc
through the run-time library and into user code.
For C++ support in SYMCC, we chose libc++ [26], the
LLVM project’s implementation of the C++ standard library.
It has the advantages that it is easy to build and that it does
not conﬂict with libstdc++, the GNU implementation of the
library installed on most Linux distributions. Compiling it
with SYMCC is a matter of setting the CC and CXX environ-
ment variables to point to SYMCC before invoking the regular
build scripts.
With those two steps—loading the compiler pass and com-
piling the run-time library—we can provide full support for
a new source language.4 As a result, SYMCC ships with a
script that can be used as a drop-in replacement for clang++
in the compilation of C++ code.
5 Evaluation
In this section we evaluate SYMCC. We ﬁrst analyze our
system’s performance on synthetic benchmarks (Section 5.1),
4Occasionally, front-ends for new languages may emit bitcode instruc-
tions that SYMCC cannot yet handle. In the case of C++, we had to add
support for a few instructions that arise in the context of exception handling
(invoke, landingpad, resume, and insertvalue).
188    29th USENIX Security Symposium
USENIX Association
allowing for precisely controlled experiments. Then we evalu-
ate our prototype on real-world software (Section 5.2), demon-
strating that the advantages we ﬁnd in the benchmarks trans-
late to beneﬁts in ﬁnding bugs in the real world. The raw data
for all ﬁgures is available at http://www.s3.eurecom.fr/
tools/symbolic_execution/symcc.html.
5.1 Benchmarks
For our benchmarks we use the setup that we proposed in
earlier work [32]: at its core, it uses a set of test programs
that was published in the course of the DARPA Cyber Grand
Challenge (CGC), along with inputs that trigger interesting
behavior in each application (called proofs of vulnerability or
PoVs). The same set of programs has been used by Yun et al.
in the evaluation of QSYM [45], so we know that QSYM is
capable of analyzing them, which enables a fair comparison.
We applied the necessary patches for KLEE in order to enable
it to analyze the benchmark programs as well.5 Note that we
excluded ﬁve programs because they require inter-process
communication between multiple components, making them
hard to ﬁt into our controlled execution environment, and one
more, NRFIN_00007, because it contains a bug that makes it
behave differently when compiled with different compilers
(see Appendix B).
A major advantage of the CGC programs over other pos-
sible test sets is that they eliminate unfairness which may
otherwise arise from the different instrumentation boundaries
in the systems under comparison (see Section 4.5): In contrast
with KLEE and QSYM, SYMCC does not currently execute
the C standard library symbolically. It would therefore gain
an unfair speed advantage in any comparison involving libc.
The CGC programs, however, use a custom “standard library”
which we compile symbolically with SYMCC, thus eliminat-
ing the bias.6
We ran the benchmark experiments on a computer with an
Intel Core i7-8550U CPU and 32 GB of RAM, using a timeout
of 30 minutes per individual execution. We use SYMCC with
the QSYM backend, which allows us to combine our novel
execution mechanism with the advanced symbolic backend
by Yun et al.
5.1.1 Comparison with other state-of-the-art systems
We begin our evaluation by comparing SYMCC with existing
symbolic execution engines on the benchmark suite described
above, performing three different experiments:
5http://www.s3.eurecom.fr/tools/symbolic_execution/ir_
study.html
6The Linux port of the custom library still relies on libc in its implemen-
tation, but it only uses library functions that are thin wrappers around system
calls without added logic, such as read, write and mmap. KLEE and QSYM
concretize at the system-call interface, so the instrumentation boundary is
effectively the same as for SYMCC.
1. We compare pure execution time, i.e., running the target
programs inside the symbolic execution tools but without
any symbolic data.
2. We analyze execution time with symbolic inputs.
3. We compare the coverage of test cases generated during
concolic execution.
The targets of our comparison are KLEE [5] and
QSYM [45]. We decided for KLEE because, like SYMCC,
it works on LLVM bitcode generated from source code; an
important difference, however, is that KLEE interprets the bit-
code while SYMCC compiles the bitcode together with code
for symbolic processing. Comparing with KLEE therefore
allows us to assess the value of compilation in the context
of symbolic execution. The decision for QSYM is largely
motivated by its fast execution component. Its authors demon-
strated considerable beneﬁts over other implementations, and
our own work provides additional evidence for the notion that
QSYM’s execution component achieves high performance in
comparison with several state-of-the-art systems [32]. More-
over, our reuse of QSYM’s symbolic backend in SYMCC
allows for a fair comparison of the two systems’ execution
components (i.e., their frontends). QSYM’s approach to sym-
bolic execution requires a relatively complex implementation
because the system must handle the entire x86 instruction
set—we demonstrate that SYMCC achieves comparable or
better performance with a much simpler implementation (and
the additional beneﬁt of architecture independence, at the cost
of requiring source code or at least LLVM bitcode).
In order to save on the already signiﬁcant use of compu-
tational resources required for our evaluation, we explicitly
excluded two other well-known symbolic execution systems:
S2E [9] and Driller [39]. S2E, being based on KLEE, is very
similar to KLEE in the aspects that matter for our evaluation,
and preliminary experiments did not yield interesting insights.
Driller is based on angr [37], whose symbolic execution com-
ponent is implemented in Python. While this gives it distinct
advantages for scripting and interactive use, it also makes
execution relatively slow [32, 45]. We therefore did not con-
sider it an interesting target for a performance evaluation of
symbolic execution.
Pure execution time We executed KLEE, QSYM and
SYMCC on the CGC programs, providing the PoVs as input.
For the measurement of pure execution time, we did not mark
any data as symbolic, therefore observing purely concrete
execution inside the symbolic execution engines. In many
real-world scenarios, only a fraction of the data in the tested
program is symbolic, so efﬁcient handling of non-symbolic
(i.e., concrete) computations is a requirement for fast symbolic
execution [45]. Figure 5 shows the results: SYMCC executes
most programs in under one second (and is therefore almost as
USENIX Association
29th USENIX Security Symposium    189
)
s
(
e
m
T
i
100
10
1
0.1
Native
SymCC
QSYM
KLEE
)
s
(
e
m
T
i
10000
1000
100
10
1
0.1
SymCC
QSYM
KLEE
Figure 5: Time spent on pure execution of the benchmark
programs, i.e., without symbolic data. Note the logarithmic
scale of the time axis. “Native” is the regular execution time of
the uninstrumented programs. On average, SYMCC is faster
than QSYM by 28× and faster than KLEE by 30× (KLEE
can execute only 56 out of 116 programs).
Figure 6: Time spent on concolic execution of the bench-
mark programs, i.e., with symbolic inputs (logarithmic scale).
SYMCC is faster than QSYM by an average factor of 10×
and faster than KLEE by 12× (KLEE can execute only 56
out of 116 programs).
fast as native execution of uninstrumented programs), while
QSYM and KLEE need seconds up to minutes.
Execution time with symbolic inputs Next, we performed
concolic execution on the CGC programs, again using the
PoVs as input. This time, we marked the input data as sym-