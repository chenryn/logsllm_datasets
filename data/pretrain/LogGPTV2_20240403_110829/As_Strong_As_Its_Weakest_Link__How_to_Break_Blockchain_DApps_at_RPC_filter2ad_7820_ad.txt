the other two exhaustXXs and can ﬁnish before Ethereum’s
default 5-second timeout.
E. Measurement Results: Gas & Rate Limits
We measure the Gas limits of the backend peers by using
program rpc_gasLimit in Figure A.15. Here, we assume
that different nodes in the same RPC service have the same
Gas limit. The results are illustrated in Table 5 which shows
that four out of nine services conﬁgure the Gas limit: Ser-
viceX3/ServiceX6/ServiceX9/ServiceX8 respectively set Gas
limit at 50/10/5/1.5 block gas.5 The services without Gas limits
are particularly vulnerable to our DoERS attacks.
In our extended study, we also measure the rate limits de-
ployed in many services’ frontend. The rate limits are intended
to protect the service against distributed DoS. However, rate
limiting without real-world identities can be easily bypassed
by a Sybil attacker who registers multiple service accounts and
accumulates much higher rate limits. Yet, requiring the DApp
clients (e.g., a web browser surﬁng a DApp page) to expose
real-world identities is impractical. We thus don’t consider
rate limiting as an effective protection against DoERS. One
can essentially bypass all RPC services’ rate limit by using as
many API keys or IPs as needed. Nevertheless, we measured
rate limits and observe the measured limits are commonly
inconsistent with the published rate limits on their website.
The measurement result is deferred to Appendix B.
F. Attack Strategies Evading Gas Limit
For the RPC node without Gas limit, we design a single-
request DoERS attack that has the power of evading all
other protective measures we will observe in the next section
(including rate limiting and load balancing). The attack sends a
single request with a very large payload size (e.g., 109) to run
the exhaustMem function in the DoERS-C smart contract.
The key observation here is this: exhaustMem runs a single
EVM instruction, namely CODECOPY,
to allocate a large
memory. Running a single EVM instruction is atomic and is
5Through our responsible disclosure, after our study, ServiceX5 has set
a limit of 10 block gas.
not interrupted, even when there is a timeout. Thus, the DoERS
attacker can increase the payload size of an exhaustMem
invocation to evade the 5-second timeout, causing a higher
resource consumption and more sever service damage, as will
be evaluated in § V-B.
For the RPC node with Gas limit, the attacker can send
multiple DoERS requests, each with a medium payload size
under the Gas limit. If the requests are sent at a sufﬁciently
high rate, there will be visible service interference, as will be
evaluated in § V-A and § V-B.
G. Summary of Attack Strategies
We summarize what an actual DoERS attacker can do, with
respect to different real-world situations. We consider the goal
of the attacker is to cause maximal damage to the DApp
ecosystem, while minimizing her cost.
C1) For nodes or services without Gas limit, the DoERS
strategy is to send a single request invoking exhaustMem
with a big-number payload size (e.g., 264). If this crashes the
EVM on the victim node, the attacker waits for 30 seconds
and pings the node before sending the request again. This
strategy also applies to any services without Gas limits — the
single-request attack evades the protection of a load balancer.
C2) For nodes with Gas limit, the DoERS strategy is to
set the payload size of an individual request under the Gas
limit and to send multiple such requests at a certain rate. In
the case of a very low Gas limit, the attacker can tune up the
request rate; because there is innate asymmetry between the
service and the DoERS attacker, the attacker can expect to
cause signiﬁcant damage to an individual node at low cost (as
will be evaluated in § V). This strategy applies to public RPC
peers and Type-i services without load balancers.
C3) For Type-iii services with Gas limit, there can be
two DoERS strategies. One (C3a) is to follow the C2 strategy
and to increase the rate as necessary to DoS all backend peers
in the service. Given the small service scale (tens of peers),
the DoERS asymmetry still helps keep attacker’s cost low (see
§ VI-A1 for an analysis). The other strategy (C3b) is to predict
load-balancing behaviors and design speciﬁc attacks, as will
be demonstrated in ServiceX6.
C4) For Type-ii services with Gas limit, the DoERS
strategy is to mount targeted attacks. As described in § IV-C,
the target can be a speciﬁc DApp client, a DApp, or a web3
library. The targeted attacks can evade the deterministic load-
balancing behaviors in Type-ii services.
V. EVALUATION OF DOERS ATTACKS
In this section, we evaluate the effectiveness and cost of
DoERS attacks. The attack effectiveness will be measured
by service performance degradation in latency increase, block
synchronization slowdown, and others. The attack cost will be
measured by the attack rate. Note that an DoERS attack costs
zero Ether by design as described in § VI-A2. Speciﬁcally, the
evaluation aims to answer the following questions:
• Are real-world RPC services and peers exploitable under
DoERS attacks? How much increase in response time will
9
be caused by DoERS with “minimal” payload and rate
(i.e., without causing any exception) on the real services?
§ V-A answers these questions.
• On a local Ethereum node, how much damage can
DoERS cause with payload and rate large enough to
trigger and bypass exceptions? The damage is measured
not only in response-time increase, but also in block
synchronization slowdown, mining rate slowdown, etc.
§ V-B answers these questions.
A. Evaluation on Deployed Services
1) Ethics-Driven Evaluation: Methodology: The goal is to
verify whether a deployed RPC service is exploitable under
DoERS attack. The main challenge comes from designing an
effective test on the target services, without attacking them —
The intensity of the test needs to be high enough to cause
observable effects while it should be low enough to minimize
actual performance degradation. The key idea here lies in
discovering what we call the “minimally effective” parameters
of the DoERS test. A DoERS test is minimally effective if
1) the difference between the response time of regular RPC
requests under the test and that without the test is statistically
signiﬁcant, and 2) the response time of regular RPCs increase
with the payload size and request rate.
More concretely, in the evaluation, we set up a virtual-
machine (VM) instance in Google Cloud Platform (GCP) [24]
for probing (a probing node) and another VM instance in
Amazon EC2 [1] for measurement (a measurement node).
With this setup, the two nodes do not share anything on their
paths to a RPC service, and hence minimize performance
interference between probing and measurement. During an
experiment, we warm up the measurement node (in its network
connection) by sending out three regular RPC requests (e.g.,
eth_getBlockNumber) to the target service. Then the
measurement node sends out regular RPC requests at a rate
of one request every two seconds. The response time of these
regular RPCs is recorded. From the 30-th second after the
measurement node starts, we launch the probing node which
sends DoERS requests with minimally effective parameters.
The probing node lasts for ta seconds and the measurement
node continues for another 60 seconds after that.
In order to discover the minimally effective DoERS pa-
rameters, we did a series of carefully designed pre-tests in
a local machine: We set up the local Ethereum node and
conduct local tests to ﬁnd the DoERS parameters such that
the response time with and without the test differ by 5×
times. During the pre-tests, we vary the attack parameters
in payload size, probe rate and contract
type. Note that
5× will be an estimate as the hardware spec on the local
node is different that on deployed services. The local pre-
tests produce several sets of candidate DoERS parameters,
each set is a triplet (cid:104)type, p, rx(cid:105) where type/p/rx is contract
type/payload size/attack rate. For instance, (cid:104)CPU, 20M, 10(cid:105)
means a DoERS attack exploit exhaustCPU function with
payload size being 20M 6 and attack rate being 10 requests
per second. In particular, rx = 0 means that a single DoERS
request is sent out in the entire test process. Based on the above
design, on each test, we would send a total of 60∗2/2+3 = 63
regular RPC requests plus at most ta ∗ rx DoERS requests.
We set the attack duration ta such that the number of DoERS
requests can be upper-bounded before the test.
Besides, we avoid directly using large attack parameters
(e.g., attack rates, payload sizes), which would have resulted
in severe damages to the service. Instead, we test each service
with a sequence of smaller and gradually increasing param-
eters, with the intention to discover the “trend” or how the
server response time grows with increasing parameters. Such
a trend allows to predict service response time under large
parameters without causing the actual damage (see Figure 8b).
With such measures, we expect each of our tests to affect no
more than three nodes (out of hundreds) on the backend of
each service for a short period of several minutes, to minimize
the impact on its normal operations.
2) Evaluation Results: We follow the above methodology
and test all nine services. Note that both measurement and
probing VM instances do not run Geth, but
instead run
Curl [9] to send RPC requests. We ﬁrst describe the experiment
with ServiceX2 as an example. We run a series of tests
described above with different minimally-effective parameters.
Each test produces a timeline of RPC response times. For
instance, Figure 8a reports such a timeline on ServiceX2 under
DoERS attacks exploiting exhaustCPU with 30, 000 payload
and at the rate of 30 requests per second. The result shows a
moderate 5× slowdown under the speciﬁc attack setting.
it
From there, we vary attack rate with payload size ﬁxed at
0.07M (vary payload sizes with attack rate ﬁxed at 18 per
second). In each test, we deﬁne the attack-effective period by
the period that the response time increases by at least 1.2×
than the response time without attacks. Then we calculate
the average response time during the attack-effective phase
and report
in Figure 8b. The result clearly shows that
the response time grows with increasing payload size and
attack rates. For ethical reasons, we stop our test at maximal
payload size 0.15M or maximal rate 30 per second, resulting
in maximal response time at about 100 milliseconds. Also, our
experiments observe no timeout or other exceptions thrown.
The trend revealed in the ﬁgure implies that an actual attacker
can use larger parameters than ours to cause a much longer
RPC delay towards crashing the service.
DoERS attacks to Type-iii services: We conduct exper-
iments on ServiceX6 as an example Type-iii service. In the
experiment, DoERS requests are sent to exhaustCPU with
payload size 1.5M at the rate of 200 requests per second. The
1.5M payload size makes the per-request Gas right below the
Gas limit of ServiceX6 service. The attack lasts for 20 seconds,
and we observe a protective measure taken by ServiceX6–
15 seconds after the attack starts, the DoERS requests are
returned with null. The timeline of measured response time is
6We use M and K to denote a million and a thousand, respectively.
10
illustrated in Figure 8d. The RPC response time increases from
40 milliseconds before the attack to 160 milliseconds after the
attack, leading to a 5× increase. We suspect two causes: First,
ServiceX6’s load balancing depends on the timing of requests:
all DoERS requests sent within one minutes are collocated to
the same three RPC nodes. Second, there are hundreds of peers
on the backend of ServiceX6 and all peers are saturated by
the DoERS attacks.
Targeted attacks to Type-ii services: Among Type-ii
services, ServiceX5 is a representative service whose load
balancer distinguishes requests based on IPs; recall Table 5.
We conduct two tests that differ only by where the DoERS
requests are sent. The speciﬁc result is in Figure 9a: If the
DoERS requests are sent from a different IP from where the
measurement requests are sent (as in our original setup), no
increase of response time can be spotted. However, if we send
the DoERS requests from the same IP with the measurement
requests, the response time clearly increases right after the
attack starts at the 5th second in Figure 9a. To eliminate the
possibility of performance interference between probing and
measuring, we conducted an extra test by sending DoERS
requests at the same rate but with a much small payload size
(e.g., 3 iterations in a loop) and no response-time increase
can be observed. The result corroborates our measured load-
balancing behavior and directly shows that the adaptive attack
strategy (recall § IV-C) is effective on ServiceX5. Note that in
Figure 9a, the attack sends only a single request exploiting
exhaustMem with 20M payload size. The 10X increase
of response time is caused by this single DoERS request.
We also conduct similar experiments on the other Type-ii
service, ServiceX4, where DoERS requests are sent with the
same/different API key with the measurement requests. The
result, presented in Figure 9b, similarly show the effectiveness
of our attack strategies – under the DoERS with the same
API key, a 6× slowdown (from 0.4 seconds to 2.4 seconds)
is caused while under the DoERS of the same API key, there
is no visible service slowdown.
Single-request memory DoERS: For RPC services with no
gas limits, the DoERS attacker can send a single RPC request
to execute the exhaustMem that bypasses any load balanc-
ing. On ServiceX2, we send a single request with parameters
eth_call(exhaustMem(5 ∗ 107)), and we report
the
response times in Figure 10a. After the attack starts at the 5th
second, the response time grows up by 20× (from 0.1 seconds
to 2 seconds). On ServiceX5, we similarly a single request
with parameters eth_call(exhaustMem(1∗109)). From
Figure 10b, the response time is increased by 150× (from 0.2
seconds to 30 seconds).
Summary of attack parameters: Table I summarizes the
effective attack parameters we found on these services. It can
be seen that most existing services, with or without Gas limits,
can be successfully attacked, causing an observable response-
time increase by at least 3.8×. On ServiceX2, for instance, the
parameters to cause 3.8× increase are (cid:104)CPU, 0.15M, 30(cid:105); note
that payload size 0.15M amounts to 0.2 block gas. Currently
ServiceX2 does not set Gas limits; but our result implies that
(a) ServiceX2 (i) (cid:104)CPU, 30K, 30(cid:105)
(b) ServiceX2 (i) w. varying rates &
payloads
(c)
(cid:104)CPU, 0.6M, 200(cid:105)
ServiceX8
(iii)
(d) ServiceX6 (iii) (cid:104)CPU, 1.5M, 200(cid:105)
Fig. 8: exhaustCPU attacks to RPC services (Type-i and iii)
10 block gas), causing 5× response-time increase. We notice
that the minimally effective payload sizes differ from different
services and this can be caused by different hardware specs
of the machines run in these services.
B. Evaluation on a Local Full Node
(a) ServiceX5 (cid:104)Mem, 50M, 0(cid:105)
(b) ServiceX4 (cid:104)CPU, 40k, 30(cid:105)
Fig. 9: Targeted attacks to RPC services (Type-ii)
(a) Block sync. slowdown under
exhaustCPU
(b) exhaustMem and timeout
Fig. 11: Evaluate DoERS attacks on a local node
In order to evaluate the damage caused by DoERS more
extensively, we conduct experiments on a local machine under
our control. The machine is a blade server with a 32-core
2.60GHz Intel(R) Xeon(R) CPU (E5-2640 v3), 256 GB RAM
and 4 TB SSD disk. We set up a Geth v1.99 client on the
server and fully synchronize it with the Ethereum mainnet.
We turn on the RPC on this full node with default settings.
The probing node and measurement node are run on the same
commodity computer as before (§ V-A2).
The ﬁrst experiment evaluates the DoERS’s impact on
the block synchronization rate on the victim. In the exper-
iments, we measure the local victim node’s current block
height, denoted by Bv. To do so,
the measurement node
sends eth_getBlockNumber RPCs to the victim. We also
monitor the block height of a regular mainnet node by Br and
record the initial block height before the attack by B0. From
there, we report a metric that we call block synchronization
slowdown: Br(10)−Bv(10)
where Br(10)/Bv(10) is the block
Br(10)−B0
height 10 minutes after the attack starts. In the experiment,
we vary the payload size and the attack rate, and report the
slowdown in Figure 11a.
The result shows that block synchronization slowdown
reaches as high as 96% with attach parameter (cid:104)CPU, 1M, 100(cid:105).
When the payload size is 0.1M which amounts to a Gas limit
(a) ServiceX2 (cid:104)Mem, 50M, 0(cid:105)
(b) ServiceX5 (cid:104)Mem, 1000M, 0(cid:105)
Fig. 10: A single-request attack exploiting exhaustMem to
nodes without gas limits
TABLE I: Minimally effective attack parameters: Gas* in the number of
block gas. In parenthesis are Gas limits.