blocks.
While both tools can achieve high accuracy, still, only
DEEPBINDIFF is able to correctly match the vulnerability
patch. More speciﬁcally, we expect difﬁng tools to identify the
patch as a new insertion, while still matching the original basic
blocks, for the vulnerability analysis. Depicted in Figure 11a,
BinDiff mismatches the vulnerable basic block with the new
condition check basic block, rendering the real matching basic
block unmatched (shown as white block). For DEEPBINDIFF,
it successfully matches the basic blocks and identiﬁes the new
condition check as an insertion. This case study shows that
DEEPBINDIFF can identify inserted basic blocks accurately,
with the help of its design choices and Algorithm 1.
VIII. DISCUSSION
A. Compiler optimizations
Different compiler optimization techniques are one of the
is
major reasons for code transformation. For example,
it
pop     rdxpop     rcxmov     esi, dword ptr [rsp+1D8h+var_1D8]mov     dword ptr [r13+60h], 0mov     r8, rbxmov     rcx, rbpmov     edx, r12dmov     rdi, r13call    dtls1_get_message_fragmentjmp     loc_40E34mov     rax, [r13+50h]mov     rax, [rax+8]add     rax, 0Chmov     [r13+58h], raxmovsxd  rax, dword ptr [r13+60h]jmp     loc_40FA1pop     rdxpop     rcxmov     esi, dword ptr [rsp+1D8h+var_1D8]mov     dword ptr [r13+60h], 0mov     r8, rbxmov     rcx, rbpmov     edx, r12dmov     rdi, r13call    dtls1_get_message_fragmentjmp     loc_40E34pop     r8pop     r9mov     rax, [r13+88h]mov     dword ptr [r13+60h], 0jmp     loc_4103Fcmp     qword ptr [rdi+1F8h], 454Chmov     eax, 454Chmov     r12, rdicmovnb  rax, [rdi+1F8h]cmp     rbp, raxjbe     short loc_3FFF0mov     rdx, [rdi+98h]mov     r12, rdicmp     qword ptr [rdx+198h], 0jz      short loc_3FEA8mov     rdx, [rdi+98h]cmp     qword ptr [rdx+198h], 0jz      short loc_40018cmp     qword ptr [rdi+1F8h], 454Chmov     eax, 454Chmov     r12, rdicmovnb  rax, [rdi+1F8h]cmp     rbp, raxjbe     short loc_3FFF0mov     rdx, [rdi+98h]mov     r12, rdicmp     qword ptr [rdx+198h], 0jz      short loc_3FEA8mov     rdx, [rdi+98h]cmp     qword ptr [rdx+198h], 0jz      short loc_40018TABLE VI: Compiler Optimizations
Optimizations
instruction scheduling
instruction replacement
block reordering
function inlining
register allocation
DEEPBINDIFF Design
1) choose not to use sequential info as a part of context
for each instruction
2) exclude instruction sequence during block feature
vector generation
1) NLP technique is used to distill semantic information
1) treat the merged ICFG as an undirected graph
1) generate random walks across function boundaries
2) avoid function level matching
3) k-Hop greedy matching is done on top of ICFG
rather than CFG
1) register name normalization
reported that about 10% functions with GCC O2 optimization
have been transformed by function inlining technique [21].
DEEPBINDIFF is designed to handle common optimization
techniques as so to achieve high matching accuracy.
As shown in Table VI, the design of DEEPBINDIFF takes
care of multiple most common compiler optimization tech-
niques [15]. We deliberately choose to exclude some easy-to-
break assumptions such as the order of instructions and blocks,
CFG directions, function boundaries.
Particularly, when training the block feature vector gener-
ation model, instruction sequential information is not part of
context information. By considering ICFG as an undirected
graph, our system will not be affected by block reordering as
long as the two blocks are still k-hop neighbors. For function
inlining, DEEPBINDIFF generates random walks based on
ICFG, meaning control dependency information is extracted
regardless of function boundary changes. Also, we choose not
to perform function level matching as in BinDiff to avoid being
affected by function boundary changes. Finally, k-Hop greedy
matching is based on ICFG other than CFG, therefore, block
matching is not affected.
B. Limitations
Besides all the advantages, DEEPBINDIFF still has a few
limitations. First, in practice, certain blocks are often merged
by the compiler to reduce branch mispredictions. Hence, the
numbers of blocks for the two binaries can be changed. In this
case, DEEPBINDIFF could mistakenly categorize some blocks
as insertions or deletions since our system performs one-to-
one block matching. We argue that our tool can still match the
merged blocks to their most similar counterparts. Therefore, if
a block is semantic-rich (i.e., contains multiple instructions),
it will still be matched correctly to the merged block, leaving
only the less meaningful block unmatched.
Second, optimizations that drastically change the control
ﬂow could thwart the effectiveness of DEEPBINDIFF. This is
due to the fact that our analysis heavily relies on ICFG to
extract graph structural information in order to differentiate
semantically similar blocks, big change of control ﬂow can
signiﬁcantly affect the results. Consequently, DEEPBINDIFF
is vulnerable to obfuscation techniques that completely alter
the CFG. Packing techniques [51], [24] that encrypt the code
can also defeat our system. But please note that no existing
learning-based techniques can do a better job since they all
rely on control ﬂow information.
Third, DEEPBINDIFF currently has no support for cross-
architecture difﬁng, which has become quite popular, espe-
cially in IoT related security research [29], [27], [19]. Poten-
tially, DEEPBINDIFF could solve this issue by lifting binaries
into IR ﬁrst and then perform difﬁng in the same way. We
leave this as a furture work.
IX. RELATED WORK
A. Code Similarity Detection
Static Approaches. Static approaches usually transform bi-
nary code into graphs and then perform the comparison.
Bindiff [10], [25] performs many-to-many graph isomorphism
detection on callgraph to match functions and leverages CFG
matching for basic blocks. Binslayer [12] further augments
the graph matching with the Hungarian algorithm to improve
the matching results. Pewny et.al. [49] searches bugs by
collecting input/output pairs to capture the semantics of a
basic block and perform graph matching. To improve runtime
performance, discovRE [27] uses lightweight syntax features
and applies pre-ﬁltering before matching. However, the pre-
ﬁltering may signiﬁcantly affect the accuracy [29]. To avoid
heavy graph matching, Tracelet [20] converts CFGs into a
number of paths with ﬁxed-length called tracelets and then
matches them via rewriting. Esh [17] decomposes the func-
tions into data-ﬂow dependent segments named strands and
uses statistical reasoning to calculate similarities. GitZ [18]
ﬁnds strands equality through re-optimization. BinGo [14]
performs selective function inlining and extracts partial traces
for function similarity detection. These techniques can only
decompose within functions to abstain from massive number
of fragments. BinHunt [30] uses static symbolic execution
and theorem proving to extract semantics. CoP [40] also uses
symbolic execution to compute the semantic similarity of
blocks and leverages the longest common sub-sequence of
linearly independent paths to measure the similarity.
Dynamic Approaches. Blanket Execution [26] executes func-
tions of the two input binaries with the same inputs and
compares monitored behaviors for similarity. iBinHunt [43]
extends the comparison to inter-procedural CFGs and reduces
the number of candidates of basic block matching by mon-
itoring the execution under a common input. BinSim [44],
which is speciﬁcally proposed to compare binaries with code
obfuscation techniques, relies on system calls to perform
dynamic slicing and then check the equivalence with symbolic
execution. Essentially, dynamic analysis based approaches
by nature suffer from poor scalability and incomplete code
coverage problem.
Learning based Approaches. Genius [29] forms attributed
CFGs and calculates the similarity via graph embeddings gen-
erated through comparing with a set of representative graphs
named codebook. Gemini [54] improves Genius by leveraging
neural network to generate function embeddings and trains
a Siamese network for similarity detection. αDiff [39] uses
a similar Siamese network with CNN to generate function
embeddings. This eliminates the need of manually-crafted
features. InnerEye [58] utilizes NLP techniques and LSTM-
RNN to automatically encode the information of basic blocks.
Asm2Vec [23] adopts an unsupervised learning approach by
generating token and function embeddings using PV-DM
model. However, it only works on function comparison. Also,
14
it does not consider any program-wide CFG structural infor-
mation during analysis. SAFE [41] leverages a self-attentive
neural network to generate function embeddings.
B. Graph Embedding Learning
HOPE [47] preserves higher-order proximity and uses gen-
eralized Singular Value Decomposition to improve efﬁciency.
TADW [56] is the ﬁrst work that considers feature vectors for
nodes during matrix factorization. REGAL [32] also performs
factorization with node features. However, it only checks the
existence of features without considering the numeric values.
DeepWalk [48] is proposed to learn latent representations
of nodes in a graph using local information from truncated
uniform random walks. node2vec [31] speciﬁcally designs
a biased random walk procedure that efﬁciently explores
diverse neighborhoods of a node to learn continuous feature
representations of nodes.
DNGR [13] proposes a graph representation model based
on deep neural networks that captures the graph structure
information directly. SDNE [52] designs a semi-supervised
model
that has multiple layers of non-linear functions to
capture both the local and global graph structures. GCN [33]
uses a localized ﬁrst-order approximation of spectral graph
convolutions to perform semi-supervised learning on graphs in
a scalable way. Structure2Vec [16] is proposed for structured
data representation via learning features spaces that embeds
latent variable models.
X. CONCLUSION
In this paper, we propose a novel unsupervised learning
based program-wide code representation learning technique
to perform binary difﬁng. To precisely match the blocks
within given binaries, we leverage NLP techniques to gen-
erate token embeddings which are further used to generate
block feature vectors containing semantic information. We then
generate inter-procedural CFGs (ICFGs), extract the program-
wide structural
information from the ICFGs using TADW
algorithm and generate basic block level embeddings. Finally,
we propose a k-hop greedy matching algorithm to ﬁnd op-
timal matching for the blocks. We implement a prototype
named DEEPBINDIFF and evaluate it against 113 binaries from
Coreutils, Diffutils and Findutils, 10 C++ binaries, and 2 real-
world vulnerabilities in OpenSSL under the scenarios of cross-
version and cross-optimization-level difﬁng. The results show
that our system could outperform state-of-the-art techniques
by a large margin.
ACKNOWLEDGEMENT
We would like to thank the anonymous reviewers for
their helpful and constructive comments. This work was sup-
ported in part by National Science Foundation under grant
No. 1719175, DARPA under grant FA8750-16-C-0044, and
Ofﬁce of Naval Research under Award No. N00014-17-1-2893.
Any opinions, ﬁndings, and conclusions or recommendations
expressed in this paper are those of the authors and do not
necessarily reﬂect the views of the funding agencies.
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
“difﬁng-with-kam1n0,”
difﬁng-with-kam1n0/, 2019.
“GNU Coretuils,” https://www.gnu.org/software/coreutils/, 2019.
“GNU Difftuils,” https://www.gnu.org/software/diffutils/, 2019.
“GNU Findutils,” https://www.gnu.org/software/ﬁndutils/, 2019.
“IDA Disassembler and debugger,” https://www.hex-rays.com/products/
ida/, 2019.
“indicators,” https://github.com/p-ranav/indicators/, 2019.
“InnerEye,” https://nmt4binaries.github.io//, 2019.
“LSHBOX,”
2019.
“OpenSSL,” https://www.openssl.org/, 2019.
“zynamics BinDiff,” https://www.zynamics.com/bindiff.html, 2019.
[9]
[10]
[11] T. Avgerinos, S. K. Cha, B. L. T. Hao, and D. Brumley, “Aeg: Automatic
https://github.com/RSIA-LIESMARS-WHU/LSHBOX/,
REFERENCES
https://www.whitehatters.academy/
exploit generation,” 2011.
[12] M. Bourquin, A. King, and E. Robbins, “Binslayer: accurate comparison
of binary executables,” in Proceedings of the 2nd ACM SIGPLAN
Program Protection and Reverse Engineering Workshop. ACM, 2013,
p. 4.
[13] S. Cao, W. Lu, and Q. Xu, “Deep neural networks for learning graph
representations.” in AAAI, 2016, pp. 1145–1152.
[14] M. Chandramohan, Y. Xue, Z. Xu, Y. Liu, C. Y. Cho, and H. B. K. Tan,
“Bingo: Cross-architecture cross-os binary search,” in Proceedings of
the 2016 24th ACM SIGSOFT International Symposium on Foundations
of Software Engineering. ACM, 2016, pp. 678–689.
[15] K. Cooper and L. Torczon, Engineering a compiler. Elsevier, 2011.
[16] H. Dai, B. Dai, and L. Song, “Discriminative embeddings of latent
variable models for structured data,” in International Conference on
Machine Learning, 2016, pp. 2702–2711.
[17] Y. David, N. Partush, and E. Yahav, “Statistical similarity of binaries,”
ACM SIGPLAN Notices, vol. 51, no. 6, pp. 266–280, 2016.
[18] ——, “Similarity of binaries through re-optimization,” in ACM SIG-
PLAN Notices, vol. 52, no. 6. ACM, 2017, pp. 79–94.
[19] ——, “Firmup: Precise static detection of common vulnerabilities in
ﬁrmware,” in ACM SIGPLAN Notices, vol. 53, no. 2. ACM, 2018, pp.
392–404.
[20] Y. David and E. Yahav, “Tracelet-based code search in executables,”
Acm Sigplan Notices, vol. 49, no. 6, pp. 349–360, 2014.
[21] F. De Go¨er, S. Rawat, D. Andriesse, H. Bos, and R. Groz, “Now you
see me: Real-time dynamic function call detection,” in Proceedings of
the 34th Annual Computer Security Applications Conference. ACM,
2018, pp. 618–628.
[22] T. Dietterich, “Overﬁtting and undercomputing in machine learning,”
ACM computing surveys, vol. 27, no. 3, pp. 326–327, 1995.
[23] S. H. Ding, B. C. Fung, and P. Charland, “Asm2vec: Boosting static
representation robustness for binary clone search against code obfus-
cation and compiler optimization,” in Security and Privacy (SP), 2019
IEEE Symposium on.
IEEE, 2019.
[24] Y. Duan, M. Zhang, A. V. Bhaskar, H. Yin, X. Pan, T. Li, X. Wang,
and X. Wang, “Things you may not know about android (un) packers:
A systematic study based on whole-system emulation.” in NDSS, 2018.
[25] T. Dullein and R. Rolles, “Graph-based comparison of executable ob-
jects,” in Proceedings of the Symposium sur la Securite des Technologies
de Linformation et des communications, 2005.
[26] M. Egele, M. Woo, P. Chapman, and D. Brumley, “Blanket execution:
Dynamic similarity testing for program binaries and components,” in
23rd USENIX Security Symposium (USENIX Security).
USENIX
Association, 2014.
[27] S. Eschweiler, K. Yakdan, and E. Gerhards-Padilla, “discovre: Efﬁcient
cross-architecture identiﬁcation of bugs in binary code.” in NDSS, 2016.
[28] M. R. Farhadi, B. C. Fung, P. Charland, and M. Debbabi, “Binclone:
Detecting code clones in malware,” in Software Security and Reliability
(SERE), 2014 Eighth International Conference on.
IEEE, 2014, pp.
78–87.
15
architecture bug search in binary executables,” in Security and Privacy
(SP), 2015 IEEE Symposium on.
IEEE, 2015, pp. 709–724.
[50] K. Sparck Jones, “A statistical interpretation of term speciﬁcity and its
application in retrieval,” Journal of documentation, vol. 28, no. 1, pp.
11–21, 1972.
[51] X. Ugarte-Pedrero, D. Balzarotti, I. Santos, and P. G. Bringas, “Sok:
Deep packer inspection: A longitudinal study of the complexity of
run-time packers,” in 2015 IEEE Symposium on Security and Privacy.
IEEE, 2015, pp. 659–673.
[52] D. Wang, P. Cui, and W. Zhu, “Structural deep network embedding,”
in Proceedings of the 22nd ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2016, pp. 1225–1234.
[53] S. Wang and D. Wu, “In-memory fuzzing for binary code similarity
analysis,” in Proceedings of the 32nd IEEE/ACM International Con-
ference on Automated Software Engineering.
IEEE Press, 2017, pp.
319–330.
[54] X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and D. Song, “Neural
network-based graph embedding for cross-platform binary code similar-
ity detection,” in Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2017, pp. 363–376.
[55] Z. Xu, B. Chen, M. Chandramohan, Y. Liu, and F. Song, “Spain:
security patch analysis for binaries towards understanding the pain and
pills,” in Proceedings of the 39th International Conference on Software
Engineering.
IEEE Press, 2017, pp. 462–472.
[56] C. Yang, Z. Liu, D. Zhao, M. Sun, and E. Y. Chang, “Network
representation learning with rich text information.” in IJCAI, 2015, pp.
2111–2117.
[57] H.-F. Yu, C.-J. Hsieh, S. Si, and I. S. Dhillon, “Parallel matrix
factorization for recommender systems,” Knowledge and Information
Systems, vol. 41, no. 3, pp. 793–819, 2014.
[58] F. Zuo, X. Li, Z. Zhang, P. Young, L. Luo, and Q. Zeng, “Neural
machine translation inspired binary code similarity comparison beyond
function pairs,” in NDSS, 2019.
[29] Q. Feng, R. Zhou, C. Xu, Y. Cheng, B. Testa, and H. Yin, “Scalable
graph-based bug search for ﬁrmware images,” in Proceedings of the
2016 ACM SIGSAC Conference on Computer and Communications
Security. ACM, 2016, pp. 480–491.
[30] D. Gao, M. K. Reiter, and D. Song, “Binhunt: Automatically ﬁnding
semantic differences in binary programs,” in International Conference
on Information and Communications Security.
Springer, 2008, pp.
238–255.
[31] A. Grover and J. Leskovec, “node2vec: Scalable feature learning for
networks,” in Proceedings of the 22nd ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM, 2016,
pp. 855–864.
[32] M. Heimann, H. Shen, T. Safavi, and D. Koutra, “Regal: Representation
learning-based graph alignment,” in Proceedings of
the 27th ACM
International Conference on Information and Knowledge Management.
ACM, 2018, pp. 117–126.
[33] T. N. Kipf and M. Welling, “Semi-supervised classiﬁcation with graph
convolutional networks,” arXiv preprint arXiv:1609.02907, 2016.
[34] Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for
recommender systems,” Computer, no. 8, pp. 30–37, 2009.
[35] H. W. Kuhn, “The hungarian method for the assignment problem,”
Naval Research Logistics (NRL), vol. 2, no. 1-2, pp. 83–97, 1955.
[36] N. Lageman, E. D. Kilmer, R. J. Walls, and P. D. McDaniel, “Bindnn:
Resilient function matching using deep learning,” in International Con-
ference on Security and Privacy in Communication Systems. Springer,
2016, pp. 517–537.
[37] Q. Le and T. Mikolov, “Distributed representations of sentences and
documents,” in International Conference on Machine Learning, 2014,
pp. 1188–1196.
[38] Y. Li, W. Xu, Y. Tang, X. Mi, and B. Wang, “Semhunt: Identifying
vulnerability type with double validation in binary code.” in SEKE,
2017, pp. 491–494.
[39] B. Liu, W. Huo, C. Zhang, W. Li, F. Li, A. Piao, and W. Zou, “αdiff:
cross-version binary code similarity detection with dnn,” in Proceedings
of the 33rd ACM/IEEE International Conference on Automated Software
Engineering. ACM, 2018, pp. 667–678.
[40] L. Luo, J. Ming, D. Wu, P. Liu, and S. Zhu, “Semantics-based
obfuscation-resilient binary code similarity comparison with applica-
tions to software plagiarism detection,” in Proceedings of the 22nd
ACM SIGSOFT International Symposium on Foundations of Software
Engineering. ACM, 2014, pp. 389–400.
[41] L. Massarelli, G. A. Di Luna, F. Petroni, R. Baldoni, and L. Querzoni,
“Safe: Self-attentive function embeddings for binary similarity,” in
International Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment. Springer, 2019, pp. 309–329.
[43]
[42] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their composi-
tionality,” in Advances in neural information processing systems, 2013,
pp. 3111–3119.
J. Ming, M. Pan, and D. Gao, “ibinhunt: Binary hunting with inter-
procedural control ﬂow,” in International Conference on Information
Security and Cryptology. Springer, 2012, pp. 92–109.
J. Ming, D. Xu, Y. Jiang, and D. Wu, “Binsim: Trace-based semantic
binary difﬁng via system call sliced segment equivalence checking,” in
Proceedings of the 26th USENIX Security Symposium, 2017.
J. Ming, D. Xu, and D. Wu, “Memoized semantics-based binary difﬁng
with application to malware lineage inference,” in IFIP International
Information Security Conference. Springer, 2015, pp. 416–430.
[44]
[45]
[46] E. W. Myers, “Ano (nd) difference algorithm and its variations,”
Algorithmica, vol. 1, no. 1-4, pp. 251–266, 1986.
[47] M. Ou, P. Cui, J. Pei, Z. Zhang, and W. Zhu, “Asymmetric transi-
tivity preserving graph embedding,” in Proceedings of the 22nd ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2016, pp. 1105–1114.
[48] B. Perozzi, R. Al-Rfou, and S. Skiena, “Deepwalk: Online learning
of social representations,” in Proceedings of the 20th ACM SIGKDD
international conference on Knowledge discovery and data mining.
ACM, 2014, pp. 701–710.
J. Pewny, B. Garmany, R. Gawlik, C. Rossow, and T. Holz, “Cross-
[49]
16