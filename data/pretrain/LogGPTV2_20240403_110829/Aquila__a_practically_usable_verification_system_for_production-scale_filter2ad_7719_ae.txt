to be used elsewhere so the header order is not carefully designed
to align with the order in the packet. The engineer failed to realize
this issue and unsurprisingly, the returned packet is wrong.
Scenario 3: Checking bugs before updates. Due to our business
diversity, the network engineers are frequently required to update
data plane programs to meet the service needs. However, the pro-
gram update is one of the major root causes of significant service
disruptions; thus, we use Aquila to verify our updates. For the up-
date scenarios, we typically use the original specification, because
we want to ensure the entire program behaves the same before and
after updates.
In an important update event, we needed to exchange the pipelines
of load balancer and switch, which means we move switch.p4 to
Pipeline 1 and loadbalancer.p4 to Pipeline 0 in Figure 2, respec-
tively. This update requirement comes from the following reason.
The load balancer pipeline contains packet processing functions
that involve virtual network encapsulation/decapsulation, such as
network address translation (or NAT). They may change the for-
warding source or destination address of a packet, which the switch
pipeline relies on. For example, NAT translates the destination ad-
dress from a public IP to an internal IP, which the switch pipeline
uses to forward the packet to the correct server. Thus, our engineers
were required to place loadbalancer.p4 in front of switch.p4; oth-
erwise, intricate metadata has to be used to make sure the switch
forwarding behavior is correct.
Such an update task required us to modify many parts of P4
programs, such as the input packet format of load balancer program,
and adding recirculation to switch. It is prone to causing functional
inconsistency before and after the update. Aquila detected a critical
bug. We have two tables, an ACL table 𝑎, which accepts IP address
10.0.1/24 but drops IP address 20.0.1/24, and a forwarding table 𝑏
which changes the IP address in a packet header from 10.0.1/24 to
20.0.1/24.2 Before the update, a packet sent to IP address 10.0.1/24
can be successfully transferred into a packet with destination IP
20.0.1/24 due to table 𝑏; however, this update moved 𝑏 in front of 𝑎,
so that 𝑏 first changes the packet’s IP from 10.0.1/24 to 20.0.1/24,
and then the packet is dropped by table 𝑎’s ACL rules. Once such an
update is committed online, all traffic destinating 10.0.1/24 would
be blocked. It is hard to manually detect such a bug due to complex
logic across pipelines.
2The IP addresses have been anonymized for confidentiality reasons.
7.2 Self Validation Experience
The majority of bugs in Aquila were detected in the early stage of
Aquila development. The self-validator helped us identify tens of
Aquila implementation bugs in total, which were caused by reasons
such as language misunderstanding, incorrect function implemen-
tation, and chip-specific feature misunderstanding. We also met
bugs in the alternative representation implementation. Because
Aquila’s verification results do not contain any false positive in
recent months, we believe the self validator successfully assisted
us to tune the correctness of Aquila implementation. We pick two
bug examples to explain below.
Language misunderstanding. The developers of Aquila may mis-
understand or ignore some features of P4 language, implicitly in-
jecting bugs in Aquila. For example, P4 allows using annotation
@defaultonly to restrict an action. The initial version of Aquila ig-
nored this feature, which caused a correct program to violate its
specification.
Function implemented incorrectly. Function-level implemen-
tation bugs accounted for the majority of Aquila’s bugs. Some of
the functional bugs were tricky to be found. For example, in our
initial attempt, our encoding module failed to well handle empty
states, implicitly returning headers that are already extracted. In
other words, this bug treated an empty state as the ‘accept’ state,
causing the parser encoding to accept more packets than its actual
code. The self validator revealed this subtle inequivalence in the
parser, which is very unlikely if we rely on human code review.
8 PERFORMANCE EVALUATION
All of our experiments were conducted in a container with 32GB
RAM and one 2.5GHz CPU core, with Z3 4.8.5 installed as an SMT
solver. We used the end-to-end verification time to evaluate our
performance, which includes the parsing, encoding and verification
process.
8.1 Benchmark
We chose twelve P4 programs, 8 open-sourced and 4 private ones,
to compare the performance of Aquila with Vera and p4v. We asked
them to check the invalid header access bugs because it is a good
benchmarking property [30]. The chosen programs had at least one
such bug. We recorded the time to find the first bug (by checking all
assertions together) and all bugs (by checking each assertion one
by one) and set 2 hours as the timeout threshold. Note that in all
experiments, we make no assumption about the table entries, regis-
ters and input packet. Also in [30], p4v only recorded the execution
time of finding the first bug in the Switch BMv2 program with
INT module disabled, we modified our own p4v implementation to
find all bugs. As shown in Table 3, Aquila could report bugs within
one second for small programs, and within one minute for large
programs. Even for the largest program, Aquila only needed 4.8
Gigabytes of memory. As a comparison, Vera took a significantly
longer time to verify the small programs, and p4v run out of mem-
ory for large programs due to lack of scalable encoding approaches.
We also observed a higher memory footprint when finding the
first bug, because Aquila encoded all the assertions at once and
maintained more states.
Table 3: Comparing verification time and memory consumption (OOT - Out of Time, OOM - Out of Memory).
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Program
Simple Router
NetPaxos Acceptor [8]
NetPaxos Coordinator
NDP [22]
Flowlet Switching
NetCache [26]
Switch BMv2 w/o INT
Switch BMv2
LoC
131
185
148
224
237
538
5036
5599
5453
> 6000
> 6000
> 2000
1
1
1
1
1
1
1
1
2
4
4
6
3
5
5
4
4
17
59
64
30
41
47
114
Pipes
Parser
States
Tables
Time (s) (Finding first/all bugs)
Vera
p4v
4
4
2
7
6
96
104
120
141
> 150
> 150
> 120
Aquila
0.01 / 0.02
0.01 / 0.09
0.01 / 0.03
0.01 / 0.04
0.01 / 0.04
0.17 / 9.56
1.26 / 290
1.41 / 347
20.1 / 1286
23.7 / 558
25.2 / 733
41.3 / 3574
0.42 / 0.45
9.71 / 9.71
4.44 / 6.70
0.50 / 0.51
2.75 / 2.94
0.90 / 241
13.5 / OOT
226 / OOT
0.01 / 0.02
0.01 / 0.17
0.01 / 0.06
0.01 / 0.06
0.02 / 0.06
0.22 / 16.1
197 / OOT
OOM / OOM
OOM / OOM Error / Error1
OOM / OOM Error / Error
OOM / OOM Error / Error
OOM / OOM Error / Error
p4v
Memory(GB) (Finding first/all bugs)
Aquila
0.1 / 0.2
0.1 / 0.2
0.1 / 0.2
0.1 / 0.2
0.1 / 0.2
0.1 / 0.4
0.4 / 0.7
0.5 / 0.8
2.5 / 1.6
2.5 / 2.6
2.9 / 2.6
4.8 / 2.7
Vera
0.1 / 0.2
0.1 / 0.1
0.1 / 0.2
0.2 / 0.3
0.1 / 0.2
0.3 / 0.8
0.1 / 0.2
0.1 / 0.1
0.1 / 0.2
0.3 / 0.3
0.1 / 0.5
0.1 / 5.4
10.5 / OOT
2.5 / OOT
OOM / OOM
12.7 / OOT
OOM / OOM Error / Error
OOM / OOM Error / Error
OOM / OOM Error / Error
OOM / OOM Error / Error
Switch from vendor
Production Program 1
Production Program 2
Production Program 3
2 Vera [1, 2] only supports P414 while the programs are written in P416. Even if it supports P416, we infer it would be OOT from Switch BMv2 results.
Table 4: Bug localization time and precision.
Scale
Large
Medium
Small
Wrong Entry
Time (s)
Prec.
100%
100%
100%
Code Missing
Time (s)
Prec.
96.0%
95.7%
94.8%
164
83.2
68.6
31.2
21.2
17.1
Code Error
Time (s)
3.01
2.92
1.47
Prec.
100%
100%
100%
(a) Program complexity
(b) Table entries.
Figure 11: Scalability evaluation.
We used two Switch BMv2 programs, one with the INT module
enable and one without. The INT module contains a complex parser
module and the additional complexity caused p4v to run out of
memory. Vera had a similar pattern that the added INT module
increases the verification time by 16× and memory by 5×. On the
contrary, due to the sequential encoding, this additional complexity
only adds 10% overhead in time and 25% in memory to Aquila. While
Vera cannot verify our production programs, since it only supports
P414, we infer it would be OOT according to Switch BMv2’s result,
whose P416 version is a part of our production programs.
8.2 Scalability
The performance of Aquila is directly affected by the complexity
of the encoded GCL representation, which is affected by the com-
plexity of the input program and the size of the data structures, e.g.,
the number of table entries. To evaluate Aquila’s scalability, we
conducted two experiments based on a vendor-provided switch.p4
program (called switch-T) with thousands lines of code.