especially since they are also often used with un-
safe copying functions. They do not contain any
information that could indirectly or directly lead
to a code injection attack.
• Attack target: Low; Attack vector: High
Other arrays are possible targets because an integer
in an array of integers could be used to store a
pointer. As with arrays of pointers, they are pos-
sible vectors, since an out of bounds write could
occur, but they are not generally used with the
most dangerous functions.
• Attack target: Medium; Attack vector:
Medium
Arrays of structures and unions are discussed sepa-
rately.
Structures/unions are assigned different target values and
attack vector-risks depending on the type of the data
they contain:
Structures containing no arrays at any level (struc-
tures and unions can contain other structures or
unions) are unlikely attack vectors, but possible
targets because they possibly contain pointers.
• Attack target: Medium; Attack vector: Low
Structures containing arrays of characters are
likely vectors because a buffer overﬂow could
occur in the character array. They are also
possible targets because they could contain
pointers.
• Attack target: Medium; Attack vector: High
possible
vectors, because overﬂows could occur. They
are also a target because the structure or union
could be used to store a pointer.
• Attack target: Medium; Attack vector:
Structures containing other arrays are
Medium
Arrays of structures/unions Arrays of structures are a
special case because the structures or unions stored in
such an array can contain arrays at some level.
Not containing arrays of characters If
struc-
tures or unions inside the array do not contain
arrays of characters at any level, we treat them
the same as other arrays: possible targets and
possible vectors.
the
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006• Attack target: Medium; Attack vector:
Medium
Containing arrays of characters As
previously
mentioned for structures or unions containing
character arrays: they are a likely target, and a
possible vector.
• Attack target: Medium; Attack vector: High
Based on these assignments and Table 1, the different
categories will contain the following data:
Category 1 : return address, other saved registers, point-
ers.
Category 2 : arrays of pointers, structures and unions (no
arrays), integers.
Category 3 : ﬂoating types, other arrays, structures/unions
containing arrays but not arrays of characters at any
levels, arrays of structures that do not contain arrays of
characters at any level.
Category 4 : structures containing array of characters, ar-
rays of structures containing arrays of characters
Category 5 : arrays of characters
Category 6 would be the hardest to protect, thankfully
it is empty in our risk/value evaluation. There is no data
on the stack that we consider to have high risk of being an
attack vector but is also a high-value target.
As with the different categories, the actual value that we
have assigned speciﬁc data is based on the value or risk that
we perceive it to have. If some data would be assigned a dif-
ferent risk or value, resulting in it being placed in a different
category, this would only require minimal modiﬁcation of
our existing countermeasure.
The main principle used to design this countermeasure
is to separate information in these different categories from
each other by storing them on separate stacks. As such they
can no longer be overwritten by information which has been
moved to a different stack. Figure 2 depicts the memory
layout if we were to map the ﬁve categories that contain
data onto ﬁve different stacks.
It is however fairly simple to modify our design (and our
implementation) to support other stack conﬁgurations de-
pending on the amount of risk that these data types or cate-
gories present (or if the risk of a particular category or data
type can be diminished or abolished entirely) in a particular
application versus the amount of memory that can be used.
An example of this would be to support only two stacks,
and to place categories one, two and three on the ﬁrst stack,
while storing categories four and ﬁve on the second stack.
3.2
Implementation
The multiple stack countermeasure was implemented in
gcc-4.1-20050902 for Linux on the IA32 architecture. Each
such stack is stored sequentially after the other and each
stack is protected from the previous using a guard page. We
start of by allocating the different stacks at a ﬁxed location
from one another. This ﬁxed point is the maximum size that
the stack can grow to (this must be known at compile time).
As long as no information is written to the speciﬁc pages
that were allocated for the stack, the program will only use
virtual address space, rather than physical address space so
we can easily map all stacks into memory without wasting
any physical memory.
The countermeasure was implemented in the pass of the
compiler that converts the GIMPLE representation3 into
RTL4.
We implement our countermeasure by modifying the
way local variables are accessed in a function. When a
function is called in a program, the return address will be
stored on the stack, however, to access local variables of
a function, the current value of the register containing the
stack pointer will be copied to the frame pointer register
(and the current saved frame pointer will be saved on the
stack). This frame pointer will be used as a ﬁxed loca-
tion to access a function’s local variables (all variables will
be accessed as an offset to the frame pointer), this mecha-
nism is used because the value of the register containing the
stack pointer is constantly changing whenever a variable is
pushed or popped from the stack. The compiler will cal-
culate the offset to the frame pointer for local variables at
compile time and will use this offset whenever it accesses
this variable. When the function returns, the saved frame
pointer will be restored into the frame pointer register.
We use this mechanism to efﬁciently implement our
countermeasure: instead of using multiple stack pointers,
we modify the offset to the frame pointer that is used to ac-
cess the variable. We add (stacknr − 1) ∗ (sizeof stack +
pagesize) to the offset, which will result in the access of
the variable on the correct stack. As such all operations that
use this variable will use the correct stack to address it. This
also means we don’t incur any overhead because the offset
will simply be a larger constant value, but the instruction to
access it will remain the same.
Because the program is instrumented in this way, the
stack pointer will remain unchanged and effectively con-
trols all ﬁve stacks. The advantage is that setjmp and
3GIMPLE is a language- and target-independent tree representation of
the program being compiled. The compiler will convert the program into
static single assignment form (SSA) at this level.
4RTL is the register transfer language, a language-independent, but
target-dependent, intermediate representation used by the the compiler to
do some optimizations.
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Figure 2. Stack layout for 5 stacks
on a single machine (Pentium 4 2.80 Ghz, 512MB RAM,
no hyper-threading, running Ubuntu Linux 5.10 with kernel
2.6.12.10). The GCC compiler version 4.1-20050902 was
used to compile all benchmarks.
4.1 Performance
This section evaluates our countermeasure in terms of
performance overhead. Both macro- and microbenchmarks
were performed.
Macrobenchmarks
All programs but one (252.eon is written in C++, while
our prototype implementation is only for C)
in the
SPEC R(cid:13)CPU2000 Integer benchmark [14] were used to
perform these benchmarks.
Table 2 contains the amount of code present in a particu-
lar program (expressed in lines of code), the runtime in sec-
onds when compiled with the unmodiﬁed gcc and the run-
time when compiled wih our multistack countermeasure.
The results in this table show that the performance over-
head of using our countermeasure are negligible for most of
these programs. There is a slightly higher overhead of 2-3%
for the programs vortex and twolf. The negative overheads
in the table are so low that they can be attributed to normal
variations between runs and, as such, these overheads can
be considered equal.
Microbenchmarks
Two programs which make extensive use of the stack were
run as a microbenchmark. One program which simply calls
a function 1 million times. This function performs an addi-
tion of two local variables (ﬁlled with ’random’6 values),
ﬁlls a local array with this random value, and allocates
and frees a chunk of random size. The second program
performs a recursive Fibonacci calculation of the 42nd Fi-
bonacci number. These programs were each run 100 times
both compiled with the unmodiﬁed gcc and our multistack
countermeasure. Table 2 contains the average runtime in
seconds, followed by the standard error for both versions.
6We use a ﬁxed seed for the random function, so the generated values
are the same over different runs.
Figure 3. Gaps on the different stacks
longjmp5 will work unchanged. The drawback of this coun-
termeasure is that it will result in gaps on the remaining
stacks, resulting in wasted memory. Figure 3 depicts this
for two stacks. We provide a more detailed discussion on
the memory overhead in section 4.
A special case which we did not address in the design
and the categories above is memory allocated with alloca.
The information stored in it could be both an attack vector
to overwrite other memory and could contain information
which could be used to perform a code injection attack (e.g.
a function or data pointer). Given this, we chose to modify
this call to allocate memory on stack three in the case of ﬁve
stacks and stack two in the case of two stacks.
4 Evaluation
To test the performance overhead, we ran several bench-
marks on programs instrumented with our countermeasure
(running with 5 stacks) and without. All tests were run
5The longjmp function will jump to the last place in the code where a
setjmp was executed, resetting the stack pointer (and other registers) to the
value they held at the moment setjmp was called.
Guard pageStack 1PointersSaved registersGuard pageStack 2Arrays of PointersStructures (no arrays)Guard pageStack 3Structures (no char array)Array of struct (no char array)ArraysGuard pageStack 4Structures (with char array)Arrays of structures (with char array)Guard pageStack 5Arrays of charactersAlloca()IntegersFloatsStack 1Stack 2Return address f1Saved frame pointer f1Pointer p1Higher addressesLower addressesArray of charactersPointer p2Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Table 2. Benchmark results
SPEC CPU2000 Integer benchmarks
Program
164.gzip
175.vpr
176.gcc
181.mcf
186.crafty
197.parser
253.perlbmk
254.gap
255.vortex
256.bzip2
300.twolf
loop
ﬁbonacci
LOC
8,616
17,729
222,182
2,423
21,150
11,391
85,185
71,430
67,220
4,649
20,459
20
14
Gcc 4.1 (s) Multistack (s) Overhead
0%
-0.47%
0.11%
0.4%
-0.86%
-0.78%
0.67%
0%
2.96%
-0.49%
2.06%
201
213
89.7
248
116
257
150
101
169
204
291
Microbenchmarks
9.166 ± 0.029
3.354 ± 0.004
201
212
89.8
249
115
255
151
101
174
203
297
9.2 ± 0.015
3.363 ± 0.005
0.37%
0.27%
These results also conﬁrm that the performance overhead
of using our countermeasure is negligible.
4.2 Memory overhead
The maximum memory overhead (which is also the gen-
eral case) of this countermeasure will be the original stack
usage multiplied by the amount of stacks that are used.
Because variables are calculated by simply adding a con-
stant value to the frame pointer, we end up with gaps on all
stacks and waste space on all stacks. To reduce the waste,
we are planning to implement a version where we calculate
the actual location that the variable is on for every stack.
This would eliminate gaps in a function entirely. Some gaps
would still exist between function calls (because we still
only have one stack pointer), but these could be reduced to
be equal to the amount of space used on the largest stack.
This still allows us to use a single stack pointer, because all
other stacks will continue to have gaps, but these gaps will
be much smaller than in the current implementation. Since
all these calculations can be done at compile time, no extra
performance overhead would be incurred.
5 Discussion and ongoing work
Most applications will never increase the default stack
size, however, applications that do, may be limited in the
size their stack may grow to a predetermined maximum,
since the location of the stacks must be set to a ﬁxed location
when the program is compiled. However, if the maximum
size that the stack could grow to is known beforehand, the
locations of the different stacks can easily be moved to ac-
commodate a larger stack. The application would only lose
virtual address space when moving the stacks further apart
and would not use any extra physical memory until the data
is written to these pages. We discuss a possible solution to
this problem below.
Our approach is incompatible with most address space
layout randomization (ASLR) [28] implementations. This
can be mitigated by ﬁnding the start of the stack dynami-
cally at program start up, when setting up the extra stacks.
This can be done either by recursively following the saved
frame pointer values or by modifying the ASLR implemen-
tation to store the value in a known location (e.g. the normal
stack location) at program start up and subsequently clear-
ing it when the multiple stacks have been set up.
Because not all applications can afford to use ﬁve stacks,
but would still like more security than simply reducing the
amount of stacks to two can offer, we are currently working
on extending the countermeasure by a concept which we
call selective bounds checking. Selective bounds checking
will only bounds check write operations to some types of ar-
rays to prevent them from being overﬂown. If, for example,
we can bounds check write accesses to arrays of pointers,
we could determine that the risk of it being used as an at-
tack vector was reduced low enough to place it in the ﬁrst
category. While the bounds checking for direct access is