tive result of LDPMiner when we have 500,000 users instead.
It is clear that the estimation becomes very accurate, not
only that it only misses one heavy hitter but also the fre-
quency estimation of each heavy hitter is very close to the
real one. Meanwhile, ﬁgure 4c shows a representative re-
sult produced by sampling RAPPOR. Though it improves as
well, it is clearly much inferior to that of LDPMiner, which
shows the beneﬁt of the proposed two-phase approach.
The skewness aﬀects the frequency diﬀerence between heavy
hitters and other items; hence, higher skewness makes it
easier to ﬁnd the correct results. LDPMiner’s eﬀectiveness
would also be aﬀected by the skewness of heavy hitters. Fig-
ure 5a shows a representative result of LDPMiner over the
synthetic dataset generated from the Laplace distribution
with 500,000 users. Compared with Figure 4c, the skewness
of heavy hitters helps further improve estimation accuracy
of LDPMiner: no actual heavy hitters are missed, and the
frequency estimation error for each heavy hitter is further
reduced. In contrast, Figure 5b shows a representative result
of sampling RAPPOR over the same dataset. It does not
show clear improvement over that in ﬁgure 4c. The reason is
that because of the skewness, the ﬁrst phase of LDPMiner is
able to accurately capture the true top heavy hitters, which
means even less privacy budget is spent on non heavy hitters
in the second phase. For sampling RAPPOR, as the privacy
budget is spread evenly over all items, it cannot take advan-
tage of the skewness of heavy hitters.
(a) LDPMiner-RAPPOR
(b) LDPMiner-RAPPOR
(c) Sampling RAPPOR
Figure 4: Experimental results over synthetic datasets generated from a normal distribution
(a) LDPMiner-RAPPOR
(b) Sampling RAPPOR
(c) LDPMiner-RAPPOR
Figure 5: (a) and (b) show the experimental results over synthetic datasets following the Laplace distribution. (c) shows the
measured Relative Error of two synthetic datasets (normal and Laplace) with diﬀerent privacy budget allocation strategies
In the above experiments, we evenly split the privacy bud-
get between the two phases of LDPMiner. One may wonder
what would be the impact if we split the budget diﬀerently.
Intuitively, we can imagine that when we allocate too little
budget to the ﬁrst phase, according to Theorem 4.2, the can-
didate heavy hitter set would be much larger, which means
that the second phase’s privacy budget would need to be
spread thin over all these candidate items. On the other
hand, if the second phase gets too little budget, though the
candidate set from the ﬁrst phase would be smaller, their fre-
quency estimation would be very noisy, due the limited bud-
get we can spend on each candidate item. Figure 5c shows
the Relative Error of the results of LDPMiner over both the
normal-distribution and the Laplace-distribution synthetic
dataset as described above with n = 500, 000. x-axis is the
percentage of the budget allocated to the ﬁrst phase of LDP-
Miner. It is clear that the relative error is minimized when
we split the budget roughly evenly. We have conducted the
same experiments with other setting and using the NDCG
metrics, obtaining similar observations. Thus, for the rest of
the experiments in this paper, we always allocate the same
amount of budget for each phase of LDPMiner.
5.3 Experiments with Real datasets
5.3.1 The impact of 
In this experiment, for both datasets, we ﬁx k = 10 and
report the utility measures of diﬀerent LDP mechanisms
when varying . Figure 6 shows the relative errors over
both datasets along with the change of . Not surprisingly,
for all four algorithms, the larger , the lower their relative
errors. Meanwhile, we see that LDPMiner-RAPPOR and
LDPMiner-SH consistently achieve much lower relative er-
rors than sampling RAPPOR and sampling SH. For most ,
the relative errors of single-phase approaches is almost twice
that of LDPMiner.
Another observation is that LDPMiner-RAPPOR consis-
tently outperforms LDPMiner-SH, which shows the utility
gain by tolerating a little more extra communication cost (k
bits vs. 1 bit per each user’s response), when using RAP-
POR instead of SH in the second phase of LDPMiner. We
also observe that sampling RAPPOR is superior to sam-
pling SH. However, this utility gain is associated with pro-
hibitively communication cost. We have similar observations
when the utility of estimated heavy hitters is measured using
NDCG, as shown in Figure 7.
5.3.2 The impact of k
In this experiment, we ﬁx  = 3 and vary the size of re-
ported heavy hitters, i.e., k, to study its impact on the utility
of each algorithm. The results are shown in Figures 8 and 9.
As expected, for all approaches their utility measures de-
0.4 0.35 0.3 0.25 C Q) ::J 0.2 O" LL 0.15 0.1 0.05 O 486Normal Distribution: n=50,000, m=500, std=100, 1=50. 500 Item Index 515 500Item Index00.050.10.150.20.250.3FrequencyNormal Distribution: n=500,000, m=500, std=100, l=50.4865150.3 0.25 .... G' 0.2 .... C ] g-0.15 .... 0.1 0.05 O 486Normal Distribution: n=S00,000, .. m=500, std=100, 1=50 .. ··1 I ... . I Ir II l11I III500 Item Index .. --] 515 Laplace Distribution: n=500,000, m=500, std=100, 1=50. 0.3-.------0.25  0.2() C Q) 5-0.15 Q) LL 0.1 0.05 ----0 ---.......... ...-...--.-......-..----.___..---.___......__, __ .-...,........._.....-__J 486 500 Item Index 515 00.050.10.150.20.250.3FrequencyLaplace Distribution: n=500,000, m=500, std=100, l=50.500Item Index4865150.10.20.30.40.50.60.70.80.9,00.511.522.533.54REPrivacy Budget AllocationNormalLaplace(a) AOL: RE
(b) Kosarak: RE
(a) AOL: RE
(b) Kosarak: RE
Figure 6: Varying : Relative Error for Real Datasets
Figure 8: Varying k: Relative Error for Real datasets
(a) AOL: NDCG
(b) Kosarak: NDCG
(a) AOL: NDCG
(b) Kosarak: NDCG
Figure 7: Varying : Normalized Discounted Cumulative
Gain for Real datasets
Figure 9: Varying : Normalized Discounted Cumulative
Gain for Real Datasets
crease when k increases. We also observe that the advantage
of LDPMiner compared to single-phase approaches is much
more signiﬁcant when k is small. Further, when k keeps in-
creasing (for example when k > 30 for the AOL dataset), the
relative error of LDPMiner becomes even higher than single-
phase based approaches. Intuitively, the proposed two-phase
framework improves the utility by reducing the size of item
sets from l to O(k), the size of candidate heavy hitter set
generated in the ﬁrst phase. When k increases, the size of
candidate sets becomes closer to l, and the utility gain due
to the trimmed candidate set is oﬀset by the utility loss
caused by budget splitting. However, it is interesting to see
that for the AOL dataset when k is larger than 30, though
the relative errors of LDPMiner are higher than sampling
RAPPOR, LDPMiner still achieves better NDCG. This ob-
servation is even clearer for the Kosarak dataset. Recall
that the relative error reﬂects the quality of frequency esti-
mation while NDCG reﬂects the quality of the ranked list
of heavy hitters. The above observation suggests that when
k increases, though the frequency estimation of LDPMiner
deteriorates, it still manages to better preserve the relative
orders among heavy hitters.
6. RELATED WORK
As discussed in Section 2, a series of works study the
problem of frequency estimation following local diﬀerential
privacy [3, 9, 19, 22]. After Warner’s ﬁrst study [28] on
randomized response method, many works have explored a
variety of perturbation mechanisms for achieving theoretical
optimal utility. In [22], the local privacy model is ﬁrst for-
malized. A recent work by Duchi et al. [9] shows an upper
bound under the LDP setting, using information theoretic
converse techniques to provide a minimax-error bound on
convex statistical estimation. Hsu et al. [19] focus on es-
timating heavy hitters based on the general technique of
random projection and concentration of measure. Following
this work, Bassily et al. [3] propose an eﬃcient protocol for
succinct histogram estimation with information-theoretical
optimal error. To handle the practical issues for private dis-
tribution estimation, RAPPOR [12, 13] is proposed to gen-
eralize Warner’s randomizer from binary alphabets to k-ary
alphabets. In [11], private estimation of frequent elements
from stream data is studied in a setting called ”pan-privacy”,
which can be considered as a variant of the LDP model.
Quite a few works focus on publishing histogram and
count queries under the centralized diﬀerential privacy model.
Hay et al. [17] generate diﬀerentially private histograms through
hierarchical partitioning of data. Moreover, wavelet trans-
form is utilized to handle multi-dimensional dataset in [30].
Li et al. [23] propose a query matrix framework that gen-
eralizes the above two works while incurring high computa-
tional complexity. Xu et al. [31] propose a two-phase kd-
tree based spatial decomposition mechanism to publish his-
tograms. Moreover, Li et al. [24] addresse the problem of
releasing histograms for dynamic datasets using sparse vec-
tor technique. He et al. [18] propose a ﬂexible policy where
users can specify sensitive information for releasing cumula-
tive histograms. In addition, there is also a rich literature
on frequent itemset mining. Among them, several works are
relevant to our work. Bhaskar et al. [4] also propose a two-
phase based approach using a truncated frequency thresh-
old to shrink the candidate list of frequent itemsets. This
work also conﬁrms the eﬀectiveness of two-phase approach
in a centralized model.
Inspired by [4], Li et al. propose
to improve the utility by constructing a basis set privately.
In addition, Chen et al. [7] study the publication of set-
valued dataset under diﬀerential privacy. They present a
tree structured partition mechanism in a top-down fashion.
012345678910Epsilon00.050.10.150.20.250.30.350.40.450.5REAOL: k=10LM-RPLM-SHRPSH012345678910Epsilon00.050.10.150.20.250.30.350.40.450.5REKorasak: k=10LM-RPLM-SH RPSH012345678910Epsilon00.10.20.30.40.50.60.70.80.91NDCGAOL: k=10LM-RPLM-SHRPSH012345678910Epsilon00.10.20.30.40.50.60.70.80.91NDCGKosarak: k=10LM-RP LM-SHRPSH051015202530354000.250.50.7511.251.51.752.25LM-RP LM-SHRPSHAOL Dataset: Epsilon=3 REk05101520253000.20.40.60.81Kosarak Dataset: Epsilon=3 REkLM-RPLM-SHRPSH051015202530354000.10.20.30.40.50.60.70.80.91LM-RPLM-SH RPSHAOL Dataset: Epsilon=3NDCGk051015202530354000.10.20.30.40.50.60.70.80.9LM-RPLM-SHRPSHKosarak(cid:3)(cid:39)(cid:68)(cid:87)(cid:68)(cid:86)(cid:72)(cid:87):(cid:3)(cid:40)(cid:83)(cid:86)(cid:76)(cid:79)(cid:82)(cid:81)(cid:32)(cid:22)(cid:3)NDCG(cid:78)However, all above mechanisms require global knowledge of
the dataset, which makes them not applicable under local
diﬀerential privacy. We remark that though not all tech-
niques developed for a centralized model is suitable to a
local model, the ideas behind these technique still might be
helpful in designing mechanisms in a LDP model.
7. CONCLUSIONS AND FUTURE WORK
In this paper, we study heavy hitter estimation under lo-
cal diﬀerential privacy over set-valued data. We ﬁrst review
existing LDP techniques and study direct extension of these
techniques to handle set-valued data. Our theoretical and
experimental analysis shows that such extensions would ei-
ther suﬀer from high communication overhead or low result
utility. To address the problem, we propose LDPMiner, a
two-phase framework: a candidate set of heavy hitters is
identiﬁed by data collector in the ﬁrst phase, so that each
participant is able to reﬁne the frequency report of items in
the candidate set in the second phase.Both theoretical analy-
sis and extensive experiments conﬁrm the utility, eﬃciency,
and practicality of LDPMiner. A natural venue built on
LDPMiner is to study frequent itemset mining under local
diﬀerential privacy. The challenge is that direct adoption of
existing frequent itemset mining algorithm would require it-
erative information exchange between users and data collec-
tors, which would result in accumulation of dramatic noise
due to the limited budget for each iteration.
8. ACKNOWLEDGMENTS
Xiaokui Xiao was supported by grant ARC19/14 from
MOE, Singapore.
9. REFERENCES
[1] Aol search log.
http://www.gregsadetsky.com/aol-data/.
[2] Spmf: An open-source data mining library.
http://www.philippe-fournier-viger.com/spmf.
[3] R. Bassily and A. D. Smith. Local, private, eﬃcient
protocols for succinct histograms. In STOC, pages
127–135, 2015.
[4] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta.
Discovering frequent patterns in sensitive data. In
SIGKDD, pages 503–512, 2010.
[5] A. Blum, K. Ligett, and A. Roth. A learning theory
approach to noninteractive database privacy. JACM,
60(2):12, 2013.
[6] C. Burges et al. Learning to rank using gradient
descent. In ICML, pages 89–96, 2005.
[7] R. Chen et al. Publishing set-valued data via
diﬀerential privacy. PVLDB, 4(11):1087–1098, 2011.
[8] J. C. Duchi, M. I. Jordan, and M. J. Wainwright.
Privacy aware learning. J. ACM, 61(6):38:1–38:57.
[9] J. C. Duchi, M. I. Jordan, and M. J. Wainwright.
Local privacy and statistical minimax rates. In FOCS,
pages 429–438, 2013.
[10] C. Dwork. Diﬀerential privacy: A survey of results. In
Theory and applications of models of computation,
pages 1–19. 2008.
[11] C. Dwork, M. Naor, T. Pitassi, G. N. Rothblum, and
S. Yekhanin. Pan-private streaming algorithms. In
ICS, pages 66–80, 2010.
[12] ´U. Erlingsson et al. Rappor: Randomized aggregatable
privacy-preserving ordinal response. In CCS, pages
1054–1067, 2014.
[13] G. Fanti et al. Building a rappor with the unknown:
Privacy-preserving learning of associations and data
dictionaries. PoPETS, issue 3, 2016, 2016.
[14] A. Gupta, M. Hardt, A. Roth, and J. Ullman.
Privately releasing conjunctions and the statistical
query barrier. SICOMP, 42(4):1494–1520, 2013.
[15] S. Hansell. Aol removes search data on vast group of
web users. New York Times, 8:C4, 2006.
[16] M. Hardt and K. Talwar. On the geometry of
diﬀerential privacy. In STOC, pages 705–714, 2010.
[17] M. Hay et al. Boosting the accuracy of diﬀerentially
private histograms through consistency. PVLDB,
3(1-2):1021–1032, 2010.
[18] X. He, A. Machanavajjhala, and B. Ding. Blowﬁsh
privacy: Tuning privacy-utility trade-oﬀs using
policies. In SIGMOD, pages 1447–1458, 2014.
[19] J. Hsu, S. Khanna, and A. Roth. Distributed private
heavy hitters. In Automata, Languages, and
Programming, pages 461–472. 2012.
[20] W. B. Johnson and J. Lindenstrauss. Extensions of
lipschitz mappings into a hilbert space. Contemporary
mathematics, 26(189-206):1, 1984.
[21] D. Karger et al. Consistent hashing and random trees:
Distributed caching protocols for relieving hot spots
on the world wide web. In STOC, pages 654–663, 1997.
[22] S. P. Kasiviswanathan et al. What can we learn
privately? SICOMP, 40(3):793–826, 2011.
[23] C. Li et al. Optimizing linear counting queries under
diﬀerential privacy. In PODS, pages 123–134, 2010.
[24] H. Li et al. Diﬀerentially private histogram
publication for dynamic datasets: an adaptive
sampling approach. In CIKM, pages 1001–1010, 2015.
[25] N. Li, W. Qardaji, D. Su, and J. Cao. Privbasis:
Frequent itemset mining with diﬀerential privacy.
PVLDB, 5(11):1340–1351, 2012.
[26] F. D. McSherry. Privacy integrated queries: an
extensible platform for privacy-preserving data
analysis. In SIGMOD, pages 19–30, 2009.
[27] T. T. Nguyˆen et al. Collecting and analyzing data
from smart device users with local diﬀerential privacy.
arXiv preprint arXiv:1606.05053, 2016.
[28] S. L. Warner. Randomized response: A survey
technique for eliminating evasive answer bias. Journal
of the ASA, 60(309):63–69, 1965.
[29] X. Xiao, Y. Tao, and M. Chen. Optimal random
perturbation at multiple privacy levels. PVLDB,
2(1):814–825, 2009.
[30] X. Xiao, G. Wang, and J. Gehrke. Diﬀerential privacy
via wavelet transforms. TKDE, 23(8):1200–1214, 2011.
[31] J. Xu et al. Diﬀerentially private histogram
publication. VLDBJ, 22(6):797–822, 2013.
[32] Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan.
Large-scale parallel collaborative ﬁltering for the
netﬂix prize. In Algorithmic Aspects in Information
and Management, pages 337–348. 2008.