### Detection of Evasive Code

Evasive code, which behaves differently in an analysis environment compared to a regular machine, is a well-recognized challenge in the binary malware community. Various techniques have been developed to detect whether a binary is running inside an emulator or a virtual machine [10, 30, 36]. In this context, evasive code includes instructions that produce different results or side effects on an emulator versus a real host [21, 26]. The original malware code is modified to include these checks: if the check identifies an analysis system, the code behaves benignly, thereby evading detection.

Researchers have addressed such evasive checks in two primary ways:
1. Designing systems that remain transparent to a wide range of malware checks [8, 39].
2. Developing techniques to detect the presence of such checks by comparing the behavior of a sample on a reference machine with that on an analysis host [3, 15].

### Similarities in Web Attacks

Similar to binary analysis environments, honeyclients (tools used to classify web pages as malicious or benign) can be confused by sophisticated evasion techniques. Honeyclients are not infallible, and attackers have found ways to evade them [16, 31, 40]. For example, malicious web pages may only launch an exploit after verifying that the visitor is a regular user, rather than an automated detection tool. These pages may check for activities like mouse movements or link clicks, or they may verify that the browser has the idiosyncratic properties of commonly used modern browsers, rather than being a simple emulator. If these checks are not satisfied, the malicious web page will refrain from launching the attack and will be incorrectly classified as benign, thus evading detection.

### Recent Research on Evasive Web Code

The problem of evasive code in web attacks has only recently been investigated. Kolbitsch et al. [17] studied the "fragility" of malicious code, i.e., its dependence on a specific execution environment (e.g., specific browser and plugin versions). They reported several techniques used by malicious code for environment matching, some of which can distinguish between analysis tools and regular browsers. They proposed ROZZLE, a system that explores multiple execution paths in a program to bypass environment checks. However, ROZZLE only detects fingerprinting that leverages control flow branches and depends on the environment. It can be evaded by techniques that do not need control-flow branches, such as those based on browser or JavaScript quirks. For instance, the property `window.innerWidth` contains the width of the browser window viewport in Firefox and Chrome but is undefined in Internet Explorer. A malicious code that initializes a decoding key as `xorkey = window.innerWidth * 0 + 3` would compute a different result for `xorkey` in Firefox/Chrome (3) and IE (NaN), and could be used to decode malicious code in specific browsers. ROZZLE would not trigger its multi-path techniques in such cases and can be evaded.

### Revolver: A Different Approach

Revolver takes a different approach to identifying evasive code in JavaScript programs. Instead of forcing an evasive program to display its full behavior by executing it in parallel on a reference host and in an analysis environment [3], or by forcing the execution through multiple, interesting paths [17], it leverages the existence of two distinct but similar pieces of code. Despite their similarity, these pieces are classified differently by detection tools. Additionally, Revolver can precisely and automatically identify the code responsible for the evasion.

### JavaScript Code Analysis

In recent years, various approaches have been developed for analyzing JavaScript code. For example, Prophiler [5] and ZOZZLE [7] use characteristics of JavaScript code to predict if a script is malicious or benign. ZOZZLE, in particular, leverages features associated with AST context information (such as the presence of a variable named `scode` in the context of a loop) for classification.

Cujo [34] uses static and dynamic code features to identify malicious JavaScript programs. It processes the static program and traces of its execution into q-grams that are classified using machine learning techniques. Revolver performs its core analysis statically by computing the similarity between pairs of ASTs. However, Revolver also relies on dynamic analysis, especially to access code generated dynamically by a script (e.g., via the `eval()` function), a common technique used by obfuscated and malicious code.

### Code Similarity

The task of automatically detecting "clones," i.e., segments of code that are similar according to some notion of similarity, is a well-established line of work in the software engineering community [27, 35]. Unfortunately, many of these techniques assume that the code under analysis is well-behaved or at least not adversarial. This assumption does not hold when examining malicious code.

Similarity between malicious binaries has been used to quickly identify different variants of the same malware family. The main challenge in this context is dealing with extremely large numbers of samples without source code and large feature spaces from runtime data. Techniques such as locality-sensitive hashing [4] and feature hashing [14] have been proposed to address these issues.

In comparison, Revolver aims not only to identify pieces of JavaScript code that are similar but also to understand why they differ and whether these differences are responsible for changing the classification of the sample.

### Conclusions

In this paper, we introduced and demonstrated Revolver, a novel approach and tool for detecting malicious JavaScript code similarities on a large scale. Revolver's approach is based on identifying scripts that are similar and taking into account an Oracle's classification of every script. By doing this, Revolver can pinpoint scripts that have high similarity but are classified differently, detecting likely evasion attempts and improving the accuracy of the Oracle.

We performed a large-scale evaluation of Revolver by running it in parallel with the popular Wepawet drive-by-detection tool. We identified several cases of evasions used in the wild to evade this tool (and likely other tools based on similar techniques) and fixed them, thereby improving the accuracy of the honeyclient.

### Acknowledgements

This work was supported by the Office of Naval Research (ONR) under grants N00014-12-1-0165 and N00014-09-1-1042, and the National Science Foundation (NSF) under grants CNS-0845559 and CNS-0905537, and by Secure Business Austria.

### References

[References listed here as in the original text]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the original content and structure.