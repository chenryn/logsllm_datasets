### 6.3 Sybil Attacks
An adversary could initiate a Sybil attack by generating a large number of fake identities (Sybils) among the potential bridge users, thereby significantly increasing the ratio \( f \) of compromised entities in the user pool. However, it is important to note that merely deploying a large number of Sybils does not necessarily lead to an increase in the number of corrupt users in the system. For honest users, invitation tickets are distributed to known individuals. In contrast, corrupt users may distribute all their received tickets to colluding entities, but the number of malicious entities they can invite is limited by the number of invitation tickets they possess, rather than the number of Sybils the adversary can create.

Alternatively, the adversary might attempt to directly deploy Sybils within the system, which would require providing each Sybil with a valid credential. This is infeasible without access to the bridge distributor's private key. Additionally, sharing credentials between corrupt users and Sybils is also infeasible because the bridge distributor recycles used credentials, preventing the adversary from gaining additional bridges.

### 6.4 Blocking the Bridge Distributor
We assume that the IP address of the bridge distributor is publicly known. Consequently, a censor could block the bridge distributor, preventing new users from joining the system or stopping existing users from receiving new bridges. An existing user with at least one unblocked bridge can use it to establish a Tor circuit and access the bridge distributor. For a new user without any usable bridge, high-latency but more robust circumvention tools (e.g., Email-based circumvention [5]) can be used to communicate with the bridge distributor to obtain initial or replacement bridges. Additionally, a new user could request their inviter (the existing user who provided the invitation ticket) to perform the initial bootstrapping on their behalf to receive the initial bridges.

### 6.5 Well-Behaving Corrupt Users
To increase the number of corrupt users in the system, the adversary might instruct corrupt users to behave legitimately for a certain period, keeping their bridges active to accumulate credits and receive invitation tickets. However, since invitation tickets are randomly distributed to qualified users, corrupt users may not necessarily receive tickets even if they have accumulated sufficient credits. Furthermore, maintaining active bridges also allows honest users to accumulate enough credits to become eligible for invitation tickets. Our simulation results in Section 4.3 (where corrupt users do not block bridges until the 225th day) show that this strategy does not help the adversary increase the ratio of corrupt users in the system. Additionally, rBridge does not allow users to transfer credits to others, making it infeasible for a few well-behaving corrupt users to assist other corrupt users by sharing their credits.

### 7 Conclusion
We introduced rBridge, a user reputation system for Tor bridge distribution. rBridge addresses two key challenges: protecting bridges from being blocked by corrupt users and preserving the privacy of bridge assignment information. By leveraging users' reputations, rBridge punishes blockers and limits their ability to repeatedly block bridges. It also employs an introduction-based mechanism to invite new users while resisting Sybil attacks. Our simulation results demonstrate that rBridge provides significantly stronger protection for bridges compared to existing schemes. Moreover, we addressed privacy preservation in rBridge by concealing users' bridge assignment information, which can otherwise be exploited to degrade users' anonymity. We designed a novel privacy-preserving reputation system using several cryptographic primitives. To the best of our knowledge, rBridge is the first scheme that perfectly preserves users' privacy in bridge distribution. We implemented a prototype of rBridge, and the experiments showed that it has reasonable performance.

### 8 Acknowledgement
We thank the anonymous reviewers for their invaluable comments on the paper. Qiyan Wang was supported in part by NSF CNS 09-53655, and Zi Lin was supported in part by NSF CNS 09-17154.

### References
[1] https://metrics.torproject.org/network.html#networksize.
[2] Ten ways to discover Tor bridges. https://blog.torproject.org/blog/research-problems-ten-ways-discover-tor-bridges.
[3] https://www.torproject.org/projects/obfsproxy.html.en.
[4] Proposal 190: Password-based Bridge Client Authorization. https://lists.torproject.org/pipermail/tor-dev/2011-November/003042.html.
[5] Feed Over Email (F.O.E). http://code.google.com/p/foe-project/.
[6] Research problem: Five ways to test bridge reachability, Dec 1, 2011. https://blog.torproject.org/blog/research-problem-five-ways-test-bridge-reachability.
[7] M. H. Au, A. Kapadia, and W. Susilo. Blacr: TTP-free blacklistable anonymous credentials with reputation. In NDSS’12, 2012.
[8] M. H. Au, W. Susilo, and Y. Mu. Constant-size dynamic k-TAA. SCN, Lecture Notes in Computer Science, 4116:111–125, 2006.
[9] J. Camenisch and M. Stadler. Proof system for general statements about discrete logarithms. In Technical Report TR 260, Institute for Theoretical Computer Science, 1997.
[10] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-generation onion router. In USENIX Security Symposium, August 2004.
[11] N. Feamster, M. Balazinska, W. Wang, H. Balakrishnan, and D. Karger. Thwarting web censorship with untrusted messenger discovery. In Privacy Enhancing Technologies (PETS), 2003.
[12] A. Fiat and A. Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO, 1986.
[13] J. Jacob. How internet censorship works in China. http://www.ibtimes.com/articles/113590/20110217/china-internet-censorship-great-firewall-us-hillary-clinton-communist.htm. Feb 17, 2011.
[14] M. Mahdian. Fighting censorship with algorithms. In Proceedings of FUN’10, 2010.
[15] D. McCoy, J. A. Morales, and K. Levchenko. Proximax: A measurement-based system for proxies dissemination. In FC’11, Feb 2011.
[16] J. McLachlan, A. Tran, N. Hopper, and Y. Kim. Scalable onion routing with torsk. In ACM CCS’09, 2009.
[17] M. Naor and B. Pinkas. Efficient oblivious transfer protocols. In SODA’01, 2001.
[18] T. Pedersen. Non-interactive and information-theoretic secure verifiable secret sharing. In Advances in Cryptology, 1992.
[19] R. Smits, D. Jain, S. Pidcock, I. Goldberg, and U. Hengartner. Bridgespa: Improving Tor bridges with single packet authorization. In WPES’11, 2011.
[20] Y. Sovran, A. Libonati, and J. Li. Pass it on: Social networks stymie censors. In IPTPS’08, 2008.
[21] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith. Blacklistable anonymous credentials: Blocking misbehaving users without TTPs. In CCS’07, 2007.
[22] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith. Perea: Towards practical TTP-free revocation in anonymous authentication. In CCS’08, 2008.
[23] J. Zittrain and B. Edelman. Internet Filtering in China. IEEE Internet Computing, 7(2):70–77, 2003. http://csdl.computer.org/comp/mags/ic/2003/02/w2070abs.htm.

### A. Dealing with Duplicate Bridges
Suppose user \( U \) receives a duplicate bridge \( Bd \) in the randomized OT, which is identical to one of their existing bridges \( Be \). We allow \( U \) to get a new bridge (by running the randomized OT again) to replace \( Bd \) as long as \( U \) can prove that they have valid signatures for both \( Bd \) and \( Be \).

However, a sophisticated distributor \( D \) might try to infer \( U \)'s bridges by constructing a list of available bridges (\( B^* \)) and checking if \( U \) later requests a replacement for a duplicate bridge. If \( U \) does, \( D \) can infer that \( B^* \) is one of \( U \)'s existing bridges. To prevent this, \( D \) computes \((C_j, O_j) = CMT(B_j)\) for each available bridge \( B_j \) and publishes all the \( C_j \)'s. Before running the randomized OT, \( U \) randomly picks \( C_p \) and \( C_q \) (with \( p \neq q \)) and asks \( D \) to prove that \( B_p \) and \( B_q \) are different. \( D \) constructs the following proof:
\[
\pi_6 = NIPK(C_p, O_p, B_p, O_p, B_q, O_q) : (C_p, O_p) = CMT(B_p) \land (C_q, O_q) = CMT(B_q) \land B_p \neq B_q
\]
Then, \( U \) runs the randomized OT to get \( O_d \); using \( O_d \), \( U \) is able to open \( B_d \) from \( C_d \). If \( B_d \) is a duplicate, \( U \) constructs the following proof:
\[
\pi_7 = NIPK(x, B_d, \tau_d, \phi_d, C_d, O_d, \sigma_d, B_e, \tau_e, \phi_e, C_e, O_e, \sigma_e) : (C_d, O_d) = CMT(B_d, \tau_d, \phi_d, x) \land \text{Verify}(PK_D, \sigma_d, C_d) = \text{Accept} \land \kappa_d = \text{Indic}(\sigma_d) \land (C_e, O_e) = CMT(B_e, \tau_e, \phi_e, x) \land \text{Verify}(PK_D, \sigma_e, C_e) = \text{Accept} \land B_d = B_e
\]
and sends \( \kappa_d \| \pi_7 \) to \( D \) through an established Tor tunnel. \( D \) verifies \( \kappa_d \notin \text{elist}_{B_d} \) and \( \pi_7 \), runs the randomized OT to provide a new bridge \( \tilde{B}_d \), and adds \( \kappa_d \) to \( \text{elist}_{B_d} \). After receiving \( \tilde{B}_d \), \( U \) constructs the proof:
\[
\pi_8 = NIPK(x, B_d, \tau_d, \phi_d, C_d, O_d, \sigma_d, \tilde{B}_d, \tilde{\tau}_d, \tilde{\phi}_d, \tilde{O}_d) : (C_d, O_d) = CMT(B_d, \tau_d, \phi_d, x) \land \text{Verify}(PK_D, \sigma_d, C_d) = \text{Accept} \land \kappa_d = \text{Indic}(\sigma_d) \land \tilde{\tau}_d = T_{\text{cur}} \land \tilde{\phi}_d = 0 \land (\tilde{C}_d, \tilde{O}_d) = CMT(\tilde{B}_d, \tilde{\tau}_d, \tilde{\phi}_d, x)
\]
and sends \( \tilde{C}_d \| \pi_8 \) to \( D \). Note that we include the commitment and signature of the duplicate bridge \( B_d \) in \( \pi_8 \) to prevent \( U \) from giving this opportunity of receiving a replacement bridge to another (colluding) user. Finally, \( D \) verifies \( \pi_8 \), signs \( \tilde{C}_d \), and sends \( \tilde{\sigma}_d \) to \( U \).

### B. Construction Details
Let \((G_1, G_2)\) be a bilinear group pair and \( G_p \) be a group of order \( p \) where DDH is intractable with \( \hat{e} : G_1 \times G_2 \rightarrow G_p \), such that \( \hat{e}(P^a, Q^b) = \hat{e}(P, Q)^{ab} \) for all \( P \in G_1 \), \( Q \in G_2 \), and \( a, b \in \mathbb{Z}_p \).

#### B.1 Key Generation
The distributor \( D \) chooses a secret key \( sk \) and generates the corresponding public key \( pk \).