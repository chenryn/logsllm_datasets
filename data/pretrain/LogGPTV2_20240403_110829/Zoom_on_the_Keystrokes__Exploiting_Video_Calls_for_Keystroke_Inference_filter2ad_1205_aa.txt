title:Zoom on the Keystrokes: Exploiting Video Calls for Keystroke Inference
Attacks
author:Mohd Sabra and
Anindya Maiti and
Murtuza Jadliwala
Zoom on the Keystrokes: Exploiting
Video Calls for Keystroke Inference Attacks
Mohd Sabra
Anindya Maiti
University of Texas at San Antonio
University of Oklahoma
PI:EMAIL
PI:EMAIL
Murtuza Jadliwala
University of Texas at San Antonio
PI:EMAIL
Abstract—Due to recent world events, video calls have be-
come the new norm for both personal and professional remote
communication. However, if a participant in a video call is not
careful, he/she can reveal his/her private information to others
in the call. In this paper, we design and evaluate an attack
framework to infer one type of such private information from
the video stream of a call – keystrokes, i.e., text typed during the
call. We evaluate our video-based keystroke inference framework
using different experimental settings and parameters, including
different webcams, video resolutions, keyboards, clothing, and
backgrounds. Our relatively high keystroke inference accuracies
under commonly occurring and realistic settings highlight the
need for awareness and countermeasures against such attacks.
Consequently, we also propose and evaluate effective mitigation
techniques that can automatically protect users when they type
during a video call.
I.
INTRODUCTION
Catalyzed by the ubiquity of the Internet, audio-video call-
ing has become a mainstream method of remote communica-
tion [13]. The trend has recently seen a further boost due to the
COVID-19 pandemic [4], whereby audio-video calls became
the default medium for professionals to confer remotely and
for students to attend lectures from home. Nonetheless, audio-
video calls (often referred to as just video calls) should be
considered privacy sensitive as participants may have spoken
or displayed private information during the call. To protect
video calls from eavesdropping threats, secure video calling
protocols are usually end-to-end encrypted. However, even if
we disregard widespread system weaknesses [2], [19], end-to-
end encryption may be ineffective when an adversary is present
at one end of the video call.
Can an adversary, who is at one end of a video call, infer
some potentially sensitive information about the participant
at the other end which is not trivially visible/audible from
the call? Modern video calling softwares such as Skype [10],
Hangouts [5] and Zoom [17] already provide features such
as background-blurring to enable users to potentially blur/hide
everything in the users’ background, except their body. In this
work, we want to investigate what sensitive information can
Research  reported  in  this  publication  was  supported  by  the  Division  of 
Computer  and  Network  Systems  (CNS)  of  the  National  Science  Foundation 
(NSF)  under  award  number  1943351.
be inferred by just observing a target users’ body and physi-
ological features in an audio/video call. More speciﬁcally, we
would like to investigate the feasibility of inferring keystrokes
of a target user on a traditional QWERTY keyboard by just
observing their video feed on a video calling application such
as Skype, Hangouts and Zoom.
Prior efforts in the literature have shown that the sound
(audio) of keystrokes typed during a video call can be exploited
to infer the text typed [29], [21]. But, audio-based keystroke
inference is not very practical primarily because of naturally
occurring (audio) noises in an audio-video call signal, such
as background sound and participants talking [21]. Moreover,
such audio-based attacks may not work for the relatively
quieter membrane and dome-switch keyboards, because (i) the
low amplitude keystroke audio emanations are not effectively
captured by many entry-level microphones [48], and (ii) non-
vocal low amplitude audio frequencies are often ﬁltered out
by many video calling applications [6], [18].
We believe that the video signal in such calls is less prone
to naturally occurring noises and can be exploited for effective
keystroke inference attacks. It is also a relatively unexplored
modality for keystroke inference. Our contributions in this
paper includes modeling commonly observed typing behaviors
during a video call, and utilizing them to construct a novel
video-based keystroke and typing detection framework. We
then create a text inference framework that uses the keystrokes
detected from the video to predict words that were most likely
typed by the target user (Section V). We then comprehensively
evaluate both the keystroke/typing detection and text inference
frameworks using data collected from a large number of human
subject participants in two different settings: (i) an In-Lab
setting (Section VI) where the video call setup, including
the device(s) used for the calls, participants’ sitting position
during the call, and the text
typed by the participants is
ﬁxed, and (ii) an At-Home setting (Section IX) where the
video call data is collected in a realistic environment without
any constraints or requirements. Evaluation results for the
In-Lab setting are outlined in Sections VII and VIII, while
results for the At-Home setting appear in Section X. We also
propose and evaluate multiple techniques which can help in
the mitigation of such keystroke inference attacks from video
calls (Section XI).
II. RELATED WORK
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2021
21-25  February  2021, Virtual
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.23063
www.ndss-symposium.org
The research literature is rich with various modalities
of side-channel inference threats targeting different types of
private information. We limit our literature review discussion
in two closely related directions as follows.
Keystroke Inference Threats. This direction deals with the
class of inference threats that aim to reconstruct text typed by
a target user, using one or more modalities of side-channels.
Keystroke inference attacks can have potentially dangerous
consequences as the text typed can often be private in nature,
and can sometime even contain sensitive information, such as
credit card numbers, authentication codes, and addresses. Side-
channel keystroke inference threats have utilized electromag-
netic emanations from keyboards [49], optical or visual cues
[44], [47], [28], Wi-Fi channel state information [20], [33],
audio or acoustic signals from keyboards [22], [24], [57], [31],
[56], [29], [21], typing-related table vibrations captured by a
nearby sensor [39], smartphone motion sensors (to infer text
typed on the smartphone) [25], [40], [42], [54], and wearable
motion sensors [51], [35], [50], [36], [38]. Among these prior
works, [29] and [21] are the most closely related research
efforts to ours. Both works demonstrated the feasibility of
accurate keystroke inference threats from keystroke sounds
propagated over a video call. However, as mentioned earlier,
such sound or audio based threats may not be practical be-
cause of naturally occurring interferences (such as participants
talking) and background noise-cancellation techniques being
used by many video calling applications [6], [18] that also
eliminates/reduces the propagation of keystroke sounds.
Inference Attacks Using Visual Side-Channels. With the
recent ubiquity of video capturing hardware embedded in
many consumer electronics, such as smartphones,
tablets,
and laptops, the threat of information leakage through visual
channel has ampliﬁed. Moreover, high-end digital cameras and
lenses have also trickled down to the consumer market at
competitive prices, making them easily accessible to an ad-
versary. Earlier works leveraged upon optical emanations from
monitors [32] or from eyes [23] to infer information such as
content being displayed or watched. More recent works studied
information leakage due to outdoor light effusions, such as
inference of multimedia consumption [37], [53] and private
data exﬁltration using smart lights [37], [43]. A few research
works also leveraged on visual side-channel for keystroke
inference threats. Simon and Anderson [44] were able to infer
keystrokes made on a smartphone based on visual movements,
captured from the on-device camera, that occurred as a result
of individual keystrokes. Similarly, Sun et al. [47] were able to
infer keystrokes typed on a tablet just from visual observation
of the rear side of the tablet. Chen et al. [28] leveraged on
users’ eye movements for touchscreen keystroke inference. To
the best of our knowledge, our paper is the ﬁrst work that
proposes and evaluates a keystroke inference framework that
solely leverages body movements observable in video calls.
III. BACKGROUND
In this section, we describe the different factors affecting
typing-related body movements observable in a video call.
Muscles, Joints and Motor Control. Human bodily move-
ments, clinically known as motor functions, are achieved
primarily through movement of joints. Joints are formed where
two or more bones are connected via ligaments, a ﬂexible
ﬁbrous connective tissue which binds together bones and/or
cartilages. These joints allow several degrees of freedom in
the human body. With the help of muscles that wrap around
the bones and connect to the bones via tendons, along with
motor control signals from the brain that appropriately engages
the required set of muscles, the human body can carry out
tasks through coordinated joint movements. Tasks may range
from basic balance and stability of the body to more complex
actions, such as running or typing on a keyboard. Also,
most tasks are actuated through movement of multiple joints
simultaneously, rather than just one at a time. Figure 16a
(Appendix A) shows an overview of the shoulder and arm
bones, and their joints, which when engaged in a series of
harmonious movements can enable a human to type hundreds
of words per minute [41].
When a user starts typing a sentence, the initial set of
joint movements are signiﬁcantly dependent on the keyboard
positioning and user’s typing habits (i.e., the set of motor
control signals learned by the brain). A user can exercise
an elbow joint, shoulder joint or joints from the Carpus
and Metacarpus regions or a combination of all of them,
that ultimately positions the user’s ﬁnger on the initial key.
The joint movements associated with keystrokes following the
initial keystroke depends primarily on the user’s typing style,
e.g., hunt-and-peck, touch-typing, or hybrid (more details on
typing styles in Appendix B). Certain typing styles, such as
hunt-and-peck, result in signiﬁcant upper hand movements
(not just ﬁngers or wrist) between keystrokes, than others.
For instance, in hunt-and-peck typing the elbow, shoulder, and
Carpus joints are heavily utilized, whereas in touch-typing the
Carpus, Metacarpus, and Phalanges joints are heavily utilized.
Reaction Force of a Keystroke. A common phenomenon
observed across all typing styles is that whenever the user
presses a key, a reaction force is produced in the opposite
direction (Newton’s third law of motion). This reaction force
propagates throughout the arm and shoulder muscles and joints
until the force is absorbed by the body. As a result, even if the
user uses only the joints in the Phalanges bones to press a key,
one can visually observe subtle arm and shoulder movements
due to the reaction force exerted by the key on the user’s hand.
However, the ﬁve ﬁngers of each hand are connected through
different bones in the wrist, that have different joints in the
Carpus area as shown in Figure 16a (Appendix A). As a result,
the reaction force of a keystroke propagates slightly differently
through the arm and shoulder muscles and joints, depending on
which ﬁnger was used to press the key. Visually, this translates
to distinguishable types of upper hand movements (which is
observable through a webcam during a video call) for key
presses with different ﬁngers.
Characteristics of the Available Call Data. During a typical
video call, an adversary can leverage two different types of
information for inferring keystrokes made during the call.
(1) Video Data or Feed: Most modern video calling appli-
cations employ a webcam to capture the visual and/or audio
signals during the call. The webcam’s camera sensor captures
the visual image of the target subject and his/her surroundings
as a series of two-dimensional images, also known as frames.
In other words, a video is a chronological ordering of two
dimensional images or frames, displayed in that order at a very
high rate or speed (often measured in frames/second or f ps in
short). A typical modern webcam can capture 30 or 60 f ps,
and at 1280×720 (921,600 pixels) or 1920×1080 (2,073,600
pixels) resolution per frame. Based on the traditional position
of a webcam during a video call, lateral movements of hand
2
and shoulder can easily be observed in the captured video
(Figures 16b and 16c in Appendix A).
(2) Audio Data or Feed: The sound during a video call
is typically captured either using a microphone sensor inte-
grated within the webcam or using an external microphone.
The captured sound often contains both the user’s voice
(or speech) and background/ambient noise, including sound
related to the keystrokes made by the user or any other
activities performed by the user during the call. Video calling
softwares also often implement audio optimizations, such as
dampening/ﬁltering of non-vocal frequencies [6], [18] and
echo suppression/cancellation. Most modern microphones can
record audio signals at 44, 100Hz or more, and such high-
ﬁdelity audio can capture ﬁne-grained audio characteristics.
However, a microphone may not always be enabled by the user
during a video call, as observed in the recent popularity of the
push-to-talk feature provided by most video calling software
that lets a user mute sound at the push of a button. Also,
during multi-participant video conference calls, it is a common
courtesy or etiquette for participants to mute their microphone
when they are not actively speaking. Nonetheless, while our
attack framework employs only the available video data for
keystroke inference, we assume the availability of audio data
for comparative evaluation with a prior work [29].
IV. ADVERSARY MODEL
The goal of an adversary in our setting is to infer keystrokes
typed by a target user at the opposite end of a video confer-
ence/call by just employing the video feed from the call. To
undertake a purely video-based keystroke inference attack, we
assume that the adversary ﬁrst records the video feed of the call
where the target user was a participant, and that the target user
typed private text on her/his keyboard during the call. More
speciﬁcally, we assume a ﬁeld-of-view of a typical desktop or
laptop webcam where the video stream would consist of only
visible upper body movements of the user (and not the actual
keys being typed as then the attack would be trivial), as shown
in Figure 17 (Appendix C). Additionally, we assume that both
shoulders and upper arms are within the ﬁeld-of-view of the
webcam, which is a practical assumption because desktop and
laptop webcams are often positioned centrally with respect to
the user. In addition to targeting participants in live video calls,
an adversary could also potentially target videos obtained from
public video sharing/streaming platforms such as YouTube [16]
and Twitch [12]. Many live streamers interact with their laptop
or desktop during a live video exposition, which could include
sensitive typed information, and thus, potentially targeted by
an adversary. As outlined earlier, the recorded video is nothing
but a series of picture frames sampled at a constant frequency,
and the adversary’s goal is to utilize the observable upper
body movements across all the recorded frames to infer the
private text typed by the target. The adversary does not have
any other medium of inferring the private text typed, and must
rely entirely on the video stream. This makes our attack more
practical as it can target not only real-time video calls (both
in a public and private setting), as well as, archived videos of
live exposition/events.
A. Overview
V. ATTACK FRAMEWORK
To draw a relationship between typing related body move-
ments observable in the video (Figure 16 in Appendix A) and
3
Fig. 1: Overview of the keystroke inference framework.
the text being typed, the adversary has to formulate two key
procedures. First, within the video stream the adversary must
be able to accurately identify the occurrences of keystrokes
based on the upper body movements. Second, by modeling
the body movement characteristics immediately before, after,
and in-between detected keystrokes, the adversary must be
able to accurately predict words and sentences typed by the
target user. Let’s ﬁrst intuitively describe how the adversary
can accomplish these objectives by giving an overview of the