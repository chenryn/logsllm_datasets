a(LK) = LOCKED
− evol(ξi
a) = {ξ : ξ(LK) = ξi
f , ξi
− meas(ξi
f ) = {ξ : ξ(LK) = ξi
a(LK)}
f (LK), ξ(PS) = (if ξi
f (presence) =
TRUE DETECTED else CLEAR), ξ(SP) = (if ξi
f (voice) =
“I am home” DETECTED else CLEAR)}. The timestamp i =
0··· n denotes the discrete time clock
s(xi) : xi ∈ ˜x};
s(x) = v.
f (presence) = FALSE, ξ0
f (voice) =
EMPTY, ξ0
f (LK) = LOCKED
4In reality, a physical feature (i.e., temperature) may be influenced by other
factors (e.g., outdoor temperature, humidity) and has uncertainty.
and the process P is the parallel composition of the following
sub-processes;
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:31 UTC from IEEE Xplore.  Restrictions apply. 
16300
− SenPS = read PS(val).snd eventA(PS, val).idle.SenPS
− SenSP = read SP(val).snd eventB(SP, val).idle.SenSP
− SenLK = read LK(val).snd eventA(LK, val).snd eventB(LK, val)
− ActLK = rcv cmdA(LK, val).wrt LK(val).idle.ActLK
− SrvPltA = rcv eventA(id, val).snd updateA(id, val)
+ rcv cmdB(LK, val).wrt LK(val).idle.ActLK
.idle.SenLK
.snd triggerR1(id, val).idle.SrvPltA
+ rcv actionR1(id, val).snd cmdA(id, val).idle.SrvPltA
− SrvPltB = rcv eventB(id, val).snd updateB(id, val)
(cid:9)
.snd triggerR2(id, val).idle.SrvPltB
+ rcv actionR2(id, val).snd cmdB(id, val).idle.SrvPltB
− RuleR1 = rcv triggerR1(id, val).if (id, val = PS, DETECTED)
(cid:8)snd actionR1(LK, UNLOCKED).idle.RuleR1
(cid:8)idle.RuleR1
− RuleR2 = rcv triggerR2(id, val).if (id, val = SP, DETECTED)(cid:8)
} else {idle.RuleR2}(cid:9)
snd conditionR2(LK).τ.rcv resR2(value in db(LK)).
if (value in db(LK) = UNLOCKED) {snd actionR2(LK, LOCKED)
else(cid:8)idle.RuleR2
(cid:9) else
− DBA = rcv updateA(id, val).update db(id, val).idle.DBA
− DBB = rcv updateB(id, val).update db(id, val).idle.DBB
(cid:9)
+ rcv conditionR2(id).τ.snd resR2(value in db(id)).idle.DB
Selective Event/Command Delaying Attack. As dis-
cussed in Section II-D,
the attacker can hijack and se-
lectively delay specific events or commands on a chan-
nel. To model the attack, we write Delay (c, c′, id, val, t) =
rcv c(x, y).idlet.snd ¯c′⟨x, y⟩.idle.Delay to denote a delay at-
tack process that delays the value-passing on channel c by t ∈
N time units. idlet.P is a shorthand for idle.··· .idle.P
where idle appears t consecutive times. t is a positive integer
if the received data (x, y) from c is an event (command) which
is produced by (destined to) a device with identifier id and has
a value equal to val; otherwise, t is equal to 0. Thus, a smart
home system Sys = E (cid:49) P being attacked becomes Sys(˜t) =
E (cid:49) P (˜t), where P (˜t) = P (˜c → ˜c′)∥ Delay (˜c, ˜c′, ˜id, ˜val, ˜t).
Specifically, P (˜c → ˜c′) substitutes new channels ˜c′ for ones
˜c that are used by the rcv actions in P. The sub-processes
that read from the attacked channels ˜c are converted to ones
that read from the corresponding channels ˜c′ maintained by
the delay attack processes.
Labelled Transition Semantics. A smart home system is
modelled as a labelled transition system (LTS) in the structural
operational semantics (SOS) style. The transitions are of kind
P α−→ Q for actions (a.k.a., labels) ranged over by α in the set
{idle, τ, snd c⟨v⟩, rcv c(x), read s(x), read a(x), wrt ¯a⟨v⟩}.
The transition rules are shown in Table VIII. Most of them
are the same as the standard ones [41], [42], except that
we distinguish the transition rules for parallel compositions
under delay-absent
situations where
(NoDelayCom) and (DelayCom) are used, respectively. For
and delay-present
brevity, we sometimes use the original notations Sys = E (cid:49) P
to denote a system under delay attacks, without rewriting the
attacked channels.
C. Formal Verification and Categorization of DAI Attacks
We use a shorthand Sys = E◦ ˜R[ ˜D ▷ ˜L] to denote a system
where each rule Rj ∈ ˜R run on a platform Lj ∈ ˜L and
reads/writes a set of devices Dj ∈ ˜D. To make a practical
sense, we only consider well-formed systems where every
platform has access to all devices used by the rules running
on it, i.e., Dj ⊂ ( ˜S ∪ ˜A). E denotes the physical environment.
Consider an attack-present system Sys = E ◦ (R1[(D1 ▷
L1]∥ R2[(D2 ▷ L2]) where two automation rules R1 and R2
are installed on two platforms L1 and L2, respectively. L1
and L2 can be the same or different platforms. We define
a specification system which runs R1 and R2 on an oracle
platform L which accesses devices without any delays, i.e.,
Sys∗ = E ◦ (R1[(D1 ▷ L∗]∥ R2[(D2 ▷ L∗]). Sys and Sys∗
describe the real system and the mentally expected system by
users, respectively.
Verification in SPSP Systems. A recent work [12] adopts
Generalized Non Deducibility on Composition (GNDC) [78]
to define a CRI-free system: a rule R1 does not interfere with
another rule R2 if the compositional runtime behavior of R1
and R2 does not differ from the behavior of R2 when running
along. Formally, R1 does not interfere with R2 under a hiding
weak bisimulation notion:
E ◦ (R1[(D1 ▷ L] ∥ R2[(D2 ▷ L]) ≈HR1 E ◦ R2[(D2 ⊢ L)]
def= obserable(R1) denoting a set of hidden actions of
for HR1
R1 that yield to observable results. Two rules R1 and R2 are
CRI-free when R1 and R2 do not interfere with each other.
(1)
However, this only considers an SPSP scenario where all
automation rules run on a platform equivalent to an oracle
platform L∗ and can only detect CRI rooted from mis-
programming or mis-configuration, subject to the same lim-
itations of other existing work [5], [6], [7], [9].
Verification in SPMP and MP Systems. In this paper, we
aim to model the uncovered CRI scenarios in a situation where
two rules automation rules R1 and R2 may run on different
platforms and the communication channels suffer from delays.
In this sense, R1 and R2 are CRI-free if in addition to the
hiding weak bisimulation, a standard weak bisimulation holds:
E ◦ (R1[D1 ▷ L1] ∥ R2[D2 ▷ L2]) ≈ E ◦ (R1[D1 ▷ L
∗
] ∥ R2[D2 ▷ L
∗
])
(2)
Formula 2 ensures that the interactions between R1 and
R2 in the real system and specification system are equivalent
at every time unit. However, it is a sufficient but not nec-
essary condition. It is too strict to say that the real system
has a significant CRI problem if it only deviates from the
specification system at a specific time unit. For example, if
the attacker delays all communications evenly by one time
unit, the real system will lag behind the specification system
but may still produce the correct automation result. Thus,
verifying CRI with Formula 2 usually causes false alarms.
To address this problem, we define an idle-insensitive weak
bisimulation ≈idle. Let ⇒idle
denote a sequence
of zero or more transitions each of which could be a τ or
idle transition. We replace the notion of an experiment e=⇒
in the definition of standard weak bisimulation [41], [79] with
e=⇒
the
interaction between R1 and R2 are said to be CRI-resistant,
if it holds that
α1−→⇒idle ··· ⇒idle
α1==⇒⇒idle. Thus,
−−−−−−→∗
{τ,idle}
def=⇒idle
idle
def=
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:31 UTC from IEEE Xplore.  Restrictions apply. 
17301
TABLE VIII: LTS for processes. ⇒def=→∗ denotes a sequence of zero or more τ transitions τ−→. α1···αn
interleaving a sequence of α transitions with any number of τ transitions.
=====⇒def=⇒ α1−−→⇒ ··· ⇒ α1==⇒⇒ denotes
(Out)
(In)
snd c⟨v⟩.P
–
snd c⟨v⟩
−−−−−→ P
–
rcv c(v)
−−−−−→ P{v/x}
rcv c(x).P
α−→ P ′ α ̸= idle
α−→ P ′ ∥ Q
(Par) P
(Rec) P{ ˜w/˜x} α−→ Q H(˜x) = P
P ∥ Q
H⟨ ˜w⟩ α−→ Q
(Elapse)
–
idle−−−→ P
idle.P
(TimeNil)
(WriteAct)
(Sum)
(IfTrue)
(Else)
–
nil
idle−−−→ nil
–
wrt a⟨v⟩
−−−−−−→ P
wrt a⟨v⟩.P
α−→ P
π1.P
α−→ P
(cid:74)b(cid:75) = true P
if (b) {P} else {Q} α−→ P ′
(cid:74)b(cid:75) = false Q
if (b) {P} else {Q} α−→ Q′
π1.P + π2.Q
α−→ Q′
α−→ P ′
(ReadAct)
(ReadSen)
read a(x).P
read s(x).P
(NoDelayCom) P
(DelayCom) P
(TimePar) P
idle−−−→ P ′ Q
P ∥ Q
τ−⧸−→
idle−−−→ Q′ P ∥ Q
idle−−−→ P ′ ∥ Q′
–
read a(v)
−−−−−−→ P{v/x}
–
read s(v)
−−−−−−→ P{v/x}
rcv c(x)
−−−−−→ Q′
τ−→ P ′ ∥ Q′{v/x}
snd c⟨v⟩
−−−−−→ P ′ Q
P ∥ Q
snd c⟨v⟩
−−−−−→ P ′ Q
P ∥ Q
rcv c(x)
−−−−−→ Q′ Delay(c,c′,id,val,t)
====⇒ P ′ ∥ Q′{v/x}
idlet
E◦(R1[D1▷L1] ∥ R2[D2▷L2]) ≈idle E◦(R1[D1▷L∗] ∥ R2[D2▷L∗]) (3)
Provided a specific home deployment and attack strategy
(the target event/command), we can use Formula 3 to verify if
the system yields different automation results from a specifi-
cation system, or say if the real system has unique CRI issues
under the attack. We can easily prove that the two rules in the
running example always generate the correct result in SPSP
system even under delay attacks. However, when the two rules
run on different platforms, delaying the UNLOCKED value on
channel eventB results in a violation of Formula 3. Due to the
space limit, proofs are omitted.
Methodology for Systematic Categorization. To systemati-
cally and comprehensively discover possible DAI attacks that
cause CRI problems, we generalize a smart home deployment
and represent it as the smart home calculus parametric on
some enumerable factors (sensor measurements, automation
rules, attack strategies). We then enumerate these factors to
find violation scenarios of the CRI-free condition (Formula 3).
State explosion challenges exist since smart home deployments
are highly diverse and it is infeasible to enumerate all deploy-
ments and states. To address this challenge, we make several
assumptions or abstractions to reduce the complexity of smart
home deployments and the enumeration space.
First, we assume that the natural communication delays are
negligible compared to the injected delays by the attacker. We
omit the sub-processes that only forward messages, such as
hubs, endpoint clouds, routers, and add up the communication
delays on these channels (if any) to the end-to-end delay
between a device and a platform.
Second, we simplify the models of IoT devices and rules.
Note that automation rules follow a trigger-condition-action
paradigm. A rule’s trigger is actually a boolean expression
that checks a device value (e.g., when temperature exceeds
75◦F ) and its condition is a set of such boolean expressions.
A rule action is not always binary (e.g., dim the light to 75%).
However, the interaction relation between a rule’s action and
another rule’s trigger, condition, or action is binary. For exam-
ple, one may ask if a rule R1’s action can control an actuator
(e.g., turn on lights) to a value that makes another rule R2’s
trigger (e.g., when the brightness is high) or condition (e.g., if
the lights are on) satisfied, or if the action is contradictory to
another rule R2’s action (i.e., turn off lights). Therefore, we
binarize the automation rules and device values. We consider
that each device has two values (0 and 1) and each rule deals
with binary values of devices. Without loss of generality, we
assume each rule condition only checks one device.
Third, we simplify the rule-device bindings. Without a
specific home deployment, one cannot know what devices
are bound to each rule. In our simplification, three devices
are granted to each rule for its trigger, condition and action,
respectively. Thus, two rules R1 and R2 choose from a set
of six devices D = {d1, d2,··· , d6}. In practice, a rule’s
trigger and condition always check different devices. We
pick D1 = {d1, d2, dk|k ∈ {1, 2, 3}} for R1 and D2 =
{di, dj, dk|di, dj, dk ∈ D; i ̸= j; x  3, y >
3, x ∈ {i, j}, y ∈ {j, k}} for R2. We only consider the
interactions between two automation rules R1 and R2 since
most, if not all, interactions among more than two rules contain
sub-interactions between two rules.
With the above abstractions, we enumerate the rules, rule-
device bindings, initial device states and the attacker’s target
events/commands and verify CRI in each configuration. In this
process, we observe that the attacks against some different
configurations essentially belong to the same category. There-
fore, we perform a manual qualitative analysis to combine the
similar attack scenarios and classify DAI attacks into seven
categories (see Section IV-B). Note that the above abstractions
are only for easing the exploration of possible attacks. Pro-
vided a specific deployment, our theoretic technique (calculus)
can verify CRI without the abstractions.
D. IRB Approval
We have received the approval from the Institutional Review
Boards (IRB) in the institution where all experiments are con-
ducted and all apartment residents (undergraduate and graduate
students) are affiliated with. The participants were recruited
following the IRB protocol and 500 USD was paid to the each
testbed. Devices and rules were furnished by the researchers.
Participants were informed of the possible outcomes caused
by the attacks and the experiments were monitored by the
researchers to avoid any hazards. The data collected from both
testbeds do not contain personally identifiable information and
are stored in a secure way. Only the researchers identified on
the IRB protocol have access to the data.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:31 UTC from IEEE Xplore.  Restrictions apply. 
18302