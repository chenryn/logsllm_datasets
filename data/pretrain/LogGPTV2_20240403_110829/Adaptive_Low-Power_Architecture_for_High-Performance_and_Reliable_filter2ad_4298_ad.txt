e
x
E
1024 2048 3072 4096 5120 6144 7168 8192 9216 10240
Matrix dimension
Figure 13. Comparison of the RA3 with varying number of multipliers
against a ABFT’ed GPU in terms of execution time.
in Table III. The fault injection campaign for the entire
benchmark is comprised of 672,348,891 injected faults. This
is achieved by using an instrumented FPGA-based emulation
of the hardware architecture, similarly to [25], which allows
for very high injection rates. For the entire benchmark,
the error detection coverage of the transactional core, i.e.,
the correction and detection error coverages summed up, is
99.9%. Considering only the corrected errors, the average
error correction coverage of the architecture is 98.7%.
The fault injection experiments of the RA3 core were
performed with six conﬁgurations of the RA3 core: 2, 4, 8,
16, 32 and 64 multipliers. We injected 50,000 faults in each
conﬁguration, for a total of 300,000 faults. The computation
workload is a matrix multiplication between two 16 × 16
integer matrices. The results are shown in Table IV. In the
entire fault injection campaign all non-masked errors were
at least detected, i.e., the RA3 core achieved a 100% error
detection coverage. In the RA3 core, the error correction
coverage starts at 94.94% for 2 multipliers, with a measured
546
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:31 UTC from IEEE Xplore.  Restrictions apply. 
FAULT INJECTION RESULTS OF THE TRANSACTIONAL CORE
TABLE III
Application
SET Correction
SET Detection
SEU Correction
SEU Detection
Total Coverage
No. of Faults Masked Faults
bbsort
lsquares
crc32
ﬂoyd
kruskal
matmul
99.86335%
99.12833%
99.68222%
99.62601%
99.10989%
99.10790%
0.06693%
0.66185%
0.29517%
0.27263%
0.77919%
0.76215%
99.83288%
98.83037%
97.89248%
99.81063%
92.08549%
99.16822%
0.06857%
0.79907%
2.02247%
0.08744%
7.79002%
0.67754%
99.92214%
99.74389%
99.97360%
99.89848%
99.88852%
99.86334%
10,808,861
44.20838%
882,007
44.97413%
20,169,300
13.88979%
254,465,240
44.97101%
109,994,127
49.08854%
276,029,356
43.20838%
FAULT INJECTION RESULTS OF THE RA3 CORE
TABLE IV
# of RA3 multipliers
2
4
8
# of corrected/non-masked errors
900/948
1563/1614
2727/2782
Error correction coverage
94.94%
96.84%
98.02%
# of RA3 multipliers
16
32
64
# of corrected/non-masked errors
4345/4414
6693/6753
9236/9289
Error correction coverage
98.44%
99.11%
99.43%
error correction coverage of 99.43% for 64 multipliers.
The observed number of masked faults decreases when the
number of multipliers increases because more bits become
sensitive, i.e., the time spent in the multipliers becomes
preponderant in the total computation time. Although more
bits are sensitive to upsets, these same bits can be considered
as un-ACE bits in the system level, because these errors are
contained inside the RA3 core and are further detected or
corrected, leading the computed output to be correct.
Because the fault injection campaign considered faults in
all architectural components, there was a small number of
errors that were not detected. These errors are due to faults
injected in the address of the data that will be written in
memory just after the comparator inside the transactional
core and right before memory is actually written. To reduce
the probability of this case, we could add more comparators
until the probability of not detecting an error is acceptable
for the system designer, paying the costs of area, power, and
latency. Another solution would be the transactional core to
encode all data with ECC so that the memory controller
could later check if the ECC is correct before writing the
data in memory. However, non-detected errors account for
less the 0.1% of all the fault injection campaign.
The results presented in this paper is a major contribution,
because until now in the published literature there is not a
single methodology that saves power and area wrt. TMR
with the same high error coverage as TMR while reducing
the performance overhead to a bare minimum. TMR is
really difﬁcult to beat in performance because its perfor-
mance overhead is negligible and it scales linearly with
the circuit’s complexity [29]. Usually, to overcome the high
area occupation and power consumption that TMR imposes,
fault tolerance solutions either relax their requirements in
performance or error coverage.
V. RELATED WORK
Atomic execution in hardware is usually linked with
‘transactional memory’ (TM) [30]. FaulTM [31] uses TM
to provide fault-tolerance at the thread level. In FaulTM, a
thread is duplicated and the two versions execute the same
set of instructions in two different cores. Right before the
thread’s memory store, the read/write instruction sets are
compared, and if they do not match an error is signaled.
The problem with this approach is the rollback scheme. The
error detection takes place right before a store instruction
by comparing the register set of the two threads and their
write sets. Because a thread usually executes thousands of
instructions interleaved with load and arithmetic ones, the
FaulTM would have to re-launch the faulty thread to some
unknown region of its code section, which is clearly not
feasible, because the authors claim that the rollback is simply
to re-launch the thread. In addition, when the thread is re-
launched, it is necessary some mechanism not mentioned in
[31] to recover the architectural context to its state before
the ﬁrst execution of the erroneous code chunk.
DIVA [9] is an architecture where its pipeline checks
the integrity of executed instructions before they commit.
The checking mechanism receives as input the instructions
from the reorder buffer of the execute stage and their inputs
and outputs. The checking re-executes the instruction, and if
there is any mismatch, DIVA signals an error. DIVA assumes
that the store instructions are correct, making it unfeasible
for realistic critical systems. In addition,
if an error is
detected at any branch instruction, the authors in [9] do
not discuss how the control-ﬂow could possibly be restored,
given that an erroneous branch instruction could lead to the
execution of several wrong instructions. Razor [32] extends
DIVA to allow dynamic voltage scaling by introducing the
‘shadow latch’, but the problem with the rollback of wrong
control-ﬂow execution is still not solved.
Selective replication [33] is an error detection technique
based on duplicating some portions of the pipeline (fetch,
rename and commit) of a superscalar architecture to reduce
the overhead associated with full core duplication. The idea
547
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:31 UTC from IEEE Xplore.  Restrictions apply. 
is to fetch multiple copies of a ‘reliable’ instruction, rename
their registers in an augmented register alias table, and
vote them at the end in the commit stage increased with
voting logic. Selective replication has an average overhead
is 53.1% less than full pipeline duplication, making it 16.5%
in average slower than the unreliable baseline architecture.
The reported error detection coverage is 97% for data-errors
and 62.5% of the manifested instruction errors.
Stochastic computing [34] is an approach for allowing
errors in computation. In this approach, the execution of
programs produces results within an error margin instead of
pursuing an exact value. In the software side, the programs
are transformed into a numerical optimization problem, and
the program execution is given by computing the gradient
descent method. The transformation is called application
robustiﬁcation [34]. In the hardware side, there is an archi-
tecture that computes the gradient descent method and that
embodies the error margin within it. The current problem of
this approach is that the authors do not give an automatic
program transformation that takes an imperative program
and yields an equivalent one in the gradient descent form.
However, this approach is interesting because it is not always
the case that a 100% correct result must be always produced,
e.g., in soft real time applications.
In the case of GPU reliability, the On-Line ABFT allows
for error detection in parallel with the matrix multiplica-
tion computation [28]. The authors report how the On-
Line ABFT behaves when executed in a GPU card, but
mentioning neither power nor energy. The use of ABFT on
GPU cards was evaluated further in [35] based on actual
radiation experiments performed with the Vesuvio particle
accelerator located at the ISIS facility in the UK [36]. The
actual GPU radiation data shows the feasibility of ABFT
under radiation even for detecting and correcting multiple
errors [35]. This result is important because ABFT was
designed to handle single errors [22]. The studies of how
ABFT behaves on GPU were important to shed light in the
feasibility of ABFT for actual radiation environments, and
the empirical results support its use for reliability.
VI. FINAL REMARKS
This paper presented the MoMa architecture for reliable
and low-power embedded computing. MoMa was exten-
sively evaluated in terms of performance, area, error cov-
erage, and power, showing that it meets all requirements of
reliable embedded computing elicited in Section II.
The TBB was introduced as a mechanism of error cor-
rection for general purpose computing, which is based on
the idea of executing a set of instructions as an atomic
transaction. If this set of instructions is correct, they are
allowed to modify the memory. Otherwise,
they are re-
dispatched for execution. The TBB allow for fast repair
in case of data-ﬂow and control-ﬂow errors, because the
worst case cost to correct the error is constant and can be
decided at compilation time. This fact gives MoMa high
predictability, making it easier to measure the impacts of
the reliability mechanism. In addition, the transactional core
avoids the duplication of the register ﬁle and reduces its size,
decreasing considerably the architecture vulnerability.
We have also discussed about MoMa’s RA3 core, which
is a dedicated and resilient matrix multiplication hardware.
This core implements ABFT as its error detection and
connection technique, making it possible to execute efﬁ-
ciently some dedicated tasks that are fairly common in the
embedded system domain such as data transforms. We have
compared this core with an GPU implementing ABFT in
software, showing the performance overhead it achieves.
As discussed in Section IV-B,
the transactional core
accounts for 5.82% of the total peak power that MoMa
dissipates. Therefore,
there’s a big room for optimizing
the interplay between the transactional core and the RA3
through hardware adaptation implemented with ‘power gat-
ing’. The design of such hardware module is our main future
work to improve the MoMa architecture.
An important future work is the radiation test of the
MoMa architecture in order to proof-test it in its actual
radiation environment using an FPGA. The challenge of
this test is to separate the errors that occur in the MoMa
architecture from the errors that occur in the FPGA’s con-
ﬁguration memory. This is a challenge because there is not
an established way in the published literature of doing so.
Therefore, the radiation test setup that we are designing to
test MoMa will also be an important contribution for the
radiation test community.
REFERENCES
[1] R. Baumann, “Soft errors in advanced computer systems,”
IEEE Design and Test of Computers, vol. 22, no. 3, pp. 258–
266, May 2005.
[2] ITRS, “ITRS 2012 roadmap,” International Technology
Roadmap for Semiconductors, Tech. Rep., 2012.
[3] T. Konefal et al., “A statistical model to estimate an upper
bound on the probability of failure of a system installed on
an irradiated vehicle,” IEEE Transactions on Electromagnetic
Compatibility, vol. 49, no. 4, pp. 840–848, 2007.
[4] A. Keys et al., “High-performance, radiation-hardened elec-
tronics for space and lunar environments,” in AIP, vol. 969,
2008, pp. 749–756.
[5] J. Penix and P. Mehlitz, “Expecting the unexpected: Radiation
hardened software,” NASA Ames, CA, Tech. Rep., 2005.
[6] NASA, “Next generation space processor – solicitation num-
ber BAA-RVKV-2013-02,” feb 2013.
[7] P. Rech et al., “Neutron-induced soft errors in graphic pro-
cessing units,” in REDW ’12:Radiation Effects Data Work-
shop.
IEEE, 2012, pp. 1–6.
548
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:31 UTC from IEEE Xplore.  Restrictions apply. 
[8] H. Esmaeilzadeh et al., “Dark silicon and the end of multicore
scaling,” in ISCA ’11: annual international symposium on
Computer architecture. ACM, 2011, pp. 365–376.
[23] N. Muralimanohar, R. Balasubramonian, and N. P. Jouppi,
“CACTI 6.0: A tool to model large caches,” HP Laboratories,
Tech. Rep., 2009.
[9] T. Austin, “DIVA: a reliable substrate for deep submicron
microarchitecture design,” in MICRO 32: int. symp. on Mi-
croarchitecture, 1999, pp. 196–207.
[10] Y. Yetim, M. Martonosi, and S. Malik, “Extracting useful
computation from error-prone processors for streaming ap-
plications,” in DATE ’13: Design, Automation and Test in
Europe, 2013, pp. 202–207.
[11] H. Esmaeilzadeh et al., “Architecture support for disciplined
approximate programming,” in ASPLOS ’12: Architectural
Support for Programming Languages and Operating Systems.
ACM, 2012, pp. 301–312.
[12] H. Chen and C. Yang, “Fault detection and recovery efﬁciency
co-optimization through compile-time analysis and runtime
adaptation,” in CASES ’13: int. conf. on Compilers, Arch.,
and Synthesis for Embedded Systems. ACM, 2013, p. 10.
[13] J. A. Blome et al., “Cost-efﬁcient soft error protection for
embedded microprocessors,” in CASES ’06: Compilers, Ar-
chitecture and Synthesis for Embedded Systems. ACM, 2006,
pp. 421–431.
[14] J. Lee and A. Shrivastava, “Software-based register ﬁle vul-
nerability reduction for embedded processors,” ACM Trans.
Embed. Comput. Syst., vol. 13, no. 1s, pp. 38:1–38:20, Dec.
2013.
[15] T. Kranenburg and R. Van Leuken, “MB-LITE: A robust,
light-weight soft-core implementation of the MicroBlaze ar-
chitecture,” in DATE ’10: Design, Automation Test in Europe.
IEEE, 2010, pp. 997–1000.
[16] J. Yan and W. Zhang, “Compiler-guided register reliability
improvement against soft errors,” in EMSOFT ’05: int. conf.
on Embedded software, 2005, pp. 203–209.
[17] M. R. Guthaus et al., “Mibench: A free, commercially repre-
sentative embedded benchmark suite,” in WWC ’01: Workload
Characterization.
IEEE, 2001, pp. 3–14.
[18] J. E. Miller and A. Agarwal, “Software-based instruction
caching for embedded processors,” in ASPLOS ’06: Archi-
tectural support for prog. languages and operating systems.
ACM, 2006, pp. 293–302.
[19] A. Chaudhari, J. Park, and J. Abraham, “A framework for low
overhead hardware based runtime control ﬂow error detection
and recovery,” in VTS’ 13: VLSI Test Symposium.
IEEE,
2013, pp. 1–6.
[20] D. Bernick et al., “NonStop advanced architecture,” in DSN
IEEE, 2005, pp.
’05: Dependable Systems and Networks.
12–21.
[21] F. Itturriet et al., “Adaptive parallelism exploitation under
physical and real-time constraints for resilient systems,”
in ReCoSoC ’12: Reconﬁgurable Communication-centric
Systems-on-Chip.
IEEE, 2012, pp. 1–8.
[22] K.-H. Huang and J. Abraham, “Algorithm-based fault toler-
ance for matrix operations,” IEEE Transactions on Comput-
ers, vol. 33, no. 6, pp. 518–528, Jun. 1984.
[24] N. Binkert et al., “The gem5 simulator,” SIGARCH Comput.
Archit. News, vol. 39, no. 2, pp. 1–7, Aug. 2011.
[25] M. Aguirre, V. Baena, J. Tombs, and M. Violante, “A new
approach to estimate the effect of single event transients in
complex circuits,” IEEE Transactions on Nuclear Science,
vol. 54, no. 4, pp. 1018–1024, 2007.
[26] E. Petersen, Single Event Effects in Aerospace, 1st ed. Wiley-
IEEE Press, 2011.
[27] S. Mukherjee et al., “A systematic methodology to compute
the architectural vulnerability factors for a high-performance
microprocessor,” in MICRO 36: International Symposium on
Microarchitecture.
IEEE, 2003, pp. 29–41.
[28] C. Ding et al., “Matrix multiplication on GPUs with on-
line fault tolerance,” in ISPA ’11: Parallel and Distributed
Processing with Applications, 2011, pp. 311–317.
[29] R. Hentschke et al., “Analyzing area and performance penalty
of protecting different digital modules with hamming code
and triple modular redundancy,” in SBCCI ’02: Integrated
circuits and systems design.
IEEE, 2002, pp. 95–100.
[30] M. Herlihy and J. Moss, “Transactional memory: architectural
support for lock-free data structures,” in ISCA ’93: interna-
tional symposium on computer architecture. ACM, 1993,
pp. 289–300.
[31] G. Yalcin, O. Unsal, and A. Cristal, “FaulTM: error detection
and recovery using hardware transactional memory,” in DATE
’13: Design, Automation and Test in Europe.
IEEE, 2013,
pp. 220–225.
[32] D. Ernst et al., “Razor: a low-power pipeline based on
circuit-level timing speculation,” in MICRO 36: int. symp.
on Microarchitecture.
IEEE, 2003, pp. 7–18.
[33] N. Nakka, K. Pattabiraman, and R. Iyer, “Processor-level
selective replication,” in DSN ’07: Dependable Systems and
Networks.
IEEE, 2007, pp. 544–553.
[34] J. Sartori, J. Sloan, and R. Kumar, “Stochastic computing:
embracing errors in architecture and design of processors and
applications,” in CASES ’11: Compilers, architectures and
synthesis for embedded systems, 2011, pp. 135–144.
[35] P. Rech et al., “An efﬁcient and experimentally tuned
software-based hardening strategy for matrix multiplication
on GPUs,” IEEE Transactions on Nuclear Science, vol. 60,
no. 4, pp. 2797–2804, 2013.
[36] C. Andreani et al., “Facility for fast neutron irradiation tests
of electronics at the ISIS spallation neutron source,” Applied
Physics Letters, vol. 92, no. 11, pp. 114 101–114 101–3, 2008.
*This work is supported by the Conselho Nacional de Desenvolvimento
Cient´ıﬁco e Tecnol´ogico (CNPq), Brazil.
549
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:31 UTC from IEEE Xplore.  Restrictions apply.