on typical BGP policies and the priority order suggested [8].
1. A route with a higher local preference value is pre-
ferred. As local preference values are not available for
most of the router dumps, we simply rely on the cus-
tomer > peer > provider policy using standard tech-
niques for inferring AS relationships [20].
2. A route with a shorter AS path is preferred.
3. A route with a smaller MED value is preferred.
110100020%40%60%80%100%Average number of network locations per user per dayCDF across 372 users  IP addressesIP prefixesASes0.1110100020%40%60%80%100%Number of transitions among network locations per dayCDF across 372 users  IP addressesIP prefixesASes265Note that the above rules approximate typical BGP poli-
cies. The numerical value of local_preference is uniformly
0 in these RIBs, so we use AS relationships instead in the
(cid:12)rst rule. The RIBs also do not have suﬃcient information
to implement early- or late-exit policies that are typically of
higher priority than multi-exit discriminator values.
6.2.2 Update cost of name-based routing
To determine if the movement of a user from one address
to another results in a change in a router’s forwarding be-
havior, we must determine whether the the mobility event
induces a change in the output port corresponding to the
highest ranked route for the user’s address. We use the
next hop AS path attribute as a proxy for the output port,
implicitly assuming that the forwarding output port changes
if and only if the next hop attribute changes, an assumption
believed to hold more often than not [45]. In practice, diﬀer-
ent next hop addresses can correspond to the same output
port, and the same next hop can correspond to diﬀerent out-
put ports at diﬀerent times because of intradomain concerns,
so we may under- or over-estimate the actual update cost.
Figure 8 shows the update cost at all of the routers using
the RIB data published on Mar 31, 2014. The update cost
is shown as the fraction of all mobility events that induce
a forwarding update at the router, also referred to as the
update rate. The results show that the update rate can be
as high as 14% at some routers. The routers at Mauritius
and Tokyo experience hardly any updates, which is unsur-
prising as most of our users are located in the USA, Europe,
and South America, so their mobility is less likely to im-
pact distant routers. We veri(cid:12)ed that the Georgia router
has a much lower next-hop degree compared to the Oregon
routers, which could plausibly explain its lower update rate.
Figure 8: Fraction of device mobility events inducing
a routeviews router update.
Sensitivity analysis. We further investigated the sensi-
tivity of the above results to: (1) time, (2) the set of routers,
and (3) the mobility workload. For the (cid:12)rst, we repeated
the experiment for 20 diﬀerent days and found that, at ev-
ery router, the standard deviation of the update rate is less
than 0.005 (or 0.5%). For the second, we repeated the exper-
iment using 13 RIPE routers [7] located in 13 diﬀerent cities,
10 of which are distinct from the RouteViews set, and found
qualitatively similar conclusions: the update rate at the me-
dian (most aﬀected) router in the RouteViews and RIPE
sets were 3.15% (14%) and 2.74% (11.3%) respectively.
For the third, we resorted to a signi(cid:12)cantly larger dataset
[54] consisting of 7137 users from UMass IMAP servers that
recently became available to us. These traces measure user
mobility in a sense distinct from device mobility (an excep-
tion to the footnote in x6.1) as observed from a speci(cid:12)c (but
universally used) application’s perspective, so the two traces
are not directly comparable. Our preliminary analysis as
above, using user mobility as a proxy for device mobility,
shows that the update rates observed at all 25 RouteViews
and RIPE routers are highly correlated with those for the
NomadLog data, with a correlation coeﬃcient of 0.88 (with
more details deferred to the technical report [21]).
Back-of-the-envelope calculations.
Update cost: Combining the above results with the results
in the previous section, we can arrive at a crude estimate of
the absolute rate of updates induced at routers because of
user mobility today. For example, if 2 billion smartphones
change network addresses three (seven) times per day like
our median (mean) user, and 3% of these mobility events in-
duce an update at a router, the corresponding update rate is
2.1K/sec (4.8K/sec). These numbers are prohibitively high
for even high-end routers today. Although it is possible to re-
design router control planes to handle such high update rates
using more compute resources and a software-de(cid:12)ned con-
trol plane, it is diﬃcult to justify this computation cost and
the bandwidth cost of propagating these updates to a large
number of Internet routers. In comparison, it is straightfor-
ward to handle this aggregate load by distributing it across
a large number of DNS servers or home agents.
Forwarding table size: Combining the typical update rate
of 3% with the fact that users typically spend 30% of a
day away from the dominant IP address (see x6.3 below)
suggests that a typical router would have to maintain extra
forwarding entries for (cid:25)1% of all devices that are displaced
(as de(cid:12)ned in x3.1) with respect to it at any given time.
6.3 Data path stretch with device mobility
The update cost analysis above induces no data path stretch
(over underlying Internet routing) for name-based routing or
for a DNS-based approach. However, indirection routing in-
(cid:13)ates the data path because of triangle routing via the home
agent. Next, we quantify this path stretch overhead.
6.3.1 Displacement from dominant location
We introduce the notion of a dominant location, i.e., the
network location where a user spends the largest fraction
of time compared to all other locations in the course of a
single day. Figure 9 shows the distribution across all days
and all users of the percentage of time spent in the dominant
location. For example, the plot shows that over 40% of users
spend around 70% of their day at the dominant IP address
and around 85% of their day at the dominant AS.
The dominant location is a natural candidate for a home
agent in an indirection routing architecture. In order to com-
pute path stretch, we need to determine C!H!M/C!M,
where C!H!M is the sum of the network latency from a
correspondent C to the home agent H and that from H to
the mobile M, and C!M is the network latency of routing
directly from C to M. We do not have a dataset of cor-
respondents initiating communication with mobile devices
05%10%15%Oregon−1Oregon−2Oregon−3Oregon−4California−1GeorgiaVirginiaSaopaulo−1London−1MauritiusTokyoSydneyFraction of mobility events inducing a router update    266(because it is largely not possible today to initiate commu-
nication to mobile devices), so instead we simply quantify
the displacement of mobile users from their home agents in
network distance, i.e., the latency of the path from H!M.
Figure 9: The CDF of time that each user spends in
the dominant location.
6.3.2 Path stretch of indirection routing
In order to determine the network distance from a user’s
dominant location (or home) to their current location in the
NomadLog trace, we rely on iPlane, a system that uses daily
traceroute measurements from a large number of distributed
vantage points to stub networks in order to predict the route
(and its latency) between an arbitrary pair of IP addresses.
Although using iPlane is convenient, it comes with two se-
vere caveats for our analysis. First, iPlane returns valid re-
sponses for only 5% of the dominant and current IP address
pairs in our trace; this is because it is designed to return re-
sponses only if it has suﬃcient traceroutes that enable it to
constructed a predicted route using segments of measured
routes. Second, even when iPlane returns a response, the
predicted route may be inaccurate.
Figure 10 shows the distribution of network latencies across
the dominant-to-current IP address pairs for which iPlane
returned a predicted route. The median displacement delay
from the dominant location is around 50ms and the corre-
sponding AS hop count is 4. Recognizing the limitations
of the estimates obtained using iPlane, we use a diﬀerent
technique to estimate a lower bound on the AS hop count
of the displacement from home. We compute the length of
the shortest AS path from the home to the current location
using the Internet’s AS-level physical topology [2] (even if
this route may not exist in the AS-level routing topology).
The median AS hop count of this shortest AS path is 2,
suggesting that mobile users typically wander two or more
ASes away from the home AS.
7. CONTENT MOBILITY
In this section, we evaluate the cost-bene(cid:12)t tradeoﬀs in
terms of update cost, forwarding table size, and path stretch
for content mobility. We begin by describing the procedure
used to measure content mobility today.
7.1 Content mobility measurement
We begin with two sets of content domain names: a pop-
ular set and an unpopular set. The former is the set of the
top 500 domains ranked according to popularity by Alexa
[1] and the set of all of their subdomains. The latter is
the least popular 500 domains and their subdomains in a
Figure 10: Distribution of delay for the IP addresses
pairs that get response from iPlane.
list of the top 1 million domain names also ranked by pop-
ularity. We explicitly obtain a list of subdomains because
Alexa ranks \websites" or top-level enterprise domains, e.g.,
nytimes.com or yahoo.com, but not their subdomains like
graphics.nytimes.com or travel.yahoo.com. More impor-
tantly, the distribution of popular, bulky content that is
ideally suited to name-based routing techniques is often out-
sourced to CDNs, and a common technique to achieve this is
to CNAME-alias subdomains, e.g., graphics.nytimes.com
is aliased to the canonical name static.nytimes.com.edge
suite.net that is in turn aliased to a1158.g1.akamai.net
that (cid:12)nally gets dynamically resolved to one or more IP ad-
dresses close to the querying client or its local name server.
The dynamic nature of resolution of domain names to IP
addresses (either because they are resolved by a CDN del-
egate in a locality-aware manner or because of DNS-based
load balancing employed by the origin server) means that
any single vantage point will see only a subset of all IP ad-
dresses from where a domain’s content may be potentially
served. Our methodology to assess content mobility (in x3.3)
relies on monitoring any changes to the set of all IP addresses
corresponding to a domain name. This methodology implic-
itly assumes that a purely name-based routing network will
announce a content domain name from all of the locations
(including CDN locations) where it resides today.
In order to measure a reasonably complete set of IP ad-
dresses to which each domain name maps, we conduct a
measurement distributed across 74 Planetlab nodes that are
chosen from as many diﬀerent countries as possible and all
continents (except Africa where Planetlab nodes were un-
available). We conducted the measurements for a three week
period from May 1 to May 22, 2014. Each node resolves each
domain name once every hour, thereby observing a subset
of the domain’s IP addresses at that time. A central con-
troller node collects measurements obtained from all of the
vantage points and merges them in time so that for each
domain name for each hour, the set of IP addresses is the
union of all IP addresses obtained from all vantage points for
that domain. As the measurement interval once per hour,
precise time synchronization is not necessary. The measure-
ment is done just once per hour per domain because our list
of subdomains corresponding to the 500 most popular Alexa
domains contains 12,342 entries, so a much higher rate would
overwhelm some nodes or trigger security alarms.
7.2 Update cost of content mobility
Figure 11(a) shows the extent of daily mobility of popular
content (i.e., the 12,342 subdomains obtained from the most
020%40%60%80%100%020%40%60%80%100%Fraction of time in the dominant location per dayCDF across 372 users and all days  IP addressesIP prefixesASes0100200300400500600020%40%60%80%100%One−way delay (ms) from the home network locationCDF across all non(cid:26)home locationsacross all users observed in the trace (5%)267(a) The average number of transitions
for popular content mobility events
(b) Fraction of popular content mobility
events inducing a router update
(c) Fraction of unpopular content mobil-
ity events inducing a router update
Figure 11: Results on the extent of content mobility and its impact on the update cost at routers.
popular 500 domains). The median number of changes in the
set of IP addresses per day is 2 (the similarity to device mo-
bility being just coincidental) and the maximum is bounded
at 24 because of our hourly measurement procedure.
Figure 11(b) shows the update rate at each of the twelve
routers because of mobility events involving popular content.
The plot shows that up to 13% of content mobility events can
induce an update at some routers when controlled (cid:13)ooding
(i.e., forwarding on all ports matching any of the domain’s
IP addresses) is used. However, at most 6% of the mobility
events induce an update at any of the routers in our dataset
when best-port forwarding is used. The reason is that al-
though there may be some (cid:13)ux in the set of addresses corre-
sponding to a domain name, the address that is the closest
to any given router rarely changes because most of the ad-
dresses in the set remain unchanged, i.e., unlike devices that
jump seemingly randomly from one address to an unrelated
address, content locations do not change arbitrarily.
Figure 11(c) shows the corresponding result for unpopular
content or the least popular 500 domains and their subdo-
mains with a popularity rank of near about one million. The
update cost for unpopular content is dramatically lower than
that for popular content; at most 1% of updates induce an
update at any of the routers even with controlled (cid:13)ooding.
With best-port forwarding, almost none of the routers ex-
perience any update during the course of our measurement
period (the median is 0.08%). This result is not surprising
as unpopular content is unlikely to be delegated to CDNs
and is probably served only from a small number of network
locations that rarely change; these multiple locations if at all
are chosen mainly for fault-tolerance or load balancing pur-
poses rather than proximity to clients, so they rarely change.
We further explicitly estimated [21] the fraction of domains
delegated to CDNs in our trace for unpopular content to be
only 1.6% compared to 24.5% for popular content.
7.3 Forwarding table size
Figure 12 shows the aggregateability (as de(cid:12)ned in x3.3.2)
for the 500 most popular domain names on 12 routeviews
routers by using the best-port forwarding strategy. We see
that the aggregateability at diﬀerent routers varies between
2(cid:2) to 16(cid:2), which suggests a commensurate reduction in the
forwarding table sizes at these routers compared to the to-
tal number of popular content domain names. Unpopular
content domain names in our dataset have hardly any sub-
Figure 12: FIB aggregateability of popular content.
domains, which implies that content routers would have to
nominally store one entry each for the long tail of unpop-
ular content domain names, unless a diﬀerent ontological
structure that helps compact routing information is used to
rename them. With respect to forwarding table size, un-
popular content domain names present a challenge similar
to device names, i.e., they both entail one forwarding entry
per principal at a router unless a location-aware scheme (like
IP addresses or geo-location) is used to \rename" them.
Back-of-the-envelope calculations.
Performing a calculation similar to that at the end of x6, if
we assume 1B content domain names (noting that DNS has
(cid:25)150M domains), an update rate of 2/day, and a 0.5% like-
lihood of inducing an update at a router, the router would
receive at most 100 updates/sec. Furthermore, for the vast
majority of long-tail domains ranked below 1M, the update
cost is likely to be even lower even if controlled (cid:13)ooding is
used as the forwarding strategy. Finally, with best-port for-
warding, the router update cost due to the mobility for vast