these distinct values, after which the data bits (and there-
fore the rest of the coding bits) may be determined.
A graph that mirrors this line of thinking has the two
data bits in l1 and l2. The remaining left-hand nodes are
coding nodes, and each has exactly one edge from li to
ri−2. The constraint nodes are partitioned into three sets
— those whose coding bits equal l1, those whose coding
bits equal l2, and those whose coding bits equal l1 ⊕ l2.
Node l1 will have an edge to every constraint node in
the ﬁrst and third groups, and node l2 will have an edge
to every constraint node in the second and third groups.
The left-hand nodes whose values equal l1 compose a
set D1, and consist of l1 itself plus the coding nodes that
equal l1. There are d1 nodes in this set. D2 and d2 are
deﬁned similarly, including l2 and all coding nodes that
equal l2. Finally, D3 is composed of the coding nodes
that equal l1 ⊕ l2, and there are d3 of these nodes.
Suppose we download x bits, and all bits are from the
same set (D1, D2, or D3). Then the graph will remain
undecoded, since only nodes that belong in that group
will be determined. As soon as we have downloaded
nodes from two different sets, we may decode the entire
graph.
(cid:8)(cid:7)
Let us focus solely on downloading bits in order. De-
ﬁne pd1,i to be the probability that the ﬁrst i bits down-
loaded come from nodes in D1, and that the i + 1-st
bit does not come from nodes in D1. Each pd1,i for
1 ≤ i ≤ d1 is equal to:
(cid:7)
d1
(cid:7)
m + 2
d1 − (i − 1)
(cid:6)
(cid:5)
m + 2 − (i − 1)
(cid:6) .
(cid:5)
m+1−i
d1−i
m+2
d1 − 1
(cid:8)(cid:7)
m + 2 − 1
m + 2 − d1
m + 2 − i
pd1,i =
(cid:8)
(cid:8)
=
...
d1
the expected value of the overhead:
We may use pdx,i for each 1 ≤ i ≤ dx to calculate
d1(cid:2)
d2(cid:2)
d3(cid:2)
(i + 1)pd1,i +
(i + 1)pd2,i +
(i + 1)pd3,i
o =
i=1
i=1
i=1
= m + 3
m + 3 − d1
+ m + 3
m + 3 − d2
+ m + 3
m + 3 − d3
− 2.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:32 UTC from IEEE Xplore.  Restrictions apply. 
m = 3 UB_6
m = 3 using Lambdas
1.2
m = 4 UB_4
m = 4 using Lambdas
m = 5 UB_2
m = 5 using Lambdas
1.2
1.1
r
o
t
c
a
F
d
a
e
h
r
e
v
O
1.2
1.1
1.0
1
1.1
1.0
1000
1
10
100
n
10
100
n
1.0
1000
1
10
n
100
1000
Figure 5: Overhead factors of codes created with the Λ vectors from Table 2 as compared to the UBp codes.
Simple math yields that this equation is minimized
when d1, d2, and d3 differ by at most one.
If we
set d1 = d2 = d3 = m+2
3 , the equation for overhead be-
comes (5m + 13)/(2m + 7), whose limit as m → ∞ is
2.5. Interestingly, this means that even though the rate of
these codes approaches zero, the overhead approaches a
constant value – 2.5.
8 Graphs for n = 3: A limitation
of having only m constraints
7
3
(cid:6)
Extrapolating from the previous section, suppose n = 3,
and our three data bits are labeled b1, b2 and b3. Now,
(cid:5)
there are only seven possible values for a node: b1, b2,
(b1 ⊕ b2), b3, (b1 ⊕ b3), (b2 ⊕ b3), and (b1 ⊕ b2⊕ b3). Of
= 35 combinations of three distinct values, there
the
are seven that cannot decode the three data bits: [b1, b2,
(b1 ⊕ b2)], [b1, b3, (b1 ⊕ b3)], [b2, b3, (b2 ⊕ b3)], [b1,
(b2 ⊕ b3), (b1 ⊕ b2 ⊕ b3)], [b2, (b1 ⊕ b3), (b1 ⊕ b2 ⊕ b3)],
[b3, (b1 ⊕ b2), (b1 ⊕ b2 ⊕ b3)], and [(b1 ⊕ b2), (b1 ⊕ b3),
(b2 ⊕ b3)].
= 112
35
35 = 13
5 = 3.2.
Any combination of four distinct values will allow
one to decode the three data bits. Therefore, if we
have n = 3 and m = 4, and we encode by having each
of the seven bits contain a distinct value, then we can
always decode with three bits when we do not receive
one of the 3-bit combinations listed above. Otherwise,
we will decode in four bits. The overhead of such a de-
coding scheme is 28∗3+7∗4
Unfortunately, the optimal graph for n = 3 and m =
35 = 3.2286, meaning that the
4 has an overhead of 113
optimal graph does not decode optimally! To see why
this is true, consider the graph in Figure 7. This graph’s
overhead is 3.2286. Suppose we download nodes D, E,
and G. Since (b1 ⊕ b2) ⊕ (b1 ⊕ b3) ⊕ (b1 ⊕ b2 ⊕ b3) is
equal to b1, we should be able to decode all the bits from
these three values. However, when we remove nodes
D, E, and G from the graph, all constraint nodes have
more than one edge still incident to them, and we cannot
decode. This is where the extra 1
35 of overhead comes
from, and there is no graph with seven left-hand nodes
and four right-hand nodes that avoids this problem.
b1
A
F
b2+b3
D
b1+b2
B
b2
b1+b2+b3
G
b1+b3
E
C
b3
Figure 6: An optimal graph for n = 3 and m = 4.
To ﬁx this, suppose we add a ﬁfth constraint to the
graph, which is connected to nodes D, E, and G. Now,
although the graph no longer ﬁts the standard Tanner
Graph description (nor does it ﬁt our deﬁnition of a Sys-
tematic graph), it does decode optimally. We do not
explore this fact or these codes further; however, we
present it here as a curiosity, and as a seed of future work
on graph-based coding.
9 Related Work/Brief Discussion
the
paper
landmark Tornado Code
in
Since
1997 [LMS+97], the focus of most LDPC researchers
has been achieving asymptotic optimality. There are
rare exceptions, such as a paper analyzing certain
classes of ﬁnite codes [DPT+02], a paper deﬁning
classes of sub-optimal codes that perform well in prac-
tice [RN04], and our previous foray into Monte-Carlo
generation and analysis of ﬁnite-length codes [PT04].
The exceptions are rare, because the asymptotic is an
easier case in which to succeed. To illustrate this, con-
sider Figure 4. Whereas the simple graph construction
using the Λ vectors fails to produce graphs that perform
nearly optimally for small n, as n grows this graph con-
struction method performs very well. It would not be
too difﬁcult to prove that the overhead factors of these
graphs indeed approach one as n → ∞, meaning that
they are asymptotically optimal. Determining true op-
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:32 UTC from IEEE Xplore.  Restrictions apply. 
timality for ﬁnite n remains an open question, one that
we will continue to address.
An important question to ask, however, is: How
important is optimality? For example, when m =
4 and n = 100, the overhead of the UB4 code is
101.01073, and the overhead of the code generated by
the Λ vector is 101.01088. Are there any scenarios
in which that extra 0.00015 is signiﬁcant? Likely not.
However, consider the case where m = 4 and n = 4,
and a 1 GB ﬁle is broken up into 256 sets of eight
blocks (4 data and 4 coding) that are distributed among
faulty servers in the wide-area. When a client tries
to download this ﬁle, the difference between the opti-
mal overhead of 4.382 and the suboptimal overhead of
4.471 (generated by the Λ vector) will be signiﬁcant in-
deed. Until true optimality is determined, suboptimal
constructions such as the UBp and Λ codes in this paper
will be extremely useful. However, until optimal, ﬁnite
codes are fully understood, the ﬁeld of LDPC codes will
continue to be an open research area.
10 Conclusion
We have performed an exploration of optimal and
nearly-optimal LDPC erasure codes for small values
of n and m. We have detailed three mechanisms for de-
termining the overhead of a code exactly, and used these
determinations, plus enumeration techniques to generate
optimal codes for m = 2 and n = 2. For m ∈ {3, 4, 5},
we have generated codes with the best known upper
bounds for n less than or equal to 1750, 1000, and 1000
respectively.
As part of our exploration, we have made the follow-
ing observations, which should be an aid to others who
need to explore these codes:
- Optimal codes are not left-regular.
- However, the best codes appear to be loosely right
regular.
- They also appear to have a property that we call
edge class equivalence. Using the above two prop-
erties can be a great aid in pruning enumerations in
order to discover good codes.
- The various counts of distinct types of left-hand
nodes do not have to equal each other for a graph
to be optimal.
- In the best graphs with a ﬁxed m, the Λ vector
of edge count probabilities, which is the backbone
of classic LDPC coding theory [LMS+97, RU03,
WK03], appears to converge to a constant as n →
∞. This vector may also be used to generate graphs
that perform very close to optimal as n grows.
- For n > 2, the iterative decoding technique of
It is an open
LDPC’s cannot decode optimally.
question of how to modify the standard deﬁnition
of LDPC’s so that they can decode better.
The quantiﬁcation of optimal parity check codes for
arbitrary values of n and m remains an open question.
In this paper, we have deﬁned uppoer bounds, and we
have helped to narrow the range of n and m for which
we don’t know optimality. We will continue work to
narrow this range by trying to understand the properties
and structure of optimal codes, and using them to prune
the search so that it is a tractable endeavor.
References
[DPT+02] C. Di, D. Proietti et al—. Finite-length analysis of low-density
parity-check codes on the binary erasure channel. IEEE Trans. on
Inf. Thy., 48:1570–1579, 2002.
[FMS+04] S. Frolund et al. A decentralized algorithm for erasure-coded vir-
tual disks. In DSN-04: Int. Conf. on Dep. Syst. and Net., 2004.
[GWGR04] G. R. Goodson et al. Efﬁcient byzantine-tolerant erasure-coded
storage. In DSN-04: Int. Conf. on Dep. Syst. and Net., 2004.
[LMS+97] M. Luby, M. Mitzenmacher, A. Shokrollahi, D. Spielman, and
In 29th Ann. ACM
V. Stemann. Practical loss-resilient codes.
Symp. on Thy. of Comp.,, pages 150–159, 1997. ACM.
[PD05]
[Pla97]
[Pla04]
[PT04]
[Riz97]
[RN04]
J. S. Plank and Y. Ding. Note: Correction to the 1997 tuto-
rial on reed-solomon coding. Software – Practice & Experience,
35(2):189–194, February 2005.
J. S. Plank. A tutorial on Reed-Solomon coding for fault-
tolerance in RAID-like systems. Software – Practice & Experi-
ence, 27(9):995–1012, September 1997.
J. S. Plank. Enumeration of small, optimal and near-optimal
parity-check erasure codes. Tech. Rep. UT-CS-04-535, Depart-
ment of Computer Science, University of Tennessee, November
2004.
J. S. Plank and M. G. Thomason. A practical analysis of low-
density parity-check erasure codes for wide-area storage applica-
tions. In DSN-04: Int. Conf. on Dep. Syst. and Net., 2004.
L. Rizzo. Effective erasure codes for reliable computer commu-
nication protocols. ACM SIGCOMM Computer Communication
Review, 27(2):24–36, 1997.
V. Roca and C. Neumann. Design, evaluation and comparison
of four large FEC Codecs, LDPC, LDGM, LDGM staircase and
LDGM triangle, plus a Reed-Solomon small block FEC Codec.
Technical Report RR-5225, INRIA Rhone-Alpes, June 2004.
[RU03]
T. Richardson and R. Urbanke. Modern coding theory. Draft from
lthcwww.epfl.ch/papers/ics.ps, 2003.
[RWE+01] S. Rhea et al. Maintenance-free global data storage. IEEE Internet
Comp., 5(5):40–49, 2001.
[Sho99]
[WK03]
[ZL02]
M. A. Shokrollahi. New sequences of linear time erasure codes ap-
proaching the channel capacity. Proc. of AAECC-13, LNCS 1719,
pages 65–76, New York, 1999. Springer-Verlag.
S. B. Wicker and S. Kim. Fundamentals of Codes, Graphs, and
Iterative Decoding. Kluwer Acad. Publ., Norwell, MA, 2003.
Z. Zhang and Q. Lian. Reperasure: Replication protocol using
erasure-code in peer-to-peer storage network. In 21st IEEE Symp.
on Rel. Dist. Sys. (SRDS’02), pages 330–339, 2002.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:53:32 UTC from IEEE Xplore.  Restrictions apply.