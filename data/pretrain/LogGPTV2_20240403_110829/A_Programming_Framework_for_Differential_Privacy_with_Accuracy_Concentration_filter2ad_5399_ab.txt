counts ← sequence [ do elems ← dpWhere ((cid:3) bin)
1 cdf1 bins eps dataset = do
2
3
4
5
6
7
8
return (norm∞ counts)
sizes
dpCount localEps elems
| bin ← bins]
where localEps = eps / (length bins)
(a) Sequential approach
sizes ← dpSelect (((cid:3) max bins) ◦ getPktLen) dataset
parts ← dpPartRepeat (dpCount eps) bins assignBin
-- parts :: Map Integer (Value Double)
9 cdf2 bins eps dataset = do
10
11
12
13
14
15
16
17
let counts
return (norm∞ cumulCounts)
sizes
= Map.elems parts
cumulCounts = [add (take i counts)
| i ← [1 . . length counts]]
(b) Parallel approach
Fig. 1: CDF’s implementations
We show how to do this using DPella in Figure 1a. We deﬁne
a function cdf1 which takes as input the list of bins describing
length ranges, the amount of budget eps to be spent by the
entire query, and the dataset where it will be computed. For
now, we assume that we have a ﬁxed list of bins for packets’
length. cdf1 uses the primitive transformation2 dpSelect to
obtain from the dataset the length of each packet via a selector
function getPktLen::String → Integer (where :: is used to
describe the type of a term in Haskell). This computation results
in a new dataset sizes. Then, we create a counting query for
each bin using the primitive dpWhere. This ﬁlters all records
that are less than the bin under consideration ((cid:3) bin). Finally,
we perform a noisy count using the DPella primitive dpCount.
The noise injected by the primitive dpCount is calibrated so
that the execution of dpCount is localEps-DP (line 8 3). The
function sequence then takes the list of queries and compute
them sequentially collecting their results in a list—to create a
list of noisy counts. We then return this list. The combinator
norm∞ in line 7 is used to mark where we want the accuracy
information to be collected, but it does not have any impact
on the actual result of the cdf.
To ensure that cdf1 is eps-differential privacy, we distributed
the given budget eps evenly among the sub-queries (this is
done in lines 5 and 8). However, a data analyst may forget
to do so, e.g., she can deﬁne localEps = eps, and in this
case the ﬁnal query is (length bins)*eps-DP, which is a
signiﬁcant change in the query’s privacy price. To prevent such
budget miscalculations or unintended expenditure of privacy
budget, DPella provides the analyst with the function budget
(see Section III) that, given a query, statically computes an
2Anticipating on Section III, in our code we will usually use the red color
for transformations, the blue color for aggregate operations, and the green
color for combinators for privacy and accuracy.
3The casting operation fromIntegral is omitted for clarity
upper bound on how much budget it will spend. To see how to
use this function, consider the function cdf1 and a its modiﬁed
(cid:3)
version cdf
1 with localEps = eps. Suppose that we want
to compute how much budget will be consumed by running
it on a list of bins of size 10 (identiﬁed as bins10) and on a
dataset networkTraffic. Then, the data analyst can ask this
as follow:
>budget (cdf1 bins10 1 networkTraffic)
 = 1
(cid:3)
1 bins10 1 networkTraffic)
>budget (cdf
 = 10
The function budget will not execute the query, it simply
performs an static analysis on the code of the query by
symbolically interpreting it. The static analysis uses infor-
mation encoded by the type of the database networkTraffic
(explained in Section III).
DPella also provides primitives to statically explore the
accuracy of a query. The function accuracy takes a query Q(·)
and a probability β and returns an estimate of the (theoretical)
error that can be achieved with conﬁdence probability 1 − β.
Suppose that we want to estimate the error we will incur in by
running cdf1 with a budget of  = 1 on with the same list of
bins and dataset as above, and we want to have this estimate
for β = 0.05 and β = 0.2, respectively. Then, the data analyst
can ask this as follow:
>accuracy (cdf1 bins10 1 networkTraffic) 0.05
α = 53
>accuracy (cdf1 bins10 1 networkTraffic) 0.2
α = 40
Since the result of the query is a vector of counts, we
measure the error α in terms of (cid:7)∞ distance with respect to
the CDF without noise. This is the max difference that we can
have in a bin due to the noise. The way to read the information
provided by DPella is that with conﬁdence 95% and 80%, we
have errors 53 and 40, respectively. These error bounds can be
used by a data analyst to ﬁgure out the exact set of parameters
that would be useful for her task.
2) Parallel CDF: Another way to compute a CDF is by ﬁrst
generating an histogram of the data according to the bins, and
then building a cumulative sum for each bin. To make this
function private, an approach could be to add noise at the
different bins of the histogram, rather than to the cumulative
sums themself, so that we could use the parallel composition,
rather than the sequential one [28], which we show how to
implement in DPella in Figure 1b. —where double-dashes are
used to introduce single-line comments.
In cdf2, we ﬁrst select all the packages whose length
is smaller than the maximum bin, and then we partition
the data accordingly to the given list of bins. To do this,
we use dpPartRepeat operator to create as many (disjoint)
datasets as given bins, where each record in each parti-
tion belongs to the range determined by an speciﬁc bin—
where the record belongs is determined by the function
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
414
cdf1 Empiric
cdf1 Theoretic
cdf2 Empiric
cdf2 Theoretic
α
2,000
1,000
0
0
50
100
150
200
250
300
Sub-queries
Fig. 2: Error comparison (95% conﬁdence)
assignBin :: Integer → Integer. After creating all par-
titions, the primitive dpPartRepeat computes the given query
dpCount eps in each partition—the name dpPartRepeat
comes from repetitively calling dpCount eps as many times
as partitions we have. As a result, dpPartRepeat returns a
ﬁnite map where the keys are the bins and the elements are
the noisy count of the records per partition—i.e., the histogram.
In what follows (lines 15–17), we compute the cumulative
sums of the noisy counts using the DPella primitive add, and
ﬁnally we build and return the list of values denoting the CDF.
The privacy analysis of cdf2 is similar to the one of cdf1.
The accuracy analysis, however, is more interesting: ﬁrst it gets
error bounds for each cumulative sum, then these are used to
give an error bound on the maximum error of the vector. For
the error bounds on the cumulative sums DPella uses either the
union bound or the Chernoff bound, depending on which one
gives the lowest error. For the maximum error of the vector,
DPella uses the union bound, similarly to what happens in
cdf1. A data analyst can explore the accuracy of cdf2.
>accuracy (cdf2 bins10 1 networkTraffic) 0.05
α = 22
>accuracy (cdf2 bins10 1 networkTraffic) 0.2
α = 20
3) Exploring the privacy-accuracy trade-off: Let us assume
that a data analyst is interested in running a CDF with an error
bounded with 90% conﬁdence, i.e., with β = 0.1, having three
bins (named bins3), and  = 1. With those assumptions in
mind, which implementation should she use? To answer that
question, the data analyst can ask DPella:
>accuracy (cdf1 bins3 1 networkTraffic) 0.1
α = 11
>accuracy (cdf2 bins3 1 networkTraffic) 0.1
α = 12
So, the analyst would know that using cdf1 in this case would
give, likely, a lower error. Suppose further that the data analyst
realize that she prefers to have a ﬁner granularity and have 10
bins, instead of only 3. Which implementation should she use?
Again, she can compute:
>accuracy (cdf1 bins10 1 networkTraffic) 0.1
α = 46
>accuracy (cdf2 bins10 1 networkTraffic) 0.1
α = 20
So, the data analyst would know that using cdf2 in this case
would give, likely, a lower error. One can also use DPella to
show a comparison between cdf1 and cdf2 in terms of error
when we keep the privacy parameter ﬁxed and we change
the number of bins, where cdf2 gives a better error when the
number of bins is large [28] as illustrated in Figure 2. In the
ﬁgure, we also show the empirical error to conﬁrm that our
estimate is tight—the oscillations on the empirical cdf1 are
given by the relative small (300) number of experimental runs
we consider.
Now, what if the data analyst choose to use cdf2 because
of what we discussed before but she realizes that she can
afford an error α (cid:3) 50; what would be then the epsilon that
gives such α? One of the feature of DPella is that the analyst
can write a simple program that ﬁnds it by repetitively calling
accuracy with different epsilons—this is one of the advantages
of providing a programming framework. These different use
cases shows the ﬂexibility of DPella for different tasks in
private data analysis.
Synthetic data: When compared with (non-compositional)
approaches for estimating accuracy based on synthetic or public
data, such as [33], the static analysis of DPella can be used in
a complimentary manner to quickly (and precisely) estimate
privacy and accuracy for a wide range of simple queries. There
are also certain kind of queries (e.g., k-way marginal) where it
is more convenient to use our static analysis than synthetic data
for high-dimensional datasets—see Appendix G for details.
The following sections will introduce the theoretical and
technical aspects of DPella.
III. PRIVACY
DPella have two kind of actors: data curators, owners of
the private dataset that decide the global privacy budget and
split it among the data analysts, the ones who write queries to
mine useful information from the data and spend the budget
they received. DPella is designed to help data analysts to have
an informed decision about how to spend their budget based
on exploring the trade-offs between privacy and accuracy.
A. Components of the API
Figure 3 shows part of DPella API. DPella introduces two
abstract data types to respectively denote datasets and queries:
data Data s r -- datasets
data Query a
-- queries
The attentive reader might have observed that the API also
introduces the data type Value a. This type is used to capture
values resulting from data aggregations. However, we defer its
explanation for Section IV since it is only used for accuracy
calculations—for this section, readers can consider the type
Value a as isomorphic to the type a. It is also worth noticing
that the API enforces an invariant by construction: it is not
possible to branch on results produced by aggregations—
observe that there is no primitive capable to destruct a value
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
415
-- Transformations (data analyst)
dpWhere
dpSelect
dpGroupBy
dpUnion
dpPart
dpIntersect :: Eq r ⇒ Data s1 r → Data s2 r
(cid:3)
(cid:3)
) → Data s r → Query (Data s r
:: (r → Bool) → Data s r → Query (Data s r)
:: (r → r
)
:: Eq k ⇒ (r → k) → Data s r
→ Query (Data (2*s) (k, [r]))
→ Query (Data (s1+s2) r)
:: Data s1 r → Data s2 r
→ Query (Data (s1+s2) r)
:: Ord k ⇒ (r → k) → Data s r
→ Map k (Data s r) → Query (Value a))
→ Query (Map k (Value a))
-- Aggregations (data analyst)
dpCount :: Stb s ⇒  → Data s r → Query (Value Double)
dpSum
dpAvg
dpMax
:: Stb s ⇒  → (r → Double) → Data s r
→ Query (Value Double)
:: Stb s ⇒  → (r → Double) → Data s r
→ Query (Value Double)
a ⇒  → Responses a → (r → a)
:: Eq
→ Data 1 r → Query (Value a)
-- Budget
budget :: Query a → 
dpEval :: (Data 1 r → Query (Value a)) → [r] →  → IO a
-- Execution (data curator)
Fig. 3: DPella API: Part I
of type Value a. While it might seem restrictive, it enables
to write counting queries, which are the bread and butter of
statistical analysis and have been the focus of the majority of
the work in DP. Section VI discusses, however, how to lift this
limitation for speciﬁc analyses.
Values of type Data s r represent sensitive datasets
with accumulated stability s, where each row is of type r.
Accumulated stability, on the other hand, is instantiated to
type-level positive natural numbers, i.e., 1, 2, etc. Stability is
a measure that captures the number of rows in the dataset that
could have been affected by transformations like selection or
grouping of rows. In DP research, stability is associated with
dataset transformations rather than with datasets themselves.
In order to simplify type signatures, DPella uses the type
parameter s in datasets to represent the accumulated stability
of the transformations for which datasets have gone through—
as done in [34]. Different than, e.g., PINQ [2], one novelty of
DPella is that it computes stability statically using Haskell’s
type-system.
Values of type Query a represent computations, or queries,
that yield values of type a. Type Query a is a monad [35],
and because of this, computations of type Query a are built
by two fundamental operations:
return :: a → Query a
(>>=)
:: Query a → (a → Query b) → Query b
The operation return x outputs a query that just produces the
value x without causing side-effects, i.e., without touching any
dataset. The function (>>=)—called bind—is used to sequence
queries and their associated side-effects. Speciﬁcally, qp >>= f
executes the query qp, takes its result, and passes it to the
function f, which then returns a second query to run. Some
>>= (λx1 → qp2
languages, like Haskell, provide syntactic sugar for monadic
computations known as do-notation. For instance, the program
>>= (λx2 → return (x1, x2))), which
qp1
performs queries qp1 and qp2 and returns their results in a pair,
can be written as do x1 ← qp1; x2 ← qp2; return (x1, x2)
which gives a more “imperative” feeling to programs. We split
the API in four parts: transformations, aggregations, budget
prediction, and execution of queries—see next section for the
description of API’s accuracy components. The ﬁrst three parts
are intended to be used by data analysts, while the last one is
intended to be only used by data curators4.
1) Transformations: The primitive dpWhere ﬁlters rows in
datasets based on a predicate functions (r → Bool). The
created query (of type Query (Data s r)) produces a dataset
with the same row type r and accumulated stability s as
the dataset given as argument (Data s r). Observe that if
we consider two datasets which differ in s rows in two
given executions, and we apply dpWhere to both of them,