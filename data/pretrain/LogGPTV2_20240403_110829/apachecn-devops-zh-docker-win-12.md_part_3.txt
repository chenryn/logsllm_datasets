这个提议很简单。我不建议将整个应用转移到 Docker——这已经是一个长期的路线图了——而只是将一项服务转移到 Docker。这方面的 WCF 端点是数据库应用外观将在 Docker 中运行，与应用的其余部分隔离。web 应用是服务的唯一消费者，所以这只是在消费者中更改服务 URL 的一个例子。这是建议的体系结构:
![](img/9b9125c5-a000-4378-8ddb-4f28f19f0ea8.png)
*   **1**:web 应用在 IIS 中运行。代码没有改变，但是配置被更新为使用在容器中运行的新集成组件的 URL。
*   **2** :最初的 WCF 服务继续在 IIS 中运行，但是删除了之前的数据库集成组件。
*   **3** :新的集成组件使用与之前相同的 WCF 契约，但是现在它被托管在一个容器中，隔离了对第三方应用数据库的访问。
这种方法有很多好处:
*   如果数据库模式改变了，我们只需要改变 Dockerized 服务
*   只需更新 Docker 映像，就可以在没有完整应用发布的情况下发布服务更改
*   它是 Docker 的沙盒介绍，因此开发和运营团队可以使用它进行评估
在这种情况下，最重要的好处是减少了测试工作量。对于完整的单片应用，一个版本需要几周的测试。通过将服务分解到 Docker 容器中，只有已经改变的服务需要测试版本。这极大地减少了所需的时间和工作量，从而允许更频繁的发布，从而更快地将新功能发布到业务中。
# 案例研究 3–Azure 物联网应用
我是一个项目的 API 架构师，该项目用于交付移动应用使用的后端服务。有两种主要的原料药。配置应用编程接口是只读的，设备调用它来检查设置和软件的更新。事件应用编程接口是只写的，设备发布了关于用户行为的匿名事件，产品团队使用这些事件为下一代设备的设计决策提供信息。
这些应用编程接口支持超过 150 万台设备。配置 API 需要高可用性；他们必须快速响应设备调用，并扩展到每秒数千个并发请求。事件应用编程接口使用来自设备的数据，并将事件推送到消息队列。监听队列的是两组处理程序:一组在 Hadoop 中存储所有事件数据，用于长期分析，另一组存储事件子集，用于提供实时仪表板。
所有组件都在 Azure 中运行，在项目的高峰期，我们使用云服务、事件中心、SQL Azure 和 HDInsight。建筑是这样的:
![](img/3994e8aa-c9c8-4b64-9aff-705bd5816469.png)
*   **1** :事件 API 托管在具有多个实例的云服务中。设备将事件发布到应用编程接口，应用编程接口进行一些预处理，并将它们分批发布到 Azure 事件中心。
*   **2** :配置 API 也托管在一个有多个实例的云服务中。设备连接到应用编程接口来检查软件更新和配置设置。
*   **3** :实时分析数据，用于关键绩效指标的子集。这是为了快速访问而存储在 SQL Azure 中的，因为这些数据量不大。
*   **4** :批量分析数据，用于存储所有设备发布的所有事件。这存储在 HDInsight 中，HDinsight 是 Azure 上的托管 Hadoop 服务，用于长期运行的大数据查询。
这个系统运行成本很高，但它为产品团队提供了许多关于设备使用方式的信息，这些信息被他们输入到下一代的设计过程中。每个人都很高兴，但后来产品路线图被取消了，不会再有设备了，所以我们不得不削减运营成本。
我的工作是将 Azure 账单从每月 5 万美元降低到每月 1 千美元以下。我可能会失去一些报告功能，但是事件 API 和配置 API 必须保持高可用性。
这发生在 Docker 在 Windows 上可用之前，所以我对该架构的第一次修订使用了运行在 Azure 中 Docker Swarm 上的 Linux 容器。我用 Elasticsearch 和 Kibana 替换了系统的分析端，用 Nginx 提供的静态内容替换了配置 API。我离开了习俗。在云服务中运行的. NET 组件，用于向 Azure 事件中心提供设备数据的事件应用编程接口，以及将数据推送到弹性搜索的消息处理程序:
![](img/97b221e5-2481-43c2-b9b2-1e18a1bc3581.png)
*   **1** :配置 API，现在在 Nginx 作为静态网站运行。配置数据作为 JSON 有效载荷，维护原始的 API 契约。
*   **2** : Kibana 用于实时和历史分析。通过减少存储的数据量，我们显著降低了数据存储需求，但代价是丢失了详细的指标。
*   **3** : Elasticsearch 用于存储传入的事件数据。. NET 云服务仍然用于从事件中心读取，但是这个版本将数据保存在弹性搜索中。
第一次修订为我们节省了所需的成本，主要是通过减少应用编程接口所需的节点数量和我们从设备中存储的数据量。我没有将所有内容都存储在 Hadoop 中，将实时数据存储在 SQL Azure 中，而是集中在弹性搜索上，只存储了一小部分数据。使用 Nginx 来提供配置 API，我们失去了产品团队用于发布配置更新的用户友好特性，但是我们可以用小得多的计算资源运行。
我监督了第二次修订，当时推出了 Windows Server 2016，并支持 Windows 上的 Docker。我在 Docker Swarm 中的现有 Linux 节点上添加了 Windows 节点，并将事件 API 和消息处理程序迁移到 Windows Docker 容器中。当时，我还将消息传递系统转移到了 NATS，运行在一个 Linux 容器中:
![](img/3243f6ae-0f38-4885-a699-aee1112ae2f5.png)
*   **1**:Events API 现在托管在 Docker 容器中，但是代码没有改变；这仍然是一个 ASP.NET 网络应用编程接口项目，运行在一个窗口容器中。
*   **2** :消息传递组件正在使用 NATS，而不是事件中心。我们失去了存储和重新处理消息的能力，但是消息队列现在具有与事件应用编程接口相同的可用性。
*   **3** :消息处理程序从 NATS 读取，并将数据保存在弹性搜索中。大部分代码没有改变，但是它现在在一个 Windows 容器中作为一个. NET 控制台应用运行。
第二次修订进一步降低了成本和复杂性:
*   每个组件现在都在 Docker 中运行，所以我可以在开发中复制整个系统
*   所有组件都是用 Docker 文件构建的，并打包成 Docker 映像，因此所有组件都使用相同的工件
*   整个解决方案具有相同的服务级别，在单个 Docker Swarm 上高效运行
在这种情况下，项目注定会结束，用新的解决方案很容易适应。设备使用情况仍会记录下来，并显示在基巴纳仪表盘上。随着时间的推移，使用的设备越来越少，服务需要的计算也越来越少，我们可以从集群中移除节点。最终，该项目将在一个最小的基础架构上运行，可能只是一个双节点群集，运行在 Azure 中的小型虚拟机上，或者它可以移回公司的数据中心。
# 摘要
全世界大大小小的公司都在转向 Windows 和 Linux 上的 Docker。一些主要的驱动因素是效率、安全性和可移植性。许多新项目都是使用容器从头开始设计的，但是有更多的现有项目将从迁移到 Docker 中受益。
在这一章中，我研究了将现有的应用迁移到 Windows 上的 Docker，建议您从自己熟悉的应用开始。一个简短的、限时的 Dockerizing PoC 应用将很快向您展示您的应用在 Dockr 中的样子。PoC 的结果将帮助您了解下一步您需要做什么，以及您需要让谁参与将 PoC 投入生产。
我完成了一些非常不同的案例研究，向您展示了如何在现有项目中引入 Docker。在一个案例中，我使用 Docker 主要是为了打包的好处，在不改变它的情况下运行一个单一的应用，但是为未来的版本提供干净的升级。在另一个例子中，我从一个单一的应用中提取了一个组件，并将其提取出来在一个容器中运行，以减轻发布的测试负担。在最后一种情况下，我将一个现有的解决方案完全迁移到了 Docker，使它运行起来更便宜，更容易维护，并且让我可以选择在任何地方运行它。
我希望这一章帮助你思考如何将 Docker 引入到你自己的项目中，我希望这本书的其余部分已经向你展示了你可以用 Docker 做什么，以及为什么它是如此令人兴奋的技术。感谢您的阅读，请务必查看我的 Pluralsight 课程并在推特上关注我，祝您在 Windows Docker 的旅程中好运！