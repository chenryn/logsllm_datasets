Besides tampering with the ticket receiver and the communication
channel to the hypervisor, the attack vectors of an attacker in the
MM and the SM are analogous.
Tamper with the Ticket Receiver. The attacker can stop or hinder
one functionality of the ticket receiver, with the same consequences
as blocking network traffic. Additionally, the execution of gated
boot potentially updates the device and patches the vulnerability
that allowed the attacker to invade the MM in the first place. Thus,
we argue that this attack vector is counterproductive for an adver-
sary. However, if the adversary does not stop or hinder the ticker
receiver, information about the dynamic state of the SM and MM
is transmitted to the SH and IH, respectively. Thus, the intrusion
might be detected and an update of the SM or the complete device
might be enforced, which locks out the attacker again.
Tamper with the Communication Channel to the Hypervisor. The
attacker can tamper with the communication between the ticket
receiver and the hypervisor (Figure 3). As explained in Section 4, this
communication channel relies on a minimal transport abstraction
and is specifically designed for the protocol to retrieve deferral
tickets. No other traffic is possible. Therefore, we assume that there
are no exploitable flaws in the communication channel.
Malicious Workloads. The attacker might start a malicious work-
load, with the expectation that it runs as long as possible without
being detected. The attack surface of this attack vector highly de-
pends on how the IH and the SH utilize the dynamic runtime infor-
mation in the deferral ticket requests in order to detect intrusions
and anomalies. Conceptually, a malicious workload (e.g. a foreign
461ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Röckl, et al.
process that appears in the process list) is detected and an update
might be enforced, locking out the attacker.
Hide Traces. An attacker might try to infiltrate the system, ex-
tract or modify data, and then try to remove all traces of infiltration
within a deferral ticket fetching interval. This way, the attacker
might be undetected. However, we state that this is an attack vector
common to all intrusion detection and anomaly detection systems
that are based on VMI. Exemplary countermeasures rely on tech-
niques to react to particular events within the VM [43, 45, 65].
Persist Privileges. The adversary might try to persist their privi-
leges during reboots of the VM. Any modification of the static file
system leads to a different checksum at the next boot, followed by
the retrieval of a trustworthy file system from the SH. While any
modification of the dynamic file system is persisted during a reboot,
the files in the dynamic file system are expected to be not usable
for an attack (Section 4.4.1).
Hardware Side-Channels. No secret is stored in the MM. How-
ever, the adversary can try to use hardware side-channels to extract
information from the hypervisor or another VM [52, 79, 81]. We
assume that a secret on the hypervisor level may only be possi-
bly leaked into a VM if the VM can trigger an operation based on
the secret, e.g. sign some data. The ticket receiver requests signed
messages from the hypervisor level and the SW (Figure 3). Thus,
from within the MM, K−1
are potentially exposed
to side-channel attacks. Notably, the dominance guarantees still
holds if either of those keys is leaked into a VM. While the attacker
would be able to forge valid deferral ticket requests, the SH and
the IH are still able to stop issuing deferral tickets and enforce an
update within a bounded amount of time. On the application level,
a formally verified cryptography library can be used to prevent
hardware side-channel attacks up to a certain extent [82]. Further,
one can reduce the attack surface by system-oriented countermea-
sures [31, 32, 44].
SM , and K−1
MM , K−1
I
VM Escapes. The attacker might exploit a vulnerability in the
hypervisor to gain hypervisor privileges.
5.3 Attacker on the Hypervisor Level
There are several potential attack vectors for an attacker on the
hypervisor level.
Tamper with the MM. An attacker on the hypervisor level may
tamper with the MM. In particular, the attacker might try to shut
down or pause the MM. The consequences of this attack vector
analogous blocking network traffic.
Overwrite Boot Order. The attacker can try to overwrite either
the boot order or the early-boot components in order to circumvent
gated boot. To parry those attack vectors, the boot order is expected
to be locked in hardware and the early-boot components are latched
(Section 3.2). Failure of one of these measures results in a breach of
the TCB.
Tamper with the Communication Channel to the Secure World.
The attacker can tamper with the communication between the
proxy and the SW (Figure 3). The communication channel between
those components is minimal, tailored to a specific use case, and
relies on a simple transport abstraction. Therefore, we assume that
an adversary is not able to exploit the channel to elevate their
privileges.
Malicious Workloads. Similar to a malicious workload in a VM,
the attacker might run a malicious workload on the hypervisor.
However, we argue that it is unlikely that an adversary can exploit
a vulnerability so that the adversary gains control of the hypervisor
without hijacking a VM before. This is because the network stack is
isolated in the MM while the services run in the SM. If, however, the
adversary hijacks a VM in advance, the intrusion is, conceptually,
detected by analyzing the dynamic runtime information in the
deferral ticket requests.
Denial of Service. The attacker might try to render the device
permanently unavailable. For example, the attacker might provoke a
flash wear-out. We refer to Huber et al. [40] who propose techniques
to tackle this specific attack vector.
To summarize, we state that the detection of malicious workloads,
intrusions, and anomalies depends on how the IH and the SH utilize
the dynamic runtime information in the deferral ticket requests
in order to detect hostile events. However, given the threat model
(Section 2), the strong resiliency and recoverability guarantees hold
as long as the TCB is not compromised.
6 IMPLEMENTATION
We prototype our approach on a Nitrogen8M [20] platform with
an NXP i.MX8M ARMv8-A CPU and 2GB RAM. We implement
the runtime components of strong dominance (Section 4.4.2) and
the weak dominance components (Section 4.5). Gated boot is not
part of the prototypical implementation since it has already been
implemented [40, 74, 78]. We demonstrate the enforced device reset
of the strong dominance relationship between the IH and the device.
Furthermore, we demonstrate and evaluate the proper functionality
of the weak dominance relationship between the IH and the MM
and between an SH and an SM.
In the SW, we use TF-A [51]. As a trusted OS, we utilize OP-
TEE [49]. The AWDT in the SW is implemented as a Pseudo Trusted
Application (PTA), which relies on a secure-world-only hardware
watchdog for the timer functionality. Throughout the system, we
serialize messages between the IH and the device with protocol
buffers [34]. Therefore, protobuf-c [7] is ported to the SW. The
cryptography is based on HACL* [82], a formally verified library,
which is ported to the SW. We use Ed25519 as a signature algorithm
and SHA-2-512 as a hash function.
Since the Nitrogen8M does not have an IOMMU, the network
stack is partially isolated relying on a network bridge (Section 4.3).
In the NW, we base our implementation on a Linux kernel [21]. We
use KVM in combination with the Firecracker [70] hypervisor. The
ticket receiver and the proxy (Section 4.4) are regular C applications.
The communication channels between a VM and the hypervisor
are implemented with Vsocks [67], which are supported by Fire-
cracker [71]. Vsock sockets rely on a minimal transport abstraction
of a virtqueue [68]. The AWDTs of the VMs (Section 4.5) are imple-
mented purely in software. The IH and the SH are implemented in
Python3, relying on the cryptography package.
462Advanced System Resiliency Based on Virtualization Techniques for IoT Devices
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 1: CPU performance score for single-core (SC) and
multi-core (MC) benchmarks. Averaged results from thirty
iterations. The last row denotes the performance relative to
the V M benchmark.
Table 2: Network throughput. Averaged results from thirty
iterations à ten minutes. The last row denotes the through-
put relative to the V M benchmark.
SC
MC
avg. [Mbit/s]
stdev. [Mbit/s]
rel. [%]
avg. [Mbit/s]
stdev. [Mbit/s]
rel. [%]
V M
870.05
44.50
100.00
DOM1 DOM5 DOM60
HY P
870.55
876.94
1036.39
48.37
34.81
2.11
100.79
100.06
119.12
2410.84
3154.58 2419.04 2270.39
169.33
78.15
93.85
99.66
872.75
38.19
100.31
2398.41
82.34
99.15
108.20
100.00
17.41
130.41
7 EVALUATION
The evaluation objective consists of giving insights into the perfor-
mance costs of the components required to establish the proposed
dominance hierarchy, i.e. the ticket receiver, the proxy, the inspector,
and the AWDTs. Although the performance impact of the virtual-
ization layer is visible, we state that a comprehensive performance
evaluation of a hypervisor is out of scope and a contribution on
its own [1, 18, 19]. Given the scenario (Section 4.1), we assume
that a hypervisor is already present on the device to isolate multi-
ple independent services. Thus, the virtualization overhead is not
considered as strictly dominance-related in this evaluation.
To quantify the costs of the dominance components, we measure
the network throughput and the CPU performance. The measure-
ments are carried out in multiple setups: The benchmarks run on
the hypervisor, without a VM or any dominance components be-
ing active (HYP). The benchmarks run in the SM, with a network
packet-forwarding MM active but no running dominance compo-
nents (V M). The benchmarks run in the SM with all dominance
components being active and a deferral ticket fetching interval of
1s (DOM1), 5s (DOM5), and 60s (DOM60). Following Xu et al. [78],
we consider an interval of 1s as unreasonable low. Still, we measure
it in order to evaluate the performance impact in edge cases.
The SM has four vCPUs and 512MB RAM. The MM has two
vCPUs and 256MB RAM. Both the IH and the SH run on a Lenovo
ThinkPad T480 with an Intel Core i7-8550U CPU, 8GB DDR4 RAM,
and an Intel Network Adapter I219-V. The hub and the device com-
municate via 100Base-TX Ethernet through a lightly loaded AVM
FritzBox! 7390 router.
We measure the CPU performance with the CoreMark-Pro [15]
benchmark. Table 1 shows the results. We consider V M as a baseline
to measure the overhead of the dominance components. Regardless
of the ticket fetching interval, we measure no overhead of the dom-
inance components in the single-core benchmark. This is plausible
since the dominance components can be scheduled on a vCPU that
is not executing the benchmark. In the multi-core benchmark, how-
ever, the CPU performance decreases by 6.15% for an unreasonable
low interval of 1s. For more realistic ticket fetching intervals, we
measure no overhead. System virtualization on ARMv8-A has an
impact on the CPU performance [17, 58]. Our evaluation shows that
the CPU performance on the hypervisor level is between 19.12%
and 30.41% higher. Additionally, an underlying hypervisor adds
more jitter to a system, resulting in a larger variation of the results.
avg. [Mbit/s]
stdev. [Mbit/s]
rel. [%]
HY P
93.95
0.47
137.61
V M
68.28
0.77
100.00
DOM1 DOM5 DOM60
68.44
66.28
0.66