Outdoors
Calm
Squatted Skill
Call
Lang
Cell
He’ll
Sale
Xcelerate
Rap
No
Khan
Lock
Lol
Doll
Out Doors
Com
Success Rate
100.0%
100.0%
100.0%
96.4%
95.0%
93.7%
88.8%
84.6%
84.2%
81.9%
81.9%
80.8%
71.0%
67.9%
Target Skill
Dime
Wet
Sweeten
Earthy
Full
Outshine
Superhighway
Meal
Bean
Tube
Main
Boil
Loud
Squatted Skill
Time
What
Sweden
Fi
Four
Outshyne
Super Highway
Meow
Been
Two
Maine
Boyle
Louder
Success Rate
65.2%
62.1%
57.4%
53.3%
26.8%
21.2%
19.7%
18.3%
17.8%
16.7%
3.1%
0.0%
0.0%
Table 4: Skill Squatting Validation—We show the results of testing 27 skill squatting attacks. The pairs of target and squatted
skills are built using the squattable words of our training set. The success rates are computed by querying the speech samples of our
test set. We are able to successfully squat 25 (92.6%) of the skills at least one time, demonstrating the feasibility of the attack.
They will instead be routed to the Boyle skill.
In order to demonstrate that our attack will work on
speakers we have not previously seen, we use two-fold
cross validation over the 60 speakers in our dataset. We
divide the set randomly into two halves, with 30 speakers
in each half. We build an error model using the ﬁrst half of
the speakers (training set) and then use this model to build
pairs of target and squatted skills. The analysis of this
training set results in 27 squattable words, all of which
are detailed in Table 4. For each speaker in the test set, we
construct a request to each of the 27 target skills and mea-
sure how many times the squatted skill is triggered. We
repeat this process ﬁve times to address non-determinism
in Alexa responses. As an ethical consideration, we test
our attack by registering our skills in a developer environ-
ment and not on the public Alexa skills store, to avoid the
possibility of regular users inadvertently triggering them.
Table 4 shows the results of our validation experiment.
We are able to successfully squat skills at least once for 25
(92.6%) of the 27 squattable skills. There are two cases
in which our squatting attack never works. In the ﬁrst
case, we expect the skill name loud to be incorrectly in-
terpreted as the word louder. However, because louder
is a native Alexa command which causes Alexa to in-
crease the volume on the end-user device, when the target
is misinterpreted, it is instead used to perform a native
Alexa function. We found no clear explanation for the
second pair of skills, Boil/Boyle.
In other cases, we ﬁnd that testing the attack in a skill
environment results in a very high rate of success. In the
Coal/Call and Sell/Cell pairs, the attack works 100%
of the time. We speculate that this is a result of a smaller
solution space when Alexa is choosing between skills
as opposed to when it is transcribing arbitrary speech
Skill
Boil an Egg
Main Site Workout
Quick Calm
Bean Stock
Test Your Luck
Comic Con Dates
Mill Valley Guide
Full Moon
Way Loud
Upstate Outdoors
Rip Ride Rockit
Squatted Skill
Boyle an Egg
Maine Site Workout
Quick Com
Been Stock
Test Your Lock
Comic Khan Dates
No Valley Guide
Four Moon
Way Louder
Upstate Out
Rap Ride Rocket
Table 5: Squattable Skills in the Alexa skills store—We
show 11 examples of squattable skills publicly available in the
Alexa skill store, as well as squatted skill names an attacker
could use to “squat” them.
within a skill. Ultimately, Table 4 demonstrates that skill
squatting attacks are feasible.
5.2 Squatting Existing Skills
We next investigate how an adversary can craft mali-
ciously named skills targeting existing skills in the Alexa
skills store, by leveraging the squattable words we identi-
ﬁed in Section 4. To this goal, we utilize our dataset of
Alexa skill names described in Section 3. First, we split
each skill name into its individual words. If a word in a
skill exists in our spoken dataset of 188 words, we check
whether that word is squattable. If it is, we exchange that
word with its most common error to create a new skill
name. As an example, the word “calm” is systematically
misinterpreted as “com” in our dataset. Therefore, a skill
USENIX Association
27th USENIX Security Symposium    39
with the word “calm” can be squatted by using the word
“com” in its place (e.g. “quick com” squats the existing
Alexa skill “quick calm”).
Using the 24 squattable words we identiﬁed in Sec-
tion 4, we ﬁnd that we can target 31 skill names that
currently exist on the Alexa Store. Only 11 (45.8%) of
the squattable words appear in Alexa skill names. Ta-
ble 5 shows one example of a squattable skill for each of
these 11 words. We note that the number of squattable
skills we identify is primarily limited by the size of our
dataset and it is not a ceiling for the pervasiveness of this
vulnerability in the Amazon market. To address this short-
coming, in the remainder of this section we demonstrate
how an attacker with a limited speech corpus can predict
squattable skills using previously-unobserved words.
5.3 Extending The Squatting Attack
An adversary that attempts this attack using the tech-
niques described thus far would be severely restricted
by the size and diversity of their speech corpus. With-
out many recordings of a target word from a variety of
speakers, they would be unable to reliably identify sys-
tematic misinterpretations of that word. Considering that
many popular skill names make use of novel words (e.g.,
WeMo) or words that appear less frequently in discourse
(e.g., Uber), acquiring such a speech corpus may prove
prohibitively costly and, in some cases, infeasible. We
now consider how an attacker could amplify the value
of their speech corpus by reasoning about Alexa misin-
terpretations at the phonetic level. To demonstrate this
approach, we consider the misinterpretation of “luck” in
Table 4.“Luck” (L AH K) is frequently misinterpreted as
“lock” (L AA K), suggesting that Alexa experiences con-
fusion speciﬁcally between the phonemes AH and AA. As
such, an attacker might predict confusion in other words
with the AH phoneme (e.g., “duck” to “dock”, “cluck” to
“clock”) without having directly observed those words in
their speech corpus.
Unfortunately, mapping an input word’s phonemes to a
misinterpreted output word’s phonemes is non-trivial. The
phonetic spelling of the input and output words may be of
different lengths, creating ambiguity in the attribution of
an error to each input phoneme. Consider the following
example from our tests, where the input word “absentee”
(AE, B, S, AH, N, T, IY) is understood by Alexa as
“apps and t.” (AE, P, S, AH, N, D, T, IY). Moving
from left to right, AE is correctly interpreted and an input
of B maps to an output of P. However, determining which
input phoneme is at fault for the D of the output is less
clear. In order to attribute errors at the phonetic level, we
thus propose a conservative approach that a) minimizes
the total number of errors attributed and b) discards errors
that cannot be attributed to a single input phoneme. Our
algorithm works in the following steps:
1. We begin by identifying the input-to-output mapping
of correct phonemes whose alignment provides the
smallest cost (i.e., fewest errors):
2. Based on this alignment, we inspect any additional
phonemes inserted into the output that do not cor-
respond to a phoneme in the input. We choose to
attribute these output phonemes to a misinterpreta-
tion of the phoneme that immediately precedes them
in the input. We extend the mappings created in the
previous step to include these errors. In our exam-
ple, we attribute the D output phoneme to the N input
phoneme, mapping N to N D:
3. Finally, we analyze the remaining unmatched
phonemes of the input. We consider unambigu-
ous cases to be where a single phoneme of the in-
put: a) occurs between two already mapped pairs
of phonemes or is the ﬁrst or the last phoneme of
the input, and b) was either omitted (maps to an
empty phoneme) or confused with one or two other
phonemes in the output.
In the example above,
we map the phoneme B of the input to its single-
phoneme misinterpretation as P in the output.
We note that this step only attributes an error when
its source is unambiguous. There exist some cases
where we cannot safely attribute errors and thus we
choose to discard an apparent phoneme error. Tak-
ing an example from our tests, when the input word
“consume” (K AH N S UW M) is confused by Alexa
as “ﬁlm” (F IH L M), the word error may have hap-
pened for reasons unrelated to phoneme misinter-
pretations and it is not clear how to align input and
output except for the ﬁnal M phoneme in both of the
words. Since the other phonemes could instead be
mapped in many ways, we discard them.
We use this algorithm to create a phoneme error model
which provides a mapping from input phonemes to many
40    27th USENIX Security Symposium
USENIX Association
AE  B  S  AH  N       T  IYAE  P  S  AH  N  D  T  IYAE  B  S  AH  N       T  IYAE  P  S  AH  N  D  T  IYAE  B  S  AH  N       T  IYAE  P  S  AH  N  D  T  IYpossible output phonemes. We next evaluate whether such
phoneme error model, built using the NSP dataset, can
predict Alexa interpretation errors for words that do not
appear in our dataset. To accomplish this, we leverage the
Forvo dataset, described in Section 3, as a test set.
First, we exclude from our test set all the speech sam-
ples of words that are also in the NSP dataset, since we
seek to predict errors for words that we have not used
before. Then, we decompose each remaining Forvo word,
w, into its phonetic spelling. For every phoneme p in each
phonetic spelling we attempt to replace p with each of
its possible misinterpretations pi present in our phoneme
error model. We then check if the resultant phoneme
string represents an English word, w(cid:48). If it does, we mark
w(cid:48) as a potential misinterpretation of w. As an example,
consider the word “should”, whose phonetic representa-
tion is SH UH D. The UH phoneme is confused with the
OW phoneme in our phoneme error model, so we attempt
a phoneme level swap and get the phoneme string SH OW
D. This phoneme string maps back to the English word
“showed”. Thus, we predict that the word “should” will
be misinterpreted by Alexa as “showed”.
Using this technique, we are able to make error pre-
dictions for 12,869 unique Forvo words. To validate the
correctness of our predictions, we next collect the ac-
tual Alexa interpretations of this set of words. We query
each speech sample from this set 50 times using our test
harness and record their interpretations. We then check
whether any observed interpretation errors in this set are
in our predictions. We observe that our predictions are
correct for 3,606 (28.8%) of the words in our set. This
set is 17.5x larger than our seed of 188 words. This indi-
cates that by extending our word model with a phoneme
model, we can successfully predict misinterpretations for
a subset of words that we have not previously seen, thus
improving the potency of this attack even with a small
speech dataset.
Identifying Existing Confused Skills
5.4
We next apply our method of extending our seed-set of
errors to identify already existing instances of confused
skills in the Alexa skills store. In total, we ﬁnd 381 unique
skill pairs that exhibit phoneme confusion. The largest
single contributor is the word “fact”, which is commonly
misinterpreted as “facts”, and “fax”. Given the large
number of fact-related skills available on the skill store, it
is unsurprising that many of these exist in the wild.
In order to determine whether these similarities are due
to chance, we investigate each pair individually on the
skill store. We ﬁnd eight examples of squatted skills that
we mark as worth investigating more closely (Table 6).
We cannot speak to the intention of the skill creators.
However, we ﬁnd it interesting that such examples cur-
Skill A
Cat Fats
Pie Number Facts
Cat Facts
Magic Hate Ball
Flite Facts
Smart Homy
Phish Geek
Snek Helper
Skill B
Cat Facts