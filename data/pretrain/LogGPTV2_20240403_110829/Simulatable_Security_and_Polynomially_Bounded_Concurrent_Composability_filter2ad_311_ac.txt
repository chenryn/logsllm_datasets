tion evaluation. That is, each Pi takes as local ﬁrst input
a tuple (bi, si) as above and eventually—after having com-
municated with k − 1 other parties—outputs a time-lock
puzzle qi as speciﬁed by f . Then Pi expects a second input
ti and ﬁnally—after further communication—outputs out
as prescribed by f .
Using the programs of these parties, we deﬁne the proto-
col machines M1 and M2 which make up the protocols ˆM1,
resp. ˆM2.4 Namely, let M1’s program be as follows:
1. Ask the protocol user H for a party index i ∈
{1, . . . , k}.
2. Run the program Pi internally, where
• Pi’s ﬁrst inputs are set to bi := real and si := 0,
and the second input is ti := ε (where ε denotes
the empty word). The ﬁrst output of Pi is simply
ignored.
• All outgoing messages are sent to H (preﬁxed
with the recipient party index or indicated as a
broadcast).
4In our example, each protocol consists of only one machine.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
• Messages coming from H that are preﬁxed with
a party index j (cid:6)= i are forwarded to the internal
Pi as if coming from Pj.
3. As soon as Pi generates its ﬁnal output out, forward
this output to H and halt.
In other words, M1 asks H for a party index i and then
expects to take part in an evaluation of f in the role of Pi.
Here, Pi’s local inputs are ﬁxed to bi := real, si := 0, and
ti := ε, and all network communication is relayed over H.
The evaluated function output is eventually forwarded to H.
As mentioned earlier, the protocol ˆM1 then consists only
of this single machine M1. On the other hand, protocol
ˆM2 consists of only one machine M2 that is deﬁned—very
similarly—as follows:
1. Ask the protocol user H for a party index i ∈
{1, . . . , k}.
2. Run the program Pi internally, where
• Pi’s ﬁrst inputs are set to bi := ideal, and the
simulator is asked for the value of si. When the
ﬁrst output qi has been generated, it is sent to the
simulator, and a second input ti is expected.
• All outgoing messages are sent to H (preﬁxed
with the recipient party index or indicated as a
broadcast).
• Messages coming from H that are preﬁxed with
a party index j (cid:6)= i are forwarded to the internal
Pi as if coming from Pj.
3. As soon as Pi generates its ﬁnal output out, forward
this output to H and halt.
The only difference between M1 and M2 lies in the way
the local inputs to Pi are determined: M1 ﬁxes these inputs
as above, and M2 only sets bi := ideal and lets the simu-
lator determine the inputs si and ti.
3.5 Security of the Single Protocol
We show that ˆM1 is as secure as ˆM2 (with respect to
computational standard simulatability. For this, we may as-
sume a given protocol user H and adversary A and need
to construct a simulator S such that H cannot distinguish
running with ˆM1 and A from running with ˆM2 and S. In-
tuitively, H can distinguish only if the respective function
evaluation outputs in ˆM1 and ˆM2 differ. So S must only en-
sure that the function outputs in ˆM2 are as they would have
been in ˆM1 (where the inputs of M1 are different from those
of the ideal-model machine M2).
More speciﬁcally, S runs A as a black box, so that com-
munication between A and H is the same in the real and in
the ideal model. The only thing that S needs to do on its
own is to answer M2’s question for the strength si and the
solution ti. When asked for these inputs, S chooses and
solves a puzzle of hardness si more than twice as large as
the largest hardness H could solve.5 (The time-lock puzzle
deﬁnition guarantees that such an S exists for ﬁxed H.) The
situation is depicted in Figure 2.
This way, S solves a puzzle of such large hardness si that
when evaluating f , this puzzle appears in the last position
in the sorted list (si1 , si2 , . . . , sin) (cf. the deﬁnition of f in
Section 3.3) and is at least twice as hard as the preceding
puzzle sin−1 (or there is an invalid solution tij with over-
whelming probability). Thus, if sin = si < 2n, then al-
ready sin−1 < 2n−1. So intuitively, it is never the “fault” of
M2 when f evaluates to false; the same would have hap-
pened in the real model with a machine M1. Conversely, if
already one of the sij (j < n) is smaller than 2j or does
not have a valid solution, then f will return false inde-
pendently of sin. So it is never the “fault” of M2 when f
evaluates to true, either.
In other words, the output of the SFE of f has the same
distribution, regardless of whether H runs with ˆM1 and A,
or with ˆM2 and S. Due to the secrecy of the SFE, this im-
plies that the internal messages of the SFE and therefore the
views of H are also indistinguishable in these two scenarios.
So we get the following lemma:
Lemma 3.1. Assume enhanced trapdoor permutations and
systems for time-lock puzzles exist. Then protocol ˆM1 from
above is as secure as protocol ˆM2 from above with respect
to computational standard simulatability.
This also holds when the honest user has access to an
auxiliary input (that may even be chosen after the simula-
tor).
The complete proof will be given in the full version of
this paper.
3.6 Insecurity under k-fold Concurrent
Composition
Lemma 3.2. Assume that systems for time-lock puzzles ex-
ist. Then for the protocols ˆM1 and ˆM2 from above, we have
that ˆM k
2 with respect to computa-
tional standard simulatability.
1 is not as secure as ˆM k
This does not depend on whether the honest user has
auxiliary input or not.
Proof. We show that ˆM k
2 . For this,
we give a special adversary A and protocol user H such that
no simulator S can mimic A in the ideal model.
1 is not as secure as ˆM k
5In the formal proof, we need a larger, yet still polynomial bound for
technical reasons.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
Mπ
real, 0, ε
qi
-
Pi
L


J
L


J
J
L


L

J

L

J


J
L


XXXXXX

LL
cc
Pi−1
Pi+1
A
Pk
...
P1
...
H
Mτ
ideal, si, ti
qi
si

qi
ti

Sp
A
-
J
-
Pi
L
J


L
J


L


L
J


L
J



J
L


XXXXXX

LL

cc
Pi−1
Pi+1
Pk
...
P1
...
H
Figure 2. Left-hand side: a single execution of protocol ˆM1 with adversary A and user H; right-hand
side: a single execution of protocol ˆM2 with simulator S and user H. The simulated parties P1, . . . , Pk
perform a secure function evaluation protocol both in ˆM1 and in ˆM2.
Let A be a machine that does nothing at all (note that
since ˆM1 is a one-party-protocol, the adversary does not
need to deliver any messages). Let H be such that, when
running with k protocol machines (either k copies of M1 or
k copies of M2), it behaves as follows:
1. FOR i := 1 TO k: Tell the i-th protocol machine (i.e.,
the i-th copy of either M1 or M2) to take the role of Pi.
END FOR
2. Whenever the i-th protocol machine wants to send a
message to the j-th protocol machine, relay this mes-
sage. (When the i-th protocol machine wants to broad-
cast a message, deliver that message to all protocol ma-
chines.)
3. As soon as the ﬁrst protocol machine generates output,
halt.
By deﬁnition of f , in the real model, running with A
and k copies of M1, this honest user H will experience a
function evaluation output out = true (i.e., at least one
copy of M1 will output true to the honest user H). Thus,
a successful simulator S has to achieve a function evalua-
tion output out = true as well with overwhelming prob-
ability. By deﬁnition of f and the ideal machines M2, this
means that it has to supply valid solutions ti to puzzles of
hardness si where at least one satisﬁes si ≥ 2k (since all
bi = ideal). However, this directly contradicts the hard-
ness requirement in the time-lock puzzle deﬁnition, since
S has to be polynomial-time. Therefore no such simulator
exists and H can always distinguish ˆM1 and ˆM2.
Combining Lemmas 3.1 and 3.2, we can summarize:
Theorem 3.3. Assume that enhanced trapdoor permuta-
tions and systems for time-lock puzzles exist. Then com-
putational standard simulatability does not guarantee poly-
nomially bounded concurrent composability. That is, there
are protocols ˆM1 and ˆM2, such that with respect to compu-
tational standard simulatability, ˆM1 is as secure as ˆM2, but
the composed protocol ˆM k
1 is not as secure as ˆM k
2 .
This holds regardless of whether the honest user has ac-
cess to an auxiliary input or not.
4 The Statistical Case
In contrast to the case of computational security, we will
show that for statistical (i.e., information theoretical) secu-
rity a concurrent composition theorem indeed holds.
First some investigation of the actual deﬁnition of statis-
tical security is necessary. The deﬁnition of statistical se-
curity for the RS framework in [11] requires the following:
Polynomial preﬁxes of the views of the honest user in the
ideal and real model shall be statistically indistinguishable.
However, in [30] it was shown that this notion is problem-
atic. It was shown that due to the restriction to polynomial
preﬁxes of views not even the simple composability holds,
even in the case of universal security. Further it was shown
in [30] that the natural correction of the problem, namely
removing the restriction to polynomial preﬁxes, ﬁxes the
(simple) composition theorem.
Therefore, we will adapt the following deﬁnition of sta-
tistical standard security:
Deﬁnition 4.1 (Strict statistical security (as in [30], slightly
simpliﬁed)). Let ˆMπ and ˆMτ be protocols. We say that
ˆMπ is as secure as ˆMτ with respect to standard statistical
security iff the following holds:
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
For every honest user H and real adversary A, there is a
simulator S, s.t. the statistical distance between the follow-
ing families of views is negligible in k:
{view H,A, ˆMπ,k(H)}k,
{view H,S, ˆMτ ,k(H)}k
(Here view X(H) denotes the view of H in a run of X.)
When the simulator S does not depend on the adversary
A, we speak of statistical universal security.
When referring to Def. 4.1 we will simply speak of sta-
tistical security for brevity.
4.1 Proving Polynomially Bounded Con-
current Composability
Here, we ﬁrst review the idea of how to show concurrent
composability in the case of universal security, and argue
why the proof idea doesn’t apply to standard security.
When investigating proofs of concurrent composabil-
ity (in the case of universal security, for more details see
e.g., [15, 10]), we see that the main proof idea is approx-