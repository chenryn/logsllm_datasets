### Time-Lock Puzzle Protocol Evaluation

Each party \( P_i \) takes as its initial input a tuple \((b_i, s_i)\) and, after communicating with \( k-1 \) other parties, outputs a time-lock puzzle \( q_i \) as specified by the function \( f \). Subsequently, \( P_i \) expects a second input \( t_i \) and, after further communication, produces the final output as prescribed by \( f \).

Using the programs of these parties, we define the protocol machines \( M_1 \) and \( M_2 \), which constitute the protocols \( \hat{M}_1 \) and \( \hat{M}_2 \), respectively. Specifically, the program for \( M_1 \) is as follows:

1. **Request Party Index:**
   - Ask the protocol user \( H \) for a party index \( i \in \{1, \ldots, k\} \).

2. **Run Internal Program:**
   - Internally run the program \( P_i \) with the following settings:
     - First inputs: \( b_i := \text{real} \) and \( s_i := 0 \).
     - Second input: \( t_i := \epsilon \) (where \( \epsilon \) denotes the empty word).
     - Ignore the first output of \( P_i \).
   - Forward all outgoing messages to \( H \) (prefixed with the recipient party index or indicated as a broadcast).
   - Relay messages from \( H \) that are prefixed with a party index \( j \neq i \) to the internal \( P_i \) as if they were coming from \( P_j \).

3. **Final Output:**
   - As soon as \( P_i \) generates its final output \( \text{out} \), forward this output to \( H \) and halt.

In essence, \( M_1 \) asks \( H \) for a party index \( i \) and then participates in the evaluation of \( f \) in the role of \( P_i \). The local inputs for \( P_i \) are fixed, and all network communication is relayed through \( H \). The final output of the evaluated function is eventually sent to \( H \).

The protocol \( \hat{M}_1 \) consists solely of the machine \( M_1 \). Conversely, the protocol \( \hat{M}_2 \) consists of a single machine \( M_2 \) defined similarly but with a different approach to setting the local inputs for \( P_i \):

1. **Request Party Index:**
   - Ask the protocol user \( H \) for a party index \( i \in \{1, \ldots, k\} \).

2. **Run Internal Program:**
   - Internally run the program \( P_i \) with the following settings:
     - First input: \( b_i := \text{ideal} \).
     - Request the value of \( s_i \) from the simulator.
     - Send the first output \( q_i \) to the simulator and expect a second input \( t_i \).
   - Forward all outgoing messages to \( H \) (prefixed with the recipient party index or indicated as a broadcast).
   - Relay messages from \( H \) that are prefixed with a party index \( j \neq i \) to the internal \( P_i \) as if they were coming from \( P_j \).

3. **Final Output:**
   - As soon as \( P_i \) generates its final output \( \text{out} \), forward this output to \( H \) and halt.

The key difference between \( M_1 \) and \( M_2 \) lies in how the local inputs to \( P_i \) are determined. \( M_1 \) fixes the inputs as described, while \( M_2 \) sets \( b_i := \text{ideal} \) and allows the simulator to determine the values of \( s_i \) and \( t_i \).

### Security of the Single Protocol

We demonstrate that \( \hat{M}_1 \) is as secure as \( \hat{M}_2 \) with respect to computational standard simulatability. To do this, we assume a given protocol user \( H \) and adversary \( A \), and construct a simulator \( S \) such that \( H \) cannot distinguish between running with \( \hat{M}_1 \) and \( A \) versus running with \( \hat{M}_2 \) and \( S \). Intuitively, \( H \) can only distinguish if the function evaluation outputs in \( \hat{M}_1 \) and \( \hat{M}_2 \) differ. Therefore, \( S \) must ensure that the function outputs in \( \hat{M}_2 \) match those in \( \hat{M}_1 \).

Specifically, \( S \) runs \( A \) as a black box, ensuring that communication between \( A \) and \( H \) is identical in both the real and ideal models. The only additional task for \( S \) is to provide the strength \( s_i \) and solution \( t_i \) when requested by \( M_2 \). When asked, \( S \) chooses and solves a puzzle of hardness \( s_i \) more than twice as large as the largest hardness \( H \) could solve. This ensures that the puzzle appears last in the sorted list of puzzles and is at least twice as hard as the preceding puzzle. Thus, the output of the secure function evaluation (SFE) of \( f \) has the same distribution, regardless of whether \( H \) runs with \( \hat{M}_1 \) and \( A \), or with \( \hat{M}_2 \) and \( S \). Due to the secrecy of the SFE, the internal messages and views of \( H \) are indistinguishable in both scenarios.

**Lemma 3.1:** Assume enhanced trapdoor permutations and systems for time-lock puzzles exist. Then protocol \( \hat{M}_1 \) is as secure as protocol \( \hat{M}_2 \) with respect to computational standard simulatability. This holds even if the honest user has access to an auxiliary input.

### Insecurity under k-Fold Concurrent Composition

**Lemma 3.2:** Assume that systems for time-lock puzzles exist. For the protocols \( \hat{M}_1 \) and \( \hat{M}_2 \), \( \hat{M}_1^k \) is not as secure as \( \hat{M}_2^k \) with respect to computational standard simulatability. This does not depend on whether the honest user has auxiliary input.

**Proof:** We show that \( \hat{M}_1^k \) is not as secure as \( \hat{M}_2^k \) by providing a special adversary \( A \) and protocol user \( H \) such that no simulator \( S \) can mimic \( A \) in the ideal model. Let \( A \) be a machine that does nothing. Let \( H \) behave as follows when running with \( k \) protocol machines (either \( k \) copies of \( M_1 \) or \( k \) copies of \( M_2 \)):

1. **Assign Roles:**
   - For \( i := 1 \) to \( k \), tell the \( i \)-th protocol machine to take the role of \( P_i \).

2. **Relay Messages:**
   - Whenever the \( i \)-th protocol machine wants to send a message to the \( j \)-th protocol machine, relay the message. If the \( i \)-th protocol machine broadcasts a message, deliver it to all protocol machines.

3. **Halt on Output:**
   - As soon as the first protocol machine generates output, halt.

By the definition of \( f \), in the real model, running with \( A \) and \( k \) copies of \( M_1 \), the honest user \( H \) will experience a function evaluation output \( \text{out} = \text{true} \). A successful simulator \( S \) must achieve the same output with overwhelming probability. This means \( S \) must supply valid solutions \( t_i \) to puzzles of hardness \( s_i \) where at least one satisfies \( s_i \geq 2k \). However, this contradicts the hardness requirement in the time-lock puzzle definition, as \( S \) must be polynomial-time. Therefore, no such simulator exists, and \( H \) can always distinguish \( \hat{M}_1 \) and \( \hat{M}_2 \).

**Theorem 3.3:** Assume that enhanced trapdoor permutations and systems for time-lock puzzles exist. Computational standard simulatability does not guarantee polynomially bounded concurrent composability. There are protocols \( \hat{M}_1 \) and \( \hat{M}_2 \) such that, with respect to computational standard simulatability, \( \hat{M}_1 \) is as secure as \( \hat{M}_2 \), but the composed protocol \( \hat{M}_1^k \) is not as secure as \( \hat{M}_2^k \). This holds regardless of whether the honest user has access to an auxiliary input.

### Statistical Security

For statistical (information-theoretical) security, we show that a concurrent composition theorem indeed holds. The definition of statistical security for the RS framework requires that polynomial prefixes of the views of the honest user in the ideal and real models be statistically indistinguishable. However, this notion is problematic, as shown in [30], because it does not even guarantee simple composability. The natural correction, removing the restriction to polynomial prefixes, fixes the composition theorem.

**Definition 4.1 (Strict Statistical Security):** Let \( \hat{M}_\pi \) and \( \hat{M}_\tau \) be protocols. We say that \( \hat{M}_\pi \) is as secure as \( \hat{M}_\tau \) with respect to standard statistical security if, for every honest user \( H \) and real adversary \( A \), there is a simulator \( S \) such that the statistical distance between the following families of views is negligible in \( k \):
- \(\{\text{view}_{H, A, \hat{M}_\pi, k(H)}\}_k\)
- \(\{\text{view}_{H, S, \hat{M}_\tau, k(H)}\}_k\)

When the simulator \( S \) does not depend on the adversary \( A \), we speak of statistical universal security.

### Proving Polynomially Bounded Concurrent Composability

To show concurrent composability in the case of universal security, we review the main proof idea. The key idea is to approximate the behavior of the simulator in the ideal model to match the real model. However, this approach does not directly apply to standard security due to the need for stronger guarantees.