tion evaluation. That is, each Pi takes as local ï¬rst input
a tuple (bi, si) as above and eventuallyâ€”after having com-
municated with k âˆ’ 1 other partiesâ€”outputs a time-lock
puzzle qi as speciï¬ed by f . Then Pi expects a second input
ti and ï¬nallyâ€”after further communicationâ€”outputs out
as prescribed by f .
Using the programs of these parties, we deï¬ne the proto-
col machines M1 and M2 which make up the protocols Ë†M1,
resp. Ë†M2.4 Namely, let M1â€™s program be as follows:
1. Ask the protocol user H for a party index i âˆˆ
{1, . . . , k}.
2. Run the program Pi internally, where
â€¢ Piâ€™s ï¬rst inputs are set to bi := real and si := 0,
and the second input is ti := Îµ (where Îµ denotes
the empty word). The ï¬rst output of Pi is simply
ignored.
â€¢ All outgoing messages are sent to H (preï¬xed
with the recipient party index or indicated as a
broadcast).
4In our example, each protocol consists of only one machine.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&Pâ€™06) 
1081-6011/06 $20.00 Â© 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
â€¢ Messages coming from H that are preï¬xed with
a party index j (cid:6)= i are forwarded to the internal
Pi as if coming from Pj.
3. As soon as Pi generates its ï¬nal output out, forward
this output to H and halt.
In other words, M1 asks H for a party index i and then
expects to take part in an evaluation of f in the role of Pi.
Here, Piâ€™s local inputs are ï¬xed to bi := real, si := 0, and
ti := Îµ, and all network communication is relayed over H.
The evaluated function output is eventually forwarded to H.
As mentioned earlier, the protocol Ë†M1 then consists only
of this single machine M1. On the other hand, protocol
Ë†M2 consists of only one machine M2 that is deï¬nedâ€”very
similarlyâ€”as follows:
1. Ask the protocol user H for a party index i âˆˆ
{1, . . . , k}.
2. Run the program Pi internally, where
â€¢ Piâ€™s ï¬rst inputs are set to bi := ideal, and the
simulator is asked for the value of si. When the
ï¬rst output qi has been generated, it is sent to the
simulator, and a second input ti is expected.
â€¢ All outgoing messages are sent to H (preï¬xed
with the recipient party index or indicated as a
broadcast).
â€¢ Messages coming from H that are preï¬xed with
a party index j (cid:6)= i are forwarded to the internal
Pi as if coming from Pj.
3. As soon as Pi generates its ï¬nal output out, forward
this output to H and halt.
The only difference between M1 and M2 lies in the way
the local inputs to Pi are determined: M1 ï¬xes these inputs
as above, and M2 only sets bi := ideal and lets the simu-
lator determine the inputs si and ti.
3.5 Security of the Single Protocol
We show that Ë†M1 is as secure as Ë†M2 (with respect to
computational standard simulatability. For this, we may as-
sume a given protocol user H and adversary A and need
to construct a simulator S such that H cannot distinguish
running with Ë†M1 and A from running with Ë†M2 and S. In-
tuitively, H can distinguish only if the respective function
evaluation outputs in Ë†M1 and Ë†M2 differ. So S must only en-
sure that the function outputs in Ë†M2 are as they would have
been in Ë†M1 (where the inputs of M1 are different from those
of the ideal-model machine M2).
More speciï¬cally, S runs A as a black box, so that com-
munication between A and H is the same in the real and in
the ideal model. The only thing that S needs to do on its
own is to answer M2â€™s question for the strength si and the
solution ti. When asked for these inputs, S chooses and
solves a puzzle of hardness si more than twice as large as
the largest hardness H could solve.5 (The time-lock puzzle
deï¬nition guarantees that such an S exists for ï¬xed H.) The
situation is depicted in Figure 2.
This way, S solves a puzzle of such large hardness si that
when evaluating f , this puzzle appears in the last position
in the sorted list (si1 , si2 , . . . , sin) (cf. the deï¬nition of f in
Section 3.3) and is at least twice as hard as the preceding
puzzle sinâˆ’1 (or there is an invalid solution tij with over-
whelming probability). Thus, if sin = si < 2n, then al-
ready sinâˆ’1 < 2nâˆ’1. So intuitively, it is never the â€œfaultâ€ of
M2 when f evaluates to false; the same would have hap-
pened in the real model with a machine M1. Conversely, if
already one of the sij (j < n) is smaller than 2j or does
not have a valid solution, then f will return false inde-
pendently of sin. So it is never the â€œfaultâ€ of M2 when f
evaluates to true, either.
In other words, the output of the SFE of f has the same
distribution, regardless of whether H runs with Ë†M1 and A,
or with Ë†M2 and S. Due to the secrecy of the SFE, this im-
plies that the internal messages of the SFE and therefore the
views of H are also indistinguishable in these two scenarios.
So we get the following lemma:
Lemma 3.1. Assume enhanced trapdoor permutations and
systems for time-lock puzzles exist. Then protocol Ë†M1 from
above is as secure as protocol Ë†M2 from above with respect
to computational standard simulatability.
This also holds when the honest user has access to an
auxiliary input (that may even be chosen after the simula-
tor).
The complete proof will be given in the full version of
this paper.
3.6 Insecurity under k-fold Concurrent
Composition
Lemma 3.2. Assume that systems for time-lock puzzles ex-
ist. Then for the protocols Ë†M1 and Ë†M2 from above, we have
that Ë†M k
2 with respect to computa-
tional standard simulatability.
1 is not as secure as Ë†M k
This does not depend on whether the honest user has
auxiliary input or not.
Proof. We show that Ë†M k
2 . For this,
we give a special adversary A and protocol user H such that
no simulator S can mimic A in the ideal model.
1 is not as secure as Ë†M k
5In the formal proof, we need a larger, yet still polynomial bound for
technical reasons.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&Pâ€™06) 
1081-6011/06 $20.00 Â© 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
MÏ€
real, 0, Îµ
qi
-
Pi
L


J
L


J
J
L


L

J

L

J


J
L


XXXXXX

LL
cc
Piâˆ’1
Pi+1
A
Pk
...
P1
...
H
MÏ„
ideal, si, ti
qi
si

qi
ti

Sp
A
-
J
-
Pi
L
J


L
J


L


L
J


L
J



J
L


XXXXXX

LL

cc
Piâˆ’1
Pi+1
Pk
...
P1
...
H
Figure 2. Left-hand side: a single execution of protocol Ë†M1 with adversary A and user H; right-hand
side: a single execution of protocol Ë†M2 with simulator S and user H. The simulated parties P1, . . . , Pk
perform a secure function evaluation protocol both in Ë†M1 and in Ë†M2.
Let A be a machine that does nothing at all (note that
since Ë†M1 is a one-party-protocol, the adversary does not
need to deliver any messages). Let H be such that, when
running with k protocol machines (either k copies of M1 or
k copies of M2), it behaves as follows:
1. FOR i := 1 TO k: Tell the i-th protocol machine (i.e.,
the i-th copy of either M1 or M2) to take the role of Pi.
END FOR
2. Whenever the i-th protocol machine wants to send a
message to the j-th protocol machine, relay this mes-
sage. (When the i-th protocol machine wants to broad-
cast a message, deliver that message to all protocol ma-
chines.)
3. As soon as the ï¬rst protocol machine generates output,
halt.
By deï¬nition of f , in the real model, running with A
and k copies of M1, this honest user H will experience a
function evaluation output out = true (i.e., at least one
copy of M1 will output true to the honest user H). Thus,
a successful simulator S has to achieve a function evalua-
tion output out = true as well with overwhelming prob-
ability. By deï¬nition of f and the ideal machines M2, this
means that it has to supply valid solutions ti to puzzles of
hardness si where at least one satisï¬es si â‰¥ 2k (since all
bi = ideal). However, this directly contradicts the hard-
ness requirement in the time-lock puzzle deï¬nition, since
S has to be polynomial-time. Therefore no such simulator
exists and H can always distinguish Ë†M1 and Ë†M2.
Combining Lemmas 3.1 and 3.2, we can summarize:
Theorem 3.3. Assume that enhanced trapdoor permuta-
tions and systems for time-lock puzzles exist. Then com-
putational standard simulatability does not guarantee poly-
nomially bounded concurrent composability. That is, there
are protocols Ë†M1 and Ë†M2, such that with respect to compu-
tational standard simulatability, Ë†M1 is as secure as Ë†M2, but
the composed protocol Ë†M k
1 is not as secure as Ë†M k
2 .
This holds regardless of whether the honest user has ac-
cess to an auxiliary input or not.
4 The Statistical Case
In contrast to the case of computational security, we will
show that for statistical (i.e., information theoretical) secu-
rity a concurrent composition theorem indeed holds.
First some investigation of the actual deï¬nition of statis-
tical security is necessary. The deï¬nition of statistical se-
curity for the RS framework in [11] requires the following:
Polynomial preï¬xes of the views of the honest user in the
ideal and real model shall be statistically indistinguishable.
However, in [30] it was shown that this notion is problem-
atic. It was shown that due to the restriction to polynomial
preï¬xes of views not even the simple composability holds,
even in the case of universal security. Further it was shown
in [30] that the natural correction of the problem, namely
removing the restriction to polynomial preï¬xes, ï¬xes the
(simple) composition theorem.
Therefore, we will adapt the following deï¬nition of sta-
tistical standard security:
Deï¬nition 4.1 (Strict statistical security (as in [30], slightly
simpliï¬ed)). Let Ë†MÏ€ and Ë†MÏ„ be protocols. We say that
Ë†MÏ€ is as secure as Ë†MÏ„ with respect to standard statistical
security iff the following holds:
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&Pâ€™06) 
1081-6011/06 $20.00 Â© 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
For every honest user H and real adversary A, there is a
simulator S, s.t. the statistical distance between the follow-
ing families of views is negligible in k:
{view H,A, Ë†MÏ€,k(H)}k,
{view H,S, Ë†MÏ„ ,k(H)}k
(Here view X(H) denotes the view of H in a run of X.)
When the simulator S does not depend on the adversary
A, we speak of statistical universal security.
When referring to Def. 4.1 we will simply speak of sta-
tistical security for brevity.
4.1 Proving Polynomially Bounded Con-
current Composability
Here, we ï¬rst review the idea of how to show concurrent
composability in the case of universal security, and argue
why the proof idea doesnâ€™t apply to standard security.
When investigating proofs of concurrent composabil-
ity (in the case of universal security, for more details see
e.g., [15, 10]), we see that the main proof idea is approx-