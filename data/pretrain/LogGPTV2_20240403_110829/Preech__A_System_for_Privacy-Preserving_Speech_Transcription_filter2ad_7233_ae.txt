the presence of only one speaker. Thus, not only does Prεεch
hide the speaker’s biometrics and map them to a single target
speaker but also ensures noise indistinguishability, which is
key to its privacy properties.
The second experiment tests Prεεch’s privacy properties
against a stronger adversary, who has access to samples from
the true speakers. We enroll segments from the true speakers
as well as the fake target speaker to Azure’s Speaker Identiﬁ-
cation API. We pass the segments from Prεεch (after adding
dummy segments and applying VC) to the API. When many-
to-one VC is applied, in all evaluation cases, the API identiﬁes
the segments as belonging to the fake target speaker. Not a
single segment was matched to the original speaker. Both ex-
periments show that prototype Prεεch is effective in sanitizing
the speaker’s voice and ensuring noise indistinguishability.
2714    29th USENIX Security Symposium
USENIX Association
0.95.(cid:2786).(cid:2785)..,.Datasets
VCTK p266
VCTK p262
Facebook
Carpenter
|V |
483
471
1098
1474
# words
in T g
S
#Extra words due to dummy segments
d=2
d=15
d=5
922 ($0.22)
914 ($0.21)
5326 ($1.24)
7703 ($1.80)
2915 ($0.68)
2845 ($0.66)
6660 ($1.55)
8915 ($2.08)
7247 ($1.69)
7157 ($1.67)
16567 ($3.87)
22296 ($5.20)
23899 ($5.58)
23230 ($5.42)
54038 ($12.62)
72907 ($17.02)
Table 3: Number of extra words due to dummy segments
and the additional monetary cost in USD with varying d,
at ε = 1 and δ = 0.05.
7.3 Q3. Textual Privacy
We perform an extensive evaluation of the textual privacy,
including sensitive word scrubbing, analysis of the DP mech-
anism, and defense against statistical analysis.
7.3.1 Sensitive Words Scrubbing:
We run PocketSphinx keyword spotting on each dataset at dif-
ferent sensitivity scores ranging from 0.2 to 117. Fig. 5 shows
the detection true positive rate (TPR) versus the false positive
rate (FPR) at different sensitivity scores. As the ﬁgure shows,
the sensitivity score is a trade-off knob between privacy (high
TPR) and utility (low FPR). We observe that Prεεch is able
to achieve almost perfect TPR with low FPR values.
Next, we evaluate the impact of SWS on the transcription
utility. We set a sensitivity score of 0.95 for all the datasets to
have a near-perfect TPR while minimizing the FPR. Our ex-
periments show that the total duration of the segments ﬂagged
with sensitive keywords at this score is: 0.13%, 0.06%, 0.18%,
0.20%, and 0.08% of the total duration of each dataset in
Fig. 5. Then, we transcribe the sensitive-ﬂagged segments
using Deep Speech. The overall transcription accuracy after
SWS (i.e., equivalent to choosing voice cloning in Prεεch as
cloning results in no addition WER) is presented in the second
column of Table 2. Since the segments are short, the portion
of speech transcribed locally is limited. Hence, the impact of
the OSP transcription errors is not signiﬁcant.
7.3.2 DP Mechanism Analysis:
We follow the DP mechanism described in Sec. 4.5.3.
Vocabulary Estimation: We estimate the vocabulary V us-
ing the OSP transcript. Let W represent the set of unique
words in T g
S . We deﬁne the accuracy of the vocabulary es-
timation, Dacc, as the ratio between the count of the cor-
, |W |est, and the
rectly identiﬁed unique words from T OSP
S , |W |. For our datasets,
count of the unique words in T g
the domain estimation accuracy is at least 75.54%. We
also calculate the weighted estimation accuracy deﬁned as:
S
Figure 6: Sentiment scores heatmap of 10 doc-
uments with varying d, at ε = 1 and δ = 0.05.
∑P(west ).1west∈W
|W |
Dweighted =
where P(west ) is the weight of
the estimated word west in T g
S . Dweighted is more informative
since it gives higher weights to the most frequent words in T g
S .
The weighted estimation accuracy is 99.989% in our datasets.
From West we select V over which we apply the DP mecha-
nism. Additionally, we extend our vocabulary to contain a set
of random words from the English dictionary.
Histogram Distance: We analyze the distance between the
original and noisy histograms (after applying Prεεch) and
its impact on the cost of online transcription. Because of the
nature of Prεεch’s DP mechanism, the noise addition depends
on four values only: |V |, ε, δ, and d.
For all our experiments, we ﬁx the values of ε = 1 and δ =
0.05. Table 3 shows the amount of noise (dummy words) and
their transcription cost in USD 18 for each of the evaluation
datasets at different values of d. Each dataset has a different
vocabulary size |V | and word count. The increase in the
vocabulary size requires adding more dummy segments to
maintain the same privacy level. In Prεεch, adding more noise
comes at an increased monetary cost, instead of a utility loss.
The table highlights the trade-off between privacy and the
cost of adding noise.
7.3.3 Statistical Analysis
In this section, we evaluate the statistical analyses (details
in Sec. 3.2) performed by the adversary to extract textual
information on the noisy transcripts obtained from Prεεch.
Topic Model: We generate the topic models from the doc-
uments corresponding to the original and noisy word his-
tograms, and evaluate their (cid:96)1 distance. The topic model oper-
ates on a corpus of documents; hence we include eight more
Supreme Court cases to our original evaluation datasets (Face-
book and Carpenter). In this evaluation, we treat all these ten
documents as one corpus; we aim to generate the topic model
before and after applying Prεεch to the whole corpus.
We use AWS Comprehend API to generate the topic model.
The API needs the number of topics as a hyperparameter that
ranges from 1 to 100. Based on our apriori knowledge of the
17The sensitive keywords list for each dataset is in the full paper [3] .
18The pricing model of Google Speech-to-Text is: $0.009 / 15 seconds.
USENIX Association
29th USENIX Security Symposium    2715
(a) 8 topics
(b) 10 topics
(c) 12 topics
(d) 14 topics
Figure 7: Topics (cid:96)1 distance CDF at d = 2, 5, and 15 for t = 8, 10, 12, and 14
true number of topics, we evaluate the topic model on the
following number of topics t = 8,10,12, and 14.
We statistically evaluate the (cid:96)1 distance between true and
noisy topics. The topic model T = {T1,··· ,Tt} is a set of
t topics where each Ti,i ∈ [t] is a word distribution. We use
i ∈ T (cid:48)
the Hungarian algorithm to match each noisy topic T(cid:48)
to its closest match in T , the true topic model. We evaluate
the topics (cid:96)1 distance for 21 runs. At each run, we generate a
random noise vector per document, select the corresponding
dummy segments, and evaluate the topic model on the set
of original and noisy documents. Fig. 7 shows the empirical
CDF of the topics (cid:96)1 distance at different values of d. As the
ﬁgure shows, the higher the distance parameter d, the larger
is the (cid:96)1 distance between true and noisy topics.
Stylometry: In this experiment, we assume that the CSP ap-
plies stylometry analysis on T CSP
in an attempt to attribute
it to an auxiliary document whose authors are known to the
CSP. To evaluate the worst-case scenario, we assume the ad-
versary possesses the original document T g
S , and we compute
the (cid:96)2 distance of the stylometric feature vectors generated
from T CSP
S
w.r.t T g
S .
S
S
S
differs from T g
First, we compute the (cid:96)2 distance of T CSP
before applying
Prεεch. The respective values for the Facebook and Carpenter
datasets are 28.19 and 60.45. T CSP
S in lexical
features due to transcription errors and because the CSP gen-
erates the punctuation instead of the actual author.
Second, we apply Prεεch on the two datasets at different
values of the distance parameter: d = 0,2,5,15. The corre-
sponding (cid:96)2 distances for the Facebook (Carpenter) dataset
equal: 73.14 (83.64), 328.80 (577.72), 947.58 (1629.79), and
2071.18 (3582.10). Note that the (cid:96)2 distance at d = 0 shows
the effect of segmentation and SWS only on obfuscating
the lexical features. Clearly, adding the dummy segments
increases the (cid:96)2 distance. This is expected as most of the
lexical features are obfuscated by the DP mechanism.
Category Classiﬁcation: Google’s NLP API can classify a
document to a predeﬁned list of 700+ document categories19.
First, we run the classiﬁcation API on the original documents
from the topic modeling corpus. All of them classify as Law
& Government. Running the API on Prεεch processed docu-
ments, using an extended-vocabulary (i.e., contains random
words), dropped the classiﬁcation accuracy to 0%. None of
the documents got identiﬁed as legal, law, or government even
at the smallest distance parameter value d = 2. Although a
portion of the noise words belongs to the original Law &
Government category, segmentation, shufﬂing, and the out-of-
domain noise words successfully confuse the classiﬁer.
Sentiment Analysis: Sentiment analysis generates a score in
the [−1,1] range, which reﬂects the positive, negative, or neu-
tral attitude in the text. First, we evaluate the sentiment scores
of the original ten documents. For all of them, the score falls
between −0.2 and −0.9, which is expected as they represent
legal documents. Next, we evaluate the scores from Prεεch
processed documents considering an extended-vocabulary.
We ﬁnd that all scores increase towards a more positive opin-
ion. Fig. 6 shows a heatmap of the sentiment scores as we
change the distance parameter d for the then evaluation doc-
uments. Thus, Prεεch’s two-pronged approach – 1) addition
of extended-vocabulary noise 2) removal of ordering infor-
mation via segmentation and shufﬂing, proves to be effective.
In a setting where the adversary has no apriori knowledge
about the general domain of the processed speech, the noise
addition mechanism gains extend from DP guarantee over the
histogram to other NLP analyses as well.
7.3.4
Indistinguishability Of Dummy Segments
The indistinguishability of the dummy segments is critical
for upholding the DP guarantee in Prεεch. We perform two
experiments to analyze whether current state-of-the-art NLP
models can distinguish the dummy segments from their tex-
tual content.
Most Probable Next Segment: In this experiment, the adver-
sary has the advantage of knowing a true segment St that is at
least a few sentences long from the Facebook dataset. We use
the state-of-the-art GPT 20 language model by OpenAI [35]
to determine the most probable next segment following St
using the model’s perplexity score. In NLP, the perplexity
score measures the likelihood that a piece of text follows the
19https://cloud.google.com/natural-language/docs/categories
20https://github.com/huggingface/transformers
2716    29th USENIX Security Symposium
USENIX Association
Minimum segment length: Fig. 8 shows the trade-off be-
tween the number of words per segment and WER as function
of the minimum segment length. As expected, increasing the
minimum duration of a segment results in an increase in the
number of words per segment. The WER in turn drops when
the number of words per segment increase as the transcrip-
tion service has more textual context. However, it can lead to
potential privacy leakage. The results in Fig. 8 indicate that
for two real-world datasets, the number of words per segment
can be kept between 2 and 3 with an acceptable degradation
of the WER.
Voice Cloning: Voice cloning does not affect the true seg-
ments (it is only applied to dummy segments), resulting in no
additional WER degradation. The WER for deploying voice
cloning is incurred only due to segmentation and SWS. Thus,
as shown in column 2 of Table 2, the relative improvement
in WER ranges from 44% to 80% over Deep Speech. This
approach, however, has two limitations. First, the speaker’s
voice biometrics from S are not protected. Second, there is no
guarantee that an adversary would not be able to distinguish
the cloned speech segments from the original ones.
Sensitivity score of KWS: As shown in Fig. 5, lower the
sensitivity score, higher is the TPR and hence greater is the
privacy (most prominent in the Carpenter2 dataset). However,
this also increases the FPR, which means a larger number of
non-sensitive segments are transcribed via the OSP resulting
in reduced accuracy.
One-To-One VC: Table 2, column 3, shows that one-to-one
VC outperforms many-to-one VC on most of the datasets. This
result is expected since sprocket is trained and tested on the
same set of source speakers while the many-to-one VC system
generalizes to previously unseen speakers.
We observe that the improvement for the VCTK dataset is
more signiﬁcant than others. Recall that in our one-to-one
VC implementation in Sec. 6, the target voice for VCTK is a
natural voice – speaker p306. The target voice for the other
datasets is a synthetic one, which hinders the quality of the
converted voice and the transcription accuracy. We investigate
this observation by training sprocket for VCTK on a synthetic
target voice as well. The WER then increased to 19.33% and
9.21% for p266 and p262. Hence, we attribute the difference
in the relative improvement to the target voice naturalness. In
practice, the target voice could easily be a natural pre-recorded
voice, and the users are asked to repeat the same utterances at
the enrollment phase.
However, the one-to-one VC technique suffers from some
privacy loss. The one-to-one VC system translates the acoustic
features from a source to a target speaker’s voice. Hence, it
may leak some features from the source speaker. We observed
that one-to-one VC is vulnerable to speaker identiﬁcation
analysis. Speciﬁcally, using Azure’s Speaker Identiﬁcation
API, 10% of the voice-converted segments using sprocket
were identiﬁed to their true speakers.
(a) Facebook
(b) Carpenter
Figure 8: Segmentation trade-off between utility and privacy.
WER(%) is measured using Google Cloud Speech-to-Text.
language model. We get the perplexity score of stitching St to
each of the other segments at the CSP. The segment with the
lowest perplexity score is selected as the most probable next
segment. We iterate over all the true segments of the Facebook
dataset, selecting them as St. We observed that a dummy seg-
ment is selected as the most probable next segment in 53.84%
of the cases. This result shows that the language model could
not differentiate between the true and dummy segments even
when part of the true text is known to the adversary.
Segments Re-ordering: Next, we attempt to re-order the seg-
ments based on the perplexity score. We give the adversary
the advantage of knowing the ﬁrst true segment S0. We get the
perplexity score of S0, followed by each of the other segments.
The segment with the lowest score is selected as the second
segment S1 and so on. We use the normalized Kendall tau
rank distance Kτ to measure the sorted-ness of the re-ordered
segments. The normalized Kτ distance measures the number
of pairwise disagreements between two ranking lists, where 0
means perfect sorting, and 1 means the lists are reversed. The
Kτ score for running this experiment on the Facebook dataset
is 0.512, which means that the re-ordered list is randomly
shufﬂed w.r.t the true order. Hence, our attempt to re-order
the segments has failed.
These empirical results show that it is hard to re-order the seg-