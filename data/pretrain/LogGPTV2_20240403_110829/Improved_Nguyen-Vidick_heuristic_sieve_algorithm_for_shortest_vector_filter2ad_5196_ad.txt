√
1 −
(
N3 = c3n3(
(
)2 −
)n,
dmax
rmin
(
√
1 − γ2
2
3
1
2
γ2
3
γ2
3
1 +1
·γ3
−γ2
2γ3
− 2γ2
−γ2
3
2γ3
, cH1 =
3 +1−γ2
γ2
−γ2
√
2γ3
1
1− (cid:13)2
1
cH2
, cH2 = γ1
γ3
√
where dmax =
1 − γ2
γ3
4cH3
c3 is a positive constant unrelated to n. Let S be a subset of Cn(γ3R)∩Bn(c1, γ1R)∩
Bn(c2, γ2R)∩ Bn(c3, γ3R) of cardinality N whose points are picked independent-
ly at random with uniform distribution. If N3 < N < 2n, then for any subset
C ⊆ S of size at least N3 whose points are picked independently at random with
uniform distribution, with overwhelming probability, for all v ∈ S, there exists a
c ∈ C such that ∥v − c∥ ≤ γ3R.
(
1 − γ2
, cH3 = γ2
2 c2H1
4
, and
1
4γ2
3
1 +1
γ1
, rmin =
1
4
2
))2
)
Proof. Combining Lemma 2 and Lemma 3, we have
′′√
≥ c
Γn(γ1, γ2, γ3)
Ωn(γ1, γ2, γ3) =
Γn(γ1, γ2)
πn2
(
)n
.
rmin
dmax
Let N3 = c3n3( dmax
rmin
)n, the remaining proof is similar to that of Theorem 2.
The Optimal Time Complexity. Since
√
2πn3/2⌉ · (cH1 )n
{ N1 = ⌈3
√
√
= ⌈3
2πn3/2⌉ · (
1
1−γ2
√
γ1
2⌉ · ( cH2
{ N2 = c2⌈n 3
)n
√
1− (cid:13)2
= c2⌈n 3
2⌉ · (
1− (cid:13)2
√
{ N3 = c3n3 · ( dmax
(
)n
1−
1
4(cid:13)2
3
2 c2H1
dmin
(cid:13)1
(cid:13)3
)
rmin
1 +1
(cid:13)2
3
γ2
4
−(cid:13)2
2(cid:13)3
= c3n3 ·
)n,
1 /4
)n,
the total time complexity is
γ3
))
2
n
.
− (2(cid:13)2
3
−(cid:13)2
1 )((cid:13)2
3
4(cid:13)2
3
−(cid:13)2
1 +1)
(
1
cH2
·(cid:13)3
2−
3 +1−(cid:13)2
(cid:13)2
(
√
1− (cid:13)2
4cH3
2
2
3
N1N2N3(N1 + N2 + N3)
=2(log2 cH1 +log2
cH2
dmin
+log2
dmax
rmin
+log2 max{cH1 ,
cH2
dmin
, dmax
rmin
})·n+o(n).
The expression of the time complexity is so complicated, so we get a numerical
optimal solution. Taking γ3 from 0.88 to 1 with step 0.01, γ1 from 1 to 1.414γ3
with step 0.0001 and γ2 from 1 to γ1 with step 0.0001, then we can easily ﬁnd the
minimal value of the constant in the exponent for the optimal time complexity.
Theorem 4. The optimal time complexity of the algorithm is 20.3778n+o(n) poly-
nomial-time operations with γ3 → 1, γ1 = 1.1399, γ2 = 1.0677, and the corre-
sponding space complexity is 20.2833n+o(n) polynomially many bits under Heuris-
tic Assumption 1.
Remark 1. As in [21], the number of iterations is usually linear in the dimension
of lattices. Regardless of the number of iterations, the polynomial factors hidden
in the time complexity in NV algorithm and WLTB algorithm are respectively
n3 and n4.5. In our three level sieve algorithm, the polynomial parts of N1, N2
and N3 given by Theorem 1, 2, and 3 are n3/2, n3/2 and n3 respectively. So the
hidden polynomial factor in our algorithm is n9 without the number of iterations.
Remark 2. It is natural to extend the three-level sieve algorithm to multiple-
level, such as four-level algorithm. However, the number of small balls will in-
crease as the number of the levels increases. Therefore, we conjecture that the
time complexity may be decreased with small number levels, but will increase if
the number of levels is greater than some positive integer.
4 Experimental Results
4.1 Comparison with the Other Heuristic Sieve Algorithms
We implemented the NV algorithm, the WLTB algorithm and our three-level
sieve algorithm on a PC with Windows 7 system, 3.00 GHz Intel 4 processor
and 2 GByte RAM using Shoup’s NTL library version 5.4.1 [29]. Instead of im-
plementing the GaussSieve algorithm, we directly applied the GaussSieve Alpha
V.01 published by Voulgaris [30] on a PC with Fedora 15 system, 3.00 GHz Intel
4 processor and 2 GByte RAM.
We performed experiments to compare our three-level sieve algorithm with
the other three algorithms. For every dimension n, we ﬁrst used the method in
[19] to pick some random n-dimensional lattice and computed the LLL-reduced
basis, then we sampled the same number of lattice vectors, and performed the
NV algorithm with γ = 0.97, the WLTB algorithm with γ1 = 1.0927, γ2 = 0.97
and our three-level sieve algorithm with γ1 = 1.1399, γ2 = 1.0667, γ3 = 0.97
using these samples. We performed one experiments on lattices with dimension
10, 20 with more than 100000 samples, but about ﬁfty experiments with fewer
samples, and two experiments on dimension 25, 30, 40, 50. Instead of using our
samples, we just performed the GaussSieve Alpha V.01 with the selected lattices
as its inputs. The experimental results of the four algorithms are shown in Table
2, where v is the output vector of the corresponding algorithm.
dimension
10
20
25
30
40
50
60
number of sample
150000 100000 8000 5000
5000
3000
2000
time of sample(sec.)
301
810
87833 73375 147445 120607 167916
Time
(sec.)
∥v∥
λ1
NV alg.
WLTB alg.
Our alg.
GaussSieve alg.
NV alg.
WLTB alg.
Our three-level alg.
GaussSieve alg.
25005 64351
23760 18034
20942 13947
0.003
1
1
1
1
1
1
1
1
120
35
27
220
42
27
625
93
57
0.013 0.068 0.098 0.421
170.1
170.1
170.1
23.8
25.9
21.2
38.3
35.1
38.3
254
46
29
187
47
30
3.181 42.696
323
347.7
347.7
323
323
347.7
1
1
1
1
1
Table 2. Experimental results.
In our experiments, the GaussSieve algorithm is much faster than the others
and succeeds to ﬁnd the shortest vectors for all the lattices we picked. Besides of
the major reason that the GaussSieve algorithm performs better in practice (it
has been reported that the GaussSieve algorithm is more eﬃcient than the NV
algorithm), another possible reason is that our implementation is a little poor.
Compared with the NV and WLTB algorithms, it seems that our algorithm
may be slower for low dimensional lattices due to the larger hidden polynomial
factor. However, on one hand, the number of sieved vectors in each iteration
of our algorithm decreases faster because the number of small balls is larger,
which implies that the number of iterations is smaller and the number of the
vectors to be sieved in the next iteration is smaller as well. On the other hand,
the time complexity is for the worst case. In practice, we need not to check all
the big balls, medium balls and small balls to decide which small ball the sieved
vector belongs to. Thus, with the same number of samples in our experiments,
our algorithm runs faster than the NV and WLTB algorithms. Since the sample
procedure is very fast when the dimension n is not greater than twenty, we can
sample enough lattice vectors to ensure that the three algorithms can ﬁnd a
shortest nonzero lattice vector. In such case, the time of sieving overwhelms the
time of sampling, so our algorithm usually costs the least total time.
4.2 On Heuristic Assumption 1
To test the validity of the Heuristic Assumption 1 that the distribution of the
sieved vectors remains uniform, we picked four random lattices of dimension 10,
25, 40 and 50, sampled 150000, 8000, 5000, 3000 lattice vectors and then sieved
them respectively. As in [21], we plotted the number of sieved vectors in each
iteration (see Figure 5). It can be seen that the head and the tail of the curve
change slightly, but most of the curve, the middle part, decreases regularly. The
lost vectors in each iteration are those used as centers or reduced to zero which
means collisions occur. So the curve shows that the numbers of centers and
collisions in most of the iterations are nearly the same, which partially suggests
that the distribution of the sieved vectors is close to uniform throughout the
iterations.
5 Conclusion
In this paper, we propose a three-level heuristic sieve algorithm to solve SVP
and prove that the optimal running time is 20.3778n+o(n) polynomial-time oper-
ations and the space requirement is 20.2833n+o(n) polynomially many bits under
Heuristic Assumption 1.
Acknowledgement. We like to thank Michael Schneider very much for his
valuable suggestions on how to improve this paper. We also thank the anonymous
referees for their helpful comments. We are grateful to Panagiotis Voulgaris for
the publication of his implementation of the GaussSieve algorithm. Pan would
like to thank Hai Long for his help on the programming.
We would like to thank Thijs Laarhoven in Eindhoven University of Technology
very much, who pointed out there was some mistake in the previous version.
References
1. L. M. Adleman. On breaking generalized knapsack public key cryptosystems. In
the 15th Annual ACM Symposium on Theory of Computing Proceedings, pages
402-412. ACM, April 1983.
(a) n=10
(b) n=25
(c) n=40
(d) n=50
Fig. 5. Cardinality of the set of sieved vectors.
2. M. Ajtai. The shortest vector problem in l2 is NP-hard for randomized reductions.
In Proc. of 30th STOC. ACM, 1998.
3. M. Ajtai, R. Kumar, and D. Sivakumar. A sieve algorithm for the shortest lattice
vector problem. In Proc. 33rd STOC, pages 601-610. ACM, 2001.
4. J. Bl¨omer and S. Naewe. Sampling methods for shortest vectors, closest vectors and
successive minima. Theor. Comput. Sci. 410(18), 1648-1665 (2009).
5. K. B¨or¨oczky and G. Wintsche. Covering the sphere by equal spherical balls. Discrete
and Computational Geometry, The Goodman-Pollack Festschrift, 237-253, 2003.
6. U. Fincke and M. Pohst. A procedure for determining algebraic integers of given
norm. In Proc. of EUROCAL, volume 162 of LNCS, pages 19–202, 1983.
7. U. Fincke and M. Pohst. Improved methods for calculating vectors of short length
in a lattice, including a complexity analysis. Math. Comp., 44(170):463–471, 1985.
8. N. Gama, N. Howgrave-Graham, H. Koy, and P. Q. Nguyen. Rankin’s constant and
blockwise lattice reduction. In Proc. CRYPTO ’06, volume 4117 of Lecture Notes
in Computer Science, pages 112-130. Springer, 2006.
9. N. Gama and P. Q. Nguyen. Finding short lattice vectors within Mordell’s inequality.
In STOC ’08-Proc. 40th ACM Symposium on the Theory of Computing. ACM, 2008.
10. N. Gama, P. Q. Nguyen and O. Regev. Lattice enumeration using extreme prun-
ning. In Advances in Cryptology - EUROCRYPT 2010 Proceedings, pages 257-278.
Springer, May 2008.
11. J. Hoﬀstein, J. Pipher, J.H. Silverman. NTRU: a ring-based public key cryptosys-
tem. In Proc. of Algorithmic Number Theory, J.P. Buhler, Ed. Berlin, Germany:
Springer-Verlag, vol. 1423 of LNCS, pp. 267-288,1998.
12. R. Kannan. Improved algorithms for integer programming and related lattice prob-
lems. In Proc. of 15th STOC, pages 193-206. ACM, 1983.
01020304050607080030,00060,00090,000120,000150,000Iteration of Sieve  No. Vectors sieved0102030405060708090010002000300040005000600070008000Iteration of SieveNo. Vectors Sieved051015202530354045500500100015002000250030003500400045005000Iteration of SieveNo. Vectors sieved0510152025303540050010001500200025003000Iteration of SieveNo. Vectors sieved13. P. N. Klein. Finding the closest lattice vector when it’s unusually close. In Proc.
of SODA, pages 937-941. ACM, 2000.
14. A. K. Lenstra, H. W. Lenstra, Jr., and L. Lov´asz. Factoring polynomials with
rational coeﬃcients. Mathematische Ann., 261:513-534, 1982.
15. J. C. Lagarias and A. M. Odlyzko. Solving low-density subset sum problems. Jour-
nal of the ACM, 32(1): 229-246, 1985.
16. D. Micciancio and P. Voulgaris. A deterministic single exponential time algorithm
for most lattice problems based on Voronoi cell computations. In Proc. of STOC,
pages 351-358. ACM, 2010.
17. D. Micciancio and P. Voulgaris. Faster exponential time algorithms for the shortest
vector problem. In the 21th Annual ACM-SIAM Symposium on Discrete Algorithms
Proceedings, pages 1468-1480. SIAM, January 2010.
18. B. Milde and M. Schneider. A parallel implementation of GaussSieve for the short-
est vector problem in lattices. In Proceedings of the 11th International Conference
on Parallel Computing Technologies, volume 6873 of LNCS, pages 452-458. Springer,
2011.
19. P. Q. Nguyen and D. Stehle. LLL on the Average. In Proc. of the 7th International
Algorithmic Number Theory Symposium, (ANTS-VII), volume 4076 of LNCS, pages
238-256. Springer-Verlag, 2006.
20. P. Q. Nguyen and J. Stern. The two faces of lattices in cryptology. In Proc. of
CALC ’01, volume 2146 of LNCS. Springer-Verlag, 2001.
21. P. Q. Nguyen and T. Vidick. Sieve algorithms for the shortest vector problem are
practical. Journal of Mathematical Cryptology, 2(2):181-207, July 2008.
22. X. Pujol and D. Stehl´e. Solving the shortest lattice vector problem in time 22.465n.
Cryptology ePrint Archive, Report 2009/605, 2009.
23. O. Regev. Lecture notes on lattices in computer science, 2004. Available at
http://www.cs.tau.ac.il/ odedr/teaching/lattices fall 2004/index. html.
24. M. Schneider. Analysis of Gauss-Sieve for Solving the Shortest Vector Problem
in Lattices. In Proceedings of the 5th International Workshop of Algorithms and
Computation, WALCOM11, volume 6552 of LNCS, pages 89-97. Springer, 2011.
25. M. Schneider. Sieving for Shortest Vectors in Ideal Lattices. Africacrypt 2013,
LNCS 7918, pages 375-391, Springer 2013.
26. C. P. Schnorr. A hierarchy of polynomial lattice basis reduction algorithms. The-
oretical Computer Science, 53:201-224, 1987.
27. C. P. Schnorr and M. Euchner. Lattice basis reduction: improved practical algo-
rithms and solving subset sum problems. Mathematics of Programming, 66: 181-199,
1994.
28. A. Shamir. A polynomial time algorithm for breading the basic Merkel-Hellman
cryptosystem. In the 23rd IEEE Symposium On Foundations of Computer Science
Proceedings, pages 145-152. IEEE, 1982.
29. V. Shoup. NTL: A library
for doing number
theory. Available
at
http://www.shoup.net/ntl/
Gauss
30. P.
Voulgaris.
alpha
http://cseweb.ucsd.edu/ pvoulgar/impl.html.
Sieve
V.0.1
(2010).
Available
at
31. X. Wang, M. Liu, C. Tian and J. Bi. Improved Nguyen-Vidick Heuristic Sieve
Algorithm for Shortest Vector Problem. The 6th ACM Symposium on Information,
Computer and Communications Security Proceedings, pages 1-9, ACM, 2011.