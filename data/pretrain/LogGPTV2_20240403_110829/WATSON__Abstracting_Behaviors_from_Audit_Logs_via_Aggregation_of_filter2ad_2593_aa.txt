title:WATSON: Abstracting Behaviors from Audit Logs via Aggregation of
Contextual Semantics
author:Jun Zeng and
Zheng Leong Chua and
Yinfang Chen and
Kaihang Ji and
Zhenkai Liang and
Jian Mao
WATSON: Abstracting Behaviors from Audit Logs
via Aggregation of Contextual Semantics
Jun Zeng† Zheng Leong Chua‡+ Yinfang Chen† Kaihang Ji† Zhenkai Liang†
Jian Mao§∗
†School of Computing, National University of Singapore
‡Independent Researcher
§School of Cyber Science and Technology, Beihang University
{junzeng, yinfang, kaihang, liangzk}@comp.nus.edu.sg
PI:EMAIL PI:EMAIL
Abstract—Endpoint monitoring solutions are widely deployed
in today’s enterprise environments to support advanced attack
detection and investigation. These monitors continuously record
system-level activities as audit logs and provide deep visibility
into security incidents. Unfortunately, to recognize behaviors
of interest and detect potential threats, cyber analysts face a
semantic gap between low-level audit events and high-level system
behaviors. To bridge this gap, existing work largely matches
streams of audit logs against a knowledge base of rules that
describe behaviors. However, specifying such rules heavily relies
on expert knowledge. In this paper, we present WATSON, an
automated approach to abstracting behaviors by inferring and
aggregating the semantics of audit events. WATSON uncovers the
semantics of events through their usage context in audit logs. By
extracting behaviors as connected system operations, WATSON
then combines event semantics as the representation of behaviors.
To reduce analysis workload, WATSON further clusters semanti-
cally similar behaviors and distinguishes the representatives for
analyst investigation. In our evaluation against both benign and
malicious behaviors, WATSON exhibits high accuracy for behavior
abstraction. Moreover, WATSON can reduce analysis workload by
two orders of magnitude for attack investigation.
I.
INTRODUCTION
Security incidents in large enterprise systems have been
on the rise globally. We have been witnessing attacks with
increasing scale and sophistication. Capital One reported that
106 million customers’ credit card information was exposed
due to unauthorized database access [6]. A recent Twitter
attack has left dozens of high-proﬁle accounts displaying fraud
messages to tens of millions of followers [14]. To better
prevent and respond to such attacks, endpoint monitoring
solutions (e.g., Security Information and Event Management
(SIEM) tools [5]) are widely deployed for enterprise security.
These monitors continuously record system-level activities as
audit logs, capturing many aspects of system’s execution states.
When reacting to a security incident, cyber analysts per-
form a causality analysis on audit logs to discover the root
cause of the attack and the scope of its damages [45], [46].
∗Corresponding author.+Research done at National University of Singa-
pore.
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24549
www.ndss-symposium.org
However, the amount of audit logs generated by a normal
system is non-trivial. Even one desktop machine can easily
produce over one million audit events per day [27], [50],
let alone busy servers in cloud infrastructures. To overcome
this challenge, recent research solutions scale up causality
analysis by eliminating irrelevant system operations in audit
logs [21], [34], [40], [50], [55], [61], [75], [82]. An alternative
research direction aims to increase the efﬁciency of log query
systems [27], [28], [32], [70]. Unfortunately, neither data
reduction nor searching improvement leads to a substantial
decrease in analysis workload. These solutions do not capture
the semantics behind audit data and leave behavior recogniza-
tion to analysts [53]. As a result, intensive manual effort is
still involved in evaluating relevant yet benign and compli-
cated events that dominate audit logs. Especially, a signiﬁcant
problem faced by analysts is a semantic gap between low-level
audit events and high-level system behaviors.
Existing work strives to bridge this gap by matching
audit events against a knowledge store of expert-deﬁned rules
that describe behaviors, such as tag-based policies [38], [39],
query graphs [62], [84], and TTP (tactic,
technique, and
procedure) speciﬁcations [35], [63]. Essentially, these solutions
identify high-level behaviors through tag propagation or graph
matching. However, an expected bottleneck is the manual
involvement of domain experts to specify such rules. For
example, MORSE [39] needs experts to traverse system entities
(e.g., ﬁles) and initialize their conﬁdentiality and integrity tags
for tag propagation. TGMiner [84] requires manual behavior
labeling in training log sets before mining discriminative
behavioral patterns and searching for their existence in test
sets. Despite crucial role in audit log analysis, mapping events
to behaviors heavily relies on expert knowledge, which may
hinder its applications in practice.
Extracting representative behaviors from audit events for
analyst investigation provides an efﬁcient strategy to mitigate
this problem. More concretely, we can use procedural analy-
sis to automatically abstract high-level behaviors and cluster
semantically similar ones, albeit without the labels explaining
what they are. However, because repetitive/comparable behav-
iors have already been clustered, analysts only need to label the
representatives from clusters, resulting in far fewer events to
be investigated. Besides reducing manual workload in behavior
analysis, automatic behavior abstraction also enables proactive
analysis to detect unusual behavioral patterns in insider threats
or external exploits. Particularly, any deviation of normal
behaviors can be ﬂagged efﬁciently for attack response.
While behavior abstraction sounds promising, there are two
main challenges to extract behaviors and infer their semantics:
event semantics differentiation and behavior identiﬁcation.
Audit events record general-purpose system activities and thus
lack knowledge of high-level semantics. A single event, such
as process creation or ﬁle deletion, can represent different
semantics in different scenarios. Furthermore, due to the large-
scale and highly interleaving nature of audit events, partition-
ing events and identifying boundaries of behaviors are like
ﬁnding needles in a haystack.
To address the above challenges, our ﬁrst key insight is
that the semantics of audit events can be revealed from the
contexts in which they are used. Intuitively, we can represent
behaviors by aggregating the semantics of their constituent
events. With such representations, similar behaviors can be
clustered together. In addition, we observe that the information
ﬂow of system entities provides a natural boundary of high-
level behaviors. It can serve as guidance to correlate audit
events belonging to individual behaviors.
In this paper, we present WATSON 1, an automated behavior
abstraction approach that aggregates the semantics of audit
events to model behavioral patterns. It does not assume expert
knowledge of event semantics to perform behavior abstraction.
The semantics is obtained automatically from the context
this the contextual
of event usage in audit
semantics of events. More speciﬁcally, WATSON ﬁrst leverages
a translation-based embedding model to infer the semantics of
audit events based on contextual information in logs. Then,
WATSON identiﬁes events connected to related data objects
(i.e., ﬁles and network sockets) and aggregates their semantics
as the representation of high-level behaviors. Finally, WATSON
clusters similar behaviors recorded in audit logs and distin-
guishes the representatives for analyst investigation.
logs. We call
To the best of our knowledge, WATSON is the ﬁrst approach
that automatically abstracts high-level behaviors from low-
level log information. WATSON provides a quantitative repre-
sentation of the semantics for both events and behaviors found
in audit logs and a way to derive them automatically. Having a
quantitative method to reason about behaviors and events gives
analysts the ability to compare, sort, and cluster behaviors. It
also enables the composition of multiple behaviors and even
the synthesis or prediction of what a particular behavior should
be. These capabilities can form the basis for designing new
security solutions, such as abnormal behavior detection, or
supporting existing solutions to select appropriate behaviors
for deep inspection.
We prototype WATSON and evaluate its correctness and
explicability using 17 daily routines and eight real-life attacks
simulated in an enterprise environment. In addition, we use the
public DARPA TRACE dataset [13] released by the DARPA
Transparent Computing program to evaluate WATSON’s efﬁ-
cacy in attack investigation. We note that WATSON is the ﬁrst
to abstract both benign and malicious behaviors for evaluation.
Previous techniques [33], [35], [36], [39], [63] do not take
benign behaviors into consideration because they mainly focus
on attack detection. However, WATSON extracts high-level
behaviors regardless of their security concerns. Experimental
1Our approach name comes from Dr. Watson, who always provides trustful
assistance for the detector, Sherlock Holmes.
Fig. 1: The provenance graph for the motivation example.
Nodes in the graph are system entities (rectangles are pro-
cesses, ovals are ﬁles, and diamonds are sockets), and edges
among nodes represent system calls. For
readability, we
present only a fragment of the graph and highlight high-level
behaviors with colored boxes.
results show that WATSON accurately correlates system entities
with similar usage contexts and achieves an average F1 score
of 92.8% in behavior abstraction. Moreover, WATSON is able
to reduce the amount of audit logs for analyst investigation by
two orders of magnitude.
In summary, we make the following contributions:
• We present WATSON,
the ﬁrst approach to abstracting
high-level behaviors from low-level logs without analyst
involvement. Our approach summarizes behaviors using
information ﬂow as guidance and derives behavior semantics
by aggregating contextual semantics of audit events.
• We propose the novel
idea of inferring log semantics
through contextual information. We provide a quantitative
representation of behavior semantics and use it to cluster
semantically similar behaviors and extract representatives.
• We prototype WATSON and conduct a systematic evaluation
with both commonly-used benign behaviors and real-world
malicious behaviors. The results show that WATSON is
effective in abstracting high-level behaviors and reducing
human workload in the analysis of logs.
II. BACKGROUND AND MOTIVATION
In this section, we ﬁrst introduce audit log analysis and
its challenges with a motivating example. We then analyze the
problem of behavior abstraction with our insights, as well as
describing the threat model.
A. Motivating Example
Scenario. Consider the following attack scenario, where an
employee wants to exﬁltrate sensitive data that he can access.
As a software tester, his regular tasks include using git to
synchronize code from the Github repository, using gcc to
compile programs from source code, and using apt to install
tested software dependencies. One day, he locates a sensitive
document (secret.txt) and wants to exﬁltrate it. To evade
detection, he tries to mimic normal behaviors in his daily jobs.
2
bashlsvimgcccc1collect2asldPro1.ca.outa.outsudovimtarEva.docEva.tarbashgit addgit commitgit push13.250.X.XData ExﬁltrationProgram Compilation and UploadGithub Submissionaptsudoaptshdpkggpgvdpkgupdate-motd-updhttphttpapt-conﬁgdpkgrmﬁndapt-keyPackage InstallationPackage List Updatebashsshshrun-partssshdgcccc1git addgit commitgit pushssh13.250.X.Xcatlscpsecret.txtPro2.cbashHe ﬁrst copies the sensitive ﬁle to his working directory as
Pro2.c. Then, he compiles the “program” using gcc and
uploads it to a Github repository under his control. Note that
the compilation of the ﬁle is unsuccessful because Pro2.c is
not a legitimate source ﬁle. This strategy attempts to disguise
the Data Exﬁltration behavior as part of an ordinary program
development activity and thus misguide analysts to ﬂag it as
a daily behavior.
Audit log analysis. System audit logs enable analysts to gain
insight into cyber attacks with data provenance. Each audit
event records an OS-level operation (i.e., system call) such
as process execution, ﬁle creation, and network connection.
Speciﬁcally, an event can be deﬁned as a triple (Subject,
Relation, Object), where Subject is a process entity, Object
is a system entity (i.e., process, ﬁle, or network socket), and
Relation is a system call function. In our motivating exam-
ple, copying secret.txt events are represented as (cp,
read, secret.txt) and (cp, write, Pro2.c). Note
that system entities are associated with a set of attributes for
identiﬁcation, such as labels (e.g., PID and inode) and names
(e.g., ﬁle path, process path, and IP address). Moreover, every
individual event (e.g., a process writing a ﬁle) stands for an
information ﬂow between Subject and Object.
To facilitate attack causality analysis, the research commu-
nity employs a provenance graph [17], [65] to allow tracking
information ﬂows efﬁciently in audit logs. In essence, the
provenance graph is a common representation of historic
causalities in the system at the OS level. Figure 1 shows an
example of a provenance graph building upon the motivating
example. The direction of an edge indicates how data transfer
between system entities. In an investigation of a given security
incident, analysts search through a provenance graph for pieces
of information related to cyber-attacks. In Figure 1, analysts
ﬁrst perform backward tracking from an incident (i.e., ﬁle
upload to an unknown Git repository) to identify its root cause.
Then, analysts perform forward tracking on the found initial
compromise point (i.e., insider login with ssh) to explore the
ramiﬁcations of the same attack. When inspecting ancestries
and progenies of a security incident through backward and
forward tracking, analysts can reason about how the incident
is caused and the high-level behaviors responsible for it.
B. Challenges
While capturing attack sequences and provenances, ana-
lysts would have to recognize not only malicious (e.g., Data
Exﬁltration) but benign behaviors (e.g., Program Compila-
tion and Upload). Although a provenance graph provides an
intuitive representation to visualize causal dependencies and
remove irrelevant events, analysts still spend excessive time in
investigating relevant but benign events due to the ubiquitous
presence of normal activities on a daily basis.
Abstracting behaviors from audit events is an efﬁcient
strategy for analysts to navigate through a large number of
events and focus on speciﬁc information. Essentially, behaviors
represent an abstraction of audit data. Working on the level of
behaviors can effectively reduce the analysis workload from
the whole event space to behaviors of interests that draw
attention in a speciﬁc scenario. Examples of such behaviors
include Data Exﬁltration, Backdoor Installation, and Program
Fig. 2: Subgraphs starting from Pro1.c, Eva.doc and
secret.txt correspond to the Program Compilation and
Upload, Github Submission and Data Exﬁltration behaviors.
We color-code the source data object in behaviors and omit
some edges (e.g., vim writes Pro1.c) for clarity.
Compilation. However,
to automatically abstract high-level
behaviors from low-level audit events, analysts face two major
challenges:
• Inferring semantics of OS-level audit
events. Audit
events record detailed system execution states but
lack
knowledge of high-level semantics critical for behavioral
pattern recognition. Speciﬁcally, two system entities with
similar semantics may be named differently. For example,
temporary ﬁles for IPC between C compiler (cc1) and
assembler (as) can be named /tmp/ccw4T8Hh.s and
/tmp/cc0JjLYr.s. On the other hand, system entities
sharing the same names could indicate different intentions.
In our motivating example, the Data Exﬁltration behavior
leverages cc1 to mimic normal user activities, while the
Program Compilation and Upload behavior uses cc1 to
compile the source code into assembly code. In order to
uncover event semantics, existing work largely parses audit
events with a knowledge store of expert-deﬁned rules or
models. However, the manual speciﬁcations could easily
undermine the scalability of behavior abstraction due to the
large scale of audit events, even in modestly sized systems.
• Identifying behavior boundaries in large-scale audit events.
The volume of audit data is typically overwhelming, and
audit events are highly interleaving. In our motivating ex-
ample, even a single Package Installation behavior with apt
generates over 50,000 events. In addition, all individual
behaviors are causally connected, as shown in Figure 1.
This makes it challenging for analysts to partition events
and distinguish behavior boundaries. More notably, most of
the events do not necessarily reﬂect behaviors but system
routines. When compiling programs with gcc, the child
process, cc1, reads a massive number of ﬁles such as C
header ﬁles, but only operations accessing Pro2.c are
particularly correlated with the Data Exﬁltration behavior.
C. Problem Analysis
Given a large set of audit logs in a user login session, we
aim to identify high-level (benign and malicious) behaviors and
provide a quantitative representation of their semantics without
analyst involvement. Furthermore, we also aim to cluster se-
mantically similar behaviors and distinguish the representatives