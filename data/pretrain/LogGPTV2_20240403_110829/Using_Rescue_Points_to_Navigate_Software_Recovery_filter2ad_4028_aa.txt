title:Using Rescue Points to Navigate Software Recovery
author:Stelios Sidiroglou and
Oren Laadan and
Angelos D. Keromytis and
Jason Nieh
Using Rescue Points to Navigate Software Recovery (Short Paper)
Stelios Sidiroglou, Oren Laadan, Angelos D. Keromytis, and Jason Nieh
Department of Computer Science, Columbia University
{stelios, orenl, angelos, nieh}@cs.columbia.edu
Abstract
We present a new technique that enables software recov-
ery in legacy applications by retroﬁtting exception-handling
capabilities, error virtualization using rescue points. We in-
troduce the idea of “rescue points” as program locations to
which an application can recover its execution in the pres-
ence of failures. The use of rescue points reduces the chance
of unanticipated execution paths thereby making recovery
more robust by mimicking system behavior under controlled
error conditions. These controlled error conditions can be
thought of as a set erroneous inputs, like the ones used by
most quality-assurance teams during software development,
designed to stress-test an application. To discover rescue
points applications are proﬁled and monitored during tests
that bombard the program with bad/random inputs. The
intuition is that by monitoring application behavior dur-
ing these runs, we gain insight into how programmer-tested
program points are used to propagate faults gracefully.
1 Introduction
In the absence of perfect software, error toleration and
recovery techniques become a necessary complement to
proactive approaches. The pressing need for techniques that
address the issue of recovering execution in the presence of
faults is reﬂected by recent emergence of a few novel re-
search ideas [17, 20]. For example, error virtualization op-
erates under the assumption that there exists a mapping be-
tween the set of errors that could occur during a program’s
execution (e.g., a caught buﬀer overﬂow attack, or an illegal
memory reference exception) and the limited set of errors
that are explicitly handled by the program’s code. Thus, a
failure that would cause the program to crash is translated
into a return with an error code from the function in which
the fault occurred (or from one of its ancestors in the stack).
These techniques, despite their novelty in dealing with this
pressing issue, have met much controversy, primarily due to
the lack of guarantees, in terms of altering program seman-
tics, that can be provided. Masking the occurrence of faults
will always carry this stigma since it forces programs down
unexpected execution paths. However, we believe that the
basic premise of masking failures to permit continued pro-
gram execution is promising, and our goal is to minimize
the likelihood of undesirable side-eﬀects.
We outline a new technique for retroﬁtting legacy ap-
plications with exception-handling capabilities. Our ap-
proach consists of a general software fault-recovery mech-
anism that uses operating system virtualization techniques
to provide “rescue points” to which an application can re-
cover execution in the presence of faults [13]. When a fault
occurs at an arbitrary location in the program, we restore
program execution to a “rescue point” and imitate its ob-
served behavior to propagate errors and recover execution.
The use of rescue points reduces the chance of unanticipated
execution paths, thereby making recovery more robust, by
mimicking system behavior under controlled error condi-
tions. These controlled error conditions can be thought of
as a set of erroneous inputs, like the ones used by most qual-
ity assurance teams during software development, designed
to stress test an application. To discover “rescue points”, ap-
plications are proﬁled and monitored during tests that bom-
bard the program with “bad input”. The intuition is that by
monitoring application behavior during these runs, we gain
insight into how programmer-tested program points propa-
gate faults gracefully.
The key diﬀerence between this work and previous tech-
niques that try to be oblivious to occurrence of faults
[17, 19, 20] is the type of impact on program semantics.
Rescue points do not try to mask errors in a demonstration
of blind faith. In fact, rescue points force the exact opposite
behavior: they induce faults at locations that are known (or
strongly suspected) to handle faults correctly. We achieve
this through an oﬄine analysis phase, in which we proﬁle
programs during erroneous test runs in order to build a be-
havioral model for the application. Using this model, we
discover candidate rescue points. We then use a set of soft-
ware probes that monitor the application for speciﬁc types
of faults. Upon detection of a fault, an operating system re-
covery mechanism is invoked that allows the application to
rollback application state to a rescue point and replay ex-
ecution pretending that an error has occurred. Using con-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:54:28 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007tinuous hypothesis testing, we conﬁrm that our action has
repaired the fault by re-running the application against the
event sequence that apparently caused the failure. We fo-
cus on automatic healing of services against newly detected
faults, including (but not limited to) software attacks.
This work focuses on server-type applications for two
reasons:
they typically have higher availability require-
ments than user-oriented applications, and they tend to have
short error-propagation distances [17], i.e., an error that
might occur during the processing of a request has little or
no impact on the service of future requests. To provide an
analogy, if one considers an organization like NASA, his-
tory has shown that it would not make sense to use a mech-
anism like error virtualization on a software system that cal-
culates space-travel trajectories since the correctness of the
results cannot be guaranteed. However, the software on the
Mars Rover would beneﬁt greatly from a technique that al-
lows for continued execution in the presence of faults [18].
Our plans for future work include investigating the applica-
bility of this technique to client applications.
2 Related Work
The acceptability envelope, a region of imperfect but ac-
ceptable software systems that surround a perfect system,
as introduced by Rinard [15] promotes the idea that current
software development eﬀorts might be misdirected, based
on the observation that certain regions of a program can be
neglected without adversely aﬀecting the overall availabil-
ity of the system. To support these claims, a number of case
studies are presented where introducing faults such as an
oﬀ-by-one error does not produce unacceptable behavior.
This work supports our claim that most complex systems
contain the necessary framework to propagate faults grace-
fully and the error toleration allowed by our system expands
the acceptability envelope of a given application.
In the same motif, Rinard et al.
[16, 17] developed
failure-oblivious computing, an instantiation of which is a
compiler that inserts code to deal with writes to unallocated
memory by virtually expanding the target buﬀer. Such a
capability aims toward the same goal our system does: pro-
vide a more robust fault response rather than simply crash-
ing. Because the program code is extensively re-written to
include the necessary checks for every memory access, their
system incurs overheads ranging from 80% up to 500% for
a variety of diﬀerent applications. Similar to our previous
work [19, 20], there is only limited empirical examination
of the side eﬀects on the program execution. Finally, this
technique is only applicable to memory errors, whereas our
technique can be applied to a variety of faults.
One of the most critical concerns with recovering from
software faults and vulnerability exploits is ensuring the
consistency and correctness of program data and state.
An important contribution in this area is Automatic Data-
structure Repair [8], which discusses mechanisms for de-
tecting corrupted data structures and ﬁxing them to match
some pre-speciﬁed constraints. While the precision of the
ﬁxes with respect to the semantics of the program is not
guaranteed, their test cases continued to operate when faults
were randomly injected. Similar results are shown in Y-
Branches [21]: when program execution is forced to take
the “wrong” path at a branch instruction, program behavior
remains the same in over half the times.
In the Rx system [14] applications are periodically
checkpointed and continuously monitored for faults. When
an error occurs, the process state is rolled back and replayed
in a new “environment”. If the changes in the environment
do not cause the bug to manifest, the program will have
survived that speciﬁc software failure. However, previous
work [6, 7] found that over 86% of application faults are in-
dependent of the operating environment and entirely deter-
ministic and repeatable, and that recovery is likely to be suc-
cessful only through application-speciﬁc (or application-
aware) techniques. Thus, it seems likely that Rx is only
applicable in a small number of cases.
3 Approach
From a bird’s eye view, our system provides a general
mechanism that applications can use to recover execution
in the presence of faults. Our approach can be summarized
by the following set of oﬀ-line and on-line actions. Oﬀ-
line, applications are proﬁled during “bad runs” in order to
build an application behavioral model. These bad runs are
generated by regression tests, if available, or through input
fuzzing techniques [3, 10], that stress the error handling ca-
pabilities of applications. The intuition is that there exists
a set of programmer-tested application points that are rou-
tinely used to propagate “expected” errors. In turn, these
application points can be harnessed to recover from failures
and thus maintain system availability. Using this model, we
isolate program locations that can be used as candidate res-
cue points. On-line, our architecture allows for the use of a
variety of fault monitors. Upon detection of a fault, appli-
cation state is rolled back to a predetermined program loca-
tion, a rescue point, where the program is forced to return an
error, imitating the behavior observed during the erroneous
runs.
The diﬀerent components are illustrated in Figure 1: A
set of sensors that continuously monitor the application for
faults and takes control whenever one is detected; an Error
Virtualization component that is responsible for determin-
ing values to inject in case of a fault; a rescue-point dis-
covery component used to identify candidate rescue points
through static and analysis; a recovery enabler that employs
a checkpoint-restart mechanism to capture the state of the
application and rollback back to a saved state; a patch gen-
erator that produces rescue-point-enabled patches for vul-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:54:28 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007Figure 1. System overview: (1) Sensors monitor the
application for faults (2) when a fault is detected, the
function where it manifested is protected using one of
fault detection techniques (3) a rescue point is deter-
mined and inserted into the application (4) a patch con-
taining the protection and rescue point is inserted into
the application (5) the generated patch is tested with the
input that caused fault and general application behav-
ior is monitored (6) the production version of the server
is updated with the patch (7) application is now able to
detect and recover from the fault using error virtualiza-
tion.
Figure 2. Error virtualization (EV) using rescue
points:
(1) Application checkpoints state at “rescue
points” (2) fault detection component monitors pro-
tected function for faults (3) when a fault occurs in a
protected function, the EV component is invoked (4) the
EV component decides on a recovery strategy and (5)
restores application state to the rescue point (6) once
application state is restored, the rescue point forces an
error return using the value determined by the EV com-
ponent.
nerable applications; a testing environment in which the
proposed patches are evaluated subsequently evaluated; and
a patch insertion tool that facilitates the insertion of ap-
proved patches into running binaries.
All of the components are designed to operate without
human intervention in order to minimize reaction time. In
the remaining of this section we elaborate on each of these
components.
3.1 Rescue-point Discovery
Determining an acceptable recovery point is of pivotal
importance to error virtualization. It determines, to a large
extent, the likelihood that the application will survive a
fault. Two mechanisms are used for the discovery of rescue
points: one static and one dynamic with more prevalence
given to the latter.
Dynamic Analysis: Dynamic analysis is the preferred
mechanism for discovering suitable rescue points because
it grants unambiguous insight into application behavior. In
particular, our goal is to learn how an application responds
to “bad input”, under controlled conditions, and use this
knowledge to map previously unseen faults to a set of ob-
served fault behavior. The intuition is that there exists a
set of programmer-tested application points that are rou-
tinely used to propagate “expected” errors. For example,
we would like to see how a program normally propagates
faults when stress-tested by quality assurance tests. Learn-
ing from “bad behavior” has been used in machine learning
and subsequently intrusion detection systems but to the best
of our knowledge has not being used to recover from soft-
ware faults.
Speciﬁcally, we instrument applications by inserting
monitoring code at every function’s entry and exit points us-
ing the run-time injection capabilities of dyninst [2], a run-
time binary injection tool. The instrumentation records both
function parameters and return types and values while the
application is bombarded with faults. From these traces, we
extract function call-graphs along with the return type in-
formation for each point in the graph. We call these graphs
the rescue graphs. The rescue-graphs are used as program
slices at function-level granularity that can, in turn, be used
to isolate the control-ﬂow of a fault and deﬁne possible res-
cue points.
Static Analysis: Static analysis is used to augment the
ﬁndings of the dynamic analysis techniques described
above. Speciﬁcally, we use static analysis in order to fa-
cilitate with error virtualization and rescue point discovery.
For error virtualization, static analysis can help determine
appropriate error return values through code inspection and
backward program slicing. In detail, we explore the back-
ward path originating at the manifestation of a fault to de-
termine where the vulnerable function resides on the call
tree. At that point, we examine how the return value of the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:54:28 UTC from IEEE Xplore.  Restrictions apply. 
ExecutingApplicationExecutingApplicationExecutingApplicationonlineofﬂineRescue Point DiscoveryPatch InsertionBad InputError VirtualizationPatch GeneratorTestingEnvironment(1) Sensors(2) FAULTPatchSafeUnsafeUnsafe(3) Rescue pointsInput(4) Generate patch(5) test patch(6) Update application(7) Recover execution(4) Error Virtualization (3)Fault Detected(5) Restore(2) Checkpoint(6) Force returnReturn errorNo errorInput(1) Malicious Inputfoo()bar()bad()2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007function gets used in the function handling code. This pro-
vides insight into what kind of values we can use during
error virtualization. For example, when a function’s return
values are used in control statements followed by exit state-
ments this provides fertile ground for using this value as an
appropriate return value during error virtualization. Dur-
ing this process we also pay close attention to the oﬀending
program slice for any problematic error virtualization cases,
including I/O that is performed along with the use of global
variable and the existence of signal-handling code.
3.2 Error Virtualization Using Rescue Points
Here, we describe the basic concept of error virtualiza-
tion using rescue points and examine the basic building
blocks of the system. As illustrated in Figure 2, error virtu-
alization can be summarized by the following steps: check-
point application state at rescue point; monitor application
for fault; when a fault occurs, undo state changes made
by the function, all the way back to the rescue point; af-
ter restoring execution to a rescue point, force error return
using observed value
Error Virtualization When a fault is detected, using one
of the available fault detection techniques, the call-stack is
examined to derive the sequence of functions that led to
the fault. At that point, we compare the call-stack with
the rescue-graph to derive common nodes. The common
nodes form a set of candidate rescue points. Candidate res-
cue points are then ﬁltered according to their return type.
For this particular implementation, candidate rescue points
are functions with non-pointer return types or function that
return pointers but the observed return value is NULL. Func-