is unwrapped and a send operation is scheduled according to
the next hop identiﬁer and delay from the metadata.
Algorithm 5 Processing of an incoming packet at mix node
n with secret key xn.
1: procedure PROCESS(packet)
2:
(M, δ) ← packet
s ← (M.α)xn
if hτ(s) ∈ tags then abort
tags ← tags ∪ {hτ(s)}
δ′ ← AEdec(s, δ, M.γ, M.β)
if δ′ =⊥ then abort
(n′, delay), M′ = PROCESSHEADER(M)
QUEUEFORSEND(n′, (M′, δ′), delay)
3:
4:
5:
6:
7:
8:
9:
A.2 MultiSphinx (our solution)
We now describe our MultiSphinx construction and highlight
the changes relative to the normal Sphinx construction in blue.
To allow for a readable description we describe everything
for p = 2 however the general case follows easily.
We use the pseudo-random function (PRF) ρ together with
its key-generating function hρ from the original Sphinx paper
to create a deterministic pseudo-random padding. Since we
need two derive to independent keys from the same secret,
3448    30th USENIX Security Symposium
USENIX Association
we extend hρ with another parameter that can be an arbitrary
string. This extension can be implemented using any suitable
HKDF function.
Algorithm 6 explains the creation of MultiSphinx mes-
sages by the sender. The part concerning the “two legs” of
the message graph is only shown once for A to allow for a
more readable presentation. Line 21 instructs which lines are
meant to be repeated for the other p − 1 recipients. In line 4
the secret s1 is computed which is required for the padding
construction in line 11. Lines 6-9 encrypt the actual payload
from the recipient nA to the multiplication node n1,A (going
backwards). The encrypted payloads δ3,A, δ2,A, δ1,A are all
smaller than the normal payload length of messages. This
would allow an attacker to distinguish such messages from
other Loopix messages (e.g. when the middle mix layer sends
loop messages). Therefore, the ciphertext is padded in line 11
with our PRF ρ. To correctly compute the MACs and headers
in lines 15-20, we ﬁrst simulate (going forwards) how the
payloads will be affected by the decryption (line 12f).
Algorithm 7 explains the processing step at a mix node.
Regular mix nodes operate as before (line 10). However, at
multiplication nodes incoming message payloads are split
into p headers and p payloads (line 12). In lines 13-16 the
pseudo-random paddings are added. This process is also visu-
alised in Figure 11. The newly created packets are processed
recursively and then scheduled for sending based on their
individual delay (line 15f). This “self-delivery” corresponds
to the loop edge of n1 in Figure 10. The extra hop allows for
delaying both messages independently at the multiplication
node (two headers allow for two delays). It also simpliﬁes our
correctness arguments.
|M|
M1
s1
MAXMSGLEN
δ1
AEdec
⊥(ABORT)
δcombined =
M1,A
δ1,A
M1,B
δ1,B
M1,A
M1,A
δ1,A
δ1,A
ρA = ρ(hρ(A, s1))
ρA = ρ(hρ(A, s1))
M1,B
δ1,B
ρB = ρ(hρ(B, s)1))
Figure 11: Processing of a MultiSphinx message at the multi-
plication node n1 resulting in two outgoing messages that are
send then re-queued for processing.
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
Algorithm 6 Creating a MultiSphinx packet to be routed
through hops n0, n1, n2,A, n2,B to nodes nA, nB.
1: procedure CREATE(δA, δB, n0, n1, n2,A, n2,B, nA, nB)
2:
assert|δA| = |δB|= (MAXMSGLEN − HDRLEN)/2
⊲ Secrets for hops from sender to multiplier node n1
s0, s1, ← COMPUTESECRETS(n0, n1)
⊲ Encrypt from recipient nA to multiplier node n1
s1,A, s2,A, sA ← COMPUTESECRETS(n1,A, n2,A, nA)
δ3,A ← C(KDF(sA, cipher)) ⊕ δA
δ2,A ← C(KDF(s2,A, cipher)) ⊕ δ3,A
δ1,A ← C(KDF(s1,A, cipher)) ⊕ δ2,A
⊲ Add pseudo-random padding and compute padded
payloads δ′
... along decryption path
δ′
1,A ← δ1,A k ρ(hρ(A, s1))
2,A ← Cdec(KDF(s1,A, cipher)) ⊕ δ′
δ′
δ′
3,A ← Cdec(KDF(s2,A, cipher)) ⊕ δ′
1,A
2,A
⊲ Compute headers and full MACs
3,A k M3.A).β)
M3,A ← CREATEHEADER(sA, ∗)
M3,A.γ ← MAC(KDF(sA, mac), δ′
M2,A ← CREATEHEADER(sA, n3,A, M3,A)
M2,A.γ ← MAC(KDF(s2,A, mac), δ′
M1,A ← CREATEHEADER(sA, n2,A, M2,A)
M1,A.γ ← MAC(KDF(s1,A, mac), δ′
Repeat lines 6 − 20 for B
2,A k M2.A).β)
1,A k M1.A).β)
⊲ From sender to multiplication node
δcombined = M1,A k δ1,A k M1,B k δ1,B
M1 ← CREATEHEADER(s1)
δ1, M1.γ ← AEenc(s1, δcombined, M1.METADATA))
M0 ← CREATEHEADER(s0, n1, M1)
δ0, M0.γ ← AEenc(s0, δ, M0.METADATA))
return (M0, δ0)
Algorithm 7 Processing of an incoming packet at mix node
n at mix layer l with secret key xn.
1: procedure PROCESS(packet)
2:
(M, δ) ← packet
s ← (M.α)xn
if hτ(s) ∈ tags then abort
tags ← tags ∪ {hτ(s)}
δ′ ← AEdec(s, δ, M.γ, M.β)
if δ′ =⊥ then abort
n′, delay, M′ = PROCESSHEADER(M)
if l 6= 1 then
QUEUEFORSEND(n′, (M′, δ′), delay)
else
⊲ δ′ = δcombined
M1,A, δ1,A, M1,B, δ1,B ← δ′
ρA, ρB ← ρ(hρ(A, s)), ρ(hρ(B, s))
⊲ s = s1
⊲ Process separately to allow independent delays
PROCESS(M1,A k δ1,A k ρA)
PROCESS(M1,B k δ1,B k ρB)
USENIX Association
30th USENIX Security Symposium    3449
B Algorithms
Algorithm 8 The fault-tolerant Rollercoaster callback handler
and send methods (signatures are checked implicitly).
1: procedure SENDTOGROUP(groupid, payload)
2:
S ← GENSCHEDULE(msg.source, msg.groupid)
for recipient ∈ {direct children of self in S} do
msg ← NEWMESSAGE()
msg.groupid ← groupid
msg.nonce ← FRESHNONCE()
msg.{source, sender, role} ← self
msg.payload ← payload
SCHEDULEFORSEND(recipient, msg)
Algorithm 9 Methods explaining how the timeout informa-
tion is stored and updated.
1: procedure ONINIT
2:
self.sessions = [·]
⊲ missing keys default to {}
3:
4: procedure ADDTIMEOUT(msg, role, recipient, timeout)
5:
CANCELTIMEOUT(msg, role, recipient)
id ← (msg.groupid, msg.nonce)
entry ← (role, recipient,timeout)
self.sessions[id] ← self.sessions[id] ∪ {entry}
6:
7:
8:
9:
10: procedure CANCELTIMEOUT(msg, role, recipient)
11:
id ← (msg.groupid, msg.nonce)
session = self.sessions[id]
self.sessions[id] ← {x ∈ self.sessions[id] | x.role 6=
12:
13:
role ∧ x.recipient 6= recipient}
Algorithm 10 Determines whether node node is a forwarding
node with regards to schedule S.
1: procedure ISFORWARDINGNODE(S, node)
2:
source ← S[0][0][0]
if node = source then
return false
for t = 1 until |S| do
R ← S[t]
for (sender, _) in R do
if node 6= source and node = sender then
return true
3:
4:
5:
6:
7:
8:
9:
10:
return false
C Extended Paper
The extended paper is available at: https://www.cl.
cam.ac.uk/techreports/UCAM-CL-TR-957.html. Its ad-
ditional appendices contain: a proof for eventual delivery of
Rollercoaster, a security proof for MultiSphinx, visualisations
of the ofﬂine models, histogram plots of latency distributions,
and additional heatmap ﬁgures. The main text of the extended
paper only differs from this paper where it references these
additional pieces of information.
3:
4:
5:
6:
7:
8:
9:
13:
14:
15:
16:
17:
18:
19:
20:
21:
25:
26:
30:
31:
32:
36:
37:
38:
39:
40:
41:
42:
43:
44:
10:
11: procedure ONPAYLOAD(msg)
12:
APPLICATIONHANDLE(msg.payload)
if msg was received while ofﬂine then return
if msg was not seen before then
S ← GENSCHEDULE(msg.source, msg.groupid)
for x ∈ {direct children of msg.role in S} do
msg′ ← COPYMESSAGE(msg)
msg′.sender ← self
msg′.role ← x
SCHEDULEFORSEND(x, msg′)
SCHEDULEFORSEND(msg.source, GENACK(msg))
22:
23: procedure ONACK(msg)
24:
assert (msg.source = self)
CANCELTIMEOUT(msg, msg.role, msg.sender)
⊲ Called when a message leaves the payload queue
27:
28: procedure ONMESSAGEISSENT(msg)
29:
S ← GENSCHEDULE(msg.source, msg.groupid)
for x ∈ {recursive children of msg.role in S} do
timeout ← ESTIMATETIMEOUT(S, x)
ADDTIMEOUT(msg, x,timeout)
33:
34: procedure ONTIMEOUT(msg, recipient f ailed)
35:
S ← GENSCHEDULE(msg.source, msg.groupid)
if not ISFORWARDINGNODE(S, msg.role) then
return
for x ∈ {recursive children of msg.role in S} do
CANCELTIMEOUT(msg, msg.role, msg.sender)
⊲ timeout will be recreated when re-try is sent
recipient′ ← NEXTRECIPIENT(S, recipient f ailed)
SCHEDULEFORSEND(recipient′, msg)
msg.role ← ∅
⊲ Re-try to failed node w/o role
SCHEDULEWITHEXPBACKOFF(recipient f ailed, msg)
3450    30th USENIX Security Symposium
USENIX Association