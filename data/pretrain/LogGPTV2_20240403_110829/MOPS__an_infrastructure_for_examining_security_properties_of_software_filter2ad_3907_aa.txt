title:MOPS: an infrastructure for examining security properties of software
author:Hao Chen and
David A. Wagner
MOPS∗: an Infrastructure for Examining Security Properties
of Software†
Hao Chen
University of California at Berkeley
PI:EMAIL
David Wagner
University of California at Berkeley
PI:EMAIL
ABSTRACT
We describe a formal approach for ﬁnding bugs in security-
relevant software and verifying their absence. The idea is as
follows: we identify rules of safe programming practice, en-
code them as safety properties, and verify whether these
properties are obeyed. Because manual veriﬁcation is too
expensive, we have built a program analysis tool to auto-
mate this process. Our program analysis models the pro-
gram to be veriﬁed as a pushdown automaton, represents
the security property as a ﬁnite state automaton, and uses
model checking techniques to identify whether any state vi-
olating the desired security goal is reachable in the program.
The major advantages of this approach are that it is sound
in verifying the absence of certain classes of vulnerabilities,
that it is fully interprocedural, and that it is eﬃcient and
scalable. Experience suggests that this approach will be use-
ful in ﬁnding a wide range of security vulnerabilities in large
programs eﬃciently.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—
veriﬁcation; D.2.4 [Software Engineering]: Software/ Pro-
gram Veriﬁcation—formal methods, model checking
General Terms
Security, Languages, Veriﬁcation
Keywords
security, model checking, veriﬁcation, static analysis
INTRODUCTION
1.
∗MOPS: MOdel Checking Programs for Security properties
†This research was supported in part by DARPA contract
N66001-01-C-8040 and by an equipment grant from Intel.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’02, November 18–22, 2002, Washington, DC, USA.
Copyright 2002 ACM 1-58113-612-9/02/0011 ...$5.00.
Software vulnerabilities are an enormous cause of security
incidents in computer systems. A system is only as secure as
its weakest link, and often the software is the weakest link.
We can attribute software vulnerabilities to several causes.
Some bugs, like buﬀer overruns in C, reﬂect poorly designed
language features and can be avoided by switching to a safer
language, like Java. However, safer programming languages
alone cannot prevent many other security bugs, especially
those involving higher level semantics. As a typical example,
OS system calls have implicit constraints on how they should
be called; if coding errors cause a program to violate such
constraints when interacting with the OS kernel, this may
introduce vulnerabilities.
In this paper, we focus on detecting violations of order-
ing constraints, also known as temporal safety properties. A
temporal safety property dictates the order of a sequence
of security-relevant operations. Our experience shows that
many rules of good programming practice for security pro-
grams can be described by temporal safety properties. Al-
though violating such properties may merely indicate risky
features in a program in some cases, it often renders the
program vulnerable to attack, depending on the nature of
the violation. In either case, the ability to detect violations
of the properties or to verify the satisfaction of them would
be a signiﬁcant help in reducing the frequency of software
vulnerabilities.
To illustrate the relevance of such temporal safety prop-
erties, we give next a few examples that reﬂect prudent pro-
gramming practice for Unix applications.
• Property 1. Suppose a process uses the chroot system
call to conﬁne its access to a sub ﬁlesystem. In this
case, the process should immediately call chdir(“/”)
to change its working directory to the root of the sub
ﬁlesystem.
This rule can be described by the temporal safety prop-
erty that any call to chroot should be immediately fol-
lowed by a call to chdir(“/”). The program in Fig-
ure 1(b) violates this property: it fails to call chdir(“/”)
after chroot(“/var/ftp/pub”), so its current directory
remains /var/ftp. As a result, a malicious user may
ask the program to open the ﬁle ../../etc/passwd
successfully even though this is outside the chroot jail
and the programmer probably intended to make it in-
accessible. Here, the malicious user takes advantage
of the method by which the operating system enforces
chroot(new root). When a process requests access to a
ﬁle, the operating system follows every directory com-
ponent in the path of the ﬁle sequentially to locate the
(a) An FSA describing the Property 1
// Here the current directory is “/var/ftp”
chroot(“/var/ftp/pub”);
ﬁlename = read from network();
fd = open(ﬁlename, O RDONLY);
(b) A program segment violating Property 1. Note that
the program fails to call chdir(“/”) after chroot(), so
if filename is “../../etc/passwd”, a security violation
ensues.
Figure 1: An FSA illustrating Property 1 (chroot()
must always be immediately followed by chdir())
and a program violating it
ﬁle. If the operating system has followed into the di-
rectory new root and if the next directory name in
the path is “..”, then “..” is ignored. However,
in the above example, since the current directory is
/var/ftp, the path ../../etc/passwd never comes
across the new root /var/ftp/pub and is therefore fol-
lowed successfully by the operating system. In short,
the chroot system call has subtle traps for the unwary,
and Property 1 encodes a safe style of programming
that avoids some of these traps.
• Property 2. A call to stat(f ) should not be followed
immediately by a call to open(f ) (otherwise, it is a
suspicious code sequence that tends to indicate poten-
tial security weaknesses [5]).
Before explaining this property, we give some back-
ground. In Unix systems, each process has an eﬀective
user ID (euid ), which determines the ﬁle access per-
mission of the process.
If the euid of the process is
zero, the user ID of the super-user root, the process
has full access to the ﬁlesystem and is said to be privi-
leged. Consider a privileged process that runs on behalf
of a normal user and that wants to constrain itself to
access only ﬁles owned by the normal user. A naive
implementation involves two steps: (1) call stat(“foo”)
to identify the owner of the ﬁle foo; (2) only open the
ﬁle if it is owned by the current user. This strategy,
however, is insecure because of a race condition: an
attacker may change the ﬁle associated with the name
foo (e.g., through modifying a symbolic link) between
the stat(“foo”) and open(“foo”) calls. The program
in Figure 2(b) illustrates this race condition. Suppose
the ﬁlename foo in the variable logfile initially is a
symbolic link to a ﬁle owned by the attacker. When
stat(logﬁle, &st) is called, the program veriﬁes that the
attacker is the owner of the ﬁle. But before the pro-
gram proceeds to open the ﬁle by calling open(logﬁle,
O RDWR), the attacker changes foo to be a symbolic
link to /etc/passwd, a ﬁle that should not be writable
(a) An FSA describing Property 2
// Here ruid=x (a normal user), euid=0 (root)
stat(logﬁle, &st);
if (st.st uid != getuid())
return -1;
open(logﬁle, O RDWR);
(b) A program segment violating Property 2. Note that
the program is susceptible to a race condition, since the
binding of logfile to a ﬁle may change between the
stat() and open() calls.
Figure 2: An FSA illustrating Property 2 (stat(f )
must not be followed by open(f )) and a program
violating it.
to him. So open(logﬁle, O RDWR) ends up opening
/etc/passwd for him in read/write mode. We see that
violations of Property 2 often point to potential secu-
rity vulnerabilities in the code.
• Property 3. Since a privileged process has full access
permission to the system, it should not make certain
system calls that run untrusted programs without ﬁrst
dropping all privileges (thereby granting them with full
access permission to the system).
One such system call is execl. For example, the pro-
gram in Figure 3(b) calls execl(“/bin/sh”, “sh”, NULL)
in the privileged state, giving the untrusted user a shell
with full ﬁlesystem access permission. It violates the
property that a privileged process should drop privi-
lege (by calling seteuid(u) with some user ID u6=0, for
example1) before calling execl.
In summary, the Unix system call interface comes with var-
ious pitfalls and implicit requirements on how this interface
should be invoked. The temporal safety properties listed
above encode some of these requirements in an explicit form.
To reduce the risk of security vulnerabilities we would like
to verify that these security properties are all satisﬁed.
Although checking temporal safety properties by hand is
feasible in small programs, it does not scale to large pro-
grams because the sequence of operations in a property may
span multiple functions or ﬁles in a program. Moreover, we
would like to be conﬁdent that the property is satisﬁed on
all execution paths in the program, yet manually checking
all paths is infeasible in most cases. This point is illustrated
in the program in Figure 4 where the path [d0d2d3d4] in the
1For additional security, a privileged process should call se-
tuid(u) or setresuid(u,u,u) to drop all the privileges in its
ruid, euid, and suid. We simplify the property by consider-
ing only the euid and the seteuid system call.
chroototherchdirotheropen(f)stat(f)otherotherint main(int argc, char *argv[])
{
// start with root privilege
do something with privilege();
drop privilege();
execl(“/bin/sh”, “/bin/sh”, NULL); // risky syscall
m0:
m1:
m2:
m3: }
void drop privilege()
{
struct passwd *passwd;
d0:
d1:
d2:
d3:
d4: }
if ((passwd = getpwuid(getuid())) == NULL)
return; // but forget to drop privilege!
fprintf(log, “drop priv for %s”, passwd->pw name);
seteuid(getuid()); // drop privilege
Figure 4: A program where the security property is
violated on one execution path but not on the other
one.
of existing algorithms and future advances from the model
checking community. Second, because it fully supports in-
terprocedural analysis and because interprocedural bugs are
more elusive than intraprocedural ones, MOPS promises to
complement manual auditing where an automated tool is
needed the most. Third, MOPS is sound (modulo the mild
assumptions to be discussed in Section 6): it reliably catches
all bugs of the speciﬁed types. This property makes MOPS
useful not only in ﬁnding security bugs but also in verify-
ing security properties. Fourth, thanks to a novel technique
that substantially reduces the size of a program without af-
fecting the result of model checking [7], MOPS scales well to
large programs in both time and space, overcoming the scal-
ability problem that hinders many software model checking
systems. Other tools have some of these properties, but to
the best of our knowledge MOPS is the only tool that has
all of these desirable properties.
This paper is organized as follows. Section 2 and 3 de-
scribe the formal models that are the foundations of this
approach. The former presents an abstract view of the mod-
els and the latter describes their implementation. Section 4
discusses how to derive a security model from the operat-
ing system accurately. Section 5 presents our experiences in
using MOPS to examine several security-relevant software.
Section 6 discusses the soundness of this approach and its
limitations. Section 7 reviews the related work and com-
pares them to MOPS.
2. FORMAL MODELS
MOPS is based on a formal approach that builds a formal
model of a program and of a security property and then
analyzes the models. We start by describing the problem.
2.1 The Problem
Given a program and a security property, the goal is to
verify whether the program satisﬁes the property, and if
not, identify why. Typically, the program performs sev-
eral security-relevant operations, and the security property