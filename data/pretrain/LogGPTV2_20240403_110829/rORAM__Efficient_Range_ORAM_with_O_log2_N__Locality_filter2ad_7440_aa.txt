title:rORAM: Efficient Range ORAM with O(log2 N) Locality
author:Anrin Chakraborti and
Adam J. Aviv and
Seung Geol Choi and
Travis Mayberry and
Daniel S. Roche and
Radu Sion
rORAM: Efﬁcient Range ORAM with O(log2 N ) Locality
Anrin Chakraborti∗, Adam J. Aviv†, Seung Geol Choi†, Travis Mayberry†, Daniel S. Roche†, Radu Sion∗
∗Stony Brook University, {anchakrabort, sion}@cs.stonybrook.edu
†United States Naval Academy, {aviv, choi, mayberry, roche}@usna.edu
1
Abstract—Oblivious RAM protocols (ORAMs) allow a client to
access data from an untrusted storage device without revealing to
that device any information about their access pattern. Typically
this is accomplished through random shufﬂing of the data such
that the storage device cannot determine where individual blocks
are located, resulting in a highly randomized access pattern.
Storage devices however, are typically optimized for sequential
access. A large number of random disk seeks during standard
ORAM operation induce a substantial overhead.
In this paper, we introduce rORAM, an ORAM speciﬁcally
suited for accessing ranges of sequentially logical blocks while
minimizing the number of random physical disk seeks. rORAM ob-
tains signiﬁcantly better asymptotic efﬁciency than prior designs
(Asharov et al., ePrint 2017, Demertzis et al., CRYPTO 2018) re-
ducing both the number of seeks and communication complexity
by a multiplicative factor of O(log N ). An rORAM prototype
is 30-50x times faster than Path ORAM for similar range-query
workloads on local HDDs, 30x faster for local SSDs, and 10x
faster for network block devices. rORAM’s novel disk layout
can also speed up standard ORAM constructions, e.g., resulting
in a 2x faster Path ORAM variant. Importantly, experiments
demonstrate suitability for real world applications – rORAM is
up to 5x faster running a ﬁle server and up to 11x faster running
a range-query intensive video server workloads compared to
standard Path ORAM.
I. INTRODUCTION
ORAM. An attacker viewing communications or tracking
accesses of a storage user can determine a wealth of private
information. Data encryption does not prevent this since access
patterns often reveal nearly as much as the data contents
themselves [28]. Oblivious RAM (ORAM) [27, 38, 41] aims
to solve this by making access patterns indistinguishable to an
adversary observing reads/writes to untrusted storage.
Typically, ORAM performance metrics have focused on
communication overhead, or bandwidth, loosely describing the
number of additional data reads/writes needed to perform a
single access [27]. More recently, other metrics have included
local computation complexity and round complexity. Numer-
ous ORAM constructions [10, 38, 40, 41, 42, 45] have been
proposed and studied optimizing these performance measures.
Data locality and range ORAM. One important measure,
so far largely overlooked, is data locality, the spatial locality
of data in storage, where related data is stored adjacent in
memory rows or blocks on disk. Due to caching effects
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2019
24-27  February  2019,  San  Diego,  CA,  USA
ISBN  1-891562-55-X
https://dx.doi.org/10.14722/ndss.2019.23320
www.ndss-symposium.org
levels of the memory hierarchy,
it has long been
at all
understood that taking advantage of spatial locality can have
signiﬁcant performance beneﬁts. In particular, a single cache
miss overhead is more costly than executing 100 instructions.
Disk seek overhead costs (e.g., time) often exceed 10000 times
the bandwidth cost of reading a single sequential block from
that disk [17]. This observation has led to the development
of efﬁcient data structures and algorithms which improve
performance by optimizing data locality in storage [18].
However, in the case of ORAMs, the randomization neces-
sary to ensure privacy seems to be in direct conﬂict with data
locality. Even for a single access, a typical ORAM requires
many non-sequential accesses to the untrusted data store. Even
worse, the upper-layer (e.g., ﬁle systems) generating optimized
accesses with high degree of locality to the underlying storage,
gains no beneﬁt when using a standard ORAM to interface
with a physical store. This is because in ORAMs, the physical
locations have no correlation with their logical addresses.
To address this, recently, Demertzis et al. [21] considered
locality for ORAMs in the context of searchable encryption
and provided an ORAM construction with O(1) disk seeks and
O(N 1/3 log2 N ) blocks communication complexity. This is a
logarithmic improvement over Path ORAM in the number of
seeks (Table I), but the signiﬁcant bandwidth blowup renders
the construction suitable only for very speciﬁc applications.
Further, in [21], range accesses – a key use case where
locality stemming from upper-layer accesses (e.g., in a ﬁle
system) should be heavily leveraged – are still inefﬁcient. For
a range of size r, the number of disk seeks required is O(r)
(note the dependence on the range size).
Asharov et al. [9] speciﬁcally considered the issue of
supporting efﬁcient range queries for ORAMs, by making disk
seeks independent of the range size. They show that ORAM
range query locality directly conﬂicts with standard ORAM
security requirements. By deﬁnition, a standard ORAM must
not reveal whether a client requests any r random items or
a contiguous region of length r. An ORAM protocol that
provides both locality and security must necessarily incur
prohibitive bandwidth overhead.
Asharov et al. further observed that carefully relaxing
the traditional ORAM security deﬁnition to match realistic
scenarios allows for signiﬁcantly more efﬁcient solutions.
Speciﬁcally, if leaking the rough size (i.e., ⌈log2 r⌉) of each
accessed range is acceptable, it is possible to design a range
ORAM construction with O(log3 N · (log log N )2) seeks per
operation, independent of the length r of the range (Table I).
For comparison, consider that Path ORAM needs O(r ·
log2 N ) seeks for r sequential accesses, where the dependency
on r stems mainly from a lack of locality. [9] does better
asymptotically when r = Ω(log N · (log log N )2), at the cost
of O(log N ) times higher communication complexity.
Our work. Unfortunately, this reduction in the number of
seeks comes at the cost of signiﬁcant bandwidth overhead,
which is often times much more expensive, especially when
data is outsourced to remote servers.
To mitigate this, we ask the following important question:
Can we construct an efﬁcient range ORAM scheme
with data locality, while ensuring that accesses to a
small range is asymptotically as fast as the traditional
ORAMs?
rORAM answers afﬁrmatively and provides a highly efﬁ-
cient range query mechanism with locality, with O(log2 N )
seek and O(r · log2 N ) non-amortized communication com-
plexity, O(log N ) times more efﬁcient than existing work.
Importantly, note that for singleton ranges, rORAM has the
same asymptotic bandwidth requirements as standard Path
ORAM [41] with a server-side position map!
A. Security & Application Setting
Security of range ORAM. At ﬁrst glance, it may seem that
allowing range size leaks seriously weakens ORAM security.
However, in most practical cases,
this leak already exists
inherent to the deployment.
For example, a typical ﬁle system running on top of an
ORAM issues a majority of its accesses in tightly time-
adjacent bursts of sequential block ranges. This immediately
leaks the range sizes to any underlying untrusted storage. In
fact, explicitly hiding range sizes may be futile if the under-
lying storage is already aware that a ﬁle system runs on top
of it. In the following, we detail several other considerations
that strengthen the case for accepting range size leaks.
First, consider that rORAM leaks only the rough length
of a range, where the actually queried range size is always
a power of 2, i.e., i = ⌈log2 r⌉. Thus for any user-desired
range length, e.g, {1, 2, 3, . . . , maxlen}, the leakage proﬁle
will be {⌈log2 1⌉,⌈log2 2⌉,⌈log2 3⌉, . . . ,⌈log2 maxlen⌉}. This
leakage contains O(log2 N ) different values and can be un-
derstood as O(log2 N ) different possible padding lengths. Of
course, padding any arbitrary length r always to a ﬁxed N
provides the best security, but it also greatly increases com-
munication costs. Having variable padding lengths provides a
tuning knob to trade off between efﬁciency and security.
More importantly, even with ﬁxed-length padding (the most
secure option), standard ORAMs leak signiﬁcant information,
mainly through the timing channel discussed above, not cap-
tured by the ORAM security deﬁnition. As discussed, for a
typical ﬁle system deployed on top of a standard ORAM block
device, accesses to different ﬁles/metadata/etc. are highly
correlated and can be determined accurately using timing
information on the number of blocks requested within a given
time window. No practically viable solution exists for this leak.
Application setting. Many applications, such as searchable
encryption, are well suited to less strict ORAM security
guarantees. Weaker ORAMs have been previously used to
design efﬁcient dynamic searchable encryption schemes [32].
Range ORAMs are particularly useful in this setting [21].
Further, as shown by experiments (Section VII), rORAM
is extremely well suited for deployment with traditional ﬁle
systems (e.g., ext4 ﬁle server). File systems typically generate
requests of variable sizes for both reading/writing ﬁles and
updating metadata. To achieve acceptable I/O throughputs,
the underlying ORAM block device needs to support efﬁcient
queries for arbitrarily-sized ranges of sequential blocks.
Accordingly, rORAM is designed to efﬁciently execute
range queries of variable sizes. This signiﬁcantly speeds up
ﬁle system operation and for large ﬁle applications (e.g., a
video server), the gains are even more noticeable. For example,
rORAM features a 5x speedup over Path ORAM running a
typical ﬁle server and an 11x speedup for a video server
application running on a local HDD.
In summary, rORAM generalizes standard ORAMs that do
not speciﬁcally support range queries, and provides an easy-
to-tune tradeoff between performance and security:
Applications querying only singleton ranges achieve
the same security guarantees as on a traditional ORAM
at similar costs. Applications querying entire ranges get
signiﬁcant performance increase at an easily quantiﬁ-
able security cost, namely leaking the size of the range.
B. rORAM Highlights
Locality-aware disk layout and batch writes. As we will see
later, a main rORAM building block is a modiﬁed version of
Path ORAM. We ﬁrst introduce a new technique for reducing
the number of seeks in a Path ORAM.
Tree-based ORAMs, such as Path ORAM, update data
in the server-side tree through an eviction operation, which
reads a speciﬁc path in its entirety and writes back as many
blocks as possible from the client-local stash along the path.
To prevent overﬂows, consecutive eviction paths are chosen
with minimum overlap, usually in bit-reversed lexicographical
ordering1 of the leaf identiﬁers [26].
However, this has a detrimental effect on the number of
seeks required when evictions are performed in batches, since
successively chosen eviction paths are topologically distant
from each other in the tree. Speciﬁcally, when tree nodes are
stored at random locations, the number of seeks required to
batch b evictions is O(b · log N ) (note the dependence on b).
Since range queries write back multiple blocks to the tree,
a more efﬁcient batching mechanism is desirable. By design,
rORAM enables many evictions to execute with very few
seeks – the number of seeks is independent of the number of
evictions performed. To this end, rORAM disk layout ensures
that tree nodes accessed in successive evictions are physically
located next to each other on the storage device.
In particular, the paths (i.e., corresponding to leaf nodes)
in the ORAM tree are labeled in bit-reversed lexicographic
ordering. Then, the physical buckets at each level of the tree
1In bit-reverse ordering, numbers are ordered by treating the leftmost bit as
the least signiﬁcant bit. For example, the sequence of 3-bit-reversed number
ordering is 000, 100, 010, 110, . . ., 111; that is, 0, 4, 2, 6, . . ., 7 in decimal.
2
Server Space
O(N log N )
rORAM (this work)
Asharov et al. (Range ORAM) [9] O(log3 N · (log log N )2), amort. O(r · log3 N ), amort. O(N log N )
Path ORAM (rec. PM) [41]
Path ORAM (local PM) [41]
Demertzis et al. [21]
O(r · log2 N )
O(N )
O(r · log N )
O(N )
O(r · N 1/3 · log2 N ) O(N )
Bandwidth
O(r · log2 N )
Seeks
O(log2 N )
O(r · log2 N )
O(r · log N )
O(r)
Client Storage
O(L · λ)
O(L · λ)
O(λ)
O(N )
O(N 1/3 log2 N )
Leakage
⌈log2 r⌉
⌈log2 r⌉
none
none
none
PERFORMANCE COMPARISON FOR A CLIENT ACCESSING A REGION OF r CONTIGUOUS BLOCKS. L IS THE MAXIMUM RANGE SIZE SUPPORTED BY THE
RANGE ORAM SCHEMES AND λ IS THE SECURITY PARAMETER. ALL COMPLEXITIES ARE IN TERMS OF NUMBER OF BLOCKS.
TABLE I
are stored adjacent to each other, following the same bit-
reversed ordering (see Figure 2 and Figure 3).
in one sub-ORAM does not immediately provide its location
in the other sub-ORAMs.
As a result, when performing b evictions together, buckets
can be fetched (and written back) level-by-level. Due to the
physical layout of the tree, the b mod 2i buckets required
from level i, will be adjacent to each other on physical storage
and can be read with only 1 seek. Effectively, b evictions now
require in total O(log N ) seeks, independent of b.
Interestingly, since rORAM applies this technique to Path
ORAM itself, it achieves better efﬁciency not only for range
query applications but also for standard Path ORAM perfor-
mance. Experiments show a 2x speedup for standard Path
ORAM equipped with the disk-aware layout and batched
evictions (Section VII).
Multiple sub-ORAMs with different data locality. rORAM
deploys O(log N ) separate Path ORAM based sub-ORAMs,
each of which contains a copy of the same data at all times.
Further, each sub-ORAM is optimized to serve a different
range size with minimal disk seeks.
Speciﬁcally, the ith sub-ORAM is optimized for access to
a contiguous range of length r where ⌈log2 r⌉ = i. This leaks
the rough size of the given range, but it allows the sub-ORAM
to be highly efﬁcient in serving the query.
Locality-sensitive mapping. The locality-aware disk layout
only ensures that multiple batched evictions incur a small
number of disk seeks independent of the batch size. However
the layout does not provide any seek-related guarantees when
querying for multiple blocks from different random paths in a
Path ORAM tree. This is because Path ORAMs place blocks
along random tree paths, regardless of the block address. As a
result, fetching a logically related range of blocks still requires
fetching multiple random paths from the tree, unavoidably
incurring a large number of seeks. Speciﬁcally, if each node
of the tree is stored at a random location on disk, fetching a
range of size r requires O(r · log N ) seeks.
To mitigate this, rORAM introduces a novel block mapping
scheme consistent with the locality-aware disk layout. In
particular, the scheme places the ﬁrst block in a range onto a
random path in the tree, and all subsequent blocks in the range
are placed along paths that are stored adjacent to each other
on disk. Now, reading a range of size r requires only O(log N )
seeks! Critically, as we will show, with an appropriately-sized
stash, the mapping provides standard privacy assurances.
Efﬁcient management of multiple position maps. Note that
since rORAM duplicates data across multiple sub-ORAMs,
updates to a block in one sub-ORAM should be reﬂected to