title:Inference of Expressive Declassification Policies
author:Jeffrey A. Vaughan and
Stephen Chong
2011 IEEE Symposium on Security and Privacy
Inference of expressive declassiﬁcation policies
Jeffrey A. Vaughan
University of California, Los Angeles
PI:EMAIL
Harvard School of Engineering and Applied Sciences
Stephen Chong
PI:EMAIL
Abstract—We explore the inference of expressive human-
readable declassiﬁcation policies as a step towards providing
practical tools and techniques for strong language-based infor-
mation security.
Security-type systems can enforce expressive information-
security policies, but can require enormous programmer effort
before any security beneﬁt is realized. To reduce the burden
on the programmer, we focus on inference of expressive yet
intuitive information-security policies from programs with few
programmer annotations.
We deﬁne a novel security policy language that can express
what information a program may release, under what condi-
tions (or, when) such release may occur, and which procedures
are involved with the release (or, where in the code the release
occur). We describe a dataﬂow analysis for precisely inferring
these policies, and build a tool that instantiates this analysis
for the Java programming language. We validate the policies,
analysis, and our implementation by applying the tool to a
collection of simple Java programs.
Keywords-declassiﬁcation policies, information ﬂow, language
based security, inference of security policies.
I. INTRODUCTION
Many computer systems manipulate sensitive informa-
tion, and it is important to reason about the information
security of these systems. Recent work on language-based
information-ﬂow security provides both expressive informa-
tion security policies, and techniques for enforcing these
policies (e.g., [1, 2, 3, 4, 5, 6]). However, it can be difﬁcult
for programmers to obtain the security guarantees offered
by these expressive policies, for at least two reasons. First,
the security policies are sometimes unintuitive, requiring
a sophisticated understanding of program semantics and
noninterference-based semantic security conditions. Second,
the most common enforcement technique, security-type sys-
tems [7], often requires enormous programmer effort before
any security guarantees are achieved. For example, Askarov
and Sabelfeld [8] report 150 person-hours to develop a
security-typed implementation of a cryptographic protocol,
compared to 60 person-hours for a non-security-typed im-
plementation.
In this work, we move towards practical language-based
information-ﬂow security by:
1) Deﬁning an expressive yet intuitive information secu-
2) Describing a dataﬂow analysis for precisely inferring
rity policy language.
these policies.
3) Building a tool that instantiates this analysis for the
Java programming language.
We validate the policies, analysis, and our implementation
by applying the tool to a collection of simple Java programs.
Inference of security policies. We focus on the inference
of security policies for a program, as contrasted with the a
priori speciﬁcation of policies by a programmer via pro-
gram annotations. During development programmers may
not yet clearly understand program structure, and may have
difﬁculty providing security-type annotations for program
variables and function declarations.
Inference of security policies during the development
process allows a programmer to understand the important
information ﬂows in a program, and to then decide if
these ﬂows are consistent with the security requirements
of the program. If the inferred security policies describe
information ﬂows that the programmer or a security audit
determine are suitable for the application, no further action
needs to be taken. Otherwise, either the program contains
insecure information ﬂows, or the analysis is insufﬁciently
precise; regardless, the programmer needs to invest more
time and effort into the program’s security, by modifying the
program, or providing additional information to the analysis.
Thus, by inferring security policies, the programmer can
receive weak security guarantees with relatively little effort,
and if those guarantees are too weak, can invest additional
effort improving the program’s security guarantees.
An additional beneﬁt is that inference of security policies
does not prevent program compilation or execution, and
thus does not prevent functional testing or deployment of
an application.
We aim to infer security policies for Java programs
with few programmer annotations. More precisely, once the
programmer has speciﬁed at
least some of the program
points where sensitive information enters the system, and
information leaves the system, our tool can infer security
policies that describe what sensitive information may be
revealed to an observer of the system.
Expressive declassiﬁcation policies. Our security poli-
cies give a concise and informative summary of the infor-
mation ﬂows in a program. Policies describe what sensitive
information may be revealed to an observer of the system,
when such information may be released, which methods
in the code base were involved with release of sensitive
1081-6011/11 $26.00 © 2011 IEEE
DOI 10.1109/SP.2011.20
180
information (a form of where declassiﬁcation, according
to the categorization by Sabelfeld and Sands [9]). The
policy language is intended to be well-known and intuitive,
balancing expressivity with ease of inference. (Of course,
the same policy language could also be used for a priori
speciﬁcation.)
For example, consider the following Java-like program
with annotations indicated by at signs (“@”).
public static void main(String args []) {
...
int creditCardNum = @input ‘‘cc’’ readCC();
String message = ‘‘No receipt.’’ ;
...
if (@input ‘‘requestReceipt’’ requestReceipt()) {
}
System.out.println(@output ‘‘stdout’’ message);
message = lastFourDigits(creditCardNum);
}
static int lastFourDigits (int n) @track {
}
return n % 10000;
1
2
3
4
5
6
7
8
9
10
11
12
13
14
The @input annotations (lines 3 and 6) indicate where
information enters the system, and provide names to refer to
these inputs (“cc” and “requestReceipt” respectively). The
@output annotation (line 9) indicates where information
leaves the system, and provides a name to refer to the output.
The information that may be revealed at the output (i.e.,
by printing the contents of variable message) satisﬁes the
security policy
if requestReceipt[0] then
Reveal(cc[0] mod 10000),
which intuitively means that if the most recent input named
requestReceipt is true, then the last four digits of the most
recent input named cc may be revealed; the value of the most
recent input named requestReceipt may also be revealed,
but no other information will be. Thus,
the policy de-
scribes what information may be released (cc[0] mod 10000),
and the conditions under which the release may occur
(requestReceipt[0] evaluates to true). Speciﬁcally, this policy
implies that if requestReceipt[0] is false, then an observer
does not learn anything about cc[0].
This policy expresses extensional
information security
about the program, that is, security in terms of the input/out-
put behavior of the program. Our policies can also represent
certain kinds of intensional information security (i.e., se-
curity in terms of the implementation of the program), by
describing which methods must be involved in the release
of information. In the code above, the @track annotation
(line 12) indicates that the programmer is interested in how
the method lastFourDigits participates in information ﬂows
in the program. The output of the program also satisﬁes the
181
Policies
p, q ::= Reveal(e1, . . . , en)
| if d then p1 else p2
| if-executed r then p
| p1 and p2
Input expressions
Revelation policy
Conditional policy
Track policy
Conjunctive policy
e ::= ν[i] | ν[i+] | n | e1 + e2 | e1 = e2 | . . .
ν ∈ ChannelName
Indices
i ::= 0 | 1 | 2 | . . .
Precise input expressions
d ::= ν[i] | n | d1 + d2 | d1 = d2 | . . .
Track expressions
r ::= k | r1∧∧∧ r2 | r1∨∨∨ r2
k ∈ Mark
Figure 1. Grammar for security policies
more restrictive policy
if requestReceipt[0] then
if-executed lastFourDigits (int) then
Reveal(cc[0] mod 10000)
which indicates that if requestReceipt[0] evaluates to true
and the method lastFourDigits (int) was executed,
then
cc[0] mod 10000 may be revealed. This is indeed the policy
that our inference algorithm infers for this program.
The rest of the paper is structured as follows. In Section II
we describe the security policies in more detail, and use a
simple imperative language to provide a formal semantics
for the policies. In Section III we describe a dataﬂow
analysis that can precisely infer security policies, and in
Section IV we discuss our implementation of the analysis
for the Java programming language. We have used this
implementation to infer security policies for several Java
programs, and we discuss our experience in Section V. Sec-
tion VI summarizes related work, and we discuss possible
extensions and conclude in Section VII.
II. POLICIES AND SECURITY
Our security policies are intended to be expressive yet
intuitive, and amenable to precise inference. In this section,
we describe our policies intuitively, then present a formal
semantics for the policies in terms of a simple imperative
language.
A. Policies
Policies describe what an observer of a program may learn
about inputs to the program. The syntax of our security
policies is described by the grammar in Fig. 1.
An input expression ν[i] indicates the ith most recent input
on the channel named ν. For example, H[0] indicates the
most recent input on channel H, and H[1] indicates the next-
to-last input on channel H. A lifted index i+ indicates all
inputs prior to and including i. For instance L[0+] indicates
all input on channel L and L[1+] indicates all inputs except
for the most recent. A precise input expression is any input
expression that contains no lifted indices. Thus, H[0] is a
precise input expression whereas H[1+] is not.
A revelation policy Reveal(e1, . . . , en) says that an ob-
server may learn the value of any and all of the input
expressions e1 to en. For example, policy Reveal(H[0])
states that an observer of the program may learn everything
about the most recent input on channel H. This policy is an
accurate description of the information ﬂow of the following
program, for an observer of the output of channel L.
input x from H; output x to L
Policy Reveal(H[0] mod 10000, H[1]) is an accurate de-
scription of the following program for an L observer, who
may learn both the last four digits of the most recent input,
and everything about the next-to-last input.
input x from H;
input y from H;
z := (“Answers are ” . (y mod 10000) . “ and ” . x);
output z to L
A conditional policy if d then p1 else p2 indicates that an
observer may learn the evaluation of precise input expression
d. Moreover, in an execution in which d evaluates to true, p1
describes additional information the observer may learn, and
in an execution in which d evaluates to false, p2 describes
additional information that may be learned.
In the following program, input from the user on channel
L determines whether a sensitive input from channel H is
revealed.
input secret from H;
input password from H;
input guess from L;
if (guess = password) then x := secret; else x := 42;
output x to L
An observer of channel L may learn information described
by the policy
if H[0] = L[0] then
Reveal(H[1])
else
Reveal(42).
There are several things to note about this policy. First, in
addition to possibly learning the value of secret, the observer
may learn whether guess is equal to password (H[0] =
L[0]). Second, the revelation policy Reveal(42) indicates that
nothing is revealed about inputs from channel H, and is
equivalent to the policy Reveal(). The semantics of policies
is discussed further in Section II-C. We write if d then p as
syntactic sugar for the policy if d then p else Reveal().
A track policy if-executed r then p indicates that if an
execution matches track expression r then p describes in-
formation an observer may learn. Track expressions are
conjunctions and disjunctions of marks, which are events
that may occur during execution, for example, a particular
procedure being called. For expository purposes, we assume
that event mark k occurs when a command mark k is
executed.
Thus, an execution trace matches mark k if the command
mark k was encountered during execution. An execution
trace matches track expression r1∧∧∧ r2 if it matches both r1
and r2, and matches r1∨∨∨ r2 if it matches either r1 or r2.
For example, in the following program, the information that
may be learned by an observer is described by the policy
if-executed CorrectGuess then Reveal(H[0]).
input secret from H;
input guess from L;
if (guess > 100) then
mark CorrectGuess;
x := secret;
else
x := 0;
output x to L
That is, for a given execution of the program, the observer
may learn the value of secret only if the mark CorrectGuess
occurred. If the mark did not occur, then the observer cannot
learn the value of the most recent input from channel H.
Thus, the following program does not satisfy the policy
if-executed CorrectGuess then Reveal(H[0]).
input secret from H; output secret to L
Track policies provide assurance that information release