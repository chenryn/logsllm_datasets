Uğ’‰ :=
(cid:110)(U1, . . . ,Uğµ) : U1, . . . ,Uğµ âŠ† [ğ‘›]
Uğ‘— = [ğ‘›] and |Uğ‘—| = â„ ğ‘— ,âˆ€ğ‘— âˆˆ [ğµ](cid:111).
where Uğ‘—â€™s are disjoint for all ğ‘— âˆˆ [ğµ]. Note also that |Uğ’‰| =(cid:0)ğ‘›
Note that for each (U1, . . . ,Uğµ) âˆˆ Uğ’‰, Uğ‘— for ğ‘— = 1, . . . , ğµ denotes
the identities of the clients that map to the ğ‘—â€™th element in [ğµ],
â„1!â„2!...â„ğµ!. It is easy to verify that for any ğ’‰ âˆˆ Ağ‘›
ğµ, ğ¹(P)(ğ’‰) is
equal to
ğµ, define
(cid:1) =
ğµ
(16)
s.t.
ğ‘—=1
ğ‘›!
ğ’‰
âˆ‘ï¸
ğµ

(U1,...,Uğµ)âˆˆUğ’‰
ğ‘—=1
ğ‘–âˆˆUğ‘—
ğ¹(P)(ğ’‰) =
ğ‘ğ‘– ğ‘—
(17)
Similarly, we can define ğ¹(Pâ€²), ğ¹(Pâˆ’ğ‘–), ğ¹(Pâ€²âˆ’ğ‘–). Note that ğ¹(P)
and ğ¹(Pâ€²) are distributions over Ağ‘›
ğµ, whereas, ğ¹(Pâˆ’ğ‘–) and ğ¹(Pâ€²âˆ’ğ‘–)
are distributions over Ağ‘›âˆ’1
ğµ . It is easy to see that ğ¹(P) = M(D)
and ğ¹(Pâ€²) = M(Dâ€²). Similarly, ğ¹(Pâˆ’ğ‘–) = M(Dâˆ’ğ‘–) and ğ¹(Pâ€²âˆ’ğ‘–) =
M(Dâ€²âˆ’ğ‘–). Now we are ready to prove Theorem 3.6.
Since R is an ğœ–0-LDP mechanism, we have
ğ‘’âˆ’ğœ–0 â‰¤ ğ‘ğ‘– ğ‘—
ğ‘â€²
ğ‘› ğ‘—
â‰¤ ğ‘’ğœ–0,
âˆ€ğ‘— âˆˆ [ğµ] , ğ‘– âˆˆ [ğ‘›].
As mentioned in Section 3.3.1, a crucial observation is that any
distribution ğ’‘ğ‘– can be written as the following mixture distribution:
(18)
ğ‘’ğœ–0 . The distribution Ëœğ’‘ğ‘– = [ Ëœğ‘ğ‘–1, . . . , Ëœğ‘ğ‘–ğµ] is given by Ëœğ‘ğ‘– ğ‘— =
1
ğ‘—=1 Ëœğ‘ğ‘– ğ‘— = 1.
, where it is easy to verify that Ëœğ‘ğ‘– ğ‘— â‰¥ 0 andğµ
where ğ‘ =
ğ‘ğ‘– ğ‘—âˆ’ğ‘ğ‘â€²
1âˆ’ğ‘
ğ‘› + (1 âˆ’ ğ‘) Ëœğ’‘ğ‘–,
ğ’‘ğ‘– = ğ‘ğ’‘â€²
ğ‘› ğ‘—
This idea of writing the distribution of the output of an LDP mech-
anism as a mixture distribution is inspired from [7, 24]. However,
we create different mixtures and use them in a distinct way to re-
duce the Renyi divergence calculation to those distributions with a
certain neighborhood structure using Lemma 5.3.
ğ‘› + (1 âˆ’ ğ‘) Ëœğ’‘ğ‘– is a mix-
ture distribution, we can write ğ¹(P) and ğ¹(Pâ€²) as certain convex
combinations. Before stating the result, we need some notation.
C, having ğ‘› distribu-
For any C âŠ† [ğ‘› âˆ’ 1], define two sets PC, Pâ€²
Now we show that since each ğ’‘ğ‘– = ğ‘ğ’‘â€²
tions each, as follows:
PC = { Ë†ğ’‘1, . . . , Ë†ğ’‘ğ‘›âˆ’1}{ğ’‘ğ‘›},
C = { Ë†ğ’‘1, . . . , Ë†ğ’‘ğ‘›âˆ’1}{ğ’‘â€²
(cid:40)
ğ‘›},
Pâ€²
where, for every ğ‘– âˆˆ [ğ‘› âˆ’ 1], Ë†ğ’‘ğ‘– is defined as follows:
ğ’‘â€²
Ëœğ’‘ğ‘–
if ğ‘– âˆˆ C,
if ğ‘– âˆˆ [ğ‘› âˆ’ 1] \ C.
ğ‘›
(21)
Ë†ğ’‘ğ‘– =
Note that PC and Pâ€²
C differ only in one distribution, where PC
C contains ğ’‘â€²
contains ğ’‘ğ‘› whereas Pâ€²
ğ‘›. In words, if clients map their
data points according to the distributions in either PC or Pâ€²
C for
any C âŠ† [ğ‘› âˆ’ 1], then for all clients ğ‘– âˆˆ C, the ğ‘–â€™th client maps its
data point according to ğ’‘â€²
ğ‘› (which is the distribution of R on input
ğ‘‘â€²
ğ‘›), and for all clients ğ‘– âˆˆ [ğ‘› âˆ’ 1] \ C, the ğ‘–â€™th client maps its data
point according to Ëœğ’‘ğ‘–. The last client maps its data point according
to ğ’‘ğ‘› or ğ’‘â€²
In the following lemma, we show that ğ¹(P) and ğ¹(Pâ€²) can be
written as convex combinations of {ğ¹(PC) : C âŠ† [ğ‘› âˆ’ 1]} and
{ğ¹(Pâ€²
C) : C âŠ† [ğ‘› âˆ’ 1]}, respectively, where for any C âŠ† [ğ‘› âˆ’ 1],
both ğ¹(PC) and ğ¹(Pâ€²
C) can be computed analogously as in (17).
Lemma 5.1 (Mixture Interpretation). ğ¹(P) and ğ¹(Pâ€²) can be
ğ‘› depending on whether the set is PC or Pâ€²
C.
written as the following convex combinations:
(19)
(20)
âˆ‘ï¸
âˆ‘ï¸
CâŠ†[ğ‘›âˆ’1]
CâŠ†[ğ‘›âˆ’1]
ğ¹(P) =
ğ¹(Pâ€²) =
ğ‘|C|(1 âˆ’ ğ‘)ğ‘›âˆ’|C|âˆ’1ğ¹(PC),
ğ‘|C|(1 âˆ’ ğ‘)ğ‘›âˆ’|C|âˆ’1ğ¹(Pâ€²
C),
(22)
(23)
where PC, Pâ€²
C are defined in (19)-(21).
We prove Lemma 5.1 in Appendix B.1.
102103104105106Number of iterations T10âˆ’1100101102Approximate DP ÎµÎµ0=3.0,n=106,Î´=10âˆ’8via RDP (1st upper bound)via RDP (lower bound)Clones[FMT20]+strong composition[KOV15]102103104105106Number of iterations T10âˆ’1100Approximate DP ÎµÎµ0=3.0,n=107,Î´=10âˆ’8via RDP (1st upper bound)via RDP (lower bound)Clones[FMT20]+strong composition[KOV15]Session 7D: Privacy for Distributed Data and Federated Learning CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea 2330Now, using Lemma 5.1, in the following lemma we show that the
RÃ©nyi divergence between ğ¹(P) and ğ¹(Pâ€²) can be upper-bounded
by a convex combination of the RÃ©nyi divergence between ğ¹(PC)
and ğ¹(Pâ€²
C) for C âŠ† [ğ‘› âˆ’ 1].
Lemma 5.2 (Joint Convexity). For any ğœ† > 1, the function
is jointly convex in (ğ¹(P), ğ¹(Pâ€²)), i.e.,
Eğ’‰âˆ¼ğ¹ (Pâ€²)
(cid:17)ğœ†(cid:21)
(cid:20)(cid:16) ğ¹ (P)(ğ’‰)
(cid:34)(cid:18) ğ¹ (P) (ğ’‰)
ğ¹ (Pâ€²)(ğ’‰)
(cid:19)ğœ†(cid:35)
C
C
CâŠ†[ğ‘›âˆ’1]
Eğ’‰âˆ¼ğ¹ (Pâ€²)
ğ‘›, . . . , ğ‘‘â€²
ğ‘›, . . . , ğ’‘â€²
ğ¹ (Pâ€²) (ğ’‰)
ğ‘|C| (1 âˆ’ ğ‘)ğ‘›âˆ’|C|âˆ’1 E
ğ‘›, ğ‘‘ğ‘›(cid:1) and Dâ€²(ğ‘›)
(24)
We prove Lemma 5.2 in Appendix B.2. For any C âŠ† [ğ‘› âˆ’ 1],
: ğ‘– âˆˆ [ğ‘› âˆ’ 1] \ C}. With this notation, note
{ğ’‘â€²
ğ‘›, . . . , ğ’‘â€²
ğ‘›} is a pair of specific neighboring distributions,
each containing |C| + 1 distributions. In other words, if we de-
fine D(ğ‘›)
ğ‘›, . . . , ğ‘‘â€²
having (|C| + 1) data points, then the mechanisms M(D(ğ‘›)
and M(Dâ€²(ğ‘›)
ğ¹(Pâ€²
(cid:17)
ğœ† .
â‰¤ âˆ‘ï¸
(cid:169)(cid:173)(cid:173)(cid:171) ğ¹ (PC) (ğ’‰)
(cid:170)(cid:174)(cid:174)(cid:172)
ğ¹(cid:16)Pâ€²
(cid:17) (ğ’‰)
ğ’‰âˆ¼ğ¹(cid:16)Pâ€²
let (cid:101)P[ğ‘›âˆ’1]\C = { Ëœğ’‘ğ‘–
ğ‘›}{ğ’‘ğ‘›} and Pâ€²
that PC \(cid:101)P[ğ‘›âˆ’1]\C = {ğ’‘â€²
C \(cid:101)P[ğ‘›âˆ’1]\C =
ğ‘›}{ğ’‘â€²
|C|+1 =(cid:0)ğ‘‘â€²
|C|+1 =(cid:0)ğ‘‘â€²
ğ‘›(cid:1), each
|C|+1) will have distributions ğ¹(PC \ (cid:101)P[ğ‘›âˆ’1]\C) and
C \(cid:101)P[ğ‘›âˆ’1]\C), respectively.
of distributions in(cid:101)P[ğ‘›âˆ’1]\C in the RHS of (24), we would be able
|C|+1, D(ğ‘›)
the distributions in(cid:101)P[ğ‘›âˆ’1]\C in the RHS (24).
(cid:20)(cid:16) ğ¹ (P)(ğ’‰)
(cid:17)ğœ†(cid:21)
to bound the RHS of (24) using the RDP for the special neighboring
datasets in D|C|+1
same . This is precisely what we will do in the follow-
ing lemma and the subsequent corollary, where we will eliminate
The following lemma holds for arbitrary pairs (P, Pâ€²) of neigh-
boring distributions P = {ğ’‘1, . . . , ğ’‘ğ‘›} and Pâ€² = {ğ’‘1, . . . , ğ’‘ğ‘›âˆ’1, ğ’‘â€²
ğ‘›},
where we show that Eğ’‰âˆ¼ğ¹ (Pâ€²)
does not decrease
when we eliminate a distribution ğ’‘ğ‘– (i.e., remove the data point
ğ‘‘ğ‘– from the datasets) for any ğ‘– âˆˆ [ğ‘› âˆ’ 1]. We need this general
statement as it will be required in the proof of Theorem 3.1 later.
same , if we remove the effect
|C|+1) âˆˆ D|C|+1
Now, since (Dâ€²(ğ‘›)
|C|+1)
ğ¹ (Pâ€²)(ğ’‰)
ğ‘›, ğ‘‘â€²
Lemma 5.3 (Monotonicity). For any ğ‘– âˆˆ [ğ‘› âˆ’ 1], we have
(cid:169)(cid:173)(cid:173)(cid:171) ğ¹ (Pâˆ’ğ‘–) (ğ’‰)
ğ¹(cid:16)Pâ€²âˆ’ğ‘–
(cid:17) (ğ’‰)
ğœ† , (25)
(cid:170)(cid:174)(cid:174)(cid:172)
â‰¤ E
ğ’‰âˆ¼ğ¹(Pâ€²
âˆ’ğ‘–)
ğ¹ (Pâ€²) (ğ’‰)
Eğ’‰âˆ¼ğ¹ (Pâ€²)
where, for ğ‘– âˆˆ [ğ‘› âˆ’ 1], Pâˆ’ğ‘– = P \ {ğ’‘ğ‘–} and Pâ€²âˆ’ğ‘– = Pâ€² \ {ğ’‘ğ‘–}. Note
that in the left hand side (LHS) of (25), ğ¹(P), ğ¹(Pâ€²) are distributions
ğµ, whereas, in the RHS, ğ¹(Pâˆ’ğ‘–), ğ¹(Pâ€²âˆ’ğ‘–) for any ğ‘– âˆˆ [ğ‘› âˆ’ 1]
over Ağ‘›
are distributions over Ağ‘›âˆ’1
ğµ .
We prove Lemma 5.3 in Appendix B.3. Note that Lemma 5.3 is a
general statement that holds for arbitrary pairs (P, Pâ€²) of neigh-
boring distributions. For our purpose, we apply Lemma 5.3 with
(PC, Pâ€²
C) for any C âŠ† [ğ‘› âˆ’ 1] and then eliminate the distribu-
tions in(cid:101)P[ğ‘›âˆ’1]\C one by one. The result is stated in the following
corollary.
(cid:34)(cid:18) ğ¹ (P) (ğ’‰)
(cid:19)ğœ†(cid:35)
(cid:0)ğ‘‘â€²
Corollary 5.4. Consider any ğ‘š âˆˆ {0, 1, . . . , ğ‘› âˆ’ 1}. Let D(ğ‘›)
ğ‘›, . . . , ğ‘‘â€²
(i.e., C âŠ† [ğ‘› âˆ’ 1] such that |C| = ğ‘š), we have
ğ‘›, . . . , ğ‘‘â€²
ğ‘š+1 =
ğ‘š
ğ‘›(cid:1). Then, for any C âˆˆ(cid:0)[ğ‘›âˆ’1]
(cid:1)
(cid:33)ğœ† .
(cid:32)M(D(ğ‘›)
ğ‘š+1)(ğ’‰)
ğ‘š+1)(ğ’‰)
M(Dâ€²(ğ‘›)
(26)
Eğ’‰âˆ¼ğ¹ (Pâ€²
C)
ğ’‰âˆ¼M(Dâ€²(ğ‘›)
ğ‘š+1)
We prove Corollary 5.4 in Appendix B.4. Substituting from (26)
ğµ, ğ¹(P)(ğ’‰) and ğ¹(Pâ€²)(ğ’‰)
into (24) and noting that for every ğ’‰ âˆˆ Ağ‘›
are distributionally equal to M(D)(ğ’‰) and M(Dâ€²)(ğ’‰), respec-
tively, we get
ğ¹(Pâ€²
C)(ğ’‰)
ğ‘›, ğ‘‘ğ‘›(cid:1) and Dâ€²(ğ‘›)
ğ‘š+1 =(cid:0)ğ‘‘â€²
(cid:32) ğ¹(PC)(ğ’‰)
(cid:33)ğœ† â‰¤ E
(cid:19)ğœ†(cid:35)
(cid:34)(cid:18) M (D) (ğ’‰)
âˆ‘ï¸
âˆ‘ï¸
(cid:18)ğ‘› âˆ’ 1
M (Dâ€²) (ğ’‰)
Câˆˆ([ğ‘›âˆ’1]
ğ‘š )
Câˆˆ([ğ‘›âˆ’1]
ğ‘š )
(cid:19)
ğ‘ğ‘š (1 âˆ’ ğ‘)ğ‘›âˆ’ğ‘šâˆ’1 E
ğ‘ğ‘š (1 âˆ’ ğ‘)ğ‘›âˆ’ğ‘šâˆ’1 E
Eğ’‰âˆ¼M(Dâ€²)
ğ‘š=0
(a)â‰¤ ğ‘›âˆ’1âˆ‘ï¸
(b)â‰¤ ğ‘›âˆ’1âˆ‘ï¸
ğ‘›âˆ’1âˆ‘ï¸
ğ‘š=0
C
C
ğ’‰âˆ¼M(Dâ€²(ğ‘›)
ğ‘š+1)