This works when all memory is MAP SHARED. How-
ever, if the reallocated object (new canonical) is large
enough to be stored on its own MAP PRIVATE pages,
create shadow will allocate a different set of physi-
cal page frames instead of creating an alias. This re-
quires copying the contents of the object to the new page
frames. Copying is mildly inefﬁcient, but few programs
use realloc extensively.
The overhead saving is upper-bounded by the original
cost of MAP SHARED arenas.
Abandoned approach: Batching system calls. We
tried batching the creation or destruction of shadows, but
did not end up using this approach in Oscar.
We implemented a custom syscall (loadable kernel
module ioctl) to create or destroy a batch of shadows.
When we have no more shadows for a canonical page,
we call our batchCreateShadow ioctl once to create
100 shadows, reducing the amortized context switch cost
per malloc by 100x. However, this does not reduce the
overall syscall cost by 100x, since mremap’s internals are
costly.
In a microbenchmark, creating and destroying
100 million shadows took roughly 90 seconds with indi-
vidual mremap/munmap calls (i.e., 200 million syscalls)
vs. ≈80 seconds with our batched syscall. The savings
of 10 seconds was consistent with the time to call a no-op
ioctl 200 million times.
Figure 11: Left: Simpliﬁed lifecycle of a chunk of mem-
ory. Right: The destroyShadow syscall has been modi-
ﬁed to simultaneously destroy the old shadow and create
a new one.
tional wisdom [23], with a small design modiﬁcation,
Oscar can both unmap and prevent reuse of a virtual
page. We use a “high water mark” for shadow addresses:
when Oscar creates a shadow, we specify the high wa-
ter mark as the requested shadow address, and then in-
crement the high water mark by the size of the alloca-
tion. This is similar to the sbrk limit of malloc. Oscar
can now safely use munmap to disable shadows, without
risk of reusing old shadows. As we show in Section 6.1,
virtual address space exhaustion is an unlikely, tractable
problem.
Our scheme,
including the high water mark,
is
compatible with address space layout randomization
(ASLR). At startup, we initialize the high-water mark
at a ﬁxed offset to the (randomized) heap base address.
To reduce variability in run-times, all benchmarks, in-
cluding the baseline, were measured without ASLR, as
is typical in similar research [40].
Refreshing shadows. Figure 11 (left) depicts the sim-
pliﬁed circle of life of a heap-allocated chunk of physi-
cal memory. Over the lifetime of a program, that chunk
may be allocated, freed, allocated, freed, etc., resulting
in syscalls to create a shadow, destroy a shadow, create a
shadow, destroy a shadow, etc. Except for the very ﬁrst
time a chunk has been created by malloc, every shadow
creation is preceded by destroying a shadow.
Oscar therefore speculatively creates a new shadow
each time it destroys a shadow, in Figure 11 (right). This
saves the cost of creating a new shadow, the next time an
object is allocated on that canonical page. The optimisti-
cally renewed shadow is stored in a hash table, keyed
by the size of shadow (in number of pages) and the ad-
dress of the canonical page (not the canonical object).
This means the shadow address can be used for the next
similarly-sized object allocated on the canonical page(s),
even if the new object does not coincide precisely with
USENIX Association
26th USENIX Security Symposium    821
    malloc() syscall: Create shadow  free() syscall: Destroy shadow Not alloc’ed; no shadow Allocated (with shadow)      malloc() syscall: Create shadow  free() syscall: Refresh shadow Not alloc’ed; fresh shadow Allocated (with shadow) Figure 12: SPEC CPU2006 C/C++ benchmarks, showing the beneﬁts of our optimizations.
In our pilot study, batching did not have a signiﬁcant
beneﬁt. It even slowed down some benchmarks, due to
mispredicting which shadows will be needed in the fu-
ture. For example, we may create 100 shadows for a
page that contains solely of a single object which is never
freed, wasting 99 shadows.
We also tried batch-disabling shadows: any objects
that are free()’d are stored in a “quarantine” of 100
objects, and when the quarantine becomes full, we dis-
able all 100 shadows with a single batched syscall, then
actually free those 100 objects. This approach maintains
temporal memory safety, unlike the standard use of quar-
antine (see Section 7). Unlike batch-creating shadows,
with batch-deletion we need not predict the future.
In our pilot study, batch deletion had mixed effects on
runtime overhead. We hypothesize this is due to disrupt-
ing favorable memory reuse patterns: malloc prefers to
reuse recently freed objects, which are likely to be hot in
cache; quarantine prevents this.
4.1 Performance Evaluation
The effect of these improvements on the previous subset
of 15 benchmarks is shown in Figure 12.
Our ﬁrst two optimizations (high water mark, refresh-
ing shadows) greatly reduce the overhead for gcc and
sphinx; this is not a surprise, as we saw from Figure
9 that much of gcc and sphinx’s overhead is due to
creating/destroying shadows. These two optimizations
do not beneﬁt mcf, as its overhead was entirely due to
MAP SHARED arenas; instead, fortuitously, the over-
head is eliminated by the MAP PRIVATE optimization.
The MAP PRIVATE optimization also reduces the over-
head on milc by roughly ten percentage points, almost
eliminating the overhead attributed to MAP SHARED.
The four allocation-intensive benchmarks are shown
in Figure 13. Recall that for these benchmarks, the
baseline scheme could not run to completion, owing
to the excessive number of leftover vm area structs
Figure 13: The 4 allocation-intensive benchmarks.
for mprotect’ed shadows corresponding to “freed” ob-
jects. The high water mark optimization, which perma-
nently munmaps the shadows, allows Linux to reclaim the
vm area structs, reducing the memory utilization sig-
niﬁcantly and enabling them to complete successfully.
To separate out the cost of syscalls from TLB pres-
sure, we backported the high water mark change to Cre-
ate/disable shadows.
For all four benchmarks, MAP SHARED and inline meta-
data costs (the ﬁrst two columns) are insigniﬁcant com-
pared to creating/disabling and using shadows. Refresh-
ing shadows reduces overhead somewhat for perlbench
and omnetpp but increases overhead for xalancbmk and
dealII.
The MAP PRIVATE optimization had a negligible ef-
fect, except for perlbench, which became 30 p.p.
slower. This was initially surprising, since in all other
cases, MAP PRIVATE is faster than MAP SHARED. How-
ever, recall that Oscar also had to change the realloc
implementation. perlbench uses realloc heavily: 11
million calls, totaling 700GB of objects; this is 19x the
reallocs of all other 18 benchmarks combined (by calls
or GBs of objects). We conﬁrmed that realloc caused
the slowdown, by modifying Refreshing shadows to use
the inefﬁcient realloc but with MAP SHARED always;
822    26th USENIX Security Symposium
USENIX Association
   -10%0%10%20%30%40%50%60%bzip2gccmcfgobmkhmmersjenglibquantumh264refmilclbmsphinxastarnamdsoplexpovrayOverhead (0% = Vanilla) Use shadowsUse shadows w/ high water markRefreshing shadowsRefreshing shadows plus MAP_PRIVATE if ok    -100%0%100%200%300%400%perlbenchomnetppxalancbmkdealIIOverhead (0% = Vanilla) MAP_SHARED arenasMAP_SHARED with paddingCreate/disable shadows w/ high water markUse shadows w/ high water markRefreshing shadowsRefreshing shadows plus MAP_PRIVATE if okFigure 14: Runtime overhead of SPEC benchmarks. The graphs have different y-axes. Some overheads are based
on results reported in the papers, not re-runs (see legend). ’?’ indicates that FreeSentry did not report results for
libquantum, DangNull did not report results for dealII, omnetpp, or perlbench, and we could not re-run DangSan
on omnetpp or perlbench. FreeSentry and CETS did not report results for any of the benchmarks in the right graph.
this was marginally slower than refreshing shadows and
using MAP PRIVATE where possible.
4.2 Runtime Overhead Comparison
Figure 14 (left) compares the runtime overhead of Os-
car against DangSan, DangNull, FreeSentry, and CETS.
Figure 14 (right) shows the remaining SPEC bench-
marks, for which results were reported by DangSan and
DangNull, but not FreeSentry or CETS.
A caveat is that CETS’ reported overheads are based
on providing temporal protection for both the stack and
heap, which is more comprehensive than Oscar’s heap-
only protection. However, since CETS must, to a ﬁrst
approximation, fully instrument pointer arithmetic and
dereferencing instructions even if only heap protection is
desired, we expect that the overhead of heap-only CETS
would still be substantially higher than Oscar.
All
other
comparisons
(DangSan, DangNull,
FreeSentry) are based on the appropriate reported
overheads for heap-only temporal protection.
Comparison to DangSan. We re-ran the latest pub-
licly available version of DangSan3 on the same hard-
ware as Oscar. DangSan re-run overheads were normal-
ized to a re-run with their “baseline LTO” script. We
were unable to re-run perlbench due to a segmentation
fault, or omnetpp due to excessive memory consump-
tion4. As seen in the graphs, our re-run results are very
similar to DangSan’s reported results; thus, unless other-
wise stated, we will compare Oscar against the latter.
3March 19, 2017, https://github.com/vusec/dangsan/
commit/78006af30db70e42df25b7d44352ec717f6b0802
4We estimate that it would require over 20GB of memory, taking
into account the baseline memory usage on our machine and DangSan’s
reported overhead for omnetpp.
Across the complete set of C/C++ SPEC CPU2006
benchmarks, Oscar and DangSan have the same over-
all overhead, within rounding error (geometric means of
40% and 41%). However, for all four of the allocation-
intensive benchmarks, as well as astar and gcc, the
overheads of both Oscar and DangSan are well above the
10% overhead threshold [39], making it unlikely that ei-
ther technique would be considered acceptable.
If we
exclude those six benchmarks, then Oscar has average
overhead of 2.5% compared to 9.9% for DangSan. Al-
ternatively, we can see that, for ﬁve benchmarks (mcf,
povray, soplex, gobmk, milc), Oscar’s overhead is 6%
or less, whereas DangSan’s is 10% or more. There are
no benchmarks where DangSan has under 10% overhead
but Oscar is 10% or more.5
Comparison to DangNull/FreeSentry. We emailed
the ﬁrst authors of DangNull and FreeSentry to ask for
the source code used in their papers, but did not re-
ceive a response. Our comparisons are therefore based
on the numbers reported in the papers rather than by re-
running their code on our system. Nonetheless, the dif-
ferences are generally large enough to show trends. In
many cases, Oscar has almost zero overhead, implying
there are few mallocs/frees (the source of Oscar’s over-
head); we expect the negligible overhead generalizes to
any system. Oscar does not instrument the application’s
pointer arithmetic/dereferencing, which makes its over-
head fairly insensitive to compiler optimizations. We
also note that DangSan – which we were able to re-run
and compare against Oscar – theoretically should have
better performance than DangNull6.
5Of course, there is a wide continuum of “under 10%”, and those
smaller differences may matter.
6However, DangSan’s empirical comparisons to DangNull and
FreeSentry were also based on reported numbers rather than re-runs.
USENIX Association
26th USENIX Security Symposium    823
? ? 672% ? ? ? 0%50%100%150%200%250%300%350%400%450%Overhead (baseline = 0%) OscarDangSan (reported)DangSan (re-run)DangNull (reported)? 95% 0%10%20%30%40%50%60%70%gobmkh264refhmmerlbmlibquantummilcsphinx3sjengOverhead (baseline = 0%) FreeSentry (reported)CETS (reported)Figure 15: Memory overhead on CPU2006. DangNull
reported a baseline of 0MB for libquantum, so an over-
head ratio is not calculable.
Oscar’s performance
excellent
compared to
is
FreeSentry and DangNull,
even though DangNull
provides less comprehensive protection: DangNull
only protects pointers to heap objects if
the pointer
is itself stored on the heap. Figure 14 (left) compares
all SPEC CPU2006 benchmarks for which DangNull
and FreeSentry both provide data.
FreeSentry has
higher overhead for several benchmarks (milc, gobmk,
hmmer, h264ref) – especially higher for the latter three.
FreeSentry is faster on the remaining three benchmarks,
but in all those cases except for sphinx3, our overhead
is negligible anyway.
DangNull has much higher
overhead than Oscar for gobmk and sphinx3. For other
benchmarks, DangNull often gets zero overhead, though
it is not much lower than Oscar’s, and comes with the
caveat of their weaker protection.
Our comparisons are based on our overall “best”
scheme with all three optimizations. For some bench-
marks, using just the high water mark optimization and
not the other two optimizations would have performed
better. Even the basic shadow pages scheme without op-
timizations would often beat DangNull/FreeSentry.
Figure 14 (right) shows additional SPEC CPU2006
benchmarks for which DangNull reported their overhead
but FreeSentry did not. For the two benchmarks where
DangNull has zero overhead (bzip2, namd), Oscar’s are
also close to zero. For the other six benchmarks, Oscar’s
overhead is markedly lower. Two highlights are soplex
and povray, where DangNull’s overhead is 150%/280%,
while Oscar’s is under 6%.
When considering only the subset of CPU2006 bench-
marks that DangNull reports results for (i.e., excluding
dealII, omnetpp and perlbench), Oscar has a geo-
metric mean runtime overhead of 15.4% compared to
49% for DangNull. For FreeSentry’s subset of reported
benchmarks, Oscar has just 2.8% overhead compared to
Figure 16: Memory overhead on CPU2006 (continued).
’?’ indicates that DangNull did not report memory usage
for dealII, omnetpp, or perlbench, and we could not
re-run DangSan on the latter two.
18% for FreeSentry.
Comparison to CETS. We compare Oscar to the
temporal-only mode of SoftBoundCETS [32] (which we
will also call “CETS” for brevity), since that has lower
overhead and a more comprehensive dataset than the
original CETS paper.
The latest publicly available version of SoftBound-
CETS for LLVM 3.47 implements both temporal and
spatial memory safety. We received some brief advice
from the author of SoftBoundCETS on how to modify
it to run in temporal-only mode, but we were unable to
get it to work beyond simple test programs. Thus, our
comparisons rely on their reported numbers rather than a
re-run.
We have omitted the bzip2 and mcf benchmarks, as