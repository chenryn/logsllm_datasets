# Environment-Sensitive Intrusion Detection

**Authors:**
- Jonathon T. Giffin<sup>1</sup>
- David Dagon<sup>2</sup>
- Somesh Jha<sup>1</sup>
- Wenke Lee<sup>2</sup>
- Barton P. Miller<sup>1</sup>

**Affiliations:**
- <sup>1</sup>Computer Sciences Department, University of Wisconsin
- <sup>2</sup>College of Computing, Georgia Institute of Technology

**Contact:**
- {giffin, jha, bart}@cs.wisc.edu
- {dagon, wenke}@cc.gatech.edu

## Abstract
We enhance host-based intrusion detection by creating a model from a program's binary code and then constraining the program's execution according to this model. Our approach improves the effectiveness of model-based intrusion detection systems by integrating environmental knowledge into the model and enhancing model accuracy through a new context-sensitive data-flow analysis algorithm.

The environment, including configuration files, command-line parameters, and environment variables, dictates acceptable process behavior. By incorporating these environmental dependencies into the program model, we update the model to reflect the current environment at each program execution.

Our novel static data-flow analysis associates a program's data flows with specific calling contexts, enabling us to differentiate system-call arguments originating from distinct call sites within the program.

Using a new average reachability measure, we demonstrate that our techniques improve the precision of several test programs' models from 76% to 100%.

**Keywords:** model-based anomaly detection, Dyck model, static binary analysis, static data-flow analysis.

## 1. Introduction
A host-based intrusion detection system (HIDS) monitors a process's execution to identify potentially malicious behavior. In a model-based anomaly HIDS or behavior-based HIDS, deviations from a precomputed model of expected behavior indicate possible intrusion attempts. The execution monitor verifies a stream of events, often system calls, generated by the executing process and rejects event streams that deviate from the model. The system's ability to detect attacks with minimal false alarms depends entirely on the precision of the model.

Static analysis constructs an execution model by analyzing the source or binary code of the program. Traditional static analysis algorithms are conservative and produce models that overapproximate correct execution. These models allow behaviors possible in any execution environment. However, processes often read the environmentâ€”configuration files, command-line parameters, and environment variables known at process load time and fixed for the entire execution. This environment can significantly constrain a process's execution, disabling entire blocks of functionality and restricting access.

If the process can generate the language of event sequences \( L_e \) given the current environment \( e \), previous program models constructed from static analysis accepted the language \( L_s = \cup_{i \in E} L_i \) for \( E \) the set of all possible environments. \( L_s \) is a superset of \( L_e \) and may contain system call sequences that cannot be generated by correct execution in environment \( e \).

These overly general models may fail to detect attacks. For example, versions of the OpenSSH secure-shell server prior to 3.0.2 had a design error that allowed users to alter the execution of the root-level login process. If the configuration file setting "uselogin" was disabled, the ssh server disabled the vulnerable code. An attacker who has subverted the process can bypass the "uselogin" checks by directly executing the vulnerable code. Previous statically constructed models allowed all paths in the program, including the disabled path. By executing the disabled code, the attacker can undetectably execute root-level commands.

In this paper, we make statically constructed program models sensitive to the execution environment. An environment-sensitive program model restricts process execution behavior to only the behavior correct in the current environment. The model accepts a limited language of event sequences \( L_v \), where \( L_e \subseteq L_v \subseteq L_s \). Event sequences that could not be correctly generated in the current environment are detected as intrusive, even if those sequences are correct in some other environment. In the OpenSSH example, if "uselogin" was disabled, the model disallows system calls and system-call arguments reachable only via the vulnerable code paths. The model detects an entire class of evasion attacks that manipulate environment data, as described in Section 7.4.

Environment dependencies characterize how execution behavior depends on environment values. Similar to def-use relations in static data-flow analysis, an environment dependency relates values in the environment, such as "uselogin," to values of internal program variables. When an environment-sensitive HIDS loads a program model for execution enforcement, it customizes the model to the current environment based on these dependencies. In this paper, we manually identify dependencies. Our long-term goal is to automate this procedure, and in Section 5.3, we postulate that automated identification will not be an onerous task.

Environment sensitivity works best with system-call argument analysis. Our static analyzer includes powerful data-flow analysis to recover statically known system-call arguments. Different execution paths in a program may set a system-call argument differently. Our previous data-flow analysis recovered argument values without calling context, ignoring the association between an argument value and the call site that set that value. In this work, we encode calling context with argument values to better model the correct execution behavior of a program. A system-call argument value observed at runtime must match the calling context leading up to the system call. Additionally, the data-flow analysis now crosses shared object boundaries, enabling static analysis of dynamically-linked executables.

Although environment-sensitive program modeling is the primary focus of our work, we also introduce a new evaluation metric. The existing standard metric measuring model precision, average branching factor, poorly evaluates models that monitor a program's call stack in addition to the system-call stream. We use context-free language reachability to move forward through stack events to discover the next set of actual system calls reachable from the current program location. Our new average reachability measure fairly evaluates the precision of program models that include function call and return events. Using the average reachability measure, we demonstrate the value of whole-program data-flow analysis and environment-sensitive models. On four test programs, we improved the precision of context-sensitive models from 76% to 100%.

In summary, this paper makes the following contributions:
- Static model construction of dynamically-linked executables. The static analyzer continues data-flow analysis across shared-object boundaries by learning the API by which programs call library code, as described in Section 4.1.
- Context-sensitive encoding of recovered system-call arguments, detailed in Section 4.2. Combined with whole-program analysis, this technique improved argument recovery by 61% to 100% in our experiments.
- A formal definition of environment-sensitive program models and methods to encode environment dependencies into statically constructed program models. Environment sensitivity and static system-call argument recovery improved the precision of program models by 76% to 100%. This work is presented in Section 5.
- An extension to the commonly-used average branching factor metric suitable for program models that require update events for function calls and returns (Section 6). The average reachability measure provides a fairer comparison of call-stack-based models and other models that do not monitor the call stack.

## 2. Related Work
In 1994, Fix and Schneider added execution environment information to a programming logic to make program specifications more precise. Their notion of environment was general, including properties such as scheduler behavior. We propose a similar idea: using environment information to more precisely characterize expected program behavior in a program model. As our models describe safety properties that must not be violated, we focus on environment aspects that can constrain these safety properties.

Chinchani et al. instrumented C source-code with security checks based on environment information. Their definition of environment primarily encompassed low-level properties of the physical machine on which a process executes. For example, knowing the number of bits per integer allowed the authors to insert code into a program to prevent integer overflows. This approach is specific to known exploit vectors and requires source-code editing, making it poorly suited for our environment-sensitive intrusion detection.

One aspect of our current work uses environment dependencies and static analysis to limit allowed values to system-call arguments. This specific problem has received prior attention. Static analysis can identify constant, statically known arguments. While extracting execution models from C source code, Wagner and Dean identified arguments known statically. In earlier work, we used binary code analysis to recover arguments in SPARC executables. These efforts suffered from several problems:
- Earlier binary data-flow analysis required statically-linked executables. In this paper, we use data-flow analysis to learn the API for a shared object. When analyzing an executable, we continue data-flow analysis anywhere the library API is used.
- Values recovered were not sensitive to calling context. This forces two inaccuracies. First, the association between a system-call argument value and the execution path using that value is lost (Fig. 1A). An attacker could undetectably use a value recovered on one execution path on any other execution path to the same system call. Second, if any execution path set an argument in a way not recoverable statically, all values recovered along all other execution paths must be discarded for the analysis to be safe (Fig. 1B). Our current work avoids these two inaccuracies by encoding calling context with recovered values.
- Static analysis cannot recover values set dynamically. In this paper, we make a distinction between dynamic values set at load time and values set by arbitrary user input. Environment dependencies augment static analysis and describe how values set when the operating system loads a process flow to system-call arguments.

Dynamic analysis learns a program model by generalizing behavior observed during a training phase. Kruegel et al. and Sekar et al. used dynamic analysis to learn constraints for system-call arguments. These constraints will include values from the environment that are used as part of a system-call argument, which forces a tradeoff. The training phase could modify environment values to learn a general model, but such a model fails to constrain later execution to the specific environment. Conversely, training could use only the current environment. If the environment ever changes, the model no longer characterizes correct execution and retraining becomes necessary. By including environment dependencies described in this paper, learning could be done only for arguments not dependent upon the environment. Environment dependencies would resolve the remaining arguments to the current environment every time the model was subsequently loaded.

Environment-sensitive models are well suited to the model-carrying code execution design. Sekar et al. proposed that unknown, untrusted executables can include models of their execution. A consumer of the executable can use a model checker to verify that the model does not violate their security policy and an execution monitor to limit the programâ€™s execution to that allowed by the model. The code producer must build the program model, but they cannot know any consumerâ€™s specific execution environment. To avoid false alarms, the model must be general to suit all possible environments. Such a general model may not satisfy a consumerâ€™s security policy. If the code producer adds environment dependencies to the model shipped with the code, the model will automatically adapt to every consumerâ€™s unique environment. With the environment constraints, the model is increasingly likely to satisfy a consumerâ€™s security policy.

## 3. Overview
Model-based anomaly detection has two phases: construction of the program model and execution enforcement using the model. Environment sensitivity affects both phases. Figure 2 shows the overall architecture of our system, including how environment information is used in each phase. Analysis, on the left, occurs once per program or shared object. The global model builder assembles all execution models into the single, whole-program model. The panel on the right, execution monitoring, occurs every time the program is loaded for execution.

The static analyzer builds a model of expected execution by reconstructing and analyzing control flows in a binary executable. The control flow model we construct is the Dyck model, a context-sensitive model that uses a finite-state machine to enforce ordering upon system-call events as well as correct function call and return behavior. The static analyzer encodes environment dependencies into the Dyck model.

![Architecture](architecture.png)

**Figure 2. Architecture**

## Code Example
```c
void parse_args(int argc, char **argv) {
    char *tn = tempnam(getenv("TMP"), "Mx");
    int execmode = 1;
    char c;

    unlink("/home/user/tmpfile");

    while ((c = getopt(argc, argv, "L:")) != -1) {
        switch (c) {
            case 'L':
                execmode = 0;
                unlink(tn);
                link(optarg, tn);
                break;
        }
    }
}
```

This code snippet demonstrates a simple function `parse_args` that reads environment variables and command-line arguments, and performs actions based on the provided options. The function creates a temporary file name, sets an execution mode, and processes command-line options. If the option `-L` is provided, it changes the execution mode, unlinks a temporary file, and links another file to the temporary file. This example illustrates the kind of environment-dependent behavior that our system aims to model and monitor.