title:Environment-Sensitive Intrusion Detection
author:Jonathon T. Giffin and
David Dagon and
Somesh Jha and
Wenke Lee and
Barton P. Miller
Environment-Sensitive Intrusion Detection
Jonathon T. Gifﬁn1, David Dagon2, Somesh Jha1, Wenke Lee2, and Barton P. Miller1
1 Computer Sciences Department, University of Wisconsin
2 College of Computing, Georgia Institute of Technology
{giffin, jha, bart}@cs.wisc.edu
{dagon, wenke}@cc.gatech.edu
Abstract. We perform host-based intrusion detection by constructing a model
from a program’s binary code and then restricting the program’s execution by
the model. We improve the effectiveness of such model-based intrusion detection
systems by incorporating into the model knowledge of the environment in which
the program runs, and by increasing the accuracy of our models with a new data-
ﬂow analysis algorithm for context-sensitive recovery of static data.
The environment—conﬁguration ﬁles, command-line parameters, and
environment variables—constrains acceptable process execution. Environment
dependencies added to a program model update the model to the current envi-
ronment at every program execution.
Our new static data-ﬂow analysis associates a program’s data ﬂows with
speciﬁc calling contexts that use the data. We use this analysis to differentiate
system-call arguments ﬂowing from distinct call sites in the program.
Using a new average reachability measure suitable for evaluation of call-stack-
based program models, we demonstrate that our techniques improve the precision
of several test programs’ models from 76% to 100%.
Keywords: model-based anomaly detection, Dyck model, static binary analysis,
static data-ﬂow analysis.
1 Introduction
A host-based intrusion detection system (HIDS) monitors a process’ execution to iden-
tify potentially malicious behavior. In a model-based anomaly HIDS or behavior-based
HIDS [3], deviations from a precomputed model of expected behavior indicate possible
intrusion attempts. An execution monitor veriﬁes a stream of events, often system calls,
generated by the executing process. The monitor rejects event streams deviating from
the model. The ability of the system to detect attacks with few or zero false alarms relies
entirely upon the precision of the model.
Static analysis builds an execution model by analyzing the source or binary code
of the program [5, 20, 10, 14]. Traditionally, static analysis algorithms are conservative
and produce models that overapproximate correct execution. In particular, previous sta-
tically constructed models allowed execution behaviors possible in any execution en-
vironment. Processes often read the environment—conﬁguration ﬁles, command-line
parameters, and environment variables known at process load time and ﬁxed for the
entire execution of the process. The environment can signiﬁcantly constrain a process’
A. Valdes and D. Zamboni (Eds.): RAID 2005, LNCS 3858, pp. 185–206, 2006.
c(cid:1) Springer-Verlag Berlin Heidelberg 2006
186
J.T. Gifﬁn et al.
execution, disabling entire blocks of functionality and restricting the process’ access.
If the process can generate the language of event sequences Le given the current en-
vironment e, then previous program models constructed from static analysis accepted
the language Ls = ∪i∈ELi for E the set of all possible environments. Ls is a super-
set of Le and may contain system call sequences that cannot be generated by correct
execution in environment e.
These overly general models may fail to detect attacks. For example, versions of
the OpenSSH secure-shell server prior to 3.0.2 had a design error that allowed users to
alter the execution of the root-level login process [19]. If the conﬁguration ﬁle setting
“uselogin” was disabled, then the ssh server disabled the vulnerable code. However, an
attacker who has subverted the process can bypass the “uselogin” checks by directly
executing the vulnerable code. Previous statically constructed models allowed all paths
in the program, including the disabled path. By executing the disabled code, the attacker
can undetectably execute root-level commands.
In this paper, we make statically constructed program models sensitive to the execu-
tion environment. An environment-sensitive program model restricts process execution
behavior to only the behavior correct in the current environment. The model accepts a
limited language of event sequences Lv, where Le ⊆ Lv ⊆ Ls. Event sequences that
could not be correctly generated in the current environment are detected as intrusive,
even if those sequences are correct in some other environment. In the OpenSSH exam-
ple, if “uselogin” was disabled, then the model disallows system calls and system-call
arguments reachable only via the vulnerable code paths. The model detects an entire
class of evasion attacks that manipulate environment data, as described in Sect. 7.4.
Environment dependencies characterize how execution behavior depends upon en-
vironment values. Similar to def-use relations in static data-ﬂow analysis [15], an en-
vironment dependency relates values in the environment, such as “uselogin”, to values
of internal program variables. When an environment-sensitive HIDS loads a program
model for execution enforcement, it customizes the model to the current environment
based upon these dependencies. In this paper, we manually identify dependencies. Our
long-term goal is to automate this procedure, and in Sect. 5.3 we postulate that auto-
mated identiﬁcation will not be an onerous task.
Environment sensitivity works best with system-call argument analysis. Our static
analyzer includes powerful data-ﬂow analysis to recover statically known system-call
arguments. Different execution paths in a program may set a system-call argument dif-
ferently. Our previous data-ﬂow analysis recovered argument values without calling
context, in that the analysis algorithm ignored the association between an argument
value and the call site that set that value [9,10]. In this work, we encode calling context
with argument values to better model the correct execution behavior of a program. A
system-call argument value observed at runtime must match the calling context leading
up to the system call. Additionally, the data-ﬂow analysis now crosses shared object
boundaries, enabling static analysis of dynamically-linked executables.
Although environment-sensitive program modeling is the primary focus of our work,
we make an additional contribution: a new evaluation metric. The existing standard
metric measuring model precision, average branching factor, poorly evaluates models
that monitor a program’s call stack in addition to the system-call stream [5, 8]. We
Environment-Sensitive Intrusion Detection
187
instead use context-free language reachability to move forward through stack events to
discover the next set of actual system calls reachable from the current program location.
Our new average reachability measure fairly evaluates the precision of program models
that include function call and return events. Using the average reachability measure, we
demonstrate the value of whole-program data-ﬂow analysis and environment-sensitive
models. On four test programs, we improved the precision of context-sensitive models
from 76% to 100%.
In summary, we believe that this paper makes the following contributions:
– Static model construction of dynamically-linked executables. In particular, the sta-
tic analyzer continues data-ﬂow analysis across shared-object boundaries by learn-
ing the API by which programs call library code, as described in Sect. 4.1.
– Context-sensitive encoding of recovered system-call arguments, detailed in Sect. 4.2.
Combined with whole-program analysis, this technique improved argument recov-
ery by 61% to 100% in our experiments.
– A formal deﬁnition of environment-sensitive program models and methods to en-
code environment dependencies into statically constructed program models. Envi-
ronment sensitivity and static system-call argument recovery improved the preci-
sion of program models by 76% to 100%. Section 5 presents this work.
– An extension to the commonly-used average branching factor metric suitable for
program models that require update events for function calls and returns (Sect. 6).
The average reachability measure provides a fairer comparison of call-stack-based
models and other models that do not monitor the call stack.
2 Related Work
In 1994, Fix and Schneider added execution environment information to a programming
logic to make program speciﬁcations more precise [7]. The logic better speciﬁed how
a program would execute, allowing for more precise analysis of the program in a proof
system. Their notion of environment was general, including properties such as sched-
uler behavior. We are proposing a similar idea: use environment information to more
precisely characterize expected program behavior in a program model. As our models
describe safety properties that must not be violated, we focus on environment aspects
that can constrain the safety properties.
Chinchani et al. instrumented C source-code with security checks based upon envi-
ronment information [1]. Their deﬁnition of environment primarily encompassed low-
level properties of the physical machine on which a process executes. For example,
knowing the number of bits per integer allowed the authors to insert code into a pro-
gram to prevent integer overﬂows. This approach is speciﬁc to known exploit vectors
and requires source-code editing, making it poorly suited for our environment-sensitive
intrusion detection.
One aspect of our current work uses environment dependencies and static analysis to
limit allowed values to system-call arguments. This speciﬁc problem has received prior
attention.
Static analysis can identify constant, statically known arguments. While extracting
execution models from C source code, Wagner and Dean identiﬁed arguments known
188
J.T. Gifﬁn et al.
callsite 1
unlink
call
callsite 2
call unlink
arg ∈ {“/home/user/testﬁle”}
arg ∈ {“/tmp/Mx.*”}
callsite 1
unlink
call
callsite 2
unlink
call
arg ∈ {“/home/user/testﬁle”}
arg is unknown
libc:
unlink
entry
arg ∈ {“/home/user/testﬁle”,
“/tmp/Mx.*”}
unlink
kernel trap
(A)
libc:
unlink
entry
arg is unknown
unlink
kernel trap
(B)
Fig. 1. Prior static argument recovery. Argument values recovered along different execution paths
join together when the execution paths converge. (A) The association between a speciﬁc argument
value and an execution path is lost. (B) If an argument value cannot be statically recovered on
any execution path leading to a system call, all other recovered values must be discarded. The
argument is completely unconstrained.
statically [20]. In earlier work, we used binary code analysis to recover arguments in
SPARC executables [9, 10]. These efforts suffered from several problems:
– Earlier binary data-ﬂow analysis required statically-linked executables. In this pa-
per, we use data-ﬂow analysis to learn the API for a shared object. When analyzing
an executable, we continue data-ﬂow analysis anywhere the library API is used.
– Values recovered were not sensitive to calling context. This forces two inaccura-
cies. First, the association between a system-call argument value and the execution
path using that value is lost (Fig. 1A). An attacker could undetectably use a value
recovered on one execution path on any other execution path to the same system
call. Second, if any execution path set an argument in a way not recoverable stati-
cally, all values recovered along all other execution paths must be discarded for the
analysis to be safe (Fig. 1B). Our current work avoids these two inaccuracies by
encoding calling context with recovered values.
– Static analysis cannot recover values set dynamically. In this paper, we make a
distinction between dynamic values set at load time and values set by arbitrary user
input. Environment dependencies augment static analysis and describe how values
set when the operating system loads a process ﬂow to system-call arguments.
Dynamic analysis learns a program model by generalizing behavior observed during
a training phase. Kruegel et al. [13] and Sekar et al. [16] used dynamic analysis to learn
constraints for system-call arguments. These constraints will include values from the
environment that are used as part of a system-call argument, which forces a tradeoff.
The training phase could modify environment values to learn a general model, but such a
model fails to constrain later execution to the speciﬁc environment. Conversely, training
could use only the current environment. If the environment ever changes, however, then
the model no longer characterizes correct execution and retraining becomes necessary.
By including environment dependencies described in this paper, learning could be done
only for arguments not dependent upon the environment. Environment dependencies
Environment-Sensitive Intrusion Detection
189
would resolve the remaining arguments to the current environment every time the model
was subsequently loaded.
Environment-sensitive models are well suited to the model-carrying code execution
design. Sekar et al. proposed that unknown, untrusted executables can include models
of their execution [16]. A consumer of the executable can use a model checker to verify
that the model does not violate their security policy and an execution monitor to limit
the program’s execution to that allowed by the model. The code producer must build the
program model, but they cannot know any consumer’s speciﬁc execution environment.
To avoid false alarms, the model must be general to suit all possible environments. Such
a general model may not satisfy a consumer’s security policy. If the code producer
adds environment dependencies to the model shipped with the code, the model will
automatically adapt to every consumer’s unique environment. With the environment
constraints, the model is increasingly likely to satisfy a consumer’s security policy.
3 Overview
Model-based anomaly detection has two phases: construction of the program model and
execution enforcement using the model. Environment sensitivity affects both phases.
Figure 2 shows the overall architecture of our system, including how environment in-
formation is used in each phase. Analysis, at the left, occurs once per program or shared
object. The global model builder assembles all execution models into the single, whole-
program model. The panel on the right, execution monitoring, occurs every time the
program is loaded for execution.
The static analyzer builds a model of expected execution by reconstructing and an-
alyzing control ﬂows in a binary executable. The control ﬂow model that we construct
is the Dyck model, a context-sensitive model that uses a ﬁnite-state machine to enforce
ordering upon system-call events as well as correct function call and return behav-
ior [10]. The static analyzer encodes environment dependencies into the Dyck model.
Environment−Sensitive
Monitoring
Program
Execution
Environment
System Call
Sequence
Execution
Monitor
Accept or
Reject
Execution
Executable Analysis
Model Assembly
Binary
Program
Environment
Dependencies
Static Binary
Analyzer
Models &
Data−Flow
Summaries
Shared Object Analysis
Shared Object
Environment
Dependencies
System Call
Specification
Static Binary
Analyzer
Models &
Data−Flow
Summaries
Global
Model
Builder
Environment−Sensitive
Program Model
...
Shared Object Analysis
Shared Object
Environment
Dependencies
System Call
Specification
Static Binary
Analyzer
Models &
Data−Flow
Summaries
Fig. 2. Architecture
190
J.T. Gifﬁn et al.
void parse args(int argc, char **argv) {
char *tn = tempnam(getenv("TMP"), "Mx");
int execmode = 1;
char c;
unlink("/home/user/tmpfile");
while ((c = getopt(argc, argv, "L:")) != -1)
switch (c) {
case ’L’:
execmode = 0;
unlink(tn);
link(optarg, tn);
break;