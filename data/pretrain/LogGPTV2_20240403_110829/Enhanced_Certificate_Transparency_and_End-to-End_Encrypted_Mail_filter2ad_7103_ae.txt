5.1 Summary
We have extended certiﬁcate transparency to handle re-
vocation efﬁciently, resulting in a system we call certiﬁcate
11
New device
Old device
(pw)x
Server
(pw)x
enc((pw)xy, k), (pw)y
enc((pw)xy, k), (pw)y
Fig. 10. Protocol to allow migration of the encryption key k from one device to another, based on SPEKE [48]. The user creates a request on her new device
(pw0)x based on a randomly chosen x; here we assume pw0 is a representation of a human-memorable password in a suitable Schnorr group. (pw0 should
not be the same password as pw in the main protocol, because the server should have no knowledge of pw0.) Next, the user’s application on her old device
retrieves the request from the server, checks it is within a suitable range, and creates an encryption key ((pw0)x)y by selecting another random y. The key k is
encrypted with (pw0)xy and sent to the server along with (pw0)y. Then the user returns to the new device, which retrieves that information, checks its range,
decrypts k, and installs it on the device.
issuance and revocation transparency. This contributes to its
usefulness on the web. We apply this certiﬁcated transparency
to email, allowing an email provider to certify keys for its
users without requiring them to trust it. This yields a system
for email which is secure (mail is end-to-end encrypted and
there are no third parties required to be trusted), and also
appears to be usable (there should be no confusing warn-
ing messages about keys and certiﬁcates). In contrast with
S/MIME, PGP, IBE and certiﬁcateless encryption, the CA (or
identity provider) is prevented from launching attacks on its
users.
5.2 Discussion: cloud
Underlying these ideas is an attacker model appropriate
for cloud computing. In most cloud-based applications today,
users are required to fully trust the cloud provider. “Fully
trusted” is unacceptably optimistic; researchers are attempting
to change that, for example with fully homomorphic encryp-
tion, so that, on the contrary, the cloud provider could be
considered fully malicious. But that is unduly pessimistic.
Cloud providers are large organisations with reputations to
preserve, and they compete to attract customers. Therefore,
they will not attack their users at any cost; they will not
launch attacks that leave veriﬁable evidence. Thus, they are
in reality somewhere between the extremes of “malicious”
and “trustworthy” (Figure 9). “Honest-but-curious” already lies
between these extremes; it says that the attacker launches
passive attacks but not active ones. However, there is no reason
to suppose a cloud provider will refrain from active attacks. We
adopt the term “malicious-but-cautious”; the cloud provider is
assumed to be malicious if he can get away with it, but cautious
in not leaving any veriﬁable evidence of its misbehaviour. This
attacker model is related to the covert adversary of [49], but
it additionally assumes that the cloud provider acts to protect
its users from third-party attacks. The malicious-but-cautious
attacker model is already implicitly used, e.g., in electronic
voting. An election manager typically can cheat, but doing so
would be detected by tests that voters use to detect election
integrity [50], [51] or voter coercion [52].
Systems based on this model (such as the email system
we detailed) deny the possibility of monetising users’ data,
e.g. for content-related advertising, as pioneered by Google
and now done by other providers. One might ask whether
providers would be willing to go on providing hosting services
for free, without this revenue opportunity. That question is
beyond the scope of the paper, but nevertheless we can’t resist
speculating about it. The most successful internet companies
today offered services long before they had any idea how they
could be monetised, so we don’t expect that to be an obstacle in
practice. Moreover, user applications may be willing to leak
some data to the provider, such as the fact that a particular
message mentions “hotel” and “Paris”, allowing the provider
to serve adverts for hotels in Paris without having the whole
plaintext message. Finally, we expect that when users fully
realise the consequences of paying for services with their data,
they will prefer to pay modest amounts of money and keep
their data private.
A more serious obstacle to take-up of such an email system
may appear to be spam. If mail is decrypted by the receiver,
it prevents the server from deleting messages after applying
spam detection. This requires spam handling on the client side,
which is less convenient than handling it on the server. Spam
can also be mitigated if users conﬁgure their mail browsers
not to accept encrypted mail unless it is also signed by users
they are already in contact with.
5.3 Future work
In future work, we intend to perform rigorous security anal-
ysis of certiﬁcate issuance and transparency, in the malicious-
but-cautious model. That involves deﬁning the model formally.
We will also analyse the email protocol in that model.
12
Acknowledgments
I am grateful to Joshua Phillips, Jiangshan Yu, and Vincent
Cheval for interesting discussions.
References
[1] A. K. Lenstra,
J. W.
Bos, T. Kleinjung, and C. Wachter, “Public keys,” in
CRYPTO’12, 2012, pp. 626–642.
J. P. Hughes, M. Augier,
[2] N. J. AlFardan and K. G. Paterson, “Lucky thirteen:
Breaking the TLS and DTLS record protocols,” IEEE
Symposium on Security and Privacy, 2013.
[3] N. J. AlFardan, D. J. Bernstein, K. G. Paterson, B. Po-
ettering, and J. C. Schuldt, “On the security of RC4 in
TLS and WPA,” 2013.
[4] P. Eckersley, “Iranian hackers obtain fraudulent HTTPS
certiﬁcates: How close to a web security meltdown
did we get?” Electronic Frontier Foundation, 2011.
[Online]. Available: https://www.eff.org/deeplinks/2011/
03/iranian-hackers-obtain-fraudulent-https
[5] J. Leyden, “Trustwave admits crafting SSL snooping
to spy on staff was
certiﬁcate: Allowing bosses
wrong,
2012.
[Online]. Available: www.theregister.co.uk/2012/02/09/
tustwave disavows mitm digital cert
biz,” The Register,
security
says
[6] “MS01-017: Erroneous verisign-issued digital certiﬁcates
[Online].
pose spooﬁng hazard,” Microsoft support.
Available: http://support.microsoft.com/kb/293818
[7] P. Roberts, “Phony SSL certiﬁcates issued for Google,
Yahoo, Skype, others,” Threat Post, March 2011,
threatpost.com/phony-ssl-certiﬁcates-issued-google-
yahoo-skype-others-032311.
[8] T.
ﬁrm warns
“Second
hack,” Yahoo! News,
Sterling,
dutch
[Online]. Available:
concern
September
after
2011.
http://news.yahoo.com/
second-ﬁrm-warns-concern-dutch-hack-215940770.html
[9] N. Falliere, L. O. Murchu, , and E. Chien, “W32.stuxnet
of
dossier. technical report, symantec corporation,” 2011.
[10] J. Appelbaum, “Detecting certiﬁcate authority compro-
mises and web browser collusion,” Tor Blog, 2011.
[11] “Black tulip report of the investigation into the diginotar
certiﬁcate authority breach,” Fox-IT (Tech. Report), 2012.
[12] C. Arthur, “Rogue web certiﬁcate could have been used
to attack iran dissidents,” The Guardian, 2011.
[13] J. Clark
van Oorschot,
challenges
and
HTTPS:revisiting
certiﬁcate
enhancements,”
Symposium on Security and Privacy, 2013.
and P. C.
past
trust model
“SSL and
evaluating
in
IEEE
[14] A. Langley, “Public-key pinning,” ImperialViolet (blog),
2011.
[15] M. Marlinspike and T. Perrin, “Trust assertions for cer-
tiﬁcate keys (TACK),” Internet draft, 2012.
13
[16] D. Wendlandt, D. G. Andersen, and A. Perrig, “Per-
spectives: improving SSH-style host authentication with
multi-path probing,” in USENIX Annual Technical Con-
ference, 2008, pp. 321–334.
[17] P. Eckersley and J. Burns, “Is the SSLiverse a safe
place?” Chaos Communication Congress, 2010.
[18] M. Alicherry and A. D. Keromytis, “Doublecheck: Multi-
path veriﬁcation against man-in-the-middle attacks,” in
ISCC, 2009, pp. 557–563.
[19] B. Amann, M. Vallentin, S. Hall, and R. Sommer, “Re-
visiting SSL: A large-scale study of the internet’s most
trusted protocol,” Technical report, ICSI, 2012.
[20] B. Laurie, E. Kasper, and A. Langley, “Certiﬁcate trans-
parency,” Internet Draft 09, March 2013.
[21] R. L. Rivest, “Can we eliminate certiﬁcate revocation
lists?” in Financial Cryptography. Springer, 1998, pp.
178–183.
[22] A. Langley, “Revocation checking and Chrome’s CRL,”
ImperialViolet (blog), 2012.
[23] B. Laurie and E. Kasper, “Revocation transparency,”
Google Research, September 2012. [Online]. Available:
www.links.org/ﬁles/RevocationTransparency.pdf
[24] A. Whitten and J. D. Tygar, “Why johnny cant encrypt:
A usability evaluation of pgp 5.0,” in Proceedings of the
8th USENIX Security Symposium, vol. 99. McGraw-Hill,
1999.
[25] Certiﬁcate
transparency.
certiﬁcate-transparency.org
[Online]. Available: www.
[26] B. Laurie, A. Langley, and E. Kasper, “Certiﬁcate Trans-
parency,” RFC 6962 (Experimental), Internet Engineering
Task Force, 2013.
[27] T. Dierks and E. Rescorla, “The transport layer security
(TLS) protocol version 1.2,” RFC 5246 (Proposed
Standard), Internet Engineering Task Force, Aug. 2008,
updated by RFCs 5746, 5878, 6176. [Online]. Available:
http://www.ietf.org/rfc/rfc5246.txt
[28] S. Turner and T. Polk, “Prohibiting secure sockets layer
(SSL) version 2.0,” RFC 6176 (Proposed Standard),
Internet Engineering Task Force, Mar. 2011. [Online].
Available: http://www.ietf.org/rfc/rfc6176.txt
[29] D. Cooper, S. Santesson, S. Farrell, S. Boeyen,
R. Housley, and W. Polk, “Internet X.509 Public
Key Infrastructure Certiﬁcate and Certiﬁcate Revocation
List (CRL) Proﬁle,” RFC 5280 (Proposed Standard),
Internet Engineering Task Force, May 2008, updated by
RFC 6818. [Online]. Available: http://www.ietf.org/rfc/
rfc5280.txt
[30] M. Jelasity, S. Voulgaris, R. Guerraoui, A.-M. Kermarrec,
and M. Van Steen, “Gossip-based peer sampling,” ACM
Transactions on Computer Systems (TOCS), vol. 25,
no. 3, p. 8, 2007.
[31] “The EFF SSL Observatory,” www.eff.org/observatory.
[32] “Certiﬁcate patrol,” http://patrol.psyced.org.
[50] S. Kremer, M. Ryan, and B. Smyth, “Election veriﬁability
in electronic voting protocols,” in ESORICS, 2010, pp.
389–404.
[51] S. Bursuc, G. S. Grewal, and M. D. Ryan, “Trivitas:
Voters directly verifying votes,” in VOTE-ID, 2011, pp.
190–207.
[52] G. S. Grewal, M. D. Ryan, S. Bursuc, and P. Y. A.
Ryan, “Caveat coercitor: Coercion-evidence in electronic
voting,” in IEEE Symposium on Security and Privacy,
2013, pp. 367–381.
[33] D. Wendlandt, D. G. Andersen, and A. Perrig, “Per-
spectives: improving SSH-style host authentication with
multi-path probing,” in USENIX Annual Technical Con-
ference, 2008, pp. 321–334.
[34] M. Alicherry and A. D. Keromytis, “Doublecheck: Multi-
path veriﬁcation against man-in-the-middle attacks,” in
ISCC, 2009, pp. 557–563.
[35] C. Soghoian and S. Stamm, “Certiﬁed lies: Detecting and
defeating government interception attacks against SSL,”
in Financial Cryptography, 2011, pp. 250–259.
[36] M. Marlinspike, “SSL and the future of authenticity,” in
Black Hat, USA, 2011.
[37] M. Marlinspike and T. Perrin, “Internet-draft: Trust as-
sertions for certiﬁcate keys (TACK),” 2012.
[38] P. Hoffman and J. Schlyter, “The DNS-Based Authen-
tication of Named Entities (DANE) Transport Layer
Security (TLS) Protocol: TLSA,” RFC 6698 (Proposed
Standard), Internet Engineering Task Force, Aug. 2012.
[Online]. Available: http://www.ietf.org/rfc/rfc6698.txt
[39] J. Kasten, E. Wustrow, and J. A. Halderman, “CAge:
Taming certiﬁcate authorities by inferring restricted
scopes,” in Financial Cryptography, 2013.
[40] P. Eckersley, “Internet-draft: Sovereign key cryptography
for internet domains,” 2012.
[41] T. H.-J. Kim, L.-S. Huang, A. Perrig, C. Jackson, and
V. Gligor, “Accountable key infrastructure (AKI): A
proposal for a public-key validation infrastructure,” in
22nd International World Wide Web Conference, 2013.
[42] A. Shamir, “Identity-based cryptosystems and signature
schemes,” in CRYPTO, 1984, pp. 47–53.
[43] D. Boneh and M. K. Franklin, “Identity-based encryption
from the weil pairing,” in CRYPTO, 2001, pp. 213–229.
[44] S. S. Al-Riyami and K. G. Paterson, “Certiﬁcateless
public key cryptography,” in ASIACRYPT, 2003, pp. 452–
473.
[45] S. Ruoti, N. Kim, B. Burgon, T. W. van der Horst,
and K. E. Seamons, “Confused Johnny: when automatic
encryption leads to confusion and mistakes,” in SOUPS,
L. Bauer, K. Beznosov, and L. F. Cranor, Eds. ACM,
2013, p. 5.
[46] “Wuala, an encrypted cloud-based store in which users’
encryption keys are not disclosed to the cloud provider.”
[Online]. Available: http://www.wuala.com
[47] M. Arapinis, S. Bursuc, and M. Ryan, “Privacy sup-
porting cloud computing: Conﬁchair, a case study,” in
Principles of Security and Trust.
Springer, 2012, pp.
89–108.
[48] D. P. Jablon, “Extended password key exchange protocols
immune to dictionary attack,” in Proceedings Sixth IEEE
Workshop on Enabling Technologies: Infrastructure for
Collaborative Enterprises, 1997, pp. 248–255.
[49] Y. Aumann and Y. Lindell, “Security against covert
adversaries: Efﬁcient protocols for realistic adversaries,”
in Theory of Cryptography.
Springer, 2007, pp. 137–
156.
14