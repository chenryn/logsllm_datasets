## 事务

Kafka中的事务概念与数据库提供的事务类似。在数据库领域，事务的安全性保障遵循ACID原则，即原子性（Atomicity）、一致性 (Consistency)、隔离性 (Isolation) 和持久性 (Durability)。然而，在实际应用中，不同数据库对ACID特性的实现方式各异，尤其是关于隔离性的理解存在较大差异。通常而言，**隔离性确保并发执行的事务相互独立，互不影响**。经典的数据库教科书将隔离性定义为可串行化(serializability)，意味着每个事务都假设自己是系统中唯一的活跃事务。

当讨论到隔离级别时，这种歧义变得更加明显。例如，一些数据库支持快照隔离级别(Snapshot Isolation)，而其他数据库则称之为可重复读(Repeatable Read)。幸运的是，对于已提交读(Read Committed)隔离级别的定义，大多数主流数据库保持一致。这一级别保证了读取操作只能访问已提交的数据，从而避免脏读现象；同时写入操作也仅能覆盖已经提交的信息，防止脏写问题的发生。

自0.11版本起，Kafka引入了对事务的支持，主要基于read committed隔离级别。它确保了多条消息能够以原子方式写入目标分区，并且消费者只能接收到那些成功完成事务的消息。接下来，我们将探讨Kafka中的事务型生产者(Transactional Producer)。

## 事务型Producer

事务型Producer能够在多个分区之间以原子方式发送消息，这意味着要么所有消息都被成功写入，要么全部失败。此外，即使发生进程重启，Kafka仍能保证这些消息被精确处理一次。要设置事务型Producer，需满足以下两个条件：

- 启用幂等性功能：`enable.idempotence = true`
- 设置Producer端参数 `transactional.id`，建议使用有意义的标识符

在代码层面，需要调用特定的事务API，如`initTransactions()`、`beginTransaction()`、`commitTransaction()`和`abortTransaction()`，分别对应事务初始化、开始、提交及回滚操作。下面是一段示例代码：

```java
producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(record1);
    producer.send(record2);
    producer.commitTransaction();
} catch (KafkaException e) {
    producer.abortTransaction();
}
```

这段代码确保了Record1和Record2作为单个事务统一提交给Kafka，要么全部成功，要么全部失败。值得注意的是，即使事务失败，Kafka也会将消息记录到底层日志中，因此消费者依然可以读取到这些信息。因此，在消费者端，针对事务型Producer发送的消息也需要进行相应调整，通过设置`isolation.level`参数来控制可见性。当前该参数有两个有效值：

1. `read_uncommitted`（默认）: 消费者能够看到所有由Kafka写入的消息，无论事务是否成功提交。
2. `read_committed`: 只显示事务型Producer成功提交的消息，同时也包括非事务型Producer的所有输出。

## 小结

简而言之，幂等性Producer与事务型Producer都是Kafka社区为了实现精确一次处理语义所开发的工具，但它们的作用范围有所不同。前者仅限于单一分区内的单一会话；后者则跨越多个分区甚至会话提供更强的一致性保证。从交付语义的角度来看，事务型Producer显然提供了更全面的支持。然而，请记住性能总是有代价的。相比幂等性Producer，事务型Producer的执行效率较低，在实际部署时应仔细评估其开销，不应盲目启用。

## 开放讨论

你对事务的理解是什么？通过今天的分享，你能想到未来可能在你们公司实际业务中应用事务型Producer的具体场景吗？欢迎留下你的想法和答案，让我们一起探讨。如果你觉得本文对你有所帮助，不妨将其分享给更多的人。

![](https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg)

# 消费者组概述

消费者组(Consumer Group)是Kafka的一项重要设计，旨在提供一种既可扩展又具备容错能力的消费机制。一个消费者组内可以包含多个消费者实例，共享同一个Group ID。组内成员协作消费订阅主题下的所有分区，但每个分区只能分配给组内的某一个特定实例。理解消费者组的关键在于以下几点：

1. 组内可以有一个或多个消费者实例，这些实例可以是单独的进程或同一进程中的线程。
2. Group ID是一个字符串，用于唯一标识集群中的某个消费者组。
3. 消费者组下所有实例订阅的主题分区，只能被组内的某个指定实例消费。

传统上，消息引擎有两种模型：点对点模型和发布/订阅模型。前者通常被称为消费队列，其中消息被消费后即从队列中移除，且只能被一个下游消费者接收。这种模型缺乏良好的伸缩性。相比之下，发布/订阅模型允许消息被多个订阅者消费，但要求每个订阅者必须全量订阅主题的所有分区，这同样限制了系统的灵活性和性能。

幸运的是，Kafka的消费者组巧妙地结合了这两种模型的优点，同时避免了各自的缺点。当一个消费者组订阅了多个主题时，组内的每个实例不必订阅所有分区，而是只负责部分分区的消息消费。不同的消费者组之间互相独立，不会互相干扰。加之Kafka Broker端的消息保留策略，使得整个系统具有极佳的伸缩性。可以说，**Kafka仅依靠消费者组这一机制就实现了传统消息引擎系统中的两种模型**：如果所有实例属于同一组，则相当于实现了消息队列模型；若各实例分属不同的组，则形成了发布/订阅模型。

理想情况下，消费者实例的数量应当等于该组订阅主题的总分区数。例如，若一个消费者组订阅了三个主题A、B、C，各自拥有1、2、3个分区，则配置6个消费者实例最为合适。当然，也可以选择少于或多于这个数量的实例，但这可能会导致资源浪费或者负载不均的问题。

## 消费者组位移管理

消费者在消费过程中需要记录自己的位置信息，即所谓的位移(Offset)。对于消费者组而言，这是一个键值对集合，其中键代表分区，值表示该分区最后一次被消费的位置。在旧版Kafka中，位移数据存储在ZooKeeper中，但在新版中改为了内部主题`__consumer_offsets`。虽然这种方法提高了Broker端的状态管理负担，但也解决了之前因频繁更新导致ZooKeeper性能下降的问题。

## Rebalance过程

Rebalance是一种协议，规定了如何在消费者组内分配主题分区。触发Rebalance的情况包括：组成员变更、订阅主题变化以及主题分区数量的变化。Rebalance过程中，所有消费者实例都会暂停工作，直到重新分配完毕。尽管Rebalance有助于公平分配任务，但它也可能带来显著的性能影响，特别是在大规模集群中。目前，社区正在努力优化这一流程，以减少其负面影响。

## 小结

今天，我们深入探讨了Kafka消费者组的概念及其特点，包括它是如何工作的、解决了哪些问题以及有哪些特性。同时，我们也讨论了消费者组位移管理和Rebalance过程。希望这些知识能在你开发消费者应用程序时提供帮助。

## 开放讨论

你觉得消费者组设计有哪些潜在的缺点？请分享你的看法和答案，共同参与讨论。如果你认为这篇文章有价值，也欢迎转发给你的朋友们。

![](https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg)