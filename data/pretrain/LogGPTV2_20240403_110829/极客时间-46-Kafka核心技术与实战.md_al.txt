## 事务Kafka的事务概念类似于我们熟知的数据库提供的事务。在数据库领域，事务提供的安全性保障是经典的ACID，即原子性（Atomicity）、一致性 (Consistency)、隔离性 (Isolation)和持久性 (Durability)。当然，在实际场景中各家数据库对 ACID 的实现各不相同。特别是 ACID本身就是一个有歧义的概念，比如对隔离性的理解。大体来看，隔离性非常自然和必要，但是具体到实现细节就显得不那么精确了。通常来说，**隔离性表明并发执行的事务彼此相互隔离，互不影响**。经典的数据库教科书把隔离性称为可串行化(serializability)，即每个事务都假装它是整个数据库中唯一的事务。提到隔离级别，这种歧义或混乱就更加明显了。很多数据库厂商对于隔离级别的实现都有自己不同的理解，比如有的数据库提供Snapshot 隔离级别，而在另外一些数据库中，它们被称为可重复读（repeatableread）。好在对于已提交读（readcommitted）隔离级别的提法，各大主流数据库厂商都比较统一。所谓的 readcommitted，指的是当读取数据库时，你只能看到已提交的数据，即无脏读。同时，当写入数据库时，你也只能覆盖掉已提交的数据，即无脏写。Kafka 自 0.11 版本开始也提供了对事务的支持，目前主要是在 read committed隔离级别上做事情。它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer 只能看到事务成功提交的消息。下面我们就来看看 Kafka 中的事务型Producer。
## 事务型 Producer事务型 Producer能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。另外，事务型Producer 也不惧进程的重启。Producer 重启回来后，Kafka依然保证它们发送消息的精确一次处理。设置事务型 Producer 的方法也很简单，满足两个要求即可：-   和幂等性 Producer 一样，开启 enable.idempotence = true。-   设置 Producer 端参数 transctional.    id。最好为其设置一个有意义的名字。此外，你还需要在 Producer 代码中做一些调整，如这段代码所示：    producer.initTransactions();try {            producer.beginTransaction();            producer.send(record1);            producer.send(record2);            producer.commitTransaction();} catch (KafkaException e) {            producer.abortTransaction();}和普通 Producer 代码相比，事务型 Producer 的显著特点是调用了一些事务API，如 initTransaction、beginTransaction、commitTransaction 和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。这段代码能够保证 Record1 和 Record2 被当作一个事务统一提交到Kafka，要么它们全部提交成功，要么全部写入失败。实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说 Consumer还是会看到这些消息。因此在 Consumer 端，读取事务型 Producer发送的消息也是需要一些变更的。修改起来也很简单，设置 isolation.level参数的值即可。当前这个参数有两个取值：1.  read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka    写入的任何消息，不论事务型 Producer    提交事务还是终止事务，其写入的消息都可以读取。很显然，如果你用了事务型    Producer，那么对应的 Consumer 就不要使用这个值。2.  read_committed：表明 Consumer 只会读取事务型 Producer    成功提交事务写入的消息。当然了，它也能看到非事务型 Producer    写入的所有消息。
## 小结简单来说，幂等性 Producer 和事务型 Producer 都是 Kafka 社区力图为 Kafka实现精确一次处理语义所提供的工具，只是它们的作用范围是不同的。幂等性Producer只能保证单分区、单会话上的消息幂等性；而事务能够保证跨分区、跨会话间的幂等性。从交付语义上来看，自然是事务型Producer 能做的更多。不过，切记天下没有免费的午餐。比起幂等性 Producer，事务型 Producer的性能要更差，在实际使用过程中，我们需要仔细评估引入事务的开销，切不可无脑地启用事务。
## 开放讨论你理解的事务是什么呢？通过今天的分享，你能列举出未来可能应用于你们公司实际业务中的事务型Producer 使用场景吗？欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}
# 15 \| 消费者组到底是什么？你好，我是胡夕。今天我要和你分享的主题是：Kafka 的消费者组。消费者组，即 Consumer Group，应该算是 Kafka 比较有亮点的设计了。那么何谓Consumer Group 呢？用一句话概括就是：**Consumer Group 是 Kafka提供的可扩展且具有容错性的消费者机制**。既然是一个组，那么组内必然可以有多个消费者或消费者实例（ConsumerInstance），它们共享一个公共的 ID，这个 ID 被称为 GroupID。组内的所有消费者协调在一起来消费订阅主题（SubscribedTopics）的所有分区（Partition）。当然，每个分区只能由同一个消费者组内的一个Consumer 实例来消费。个人认为，理解 Consumer Group记住下面这三个特性就好了。1.  Consumer Group 下可以有一个或多个 Consumer    实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。2.  Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个    Consumer Group。3.  Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个    Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。``{=html}你应该还记得我在专栏[第 1期](https://time.geekbang.org/column/article/98948)中提到的两种消息引擎模型吧？它们分别是**点对点模型和发布/订阅模型**，前者也称为消费队列。当然，你要注意区分很多架构文章中涉及的消息队列与这里的消息队列。国内很多文章都习惯把消息中间件这类框架统称为消息队列，我在这里不评价这种提法是否准确，只是想提醒你注意这里所说的消息队列，特指经典的消息引擎模型。好了，传统的消息引擎模型就是这两大类，它们各有优劣。我们来简单回顾一下。传统的消息队列模型的缺陷在于消息一旦被消费，就会从队列中被删除，而且只能被下游的一个Consumer消费。严格来说，这一点不算是缺陷，只能算是它的一个特性。但很显然，这种模型的伸缩性（scalability）很差，因为下游的多个Consumer 都要"抢"这个共享消息队列的消息。发布 /订阅模型倒是允许消息被多个 Consumer消费，但它的问题也是伸缩性不高，因为每个订阅者都必须要订阅主题的所有分区。这种全量订阅的方式既不灵活，也会影响消息的真实投递效果。如果有这么一种机制，既可以避开这两种模型的缺陷，又兼具它们的优点，那就太好了。幸运的是，Kafka的 Consumer Group 就是这样的机制。当 Consumer Group订阅了多个主题后，组内的每个实例不要求一定要订阅主题的所有分区，它只会消费部分分区中的消息。Consumer Group之间彼此独立，互不影响，它们能够订阅相同的一组主题而互不干涉。再加上Broker 端的消息留存机制，Kafka 的 Consumer Group完美地规避了上面提到的伸缩性差的问题。可以这么说，**Kafka 仅仅使用Consumer Group这一种机制，却同时实现了传统消息引擎系统的两大模型**：如果所有实例都属于同一个Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的Group，那么它实现的就是发布 / 订阅模型。在了解了 Consumer Group以及它的设计亮点之后，你可能会有这样的疑问：在实际使用场景中，我怎么知道一个Group 下该有多少个 Consumer 实例呢？**理想情况下，Consumer实例的数量应该等于该 Group 订阅主题的分区总数。**举个简单的例子，假设一个 Consumer Group 订阅了 3 个主题，分别是A、B、C，它们的分区数依次是 1、2、3，那么通常情况下，为该 Group 设置 6个 Consumer 实例是比较理想的情形，因为它能最大限度地实现高伸缩性。你可能会问，我能设置小于或大于 6 的实例吗？当然可以！如果你有 3个实例，那么平均下来每个实例大约消费 2 个分区（6 / 3 = 2）；如果你设置了8 个实例，那么很遗憾，有 2 个实例（8 -- 6 =2）将不会被分配任何分区，它们永远处于空闲状态。因此，在实际使用过程中一般不推荐设置大于总分区数的Consumer 实例。设置多余的实例只会浪费资源，而没有任何好处。好了，说完了 Consumer Group 的设计特性，我们来讨论一个问题：针对Consumer Group，Kafka是怎么管理位移的呢？你还记得吧，消费者在消费的过程中需要记录自己消费了多少数据，即消费位置信息。在Kafka 中，这个位置信息有个专门的术语：位移（Offset）。看上去该 Offset 就是一个数值而已，其实对于 Consumer Group 而言，它是一组KV 对，Key 是分区，V 对应 Consumer 消费该分区的最新位移。如果用 Java来表示的话，你大致可以认为是这样的数据结构，即 Map\，其中 TopicPartition 表示一个分区，而 Long表示位移的类型。当然，我必须承认 Kafka源码中并不是这样简单的数据结构，而是要比这个复杂得多，不过这并不会妨碍我们对Group 位移的理解。我在专栏[第 4期](https://time.geekbang.org/column/article/100285)中提到过 Kafka有新旧客户端 API 之分，那自然也就有新旧 Consumer 之分。老版本的 Consumer也有消费者组的概念，它和我们目前讨论的 Consumer Group在使用感上并没有太多的不同，只是它管理位移的方式和新版本是不一样的。老版本的 Consumer Group 把位移保存在 ZooKeeper 中。Apache ZooKeeper是一个分布式的协调服务框架，Kafka重度依赖它实现各种各样的协调管理。将位移保存在 ZooKeeper外部系统的做法，最显而易见的好处就是减少了 Kafka Broker端的状态保存开销。现在比较流行的提法是将服务器节点做成无状态的，这样可以自由地扩缩容，实现超强的伸缩性。Kafka最开始也是基于这样的考虑，才将 Consumer Group 位移保存在独立于 Kafka集群之外的框架中。不过，慢慢地人们发现了一个问题，即 ZooKeeper这类元框架其实并不适合进行频繁的写更新，而 Consumer Group的位移更新却是一个非常频繁的操作。这种大吞吐量的写操作会极大地拖慢ZooKeeper 集群的性能，因此 Kafka 社区渐渐有了这样的共识：将 Consumer位移保存在 ZooKeeper 中是不合适的做法。于是，在新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer Group的位移管理方式，采用了将位移保存在 Kafka内部主题的方法。这个内部主题就是让人既爱又恨的\_\_consumer_offsets。我会在专栏后面的内容中专门介绍这个神秘的主题。不过，现在你需要记住新版本的Consumer Group 将位移保存在 Broker 端的内部主题中。最后，我们来说说 Consumer Group 端大名鼎鼎的重平衡，也就是所谓的Rebalance过程。我形容其为"大名鼎鼎"，从某种程度上来说其实也是"臭名昭著"，因为有关它的bug真可谓是此起彼伏，从未间断。这里我先卖个关子，后面我会解释它"遭人恨"的地方。我们先来了解一下什么是Rebalance。**Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有Consumer 如何达成一致，来分配订阅 Topic 的每个分区**。比如某个 Group下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5个分区。这个分配的过程就叫 Rebalance。那么 Consumer Group 何时进行 Rebalance 呢？Rebalance 的触发条件有 3 个。1.  组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有    Consumer 实例崩溃被"踢出"组。2.  订阅主题数发生变更。Consumer Group    可以使用正则表达式的方式订阅主题，比如    consumer.subscribe(Pattern.compile("t.\*c")) 就表明该 Group    订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group    的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group    就会发生 Rebalance。3.  订阅主题的分区数发生变更。Kafka    当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有    Group 开启 Rebalance。Rebalance 发生时，Group 下所有的 Consumer实例都会协调在一起共同参与。你可能会问，每个 Consumer实例怎么知道应该消费订阅主题的哪些分区呢？这就需要分配策略的协助了。当前 Kafka 默认提供了 3种分配策略，每种策略都有一定的优势和劣势，我们今天就不展开讨论了，你只需要记住社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer 实例都能够得到较为平均的分区数。比如一个 Group 内有 10 个Consumer 实例，要消费 100 个分区，理想的分配策略自然是每个实例平均得到10个分区。这就叫公平的分配策略。如果出现了严重的分配倾斜，势必会出现这种情况：有的实例会"闲死"，而有的实例则会"忙死"。我们举个简单的例子来说明一下 Consumer Group 发生 Rebalance的过程。假设目前某个 Consumer Group 下有两个 Consumer，比如 A 和B，当第三个成员 C 加入时，Kafka 会触发Rebalance，并根据默认的分配策略重新为 A、B 和 C 分配分区，如下图所示：![](Images/74017ed2b5051c885d2bc15b9f659fd1.png){savepage-src="https://static001.geekbang.org/resource/image/29/1b/2976713957cd4cc8cc796aa64222611b.png"}显然，Rebalance 之后的分配依然是公平的，即每个 Consumer 实例都获得了 3个分区的消费权。这是我们希望出现的情形。讲完了 Rebalance，现在我来说说它"遭人恨"的地方。首先，Rebalance 过程对 Consumer Group 消费过程有极大的影响。如果你了解JVM 的垃圾回收机制，你一定听过万物静止的收集方式，即著名的 stop theworld，简称 STW。在 STW期间，所有应用线程都会停止工作，表现为整个应用程序僵在那边一动不动。Rebalance过程也和这个类似，在 Rebalance 过程中，所有 Consumer实例都会停止消费，等待 Rebalance 完成。这是 Rebalance为人诟病的一个方面。其次，目前 Rebalance 的设计是所有 Consumer实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。例如实例A 之前负责消费分区 1、2、3，那么 Rebalance之后，如果可能的话，最好还是让实例 A 继续消费分区1、2、3，而不是被重新分配其他的分区。这样的话，实例 A 连接这些分区所在Broker 的 TCP 连接就可以继续用，不用重新创建连接其他 Broker 的 Socket资源。最后，Rebalance 实在是太慢了。曾经，有个国外用户的 Group 内有几百个Consumer 实例，成功 Rebalance一次要几个小时！这完全是不能忍受的。最悲剧的是，目前社区对此无能为力，至少现在还没有特别好的解决方案。所谓"本事大不如不摊上"，也许最好的解决方案就是避免Rebalance 的发生吧。
## 小结总结一下，今天我跟你分享了 Kafka Consumer Group的方方面面，包括它是怎么定义的，它解决了哪些问题，有哪些特性。同时，我们也聊到了Consumer Group 的位移管理以及著名的 Rebalance 过程。希望在你开发Consumer 应用时，它们能够助你一臂之力。
## 开放讨论今天我貌似说了很多 Consumer Group 的好话（除了Rebalance），你觉得这种消费者组设计的弊端有哪些呢？欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}