III. SYSTEM DESIGN
In this section, we ﬁrst present
the assumptions and
security goals of Mimosa. We then introduce the general
system architecture, and some important details in the design
of Mimosa.
A. Assumptions and Security Goals
Assumptions. We assume the correct hardware implemen-
tation of HTM (i.e., Intel TSX in our prototype system or
others in the future). This assumption is expected to be
guaranteed in COTS platforms. We also assume a secure
initialization phase during the OS boot process; that is, the
system is clean and not attacked during this small time
window.
The attackers are assumed to be able to launch various
memory disclosure attacks on the protected system. The
attackers can stealthily read data in memory with root
privileges by exploiting software vulnerabilities [31, 50, 57–
59], or launch cold-boot attacks [32] on the system. They
can also eavesdrop the communication between the CPU and
RAM chips on the bus. Mimosa is designed to defend against
the “silent” memory disclosure attacks that read sensitive
data from memory without breaking the integrity of the
systems’ executable binaries. For instance, the attacks that
exploit various Linux kernel vulnerabilities [24] to access
unauthorized data. We do not consider the multi-step attacks
that compromise OS kernel – the attacks that ﬁrst write
malicious binary codes into the victim machine’s kernel,
and then access sensitive data via the injected codes. That
is, Mimosa assumes that the integrity of OS kernel is not
compromised.
Different from the existing security mechanisms which
attempt to detect or prevent software attacks (e.g., kernel
integrity protections [38, 47, 63, 70] and buffer-overﬂow
guards [22, 23, 83]), Mimosa follows a different philosophy
– it tries to “dance” with attacks. That is, even when an
attacker exploits memory disclosure vulnerabilities (e.g.,
OpenSSL Heartbleed [58]) to successfully circumvent these
protections and read data from memory, Mimosa ensures
that the attacker still cannot obtain the private keys that were
originally stored at the memory address.
Last, since Mimosa employs TRESOR [56] to protect
the AES master key, it also inherits the assumptions made
by TRESOR. In particular, TRESOR (and similar solutions
[29, 30, 73]) assumes an OS without any interface or
vulnerability that allows attackers to access the privileged
debug registers. As analyzed in [29, 30, 56, 73], the access to
the privileged debug registers can be blocked by patching the
ptrace system call (the only interface to debug registers
from user space applications), disabling loadable kernel
modules (LKMs) and kmem, and removing JTAG ports (as
done in COTS products).
Security Goal. Based on the above assumptions, we design
Mimosa with the following goals:
1) During each signing/decryption computation, no pro-
cess other than the Mimosa computing task can access
the sensitive data in memory, including the AES mas-
ter key, the plaintext RSA private key and intermediate
states.
2) Either successfully completed or accidentally inter-
rupted, each Mimosa computing task is ensured to
immediately clear all sensitive data, so it cannot be
suspended to dump these sensitive data.
3) The sensitive data never appear on the RAM chips.
The ﬁrst goal thwarts direct software-based memory dis-
closure attacks, and the second prevents the sensitive data
from being propagated to other vulnerable places. The third
goal makes a successful cold-boot attack only get encrypted
copies of private keys.
B. The Mimosa Architecture
Mimosa adopts the common key-encryption-key structure.
The AES master key is generated early during the OS boot
process and is stored in debug registers since then. The
RSA context is dynamically constructed, used and ﬁnally
destroyed within a transactional execution, when Mimosa
serves signing/decryption requests. When the Mimosa ser-
vice is in idle, the private keys always remain encrypted by
the AES key.
The operation of Mimosa consists of two phases as shown
in Figure 1: an initialization phase and a protected com-
puting phase. The initialization phase is executed only once
when the system boots. It initializes the AES master key and
sets up necessary resources. The protected computing phase
is executed on each RSA private-key computation request.
This phase performs the requested RSA computations. All
memory accesses during the protected computing phase
are tracked and examined to achieve the security goals of
Mimosa.
66
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:11 UTC from IEEE Xplore.  Restrictions apply. 
ALLOCATION
CONTEXT 3
ALLOCATION
CONTEXT 2
ALLOCATION
CONTEXT 1
ALLOCATION
CONTEXT 0
(cid:258)(cid:258)
Thread Stack
(cid:258)(cid:258)
Private Key 1
Key Id 1
Disk
Init.2
Init.1
PrCmpt.4
Intermediate
Variable
RSA Context
Input
Output
Private Key 0
PrCmpt.1
Private Key 0
PrCmpt.3
Key Id 0
(cid:258)(cid:258)
RAM
AES Context
PrCmpt.2
L1D Cache
L1D
Cache
L1D
Cache
L1D
Cache
L1D
Cache
db0~3
eax,ebx
etc.
Core 3
db0~3
eax,ebx
etc.
Core 2
db0~3
eax,ebx
etc.
Core 1
db0~3
eax,ebx
etc.
Core 0
Processor
Figure 1: Mimosa Overview
Init.1
Init.2
Prepare
PrCmpt.1
PrCmpt.2
PrCmpt.3
PrCmpt.4
PrCmpt.5
Commit
n
o
i
t
a
z
i
l
a
i
t
i
n
I
e
s
a
h
P
g
n
i
t
u
p
m
o
C
d
e
t
c
e
t
o
r
P
e
s
a
h
P
Initialization Phase. This phase contains two steps. Init.1
resembles TRESOR [56] and executes completely in kernel
space when the system boots. First, a command line prompt
is set up for the user to enter a password. Then, the AES
master key is derived from the password, and copied to the
debug registers of every CPU core. All intermediate states
of this derivation are carefully erased. Moreover, the user is
required to type in 4096 more characters to overwrite input
buffers. We assume that there is no software or physical
memory disclosure attack during this step, and the password
is strong enough to resist brute-force attacks.
In Init.2, a ﬁle containing an array of ciphertext private
keys is loaded from hard disks or other non-volatile storages
into memory. These private keys are securely generated and
encrypted by the AES master key into the ﬁle in a secure
environment, e.g., another off-line trustworthy machine.
Protected Computing Phase. When Mimosa receives a
private-key computation request from users,
it uses the
corresponding private key to perform the computation, and
then returns the result to users. In this phase, Mimosa pre-
pares the transactional execution, performs the private-key
computation, erases all sensitive data, and ﬁnally terminates
the transaction to commit the result. In particular, it includes
the following steps:
• Prepare: HTM starts to track memory accesses in the
read-set and the write-set in the L1D cache.
• PrCmpt.1: The ciphertext private key is loaded from
the RAM to the cache.
• PrCmpt.2: The master key is loaded from the debug
registers to the cache.
• PrCmpt.3: With the master key and ciphertext private
key, the private key context is constructed.
• PrCmpt.4: With the plaintext private key, the requested
decryption/signing operation is performed.
• PrCmpt.5: All the sensitive variables in caches and
registers are erased, except the result.
• Commit: Finish the transaction and make the result
available.
All memory accesses during the protected computing
phase are strictly monitored by hardware. In particular,
we declare a transactional region. During the transactional
execution, all memory operations that might break Mimosa’s
security principles are detected by hardware: (1) any attempt
to access the modiﬁed memory locations, i.e., the plaintext
private key and any intermediate states generated in the
transactional execution; and (2) cache eviction or replace-
ment that synchronizes data in caches to the RAM.
If no such memory exception is detected, the transaction
commits and the result
is returned to users. Otherwise,
the hardware-enabled abort processing handler is triggered
automatically to discard all modiﬁed data. Then, it executes
the program-speciﬁed fallback function (not shown in Fig-
ure 1) to process the exceptional situation; in the fallback
function, we can choose to retry immediately or take other
supplementary actions before retrying (see Section IV-C).
To take full advantage of multi-core processors, Mimosa is
designed to support multiple private-key computation tasks
in parallel. Each core is conﬁgured with its own resources
for Mimosa. A block of memory space is reserved for each
core in the transactional region (i.e, the protected computing
phase). This space is mainly used for the dynamic memory
allocation in RSA computations. The reserved space is
separated properly for each core to avoid data conﬂict that
would lead to aborts (see Section IV-C for details).
Finally, we would like to emphasize that the design of the
Mimosa architecture is based on the general properties of
77
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:11 UTC from IEEE Xplore.  Restrictions apply. 
hardware transactional memory. That is, Mimosa does not
rely on any speciﬁc HTM implementation. It is expected
that
this architecture could be adopted with any COTS
HTM product. In the rest of the paper, we will describe
the implementation and evaluation of Mimosa with a COTS
HTM product, i.e., Intel TSX.
IV. IMPLEMENTATION
Mimosa is implemented as a kernel module patched to
Linux kernel v3.13.1. It provides RSA private-key compu-
tation services to the user space through the ioctl system
call. In addition, the ioctl interface is further encapsu-
lated into an OpenSSL engine, facilitating the integration
of Mimosa into other applications. The Mimosa prototype
supports 1024/2048/3072/4096-bit RSA algorithms.
In this section, we ﬁrstly describe the RTM interface of
Intel TSX, and then a na¨ıve implementation of Mimosa.
However, in this implementation, the transactional execution
rarely commits, resulting in unacceptable performance. Next,
we identify the abort reasons, and eliminate them one by
one. The ﬁnal implementation offers efﬁciency comparable
to conventional RSA implementations without such protec-
tions. The performance tuning steps produce an empirical
guideline to perform heavy cryptographic computations with
Intel TSX. We also brieﬂy describe the utility issues of
Mimosa, including private key generation and the user-space
API. Finally, we discuss the applicability of Mimosa design,
i.e., how to apply the Mimosa architecture to other HTM
solutions.
A. RTM Programming Interface
In the protected computing phase,
the computation is
constrained in a transaction. Mimosa utilizes Intel TSX as
the underlying transactional memory primitive. In particular,
we choose RTM as the HTM programming interface. With
this ﬂexible interface, we have control over the fallback path,
in which Mimosa can deﬁne the policy to handle aborts.
RTM consists of three new instructions (XBEGIN, XEND
and XABORT) to start, commit and abort a transactional exe-
cution. XBEGIN consists of a two-byte opcode 0xC7 0xF8
and an immediate operand. The operand is a relative offset
to the EIP register, which is used to calculate the address
of the program-speciﬁed fallback function. On aborts, TSX
immediately breaks the transaction and restores architectural
states by the hardware-enabled abort handler. Then, the
execution resumes at the fallback function. At the same
time, the reason of abort is marked in the corresponding
bit(s) of the EAX register. The reason code in EAX is used
for quick decisions (in the fallback function) at runtime; for
example, the third bit indicates a data conﬂict, and the fourth
bit indicates that the cache is full. However, this returned
code does not precisely reﬂect every event that leads to the
abort [40]. For instance, aborts due to unfriendly instruction
or interrupt will not set any bit: the codes for them are both
0. With this code, we cannot determine the exact reason
for aborts at runtime. In fact, Intel suggests performance
monitoring for deep analysis (see the remainder of this
section for details) when programming with TSX, before
releasing the software. In addition, Intel provides the XTEST
instruction to test whether the CPU core is in a transaction
region.
We encapsulate the above instructions into C functions
in kernel. At the time of Mimosa implementation, we did
not ﬁnd any ofﬁcial support for RTM in the main Linux
kernel branch. Although Intel Compiler, Microsoft Visual
Studio, and GCC have developed supports for RTM in
user programming, they cannot be readily used for kernel
programming. Therefore, we refer to Intel Architectures
Optimization Reference Manual [39] to emulate RTM in-
trinsics using inline assembler equivalents. We show the
implementation of _xbegin() to start the transactional
execution of RTM as follows:
static __attribute__((__always_inline__)) inline