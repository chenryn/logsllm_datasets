# 关于TCP 半连接队列和全连接队列
> 最近碰到一个client端连接异常问题，然后定位分析发现是因为全连接队列满了导致的。查阅各种资料文章和通过一系列的实验对TCP连接队列有了更深入的理解
> 
> 查资料过程中发现没有文章把这两个队列以及怎么观察他们的指标说清楚，希望通过这篇文章能说清楚:
> 
> 1.  这两个队列是干什么用的；
> 
> 2）怎么设置和观察他们的最大值；
> 
> 3）怎么查看这两个队列当前使用到了多少；
> 
> 4）一旦溢出的后果和现象是什么
## 问题描述
```
场景：JAVA的client和server，使用socket通信。server使用NIO。
1.间歇性的出现client向server建立连接三次握手已经完成，但server的selector没有响应到这连接。
2.出问题的时间点，会同时有很多连接出现这个问题。
3.selector没有销毁重建，一直用的都是一个。
4.程序刚启动的时候必会出现一些，之后会间歇性出现。
```
## 分析问题
### 正常TCP建连接三次握手过程：
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/159a331ff8cdd4b8-159a331ff8cdd4b8994dfe6a209d035f.png)
-   第一步：client 发送 syn 到server 发起握手；
-   第二步：server 收到 syn后回复syn+ack给client；
-   第三步：client 收到syn+ack后，回复server一个ack表示收到了server的syn+ack（此时client的56911端口的连接已经是established）
从问题的描述来看，有点像TCP建连接的时候全连接队列（accept队列，后面具体讲）满了，尤其是症状2、4. 为了证明是这个原因，马上通过 netstat -s | egrep "listen" 去看队列的溢出统计数据：
```
667399 times the listen queue of a socket overflowed
```
反复看了几次之后发现这个overflowed 一直在增加，那么可以明确的是server上全连接队列一定溢出了
接着查看溢出后，OS怎么处理：
```
# cat /proc/sys/net/ipv4/tcp_abort_on_overflow
0
```
**tcp_abort_on_overflow 为0表示如果三次握手第三步的时候全连接队列满了那么server扔掉client 发过来的ack（在server端认为连接还没建立起来）**
为了证明客户端应用代码的异常跟全连接队列满有关系，我先把tcp_abort_on_overflow修改成 1，1表示第三步的时候如果全连接队列满了，server发送一个reset包给client，表示废掉这个握手过程和这个连接（本来在server端这个连接就还没建立起来）。
接着测试，这时在客户端异常中可以看到很多connection reset by peer的错误，**到此证明客户端错误是这个原因导致的（逻辑严谨、快速证明问题的关键点所在）**。
于是开发同学翻看java 源代码发现socket 默认的backlog（这个值控制全连接队列的大小，后面再详述）是50，于是改大重新跑，经过12个小时以上的压测，这个错误一次都没出现了，同时观察到 overflowed 也不再增加了。
到此问题解决，**简单来说TCP三次握手后有个accept队列，进到这个队列才能从Listen变成accept，默认backlog 值是50，很容易就满了**。满了之后握手第三步的时候server就忽略了client发过来的ack包（隔一段时间server重发握手第二步的syn+ack包给client），如果这个连接一直排不上队就异常了。
> 但是不能只是满足问题的解决，而是要去复盘解决过程，中间涉及到了哪些知识点是我所缺失或者理解不到位的；这个问题除了上面的异常信息表现出来之外，还有没有更明确地指征来查看和确认这个问题。
## 深入理解TCP握手过程中建连接的流程和队列
![image.png](https://cdn.jsdelivr.net/gh/shareImage/image@_md2zhihu_programmer_case_81efef37/就是要你懂TCP--半连接队列和全连接队列/bcf463efeb677d57-bcf463efeb677d5749d8d7571274ee79.png)
如上图所示，这里有两个队列：syns queue(半连接队列）；accept queue（全连接队列）
三次握手中，在第一步server收到client的syn后，把这个连接信息放到半连接队列中，同时回复syn+ack给client（第二步）；
```
题外话，比如syn floods 攻击就是针对半连接队列的，攻击方不停地建连接，但是建连接的时候只做第一步，第二步中攻击方收到server的syn+ack后故意扔掉什么也不做，导致server上这个队列满其它正常请求无法进来
```
第三步的时候server收到client的ack，如果这时全连接队列没满，那么从半连接队列拿出这个连接的信息放入到全连接队列中，同时将连接状态从 SYN_RECV 改成 ESTABLISHED 状态，否则按tcp_abort_on_overflow指示的执行。
这时如果全连接队列满了并且tcp_abort_on_overflow是0的话，server会扔掉三次握手中第三步收到的ack（假装没有收到一样），过一段时间再次发送syn+ack给client（也就是重新走握手的第二步），如果client超时等待比较短，就很容易异常了。其实这个时候client认为连接已经建立了，可以发数据或者可以断开，而实际server上连接还没建立好（还没能力）。
在我们的os中retry 第二步的默认次数是2（centos默认是5次）：
```
net.ipv4.tcp_synack_retries = 2
```
## 如果TCP连接队列溢出，有哪些指标可以看呢？
上述解决过程有点绕，听起来蒙逼，那么下次再出现类似问题有什么更快更明确的手段来确认这个问题呢？
（*通过具体的、感性的东西来强化我们对知识点的理解和吸收*）
### netstat -s
```
[root@server ~]#  netstat -s | egrep "listen|LISTEN" 
667399 times the listen queue of a socket overflowed
667399 SYNs to LISTEN sockets ignored
```
比如上面看到的 667399 times ，表示全连接队列溢出的次数，隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。
### ss 命令
```
[root@server ~]# ss -lnt
Recv-Q Send-Q Local Address:Port  Peer Address:Port 
0        50               *:3306             *:* 
```
**上面看到的第二列Send-Q 值是50，表示第三列的listen端口上的全连接队列最大为50，第一列Recv-Q为全连接队列当前使用了多少**
**全连接队列的大小取决于：min(backlog, somaxconn) . backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数**
《Unix Network Programming》中关于backlog的描述
> The backlog argument to the listen function has historically specified the maximum value for the sum of both queues.
> 
> There has never been a formal definition of what the backlog means. The 4.2BSD man page says that it "defines the maximum length the queue of pending connections may grow to." Many man pages and even the POSIX specification copy this definition verbatim, but this definition does not say whether a pending connection is one in the SYN_RCVD state, one in the ESTABLISHED state that has not yet been accepted, or either. The historical definition in this bullet is the Berkeley implementation, dating back to 4.2BSD, and copied by many others.
关于 [somaxconn 终于在2019年将默认值从128调整到了2048](https://github.com/torvalds/linux/commit/19f92a030ca6d772ab44b22ee6a01378a8cb32d4), 这个调整合并到了kernel 5.17中
> SOMAXCONN is /proc/sys/net/core/somaxconn default value.
> 
> It has been defined as 128 more than 20 years ago.
> 
> Since it caps the listen() backlog values, the very small value has
> caused numerous problems over the years, and many people had
> to raise it on their hosts after beeing hit by problems.
> 
> Google has been using 1024 for at least 15 years, and we increased
> this to 4096 after TCP listener rework has been completed, more than
> 4 years ago. We got no complain of this change breaking any
> legacy application.
> 
> Many applications indeed setup a TCP listener with listen(fd, -1);
> meaning they let the system select the backlog.
> 
> Raising SOMAXCONN lowers chance of the port being unavailable under
> even small SYNFLOOD attack, and reduces possibilities of side channel
> vulnerabilities.
这个时候可以跟我们的代码建立联系了，比如Java创建ServerSocket的时候会让你传入backlog的值：
```
ServerSocket()
	Creates an unbound server socket.
ServerSocket(int port)
	Creates a server socket, bound to the specified port.
ServerSocket(int port, int backlog)
	Creates a server socket and binds it to the specified local port number, with the specified backlog.
ServerSocket(int port, int backlog, InetAddress bindAddr)
	Create a server with the specified port, listen backlog, and local IP address to bind to.
```