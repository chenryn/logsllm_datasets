A malicious third party can access a user's personal data, which 
could be a violation of federal privacy regulations. 
Proposed 
remediation 
Make error messages ambiguous so an attacker doesn't know 
whether the username or password is invalid. 
Lock the user account after repeated failed login attempts. (Three or 
five attempts would be appropriate.) 
Risk 
Damage potential: 6 
Reproducibility: 8 
Exploitability: 4 
Affected users: 5 
Discoverability: 8 
Overall: 6.2 
This sample is certainly functional; however, it's not the only approach. Your level of 
detail can vary depending on your reasons for the audit and who the report is for. The 
following list is considered useful information to support a security finding: 
Location of the vulnerability This information (in Table 4-2's Module details 
row) should be fairly specific. You should usually include the filename, function 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
118 
name, and line number in the code. Sometimes a vulnerability spans many 
lines of code (and possibly several functions); in this case, you could omit a 
line number or give a range of line numbers. Also, you might choose to have 
one finding that represents a pervasive vulnerability, in which case this 
information would contain a large list of locations or refer to an external list 
generated by a tool or search. 
Vulnerability class A classification of sorts about the nature of the bug, 
whether it's buffer overflow, integer overflow, unchecked copy, dangerous API 
use, or one of the other vulnerability classes discussed in this book. 
Vulnerability description This summary of the vulnerability should describe 
why the code you're drawing attention to isn't secure. In some cases (such as 
a generic buffer overflow), you need to write very little, but more complex or 
unique vulnerabilities might require expanding the description to include more 
specifics. 
Prerequisites This is a list of prerequisite conditions that need to be true for the 
vulnerability to be triggered. The list might include configuration options or 
technical factors that need to exist before the vulnerability is a problem. 
Business impact Most reviews need to put technical risks in the context of 
business risks. Specifying the business impact can be tricky, as it changes 
depending on who's expected to deploy the application and how it will be used. 
However, business factors are what motivate the review, so your findings 
need to address these concerns. 
Remediation It is possible that this information might not be required in some 
cases, or it might only be a simple line or two explaining how the developers 
might want to fix the vulnerability. When working closely with a development 
team, however, the remediation section might be quite detailed and provide 
several options for addressing the vulnerability. 
Risk This rating is the risk determined from the vulnerability's severity 
combined with the probability of exploit. The DREAD rating system from 
Chapter 2(? [????.]) encapsulates this information as the overall risk rating. 
Severity This information is the amount of damage that can be incurred if the 
vulnerability is exploited successfully. The DREAD rating system from Chapter 
2(? [????.]) encapsulates severity in the damage potential and affected users 
risk factors. 
Probability This information is the likelihood of the vulnerability being 
exploited successfully. The DREAD rating system from Chapter 2(? [????.]) 
encapsulates probability in the reproducibility, discoverability, and 
exploitability risk factors. 
Generally, you need to include an overall summary of how the application measured 
up. Was it extremely secure, making exploitable bugs difficult to find? Or did it seem 
as though the developers weren't aware of security considerations? Assigning an 
overall "grade" can be subjective, so make sure you don't come across as judgmental 
or condescending. Instead, you should rely on your results to convey the application's 
quality, and try to express the trends you see and the potential for future problems. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
119 
After you have some experience, the summary component will seem easier, as you 
should be able to get a feel for how securely an application is developed. 
6.4.6 Reporting and Remediation Support 
A good application security assessment should not be an isolated event. Sometimes 
the findings are just handed off and the job is done. However, most assessments 
require some degree of follow-up and interaction with the development team. 
Application security often isn't well understood, so you might play a big part in 
carrying out remediation. In particular, the developers might need to be educated on 
the nature of the vulnerabilities you identify. They might also need you to review the 
proposed remediation and identify any issues that weren't addressed adequately or 
spot the introduction of new vulnerabilities. 
The remediation review can also introduce additional operational review 
requirements, which often occurs with serious design vulnerabilities or pandemic 
implementation issues. Severe issues might be too expensive or time consuming to 
address adequately. Therefore, the development team might need your assistance in 
identifying stopgap measures and operational protections that can provide additional 
assurance. 
Vulnerability research has its own unique process, even though a researcher typically 
has only one or two critical risk bugs that warrant publication. The amount of work 
required to document, report, and support just one bug can easily exceed the effort 
needed to support an internal assessment with 30 findings. The issue must be 
documented technically and reported to third-party vendors, which is usually fairly 
straightforward. A researcher generally constructs exploits for a few platforms before 
contacting the vendor. This step is a final sanity check of the analysis and 
unequivocally establishes the risk of the issue in case its exploitability is disputed. 
The vendor typically asks for at least a month to fix the bug. At some point, the 
researcher has to prepare information for publication, which must be scrutinized and 
fact checked. Researchers might also be responsible for constructing intrusion 
detection system (IDS) signatures and scanner checks or creating reliable exploits 
suitable for penetration testers to use. Before publication, sometimes they're asked 
to verify the developer's remediation, and they often help the marketing staff prepare 
a press release to accompany any advisory. After the vulnerability is published, the 
researcher occasionally explains the issue to reporters and addresses any issues 
raised in response to the disclosure. 
6.4.7 Code Navigation 
There are a few basic ways to traverse through functions and modules in source code, 
defined by where you start, what your goal is, and how you follow the code. 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
120 
Borrowing some language from other disciplines, code navigation can be described in 
terms of external flow sensitivity and tracing direction. 
External Flow Sensitivity 
When you review an entire application, you need to find different ways to decompose 
it into more manageable parts. One of the easiest ways to do this is to isolate the 
application code's external flow, which refers to how execution proceeds from 
function to function, but not inside a function. It's divided into two categories: 
control-flow sensitive and data-flow sensitive. A brief example should help 
illustrate what this concept means: 
int bob(int c) 
{ 
    if (c == 4) 
        fred(c); 
    if (c == 72) 
        jim(); 
    for (; c; c) 
        updateglobalstate(); 
} 
Look at this example first in the context of ignoring external control flow and data flow. 
This means you simply read this code from top to bottom; you don't branch out to any 
function calls. You might note that the code uses some sentinel values to call fred() 
and jim() and seems to trust its input c. However, all your analysis should be isolated 
to this function. 
Consider the same example from a control-flow sensitive viewpoint. In this case, you 
start reading this function and see the call to fred(). Because you haven't seen fred() 
before, you pull it up and start checking it out. Then you trace into the call to jim() 
and do the same for the call to updateglobalstate(). Of course, each of these 
functions might call other unfamiliar functions, so your control-flow sensitive 
approach requires evaluating each one. This approach could conceivably involve 
reading dozens of functions before you finish this simple code path. 
Now say you follow only the data flow corresponding to the data in the c variable and 
ignore any control flow that doesn't affect this data directly. With this approach, you 
trace through to the call to fred() because it passes the c variable. However, this 
analysis simply ignores jim() because it doesn't affect the data. 
Finally, if you were following control flow and data flow, you'd have some idea of what 
the value of c might be coming into this function. You might have a certain value in 
mind or a possible set of values. For example, if you know that c couldn't be 4, you 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
121 
wouldn't bother reading fred(). If you suspected that c could be 72, however, you 
need to trace into jim(). 
If you haven't done much code review, you would probably guess that the most useful 
method combines control-flow sensitive and data-flow sensitive approaches because 
you'd be closely following what could happen as the program runs. It might surprise 
you to know that many experienced auditors rely primarily on techniques that aren't 
control-flow or data-flow sensitive. The reason they have done so is to simplify the 
number of mental context switches they deal with to make the most effective use of 
their time. Generally, it's more effective to review functions in isolation and trace the 
code flow only when absolutely necessary. 
Note 
Flow analysis is an important concept in compiler design, and these characterizations 
between control flow and data flow have been simplified for the purposes of this 
discussion. However, real compiler theory is far more complex and should only be 
attempted by card carrying computer scientists. 
Tracing Direction 
When tracing code, you can follow one of two paths: forward-tracing, usually done to 
evaluate code functionality, and back-tracing, usually done to evaluate code 
reachability. 
Forward-tracing can be done using any of the four types of flow sensitivity outlined 
previously. Forward traces that incorporate control flow and/or data flow start at 
entry points, trust boundaries, or the first line of key algorithms. Forward traces that 
ignore control flow and data flow start at the first line of a file or the top of a module 
implementation. All four techniques are essential core processes for analyzing code. 
Back-tracing usually starts at a piece of code identified as a candidate point, which 
represents a potential vulnerability in the system. Examples include issuing dynamic 
SQL statements, using unbounded string copies, or accessing dynamically generated 
file paths. Candidate points are usually identified through some form of automated 
analysis or by going through the code with the grep utility to find known vulnerable 
patterns. After identifying candidate points, the reviewer traces from them back to 
the application's entry points. 
The advantage of back-tracing is that it involves fewer code paths than 
forward-tracing. The disadvantage is that it's only as strong as your selection of 
candidate points, so you run the risk of overlooking exploitable pathways because you 
didn't consider valid candidate points. You also tend to miss logic-related 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
122 
vulnerabilities entirely because they rarely map cleanly to algorithmically detectable 
candidate points. 
6.4.8 Code-Auditing Strategies 
This section introduces a number of strategies for auditing code and explains their 
strengths and weaknesses. Keep in mind that these strategies can (and often must) 
be combined to suit the nuances of the application you're reviewing. Developing your 
own strategies based on the workflow you find most appealing is encouraged, too. 
Three basic categories of code-auditing strategies are described in the following 
sections, and all three have their value in different situations. The following list 
summarizes the categories: 
Code comprehension (CC) strategies These strategies involve analyzing 
the source code directly to discover vulnerabilities and improve your 
understanding of the application. 
Candidate point (CP) strategies These strategies feature two distinct steps. 
First, create a list of potential issues through some mechanism or process. 
Second, examine the source code to determine the relevance of these issues. 
Design generalization (DG) strategies These strategies, a bit more 
flexible in nature, are intended for analyzing potential medium- to high-level 
logic and design flaws. 
Each strategy description in the following sections includes a scorecard so that you 
can compare the finer points easily. Table 4-3 gives you a legend for understanding 
these scorecards. 
Table 4-3. Auditing Strategies Scorecard Legend 
Start point 
Where tracing begins for the strategy 
End point 
The goal for the strategy or where tracing ends 
Tracing method 
Defines the types of external code flow analysis and tracing 
direction associated with the strategy 
Goal 
Identifies the purpose of the strategy, meaning what general types 
of vulnerabilities it targets 
Difficulty 
The difficulty of using the strategy; however, difficulty generally 
decreases as you gain a better understanding of the code. These 
measures are defined as follows: 
Easy 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
123 
Table 4-3. Auditing Strategies Scorecard Legend 
Start point 
Where tracing begins for the strategy 
Moderate 
Hard 
Very hard 
Speed 
A measure of how quickly you can perform the strategy, which is 
often affected by its difficulty. These measures are defined as 
follows: 
Very slow 
Slow 
Medium 
Fast 
Very fast 
Comprehension 
impact 
A measure of how much this review strategy builds your 
understanding of the application's function, including the design 
and implementation. Strategies with a higher comprehension 
impact are usually more difficult but pay off by allowing you to 
identify more complex flaws. These measures are defined as 
follows: 
Very low 
Low 
Medium 
High 
Very high 
Abstraction 
Identifies the level at which the strategy operates, which 
determines the types of vulnerabilities it identifies and the existing 
knowledge you need to apply the strategy. These levels are defined 
as follows:  
Basic implementation: Vulnerabilities in implementation that can 
be identified without understanding the application's function or 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
124 
Table 4-3. Auditing Strategies Scorecard Legend 
Start point 
Where tracing begins for the strategy 
purpose; includes simple buffer overflows, format strings, and so 
forth. 
Complex implementation: More complex implementation 
vulnerabilities that can be identified with some additional 
application context but require no understanding of the function 
and purpose; includes integer and typing issues, synchronization 
issues, and so on. 
Implementation logic: Vulnerabilities identified from 
understanding the application's function at a module level but 
doesn't necessarily require knowing the high-level design 
abstractions. 
Design: Vulnerabilities in an application's abstract design. 
Architectural: Vulnerabilities in the high-level interaction between 
an application's components or its relationship with other systems; 
includes many classes of operational vulnerabilities. 
Strengths 
A summary of this strategy's common strengths compared to other 
strategies 
Weaknesses 
A summary of this strategy's common weaknesses compared to 
other strategies 
Code Comprehension Strategies 
Code comprehension strategies are organized around discovering vulnerabilities by 
directly analyzing the code. Typically, success with these techniques require you to 
read the code and understand it. They require higher degrees of concentration and 
discipline than other techniques, but they pay dividends in terms of learning the 
codebase. As noted in the previous bulleted list, the abbreviation "CC" is used for the 
following discussion of these strategies. 
Trace Malicious Input 
The CC1 technique (see Table 4-4) is close to what most people think code review 
involves. You start at an entry point to the system, where user-malleable information 
can come in. You then trace the flow of code forward, performing limited data flow 
analysis. You keep a set of possible "bad" inputs in the back of your mind as you read 
the code and try to trace down anything that looks like a potential security issue. This 
The Art of Software Security Assessment - Identifying and Preventing Software Vulnerabilities 
125 
technique is an effective way to analyze code, but it requires some experience so that 
you know which functions to trace into. 
Table 4-4. CC1: Trace Malicious Input 
Start point 
Data entry points 
End point 
Security vulnerabilities (open-ended) 
Tracing method 
Forward, control-flow sensitive, data-flow sensitive 
Goal 
Discover security problems that can be caused by malicious 
input. Use threat model and/or common vulnerability classes to 
help guide analysis. 
Difficulty 
Hard 
Speed 