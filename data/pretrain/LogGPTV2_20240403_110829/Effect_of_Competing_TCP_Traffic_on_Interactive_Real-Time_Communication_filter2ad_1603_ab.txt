0
4
6
8
1
1
2
0
0
0
0
5
0
4
6
8
1
1
2
0
0
0
0
5
0
4
6
8
1
1
2
0
0
0
0
5
0
4
6
8
1
1
2
0
0
0
0
5
0
m
m
m
0
0
0
m
m
m
0
0
0
m
m
m
0
0
0
m
m
m
0
0
0
m
m
m
0
0
0
m
m
m
0
0
0
s
s
s
m
m
m
s
s
s
s
s
s
m
m
m
s
s
s
s
s
s
m
m
m
s
s
s
s
s
s
m
m
m
s
s
s
s
s
s
m
m
m
s
s
s
s
s
s
m
m
m
s
s
s
Audio+1 short TCP flow
Audio+2 short TCP flows
Audio+6 short TCP flows
Fig. 4. CDF of one-way delay for an audio
ﬂow competing with n short TCP ﬂows,
50 replications
Fig. 5. Loss rate with diﬀerent jitter
buﬀer sizes for Audio+n short TCP ﬂows
workload
approaches 200ms but remains below 150ms even with one and two competing
TCP ﬂows.
IP Packet Delay Variation (IPDV) [4] for the media ﬂow is shown in Table 1.
As the high-end values seemed to correlate well with the increase in the size of the
combined initial windows of parallel TCP ﬂows, we extracted from the packet
traces those TCP data packets that are received between two audio packets
and conﬁrmed that the large IPDV values typically occur when the TCP initial
windows are among those TCP packets. In particular, with IW10 the large IPDV
values are mostly introduced when the TCP ﬂows inject the initial windows into
the network.
4 Estimated Delay Induced Loss Period Eﬀects
In order to explore the transient eﬀect of the delay jitter on the media ﬂow,
we introduce a jitter ﬁlter to mimic receiving codec behavior in dropping late
arriving media ﬂow packets. First, there are “pure losses” when a packet is
dropped in the network, either due to congestion or link errors. With interactive
media, there is also “delay-based loss” when a media ﬂow packet delay exceeds
the jitter buﬀer limit and thereby misses the deadline for codec to decode and
play the transmitted content. Such a packet is unusable similar to the pure loss.
Delay-based losses are ﬂagged when one-way delay of the packet exceeds “base
Table 1. CDF of IPDV for an audio ﬂow competing with n short TCP ﬂows, 50
replications
IW n
Min
25% Median
75%
90%
95%
96%
97%
98%
99%
Max
3 1 -0.020107 -0.011373 -0.000206 0.009194 0.020072 0.029445 0.031174 0.034697 0.043296 0.070158 0.111526
3 2 -0.020102 -0.011242 -0.000281 0.008824 0.018924 0.028301 0.029892 0.039526 0.050787 0.100523 0.182076
3 6 -0.020107 -0.011696 -0.000588 0.001666 0.012330 0.025413 0.031916 0.059762 0.081594 0.125042 0.282826
10 1 -0.020414 -0.012084 -0.000482 0.001835 0.016195 0.020696 0.029253 0.030297 0.050413 0.172464 0.242798
10 2 -0.020128 -0.019264 -0.000919 0.003032 0.019432 0.030032 0.031393 0.041291 0.070785 0.160448 0.322197
10 6 -0.020098 -0.019541 -0.009664 0.000454 0.018741 0.030004 0.040417 0.069099 0.121090 0.220447 0.589717
100
I. J¨arvinen et al.
delay” plus jitter buﬀer size. The “base delay” is calculated as the minimum
delay over the period of two seconds prior to the arrival of the TCP ﬂows.
Figure 5 shows the loss rate with diﬀerent jitter buﬀer sizes, number of con-
nections, and initial window settings. The loss rate is determined by combining
pure losses and delay-based losses. IW10 increases the loss rate dramatically to
nearly 100% with lower jitter buﬀer sizes. However, also IW3 with a large num-
ber of parallel connections produces signiﬁcant number of losses. We want to
reiterate that these losses occur almost solely due to excessive delay, not due to
pure losses.
As codecs often are able to conceal isolated losses quite well, we specify a
metric to estimate loss period eﬀect on the interactive media from codec and end
user perspective. The estimate is based on loss periods [12] that are encountered
by the codec when several consecutive media ﬂow packets are dropped due to
jitter delay. We combine also pure losses into this metric though pure losses occur
infrequently in our experiments. For a given jitter buﬀer size, each data packet
carrying interactive media (Audio) is assigned a loss period level according to
the deﬁnition in Table 2.
We intentionally chose to use minimum delay as base delay in order to report
the worst-case behavior. As a real codec might choose higher value, it is rea-
sonable to assume that the loss period eﬀect is unlikely to be worse than that
indicated by the loss period level.
In order to better understand transient eﬀects that are hidden with CDF,
Figures 6a, 6b, and 6c estimate the loss period eﬀect in a function of time for a
media ﬂow using 40 ms jitter buﬀer size and competing with 1, 2, and 6 short
TCP ﬂows, respectively. 50 replications are included in each test case. The loss
period level values are ﬁltered to only include the media ﬂow packets that overlap
with the TCP transfers and therefore the number of samples starts to decline
around 1 second when the TCP ﬂows in individual test replications start to
complete.
Almost immediately when the TCP ﬂows start the TCP traﬃc generates
signiﬁcant loss period eﬀect on the media ﬂow packets, as the SYN handshakes
complete and the TCP ﬂows inject their initial windows into the network. We
note that the arrival of the initial windows causes the worst eﬀect during the
whole transfer. When only a single TCP connection is competing with the media
Table 2. Loss period level deﬁnition for estimating loss period eﬀects
Value Description
0
1
2
3
4
5
no loss
20 ms gap in the stream, no adjacent packet lost
40-60 ms of the stream was lost
80-100 ms of the stream was lost
120-180 ms of the stream was lost
200+ ms of the stream was lost
Eﬀect of Competing TCP Traﬃc on Interactive Real-Time Communication
101
Loss Period Level for Audio with 1 short TCP flow, Jitter Buffer of 40 ms
Loss Period Level for Audio with 2 short TCP flows, Jitter Buffer of 40 ms
)
d
e
z
i
l
a
m
r
o
n
(
s
t
e
k
c
a
p
f
o
r
e
b
m
u
N
 1.2
 1.1
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
0
Best - 0
1
2
3
4
Worst - 5
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
Time (s)
)
d
e
z
i
l
a
m
r
o
n
(
s
t
e
k
c
a
p
f
o
r
e
b
m
u
N
 1.2
 1.1
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
0
Best - 0
1
2
3
4