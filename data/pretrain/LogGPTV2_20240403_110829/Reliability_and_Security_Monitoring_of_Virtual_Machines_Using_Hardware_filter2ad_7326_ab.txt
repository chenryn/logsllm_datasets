perform on-the-Ô¨Çy, but since malware always tries to minimize
15151515
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply. 
SHARED EVENT LOGGING
(A) Guest OS 
Operations
Context switch
Syscall
IO Access
(B) Hardware
Operations
Modify CR3 
register
Set MSR register
Issue interrupts
Page fault
IO instructions
External interrupts
RELIABILITY  & 
SECURITY 
AUDITING
(D) VM Auditors
Auditor 1
(C) Hardware
Virtualization 
Enforcement
VM Exit Events
Auditor 2
VM Exit Events
(root of trust)
CR_ACCESS
EXT_INT ...
HW state (root of trust)
RSP
CR3
Page Dir.
TR
TSS
Auditor 3
Guest OS state
thread_info
task_struct
VM Auditor (running outside VM)
1
2
3
Capture VM Exit = 
Intercept OS ops
Obtain relevant HW 
state
Derive relevant guest 
OS state
n
o
i
t
c
e
p
s
n
I
4
Fig. 1: HyperTap Monitoring Framework: (A) Guest OS operations that are subjects of the monitors; (B) Hardware operations
that are required to perform each guest OS operation; (C) VM Exit events that are generated before logged operations are
performed; (D) The captured events are delivered to auditors running outside the VM.
its footprint, our approach signiÔ¨Åcantly impedes would-be
attackers.
C. Robust Active Monitoring
Passive monitoring is suitable for persistent failures and
attacks, because it assumes the corrupted or compromised
state remains in the system sufÔ¨Åciently longer than the polling
interval. That assumption does not hold in many RnS prob-
lems. For example, the majority of crash and hang failures
in Linux systems have short failure latencies (the time for
faults to manifest into failures) [25]. An unnecessarily long
detection latency, e.g., caused by polling monitoring, would
result in subsequent failure propagation or inefÔ¨Åcient recovery
(e.g., multiple roll-backs).
As we demonstrate in Section VIII-C, a transient attack can
be combined with other techniques to create a stealthy attack
that can defeat passive monitoring.
Active monitoring, on the other hand, possesses many attrac-
tive features. Since it is event-driven, there is no time depen-
dence that can be exploited. Furthermore, active monitoring
can capture system activities in addition to the system state,
which passive monitoring provides. System activities are the
operations that transition a system from one state to another.
Invoking a system call is an example of a system activity. In
many cases, information about system activities is crucial to
enforcing RnS policies.
Active monitoring is not foolproof, as it can suffer from
event bypass attacks. If an attack can prevent or avoid gener-
ation of events that trigger logging, it can bypass the monitor.
To make active monitoring robust, we propose to use hardware
invariants, speciÔ¨Åcally the VM Exit feature provided by HAV,
to generate events. Section VI presents the hardware invariants
used to ensure the trustworthiness of generated events.
V. HYPERTAP FRAMEWORK AND IMPLEMENTATION
Following the principles presented in the previous section,
here we describe the design and implementation of HyperTap.
A. Scope and Assumptions
HyperTap integrates with existing hypervisors to safeguard
VMs against failures and attacks. It aims to make this pro-
tection transparent
to VMs by utilizing existing hardware
16161616
Auditing containers 
User VMs 
External 
machine  




$
%
Audit VM1 
Audit VM2 
















!$%
Kernel module 
   Linux kernel 



&



'
 
$%
	
KVM Hypervisor 
Non-blocking 
Blocking 
API call 

"

Fig. 2: Implementation of HyperTap in the KVM hypervisor.
The hypervisor is modiÔ¨Åed to forward VM Exit events to
the Event Multiplexer (EM), which is implemented as a
separate kernel module. The EM forwards events to registered
auditors running as user processes inside auditing containers.
The Remote Health Checker (RHC) monitors the hypervisor‚Äôs
liveness.
HyperTap‚Äôs implementation assumes that
features. Thus, HyperTap does not require modiÔ¨Åcation of
either the existing hardware or the guest OS‚Äôs software stack.
the underlying
hardware and hypervisor are trusted. Although extra validation
and protection for the hardware and hypervisor could address
concerns about the robustness of different hypervisors against
failures and attacks, these issues are beyond the scope of this
work.
B. Monitoring WorkÔ¨Çow
Fig. 1 depicts the overall workÔ¨Çow of HyperTap. The left
side of the Ô¨Ågure illustrates how the shared event logging
mechanism works and the right side describes the auditing
phase. HyperTap utilizes HAV to intercept the desired guest
OS operations through VM Exit events generated by cor-
responding hardware operations. Since the HAV VM Exit
mechanism is not designed to intercept all desired operations,
e.g., system calls, Section VI presents algorithms to generate
VM Exit events for such operations.
HyperTap supports a wide range of events, from coarse-
grained events, such as process context switches, to Ô¨Åner-
grained events, such as system calls, and very Ô¨Åne grained
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply. 
events, such as instruction execution and memory accesses.
That variable granularity ensures that HyperTap can be
adopted for a broad range of RnS policies.
HyperTap delivers captured events to registered auditors,
which implement speciÔ¨Åc RnS policies. An auditor starts by
registering for a set of events needed to enforce its policy.
Upon the arrival of each event, the auditor analyzes the state
information associated with the event. Auditors are associated
with VMs and each VM can have multiple auditors.
HyperTap also provides an interface that allows auditors to
control to target VMs. For example, the auditing phase is non-
blocking by default, but an auditor may pause its target VM
during analysis in order to stop the VM during an attack, or
roll-back the VM when it detects a non-recoverable failure.
C. Implementation
This subsection presents the integration of HyperTap with
KVM [26], hypervisor built with HAV as a Linux kernel mod-
ule. Fig. 2 depicts the deployment of HyperTap‚Äôs components.
HyperTap‚Äôs uniÔ¨Åed logging channel is implemented through
two components: an Event Forwarder (EF) and an Event
Multiplexer (EM). The EF is integrated into the KVM module,
and forwards VM Exit events and relevant guest hardware
state to the EM. By default, events are sent non-blocking to
minimize overhead. The EM, which is implemented as another
Linux kernel module in the host OS, buffers input events from
the EF and delivers them to the appropriate auditors.
The EM is also responsible for sampling VM Exit events
that are sent to a Remote Health Checker (RHC) running in a
separate machine. The RHC server acts as a heartbeat server
to measure the intervals between received events. If no events
are received after a certain amount of time, it raises an alert
about the liveness of the monitoring system.
Auditors are implemented as user processes inside auditing
containers1 running on the host OS. Compared to the dedicated
auditing VM used in previous work [12] [3], this approach
offers multiple beneÔ¨Åts. First, it provides lightweight attack
and failure isolation among different VMs‚Äô auditors, and
between auditors and the host OS. Second, it simpliÔ¨Åes im-
plementation and reduces the performance overhead of event
delivery from the EM module. Finally, it allows the integration
of auditors into existing systems, since containers are robust
and compatible with most current Linux distributions.
We needed to add less than 100 lines of code to KVM to
implement the EF component and export Helper APIs.
VI. HARDWARE INVARIANTS FOR VM LOGGING
This section describes events that can be monitored via
hardware invariants and VM Exit events, the core mechanism
of HyperTap‚Äôs shared logging channel. Table I summarizes
guest systems‚Äô internal operations, the hardware invariants,
and the types of VM Exit events associated with them. The
following sub-sections detail the use of these invariants.
1We use Linux containers (LXC) http://linuxcontainers.org/
A. Context Switch Interception
1) Process Switch Interception: Architectural Invariant.
Process switches can be observed by monitoring CR_ACCESS
VM Exit events. In x86, the CR3 register, or Page Direc-
tory Base Register (PDBR) contains the Page Directory Base
Address (PDBA) for the virtual address space of the running
process. As this base address is unique for each user process,
we can use it as a process identiÔ¨Åer.
Process Counting Algorithm. We can count the number of
processes running on a guest VM by monitoring CR_ACCESS
events. This algorithm is independent of any data structure the
guest OS uses to manage its processes.
Fig. 3A shows the pseudo-code for the process counting
algorithm. The set of PDBAs (PDBA_set) is empty when the
guest OS boots up. At each CR_ACCESS event in which CR3
is modiÔ¨Åed (CR3 <- PDBA), the algorithm updates PDBA_set
with the value that will be written to CR3.
2) Thread Switch Interception: Monitoring of
thread2
switches requires more effort than tracking CR_ACCESS events,
as threads can share the same virtual address space. In addi-
tion, a thread can reuse the virtual address space of another
process (e.g., Linux kernel threads).3
Architectural Invariant. In order to manage threads, the
x86 processor uses the Task Register (TR) and Task-State
Segment (TSS) structures. The TSS, stored in main memory,
holds the stack pointers of a task for different privilege levels,
and the TR points to the TSS structure of the current task. The
TSS is also used to support privilege protection. Each time
execution transfers from user level (3) to kernel level (0), the
kernel stack pointer is automatically loaded from the TSS by
the CPU (e.g., RSP <- TSS‚ÜíRSP0). Since all kernel threads
share the same virtual address range, each has a separate
address range for its stack. Therefore, the kernel stack pointer
(RSP0) stored in the TSS can be used as a thread identiÔ¨Åer.
Thread Switch Interception Algorithm. Each thread
switch modiÔ¨Åes the TSS stored in memory. Therefore, we can
track thread switches by setting memory access permissions.
SpeciÔ¨Åcally, on a guest system with EPT, a write to an EPT
write-protected address triggers an EPT_VIOLATION VM Exit.
We use this mechanism to track the kernel stack pointer.
Fig. 3B shows the pseudo-code for this algorithm. After
the guest OS Ô¨Ånishes setting up its data structures (e.g., the
CR3 register gets written for the Ô¨Årst time), the algorithm
sets all pages that contain TSS structures (one per vCPU) as
write-protected. Each time a TSS structure is modiÔ¨Åed, the
hypervisor gets notiÔ¨Åed by an EPT_VIOLATION event.
B. System Call Interception
System calls allow user mode processes to invoke kernel
mode functions. At the hardware level, a system call transfers
the CPU from user to kernel mode. That transfer from a lower
2A thread is equivalent to a task in the x86 architecture.
3kthreads reuse the virtual address space of the previously sched-
uled process. All processes in Linux have the same kernel address
range. Windows does not have standalone kernel threads.
17171717
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I: Summary of guest internal events and related VM Exit types
Monitoring Category
Context switch interception (¬ßVI-A)
System call interception (¬ßVI-B)
I/O access interception (¬ßVI-C)
Low-level interception (¬ßVI-D)
Guest event
Process context switch (¬ßVI-A1)
Thread switch (¬ßVI-A2)
Interrupt-based system call (¬ßVI-B1)
Fast system call (¬ßVI-B2)
Programmed I/O
Memory mapped I/O
Hardware interrupt
I/O APIC access
Memory access
Instruction execution
Related VM Exit
CR_ACCESS
EPT_VIOLATION
Architectural Invariant
The CR3 register always points to the PDBA of the running process
Writes to CR registers cause CR_ACCESS VM Exits
The TR register always points to the TSS structure of the running process
TSS.RSP0 is unique for each thread
Software interrupts cause EXCEPTION VM Exits
SYSENTER‚Äôs target instruction is stored in an MSR register
EXCEPTION
WRMSR,
EPT_VIOLATION Write to MSR registers causes WRMSR VM Exit
IO_INST
EPT_VIOLATION
EXTERNAL_INT
APIC_ACCESS
EPT_VIOLATION
EPT_VIOLATION
Execution of I/O instructions (e.g., IN, INS, OUT, OUTS)
Access to memory mapped I/O areas, which are set as protected
Hardware interrupt delivery causes EXTERNAL_INT VM Exits
I/O Advance Programmable Interrupt Controller (APIC) events
Accesses to memory regions with proper permissions cause EPT_VIOLATION VM Exits
Execution of instructions from non-executable regions causes EPT_VIOLATION VM Exits
to higher privilege is strictly checked by the processor: it
must be done through pre-deÔ¨Åned gates. This section describes
techniques to intercept two types of system calls: interrupt-
based system calls and fast system calls.
1) Interrupt-based System Calls: The legacy method for