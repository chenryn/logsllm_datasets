+top.frames[0].document.forms["fug
ulocation"].URL_text.value+(new Da
te()).getTime()+document.cookie;')
;
to 
to 
its  own 
include  a  call 
As  part  of  its  sanitization,  SafeWeb  alters  every  Web 
page 
function 
cookie_munch,  which  is  defined  in  the  context  of  the 
top frame.  This attack simply changes the definition of 
that function, so that every time SafeWeb processes a 
new  page  (whether  the  user  types  it  in  manually  or 
simply  clicks  on  a  link),  this  function  will  be  called, 
and it will grab the current URL and send it off to the 
attacker.    An  attacker  could  also  break  the  actual 
document  (document.body  .innerHTML)  into  pieces 
and use Web bugs to deliver it elsewhere [50]. 
This one-line attack doesn’t work in Internet Explorer, 
because  the  spyware  function  it  creates  is  destroyed 
when  the  frame  content  displaying  it  changes  –  i.e., 
when  the  user  navigates  to  a  new  page.    It  can  be 
generalized  to  work  in  Internet  Explorer,  but  the 
resulting attack is very long, because it includes the full 
HTML source for SafeWeb’s upper frame.  We omit it 
here.    (Our  longer  attack  causes  a  brief  flash  in  the 
upper frame when it first loads.) 
5.3.  DNS attack 
var s = "https://www.safeweb.com.evil
.edu/";
document.images[0].src = s;
When SafeWeb processes the program above, it passes 
the first statement through unchanged and rewrites the 
second statement as follows: 
document.images[0].src = (s)?((s).ind
exOf ('https://www.safeweb.com') =
= 0)?(s):("https://www.safeweb.com
/o/_o(410):_win(1):_base(https://e
vil.edu/):" + (s)):' ';
SafeWeb is checking to see if the string appears to be 
sanitized  or  not.    The  rule  is:  if  it  begins  with 
“https://www.safeweb.com”, then it’s safe, otherwise it 
still  needs  to  be  sanitized.    Our  DNS  attack  succeeds 
because the string does begin that way, but that doesn’t 
mean  that  the  URL  refers  to  the  SafeWeb  site.    By 
controlling the evil.edu domain, we can make the URL 
“https://www.safeweb.com.evil.edu/” 
to  any 
computer we like.   
refer 
This  simple  (and  easily  fixed)  implementation  error 
highlights  the  danger  in  relying  on  a  simple  piece  of 
text as the magic indicator of data that has already been 
sanitized.  
A  non-DNS  attack  that  is  not  so  easily  defeated,  but 
that  has  the  same  effect,  simply  subclasses  String  so 
that its overridden indexOf method always returns 0. 
5.4.  About  paranoid mode 
The only difference between  recommended  mode and 
paranoid  mode  is  in  how  eagerly  the  SafeWeb 
rewriting engine rewrites JavaScript code on the way to 
the browser.  Once a piece of JavaScript code arrives at 
the browser, SafeWeb’s paranoia level has no effect on 
the type of damage that attacking code can inflict.     
javascript:  URLs. 
In paranoid mode, SafeWeb removes references to the 
eval function and many equivalent constructs, such as 
document.write  and 
  SafeWeb 
maintained  that  this  blocked  all  dangerous  JavaScript 
[7].    But  this  approach  amounts  to  making  a  list  of 
known-unsafe  constructs  and  blocking  them.    In  fact, 
the  paranoid  mode  rewriter  considers  the  content  it 
doesn’t understand to be safe.  So in order to mount an 
attack  in  paranoid  mode,  an  attacker  only  needs  to 
think  of  a  way  to  gain  access  to  the  JavaScript 
interpreter that the SafeWeb architects didn’t envision.  
Indeed,  all  of  our  attacks  above  succeed  in  paranoid 
mode.  This approach to safety is in opposition to the 
advice of Venema in [59]: 
"When  a  program  has  to  defend  itself  against 
malicious  data,  there  are  two  ways  to  fix  the 
problem:  the  right  fix  and  the  wrong  fix.  The 
right fix is to permit only data that is known to 
give no problems: letters, digits, dots, and a few 
other symbols… 
"Unfortunately, many people choose the wrong 
fix: they allow everything except the values that 
are known to give trouble. This approach is an 
invitation to disaster." 
than 
If SafeWeb had tackled the problem using this allow-
safe  approach  rather 
the  disallow-  unsafe 
approach,  we  believe  it  would  have  quickly  become 
clear  that  the  toggle  between  recommended  and 
paranoid modes didn’t actually correspond to a choice 
between  faithfulness  and  anonymity.    While  selecting 
paranoid  mode  does  reduce  faithfulness,  it  fails  to 
improve anonymity.  There’s no reason to use it. 
To get an idea of the kind of problem SafeWeb is up 
against in sanitizing JavaScript, consider the following 
snippet: 
self[‘document’][‘write’](‘’);
Keep  in  mind  that  while  this  example  uses  string 
literals  such  as  “document”  and  “write”,  an  attack 
could  instead  compute  those  strings  at  run  time.  To 
prevent the attacking code from reaching the browser, 
SafeWeb would either need to forbid access to the self 
object,  forbid  array  dereferencing,  forbid  function 
calls, or disable the document.write method at run time 
(e.g.,  document.write=  function()  {}  ).    The  latter 
seems 
  But 
JavaScript  is  lexically  scoped;  changing  one  entry 
point  to  a  method  is  not  the  same  as  making  its 
previous  meaning  totally  inaccessible  to  the  running 
program.    Our  getCookieData  attack  in  Section  5.1.2 
illustrates this. 
the  most  promising  approach. 
like 
5.5.  Other direct identification attacks 
Rubin  [38]  and  Yezhov  [64]  first  wrote  about  related 
problems  with  SafeWeb.    Uhley  describes  several 
attacks  as  well  [58],  including  problems  with  event 
handlers,  VBScript,  and  commandeering  SafeWeb 
internal  functions.    We  estimate  that  15-25  distinct 
attacks are known to outsiders by now.  Since we and 
other adversarial investigators  tend to declare victory 
and move on after succeeding in a few different ways, 
these numbers may underestimate the vulnerabilities in 
SafeWeb’s rewriting engine. 
5.6.  The tightrope balance threat  
Configuring an HTTP proxy creates a sort of attraction 
between  HTTP  transactions  and  the  proxy  server, 
wherein all of the components work together to make 
sure that all transactions involve the proxy.  SafeWeb 
has  no  such  drawing  power  and  might  even  be 
considered more of a tightrope than a web.  A user is 
“within”  SafeWeb  only  as  long  as  all  of  the  links 
presented have been rewritten to refer to SafeWeb; if a 
user  clicks  on  any  that  arrive  unsanitized,  then  the 
SafeWeb protection silently slips away.  
For example, a computer with Adobe Acrobat installed 
will generally display PDF files directly within Internet 
Explorer.  But SafeWeb doesn’t sanitize PDF files.  So 
when a user clicks on a URL displayed within a PDF 
file,  Acrobat  will  directly  contact  the  named  host, 
violating anonymity.  Microsoft Office documents can 
leak information in the same way.  The result is a Web 
browser  that  looks  like  SafeWeb,  with  the  logo  and 
standard  buttons  intact,  but  that  completely  bypasses 
the  SafeWeb 
reassurance  without 
assurance. 
system: 
it’s 
5.7.  The rewriter evasion threat 
Our attacks cause malicious code to reach the browser 
even  after  it  is  processed  by  SafeWeb’s  JavaScript 
rewriting  engine.    But  the  problem  of  accurately 
identifying JavaScript content within HTML is known 
to be hard for a third party observer [20,26,29,49,64].  
To recognize JavaScript content, the SafeWeb servers 
have to parse all of the pages requested by their users 
in exactly the same way that the user’s Web browsers 
will later parse the content.  This is difficult not only 
because  of  natural  differences  between  browser 
implementations,  but  also  because  Web  browsers  are 
designed 
to  display  all  manners  of  standards-
noncompliant  content.    Each  discrepancy  between  a 
Web browser’s understanding of a page and SafeWeb’s 
prediction of the browser’s  understanding of the page 
can  lead  to  content  evading  the  rewriter  altogether.  
SafeWeb could have attempted to block all third party 
JavaScript content and their users would still have been 
at  risk  to  attacks  contained  within  such  evasions,  as 
long as JavaScript was enabled at the browser level. 
5.8.  The local identification threat 
it 
to 
expose 
JavaScript 
Our attacks ask the victim’s computer to identify itself 
by  contacting  the  attacker  directly,  but  this  isn’t  the 
only  possible  approach  for  obtaining 
the  victim 
computer’s IP address.  For example, some versions of 
Netscape 
through 
java.net.InetAddress.getLocalHost().getHostAddress(); 
SafeWeb doesn’t interfere at all. This and other known 
methods of grabbing the IP address have been patched 
in  later  browsers  [26,27,51,53].    Scriptable  ActiveX 
objects  might  also  reveal  this  information  in  Internet 
Explorer.    But  whatever  the  secret  is,  once  the 
attacker’s script has possession of it, the game is over.  
Covert  channel  minimization  techniques  are  not  very 
useful  here,  because  they  require  the  censor  to 
carefully manage information representation, and such 
techniques  would  sharply  collide  with  SafeWeb's 
usability  and  faithfulness  requirements.    After  all, 
SafeWeb’s  job  is  to  quickly  relay  Web  material 
between  arbitrary  third  parties.    The  attacker  can  just 
stuff the secret into a URL; SafeWeb will happily wrap 
a request to safeweb.com around it, and then relay that 
URL back to the attacker’s Web server. 
5.9.  A fingerprinting attack 
Using file size and timing signatures, Hintz [22] shows 
how an observer of an encrypted SafeWeb session can 
probably  confirm  a    suspicion  about  the  page  a 
SafeWeb user is visiting. 
6.  Possible remedies 
We  have  seen  SafeWeb’s  requirements  colliding  in  a 
way that breaks both faithfulness and anonymity.  This 
isn’t the only possible outcome, however.   
6.1.  Sacrifice anonymity 
All  of  the  attacks  described  in  this  paper  would  be 
irrelevant if SafeWeb had simply disavowed its claim 
to  anonymity.    The  system  would  probably  still  have 
attracted  and  served  users  with 
its  censorship 
avoidance  properties.    After  all,  anyone  can  tell 
whether that is working: either the content appears or it 
doesn’t.  It would be important, however, to warn users 
that there is a risk that they might be identified while 
using the system.   
An  alternative  is  to  clarify  to  users  that  the  SafeWeb 
system  can  only  protect  their  identity  from  strictly 
passive 
the 
fingerprinting attack of Section 5.9), and that the cost 
of this protection is a sharply pronounced exposure to 
those adversaries willing to lie in wait.   
eavesdroppers 
don’t 
(who 
use 
6.2.  Sacrifice faithfulness 
Another option is to support censorship avoidance and 
anonymity  by  sacrificing  more  faithfulness, 
i.e., 
making  the  system  usable  even  when  JavaScript  and 
cookies  are  disabled  at  the  browser  level.    After  an 
early version of this paper appeared, SafeWeb tweaked 
its system to do precisely this – previously, the system 
did  not  work  at  all  if  JavaScript  was  disabled.    A 
weaker  sacrifice  would  be  to  simply  remove  all 
JavaScript  encountered  in  paranoid  mode,  without 
requiring JavaScript to be disabled in the browser.  But 
usability  would  also  be  affected,  and  the  tightrope 
balance  and  rewriter  evasion  threats  of  Sections  5.6 
and 5.7 would remain. 
6.3.  Sacrifice usability 
Although  it  may  be  a  bit  far-fetched,  SafeWeb  could 
embed  a  JavaScript  parser  of  its  own  design  within 
each Web page.  This parser would itself be written in 
JavaScript  or  some  other  widely  available  scripting 
language (so as to satisfy  no-mods).  SafeWeb  would 
then  arrange  to  deliver  each  untrusted  JavaScript 
program  as  text  input  to  the  parser.    At  run-time,  the 
parser  would  interpret  its  input  program  but  refuse  to 
do  perform  any  operation  that  is  immediately  unsafe 
(such  as  initiating  a  Web  transaction  to  the  “wrong” 
host, or eval()ing a string outside of the parser context).  
This approach doesn’t deal with the tightrope balance 
and  rewriter  evasion  threats  of  Sections  5.6  and  5.7, 
and  is  likely  to  be  slow,  heavyweight,  and  hard  to 
perfect, but it would be a conceptually lovely thought 
experiment  in  a  computability  theory  or  compilers 
class. 
6.3.1. Encrypt the master cookie 
If  SafeWeb  arranged  to  encrypt  the  master  cookie 
under  a  key  known  only  to  the  SafeWeb  server 
whenever  transmitting  it  to  a  browser,  then  attacks 
against 
less 
rewarding.    Some  extra  server  roundtrips  would  be 
required  to  manipulate  the  cookie,  however,  and  this 
might  affect  usability.    Anonymizer.com  uses  an 
encrypted master cookie approach [2]. 
the  master  cookie  would  be  much 
6.4.  Sacrifice no-mods 
right 
could 
ensure 
layer 
network 
from  spilling 
Relaxing  the  no-mods  requirement  makes  it  much 
easier to satisfy the others.   A component installed at 
the 
that 
communications  are  restricted  to  the  SafeWeb  server, 
thus  preventing  our  attacks 
the 
computer’s  IP  address.    Simply  using  the  standard 
HTTP  proxy  mechanism  would  be  a  very  good  start.  
The top frame JavaScript infrastructure  would  still be 
vulnerable  to  spyware  infiltration,  but  without  the 
ability  to  spill  the  IP  address  directly  to  an  attacker’s 
computer, 