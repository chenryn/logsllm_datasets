# Power-Capping Aware Checkpointing: On the Interplay Among Power-Capping, Temperature, Reliability, Performance, and Energy

**Authors:**
- Kun Tang
- Devesh Tiwari
- Saurabh Gupta
- Ping Huang
- Qiqi Lu
- Christian Engelmann
- Xubin He

**Affiliations:**
- Virginia Commonwealth University
- Oak Ridge National Laboratory

## Abstract
Checkpoint and restart mechanisms are widely used in large scientific simulation applications to ensure forward progress in case of failures. However, prior works have not considered the interaction of power constraints with temperature, reliability, performance, and checkpointing intervals. This paper develops a deep understanding of the interplay between power-capping and scientific applications using checkpoint/restart as a resilience mechanism and proposes a new model for the optimal checkpointing interval (OCI) under power-capping. Our study reveals several interesting and previously unknown insights into how power-capping affects reliability, energy consumption, and performance.

## 1. Introduction
The continuous growth in computing capability has expedited scientific discovery and enabled simulations of larger and more complex physical phenomena. However, as the scale of computing increases, so does the likelihood of failures, which can impede the progress of scientific applications. To address this, scientists typically use checkpoint-restart mechanisms to guarantee forward progress in case of failures. While these mechanisms are effective, they also introduce significant I/O overhead, which can hinder scientific productivity, especially at exascale levels where it is estimated that applications may spend over 50% of their total execution time on checkpointing, restarting, and lost work.

The checkpointing process involves a trade-off between performance and I/O overhead. A small checkpointing interval leads to high I/O overhead, while a large interval results in high wasted work if a failure occurs. Finding the optimal checkpointing interval (OCI) is crucial. Previous studies, such as those by Young [10] and Daly [11], [12], have proposed models for OCI, but none have considered the impact of power constraints.

Power consumption is a first-order concern for high-performance computing (HPC) facilities, and efficient operation requires considering power constraints at all layers. Power capping limits the maximum allowable power consumption, potentially affecting temperature, reliability, performance, and energy efficiency. This paper investigates how power capping affects the OCI and the associated trade-offs in temperature, reliability, performance, and energy.

To the best of our knowledge, no prior study has examined the impact of power capping on checkpointing decisions for scientific applications in large-scale HPC environments. Therefore, our goal is to develop an understanding of the interaction between power capping and scientific applications using checkpoint/restart. Our study is based on real-system experiments, analytical models, and statistical techniques, and we make the following contributions:

1. We study the effect of power capping on the compute and checkpointing phases for various scientific applications using the Berkeley Lab Checkpoint/Restart library. We quantify how power capping affects system reliability due to changes in temperature.
2. We propose a new model for the optimal checkpointing interval (OCI) under power capping, deriving OCI for both execution time and energy consumption.
3. We validate our model and present results for a wide range of scenarios, showing that our model is significantly more accurate than previous power-capping-unaware models. Our model results in substantial time and energy savings for both peta- and exa-scale systems, with different checkpointing costs, a wide range of power caps, and for different application and system characteristics.

Our study also provides several previously unknown insights into how power capping affects temperature, reliability, energy consumption, and performance of large-scale leadership applications. These insights have significant implications for data center facilities, researchers focusing on resilience, and end users.

## 2. Related Work
This paper investigates how power capping affects application performance, system reliability, and optimal checkpointing decisions. Power capping can be achieved through Dynamic Voltage and Frequency Scaling (DVFS) or throttling by idle cycle insertion. We use the Intel Power Governor, which utilizes the throttling technique.

Previous studies have explored methods to reduce checkpointing overheads, such as incremental checkpointing schemes and diskless checkpointing. However, none of these works have considered the impact of power capping on checkpointing for large-scale HPC applications.

## 3. Background and Methodology
Our work is modeled after Titan, a supercomputer ranked No. 2 on the Top 500 list, consisting of 18,688 compute nodes and over 700 TB of memory capacity. We use data from the Oak Ridge Leadership Computing Facility, including Titanâ€™s failure log data over two years, to evaluate the impact of our proposed model on various leadership applications.

To study the impact of power capping on the optimal checkpointing interval, we combine experiments, simulations, and model analyses. We obtain performance and temperature data under power capping on small-scale machines, develop our OCI model based on regression analysis, and validate the model through simulations. We also present a case study based on large-scale leadership application runs.

We use the BLCR checkpointing library to perform system-level checkpointing on scientific applications. Performance is measured as the reciprocal of execution time, and each processor runs at full capacity. Librapl and Intel Power Governor are used to profile CPU power consumption and cap package power consumption, respectively. CPU temperature is measured using Linux-monitoring sensors.

## 4. Power Capping Effects on Performance
To determine the optimal checkpointing interval under power capping, we need to understand how power capping affects the execution time of the simulation (computation time), the execution time of checkpointing, and system reliability. In this section, we focus on the first two goals: how power capping affects the performance/execution time of the application computation phase and the checkpointing phase.

We present results that show how different power capping levels affect the execution time of the application computation phase. Figure 1 shows the normalized execution time for a set of scientific benchmarks on two different platforms. We observe that the execution time increases non-linearly across all benchmarks, indicating that power capping significantly affects computation time, though the degree of effect varies across benchmarks and platforms.

To capture this trend mathematically, we fit the normalized execution time under power capping for a given benchmark using an exponential function. The R-squared values of the regression functions are above 0.97, indicating a statistically sound fit. The exponential regression functions can be generalized as Equation 1.

\[ \frac{T_{\text{comp}}(P_i)}{T_{\text{comp}}} = A \times e^{B \times P_i} + 1 \]

where \( T_{\text{comp}} \) represents computation time without power capping, and \( T_{\text{comp}}(P_i) \) denotes the computation time under power cap \( P_i \). The upper and lower bound regression functions for both platforms are shown in Figure 1. These results indicate that both applications and platforms influence the coefficients in the fitted exponential functions. We study the impact of these coefficients in later sections, particularly how they affect the optimal checkpointing interval and total execution time under different power capping scenarios.

[Figure 1: Normalized Execution Time Under Power Capping]

## 5. Conclusion
In this paper, we have developed a comprehensive understanding of the interplay between power capping and scientific applications using checkpoint/restart. We have proposed a new model for the optimal checkpointing interval (OCI) under power capping, which takes into account the effects on execution time and energy consumption. Our model is validated through real-system experiments and simulations, and it demonstrates significant improvements over previous power-capping-unaware models. The insights derived from this work have important implications for data center facilities, resilience researchers, and end users.