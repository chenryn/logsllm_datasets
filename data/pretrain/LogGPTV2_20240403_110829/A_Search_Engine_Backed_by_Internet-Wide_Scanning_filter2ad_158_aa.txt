# A Search Engine Backed by Internet-Wide Scanning

**Authors:**
- Zakir Durumeric†
- David Adrian†
- Ariana Mirian†
- Michael Bailey‡
- J. Alex Halderman†

**Affiliations:**
- † University of Michigan
- ‡ University of Illinois, Urbana Champaign

**Contact:**
- {zakir, davadria, amirian, jhalderm}@umich.edu

## Abstract
Fast Internet-wide scanning has opened new avenues for security research, from uncovering widespread vulnerabilities in random number generators to tracking the evolving impact of Heartbleed. However, this technique still requires significant effort. Even simple questions, such as "What models of embedded devices prefer CBC ciphers?", require developing an application scanner, manually identifying and tagging devices, negotiating with network administrators, and responding to abuse complaints. In this paper, we introduce Censys, a public search engine and data processing facility backed by data collected from ongoing Internet-wide scans. Designed to help researchers answer security-related questions, Censys supports full-text searches on protocol banners and querying a wide range of derived fields (e.g., 443.https.cipher). It can identify specific vulnerable devices and networks and generate statistical reports on broad usage patterns and trends. Censys returns these results in sub-second time, dramatically reducing the effort of understanding the hosts that comprise the Internet. We present the search engine architecture and experimentally evaluate its performance. We also explore Censys’s applications and show how questions asked in recent studies become simple to answer.

## 1. Introduction
Fast Internet-wide scanning has opened new avenues for empirically-driven security research, as evidenced by the recent surge in publications based on the technique (e.g., [1,7–11,13,14,18,19,24–29,38]). While tools like ZMap [20] have reduced the time required for large-scale port scans, collecting meaningful data through Internet-wide scanning remains a specialized and labor-intensive process. Answering simple questions, such as "What fraction of HTTPS servers prefer forward-secret key exchange methods?", can take weeks of implementation and debugging, reducing the time security researchers have to focus on more important questions. 

For example, a researcher would need to develop a high-performance application scanner to make HTTPS connections to hosts listening on port 443, test and fix problems with hosts that do not fully follow the TLS specification, run the actual scan, and then process many gigabytes of resulting data. Before beginning this process, security researchers must negotiate with their institution’s legal and networking teams for permission to conduct the scan, coordinate with their upstream network providers, and later respond to resulting abuse complaints. Many institutions (and independent researchers) lack the network facilities or administrative backing to perform scans. For these reasons, Internet-wide scanning has remained the province of a small number of research groups, which severely limits the applications to which this powerful methodology is applied.

To democratize Internet-wide scanning and enable researchers to efficiently ask questions about how security protocols have been deployed in practice, we have developed Censys, a cloud-based service that maintains an up-to-date snapshot of the hosts and services running across the public IPv4 address space and exposes this data through a search engine and API. Unlike existing scanning tools, which primarily focus on performing host discovery, Censys immediately produces results based on full protocol handshakes, facilitates a community-driven approach to characterizing the growing number of embedded devices and vulnerabilities on the Internet, and requires little or no user preparation.

Censys continually scans the public address space across a range of important ports and protocols to approximate a real-time “bird’s eye view” of the Internet. It validates this data and performs application-layer handshakes using a pluggable scanner framework, which dissects handshakes to produce structured data about each host and protocol. The resulting data is post-processed with an extensible annotation framework that enables researchers to programmatically define additional attributes that identify device models and tag security-relevant properties of each host. We operate Censys transparently and expose data back to the research community. In turn, we encourage external researchers to contribute both application scanners (to scan additional protocols) and annotations (to identify devices or properties) to Censys. This way, Censys automates and centralizes the mechanical aspects of scanning.

Censys exposes data to researchers through a public search engine, REST API, publicly accessible tables on Google BigQuery, and downloadable datasets. The search interface enables researchers to perform full-text searches and query any of the structured fields and tags produced during scanning and post-processing (e.g., 443.https.cipher_suite). It supports full-text searches, regular expressions, and numeric ranges, and queries can be combined with Boolean logic. These queries can be run against a current snapshot of publicly accessible IPv4 hosts, Alexa Top 1 Million websites, and known X.509 certificates. After running a query, users can interactively explore the hosts, sites, and certificates that match their query, as well as generate statistical reports suitable for direct use in research.

As a simple example, Censys can identify the set of hosts in the U.S. that are currently vulnerable to Heartbleed with the query:
```
443.https.heartbleed.vulnerable: true AND location.country_code: US
```
From there, Censys can output a complete list of matching IP addresses and graph the distribution of the most common vulnerable device models. These queries complete in under one second.

To facilitate more complex analysis, we publish raw application handshakes and daily point-in-time snapshots of the structured data. These can be queried using SQL through publicly accessible Google BigQuery tables or downloaded in JSON form. Censys additionally exposes data through a public REST API that allows researchers to export raw query results, fetch statistical data, and view the historical state of specific hosts and networks.

We present Censys’s data collection architecture in Section 3, explain how Censys presents data to researchers in Section 4, and describe our deployment in Section 5. We then illustrate Censys’s potential in Section 6 by showing how it can be applied to easily answer a range of questions from recent security studies, including measuring the impact of POODLE and tracking vulnerable industrial control systems.

Internet-wide scanning has already shown great potential for uncovering security problems and understanding the security of complex distributed systems. By moving scanning to the cloud, Censys dramatically reduces the effort needed to investigate these questions, enabling researchers to focus on asking more important questions rather than on the mechanics of answering them. Further, Censys allows the security community to increase global protocol coverage and provides a tractable solution for understanding the increasing number of embedded devices on the Internet. Simultaneously, it minimizes redundant scanning by research groups and minimizes the incoming network traffic monitored by network operators.

Censys is available free to the public at https://censys.io.

## 2. Good Internet Citizenship
As with any research conducted through active network probing, our work raises important ethical considerations. We carefully considered the impact of our experimental measurements and disclosure of our results. When reasoning about our impact, we considered a variety of stakeholders, from our local institution to Internet service providers and the owners of the remote systems. Although the community has yet to derive robust ethical standards for active measurement, our reasoning was guided by broad ethical principles, such as those embodied in the Menlo Report [5], as well as by the guidelines for ethical scanning set forth in the original ZMap work [20].

We coordinated with network administrators and IT leadership at our department, college, and institution, as well as with our upstream ISP, to ensure that our scans do not adversely impact network operations and that all support centers can route external inquiries to our team. Second, we signaled the benign intent of our activities. All of the scanning hosts have WHOIS records and reverse DNS entries that describe the intent of the scanning. Further, each scanning host runs a simple website on port 80 that describes the goals of the research, including what data we collect and how to contact us. Third, we invite user exclusion requests and respond to requests within 24 hours. Fourth, all scans perform standards-compliant handshakes; we do not send malformed packets or handshakes.

Disclosure of scan data also raises ethical questions, since it exposes information about potentially vulnerable systems. To minimize harms, we deliberately choose to collect and distribute data that is, at least in principle, already publicly visible. Our scanners do not perform login attempts, deploy any exploits, or try to access non-public resource paths. Furthermore, we treat opt-out requests for scanning as a request to be removed from the search index, which allows remote administrators to decide whether or not to be included in Censys’s public interface. Many network operators, after understanding the goals of our measurement work, have responded supportively and invited us to continue scanning them. Finally, it is our hope that by publishing scan data, carefully acquired and properly curated, we can reduce the need for Internet scanning performed by other researchers, and thus reduce the overall burden on destination networks.

In contrast, it is well established that attackers already use Internet-wide scanning to find vulnerable machines from botnets and bullet-proof hosting providers [17]. Thus, systems that are configured to expose data publicly are already at risk. Censys helps level the playing field by enabling legitimate researchers to study and enhance the security of these hosts by providing a source of reliable and ethically collected data.

## 3. Collecting Data
The data that powers Censys is collected through horizontal application scans of the public IPv4 address space, scheduled across a pool of scan workers. In the first step, we perform host discovery scans using ZMap [20], complete application handshakes with responsive hosts using pluggable application scanners, and derive structured fields (e.g., certificate subject or TLS cipher suite) from the handshake. We save and publish the raw handshakes but continue further processing, validating the collected scan data, extracting valuable fields, and annotating handshakes with additional metadata, such as device model and software version, using user-defined annotations.

The structured, annotated data is then streamed to a central database, ZDb, which aggregates the horizontal scan results, pivoting the data and updating comprehensive records describing individual IPv4 hosts, Alexa Top 1 Million websites, as well as maintaining auxiliary collections of all found X.509 certificates and public keys. ZDb streams changes to downstream services and produces publishable point-in-time snapshots of hosts and websites, as well as differential updates to its collection of certificates and public keys.

There are several observations that led to this architecture. First, while horizontal scans measure a single aspect of a service (e.g., whether an HTTPS server supports SSLv3), research questions frequently depend on multiple scans. For example, calculating the percentage of HTTPS servers that support SSLv3 requires a generic TLS scan and an SSLv3 scan. Similarly, a device model may only be identifiable based on its HTTP page, but this information is useful when studying any protocol. Therefore, despite being collected by protocol, data should be grouped by host. Second, our framework needs to be extensible and facilitate community involvement. Much of ZMap’s success is due to user-contributed probe modules, and we believe the same will be true for Censys. This is particularly true for annotating hosts and services given the growing number of embedded devices on the Internet. In turn, Censys needs to operate transparently and provide data back to the community. Third, the number of scans and annotations will grow over time; our architecture should scale linearly to handle this increased load.

### 3.1 Internet-Wide Scanning
In the first step of data collection, we use ZMap [20] to perform single-packet host discovery scans against the IPv4 address space. The hosts found by ZMap seed pluggable application scanners, which perform a follow-up application-layer handshake and produce structured JSON data describing a certain aspect of how a host is configured. Typically, application scanners only perform a single handshake and measure one aspect of how a service is configured. For example, we perform separate horizontal scans and use different pluggable scanners to measure how HTTPS hosts respond to a typical TLS handshake, whether hosts support SSLv3, and whether a host is vulnerable to the Heartbleed attack.

#### Pluggable Scanners
While we can use ZMap to perform host discovery for many protocols, every application scanner requires protocol-specific code, and Censys’s long-term success is dependent on easily adding new protocols. To reduce the effort required to scan new protocols, Censys handles the details of a scan and expects a minimally featured application scanner. Specifically, Censys expects a self-contained Linux executable that performs application-layer handshakes with IP addresses input on stdin and produces structured JSON output that describes how the protocol is configured on stdout. Censys controls network bandwidth by rate limiting the IP addresses provided to scanners, splits scans across multiple scan workers using ZMap’s built-in sharding [2], and guarantees that application scanners do not scan networks that have requested exclusion using ZMap’s blacklist.

To protect our infrastructure, we require that application scanners operate without root privileges or kernel modifications. Lastly, we encourage researchers to output metadata about the scan in JSON form and to log errors in a standard format, which enables Censys to confirm whether a scan completed successfully. We hope that by requiring a minimal feature set and allowing flexibility in language, we not only reduce the effort required for our team to add additional protocols but also encourage an external community that develops new scanners.

#### Scheduling Scans
While it would be technically simplest to measure every aspect of a protocol at once, this frequently involves making multiple handshakes, which could potentially inundate a host (e.g., an embedded device that responds slowly). Therefore, we schedule scans to avoid overwhelming hosts and ensure efficient data collection.