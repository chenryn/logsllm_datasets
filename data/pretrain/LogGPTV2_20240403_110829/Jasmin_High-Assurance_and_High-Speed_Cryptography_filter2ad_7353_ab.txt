formed by the points of carefully chosen elliptic curves over finite
fields. Let Fq be the finite field of prime order q. An elliptic curve is
defined by the set of points (x, y) ∈ Fq × Fq that satisfy an equation
of the form E : y2 + a1xy + a3y = x3 + a2x2 + a4x + a6, for a1, a2,
a3, a4, a6 ∈ Fq (with certain restrictions on these parameters). This
set of points, together with a “point at infinity”, form a group of
size l ≈ q. The group law has a geometric interpretation, which
is not relevant for the purpose of this paper; what is important is
that the group law can be computed very efficiently—particularly
when compared to the computations underlying other algebraic
structures used in public-key cryptography—using only a few op-
erations in Fq. Similarly, scalar multiplication,2 which is the core
operation for elliptic curve cryptography, can also be computed
very efficiently.
Curve25519. X25519 is an elliptic-curve Diffie-Hellman key ex-
change protocol proposed by Bernstein [13]. It is based on the
custom-designed curve Curve25519 defined as E : y2 = x3 +
486662x2 + x over the field F2255−19. This curve was chosen to
2Given a curve point P and a scalar k ∈ Z, scalar multiplication computes the point
Q = k · P = P + . . . + P
k times
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
.
Session H4:  Formal VerificationCCS’17, October 30-November 3, 2017, Dallas, TX, USA1809provide cryptographic security, but design choices also took into
consideration the need for aggressive optimization. As a result of
these choices, Curve25519 has been adopted for widespread use in
various contexts, including the TLS and the Signal protocols.
Scalar multiplication in Curve25519 is usually implemented us-
ing Montgomery’s differential-addition chain—a.k.a. Montgomery
ladder—which permits performing the computation directly over
the x-coordinate of elliptic curve points. This algorithm is shown
in Algorithm 1. It is ideal for high-security and high-speed im-
plementation for two reasons. First, it is much simpler than the
generic algorithm for elliptic curves, so its overall efficiency essen-
tially only depends on the cost of the underlying field operations,
which can be computed very fast in modern architectures. Second,
it is highly regular and can be implemented in constant-time by
executing exactly the same code for each scalar bit (called a lad-
der step), making sure that the appropriate inputs are fed to this
code via (constant-time) swapping of (X2, Z2) with (X3, Z3). The
computations of each step in the ladder, all over Fq, are shown in
Algorithm 2. Typical implementations of the scalar multiplication
operation implement the Montgomery ladder step in fully inlined
hand-optimized assembly, and also include field multiplication and
inversion as hand-optimized assembly routines (these are needed to
recover the final x-coordinate of the result once the ladder is com-
puted). The main difference between various implementations lies
in the representation of F2255−19 field elements and their handling
in the hand-crafted assembly code, as the optimal choice varies
from one architecture to another due to word size and available
machine operations, and their relative efficiency. The higher-level
functions that call the assembly routines for the various ladder
steps and finalize the results are usually implemented in C. This is
inconvenient when formal verification is the goal, since the relevant
routines are now split between two programming languages with
very different characteristics.
Algorithm 1 Curve25519 Montgomery Ladder
Input: A scalar k and the x-coordinate xP of a point P on E.
Output: (XkP , ZkP ) fulfilling xkP = XkP /ZkP
t ← ⌈log2 k + 1⌉
X1 ← xP; X2 ← 1; Z2 ← 0; X3 ← xP ; Z3 ← 1
for i ← t − 1 downto 0 do
if bit i of k is 1 then
else
(X3, Z3, X2, Z2) ← ladderstep(X1, X3, Z3, X2, Z2)
(X2, Z2, X3, Z3) ← ladderstep(X1, X2, Z2, X3, Z3)
end if
end for
return (X2, Z2)
3 JASMIN LANGUAGE
The claim of this paper is that it is possible to obtain the best of
the two worlds, and to develop effective verification methodologies
whose guarantees carry to assembly-level implementations. The
key to achieving this goal is the Jasmin programming language,
which is specifically designed to ease the writing and verification
Algorithm 2 One step of the Curve25519 Montgomery Ladder
function ladderstep(X1, X2, Z2, X3, Z3)
T1 ← X2 + Z2
T2 ← X2 − Z2
T7 ← T 2
2
T6 ← T 2
1
T5 ← T6 − T7
T3 ← X3 + Z3
T4 ← X3 − Z3
T9 ← T3 · T2
T8 ← T4 · T1
X3 ← T8 + T9
Z3 ← T8 − T9
X3 ← X 2
3
Z3 ← Z 2
3
Z3 ← Z3 · X1
X2 ← T6 · T7
Z2 ← 121666 · T5
Z2 ← Z2 + T7
Z2 ← Z2 · T5
return (X2, Z2, X3, Z3)
end function
of high-speed code, and the Jasmin verified compiler, which en-
sures that properties of programs provably carry to their assembly
implementations.
In this section, we detail the design rationale of the Jasmin lan-
guage, and then give a formal overview of its syntax and semantics.
3.1 Language design
Figures 3 and 2 show two illustrative snippets of a Jasmin imple-
mentation of scalar multiplication for Curve25519. This example
highlights one fundamental design goal of Jasmin: one can imple-
ment complete cryptographic primitives within a single language
and use different programming idioms for different parts of the
implementation. On the one hand, the ladder step is implemented
as hand-optimized code, using a convenient and uniform syntax
for instructions. This style of programming is close to qhasm, with
each statement corresponding to a single processor instruction. On
the other hand, the ladder itself uses high-level control-flow struc-
tures, including for and while loops, function calls, array notation
and the passing of arrays as parameters. This style of programming
leads to compact and intuitive code, and also greatly facilitates
safety, side-channel and functional correctness verification. We
detail these choices next.
Predictable pre-assembly programming. Jasmin aims to provide
the highest level of control and expressiveness to programmers.
Informally, the essential property that Jasmin aims to achieve is
predictability: the expert programmer will be able to precisely an-
ticipate and shape the generated assembly code, so as to be able to
achieve optimal efficiency.
Jasmin provides a uniform syntax that unifies machine instruc-
tions provided by different micro-architectures. The main purpose
of this syntax is to ease programming and to enhance portability.
However, platform-specific instructions are also available and can
Session H4:  Formal VerificationCCS’17, October 30-November 3, 2017, Dallas, TX, USA1810Figure 2: Snippets of Jasmin ladder step function (left) gen-
erated from qhasm (right).
export fn ladderstep(reg b64 workp) {
reg b64 addt0;
reg b64 addt1;
reg bool cf;
reg b64 t10;
reg b64 t11;
reg b64 t12;
reg b64 t13;
reg b64 t20;
reg b64 t21;
reg b64 t22;
reg b64 t23;
. . .
t10 = [workp + 4 * 8];
t11 = [workp + 5 * 8];
t12 = [workp + 6 * 8];
t13 = [workp + 7 * 8];
t20 = t10;
t21 = t11;
t22 = t12;
t23 = t13;
cf, t10 += [workp + 8 * 8];
cf, t11 += [workp + 9 * 8] + cf;
cf, t12 += [workp + 10 * 8] + cf;
cf, t13 += [workp + 11 * 8] + cf;
addt0 = 0;
addt1 = 38;
addt1 = addt0 if ! cf;
cf, t10 += addt1;
cf, t11 += addt0 + cf;
cf, t12 += addt0 + cf;
cf, t13 += addt0 + cf;
addt0 = addt1 if cf;
input workp
int64 addt0
int64 addt1
int64 t10
int64 t11
int64 t12
int64 t13
int64 t20
int64 t21
int64 t22
int64 t23
...
enter ladderstep
t10 = ∗(uint64 ∗)(workp + 32)
t11 = ∗(uint64 ∗)(workp + 40)
t12 = ∗(uint64 ∗)(workp + 48)
t13 = ∗(uint64 ∗)(workp + 56)
t20 = t10
t21 = t11
t22 = t12
t23 = t13
carry? t10 += ∗(uint64 ∗)(workp + 64)
carry? t11 += ∗(uint64 ∗)(workp + 72) + carry
carry? t12 += ∗(uint64 ∗)(workp + 80) + carry
carry? t13 += ∗(uint64 ∗)(workp + 88) + carry
addt0 = 0
addt1 = 38
addt1 = addt0 if !carry
carry? t10 += addt1
carry? t11 += addt0 + carry
carry? t12 += addt0 + carry
carry? t13 += addt0 + carry
addt0 = addt1 if carry
be used whenever important, e.g., for efficiency. In particular, and
similarly to qhasm, programmers may always use a Jasmin dialect
where there is a strict one-to-one mapping between Jasmin instruc-
tions and assembly instructions. This is visible in Figure 2, where
we show qhasm and corresponding Jasmin code side by side; these
are snippets of the implementation of the ladder-step algorithm in
Algorithm 2.
Finally, to ensure predictability, the programmer must also spec-
ify the storage for program variables (stack, register) and must han-
dle spilling explicitly. However, full register naming is not needed;
the programmer only needs to ensure that there exists a mapping
from register variables to machine registers (without spilling), but
the actual mapping is later found by the compiler. At the source
level, stack variables and register variables are interpreted simply
as variables; the storage modifier is only used as advice for register
allocation. In particular, at this level the memory is assumed to
be disjoint from stack storage. The compiler will later refine this
model and conciliate the fact that stack data must reside in memory
as well.
Verifiability. Formal verification of low-level code is extremely
hard, because of complex side-effects (e.g. shift instructions have
side-effects on flags), unstructured control-flow, and flat structure
(i.e. code is often created by copy-and-paste followed by variable
or register renaming). Jasmin includes several features that avoid
these issues and enable a streamlined formal verification workflow.
Jasmin ensures that side-effects are explicit from the program
code, by not treating flags specially in the input language; instead,
flags are simply boolean variables. This treatment of flags is illus-
trated in Figure 2, where the carry flag cf is declared as a boolean
variable. The programmer is expected to ensure that writing and
reading of these variables is consistent with the underlying ma-
chine instruction semantics, which is checked by the compiler using
an extended form of register allocation. Treating flags as boolean
variables allows all operators to be pure, and so state modifications
are all explicit, e.g., code of the form (x1, . . . , xn ) := op(e1, . . . , ek )
only changes (function local) variables xi. This approach makes
verification of functional correctness and even side-channel secu-
rity significantly simpler, since it avoids the intricacies of dealing
with the side-effects associated with flags.3
Unlike qhasm, Jasmin supports function calls. The use of func-
tion calls is shown in Figure 3, where two functions are used for
computing a single ladder step and for performing a constant-time
swap. Function calls naturally lead to a style of programming that
favours modularity, and thus is more easily amenable to modular
verification. Functions are always inlined and must explicitly return
all changed values.4 The stack allocation procedure ensures that
inlining is “zero-cost”, so that the extra benefits of modular code
writing and analysis comes with no performance penalty.
Jasmin also supports high-level control-flow structures, instead
of jumps supported by qhasm. The use of control-flow structures
can be seen in Figure 3, where a while loop is used to iterate over
the bit representation of the scalar in constant-time. The choice
of using high-level structures over jumps usually has no impact
on the efficiency of the generated code; indeed, the translation
to assembly, which is achieved by unrolling or trivial mapping to
label-goto constructions, is simple enough to retain predictabil-
ity and our structures are sufficient to express the control-flow
typically found in cryptographic implementations. In contrast, it
considerably simplifies verification of functional correctness, safety
and side-channel security, and is critical to leverage off-the-shelf
verification frameworks, which are often focused on high-level
programs.
Jasmin also supports functional arrays for describing collections
of registers and stack variables. Figure 3 shows how arrays can be
used to refer to various registers/stack positions holding the data
as x[i] rather than hardwired variable names such as x1, x2, etc.
This notation leads to compact and intuitive code and simplifies
loop invariants and proofs of functional correctness. Arrays are
meant to be resolved at compile-time, and so they can only be
indexed by compile-time expressions. These can be used to describe
statically unrollable for loops and conditional expressions, which
permits replicating within the Jasmin language coding techniques
that are typically implemented using macros in C. For example,
one can write a for-loop ranging over the number of limbs for
representing an element of Fq, as in Figure 3 whereas a qhasm
3The exception are, of course, memory accesses, which are handled in the standard
way by treating memory as a large chunk of shared state that can be accessed in
an array-like form. However, memory access is often very simple in cryptographic
implementations (particularly those dealing with algebraic operations) and so this has
relatively low impact in the formal verification effort.
4This is expected to change in future versions of Jasmin.
Session H4:  Formal VerificationCCS’17, October 30-November 3, 2017, Dallas, TX, USA1811Figure 3: Constant-time Montgomery Ladder in Jasmin
}
fn mladder(stack b64[4] xr, reg b64 sp) −→ stack b64[4], stack b64[4] {
fn set_int(reg b64 v) −→ reg b64[4] {
reg b64[4] res;
inline int i;
res[0] = v;
for i = 1 to 3 { res[i] = 0; }
return res;
reg bool cf;
reg b64 tmp1, tmp2, bit, swap, i, j;
stack b64 prevbit, is, js, s;
stack b64[4] x1, x2, z2, x3, z3;
inline int k;
x1 = xr;
x2 = set_int(1);
z2 = set_int(0);