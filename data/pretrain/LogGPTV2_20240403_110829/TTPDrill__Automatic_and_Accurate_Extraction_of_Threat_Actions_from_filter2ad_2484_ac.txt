### Table 3: Classification Results for Techniques Prediction

**Abbreviations:**
- CC = Classifier Chain
- BR = Binary Relevance
- DT = Decision Tree
- T = Tree
- NB = Naive Bayes

| **Method** | **Without Resampling** | **With Resampling** |
|------------|------------------------|---------------------|
| **Micro**  | Precision | Recall | F0.5 | Precision | Recall | F0.5 |
| **Macro**  | F0.5 | Precision | Recall | F0.5 | Precision | Recall |

| **Majority Baseline** | 36.64% | 13.27% | 27.05% | 18.38% | 8.98% | 13.72% |
| **Term Frequency** | 36.64% | 13.06% | 26.98% | 17.70% | 8.44% | 13.19% |
| **CC Adaboost DT** | 39.95% | 5.83% | 18.24% | 23.18% | 18.47% | 22.02% |
| **CC Bagging DT** | 14.82% | 25.59% | 16.16% | 14.96% | 25.96% | 16.33% |
| **CC Ridge Classifier** | 22.44% | 17.94% | 21.31% | 22.87% | 19.22% | 21.98% |
| **CC Decision Tree** | 35.60% | 16.04% | 28.56% | 35.04% | 14.77% | 27.41% |
| **BR AdaBoost DT** | 39.30% | 7.63% | 21.42% | 35.04% | 14.77% | 27.41% |
| **BR Bagging DT** | - | - | - | 25.85% | 11.60% | 20.72% |
| **BR Gradient T Boosting** | 27.60% | 12.67% | 22.31% | 25.85% | 11.60% | 20.72% |
| **BR Ridge Classifier** | 22.87% | 19.22% | 21.98% | 22.87% | 19.22% | 21.98% |
| **BR Linear SVC** | 23.06% | 18.53% | 21.94% | 20.72% | 18.31% | 20.15% |
| **BR Decision Tree** | 16.23% | 14.06% | 15.71% | 14.11% | 12.19% | 13.65% |
| **Adapted Decision Tree** | 12.86% | 10.10% | 12.19% | 12.54% | 9.83% | 11.85% |
| **Adapted Extra Tree** | 12.86% | 10.10% | 12.19% | 12.54% | 9.83% | 11.85% |
| **Term Frequency-Inverse Document Frequency** | 37.06% | 13.06% | 26.98% | 37.06% | 13.06% | 26.98% |
| **Word2Vec average** | 27.88% | 7.34% | 17.68% | 27.88% | 7.34% | 17.68% |
| **Word2Vec sum** | 28.34% | 11.69% | 21.93% | 28.34% | 11.69% | 21.93% |

### Analysis of Text Representation Methods and Classifiers

When comparing the text representation methods, we observe that models using Word2vec (either with a sum or an average of word vectors) generally underperform compared to those using TF (Term Frequency) or TF-IDF (Term Frequency-Inverse Document Frequency) weighting systems. There are minor differences between the average and sum of vectors in the Word2vec approach, but it is not conclusive which method is superior, as the results vary depending on the classifier used.

In terms of classifiers, adapted algorithms tend to underperform compared to classifier chains and binary relevance models for both tactics and techniques predictions. Overall, binary relevance models slightly outperform classifier chain models, suggesting that the relationships between labels may not be as impactful as expected.

For the classification of tactics, the following classifiers perform best, regardless of whether TF-IDF or TF is used:
- AdaBoost Decision Tree
- Gradient Tree Boosting
- Perceptron
- Linear SVC

These classifiers show strong performance in both classifier chain and binary relevance models. Additionally, Bagging Decision Tree, Ridge Classifier, and Logistic Regression also perform well, particularly when used in binary relevance. For classifier chains, Logistic Regression and Bagging Decision Tree perform well with TF weighting, while the Ridge Classifier performs well with TF-IDF weighting.

Similar trends are observed for techniques prediction, with the Decision Tree classifier also performing well in both binary relevance and classifier chain models.