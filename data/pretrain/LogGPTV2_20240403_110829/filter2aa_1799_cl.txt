the entire UEFI runtime services code in VTL 1. Historically, multiple bugs have been discovered in the 
UEFI firmware code (in SMM especially). Mapping the firmware in VTL 1 could be dangerous, but it’s the 
only solution compatible with HVCI. (New systems, as stated before, never map any UEFI firmware code 
in VTL 1.) At startup time, the NT Hal detects that HVCI is on and that the firmware is entirely mapped 
in VTL 1. So, it switches its internal EFI service table’s pointer to a new table, called UEFI wrapper table. 
Entries of the wrapper table contain stub routines that use the INVOKE_EFI_RUNTIME_SERVICE secure 
call to enter in VTL 1. The Secure Kernel marshals the parameters, executes the firmware call, and yields 
the results to VTL 0. In this case, all the physical memory that describes the entire UEFI firmware is still 
360 
CHAPTER 9 Virtualization technologies
mapped in read-only mode in VTL 0. The goal is to allow drivers to correctly read information from the 
UEFI firmware memory region (like ACPI tables, for example). Old drivers that directly write into UEFI 
memory regions are not compatible with HVCI in this scenario.
When the Secure Kernel resumes from hibernation, it updates the in-memory UEFI service table 
to point to the new services’ location. Furthermore, in systems that have the new UEFI firmware, the 
Secure Kernel reapplies the SLAT protection on each memory region mapped in VTL 0 (the Windows 
Loader is able to change the regions’ virtual addresses if needed).
VSM startup
Although we describe the entire Windows startup and shutdown mechanism in Chapter 12, this sec-
tion describes the way in which the Secure Kernel and all the VSM infrastructure is started. The Secure 
Kernel is dependent on the hypervisor, the Windows Loader, and the NT kernel to properly start up. 
We discuss the Windows Loader, the hypervisor loader, and the preliminary phases by which the Secure 
Kernel is initialized in VTL 0 by these two modules in Chapter 12. In this section, we focus on the VSM 
startup method, which is implemented in the securekernel.exe binary.
The first code executed by the securekernel.exe binary is still running in VTL 0; the hypervisor already 
has been started, and the page tables used for VTL 1 have been built. The Secure Kernel initializes the 
following components in VTL 0:
I 
The memory manager’s initialization function stores the PFN of the VTL 0 root-level page-
level structure, saves the code integrity data, and enables HVCI, MBEC (Mode-Based Execution
Control), kernel CFG, and hot patching.
I 
Shared architecture-specific CPU components, like the GDT and IDT.
I 
Normal calls and secure system calls dispatch tables (initialization and compaction).
I 
The boot processor. The process of starting the boot processor requires the Secure Kernel to
allocate its kernel and interrupt stacks; initialize the architecture-specific components, which
can’t be shared between different processors (like the TSS); and finally allocate the processor’s
SKPRCB. The latter is an important data structure, which, like the PRCB data structure in VTL 0, is
used to store important information associated to each CPU.
The Secure Kernel initialization code is ready to enter VTL 1 for the first time. The hypervisor subsystem 
initialization function (ShvlInitSystem routine) connects to the hypervisor (through the hypervisor CPUID 
classes; see the previous section for more details) and checks the supported enlightenments. Then it saves 
the VTL 1’s page table (previously created by the Windows Loader) and the allocated hypercall pages 
(used for holding hypercall parameters). It finally initializes and enters VTL 1 in the following way:
1.
Enables VTL 1 for the current hypervisor partition through the HvEnablePartitionVtl hypercall.
The hypervisor copies the existing SLAT table of normal VTL to VTL 1 and enables MBEC and
the new VTL 1 for the partition.
2.
Enables VTL 1 for the boot processor through HvEnableVpVtl hypercall. The hypervisor initial-
izes a new per-level VMCS data structure, compiles it, and sets the SLAT table.
CHAPTER 9 Virtualization technologies
361
3.
Asks the hypervisor for the location of the platform-dependent VtlCall and VtlReturn hypercall
code. The CPU opcodes needed for performing VSM calls are hidden from the Secure Kernel
implementation. This allows most of the Secure Kernel’s code to be platform-independent.
Finally, the Secure Kernel executes the transition to VTL 1, through the HvVtlCall hypercall. The
hypervisor loads the VMCS for the new VTL and switches to it (making it active). This basically
renders the new VTL runnable.
The Secure Kernel starts a complex initialization procedure in VTL 1, which still depends on the 
Windows Loader and also on the NT kernel. It is worth noting that, at this stage, VTL 1 memory is still 
identity-mapped in VTL 0; the Secure Kernel and its dependent modules are still accessible to the nor-
mal world. After the switch to VTL 1, the Secure Kernel initializes the boot processor:
1.
Gets the virtual address of the Synthetic Interrupt controller shared page, TSC, and VP assist
page, which are provided by the hypervisor for sharing data between the hypervisor and VTL 1
code. Maps in VTL 1 the Hypercall page.
2.
Blocks the possibility for other system virtual processors to be started by a lower VTL and
requests the memory to be zero-filled on reboot to the hypervisor.
3.
Initializes and fills the boot processor Interrupt Descriptor Table (IDT). Configures the IPI,
callbacks, and secure timer interrupt handlers and sets the current secure thread as the default
SKPRCB thread.
4.
Starts the VTL 1 secure memory manager, which creates the boot table mapping and maps the
boot loader’s memory in VTL 1, creates the secure PFN database and system hyperspace, initial-
izes the secure memory pool support, and reads the VTL 0 loader block to copy the module
descriptors of the Secure Kernel’s imported images (Skci.dll, Cnf.sys, and Vmsvcext.sys). It finally
walks the NT loaded module list to establish each driver state, creating a NAR (normal address
range) data structure for each one and compiling an Normal Table Entry (NTE) for every page
composing the boot driver’s sections. Furthermore, the secure memory manager initialization
function applies the correct VTL 0 SLAT protection to each driver’s sections.
5.
Initializes the HAL, the secure threads pool, the process subsystem, the synthetic APIC, Secure
PNP, and Secure PCI.
6.
Applies a read-only VTL 0 SLAT protection for the Secure Kernel pages, configures MBEC, and
enables the VINA virtual interrupt on the boot processor.
When this part of the initialization ends, the Secure Kernel unmaps the boot-loaded memory. The 
secure memory manager, as we discuss in the next section, depends on the VTL 0 memory manager for 
being able to allocate and free VTL 1 memory. VTL 1 does not own any physical memory; at this stage, 
it relies on some previously allocated (by the Windows Loader) physical pages for being able to satisfy 
memory allocation requests. When the NT kernel later starts, the Secure Kernel performs normal calls for 
requesting memory services to the VTL 0 memory manager. As a result, some parts of the Secure Kernel 
initialization must be deferred after the NT kernel is started. Execution flow returns to the Windows 
Loader in VTL 0. The latter loads and starts the NT kernel. The last part of the Secure Kernel initializa-
tion happens in phase 0 and phase 1 of the NT kernel initialization (see Chapter 12 for further details). 
362 
CHAPTER 9 Virtualization technologies
Phase 0 of the NT kernel initialization still has no memory services available, but this is the last 
moment in which the Secure Kernel fully trusts the normal world. Boot-loaded drivers still have not 
been initialized and the initial boot process should have been already protected by Secure Boot. The 
PHASE3_INIT secure call handler modifies the SLAT protections of all the physical pages belonging 
to Secure Kernel and to its depended modules, rendering them inaccessible to VTL 0. Furthermore, it 
applies a read-only protection to the kernel CFG bitmaps. At this stage, the Secure Kernel enables the 
support for pagefile integrity, creates the initial system process and its address space, and saves all the 
“trusted” values of the shared CPU registers (like IDT, GDT, Syscall MSR, and so on). The data structures 
that the shared registers point to are verified (thanks to the NTE database). Finally, the secure thread 
pool is started and the object manager, the secure code integrity module (Skci.dll), and HyperGuard 
are initialized (more details on HyperGuard are available in Chapter 7 of Part 1).
When the execution flow is returned to VTL 0, the NT kernel can then start all the other application 
processors (APs). When the Secure Kernel is enabled, the AP’s initialization happens in a slightly differ-
ent way (we discuss AP initialization in the next section).
As part of the phase 1 of the NT kernel initialization, the system starts the I/O manager. The I/O man-
ager, as discussed in Part 1, Chapter 6, “I/O system,” is the core of the I/O system and defines the model 
within which I/O requests are delivered to device drivers. One of the duties of the I/O manager is to initial-
ize and start the boot-loaded and ELAM drivers. Before creating the special sections for mapping the 
user mode system DLLs, the I/O manager initialization function emits a PHASE4_INIT secure call to start 
the last initialization phase of the Secure Kernel. At this stage, the Secure Kernel does not trust the VTL 0 
anymore, but it can use the services provided by the NT memory manager. The Secure Kernel initializes 
the content of the Secure User Shared data page (which is mapped both in VTL 1 user mode and kernel 
mode) and finalizes the executive subsystem initialization. It reclaims any resources that were reserved 
during the boot process, calls each of its own dependent module entry points (in particular, cng.sys and 
vmsvcext.sys, which start before any normal boot drivers). It allocates the necessary resources for the 
encryption of the hibernation, crash-dump, paging files, and memory-page integrity. It finally reads and 
maps the API set schema file in VTL 1 memory. At this stage, VSM is completely initialized.
Application processors (APs) startup
One of the security features provided by the Secure Kernel is the startup of the application processors 
(APs), which are the ones not used to boot up the system. When the system starts, the Intel and AMD 
specifications of the x86 and AMD64 architectures define a precise algorithm that chooses the boot 
strap processor (BSP) in multiprocessor systems. The boot processor always starts in 16-bit real mode 
(where it’s able to access only 1 MB of physical memory) and usually executes the machine’s firmware 
code (UEFI in most cases), which needs to be located at a specific physical memory location (the loca-
tion is called reset vector). The boot processor executes almost all of the initialization of the OS, hyper-
visor, and Secure Kernel. For starting other non-boot processors, the system needs to send a special IPI 
(inter-processor interrupt) to the local APICs belonging to each processor. The startup IPI (SIPI) vector 
contains the physical memory address of the processor start block, a block of code that includes the 
instructions for performing the following basic operations:
1. 
Load a GDT and switch from 16-bit real-mode to 32-bit protected mode (with no paging enabled).
CHAPTER 9 Virtualization technologies
363
2.
Set a basic page table, enable paging, and enter 64-bit long mode.
3.
Load the 64-bit IDT and GDT, set the proper processor registers, and jump to the OS startup
function (KiSystemStartup).
This process is vulnerable to malicious attacks. The processor startup code could be modified by 
external entities while it is executing on the AP processor (the NT kernel has no control at this point). 
In this case, all the security promises brought by VSM could be easily fooled. When the hypervisor 
and the Secure Kernel are enabled, the application processors are still started by the NT kernel but 
using the hypervisor.
KeStartAllProcessors, which is the function called by phase 1 of the NT kernel initialization (see 
Chapter 12 for more details), with the goal of starting all the APs, builds a shared IDT and enumerates 
all the available processors by consulting the Multiple APIC Description Table (MADT) ACPI table. For 
each discovered processor, it allocates memory for the PRCB and all the private CPU data structures for 
the kernel and DPC stack. If the VSM is enabled, it then starts the AP by sending a START_PROCESSOR 
secure call to the Secure Kernel. The latter validates that all the data structures allocated and filled 
for the new processor are valid, including the initial values of the processor registers and the startup 
routine (KiSystemStartup) and ensures that the APs startups happen sequentially and only once per 
processor. It then initializes the VTL 1 data structures needed for the new application processor (the 
SKPRCB in particular). The PRCB thread, which is used for dispatching the Secure Calls in the context 
of the new processor, is started, and the VTL 0 CPU data structures are protected by using the SLAT. 
The Secure Kernel finally enables VTL 1 for the new application processor and starts it by using the 
HvStartVirtualProcessor hypercall. The hypervisor starts the AP in a similar way described in the begin-
ning of this section (by sending the startup IPI). In this case, however, the AP starts its execution in the 
hypervisor context, switches to 64-bit long mode execution, and returns to VTL 1.
The first function executed by the application processor resides in VTL 1. The Secure Kernel’s CPU 
initialization routine maps the per-processor VP assist page and SynIC control page, configures MBEC, 
and enables the VINA. It then returns to VTL 0 through the HvVtlReturn hypercall. The first routine exe-
cuted in VTL 0 is KiSystemStartup, which initializes the data structures needed by the NT kernel to man-
age the AP, initializes the HAL, and jumps to the idle loop (read more details in Chapter 12). The Secure 
Call dispatch loop is initialized later by the normal NT kernel when the first secure call is executed.
An attacker in this case can’t modify the processor startup block or any initial value of the CPU’s 
registers and data structures. With the described secure AP start-up, any modification would have been 
detected by the Secure Kernel and the system bug checked to defeat any attack effort.
The Secure Kernel memory manager
The Secure Kernel memory manager heavily depends on the NT memory manager (and on the 
Windows Loader memory manager for its startup code). Entirely describing the Secure Kernel memory 
manager is outside the scope of this book. Here we discuss only the most important concepts and data 
structures used by the Secure Kernel.
364 
CHAPTER 9 Virtualization technologies
As mentioned in the previous section, the Secure Kernel memory manager initialization is divided 
into three phases. In phase 1, the most important, the memory manager performs the following:
1.
Maps the boot loader firmware memory descriptor list in VTL 1, scans the list, and determines
the first physical page that it can use for allocating the memory needed for its initial startup
(this memory type is called SLAB). Maps the VTL 0’s page tables in a virtual address that is
located exactly 512 GB before the VTL 1’s page table. This allows the Secure Kernel to perform
a fast conversion between an NT virtual address and one from the Secure Kernel.
2.
Initializes the PTE range data structures. A PTE range contains a bitmap that describes each
chunk of allocated virtual address range and helps the Secure Kernel to allocate PTEs for its
own address space.
3.
Creates the Secure PFN database and initializes the Memory pool.
4.
Initializes the sparse NT address table. For each boot-loaded driver, it creates and fills a NAR,
verifies the integrity of the binary, fills the hot patch information, and, if HVCI is on, protects
each executable section of driver using the SLAT. It then cycles between each PTE of the
memory image and writes an NT Address Table Entry (NTE) in the NT address table.
5.
Initializes the page bundles.
The Secure Kernel keeps track of the memory that the normal NT kernel uses. The Secure Kernel 
memory manager uses the NAR data structure for describing a kernel virtual address range that 
contains executable code. The NAR contains some information of the range (such as its base address 
and size) and a pointer to a SECURE_IMAGE data structure, which is used for describing runtime drivers 
(in general, images verified using Secure HVCI, including user mode images used for trustlets) loaded 
in VTL 0. Boot-loaded drivers do not use the SECURE_IMAGE data structure because they are treated 
by the NT memory manager as private pages that contain executable code. The latter data structure 
contains information regarding a loaded image in the NT kernel (which is verified by SKCI), like the ad-
dress of its entry point, a copy of its relocation tables (used also for dealing with Retpoline and Import 
Optimization), the pointer to its shared prototype PTEs, hot-patch information, and a data structure 
that specifies the authorized use of its memory pages. The SECURE_IMAGE data structure is very 
important because it’s used by the Secure Kernel to track and verify the shared memory pages that 
are used by runtime drivers.
For tracking VTL 0 kernel private pages, the Secure Kernel uses the NTE  data structure. An NTE ex-
ists for every virtual page in the VTL 0 address space that requires supervision from the Secure Kernel; 
it’s often used for private pages. An NTE tracks a VTL 0 virtual page’s PTE and stores the page state and 
protection. When HVCI is enabled, the NTE table divides all the virtual pages between privileged and 
non-privileged. A privileged page represents a memory page that the NT kernel is not able to touch on 
its own because it’s protected through SLAT and usually corresponds to an executable page or to a kernel 
CFG read-only page. A nonprivileged page represents all the other types of memory pages that the NT 
kernel has full control over. The Secure Kernel uses invalid NTEs to represent nonprivileged pages. When 
HVCI is off, all the private pages are nonprivileged (the NT kernel has full control of all its pages indeed).
In HVCI-enabled systems, the NT memory manager can’t modify any protected pages. Otherwise, 
an EPT violation exception will raise in the hypervisor, resulting in a system crash. After those systems 
CHAPTER 9 Virtualization technologies
365
complete their boot phase, the Secure Kernel has already processed all the nonexecutable physical 
pages by SLAT-protecting them only for read and write access. In this scenario, new executable pages 
can be allocated only if the target code has been verified by Secure HVCI. 
When the system, an application, or the Plug and Play manager require the loading of a new run-
time driver, a complex procedure starts that involves the NT and the Secure Kernel memory manager, 
summarized here:
1.
The NT memory manager creates a section object, allocates and fills a new Control area (more
details about the NT memory manager are available in Chapter 5 of Part 1), reads the first page
of the binary, and calls the Secure Kernel with the goal to create the relative secure image,
which describe the new loaded module.
2.
The Secure Kernel creates the SECURE_IMAGE data structure, parses all the sections of the
binary file, and fills the secure prototype PTEs array.
3.
The NT kernel reads the entire binary in nonexecutable shared memory (pointed by the
prototype PTEs of the control area). Calls the Secure Kernel, which, using Secure HVCI, cycles
between each section of the binary image and calculates the final image hash.
4.
If the calculated file hash matches the one stored in the digital signature, the NT memory walks
the entire image and for each page calls the Secure Kernel, which validates the page (each page
hash has been already calculated in the previous phase), applies the needed relocations (ASLR,
Retpoline, and Import Optimization), and applies the new SLAT protection, allowing the page
to be executable but not writable anymore.
5.
The Section object has been created. The NT memory manager needs to map the driver in its
address space. It calls the Secure Kernel for allocating the needed privileged PTEs for describ-
ing the driver’s virtual address range. The Secure Kernel creates the NAR data structure. It
then maps the physical pages of the driver, which have been previously verified, using the
MiMapSystemImage routine.
Note When a NARs is initialized for a runtime driver, part of the NTE table is filled for de-
scribing the new driver address space. The NTEs are not used for keeping track of a runtime 
driver’s virtual address range (its virtual pages are shared and not private), so the relative 
part of the NT address table is filled with invalid “reserved” NTEs.
While VTL 0 kernel virtual address ranges are represented using the NAR data structure, the Secure 
Kernel uses secure VADs (virtual address descriptors) to track user-mode virtual addresses in VTL 1. 
Secure VADs are created every time a new private virtual allocation is made, a binary image is mapped 
in the address space of a trustlet (secure process), and when a VBS-enclave is created or a module is 
mapped into its address space. A secure VAD is similar to the NT kernel VAD and contains a descriptor 
of the VA range, a reference counter, some flags, and a pointer to the Secure section, which has been 
created by SKCI. (The secure section pointer is set to 0 in case of secure VADs describing private virtual 
allocations.) More details about Trustlets and VBS-based enclaves will be discussed later in this chapter.
366 
CHAPTER 9 Virtualization technologies
Page identity and the secure PFN database
After a driver is loaded and mapped correctly into VTL 0 memory, the NT memory manager needs to 
be able to manage its memory pages (for various reasons, like the paging out of a pageable driver’s 
section, the creation of private pages, the application of private fixups, and so on; see Chapter 5 in 
Part 1 for more details). Every time the NT memory manager operates on protected memory, it needs 
the cooperation of the Secure Kernel. Two main kinds of secure services are offered to the NT memory 
manager for operating with privileged memory: protected pages copy and protected pages removal. 
A PAGE_IDENTITY data structure is the glue that allows the Secure Kernel to keep track of all the 
different kinds of pages. The data structure is composed of two fields: an Address Context and a Virtual 
Address. Every time the NT kernel calls the Secure Kernel for operating on privileged pages, it needs 
to specify the physical page number along with a valid PAGE_IDENTITY data structure describing what 
the physical page is used for. Through this data structure, the Secure Kernel can verify the requested 
page usage and decide whether to allow the request. 
Table 9-4 shows the PAGE_IDENTITY data structure (second and third columns), and all the types of 
verification performed by the Secure Kernel on different memory pages:
I 
If the Secure Kernel receives a request to copy or to release a shared executable page of a
runtime driver, it validates the secure image handle (specified by the caller) and gets its relative
data structure (SECURE_IMAGE). It then uses the relative virtual address (RVA) as an index into