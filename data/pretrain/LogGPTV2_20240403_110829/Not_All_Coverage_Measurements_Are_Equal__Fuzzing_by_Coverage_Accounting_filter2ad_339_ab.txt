patterns, but they cause higher overhead due to type inference,
and that input mutation is separate from input prioritization
in our context that could be complementary to our approach.
1) Function Calls
On the function call level, we abstract memory access
operations as the function itself. Intuitively, if a function was
involved in a memory corruption, appearing in the call stack
of the crash, then it is likely that the function will be involved
again due to patch incompleteness or developers’ repeated
errors, and we should prioritize the inputs that will visit this
function.
TABLE I: Top 20 vulnerability involved functions.
Function
memcpy
strlen
ReadImage
malloc
memmove
free
memset
delete
memcmp
getString
Function
vsprintf
Number
80
35 GET_COLOR
17
15
12
12
12
11
10
9
read
load_bmp
huffcode
strcmp
new
getName
strncat
png_load
Number
9
7
7
6
6
6
5
5
5
5
Inspired by VCCFinder [41], we check the information
of disclosed vulnerabilities on the Common Vulnerabilities
and Exposures2 in the latest 4 years to ﬁnd the vulnerability-
involved functions. We crawl the reference webpages on CVE
descriptions and the children webpages, extract the call stacks
from the reference webpages and synthesize the involved
functions. Part of them are shown in Table I (the top 20
vulnerability functions). We observe from this table that the
top frequent vulnerability-involved functions are mostly from
libraries, especially libc, which matches with the general
impression that memory operation-related functions in libc
such as strlen and memcpy are more likely to be involved
in memory corruptions.
Given the vulnerability-involved functions, we assess an
edge by the number of vulnerability-involved functions in the
destination basic block. Formally, let F denote for the set
of vulnerability-involved functions, let dste denote for the
destination basic block of edge e, and let C(b) denote for
the calling functions in basic block b. For an e, we have:
(cid:16)
C(dst e) ∩ F(cid:17)
Func(e) = card
(1)
where Func(e) represents the metric, and card (·) represents
for the cardinality of the variable as a set.
2) Loops
Loops are widely used for accessing data and are closely
related to memory errors such as overﬂow vulnerabilities.
Therefore, we introduce the loop metric to incentivize inputs
that iterate a loop, and we use the back edge to indicate that.
To deal with back edges, we introduce CFG-level instrumen-
tation to track this information, instead of the basic block
instrumentation. We construct CFGs for each module of the
target program, and analyze the natural loops by detecting
back edges [1]. Let function IsBackEdge(e) be a boolean
function outputting whether or not edge e is a back edge.
Given an edge indicated by e, we have the loop metric
Loop(e) as follows:
(cid:26)1, if IsBackEdge(e) = True
(2)
Loop(e) =
0, otherwise
3) Basic Blocks
The basic block metric abstracts the memory operations
that will be executed immediately followed by the edge.
2For prototype, we use CVE dataset, https://cve.mitre.org/
5
As a basic block has only one exit, all instructions will be
executed, and the memory access in this basic block will also
be enforced. Therefore, it is reasonable to consider the basic
block metric as the ﬁnest granularity for coverage accounting.
Speciﬁcally, we evaluate an edge by the number of instruc-
tions that involve memory operations. Let IsContainMem(i)
be a boolean function for whether or not an instruction i
contains memory operations. For edge e with destination basic
block dste, we evaluate the edge by the basic block metric
BB(e) as follows:
(cid:16)(cid:8)i|i ∈ dst e ∧ IsContainMem(i)(cid:9)(cid:17)
BB(e) = card
(3)
Discussion: Coverage accounting design. One concern is
that the choice of the vulnerable is too speciﬁc and heuristic-
based. We try to make it more general by selecting based
on commit history and vulnerability reports, which is also
acceptable by related papers [34, 35, 40, 44]. One may
argue that this method cannot ﬁnd vulnerabilities associated
with functions that were not involved in any vulnerabilities
before or custom functions. This concern is valid, but can
be resolved by the other two metrics in a ﬁner granularity
as the three coverage accounting metrics are complementary.
Moreover, all three metrics contribute to the ﬁnal results of
ﬁnding vulnerabilities (More details in subsection “Coverage
accounting metrics" in Section VI-D).
Another way to select vulnerable functions is code analysis
and there is a recent relevant paper LEOPARD [15] which
is according to the complexity score and vulnerability score
of functions. The score is calculated based on several code
features including loops and memory accesses, which is more
like the combination of all three coverage accounting metrics
we propose. As the paper of LEOPARD mentioned that it
could be used for fuzzing, we set an experiment to compare
with it on our data set (More details in subsection “Coverage
accounting vs. other metrics" in Section VI-D).
IV. THE DESIGN OF TORTOISEFUZZ
On the high-level, the goal of our design is to prioritize
the inputs that are more likely to lead to vulnerable code,
and meanwhile ensure the prioritized inputs cover enough
code to mitigate the issue that the fuzzer gets trapped or
misses vulnerabilities. There are three challenges for the goal.
The ﬁrst challenge is how to properly deﬁne the scope of
the code to be covered and select a subset of inputs that
achieve the complete coverage. Basically AFL’s queue culling
algorithm guarantees that the selected inputs will cover all
visited edges. Our insight is that, since memory operations
are the prerequisite of memory errors, only security-sensitive
edges matter for the vulnerabilities and thus should be fully
covered by selected input. Based on this insight, we re-scope
the edges from all visited edges to security-sensitive only,
and we apply AFL’s queue culling algorithm on the visited
security-sensitive edges. In this way, we are able to select a
subset of inputs that cover all visited security-sensitive edges.
The following challenge is how to deﬁne security-sensitive
with coverage accounting. It is intuitive to set a threshold for
the metrics, and then deﬁne edges exceeding the threshold as
security sensitive. We set the threshold conservatively: edges
are security sensitive as long as the value of the metrics is
above 0. We leave the investigation on the threshold as future
work (see Section VII).
The last challenge is how to make fuzzing evolve towards
vulnerabilities. Our intuition is that, the more an input hits a
security-sensitive edge, the more likely the input will evolve
to trigger a vulnerability. We prioritize an input with hit count,
based on the proposed metrics for coverage accounting.
Based on the above considerations, we decide to design
TortoiseFuzz based upon AFL, and remain the combination
of input ﬁltering and queue culling for input prioritization.
TortoiseFuzz, as a greybox coverage-guided fuzzer with cov-
erage accounting for input prioritization, is lightweighted and
robust to anti-fuzzing. For the ease of demonstration, we show
the algorithm of AFL in Algorithm 1, and explain our design
(marked in grey) based on AFL’s algorithm.
Algorithm 1 Fuzzing algorithm with coverage accounting
1: function FUZZING(P rogram, Seeds)
2:
P ← INSTRUMENT(Program, CovFb, AccountingFb)
(cid:46) Instr.
Phase
3:
// AccountingFb is FunCallMap, LoopMap, or InsMap
INITIALIZE(Queue, CrashSet, Seeds)
INITIALIZE(CovFb, accCov, TopCov)
INITIALIZE(AccountingFb, accAccounting, TopAccounting)
// accAccounting is MaxFunCallMap, MaxLoopMap, or MaxInsMap
repeat
(cid:46) Fuzzing Loop Phase
input ← NEXTSEED(Queue)
NumChildren ← MUTATEENERGY(input)
for i = 0 → NumChildren do
child ← MUTATE(input)
IsCrash, CovFb, AccountingFb ← RUN(P, child)
if IsCrash then
else if SAVE_IF_INTERESTING(CovFb, accCov) then
CrashSet ← CrashSet ∪ child
TopCov, TopAccounting ←
UPDATE(child, CovFb, AccountingFb, accAccounting)
Queue ← Queue ∪ child
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: end function
end if
until time out
end for
CULL_QUEUE(Queue, TopCov, TopAccounting)
A. Framework
The process of TortoiseFuzz is shown in Algorithm 1.
TortoiseFuzz consists of two phases: instrumentation phase
and fuzzing loop phase. In the instrumentation phase (Sec-
tion IV-B), the target program is instrumented with codes for
preliminary analysis and runtime execution feedback. In the
fuzzing loop phase (Section IV-C), TortoiseFuzz iteratively
executes the target program with testcases, appends interesting
samples to the fuzzing queue based on the execution feedback,
and selects inputs for future iterations.
B.
Instrumentation Phase
The instrumentation phase is to insert runtime analysis
code into the program. For source code, we add the analysis
code during compilation; otherwise, we rewrite the code to
insert the instrumentation. If the target requires speciﬁc types
of inputs, we modify the I/O interface with instrumentation.
The inserted runtime analysis code collects the statistics for
coverage and security sensitivity evaluation.
C. Fuzzing Loop Phase
The fuzzing loop is described from line 8 to 23 in
Algorithm 1. Before the loop starts, TortoiseFuzz ﬁrst creates a
sample queue Queue from the initial seeds and a set of crashes
CrashSet (line 4). The execution feedback for each sample is
recorded in the coverage feedback map (i.e., CovFb at line 5)
and accounting feedback map (i.e., AccountingFb at line 6).
The corresponding maps accCov (line 5) and accAccounting
(line 6) are global accumulated structures to hold all covered
transitions and their maximum hit counts. The TopCov and
TopAccounting are used to prioritize samples.
For each mutated sample, TortoiseFuzz feeds it to the
target program and reports if the return status is crashed.
Otherwise, it uses the function Save_If_Interesting to append
it to the sample queue Queue if it matches the input ﬁlter
conditions (new edges or hit bucket change) (line 16). It will
also update the structure accCov.
For the samples in Queue, the function NextSeed selects
a seed for the next test round according to the probability
(line 9), which is determined by the favor attribute of the
sample. If the value of favor is 1, then the probability is 100%;
otherwise it is 1%. The origin purpose of favor is to have a
minimal set of samples that could cover all edges seen so far,
and turn to fuzz them at the expense of the rest. We improve
the mechanism to prioritize mutated samples with two steps,
Update (line 18) and Cull_Queue (line 22). More speciﬁcally,
Update will update the structure accAccounting and return the
top rated lists TopCov and TopAccounting, which are used in
the following step of function Cull_Queue.
1) Updating Top Rated Candidates
To prioritize the saved interesting mutations, greybox
fuzzers (e.g., AFL) maintain a list of entries TopCov for each
edge edgei to record the best candidates, samplej, that are
more favorable to explore. As shown in Formula 4, samplej is
“favor” for edgei as the sample can cover edgei and there are
no previous candidates, or if it has less cost than the previous
ones (i.e., execution latency multiplied by ﬁle size).
 sample j, CovFbj[edge i] > 0
otherwise
0,
∧ (TopCov [edge i] = ∅
∨ IsMin(exec_time j ∗ size j)
(4)
TopCov [edge i] =
Cost-favor entries are not sufﬁcient for the fuzzer to keep
the sensitivity information to the memory operations; hence,
TortoiseFuzz maintains a list of entries for each memory-
related edge to record the “memory operation favor”. As
Formula 5 shows, if there is no candidate for edgei, or if the
samplej could max the hit count of edge edgei, we mark it as
“favor”. If the hit count is the same with the previous saved
one, we mark it as “favor” if the cost is less. The AccountingFb
6
and accAccounting are determined by coverage accounting.
(TopAccounting[edge i] == ∅ ∧ CovFbj[edge i] > 0)
∨ AccountingFbj[edge i] > accAccounting[edge i]
∨ (AccountingFbj[edge i] == accAccounting[edge i]
∧IsMin(exec_time j ∗ size j))
TopAccounting[edge i] =
sample j,
0,
otherwise
(5)
2) Queue Culling
The top-rated candidates recorded by TopAccounting are
a superset of samples that can cover all the security-sensitive
edges seen so far. To optimize the fuzzing effort, as shown in
Algorithm 2, TortoiseFuzz re-evaluates all top rated candidates
after each round of testing to select a quasi-minimal subset
of samples that cover all of the accumulated memory related
edges and have not been fuzzed. First, we create a temporal
structure Temp_map to hold all the edges seen up to now.
During traversing the seed queue Queue, if a sample is labeled
with “favor”, we will choose it as ﬁnal “favor” (line 9). Then
the edges covered by this sample is computed and the temporal
Temp_map (line 10) is updated. The process proceeds until
all the edges seen so far are covered. With this algorithm, we
select favorable seeds for the next generation and we expect
they are more dangerous to memory errors (line 13).
However, TortoiseFuzz prefers to exploring program states
with less breadth than the original path coverage. This may re-
sult in a slow increase of samples in Queue and fewer samples
with the favor attributes. To solve this problem, TortoiseFuzz
uses the original coverage-sensitive top rated entries TopCov to
re-cull the Queue while there is no favor sample in the Queue
(line 15-24). Also, whenever the TopAccounting is changed
(line 5), TortoiseFuzz will switch back to the security-sensitive
strategy.
if TopAccounting[i] && TopAccounting[i].unfuzzed then
q.favor = 0
for q = Queue.head → Queue.end do
TopAccounting[i].favor = 1
UPDATE_MAP(TopAccounting[i], Temp_map)
end for
if IsChanged(TopAccounting) then
Temp_map ← accCov[MapSize]
for i = 0 → MapSize do
Algorithm 2 Cull Queue
1: function CULL_QUEUE(Queue, T opCov, T opAccounting)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25: end function
// switch back to TopCov with coverage-favor
for i = 0 → MapSize do
Temp_map ← accCov[MapSize]
if TopCov[i] && Temp_map[i] then
TopCov[i].favor = 1
UPDATE_MAP(TopCov[i], Temp_map)
end for
SYN(Queue, TopAccounting)
end if
end for
SYN(Queue, TopCov)
end if
else
end if
Discussion: Defending against anti-fuzzing. Current anti-
fuzzing techniques defeat prior fuzzing tools by inserting fake
paths that trap fuzzers, adding a delay in error-handling code,
7
and obfuscating code to slow down taint analysis and symbolic
execution. TortoiseFuzz, along with coverage accounting, is
robust to code obfuscation as it does not require taint analysis
or symbolic execution. It
is also not highly affected by
anti-fuzzing because input prioritization helps to avoid the
execution of error-handling code since error-handling code
do not typically contain intensive memory operation. Also
coverage accounting is robust to inserted fake branches created
by Fuzziﬁcation [28], which the branches are composed of
pop and ret. As Coverage accounting does not consider pop
and ret as security-sensitive operations, it will not prioritize
inputs that visit fake branches.
One may argue that a simple update for anti-fuzzing will
defeat TortoiseFuzz, such as adding memory operations in
fake branches. However, since memory access costs much
more than other operations such as arithmetic operations,
adding memory access operations in fake branches may cause
slowdown and affect the performance for normal inputs, which
is not acceptable for real-world software. Therefore, one has
to carefully design fake branches that defeat TortoiseFuzz
and keep reasonable performance, which is much harder than
the current anti-fuzzing methods. Therefore, we argue that
although TortoiseFuzz is not guaranteed to defend against all
anti-fuzzing techniques now and future, it will signiﬁcantly
increase the difﬁculty of successful anti-fuzzing.
V.
IMPLEMENTATION
TortoiseFuzz is implemented based on AFL [60]. Besides
the AFL original implementation, TortoiseFuzz consists of
about 1400 lines of code including instrumentation (∼700
lines in C++) and fuzzing loop (∼700 lines in C). We also
wrote a python program of 34 lines to crawl the vulnerability
reports. For the function call level coverage accounting, we
get the function names in instructions by calling getCalled-
Function() in the LLVM pass, and calculate the weight value
by matching with the list of high-risk functions in Table I.
For the loop level coverage accounting, we construct the CFG
with adjacency matrix and then use the depth-ﬁrst search
algorithm to traverse the CFG and mark the back edges.
For the basic block level coverage accounting, we mark the
memory access characteristics of the instructions with the
mayReadFromMemory() and mayWriteToMemory() functions
from LLVM [30].
VI. EVALUATION
vulnerabilities?
In this section, we evaluate coverage accounting by testing
TortoiseFuzz on real-world applications. We will answer the
following research questions:
• RQ1: Is TortoiseFuzz able to ﬁnd real-world zero-day
• RQ2: How do the results of TortoiseFuzz compare to pre-
vious greybox or hybrid fuzzers in real-world programs?
• RQ3: How do the results of the three coverage account-
ing metrics compare to other coverage metrics or input
prioritization approaches?
• RQ4: Is coverage accounting able to cooperate with
other fuzzing techniques and help improve vulnerability