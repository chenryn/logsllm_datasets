Figure 1a, with some ISPs as high as 80% and others with 0%.
Moreover, a single ISP’s infection rate often varies by several
orders of magnitude from one week to the next. For example, in
April, 2011 an ISP in Pakistan experienced a more than 800-fold
increase in wickedness in a single week. Previous work has also
observed highly dynamic infection levels in IP space [6, 65].
In spite of this large variation, our analysis shows that wicked-
ness at the individual ISP level is highly autocorrelated, i.e. the
correlation between wickedness in any given week and the previous
week is high (Kendall’s τ =0.93). Kendall’s τ is a non-parametric
measure of statistical dependence. Unlike the more widely used
Pearson’s r, Kendall’s τ does not assume a linear relationship be-
tween the data, and is therefore better able to identify non-linear
relationships, which abound in our data [32].2 This counterin-
tuitive result is explained by the fact that in the vast majority
of cases week-to-week variation is small, even though a minor-
ity of cases break this pattern by varying over several orders
of magnitude. Such high variance can often lead to erroneous
1Alternatively, wickedness could be defined using messages per
customer. We have analyzed the data both ways (data not shown),
with essentially identical results.
2Measures of linear correlation between the lnWi(t) and lnWi(t−1)
are exceptionally high (Pearson’s r = 0.990), suggesting a nonlinear
relationship similar to a power law. This informs the construction
of our model in section 4.
Figure 2: Correlation between wickedness and ISP graph topology.
The vertical axis in all plots shows the Kendall’s τ between
wickedness and the topological measure for the corresponding
week on the horizontal axis. Red indicates significant correlations
at the p<.05 level.
Figure 3: Correlation between wickedness and GDP (top panel),
wickedness and traffic (middle panel), and wickedness and
average regional wickedness (bottom panel). The vertical axis
in all plots is Kendall’s τ between wickedness and traffic during
the week shown on the horizontal axis. Red indicates significant
correlations at the p<.05 level.
conclusions about data. Many statistical methods require that
data have limited variance, and using such methods might indicate
significant changes when none exist [15].
Figure 1b shows several possible qualitative changes in spam vol-
ume, and in subsection 4.2 we find that spam exhibits statistically
significantly different behavior during these periods.
Era 1 : Beginning in 2005, spam increased dramatically until
the first botnet takedowns occurred in 2008. During this time
period spam levels were volatile and punctuated sharp increases
and decreases both globally and at the ISP level.
Era 2 : In mid 2010, spam levels began to drop dramatically
and seemingly permanently. We find a statistically significant
effect in late 2010.
Era 3 : In mid 2012, a spike is observed in the data, followed
by a further decline in wickedness. During this time period the
variance in global wickedness also decreases.
These three eras are highlighted in Figure 1b. In subsection 4.2
we use maximum likelihood techniques to pinpoint when statis-
tically significant transitions occurred and discuss possible causes
of these transitions.
3. RISK FACTORS
The previous section defined wickedness and examined its prop-
erties in our dataset. Next we ask if certain external “risk factors”
are related to an ISP’s level of wickedness. In this section, we
consider demographic factors, the effect of geography, network
effects, and traffic dynamics.
3.1 Demographic Factors
Previous work identified correlations between spam concen-
trations and measures of development, such as Internet use per
capita or education [73, 82]. We find similar results using gross do-
mestic product per capita (GDP). GDP data were obtained from
the World Bank, which produces annual data on a per-country
for multiple demographic factors [3]. We use GDP per Capita
because recent data is readily available, but other measures of
development such as unemployment or corruption within institu-
tions may provide different insights. We used linear interpolation
to infer weekly values from the annual data.
For each week of data, we compute τ between ISP wickedness
and the GDP of the country in which each ISP was operating. The
top panel of Figure 3 shows these correlations over the course of our
520 weeks, and indicates that GDP is consistently negatively cor-
related with wickedness, in agreement with results from previous
studies [73, 82]. In subsection 4.1 we calculate the size of this effect.
The decline in magnitude in correlation seen in the later portions
of the data may indicate that infection rates are becoming less
tethered to development, as technology levels rise across the globe.
3.2 Geographic Clustering
Qualitatively, we observe that wickedness levels cluster in cer-
tain geographic regions during specific periods. For example,
during January, 2011 high levels of wickedness are observed in
Eastern European countries. Roughly a year later, Eastern Eu-
rope experienced lower levels of wickedness while there were higher
concentrations in Southeast Asia3.
To study this geographic clustering, we divide the world into
14 regions, as defined by the United Nations [56], and measured
the correlation between the wickedness of an ISP and the average
wickedness of all other ISPs in the same region (excluding the
original ISP) in the previous week.
We find significant positive correlations between this value and
wickedness throughout most of the data (see Figure 3). We study
this result more in depth in section 4.
3.3 Autonomous System Topology
Another possible risk factor is an ISP’s position in the topo-
logical structure of the Internet at the Autonomous System (AS)
routing level. To investigate the strength of this effect, we mea-
sured the correlation between wickedness and several popular
topological metrics [14]. This is not straightforward, however,
because our data were collected at the ISP level, and connectivity
between ISPs is not identical to Autonomous System connectivity.
We address this problem by constructing a hybrid network that
reflects both topologies.
We constructed this new network by beginning with the AS
level, retrieving AS network data from the Internet Research
3Map not shown due to space constraints
Lab’s Internet AS-Level Topology Archive.4 The archive collects
daily and monthly snapshots of AS-level topology from a number
of different sources and, at the time of download on February 11,
2015, was one of the most complete publicly available sources of
the AS-level Internet topology [58]. We construct the ISP graph
using the following steps:
1. Aggregate nodes: Combine all ASNs owned by a single ISP
into a single node. This produces a graph that contains
both ISP nodes and ASN nodes.
2. Aggregate edges: If there are multiple edges between two
nodes, combine them into a single weighted edge, with
weight equal to the number of connections between the
nodes.
3. Remove stubs: Remove ASN nodes that are not directly
connected to an ISP and have degree equal to one.
4. Combine the daily version of the graph into a weekly snap-
shot by taking the graph union.
We remove stub ASes because they likely have little real-world
influence on traffic flow in the ISP graph [48].
Using this hybrid graph, we investigated the correlation be-
tween ISP wickedness and a number of popular measures of graph
topology [14]. In total we tested eight different measures.
Figure 2 shows the correlation between wickedness and the
six of the eight topological features we tested. Three features
are significantly correlated with wickedness throughout the study
period (top two panels, and middle right panel): an ISP’s location
within the Internet hierarchy(Core Number and Average Short-
est Path Length) and centrality (weighted degree). Weighted
degree is correlated for the majority of time steps (middle right
panel), excluding the early part of the time series, a few weeks
in 2010 and 2011, and late in the data. By contrast, between-
ness centrality and clustering coefficient do not show significant
correlation throughout the time series, while page rank is only
correlated roughly one third of the time. The correlations that
do exist show that in general ISPs with high centrality (degree),
tend to have low wickedness, while ISPs on the periphery of the
network (low core number, high average shortest path length),
have higher wickedness values. It is not clear why this is the case;
one possibility is that ISPs on the edge of the network tend to
be smaller and thus have fewer resources to counter infections.
ASNs are often categorized based on the type of services they
provide [11], and this could influence the amount of wickedness
present in a given ISP. We did not include this factor in our
analysis because each ISP could be an aggregation of multiple
ASNs, and consequently, clear categorizations of the services
provided by an ISP are difficult to ascertain. Moreover, since our
data on subscriber numbers is at the ISP level, we cannot easily
allocate it to different ASNs.
3.4 Network Trafﬁc Dynamics
Traffic dynamics affect the concentration of malicious hosts [25],
but appropriate network traffic datasets are not publicly available.
Numerous models of traffic flow have been proposed for the AS
network, ranging from simple [64] to elaborate [5], and for this
study we adapted Roughan et al.’s gravity model [64] to simulate
malicious traffic between nodes in the ISP graph. In the gravity
model, the traffic received by node i from j is expressed as:
rij =
CiCj
d2
ij
(2)
where Ci is the number of customers for ISP i, and dij is the
shortest path length between the two ISPs in the ISP graph.
We assume that malicious traffic is proportional to the total
traffic received by an ISP i, and then calculate the expected per
customer rate of malicious traffic:
4http://irl.cs.ucla.edu/topology/ipv4/daily/.
(cid:80)
j(cid:54)=iRijWj
Ci
Ri =
(3)
where Wj is the concentration of spam-emitting IP addresses at
ISP j and Rij is fraction of j’s traffic destined for i (normalized
rij). Normalizing by Ci allows us to interpret Ri as the expected
fraction of malicious traffic received by each customer of ISP i.
We test whether this calculated value correlates with wickedness
in the same way we did for the topological factors, except we
consider time by introducing a one time-step lag between the
two series. This allows us to identify possible causal relationship
between traffic and wickedness[22], as shown in the top panel of
Figure 3. The figure shows that there is a statistically significant
positive correlation through time. This indicates that the flow
of malicious traffic, in particular, the amount of malicious traf-
fic received per customer in the previous week, correlates with
increased wickedness in the next week.
4. MODELING
In the previous section we identified external factors that are in-
dividually correlated with wickedness. In this section, we develop
an autoregressive model that incorporates and combines these
factors. We then use the model to explore the relative strengths
of these effects and identify the transitions between spam eras.
4.1 Autoregressive Model
An autoregressive model is a type of linear regression, which
uses previous values in a time series to predict future values.
We have already discovered in subsection 2.2 that our dataset is
highly autocorrelated, which justifies this model selection, and
we include the external risk factors identified in section 2.
Visual inspection of the data reveals an obvious drop-off in
wickedness levels somewhere after 2010. We incorporated this
observation into the model by hypothesizing up to three distinct
temporal eras. In each era y, the wickedness of ISP i at time t
is modeled as:
ln(Wi,y(t))=β0,yln(Wi(t−1))+β1,yln(Ri(t−1))+
β2,yln(Gi(t−1))+β3,yln(Ei(t))+
β4,yPi(t)+β5,yln(Di(t))+y
(4)
Each symbol in Equation 4 is described in Table 1. In section
subsection 3.3 we found that both average shortest path length
and core number are correlated with wickedness. However, these
two measures are highly correlated with each other, and including
both metrics in the model could cause estimates of βx,y to be
incorrect [79], so we selected average path length.
All autoregressive models include a distribution of error terms,
here represented by , and they are usually assumed to be nor-
mally distributed [79]. In our case, given the high variance of
the data (section 2), we assume y∼T (ν,σ), where T (ν,σ) is the
non-standardized Student’s T distribution, which is considered
to be more appropriate when a dependent variable has high
variance [79] which we observed in section 2.
In the model some variables are log transformed because prelim-
inary inspection revealed that their functional relationships were
non-linear in particular ways (i.e. roughly linear on log/log plots).5
4.2
Identifying Model Transitions
In section 1 we noted that the data experiences several possible
qualitative changes, and that they may correspond to changes
in spam tactics or the development of new spam fighting tools.
However, it is unclear exactly when these changes might have
5We speculate that the log/log relationship between Wi(t) and
Wi(t−1), may arise from an underlying growth or decay process in
malware infected hosts.
Table 1: Coefficients for the autoregressive model. Range indicates the range of possible values for each variable. Bold coefficients
are statistically significant at the p<0.01 level.
Variable
Symbol βi,y Range
Jan 2005-Dec 2010 Dec 2010-June 2012 June 2012-Dec 2014
Era 1
Era 2
Era 3
Log Prev Wickedness
Log Prev Wicked Traffic
Log Prev Region Wickedness ln(Gi(t-1)) β2,y
β3,y
Log GDP per capita
β4,y
Shortest Path Length
Log Weighted Degree
β5,y
ln(Wi(t-1)) β0,y
[-18.1,0.26]
ln(Ri(t-1)) β1,y [-29.4,-10.4]
[-13.3,-2.1]
[6.5,11.7]
[0.0,8.2]
[2.7,4.9]
ln(Ei(t))
Pi(t)
ln(Di(t))
R2
occurred. Rather than pre-define transitions between eras based
on industry reports or qualitative evaluations of the data, we used
the model to determine the most likely dates when significant
changes in spam concentrations occurred, testing for zero, one,
or two significant transitions.
For each possible combination of two transition dates, we use
maximum likelihood estimation (MLE) to estimate the values for
all βx,y and their standard errors. We then selected transition
dates which gave the model the highest likelihood.
To measure whether dividing the data into three eras is justified,
we compared the model to one with a single division into two
eras, and one with no divisions. We used the Akaike Information
Criteria (AIC)[79], which is a measure of goodness of fit based
on likelihood that penalizes more complex models. We found
a statistically significant improvement between the model with
two divisions and models with a single or no divisions. It is also
possible that there are more statistically significant transitions
in the data than we were able to test for due to computational
constraints. We leave this topic for future investigation.
The first change identified by our methodology begins in Decem-
ber 2010, after which we see a steady decline in spam levels. This
may be due to the increasing efficacy of adaptive, real-time filtering,
although filtering systems were first deployed at companies such
as Google as early as 2006 [71]. There is evidence that improved
filtering forced spammers to deploy new more costly methods
of spamming, such as large-scale account hacking [21]. Filtering
even impacted delivery of legitimate bulk email in the first half of
2011 [59]. Microsoft’s Security Intelligence Report attributes the
decline in 2011 to both more sophisticated filtering techniques,
and to the takedown of the Cutwail and Rustock botnets [50].
We identify a second transition beginning in June 2012. In
May, 2011 Kanich et al. published a paper which identified a
handful of banks that were responsible for processing most of the
payments made by spam victims [29]. Shortly after the paper
was published, Visa tightened requirements for merchants, and