title:Engineering Fault-Tolerant TCP/IP Servers Using FT-TCP
author:Dmitrii Zagorodnov and
Keith Marzullo and
Lorenzo Alvisi and
Thomas C. Bressoud
Engineering Fault-Tolerant TCP/IP Servers Using FT-TCP ∗
Dmitrii Zagorodnov
†
Keith Marzullo
University of California, San Diego
Computer Science & Engineering
9500 Gilman Dr (MC 0114)
La Jolla, CA 92037 USA
{dzagorod,marzullo}@cs.ucsd.edu
†
†
Lorenzo Alvisi
‡
Thomas C. Bressoud
§
‡
The University of Texas at Austin
Department of Computer Science
1 University Station C0500
Austin, TX 78712 USA
PI:EMAIL
Denison University
225a Olin Hall
§
Granville, OH 43023 USA
PI:EMAIL
Abstract
In a recent paper [2] we have proposed FT-TCP: an ar-
chitecture that allows a replicated service to survive crashes
without breaking its TCP connections. FT-TCP is attrac-
tive in principle because it does not require modiﬁcations
to the TCP protocol and does not affect any of the software
running on the clients; however, its practicality for real-
world applications remains to be proven. In this paper, we
report on our experience in engineering FT-TCP for two
such applications—the Samba ﬁle server and a multime-
dia streaming server from Apple. We compare two imple-
mentations of FT-TCP, one based on primary-backup and
another based on message logging, focusing on scalabil-
ity, failover time, and application transparency. Our ex-
periments suggest that FT-TCP is a practicable approach
for replicating TCP/IP-based services that incurs low over-
head on throughput, scales well as the number of clients in-
creases, and allows recovery of the service in near-optimal
time.
1. Introduction
Consider a company that provides a TCP-based service
on a large intranet or the Internet. The service is important;
if it fails, then it needs to be restarted in a timely manner.
∗
Alvisi was supported in part by the National Science Foundation (CA-
REER award CCR-9734185), an Alfred P. Sloan Fellowship, a grant from
the Texas Advanced Technology Program, and the AFRL/Cornell Informa-
tion Assurance Institute. Marzullo and Zagorodnov were supported in part
by the AFOSR MURI grant 411316865 and by the DARPA grant N66001-
01-1-8933
There are some constraints the company might face when
deciding how to provide service failover:
• If the client base is large and diverse, then the most
important constraint can be the lack of control over the
client host conﬁguration and the applications running
on the host. This means that client applications can not
be expected to help in the failover of the service.
• While service outages can have a large impact on a
company’s business, service outages are rare. Hence,
the failover approach should incur a low cost in terms
of performance of the server during periods of time
when there are no failures.
• Deploying the failover approach should have a low im-
pact on the design and installation of the service, since
changes in server platforms, upgrading failover soft-
ware, and deploying new services can be costly. Since
this is an ofﬂine cost, though, it can be less important
than the ﬁrst two constraints.
• Depending on the service, failover time might need to
be rapid. For example, a client playing a QuickTime
movie would experience visualization problems if the
failover lasts too long.
Many companies marketing high-end server hardware
these days—IBM, Sun, HP, Veritas, Integratus—offer fault-
tolerant solutions for TCP-based servers. They are usually
built using a cluster of servers interconnected with a fast
private network which is used for access to shared disks,
for coordination, and for failure detection. Clients notice
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:01:39 UTC from IEEE Xplore.  Restrictions apply. 
when a server they are connected to fails, but if they were to
open another connection they would reach a healthy server.
It is often desirable to hide server failures from the
clients. One reason is that the client may have state asso-
ciated with the open TCP connection to the server; losing
the connection may require the client to redo a signiﬁcant
amount of work. For example, a client with a connection
to an Oracle server will abort all open transactions if the
server fails over. A similar case occurs with existing Samba
clients: when a Samba server fails, all transfers are aborted
and the user must explicitly restart the transaction.
We have previously shown that it is possible to hide
server failures from clients [2]. We did this by building
FT-TCP, which is a failover service based on message log-
ging [6]. We evaluated the performance of FT-TCP for a
synthetic application consisting of a single client having one
connection open to the server. In this paper, we argue that
FT-TCP can be made practicable. We show that:
• While it was necessary to modify the code of two ex-
isting services to have them be recoverable using FT-
TCP, the modiﬁcations were few.
• The failure-free overhead of FT-TCP is very low and
the system does not have inherent scalability problems.
• A primary-backup [4] version of FT-TCP performs al-
most indistinguishably from a message logging ver-
sion and has the beneﬁt of a shorter failover time.
• The failover time of FT-TCP can be made very short,
but to do so requires the backup to capture the data sent
by the client immediately before the server failed.
We compare FT-TCP to other possible approaches and
already existing systems in Section 2. Architecture of
the system—primary-backup as well as message-logging
versions—is presented in Section 3. Our experience with
getting two popular applications to run under FT-TCP is de-
scribed in Section 4. Performance during normal operation,
as well as behavior of FT-TCP during failover are presented
in Section 5. Conclusions are drawn in Section 6.
2. Related Work
One can categorize solutions to the problem of connec-
tion failover according to the level at which server failures
are masked. With application-level recovery the failures are
masked from the user by the client application that attempts
to reestablish broken connections. An FTP client that au-
tomatically restarts aborted transfers is an example of such
recovery. NFS and Samba clients also fall in this category
because in many cases they can recover from short discon-
nections transparently. Since the client needs to be explic-
itly designed to support application-level recovery, this ap-
proach is inapplicable to the already deployed applications.
Several projects have explored the idea of socket-level re-
covery, where the failure is hidden from the client by some
lower layer that reestablishes connections when necessary
and provides a reliable socket to the application. One such
system [11] extends the TCP protocol with an option that
enables migration of connections from one host to another.
Among other things, this allows the service provider to ask
the client TCP stack to migrate a failed connection to a
backup. A similar approach was adopted by [12], but it re-
quires the server application to be aware of the replication.
The system described in [7] enables transparent recon-
nection in Windows NT without changing the TCP stack
by wrapping the socket standard library routines. This sys-
tem was designed to support process migration, but can be
used for fault tolerance as well. The system described in [8]
applied a similar wrapping technique to the standard C li-
brary on Linux to mask server failures. They evaluated the
feasibility of having the backup snoop on packets sent to
the primary and concluded that such a system would not
have signiﬁcant overhead. Another system based on wrap-
ping is described in [13], although their goals were to mask
connection failures due to network problems rather than
server crashes. This last paper describes two approaches
to connection recovery, one of which relies on the intercep-
tion of packets, just like our system. The main drawback
of socket-level recovery is that it requires upgrading some
of the infrastructure—operating system, protocol stack, or
middleware—on the client host.
Server-side recovery restricts the fault-tolerance logic to
the server cluster. This is the easiest solution to deploy:
as soon as the servers are fault-tolerant, then any client can
beneﬁt from greater reliability. Our earlier work [2] demon-
strated the feasibility of efﬁcient server-side recovery. This
work expands on that by evaluating our approach with two
well-known replication techniques and for two real-life ap-
plications.
The authors of [1] share our philosophy of server-side re-
covery. They have developed a protocol similar to ours that
is specialized to HTTP request/reply pairs. In doing so, they
are able to avoid the problem of server nondeterminism.
Another TCP server-side recovery approach is described in
[10], which proposes using several router-level redirectors
scattered across the Internet to fan out packets to several
geographically-distributed replicas. While deploying redi-
rectors may be a costly endeavor, this system has the beneﬁt
of tolerating WAN partitions in addition to failures that are
local to the server.
3. Architecture
In this section, we ﬁrst introduce several concepts that
are relevant to discussion of server-side recovery. We then
describe the structure and operation of FT-TCP.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:01:39 UTC from IEEE Xplore.  Restrictions apply. 
3.1. Replication Concepts
To enable recovery of a network service every connec-
tion must be backed by a number of server replicas: a pri-
mary server and at least one backup. Should the primary
fail, the backups must have all the information needed to
take over the connection. Several general approaches to
coordinating replicas have been considered by the research
community; FT-TCP supports two of them.
In the ﬁrst approach, called primary-backup [4], every
replica processes client requests and when everyone is done
then one of them (the primary) replies. If the primary fails,
one of the backup replicas is chosen as the new primary. In
the second approach, called message logging [6], only one
replica is active at a time and all requests from the client are
saved in a log that can survive failures. Just like in the ﬁrst
approach, the primary does not reply until it knows that all
prior requests have been logged. If a failure occurs, another
replica replays messages from the log to bring it to the pre-
failure state of the primary.
To make the terms more consistent, we refer to these two
approaches as hot backup and cold backup, respectively.
In both approaches the primary waits before replying to a
client until it knows that the backup could be recovered to
the primary’s current state. This is commonly referred to
as output commit problem [6]. We henceforth refer to these
forced waiting periods as output commit stalls. Note that,
when a backup takes over, it does not know whether the
primary failed before or after replying to the client. Fortu-
nately, TCP was designed to deal with duplicate packets, so
when in doubt the backup can safely resend the reply.
Another issue that comes up in the context of replicated
processes is nondeterministic execution. For both hot and
cold backups, the execution paths of the primary and the
backups must match. If they do not, a backup may never
reach the state of the primary and therefore will not be able
to take over the connection.
We discuss how we deal with sources of nondeterminism
that cause execution path diversions in the next two sec-
tions.
3.2. FT-TCP System
FT-TCP is implemented by “wrapping” the TCP/IP
stack. By this, we mean that it can intercept, modify, and
discard packets on their way in and out of the TCP/IP stack
using a component we call the south-side wrap or SSW. FT-
TCP can also intercept and change the semantics of system
calls made by the server application using a component we
call the north-side wrap or NSW. Both wraps on the primary
replica place some data into a stable buffer that is designed
to survive crashes.
In our case, the buffer is located in physical memory of
the backup machines, but other approaches—such as sav-
ing data on disk or in non-volatile memory—are possible.
In addition to saving data, a stable buffer can acknowledge
Primary
Server
NSW
TCP/IP
SSW
Client
Packet & 
System call
Stable Buffer
Backup
Server
NSW
TCP/IP
SSW
Figure 1. FT-TCP Architecture
the pieces of data it receives, as well as send them back in
FIFO order. In the rest of the paper we will use a setup with
one backup (and therefore one stable buffer, located on that
backup), but our technique can be extended in a straightfor-
ward way to use any number of backup hosts. The setup is
shown in Figure 1.
3.2.1 Normal Operation
During normal operation the SSW sends incoming pack-
ets to the backup and the NSW does the same with results
of system calls (syscalls) that the application makes. Ev-
ery attempt to send data to the client is suspended until all
syscalls have been acknowledged. Fortunately, it is not nec-
essary to wait for backup to acknowledge packets. Because
TCP buffers outgoing data on the sender until the receiver
acknowledges it, we can effectively have client store pack-
ets until the backup has them by never acknowledging to
the client more than was acknowledged by the backup. Our
earlier paper [2] discusses in detail how FT-TCP manipu-
lates TCP sequence numbers to achieve this. Any packets
lost in a failure will be resent through the standard TCP re-
transmission mechanism.
With a cold backup, nothing besides saving incoming re-
quests in the stable buffer and acknowledging them is hap-
pening on the backup host. A hot backup, on the other hand,
runs its own copy of the server process and provides that
process with data that it removes from the stable buffer. To
establish a connection, FT-TCP on the backup removes a
buffered SYN packet, changes the destination address on
that packet to its own address and injects it into its TCP
stack. The stack replies with a SYN+ACK packet, which is
caught and acknowledged with an ACK packet by the SSW.
This 3-way handshake is not visible outside the backup
host, but its TCP thinks it just received a connection from
the client.
Up at the application level, the call to accept() returns
and the server process (on both replicas) proceeds to service
the incoming connection. As the process on the primary
host makes syscalls, their results are sent to the backup.
When a backup process makes a syscall, FT-TCP uses the
corresponding syscall record from the primary to do one of
several things:
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:01:39 UTC from IEEE Xplore.  Restrictions apply. 
• For calls that query the environment – such as
gettimeofday() and getpid() – the backup
immediately returns the result that the primary got;
• For a send(), the backup ignores the actual data
passed by the server application and simply returns the
result that the primary got. For debugging, the buffers
returned by the backup and the primary (or their check-
sums) can be compared to ﬂag any inconsistencies;
• For a recv(), the backup waits until all necessary
data packets are in the stable buffer, copies the same
number of bytes as the primary got, and returns the
same result;
• For the two calls that return socket status – select()
and poll() – the backup returns the value from the
primary (if a timeout was speciﬁed, then the backup
invocation will block until the same call on the primary
times out);
• For all others, the backup executes the call and com-
pares its result to what the primary got. Any inconsis-
tencies are ﬂagged as a potential diversion in execution
paths.
The ﬁrst category of calls takes care of simple sources of
nondeterminism such as different clock values on the repli-
cas and different attributes of their process environments.