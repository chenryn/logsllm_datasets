We will apply Principal Component Analysis (PCA) to our link data matrix \( Y \), treating each row of \( Y \) as a point in \( \mathbb{R}^m \). However, before applying PCA, it is necessary to adjust \( Y \) so that its columns have zero mean. This step ensures that the PCA dimensions capture true variance and avoids skewing results due to differences in mean link utilization. For the rest of this paper, \( Y \) will denote the mean-centered link traffic data.

Applying PCA to \( Y \) yields a set of \( m \) principal components, \(\{v_i\}_{i=1}^m\). The first principal component \( v_1 \) is the vector that points in the direction of maximum variance in \( Y \):

\[
v_1 = \arg \max_{\|v\|=1} \|Yv\|
\]

where \(\|Yv\|^2\) is proportional to the variance of the data measured along \( v \). Iteratively, once the first \( k-1 \) principal components have been determined, the \( k \)-th principal component corresponds to the direction of maximum variance in the residual. The residual is the difference between the original data and the data mapped onto the first \( k-1 \) principal axes. Thus, we can write the \( k \)-th principal component \( v_k \) as:

\[
v_k = \arg \max_{\|v\|=1} \left\| \left( Y - \sum_{i=1}^{k-1} Yv_i v_i^T \right) v \right\|
\]

An important use of PCA is to explore the intrinsic dimensionality of a set of data points. By examining the amount of variance captured by each principal component, \(\|Yv_i\|^2\), we can determine whether most of the variability in the data can be captured in a lower-dimensional space. If we find that only the variance along the first \( r \) dimensions is non-negligible, then we can conclude that the point set represented by \( Y \) effectively resides in an \( r \)-dimensional subspace of \( \mathbb{R}^m \).

In Figure 2, we plot the fraction of total variance captured by each principal component of \( Y \) for all three of our datasets. This plot reveals that even though both networks have more than 40 links, the vast majority of the variance in each link timeseries can be well captured by 3 or 4 principal components. This low effective dimensionality of link timeseries is consistent with the finding that the underlying OD flows themselves have low intrinsic dimensionality [16]. In fact, the low effective dimensionality of link traffic forms the basis for the success of the subspace methods we describe in the following sections.

### 4.3 Subspace Construction via PCA

Once the principal axes have been determined, the dataset can be mapped onto the new axes. The mapping of the data to principal axis \( i \) is given by \( Yv_i \). This vector can be normalized to unit length by dividing it by \(\|Yv_i\|\). Thus, we have for each principal axis \( i \):

\[
u_i = \frac{Yv_i}{\|Yv_i\|}, \quad i = 1, \ldots, m
\]

The \( u_i \) are vectors of size \( t \) and are orthogonal by construction. The above equation shows that all the link counts, when weighted by \( v_i \), produce one dimension of the transformed data. Thus, vector \( u_i \) captures the temporal variation common to the entire ensemble of link traffic timeseries along principal axis \( i \). Since the principal axes are ordered by their contribution to overall variance, \( u_1 \) captures the strongest temporal trend common to all link traffic, \( u_2 \) captures the next strongest, and so on. Specifically, as Figure 2 shows, the set \(\{u_i\}_{i=1}^4\) captures most of the variance and hence the most significant temporal patterns common to the ensemble of all link traffic timeseries.

Figure 3 illustrates the difference between normal and anomalous traffic variation, as captured in the PCA decomposition. The figure shows sample projections of the Sprint-1 dataset onto selected principal components. On the left, we show projections onto the first two principal components (\( u_1 \) and \( u_2 \)), which capture the most significant variation in the data. These timeseries are periodic and reasonably deterministic, and clearly capture the typical diurnal patterns common across traffic on all links. Note that \( u_1 \) and \( u_2 \) are roughly 180 degrees out of phase, meaning that the two can be used in linear combination to roughly construct a sinusoid of any phase. Thus, the extraction of common temporal patterns via PCA does not require the underlying traffic timeseries to have the same periodic phase (e.g., as reflected in traffic in the same time zone). The subspace method assigns these traffic variations to the normal subspace.

We also show projections \( u_6 \) and \( u_8 \) on the right side of Figure 3. In contrast to \( u_1 \) and \( u_2 \), these projections of the data exhibit significant anomalous behavior. These traffic "spikes" indicate unusual network conditions, possibly induced by a volume anomaly at the OD flow level. The subspace method treats such projections of the data as belonging to the anomalous subspace.

A variety of procedures can be applied to separate the two types of projections into normal and anomalous sets. Based on examining the differences between typical and atypical projections (left and right sides of Figure 3), we developed a simple threshold-based separation method that works well in practice. Specifically, our separation procedure examines the projection on each principal axis in order; as soon as a projection is found that exceeds the threshold (e.g., contains a 3Ïƒ deviation from the mean), that principal axis and all subsequent axes are assigned to the anomalous subspace. All previous principal axes are then assigned to the normal subspace. This procedure resulted in placing the first four principal components in the normal subspace in each case; as can be seen from Figure 2, this means that all dimensions showing significant variance are assigned to the normal subspace.

Having separated the space of all possible link traffic measurements into the subspaces \( S \) and \( \tilde{S} \), we can then decompose the traffic on each link into its normal and anomalous components. We show how to use this idea to diagnose volume anomalies in the next section.

### 5. Diagnosing Volume Anomalies

The methods we use for detecting and identifying volume anomalies draw from theory developed for subspace-based fault detection in multivariate process control [5, 6, 11]. Our notation in the following subsections follows [5].

#### 5.1 Detection

Detecting volume anomalies in link traffic relies on the separation of link traffic \( y \) at any timestep into normal and anomalous components. We will refer to these as the modeled and residual parts of \( y \).

The key idea in the subspace-based detection step is that, once \( S \) and \( \tilde{S} \) have been constructed, this separation can be effectively performed by forming the projection of link traffic onto these two subspaces. That is, we seek to decompose the set of link measurements at a given point in time \( y \):

\[
y = \hat{y} + \tilde{y}
\]

such that \( \hat{y} \) corresponds to modeled and \( \tilde{y} \) to residual traffic. We form \( \hat{y} \) by projecting \( y \) onto \( S \), and we form \( \tilde{y} \) by projecting \( y \) onto \( \tilde{S} \).

To accomplish this, we arrange the set of principal components corresponding to the normal subspace (\( v_1, v_2, \ldots, v_r \)) as columns of a matrix \( P \) of size \( m \times r \), where \( r \) denotes the number of normal axes (chosen as described in Section 4.3). We can then write \( \hat{y} \) and \( \tilde{y} \) as:

\[
\hat{y} = P P^T y = C y \quad \text{and} \quad \tilde{y} = (I - P P^T) y = \tilde{C} y
\]

where the matrix \( C = P P^T \) represents the linear operator that performs projection onto the normal subspace \( S \), and \( \tilde{C} \) likewise projects onto the anomaly subspace \( \tilde{S} \).

Thus, \( \hat{y} \) contains the modeled traffic and \( \tilde{y} \) the residual traffic. In general, the occurrence of a volume anomaly will tend to result in a large change to \( \tilde{y} \).

A useful statistic for detecting abnormal changes in \( \tilde{y} \) is the squared prediction error (SPE):

\[
\text{SPE} \equiv \|\tilde{y}\|^2 = \|\tilde{C} y\|^2
\]

and we may consider network traffic to be normal if:

\[
\text{SPE} \leq \delta_\alpha^2
\]

where \( \delta_\alpha^2 \) denotes the threshold for the SPE at the \( 1 - \alpha \) confidence level. A statistical test for the residual vector known as the Q-statistic was developed by Jackson and Mudholkar and is given in [11] as:

\[
\delta_\alpha^2 = \phi_1 \left( \frac{c_\alpha}{2 \phi_2 h_0} \right)^{\frac{h_0(h_0 - 1)}{\phi_2^2}} - 1
\]

where \( \phi_1 \) and \( \phi_2 \) are parameters derived from the data.