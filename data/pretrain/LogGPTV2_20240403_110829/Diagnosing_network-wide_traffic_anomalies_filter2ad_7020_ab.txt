We will apply PCA on our link data matrix Y, treating each
row of Y as a point in IRm. However, before we can do so it is
necessary to adjust Y so that that its columns have zero mean. This
ensures that PCA dimensions capture true variance, and thus avoids
skewing results due to differences in mean link utilization. For the
rest of this paper, Y will denote the mean-centered link trafﬁc data.
Applying PCA to Y yields a set of m principal components,
{vi}m
i=1. The ﬁrst principal component v1 is the vector that points
in the direction of maximum variance in Y:
(cid:6)Yv(cid:6)
v1 = arg max
(cid:1)v(cid:1)=1
where (cid:6)Yv(cid:6)2 is proportional to the variance of the data measured
along v. Proceeding iteratively, once the ﬁrst k − 1 principal com-
ponents have been determined, the k-th principal component cor-
responds to the maximum variance of the residual. The residual is
the difference between the original data and the data mapped onto
the ﬁrst k − 1 principal axes. Thus, we can write the k-th principal
component vk as:
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
d
e
r
u
t
p
a
C
e
c
n
a
i
r
a
V
0.1
0.08
0.06
0.04
0.02
0
1
2
3
4
5
Sprint−1
Sprint−2
Abilene
5
10
15
20
25
30
35
40
45
Principal Component
Figure 2: Fraction of total link trafﬁc variance captured by
each principal component.
vk = arg max
(cid:1)v(cid:1)=1
(cid:6)(Y − k−1X
i=1
YvivT
i )v(cid:6).
An important use of PCA is to explore the intrinsic dimension-
ality of a set of data points. By examining the amount of vari-
ance captured by each principal component, (cid:6)Yvi(cid:6)2, we can ask
whether most of the variability in the data can be captured in a space
of lower dimension.
If we ﬁnd that only the variance along the
ﬁrst r dimensions is non-negligible, then we can conclude that the
pointset represented by Y effectively resides in an r-dimensional
subspace of IRm.
We can observe the phenomenon of low effective dimensionality
in our link data. In Figure 2, we plot the fraction of total variance
captured by each principal component of Y, for all three of our
datasets. This plot reveals that even though both networks have
more than 40 links, the vast majority of the variance in each link
timeseries can be well captured by 3 or 4 principal components.
This low effective dimensionality of link timeseries is consistent
with the ﬁnding that the underlying OD ﬂows themselves have low
intrinisic dimensionality [16]. In fact, the low effective dimension-
ality of link trafﬁc forms the basis for the success of the subspace
methods we describe in the following sections.
4.3 Subspace construction via PCA
Once the principal axes have been determined, the dataset can be
mapped onto the new axes. The mapping of the data to principal
axis i is given by Yvi. This vector can be normalized to unit length
by dividing it by (cid:6)Yvi(cid:6). Thus, we have for each principal axis i,
ui =
Yvi
(cid:6)Yvi(cid:6) i = 1, ..., m.
The ui are vectors of size t and are orthogonal by construction.
The above equation shows that all the link counts, when weighted
by vi, produce one dimension of the transformed data. Thus vector
ui captures the temporal variation common to the entire ensemble
of link trafﬁc timeseries along principal axis i. Since the principal
axes are in order of contribution to overall variance, u1 captures the
strongest temporal trend common to all link trafﬁc, u2 captures the
next strongest, and so on. Speciﬁcally as Figure 2 shows, the set
{ui}4
i=1 captures most of the variance and hence the most signif-
icant temporal patterns common to the ensemble of all link trafﬁc
timeseries.
0.05
0.04
0.03
0.02
0.01
0
−0.01
−0.02
−0.03
−0.04
−0.05
j
n
o
i
t
c
e
o
r
P
1
−
C
P
j
n
o
i
t
c
e
o
r
P
2
−
C
P
0.06
0.04
0.02
0
−0.02
−0.04
−0.06
−0.08
0.25
0.2
0.15
0.1
0.05
0
−0.05
j
n
o
i
t
c
e
o
r
P
6
−
C
P
Mon
Tue
Wed
Thu
Fri
Sat
Sun
Mon
Tue
Wed
Thu
Fri
Sat
Sun
Mon
Tue
Wed
Thu
Fri
Sat
Sun
u1
u2
(a) Normal Behavior
u6
(b) Anomalous Behavior
n
o
j
i
t
c
e
o
r
P
8
−
C
P
0.05
0
−0.05
−0.1
−0.15
Mon
Tue
Wed
Thu
Fri
Sat
Sun
u8
Figure 3: Projections onto principal components showing normal and anomalous trafﬁc variation.
The subspace method works by separating the principal axes into
two sets, corresponding to normal and anomalous variation in traf-
ﬁc. The space spanned by the set of normal axes is the normal
subspace S and the space spanned by the anomalous axes is the
anomalous subspace ˜S.
Figure 3 illustrates the difference between normal and anoma-
lous trafﬁc variation, as captured in the PCA decomposition. The
ﬁgure shows sample projections of the Sprint-1 dataset onto se-
lected principal components. On the left, we show projections onto
the ﬁrst two principal components (u1 and u2), which capture the
most signiﬁcant variation in the data. These timeseries are periodic
and reasonably deterministic, and clearly capture the typical diurnal
patterns which are common across trafﬁc on all links. Note that u1
and u2 are roughly 180 degrees out of phase, meaning that the two
can be used in linear combination to roughly construct of sinusoid
of any phase. Thus the extraction of common temporal patterns via
PCA does not require the underlying trafﬁc timeseries to have the
same periodic phase (e.g., as reﬂected in trafﬁc in the same time-
zone). The subspace method assigns these trafﬁc variations to the
normal subspace.
We also show projections u6 and u8 on the right side of Fig-
ure 3. In contrast to u1 and u2, these projections of the data exhibit
signiﬁcant anomalous behavior. These trafﬁc “spikes” indicate un-
usual network conditions, possibly induced by a volume anomaly
at the OD ﬂow level. The subspace method treats such projections
of the data as belonging to the anomalous subspace.
A variety of procedures can be applied to separate the two types
of projections into normal and anomalous sets. Based on exam-
ining the differences between typical and atypical projections (left
and right sides of Figure 3), we developed a simple threshold-based
separation method that we found to work well in practice. Specif-
ically, our separation procedure examines the projection on each
principal axis in order; as soon as a projection is found that exceeds
the threshold (e.g., contains a 3σ deviation from the mean), that
principal axis and all subsequent axes are assigned to the anoma-
lous subspace. All previous principal axes then are assigned to the
normal subspace. This procedure resulted in placing the ﬁrst four
principal components in the normal subspace in each case; as can
be seen from Figure 2, this means that all dimensions showing sig-
niﬁcant variance are assigned to the normal subspace.
Having separated the space of all possible link trafﬁc measure-
ments into the subspaces S and ˜S, we can then decompose the
trafﬁc on each link into its normal and anomalous components. We
show how to use this idea to diagnose volume anomalies in the next
section.
5. DIAGNOSING VOLUME ANOMALIES
The methods we use for detecting and identifying volume anoma-
lies draw from theory developed for subspace-based fault detection
in multivariate process control [5, 6, 11]. Our notation in the fol-
lowing subsections follows [5].
5.1 Detection
Detecting volume anomalies in link trafﬁc relies on the separa-
tion of link trafﬁc y at any timestep into normal and anomalous
components. We will refer to these as the modeled and residual
parts of y.
The key idea in the subspace-based detection step is that, once
S and ˜S have been constructed, this separation can be effectively
performed by forming the projection of link trafﬁc onto these two
subspaces. That is, we seek to decompose the set of link measure-
ments at a given point in time y:
y = ˆy + ˜y
such that ˆy corresponds to modeled and ˜y to residual trafﬁc. We
form ˆy by projecting y onto S, and we form ˜y by projecting y onto
˜S.
To accomplish this, we arrange the set of principal components
corresponding to the normal subspace (v1, v2, ..., vr) as columns
of a matrix P of size m × r where r denotes the number of normal
axes (chosen as described in Section 4.3). We can then write ˆy and
˜y as:
`
I − PPT
´
y = ˜Cy
ˆy = PPTy = Cy and
˜y =
where the matrix C = PPT represents the linear operator that
performs projection onto the normal subspace S, and ˜C likewise
projects onto the anomaly subspace ˜S.
Thus, ˆy contains the modeled trafﬁc and ˜y the residual trafﬁc. In
general, the occurrence of a volume anomaly will tend to result in
a large change to ˜y.
A useful statistic for detecting abnormal changes in ˜y is the
squared prediction error (SPE):
SPE ≡ (cid:6)˜y(cid:6)2
= (cid:6) ˜Cy(cid:6)2
and we may consider network trafﬁc to be normal if
SPE ≤ δ2
α
α denotes the threshold for the SPE at the 1 − α conﬁ-
where δ2
dence level. A statistical test for the residual vector known as the
Q-statistic was developed by Jackson and Mudholkar and is given
in [11] as:
p
»
cα
δ2
α = φ1
2φ2h2
0
φ1
+ 1 +
φ2h0(h0 − 1)
φ2
1
– 1
h0
r
o
t
c
e
V
e
a
S
t
t
x 1015
15
10
5
x 1016
3
2.5
2
1.5
1
0.5
r
o
t
c
e
V
e
t
t
a
S
Mon
Tue
Wed
Thu
Fri
Sat
Sun
Mon
Tue
Wed
Thu
Fri
Sat
Sun
x 1015
3.5
3
2.5
2
1.5
1
0.5
x 1015
5
4
3
2
1
r
o
t
c
e
V
l
i
a
u
d
s
e
R
r