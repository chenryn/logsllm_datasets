2
2
2
2
2
2 VBA32
1
2 Zillya
1
2 Qihoo-360
2 Kaspersky
1
2 ZoneAlarm 1
2
2
malformed signatures reduced the VirusTotal detection rate rmal
by 20.7%. We believe that this is due to the fact that AVs take digital
signatures into account when filter and prioritize the list of files to
scan, in order to reduce the overhead imposed on the user’s host.
However, the incorrect implementation of Authenticode signature
checks in many AVs gives malware authors the opportunity to
evade detection with a simple and inexpensive method.
We have reported the issue to the antivirus companies. One of
them confirmed that their product fails to check the signatures
properly and plans to fix the issue. A second company gave us a
confirmation but did not provide details.
4.4 Properly signed malware
189 malware samples in our data set carry correct digital signatures,
generated using 111 unique certificates. To generate these signa-
tures, adversaries must have controlled the private keys of these
certificates. We will analyze the weaknesses in the code-signing PKI
that contributed to this abuse in Section 4.5. But first we investigate
how these certificates are used in the wild and for how long users
are exposed to these threats.
At the time of writing, 27 of these certificates had been revoked.
While all the abusive certificates in our data set had expired, ex-
ecutable files signed with one of the 84 certificates that were not
revoked may still be valid, as long as they carry a trusted times-
tamp obtained during the validity of the certificate. For example,
the digital signatures from 109 malware samples in our data set
remain valid. We notified the CAs of the compromised certificates
and asked them for revocation of the certificates except for two
CAs (GlobalSign and GoDadday) due to their abuse report system
errors.
Malware families. We determined the malware family from the
AV labels, using AVClass [32]. We identify a total of 116 unique
families in the 189 properly signed malware samples. The most
prevalent family is delf (7 samples), followed by fareit (4 samples).
Figure 4 illustrates the number of unique certificates used per
malware family. 103 families utilize a single certificate, and 13
use more than two certificates. Among the families with multiple
certificates we observe droppers (autoit, banload, agentb, dynamer,
delf), bots (Zeus), and fake AVs (smartfortress and onescan). Similar
types of malware appear again in the list of families with a single
certificate. However, here we also find malware used in targeted
attacks. For example, Krbanker was reported to be involved in
targeted attacks against customers of South Korean banks. Shylock
is also known as a banking trojan that targeted customers of UK
banks. The large faction (88.8%) of malware families relying on a
Figure 4: Number of unique certificates per family.
single certificate suggests that, in most cases, abusive certificates
are controlled by the malware authors rather than by third parties.
Certificates. On average, an abusive certificate signs samples from
1.5 malware families. Most certificates (79.3%) were issued to pub-
lishers in five countries (China, Korea, USA, Brazil, and UK). We
believe that this observation reflects the reputation of these publish-
ers, which makes them attractive targets for abuse. This is particu-
larly important for targeted attacks against users or organizations
located in one of these countries.
In a total of the 189 properly signed malware, most (111, 66.8%)
were signature-timestamped through TSA; Verisign was the pre-
ferred TSA for most samples (38, 34.2%). This suggests that malware
authors value the extended validity provided by trusted timestamps
and that they are not concerned about submitting hashes of their
malware samples to the timestamping authorities.
Certificate lifecycle. To determine how long users are exposed to
these threats, we examine the lifecycle of these abusive certificates.
For each certificate, we investigate the expiration date specified in
the certificate, the revocation date specified in the CRL (if available),
and the dates when benign and malicious binaries are signed with
these certificates. If a binary has a trusted timestamp, we use that
timestamp as the signing date. This corresponds to 66.8% of the
binaries in our data set. For the other samples, we inspect their first
appearance in WINE and the first submission to VT; we use the
earliest timestamp as the signing date.
Figure 5 illustrates the timelines reconstructed in this manner.
For example, the compromised certificate used by Stuxnet had
previously been utilized to sign several legitimate binaries. These
binaries have been signed both before and after the malware’s
signing date. After the abuse was discovered, the certificate was
revoked as of the date when the malware was signed, which also
invalidated all the benign binaries signed after that date. We note
that the revocation date indicates when the certificate should cease
to be valid and not when the certificate was added to a CRL. In
other words, revocation dates do not allow us to determine for how
long users were exposed to the abuse.
While the Stuxnet incident raised awareness about digitally
signed malware, we observe that this problem was prevalent in the
wild before Stuxnet. We found a certificate from Skyline Sotftware
Families with one certiﬁcateNumber of certiﬁcatesNumber of familyStuxnetKrbankerShylockDelfOnescanInduc, Zbot, Autoit, Agentb,Banload, Dynamer,Smartfortress020406080100120140103116Figure 5: Lifecycle of the abusive certificates. (The red-filled circle, empty circle, green bar, and orange diamond indicate
malware, benign sample, expiration date, and revocation date, respectively.)
Systems compromised to sign a malware at the year 2003, which is
before Stuxnet appeared. Moreover, in Figure 3, we have 195 signed
malware which appeared before the year 2010, when Stuxnet was
discovered. Additionally, we observed two interesting behaviors. 5
certificates were used to sign malware that was not timestamped
and was seen in the wild after the certificate expired. Other than the
opportunity to evade some AV products as discussed in Section 4.3
(which does not require a certificate), there is no motivation for the
malware writers to release their code after the expiration date. We
therefore believe that these samples correspond to stealthy attacks
and were present in the wild for a long time but managed to evade
detection. We also find 7 certificates with ineffective revocations.
In these cases, the revocation dates were set after the timestamping
dates of the malware samples, which allowed the malware to remain
valid after revocation. This illustrates the challenge of estimating
when certificates are compromised: setting the revocation date
too early may invalidate many benign executables (as in Stuxnet’s
case), but setting it too late may prevent the invalidation of certain
malware samples in the wild.
To determine for how long the compromised certificates remain a
threat, we perform survival analysis [17]. This statistical technique
allows us to estimate the probability that an abused certificate will
“survive” (i.e. it will not be revoked) after a given number of days.
We consider the signing date (estimated as described above) of
the oldest malware sample signed with the same certificate as the
“birth” of the abuse. We estimate “death events”—the dates when
certificates are added to CRLs—as follows. For a revoked certificate,
we collect the scan date and the state of the certificate in VirusTotal
for all the binaries signed with the certificate. We sort the scan dates,
and take the very last date when state was “valid” right before the
Figure 6: Estimation of the threat effectiveness.
first scan date where the state is "revoked". We then calculate the
time difference in days between birth and death events for the
abused certificate. This represents a conservative estimation of the
threat exposure, as the birth is an upper bound for the compromise
date and the death is a lower bound for the revocation date. We
also account for the fact that we cannot observe the death of some
of the abusive certificates—the ones that are not yet revoked. In
these cases, we do not know how big the revocation delay is, but
we know that the certificates were not yet revoked on May 18, 2017;
in survival analysis terminology, these data points are censored. We
compute the Kaplan-Meier estimator [17] of the survival function,
as it can account for censored data in the estimation.
We present the estimation in Figure 6. The probability that a
certificate is not yet revoked decreases to 96% after the first day,
CertiﬁcateDateStuxnetStolenInducIdentitiy theftShellUnknown020406080100200420072008200920102011201220132014201520162017Valid certiﬁcates (%)Number of days808590950100020003000Identify Theft
Issuer
Count
Compromised
Issuer
Count
Thawte
VeriSign
Comodo
USERTrust
Certum
Others
Total
27 Thawte
24 Comodo
8 VeriSign
2
2 USERTrust
9 Others
72 (64.9%) Total
eBiz Networks
Shell Company
Issuer
Count
8 Wosign
4 DigiCert
4 USERTrust
3 GlobalSign
1
2
2
1
1
1
22 (19.8%) Total
5 (4.5%)
Table 4: Type of abuse and the top 5 frequent CAs.
owing to some certificates for which all the VT reports indicated a
“revoked” status. The probability continues to decrease slowly for
5.6 years, then it stops decreasing after reaching 80%. This suggests
that the threat of abused certificates is very resilient: only 20%
of the certificates used to sign malware are likely to be revoked
during our observation period, which spans 15 years. If the malware
samples signed with the remaining certificates also carry a trusted
timestamp, they remain valid today.
4.5 Measuring the abuse factors
To gain insight into the attackers’ methods, we utilize the algorithm
from Section 3.4 to identify the PKI weakness exploited in abusing
the 111 certificates.
Publisher-side key mismanagement. We considered a certifi-
cate as falling into this category if it was used for signing both
benign and malicious programs. Of the 111 clusters (i.e., certifi-
cates), at least 75 certificates were used for signing both.
gated malware samples signed with each certificate.
We examined the validity of the samples in this case. Surpris-
ingly, as of this writing, most (50, 66.7%) are still valid while only
some certificates (10, 13.3%) were explicitly revoked. Although all
certificates were already expired, the executable files signed with
the certificates are still valid beyond the expiration date due to trust
time stamping. Therefore, users will be displayed a message saying
the publisher is verified and legitimate when they run the malware.
To categorize the certificates, we manually and deeply investi-
• Compromised certificate. Out of 75 certificates, we believe
that most (72) were compromised and used for signing mal-
ware. Using this method, we found the Stuxnet malware,
which is known to have been signed with a compromised
certificate [10]. In our dataset, it was signed with the Realtek
Semiconductor Corp. certificate issued by Verisign. Our sys-
tems also detected that an Australian department’s private
key was also stolen and used to sign malware, labeled as
autoit.
• Infected developer machines. We also identified developer
machines that were infected and used to sign malicious code
with a legitimate certificate. This resulted in signed malicious
code shipped with a legitimate package. We found three
certificates used to sign W32/Induc.A that infects only Delphi
developer machines. We investigated the prevalence of Induc
in the wild using the WINE dataset. About 1,554 binaries
were detected as a variant of Induc and 93,016 machines were
infected. Among these machines, 180 were Delphi compiler
machines. This suggests that infecting developer machines
is an effective method for amplifying the impact of signed
malware and ultimately infecting 517× more machines.
As depicted in Table 4, 70% of them are issued by Symantec
group (Thawte and Verisign).
CA-side verification failure. This weakness is caused by CAs’
failure in verifying the publisher’s identity. CAs may issue certifi-
cates to an adversary who impersonates someone else or uses shell
company information.
We believe that 27 certificates were issued to malicious publish-
ers due to verification failures. To distinguish between identity theft
and shell companies, we also manually investigated each certificate
by searching for the publisher names in the Internet or in openCor-
porates to see if the publishers are legitimate. 22 certificates out of
27 certificates issued through identify theft and 5 certificates were
done through shell company information. For example, a certificate
issued to a delivery service company in Korea was used to sign
malware. Another certificate was issued to an Oregon resident. We
believe that the company is not related to software developments,
and has never released any software. Moreover, we doubt that for
a malware writer it is worth to reveal his/her identity. Therefore,
we consider that these are cases of identity theft.
We investigate the process for issuing code signing certificates
to understand the weakness that allowed these certificates to be
issued. The policy might have changed from that of the time when
these certificates were issued; however, we set an assumption that
the policy will not downgrade. Around the end of 2016, Certifi-
cate Authority Security Council (CASC) announced a minimum
requirements for code signing certificates.13 The new requirements
include:
• Stronger protection of private keys. Now the private keys
should only be stored on secure cryptographic hardware,
e.g., a USB token or Hardware security module (HSM).
• Careful identity verification. The new requirement asks CAs
to strictly verify the identity of the publisher, which includes
checking the legal identity of the publisher and the cross-
checking with the known bad publisher list.
• Better response to the abuse. The CAs now have to quickly
respond to the revocation request. They have to revoke the
certificate within two days, or notify the reporter that the
investigation has started.
• TSA is now a requirement. Now every code signing provider
must operate a RFC-3161 compliant TSA.
These guidelines suggest CASC is aware of the abuse happening
in the wild. Increased protection of the private keys would help
prevent certificates from being compromised; strict identification
check will make it hard to acquire a certificate by impersonating.
Moreover, Microsoft announced the CAs must follow these guide-
lines starting February 1, 2017.
We investigated the policies of the top ten code signing CAs listed
in Table 2. We found that only Certum follows the guidelines. The
result of the survey suggest that the code signing is still vulnerable
to the certification thefts and fraudulent applications.
13https://casecurity.org/2016/12/08/leading-certificate-authorities-and-microsoft-
introduce-new-standards-to-protect-consumers-online/
Revocation. We investigate the revocation practice in the field. By
category, 15.3%, 40.9%, and 80.0% of the certificates were revoked
for compromised, identity theft, and shell company, repectively.
Interestingly, the revocation rate was significantly less for the com-
promised certificates compared to the other abuse types.
Verification and further investigation. We decided to contact
the owners of the compromised certificates we found to inform
them that their certificates were used for signing malware, and
to better understand the code signing ecosystem. We manually
searched for their websites, and sent 23 publishers email to ask them
to check if the certificate was owned by them. We were unable to
send more publishers email due to unrecognizable publisher names,
closures, etc.
As of this writing, we received eight replies from those who we
emailed. All of them said that they issued and used the certificates
to sign their benign programs. Three of them were already aware
that their certificates were abused by adversaries and revoked by
their CAs because the CAs notified them that the certificates were
compromised. One publisher told us that their private key may have