Pre-training Language Models for IT Operations 151
200 companies across North America and Europe [4]. The best of the analyti-
cal tools fall short of detecting incidents early, predicting when incidents may
occur, offering timely and relevant guidance on how to resolve incidents quickly
and efficiently and helping avoid them from recurring. This can be attributed
to the complexity of the problem at hand. IT applications, the infrastructure
that they run on and the networking systems that support that infrastructure,
all produce large amounts of structured and unstructured data in the form of
logs and metrics. The volume and the variety of data generated in real-time
poses significant challenges for analytical tools in processing them for detect-
ing genuine anomalies, correlating disparate signals from multiple sources, and
raisingonlythosealertsthatneedITOperationsmanagementteams’attention.
To add to this, data volumes continue to grow rapidly as companies move to
modular microservices-based architectures, further compounding the problem.
Furthermore, the heterogeneous nature of environments, where companies’ IT
applications can run on a mix of traditional bare metal, virtual machines, and
public or private clouds operated by different parties, adds to the diversity of
formats, platforms and scale that IT Operations management solutions must
deal with. These complex and dynamic environments demand a new approach
to IT Operations management that is fast, real-time, adaptive, customizable,
and scalable.
TheriseofArtificialIntelligence(AI)poweredbytheadvancementsinhard-
ware architectures, cloud computing, natural language processing (NLP), and
machinelearning(ML),hasopenedupnewopportunitiesforoptimizingvarious
industries and business processes. Operations management of IT systems is one
such an area that is prime for optimization. AI can help IT Operations man-
agement personnel in detecting issues early, predicting them before they occur,
locating the specific application or infrastructure component that is the source
of the issue, and recommending relevant and timely recommendation actions
based on mining prior issue records. All these analytics help reduce the mean
time to resolve (MTTR) an incident, which in turn, saves millions of dollars by
preventingdirectcosts(lostrevenue,penalties,opportunitycosts,etc.)andindi-
rect costs (customer dissatisfaction, lost customers, lost references, etc.). Many
IT Operations management vendors are starting to embed AI capabilities into
their products. An advanced IT Operations management system needs to take
all kinds of data as inputs, detect anomalies early, predict when incidents may
occur, offer timely and relevant guidance on how to resolve incidents quickly
andefficiently,automaticallyapplyresolutionswhenapplicable,andproactively
avoidthemfromrecurringbyenforcingtherequiredfeedbackloopsintothevar-
ious software development lifecycles. This can increase the productivity of IT
Operations personnel or Site Reliability Engineers (SREs) and thereby improve
the mean times to detect, identify and resolve incidents.
In this work, we present an approach to leveraging language models to pre-
train features for optimizing IT Operations management tasks such as anomaly
prediction from logs. Specifically, using log-based anomaly prediction as the
task, we show that the machine learning models built using language models
152 X. Liu et al.
(embeddings) trained with the IT Operations domain data as features outper-
form those AI models built using language models with general-purpose data as
features. Furthermore, we present our empirical results outlining the influence
of factors such as the type of language models, the type of input data, and the
diversityofinputdata,onthepredictionaccuracyofourloganomalyprediction
model when language models trained from IT Operations domain data are used
as features. We also present the run-time inference performance of log anomaly
prediction models built using language models as features in an IT Operations
production environment.
The structure of the rest of this paper is as follows: Sect.2 discusses the
relatedworksandtechniques.Section3presentsourmethodtopre-trainfeatures
using language models for IT Operations, followed by our case study on log
anomaly prediction in Sect.4. We conclude the paper in Sect.5.
2 Related Works
The notion of application of AI to optimize IT is often referred to as AI Oper-
ations (or AIOps in short) in the industry. Coined by Gartner [6], the field of
AIOps is a specific space, stretching across several markets including Applica-
tionPerformanceManagement(APM),ITOperationsManagement(ITOM),IT
AutomationandConfigurationManagement(ITACM),andITServiceManage-
ment(ITSM)withaspecificfocusonAI-infusion.Researchproblemsinthisfield
include anomaly detection and prediction [10], incident management [16], fault
localization [21], root cause analysis [20], and so on. Our work uses log-based
anomaly prediction as the task to study the effects of pre-trained features from
languagemodeling.Priorworkinthisspacemainlyreliesonparsingstablelogs,
where the set of distinct log events is known and will not change over time [22].
However, in practice log data often contains previously unseen log events or log
sequences. Furthermore, it can be challenging for conventional log parsers to
adapt to different microservices since logs in each microservice may have their
owncontextinformation.Inthiswork,weleveragelanguagemodelstopre-train
featuresfromITOperationslogdata,whichmakesiteasiertoparsedynamically
evolving logs in a cloud environment for anomaly detection and prediction.
Language modeling and embedding representation learning has been an
active area of research in NLP, starting from word embeddings that map words
in a vocabulary to vectors of real numbers so that words of similar semantic
meaning are close to each other in the embedding space. Two language models
aretypicallyusedtolearnthewordembeddingrepresentations:ContinuousBag
of Words Model (CBOW) and Skip-gram. In the CBOW model, the distributed
representationsofcontextarecombinedtopredictthewordinthemiddle,while
in the Skip-gram model, the distributed representation of the input word is
used to predict the context. Word2vec [12] was the first popular embedding
method for NLP tasks. The embeddings were derived from a Skip-gram model
represented as a neural network with a single hidden layer. GloVe [13] learned
the embeddings through dimensionality reduction on the co-occurrence counts
Pre-training Language Models for IT Operations 153
matrix.FastText[2]introducedtheconceptofsubword-levelembeddings,based
on the Skip-gram model. Each word is represented as a bag of character n-
grams, and their embeddings are the sum of vector representations associated
with each character n-gram. Recent research in language modeling and deep
learning has advanced contextualized embedding learning to address the issue
of polysemous and the context-dependent nature of words. ELMo [14] extracts
context-sensitive features from a bidirectional LSTM language model and pro-
vides additional features for a task-specific architecture. ULMFiT [7] advocates
discriminative fine-tuning and slanted triangular learning rates to stabilize the
fine-tuningprocesswithrespecttoendtasks.OpenAIGPT[15]buildsonmulti-
layer transformer [17] decoders instead of LSTM to achieve effective transfer
while requiring minimal changes to the model architecture. BERT [5] uses bidi-
rectional transformer encoders to pre-train a large corpus, and fine-tunes the
pre-trained model that requires almost no specific architecture for each end
task. In this work, we empirically investigate the impact of embeddings and
language models pre-trained using IT Operations domain data for optimizing
the domain-specific tasks.
3 Approach
Inthissection,wedescribeourapproachtopre-trainingfeaturesusinglanguage
models for optimizing different IT Operations management tasks.
3.1 Motivation
ITOperationsenvironmentgeneratesmanykindsofdata.Theseincludemetrics,
alerts, events, logs, tickets, application and infrastructure topology, deployment
configurations,andchatconversations.Ofthese,metricstendtobestructuredin
naturewhilelogs,alerts,andeventsaresemi-structured,andticketsareunstruc-
tured data types. Also, among all the data types, logs and metrics sometimes
can be leading indicators of problems, while alerts, tickets and chat conversa-
tions tend to be lagging indicators. The volume, the variety and the complexity
of these data offers both challenges and opportunities in developing AI-infused
analytical tools to optimize IT Operations management tasks. Leveraging lan-
guage models to pre-train features from IT Operations domain data, we present
atransferlearningapproachthatservesasstrongafoundationtobuildAImod-
els for various different IT Operations management tasks, such as log anomaly
detection, fault localization, named entity extraction, similar incident analysis,
and event grouping (as illustrated in Fig.1).
3.2 Embedding and Language Modeling
Embeddings,alsoknownasdistributedvectorrepresentations,havebeenwidely
used in NLP and natural language understanding. In a pretrained embedding
154 X. Liu et al.
Fig.1. An illustration of language models for different IT Operations management
tasks.
space,wordsorphrasesfromthevocabularyaremappedtovectorsofrealnum-
bers, and each is associated with a feature vector of a fixed dimension. Embed-
dingsarepre-trainedonlargetextcorpususingalanguagemodelingtask,which
assigns a probability distribution over sequences of words that matches the dis-
tribution of a language. After that, embeddings can be extracted from the pre-
trained language model.
Typically,wecancategorizeembeddingsintotwotypesbasedonthelanguage
modeling approach in use: context-free embeddings and contextualized embed-
dings.Staticwordembeddings(e.g.,Word2Vec,Glove,fastText)arecontext-free
as the language models generate the same embedding for the same word even
in different context. Deep pre-trained language models (e.g., ELMo, ULMFiT,
BERT)cangeneratecontextualizedembeddingswheretherepresentationofeach
wordalsodependsontheotherwordsinasentence(i.e.,thecontextoftheword).
For the scope of this work, we select two representative embeddings from each
type: fastText for context-free embedding and BERT for contextualized embed-
ding.
3.3 Pre-training Language Models for IT Operations Management
Most existing embeddings available in the literature were created from text cor-
pus in natural language such as Wikipedia pages and news articles. However,
the text data generated in the IT Operations domain are different from natural
language texts, as the vocabulary of the IT Operations domain is quite unique.
Forexample,logscancontainamixofthedate,thetime,thepodid,thelevelof
logging, the component where the system runs, and the content of log message.
To pre-train language models in the IT Operations domain, we first process
the input text data into a normalized format using predefined rules, extract-
ing the most informative texts such as log messages, ticket descriptions and so
on. We also remove duplicates of texts, which may be auto-generated multi-
ple times by the system for the same event. Next, we randomly sample data
Pre-training Language Models for IT Operations 155
from each data source, and use the data samples to learn the vocabulary of the
whole IT Operations domain. For fastText the vocabulary of words are learned
when pre-training the language model. For BERT since the vocabulary has to
be predetermined prior to the neural model training, we use sentencepiece [9] to
learn the vocabulary of subwords. After that, we pre-train the language model
using the sampled data, and tune the parameters based on model evaluation.
An overview of the pre-training pipeline is shown in Fig.2.
Fig.2.Thepipelineofpre-traininglanguagemodelsusingITOperationsdomaindata.
4 Case Study: Log Anomaly Detection
Todemonstratethefeasibilityofourapproach,wedescribeacasestudyofusing
language models to pre-train features for building log anomaly detection and
prediction models in IT Operations management.
4.1 Problem Statement
Anomaly detection from logs is one fundamental IT Operations management
task,whichaimstodetectanomaloussystembehaviorsandfindsignalsthatcan
providecluestothereasonsandtheanatomyofasystem’sfailure.Logmessages
are inherently unstructured, since system events can be recorded by developers
using any text for the purpose of convenience and flexibility. Traditionally, log
parsingisusuallyappliedasafirststeptowardsdown-streamloganalysistasksto
convertunstructuredtextuallog messagesinto astructuredformatthatenables
efficientsearching,filtering,grouping,counting,andsophisticatedminingoflogs.
Inparticular,logtemplatesareextractedfromlogstorepresentanabstractionof
log messages by masking system parameters recorded in logs. However, existing
logparsingapproachesareunabletoadapttoevolvinglogs,makingitchallenging
forcontinuousmodelimprovementandcustomization.Furthermore,itisdifficult
to capture the semantic information in log messages with log templates.
156 X. Liu et al.
4.2 System Overview
To tackle these challenges, we develop a system to perform anomaly detection
andpredictionbasedonpre-trainedfeaturesfromlanguagemodels.Anoverview
ofoursystemisshowninFig.3.Oursystemconsistsoftwosubsystems:Off-line
TrainingandRuntimeInference.TheOff-lineTrainingsubsystemfocusesonlog
parsing,embeddingextractionandanomalydetectortraining.Theinputtothis
subsystem are randomly sampled log data and a pre-trained language model
(fastText or BERT). We generate a vector representation for each log message:
from fastText embeddings, we aggregate the embeddings from the words in a
sentence using tf-idf weighting; from the pre-trained BERT model, we take its
final hidden state of the token [CLS] as the aggregate sequence representation.
To model the system behavior over time, we group the log messages of every
10s time window based on the logging timestamp, and average the vectors of
logs within each time window to form the feature vector. We learn a Princi-
palComponentAnalysis(PCA)[18]transformationmatrixfromfeaturevectors
in training data collected when the system was running in normal condition.
The output of this subsystem are trained log anomaly detection models, which
are saved to the storage repository Data Lake. The Runtime Inference subsys-
tem checks if an anomaly occurs for a given time window during runtime. The
input to this subsystem are the trained models from the Off-line Training sub-
system in the Data Lake, as well as new logs in a streaming fashion through
Kafka [8], a unified, high-throughput, low-latency platform for handling real-
time data streams. Our system will predict anomaly if the feature vector of
a new time window is sufficiently different from the normal space constructed
by PCA. The output of this subsystem are anomalies detected from the logs.
Fig.3. An overview of our anomaly detection system built with embeddings from
pre-trained language models.
Pre-training Language Models for IT Operations 157
Feedback on the anomaly detection results will be used to continuously improve
the Off-line Training subsystem.
4.3 Evaluation
In our experiments, we explore the effects of three factors that may affect lan-
guage model pre-training for IT Operations management: the type of language
models(context-freeorcontextualizedembeddings),thetypeofpretraineddata
(domain-specific data or general-purpose data), and the diversity of pre-trained
data.
Datasets and Benchmarks. For pre-training the language models, we take
3 million sampled logs from 64 different applications: 48 cloud microservices in
IBM Watson Assistant (WA) [1] (1 million logs), and 15 applications in Loghub
collection [22] (2 million logs), ranging from distributed systems, supercomput-
ers,operatingsystemstoserverapplications.Totesttheaccuracyofourtrained
anomalydetectormodels,wecollectlogswithgroundtruthfromtwoIBMWat-
sonAssistantmicroservices(denotedas WA-1 and WA-2)whenthesystemwas
running in normal or abnormal condition, along with the HDFS ground truth
data from Loghub. We compare the predictions with ground truth and compute
the per-class accuracy as the percentage of correct predictions in the normal or
abnormal test data set, respectively.
Accuracy Testing. We trained the following variants of anomaly detection
models using different pre-trained features in our experiments:
– Baseline.Ourbaselineusescountvectorsoflogtemplatesasfeaturevectors
to build the model [19].
– fastText-origin. The model was built using features from the original pre-
trained fastText embedding using general-purpose data [11].
– fastText-wa. The model was built using features from our fastText embed-
ding pre-trained using IBM Watson Assistant data.
– fastText-wa-loghub. The model was built using features from our fastText
embedding pre-trained using IBM Watson Assistant and Loghub data.
– BERT-origin. The model was built using features from the original pre-
trained BERT using general-purpose data [5].
– BERT-wa. The model was built using features from our pre-trained BERT
using IBM Watson Assistant data.
– BERT-wa-loghub.Themodelwasbuiltusingfeaturesfromourpre-trained
BERT using IBM Watson Assistant and Loghub data.
InTable1,wereporttheaccuracyresultsofanomalypredictiononthebench-
markdatasetsacrossvariousmodels.Firstly,wecanseethatthemodelstrained
withcontext-freeembeddingsconsistentlyoutperformourbaselineaswellasthe
models trained with contextualized embeddings. While our pre-trained fastText