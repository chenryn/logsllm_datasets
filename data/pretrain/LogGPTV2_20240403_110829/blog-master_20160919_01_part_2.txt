discard
  Boolean; if on a discard/TRIM will be issued to each bucket before it is
  reused. Defaults to off, since SATA TRIM is an unqueued command (and thus
  slow).
block_size
Minimum granularity of writes - should match hardware sector size.
```
6\. 创建backing设备，(data-offset可以用来指定偏移量，达到对齐的目的)。  
backing设备与cache设备的block_size必须设置为一样的，所以以两者大的为准即可。  
```
#make-bcache -B --writeback -w 4KiB /dev/sdb1 --wipe-bcache
UUID:                   d813d8ab-6541-4296-a77e-e35d18d2d6ec
Set UUID:               8033e49c-270d-4a8f-b5e9-f331ac77bf80
version:                1
block_size:             8    单位(扇区,512字节)
data_offset:            16   单位(扇区,512字节)
```
7\. 注册cache, backing设备  
```
echo /dev/dfa1 > /sys/fs/bcache/register
echo /dev/sdb1 > /sys/fs/bcache/register
```
8\. 观察  
```
#ll /sys/block/dfa/dfa1/bcache/
block_size                bucket_size               clear_stats               io_errors                 nbuckets                  priority_stats            written                   
btree_written             cache_replacement_policy  discard                   metadata_written          physical_block_size       set/ 
#ll /sys/block/sdb/sdb1/bcache/
attach                         dirty_bytes                    no_cache_wt_pages              sequential_cutoff              stripe_size                    writeback_percent              writeback_running
cache_mode                     dirty_data                     page_cache_enable              state                          tdc/                           writeback_rate                 wt_torture_test
clear_stats                    drop_page_cache                partial_stripes_expensive      stats_day/                     winto_keys_debug               writeback_rate_debug           
dc_high_latency_filter_ms      io_stats_read                  readahead                      stats_five_minute/             writeback_debug                writeback_rate_d_term          
dc_high_latency_stats          io_stats_write                 read_via_page_cache            stats_hour/                    writeback_delay                writeback_rate_min             
detach                         io_stats_writeback_detail      running                        stats_total/                   writeback_flush_enable         writeback_rate_p_term_inverse  
device/                        label                          sequential_bios                stop                           writeback_metadata             writeback_rate_update_seconds 
```
如果注册了cache设备，可以看到bcache的cache set UUID，对应创建cache设备是返回的Set UUID:   
```
#ll /sys/fs/bcache/
total 0
drwxr-xr-x 7 root root    0 Sep 18 16:39 a01f921f-a91b-46ad-b682-2f59d0be4717
drwxr-xr-x 2 root root    0 Sep 18 16:41 bdevs
--w------- 1 root root 4096 Sep 18 16:38 register
--w------- 1 root root 4096 Sep 18 16:41 register_quiet
```
注册了backing设备，则可以看到对应的bcache设备  
```
#lsblk
sdb           8:16   0   xxT  0 disk 
`-sdb1        8:17   0   xxT  0 part 
  `-bcache0 251:0    0   xxT  0 disk 
```
9\. 将cache设备绑定到backing设备  
完成这一步，ssd缓存才生效  
指定cache设备的UUID(通过#ll /sys/fs/bcache/得到)，写入backing设备对应的attach  
```
# echo a01f921f-a91b-46ad-b682-2f59d0be4717 > /sys/block/sdb/sdb1/bcache/attach
```
10\. 检查bcache设备状态  
```
#cat /sys/block/sdb/sdb1/bcache/state 
clean
```
11\. 检查 或 修改缓存模式   
```
#cat /sys/block/sdb/sdb1/bcache/cache_mode 
writethrough [writeback] writearound none
#echo writethrough > /sys/block/sdb/sdb1/bcache/cache_mode 
#cat /sys/block/sdb/sdb1/bcache/cache_mode 
[writethrough] writeback writearound none
#echo writeback > /sys/block/sdb/sdb1/bcache/cache_mode 
#cat /sys/block/sdb/sdb1/bcache/cache_mode 
writethrough [writeback] writearound none
```
12\. 创建文件系统  
```
#mkfs.ext4 /dev/bcache0 -m 0 -O extent,uninit_bg -E lazy_itable_init=1 -T largefile -L sdb1
```
13\. mount 文件系统  
```
mount -o defaults,noatime,nodiratime,nodelalloc,barrier=0 LABEL=sdb1 /disk1
```
## 四、bcache 调优
1\. backing设备块对齐，如果backing设备是RAID设备，可以将--data-offset设置为raid 条带大小的倍数，避免写放大。  
```
make-bcache --data-offset  
```
如果考虑未来RAID的扩展，则建议这样计算data-offset的值    
```
   For example:  If you have a 64k stripe size, then the following offset
   would provide alignment for many common RAID5 data spindle counts:
	64k * 2*2*2*3*3*5*7 bytes = 161280k
   That space is wasted, but for only 157.5MB you can grow your RAID 5
   volume to the following data-spindle counts without re-aligning:
	3,4,5,6,7,8,9,10,12,14,15,18,20,21 ...
```
2\. 调整backing设备的连续IO阈值，表示bcache0设备的连续写IO大于4MB时，大于4MB的部分不会过SSD设备，也不会缓存到ssd，而是直接写backing设备。  
```
echo 4M > /sys/block/bcache0/bcache/sequential_cutoff
```
3\. 如何防止cache设备成为瓶颈  
bcache会跟踪每个IO，如果IO的时间超过阈值，则旁路cache设备，直接读写backing设备。  
如果你的SSD足够强大，可以不跟踪，减少跟踪的开销。  
```
   # echo 0 > /sys/fs/bcache//congested_read_threshold_us
   # echo 0 > /sys/fs/bcache//congested_write_threshold_us
```
关闭旁路的另一个好处是，所有的离散读写都会经过cache设备，从而不会导致cache missing。  
默认情况下当读请求超过2ms，写请求超过20ms时，旁路cache设备。  
```
   The default is 2000 us (2 milliseconds) for reads, and 20000 for writes.  
```
## 五、bcache 自启动脚本
重启后，需要启动bcache模块(内核自带bcache除外)，重新注册设备，如果修改了bcache的一些配置，也需要重新修改，例如。  
```
加载内核模块
modprobe bcache
注册设备
echo /dev/dfa1 > /sys/fs/bcache/register
echo /dev/sdb1 > /sys/fs/bcache/register
......
```
重启后，不需要重新创建cache, backing设备，不需要重新绑定backing和cache设备。  
## 六、bcache 性能测试
使用fio测试bcache设备的性能。  
```
yum install -y libaio
git clone https://github.com/axboe/fio
cd fio
./configure --prefix=/home/digoal/fiohome
make -j 32
make install
export PATH=/home/digoal/fiohome/bin:$PATH
```
测试性能  
假设bcache设备的挂载点为/disk1  
```
fio -filename=/disk1/testdir -direct=1 -iodepth 1 -thread -rw=write -ioengine=libaio -bs=32K -size=16G -numjobs=128 -runtime=60 -group_reporting -name=mytest
fio -filename=/disk1/testdir -direct=1 -iodepth 1 -thread -rw=read -ioengine=libaio -bs=32K -size=16G -numjobs=128 -runtime=60 -group_reporting -name=mytest
fio -filename=/disk1/testdir -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=libaio -bs=32K -size=16G -numjobs=128 -runtime=60 -group_reporting -name=mytest
fio -filename=/disk1/testdir -direct=1 -iodepth 1 -thread -rw=randread -ioengine=libaio -bs=32K -size=16G -numjobs=128 -runtime=60 -group_reporting -name=mytest
```
## 七、bcache 维护
### 添加backing, cache设备
1\. 添加cache设备  
```
#make-bcache -C -b 1MiB -w 4KiB --discard --cache_replacement_policy=lru /dev/dfa2
UUID:                   cbe1760b-43bf-47f0-94b1-cd1136576873
Set UUID:               826b8b21-1f40-4a1d-ad2b-84f1ecbb4c45
version:                0
nbuckets:               1525878
block_size:             8
bucket_size:            2048
nr_in_set:              1
nr_this_dev:            0
first_bucket:           1
```
2\. 注册cache设备  
```
echo /dev/dfa2 > /sys/fs/bcache/register
```
3\. 添加backing设备  
```
# make-bcache -B --writeback -w 4KiB /dev/sdc1 --wipe-bcache
UUID:                   e406b0b2-69f9-4f4c-8b18-2d314ce6ed35
Set UUID:               f8877b48-3c59-40a7-919e-029ce2d3249d
version:                1
block_size:             8
data_offset:            16
```
4\. 注册backing设备  
```
echo /dev/sdc1 > /sys/fs/bcache/register
```
5\. 绑定cache与backing设备  
```
echo 826b8b21-1f40-4a1d-ad2b-84f1ecbb4c45 > /sys/block/sdc/sdc1/bcache/attach
```
使用以上方法，将所有的backding盘都操作一下(mklabel gpt, mkpart, make-bcache -B, register, 绑定)。    
现在变成这样的。  
```
#lsblk
NAME         MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sdb            8:16   0   xxT  0 disk 
`-sdb1         8:17   0   xxT  0 part 
  `-bcache0  251:0    0   xxT  0 disk /disk1
sdc            8:32   0   xxT  0 disk 
`-sdc1         8:33   0   xxT  0 part 
  `-bcache1  251:1    0   xxT  0 disk 
......
dfa          252:0    0   zzT  0 disk 
|-dfa1       252:1    0   yyT  0 part 
| |-bcache0  251:0    0   xxT  0 disk /disk1
| |-bcache1  251:1    0   xxT  0 disk 
| |...
| `-bcache5  251:5    0   xxT  0 disk 
`-dfa2       252:2    0   yyT  0 part 
  |-bcache6  251:6    0   xxT  0 disk 
  |-bcache7  251:7    0   xxT  0 disk 
  |...
  `-bcache11 251:11   0   xxT  0 disk 
```
12块机械盘分别绑定到两个cache设备上。    
注意  
如果有多个SSD设备都需要作为一个backing设备的cache设备的话，可以使用lvm将ssd做成条带，从而提升cache设备的整体IO能力和带宽能力。  
然后再将lvm设备作为cache设备即可。    
如果是多个backding设备，则可以像以上的方法一样，不同的backing设备绑定不同的cache设备。  
### 删除backing, cache设备  
步骤如下  
1\. umount 挂载点  
2\. 如果有在bcache设备上建立了软RAID或者逻辑卷，首先要解除这层关系  
```
lvremove 
vgremove
pvremove
```
或
```
mdadm -S md设备
```
3\. 删除cache设备前，必须确保没有任何与之绑定的backing设备，解除backing与cache设备的绑定 (detach)    
```
echo 1 > /sys/block/sdX/sdX[Y]/bcache/detach  
echo  /sys/block/bcache/bcache/detach
```
4\. 停止 backing设备  
detach cache设备后，我们还需要这一步，才能删除backing设备。  
```
echo 1 > /sys/block/sdX/sdX[Y]/bcache/stop
```
5\. unregister cache 设备  