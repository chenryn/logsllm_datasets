title:Principled Sampling for Anomaly Detection
author:Brendan Juba and
Christopher Musco and
Fan Long and
Stelios Sidiroglou-Douskos and
Martin C. Rinard
Principled Sampling for Anomaly Detection
Brendan Juba
Washington University in St. Louis
PI:EMAIL
Christopher Musco, Fan Long,
Stelios Sidiroglou-Douskos and Martin Rinard
Massachusetts Institute of Technology
{fanl,cpmusco,stelios,rinard}@csail.mit.edu
Abstract—Anomaly detection plays an important role in pro-
tecting computer systems from unforeseen attack by automati-
cally recognizing and ﬁlter atypical inputs. However, it can be
difﬁcult to balance the sensitivity of a detector – an aggressive
system can ﬁlter too many benign inputs while a conservative
system can fail to catch anomalies. Accordingly, it is important
to rigorously test anomaly detectors to evaluate potential error
rates before deployment. However, principled systems for doing
so have not been studied – testing is typically ad hoc, making it
difﬁcult to reproduce results or formally compare detectors.
To address this issue we present a technique and implemented
system, Fortuna, for obtaining probabilistic bounds on false
positive rates for anomaly detectors that process Internet data.
Using a probability distribution based on PageRank and an
efﬁcient algorithm to draw samples from the distribution, Fortuna
computes an estimated false positive rate and a probabilistic
bound on the estimate’s accuracy. By drawing test samples from
a well deﬁned distribution that correlates well with data seen in
practice, Fortuna improves on ad hoc methods for estimating false
positive rate, giving bounds that are reproducible, comparable
across different anomaly detectors, and theoretically sound.
Experimental evaluations of three anomaly detectors (SIFT,
SOAP, and JSAND) show that Fortuna is efﬁcient enough to use
in practice — it can sample enough inputs to obtain tight false
positive rate bounds in less than 10 hours for all three detectors.
These results indicate that Fortuna can, in practice, help place
anomaly detection on a stronger theoretical foundation and help
practitioners better understand the behavior and consequences
of the anomaly detectors that they deploy.
As part of our work, we obtain a theoretical result that may
be of independent interest: We give a simple analysis of the
convergence rate of the random surfer process deﬁning PageRank
that guarantees the same rate as the standard, second-eigenvalue
analysis, but does not rely on any assumptions about the link
structure of the web.
I.
INTRODUCTION
Anomaly detection systems are critical components of
many security systems. By recognizing, then discarding, sani-
tizing, or otherwise nullifying outlier inputs that might other-
wise exploit security vulnerabilities, anomaly detectors often
play a central role in many computer security systems.
In general, however, anomaly detectors are not perfect.
Speciﬁcally, anomaly detectors typically navigate a trade off
between two kinds of errors:
False Positives - Type I error A Type I error occurs when
an anomaly detector (incorrectly) rejects a benign input. A
high false positive rate can signiﬁcantly impair the utility
of an anomaly detector — each false positive denies some
part of the functionality of the system to the user.
False Negatives - Type II error A Type II error occurs
when an anomaly detector (incorrectly) accepts a mali-
cious input, leaving the system open to attack.
In general, making an anomaly detector more sensitive in-
creases the false positive rate and decreases the false nega-
tive rate (and vice-versa). Appropriately balancing these two
rates is therefore essential in obtaining an effective anomaly
detector. Practitioners typically tune their anomaly detectors
by running the detector on a (representative) set of inputs to
develop an intuitive understanding of how the anomaly detector
will operate in practice. Current techniques are ad-hoc, not
guided by any theoretically well-founded framework or anal-
ysis, and therefore provide no guarantees on the effectiveness
of the anomaly detector when deployed in production and no
guidance on how to effectively test the anomaly detector to
determine if it will work well in practice.
We present a technique and implemented system, Fortuna,
that, for the ﬁrst time, provides bounds on the number of false
positives that a given anomaly detector will incur in practice.
Fortuna focuses speciﬁcally on anomaly detection systems that
handle data from browsing the Internet. This class of systems is
very well studied and includes, for example, anomaly detectors
that ﬁlter potentially anomalous video, images, and JavaScript
ﬁles [18], [20], [28], [36], [38] or seek to ﬁlter entire malicious
webpages [44], [47], [48]. Nevertheless, our approach is broad
and we provide a general framework for building analysis
systems for other classes of anomaly detectors.
B. Juba was afﬁliated with Harvard University when this work was
performed.
A. False Positive Bounds
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23268
Speciﬁcally, Fortuna’s sampling algorithm collects a se-
quence of randomly chosen benign inputs that enables Fortuna
to derive probabilistic bounds of the following form:
• One-Sided Bound: For anomaly detectors with no false
positives in the sequence of test inputs that the sampling
algorithm generates, Fortuna provides a bound of the form
P r(err(1)  1 − δ, where err(1) is the actual Type
I error (false positive rate) that the anomaly detector will
incur in practice,  is an upper bound on this false positive
rate, and 1− δ is the certainty with which Fortuna is able
to provide this bound.
For example, with a sequence of 46,052 sampled inputs
and no false positives, Fortuna can show that the proba-
bility that the false positive rate is less than 0.01% is at
least 99%.
• Two-Sided Bound: For anomaly detectors with some
false positives in the sequence of test inputs that the
sampling algorithm generates, Fortuna provides a bound
of the form P r(|err(1) − (cid:102)err(1)|  1 − δ, where
the anomaly detector will incur in practice, (cid:102)err(1) is the
(cid:102)err(1), and 1 − δ is the certainty with which Fortuna is
(empirical) Type I error for the sequence of sampled
inputs,  is a bound on the difference between err(1) and
err(1) is the actual Type I error (false positive rate) that
able to provide this bound.
For example, with a sequence of 26,492 sampled inputs,
Fortuna produces an estimate of the false positive rate
that is within 1% of the true false positive rate with 99%
probability.
These bounds are based on standard statistical inequalities
and are a function of the number of inputs that Fortuna’s
sampling algorithm is directed to obtain, with the bounds be-
coming tighter as the number of inputs increases. Speciﬁcally,
for the one-sided bound, the number of required samples is
proportional to (1/) · log(1/δ); for the two-sided bound, the
number of required samples is proportional to (1/2)·log(1/δ).
Fortuna therefore enables practioners to determine, ahead of
time, how many test inputs are required to obtain a desired
bound. Our experimental results show that, in practice, Fortuna
is easily able to obtain enough samples to provide tight bounds
(see Section VI).
B. Accurate Sampling
To provide accurate false positive bounds, Fortuna’s sam-
pling algorithm delivers inputs from a probability distribution
for benign inputs that accurately models the distribution the
anomaly detector will encounter in practice.1 We note that the
standard approach of collecting a large set of inputs from an
available source such as the Internet, then computing the false
positive rate over this input set, does not provide an accurate
estimate of the false positive rate — in general, the anomaly
detector is more likely to encounter some inputs than others,
with signiﬁcant dependence on the ad hoc collection method
selected. To obtain accurate bounds, Fortuna must select inputs
from a concrete probability distribution over benign inputs that
has two properties:
• Reﬂects Production Use: The probability distribution
reﬂects the distribution of inputs that the anomaly detector
will encounter in production use.
• Efﬁcient Sampling Algorithm: The probability distribu-
tion supports an efﬁcient sampling algorithm that Fortuna
can use to generate its random sequence of inputs.
1The false positive rate does not depend on the distribution of malicious
inputs — each malicious input is either a true negative or a false negative.
Each benign input, in contrast, is either a true positive (when the anomaly
detector accepts the input) or a false positive (when the anomaly detector
rejects the input).
2
Fortuna is speciﬁcally designed to work with systems that
process inputs that a typical user would see when browsing
the Internet. Thus, it uses a probability distribution based on
PageRank (ﬁrst deﬁned by Page et al. [45] for ranking web
pages). The original motivation for PageRank was to weight
web pages according to user desirability in order to provide rel-
evant search results to a user (cf. [32, p.4]). At the same time,
PageRank was also designed to be computationally tractable.
A complete justiﬁcation for our selection of PageRank can be
found in Section II.
We are not interested in computing PageRank scores (prob-
abilities) for all pages, but rather in sampling according to the
PageRank distribution. It turns out that generating samples is
even easier than computing the scores, which enables Fortuna
to generate large enough sequences to provide tight false
positive bounds. Speciﬁcally, a characterization of PageRank
distributions that ﬁrst appeared in the work of Andersen et
al. [11] can be interpreted as a simple sampling algorithm. We
develop a system based on this algorithm for rapidly sampling
image ﬁles from a PageRank distribution. The system only
requires access to freely available data, the web, and simple
scripts.
Note that there is a crucial difference between the prob-
ability distributions of malicious and benign inputs. Because
malicious inputs are speciﬁcally designed to target (in many
cases not publicly known) program vulnerabilities, and because
malicious inputs evolve rapidly in response to countermeasures
(such as deployed anomaly detection systems), it is not typi-
cally possible to obtain reasonable probability distributions for
malicious inputs. For this reason, Fortuna does not attempt to
provide bounds about the false negative rate that the anomaly
detector will encounter in production use. Our focus is in
line with previous literature on anomaly detection – in light
of limited access to malicious inputs, systems are typically
designed to handle a ﬁxed set of malicious examples and,
during evaluation, false positive rate is used as the main quality
metric.
C. Experimental Results
trigger target
the input will not
We evaluate Fortuna on three anomaly detectors:
the
SIFT [38], SOAP [37], and JSAND [18] anomaly detectors:
• SIFT: SIFT uses a conservative static program analysis
to obtain a set of constraints on the values of ﬁelds in
JPG and PNG image ﬁles processed by png2swf [8],
jpg2swf [8], and Dillo [5].
If an input satisﬁes the constraints, SIFT guarantees
that
integer overﬂow
errors [38]. Because the SIFT analysis is conservative,
it may reject
trigger the error.
We consider an input ﬁle to be a false positive if it 1)
violates the constraints but 2) does not trigger the integer
overﬂow error. The results show that the SIFT anomaly
detector can effectively guarantee the absence of integer
overﬂow errors at critical memory allocation and block
copy sites in our benchmark applications, including at
least six potentially exploitable errors.
• SOAP: SOAP learns characteristics of ﬁelds in JPG
and PNG image ﬁles that are processed by applications
such as ImageMagick [7] and Dillo [5]. Speciﬁcally,
inputs that would not
SOAP processes input ﬁles that the applications handle
successfully to infer upper bound constraints of integer
ﬁelds, sign constraints of integer ﬁelds, and upper bound
constraints of data ﬁeld lengths [37].
We consider an input ﬁle to be a false positive if it 1)
violates the learned constraints but 2) the application can
process the input ﬁle successfully. SOAP also has the
capability to rectify such ﬁles (i.e., modify the ﬁle so
that it satisﬁes the learned constraints [37], then pass the
rectiﬁed ﬁle along to the application). The results show
that the SOAP anomaly detector/input rectiﬁer effectively
nulliﬁes six potentially exploitable errors in the sample
applications [37].
We trained the SOAP anomaly detector on several thou-
sand input ﬁles (5130 PNG and 3386 JPG) drawn from
Fortuna’s PageRank probability distribution. These train-
ing ﬁles are disjoint from the set of ﬁles used to evaluate
the anomaly detector and compute the false positive rate
bounds.
• JSAND: JSAND is a popular, publicly available anomaly
detector for JavaScript. JSAND uses a variety of machine
learning techniques to detect “Drive-by download” at-
tacks, a common form of JavaScript malware that attempts
to automatically download malicious software onto a
users computer.
JSAND provides a widely used Internet interface that
allows a user to submit a JavaScript program to the
JSAND anomaly detector [9]. The JSAND anomaly de-
tector classiﬁes the submitted program as either normal,
suspicious, or malicious. We analyze two cases: the ﬁrst
considers suspicious ﬁles as false positives (aggressive
ﬁltering), the other considers them benign (conservative
ﬁltering).
We report results for the three anomaly detectors on sample
inputs drawn from the Internet according to the PageRank
probability distribution (see Section V). Over the course of
less than 10 hours, Fortuna was able to sample over 40,000
JPG input ﬁles, over 60,000 PNG input ﬁles, and over 8,000
JavaScript programs from the Internet according to the Page-
Rank distribution. On the resulting JPG and PNG input ﬁles,
SIFT encountered no false positives. SOAP encountered fewer
than 1,000 false positives on these same ﬁles. JSAND encoun-
tered 12 suspicious and 0 malicious JavaScript programs. The
resulting false positive rate bounds are quite tight. Speciﬁcally,
on all programs evaluated, Fortuna guarantees that SIFT has
a false positive rate below 0.011%, with 99% conﬁdence. The
false positive rate for SOAP is 1.99% ± 0.83% for JPEG ﬁles
and 0.29%±0.67% for PNG ﬁles, both two-sided bounds with
conﬁdence 99%. For JSAND, the false positive rate is less
than 0.52% with conﬁdence 99% if conservative ﬁltering is
performed (i.e. suspicious inputs are not rejected). If aggressive
ﬁltering is used (i.e. suspicious inputs are considered malicious
and rejected), it is necessary to use the somewhat weaker
two-sided bound, which guarantees the false positive rate is
0.14%± 1.73% with conﬁdence 99%. These results show that
it is very feasible to use Fortuna in practice to obtain tight
bounds on false positive rates for anomaly detectors.
D. Contributions
This paper makes the following contributions:
• Technique: We present a technique for obtaining tight
probabilistic bounds on the false positive rates that
anomaly detectors will encounter when deployed in pro-
duction use. This technique is, to the best of our knowl-
edge, the ﬁrst technique to provide any bound whatsoever
on anomaly detector false positive rates.
• Distribution and Sampling Algorithm: One of the
keys to obtaining tight bounds is obtaining a probability
distribution that reﬂects the distribution of inputs that
the anomaly detector will encounter in practice. At the
same time, this probability distribution must also support
a sampling algorithm that is efﬁcient enough to use in
practice. This paper presents a combination of probability
distribution and sampling algorithm that satisﬁes both of
these constraints. The distribution models inputs encoun-
tered by a typical user browsing the Internet (currently
one of the most common input sources for anomaly
detectors).
• Analysis: We present a formal analysis of the sampling
algorithm and resulting false positive guarantees. This