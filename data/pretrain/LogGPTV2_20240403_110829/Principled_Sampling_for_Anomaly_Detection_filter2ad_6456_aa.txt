# Principled Sampling for Anomaly Detection

**Authors:**
- Brendan Juba, Washington University in St. Louis
- Christopher Musco, Massachusetts Institute of Technology
- Fan Long, Massachusetts Institute of Technology
- Stelios Sidiroglou-Douskos, Massachusetts Institute of Technology
- Martin C. Rinard, Massachusetts Institute of Technology

**Contact:**
- Brendan Juba: [PI:EMAIL]
- Christopher Musco, Fan Long, Stelios Sidiroglou-Douskos, and Martin Rinard: {fanl,cpmusco,stelios,rinard}@csail.mit.edu

## Abstract
Anomaly detection is crucial for protecting computer systems from unforeseen attacks by automatically recognizing and filtering atypical inputs. Balancing the sensitivity of a detector is challenging: an aggressive system may filter too many benign inputs, while a conservative system may miss anomalies. Rigorous testing of anomaly detectors is essential to evaluate potential error rates before deployment. However, principled testing methods have not been well-studied, leading to ad hoc approaches that are difficult to reproduce or compare.

To address this, we present Fortuna, a technique and implemented system for obtaining probabilistic bounds on false positive rates for anomaly detectors processing Internet data. Fortuna uses a PageRank-based probability distribution and an efficient sampling algorithm to compute estimated false positive rates and their probabilistic bounds. By drawing test samples from a well-defined distribution that correlates with real-world data, Fortuna provides reproducible, comparable, and theoretically sound results.

Experimental evaluations of three anomaly detectors (SIFT, SOAP, and JSAND) show that Fortuna can efficiently sample enough inputs to obtain tight false positive rate bounds within 10 hours. These results indicate that Fortuna can help place anomaly detection on a stronger theoretical foundation and assist practitioners in better understanding the behavior and consequences of deployed anomaly detectors.

Additionally, we provide a theoretical analysis of the convergence rate of the random surfer process defining PageRank, which guarantees the same rate as the standard second-eigenvalue analysis without relying on assumptions about web link structure.

## 1. Introduction
Anomaly detection systems are critical components of many security systems. They recognize and discard, sanitize, or nullify outlier inputs that might exploit security vulnerabilities. However, these systems are not perfect and must balance two types of errors:

- **False Positives (Type I Error):** Occur when a benign input is incorrectly rejected. High false positive rates can significantly impair system utility.
- **False Negatives (Type II Error):** Occur when a malicious input is incorrectly accepted, leaving the system vulnerable to attack.

Balancing these rates is essential for effective anomaly detection. Current techniques for tuning anomaly detectors are ad-hoc, lacking a theoretically sound framework. This makes it difficult to guarantee the effectiveness of the detector in production and to effectively test its performance.

We introduce Fortuna, a technique and system that provides bounds on the number of false positives for anomaly detectors handling Internet data. Fortuna's approach is broadly applicable and can be extended to other classes of anomaly detectors.

### 1.1 False Positive Bounds
Fortuna's sampling algorithm collects a sequence of randomly chosen benign inputs, enabling it to derive probabilistic bounds:

- **One-Sided Bound:** For detectors with no false positives in the test inputs, Fortuna provides a bound of the form \( P(\text{err}(1) < \epsilon) \geq 1 - \delta \), where \(\text{err}(1)\) is the actual Type I error (false positive rate), \(\epsilon\) is an upper bound on this rate, and \(1 - \delta\) is the certainty level.
  
- **Two-Sided Bound:** For detectors with some false positives, Fortuna provides a bound of the form \( P(|\text{err}(1) - \hat{\text{err}}(1)| < \epsilon) \geq 1 - \delta \), where \(\hat{\text{err}}(1)\) is the empirical Type I error for the sampled inputs, and \(\epsilon\) is a bound on the difference between the actual and empirical error rates.

These bounds are based on standard statistical inequalities and become tighter as the number of samples increases. For the one-sided bound, the number of required samples is proportional to \((1/\epsilon) \cdot \log(1/\delta)\); for the two-sided bound, it is proportional to \((1/\epsilon^2) \cdot \log(1/\delta)\).

### 1.2 Accurate Sampling
To provide accurate false positive bounds, Fortuna's sampling algorithm delivers inputs from a probability distribution that accurately models the distribution encountered in production. The standard approach of collecting a large set of inputs from the Internet does not provide an accurate estimate because the anomaly detector is more likely to encounter some inputs than others, depending on the collection method.

Fortuna uses a PageRank-based probability distribution, which was originally designed to weight web pages according to user desirability. Generating samples from this distribution is computationally tractable and enables Fortuna to generate large sequences of inputs.

### 1.3 Experimental Results
We evaluated Fortuna on three anomaly detectors: SIFT, SOAP, and JSAND.

- **SIFT:** Uses a conservative static program analysis to obtain constraints on image file fields. SIFT guarantees the absence of integer overflow errors but may reject some benign inputs.
- **SOAP:** Learns characteristics of image file fields and infers constraints. It can also rectify files to satisfy learned constraints.
- **JSAND:** Detects JavaScript malware using machine learning techniques. It classifies programs as normal, suspicious, or malicious.

Over less than 10 hours, Fortuna sampled over 40,000 JPG files, 60,000 PNG files, and 8,000 JavaScript programs. SIFT encountered no false positives, SOAP had fewer than 1,000 false positives, and JSAND encountered 12 suspicious and 0 malicious programs. The resulting false positive rate bounds are tight, demonstrating the feasibility of using Fortuna in practice.

### 1.4 Contributions
This paper makes the following contributions:
- **Technique:** A method for obtaining tight probabilistic bounds on false positive rates for anomaly detectors.
- **Distribution and Sampling Algorithm:** A combination of a probability distribution and sampling algorithm that reflects real-world input distributions and is efficient.
- **Analysis:** A formal analysis of the sampling algorithm and resulting false positive guarantees.

By providing a principled approach to testing anomaly detectors, Fortuna helps practitioners better understand and improve the performance of their systems.