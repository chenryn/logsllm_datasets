similarly to Comet [19]. It embeds a reputation system that
relies on the capacity of nodes to store documents until their
expiration. In contrast, RECAST assumes to always have sufﬁ-
cient storage capacity, and documents never vanish. Moreover,
RECAST is not intended to provide anonymity, an orthogonal
concern to be handled by upper layers.
PUBLIUS [1] encrypts and spreads documents over a set
of (static) servers. The data encryption key is secret-shared
among k of the n servers using (k, n)-Shamir secret sharing.
Each server hosts the encrypted PUBLIUS content and a share
of the key. The content can be tamper-checked because it is
cryptographically tied to the Publius address: any modiﬁcation
of one of these two components will cause the tamper check
to fail. RECAST implements tamper-check by exploiting de-
coding in document reads: if any block is corrupted, then the
decoding fails and reconstruction is triggered.
MNEMOSYNE [20] is a steganographic peer-to-peer storage
system. Nodes are continuously ﬁlled with random data. Upon
archival of a real document, its content is encrypted and made
indistinguishable from the random substrate, preventing an
attacker to determine the existence of a ﬁle and ensuring
privacy and deniability of the content itself. As in PUBLIUS,
data is spread across nodes [21] mainly for resiliency and each
of the nodes is unaware of the other nodes holding parts of the
ﬁle. RECAST tolerates a stronger threat model where storage
nodes have access to metadata information.
and replicating the most valuable pieces of compressed infor-
mation. DEEPSTORE relies on the PRESIDIO framework [23]
to implement hybrid compression across heterogeneous data,
as well as deduplication to eliminate redundant data.
LOCKSS [24] is an archival system based on a voting
protocol. The “opinion pools” provide system peers with
conﬁdence in content authenticity and integrity. Moreover,
content is replicated among peers and replicas are regularly
audited to promptly repair any damage. RECAST implements
temporary replication to protect recently inserted documents
and uses an auditing subsystem to remove temporary replicas
from the system as soon as blocks are sufﬁciently entangled.
SAFESTORE [9] is a distributed storage system offering
long-term data durability. It exploits an aggressive isolation
scheme across multiple storage service providers. It uses an
informed hierarchical erasure coding scheme that maximizes
data durability and provides redundancy in the fault-isolated
domains. Depending on the code’s parameters, a certain num-
ber of faults can be recovered in each fault-isolated domain
and an auditing subsystem further monitors data loss and
triggers reconstruction. RECAST and Safestore sit on opposite
sides from an architectural point of view: while RECAST
uses entanglement, SAFESTORE exploits aggressive isolation,
which leads to high durability but does not offer strong
resilience against an active censor.
PERCIVAL [25] and POTSHARDS [15] are two systems
relying on secret-splitting techniques. The latter offers long-
term security by using two levels of secret splitting and
placement. The ﬁrst level provides secrecy by XORing content
with random data. It produces n fragments using (k, n)-Shamir
secret sharing and places them into shards for availability.
Shards retrieval is based on indexes accessible by all users, in
a similar manner to RECAST’s metadata indexes. POTSHARDS
uses approximate pointers to allow for quick reconstruction of
user data without the need of external information, similar to
RECAST’s emergency recovery procedure.
Finally,
the design of RECAST is based on STEP-
archival [5]. STEP-archival is the theoretical foundation of
RECAST and provides tools such as greedy attack heuristics
and recursive reconstruction that we exploit in this work. We
elaborate on such a base to build a practical STEP-archive. In
practice, we overcome the poor short term protection of the
uniform random entanglement studied in [5] by developing
new entanglement heuristics. Moreover, we build a complete
storage system that we evaluate by means of our fully-ﬂedged
in greater
prototype.
details.
Section IV presents STEP-archival
IV. STEP-ARCHIVAL
In this section we revisit the technique presented in [5] for
creating interdependencies between data to be stored and data
already archived in the system. Upon archival, the blocks of
a document are entangled with some blocks of documents
previously archived in the system. The entanglement builds
strong ties between content, preventing silent censorship of
rarely accessed data. An attacker wishing to censor a target
173
OCEANSTORE [13] is a persistent data store on top of an
untrusted infrastructure. It uses promiscuous caching (data is
cached everywhere and at any time) to enhance locality and
availability. This solution relies on classic erasure coding tech-
niques, speciﬁcally a Cauchy Reed-Solomon code of length 32
and dimension 16 [22], to ensure durability.
DEEPSTORE [10] is a large-scale archival system for im-
mutable data. It achieves a good efﬁciency/redundancy com-
promise by applying compression with inter-ﬁle dependencies
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:23:09 UTC from IEEE Xplore.  Restrictions apply. 
document 

...

...

...
1
1
1
split into s source blocks
s source blocks
s
select t pointers (Section V)
s
1
...
...
t pointers
t
create p parities via Reed-Solomon encoding
s
1
...
t
1
store parities only
...

p parities
p
1
...
p
Fig. 1. Entanglement logical ﬂow.
document must cause collateral damage by corrupting several
other archived documents.
More formally, a (s, t, e, p)-archive [5] is a storage system
where each archived document consists of a codeword of s
source blocks, t pointers or tangled blocks (i.e., old blocks
already archived in the system), p parity blocks, and that can
correct e = p− s erasures (e.g. missing blocks) per codeword.
The logical ﬂow to archive a document in a (s, t, e, p)-
archive is illustrated in Figure 1. The document to be archived
is split into s ≥ 1 source blocks (solid ﬁll) . From the
archive, t distinct old blocks, the pointers (dot pattern), are
selected  and a Reed-Solomon (RS) code is used to create
p ≥ s parity blocks (stripe pattern)  depending on both
source blocks and pointers. In particular, the p parity blocks
are computed using a RS(s + t + p, s + t) code [26], which
encodes s + t blocks into a (s + t + p)-long codeword with the
property that any s + t blocks of the codeword are necessary
and sufﬁcient to reconstruct all its s + t + p blocks [22].
In
the last step , we only archive the p parity blocks (making
the code non-systematic). The t pointer blocks come from the
archive so we do not need to store them again. The choice of
not storing the source blocks enhances security [5]. As a trade-
off, read performance is degraded both in terms of latency
and bandwidth since reading a document from a STEP-archive
always requires a decoding operation involving s+t blocks, as
opposed to a systematic code where the s alive source blocks
can be directly accessed.
STEP-archive asymmetry. To censor an archived docu-
ment, it is not always sufﬁcient to destroy its code blocks
because they can sometimes be recovered recursively. On the
one hand, it has been proven [5] that ﬁnding the minimal
set of documents required to irrecoverably censor a target
document is NP-hard. On the other hand, the system can repair
recoverable attacks using a simple and efﬁcient reconstruction
algorithm: we ﬁrst scan the archive and build a set C of
corrupted document with at most e erased blocks. We pick a
document from C, repair it, and update the set of documents
uniform entanglement
normal entanglement with standard deviation σ = 1000
normal entanglement with standard deviation σ
normal-uniform entanglement with standard deviation σ = 1000
normal-uniform entanglement with standard deviation σ
u
n
nσ
nu
nuσ
l
c
rα
leaping attack
creeping attack
level of temporary replication α
TABLE II
NOTATION. E.G., WE WRITE U-L-(S,T,E,P)-Rα FOR THE LEAPING
ATTACK RUNNING ON A (s, t, e, p)-ARCHIVE WITH UNIFORM
ENTANGLEMENT AND KEEPING α TEMPORARY COPIES FOR EACH
DOCUMENT IN THE TAIL OF THE ARCHIVE. THE REPLICATION PARAMETER
IS OMITTED WHEN TEMPORARY REPLICATION IS NOT IN PLACE.
with at most e erased blocks in C. The algorithm stops when
C is empty. At this point, either the system is completely
repaired or there is a closed set of documents with strictly
more than e erased blocks.
Flavors of entanglement. Different ﬂavors of entanglement
are studied in [5]. Uniform random entanglement selects
pointer blocks uniformly at random. The randomness of this
approach is an advantage as pre-planning an attack against
such a structure is not feasible. Uniform entanglement has
the main drawback of requiring increasingly longer periods of
time to protect young documents as the archive increases. For
example, Figure 2 shows that after inserting 10000 documents,
25% them are either not pointed to or pointed to only once.
An attacker wishing to tamper with these documents can thus
do so without causing collateral damage. The authors of [5]
also show how to speed up the protection of new documents
by selecting the pointers to entangled blocks from a sliding
window bounded to the recent past, although this has the
drawback to bound the entanglement level of the documents
in the archive.
Practical resilience to censorship. Since censoring a
document optimally is NP-hard, to evaluate the censorship
resistance of the system, one can rely on suboptimal heuristics.
We exploit the greedy attacks as well as a branch and bound
technique introduced in [5]. We include a brief summary and
refer the reader to [5] for more details.
We play the attacker and we select a target to be censored.
Erasing blocks in the target produces erasures in other doc-
uments because of entanglement. To prevent recursive repair
we must corrupt those documents as well. So at each step of
the attack we face the choice of which block to delete and we
use one of two greedy heuristics to make the decision:
• The leaping attack leverages the fact that it is easier to
attack recent documents rather than old ones (because
they have fewer incoming pointers).
• The creeping attack tries to keep the set of corrupted
documents as compact in time as possible by preferring
documents having approximately the same archival date,
which is very effective against window-constrained en-
tanglement strategies.
It is possible to improve on these greedy heuristics by means of
a branch and bound technique: at each step of the computation
of the minimal set of blocks to be erased, we retain the
174
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:23:09 UTC from IEEE Xplore.  Restrictions apply. 
s
r
e
t
n
o
p
#
i
 20
 15
 10
 5
 0
Uniform Entanglement - Pointer Distributions
95th
90th
75th
50th
25th
Min
1
2
3
4
5
6
7
8
9
10
# archived documents (x1000)
s
t
n
e
m
u
c
o
d
d
e
y
o
r
t
s
e
d
#
1500
1000
500
0
0
1
2
t=3
t=4
t=5
t=10
998000 docs
2000 docs
4
3
index target document (x100000)
5
6
7
8
9 9.98
9.98 9.99 10
Fig. 2. Variation of number of pointers to each document in a u-(1, 5, 2, 3)-
archive with 104 documents. At the end, the 25% of documents is pointed to
at most once, hence not protected by entanglement.
Fig. 4. Number of corrupted documents to erase a target (x-axis) with a
creeping attack in a n-(1, t, 2, 3)-archive with t = 3, 4, 5, 10. Notation in
Table II.
t=3
t=4
t=5
t=10
s
r
e
t
i
n
o
p
#
 20
 15
 10
 5
 0
Normal Entanglement - Pointer Distributions
95th
90th
75th
50th
25th
Min
1
2
3
4
5
6
7
8
9
10
# archived documents (x1000)
Fig. 3. Variation of number of pointers to each document in a n-(1, 5, 2, 3)-
archive with 104 documents. Normal entanglement evenly spreads the pro-
tection among documents: at the end the 50% of documents have between 5
and 9 pointers.
best partial solutions up a certain buffer size and expand
all of them. Throughout the paper we adopt the notation
summarized in Table II.
V. HYBRID ENTANGLEMENT
In this section, we leverage the beneﬁts of the uniform and
window entanglement strategies. We present a hybrid entangle-
ment technique mixing pointers chosen uniformly at random
and pointers chosen from a normal distribution. We further
enhance anti-censorship for recently archived documents using
temporary replication.
Normal entanglement. To archive document di+1, we ex-
tract t pointer blocks from a left half-normal distribution with
standard deviation σ centered in the last archived document
di. This models a sliding window of about size 2σ, in which
the probability to point to a document older than di−2σ is 5%,
and the probability to point to a document older than di−3σ is
0.3%. On the one hand, this means that documents are quickly
protected: we just need to wait for 2σ documents to reach the
average protection offered by the archive. Furthermore, this
does not depend on the size of the archive but only on the
chosen standard deviation σ. Comparing Figures 2 and 3 we
s
t
n
e
m
u
c
o
d
d
e
y
o
r
t
s
e
d
#
106
105