benefits of commercial tools comes from the maintenance. A commercial fuzzer tool
vendor will ensure future development and updates for a fixed fee that is easy to
forecast and is always lower than dedicated or contracted personnel. A contracted
fuzzer can also be negotiated to come with a fixed maintenance fee. The main
advantage of an in-house development is having complete control over the project
and being able to customize the fuzzer for your specific product.
The pricing of commercial tools can also be difficult to estimate without under-
standing how the world of commercial fuzzers works. Whereas a subscription license
to a Web fuzzer can cost $17,000 a year, a complete protocol fuzzer for telecommuni-
cation interfaces can cost hundreds of thousands of dollars. This (hopefully) depends
on the costs that the fuzzer company needs to cover, and the business opportunity
they see with that product. Development, testing, maintenance, support, product
training, and other related services do not come for free. Still, this is typically an
area where commercial products rule, as they can cover the implementation costs
with a number of sales. A fuzzer that takes several dedicated people to develop
and maintain can reach better test coverage at a fraction of the costs compared to
contracted development. On the other hand, contract developers do not turn down
requests just because they see only a small market opportunity for such a tool,
meaning for very specialized or proprietary protocols, commercial fuzzers will not
be a possibility. It would be interesting to compare the test results of the contract
programmer with the test efficiency of other fuzzer products, but unfortunately
these proprietary tools are not easily available for comparison. There are several
examples in which a person who knows one particular test subject (or protocol)
precisely can use that knowledge to build a more efficient fuzzer for that specific
setup. But, on the other hand, commercial companies doing fuzzers day in and day
out might have more experience and feedback from their customers to improve the
tests as time goes on. Commercially available fuzzers have also usually been verified
to work with as many implementations of the tested interface as possible, which
indicates that they are more likely to work also against any new implementations.
Nevertheless, forecasting the efficiency of a fuzzer is a very difficult task.
In our comparison we have not made a significant difference in the test execu-
tion times. Whereas tests conducted as part of a larger test process can easily take
a week to execute without hurting the overall process, a fuzz test conducted as
part of regression tests can almost never take more than 24 hours to execute. The
requirements set for test automation depend on what you are looking for. How
much time can you dedicate for the test execution? Where do you apply the tests
in your SDLC? And what types of people do you have available? The purposes of
test automation in general are to
• Reduce time from test to fix;
• Make testing repeatable;
• Reduce expertise and human error.
6760 Book.indb 113 12/22/17 10:50 AM
114 Fuzzing Metrics
Commercial tools are typically built according to real test automation require-
ments set by commercial customers, and therefore, commercial fuzzers should
integrate easily with existing test execution frameworks (test controllers) and test
subject monitoring tools (instrumentation mechanisms). But it is understandable
that those integration interfaces do not apply to 100% of the users, especially when
the test target is a proprietary embedded device. Therefore, actual integration can
vary from plug-and-play to complex integration projects.
Sometimes an internally built one-off proof-of-concept fuzzer is the best solu-
tion for a security assessment. The total costs involved can be cheaper compared to
commercial tools, but the results may not necessarily be the most effective. That is
to say, a custom fuzzer may be significantly cheaper but miss a few bugs that may
have been found by a commercial fuzzer. It really depends on the priorities of the
project. When making your final decision on the fuzzer project, please remember
the users of the fuzzers. Most of the commercial tools out there are ready to be used
by the average QA person without any changes by the end users, whereas for other
tools there will be almost always constant customization needs. The techniques
used in fuzzers (and explained in later chapters) will influence the easiness of those
changes for various future needs.
From a test automation perspective, the actual usage of the tools varies, as we
will explore in later chapters. Most commercial tools are ready to go in the test
setup in that you can install them and immediately fire them up, giving them an IP
to blast away at. From a QA perspective, you might want a few additional things
to be at your disposal, and therefore, increase the cost of the test environment (tes-
tbed), for example, instrumentation. Various tools can be used to catch the crashes
or other suspicious failures. In fuzzing you need to do this in an automated fashion.
Valgrind10 is an example analysis framework for the Linux platform, and PaiMei/
Pydbg is a great example of this for the Windows platforms, as you can have the
tested application crash, do its core dump, and then respawn the process to con-
tinue with your next test case. After you are finished with the test run, you will
have an accurate picture of where the problems lie. Additional on-host instruments
can monitor thread counts, file handle counts, and memory usage. The problem
with on-host instrumentation is supporting all possible embedded devices and both
commercial and proprietary operating systems used in application platforms. Most
development platforms offer such monitoring in their development environments
and through various debuggers. We will discuss this more in Chapter 6.
4.2.2 Cost of remediation
In addition to the cost of discovery, we also need to understand the cost of fixing
each bug. After a software vulnerability is found, developers need to go back to
the drawing board and fix the flaw. A flaw found during the design phase is less
costly than a flaw found after the product has been launched. Various attempts at
summarizing the economics of software defects indicate very similar results, and
people only argue about the actual multipliers in the cost increase. Figure 4.2 gives
10 For more information on Valgrind, see http://valgrind.org.
6760 Book.indb 114 12/22/17 10:50 AM
4.2 Transition to Proactive Security 115
one perspective to the cost increases, based on various studies and especially those
from NIST.
A tool that automatically categorizes the findings during the discovery phase
can reduce the cost of defect elimination. When the person conducting the tests can
immediately see that 10 programming flaws cause the failures, he or she can then
issue fewer reports for those in charge of the repairs. With a fuzzer that is based on
semi-random inputs, you can potentially have 100,000 tests that find something
suspicious. Analyzing all those problems will take more time than just analyzing
ten identified and verified flaws.
Two categories of metrics can apply to the repair process:
• Resources needed to fix the problems (required time from the development
people): After the failures have been analyzed, the developers start their task
in analyzing the bug reports and fixing the flaws. Although there rarely are
any false positives with fuzzing, a common problem with the test results is
that a large number of issues can be caused by a single flaw.
• Time required to fix the found issues (delays to product launch): Adding more
developers to the repair process does not necessarily reduce the total calendar
days spent on repairing the found issues.
4.2.3 Cost of Security Compromises
An important aspect of security is the assurance of service availability and software
reliability. Reliability is measured by up-time and downtime and studies the reasons
Figure 4.2 The increasing cost of repairing with estimates on the numbers of defects found,
with relation to the development phase where discovered (based on NIST publications).
6760 Book.indb 115 12/22/17 10:50 AM
116 Fuzzing Metrics
for the downtime, or outages. Downtime can be either planned or unplanned and
can be due to change control or third-party involvement, or even an act of god such
as an earthquake. Planned downtime can be due to regular maintenance such as
deploying regularly released security updates or to scheduled activities related to
upgrades and other housekeeping jobs. Security compromises are an example of
unplanned events that are caused by a third party (an attacker), and they often lead
to downtime of a device or a service. But security incidents are not the only reason
for unplanned downtime of critical systems. Other unexpected outages include hard-
ware failures, system failures, and natural disasters. As traditional metrics already
exist for these purposes, they should be applied as metrics to security-related avail-
ability analysis. The metrics used by IT operations personnel study the efficiency
of IT reliability, and these same metrics are applicable to the inability of software
to withstand denial of service attacks. Useful metrics related to uptime include:11
• Measured up-time of software, host, or service (percent, hours) gives the
availability metric such as five nines 99.999% uptime.
• Planned downtime (percent, time) is the total amount of time that resources
were out of service due to regular maintenance.
• Unplanned downtime (percent, hours) shows the total amount of time related to
unexpected service outages and represents the change control process variance.
• Unplanned downtime due to security incidents (percent, hours) is often a
subset of the above and indicates the result of security shortcomings.
• Mean/median of unplanned outage (time) characterizes the seriousness of
a typical unplanned outage, again with a special attention to those that are
security related.
• System revenue generation (cost per hour) shows the business value of the
service or the system, such as loss of revenue per hour of downtime.
• Unplanned downtime impact (cost) quantifies foregone revenue due to the
impact of incidents.
• Mean time between failures (time) characterizes how long systems are typi-
cally up between failures.
• Loss of data (cost) fees associated with loss of data due to security breach.
• Intangibles (cost) loss of business or credibility due to outages, especially those
caused by security incidents.
When such metrics are in place and monitored, the amount of downtime related
to security incidents can create revealing insight into the value of software vulner-
abilities. However, there is one problem with some of the above availability metrics
from a security perspective. When a hidden security vulnerability exists in a system,
the system can be shut down by anyone who knows the details of that vulnerability
at any given time. Furthermore, the system can be kept down using repeated attacks.
Typical availability metrics work best when incidents are not caused by humans.
For example, all the above metrics are better suited for hardware-related failures.
Still, these metrics are very useful because the people responsible for IT operations
11 Andrew Jaquith. (2007). Security Metrics: Replacing Fear, Uncertainty, and Doubt (pp. 68–71)
Boston: Addison-Wesley.
6760 Book.indb 116 12/22/17 10:50 AM
4.2 Transition to Proactive Security 117
easily understand them. These metrics are highly valuable when the direct costs
related to security incident needs to be explained to people who have not personally
encountered a security incident, at least not yet.
The cost can also be the actual value of the device or a service, which is very
direct and concrete. For example, in cases in which security vulnerabilities are found
and exploited in embedded devices, the system can become corrupt to a point that
it cannot be repaired or it would require reprogramming by the manufacturer. The
same applies when critical data is destroyed or leaked to the public. These types of
mistakes can be impossible for the end user to repair.
A commonly used metric for this purpose is ROSI (return on security invest-
ment). If investment in a fuzzer is less than the value (cost) of a security incident
multiplied by the probability of an incident, the investment in fuzzing can be justified.
4.2.4 Cost of patch Deployment
Deploying changes to the system after failure creates additional direct and measur-
able costs besides the direct costs caused by the incident itself. Some of these metrics
are directly related to the downtime metric in case the system requires third-party
involvement to recover from the crash or failure. Such metrics provide additional
information related to the maturity of the process of recovering the system back to
running. These system recovery related metrics are:12
• Support response time (average time) indicates the time it takes from the out-
age to the time of response from the responsible internal support personnel,
or from the manufacturer or vendor of the failing component.
• Mean time to recovery (time) characterizes how long it takes to recover from
incidents once the repair activities are started.
• Elapsed time since last disaster recovery walk-through (time) shows the rela-
tive readiness of disaster recovery programs.
Although this metric can be adequate for an enterprise user, it does not provide
enough details on what happens behind the scenes when the failure is repaired.
Repairing a security mistake is almost never as easy as removing the failing compo-
nent and replacing it with a functional component. Problems related to the recovery
metrics from the software security perspective are related to the complexity of the
security updates and the readiness of the entity responsible for software develop-
ment to dedicate resources for creating such security update. The problem cannot
be fixed by the IT staff if there is no update or patch available to deploy. In our
research we have seen everything from a matter of hours up to more than a year of
response time from the discovery of a new security flaw into releasing an update
to correct the software. Unfortunately, in many cases, without public disclosure
of the vulnerability details, or without an incident related to that specific security
flaw, a vendor might not be motivated enough to develop and release these critical
updates to its software. This is apparent from the metrics available from the OUSPG
12 Andrew Jaquith. (2007). Security Metrics: Replacing Fear, Uncertainty, and Doubt (pp. 71–72).
Boston: Addison-Wesley.
6760 Book.indb 117 12/22/17 10:50 AM
118 Fuzzing Metrics
disclosure process shown in Figure 4.3.13 The OUSPG research team noted time
frames from a matter of days up to several years from the disclosure of the issue to
the manufacturer to the release of an update. On the other hand, if the flaw was
reported publicly (public disclosure), it was typically fixed in matter of few hours
up to few weeks.
Change control and configuration management are critical components of any
effective security program. These define the process for managing and monitoring
changes to the configuration of the operational environment. Clear separation of
duties in relation to updating and configuring the system and strong access control
for making those critical changes are needed. No change should happen without a
process, and all changes should be clearly tracked. These preparations will enable
the use of metrics related to change control:14
• Number of changes per period (number) measures the amount of periodic
change made to the production environment.
• Change control exemptions per period (number, percentage) shows how often
special exceptions are made for rushing through changes.
• Change control violations per period (number, percentage) shows how often
change control rules are willfully violated or ignored.
From a security perspective, special attention is paid to deploying security
updates, patches, workarounds, and other configuration changes related to security.
To be prepared for the abovementioned exemptions, and even violations in cases of
a crisis, are critical when a critical security update needs to be deployed in a matter
of hours from its issuance by the relevant vendor. A strict environment that is not
ready for immediate updating can be vulnerable to attacks until these protective
measures are in place.
Regression testing, or patch verification, is a critical metrics for patch develop-
ment and deployment. Fuzzing needs to be repeatable. This is why most fuzzing tools
pay significant attention to the repeatability of each test. An important aspect of
testing in QA is being able to perform regression tests to ensure you are not causing
new bugs because of issuing fixes to old problems. A pseudo-random fuzzer does
a great job of this by providing a seed value when you initiate fuzz testing. Other
fuzzers use or create static test cases that can be used for regression tests. Note that
the repeatability with random testing needs to take into account the changes in the
tested interface. Communication interfaces are constantly updated as new protocol
specifications emerge. A traditional random fuzzer typically takes two seeds: the
data seed (e.g., a network capture) and the seed for the randomization process. If
either one of these changes, you will have a different set of tests on your hands, and
you cannot thoroughly verify the vendor-issued patch with the new modified test
setup. In model-based testing, these two seeds are not needed, but instead the tests
13 M. Laakso, A. Takanen, J. Röning. “The Vulnerability Process: A Tiger Team Approach to Resolving
Vulnerability Cases.” In Proceedings of the 11th FIRST Conference on Computer Security Incident
Handling and Response. Brisbane, Australia. June 13–18, 1999.
14 Andrew Jaquith. (2007). Security Metrics: Replacing Fear, Uncertainty, and Doubt (pp. 72–73).
Boston: Addison-Wesley.
6760 Book.indb 118 12/22/17 10:50 AM
4.3 Defect Metrics and Security 119
Figure 4.3 Disclosure process and milestones used in disclosure metrics.
are built from an interface specification. The generated tests remain the same, until
an eventual change in the used protocol specification will necessitate a change in
the tests produced by model-based fuzzing test tool.
4.3 Defect Metrics and Security
Measuring the security of software-based solutions is a difficult task, because secu-
rity is a hidden property only visible when individual vulnerabilities are uncovered.
Through different vulnerability assessment methodologies and testing techniques,
we are able to get some visibility into the true security of a product or a service. The
challenging part is turning those results into something measurable. We can apply
some selected metrics from the quality assurance side or from the security field to
summarize our findings into something that is easier to grasp even by someone
6760 Book.indb 119 12/22/17 10:50 AM
120 Fuzzing Metrics
who does not understand the technology that well. Fortunately, some methods of
fuzzing, and especially robustness testing, are very useful techniques in providing
more insight in this type of measurement. Interestingly, the same metrics can also
be used to assess the efficiency of the testing technique itself. To understand this
better, let us first have a look at some useful metrics in software security.
The first challenge we encounter is how to define the software or the system
being assessed. The simplest metrics we need to collect are related to the software
itself and are drawn from white-box tools. These techniques are based on the source
code and include metrics such as the number of lines of code, branches, modules,
and other measurable units. The software also needs to interact with the outer world
to be useful, and therefore, looking at the software from a black-box perspective
gives us a new set of metrics. These include available services, open network ports
or sockets, wireless interfaces, and user interfaces.
The term attack surface has been used to indicate the subset of the complete
application that can be accessed by attackers. Several different metrics are used to
define attack surfaces. From the top down, a network-topology-based attack surface
can identify which networked computers are susceptible to attacks by nontrusted
parties such as local users or by anyone with access to the internet. When the hosts
have been identified, the analysis can be extended to the network services on those
hosts that are accessible from the open network or through other remote or local
interfaces. Finally, various code coverage metrics can be used against each identified
service for studying which part of the exposed applications can be accessed through
those interfaces. Measuring the attack surface of an individual piece of software