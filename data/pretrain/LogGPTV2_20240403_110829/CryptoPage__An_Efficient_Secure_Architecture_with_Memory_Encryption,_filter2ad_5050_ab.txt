the probability of a collision is high (> 1/2) after
2119 =
259.5 random draws. So after 259.5 permutations, the risk of
collision, and so of using the same encryption pad twice, is
high. Even if the processor was able to perform a chunk per-
mutation every cycle at 1 GHz, it would take about 25 years
on average to ﬁnd a collision, so this is not a critical security
issue. In addition, to perform an attack, the attacker would
have to know when the collision happened and this is not
possible if R(cid:1)
c,p is encrypted in the page information data
structure.
However, the counter mode does not provide any in-
tegrity protection. It is very easy to modify plaintext with-
out being detected so we have to use another mechanism.
In our proposition, the integrity protection (provided by
the MAC function) is applied on the encrypted data. This
scheme is called Encrypt-Then-MAC in the literature. Bel-
lare et al. have proved in [3] that this construction does not
decrease the conﬁdentiality of the encrypted data and that,
if the MAC function used is sufﬁciently strong, it guarantees
the integrity of the data.
Before using a line read from the memory, the proces-
sor needs to decrypt and verify it. To decrypt the line, the
2If we use the following parameters: the encryption algorithm is AES
whose block size is 128 bits; the size of a cache line is 32 bytes (256 bits),
so i is 1-bit long; the size of a memory page is 8 kB, so the number a of
the cache line in the page is 8-bits long.
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006processor computes the pads and performs a bit-wise XOR
between the content of the line and the pads (the inverse of
equation 2). The pads can be computed during the mem-
ory access as they only depend on R(cid:1)
c,p, a and Ke. If the
time needed by the encryption unit to compute these pads
is less than the time needed by the processor to fetch a line
from the memory, the pads are ready before the encrypted
data arrives and so, the end of the decryption process is per-
formed in only one cycle (the XOR operation). To verify
the integrity of the line, the processor computes the MAC
(with equations 4 to 6) and compares it to the value Ha,c
read from the memory. If they are identical, the line has not
been corrupted. This decryption mechanism is summarized
in Figure 2.
This mechanism can prevent three attacks from happen-
ing. First, an attacker cannot inject a modiﬁed value in
memory because he would need to compute the correct MAC
for it so, if the MAC function used is strong, he would need
to know the key Km and this is not the case. The attacker
also cannot copy a line and its MAC to somewhere else in
memory because the MAC depends on the virtual address
line. Finally, if the attacker cannot replay the value of the
random number Rc,p, he cannot perform replay attacks3 be-
cause the MAC depends on Rc,p which changes between
each permutation.
2.4. Protection of chunk information
Therefore, to prevent replay attacks, we need to prevent
Rc,p from being replayed. To do this, we protect the data
structure containing the information about a chunk (Rc,p,
R(cid:1)
c,p, the permutation table, etc.), which is stored in an ex-
tension of the Translation Lookaside Buffer (TLB), with a
Merkle tree [20].
The principle of this mechanism is to build a tree over
all the page data structures. The leaves of the tree are the
data structures themselves. The nodes of the tree contain a
cryptographic hash of the content of their children. The root
of the tree is stored in a secure memory inside the processor
so it cannot be altered or replayed by an attacker. When the
processor updates a chunk data structure (after a permuta-
tion for instance), it updates the values of the ancestor nodes
up to the root. When the processor reads a chunk data struc-
ture (during a TLB miss), it checks the values of the ancestor
nodes up to the root.
If we want to protect an area of n (with n a power of
2) memory elements (in our case, page data structures) rep-
resented by blog2 n,0 to blog2 n,n−1 (see Figure 3), the al-
gorithms used to perform a veriﬁed read (RV(i, j)) or write
(WV(bi,j, i, j)) are given in Figures 4a and 4b [15, 6], where
H is a one-way hash function, R(i, j) the function that re-
3A replay attack involves saving a value and its MAC and replaying
them later at the same place in memory.
b0,0 = H(b1,0, b1,1)
b1,0 = H(b2,0, b2,1)
b1,1 = H(b2,2, b2,3)
b2,0
b2,1
b2,2
b2,3
Figure 3. Merkle tree.
RV (i, j) :
bi,j = R(i, j)
while i > 0 :
2
(cid:5)
f = j ⊕ 1; p = (cid:4) j
{ Read the sibling node }
bi,f = R(i, f )
bi−1,p = R(i − 1, p) { Read the parent node }
if bi−1,p (cid:6)= H(bi,min(j,f ), bi,max(j,f )) :
i = i − 1; j = p { Continue veriﬁcation above }
error
return bi,j
(a) Veriﬁed read algorithm.
WV (bi,j, i, j) :
if i > 0 :
2
(cid:5)
f = j ⊕ 1; p = (cid:4) j
bi,f = RV (i, f )
{ Read & verify the sibling node }
bi−1,p = H(bi,min(j,f ), bi,max(j,f ))
WV (bi−1,p, i − 1, p) { Write & verify the parent node }
{ Write the node }
W(bi,j, i, j)
(b) Veriﬁed write algorithm.
Figure 4. Veriﬁed read and write algorithms.
turns the value of the node bi,j from memory (except for
b0,0 which is securely stored in a special part of the proces-
sor), W(bi,j, i, j) the function that writes the value of bi,j
to memory (except for b0,0).
This Merkle tree prevents an attacker from replaying the
values of a chunk data structure and so prevents him from
being able to replay data in memory. To reduce the time
needed to perform the check of the Merkle tree during a
TLB miss, we use a small cache that stores some nodes of
the tree. During a check operation, the processor can stop as
soon as the node of the tree that it is fetching is in this cache.
Indeed, in order to be in the cache, a node must have been
checked during a previous read operation and, as the cache
is inside the processor, it cannot be altered by an attacker,
so a node in the cache is necessarily correct. It is also a
good idea to store a node and its sibling node together in
the cache because, when we read or write a node, we will
always need the sibling node.
These data structures also need to be encrypted to guar-
antee that an attacker cannot access the permutation table,
which would destroy the information leakage protection. So
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006these structures are encrypted with the secret key Kp only
known by the processor using a symmetric algorithm, for
instance, with the AES used in the cipher-block chaining
(CBC) mode with a random initialization vector (IV).
2.5. Management of the Merkle tree
In Section 2.4, we have seen that we have to maintain
a Merkle tree over the data structures that store the chunk
information. We also have to implement the veriﬁed read
and write algorithms that check the integrity of these data
structures using the Merkle tree.
To reduce hardware modiﬁcations, we want to delegate
the loading of the secure chunk data structures and the stor-
age of the Merkle tree needed for the global certiﬁcation to
the operating system without allowing the operating system
to break the security of the running process.
The hardware provides the operating system with two
new special instructions that can only be executed in the
privileged mode: LoadNode and HashCheck, and a
special buffer, called the veriﬁcation buffer (VB) which
can contain exactly n − 1 double tree nodes (where n =
log2(maximum number of pages)).
The ﬁrst instruction, LoadNode takes three parameters:
the physical address where the value of the node bi,j is
stored, the depth i of this node and the horizontal position j
of this node in the Merkle tree. This instruction ﬁrst checks
if the node bi,j is already available in the Merkle tree cache.
If so, it does nothing except to set a special ﬂag in the pro-
cessor’s status register to inform the operating system. Oth-
erwise this instruction reads the node bi,j and the sibling
node bi,j⊕1 located at the given physical address and stores
them together in line number i of the VB.
The second instruction, HashCheck takes only one pa-
rameter: the number of the line to check in the VB. This
instruction hashes the content of the nodes bi,j and bi,j⊕1
stored in line number i of the VB and compares the result
with the parent node bi−1,(cid:3) j
2 (cid:4) which must be already stored
in the Merkle tree cache (and not in the VB). If the hash and
the parent node are equal, the nodes bi,j and bi,j⊕1 in the VB
are correct so the instruction copies them to the Merkle tree
cache. If the hash and the parent node are different, or if the
parent node is not already in the Merkle tree cache (not the
VB), the instruction triggers a security exception and aborts
the execution of the secure process.
With these two instructions and the VB, some of the op-
erations required to perform the veriﬁed read can be per-
formed by the operating system. When the processor needs
information about a page p that is not already available in
the TLB, the processor generates a special exception to in-
form the operating system that it needs to fetch and check
bn,p. Then the operating system executes the algorithm
shown in Figure 5. At the end, the operating system restarts
the execution of the process. The processor expects the
presence of bn,p in the Merkle tree cache in order to con-
tinue the execution of the process.
The load and veriﬁcation algorithm given in Figure 5
performs the following operations. First, it loads into the
VB, using the instruction LoadNode, the nodes located in
the path from the page information data structure to the root
of the Merkle tree, by beginning at the bottom of the tree.
As soon as it tries to load a node that is already in the Merkle
tree cache, it begins the veriﬁcation of the nodes from the
missing node, down to the bottom of the tree. If d is the
depth of the last missing node in the cache, the algorithm
executes the instruction HashCheck d which veriﬁes that
H(bd,2i, bd,2i+1) = bd−1,i.
If this veriﬁcation succeeds,
the two nodes at depth d are correct, so the instruction
HashCheck can move them from the VB to the Merkle
cache. The algorithm performs this operation several times,
up to the leaves of the tree. If no security exception was
raised during veriﬁcation, at the end of the algorithm, the
node requested by the processor is in the Merkle tree and so
the secure process can restart.
The Merkle tree cache and the VB are also automatically
invalidated when the processor switches from one secure
process to another. With this solution, the operating system
can choose by itself the best way to store and to manage
the Merkle tree as it is the operating system that tells the
processor where to ﬁnd information about a page and the
nodes of the tree.
2.6. Other security aspects
Several other aspects required to implement our archi-
tecture are not studied in this paper because they have been
studied elsewhere. For instance, the conﬁdentiality and the
integrity of the hardware context of a secure process have
to be maintained during an interrupt or while another pro-
cess is running. The operating system, or any other pro-
cess, should not have access to the state of the registers
during an interrupt. In addition, the creation and the load-
ing of an encrypted binary is also not described here. All
these points have been described in depth in several arti-
cles [26, 17, 16, 5, 30].
When an interrupt occurs, the hardware context (which
contains the registers, the encryption keys, the root of the
Merkle tree, etc.) of the current running secure process is
saved into one of several hardware context buffers (HCB)
inside the processor. Next, all the registers are blanked in
order to prevent information leakage. When the operating
system wants to restart the secure process, it executes a spe-
cial instruction which restores the state of the process from
a given HCB. As the operating system cannot read or mod-
ify the content of the HCB, it cannot disturb or spy on the
process. If there are several secure processes running, the
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006LoadPageInfo(p) :
{ Find the branch of the tree to check from the bottom: }
d = n; q = p
while d > 0 :
Ad,q = getNodeAddress(d, q)
LoadNode Ad,q, d, q
if bd,q is already in the cache:
d = d − 1; q = (cid:1) q
break
(cid:2)
2
{ The processor needs a secured TLB of the memory page p }
{ The OS ﬁnds the address of the node by itself }
{ Asks the processor to load a node in the VB }
{ We ﬁnd a node that is already certiﬁed in the cache }
{ We climb the tree }
{ We descend to the ﬁrst node missing }
d = d + 1
{ We descend to verify the branch: }
while d ≤ n :
HashCheck d
d = d + 1
{ Asks the processor to verify the node in the VB and if it is correct to move it to the cache }
{ Descends to the next missing node }
ReturnFromInterrupt { Restarts the execution. The TLB is missing in case of an attack so denial of service is detected }
Figure 5. Veriﬁcation by the OS of the data of a memory page.
operating system can ask the processor to encrypt the con-
tent of one HCB and can save the result of the encryption to
memory. It can also load one HCB with an encrypted hard-
ware context and ask the processor to decrypt it in order to
restart the execution of the corresponding secure process.
To allow system calls, the process can choose not to
blank or restore one or several registers for the next inter-
rupt. The process can also specify the address of a sig-
nal handling function where the operating system can ask
the processor to jump to with a special instruction, without
triggering a security exception. To execute a secure pro-
gram, the operating system copies the initial hardware con-
text which is encrypted using the public key of the processor
to a special buffer inside the processor which can decrypt it
and start the execution.
3. Evaluation and results
In this section, we use the same architectural parameters
as [30] to evaluate the performance of our proposition. They
are summarized in Table 1. The AES unit is fully pipelined
and its latency is 11 cycles.
3.1. Theoretical analysis
Figure 6 describes the chronology of a read operation
when there is a cache miss under the hypothesis that the
information about the chunk is already available in the TLB.
The slowdown due to the decryption and the veriﬁcation of
the line is 13 % (107 cycles instead of 95 cycles without
encryption and veriﬁcation).
However, the decryption by itself takes only one cycle
in this example. So the line can be used in a speculative
way as soon as it is decrypted (with, in this case, a slow-
down of only 1 %). The processor should avoid any security
side-effect based on the results of this line (such as a non-
Architectural parameter
Speciﬁcations
Clock frequency
Cache line size
Data L1
Instruction L1
L1 miss latency
Uniﬁed L2
L2 miss latency
ITLB
DTLB
TLB miss latency
Memory bus
Memory latency
Page size
Fetch/decode width
Issue/commit width
Load/store queue size
Register update unit size
Encryption algorithm
Encryption block length
Encryption latency
1 GHz
32 bytes
Direct mapped, 8 kB, LRU
Direct mapped, 8 kB, LRU
1 cycle
4-way associative, 1 MB, LRU
12 cycles
4-way associative, 64 entries, LRU
4-way associative, 128 entries, LRU
30 cycles
200 MHz, 8 bytes wide
80 (ﬁrst), 5 (inter) cycles
8 kB
32/8 per cycle
8/8 per cycle
64
128
AES
128 bits (so l = 2)
11 cycles
Table 1.
simulations.
Architectural parameters used in
encrypted write to external memory), before the integrity of
the line has been checked.
During a TLB miss, the processor needs to check the
Merkle tree that protects the information concerning the
page. If the secure process uses its full 32-bit address space
(4 Gbytes), the depth of the Merkle tree would be 19, so,
in the worst case, the processor would need to compute
19 hashes and it would take 1,520 cycles4. However, this