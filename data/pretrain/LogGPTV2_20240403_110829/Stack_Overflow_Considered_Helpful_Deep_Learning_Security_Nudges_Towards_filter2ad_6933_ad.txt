### Improved Text

#### New Embeddings and Cluster Formation
The new embeddings now form dense and well-separated clusters for each use case in the plot. The network has adjusted the pattern embeddings, bringing those that belong to the same use case closer together and pushing different use case clusters further apart in the embedding space.

#### Accuracy
The promising observations from the visualization of pattern embeddings are confirmed by the accuracy results of the classification model. A grid search revealed that the optimal neighborhood size is \( K = 5 \). The average Area Under the Curve (AUC) for predicting different use cases reaches its peak of 0.999 after 20 epochs. As indicated by the Principal Component Analysis (PCA) plots, the pattern embeddings provide an excellent representation of the use cases, with the average AUC for all classes before training (epoch zero) already above 0.998. However, the precision and recall for IV, HNVOR, and TM start below 0.878 and improve to above 0.986 within 30 epochs of training.

#### Security Classification
**Visualization:**
We begin by illustrating the transfer-learning process for security classification by plotting pattern embeddings before and after training. Figure 5(c) shows the pattern embeddings before training, with their respective security scores. Figure 5(d) displays the new embeddings after training. Secure samples are depicted in blue, while insecure samples are in red. Comparing Figures 5(a) and 5(c), we can observe several secure and insecure clusters within the use case clusters, such as Hash, Cipher, and SSL/TLS. However, many secure and insecure samples appear to have a wide distribution because PCA does not group them into dense clusters. After training the security classification model, we input the complete set of pattern embeddings and plot the last layer of the neural network for each sample again in Figure 5(d). Now, we see dense and separated clusters for secure and insecure samples. The network has adjusted the pattern embeddings so that samples within the same security class are closer together, while samples with different security labels are further apart, forming two distinct security clusters.

**Accuracy:**
We trained a single model using a labeled dataset of 16,539 pattern embeddings, allowing the model to learn security classification for all use cases. Our grid search revealed \( K = 5 \) as the optimal neighborhood size. The model fits well, with training and validation loss converging after 50 epochs. On our system, a single epoch takes an average of 0.58 seconds, resulting in a total training time of approximately five minutes. We plot Receiver Operating Characteristic (ROC) curves for security prediction for each use case class in Figure 6. The three use cases—Hash, Cipher, and SSL/TLS—which provide the largest percentage of samples in the dataset, achieve the best results. The model achieves very high classification accuracy with AUC values of 0.999, 0.996, and 0.999, respectively, similar to HNVOR and TM. However, performance drops slightly for IV, Key, and HNV, with AUC values of 0.980, 0.970, and 0.953, respectively.

**Comparison:**
In Table 2, we compare our approach to security prediction on Stack Overflow with [17], where the authors use term frequency-inverse document frequency (tf-idf) to create feature vectors and train a Support Vector Machine (SVM) to predict binary security scores. Our deep learning approach (marked as CNN in the table) significantly outperforms their classifier in all use cases, especially for IV, Key, and HNVOR, where security evaluation heavily relies on data and control flow. In contrast, the work by Fischer et al. [17] relies solely on lexical features and does not inform the learning model about these properties.

Moreover, our deep learning approach allows for a higher level of explainability to the user. While [17] can only report security warnings for the entire code snippet, our more fine-grained approach can directly highlight statements in the code and provide annotations that explain the security issue. Since we learn a representation of code patterns that allows prediction of various code properties beyond security, we can offer this additional explanation, which is crucial for developer advice.

| **Method** | **Cipher** | **Hash** | **TLS** | **IV** | **Key** | **HNV** | **HNVOR** | **TM** |
|------------|------------|----------|---------|--------|---------|---------|-----------|--------|
| **CNN**    | 0.996      | 0.999    | 0.999   | 0.980  | 0.970   | 0.953   | 0.998     | 1.000  |
| **Explanation** | SW, CA | SW, CA | SW, CA | SW, CA | SW, CA | SW, CA | SW, CA | SW, CA |
| **tf-idf + SVM** | 0.960 | 0.956 | 0.902 | 0.881 | 0.886 | 0.922 | 0.850 | 0.982 |
| **Explanation** | SW | SW | SW | SW | SW | SW | SW | SW |

**Table 2:** Performance and explainability comparison of security prediction on Stack Overflow. SW: Provides security warnings for the complete snippet. CA: Additionally provides code annotation that explains the issue in detail.

#### Recommendations
We applied our trained models to evaluate whether Stack Overflow provides secure alternative code snippets that preserve the use case and are similar to detected insecure code examples. We extracted all methods from the complete set of 10,558 snippets, generated their aggregated embeddings, and separated them into two sets. The first set contains all 6,442 distinct insecure query embeddings, and the second set contains all 3,579 distinct secure target embeddings. We created these sets by applying the security model and predicting the security of each pattern within a given method. Finally, we ranked the embeddings based on their Jaccard distance and cosine similarity, as described in Section 6.2. We found that 6,402 (99.37%) query methods have a Jaccard distance of 0.0 to at least one target method. This means that for almost every insecure method, a secure alternative exists on Stack Overflow that serves the same use case. When additionally demanding code similarity, we found 6,047 (93.86%) query methods with a cosine similarity above 0.81 and 4,805 (75.58%) query methods with a similarity above 0.9 to at least one target method.

#### Evaluation of Security Nudges
To evaluate the impact of our system, including the security nudges, on the security of programming results, we conducted a laboratory user study. Participants had to solve programming tasks with the help of Stack Overflow.

**User Study Setup:**
Participants were randomly assigned to one of two treatment conditions. For the nudge treatment, we provided security warnings (Figure 2a) for insecure code examples, recommendations for secure snippets (Figure 2b), and recommendation lists attached to each warning (Figure 8). Security reminders were also enabled. In the control treatment, all security nudges on Stack Overflow were disabled. Participants were advised to use Stack Overflow to solve the tasks. We restricted Stack Overflow search results to posts containing code examples from the set of 10,558 code examples we extracted. We also applied a whitelist filter to restrict access to Stack Overflow in the Chrome browser. Any requests to different domains were redirected to the Stack Overflow search page. Participants were provided with the Google Chrome browser and Eclipse pre-loaded with two Java class templates. Both class templates provided code skeletons to reduce the participants' workload and simplify the programming tasks. Using additional applications was prohibited. All tasks had to be solved within one hour. We avoided any security or privacy priming during the introduction and throughout the study. Moreover, we did not name or explain any of the security nudges on Stack Overflow.

**Tasks:**
All participants had to solve five programming tasks related to symmetric encryption and certificate pinning. These two use cases were chosen as they provide the most error-prone cryptographic problems in Android [17].

- **Symmetric Encryption:**
  - **Task Cipher:** Initialize a symmetric cipher by setting the algorithm, block mode, and padding. The main security pitfalls in this task are choosing a weak cipher and block mode.
  - **Task Key:** Generate a symmetric cryptographic key with the correct and secure key length necessary for the previously defined cipher. The key must be generated from a secure random source and should not be stored in plaintext.
  - **Task IV:** Instantiate an initialization vector. Like key generation, this task is particularly error-prone, as choosing the correct length, secure random source, and storage can be challenging.

- **Certificate Pinning:**
  - **Task TLS:** Create an SSL/TLS context to securely communicate with a specific server via HTTPS. The program should be able to perform a successful GET request on the server while denying connection attempts to domains that provide a different server certificate. A solution would be to select a secure TLS version to initialize the context.
  - **Task TM:** Add the server's certificate to an empty custom trust manager, replacing the default manager. This way, the program will pin the server's certificate and create a secure communication channel, rejecting attempts to any other server with a different certificate.

**Preliminaries and Participants:**
We advertised the study in lectures and across various university communication channels. Thirty subjects participated, but three dropped out due to misunderstanding a basic participation requirement (i.e., having at least basic Java programming knowledge). Of the remaining 27 subjects, 16 were assigned to the nudge treatment, and 11 to the control treatment. While being students, our sample varied across demographics and programming skill, but none of the self-reported characteristics systematically differed across the two treatments (see Appendix A for details). We followed well-established community principles for conducting security and privacy studies [29]. Participants were presented with a comprehensive consent form and separate study instructions on paper. Participants were compensated with 20 Euros.

After submission of the solutions, participants were asked to complete a short exit survey. We asked specific questions addressing the effectiveness of the security nudges and whether they were noticed by the participants. We also asked demographic questions at this point to avoid any bias during the study. See Table 3 in the Appendix for details.

**User Study Results:**

- **Functional Correctness:**
  Our system is not designed to address difficulties programmers may have in delivering functionally correct code. However, it is important that using the system does not create obstacles for programmers. Participants predominantly submitted functionally correct code in both treatments, with some differences across tasks (cf. Figure 7c). Applying ordinal logistic regression (cf. Table 4 in the Appendix) indicates that the nudge treatment has no effect on functional correctness of submitted tasks. However, non-professionals submitted significantly less functional code (p < 0.05). Cipher submissions are more often functional, irrespective of the treatment (p < 0.05).

- **Security:**
  Figure 7a shows the security results per task for both treatments. Performing ordinal logistic regression (see Table 5 in the Appendix), we show that the nudge treatment significantly outperforms the control group in producing secure solutions (with an estimate of 1.303 and p < 0.01; Model 4). While the main effect of the nudge treatment dominates the regression models, we can observe from Figure 7a that comparatively more secure submissions are made for TM and Key. Pairwise testing using Chi-Square tests reveals p < 0.001 for both tasks. Participants from the nudge group provided 84.6% secure solutions for Key and 76.9% for TM, while 60.0% and 66.7% of the respective solutions submitted by the control group were insecure. These observations for TM are somewhat encouraging, given previous findings: [17] showed that reused insecure TM code snippets from Stack Overflow were responsible for 91% (183,268) of tested apps from Google Play being vulnerable. Only 0.002% (441) of apps contained secure TM code from Stack Overflow.

**Figures:**
- **Figure 7:**
  - (a) Security results
  - (b) Copy-paste rate (average)
  - (c) Correctness results

**Conclusion:**
Our system effectively improves the security of code snippets used by developers, particularly in critical areas like key management and certificate pinning. The nudge treatment significantly enhances the security of the submitted solutions without hindering functional correctness.