2
3
4
arr A;
# Fill A with pointers
for ( i = 0;
i < len(A); i++)
*(...) **A[k*i];
(b) L-level pointer-chasing.
arr A;
arr B;
# Fill A with offsets
for ( i = 0;
i < len(A); i++)
B[A[k*i]];
(c) 1-level indirection-based.
1
2
3
4
5
6
7
arr A;
... # Many such arrays
arr Y;
arr Z;
# Fill arr A−Y with offsets
for ( i = 0;
i < len(A); i++)
Z[Y [(...) A[k*i ]]];
(d) L-level indirection-based.
Fig. 2: Examples of types of DMP expected access patterns. k is the constant
stride. L is the number of pointer dereferences that occur ignoring streaming
over A. The left column is the explicit L = 1 case. L is a DMP design decision.
We discovered a 1-Level Pointer Chasing DMP (a) on the Apple M1.
B for future k*(i+delta), the DMP must use the data and
addresses it has seen so far to infer &B[0]. Note, A[k*i] is
an offset into an array in the program’s virtual address space,
whereas &B[A[k*i]] is likely a physical address. So, the
DMP must autonomously perform virtual to physical address
translations to identify data-address correspondences.
D. DMP security implications
To our knowledge, prior to this paper, there has been no
evidence to suggest that any DMP is implemented in any
commercial processor. Nor (by extension) has there been
analysis of the security implications of DMPs in the wild.
Vicarte et al. [45] did recently perform an analysis of the
security implications of proposed microarchitecture, includ-
ing DMPs, but these were not known to be implemented.
While their work was theoretical, it points out how DMPs
have potentially disastrous security implications. For example,
consider an indirection-based DMP that prefetches the pattern
C[B[A[k*i]] similar to the one in Figure 2d. Misused, this
DMP can be coerced to leak all of program memory, similar
to Spectre and Meltdown [30, 33]. To see this, suppose that
the DMP was used in a sandbox setting. In that case, the
attacker controls the program and can therefore easily force
the DMP to activate. The attack proceeds as follows. 1) the
attacker specifies a value (call it j) stored off the end of array
A. j will correspond to the address of the value in memory the
attacker wants to learn. 2) the DMP erroneously reads j and
accesses memory to read C[B[j]]. Recall from Section II-A,
prefetchers do not know array bounds. Thus, B[j] can refer
to the data at any memory location. Finally, C[B[j]] serves
as the transmitter in a memory side channel: B[j] is a secret
and C[B[j]] turns that secret into an address to memory.
E. Apple Silicon
Modern Macs no longer use Intel processors, but instead use
the new (ARM) M1 line. As the M1 is very similar to previous
Apple processors, vulnerabilities in it may affect millions of
consumers. We have confirmed that our findings apply to the
A14 (iPhone 12) and the new M1 Max at a minimum.
The M1 has eight cores: four high-performance Firestorm
and four energy-efficient Icestorm cores [12]. As we find the
DMP to only be present on the Firestorm cores, we focus
on the relevant Firestorm details. Each core has a private L1
cache, and there are two large L2 caches shared between cores
of the same type. The four Firestorm cores share a 12 MiB
L2, and the Icestorm cores share 4 MiB. Each Firestorm core
has a private 192 KiB L1 instruction cache and 128 KiB L1
data cache [11]. While there is no official information on the
associativity or cacheline size, we found that L2 lines are 128
bytes, and L1 lines are 64 bytes. When filling L1d lines,
two adjacent L1d lines are brought in at a time, and both
are independently evictable. We also believe that the L1 is
8-way associative and the L2 is 16-way associative from our
experience building eviction sets (Section VII-C).
A major complication for reverse engineering is reports that
the M1 DRAM controller performs frequency scaling [34].
This matches our observations that a cache miss to DRAM can
return in a wide range of times. We find that increasing the
pressure on DRAM can reduce the average access time more
than amortizing measurement costs would anticipate. The net
effect is that we observe otherwise inexplicable decreases in
memory access times for longer experiments.
Other relevant aspects of the M1 include that it can have
an unusually large number of instructions in flight to exploit
instruction level parallelism [28], and does not support any
form of Simultaneous Multi-Threading (SMT).
III. THREAT MODEL AND ATTACKER OBJECTIVES
There are two main threat models we consider for the M1
DMP: adversarial unprivileged (or sandboxed) code, and latent
gadgets in benign code. This is similar to prior microarchitec-
tural vulnerability research that exploits unprivileged attacker
code as well as cases of privileged programs containing
speculative gadgets [30]. The M1 does not support any form
of simultaneous multithreading and so it is not considered.
A. Sandboxed Adversarial Code
In this model, we assume a standard microarchitectural
sandboxed attacker: the adversary is able to run arbitrary sand-
boxed code on a system that does not trust the sandboxed code.
The adversary is attempting to perform memory reads outside
the sandbox and will leverage microarchitectural details of the
processor to achieve this. This is a scenario commonly seen
with JavaScript sandboxes in browsers, the kernel sandbox for
eBPF code, NaCl modules, and more.
As we assume the sandbox model, the adversary will control
the training pattern that will eventually activate the DMP.
The training pattern is the series of legal, in-sandbox memory
accesses made by the adversary that will cause the DMP to
activate and fetch data based on the predicted next accesses
after the training pattern. The adversary leverages this behavior
to cause the DMP to read outside of the sandbox, and then
leak that information back to the adversary.
We additionally assume that the adversary can use standard
cache side channels to retrieve information about the cache
state. We demonstrate specifically using Prime+Probe on the
4
M1 in Section VII-C, but these include Prime+Probe [35, 38],
Flush+Reload [48], and other similar styles of attack. The
attacker will use these techniques to receive the secrets trans-
mitted via cache state by the DMP.
B. Latent DMP Gadgets
Like with other microarchitectural attacks, it may be the
case that a victim program already contains the necessary
code patterns an adversary can use to induce an adversarial
training pattern. This is not unlikely, as during our reverse
engineering we found it easy to unintentionally activate the
DMP by accessing stack variables that are pointers and causing
the DMP to prefetch other pointers on the stack.
In this model, we assume the adversary at most has control
over a set of inputs to the program, and must leverage an
existing set of memory operations. This model can facilitate
an attack, e.g., if the memory operations’ access pattern is a
function of the attacker input. It is also possible for a program
to, without any adversarial interaction, cause a DMP to activate
and leak information.
One possible example of the former would be a syscall
that dereferences userspace-defined pointers, such as readv
or writev. In these situations, the adversary may be able
to induce activation of the DMP during kernel execution and
cause the DMP to leak data near the kernel buffer containing
data copied from userspace.
For the latter, consider a program that accesses (uncondi-
tionally) addresses X, A, B, and C, where X is the address of
an attacker controlled string buffer. If the buffer contains the
values “A,B,C,Z” then it is possible the DMP will interpret
X as an Array-of-Pointers currently being iterated over and
dereferenced, and then (attempt) to prefetch Z.
IV. THE DANGERS OF DMPS
As part of our study of the DMP present in Apple CPUs,
we first had to consider the possible design dimensions of
a DMP, and the relevant security impact of each. While
any DMP will have security implications, understanding the
implementation of a specific DMP is necessary for making
definite claims about the vulnerability of real programs and to
formulate platform-specific software defenses. For example, a
DMP using a prefetch buffer (see Section IV-D) may not even
provide an advantage over standard cache side channels!
A DMP performs several important actions during operation
that allow for the use of side channels to determine secrets.
We will use the terminology of access-transmit-receive for
discussing the leakage of secrets [29]. After activating, any
data read by the DMP to determine addresses for prefetching
is considered accessed. The DMP is then considered to have
transmitted that data when it performs a prefetch to an address
which is a function of the data. Finally, the adversary uses
some side-channel attack (cache occupancy, cache contention,
etc.) to receive that data.
Below, we explore the possible design space for a DMP
through a security lens. This analysis is driven by our survey
of existing DMP and prefetcher literature, existing prefetcher
reverse engineering, and questions that arose while working on
this paper. As real DMPs have not previously been evaluated
for security impact,
this is an unexplored area useful for
framing both the M1’s DMP as well as any future DMP
analysis. Relevant axes of interest are:
• What are the preconditions for DMP activation?
• What memory is accessed to inform prefetching?
• What function of memory values is transmitted?
• How can the adversary receive the transmitted values?
A. Preconditions for a DMP to activate
Like classical prefetchers, a DMP must
track memory
accesses made by programs and decide when to activate. Based
on previous prefetcher designs, we know that this may track
only address suffixes, may organize tracking entries by PID,
may organize memory accesses by the instruction address they
originate from, and may rely on another non-DMP prefetcher
to retrieve data. Each of these possibilities has significant
impact on what an attacker can do with that DMP.
then it
If, like the Intel L1i prefetcher [17], the DMP only tracks
is vulnerable to aliasing attacks.
address suffixes,
This allows an adversary to train the prefetcher using non-
contiguous memory accesses that only appear to be contiguous
when the upper bits of the address are ignored. For example,
an adversary could train a DMP over a sandboxed memory
region but a safe access outside of the sandbox that aliases to
the same pattern could activate prefetches outside the sandbox.
Instruction-pointer (IP) tagged pattern tracking on the other
hand limits attacker capabilities by restricting the code per-
forming dereferences to loops. Without IP tagging, the mem-
ory access pattern can originate from any series of instructions
that perform memory accesses. These instructions may not
even intentionally be referencing related memory, and may
simply appear to the DMP to be a contiguous streaming access.
Like general DMP address tracking, IP tagging may only
track address suffixes [31]. Once again, this will allow an
adversary to perform aliasing attacks where two distinct in-
structions that share an address suffix will be conflated by the
DMP as the same originating address.
Process ID (PID) tagging, like IP tagging, limits the ad-
versary by forcing all accesses and prefetches to occur in the
same process. Without PID tagging an adversary may be able
to train the DMP on one process, and then allow the unrelated
victim accesses to cause DMP prefetches.
Finally, it may be the case that the DMP follows some
classical prefetcher on the system. This would mean that the
DMP’s top-level activation criteria and restrictions are the
same as that classical prefetcher’s.
B. Data access patterns for DMPs
The most important feature to the attacker is which values
the DMP will access to inform prefetching.
The first concern is if the DMP is single or multi-layer (see
Figure 2). A single layer DMP performs only one (effective)
memory dereference per-prefetch. An N-layer DMP will per-
form N dereferences per-prefetch. As an example, a prefetcher
that simply prefetches the memory backing all pointers in
an array-of-pointers (*arr[n+1]) is a single-layer DMP. A
5
prefetcher that fetches not only the data backing a pointer
in memory, but also interprets that data as a pointer and
dereferences again (**arr[n+1]) is a two-layer prefetcher.
Multi-layer DMPs are exceptionally powerful for an attacker
if the
and most other design decisions become irrelevant
DMP is multi-layer. The reason is that
the attacker can
precondition the first value being accessed (e.g., arr[n+1])
to refer to an arbitrary memory location, meaning the DMP
can subsequently access arbitrary program memory. This is
well demonstrated in Vicarte et al. [45] which shows how
to use the 2-level Indirect Memory Prefetcher (IMP) [50] to
construct a Universal Read Gadget and transmit the contents
of all of virtual memory. For the rest of this section we assume
a single-layer DMP.
As with classical prefetchers, a DMP is likely capable of
detecting a stride pattern where the access pattern touches
non-adjacent
items in memory. Stride detection will have
some maximum distance within which sequential accesses
are considered part of the pattern. This maximum stride will
determine the maximum distance from the end of the training
pattern that the DMP will prefetch from.
Any prefetcher will also have a maximum number of
elements that it is willing to prefetch, generally increasing with
higher confidence. This is the effective depth of the prefetcher.
Fundamentally,
the furthest value that can be targeted by
a DMP is (max stride× depth) + end o f
training address.
We will refer to max stride× depth as the maximum prefetch
distance (in bytes).
As we will see with the M1 AoP DMP, there can be other
unusual restrictions on what memory the DMP can access.
These don’t follow any particular set of rules.
C. Function of data transmitted by a DMP
A DMP can be either a pointer-chasing prefetcher or it can
be an indirection based prefetcher (see Figure 2).
A pointer-chasing DMP dereferences pointers in memory
and prefetches the cache lines found there. Thus, an attacker
that controls the train pattern can trick the DMP into deref-
erencing a secret value as if it were a pointer. These DMPs
allow an adversary in control of the training pattern to cause
a secret memory location to be treated as an address, and to