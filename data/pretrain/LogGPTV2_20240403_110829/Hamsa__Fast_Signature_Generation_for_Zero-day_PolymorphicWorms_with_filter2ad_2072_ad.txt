rience, we found that we get good performance with only
50MB–200MB memory using this approach.
The large memory requirement due to sufﬁx arrays can
also be alleviated at the cost of accuracy, speed or expense
as follows.
1. By dividing the normal pool randomly into a num-
ber of equal sized chunks and creating a sufﬁx array
over each of these chunks, the false positive can be ap-
proximated by the false positive over any one of these
chunks kept in primary storage while the rest are in
secondary storage. For tokens whose false positive is
close to the threshold, a more accurate estimation can
be performed by using chunks of normal trafﬁc pool
from secondary storage.
2. Each normal ﬂow can be compressed using compres-
sion schemes such as LZ1. To compute the false pos-
itive for a token t, we can employ the string match-
ing algorithms over compressed strings as discussed
by Farach et al. [8]. This approach is more time con-
suming than sufﬁx array based approach but doesn’t
sacriﬁce accuracy.
3. Since the false positive calculation is just a special case
of string matching, hardware-based memory-efﬁcient
string matching algorithms can be employed. The
ASIC/FPGA based implementation [27] can archive a
matching speed of 6–8Gb/s. However, such special-
ized hardware makes the system expensive.
7 Evaluation
7.1 Methodology
Since there are no known polymorphic worms on the In-
ternet, a real online evaluation is not possible. Instead, we
test our approach ofﬂine on synthetically generated poly-
morphic worms. Since the ﬂow classiﬁcation is not the fo-
cus of this paper, we assume we have a ﬂow classiﬁer that
can separate network trafﬁc into two pools, a normal traf-
ﬁc pool and a suspicious pool (with polymorphic worms
and possible noise). We take the two trafﬁc pools as in-
put and output a set of signatures and also their coverage
of the suspicious pool and the false positives in the normal
trafﬁc pool. The input trafﬁc pools can be treated as training
datasets. After signature generation, we match the signature
of each worm against 5000 samples generated by the same
worm to evaluate false negatives and also against another
16GB of normal network trafﬁc to evaluate false positives.
Since most of the worm ﬂow is usually binary code, we also
create a binary evaluation dataset for testing false positives
against the Linux binary distribution of /usr/bin in Fedora
Core 4.
7.1.1 Polymorphic Worm Workload
In related work, Polygraph [16] generates several pseudo
polymorphic worms based on real-world exploits for eval-
uation purposes. Polygraph’s pseudo polymorphic worms
are based on the following exploits: the Apache-Knacker
exploit and the ATPhttpd exploit.
For our experiments, we use Polygraph’s pseudo poly-
morphic worms and also develop a polymorphic version of
Code-Red II. The polymorphic version of Code-Red II con-
tains invariant content inherent to Code-Red II. We were
able to detect and generate signatures for all of the poly-
morphic worms even in presence of normal trafﬁc noise.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:34 UTC from IEEE Xplore.  Restrictions apply. 
We also used two polymorphic engines found on the In-
ternet, the CLET [7] and TAPiON [21] polymorphic en-
gines to generate polymorphic worms. The CLET polymor-
phic engine is a sophisticated engine that is designed to gen-
erate polymorphic worms that ﬁt closely to normal trafﬁc
distributions. For example, CLET can generate a NOP ﬁeld
for a polymorphic worm using English words. In addition,
given a spectral ﬁle of byte frequencies, the CLET engine
can give precedence to certain byte values when generat-
ing bytes for a polymorphic worm. We created a spectral
frequency distribution from normal HTTP trafﬁc to use as
input to the CLET engine when creating our samples. With
all the advanced features of the CLET engine enabled we
were still able to detect and generate signatures for samples
created by the CLET engine.
The TAPiON polymorphic engine is a very new and re-
cent polymorphic engine. We used the TAPiON engine to
generate 5000 samples of a known MS-DOS virus called
MutaGen. Again we are able to apply our technique and
generate signatures for samples created by the TAPiON en-
gine.
7.1.2 Normal Trafﬁc Data
We collected several normal network trafﬁc traces for the
normal trafﬁc pool and evaluation datasets. Since most of
our sample worms target web services, we use HTTP traces
as normal trafﬁc data. We collected two HTTP traces. The
ﬁrst HTTP trace is a 4-day web trace (12GB) collected from
our departmental network gateway. The second HTTP trace
(3.7GB) was collected by using web crawling tools that in-
cluded many different ﬁle types: .mp3 .rm .pdf .ppt .doc
.swf etc..
7.1.3 Experiment Settings
Parameters for token extraction We set the minimum
token length (cid:6)min = 2 and require each token to cover at
least λ = 15% of the suspicious pool.
Signature generation We used the scoring function de-
ﬁned in Section 6.1 with a = 20 and b = 0.01. Moreover,
we rejected any signature whose false positive rate is larger
than 1% in the normal trafﬁc pool. For u-parameters, we
chose: k∗ = 15, u(1) = 0.15, and ur = 0.5. Based on ur
we can calculate u(i) = u(1) ∗ u(i−1)
. In Section 7.3, we
evaluate this choice of u-parameters.
All experiments were executed on a PC with a 3.2GHz
r
Intel Pentium IV running Linux Fedora Core 4.
7.2 Signature Generation without Noise
We tested our ﬁve worms separately without noise.
Comparing our approach with Polygraph, we found the sig-
natures we generated were very close to conjunction sig-
natures generated with Polygraph (single worm without
noise). We found that our signatures are sometimes more
speciﬁc than those of Polygraph while maintaining zero
false negatives.
For a suspicious pool size of 100 samples and a normal
trafﬁc pool size of 300MB, the false negative and false pos-
itive measurements on training datasets are very close to
those for much larger evaluation datasets. Moreover, we
also tested on smaller normal trafﬁc pool sizes: 30MB and
50MB. We found our approach to work well for both large
and small pool sizes. Thus, we are not very sensitive to the
size of the normal trafﬁc pool. In Section 7.5, we discuss
the effects of the number of worms in the suspicious pool
on generating correct signatures.
7.3 u-parameter Evaluation
As mentioned before, we can use k∗, u(1), and ur to
generate all the u-parameters. If we set u(1) and ur too
high, it loosens our bound on attack resilience and may
also result in signature with have high false positive. If we
choose too low a value, we risk generating a signature alto-
gether. Therefore, for all the worms we tested, we evaluated
the minimum required value of u(1) and ur. We randomly
injected 80 worm samples and 20 normal trafﬁc noises into
the suspicious pool (20% noise), and used the 300MB nor-
mal trafﬁc pool. We tested our worms with various com-
binations of (u(1),ur) with u(1) taking values from {0.02,
0.04, 0.06, 0.08, 0.10, 0.20, 0.30, 0.40, 0.50}, and ur from
{0.20, 0.40, 0.60, 0.80}. We found the minimum value of
(u(1),ur) that works for all our test worms was (0.08,0.20).
We choose a far more conservative value of u(1) = 0.15
and ur = 0.5 for our evaluation. Note that for k∗ = 15,
u(k∗) = 9.16 ∗ 10−6.
7.4 Signature Generation in Presence of
Noise
The ﬁrst experiment consists of randomly selecting 100
worm samples for each worm, and injecting different por-
tions of noise, to create different noise ratios: 0%, 10%,
30%, 50%, and 70%. In our second experiment we ﬁx the
suspicious pool size to 100 and 200 samples, and evaluate
for the noise ratios used in the ﬁrst experiment.
As shown in Figure 3, Hamsa generates the signatures
for the suspicious pool iteratively. So it can generate
more than one signature if required and thus detect mul-
tiple worms. As shown in Table 2, we always generate
worm signatures with zero false negative and low false pos-
itive. Since our algorithm generates signatures that have
high coverage of the suspicious pool and low false positive
of the normal trafﬁc pool, if the noise ratio is larger than
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:34 UTC from IEEE Xplore.  Restrictions apply. 
Worm
name
Code-Red II
Training
FN
0
Training
FP
0
Evaluation
FN
0
Evaluation
FP
0
Binary
eval FP
0
Signature
{’.ida?’: 1, ’%u780’: 1, ’ HTTP/1.0\r\n’: 1,
’GET /’: 1, ’%u’: 2}
Apache-
Knacker
ATPhttpd
CLET
TAPiON
0
0
0
0
0
0
0.109%
0.282%
0
0
0
0
0
0
0.038% {’\xff\xbf’: 1, ’GET ’: 1, ’: ’: 4, ’\r\n’: 5,
0
’ HTTP/1.1\r\n’: 1, ’\r\nHost: ’: 2}
{’\x9e\xf8’: 1, ’ HTTP/1.1\r\n’: 1,
’GET /’: 1}
0.06236% 0.268% { ’0\x8b’: 1, ’\xff\xff\xff’: 1,
’t\x07\xeb’: 1}
0.1839%
0.115% {’\x00\x00’: 1, ’\x9b\xdb\xe3’: 1}
Table 2. Signatures for the ﬁve worms tested and accuracy of these signatures. {’\r\nHost: ’: 2}
means token ’\r\nHost: ’ occurs twice in each worm sample. FN stands for “False Negative” and FP
stands for “False Positive”.
50%, sometimes, we will generate two signatures. How-
ever, only one of them is the true signature for the worm in
the suspicious pool; the other is due to normal trafﬁc noise.
We tested the noise signatures against the binary evaluation
dataset and found they all have zero false positives. The av-
erage and maximum false positive rate for the 16GB normal
trafﬁc pool is 0.09% and 0.7% respectively. The following
is an example of a noise signature.
’47 ’: 1, ’en’: 3, ’od’: 3, ’ed’: 1, ’b/’: 1,
’: ’: 6, ’ GMT\r\nServer: Apache/’: 1, ’0 m’: 1
’ mod_auth_’: 1, ’\r\n\r\n’: 1, ’odi’: 1,
’(Unix) mod_’: 1, ’e: ’: 2, ’ep’: 1, ’er’: 3,
’ec’: 1, ’00’: 3, ’mod_ssl/2.’: 1, ’, ’: 2,
’1 ’: 2, ’47’: 2, ’ mod_’: 2, ’4.’: 1, ’2’: 1,
’rb’: 1, ’pe’: 2, ’.1’: 3, ’te’: 3, ’0.’: 3,
’.6’: 1, ’\r\nCon’: 2, ’ 20’: 3, ’.3.’: 1,
’7 ’: 2, ’10 ’: 1, ’13’: 1, ’HTTP/1.1 ’: 1,
’b D’: 1, ’ PHP’: 1, ’ker’: 1, ’on’: 5,
’2.0.’: 2, ’ma’: 1, ’ 200’: 2, ’/2’: 3,
’\r\nDate: Mon, 11 Jul 2005 20:’: 1, ’.4’: 1,
’ OpenSSL/0.9.’: 1, ’\r\n’: 9, ’e/2’: 1,
Noise signatures can be identiﬁed as follows. If a sig-
nature has low coverage than some threshold for a differ-
ent suspicious pool, then it is likely to be a noise signa-
ture. However, since noise signatures have low false posi-
tive rates, it is safe to include them as valid signatures.
7.5 Suspicious Pool Size Requirement
For worms obtained from Polygraph and the polymor-
phic Code-Red II worm, we only need a suspicious pool size
of 10 samples (in presence of 20% noise) to obtain the exact
same signature as shown in Table 2. However, for worms
generated using CLET and TAPiON engines, a small suspi-
cious pool size of 10–50 samples in presence of 20% noise
could result in too speciﬁc a signature, such as { ’0\x8b’:
1, ’\xff\xff\xff’: 1, ’t\x07\xeb’: 1 ’ER’: 1 }. This is due
to the polymorphic engines using common preﬁxes or suf-
ﬁxes in English words to pad the variant parts in the worm.
This is similar to the coincidental-pattern attack mentioned
in the Polygraph paper. In the above mentioned example,
95% of the worms have the token ’ER’. It is possible that
when the suspicious pool is small, all the samples contain
token ’ER’, thus making ’ER’ seem invariant and hence a
part of the signature. This is why the signature above has
0% training false negative, but 5% false negative over the
evaluation dataset. Therefore, for unknown worms it is best
to use a large suspicious pool size, such as 100 samples.
7.6 Speed Comparison with Polygraph
Signature generation speeds are critical for containing
worms in their early stages of infection. Both Polygraph
and Hamsa have similar pre-processing requirements.
In
Section 4.1, we analyzed the time complexity of signa-
ture generation for Hamsa to be O(T ·|N |) where T is the
number of tokens. The hierarchical clustering algorithm
proposed by Polygraph needs O(|M|2) comparison and
for each comparison we need to compute its false positive
which takes O(|N |) time. By making use of appropriate
data structures, it is possible to merge the clusters and gen-
erate the signature for the new clusters so that the total run-
time is O(|M|2·|N |).
So the asymptotic runtime difference between the two
approaches is O(T ) vs. O(|M|2). In our experiments, we
determine the average number of tokens T of 5 different
runs for the same pool size |M|. Table 3 summarizes our
experimental observations. Note that the number of tokens
T decreases as |M| increases. The larger the suspicious
pool size |M |, the bigger the speed up ratio. Table 4 shows
that Hamsa is analytically tens to hundreds of times faster
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:34 UTC from IEEE Xplore.  Restrictions apply. 
than Polygraph. In our experiments over various parameter
settings, Hamsa was found to be 64 to 361 times faster than
Polygraph 2.
Noise Ratio
|M |
150
250
350
20% 30% 40% 50%
2703
303
290
2450
2062
274
1582
1327
1172
589
559
558
Table 3. The number of tokens for different
pool sizes and noise ratios.
|M |
150
250
350
20%
74.26 (64.28)
215.52 (361.32)
447.08
Noise ratio
30%
38.20
111.81
219.53
40%
14.22
47.10
104.52
50%
8.32 (69.89)
25.51
59.41
Table 4. |M|2/T , the asymptotic speed up ra-
tio with respect to Polygraph. The number in
braces indicate the empirical speed up ratio.
7.7 Speed and Memory Consumption Re-
sults
We evaluate the speed and memory consumption of our
optimized C++ implementation for different settings shown
in Table 5. For each of the settings, we run our experiments
for all the 5 different worms. The value reported in Table 5
is the maximum of the values obtained for the 5 worms. For
the “pre-load” setting, we pre-load the normal trafﬁc pool
and its sufﬁx array in the memory before running the code.
Since the data is readily available in memory, we achieve
very good speeds. However, the pre-load size is 5 times the
normal pool size which could be too large for some cases.
By using MMAP, we break the sufﬁx array and the normal
trafﬁc pool into 4KB pages, and only load the parts which
are required by the system. This saves a lot of memory but
introduces some disk overheads. In all our experiments, we
use a noise ratio of 20%.
2For a fair comparison, both systems are implemented in Python and
use the same sufﬁx tree based token extraction and the sufﬁx array based
false positive calculation techniques.
Number of Normal Memory
usage