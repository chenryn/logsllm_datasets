tion sets. They also have restricted memory capacity and
narrow addressing buses. For an embedded protocol to be
viable in many situations, it must be feasible to implement
the protocol on these processors using some type of opti-
mized CRC algorithm. In our examination of performance
tradeoffs, we focus on code word lengths of up to 2048 bits,
which is at or well beyond maximum message lengths for
typical embedded networks.
For these implementations, we examine optimized as-
sembly implementations in two 8-bit microcontroller ar-
chitectures, the PIC16F series from MicrochipTM[19] and
the HS08 series from FreescaleTM[9]. These were selected
because they are representative of typical small microcon-
trollers in widespread use. The PIC16F has a Harvard ar-
chitecture, meaning it has separate buses for program and
data memory. All instructions take 4 clock cycles to exe-
cute, except jump instructions, which take 8 clock cycles
(due to prefetch queue ﬂushing). The HS08 architecture is
a von Neumann machine, with a single memory space for
addressing data RAM and program memory. Instructions
take a varying number of clock cycles to complete. Both
architectures utilize an accumulator register for arithmetic
operations. Every attempt was made to introduce an equiv-
alent implementation in both systems, but some differences
remain due to the inherently different natures of the archi-
tectures. These differences are of minimal importance be-
cause our goal is simply to illustrate typical approaches.
We wish to emphasize that our goal is not to analyze the
relative performance of the Microchip and Freescale prod-
ucts, to evaluate their ﬁtness for the purpose of computing
CRCs, or to recommend their use for embedded or safety-
critical embedded applications. Rather, our goal is to show
that there is a performance relationship among the various
algorithms, and that the trends in performance are general
rather than peculiar to only a single architecture.
In the remainder of this section, we describe four typi-
cal classes of implementation for the CRC algorithm, and
compare the performance tradeoffs in low-end embedded
systems. For each CPU architecture, assembly language
implementations were developed for each software algo-
rithm for CRC16, CRC24, CRC32, and the special purpose
optimized polynomials.
Implementations of CRC8 were
not considered because that size CRC cannot achieve high
enough HD for critical applications.
3.1 Bit-shift Algorithm
The bit-shift algorithm (BSA) is exactly the algorithm
previously described in Section 2 and Figure 1. This “ba-
sic” algorithm is directly derived from the binary division
operation. It is simple to implement and requires minimal
program memory. However, the loop must execute once for
every bit of the data word, hence it is also the slowest exe-
cuting algorithm.
3.2 Table Lookup Algorithm
The table lookup algorithm (TLA) is described in [22]
and [25]. This algorithm can update the accumulated FCS
value for multiple bits of the data word in a single compu-
tation. The TLA is optimized through the use of a precom-
puted table of values. Each table entry is the CRC checksum
of the table index value, and is k bits in length (the block
size of the FCS). Processing n bits of data at a time requires
table of size k ∗ 2n bits. Because the entries depend only on
the CRC generator polynomial, they can be computed and
stored at design time. When the algorithm is being run, the
index for the table lookup is a combination of the current
CRC value and the new data. As the algorithm iterates over
each n bits of data, the current CRC value is shifted by n
bits and XORed with the table entry.
For our implementation, the algorithm iterates the com-
putation over 8-bit blocks of data (n = 8), with table en-
tries being the same width as the FCS. Thus the total ta-
ble sizes are 512, 768, and 1024 bytes for CRC16, CRC24,
and CRC32, respectively. Because the 8-bit architectures
only have an 8-bit data bus, the table is organized as several
256-byte tables, each requiring a separate computed goto or
memory fetch (depending on the architecture). The TLA is
commonly considered the fastest executing algorithm, but
its memory footprint can be prohibitively large for embed-
ded processors that might only have a few kilobits of mem-
ory. In a real system, the high memory requirement is likely
to be further exacerbated by memory paging problems. In
both architectures, the table lookup instructions use an 8-
bit operand, so each 256-byte table must start on a page
boundary. Any memory between the end of the program in-
structions and the beginning of the table entries is therefore
wasted.
3.3 Virtual Table Algorithm
The virtual table algorithm (VTA) is based on an algo-
rithm in [24]. Like the TLA, it can operate on multiple bits
of the data word concurrently. However, instead of retriev-
ing the table entry from memory, a virtual table entry is
computed on the ﬂy. The table entries are computed based
on the contribution of each bit of index value to the ﬁnal
table value, with each virtual table entry computation re-
sulting in the identical value that would have been fetched
from memory had a physical table been precomputed and
stored in memory per the TLA approach.
denoted by the XOR of single bit values b0 − bn−1:
For processing n bits of data at a time, the index can be
index = (bn−1 × (2n−1)) ⊕ . . . ⊕ (b1 × (21)) ⊕ b0
Then because the CRC is linear over XOR, we have:
crc(index) = crc(bn−1 × (2n−1))
⊕ . . .⊕crc(b1 × (21))
⊕crc(b0)
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:24 UTC from IEEE Xplore.  Restrictions apply. 
Thus, for processing n bits of data at a time, only the
precomputed values crc(bi × 2i), i  {0, . . . , n} are stored.
The index is computed and the current CRC value shifted
(as in the TLA). If bit i of the index is a 1, the value crc(bi×
2i) is XORed with the CRC.
This algorithm is similar to the “reduced table algo-
rithm” described in [24]. We prefer to term this algo-
rithm as “virtual table” rather than “reduced table” because
an important aspect of this algorithm is that the values of
crc(bi × 2i) do not depend on the current state of the com-
putation. Thus the precomputed values can be hard coded
into the routine and do not actually require the overhead
associated with multiple table lookups (this optimization is
not mentioned in [24]).
In general, the VTA is faster than the BSA (because of
bytewise processing), but slower than the TLA. However,
the memory savings over TLA are substantial because there
is very little memory spent on a table – n in-line data entries
rather than a 2n entry table plus the code to fetch the values.
3.4 Optimized Virtual Table Algorithm
The optimized virtual table algorithm (OVTA) is a spe-
cial case of the VTA, and is suggested by [6], as well as
being similar to the on-the-ﬂy algorithm suggested by [22].
Rather than computing table entries by bit-testing various
positions in the index, the table entry can in some cases be
constructed by observing patterns in the table values and
devising a series of shift-and-XOR operations.
As we will show, the OVTA can be faster than the VTA.
In some cases, it can even approach the speed of the TLA.
There is one important difference between this algorithm
and the others. For the BSA, TLA, and VTA, the computa-
tional speed of the algorithm is independent of the poly-
nomial chosen. However, for the OVTA, the optimiza-
tion over VTA depends completely on the characteristics
of the generator polynomial chosen. Table 2 shows the
improvement over the VTA for several different polyno-
mials (refer to Section 4 for a description of CRC32sub8
and CRC32sub16) . Note that for the particular CRC24
and CRC32 polynomials we used for our experiments, the
OVTA has no improvement at all over the VTA. This is be-
cause the pattern of bits was too complicated to develop
a shift-and-XOR implementation that was faster than the
VTA. The performance of the VTA represents the upper
bound on the performance of OVTA, because a designer
can fall back to the VTA if the optimization strategy has
a negative effect on performance.
4 Algorithm Optimization for Special Poly-
nomial Classes
The four algorithmic approaches discussed in Section 3
provide speed vs. memory size tradeoff points widely used
in current CRC implementations. However, it is possible
Table 2. Speedup in Worst-Case Execution
Time for Optimized Virtual Table Algorithm
1021
Algorithm
CRC16
Polynomial
CRC32sub8
Architecture
PIC
HS08
42.1% 55.0%
0x000001ED 11.5% 30.2%
0x5D6DCB
0.0%
0.0%
29.9% 34.1%
0x0001B435
0x4C11DB7
0.0%
0.0%
* 0% speedup reﬂects an algorithm where no polynomial spe-
ciﬁc optimization could be made over standard virtual table al-
gorithm.
CRC32sub16
∗
∗
CRC24
CRC32
to get further speed increases for some of the methods by
careful selection of CRC polynomials.
It seems obvious that the CRC32 computation should re-
quire more cycles than the CRC24 computation, which in
turn should require more cycles than the CRC16 computa-
tion. In this section, we examine the actual source of the ad-
ditional overhead and identify some optimizations that can
be used to improve the speed of the computation of CRC32
to rival CRC24 and CRC16 computation speed while simul-
taneously improving error detection capabilities to CRC32
levels of error detection (for shorter data words).
For each algorithm described in Section 3, all arithmetic
and shift operations must be done byte-by-byte. For exam-
ple, an XOR in the generic algorithm (Table 1) requires 2, 3,
and 4 XOR operations in the embedded implementations of
the CRC16, CRC24, and CRC32, respectively. By eliminat-
ing some of these operations, the performance of the CRC
algorithm can be signiﬁcantly improved.
We begin this optimization by observing the characteris-
tics of certain CRC32 polynomials. We specify this class of
polynomials as CRCksubr, with the form1 :
xk + ar ∗ xr + . . . + a1 ∗ x1 + a0 ∗ x0
These polynomials have the desirable characteristic that
the generator polynomial and the resulting table entries have
whole bytes of zeros. Table 3 compares table values for
a regular CRC32 polynomial to a CRC32sub8 polynomial.
Note that the upper two bytes of the CRC32sub8 polyno-
mial table entries are always 0.
Because XOR with a zero value is the identity operation,
using the CRCksubr polynomials allows us to eliminate
some of the overhead of the CRC computation of longer
FCS values. In the BSA, we only need to consider the non-
zero bytes when XORing in the CRC polynomial. In the
TLA, VTA, and OVTA, the size of the table entries (and
therefore the computational cost of looking them up or com-
1The reverse polynomials (i.e. those of the form xk + ak−1 ∗ xk−1 +
. . . + ak−r ∗ xk−r + a0 ∗ x0 ) have the similar table properties and
identical error performance, so we omit them from this discussion.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:24 UTC from IEEE Xplore.  Restrictions apply. 
Table 3. Sample Table-Lookup Entries for
CRC32 and CRC32sub8
CRC32sub8
(0x000001ed)
0x00000000
0x000001ed
CRC32
(0x04c11db7)
0x00000000
0x04c11db7
. . .
. . .
Table Index
0
1
. . .
254
255
0xb5365d03
0xb1f740b4
Note that the upper two bytes of the table entries for the
polynomial 0x000001ED are always 0.
0x0000a5b6
0x0000a45b
puting them) is also reduced. Additionally, this approach re-
duces the lookup table memory size for the TLA algorithm.
The CRC32sub8 table has two non-zero bytes in it (one
for the low 8 bits of result, and one to account for left-shift
propagation of up to 8 bits for byte-by-byte processing).
Intuitively, this makes the computational cost similar to a
normal CRC16 computation, which also has two-byte ta-
bles. Similarly, the CRC32sub16, which has three non-zero
bytes, has performance similar to that of the CRC24 com-
putation. The CRCksubr polynomials are slightly slower
because there is some additional overhead to handling the
larger FCS that cannot be eliminated.
It is important to note that the increased computational
speed of the CRCksubr polynomials is not without some
tradeoffs. The size of the FCS is still k bits and cannot be
reduced. Therefore, increased bandwidth or storage size for
the larger FCS (and correspondingly larger code word) is
an additional cost of this approach. However, at times when
the error detection effectiveness of a 32-bit CRC is desired
at reduced cost, this technique can prove useful.
5 Experiments
In order to implement the various CRC algorithms,
we obtained development tools from Microchip (for the
PIC16F) and Freescale (for the HS08). We implemented
each of the four algorithms (BSA, TLA, VTA, and OVTA)
for each class of CRC polynomials (CRC16, CRC24,
CRC32, CRC32sub8, and CRC32sub16) on both architec-
tures. All code development was done in assembly, and
the resulting programs were simulated using cycle-accurate
software tools provided by the respective manufacturers.
These tools allowed us to measure execution times and
memory requirements for each algorithm exactly.
In our experiment, we measure worst-case execution
time (WCET), average execution time (AET), and best-case
execution time (BCET). WCET is the longest possible path
through the code, and BCET is the shortest path. These
measurements were taken using simulation tools to force
the code into longer or shorter branch paths. AET was de-
termined by measuring the execution time required to com-
pute the CRC over 512 byte samples of random data. Some
algorithms (notably the TLA) have a ﬁxed execution se-
quence, so the WCET, AET, and BCET are equal.
For memory requirements, we measure the total number
of program memory words required to implement the algo-
rithm, including memory for table entries and any memory
required for storage of program code. The algorithms with
the heaviest memory usage are the TLA implementations.
Although program memory words are 14 bits in the PIC16F
and 8 bits in the HS08, a 256 byte table requires 256 pro-
gram memory words in either case. The additional mem-
ory required by the PIC implementation is not “wasted” be-
cause the PIC architecture does not allow program memory
to be read directly. Because we did not set out to compare
the performance of these particular processors (or architec-