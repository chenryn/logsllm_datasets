for ﬁle and printer sharing, as well as an inter-process
communication layer. Over the years, it has been an attack
vector due to numerous vulnerabilities, and has been exploited
by worms, including Sasser and Conﬁcker [40]. It is often on the
Internet Storm Center’s list of top-10 most scanned ports [45].
As such, this port is often treated as internal-only by operators
and is commonly the subject of ﬁltering policy [46]. The remote
desktop protocol (RDP) is also built into Windows servers and
clients and allows remote console access to the systems. While
this application does not have as deep a history of exploits as
SMB, it does provide management access to Windows systems;
thus, as with SSH and Telnet, if it is exposed to connections
from the public network, the potential exists for brute-force
or other exploits that can lead to system compromise. In our
analysis, SMB was found to be open on 25% more hosts via
IPv6, exposing a total of 2.4K hosts that have it blocked on
IPv4 in the overall server population. In the non-webserver
population, 49% more hosts were reachable only via IPv6. RDP
is less open on IPv6, but we did see nearly 700 servers with
this port open for IPv6 where it was closed on IPv4.
DNS and NTP: Open DNS resolvers are problematic for
two reasons. First, open resolvers can be susceptible to cache
poisoning attacks [31], [48]. These, in turn, leave the users
of subverted resolvers vulnerable to being re-directed to
malicious services. Second, open resolvers are susceptible to
being leveraged in reﬂection and ampliﬁcation DDoS attacks
(e.g., [37]). The DNS port on servers is less open via IPv6
than IPv4. A small fraction of servers, numbering 2.3K, were
found reachable via only IPv6. We also found 52% more
servers allowing NTP queries via IPv6 compared to IPv4. This
means roughly 10K additional servers—that return system and
version information—can be used as DDoS ampliﬁers [18] or
for reconnaissance to gather version and system information
8
about the servers. While weaker threats, both DNS and NTP
have had vulnerabilities reported as well as been used to attack
others in DDoS campaigns.
FTP: We found FTP to be slightly less open (7%) in IPv6 than
IPv4 in the overall server population tested, though more open
(5%) in the non-webserver population. For IPv6, there were a
small number (3K hosts, 0.8%) only allowing FTP connections
over IPv6 (versus 3.1% only on IPv4). Interestingly, FTP’s
prevalence in the webserver set is more closely correlated with
being on an HTTP server. For the fraction that were open in
IPv6 where IPv4 was blocked, these could represent a back
door to content, including source code to websites.
SNMP: Although the absolute numbers were low for SNMP
among servers, we found 109% more of them (1.6K) to
respond over IPv6 than IPv4; in the non-webserver population,
a staggering 345% more systems were open over IPv6 where
the IPv4 application was blocked. This may be a source of
reconnaissance for attackers or may indicate that the default
read/write private community is also open on these servers
(which, for ethical reasons, we did not test). As such, it is
concerning that an additional almost two thousand servers may
be probed (and possibly manipulated) over IPv6 via SNMP.
MySQL: Finally, we probed servers for the MySQL server
port, and found that only 0.5% supported IPv6 at all. MySQL
prior to version 5.5.3, released in mid-2010, did not support
IPv6. Current versions of the database support IPv6, but IPv6
was not enabled by default, even on dual-stacked hosts, until
version 5.6.6—ﬁrst released in mid-2012 [39]. In fact, when
we analyzed the MySQL minor version strings returned by 32K
servers that responded to our banner grab, as described in § III,
26% were running versions that did not even support IPv6,
66% were running versions with IPv6 disabled by default, and
just 8% were running versions where IPv6 was supported
and enabled by default. In absolute numbers, nearly 600
servers responded on IPv6 only, while 2.2K responded on
both protocols and 35K responded on IPv4 only. Similar to
FTP access, MySQL access is correlated with presence on a
webserver, suggesting a reliance on a database system that is
needlessly exposed to the Internet. In fact, since databases are
typically run as back-end services to web sites or internally
in organizations, the fairly high number of globally reachable
servers was surprising, and the several hundred apparently
reachable by IPv6 only, though relatively few, is concerning.
Overall, the server dataset showed smaller discrepancy
between IPv4 and IPv6 port ﬁltering policy for the applications
we tested than we found in the router probes. However, as we
noted, there were some high-value applications that were more
open, and, due to the substantially larger population, the raw
numbers of servers open on IPv6 only for many applications is
of concern. In many cases, brute-force attacks are enabled by
this discrepancy, and in other cases, known vulnerabilities in
software may be exposed on thousands of dual-stack servers
whose operators may believe that they have no exposure to
these threats due to their IPv4 ﬁltering.
V. POLICY UNIFORMITY
A. Network Response Uniformity
Section IV shows a difference between IPv6 policy and
the intended policy, as indicated by the IPv4 policy. We seek
to understand whether this discrepancy is a symptom of an
organization’s overall security posture or due to small scale
misconﬁguration that deviates from the organization’s intended
policy. Therefore, in this section we aggregate results for each
organization—at both routed preﬁx and autonomous system
granularities—and assess policy uniformity.
We aggregate hosts in our RT and ST datasets by routed
preﬁx and origin AS based on BGP table data collected by
RouteViews and the RIPE RIS BGP collector on February 1,
2015. We ﬁnd that the IPv4 and IPv6 addresses for a host are
mapped to the same AS in 94% (RT ) and 95% (ST ) of the cases.
Therefore, for simplicity we label the hosts with their IPv4
routed preﬁx and AS number. Table III shows the mean and
median number of devices we detect in each organization for
our datasets. Further, we label each host and service with the
protocol(s) that allow connection. Hosts with multiple IPs are
labeled by majority. When a given service is unreachable via
both versions of IP we exclude it from further analysis because
we cannot determine whether the service is not reachable due
to policy or simply not running, and, therefore, these cases
provide no policy insight. For each service on each host we
are left with one of three labels: “4” for services that are only
reachable via IPv4, “6” for services that are only reachable via
IPv6 and “B” for services that are reachable via both IPv4 and
IPv6. Given these labels, we deﬁne the uniformity for each
service within the organization—delimited by routed preﬁx or
AS—as the fraction of hosts with the most common label for
that service. For example, consider an organization with ﬁve
devices running DNS, three of which are labeled “B”, one
labeled “4” and one labeled “6”. The uniformity is therefore
60%.
TABLE III: Number of devices within an organization.
Dataset
Router
Server
Aggregation
Mean Median
Routed Preﬁxes
Autonomous Systems
Routed Preﬁxes
Autonomous Systems
20
40
52
133
5
5
6
8
To put our uniformity results in perspective, we compare
with a “pseudo network” which is made up of a random
selection of hosts—regardless of network boundary—of the
same size as the median organization size given in table III.
We compute uniformity across the randomly chosen pseudo
network just as we describe above. For each application,
we calculate the mean uniformity across 1,000 such random
pseudo networks. Figure 3 shows the mean uniformity results
for both routed preﬁxes and random pseudo networks for
both datasets. First, we ﬁnd at least 90% mean consistency
within organizations across applications. This indicates that
the disparity we detect between IPv4 and IPv6 policy is not
driven by one-off misconﬁgurations, but is in fact a systematic
difference in policy deployment.
Additionally,
the ﬁgure shows—across datasets and
applications— higher uniformity within actual organizations
than within randomly selected pseudo networks. This strength-
ens our conclusion that we are detecting in-situ policy dif-
ferences and are not being lead astray by small, but broad
misconﬁgurations. Also, we elide the results for organizations
9
Fig. 3: Average organization uniformity for router (RT )
and server (ST ) dataset compared to the average pseudo-
network of same median host count (each randomly se-
lected from population of host results). Uniformity is more
consistent within network boundaries than within random
groupings.
deﬁned by AS for clarity, however note: (i) the uniformity is
generally lower for AS-based organizations than routed preﬁxes
due to the increased aggregation across different administrative
domains, and (ii) just as with routed preﬁxes the uniformity is
greater for actual organizations than for pseudo networks.
B. Intra-protocol uniformity
We next
tackle an issue related to organization-level
uniformity: host-level uniformity. That is, how uniform are
individual hosts for the same version of IP across addresses?
This question is important for two reasons. First, if policy
differs for hosts across different addresses via the same protocol,
it may not be surprising that there are differences between
IPv4 and IPv6. Further, non-uniformity at the address level
could indicate ad-hoc policy applied at individual machines
as opposed to systematic policy at the organizational border.
Second, intra-protocol uniformity speaks to the maturity of
security controls and, on average, is useful in comparing the
difference in maturity between protocols. For example, if we
ﬁnd IPv4 to be more consistent than IPv6, this may be an
indication that security controls for IPv4 are more mature,
tested, and robust than for IPv6.
We calculate the uniformity across each host and IP version
and present the mean uniformity across hosts in Figure 4. In
addition to per-application results, we also show two additional
sets of bars: (i) the overall mean across all applications and (ii)
the mean uniformity for ICMP ping. The plots ﬁrst show that
the host-level uniformity is higher for servers (90–95%) than
for routers (70–90%). One possible reason for this difference is
10
Fig. 4: Average intra-IP version uniformity within hosts
having more than one IP of the given version. We see that
results are more consistent for IPv4 than IPv6, and more in
the server (ST ) dataset than the router (RT ) dataset. Also,
we show that the fraction of addresses that are ICMP-
pingable when multiple addresses are associated with the
same host is higher for IPv6 than IPv4.
router IP addresses identify individual interfaces, which have
different tasks (i.e., peering with different networks). Therefore,
it may be natural to ﬁnd different policy applied to different
interfaces. On the other hand, servers do not have the same sort
of natural per-IP division of labor and therefore show higher
uniformity across addresses.
In the ST dataset we ﬁnd approximate parity between IPv4
and IPv6 in terms of uniformity across applications. This is
in contrast to the RT dataset where we generally ﬁnd higher
uniformity in IPv4 compared to IPv6. There are two exceptions
where IPv6 is more uniform than IPv4: BGP and ICMP. While
we cannot readily explain BGP’s disparity, the ICMP difference
may stem from ICMP being less strictly ﬁltered in IPv6 due
to a deployment requirement for IPv6 (e.g., [23]).
VI. BLOCKING ENFORCEMENT
Having established that myriad ﬁltering occurs, we next
turn our attention to the mechanisms employed to block trafﬁc
and where those mechanisms are implemented. To study this,
we use traceroute probes, as described in § II-B, for both
routers (RT ) and servers (ST ). For each application, and each
address associated with each host, we ﬁrst determine whether
the application is open or closed. For each closed application
we determine the enforcement mechanism. As we note in the
last section, we do ﬁnd cases where policy differs within the
same IP protocol. In these cases, we label the host based on
(a) RoutersAverage Network Uniformity(b) Servers1NTPSNMPHTTPHTTPSDNSFTPSMBMySQLRDP0.60.40.200.81RandomPrefixesSSHSSHTelnetNTPSNMPHTTPHTTPSDNSBGP00.20.40.60.8Telnet0.2(a) Routers00.20.40.60.81(b) Servers10.80.60.40Average Protocol UniformityHTTPRDPMySQLSMBFTPHTTPSDNSBGPMeanIPv4IPv6DNSHTTPSHTTPSNMPNTPTelnetSSHPingablePingableSSHTelnetNTPSNMPMeanthe majority enforcement mechanism. We classify each attempt,
as follows.
•
•
•
•
•
Open: In this case, the target host responds favorably
(i.e., with a TCP SYN+ACK or a UDP response).
Passive:Target: In this case, the target host silently
drops the SYN or UDP request. We detect this by
observing that the last responding host within the
traceroute is the hop immediately prior to the target
host (as established by ICMP-based traceroutes and/or
traceroutes involving other applications).
Passive:Other: In this case, we ﬁnd that a hop in the
path prior to the hop before the target host is the
last hop to respond to the traceroute. Therefore, we
conclude that a ﬁrewall is silently dropping the trafﬁc
before arriving at the target host.
Active:Target: In this case, the target host actively
responds to our SYN or UDP request with an error
indicating the service is not available (e.g., TCP reset
or ICMP error message).
Active:Other: In this case, a device on the path towards
the target host issues an active ICMP error or TCP
reset that indicates the service is not available.
Note, ﬁrewalls typically simply drop undesired trafﬁc
silently without generating error trafﬁc (i.e., fall in the “Pas-
sive:Other” category). Closed ports on hosts are more prone to
generating an active error message (i.e., “Active:Target”). Thus,
the breakdown between our various categories can shed light
on ﬁrewall, access control list, or other similar policy-enforcing
device in the path to the target.
TABLE IV: Connection failure mode distribution dif-
ferences. We observe that connection failures are more
frequently active for IPv6 than for IPv4 in both datasets,
suggesting fewer silently-dropping policy devices in IPv6.
Mode
Open
Passive:Target
Passive:Other
Active:Target
Active:Other
Router (RT )
Server (ST )
Mean IPv4 Mean IPv6
Mean IPv4 Mean IPv6
4.17
43.50
10.12
30.93
3.55
6.04
27.15
15.82
36.14
6.94
18.57
36.06
16.31
22.82
2.09
18.89
31.17
14.20
27.61
2.79
A. Typical Connection Failure Modes
Table IV shows the average breakdown across applications
into the categories above for each dataset and for IPv4 and
IPv6. We ﬁrst note that across dataset and IP version host-based
policy enforcement accounts for the majority of the cases where
trafﬁc is ﬁltered (i.e., the “:Target” categories). Additionally,