### Influence Maximization and Node Activation

The process terminates when \( |S_t| = 0 \), i.e., when no further nodes are activated. The influence of the seed set \( S \) is then the expected number of activated nodes when applying the above stochastic activation procedure.

Numerous algorithms are available to solve the influence maximization problem [12]. In our scenario, each graph \( G_i \) is relatively small, making the choice of algorithm less critical. We select the Influence Ranking Influence Estimation (IRIE) algorithm [8] for this task. IRIE estimates the influence \( r(u) \) for each node \( u \) by deriving a system of \( n \) linear equations with \( n \) variables. The influence of a node \( u \) comprises its own influence, 1, and the sum of the influences it propagates to its neighbors.

### Evaluation

In this section, we present the experimental setup and evaluation results. We perform two main experiments: one to verify the correctness of our causal graph and a second to evaluate the root cause identification accuracy. The first experiment is conducted on both synthetic and real-world data, while the second is completed on the real-world dataset. The datasets and code are available at https://github.com/shaido987/alarm-rca.

#### Synthetic Data Generation

Synthetic event sequences are generated in four steps:
1. We randomly generate a Directed Acyclic Graph (DAG) \( G \) with an average out-degree \( d \) and \( N \) event types. We set \( d \) to 1.5 to emulate the sparsity property of our real-world dataset.
2. For each edge \( (u, v) \), a weight \( \alpha_{uv} \) is assigned by uniform random sampling from a range \( r \in [(0.01, 0.05), (0.05, 0.1), (0.1, 0.5), (0.5, 1.0)] \).
3. For each event type \( u \in U \), we assign a background intensity \( \mu_u \) by uniform random sampling from \( (0.001, 0.005) \).
4. Following Ogata [17], we use \( \alpha_{uv} \) and \( \mu_u \) as parameters of a Multi-dimensional Hawkes process to simulate event sequences. We generate event sequences of length \( T = 14 \) days, ensuring that the total number of events is greater than 10,000.

#### Real-World Dataset

The dataset was collected from a major cellular carrier in a moderate-sized city in China between August 4th, 2018, and October 24th, 2018. After preprocessing, it consists of 672,639 alarm records from 3,818 devices with 78 different alarm types. Due to the difficulty of labeling causal relations, we have ground-truth causal relations for a subset of 15 alarm types, comprising 44 directed edges in the graph. Additionally, we have obtained ground-truth root cause alarms in a random sample of 6,000 alarm transactions, which are used to evaluate the root cause localization accuracy.

### Causal Graph Structure Correctness

We evaluate our proposed HPCI method and the accuracy of the discovered causal graphs. We use four frequently used causal inference methods for sequential data as baselines:
- **PC-GS**: PC algorithm with G-square CI test.
- **PC-FZ**: PC algorithm with Fisher-Z CI test.
- **PCTS**: Improved PC algorithm for causal discovery in time series [14].
- **HPADM4**: Multi-dimensional Hawkes process with exponential parameterization of the kernels and a mix of L1 and nuclear-norm [25].

The significance level \( p \) in the conditional independence tests included in the methods is set to 0.05. The size of the time window \( w \) for aggregating event sequences is set to 300 seconds, the maximum lag \( \tau_{\text{max}} = 2 \) in PCTS, and the penalization level in HPADM4 is set to the default 1,000. Furthermore, the decay parameter \( \beta \) in the Hawkes process is set to 0.1, and we select Fisher-Z as the CI test in our HPCI algorithm. For evaluation, we define three metrics as follows:

\[
\text{Precision} = \frac{|P \cap S|}{|P|}, \quad \text{Recall} = \frac{|P \cap S|}{|S|}, \quad \text{F1-score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]

where \( P \) is the set of all directed edges in the learned causal graph \( G_C \) and \( S \) is the set of ground-truth edges.

#### Results

The F1-scores using synthetic data with \( N \in [10, 15, 20] \) are shown in Table 1. As shown, HPCI outperforms the baselines for nearly all settings of \( N \) and \( \alpha \). However, HPADM4 obtains the best result for \( N = 10 \) and low \( \alpha \), due to the sparse distribution of event occurrence intervals, which makes the causal dependency straightforward to capture using a Hawkes process. For higher \( N \) or \( \alpha \), the events will be denser, making it difficult for the Hawkes process to distinguish instantaneous causal relations, especially when events co-occur. The use of CI tests in HPCI helps to distinguish these instantaneous causal relations by considering distribution changes in the aggregated data without time-lagged information among events, thus achieving better results.

The results on the real-world data are shown in Table 2. HPCI performs significantly better than all baselines in precision and F1-score, while PCTS obtains the highest recall. PCTS also has significantly lower precision, indicating more false positives. PCTS is designed for time series, but periodicity can give higher lagged-correlation values leading to more redundant edges. HPCI finds a good balance between precision and recall, indicating that the causality behind the real alarm data conforms to the assumptions of HPCI to a certain extent.

### Root Cause Alarm Identification

We evaluate the effectiveness of CPBE and the root cause alarm accuracy on the real-world dataset. We use the causal graph structure created by HPCI as the base and augment it with the 44 known causal ground-truths. The causal graph is thus as accurate as possible. CPBE is compared with four baseline methods, all used for determining edge weights:
- **IT**: Directly use the weighted causal graph discovered by HPCI with the learned influence intensities as edge weights.
- **Pearson**: Uses the aligned Pearson correlation of each alarm pair [16].
- **CP**: Estimates edge weights based on the number of times \( u \) occurs before \( v \).
- **ST**: A static model with a maximum likelihood estimator [5], similar to CP but \( A_{uv} \) represents the number of times \( u \) occurs before \( v \).

For each method, IRIE is used to find the top-K most likely root cause alarms in each of the 6,000 labeled alarm transactions. For IRIE, we use the default parameters. We attempt to use RandomWalk, BFS, and DFS for traversal in CPBE, as well as different Skip-gram configurations with \( w \in [1, 5] \) and vector length \( L \in [10, 30] \). However, there is no significant difference in the outcome, indicating that CPBE is insensitive to these parameter choices on our data.

The results for different \( K \) when using RandomWalk are shown in Table 3. As shown, CPBE outperforms the baselines for all \( K \). For \( K = 1 \), CPBE achieves an accuracy of 61.8%, which is an excellent outcome considering that no expert knowledge is integrated into the system. Moreover, the running time of CPBE is around 10 seconds, and IRIE takes 325 seconds for all 6,000 alarm transactions, which is fast enough for system deployment.

### Conclusion

We present a framework to identify root cause alarms of network faults in large telecom networks without relying on any expert knowledge. We output a clear ranking of the most crucial alarms to assist in locating network faults. To this end, we propose a causal inference method (HPCI) and a novel network embedding-based algorithm (CPBE) for inferring network weights. Combining the two methods, we construct an alarm influence graph from historical alarm data. The learned graph is then applied to identify root cause alarms through a flexible ranking method based on influence maximization. We verify the correctness of the learned graph using known causal relations and show a significant improvement over the best baseline on both synthetic and real-world data. Moreover, we demonstrate that our proposed framework beats the baselines in identifying root cause alarms.

### References

1. Abele, L., Anic, M., et al.: Combining knowledge modeling and machine learning for alarm root cause analysis. IFAC Proc. Volumes 46(9), 1843–1848 (2013)
2. Bahl, P., Chandra, R., et al.: Towards highly reliable enterprise network services via inference of multi-level dependencies. In: ACM SIGCOMM Computer Communication Review, vol. 37, pp. 13–24. ACM (2007)
3. Chen, P., Qi, Y., et al.: CauseInfer: automatic and distributed performance diagnosis with hierarchical causality graph in large distributed systems. In: INFOCOM, 2014 Proceedings IEEE, pp. 1887–1895. IEEE (2014)
4. Ge, Z., Yates, J., et al.: GRCA: a generic root cause analysis platform for service quality management in large ISP networks. In: ACM CoNEXT Conference on Emerging Networking Experiments and Technologies (2010)
5. Goyal, A., Bonchi, F., et al.: Learning influence probabilities in social networks. In: Proceedings of the third ACM International Conference on Web Search and Data Mining, pp. 241–250. ACM (2010)
6. Grover, A., Leskovec, J.: node2vec: scalable feature learning for networks. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 855–864. ACM (2016)
7. Hawkes, A.G.: Spectra of some self-exciting and mutually exciting point processes. Biometrika 58(1), 83–90 (1971)
8. Jung, K., Heo, W., et al.: IRIE: scalable and robust influence maximization in social networks. In: 2012 IEEE 12th International Conference on Data Mining (ICDM), pp. 918–923. IEEE (2012)
9. Kalisch, M., Bühlmann, P.: Estimating high-dimensional directed acyclic graphs with the PC-algorithm. J. Mach. Learn. Res. 8, 613–636 (2007)
10. Kempe, D., Kleinberg, J., et al.: Maximizing the spread of influence through a social network. In: Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 137–146. ACM (2003)
11. Kobayashi, S., Otomo, K., et al.: Mining causality of network events in log data. IEEE Trans. Netw. Serv. Manag. 15(1), 53–67 (2018)
12. Li, Y., Fan, J., et al.: Influence maximization on social graphs: a survey. IEEE Trans. Knowl. Data Eng. 30(10), 1852–1872 (2018)
13. Lou, J.G., Fu, Q., et al.: Mining dependency in distributed systems through unstructured logs analysis. SIGOPS Oper. Syst. Rev. 44(1), 91–96 (2010)
14. Meng, Y., et al.: Localizing failure root causes in a microservice through causality inference. In: 2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS), pp. 1–10. IEEE (2020)
15. Mikolov, T., Sutskever, I., et al.: Distributed representations of words and phrases and their compositionality. In: Advances in Neural Information Processing Systems, pp. 3111–3119 (2013)
16. Nie, X., Zhao, Y., et al.: Mining causality graph for automatic web-based service diagnosis. In: 2016 IEEE 35th International Performance Computing and Communications Conference (IPCCC), pp. 1–8 (2016)
17. Ogata, Y.: On Lewis’ simulation method for point processes. IEEE Trans. Inf. Theory 27(1), 23–31 (1981)
18. Peters, J., Mooij, J.M., et al.: Causal discovery with continuous additive noise models. J. Mach. Learn. Res. 15(1), 2009–2053 (2014)
19. Spirtes, P., Glymour, C.: An algorithm for fast recovery of sparse causal graphs. Soc. Sci. Comput. Rev. 9(1), 62–72 (1991)
20. Spirtes, P., Glymour, C.N., et al.: Causation, Prediction, and Search. MIT Press, Cambridge (2000)
21. Su, C., Hailong, Z., et al.: Association mining analysis of alarm root-causes in power system with topological constraints. In: Proceedings of the 2017 International Conference on Information Technology, pp. 461–468. ACM (2017)
22. Veen, A., Schoenberg, F.P.: Estimation of space-time branching process models in seismology using an EM-type algorithm. J. Am. Stat. Assoc. 103(482), 614–624 (2008)
23. Wang, P., Xu, J., et al.: CloudRanger: root cause identification for cloud native systems. In: 2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID), pp. 492–502. IEEE (2018)
24. Zhang, X., Bai, Y., et al.: Network alarm flood pattern mining algorithm based on multi-dimensional association. In: Proceedings of the 21st ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems, pp. 71–78. ACM (2018)
25. Zhou, K., Zha, H., et al.: Learning social infectivity in sparse low-rank networks using multi-dimensional Hawkes processes. In: Artificial Intelligence and Statistics, pp. 641–649 (2013)

### Localization of Operational Faults in Cloud Applications by Mining Causal Dependencies in Logs Using Golden Signals

**Authors:**
- Pooja Aggarwal
- Ajay Gupta
- Prateeti Mohapatra
- Seema Nagar
- Atri Mandal
- Qing Wang
- Amit Paradkar

**Affiliation:**
IBM Research AI, New Delhi, India

**Emails:**
- {aggarwal.pooja, ajaygupta, pramoh01, senagar3, atri.mandal}@in.ibm.com
- PI:EMAIL, PI:EMAIL

**Abstract:**
Cloud-based microservice architecture has become a powerful mechanism in helping organizations scale operations by accelerating the pace of change at minimal cost. With cloud-based applications being accessed from diverse geographies, there is a need for round-the-clock monitoring of faults to prevent or limit the impact of outages. Pinpointing the sources of faults in cloud applications is a challenging problem due to complex interdependencies between applications, middleware, and hardware infrastructure, all of which may be subject to frequent and dynamic updates. In this paper, we propose a lightweight fault localization technique that can reduce human effort and dependency on domain knowledge for localizing observable operational faults. We model multivariate error-rate time series using minimal runtime logs to infer causal relationships among golden signal errors (error rates) and micro-service errors to discover a ranked list of possible faulty components. Our experimental results show that our system can localize operational faults with high accuracy (F1 = 88.4%), underscoring the effectiveness of using golden signal error rates in fault localization.

**Keywords:**
- Hybrid cloud
- Fault localization
- Golden signals
- Causal modeling
- PageRank

### Introduction

Run-time failures in running software systems are unavoidable. Recovering systems from such failures is an important aspect of incident management in IT Operations. To identify the mitigating actions that will lead to system recovery, the failure needs to be triaged to a faulty system component (along with the reason for component failure). This triaging process, known as fault localization, is crucial for efficient incident management.