pairs as future work. We also plan to investigate principled
methodologies to reduce the search space of vulnerable pairs.
Public cloud setting. Since INVISIPROBE is implemented
based on the features and ISA of Intel CPUs, the public
Fig. 8: Comparison between Pythia, NetCat and our attack.
Shaded parts show where the attack is focusing on.
cloud supporting RDMA, in particular CloudLab, cannot be
evaluated against, because it only has AMD CPUs. We leave
the attack implementation AMD platforms as a future work.
Single-CPU setting. Though INVISIPROBE is expected to be
used as a cross-CPU attack vector, e.g., in a full disaggregated
server rack, so far, we only evaluated INVISIPROBE under
the single-CPU setting because our motherboard only has
one CPU slot. We plan to evaluate INVISIPROBE under the
cross-CPU setting with a new motherboard, e.g., Supermicro
X11DPH-T.
PCIe topology. In evaluation, we assume the adversary knows
the PCIe topology of the targeted machine, and then selects
attacker and victim peripheral devices accordingly. When
the information is unavailable, the attacker would need to
infer which victim device shares the I/O switch. This task is
similar as VM co-residency attack [82], in which the adversary
leverages side-channels to determine when her VM shares a
physical machine with another victim VM. The probing delays
observed by the adversary might fulﬁll this task, and we plan
to validate this hypothesis.
VIII. RELATED WORKS
Side-channel attacks in data center. Recently, a few works
studied how RDMA can be exploited to break the conﬁden-
tiality of machines/programs in a data center with cache-based
side-channel attacks. In the attack named NetCat [23], Kurth et
al. showed that an attacker can remotely Prime+Probe the LLC
of the victim machine with the help of RDMA NICs and
Intel’s special cache mechanism named DDIO (Data-Direct
I/O). The attacker is able to infer the memory access pattern
of the victim machine, resulting in consequences like password
leakages. In the attack named Pythia [24], Tsai et al. found
that Evict+Reload can be launched against metadata stored in
the SRAM on RDMA NIC. With this attack, other RDMA
nodes’ access patterns can be inferred.
Our attacks explore another direction to launch attacks on
RDMA NICs. The two literature [23], [24] focused on cache
timing on host CPU and NICs respectively. Our attacks focus
on timing related to PCIe links between host CPU and NICs.
Figure 8 shows the comparison.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
334
CPU #0...Root ComplexCPU #nRoot ComplexPCIeSwitchPCIeSwitchGPUNVME SSDGPUMemoryMemory......fabricCPU CoresL3 CacheVictim Machine (Our Attack & NetCat)Root ComplexPCIe SwitchSRAM (cache)RDMA NICSRAM (cache)RDMA NICAttack MachineVictim Machine (Pythia)RDMA NICRDMA NICNetCatOur AttackPythiaSecurity implications of bandwidth contention. Previous
works have shown bandwidth contention can be exploited for
side-channel and covert-channel for attacks. Hu et al.
[83],
[84] and Gray et al.
[85], [86] studied the covert channels
based on bus/cache contention between VMs managed by
VAX security kernel. Wu et al. investigated a similar attack
in the contemporary public cloud environment [87]. DRAMA
exploits the DRAM row buffers that are shared in multipro-
cessor systems for cross-CPU attacks [88]. Irazoqui et al. also
conducted cross-CPU attacks on the CPU interconnect [89].
None of the prior works investigated the issues on the high-
speed I/O protocols like PCIe, and we made the ﬁrst attempt.
Keystroke inference. Keystroke inference was studied based
on the network communication patterns [90]. Following that,
a number of works studied how information leaked from
software and hardware can be exploited for the same purpose.
For instance, Zhang et al. [12] proposed that the pattern of
ESP register value of a thread can be used as ﬁngerprints
of keystroke events. Schwarz et al. proposed KeyDrown [47]
showing 1) timing attack on keyboard interrupt and 2) cache
attack on the interrupt handler in the kernel can lead to
keystroke inference. Wang et al. showed that by launching
cache-based side-channel attacks against graphic libraries, the
same goal can be achieved [48]. INVISIPROBE reveals a new
remote side-channel for keystroke inference.
Website inference. When the adversary is able to eavesdrop
the trafﬁc between the victim user and a remote entity, even if
the trafﬁc is encrypted, which website might is visited can still
be inferred, based on packet sizes and time intervals [91]–[95].
As more and more browsers choose to render webpages in
the GPU, which webpage is visited can be recovered through
GPU-based side-channel, in memory residue, access patterns
and performance counters [25], [65], [96]. Besides, cache side-
channel attacks have also been found effective for website
inference [66], [97].
Stealing machine-learning model. As the machine-learning
model structure can be considered as a secret, recently a
number of works studied how it can be inferred with side-
channel attacks. The exploited side-channels include power
consumption [98]–[100], CPU cache [101]–[103] and GPU
resource contention [25], [26]. The one closest to our work
snoops PCIe bus [59]. The attacker needs physical access to
the edge device to obtain such information. Our adversary can
be remote.
IX. CONCLUSION
PCIe congestion resulted from the insufﬁcient forwarding
capability of I/O switches introduces I/O delays to a connected
device. When exploited by an attacker, who intentionally
introduces PCIe congestion, sensitive user activities on a
device can be inferred. We identiﬁed four attacks in two
scenarios (using RDMA NIC to attack GPU and using NVMe
SSD to attack NIC), showing sensitive information like the
keystroke timings, webpage visits, trained machine-learning
models can be inferred at high accuracy. We call the awareness
of server manufacturers and the security community, and our
study can serve as the motivation to design security-enhanced
PCIe implementations.
X. ACKNOWLEDGEMENT
We thank the valuable comments from the anonymous re-
viewers, who have guided us to signiﬁcantly improve the paper
from its initial version. The authors from Fudan University are
supported by NSFC 61802068 and Shanghai Sailing Program
18YF1402200.
REFERENCES
[1] “The three most common ethernet speeds,” https://smallbusiness.chro
n.com/three-common-ethernet-speeds-69375.html, accessed: 2020-02-
11.
[2] “Nvme ssds: Everything you need to know about this insanely fast stor-
age,” https://www.pcworld.com/article/2899351/everything-you-need-t
o-know-about-nvme.html, accessed: 2020-02-11.
[3] R. Neugebauer, G. Antichi, J. F. Zazo, Y. Audzevich, S. L´opez-
Buedo, and A. W. Moore, “Understanding pcie performance for end
host networking,” in Proceedings of the 2018 Conference of the ACM
Special Interest Group on Data Communication, 2018, pp. 327–341.
impact gpu performance?”
[4] “Pcie 3.0 x8 vs. x16: Does
it
https://www.gamersnexus.net/guides/2488-pci-e-3-x8-vs-x16-per
formance-impact-on-gpus, accessed: 2020-02-11.
[5] “2nd generation intel xeon scalable processors with intel c620 series
chipsets (purley refresh),” https://www.intel.com/content/www/us/en/
design/products-and-solutions/processors-and-chipsets/cascade-lake/
2nd-gen-intel-xeon-scalable-processors.html, accessed: 2020-02-29.
[6] “Tyan thunder hx ft77db7109,” https://www.tyan.com/Barebones FT7
7DB7109 B7109F77DV14HR-8X-2T-F, accessed: 2020-02-20.
[7] A. Burnes, “Introducing NVIDIA RTX IO,” https://www.nvidia.com
/en-us/geforce/news/rtx-io-gpu-accelerated-storage-technology/, 2020,
[Online; accessed 18-December-2020].
[8] L. Yin, X. Chen, Z. Qin, Z. Zhang, J. Feng, and D. Li, “An experimental
perspective for computation-efﬁcient neural networks training,” in
Conference on Advanced Computer Architecture. Springer, 2018, pp.
168–178.
[9] R. Budruk, “Pci express basics,” in PCI-SIG Developers Conference,
2007.
[10] W. Sun, L. Xu, S. Elbaum, and D. Zhao, “Model-agnostic and efﬁcient
exploration of numerical state space of real-world TCP congestion
control implementations,” in 16th USENIX Symposium on Networked
Systems Design and Implementation (NSDI 19), 2019, pp. 719–734.
[11] S. Jero, M. E. Hoque, D. R. Choffnes, A. Mislove, and C. Nita-Rotaru,
“Automated attack discovery in tcp congestion control using a model-
guided approach.” in ANRW, 2018, p. 95.
[12] K. Zhang and X. Wang, “Peeping tom in the neighborhood: Keystroke
eavesdropping on multi-user systems,” in USENIX Security Symposium,
vol. 20, 2009, p. 23.
[13] P. Zhou, W. Shi, J. Tian, Z. Qi, B. Li, H. Hao, and B. Xu, “Attention-
long short-term memory networks for relation
based bidirectional
classiﬁcation,” in Proceedings of
the
association for computational linguistics (volume 2: Short papers),
2016, pp. 207–212.
the 54th annual meeting of
[14] “Intel pcie introduction,” https://www.intel.com/content/www/us/en/io
/pci-express/pci-express-architecture-general.html, accessed: 2020-02-
29.
[15] “Down to the tlp: How pci express devices talk,” http://xillybus.com
/tutorials/pci-express-tlp-pcie-primer-tutorial-guide-1, accessed: 2020-
02-11.
[16] “8th generation intel core processor family and intel xeon processor
e-2100m family (coffee lake h),” https://www.intel.com/content/www/
us/en/design/products-and-solutions/processors-and-chipsets/coffee-l
ake-h/overview.html, accessed: 2020-02-29.
[17] T. Shanley, InﬁniBand network architecture. Addison-Wesley Profes-
sional, 2003.
[18] M. Beck and M. Kagan, “Performance evaluation of the rdma over
ethernet (roce) standard in enterprise data centers infrastructure,” in
Proceedings of
the 3rd Workshop on Data Center-Converged and
Virtual Ethernet Switching, 2011, pp. 9–15.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
335
[19] F. D. Neeser, B. Metzler, and P. W. Frey, “Softrdma: Implementing
iwarp over tcp kernel sockets,” IBM Journal of Research and Devel-
opment, vol. 54, no. 1, pp. 5–1, 2010.
[20] C. Mitchell, Y. Geng, and J. Li, “Using one-sided RDMA reads to
build a fast, cpu-efﬁcient key-value store,” in Presented as part of the
2013 USENIX Annual Technical Conference (USENIXATC 13), 2013,
pp. 103–114.
[21] J. Shi, Y. Yao, R. Chen, H. Chen, and F. Li, “Fast and concurrent
RDF queries with rdma-based distributed graph exploration,” in 12th
USENIX Symposium on Operating Systems Design and Implementation
(OSDI 16), 2016, pp. 317–332.
[22] J. Xue, Y. Miao, C. Chen, M. Wu, L. Zhang, and L. Zhou, “Fast
distributed deep learning over rdma,” in Proceedings of the Fourteenth
EuroSys Conference 2019, 2019, pp. 1–14.
[23] M. Kurth, B. Gras, D. Andriesse, C. Giuffrida, H. Bos, and K. Razavi,
“Netcat: Practical cache attacks from the network,” in Proceedings of
IEEE Security & Privacy 2020.
IEEE, 2020.
[24] S.-Y. Tsai, M. Payer, and Y. Zhang, “Pythia: remote oracles for the
masses,” in 28th USENIX Security Symposium (USENIX Security 19),
2019, pp. 693–710.
[25] H. Naghibijouybari, A. Neupane, Z. Qian, and N. Abu-Ghazaleh,
“Rendered insecure: Gpu side channel attacks are practical,” in Pro-
ceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, 2018, pp. 2139–2153.
[26] J. Wei, Y. Zhang, Z. Zhou, Z. Li, and M. A. A. Faruque, “Leaky
DNN: stealing deep-learning model secret with GPU context-switching
side-channel,” in 50th Annual IEEE/IFIP International Conference on
Dependable Systems and Networks, DSN 2020, Valencia, Spain, June
29 - July 2, 2020, 2020, pp. 125–137.
[27] “Nvme over fabrics,” https://nvmexpress.org/wp-content/uploads/NVM
e Over Fabrics.pdf, accessed: 2020-03-05.
[28] D. J. Miller, P. M. Watts, and A. W. Moore, “Motivating future
interconnects: a differential measurement analysis of pci latency,” in
Proceedings of the 5th ACM/IEEE Symposium on Architectures for
Networking and Communications Systems, 2009, pp. 94–103.
[29] M. Martinasso, G. Kwasniewski, S. R. Alam, T. C. Schulthess, and
T. Hoeﬂer, “A pcie congestion-aware performance model for densely
populated accelerator servers,” in SC’16: Proceedings of the Inter-
national Conference for High Performance Computing, Networking,
Storage and Analysis.
IEEE, 2016, pp. 739–749.
[30] M. Martinasso and J.-F. M´ehaut, “A contention-aware performance
model for hpc-based networks: A case study of the inﬁniband network,”
in European Conference on Parallel Processing. Springer, 2011, pp.
91–102.
[31] L. Soares and M. Stumm, “Flexsc: Flexible system call scheduling with
exception-less system calls.” in Osdi, vol. 10, 2010, pp. 1–8.
[32] “What
is rdma?” https://community.mellanox.com/s/article/what-is-r
dma-x, accessed: 2020-08-27.
[33] Z. Yang, J. R. Harris, B. Walker, D. Verkamp, C. Liu, C. Chang, G. Cao,
J. Stern, V. Verma, and L. E. Paul, “Spdk: A development kit to build
high performance storage applications,” in 2017 IEEE International
Conference on Cloud Computing Technology and Science (CloudCom).
IEEE, 2017, pp. 154–161.
[34] “Userspace networking with dpdk,” https://www.linuxjournal.com/con
tent/userspace-networking-dpdk, accessed: 2020-02-29.
[35] “Rdtscp,” https://www.felixcloutier.com/x86/rdtscp, accessed: 2020-02-
29.
[36] “Ip over inﬁniband (ipoib),” https://docs.mellanox.com/pages/viewpage
.action?pageId=12004991, accessed: 2020-08-27.
[37] “Which queue pair type to use,” https://www.rdmamojo.com/2013/06
/01/which-queue-pair-type-to-use/, accessed: 2020-02-29.
[38] “Introducing 200g hdr inﬁniband solutions,” https://www.mellanox.c
om/related-docs/whitepapers/WP Introducing 200G HDR InfiniBan
d Solutions.pdf, accessed: 2020-02-25.
[39] C. Maurice, C. Neumann, O. Heen, and A. Francillon, “C5: cross-
cores cache covert channel,” in International Conference on Detection
of Intrusions and Malware, and Vulnerability Assessment.
Springer,
2015, pp. 46–64.
[40] “Enabling gpu rendering on windows server 2016 / windows 10
rdp,” https://community.esri.com/thread/225251-enabling-gpu-renderi
ng-on-windows-server-2016-windows-10-rdp, accessed: 2020-08-27.
workstation,”
gpu-accelerated
[41] “Creating
virtual
linux
a
https://cloud.google.com/solutions/creating-a-virtual-gpu-accelerat
ed-linux-workstation, accessed: 2020-08-27.
[42] “Deploying a 4x4k, gpu-backed linux desktop instance on aws,”
https://aws.amazon.com/cn/blogs/compute/deploying-4k-gpu-backed-l
inux-desktop-instance-on-aws/, accessed: 2020-02-20.
[43] Unknown, “Steamworks,” https://partner.steamgames.com/, 2020, [On-
line; accessed 18-December-2020].
[44] ——, “Rethinking Visual Cloud Services for Evolving Media,”
https://www.intel.ru/content/dam/www/public/us/en/documents/guides
/vcd-wp-v6.pdf, 2020, [Online; accessed 18-August-2020].
[45] “Remote desktop services - gpu acceleration,” https://docs.microsoft.c
om/en-us/windows-server/remote/remote-desktop-services/rds-graphic
s-virtualization, accessed: 2020-08-27.
[46] “Remote desktop software statistics and trends,” https://www.trustr
adius.com/vendor-blog/remote-desktop-buyer-statistics-and-trends,
accessed: 2020-08-27.
[47] M. Schwarz, M. Lipp, D. Gruss, S. Weiser, C. Maurice, R. Spreitzer,
and S. Mangard, “Keydrown: Eliminating software-based keystroke
timing side-channel attacks,” 2018.
[48] D. Wang, A. Neupane, Z. Qian, N. B. Abu-Ghazaleh, S. V. Krish-
namurthy, E. J. Colbert, and P. Yu, “Unveiling your keystrokes: A
cache-based side-channel attack on graphics libraries,” in NDSS, 2019.
[49] L. R. Rabiner, “A tutorial on hidden markov models and selected
applications in speech recognition,” Proceedings of the IEEE, vol. 77,
no. 2, pp. 257–286, 1989.
[50] “Gpu accelerated compositing in chrome,” https://www.chromium.org
/developers/design-documents/gpu-accelerated-compositing-in-chrom
e, accessed: 2020-02-20.
[51] “Webgl: 2d and 3d graphics for the web,” https://developer.mozilla.or
g/en-US/docs/Web/API/WebGL API, accessed: 2020-02-29.
[52] “How to turn hardware acceleration on and off