942
942
942
942
1530
1530
1530
1530
0.1
0.12
0.04
0.01
0.05
0.01
0.001
0.02
0.11
0.13
0.04
0.01
0.0033
0.0006
0.00006
0.001
at once. Feature extraction averagely takes 0.1 second for
each of 1530 detected malware.
With regard to the time of dynamic conﬁrmation on 234
samples, it takes 1,544 seconds. Including the 168 seconds
used for classiﬁcation (with feature extraction time for 1530
samples), it takes 1,712 seconds to ﬁnish identifying attack
types for the 1530 malware, i.e., around 1 second per mal-
ware. Thus, combining this two techniques can improve the
overall accuracy and meanwhile attain good performance.
8. DISCUSSION
Two- or one-phase machine learning classiﬁcation?
A concern is that how the accuracy will be if we make two
phase classiﬁcation into one—that is we do classiﬁcation at
once according to samples with benign labels and labels of
eight attack types. On the 20942 training samples, the ac-
curacy of the 4 trained classiﬁers is 90.99% (RF), 85.74%
(J48), 77.15% (NB) and 88.27% (RT), respectively. We ex-
amine the results and ﬁnd the diﬀerence for RF is not sig-
niﬁcant. Among 20000 benign samples, only one is wrongly
classiﬁed for RF, while among 942 malicious samples, 84
are wrongly classiﬁed for RF. In contrast, 74 out of 942 are
wrongly classiﬁed in our two phase classiﬁcation of RF. But
NB shows signiﬁcant diﬀerences—it wrongly classiﬁes 203
out of 942 malicious samples in one phase classiﬁcation, in
contrast, this number is 156 in our two phase classiﬁcation.
As the training time is almost ignorable if feature extraction
is done, we consider two phase classiﬁcation is worth.
Predicative features. We ﬁnd that the malware detec-
tion has some decisive features: e.g., 98% of benign scripts
use eval function only 0 or 1 times, while 87% malicious ones
use more than 2 times, and as many as 1778 times. Dur-
ing attack type classiﬁcation, we observe that there are no
decisive features that can exclusively characterize a certain
attack type. Instead, we indeed ﬁnd some predicative fea-
tures that can be eﬀective in most cases. Speciﬁcally, among
our 942 training malicious samples, we observe the following
facts: 89% of Type I samples have feature changeSRC 20 ; 74% of Type III have feature
eval in Figure 4 with a value>1000; 83% of Type IV have
feature GetU serAgent > 2.5; 87% of Type V have fea-
ture ref erenceError 5000.
Thread to validity. First, the training sets are from
three origins: VXHeaven, OpenMalware and Web In-
spector. Thus, the collected samples directly aﬀect the
accuracy of trained classiﬁers. To address this problem, we
need to further investigate the impact of sample size and rep-
118resentativeness on the results. Second, the parameters and
set-up for machine learning classiﬁers are the default ones.
Further investigation should be conducted to see the eﬀects
of parameters. Lastly, the dynamic attack conﬁrmation re-
lies on experts’ knowledge to reﬁne the learned DFA. The
rationale of learned DFAs can aﬀect the accuracy of attack
conﬁrmation—checking if a trace of a sample is accepted by
the DFA of a certain attack type.
9. RELATED WORK
Since the past few years, JavaScript malware detection has
intrigued the interest of security researchers and many ap-
proaches have been proposed. Existing approaches to Java-
Script malware detection mostly rely on static analysis with
machine learning techniques or dynamic analysis with be-
havioural abnormality checking. However, beyond the mere
detection, there are few studies that focus on malware clas-
siﬁcation according to vulnerability or attack behaviors.
9.1 Machine Learning Approaches
In 2009, Likarish et al. [27] adopted 4 classiﬁers (i.e., NB,
ADTree, SVM and RIPPER) to detect obfuscated Java-
Script malware. The assumption of their approach is that
malware utilizes obfuscation to hide the exploits and to
evade the detection. They reported that features extracted
from the strings of obfuscated scripts can distinguish obfus-
cated (malicious) scripts from non-obfuscated (benign) ones
by machine learning classiﬁers. Likarish et al. acknowledged
that the false positive rate is due to obfuscated but benign
scripts, which poses threat to the assumption. However, in
our study, we use not only features on obfuscation, but also
other features on program information. By this, we can re-
duce false positive rate due to obfuscated but benign scripts.
In 2010, JSand (JavaScript Anomaly-based aNalysis and
Detection) [17] was presented to detect Drive-by Downloads
(DbD) attacks. JSand identiﬁes 10 features characterizing
intrinsic events of a drive-by download attack, and then uses
these features for machine learning technique (NB) to detect
malicious samples. These 10 features are extracted from 4
aspects (redirection, de-obfuscation, environmental context
and exploitation) by dynamic anomaly detection with em-
ulation in HtmlUnit [1]. Diﬀerent from our work, JSand
adopts dynamic analysis and fails to investigate the impact
of the diﬀerent classiﬁers. Dynamic anomaly-based analysis
can be eﬀective but not eﬃcient—JSand needs 2:22 hours to
scan the Wepawet-bad dataset which consists of 531 URLs.
Also in 2010, Cujo [33] uses hybrid analysis to on-the-ﬂy
capture program information (by static analysis) and exe-
cution traces (by dynamic analysis) of JavaScript program.
The authors explored the distinct features for heap-spraying
attacks and obfuscated attacks. But they failed to examine
features for obfuscated but benign scripts, and overlooked
classiﬁcation according to vulnerabilities or attack behav-
iors as we do in this study. Note that Cujo requires exe-
cuting every script to capture dynamic features, while our
approach only executes scripts that fall into grey zone for
dynamic conﬁrmation. Finally, Cujo takes averagely 500ms
to analyze a webpage. In contrast, JSDC takes about 80 ms
in detection per script, including 70 ms for feature extraction
and 10 ms for classiﬁcation.
Later in 2011, Canali et al. [14] proposed a ﬁlter, called
Prophiler, to quickly ﬁlter out benign pages and forward
to the costly analysis tools only the suspicious pages that are
highly malicious. The ﬁlter’s detection models are learned
based on 70 features extracted from HTML contents of a
page, from the associated JavaScript code, and from the cor-
responding URL. Then, multiple classiﬁers, Bayes Net(BN),
J48, Logistic, RT and RF, are used to classify the malicious
and benign web-pages. For JavaScript, the FP of these clas-
siﬁers is good, ranging from 0.0% to 1.7%, but the FN ranges
from 18.1% to 81%, which is worser than our approach.
In the same year, AST is used to extract characteristics
for malicious JavaScript detection [18]. Curtsinger et al. [18]
presented the tool Zozzle that predicates the benignity or
maliciousness of JavaScript by leveraging features associated
with AST contextual information. Around one to two thou-
sand of features are extracted from the hierarchical structure
and texts in ASTs, and then the classiﬁer NB is applied. To
remove the noise due to obfuscation, Zozzle uses Detours
binary instrumentation to get the ﬁnal, unpacked code for
accurate AST generation. After tuning up with diﬀerent
set-up, the authors reported the FP ranges from 0.0003% to
4.5%, and the FN from 1.26% to 11.08%.
To sum up, none of the existing studies investigate the ef-
fective features for classifying JavaScript malware into var-
ious attack types as we do in this study. Additionally, we
propose to apply dynamic conﬁrmation to the cases that fall
into grey zone in classiﬁcation. By this, we can improve the
overall accuracy and meanwhile achieve scalability.
9.2 Other Detection Techniques
Various approaches have been presented to detect special-
ized JavaScript malware in line with diﬀerent attacks.
Attacks of obfuscated malware. In [16], the param-
eters for dangerous functions (eval, document.write, and so
on) in web pages are processed to get 3 types of metrics
data, i.e., N-gram, entropy and word size. The metrics data
is compared with a certain threshold that is learned from
empirical study to judge the maliciousness of the correspond-
ing web page. Recently, JStill [38] detects obfuscated at-
tacks based on the observation that—JavaScript has to be
de-obfuscated before doing its malicious intention, but the
deobfuscation process inevitably invokes certain functions.
Policy violation attacks. As early as in 2005, Hal-
laraker et al. [24] monitored the JavsScript execution and
then checked the execution trace against the high-level se-
curity policies (e.g., the same-origin policy and the signed-
script policy), to detect malicious attack behaviour.
Heap spread attacks. In 2009, Egele et al. [20] man-
aged to detect heap spread attacks by checking instantiation
of shell-code strings in the heap—speciﬁcally—checking if
the string contains executable x86 code. The similar idea
is adopted in Nozzle [32], which individually examines all
objects in the heap, interpreting object content as code and
conducting a static analysis on the code to discover exploits.
JavaScript-bearing PDF documents. Tzermias et
al. [36] presents MDScan, which instrumented Firefox Spi-
derMonkey. In such way, all the allocated string objects are
scanned by the shellcode detector Nemu [31], and possible
exploits are detected. MDScan failed to address this prob-
lem completely since it only searched for legitimate Java-
Script inclusions (denoted by the /JS tag), while an attacker
can easily circumvent this by encoding the script as text and
evaluate it at runtime (e.g. via eval).
JavaScript worms. The tool Spectator [28] detects a
worm whenever a unusually long propagation chain is found.
The idea is using a web proxy to monitor the cookie session
and propagation chain for identiﬁcation of worm replication.
119In [15], PathCutter adopts the idea of running an individ-
ual script in diﬀerent isolated and trusted components of
web-pages. It prevents the propagation of worms by grant-
ing scripts the permission to do only legitimate operations.
10. CONCLUSION
A key to protecting user from exploitation is the rigor-
ous eliminating of malware on Internet. To this end, we
propose a method to accelerate the process of manual mal-
ware detection by suggesting potentially malware and their
attack types to an analyst or an end-user. Our method
not only learned features of maliciousness but also of attack
type. Therefore, we can tell not only presence of malware,
but malicious behaviors with attack approach information
by virtue of dynamic attack conﬁrmation. We also demon-
strated our eﬀectiveness and eﬃciency by empirical wild pre-
diction. Among over 1,400,000 scripts, we ﬁnd over 1,500
malware with 8 attack types. Our detection speed is scalable
with below 80 ms per script. The attack type classiﬁcation
takes around 1 second for each malware, combining machine
learning classiﬁers and dynamic attack conﬁrmation.
11. ACKNOWLEDGEMENTS
This work is supported by ”Formal Veriﬁcation on Cloud”
project under Grant No: M4081155.020 and ”Vulnerability
Detection in Binary Code” project under Grant No: M40
61366.680.
12. REFERENCES
[1] Htmlunit. http://htmlunit.sourceforge.net/.
[2] Internet security threat report. http://www.symantec.com/
security_response/publications/threatreport.jsp.
[3] Openmalware.
http://http://oc.gtisc.gatech.edu:8080/.
[4] Vxheaven. http://vxheavens.com/.
[5] Web inspector: Website security with malware scan and pci
compliance. http://www.webinspector.com/.
[6] Rhino. https://developer.mozilla.org/en-US/docs/
Mozilla/Projects/Rhino, 2005.
[7] The heritrix web crawler project.
http://crawler.archive.org/, 2007.
[8] Kaspersky security bulletin 2013.
http://media.kaspersky.com/pdf/KSB_2013_EN.pdf, 2013.
[9] JSDC. https://sites.google.com/site/
jsmalwaredetection/models.html, 2014.
[10] MDN:XPCOM. https://developer.mozilla.org/en-US/
docs/Mozilla/Tech/XPCOM, 2014.
[11] VirusTotal. https://www.virustotal.com/, 2014.
[12] Microsoft Security Intelligence Report,Volume 15. http://
www.microsoft.com/security/sir/archive/default.aspx,
Jan. 2013 to Jun. 2013.
[13] P. Agten, S. Van Acker, Y. Brondsema, P. H. Phung,
L. Desmet, and F. Piessens. Jsand: Complete client-side
sandboxing of third-party javascript without browser
modiﬁcations. In Proceedings of the 28th Annual Computer
Security Applications Conference, pages 1–10, New York,
NY, USA, 2012. ACM.
[14] D. Canali, M. Cova, G. Vigna, and C. Kruegel. Prophiler: a
fast ﬁlter for the large-scale detection of malicious web
pages. In WWW, pages 197–206, 2011.
[15] Y. Cao, V. Yegneswaran, P. A. Porras, and Y. Chen.
Pathcutter: Severing the self-propagation path of xss
javascript worms in social web networks. In NDSS, 2012.
[16] Y. Choi, T. Kim, S. Choi, and C. Lee. Automatic detection
for javascript obfuscation attacks in web pages through
string pattern analysis. In International Conference on
Future Generation Information Technology, pages 160–172,
Berlin, Heidelberg, Germany, 2009.
[17] M. Cova, C. Kr¨ugel, and G. Vigna. Detection and analysis
of drive-by-download attacks and malicious javascript code.
In WWW, pages 281–290, 2010.
[18] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert. Zozzle:
Fast and precise in-browser javascript malware detection.
In the 20th USENIX conference on Security, Berkeley, CA,
USA, 2011.
[19] M. Egele, T. Scholte, E. Kirda, and C. Kruegel. A survey
on automated dynamic malware-analysis techniques and
tools. ACM Comput. Surv., 44(2):6, 2012.
[20] M. Egele, P. Wurzinger, C. Kruegel, and E. Kirda.
Defending browsers against drive-by downloads: Mitigating
heap-spraying code injection attacks. In DIMVA, pages
88–106, 2009.
[21] B. Feinstein and D. Peck. Caﬀeine monkey: Automated
collection, detection and analysis of malicious javascript. In
DEFCON 15, USA, 2007.
[22] J. J. Garrett et al. Ajax: A new approach to web
applications. 2005.
[23] M. Hall, E. Frank, G. Holmes, B. Pfahringer,
P. Reutemann, and I. H. Witten. The weka data mining
software: an update. ACM SIGKDD explorations
newsletter, 11(1):10–18, 2009.
[24] O. Hallaraker and G. Vigna. Detecting malicious javascript
code in mozilla. In ICECCS, pages 85–94, 2005.
[25] A. Ikinci, T. Holz, and F. C. Freiling. Monkey-spider:
Detecting malicious websites with low-interaction
honeyclients. In Sicherheit, volume 8, pages 407–421, 2008.
[26] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and
G. Vigna. Revolver: An automated Approach to the
Detection of Evasive Web-based Malware. In USENIX
Security, pages 637–652, 2013.
[27] P. Likarish, E. Jung, and I. Jo. Obfuscated malicious
javascript detection using classiﬁcation techniques. In
MALWARE, pages 47–54, Montreal, QC, Oct. 2009.
[28] V. B. Livshits and W. Cui. Spectator: Detection and
containment of javascript worms. In USENIX Annual
Technical Conference, pages 335–348, 2008.
[29] G. Mohr, M. Stack, I. Rnitovic, D. Avery, and M. Kimpton.
Introduction to heritrix. In 4th International Web
Archiving Workshop, 2004.
[30] J. Oncina and P. Garcia. Inferring Regular Languages in
Polynomial Update Time. Pattern Recognition and Image
Analysis, pages 49–61, 1992.
[31] M. Polychronakis, K. G. Anagnostakis, and E. P. Markatos.
An empirical study of real-world polymorphic code
injection attacks. In LEET, 2009.
[32] P. Ratanaworabhan, V. B. Livshits, and B. G. Zorn. Nozzle:
A defense against heap-spraying code injection attacks. In
USENIX Security Symposium, pages 169–186, 2009.
[33] K. Rieck, T. Krueger, and A. Dewald. Cujo: eﬃcient
detection and prevention of drive-by-download attacks. In
ACSAC, pages 31–39, 2010.
[34] M. Roesch et al. Snort: Lightweight intrusion detection for
networks. In LISA, volume 99, pages 229–238, 1999.
[35] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast
automaton-based method for detecting anomalous program
behaviors. In IEEE Symposium on Security and Privacy,
pages 144–155, 2001.
[36] Z. Tzermias, G. Sykiotakis, M. Polychronakis, and E. P.
Markatos. Combining static and dynamic analysis for the
detection of malicious documents. In EUROSEC, page 4,
2011.
[37] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski,
S. Chen, and S. T. King. Automated web patrol with
strider honeymonkeys: Finding web sites that exploit
browser vulnerabilities. In NDSS, 2006.
[38] W. Xu, F. Zhang, and S. Zhu. Jstill: mostly static
detection of obfuscated malicious javascript code. In
CODASPY, pages 117–128, 2013.
120