### 优化后的文本

#### 实验结果
对于1530个检测到的恶意软件样本，特征提取平均耗时0.1秒。在234个样本上进行动态确认的时间为1,544秒。包括用于分类（含1530个样本的特征提取时间）的168秒，总共需要1,712秒来完成对1530个恶意软件攻击类型的识别，即每个恶意软件大约需要1秒。因此，结合这两种技术可以在提高整体准确性的同时保持良好的性能。

### 讨论
#### 两阶段或单阶段机器学习分类？
一个关注点是，如果将两阶段分类合并为单阶段分类，即将良性标签和八种攻击类型标签一起进行分类，其准确性会如何变化。在20942个训练样本上，四种分类器的准确率分别为：RF（90.99%）、J48（85.74%）、NB（77.15%）和RT（88.27%）。我们检查了结果，发现RF的差异不显著。在20000个良性样本中，RF仅错误分类了一个样本；而在942个恶意样本中，RF错误分类了84个。相比之下，在我们的两阶段分类中，RF错误分类了74个恶意样本。然而，NB表现出显著差异——在单阶段分类中，NB错误分类了203个恶意样本，而两阶段分类中这一数字为156。鉴于特征提取完成后，训练时间几乎可以忽略不计，我们认为两阶段分类是值得的。

#### 预测性特征
我们发现恶意软件检测具有一些决定性的特征：例如，98%的良性脚本使用`eval`函数不超过一次，而87%的恶意脚本使用超过两次，最多可达1778次。在攻击类型分类过程中，我们观察到没有单一特征能够完全表征某一特定攻击类型。相反，我们确实发现了一些在大多数情况下有效的预测性特征。具体而言，在942个训练恶意样本中，我们观察到以下事实：
- 89%的Type I样本具有`changeSRC`特征值为20；
- 74%的Type III样本具有`eval`特征值大于1000；
- 83%的Type IV样本具有`GetUserAgent`特征值大于2.5；
- 87%的Type V样本具有`referenceError`特征值大于5000。

#### 对有效性的威胁
首先，训练集来自三个来源：VXHeaven、OpenMalware和Web Inspector。因此，收集的样本直接影响训练分类器的准确性。为解决此问题，我们需要进一步研究样本大小和代表性对结果的影响。其次，机器学习分类器的参数和设置均为默认值。应进一步研究这些参数的效果。最后，动态攻击确认依赖于专家知识来完善学习的DFA。所学DFA的合理性会影响攻击确认的准确性——检查样本的跟踪是否被某种攻击类型的DFA接受。

### 相关工作
近年来，JavaScript恶意软件检测引起了安全研究人员的兴趣，并提出了许多方法。现有的JavaScript恶意软件检测方法主要依赖于静态分析与机器学习技术或动态分析与行为异常检测。然而，除了单纯的检测之外，很少有研究专注于根据漏洞或攻击行为对恶意软件进行分类。

#### 机器学习方法
2009年，Likarish等人[27]采用了四个分类器（即NB、ADTree、SVM和RIPPER）来检测混淆的JavaScript恶意软件。他们的假设是，恶意软件利用混淆来隐藏漏洞并逃避检测。他们报告称，从混淆脚本的字符串中提取的特征可以通过机器学习分类器区分混淆（恶意）脚本和非混淆（良性）脚本。Likarish等人承认，由于混淆但良性的脚本导致了假阳性率，这对假设构成了威胁。然而，在我们的研究中，我们不仅使用了混淆相关的特征，还使用了其他程序信息特征，从而降低了混淆但良性脚本导致的假阳性率。

2010年，JSand（JavaScript Anomaly-based aNalysis and Detection）[17]提出了一种检测Drive-by Downloads (DbD)攻击的方法。JSand识别出驱动下载攻击的10个特征，并使用这些特征通过机器学习技术（NB）检测恶意样本。这10个特征是从四个方面（重定向、去混淆、环境上下文和利用）通过动态异常检测和HtmlUnit仿真提取的。与我们的工作不同，JSand采用动态分析，未能研究不同分类器的影响。尽管动态异常分析有效，但效率不高——JSand扫描包含531个URL的Wepawet-bad数据集需要2小时22分钟。

同样在2010年，Cujo[33]使用混合分析实时捕获JavaScript程序的程序信息（通过静态分析）和执行跟踪（通过动态分析）。作者探讨了堆喷射攻击和混淆攻击的独特特征。但他们未能检查混淆但良性脚本的特征，也忽略了根据漏洞或攻击行为进行分类的研究。需要注意的是，Cujo需要执行每个脚本来捕获动态特征，而我们的方法仅对灰色区域的脚本进行动态确认。Cujo平均需要500毫秒来分析一个网页，而JSDC每脚本检测时间约为80毫秒，包括70毫秒的特征提取和10毫秒的分类。

2011年，Canali等人[14]提出了一种名为Prophiler的过滤器，以快速过滤掉良性页面，并仅将高度可疑的页面传递给成本高昂的分析工具。过滤器的检测模型基于从页面HTML内容、相关JavaScript代码和相应URL中提取的70个特征学习得到。然后，使用多个分类器（Bayes Net(BN)、J48、Logistic、RT和RF）来分类恶意和良性网页。对于JavaScript，这些分类器的假阳性率较好，范围从0.0%到1.7%，但假阴性率从18.1%到81%，比我们的方法更差。

同年，AST被用于提取恶意JavaScript检测的特征[18]。Curtsinger等人[18]提出了Zozzle工具，该工具通过利用与AST上下文信息相关的特征来预测JavaScript的良性或恶意。从AST的层次结构和文本中提取约一千至两千个特征，然后应用NB分类器。为了消除混淆带来的噪声，Zozzle使用Detours二进制插桩获取最终解包的代码以生成准确的AST。经过不同的设置调整后，作者报告假阳性率范围从0.0003%到4.5%，假阴性率从1.26%到11.08%。

综上所述，现有研究均未探讨有效特征以将JavaScript恶意软件分类为各种攻击类型。此外，我们提出对分类中的灰色区域进行动态确认。通过这种方法，我们可以提高整体准确性并实现可扩展性。

#### 其他检测技术
针对不同攻击类型的专门化JavaScript恶意软件检测方法已有很多。

**混淆恶意软件攻击**：文献[16]处理了网页中危险函数（如`eval`、`document.write`等）的参数，以获得三类度量数据，即N-gram、熵和单词大小。将这些度量数据与从经验研究中学习到的阈值进行比较，以判断相应网页的恶意性。最近，JStill[38]基于JavaScript在执行恶意意图之前必须先去混淆，而去混淆过程不可避免地会调用某些函数这一观察，检测混淆攻击。

**策略违规攻击**：早在2005年，Hellaraker等人[24]通过监控JavaScript执行并将其执行跟踪与高级安全策略（如同源策略和签名脚本策略）进行对比，检测恶意攻击行为。

**堆喷射攻击**：2009年，Egele等人[20]通过检查堆中的shell-code字符串实例化来检测堆喷射攻击，特别是检查字符串是否包含可执行的x86代码。类似的想法也在Nozzle[32]中被采用，该工具单独检查堆中的所有对象，将对象内容解释为代码并对其进行静态分析以发现漏洞。

**携带JavaScript的PDF文档**：Tzermias等人[36]提出了MDScan，它通过Firefox SpiderMonkey进行仪器化，扫描所有分配的字符串对象，并使用shellcode检测器Nemu[31]检测可能的漏洞。MDScan未能完全解决这个问题，因为它只搜索合法的JavaScript包含（由/JS标记表示），而攻击者可以通过将脚本编码为文本并在运行时评估（例如通过`eval`）来绕过这一点。

**JavaScript蠕虫**：Spectator[28]工具在发现异常长的传播链时检测蠕虫。该工具通过Web代理监控cookie会话和传播链来识别蠕虫复制。PathCutter[15]采用在不同隔离且受信任的网页组件中单独运行脚本的想法，通过授予脚本仅执行合法操作的权限来防止蠕虫传播。

### 结论
保护用户免受攻击的关键在于严格清除互联网上的恶意软件。为此，我们提出了一种方法，通过向分析师或终端用户提供潜在的恶意软件及其攻击类型建议，加速手动恶意软件检测过程。我们的方法不仅学习了恶意性特征，还学习了攻击类型特征。因此，通过动态攻击确认，我们不仅可以检测到恶意软件的存在，还可以提供带有攻击方式信息的恶意行为。我们还通过实际预测展示了我们的有效性和高效性。在超过1,400,000个脚本中，我们发现了超过1,500个具有8种攻击类型的恶意软件。我们的检测速度可扩展，每个脚本低于80毫秒。结合机器学习分类器和动态攻击确认，每个恶意软件的攻击类型分类大约需要1秒。

### 致谢
本研究得到了“云形式验证”项目（资助号：M4081155.020）和“二进制代码漏洞检测”项目（资助号：M4061366.680）的支持。

### 参考文献
[略]

---

以上是对原文的优化，使其更加清晰、连贯和专业。希望对你有所帮助！