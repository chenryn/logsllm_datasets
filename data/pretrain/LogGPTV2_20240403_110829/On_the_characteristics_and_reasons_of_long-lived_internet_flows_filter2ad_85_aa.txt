# On the Characteristics and Reasons of Long-lived Internet Flows

## Authors
- Lin Quan
- John S. Heidemann

### Affiliations
**USC/Information Sciences Institute**  
4676 Admiralty Way, Suite 1001  
Marina del Rey, CA 90292  
Email: [PI:EMAIL]

## Abstract
Previous studies of Internet traffic have analyzed data at various resolutions and time scales, including packets and flows over hours or days, aggregate packet statistics for days or weeks, and hourly trends for months. However, little is known about the long-term behavior of individual flows. In this paper, we study individual flows (defined by the 5-tuple of protocol, source and destination IP addresses, and ports) over days and weeks. While most flows are short, approximately 20% of the total bytes are carried in flows lasting longer than 10 minutes, and 2% of the traffic is in flows lasting 100 minutes or more. We show that long-lived flows are qualitatively different from short flows: they are generally slower, less bursty, and associated with different applications and protocols. We investigate the causes of short- and long-lived flows, and find that the traffic mix varies significantly depending on the duration time scale, with computer-to-computer traffic becoming more dominant at larger time scales.

## Categories and Subject Descriptors
- **C.2.3 [Computer-Communication Networks]: Network Operations—Network Monitoring**
- **C.2.5 [Computer-Communication Networks]: Local and Wide-Area Networks—Internet**
- **C.2.6 [Computer-Communication Networks]: Internetworking**

## General Terms
- Measurement

## Acknowledgments
Lin Quan and John Heidemann are partially supported by the US DHS (contract number NBCHC080035) and the NSF (grant number CNS-0626696). The conclusions of this work are those of the authors and do not necessarily reflect the views of DHS or NSF.

## Permissions
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

IMC’10, November 1–3, 2010, Melbourne, Australia.  
Copyright 2010 ACM 978-1-4503-0057-5/10/11 ...$10.00.

## Keywords
- Long Duration Flow
- Computer-to-Computer Communication

## 1. Introduction
Internet traffic is a complex mix of effects from protocols, routing, traffic engineering, and user behaviors. Understanding traffic is essential for modeling and simulation, traffic engineering and planning, router design, and a better understanding of the Internet. There has been extensive research on traffic at the protocol level and at time scales of seconds to hours, as well as over longer terms for planning. However, there has been little attempt to bridge these divisions and understand the protocol effects on long-lived traffic.

This paper explores how users and protocols affect long-lived network traffic. Unlike previous protocol studies, we examine traffic that lasts for multiple hours to days. Unlike previous long-term traffic studies, we explore the causes of traffic patterns at the flow level across multiple time scales, rather than just trends of aggregate traffic. We use the standard flow definition of the 5-tuple of source and destination IP address and port, plus the protocol number, ended by a timeout.

Understanding long-lived flows is increasingly important for several reasons:
1. **Network Management**: While capacity planning can be done using measures of aggregate traffic, several kinds of online traffic control, such as protocol trunking, optical trunking, lambda switching, and low-buffer operation, require flow-level traffic characterization.
2. **Scientific Understanding**: A scientific understanding of the Internet must investigate the patterns and causes of long-lived traffic. What are the first-order statistical properties of long-lived flows, and how do they differ from short ones? Short-term studies of network packet data have shown self-similar behavior in time scales of seconds to hours, but most such analysis stops as diurnal effects dominate.
3. **Long-Term Traffic Causes**: Protocol effects dominate sub-second time scales, and human behavior governs diurnal and weekend effects. Some human-centric traffic, such as "patient" peer-to-peer file sharing and unattended streaming media, is no longer bound by human patience. Computer-to-computer traffic is growing due to automated control and sensing, online backup, and distributed processing in the cloud and across distributed data centers. We hypothesize that at some point in the future, computer-to-computer traffic will eclipse human-driven traffic, just as data traffic has eclipsed voice.

The contribution of this paper is to begin answering these questions. We describe new mechanisms for multi-time-scale flow analysis that allow efficient evaluation of network traffic from time scales of minutes to weeks. We have operated this system for more than six months, collecting data from a regional network. We document the presence of long-lived flows, showing that 21% of Internet traffic (by bytes) is carried by flows longer than 10 minutes, and nearly 2% is carried by flows lasting 100 minutes or more. Finally, we begin to evaluate the causes of such traffic, exploring how the protocol mix changes as a function of time scale.

## 2. Related Work
An important aspect of understanding Internet traffic is the distribution of packet sizes and protocols. Thompson et al. studied the packet size distribution and protocol mixes in one-day periods and diurnal patterns of aggregate traffic over seven-day periods. CAIDA has collected 90-second traces each day over ten months, studying trends in packet lengths and protocol mixes. We use the common 5-tuple flow definition but are more interested in flow characteristics and traffic mixes across different time scales.

Characteristics of Internet flows have also been extensively studied. Brownlee et al. found that at least 45% of streams last less than 2 seconds, 98% last less than 15 minutes, and the remaining 2% are long-lived. Similarly, we find that most Internet bytes are carried by the vast majority of short flows, but long flows also account for a considerable fraction of bytes. Later work systematically studied flow characteristics, showing correlations between flow size, duration, rate, and burstiness. We adopt similar ideas but compare flow behavior as a function of duration.

Due to the large volume of traffic, careful sampling techniques have been used to achieve better processing rates. Researchers from AT&T estimated flow statistics by sampling packet streams and exploiting protocol details. Researchers at UCSD used adaptive sampling algorithms to increase Cisco NetFlow system robustness without compromising accuracy. Zhang et al. studied the distributions and causes of different flow rates, collecting sampled traces from a backbone ISP and unsampled traces ranging from 30 to 120 minutes. They also studied correlations between flow rates with size and duration, providing a detailed analysis of the causes of different flow rates. Our work builds on theirs: we continuously collect unsampled IP packet headers and systematically study the relations between flow durations and other characteristics. We also provide the ability to investigate multi-time-scale flows for efficient analysis and give preliminary analysis of the causes of long-lived flows.

Several groups have exploited flow characteristics for traffic engineering purposes. Shaikh et al. studied load-sensitive routing, adopting a conservative definition of long flows. We study several longer time scales and find interesting implications of long flows. Trunking (with TCP or optical networks) gathers groups of flows to achieve throughput benefits. Our work identifies long-duration flows that could be used by trunking. Recent work in low-buffer routing has shown the possibility of using very few router buffers, provided that traffic is "sufficiently" smooth. We show that long-duration flows are smoother and could be good candidates for such optimization.

## 3. Data Collection and Analysis
Network packet trace collection is well understood, but sequential processing becomes challenging as datasets stretch from minutes to months. In this section, we review our approach to long-term collection of network flows and multi-time-scale analysis of that data.

### 3.1 Collection and Anonymization
Our campus network operators provide us with anonymized packet headers at the main USC connection to our upstream regional network. We use the LANDER system to process data at USC’s HPCC compute cluster, coordinating parallel processing of 512MB fixed-length, Endace ERF-format, packet-header traces.

The default LANDER policy anonymizes traffic with keys that rotate at regular intervals, ensuring that any accidental information disclosure in one period does not assist unanonymization in other periods. However, key rotation impedes analysis of flows longer than the rotation period. Therefore, LANDER re-anonymizes all flows with a common, long-term key. We reduce this greater risk through stricter policy controls: we control access to the long-term data and prohibit those with access from attempting unanonymization.

Although our work builds on packet-header traces, a potential direction for the future is to start with NetFlow records as a data source. Another interesting direction is to compare characteristics of long flows at different places in the Internet.

### 3.2 Multi-time-scale IP Flow Analysis
Given our goal of observing long-duration flows, we face four problems: defining what flows are and what to record for each flow; managing streaming data and incremental analysis; supporting analysis at very different time scales, from seconds to weeks or more. We consider each of these next.

We use the standard 5-tuple definition of flows: source and destination port and IP address, plus protocol. We convert LANDER’s packet headers into flow records using a slightly modified Argus toolkit. Argus flow records provide the 5-tuple flow identifier, flow start and finish times, number of packets, and number of bytes in the flow. Flows begin with the first packet with a unique 5-tuple and continue until a timeout (currently set to 60 seconds).

We extend Argus to capture information about flow burstiness, defined as the variance of bytes over a fixed time period T. We record the number of time periods observed, and the average and square sum of bytes over the time periods. Our base time period for variance is T = 10 minutes, the same as our base segment length. This data allows us to compute the standard deviation of bytes over T afterward.

Because we expect to run data collection indefinitely, it is essential that we collect data concurrently with analysis and store data in a manner that supports efficient queries. An easy algorithm would use an in-memory flow table (indexed by the 5-tuple) and update corresponding flow records upon seeing a flow. However, this algorithm can easily run out of memory due to a large number of concurrent flows, particularly with long timeouts. So, we divide flow records into segments for efficient analysis. LANDER uses fixed-size segments (each 512MB of packet headers, or 1–2 minutes at our current capture rates), and these traces arrive asynchronously, invoking our segment processing engine as they arrive.

We convert these variable-duration segments to hierarchical, fixed-duration segments to support efficient analysis and queries that span different timescales. We call the initial fixed-duration segments level-0 flow segments, currently each at a duration of T = 10 minutes. When we determine that all packet-header traces needed to cover a flow segment are present, we process them to create the corresponding level-0 flow-segment. Care must be taken because each flow segment typically requires several packet-header traces, and the packet-header trace at the start or end of a flow segment typically spans two flow segments. When a trace spans multiple segments, we place the packets corresponding to each segment in separate flow records in each segment. These records will later be merged into a common flow record in hierarchical merging described next.

To avoid segments growing in size indefinitely and to allow efficient queries at large timescales, we prune the flow contents at each level according to the following rule:

- **Pruning Rule**: A level-i segment starting at time t must preserve all flows of duration longer than T * 2^(i-2) (the duration rule) and all flows that are active in the timeout period (the last τ seconds of the trace) (the tail rule).
- **Presence Corollary**: A level-i segment starting at time t guarantees to contain all flows of durations between T * 2^(i-2) and T * 2^(i-1) that start in the time [t, t + T * 2^(i-1)]. It may also contain some shorter flows at the end and some longer flows (up to T * 2^i) which are not complete yet.

The duration part of the pruning rule keeps each level file small, as each targets a specific time duration and guarantees coverage for that duration. All short flows that are not active at the end of the segment may be discarded. We can prove the presence corollary because we guarantee coverage for flows that start in the first half of the segment and last for between a quarter and a half of the segment, as by definition, those flows must terminate in the segment and are too long to be discarded. We do not guarantee all shorter flows are present, as they will be discarded to keep segment sizes manageable. We cannot guarantee that longer flows are complete, as they may stretch into subsequent segments.

The tail part of the pruning rule allows adjacent segments to be merged without loss of information. Only flows that are active in the last τ seconds of the segment are candidates to merge with the next segment, as by our definition of flows, they will timeout if the gap is longer. By keeping all flows active in this window at the end of the trace, we guarantee no information about mergeable flows will be discarded, so we do not accidentally truncate the head of a new long-duration flow. Finally, the rule keeps flows that are active in the last τ seconds, more than flows started in the last τ seconds—a flow may start anywhere in the segment, and long-running flows will typically span most or all of the segments.

Several details in segment organization support merging and processing. When merging two adjacent level-i segments to create a level-i + 1 segment, we combine and reorder flow records. We keep flow records sorted by flow start time, so if the level-i files are numbered n and n + 1, the merge must scan all of file n but only the head of n + 1. Variance can be combined across segments because we preserve the sum of observations and their squares, not just the computed variance.

Figure 1: The structure of multi-level flow records: each level has primarily flows with exponentially longer durations, plus a "tail" to permit merging.

## 4. Results
### 4.1 Presence of Long-Lived Flows
We document the presence of long-lived flows, showing that 21% of Internet traffic (by bytes) is carried by flows longer than 10 minutes, and nearly 2% is carried by flows lasting 100 minutes or more.

### 4.2 Causes of Long-Lived Flows
We begin to evaluate the causes of such traffic, exploring how the protocol mix changes as a function of time scale.