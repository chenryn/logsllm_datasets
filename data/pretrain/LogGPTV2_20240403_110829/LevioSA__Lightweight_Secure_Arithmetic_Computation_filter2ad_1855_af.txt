5.2 Main Application: Arithmetic 2PC with
Active Security
Our main result provides a concretely efficient two-party protocol
for arbitrary arithmetic computations with active security against
static corruptions. Given an arbitrary instantiation of a passive OLE
protocol, we describe two instantiations:
• For “large and wide” arithmetic computations (in the sense
explained in Section 5.1), we design a protocol that makes 4
amortized black-box invocations of a passive OLE protocol
per multiplication gate in the computation.
• For arbitrary arithmetic computations, we design a protocol
that makes 16 amortized black-box invocations of a passive
OLE per multiplication gate in the computation.
Variant 1: In our first variant we consider arithmetic circuits over
an arbitrary field F for which we can pick a large value w such that
each layer has a multiple of w gates (or is a few gates short of such
a multiple). In these cases, the combined protocol of figure 9 can
be directly instantiated with the appropriate w and the parameters
from table 2.
Common examples of wide computations include basic vec-
tor/matrix operations. Another concrete use case is when the same
circuit is evaluated on several inputs in parallel, eg ML classification
or nearest-neighbor database search of many inputs [17] and [3].
Arguably, most circuits that arise in real-life MPC applications are
wide and shallow. Indeed, authenticated triples generation serves
as a good example for a wide circuit.
Variant 2: In our second variant we will rely on the work of Döt-
tling et al. [15] to yield a secure two-party protocol for general
arithmetic circuits, which, in particular can have arbitrary few gates
per layer. In more detail, this work shows how to reduce the design
of secure arithmetic computation to realizing an input-independent
offline arithmetic functionality. This functionality described in Fig-
ure 4 essentially generates “authenticated” triples which are pro-
vided to the parties. We can instantiate their protocol by securely
realizing the offline functionality using our first variant. Note that
these authenticated triples can be computed using a wide circuit,
where the width is proportional to the number of triples required
in the computation of the original circuit, which equals the number
Session 2C: Secure Computing ICCS ’19, November 11–15, 2019, London, United Kingdom338of multiplication gates in such a circuit. This offline functionality
requires 4 multiplications to be performed per triple. Furthermore,
our first variant implies 4 passive OLE per multiplication for wide
circuits. Hence, we obtain a protocol that consumes 16 passive OLE
per multiplication gate.
5.3 Black-Box Active OLE from Passive OLE
Our second application is a concretely efficient protocol for achiev-
ing OLE with active security from active OT and passive OLE in a
black-box way, where the overhead is roughly 2 passive OLE. This
is obtained by instantiating our compiler with the batch (or parallel)
OLE functionality as described in Figure 6. This overhead can be
achieved by instantiating our compiler with parameters specified
in Table 2.
We remark that, in general, our compiler invokes 2 calls to the
passive OLE protocol per server per multiplication gate in the cir-
cuit. In order to realize w parallel invocations of the active OLE
functionality naively, this would result in 2 · n calls to the passive
OLE protocol, i.e. an amortized overhead of 2 · n/w. We now de-
scribe a simple optimization that can reduce this by a half to get
an overhead of only n/w. Our optimization exploits the fact that
all the multiplications computed within the OLE functionality are
performed in the first layer, where the left input wires and the right
input wires are respectively split between the parties. Therefore,
the input sharing phase can be avoided. This implies that we need
only one passive OLE call per server per multiplication and thus
obtain an overhead of n/w calls which for large w results in roughly
2.
This protocol results in the following communication complexity.
+ 2 · σ · (t + e + w) · log2 |F|
OT
t−out−of−n
ρ
κ-bits OT
Our construction naturally extends to the setting when the under-
lying passive OLE protocol is batched. This scenario is particularly
interesting when instantiating our protocol with packed additively
homomorphic encryption schemes based on LWE that allow for
parallel passive OLE computations.
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
(cid:124)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:125)
+ n · CCρ
passive OLE
+ 3 · κ(cid:124)(cid:123)(cid:122)(cid:125)
degree test
coin-toss
5.4 Privacy-Preserving Secure Neural Network
Inference
We next describe a concrete use case of outsourcing arithmetic com-
putation in the two-server setting. Such a model has already been
considered by several works, focussing on machine learning com-
putations [43, 48], which are heavily arithmetic in nature, where
most previous works in this area only achieve passive security. In
more detail, we consider two clients: C0 and C1 with private inputs,
respectively x and y, that wish to securely outsource an arithmetic
computation F to two cloud servers s1 and s2. This can be done by
having the clients share their inputs with the servers that, upon
receiving the inputs’ shares, securely evaluate the function F and
return the result to the clients. We require that the protocol will be
secure against an active corruption of at most one server and one
client up to abort and employ our protocol from Section 4.2 for this
goal. In order to ensure the authentication of the inputs we employ
a simple MAC.
We begin with a slightly modified (randomized) functionality
F ′. Roughly speaking, F ′ takes as input MAC keys kx and ky and
MACs mx and my, in addition to the inputs x and y, and produces
as output (f (x, y), flag). The flag bit will be set to a random linear
combination of the values dx = mx − MACkx (x) and dy = my −
MACky(y). The actual functionality F computed by the servers
will essentially be F ′ with the exception that the inputs to F ′
are additively shared between the two servers. In other words, the
functionality takes the shares from the servers along with MACs
and MAC keys, reconstructs the inputs and evaluates F ′ on the
outcomes. In the actual realization, the servers employ the protocol
from Section 4.2 and return the results to the clients. If the flag bit
is zero the clients accept the output, and reject it otherwise.
To formally argue security, we observe that a corrupted server
can change the additive share received as input before entering the
computation. This can be captured as an additive input-independent
attack on the input of the protocol. We now have that if any cor-
rupted server manipulates its input, the probability that either dx
or dy is non-zero and the output flag bit is zero is at most 1
|F| by the
security of the MAC. Therefore, the clients will reject the output
with very high probability.
As a concrete instantiation of this framework, we implement
a secure neural network (NN) inference problem and consider a
neural network that is an arithmetic circuit friendly. Specifically,
following Ghodsi et al., [22], we consider the following neural net-
work repeated verbatim from their work. Without loss of generality,
a standard L layer neural network can be modeled as follows. The
input to the network is x ∈ Fn0×b where n0 is the dimension of
each input and b is the batch size. Layer i ∈ [1, L] has ni output
neurons, and is specified using a weight matrix wi−1 ∈ Fni×ni−1
and biases bi−1 ∈ Fni
of Layer i ∈ [1, L] is
defined by:
p . The output yi ∈ Fni×b
p
p
yi = σquad(wi−1 · yi−1 + bi−11T )
∀i ∈ [1, L − 1]; yL = σout(wL−1 · yL−1 + bL−11T )
where σquad(·) is the quadratic activation function, σout(·) is the
activation function of the output layer and 1 ∈ Fb
p is the vector of all
ones. The final output layer uses the softmax activation. We consider
a 3 layer NN with quadratic activation function. The performance
of such NN has been discussed in [22]. We provide benchmark for
this application in Section 7.
6 ACTIVE OLE FROM IMPERFECT OLE
In this section, we analyze the security of our compiler when applied
to an imperfect passive OLE, which may have a non-negligible
simulation error. This is particularly relevant to lattice-based OLE
constructions, for which setting the parameters more aggressively
can lead to better efficiency at the expense of such a simulation
error. We show that our compiler can indeed tolerate an imperfect
OLE in a natural “exclusion set” model described below.
We start by explaining why relevant techniques from the lit-
erature are insufficient for our purposes. One approach towards
amplifying the security of an imperfect OLE is to show that it per-
fectly realizes a simple leaky OLE functionality that reveals the
entire honest inputs to the adversary with small probability and
Session 2C: Secure Computing ICCS ’19, November 11–15, 2019, London, United Kingdom339otherwise leaks nothing. When this OLE is plugged into the IPS
compiler we can amplify it to full security by increasing the security
threshold t to be large enough to accommodate the leakage caused
by a few faulty OLE. To employ such an argument one would need a
strong “statistical-to-perfect” style lemma [16, 28, 45]. For example,
Ishai et al. [28] proved that any implementation of functionality F
with statistical error ϵ perfectly realizes a weakened functionality
F ϵ′ for ϵ′ = ϵ · |X| · |Y| where X and Y are the respective domain
and range of F , and where F ϵ′ is equal to F with probability 1−ϵ′
and reveals the inputs to the adversary with the probability ϵ′. For
OLE over small fields, the statistical-to-perfect lemma gives good
bounds. But for large fields, this lemma gives poor bounds that only
apply when the statistical error is smaller than the inverse of the
field size. In fact, as shown in [28] such a loss in a inherent for large
domains in the worst case.
We consider the case of employing OLE over random inputs
as this is what is needed for our compiler. Furthermore, we will
focus on the case of OLE that is (fully) computationally secure
against passive corruption of the sender and is ϵ-statistically secure
against passive corruption of the receiver on random inputs. This
will be sufficient to capture our OLE instantiations based on lattice
assumptions. We start by defining the notion of ϵ-secure OLE over
uniformly random inputs. Let Π = ⟨P0, P1⟩ denote a two-party
protocol, where each party is given an input (x for P0 and y for P1).
Denote by ViewPi(P0(x), P1(y)) the view of the party Pi in the real
execution of Π where x is P0’s initial input, y is P1’s initial input.
Definition 5 (ϵ-secure OLE). We say that a two party protocol
Π = (S, R) is an ϵ-secure implementation of an OLE over Fp w.r.t
the uniform distribution, if for every x ∈ Fp the statistical distance
between the following two distributions is bounded by ϵ:
• {(a, b, ViewR(S(a, b), R(x)))}
• {(a′, b′, ViewR(S(a, b), R(x)))}
over a, b sampled uniformly from Fp and a′, b′ sampled uniformly
from Fp subject to a′x + b′ = ax + b over Fp.
We conjecture that given an ϵ-secure OLE, our compiler from
Section 4.2 can compile it to a fully secure OLE. More formally:
Conjecture 1. Let Π be an ϵ-secure implementation of an OLE
over a field F of size p. Then, the protocol obtained by instantiating the
IPS compiler with the MPC protocol from Theorem 1, where the calls to
OLE are replaced with protocol Π and using parameters k, e, t, w and
σ such that k ≥ w +e +t, e < d/3, 2k +e < n, securely realizes F w
OLE in
the (FOT, FCOIN)-hybrid model, tolerating one active (static) corruption,
with security (d + 2)/|F|σ + (1 − e/n)t + p−k +1 · O((ϵ · p)n−t−e).
We leave the question of proving or disproving this conjecture
as an interesting open problem. In this work we provide evidence
supporting the conjecture by analyzing our compiler with an im-
perfect OLE that is an instance of an ϵ-secure OLE. We consider an
ideal OLE functionality that will ask the adversary to specify an
exclusion set A and will leak to the adversary one bit of informa-
tion on whether the honest party’s input belongs to the exclusion
set. For this model, we are able to prove that if the exclusion set
is relatively small compared to the field size, we can amplify the
security via the IPS compiler. On a high-level, we will argue that,
in the IPS compiler, even if the adversary learns all the shares in its
watchlist and a little bit of leakage (via exclusion sets) in each of the
remaining shares, the actual secret remains hidden. Recently, the
leakage-resilience of Shamir’s secret sharing scheme was studied
in the work of Benhamouda et al. [6] who gave some parameter
regimes under which the scheme is leakage resilient. However, their
results are not strong enough for our setting as they consider the
case where 2k ≥ n such that k is the degree of the Shamir shares.
We establish a new result on the leakage resilience of Shamir’s se-
cret sharing scheme that will allow us to argue security also when
2k < n. We remark that their work studied the leakage resilience
where m bits of information were leaked on every share, while
we will consider the exclusion-set model where less than one bit
of information is leaked on each share. Our approach extends the
analysis from [6] and sharpens the parameters. We remark that our
bounds still look pessimistic and leave room for improved analysis.
Our leakage model follows the one from [6], where the adversary
can first choose a subset Γ ⊆ [n] of the parties and obtain their
entire shares, and then leak partial information from all the shares
of the remaining parties. The information learned by the adversary
(Γ), s(i)))i∈[n]) where
is captured as follows: LeakΓ,τ = (s
(Γ) =
τ = (τ(1), τ(2), . . . , τ(n)) is a family of leakage predicates and s
(s(j))j∈Γ are the complete shares of the corrupted parties. We allow
the adversary to choose the functions τ arbitrarily. In the exclusion
set model, we restrict the functions in τ to be predicates and bound
the fraction of inputs on which the functions take the value 1. Next,
we recall (a simplified variant of) the definition of local leakage
resilient from [6].
(Γ),(τ(i)(s
Definition 6. Let Γ ⊆ [n]. A secret sharing scheme (Share, Rec)
is said to be (Γ, µ)-local leakage resilient if for every leakage function
family τ = (τ(1), τ(2), . . . , τ(n)) where τ(j) is a predicate for every j,
and for any pair of secretes s0, s1 we have that the statistical distance
between the following two distributions is at most µ:
• {s ← Share(s0) : LeakΓ,τ (s)}
• {s ← Share(s1) : LeakΓ,τ (s)}
We next prove Theorem 3 where we focus on the case where
the leakage functions are “exclusion-sets”. Namely, there exists an
ϵ such that the leakage functions are predicates τ and the fraction
of inputs on which τ returns 1 is bounded by ϵ.
Theorem 3. Let C = RSFp ,n,t ,η be an RS code. Let τ = (τ(1),
τ(2), . . . , τ(n)) be any family of leakage predicates such that for all j,
|{x ← Fp : τ(j)(x) = 1}| ≤ ϵ · p, and let cϵ =
sin(ϵ ·π)
p·sin(π/p) . Then,
SD(τ(C), τ(Un)) ≤ 1
2(p − 1)p
−t(1 + 2 · cϵ · p)n .
Proof: We follow the proof strategy of [6], which relies on the
Fourier analysis, and adapt it to our setting. We recall some basic