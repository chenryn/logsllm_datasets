title:"\emphYour hashed IP address: Ubuntu.": perspectives on transparency
tools for online advertising
author:Tobias Urban and
Martin Degeling and
Thorsten Holz and
Norbert Pohlmann
“Your Hashed IP Address: Ubuntu.”
Perspectives on Transparency Tools for Online Advertising
Tobias Urban
PI:EMAIL
Institute for Internet Security
Ruhr University Bochum
Thorsten Holz
PI:EMAIL
Ruhr University Bochum
ABSTRACT
Ad personalization has been criticized in the past for invading
privacy, lack of transparency, and improper controls offered to
users. Recently, companies started to provide web portals and other
means for users to access data collected about them. In this paper,
we study these new transparency tools from multiple perspectives
using a mixed-methods approach. Still practices of data sharing
barely changed until recently when new legislation required all
companies to grant individual access to personal data stored about
them. Using a mixed-methods approach we study the benefits of
the new rights for users. First, we analyze transparency tools pro-
vided by 22 companies and check whether they follow previous
recommendations for usability and user expectations. Based on
these insights, we conduct a survey with 490 participants to eval-
uate three common approaches to disclose data. To complement
this user-centric view, we shed light on the design decisions and
complexities of transparency in online advertising using an online
survey (n = 24) and in-person interviews (n = 8) with experts from
the industry. We find that newly created transparency tools present
a variety of information to users, from detailed technical logs to
high-level interest segment information. Our results indicate that
users do not (yet) know what to learn from the data and mistrust the
accuracy of the information shown to them. At the same time, new
transparency requirements pose several challenges to an industry
that excessively shares data that even they sometimes cannot relate
to an individual.
CCS CONCEPTS
• Security and privacy → Usability in security and privacy.
KEYWORDS
usability, privacy, transparency , online advertisement, GDPR, SAR
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7628-0/19/12...$15.00
https://doi.org/10.1145/3359789.3359798
Martin Degeling
PI:EMAIL
Ruhr University Bochum
Norbert Pohlmann
PI:EMAIL
Institute for Internet Security
ACM Reference Format:
Tobias Urban, Martin Degeling, Thorsten Holz, and Norbert Pohlmann. 2019.
“Your Hashed IP Address: Ubuntu.” Perspectives on Transparency Tools for
Online Advertising. In 2019 Annual Computer Security Applications Confer-
ence (ACSAC ’19), December 9–13, 2019, San Juan, PR, USA. ACM, New York,
NY, USA, 16 pages. https://doi.org/10.1145/3359789.3359798
1 INTRODUCTION
Advertisements are an essential part of modern online services’ busi-
ness models. A multi-billion dollar industry has evolved around
the placement of ad banners and videos that target potential cus-
tomers [28, 29]. Successful ad campaigns are expected to reach an
audience that is likely to be interested in the advertised product and
part of a target group defined by multiple attributes like location,
age, or interests. To achieve this, ad companies build behavioral
user profiles which often include data like their assumed interests
in products and demographic information as well as clickstream
data of websites the users have been tracked on. This personal data
is collected or inferred by the ad companies (mostly) without the
users’ explicit consent or knowledge about these mechanisms [13].
Previous studies have measured users’ discomfort with ad person-
alization [36, 51] and highlighted the importance of transparency
as a critical factor [18]. Therefore, scholars have argued that trans-
parency is critical to counter the knowledge imbalance between
tracking services and individuals that increments the discomfort [26].
To counter these problems an increasing number of ad-tech
companies offer ways to access such data via web portals (e. g., Trip-
pleLift’s approach [50]) or offer to answer data access requests
via email. Through these means, users can gain insights into the
data collected about them (e. g., sites they were tracked on) or
information inferred from such data. The industry’s increase in
transparency is likely fostered by new regulation introduced to ac-
count for the users’ demand to more transparency [25]. The General
Data Protection Regulation (GDPR) [47] and the upcoming Califor-
nia Consumer Privacy Act (CCPA) [46] include the right of each
user to request access to the data a company has collected about
them (Right to Access, Article 15 GDPR).
Prior work on ad transparency only analyzed a small number of
services offered by Facebook or Google, pioneers in this area [5]. The
ongoing trend towards more transparency massively extends the
number of services that have to disclose information and provide
access to user data. In this paper, we present a study on the extent of
702new transparency mechanisms and provides insights into how users
and companies struggle with new opportunities and regulations.
In a system as complex as online advertising with multiple ac-
tors sharing and building upon tracking data, there are multiple
challenges to effective transparency [35, 40, 57]. First, those collect-
ing the data must be aware of what and whose data they directly
or indirectly collect through third parties. Second, transparency
is not an end in itself, so when personal data is provided to data
subjects, it has to be contextualized and presented in a way that
conveys the essential facts but does not overwhelm the user. We
study aspects of both challenges by evaluating the current state of
transparency tools and the data provided to users when they request
access. While we first focus on the views and needs of users, we also
try to understand the challenges companies face when providing
transparency. In short, we make the following three contributions:
• We analyze 22 transparency tools of online advertising com-
panies regarding their compliance with users’ expectations,
legal norms, and similar aspects. We find that only three of
the tools meet the requirements described in previous work.
• To gain further insights, we conduct an online user study
(n = 490) to better understand user needs when it comes to
transparency in the online advertising ecosystem. We found
that—if not explicitly stated—users often do not know who
collects their data. Furthermore, users struggle to understand
the data provided to them.
• Finally, we investigate the perspective of online advertising
companies in an online survey (n = 24) and in-person in-
terviews (n = 8). They acknowledge problems with existing
approaches, some inherent to an ecosystem that is not fully
aware of the data flows within.
In summary, our analysis shows that transparency tools do not
offer much help to users, yet. It is hard to identify whom some-
one has to ask for access and often the data is hard to interpret.
Participants are not able to draw conclusions. This is reflected in
the low number of requests that are reported by industry experts.
Going forward tools need to be developed that help users better
understand what data is used for what purposes, while at the same
time the industry has to find adequate means to communicate what
data they are collecting (sometimes it seems that have to learn that
for themselves first).
2 BACKGROUND
Many digital services such as websites or mobile apps rely on rev-
enue from displaying ads to their customers. In 2017, the online ad
industry generated an estimated revenue of over e 41.8 billion [29]
in Europe and $88.0 billion US dollars in the US [28].
Online Behavioral Advertising (OBA). OBA is a technique to tailor
ads to individuals based on their online behavior, on their click-
stream [9], or other personal data like IP addresses. To perform
ad personalization, companies need to collect data, often by track-
ing users across the web or utilizing a service that does that, and
therefore user tracking has become an essential part of the business
model of web services [45]. Unique identifiers are assigned to each
user, either generated by the ad company or computed based on
properties of the users’ device (so-called device fingerprinting) [20].
In the mobile world, unique advertising identifiers are used to iden-
tify users. These identifiers are often provided by the operating
system of the phone and are only accessible from apps installed on
the phone but not from web pages [56]. Similar to cookie deletion
and opt-out mechanisms in web browsers, users can choose to reset
these IDs or turn them off altogether, preventing companies from
recognizing them [32].
Available ad space is sold on real-time bidding (RTB) platforms
whenever a user visits a website. Different entities are involved in
the RTB process, but the general flow of information, as described
by Yuan et al. [58], is as follows: When a user visits a website, the
site provides the available ad space (formally called inventory or
impressions) to an ad exchange service which starts auctions for
the available impressions on the site. Websites often use a service
(so-called supply-side platforms) to provide the inventory. Now,
several demand-side platforms, who help to manage ad campaigns,
place bids on the ad space depending on their estimated value of
the impression. These bids are placed on behalf of the advertisers
(e. g., brands) who want to place ads. The highest bid wins the
impression, ensuring that the ad selling price is maximized.
Legal Background. In 2016, the European Union (EU) harmonized
data protection laws of its member states by introducing the Gen-
eral Data Protection Regulation (GDPR or Regulation 2016/679) [47],
which went into effect on May 25, 2018. Among other legal obliga-
tions, the GDPR specifies under which circumstances the personal
data of EU citizens may be processed and defines the obligations of
companies processing the data. Similarly, the California Consumer
Privacy Act (CCPA) of 2018 [46] aims to strengthen privacy rights
of California residents. The CCPA is planned to go into effect on
January 01, 2020.
Article 15 GDPR describes an individual’s right to access. The
right to access describes which information data controllers have to
provide to users upon request. This includes information typically
found in a privacy policy like the categories of personal data pro-
cessed, the purpose of processing, or the right to file a complaint
with data protection authorities. In addition, Article 15 grants users
the right to access their personal data (“The data subject shall have
the right to obtain [...] access to the personal data [...]”). Article 20
GDPR extends the access right to the right to data portability, mean-
ing that an individual may not only review data stored about them
but can also request a copy of the collected personal data. Similar
to the GDPR, the CCPA requires that starting in 2020 “a business
that receives a verifiable consumer request from a consumer to ac-
cess personal information shall promptly take steps to disclose and
deliver, free of charge to the consumer [...]”. Requests to data access
are referred to as subject access requests (SAR).
3 ANALYSIS OF TRANSPARENCY TOOLS
Some ad-tech companies implemented ways to give individuals ac-
cess to data stored about them to account for growing user demand.
Most notable, Google and Facebook developed privacy dashboards
or transparency portals after their data collection practices had
come under public scrutiny [5]. Other businesses have also set up
information sites or web forms individuals can use to request their
data. Recently, the number of available tools has grown to account
for regulatory obligations of the GDPR and CCPA that require
703companies to give individuals access to collected personal data.
Several examples of data such tools provide to users are shown in
Figures 3, 4, and 5 in Appendix A.
Companies to Analyze. Previous work has shown how difficult it
can be to get access to data and that requests not always success-
ful [52]. To avoid overhead of tedious and possibly unsuccessful
access requests, we looked at all members of large online adver-
tising alliances (i. e., the Network Advertising Initiative (NAI), the
Interactive Advertising Bureau (IAB), and the Digital Advertising
Alliance (DAA)) and checked which company offered an online tool
to access personal data. If a company offered an online tool, we
analyzed it in our study.
According to public statements of these alliances, they represent
over 5,500 companies. However, they have only 500–600 (distinct)
members listed on the organizations’ websites which we all manu-
ally reviewed. We analyzed all online tools we found and asked for
access to our personal data with companies that do not provide an
online tool but did reportedly grant access in an easy way. In total,
we analyzed 22 web portals (15) and responses (7) to our subject
access requests. These companies include ad-tech industry giants
(e. g., Google and Facebook) and medium size companies (e. g., So-
jern and MediaMath). We differentiate between two types of how
users can access their personal data: online and offline. By online
we mean that users can visit a website which (automatically) reads
the user’s cookie store and shows personal data associated with
the read identifier. If the data is provided in a file format (e. g., .csv
or .pdf files), we labeled it offline. Using a VPN service (US–VA),
we also verified that all online tools are also available to US-based
IP addresses.
3.1 Criteria Definition
We evaluated the transparency tools based on heuristics from mul-
tiple sources: (1) user expectations elicited in previous studies, (2)
descriptive information found in the privacy policies, and (3) self-
regulative norms proposed by industry groups. In the following,
we describe all criteria we used to analyze the transparency tools
of the 22 companies in detail.
User Expectations. Previous work has shown that users have
different—mostly negative—views on online behavioral advertis-
ing (OBA) but also demonstrate a need for transparency in OBA.
In the following, we describe criteria found by previous work to
be most important to users when it comes to transparency and
understanding of OBA.
Interest segments/Demographics: Dolin et al. found that users
are more comfortable with OBA if they are aware of the connec-
tion between the created profile and their interests [18] (criterion
C1). They also found that users’ comfort with personalized ads is
(positively) correlated with the perceived sensitivity of the data
category (e. g., health-related information is seen as critical). One
approach to increase users’ comfort could be to show the segment
data assigned to the user by a company, although previous work
has shown that these profiles tend to be inaccurate [5, 42]. Besides
assumed interests, OBA is often based on (inferred) demographic
information (e. g., ethnicity, age, location, or salary). Discrimina-
tion based on this demographic information is a big concern [41]
(criterion C2). Displaying interest segments or demographic data to
users can help them understand how companies use the collected
data and why they see specific ads.
Tracking and Clickstream Data: Ur et al. found that users’
views on online tracking can range from “useful” to “scary” [51],
and other work highlights the dislike of ads based on clickstream
data [37]. Therefore, when companies disclose on what websites
they have tracked users, it can be helpful to understand why certain
ads are displayed, e. g., in cases of re-targeting where ads are based
on products a user has previously viewed online. As shown in
Figure 5 (App. A), clickstream data is made accessible in varying
granularity ranging from raw data that includes user-agent and
other technical information to lists of timestamps and websites
recorded.
The willingness of users to share data with advertisers was an-
alyzed by Chiasson et al. [11] (criterion C3). They found different
factors that influence the willingness to share and show that users
have complex privacy needs which are not accounted for by cur-
rent tools. Our work differs from the named approaches as we
measure the transparency needs of users concerning OBA instead
of analyzing their attitude towards different aspects of OBA.
To summarize, previous work found three criteria users expect
to find when evaluating personal data an ad company collected:
(1) interest segment data [18], (2) demographic data [41], and (3)
tracking data [11]. We inspected the data provided by the tools of
the 22 companies and checked if the data can be grouped into any
of these groups and did also check if the privacy policy did state if
such data was collected/inferred.
Privacy Policies. The content of privacy policies should be helpful
to users who want to learn more about the privacy practices of