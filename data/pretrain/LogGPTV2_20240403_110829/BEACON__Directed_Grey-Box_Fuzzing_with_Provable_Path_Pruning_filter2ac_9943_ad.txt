stractions of w. We deﬁne the problem of minimizing precision
loss in join as ﬁnding the smallest intersection area among
different polygon search spaces described by each abstraction.
Conventionally, the intersections of two abstract domains can
Figure 7: Precision loss of joining different disjunctive path
conditions for backward precondition inference.
be measured by the Fr´echet distance [41]. Speciﬁcally for our
interval domain, we only need to calculate the precision loss by
accumulating the distance from the interval of each variable.
Thus, the intersection can be measured by the distance of two
intervals, which is deﬁned as:
L “
minpmaxp0, u1 ´ l2q, maxp0, u2 ´ l1qq
ÿ
vPφ1Xφ2
where v is a shared variable of the path conditions φ1 and φ2,
whose interval abstractions are vφ1=rl1, u1s and vφ2=rl2, u2s.
As an example, In Algorithm 2, suppose the program loca-
tion l already has two paths reaching it and ˆwpplq “ tB, Cu
records their propagated conditions, and a new condition with
interval abstraction A now reaches l:
A: x P p´8, 20q ^ y P p20, 50q
B: x P p30, 50q ^ y P p60, 70q
C: x P p90, 140q ^ y P p100,`8q ^ z P p200,`8q
With threshold “ 2, A needs to be joined with either B or C
to restrict the numebr of paths. we can measure the precision
loss induced by joining as distance L: LpA, Bq=10+10=20,
and LpA, Cq=70+50=120. We choose to join A, B since it
suffers from the minimum precision loss, and the joined
abstraction used for further propagation is:
x P p´8, 50q ^ y P p20, 70q
D. Precondition Instrumentation
We instrument the program using the inferred necessary
precondition to prune infeasible paths at runtime. Notice that
the elaborative analysis result may put a heavy burden on
instrumentation and increase the runtime overhead of fuzzing:
it contains a map from variable to its disjunctive interval values
at various program locations. Therefore, we need to perform
the instrumentation selectively to reduce the overhead.
We observe that it is unnecessary to instrument and check
the values of all variables. Also, it is unnecessary to check
for one variable at various program locations. For instance,
in Figure 2, instrumentation is added for u (Line 7) but not
v, since the value of u determines the value of v. Also, we
place the instrumentation for variables w, x, y, z right after
their deﬁnitions in Line 4, instead of checking them at every
program location that uses these variables since their values
do not change after deﬁnition. Based on these observations,
we apply the lightweight instrumentation as following:
43
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:18 UTC from IEEE Xplore.  Restrictions apply. 
3050{Precision	Lossw3050No	precision	lossw-20	<	w	<	30	or	50	<	w	<	100-201000800	<	w	<	50	or	30	<	w	<	80ABAB1) We ﬁrst
transform the program into SSA form [42],
and only consider variable deﬁnitions as the candidate
program locations for instrumentation. This is correct
because the SSA form guarantees that a variable is not
written after being deﬁned.
2) When the value of a variable v1 depends only on another
variable v2, v1 should not be instrumented. Such infor-
mation can be computed by the reaching deﬁnition data
ﬂow analysis [43]. As an example, in Figure 2, v depends
only on u instead of x or z.
V. EVALUATION
We implemented BEACON, a grey-box fuzzer with a precon-
dition analysis and an instrumentation component, based on
LLVM [44]. That is, as shown in Figure 3, we ﬁrst compile the
input source code to LLVM bitcode, on which the precondition
analysis, the instrumentation for checking preconditions, and
other coverage-related instrumentation are performed. After
instrumentation, the LLVM bitcode is compiled to an exe-
cutable binary, which can be integrated with various fuzzing
engines, such as AFL [12], AFLGo [1], amongst many others.
By default, we choose to use AFLGo as the fuzzing engine.
With the implementation, we conducted a series of exper-
iments to evaluate the effectiveness of BEACON. First, we
compared BEACON with four state-of-the-art (directed) fuzzers
in the application scenario of vulnerability reproduction (Sec-
tion V-A). This experiment aims to show that BEACON is
far more efﬁcient
than existing directed fuzzers, and the
performance of existing non-directed fuzzers can be notably
improved when armed with the path pruning methods of BEA-
CON. Second, since BEACON prunes paths based on both path
slicing (slices away infeasible paths based on the reachability
on the control ﬂow graph) and precondition checking (prunes
infeasible paths according to the precondition analysis), and
thus, to better understand the two strategies, we also evaluated
how much they contribute to the time reduction in fuzzing
(Section V-B). Third, we argued that our precondition anal-
ysis is both precise and fast due to two techniques, namely
relationship preservation and bounded disjunction. Therefore,
we evaluated their impacts on fuzzing by removing them
from the static analysis, respectively (Section V-C). Fourth,
we also evaluated the runtime overhead introduced by our
instrumentation, which aims to show the effectiveness of our
instrumentation strategy.
Baselines. We compared BEACON with the fuzzers men-
tioned in Table I. AFLGo [1] and Hawkeye [2] are two recent
directed grey-box fuzzers that prioritize inputs so that inputs
closer to the target code can be executed in a high priority.
Their technical details are mentioned in Section II-A. We
also planed to compare with Fuzzguard and Savior. However,
Fuzzguard is not open source, and we cannot reproduce the
experiments mentioned in their paper in our environments.
Savior mainly depends on prioritizing the symbolic execution
engine for multiple targets (provided by the address sanitizer)
in the programs. Since it is different from grey-box fuzzing
Table I: Compared fuzzers.
Description
Sophisticated seeds prioritization
Fuzzer
Category
AFLGO [1] Directed
Hawkeye [2] Directed Optimized ﬁtness function + mutation strategies
Greybox
AFL [12]
Mopt [13]
Greybox
AFL++ [45] Greybox
Evolutionary mutation strategies
Mutation operator prioritiztion
Optimization of overall fuzzing framework
Table II: Real-world benchmark programs and vulnerabilities.
Project
Binutils
Libjpeg
Ming
Libxml2
Lrzip
Libpng
Libpoppler
Libav
Program Version
cxxﬁlt
objdump
objcopy
cjpeg
cjpeg
swftophp
swftophp
xmllint
lrzip
pngimage
pdftoppm
pdftops
pdfdetach
avaconv
2.26
2.28
2.28
2.04
1.98
0.4.7
0.4.8
20902
0.631
1.6.35
0.74
0.74
0.71
12.3
Input format Num. CVEs
TXT
ELF
ELF
JPG
JPG
SWF
SWF
XML
ZIP
PNG
PDF
PDF
PDF
AVI/AAC
2
7
4
1
1
7
10
4
2
1
3
1
3
5
and the applicable scenarios are different, we suppose it is
orthogonal to our approach.
To show the capability of BEACON to cooperate with
other fuzzers, we also choose AFL, AFL++, and Mopt, three
coverage-guided grey-box fuzzers, to evaluate how our idea
of path pruning can improve their performance. AFL is one
of the most widely-used fuzzers nowadays, and many existing
works are built based on AFL, such as AFLGo and Hawkeye.
Mopt and AFL++ are also built upon AFL. The former im-
proves input generation by prioritizing the mutation strategies.
The latter integrates with multiple engineer optimizations to
improve the overall performance.
Benchmarks. We chose 51 vulnerabilities in 14 real-world
programs that have been frequently evaluated in the existing
fuzzing frameworks [1], [2]. The chosen programs, which are
shown in Table II, also have diverse functionalities as well as
different program sizes. Moreover, the vulnerabilities chosen
are either causing multiple issues (cause several CVEs) or too
complicated to be ﬁxed completely even after several patches.
Conﬁgurations. The initial seed corpus determines the
effectiveness of fuzzing [46]. To achieve the best performance
of related work, we used the seeds provided by AFLGo in
their Github repository3 with the intuition that the related
works should perform better in their own proposed setting. By
experience, we set the threshold “ 5 for bounded disjunction
in BEACON. We conducted every experiment 10 times and, for
each time, the experiment is run with a time budget of 120
hours. Besides, we employed the Mann-Whitney U Test [47]
to demonstrate the statistical signiﬁcance of the contribution
made by each part of our framework.
All experiments were conducted on an Intel Xeon(R) com-
puter with an E5-1620 v3 CPU and 64GB of memory running
Ubuntu 16.04 LTS.
3https://github.com/aﬂgo/aﬂgo/tree/master/scripts/fuzz
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:18 UTC from IEEE Xplore.  Restrictions apply. 
44
Table III: Comparing to AFLGo with 10 repeated experiments
of vulnerability reproduction. Tsa and Tf are the time cost
of static analysis and fuzzing, respectively. N is the number
of executions. F is the ratio of the executions that are early
stopped by BEACON.
CVE
No. Program
Beacon
F
Tsa
Tf
0.31h
5.54h
0.62h
0.29h
1.45h
Tall
0.32h
5.55h
0.62h
0.30h
1.46h
AFLGo
N
TAF LGo
0.28M 80.7%
43s
1.25h
5.25M 82.6%
18s
T.O.
0.47M 84.3%
16s
2.52h
0.26M 80.8%
20s
2.43h
20s
1.26M 72.3%
37.99h
27s 11.14h 11.15h 23.70M 84.6%
T.O.
1.02h
2.02M 82.0%
27s
1.03h
4.34h
1.75h
21s
3.91M 85.8%
1.76h
T.O.
1.89h
4.42M 83.9%
16s
1.89h
10.71h
1.92h
5.96M 88.8%
20s
1.93h
35.39h
3.13h
6.07M 84.9%
20s
3.14h
60.29h
2.84h
4.33M 91.7%
17s
2.84h
34.23h
3.98h
5.25M 89.0%
18s
3.99h
37.59h
3.14h
7.81M 86.2%
21s
3.15h
T.O.
3.53h
22s
7.08M 84.0%
3.54h
T.O.
2.47h
4.12M 82.3%
20s
2.48h
T.O.
3.91h
8.76M 84.3%
24s
3.92h
T.O.
1.78h
1.32M 86.4%
61s
1.80h
5.05h
1.17h
0.89M 92.4%
68s
1.19h