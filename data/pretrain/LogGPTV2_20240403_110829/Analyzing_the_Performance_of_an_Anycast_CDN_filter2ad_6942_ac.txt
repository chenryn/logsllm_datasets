nal benchmarks for a variety of comparisons. Next, we evaluate
prediction using both ECS and LDNS client grouping.
2We cannot make predictions at ﬁner timescales, as our sampling rate was limited due
to engineering issues.
Figure 7: The cumulative fraction of clients that have changed front-
ends at least once by diﬀerent points in a week
for a single day. Next we look at how much of poor performance
can be attributed to clients frequently switching between good and
poor performing front-ends.
Front-end Aﬃnity: Recurrent front-end selection changes for user
over time may indicate route stability issues which can lead to any-
cast performance problems. We refer to how “attached" particular
clients are to a front-end as front-end aﬃnity. In this section, we
analyze our passive logs.
Figure 7 shows the cumulative fraction of clients that have
switched front-ends at least once by that time of the week. Within
the ﬁrst day, 7% of clients landed on multiple front-ends. An
additional 2-4% clients see a front-end change each day until the
weekend, where there is very little churn, less than .5%. This
could be from network operators not pushing out changes during
the weekend unless they have to. From the weekend to the begin-
ning of the week, the amount of churn increases again to 2-4% each
day. Across the entire week, 21% of clients landed on multiple
front-ends, but the vast majority of clients were stable. We discuss
potential solutions to this more at the end of §6. We observe that
the number of client front-end switches is slightly higher in a one
day snapshot compared to the 1.1-4.7% reported in previous work
on DNS instance-switches in anycast root nameservers [20, 33]. A
likely contributing factor is that our anycast deployment is around
10 times larger than the number of instances present in K root name
server at the time of that work.
Figure 8 shows the change in the client-to-front-end distance
when the front-end changes. This shows that when the majority of
clients switch front-ends, it is to a nearby front-end. This makes
sense given the CDN front-end density in North America and Eu-
rope. The median change in distance from front-end switches is
483 km while 83% are within 2000 km.
We saw in this section that most clients show high front-end-
aﬃnity, that is, they continue going to the same front-end over time.
For the clients that do switch front-ends, there is a long tail of
distance between a client and switched pairs of front-ends.
 0 0.2 0.4 0.6 0.8 1151015CDF of Client /24sNumber of DaysMax # of Consecutive Days# Days 0 0.2 0.4 0.6 0.8 1WedThuFriSatSunMonTueCumulative Fraction of ClientsDay of the Week 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 64 128 256 512 1024 2048 4096 8192CDF of Front-end ChangesChange in client-to-front-end distancewhen the front-end changes (km)535tralized route controller. Unlike our work, they do not examine
the end-to-end application performance comparison between DNS
redirection and anycast. Follow up work focuses on handling any-
cast TCP session disruption due to BGP path changes [7]. Our work
is also closely related to FastRoute [23], a system for load balanc-
ing within an anycast CDN, but it does not address performance
issues around redirection. There has been a good deal of work on
improving and evaluating general CDN performance [37, 24, 36,
6, 35, 25]. The majority of previous work on anycast performance
has focused on DNS. There has been signiﬁcant attention to anycast
DNS from the network operations community [13, 15, 14, 28, 19,
12, 20] but less so for TCP and anycast [31]. Sarat et al. examined
the performance impact of anycast on DNS across diﬀerent anycast
conﬁgurations [38]. Fan et al. [22] present new methods to identify
and characterize anycast nodes. There are several pieces of work
describing deployment of anycast services [30, 10, 11, 26].
Akamai recently published a study on DNS-based redirec-
tion [17]. The authors showed that the majority of clients are nearby
their LDNS, enabling DNS-based redirection to perform well. How-
ever, they also show that a signiﬁcant number of clients are far from
their LDNS, and that some LDNS serve clients spread over large
geographic regions. The paper describes Akamai’s adoption of
ECS-based redirection for clients of public DNS resolvers, show-
ing impressive performance improvements for these clients versus
LDNS-based redirection. However, public resolvers only make up a
small fraction of global DNS traﬃc. Clients using their ISPs’ LDNS
cannot beneﬁt unless the ISPs enable ECS and the CDN supports
ECS requests from the LDNS. Since anycast works well for many
clients, we see beneﬁt in a hybrid approach that chooses whether
to use DNS redirection or anycast based on measurements of which
works better for the LDNS and whether the LDNS supports ECS.
8. CONCLUSION
In this paper we studied the performance of a large anycast-
based CDN, and evaluated whether it could be improved by using
a centralized, DNS-based solution. We found that anycast usually
performs well despite the lack of precise control, but that it directs
≈ 20% of clients to a suboptimal front-end. We demonstrated
that a simple prediction scheme may allow DNS redirection to
improve performance for some of the clients that see poor anycast
performance.
Acknowledgements
We gratefully acknowledge Nick Holt and Daniel Gicklhorn for
their support of this work. Matt Calder and Ethan Katz-Bassett
were partially supported by the U.S. National Science Foundation
grant numbers CNS-1351100 and CNS-1413978.
9. REFERENCES
[1] CloudFlare. https://www.cloudflare.com/.
[2] RIPE Atlas. https://atlas.ripe.net/.
[3] USC CDN Coverage.
http://usc-nsl.github.io/cdn-coverage.
[4] V. K. Adhikari, Y. Guo, F. Hao, V. Hilt, and Z.-L. Zhang.
Tale of Three CDNs: An Active Measurement Study of Hulu
and its CDNs. In IEEE Global Internet Symposium ’12.
[5] B. Ager, W. Mühlbauer, G. Smaragdakis, and S. Uhlig.
Comparing DNS Resolvers in the Wild. In IMC ’10.
[6] B. Ager, W. Mühlbauer, G. Smaragdakis, and S. Uhlig. Web
Content Cartography. In IMC ’11.
Figure 9: Improvement over anycast from making LDNS or ECS-based
decisions with prediction using 25th percentile prediction metric. Neg-
ative x-axis values show where anycast was better than our prediction.
Values at 0 show when we predicted anycast was the best performing.
Positive x-axis values show our improvement.
Prediction using EDNS client-subnet-preﬁx: The ECS exten-
sion [21] enables precise client redirection by including the client’s
preﬁx in a DNS request. Our prediction scheme is straightforward:
we consider all beacon measurements for a /24 client network and
choose the front-end according to the prediction metrics.
The “EDNS-0” lines in Figure 9 depict, as a distribution across
clients weighted by query volume, the diﬀerence between perfor-
mance to the predicted front-end (at the 50th and 75th percentile)
and the performance to the anycast-routed front-end (at the same
percentiles). Most clients see no diﬀerence in performance, in most
cases because prediction selected the anycast address. For the nearly
40% of queries-weighted preﬁxes we predict to see improvement
over anycast, only 30% see a performance improvement over any-
cast, while 10% of weighted preﬁxes see worse performance than
they would with anycast.
LDNS-based prediction: Traditionally, DNS-based redirection
can only make decisions based on a client’s LDNS. In this sec-
tion, we estimate to what degree LDNS granularity can achieve
optimal performance when anycast routing sends clients to subop-
timal servers. We construct a latency mapping from LDNS to each
measured edge by assigning each front-end measurement made by
a client to the client’s LDNS, which we can identify by joining our
DNS and HTTP logs based on the unique hostname for the mea-
surement. We then consider all beacon measurements assigned to
an LDNS and select the LDNS’s best front-end using the prediction
metrics. In the page loads in our experiment, public DNS resolvers
made up a negligible fraction of total LDNS traﬃc so their wide
user base have an insigniﬁcant impact on results.
The “LDNS” lines in Figure 9 show the fraction of /24 client
networks that can be improved from using prediction of performance
based on an LDNS-based mapping. While we see improvement for
around 27% of weighted /24s, we also pay a penalty where our
prediction did poorly for around 17% of /24s.
Our results demonstrate that traditional and recent DNS tech-
niques can improve performance for many of the clients who expe-
rience suboptimal anycast routing. We are also considering a hybrid
approach that combines anycast with DNS-based redirection. The
key idea is to use DNS-based redirection for a small subset of poor
performing clients, while leaving others to anycast. Such a hy-
brid approach may outperform DNS redirection for clients not well
represented by their LDNS, and it may be more scalable.
7. RELATED WORK
Most closely related to our work is from Alzoubi et al. [9, 8].
They describe a load-aware anycast CDN architecture where ingress
routes from a CDN to a large ISP are managed by an ISP’s cen-
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1-400-300-200-100 0 100 200 300 400CDF of Weighted /24sImprovement (ms)EDNS-0 MedianEDNS-0 75thLDNS MedianLDNS 75th536[7] Z. Al-Qudah, S. Lee, M. Rabinovich, O. Spatscheck, and
J. Van der Merwe. Anycast-aware Transport for Content
Delivery Networks. In WWW ’09.
[8] H. A. Alzoubi, S. Lee, M. Rabinovich, O. Spatscheck, and
J. Van Der Merwe. A Practical Architecture for an Anycast
CDN. ACM Transactions on the Web (TWEB) ’11.
[9] H. A. Alzoubi, S. Lee, M. Rabinovich, O. Spatscheck, and
J. Van der Merwe. Anycast CDNs Revisited. In WWW ’08.
[10] H. Ballani and P. Francis. Towards a Global IP Anycast
Service. In SIGCOMM ’05.
[11] H. Ballani, P. Francis, and S. Ratnasamy. A
Measurement-based Deployment Proposal for IP Anycast. In
IMC ’06.
[12] P. Barber, M. Larson, and M. Kosters. Traﬃc Source Analysis
of the J Root Anycast Instances. NANOG 39. February, ’07.
[13] P. Barber, M. Larson, M. Kosters, and P. Toscano. Life and
Times of J-ROOT. NANOG 32. October, ’04.
[14] P. Boothe and R. Bush. Anycast Measurements Used To
Highlight Routing Instabilities. NANOG 35. October, ’05.
[15] P. Boothe and R. Bush. DNS Anycast Stability. 19th APNIC,
’05.
[16] M. Calder, X. Fan, Z. Hu, E. Katz-Bassett, J. Heidemann,
and R. Govindan. Mapping the Expansion of Google’s
Serving Infrastructure. In IMC ’13.
[17] F. Cheng, R. K. Sitaraman, and M. Torres. End-user
mapping: Next Generation Request Routing for Content
Delivery. In SIGCOMM ’15.
[18] Y. Chiu, B. Schlinker, A. B. Radhakrishnan, E. Katz-Bassett,
and R. Govindan. Are We One Hop Away from a Better
Internet? In IMC ’15.
[19] L. Coletti. Eﬀects of Anycast on K-root Performance.
NANOG 37. June, ’06.
[20] L. Colitti, E. Romijn, H. Uijterwaal, and A. Robachevsky.
Evaluating the Eﬀects of Anycast on DNS Root Name
Servers. RIPE document RIPE-393, ’06.
[21] C. Contavalli, W. van der Gaast, D. Lawrence, and
W. Kumari. Client Subnet in DNS Requests. IETF Draft
draft-vandergaast-edns-client-subnet-02, July 2015.
[22] X. Fan, J. Heidemann, and R. Govindan. Evaluating Anycast
in the Domain Name System. In INFOCOM ’13.
[23] A. Flavel, P. Mani, D. Maltz, N. Holt, J. Liu, Y. Chen, and
O. Surmachev. FastRoute: A Scalable Load-Aware Anycast
Routing Architecture for Modern CDNs. In NSDI ’15.
[24] B. Frank, I. Poese, Y. Lin, G. Smaragdakis, A. Feldmann,
B. Maggs, J. Rake, S. Uhlig, and R. Weber. Pushing
CDN-ISP Collaboration to the Limit. SIGCOMM CCR ’14.
[25] M. J. Freedman, E. Freudenthal, and D. Mazieres.
Democratizing Content Publication with Coral. In NSDI ’04.
[26] M. J. Freedman, K. Lakshminarayanan, and D. Mazières.
OASIS: Anycast for Any Service. In NSDI ’06.
[27] M. J. Freedman, M. Vutukuru, N. Feamster, and
H. Balakrishnan. Geographic Locality of IP Preﬁxes. In IMC
’05.
[28] J. Hiebert, P. Boothe, R. Bush, and L. Lynch. Determining
the Cause and Frequency of Routing Instability with Anycast.
In AINTEC ’06.
[29] A. Jain, J. Mann, Z. Wang, and A. Quach. W3C Resource
Timing Working Draft.
http://www.w3.org/TR/resource-timing/, July 2015.
[30] D. Katabi and J. Wroclawski. A Framework For Scalable
Global IP-anycast (GIA). SIGCOMM CCR ’00.
[31] M. Levine, B. Lyon, and T. Underwood. Operation
Experience with TCP and Anycast. NANOG 37. June, ’06.
[32] W. Li, R. K. Mok, R. K. Chang, and W. W. Fok. Appraising
the Delay Accuracy In Browser-based Network
Measurement. In IMC ’13.
[33] Z. Liu, B. Huﬀaker, M. Fomenkov, N. Brownlee, et al. Two
Days in the Life of the DNS Anycast Root Servers. In PAM
’07.
[34] Z. M. Mao, C. D. Cranor, F. Douglis, M. Rabinovich,
O. Spatscheck, and J. Wang. A Precise and Eﬃcient
Evaluation of the Proximity Between Web Clients and Their
Local DNS Servers. In USENIX ATC ’02.
[35] E. Nygren, R. K. Sitaraman, and J. Sun. The Akamai
Network: A Platform for High-performance Internet
Applications. SIGOPS ’10.
[36] J. S. Otto, M. A. Sánchez, J. P. Rula, and F. E. Bustamante.
Content Delivery and the Natural Evolution of DNS: Remote
DNS Trends, Performance Issues and Alternative Solutions.
In IMC ’12.
[37] I. Poese, B. Frank, B. Ager, G. Smaragdakis, S. Uhlig, and
A. Feldmann. Improving Content Delivery with PaDIS.
Internet Computing, IEEE ’12.
[38] S. Sarat, V. Pappas, and A. Terzis. On the Use of Anycast in
DNS. In ICCCN ’06.
[39] N. Spring, R. Mahajan, and T. Anderson. The Causes of Path
Inﬂation. In SIGCOMM ’03.
537