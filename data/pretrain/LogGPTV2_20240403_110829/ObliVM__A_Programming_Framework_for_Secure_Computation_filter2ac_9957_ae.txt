A. Case Study: Basic Arithmetic Operations
The rich language features provided by ObliVM-lang make
it possible to implement complex arithmetic operations easily
and efﬁciently. We give a case study to demonstrate how to
use ObliVM-lang to implement Karatsuba multiplication.
Implementing Karatsuba multiplication. Figure 4 con-
tains the implementation of Karatsuba multiplication [50] in
ObliVM-lang. Karatsuba multiplication implements the fol-
lowing recursive algorithm to compute multiplication of two
n bit numbers, x and y, taking O(nlog2 3) amount of time.
As a quick overview, the algorithm works as follows. First,
express the n-bit integers x and y as the concatenation of n
2 -
bit integers: x = a*2n/2+b, y = c*2n/2+d. Now, x*y can be
calculated as follows:
t1 = a*c; t2 = b*d; t3 = (a+b)*(c+d);
x*y = t1{
int@n id, pos;
T
data;
};
struct CircuitOram@n{
dummy Block@n[public 1[public STASHSIZE] stash;
};
phantom T
CircuitOram@n
.readAndRemove(int@n id, rnd@n pos) {
public int32 pubPos = pos;
public int32 i = (1 =0; k=k-1) {
res;
for (public int32 j=0;j.
Circuit ORAM (line 7-10) is organized to contain an array
of buckets (i.e. arrays of ORAM blocks), and a stash (i.e. an
array of blocks). The dummy keyword in front of Block@n
indicates the value of this type can be null. In many cases,
(e.g. Circuit ORAM implementation), using dummy keyword
leads to a more efﬁcient circuit generation.
Line 11-30 demonstrates how readAndRemove can be im-
plemented. Taking the input of an secret integer index id, and
a random position label pos, the label pos is ﬁrst declassiﬁed
into public. Then afﬁne type system allows declassifying pos
once,
i.e. pos is never used for the rest of the program.
Further in a function calling readAndRemove with inputs arg1
and arg2, arg2 cannot be used either for the rest of the
program. This is crucial to enforce that every position labels
will use revealed only once after its generation, and, to our
best knowledge, no prior work enables such an enforcement
in a compiler.
VI. BACK END ARCHITECTURE
Our compiler emits code to a Java-based secure computa-
tion back end called ObliVM-GC. We defer details of ObliVM-
GC to our online full version [39].
VII. EVALUATION
A. Metrics and Experiment Setup
Number of AND gates. In Garbled Circuit-based secure
computation, functions are represented in boolean circuits
consisting of XOR and AND gates. Due to well-known Free
XOR techniques [5]–[7], the cost of evaluating XOR gates
are insigniﬁcant in comparison with AND gates. Therefore, a
primary performance metric is the number of AND gates. This
metric is platform independent, i.e., independent of the artifacts
of the underlying software implementation, or the hardware
conﬁgurations where the benchmark numbers are measured.
This metric facilitates a fair comparison with existing works
based on boolean circuits, and is one of the most popular
metrics used in earlier works [10], [11], [15], [16], [25], [26],
[33], [51], [52].
Wall-clock runtime. Unless noted otherwise, all wall-clock
numbers are measured by executing the protocols between two
Amazon EC2 machines of types c4.8xlarge and c3.8xlarge.
This metric is platform and implementation dependent, and
therefore we will explain how to best
interpret wallclock
runtimes, and how these runtimes will be affected by the
underlying software and hardware conﬁgurations.
Compilation time. For all programs we ran, the compilation
time is under 1 second. Therefore, we do not separately report
the compilation time for each program.
B. Comparison with Previous Automated Approaches
The ﬁrst general-purpose secure computation system, Fair-
play, was built in 2004 [12]. Since then, several improved
systems were built [9]–[11], [13], [14], [16], [33]. Except
for our prior work SCVM [15], existing systems provide no
support for ORAM – and therefore, each dynamic memory
access would be compiled to a linear scan of memory.
We now evaluate the speedup ObliVM achieves relative to
previous approaches. To illustrate the sources of the speedup,
we consider the following sequence of progressive baselines.
We start from Baseline 1 which is representative of a state-of-
the-art automated secure computation system. We then add one
feature at a time to the baseline, resulting in the next baseline,
until we arrive at Baseline 5 which is essentially our ObliVM
system.
• Baseline 1: A state-of-the-art automated system with
no ORAM support. Baseline 1 is intended to char-
acterize a state-of-the-art automated secure computation
system with no ORAM support. We assume a compiler
that can detect public memory accesses (whose addresses
are statically inferrable), and directly make such memory
accesses. For each each dynamic memory access (whose
address depends on secret inputs), a linear scan of mem-
ory is employed. Baseline 1 is effectively a lower-bound
370
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:02 UTC from IEEE Xplore.  Restrictions apply. 
Oblivious programming abstractions and
compiler optimizations demonstrated
Dijkstra’s Algorithm Loop coalescing abstraction (see
MST
Heap
Map/Set
Binary Search
AMS Sketch
Count Min Sketch
K-Means
Section IV-C).
Oblivious data structure abstraction (see
Section IV-B).
Compile-time optimizations: split data into
separate ORAMs [15].
MapReduce abstraction (see Section IV-A).
Parameters for Figure 6
Parameters for Table IV
and Table V
V = 214, E = 3V
V = 210, E = 3V
N = 227, K = 32, V = 480
N = 223, K = 32, V = 992
 = 6 × 10−5, δ = 2−20
N = 223, K = 32, V = 992
 = 2.4 × 10−4, δ = 2−20
 = 3 × 10−6, δ = 2−20
N = 218
N = 216
TABLE III: List of applications used in Figures 6. For graph algorithms, V, E stand for number of vertices and edges; for data
structures, N, K, V stand for capacity, bit-length of key and bit-length of value; for streaming algorithms, , δ stand for relative
error and failure probability; for K-Means, N stands for number of points.
estimate of the cost incurred by CMBC-GC [16], a state-
of-the-art system in 2012.
• Baseline 2: With GO-ORAM [40]. In Baseline 2, we
implement the GO-ORAM scheme on top of Baseline 1.
Dynamic memory accesses made by a program will be
compiled to GO-ORAM accesses. We make no additional
compile-time optimizations.
• Baseline 3: With Circuit ORAM [29]. Baseline 3 is
essentially the same as Baseline 2 except that we now
replace the ORAM scheme with a state-of-the-art Circuit
ORAM scheme [29].
• Baseline 4: Language and compiler. Baseline 4 assumes
that the ObliVM language and compiler are additionally
employed (on top of Baseline 3), resulting in additional
savings due to our compile-time optimizations as well as
our oblivious programming abstractions.
• Baseline 5: Back end optimizations. In Baseline 5, we
employ additional back end optimizations atop Baseline 4.
Baseline 5 reﬂects the performance of the actual ObliVM
system.
We consider a set of applications in our evaluation as
described in Table III. We select several applications to
showcase our oblivious programming abstractions, including
MapReduce,
loop coalescing, and oblivious data structure
abstractions. For all applications, we choose moderately large
data sizes ranging from 768KB to 10GB. For data structures
(e.g., Heap, Map/Set) and binary search, for Baseline 1, we
assume that each operation (e.g., search, add, delete) is done
with a single linear scan. For Baseline 2 and 3, we assume that
a typical sub-linear implementation is adopted. For all other
applications, we assume that Baseline 1 to 3 adopt the most
straightforward implementation of the algorithm.
Results. Figure 6 shows the speedup we achieve relative
to a state-of-the-art automated system that does not employ
ORAM [16]. This speedup comes from the following sources:
No ORAM to GO-ORAM: For most of the cases, the data
size considered was not big enough for GO-ORAM to be
competitive to a linear-scan ORAM. The only exception was
AMS sketch, where we chose a large sketch size. In this
case, using GO-ORAM would result in a 300× speedup in
comparison with no ORAM (i.e., linear-scan for each dynamic
memory access). This part of the speedup is reﬂected in purple
in Figure 6. Here the speedup stems from a reduction in circuit
size (as measured by the number of AND gates).
Circuit ORAM: The red parts in Figure 6 reﬂect
the
multiplicative speedup attained when we instead use Circuit
ORAM (as opposed to no ORAM or GO-ORAM, whichever
is faster). This way, we achieve an additional 51× to 530
performance gains – reﬂected by a reduction in the total circuit
size.
Language and compiler: As reﬂected by the blue bars
in Figure 6, our oblivious programming abstractions and
compile-time optimizations bring an additional 2× to 2500×
performance savings on top of a generic Circuit ORAM-
based approach. This speedup is also measurable in terms of
reduction in the circuit size.
Back end optimizations: Our ObliVM-GC is a better
architected and more optimized version of
its predeces-
sor FastGC [33] which is employed by CMBC-GC [16].
FastGC [33] reported a garbling speed of 96K AND gates/sec,
whereas ObliVM garbles at 670K AND gates/sec on a com-
parable machine. In total, we achieve an 7× overall speedup
compared with FastGC [33].
We stress, however, that ObliVM’s main contribution is not
the back end implementation. In fact, it would be faster to hook
up ObliVM’s language and compiler with a JustGarble-like
system that employs a C-based implementation and hardware
AES-NI. However, presently JustGarble does not provide a
fully working end-to-end protocol. Therefore, it is an important
direction of future work to extend JustGarble to a fully working
protocol, and integrate it into ObliVM.
Comparison with SCVM.
In comparison with SCVM,
ObliVM’s offers the following new features: 1) new oblivious
programming abstractions; 2) Circuit ORAM implementation
that is 20× to 30× times faster than SCVM’s binary-tree
ORAM implementation for 4MB to 4GB data sizes; and 3)
ability to implement low-level gadgets including the ORAM
algorithm itself in the source language.
In the online full version [39], we give a detailed compar-
ison with an SCVM-like system. Since the design of efﬁcient
ORAM algorithms is mainly the contribution of the Circuit
ORAM paper [29], here we focus on evaluating the gains from
programming abstractions. Therefore, instead of comparing
with SCVM per se, we compare with SCVM + Circuit ORAM
instead (i.e., SCVM with its ORAM implementation updated
to the latest Circuit ORAM).
371
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:02 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 6: Sources of speedup in comparison with state-of-the-art in 2012 [16]: an in-depth look.
C. ObliVM vs. Hand-Crafted Solutions
We show that ObliVM achieves competitive performance
relative to hand-crafted solutions for a wide class of common
tasks. We also show that ObliVM signiﬁcantly reduces devel-
opment effort in comparison with previous secure computation
frameworks.
Competitive performance. For a set of applications, includ-
ing Heap, Map/Set, AMS Sketch, Count-Min Sketch, and
K-Means, we compared implementations auto-generated by
ObliVM with implementations hand-crafted by human experts.
Here the human experts are authors of this paper. We assume
that the human experts have wisdom of employing the most
efﬁcient, state-of-the-art oblivious algorithms when designing
circuits for these algorithms. For example, Histogram and K-
Means algorithms are implemented with oblivious sorting pro-
tocols instead of generic ORAM. Heap and Map/Set employ
state-of-the-art oblivious data structure techniques [26]. The
graph algorithms including Dijkstra and MST employ novel
oblivious algorithms proposed in this paper. In comparison, our
ObliVM programs for the same applications do not require spe-
cial security expertise to create. The programmer simply has to
express these tasks in the programming abstractions we offer
whenever possible. Over the suite of application benchmarks
we consider, our ObliVM programs are competitive to hand-
crafted implementations – and the performance difference is
only 0.5% − 2% throughout.
We remark that the hand-crafted circuits are not necessarily
the optimal circuits for each computation task. However, they
do represent asymptotically the best known algorithms (or new
algorithms that are direct implications of this paper). It is
conceivable that circuit optimization techniques such as those
proposed in TinyGarble [34] can further reduce circuit sizes
by a small constant factor (e.g., 50%). We leave this part as
an interesting direction of future research.
Developer effort. We use two concrete case studies to demon-
strate the signiﬁcant reduction of developer effort enabled by
ObliVM.
Case study: ridge regression. Ridge regression [53] takes
as input a large number of data points and ﬁnds the best-ﬁt
linear curve for these points. The algorithm is an important
building block in various machine-learning tasks [52]. Previ-
ously, Nikolaenko et al. [52] developed a system to securely
evaluate ridge regression, using the FastGC framework [33],
which took them roughly three weeks [54]. In contrast, we
spent two student·hours to accomplish the same task using
ObliVM. In addition to the speedup gain from ObliVM-GC
back end, our optimized libraries result in 3× smaller circuits
with aligned parameters. We defer the detailed comparison to
the online technical report [39].
Case study: oblivious data structures. Oblivious AVL tree
(i.e, the Map/Set data structure) is an example algorithm that
was previously too complex to program as circuits, but now
becomes very easy with ObliVM. In an earlier work [26], we