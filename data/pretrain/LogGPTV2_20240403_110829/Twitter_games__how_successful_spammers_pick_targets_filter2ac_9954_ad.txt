9%
1%
0%
917,258
14,230
436,047
68,044
1,919
100
Table 7: Tweet posting methodology of successful and unsuccessful spam proﬁles and of regular Twitter users
6.1 Unbinned Spam Proﬁles
We discussed ﬁve strategies that successful spammers use
to pick their spam targets in Section 4. Collectively, these
strategies helped understand the spamming behavior of 62%
of the 14,230 proﬁles of successful spammers.
In trying
to understand the behavior of unbinned spam proﬁles, we
learnt a few things. First, of the 5,425 unbinned proﬁles,
the largest chunk, 64.7%, exclusively made use of regular
tweets and could not have directly targeted any other Twit-
ter users but their followers. Owing to this observation, they
could only be binned under Section 4.1 amongst the strate-
gies we describe. Recall that in Section 4.1, we considered
a proﬁle binned if it appeared to be running a campaign,
deﬁned by at least 10 tweets with links and 80% of the links
leading to a single domain. Since alternative deﬁnitions for
campaigns is possible, we tried a few diﬀerent ones to see
their impact on the proportion of unbinned proﬁles. For
example, if we require that a proﬁle only have at least ﬁve
tweets with links and when the number of tweets with links
is less than 10, 80% of them be leading to a speciﬁc domain
and when the number of tweets with links is 10 or more, 50%
of them be leading to a speciﬁc domain, we bin 8,034 proﬁles
in Section 4.1 as against 6,630. In turn, 72% spam proﬁles
get binned. This simple exercise suggests that further ex-
perimentation with deﬁnitions of campaign is one avenue for
binning more spam proﬁles.
Of the remaining 1,910 unbinned proﬁles, 89.7% sent at
least one mention tweet and 328 sent exclusively mention
tweets. Note that of the two strategies involving mention
tweets, described in Sections 4.2 and 4.3, the latter had to
ignore mention tweets due to the unavailability of keywords
spammers may have targeted from users’ original tweets.
This caused us to miss an opportunity of binning more spam
proﬁles that used mention tweets.
Further, spam automators, such as TweetAdder, provide
other ways spammers could use to pick their targets. For ex-
ample, targets could be chosen based on their geographical
location and language, which are pieces of information typ-
ically associated with Twitter proﬁles. However, given that
the proﬁles we investigated were already suspended, we did
not have access to information about their followers. Such
information may have helped us investigate more strategies
used, especially by regular tweeting proﬁles, to identify tar-
gets.
6.2 Garnering Followers
Given that about 90% of successful spam proﬁles make
use of regular tweets and 2/3rd of them use them exclu-
sively, how spammers garner followers is an interesting con-
sideration. Indeed, Figure 3 conﬁrmed that a large number
of successful spammers have a respectable number of follow-
ers.
There are many ways spammers can use to garner fol-
lowers. A popular mechanism is to become a part of one
or more peer-driven communities that encourage following
back. We discovered two interesting communities in our
data, #InstantFollowBack (#IFB) and #TeamFollowBack
(#TFB).
The ﬁrst of these is controlled by a third-party client un-
der the Twitter proﬁle name ’instantfollowBA’ that allows
a Twitter user to ﬁnd and follow users on Twitter by re-
quiring them to be listed under it’s follow back community
#InstantFollowBackGradeA. The requirements for this is to
have public account with minimum 500 followers and follow
back 99% of the them on a every day basis which the client
app claims to make it easier by providing a few tools. Addi-
tionally, it rewards each user with points that oﬀer diﬀerent
levels of promotions. Each user is given a ’status’ that indi-
cates the number the ’Gold’ and ’Experience’ points earned
by them. Users can increase their points by being a part of
#InstantFollowBackGradeA and by tweeting (advertising)
about ’instantfollowBA’. As the level of a user increases,
more points are awarded. After collecting a suﬃcient num-
ber of points, a user gains center stage in promotions, such as
retweets to all of the main #IFB proﬁle’s followers, retweets
by others in the community to increase the proﬁle’s visibil-
ity in Twitter, display of banner ads by several members of
the #IFB community and so on. This method of incentiviz-
ing users to join a follow back community is unique though
its popularity may be limited due to the complicated na-
ture of the setup. In fact, we found only 217 proﬁles from
our data set that were involved in this scheme. The sec-
ond community in our data, #TFB, is a Twitter hashtag
used by numerous follow back groups with goals similar to
#IFB. Proﬁles involved in these schemes sign their tweets
with the #TFB hashtag. Often, they add the hashtag to
their publicly searchable proﬁle information. This makes it
easy for anyone requiring followers to ﬁnd proﬁles willing
to follow them back without regard to who is requesting or
what content is being tweeted. We found 509 proﬁles in our
data using the #TFB hashtag, all in Section 4.4.
Yet another option for increasing the number of followers
is to buy them. Owing to the importance of collecting follow-
ers, websites such as, http://getfollowrsontwitter.org/,
have cropped up that allow one to buy followers, often in
increments of thousands. At the same time, online mar-
ketplaces for services, such as fiverr.com, routinely feature
services where oﬀerers guarantee thousands of Twitter fol-
lowers for as little as $5 (see Figure 5 for an example of such
an oﬀering). Works in [6, 13] studied Twitter account mar-
396
kets and conﬁrmed that buying followers is indeed prevalent
on Twitter.
Figure 5: An advertisement oﬀering to gather Twit-
ter followers
It is important to note that the techniques described thus
far only go as far in ﬁnding followers. Speciﬁcally, they are
unlikely to work well for spam proﬁles that require relevant
followers, such as in the case of exclusive regular tweeters.
As described before, these are the largest chunk of successful
spammers and require more intelligent strategies for garner-
ing followers. To garner such followers, spammers could use
the strategies we described in Sections 4.2 and 4.3 to lo-
cate targets and friend them. Additionally, a spammer may
use publicly searchable proﬁle information to target peo-
ple based on location, interests etc. Since a good number
of these targets may be genuinely interested in the content
promoted by a spammer, it may increase the likelihood of
them actually following the spammer back. While we have
seen evidence of such activity in a few spam proﬁles that
are alive, it is in general diﬃcult to prove if the followers
of a proﬁle were gathered using a certain strategy. In fact,
spamming only one’s followers thins the line between gen-
uine and spam content since the only real violation by spam
accounts tweeting only to their followers is the use of an au-
tomated tool to send tweet in large volumes. In contrast,
the dominant spammers in Thomas et al.’s work were bla-
tant violators of Twitter terms and conditions since they
largely made use of unsolicited mentions to promote spam
tweets.
7. RELATED WORK
Spam on online social networks has been analyzed in a
number of diﬀerent ways. Benevenuto et al. [2] analyze on-
line video spam on Youtube and employ machine learning
techniques to identify spammers on YouTube. The study
by Gao et al. [5] involves detecting and characterizing spam
campaigns on Facebook. Here, we focus primarily on works
related to Twitter, focusing particularly on previous research
which is most related to our work and inﬂuenced our inves-
tigation.
Much of the research on Twitter spam has focused on
building classiﬁers that distinguish spam proﬁles from non-
397
spam proﬁles or spam tweets from non-spam tweets. Lee
et al. [10] and Stringhini et al. [14] investigated spam on
Twitter using social honey pots, which are proﬁles created
specially for the purpose of being spammed and proposed
a machine learning based approach to classify proﬁles that
send spam to these accounts. Lee et al [9] also studied col-
lective spam on Twitter by analyzing how cyber criminals
exploit trending topics to propagate spam and devised a ma-
chine learning based methodology to detect them. Yang et
al. [22] studied tactics used by spammers and employed ma-
chine learning features to detect them. Hongyu et al. [4]
gathered spam messages into campaigns and used super-
vised machine learning framework for ﬁltering them. Works
in [1, 3, 21] studied spam by manually labeling their data
sets into spam and non-spam accounts and built a classiﬁer
using account-based, content-based and behavior-based fea-
tures. Classiﬁers of nature similar to these works can beneﬁt
from using features we found common across spam proﬁles
in our data.
Signiﬁcant research has also been done in detection and
characterization of suspicious URLs in Twitter. Lee et al. [11]
proposed a machine learning classiﬁer to detect suspicious
URLs by identifying characteristics of URLs in spam tweets.
Thomas et al. [15] proposed a real time URL classiﬁer that
extracts features from page content, hosting infrastructure
and lexical properties of URLs to detect spam urls in a Twit-
ter stream.
Grier et al. [7] characterized Twitter spam by discussing
various topics like type of tweets spammers use, click through
rates of shortened URLs, types of spam accounts, blacklist
performance and the techniques used by spammers to garner
a wider audience.According to their analysis, 70% of spam
tweets had hashtags (compared to 7.3% in our data), 11%
were retweets (compared to 1.1% in our data) and 10.6%
(compared to 5.1% in our data) were mentions.
Yang et al. [23] studied how spammers get embedded
deeper in social networks and found three categories of users
that form closer relationships with spammers that post ma-
licious links. Jonghyuk et al. [12] proposed a spam ﬁltering
technique by analyzing sender-receiver relationship between
users.
A very closely related work to our work here was done
by Thomson et al. [16]. The authors collect a large number
of suspended Twitter accounts over a period of time and
analyze their behavior. Although we have a similar data
collection methodology (albeit for a shorter period of time),
we show how much Twitter spam has evolved since their
study, likely to counter Twitter’s current anti-spam eﬀorts.
Speciﬁcally, we ﬁnd that multiple characteristics of spam
accounts, such as social relationships formed, longevity and
type of tweets used diﬀer signiﬁcantly in our study even
though the nature of spam campaigns remains essentially
the same. We focus on spam accounts which survive much
longer than those set up by naive spammers and discuss their
strategies.
8. CONCLUSION
We analyzed strategies of successful Twitter spammers
in this paper, particularly as they relate to picking spam
targets. A key ﬁnding of our work was that while spam
campaigns on Twitter changed little, the spammers them-
selves evolved in a mere matter of one year since Thomas
et al., perhaps to stay aﬂoat amidst take-down eﬀorts. The
[13] Stringhini, G., Egele, M., Kruegel, C., and Vigna, G. Poultry
markets: On the underground economy of Twitter followers. In
ACM Workshop on Online Social Networks (WOSN) (2012).
[14] Stringhini, G., Kruegel, C., and Vigna, G. Detecting
spammers on social networks. In Annual Computer Security
Applications (ACSAC) conference (2010).
[15] Thomas, K., Grier, C., Ma, J., Paxson, V., and Song, D.
Design and evaluation of a real-time URL spam ﬁltering
service. In IEEE Symposium on Security and Privacy (2011).
[16] Thomas, K., Grier, C., Song, D., and Paxson, V. Suspended
accounts in retrospect: an analysis of twitter spam. In
ACM/USENIX Internet Measurement Conference (IMC)
(2011).
[17] TweetAdder, 2012. http://www.tweetadder.com.
[18] TweetAttacks manual, 2012.
http://www.scribd.com/doc/59395233/Manual-Tweet-Attacks.
[19] Twitter rules, 2012. https:
//support.twitter.com/entries/18311-the-twitter-rules.
[20] Twitter size, 2012.
http://blog.twitter.com/2012/03/twitter-turns-six.html.
[21] Wang, A. H. Don’t follow me: Spam detection in Twitter. In
International Conference on Security and Cryptography
(SECRYPT) (2010).
[22] Yang, C., Harkreader, R., and Gu, G. Die free or live hard?
Empirical evaluation and new design for ﬁghting evolving
Twitter spammers. In International Symposium on Recent
Advances in Intrusion Detection (RAID) (2011).
[23] Yang, C., Harkreader, R., Zhang, J., Shin, S., and Gu, G.
Analyzing spammers’ social networks for fun and proﬁt: A case
study of cyber criminal ecosystem on Twitter. In International
Conference on World Wide Web (WWW) (2012).
complexity of their strategies are only likely to increase as
more and more tools which simulate normal human behav-
ior are developed. Given the shift in spammer behavior to
integrate more closely into the social network, this will re-
quire constant scrutiny on the part of Twitter to discover
newer and more complex strategies. We believe there is a
need for spam classiﬁers to include social metadata such as
follower metadata, keywords cloud, domains linked in tweets
etc. along with the traditional signals used in classiﬁers to-
day to achieve true success in identifying sophisticated spam
proﬁles.
Acknowledgements
We thank Fil Menczer and the Center for Complex Networks
and System Research (CNetS) at Indiana University for pro-
viding us access to the Twitter streaming API data through
their Truthy project. The Truthy project and its infras-
tructure are supported by the National Science Foundation
(NSF) grants CCF-1101743 and IIS-0811994 respectively.
The work in this paper is supported by the National Sci-
ence Foundation (NSF) under Grant Number CNS-1018617.
Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the author(s) and
do not necessarily reﬂect the views of the National Science
Foundation.
9. REFERENCES
[1] Benevenuto, F., Magno, G., Rodrigues, T., and Almeida, V.
Detecting spammers on Twitter. In Collaboration, Electronic
messaging, Anti-Abuse and Spam Conference (CEAS) (2010).
[2] Benevenuto, F., Rodrigues, T., Almeida, V., Almeida, J., and
Chao Zhang, K. R. Identifying video spammers in online social
networks. In Workshop on Adversarial Information Retrieval
on the Web (AirWeb), held in conjunction with the
International World Wide Web (WWW) conference (2008).
[3] Chu, Z., Gianvecchio, S., and Wang, H. Who is tweeting on
Twitter: Human, bot, or cyborg? In Annual Computer
Security Applications Conference (ACSAC) (2010).
[4] Gao, H., Chen, Y., Lee, K., Palsetia, D., and Choudhary, A.
Towards online spam ﬁltering in social networks. In ISOC
Network and Distributed System Security Symposium (NDSS)
(2012).
[5] Gao, H., Hu, J., Wilson, C., Li, Z., Chen, Y., and Zhao, B. Y.
Detecting and characterizing social spam campaigns. In
ACM/USENIX Internet Measurement Conference (IMC)
(2010).
[6] Ghosh, S., Viswanath, B., Kooti, F., Sharma, N. K., Korlam,
G., Benevenuto, F., Ganguly, N., and Gummadi, K. P.
Understanding and combating link farming in the Twitter
social network. In International Conference on World Wide
Web (WWW) (2012).
[7] Grier, C., Thomas, K., Paxson, V., and Zhang, M. @spam: the
underground on 140 characters or less. In ACM Conference on
Computer and Communications Security (CCS) (2010).
[8] Jones, K. S. A statistical interpretation of term speciﬁcity and
its application in retrieval. In Journal of Documentation, Vol.
28 Issue: 1, pp.11 - 21 (1972).
[9] Lee, K., Caverlee, J., Kamath, K. Y., and Cheng, Z. Detecting
collective attention spam. In Workshop on WebQuality, held
in conjunction with International World Wide Web (WWW)
conference (2012).
[10] Lee, K., Caverlee, J., and Webb, S. Uncovering social
spammers: Social honeypots + machine learning. In ACM
Special Interest Group on Information Retrieval (SIGIR)
Conference (2010).
[11] Lee, S., and Kim, J. Warningbird: Detecting suspicious URLs in
twitter stream. In ISOC Network and Distributed System
Security Symposium (NDSS) (2012).
[12] Song, J., Lee, S., and Kim, J. Spam ﬁltering in twitter using
sender-receiver relationship. In International Symposium on
Recent Advances in Intrusion Detection (RAID) (2011).
398