20
12
10
18
14
16
High BW (hours)
6
Medium BW (hours)
(a) Fixed online hours for Type1 at 2,
varying other two types.
12
4
8
)
s
p
b
k
(
24
W
B
d
e
t
h
g
e
W
i
22
20
18
24
22
20
12
10
18
14
16
6
High BW (hours)
Medium BW (hours)
(b) Fixed online hours for Type1 at 4,
varying other two types.
12
4
8
)
s
p
b
k
(
24
W
B
d
e
t
h
g
e
W
i
22
20
18
24
22
20
12
10
18
14
16
Medium BW (hours)
High BW (hours)
(c) Fixed online hours for Type1 at 6,
varying other two types.
12
4
6
8
Figure 1. Weighted bandwidth and diurnal sensitivity. Low-bandwidth bots have a signiﬁcant effect
on average bandwidth when they are online for more than ≈ 4 hours. Figures (a) through (c) ﬁx the
diurnal weight of low-bandwidth bots at 2, 4 and 6 hours. Only at the extreme, plot (c), does average
bandwidth change signiﬁcantly. This impact is seen when high- and medium bandwidths bots have
less than 24-hour/day connectivity.
may recall that in Milgram’s famous paper, social networks
were shown to have short average geodesic lengths, approx-
imately log N , or l ≈ 6 (“six degrees of separation”) for
general society [36], while the web has a larger estimated
length, l ≈ 17 [3].
As in [23], we use the inverse geodesic length, l−1, in-
stead of l, deﬁned as:
(cid:4)
(cid:3)
l−1 =
1
d(v, w)
=
1
N (N − 1)
(cid:2)
(cid:2)
v∈V
w(cid:3)=v∈W
1
d(v, w)(cid:4)
(2)
This way, if bots v and w are disconnected, the distance
d is zero. Further, the inverse length is normalized, ranging
from 0 (no edges) to 1 (fully connected).
In the context
of botnets, l−1 refers to the overlay network of bot-to-bot
connections created by the malware, instead of the physical
topology of the Internet. Thus, bot victims on the same
local network (one hop away) may be several edges apart or
even unconnected in the overlay bot network created by the
malware.
This metric is also relevant to robustness because with
each message passed through a botnet, there is a probabil-
ity of detection or failure. Some researchers have already
investigated zombie detection via stepping stone analysis,
or the detection of messages being relayed through victim
proxies [59]. It is difﬁcult to express this chance of detec-
tion precisely, since botnet identiﬁcation is a new, develop-
ing ﬁeld. But at a high level, botnet detection techniques
will generally rely on the chance of intercepting (i.e., de-
tecting and corrupting or halting) a message between two
bots in a network. Assume that bots u and v are connected
through n possible paths, P1, . . . Pn, and that each node in
the path can be recovered (cleaned) with probability α. If
i is the chance that path Pi is corrupted, quarantined or
328328
blocked, then all paths between u and v are blocked with
probability:
n(cid:5)
i ≤ (1 − α)n
(3)
i=1
While bots u and v are connected through some path with
probability 1 − (1 − α)n, the chance of failure increases
with α (i.e., as detection technologies improve). Section 3
characterizes the performance of l−1 under increasing link
decay.
We expect that in the future, botnet researchers will pro-
pose many techniques to detect, disrupt, or interfere with
botnet messaging. Network diameter, l−1 is therefore a ba-
sic, relevant metric to determine how many opportunities
network administrators have to observe, disrupt or measure
messaging.
The incentive of the botmaster is to increase l−1, which
yields a more efﬁcient/robust botnet, at least for selected
uses noted in Table 1. Under an ideal l−1 = 1, every bot
can talk directly to every other bot. Since a botnet with more
interconnections has more short paths, it passes messages
quickly, and provides fewer detection opportunities.
2.5 Measuring Botnet Robustness
A ﬁnal category of botnet use can be expressed in the
robustness of such networks. Bots routinely lose and gain
new members over time. If victim machines are perform-
ing state-sensitive tasks (e.g., storing ﬁles for download, or
sending spam messages from a queue), a higher-degree of
connection between bots provides fault tolerance and recov-
ery.
To some degree this metric correlates with an improved
redundancy. l−1 already indicates robustness in some sense.
But we more precisely capture the robustness of networks
using local transitivity to measure redundancy. Local tran-
sitivity measures the likelihood that nodes appear in “triad”
groups. That is, given two node pairs, {u, v} and {u, w},
that share a common node, u, local transitivity measures
the chance that the other two, v and w, also share an edge.
A clustering coefﬁcient γ, measures the average degree of
local transitivity [56], in a neighborhood of vertices around
node v, Γv. If Ev represents the number of edges in Γv,
then γv is the clustering coefﬁcient of node v. Where kv
represents the number of vertices in Γv, then we have:
γv =
Ev(cid:6)
(cid:7) , γ = (cid:4)γ(cid:5) =
kv
2
1
N
(cid:2)
v∈V
γv.
(4)
The average clustering coefﬁcient (cid:4)γ(cid:5) measures the number
of triads divided by the maximal number of possible triads.
Just like l−1, γ ranges from [0, 1], with 1 representing a
complete mesh.
Local transitivity is an important measure for certain bot-
net uses. Warez (stolen programs) and key cracking require
reliable, redundant storage, particularly since botnets ex-
hibit strongly diurnal properties. To ensure uninterrupted
key cracking, or that ﬁle resources are always available, bot-
masters routinely designate multiple victims to store iden-
tical ﬁles. (For examples, consult [12].) Botmasters could
use quorum systems in addition to simple backups. How-
ever, the transitivity measure γ index generally captures the
robustness of a botnet.
2.6 Botnet Network Models
To measure the robustness of different botnet architec-
tures, we must further specify the types of response actions
available to network administrators.
In a general sense,
botnets can suffer random and targeted responses. Ran-
dom failures correspond to patching by normal users, diur-
nal properties of computers being powered off at night, and
other random failures in a network. Targeted responses are
those that select “high value” machines to recover or patch.
These response types all correspond to actions directed at
botnet vertices. Edge-oriented responses (e.g., quarantine,
null routing) have been considered elsewhere, e.g., [64].
Expanding on the general categories of botnets noted
in [13], we consider different types of graphs studied in the
extensive literature on complex networks. Our taxonomy
uses the major models from that ﬁeld. For a comprehensive
overview of complex network mechanics, see [4].
2.6.1 Erd¨os-R´enyi Random Graph Models
To avoid creating predictable ﬂows, botnets can be struc-
tured as random graphs. In a random graph, each node is
connected with equal probability to the other N − 1 nodes.
329329
Such networks have a logarithmically increasing l−1. The
chance a bot has a degree of k is the binomial distribution:
(cid:8)
(cid:9)
N − 1
k
P r(k) =
pk(1 − p)N −1−k
(5)
Particularly for large networks like botnets, it makes
sense to limit the degree k to a maximum number of edges,
L. For our analysis below, we select an average (cid:4)k(cid:5) appro-
priate to botnets, instead of (cid:4)k(cid:5) ≈ 2L/N used by others
studying general network complexity problems [23]. With-
out such a limitation, a pure Erd¨os-R´enyi random botnet
would potentially create individual bots with hundreds of
edges, even for small (5K victim) botnets. Large numbers
of connections on a client host are highly unusual, even
for P2P software [33, 49]. So, unless the victim is a rare
high-capacity server, botmasters would keep (cid:4)k(cid:5) small, say
(cid:4)k(cid:5) ≈ 10. In Section 3, we measure the degree of connec-
tion in an unstructured P2P botnet, to conﬁrm that (cid:4)k(cid:5) will
have fairly low values.
One difﬁculty in random graphs is easily overcome by
certain types of botnets. Since each node has a probabil-
ity P r(k) of being connected to each vertex, the creation
of the graph requires some central collection (or record) of
vertices. That is, each bot must either know or learn the
address of all the other bots, in order to have a chance of
sharing an edge. Because such a list may be discovered by
honeypot operators, botmasters have an incentive to not cre-
ate such a centralized master list, and some bots, e.g., those
created by the Zindos worm [32], take explicit steps to limit
the number of victim addresses stored in one place.
This creates a technical problem for botnets that propa-
gate through traditional (e.g., scanning, mass-mailing) tech-
niques. The ﬁrst victims will not know the address of subse-
quent victims, and have a P r(k) biased towards zero. One
solution is for the attacker to keep track of victims joining
their botnet, generate a desired topology overlay, and trans-
mit the edge sets to each bot.
Botmasters can easily select a desired (cid:4)k(cid:5) to generate
such a network. For example, they may select (cid:4)k(cid:5) ≤ 10, so
that bots appear to have ﬂow behavior similar to many peer-
to-peer applications [33, 49]. A botmaster could of course
select a higher (cid:4)k(cid:5), even one close to N to create a mesh,
but such structures quickly exhaust bot resources, and may
be easily detected by network administrators.
If existing botnets are not available to generate a ran-
dom graph, one solution was proposed by [13], where bots
could randomly scan the Internet to ﬁnd fellow bots. Al-
though noisy, this approach provides a last-resort technique
for botnet creation. Assuming random scanning up to L
connections, the resulting botnet would have a poisson k
distribution, and both the clustering and diameter properties
of a random graph.
2.6.2 Watts-Strogatz Small World Models
under gnutella or kazaa [45].
Another topology botnets can use is a Watts-Strogatz net-
work. In such a network, a regional network of local con-
nections is created in a ring, within a range r. Each bot is
further connected with probability P to nodes on the oppo-
site side of the ring through a “shortcut”. Typically, P is
quite low, and the resulting network has a length l ≈ log N .
See [4] for further discussion of small world networks.
Intuitively, we can imagine a botnet that spreads by pass-
ing along a list of r prior victims, so that each new bot can
connect to the previous r victims. To create shortcuts in the
small world, bots could also append their address to a grow-
ing list of victims, and with probability P connect back to a
prior bot. As noted in Section 3, we have witnessed only a
few anecdotal botnets that create prior victim lists, e.g., Zin-
dos [32]. To frustrate remediation and recovery, the lists are
typically small r ≈ 5. In the case of propagation-created
botnets, botmasters may prudently use P = 0, to avoiding
transmitting a lengthy list of prior victims. Otherwise, a bot
would have to append its address to a growing list of IPs
forwarded to each new victim. As noted above, if a botmas-
ter desired to have shortcuts in a small world botnet, they
could instead just use an existing botnet.
2.6.3 Barab´asi-Albert Scale Free Models
The previous botnet structures are characterized by varia-
tions in clustering, and each node exhibits a similar degree,
k ≈ (cid:4)k(cid:5).
In contrast, a Barab´asi-Albert network is dis-
tinguished by degree distribution, and the distribution of k
decays as a power law. Many real-world networks have an
observed power-law distribution of degrees, creating a so-
called scale free structure.
Scale-free networks contain a small number of central,