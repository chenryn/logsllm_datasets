Another technology for automatic patch generation is automated patch generation using error
report information. R2Fix is the typical tool for generating a patch automatically using error report
information, it is based on the fact that there are many errors in the developed software that have not
been modiﬁed due to a lack of resources to correct the already known errors [21]. R2Fix automatically
performs patches by combining error correction patterns, machine learning, and patch generation
techniques. R2Fix consists of three modules: Classiﬁers, Extractor, and Patch Generator. Classiﬁers
apply machine learning to collect error information from error reports and automatically categorize,
Extractors extract the general parameters (ﬁle name, version, etc.) and detailed information parameters
(buffer name, size, bound check condition, etc.) for each type of error, and lastly, the Patch Generator
generates and applies patch codes using modiﬁcation patterns. According to the study, R2Fix
performed a vulnerability patch for buffer overﬂow, null pointer reference, and memory leakage
in Linux kernels, Mozilla, and Apache. It also created 57 patches for common errors, ﬁve of them were
patches for new errors not expected by the developer.
Sustainability 2018, 10, 1652
5 of 12
Among the automatic patch generation technologies, there is a technique using patch information
written by experts. PAR is a representative tool for generating patches by automatically using patch
information written by experts [22]. It manually analyzes more than 60,000 patches to ﬁnd several
common patterns, and automatically generates patches based on those patterns. PAR creates patches
through a total of three steps: Fault Localization, Template-based Patch Candidate Generation,
and Patch Evaluation. The Fault Localization phase uses a statistical fault positioning algorithm
that assign weights to each running syntax based on a Positive/Negative test case. In this step,
the key assumption is that the syntax on which the Negative test case is executed is likely to be
faulty. First, it runs both test cases and records the route. The route is then divided into four groups,
(1) execution syntax visited by both groups; (2) execution syntax for visiting Positive only; (3) execution
syntax for visiting Negative only and (4) execution syntax not visited by both groups, and assigned
weights. The weights are 1.0 for (3), 0.1 for (1), and 0 for others. Depending on the weights assigned,
this creates a candidate patch on that position. During the Template-based Patch Candidate Generation
phase, a total of 10 modiﬁcation templates are applied, including Parameter Replacer, Method Replacer,
and Expression Replacer, for each fault location and each candidate patch. The generation of candidate
patches is carried out in three stages: (1) AST Analysis; (2) Context Check; and; (3) Program Edition.
Step (1), AST scan of the target program occurs and it analyzes the location of the error and its proximity.
Step (2) examine whether it is possible to modify the location with the modiﬁcation template and,
if applicable, create a candidate patch by rewriting the AST for the target program based on the script
that is predeﬁned in the modify template in Step (3). Finally, the Patch Evaluation phase evaluates
the suitability of the candidate patches created using the various test cases collected from the issue
trackers (Bugziila, JIRA, etc.) of the target program. For each candidate patch, the candidate patch
carrying out all test cases are selected and applied as ﬁnal patches.
3. Automated Vulnerability Detection and Remediation Method
Fuzzing works much faster than symbolic execution and is capable of exploring a deeper range
of code depths. However, it is difﬁcult for a fuzzer to explore widespread code. Symbolic execution
can discover possible paths of the program, but exploring is limited due to path explosion with
an explosive number of paths. Many types of hybrid fuzzers are available to complement these mutual
strengths and weaknesses. However, most hybrid fuzzers choose a vulnerability detection engine
without analyzing the target program. A program has complex parts such as loops and recursions that
are hard to explore, but some parts of the program are simply reachable. Accordingly, it is possible to
identify which parts are advantageous for fuzzing or symbolic execution. In this paper, we introduce
a binary analysis method to identify the advantageous areas for fuzzing and symbolic execution,
as shown in Figure 1.
Figure 1. Automated Vulnerability Detection and Remediation Architecture.
Sustainability 2018, 10, x FOR PEER REVIEW  5 of 12 Among the automatic patch generation technologies, there is a technique using patch information written by experts. PAR is a representative tool for generating patches by automatically using patch information written by experts [22]. It manually analyzes more than 60,000 patches to find several common patterns, and automatically generates patches based on those patterns. PAR creates patches through a total of three steps: Fault Localization, Template-based Patch Candidate Generation, and Patch Evaluation. The Fault Localization phase uses a statistical fault positioning algorithm that assign weights to each running syntax based on a Positive/Negative test case. In this step, the key assumption is that the syntax on which the Negative test case is executed is likely to be faulty. First, it runs both test cases and records the route. The route is then divided into four groups, (1) execution syntax visited by both groups; (2) execution syntax for visiting Positive only; (3) execution syntax for visiting Negative only and (4) execution syntax not visited by both groups, and assigned weights. The weights are 1.0 for (3), 0.1 for (1), and 0 for others. Depending on the weights assigned, this creates a candidate patch on that position. During the Template-based Patch Candidate Generation phase, a total of 10 modification templates are applied, including Parameter Replacer, Method Replacer, and Expression Replacer, for each fault location and each candidate patch. The generation of candidate patches is carried out in three stages: (1) AST Analysis; (2) Context Check; and; (3) Program Edition. Step (1), AST scan of the target program occurs and it analyzes the location of the error and its proximity. Step (2) examine whether it is possible to modify the location with the modification template and, if applicable, create a candidate patch by rewriting the AST for the target program based on the script that is predefined in the modify template in Step (3). Finally, the Patch Evaluation phase evaluates the suitability of the candidate patches created using the various test cases collected from the issue trackers (Bugziila, JIRA, etc.) of the target program. For each candidate patch, the candidate patch carrying out all test cases are selected and applied as final patches. 3. Automated Vulnerability Detection and Remediation Method Fuzzing works much faster than symbolic execution and is capable of exploring a deeper range of code depths. However, it is difficult for a fuzzer to explore widespread code. Symbolic execution can discover possible paths of the program, but exploring is limited due to path explosion with an explosive number of paths. Many types of hybrid fuzzers are available to complement these mutual strengths and weaknesses. However, most hybrid fuzzers choose a vulnerability detection engine without analyzing the target program. A program has complex parts such as loops and recursions that are hard to explore, but some parts of the program are simply reachable. Accordingly, it is possible to identify which parts are advantageous for fuzzing or symbolic execution. In this paper, we introduce a binary analysis method to identify the advantageous areas for fuzzing and symbolic execution, as shown in Figure 1.   Figure 1. Automated Vulnerability Detection and Remediation Architecture. Sustainability 2018, 10, 1652
6 of 12
Hybrid fuzzing based on binary analysis selects fuzzing and symbolic execution through binary
complexity metrics. Using the selected vulnerability search engine, it creates a new seed that causes
a state transition. The newly created seed is used to analyze the binary complexity again and repeats
the same process. Hybrid fuzzing based on a binary analysis will then proceed to the next ﬁve steps:
1.
2.
3.
4.
5.
Seed Selection: Seed selection is a step to select the input value to be used for vulnerability
detection.
In a ﬁrst iteration, a seed scheduler selects a seed deﬁned by the user to detect
vulnerability. From a second iteration, a new seed created by the seed generation engine is
selected for the next step.
Binary Analysis: A binary analysis module executes the target binary in an instrumentation
environment. As a binary is executed, disassembly code and function call information are
extracted through binary instrumentation. Binary complexity and vulnerability scores are
analyzed using the extracted information. The results of the complexity analysis determine
whether to run a fuzzer or symbolic executor to detect vulnerabilities. The results of the
vulnerability score will be used to determine whether a detected crash is exploitable in
future research.
Engine Selection: The engine selection module chooses one of the fuzzing and symbolic execution
engines according to the result of the complexity analysis. The symbolic execution engine
is executed if the complexity analysis result is smaller than a speciﬁc threshold; otherwise,
the fuzzing engine is selected.
Seed Generation: The fuzzer or symbolic executor is executed to generate seeds to be used in the
next iteration. The seed generation process is performed until a state transition occurs. When
a state transition occurs, the seed value that caused the state transition is stored in the seed DB.
Repeat.
For automated vulnerability remediation, the vulnerable function-based patch technique is
utilized to create a weak function list and modify the PLT/GOT with respect to the corresponding
functions, to induce a call to a safe function. This is an application of the mechanism of lazy binding
that the binary performs as a dynamic linking method to use a shared library. In addition, as shown in
Table 3, the vulnerable function list is composed of 50 functions that can cause each of the four types of
vulnerability, such as buffer overﬂow, format string, race condition, and multiple command execution.
Table 3. List of Vulnerable Functions by Vulnerability Type.
Vulnerable Functions
strcpy, wcscpy, stpcpy, wcpcpy, strecpy, memcpy, strcat, wcscat, streadd,
strtrns, sprintf, vsprintf, vprintf, vfprintf, gets, scanf, fscanf, vscanf, vsscanf,
sscanf, vfscanf, getwd, realpath
syslog, vsyslog, fprintf, printf, sprintf, vfprintf, vprintf, vsprintf, snprintf,
vsnprintf, vasprintf, asprintf, vdprintf, dprintf
tmpnam, tmpnam_r, mktemp
system, popen, execve, fexecve, execv, execle, execl, execvp, execlp, execvpe
Vulnerability Type
Buffer Overﬂow
Format String
Race Condition
Multiple Command Execution
3.1. Binary Analysis
3.1.1. Instrumentation
To extract binary information, we leveraged a QEMU instrumentation tool [23]. QEMU is
a virtualization tool that is often used for binary dynamic analysis. QEMU produces a TCG (tiny code
generator) that converts binary code to IL (intermediate language). After converting, QEMU inserts
a shadow value at the IL to extract the information we want to analyze. We utilize this instrumentation
function to obtain disassembly code information and function call information.
Sustainability 2018, 10, 1652
3.1.2. Complexity Analysis
7 of 12
We utilized the Halstead complexity metrics to analyze binary complexity. The metrics were
published in 1977 by Maurice Howard Halstead [24]. The metrics are intended to determine the
relationship between measurable properties and Software Complexity. The metrics were originally
developed to measure the complexity of the source code, but we applied it to measure the complexity
of the assembly code. We analyzed the binary complexity by measuring the number of operators and
operands in the assembly code using the metrics in Table 4.
Table 4. Halstead Complexity Metrics.
Classiﬁcation
Variable
Description
Variable
Complexity Formula
n1
n2
N1
N2
n
N
V = N × log2n
2 × N2
D = n1
n2
E = D × V
B = E
2
3
3000
Number of Operators
Number of Operands
Total Operators
Total Operands
n1 + n2
N1 + N2
Program Volume
Program Difﬁculty
Effort
Estimated Bugs
3.1.3. Vulnerability Scoring
When executing the binary, it traces all the function calls of the executed path. In the traced
function calls, we check whether a function from the vulnerable functions shown in Table 5 is called.
We assigned a vulnerability score separately for dangerous functions and banned functions as shown
in Table 5. The number of a called function, which is deﬁned as a dangerous function, is shown in
Table 5. We accumulate scores whenever a dangerous function or a banned function is called. We refer
to research on detecting vulnerabilities through software complexity and vulnerability scoring [25].
We are planning to extend this research to automatic exploit generation and automatic patch generation.
Table 5. Functions for Vulnerability Scoring.
Functions
scanf, fscanf, vscanf, vsscanf, sscanf, vfscanf, snprintf, vsnprintf, strtok, wcstok, itoa
strcpy, wcscpy, stpcpy, wcpcpy, strecpy, memcpy, strcat, wcscat, streadd, strtrns,
sprintf, vsprintf, vprintf, vfprintf, gets, getwd, realpath, syslog, vsyslog, fprintf,
printf, sprintf, vfprintf, vprintf, vsprintf, vasprintf, asprintf, vdprintf, dprintf
Vulnerability Score
0.5 (Dangerous)
1.0 (Banned)
3.2. Engine Selection
The Engine Selection Module choose between the fuzzing and symbolic execution engine through
a complexity analysis of the target binary. For the complexity analysis, the user deﬁned the threshold
value and put this value as an input of the engine selection. The number of operators, number of
operands, total operators, and total operands extracted from dynamic binary instrumentation are
used to measure program difﬁculty. If the program difﬁculty is lower than the threshold, the engine
selection module chooses the symbolic executor. If not, the fuzzer is selected. The algorithm for the
vulnerability detection engine selection is as follows.
Sustainability 2018, 10, 1652
8 of 12
Algorithm: Selection of Vulnerability Detection Engine
Input: Threshold T
Data: Difﬁculty D, n1, n2, N1, N2
Result: Seed S
function Engine Selection(T);
begin
D ← Complexity (n1, n2, N1, N2);
if D < T then
S ← Symbolic Executor();
S ← Fuzzer();
else
end
return S;
end
3.3. Fuzzing
We used AFL (American Fuzzy Lop), which is an evolutionary fuzzer using a genetic algorithm.
AFL performs fuzzing in three main steps. First, the AFL mutates the seed value with various bit
mutation strategies (e.g., interest bit ﬂip, subtract/add bit ﬂip). Second, the AFL continues to monitor
the execution status and records the state transition to expand code coverage. Third, the AFL trims
parts that do not affect the state transition to minimize the range of mutation. By repeating the above
three steps, the input value is developed in the direction of the state transition. We did not modify
the core engine of the AFL Fuzzer and considered only its coordination with the symbolic executor.
The Fuzzer operates when the binary analysis result is greater than the threshold.
3.4. Symbolic Execution
The Angr tool was used for Symbolic Execution. Angr utilizes Valgrind’s VEX IR to build
a symbolic execution environment. SimuVEX, which is a VEX IR emulator, produces an environment to
execute a symbolic state translated from binary through VEX IR. If the branch statement is encountered
while executing binary, the path predicate for the branch is generated and the z3 solver tries to solve
the constraint in the path predicate. Angr also provides various functions for analyzing the control
ﬂow graph. The main function is backward slicing, which helps to locate the source of a variable on
a program slice. We will develop this backward slicing function to ﬁnd the root cause of a vulnerability.
It produces two methods to recover the control ﬂow graph. We did not modify the symbolic execution
engine. The symbolic executor operates when the binary analysis result is less than the threshold.
3.5. Automatic Binary Patch
The execution ﬁle of the Linux environment is the ELF (Executable and Linkable File) format.
The structure of the ELF ﬁle is brieﬂy shown in Figure 2, of which the text section contains the code
necessary for execution. In this section, the code is the main () function and is the initialization for
conﬁguring the execution environment, consisting of argc/argv argument processing, stack setting,
library loading for normal execution of the main () function, and the termination processing code.
Figure 2. ELF ﬁle structure modiﬁcation.
Sustainability 2018, 10, x FOR PEER REVIEW  8 of 12 Algorithm: Selection of Vulnerability Detection Engine Input: Threshold T Data: Difficulty D, (cid:1866)(cid:2869),(cid:1866)(cid:2870),(cid:1840)(cid:2869),(cid:1840)(cid:2870) Result: Seed S function Engine Selection(T); begin D ← Complexity ((cid:1866)(cid:2869),(cid:1866)(cid:2870),(cid:1840)(cid:2869),(cid:1840)(cid:2870)); if D < T then S ← Symbolic Executor(); else  S ← Fuzzer(); end return S; end 3.3. Fuzzing We used AFL (American Fuzzy Lop), which is an evolutionary fuzzer using a genetic algorithm. AFL performs fuzzing in three main steps. First, the AFL mutates the seed value with various bit mutation strategies (e.g., interest bit flip, subtract/add bit flip). Second, the AFL continues to monitor the execution status and records the state transition to expand code coverage. Third, the AFL trims parts that do not affect the state transition to minimize the range of mutation. By repeating the above three steps, the input value is developed in the direction of the state transition. We did not modify the core engine of the AFL Fuzzer and considered only its coordination with the symbolic executor. The Fuzzer operates when the binary analysis result is greater than the threshold. 3.4. Symbolic Execution The Angr tool was used for Symbolic Execution. Angr utilizes Valgrind’s VEX IR to build a symbolic execution environment. SimuVEX, which is a VEX IR emulator, produces an environment to execute a symbolic state translated from binary through VEX IR. If the branch statement is encountered while executing binary, the path predicate for the branch is generated and the z3 solver tries to solve the constraint in the path predicate. Angr also provides various functions for analyzing the control flow graph. The main function is backward slicing, which helps to locate the source of a variable on a program slice. We will develop this backward slicing function to find the root cause of a vulnerability. It produces two methods to recover the control flow graph. We did not modify the symbolic execution engine. The symbolic executor operates when the binary analysis result is less than the threshold. 3.5. Automatic Binary Patch The execution file of the Linux environment is the ELF (Executable and Linkable File) format. The structure of the ELF file is briefly shown in Figure 2, of which the text section contains the code necessary for execution. In this section, the code is the main () function and is the initialization for configuring the execution environment, consisting of argc/argv argument processing, stack setting, library loading for normal execution of the main () function, and the termination processing code.  Figure 2. ELF file structure modification. Sustainability 2018, 10, 1652
9 of 12