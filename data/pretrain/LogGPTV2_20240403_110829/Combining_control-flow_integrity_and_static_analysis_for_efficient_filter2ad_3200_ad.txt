CFI.no-jt.no-skip (%)
3.47
14.72
3.84
14.45
1.05
3.23
1.01
3.77
2.52
4.14
2.46
5.73
0.09
0.14
0.04
0.09
11.47
25.28
15.28
34.11
13.87
82.03
13.61
81.73
26.78
67.66
28.39
72.96
6.36
22.18
6.32
22.29
4.04
4.74
3.18
5.68
7.74
24.90
8.24
26.76
Table 1: CFI runtime overheads for SPECint2000.
DS-W.CFI (%)
DS-RW.CFI.no-opt (%)
DS-RW.live (%)
DS-RW.live.in-place (%)
DS-RW.CFI (%)
gzip
6.21
384.34
24.38
24.29
23.66
vpr
5.82
429.38
28.06
26.69
25.12
gcc
2.29
129.36
6.30
5.81
4.96
mcf
crafty
gap
vortex
bzip2
twolf
average
1.80
12.80
13.16
29.77
14.18
7.55
10.40
452.51
8.15
5.13
4.53
523.66
39.67
39.12
37.70
1092.98
58.02
49.23
44.49
690.73
43.04
39.08
34.55
748.27
23.58
23.65
23.41
476.25
52.91
48.69
45.94
547.50
31.57
29.08
27.15
Table 2: Runtime overheads of data sandboxing plus CFI for SPECint2000.
tation is eﬃcient even though we have not yet implemented
sophisticated CFI optimizations.
Table 2 presents the runtime percentage increases for data
sandboxing. All numbers in the table include the CFI over-
head because our data-sandboxing optimizations build on
top of CFI. The row of DS-w.CFI contains the numbers
when sandboxing only the writes. The average overhead is
10.40%, which means it adds roughly 2.7% on top of CFI.
The overhead is low considering it sandboxes memory writes
and enforces CFI.
Table 2 also presents the overheads when sandboxing both
reads and writes. To understand the overhead reduction
of the three data-sandboxing optimizations, it presents the
overheads incrementally with respect to the optimizations.
The row of DS-RW.CFI.no-opt contains the numbers when
all optimizations are disabled.
In this case, a check is in-
serted before every memory access; scratch registers and the
ﬂags register are saved on and restored from the stack. Over-
heads are high because the saving and restoring registers and
the ﬂags register are costly. The row of ”DS-RW.CFI.live”
contains the numbers after performing liveness analysis to
remove unnecessary saving and restoring operations. After
this optimization, the overheads are signiﬁcantly lower. The
row of ”DS-RW.CFI.live.in-place” contains the numbers with
both liveness analysis and the technique of in-place sand-
boxing; this drives down about 2% of the overhead. Finally,
the last row contains numbers when optimizations based on
range analysis are turned on; they cut down another 2% of
the overhead. When all optimizations are turned on, data
sandboxing adds about 19% on top of CFI. The overhead
for protecting both reads and writes is modest and it is ac-
ceptable for applications where conﬁdentiality is of great
concern.
Performance comparison with related systems. We
next compare our system with PittSFIeld and XFI, two
systems that adopt software-only techniques for protection.
PittSFIeld reports an average of 21% for SPECint2000 for
sandboxing both memory writes and jumps. Our system has
a lower overhead (10.4% for CFI and write protection) and
provides stronger control-ﬂow integrity; it can additionally
sandbox memory reads with acceptable overheads.
To compare with XFI, we have evaluated our implemen-
tation on the Independent JPEG Group’s image-decoding
reference implementation. The XFI paper reports both fast-
path and slowpath overheads for the JPEG program; the
XFI fastpath overhead is directly comparable with our im-
plementation. The following table shows the performance
overheads of our implementation compared to XFI’s fast-
path implementation, for images of diﬀerent sizes. The
columns of DS-W.CFI and DS-RW.CFI report the numbers
of our system for write protection and read-write protection,
respectively. The columns of XFI-W and XFI-RW report
XFI’s numbers for write protection and read-write protec-
tion, respectively. In both cases, our implementation reports
lesser overheads. It seems that our optimizations are eﬀec-
tive at bringing down the overheads. Note the comparison
is preliminary as we have tested only on one program and
LLVM is a diﬀerent compiler from the one used in XFI.
Size DS-W.CFI DS-RW.CFI XFI-W XFI-RW
4k (%)
14k (%)
63k (%)
229k (%)
2.90
2.32
9.99
9.09
15.53
13.09
25.27
14.17
18
18
17
15
78
80
75
68
8. FUTURE WORK
We plan to implement more static-analysis based opti-
mizations. First, more aggressive loop optimizations based
on induction variable analysis should further bring down the
data sandboxing overhead. Second, CFI can also beneﬁt
from static analysis—an ID check for a computed jump is
unnecessary if the jump targets can be statically determined
to obey the control-ﬂow policy.
Our prototype implementation is built for x86-32 and we
have not addressed the portability issue. We plan to port
our implementation to newer architectures including x86-
64 and ARM. These architectures should beneﬁt more since
they do not have the hardware segmentation support.
SFI is a special kind of Inlined Reference Monitors (IRM [12,
13]). IRMs can enforce ﬁne-grained safety properties. Clearly,
the methodology of combining CFI with static analysis to
reduce the runtime overhead applies to general IRMs. For
instance, ﬁne-grained memory protection, which allows ac-
cess control of multiple data regions of small sizes [4, 5, 8],
can also beneﬁt from CFI-enabled optimizations. Dynamic
taint tracking is another example.
389. CONCLUSIONS
In this research, we have explored how CFI-enabled static
analysis can help build eﬃcient and validated system for
data sandboxing, for the case of protecting both integrity
and conﬁdentiality. We believe the combination of CFI and
static analysis provides a sweet point in design space for en-
forcing security policies on untrusted or buggy software: it
provides strong security, enables sound optimization strate-
gies, is thread safe, and can be easily integrated into the
software tool chain. The combination can possibly serve as
a foundation for improving eﬃciency of general inlined ref-
erence monitors for enforcing advanced security polices.
Acknowledgments
This research is supported in part by NSF grant CCF-0915157,
CCF-0915030, a research grant from Google, and by AFOSR
MURI grant FA9550-09-1-0539.
10. REFERENCES
[1] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti.
Control-ﬂow integrity. In 12th CCS, pages 340–353, 2005.
[2] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti.
Control-ﬂow integrity principles, implementations, and
applications. ACM Transactions on Information and
System Security, 13:4:1–4:40, Nov. 2009.
[3] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers:
Principles, Techniques, and Tools. Addison-Wesley,
Reading, MA, 1986.
[4] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro.
Preventing memory error exploits with wit. In IEEE S&P,
pages 263–277, 2008.
[5] P. Akritidis, M. Costa, M. Castro, and S. Hand. Baggy
bounds checking: An eﬃcient and backwards-compatible
defense against out-of-bounds errors. In 18th Usenix
Security Symposium, pages 51–66, 2009.
[6] J. Ansel, P. Marchenko, ´U. Erlingsson, E. Taylor, B. Chen,
D. Schuﬀ, D. Sehr, C. Biﬄe, and B. Yee.
Language-independent sandboxing of just-in-time
compilation and self-modifying code. In PLDI, pages
355–366, 2011.
[7] G. Balakrishnan and T. Reps. Analyzing memory accesses
in x86 executables. In 13th International Conference on
Compiler Construction (CC), pages 5–23, 2004.
[8] M. Castro, M. Costa, J.-P. Martin, M. Peinado,
P. Akritidis, A. Donnelly, P. Barham, and R. Black. Fast
byte-granularity software fault isolation. In SOSP, pages
45–58, 2009.
[9] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi,
H. Shacham, and M. Winandy. Return-oriented
programming without returns. In 17th CCS, pages 559–572,
2010.
[10] J. R. Douceur, J. Elson, J. Howell, and J. R. Lorch.
Leveraging legacy code to deploy desktop applications on
the web. In OSDI, pages 339–354, 2008.
[11] ´U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and
G. Necula. XFI: Software guards for system address spaces.
In OSDI, pages 75–88, 2006.
[12] ´U. Erlingsson and F. Schneider. SASI enforcement of
security policies: A retrospective. In Proceedings of the
New Security Paradigms Workshop (NSPW), pages 87–95.
ACM Press, 1999.
[13] ´U. Erlingsson and F. Schneider. IRM enforcement of Java
stack inspection. In IEEE S&P, pages 246–255, 2000.
[14] B. Ford and R. Cox. Vx32: Lightweight user-level
sandboxing on the x86. In USENIX Annual Technical
Conference, pages 293–306, 2008.
[15] T. Garﬁnkel, B. Pfaﬀ, and M. Rosenblum. Ostia: A
delegating architecture for secure system call interposition.
In NDSS, 2004.
[16] I. Goldberg, D. Wagner, R. Thomas, and E. A. Brewer. A
secure environment for untrusted helper applications:
Conﬁning the wily hacker. In Proceedings of the 6th
conference on USENIX Security Symposium, 1996.
[17] S. Ioannidis, S. M. Bellovin, and J. M. Smith.
Sub-operating systems: a new approach to application
security. In ACM SIGOPS European Workshop, pages
108–115, 2002.
[18] V. Kiriansky, D. Bruening, and S. Amarasinghe. Secure
execution via program shepherding. In 11th Usenix
Security Symposium, pages 191–206, 2002.
[19] P. Klinkoﬀ, E. Kirda, C. Kruegel, and G. Vigna. Extending
.NET security to unmanaged code. Internation Journal of
Information Security, 6(6):417–428, 2007.
[20] LLVM 2.8. http://llvm.org.
[21] S. McCamant and G. Morrisett. Evaluating SFI for a CISC
architecture. In 15th Usenix Security Symposium, 2006.
[22] M. Payer and T. R. Gross. Fine-grained user-space security
through virtualization. In Proceedings of the 7th ACM
SIGPLAN/SIGOPS international conference on Virtual
execution environments (VEE), pages 157–168, 2011.
[23] N. Provos. Improving host security with system call
policies. In 12th Usenix Security Symposium, pages
257–272, 2003.
[24] K. Scott and J. Davidson. Safe virtual execution using
software dynamic translation. In Proceedings of the 18th
Annual Computer Security Applications Conference,
ACSAC ’02, pages 209–218, 2002.
[25] D. Sehr, R. Muth, C. Biﬄe, V. Khimenko, E. Pasko,
K. Schimpf, B. Yee, and B. Chen. Adapting software fault
isolation to contemporary CPU architectures. In 19th
Usenix Security Symposium, pages 1–12, 2010.
[26] H. Shacham. The geometry of innocent ﬂesh on the bone:
return-into-libc without function calls (on the x86). In 14th
CCS, pages 552–561, 2007.
[27] J. Siefers, G. Tan, and G. Morrisett. Robusta: Taming the
native beast of the JVM. In 17th CCS, pages 201–211, 2010.
[28] C. Small. A tool for constructing safe extensible C++
systems. In COOTS’97: Proceedings of the 3rd conference
on USENIX Conference on Object-Oriented Technologies
(COOTS), pages 174–184, 1997.
[29] D. Song, D. Brumley, H. Yin, J. Caballero, I. Jager, M. G.
Kang, Z. Liang, J. Newsome, P. Poosankam, and
P. Saxena. BitBlaze: A new approach to computer security
via binary analysis. In Proceedings of the 4th International
Conference on Information Systems Security. Keynote
invited paper, Hyderabad, India, Dec. 2008.
[30] M. M. Swift, M. Annamalai, B. N. Bershad, and H. M.
Levy. Recovering device drivers. In OSDI, pages 1–16, 2004.
[31] R. Wahbe, S. Lucco, T. Anderson, and S. Graham. Eﬃcient
software-based fault isolation. In SOSP, pages 203–216,
New York, 1993. ACM Press.
[32] Z. Wang and X. Jiang. Hypersafe: A lightweight approach
to provide lifetime hypervisor control-ﬂow integrity. In
IEEE S&P, pages 380–395, 2010.
[33] Z. Xu, B. Miller, and T. Reps. Safety checking of machine
code. In PLDI, pages 70–82, 2000.
[34] B. Yee, D. Sehr, G. Dardyk, B. Chen, R. Muth,
T. Ormandy, S. Okasaka, N. Narula, and N. Fullagar.
Native client: A sandbox for portable, untrusted x86 native
code. In IEEE S&P, May 2009.
39