title:Profit: Detecting and Quantifying Side Channels in Networked Applications
author:Nicol&apos;as Rosner and
Ismet Burak Kadron and
Lucas Bang and
Tevfik Bultan
Proﬁt: Detecting and Quantifying Side Channels in
Networked Applications
Nicol´as Rosner∗, Ismet Burak Kadron∗, Lucas Bang†, and Tevﬁk Bultan∗
∗University of California Santa Barbara
{rosner, kadron, bultan}@cs.ucsb.edu
†Harvey Mudd College
PI:EMAIL
Abstract—We present a black-box, dynamic technique to
detect and quantify side-channel information leaks in networked
applications that communicate through a TLS-encrypted stream.
Given a user-supplied proﬁling-input suite in which some aspect
of the inputs is marked as secret, we run the application over the
inputs and capture a collection of variable-length network packet
traces. The captured traces give rise to a vast side-channel feature
space, including the size and timestamp of each individual packet
as well as their aggregations (such as total time, median size, etc.)
over every possible subset of packets. Finding the features that
leak the most information is a difﬁcult problem.
Our approach addresses this problem in three steps: 1) Global
analysis of traces for their alignment and identiﬁcation of phases
across traces; 2) Feature extraction using the identiﬁed phases;
3) Information leakage quantiﬁcation and ranking of features via
estimation of probability distribution.
We embody this approach in a tool called Proﬁt and ex-
perimentally evaluate it on a benchmark of applications from
the DARPA STAC program, which were developed to assess the
effectiveness of side-channel analysis techniques. Our experimen-
tal results demonstrate that, given suitable proﬁling-input suites,
Proﬁt is successful in automatically detecting information-leaking
features in applications, and correctly ordering the strength of the
leakage for differently-leaking variants of the same application.
I.
INTRODUCTION
Our world’s professional, governmental, and personal ac-
tivities are quickly migrating to networked software systems.
Standalone systems are becoming an artifact of the past.
To mitigate information leakage, most of the top-100 online
services are now using SSL/TLS encryption, and its adoption
by smaller websites and services is growing at a fast pace [24].
This is a positive step toward avoiding trivial leaks, but can
also provide a false sense of security. This kind of encryption
only hides the content of TCP/IP packet payloads. There is
still a plethora of visible metadata (e.g., packet sizes, timings,
directions, ﬂags) that can be obtained from message headers
and whose patterns may be exploitable as side channels. Side-
channel analysis of encrypted network trafﬁc has been used,
for example, to gain some knowledge about user keystrokes
during SSH connections [46], to identify medical conditions
of a patient from the encrypted trafﬁc generated by a healthcare
website [12], and to identify which app, among a known set of
ﬁngerprinted apps, is being used by a mobile phone user [47].
Network and Distributed Systems Security (NDSS) Symposium 2019
24-27 February 2019, San Diego, CA, USA
ISBN 1-891562-55-X
https://dx.doi.org/10.14722/ndss.2019.23536
www.ndss-symposium.org
Detecting network-based side channels requires searching
for correlations between sensitive information that the system
accesses (i.e., some kind of secret
inputs to the system)
and the outputs of the system that are observable over the
network. Packet traces are a complex form of output. Each
captured trace contains a large number of observable aspects,
including not just the size and the timing of each individual
packet, but also their aggregations over every possible subset
of packets. This results in an intractable number of potential
features to investigate for information leakage. Deciding which
features to analyze and quantifying the amount of information
leaked are challenging problems. We present Proﬁt, a tool
that, given a software application and a proﬁling-input suite,
determines whether and how much information leakage occurs
in a network stream for a particular secret of interest. Proﬁt
uses black-box proﬁling to build a model of the correlation
between the secret value associated with each input and the
observable side-channel outputs on the network. It does so by
successively running the set of inputs through the system and
capturing a set of packet traces (pcaps), each one labeled with
the secret value used to produce it. To identify the features that
leak information and to quantify the amount of information
leaked, Proﬁt uses a three-step approach:
1) Alignment and Phase Detection: We use multiple-sequence-
alignment techniques from genomics to align the packets
of captured traces. By studying recurrent patterns and
variations across aligned traces, we automatically identify
phases in the traces, which often reﬂect application-level
behavior such as a login phase, a ﬁle upload phase, etc.
2) Feature Extraction: We deﬁne a feature space that includes
observations about individual packets and about sequences
of packets (e.g., the time difference between two packets,
the total size of all packets). Phase detection allows us
to identify additional features that we would not consider
otherwise (e.g., total size of all packets in the third phase).
We also extract features from the full original traces.
3) Information Leakage Quantiﬁcation: We use information-
theoretic techniques based on Shannon entropy to quantify
the amount of information leaked by network observations
based on the features identiﬁed during phase detection and
feature extraction and the automatically inferred probability
distributions for features. After quantifying the leakage for
each extracted feature, we present the user with a ranking
of the features that are most worth looking into, sorted by
their amount of information leakage.
Combined, these three steps provide a black-box approach
for detecting and quantifying information leakage from appli-
cations that communicate over an encrypted network stream.
We experimentally evaluate Proﬁt using applications from
the DARPA Space/Time Analysis for Cybersecurity (STAC)
program [20], which are publicly available [21]. The STAC
applications are developed by DARPA to evaluate the effective-
ness of side-channel vulnerability detection techniques. They
are software systems that
• are of signiﬁcant size (often hundreds of classes)
• are hard to analyze statically
• are Web-based, client-server, or peer-to-peer
• communicate over TLS-encryped TCP streams
• require user inputs that are often complex and structured
(sequences of actions, ﬁle uploads, etc.)
Many of these applications contain a side-channel vulner-
ability that causes the value of some secret variable of interest
to be leaked, totally or partially, at the network packet level.
DARPA gave us applications that contained and that did not
contain vulnerabilities, without telling us which ones did. In
some cases they gave us multiple variants of each application,
each of which could potentially contain different vulnerabilities
that leak different amounts of information about the secret.
Since the challenge has ended, we now know (from our
own investigations and from DARPA’s ofﬁcial correct answers)
whether or not a side-channel vulnerability is present in each
of the application variants. We also know the most accurate
way to spot each vulnerability on the network. This allows
us to evaluate whether the ranking of top-leaking features
that Proﬁt generates is consistent with reality. In some cases
we also know the relative strength of the vulnerability in
different variants, allowing us to evaluate whether Proﬁt’s
leakage estimations are consistent with reality. For example,
a variant of a vulnerable application that contains a mitigated
version of a vulnerability should leak less than a variant that
contains the same vulnerability in full strength, and leak more
than a variant in which the vulnerability is not present at all.
Our experiments with the DARPA STAC benchmark show
that, given a suitable proﬁling-input suite, Proﬁt is able to
automatically identify features associated with the side-channel
vulnerabilities in these applications and quantify the amount of
information leaked by each feature, providing crucial insight
about the existence and severity of side-channel vulnerabilities.
The rest of the paper is organized as follows. In Section II
we give an overview of our approach and discuss two moti-
vating examples. In Section III we discuss the system model
that we use. In Section IV we present the trace alignment and
phase detection techniques. In Section V we present the feature
extraction and leakage quantiﬁcation techniques. In Section VI
we discuss the experimental evaluation of our approach using
the DARPA STAC benchmark. In Section VII we discuss the
limitations of our approach. In Section VIII we discuss the
related work. In Section IX we conclude the paper.
II. MOTIVATION AND OVERVIEW
Before we present the technical details of our analysis, we
discuss two examples that motivate our approach.
During the challenge we investigated the applications from
scratch, with almost no initial knowledge. In each case, we did
not know whether a vulnerability was present, and if so, what
parts of the code might cause it, which network packets might
be affected by it, and how. We were only told which was the
secret variable of interest, which gave us some hints regarding
which functionalities of the application to consider.
First example
TOURPLANNER is a client-server system. Given the names
of ﬁve cities that the user would like to visit, it can compute
a Hamiltonian circuit that minimizes certain costs. The secret
of interest speciﬁed by DARPA is the set of ﬁve cities that the
user wants to visit. In other words, we want to ﬁnd out whether
someone who can eavesdrop on the TLS-encrypted TCP trafﬁc
between client and server would gain information about the set
of cities that the user wants to visit. The eavesdropper could
build a statistical model by proﬁling the system beforehand
(that is, by interacting with it many times through the network).
Armed with such a proﬁle, they could inspect the packets
exchanged between another client and the server, and use the
statistical model to infer some information about the secret
value contained in that interaction.
Suppose that we have a proﬁling-input suite consisting
of many different queries (i.e., many random sets of ﬁve
cities). For each set in the suite, we send a “compute tour”
request to the server and receive the response. To account for
network noise, we can execute each input multiple times. All
trafﬁc is sniffed and recorded. This black-box proﬁling yields a
series of (cid:104)input, output(cid:105) pairs, where each output is a captured
packet trace ﬁle (pcap) that contains thousands of observables,
including every header of every layer of every packet. Even if
we focus only on the most important side-channel observables
(such as the time, size and direction of each packet), automat-
ically ﬁnding features that have maximum correlation with the
secret is a hard problem, since there are too many features.
Figure 1 (left side) shows a sample of 1,000 captured traces
that correspond to 100 different inputs, each one executed 10
times. We represent each packet with a bubble. The size of
the bubble is proportional to the size of the packet. The x-axis
shows the timestamp of each packet. The y-axis denotes the
trace number (i-th trace). It is hard to extract any information
by looking at the raw traces as they were captured. Even the
fact that each input was run multiple times is hard to see.
Figure 1 (right side) shows the same traces after a very
simple alignment: add an offset to each trace so that the ﬁrst
packet of every trace occurs at the same time. Now it is clear
that each input was repeated multiple times. More importantly,
visible patterns emerge which suggest that (i) the ﬁrst few
packets of each trace are not input-dependent, and (ii) some
of the inter-packet time differences (deltas) might be correlated
with the secret input (the set of ﬁve cities).
It turns out that, during the computation of the optimal tour,
the server sends some progress packets back to the client. The
four deltas shown in Figure 2 are affected by the time taken by
each step of the computation, and may be used as a ﬁngerprint
for the user’s query. Each one of the four deltas reveals some
information and has some correlation with the secret. When all
four delta-values are considered together, the resulting vector
in R4 bears a strong correlation with the secret.
2
growing trend of running open-source software components on
standardized cloud hardware.
GABFEED is another DARPA STAC application. It is a
Web-based forum. Users can post messages, search the posted
messages, engage in direct chat, etcetera. The server has a
private key that is used for authentication purposes.
The following situation arose during our exploration of
GABFEED. The secret variable that we were interested in
was the Hamming weight (number of ones) of the server’s
private key. We were studying the following interaction: A user
performs a search for something public and then, after an
authentication step, performs another search for something
nonpublic. (We would later conﬁrm that the delay between
two of the network packets that are spawned by this inter-
action is proportional to the Hamming weight of the binary
representation of the server’s private key.)
To build a proﬁle, we executed this interaction repeatedly,
using different server keys with varying Hamming weight, and
captured all network trafﬁc. However, examining pcaps by
hand (using a tool like WireShark [16]) is cumbersome. Even
when you do have some hypothesis about which packets might
be leaking information, verifying it by artisanally skimming
through thousands of packets is an extremely tedious task.
Considering that we had no hypothesis whatsoever as to which
packets might be leaking information, manual inspection of the
captured traces would have been a daunting endeavor.
An automated tool that can assist in such a search would
need to examine a vast feature space—not just the size of each
packet, its ﬂags, and its direction, but also all possible time
differences (deltas), all sums of sizes over all possible subsets
of packets, etcetera. This is infeasible for all but the shortest
network traces. Therefore, an appropriate feature space needs
to be automatically selected for further consideration.
Figure 3a shows the network trafﬁc captured by Proﬁt
for the GABFEED application for 50 successive interactions,
using many different server private keys with 12 different
Hamming weights for the key, and different search queries.
Each row represents a complete interaction (a captured trace)
as a sequence of packet sizes. Colors encode packet sizes and
direction. The color palette is intentionally not a gradient in
order to keep small variations visible.
In this example, the crucial feature is harder to characterize
due to the fact that both search operations introduce a variable
number of packets before and after the packet
leaks
information. As a consequence of this, even naming the crucial
feature in terms of the captured trafﬁc becomes difﬁcult, since
it is not “the i-th packet” for any consistent value of i.
that
In the general case, interactions with an application often
involve a sequence of actions, and some actions spawn a
non-constant number of packets. The captured traces can be
seen as consisting of several phases—subsequences of packets
that may correspond to different phases of application-level
behavior, e.g., uploading a ﬁle and then downloading another
one. Recurring patterns that appear across most of the traces
can be helpful for automatically detecting phase boundaries.
Figures 3b and 3c show the same 50 GABFEED traces
after being globally aligned and then separated into phases,
Fig. 1: TOURPLANNER: A sample of 1,000 traces obtained
by running 100 different inputs, 10 times each. Bubble size is
packet size. Left: raw packets from original pcap ﬁle. Right:
same data after a simple alignment based on the ﬁrst packet.
Fig. 2: Right side of Figure 1, magniﬁed for detail. The four
time differences shown with red arrows constitute a ﬁngerprint
in R4 that correlates with the secret.
Second example
One basic assumption of this work is that during proﬁling,
the Proﬁt user can control the secret value for each execution,
even if that value would not normally be publicly visible. This
is true in many real-world scenarios. In the most common
scenario, the Proﬁt user is a security analyst who is trying to
determine whether their own system leaks a certain secret. In
a different kind of scenario, an external attacker could build
a replica of a system, populate it with their own data, and
use it to build a proﬁle that can then be leveraged against the
real system. This scenario becomes increasingly likely with the
3
0.200.210.220.230.240.200.210.220.230.2410001200300400500600700800900100Trace numberTime (seconds)Time (seconds)10001200300400500600700800900100Raw packets as capturedAfter 1st-packet alignment(a) Traces as captured.
(b) After alignment.
(c) After splitting into phases.
Fig. 3: Trace alignment and phase detection (50 traces shown) for GABFEED. Colors represent different packet sizes.
(a) Feature: Time elapsed between ﬁrst and
last packets of the whole trace.
(b) Feature: Time elapsed between ﬁrst and
last packets of the ﬁfth phase of the trace.
(c) Feature: Time elapsed between packets
#3 and #4 of the ﬁfth phase of the trace.
Fig. 4: Probability densities for the top-leaking time-based features in the GABFEED example. X-axis is feature value in seconds.
Y-axis is probability. Different curves represent different secret values. Intuitively, features with less overlap between curves leak
more information—for a given observation of the feature value, there is less uncertainty about the secret value.
respectively, by Proﬁt. This process enables Proﬁt to synthesize
the crucial feature that successfully captures this side channel.
Figure 4 shows one plot for each of the three top-leaking
features among the numerous features that were considered by
Proﬁt during the leakage quantiﬁcation step. Each plot shows
the probability distributions for each value of the secret, i.e.,
for each Hamming weight of the private key.
Without knowledge of phases, the best (i.e., most-leaking)
feature that Proﬁt can report is the time elapsed between the
ﬁrst and last packets of each trace—that is, the duration of
each trace. Since there are 12 different values of the secret
(Hamming weight of key), there are log2 12 = 3.58 bits of
secret information. Proﬁt quantiﬁed the leakage of this feature
as roughly 40% of the secret information (1.44 of 3.58 bits).
Figure 4a shows the probability density functions inferred
by Proﬁt. Each curve represents one possible value of the
secret. Intuitively, the leakage of 40% is much less than 100%
because of the signiﬁcant overlap between the distributions,
yet well above 0% because there is some degree of certainty
(the ﬁrst and last curves, for instance, are almost completely
non-overlapping).
With phase knowledge, Proﬁt can consider more reﬁned