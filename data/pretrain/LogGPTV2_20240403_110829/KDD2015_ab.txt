ability of observing a sample at time t. Depending on the desired level of sensitivity, one can measure if a given sam-
bution. 	ple lies within the 95.45% or 68.27% of all the samples forK = 2 or 1 respectively. Note that the assumption here was
We believe the model-based change point detection methods are more useful than the absolute methods in the practical applications. This is because the change points are mean-ingful as much as our models cannot explain the behavior of the time-series after a certain time point. However, if the model can explain the time-series behavior even after an ab-solute change point, from the practical point of view, there is no reason for us to consider that time point as a change point. In other words, the change points are relative to the underlying model used to explain the behavior of the time-series, which in turn gives rise to the relative change-point detection techniques.that our deviation metrics are normally distributed.
The second approach is non-parametric and is useful for the cases when the deviation metric is not normally distributed. The basic idea is to to find low density regions of the devi-ation metric distribution. One approach is to use an algo-rithm such as Local Outlier Factor (LOF) [3] which is based on a concept of a local density, where locality is given by nearest neighbors, whose distance is used to estimate the density. By comparing the local density of an object to the local densities of its neighbors, one can identify regions of similar density, and points that have a substantially lower density than their neighbors. 	These are considered to be3.3 Detecting Anomalous Time-series outliers.
Another class of anomaly detection techniques supportedby EGADS involves detecting anomalous time-series. 	An anomalous time-series T is defined as a time-series whose average deviation from the other time-series is significant. Assuming all time-series are homogeneous and come from the same source (i.e. 	are part of the same cluster) one can simply compute the average deviation for time-series (i) relative to other time-series. 	In EGADS our current approach involves clustering the time-series into a set of clusters C based on various time-series features including trend & seasonality, spectral entropy, autocorrelation, av-erage Euclidean distance etc. After clustering we perform intra or inter-cluster time-series anomaly detection by mea-suring the deviation within or among the cluster centroids and the time-series (i). A common use-case for this EGADS anomaly detection type involves triaging. For example if a network engineer wants to find an anomalous server amongst millions of time-series, it can be impractical with the pre-vious approaches because the modeling is done on the per time-series basis without taking into account the behavior of other metrics. Another application of this anomaly detec-tion type is in finding similar anomalies, which is the inverse of the previous use-case.4.2 	Filtering 
Filtering performs the last stage post-processing on the anoma-lies which are then delivered to the consumer. While the candidate anomalies, which are the input to the filtering stage, are statistically significant, not all of them will be rel-evant for a particular use-case. For example some consumers are interested in spikes in the time-series, while others are interested in dips, yet others are interested in change points.EGADS provides a simple and intuitive interface which al-lows users to mark the regions of the time-series that are anomalous. This feedback is then used by EGADS together with time-series and model features to train a classifier that predicts if an anomaly ai is relevant to user uj. The time-series features tracked by EGADS are shown in Table 1 and Section 6.4 explores are described in more detail in [25].the performance of a filtering module for a specific use-case.
Like other components of EGADS, the filtering component is extensible in terms of models and features.
| Time-series feature | Description |
|---|---|
| Periodicity (frequency) |Periodicity is very important for de-termining the seasonality. |
| Trend |Exists if there is a long-term change in the mean level || Seasonality |Exists when a time series is influ-enced by seasonal factors, such as month of the year or day of the week |
| Auto-correlation |Represents long-range dependence. |
| Non-linearity |A non-linear time-series contains complex dynamics that are usually not represented by linear models. |
| Skewness |Measures symmetry, or more pre-cisely, the lack of symmetry. || Kurtosis |Measures if the data are peaked or flat, relative to a normal distribu-tion. |
| Hurst |A measure of long-term memory of time series. |
| Lyapunov Exponent |A measure of the rate of divergence of nearby trajectories. |
Table 1: Time-series features used by EGADSFigure 2 shows the feature profile of a sample time-series. Note that the metrics beginning with dc are obtained on the adjusted time-series (i.e. after removing trend and sea-sonality). In Section 6.2 we look at how these time-series characteristics impact the model performance.
5. 	RELATED WORKThere are a number of anomaly detection techniques in the literature. The techniques range from point anomaly detec-tion algorithms to change-point detection algorithms. In [21] authors propose an outlier detection technique based on hy-pothesis testing, which is very accurate at detecting extreme outliers. In fact Twitter, [23], uses [21] in conjunction with piecewise approximation of the underlying long-term trends to remove many of the false positives. Twitter’s approach is fast and enjoys an impressive precision and recall, however it is specific to the use-case of Twitter. There are also a number of open-source point anomaly detection techniques available including [24, 15].a given anomaly category of interest. Therefore, based on the observation that ‘One Size Fits All’ is a myth in the anomaly detection world, EGADS uses a strategy where a collection of well trained anomaly detection models with a post-processing use-case-specific anomaly filtering stage is used.
6. 	EXPERIMENTAL STUDY 
We present the experiments for the modeling, anomaly de-tection and alerting components of EGADS next.6.1 	DataThe dataset used for the experiments is comprised of a mix-ture (50/50) of synthetic and real data. We have created a synthetic time-series generation tool that is being open-sourced along with the framework and the benchmarking data. Using the tool, each synthetic time-series is generated by specifying the length, magnitude, number of anomalies, anomaly type, anomaly magnitude, noise level, trend and seasonality. These parameters are picked from a fixed distri-bution. The real dataset is comprised of Yahoo Membership Login (YML) data. The YML data tracks the aggregate sta-tus of user logins to the Yahoo network. Both the synthetic and real time-series contain 3000 data-points each, which for the YML data represent 3 months worth of data-points. Unless otherwise stated, all experiments were run on 1000 randomly picked time-series and the results were averaged. Also note that both the synthetic and real-time data have anomaly labels, that are either synthetically or editorially generated, allowing us to measure precision and recall.6.2 	Modeling Experiments 
Time-series modeling (captured by the TMM component in EGADS) is a fundamental part of anomaly detection. 	It is often the case that the anomaly detection is as good as the underlying time-series model. Due to a large number of candidate models, model-selection becomes critical and depends upon time-series characteristics and available re-sources. 	In the experiments that follow, we demonstrate the impact of time-series features on the model performance and show the trade-off between accuracy, memory usage and training time. The models and the error metrics used in the experiments are described in Tables 2 and 3 respectively. More details about the models and the metrics can be found| Authors in [13] provide an anomaly detection technique that finds ‘Change Points’ or ‘Level Shifts’. Change Points (CP) are different form point anomalies or point outliers in that CP reflect a change in underlying statistic of the time-series | in [10] and [25]. | in [10] and [25]. |
|---|---|---||---|---|---|
| Authors in [13] provide an anomaly detection technique that finds ‘Change Points’ or ‘Level Shifts’. Change Points (CP) are different form point anomalies or point outliers in that CP reflect a change in underlying statistic of the time-series |6.2.1 |Time-series Characteristics and || Authors in [13] provide an anomaly detection technique that finds ‘Change Points’ or ‘Level Shifts’. Change Points (CP) are different form point anomalies or point outliers in that CP reflect a change in underlying statistic of the time-series |Model Performance |Model Performance |
(e.g., Mean shift). CP typically occurs in a time-series with a launch of a new product feature or a new platform. There are a number of open-source change point detection algo-To demonstrate the impact of time-series features on model performance we compare the error metrics of different mod-els when fitting time-series with different features (see Sec-
rithms available including [14]. 	tion 4.2). 	Figure 3 shows that time-series characteristics
play an important role in model behavior. 	For example
In our experience, a particular anomaly detection algorithm 	the Olympic Model, which is a seasonal model, performsis usually applicable to only a specific use-case. 	As au-	poorly on a dataset with no seasonality and a strong trend.
thors in [1] mention the anomalies will have typically a high anomaly score, but the high score alone is not a distin-guishing factor for an anomaly. Rather, it is the analyst, who regulates the distinction between noise and anomaly. Similarly, authors in [4] provide a concise overview of the anomaly detection technique per category, citing the factEGADS keeps track of the historic time-series characteris-tics and model performance. Using this historical informa-tion, EGADS selects the best model (given the time-series features) judged by the error metrics described in Table 3. In practice, performing model selection based on the data features is much faster than performing cross-validation for
that only a set of anomaly models are most appropriate for 	every model.Figure 2: An example of the time-series and its characteristics extracted by EGADS. These characteristics are used by EGADS for filtering and model selection.
| Model | Description |
|---|---|
| Olympic  Model 	(Sea-sonal Naive) |The naive seasonal model where the pre-diction for next point is a smoothed aver-age over previous n periods. || Exponential Smoothing  Model |smoothed time-series. Double and Triple exponential smoothing variants add trend and seasonality into the model. the ETS model used for the experiments auto-matically picks the best ‘fit’ exponential smoothing model. || Moving  Average  Model |In this mode, the forecast is based on an artificially constructed time series in which the value for a given time period is replaced by the mean of that value and the values for some number of preceding and succeed-ing time periods. 	The Weighted Moving Average and Naive Forecasting Model are special cases of the moving average model. || Regression Models |Models the relationship between x & y us-ing one or more variable. |
| ARIMA |Autoregressive integrated moving average. |
| (T)BATS Family |state space model with Box-Cox transfor-mation. |
Table 2: Models Used for Modeling Experiments
| Model | Description |
|---|---|
| Bias |The arithmetic mean of the errors. |
| MAD |The mean absolute deviation. Also known as MAE. || MAPE |The mean absolute percentage error. |
| MSE |The mean square of the errors. |
| SAE |The Sum of Absolute Errors. |
| ME |Mean Error. |
| MASE |Mean absolute scaled error. |
| MPE |Mean percentage error. |
Table 3: Metrics Used for Modeling Experiments
6.2.2 	Time-series Model Scalability6.2.2 	Time-series Model Scalability 
As discussed in Section 2 it is often prohibitive to build mod-els for every time-series and optimization techniques are re-quired to support real-time performance over massive (e.g., millions of points every second) data-streams. A fundamen-tal optimization performs a trade-off between model size, 	Such a trade-off is shown in training time and accuracy.Figures 4(a) and 4(b). From the figure, for example, it is clear that the Seasonal Naive model is quick to train but has a relatively large memory requirement and a high average error. At Yahoo, a target in terms of resources and training time is first set and then the models are picked accordingly. In other words, the objective is to minimize the errors in Table 3 subject to the resource and model building time constrains. Other optimization techniques including time-series sampling and model sharing are being investigated.(a) Model performance on TimeSeries with trend.
(b) Model performance on TimeSeries with seasonality.
Figure 3: Model performance on time-series with varying characteristics.
(a) Model Tradeoff: Model Size vs Training Time
(b) Model Accuracy
Figure 4: Model trade-offs
6.3 	Anomaly Detection Experiments 
In this section we compare open source system against EGADS.The open source systems considered are shown in Table 4.
The results on the data described in Section 6.1 are shown in Figure 5. The results are compared in terms of the stan-precision+recall. The results indicate dard F1-Score = 2 ×precision×recall that there is no best anomaly detection model for all use-cases. In particular different algorithms are best at detec-tion different types of anomalies. For example Twitter [13] performs best on dataset TS-2 while ExtremeLowDensity model is best on TS-3. These datasets contain a mixture of anomaly types (e.g., outliers, change-points), and one might argue that comparing an algorithm that is only meant for change-point detection is not fair. Recall, however, that the motivation for EGADS was that the user should be agnostic to the type of time-series and the type of anomalies that are in the data. The system must be able to gracefully and robustly deal with a wide variety of anomalies present in the data. For this reason, EGADS is built as a library that combines a set of anomaly detection models into a single framework. The anomalies from these models are forwarded to the filtering component for accurate anomaly detection.6.4 	Anomaly Filtering Experiments 
The importance of an anomaly often depends on the use-case. Specifically, some users may be interested in the time-series behavior that exhibits a malicious attack, while oth-ers may be interested in revenue drops. Yahoo Membership (YM) use-case refers to the former set of users. Specifically
Figure 5: Anomaly model performance on different datasets. Observe that there is no single model that is best on all datasets.for the YM use-case, editors supplied feedback to EGADS