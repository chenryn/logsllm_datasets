large ﬁle. The redline in Figure 6(e) represents this result.
Consistent with the results of ELISE, when using more and
more data to train the model, the compression ratio gets lower
and lower.
Finetuning with entire data. Similar to the experiments for
ELISE, we also evaluate the effect of ﬁnetuning DeepZip by
splitting 10 ﬁles (L0 to L9) from the Lin-16.1G log ﬁle. The
size of each ﬁle is 200 MB. A model is pretrained on data ﬁle
L0, and ﬁnetuned on the rest 9 ﬁles, L1 to L9. We present the
result in Figure 6(f). As we can see, some compression ratios
are low while others are high. This is because DeepZip can
only identify simple contextual redundancy (but not structural
Table 3: The Results of Forensic Analysis of 3 Starting nodes.
Experiment
Number of Related Activities
Original Data
ELISE
Graph Match
1
2
3
320
199
69743
320
199
69743
!
!
!
and complex contextual redundancy, such as monotonous val-
ues and sessions). As a result, when the contexts in test ﬁles
(i.e., L1 to L9) and the training ﬁle (i.e., L0) are similar, us-
ing this pre-trained model can get low compression ratios,
and vice versa. This result demonstrates the advantage of
using ELISE. By applying preprocessing rules, ELISE can
capture all types of contextual and structural redundancies,
and achieve good results even when the workloads are differ-
ent.
Finetuning with partial data. Similar to ELISE, we also try
ﬁnetuning with partial data in DeepZip. Speciﬁcally, we pre-
train a model on a 200 MB ﬁle split from Lin-7.7G, and
ﬁnetune it on different percentage of another 200 MB ﬁle.
The blue line in Figure 6(e) shows the compression ratios in
different settings. It shows a similar trend with using partial
data training, and also a consistent trend with that of ELISE.
4.5 Supports of Security Investigation
As a lossless compression, ELISE naturally supports all log
based security applications. To verify this, we perform log
based security incident investigations using the log from
DARPA transparent computing (TC) project Engagement 5
and compare the results with existing work [41, 42] to see if
ELISE can produce the same results. These tasks are forensic
analysis aiming to generate a provenance graph from log data
and analyze the attack activity by searching 1 backward in
the graph to ﬁnd all malicious events that may have led to this
activity, and 2 forward to ﬁnd affected ﬁles, processes, etc.
For each task, we start from a system subject or object as the
starting point, and compare the results of using ELISE and
raw log. Table 3 summarizes the results for these three exper-
iments including the number of nodes shown in the generated
graphs using unmodiﬁed log and ELISE (columns 2 and 3,
respectively). We also manually check if the graphs match or
not (results in column 4 of Table 3). As indicated by the table,
ELISE can fully support the log based security analysis.
5 Discussion
As demonstrated by DeepZip and ELISE, DNN based data
compression has shown great potential. In some cases, it can
reduce 10 times or even more space overhead compared with
traditional compression methods like Gzip. On the other hand,
DeepZip has a signiﬁcantly high runtime overhead. ELISE
3036    30th USENIX Security Symposium
USENIX Association
has proposed novel techniques to alleviate this problem, mak-
ing it practically usable. Gzip still outperforms DNN based
compressions. Since real world logs are quite large, even a 1%
lower compression ratio can save GBs of storage space per
day in a large organization. Meanwhile, individual log ﬁles
are only decompressed when needed. We think that ELISE is
still valuable in practice. We also envision that with better
DNN inference optimization techniques such as inference
accelerate hardware (e.g., AI chips) and frameworks, model
compression and other potential techniques, the runtime of
ELISE can be further optimized.
In the future, there are a few promising research directions
based on proposed work. i) Optimizing ELISE runtime. As
mentioned earlier, ELISE still suffers from high runtime over-
head compared with Gzip. Optimizing the runtime of ELISE
is important. Based on results in Section 4, we know that the
inference of DNN is the most time-consuming step in ELISE,
which can be optimized and is currently an important topic
in the ML community as well. There are already existing
methods, such as using inference frameworks or hardware,
leveraging pre-trained model, and compressing large model.
ii) Optimizing preprocessing and model training. Finding
other redundancies in log ﬁle and designing new preprocess-
ing for it can potentially improve the compression efﬁciency.
Similarly, the training procedure can potentially be optimized
by using better model architectures or loss functions. We sus-
pect that a lot of existing AutoML techniques can be altered
to ﬁt in this application scenario and provide better results. iii)
Integrating ELISE in Existing Systems. ELISE is orthogonal to
many existing techniques, such as redundancy reduction tech-
niques like LogGC [37] when the security application is ﬁxed.
Thus, we believe that ELISE can be integrated to existing
provenance system and logging system pipelines. Exploring
how this can be done is also an interesting direction.
6 Related Work
Besides the directly related works regarding data compression
and log reduction discussed in Section 2, ELISE is highly
related to log analysis.
Existing threat detection approaches usually learn the pat-
tern of normal behaviors from logs and detect threats if they
behave differently. Some work deﬁnes normal patterns as
single event matching rules [2, 3, 39], and detect potential
threats by comparing an activity with such predeﬁned rules
learned from historical logs. Forrest et al. [15] uses a ﬁxed
size sequence of syscalls to help identify normal behaviors of
UNIX processes. Other work [11, 59] improves the intrusion
using variable size sequence.
For APTs, many approaches leverage contextual infor-
mation of events to analyze the provenance graph so that
it reduces the false positive alarms in detection. Some of
them [22,44] utilize the information provided by log to create
either static or dynamic normal behavior models for threat
detection. If an activity does not belong to any normal behav-
ior models, it will be treated as an intrusion. SOTA system
in this kind, Unicorn [21] achieves better detection results by
learning several normal behavior models from log data.
Moreover, NoDoze [26] exploits historical system execu-
tion information integrated in system logs to learn normal
behavior patterns. It assigns higher anomaly values to rarely
occurring events counted from the historical log. Then, it
propagates and updates the anomaly value of each event with
its casually related events. Finally, it reduces a large number
of false intrusion alerts by ﬁltering out warnings with lower
anomaly values. These methods, which utilize historical logs
to learn the contextual information, require logs collected for
a long time.
Many security analyses leverage provenance graphs, such
as forensic analysis and attack attribution [5, 51]. Provenance
graphs provide a big picture of the whole attack by backward
tracing [32] the events that led to the alert, and forward search-
ing [38] the consequences of the attack. HERCULE [50]
reconstructs the attack history using community discovery
on correlated log graphs. NoDoze [26] selects the malicious
path in the provenance graph. Because provenance analysis is
usually performed on a large provenance graph that contains
much information, Lee et al. [36] propose to use execution par-
tition to simplify the provenance graph. ProTracer [42] further
designs a lightweight tracing system to mitigate this problem
and reduce runtime overhead. A lot of existing work [28, 49]
focuses on similar topics and removes redundant information
of the provenance graph to improve usability.
7 Conclusion
In this paper, we propose and build novel lossless data com-
pression techniques to build a storage efﬁcient logging sys-
tems, ELISE. By leveraging a few preprocessing steps, ELISE
is able to reduce structural and contextual redundancies that
existing techniques cannot reduce, and convert hard to train
natural languages in logs to numerical formats. Moreover, it
uses a deep neural network based representation learning tech-
nique to train an optimal encoder that can represent the same
contents with shorter binary strings. Our evaluation shows
that ELISE beats existing lossless compression techniques by
1.13− 12.97 times with less than 20% overhead compared
with methods in its kind.
Availability
ELISE is hosted on GitHub. To facilitate the reproducibility of
this paper and deployment of such systems, we also provide
ready-to-use containers. The code can be found at https:
//github.com/dhl123/ELISE-2021
USENIX Association
30th USENIX Security Symposium    3037
References
[1] Logstash. Website, 2020. https://www.elastic.co/cn/logsta
sh.
[2] How many alerts is too many to handle. https://www.fireeye.co
m/offers/rpt-idc-the-numbers-game.html., 2021.
[3] Insider threat detection. https://www.netwrix.com/insiderthr
eatdetection.html., 2021.
[4] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving,
Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry
Moore, Derek Gordon Murray, Benoit Steiner, Paul A. Tucker, Vijay Va-
sudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng.
Tensorﬂow: A system for large-scale machine learning. In Kimberly
Keeton and Timothy Roscoe, editors, 12th USENIX Symposium on
Operating Systems Design and Implementation, OSDI 2016, Savannah,
GA, USA, November 2-4, 2016, pages 265–283. USENIX Association,
2016.
[5] Adam Bates, Dave Jing Tian, Kevin RB Butler, and Thomas Moyer.
Trustworthy whole-system provenance for the linux kernel. In 24th
{USENIX} Security Symposium ({USENIX} Security 15), pages 319–
334, 2015.
[6] Fabrice Bellard. Lossless data compression with neural networks.
https://bellard.org/nncp/nncp.pdf, 2019.
[7] François Chollet et al. Keras. https://keras.io, 2015.
[8] John G. Cleary and Ian H. Witten. Data compression using adaptive
coding and partial string matching. IEEE Trans. Commun., 32(4):396–
402, 1984.
[9] John G. Cleary and Ian H. Witten. Data compression using adaptive
coding and partial string matching. IEEE Trans. Commun., 32(4):396–
402, 1984.
[10] David Cox. Syntactically informed text compression with recurrent
neural networks. arXiv preprint, arXiv:1608.02893, 2016.
[11] Hervé Debar, Marc Dacier, Mehdi Nassehi, and Andreas Wespi. Fixed
vs. variable-length patterns for detecting suspicious process behavior.
In Jean-Jacques Quisquater, Yves Deswarte, Catherine A. Meadows,
and Dieter Gollmann, editors, Computer Security - ESORICS 98, 5th
European Symposium on Research in Computer Security, Louvain-la-
Neuve, Belgium, September 16-18, 1998, Proceedings, volume 1485 of
Lecture Notes in Computer Science, pages 1–15. Springer, 1998.
[12] David Devecsery, Michael Chow, Xianzheng Dou, Jason Flinn, and
Peter M. Chen. Eidetic systems.
In Jason Flinn and Hank Levy,
editors, 11th USENIX Symposium on Operating Systems Design and
Implementation, OSDI ’14, Broomﬁeld, CO, USA, October 6-8, 2014,
pages 525–540. USENIX Association, 2014.
[13] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. Deeplog:
Anomaly detection and diagnosis from system logs through deep learn-
ing.
In Bhavani M. Thuraisingham, David Evans, Tal Malkin, and
Dongyan Xu, editors, Proceedings of the 2017 ACM SIGSAC Confer-
ence on Computer and Communications Security, CCS 2017, Dallas,
TX, USA, October 30 - November 03, 2017, pages 1285–1298. ACM,
2017.
[14] En.Wikipedia.Org.
2020 united states federal government data
breach. https://en.wikipedia.org/wiki/2020_United_State
s_federal_government_data_breach, 2021.
[15] Stephanie Forrest, Steven A. Hofmeyr, Anil Somayaji, and Thomas A.
Longstaff. A sense of self for unix processes. In 1996 IEEE Symposium
on Security and Privacy, May 6-8, 1996, Oakland, CA, USA, pages 120–
128. IEEE Computer Society, 1996.
[16] Qiang Fu, Jian-Guang Lou, Yi Wang, and Jiang Li. Execution anomaly
detection in distributed systems through unstructured log analysis. In
Wei Wang, Hillol Kargupta, Sanjay Ranka, Philip S. Yu, and Xindong
Wu, editors, ICDM 2009, The Ninth IEEE International Conference
on Data Mining, Miami, Florida, USA, 6-9 December 2009, pages
149–158. IEEE Computer Society, 2009.
[17] Ashvin Goel, Kenneth Po, Kamran Farhadi, Zheng Li, and Eyal de Lara.
The taser intrusion recovery system. In Andrew Herbert and Kenneth P.
Birman, editors, Proceedings of the 20th ACM Symposium on Operating
Systems Principles 2005, SOSP 2005, Brighton, UK, October 23-26,
2005, pages 163–176. ACM, 2005.
[18] Noah Golmant, Nikita Vemuri, Zhewei Yao, Vladimir Feinberg, Amir
Gholami, Kai Rothauge, Michael W. Mahoney, and Joseph Gonzalez.
On the computational inefﬁciency of large batch sizes for stochastic
gradient descent. arXiv preprint, arXiv:1811.12941, 2018.
[19] Mohit Goyal, Kedar Tatwawadi, Shubham Chandak, and Idoia Ochoa.
Deepzip: Lossless data compression using recurrent neural networks.
In Ali Bilgin, Michael W. Marcellin, Joan Serra-Sagristà, and James A.