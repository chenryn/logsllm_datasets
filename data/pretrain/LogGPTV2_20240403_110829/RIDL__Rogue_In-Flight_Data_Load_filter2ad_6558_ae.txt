SGX
Cross-address space
XPC SP‡ XVM
Victim
cooperation
Valid address
translation
(cid:2)
(cid:2)
(cid:2)
Direct branch
Indirect branch
Return stack
Control Speculation
BCB{S} [2], [5]
BTI [2], [70]
RSB [4], [71]
Data Speculation
SSB [72]
RDCL [1]
RSRR [73]
LazyFP [74]
L1TF [75]
RIDL
SB = Sandbox, SP† = Supervisor pre-KPTI, SP‡ = Supervisor post-KPTI, XPC = Cross-process, XVM = Cross
Virtual Machines
L1D
FPU
L1D
LFB
Disambiguation
Memory
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
TABLE III: List of existing mitigations against currently disclosed speculative execution attacks grouped based on the nature of
the defense.
Inhibit trigger
Hide Secret
Attacks
LFENCE[76]
IRBS,IBPB
STIBP[76]
SSBD[44]
RSRR
Fix[73]
Retpoline[6]
RSB
Filling[77]
EagerFPU[74]
ArrayIndex
Masking[7]
KPTI[9]
Multi-Process
Isolation[63]
Flushing[78]
L1D
HyperClear[50]
Inversion[78]
PTE
G
G
G
G
Control Speculation
BCB{S} [2], [5]
BTI [2], [70]
RSB [4], [71]
Data Speculation
SSB [72]
RDCL [1]
RSRR [73]
LazyFP [74]
L1TF [75]
RIDL
G = Generic, SB = Sandbox, SP† = Supervisor pre-KPTI, XPC = Cross-process, XVM = Cross Virtual Machines,
SB,
SGX
SP†
SP†
SB
SB
SB
XVM
SB
G
G
G
G
G
G
Indirect branches and calls: These branches are also
targets of speculative execution optimizations. The Branch
Target Buﬀer (BTB) is a unit embedded in modern CPUs
that stores a mapping between the source of a branch
or call instruction and its likely destination. An attacker
running on the same physical core of the victim can
poison the BTB to perform attacks known as Branch
Target Injection (BTI). The attacker pollutes the buﬀer
by injecting arbitrary entries in the table to divert the
victim’s indirect branches to the target of interest—within
the victim address space. No checks are performed on
the pid, hence the possibility of cross-process mistraining.
This makes it possible to build speculative code-reuse (e.g.,
ROP) attacks to leak data. Branch target injection has
been demonstrated eﬀective to escape sandboxed environ-
ments (e.g., JavaScript sandbox) [2], to build cross-process
attacks [2] and to leak data from SGX enclaves [70].
Return speculation: The use of the BTB is ineﬃcient for
the prediction of return instructions, as functions may have
many diﬀerent call sites. Therefore, modern processors
employ a Return Stack Buﬀer (RSB), a hardware stack
buﬀer to which the processor pushes the return address
whenever it executes a call
instruction. Whenever the
processor stumbles upon a return instruction, it pops the
address from the top of the RSB to predict the return
point of the function, and it executes the instructions along
that path speculatively. The RSB misspeculates when the
return address value in the RSB does not match the one
on the software stack. Unfortunately, the RSB consists of
a limited number of entries and employs a round robin
replacement policy. As a result, an attacker can overﬂow
the RSB to overwrite the “alleged” return address of a
function and speculatively execute the code at this address.
Researchers have reported RSB attacks against sandboxes
and enclaves [4], [71].
Constraints: Control speculation attacks, while powerful,
(cid:26)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:31 UTC from IEEE Xplore.  Restrictions apply. 
are only eﬀective in intra-address space attacks (e.g., sand-
boxes). Furthermore, their exploitation requires (some)
cooperation from the victim’s code. In situations where
the attacker can generate code inside the victim (e.g.,
JIT compilation inside a browser, eBPF in the Linux
kernel) it is easy to meet this constraint. In the other
cases (e.g., enclaves or Linux kernel without eBPF), this
constraint is harder to meet. The attacker needs to mount
confused-deputy attacks that lure the victim component
into speculatively executing speciﬁc “gadgets”, making
exploitation more diﬃcult. Perhaps more importantly, this
class of attacks can be mitigated in software using either
compiler support for emitting safe code or manually stop-
ping speculation when deemed dangerous.
B. Data Speculation
Data speculation is the second type of speculative exe-
cution. This type of speculation does not divert the control
ﬂow of the application, but instead speculates on the value
to be used. As discussed in Section VII-A, manipulating
control ﬂow is not enough to build eﬀective cross-privilege
and cross-address space attacks. Attackers can overcome
these constraints by taking advantage of data speculation.
Speculative Store Bypass (SSB) [72] takes advantage of
the address prediction performed by the Memory Disam-
biguator. This unit is in charge of predicting read-after-
write hazards. If the prediction fails, the attacker may
be able to leak stale L1 cache lines previously stored at
that address. However, this attack provides a small window
of exploitation and works only within intra-address space
boundaries, making it hard to exploit in practice.
Exception deferral: To bypass this limitation and allow
cross-boundary leaks, researchers identiﬁed a new class
of data speculation attacks that we refer to as exception
deferral attacks. A similar distinction was previously made
in the literature [5] under the nomenclature of exception
speculation. However, as explained in Section II, specu-
lation represents a misleading terminology of the actual
issue under scrutiny. The CPU does not perform any
type of speculation on the validity of the operation. It
simply executes instructions speculatively out-of-order and
eventually retires them in-order. The ﬂaw of this design is
that the Retirement Unit is oﬃcially in charge of handling
CPU exceptions. Thus, an attacker can perform loads that
trigger exceptions (e.g., Page Faults) during the specula-
tive execution window, but such loads will not fault until
the Retirement Unit performs the compulsory checks.
Multiple attacks have exploited CPUs’ exception de-
ferral
in order to circumvent diﬀerent security checks.
RDCL [1] (known as Meltdown) and RSRR [73] exploited
the deferral of a page fault (#PF) exception caused by
the presence of the supervisor bit in order to read privi-
leged kernel memory and Model Speciﬁc Registers (MSRs).
LazyFP [74] took advantage of the deferral of the Device
not available (#NM) exception to leak Floating Point Units
(FPUs) register state and break cryptographic algorithms.
Foreshadow [75] disclosed how the deferral of a Terminal
Fault (#TF) generated by a failed check on the present or
reserved bits of a PTE allows leaking arbitrary contents
from the L1 cache. Given that Foreshadow operates on
physical memory addresses, it can leak information across
privilege and address space boundaries breaking kernel,
enclaves, and VM isolation. Crafting Foreshadow attacks,
however, requires control over addresses residing in PTEs
as we discuss next.
Constraints: Data speculation allows attackers to operate
on data they are not supposed to have access to. Further-
more, when combined with exception deferral, they gain
the capability of not relying on victim code to leak data.
With RDCL, for example, attackers can directly read from
kernel memory without relying on “gadgets” in the kernel
code. Most of these attacks, however, are still limited by
the necessity of a valid address translation. That is, a valid
(and known) address to leak the data from. For instance,
in the case of Foreshadow, the attacker can theoretically
read any arbitrary cache line in the L1d cache. However,
since L1d cache lines are physically tagged, the attacker
needs control over virtual-to-physical address mappings
(PTEs). This constraint is easily met in situations where
the attacker controls these mappings, such as inside guest
VMs or SGX enclaves. In the other cases, this constraint
is harder to meet, such as when attacking the kernel or
another user process.
C. Comparing with RIDL
While RIDL still falls under the umbrella of data spec-
ulation attacks, it presents a unique feature that makes it
stand out among the other attacks: the ability to induce
leaks that are completely agnostic to address translation.
All the other attacks other than LazyFP [74] (which is
limited to leaking stale ﬂoating point registers) require a
valid address for performing tag checks before retrieving
the data. If this check fails, the speculation aborts. On the
other hand, in the case of RIDL, the attacker can access
any in-ﬂight data currently streaming through internal
CPU buﬀers without performing any check. As a result,
address space, privilege, and even enclave boundaries do
not represent a restriction for RIDL attacks.
VIII. Existing defenses
In response to the plethora of attacks described in
Section VII, hardware and software vendors have been
struggling to catch up with mitigations that can safeguard
vulnerable systems. In this section, we perform an exhaus-
tive analysis of all the existing state-of-the-art mitigations,
pinpointing the current shortcomings of such solutions
when applied to the RIDL family of attacks.
These mitigations can operate at three diﬀerent layers:
1 inhibiting the trigger of the speculation, 2 protecting
the secret the attacker is trying to disclose, or 3 disrupt-
ing the channel of the leakage. We focus on the ﬁrst two
classes, which are speciﬁc to speculative execution attacks;
the third typically applies to any timing side-channels
(e.g., disabling high-precision timers in browsers [63]). We
summarize all the currently deployed mitigations and their
eﬀects on currently-known attacks in Table III.
(cid:26)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:51:31 UTC from IEEE Xplore.  Restrictions apply. 
A. Inhibiting the trigger
To protect against control speculation attacks, vendors
have released mitigations that prevent the hardware from
executing (speculatively) unsafe code paths. For instance,
Intel released a microcode update with three new ca-
pabilities: IRBS, STIBP and IBPB to prevent indirect
branch poisoning instructions and to protect against BTI
attacks [76]. Another suggested mitigation uses the lfence
instruction to restrict control speculation. This can be
applied as a compiler-based defense, mitigating multiple
families of attacks. 1 To protect against BCB attacks, the
compiler inserts an lfence instruction after conditional
branches to stop the BPU from speculating on the code
path taken. 2 To protect against BTI attacks, the lfence
instruction is introduced as part of the Retpoline [6] mitiga-
tion. Researchers have also suggested extending Retpoline
to guard ret instructions and prevent RSB attacks [71].
The Retpoline mitigation converts each indirect jump
into a direct call to a stub function, that returns to the
destination of the initial indirect branch. This is achieved
by altering the stack, replacing the return address of the
function. Since return instructions also trigger speculation,
an lfence loop is inserted at the expected return site of
the stub, to inhibit further code execution. Retpoline can
also perform RSB ﬁlling [77]. This is required for Intel
architectures newer than Haswell where,
in case of an
empty RSB, the BTB provides the speculation address.
Software mitigations such as Retpoline do not apply
for data speculation attacks since there is no need to
(speculatively) divert the control ﬂow of the application.
As such, most defenses against data speculation have been
in the form of microcode updates, such as:
• SSBD: Speculative Store Bypass Disable adds an MSR
which can be used to prevent loads from executing
before addresses of previous stores are known [44].
• RSRR ﬁx: Intel’s mitigation for Rogue System Regis-
ter Reads patches rdmsr to avoid speculative L1 loads
of MSR data for unprivileged users [73].
Finally, to protect against LazyFP, it suﬃces to enable
Eager FPU context switching. This restores FPU register
state when performing a context switch, preventing spec-
ulative execution on stale register contents [74].
B. Protect the secret
When preventing the CPU from speculating becomes
unfeasible, the other solution is to conceal the sensitive
information from the attacker. Defenses falling under this
category are clearly context sensitive. That is, they highly
depend on the environment they get deployed on since
diﬀerent environments secure diﬀerent secrets. A primary
example is Kernel Page Table Isolation (KPTI) [9]. KPTI
was eﬀectively the ﬁrst mitigation deployed against spec-
ulative execution attacks and was introduced to protect
the Kernel against RDCL (i.e., Meltdown) by separating
kernel and user address spaces.
A similar compartmentalization approach was then
deployed in other environments. 1 Array index masking
was deployed in the kernel and in sandboxed environ-
ments to protect against intra-address space BCB attacks.
2 Multi-process isolation, similarly to KPTI, protects
sandboxed environments from cross-domain attacks (e.g.,
JavaScript VMs) by generating a diﬀerent process for every
origin—hence a diﬀerent address space.
These mitigations were considered eﬀective until the
disclosure of the Foreshadow attack. Foreshadow relaxed
the requirement of victim cooperation for cross-address
space attacks by leaking any data present in the L1d
cache. Protecting against this new class of attacks requires
stronger solutions targeting physical addresses. Two in-
stances of such mitigations are PTE inversion and L1d
ﬂush [78]. PTE inversion protects kernel and enclave mem-
ory from being leaked through the L1d cache by scrambling
the physical address in the PTE when a page is marked
as non-present. L1d ﬂush removes any secret information
from the cache during a context switch, making it impos-
sible to retrieve any data. The latter is part of a set of
mitigations intended for environments such as the cloud,
where an attacker may have control of PTE contents.
Another example of such solutions is HyperClear [50],
deployed by Microsoft to safeguard Hyper-V. The mit-
igation consists of three units: 1 The Core Scheduler,
which performs safe scheduling of sibling logical processors
by allocating resources for a single VM on the same
physical processor. 2 Address space isolation per virtual
processor, which limits the hypervisor access to memory
only belonging to the VMs running on the same phys-
ical core—preventing cross-VM leaks. 3 Sensitive data
scrubbing, which protects nested hypervisors from leaking
sensitive data. This is done by zeroing the latter before
switching VMs and avoiding the performance impact of a
complete L1d ﬂush. Similar solutions have been deployed
on other hypervisors such as KVM [8].
C. Defenses vs. RIDL
In Section VI, we reported the results of all our proof-
of-concept exploits on fully patched systems with the
latest microcode updates. As the positive results demon-
strate, the currently deployed mitigations fail to protect
against RIDL attacks. As we discussed in Section VIII-A,
mitigations for data speculation attacks usually rely on
microcode patches. Since the existing defenses trying to
inhibit speculation do not account for the Line Fill Buﬀer,
RIDL is not impacted by any of them.
On the other hand, defenses aiming at protecting the
secret fail at defending from RIDL attacks for a diﬀerent
reason: they all consider a valid address a strict require-
ment. RIDL demonstrates that not all the sources of data