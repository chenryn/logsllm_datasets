decrypt the email (step ➁). The e2e module can implement any
end-to-end encryption scheme; Pretzel’s current prototype uses
OpenPGP [1, 37]. Next, the recipient passes the decrypted email
contents to the client-side components of the function modules
(step ➂), which then participate in a protocol with their counter-
parts at the provider (step ➃). At the end of the protocol, either
the client or the provider learns the output of the computation (for
example, a bit encoding whether the email is spam or not). Finally,
the client processes the decrypted email according to the output (for
example, labels it as spam), and delivers it to the recipient (step ➄).
Pretzel’s e2e module requires cryptographic keys for encrypting,
decrypting, signing, and verifying. Thus, Pretzel requires a solution
to key management [2, 31, 93, 126]. However, this is a separate
effort, deserving of its own paper or product and (as noted in the
introduction) is one of the obstacles that Pretzel does not address.
Later (§7), we discuss why we are optimistic that it will ultimately
be overcome.
The main work for Pretzel surrounds the function modules; the
challenge is to balance privacy, functionality, and performance (§2.1).
Our focus will be on two modules: spam filtering and topic extrac-
tion (§3, §4). We will also report on an elementary keyword search
module (§5). But before delving into details, we walk through some
necessary background on the class of computations run by these
modules and the cryptographic protocols that they build on.
classifiers, specifically a variant of Graham-Robinson’s NB [68, 104]
for spam filtering (we call this variant GR-NB),1 and multinomial
NB [92] for topic extraction; Logistic Regression (LR) classifiers [57,
62, 86, 98], specifically binary LR [86] and multinomial LR [57] for
spam filtering and topic extraction respectively; and linear Sup-
port Vector Machine (SVM) classifiers [32, 45, 78, 109], specifically
two-class and one-versus-all SVM [32] for spam filtering and topic
extraction respectively. These algorithms, or variants of them, yield
high accuracy [44, 62, 68, 71, 78, 141] (see also §6.1, §6.2), and are
used in popular open-source software packages for spam filtering,
classification, and general machine learning [3–7, 57].
The three types of classifiers differ in their underlying assump-
tions and how they learn parameters from training data. However,
when applying a trained model, they all perform analogous linear
operations. We will use Naive Bayes as a running example, because
it is the simplest to explain.
Naive Bayes classifiers. These algorithms assume that a docu-
ment (an email, in our context) can belong to one of several cate-
gories (for example, spam or non-spam). The algorithms output a
prediction of a document’s category.
Documents are represented by feature vectors ⃗x = (x1, . . . , xN ),
where N is the total number of features. A feature can be a word,
a group of words, or any other efficiently computable aspect of
the document; the algorithms do not assume a particular mapping
between documents and feature vectors, only that some mapping
exists. In the GR-NB spam classifier [68, 104], xi is Boolean, and
indicates the presence or absence of feature i in the document; in
the multinomial NB text classifier, xi is the frequency of feature i.
The algorithms take as input a feature vector and a model that
describes the categories. A model is a set of vectors {(⃗vj, p(Cj ))}
(1 ≤ j ≤ B), where Cj is a category (for example, spam or non-
spam), and B is the number of categories (two for spam; 2208 for
topics, based on Google’s public list of topics [8]). p(Cj ) denotes
the assumed a priori category distribution. The ith entry of ⃗vj is
denoted p(ti | Cj ) and is, roughly speaking, the probability that
feature i, call it ti, appears in documents whose category is Cj.2
The GR-NB spam classification algorithm labels an email, as
represented by feature vector ⃗x, as spam if p(spam | ⃗x) is greater
than some fixed threshold. To do so, the algorithm computes α =
1/p(spam | ⃗x) − 1 in log space. One can show [70, Appx A.1] that
log α is equivalent to:
(cid:43)(cid:47)(cid:45) + 1 · log p(C2)
(cid:43)(cid:47)(cid:45) + 1 · log p(C1),
(1)
(cid:42)(cid:46)(cid:44)i=N(cid:88)
−(cid:42)(cid:46)(cid:44)i=N(cid:88)
i=1
xi · log p(ti | C2)
xi · log p(ti | C1)
i=1
where C1 represents spam and C2 represents non-spam.
3 BACKGROUND, BASELINE, RELATED WORK
3.1 Classification
Spam filtering and topic extraction are classification problems and,
as such, require classifier algorithms. Pretzel is geared to linear classi-
fiers. So far, we have implemented Naive Bayes (NB) [68, 92, 95, 104]
1The original Graham-Robinson NB protects against spam emails that hide a short
message within a large non-spam text [69]. We do not implement that piece; the
resulting change in classification accuracy is small (§6.1).
2In more detail, the GR-NB spam classifier assumes that the {xi} are realizations
of independent Bernoulli random variables (RVs), with the probabilities of each RV,
p(ti | Cj ), depending on the hypothesized category. The multinomial NB text classifier
i xi trials,
where the bin probabilities are p(ti | Cj ) and depend on the hypothesized category.
assumes that the {xi} follow a multinomial distribution, with N bins and(cid:80)
recipient's email cliente2e modulea function moduleemail emailboxe2e modulee'e'sender's email clientrecipient's email provider123e4 e5SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
T. Gupta et al.
• The protocol has two parties. Party X begins with a matrix; Party Y begins with a vector. The protocol computes a vector-matrix product and
then performs an arbitrary computation, ϕ, on the resulting vector; neither party’s input is revealed to the other.
• The protocol assumes an additively homomorphic encryption (AHE) scheme (Gen, Enc, Dec), meaning that Enc(pk, m1) · Enc(pk, m2) =
Enc(pk, m1 + m2), where m1, m2 are plaintext messages, + represents addition of two plaintext messages, and · is an operation on the
ciphertexts. This also implies that given a constant z and Enc(pk, m1), one can compute Enc(pk, z · m1).
Yao+gllm
Setup phase
(1) Party X forms a matrix with columns ⃗v1, . . . , ⃗vB; each vector has N components. It does the following:
(a) Generates public and secret keys (pk, sk) ← Gen(1k ), where k is a security parameter.
(b) Encrypts each column component-wise, so Enc(pk, ⃗vj ) = (Enc(pk, v1,j ), . . . , Enc(pk, vN,j )).
(c) Sends the encrypted matrix columns and pk to Party Y.
(2) Party Y begins with an N-component vector ⃗x = (x1, . . . , xN ). It does the following:
(a) (dot products) Computes encrypted dot product for each matrix column: Enc(pk, dj ) = Enc(pk,(cid:80)N
since the encryption function is not deterministic. The computation relies on the homomorphic property.
i=1 xi · vi,j ), this abuses notation,
(b) (blinding) Blinds dj by adding random noise nj ∈R {0, 1}b+δ . That is, computes Enc(pk, dj + nj ) = Enc(pk, dj ) · Enc(pk, nj ). Here b is
Computation phase
the bit-length of dj and δ ≥ 1 is a security parameter.
(c) Sends (Enc(pk, d1 + n1), . . . , Enc(pk, dB + nB)) to Party X.
(3) Party X applies Dec component-wise, to get (d1 + n1, . . . , dB + nB)
(4) Party X and Party Y participate in Yao’s 2PC protocol; they use a function f that subtracts the noise nj from dj + nj and applies the
function ϕ to the dj. One of the two parties (which one depends on the arrangement) obtains the output ϕ(d1, . . . , dB).
Figure 2: Yao+gllm. This protocol [19, 30, 75, 100, 106] combines GLLM’s secure dot products [60] with Yao’s general-purpose 2PC [133].
Pretzel’s design and implementation apply this protocol to the linear classifiers described in §3.1. The provider is Party X, and the client is
Party Y. Pretzel’s instantiation of this protocol incorporates several additional elements (§3.3): a variant of Yao [77, 81] that defends against
actively adversarial parties; amortization of the expense of this variant via precomputation in the setup phase; a technique to defend against
adversarial key generation (for example, not invoking Gen correctly); and a packing technique (§4.2) in steps 1b and 2a.
For the multinomial NB text classifier, selection works by choos-
ing the category Cj∗ that maximizes likelihood: j∗=argmaxj p(Cj | ⃗x).
One can show [70, Appx A.2] that it suffices to select the Cj for
which the following is maximal:
(cid:42)(cid:46)(cid:44)i=N(cid:88)
i=1
xi · log p(ti | Cj )
(2)
(cid:43)(cid:47)(cid:45) + 1 · log p(Cj ).
For LR and SVM classifiers, the term log p(ti | Cj ) is replaced by
a “weight” term wi,j for feature xi and category Cj, and log p(Cj ) is
replaced by a “bias” term bj for category j.
3.2 Secure two-party computation
To perform the computation described above within a function mod-
ule (§2.2) securely, that is, in a way that the client does not learn the
model parameters and the provider does not learn the feature vec-
tor, Pretzel uses secure two-party computation (2PC): cryptographic
protocols that enable two parties to compute a function without
revealing their inputs to each other [61, 133]. Pretzel builds on a
relatively efficient 2PC protocol [19, 30, 75, 100, 106] that we name
Yao+gllm; we present this below, informally and bottom up (for
details and rigorous descriptions, see [60, 72, 88, 107]).
Yao’s 2PC. A building block of Yao+gllm is the classic scheme
of Yao [133]. Let f be a function, represented as a Boolean circuit
(meaning a network of Boolean gates: AND, OR, etc.), with n-bit
input, and let there be two parties P1 and P2 that supply separate
pieces of this input, denoted x1 and x2, respectively. Then Yao (as
the protocol is sometimes known), when run between P1 and P2,
takes as inputs f and x1 from P1, x2 from P2, and outputs f (x1, x2)
to P2, such that P1 does not learn anything about x2, and P2 does not
learn anything about x1 except what can be inferred from f (x1, x2).
At a very high level, Yao works by having one party generate
encrypted truth tables, called garbled Boolean gates, for gates in the
original circuit, and having the other party decrypt and thereby
evaluate the garbled gates.
In principle, Yao handles arbitrary functions. In practice, how-
ever, the costs are high. A big problem is the computational model.
For example, 32-bit multiplication, when represented as a Boolean
circuit, requires on the order of 2,000 gates, and each of those gates
induces cryptographic operations (encryption, etc.). Recent activity
has improved the costs (see [66, 73, 81, 83, 87, 114, 138, 139] and
references therein), but the bottom line is still too expensive to
handle arbitrary computations. Indeed, Pretzel’s prototype uses
Yao very selectively—just to compute several comparisons of 32-bit
numbers—and even then it turns out to be a bottleneck (§6.1, §6.2),
despite using a recent and optimized implementation [137, 138].
Secure dot products. Another building block of Yao+gllm is a
secure dot product protocol, specifically GLLM [60]. Many such
protocols (also called secure scalar product (SSP) protocols) have
Pretzel: Email encryption and provider-supplied functions are compatible
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
been proposed [21, 25, 51–54, 60, 76, 111, 118, 120, 129, 143]. They
fall into two categories: those that are provably secure [51, 60, 129]
and those that either have no security proof or require trusting a
third party [21, 25, 52–54, 76, 111, 118, 120, 143]. Several protocols in
the latter category have been attacked [38, 60, 74, 80, 84]. GLLM [60]
is in the first category, is state of the art, and is widely used.
Hybrid: Yao+gllm. Pretzel’s starting point is Yao+gllm, a hybrid
of Yao and GLLM. It is depicted in Figure 2. One party starts with
a matrix, and encrypts the entries. The other party starts with a
vector and leverages additive (not fully) homomorphic encryption
(AHE) to (a) compute the vector-matrix product in cipherspace, and
(b) blind the resulting vector. The first party then decrypts to obtain
the blinded vector. The vector then feeds into Yao: the two parties
remove the blinding and perform some computation ϕ.
Yao+gllm has been applied to spam filtering using LR [100], face
recognition using SVM [19], and face and biometric identification
using Euclidean distance [30, 75, 106].
Other related work. There are many works on private classifica-
tion that do not build on Yao+gllm. They rely on alternate building
blocks or hybrids: additively homomorphic encryption [33, 89],
fully homomorphic encryption [82] (FHE), or a different Yao hy-
brid [36]. For us, Yao+gllm appeared to be a more promising start-
ing point. For example, in contrast to the protocol of Khedr et
al. [82], Yao+gllm reveals only the final output of the computation
rather than intermediate dot products. As another example, the
resource consumption in Yao+gllm is considerably lower than in
Bost et al. [33].3
Another related line of research focuses on privacy and linear
classifiers—but in the training phase. Multiple parties can train a
global model without revealing their private inputs [121, 123, 132,
134–136], or a party can release a trained “noisy” model that hides
its training data [79, 122, 142]. These works are complementary to
Pretzel’s focus on applying trained models.
3.3 Baseline protocol
Pretzel begins by applying the Yao+gllm protocol (Figure 2, §3.2) to
the algorithms described in Section 3.1. This works because expres-
sions (1) and (2) are dot products of the necessary form. Specifically,
the provider is party X and supplies (⃗vj, p(Cj )); the client is party Y
and supplies (⃗x, 1), which it obtains from an email using a feature
extraction algorithm supplied by the provider (§2.1); and the proto-
col computes their dot product. Then, the threshold comparison (for
spam filtering) or the maximal selection (for topic extraction) hap-
pens inside an instance of Yao. For spam filtering, the client receives
the classification output; for topic extraction, the provider does.
Note that storing the encrypted model at the client is justified by an
assumption that model vectors change infrequently [43, 108, 109].
In defining this baseline, we include mechanisms to defend
against adversarial parties (§2.1). Specifically, whereas under the
classical Yao protocol an actively adversarial party can obtain the
3For the data point at N = 70, B = 24 (these variables are defined in Figure 2), Bost et
al. report network transfers and computation times (for the two parties) of 1911 KB,
1664 ms, and 1652 ms [33], whereas these overheads are 156.1 KB, 757.9 ms, and 8.6 ms
for our implementation of Yao+gllm (§5) on comparable hardware. These differences
in overheads are due to a packing optimization in Yao+gllm and improvements (see
the pointers to recent activity above) that reduce the overheads of Yao.
other’s private inputs [77], Pretzel incorporates a variant [77, 81]
that solves this problem. This variant brings some additional ex-
pense, but that expense can be incurred during the setup phase
and amortized. Also, Yao+gllm assumes that the AHE’s key gener-
ation is done honestly, whereas we would prefer not to make that
assumption; Pretzel incorporates the standard response.4
While the overall baseline is literally new (Yao+gllm was pre-
viously used in weaker threat models, etc.), its elements are well-
known, so we do not claim novelty.
4 PRETZEL’S PROTOCOL REFINEMENTS
The baseline just described is a promising foundation for private