L2_RQSTS.DEMAND_DATA_RD_MISS
L1D_PEND_MISS.PENDING_CYCLES
None found
Name
SR1: Network Port Filter
SR2: File Hiding
SR3: Process Hiding
SR4: File Hiding
SR5: Direct Kernel Object Manipulation
DKOM
Figure 4: Visualization of the synthetic rootkit traces in a
PCA reduced feature space
der to reduce the feature space from 16 down even further
to three dimensions, albeit at a loss of accuracy. This allows
us to graph an estimate of the traces. Fig. 4 shows these
results for SR1-SR4 as well as clean traces. As can be seen,
there is a very clear delineation between the clean traces and
those from the synthetic rootkits. This leads us to believe
that the detection of hooking rootkits using HPCs will be
very accurate.
4. ROOTKIT DETECTION USING HPCS
Now that we have identiﬁed the top HPCs for detecting
various types of rootkit functionality in our synthetic tests,
can we use that information to detect real rootkits?
In order to answer this question, we trained a machine
learning based detector using a set of clean traces as well as
the dirty traces taken from the synthetic rootkits, but only
for the 16 most signiﬁcant HPCs determined in Section 3.5.
We then used this trained detector to classify dirty traces
taken from real rootkits as well as additional clean traces
captured under the four diﬀerent background workload con-
ditions of Table 2.
4.1 Rootkit Samples
As examples of real rootkits, we identiﬁed 20 variants of
ﬁve diﬀerent well-known Windows 7 rootkits: Zeus, ZeroAc-
cess, Hickit, Ramnit and Turla. All 100 samples were down-
loaded from VirusTotal [28]. We chose these rootkits be-
cause they were accessible, successfully executed on Win-
dows 7, performed some sort of rootkit activity, and enough
variants were available to collect a variety of traces. The
types of rootkit attacks performed vary between the various
rootkits. ZeroAccess, for example, employs IRP hooking in
order to support ﬁle hiding. On the other hand, Zeus and
some of its variants displayed signs of SSDT Hooking. The
execution and proper functioning of all rootkit samples was
manually veriﬁed.
4.2 Additional Trace Collection
Given the new rootkits, traces were collected of each rootkit
sample using the 16 most signiﬁcant HPCs discovered in Sec-
tion 3.5. In order to further vary the testing conditions, an
additional two background conditions (Table 4) were added.
For each of the 100 rootkit variants, we collected 10 traces
under each of the four background workload conditions for a
total of 4000 dirty traces. Given that we collected far fewer
HPCs, this data collection only required 8 days of CPU time
in order to get all 4000 traces.
We also collected an additional 24,000 clean traces using
the same 16 HPCs under the four background workload con-
ditions.
488Figure 5: Training and Testing Architecture
Table 4: Additional Trace Background Workload Conditions
Name Description
Noisy 2 The proﬁling benchmark is executed and
Google Chrome is running, opening a variety
of websites in multiple tabs.
Noisy 3 The proﬁling benchmark is executed and the
Windows System Assessment Tool is executed
to benchmark the memory and disk perfor-
mance of the machine.
4.3 Machine Learning Methodology
We made use of the scikit-learn [20] Python library to
implement our system.
We evaluated the eﬀectiveness of four diﬀerent classiﬁers
for detecting rootkits. When using machine learning for clas-
siﬁcation, classiﬁers are used to distinguish data points in
order to determine which of the N classes every point be-
longs to. In our case, we have used two classes - clean and
dirty (infected). Hence, we can use our classiﬁers to predict
the probability of each data point in our test data which
represents the likelihood of it being a rootkit. What follows
is a brief description of each of the classiﬁers used.
SVM Support vector machines, SVM, are based on super-
vised machine learning models. The classiﬁer is trained by
passing it a set of data points with each data point marked
into one of the two categories. The training algorithm then
ﬁnds an appropriate plane/hyperplane that separates the
two classes best. To classify, the new point is mapped to ei-
ther class based on its location with respect to the plane/hy-
perplane. We used two diﬀerent SVM kernels: Linear and
RBF. Linear attempts to ﬁnd a simple, linear plane/hyper-
plane separating the classes, while RBF builds a more a
complex plane/hyperplane.
OC-SVM One class SVM is an unsupervised learning model,
meaning it is trained only one class of data (in this case,
dirty). Unlike SVM, OC-SVM classiﬁes data points as ei-
ther belonging to the class or not.
Instead of ﬁnding the
best plane/hyperplane to separate data, the data points are
enclosed in a distinguishing shape that contains all the data
points that belong to one class. Data points outside that
shape are marked as not part of the class.
Naive Bayes Naive Bayes is a supervised algorithm based
on a probabilistic classiﬁcation approach. In this classiﬁer,
Bayes’ theorem is used to construct a probability model
while assuming that all features are independent. A sim-
ple decision rule is then applied to the probability model,
creating the classiﬁer.
Decision Trees A decision tree is used in a supervised clas-
siﬁcation environment. A decision tree is made up of several
features. To train the classifying tree, the training data is
divided into subsets based on a given feature. Each sub-
set is then recursively divided and checked if it adds any
value to the classiﬁcation process. If either the maximum
depth is reached or the division no longer makes the predic-
tion better, the node terminates. In order to classify a new
data point, the point traverses the whole tree based on the
branch conditions.
It stops once it reaches a terminating
node which speciﬁes its predicted class.
4.4 Training and Testing
We trained our classiﬁers using the 500 dirty traces from
the synthetic rootkits captured in Section 3 (reduced to only
the 16 HPCs) as well as 20,000 of the 24,000 clean traces
captured in Section 4.2. The architecture of our training
approach can be seen in Fig. 5.
For machine learning techniques that require tuned pa-
rameters (such as the γ value for SVM with an RBF ker-
nel), we applied a cross-validation grid-search over a range
of possible values. The parameter that is selected is the one
that gives the maximum accuracy on the test part of the
cross-validated data. The parameter values are obtained by
cross-validating the training data using a 60%/40% split.
None of the testing data is used as part of tuning.
Because our training data contains signiﬁcantly more clean
traces than dirty ones, we have adjusted the weights given
to each class to balance the frequencies.
In this method,
class samples get weights that are inversely proportional to
the class size. For example, in our training data the clean
class is 40 times larger than the dirty class. This can lead
to skewed results if this is not corrected for. By adjusting
weights of both classes during training, we can account for
this discrepancy and produce more accurate results.
It is important to emphasize that our dirty training data
consists of only traces from the synthetic rootkits of Sec-
tion 3. Traces from the real rootkits were not included.
Machine Learning Based ClassifierTrainedModelRealRootkitTracesCleanTracesTesting DataClassification ResultsMachine LearningBased Training SystemSyntheticRootkitTracesCleanTracesTraining Data489Figure 6: ROC Curve Graph
This is because we want to determine if HPCs can be used
to detect previously unseen rootkits based on their function-
ality.
When testing our model, we used the remaining 4,000
clean traces (from the original 24,000 captured) as well as
the 4,000 traces captured from the real rootkits.
4.5 Results
Table 5 shows the true positive, false positive, true neg-
ative, and false negative rates that each classiﬁer achieves
when classifying the 8000 traces found in the testing set.
Fig. 6 shows the ROC curves for the classiﬁers as well. For
classiﬁers that involve randomness in their execution, the
data reﬂects the average of 50 runs.
From the results, we can see that both versions of SVM
(Linear and RBF) produce extremely accurate results with
a true positive rate of 99.91% and a 0% false positive rate.
This indicates that the distinction between clean and dirty
in the data is very clear, and hence SVM is able to easily
distinguish between the two.
In order to visualize this distinction, we combined the
synthetic rootkit traces, real rootkit traces, and a set of
clean traces and once again performed a PCA reduction of
the feature space into three dimensions. The results can be
found in Fig. 7. As can be seen, there is a clear delineation
between the various rootkit traces and the clean traces. This
leads to very accurate detection using SVM.
The extremely high detection rate is particularly surpris-
ing given that the detector was trained on the synthetic
rootkits and used to detect the real rootkits. The system is
able to detect rootkits it has never seen before, even as vari-
ants. This means that HPCs are suitable for the detection
of zero-day rootkit attacks as long as those rootkits employ
previously known attack mechanisms.
5. DISCUSSION
The results in this paper raise a number of points that
deserve further discussion.
5.1 Explanation of Signiﬁcant HPCs
In some ways the results of this work leave the reader
wanting because while it describes the observation and ap-
plication of a phenomenon (namely that HPCs can be used
Figure 7: Visualization of the real and synthetic rootkit
traces in a PCA reduced feature space
to accurately detect rootkits) it does not address the ques-
tion of Why?
When analyzing the 16 HPCs identiﬁed in Table 3, it is
tempting to try and explain exactly why each HPC is signif-
icant to each rootkit. For example, one could theorize that
SR1 and SR2 impact the BR_INST_RETIRED.NEAR_TAKEN HPC
because IRP hooking causes additional branches to occur,
and hence there are additional branches retired. (That ex-
planation, while sounding good, is completely fabricated.)
Indeed, the authors wrote multiple attempts at making just
these sorts of explanations. However, after multiple revisions
and detailed analysis of the data we removed such explana-
tions and have instead come to a diﬀerent conclusion: We do
not have enough data to properly ascertain why a particular
HPC is impacted by the rootkit.
To do so would require a much ﬁner granularity of HPC
collection than was employed here. One way to obtain data
at that granularity would be to instrument the OS kernel to
capture HPC information at various points (or perhaps at
every instruction) along the control-ﬂow, and use the data
to create an annotated version of the code that details how
HPCs are impacted during execution. This is eﬀectively su-
perimposing the time series HPC information onto a control-
ﬂow graph. (The need to directly correlated HPC changes
with the code that caused them is the reason that a simple
time series HPC capture could not be used.) These an-
notated control-ﬂow traces could then be obtained for in-
fected and non-infected runs, and the results compared to
determine exactly which code causes the HPC data to de-
viate. This would allow one to much more conclusively de-
scribe why the various HPCs are impacted by the rootkits,
and would also give additional insight into the possibility of
rootkits designed to evade such detection techniques.
5.2 Design Considerations for a Practical De-
tector
Obviously the approach used to gather HPCs in this work
would not be suitable for constructing a true rootkit detec-
tor. First, the trusted computing based (TCB) is too large
and actually includes the very operating system kernel that
malware is infecting.
Intel’s VTune, while convenient for
gathering traces, runs at a privilege level that would allow
a rootkit attacker to disable it or modify its results at run-
time. In addition, our results indicate that rootkit detection
490Table 5: Accuracy Results of Various Machine Learning Algorithms
ML algorithm
Decision Tree
Naive Bayes
OC-SVM
SVM(RBF Kernel)
SVM(Linear Kernel)
TP Rate FP Rate TN Rate FN Rate
67.43%
51.22%
100%
99.88%
99.91%
0.001%
0.52%
49.81%
0%
0%
99.99%
99.48%
50.19%
100%
100%
32.57%
48.78%
0%
0.12%
0.09%
is most eﬀective with at least 16 diﬀerent HPCs, while mod-
ern Intel processors only allow four HPCs to be collected
simultaneously.
We will now discuss the considerations that should be
made for an actual rootkit detection system based on HPCs.
Existing work [6, 27, 18] has already proposed a variety of
design choices and recommendations, and ours will build on
these. In general, an HPC based rootkit detector should not
be constructed independently, instead it should be part of
the integrated design of a more general purpose HPC based
malware detector.
Simultaneous HPC Capture Both [6] and [27] propose that
hardware should be modiﬁed to allow for more than four
HPCs to be monitored simultaneously, but neither work pro-
vides guidelines for how many this should be. Our results
indicate that 16 might be the lower bound, although in prac-
tice we do not believe that many more than this should be
required. Existing work has obtained very good results with
only the four, and with better machine learning approaches
we believe that our count of 16 could be reduced as well.
Location and Updating of Detection Engine In [18] the de-
tection engine is designed and implemented in hardware,
and while both [6] and [27] place it in software, [6] proposes
updates to it occur with hardware validation assistance. In
general, we feel that the less reliant on hardware the detec-
tion engine is, the more robust it will be as attacks evolve
and the machine learning techniques required evolve with
them. Recent advances in compartmental execution provide
an elegant solution to this problem. Solutions such as In-
tel’s SGX [1] and Iso-X [7] provide methods for running code
in a hardware protected enclave whose data cannot be ma-
nipulated by other software layers, including more privileged
ones. This would allow a software-only detection engine that
can be updated without special purpose hardware assistance
beyond what is oﬀered by the compartment system.
Secure Acquisition of HPC Data All three existing recom-
mendations propose tamper-proof, interrupt-less capture of
HPC data. We expand this recommendation by noting that
the secure delivery of HPC data should be incorporated into
the design of the compartment system, eliminating the need