that, following our work and the tests they ran on our VMs,
they updated their forensic investigation procedures.
1.1 Contributions
The basic conceptual contribution of this paper lies in
identifying and calling attention to the threat of framing,
especially via cross-site attacks.
The ‘classic’ computer-framing attack requires physical
access to the device or remote control over the devices, as
with malware. We identify and demonstrate the more insidi-
ous threat of cross-site framing attacks, which do not require
physical access or control over the computer by malware or
otherwise. Such attacks are easier and less-risky to launch
and may be harder to defend against.
Additional contributions of this paper are in the identiﬁ-
cation and the evaluation of risks that have not yet been
studied in popular web-services, browsers, and operating
systems. These include:
able sites (Section 3; see Table 1).
• Planting search history is possible in popular and reli-
• Exploiting and evaluating automatic ﬁle download in
Google Chrome and Safari for Mac OS as well as other
risky browser features (Section 4).
• Manipulations of ﬁle systems to unlink framing ﬁles
• Covering the traces of cross-site attacks, both in the
victim’s computer and in logs of the web-services (Sec-
tion 6).
• Discussing mitigation techniques and oﬀering a design
from the web (Section 5).
for eﬀective defense (Section 7).
163
• Evaluation of the attacks by forensic software and with
the collaboration of legal authorities.
Following our work, the Israel Police updated their foren-
sic investigation procedures. This is a strong indication re-
garding the impact of our results and the importance in pub-
lishing them. We hope legal authorities in other countries
will also test and improve their forensic procedures.
Demos of the attacks are available in [15].
1.2 Related Work
There is extensive research on diﬀerent attacks by rogue
websites on their visitors, including many cross-site attacks
exploiting weaknesses in popular websites, e.g., [2, 28], and
oﬀ-path attacks exploiting network-protocol weaknesses [16].
However, to the best of our knowledge, this is the ﬁrst paper
that raises the risk of cross-site framing attacks.
In this work, we sent forged cross-site requests to manip-
ulate popular websites. Xing et al. [28] used similar manip-
ulations but only to pollute user personalization algorithms
in Google, Amazon, and YouTube.
2. ADVERSARY MODEL & ROADMAP
We consider an adversary that is running a malicious web-
site, without eavesdropping or MitM abilities. We assume
the adversary is able to ‘lure’ the victim into visiting the
website; we justify this assumption below.
While the victim visits the attacker’s website, we assume
the browser will run scripts on that page using typical ‘sand-
box’ mechanisms. For example, these mechanisms let scripts
instruct the browser to display objects from arbitrary do-
mains (e.g.,
images) and load other pages (embedded in
frame using  or in separate window/tab).
The malicious script is often referred to as a puppet [5],
since it is running within sandbox limitations.
We now discuss the roadmap of our framing attacks.
Luring the victim to the attacker’s website. Cross-
site framing and other attacks by a malicious website need
to cause the user to visit the malicious site. There are sev-
eral ways the attacker can cause a random user, or even
a speciﬁc user, to visit his website. These range from le-
gitimate site-promotion techniques, to the use of (targeted)
phishing emails and social-engineering [13, 19, 20], or even
the take-over of a benign (but not well protected) site.
Attacks on a speciﬁc site (Section 3) require that the user
is authenticated to that site. Many users are authenticated
to several sites most of the time, and since our attacks in-
clude some of the most popular sites, this assumption is
generally true. In other cases, the attacker may use social
engineering to coerce the user into connecting to the desired
website.
Planting evidence. Once the victim loads the adver-
sary’s website, the adversary can plant incriminating evi-
dence using the techniques described in the following sec-
tions.
Covering traces. The adversary can use several tech-
niques to hide the attack from the victim and eliminate the
attack’s traces from both the victim’s computer and from
the logs of the web-services.
3. FRAMING WEB-SERVICES EVIDENCE
Records kept by service providers such as banks, utility
companies, telecommunication providers, and others are of-
ten considered reliable evidence and are generally admissible
in court. With the growing familiarity and usage of many
diﬀerent popular web-services, their records are also increas-
ingly viewed as legitimate, reliable evidence, and have been
applied in several court cases (see Table 2).
As with other evidence, these have a cumulative value.
Namely, a collection of a large amount of web-service evi-
dence can have considerable weight, especially if it includes
diﬀerent forms of evidence from multiple web-services. We
next argue that such evidence should be used with care.
We show that popular, reliable, and widely-trusted web-
services, may often allow such records and evidence to be
easily planted. See summary in Table 1.
The vulnerabilities we present may not pose an obvious
business risk to the providers, beyond their potential abuse
for creating fake evidence. Consequently, the web-service
providers may not have signiﬁcant business motivation to
ﬁx them. This may be an important diﬀerence between the
public perception of record keeping by a reliable, trustwor-
thy organization, and the reality of web-services. This also
raises interesting ethical, legal, and social dilemmas. Should
society demand that web-services do more to protect their
records and prevent framing? Is there an ethical obligation
on web developers and security experts to consider and ﬁx
such vulnerabilities? Are such records subject to privacy
laws and regulations?
In the adversary model discussed here, an attacker can
launch CSRF attacks [2] to perform framing operations in
the name of the victim. We show how, by performing in-
nocuous operations in the name of the victim, it is possi-
ble to create new framing records in the logs kept by the
web-services. We do not discuss framing operations such as
sending or posting messages in the name of the victim, as it
is clear that sites should prevent attackers from performing
such activities. Instead, we focus on simple operations that
do not appear to be suspicious; some of the popular web-
sites we tested do not protect these operations from CSRF
attacks. We categorize these operations into two categories:
search history and relevant items history.
3.1 Search History Evidence
Search is a basic operation performed by search engines
and many other websites. Websites save the search history
of their users, to give them personalized services, e.g., pro-
vide more relevant content. However, the search history is
private; the terms that a user searches for, may expose in-
formation about the user and her needs and interests. We
found that by sending a cross-site search request, an attacker
can add a record of this search to the logs kept by websites.
In some sites it is also possible to manipulate the clicked
search results or to add saved searches. We now elaborate
on the diﬀerent attacks we found.
Search history. Search engines, and other sites provid-
ing search services, often maintain the history (records) of
users’ search queries. We checked the search history in the
three most popular search engines [4] Google, Yahoo!, and
Bing, and for YouTube and Facebook. We found that all of
them save a history of the user’s search queries by default,
even if the queries are sent from other sites. Furthermore,
in all engines there does not appear to be any ﬁltering of
‘problematic’ terms.
All of these sites collect users’ search history, even when
the user surfs privately (e.g., in Chrome incognito mode)
and/or chooses privacy-options such as Send “Do not track”
request with your browsing traﬃc in Google Chrome browser
[17]. In particular, this implies that search-history framing
is also possible from a site visited while in ‘incognito’ mode.
Followed-links history. Two of the three search engines
we tested, Google and Bing, maintain and provide an inter-
face showing the history of links followed (‘clicked’) by the
user from among the search results; this is used for diﬀerent
(legitimate) purposes. However, these records can also pro-
vide additional (framing) evidence about user activity, pos-
sibly even more incriminating than the search history. We
found vulnerabilities allowing the insertion of fake records
into the followed-links history of both Google and Bing, each
of these was done using a completely diﬀerent technique, as
we now explain.
Followed-links framing - in Google. When Google presents
search results, the links provided with each result are not di-
rect links to the corresponding pages. Instead, the links are
all GET requests to Google, with a parameter that indi-
cates the destination URL. Clicking on a link redirects the
browser to the destination URL and adds that URL to the
followed-links history. It turns out that sending the same
GET requests when other clients are authenticated from
other websites, has the same eﬀect; see demo in [15].
Followed-links framing - Bing. In Bing, we found a diﬀer-
ent vulnerability that oﬀers the same result, i.e., injecting
entries to the followed-links history. Speciﬁcally, Bing al-
lows its search page to be used within a frame (
tag), embedded within another website, permitting click-
jacking [26]. To inject a URL into the followed-links history
of Bing, the attacker embeds this link inside an iframe, and
overlays this with a layer that causes the user to click on
that link (without being aware of this being a link).
Saved searches history. Some web-services allow users
to save selected searches in their proﬁle.
In particular,
Craigslist oﬀers such a mechanism, using a simple ﬁxed-
request format that can be used from an arbitrary website.
Attackers can therefore inject fake ‘saved search’ records.
3.2 Evidence of Relevant Items History
E-commerce and content websites save the items in which
users express interest. This is done to personalize the pages
presented to the user and to oﬀer her more relevant items.
It also allows the website to learn about trends and oﬀer
information for other users. Attackers can easily manipulate
these records to plant fake indications about the interests of
the users.
We now bring examples from the popular websites we
tested:
Clicked videos, news, and advertisements in
Google. Similar to the followed-links framing in Google,
it is possible to take links to videos, news, or advertisements
that appear in the search, and send them from the attacker’s
website. The items that are related to the links will be added
to the history of the victim.
Watched video history in YouTube.
In addition
to search history, YouTube also maintains and displays
the ‘watched videos’. YouTube’s mechanism is similar to
Google’s ‘followed links’, and has the same vulnerability.
Speciﬁcally, it adds videos to the user’s history upon an
HTTP GET request, normally sent by the script running in
the browser of a user visiting YouTube. However, the same
164
request may be sent from the browser upon visiting a rogue
website, adding a video to the user’s history.
Amazon watched items. Amazon saves the items
watched (clicked) by the user. An attacker can copy the
GET requests linking to speciﬁc items from the search re-
sults returned by the Amazon e-commerce service. These
links can then be invoked on the attacker’s website when it
is visited by an Amazon client. This will cause Amazon to
list these items as viewed by the client.
Watched items in eBay.
eBay allows its users to
add products to both the shopping cart and the watch-list.
While this is not a purchase of product, it indicates the
user’s interests.
4. COMPUTER FRAMING
The framing attacks discussed in Section 3 exploit vulner-
abilities of the web-service. Here we present framing attacks
that exploit browser features and vulnerabilities, instead of
web-server vulnerabilities as in previous sections. The fram-
ing attacks we describe in this section include ‘classical’
pieces of evidence that are found on digital devices, such
as ﬁles and browsing history.
4.1 Framing via Files in the Browser Cache
The screening of a suspect’s computer to search for incrim-
inating ﬁles is a standard forensic procedure [8, 18]. Speciﬁ-
cally, it is recommended to check ﬁles in the browser cache;
indeed, cached-ﬁles were reported as evidence in several of
the cases we surveyed in Table 2.
Web users often visit the same pages several times. Hence,
browsers automatically save received pages and other ob-
jects in a cache. The browser used the cached objects when
the user visits the same page again, if the contents are still
valid. For each object (ﬁle), browsers save the content as
well as meta-data such as the URL, download time, and
expiration time.
Browsers normally allow any website to request arbitrary
objects and web pages. Furthermore, the cache does not
maintain a record of the site originating the request. Hence,
a framing attacker can cause the browser to load incrimi-
nating content (e.g., in iframes). The content can be taken
from diﬀerent websites on the Internet or from the Deep Web
via services like Tor2web [1]. This would allow the attacker
to provide customized content from a site controlled by the
attacker, without leaving traces. In short, it is easy for a
framing attacker to cause the caching of arbitrary incrimi-
nating ﬁles and objects. While users are technically able to
inspect their browser cache, remove speciﬁc items or simply
clean the cache, most users rarely do it, if ever. Therefore,
attackers can assume that incriminating, false-evidence ﬁles
that are stored in the cache, will remain there for long pe-
riods, without the user noticing. Moreover, traces of cached
ﬁles may remain on the disk even after deletion.
4.2 Framing via File Download
Browsers allow users to save or download web-objects
(e.g., complete web pages, images, movies, and documents)
usually to a default directory. The download is generally ini-
tiated by the user. Web pages can also initiate the download
process, however, this is less common, and the user is asked
and/or allowed to cancel the download. Consequently, in-
criminating ﬁles in the downloads folder may be more damn-
ing than ﬁles stored (automatically) in the browser cache,
as discussed in the previous subsection.
In at least two popular browsers, Google Chrome and Sa-
fari for MacOS, ﬁles are downloaded automatically by de-
fault, without asking users for explicit consent. Once the
ﬁle is downloaded, the user has to delete it via the regular
ﬁle system. Note that forensic software can often ﬁnd such
incriminating evidence even after it was deleted (usually,
until it is eventually overwritten by new data). The rele-
vant questions are, therefore: how eﬀective is incrimination
by exploiting the automatic ﬁle download feature? Would
users notice and abort the download, or later delete the ﬁle?
We tested these questions in the experiment described in
Section 4.2.1.
4.2.1 Experiment: Automatic Download Framing
Goal: Determine for how many users automated down-
load of ﬁles will work and how many would abort the down-
load or remove the ﬁle.
Methodology and ethics: We did not expect users to
react similarly to automated download attempts on a com-
puter we provided to them for the experiment. Such reac-
tions are likely to be biased, possibly even more so if we ex-
plain to the users that our goal is to measure their reaction to
automated ﬁle download. Hence, we could not conduct the
experiment in our lab or on an experiment-computer. We
had to create a natural environment in which users would
use their personal computers for a typical purpose, and then
test their responses to an automated download attempt.
We created a web page containing an online practice-exam
for students in the Data Structures course (ﬁrst year under-