perform a quadratic number of user-user similarity computations.
The challenge is to effectively partition the user activity data, while
retaining the capability of accurately capturing action matches. Our
insight is to divide the user actions into overlapping sliding win-
dows in the time dimension and to process different sliding win-
dows in parallel. This method not only mitigates the straggler issue
by feeding each individual worker smaller chunks of data, but also
effectively ﬁlters out unmatched actions that reside in different slid-
ing windows before the pairwise comparison.
Figure 6 illustrates how we partition by overlapping sliding win-
dows to precisely capture all possible user-action matches with a
matching window set to Tsim. In principle, a sliding window size
>Tsim and an overlapping period ≥ Tsim can guarantee the full
coverage of user-action matches. This is because a sliding window
size >Tsim ensures that any user-action match with a maximum
spanning period Tsim can be covered by a sliding window; an over-
lapping period ≥ Tsim ensures that the sliding windows are dense
enough to cover the all user-action matches across windows.
Sliding window setup. Counting in each overlapping sliding win-
dow entails duplicates of user-action matches that appear in the
overlapping area. The de-duplication of action matches could be
complicated if the sliding window size and the overlapping period
are not properly set. To strike an appropriate balance between the
effectiveness of cutting the data volume within each sliding window
and the complexity of de-duplicating action matches, we choose to
use a sliding window size of 2Tsim and an overlapping period of
length Tsim (Figure 6). With such a setting, we achieve single
counting by simply discarding the user action matches within the
second (or the ﬁrst) half of each sliding window.
Figure 6: Settings of the overlapping sliding windows in
SynchroTrap. Action matches within the overlapping area
(shaded) are exactly double counted. We depict actions from
different users using different markers.
We now discuss our parallel counting scheme’s guarantee that
one can exactly single count all user-action matches by indepen-
dently counting in each sliding window only. Suppose we have a
sequence of sliding windows SWi = [iTsim, (i + 2)Tsim) (i ≥ 0).
Without loss of generality, let t1 and t2 be the timestamps of two
matched user actions, where t2 ∈ [t1, t1 + Tsim]. Suppose t1 ∈
[jTsim, (j + 1)Tsim) (j ≥ 0). We have t2 < (j + 2)Tsim. Two
cases exist regarding the location of the action pair: a) t2 < (j +
1)Tsim. Both t1 and t2 belong to the interval [jTsim, (j +1)Tsim),
which is the overlapping area of two consecutive sliding windows
SWj−1 and SWj . Because we discard action matches within each
second-half window, the action pair is only single counted in SWj ;
b) t2 ∈ [(j + 1)Tsim, (j + 2)Tsim). Only SWj covers both t1 and
t2, because t1 ∈ [jTsim, (j + 1)Tsim). Hence the action pair is
single counted in SWj. We always append an empty half window
after the last sliding window in order to cope with the extreme case
at the end of the data stream.
4.6 Improving accuracy
It is challenging for a detection system, such as SynchroTrap,
to achieve desired accuracy for several reasons. First, the volumes
and synchronization levels of malicious actions vary in different
OSN applications.
In extreme cases, attackers may change their
strategies over time to evade an existing detection scheme. Sec-
ond, as a system that inﬂuences user experience on an OSN, Syn-
chroTrap must use conservative parameters to minimize the false
positive rate, i.e., not ﬂagging any legitimate user as malicious.
SynchroTrap allows OSN operators to tune a set of parameters
to achieve the desired trade-off between false positives and false
negatives. The main parameters include the action-matching win-
dow size Tsim and the ﬁltering thresholds for per-constraint sim-
ilarity (Simpc) and overall similarity (Simoverall). The settings of
these parameters have monotonic effects on false rates: a larger
action-matching window enables SynchroTrap to ﬁnd a larger set
of matched actions for two users, and hence increases their similar-
ity on a constraint object; on the other hand, a larger user similarity
threshold decreases the number of user pairs considered similar and
reduces the likelihood that two users are clustered together. These
monotonic effects simplify the process of setting parameters and
reduce the need for human intervention. The operators of our sys-
tem can choose to tune parameter values up or down according to
the false positive rate with the current settings. At Facebook we
set parameters equal to the values that meet the internal production
requirements. We do not reveal the speciﬁc parameter settings due
to conﬁdentiality agreements.
4.7 Computational cost
In theory, SynchroTrap’s computational cost is O(rn2), where
n is the number of daily active users per application and r is the
number of daily actions per user. In practice, we can signiﬁcantly
reduce this computational cost because we only need to compare
user actions pertaining to the same target object or coming from
the same source object. Therefore, in our implementation, the daily
computational cost is the O(rm2), where m is the number of daily
active users per application per target or source object (i.e., per
campaign target or per IP address). The cost for weekly aggregation
is linear to the number of user pairs generated by daily jobs. The
cost for searching connected components in a user similarity graph
is O(n). Thus the overall computational cost is O(rm2 + n).
5.
IMPLEMENTATION
We built SynchroTrap on top of the Hadoop MapReduce stack [38]
at Facebook. We implemented the daily user comparison module
and the weekly aggregation module on Hadoop [6], and the cluster-
ing module on Giraph [5], a large-graph processing platform based
on the Bulk Synchronous Parallel (BSP) model [30]. Giraph pro-
vides a parallel implementation of the connected components algo-
rithm. Apart from the basic functions supported by Facebook’s in-
frastructure, our implementation of SynchroTrap consists of 2,500
lines of Java code and 1,500 lines of Python code.
6. SECURITY ANALYSIS
In this section we provide a security analysis of our approach
under various adversarial strategies.
Spread-spectrum attacks. Attackers could attempt to hide the
synchronization signal that SynchroTrap detects, which we call the
spread-spectrum attacks. Given a target amount of abusive actions,
attackers can statistically spread actions over either a longer time
period or more constraint objects (e.g., IP addresses and campaign
targets). Due to the increased resource cost and the reduced cam-
paign revenue, such attacks are less proﬁtable. We now show that
SynchroTrap limits the damage of attack campaigns, even if at-
tackers control an unlimited number of accounts. We provide an
upper-bound analysis on the total number of actions that attackers
can perform on a constraint object during a certain period of time.
Suppose our detection window Tp (e.g., one week) contains w
action-matching windows of length Tm (e.g., 1 hour). Because
per-account rate-limiting is widely used in OSNs such as Face-
book [13, 14], we assume that an account can perform at most L
actions within each action-matching window. Although the number
of each account’s actions is bounded by wL, without SynchroTrap
the total malicious actions remain unlimited if attackers can control
an extremely large number of malicious accounts.
In contrast, SynchroTrap limits the total number of abusive ac-
tions on a constraint object (e.g., an IP address), irrespective of the
number of malicious accounts an attacker controls. The intuition is
that under SynchroTrap an attacker has to spread out the actions of
his accounts over matching windows so that a pair of accounts do
not have many matched actions. Therefore, given w matching win-
dows, the number of malicious accounts that can simultaneously
act on a constraint object is bounded.
Speciﬁcally, SynchroTrap uses the Jaccard similarity to evaluate
the action sets of two users. In order to evade the detection, the
fraction of matched actions of malicious accounts Ui and Uj must
be below a certain threshold p (0 < p < 1): |Ai ∩ Aj | ≤ p × |Ai|
and |Ai ∩Aj| ≤ p ×|Aj|. An optimal attack strategy is to schedule
a group of accounts according to the set of such action sets {Ai}
that has the maximum cardinality so as to minimize the chances
two malicious accounts are caught in the same cluster. Finding
{Ai} with the maximum cardinality is still an open problem in in-
tersection set theory [18], which poses a challenge to attackers.
We give an upper bound on the cardinality of such a set {Ai}
by computing the maximum size of its superset. We ﬁnd such a
superset {Bi} in which Bi ⊆ Bj only if Bi = Bj . That is, in {Bi}
none of the sets is contained in another. Because set {Bi} does not
require a threshold on |Bi ∩ Bj |, it relaxes the conditions of set
{Ai} and hence {Ai} ⊂ {Bi}. Set {Bi} approximates set {Ai}
if the matched fraction threshold p is set close to 1. In set theory,
{Bi} is called an antichain of sets in which none of the sets is a
subset of another. According to the Sperner’s theorem [15], given
that the detection window contains w matching windows, the size
of the maximum antichain satisﬁes |{Bi}| ≤ (cid:0) w
⌊w/2⌋(cid:1). Therefore,
we have |{Ai}| < (cid:0) w
⌊w/2⌋(cid:1), which speciﬁes the upper bound of the
number of active malicious accounts per constraint object. Thus,
the total number of actions from this malicious account group is
further bounded by (cid:0) w
⌊w/2⌋(cid:1)wL, assuming all of the accounts are
kept active during the detection window Tp.
Aggressive attacks. Aggressive attacks could be launched by con-
trolling accounts to perform bulk actions within a short time period.
SynchroTrap may miss such attacks if the user action-set size or
the user-pair similarity does not meet the criteria of SynchroTrap’s
user-pair ﬁltering function. However, such attacks have been the
focus of existing countermeasures [35], which look for the abrupt
changes in user activity. Our system works together with existing
anomaly detection schemes and complements them by targeting the
stealthier attacks.
7. DEPLOYMENT
We deployed SynchroTrap at Facebook and Instagram to un-
cover malicious accounts and integrated it into the site-protecting
stack at Facebook. In this section, we present ﬁve use cases (§ 7.1)
and describe how the ﬁndings of SynchroTrap can be used to better
monitor and protect OSN services (§ 7.2).
7.1 Use cases at Facebook and Instagram
We present SynchroTrap’s use cases according to the constraint
by which an attack campaign is bound. For each type of attacker-
side constraint, we present a couple of use cases at Facebook and
Instagram.
Resource-constrained synchronization. The resource constraint
we use is the source IP addresses from which the attacks origi-
nate. We deployed SynchroTrap with this conﬁguration at Face-
book user login and photo upload. An OSN provider could also in-
clude certain security cookies [7, 12] into SynchroTrap’s constraint
ﬁeld, which enables the detection of resource-constrained attacks
at a ﬁner granularity.
Mission-constrained synchronization. The mission constraints
we use are target object IDs, which include Facebook app ID, Face-
book page ID, and Instagram followee ID as the constraint ﬁeld, re-
spectively. We deployed SynchroTrap at Facebook app installation
and page like, and at Instagram user following context. We used
the overall similarity in these cases.
7.2 Signatures and response
As an unsupervised detection scheme, SynchroTrap automati-
cally discovers large groups of malicious accounts after its deploy-
ment. This malicious account corpus can be used as high-quality
training data to build accurate classiﬁers. We now describe how
we ﬁngerprint attacks and take actions on detected accounts and
user-created content.
Attack signatures. SynchroTrap extracts the common constraint
objects on which groups of suspicious accounts act together. The
OSN entities pointed by those constraint objects can be abusive,
and thus can be used as attack signatures. They include rogue Face-
book apps, Facebook pages with inappropriate content, abusive In-
stagram accounts soliciting excessive followers, etc. By tracking
back to the complete user action log, SynchroTrap can even provide
the ﬁngerprints of an attacker’s machines, including IP addresses,
user agents, browser cookies, etc. All of the above signatures can
be used to build fast classiﬁers to suppress future attacks in nearly
real time [35], and to decide on proper responses.
Response. The response to attacks in SynchroTrap is multifold:
large groups of detected accounts are challenged with CAPTCHAs;
actions performed in attack campaigns are invalidated in retrospect;
and user-created content, such as photos, is sent for automated san-
ity check (e.g., photoDNA [9]) or manual inspection.
8. EVALUATION
We evaluate SynchroTrap using a one-month execution log at
Facebook in August 2013. We answer the following questions to
show that SynchroTrap provides a practical solution for large on-
line social networks:
• Can SynchroTrap accurately detect malicious accounts while
yielding low false positives?
• How effective is SynchroTrap in uncovering new attacks?
• Can SynchroTrap scale up to Facebook-size OSNs?
We obtain SynchroTrap’s detection accuracy by manually in-
specting sampled accounts and activities it uncovered. We then
study the new ﬁndings through cross-validation against existing
approaches that run at Facebook. We examine the social connec-
tivity of the identiﬁed accounts by using SybilRank [19], a scal-
able social-graph-based fake account detection system. We also
share the operation experience to shed light on how SynchroTrap
works in practice over time. Lastly, we demonstrate the scalability
of SynchroTrap using performance measurements obtained from a
200-machine cluster.
8.1 Validation of identiﬁed accounts
We ﬁrst validate the malicious accounts with support from the
Facebook security team. We proceed with investigation of the con-
ﬁrmed accounts to understand how adversaries managed to take
control of them. Furthermore, we study the network-level charac-
teristics of the detected attacks, including the email domains and IP
addresses used by malicious accounts.
Application
Campaigns
Accounts
Actions
Precision
Instagram App
Page
follow
like
531
201
730K
589K
357M 65M
99.0% 99.7%
install
321
74
564K
164K 120K
4M
29M
48M
100% 100% 100%
Photo
upload
29
Login
Table 2: Identiﬁed accounts and precision. Precision is the portion of
identiﬁed accounts that are conﬁrmed malicious. We derived precision
from manual inspection of randomly sampled accounts by the Face-
book security team.
Methodology. A main challenge to validate the detected accounts
and their actions is their large number. During the month of our
i
s
n
g
a
p
m
a
c
f
o
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
102
103
104
105
Number of users in a campaign
Figure 7: CDF of campaigns with respect to the number of in-
volved users. In a large campaign, an attacker manipulates
multiple thousands of malicious accounts.
study, SynchroTrap uncovers millions of accounts. Manually re-
viewing all those accounts imposes prohibitive human workload.
Furthermore, cross validating the detected accounts with other ex-
isting Facebook countermeasures is not possible because a large
fraction of detected accounts are not caught by other methods (§ 8.2).
Therefore, our approach is to inspect representative samples of the
detected accounts with manual assistance from the security spe-
cialists. We randomly sample subsets of the detected accounts for
inspection and obtain the false rates.
Precision. Table 2 shows the numbers of suspicious accounts Syn-
chroTrap caught and attack campaigns uncovered by SynchroTrap,
and the precision in each application.
In total, SynchroTrap de-
tected 1156 large campaigns that involve more than 2 million ma-
licious accounts, with a precision higher than 99%. Table 2 also
shows that the large attack campaigns are comprised of millions of
user actions. Among the ﬁve deployed applications, attackers were
more active in page like and user following, presumably because
campaigns in these applications are more lucrative. By uncovering
large campaigns, SynchroTrap allows Facebook and Instagram to
identify and properly invalidate millions of malicious user actions
in each application.
Post-processing to deal with false positives. False positives are
detrimental to OSN user experience. Besides adding human efforts
into the process of setting parameters (§ 4.6), we further reduce
false positives through post-processing. First, we discard small user
clusters and screen out only large clusters, which are more likely to
result from large attacks. Based on the experience with the system,
the Facebook security team sets a threshold of 200, above which
almost all users in each cluster are found malicious. Second, we
do not invalidate all actions that a malicious account has performed
during a detection window Tp, but conservatively focus on those
that match at least one action of each of the other accounts in the
same cluster. This post processing step helps rule out valid actions
that a user account may have delivered while being compromised.
Scale of campaigns. Figure 7 shows the CDF of the scale of the
attack campaigns after post-processing, in terms of the number of
involved malicious accounts. While 80% of the campaigns involve
fewer than 1,000 accounts, we also ﬁnd a few very large campaigns,
in which attackers manipulate a few thousands of accounts.
How are the malicious accounts taken under control? Because
attackers have to use accounts to perform malicious activities in
OSNs, it is critical for them to own or hijack a large number of
accounts before launching their campaigns. To understand how
adversaries take control of accounts, the Facebook security team
classiﬁes the reviewed accounts into categories based on how they
were involved in campaigns. The means by which attackers harness
s
t
n
u
o