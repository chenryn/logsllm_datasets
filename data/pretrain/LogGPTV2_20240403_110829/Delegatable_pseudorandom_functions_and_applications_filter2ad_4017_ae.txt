1. Invoke TBRC(a, b, k) and receive the output τ
2. if τ consists only of pair (y, d) then
3.
4. Let τ = (cid:104)(y1, d1), . . . , (yn, dm)(cid:105) and
D = ((d1, . . . , dc), (dc+1, . . . , dm))
be the corresponding decomposition of r = b − a + 1
5. while there is a maximum integer x in {0, . . . , MD} that
does not appear in D:
6.
7.
Find the rightmost pair (yi, x + 1) and compute values
i = G0(yi), y1
y0
Remove (yi, x + 1) from τ , insert the pairs
(y0
order, and update D accordingly
i , x) in τ respecting the strictly decreasing
i , x) and (y1
i = G1(yi)
8. if the leftmost sequence of D is not (B(r), . . . , 0) then
9.
Fill leftmost sequence with values from rightmost
sequence until it complies with the uniform
decomposition of r
10. return τ
In our running example, for the range [2, 7], the TURC al-
gorithm in URC converts the original token retrieved by the
trapdoor algorithm of BRC, τ = (cid:104)(fk(001), 1), (fk(01), 2)(cid:105),
as follows (we underline a newly inserted element to the left
sequence, and depict as bold a newly inserted element to the
right sequence):
(cid:104)(fk(001), 1), (fk(01), 2)(cid:105)
(cid:104)(fk(0010), 0), (fk(01), 2), (fk(0011), 0)(cid:105)
↓
↓
(cid:104)(fk(010), 1), (fk(0010), 0), (fk(011), 1), (fk(0011), 0)(cid:105) .
The C algorithm of URC is identical to that of BRC, be-
cause the trapdoor in URC has exactly the format expected
by this algorithm, i.e., pairs of PRF values corresponding to
GGM subtrees along with their depths. Moreover, during
the evolution of the initial BRC trapdoor into one of uni-
form decomposition in the T algorithm of URC, a partial
PRF value y is substituted by two new PRF values that can
generate the same leaf PRF values as y. As such, the cor-
rectness of the BRC scheme is inherited in URC. Finally,
due to Lemma 1, the size of a w.c.d. (and, hence, also a
uniform decomposition) of r is O(log(r)), which means that
the trapdoor size in URC is also O(log(r)).
4.3 Security
In this section we prove the security of BRC and URC.
Both proofs rely on the security of the pseudorandom gen-
erator of the underlying GGM construction. Note that the
security proof does not follow straightforwardly from the
GGM proof because contrary to the case of GGM where the
adversary obtains only leaf PRFs, the adversary in a DPRF
can obtain also partial PRF values in the GGM tree (via
delegation queries). Note that the tree structure of a trap-
door (which is independent of k) for a range predicate P of
size r is deterministic and public in both BRC and URC.
Thus, when querying the oracle in the security game, the
adversary can map the partial or full PRF values appearing
in τ for a selected P to subtrees in the GGM tree. Based on
this observation, we prove ﬁrst the security of BRC against
adversaries that query only subtrees, or equivalently preﬁxes
for strings in {0, 1}n, where n is the depth of the GGM tree.
We call this type of security subtree security. We conclude
our proofs by showing that the subtree security of BRC im-
plies the security of both schemes.
In order to prove the subtree security property of BRC,
we insure and exploit the subtree security for two special
cases. First, we consider the case that the adversary is non-
adaptive, i.e., it poses all its queries in advance.
Lemma 2 The BRC scheme with depth n and range size at
most λγ is subtree secure against PPT adversaries that make
all their queries, even the challenge query, non-adaptively.
Proof. Let A be a non-adaptive preﬁx-only PPT adver-
sary against a BRC scheme with depth n and maximum
range size λγ. Without loss of generality we assume that
A always advances to step 3 (submits a challenge to the
challenger).
We deﬁne recursively two sequences of PPT algorithms
A = An, . . . ,A1 and Sn, . . . ,S1 as follows.
For i = n − 1, . . . , 1, Ai on input 1λ, initially invokes
Ai+1 receiving all of its non-adaptive queries, and chooses a
random value k(cid:48) in {0, 1}λ. If a query xi ··· xt has the same
most signiﬁcant bit (MSB) as the challenge query, Ai makes
the query xi−1 ··· xt, and responds with the received value y.
Otherwise, it responds with the value Gxt (··· (Gxi−1 (k(cid:48)))).
It returns Ai+1’s output.
For i = n, . . . , 1, on input (z0, z1) ∈ {0, 1}2λ, Si invokes
Ai and receives all of its queries. For every query xi−1 ··· xt,
it responds with Gxt (··· (Gxi−2 (zxi−1 ))) (or zx0 for i = 1).
On the challenge phase, it ﬂips a coin b and acts as the
challenger in a DPRF security game with Ai. It returns 1
iﬀ Ai returns b.
Let qi and pi be the probabilities that Si outputs 1 when
it receives its input from the uniform distribution U2λ in
{0, 1}2λ and the pseudorandom distribution G(Uλ), respec-
tively. By the deﬁnition of Si, pn = Pr[GA
SEC(1λ) = 1] while
q1 ≤ 1/2, since it corresponds to a totally random game.
We next observe that An−1, . . . ,A1 behave like attackers
against the subtree security of BRC schemes with respective
depths n− 1, . . . , 1. The behavior of Ai as an attacker is the
same as Ai+1’s, when the latter interacts with a modiﬁed
challenger that replaces the two possible partial PRF values
for the MSB of a preﬁx, with two random values. Thus,
following the previous notation, we have that pi = qi+1.
Since G(Uλ) and U2λ are indistinguishable, it holds that
|pi − qi| ≤ i(λ), where i(·) is a negligible function. Finally:
|pn − q1| = | nX
(pi − qi)| ≤ nX
|pi − qi| ≤ nX
i(λ) ,
i=1
i=1
i=1
SEC(1λ) = 1] = pn ≤ q1 + n · (λ) ≤ 1/2 + n · (λ),
hence Pr[GA
where (λ) = max
{i(λ)}.
i
We use the above lemma to prove the security of a special
category of BRC schemes, where the maximum range size is
at least half of A = [0, 2n − 1], which represents the biggest
interval where range predicates are deﬁned. This will serve
as a stepping stone for designing our ﬁnal security proof.
Lemma 3 The BRC scheme with depth n and maximum
range size λγ is subtree secure if 2n−1 ≤ λγ < 2n.
n−1 ··· x∗
n−1 ··· x∗
i ⊕ 1), . . . , (x∗
Proof. Let A be a preﬁx-only adversary. We construct a
non-adaptive preﬁx-only adversary B for the subtree security
game that on input 1λ chooses randomly a challenge x∗ in
[0, 2n−1] and makes the n queries that cover all the possible
values except from x∗. Namely, B makes queries (x∗
n−1 ⊕
0 ⊕ 1) and submits
1), . . . , (x∗
challenge x∗. It receives responses yn−1, . . . , y0 respectively,
along with y∗ which is the response to x∗. Then, it invokes
A and plays the security game with A, as a challenger that
can respond appropriately for every value that is not x∗ or a
range that does not contain x∗. If A sets x∗ as a challenge,
then B responds with y∗, and returns A’s guess. Otherwise,
A has either made a query which is a preﬁx of x∗, or it has
submitted a challenge diﬀerent than x∗, so B terminates the
game it plays with A and returns a random bit, as its guess
to its challenge.
Let E be the event that B guesses A’s challenge, i.e. A’s
challenge is x∗. By the description of B we have that
SEC(1λ) = 1 ∧ ¬E] = 1/2 · (1 − 1/2n) and
SEC(1λ) = 1 ∧ E] = 1/2n · Pr[GA
SEC(1λ) = 1] .
Pr[GB
Pr[GB
Since B is non-adaptive, by Lemma 2 we get that for some
SEC(1λ) = 1] ≤ 1/2 + (λ). By
negligible function (·), Pr[GB
adding the above equations we have that
1/2n · (Pr[GA
SEC(1λ) = 1] − 1/2) + 1/2 ≤ 1/2 + (λ) ,
SEC(1λ) = 1] ≤ 1/2 + 2n · (λ) ≤ 1/2 + 2λγ · (λ).
so, Pr[GA
We apply Lemma 3 to prove the subtree security of BRC.
Lemma 4 The BRC scheme with depth n and maximum
range size λγ is subtree secure.
Proof. See Appendix.
Finally, we prove that the subtree security of BRC implies
the security of BRC and URC.
Theorem 3 The BRC and URC schemes with depth n and
maximum range size λγ are secure.
Proof. Let A be a PPT adversary that wins the DPRF
security game of either BRC or URC with non-negligible
advantage α(·). As noted in the beginning of this section,
any query A makes, can be represented as a sequence of
O(log(λγ)) subtrees, or equivalently of O(log(λγ)) preﬁxes.
Thus, we can construct a preﬁx-only adversary A(cid:48) that in-
vokes A and when it receives a query sequence (cid:104)x1
n−1 ··· x1
t1 ,
678
n−1 ··· xm
tm(cid:105) from A, it makes all preﬁx queries sepa-
. . . , xm
rately, receives y1, . . . , ym and answers by (cid:104)y1, . . . , ym(cid:105). A(cid:48)
also transfers A’s challenge and outputs its guess. There-
fore, it wins the DPRF security game with advantage α(·),
which contradicts Lemma 4.
4.4 Policy Privacy
This section analyzes the policy privacy of URC. Accord-
ing to the lower bound argument we gave in Section 3, URC
cannot be expected to satisfy the general policy-privacy prop-
erty, because it is eﬃcient. We illustrate this explicitly with
a toy example. For challenge ranges [2, 5] and [4, 7], the
trapdoors will contain PRF values corresponding to subtrees
covering the ranges as [2, 3],{4},{5} and [4, 5],{6},{7}, re-
spectively. Therefore, the adversary can issue query for leaf
4 and receive a PRF value y. Having (cid:104)(y1, 1), (y2, 0), (y3, 0)(cid:105)
as challenge trapdoor, it can check whether y2 = y, which
happens only when [2, 5] was chosen by the challenger.
Nevertheless, in the theorem below we prove that URC
achieves union policy privacy. The above attack is circum-
vented as in the union policy-privacy game, the adversary
cannot obtain a PRF value for a leaf in the intersection of
the challenge ranges, i.e., for 4 and 5.
Theorem 4 The URC scheme with depth n and maximum
range size λγ is a DPRF with union policy privacy.
Proof. See Appendix.
5. APPLICATIONS
In this section we discuss interesting applications of the
general DPRF primitive and our specialized constructions
for range-based policies. We stress, though, that their ap-
plicability is not limited to these scenarios; we are conﬁdent
that they can capture a much wider set of applications.
Authentication and access control in RFID. Radio
Frequency Identiﬁcation (RFID) is a popular technology that
is expected to become ubiquitous in the near future. An
RFID tag is a small chip with an antenna. It typically stores
a unique ID along with other data, which can be transmit-
ted to a reading device lying within a certain range from the
tag. Suppose that a trusted center (TC) possesses a set of
RFID tags (attached to books, clothes, etc.), and distributes
RFID readers to speciﬁed locations (e.g., libraries, restau-
rants, etc.). Whenever a person or object carrying a tag lies
in proximity with a reader, it transmits its data (e.g., the
title of a book, the brand of a jacket, etc.). The TC can
then retrieve these data from the RFID readers, and mine
useful information (e.g., hotlist books and clothes, etc.).
Despite its merits, RFID technology is challenged by secu-
rity and privacy issues. For example, due to the availability
and low cost of the RFID tags, one can easily create tags
with arbitrary information. As such, an adversary may im-
personate other tags, and provide falsiﬁed data to legitimate
readers. On the other hand, a reader can receive data from
any tag in its vicinity. Therefore, sensitive information may
be leaked to a reader controlled by an adversary. For exam-
ple, the adversary may learn the ID and the title of a book
stored in a tag, match it with public library records, and
discover the identity and reading habits of an individual.
Motivated by the above, authentication and access control
in RFID-based systems has been studied in the literature.
A notable paradigm was introduced in [30], which can be
directly beneﬁted by DPRFs. At a high level, every tag is
associated with a key, and the TC delegates to a reader a set
of these keys (i.e., the reader is authorized to authenticate
and access data from only a subset of the tags). The goal
is for the TC to reduce certain costs, e.g., the size of the
delegation information required to derive the tag keys while
maintaining a high number of distinct keys in order to ensure
that attacks can be compartmentalized.
Observe that a DPRF (F, T, C) is directly applicable to
the above setting. F is deﬁned on the domain of the tag IDs,
and its range is the tag keys. Given a delegation predicate on
the tag IDs, the TC generates a trapdoor via algorithm T ,
and sends it to the reader. The latter runs C on the trapdoor
to retrieve the tag keys. In fact, for the special case where
the access policy is a range of IDs, the delegation protocol
suggested in [30] is identical to the non-private BRC scheme
(we should stress though that [30] lacks rigorous deﬁnitions
and proofs). Range-based policies are meaningful, since tag
IDs may be sequenced according to some common theme
(e.g., books on the same topic are assigned consecutive tag
IDs). In this case, a range policy concisely describes a set
of tags (e.g., books about a certain religion) and, hence, the
system can enjoy the logarithmic delegation size of BRC.
However, as explained in Section 4, BRC leaks the position
of the IDs in the tree, which may further leak information
about the tags. Although [30] addresses tag privacy, it pro-
vides no privacy formulation, and overlooks the above struc-
tural leakage. This can be mitigated by directly applying
our policy-private URC construction for delegating tag keys