should not help to break the Co-CDH assumption.
The entire security experiment consists of four steps:
1. C sends a bilinear group G = (p, g1, g2, e) and gz
2for uni-
formly random z ∈ Zp to A together with uniformly random
A ∈ G1.
2. A outputs Y ∈ GT .
3. C outputs the group elements A1/z ∈ G1 and U ∈ G2 such
that e(A, g2) · Y = e(g1, U ).
4. A outputs W ∈ G2.
A wins if e(A, g2) = e(g1, W ).
DEFINITION 5. We say that the Modiﬁed Knowledge of Co-
CDH Assumption (MKCoCDH) holds if for every PPT algorithm
A there exists another algorithm A’ that given the same inputs and
random coins as A behaves exactly like A while in the second step
of the above security experiment additionally outputting i ∈ Zp
and T ∈ GT such that Y = e(A, g2)i · e(g1, T ) whenever A wins.
2.2 Hash Functions
DEFINITION 6. Consider a set H = {Ht}2κ
t=1 of hash func-
tions indexed by t where each Ht maps from {0, 1}∗ to the hash
space T . We require that log2(|T|) is a polynomial in κ. We say
that H is collision-resistant if for uniformly random t no PPT at-
tacker can output two distinct string m1, m2, such that Ht(m1) =
Ht(m2).
In the following we will always implicitly assume that t is chosen
uniformly at random at the beginning of the setup phase. We will
then drop t and simply write H (and H(cid:48)). In the security proofs we
model hash functions as random oracles.
2.3 Security Model
Let us very brieﬂy re-call the basic features of the security model
we use. For a more detailed exposition we refer to [18].
PROTOCOL FRAMEWORK. We consider a set of up to n = n(κ)
parties P1 to Pn, each of which is identiﬁed via unique (identity)
strings idi for i = 1, . . . , n, and a 2-pass key exchange protocol
Π that can be run between two parties that we typically denote as
idA and idB – or Alice and Bob. Unless stated explicitly otherwise
we always assume that idA (cid:54)= idB. Each instance of the protocol
run at party idi is called session while idi is also called the holder
of that session. A session can either complete, what involves pro-
cessing incoming messages and computing outgoing messages and
a session key K or abort in which case no session key will be com-
puted. Additionally we consider expired sessions which are com-
pleted sessions where the session key and all ephemeral values to
compute the session key have been erased.
2,z(cid:48)
3,z(cid:48)
1, z3 = z(cid:48)
2, z2 = z(cid:48)
4, and z4 = z(cid:48)
4) that z1 = z(cid:48)
The party with which the session key is intended to be shared
with after the protocol run is called peer. (More technically, Bob
is the the peer of one of Alice’s sessions if that session uses idB
to derive the session key.) The session identiﬁer (z1,z2,z3,z4) of
a session is a combination of the identity string of the holder z1,
the identity of the peer z2, the message sent by the session z3,
and the message received by the session z4. We say that two ses-
sions match if it holds for their session identiﬁers (z1,z2,z3,z4) and
(z(cid:48)
1,z(cid:48)
3. There
is also a special party called the key generation center that holds a
master secret key msk and publishes a corresponding master public
key mpk. The msk is used to derive secret keys ski for i = 1, . . . , n
for each of the parties from their corresponding identity strings. We
assume that each party idi receives its ski from the KGC (in an au-
thentic and conﬁdential way that is out of the scope of this paper).
The master public key contains all public information required by
the parties to run the protocol. We assume that each party knows
all identity strings of the other parties.
ATTACKER. We consider an attacker A that controls the entire
network, being able to intercept, modify, drop, replay, and insert
messages on transit. To model this, all outgoing messages are de-
livered to the adversary. If A only relays all the messages that are
sent to some session by its peer it is called passive with respect to
that session, otherwise it is called active. A can also activate ses-
sions of parties to make them engage in a protocol run with peers
of A’s choice. To model attack capabilities that grant the adversary
access to the secret information of sessions, parties, or the KGC,
we allow A to sent different types of queries to sessions.
- A Reveal query reveals the session key of a complete ses-
sion.
- A Corrupt query returns all information in the memory of
the holder of a session. This includes the secret keys of the
party as well as the state information of all its sessions. If a
query has been asked to a session with holder idi we also say
that idi is corrupted.
- A Test query can only be asked once and only to a complete
session that is not exposed. Depending on the outcome of a
randomly tossed coin c ∈ {0, 1}, the output of this query is
either the session key K stored at that session (in this context
also called the test-session) in case c = 0 or a random key
uniformly drawn from the space of session keys in case c =
1.
- The adversary may also make (up to n) Register queries.
On input the j-th identity idj with idj /∈ {id1, . . . , idj−1}
1228for 1 ≤ j ≤ n, this query creates5 party Pj and assigns
identity idj to it. Also the secret key skj corresponding to
identity idj is given to Pj. We assume that parties are ini-
tially uncorrupted.
Observe that in contrast to [18] we have formally introduced a
Register query. This models that the adversary may also adap-
tively choose the identities of the honest (uncorrupted) parties. This
is much stronger than in the mOT model, where the identities of
the uncorrupted parties are ﬁxed at start-up. (We consider it as an
essential feature of identity-based cryptography that the adversary
may choose the identities of the honest parties. This is in fact not
possible in classical key exchange, where we cannot rule out that
when an adversary registers a new public key that it knows the cor-
responding secret key.) Also, via a combination of Register and
Corrupt queries the adversary may obtain secret keys on identities
of his choice. The original model in [20] also speciﬁes queries
that reveal the secret state information of sessions. However, as
stated before, like mOT, our protocol will not be secure against
StateReveal queries (even not when only revealing the ephemeral
public keys gx
2 ). As in [18] we instead require protection
of these values to be at the same level as that of ski. As mentioned
before we can show in Appendix E that any protocol which allows
the adversary to obtain ephemeral secret keys, cannot provide full
PFS. In general, we require that except for session keys, all inter-
nal information of parties and sessions can only be revealed via full
party corruptions.
1 and gy
We say that a session is exposed if its holder has been corrupted
or its session key been revealed. Additionally sessions are consid-
ered exposed if there exists a matching session that is exposed.
SECURITY DEFINITIONS. Let SG denote the following security
game between a challenger C and an attacker A.
1. C gives to A the master public key mpk.
2. A may activate sessions and issue Reveal, Corrupt, and
Register queries to its liking. Also, A may use its control of
the network to modify messages on transit.
3. A may ask the Test query to some completed, unexposed
session with holder idA and peer idB such that idA (cid:54)= idB.
Let K be the response and c the internal random coin gener-
ated by the test session when answering the query.
4. A may activate sessions, issue Reveal, Corrupt, Register
queries, and use its control of the network to modify mes-
sages on transit.
5. A outputs c(cid:48) ∈ {0, 1}.
We say that an attacker A succeeds in a distinguishing attack if
c(cid:48) = c, the test session is not exposed and the peer of the test-
session has not been corrupted.
DEFINITION 7. An identity-based key agreement protocol Π is
secure if for all PPT attackers A that are given the above attack
capabilities, it holds that i) if two matching sessions of uncorrupted
parties complete the probability that the corresponding session keys
differ is negligibly close to zero and ii) A has success probability
in a distinguishing attack negligibly close to 1/2.
5Alternatively we may think of all the Pi for 1 ≤ i ≤ n to exists
before the security game without any identity or secret key. More-
over, they cannot be corrupted. Then Register only assigns idj and
skj to Pj.
DEFINITION 8
(WEAK PFS). We say that Π is secure with
weak perfect forward secrecy if in SG attacker A is also allowed
to corrupt the peer and the holder of the test-session after the test-
session key expired and A has remained passive (only) with respect
to the test-session and its matching session(s).
We stress that in our security proof of weak forward secrecy, secu-
rity even holds when the attacker knows the secret long term keys
(but no other session speciﬁc secret information) of the peer and the
holder and the KGC before the session key is computed. This can
be interesting when dealing with devices where long-term keys and
session speciﬁc information are stored separately in two different
memories possibly at different locations, but both with approxi-
mately the same level of protection against unauthenticated access.
Thus corruptions would not reveal session-speciﬁc information. In
these scenarios the Corrupt query would only allow to reveal the
long-term secrets. Next, we present a formal deﬁnition that cap-
tures this strengthened form of weak PFS. Essentially, it reﬂects
the intuition that forward secrecy should only rely on the secrecy
of the ephemeral keys but not of any long-term secret.
DEFINITION 9
(ENHANCED WEAK PFS). We say that Π pro-
vides enhanced weak perfect forward secrecy if Π is secure with
weak perfect forward secrecy even if A is additionally given the
secret keys of all parties and the secret key of the KGC at the be-
ginning of the security game and we allow that idA = idB.
Let us now deﬁne full PFS. In contrast to the previous deﬁnitions
we do not require the attacker to remain passive with respect to the
test-session.
DEFINITION 10
(FULL PFS). We say that Π is secure with
full perfect forward secrecy if in SG attacker A is additionally al-
lowed to i) obtain the secret key of the holder of the test session at
the beginning of the security experiment and ii) corrupt the peer of
the test session after the test-session key expired.
KEY COMPROMISE IMPERSONATION ATTACKS. We also cover
key compromise impersonation attacks. In a KCI attack, A may
after obtaining the secret key of party idA make idA falsely believe
that it is communicating with some other uncorrupted party idB al-
though idA actually isn’t. (Obviously impersonating Alice to other
parties with the help of Alice’s secret key is trivial.)
DEFINITION 11
(KCI SECURITY). We say that Π is secure
against KCI attacks if in SG attacker A is additionally given the
secret key of the holder of the test session at the beginning of the
security experiment.
Obviously, KCI security implies security under Deﬁnition 7 since
the adversary is only given additional information to mount its at-
tack.
REFLECTION ATTACKS. We additionally cover reﬂection attacks
in which an attacker makes two sessions of the same party com-
municate with each other. As pointed out by GKR, these attacks
are relevant in real-life scenarios when Alice wants to establish a
connection between two of her computers (for example access to a
home computer via her laptop).
DEFINITION 12
(SECURITY AGAINST REFLECT. ATTACKS).
We say that Π is secure against reﬂection attacks if in SG attacker
A may also choose a test-session whose peer is equal to its holder,
i.e. allowing idA = idB.
12293. MAIN RESULT
A detailed description of TOPAS is given in Figure 1. We re-
mark that the challenge in designing a protocol which provides
optimal message size and full PFS is that any such protocol must
provide two key properties. First, it must include an exchange of
ephemeral public keys as otherwise we cannot have any meaningful
form of forward secrecy. (Otherwise the session key can be derived
by Alice solely from her long-term key and any adversary that ob-
tains this key in a PFS experiment can also compute the session
key.) On the other hand, the protocol must also somehow make
the parties ‘authenticate’ their ephemeral public keys using their
corresponding long-term secrets as otherwise, by the impossibility
result of Krawczyk (Appendix D), we cannot have full PFS. The
difﬁculty when designing a protocol with optimal message length
now lies in the fact that we need to combine the two requirements
into a single short value.
In TOPAS, Alice and Bob exchange blinded versions of their
long-term keys. In particular, in each message the long-term secret
is multiplied by a fresh ephemeral Difﬁe-Hellman key. Each long-
term key in turn is a unique signature on the identity of its holder
under the master secret. The veriﬁcation equation for this signature
relies on the bilinear pairing and can be re-written as
e(skA, gz
2 )/e(H(idA), g2) ?= 1.
The crucial feature of the key derivation of TOPAS is that, due
to the bilinearity of the pairing, Bob can strip off the signature
skA (and thus any identity-speciﬁc information) from the message
1 skA. However, the result lies in the target group and has an
a = gx
additional exponent z:
e(a, gz
2 )/e(H(idB), g2)
2 )/e(H(idA), g2) = e(gx
= e(gx
1 , gz
1 , gz
2 )e(skA, gz
2 ) = e(g1, g2)xz.
By symmetry, Alice computes e(g1, g2)yz. Together with their own
secret ephemeral key, each party can now compute e(g1, g2)xyz.
In this rest of this section we present a security analysis of our
new protocol. We start by showing that TOPAS provides security
against KCI and reﬂection attacks, as well as enhanced weak PFS
under non-interactive security assumptions. Next, we provide a
proof of full PFS security.
3.1 Basic Security Properties
THEOREM 1. In the random oracle model, TOPAS is secure
against KCI attacks under the (2, 3)-CBDHI assumption, and se-
cure against reﬂection attacks under the (2, 3)-GCBDHI assump-
tion.
PROOF. It is straight-forward to show that two matching ses-
sions compute the same key. Since they are matching, they com-
pute the same session identiﬁer. Also, as shown above they com-
pute the same values k, k(cid:48). Thus all inputs to H(cid:48) are identical for
each session and the session key is equal too.
1, ˆgt
2, ˆgt2
1, ˆgt2
2, ˆgt3
In the next step, we show that real session keys are indistinguish-
able from random keys. Assume we are given the random input
G = (p, ˆg1, ˆg2, e) and (ˆgt
2 ) to the CBDHI/GCBDHI
2 = ˆgti
challenge. First, we let the simulator set g1 = ˆgt
2
for i = 1, 2, 3. This implicitly sets msk = z = t. Next, the simu-
lator draws random r, s ∈ Zp and sets h2 = gs
2 and
for some v ∈ Zp. This implicitly sets
hz
2 = (gz
v = s − rz2. Observe that all values are distributed exactly as in
the original security game.
2 )r = gvz
2