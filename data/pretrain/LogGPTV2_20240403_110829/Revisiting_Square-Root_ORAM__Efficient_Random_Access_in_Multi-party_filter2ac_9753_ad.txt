### Corresponding Waksman Control Bits

The corresponding Waksman control bits are used to jointly permute the elements of the secret permutation \(\pi^{-1}\), resulting in \(\pi^{-1} \cdot \pi_a = \pi_b\). Next, \(\pi_b\) is revealed to the second party, Bob (but not to Alice). Bob does not learn anything about \(\pi^{-1}\) because it is masked by \(\pi_a\). Bob then locally computes \(\pi_b^{-1}\), and the two parties jointly execute another Waksman network to compute \(\pi_a \cdot \pi_b^{-1} = \pi\).

### Evaluation

To evaluate our design, we implemented our Square-Root ORAM and Circuit ORAM, the best-performing previous ORAM design, using the same state-of-the-art MPC frameworks. We measured their performance on a set of microbenchmarks. Additionally, we wanted to understand the impact of different ORAM designs on application performance and how close we are to enabling general-purpose MPC. To this end, we implemented several application benchmarks representing a wide range of memory behaviors and evaluated their performance with different ORAM designs.

#### A. Experimental Setup

We implemented and benchmarked RAM-SC protocols based on our ORAM and Circuit ORAM using the Obliv-C [40] framework, which executes Yao’s garbled circuit protocol. Obliv-C provides a C-like language interface and incorporates many recent optimizations [3, 17, 41].

All code was compiled using gcc version 4.8.4 with the -O3 flag enabled. Unless otherwise specified, all reported times are wall-clock times for the entire protocol execution. Our benchmarks were performed using commercially available computing resources from Amazon Elastic Compute Cloud (EC2). We used compute-optimized instances of type C4.2xlarge running Amazon’s distribution of Ubuntu 14.04 (64-bit). These instances provide four physical cores (capable of executing eight simultaneous threads in total), partitioned from an Intel Xeon E5-2666 v3, and 15 GiB of memory. Our benchmarks are single-threaded and do not saturate the available processing power. We selected C4.2xlarge nodes based on their greater bandwidth and memory. Each benchmark was executed between two separate nodes within the same datacenter. We used iperf to measure the inter-node bandwidth, finding it to be approximately 1.03 Gbps.

In addition to square-root ORAM, we benchmarked a simple linear scan and an implementation of Circuit ORAM, the best previously reported ORAM construction for MPC. Our implementation of Circuit ORAM is much more efficient than the original implementation described in Wang et al. [34]. For example, while executing benchmarks on an Amazon C4.8xlarge EC2 instance for an ORAM of one million 32-bit blocks, they reported an access time of two seconds. On a less powerful, more bandwidth-constrained C4.2xlarge EC2 instance, our implementation requires only 0.16 seconds per access for an ORAM with the same parameters. This reduction by a factor of roughly twelve is mostly due to the efficiency advantages of the Obliv-C framework over the ObliVM [24] framework used by Wang et al.’s implementation. For all performance reported, we let Circuit ORAM and square-root ORAM pack 8 entries in each recursive level. Circuit ORAM stops recursion when there are fewer than 28 entries.

#### B. Microbenchmarks

We performed several microbenchmarks to assess the granular performance of different ORAM designs. We observed single-access execution times for block counts varying from 4 to 1024 and block sizes varying from 4 to 1024 bytes. This is the region of parameter space where the efficiencies of Square-Root ORAM and linear scan overlap. Figure 8 shows the efficiency crossover points derived from this data, ignoring initialization costs.

Due to the nature of the Square-Root ORAM algorithm, each access is more expensive than the previous one until a shuffle occurs and resets the cycle. To ensure our averages are representative, we collected a number of samples for each ORAM configuration equal to a multiple of the Square-Root ORAM shuffle period that is greater than thirty, except in the case of linear scan, for which exactly thirty samples were collected.

**Break-even Points:**
- Linear scan is preferred to Square-Root ORAM only for very small numbers of blocks.
- Circuit ORAM is orders of magnitude more expensive for similar parameters due to its high fixed access cost.
- Our Square-Root ORAM implementation achieves a very low break-even point with linear scan. When using 4096 or fewer blocks, Circuit ORAM never outperforms. At a block size of 4 bytes, Circuit ORAM remains suboptimal until more than 500,000 blocks, but this increases initialization costs.

**Comparison to Circuit ORAM:**
- In comparing our Square-Root ORAM scheme to Circuit ORAM, we consider initialization and access costs separately since the number of accesses per initialization will vary across applications.
- Figure 9 shows the per-access wall-clock time for both designs, as well as for linear scan, ignoring initialization.
- As expected, Circuit ORAM has the best asymptotic performance but also has a very high fixed cost per access, independent of the number of blocks.
- Square-Root ORAM performs better than Circuit ORAM for all block counts up to \(2^{16}\), even ignoring initialization costs. For block counts less than \(2^{11}\), linear scan also outperforms Circuit ORAM.
- These results are consistent with our analysis in Section III-D that Square-Root ORAM has worse asymptotic behavior but smaller hidden constants.

**Initialization Costs:**
- For any application where the number of accesses is not significantly larger than the number of blocks in the ORAM, initialization cost must be considered.
- Figure 10 shows the initialization wall-clock times for Square-Root and Circuit ORAM, with parameters matching those in our access-time comparison.
- Initializing Square-Root ORAM is approximately 100 times faster than initializing Circuit ORAM, regardless of block count or block size.
- The standard way to populate Circuit ORAM is to insert each data element individually, using standard ORAM access operations; thus, the cost scales linearly with the number of blocks to be populated.
- We hypothesize that most of this speed improvement comes from having fewer network round trips in our initialization process. Circuit ORAM requires \(\Theta(N \log N)\) round trips for initialization, while our scheme requires only \(\Theta(\log N)\).

#### C. Oblivious Binary Search

Unlike our other application benchmarks, binary search performs very few accesses relative to the ORAM size. An equivalent search can be performed using a single linear scan, and if only one search is to be performed, the linear scan is always more efficient. Consequently, we varied the number of searches performed for this benchmark rather than the block size or block count.

We benchmarked binary search using a block size of 16 bytes and element counts of \(2^{10}\) and \(2^{15}\). For arrays of \(2^{10}\) elements, we averaged the running time over 30 samples, and for \(2^{15}\) elements, we used 3 samples. A few representative combinations for \(2^{15}\) elements are reported in Table I.

**Results:**
- Initialization dominates execution time unless many searches are performed on the same data.
- Square-Root ORAM is more than two orders of magnitude better than Circuit ORAM when only one search is performed.
- For searches of \(2^{10}\) elements, the linear scan method is more efficient than a binary search regardless of the ORAM type or the number of searches performed.
- Linear scan is initially faster for searches of \(2^{15}\) elements as well, but Square-Root ORAM becomes more efficient than the linear scan method at 25 searches.
- Accesses to a Circuit ORAM of \(2^{15}\) elements are more expensive than accesses to a Square-Root ORAM of the same size, so at this array size, Circuit ORAM will never be more efficient regardless of the number of searches performed.

#### D. Oblivious Breadth-First Search

Natively-oblivious formulations of Breadth-First Search (BFS) and other graph algorithms have been explored in the past [5]; however, we use a variant of the standard algorithm optimized for use in an oblivious context. It has complexity in \(\Theta((V + E)C_{\text{Access}})\), where \(C_{\text{Access}}\) is the complexity of accessing an element in the underlying ORAM construction. We allow our ORAM implementations to apply arbitrary functions to modify the blocks they access, as opposed to the simple read and write functions shown in Figure 2. This reduces the total number of ORAM accesses, for example, by permitting combined read and update operations. Rather than using an ORAM to house the queue, we use the oblivious queue data structure from Zahur and Evans [39].

We benchmarked our BFS implementation using linear scan, Circuit ORAM, and Square-Root ORAM. We took 30 samples for experiments of \(n\) vertices and \(\gamma \times n\) edges, with \(n\) ranging from 4 to 1024 and \(\gamma\) as 8. For each sample, a fresh set of edges was generated randomly among the chosen number of vertices. A few representative combinations are shown in Table I.

**Results:**
- The results of the BFS benchmark roughly follow the pattern established by the microbenchmarks in Section V-B.
- Small numbers of vertices and edges yield small ORAMs, and linear scan proves to be best in these cases.
- As the number of vertices or edges begins to rise, Square-Root ORAM quickly becomes more efficient than linear scan.
- Our BFS implementation uses blocks of only a few bytes each; as a result, Circuit ORAM eventually becomes more efficient than linear scan, but it does not approach the efficiency of Square-Root ORAM before the upper bound of our testing range is reached at \(n = 2^{10}\). Beyond that point, the benchmarks would have required several hours to complete.

#### E. Oblivious Stable Matching

To explore a benchmark representative of a complex algorithm, we implemented an oblivious version of the Gale-Shapley stable matching algorithm [8]. We followed the textbook algorithm closely. Although we believe there are significant optimizations available in adapting the algorithm for use in MPC, they are beyond the scope of this work.

As a result, our implementation requires \(\Theta(n^2)\) accesses of an ORAM with \(n^2\) elements. It also uses several ORAMs of length \(n\). The most efficient arrangement may be to mix ORAM schemes, but we have not done this. As in our BFS implementation, we used function application to reduce the number of ORAM accesses.

We benchmarked our implementation of Gale-Shapley with both Circuit and Square-Root ORAMs as the underlying structure, but not linear scan, since it is clear that linear scan cannot be competitive for this benchmark, and the expense of executing it on non-trivial sizes would be considerable. The number of pairs to be matched ranged from 4 to 512. When the pair count was less than 128, we collected 30 samples; for pair counts of 128 and 256, we collected 3 samples; for 512 pairs, we collected one sample. Results for a few representative configurations are included in Table I.

**Results:**
- Square-Root ORAM proved more efficient over the range of tested configurations.