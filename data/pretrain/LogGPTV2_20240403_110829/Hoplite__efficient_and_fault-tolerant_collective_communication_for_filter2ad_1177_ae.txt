training throughput by 2.2x on the 8-node configuration and 3.9x
on the 16-node configuration. Unlike IMPALA, A3C achieves almost
linear scaling with the number of workers. A3C on Ray cannot scale
linearly from 8 nodes to 16 nodes because of the communication
bottleneck.
5.4 ML Model Serving
Machine learning is deployed in a growing number of applications
which demand real-time, accurate, and robust predictions under
heavy query load [3, 10, 36]. An important use case of task-based
distributed system is to serve a wide range of machine learning
models implemented with different machine learning frameworks
[30].
We evaluate Hoplite with Ray Serve [42], a framework-agnostic
distributed machine learning model serving library built on Ray.
We set up an image classification service with a majority vote-
based ensemble of the following models: AlexNet [23], ResNet34
[18], EfficientNet-B1/-B2 [50], MobileNet V2 [45], ShuffleNet V2
x0.5/x1.0 [28], and SqueezeNet V1.1 [20]. We test two cluster con-
figurations: 8 p3.2xlarge nodes and 16 p3.2xlarge nodes on AWS.
For 8 nodes setting, we serve a different model on each node. For 16
nodes setting, each model is served by two different nodes and the
two nodes serve the model with two different versions of weight
parameters. Each query to the service includes a batch of 64 im-
ages of size 256×256. During serving, the service will broadcast the
AlexNetVGG-16ResNet50025050075010001250150017502000Throughput(samples/s)HopliteRayAlexNetVGG-16ResNet50025050075010001250150017502000Throughput(samples/s)HopliteRay816Number of nodes050100150200250300Throughput(samples/s)HopliteRay816Number of nodes020406080100Throughput(samples/s)HopliteRayHoplite: Efficient and Fault-Tolerant Collective Communication for Task-Based Distributed Systems
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Figure 11: Ray Serve’s performance (queries per second) on Ray and
Hoplite for an ensemble of image classification models.
Figure 13: Training throughput (number of training samples per second)
for synchronous data-parallel training.
(a) Number of Nodes = 8
(b) Number of Nodes = 16
rejoin). In async SGD, latency for training each iteration increases
in the recovery window because of the temporary loss of a worker.
The difference in recovery latency (duration of the recovery win-
dow) between Ray and Hoplite is negligible because both use Ray’s
mechanism to reconstruct the failed task.
(a) Ray Server latency.
(b) Async SGD latency.
Figure 12: Latency when a pariticipating task fails and rejoins on (a) Ray
Serve and (b) async SGD.
query to all the nodes to evaluate on different models, gather the
classification results, and return the majority vote to the user.
We visualize the results in Figure 11. Hoplite improves the serv-
ing throughput for serving an ensemble of image classification
models. Comparing to Ray, it speedups the serving throughput by
2.2x for 8 nodes and 3.3x for 16 nodes. This shows that the opti-
mized broadcast algorithm in Hoplite helps Ray Serve to improve
the serving throughput.
5.5 Fault Tolerance
We evaluate the failure recovery latency before and after we apply
Hoplite to Ray. We rerun our model serving with 8 models and
async SGD workloads with 6 workers, and we manually trigger
a failure. We do this experiment 10 times. Figure 12 shows one
particular run. The y-axis shows the latency per query (in model
serving) or per iteration (in async SGD), and the x-axis shows the
index of the query or the iteration. Hoplite significantly improves
Ray’s performance. Ray’s failure detection latency is 0.58 ± 0.13
second, and after we apply Hoplite to Ray, Ray’s failure detection
latency increases to 0.74 ± 0.05 second. The additional 28% latency
introduced by Hoplite is because Hoplite has a different failure
detection mechanism. Ray detects failure by monitoring the live-
ness of the worker process. Hoplite detects failure by checking the
liveness of a socket connection.
After the failure, Ray Serve’s latency drops because it only needs
to broadcast to less receivers. The latency comes back to normal
after the failed worker rejoins. For Hoplite, the latency difference
is negligible because of the efficient broadcast algorithm. Hoplite
takes more queries between the task fails and the task rejoins. This
is because Hoplite is efficient and has processed more queries dur-
ing the recovery window (the time between the failure and task
5.6 Synchronous Data-Parallel Training
Synchronous data-parallel training involves a set of workers, each
runs on a partition of training data, and the workers synchronize
the gradients each round using allreduce [15]. Speeding up synchro-
nous data-parallel training workloads is not our design goal, and
they do not require the flexibility provided by task-based systems.
Instead, they can run directly on specialized distributed systems
that are optimized for static and synchronous workloads (e.g., Ten-
sorFlow [1], PyTorch [37]). These systems rely on efficient allreduce
implementations in traditional collective communication frame-
works (e.g., OpenMPI, Gloo).
However, an interesting question to ask is how much perfor-
mance developers have to pay if they choose to run these static
and synchronous workloads on task-based distributed systems. Our
cluster setup is the same as the asynchronous parameter server
experiment. In addition to Ray, we evaluate Gloo and OpenMPI.
We evaluate the Gloo baseline through PyTorch, which chooses
ring-chunked allreduce as its choice for Gloo’s algorithm.
We show the results in Figure 13. Hoplite significantly improves
the synchronous data-parallel training for Ray. Ray is slower than
Hoplite, OpenMPI, and Gloo, with the similar reason as in asyn-
chronous parameter server. Hoplite achieves similar speed with
OpenMPI. However, Hoplite is 12-24% slower than Gloo. This is
expected because ring-allreduce is more bandwidth efficient than
the tree-reduce plus broadcast in Hoplite.
6 DISCUSSION
Garbage collection. Hoplite provides a Delete call (Table 1) that
deletes all copies of an object from the store. This can be used to
garbage-collect an object whose ObjectID is no longer in scope in
the application. However, it is still the task framework or applica-
tion’s responsibility to determine when Delete can and should be
called, since only these layers have visibility into which ObjectIDs
a task has references to. The guarantee that Hoplite provides is
simple: when Put is called on an ObjectID, the object copy that is
created will be pinned in its local store until the framework calls
Delete on the same ID. This guarantees that there will always be
at least one available location of the object to copy from, to fulfill
816Number of nodes012345678Throughput(queries/s)HopliteRay010203040506070Queries0.00.20.40.60.8Latency (s)RayHopliteWorker FailedWorker Rejoined051015202530Iterations0.000.250.500.751.001.251.50Latency (s)RayHopliteWorker FailedWorker RejoinedAlexNetVGG-16ResNet50050010001500200025003000Throughput(samples/s)HopliteOpenMPIGlooRayAlexNetVGG-16ResNet50050010001500200025003000Throughput(samples/s)HopliteOpenMPIGlooRaySIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Siyuan Zhuang et al.
future Get requests. Meanwhile, Hoplite is free to evict any addi-
tional copies that were generated on other nodes during execution,
to make room for new objects. The overhead of eviction is very low,
since Hoplite uses a local LRU policy per node that considers all
unpinned object copies in the local store.
Framework’s Fault tolerance. Hoplite ensures that collective com-
munication can tolerate task failure. A task-based distributed sys-
tem has a set of control processes that can also fail, and they usually
require separate mechanisms to tolerate failures. For example, the
object directory service can fail and requires replication for dura-
bility. These failures are handled by the underlying framework
independent of whether Hoplite is used.
Network Heterogeneity. The design of Hoplite assumes that the
network capacity between all the nodes is uniform. Accommodat-
ing heterogeneous network can achieve higher performance (e.g.,
using high bandwidth nodes as intermediate nodes for broadcast,
fetching objects from a node which has lower latency). This can be
done by monitoring network metrics at run time. We do not need
this feature for our use cases because our cloud provider ensures
uniform network bandwidth between our nodes.
Integration with GPU. Hoplite currently does not support pipelin-
ing into GPU memory. If training processes need to use GPU, the
application has to copy data between GPU and CPU memory. In
the future, we want to extend our pipelining mechanism into GPU
memory.
7 RELATED WORK
Optimizing data transfer for cluster computing. Cluster computing
frameworks, such as Spark [53] and MapReduce [12], have been
popular for decades for data processing, and optimizing data trans-
fer for them [7–9, 24, 39] has been studied extensively. AI appli-
cations are particularly relevant because they are communication-
intensive, and traditional collective communication techniques are
widely-used [14, 47, 51]. Pipelining is also a well-known technique
to improve performance [33, 38]. Our work focuses on improving
task-based distributed systems [19, 30, 44]. Applications on these
frameworks have dynamic and asynchronous traffic patterns. To
the best of our knowledge, Hoplite is the first work to provide effi-
cient collective communication support for task-based distributed
systems.
Using named objects or object futures for data communication. Us-
ing named objects or object futures for data communication is not
new. In serverless computing, tasks (or functions) cannot communi-
cate directly. As a result, tasks communicate through external data
stores [40], such as Amazon S3 [2] or Redis [43]. There, the storage
and compute servers are disaggregated, and computer servers do
not directly communicate. We target a standard cluster comput-
ing scenario, where data is directly transmitted between compute
servers. Object futures are a useful construct for expressing asyn-
chronous computation. Dask, Ray, Hydro, and PyTorch [37] all use
futures to represent results of remote tasks. Our work is comple-
mentary to them, showing that efficient collective communication
can co-exist with named objects or object futures.
Asynchronous MPI. MPI supports two flavors of asynchrony. First,
similar to a non-blocking POSIX socket, MPI allows an applica-
tion to issue asynchronous network primitives and exposes an
MPI_Wait primitive to fetch the result. Second, depending on the
MPI implementation, some collective communication primitives
can make some progress with a subset of participants. For example,
in MPI_Bcast, the sender generates a static broadcast tree. If the
receivers arrive in order from the root of the tree to the leaves of
the tree, the receivers can make significant progress before the last
receiver arrives. If not, then a receiver must wait until all its up-
stream ancestors are ready before making any progress (evaluated
in Figure 8). In Hoplite, the broadcast tree is generated dynamically
at runtime, so the arrival order does not matter. In addition, asyn-
chronous MPI primitives still require applications to specify all the
participants before runtime. In Hoplite, the communication pattern
can be expressed dynamically and incrementally, allowing Hoplite
to work with existing task-based distributed systems.
Collective communication in other domains. Optimizing data trans-
fer has been studied extensively in other domains. Application-level
multicast [5, 6] for streaming video on wide-area networks. IP mul-
ticast [21] enables a sender to send simultaneously to multiple IP
addresses at the same time. These work mostly focus entirely on
multicast rather than general-purpose collective communication in
distributed computing frameworks.
8 CONCLUSION
Task-based distributed computing frameworks have become pop-
ular for distributed applications that contain dynamic and asyn-
chronous workloads. We cannot directly use traditional collective
communication libraries in task-based distributed systems, because
(1) they require static communication patterns and (2) they are
not fault-tolerant. We design and implement Hoplite, an efficient
and fault-tolerant communication layer for task-based distributed
systems that achieves efficient collective communication. Hoplite
computes data transfer schedules on the fly, and even when tasks
fail, Hoplite can allow well-behaving tasks to keep making progress
while waiting for the failed tasks to recover. We port a popular
distributed computing framework, Ray, on top of Hoplite. Hoplite
speeds up asynchronous SGD, RL, model serving workloads by up
to 7.8x, 3.9x, and 3.3x, respectively. Hoplite’s source code is publicly
available (https://github.com/suquark/hoplite). This work does not
raise any ethical issues.
ACKNOWLEDGEMENTS
We thank our shepherd Kai Chen and the anonymous reviewers
for their insightful feedback. We also thank Hong Zhang and many
others at the UC Berkeley RISELab for their helpful discussion
and comments. In addition to NSF CISE Expeditions Award CCF-
1730628, this research is supported by gifts from Alibaba Group,
Amazon Web Services, Ant Group, CapitalOne, Ericsson, Facebook,
Futurewei, Google, Intel, Microsoft, Nvidia, Scotiabank, Splunk, and
VMware. Danyang Zhuo is supported by an IBM Academic Award.
REFERENCES
[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, and et
al. 2016. TensorFlow: A System for Large-Scale Machine Learning. In Proceedings
of the 12th USENIX Conference on Operating Systems Design and Implementation
(Savannah, GA, USA) (OSDI’16). USENIX Association, USA, 265–283.
[2] Amazon S3 2020. Amazon S3. Object storage built to store and retrieve any
amount of data from anywhere. https://aws.amazon.com/s3/.
Hoplite: Efficient and Fault-Tolerant Collective Communication for Task-Based Distributed Systems
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
[3] Denis Baylor, Eric Breck, Heng-Tze Cheng, Noah Fiedel, Chuan Yu Foo, Zakaria
Haque, Salem Haykal, Mustafa Ispir, Vihan Jain, Levent Koc, et al. 2017. Tfx: A
tensorflow-based production-scale machine learning platform. In Proceedings of