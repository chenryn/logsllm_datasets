28th USENIX Security Symposium    605
goal of understanding the software’s ultimate behaviour, but
they offer insights with different certainty and granularity:
static analysis reports instances of hypothetical behaviour;
dynamic analysis gives reports of observed behaviour.
Static Analysis Static analysis involves scanning the code
for all possible combinations of execution ﬂows to understand
potential execution behaviours—the behaviours of interest
may include various privacy violations (e.g., access to sen-
sitive user data). Several studies have used static analysis to
analyze different types of software in search of malicious be-
haviours and privacy leaks [4, 9–11, 19–22, 32, 37, 39, 41, 45,
92]. However, static analysis does not produce actual observa-
tions of privacy violations; it can only suggest that a violation
may happen if a given part of the code gets executed at run-
time. This means that static analysis provides an upper bound
on hypothetical behaviours (i.e., yielding false positives).
The biggest advantage of static analysis is that it is easy
to perform automatically and at scale. Developers, however,
have options to evade detection by static analysis because a
program’s runtime behaviour can differ enormously from its
superﬁcial appearance. For example, they can use code obfus-
cation [23, 29, 48] or alter the ﬂow of the program to hide the
way that the software operates in reality [23, 29, 48]. Native
code in unmanaged languages allow pointer arithmetic that
can skip over parts of functions that guarantee pre-conditions.
Java’s reﬂection feature allows the execution of dynamically
created instructions and dynamically loaded code that simi-
larly evades static analysis. Recent studies have shown that
around 30% of apps render code dynamically [46], so static
analysis may be insufﬁcient in those cases.
From an app analysis perspective, static analysis lacks the
contextual aspect, i.e., it fails to observe the circumstances
surrounding each observation of sensitive resource access
and sharing, which is important in understanding when a
given privacy violation is likely to happen. For these reasons,
static analysis is useful, but is well complemented by dynamic
analysis to augment or conﬁrm ﬁndings.
Dynamic analysis Dynamic analysis studies an executable
by running it and auditing its runtime behaviour. Typically,
dynamic analysis beneﬁts from running the executable in
a controlled environment, such as an instrumented mobile
OS [27, 85], to gain observations of an app’s behaviour [16,
32, 46, 47, 50, 65, 66, 73, 85, 87–89].
There are several methods that can be used in dynamic
analysis, one example is taint analysis [27, 32] which can be
inefﬁcient and prone to control ﬂow attacks [68, 71]. A chal-
lenge to performing dynamic analysis is the logistical burden
of performing it at scale. Analyzing a single Android app in
isolation is straightforward, but scaling it to run automatically
for tens of thousands of apps is not. Scaling dynamic analysis
is facilitated with automated execution and creation of be-
havioural reports. This means that effective dynamic analysis
Figure 1: Covert and side channels. (a) A security mechanism
allows app1 access to resources but denies app2 access; this is
circumvented by app2 using app1 as a facade to obtain access
over a communication channel not monitored by the security
mechanism. (b) A security mechanism denies app1 access
to resources; this is circumvented by accessing the resources
through a side channel that bypasses the security mechanism.
being protected by the same permission. A classical example
of a side channel attack is the timing attack to exﬁltrate an
encryption key from secure storage [42]. The system under
attack is an algorithm that performs computation with the key
and unintentionally leaks timing information—i.e., how long
it runs—that reveals critical information about the key.
Side channels are typically an unintentional consequence of
a complicated system. (“Backdoors” are intentionally-created
side channels that are meant to be obscure.) In Android, a
large and complicated API results in the same data appear-
ing in different locations, each governed by different access
control mechanisms. When one API is protected with permis-
sions, another unprotected method may be used to obtain the
same data or an ersatz version of it.
2.3 App Analysis Methods
Researchers use two primary techniques to analyze app be-
haviour: static and dynamic analysis. In short, static analysis
studies software as data by reading it; dynamic analysis stud-
ies software as code by running it. Both approaches have the
606    28th USENIX Security Symposium
USENIX Association
(b) side channel(a) covert channelaccessallow denyaccesssecurity mechanismside channelapp 1security mechanismapp 1accessdeny app 2covert channelrequires building an instrumentation framework for possible
behaviours of interest a priori and then engineering a system
to manage the endeavor.
Nevertheless, some apps are resistant to being audited when
run in virtual or privileged environments [12, 68]. This has
led to new auditing techniques that involve app execution on
real phones, such as by forwarding trafﬁc through a VPN in
order to inspect network communications [44, 60, 63]. The
limitations of this approach are the use of techniques robust
to man-in-the-middle attacks [28, 31, 61] and scalability due
to the need to actually run apps with user input.
A tool to automatically execute apps on the Android plat-
form is the UI/Application Exerciser Monkey [6]. The Mon-
key is a UI fuzzer that generates synthetic user input, ensuring
that some interaction occurs with the app being automatically
tested. The Monkey has no context for its actions with the UI,
however, so some important code paths may not be executed
due to the random nature of its interactions with the app. As
a result, this gives a lower bound for possible app behaviours,
but unlike static analysis, it does not yield false positives.
Hybrid Analysis Static and dynamic analysis methods
complement each other. In fact, some types of analysis bene-
ﬁt from a hybrid approach, in which combining both methods
can increase the coverage, scalability, or visibility of the anal-
yses. This is the case for malicious or deceptive apps that
actively try to defeat one individual method (e.g., by using ob-
fuscation or techniques to detect virtualized environments or
TLS interception). One approach would be to ﬁrst carry out
dynamic analysis to triage potential suspicious cases, based
on collected observations, to be later examined thoroughly us-
ing static analysis. Another approach is to ﬁrst carry out static
analysis to identify interesting code branches that can then be
instrumented for dynamic analysis to conﬁrm the ﬁndings.
3 Testing Environment and Analysis Pipeline
Our instrumentation and processing pipeline, depicted and
described in Figure 2, combines the advantages of both static
and dynamic analysis techniques to triage suspicious apps
and analyze their behaviours in depth. We used this testing
environment to ﬁnd evidence of covert- and side-channel
usage in 252,864 versions of 88,113 different Android apps,
all of them downloaded from the U.S. Google Play Store
using a purpose-built Google Play scraper. We executed each
app version individually on a physical mobile phone equipped
with a customized operating system and network monitor.
This testbed allows us to observe apps’ runtime behaviours
both at the OS and network levels. We can observe how apps
request and access sensitive resources and their data sharing
practices. We also have a comprehensive data analysis tool
to de-obfuscate collected network data to uncover potential
deceptive practices.
Figure 2: Overview of our analysis pipeline. Apps are auto-
matically run and the transmissions of sensitive data are com-
pared to what would be allowed. Those suspected of using a
side or covert channel are manually reverse engineered.
Before running each app, we gather the permission-
protected identiﬁers and data. We then execute each app while
collecting all of its network trafﬁc. We apply a suite of de-
codings to the trafﬁc ﬂows and search for the permission-
protected data in the decoded trafﬁc. We record all transmis-
sions and later ﬁlter for those containing permission-protected
data sent by apps not holding the requisite permissions. We
hypothesize that these are due to the use of side and covert
channels; that is, we are not looking for these channels, but
rather looking for evidence of their use (i.e., transmissions of
protected data). Then, we group the suspect transmissions by
the data type sent and the destination where it was sent, be-
cause we found that the same data-destination pair reﬂects the
same underlying side or covert channel. We take one example
per group and manually reverse engineer it to determine how
the app gained permission-protected information without the
corresponding permission.
Finally, we ﬁngerprint the apps and libraries found using
covert- and side-channels to identify the static presence of the
same code in other apps in our corpus. A ﬁngerprint is any
string constant, such as speciﬁc ﬁlename or error message,
that can be used to statically analyze our corpus to determine
if the same technique exists in other apps that did not get
triggered during our dynamic analysis phase.
USENIX Association
28th USENIX Security Symposium    607
reverse engineeringcov.chan.appcorpusPIIsentoutPIIaccesstoallowedcheatappsthatsidechan.set minus!!okalert3.1 App Collection
We wrote a Google Play Store scraper to download the most-
popular apps under each category. Because the popularity
distribution of apps is long tailed, our analysis of the 88,113
most-popular apps is likely to cover most of the apps that peo-
ple currently use. This includes 1,505 non-free apps we pur-
chased for another study [38]. We instrumented the scraper to
inspect the Google Play Store to obtain application executa-
bles (APK ﬁles) and their associated metadata (e.g., number
of installs, category, developer information, etc.).
As developers tend to update their Android software to add
new functionality or to patch bugs [64], these updates can also
be used to introduce new side and covert channels. Therefore,
it is important to examine different versions of the same app,
because they may exhibit different behaviours. In order to
do so, our scraper periodically checks if a new version of an
already downloaded app is available and downloads it. This
process allowed us to create a dataset consisting of 252,864
different versions of 88,113 Android apps.
3.2 Dynamic Analysis Environment
We implemented the dynamic testing environment described
in Figure 2, which consists of about a dozen Nexus 5X An-
droid phones running an instrumented version of the Android
Marshmallow platform.1 This purpose-built environment al-
lows us to comprehensively monitor the behaviour of each of
88,113 Android apps at the kernel, Android-framework, and
network trafﬁc levels. We execute each app automatically us-
ing the Android Automator Monkey [6] to achieve scale by
eliminating any human intervention. We store the resulting
OS-execution logs and network trafﬁc in a database for of-
ﬂine analysis, which we discuss in Section 3.3. The dynamic
analysis is done by extending a platform that we have used in
previous work [66].
Platform-Level Instrumentation We built an instru-
mented version of the Android 6.0.1 platform (Marshmallow).
The instrumentation monitored resource accesses and logged
when apps were installed and executed. We ran apps one at a
time and uninstalled them afterwards. Regardless of the obfus-
cation techniques apps use to disrupt static analysis, no app
can avoid our instrumentation, since it executes in the system
space of the Android framework. In a sense, our environment
is a honeypot allowing apps to execute as their true selves.
For the purposes of preparing our bug reports to Google for
responsible disclosure of our ﬁndings, we retested our ﬁnd-
ings on a stock Pixel 2 running Android Pie—the most-recent
version at the time—to demonstrate that they were still valid.
1While as of this writing Android Pie is the current release [35], Marsh-
mallow and older versions were used by a majority of users at the time that
we began data collection.
Kernel-Level Instrumentation We built and integrated a
custom Linux kernel into our testing environment to record
apps’ access to the ﬁle system. This module allowed us to
record every time an app opened a ﬁle for reading or writing
or unlinked a ﬁle. Because we instrumented the system calls
to open ﬁles, our instrumentation logged both regular ﬁles and
special ﬁles, such as device and interface ﬁles, and the proc/
ﬁlesystem, as a result of the “everything is a ﬁle” UNIX phi-
losophy. We also logged whenever an ioctl was issued to the
ﬁle system. Some of the side channels for bypassing permis-
sion checking in the Android platform may involve directly
accessing the kernel, and so kernel-level instrumentation pro-
vides clear evidence of these being used in practice.
We ignored the special device ﬁle /dev/ashmem (Android-
speciﬁc implementation of asynchronous shared memory for
inter-process communication) because it overwhelmed the
logs due to its frequent use. As Android assigns a separate
user (i.e., uid) to each app, we could accurately attribute the
access to such ﬁles to the responsible app.
Network-Level Monitoring We monitored all network
trafﬁc, including TLS-secured ﬂows, using a network moni-
toring tool developed for our previous research activities [63].
This network monitoring module leverages Android’s VPN
API to redirect all the device’s network trafﬁc through a lo-
calhost service that inspects all network trafﬁc, regardless of
the protocol used, through deep-packet inspection and in user-
space. It reconstructs the network streams and ascribes them
to the originating app by mapping the app owning the socket
to the UID as reported by the proc ﬁlesystem. Furthermore, it
also performs TLS interception by installing a root certiﬁcate
in the system trusted certiﬁcate store. This technique allows it
to decrypt TLS trafﬁc unless the app performs advanced tech-
niques, such as certiﬁcate pinning, which can be identiﬁed by
monitoring TLS records and proxy exceptions [61].
Automatic App Execution Since our analysis framework
is based on dynamic analysis, apps must be executed so that
our instrumentation can monitor their behaviours. In order to
scale to hundreds of thousands of apps tested, we cannot rely
on real user interaction with each app being tested. As such,
we use Android’s UI/Application Exerciser Monkey, a tool
provided by Android’s development SDK to automate and
parallelize the execution of apps by simulating user inputs
(i.e., taps, swipes, etc.).
The Monkey injects a pseudo-random stream of simulated
user input events into the app, i.e., it is a UI fuzzer. We use the
Monkey to interact with each version of each app for a period
of ten minutes, during which the aforementioned tools log the
app’s execution as a result of the random UI events generated
by the Monkey. Apps are rerun if the operation fails during
execution. Each version of each app is run once in this manner;
our system also reruns apps if there is unused capacity.
608    28th USENIX Security Symposium
USENIX Association
After running the app, the kernel, platform, and network
logs are collected. The app is then uninstalled along with any
other app that may have been installed through the process of
automatic exploration. We do this with a white list of allowed
apps; all other apps are uninstalled. The logs are then cleared
and the device is ready to be used for the next test.
3.3 Personal Information in Network Flows
Detecting whether an app has legitimately accessed a given re-
source is straightforward: we compare its runtime behaviour
with the permissions it had requested. Both users and re-
searchers assess apps’ privacy risks by examining their re-
quested permissions. This presents an incomplete picture,
however, because it only indicates what data an app might ac-
cess, and says nothing about with whom it may share it and
under what circumstances. The only way of answering these
questions is by inspecting the apps’ network trafﬁc. However,
identifying personal information inside network transmissions
requires signiﬁcant effort because apps and embedded third-
party SDKs often use different encodings and obfuscation
techniques to transmit data. Thus, it is a signiﬁcant technical
challenge to be able to de-obfuscate all network trafﬁc and
search it for personal information. This subsection discusses
how we tackle these challenges in detail.
Personal Information We deﬁne “personal information”
as any piece of data that could potentially identify a speciﬁc
individual and distinguish them from another. Online compa-
nies, such as mobile app developers and third-party advertis-
ing networks, want this type of information in order to track
users across devices, websites, and apps, as this allows them
to gather more insights about individual consumers and thus
generate more revenue via targeted advertisements. For this
reason, we are primarily interested in examining apps’ access
to the persistent identiﬁers that enable long-term tracking, as
well as their geolocation information.
We focus our study on detecting apps using covert and side
channels to access speciﬁc types of highly sensitive data, in-
cluding persistent identiﬁers and geolocation information. No-
tably, the unauthorized collection of geolocation information
in Android has been the subject of prior regulatory action [82].
Table 1 shows the different types of personal information that
we look for in network transmissions, what each can be used
for, the Android permission that protects it, and the subsec-
tion in this paper where we discuss ﬁndings that concern side
and covert channels for accessing that type of data.
Decoding Obfuscations
In our previous work [66], we
found instances of apps and third-party libraries (SDKs) us-
ing obfuscation techniques to transmit personal information
over the network with varying degrees of sophistication. To
identify and report such cases, we automated the decoding
of a standard suite of standard HTTP encodings to identify
personal information encoded in network ﬂows, such as gzip,
base64, and ASCII-encoded hexadecimal. Additionally, we
search for personal information directly, as well as the MD5,
SHA1, and SHA256 hashes of it.
After analyzing thousands of network traces, we still ﬁnd