is used to re-assign the check bits in proportion to the number
of errors in the line.
G. Need for a Practical Solution
Ideally we would like to have a solution that enables low
voltage operation of the processor chip without relying on
signiﬁcant storage or logic overhead and causing negligible
changes to existing structures. Changing cache structure, and
implementing complex circuitry not only requires area over-
head but also entails effort from design, veriﬁcation and testing
teams. We would like to minimize these overheads. Unfor-
tunately, all previous approaches, including VS-ECC, require
signiﬁcant changes to existing cache structure (to add extra
ECC bits), and complex ECC decoding circuitry. Furthermore,
because VS-ECC uses ECC-4 in the quarter of the cache during
testing time, its effectiveness is limited to Vmin obtained with
ECC-4 (540mv regime). We can obtain even lower Vmin and
avoid the hardware changes required by VS-ECC if we can
use existing cache circuitry for reliable operation during the
testing phase and simply disable faulty lines during the normal
phase. Based on this insight, we propose FLexible Replication
(FLexR) that performs dynamic two-way replication of lines
for robustness during testing phase. We will ﬁrst describe the
basic architecture of FLexR, before describing the enhanced
version our proposal in Section IV.
III. FLEXIBLE REPLICATION: DESIGN AND ANALYSIS
Similar to VS-ECC, our proposal relies on runtime testing
to identify faulty lines. However, unlike VS-ECC, it does not
need precise number of faults in the line and instead bins
the lines into three categories: no faults, exactly one fault,
and two-or-more faults. Testing is still performed in pipelined
fashion on a way-by-way basis. As testing takes a long time
(50 seconds or more [2]), it is desirable to have at-least some
portion of the cache usable during the testing phase. Unlike
VS-ECC, which relies on having ECC-4 for a quarter of
the cache, our design relies on alternative low-cost means to
provide robustness during the testing phase.
To MEMORY
To MEMORY
READ ADDR
LLC
WAYS
UNDER
TEST
WR ADDR
LLC
WAYS
UNDER
TEST
DATA  ERROR
DETECTED
WR DATA 
Fig. 3. Basic architecture to support Flexible Replication. The data-ﬂow is
shown only for the testing phase, for read (left) and for write(right).
A. Flexible Replication Architecture
One of the major design choice that we make to keep
FLexR simple and practical is to eliminate the presence of
dirty lines in the last level cache during the testing phase, as
shown in Figure 3. While this increases the trafﬁc to memory,
we rely on two factors to keep this overhead manageable. First,
even if the LLC is used as write-through, the L2 cache is still
architected to be a writeback cache. So, only the dirty lines
evicted out of the L2 cache will be written to memory and
not the unﬁltered stream emanating from the processor (we
found that with our write-through design, the memory trafﬁc
during testing mode increased by 2% compared to VS-ECC on
average, See Appendix A). Second, the extra memory trafﬁc
due to write through is incurred only during the testing phase
(which although is few tens of second, would be much smaller
than the up-time of the machine). After the testing phase, the
cache still operates as a write-back cache.
Making the cache write through in the testing phase has the
major advantage that it transforms the cache reliability problem
from an error-correction problem into a much more tractable
error-detection problem.
What we ideally want is a storage-efﬁcient on-demand error
detection, that does not incur any storage overhead compared
to SECDED. Unfortunately, SECDED codes can detect only
up-to two errors.2 For our target operating Vmin a line can
have up-to 8 errors, therefore if we want to provision each
line with an error detection code, that code will require to
ensure that the minimum hamming distance between valid
code words is 9, and will incur a hardware overhead similar to
ECC-4, which we are trying to avoid. Another alternative is to
consider checksum codes or cyclic redundancy codes (CRC).
However, these codes can detect multi-bit faults efﬁciently
only if the errors happen in spatially close positions. For,
multi-bit errors that can happen randomly, simple CRC codes
and checksum codes are not effective at provide guaranteed
detection. Furthermore, we want to avoid the storage and logic
overheads associated in designing another coding scheme, in
addition to the existing SECDED.
Thus, we need a way to enable part of the cache with
multi-bit error detection capability without the storage and
logic overheads associated with typical multi-bit error detec-
tion schemes. We leverage the insight that during the testing
phase, only part of the cache is operational anyways, so we
can used the non-operational part for storage-efﬁcient error
detection. We propose to replicate two lines in a Dual Modulo
Redundancy (DMR) fashion for error detection. While this
may seem to reduce the effective size to only half the cache
capacity, we note that prior VS-ECC proposal have enabled
only quarter of the cache capacity in order to provide cache
space during the testing phase. So, the effective cache capacity
with our design is higher than provided by VS-ECC.
B. Cache Structure with FLexR
Figure 4 shows one of the set of an 8-way set associative
cache with FLexR, where we have used DMR for error
detection. Ways 0 and 1 each store a copy of Line A; ways
2 and 3 each store a copy of Line B; and ways 4 and 5 each
store a copy of line C. Way 6 and 7 are not available as they
are undergoing testing. On a read access, the two lines in the
DMR pair are read, SECDED correction is performed on each
of the two lines. If SECDED detects a correctable failure, it
2In reality, SECDED codes can detect up-to three errors if we give up on
correction of lines with single bit failure. However, given that for our target
operating Vmin of 485mv we have about 30% of the lines with single bit
error. Therefore, the correction capability of SECDED is important even in the
testing phase, and hence we use per-line error correction storage as SECDED
instead of ZECTED (Zero Error Correction Triple Error Detection).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
performs correction and then supplies a corrected copy of the
line for the DMR comparison. Whereas, if SECDED detects an
error that is uncorrectable it simply supplies the original value
(as correction is likely to increase the number of bit errors).
DMR is performed on the two lines on a bit-by-bit basis. If
at-least one of the bits do not match, then an error is detected
and the two lines in the DMR pair are both invalidated, and the
corresponding data line is read from memory. When an error
is identiﬁed, FLexR marks both lines in the pair as disabled
(using a cache line disable bit) during testing mode so that
we can avoid future invalidation on these lines.3 The logic
overhead of DMR checking is 512 two-input ex-or gates and
256 2-input OR gates, this logic complexity is almost an order
of magnitude lower than required for SECDED, and the latency
for this DMR check is approximately 9 FO4 (at-most one
processor cycle).
Way  Number
SET
0
A1
S
1
A2
S
2
B1
S
3
B2
S
4
C1
S
5
C2
S
6
7
UNDER TEST
DMR
LINE A
S
=SECDED
Fig. 4. One set of an 8-way set-associative cache that facilitates FLexR. The
ﬁrst six ways provide 3 ways of DMR, the other two ways are reserved for
testing.
cause failure if each line in the pair has one failed bit and
the positions of the faulty bits overlap. The vulnerability of
DMR without SECDED can be computed as a product of
three components: First, probability of two errors in the pair
(prob=18%). Second, the probability that each line in pair
will get one error each (prob=0.5). Third, the two bits will
land in the same position of two lines (prob=1/512). Thus,
the vulnerability of DMR is approximately 2−12, which is
much higher than the TPF we seek (2−25.7). Furthermore, if
we want soft error tolerance, then DMR without SECDED
may cause fault even if the pair has one hard fault (if the soft
error happens in the other line in the pair at the same position).
Thus, DMR alone (without SECDED) falls quite short in terms
of robustness for our requirements.
D. Shortcoming of FLexR
FLexR uses SECDED correction before employing DMR.
While SECDED is effective in correcting one-bit errors, it does
not attempt to correct lines with two errors (as miscorrection
can increase the number of errors in the line, and the position
of the miscorrected bit would depend on data value). We
analyze the detection capability of FLexR under two settings:
with and without soft-error tolerance.
For DMR to cause failure the component lines must have at
least one failed bit after SECDED correction. Thus, for DMR
to fail, we need at-least two erroneous bits per line. The most
dominant failure case would then be when the pair has four
errors, each line gets two errors, and those the positions of the
errors overlap, as shown in Figure 5.
C. Pair Failure Rate at Target Vmin
Our baseline 8MB cache is 16-way, and contains 217 lines.
During testing mode we dedicate two ways for testing and use
the remaining 14 ways to implement DMR. Thus the total
number of pairs that must be supported during testing is 7
·
217. To guarantee that no more than 1 in a 1000 caches fail,
we would need to ensure that no more than one in every 1000 ·
· 217 = 225.7 pair can fail. Thus, we seek an effective target
failure probability of the pair to be 2−25.7. We will call this
critical value as Target Pair-Failure (TPF).
16
7
16
Table II shows the probability of number of errors in the
pair of two lines (64 bytes each) at an operating voltage of
485mv. For the purpose of analyzing the vulnerability of DMR,
we need to consider only up-to four errors in the pair, hence
we club ﬁve or more errors into a single bin. Analysis with a
larger number of errors will be performed in Section IV.
TABLE II.
EXPECTED NUMBER OF ERRORS IN THE PAIR AT 485MV (5+
DENOTES FIVE OR MORE ERRORS).
Num Errors in Pair
0
1
2
3
4
5+
35.9% 36.8% 18.8% 6.4% 1.6% 0.4%
Table II shows why DMR without SECDED correction
would not be very useful. DMR without SECDED would
3Note that such a disable with DMR is valid only before the pairs are tested.
After testing, we may chose to disable only one line in the pair.
X
= Hard Error
Line−0
Line−1
X
X
X
X
Fig. 5. Dominant mode of failure for a pair with FLexR, if we consider only
hard errors.
Thus, failure probability of FLexR can be computed as the
product of three components. First, the probability that the pair
has four errors (prob: 1.6%). Second, each line gets two errors
each (prob: 6/16). Third, the position of errors overlap in the
two lines (prob:
512·511 ). Thus, the vulnerability of a given
pair under these conditions is equal to 2−24.5, which is higher
than our TPF of 2−25.7. While this difference may seem small
(a difference of only about 2x), this analysis assumes that hard
errors are the only source of vulnerability and does not take
into account soft errors.
2
We want our solution to not compromise on soft error
tolerance at all compared to SECDED. Therefore, we have
to provision for the case that any bit in the line can get a
fault due to soft error. Given the low rate of soft-error we will
assume that there can be at-most one error in the pair. When
we include the vulnerability to soft-error in our analysis, the
dominant failure case for FLexR is when the pair has 3 errors,
there is a (1,2) split of errors between the two lines in the
pair, and the position of error in 1 error line overlaps with the
position of error of one of the two errors in the line with 2
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:43:00 UTC from IEEE Xplore.  Restrictions apply. 
errors. Then, if a soft-error strikes the line with 1 error, in a
position overlapping with the second error in the 2-error line,
FLexR will be unable to detect this error, as shown in Figure 6.
X
= Hard Error
S = Soft Error
Line−0
Line−1
X
X
X
S?
Fig. 6. Dominant mode of failure for a pair with FLexR, considering both
hard and soft error.
The vulnerability in this case can be calculated as the
product of three components. First, the pair has three failure
(prob: 5.9%). Second, one line gets two errors and the other
gets one error (prob: 6/8). Third, there are two errors in the
same bit position (prob: 2/512). Thus, the overall vulnerability
is approximately 2−14 which is almost an order of magnitude
higher than the TPF we seek 2−25.7.
In summary, employing simple DMR after SECDED, as
done with FLexR, is not sufﬁcient to provide 485mv operation
while tolerating soft errors. The next section describes a simple
and effective extension that can provide reliable operation at
485mv while maintaining soft-error resilience.
IV. FLEXIBLE AND INTROSPECTIVE REPLICATION
One of the common case of failure of FLexR happens
when both lines in the DMR pair have a detectable error.
To enhance the detection capability of FLexR, we observe
that FLexR does not utilize the correction status of SECDED.
We could obtain improved robustness in such a scenario by
noting that two lines in the pair had an uncorrectable error,
and simply indicating that the pair has an undetectable error,
rather than providing the incorrect data. Based on this insight,
we propose FLexible And Introspective Replication (FLAIR).
FLAIR performs Flexible Replication (DMR is employed only
in the testing phase and disabled during the normal mode)
and Introspective Replication (SECDED status of each line is
checked for decision making). Before we discuss the detection
algorithm of FLAIR, we will ﬁrst provide the basic working
of SECDED code as the number of errors in the line is varied
(Figure 7). This understanding is the key in developing the
effective detection algorithm of FLAIR.
A. A Primer on SECDED Code
We will limit our discussion to SECDED implementations
based on Hamming code. Hamming codes can perform error
correction by adding a few extra bits (called check bits) to
the data word, and this combination of data-word and check-
bits is called a codeword. The check bits are determined as a
parity over a subset of data-bits and the parity bits. The key
to hamming code is to have the parity bits overlap, such that
they manage to check each other as well as the data.
In order to correct a single erroneous bit, we need that
the valid code words are at least a hamming distance of three
away from each other. In that case, if one error occurs, then the
regeneration of parity bits (called syndrome) will indicate the
position of the bit that has failed. A zero syndrome indicates
that there is no error detected (bit positions are numbered from
1 onward). For implementing such a Single Error Correcting
(SEC) code for data-word consisting of N bits, we need 1 +
log2(N ) check-bits. Thus, implementing SEC for a line with
512 bits requires 10 check bits.
SECDED
SEC CODE
GLOBAL
PARITY
DATA BITS
CHECK−BITS
GP
SYNDROME
MATCH
Fig. 8. Typical structure of SECDED, consisting of SEC and global parity.
SYNDROME indicates error-position and MATCH indicates global-parity
agreement.
As SEC has a minimum distance of 3, it can either only
correct 1 bit error or detect 2 bit error but not both. To extend
SEC to have guaranteed double error detection, we add a
global parity bit GP which tracks the parity over both the
data-word and check-bits, as shown in Figure 8. If there are
two errors in the (data-word+check-bits) the SEC will provide
a non-zero syndrome (possibly causing error in an error free
bit). However, if there are 2 errors then the GP bit will result
in a parity match, indicating either zero or even number of
errors. Given non-zero syndrome for SEC we know that the
number of errors is the codeword is non-zero, and we can ﬂag
a detectable-but-uncorrectable error with SECDED.
For SECDED, the codewords are at least a distance of 4
from each other. However, this does not mean that the valid
code word are placed exactly at a distance of 4, they may be
placed at any distance greater than or equal to 4. For our work,
we analyze what happens to SECDED at a distance larger than
4, as shown in Figure 7.
The operation of SECDED can be generalized to any
number of errors. If there is a GP match, and SEC indicates
zero syndrome, then SECDED estimates such a line to have no
error. If GP indicates mismatch, and SEC indicates non-zero
syndrome then SECDED estimates that this is a correctable
error. If the parity and syndrome do not agree (one indicates no
error, and the other indicates error) then SECDED can denote
such lines as detectable-but-uncorrectable error lines.4
B. Classifying Lines Based on SECDED Status
SECDED is based on two outcomes: one from SEC and
second from GP. Based on the result of these two outcomes, the
lines can be classiﬁed into one of three types after SECDED
correction:
1) Good Line (G Line): Indicates a line for which
SECDED estimates no error. It will not modify
the contents of the line. This estimation if correct
4When GP indicates mismatch but SEC provides non-zero syndrome, this
can happen if there is a single bit error only in the GP bit. During the testing