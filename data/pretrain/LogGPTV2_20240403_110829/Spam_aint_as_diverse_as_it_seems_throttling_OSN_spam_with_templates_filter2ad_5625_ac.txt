plate generation algorithm. Intuitively, spams from diﬀerent
campaigns will result in non-compact templates, a fact we
utilize to identify which spam should be removed from a
given cluster. Speciﬁcally, during template generation, we
repeatedly remove the row with the largest number of ε, be-
cause it likely results from a clustering error. A column will
be removed if all its non-ε cells are removed. We repeat this
process until the matrix contains suﬃciently low number of
ε.
3.4 Noise Labeling
Spam tweets often mention other users, popular terms
and hashtags that are unrelated to the semantics of the
rest of the tweet. Earlier research has conﬁrmed this phe-
nomenon [8]. Such content helps to expose spam to a larger
audience, because users may search or browse tweets by
topic.
It also diversiﬁes spam and increases the diﬃculty
to detect spam. We refer to this type of content as noise.
Popular forms of noise include celebrity names, TV shows,
trending hashtags and many others. We next elaborate how
noise aﬀects template generation and design a model to au-
tomatically label noise given a small amount of easily, man-
ually labeled noise as trained data. Once trained well, the
model can accurately label noise tokens in real-time stream
of spam tweets during Tangram execution.
Noise creates extra diﬃculties for template generation. If
the generated template contains a segment of noise, the tem-
plate will be too “speciﬁc”, in the sense that it cannot match
the spam with a diﬀerent sequence of noise terms. In addi-
tion, spam instantiating diﬀerent templates may coinciden-
tally share an identical sequence of noise terms. It increases
the chance to mislead the template generation module so
that it attempts to extract a single template for them. Thus,
we ﬁrst perform a pre-processing step to identify noise to-
kens in the tweet, and then eﬀectively ignore them when
generating the template (i.e., we replace them with .*, a
wildcard that matches anything).
We treat noise detection as a sequence labeling task, in
which the goal is to automatically label each token in the
tweet as noise or non-noise. We employ a standard sequence-
labeling approach, Conditional Random Fields (CRFs) [14].
The CRF is a model, learned from training data, that infers
a label for each token in a given tweet. The model exploits
regularities in the features of noise and non-noise tokens
(detailed below), as well as regularities in label sequences.
The CRF requires identifying a set of features for each
token that are relevant to the task. In our case, we found a
set of features that appear to be highly indicative of noise.
The key observation is that noise terms are popular, yet un-
related to each other and to other elements of the tweet.
As a result, we would expect regions of noise to contain
individual tokens that are common on Twitter, but tran-
sitions between tokens that are relatively uncommon. We
capture these intuitions with three numeric features. Let
f req(s) represent the frequency of a string s, which we
measure of a large set of unlabeled tweets. For each to-
ken ti in a tweet, we create the following three features in
the CRF: f req(ti), f req(titi+1)2/(f req(ti)f req(ti+1)), and
f req(ti−1ti)2/(f req(ti−1) f req(ti)). The ﬁrst feature cap-
tures the popularity of the token ti, whereas the second and
third estimate how likely ti is to occur given the surround-
ing tokens. We processed these features into ﬁve discrete
quantiles for incorporation into the CRF.
We further add four orthographic features to capture com-
mon elements of noise terms. They indicate whether ti is
capitalized, is numeric, is a hashtag, or is a user mention
(i.e. using @).
To train our CRF, we hand-labeled 1,000 tweets as train-
ing data, manually identifying each token as noise or non-
noise. We then employed this learned model on each tweet
before template generation.
In a separate experiment on
the labeled tweets, we found that our trained CRF correctly
labeled an average of 92% of test-set tokens as noise or non-
noise.
Detection based on noise labeling. Besides pre-processing
tweets to facilitate template generation, noise labeling can
also directly detect spam from another angle.
Intuitively,
we expect legitimate messages to have very few semanti-
cally unrelated noise terms, whereas spam contains much
larger number of noise terms. We design a straightforward
idea to use the percentage of noise terms in the message to
distinguish spam. Our system classiﬁes a tweet as spam if
its percentage of noise terms is larger than a threshold t. In
the experiments we set t to be 75%. This threshold is rela-
tively high and conservative, because we want to minimize
the false alarm on legitimate tweets.
4. EXPERIMENTS
We evaluate Tangram using the labeled dataset in Sec-
tion 2.1 as ground truth. The two major metrics that we
use to evaluate the system are accuracy and speed. We
conduct a strict accuracy evaluation. We only count spam
caught by template matching or noise detection as true pos-
itives. We count spam missed by these two but caught by
the auxiliary spam ﬁlter as false negatives. In this way, we
are only evaluating the detection accuracy of the modules
proposed in this paper, not the accuracy of the auxiliary
spam ﬁlter. For speed, we evaluate the template generation
and matching latency. We feed the system with the collected
tweets obeying their timestamp order to reﬂect the perfor-
mance in real-world scenario. We conduct all experiments
on a server with an eight-core Xeon E5520 2.2GHz CPU and
16GB memory.
Tangram needs an auxiliary spam ﬁltering module to pro-
vide the initial set of spam messages to construct the under-
lying template. We leverage an existing online OSN spam
ﬁltering tool [6] for this task to conduct a realistic evalua-
tion. We reuse the same parameters reported in the paper.
The auxiliary spam ﬁlter is not an oracle. It may mistakenly
report legitimate messages as spam, or miss to report spam
messages.
4.1 Detection Accuracy
We test Tangram with spam window size t = 1000, which
means when the number of spam messages that slip through
the template matching module but are blocked by the auxil-
iary spam ﬁlter reaches 1000, the system will invoke the tem-
plate generation module to infer the underlying templates of
the messages. The value of parameter k is 4.
The results show that the TP rate for the most prevalent
template-based spam achieves 95.7%. The system can also
detect some spam messages that are not template-based, be-
cause the system treats all messages as if they were template-
based, and makes best-eﬀort detection. As expected, the TP
rate of such messages is lower than the TP rate of template-
based messages. The overall TP and FP rate are 76.2% and
0.12%, respectively.
True Positive Analysis. Table 5 reports a detailed
breakdown of true positive rate into diﬀerent spam cate-
gories. Tangram has two detection modules. Both modules
perform well on the speciﬁc spam category that they are de-
signed for. The template generation/matching module can
detect template-based spam with 95.7% TP rate. The noise
detection module can detect no-content spam with 73.8%
TP rate. Unfortunately, the true positive rate of the other
two spam categories is lower. About 80% of the false nega-
tives (spam misclassiﬁed as legitimate) belong to the other
two categories.
False Positive Analysis. Since the labeling approach
we use to build the ground truth may miss to label true
spam tweets (Section 2.1), We further compare the true
positives against the detected tweets that are not labeled.
We observe that spammers frequently attach Retweet marks
(RT @username) and Mentions (@username) at the be-
ginning of tweets, as well as noise words after the embedded
URL. Hence, we remove all the noise and acquire the stem
of spam tweets. Any tweet that shares the same stem with
spam tweets is also regarded as spam. The comparison re-
veals that 15,271 (0.12%) tweets reported by Tangram are
neither labeled as spam, nor sharing the same stem with
spam tweets. They represent the false positives that our
system incurs. The comparison approach exploits charac-
teristics that may only apply to our speciﬁc dataset. Hence,
we only use it as a post-processing step in the evaluation,
rather than adopting it in the system design.
Among the false positive tweets, 42.0% of them are caused
by overly general spam templates. Another 21.7% of them
are popular tweets like birthday wishes for Nelson Mandela.
These popular tweets are mistakenly reported as spam by
System
Spam Category
Template-based
Paraphrase
No-content
Other
Overall TP
FP
Template Based
Tangram Judo
Syntactical Tangram +
Clustering
Syntactical
95.7%
51.0%
73.8%
18.4%
76.2%
0.12%
32.3%
52.2%
41.9%
30.4%
35.9%
5.0%
70.1%
51.4%
67.0%
43.2%
63.3%
0.27%
98.4%
70.1%
83.1%
44.7%
85.4%
0.33%
Table 5: The detection accuracy of Tangram and two
existing systems compared in Section 4.2. The last
column shows the accuracy if we combine Tangram
and the syntactical approach.
)
s
m
(
y
c
n
e
t
a
L
 80
 70
 60
 50
 40
 30
 20
 10
 0
 0
 200
 400
 600
 800  1000  1200
Template #
the auxiliary ﬁlter, so templates are generated to match
them.
4.2 Detection Accuracy Comparison with Ex-
isting Work
We limit the direct experimental comparison to only the
approaches that examine the message content to detect spam.
Syntactical clustering + machine learning. We ﬁrst
compare with a recent spam detection work that adopts syn-
tactical message clustering and supervised machine learn-
ing [6] (denoted as the syntactical clustering approach here-
after) in detail. The two systems share similar design goals.
In addition, the existing approach is used as the auxiliary
spam ﬁlter in our experiment. Hence, it is crucial to quantify
the detection accuracy gains over directly using the existing
system. We run the system using the same dataset on which
we test Tangram.
The syntactical clustering approach achieves an overall
detection accuracy of 63.3% TP rate and 0.27% FP rate.
The true positive rate obtained by the syntactical clustering
approach on our data is lower than the reported number
in [6]. The reason is that our spam labeling approach labels
more spam tweets as ground truth, which the syntactical
clustering approach does not detect. In contrast, Tangram
achieves a substantial improvement on both the TP rate
(to 76.2%) and the FP rate (to 0.12%). Table 5 lists the
detailed accuracy comparison. The diﬀerence between the
spam detected by these two systems indicates that they can
potentially complement each other. Both systems work in a
similar way and it is straightforward to integrate them. For
example, a message can be labeled as spam if either system
blocks it. This simple integration suﬀers from the increased
FP rate of 0.33%, but can boost the TP rate to 85.4%.
Judo. To validate that our template generation technique
is more tailored to OSN spam detection, we also compare
our work with a recent email spam detection system called
Judo [22]. Judo detects email spam based on template gen-
eration. We have already presented the diﬀerence between
the two systems analytically by elaborating the diﬀerence
in the critical system assumptions, i.e., invariant substring
in template and quality of training samples. We further
demonstrate their diﬀerence in experimental results, shown
in Table 5, column “Judo”. Diﬀerent from our system, Judo
requires training set that contains pure spam generated by
the same underlying template. As a result, in real-world
deployment the system relies on the assumption that only a
small number of templates are actively used at a given time,
so that the training set is pure at least within a given small
time window. We implement the template generation mech-
Figure 2: The box plot of template matching latency
as a function of the number of generated templates.
anism of Judo as described in [22], and test the detection
accuracy using the same dataset. Even with small window
size (10 spam messages), the generated templates can only
achieve 35.9% TP rate. The TP rate further drops to 10.6%
if the window size is increased to 20. On the other hand, the
FP rate is high (5.0%). It shows that real-world OSN trace
breaks the crucial assumptions of Judo. As a result, Judo
achieves extremely high accuracy in email spam detection,
but does not perform well for OSN spam detection. In com-
parison, our system achieves much higher accuracy on the
same corpus.
4.3 Template Generation/Matching Speed
Template matching. The template matching latency
incurred by Tangram is minimal and is not noticeable to
users. Figure 2 plots the minimum, 25% quantile, 75% quan-
tile and maximum of the template matching time as a func-
tion of the number of generated templates during our online
experiment. We observe a large variance of template match-
ing latency, because the time consumed for regular expres-
sion matching highly depends on the text being matched.
Nevertheless, the largest latency in the entire dataset is less
than 80ms. The overall trend is that the template matching
latency, shown by the boxes representing the 25% quantile
and the 75% quantile, grows slowly with the number of tem-
plates. Even with more than one thousand templates, the
median template matching latency is only 8ms.
Template generation.
It is crucial to throttle spam
campaigns at their early stage. Hence, we measure how
fast templates can be generated. The time to generate tem-
plate depends on the number of buﬀered spam messages. In
our experiment, the mean template generation time is only
2.3 seconds. Although the time needed for template gen-
eration is larger than the time for template matching, the
template generation time is not the bottleneck of Tangram,
since template generation is performed in parallel with tem-
plate matching.
4.4 Sensitivity for New Campaigns
We take the ﬁve largest campaigns, one of which matches
the template instantiated by spam in Table 1, and evalu-
ate how fast Tangram reacts to newly emerged spam. We
randomly select a small percentage of messages from each
campaign, and use them as training samples to generate the
template. We vary the percentage of training samples from
0.05% to 0.5%. The remaining messages serve as the testing
set. We measure the true positive rate as the percentage
)
%
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
Campaign No. 1
Campaign No. 2
Campaign No. 3
Campaign No. 4