1、解析规则内的各解析项之间遵循自上而下的顺序，前后正则要求互斥；
2、如果配置了多个 raw_message 的正则解析，一个解析成功，其他的就不会再解析；
一条解析项，对应一种解析方法，解析方法又称算子。
内置规则
日志易可以自动解析 Apache，Nginx，JSON 等类型的日志，对于不能被自动识别的日志，
我们会对其全文索引，但是这将无法让您充分使用日志易的字段搜索功能。在本节中我们将
介绍日志易支持的日志类型。
日志易目前支持自动解析以下日志格式:
•Apache •Nginx•Log4j•JSON•MySQL
其中，Nginx日志和Apache日志格式相同，nginx日志的logtype会被自动匹配为apache，
Log4j日志的logtype会被自动匹配为java。
由于自动解析功能需要遍历规则进行尝试，在某些情况下，正则表达式的低效影响会被放大，
严重影响字段提取模型的运行效率。日志易允许您在这种情况下，主动关闭自动解析功能，
提高效率。
在日志易 Manager 中修改 logriver 配置项 switch_enable_builtin_rules 为 false 即可。
解析原则
初级产品学习过程中，我们已经知道日志解析有以下几个要点，这些要点在日志易日志解析
流程中长期适用：
1、日志提取规则不必提取全部的日志字段：解析的字段较多时，会对系统性能造成影响，
不常使用的字段，只要使用时再做提取即可。
2、规则（logtype）与appname、tag的关系建议为1对多：日志入库时，会使用日志的
appname、tags和配置的appname、tag匹配；匹配到多个规则，只用第一条规则；没
找到对应规则，用内置的规则(json,apache,mysql等)。
3、appname和tag的匹配原则不同：日志的appname需要与logtype所指定的appname
完全匹配；日志的tag有多个，只要有一个能匹配到配置的tag就能匹配；appname和
tag同时匹配才执行对应的规则。
2-66
日志学院
4、时间戳为日志必须要提取的字段：日志从日志源产生日志到入库日志易系统一共有4个
时间戳：日志内容时间、日志解析时间、日志发送时间、日志接收时间。不做时间戳解
析，会使用“日志发送时间”作为日志的timestamp。
5、相同appname、tag的解析规则，先建立的生效，后建立的不匹配。
2.2. 常用解析算子
对于日志易预置规则不支持的日志格式，用户可以在产品页面的“设置”标签下的“字段提取”
标签里配置客户领域内特定的日志格式解析规则，提取特定字段。
常用解析方法有：
 正则解析：日志输出的格式较为标准时使用，如果一种日志中有多种格式的日志需要解
析，则需要多条正则；
 Json：json格式的日志解析；
 KeyValue：键值对字符串的解析；
 KeyValue正则：复杂格式的键值对解析，如“policyActType(1071)=denied”，丢弃其中
的1071，解析出字段名为policyActType，字段值为denied；
 CSV解析：针对csv格式的字符串进行解析；
 自定义字典：通过csv方式，自定义字段扩展；
 XML解析：XML格式的解析
除此之外，常用的解析规则还有以下几类：
字段转换类：
 时间戳识别：识别时间戳，并转换为标准格式；
 数值型字段转换：将数值字段由字符串格式转化为数值格式，目前有数值格式可转化为
整型、浮点型；
字段处理类：
 格式化处理：字段合并；
 删除字段：当日志字段过多，或字段已被合并，先前的字段不再使用时，可以删除无用
字段；
 内容替换：常用于删除字段中的某一字符，如去除字段中的 /、“、”、{、} 等符号；或
将日志字段的tag由1个替换为多个；
 脱敏：如为保护用户隐私，将手机号18437980688处理成184****0688的格式；
 字段重命名：字段名修改；
 结构化解析：当编码不同导致字符长度、数据类型不一致时，仅保留需要的规定长度的
字符串。
 重定向解析：如果一条解析规则中的解析项过多，可以将一些解析项拆分出来，使用重
定向规则进行引用拆分出的另一规则。
固定格式解析
 UserAgent解析：用户浏览器识别（用户访问日志中）；
 URL解码：URL中的query解析；
2-67
日志学院
 Syslog_pri解析：对Syslog日志开头的PRI进行解析；
 IP格式转换：将整数型IP地址转换为标准的217.171.89.66格式的IP地址；
 手机号码解析：解析出城市、运营商等信息；
 固定电话解析：解析固定电话归属地；
 Hex转换：16进制数据转换；
 Geo：IP地址的地址位置解析，常用于绘制访客的地域分布。
正则解析
正则是处理文本解析的有力工具。
初级培训中，我们已经知道，像下面这样的日志：
2014-05-1423:24:4715752[Note]InnoDB:128rollbacksegment(s)areactive
我们希望提取出以下字段：timestamp，pid，loglevel和message，可以配置如下的表达式：
(?\S+\S+)(?\S+)\[(?\S+\](?.*)
其中\S表示匹配非空格字符，\S+表示匹配连续的非空格字符，(?value) 表示提取名字
为key的字段， 其值为value，使用这样的规则，会解析出如下字段：
1.timestamp:2014-05-1423:24:47
2.pid:15752
3.loglevel:Note
4.message:InnoDB:128rollbacksegment(s)areactive
上面是我们使用正则中的后向引用所写的匹配规则，除了手写正则匹配外，日志易正则解析
还提供一些比较好用的小功能以提升正则解析的效率，这些功能包括：
1、正则库引用：日志易提供了一些常用的正则表达式，可以通过 %{XXX} 的方式来引用，
省去了书写常用的固定格式的正则的重复工作；
2、鼠标划选辅助：可使用鼠标划选自动生成正则表达式；
3、多行模式与注释功能：多行模式下，可自动忽略大小写，或在复杂的正则中添加注释以
提升维护可读性。
正则库引用
除了正常的正则表达式，日志易还提供了一些常用的正则表达式，可以通过 %{XXX} 的方式
来引用。
除了正常的正则表达式，日志易还提供了一些常用的正则表达式，可以通过 %{XXX} 的方式
来引用。比如可以使用 %{NOTSPACE} 来代替 \S+，这样上面的正则表达式又可以写为：
(?%{NOTSPACE}%{NOTSPACE})%{NOTSPACE:pid}
\[%{NOTSPACE:loglevel}\]%{GREEDYDATA:message}
2-68
日志学院
默认的字段值是string类型的，如果您想将其转换为number类型，可以在引用中加入type
类型，目前仅支持int和float类型，例如:
%{XXX:int}
或者
%{XXX:float}
常用的正则表达式
1. 基本：
%{NUMBER} (?:%{BASE10NUM})
%{POSINT} \b(?:[1-9][0-9]*)\b
%{NONNEGINT} \b(?:[0-9]+)\b
%{WORD} \b\w+\b
%{NOTSPACE} \S+
%{SPACE} \s*
%{MORESPACE} \s+
%{DATA} .*?
%{GREEDYDATA} .*
%{IP} 略
%{PORT} 略
2.Apache/Nginx：
%{ApcClientIP}
%{ApcIdent}
%{ApcUser}
%{ApcTimestamp}
%{ApcStatus}
%{ApcRespLen}
%{ApcReferer}
%{ApcUa}
%{ApcXForward}
%{ApcRequest}
例如原始日志:
192.168.1.139--[24/Jan/2015:17:03:49+0800]"GET
/api/v0/search/fields/?field=tag&filters=&order=desc&page=1&query=*&size=50&sourcegro
up=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&
type=fieldsHTTP/1.1"200363
"http://alltest.rizhiyi.com/search/?query=*&time_range=-2d%2Cnow&order=desc&size=20&p
age=1&sourcegroup=all&type=timeline&_t=1422088066859&title=%E9%BB%98%E8%AE%A4&in
dex=0""Mozilla/5.0(Macintosh;IntelMacOSX10.10;rv:35.0)Gecko/20100101Firefox/35.0"
可以采用如下配置：
%{ApcClientIP}%{ApcIdent}%{ApcUser}%{ApcTimestamp}%{ApcRequest} %{ApcStatus}%{ApcRe
spLen}%{ApcReferer}%{ApcUa}
抽取出如下字段：
2-69
日志学院
注意：
 正则库使用的是完全匹配模式，即正则表达式需要消耗掉整条日志才可以匹配；
 %{IP:ip}:%{PORT:port} 不会匹配 2014-10-20192.168.1.1:8080 和 192.168.1.1:8080
2014-NOTE10-20，只会匹配 192.168.1.1:8080；
 一个正则表达式中分组命名的字段不能重复，如果命名的字段有 @、 . 或空格，它们
都会被替换成下划线“_”，因此不要使用这些符号。
鼠标划选辅助
为帮助用户实现正则解析，日志易提供鼠标划选自动生成正则表达式功能。点击划选辅助即
可使用。
用鼠标划选字段，然后填写对应的字段名，字段命名成功后即高亮显示。重新点击高亮部分
取消划选。
2-70
日志学院
需要注意的是，划选辅助功能并非十分精确，如果一条样例生成的正则不太对，可以点击添
加多个日志样例，使生成的正则表达式更精准。
多行模式与注释功能
日志易支持多种通用的正则运行模式。常见的有(?i)忽略大小写和(?x)多行模式。在多行模式
下，您可以使用#添加注释说明，在正则表达式比较复杂的时候，有助于维护可读性。
比如如下一行原文：
/dev/vda1 485M 32M 428M 7%/boot
您可以在正则解析中填入如下正则:
(?xmi)^(
(?\S+)#第一段是磁盘号
\s+#空格或制表符分隔
(?\S+)#总大小
\s+#空格或制表符分隔
(?\S+)#已用大小
\s+#空格或制表符分隔
(?\w+)#可用大小
\s+#空格或制表符分隔
(?\S+)#已用百分比
\s+#空格或制表符分隔
(?\S+)#目录
\s
)$
注意：多行模式下空格和#注释符有特殊含义，正则表达式中的这两种符号会自动忽略。如
果表达式中确实需要使用空格和#号，请预先转义。
2-71
日志学院
JSON 解析
同上节一样，JSON解析算子对多层嵌套数组也支持jsonpath的语法，在层级较多且复杂的
情况下，通过该语法轻松获取其中特定的字段值。 JSON解析主要用于解析JSON格式的日
志, 例如原始日志为:
{"Name":"JohnSmith","Age":23,"Employed":true,"Address":
{"Street":"324Chrome St","City":"Portland,NewYork,LosAngeles",
"Country":"UnitedStates"}}
JSON解析后如下图所示：
同xml解析规则一样，json解析长度同样受限制：在这个长度范围之内的字段正常抽取, 超
过这个长度的字段忽略。
 参考"高级配置功能"里的json解析，对应配置项extract_limit,0代表不限制。范围内正
常解析，超出范围的不解析。
 配置里没有extract_limit, 使用logriver的默认配置：log_parser.json_parse_extract_limit
json解析长度限制，默认5000，0代表不限制。
需要注意：json解析使用jsonpath不受长度限制影响。
KeyValue 分解
KV分解算子主要用来解析明显的KV字符串，例如上面的例子中正则表达式解析后，
request_query字段为：
field=tag&filters=&order=desc&page=1&query=*&size=50&sourcegroup=all&sourcegroupC
n=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
这是一个按照"&"和"="来分割的KV字段。添加解析规则：KeyValue分解，source字段选 择
request_query，定义字段分隔符为&，定义k-v分隔符为=，点击解析，如图可看到解析结
果：
2-72
日志学院
注意：
如果可能有很多个key，推荐 您通过填写key名称做保留或者取舍，也可以填写丢弃前缀
名简化日志内容。
KeyValue 正则匹配
某些日志中KV字段可能比较复杂，用户往往希望查看解析后简单明了的字段格式，并丢弃
某些无关紧要的字段，您可以使用KeyValue正则匹配算子，来提取字段，例如一条日志为：
May1811:20:102016
HLJ_S12508_1_FW %%10FILTER/6/ZONE_DP_FLT_EXECUTION_TCP_LOG(l):
-DEV_TYPE=SECPATH -PN=210231A0H6010C000002;
srcZoneName(1034)=serveruntrust;destZoneName(1035)=servertrust;rule_ID(1
070)=90;policyActType(1071)=denied;protType(1001)=TCP(6);srcIPAddr(1017)
=10.167.77.99;destIPAddr(1019)=10.166.5.70;srcPortNum(1018)=49362;destPo
rtNum(1020)=1521;beginTime_e(1013)=05182016112009;endTime_e(1014)=051820
16112009;