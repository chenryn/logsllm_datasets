eration. (a) Transcript success rate (TSR) and (b) Character
success rate (CSR) in different attack distances. Our ﬁnal
design further extends the effective attacking distance to 6 m.
2) Enhancing Adversarial Examples: As the perturbation
δ obtained from the initial adversarial example generation
inevitably contain some device- and environment-speciﬁc fea-
tures from the M channel measurements (to minimize the
optimization loss), its performance will be limited at new
locations, especially when the attacking distance is long and
the multi-path’s impact becomes stronger. To alleviate this
issue, we plan to clean the initial δ by excluding its embraced
measurement-speciﬁc features. After this operation, a more
generic and robust perturbation δ can be obtained, which can
improve the attacking distance and accuracy at new locations.
Inspired by the huge success in domain adaptation tech-
niques [22] for object detection [39], semantic segmenta-
tion [61] and person re-identiﬁcation [24], we introduce a
domain discriminator as depicted in Figure 9 to clean the
initial δ . The term “domain” here refers to the acoustic signal
transmissions using different devices and settings (distances
and environments). The goal of the discriminator alone is to
distinguish different domains in the M prior measures. How-
ever, with a proper loss function design (below), the device-
and environment-speciﬁc features can be further removed.
Domain discriminator. To design the domain discriminator,
we classify the M measurements into 21 different environ-
ments, according to different transmission distances (with the
one-meter step size), different rooms used in these measure-
ments and different devices (different datasets use different
devices). The discriminator then takes the MFCC feature
vector F as input in Figure 9 to recognize these domains.
In particular, the MFCC feature vector F is ﬁrst processed
by two fully-connected layers of the discriminator to extract
the measurement-dependent features. Since the audio ﬁle is
a temporal sequence,
the extracted features will be then
processed by a RNN module, e.g., Long Short-Term Memory
(LSTM). To further ensure the recognition of both the initial
adversarial example generator and the domain discriminator,
as suggested by [29], [60],
the feature vector (before the
loss calculation in the generator) can be integrated into the
discriminator. Therefore, we apply this integration after the
LSTM in Figure 9. After the integration, we insert one more
fully-connected layer to extract their overall feature before a
soft-max for the domain recognition.
Loss function. We denote the loss function of the discriminator
as Ld. With the discriminator, our goal can be achieved by
minimizing the following integrated loss:
Lloss = Lctc − β · Ld,
(6)
where β is the weighting factor for Ld, which is conﬁgured in
§IV-A. The goal of the discriminator itself aims to minimize
Ld. But as Lctc and Ld are connected by minus, by minimizing
Lloss, we essentially
• 1) minimize the loss of the adversarial example generator,
• 2) try the best to “cheat” the discriminator to maximize
its loss Ld and make it tend to distinguish the domains
incorrectly, so that the measurement speciﬁc features can
be gradually removed from the MFCC feature vector, by
adjusting the perturbation δ .
i.e., the adversarial example is still functionable.
Improving loss to alleviate over-ﬁtting. With the integrated
loss function deﬁned in Eqn. (6), we ﬁnd that the loss function
can be further improved with the following observation.
For those primary adversarial examples that are failed
to be recognized as the targeted transcript T(cid:48) in Figure 10,
we compare all the intermediate results inside DeepSpeech
when we convert I + δ and H(I + δ ) to their corresponding
transcripts before and after the transmission, respectively. We
observe that for many characters c j that did not survive after
the transmission, the likelihood (calculated by SR) to recognize
their corresponding CTC tokens (i.e., English letters, space
or the special token ε stated in §II-B) is high before the
transmission, e.g., 0.9, but this likelihood becomes very small
at the receiver side after the transmission, e.g., reduced to
0.1, so that another (incorrect) character token with a higher
likelihood is selected in the recognized transcript.
This phenomenon suggests that the primary adversarial ex-
amples are not reliable enough, and the signiﬁcant conﬁdence
reduction is likely an occurrence of over-ﬁtting in δ for these
inaccurately recognized characters. To address this issue, we
can further improve the loss function in Eqn. (6), by adding a
term Lo f to alleviate the over-ﬁtting [29]. The key idea is to
introduce certain (N) “noises”, so that before and after adding
these noises, the recognized CTC token sequences, denoted as
s and sn respectively, should be similar (otherwise it is likely
an over-ﬁtting). Its similarity can be measured by
n=1 JSD(si||sn
i ),
(7)
where JSD(·) is the Jensen-Shannon divergence [29]. Putting
them all together, the improved integrated loss function is
Lo f =
1
MN ∑M
i=1∑N
Lloss = Lctc + γ · Lo f − β · Ld,
(8)
based on which robust adversarial examples can be generated.
As shown in §IV, transcript success rate after enhancement
can be .95 when the attack distance is even up to 6 m.
C. Improving Audio Quality
With the practical audio adversarial example generated in
§III-B that can survive from the over-the-air transmission, in
this subsection, we further consider its audio quality. In partic-
ular, we propose two mechanisms to minimize the perception
of the added perturbation δ by human’s ear. First, we propose
to customize the perturbation shape, so that it sounds more
similar as some real-world sound, e.g., bird’s chirp. We name
it as a “acoustic grafﬁti”. With this design, the audience may
believe that the added perturbation is a part of the original
7
audio clip (§III-C1). Second, we ﬁnd that we only need to
train δ for covering a part of the original audio clip I (in the
time domain), which could further reduce the percentage of
contents in I to be modiﬁed by δ (§III-C2).
1) Acoustic Grafﬁti: To alleviate the perception of the
target command information (which might be leaked by the
added perturbation δ ), we propose to customize (or reshape)
the added perturbation, so that it sounds similar as some real-
world background noise. In particular, the attacker can visit the
nearby environment of the victim receiver, identify the noises
that could appear in this environment, and then record them. If
the on-site visit is not possible, the attacker can instead select
any other audio template that would not raise the victim’s
concern, such as the soft music, the source audio itself, general
ambient sounds (trafﬁc sound for example), etc.
For one selected acoustic grafﬁti template, the attacker
ﬁrst normalizes the amplitude of both the perturbation δ and
the template audio (scaling them to the same unit) and then
computes the loss introduced by the shape difference between
the perturbation and the template audio ˆN. The optimization
loss will be updated as follows:
Lloss = (Lctc + γ · Lo f − β · Ld) + η · dist(δ , ˆN),
(9)
where dist(·) measures the MFCC difference between δ and
ˆN. With this updated loss, δ is customized to be similar as the
acoustic grafﬁti template.
2) Reducing Perturbation’s Coverage: As stated in §II-B,
the audio clip I is divided into frames (e.g., 20 ms) by SR for
processing and each frame contains multiple sampling points
the perturbation δ essentially alters (increases
(e.g., 320),
or decreases) the amplitude of each sampling point. In the
formulation to train δ in Eqns (1)-(3), the objective is to
minimize the sampling point’s amplitude changing to ensure
a good audio quality. Next by referring to the selected grafﬁti
template, the perturbation then sounds more like an acoustic
grafﬁti. In this section, we ﬁnd we can reduce the amount of
frame sampling points to be altered by δ , i.e., coverage of δ ,
to further improve the audio quality.
To recognize one audio clip I as the corresponding tran-
script T by SR, different frames usually have a different
importance in this recognition [20], [25]. However, during the
training of δ , it is unclear which frame sampling points from
I + δ could contribute more to the recognition of the target
transcript T(cid:48) in advance, since δ keeps being updated in the
training. To overcome this issue, we add an L2 regularization in
the loss function to punish perturbation amplitude [20], With
this L2 regularization term, the perturbation value can maintain
to be small. We can thus treat such very small perturbation
values as 0 and their corresponding frame sampling points in I
will not be altered. With L2 regularization and grafﬁti template,
the attacker can ﬁnally train δ again by:
argminδ α · dBI(δ ) + Lctc
+ γ · Lo f − β · Ld + η · dist(δ , ˆN) + µ · L2,
(10)
where µ is the weighting factor for L2, which is conﬁgured
in §IV-A. For the δ obtained from Eqn. (10), we can deﬁne a
perturbation coverage mask C = {Cf}, where f is the sampling
Figure 11: Perturbations trained by (a) the enhanced adver-
sarial example generation in §III-B2 and (b) further with the
improved audio quality in §III-C.
point index, as follows:
(cid:26) 1,
0,
Cf =
if s < δ f ,
otherwise,
where s is the threshold to determine whether δ for each sam-
pling point f is small enough, e.g., s = 20 in the amplitude’s
representation range from −215 to 215 (int-16). Thus, C·δ will
ignore those very small perturbation values and thus reduce
the δ ’s coverage. Figure 11(a) depicts one δ obtained from
§III-B. When Eqn. (10) is adopted, the resulting δ is shown
in Figure 11(b), and we can see that many perturbation values
in δ are very small. By applying the mask C, we can obtain
the masked C· δ as the ﬁnal perturbation.
IV. EVALUATION
In this section, we ﬁrst introduce the evaluation setup,
including data collection and training, hardware and software,
evaluation metrics, parameter settings and comparison meth-
ods. We then present ﬁeld studies, which comprehensively
evaluate both the attack success rate and audio quality in both
line-of-sight (LOS) and none-line-of-sight (NLOS) settings.
We ﬁnally describe micro-benchmark results in terms of hard-
ware diversity, ambient noise, victim movement, etc.
A. Experiment Setup
1) Data Collection and Training: To demonstrate Meta-
morph could generate over-the-air adversarial examples with
a small set of prior H(·) measurements, we only use 370
channel impulse response (CIR) measures from four public
acoustic CIR dataset (AIR [28], MARDY [53], REVERB [32]
and RWCP [37]) for the perturbation generation. No CIRs are
collected from our experimental environment directly. These
four CIR datasets are recorded in different rooms (e.g., ane-
choic chamber, lecture and meeting room, stairway, corridor,
church.) with various link distance (0–3 m). Our selected 370
CIRs cover 21 different environments4. With this setting, we
observe that using these CIR traces can achieve a good attack
performance already and also lead to a reasonable computation
overhead as stated below.
Metamorph is implemented using tensorﬂow 1.8.0 [11] and
trained by Adam optimizer [31], together with a our proposed
domain discriminator, on a high-end server equipped with two
4When future research studies employ our approach, they do not need to
design the domain discriminator speciﬁcally for their anticipated environments
neither. If the domain discriminator needs to be more generic, they can further
include additional CIR traces covering more environments, e.g., these datasets
contain over 50 different environments in total.
8
Figure 12: Floorplan of the ﬁeld study. We initiate both LOS
and NLOS adversarial attacks in an ofﬁce building.
NVIDIA GTX 1080Ti GPU and 32GB RAM. The training
time of an adversarial example depends on the length of this
adversarial audio clip. For example, generating a 6-second
adversarial example takes around ﬁve to seven hours on a
single NVIDIA GTX 1080Ti GPU, respectively. The training
process in the future can be accelerated when more GPUs can
be used in parallel. We then conduct trace-driven evaluations to
quantify the system performance. In particular, we initiate the
adversarial attack using different receivers (including a Google
Nexus 5X, Samsung Galaxy S7, HTC A9W and iPhone 8)
and one default transmitter (HiVi M200MKIII [5]) across 29
different locations, as shown in Figure 12. At each location,
we play each adversarial example 100 times. The receiver
records the received adversarial examples and feeds them
into the targeting neural network for speech recognition, i.e.,
DeepSpeech. We then evaluate using following metrics.
2) Metrics: Our experiments primarily rely on the follow-
ing three metrics to evaluate Metamorph’s performance:
• Character success rate (CSR) is deﬁned as the ratio
of characters being successfully interpreted to the total
number of characters conveyed by the adversarial example.
• Transcript success rate (TSR) is deﬁned as the ratio of
transcripts being successfully interpreted to the total num-
ber of transcript conveyed by all the adversarial examples.
• Mel Cepstral Distortion (MCD) [19] measures the sound
quality by comparing the distance between the target
sound (the encoded audio adversarial) and the reference
sound (the original sound). MCD is calculated by: MCD =
i − mce
i and mce
i
denote target and the estimated MCD, respectively. Lower
MCD indicates better sound quality.
3) Comparison Schemes: We evaluate following schemes:
(10/ln(10)) ·(cid:113)
i )2, where mct
2· ∑24
i=1(mct
• Meta-Init is the initial version of Metamorph (§III-B).
• Meta-Enha is the domain discriminator-based version of
Metamorph (§III-B2). It minimizes the effects of the device-
and environment-speciﬁc features from perturbation to im-
prove the attack distance and reliability.
• Meta-Qual represents the audio quality improved version
of Metamorph (§III-C).
4) System Conﬁgurations: Metamorph contains several pa-
rameters. According to our detailed investigation in Appendix,
we adopt the default β , γ, η and µ from the ﬁnal loss function
in Eqn. (10) as 0.05, 500, 1e-4, 1e-12 respectively in the
9
Figure 13: Performance of LOS attack by three comparison
schemes. (a) Character successful rate (CSR) and (b) Tran-
script successful rate (TSR) in different attack distances.
experiments. On the other hand, the ratio of the characters
being en-coded into the source audio to the total number of
source audio frames, deﬁned as frame utilize rate (FUR), is
set to be less than or equal to 0.2 by default (Section IV-C).
We generate two types of adversarial examples (music and
speech) with different source and target transcripts, detailed in
Table 5 (Appendix). The source musics are labelled in Table 5
directly, and the speech adversarial examples are generated
based on 11 different speech samples from the public Mozilla
Common Voice Dataset [6]. For each adversarial example, we
generate three versions using three comparison schemes.
B. Field Study
1) LOS Attack: We ﬁrst
initiate adversarial attacks at
different
locations that all have a clear LOS path to the
victim microphone. Figure 13 shows the averaged TSR and
CSR achieved by three versions of Metamorph in different
link distance settings. We divide the link distance into three
categories: short-range (0.5–1 m), mid-range (2–6 m), and
long-range (6–8 m).
CSR performance. We observe that the initial version Meta-
Init achieves nearly 100% CSR in short range settings. As
we expand the link distance to the mid-range settings, the
multi-path effect grows. Since the initial version has limited
robustness to the multi-path effect, we thus see that CSR
drops signiﬁcantly to around 50%. As we further increase the