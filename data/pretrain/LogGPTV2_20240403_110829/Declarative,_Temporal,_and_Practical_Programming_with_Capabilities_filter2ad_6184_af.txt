the security requirements of the program and its original
functionality.
The number of program points at which capweave
introduced instrumentation (i.e., “Woven Points”) was small
relative to the size of each benchmark. Furthermore, the
number of functions that each woven benchmark executed
between a synchronous fork and join (i.e., “Interproc.
Funcs”) was small, and matched the number of functions
that each hand-woven benchmark executed between a syn-
chronous fork and join (and thus likely was minimal).
However, woven versions of bzip2, gzip, php-cgi, and
wget incurred noticeable overhead. We suspected that the
woven versions of these programs would introduce the most
overhead on small workloads, because on such workloads,
the ﬁxed overhead of executing a synchronous fork and
join dominates the overall runtime of the program.
To measure the performance of the woven programs
on larger workloads, we generated a 1 GB ﬁle of source
code from the Capsicum kernel source tree, and used it as
a workload for bzip2, gzip, and wget. The unwoven
bzip2 compressed the large ﬁle in 25m31s, and the woven
bzip2 compressed the large data with 4% overhead over
the baseline time. The unwoven gzip compressed the large
ﬁle in 5m27s, and the woven gzip compressed the large
data with 3% overhead over the baseline time. The unwoven
wget downloaded the large ﬁle from a server on the same
local network in 1m06s, and the woven wget downloaded
the large data with −4% overhead over the baseline time,
indicating that the overhead of the weaving is obscured by
noise introduced by network trafﬁc. Thus, the maximum
overhead of the woven programs over unwoven programs
is 4%, and geometric mean of all the overheads is 1%. The
overhead for php-cgi depends entirely on how frequently
an input PHP script opens ﬁles over the course of its
execution.
The woven versions of tar and tcpdump introduced
noticeable overhead on operations that execute frequently
on all workloads, such as a procedure in tar that reads
data into a buffer, or a procedure in tcpdump that resolves
network addresses to names. The per-operation overhead
induces an enormous overhead in tar in particular, and
illustrates another limitation of capweave: some policies
induce capweave to introduce costly primitives, such as
fork, at program points that induce considerable overhead,
whereas capweave might be able to instrument other pro-
gram points that induce much less overhead. The overhead
of the hand-woven program, while less than the overhead
of the capweave-woven program,
is still considerable:
in our experience, weaving tar efﬁciently is a difﬁcult
problem, and one that could beneﬁt signiﬁcantly from further
automatic-tool support. In future work, we hope to address
this limitation by extending capweave to use a cost metric,
and generalizing the game solver to ﬁnd optimal strategies
30
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:01 UTC from IEEE Xplore.  Restrictions apply. 
for quantitative games [22].
V. RELATED WORK
Capability systems: Karger [23] introduced a capa-
bility system that mitigates the effects of an attack by
a malicious program run on the system. The Capsicum
operating system [10] provides security primitives to support
isolating components of a program in sandboxes that run
with different capabilities based on UNIX ﬁle descriptors.
This paper describes the capweave tool, which greatly
eases the burden of using Capsicum by allowing policies to
be stated as a separate speciﬁcation that capweave weaves
into the program automatically.
Security monitors: Operating systems that provide
security system calls, such as Capsicum, HiStar
[11],
Wedge [24] etc., allow an application developer to deﬁne
program-speciﬁc policies (where the nature of the policy
depends on the security primitives offered by the operating
system). In contrast, Mandatory Access Control (MAC) op-
erating systems, such as [25]–[27] only support system-wide
policies described in terms of standard system events. Such
policies cannot refer to important events in the execution
of a particular program, but many practical policies can
only be deﬁned in terms of such events [28]. UNIX can
monitor programs to ensure that they satisfy policies if the
program correctly uses the setuid system call, but in
general this approach suffers the same shortcomings as MAC
systems. In comparison, systems with security primitives
allow an application to signal key events in its execution to
the operating system. Watson has described the challenges
of developing an access-control system, and has surveyed
recent implementations of such systems [29].
An Inline Reference Monitor (IRM) rewriter takes a policy
expressed as an automaton and instruments a target program
with an IRM, which executes in the same memory space as
the program, and halts the program if it attempts to perform
some sequence of actions that would violate the policy [28],
[30]. Edit automata [31] generalize IRMs by also supressing
or adding security-sensitive events to ensure that the program
satisﬁes a policy. Because an IRM (or edit automaton)
executes in the same memory space as the program that it
monitors, it can enforce policies deﬁned over arbitrary events
in the execution of the program. However, for the same
reason, an IRM can only monitor the execution of managed
code. In comparison, systems with security primitives can
safely and efﬁciently monitor programs composed largely
of unmanaged code [10], [11].
Writing programs for security monitors: Prior work
on programming aids for systems with security primitives
automatically veriﬁes that a program instrumented to use the
Flume OS [9] primitives enforces a high-level policy [32],
automatically instruments programs to use the primitives of
the HiStar OS to satisfy a policy [33], and automatically
instruments programs [32] to use the primitives of the Flume
OS [9]. However, the languages of policies used in the
approaches presented in [33], [34] are not temporal, and
cannot clearly be applied to other systems with security
primitives. The weaving algorithm presented in this paper
applies a known automata-theoretic weaving algorithm [15],
and can, in principle, be applied in multiple settings. The
main contribution of this paper is to describe how the
automata-theoretic algorithm can be applied as an engine
to rewrite programs for a practical capability system.
In the privsep project [35], OpenSSH was rewritten
manually to execute using a trusted, privileged parent pro-
cess and an unprivileged child process. A programmer can
use the Privman [36] library to manually compartmentalize
a UNIX daemon into high and low-privilege processes.
Previous work [37], [38] automatically partitions programs
so that high and low-conﬁdentiality data are processed
by separate processes, or on separate hosts. The SOAPP
project [39] proposes a semi-automatic technique in which
a programmer annotates a program with a hypothetical sand-
box, and a program analysis validates that the sandbox does
not introduce unexpected program behavior. The SOAPP
approach is similar in spirit
to [32], which uses model
checking to verify that a programmer-proposed partitioning
and set of calls to security primitives satisﬁes a given
policy. In contrast, capweave automatically infers where to
invoke library functions that cause the program to execute in
different processes (if necessary), and rewrites the program
accordingly.
Skalka and Smith [40] present an algorithm that takes
a Java program instrumented with capability-based security
checks, and attempts to show statically that some checks
are always satisﬁed. Hamlen et al. [41] verify that programs
rewritten by an IRM rewriter are correct. Thus, the work
in both of those papers concerns identifying superﬂuous
capability checks in managed programs, whereas our work
concerns how to infer the correct placement of primitives to
restrict the capabilities of unmanaged programs.
Safety games: Safety games have been studied as a
framework for synthesizing reactive programs and control
mechanisms [14], [42]. Previous work describes algorithms
that take a safety game, determine which player can always
win the game, and synthesize a winning strategy for the
winning player [14]. The key contribution of our work is
to demonstrate that such game-theoretic problems can be
applied in practice to rewrite programs to enforce a security
policy.
VI. CONCLUSION
New operating systems, such as the Capsicum capability
system, deﬁne powerful system-level primitives for secure
programming, but such primitives are non-trivial to use. This
paper presents a policy-weaver for Capsicum, capweave,
that takes from a programmer an uninstrumented program
and a high-level policy that describes correct behavior of the
31
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:01 UTC from IEEE Xplore.  Restrictions apply. 
program. capweave automatically infers where to invoke
security primitives and rewrites the program accordingly.
In practice, capweave produces programs that match the
behavior and performance of programs manually modiﬁed
by an expert. capweave is designed so that a Capsicum Ar-
chitect can easily add, remove, or update new programming
libraries as they continue to be developed.
Acknowledgments: We gratefully acknowledge the
work of the Capsicum development team, in particular Pawel
Dawidek, Khilan Gudka, and Ben Laurie, in developing Cap-
sicum and manually instrumenting programs for Capsicum.
We thank Michael Zhivich and Jeffrey Seibert at MITLL
for developing the capweave policy for PHP. We thank
our shepherd, Niels Provos.
Supported, in part, by DARPA and AFRL under contracts
FA8650-10-C-7088 and FA8750-10-C-0237. The views,
opinions, and/or ﬁndings contained herein are those of the
authors and should not be interpreted as representing the
ofﬁcial views or policies, either expressed or implied, of
the Defense Advanced Research Projects Agency or the
Department of Defense.
REFERENCES
[1] “CVE-2007-3798,” http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2007-3798, July 2007.
[2] “CVE-2004-1488,” http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CAN-2004-1488, Feb 2005.
[3] “CVE-2010-0405,” http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2010-0405, April 2010.
[4] “Vulnerability note VU#381508,” http://www.kb.cert.org/
[5] “Vulnerability note VU#520827,” http://www.kb.cert.org/
vuls/id/381508, July 2011.
vuls/id/520827, May 2012.
[6] “CVE-2007-4476,” http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2007-4476, Aug 2007.
[7] “GNU Tar and GNU Cpio rmt read
() function buffer
overﬂow,” http://xforce.iss.net/xforce/xfdb/56803, Mar 2010.
[8] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey,
D. Ziegler, E. Kohler, D. Mazi`eres, F. Kaashoek, and R. Mor-
ris, “Labels and event processes in the Asbestos operating
system,” in SOSP, 2005.
[9] M. Krohn, A. Yip, M. Brodsky, N. Cliffer, M. F. Kaashoek,
E. Kohler, and R. Morris, “Information ﬂow control for
standard OS abstractions,” in SOSP, 2007.
[10] R. N. M. Watson, J. Anderson, B. Laurie, and K. Kennaway,
“Capsicum: Practical capabilities for UNIX,” in USENIX
Security, 2010.
[11] N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazi`eres,
“Making information ﬂow explicit in HiStar,” in OSDI, 2006.
http:
announcement,”
[12] “FreeBSD
9.0-RELEASE
//www.freebsd.org/releases/9.0R/announce.html, Jan. 2012.
[13] “cl-capsicum-discuss – Capsicum project discussion list,”
https://lists.cam.ac.uk/mailman/listinfo/cl-capsicum-discuss,
2012.
[14] R. Alur, S. L. Torre, and P. Madhusudan, “Modular strategies
for recursive game graphs,” in TACAS, 2003.
[15] W. R. Harris, S. Jha, and T. W. Reps, “Secure programming
via visibly pushdown safety games,” in CAV, 2012.
[16] C. Lattner, http://llvm.org/, Nov. 2011.
[19] W. R. Harris, S. Jha, T. Reps, J. Anderson, and R. N. M. Wat-
son, “Declarative, temporal, and practical programming with
capabilities,” http://minds.wisconsin.edu/handle/1793/64927,
University of Wisconsin-Madison, Tech. Rep. TR1785, 2013.
[20] A. One, “Smashing the stack for fun and proﬁt,” Phrack
Magazine, vol. 49, no. 14, 1998.
[21] “Using Capsicum for sandboxing,” http://www.links.org/?p=
1242, April 2012.
[22] A. Ehrenfeucht and J. Mycielski, “Positional strategies for
mean payoff games,” International Journal of Game Theory,
vol. 8, no. 2, 1979.
[23] P. A. Karger, “Limiting the damage potential of discretionary
trojan horses,” in IEEE S&P, 1987.
[24] A. Bittau, P. Marchenko, M. Handley, and B. Karp, “Wedge:
Splitting applications into reduced-privilege compartments,”
in NSDI, 2008.
[25] P. Loscocco and S. Smalley, “Integrating ﬂexible support for
security policies into the Linux operating system,” in USENIX
Annual Technical Conference, 2001.
[26] O. S. Saydjari, “Lock : An historical perspective,” in ACSAC,
2002.
[17] R. Alur and P. Madhusudan, “Visibly pushdown languages,”
[18] S. Graf and H. Sa¨ıdi, “Construction of abstract state graphs
in STOC, 2004.
with PVS,” in CAV, 1997.
[27] C. Wright, C. Cowan, J. Morris, and S. S. G. Kroah-Hartman,
“Linux security modules: General security support for the
Linux kernel,” in Found. of Intrusion Tolerant Systems, 2003.
´U. Erlingsson and F. B. Schneider, “IRM enforcement of Java
stack inspection,” in IEEE S&P, 2000.
[29] R. N. M. Watson, “A decade of OS access-control extensibil-
[28]
ity,” Commun. ACM, vol. 56, no. 2, Feb. 2013.
[30] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti, “Control-
ﬂow integrity,” in CCS, 2005.
[31] J. Ligatti, L. Bauer, and D. Walker, “Edit automata: Enforce-
ment mechanisms for run-time security policies,” Int. J. Inf.
Sec., vol. 4, no. 1-2, 2005.
[32] W. R. Harris, N. A. Kidd, S. Chaki, S. Jha, and T. Reps, “Ver-
ifying information ﬂow control over unbounded processes,”
in FM, 2009.
[33] P. Efstathopoulos and E. Kohler, “Manageable ﬁne-grained
information ﬂow,” in EuroSys, 2008.
[34] W. R. Harris, S. Jha, and T. Reps, “DIFC programs by
automatic instrumentation,” in CCS, 2010.
[35] N. Provos, “Privilege separated OpenSSH,” http://www.citi.
umich.edu/u/provos/ssh/privsep.html, Aug 2003.
[36] D. Kilpatrick, “Privman: A library for partitioning applica-
tions,” in USENIX Annual Technical Conference, 2003.
[37] D. Brumley and D. X. Song, “Privtrans: Automatically
partitioning programs for privilege separation,” in USENIX
Security Symposium, 2004.
[38] S. Chong, J. Liu, A. C. Myers, X. Qi, K. Vikram, L. Zheng,
and X. Zheng, “Secure web application via automatic parti-
tioning,” in SOSP, 2007.
[39] K. Gudka, R. N. M. Watson, S. Hand, B. Laurie, and A. Mad-
havapeddy, “Exploring compartmentalization hypothesis with
SOAPP,” in AHANS 2012, 2012.
[40] C. Skalka and S. F. Smith, “Static enforcement of security
with types,” in ICFP, 2000.
[41] K. W. Hamlen, G. Morrisett, and F. B. Schneider, “Certiﬁed
in-lined reference monitoring on .NET,” in PLAS, 2006.
[42] R. Alur, T. A. Henzinger, and O. Kupferman, “Alternating-
time temporal logic,” in FOCS, 1997.
32
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:01 UTC from IEEE Xplore.  Restrictions apply.