The checker has as a parameter, a worst-case bound. The
bound is expressed relative to the bandwidth overhead of
the hash tree, if the hash tree had been used to check the
integrity of the RAM during the FSM’s execution. For
instance, if the bound is set at 10%, then, for all FSMs,
the tree-log bandwidth overhead is guaranteed to be less
than 1.1 times the hash tree bandwidth overhead.
(The
bandwidth overhead is deﬁned as the additional bandwidth
consumed during the program’s execution by the integrity
checking scheme compared to the bandwidth the program
would have consumed without any integrity checking.)
During the FSM’s execution, the checker monitors its
bandwidth overhead, and it moves addresses to the log-
hash scheme based on its bandwidth overhead. Whenever
an adaptive-tree-log-check operation occurs, the checker
moves all of the addresses in the log-hash scheme back to
the tree to optimize the log-hash scheme; the operation does
not need any arguments from the FSM because the checker
moves all of the addresses in the log-hash scheme to the
tree. The adaptive-tree-log-check operation can be per-
formed at anytime; whenever it is performed, the bandwidth
overhead of the checker is guaranteed never to be worse
than the parameterizable worst-case bound.
6.2. Without Caching: Worst-case Bound
First, we consider the case where the FSM does not use
a cache. We make no assumptions about the FSM’s access
patterns. The na¨ıve approach would be for the checker to
just move addresses to the log-hash scheme each time it ac-
cesses an address that is in the tree. The na¨ıve approach is
a valid approach of using the tree-log scheme. However,
the bandwidth overhead of the approach could potentially
be more than twice that of the hash tree during short check
periods (primarily because of the extra cost of the tree-
log-check operation). Thus, to provide the parameterizable
worst case bound, the checker needs to regulate the rate at
which addresses are added to the log-hash scheme.
Let ω be the parameterizable worst case bound (e.g.,
if the bound is 10%, ω = 0.1). While the FSM is run-
ning, the adaptive tree-log checker maintains two statis-
tics: (1) its current total reserve, R, and (2) the number
of data value blocks currently in the log-hash scheme, nlh.
R = (1 + ω)Bht − Btl where Btl is the current total tree-
log bandwidth overhead and Bht is the current total hash
tree bandwidth overhead, if the hash tree had been used to
check the RAM. Intuitively, R is how many bits ahead the
tree-log checker is of the parameterizable worst-case bound.
Bht is easily determined given the height of the tree, the size
of a hash and its siblings, and the total number of FSM op-
erations performed thus far. R and nlh are also maintained
in the checker’s ﬁxed-sized trusted state. nlh is incremented
whenever an address is moved from the tree to the log-hash
scheme, and reset to zero on a tree-log-check operation af-
ter the operation has moved the addresses back to the tree.
R is updated on each checker operation.
We itemize how R changes on each tree-log operation:
• tree-log-store/tree-log-load: R increases with each
operation.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
adaptive-tree-log-store(a, v):
1. If a is in the tree, and Rcp > C
2. tree-log-store(a, v).
adaptive-tree-log-load(a):
1. If a is in the tree, and Rcp > C
2. tree-log-load(a).
adaptive-tree-log-check():
tl-mv-to-lh
+ C
tl-chk
(nlh + 1), then tree-log-moveToLogHash(a).
tl-mv-to-lh
+ C
tl-chk
(nlh + 1), then tree-log-moveToLogHash(a).
1. Let Z be the set of addresses in the log-hash scheme. tree-log-check(Z).
Figure 7. Adaptive tree-log checker for untrusted RAM, without caching
• tree-log-moveToLogHash: R decreases with each
operation. Let C
tl-mv-to-lh be the b/w consumed
by the tree-log-moveToLogHash operation. Then,
∆R = −C
tl-mv-to-lh.
• tree-log-check: R decreases with each operation. Let
(nlh) be the bandwidth consumed by the tree-
(nlh) increases with nlh.
C
log-check operation; C
∆R = −C
(nlh).
tl-chk
tl-chk
tl-chk
Table 1 details the amounts by which R changes when a
range is used for bookkeeping (cf. Section 5.2). The reserve
increases on each tree-log-store/tree-log-load operation.
The essential idea of how we bound the worst case tree-log
bandwidth overhead is to have the checker build up enough
reserve to cover the cost of the tree-log-moveToLogHash
operation plus the increased cost of the tree-log-check op-
eration before the checker moves an address from the tree
to the log-hash scheme. Whenever the checker wants to
move an address to the log-hash scheme, it performs a test
to determine if it has enough reserve to do so. For the test,
the checker checks that the address is in the tree and that
(nlh + 1). If these checks
R > C
pass, the test returns true; otherwise, the test returns false.
If the test returns true, the checker has enough reserve to
be able to move the address to the log-hash scheme. Other-
wise, the checker cannot move the address to the log-hash
scheme. Whenever an address is moved to the log-hash
scheme, nlh is incremented.
tl-mv-to-lh
tl-chk
+ C
The mechanism described in this section is a safety
mechanism for the adaptive tree-log scheme: whenever an
adaptive-tree-log-check operation occurs, the bandwidth
overhead of the checker is guaranteed never to be larger
than (1 + ω)Bht. As can be seen from the expression for
R, the larger ω is, the sooner the checker will be able to
move addresses to the log-hash scheme. Also, the larger
ω is, the larger could be the potential loss in the case that
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
the tree-log scheme has to perform an adaptive-tree-log-
check soon after it has started moving addresses to the log-
hash scheme; however, in the case that the performance of
the tree-log scheme improves when the log-hash scheme is
used, which is the case we expect, the larger ω is, the greater
the rate at which addresses can be added to the log-hash
scheme and the greater can be the performance beneﬁt of
using the log-hash scheme. Also from the expression for
R, the smaller the tree-log bandwidth overhead compared
to the hash tree bandwidth overhead, the better the tree-log
scheme performs and the greater the rate at which addresses
can be added to the log-hash scheme. This helps the checker
adapt to the performance of the scheme, while still guaran-
teeing the worst-case bound.
6.3. Without Caching: Tree-Log Strategy
Section 6.2 describes the minimal requirements that are
needed to guarantee the bound on the worst-case bandwidth
overhead of the tree-log checker. The approach described in
Section 6.2 can be applied as a greedy algorithm in which
addresses are moved to the log-hash scheme whenever R is
sufﬁciently high. However, it is common for programs to
have a long check period during which they process data,
then have a sequence of short check periods as they per-
form critical instructions to display or sign the results. If
the checker simply moved addresses to the log-hash scheme
as long as R was large enough, for short check periods,
the checker might move a lot of data into the log-hash
scheme and incur a costly penalty during that check period
when the adaptive-tree-log-check operation occurs. We
do not want to risk gains from one check period in sub-
sequent check periods. Thus, instead of using R, we use
Rcp, the reserve that the checker has gained during the cur-
rent check period, to control the rate at which addresses
are added to the log-hash scheme. By using Rcp instead
of R, for short check periods, it is more likely that the
checker will just keep addresses in the tree, instead of mov-
ing addresses to the log-hash scheme. If we let R
cp-start
be the value of R at the beginning of the check period, then
Rcp = R − R
cp-start. Rcp regulates the rate at which ad-
dresses are added to the log-hash scheme during the current
check period.
Figure 7 shows the interface the FSM uses to call the
adaptive tree-log checker. The strategy we use is a sim-
ple strategy and more sophisticated strategies for moving
addresses from the tree to the log-hash scheme can be de-
veloped in the future. Nevertheless, the principal point is
that whatever strategy the checker uses can be layered over
the safety mechanism in Section 6.2 to ensure that the strat-
egy’s bandwidth overhead is never worse than the parame-
terizable worst-case bound.
At this point, we precisely describe the three features of
the adaptive tree-log checker. Firstly, the checker adap-
tively chooses a tree-log strategy for the FSM when the
FSM is executed. This allows FSMs to be run unmodiﬁed,
yet still be able to beneﬁt from the checker’s features. Sec-
ondly, even though the checker is adaptive, it is able to pro-
vide a guarantee on its worst case performance, such that,
for all FSMs, the performance of the checker is guaran-
teed to never be worse than the parameterizable worst case
bound. This feature allows the adaptive tree-log checker to
be turned on by default in systems. The third feature is that,
for all FSMs, as the average number of per data FSM op-
erations (total number of FSM data operations/total number
of data accessed) during a checking period increases, the
checker moves from a logarithmic bandwidth overhead to a
constant bandwidth overhead, ignoring the bandwidth con-
sumption of intermediate log-hash integrity checks. This
feature allows large classes of FSMs to take advantage of
the constant runtime bandwidth overhead of the optimized
log-hash scheme to improve their integrity checking perfor-
mance, because FSMs typically perform many data opera-
tions before performing a critical operation.
Let |TIMER| be the bit-length of the log-hash TIMER
counter. In the third feature, we exclude intermediate log-
hash integrity checks because they become insigniﬁcant for
sufﬁciently large |TIMER|. Whenever the TIMER reaches its
maximum value during a check period, an intermediate log-
hash check is performed (cf. Section 5). However, by using
a large enough |TIMER|, intermediate checks occur so in-
frequently that the amortized bandwidth cost of the check is
very small, and the principal overhead is the constant run-
time bandwidth overhead of the time stamps.
6.4. With Caching
We now consider the case where the FSM uses a cache.
The only assumption that we make about the cache is that
it uses a deterministic cache replacement policy, such as
the popular LRU (least recently-used) policy. There are
two main extensions that are made to the methodology in
Sections 6.2 and 6.3. Firstly, to accurately calculate the re-
serves, the checker will need to be equipped with cache sim-
ulators. Secondly, with a cache, the hash tree may perform
very well. There can exist FSMs for which the reserve can
decrease on tree-log-store and tree-log-load operations.
To handle this situation, the adaptive checker will need an
additional tree-log operation that allows it to backoff, and
will need to perform an additional test to determine whether
it will need to backoff. We describe the extensions.
Cache performance is very difﬁcult to predict. Thus,
to help determine Btl and Bht, the checker maintains a
hash tree cache simulator and a base cache simulator. The
hash tree simulator simulates the hash tree and gives the
hash tree bandwidth consumption. The base cache simula-
tor simulates the FSM with no memory integrity checking
and gives the base bandwidth consumption, from which the
bandwidth overheads can be calculated. The checker also
maintains a tree-log simulator that can be used to determine
the cost of a particular tree-log operation before the checker
actually executes the operation. It is important to note that
each simulator only needs the cache status bits (e.g., the
dirty bits and the valid bits) and the cache addresses, in par-
ticular the cache address tags [7]; the data values are not
needed. The tag RAM is a small percentage of the cache
[7]. Thus, each simulator is small and of a ﬁxed size (be-
cause the cache is of a ﬁxed size) and can, in accordance
with our model in Section 3, be maintained in the checker.
The simulators do not make any accesses to the untrusted
RAM. The simulators are being used to help guarantee the
worst-case bound when the FSM uses a cache and, in Ap-
pendix C, we discuss how they can be dropped if the strict-
ness of the bound is relaxed.
We expect tree-log-store and tree-log-load operations
to generally perform better than the corresponding hash tree
operations because the log-hash scheme does not pollute the
cache with hashes and because the runtime overhead of the
log-hash scheme is constant-sized instead of logarithmic.
However, unlike a cacheless hash tree, a hash tree with a
cache may perform very well. Furthermore, in the tree-
log scheme, because the log-hash scheme does not cache
hashes, when the hash tree is used, the tree’s cost may be
more expensive on average. Also, the tree-log and hash tree
cache access patterns are different, and the tree-log cache
performance could be worse than the hash tree cache perfor-
mance. Reserve can sometimes decrease on tree-log-store
and tree-log-load operations. Thus, because the FSM uses
a cache, the adaptive checker needs to have an additional
backoff procedure that reverts it to the vanilla hash tree if
the reserve gets dangerously low.
The backoff procedure consists of performing a tree-
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
adaptive-tree-log-store(a, v):
1. If a is in the tree, and R(cid:1)
cp > C
then tree-log-moveToLogHash(a).
tl-mv-to-lh
+ C
tl-chk
(nlh + 1) + C
buffer
(nlh + 1),
2. If the tree-log and hash tree caches are not synchronized, if R + ∆R
tl-op
< C
bkoff
(nlh),
then tree-log-bkoff.
3. tree-log-store(a, v).
Figure 8. adaptive-tree-log-store, with caching
log-check operation and synchronizing the FSM’s cache
by putting the cache into the exact state in which it would
have been in the hash-tree scheme. This is done by writ-
ing back dirty tree nodes that are in the cache and updat-
ing them in the tree in RAM, then checking and bringing
into the cache, blocks from RAM that are in the hash tree
cache simulator that are not in the FSM’s cache3. We re-
fer to the backoff procedure as tree-log-bkoff. Let Csync
be the cost of synchronizing the cache (it is independent
of nlh). Then the bandwidth consumed by tree-log-bkoff
(nlh) + Csync. Whenever the
is C
checker backs off, it continues execution just using the tree
alone, until it has enough reserve to try moving addresses to
the log-hash scheme again.
(nlh) = C
tl-chk
bkoff
Again, we indicate how R changes with each tree-log
operation:
• tree-log-store/tree-log-load: With each operation,
R usually increases; however it can decrease. Let
∆R
tl-op be the change in R that occurs when the
store/load operation is performed; ∆R
tl-op can be
positive or negative (and is different for each store/load
operation). ∆R = ∆R
tl-op.
• tree-log-moveToLogHash: R decreases with each
operation. ∆R = −C
tl-mv-to-lh.
• tree-log-check: R decreases with each operation.
∆R ≥ −C
(nlh).
tl-chk
• tree-log-bkoff: R decreases with each operation.
∆R ≥ −C
(nlh).
bkoff
Figure 8 shows the adaptive-tree-log-store operation
when the FSM uses a cache. The adaptive-tree-log-load
operation is similarly modiﬁed. adaptive-tree-log-check
is similar to the operation in Figure 7. The actual costs
of ∆R