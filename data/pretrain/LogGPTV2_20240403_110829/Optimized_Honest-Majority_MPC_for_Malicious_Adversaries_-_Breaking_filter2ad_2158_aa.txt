title:Optimized Honest-Majority MPC for Malicious Adversaries - Breaking
the 1 Billion-Gate Per Second Barrier
author:Toshinori Araki and
Assi Barak and
Jun Furukawa and
Tamar Lichter and
Yehuda Lindell and
Ariel Nof and
Kazuma Ohara and
Adi Watzman and
Or Weinstein
2017 IEEE Symposium on Security and Privacy
Optimized Honest-Majority MPC for Malicious
Adversaries - Breaking the 1 Billion-Gate Per
Second Barrier
Toshinori Araki∗, Assi Barak† Jun Furukawa‡, Tamar Lichter§, Yehuda Lindell†,
Ariel Nof†, Kazuma Ohara∗, Adi Watzman¶ and Or Weinstein†
Email: PI:EMAIL, PI:EMAIL
∗NEC Corporation, Japan
†Bar-Ilan University, Israel
‡NEC Corporation, Israel
Email: PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL
§Queens College, New York, USA; work carried out at Bar-Ilan University
Email: PI:EMAIL
¶Weizman Institute, Israel; work carried out at Bar-Ilan University
Email: PI:EMAIL
Email: PI:EMAIL
Abstract—Secure multiparty computation enables a set of
parties to securely carry out a joint computation of their private
inputs without revealing anything but the output. In the past
few years, the efﬁciency of secure computation protocols has
increased in leaps and bounds. However, when considering the
case of security in the presence of malicious adversaries (who
may arbitrarily deviate from the protocol speciﬁcation), we
are still very far from achieving high efﬁciency. In this paper,
we consider the speciﬁc case of three parties and an honest
majority. We provide general techniques for improving efﬁciency
of cut-and-choose protocols on multiplication triples and utilize
them to signiﬁcantly improve the recently published protocol of
Furukawa et al. (ePrint 2016/944). We reduce the bandwidth of
their protocol down from 10 bits per AND gate to 7 bits per AND
gate, and show how to improve some computationally expensive
parts of their protocol. Most notably, we design cache-efﬁcient
shufﬂing techniques for implementing cut-and-choose without
randomly permuting large arrays (which is very slow due to con-
tinual cache misses). We provide a combinatorial analysis of our
techniques, bounding the cheating probability of the adversary.
Our implementation achieves a rate of approximately 1.15 billion
AND gates per second on a cluster of three 20-core machines with
a 10Gbps network. Thus, we can securely compute 212,000 AES
encryptions per second (which is hundreds of times faster than
previous work for this setting). Our results demonstrate that
high-throughput secure computation for malicious adversaries is
possible.
A. Background
I. INTRODUCTION
In the setting of secure computation, a set of parties with
private inputs wish to compute a joint function of their inputs,
without revealing anything but the output. Protocols for secure
computation guarantee privacy (meaning that
the protocol
reveals nothing but the output), correctness (meaning that
the correct function is computed), and more. These secu-
rity guarantees are provided in the presence of adversarial
behavior. There are two classic adversary models that are
typically considered: semi-honest (where the adversary follows
the protocol speciﬁcation but may try to learn more than
allowed from the protocol transcript) and malicious (where
the adversary can run any arbitrary polynomial-time attack
strategy). Security in the presence of malicious adversaries
provides much stronger security guarantees, but is far more
challenging with respect to efﬁciency.
Feasibility and construction paradigms. Despite its strin-
gent requirements, it has been shown that any polynomial-
time functionality can be securely computed with computa-
tional security [25], [12], [3] and with information-theoretic
security [5], [7]. These results hold both for semi-honest
and malicious adversaries, but an honest majority must be
assumed in order to obtain information-theoretic security even
for semi-honest adversaries. There are two main approaches to
constructing secure computation protocols: the secret-sharing
approach (followed by [5], [7], [12]) works by having the par-
ties interact for every gate of the circuit, whereas the garbled-
circuit approach (followed by [25], [3]) works by having the
parties construct an encrypted version of the circuit which can
be computed at once. Both approaches have importance and
have settings where they perform better than the other. On the
one hand, the garbled-circuit approach yields protocols with
a constant number of rounds. Thus, in high-latency networks,
they far outperform secret-sharing based protocols which have
a number of rounds linear in the depth of the circuit being
computed. On the other hand, protocols based on secret-
sharing have many rounds but can have much lower bandwidth
than protocols based on garbled circuits. Thus, in low-latency
networks, the secret-sharing approach can potentially achieve
a far higher throughput (and reasonable latency for circuits
that are not too deep).
As a result, the type of protocol preferred depends very
much on whether or not high throughput or low latency is the
goal. If low latency is needed (and the circuit being computed
is deep), then constant-round protocols like [25] outperform
secret-sharing based protocols, even on very fast networks.
© 2017, Toshinori Araki. Under license to IEEE.
DOI 10.1109/SP.2017.15
843
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:59 UTC from IEEE Xplore.  Restrictions apply. 
However, these same protocols fail to achieve high throughput
due to the large bandwidth incurred. Due to this situation, it
is important to develop protocols for low and high latency
networks, with better response time and/or throughput.
In this paper, we focus on the task of achieving high-
throughput secure computation on low-latency networks, with
security for malicious adversaries.
Efﬁciency. The aforementioned feasibility results demonstrate
that secure computation is possible in theory, but do not
necessarily show how to achieve it efﬁciently. The problem
of constructing efﬁcient protocols for secure computation has
interest recently and progress has been
gained signiﬁcant
extraordinarily fast,
transforming the topic from a notion
of theoretical interest only, into a technology that is even
being commercialized by multiple companies. In order to
demonstrate this progress,
it sufﬁces to compare the ﬁrst
implementation in 2004 of a semi-honest two-party protocol
based on Yao’s garbled circuits that computed at a rate of
approximately 620 gates per second [21], to more recent work
that processes at a rate of approximately 1.3 million gates per
second [13]. This amazing progress was due to a long series
of works that focused on all cryptographic and algorithmic
aspects of the problem, as well as the advent of ubiquitous
crypto hardware acceleration in the form of AES-NI and more.
See [15], [18], [8], [14], [9], [19], [4], [17], [24], [20], [26],
[16], [23] for just some examples.
Despite this extraordinary progress, we are still very far
away from the goal of achieving high throughput secure com-
putation, especially for malicious adversaries. In 2012, [19]
declared the age of “billion-gate secure computation” for
malicious adversaries; however, their implementation utilized
256-core machines and took over 2.5 hours to process a billion
AND gates, thereby achieving a rate of 100,000 AND gates
per second. More recently, two-party secure computation for
malicious adversaries was achieved at the rate of over 26,000
AND gates per second on standard hardware [23].
Due to the great difﬁculty of achieving high throughput for
the setting of two parties (and no honest majority in general),
we consider the three-party case with an honest-majority. This
is interesting in many applications, as described in [22], [1],
and is thus worth focusing on.
B. Our Contributions
In this paper, we present a high-throughput protocol for
three-party secure computation with an honest majority and
security for malicious adversaries. We optimize and imple-
ment the protocol of [11], that builds on the protocol of [1]
that achieves a rate of over 7 billion AND gates per second,
but with security only for semi-honest adversaries. The multi-
plication (AND gate) protocol of [1] is very simple; each party
sends only a single bit to one other party and needs to compute
only a few very simple AND and XOR operations. Security
in the presence of malicious adversaries is achieved in [11] by
using the cut-and-choose technique in order to generate many
valid multiplication triples (shares of secret bits (a, b, c) where
a, b are random and c = ab). These triples are then used to
guarantee secure computation, as shown in [2]. This paradigm
has been utilized in many protocols; see [20], [9], [16] for just
a few examples.
The cut-and-choose method works by ﬁrst generating many
triples, but with the property that a malicious party can make
844
c (cid:2)= ab. Then, some of the triples are fully “opened” and
inspected, to verify that indeed c = ab. The rest of the triples
are then grouped together in “buckets”; in each bucket, one
triple is veriﬁed by using all the others in the bucket. This
procedure has the property that the veriﬁed triple is valid (and
a, b, c unknown), unless the unfortunate event occurs that all
triples in the bucket are invalid. This method is effective since
if the adversary causes many triples to be invalid then it is
caught when opening triples, and if it makes only a few triples
invalid then the chance of a bucket being “fully bad” is very
small. The parameters needed (how many triples to open and
how many in a bucket) are better – yielding higher efﬁciency –
as the number of triples generated overall increases. Since [1]
is so efﬁcient, it is possible to generate a very large number
of triples very quickly and thereby obtain a very small bucket
−40,
size. Using this idea, with a statistical security level of 2
the protocol of [11] can generate 220 triples while opening very
few and using a bucket size of only 3. In the resulting protocol,
each party sends only 10 bits per AND gate, providing the
potential of achieving very high throughput.
We carried out a highly-optimized implementation of [11]
and obtained a very impressive rate of approximately 500
million AND gates per second. However, our aim is to obtain
even higher rates, and the microbenchmarking of our imple-
mentation pointed to some signiﬁcant bottlenecks that must be
overcome in order to achieve this. First, in order for cut-and-
choose to work, the multiplication triples must be randomly
divided into buckets. This requires permuting very large arrays,
which turns out to be very expensive computationally due to
the large number of cache misses involved (no cache-aware
methods for random permutation are known and thus many
cache misses occur). In order to understand the effect of this,
note that on Intel Haswell chips the L1 cache latency is 4
cycles while the L3 cache latency is 42 cycles [27]. Thus, on
a 3.4 GHz processor, the shufﬂing alone of one billion items
in L3 cache would cost 11.7 seconds, making it impossible
to achieve a rate of 1 billion gates per second (even using
20 cores). In contrast, in L1 cache the cost would be reduced
to just 1.17 seconds, which when spread over 20 cores is not
signiﬁcant. Of course, this is a simplistic and inexact analysis;
nevertheless, our experiments conﬁrm this type of behavior.
In addition to addressing this problem, we design protocol
variants of the protocol of [11] that require less communica-
tions. This is motivated by the assumption that bandwidth is
a major factor in the efﬁciency of the protocol.
Protocol-design contributions. We optimized the protocol
of [11], both improving its theoretical efﬁciency (e.g., com-
munication) as well as its practical efﬁciency (e.g., via cache-
aware design). We have the following contributions:
1) Cache-efﬁcient shufﬂing (Section III-A): We devise a cache-
efﬁcient method of permuting arrays that is sufﬁcient for
cut-and-choose. We stress that our method does not yield
a truly random permutation of the items. Nevertheless,
we provide a full combinatorial analysis proving that it
sufﬁces for the goal of cut-and-choose. We prove that the
probability that an adversary can successfully cheat with
our new shufﬂe technique is the same as when carrying
out a truly random permutation.
2) Reduced bucket size (Section III-B): As we have described
above, in the protocol of [11], each party sends 10 bits to
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:59 UTC from IEEE Xplore.  Restrictions apply. 
one other party for every AND gate (when computing 220
−40).
AND gates and with a statistical security level of 2
This is achieved by taking a bucket size of 3. We reduce
the bucket size by 1 and thus the number of multiplication
triples that need to be generated and used for veriﬁcation by
one third. This saves both communication and computation,
and results in a concrete cost of each party sending 7 bits
to one other party for every AND gate (instead of 10).
3) On-demand with smaller buckets (Section III-C): As will be
described below, the improved protocol with smaller buck-
ets works by running an additional shufﬂe on the array of
multiplication triples after the actual circuit multiplications
(AND gates) are computed. This is very problematic from
a practical standpoint since many computations require
far less than 220 AND gates, and reshufﬂing the entire
large array after every small computation is very wasteful.
We therefore provide an additional protocol variant that
achieves the same efﬁciency but without this limitation.
All of our protocol improvements and variants involve an-
alyzing different combinatorial games that model what the
adversary must do in order to successfully cheat. Since the
parameters used in the protocol are crucial to efﬁciency, we
provide (close to) tight analyses of all games.
Implementation contributions. We provide a high-quality
implementation of the protocol of [11] and of our proto-
col variants. By proﬁling the code, we discovered that the
SHA256 hash function computations speciﬁed in [11] take a
considerable percentage of the computation time. We therefore
show how to replace the use of a collision-resistant hash func-
tion with a secure MAC and preserve security; surprisingly,
this alone resulted in approximately a 15% improvement in
throughput. This is described in Section III-D.
We implemented the different protocol variants and ran
them on a cluster of three mid-level servers (2.3GHz CPUs
with twenty cores) connected by a 10Gbps network. As we
describe in Section IV, we used Intel vectorization and a
series of optimizations to achieve our results. Due to the
practical limitations of the ﬁrst variant with smaller buckets,
we only implemented the on-demand version. The highlights
are presented in Table I. Observe that our fastest variant
achieves a rate of over 1.1 billion AND-gates per second,
meaning that large scale secure computation is possible even
for malicious adversaries.
IMPLEMENTATION RESULTS; THROUGHPUT
TABLE I
Protocol Variant
Baseline [11]
Cache-efﬁcient (SHA256)
Smaller buckets, on-demand (SHA256)
AND gates/sec %CPU
71.7%
503,766,615
64.84%
765,448,459
65.8%
988,216,830
1,152,751,967
71.28%
Gbps
4.55
7.28
6.84
7.89
Smaller buckets, on-demand (MAC)
Observe that the cache-efﬁcient shufﬂe alone results in a
50% increase in throughput, and our best protocol version is
2.3 times faster than the protocol described in [11].
Ofﬂine/online. Our protocols can run in ofﬂine/online mode,
where multiplication triples are generated in the ofﬂine phase
and used to validate multiplications in the online phase. The
protocol variants with smaller bucket size (items (2) and (3)
above) both require additional work in the online phase to
randomly match triples to gates. Thus, although these variants
have higher throughput, they have a slightly slower online time
(providing an interesting tradeoff). We measured the online
time only of the fastest online version; this version achieves
a processing rate of 2.1 billion AND gates per second (using
triples that were previously prepared in the ofﬂine phase).
Combinatorial analyses. As we have mentioned above,
the combinatorial analyses used to prove the security of
our different protocols are crucial for efﬁciency. Due to this
observation, we prove some independent claims in Section V
that are relevant to all cut-and-choose protocols. First, we ask
the question as to whether having different-sized buckets can
improve the parameters (intuitively, this is the case since it
seems harder for an adversary to ﬁll a bucket with all-bad
items if it doesn’t know the size of the bucket). We show
that this cannot help “much” and it is best to take buckets of
all the same size or of two sizes B and B + 1 for some B.
Furthermore, we show that it is possible to somewhat tune the
cheating probability of the adversary. Speciﬁcally, if a bucket-
size B taken does not give a low enough cheating probability
then we show that instead of increasing the bucket size to
B +1 (which is expensive), it is possible to lower the cheating
probability moderately at less expense.
C. Related work.
As we have described above, a long series of work has been
carried out on making secure computation efﬁcient, both for
semi-honest and malicious adversaries. Recent works like [23]
provide very good times for the setting of two parties and
malicious adversaries (achieving a rate of 26,000 AND gates
per second). This is far from the rates we achieve here.
However, we stress that they work in a much more difﬁcult
setting, where there is no honest majority.
To the best of our knowledge, the only highly-efﬁcient
implemented protocol for the case of three parties with an
honest majority and (full simulation-based security) for mali-
cious adversaries is that of [22], which follows the garbled-
circuit approach. Their protocol achieves a processing rate of