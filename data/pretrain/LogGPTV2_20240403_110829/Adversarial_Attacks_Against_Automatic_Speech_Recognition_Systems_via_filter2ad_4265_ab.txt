2) Neural Network: Like many statistical models, an arti-
Ô¨Åcial neural network can learn very general input/output map-
pings from training data. For this purpose, so-called neurons
are arranged in layers and these layers are stacked on top of
each other and are connected by weighted edges to form a
DNN. Their parameters, i. e., the weights, are adapted during
the training of the network. In the context of ASR, DNNs
can be used differently. The most attractive and most difÔ¨Åcult
application would be the direct transformation of the spoken
text at the input to a character transcription of the same text at
the output. This is referred to as an end-to-end-system. Kaldi
takes a different route: it uses a more conventional Hidden
Markov Model (HMM) representation in the decoding stage
and uses the DNN to model the probability of all HMM states
(modeling context-dependent phonetic units) given the acoustic
input signal. Therefore, the outputs of the DNN are pseudo-
posteriors, which are used during the decoding step in order
to Ô¨Ånd the most likely word sequence.
3) Decoding: Decoding in ASR systems, in general, uti-
lizes some form of graph search for the inference of the most
probable word sequence from the acoustic signal. In Kaldi,
a static decoding graph is constructed as a composition of
individual transducers (i. e., graphs with input/output symbol
mappings attached to the edges). These individual transducers
describe for example the grammar, the lexicon, context depen-
dency of context-dependent phonetic units, and the transition
and output probability functions of these phonetic units. The
transducers and the pseudo-posteriors (i. e., the output of the
DNN) are then used to Ô¨Ånd an optimal path through the word
graph.
B. Adversarial Machine Learning
Adversarial attacks can,
in general, be applied to any
kind of machine learning system [5], [6], [26], but they are
successful especially for DNNs [18], [35].
As noted above, a trained DNN maps an input x to an
output y = F (x). In the case of a trained ASR system, this
is a mapping of the features into estimated pseudo-posteriors.
Unfortunately, this mapping is not well deÔ¨Åned in all cases due
to the high number of parameters in the DNN, which leads
to a very complex function F (x). InsufÔ¨Åcient generalization
of F (x) can lead to blind spots, which may not be obvious
to humans. We exploit this weakness by using a manipulated
input x(cid:48) that closely resembles the original input x, but leads
to a different mapping:
x(cid:48) = x + Œ¥,
such that F (x) (cid:54)= F (x(cid:48)),
3
1.pre-processing2.DNN3.decodingrawaudiofeaturespseudo-posteriorstranscription‚ÄùHELLODARKNESSMYOLDFRIEND‚Äùwhere we minimize any additional noise Œ¥ such that it stays
close to the hearing threshold. For the minimization, we use
a model of human audio signal perception. This is easy for
cases where no speciÔ¨Åc target y(cid:48) is deÔ¨Åned. In the following,
we show that adversarial examples can even be created very
reliably for targeted attacks, where the output y(cid:48) is deÔ¨Åned.
C. Backpropagation
Backpropagation is an optimization algorithm for computa-
tional graphs (like those of neural networks) based on gradient
descent. It is normally used during the training of DNNs to
learn the optimal weights. With only minor changes, it is pos-
sible to use the same algorithm to create adversarial examples
from arbitrary inputs. For this purpose, the parameters of the
DNN are kept unchanged and only the input vector is updated.
For backpropagation, three components are necessary:
1) Measure loss. The difference between the actual out-
put yi = F (xi) and the target output y(cid:48) is measured
with a loss function L(yi, y(cid:48)). The index i denotes
the current iteration step, as backpropagation is an
iterative algorithm. The cross-entropy, a commonly
used loss function for DNNs with classiÔ¨Åcation tasks,
is employed here S
(cid:88)
L(yi, y(cid:48)) = ‚àí
yi log(y(cid:48)).
Calculate gradient. The loss is back-propagated to
the input xi of the neural network. For this purpose,
the gradient ‚àáxi is calculated by partial derivatives
and the chain rule
‚àáxi =
‚àÇL(yi, y(cid:48))
‚àÇxi
=
‚àÇL(yi, y(cid:48))
‚àÇF (xi)
¬∑
‚àÇF (xi)
‚àÇxi
.
(1)
The derivative of F (xi) depends on the topology of
the neural network and is also calculated via the chain
rule, going backward through the different layers.
Update. The input is updated according to the back-
propagated gradient and a learning rate Œ± via
2)
3)
xi+1 = xi ‚àí ‚àáxi ¬∑ Œ±.
These steps are repeated until convergence or until an
upper limit for the number of iterations is reached. With this
algorithm, it is possible to approximately solve problems iter-
atively, which cannot be solved analytically. Backpropagation
is guaranteed to Ô¨Ånd a minimum, but not necessarily the global
minimum. As there is not only one solution for a speciÔ¨Åc target
transcription, it is sufÔ¨Åcient for us to Ô¨Ånd any solution for a
valid adversarial example.
D. Psychoacoustic Modeling
Psychoacoustic hearing thresholds describe how the depen-
dencies between frequencies lead to masking effects in the
human perception. Probably the best-known example for this
is MP3 compression [21], where the compression algorithm
applies a set of empirical hearing thresholds to the input
signal. By removing those parts of the input signal that are
inaudible by human perception, the original input signal can
be transformed into a smaller but lossy representation.
4
Fig. 2: Hearing threshold of test tone (dashed line) masked
by a LCB = 60dB tone at 1 kHz [62]. In green, the hearing
threshold in quiet is shown.
1) Hearing Thresholds: MP3 compression depends on an
empirical set of hearing thresholds that deÔ¨Åne how depen-
dencies between certain frequencies can mask,
i. e., make
inaudible, other parts of an audio signal. The thresholds derived
from the audio do not depend on the audio type, e.g., whether
music or speech was used. When applied to the frequency
domain representation of an input signal, the thresholds indi-
cate which parts of the signal can be altered in the following
quantization step, and hence, help to compress the input. We
utilize this psychoacoustic model for our manipulations of
the signal, i. e., we apply it as a rule set to add inaudible
noise. We derive the respective set of thresholds for an audio
input from the psychoacoustic model of MP3 compression.
In Figure 2 an example for a single tone masker is shown.
Here, the green line represents the human hearing thresholds
in quiet over the complete human-perceptible frequency range.
In case of a masking tone, this threshold increases, reÔ¨Çecting
the decrease in sensitivity in the frequencies around the test
tone. In Figure 2 this is shown for 1 kHz and 60 dB.
2) MP3 Compression: We receive the original input data
in buffers of 1024 samples length that consist of two 576
sample granule windows. One of these windows is the current
granule, the other is the previous granule that we use for
comparison. We use the fast Fourier transform to derive 32
frequency bands from both granules and break this spec-
trum into MPEG ISO [21] speciÔ¨Åed scale factor bands. This
segmentation of frequency bands helps to analyze the input
signal according to its acoustic characteristics, as the hearing
thresholds and masking effects directly relate to the individual
bands. We measure this segmentation of bands in bark, a
subjective measurement of frequency. Using this bark scale, we
estimate the relevance of each band and compute its energy.
In the following steps of the MP3 compression, the thresh-
olds for each band indicate which parts of the frequency do-
main can be removed while maintaining a certain audio quality
during quantization. In the context of our work, we use the
hearing thresholds as a guideline for acceptable manipulations
of the input signal. They describe the amount of energy that can
be added to the input in each individual window of the signal.
An example of such a matrix is visualized in Figure 5d. The
matrices are always normalized in such a way that the largest
time-frequency-bin energy is limited to 95 dB.
III. ATTACKING ASR VIA PSYCHOACOUSTIC HIDING
In the following, we show how the audible noise can be
limited by applying hearing thresholds during the creation of
100806040200Level test tone [dB]0.020.050.10.20.51251020Frequency test tone [kHz]ùêøùëÄ=60ùëëùêµÔ¨Ånd the best target pseudo-posteriors. The forced alignment is
performed once at the beginning of the algorithm.
With the resulting target, we are able to apply backpropa-
gation to manipulate our input signal in such a way that the
speech recognition system transcribes the desired output. The
backpropagation is an iterative process and will, therefore, be
repeated until it converges or a Ô¨Åxed upper limit for the number
of iterations is reached.
The hearing thresholds are applied during the backpropa-
gation in order to limit the changes that are perceptible by a
human. The hearing thresholds are also calculated once and
stored for the backpropagation. A detailed description of the
integration is provided in Section III-F.
C. Forced Alignment
One major problem of attacks against ASR systems is
that they require the recognition to pass through a certain
sequence of HMM states in such a way that
leads to
the target transcription. However, due to the decoding step‚Äî
which includes a graph search‚Äîfor a given transcription, many
valid pseudo-posterior combinations exist. For example, when
the same text is spoken at different speeds, the sequence of
the HMM states is correspondingly faster or slower. We can
beneÔ¨Åt from this fact by using that version of pseudo-posteriors
which best Ô¨Åts the given audio signal and the desired target
transcription.
it
We use forced alignment as an algorithm for Ô¨Ånding the
best possible temporal alignment between the acoustic signal
that we manipulate and the transcription that we wish to obtain.
This algorithm is provided by the Kaldi toolkit. Note that it is
not always possible to Ô¨Ånd an alignment that Ô¨Åts an audio Ô¨Åle
to any target transcription. In this case, we set the alignment
by dividing the audio sample equally into the number of states
and set the target according to this division.
D. Integrating Preprocessing
We integrate the preprocessing step and the DNN step into
one joint DNN. This approach is sketched in Figure 4. The
input for the preprocessing is the same as in Figure 1, and
the pseudo-posteriors are also unchanged. For presentation
purposes, this is only a sketch of the DNN, the used DNN
contains far more neurons.
This design choice does not affect the accuracy of the ASR
system, but it allows for manipulating the raw audio data by
applying backpropagation to the preprocessing steps, directly
giving us the optimally adversarial audio signal as result.
E. Backpropagation
Due to this integration of preprocessing into the DNN,
Equation (1) has to be extended to
‚àáx =
‚àÇL(y, y(cid:48))
‚àÇF (œá)
‚àÇF (œá)
‚àÇFP (x) ¬∑
¬∑
‚àÇFP (x)
‚àÇx
,
where we ignore the iteration index i for simplicity. All
preprocessing steps are included in œá = FP (x) and return the
input features œá for the DNN. In order to calculate ‚àÇFP (x)
,
it is necessary to know the derivatives of each of the four
preprocessing steps. We will introduce these preprocessing
steps and the corresponding derivatives in the following.
‚àÇx
Fig. 3: The creation of adversarial examples can be divided
into three components: (1) forced alignment to Ô¨Ånd an optimal
target for the (2) backpropagation and the integration of (3) the
hearing thresholds.
adversarial examples. As an additional challenge, we need to
Ô¨Ånd the optimal temporal alignment, which gives us the best
starting point for the insertion of malicious perturbations. Note
that our attack integrates well into the DNN-based speech
recognition process: we use the trained ASR system and
apply backpropagation to update the input, eventually resulting
in adversarial examples. A demonstration of our attack is
available at https://adversarial-attacks.net.
A. Adversary Model
Throughout the rest of this paper, we assume the following
adversary model. First, we assume a white-box attack, where
the adversary knows the ASR mechanism of the attacked
system. Using this knowledge, the attacker generates audio
samples containing malicious perturbations before the actual
attack takes place, i. e., the attacker exploits the ASR system
to obtain an audio Ô¨Åle that produces the desired recognition
result. Second, we assume the ASR system to be conÔ¨Ågured in
such a way that it gives the best possible recognition rate. In
addition, the trained ASR system, including the DNN, remains
unchanged over time. Finally, we assume a perfect transmis-
sion channel for replaying the manipulated audio samples,
hence, we do not take perturbations through audio codecs,
compression, hardware, etc. into account by feeding the audio
Ô¨Åle directly into the recognizer. Note that we only consider
targeted attacks, where the target transcription is predeÔ¨Åned
(i. e., the adversary chooses the target sentence).
B. High-Level Overview
The algorithm for the calculation of adversarial examples
can be divided into three parts, which are sketched in Figure 3.
The main difference between original audio and raw audio is
that the original audio does not change during the run-time
of the algorithm, but the raw audio is updated iteratively in
order to result in an adversarial example. Before the backprop-
agation, the best possible temporal alignment is calculated via
so-called forced alignment. The algorithm uses the original
audio signal and the target transcription as inputs in order to
5
1.forcedalignment2.backpropagation3.hearingthresholdsHMML(y,y0)pseudo-posteriorstargetyy0‚ÄùDEACTIVATESECURITYCAMERAANDUNLOCKFRONTDOOR‚Äùtargettranscription‚àáx‚àíŒ±rawaudiocalculatehearingthresholds‚ÄùHELLODARKNESSMYOLDFRIEND‚ÄùoriginalaudioN‚àí1(cid:88)
n=0
1) Framing and Window Function: In the Ô¨Årst step, the
raw audio data is divided into T frames of length N and a
window function is applied to each frame. A window function
is a simple, element-wise multiplication with Ô¨Åxed values w(n)
xw(t, n) = x(t, n) ¬∑ w(n), n = 0, . . . , N ‚àí 1,
with t = 0, . . . , T ‚àí 1. Thus, the derivative is just
‚àÇxw(t, n)
‚àÇx(t, n)
= w(n).
2) Discrete Fourier Transform: For transforming the audio
signal into the frequency domain, we apply a DFT to each
frame xw. This transformation is a common choice for audio
features. The DFT is deÔ¨Åned as
X(t, k) =
xw(t, n)e‚àíi2œÄ kn
N ,