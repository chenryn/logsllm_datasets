title:Protocol State Fuzzing of TLS Implementations
author:Joeri de Ruiter and
Erik Poll
Protocol State Fuzzing of TLS Implementations
Joeri de Ruiter, University of Birmingham; Erik Poll, Radboud University Nijmegen
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/de-ruiter
This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-939133-11-3Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXProtocol state fuzzing of TLS implementations
Joeri de Ruiter
School of Computer Science
University of Birmingham
Erik Poll
Institute for Computing and Information Science
Radboud University Nijmegen
Abstract
We describe a largely automated and systematic analysis
of TLS implementations by what we call ‘protocol state
fuzzing’: we use state machine learning to infer state ma-
chines from protocol implementations, using only black-
box testing, and then inspect the inferred state machines
to look for spurious behaviour which might be an indica-
tion of ﬂaws in the program logic. For detecting the pres-
ence of spurious behaviour the approach is almost fully
automatic: we automatically obtain state machines and
any spurious behaviour is then trivial to see. Detecting
whether the spurious behaviour introduces exploitable
security weaknesses does require manual investigation.
Still, we take the point of view that any spurious func-
tionality in a security protocol implementation is danger-
ous and should be removed.
We analysed both server- and client-side implemen-
tations with a test harness that supports several key ex-
change algorithms and the option of client certiﬁcate au-
thentication. We show that this approach can catch an
interesting class of implementation ﬂaws that is appar-
ently common in security protocol implementations: in
three of the TLS implementations analysed new security
ﬂaws were found (in GnuTLS, the Java Secure Socket
Extension, and OpenSSL). This shows that protocol state
fuzzing is a useful technique to systematically analyse
security protocol implementations. As our analysis of
different TLS implementations resulted in different and
unique state machines for each one, the technique can
also be used for ﬁngerprinting TLS implementations.
1 Introduction
TLS, short for Transport Layer Security, is widely used
to secure network connections, for example in HTTPS.
Being one of the most widely used security protocols,
TLS has been the subject of a lot of research and many
issues have been identiﬁed. These range from crypto-
graphic attacks (such as problems when using RC4 [4])
to serious implementation bugs (such as Heartbleed [13])
and timing attacks (for example, Lucky Thirteen and
variations of the Bleichenbacher attack [3, 30, 9]).
To describe TLS, or protocols in general, a state ma-
chine can be used to specify possible sequences of mes-
sages that can be sent and received. Using automated
learning techniques, it is possible to automatically ex-
tract these state machines from protocol implementa-
tions, relying only on black-box testing.
In essence,
this involves fuzzing different sequences of messages,
which is why we call this approach protocol state fuzzing.
By analysing these state machines, logical ﬂaws in the
protocol ﬂow can be discovered. An example of such
a ﬂaw is accepting and processing a message to per-
form some security-sensitive action before authentica-
tion takes place. The analysis of the state machines can
be done by hand or using a model checker; for the anal-
yses discussed in this paper we simply relied on manual
analysis. Both approaches require knowledge of the pro-
tocol to interpret the results or specify the requirements.
However, in security protocols, every superﬂuous state or
transition is undesirable and a reason for closer inspec-
tion. The presence of such superﬂuous states or transi-
tions is typically easy to spot visually.
1.1 Related work on TLS
Various formal methods have been used to analyse dif-
ferent parts and properties of the TLS protocol [33, 16,
22, 32, 20, 31, 26, 24, 28]. However, these analyses look
at abstract descriptions of TLS, not actual implementa-
tions, and in practice many security problems with TLS
have been due to mistakes in implementation [29]. To
bridge the gap between the speciﬁcation and implemen-
tation, formally veriﬁed TLS implementations have been
proposed [7, 8].
Existing tools to analyse TLS implementations mainly
focus on fuzzing of individual messages, in particular the
USENIX Association  
24th USENIX Security Symposium  193
certiﬁcates that are used. These certiﬁcates have been
the source of numerous security problems in the past.
An automated approach to test for vulnerabilities in the
processing of certiﬁcates is using Frankencerts as pro-
posed by Brubaker et al. [10] or using the tool x509test1.
Fuzzing of individual messages is orthogonal to the tech-
nique we propose as it targets different parts or aspects of
the code. However, the results of our analysis could be
used to guide fuzzing of messages by indicating proto-
col states that might be interesting places to start fuzzing
messages.
Another category of tools analyses implementations
by looking at the particular conﬁguration that is used.
Examples of this are the SSL Server Test2 and sslmap3.
Finally, closely related research on the implementation
of state machines for TLS was done by Beurdouche et al.
[6]. We compare their work with ours in Section 5.
1.2 Related work on state machine learn-
ing
When learning state machines, we can distinguish be-
tween a passive and active approach. In passive learning,
only existing data is used and based on this a model is
constructed. For example, in [14] passive learning tech-
niques are used on observed network trafﬁc to infer a
state machine of the protocol used by a botnet. This
approach has been combined with the automated learn-
ing of message formats in [23], which then also used the
model obtained as a basis for fuzz-testing.
When using active automated learning techniques, as
done in this paper, an implementation is actively queried
by the learning algorithm and based on the responses a
model is constructed. We have used this approach before
to analyse implementations of security protocols in EMV
bank cards [1] and handheld readers for online banking
[11], and colleagues have used it to analyse electronic
passports [2]. These investigations did not reveal new
security vulnerabilities, but they did provide interesting
insights in the implementations analysed. In particular,
it showed a lot of variation in implementations of bank
cards [1] – even cards implementing the same Master-
Card standard – and a known attack was conﬁrmed for
the online banking device and conﬁrmed to be ﬁxed in a
new version [11].
1.3 Overview
We ﬁrst discuss the TLS protocol in more detail in Sec-
tion 2. Next we present our setup for the automated
learning in Section 3. The results of our analysis of nine
1https://github.com/yymax/x509test
2https://www.ssllabs.com/ssltest/
3https://www.thesprawl.org/projects/sslmap/
TLS implementations are subsequently discussed in Sec-
tion 4, after which we conclude in Section 5.
2 The TLS protocol
The TLS protocol was originally known as SSL (Secure
Socket Layer), which was developed at Netscape. SSL
1.0 was never released and version 2.0 contained numer-
ous security ﬂaws [37]. This lead to the development of
SSL 3.0, on which all later versions are based. After SSL
3.0, the name was changed to TLS and currently three
versions are published: 1.0, 1.1 and 1.2 [17, 18, 19]. The
speciﬁcations for these versions are published in RFCs
issued by the Internet Engineering Task Force (IETF).
To establish a secure connection, different subproto-
cols are used within TLS:
• The Handshake protocol is used to establish session
keys and parameters and to optionally authenticate
the server and/or client.
• The ChangeCipherSpec protocol – consisting of
only one message – is used to indicate the start of
the use of established session keys.
• To indicate errors or notiﬁcations, the Alert protocol
is used to send the level of the alert (either warning
or fatal) and a one byte description.
In Fig. 1 a normal ﬂow for a TLS session is given. In
the ClientHello message, the client indicates the desired
TLS version, supported cipher suites and optional exten-
sions. A cipher suite is a combination of algorithms used
for the key exchange, encryption, and MAC computa-
tion. During the key exchange a premaster secret is es-
tablished. This premaster secret is used in combination
with random values from both the client and server to
derive the master secret. This master secret is then used
to derive the actual keys that are used for encryption and
MAC computation. Different keys are used for messages
from the client to the server and for messages in the op-
posite direction. Optionally, the key exchange can be
followed by client veriﬁcation where the client proves it
knows the private key corresponding to the public key
in the certiﬁcate it presents to the server. After the key
exchange and optional client veriﬁcation, a ChangeCi-
pherSpec message is used to indicate that from that point
on the agreed keys will be used to encrypt all messages
and add a MAC to them. The Finished message is ﬁ-
nally used to conclude the handshake phase. It contains
a keyed hash, computed using the master secret, of all
previously exchanged handshake messages. Since it is
sent after the ChangeCipherSpec message it is the ﬁrst
message that is encrypted and MACed. After the hand-
shake phase, application data can be exchanged over the
established secure channel.
194  24th USENIX Security Symposium 
USENIX Association
2
To add additional functionality, TLS offers the possi-
bility to add extensions to the protocol. One example of
such an extension is the – due to Heartbleed [13] by now
well-known – Heartbeat Extension, which can be used
to keep a connection alive using HeartbeatRequest and
HeartbeatResponse messages [36].
Client
Server
ClientHello
ServerHello;
[Certiﬁcate;]
[ServerKeyExchange;]
[CertiﬁcateRequest;]
ServerHelloDone
ClientKeyExchange;
[Certiﬁcate;]
[CertiﬁcateVerify;]
ChangeCipherSpec;
{Finished}
ChangeCipherSpec;
{Finished}
{ApplicationData}
{ApplicationData}
Figure 1: A regular TLS session. An encrypted message
m is denoted as {m}. If message m is optional, this is
indicated by [m].
As the actual state machine is not known, the equiv-
alence check has to be approximated, with what is ef-
fectively a form of model-based testing. For this we use
an improved version of Chow’s W-method [12]. The W-
method is guaranteed to be correct given an upper bound
for the number of states. For LearnLib we can specify a
depth for the equivalence checking: given a hypothesis
for the state machine, the upper bound for the W-method
is set to the number of found states plus the speciﬁed
depth. The algorithm will only look for counterexample
traces of which the lengths is at most the set upper bound,
and if none can be found the current hypothesis for the
state machine is assumed to be equivalent with the one
implemented. This assumption is correct if the actual
state machine does not have more states than the number
of found states plus the speciﬁed depth. The W-method
is very powerful but comes at a high cost in terms of per-
formance. Therefore we improved the algorithm to take
advantage of a property of the system we learn, namely
that once a connection is closed, all outputs returned af-
terwards will be the same (namely Connection closed).
So when looking for counterexamples, extending a trial
trace that results in the connection being closed is point-
less. The W-method, however, will still look for coun-
terexamples by extending traces which result in a closed
connection. We improved the W-method by adding a
check to see if it makes sense to continue searching for
counterexamples with a particular preﬁx, and for this we
simply check if the connection has not been closed. This
simple modiﬁcation of the W-method greatly reduced the
number of equivalence queries needed, as we will see in
Section 4.
3 State machine learning
3.1 Test harness
To infer the state machines of implementations of the
TLS protocol we used LearnLib [34], which uses a mod-
iﬁed version of Angluin’s L* algorithm [5]. An imple-
mentation that is analysed is referred to as the System
Under Test (SUT) and is considered to be a black box.
LearnLib has to be provided with a list of messages it
can send to the SUT (also known as the input alphabet),
and a command to reset the SUT to its initial state. A test
harness is needed to translate abstract messages from the
input alphabet to concrete messages that can be sent to
the SUT. To be able to implement this test harness we
need to know the messages that are used by the SUT.
By sending sequences of messages and reset commands,
LearnLib tries to come up with hypotheses for the state
machine based on the responses it receives from the SUT.
Such hypotheses are then checked for equivalence with
the actual state machine. If the models are not equivalent,
a counter-example is returned and LearnLib will use this
to redeﬁne its hypothesis.
To use LearnLib, we need to ﬁx an input alphabet
of messages that can be sent to the SUT. This alpha-
bet is an abstraction of the actual messages sent.
In
our analyses we use different input alphabets depend-
ing on whether we test a client or server, and whether
we perform a more limited or more extensive analy-
sis. To test servers we support the following mes-
sages: ClientHello (RSA and DHE), Certiﬁcate (RSA
and empty), ClientKeyExchange, ClientCertiﬁcateVer-
ify, ChangeCipherSpec, Finished, ApplicationData (reg-
ular and empty), HeartbeatRequest and HeartbeatRe-
sponse. To test clients we support the following mes-
sages: ServerHello (RSA and DHE), Certiﬁcate (RSA
and empty), CertiﬁcateRequest, ServerKeyExchange,
ServerHelloDone, ChangeCipherSpec, Finished, Appli-
cationData (regular and empty), HeartbeatRequest and
HeartbeatResponse.
We thus support all regular TLS messages as well as
the messages for the Heartbeat Extension. The test har-
USENIX Association  
24th USENIX Security Symposium  195
3
ness supports both TLS version 1.2 and, in order to test
older implementations, version 1.0. The input alphabet
is not ﬁxed, but can be conﬁgured per analysis as de-
sired. For the output alphabet we use all the regular TLS
messages as well as the messages from the Alert protocol
that can be returned. This is extended with some special
symbols that correspond with exceptions that can occur
in the test harness:
• Empty, this is returned if no data is received from
the SUT before a timeout occurs in the test harness.
• Decryption failed, this is returned if decryption fails
in the test harness after a ChangeChipherSpec mes-
sage was received. This could happen, for example,
if not enough data is received, the padding is incor-
rect after decryption (e.g. because a different key
was used for encryption) or the MAC veriﬁcation
fails.
• Connection closed, this is returned if a socket ex-
ception occurs or the socket is closed.
LearnLib uses these abstract inputs and outputs as la-
bels on the transitions of the state machine. To interact
with an actual TLS server or client we need a test harness
that translates the abstract input messages to actual TLS
packets and the responses back to abstract responses. As
we make use of cryptographic operations in the protocol,
we needed to introduce state in our test harness, for in-