6.57
6.57
6.59
6.55
6.59
6.59
6.57
6.56
6.60
6.58
6.58
6.58
12.23
12.22
12.22
12.18
12.21
12.20
12.22
6.60
6.55
12.19
12.22
12.20
12.23
12.25
12.22
12.23
6.51
Cycle count
6.59
12.22
12.21
12.17
12.24
12.23
12.24
12.25
6.59
6.54
12.22
12.21
12.21
12.22
12.18
12.24
12.20
6.57
6.54
6.56
6.59
6.58
6.59
6.56
6.57
6.57
6.58
6.56
12.25
12.23
12.17
12.24
12.21
12.23
12.23
6.55
6.56
6.56
6.59
6.57
6.57
6.58
6.54
6.58
6.58
Figure 11: Division timing for double precision ﬂoats on Intel i5-4460+FTZ/DAZ
loops over doubles, or tight square root operations over
ﬂoats. Thus, our attack must circumvent the use of the
FTZ and DAZ ﬂags altogether.
Chrome enables the FTZ and DAZ control ﬂags when-
ever a ﬁlter is set to run on the CPU, which disallows
our Firefox or Safari attacks from applying directly to
Chrome. However, we found that the FTZ and DAZ ﬂags
are not set when a ﬁlter is going to execute on the GPU.
This would normally only be useful for a GPU-based at-
tack but we can force the feConvolveMatrix ﬁlter
to abort from GPU acceleration at the last possible mo-
ment and fall back to the CPU implementation by having
a kernel matrix over the maximum supported GPU size
of 36 elements. Chrome does not enable the FTZ and
DAZ ﬂags when it executes this fallback, allowing our
timing attack to use subnormal values.
We force the target  to start on the GPU render-
ing path by applying a CSS transform:rotateY()
to it. This is a well known trick for causing future anima-
tions and ﬁlters to be performed on the GPU, and it works
consistently. Without this, the feConvolveMatrix
GPU implementation would never ﬁre, as it will not
choose the GPU over the CPU on its own. It is only be-
cause of our ability to force CPU fallback with the FTZ
and DAZ ﬂags disabled that allows our CPU Chrome at-
tack to function.
Note that even if FTZ/DAZ are enabled in all cases
there are still scenerios that show timing variation as seen
in ﬁgures 11 and 9. Chrome’s Skia conﬁguration cur-
rently uses single precision ﬂoats, and thus only need
avoid sqrt operations as far as we know. However, any
use of double precision ﬂoats will additionally require
avoidance of division. We did not observe any currently
vulnerable uses of single precision sqrt, or of double pre-
cision ﬂoating point operations in the Skia codebase.
We notiﬁed Google of this attack and a ﬁx is in
progress.
6.2 Frame timing on Chrome
An additional obstacle to our Chrome attack was obtain-
ing accurate frame render times. Unlike on Firefox or
Safari, adding a ﬁlter to a ’s style and then calling
getAnimationFrame is insufﬁcient to be sure that
the time until the callback occurs will accurately repre-
sent the rendering time of the ﬁlter. In fact, the frame
that the ﬁlter is actually rendered on differs by platform
and is not consistent on Linux. We instead run algorithm
1 to get the approximate rendering time of a given frame.
Since we only care about the relative rendering time be-
tween white and black pixels, the possibly extra time in-
cluded doesn’t matter as long as it is moderately consis-
tent. This technique allowed our attack to operate on all
tested platforms without modiﬁcation.
7 Revisiting the effectiveness of Escort
Escort [15] proposes defenses against multiple types of
timing side channels, notably a defense using SIMD vec-
USENIX Association
26th USENIX Security Symposium    75
Result: Duration of SVG ﬁlter rendering
total_duration = 0ms;
long_frame_seen = False;
while true do
/* Wait for next frame
requestAnimationFrame;
if duration > 40ms then
/* Long frame probably
containing the SVG
rendering occurred
long_frame_seen = True;
total_duration += duration;
else
if long_frame_seen then
/* A short frame after a
long frame
return total_duration;
end
end
total_duration += duration;
Operation
Single Precision
Add/Sub
Mul
Div
Sqrt
Double Precision
Add/Sub
Mul
Div
Sqrt
Default libdrag
–
S
S
M
–
S
M
M
–
–
Z
Z
–
–
Z
Z
Figure 12: Timing differences observed for libdrag vs
default operations on an Intel i5-4460. – : no variation, S
: Subnormals are slower, Z : all zero exponent or signiﬁ-
cand values are faster, M : mixture of several effects
*/
*/
*/
end
Algorithm 1: How to measure SVG ﬁlter rendering
times in Chrome
tor operations to protect against the ﬂoating point attack
presented by Andrysco et al in [2].
Single Instruction, Multiple Data (SIMD) instructions
are an extension to the x86_64 ISA designed to improve
the performance of vector operations. These instructions
allow 1-4 independent computations of the same opera-
tion (divide, add, subtract, etc) to be performed at once
using large registers. By placing the ﬁrst set of operands
in the top half of the register, and the second set of
operands in the bottom half, multiple computations can
be easily performed with a single opcode. Intel does not
provide signiﬁcant detail about the execution of these in-
structions and does not provide guarantees about their
performance behavior.
7.1 Escort overview
Escort performs several transforms during compilation
designed to remove timing side channels. First, they
modify ’elementary operations’ (ﬂoating point math op-
erations for the purpose of this paper). Second, they per-
form a number of basic block linearizations, array access
changes, and branch removals to transform the control
ﬂow of the program to constant time and minimize side
effects.
We do not evaluate the efﬁcacy of the higher level con-
trol ﬂow transforms and instead evaluate only the ele-
mentary operations.
Escort’s tool is to construct a set of dummy operands
(the escort) that are computed at the same time as the
Operation
Single Precision
Add/Sub
Mul
Div
Sqrt
Double Precision
Add/Sub
Mul
Div
Sqrt
Default libdrag
S
S
S
S
S
S
S
S
S
–
–
–
S
–
–
–
Figure 13: Timing differences observed for libdrag
vs default operations on an AMD Phenom II X2 550. –
: no variation, S : Subnormals are slower, Z : all zero
exponent or signiﬁcand values are faster, M : mixture of
several effects
secret operands to obscure the running time of the se-
cret operands. Escort places the dummy arguments in
one lane of the SIMD instruction, and the sensitive argu-
ments in another lane. Since the instruction only retires
when the full set of computations are complete, the run-
ning time of the entire operation is hypothesized to be
dependent only on the slowest operation. This is true if
and only if the different lanes are computed in parallel.
To obscure the running time of the sensitive operands,
Escort places two subnormal arguments in the dummy
lane of all modiﬁed operations under the assumption that
this will exercise the slowest path through the hardware.
Escort will replace most ﬂoating point operations it en-
counters. However, if it can prove (using the Z3 SMT
solver [4]) that the operation will never have subnormal
values as operands it declines to replace the operation.
This means that if a function ﬁlters out subnormals be-
76    26th USENIX Security Symposium
USENIX Association
Dividend
0.0
1.0
1e10
1e+200
0.0
1.0
1e10
1e+200
1e-300
1e-42
256
257
1e-320
186.46
186.45
186.51
186.50
186.48
186.44
186.49
186.46
186.49
186.48
186.48
186.49
186.50
186.44
186.51
186.49
186.47
186.49
186.50
195.93
195.92
195.90
195.91
195.92
195.91
195.96
186.43
186.44
195.94
195.90
195.94
195.88
195.94
195.91
195.92
186.48
Divisor
1e-300
1e-42
256
257
1e-320
Cycle count
186.42
195.93
195.92
195.89
195.93
195.87
195.87
195.92
186.49
186.49
195.86
195.87
195.91
195.92
195.89
195.89
195.96
186.49
186.50
186.48
186.47
186.46
186.53
186.51
186.45
186.49
186.50
186.48
195.87
195.86
195.90
195.95
195.93
195.91
195.98
186.52
186.51
186.48
186.46
186.50
186.44
186.47
186.44
186.45
186.46
Figure 14: Division timing for double precision ﬂoats on Intel i5-4460+Escort
Dividend
0.0
1.0
1.0e-10
0.0
1.0
1.0e-10
1.0e-323
1.0e-43
1.0e100
256
257
10.09
10.08
10.08
10.08
10.08
10.08
10.08
10.09
10.08
10.08
10.08
10.08
10.08
10.08
10.08
10.08
10.08
10.55
10.55
10.08
10.55
10.55
10.55
10.55
Divisor
1.0e-43
1.0e-323
Runtime (Seconds)
10.08
10.08
10.55
10.08
10.08
10.55
10.08
10.08
10.55
10.08
10.55
10.08
10.08
10.57
10.57
10.08
1.0e100
256
257
10.08
10.55
10.55
10.08
10.55
10.55
10.55
10.55
10.08
10.08
10.08
10.08
10.08
10.08
10.08
10.08
10.10
10.55
10.55
10.08
10.55
10.55
10.57
10.55
Figure 15: Division timing for double precision ﬂoats on Intel i5-4460 macro-test
fore performing computation, the computation will be
done with standard scalar ﬂoating point operations and
not vector operations. This results in signiﬁcant perfor-
mance gains when applicable, as the scalar operations
can be two orders of magnitude faster than the subnormal
vector operations. The replacement operations consist of
hand-coded assembly contained in a library; libdrag.
However, operations that do not receive subnormals
can still exhibit timing differences. As seen in ﬁgure 7
and summarized in ﬁgure 9 timing differences arise on
value types that can commonly occur (0, powers of 2,
etc). While signiﬁcantly less obvious than the impact of
subnormals, these still constitute a potential timing side
channel. libdrag can easily ﬁx this, at serious perfor-
mance cost, by enabling the ﬂoating point replacements
for all ﬂoating point operations with no exceptions.
To determine if Escort closes ﬂoating point timing side
channel when enabled, we measured the timing behavior
of Escort’s libdrag ﬂoating point operations, as well
as the end-to-end runtime of toy programs compiled un-
der Escort.
7.2 libdrag micro-benchmarks
For the micro-benchmarking of the libdrag functions
we use a simple tool we developed for running timing
tests of library functions based on Intel’s recommenda-
tions for instruction timing. This is the same tool we
used to produce measurements for section 3.
We benchmarked each of libdrag’s functions
against a range of valid numbers on several different
CPUs. We do not present results for Not-a-Number
(NaN) or inﬁnities.
7.2.1 Results on Intel i5-4460
Our results for the Intel i5-4460 CPU roughly correspond