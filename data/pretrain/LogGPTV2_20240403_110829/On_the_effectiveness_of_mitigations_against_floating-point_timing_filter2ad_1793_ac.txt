### Division Timing for Double Precision Floats on Intel i5-4460+FTZ/DAZ

| 6.57 | 6.57 | 6.59 | 6.55 | 6.59 | 6.59 | 6.57 | 6.56 | 6.60 | 6.58 | 6.58 | 6.58 |
| 12.23 | 12.22 | 12.22 | 12.18 | 12.21 | 12.20 | 12.22 | 6.60 | 6.55 | 12.19 | 12.22 | 12.20 |
| 12.23 | 12.25 | 12.22 | 12.23 | 6.51 | Cycle count | 6.59 | 12.22 | 12.21 | 12.17 | 12.24 | 12.23 | 12.24 | 12.25 |
| 6.59 | 6.54 | 12.22 | 12.21 | 12.21 | 12.22 | 12.18 | 12.24 | 12.20 | 6.57 | 6.54 | 6.56 | 6.59 | 6.58 | 6.59 | 6.56 | 6.57 | 6.57 | 6.58 | 6.56 |
| 12.25 | 12.23 | 12.17 | 12.24 | 12.21 | 12.23 | 12.23 | 6.55 | 6.56 | 6.56 | 6.59 | 6.57 | 6.57 | 6.58 | 6.54 | 6.58 | 6.58 |

**Figure 11: Division timing for double precision floats on Intel i5-4460+FTZ/DAZ**

### Context and Attack Overview

The division and square root operations over floating-point numbers, particularly in tight loops, can be exploited to perform timing attacks. These operations are sensitive to the use of Flush-to-Zero (FTZ) and Denormals-Are-Zero (DAZ) flags. Our attack aims to circumvent these flags.

### Browser-Specific Behavior

#### Chrome
Chrome enables the FTZ and DAZ control flags when a filter is set to run on the CPU. This prevents our Firefox or Safari attacks from being directly applicable to Chrome. However, we discovered that the FTZ and DAZ flags are not set when a filter is executed on the GPU. By forcing the `feConvolveMatrix` filter to abort GPU acceleration and fall back to the CPU, we can exploit this behavior. We achieve this by using a kernel matrix larger than the maximum supported GPU size of 36 elements. When the fallback occurs, Chrome does not enable the FTZ and DAZ flags, allowing our timing attack to use subnormal values.

To ensure the target starts on the GPU rendering path, we apply a CSS `transform: rotateY()` to it. This is a well-known technique to force future animations and filters to run on the GPU. Without this, the `feConvolveMatrix` GPU implementation would not fire, as it would not choose the GPU over the CPU on its own. Our ability to force CPU fallback with the FTZ and DAZ flags disabled is crucial for our CPU-based Chrome attack.

#### Frame Timing on Chrome
Another challenge in our Chrome attack was obtaining accurate frame render times. Unlike in Firefox or Safari, simply adding a filter to an element's style and calling `requestAnimationFrame` is insufficient to ensure the callback time accurately represents the rendering time of the filter. The frame that the filter is rendered on varies by platform and is inconsistent on Linux. We instead use Algorithm 1 to get the approximate rendering time of a given frame. Since we only care about the relative rendering time between white and black pixels, any extra time included is acceptable as long as it is moderately consistent. This technique allows our attack to operate on all tested platforms without modification.

**Algorithm 1: Measuring SVG Filter Rendering Times in Chrome**
```python
total_duration = 0ms;
long_frame_seen = False;
while true do
    /* Wait for next frame */
    requestAnimationFrame;
    if duration > 40ms then
        /* Long frame probably containing the SVG rendering occurred */
        long_frame_seen = True;
        total_duration += duration;
    else
        if long_frame_seen then
            /* A short frame after a long frame */
            return total_duration;
        end
    end
    total_duration += duration;
end
```

### Revisiting Escort's Effectiveness

Escort [15] proposes defenses against multiple types of timing side channels, including a defense using SIMD vector operations to protect against the floating-point attack presented by Andrysco et al. [2].

**SIMD Instructions**
Single Instruction, Multiple Data (SIMD) instructions are an extension to the x86_64 ISA designed to improve the performance of vector operations. These instructions allow 1-4 independent computations of the same operation (divide, add, subtract, etc.) to be performed at once using large registers. Intel provides limited details about the execution of these instructions and does not guarantee their performance behavior.

**Escort Overview**
Escort performs several transformations during compilation to remove timing side channels. First, it modifies elementary operations (floating-point math operations). Second, it linearizes basic blocks, changes array accesses, and removes branches to transform the control flow to constant time and minimize side effects.

We evaluate only the elementary operations. Escort constructs a set of dummy operands (the escort) that are computed simultaneously with the secret operands to obscure the running time. The dummy arguments are placed in one lane of the SIMD instruction, and the sensitive arguments in another. The running time of the entire operation is hypothesized to depend only on the slowest operation, assuming the different lanes are computed in parallel.

**libdrag Micro-Benchmarks**
For micro-benchmarking, we used a tool we developed based on Intel's recommendations for instruction timing. We benchmarked each of libdrag's functions against a range of valid numbers on several different CPUs. Results for Not-a-Number (NaN) or infinities are not presented.

**Results on Intel i5-4460**
Our results for the Intel i5-4460 CPU show that while Escort's libdrag significantly reduces timing variations, some differences still exist. This indicates that further optimizations may be necessary to fully close the floating-point timing side channel.

**Figure 12: Timing Differences Observed for libdrag vs. Default Operations on an Intel i5-4460**
- **S**: Subnormals are slower
- **Z**: All zero exponent or significand values are faster
- **M**: Mixture of several effects
- **â€“**: No variation

**Figure 13: Timing Differences Observed for libdrag vs. Default Operations on an AMD Phenom II X2 550**

**Figure 14: Division Timing for Double Precision Floats on Intel i5-4460+Escort**

**Figure 15: Division Timing for Double Precision Floats on Intel i5-4460 Macro-Test**

### Conclusion
While Escort provides a robust defense against many timing side channels, some variations still exist, particularly with specific value types. Further research and optimization are needed to fully mitigate these vulnerabilities.