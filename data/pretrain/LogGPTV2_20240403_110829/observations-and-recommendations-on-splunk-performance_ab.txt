|---|---|---|---|---|---||---|---|---|---|---|---|
| Find buckets  |check tsidx for  |For each bucket  |st rename,  |Filter events to  |Write temporary  |
| Find buckets  |check tsidx for  |read journal.gz |st rename,  |match the search  |Write temporary  |
| Find buckets  |events that  |read journal.gz |extract, report,  |match the search  |results to  |
| based on search  |events that  |at offsets  |extract, report,  |string (+  |results to  || based on search  |match LISPY  |at offsets  |kv, alias, eval,  |string (+  |dispatch  |
| timerange |match LISPY  |supplied by  |kv, alias, eval,  |eventtyping |dispatch  |
| timerange |and find rawdata |supplied by  |lookup,  |eventtyping |directory |
| timerange |and find rawdata |previous step |lookup,  |tagging) |directory |
| timerange |offset |previous step |subsecond |tagging) |Return progress  || timerange |IO |previous step |subsecond |tagging) |Return progress  |
to SH splunkd
22
Search pipeline (High Level)
Some 
preparatory 
steps here
Repeat until search completes
| Find buckets  | For each bucket  | For each bucket  | Process events:  | Filter events to  | Write temporary  |
|---|---|---|---|---|---|
| Find buckets  |check tsidx for  |For each bucket  |st rename,  |Filter events to  |Write temporary  || Find buckets  |check tsidx for  |read journal.gz |st rename,  |match the search  |Write temporary  |
| Find buckets  |events that  |read journal.gz |extract, report,  |match the search  |results to  |
| based on search  |events that  |at offsets  |extract, report,  |string (+  |results to  |
| based on search  |match LISPY  |at offsets  |kv, alias, eval,  |string (+  |dispatch  || timerange |match LISPY  |supplied by  |kv, alias, eval,  |eventtyping |dispatch  |
| timerange |and find rawdata |supplied by  |lookup,  |eventtyping |directory |
| timerange |and find rawdata |previous step |lookup,  |tagging) |directory |
| timerange |offset |previous step |subsecond |tagging) |directory |
Return progress 	to SH splunkd
23
Search pipeline boundedness
Some 
preparatorySome 
preparatory 
steps here
Repeat until search completes
| Find buckets  | For each bucket  | For each bucket  | Process events: st rename, 
extract, report, kv, alias, eval, 
lookup, 
subsecond | Filter events to 
match the search string (+ 
eventtyping 
tagging) | Write temporary  |
|---|---|---|---|---|---||---|---|---|---|---|---|
| Find buckets  |check tsidx for  |For each bucket  |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |Write temporary  |
| Find buckets  |check tsidx for  |read journal.gz |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |Write temporary  || Find buckets  |events that  |read journal.gz |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |results to  |
| based on search  |events that  |at offsets  |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |results to  || based on search  |match LISPY  |at offsets  |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |dispatch  |
| timerange |match LISPY  |supplied by  |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |dispatch  || timerange |and find rawdata |supplied by  |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |directory |
| timerange |and find rawdata |previous step |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |directory || timerange |offset |previous step |Process events: st rename,  extract, report, kv, alias, eval,  lookup,  subsecond |Filter events to  match the search string (+  eventtyping  tagging) |directory |
| timerange |IO |previous step |CPU + Memory |CPU + Memory |Return progress  |
to SH splunkd
24
Search Types
Dense
–	Characterized predominantly by returning many events per bucketindex=web | stats count by clientip
Sparse
–	Characterized predominantly by returning some events per bucket
index=web some_term | stats count by clientip
Rare
–	Characterized predominantly by returning only a few events per index
index=web url=onedomain* | stats count by clientip
25
	Okay, let’s test some searches Use our already indexed data 
–	It contains many unique terms with predictable term densitySearch under several term densities and concurrencies 
–
–
– Term density: 1/100, 1/1M, 1/100M Search Concurrency: 4 – 60 
Searches: 
ê Rare: over all 1TB dataset
ê Dense: over a preselected time range 
Repeat all of the above while under an indexing workload
Measure
26
Dense Searches Hitting 100% 
CPU at 
CPU Utilization (%)
IO Wait (%) 
27
	Indexing with Dense Searches CPU Utilization (%)Hitting 100% earlier
Indexing Throughput (KB/s)
Indexing Only
Search Duration (s)
28
	Dense Searches Summary Dense workloads are CPU bound 
Dense workload completion times and indexing throughput both negatively 
affected while running simultaneously 
Faster disk wont necessarily help as much here
–	Majority of time in dense searches is spent in CPU decompressing rawdata + other SPL 
processingprocessing
Faster and more CPUs would have improved overall performance
29
	Rare Searches CPU Utilization (%)
Reads/s (from sar)
IO Wait (%)
30
	Indexing with Rare Searches CPU Utilization (%)
Reads/s (from sar)
IO Wait (%)
31
Indexing & Searching Rare
Indexing Throughput (KB/s) 
Search Duration (s)
Search Duration (s)
32
Rare Searches Summary
Rare workloads (investigative, ad-hoc) are IO boundRare workload completion times and indexing throughput both negatively affected while running simultaneously 
1/100M searches have a lesser impact on IO than 1/1M. 
When indexing is on, in 1/1M case search duration increases substantially more vs. 1/100M. Search and indexing are both contenting for IO. 
In case of 1/100M, bloomfilters help improve search performanceBloomfilters are special data structures that indicate with 100% certainty that a term does not –
exist in a bucket (indicating to the search process to skip that bucket). 
Faster disks would have definitely helped here 
More CPUs would not have improved performance by much
33
Is my search CPU or IO bound?
Guideline in absence of full instrumentation 
command.search.rawdata ~ CPU Boundcommand.search.rawdata ~ CPU Bound
–	Others: .kv, .typer, .calcfields, 
command.search.index ~ IO Bound
34
Metric Store 
Types & Tests
	Metric Store Performance Query Response Times Metrics vs Events
360M events, 10 hosts, 87 distinct metrics
Metric Store Performance Ingestion
HTTP Endpoint (AKA HTTP Event Collector, HEC)
–
– ~55,000 EPS / indexer sans search load Scales nearly linearlyUDP
| 
 |  |  | – | Varies |  |  |  |
|---|---|---|---|---|---|---|---|
|   | | |– |33% packet loss at 10,000 EPS | | | |
| • Indexing 	Top Takeaways
– Distribute – Splunk scales horizontally
– Tune event breaking and timestamp extraction – Faster CPUs will help with indexing performance
• Searching
	– Distribute – Splunk scales horizontally 
	– Dense Search Workloads– Dense Search Workloads 
	ê CPU Bound, better with indexing than rare  | • Indexing 	Top Takeaways
– Distribute – Splunk scales horizontally
– Tune event breaking and timestamp extraction – Faster CPUs will help with indexing performance
• Searching
	– Distribute – Splunk scales horizontally 
	– Dense Search Workloads 
	ê CPU Bound, better with indexing than rare  | CPU 
	Term 
Density
IO |Term 
Density
IO |
|---|---|---|
| 	workloads  	ê Faster and more CPUs will help – Rare Search Workloads  	ê IO Bound, not that great with indexing  |Use case  |CPU  	Term  Density IO |
| 	workloads  	ê Faster and more CPUs will help – Rare Search Workloads  	ê IO Bound, not that great with indexing  |Use case  |	What Helps? |
| ê Bloomfilters help significantly ê Faster disks will help |Trending, reporting over long term etc. |	What Helps? || ê Bloomfilters help significantly ê Faster disks will help |Trending, reporting over long term etc. |	More distribution Faster, more CPUs |
| • Performance 	– Avoid generality, optimize for expected case and add 	hardware whenever you can | |	More distribution Faster, more CPUs |
| • Performance 	– Avoid generality, optimize for expected case and add 	hardware whenever you can |Ad-hoc analysis, investigative type  |More distribution  Faster Disks, SSDs |38
Testing Disclaimer Reminder
1. 	Testing conducted on arbitrary 
datasets
2.	“closed course” (lab) environment
3. 	Not to be interpreted out of context
39
Q&A 
Simeon Yep  |  AVP GSA
Brian Wooden  |  Partner Integrations
© 2017 SPLUNK INC.
Thank You
Don't forget to rate this session in the 
.conf2017 mobile app