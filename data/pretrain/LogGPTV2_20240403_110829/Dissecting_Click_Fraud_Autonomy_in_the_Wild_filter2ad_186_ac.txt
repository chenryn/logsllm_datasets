bodies into subgraphs of the DDG. 3) If it is a variable that is
usually formed by different types of data, to figure out the variableâ€™s
meaning, ClickScanner needs to find the variableâ€™s assignment
process. Therefore, ClickScanner finds its predecessors from the
definition site of the variable based on the ICFG and UD chains and
adds it to the DDG. 4) If it is a parameter of the method in which the
dispatchTouchEvent is called, ClickScanner first gets the caller
of the method based on ICFG and then finds the parameter values
of the method.
As shown in Fig. 6, ClickScanner successfully finds exactly
where the humanoid attack occurs in codes. The process of gen-
erating the DDG of the trigger condition is similar to the above
description, so we omit it due to space limitations.
4.2 Feature Extraction Module
Once a DDG is built, ClickScanner can find all necessary features
in it for verifying whether the humanoid attack takes place in the
given app. Android systems typically have 7 different constructors
for the MotionEvent.obtain and all of them have the following
common parameters: eventTime, actionType, axisValue and metaS-
tate, among which we choose the axis values (i.e., touch position
(AXIS_X, AXIS_Y)) for further study. Because the benign app re-
ceives the MotionEvent object from the system, sometimes it needs
to record the coordinates of the click, and then dispatches it. How-
ever, for fraudulent apps (i.e., Fig. 4 at lines 5 and 6), they first
obtain the height and width of the ad view and construct the fake
clickâ€™s coordinates that follow a random distribution, which mimics
the benign app behaviors. As a result, even if the traditional click
fraud detection approaches can obtain click traffic, they cannot
distinguish between a humanoid attack and a normal click since
properties such as the coordinates are similar.
This shows that instead of analyzing the pattern of generated
coordinates, the humanoid attack can be identified by checking
the process of coordinate generating. For instance, the â€œillegal oper-
ationsâ€ including obtaining height/width and exploiting Random()
â€¦$r3 = new Random;invoke $r3.()>();$i2 = $r1.();$i2 = $r3.($i2);$f1 = (float) $i2;â€¦r3i2i2f1â€¦$r3 = new Random;invoke $r3.()>();$i2 = $r1.();$i2 = $r3.($i2);$f0 = (float) $i2;â€¦r3i2i2f0â€¦$r4 = (..., $f0, $f1, ...);$r5 = (..., $f0, $f1, ...);...x coordinatey coordinateâ€¦$r0 := @adview;$r1 = $r0.;â€¦r0r1Session 1D: Authentication and Click Fraud CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea276method in Fig. 4 may be used to detect its fraudulent behaviors.
In a real-world scenario, we further characterize the axis into five
features:
(1) The number of APIs for getting the actual click coordi-
nates generated by users (AxisAPI). As shown in Fig. 4, the
fraudulent app involves no APIs to get the coordinates of real usersâ€™
click (e.g., getX() and getY()). Instead, it constructs the coordinates
by itself. Intuitively, the existence of APIs, which are used to get
the actual click coordinates generated by users, can be indicative of
whether the app is a fraudulent application. When an app contains
a MotionEvent whose coordinate parameters do not involve the sys-
tem APIs above, we take it as a potentially fraudulent application.
As shown in Table 1, the F-score of AxisAPI is 0.81 when identifying
humanoid attack instances over our ground truth dataset (seed
apps).
(2) The number of APIs for getting the size of ad view (View-
SizeAPI). Many fraudulent apps obtain the size of the ad view in
order to place the coordinates of the fake click inside the ad view.
Although some benign apps will also get the view size, the pro-
portion is much lower than that in fraudulent apps based on the
observation of benign samples in our dataset.
(3) The number of the constants (Const). Since some fraudulent
apps try to click on the area around a fixed point in the ad view,
such as the download and install button, they will obtain the size
of a view and calculate it with a constant to get a specific point
coordinate. The F-score for this feature is shown in Table 1.
(4) The number of API for getting random numbers (Ran-
dAxis). To better mimic human clicks, the fraudulent apps often use
APIs that generate random numbers (e.g., random.nextGaussian)
when constructing click coordinates or the time distribution of
clicks, as shown in the motivating example. In doing so, attackers
can disguise the traffic generated by fake clicks as traffic generated
by real people and make the fake clicks unpredictable to evade the
dynamic analysis. Therefore, we use this as an indicator to identify
fraudulent apps. The F-score for this feature, as measured on our
ground-truth set, is illustrated in Table 1.
(5) Size of the DDG (DDGSize). Our manually labeled dataset
shows that fraudulent apps tend to process the data several times
before passing it to the MotionEvent.obtain as its coordinate
parameters, while benign apps tend to directly take the return
value of the methods like getX as the coordinate parameters. The
larger size of the DDG indicates that the data have been processed
more times before being passed to the MotionEvent.obtain. The
F-score for this feature is shown in Table 1.
Meanwhile, the attackers also tend to change their behaviors to
evade detection, which can be detected by analyzing the trigger
conditions of the click events. The unique software and hardware
resources on mobile devices enable fraudulent apps to cover their
behaviors with a wider spectrum of triggers, that is, conditions
under which the hidden operations will be performed [33]. For
example, in Fig. 4 at line 4, the fraudulent app tries to fool detectors
by randomizing the trigger condition of the click event, which is
like a humanâ€™s click timing pattern and difficult to be triggered by
dynamic analysis. Therefore, we also focus on the trigger condition
of click events and characterize it into two features:
Table 1: F-score of features
AxisAPI ViewSizeAPI
0.81
0.79
Const
0.83
RandAxis
0.62
DDGSize RandCondition SysAPI
0.82
0.54
0.61
1 F-score is calculated based on classification with each single feature.
(6) Random Numbers in Condition Expression (RandCondi-
tion). Many fraudulent apps tend to randomize the trigger con-
ditions and trigger frequency of humanoid attacks to simulate
legitimate clicks, which makes the fake clicks indistinguishable and
undetectable. Additionally, dynamic analysis requires much time
to interact with these apps so it is difficult to cover all paths of
the humanoid attack. Hence, we regard the invocations of func-
tions in the process formation of the trigger conditions, which can
generate random numbers as a feature to identify the humanoid
attack.
(7) System Call in Condition Expression (SysAPI). Some hid-
den sensitive instances with a similar purpose to the humanoid
attack have been discussed [15, 33]. They are subject to some sys-
tem properties or environment parameters (i.e., OS or hardware
traces of a mobile device). They can only be exposed to an app
through system interfaces. Hence, we can infer that the condition
of the humanoid attack is also expected to involve, directly or
indirectly, one or more API calls for interacting with the OS, and
we regard them as another feature. The F-score for this feature is
0.61 as illustrated in Table 1.
Although all the above features can contribute to the detection of
humanoid attacks to a certain degree, certain kinds of humanoid
attacks may involve several features and a single feature may
cause high false positives and negatives. Therefore, none of those
features can work alone. [51] Hence, our key idea is to use some of
these features collectively. We finally combine all 7 features into the
same feature space according to our experiment result, which is il-
lustrated in Section 5.1. Furthermore, we apply normalization to the
features before feature vectors formalization because the compo-
nents of the features are different. To determine the weight of each
feature, the entropy weight method is deployed by ClickScanner.
4.3 Fraud Decision Module
Existing click fraud detection models either need to specify many
rules for classification [8, 14, 28, 32], which leads to high false
negatives due to the incomplete and statistically unrepresentative
rules, or require a large number of malicious samples as the training
set [11], which is unrealistic due to the lack of labeled datasets. More-
over, since these existing approaches rely heavily on the knowledge
of certain rules and training set labels, they may fail to handle sub-
sequent variant click fraud. To overcome these limitations, we build
an effective classifier based on Variational AutoEncoders (VAEs)
with limited knowledge about fraudulent examples. This can reduce
the researchersâ€™ dependence on fraudulent data sets and is more
robust to variants of such newly discovered attacks.
In a nutshell, a VAE is an autoencoder whose encoding distri-
bution is regularized during training in order to ensure that its
latent space has good properties so that it can be used to generate
Session 1D: Authentication and Click Fraud CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea277new data that is similar to the inputs. We use benign examples to
train our classifier and determine whether an input is benign or not
according to the reconstruction error between the input and output.
Specifically, the encoder is a neural network. Its input is ğ‘¥, which is
the feature vectors generated by the ClickScanner. The encoderâ€™s
output is a hidden representation ğ‘§, which is the aforementioned
latent space. The encoder will perform dimensionality reduction
on the input ğ‘¥ because the encoder must learn an efficient compres-
sion of the data into this lower-dimensional space. The decoder is
another neural network. Its input is the representation ğ‘§, and its
outputs are the parameters to the probability distribution of the
data with weights and biases ğœ™. Some information may be lost due
to the dimensionality reduction of the encoder, and some new data
are generated due to the random sampling of the decoder. We can
use the reconstruction error to measure the difference between the
input and output.
In the training phase of our classifier, it is trained with benign
examplesâ€™ feature vectors in advance so that its encoder will be able
to learn the representations of benign examples. To do this, we ran-
domly selected 10,000 benign apps from [1] for training. We train
the VAE with feature vectors of those APKs that are not marked by
all the engines from VirusTotal [46], a website that aggregates many
antivirus products and online scan engines to check for viruses.
Although, as mentioned in [52], the detection results of VirusTotal
are not always reliable, because we use many benign samples for
training, a relatively small number of fraudulent samples that are
not detected by VirusTotal will not affect the distribution of the la-
tent space. Once the classifier has been well trained, its encoder will
learn benign examplesâ€™ representations in the latent space. After
training, we feed a tested appâ€™s feature vector, which is extracted
from the newly formed DDG in the Extractor, to the VAE and out-
put the reconstructed feature vector containing the information of
the latent space in the training phase. Our classifier will consider its
input to be fraudulent only when its reconstruction error exceeds a
certain threshold ğ‘¡. It is similar to building a borderline that encom-
passes all benign examples so that we only need to check whether
an input is in the borderline by computing the reconstruction error.
To the best of our knowledge, our model is the first Android
humanoid attack detector with limited knowledge about fraudu-
lent examples. Due to the lack of malicious examples in reality, this
makes ClickScanner practical to deploy.
5 MEASUREMENTS
As mentioned in Section 3.1, due to the absence of existing bench-
marks in this research area, we manually label 100 apps containing
50 fraudulent examples and 50 benign examples as our seed apps for
fine-tuning and accuracy tests. Then we utilize ClickScanner to
conduct the first large-scale measurement of the humanoid attack
in the current app market based on 120,000 apps (10,000 top-rated
apps from Google Play, 10,000 top-rated apps from Huawei App-
Gallery, and 100,000 randomly selected apps from Google Play),
and elaborate on several important findings. All experiments are
performed on a Windows 10 Desktop, equipped with 8 CPU Cores
at 3.6GHz and 32 GB of RAM.
Table 2: Performance of the classifier
Seed Apps
Precision
48/50 = 96% 48/50=96%
Recall
F-score
0.960
5.1 Evaluation of ClickScanner
Fine-tuning of ClickScanner. Before utilizing ClickScan-
5.1.1
ner to conduct large-scale analysis, it is necessary to fine-tune
the ClickScannerâ€™s parameters on seed apps to achieve the best
performance. As mentioned in Section 4.2, there are seven dif-
ferent features for ClickScanner. To determine the best feature
combinations, we traverse all combinations from 2 to 7 features
and show their best performances with the ROC (Receiver Oper-
ating Characteristic) curves in Fig. 7. It is observed that the per-
formance is improved by adding new features. When there are
5 features selected (ğ´ğ‘¥ğ‘–ğ‘ ğ´ğ‘ƒğ¼, ğ‘‰ ğ‘–ğ‘’ğ‘¤ğ‘†ğ‘–ğ‘§ğ‘’ğ´ğ‘ƒğ¼, ğ‘…ğ‘ğ‘›ğ‘‘ğ´ğ‘¥ğ‘–ğ‘ , ğ·ğ·ğºğ‘†ğ‘–ğ‘§ğ‘’,
ğ‘…ğ‘ğ‘›ğ‘‘ğ¶ğ‘œğ‘›ğ‘‘ğ‘–ğ‘¡ğ‘–ğ‘œğ‘›), adding more features only leads to a slight im-
provement in accuracy, which demonstrates that our feature vector
can adequately describe the app behaviors and help classifiers to
identify fraudulent apps. We also evaluate ClickScanner under
different thresholds ğ‘¡ for threshold selection. It is observed when ğ‘¡
is set to 2.04, ClickScanner achieves the best performance. In the
following measurement study, to achieve the best accuracy, ğ‘¡ is set
to 2.04 and all 7 features are selected by ClickScanner.
5.1.2 Effectiveness of ClickScanner. Table 2 shows when choos-
ing the above parameters, 48 apps out of 50 fraud apps in the seed
apps are successfully recognized by ClickScanner. ClickScanner
achieves the F-score of 0.960, showing its effectiveness in detecting
humanoid attacks. There are 2 false positive and 2 false nega-
tive cases and we discuss the root causes in Section 7. Note that
since seed apps are independently extracted from manual check
(see Section 3.1), ClickScanner achieves high average values of
precision and F1-score with limited knowledge about malicious
examples, which implies its effectiveness. The effectiveness is also
substantiated with the high precision of detection in the wild (see
Section 5.2.2).
5.1.3 Comparison with the State-of-the-Art Ad Fraud Detection Tool.
Currently, the most up-to-date fraud detection tool is FraudDetec-
tive implemented by Kim et al. [20], which computes a full stack
trace from an observed ad fraud activity to a user event by connect-
ing fragmented multiple stack traces. It is an effective tool which
could detect three types of ad fraud. However, like other tools that
use dynamic analysis, it incurs a large time overhead to execute
apps and interact with them. Additionally, since some fraudulent
apps will randomly trigger the humanoid attack, FraudDetective
may not be able to cover all the program paths, and thus it is difficult
for FraudDetective to trigger all humanoid attacks discovered in
our study.
Since FraudDetective and their datasets are not publicly avail-
able, we make our best effort to craft the datasets of ClickScanner
as similar as possible to the ones used by FraudDetective, and we
acknowledge that data duplication may exist between ClickScan-
ner and FraudDetective. The two datasets were obtained around
the same time with a similar data collection methodology. In our
basic dataset, we collected 10,000 top-rated apps in total from
Session 1D: Authentication and Click Fraud CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea278Figure 7: The ROC curve for different combination of fea-
tures.
each category from Google Play updated in July 2020, and we also
conducted a longitudinal study, collecting fraudulent apps with
different versions published from August 2017 to December 2020.
The researchers of FraudDetective collected the top 10,024 apps
from each of the Google Play categories from April 2019 to Sep-
tember 2020 and randomly sampled additional 38,148 apps from
APK mirror sites. We believe that these two datasets are likely to
have overlapped apps. However, FraudDetective may fail to trig-
ger humanoid attacks discovered in this paper since it is based
on dynamic analysis alone. In their evaluation part, FraudDetec-
tive did not detect any app that generates a forged click among
the 48,172 apps crawled from the Google Play Store. By contrast,
ClickScanner successfully identified 157 fraudulent apps among
20,000 apps in the basic dataset as shown in Section 5.2.1. In
summary, ClickScanner outperforms existing detection tools in
the aspect of detecting humanoid attacks, and we leave the com-
parison on the same large-scale dataset for future work.
5.2 Detecting Humanoid Attacks in App
Markets