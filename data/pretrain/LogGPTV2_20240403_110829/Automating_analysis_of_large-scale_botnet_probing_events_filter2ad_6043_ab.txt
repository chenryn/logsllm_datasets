ferentiation based on payload (when available). To do so, we imple-
mented payload summary scripts for 20 commonly seen protocols,
based on the Bro system’s network analysis capabilities [22].
Event Extraction: Figure 3 shows source arrival counts for VNC
(TCP port 5900) for the year 2006 on our sensor, where each point
represents the number of sources within a six-hour interval. Large
spikes in such plots generally correspond to scanning from worms
or apparent botnets, or miscon(cid:2)gurations. We classify such spikes
as events, as follows. We de(cid:2)ne the noise strength N as the per-
interval count of unique sources seen in the absence of events. Sup-
pose the time interval length is I. We calculate N as the median
of unique source counts of K continuous time intervals before the
event. We de(cid:2)ne signal strength S = X (cid:0) N as the peak unique
source count arrival X minus the noise strength N, and de(cid:2)ne the
signal-to-noise ratio as SNR= S
In our evaluation we use I = 6 hours and K = 120. The ag-
gregated time window I (cid:2) K is about 30 days. We only examine
events with SNR(cid:21) 50. We automatically extract potential events as
follows: for any given time interval, we calculate the median of the
previous normal K intervals and the SNR. For those spikes exceed-
ing our SNR threshold, we extend the time range to both sides until
S (cid:20) !N where ! is a tunable parameter controlling the amount of
the signal tail to include in the event. (We use ! = 5, though we
(cid:2)nd ranging it over 3 : : : 8 does not signi(cid:2)cantly alter the results.)
For multiple events within one time series, we extract the events
iteratively, starting with the event with largest SNR.
One problem we have to consider is that some events have com-
plex session structures involving multiple protocols. After traf(cid:2)c
classi(cid:2)cation by protocol information, a single event can be sepa-
rated to multiple events. Therefore, after event classi(cid:2)cation, we
need to merge them. We detect such cases by checking the con-
nection correlation. If two connections are in one session, they will
be both from host A to host B and the protocols of the two con-
nections are (cid:2)xed. For example, suppose the (cid:2)rst connection is
HTTP and the second one is WINRPC. If we (cid:2)nd such events to
be highly correlated, i.e., for most connections in the HTTP event,
each HTTP connection is followed by a WINRPC connection from
the WINRPC event for the same source and destination pair, we
merge them as one event.
Event Classi(cid:2)cation and Separation: We separate miscon(cid:2)gura-
tions from worms or botnets based on the observation that botnet
scans and worms should contact a signi(cid:2)cant range of the IP ad-
dresses, whereas miscon(cid:2)gurations exhibit a few hot-spot targets.
We found that most miscon(cid:2)guration events are due to P2P traf-
N = X(cid:0)N
N = X
N (cid:0) 1.
(cid:6) (cid:3)(cid:14)
(cid:16) (cid:2)(cid:5)(cid:2)(cid:6) (cid:2)(cid:5)(cid:13)
(cid:17) (cid:3)(cid:18)
(cid:8) (cid:5)(cid:9)
(cid:17) (cid:3)(cid:18)
(cid:6) (cid:3)(cid:14)
(cid:1)(cid:2)(cid:6) (cid:3)(cid:12)
(cid:17) (cid:3)(cid:18)
(cid:16) (cid:2)(cid:5)(cid:2)(cid:6) (cid:2)(cid:5)(cid:13)
(cid:27) (cid:3)(cid:16) (cid:2)(cid:5)(cid:2)(cid:6) (cid:2)(cid:5)(cid:13)
(cid:8) (cid:5)(cid:9)
(cid:17) (cid:3)(cid:18)
(cid:8) (cid:5)(cid:9)
(cid:10)(cid:11) (cid:3)(cid:4)(cid:2)(cid:5)(cid:2)
(cid:8) (cid:5)(cid:9)
(cid:21) (cid:2)(cid:7) (cid:4)(cid:3)(cid:22)
(cid:8) (cid:5)(cid:9)
(cid:8) (cid:5)(cid:6)
(cid:21) (cid:2)(cid:7) (cid:4)(cid:3)(cid:22)
(cid:20) (cid:5)(cid:13)
(cid:23) (cid:5)(cid:9)
(cid:20) (cid:5)(cid:13)
(cid:1)(cid:2)(cid:5)(cid:19)(cid:13) (cid:5)(cid:9)
(cid:8) (cid:5)(cid:6)
(cid:1)(cid:2)(cid:5)(cid:19)
(cid:20) (cid:5)(cid:13)
(cid:21) (cid:2)(cid:7) (cid:4)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:2)(cid:5)(cid:2)
(cid:3)(cid:6)
(cid:8) (cid:5)(cid:9)
(cid:8) (cid:5)(cid:9)
(cid:1)(cid:2)(cid:5)(cid:19)
(cid:20) (cid:5)(cid:13)
(cid:21) (cid:2)(cid:7) (cid:4)
(cid:27) (cid:3)(cid:16) (cid:2)(cid:5)(cid:2)(cid:6) (cid:2)(cid:5)(cid:13)
(cid:21) (cid:2)(cid:7) (cid:4)(cid:3)(cid:22)
(cid:8) (cid:5)(cid:9)
(cid:8) (cid:5)(cid:6)
(cid:21) (cid:2)(cid:7) (cid:4)(cid:3)(cid:22)
(cid:8) (cid:5)(cid:6)
(cid:20) (cid:5)(cid:13)
(cid:23) (cid:5)(cid:9)
(cid:20) (cid:5)(cid:13)
(cid:1)(cid:2)(cid:5)(cid:19)(cid:13) (cid:5)(cid:9)
Figure 4: Model Checking Design Space.
(cid:2)c. The detailed analysis of these miscon(cid:2)guration is our technical
report [17,18].
In general, probing from worms (self-propagating processes) can
look very similar to that from botnets (processes under a common
C&C), and indeed the line between the two can blur depending on
the nature of the commands that botmasters issue to their bots. For
our purposes, we identify and remove as worms those events that
exhibit an exponential growing trend (per the technique developed
in [31]) and deem the remainder as botnet probing events.
2.3 Botnet Inference Subsystem
Scan Pattern Checking: For botnet probing events, there are nu-
merous scanning strategies that attackers can potentially use. Iden-
tifying the particular approach can provide a basis to infer further
properties of the events and perhaps of the botnets themselves. We
refer to these strategies as scan patterns, and undertake to develop
a set of scan-pattern checking techniques to understand different
dimensions of such strategies:
(cid:15) Monotonic trend checking
(cid:15) Hit list checking
(cid:15) Uniformity checking
(cid:15) Dependency checking
For details, see Section 3.
Global Property Extrapolation: Once we identify a probing
event’s scan pattern, we then use the scan pattern to extrapolate
a global view of the event. We focus on two of the most common
scan patterns: uniform random scanning, and uniform hit-list scan-
ning. We con(cid:2)rm their common use both from botnet source code
analysis (Section A) and experimental observations (Section 5). We
then extrapolate the global scan scope and the global number of
bots based on these two scan patterns, using techniques developed
in Section 4.
3. PROPERTY CHECKING OF BOTNET
SCAN PATTERNS
The whole design space of the botnet probing strategies is very
large.
It is hard to consider all of them in our botnet inference
framework. Through botnet source code analysis and reason-
ing what a rationale botnet master will do (the details is in Ap-
pendix A), We (cid:2)nd the uniform random scanning, hit-list scanning,
monotonic scanning and coordinated permutation scanning are the
strategies more likely used by the botmasters, given they are simple
and effective.
In this section we develop a set of analysis algorithms for de-
tecting these scan strategies. Each is designed to check a single
dimension of characteristics in the scan pattern. Then we combine
the characteristics of an event to construct the scan pattern in use.
We (cid:2)rst classify the scan traf(cid:2)c pattern into monotonic, partially
monotonic and non-monotonic trends. For non-monotonic trend,
we assess the possible use of a hit-list or random-uniform scanning
(even distribution of scans across the portion of the sensor space).
Finally, for random-uniform pattern we test whether the senders
can be modeled as independent.
(cid:7)
(cid:6)
(cid:7)
(cid:12)
(cid:13)
(cid:13)
(cid:15)
(cid:6)
(cid:13)
(cid:13)
(cid:15)
(cid:6)
(cid:7)
(cid:7)
(cid:8)
(cid:24)
(cid:8)
(cid:24)
(cid:8)
(cid:9)
(cid:8)
(cid:24)
(cid:8)
(cid:9)
(cid:8)
(cid:24)
(cid:25)
(cid:26)
(cid:7)
(cid:6)
(cid:13)
(cid:26)
(cid:7)
(cid:25)
(cid:26)
(cid:7)
(cid:6)
(cid:13)
(cid:26)
(cid:7)
Hit−list
0
1
8
P
Uniform random
I
r
e
p
n
a
c
s
#
6
4
2
0
0
2
5
1
P
I
r
e
p
n
a
c
s
#
0
1
5
0
0
1000
1500
0
2500
1500
1000
500
2000
Destination IPs in the sensor
500
2000
Destination IPs in the sensor
2500
Figure 5: Hit-list and uniform scanning distribution on the sen-
sor.
3.1 Monotonic Trend Checking
ning?
Question: Do senders follow a monotonic trend in their scan-
Monotonically scanning the destination IP addresses (e.g., se-
quentially one after another) is a common scan strategy widely
used by network scanning tools. In our evaluation, we did (cid:2)nd a
few events which use the monotonic trend scanning. Furthermore,
for random events, the monotonic trend checking can help us (cid:2)lter
out the noises caused by the non-bot scanners.
For each sender, we test for monotonicity in targeting by apply-
ing the Mann-Kendall trend test [15], a non-parametric hypothesis
testing approach. In our study, we set the signi(cid:2)cance level to 0.5%,
since a higher signi(cid:2)cance level will introduce more false positives
and we need to check thousands of sources. In our evaluation, we
manually check the statistical power and (cid:2)nd it high enough to de-
tect weak trends. The intuition behind this test is that if the data
have a monotonic trend, the aggregated sign value(>! 1; =! 0;
<! (cid:0)1.) of all the consecutive value pairs would be out of the
range the randomness can achieve. In our technical report [18], we
describe the detailed approach and our enhancement to the original
Mann-Kendall trend test.
We label an entire event as having a monotonic trend if more
than 80% of senders exhibit a trend, and for further analysis re-
move those that do not re(cid:3)ect a trend as likely representing sepa-
rate activity (and thus likely removing a source of potential noise).
We instead label the event as non-monotonic if more than 80% of
senders do not exhibit a trend. We label the remainder as partial
monotonic.
3.2 Hit-List Checking
Question: Do the bots use a target hit-list for scanning?
By hit-list scanning, we refer to an event for which the attacker
appears to have previously acquired a speci(cid:2)c list of targets. Hit-
list is often employed by sophisticated botmasters to achieve high
scan ef(cid:2)ciency. It is important for the network administrators to
know whether they are in the hit-list. When that is the case, most
likely they will be re-scanned by the attacker again and again. We
detect the use of a hit-list based on the observation that such scans
should heavily favor the use of (cid:147)live(cid:148) addresses (those that respond)
to (cid:147)dark(cid:148) (non-responsive) addresses.
To this end, we operate half of our sensor region in a live fashion
and half dark. If we observe an event in the Honeynet portion, but
not in the darknet portion, this provides strong evidence that the
scan used a hit list. However, one consideration is event (cid:147)pollution(cid:148)
(sources that actually are background noise rather than part of the
botnet). We do not require a complete absence of darknet scanning,
instead test for the prevalence of honeynet scans over darknet scans
signi(cid:2)cantly exceeding what we would expect.
Figure 5 compares an example hit-list event (WINRPC-070625)
versus a random-uniform event (VNC-060729). To distinguish be-
tween two such cases, we de(cid:2)ne the ratio of the number of senders
which target the darknet (md) over those of the honeynet (mh) as
. Then we test whether (cid:18) crosses a given threshold. In our
(cid:18) = md
mh
evaluation, we (cid:2)nd the results are not sensitive to the threshold we
choose.
Note that for the events that require application-level analysis
to separate the activity from the background traf(cid:2)c (e.g., different
types of HTTP probing), sources in the event will necessarily be
restricted to the honeynet because application-level dialog requires
responses that the darknet cannot provide. In this case we can still
perform an approximate test, by testing the volume of traf(cid:2)c seen
concurrently in the darknet using the same port number. Doing so,
may miss some hit-list events, however, because we tend to overes-
timate the amount of activity the botnet exhibits in the darknet.
Even other factors could potentially cause an imbalance between
the darknet and the Honeynet. However, most of these do not re-
sult in a signi(cid:2)cantly small (cid:18), except the one in which an attacker
chooses a small scan range that happens to include only the Hon-
eynet addresses. However, even if this occurs we would also (if
it does not re(cid:3)ect previous scanning, i.e., is not a hit-list) expect
it to occur equally often the other way around, i.e., including only
darknet addresses but not Honeynet addresses, which have not been
observed over two years.
In the 203 events we analyzed, we (cid:2)nd 33 (16.3%) hit-list events.
3.3 Uniformity Checking
Question: Does an event uniformly scan the target range?
A natural technical for bots is to employ uniform random scan-
ning across the target range. Testing whether the scans are evenly
distributed in the honeynet sensor can be described as a distribu-
tion checking problem. We employ a simple (cid:31)2 test, which is well-
suited for the discrete nature of address blocks. For (cid:31)2 test, when
choosing the number of bins for the test, a key requirement is to
ensure that the expected value Ei for any bin should exceed 5 [26].
Accordingly, given that our events have at least several hundred
scans in them, we divide the 2,560 addresses in our Honeynet into
40 bins with 64 addresses per bin. We then use the (cid:31)2 test with
a signi(cid:2)cance level of 0.5%, which is found to work well in our
subsequent evaluation in Section 5.3.
3.4 Dependency Checking
dinated?
Question: Do the sources scan independently or are they coor-
Sophisticated scanning strategies can introduce correlations be-
tween the sources in order to control the work that each contributes
more ef(cid:2)ciently. For example, In Appendix A.2, we describe a
more ef(cid:2)cient coordinated scheme ABPS (Advanced Botnet Per-
mutation Scanning) based on permutation scanning will induce
negative correlations in the targeting among the sources (they try
to (cid:147)get out of each other’s way(cid:148)).
Since traditional approach only an work in linear dependence or
two-variable cases, we develop a new hypothesis testing approach.
To test for such coordination, we use the following hypothesis test.
The null hypothesis is that the senders act in a uniform, indepen-
dent fashion (where we (cid:2)rst test for uniformity as discussed above);
while the alternative hypothesis is that the senders do not act in an
independent fashion. If an event comprises n scans targeting d des-
tinations in a uniform random manner, we can in principle calculate
the distribution of the number of destinations that receive exactly
k scans, Zk. We then reject the null hypothesis if the observed
value is too unlikely given this distribution (we again use a 0.5%
signi(cid:2)cance level).
THEOREM 1. If n scans target d addresses in a uniform inde-
pendent manner, the number of addresses Z0 (k = 0) which do not