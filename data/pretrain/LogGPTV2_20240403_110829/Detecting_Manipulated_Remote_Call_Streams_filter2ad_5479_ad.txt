32.59
21.08
Null calls
fan-in 2
287.27
675.47
10.68
55.50
33.72
21.00
% increase
37.9 %
728.9 %
10.4 %
0.5 %
11.5 %
0.5 %
Our efﬁciency measurements are straightforward.
Using the UNIX utility time, we measure each applica-
tion’s execution time in the simulated environment with-
out operating any model. This is a baseline measure
indicating delay due to simulated network transit over-
head, equivalent to a remote execution environment’s
run-time conditions. We then turn on checking and vari-
ous optimizations to measure the overhead introduced
by our checking agent. We ﬁnd the NFA model efﬁcient
to operate but the bounded PDA disappointingly slow.
However, the extra precision gained from inclusion of
null calls into the bounded PDA model dramatically
improves efﬁciency.
4.3 The NFA Model
We evaluate the models of the six test programs with
respect to precision and efﬁciency. Our baseline ana-
includes renaming, argument
lyzer
recovery, dead
automaton removal, and single-edge replacement. Using
the NFA model, we compare the results of several null
call placement strategies against this baseline and con-
sider the trade-off between performance and efﬁciency
due to the null call insertion.
We use four different null call placement strategies.
First, no calls are inserted. Second, calls are inserted at
the entry point of every function with a fan-in of 10 or
more–that is, the functions called by 10 or more other
functions in the application. Third, we insert calls at the
entry point of every function with a fan-in of 5 or
greater. Fourth, we instrument functions with a fan-in of
2 or more. We have tried three other placement strate-
gies but found they occasionally introduced a glut of
null calls that would overwhelm the network: adding
calls to all functions on recursive cycles; to all functions
r
o
t
c
a
F
g
n
i
h
c
n
a
r
B
e
g
a
r
e
v
A
12
10
8
6
4
2
0
NFA Precision
*
*
gzip
procmail
G
N
random1
*
entropy
No null calls
Null calls in functions with fan-in >= 10
Null calls in functions with fan-in >= 5
Null calls in functions with fan-in >= 2
finger
U finger
*  Value = 10
Null calls in functions with fan-in >= 5
Null calls in functions with fan-in >= 2
Figure 12: Precision improvements with renamed call sites
and argument recovery.
At ﬁrst glance, it may seem counter-intuitive that
argument recovery should reduce imprecision to a
greater degree than renaming. Argument recovery is,
after all, a subset of renaming; static arguments distin-
guish the call site. However, an attacker cannot manipu-
late a recovered argument, so system calls that were
dangerous with unknown arguments become of no
threat with argument recovery.
We analyzed the bounded PDA model for procmail
with stack bounds from 0 to 10. Figure 13 shows the
average branching factors of our PDA at varying levels
of null call instrumentation and bounded stack depth.
Figures 14 and 15 show the run-time overheads of these
models at two different time scales.
Null call insertion has a surprising effect on opera-
tion of the bounded stack models. The added precision
of the null calls actually decreases run-time overheads.
We were surprised to discover cases where the bounded-
stack PDA with null call instrumentation was nearly as
efﬁcient to operate as an NFA model, but at a higher
level of precision. Observe that higher levels of null call
instrumentation actually reduce the execution times, as
operation of the models becomes more precise.
Increasing the stack size produces a similar effect.
The plots for instrumentation in functions with fan-in of
5 in Figure 14 and in functions with fan-in of 10 in
Figure 15 show a common pattern. Up until a stack
bound of size 6, the model’s efﬁciency improves. More
execution context is retained, so fewer paths in the
model are possible. As the state grows past a bound of 6,
the cost of increased state begins to dominate. Finding
this transition value is an important area for future
research.
4.5 Discussion on Metrics
Measuring precision with the dynamic average branch-
ing factor metric ignores several important consider-
ations:
1. An attack likely consists of a sequence of system
calls and is not a single call in isolation. A call may
be dangerous only when combined with other calls.
2. The attacker could steer execution through one or
more “safe” system calls to reach a portion of the
model that accepts an attack sequence. Perhaps a
typical run of the program does not reach this area
of the model, so the dangerous edges do not appear
in the dynamic average branching factor. Such safe
edges should not cover the potential for an attack
downstream in the remote call sequence.
We do not see any obvious dynamic metric that easily
overcomes these objections. The straightforward static
analogue to dynamic average branching factor is static
average branching factor, the same count averaged over
the entire automaton with all states weighted equally.
The prior complaints remain unsatisﬁed.
We propose a metric that combines static and
dynamic measurements. Our average adversarial
opportunity metric requires two stages of computation:
ﬁrst, the automaton modeling the application is com-
posed with a set of attack automata to identify all model
states with attack potential; then, the monitor maintains
a count of the dangerous states encountered during run-
time. “Attack potential” indicates a known attack is pos-
sible beginning at the current state or at a state reach-
able from it. We are locating those positions in the
model where an adversary could successfully insert an
attack and counting visits to those states at run-time.
5 Comparison with Existing Work
We measured dynamic average branching factor and
execution overhead for comparison with the earlier work
of Wagner and Dean. We compare only the NFA model,
as it is the only model our work has in common with
their own. They analyzed four programs; two of them,
procmail and ﬁnger intersect our own experimental set.
Although we do not know what version of ﬁnger Wag-
ner and Dean used, we compared their numbers against
our analysis of GNU ﬁnger. We used call site renaming,
argument recovery, and single-edge replacement. The
results for Wagner and Dean include argument recovery.
(They have no analogue to renaming or edge replace-
ment). On the two programs, we observed a signiﬁcant
discrepancy between their reported precision values and
those we could generate. Upon investigation, it appears
PDA Precision - Effect of Stack Depth (procmail)
No null calls
Null calls in functions with fan-in >= 10
Null calls in functions with fan-in >= 5
Null calls in functions with fan-in >= 2
r
o
t
c
a
F
g
n
i
h
c
n
a
r
B
e
g
a
r
e
v
A
12
11
10
9
8
7
6
5
4
3
2
1
0
0
1
2
3
5
6
4
Stack Bound
7
8
9
10
Figure 13: Effect of stack depth and null call insertion upon PDA precision. Baseline optimizations were used.
PDA Overhead - Effect of Stack Depth - 7 sec Time Scale (procmail)
> 12 sec
No null calls
Null calls in functions with fan-in >= 10
Null calls in functions with fan-in >= 5
Null calls in functions with fan-in >= 2
7
8
9
10
0
1
2
3
5
4
Stack Bound
6
)
s
d
n
o
c
e
s
(
d
a
e
h
r
e
v
O
7
6
5
4
3
2
1
0
Figure 14: Effect of stack depth and null call insertion upon PDA run-time overhead, 7 second time scale. Baseline
optimizations were used. This time scale shows trends for null call insertion for fan-ins of 5 and 2.
)
s
d
n
o
c
e
s
(
d
a
e
h
r
e
v
O
700
600
500
400
300
200
100
0
PDA Overhead - Effect of Stack Depth - 700 sec Time Scale (procmail)
756 sec
No null calls
Null calls in functions with fan-in >= 10
Null calls in functions with fan-in >= 5
Null calls in functions with fan-in >= 2
7
8
9
10
0
1
2
3
5
4
Stack Bound
6
Figure 15: Effect of stack depth and null call insertion upon PDA run-time overhead, 700 second time scale. The source data
is identical to that of Figure 14. This time scale shows trends for no null call insertion and insertion for fan-in of 10.
Figure 16: The socket model in Solaris libc.