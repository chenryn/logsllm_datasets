mental privacy-performance tradeoﬀs whereas others simply
reﬂect the current state of the art. To provide one example in
the latter category: most 𝙻𝚎𝚐𝚊𝚌𝚢 systems leak information at
ingestion, whereas most 𝙲𝚞𝚜𝚝𝚘𝚖 only leak information after
queries have been made against the system. The recent Arx-
EQ [14] bucks this trend by requiring the client to remember
the frequency of each keyword.
B. Leakage Inference Attacks
In this subsection and Table III, we summarize leakage
inference attacks that can exploit the leakage revealed by a
protected search system in order to recover some information
about sensitive data or queries. Hence, this section details the
real-world impact of the leakage bounds and threat models
depicted in Table II. The two tables are connected via a JOIN
on the “𝑆 leakage” columns: a protected search scheme is
aﬀected by an attack if the scheme’s leakage to the server is
at least as large as the attack’s required minimum leakage.
We stress that
leakage inference is a new and rapidly
evolving ﬁeld. As a consequence,
the attacks in Table III
only cover a subset of leakage proﬁles included in Table II.
Additionally, this section merely provides lower bounds on the
impact of leakage because attacks only improve over time.
We start by introducing the diﬀerent dimensions that char-
acterize attack requirements and eﬃcacy. Then, we sketch a
couple representative attacks from the literature. Finally, we
describe how the provider and querier should use these attacks
to inform their choice of a search system that adequately
protects their interests.
1) Attack Requirements: We classify attacks along four
dimensions: attacker goal, required leakage, attacker model,
and prior knowledge. The attacker is the server in all of the
attacks we consider, except for the Communication Volume
Attack of [125], which can be executed by a network observer
who knows the size of the dataset. We expect future research
on attacks using leakage available to other insiders.
a) Attacker Goal: Current attacks try to recover either
a set of queries asked by the querier (query recovery) or the
data being stored at the server (data recovery).
b) Required Leakage: This is the leakage function that
must be available to the attacker. We focus on the common
leakage functions on the dataset and responses identiﬁed in
Section II-E. Examples include the cardinality of a response
set, the ordering of records in the database, and identiﬁers
of the returned records. Some attacks require leakage on the
entire dataset while others only require leakage on query
responses.
c) Attacker Model: Current inference attacks assume one
of two attacker models. The ﬁrst is a semi-honest attacker as
discussed in Section II-D. The second is an attacker capable
of data injection: it can create specially crafted records and
have the provider insert them into the database. Note that
this capability falls outside the usual malicious model for the
server. The attacker’s ability to perform data injection depends
on the use case. For example, if a server can send an email to
a user that automatically updates the protected database, this
model is reasonable. On the other hand, it might be harder to
insert an arbitrary record into a database of hospital medical
records.
d) Attacker Prior Knowledge: All current attacks assume
some prior knowledge, which is usually information about the
stored data but may include information about the queries
made. Attack success is judged by the ability to learn informa-
tion beyond the prior knowledge. The following types of prior
179
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:00 UTC from IEEE Xplore.  Restrictions apply. 
knowledge (ordered from most to least information) help to
execute attacks.
(cid:4) Contents of full dataset: the data items contained in the
database. The only possible attacker goal in this case is
query recovery.
◕ Contents of a subset of dataset: a set of items contained
in the database. Both attacker goals are interesting in this
case.
(cid:3)(cid:2) Distributional knowledge of dataset: information about the
probability distribution from which database entries are
drawn. For example, this could include knowledge of the
frequency of ﬁrst names in English-speaking countries.
This type of knowledge can be gained by examining
correlated datasets.
◔ Distributional knowledge of queries: information about
the probability distribution from which queries are drawn.
As above,
this might be knowledge that names will
be queried according to their frequency in the overall
population.
(cid:2) Keyword universe: knowledge of the possible values for
each ﬁeld.
Naturally, attacks that require full knowledge of the data are
more eﬀective; the reasonableness of this assumption should
be evaluated for each use case.
2) Attack Eﬃcacy: We evaluate attack eﬃcacy qualitatively
in terms of three metrics: 1) the runtime of the attack,
including time required to create any inserted records; 2)
the sensitivity of the recovery rate to the amount of prior
knowledge; and 3) the keyword universe size attacked. Note
that the strength of an attack is strongly application-dependent;
an attack that is devastating on one dataset may be completely
ineﬀective on another dataset.
Table III characterizes currently known attacks based upon
their requirements and eﬃcacy. All of the attacks described in
the table only require modest computing resources.
3) Attack Techniques: Leakage inference attacks against
protected search systems have evolved rapidly over the last
few years, with Islam et al. [132] in 2012 inspiring many
other papers. Most of the attacks in Table III rely on the
following two facts: 1) diﬀerent keywords are associated with
diﬀerent numbers of records, and 2) most systems reveal
keyword identiﬁers for a record either at rest (e.g., DET [15]
reveals during 𝐈𝐧𝐢𝐭 if records share keywords) or when it is
returned across multiple queries (e.g., Blind Seer [16] reveals
during 𝐐𝐮𝐞𝐫𝐲 which returned records share keywords). To
give intuition for how these attacks work we brieﬂy summarize
two entries of Table III.
Cash et al.’s [128] Count Attack is a conceptually simple
way to exploit this information. Assume the attacker has full
knowledge of the database and is trying to learn the query.
The attacker sees how many records are returned in response
to a query. If that number is unique it can identify the query.
Furthermore, by identifying the query, the attacker learns that
every returned record is associated with that keyword.
For example, suppose the attacker learns the ﬁrst query was
for LastName = ‘Smith’. Now consider a second query for
an unknown ﬁrst name. The query does not return a unique
number of records, so the method above cannot be used.
Suppose that FirstName=‘John’ and FirstName=‘Matthew’
both return 1000 records. The attacker can also check how
many records are in common with the previous query. This
creates an additional constraint, for example there may be
100 records with name ‘John Smith’ but only 10 records
with name ‘Matthew Smith’. By checking record overlap with
the previously identiﬁed query, the attacker can identify the
queried ﬁrst name. This attack iteratively identiﬁes queries
and uses them as additional constraints to identify unknown
queries.
Cash et al.’s attack is fairly simple and performs well if the
keyword universe sizes is at most 5000. However, it requires a
large portion of the dataset to be known to the attacker. With
80% of the dataset known to the attacker, Cash et al. [128]
yield a 40% keyword recovery rate.
Zhang et al. [127] extend the Count Attack to a malicious
adversary setting, allowing a server to inject a set of con-
structed records. This capability greatly improves keyword
recovery. By carefully constructing a small number of these
records (e.g., nine records for a universe of 5000 keywords),
it is possible to search the keyword universe and identify
the keyword. Although the records are fairly large, the attack
extends if the database only allows a limited number of
keywords per data record. This attack recovers more keywords
than the attack of Cash et al.: 40% of the data must be leaked
to obtain a 40% keyword recovery rate.
4) Discussion: The provider and querier rely upon pro-
tected search to protect
the server, or
anyone who compromises the server. Our systemization of
attacks shows that they should consider the following four
questions before choosing a protected search technique to use.
themselves against
∙ How large is the keyword universe?
∙ How much of the dataset or query keyword universe (and
corresponding frequency) can the attacker predict?
∙ Can an attacker reasonably insert crafted records?
∙ Does the adversary have persistent access to the server,
or merely a snapshot of it at a single point in time?
Answers to the ﬁrst three questions depend upon the intended
use case. For example, a system with a smaller leakage proﬁle
may be necessary in a setting where the keyword universe is
small and the attacker has the ability to add records. A system
with a larger leakage proﬁle may suﬃce in a setting where the
keyword universe is very large.
The fourth question pertains to adversaries who compromise
the server. 𝙻𝚎𝚐𝚊𝚌𝚢 schemes tend to leak information about the
entire database to the server. Thus, using the terminology of
Grubbs et al. [74], they are susceptible to an adversary who
only gets a snapshot of the database at some point in time.
In contrast, 𝙲𝚞𝚜𝚝𝚘𝚖 schemes tend to reveal information about
records only during record retrieval or index modiﬁcation as
part of the querying process, so they require a persistent
adversary who can observe the evolution of the database state
over time. (We note however that many Boolean schemes have
additional leakage about data statistics for the entire database.)
180
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:00 UTC from IEEE Xplore.  Restrictions apply. 
𝑆 leakage
Scale
Crypto
Network
e
p
y
t
y
r
e
u
Q
y
t
i
l
a
u
q
E
Scheme (References)
Arx-EQ [14]
Kamara-Papamanthou [106]
Blind Storage [100]
Sophos (Σo𝜙o𝜍) [101]
Stefanov et al [107]
vORAM+HIRB [120]
TWORAM [121]
3PC-ORAM [124]
n DET [15], [92]
a
e
l
o
o
B
e
g
n
a
R
r
e
h
t
O
BLIND SEER [16], [17]
OSPIR-OXT [18]–[21], [104]
Kamara-Moataz [102]
OPE [93]–[95]
Mutable OPE [97]
Partial OPE [111]
Arx-RANGE [110]
SisoSPIR [22]
GraphEnc1 [116]
GraphEnc3 [116]
Chase-Shen [109], [126]
Moataz-Blass [123]
s
e
i
t
r
a
p
Threats
𝑄
𝑆
l
a
i
r
a
s
r
e
v
d
A
l
a
i
r
a
s
r
e
v
d
A
t
i
n
I
3
f
o
Approach #
𝙻𝚎𝚐𝚊𝚌𝚢
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖
𝙾𝚋𝚕𝚒𝚟
𝙾𝚋𝚕𝚒𝚟
𝙾𝚋𝚕𝚒𝚟
𝙻𝚎𝚐𝚊𝚌𝚢
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖
𝙻𝚎𝚐𝚊𝚌𝚢
𝙻𝚎𝚐𝚊𝚌𝚢
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖
𝙾𝚋𝚕𝚒𝚟
𝙲𝚞𝚜𝚝𝚘𝚖
𝙲𝚞𝚜𝚝𝚘𝚖