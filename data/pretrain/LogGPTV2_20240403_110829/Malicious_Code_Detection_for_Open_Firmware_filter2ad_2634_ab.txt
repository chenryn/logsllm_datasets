In this section we describe in some detail our prototype,
called BootSafe. We hope to convince the reader, as we are
ourselves convinced, that this is a sound and commercially
viable approach to protection against an important class of
malicious boot ﬁrmware.
Our objective is to detect malicious fcode programs dur-
ing the Open Firmware boot cycle as they are loaded, in
order to prevent them from executing.
Detection is based on ECC veriﬁcation as described in
Section 3 above. However, veriﬁcation will go beyond
the basic safety properties of the original ECC prototype.
This will require a meaningful security policy for fcode
programs—essentially a conservative deﬁnition of program
safety—and a means of enforcing that policy. Devising an
effective policy is difﬁcult because it is hard to foresee all
the ways that an attacker could harm us.
The BootSafe system consists of a Java-to-fcode certify-
ing compiler J2F and a corresponding fcode veriﬁer (Fig. 2).
The following sections detail our approach to compila-
tion and veriﬁcation. Following that are sections containing
some background information.
4.1 Compilation
The compilation of a Java program to fcode is a two-
stage process.
In the ﬁrst stage, Java source is compiled
down to Java Virtual Machine (VM) code, also known as
Java compiler
?
J2F compiler
Java program
?
?
(cid:15)
Æ
bytecode(cid:15)
Æ
(cid:27)
(cid:26)
?
fcode +
certiﬁcate
(cid:12)
(cid:13)
(cid:12)
(cid:13)
(cid:24)
(cid:25)
6
B
o
o
t
S
a
f
e
?
veriﬁer
?
fcode interpreter
?
Firmware
Development
trust boundary
Open Firmware
Boot System
Figure 2. The BootSafe System
bytecode. For this purpose we can use any existing Java
compiler, such as the javac compiler available from Sun Mi-
crosystems. For the second stage, we are implementing a
compiler J2F that maps Java VM code to Forth VM code,
also known as fcode. Thus we can leverage existing com-
pilers for Java. In addition, we will be able to leverage the
Java bytecode veriﬁer, as explained below.
The translation from Java VM to Forth VM is relatively
straightforward in many ways, although there are some de-
sign challenges. One such challenge is to design an ap-
propriate object encoding and method dispatch mechanism.
Since Forth contains no prior support for objects, we must
design the object encoding from scratch. This goal has al-
ready been achieved.
Another issue is the class loading and initialization strat-
egy. The standard Java strategy loads and initializes classes
at their ﬁrst active use. This is known as lazy initialization.
For applications in boot ﬁrmware, lazy initialization is less
desirable because it imposes a runtime overhead that could
play havoc with real-time constraints that boot-time drivers
are often subject to during diagnostic testing of devices. We
thus prefer an eager initialization strategy to avoid this over-
head. We have designed and implemented a load-time static
analysis method that computes initialization dependencies
among Java classes based on the static call graph of the
class initializers [7]. We can use the computed dependen-
cies to order the classes for initialization at load time. This
is a departure from standard Java semantics, but a valuable
one for this application. In addition to avoiding the run-
time overhead of lazy initialization, it gives a clearer pic-
ture of the dependencies involved in class initialization, and
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
can ﬂag a variety of erroneous circularities that the standard
lazy method lets pass.
Our J2F compiler can currently compile with int,
boolean, and char types, String and StringBuffer classes,
user-deﬁned classes, and arrays of these types. It performs
both static and instance method dispatch correctly. It incor-
porates our eager class initialization strategy as described in
the preceding paragraph. The output of our J2F compiler is
a working Forth program. The Forth code produced, along
with a runtime support module of our design, can be suc-
cessfully read and interpreted by the Forth interpreter that
is part of SmartFirmware (a commercial implementation of
Open Firmware). In the future we will utilize a backend
mapping to fcode, and all veriﬁcation will be done on the
fcode, allowing us to produce a much more compact object
involving Forth execution tokens instead of text. However,
throughout the prototyping phase, we will continue to work
with Forth source code so as to make it easier to debug the
design of our J2F compiler and BootSafe veriﬁer.
In the near future we will ﬁll out the existing J2F proto-
type to handle a variety of other built-in types and library
classes, eventually moving toward a signiﬁcant and robust
subset of Java, perhaps full Java minus only support for re-
ﬂection and concurrency. It is also not clear that it will be
necessary to support the double-word types long and double
for applications in ﬁrmware. The elimination of these two
types would result in a substantial simpliﬁcation, since they
requires special handling.
One signiﬁcant advantage of Java over Forth is that the
Open Firmware architecture is naturally object-oriented.
Objects and inheritance can be used to great advantage in
modeling the device tree and the various devices that com-
prise it. For example, the standard API of a PCI bus can be
represented as an abstract class that manufacturers can sub-
class in order to implement drivers for their speciﬁc prod-
ucts.
In fact, we will require such subclassing as one of
the architectural constraints, mentioned above, that lead to
enforcement of the security policy.
4.2 Veriﬁcation
Sun has deﬁned a form of safety veriﬁcation for JVM
bytecode as part of its deﬁnition of the JVM. Our veriﬁ-
cation will build on this, verifying analogous properties of
fcode programs that have been translated from bytecode,
as well as some new checks that are peculiar to the Open
Firmware environment.
Veriﬁcation consists of a general device-independent
part that applies to all drivers and a device-speciﬁc part that
may vary depending on the kind of device. The overall se-
curity policy we will eventually enforce is three-tiered. En-
forcement of each tier depends on the previous ones.
Tier 1: Basic safety policy. This basic level corresponds
to that which is commonly called type-safety in the liter-
ature on language-based security. It has a ﬁxed platform-
and application-independent description involving memory
safety, control ﬂow safety, and stack safety that are all in-
terrelated. This level corresponds roughly to the level of
safety provided by the Java bytecode veriﬁer. It is also the
easiest of the three levels to design and implement, because
we can leverage the design of the Java bytecode veriﬁer in
our fcode veriﬁer. Since we are translating from Java, it is
possible to mimic the behavior of the Java bytecode veriﬁer
fairly directly, supplying the necessary typing information
in the form of an attached certiﬁcate, as in the ECC proto-
type. Since we have a formal description of the Java veri-
ﬁcation process, we can supply in the certiﬁcate whatever
extra information we need that may be present in the Java
bytecode, then build our veriﬁer to perform the same checks
as the Java veriﬁer. Thus the established type safety of Java
and the existence of well-documented bytecode veriﬁcation
algorithms are a huge advantage that will save us much de-
sign time.
Tier 2: Device encapsulation policy. Each peripheral de-
vice is operated directly or indirectly only by its own device
driver. Each device driver provides the only interface (API)
for the rest of Open Firmware to access the corresponding
device. Drivers that must access their devices through a
chain of other devices, such as buses, must do so in a highly
controlled and prespeciﬁed manner that is veriﬁable. Such
forms of indirect access typically involve some form of ad-
dress translation that is set up by the Open Firmware mapin
procedure whose application can be tightly controlled. Al-
though there is no software mediation at the time of the ac-
tual device access, it is possible for the veriﬁer to check that
the mapin procedure is called according to a highly con-
strained and recognizable pattern and that all bus addresses
subsequently accessed by the driver are within the memory
range allocated to that device by mapin. This is more or less
comparable to an array bounds check in Java.
Tier 3: Prevention of speciﬁc forms of harm.
In this
tier, we enforce conventions that any reasonable device
driver should adhere to. In so doing, we rule out many of
the routes by which malicious fcode could cause harm. For
instance, device drivers, once they are loaded, should never
be redeﬁned—there is no legitimate reason to do so. Such
redeﬁnition is otherwise legal within fcode, and would be a
very attractive attack mechanism.
Enforcement of tier 2 and 3 policies will be based on ar-
chitectural constraints—restricting the interaction of mod-
ules with one another and constraining the interfaces. This
enables two strategies for enhancing safety: ruling out in-
teractions that should never happen in legitimate ﬁrmware,
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
and require that services are accessed via wrappers that per-
form run-time checks. Some Java language features such as
private, protected, and ﬁnal methods can be of great bene-
ﬁt here. For instance, by requiring that untrusted code is a
subclass of a trusted class, we can ensure that ﬁnal methods
of the trusted class cannot be overridden in the subclass.
5. Related Work
In this section we discuss the mechanisms, such as cryp-
tography and mediated access, that have been most com-
monly used to address security threats and their practical
limitations for guarding against malicious ﬁrmware. We
then discuss other important examples of language-based
security mechanisms (Java, proof carrying code, and typed
assembly language) and the tradeoffs involved in deciding
which is appropriate for a particular application.
5.1 Non-Language-Based Mechanisms
Traditional approaches to the security problem include:
mediated access or proxy execution, cryptography, code in-
strumentation, and trusted compilation.
Mediated access or proxy execution, probably the oldest
and most widespread system security mechanism, proceeds
by isolating critical operations and data in a system kernel,
the only code privileged to access these operations and data
directly. All other processes gain access only by using the
kernel as a proxy, after communicating their desires by mes-
sage. This not only prevents untrusted code from corrupting
the system, but also allows the kernel to monitor all access,
perform authentication, or enforce other safety policies.
Cryptography discourages access to sensitive data during
transit across an untrusted network and can also be used for
authentication.
Code instrumentation, software fault isolation (SFI), and
sandboxing [24] alter (instrument) machine code so that
critical operations can be monitored during execution in or-
der to enforce a security policy. The monitor is invisible
(except for performance costs) so long as execution follows
the policy, but intervenes to protect the system when a vi-
olation is detected. Schneider [20, 21] extends this idea
to handle any security policy that can be expressed by a
ﬁnite-state automaton. For example, one can express the
condition, “No message is ever sent out on the net after a
disk read,” with a two-state automaton. These automata are
called security automata. The code is instrumented so that
every instruction that could potentially affect the state of
the security automaton is preceded by a call to the automa-
ton. Security automata give considerable ﬂexibility in the
speciﬁcation of safety policies and allow the construction
of specialized policies tailored to a consumer’s particular
needs. The main drawback is that some runtime overhead
is incurred for the runtime calls to simulate the automaton.
Trusted compilation is the practice of compiling locally
using a trusted compiler.
None of these mechanisms are well suited to ﬁrmware.
Firmware typically runs before the system kernel is even
loaded. Mediation can be provided only by the BIOS, which
operates in a relatively austere environment unequipped for
proxy execution: ﬁrmware drivers associated with installed
components are typically given direct access to critical sys-
tem components.
It is desirable to allow this capability
without compromising security.
Code instrumentation is also costly. The runtime check
required before every sensitive operation could contribute
substantially to runtime overhead. Some runtime checks
can be eliminated if program analysis determines that they
are unnecessary, but this is also a costly undertaking and
could contribute substantially to load time overhead. More-
over, even the most sophisticated analysis techniques are
necessarily incomplete, because safety properties are unde-
cidable in general.
Trusted compilation of the ﬁrmware would have to be
redone every time a system is booted, incurring not only
a performance penalty but the additional complexity of in-
cluding the compiler in the trusted computing base. Also,
trusted compilation does not by itself supply any justiﬁca-
tion for trust in the source code that is being compiled.
5.1.1 Cryptographic Authentication (AEGIS)
We have already noted that authentication alone cannot en-
sure that untrusted code is safe to run. Clearly, however,
it can provide some protection. The most sophisticated au-
thentication architecture for ﬁrmware is provided by AEGIS
[2]. The prototype has been designed as a minimal change
to the boot process of the IBM PC that provides a lay-
ered sequence of authentication checks of untrusted BIOS
code and CMOS, then expansions cards, then the operating
system boot blocks, etc., throughout the boot process.
It
also provides a mechanism for attempting to recover from
a failed integrity check by obtaining a replacement module
from a trusted source.
5.2 Language-Based Mechanisms
Compilers for high-level programming languages typi-
cally accumulate much information about a program dur-
ing the compilation process. This information may take the
form of type information or other constraints on the values
of variables, structural information, or naming information.
This information may be obtained through parsing or pro-
gram analysis and may be used to perform optimizations or
to check type correctness. After a successful compilation,
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
compilers traditionally throw this extra information away,
leaving a monolithic sequence of instructions with no ap-
parent structure or discernible properties.
Some of this extra information may have implications
regarding the safety of the compiled object code. For ex-
ample, programs written in type-safe languages must type-
check successfully before they will compile, and assum-
ing that the compiler is correct, any object code compiled
from a successfully typechecked source program should be
memory-safe. If a code consumer only had access to the
extra information known to the compiler when the program
was compiled, it might be easier to determine whether the
code is safe to run.
Code certiﬁcation refers to the idea of retaining ex-
tra information from a program written in a high-level
language in the object code compiled from it. This ex-
tra information—called a certiﬁcate—is created at compile