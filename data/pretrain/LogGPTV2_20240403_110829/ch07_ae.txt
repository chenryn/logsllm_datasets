服务发现包括静态 DNS 记录以及手动编辑和维护的区域文件。DNS 更改通常由运维审核和部署。我们在 DNS 部署期间往往通过脚本自动在 IRC 上喊话“DNS 部署开始了！”。
运维所有者和开发所有者定期浏览容量规划电子表格，以确保服务有足够的容量来维持当前使用量的增加。收集访问模式和资源利用率，并根据当前增长预测容量需求。对于几十个服务的所有者来说，这意味着要进行大量的容量规划。
在 2012 年下半年，我们达到 100 万并发用户。这意味着有一百万人直接收听连接到我们三个数据中心之一的音乐。一个相当伟大的壮举。回顾一下，这应该归因于一些早期的决策，如 Spotify 后端架构被设计为可扩展，早期的客户端/协议/后端优化，以及良好的实现，这些都得到了回报。此外，由于没有复杂的逻辑，大多数故障都可以轻松定位和隔离。每个后端服务都做了一件事，并且做了正确的事。我们保持简单。
随着流媒体音乐用户数量呈指数级增长，运维团队无法做到这一点。我们发现集中式 SRE 运维团队是一个无法扩展的系统。
关键收获
我们从这一时期的主要学习是：
使运维从开始真正成为默认的；如果你构建它，你就要运行和维护它。
将运维责任转移到更接近于目标的人：开发人员。
随着服务生态系统的扩展，需要不断审视运维工作是如何扩展的。昨天效果好的东西今天可能效果不好。 
介绍小组内嵌运维：2013~2015
  近 50 名运维工程师
近 150 名后端工程师
3 个数据中心
60 个后端服务
1 个用于登台环境的云服务商
前奏3 个数据中心
60 个后端服务
1 个用于登台环境的云服务商
前奏
在本节中，我们将讨论新的运维方法如何减少瓶颈并允许技术组织更快地增长：
迭代胜过失败
采用“小组内嵌运维”的新模式，使我们得以集中精力尽量减少手工作业。
核心工程价值
小组拥有自己的运维人员，这在不知不觉中帮助我们维护了自主和信任的价值观。工程师有可能造成广泛的损害，但同时他们手上也有避免这种破坏的工具和流程。
此时，工程组织已经变得太大，无法作为单个团队运行。于是基础架构和运维（IO）部落成立，专注于为我们的后端开发人员提供基础架构，并解决大规模运维带来的问题。这个部落的一部分叫做服务可用性（SA），主要由我们以前在生产运维中工作的工程师组成。到 2013 年，SA 由四个小队组成，分别是：安全、监控和另外两个工作小组（他们负责提供管理服务器所需的任何其他基础设施工具）。我们聘用新开发人员和启动新开发团队的速度太高，以至于这四个 SA 团队无法跟上。由于我们可以购买和安装新服务器、查看和合并 Puppet 更改、添加 DNS 记录或为服务设置警报的速度，交付新功能或改进功能的能力越来越慢。数十个功能团队迫不及待地等待将更新分发给我们的用户，但不得不等待我们进行代码审查或为其服务提供硬件。我们还在要求提供核心服务，在我们努力跟上不断积累的任务时，这些服务的业务质量和稳定性受到了影响。全球“运维任务清单”一直在不断增长。
减轻手动负载
 在查看了后端工程师如何工作以及最常陷入等待的位置数据后，我们决定尽可能专注于消除这些障碍。是时候考虑恢复小型初创公司的协作氛围，在开发与运维之间的相互信任，使我们的功能团队能够快速迭代，同时保持生产的可靠性。
首先需要改进的领域之一是服务器的预配。当我们的数据中心中有服务器时，我们仍必须引导操作系统并配置基本环境。我们有一些基本的自动化，但为了启动这个过程，后端工程师必须为运维团队创建一个工单，指定他们需要哪个数据中心、多少台服务器以及什么服务。然后，守门员会照顾这个工单，并使用我们的一组管道式数据库和命令行工具来启动预配过程。通常在大约 40 分钟的自动化任务之后，服务器才为后端开发人员做好准备。我们改善这个过程的第一次尝试是一个叫做 provgun 的工具，简称为“预配枪”。团队现在可以打开 JIRA 工单，自行启动预配，而不需要向运维团队发送工单或指望运维人员的垂青。一段时间后，cronjob 将扫描这些打开的工单，并自动启动我们以前手动执行的所有步骤，然后在成功预配服务器时向工单发出答复。
这释放了时间，让运维团队专注于其他事项，例如处理此系统的下一个版本：具有硬件可配置性和可用库存的自定义 Web 界面。此 Web 界面将显示未完成请求的队列、服务器的物理位置、机架多样性以及每个数据中心的可用服务器的当前库存，使开发人员有更多的选择，并更好地了解我们是如何构建我们的硬件生态系统。
 接下来要解决的是 DNS 基础结构。当时，运维团队手动添加和部署服务器的 DNS 记录。运维团队做的第一件事是使用 CMDB 作为事实来源，以确定哪些服务器记录应自动添加到区域文件中。这有助于减少错误的数量，例如忘记添加尾随的点号。经过反复检验，我们确信这些区域文件是准确的，于是它们能自动部署到权威 DNS 服务器。这再次释放了我们大部分的时间，开发人员的满意度也提高了。我们的后端中的服务使用 DNS SRV 记录发现彼此。另外还有一些用户友好的 CNAME，任须手动添加到区域文件中，这是一个繁琐且容易出错的任务，仍然需要运维工程师来查看和部署更改。
为了消除这一瓶颈，我们考虑了如何自动执行审核和部署过程。引入了一个基本测试框架，其中可以表达在审核中需要寻找的东西，例如“播放列表服务在我们的数据中心中是否可以发现？”我们还创建了一个自动程序，允许任何人合并更改（只要测试通过且经过互审）。
这是一个重大的更新：一个文件的简单更改可能会影响整个数据中心。在最初的一些事件中，一个团队的意外修改往往导致比预期的要严重的后果。但是，我们的后端开发人员很快了解了这些改变带来的力量和责任；很快，错误的数量几乎降到了零。同样，这减少了他们不得不等待运维团队的时间（从几天到几分钟）。DNS 和服务器预配成功后，下一个难题是 Puppet，配置管理系统，它在我们的服务器上安装了所有软件并部署了我们的应用程序。运维团队早就接受了对 Puppet 的补丁，但在合并任何内容之前需要每个提交进行审查。对于较大的提交或复杂的系统，这意味着他们可能会等待审查数天之久，直到有人找到足够的时间来审查它。
我们尝试了使用 DNS 的方法：合并你自己的更改，只要你的修补程序得到了其他人的积极评价。在最初的几周里，我们都非常焦虑，几乎对合并的每一个承诺都进行了监控。我们很快发现这些焦虑其实没有什么理由。给后端开发人员一个反馈周期，让他们放手进行更改、合并、部署、发现问题，然后再做一遍，这样他们会更深入地了解我们遇到的许多常见问题，总体而言，这些反馈周期提高了代码质量。使团队在运维上负责的最初几个步骤是成功的。他们现在可以获取服务器，为这些服务器添加 DNS 记录，并自行将配置和应用程序部署到新预配的服务器。我们不仅消除了开发人员的主要摩擦点和等待时间，而且由于从“构建它”到“运行它”的第一次责任转变，服务的稳定性也提高了。
以信任为基础
 但是，当我们跳过了运维团队以前完成的这些“运行状况检查”时，我们面临着一个新问题。没有运维团队的指导，后端现在更无序了。测试不足的服务和简单的实验使其问题进入生产环境，有时会导致停机，并要求轮值工程师的帮助，但他们现在缺乏对生产中运行内容的必要了解。我们需要找到一个办法，将知识和运维责任带回正确的位置，安排适当的人员来排除故障。
当 Spotify 是一个小型组织时，传统的运维所有者方法效果很好，但它在技术和组织方面都有复杂性和可扩展性问题。依靠一个或两个系统所有者来找出所有的问题是不可能的。我们还意识到，作为运维的看门人，这意味着我们保持了对运维学习机会的垄断。将责任移交给后端团队似乎是合乎逻辑的下一步。下一个问题是如何继续。我们需要与团队积极接触，并找出与技术组织的其他部门合作的方法。
 我们开始推出一种新的工作方式，即“小组中的荣誉运维”，这实质上包括将服务轮值和运营责任移交给开发服务的团队所需的一切。我们需要编写工具来完成许多以前手工完成的事情；我们需要更好的文档和培训，以便开发人员能够解决生产问题；我们需要开发者的同意来推动这一变化。
为开发人员和运维人员创建的指导文件，在每个人之间共享知识并打开双向沟通渠道，定义了我们需要的一些关键内容：
定义服务级别协议的标准化方法（SLA；我们当时没有使用服务级别指标【SLI】和服务级别目标【SLO】概念）
关于轮值、处理事件、执行根本原因分析和进行故障报告的速成课程
关于容量规划的指导
设置监控和警报的最佳做法，以及解释监控数据的指导
故障排除、系统交互和基础结构工具的培训故障排除、系统交互和基础结构工具的培训
当然，将所有这些责任交给团队，在很长一段时间内都是一项艰巨的任务，而基础设施团队仍要支持和构建核心平台。我们努力定义到底是什么算是核心平台；有些事情是显而易见的，例如网络、监视和预配，但其他系统更难分类。需要评估我们基础设施的关键部分，如用户登录服务、播放列表系统或歌曲加密密钥系统：它们是核心基础结构，还是应该像任何其他后端系统一样处理它们？
我们想达成交易：我们负责消除拥塞和摩擦，以换取将运维责任转移到功能团队中。如果团队需要在周五部署更改，则不应阻止它这样做。我们努力使运维服务的知识对开发人员来说唾手可得。
这没有得到组织内每个人的欢呼和鼓励；有人担心会对功能团队的迭代速度产生负面影响。如果团队还处理其系统的维护和操作职责，他们将如何有足够的时间来交付功能和增长？这些团队由开发人员组成，而不是 SRE；他们有多少时间要用于学习和练习操作？准备、过程和工具对于说服人们承担这一责任至关重要。我们继续投入大量资源来改进我们的工具，编写和推广框架，并编写文档，以帮助大多数团队尽可能顺利地过渡。 