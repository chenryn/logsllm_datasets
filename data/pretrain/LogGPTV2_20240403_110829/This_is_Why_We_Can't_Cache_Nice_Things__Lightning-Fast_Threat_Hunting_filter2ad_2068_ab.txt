incurs slow response times during forensic analysis. Moreover,
4Prior work [41] has shown that incorporating historical context into alert triage may
reduce the false positives of a commercial TDS by up to 84%.
3
KCAL does not provide any scalable solution for causal analysis on
enterprise-wide data.
Graph Databases. Given the high-throughput and low-latency
requirements of large-scale streaming systems, key-value storage
systems are shifting to in-memory designs [25, 56, 66]. Existing
graph databases (e.g., Redis [26], Neo4J [21], and Stinger [35]) can-
not be used directly in forensic analysis domain because of two
main reasons. First, these databases need to load and keep the whole
causal graph in the main memory to enable forensic analysis queries
(e.g., backward tracing). In large enterprises where terabytes of data
needs to be loaded from disk for long-running attack campaigns,
this approach incurs a significant I/O bandwidth. Even assigning
large main memory is prohibitively impractical for large enterprises
because they need to store six months of log data, which is the av-
erage attacker dwell time, in the main-memory to provide real-time
causal analysis. For example, NEC Labs America, with 191 hosts,
generated about 20 TB of audit log in six months. So 20 TB of audit
log needs to be stored in the main memory to provide real-time
causal analysis at that enterprise.
Second, all-purpose graph databases incur a lot of space overhead
to maintain every edge/vertex because they need to support most of
the graph algorithms (e.g., clustering coefficient) not just forensic
analysis algorithms. On the other hand, Swift provides causal
graph database which is optimized for forensic analysis and keeps
only forensically-relevant graph in the main memory to enable fast
alert’s causal graph generation.
Alert Correlation. Alert correlation techniques assist security
analysts by correlating similar threat alerts. Existing systems use
statistical-, heuristic-, and probabilistic-based methods [34, 67, 72]
to derive correlations between generated threat alerts. Moreover, se-
curity information and event management (SIEM) [16, 28] systems
use similar approaches for alert correlation. We argue that these
techniques are based on mere event correlations, while through
causal analysis we can establish actual system-layer dependencies
between events as provided by Swift.
3 THREAT MODEL AND ASSUMPTIONS
This work considers a large enterprise environment, comprised
of upwards of thousands of machines, that is the target of a so-
phisticated and well-funded remote attacker. The attacker follows
the pattern of rapid cyber attacks which are both fast – taking
minutes to spread through the whole enterprise and disruptive –
creating significant business disruption by establishing persistence,
privilege escalation and lateral movement.
We make the following assumptions about the environment.
We assume that there is a kernel-level causality tracker running
on each host in the enterprise (e.g., Linux Audit, LPM [31]). We
also assume the presence of one or many threat detection systems
that generate threat alerts in real-time (e.g., [1, 2, 6, 16, 70]); recall
that our solution will use causal analysis to triage, correlate, and
provide historical context to these alerts. Like other work in this
space (e.g., [40, 42, 43, 45, 53]), we assume that the causality tracker
is not compromised and that the audit logs are correct at the time
of forensic analysis. Hardware-layer or physical attacks, as well as
side-channels, are designated as out of the scope of this paper.
Figure 3: An example causal graph. The event (edge) E4 has triggered
an alert. The full graph describes the causality of the alert.
4 PRELIMINARIES
4.1 Causality Analysis
Audit logs are a set of records that provide a detailed history of the
activities that have affected an operating system. Audit support is
included in all major operating system families, such as the Linux
Audit [4] and Event Tracing for Windows (ETW) [3]. Causality
trackers incrementally parse events in these audit logs into causal
graphs of the form G =. V is a set of vertices representing
different system entities (e.g., processes, file) that are identified by
various metadata such PID and file path. E is a set of edges defined
by the 4-tuple (src, dst, t, rel) where rel is a causal relationship type
between vertex src and vertex dst that occurred at time t. Because
each threat alert in the system is an event associated with an edge
e ∈ E, a cyber analyst can issue a backward tracing query on the
causal graph to identify the root cause of e, then issue a forward
tracing query to identify other ramifications of the same attack.
Figure 3 shows the simplified causal graph generated for a threat
alert triggered by event E4, which documents a process mal.exe
initiating a network connection to IP Y.Y.Y.Y. The full graph shows
the backward trace, or provenance, of E4, revealing that mal.exe
was downloaded from IP X.X.X.X. This contextual information can
help cyber analysts to validate and investigate the generated alert.
A causal graph consists of one or more causal paths, which are
defined as follows:
Def. 1. Causal Path. A causal path P of a event ea represents a
chain of events that led to ea and chain of events induced by ea in
the future. It is a temporally ordered sequence of events and repre-
sented as P := {e1, . . . , ea, . . . , en } of length n. Each event can have
multiple causal paths where each path represents one possible flow of
information through ea.
4.2 Suspicious Influence Score
When analyzing causal paths, it is desirable to understand how the
suspiciousness of each event relates to the whole. Here, our suspi-
cion may relate purely to an event’s rarity, but may also incorporate
other knowledge sources besides frequency, such as IP blacklists
or antivirus signatures. To evaluate the suspiciousness of an entire
path, we introduce the notion of a suspicious influence score. We
say that a path exerts “suspicious influence” because it influences
the level of suspicion that we have for future events, including alert
events.
Def. 2. Suspicious Influence Score. For a causal path P :=
{e1,. . . ,ei ,. . . ,en } where the suspiciousness score for event ei is given
by AS (ei ), the suspicious influence score AS (P ) is a function that
combines the suspiciousness score of each event in the path P.
Figure 4: Example of causal graph database updates over time.
Many prior works satisfy this definition for a suspicious influence
scoring algorithm, e.g., [33, 41, 50, 51, 57]. In our approach, we
require the scoring algorithm to satisfy three specific properties:
Cumulativity, Temporality, and Monotonicity. Combined, these
properties will allow Swift to track causality in an online fashion
with a low time complexity and minimal disk operations. To better
explain these properties, we use Figure 4 as an example.
The first property, Cumulativity, means that the suspicious
influence score of a path can be calculated from the suspicious
influence score of its prefix and the suspiciousness score of its last
event. For example, in Figure 4, to calculate the suspicious influence
score of the causal path P1 = {B → A → D}, we only need to
know the suspicious influence score of P′
= {B → A} and the
suspiciousness score of event A → D. This property guarantees
that while adding new events to an existing path, Swift does not
need to backtrack the existing path to generate the suspicious
influence score for the newly extended path.
1
The second property, Temporality, means that an event can
only affect the suspicious influence score of events that happen
after it. For two events e1 = {V1 → V2} and e2 = {V2 → V3}, event
AS (e2) depends on AS (e1) only if e1 happens before e2. This is
intuitive from an information flow perspective, as V2 will not have
been inform by V1 until after e1 occurs. For example, at time T2 in
Figure 4, events A → E and A → D do not depend on event F → A
because this occurred at time T3. Therefore, we do not calculate the
suspicious influence scores AS (F → A → E) or AS (F → A → D).
The third property Monotonicity, means that when a new event
is appended to two existing paths it does not change the suspicious
influence score of the existing paths. Let P1 = {P′
1 → S → D} and
P2 = {P′
are distinct causal paths
prefixes and {S → D} is a new event shared by P1 and P2. The
monotonicity property states that if AS (P′
1 → S ) > AS (P′
2 → S )
then it must also be true that AS (P1) > AS (P2). For example in
Figure 4, if AS (B → A) > AS (C → A) at time T1 then it must
also be true that AS (B → A → E) > AS (C → A → E) at time T2.
This property helps ensure the correctness of our online causality
tracking.
2 → S → D}, where P′
and P′
1
2
5 VERTEX-CENTRIC CAUSAL GRAPH
In this section, we first explain different graph formats and de-
scribe their merits and limitations for fast causal analysis. Then,
we present the graph format used by Swift.
5.1 Graph Representation
There are two major data formats for graphs [52]. First, the Edge List
format is a collection of edges, each a pair of vertices, that captures
4
A:X.X.X.X ; B:Firefox ; C:/Downloads/mal.exeBDCAEE1E2E3E4D:mal.exe ; E:Y.Y.Y.YDBACT1DBACT2EEBADT3FCB’A’B’A’B’A’the incoming data in their arrival order. Second, the Adjacency
List format manages the neighbors of each vertex in separate per-
vertex edge arrays. In Edge Lists, the neighbors for each vertex are
scattered across the data structure, making it difficult to traverse
the graph quickly. On the other hand, in Adjacency Lists vertex
neighbors are easy to reference, making them better suited for
causal graph traversal.
In our causal graph schema, each system subject and object is
represented as a vertex in the causal graph and stored as an entry
in a key-value storage. In each key-value pair ⟨Key, V al⟩, Key is
the unique identifier representing the vertex and V al is a list of
three entries. For a vertex K this list is as follows:
(1) A list of K’s parent vertices’ unique identifiers, Lpar ents.
Each parent identifier is associated with a timestamp for the
event’s creation and the edge relationship type.
(2) A list of K’s child vertices’ unique identifiers Lchildr en. Each
child identifier is associated with a timestamp for the event’s
creation and the edge relationship type.
(3) An ordered list PAT Habnormal of the m most suspicious causal
paths that end with vertex K, sorted in order of each path’s
suspicious influence score.
This graph representation is specifically tailored towards forensic
analysis queries, i.e., backward and forward tracing queries. We use
the same graph representation for both main-memory and on-disk
storage. Recall that a major goal of Swift is to provide hierarchical
storage that can quickly query the most suspicious causal graphs.
Our graph schema supports this through the PAT Habnormal objects,
which are sorted in a descending order of their suspicious influence
scores. Note that each vertex has a set of causal paths that end at it,
even though these may be sub-paths of other paths. For example, in
Figure 4, vertex A has two paths in its PAT Habnormal, P1 = {B → A}
and P2 = {C → A}. These two paths are the sub-paths of P3 = {B →
A → D} and P4 = {C → A → D}, respectively.
5.2 Suspicious Causal Paths
For a vertex K, each path in PAT Habnormal is a tuple in the form
of (P, S, t, Rel, Rank ): P is the unique identifier of the parent vertex
of K in a given causal path; S is the suspicious influence score of
the path; t is the timestamp of the edge event P → K; Rel is edge
relationship between K and P; and Rank is the relative score ranking
of all the paths that end at P → K. In the case when multiple edges
with the same edge relationship Rel exists between two vertices,
we keep only the latest timestamp. This is because ignoring the
previous edges does not affect the correctness of forensic analysis,
as shown by previous works (e.g., [44, 55]).
We use Figure 4 as an example to explain our design of PAT Habnormal.
Note that we do not show edge relationships in this figure and rest
of the paper for simplicity although we do store edge relationships
in our schema. In Figure 4 there are three paths ending at the vertex
D, which are P1 = {B → A → D}, P2 = {C → A → D}, and
P3 = {B′ → A′ → D}. Assume the suspicious influence score
and the timestamps of P1, P2, and P3 are S1, S2, and S3 and t1,
t2, t3, respectively. If S1 > S2 > S3, then PAT Habnormal of D is
[(A, S1, t1, Rel10), (A, S2, t2, Rel2, 1), (A′, S3, t3, Rel3, 0)]. For the tu-
ple (A, S1, t1, Rel1, 0), it means that the parent of the given causal
path is A, its suspicious influence score is S1, the event A → D
5
Algorithm 1: PathDiscover
Inputs :V , R, Seen
Output: PAT H
5
return N ull
1 Par ent = GetParent(V ,R)
2 if Par ent = N ull then
3
4 if Par ent ∈ Seen then
return N ull
6 Seen ← Par ent
7 Par ent Rank = GetRank(V ,R)
8 PAT H = PathDiscover(Par ent,Par ent Rank, Seen)
9 Append(PAT H ,Par ent)
10 return PAT H
happens at time t1 with edge relationship Rel1 and its suspicious
score ranks the first among all paths which have the last edge as
A → D.
The number of paths that end
Limiting the Size of PAT Habnormal
at each vertex is exponential to the number of vertices. Maintaining
a PAT Habnormal that contains all paths is not realistic. To address
this limitation, in our design of Swift, the length of PAT Habnormal
is limited to m. Limiting the size of PAT Habnormal means that for
each vertex in the causal graph, Swift only keeps the top m most
suspicious paths that end at that vertex in memory. Note that this
does not affect the completeness of the whole causal graph since
the complete parent and child list for each vertex is maintained on
disk. It only affects the paths that can be retrieved quickly from the
main memory. Based on the Hypothesis H2, these suspicious paths
are more likely to represent attacks. Thus, it is reasonable for us to
limit the size of PAT Habnormal for each vertex.
5.3 Graph Query
Our design of the causal graph schema and database allows fast
recovery of a causal path with the unique identifier of its last vertex
and its index in PAT Habnormal. The time complexity of the recover-