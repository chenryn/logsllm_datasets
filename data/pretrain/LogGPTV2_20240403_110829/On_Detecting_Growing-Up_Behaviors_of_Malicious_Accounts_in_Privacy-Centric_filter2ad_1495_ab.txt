profiles and posts. Even with restricted access by default, WeChat
does allow users to opt-in to various public services to interact with
strangers. As a result, malicious users often excessively use these
kinds of services to carry out phishing campaigns.
2.3 Growing-up Accounts
Due to the stricter account and content access restrictions com-
pared with traditional OSNs, malicious users in PC-MSNs need to
build large social groups to conduct effective malicious campaigns
listed in Section 2.2. Therefore, upon registration, these accounts
are not employed to launch campaigns immediately. Instead, they
pretend to be benign to gradually enlarge their social spheres by
building connections with other benign accounts and joining their
communities. When the time elapses, these growing-up accounts
start malicious campaigns. Take our dataset from WeChat as an
example, we find less than 10% of malicious accounts performed
obvious malicious campaigns (e.g., click farm, spam, and phishing)
during the first week after registration, i.e., over 90% of them can
be classified as growing-up accounts. The attacking philosophy of
growing-up accounts is similar to that of the Advanced Persistent
Threat (APT) where malware intruded into a system stealthily op-
erates normally for a while before launching attacks. In this paper,
our goal is to design a robust unsupervised learning method to
detect growing-up accounts in the growing-up stage before they
engage in obvious malicious activities.
3 OBSERVATIONS: GROWING-UP ACCOUNTS
IN WECHAT
In this section, we analyze the account behaviors in various do-
mains and explore the pattern differences among typical malicious
accounts, growing-up accounts, and benign accounts from Wechat2.
3.1 Dataset
We obtain an anonymized dataset from WeChat, which contains
the first-week action records after registration of around 440k ac-
counts. Each record consists of five fields: universal unique identi-
fier (UUID), action type, timestamp, IP address, and client version.
Specifically, each (anonymous) UUID is associated with an account.
Different action records could have the same UUID but with dif-
ferent action types or timestamps. There are more than 100 action
types in our dataset. Timestamp is the time an account performs
an action.
In our dataset, there are around 300k malicious accounts and
140k benign accounts. The labels are provided and verified by the
WeChat security team. We filter to get 24k typical malicious ac-
counts that have shown obvious malicious behaviors as described in
Section 2.2 in the first week after registration. These accounts pose
strong malicious intents and are easily detected by off-the-shelf
2We performed experiments at WeChat who anonymized the dataset to the extent
that the dataset is just enough for our study.
299ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3
Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5
(a)
(b)
Figure 1: (a) CDF of the number of used IP addresses; (b) The
number of accounts sharing each IP address.
behavior-based detection methods. The remaining 276k malicious
accounts are growing-up accounts that show no particular mali-
cious intends during the first week but are labeled for their later
malicious campaigns. Next, we will investigate the behavior pat-
terns and explore the differences among typical malicious accounts,
growing-up accounts, and benign accounts.
Ethical and privacy considerations. The collected data are spec-
ified in WeChat’s privacy policy, to which a user consents before
using WeChat. Moreover, to protect user privacy, WeChat has
anonymized attributes before being submitted to WeChat’s servers.
Specifically, each account is represented by a 32-bit random integer
without account-specific information. Besides, the last four digits of
a phone number are removed and the IP address is hashed segment
by segment. All datasets were stored on WeChat’s on-prem servers
and we accessed them through an internship program.
3.2 Behavior Patterns
IP address. The IP address is an important source to target growing-
up accounts since they are geographically meaningful. We aim to
study two questions: (i) How many IP addresses one account has
ever used? This answer indicates the mobility of the account. (ii)
How many accounts have ever used the same IP address? This
answer indicates the aggregation of accounts.
To answer the first question, we calculate the set of IP addresses
used by each account. For individual accounts, we inspect the ac-
count cumulative distribution function (CDF) of the number of IP
addresses they used (see Figure 1a). We observe that typical ma-
licious accounts are more likely to use a larger range number of
IP addresses, while growing-up accounts tend to use a small set of
IP addresses. The number of IP addresses used by benign accounts
is between that of malicious accounts and growing-up accounts.
Intuitively, benign accounts use a small set of IP addresses because
they have fixed daily routines and therefore tend to stay in a rela-
tively small number of places. Malicious accounts may maintain a
large IP pool to ensure the diversity of IP address and frequently
switch the IP address to evade IP-based detection or blacklisting.
However, growing-up accounts would pretend to be benign in the
early growing-up period and tend to reduce the number of activities,
resulting in using a relatively small number of IP addresses.
To answer the second question, we calculate the number of
accounts that use a specific IP address and show the results in
Figure 1b. We observe that growing-up accounts tend to frequently
reuse IP addresses, while benign accounts rarely share IP addresses.
We find that only around half a thousand IP addresses are used by
Figure 2: CDF of client versions. Higher indexes correspond
to more recent versions.
more than a hundred growing-up accounts, while this number for
benign accounts is merely half a dozen.
There are two possible reasons for a large number of accounts
using the same IP address. The first reason is that Internet service
providers often adopt network address translation (NAT) when
providing customers the Internet access. Thus, nearby accounts
using the same Internet service provider are likely to be mapped
to the same public IP. This explains why a small number of benign
accounts share the IP address. We manually inspect that these IP
addresses are all located in the big cities. The second reason is that
many accounts could use the same physical Internet access point,
which has a fixed IP address. Actually, this is a common way that
growing-up accounts conduct malicious activities, e.g., they keep
switching from one malicious account to another one on a phone.
Client version. Malicious users usually leverage automated scripts
or machines to boost the efficiency of malicious activities. This
method usually has special requirements on the client versions.
Here, we inspect the distribution of client versions of typical mali-
cious accounts, growing-up accounts, and benign accounts.
We note that not all client versions are equally prevalent. We
select the versions that include most of the action records in our
dataset and find that more than 99% of action records of all accounts
are generated from clients with less than a hundred versions. We
further investigate the account distribution of these main client
versions. Specifically, we calculate the number of accounts that
use each client version. We obtain the CDF curve from the oldest
version to the latest version. Figure 2 shows the CDF curves of
malicious accounts, growing-up accounts, and benign accounts. We
observe that malicious accounts and growing-up accounts tend to
use old versions more often, e.g., more than 20% of malicious ac-
counts and growing-up accounts use the oldest 33% client versions,
while less than 4% of benign accounts use these versions. This ob-
servation implies that malicious accounts and growing-up accounts
are restricted by certain outdated client versions. One reason is that,
due to limited resources, malicious users use automated scripts or
machines with certain client versions to control various accounts
at the same time. To reduce the costs, once the scripts are set up,
malicious users are not willing to adapt these scripts to the new
versions, as the user interfaces and the logic of interaction may also
change in the new versions.
Action type. Compared with the IP address and client version, ac-
tion types can reflect more detailed information about accounts. For
instance, a sociable user tends to send out a great number of friend
requests, hence frequently performing the "send friend request"
action; a retailer uses the payment service quite often and thus
100101Number of IP addresses0.00.20.40.60.81.0CDFMaliciousBenignGrowing-upOldNewClient version0.00.20.40.60.81.0CDFMaliciousBenignGrowing-up300On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Figure 3: (a) Top-10 growing-up accounts related actions; (b) Top-10 benign accounts related actions.
(a)
(b)
to personal profiles. Therefore, growing-up accounts can hardly
connect with benign accounts. However, chatroom service provides
a good opportunity. To enter a chatroom, one can be directly invited
by a friend, scan the chatroom QR code, or click the link shared
by chatroom members. Many QR codes and invitation links are
available in public. In this way, growing-up accounts can easily get
in touch with a bunch of benign accounts in a short period. More-
over, large chatrooms are usually created for people with the same
interest, e.g., swimming clubs. If malicious users enter chatrooms of
online gaming fans, they can precisely deliver their advertisements
or phishing messages. Third, the most significant action for benign
accounts is to add others as friends, which is consistent with the
role of WeChat as an OSN. We also note that other dominating
actions involve interactions between accounts, i.e., commenting
on others’ posts or getting comments from others. These kinds of
actions are hard to manipulate since script-controlled growing-up
accounts have few active friends, hence having fewer number of
posts to comment on.
4 DESIGN
4.1 Overview
Our large-scale analysis of growing-up accounts does reveal that
the behavior patterns of growing-up accounts are quite different
from typical malicious accounts in several domains, while growing-
up accounts and benign accounts behave very similarly. Existing
behavior-based detection techniques are unable to detect such
growing-up accounts because they cannot capture the slight dif-
ferences between growing-up accounts and benign accounts (see
Section 5.2). In this paper, we aim to design a robust unsuper-
vised method to capture these differences and detect growing-up
accounts.
Figure 5 is the overview of our method Muses. Muses includes
four components: account-behavior bigraph construction, account-
account graph construction, unsupervised maliciousness assessment,
and growing-up account detection. Specifically, Muses first constructs
account-behavior bigraph for each behavior (i.e., account-IP bi-
graph, account-version bigraph, and account-action bigraph). Then,
in each account-behavior bigraph, Muses performs a random walk
from each account and captures the correlation between each ac-
count and the attributes of the behavior. Muses further builds an
account-account graph for each behavior to model the similarity
between accounts from each behavior’s perspective. Next, in each
account-account graph, Muses adopts a community detection algo-
rithm to group the accounts into communities, and utilizes a novel
Figure 4: Account CDF of action counts.
performs the "transfer money" action frequently. In our dataset, we
observe that the number of action records for each account varies
from dozens to tens of thousands. We first study the distribution
of the action count of all accounts. Specifically, we calculate the
number of accounts that perform a certain number of actions and
then draw the CDF curve. Figure 4 shows the CDF curves of the
number of actions. We observe that around 90% of growing-up
accounts have less than 100 actions, while the percentage of benign
accounts is around 75% and malicious accounts is about 15%. Com-
mon techniques often tend to classify accounts acting frequently
and monotonously as malicious ones. Thus, a straightforward way
for a growing-up account to pretend to be a benign one is to re-
duce its activities. Meanwhile, growing-up accounts are difficult to
build connections with other benign accounts, resulting in fewer
interactions with other accounts and a relatively small number of
actions.
Next, we focus on studying accounts that have a relatively large
number of action records. Specifically, we select 1,000 benign ac-
counts and 1,000 growing-up accounts that have the largest number
of action records. For each action type, we first compute the fre-
quency each selected account has performed this action, and then
calculate the average number among the selected benign accounts
and growing-up accounts, respectively. Figure 3a shows ten action
types in which growing-up accounts outnumber benign accounts
more than 2 times, which mainly include joining and quitting chat-
rooms. Figure 3b shows ten action types in which benign accounts
outnumber growing-up accounts more than 2 times, which mainly
include adding friends with others, commenting on other posts,
and setting aliases for each other.
According to these results, we have several key observations.
First, we observe that benign accounts and growing-up accounts
have different preferred actions. Second, growing-up accounts per-
form chatroom-related action types more often. Since PC-MSNs aim
to protect user privacy, they put a high restriction on public access
050100150200250Average action number of the selected accountsA10A9A8A7A6A5A4A3A2A1Growing-upBenign0100200300400Average action number of the selected accountsB10B9B8B7B6B5B4B3B2B1Growing-upBenign101102103The number of action count0.00.20.40.60.81.0CDFGrowing-upMaliciousBenign301ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3
Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5
Figure 5: Overview of Muses.
metric to adaptively evaluate the maliciousness of each community
in an unsupervised way. Our metric is based on the variance of
the account degree distribution of all accounts in a community and
assigns an equal score to every account. Finally, Muses assigns a
malicious score to each account by combining the scores from all
account-account graphs and detects growing-up accounts based on
the score.
In particular, Muses is designed to be robust against various
evasion attacks that aim at manipulating account behaviors to
bypass detection. The robustness of Muses stems from the following
three aspects. First, Muses constructs the bigraph for each type of
behavior. These bigraphs capture the characteristics of growing-up
accounts from different perspectives. Thus, when an attacker tries to
manipulate a certain behavior, e.g., modifying IP addresses of some
growing-up accounts, it would have little impact on the malicious
scores generated from other behaviors (therefore having minimal
impact on detection). Second, Muses assigns the malicious score
by considering all accounts in a community instead of individual
accounts. As a result, even if a fraction of growing-up accounts in a
community modified their attribute values, Muses can still identify
these accounts. Third, Muses determines the final malicious score
for each account by combining scores of all behaviors. Similarly,
a growing-up account manipulating a certain behavior has little
impact on other behaviors.
However, it is challenging to design Muses. First, it is difficult to
identify correlations among these attributes for bigraph construc-
tion since different behavior attributes have large value ranges.
Second, according to the built bigraph, it is not easy to find cor-
relations among growing-up accounts because most attributes of
these accounts in bigraph are not popular while the popular at-
tributes dominate the results of the random walk. Third, traditional
community-based detection is insufficient to detect growing-up
accounts since growing-up accounts have similar attributes to be-
nign ones and they are always mixed in the same communities. We
address these challenges in the following designs.
4.2 Account-Behavior Bigraph Construction
To capture the relationship between accounts and behavior at-
tributes, we construct a bigraph for each behavior domain, i.e., IP
address, client version, and action count. Each node in the bigraph
represents either an account or an attribute of a behavior. Each edge
between an account and an attribute means the account has the
attribute. For instance, if a user registers an account A with an IP
"192.168.1.1", then there is an edge between A and "192.168.1.1" in
the account-IP bigraph. Accordingly, we denote these bigraphs as
account-IP bigraph, account-version bigraph, and account-action bi-
graph, respectively. We develop a novel dynamic segmentation tech-
nique to construct the account-IP and account-version bigraphs, and
an exponential segmentation technique to construct the account-
action bigraph. By using these two techniques, we can aggregate
attributes of the accounts to effectively identify similar behavior’s
attributes even though the attributes have large value ranges, which
also reduces the computational and storage cost.
Dynamic segmentation. As we discussed in Section 3, the num-
ber of accounts that share the same IP address or client version