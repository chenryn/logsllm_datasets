m
o
c
#
 600
 500
 400
 300
 200
 100
 0
O0
O1
O2
O3
O0
O1
O2
O3
O0
O1
O2
O3
O0
O1
O2
O3
O0
O1
O2
O3
O0
O1
O2
O3
Figure 4: Prevalence of complex constructs in SPEC CPU2006 binaries.
the targeted main function bodies as multi-entry targets.
In binaries compiled with gcc and clang, we found up
to 18 multi-entry jumps for C code, and up to 64 for C++,
with the highest prevalence in x64 binaries. Visual Studio
produced up to 172 multi-entry jumps for C, and up to
88 for C++, the construct being most prevalent in x86
code. This kind of multi-entry function is handled well by
disassemblers in practice, producing no notable decrease
in disassembly accuracy compared to other functions.
Tailcalls form the most prevalent complex case, and
do negatively affect function start detection if the target
function is never called normally (see Section 3.1.1). The
largest number of tailcalls (listed as tailcall jumps in Fig-
ure 4) is found in clang x64 C++ binaries, at a mean
of 545 cases. Visual Studio produces a similar number
of tailcalls. For clang, the number of tailcalls peaks at
optimization level O1, while Visual Studio peaks at O3.
For clang (and to a lesser extent gcc), higher optimiza-
tion levels can lead to a decrease in tailcalls through other
modiﬁcations like code merging and code elimination.
Jump tables (due to switches) are by far the most com-
mon case of inline data. They occur as inline data only
on Visual Studio (gcc and clang place jump tables in
the .rodata section). As seen in Section 3.1.1, inline
data causes false positive instructions especially in linear
disassembly (peaking at 0.56% false positives).
Another challenge due to jump tables is locating all
case blocks belonging to the switch; these are typically
reached indirectly via a jump that loads its target ad-
dress from the jump table. Linear disassembly covers
100% of case blocks correctly on gcc and clang (see
Section 3.1.1), and also achieves very high accuracy for
Visual Studio. The best performing recursive disassem-
blers, most notably IDA Pro, also achieved very high
coverage of switch/case blocks; coverage of these blocks
is comparable to the overall instruction/basic block recov-
ery rates. This is because many recursive disassemblers
have special heuristics for identifying and parsing stan-
dard jump tables.
3.1.4 Optimizing for Size
At optimization levels O0–O3, no overlapping or shared
basic blocks occur. A reasonable hypothesis is that com-
pilers might more readily produce such blocks when op-
timizing for size (optimization level Os) rather than for
performance. To verify this, we recompiled the SPEC C
and C++ benchmarks with size optimization, and repeated
our disassembly tests.
Even for size-optimized binaries, we did not ﬁnd any
overlapping or shared blocks. Moreover, the accuracy of
the instruction boundaries, callgraph and ICFG did not
signiﬁcantly differ from our results for O0–O3. Function
starts and argument lists were comparable in precision to
those for performance-optimized binaries (O2–O3).
3.2 Shared Library Objects
This section discusses our disassembly results and com-
plex case analysis for library code. Libraries are often
highly optimized, and therefore contain more complex
(handcrafted) corner cases than application code. We fo-
cus our analysis on glibc-2.22, the standard C library
used in GNU systems, compiled in its default conﬁgura-
tion (gcc with optimization level O2). This is one of the
most widespread and highly optimized libraries, and is
often cited as a highly complex case [5, 23].
3.2.1 Disassembly Results
Table 2 shows disassembly results for glibc-2.22, for
all tested disassemblers that support 64-bit ELF bina-
ries. Nearly all disassemblers display signiﬁcantly lower
592  25th USENIX Security Symposium 
USENIX Association
10
Instructions
u
F
nctions
Signatures
G
F
IC
h
Callgrap
gcc-5.1.1 x64
angr 64.4 75.6 — 70.2 87.9
BAP 65.3 79.6 — 72.4 84.8
ByteWeight — 29.3 — — —
Dyninst 79.7 85.2 — 87.6 95.5
Hopper 84.3 93.3 — 90.6 93.9
IDA Pro 96.0 92.0 5.4 99.9 99.9
Linear 99.9 — — — —
Table 2: Disassembly results for glibc (% correct).
accuracy on instruction boundaries than the mean for ap-
plication binaries in equivalent compiler conﬁgurations.
Only IDA Pro and linear disassembly are on par with their
performance on application code, achieving very good
accuracy without any false positives. Note that objdump
achieves 99.9% accuracy instead of the usual 100% for
ELF binaries. This is because unlike IDA Pro, it does not
explicitly separate the overlapping instructions that occur
in glibc (see Section 3.2.2).
Function start results are on par with, or even exceed
the mean for application binaries; this holds true for all
disassemblers. Moreover, the accuracy of function argu-
ment lists (5.4%) is much higher than one would expect
from the x64 SPEC CPU2006 results (under 1% accu-
racy). This is because IDA Pro comes with a set of code
signatures designed to recognize standard library func-
tions that are statically linked into binaries.
For the ICFG, we see the same pattern as for instruc-
tions: all disassemblers perform worse than for applica-
tion code, while IDA Pro delivers comparable accuracy.
Callgraph accuracy is below the mean for most disassem-
blers, though IDA Pro and Dyninst perform very close to
the mean, and BAP well exceeds it.
3.2.2 Complex Constructs
Overall, we found the glibc-2.22 code to be surpris-
ingly well-behaved. Our analysis found no overlapping
or shared basic blocks, and no inline data. Indeed, the
glibc developers have taken special care to prevent this,
explicitly placing data and jump tables in the .rodata
section even when manually declared in handwritten as-
sembly code. Prior work has analysed earlier versions
of glibc, showing that inline jump tables are present in
glibc-2.12 [23]. Moreover, inline zero-bytes used for
function padding are conﬁrmed in versions up to 2.21.
This is worth noting, as older glibc versions may still be
encountered in practice. Our analysis of glibc versions
ranging from 2.12 to 2.22 shows consistently improving
disassembler-friendliness over time.
We did ﬁnd some complex constructs that do not occur
in application code, the most notable being overlapping
7b05a:
7b063:
7b065:
cmpl
je
lock cmpxchg %rcx,0x3230fa(%rip)
$0x0,%fs:0x18
7b066
Listing 6: Overlapping instruction in glibc-2.22.
e9a30 :
e9a30:
e9a37:
cmpl
jne
$0x0,0x2b9da9(%rip)
e9a4c 
e9a39 :
%rcx,%r10
$0x113,%eax
e9a39:
e9a3c:
e9a41:
e9a43:
e9a49:
e9a4b:
e9a4c:
e9a50:
[...]
mov
mov
syscall
cmp
jae
retq
sub
callq
$0xfffffffffffff001,%rax
e9a7f 
$0x8,%rsp
f56d0 
Listing 7: Multi-entry function in glibc-2.22.
instructions. We found 31 such instructions in glibc. All
of these are instructions with optional preﬁxes, such as the
one shown in Listing 6. These overlapping instructions
are deﬁned manually in handcrafted assembly code, and
typically use a conditional jump to optionally skip a lock
preﬁx. They correspond to frequently cited complex cases
in the literature [5, 23].
In addition, we found 508 tailcalls resulting from the
compiler’s normal optimization; a number comparable
to application binaries of similar size as glibc. We also
found signiﬁcantly more multi-entry functions than in
the SPEC benchmarks. Most of these belong to the
nocancel family, explicitly deﬁned in glibc, an ex-
ample of which is shown in Listing 7. These functions
provide optional basic blocks which can be preﬁxed to
the main function body to choose a threadsafe variant of
the function. These preﬁx blocks end by jumping over
the prologue of the main function body, a pattern also
sometimes seen in application code.
Given that all non-standard complex constructs in
glibc are due to handwritten assembly, we manually
analyzed all assembly code in libc++ and libstdc++.
However, the amount of assembly in these libraries is
very limited and revealed no new complex constructs.
This suggests that the optimization constructs in glibc
are typical for low-level libraries, and less common in
higher-level ones such as the C++ standard libraries.
3.3 Static Linking & Linker Optimization
Static linking can reduce disassembler performance on
application binaries by merging complex library code into
the binary. Link-time optimization performs intermodu-
lar optimization at link-time, as opposed to more local
compile-time optimizations. It is a relatively new feature
that is gaining in popularity, and could worsen disassem-
bler performance if combined with static linking, by opti-
mizing application and library code as a whole. To study
USENIX Association  
25th USENIX Security Symposium  593
11
Instructions
u
F
nctions
Signatures
G
F
IC
h
Callgrap
Control-Flow Integrity, (2) Decompilation, and (3) Auto-
matic bug search. A detailed comparison of our results to
assumptions in the literature is given in Section 5.
gcc-5.1.1 x64 with -static
SPEC/C O0 96.2 69.4 0.1 98.3 98.2
SPEC/C O1 96.2 68.4 0.2 98.6 98.4
SPEC/C O2 95.5 67.1 0.2 98.8 98.9
SPEC/C O3 95.6 65.7 0.2 98.7 98.7
SPEC/C Os 95.9 67.8 0.2 98.7 98.4
gcc-5.1.1 x64 with -static and -ﬂto
SPEC/C O0 96.3 69.3 0.2 98.5 98.3
SPEC/C O1 96.0 68.6 0.3 98.6 98.4
SPEC/C O2 95.0 67.4 0.3 98.3 98.0
SPEC/C O3 95.2 66.9 0.3 98.3 98.4
SPEC/C Os 95.5 67.8 0.2 98.4 97.7
Table 3: IDA Pro 6.7 disassembly results for static and
link-time optimized SPEC C benchmarks (% correct, ge-
ometric mean).
the effects of these options, we recompiled the SPEC
CPU2006 C benchmarks, statically linking them with
glibc-2.22 using gcc’s -static ﬂag. Subsequently,
we repeated the process with both static linking and link-
time optimization (gcc’s -flto) enabled.
As expected, static linking merges complex cases from
glibc into SPEC, including overlapping instructions.
The effect on disassembly performance is shown in Ta-
ble 3 for IDA, the overall best performing disassembler in
our glibc tests. The impact is slight but noticeable, with
an instruction accuracy drop of up to 3 percentage points
compared to baseline SPEC; about the same as for glibc.
As can be seen in Table 3, link-time optimization does not
signiﬁcantly decrease disassembly accuracy compared to
static linking only.
Function start detection suffers from static linking
mostly at lower optimization levels, dropping from a
mean of 80% to just under 70% for O0; at level O3 the per-
formance is not signiﬁcantly reduced. Again, link-time
optimization does not worsen the situation compared to
pure static linking. For the ICFG and callgraph tests, a
small accuracy drop is again seen at lower optimization
levels, again with no more adverse effects due to link-time
optimization. For instance, ICFG accuracy drops from
close to 100% mean in baseline SPEC to just over 98%
in statically linked SPEC at O0, while the results at O2
and O3 show no negative impact. We suspect that this is
a result of optimized library code being linked in even
at lower optimization levels. Overall, we do not expect
any signiﬁcant adverse impact on binary-based research
as link-time optimization gains in popularity.
4
Implications of Results
This section discusses the implications of our results for
three popular directions in binary-based research: (1)
4.1 Control-Flow Integrity
Control-Flow Integrity (CFI) is currently one of the most
popular research directions in systems security, as shown
in Table 6. Binary-level CFI typically relies on binary
instrumentation to insert control ﬂow protections into pro-
prietary or legacy binaries [1, 10, 24, 29, 41, 45, 46, 48].
Though a wide variety of CFI solutions has been proposed,
most of these have similar binary analysis requirements,
due to their common aim of protecting indirect jumps,
indirect calls, and return instructions. We structure our
discussion around what is needed to analyze and protect
each of these control edge types.
Indirect calls. Typically, protecting an indirect call
requires instrumenting both the call site (the call in-
struction itself, possibly including parameters), and the
call target (the called function). Finding call sites relies
mainly on accurate and complete disassembly of the ba-
sic instructions. As shown in Figure 2a, these can be
recovered with extremely high accuracy, even 100% ac-
curacy for linear disassembly on gcc and clang binaries.
Thus, a binary-level CFI solution is unlikely to encounter
problems analyzing and instrumenting call sites.
For Visual Studio binaries, there is a chance that a small
percentage of call sites may be missed. Depending on the
speciﬁc CFI solution, it may be possible to detect calls
from uninstrumented sites in the target function, trigger-
ing a runtime error handling mechanism (see Section 5).
Since these cases are rare, it is then feasible to perform
more elaborate (slow path) alternative security checks.
The main challenge is to accurately detect all possible
target functions for each indirect call. As a basic prereq-
uisite, this requires ﬁnding the complete set of indirectly
called functions. As shown in Section 3.1.1 and Figure 2b,
this is one of the most challenging problems in disassem-
bly — at high optimization levels, 20% or more of all
functions are routinely missed.
Moreover, ﬁne-grained CFI systems must perform even
more elaborate analysis to decide which functions are le-
gal targets for each indirect call site. Overestimating the
set of legal targets leads to attacks which redirect indirect
calls to unexpected functions [12]. Matching call sites to
a set of targets typically requires an accurate (I)CFG, so
that control-ﬂow and data-ﬂow analysis can be performed
to determine which function pointers are passed to each
call site. Figure 2d and Sections 3.1.1–3.1.3 show that an
accurate and complete ICFG is typically available, includ-
ing accurate resolution of switch/jump tables in the best
disassemblers. Although this type of analysis remains
594  25th USENIX Security Symposium 
USENIX Association
12
extremely challenging, especially if done interprocedu-
rally (requiring accurate indirect call resolution), it is at
least not limited by the accuracy of basic blocks or direct
control edges.
Additionally, ﬁne-grained CFI systems can beneﬁt
from function signature information, to further narrow
down the set of targets per call site by matching the func-
tion prototype to parameters passed at the call site [39].
Though signature information is often far from complete
(Figure 2c), especially on x64, the information which is
available can still be useful — even with incomplete infor-
mation, the target set can be reduced, directly leading to
security improvements. However, care must be taken to
make the analysis as conservative as possible; if this is not
done, the inaccuracy of function signature information
can easily cause illegal function calls to be allowed, or
worse, can cause legal calls to be inadvertently blocked.
Indirect jumps. Protecting indirect jumps requires
analysis similar to the requirements for indirect calls.
However, as indirect jumps are typically intraprocedu-
ral, protecting them usually does not rely on function
detection. Instead, accurate switch/jump table resolution
is required, which is available in disassemblers like IDA
Pro (Section 3.1.3).
Return instructions. Return instructions are typi-
cally protected using a shadow stack, which requires in-
strumenting all call and return sites (and jumps, to handle
tailcalls) [8]. Given the accurate instruction recovery pos-
sible with modern disassemblers (Figure 2a), it is possible
to accurately and completely instrument these sites.
Summarizing, the main challenge for modern CFI lies
in accurately and completely protecting indirect call sites.
The reasons for this are twofold: (1) Function detection
is one of the most inaccurate primitives (especially for
indirectly called functions), even in state of the art disas-
semblers, and (2) It is currently very difﬁcult to recover
rich information, such as function signature information,
through disassembly. This makes it extremely challenging
to accurately couple indirect call sites with valid targets.
4.2 Decompilation
Instead of translating a binary into assembly instructions,
decompilers lift binaries to a higher-level language, typ-
ically (pseudo-) C. Decompilers are typically built on
top of a disassembler, and therefore rely heavily on the
quality of the disassembly [33, 44].
As most decompilers operate at function granularity,
they rely on accurate function start information. More-
over, they must translate all basic blocks belonging to
a function, requiring knowledge of the function’s CFG.
In effect, this requires not only accurate function start
detection, but accurate function boundary detection. As
described in related work, function boundary detection
is even more challenging than function start detection, as
it additionally requires locating the end address of each
function [4]. This is difﬁcult, especially in optimized bi-
naries, where tailcalls often blur the boundaries between
functions (since the jmp instructions used in tailcalls can
easily be mistaken for intraprocedural control transfers).
In addition to function detection, decompilers rely on
accurate instruction disassembly, and can also greatly
beneﬁt from function signature/type information. More-
over, switch detection is required to correctly attribute all
switch case blocks to their parent function. Finally, call-
graph information is useful to understand the connections
between decompiled functions.
The impact of inaccuracies for decompilation is not
as severe as for CFI systems, since decompiled code is
typically intended for use in manual reverse engineering