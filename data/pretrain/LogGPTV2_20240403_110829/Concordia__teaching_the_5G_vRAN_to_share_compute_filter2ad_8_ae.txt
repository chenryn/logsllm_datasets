Offloading vRAN tasks to hardware accelerators: The focus of
this paper has been on vRAN deployments that fully rely on CPUs
for signal processing. However, in many practical scenarios hardware
accelerators (e.g. FPGAs, GPUs) could be used to offload heavy tasks
like LDPC encoding/decoding [48] to reduce processing latency and
to improve energy efficiency.
(a) Processing overhead of Concor-
dia WCET predictor and scheduler
for a varying number of cells
(b) Effect of TTI deadline param-
eter on tail latency and reclaimed
cores (20MHz cell configuration)
Figure 15: Characteristics of Concordia scheduler
is almost equally effective to the quantile decision tree in predicting
deadlines, and much better than the linear model. However, as shown
in Fig. 14a, the quantile decision tree has the smallest average WCET
prediction error when deadlines are met (43us), making it the most
efficient of all studied algorithms. Given the lack of space, please see
Appendix A.2 for additional prediction accuracy results of other com-
putationally intensive signal processing tasks. It should be noted that
while the prediction accuracy for individual tasks is not 0.99999, the
Concordia scheduler compensates for any misprediction by updating
its scheduling decision every 20 ùúás. This results in 99.999 reliability
for the full DAG execution, as shown if Fig. 14a and in Section 6.2.
6.5 Concordia scheduler characteristics
Execution times: The Concordia scheduler runs once every 20 ùúás
and the WCET predictor once every TTI slot, so they have to be very
fast. We evaluate their execution time while varying the number of
cells from 1 to 7. As shown in Fig. 15a, their overhead increases
linearly with the number of cells, since the number of tasks being pro-
cessed scales the same way. The scheduler runs on the timer thread,
but as its overhead for up to 7 cells remains always below 2 ùúás, it can
run every 20 ùúás without any issues (it is also possible to multiplex
the scheduler with other tasks on the timer core, such as processing
the incoming fronthaul packets). The total overhead of the WCET
predictions grows from 4 ùúás for 1 cell to 24 ùúás for 7 cells. This is less
than 0.2% of the overall vRAN pool processing time per TTI slot
(and as it runs on the vRAN pool cores as discussed in Section 5, it
doesn‚Äôt block the timer thread).
Effect of TTI deadline: Next, we study the effect of the signal pro-
cessing DAG deadline to the performance of the vRAN and the
number of reclaimed cores. We consider as an example the 20MHz
7 cell configuration of Table 2, with a cell traffic load of 25% of the
max designated capacity. As it can be seen in Fig. 15b, the shorter
the deadline is, the lower the tail TTI processing latency gets at the
expense of a lower number of reclaimed CPU cores. Similar obser-
vations can be made for other cell configurations (omitted due to
lack of space). The DAG deadline can therefore be used to tune the
performance of the vRAN with different values providing a tradeoff
between the vRAN reliability (e.g. 99.99% or 99.999%) and the
percentage of reclaimed vRAN pool CPU cycles.
# cells Minimum # CPU cores
1
2
3
1
3
4
Average CPU utilization
58.2%
46.6%
58.7%
Table 3: vRAN pool CPU requirements for 100MHz TDD cell
configuration (1.6Gbps DL, 150Mbps UL per cell) and FPGA
LDPC acceleration
To understand the impact of accelerators to the benefits of Con-
cordia, we extended our FlexRAN testbed with a server (Intel Xeon
W-2295 @ 3GHz, Ubuntu 18.04 lowlatency kernel) equipped with an
FPGA (Terasic DE5-Net) for offloading LDPC encoding/decoding
tasks. We profile the vRAN performance for peak traffic and measure
the minimum number of vRAN pool cores required to support the
vRAN, as well as their utilization for a varying number of 100MHz
TDD cells. As shown in Table 3, the FPGA use enables support for
more cells with higher traffic loads on the same number of CPU cores
compared to the scenarios studied in Section 6. However, the CPU
Average processing time
of non-offloaded tasks (ùúás)
515
196
Average total processing
time of single slot (ùúás)
1414
366
Uplink
Downlink
Table 4: Average processing times for uplink/downlink slot of
single cell (including FPGA acceleration) and for non-offloaded
tasks (excluding FPGA acceleration) on 1 CPU core.
utilization still remains below 60% in all cases. This underutilization
of the cores even at peak capacity happens for two main reasons:
‚Ä¢ Time division multiplexing As in the case of non-accelerated
configurations, the time division multiplexing of cells creates idle
periods for the vRAN pool cores, since the downlink processing time
is significantly lower compared to the uplink for the non-offloaded
tasks. This can be seen in Table 4 for the single cell case of the
scenario under study, where the average total pool CPU core time
spent on the non-offloaded uplink processing tasks is more than 2.5
times higher than the downlink, even though the downlink traffic
volume is an order of magnitude higher.
‚Ä¢ Offload processing wait times Due to the dependencies of
the tasks in the DAG structures of the signal processing chains, the
worker threads running on the vRAN pool cores have periods when
they cannot make any progress and therefore have to block, waiting
for the completion of FPGA offloaded tasks. As shown in Table 4,
the average total processing time of a single uplink slot (including
the FPGA processing time) is ‚àº2.5 times higher than the average
processing time for the non-offloaded tasks executed on the allocated
vRAN pool core. Their difference matches the time that the vRAN
pool worker thread had to block, waiting for the offloaded tasks to
be completed. Similar observations can be made for the downlink,
where the total slot processing time is ‚àº1.9 times higher than the
processing time of the non-offloaded tasks.
590
246Number of cells0510152025Processing time (us)Concordia SchedulerConcordia WCET Predictor160018002000TTI Deadline (us)1.601.621.6499.999% processing latency1e30102030405060Reclaimed CPU (%)SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Xenofon Foukas and Bozidar Radunovic
The aforementioned observations demonstrate that there are signif-
icant opportunities for reclaiming vRAN CPU cores even in the
presence of hardware accelerators. We plan to extend Concordia to
accommodate such scenarios. This can be achieved by extending Con-
cordia‚Äôs WCET predictor to also predict the WCET of the offloaded
tasks, as well as by adapting Concordia‚Äôs scheduler to factor in the
idle periods arising from the offloading of the tasks, e.g., by creating
separate DAGs for the tasks running before/after the offloaded tasks
and adjusting the deadlines of those DAGs appropriately.
Extending Concordia for other workloads: Throughout this work,
we assumed that the vRAN is the high priority workload, with a
maximum scheduling priority. All other workloads are considered as
best-effort and as such can be pre-empted by the vRAN at any point
in time. Based on this, the focus of this work has been on providing
predictions specifically targeting the physical layer signal processing
vRAN tasks. However, the techniques used by Concordia could be
generalized to also apply to other task-based deadline-constrained
workloads across the protocol stack of the vRAN, as well as to applica-
tions running as part of a (near) real-time RAN intelligent controller
for the optimization of the RAN radio resources [2, 36, 38, 73].
One characteristic example is the MAC layer of the vRAN, which
is responsible for the scheduling of radio resources to mobile devices.
The schedulers of the MAC layer (e.g. uplink, downlink, broadcast
etc.) can be viewed as deadline tasks that can be processed by a
vRAN pool, similar to the signal processing tasks of the physical
layer. In fact, this is the approach proposed by Intel as a best practice
for the L2 of FlexRAN [62]. Moving towards 5G networks and be-
yond, the processing requirements of the MAC layer increase. For
example, the introduction of Massive MIMO increases the schedul-
ing complexity, which can greatly fluctuate depending on the number
of scheduled users and their mapping to antennas [14]. The WCET
prediction capabilities of Concordia could allow the vRAN MAC to
be multiplexed with other workloads.
The proposed schemes of Concordia could be extended and ap-
plied to other domains with latency sensitive characteristics, like
AR/VR workloads [55, 64] and video analytics [3], where the pro-
cessing time of frames needs to be minimized to provide the optimal
experience and/or to actuate some other system (e.g. traffic lights).
8 RELATED WORK
vRAN resource management: A number of works have focused
on the problem of vRAN resource pooling to optimize the allocation
of compute resources across BBUs [15, 40, 115]. Going one step
beyond, vrAIn [5] proposes a joint compute and radio resource allo-
cation framework for the vRAN based on reinforcement learning. In
contrast to Concordia, the aforementioned works assume an isolated
vRAN and do not consider the effects of scheduling latency and cache
interference to the WCET of signal processing tasks. The problem
of controlled tail latency for signal processing tasks has been studied
both in the context of general purpose processors (e.g. [101]) and
DSPs (e.g. [7]). However, such works do not consider the presence
of collocated workloads as in the case of Concordia. Finally, a num-
ber of ML-based techniques have been proposed for the intelligent
allocation of resources to the RAN (e.g., [10, 37, 97]). However, the
focus of such works has been on the radio resources and not on the
optimization of compute.
591
Real-time scheduling: Real-time scheduling has been studied ex-
tensively in the literature [24]. Relevant to Concordia, a plethora
of works focus on mixed-criticality systems[17] and on the sched-
uling of parallel task DAG models similar to that of the vRAN
(e.g., [8, 9, 50, 59‚Äì61, 82, 91]). Concordia builds on the work in [61],
which proposes the most relevant state-of-the art mixed-criticality
deadline scheduler.
An integral requirement of real-time schedulers is the knowledge of
task WCETs. As such, there exists a large volume of work on WCET
prediction for hard real-time systems [111]. More recent approaches
have focused on providing probabilistic WCET bounds (e.g. with
4 or 5 nines) through distributions obtained using static analysis,
measurements or a combination of both [18]. However, in all such
works, the WCET prediction does not adjust dynamically at runtime
based on the input, leading to underutilization of the compute re-
sources. Moreover, most such works target embedded systems and
therefore assume that real-time tasks operate without the presence
of other interfering non real-time workloads. Concordia overcomes
this limitation through the introduction of its novel parameterized
WCET predictor and its offline and constant online training phases.
Low-latency scheduling frameworks: Workload interference is a
well-known problem. As such, various resource allocation and sched-
uling optimization frameworks have been proposed (e.g. [13, 65, 81,
83]). While the goal of such frameworks is to mitigate the effects
of interference, they operate at a coarse time granularity, which is
not suitable to deal with the sub-millisecond requirements of the
vRAN. Shinjuku [51] enables scheduling for microsecond-scale tail
latencies. However, its design as a single-address space OS does not
allow the deployment of conventional applications. Shenango [75]
and Snap [68] bear the most similarities to Concordia. However, nei-
ther provides mechanisms to predict the (varying) WCETs of tasks,
nor is able to provide 99.999 reliability. Moreover, Shenango requires
from applications to implement a specific API and to avoid the use
of system calls. In contrast, Concordia allows the collocation of the
vRAN with conventional applications (e.g. running in containers).
9 CONCLUSIONS
In this work we presented Concordia, a userspace deadline-aware
scheduling framework for the sharing of compute resources between
the vRAN and best-effort workloads. Concordia allocates CPU re-
sources among the vRAN physical layer and other workloads at a
granularity of 20 ùúás, ensuring that the vRAN meets its real-time
signal processing deadlines. The scheduling decisions of Concordia
are powered by a prediction mechanism based on quantile decision
trees that predicts the WCET of signal processing tasks in the pres-
ence of interference from other workloads. Experimental results on
a prototype based on the commercial Intel FlexRAN vRAN solution
demonstrate the ability of Concordia to reclaim more than 70% of
the vRAN‚Äôs compute resources, while providing 99.999% reliability
in meeting vRAN signal processing deadlines.
ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers and our shepherd
Muhammad Shahbaz for their valuable feedback that helped us im-
prove this work.
Concordia: Teaching 5G vRAN to Share Compute
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
REFERENCES
[1] 3GPP. 2019. 5G NR Physical Channels and Modulation, document 38.211.
[2] ORAN Alliance. 2020. O-RAN Use Cases and Deployment Scenarios. White
Paper, Feb (2020).
[3] Ganesh Ananthanarayanan, Paramvir Bahl, Peter Bod√≠k, Krishna Chintalapudi,
Matthai Philipose, Lenin Ravindranath, and Sudipta Sinha. 2017. Real-time video
analytics: The killer app for edge computing. computer 50, 10 (2017), 58‚Äì67.
[4] Erdal Arikan. 2009. Channel polarization: A method for constructing capacity-
achieving codes for symmetric binary-input memoryless channels. IEEE Trans-
actions on information Theory 55, 7 (2009), 3051‚Äì3073.
[5] Jose A Ayala-Romero, Andres Garcia-Saavedra, Marco Gramaglia, Xavier Costa-
Perez, Albert Banchs, and Juan J Alcaraz. 2019. vrAIn: A Deep Learning Ap-
proach Tailoring Computing and Radio Resources in Virtualized RANs. In The
25th Annual International Conference on Mobile Computing and Networking.
1‚Äì16.
[6] Arjun Balasingam, Manu Bansal, Rakesh Misra, Kanthi Nagaraj, Rahul Tandra,
Sachin Katti, and Aaron Schulman. 2019. Detecting if LTE is the Bottleneck with
BurstTracker. In The 25th Annual International Conference on Mobile Computing
and Networking. 1‚Äì15.
[7] Manu Bansal, Aaron Schulman, and Sachin Katti. 2015. Atomix: A framework
for deploying signal processing applications on wireless infrastructure. In 12th
USENIX Symposium on Networked Systems Design and Implementation (NSDI
15). 173‚Äì188.
[8] Sanjoy Baruah. 2016. The federated scheduling of systems of mixed-criticality
sporadic DAG tasks. In 2016 IEEE Real-Time Systems Symposium (RTSS). IEEE,
227‚Äì236.
[9] Sanjoy Baruah, Vincenzo Bonifaci, Alberto Marchetti-Spaccamela, Leen Stougie,
and Andreas Wiese. 2012. A generalized parallel task model for recurrent real-
time processes. In 2012 IEEE 33rd Real-Time Systems Symposium. IEEE, 63‚Äì72.
[10] Ali Kashif Bashir, Rajakumar Arul, Shakila Basheer, Gunasekaran Raja, Ramku-