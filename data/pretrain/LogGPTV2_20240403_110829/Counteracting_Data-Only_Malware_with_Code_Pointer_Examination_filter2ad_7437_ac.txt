### 6.2 Code Pointer Examination

After verifying the integrity of critical data structures, we proceed to scan the remaining kernel data memory for pointers to executable kernel code. This process involves the following steps:

1. **Extracting Executable Kernel Code Sections:**
   - We first identify the memory regions of the executable kernel code sections in the monitored virtual machine using the page table structure.

2. **Extracting Data Pages:**
   - Next, we extract the data pages of the monitored guest system. This is done by obtaining all pages marked as supervisor and non-executable in the page tables. These pages contain the kernel's data memory, including all pointers accessible from within the Linux kernel.
   - The information used for this analysis is reliable, as it is derived from either hardware or trusted kernel reference binaries.

3. **Iterating Through Memory:**
   - With the code and data pages identified, we iterate through the extracted pages byte by byte. Each eight-byte value (regardless of alignment) is interpreted as a pointer and checked to see if it points to one of the memory locations identified as containing kernel code.
   - If a pointer points to executable kernel memory, we check if its destination is in the list of valid functions.

4. **Validating Return Addresses:**
   - If a pointer does not point to a valid function, we check if it is a return address. Our framework uses multiple approaches to identify return addresses:
     - A return address must point to an instruction within a function that is preceded by a call instruction.
     - We disassemble the function the pointer allegedly points to from the beginning and verify that the pointer points to a valid disassembled instruction, not between instructions.
     - We also ensure that a call instruction resides before the instruction the pointer points to.
   - If any of these conditions fail, the code pointer is considered invalid, and we continue to the next category.

5. **Handling Special Cases:**
   - Some kernel functions save the return address of the current function for various purposes, such as debugging or timers. For example, the `struct hrtimer` contains a pointer to the instruction after the call instruction that started the timer.
   - To differentiate between legitimate return addresses and specially crafted control structures for code reuse techniques, we maintain a whitelist of calls to functions that contain problematic instructions. Only return addresses in the kernel’s data segment that point to these whitelisted functions are allowed.

6. **Malicious Pointer Detection:**
   - If a pointer does not point to a valid function or a return address, it is flagged as potentially malicious, and a human investigator is notified. The system also enriches the error message with the name of the function or symbol the pointer is pointing into.

### 7. Evaluation

In this section, we evaluate our approach using the prototype implementation described in Section 6. We aim to determine whether our framework meets the goals set in Section 5 by first assessing its performance characteristics and then evaluating its effectiveness against data-only malware in both live monitoring and forensic applications. We follow this with an in-depth discussion of the security aspects of our system.

#### 7.1 Experiments

**System Configuration:**
- **Host System:** AMD Phenom II X4 945 CPU with 13 GB of RAM running Linux kernel version 3.16 (Debian Jessie).
- **Guest Systems:** Two VMs running Linux 3.8 and Linux 3.16, each with access to two virtual CPUs and 1 GB of RAM.
- **Hypervisor:** XEN.

**Performance and False Positives:**
- We evaluated the performance of our system and its susceptibility to false positives using the Phoronix Test Suite. Specifically, we ran the `pts/kernel` test suite three times on each test kernel.
- **Baseline Performance:** First, we disabled all external monitoring to obtain a baseline of normal system performance.
- **Code Validation Component:** In the second set of tests, we enabled the code validation component to differentiate between the overhead of our framework and the code validation system.
- **Pointer Validation Module:** Finally, we enabled both the code validation component and our new pointer validation module to identify the additional overhead.

**Results:**
- **Linux 3.8 Kernel:**
  - 80 code pages and 426 data pages.
  - One complete Code Integrity Validation took 255.8 ms.
  - Combined CIV and Pointer Examination took 567.58 ms (341.78 ms for CPE).

- **Linux 3.16 Kernel:**
  - 408 code pages and 986 data pages.
  - Code Integrity Validation alone took 639.8 ms per iteration.
  - Combined CIV and Pointer Examination took 962.0 ms per iteration (322.2 ms for CPE).

- **Average Page Check Time:** Less than 1 ms per page.

**Performance Overhead:**
- The performance overhead of our framework is very small. The use of the underlying Code Validation Component incurs a larger overhead than our CPE framework.
- For most benchmarks, the performance impact is well under one percent. The main reason for this is that our framework uses passive monitoring of the guest system whenever applicable, reducing the need for hypervisor interruptions.
- **FSMark Benchmark:** On Linux 3.8, a performance degradation of about 2.65% was observed, but this was not seen in the results for Linux 3.16.
- No noticeable overhead was observed from within the guest system when monitoring was enabled.

**False Positives:**
- During our experiments, no false positives were observed. All pointers encountered during the validation process could be classified using the heuristics described in Section 5.
- However, due to the design of our system, we cannot rule out the possibility of false positives in all scenarios.

### Tables

**Table 1: Results of the Phoronix Test Suite for Linux 3.8**

| Test (Unit)                          | w/o      | CIV (%)           | CIV & CPE (%)    |
|--------------------------------------|----------|-------------------|------------------|
| Gcrypt Library (ms)                  | 32.57    | 30.10 (8.21%)     | 31.73 (2.65%)    |
| Timed MAFFT Alignment (s)            | 69.84    | 71.54 (−2.38%)    | 66.53 (4.98%)    |
| 7-Zip Compression (MIPS)             | 20.63    | 20.70 (0.34%)     | 20.63 (0.00%)    |
| C-Ray - Total Time (s)               | 2857     | 2853 (−0.14%)     | 2837 (−0.70%)    |
| John The Ripper (Real C/S)           | 1689     | 1689 (0.00%)      | 1688 (0.06%)     |
| H.264 Video Encoding (FPS)           | 35.38    | 35.23 (0.43%)     | 35.31 (0.20%)    |
| GraphicsMagick 1 (Iter/min)          | 95       | 95 (0.00%)        | 95 (0.00%)       |
| GraphicsMagick 2 (Iter/min)          | 58       | 58 (0.00%)        | 58 (0.00%)       |
| FS-Mark (Files/s)                    | 585.73   | 586.24 (1.25%)    | 4706 (0.19%)     |
| Dbench (MB/s)                        | 4702     | 4706 (0.19%)      | 4706 (0.19%)     |
| Himeno Benchmark (MFLOPS)            | 131.00   | 130.99 (0.02%)    | 130.99 (0.02%)   |
| PostgreSQL pgbench (Trans/s)         | 36.35    | 36.47 (0.33%)     | 36.47 (0.33%)    |
| Apache Benchmark (Requests/s)        | 10585.45 | 10481.21 (0.99%)  | 10506.23 (0.75%) |

**Table 2: Results of the Phoronix Test Suite for Linux 3.16**

| Test (Unit)                          | w/o      | CIV (%)           | CIV & CPE (%)    |
|--------------------------------------|----------|-------------------|------------------|
| FS-Mark (Files/s)                    | 30.90    | 31.37 (−1.50%)    | 31.67 (−2.43%)   |
| Dbench (MB/s)                        | 61.42    | 60.76 (1.09%)     | 61.04 (0.62%)    |
| Timed MAFFT Alignment (s)            | 20.74    | 20.79 (0.24%)     | 20.75 (0.05%)    |
| Gcrypt Library (ms)                  | 3747.00  | 3740 (−0.19%)     | 3733 (−0.37%)    |
| John The Ripper (Real C/S)           | 1693.00  | 1693 (0.00%)      | 1692 (0.06%)     |
| H.264 Video Encoding (FPS)           | 34.60    | 34.32 (0.82%)     | 34.35 (0.73%)    |
| Himeno Benchmark (MFLOPS)            | 598.71   | 582.78 (2.73%)    | 585.78 (2.21%)   |
| 7-Zip Compression (MIPS)             | 4850.00  | 4805 (0.94%)      | 4730 (2.54%)     |
| Parallel BZIP2 Compression (s)       | 89.80    | 89.81 (0.01%)     | 89.80 (0.00%)    |
| Smallpt (s)                          | 31.25    | 31.41 (0.51%)     | 31.37 (0.38%)    |
| LZMA Compression (s)                 | 407.00   | 407 (0.00%)       | 407 (0.00%)      |
| dcraw (s)                            | 236.62   | 241.49 (2.06%)    | 242.17 (2.35%)   |
| Ffmpeg (s)                           | 117.54   | 117.47 (−0.06%)   | 117.29 (−0.21%)  |
| GnuPG (s)                            | 23.39    | 23.41 (0.09%)     | 23.40 (0.04%)    |
| LAME MP3 Encoding (s)                | 13.72    | 13.65 (−0.51%)    | 13.98 (1.90%)    |
| OpenSSL (Signs/s)                    | 173.63   | 173.37 (0.15%)    | 173.57 (0.03%)   |