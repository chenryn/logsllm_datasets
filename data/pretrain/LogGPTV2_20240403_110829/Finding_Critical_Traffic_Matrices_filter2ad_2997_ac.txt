volume(head(hi, hk)) - max(mi, mk)
insert cost(i, k) in sorted list
Figure 2. Critical-ness Aware Clustering
are close to the original vector set and are able to dominate
all vectors in the set by linear combination. One direct ap-
proach is to utilize the result from clustering algorithm by
generating one “head” vector from each of the cluster such
that the head vector dominates the vectors within the cluster.
This can be achieved by setting the value of the head vector
to the maximum value of all cluster members in each dimen-
sion, i.e., head({~xi}) = (maxi xi,1, maxi xi,2, . . .) where
~xi = (xi,1, xi,2, . . .). Since the cluster members are close to
each other, the head vector should also be close to the cluster
members, satisfying the requirement for CritMat. We use
the result from the above method as our baseline algorithms.
In the rest of the paper, we will refer to these algorithms
as K-means Head and Hierarchical Head respectively, de-
pending on which algorithm is used for clustering.
A potential problem with the above clustering-based al-
gorithms is that clustering treats each vector in the origi-
nal data set equally while CritMat gives more importance
to the vectors with high volume. To correct this effect, we
proposed a Critical-ness Aware Clustering (CritAC) al-
gorithm by adapting the hierarchical agglomeration method.
The key idea is to deﬁne a dominating cluster head, as op-
posed to a cluster center, and explicitly consider the oversiz-
ing cost function in every agglomeration step. CritAC starts
with n clusters headed by each of the original n vectors. At
each iteration, the pair of clusters with the minimum “merg-
ing cost” are agglomerated and the vector that has value in
every dimension equal to that of the maximum among vec-
tors from both clusters becomes the new cluster head. This
process stops after n − m iterations when there are m clus-
ters left. Figure 2 presents the pseudo-code of the algorithm.
The runtime of CritAC can be evaluated as follows. The
most expensive computation in initialization is to calculate
cost(i, j) for all n(n − 1)/2 pairs of clusters. Each pair re-
quires O(K) computations (to obtain head(Ci, Cj)), where
K is the number of dimensions. Thus the runtime for line
6 to line 8 is O(n2K). In line 9, sorting n(n − 1)/2 cost
values requires O(n2 log(n)) computation. Thus the overall
runtime for initialization is O(n2K + n2 log(n)). For ag-
glomeration steps, each iteration requires O(nK +n log(n))
computation for calculating cost(i, k) and inserting the re-
sult into sorted list (line 16 to 19). There are n − m iter-
ations. Thus the overall runtime for agglomeration steps is
O(n(n − m)K + n(n − m) log(n)) and the total runtime
of CritAC is dominated by that of the initialization steps –
O(n2K + n2 log(n)).
We should note that it is possible to use other forms of
the cost function in CritAC. For example, we can associate
a weight for each dimension in the trafﬁc matrices that cap-
tures the distance between the corresponding ﬂow’s origin
and destination (similar to the distance function in Section
2.1). We have explored these variations of the algorithm.
However, for the data set that we evaluated in Section 5, we
found little difference in their performance. Therefore, we
omit these variations of the algorithm and the corresponding
performance results for the interest of brevity.
4 Evaluation Methodology
In this section, we ﬁrst discuss the performance metrics
that we use for comparing different methods. Next, we
summarize the baseline algorithms for comparing against
CritAC. We then describe the trafﬁc matrices, network
topology, and routing conﬁguration used in our evaluation.
4.1 Performance Metrics
We use two sets of metrics to compare the performance
of different methods. The ﬁrst set of metrics are more di-
rect. They are simply the objective function of CritMat –
the distance function ||~y, X|| – in various forms as described
in Section 2.1. The second set of performance metrics are
more application speciﬁc. We take the set of critical traf-
ﬁc matrices produced by different algorithms and use them
as input for two speciﬁc network engineering applications,
namely OSPF route optimization and network survivability
analysis. We then evaluate the results of these applications.
4.2 Baseline Algorithms
Category
Direct clustering
Methods
K-means Head, Hierarchical
Head, Peak-all-elements
Total volume based TopN, TopConsecN, Top1
Table 1. Baseline algorithms for evaluation.
In our evaluation, we compare CritAC with six alterna-
tives (as summarized in Table 1). These methods can be
classiﬁed into the following two categories:
• Direct clustering based methods, which apply standard
clustering techniques to cluster the input trafﬁc ma-
trices and then return the head vectors of the resulted
clusters as the critical trafﬁc matrices. K-means Head
and Hierarchical Head, as described in Section 3, be-
long to this class. Another method that belongs to this
class is Peak-all-elements, which returns a critical traf-
ﬁc matrix that has the peak demand for each individual
origin-destination ﬂow. Note that Peak-all-elements
can be viewed as a special case of K-means Head
and Hierarchical Head, with all input trafﬁc matrices
forming a single cluster.
• Total volume based methods, which return a subset of
input trafﬁc matrices as the critical ones based on their
volumes. Two methods that belong to this class are
TopN, which returns N trafﬁc matrices with the highest
volumes, and TopConsecN, which returns a set of N
consecutive trafﬁc matrices with the highest total vol-
ume (among all possible consecutive trafﬁc matrices).
We also consider a third alternative Top1, which is a
special case of TopN and TopConsecN with N = 1.
Note that the trafﬁc matrices returned by total volume
based methods are not exactly critical trafﬁc matrices in that
their linear combination may not dominate all input trafﬁc
matrices. As a result, we cannot apply the direct metrics
mentioned above to evaluate these methods. So we will only
evaluate them in the context of network survivability analy-
sis, and OSPF route optimization.
4.3 Trafﬁc Matrices
Our evaluations are based on real trafﬁc matrices col-
lected from a large operational IP network – AT&T’s North
American commercial backbone network. The network con-
sists of tens of Point of Presence (PoPs), hundreds of routers,
thousands of links, and carries over one petabyte of trafﬁc
per day.
The trafﬁc matrices are estimated from SNMP link load
measurements using the tomo-gravity method [15, 16],
which has been shown to yield accurate estimates especially
for large trafﬁc matrix elements. We use hourly trafﬁc ma-
trices, as they are commonly used in network engineering
applications. The data collection in our study contains more
than ﬁve months of hourly trafﬁc matrices (from January 2,
2004 to June 10, 2004), which provide us 3048 instances of
trafﬁc matrices in total. The trafﬁc matrices in our original
dataset are at the router level. For simplicity, we aggregate
them into PoP-level trafﬁc matrices (so that we don’t have
to deal with changes in the number of origin-destination
ﬂows due to router failures or newly added routers). Each
PoP-level trafﬁc matrix contains over 400 origin-destination
ﬂows at rates ranging from tens of Kbps to tens of Gbps.
4.4 Network Topology and Routing
We use the PoP-level network topology on June 10, 2004
in our evaluations. We ﬁrst obtain the router-level topology
using the methods by Feldmann et al. [7]. We then reduce
the router-level topology into a PoP-level topology by col-
lapsing all the router-level links between each PoP into a
single PoP-level link. The capacity of the PoP-level link is
computed as the sum of the capacities of all the underly-
ing router-level links. We also compute the geographical
distance (in miles) for each PoP-level link using the lati-
tude/longitude information for its two end points.
In order to translate trafﬁc matrices into link loads or uti-
lization, we need to have the routing information. By de-
fault, Cisco routers [4] set the OSPF weight of each link to
be inversely proportional to its capacity — we refer to this
setting as the InvCap weight setting and use it as the default
conﬁguration for our PoP-level topology.
5 Results
In this section, we present the results of our evaluation of
different methods for selecting critical trafﬁc matrices. We
ﬁrst compare different clustering based methods based on a
set of direct performance metrics (i.e., various forms of the
distance function ||~y, X|| as described in Section 2.1). We
then report on the performance of different methods in the
context of network survivability analysis and OSPF route
optimization.
5.1 Simple Metrics
In this section, we evaluate CritAC against direct clus-
tering based methods, using various forms of ||~y, X|| as our
performance metrics. We cannot report the exact values of
||~y, X||, as they are considered proprietary. So instead we
only report on the normalized values. The normalized met-
rics are summarized below:
• the trafﬁc demand oversizing ratio
|~y − ~x|1
max
~y∈Y
min
~x∈X,~x≤d~y
|~x|1
max
~x∈X
• the weighted demand oversizing ratio
max
~y∈Y
min
~x∈X,~x≤d~y
max
~x∈X
~w · (~y − ~x)
~w · ~x
where ~w is the geographical distance (i.e., air miles)
between the ﬂow source and destination of each ﬂow.
• the link load oversizing ratio
max
~y∈Y
min
~x∈X,~x≤d~y
max
~x∈X
|A(~y − ~x)|1
|A~x|1
where A is the routing matrix obtained using the default
InvCap weight setting.
• the weighted link load oversizing ratio
max
~y∈Y
min
~x∈X,~x≤d~y
max
x∈X
~d · (A(~y − ~x))
~d · A~x
where A is the routing matrix obtained using the default
InvCap weight setting, and ~d is the length (in miles) of
each link.
We compute the above oversizing ratios for the three
clustering based methods using either 500 or 1000 consecu-
tive trafﬁc matrices, which correspond to 22 days or 44 days
of measurement, at different times during the 5-month pe-
riod of our data collection. For the interest of brevity, we
only present the results for the ﬁrst 1000 trafﬁc matrices.
The results for other periods of time are qualitatively simi-
lar.
Figure 3 shows the four different kinds of oversizing ra-
tio as a function of the number of critical trafﬁc matrices de-
sired. We observe that different performance metrics have
given consistent result. If we look at the case at which the
number of critical trafﬁc matrices is 1, which corresponds
to Peak-all-elements, we ﬁnd that the oversizing ratio is
more than 100% in all graphs (the left most point in each
graph). This conﬁrms our intuition that Peak-all-elements
is an overly conservative method.
Comparing CritAC with Hierarchical Heads and K-
means Heads, we ﬁnd that CritAC achieves much lower
oversizing ratio. With CritAC, the oversizing ratio decays
rapidly to below 20% with only 24 critical trafﬁc matrices.
In contrast, with Hierarchical Heads and K-means Heads,
the oversize ratio undergoes a quick decay to about 40% and
then decays very slowly – even with 200 critical trafﬁc ma-
trices, the oversizing ratio is still close to the oversizing ratio