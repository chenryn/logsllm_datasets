features, such as the time elapsed between the ﬁrst and last
packets of the ﬁfth phase. Figure 4b shows the probability
densities for this feature, for which Proﬁt computed 99%
leakage (3.56 of 3.58 bits). Note that the total duration of
phase 5 includes some noise from other packets in that phase,
which entails some overlap.
In fact, the top-ranking feature reported by Proﬁt was the
time difference between packets #3 and #4 of the ﬁfth phase.
As illustrated in Figure 4c, this even more speciﬁc feature has
maximal separation between the distributions of each secret’s
probability given an observation. This is the only feature that
yielded 100% leakage (3.58 of 3.58 bits) according to Proﬁt’s
feature extraction and leakage quantiﬁcation.
Figure 5 shows the three main steps of our approach
implemented in our tool Proﬁt. Given a proﬁling suite, we
ﬁrst generate network traces that correspond to each input
value. We run each input value multiple times in order to
capture variations due to noise. Next, we align network traces
and divide the aligned block into phases. After alignment and
phase detection, each network trace is divided into a ﬁxed
number of subtraces, where each subtrace corresponds to a
phase. Next, using our feature library, we identify the set
of features for each phase. We then quantify the amount of
information leaked via each feature in terms of entropy using
the automatically inferred probability distributions for features.
4
Fig. 5: Proﬁt workﬂow.
payload in bytes (p.size), the time at which the packet was
captured (p.time), and the source and destination addresses
(p.src, p.dst) of the packet.
Traces: Running a certain input i ∈ I through the system
while capturing network trafﬁc yields a trace, which is a
sequence of packets t = (cid:104) p1, p2, . . . , p|t|(cid:105). Let T be the set
of all possible traces.
Input set and secret set: Generally, it is not feasible to run
all possible inputs exhaustively through the system. Therefore,
the user typically needs to select a subset of I that she wants
to proﬁle, i.e., a proﬁling input suite. Let the input set I ⊆ I
denote this set of distinct inputs that will be fed into the system
during the analysis.
As explained above, each input i ∈ I has an associated
secret value ζ(i). By choosing a set of inputs, the user is also
choosing a set of secrets. Let the secret set (i.e., the set of
secrets) S ⊆ S be the set of distinct secrets fed into the system
during the analysis.
Input list, secret list, captured trace list: Due to system
nondeterminism (e.g., network noise, randomized padding),
two runs with the same input i ∈ I may yield different traces.
The user may ﬁnd it desirable to run each input multiple times.
We thus introduce input lists, which may include multiple
appearances of each input.
When conducting a Proﬁt analysis, the user generates a
list of n inputs (cid:104) i1, i2, . . . , in(cid:105), which implies a list of n
secrets (cid:104) s1, s2, . . . , sn(cid:105) that can be obtained via ζ(ij). Running
all the inputs through the system while capturing network
trafﬁc yields a list of traces (cid:104) t1, t2, . . . , tn(cid:105). We will call these
lists the input list, the secret list, and the captured trace list,
respectively.
Features: A feature is a function f : T −→ R that projects
some measurable aspect of a network trace. Some examples of
possible features are: the size of the ﬁrst packet in the trace,
the time of the last packet in the trace, the maximum of all
sizes of odd-numbered packets in the trace, etc. There is an
inﬁnite number of possible features, ranging from very simple
to arbitrarily complex ones.
Proﬁles: By running a Proﬁt analysis, a proﬁle of the
system is obtained, which maps each feature name to the
proﬁle for that feature. The proﬁle of the system for a feature
f is the list of (ζ(ij), f (tj)) tuples for j ∈ [1 . . . n], i.e.,
(cid:104) (s1, f (t1)), (s2, f (t2)), . . . , (sn, f (tn))(cid:105). In other words, the
system proﬁle for a feature f associates the secret value of
each trace with the value of f for that trace.
Fig. 6: DARPA STAC conﬁguration and trafﬁc directions.
In the end, Proﬁt produces a ranked list of features, sorted with
respect to the amount of information leaked via that feature.
Proﬁt also reports the amount of information leaked via each
feature in terms of number of bits using Shannon entropy.
III. SYSTEM MODEL
We present a simple formalization of the system model and
deﬁnitions for some of the concepts used in our approach.
Inputs and secrets: We target networked applications, such
as client-server and peer-to-peer systems, that communicate
through an encrypted network channel (typically TCP en-
crypted using SSL/TLS). Our target systems often require
complex, structured inputs. For a particular system of choice,
let the input domain I be the set of all valid inputs, and let
ζ : I −→ S be a function which, given an input, projects the
value of the secret—a piece of conﬁdential information that
the user wants to make sure that the system does not leak. We
will call ζ the secret function (i.e., the secret-value-projecting
function), and S the secret domain (i.e., the domain of the
secret).
Packets: A packet is an abstraction of a network packet.
Real-world packets contain many details,
including nested
payloads and headers with many ﬁelds and options. We assume
that payloads are encrypted, and attacks trying to break the
encryption itself are outside the scope of this work. However,
an attack which attempts to ﬁnd an encryption key are in
scope. We limit our abstraction of packets to a core subset
of metadata from the highest-level header that is particularly
relevant for side-channel analysis: the size of the encrypted
5
(1)Phasedetection(2)Featureextraction(3)Leakage quantiﬁcationCaptured packet tracesfor each input in suite.Split-traces enrichedwith phase information.Value of each featurefor each secret.i1i2i3i4• Proﬁle-input suite:    a  diﬀerent secrets    b  inputs per secret    c  samples per input    n = a∙b∙c inputsBlack-boxsystemexecutioni1i2i3i4s1s2s3s4Ranking of the most-leakingfeatures, sorted by leakage.Total sizeA->BPhase 3100%• Secret function • Time or space.Packet #17B->APhase 272%Packet #5A->BFull trace71%Total sizeB->AFull trace4%…………Client machineServer machineLANAttacker machineCSAClient-server applications(incl. Web applications)⟶⟵ ⟷Client machineServer machineLANAttacker machineP1APeer-to-peer applications⟶⟵ ⟷P2P3P4Direction-induced subtraces: If t ∈ T is a trace, let t↑
and t↓ be the traces induced by keeping only the packets
from t whose attributes p.src and p.dst are consistent with the
speciﬁed direction, respectively (see Figure 6). For instance,
suppose t = (cid:104) p1, p2, p3, p4(cid:105) where p1 and p4 were sent from
client
to server, and p2 and p3 were sent from server to
client. Then t↑ = (cid:104) p1, p4(cid:105) and t↓ = (cid:104) p2, p3(cid:105). For peer-to-
peer systems, as shown in Figure 6, the lower side denotes a
designated peer that runs on the client machine, and the upper
side denotes all other peers, running on the server machine.
Finally, the notation t(cid:108) is equivalent to just t.
Split traces: A trace-splitting function φ is a function
that, given a trace t ∈ T, splits t into subtraces (which are
themselves traces) whose concatenation is the original t. A
split trace is a sequence of traces obtained by splitting a trace.
IV. ALIGNMENT AND PHASE DETECTION
We now describe our heuristics for trace alignment, which
is based on tools from computational biology, and for phase
detection, which is based on the aligned traces.
Our goal is to study the patterns that appear across traces,
use them to detect potentially meaningful phases, and generate
a mechanism that can split any trace into phases accordingly.
In other words, we want to generate a trace-splitting function
from a collection of traces. Its construction requires examining
multiple traces at once, but once constructed, it can be applied
to any individual trace. Note that the word phases can be used
in a global sense, denoting the trace-splitting function obtained
from a collection of traces, and in a local sense, denoting the
result of splitting one particular trace into phases.
A. Trace alignment
Given a list of captured traces (cid:104) t1, t2, . . . , tn(cid:105), where each
ti may have a different length, we would like to detect stable
patterns that appear in nearly identical form across nearly all
of the ti, and use them to identify the variable parts in be-
tween them, which, despite varying signiﬁcantly across traces,
could be semantically related in a meaningful way. This is
essentially multiple sequence alignment (MSA), a well-studied
problem in computational biology [38] where sequences of
nucleic acids need to be aligned in a similar fashion. Many
crucial analyses in biology (e.g., determining the evolutionary
history of a family of proteins) depend on MSA. However,
obtaining an optimal alignment is an NP-hard problem [22],
[36]. Many heuristic approaches exist,
typically based on
progressive methods [25] or iterative reﬁnement [2], [3].
Some popular heuristic toolkits that yield a good compromise
between accuracy and execution time are the CLUSTAL [33]
family, T-COFFEE [37], and MAFFT [32]. Typically they
are limited to small alphabets, give each character a speciﬁc
biological meaning, and rely heavily on precomputed tables
for common character combinations from the biology domain.
We use MAFFT, which offers a generic mode in which the
alphabet can comprise up to 255 symbols and no biology-
speciﬁc meaning is attributed to the symbols.
We align the traces based on their sequences of packet
i.e., for a trace t = (cid:104) p1, p2, . . . , p|t|(cid:105) we consider
sizes,
(cid:104) p1.size, p2.size, . . . , p|t|.size(cid:105). We also incorporate some in-
formation about packet direction into the sequence of sizes
8
8
8
8
8
7
8
8
5
5
5
3
2
0
2
2
Fig. 7: A few unaligned sequences of values.
9
-4
8
4
-4
-3
6
-4
-3
1
-4
-6
1
1
-3
1
1
1
1
1
1
1
1
1
2
0
2
2
5
5
5
3
8
8
8
8
8
7
8
8
9
–
8
4
–
–
6
–
-4
-4
-4
-4
-3
-3
-3
-6
1
1
1
1
1
1
1
1
1
–
1
1
–
–
–
1
Fig. 8: Post-alignment matrix (with gaps).
by encoding the direction of each packet into the sign of
its size. Considering packet timestamps could also provide
useful insight for alignment. However, we found it difﬁcult
to leverage both size and time information simultaneously in
a consistent way. For the purpose of alignment, and for our
benchmark, sequences of (directed) packet sizes proved to be a
far more useful characterization than sequences of timestamps.
Moreover, a size-based alignment can also help ﬁnd time-based
features, as we saw in the GABFEED example from Section II.
Recall Figure 3 from Section II, which shows 50 traces
captured from GABFEED before alignment, after alignment,
and after phase splitting. White boxes represent the absence of
a packet. Alignment yields a list of sequences of packet sizes
in which each sequence may contain gaps, shown in white.
Gaps are inserted so as to maximize the alignment of patterns
that are recurrent across many traces. As a consequence, stable
patterns are aligned into columns. The variable patterns located
between these columns give rise to meaningful features which
would be hard to isolate without alignment.
B. Phase detection
As exempliﬁed by Figure 3 (b), thanks to the inserted gaps,
the matrix of aligned sequences presents a new horizontal axis
that is better suited for splitting the traces into meaningful
subtraces. This eases the detection of stable regions, which we
will call stable phases, and as a consequence, of the variable
regions that appear before, in between, or after them, which
we will call variable phases.
We now need a heuristic method to ﬁnd stable phases and
select cut-points along the horizontal axis of the matrix. Let
M be an aligned matrix with n rows and m columns. Let Cj
be the j-th column, and #Gj the number of gaps in it. The
density of the j-th column is the ratio Cj/n, and its diversity
is the variance of the (n − #Gj) values in Cj that are not
gaps. We characterize stable regions using two thresholds: the
maximum diversity (ψ) that a column may have in order to be
part of a stable phase, and the minimum width (ω), in columns,
that may constitute a stable phase.
Hence, a stable phase is a maximally wide run of adjacent
columns that are fully dense and that satisfy both thresholds: (i)
the run is at least ω columns wide, and (ii) each column within
the run has at most ψ diversity. Using this characterization,
we synthesize a regular pattern that can parse all sequences
of values. The pattern is akin to a regular expression, but
with arbitrary integer values instead of characters. Figures 7
6
and 8 are analogous to Figures 3a and 3b, respectively, but
show a much smaller example with shorter sequences. For the
example shown in Figure 8, assuming ω = 3 and ψ = 0.25,
the synthesized pattern would be
(int*)((2|0)(5|3)(8)(8|7))(int*)((−4)(−3| − 6)(1)(1)(int*))
where int stands for “any integer” and * is the Kleene star.
The pattern demands that
the stable parts be present,
accounts for some amount of diversity in them, and allows
for freedom before, after, and in between the stable parts. In
general, assuming k > 0 stable regions are found, we build a
pattern of the form
(V1)(S1)(V2)(S2) . . . (Vk)(Sk)(Vk+1)
Each Si represents a stable region. For the i-th stable region
with length l, Si = d1d2 . . . dl, where each of the dj is
either a constant integer (if position j within Si always had
the exact same value for all traces), or a union of integers
dj = (x1|x2| . . .|xr) if that position exhibited r different
values within the allowed threshold. Each Vi represents a
variable region and consists of a free pattern (any sequence
of integers). All regions are named and used to extract the
corresponding groups. The synthesized expression becomes a
parser for sequences of packet sizes, and thus an implementa-
tion of the trace-splitting function that we wanted to construct.
If the number of available captured traces is so large that
the MSA tool would take too long to ﬁnd an alignment, we
can still apply the tool to a reasonably large random subset
of the traces. We then detect phases as explained above, and
use the synthesized expression to parse the rest of the traces.
Some traces could fail to parse if their stable parts include
extraneous values that were not present in any of the aligned
traces. If the traces that fail to parse are less than 1% of the
total number of traces, we consider them outliers and ignore
them. If they exceed 1%, we add them to the initial subset and
realign. For all the examples in our benchmark, using a subset
of at least 500 traces, we have never encountered a case where
more than 1% of the traces have failed to parse.
V. LEAKAGE QUANTIFICATION