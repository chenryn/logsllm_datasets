tion for a large number of time series representing multiple
resource usages from co-located VMs at production data
centers. The immediate obstacles of prediction given a large
number of demand series are accuracy, training overhead, and
model scalability. Typically, temporal models [10], such as
ARIMA are not able to capture well bursty behaviors. More
sophisticated temporal models such as neural networks, cap-
ture irregular patterns better but at much higher computational
overheads. Given such restrictions, it is important to come up
with efﬁcient and accurate prediction models that also scale
well.
We propose a new prediction methodology that combines
both temporal and spatial models to predict on each box the
resource demand time series2 Di (∀i ∈ [1, M × N ]) where
M is the number of co-located VMs and N is the number
of different resources taken into consideration. We introduce
2Demand series is the product of usage series and the allocated virtual
capacity. Both demand and usage series share the same correlation character-
istics. For the purpose of virtual resource resizing, we predict demand series
directly.
337
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:56 UTC from IEEE Xplore.  Restrictions apply. 
the concept of signature series: a minimum number of time
series that are predicted via temporal models. The rest of
the demand series, termed as dependent series, are predicted
through a linear combination of signature series via spatial
models. Essentially, we divide the demand series, Di, into
two sets: the signature set, denoted by Ωs, and the dependent
set, Ωd.
The novelty of ATM is to derive novel spatial models for
dependent series while applying existing temporal models to
predict signature series. Many practical techniques exist in the
literature for reducing the overhead of temporal models by
extracting and storing features of the time series [7], [11].
We stress that any temporal prediction model can be directly
plugged into the ATM framework.
To derive the spatial models, we want to express all demand
series Dk, k ∈ Ωd by a linear combination fk of the signature
series Dj, j ∈ Ωs:
Dk = fk(Dj).
(1)
As every demand series can be either a signature or a depen-
dent series, a brute force solution to ﬁnd the minimum sig-
nature set is to explore all 2N×M combinations of regression
models. For boxes hosting an average number of VMs, i.e.,
M around 10 and expected to grow as servers become more
powerful, it is clear that this method is not viable. To address
this issue, we devise an efﬁcient searching algorithm that can
quickly ﬁnd signature series without using exhaustive search,
by leveraging time series clustering techniques and stepwise
regression.
A. Searching for Signature Demand Series
Key to the discovery of signature series is clustering. We
propose a two-step algorithm to identify the signature set
Ωs. Step 1 deﬁnes the initial set of signature series. This
is achieved using time series clustering, speciﬁcally dynamic
time warping (DTW) [12] or correlation based clustering
(CBC) that we propose here. Step 2 deﬁnes the ﬁnal set of
signature series by detecting and removing multicollinearity
among initial set of signature series using variance inﬂation
factors (VIF) and stepwise regression. The intent of the second
step is to ﬁx the pitfall that although signature series appear
independent, it is possible that a combination of certain subsets
of the initial signature series can well represent the others. For
example, a group of series can be separated into three clusters
because of their dissimilarity in the distances or the correlation
patterns. If however one of the clusters can actually be well
expressed as a linear combination of the other two, then this
falls under a classical example of multicollinearity. Figure 4
illustrates the steps of signature set search.
Step 1: Time Series Clustering: Dynamic time warping is
an effective solution for ﬁnding clusters of time series where
the distance across the series is short. A potential problem is
that DTW falls short in capturing within the cluster series that
are of larger distance. Correlation based clustering solves this
problem by capturing highly correlated time series that are far
enough apart and cannot be captured by DTW. Applying DTW
Fig. 4: Overview of searching for signature set.
on the exemplary four series shown in Figure 1 illustrates
how clustering with DTW only offers a partial solution. DTW
detects three clusters: cluster 1 VM1, cluster 2 VM2, and
cluster 3 VM3 and VM4. CBC instead puts VM1, VM3, and
VM4 within the same cluster. Indeed, the series D1 and D4 of
VM1 and VM4 can be well represented as linear models of the
series D3 of VM3, e.g., D1 = a0+aD3, and D4 = b0+bD3,
where a0, a, b0, and b are scalars. In the remaining of this
section we provide details on DTW and CBC.
Dynamic Time Warping Clustering: The high level idea of
DTW is to group series that show low distance dissimilarity.
To obtain the distance dissimilarity between two series P =
{p1, p2, ..., pi, ..., pn} and Q = {q1, q2, ..., qj, ..., qm}, we ﬁrst
build a matrix that consists of the pair-wise squared distances,
i.e., d(pi, qj) = (pi − qj)2, between each pair of elements pi
and qj in the two series. The distance dissimilarity λ(n, m)
of the two series is given by the wrapping path through the
matrix that minimizes the total cumulative distance [12] and
can be recursively computed as follows:
λ(i, j) = d(pi, qj) +
min{λ(i − 1, j − 1), λ(i − 1, j), λ(i, j − 1)}.
(2)
Next, we apply hierarchical clustering [13] for any given
number of clusters, ranging from 2 to (M × N )/2 since we
aim to reduce the original set to at least its half. We determine
the optimal number of clusters, based on the average silhouette
value [14] of all time series within each cluster. For each series
i, its silhouette value s(i) is deﬁned as
b(i) − a(i)
s(i) =
max{b(i), a(i)}
(3)
where a(i) is the average distance dissimilarity between series
i to all the other series within the same cluster using DTW,
and b(i) is the lowest average distance dissimilarity between
series i to the all the series in a different cluster. The higher the
silhouette value, the better the series lies within its cluster. For
each number of clusters, we average the silhouette values of all
the series as the representative silhouette value. The optimal
number of clusters is the one with the maximal silhouette
value. As last step and beyond conventional DTW, we identify
338
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:56 UTC from IEEE Xplore.  Restrictions apply. 
each signature series as the series with the lowest average
dissimilarity in each cluster.
Correlation-based Clustering: CBC focuses on grouping
series showing high correlation. For each box, we ﬁrst compute
the pairwise correlation coefﬁcients, denoted as ρ, for all pairs
of the M × N series. For a demand series Di, there are
(M × N − 1) pairs ρi,l,∀l (cid:4)= i. To form the clusters, we rank
each series Di, i ∈ [1, M ×N ] ﬁrst by the total number of ρi,l
above a threshold ρT h, and second by the mean value of the
ρi,l above the threshold. In the following we set ρT h = 0.7, a
common threshold value used to determine strong correlation
between two series, which suggests a potential for linear
ﬁtting [15]. After the series have been ranked, we select the
topmost one and remove it together with all the series being
correlated with it with a correlation coefﬁcient higher than
the threshold. These series are now considered within a new
cluster with the top ranked series being the signature series.
This procedure continues by selecting the next topmost series
still in the ranked list and ends when the ranked list becomes
empty.
Step 2: Stepwise Regression: To further reduce the number
of signature series, we calculate the variance inﬂation factor
– a metric that can detect multicollinearity in regression. For
each series in the signature set, we regress it on the rest of
signature series and obtain its VIF value [15]. The rule of
practice is that a VIF greater than 4 indicates a dependency
with the other series in the initial set. After detecting the risk
of multicollinearity, i.e., at least one series has a VIF greater
than 4, we perform standard stepwise regression to remove
the series that can be represented as linear combinations of
the other signature series.
B. Prediction Models
To predict all M × N demand series, we ﬁrst predict the
signature series Di (i ∈ Ωs), using neural network models
and their historical data [7]. To predict all dependent series,
we regress each dependent series on the set of signature series,
obtaining coefﬁcients using ordinary least square estimates.
We stress that the signature series predictions are not tied to
the any speciﬁc model rather any suitable prediction model
can be easily plugged into our ATM framework.
In summary, we ﬁrst leverage historical data to develop
spatial models to deﬁne dependent series and their respective
signatures. Later, we use temporal models to predict
the
signature series and inexpensive linear transformation models
to predict the dependent series.
C. Results on Spatial Models
Prior to moving to the proposed VM resizing policy, we
present evaluation results of the proposed spatial models across
the demand series of the trace data (6K boxes and 80K
VMs) presented in Section II. Our evaluation focuses on: (i)
the difference between DTW and CBC clustering, (ii) the
effectiveness of clustering and stepwise regression, and (iii)
inter- v.s.
is necessary to
treat different resource series, e.g., CPU and RAM, separately.
intra-resource models,
i.e.,
if it
)
%
(
s
e
x
o
B
f
o
e
g
a
t
n
e
c
r
e
P
70
60
50
40
30
20
10
0
2-3
4-5
CPU-DTW
CPU-CBC
RAM-DTW
RAM-CBC
6-7
8-9 10-15 16-31 32-64
Number of Clusters
Fig. 5: Comparison of clustering results using DTW and CBC.
Since the purpose of spatial models is to use a minimum subset
of original series to accurately represent the data center, the
metrics of interest are: (i) the percent of signature series out
of the total demand series and (ii) the prediction error. In
this section we only focus on the effectiveness of the spatial
models, i.e., how close the dependent series are from the actual
time series counterparts. The overall prediction accuracy of
combining spatial models with temporal models is presented
in Section V.
1) Difference between DTW and CBC: Figure 5 compares
the distribution of the number of clusters resulting from DTW
and CBC and highlights the type of each signature series, i.e.,
CPU or RAM. For DTW, roughly 70% of boxes have only 2
to 3 clusters, and the rest have 4 to 31 clusters. In contrast,
CBC is less aggressive resulting in a higher number of clusters
and, consequently, a higher number of signature series. This
indicates a higher overhead to develop their temporal models.
Moreover, in terms of signature series types, under DTW, one
can see that both CPU and RAM roughly account for 50% of
the signature series. This is consistent across all DTW bars in
Figure 5. Instead, with CBC, most signature series are CPU
series.
2) Effectiveness of the Two-Step Approach: To better illus-
trate the beneﬁts of time series clustering (DTW or CBC) and
stepwise regression, we compare the signature set reduction
and prediction accuracy of each step in Figure 6. Each box
represents the 25th, 50th (mid line), and 75th percentiles,
whereas the dot marks the mean and the whiskers the most
extreme data points.
Figure 6(a) shows the percent of signature series out of the
total number of series for each of the 6K physical boxes. Since
DTW is quite aggressive in reducing the number of time series,
there is almost no further reduction after applying stepwise
regression. Both steps reduce the entire set to 26%. After CBC,
the set is reduced to 82%, however stepwise regression brings
further down the number to 66%.
Considering prediction accuracy, as shown in Figure 6(b),
both DTW and CBC experience minor losses. The average
339
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:56 UTC from IEEE Xplore.  Restrictions apply. 
)
%
(
l
a
n
g
i
r
i
O
o
t
.
i
g
S
f
o
o
i
t
a
R
100
80
60
40
20
0
DTW
CBC
Clustering
Stepwise
)
%
(
r
o
r
r
E
T
C
P
.
s
b
A
n
a
e
M
60
50
40
30
20
10
0
(a) Signature set reduction
DTW
CBC
Clustering
Stepwise
(b) Prediction error
Fig. 6: Comparison of the two steps: effectiveness of clustering
and stepwise regression.
)
%
(
l
a
n
g
i
r
i
O
o
t
.
i
g
S
f
o
o
i
t
a
R
100
80
60
40
20
0
)
%
(
r
o
r
r
E
T
C
P
.
s
b
A
n
a
e
M
80
60
40
20
0
Inter-CPU/RAM
Intra-CPU
Intra-RAM
CBC
DTW
Inter-CPU/RAM
Intra-CPU
Intra-RAM
(a) Signature set reduction
Fig. 7: Comparison of inter- and intra-resource models.
DTW
CBC
(b) Prediction error
absolute percentage error (APE)3 from DTW is about 28%,
while the average APE for CBC is only around 20%. Since
stepwise regression almost does not affect the signature set of
DTW, one expects no obvious decrease in prediction accuracy.
This is indeed shown in the graph. Surprisingly, the same
holds true with CBC where stepwise regression reduces CBC’s
accuracy only by 1%. These results conﬁrm the effectiveness
of stepwise regression in reducing the signature set without
degrading in prediction accuracy.