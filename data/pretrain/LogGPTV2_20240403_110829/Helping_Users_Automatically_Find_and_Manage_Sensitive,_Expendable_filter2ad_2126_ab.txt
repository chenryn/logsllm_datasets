### Figure 2: Overview of Our Approach Combining Qualitative Interviews and Two Rounds of Quantitative Data Collection

Our approach integrates qualitative interviews with two rounds of quantitative data collection, leveraging cloud storage providers and third-party services like Google Cloud Vision for deeper content analysis. The survey involved presenting participants with files from their Google Drive or Dropbox accounts and asking them to label and explain the sensitivity and usefulness of each file. Participants were also asked to indicate a file-management decision: whether they would keep, delete, or protect each file.

Given the impracticality of showing all files in an account, selecting a representative subset was a challenge. To address this, we conducted two rounds of data collection:
- **Round 1**: We used heuristic-based file selection, informed by insights from our interviews. This method yielded a small number of sensitive data points.
- **Round 2**: We trained a preliminary classifier using Round 1 data and used its predictions to select files, allowing us to oversample the minority class (sensitive files).

Section 5 provides further details on our method, while Section 6 summarizes the findings from both rounds of data collection.

### 3. Developing Aletheia, an Automated Classifier

Using the data collected from both rounds, we built classifiers to predict:
- File sensitivity
- File usefulness
- Desired file management

Each prediction was formulated as a classification task. File-management decisions are heavily influenced by file sensitivity and usefulness. For Round 2, we used an initial version of the sensitivity classifier to select files. Given the subjective and consequential nature of deleting data, Aletheia is designed to be part of a human-in-the-loop support system rather than a fully automated tool.

We evaluated Aletheia using precision-recall analysis, which aligns with ranking files for user interface presentation or recommendations. The area under the precision-recall curve (AUC) was used to quantify model accuracy. Section 7 details Aletheia’s experimental setup and performance results.

### 4. Qualitative Interviews

To gain an initial understanding of how people perceive the sensitivity and usefulness of files in the cloud, we conducted semi-structured interviews with cloud storage users. The goal was to build a formative understanding of the factors that influence these perceptions.

#### 4.1 Methodology

We recruited participants via Craigslist who had a Google Drive or Dropbox account over three months old and were willing to attend an in-person interview. We interviewed 17 participants between January and June 2019. Among them, 10 identified as male and 7 as female, with ages ranging from 20 to 45 years. We prioritized participants without IT-related experience. Six participants were full-time students from non-STEM majors, and the rest had completed college education. Each interview lasted approximately 30 minutes, and participants received a $20 Amazon gift card as compensation.

The interview protocol explored participants’ approaches to cloud storage both abstractly and concretely. The first half focused on general reasons for using cloud storage and open-ended discussions about broad classes and characteristics of sensitive and useful files. We provided specific scenarios (Table 1) to spur further thinking. The second half involved participants logging into a web app we built, which used the Google Drive and Dropbox APIs to show ten randomly selected files from their account. Participants explained the sensitivity and usefulness of each file and provided feedback on draft questions for our quantitative survey.

All interview responses were audio recorded with consent and transcribed using the Google Speech to Text API. One member of the research team open-coded the transcriptions, and a second member independently coded the extracted quotes. Cohen’s κ, a measure of intercoder reliability, was 0.87. Conflicting codes were resolved, and the final codebook, available online, contained thirty distinct codes across sixteen prompts and questions.

We ensured ethical conduct by obtaining IRB approval, using opt-in permission for audio recording, and encouraging participants to use their own devices to view selected files, ensuring privacy.

#### 4.2 Results

Participants' conceptions of file sensitivity and usefulness in the cloud are summarized below.

##### 4.2.1 Why a File Might Be Perceived as Sensitive

Participants identified seven classes of sensitivity:
- **Personally Identifiable Information (PII)**: Files containing names, contact details, dates of birth, passports, or driver’s licenses.
- **Confidential Information**: Proprietary or confidential data, such as original work that could be plagiarized.
- **Financial Information**: Tax documents, pay stubs, and files with Social Security Numbers.
- **Intimate Content**: Photos, videos, and other media files, including personal and adult content.
- **Personal Views**: Files containing personal views or opinions, such as religious or political content.
- **Self-Presentation**: Files related to self-presentation, such as unflattering photos.
- **Content That May Be Misinterpreted**: Contextual and subjective content that could be misconstrued.

##### 4.2.2 Why a File Might Be Perceived as Useful

Participants considered files useful if they might need to access them in the future, citing five categories:
- **Reminiscence**: Sentimental value and memories, such as photos.
- **Active Projects**: Work or school-related files.
- **Recent Files for Reference**: Recently accessed or modified files.
- **Files Frequently Updated Over Time**: Evolving documents like journals.
- **Sharing**: Shared files, such as midterm or final papers.

This qualitative understanding informed the development of closed-form survey questions and the identification of metadata and content features for training our classifiers.

### 5. Quantitative Online User Study: Method

Building on the insights from our qualitative interviews, we conducted an online user study combining a survey and automated data collection from participants’ cloud accounts. Our core goal was to collect rich data about participants’ perceptions alongside quantitative features of files in the cloud to train an automated tool for aiding cloud file management.

#### 5.1 Study Overview and Survey Structure

We recruited participants on Amazon’s Mechanical Turk (Mturk) and Proliﬁc Academic, targeting American participants aged 18+ with a platform approval rating of 95%+. Participants were required to have a Google Drive or Dropbox account over three months old with 100+ files.

The survey consisted of three sections:
- Broad questions about cloud storage use.
- File-specific questions about the sensitivity and usefulness of particular files.
- Questions about demographics and account protection mechanisms.

**File-Specific Survey**: The focus was on querying participants about specific files stored in their accounts. Their responses, paired with the file features we collected, formed the training data for Aletheia.

**File-Selection Strategies**:
- **Round 1**: Heuristic-based file selection, looking for sensitive keywords in filenames and categorizing document and media files.
- **Round 2**: File selection based on a preliminary classifier trained from Round 1 data, allowing us to oversample sensitive files.

Table 2 outlines the file-selection strategies across the two rounds of data collection.

| # of Files | File Description |
|------------|------------------|
| **Category** |
| **Round 1 (Heuristic-based)** |
| 8          | Files containing a sensitive keyword in filename |
| 8          | Document files (.txt, .docx, .pdf, .xlsx, .ppt, etc.) |
| 4          | Media files (.jpg, .png, .mp4, .mpeg, etc.) |
| 5          | Files other than documents or media |
| **Round 2 (Classifier-based)** |

This structured approach allowed us to gather comprehensive data for developing and evaluating Aletheia.