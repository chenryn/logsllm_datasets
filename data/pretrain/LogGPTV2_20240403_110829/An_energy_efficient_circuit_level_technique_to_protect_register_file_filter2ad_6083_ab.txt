197
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 09:56:57 UTC from IEEE Xplore.  Restrictions apply. 
 Finally, the AVF of a register is the percentage of time in which the register is in its ACE time.  Figure 1.a represents a typical register ACE and Un-ACE times. As shown in Figure 1.a, when a write operation is performed on the register, it enters its ACE time until the last read operation from the register. The time duration between the last read from the register and the next write to the register is considered as the Un-ACE time. If there is no read operation between two consecutive write operations (Figure 1.b), the register is always in its Un-ACE time. This means that a value is written to a register but never used.    (a)   (b) Figure 1. The ACE and Un-ACE time of a register  3.2. SEU/SET-Tolerant Latches & Flip Flops Circuit level techniques for soft errors protection can effectively mask the effect of particle strikes i.e. SEUs and SETs. At this level of abstraction, extra circuitry is utilized to mask the transient voltage caused by particle strikes in the time of occurrence. The circuit level schematic of the SEU/SET tolerant latch proposed in [11][18] is shown in Figure 2. To mask the SEUs occurring in the internal nodes of the latch, a redundant feedback path and three filtering circuits called C-Element are used.  The redundant feedback path provides a copy of the stored value inside the latch and the C-Element examines if the two values stored in the main and the redundant feedback paths are equal. The C-element is a state holding element that holds its previous state if its inputs are different and inverts its inputs if they are of identical logic value. To mask the SETs occurring in the combinational parts (which in turn can propagate to the input line of the latch), a CMOS delay element is utilized in the latch. To do this, the main input and its delayed version are compared using a C-Element. To minimize the cost of the latch, the already available C-Element used for the SEU tolerance purpose is also utilized for masking SETs. It should be noted that the use of delay elements is a common practice in the design of reliable latches [19][20]. The amount of delay that should be applied to the input line of the latch depends on the amount of the required reliability. According to some studies [21], the SET pulse widths may be even more than few nanoseconds depending on the used technology and the particle energy. But the probability of a particle strike with a specific amount of charge decreases exponentially as the amount of deposited charge increases.   Figure 2. The circuit level schematic of the SEU/SET tolerant latch [11][18]  It means that the occurrence of a wide pulse is significantly less frequent than the narrow ones. In other words, if it is required that the latch filters out all possible SETs, the amount of the delay should be greater than the possible longest SET. Figure 3 shows a situation in which the SET pulse width is less than the amount of the applied delay. In this situation, the SET is masked by the C-element as it has occurred in the latch input and has not overlapped its delayed version.   Figure 3. An example of an SET occurring in the input line of the latch (TSETTDelay)   Figure 5. An SEU/SET tolerant FF 4. The Proposed MBU/SET Technique for Register Files As mentioned in Section 2, the need for a fault tolerant technique that efficiently tolerates both SETs and MBUs while satisfying embedded system constraints, such as power consumption, is severely magnified. Circuit level techniques for protecting digital systems against particle strikes are very effective. In these techniques extra circuitry are used in the design of a memory element such as SRAM cells, latches or flip flops to prevent the voltage transients caused by particle strikes in sequential or combinational parts to turn into soft errors. In fact, they mask the effect of particle strikes in the time of occurrence. The main problem is that, exploiting robust latches to protect entire register file is not a viable solution as it imposes high power and area overheads. In the following section, we will show that how we can utilize the advantages of circuit level techniques to protect the register file from MBUs and SETs while providing attractive tradeoffs between reliability and power consumption.  4.1. The Simulation Platform and Benchmarks Since the main target of this paper is embedded processors, A synthesizable VHDL model of the LEON2 processor that is designed for embedded application is used. LEON2 is a 32-bit processor conforming to the IEEE-1754 (SPARC V8) architecture [22]. The LEON register file has one 32-bits write port and two 32-bits read ports. LEON exploits register windowing. Number of registers depends on the configured number of register windows. The standard configuration is 8 windows requiring 136 registers. In this paper, two register windows consisting 64 registers are used. Some of the benchmarks of MiBench, An embedded benchmark suite [25], are used as the workload programs in our experiments. 4.2. Clock Gating The two main source of power dissipation in CMOS circuits are static current caused by nominally off state transistors and dynamic power due to voltage transitions or switching activities. The dynamic power consumption is modeled as Eq.1: (cid:1842)(cid:3031)(cid:3052)(cid:3041)(cid:3028)(cid:3040)(cid:3036)(cid:3030)(cid:3404) (cid:2009).(cid:1829).(cid:1848)(cid:3031)(cid:3031)(cid:2870).(cid:1858) Where (cid:2009) is the switching activity, C is the total load capacitance, Vdd is the supply voltage and f is the operational frequency of the circuit. Different low power design techniques try to decrease one of these factors to reduce the dynamic power. For example, in dynamic voltage scaling technique (DVS), the frequency and supply voltage are scaled down. Although this technique significantly reduces the total power consumption, it has a negative effect on soft error rate of the system [5]. This is so since reducing the supply voltage results in an exponential increase in soft error rate [12][13].    Other low power techniques such as clock gating try to reduce the switching activity ((cid:2009)) by decreasing the unnecessary transitions. In the clock gating technique, the clock signal of the circuit is gated when there is no need to write a value to a memory element. These techniques have no negative effect on system reliability so that they are useful to reduce the power consumption in safety critical systems. There are two styles for clock gating in memory cells, namely OR-based (Figure 6.a) which is employed in the proposed technique and Latch based (Figure 6.b). In both styles, the “enable” signal determines when the clock should be gated. The clock gating technique results in considerable power reduction in the processor if it is used in components that are frequently accessed and containing many memory cells such as the register file.   (a)Or-based style  (b) Latch Based style  Figure 6. Different styles for clock gating techniques 4.3. Register Caching  The basic concept of register caching is to use a small cache memory along the register file to decrease the register access time. In [23], it has been reported that there is a substantial locality in register values such that when a new value is written to a register, it takes a few cycles before the first read operation is performed. This small distance between writing a new value and its 978-1-4244-4421-2/09/$25.00 c(cid:13)2009 IEEE
199
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 09:56:57 UTC from IEEE Xplore.  Restrictions apply. 
 first use suggests that the register caching could be beneficial.     In [23] a register caching technique is proposed for high performance processors exploiting Out-of-Order Execution technique. The register cache contains register values bypassed within a processor pipeline. If the cache size is properly selected, the register cache supplies most of the bypassed values. In [24] a use-based register caching technique is proposed to enhance the performance of the register caching. This is achieved by not caching the register values whose predicted consumers are satisfied by the bypass network. To achieve this goal, a use predictor is designed to predict the probable number of times a register value is used. Using this predictor prevents caching registers whose consumers are satisfied.  These techniques are designed to reduce the register access time resulting in performance gain. Although register caching for enhancing the performance is a viable solution, it is not profitable in embedded applications. This is because, it imposes power overheads due to use of a cache memory and the additional hardware needed to manage the insertion policy, replacement policy and register use prediction. Moreover, using cache memory increase the occupation area both in combinational and sequential components resulting in higher soft error susceptibility. In fact, performance is not a first order concern in embedded systems design. Therefore, performance gain at the cost of power consumption increase or reliability decrease is not acceptable in such applications.  In [26], a technique called register value caching is proposed to enhance the reliability of the register file for ARM based embedded processors. In this technique, a duplicate version of register values is stored in a small register cache memory. The register cache is protected by the CRC codes. In each read operation, the register value in the register file is compared with its possible stored duplicate value in the register cache. If a mismatch occurs, the register value stored in the register cache is checked. If it is erroneous, the register value stored in the main register file is considered as the correct value otherwise the content of register cache is selected to perform the operation. This technique has two shortcomings: 1) it is not power efficient since in each read operation both register file and register cache are accessed and a comparison is performed; 2) similar to ECC based techniques, this technique cannot cope with SETs in the combinational part of the register file. In the following sections, firstly, we will investigate how the register caching can be used for protecting the register file against particle strike effects such as MBUs and SETs. Secondly, we will show that how the additional power overhead can be minimized with the use of register caching. 4.4. Robust Register Caching Technique (RRC) In this section, we will show that how the register caching can be employed: 1) to store the most vulnerable registers in the register cache; 2) to protect the register file against MBUs and SETs; and 3) to provide conditions in which the clock gating technique can be efficiently used to decrease the imposed power overhead. For the sake of clarity, the proposed technique is explained by answering to the following two questions. 1) Can we efficiently employ register caching for reliability enhancement of the register file? The registers are vulnerable to soft errors when they are containing useful data. In other words, the registers are vulnerable to soft errors when they are in their ACE time. In addition, not all allocated registers are simultaneously in their ACE time. To prove this claim, a set of simulations has been carried out to extract the average number of live registers for different bechmarks. To do this, the total number of registers which are in their ACE time are counted in five parts of the program execution i.e. when 20%, 40%, 60%, 80% and 100% of the program is executed. Finally, the average of the extracted values are shown in Figure 7. As shown in Figure 7, in the average case, maximum number of 25 registers are simultaneously in their ACE time. This implies that, it is not required to protect the entire register file during the whole program execution, but rather it is quite enough to protect only the registers when they are in their ACE time.   Figure 7, the number of live registers during program execution time (E.T=Execution Time) Therefore, if we cache the register file in a way that most of the live registers are stored in the cache and if we protect the register cache with a proper protection technique, we can increase the reliability of the register file with lower power overhead as compared to protection of the entire register file. This is because; most of the live registers are read from the protected cache instead of non-protected register file.  2) How can we employ the cache to provide high level of reliability?  It was shown that using register caching is a viable solution to protect the register file. However, two questions still exist: 1) which protection technique should be employed in the register cache to efficiently protect it against MBUs and SETs?; 2) how can we guarantee that most of the registers are stored in the register cache during their ACE time?  As mentioned in section 3, the circuit level soft error protection techniques are most efficient techniques to cope with particle strikes as 1) they mask the effect of particles at the time of strike; 2) they can protect the circuit both from MBUs and SETs. The main problem is that the circuit level techniques suffer from high area and power overhead when they are used in power consuming parts of the processor such as the register 510152025303540# of Live RegistersE.T.=20%E.T.=40%E.T.=60%E.T.=80%E.T.=100%978-1-4244-4421-2/09/$25.00 c(cid:13)2009 IEEE
200
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 09:56:57 UTC from IEEE Xplore.  Restrictions apply. 
 file. Since the register cache is considerably smaller than the register file, using the SEU/SET tolerant memory elements in the register cache is power and area efficient. In the RRC technique, the register cache is a fully associative cache built by SEU/SET-tolerant flip flops introduced in Section 3.  The main part of a caching technique is the replacement policy that determines the victim entry when the cache is full. As in the RRC technique, the main goal is to hold the registers in the cache when they are in their ACE time, the replacement policy should give the high priority to those registers which are less probable to reach their UN-ACE times. In other words, the victim entry is one which is containing a register value that most of its consumers are satisfied. Therefore, the number of read operation from a register value is a proper criterion to determine the victim cache entry. Consequently, the cache entry containing a register value with highest read count is selected as the victim entry. To reach the aim, a read counter is assigned to each entry of the cache and incremented in each read operation. The question arises here is how to determine the best size for the read counter.  Figure 8, the average number of read operations from a register value  To determine the size of the read counter, a set of simulations has been done to extract the average number of read operations from a register during its ACE time. The simulation results shown in Figure 8 reveal that more than 90% of live registers have at most five read operations during their ACE time. This means that a three-bits read counter is sufficient for determination of the victim entry. The schematic of a register file protected by the RRC technique is depicted in Figure 9. For the sake of simplicity, the RRC technique for write to a register and read from a register operation is explained separately. Write to a Register- in the RRC technique, all new values are stored in the register cache. It means that the new values are not written to the main register file. As shown in Figure 9, there is no data and address path between the processor core and the main register file. When a write operation to a register is issued by the processor, the new data and its delayed version are fed to the register cache. The delay elements are used since the robust FFs require both input and its delayed version for SET tolerance purpose (see Section 3.2). If there is an empty entry in the cache, the new value will be stored in that entry, otherwise one of two following scenarios occurs: 1) the new value is written to a register already cached with an old value, e.g. the new value is written to R0 while R0 already exists in the cache; and 2) there is no empty entry and no entry containing the same register is cached. In the first case, the new value is overwritten with the old one and there is no need to store the old value in the main register file. In the second case, a replacement should be done. In the employed replacement policy, the entry with maximum read count is selected as the victim entry. The value of the victim entry is then stored in a robust buffer. This buffer contains the data, register address, a validation bit that determines if the buffer is containing a victim value and a parity bit. The content of the buffer is copied to the main register file in the beginning of each read and write operations. In fact, the victim value is copied into the main register file in the next read or write operation. This prevents extra cycle imposed for writing the victim entry to the main register file.  Figure 9. the RRC architecture  When a victim register is copied to the main register file, it is probable that it is still in its ACE time so that a parity bit is added to each register in the main register file. Therefore, when a victim value is copied to the buffer, the parity bit of the register value is computed and stored in the corresponding bit. In fact, one- bit parity is used for the main register file for protection of those registers that are transferred from the register cache to the main register file and are still in their ACE time.  To decrease the power consumption of the register file, the clock gating technique is utilized. As mentioned, all new values are written to the register cache, and the main register file is accessed only in read operations and when the buffer is containing valid data. Therefore, the clock of the main register file can be gated when a new data is written to the register cache and the buffer is not containing a valid data. In the next section, we will show that if the cache size is properly selected, clock gating technique can be efficiently employed to significantly reduce the total power consumption.    0%10%20%30%40%50%60%70%80%90%100%Quick SortBubble SortBasic MathBit CountSusanJPEGtiff2rgbatiff-datadijkstraAveragePercentage of Read OperationsBenchmarks>654321Register FileAddressDataBufferRobust Register CacheRead CountParity GeneratorParity CheckerParityDataHit01RDWRCLKRDCLKData+AddressRead DataVVWRClock Gating LogicDelay978-1-4244-4421-2/09/$25.00 c(cid:13)2009 IEEE