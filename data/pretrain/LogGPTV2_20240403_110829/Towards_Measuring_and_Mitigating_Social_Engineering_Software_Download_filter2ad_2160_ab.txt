Repackage
Impersonate
Invent
Alarm
Entice
Comply
Figure 1: Categorization of SE downloads on the web.
clickable links) such as free software, books, music and
movies.
It is not uncommon for these three techniques (ads,
search, and web posts) to be combined. For instance, at-
tackers will use search and ads in combination to get the
user’s attention. Targeted search engine ads related to
the search terms entered by users are often displayed be-
fore the real search results, thus increasing the likelihood
of a click. This common search engine feature is often
abused by attackers. Also, users may search for certain
specific terms on web forums, social network sites, etc.,
and may fall victim to targeted web posts.
Deception and persuasion tactics. After an attacker
gains the user’s attention, they must convince them to
download and install their malicious or unwanted soft-
ware. This typically involves combining a subset of the
deception and persuasion techniques summarized in Fig-
ure 1. As one scrolls from left to right in the figure,
the techniques move from deception towards persuasion.
Notice that none of the techniques we list involve only
deception or only persuasion; instead, the different tech-
niques vary in their levels of each. We now provide a de-
scription of the deception and persuasion classes shown
in Figure 1. We will then present examples of real-world
SE download attacks that make use of a combination of
these techniques.
(1) Decoy: Attackers will purposely place decoy “click-
able” objects, such as a hyperlink, at a location on a
web page that will attract users to it and away from
the actual object desired (or searched) by the user.
An image of a “flashy” download button (e.g., deliv-
ered as an ad banner) on a free download site located
prior to the actual download link desired by the user
is an example of this technique.
(2) Repackage: To distribute malicious and unwanted
software, attackers may group benign and PUP (or
malware) executables together, and present them to
the user as a single application. An example tech-
nique from this class is adware bundled with a be-
nign application and served as a single software
download on a free software distribution website.
(3) Impersonate: Using specific images, words and col-
ors can make an executable appear as if it was a
known popular benign application. Also, claiming
that a software provides desirable features or ser-
vices (though it does not supply them) is a way to
convince the user to download and install the appli-
cation. Malicious executables pretending to be an
Adobe Flash Player update, e.g., by using logos or
icons similar to the original Adobe products and key-
words such as “adobe” and “flash,” is an example of
impersonation techniques from this class.
(4) Invent: Creating a false reality for the user may
compel them to download a malicious or unwanted
executable. For example, alerting the user stat-
ing that their machine is infected with malware and
instructing them to download (malicious) clean-up
software (e.g., a fake AV) is an example of the invent
tactic.
(5) Alarm: Using fear and trepidation aims to scare
the user into downloading (malicious) software that
promises to safeguard them. For instance, an online
ad claiming that the user’s browser is out-of-date and
vulnerable to exploitation is an example of alarm
techniques.
(6) Entice: Attackers often attempt to attract users to
download a malicious or unwanted executable by of-
fering features, content or advantages. As an exam-
ple, a user may be shown an ad for a system opti-
mization utility stating that it will “speedup” their
PC, but hides malicious software.
(7) Comply: A user may be (apparently) required to in-
stall an (malicious) application before she can con-
tinue. For instance, a user visiting a video stream-
ing website may be prompted to install a necessary
“codec” before she can watch a free movie. As the
user is motivated to watch the movie, she complies
with the codec installation request, thus getting in-
fected with malware.
It is important to note that none of the SE attacks in our
study fall into a single class. Instead the in-the-wild SE
attacks we collected often use techniques across two or
more of the above classes to trick the user into infecting
their machine. Labeling a download using these classes
involves understanding the motivations employed to con-
vince a user to install the malicious software. These are
776  25th USENIX Security Symposium 
USENIX Association
4
typically easy to identify by examining the words and
images used in an attack. For instance, an attack that im-
personates will claim to be software that it is not, such
as Adobe Flash Player. On the other hand, an attack that
entices a user will often use words like “free” and de-
scribe all the benefits of installing the software. Entice
and impersonate are not mutually exclusive and are used
together in some SE attacks. Allowing an SE attack to
be assigned to more than one class simplifies the label-
ing process because all perception/deception tactics can
be included, not just the one believed to be the primary
tactic.
3.2 Examples of In-The-Wild SE Attacks
In this section, we present two examples from our
dataset of reconstructed SE download attacks, and clas-
sify their SE tactics using our categorization system (see
Figure 1). To aid in our discussion we define the nota-
tion “attention:deception/persuasion,” where the atten-
tion string refers to how attackers attempt to attract users’
attention, and the deception/persuasion string refers to
the combination of the deception/persuasion techniques
used to trigger the malware download. For example, if an
SE attack relies on an ad and uses alarm and imperson-
ate deception/persuasion tactics, then we label the attack
using our notation as “ad:alarm+impersonate.”
Attack 1. A user searches for “Gary Roberts free pics”
using a popular search engine. A page hosted on a com-
promised website is returned as a top result. The page
contains various content referring to “Gary Roberts”, but
this content is incoherent and likely only present for
blackhat search engine optimization (SEO). However,
the user never sees the content because the javascript
code located at the top of the served page immediately
closes the document, and then reopens it to inject a script
that redirects the user to a page that says “gary-roberts-
free-pics is ready for download. Your file download
should automatically start within seconds. If it doesn’t,
click to restart the download.” But the downloaded file
does not contain any pictures, and instead carries mali-
cious code that is later flagged as malware by some AV
vendors.
Using our categorization system we classify this at-
tack as “search:entice+decoy+impersonate.” Search is
the method of gaining the users attention. In this exam-
ple this is obvious because the SE page appeared in the
results page provided by a search engine. The entice part
of the attack is the offering of “free” pics of the subject of
interest. Decoy is due to the fact that blackhat SEO was
used to elevate the SE page in the search results above
other legitimate pages. Lastly, what the user downloads
is not pics of Gary Roberts; instead, it is a malicious ex-
ecutable impersonating what the user wants (e.g., Gary
Figure 2: SE ad for Ebola early warning system.
Roberts free pictures).
Attack 2. A user is watching an episode of “Agents of
Shield” on a free video website when they are presented
with an ad. The ad, similar to the one shown in Fig-
ure 2, presents the user with the option of downloading
an early warning system for Ebola. However, the down-
loaded file does not provide information about an Ebola
outbreak; instead, it infects the user’s system with mali-
cious software.
We classify this attack as “ad:alarm+impersonate” us-
ing our categorization system. The user’s attention is
gained through an ad, in which their fear of Ebola is used
to alarm the user into downloading a tracking system.
Unfortunately, what the user downloads only imperson-
ates a tracking systems, and instead contains malicious
code.
4 Collecting and Labeling SE Attacks
In this section we discuss in detail how we collected
and labeled our dataset of 2,004 SE download attacks.
We will then present an analysis of the prevalence and
characteristics of the collected attacks in Section 5.
4.1 Data Collection Approach
To collect and reconstruct SE download attacks, we
monitor all web traffic at the edge of a large network (this
study was authorized by our organization’s Institutional
Review Board). Using deep packet inspection, we pro-
cess the network traffic in real-time, reconstructing TCP
connections, analyzing the content of HTTP responses
and recording all traffic related to the download of exe-
cutable files (Windows executables).
While monitoring the traffic, we maintain a buffer
of all recent HTTP transactions (i.e., request-response
pairs) that occurred in the past few minutes. When an
HTTP transaction that carries the download of an exe-
cutable file is found, we passively reconstruct and store a
copy of the file itself. In addition, we trigger a dump of
the traffic buffer, recording all the web traffic generated
USENIX Association  
25th USENIX Security Symposium  777
5
by the same client that initiated the file download dur-
ing the past few minutes before the download started. In
other words, we store all HTTP traffic a client generated
up to (and including) the executable file download.
We then process these HTTP transaction captures us-
ing the trace-back algorithm presented in [30]. The trace-
back algorithm builds a graph where each node is an
HTTP transaction. Given two nodes T1 and T2, they are
connected by an edge if T2 was “likely referred to” by T1.
For instance, a directed edge is drawn from T1 to T2 if the
user clicked on a link in T1’s page and as a consequence
the browser loaded T2. Then, starting from the download
node, the algorithm walks backwards along this graph to
trace back the most likely path (i.e., sequence of HTTP
transactions) that brought the user to initiate the down-
load event. For more details, we refer the reader to [30].
These reconstructed download paths are later analyzed
to identify and categorize SE download attacks. It is im-
portant to note that we do not claim automatic download
path traceback as a contribution of this paper. Instead,
our focus is on the collection, analysis, and categoriza-
tion of SE download attacks, and on the detection and
mitigation of ad-based SE infections. Automatic down-
load traceback is just one of the tools we use to aid in our
analysis.
We deployed the data collection process described
above on a large academic network serving tens of thou-
sands users for a period of two months. To avoid un-
necessarily storing the download traces related to fre-
quent software updates for popular benign software, we
compiled a conservative whitelist consisting of 128 do-
main names owned by major software vendors (e.g., Mi-
crosoft, Adobe, Google, etc.). Therefore, executable files
downloaded from these domains were excluded from our
dataset.
Overall, during our two month deployment, we col-
lected a total of 35,638 executable downloads. The pro-
cess we used to identify the downloads due to SE attacks
is described in the following sections.
4.2 Automatic Data Filtering
Even though we filter out popular benign software up-
dates up front, we found that the majority of executable
downloads observed on a network are updates to (more
or less popular) software already installed on systems.
As we are interested in new infections caused by web-
based SE attacks, we aim to automatically identify and
filter out such software updates.
To this end, we developed a set of conservative heuris-
tics that allow us to identify and filter out most soft-
ware update events based on an analysis of their respec-
tive download path. First, we examine the length of the
download path. The intuition is that software updates
tend to come from very short download paths, which of-
ten consist of a single HTTP request to directly fetch
a new executable file from a software vendor’s web-
site (or one of its mirrors). Conversely, the download
path related to SE download attacks usually consists of a
number of navigation steps (e.g., the may user navigate
through different pages before stumbling upon a mali-
cious SE advertisement).
For the next step in the analysis, we review the user-
agent string observed in the HTTP requests on the down-
load path. The user-agent string appearing in software
update requests is typically not the one used by the
client’s browser (similar observations were made by the
authors of [30]), because the user-agent found in these
requests often contains the name of the software that
is being updated (e.g., Java or Acrobat reader). Since
web-based SE attacks happen to users browsing the web,
HTTP requests on the download path typically carry the
user-agent string of the victim’s browser.
Therefore, to automatically identify and filter out up-
date downloads we use the following heuristics. If the
download path contains a single HTTP transaction (the
update request itself), and the user-agent string does not
indicate that the request has been made by a browser, we
filter out the event from our dataset.
Overall, the conservative filtering approach outlined
above allowed us to reduce the number of download
paths to be further analyzed. Specifically, we were able
to reduce our download traces dataset by 61%, leaving us
with a total of 13,762 that required further analysis and
labeling.
4.3 Analysis of Software Download Events
After filtering, our dataset consists of 13,762 software
download events (i.e., the downloaded executable files
and related download paths) that required further detailed
analysis and labeling. As our primary goal is to create a
high quality dataset of labeled SE download attacks, we
aim to manually analyze and perform a detailed recon-
struction of the attacks captured by our archive of soft-
ware download events.
To aid in the manual analysis process and reduce the
cost of this time-consuming effort, we leveraged unsu-
pervised learning techniques. Specifically, we identify
a number of statistical features that allow us to discover
clusters of download events that are similar to each other.
For instance, we aim to group different downloads of the
same benign software by different clients. At the same
time, we also aim to group together similar download
events triggered by the same SE attack campaign.
To identify and automatically clusters similar down-
load events, we developed a set of statistical features. We
would like to emphasize that none of the features we de-
scribe below is able to independently yield high-quality
778  25th USENIX Security Symposium 
USENIX Association
6
clustering results. Rather, it is the combination of these
features that allows us to obtain high quality clusters of
related software download events.
Notice also that the purpose of this clustering process
is simply to reduce the time needed to manually analyze
the software download events we collected. By using a
conservative clustering threshold (discussed below) and
by manually reviewing all obtained clusters, we mini-
mize the impact of possible noise in the results.
To perform the clustering, we leverage a number of
simple statistical features, some of which (e.g., URL
similarity, domain name similarity, etc.) are commonly
used to find the similarity between network-level events.
Notice, however, that our main goal in this clustering
process is not to design novel features; rather, we simply
aim to reduce the manual analysis and labeling efforts
needed to produce a high-quality dataset of in-the-wild
SE download attacks.
We now describe our clustering features:
(1) Filename Similarity: Benign executable files dis-
tributed by the same organization (e.g., an applica-
tion distributed by a given vendor or software distri-
bution site) tend to have similar filenames. Notice
that often this also holds for SE attack campaigns,
because the files distributed by the same campaign
often follow a consistent “theme” to aid in the de-
ception of the end users. For instance, the malware