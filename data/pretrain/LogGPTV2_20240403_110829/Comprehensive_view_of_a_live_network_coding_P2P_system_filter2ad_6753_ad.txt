7. SECURITY
A common concern about network coding is the protection against
malicious users. Unlike unencoded transmission, where the server
knows and can digitally sign each block, in network coding each in-
termediate node produces “new” blocks. Homomorphic hash func-
tions can be used to verify the encoded blocks using the hashes
of the original blocks, however, such functions are computation-
ally expensive [24]. Our scheme is based on the use of random
masks and mask-based hashes, which we refer to as Secure Ran-
dom Checksums (SRCs). SRCs provide signatures capable of ver-
ifying the integrity of encoded blocks on-the-ﬂy at a low computa-
tion cost. SRCs also have the nice property that they work well with
Galois Fields (and not just with modular ﬁelds, which are known
to be produce more expensive operations, as is the case with homo-
morphic hash functions).
Pm
We now give a high-level explanation of how SRCs work. To
produce an SRC, the server creates a vector r = [r1 . . . rm] of ran-
dom elements in Zq (often q = 16 digits). The size of the vector
m is the number of symbols per block (for a block of 2 MBytes m
is 2 ∗ 10242). Then, the server performs pairwise multiplication
of the vector of random elements with the vector of symbols of a
particular block and adds the results in GF (2q). For example, as-
sume that the symbols of block i are bi = [bi,1 . . . bi,m] and the
random numbers are r = [r1 . . . rm], then the SRC of block i is
j=1 rjbi,j. The same process is repeated for all n ﬁle blocks.
Together with the SRCs, the random element vector is transmitted
(note that the set of random elements can be replaced with the seed
used for the random number generator). Because of the linearity
of the computation, it is easy to show that the SRC of an encoded
block can be computed from the SRCs of the original blocks. In
i=1 cibi, correspond-
ing to coefﬁcient vector ~c. To verify whether encoded block e is
corrupted or not, a node applies the random vector to the e block
and checks whether the following equation holds:
particular, assume an encoded block e = Pn
3NAT traversal techniques can solve the connectivity problem [17];
in this work we are interested in investigating the throughput poten-
tial in the absence of such techniques
4 In our system, (unreachable) nodes periodically attempt to initi-
ate upload connections to other nodes in order to fully utilize their
upload capacity.
Figure 10: The effect of unreachable peers on the overall performance for two trials (left: Trial-1, right: Trial-4). The top curves are
computed assuming all nodes are reachable; the lower curves take into consideration the set of unreachable peers over time.
j=1 rjej = Pm
Pm
= Pn
j=1 rj(Pn
i=1 ci(Pm
i=1 cibi,j)
j=1 rjbi,j)
The size of each random element rj is q bits. Rather than sending
the random mask vector, in our implementation, each node down-
loads the seed used by the server to generate the random mask.
Based on the seed, nodes can reproduce the random mask vector
~r locally. The size of the seed is 128 bits, which is negligible. In
addition to the seed, each node also downloads the per-block SRC
value. The size of the SRCs for all blocks in the ﬁle is n · q bits,
which results in 2 KBytes for a 1000 block ﬁle.
When a new client joins the system, it ﬁrst contacts the server
which computes a new set of SRCs for that client and communi-
cates the SRCs to the client over a secure channel. The client keeps
the SRCs secret, since if they are revealed, a malicious node can
efﬁciently fabricate corrupted blocks. A malicious node that does
not know the SRCs can trick a node only by pure luck. If the client
receives many SRCs,5 then it is computational infeasible for an at-
tacker to construct corrupted encoded blocks without the corruption
being detected.
The SRCs are linear operations and can be computed very efﬁ-
ciently. In our current implementation running on a 3.0 GHz Pen-
tium 4 with 1GB of RAM, SRC generation takes 1 sec/SRC for ﬁle
of 2 GBytes, which is close to the cost of reading the ﬁle once. In
the current implementation, the cost of producing SRCs increases
linearly with the size of the ﬁle. However, more efﬁcient imple-
mentations are possible. Note that for a smaller ﬁle size (e.g. 200
MBytes), one single server can produce SRCs to serve peers at a
rate of 10 peers/sec, or 864,000 users/day. Also, the rate of genera-
tion of SRCs at the server is not that critical since it is a process that
can happen in the background before the download commences.
The rate of SRC veriﬁcation is close to 1.6 Gbps, which is much
faster than the rate at which encoded blocks can be generated. In
general, we have observed a negligable impact caused by SRC ver-
iﬁcation on the nodes performance.
8. RELATED WORK
Understanding and evaluating swarming protocols has been an im-
portant topic in the recent years. For instance, [3] compares differ-
ent swarming strategies and discusses the impact of the number of
blocks and the number of simultaneous uploads. They show that
5In our implementation each symbol is 16 bits long, and hence 10
SRCs result in 160 random bits
the number of chunks should be large and that the number of si-
multaneous uploads should be between 3 and 5 in order to have
good efﬁciency. Qiu and Srikant [29] provided an analytical solu-
tion to a ﬂuid model of BitTorrent with global information. Felber
et al. [9] compared different peer and piece selection strategies in
static scenarios using simulations. Bharambe et al. [2] presented a
simulation-based study of BitTorrent using a discrete-event simula-
tor that supports up to 5000 peers and found different inefﬁciencies
using peer sets lower than 15 peers. Izal et al. [21] provided insights
into BitTorrent based on data collected from a popular tracker log
from a local peer perspective. Our work differs in that it provides
detailed experimental results of a live P2P distribution system from
a variety of novel angles by monitoring all its components. In ad-
dition, our paper provides details of our experiences with network
coding in a P2P environment.
A number of cooperative architectures [23] [4] have proposed the
use of Erasure Codes [28] (e.g. Digital Fountain [5]) to efﬁciently
transfer bulk data. However, in such systems the set of symbols
acquired by nodes is likely to overlap substantially, and care must
be taken to enable nodes to collaborate effectively. This makes co-
operation and reconciliation among nodes more difﬁcult than when
no content is encoded. Network coding can be seen as an extension
or generalization of the Digital Fountain approach since both the
server and the end-system nodes perform information encoding.
Most of the previous work on network coding is largely based
on theoretical calculations that assume a detailed knowledge of the
topology, a centralized knowledge point for computing the distribu-
tion scheme and focus on multicast environments. However, little
effort has been made to build and evaluate the feasibility of net-
work coding on a real setting. In [11] we provided a comparison
of different swarming algorithms and evaluated via simulations the
performance of a network coding in P2P systems. However, it was
believed that network coding could not be made practical in real
settings due to its computational complexity and the difﬁculties
protecting against block pollution attacks. Our work focuses on
the study of a live network coding P2P system. In a similar spirit,
recent work by Katti et al. [22] provides the ﬁrst implementation
results of network coding in Wireless networks. The authors imple-
mented and tested network coding in a mesh wireless network and
showed important beneﬁts when multiple unicast ﬂows are mixed.
9. SUMMARY
In this paper we have described our experiences with a P2P system
that uses network coding. Based on a prototype implementation of
our system and the result of several live distributions, we show that
network coding overhead is relatively small, both in terms of CPU
processing and I/O activity. We also describe a scheme for efﬁ-
cient veriﬁcation of encoded blocks and show that the veriﬁcation
process is very efﬁcient.
Moreover, we measure a high utilization of the system resources
and large savings for the content provider even during ﬂash-crowd
events. We also observed a smooth ﬁle download progress (i.e.
users do not spend much time in the beginning or the end of the
download), and very efﬁcient utilization of the server capacity.
While coding obviates the need for fancy block selection algo-
rithms, the system’s efﬁciency still depends largely on how peers
are connected. We provide an initial description of the impact that
unreachable nodes can have and show that surprisingly the system
is highly resilient to very large number of unreachable peers (e.g.
as high as 70%). We also show that the topology construction al-
gorithms can have a signiﬁcant impact in the overall system perfor-
mance. However, a deeper analysis is required to better understand
the impact of peer-matching algorithms in the system’s efﬁciency
(e.g. algorithms that take into account connectivity or access rates
to pair nodes).
10. REFERENCES
[1] R. Ahlswede, N. Cai, S. R. Li, and R. W. Yeung. Network
information ﬂow. IEEE Transactions on Information Theory,
2000.
[2] A. Bharambe, C. Herley, and Venkat Padmanabhan.
Analysing and improving bittorrent performance. In Infocom
2006, 2006.
[3] Ernst Biersack, Pablo Rodriguez, and Pascal Felber.
Performance analysis of peer-to-peer networks for ﬁle
distribution. In Fifth International Workshop on Quality of
Future Internet Services (QofIS04), 2004.
[4] John Byers, Jeffrey Considine, Michael Mitzenmacher, and
Stanislav Rost. Informed content delivery across adaptive
overlay networks. In SIGCOMM, Pittsburgh, PA, 2002.
ACM.
[5] John Byers, Michael Luby, Michael Mitzenmacher, and
Ashutosh Rege. A digital fountain approach to reliable
distribution of bulk data. In SIGCOMM, 1998.
[6] P. A. Chou, Y. Wu, and K Jain. Practical network coding. In
Allerton Conference on Communication, Control, and
Computing, 2003.
[7] Fan R. K. Chung. Spectral graph theory. Regional
conference series in mathematics, no. 92. Published for the
Conference Board of the mathematical sciences by the
American Mathematical Society, Providence, R.I., 1997. Fan
R.K. Chung. 26 cm. ”CBMS Conference on Recent
Advances in Spectral Graph Theory held at California State
University at Fresno, June 6-10, 1994”–T.p. verso.
[8] Bram Cohen. .
[9] P. Felber and Ernst Biersack. Self-scaling networks for
content distribution. In International Workshop on Self
Properties in Complex Information Systems, 2004.
[10] C. Fragouli, J.-Y. Le Boudec, and J. Widmer. Network
coding: An instant primer. Technical Report TR-2005-010,
EPFL, 2005.
[11] C. Gkantsidis and P. Rodriguez. Network coding for large
scale content distribution. In IEEE Incofom, Miami, FL,
2005.
[12] C. Gkantsidis and P. Rodriguez. Cooperative security for
network coding ﬁle distribution. In IEEE Infocom, 2006.
[13] Christos Gkantsidis, Milena Mihail, and Amin Saberi.
Conductance and congestion in power law graphs. In ACM
SIGMETRICS, pages 148–159, San Diego, CA, US, 2003.
ACM Press.
[14] Christos Gkantsidis, Milena Mihail, and Amin Saberi.
Random walks in peer-to-peer networks. In IEEE Infocom,
Hong Kong, 2004.
[15] Christos Gkantsidis, Milena Mihail, and Ellen Zegura. The
markov chain simulation method for generating connected
power law random graphs. In SIAM Alenex, Baltimore, MD,
2003.
[16] Christos Gkantsidis, Milena Mihail, and Ellen Zegura.
Spectral analysis of Internet topologies. In IEEE Infocom,
San Francisco, CA, US, 2003.
[17] S. Guha and P. Francis. Characterization and measurement of
TCP traversal through NATs and ﬁrewalls. In ACM IMC,
2005.
[18] Tracey Ho, Ralf Koetter, Muriel Medard, David R. Karger,
and Michelle Effros. The beneﬁts of coding over routing in a
randomized setting. In IEEE International Symposium on
Information Theory (ISIT), page 442, Yokohama, Japan,
2003.
[19] BBC iMP. .
[20] AOL In2TV.
.
[21] M. Izal, G. Urvoy-Keller, E. W. Biersack, P. Felber, A. Al
Hamra, and L. Garces-Erice. Dissecting bittorrent: Five
months in a torrent’s lifetime. In Passive and Active
Measurements (PAM), 2004.
[22] S. Katti, H. Rahul, W. Hu, D. Katabi, J. Crowcroft, and
M. Medard. Network coding made practical. ,
2006.
[23] D. Kostic, A. Rodriguez, J. Albrecht, and A. Vahdat. Bullet:
High bandwidth data dissemination using an overlay mesh.
In Symposium on Operating Systems Principles (SOSP),
2003.
[24] M. N. Krohn, M. J. Freedman, and D. Mazieres. On-the-ﬂy
veriﬁcation of rateless erasure codes for efﬁcient content
distribution. In IEEE Symposium on Security and Privacy,
2004.
[25] Ching Law and Kai-Yeung Siu. Distributed construction of
random expander networks. In IEEE Infocom, San Francisco,
CA, USA, 2003.
[26] Zongpeng Li, Baochun Li, and Lap Chi Lau. On achieving
maximum information ﬂow rates in undirected networks.
Joint Special Issue on Networking and Information Theory,
IEEE Transactions on Information Theory and IEEE/ACM
Transactions on Networking, June 2006.
[27] David Mackay. Information theory, inference, and learning
algorithms. In Cambridge University Press, 2003.
[28] Petar Maymounkov and David Mazires. Rateless codes and
big downloads. In IPTPS’03, 2003.
[29] D. Qiu and R. Srikant. Modeling and performance analysis
of bittorrentlike peer-to-peer networks. In ACM
SIGCOMM04, Portland, 2004.
[30] Ye Tian, D. Wu, and K.-W. Ng. Modeling, analysis and
improvement for bittorrent-like ﬁle sharing networks. In
IEEE Infocom, 2006.
[31] V. Vishnumurthy and P. Francis. On heterogeneous overlay
construction and random node selection in unstructured p2p
networks. In IEEE Infocom, 2006.