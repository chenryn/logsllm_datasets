by saying that h1(t) shall not be lower than h2(t), or equivalently,
t  2, the weight gi is distributed uniformly around the original
ﬂow length N i. The lowest two weights g0 and gi are distributed
in two regions [1, t(2)] and (t(2), (cid:9)3N/2(cid:10)] where t(2) is determined
the details. We call the resulting inferred frequencies (cid:5)f
from the lowest two weights g0 and g1 analogously to (6); we omit
(cid:5)f
of Section 4.3. (cid:5)f (2) uses more data, and thus should be subject to
i ∈ [1, t(2)]
i ∈ (t(2),(cid:2)3N/2(cid:3)],
i ∈ (iN (j), iN (j + 1)], j ≥ 2
A discussion of the relative advantages of (7) and (8) reﬂects that
 g0/t(2),
(cid:4)3N/2(cid:5)−t
gj/N,
(2)
i =
(2)
i
(2) ,
(8)
g1
:
smaller variance. However, (cid:5)f (1) is less susceptible to the effects of
properties of (cid:5)f (1) and (cid:5)f (2) in Section 7.2.
ﬂow splitting, under our assumptions, since it counts at most one
measured ﬂow from each TCP ﬂow. We compare the experimental
5.
INVERSION AND ITS DEFICIENCIES
Before proceeding to the full ML estimator, we brieﬂy examine
an unbiased estimator, then discard it due to high variance. This
estimator exploits the fact the expected values of the sampled fre-
quencies gi are an invertible function of the original frequencies fi.
Here we assume independent packet sampling with probability p,
we ignore splitting, and assume that the original ﬂow lengths are
bounded above by some m. Under these assumptions, the gi have
m
expectation E[gj] =
i=1 Cji(m)fi, where Cji(m) = Bp(i, j)
for m ≥ i ≥ j ≥ 1 and 0 otherwise. We can prove that
(cid:4)
−j−i
ij (m) = Bp(i, j)(−p)
−1
Lemma 3. C(m) is invertible: C
for m ≥ j ≥ i ≥ 1 and 0 otherwise.
This suggests estimating fi from measured gi as (cid:5)f = C
−1(m)g,
taking as m the maximum desired original ﬂow length. However,
this estimator is not well-behaved. The alternating parity with j of
−1
the components C
ij (m) makes estimates very sensitive to vari-
ations in g; some of the estimated frequencies may be negative.
This is manifested in the growth of the variance with m: it can be
−m = N m. Unless the possible ﬂow
shown that Var (cid:5)fi grows like p
lengths are small, variance rapidly makes the estimator useless.
6. MAXIMUM LIKELIHOOD ESTIMATION
OF FLOW LENGTH DISTRIBUTIONS
While simple to compute, the multiplicative scaling-based es-
timators f (1) and f (2) have the disadvantage that their coarseness
increases on the scale of N. In this section we present a direct MLE
of the original ﬂow length frequencies that, with sufﬁcient data, can
provide smoothing at all scales. The method has two versions. The
ﬁrst exploits the sampling properties of SYN ﬂows to estimate TCP
ﬂow frequencies; the second does not rely on the properties of SYN
ﬂows and hence is not restricted to TCP trafﬁc. In what follows we
assume that splitting due to sparseness has been suppressed by any
of the means described in Section 2.5.
6.1 ML Estimation for TCP Flows
6.1.1 Likelihood Function and Stationary Points
Let there be n original ﬂows, and let φi denote the probability
that an original ﬂow has i packets. All original ﬂows are assumed
to contain exactly one SYN packet. We assume independent packet
sampling with probability p = 1/N. Our aim is to estimate n and
φ = {φi}, from the frequencies gSYN = {gSYN
i } of sampled SYN
ﬂows of length i. We now derive an expression for log-likelihood
J (n, φ) to obtain gSYN given n and φ.
The probability the an original SYN ﬂow gives rise to a sampled
SYN ﬂow is p, i.e., the probability that the SYN packet is sam-
pled. Hence the probability to obtain γSYN =
sampled
K(n) = Bp(n, γSYN).
SYN ﬂows in total is e
Ignoring splitting,
the probability the sampled SYN ﬂow has j packets is
i≥1 φicij
where cij is the binomial probability Bp(i − 1, j − 1). Hence
(cid:3)
J (n, φ) = K(n) + L(φ), where
(cid:3)
(cid:4)
i gSYN
i
(cid:4)
L(φ) =
gSYN
j
φicij
log
i≥j
(9)
j≥1
(cid:4)
K and L can be are maximized independently over n and φ respec-
of K(n) are as described in Lemma 1.
∗
tively. The maximizer(s) n
Following Lemma 2(i), we estimate n by M (3) = γp
We wish to maximize L(φ) subject to the constraints φ ∈ ∆ =
{φ : φi ≥ 0,
i φi = 1}. Candidates for the MLE are stationary
points of L. Since log is concave, so is L and hence L has a unique
(cid:4)
∗
. Differentiating (9) w.r.t. φi, subject to the
stationary point φ
constraint
must be such that the derivative:
∗
i φi = 1, then φ
−1.
(cid:3)
=
j
j(cid:4)
cij gSYN
k≥j φkckj
∂L(φ)
∂φi
∗
is independent of i for φ
(cid:4)
(10)
(cid:4)
∗
i for which gSYN
. Any φ
j
i≥j φ
−1)ijgSYN
is proportional to
∗
i cij this property, and in particular, the (normalized) inver-
found from Lemma 3. As discussed
sion estimator
j (c
∗
∗
in Section 5, φ
is not guaranteed to lie in ∆: some of the φ
i may
be negative. In this case, the MLE must lie in the boundary of ∆,
but not be a stationary point of L.
6.1.2 Expectation Maximization Algorithm
j
Location of a non-stationary MLE on a boundary by analytical
means is generally difﬁcult. We adopt instead a standard itera-
tive approach: the Expectation Maximization (EM) algorithm [7],
whose application we now describe.
(i) Initialization. Pick some initial ﬂow length distribution φ(0), for
example, the estimate obtained in Section 4.2.
(ii) Expectation. Let f SYN
ij denote the frequencies of original SYN
ﬂows from which j packets are sampled, including the SYN packet.
Thus gSYN
is the frequency of
original SYN ﬂows of i packets whose SYN packet is sampled.
Form the complete data likelihood function assuming known fSYN
ij :
ij , while f SYN
(cid:4)
(cid:4)
j f SYN
i f SYN
i =
j =
ij
f SYN
ij
log φicij .
(11)
Lc(φ) =
(cid:3)
i≥j≥1
Form the expectation Q(φ, φ(k)) of Lc(φ) conditional on the known
frequencies gSYN
, according to a distribution φ(k):
j
Q(φ, φ
(k)
) =
Eφ
(k) [f SYN
ij
| gSYN] log φicij
(12)
(cid:3)
i≥j
(iii) Maximization. Deﬁne φ(k+1) = arg maxφ∈∆ Q(φ, φ(k)). Dif-
ferentiating to ﬁnd the stationary point φ(k+1) in the interior of ∆:
(k+1)
i
φ
=
Eφ
(k) [f SYN
i
γSYN
| gSYN]
=
(k)
i
φ
γSYN
(cid:3)
i≥j≥1
j(cid:4)
cij gSYN
(k)
l≥j φ
l clj
(13)
The ﬁrst equality in (13) arises from the Legendre equations in the
maximization of Q(φ, φ(k)) subject to φ ∈ ∆. The second equal-
ity can be established through direct computation of the conditional
probability. φ(k+1) can be thought of as reﬁning the estimate φ(k)
as the expected proportions of sampled SYN ﬂows under the prob-
ability distribution φ(k), given the measured frequencies gSYN.
(iv) Iteration. Iterate steps (ii) and (iii) until some termination cri-
terion is satisﬁed, e.g., some metric distance between successive
iterates falls below a speciﬁed threshold. Let (cid:5)φ denote the termi-
original ﬂows as (cid:5)f
nation point. We write our estimate of the absolute frequencies of
i = M (3)(cid:5)φi.
(3)
6.2 ML Estimation for General Flows
For general ﬂows—e.g. those using the UDP protocol that has
no SYN ﬂag or equivalent—we cannot directly estimate the num-
ber of original ﬂows from the number of measured ﬂows. This is
because the probability for a ﬂow to be sampled depends on its
length, whose distribution is what we are trying to determine! In-
stead we adopt a two stage approach. The ﬁrst stage is to estimate
(cid:2)
the frequencies φ
i of original ﬂows of length i conditional on at
least one of its packets being selected. The second stage is to re-
cover the unconditional distribution.
(cid:2)
In order to estimate φ
, we can reuse the formulation of Sec-
tion 6.1.2. This involves constructing analogs of the likelihood
functions L and Lc for the conditional length distribution, and in
particular the the iteration (13), with the following changes. Re-
ij = Bp(i, j)/(1−
(cid:2)
(cid:2)
place gSYN by g, γSYN by γ; φ by φ
and cij by c
With this modiﬁcation, the EM iteration yields an estimate(cid:5)φ
Bp(i, 0), the probability that j packets are sampled form a ﬂow
of length i, conditional on j ≥ 1, i.e., that the ﬂow is sampled.
(cid:2)
(cid:2)