x
x
x
x
Reduction Over
CMTB
KSS
42.62% 90.20%
35.56%
62.97%
48.82%
41.05%
36.41%
91.73%
91.93%
92.08%
x
x
x
x
x
x
x
x
x
x
Table 3: Bandwidth measures for all experiment circuits. Note that there is as much as a 84% reduction in bandwidth
when using the Whitewash protocol.
part of this efﬁciency improvement results from the underlying protocol of Whitewash, which uses only symmetric-key
operations outside of the oblivious transfers between the servers. The reduced non-XOR gate counts and more compact
circuit representation of the PCF compiler also contribute to this improvement. Ultimately, because Whitewash ensures
that the phone participates minimally in the protocol, it no longer acts as a bottleneck on computation. We essentially
reduce performance of our outsourcing protocol to that of the underlying two-party protocol, allowing this technique
for outsourcing to beneﬁt as more improvements are made in non-outsourced garbled circuit protocols. In addition,
this minimal level of interactivity allows us to run these protocols with 256 circuits, equivalent to a security parameter
of approximately 80-bit security, which is agreed by the research community to be an adequate security parameter.
Finally, since the phone is active for mere seconds during this large computation, its system resources are free for other
user applications while the servers complete the computation. This shows that Whitewash is capable of evaluating the
same circuits as the most efﬁcient desktop-based garbled circuit protocols with a minimal overhead cost. For full
experimental results, see Appendix B.
13
WWCMTB100101102103Time (sec)  CHKSMOBIEVLOTOTEVLMOBICHKSFigure 5: An example of the privacy-preserving navigation application of CMTB [6] retroﬁtted to use the Whitewash
protocol. Such an application would allow a mobile user to compute the fastest route between two points using a
mapping service that possesses potentially proprietary or secret geographic information. This application has many
uses in military (troop movement), government (dignitary motorcade), and commercial (supply chain) settings.
6.4 Network Bandwidth
The Whitewash protocol not only improves the speed of execution when outsourcing garbled circuit computation, it
also signiﬁcantly reduces the amount of bandwidth required by the mobile device to participate in the computation.
Table 3 shows the bandwidth used by the mobile device for each test circuit. In the best case, for Dijkstra’s algorithm
over 50 node graphs, we observed a 92% reduction in bandwidth between Whitewash and CMTB. This is a result of
the mobile device not performing OTs and only sending relatively small symmetric-key values instead of algebraic
elements for consistency checks. For all test circuits, we observed a small decrease in the amount of improvement
between the two protocols as the input size increased. This is because the number of commitments sent by the phone
in Whitewash increases as the size of the input grows, while CMTB performs a ﬁxed number of OTs as the input size
increases. However, the obvious transfers still require a signiﬁcant enough amount of bandwidth to make removing
them the most efﬁcient option. When comparing to not outsourcing garbled circuit generation, the cost of oblivious
transfers and sending several copies of the garbled circuit to the evaluator quickly adds up to a signiﬁcant bandwidth
cost. For the smallest circuit evaluated, outsourcing the circuit garbling reduces the required amount of bandwidth by
90%. The importance of these bandwidth reductions is further highlighted when considering mobile power savings.
With data transmission costing roughly 100 times as much power as computation on the same amount of data, any
reduction in the bandwidth required by a protocol implies a critical improvement in practicality.
One challenge encountered during the implementation of the Whitewash protocol was the extensive use of hardware-
speciﬁc functions used to implement commitment schemes in shelat and Shen’s code. Rather than try to port this code
over to Android, which would require signiﬁcant development of hardware-speciﬁc libraries, we chose to implement
the protocol in an equivalently secure manner by having the Cloud generate part of the commitments (which requires
these functions) and send them to the mobile device. The mobile device then ﬁnishes generating the commitments that
match its input and forwards them to the evaluator. If we were to implement these machine-speciﬁc instruction, we
14
Figure 6: Execution time (s) for Dijkstra’s algorithm with input sizes of 10, 20, and 50 node graphs for σ = 256. This
ﬁgure shows that the Whitewash protocol allows for computation that was only feasible to be executed in a close to
practically useful time frame.
could further reduce the measured bandwidth values by over 60%. With already signiﬁcant bandwidth reductions from
previous outsourcing schemes, our protocol will see further improvements as mobile hardware begins to incorporate
these machine-speciﬁc libraries in the next few years.
7 Conclusion
With the increasingly pervasive and personal nature of mobile computing, garbled circuits provide a solution that pre-
serves both user privacy and application functionality. However, to make these computationally expensive protocols
usable on mobile devices, secure outsourcing to the cloud is necessary. We develop a new scheme that eliminates the
most costly operations, including oblivious transfers, from the mobile device. By requiring that the mobile device
instead produce the randomness required for circuit generation, we signiﬁcantly reduce the number of algebraic group
operations and communication rounds for the mobile device. Our performance evaluation shows performance gains
as high as 98% for execution time and 92% for bandwidth over the previous outsourcing protocol. These improve-
ments allow large circuits representing practical applications to be computed efﬁciently from a mobile device. As a
result, we show that the use of garbled circuits can be made nearly as efﬁcient for mobile devices as it is becoming for
server-class machines.
Acknowledgments This material is based on research sponsored by DARPA under agreement number FA8750-11-
2-0211. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwith-
standing any copyright notation thereon. The views and conclusions contained herein are those of the authors and
should not be interpreted as necessarily representing the ofﬁcial policies or endorsements, either expressed or implied,
of DARPA or the U.S. Government.
References
[1] ATALLAH, M. J., AND FRIKKEN, K. B. Securely outsourcing linear algebra computations. In Proceedings of
the ACM Symposium on Information, Computer and Communications Security (ASIACCS) (2010).
[2] AUMANN, Y. Security Against Covert Adversaries: Efﬁcient Protocols for Realistic Adversaries. Journal of
Cryptology 18, 3 (2010), 554–343.
[3] BEAVER, D. Server-assisted cryptography. In Proceedings of the workshop on New security paradigms (NSPW)
(1998).
15
Dijkstra 10Dijkstra 20Dijkstra 500500100015002000CircuitTime (sec)  WWCMTB[4] BRICKELL, J., AND SHMATIKOV, V. Privacy-preserving graph algorithms in the semi-honest model. In Pro-
ceedings of the international conference on Theory and Application of Cryptology and Information Security
(2005).
[5] CARTER, H., AMRUTKAR, C., DACOSTA, I., AND TRAYNOR, P. For your phone only: custom protocols for
efﬁcient secure function evaluation on mobile devices. Journal of Security and Communication Networks (SCN)
(To appear 2014).
[6] CARTER, H., MOOD, B., TRAYNOR, P., AND BUTLER, K. Secure Outsourced Garbled Circuit Evaluation for
Mobile Devices. In Proceedings of the USENIX Security Symposium (2013).
[7] COMSCORE.
comScore Reports February 2013 U.S. Smartphone Subscriber Market Share.
http://www.comscore.com/Insights/Press_Releases/2013/4/comScore_Reports_
February_2013_U.S._Smartphone_Subscriber_Market_Share, 2013.
[8] DAMG ˚ARD, I., GEISLER, M., AND NIELSEN, J. B. From passive to covert security at low cost. In Proceedings
of the 7th international conference on Theory of Cryptography (2010).
[9] DAMGARD, I., PASTRO, V., SMART, N., AND ZAKARIAS, S. Multiparty computation from somewhat ho-
In Proceedings of the Annual International Cryptology Conference on Advances in
momorphic encryption.
Cryptology (2012).
[10] GENTRY, C., HALEVI, S., AND SMART, N. P. Homomorphic evaluation of the AES circuit. In Advances in
Cryptology - CRYPTO (2012).
[11] GORDON, S. D., KATZ, J., KOLESNIKOV, V., LABS, A.-L. B., KRELL, F., AND RAYKOVA, M. Secure Two-
Party Computation in Sublinear (Amortized) Time. In Proceedings of the ACM conference on Computer and
communications security (CCS) (2012).
[12] GREEN, M., HOHENBERGER, S., AND WATERS, B. Outsourcing the Decryption of ABE Ciphertexts.
Proceedings of the USENIX Security Symposium (2011).
In
[13] HAZAY, C., AND LINDELL, Y. Efﬁcient Protocols for Set Intersection and Pattern Matching with Security
Against Malicious and Covert Adversaries. Journal of Cryptology 23, 3 (2008), 422–456.
[14] HUANG, Y., EVANS, D., KATZ, J., AND MALKA, L. Faster Secure Two-Party Computation Using Garbled
Circuits. In Proceedings of the USENIX Security Symposium (2011).
[15] HUANG, Y., KATZ, J., AND EVANS, D. Quid-pro-quo-tocols: Strengthening semi-honest protocols with dual
execution. In Proceedings of the IEEE Symposium on Security and Privacy (2012).
[16] HUANG, Y., KATZ, J., AND EVANS, D. Efﬁcient secure two-party computation using symmetric cut-and-
choose. In Advances in Cryptology–CRYPTO (2013).
[17] HUSTEAD, N., MYERS, S., ABHI SHELAT, AND GRUBBS, P. GPU and CPU parallelization of honest-but-
curious secure two-party computation. In Proceedings of the Annual Computer Security Applications Conference
(ACSAC) (2013).
[18] ILIEV, A., AND SMITH, S. W. Small, Stupid, and Scalable: Secure Computing with Faerieplay. In The ACM
Workshop on Scalable Trusted Computing (2010).
[19] JHA, S., KRUGER, L., AND SHMATIKOV, V. Towards practical privacy for genomic computation. In Proceed-
ings of the IEEE Symposium on Security and Privacy (2008).
[20] KAMARA, S., MOHASSEL, P., AND RAYKOVA, M. Outsourcing multi-party computation. Cryptology ePrint
Archive, Report 2011/272, 2011. http://eprint.iacr.org/.
[21] KAMARA, S., MOHASSEL, P., AND RIVA, B. Salus: A system for server-aided secure function evaluation. In
Proceedings of the ACM conference on Computer and communications security (CCS) (2012).
16
[22] KERSCHBAUM, F. Collusion-resistant outsourcing of private set intersection. In Proceedings of the ACM Sym-
posium on Applied Computing (2012).
[23] KIRAZ, M., AND SCHOENMAKERS, B. A Protocol Issue for The Malicious Case of Yao’s Garbled Circuit
Construction. In Proceedings of the Symposium on Information Theory in the Benelux (2006).
[24] KIRAZ, M. S. Secure and Fair Two-Party Computation. PhD thesis, Technische Universiteit Eindhoven, 2008.
[25] KREUTER, B., SHELAT, A., MOOD, B., AND BUTLER, K. PCF: A portable circuit format for scalable two-party
secure computation. In Proceedings of the USENIX Security Symposium (2013).
[26] KREUTER, B., SHELAT, A., AND SHEN, C. Billion-Gate Secure Computation with Malicious Adversaries. In
Proceedings of the USENIX Security Symposium (2012).
[27] KRUGER, L., JHA, S., GOH, E.-J., AND BONEH, D. Secure Function Evaluation with Ordered Binary Decision
Diagrams. In Proceedings of the ACM conference on Computer and communications security (CCS) (2006).
[28] LINDELL, Y. Fast cut-and-choose based protocols for malicious and covert adversaries.
Cryptology–CRYPTO (2013).
In Advances in
[29] LINDELL, Y., AND PINKAS, B. Privacy preserving data mining. In Proceedings of the Annual International
Cryptology Conference on Advances in Cryptology (2000).
[30] LINDELL, Y., AND PINKAS, B. An efﬁcient protocol for secure two-party computation in the presence of
malicious adversaries. In Proceedings of the annual international conference on Advances in Cryptology (2007).
[31] LINDELL, Y., AND PINKAS, B. Secure two-party computation via cut-and-choose oblivious transfer. In Pro-
ceedings of the conference on Theory of cryptography (2011).
[32] MALKA, L. Vmcrypt: modular software architecture for scalable secure computation. In Proceedings of the
18th ACM conference on Computer and communications security (2011).
[33] MALKHI, D., NISAN, N., PINKAS, B., AND SELLA, Y. Fairplay–a secure two-party computation system. In
Proceedings of the USENIX Security Symposium (2004).
[34] MIYAJI, A., AND RAHMAN, M. S. Privacy-preserving data mining in presence of covert adversaries.
Proceedings of the international conference on Advanced data mining and applications: Part I (2010).
In
[35] MOHASSEL, P., AND FRANKLIN, M. Efﬁciency tradeoffs for malicious two-party computation. In Proceedings
of the Public Key Cryptography conference (2006).
[36] SHELAT, A., AND SHEN, C.-H. Two-output secure computation with malicious adversaries. In Proceedings of
the Annual international conference on Theory and applications of cryptographic techniques (2011).
[37] SHELAT, A., AND SHEN, C.-H. Fast two-party secure computation with minimal assumptions. In Proceedings
of the ACM conference on Computer and communications security (CCS) (2013).
[38] TALBOT, D.
Security in the ether.
416804/security-in-the-ether/, 2009.
http://www.technologyreview.com/featuredstory/
[39] YAO, A. C. Protocols for secure computations. In Proceedings of the Annual Symposium on Foundations of
Computer Science (1982).
A Proof of Security
Following the security deﬁnition from Section 3, we prove the following theorem.
Theorem 1. The Whitewash outsourced two-party SFE protocol securely computes a function f (a, b) in the following
three corruption scenarios: (1) The cloud is malicious and non-cooperative with respect to the rest of the parties, while
all other parties are semi-honest; (2) All but one party providing input is malicious, while the cloud is semi-honest; or
(3) The cloud and mobile device are malicious and colluding, while the evaluator is semi-honest.
Note that existing outsourcing schemes [21, 6] are only secure in corruption scenarios (1) and (2).
17
A.1 Malicious application server A∗
Consider when Alice can perform arbitrarily malicious actions while Bob and Cloud follow the protocol in a semi-
honest manner. We note that the operations performed by A∗ and the messages received by A∗ are nearly identical
to the malicious evaluator P ∗
2 from shelat and Shen’s proof of their two-party computation scheme [37]. We note
here four slight alterations necessary to their simulator S2, none of which change their proof of security. We call the
modiﬁed simulator SA
1. Input generation: When SA generates a random input x(cid:48) for Bob, it also generates a random input z(cid:48) for Cloud.
Because this input is chosen from a uniform distribution in both the real and the ideal world, it is statistically
indistinguishable.
2. Input commitments: When SA generates the input commitments {Γ(j)}j∈σ, it also generates commitments
{Ξ(j)}j∈σ to commit to Cloud’s input.
3. Wire label commitments: When SA generates the commitments to its input wires {Θ(j)}j∈σ, it also generates
commitments to Cloud’s input wire labels {Ψ(j)}j∈σ.
4. Output proof: If A∗ successfully proves the correctness of Bob’s output, the simulator SA delivers the random
input z(cid:48) to A∗. As stated above, this input is statistically indistinguishable from Cloud’s input in the real world.
Given the existence of the simulator SA, this proves security when the evaluating party A∗ is malicious (scenario
2).
A.2 Malicious mobile device B∗
Consider when Bob can perform arbitrarily malicious actions while Alice and Cloud follow the protocol in a semi-
honest manner. We construct a simulator SB in the ideal world to simulate Bob’s view of a real execution of the
protocol. Note that the simulator does not have the other parties’ inputs, nor does it know what input the malicious B∗
will use. Thus, Bob’s inputs and commitments must be checked, and the output proof and result of computation must
be simulated. Consider the following hybrid of experiments.
Hybrid1(B)(k, x; r): This experiment is identical to the experiment REAL(B)(k, x; r) except that the experiment
receives the values {ρ(j)}j∈σ,{γ(j)}j∈σ, and {Γ(j)}j∈σ from B∗ and uses them to recover B∗s input. If for any
j ∈ S, the decommitment Γ(j) cannot reveal B∗s input x∗(j), the simulator aborts.
c≈ Hybrid1(B)(k, x; r)
Lemma 1. REAL(B)(k, x; r)
Proof. Because the experiment is in control of Alice and Cloud, for any j ∈ σ we know that the commitment Θ(j) is
constructed correctly using ρ(j). Thus, the only possible way that the experiment will not uncover the value for some
x∗(j) is if {θ(j)
}i∈[mb], when decommitted from Γ(j) using γ(j) correctly decommits the i ⊕ 1 half of Θ(j), which
i,x∗
happens with negligible probability based on the binding property of the commitment. Otherwise, at least one of the
two commitments Γ(j) or Θ(j)
i must fail to decommit, in which case both experiments abort.
i
Hybrid2(B)(k, x; r): This experiment is identical to the experiment Hybrid1(B)(k, x; r) except that if the ex-
tracted inputs are inconsistent, the experiment aborts.
Lemma 2. Hybrid1(B)(k, x; r)
c≈ Hybrid2(B)(k, x; r)
Proof. This follows from the 2-universal hash check of consistency. Since all of the circuits are generated by the
experiment as cloud, they are all constructed correctly. Following from Lemma G.10 in shelat and Shen’s proof [37],
indistinguishability holds here.
Hybrid3(B)(k, x; r): This experiment is identical to the experiment Hybrid2(B)(k, x; r) except that the experi-
ment passes x∗ to the trusted third party and receives fb(x∗, y) in return. It then randomly selects an evaluated circuit
G(C)(j) and uses the output keys from that circuit to run the output proof of correctness for fb(x∗, y) ⊕ e∗ ⊕ pb with
B∗.