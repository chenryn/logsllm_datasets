After making a recent build I found that I could not create a cluster.
    $ kubectl version
    Client Version: version.Info{Major:"0", Minor:"15", GitVersion:"v0.15.0", GitCommit:"831f3e60d7cd64c61a775d6c78acce1673dd8aa9", GitTreeState:"clean"}
    Server Version: version.Info{Major:"0", Minor:"16+", GitVersion:"v0.16.0-46-gee27094238dbd7-dirty", GitCommit:"ee27094238dbd797c363bac6a54bc28a2cf71225", GitTreeState:"dirty"}
    ...
    Kubernetes cluster is running.  The master is running at:
      https://104.197.49.90
    The user name and password to use is located in /usr/local/google/home/satnam/.config/gcloud/kubernetes/kubeconfig.
    ... calling validate-cluster
    Starting cluster using os distro: debian
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get nodes -o template -t {{range.items}}{{.metadata.name}}
    {{end}} --api-version=v1beta3
    Found 4 nodes.
         1  kubernetes-minion-hhbv
         2  kubernetes-minion-jy35
         3  kubernetes-minion-lfcu
         4  kubernetes-minion-r2ez
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get cs
    Cluster not working yet.
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get cs
    Cluster not working yet.
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get cs
    Cluster not working yet.
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get cs
    Cluster not working yet.
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get cs
    Cluster not working yet.
    Starting cluster using os distro: debian
    current-context: "kubernetes-satnam_kubernetes"
    Running: cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../cluster/../cluster/gce/../../cluster/../_output/dockerized/bin/linux/amd64/kubectl get cs
     Validate output:
    NAME                 STATUS      MESSAGE   ERROR
    node-0               Healthy     ok        nil
    node-1               Healthy     ok        nil
    node-2               Unhealthy             Get https://kubernetes-minion-lfcu:10250/healthz: dial tcp 10.240.7.38:10250: connection refused
    node-3               Healthy     ok        nil
    controller-manager   Healthy     ok        nil
    scheduler            Healthy     ok        nil
    etcd-0               Healthy     {"action":"get","node":{"dir":true,"nodes":[{"key":"/registry","dir":true,"modifiedIndex":3,"createdIndex":3}]}}
                         nil
    Validation returned one or more failed components. Cluster is probably broken.