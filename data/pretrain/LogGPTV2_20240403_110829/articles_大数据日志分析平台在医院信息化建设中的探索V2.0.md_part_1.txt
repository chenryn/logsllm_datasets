**大数据日志分析平台在医院信息化建设中的**
**实践与探索**
1 研究背景
随着信息技术的不断发展，医院规模的不断扩大，医院的信息系统也愈加复杂。现代医院的高效运行高度依赖于医院信息系统的可靠运行。如何尽早的发现系统隐患，尽快排除系统故障是医院信息管理部门最迫切关心的问题。
传统的故障排查方式是由医院或信息系统外包服务人员逐个环节登录机器检查客户终端、交换机、防火墙、服务器主机操作系统、中间件、数据库以及应用服务等各层级的日志，分析各设备日志的异常情况，找到异常环节后才能开展修复措施。
传统排错方式操作繁琐、效率低下。各类设备日志格式各异，解读困难，对技术人员专业门槛要求较高；分析对象太多也导致难以聚焦问题所在，降低了分析准确性；同时生产设备被频繁登录，不同技术人员的执行操作使系统权限控制困难，安全隐患增多。
如何使用工具组件搭建集中统一的日志分析平台，解决运维管理难题，成为医院信息系统运维管理面临的新课题。
2日志分析平台的关键技术与组件
医院信息系统中的主机、服务器、网络设备、安全设备、数据库及各种应用服务软件在运行过程中都会产生大量的日志：如win
Sysmon、Linux、中间件运行环境日志、数据库日志、网络设备日志、安全设备日志、网络审计日志、运行日志、安全日志和行为日志，这些体量巨大的日志蕴含着丰富的信息。当前对于实现日志分析平台存在以下几种关键技术和组件：
-   日志采集
    日志采集主要通过主动采集和被动收集两种方式实现。主动采集方式包括agent代理、浏览器控件、Js采集脚本、Python实现的网络爬虫等；被动收集方式包括snmp、syslog/rsyslog、网络流量复制、定制发送方式等。
Heka：Heka是一个高可扩展的数据收集和处理工具。它的可扩展性不仅仅是体现在程序本身可以进行插件开发，还可以方便的通过添加机器进行水平扩展。Heka由使用Go语言开发，大量使用了Go的goroutine并发和channel通信。通过heka的个性化定制开发，可以以终端代理的方式，实现对各类日志源的统一收集、数据补全和转发处理。
Logstash：Logstash
主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等
-   日志处理
Spark：Spark是一种数据处理引擎，在内存中时，其速度比MapReduce最多快100倍；用在磁盘上时，其速度比MapReduce最多快10倍。它可以与Hadoop和Apache
Mesos一起使用，也可以独立使用。
Flink：Apache
Flink是一个可伸缩的开源批处理和流处理平台。其核心模块是一个数据流引擎，该引擎在分布式的流数据处理的基础上提供数据分发、交流、以及容错的功能
Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理所有动作流数据。通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能
-   日志存储
CouchDB：CouchDB 是一个开源的面向文档的数据库管理系统，可以通过 RESTful
JavaScript Object Notation (JSON) API 访问。术语 "Couch" 是 "Cluster Of
Unreliable Commodity Hardware" 的首字母缩写，它反映了 CouchDB
的目标具有高度可伸缩性，提供了高可用性和高可靠性，即使运行在容易出现故障的硬件上也是如此。
MongoDB：:
是目前非常流行的一种非关系型(NoSQL)数据库。MongoDB是一个面向文档的数据库,目前由10gen开发并维护,它的功能丰富,齐全。
-   日志索引与检索
Elasticsearch：开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。使用Java开发，基于Lucene、分布式、通过Restful方式进
行交互的近实时搜索平台框架。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，Restful风格接口，多数据源，自动搜索负载等。
-   日志展示与可视化
Kibana：Kibana是一个开源和免费的工具，可以提供对日志分析友好的 Web
界面，帮助汇总、分析和搜索重要数据日志。
Nginx
3.实践与探索
3.1 大数据日志分析平台架构设计
结合医院信息系统的特点及日志管理工作现状，大数据日志分析平台采用集群式部署方式，总体架构设计如下：
日志平台由多个模块构成，支持资源横向拓展及功能模块重新分布，医院可根据自身服务器资源、数据量、系统稳定性等因素自定义各个模块的节点组成，同时支持物理机和虚拟机混合部署以保证数据安全性。在数据量超过日均10TB时，通过集群部署方式，可借助云计算能力和存储的弹性扩展能力提供可靠的运行环境，实现日志集中采集、统一管理，满足安全审计、业务分析等应用需求。
![arch (1)](media/image1.jpeg){width="5.740972222222222in"
height="3.223611111111111in"}
功能架构图
![module arch](media/image2.png){width="5.833333333333333in"
height="2.834722222222222in"}
大数据日志分析平台主要由以下几个模块组成：
-   Agent（数据采集模块）
 Golang
语言编写的轻量级实现，与主流开源Agent相比，在相同资源消耗的情况下能实现更高的发送速率。
-   Collector（数据接收模块）
Collector模块接收来自agent采集的数据，并对数据进行标签识别，添加时间戳等处理。
-   Kafka（消息队列模块）
分布式消息处理队列用于消息的持久化和缓存，原始数据存储在raw_message
topic队列，可对第三方提供数据插入和订阅服务，需自行新建topic队列。经过字段提取后的数据，自动存储于logriver队列。
-   Logriver（字段提取模块）
自动解析Apache，Nginx，JSON等类型的日志以及DB2、Oracle、SQL、Mysql等常规数据库日志类型；支持常见网络设备、应用、中间件、流量等日志信息的解析；支持对加密文件、压缩文件、数据库镜像文件、javacore等特殊格式的解读；支持主流硬件设备的性能日志等信息进行解析。
-   Beaver（索引存储模块）
针对日志数据的特点，采用 C++ 语言开发Beaver
索引存储组件，可比主流开源方案节省一半成本。
-   Master（任务协调模块）
维护系统的meta信息，譬如索引、分片(Shard)及其位置信息；