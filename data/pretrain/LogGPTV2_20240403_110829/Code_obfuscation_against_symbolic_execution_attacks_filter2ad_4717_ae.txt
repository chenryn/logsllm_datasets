generated depend on input values, then the symbolic exe-
cution engine must guess the right value of the instruction
that is to be executed, which is diﬃcult. The drawback of
dynamically modifying code is that it aﬀects the input out-
put behavior of the program and opens the door to remote
attacks. Since most software developers are more concerned
about remote attacks than automatic analysis attacks, they
would avoid using such transformations and resort to obfus-
cation transformations which do not induce this risk. There-
fore, in this work we focus on obfuscation transformations
which do not introduce remote attacks.
Complex Constraints: Applying cryptographic hash
functions to equality checks based on input values is a type
of data obfuscation transformation, which is problematic for
symbolic execution. In particular, the SMT solvers used by
symbolic execution engines are known to have practical lim-
itations w.r.t. inverting cryptographic hash functions [41,
49]. However, we note that cryptographic hash functions
are based on large look-up tables containing random num-
bers which are publicly known and easy to locate in code.
Therefore, we argue that an active attacker as described in
§ 2.4 will be able to locate and disable explicit checks which
use hash functions on input values. Implicit checks cannot
be disabled, however they may cause the application to crash
which is undesirable for many developers or even worse they
may open the door for remote attacks as discussed in the
previous paragraph. Moreover, note that hash functions are
only applicable for equality comparisons and therefore range
comparisons need to be protected in a diﬀerent way. In this
paper we discuss obfuscation transformations that hide the
location of checks via control-ﬂow obfuscation.
6. CONCLUSIONS
We have discussed why test case generation is a com-
mon subgoal of three frequent attacker goals: simplifying
the CFG; identifying and disabling integrity checks; and by-
passing license checks. Our empirical case-study indicates
that for the datasets of programs used in this paper, a sub-
set of existing obfuscation transformations are weak against
white-box test case generation via symbolic execution. Since
these datasets are heterogeneous, as indicated by the high
standard deviations in Tables 1 & 2, we believe these results
to generalize to other programs.
Symbolic execution has several limitations when applied
to large software programs (§ 5). However, we note that
symbolic execution is currently a highly active ﬁeld of re-
search and has been successfully applied for ﬁnding bugs
in Microsoft Windows 7 [33] and it is being used by several
teams in the DARPA Cyber Grand Challenge for automated
exploit generation [5]. Moreover, several deobfuscation tech-
niques rely on symbolic execution [47]. Furthermore, obfus-
cation is often applied only to parts of software to minimize
performance impact [19], hence attackers may isolate and
symbolically analyze smaller parts of the software [2].
We also proposed an obfuscation approach that improves
resilience against symbolic execution. We have implemented
this approach and empirically veriﬁed that it increases slow-
down of symbolic execution by 4 orders of magnitude w.r.t.
the original (unobfuscated) program. We oﬀer our imple-
mentation freely to members of academia and industry.
In future work we wish to extend this study using more
datasets of programs, more obfuscation implementations and
more symbolic execution engines. Additionally, we wish to
measure the resilience of obfuscation against active attacks
(see § 2.4). We believe that this empirical study may be
useful in developing a model that can accurately predict
the resilience of diﬀerent obfuscation techniques w.r.t. au-
tomated analysis attacks such as symbolic execution. For
this purpose we intend to use machine learning algorithms
for training a model and then test its prediction accuracy.
Finally, we also plan to perform analytical studies and oﬀer
a formal deﬁnition of practical obfuscation.
Acknowledgements: We thank Saumya Debray and
Mart´ın Ochoa for their valuable insights and feedback. Coll-
berg was supported by National Science Foundation grants
1525820 and 1318955.
and Vulnerability Assessment, pages 143–163.
Springer, 2008.
7. REFERENCES
[1] S. Anand, E. K. Burke, T. Y. Chen, J. Clark, M. B.
Cohen, W. Grieskamp, M. Harman, M. J. Harrold,
P. McMinn, et al. An orchestrated survey of
methodologies for automated software test case
generation. Journal of Systems and Software,
86(8):1978–2001, 2013.
[2] S. Anand, P. Godefroid, and N. Tillmann.
Demand-driven compositional symbolic execution. In
Tools and Algorithms for the Construction and
Analysis of Systems, pages 367–381. Springer, 2008.
[3] B. Anckaert, M. Madou, B. De Sutter, B. De Bus,
K. De Bosschere, and B. Preneel. Program
obfuscation: a quantitative approach. In Proceedings
of the 2007 ACM workshop on Quality of protection,
pages 15–20. ACM, 2007.
[4] D. Aucsmith. Tamper resistant software: An
implementation. In Information Hiding, pages
317–333. Springer, 1996.
[5] T. Avgerinos, S. K. Cha, A. Rebert, E. J. Schwartz,
M. Woo, and D. Brumley. Automatic exploit
generation. Communications of the ACM, 57(2):74–84,
2014.
[6] S. Banescu, M. Ochoa, and A. Pretschner. A
framework for measuring software obfuscation
resilience against automated attacks. In Software
Protection (SPRO), 2015 IEEE/ACM 1st
International Workshop on, pages 45–51. IEEE, 2015.
[7] S. Banescu, A. Pretschner, D. Battr´e, S. Cazzulani,
R. Shield, and G. Thompson. Software-based
protection against changeware. In Proceedings of the
5th ACM Conference on Data and Application
Security and Privacy, pages 231–242. ACM, 2015.
[8] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,
A. Sahai, S. Vadhan, and K. Yang. On the (im)
possibility of obfuscating programs. In Advances in
Cryptology CRYPTO 2001, pages 1–18. Springer,
2001.
[9] C. W. Barrett, R. Sebastiani, S. A. Seshia, and
C. Tinelli. Satisﬁability modulo theories. Handbook of
satisﬁability, 185:825–885, 2009.
[10] C. Basile, S. Di Carlo, T. Herlea, V. Business,
J. Nagra, and B. Wyseur. Towards a formal model for
software tamper resistance. In Second International
Workshop on Remote Entrusting (ReTtust 2009),
volume 16.
[11] C. Cadar, D. Dunbar, and D. R. Engler. Klee:
Unassisted and automatic generation of high-coverage
tests for complex systems programs. In OSDI, 2008.
[12] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill,
and D. R. Engler. EXE: Automatically generating
inputs of death. In Proceedings of the 13th ACM
Conference on Computer and Communications
Security, CCS ’06, pages 322–335, New York, NY,
USA, 2006. ACM. 00041.
[13] L. Cavallaro, P. Saxena, and R. Sekar. On the limits of
information ﬂow techniques for malware analysis and
containment. In Detection of Intrusions and Malware,
[14] M. Ceccato, M. Di Penta, J. Nagra, P. Falcarin,
F. Ricca, M. Torchiano, and P. Tonella. The
eﬀectiveness of source code obfuscation: an
experimental assessment. In Program Comprehension,
2009. ICPC’09. IEEE 17th International Conference
on, pages 178–187. IEEE, 2009.
[15] M. Ceccato, M. D. Penta, P. Falcarin, F. Ricca,
M. Torchiano, and P. Tonella. A family of experiments
to assess the eﬀectiveness and eﬃciency of source code
obfuscation techniques. Empirical Software
Engineering, 19(4):1040–1074, Feb. 2013.
[16] H. Chang and M. J. Atallah. Protecting software code
by guards. In Security and privacy in digital rights
management, pages 160–175. Springer, 2001.
[17] V. Chipounov, V. Kuznetsov, and G. Candea. S2E: A
Platform for In-vivo Multi-path Analysis of Software
Systems. ASPLOS XVI, pages 265–278, New York,
NY, USA, 2011. ACM.
[18] C. Collberg, S. Martin, J. Myers, and J. Nagra.
Distributed application tamper detection via
continuous software updates. In Proceedings of the
28th Annual Computer Security Applications
Conference, ACSAC ’12, pages 319–328, New York,
NY, USA, 2012. ACM.
[19] C. Collberg and J. Nagra. Surreptitious software.
Upper Saddle River, NJ: Addision-Wesley
Professional, 2010.
[20] C. Collberg, C. Thomborson, and D. Low. A
taxonomy of obfuscating transformations. Technical
report, Department of Computer Science, The
University of Auckland, New Zealand, 1997.
[21] C. Collberg, C. Thomborson, and D. Low.
Manufacturing cheap, resilient, and stealthy opaque
constructs. In Proceedings of the 25th ACM
SIGPLAN-SIGACT symposium on Principles of
programming languages, POPL ’98, pages 184–196,
New York, NY, USA, 1998. ACM.
[22] K. Coogan, G. Lu, and S. Debray. Deobfuscation of
virtualization-obfuscated software: A semantics-based
approach. In Proceedings of the 18th ACM Conference
on Computer and Communications Security, CCS ’11,
pages 275–284, New York, NY, USA, 2011. ACM.
[23] M. Dalla Preda. Code obfuscation and malware
detection by abstract interpretation. PhD thesis,
University of Verona, 2007.
[24] M. Dalla Preda and R. Giacobazzi. Control code
obfuscation by abstract interpretation. In Third IEEE
International Conference on Software Engineering and
Formal Methods., pages 301–310. IEEE, 2005.
[25] C. Eagle. The IDA pro book: the unoﬃcial guide to
the world’s most popular disassembler. No Starch
Press, 2011.
[26] S. Forrest, A. Somayaji, and D. H. Ackley. Building
diverse computer systems. In Operating Systems,
1997., The Sixth Workshop on Hot Topics in, pages
67–72. IEEE, 1997.
[27] M. Franz. E unibus pluram: massive-scale software
diversity as a defense mechanism. In Proceedings of
the 2010 workshop on New security paradigms, pages
7–16. ACM, 2010.
[28] V. Ganesh and D. L. Dill. A decision procedure for
bit-vectors and arrays. In Computer Aided
Veriﬁcation, pages 519–531. Springer, 2007.
[29] S. Garg, C. Gentry, S. Halevi, M. Raykova, A. Sahai,
and B. Waters. Candidate indistinguishability
obfuscation and functional encryption for all circuits.
In Proc. of the 54th Annual Symp. on Foundations of
Computer Science, pages 40–49, 2013.
[30] L. E. Garner. On the Collatz 3n + 1 algorithm.
Proceedings of the American Mathematical Society,
82(1):19–22, 1981.
[31] I. P. Gent, E. MacIntyre, P. Prosser, T. Walsh, et al.
The constrainedness of search. In AAAI/IAAI, Vol. 1,
pages 246–252, 1996.
[32] P. Godefroid, N. Klarlund, and K. Sen. DART:
Directed automated random testing. In Proceedings of
the 2005 ACM SIGPLAN Conference on Programming
Language Design and Implementation, PLDI ’05,
pages 213–223, New York, NY, USA, 2005.
[33] P. Godefroid, M. Y. Levin, and D. Molnar. Sage:
whitebox fuzzing for security testing. Queue, 10(1):20,
2012.
[34] P. Godefroid, M. Y. Levin, D. A. Molnar, et al.
Automated whitebox fuzz testing. In NDSS, volume 8,
pages 151–166, 2008.
[35] Y. Guillot and A. Gazet. Automatic binary
deobfuscation. Journal in computer virology,
6(3):261–276, 2010.
[36] B. Horne, L. Matheson, C. Sheehan, and R. E. Tarjan.
Dynamic self-checking techniques for improved tamper
resistance. In Security and privacy in digital rights
management, pages 141–159. Springer, 2002.
[37] P. Junod, J. Rinaldini, J. Wehrli, and J. Michielin.
Obfuscator-LLVM – software protection for the
masses. In B. Wyseur, editor, Proceedings of the
IEEE/ACM 1st International Workshop on Software
Protection, SPRO’15, Firenze, Italy, May 19th, 2015,
pages 3–9. IEEE, 2015.
[38] J. Kinder. Towards static analysis of
virtualization-obfuscated binaries. In 19th Working
Conference on Reverse Engineering (WCRE), pages
61–70, Oct 2012.
[39] J. C. King. Symbolic execution and program testing.
Rolles Program Synthesis in reverse Engineering.pdf,
2014. NoSuchCon 2014, Accessed:2016-05-24.
[45] F. Saudel and J. Salwan. Triton: A dynamic symbolic
execution framework. In Symposium sur la s´ecurit´e
des technologies de l’information et des
communications, SSTIC, France, Rennes, June 3-5
2015, pages 31–54. SSTIC, 2015.
[46] S. Schrittwieser, S. Katzenbeisser, J. Kinder,
G. Merzdovnik, and E. Weippl. Protecting software
through obfuscation: Can it keep pace with progress
in code analysis? ACM Computing Surveys (CSUR),
49(1):4, 2016.
[47] E. J. Schwartz, T. Avgerinos, and D. Brumley. All you
ever wanted to know about dynamic taint analysis and
forward symbolic execution (but might have been
afraid to ask). In Security and Privacy (SP), 2010
IEEE Symposium on, pages 317–331. IEEE, 2010.
[48] M. Sharif, A. Lanzi, J. Giﬃn, and W. Lee. Automatic
reverse engineering of malware emulators. In Security
and Privacy, 2009 30th IEEE Symposium on, pages
94–109, May 2009.
[49] M. I. Sharif, A. Lanzi, J. T. Giﬃn, and W. Lee.
Impeding malware analysis using conditional code
obfuscation. In NDSS, 2008.
[50] Y. Shoshitaishvili, R. Wang, C. Hauser, C. Kruegel,
and G. Vigna. Firmalice - automatic detection of
authentication bypass vulnerabilities in binary
ﬁrmware. 2015.
[51] D. Song, D. Brumley, H. Yin, J. Caballero, I. Jager,
M. G. Kang, Z. Liang, J. Newsome, P. Poosankam,
and P. Saxena. Bitblaze: A new approach to computer
security via binary analysis. In Information systems
security, pages 1–25. Springer, 2008.
[52] Symantec Corporation. Internet Security Threat
Report 2016. Technical Report April, 2016.
https://www.symantec.com/content/dam/symantec/
docs/reports/istr-21-2016-en.pdf.
[53] S. Udupa, S. Debray, and M. Madou. Deobfuscation:
reverse engineering obfuscated code. In 12th Working
Conference on Reverse Engineering, 2005.
[54] M. Varia. Studies in program obfuscation. PhD thesis,
School of Computer Science, Tel Aviv University,
2010.
Communications of the ACM, 19(7):385–394, 1976.
[55] T. Wang, T. Wei, G. Gu, and W. Zou. Taintscope: A
[40] McAfee. McAfee Labs Threats Report. Technical
Report March, 2016. http://www.mcafee.com/us/
resources/reports/rp-quarterly-threats-mar-2016.pdf.
[41] I. Mironov and L. Zhang. Applications of sat solvers
to cryptanalysis of hash functions. In Theory and
Applications of Satisﬁability Testing-SAT 2006, pages
102–115. Springer, 2006.
[42] G. Naumovich and N. Memon. Preventing piracy,
reverse engineering, and tampering. Computer,
(7):64–71, 2003.
[43] J. Qiu, B. Yadegari, B. Johannesmeyer, S. Debray,
and X. Su. Identifying and understanding
self-checksumming defenses in software. In Proceedings
of the 5th ACM Conference on Data and Application
Security and Privacy, pages 207–218. ACM, 2015.
[44] R. Rolles. Program Synthesis in Reverse Engineering.
http://www.nosuchcon.org/talks/2014/D1 01 Rolf
checksum-aware directed fuzzing tool for automatic
software vulnerability detection. In Security and
privacy (SP), 2010 IEEE symposium on, pages
497–512. IEEE, 2010.
[56] Z. Wang, J. Ming, C. Jia, and D. Gao. Linear
obfuscation to combat symbolic execution. In
Computer Security–ESORICS 2011, pages 210–226.
Springer, 2011.
[57] B. Yadegari and S. Debray. Symbolic execution of
obfuscated code. In Proceedings of the 22Nd ACM
SIGSAC Conference on Computer and
Communications Security, ser. CCS, volume 15, pages
732–744, 2015.
[58] B. Yadegari, B. Johannesmeyer, B. Whitely, and
S. Debray. A generic approach to automatic
deobfuscation of executable code. In Security and
Privacy (SP), 2015 IEEE Symposium on, pages
674–691. IEEE, 2015.