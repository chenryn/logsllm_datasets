hit counts, we observe that most new hit count coverage is localized
to loops (e.g., for(), while()). As Rawat and Mounier [43] demon-
strate that as many as 42% of binary code loops induce buffer over-
flows (e.g., by iterating over user-provided input with strcpy()),
it is imperative to track hit counts as a means of assessing‚Äîand
prioritizing‚Äîfuzzer ‚Äúprogress‚Äù toward higher loop iterations. How-
ever, inferring a loop‚Äôs iteration count is achievable purely from
monitoring its induction variable‚Äîeliminating the expense of track-
ing hit counts for every loop block (as AFL and libFuzzer do).
Observation 2: Hit counts provide fuzzing a notion of loop explo-
ration progress, but need only be tracked once per loop iteration.
3.2.1 Bucketed Unrolling. AFL-style [59] hit count tracking
adds counters to each block/edge to dynamically update their re-
spective hit counts in a shared memory coverage bitmap. However,
this approach is fundamentally incompatible with the binarized
nature of CGT‚Äôs block-centric, interrupt-driven coverage. While a
naive solution is to instead add CGT‚Äôs interrupts following the ap-
plication of a loop peeling transformation‚Äîmaking several copies of
the loop‚Äôs body and stitching them together with direct jumps (e.g.,
head ‚Üí body1 ‚Üí ... ‚Üí bodyùëõ ‚Üí tail)‚Äîthe resulting binary will
be exceedingly space inefficient due to excessive code duplication‚Äî
especially for nested loops.
Session 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea355In search of a more performant solution, we develop bucketed
unrolling‚Äîdrawing from compiler loop unrolling principles to en-
code the functionality of AFL-style bucketed hit counts as a series
of binarized range comparisons.
Figure 5: Bucketed unrolling applied to a simple loop.
As shown in Figure 5, bucketed unrolling augments each loop
header with a series of sequential conditional statements weighing
the loop induction variable against the desired hit count bucket
ranges (e.g., AFL‚Äôs eight). To support CGT, each conditional‚Äôs fall-
through block is assigned an interrupt; taking any conditional‚Äôs tar-
get branch jumps directly to the loop‚Äôs body, indicating no change
from the current bucket range; and taking the fall-through triggers
the next sequential interrupt, thus signaling an advancement to
the next bucket. The resulting code replicates the functionality of
AFL-style hit count tracking‚Äîbut obtains much higher performance
by doing so at just one instrumentation location per loop.
Technique 2: Encoding conventional bucketed hit count tracking as
a series of sequential, binarized range checks enables CGT to cap-
ture binary-level loop exploration progress‚Äîwhile upholding its fast,
interrupt-driven coverage-tracing strategy.
4 IMPLEMENTATION: HEXCITE
In this section we introduce HeXcite‚ÄîHigh-Efficiency eXpanded
Coverage for Improved Testing of Executables‚Äîour implementation
of binary-only coverage-preserving Coverage-guided Tracing. Below
we discuss HeXcite‚Äôs core architecture, and our design decisions
in realizing jump mistargeting and bucketed unrolling.
4.1 Architectural Overview
HeXcite consists of three main components: (1) binary genera-
tion, (2) control-flow mapping, and (3) the fuzzer. We imple-
ment components 1‚Äì2 as a set of analysis and transformation passes
atop the ZAFL static rewriting platform [38], and component 3 atop
the industry-standard fuzzer AFL [59]. Below we briefly discuss
each and their synergy in facilitating coverage-preserving CGT.
Binary Generation: HeXcite‚Äôs workflow is similar in nature
to UnTracer‚Äôs (Figure 2); i.e., we generate two versions of the orig-
inal target binary: (1) an oracle (run for every test case) with in-
terrupts added to each basic block; and (2) a tracer (run only for
coverage-increasing test cases) equipped with conventional tracing
instrumentation. While many fuzzers embrace compiler instrumen-
tation for its speed and soundness (i.e., LLVM [33]), there are by
now a number of static binary rewriters with comparable qualities.
We examine several popular and/or emerging security-oriented
binary rewriters‚ÄîDyninst [40], McSema [14], RetroWrite [15], and
ZAFL [38]‚Äîand distill a set of properties we feel are best-suited
supporting jump mistargeting and bucketed unrolling: (1) a modi-
fiable control-flow representation; (2) dominator flow analysis [2]);
and (3) sound code transformation and generation. We select ZAFL as
the basis for HeXcite as it is the highest performance rewriter that
possesses the above three properties in addition to an LLVM-like
transformation API. We expect that with additional engineering
effort, our findings apply to the other rewriters listed.
Like most static binary rewriters, ZAFL operates by first dis-
assembling and lifting the input binary to an intermediate repre-
sentation;3 and performing all code transformation at this IR level
(e.g., injecting bucketed unrolling‚Äôs range checks ¬ß 4.3), adjusting
the binary‚Äôs layout as necessary before reconstituting the final
executable. While relocating direct (i.e., absolute and PC-relative)
control flow is generally trivial, attempting so for indirect trans-
fers is undecidable and risks corrupting the resulting binary, as
their respective targets cannot be identified with any generalizable
accuracy [39, 54]. ZAFL addresses this challenge conservatively
via address pinning [25, 27], which ‚Äúpins‚Äù any unmovable items
(including but not limited to: indirectly-called function entries,
callee-to-caller return targets, data, or items that cannot be pre-
cisely disambiguated as being either code or data) to their original
addresses;4 while safely relocating the remaining movable items
around these pins (often via chained jumps). Though address pin-
ning will likely over-approximate the set of unmovable items at
slight cost to binary performance and/or space efficiency (particu-
larly for exceedingly-complex binaries with an abundance of jump
tables, handwritten assembly, or data-in-code), its general-purpose
soundness, speed, and scalability [38] makes it promising for facili-
tating coverage-preserving CGT. Our current prototype, HeXcite,
supports binary fuzzing of x86-64 Linux C and C++ executables.
Control-flow Mapping: A key requirement of CGT is a map-
ping of each oracle basic block‚Äôs address (i.e., where an interrupt
is added) to its corresponding tracer binary trace-block ID; when
a coverage-increasing test case is found, the tracer is invoked to
capture the test case‚Äôs full coverage, for which all interrupts are sub-
sequently removed at their addresses in the oracle. To generate this
mapping, we save the original and rewritten control-flow graphs for
both the oracle and tracer binaries. We then parse the pair of original
control-flow graphs to find their corresponding matches, and subse-
quently map each to their oracle and tracer binary counterparts (i.e.,
(cfgBB,oracleBB) ‚Üí (cfgBB,tracerBB)). From there, we gener-
ate the necessary (oracleAddr,tracerID,interruptBytes) map-
ping for each block (e.g., (0x400400,30,0xCC)). If mapping should
fail (e.g., a tracer block with no corresponding oracle block), we
omit the block to avoid problematic interrupts; we observe this gen-
erally amounts to no more than a handful of instances per binary,
and does not impact HeXcite‚Äôs overall coverage (¬ß 5.2.1‚Äì¬ß 5.2.2).
The Fuzzer: Like UnTracer, we implement HeXcite atop the
industry-standard fuzzer AFL [59] 2.52b with several changes in
3ZAFL‚Äôs disassembly supports mixing-and-matching of recursive descent and linear
sweep. The current tools utilized are based on IDA Pro [24] and GNU objdump [20].
4To support address pinning, ZAFL conservatively scans for addresses likely targeted
by indirect control flow; generally this is achieved via rudimentary heuristics (e.g.,
post-call instructions, jump table entries, etc.). Additionally, ZAFL pins all data items.
ABCi > 1i > 2i > 7i = [0,1]i = 2i = [3,7]Original LoopWith Bucketed Unrollingon ranges = {0-1, 2, 3-7, 8+}ABCi = [8,‚àû)HeaderLoopBodyHeaderLoopBodySession 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea356test case handling logic (Figure 6). We default to conventional trac-
ing for any executions where coverage is required (e.g., calibration
and trimming), while not re-executing or saving timeout-producing
test cases. As jump mistargeting triggers signals that might oth-
erwise appear as valid crashes (e.g., SIGSEGV), we alter HeXcite‚Äôs
fuzzer-side crash-handling logic as follows: if a test case crashes
the oracle, we re-run it on the tracer to verify whether it is a true or
a mistargeted crash; if it does not crash the tracer, we conclude it is
the result of taking a mistargeted critical edge (i.e., a SIGSEGV from
jumping to the zero address), and save it to the fuzzer queue. We
note that the core principles of coverage-preserving CGT scale to
any fuzzer (e.g., honggFuzz), as evidenced by emerging CGT-based
efforts within the fuzzing community [18, 23, 30].
Figure 6: HeXcite‚Äôs fuzzer-side test case handling logic. Like UnTracer, we
discard timeout-producing test cases; however, we re-run crashing test cases
to determine whether they are a true crash (i.e., occurring on both the ora-
cle and tracer) or the result of hitting an oracle mistargeted edge (generally
triggering a SIGSEGV from the jump being redirected to the zero address).
4.2 Implementing Jump Mistargeting
We implement zero-address jump mistargeting for the common-
case of critical edges, conditional jump target branches (¬ß 3.1), as
follows. To statically identify critical edges we first enumerate all
control-flow edges, and mark an edge as critical if at least two edges
both precede and succeed it. We subsequently parse each critical
edge and categorize it by type by examining its starting block‚Äôs
last instruction (Table 3). Lastly, we update an offline record of
each critical edge by type (e.g., ‚Äúconditional jump target‚Äù) and its
respective starting/ending basic block addresses.
We enumerate all conditional jump target critical edges; as x86-
64 conditional jumps are 6-bytes in length and encoded with a
32-bit PC-relative displacement, we compute the sum of the in-
struction‚Äôs address and its length, and determine the 2‚Äôs comple-
ment (i.e., negative binary representation). Using basic file I/O we
then statically overwrite the jump‚Äôs displacement operand with
the little-endian encoding of the zero-address-mistargeted displace-
ment, and update our oracle-to-tracer mapping accordingly (e.g.,
(0x400400,30,0x7C000000) for the example in ¬ß 3.1).
If a critical edge cannot accommodate zero-address mistargeting
(e.g., from having a <32-bit displacement), we attempt to fall-back to
conventional SanitizerCoverage-style [50] edge splitting, inserting a
dummy block and connecting it to the edge‚Äôs end block. Conditional
fall-through critical edges require careful handling, as accommo-
dating the transfer from the edge‚Äôs starting block to the dummy
requires the dummy be placed immediately after the starting block
(i.e., the next sequential address). However, splitting indirect critical
edges remains a universal problem even for robust compilers like
1
2
3
4
5
6
7
8
#¬ª
LLVM (¬ß 6.1). While recent work [31] reveals the possibility that
indirect edges may be modeled at the binary level, such approaches
are still too imprecise to be realistically deployed; hence, we conser-
vatively omit indirect critical edges as we observe they have little
overall significance on dynamically-seen control-flow (Figure 3).
4.3 Implementing Bucketed Unrolling
We implement bucketed unrolling to replicate AFL-style loop hit
count tracking, beginning with an analysis pass to retrieve all code
loops from the target binary based on the classic dominance-based
loop detection [42]: given the control-flow graph and dominator
tree (generally available in any off-the-shelf static rewriter‚Äôs API),
we mark a set of blocks S as a loop if (1) there exists a header block h
that dominates all blocks in S; and (2) there exists a backward edge
bh from some block b ‚àà S such that h dominates b.5 Though binary-
level loop head/body detection is difficult‚Äîparticularly around com-
plex optimizations like Loop-invariant Code Motion‚Äîwe observe
that the standard dominance-based algorithm is sufficient; and
while HeXcite attains the highest loop coverage in our evalua-
tion (¬ß 5.2.2), we expect that future advances in optimized-binary
loop detection will only improve these capabilities.
As pinpointing a loop‚Äôs induction variable (the target of bucketed
unrolling‚Äôs discrete range checks) is itself semantically challenging
at the binary level, we opt for a simpler approach and instead add
a ‚Äúfake‚Äù loop counter before each loop header; and augment the
header with an instruction to increment this counter per iteration
(e.g., x86‚Äôs incl). Where the increment is inserted in the header
ultimately depends on the static rewriter of choice; Dyninst [40]
prefers to conservatively insert new code at basic block entrypoints
to avoid clobbering occupied registers; while RetroWrite [15] and
ZAFL [38] analyze register liveness to more tightly weave code
with the original instructions. Either style is supportive of HeXcite,
though tight code insertion is preferable for higher runtime speed.
We implement bucketed unrolling‚Äôs sequential range checks (per
AFL‚Äôs 8-bucket hit count scheme) as a transformation pass directly
before the loop‚Äôs first body block; and connect each to the first body
block via direct jumps, and to each other via fall-throughs. The
resulting assembly resembles the following (shown in Intel syntax):
_loop_head:
incl rdx
cmpl rdx, 1
jle
cmpl rdx, 2
jle
...
_loop_body
_loop_body
_loop_body:
To facilitate signaling of a range change, we flag the start of each
sequential range check (e.g., lines 3 and 5 above) with the one-byte
0xCC interrupt. To maintain control-flow congruence, we apply this
transformation to both the oracle and tracer binaries.
5 EVALUATION
Our evaluation of the effectiveness of coverage-preserving Coverage-
guided Tracing is motivated by three key questions:
5In compiler and graph theory, a basic block a is said to dominate basic block b if and
only if every path through b also covers a. [2]
RunOracleRunTracerTotalTmouts++NewCoverage?Save toQueueDiscardCalibrateTotalCrashes++DiscardNew Crash Coverage?noyesDiscardUniqueCrashes++Save toCrashesno faultcrashnoyestmoutcrashtmoutinterruptCoverage-preserving Coverage-guided TracingFuzzer-side Test Case HandlingSession 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea357Q1: Do jump mistargeting and bucketed unrolling improve cov-
erage over basic-block-only CGT?
Q2: What are the performance impacts of expanding CGT to
finer-grained code coverage metrics?
Q3: How do the benefits of coverage-preserving CGT impact
fuzzing bug-finding effectiveness?
5.1 Experiment Setup
Below we provide expanded detail on our evaluation: the coverage-
tracing approaches we are testing, our benchmark selection, and
our experimental infrastructure and analysis procedures.
Competing Tracing Approaches: Table 5 lists the fuzzing
coverage-tracing approaches tested in our evaluation. We eval-
uate our binary-only coverage-preserving CGT implementation,
HeXcite, alongside the current block-coverage-only CGT approach
UnTracer [37].6 To test HeXcite‚Äôs fidelity against the conventional
always-on coverage tracing in binary fuzzing, we also evaluate the
leading binary tracers QEMU (AFL [59] and honggFuzz‚Äôs [49] de-
fault approach for fuzzing binary-only targets); Dyninst (a popular
static-rewriting-based alternative [26]); and RetroWrite [15] (a
recent static-rewriting-based instrumenter). Lastly, we replicate
UnTracer‚Äôs evaluation for open-source targets by further compar-
ing against AFL-Clang (AFL‚Äôs [59] source-level always-on trac-
ing) [37]. We report HeXcite‚Äôs best-performing coverage configu-
ration (edge coverage or edge+count coverage) in all experiments.
Approach
HeXcite
UnTracer [37]
QEMU [59]
Dyninst [26]
RetroWrite [15]
Clang [59]
Tracing Type
coverage-guided
coverage-guided
always-on
always-on
always-on
always-on
Level
binary
binary
binary
binary
binary
source
Coverage
edge + counts
block
edge + counts
edge + counts
edge + counts
edge + counts
Table 5: Fuzzing coverage tracers evaluated alongside HeXcite; and their type,
level, and coverage metric.
Binary
Package
Source
Input File
jasper-1.701.0
jasper
mjs
nasm
sam2p
sfconvert
tcpdump
unrtf
yara
lzturbo
pngout
rar
unrar
JPG
JS
ASM
BMP
WAV
PCAP
RTF
YAR
LZT
PNG
RAR
RAR
Table 6: Our evaluation benchmark corpora.
mjs-1.20.1
nasm-2.10
sam2p-0.49.3
audiofile-0.2.7
tcpdump-4.5.1
unrtf-0.20.0