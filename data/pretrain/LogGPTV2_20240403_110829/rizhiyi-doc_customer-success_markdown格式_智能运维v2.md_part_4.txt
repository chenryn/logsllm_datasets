1.  配置历史指标数据回写自定义topic后，通过 Kafka
    Consumer组件获取自定义topic中的历史指标数据。
![](media/image39.png){width="5.768055555555556in"
height="2.811111111111111in"}
2.  通过Field
    Remover组件对历史指标数据中包含智能运维标准格式的字段进行保留。
![](media/image40.png){width="5.768055555555556in"
height="2.529861111111111in"}
3.  通过Field
    Renamer组件对历史指标数据进行重命名，达到符合智能运维固定标准格式的要求。
![](media/image41.png){width="5.768055555555556in"
height="2.678472222222222in"}
4.  通过Kafka Producer组件将清洗好的历史指标数据对接至智能运维topic
    lynxee。
![](media/image42.png){width="5.768055555555556in"
height="2.7576388888888888in"}
### 指标手动训练
1、查看趋势图：指标数据对接至智能运维topic后，指标数据需要通过算法训练后才能作为监控项继续使用，在指标与监控项界面可查看到对接的指标数据，点击endpoint，可通过趋势图查看指标趋势情况。
![](media/image43.png){width="5.768055555555556in"
height="1.9541666666666666in"}
![](media/image44.png){width="5.768055555555556in"
height="2.0458333333333334in"}
2、选择算法进行训练：点击设为监控项，算法选择中包括图中四种算法，可根据指标数据特性判断选用哪种指标，选中算法后可进行指标算法训练，注意默认指标个数需大于10080个才能训练成功，训练完成后，点击已存训练数据，下一步。
![](media/image45.png){width="5.768055555555556in"
height="2.4305555555555554in"}
![](media/image46.png){width="5.768055555555556in" height="2.45in"}
3、调试：进入算法测试界面，可通过调整敏感度对异常点进行调试，可通过趋势图对指标原始值和异常分进行查看。测试完成后点击保存，指标数据就会处于监控状态中。
![](media/image47.png){width="5.768055555555556in"
height="2.654861111111111in"}
### 注意事项
可通过kafka工具对智能运维lynxee_kpis
topic进行格式及内容验证，实时观察智能运维lynxee_kpis中指标数据情况，使用命令如下：
/opt/rizhiyi/tools/kafka/bin/kafka-console-consumer.sh \--zookeeper
ip:2181 \--max-messages 10 \--topic topic_name
![](media/image48.png){width="5.768055555555556in"
height="1.4423611111111112in"}
# 产品使用
日志易日志分析系统是由后端各类服务模块构成的整体业务系统，基于日志易集群来建立一个集群服务性能指标异常检测的服务模型，可以筛选关键应用的核心指标来做服务场景和指标异常检测。
通过自动选择时序指标检测算法实现服务模型的健康度状态感知和异常报警，在出现异常时可以从服务模型看到异常点，并且可以关联异常点所归属的服务模块或操作系统的日志上下文实现故障推荐和根因分析，提高运维效率，并提升故障发现、修复时间。
前面我们已经说过，日志易智能运维Lynxee的主要使用场景分为三类：
-   单KPI指标异常检测；
-   日志模式异常检测；
-   基于多KPI指标的服务模型健康度异常检测。
这一章节通过三个使用场景引入，详细介绍了从指标到告警构建智能运维体系的流程。
如对具体的产品使用流程存疑，可参考《日志易Lynxee使用手册》。
1.  ## Lynxee使用场景
    1.  ### 指标异常检测
在日志易中，我们都可以通过类似下面的SPL语句，快速将不同的日志数据，转换成为对应的指标数据：
logtype:web_access code:\>=400
\| bucket timestamp span=1m as ts
\| stats avg(resp_time) by ts
只需要更换红字这段过滤条件，就可以做到全面的指标数据覆盖。
既然有了指标数据，下一步就是如何智能的检测它，根据历史情况，智能的发现问题。
因为指标的千差万别，很难有一种单一的普适算法。所以日志易针对不同场景需求，启用不同的算法。
#### 常用算法介绍
![](media/image49.png){width="5.768055555555556in"
height="4.336805555555555in"}
针对常用的预测分析场景，下面稍微介绍一些不同算法的原理。
指标异常检测的本质，就是如何把原始数据转化成可以使用3sigma检测的集合。3sigma来源于正态分布。99.7%的数据集中在\[μ±3σ\]，这就是我们常说的3sigma原则。
![](media/image50.png){width="5.768055555555556in"
height="2.8513888888888888in"}
正态分布在PMP项目管理课程中有提及，如对此概念不熟悉可参考
。
深度学习算法则有：
-   VAE(变分自编码器)
-   CVAE(条件变分自编码器)
-   isolcationForest(孤立森林)
-   MovingAverage(移动均值)
-   KDE(核密度分析)
-   GBRT(梯度增强回归树)
以下对使用较多的CVAE、iForest、KDE、GBRT算法进行介绍：
CVAE算法
CVAE算法是从图像识别VAE算法发展而来的，借鉴了阿里巴巴开源Donut项目的强周期性指标检测算法。
![智能运维概念图-02.jpg](media/image51.jpeg){width="5.768055555555556in"
height="1.5854166666666667in"}
在Lynxee中，我们把周期曲线按照滑动窗口的形式，切割成一段一段的小曲线，合在一起，就成了一个特征矩阵了，然后进入多层的编码解码，反复迭代，得到最好的模型。
为了提高效果，在训练数据上，还可以主动添加一些噪声误差。
然后实际检测的时候，我们就把测试数据经过编解码出来的最后一小段模拟曲线的分布和实际数据作对比，是不是发生了严重偏离。因为模拟曲线是正态分布的，所以这个偏离就是3sigma。
一般来说，该算法适合由大量人群行为导致的数据，比如业务访问量。
日志易在这块还有一个创新，即加强了时间特征上的处理。我们知道，人的行为是有大小周期的，今天和昨天，本周一和上周一，每个月一号，甚至每年春节，每年618，双十一。这些都是在算法上会重点加强学习的。
CVAE强制要求数据采样间隔一致，但允许个别采样点缺失。CVAE示例图形如下：
![](media/image52.png){width="5.768055555555556in"
height="2.8784722222222223in"}
iForest算法
iForest算法是一个专门用来做异常检测的随机森林算法变种。同样把指标曲线按窗口转换，然后构建分类树，随机切分迭代。检测适合、正常的情况下，划分次数越少，越可能是异常点。
![智能运维概念图-03.jpg](media/image53.jpeg){width="5.768055555555556in"
height="2.8513888888888888in"}
它适合一些和时间没有强相关性的指标，比如主机的CPU啊，内存啊什么的，数据本身离散度较大，没有什么规律，可能主要关心的就是它不要出现太明显的偏离。
这种指标比较多，要求算法检测速度够快。
iForest不关心历史数据，单纯从数据分布特征上进行检测，适用于机器指标。
![](media/image54.png){width="5.768055555555556in"
height="2.939583333333333in"}
KDE算法
第三个是KDE算法，这个算法针对的是一类特殊的场景。我们知道，有些服务，并不是7\*24运行的。比如股票市场，每天9点开盘3点关。在闭市的时候，证券公司相关系统的业务指标，完全是零。闭市和开市两个阶段，泾渭分明。普通算法，在这两个跃迁的时刻，几乎肯定是要误报的。
同理还有很多理财啊之类的金融场景，在周末两天也是一个道理。
![智能运维概念图-04.jpg](media/image55.jpeg){width="5.768055555555556in"
height="2.1020833333333333in"}
所以我们按照天的维度，对每天的每个时间点都选取它周围的若干个点，形成一个集合，进行核密度分析，然后一天的所有点合起来，得到最终的KDE模型。这个模型有点类似于在3D地图上，无数个正态分布堆在一起形成的山峦。那么检测的时候，对应时间过来的值，如果出现在平原地带，就是明显的异常了。
GRBT算法
最后一个是GRBT算法，我们会同时提取时序数据的统计学特征，以及它的时间戳特征。它的用途场景，和KDE、iForest相比，更广泛普适一些。突变的和业务的都能用。
![智能运维概念图-05.jpg](media/image56.jpeg){width="5.768055555555556in"
height="2.729861111111111in"}
可以看到这个算法原理，和前面iForest比较像。因为都是决策树森林。不过iForest是每次部分抽样迭代，而boost是每次根据上一次迭代的结果来重新选取分界点。
但是这是一个有监督学习的算法，所以想用好，需要训练样本里有一定的异常点标注。
有这么多不同的算法针对不同的场景，运维人员根据实际的区别，选用不同的算法，就可以达到比较好的算法覆盖了。
Lynxee后续也会继续研究指标数据的类型自动判断，尽量减少运维配置选取的工作量。
#### 应用场景
KPI异常检测功能主要适用于对企业业务KPI和系统KPI进行异常检测的场景，及时发现问题并告警，辅助运维人员快速定位问题。
KPI指标的数据类型分为三种常见数据类型，包括周期型数据、非周期型数据和特殊种类数据：
-   周期型数据：业务类指标往往是和人相关，人的自然作息周期就决定了业务类指标往往是周期的，如TPS、UV、PV、QPS。
-   非周期：系统类指标往往采集自机器，因为负载均衡、网络波动、内存优化甚至GC（Java的垃圾回收）系统指标基本没有明确的周期。
-   特殊种类：有些指标数据因为行业自身的特殊性，具有不同于一般周期的数据特点。比如证券行业有固定的交易时间，非交易时段没有指标产生。
KPI异常的异常类型分为极值类异常、平台类异常和业务类异常：
-   极值类异常，突然出现的离群值，可能是异常操作或系统延迟导致。
-   平台类异常：大段的连续异常，可能是目标业务系统宕机（极小值）或收到恶意攻击导致（极大值）。
-   业务类异常：基于业务原理下的异常，如应当出现高峰的时候出现低谷。即预期的指标走势和实际的指标结果出现了偏差。
日志易智能运维产品目前提供4个算法，KDE核密度分析、CAVE条件变分自编码器、MA移动均值、IF孤立森林，可以分别适用于不同的需求场景（高学习速度、高识别精度）：