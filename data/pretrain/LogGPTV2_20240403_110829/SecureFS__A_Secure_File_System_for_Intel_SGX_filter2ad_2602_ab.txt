may harm the confidentiality guarantee provided by an SGX
enclave. For example, consider filesystem operations where
the untrusted kernel observes which file has been accessed
and/or what exact offset has been read from or written to.
Haven [9] and Ryoan [18] attempt to address this issue by
introducing an in-memory file system for SGX. However, in-
memory filesystem is also insecure which we discuss further
in §III.
Page fault based side-channel attacks [50] are memory
access pattern based attacks for the SGX context. The untrusted
kernel can mark all of these pages to be non-accessible by
either manipulating page table permissions or directly evicting
them. This allows the kernel to learn which memory page has
been accessed by an enclave program through page faults. It is
worth noting that the SGX clears the offset of the page before
switching context to the kernel and therefore the granularity of
this attack is a paging unit (i.e., 4KB). Several works [34, 42]
have presented solutions to mitigate this attack, but each of
these has its own limitations, especially when we consider the
filesystem §X.
Recent reports [10, 40] have shown that SGX is vulnerable
against cache-channel attacks, specifically the Prime+Probe at-
tack. Although these reports show how cache based attacks can
be used to obtain cryptographic keys in an SGX setting, similar
attacks can be mounted against the filesystem (specifically
the in-memory filesystem) to find out what offset within the
filesystem was accessed. This attack is conceptually similar to
its variant in the non-SGX setting but previous solutions [21, 51]
considered a trusted OS to perform various mitigations. Those
solutions are not applicable within the SGX setting since the
OS is now untrusted.
B. ORAM
ORAM [16] provides obfuscated access to encrypted
memory which prevents an attacker from learning information
about the user/program even though the attacker can observe
the data access patterns. The key idea behind ORAM is to
obfuscate access to the same memory region each time (by
re-shuffling and re-encrypting with a new nonce) so that the
attacker is unsure which memory region is being accessed
despite observing multiple runs of the same program. ORAM
was originally introduced for the remote setting where a client
stores his/her encrypted data in an untrusted memory region
(i.e., remote machine) and does not want an attacker to learn
what data is being accessed as he/she tries to retrieve the data.
To achieve this, ORAM assumes the availability of a trusted
memory region which stores some metadata corresponding to
the untrusted memory. This metadata is essential to keeping
track of the actual location of stored data in the untrusted
memory. In the traditional sense, the trusted memory region
could be located within the client’s personal machine or some
other trusted machine. We explain some of the popular ORAM
designs [28, 46], below.
Path ORAM [46] is an optimization of ORAM which uses
a complete binary-tree structure to store encrypted blocks of
memory in an untrusted machine. The tree is made up of
multiple nodes where each node holds multiple blocks. A path
ORAM tree contains both real blocks (i.e., blocks that hold
client’s data) and dummy blocks (i.e., useless blocks). Since
all blocks are encrypted, the untrusted entity cannot distinguish
between them. The number of real blocks in a path ORAM
tree is always equal to the number of leaf nodes within the tree.
The remaining blocks are filled up with the dummy blocks. All
these blocks are randomly distributed within the tree, and the
client maintains a Position Map which points to the leaf node
on whose path, the block is located. Moreover, the client needs
maintain a Stash region to retrieve and store blocks after an
access. Figure 1 illustrates an example on how Path ORAM
accesses a block.
In Path ORAM, read and write operations are almost the
same and the data access is at the granularity of a block. To
read or write a specific real block, the client first consults
the Position Map and obtains the leaf L corresponding to the
block in the untrusted memory region. To maintain access
confidentiality, the client retrieves all blocks on the path from
the root to the corresponding leaf L. On receiving the blocks,
the client discards all dummy blocks and only saves the real
block(s) (there can be more than 1 block in the path) into the
stash region. In case of a write operation, the targeted real
block is updated and in the case of a read, it is simply copied
onto a separate buffer. In order to obfuscate access to this
real block for the next time, a new leaf node L’ is chosen,
uniformly at random. Then the client writes back all retrieved
real blocks to the old path L with the constraint that the targeted
real block should be placed on the newly chosen path (i.e.,
from the root to L’). It is important to note here that all real
blocks (along path L) are re-encrypted with a random nonce.
Also, all nodes (along path L) are filled with their regular quota
of nodes by adding newly generated dummy blocks in case
they are not filled by real blocks. Path-ORAM’s obliviousness
is achieved by the fact that each access to the same block
will yield a new path. Another popular tree-based ORAM is
3
Fig. 1: A Path ORAM example in reading a block ‘a’ (assuming one block per node for simplicity). Filled blocks (from ‘a’ to ‘d’) are real
blocks and unfilled blocks are dummy blocks (from ‘e’ to ‘i’). 1 : It attempts to read the block ‘a’, so all blocks on path ‘00’ are first loaded to
the stash. 2 : It randomly picks a new leaf path (assume ‘10’), and writes back the real block ‘a’ to the block on the new leaf path. All other
blocks on the path ‘00’ are filled with newly generated dummy blocks (i.e., ‘h’ and ‘i’).
ocall. Then the untrusted library invokes a corresponding system
call which is then processed by the kernel. Therefore, the kernel
maintains all filesystem related key metadata, including the
file descriptor as well as its associated file buffer cache. The
return procedure of the system call is also similar — the kernel
first returns the results to the untrusted library, which in turn
relays it back to the enclave. In order to provide integrity and
confidentiality, an encryption scheme with integrity checks can
be used together, where the encryption key (i.e., a sealing key
in the SGX context) can be bound with either the enclave’s
identity itself or the authority that owns the enclave program [4].
Limitation: Syscall Snooping Attacks. Since the kernel
performs all syscall operations, it has complete knowledge
about (a) which file is being processed during open and (b)
at which file offset the processing is currently taking place
during read and write. It is worth to note that, even though
encryption schemes using an SGX sealing mechanism has been
employed, it is still possible that the untrusted kernel may
learn much information out of the encrypted file. To be more
specific, the order of blocks will stay the same as before being
encrypted, because a block-wise encryption scheme (which
allows an encrypted memory block to be decrypted as it is
without decrypting the whole file) is used. As a result, the
offset information in read would reveal such an order thereby
allowing attackers to guess which part of the file has been
accessed.
B. In-memory SGX Filesystem
The in-memory filesystem (shown in Figure 2-b) performs
the majority of filesystem interactions within the enclave i.e.
EPC memory. Haven [9] and Ryoan [18] use an in-memory
filesystem design to overcome syscall snooping attacks. The
key difference from §III-A is that the application buffers the
complete file data, along with associated metadata, within
its enclave. Thus, all following filesystem operations can be
performed on the buffered data without involving adversarial
system components. For example, in response to open, the
trusted FS library (that is linked together with an enclave
application) opens the file and reads in all file data with the
help of the untrusted kernel similar to §III-A. This file data is
stored in buffer pages, located within the enclave, which is pre-
allocated beforehand. All corresponding filesystem operations,
i.e., read, write, etc. are handled within the enclave.
Limitation: Page Fault and Cache Based Attacks. This
model is vulnerable to both page fault based [50] and cache
based [10, 17, 40] side-channel attacks launched by the
untrusted kernel. In the case of page fault attack, the untrusted
Fig. 2: Available file system designs for Intel SGX. All threes are
vulnerable to either syscall snooping attacks ( 1 ), page fault based
side-channel attacks ( 2 ) and cache based attacks ( 3 ).
the recursive ORAM [28]. The author’s claim to reduce the
communication overhead by 30% over traditional Path-ORAM.
These two ORAM algorithms have inspired the ORAM-tree
structure of OBLIVIATE which we explain in §VI.
III. CURRENT SGX FILESYSTEM MODELS
In this section, we describe current filesystem schemes
for Intel SGX as well as pointing out potential attacks to
them. Depending on how filesystem related system calls are
processed and where filesystem metadata is maintained, existing
filesystems can be categorized into three different models:
(a) Naive SGX filesystem, which simply forwards all system
calls and the OS maintains the metadata; (b) In-memory SGX
filesystem, which handles the metadata, filebuffers and syscalls
within the enclave; (c) Hybrid SGX filesystem, which uses a
combination of the above two models.
A. Naive SGX Filesystem
This model is a natural extension of the traditional filesystem
access mechanism for SGX (shown in Figure 2-a), which is used
by Intel’s Protected File System Library Using SGX [3] and
SCONE [7]. In this model, all filesystem operations (including
metadata handling) are performed by the kernel. In particular,
since SGX does not allow direct syscall invocation, this model
simply forwards all filesystem related system calls to its
untrusted library, which is running outside an enclave, through
4
efgabcd010101a00b01c10d11efgabcd010101a10b01c10d11ahgibcd010101efaPositionmapPositionmapStashStashStashvuAppTrustedFS LibUntrusted FS LibAppUntrusted FS Lib(b) In-memory FS(c) Hybrid FSAppUntrusted FS Libopen()Read(), write()A file descriptorA data block (filled)A data block (empty)(a) Naive FSKernel (Untrusted)File storage(Untrusted)Process(Untrusted)uEnclave(Trusted)uvwvwSGX driver is capable of marking all EPC memory pages non-
accessible by manipulating page table permissions or directly
evicting mapped pages from the EPC regions. This leads an
enclave execution context to raise a page fault onto the page it is
accessing which is first delivered to the kernel. Then the kernel
re-enables access onto the page so that the enclave program
can resume its execution. As a result, this attack allows the
adversarial kernel to learn the file buffer access information up
to the granularity of a paging unit (i.e., 4 KB).
Similarly, the cache based attack is also feasible. The
kernel can monitor one of the caches (L1 to LLC) to find
out which cache-set and corresponding file offset was accessed.
Assuming the adversarial kernel has prior-knowledge on the
rough semantic information of enclave’s memory layout (e.g.,
where file buffers are located), the attacker will learn which
part of the file has been accessed.
C. Hybrid Filesystem
The hybrid filesystem model blends previously mentioned
designs, naive FS model and in-memory FS model. In this
model, unlike the in-memory filesystem model, the trusted
library does not load the complete file data into the enclave but
instead does so on-demand. To gain a clearer understanding, the
file is buffered within the non-enclave memory (but within the
DRAM) and copied into the enclave as required. Graphene [47],
particularly the version ported for SGX environments [48],
employs this filesystem model.
Limitation. Since the hybrid model mixes up two filesystem
models without special security mechanisms, its attack surface
also inherits from both models. Thus, although there can be
subtle differences in the attacker’s capability, the hybrid model
is basically vulnerable to all aforementioned attacks, from
system call based attacks to page fault and cache based attacks.
IV. CASE STUDY: LAUNCHING ATTACKS
To clearly demonstrate the feasibility of attacks, we per-
formed concrete attacks against current filesystems for SGX.
In this attack, we assume that an enclave application runs a
popular database application, SQLite [33], where the database
file is encrypted and the database communication channel is
encrypted as well. SQLite stores user-data persistently through
files which are created using the regular Linux Filesystem
API, i.e., open. Afterwards, all database operations including
insert, select, etc. are completed by indexing into the
database file using read, write, pread, pwrite, etc. For
simplicity of the attack, we also assume that the attacker has
knowledge about database schema (e.g., the count of the tables
stored in the database file, and the size of a single row within
the table). The attacker can also infer these details by closely
monitoring the access patterns onto the database file since
SQLite uses data-dependent access to optimize performance.
In this setting, we assume a usage scenario that an insurance
company maintains a database storing medical records in order
to set insurance premiums. The company wants to use a cloud
infrastructure while ensuring that the data is completely isolated
and secure. For this purpose, the company runs SQLite inside
an SGX enclave. All data (outside the enclave) is encrypted
and therefore even a privileged attacker cannot directly read
the data. However, the attacker knows that one of the database
1 // Table -> (id (4bytes), history (4KB), no-history (4KB))
2 open("heart.db", O_RDWR, 0666);
3
4 // Query 1: For patient with heart disease.
5 pread64(3, 0x2783933, 4096, 0);
6 pread64(3, 0x2637298, 4096, 4096);
7 pread64(3, 0x2732123, 4096, 32768);
8
9 // Query 2: For patient without heart disease.
10 pread64(3, 0x2637221, 4096, 0);
11 pread64(3, 0x2738212, 4096, 4096);
12 pread64(3, 0x2632119, 4096, 40960);
13 pread64(3, 0x2637223, 4096, 45056);
Fig. 3: Syscall traces observed by an attacker, i.e., an untrusted kernel.
The first 8KB correspond to the metadata of the SQLite database.
files contains privacy sensitive information, indicating whether
a person has a history of heart disease within his/her family
or not. The goal of the attacker is to leverage this schema
information to find out whether a given query returns a row
with heart disease or not.
Elaborating more details on this medical database schema,
each row corresponds to a 8194 m
emory chunk which is divided
¯
into one column of 4 bytes and two columns of 4 KB each. The
first column contains identification information about the person
to which this specific row belongs. The second column contains
information if the person has a history of heart diseases, and
the third column contains information if the person does not
have a history of heart diseases. Also, the company runs a
single query on the database. The query checks if the provided
person ID is associated with a history of heart disease or not,
and returns information from one of the intended columns.
Syscall Snooping Attack.
In this attack, we run a victim
SQLite server within an enclave, where SQLite is built with
Intel’s Protected File System Library (i.e., naive FS model).
Figure 3 shows the syscall traces that can be collected by a
privileged attacker. The victim first opens a database file using
the open syscall (line 1) and the host OS now knows which
file is being used (i.e., “heart.db”). Next, the database always
reads the first two pages (8KB) in order to maintain metadata
information from the database file. The victim runs two queries
shown by lines 5-7 and lines 10-13. Furthermore, the attacker
observes that the first query (lines 5-7) accesses the fourth row
within the database by calculating it against the size of a row
(8KB). Also, since the database only reads the first 4KB from
then on (line 7), the attacker can infer that only the first column
was accessed, which means that the query was meant for a
person with history of heart disease. In the second query (lines
10-13), the attacker observes that the offset corresponds to the
fifth row, and since it reads two 4KB offsets (lines 12-13), the
attacker can infer that this query hits the second column, i.e.,
a patient without heart disease.