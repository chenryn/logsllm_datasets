servicecalls.InFig.1,weshowatracewhentheuserrequests
tree based on the frequency counts of the words appearing on
creation and deletion of a network as operation in the cloud.
particular positions within the text sequence. The spans with
At the bottom of the image the POST /v3/auth/tokens/ span
reduceddescriptionaregivenasinputtoDrain.Drainasoutput
is replaced with the [MASK] span. We refer to the POST
generatesasetofgroupsofspansorspantemplates.Thusthe
/v3/auth/tokens/ as masked span, while all of the other spans
trace can be represented as a sequence of span templates or
form its context.
sequence of symbols.
To address the problem of the prediction of a masked span
Due to the complexity arising in the distributed systems it
of a trace given its context, we introduce the masked span
canhappenthatthetracesofsuccessfulexecutionofthesame
prediction (MSP) task. As a learning task, it aims to pinpoint
request multiple times, the traces to be of different length.
what is the most likely span to occur on a particular masked
To account for the different length of the traces, the traces
position given its context from the neighbouring spans. A
arepaddedupto(max len)numberofspans.Thisparameter
masked span in a trace can be any randomly chosen span
represents the maximum allowed trace length. Additionally,
that during the learning procedure is labeled with a special
to conserve the information for the length of the traces, two
[MASK] span from the input. During the learning procedure,
special spans ([START] and [STOP]) are introduced. They
the true value of the masked token is used as a target and it
are added to the beginning and the end of the trace, prior
is predicted by the remaining spans that construct the context
to padding. The training dataset is composed just of traces of
(givenasinput).Insuchaway,oneallowsforthemaskedspan
normalexecutionoftheworkload.Thisisastrongrequirement
to ”score” how much the spans from the context are relevant
since the cost for labeling tracing data is large.
for its prediction.
B. Method Design
A common approach for modeling the normal execution of Input:
a trace is utilizes the autoregressive modelling concept [9]. trace 1 trace 2
It assumes that each trace has a particular number of spans
m, where each span S mi ∈ V is part of the set of span [start] [start] Output:
templates V. An autoregressive statistical approach aims to
[m] s 1 p(s 1)
assign probabilities to sequences of symbols using the chain
rule of probability: s s 2 2 (cid:172)redocnE redoceD xamtfoS
(cid:2)T p(s 2)
... ...
P(S 1:T)= P(S t|S <t) (1)
t=1 s k-2 [m] ...
where S <t denotes the (potentially empty) sequence of spans
from S 1 to S t−1. The conditional probabilities on the right- s k-1 s k-1 p(s n)
handsidecanbemodeledwitharecurrentneuralnetworke.g
[stop] [stop]
MSP task solver
LSTM [8]. This approach is autoregressive, since it uses just
forward context at time. As such it is limited in the amount
of exposed context during the learning phase e.g backwards Fig.2. TheneuralnetworkarchitectureusedtosolvetheMSPtask.Itisan
context is not taken care of. encoder-decoder architecture with residual connections, layer-normalization
anddropoutateachlayerappliedasregularization.
In our approach, the underlying premise suggests that the
appearing of a span on a particular position in a trace is Fig.2depictstheadoptedmethod.Itisanencoder-decoder
conditioned not only on the previous spans but also on the structure that maps the context of the span in a vector format
344
Authorized licensed use limited to: Technische Universitaet Berlin. Downloaded on September 06,2021 at 12:04:10 UTC from IEEE Xplore. Restrictions apply.
to a probability distribution over the vocabulary of spans. A. Experimental data
The encoder uses a multi-head self-attention neural network
To test and verify our approach and due to the absence of
learning mechanism as an encoder [17]. This architecture
publiclyavailabledatasetsforevaluation,wefirstdeployedan
allows for selective prediction of the relevant spans from the
OpenStack [18] testbed. Fig. 3 depicts the architecture. It is
context for prediction of the given masked span.
based on a microservice architecture, running in a dockerized
To train the neural network the inputs should be in the
environment Kolla-Ansible [19]. There are 4 compute and
appropriateformat.Theyareformedinawaythatforeachof
one control node. Further specifications include deployment
thetracesk randomlychosenspansduringthelearningphase,
on bare-metal nodes, where each node has RAM 16GB, 3x
aremasked.Insuchawayasingletraceismultipletimesfed
1TB of disks, and 2x 1Gbit Ethernet NIC. To automate and
through the encoder neural network, each time with different
unify the multi-node OpenStack deployment, cloud verifica-
spanbeingmasked.Assuchitisakeyfeaturethatallowsthe
tion, testing, profiling the workload generation and anomaly
usage of the method for anomaly detection. Additionally, it
injection we used Rally [20].
gives flexibility of the method to build one single model for
The normal and anomalous data is generated from the
multipleuserrequestsinsteadofseparatemodelsfordifferent
execution of the three workloads. Create and delete server
user requests. Encoder neural network implements the self-
uses a task from Rally to create and delete a virtual machine.
attention learning mechanism.
The fault is injected in a compute node which restarts the
Outputsfromtheself-attentionlayerarefedthroughaone-
APIcontainerthatrunsonthecomputenodes.Thissimulates
layernetworkwithsoft-maxattheendthatservesasadecoder.
a failure of a service. Create and delete image uses the
The soft-max is used as a function to generate probability
glance project of OpenStack to create and delete an image.
estimatesoverthewholedictionaryofspantemplatesV.These
The faults are injected via restarting of the glance-API which
probabilities suggest how likely is the current masked span to
runs on the controller node. Create and delete network is a
beassociatedwithasymbolwithinthevocabularyofsymbols
an operation that provides network interface. The anomaly is
conditioned on the context.
injected with disturbing of one of the neutron services: (e.g.
The MSP is a proxy task for anomaly detection. As a neutronmetadataagent,neutronserver)duringthecreationof
standalone task cannot be used for anomaly detection. To this a network.
end,weintroduceadditionalpostprocessingofthepredictions
Torepresentascenarioasclosetothereal-world,theoper-
oftheMSPmodeltodetectanomalies.TheoutputfromMSP
ations are executed concurrently. Furthermore, the operations
for a particular trace is an ordered list of spans for each
are scheduled to last for an equal period. Since some of
position of the trace. The lists are ordered according to their
the operations are faster than others (e.g, we need greater
relevance to fill up the particular position of the trace. During
time to boot a machine compared to the time needed to
the anomaly detection procedure, each of the ordered lists on
create a network) the operations are started with different
theparticularpositioninthetraceisexaminedinthefollowing
repetitions. Specifically, 2000, 3000, and 6000 iterations for
way. If the real value on a particular position of the trace is
create and delete server, create and delete image and create
not in the first top−k elements of the list generated of the
anddeletenetworkwereconducted,respectively.Theinjection
MSP task module for that position, we consider the span as
of the faults happens at different rate - 250 for create and
not being correct. We count the number of errors for each
delete server and create and delete image and 500 iterations
trace and divide with the trace length forming the ratio of
for create and delete network. After the execution of the
misclassified examples (span error rate per trace). This span
sequenceofworkloads,reportsfortheconductedexperiments
error rate serves as an anomaly score. It is expected that if a
are generated. The reports have details for the successful
model makes many mistakes, the anomaly score to be high,
executionoftheworkload.Theyareusedtoinducetheground
thus the trace is anomalous. Setting a decision threshold on
truth label for a particular user-request. This is needed to
the anomaly score serves to decide if the trace is normal or
separate the normal from anomalous traces to perform the
anomalous.
evaluation.
Workloads and faults UI / Dashboards
IV. RESULTSANDDISCUSSIONS
Monitorinig and Logging
Co wn atr lo lyl 1n 1o 3de Kibana
In this section, first, details on experimental testbed used
f ao dr ee sv ca rl iu pa tit oio nn oo ff tht ehe lem are nt ih no gd sa cn end at rh ioe sd wat ea aa dr oe pg teiv de tn o. eS ve ac lo un ad te, and E inwx jee o ccR r tu k ia olt ol i nl oy a n d o s fo ff a(cid:172) ults TA raPA cIP eA S I cP g e oS eIr l e n lv S er ei ec cv re tir ac iv os tei i nc ose ns and 11C 7o , m 1w 2p 2u a ,t l e ly 1 2n x 3o ,d 1e 2s 4 ElasF tl iu ce -sn et ad rch recnalab daoL
Redis Services
the performance of our method and the corresponding com-
DB MQ (gM lae ntr cic es s)
parative analysis of the three learning scenarios.Finally, we