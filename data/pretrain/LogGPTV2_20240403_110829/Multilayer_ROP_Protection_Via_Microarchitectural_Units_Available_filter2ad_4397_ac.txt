the result of an unaligned memory access. Finally, we use Pin
to simulate the call validation mechanism of Section III-B.
Pin lets us inspect each instruction upon its execution. We
use it to verify (i) that the destination address of a call that
precedes a candidate gadget is executable and (ii) to simulate
the presence of the LBR.
Analysis of Results. Figure 5 shows the results of this
experiment on seven large applications – four of which are
vulnerable to known ROP exploits. The number of gadgets
left by the executable target constraint (XT) is 0.06% of the
total number of gadgets in the binary. To give the reader some
perspective on this number, this constraint leaves 34.94 times
less gadgets than the call-preceded constraint when applied
onto the same suite. The call-preceded constraint is central to
many previous defense mechanisms [25], [41], [43], [60]–[62].
In practice, the reduction that our new constraint achieves
makes it very difﬁcult to build effective ROP attacks. We
support this statement with a statistical argument ﬁrst used by
Schwartz et al. [35]. Their tool, Q, usually requires binaries
with at least 100KB to be able to execute calls to any function
in libc. Similarly, it requires binaries of at least 20KB to
invoke linked functions and update arbitrary locations. In other
words, the number of gadgets expected to be found within
20KB of code is enough to carry out an attack. The executable
target constraint reduces the density of gadgets in the binary.
Pragmatically, this is equivalent to reducing the size of the
binary available to the attacker. Figure 5 shows the size of
the binary representation of each application. The last column
of Figure 5 shows the “apparent” size of those binaries, in
terms of number of gadgets, that Q would see. Notice that this
new size is given in KBs, not in MBs. The largest apparent
size, found in Internet Explorer 8, is over 5x smaller than the
minimum size that Q requires to perform a successful exploit.
B. RQ2 – Filtering statistics
The multilayer approach that we advocate in this paper is
interesting if a large volume of indirect branches is ﬁltered
across successive layers. In this section, we show that the
ﬂow of indirect branches to be validated is drastically reduced
by going through Layers 1 and 2 of our model. We test two
different implementations of Layer 2: in Section IV-B2 we use
the executable target constraint (XT), and in Section IV-B3 we
use Intel’s Control-ﬂow Enforcement Technology (CET).
1) From Layer 1 to Layer 2: Indirect branch prediction:
The Layer 1 of our model, described in Section III-A, uses
branch prediction to validate program ﬂows. The greater the
number of indirect branches that can be correctly predicted,
the smaller the number of cases that reach Layer 2. In this
section we shall count this hit rate.
Measurement methodology. To analyze the effectiveness of
modern indirect branch predictors, we count the actual number
of prediction misses. To this end, we use Hardware Perfor-
mance Counters (HPCs) available in current x86 processors.
In the experiments, we calculate the percentage of indirect
branches correctly predicted by monitoring the number of
misses and the total amount of branches executed. x86 imple-
ments different prediction strategies for different categories of
branches. Thus, we had to capture the performance counters
for each type of indirect branch. We count the taken specula-
tive and retired returns, indirect calls, and indirect jmps.
We also measure the number of mispredictions for the same
instructions. To produce summarized results, all the average
values presented were weighted on the number of instructions
executed by the benchmarks: programs with more instructions
contribute proportionally more towards the ﬁnal average.
Analysis of Results. Figure 6 reports the accuracy of the
branch predictor for the programs in the SPEC CPU2006
collection, and in the LLVM test suite. We have grouped
the results for the LLVM test suite into a single bar, called
LLVM. This procedure will be also used in the next charts
that we present in this paper. The benchmark that executed
the lowest number of instructions was gobmk, with 6.8E+10
321
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:52:59 UTC from IEEE Xplore.  Restrictions apply. 
(cid:49)(cid:48)(cid:48)(cid:1)
(cid:55)(cid:53)(cid:1)
(cid:53)(cid:48)(cid:1)
(cid:50)(cid:53)(cid:1)
(cid:48)(cid:1)
)
%
(
e
t
a
r
t
i
H
(cid:9)(cid:11)(cid:12)(cid:1)(cid:44)(cid:57)(cid:50)(cid:43)(cid:56)(cid:49)(cid:60)(cid:45)(cid:1)
(cid:13)(cid:5)(cid:14)(cid:1)(cid:44)(cid:57)(cid:57)(cid:43)(cid:48)(cid:51)(cid:60)(cid:45)(cid:1)
(cid:3)(cid:2)(cid:10)(cid:10)(cid:1)(cid:44)(cid:56)(cid:57)(cid:43)(cid:51)(cid:50)(cid:60)(cid:45)(cid:1)
(cid:1)
(cid:34)
(cid:17)
(cid:36)
(cid:35)
(cid:17)
(cid:1)
(cid:50)
(cid:32)
(cid:25)
(cid:42)
(cid:18)
(cid:1)
(cid:35)
(cid:21)
(cid:38)
(cid:17)
(cid:39)
(cid:18)
(cid:1)
(cid:40)
(cid:25)
(cid:28)
(cid:37)
(cid:19)
(cid:28)
(cid:17)
(cid:19)
(cid:2)
(cid:35)
(cid:37)
(cid:36)
(cid:19)
(cid:17)
(cid:19)
(cid:1)
(cid:8)
(cid:8)
(cid:28)
(cid:17)
(cid:21)
(cid:20)
(cid:1)
(cid:35)
(cid:35)
(cid:21)
(cid:29)
(cid:17)
(cid:23)
(cid:1)
(cid:19)
(cid:19)
(cid:23)
(cid:4)
(cid:6)
(cid:35)
(cid:29)
(cid:21)
(cid:7)
(cid:1)
(cid:27)
(cid:29)
(cid:18)
(cid:31)
(cid:23)
(cid:1)
(cid:35)
(cid:19)
(cid:17)
(cid:29)
(cid:31)
(cid:34)
(cid:23)
(cid:1)
(cid:22)
(cid:21)
(cid:34)
(cid:52)
(cid:54)
(cid:50)
(cid:24)
(cid:1)
(cid:34)
(cid:21)
(cid:29)
(cid:29)
(cid:24)
(cid:1)
(cid:29)
(cid:18)
(cid:28)
(cid:1)
(cid:20)
(cid:51)
(cid:21)
(cid:25)
(cid:28)
(cid:35)
(cid:21)
(cid:28)
(cid:36)
(cid:30)
(cid:17)
(cid:37)
(cid:33)
(cid:18)
(cid:25)
(cid:28)
(cid:1)
(cid:22)
(cid:19)
(cid:29)
(cid:1)
(cid:19)
(cid:28)
(cid:25)
(cid:29)
(cid:1)
(cid:20)
(cid:29)
(cid:17)
(cid:30)
(cid:32)
(cid:36)
(cid:21)
(cid:30)
(cid:29)
(cid:31)
(cid:30)
(cid:21)
(cid:18)
(cid:28)
(cid:34)
(cid:21)
(cid:32)
(cid:1)
(cid:41)
(cid:17)
(cid:34)
(cid:38)
(cid:31)
(cid:32)
(cid:1)
(cid:23)
(cid:30)
(cid:21)
(cid:26)
(cid:35)
(cid:28)
(cid:1)
(cid:40)
(cid:21)
(cid:32)
(cid:31)
(cid:35)
(cid:25)
(cid:1)
(cid:40)
(cid:30)
(cid:24)
(cid:32)
(cid:35)
(cid:1)
(cid:31)
(cid:36)
(cid:30)
(cid:31)
(cid:36)
(cid:1)
(cid:22)
(cid:34)
(cid:39)
(cid:1)
(cid:30)
(cid:17)
(cid:17)
(cid:16)
(cid:28)
(cid:1)
(cid:11)
(cid:15)
(cid:10)
(cid:10)
(cid:1)
(cid:32)
(cid:29)
(cid:35)
(cid:37)
(cid:21)
(cid:42)
Figure 6. Hit rate (%) of the branch predictors for the programs in the SPEC
CPU2006 and LLVM Test benchmark suites. Numbers next to labels show
the weighted average accuracy of each predictor. The LLVM bar subsumes
results of 209 programs in the LLVM test suite.
operations. The largest number of instructions was executed by
calculix: 6.1E+12. In total, we observed 4.8E+13 instruc-
tions when evaluating SPEC CPU2006. The dynamic predictor
succeeds in 97.72% of the indirect branches executed. This
number is the average of all the averages, weighted by the
number of instructions in each benchmark. In the speciﬁc case
of return addresses, the return address stack (RAS) achieved
the accuracy of 99.03%. The prediction of targets of indirect
jmps and calls achieved respectively a hit rate of 92.81%
and 89.32%. These values corroborate the hypothesis that
dynamic predictors of indirect branches are an effective way
to ﬁlter out the cases to be monitored. If we consider all
the instructions executed, on average one in 100,000 requires
action of Layer 2. This is the main reason for the low overhead
imposed by our model, as we shall discuss in Section IV-C.
2) From Layer 2 to Layer 3 - Return Address Valida-
tion: Our Layer 2 applies the Executable Target Constraint
described in Section III-B to validate returns that are
mispredicted. This layer is effective as long as most of the
return addresses are preceded by valid call instructions. In
this section we quantify them.
Measurement methodology. We use the prototype described
in Section III-B to simulate the Executable Target Constraint.
We also simulate the Instruction Translation Lookaside Buffer
(iTLB). The idea is to check the execution permission of the
target of a direct call instruction in the same frequency that
a page walk actually happens on a real processor. Using this
strategy, we establish an upper bound that better approximates
the execution time of a solution implemented in hardware.
We have used hardware performance counters to estimate the
iTLB miss rate observed when executing SPEC CPU2006
benchmarks. We use this estimate, plus a counter in the Pin-
tool, to mimic the hardware behavior adjusting the frequency
that permission checks should actually execute. Our machine’s
iTLB is parameterized in the following way: L1 instruction
TLB for 2M/4M pages is fully associative with 8 entries; L1
instruction TLB for 4K pages is 4-way associative with 64
entries; and L2 TLB (instructions and data) for 4K pages is
return addresses preceded 
Direct
by Valid CALLs
Indirect
return addresses preceded 
Direct
by Invalid CALLs
Indirect
return addresses not preceded by CALLs
69.84%
27.01%
0.17%
1.54%
1.44%
96.86%
3.14%
Figure 7. Validations that slip from Layer 2 to Layer 3. 96.86% of return
addresses are validated at Layer 2; 3.14% will slip to Layer 3.
4-way associative with 512 entries.
Analysis of Results. Figure 7 displays the results of this
experiment, using the same applications seen in Figure 5. The
upper rows in Figure 7 show cases where return addresses are
properly validated (preceded by a valid call). Lower rows
indicate the percentage of cases that will be submitted to a new
analysis at Layer 3. As in the prediction of return addresses,
the validation of these targets presents a very high percentage
of success (96.86%). Checking the calls that precede the
return address adds few cases to the subsequent layer (3.14%).
Therefore, considering the beneﬁt provided by this strategy
with the reduction in the number of gadgets, the validation of
return addresses proposed in this work is worth it.
3) From Layer 2 to Layer 3 - Control-Flow Enforcement
Technology: As mentioned in Section I, our multilayer ap-
proach yields a modular design. Different implementations are
possible, for instance, at the level of Layer 2. One such possi-
ble implementation is based on the Control-ﬂow Enforcement
Technology (CET) from Intel. We have experimented with a
CET-like implementation. This section reports our ﬁndings.
Measurement Methodology. We have implemented a CET-
like validation of return instructions,
following public
knowledge [29]. A shadow stack was implemented using Pin.
Like CET, our Pintool creates a stack in memory and instru-
ments every call and return executed by the application.
Whenever a call is processed, our prototype pushes the
address of the next instruction into the shadow stack. When
a return executes, we check if the return address matches
the address in the top of the shadow stack. Like CET, our
implementation is not affected by context switches. We also
create one shadow stack for each thread of the application and
use Pin locking system to avoid interferences.
Analysis of Results. Using CET’s shadow stack, we observed
that 1.44% of the branches slip from Layer 2 to Layer 3.
The target execution constraint, as seen in Figure 7, gives
3.44%. As recently pointed by Qiu et al. [44, Sec.V.C],
a CET-like shadow stack has more cases that yield false
positives than those we have enumerated for the executable
target constraint. Nevertheless, in our experiments, CET has
been able to validate more return instructions than XT. We
speculate that this result is due to the fact that Pin does not
instrument privileged code and some of the known cases of
false positives are related to system calls. This said, our results
indicate that both strategies produce a comparably low false
positive rate. On the other hand, a shadow stack is more costly,
from an implementation perspective, as we discuss next.
322
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:52:59 UTC from IEEE Xplore.  Restrictions apply. 
A shadow stack has three shortcomings, which do not exist
in the executable target constraint. First, XT has lower impact
on the instruction pipeline since validations happen in parallel
with instruction processing. To manipulate the shadow stack,
on the other hand, CET adds work onto call and return
instructions. It also adds work onto store operations. Such
instructions must be veriﬁed to prevent them from tampering
with the shadow stack, as pointed out by Sinha et al. [63].