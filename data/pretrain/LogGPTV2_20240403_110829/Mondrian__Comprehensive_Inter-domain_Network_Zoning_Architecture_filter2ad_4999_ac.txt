not requiring veriﬁcation of the zone transition authorization.
Upon receiving a packet, T Pdst checks the authenticity of
the packet, decrypts EIP, and forwards the original IP packet
to the destination host. This trust model simpliﬁes the entire
veriﬁcation process signiﬁcantly by omitting the authorization
step which requires an additional challenge-response protocol
to the controller, improving practicality for TPs running at
small branches limited in operational resources.
C. Key Management
In order for the TPs to create and verify authentica-
tors based on symmetric cryptography we need a scheme
to distribute keys amongst them. Ideally, the keys used for
| zoneIDdst} should be
every triplet of {T Psrc | T Pdst
different. Additionally, ease of key management is a major
concern as key distribution mechanisms in today’s Internet,
such as IKE [39], [22], [30], are complicated and introduce
management overhead; the number of symmetric key pairs
increases quadratically with the number of zones, which ham-
pers scalability. To alleviate these problems we propose a key
management system based on PISKES [56].
Major modiﬁcations to PISKES for MONDRIAN key man-
agement stem from the following requirements: ﬁrst, in the
context of network zoning, we require a high degree of
conﬁdentiality on top of authenticity to protect sensitive in-
formation. PISKES mainly targets authenticity for network
entities, not conﬁdentiality. Second, it is unlikely that an AS
wants to have a dedicated key-establishment service for each
enterprise, while PISKES’s key establishment relies on the
asymmetric key pair issued to each AS. The AS-driven key
establishment approach would require additional management
overhead and deployment for ASes. Third, MONDRIAN re-
quires key management at zone granularity, while PISKES
is intended to support key exchanges at a ﬁner granularity
(e.g., per host or application). Thus, design simpliﬁcation also
simpliﬁes the architecture, reducing functional complexity and
enhancing management scalability.
Driven by this, we redesign the PISKES’s key-derivation
architecture removing the AS dependency (i.e., the AS keys
and the dedicated key servers at each AS), meaning that an
enterprise has full control over distributed network zones and
does not need to trust other ASes for inter-zone networking.
Additionally, we simplify the key derivation to work at zone
granularity, supporting faster key derivation while providing
the same level of security.
Key Hierarchy. PISKES introduces a key hierarchy that allows
services to efﬁciently derive symmetric keys. We adapt the
concept to support key derivation in the context of network
zoning. The key hierarchy is as follows:
•
•
•
0th-level key: ST P is the secret value generated by
each TP individually.
1st-level key: a TP derives different symmetric keys
for other TPs from the local secret value ST P . The
derived symmetric keys are called ﬁrst-level keys and
are calculated as
(A),
KA→B = P RFST P B
(5)
where B stands for the receiving TP address and P RF
is a secure pseudo-random function. Since only one of
the two parties can derive this key, it is necessary for
the other party, in this case A, to fetch the shared
symmetric key by contacting B†.
2nd-level key: from the ﬁrst-level keys, second-level
keys are derived to provide diverse symmetric keys
for each zone within the same source and destination
TP pairs. The second-level keys are calculated as
KA→B:Z = P RFKA→B (Z).
(6)
Z is the zone ID of the target zone where the desti-
nation host resides.
This hierarchical key structure is beneﬁcial in multiple
aspects: ﬁrst, it delivers key diversity. Since a second-level
key is bound to a destined zone, it enables each zone to
have different keys even for the same pair of source and
destination TPs. Second, it is easy for TPs to efﬁciently derive
the symmetric keys as all the required inputs to derive the
key (i.e., local and remote TP address, and destination zone)
are contained in the packet header. In particular, a remote
TP thus can derive the key directly from the packet header
without a memory lookup. Finally, since all second-level keys
are derived directly from ﬁrst-level keys, the system scales
linearly with the number of TPs, not the number of zones,
achieving scalability.
Bootstrapping Keys. Each TP randomly generates a local
secret value ST P , the root of the TP-speciﬁc key hierarchy.
Since the ﬁrst and second-level keys are derived from the secret
value recursively, they inherit the randomness and secrecy of
ST P . We suggest using a true random number generator. The
randomly generated secret value never leaves TP premises and
is frequently renewed, e.g., on a daily basis, to achieve perfect
forward secrecy [26], [55].
Key Establishment. Key establishment precedes the ﬁrst
data transmission. To establish a ﬁrst-level key, the source
TP initializes the key exchange protocol by sending a key
exchange request:
req = A | B | V alT ime,
,
T PA → T PB : req | {H(req)}K
−
A
(7a)
(7b)
where V alT ime represents the validity period of the request.
The hash value of the request is signed with the requesting
TP’s private key K−
A , such that the receiving TP can verify the
authenticity of the request packet. Recall that, for authenticity
†We note that, in contrast to PISKES, the arrow direction in the notation
indicates the communication direction for which the key is used.
7
of MONDRIAN entities, each TP veriﬁes the public key based
on a certiﬁcate issued by the trusted CA, i.e., the controller.
Upon receiving the key exchange request, T PB veriﬁes the
source authenticity and checks the validity of V alT ime. If the
request is valid T PB derives a ﬁrst-level key from the local
secret value ST P B and replies back to the requester. The reply
packet is formed as follows:
KA→B = P RFST P B
(A),
rep = {B | KA→B | ExpT ime}K+
T PB → T PA : rep | {H(rep)}K
,
−
B
,
(8a)
(8b)
(8c)
A
where ExpT ime denotes the expiration time of the ﬁrst-level
key, K +
A is the T PA’s public key used for encryption, and
K−
B is the T PB’s private key to sign the reply packet. Finally,
the requesting TP veriﬁes the validity of the reply packet and
caches KA→B until it expires.
Ideally, a TP prefetches all the ﬁrst-level keys for other
TPs it wishes to communicate with. The TP acquires the list
of active TPs from its controller and initiates the key exchange
protocol for these TPs in advance. This is feasible because the
number of TPs for an enterprise is surely limited; for example,
the total number of branches that the Bank of America has in
2019 is approximately 4.6k [62]. Each branch would need at
least one TP, which means that a TP needs to prefetch more
than 4.6k ﬁrst-level keys. Nonetheless, on-demand key fetching
is also possible. In particular, when the current ﬁrst-level key
expires in the middle of on-going data transmission or a new
TP joins, a key exchange is initiated.
TPs are also responsible for second-level key establish-
ment. However, this does not require any key exchange pro-
tocol. Upon data transmission, source and destination TPs are
able to dynamically derive the same second-level key for the
destined zone from the shared ﬁrst-level key as shown in
Equation 6.
V.
IMPLEMENTATION
We now describe the implementation details of each com-
ponent
in MONDRIAN. We implemented a prototype that
comprises a software-based gateway and controller. The main
development language is golang 1.14.1 [20], and we used
SQLite3 [61] for the database. To secure control-plane chan-
nels, we also leveraged TLS 1.3 [55]. The prototype is publicly
available [52].
Our implementation builds on top of the SCION archi-
tecture [49]. The implementation decision has been driven
by the following reasons: i) SCION provides network pro-
grammability along with the separation of control and data
plane, ii) SCION comes with an embedded PKI system that
can be utilized for our key management system, and iii) the
opensource version of the PISKES system [51] as well as a
software-based gateway working with SCION are available,
thus enabling rapid prototyping.
A. Translation Point
To implement a prototype of TP, we extend the SCION-IP
Gateway (SIG) [59]. The main functionality of the SIG is to
encapsulate legacy IP packets into SCION packets and vice
from other TPs and derive a second-level key to generate the
authentication token. Inversely, for packets from other TPs,
it derives the corresponding 2nd-level key and veriﬁes the
delivered authentication token.
Database. The TP’s database consists of three tables: Zone
Table, Zone Transition Table, and Key Table. The zone table
is used to map hosts to their corresponding zones. For a fast
table lookup, we leverage Radix Trees (also known as a trie or
compact preﬁx tree), cidranger [8] in particular. The zone
transition table is a database in which the zone transition rules
are stored. The two tables are populated with the information
acquired from the controller. The key table is where the shared
ﬁrst-level keys are stored.
Policy Miss. The current TP’s implementation keeps sessions
associated with a certain remote site. Packets from the interface
are added to the ring buffer of their corresponding session.
Each session keeps a set of worker threads handling its packets.
If there is a policy miss in lookup, the worker handling the
packet will initiate a policy fetch from the controller while the
packet is kept in memory. It could happen that all workers of a
given session are busy handling packets of a stream for which
the policy is missing. This would stall communication with
the corresponding remote entity until the policy is installed
locally. Other sessions remain unaffected.
B. Controller
We implemented the controller as a Web server written in
golang with an SQLite database storing the zone information
and transition policies. The controller offers an API which
allows TPs to fetch zoning information via HTTPS GET
requests.
APIs. The endpoints of interest are: i) /api/get-subnets and
ii) /api/get-transitions. Using these endpoints TPs fetch IP
subnet and zone transition rules. Important to note is that the
controller only hands out the subset of the full set of rules
which is required for the requesting TP to be operational. This
minimizes the size of data transmissions and also improves
security by not disclosing the full network view to every
TP. For every call to the API the controller ﬁrst veriﬁes the
authenticity of the caller before the request is forwarded to the
corresponding handler. The handlers then load the requested
data from the database and send it to the caller as JSON-
formatted bytes.
Database. The database consists of four tables (Zones, Sites,
Subnets, Transitions), each describing one of the core ele-
ments of the architecture. The database schema is listed in
Appendix B. An abstraction layer written in golang allows the
controller to interface with the database using high-level calls.
The abstraction layer makes use of transactional queries to
ensure consistency even in the event of errors. Furthermore, the
abstraction uses prepared statements for insertions, deletions
and retrievals of data. This protects against SQL-injections and
improves the speed of queries.
C. Authentication Token
Fig. 4: An overview of the modularized TP implementation.
Major usecases are also indicated with colored arrows.
versa. In this context, a SIG acts as a gateway between an
internal (legacy) network and an external (SCION) network.
Since TP is designed as a gateway that bridges LAN trafﬁc
over WAN—the underlying inter-domain routing protocol is
not relevant here—the functional aspects of TP meets with
what SIG provides. To be integrated with SIG, TP mediates
between the UNIX socket and SIG socket, and performs zone
transition authorization and veriﬁcation for all incoming/outgo-
ing packets. Figure 4 illustrates the implementation details of
the modularized TP design that consists of three main modules:
i) core module, ii) transition module, and iii) authentication
module.
Core Module. The core module is the main loop of TP. It
reads packets from the UNIX socket and redistributes them to
the corresponding interfaces. More precisely, when receiving
packets from the internal network, it retrieves metadata (further
illustrated in Appendix A) from the raw packet, and hands over
to the transition module. If the zone transition is authorized
(return = 1), the packet is then either forwarded back to the
internal network or, in case the given destination is in a remote
zone, once again handed over to the authentication module to
be prepared for secure transmission. For packets coming from
the external network, TP ﬁrst calls the authentication module
for veriﬁcation of the conveyed authentication token. Packets
with invalid tokens are simply discarded.
Transition Module. The main objective of this module is
to check the zone transition rules. The transition module
communicates with its controller to maintain a list of up-to-
date zone transition policies. To this end, it establishes a TLS
channel with the controller, downloads policies, and populates
the database. We implemented the transition module to support
different drop-in options using APIs.
•
•
•
No-Op: This is for a setup in which no inter-domain
zone transition is required, but only inter-domain zone
extensions.
Standard: This mode would perform an authorization
check for the requested zone transition based on the
source and destination IP addresses.
Firewall: If needed, the module could be instantiated
as a full-ﬂedged ﬁrewall.
Authentication Module. For inter-domain packet transmis-
sions, the authentication module issues an authentication token
for the packet. It (ideally) caches the ﬁrst-level keys prefetched
The MONDRIAN packet format follows the IP tunneling
conventions of encapsulating the original packet with a new
outer IP header that indicates the two tunnel endpoints as the
8
then compares them to the zone transition policies. The au-
thorization performance is therefore dependent on the lookup
time of the policy database.
Table I shows the benchmark results of database lookups
for different quantities of policies. Each benchmark ran over
two million iterations and kept the mean value. The autho-
rization check takes approximately 300 to 500 ns per packet,
which is a notable result considering: i) a lookup consists of
three tree searches, ii) the result is from a high-level language
implementation, and iii) the size of the test set is increased by
a factor of 1000. Interestingly, a lookup failure is commonly
24 to 31 % faster than a successful lookup. This implies that
abnormal packets with invalid zone transition requests can be
quickly discarded.
Key Derivation. We investigate the key derivation perfor-
mance. Recall that the key derivation proceeds differently for
sender and receiver (See §IV-C). The receiver directly derives
the ﬁrst and second-level key from the local secret, whereas the
sender-side key derivation comprises two steps: fetching the
ﬁrst-level key from the key table and deriving the second-level
key from the ﬁrst-level key. From a scalability perspective, we
increase the number of stored ﬁrst-level keys up to 100 K.
Table II shows the average key derivation time for the
benchmark tests (each number reported represents the average
of over a million trials). The time duration to obtain the ﬁrst-
level key at the source TP requires 154∼ 161 ns (key lookup),
while at the destination TP it requires 188∼ 197 ns (key
derivation). While key derivation can be optimized to require
only tens of nanoseconds [56], the high-level golang imple-