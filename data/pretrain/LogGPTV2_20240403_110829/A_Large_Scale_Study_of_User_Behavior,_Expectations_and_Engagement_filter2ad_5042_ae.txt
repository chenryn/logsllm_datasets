### Most Interesting Findings

Interestingly, the distribution of deny rates for participants with relatively high overall privacy sensitivity (scores > 1.0) is not uniform. A significant proportion, 29% (296 out of 1027), have deny rates lower than the population average of 16.7%, and this group appears as a concentration of users near the bottom middle right of the distribution. This discrepancy between high privacy scores (attitudes) and low deny rates (behavior) may indicate the well-known "privacy paradox" effect [16, 43]. However, permission decisions are highly contextual [28], and it is impossible to assess the privacy paradox without a complete understanding of the context leading to each decision.

Users with high privacy scores may still grant permissions if they carefully select their apps and have a good understanding of the permissions and their purposes. We hypothesize that among participants with high privacy scores, there may be more engaged users who are careful in their app selection and better understand the context. These engaged users might make context-specific permission choices. While a separate study would be needed to evaluate this hypothesis, we check if our data can offer any preliminary insights.

### Contextual Expectations and Privacy Scores

As described in Section 5.3.2, participants' expectations serve as a proxy for the context of a permission request, including both the user's perspective and the information provided by the app. We evaluate whether the install-time and run-time expectation distributions differ between participants with high (> 1.0) and low privacy scores using two separate Kolmogorov-Smirnov (K-S) tests, one for each type of expectation. In both tests, the null hypothesis is that the distributions are the same across the two privacy score groups.

For the install-time expectation, the K-S statistic (D) is 0.104 with a p-value of 0.02. For the run-time expectation, the D value is 0.12 with a p-value of 0.014. Based on these p-values, we reject the null hypothesis, indicating that the expectation distributions differ significantly between the two privacy score groups.

Participants with high privacy scores generally have a higher percentage of correctly expected permissions at install time (average 31.4%, median 26%) compared to those with low privacy scores (average 27.1%, median 18%). Additionally, participants with higher privacy scores report higher percentages (75%) of expected permissions at run-time compared to those with low privacy scores (69%). In summary, participants with higher privacy scores are more likely to have their (install and run-time) expectations match reality than those with lower privacy scores. These findings partially support our hypothesis that users with both high privacy scores and low deny rates may be more engaged and better understand the context.

### Limitations

Due to our participant recruitment method, which relies on online advertising, our study is biased towards users who interact with online ads. All participants were also willing to install an application that collects data about their smartphone usage, introducing unavoidable selection bias. As mentioned in Section 3, females were under-represented in our study. To assess demographic sample bias, we compared the age and educational attainment distributions of our US participants with 2019 US Census Bureau statistics. We found that younger people (77% of study participants are under 40 vs. 40% for all US residents) and those with lower educational attainment (78% of study participants have high school or less vs. 54% for all US residents) are over-represented in our group. This bias may be due to higher smartphone use among the younger population and the low monetary incentive ($10 USD) being more attractive to participants with lower educational attainment.

PrivaDroid cannot collect data on events that occurred before it was installed, so we do not see any permission decisions made with apps prior to the start of our study. This may under-count events caused by default apps or popular applications already installed on participants' phones. Both participant bias and blindness to pre-install events are unavoidable side effects of our recruitment and data collection methodologies. Additionally, 42% of participants joined the study after March 15, 2020, when social and economic measures due to the COVID-19 pandemic were in place, and we cannot conclusively determine the impact of these measures on this group.

### Conclusions

Our study confirms that some trends reported in [4] remain consistent: the aggregate denial rate hovers around 16-17%, Microphone is still the most frequently denied permission, and there is variation in deny rates across different permission types. Notable changes include a significant increase in the Calendar permission deny rate from 10% [4] to 21.7% today, and a decrease in the Phone permission deny rate from 19% to 12.6%.

Demographic analysis reveals interesting trends across countries, with two distinct clusters of countries having statistically similar deny rates. Some countries do not fit cleanly into either cluster. Our regression models confirm that nationality influences users' willingness to share personal data, specifically for Android apps and user behavior on personal devices. The study shows that users are less likely to deny permission requests when explanations are provided. Regression models demonstrate that this trend holds even when accounting for other factors (e.g., age, app, country, attitude). The average deny rate is reduced by half when an explanation is present (15% vs. 7%).

Expectations significantly influence permission decision-making. Participants deny permissions more often when an app asks for a permission they did not expect. This bias exists for both types of expectations (install-time and run-time) but is significantly stronger for run-time expectations, where the deny rate for unexpected permissions is double that of expected permissions. This corroborates prior work [48] on a larger scale and across multiple countries.

One key takeaway is that users are more likely to grant permission requests that are expected, suggesting that the permission system works when a request "makes sense." This indicates that the gap between users' desires to constrain applications and the reality is more due to a lack of understanding of the interplay between apps and permissions and the context of permission requests, rather than the permission mechanism itself (with the exception of temporary permissions, which our study showed have some benefit to users). Transparency features, such as Apple’s “Privacy Nutrition Labels” and Google Play’s Safety directive, may complement the current smartphone permissions system design. However, our results show that the effect of unexpected permissions at run-time is more pronounced than at install-time, suggesting that transparency features targeting only install-time permissions may not be as effective as those that are more dynamic and linked to specific permission types. Future research on the quality of explanations and how and when to use them would be beneficial for the proper adaptation of explanation labels.

### Acknowledgements

We thank the anonymous reviewers and our shepherd, Sven Bugiel, for their valuable feedback and suggestions. We also thank Nicolas Papernot, Adelin Travers, Beom Heyn Kim, Sukwon Oh, and Mariana D’Angelo for helping us check our translations. Kelly Hayward and Dubravka Burin assisted us with the administrative and reporting complexities of making hundreds of international payments from a public institution. Manya Sleeper and Micha Segeritz helped with the regression analysis. Financial support for this research was provided in part by the University of Toronto’s Connaught Fund, a Canada Research Chair, an NSERC USRA grant, and a Security and Privacy Research Award from Google.

### References

[References listed as in the original text]

This optimized version aims to enhance clarity, coherence, and professionalism while maintaining the original content and structure.