1
1
1
1
1
R
W
t
z
A
A
N
s
c
0
0
0
0
1
1
1
1
1
:
:
:
:
:
s
W
c
a
l
t
N
z
A
A
R
0
0
0
0
0
0
0
a
a
l
0
0
l
0
0
0
0
0
0
0
0
0
0
0
0
Figure 11: Comparing the prediction performance of metric- and classiﬁcation-based prediction algorithms.
s
t
n
e
c
i
f
f
i
e
o
C
l
t
a
o
T
 1
 0.8
 0.6
 0.4
 0.2
 0
Renren
Facebook
Youtube
1
4
7
10
14
Top N Metrics
Figure 12: The relationship between top similarity met-
rics and top SVM features, shown as the total normalized
SVM coefﬁcient of top N similarity metrics, N =1,2,...,14.
metrics and SVM features, i.e.
top similarity metrics are
also top features in SVM. For YouTube, the orders are less
consistent, except that Rescal always ranks ﬁrst.
Next, we study how top similarity metrics contribute to
SVM by comparing their feature coefﬁcients. Speciﬁcally,
for each graph we pick the top N similarity metrics and cal-
culate their total normalized SVM coefﬁcients, where N =
1, 2, ..., 14. Figure 12 presents the results for the large data
instance listed in Table 6 with the largest θ. Results of small
data instances and other values of θ are consistent and omit-
ted for brevity.
We see that for Renren and Facebook the similarity met-
rics make similar contributions to the machine learning pro-
cess. The top 6 similarity metrics have a slightly higher
weight than the rest. For YouTube, the top ﬁrst similarity
metric (Rescal) and a lower ranked metric (Katz) are the key
contributors while the rest make similar contributions.
Together, these results suggest that in general the metric-
based and classiﬁer-based methods share similar preferences
on similarity metrics. But the classiﬁer-based methods can
combine prediction power of multiple metrics to achieve a
higher accuracy and robustness across different datasets. Fi-
nally, the difference between Renren/Facebook and YouTube
aligns with our earlier observation that as a subscription net-
work YouTube’s link prediction pattern differs from those of
Renren and Facebook.
6.
IMPROVING LINK PREDICTION
While our results show that today’s prediction algorithms
signiﬁcantly outperform random prediction, they are still lim-
ited in their prediction accuracy. A fundamental contribut-
ing factor is that current prediction algorithms take a purely
static approach to network analysis, and do not take in ac-
count temporal patterns exhibited by an evolving network.
While recent studies seek to extend link prediction to sup-
port dynamic networks, they either do not scale [36], or are
restricted to single model or metric [40] where performance
vary signiﬁcantly across datasets.
In this section, we improve existing link prediction algo-
rithms by integrating them with dynamic network analysis.
Speciﬁcally, we identify key patterns on network dynamics,
and use them to build temporal ﬁlters that drastically reduce
the search space for link prediction. Our proposed ﬁlters
effectively augment existing link prediction algorithms, pro-
viding a signiﬁcant boost in prediction accuracy. This is even
true for algorithms that were already designed to capture net-
work dynamics, e.g. [10].
6.1 Temporal Properties on Edge Creation
Using our dynamic OSN datasets, we investigate how dif-
ferent properties of network dynamics affect edge creation.
These include node activeness, neighborhood structure evo-
lution, neighborhood activeness, and arrival of common neigh-
bor. We conclude that node activity and arrival of common
neighbor are the key factors for all three networks, and thus
we omit analysis for other explorations here. We have con-
sistent observations across different snapshots and over dif-
ferent networks, and due to space limitation we only show
ﬁgures for Renren snapshot at 55M edges in this subsection.
We will brieﬂy summarize our observations for other net-
works in the next subsection.
Intuitively, a node that has recently
Node Activeness.
actively created edges is more likely to create edges in the
near future. We validate this by measuring node activity on
both positive and negative node pairs (i.e. those with edges
and those without). For each node pair, we mark the node
with longer idle time (deﬁned in §4.4) as the inactive node
and the other as the active node. We measure activity by
the idle time of the active node, the idle time of the inactive
node, and the number of edges created by the active node in
the past d days.
We found that for positive node pairs, i.e. those who will
connect in the prediction timeframe, the idle times of both
active and inactive nodes are signiﬁcantly smaller. Figure 13
plots the CDF of the active node’s idle time for the Renren
snapshot at 55M edges. More than 90% of positive node
pairs have <3 days idle time while only 40% of negative
pairs do so. This 3-day threshold can effectively distinguish
positive and negative node pairs. Similar patterns can be
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Positive
Negative
 5
 10
 15
 20
 25
 30
Idle Time (Days)
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Negative
Positive
 5
 10
 15
 20
New Edge Created in 7 days
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Positive
Negative
 5
 10
 15
 20
 25
 30
CN Time Gap (Days)
Figure 13: CDF of active node idle time
in a Renren snapshot.
Figure 14: CDF of new edges created in
the past 7 days by a node in a Renren
snapshot.
Figure 15: CDF of CN time gap of pos-
itive and negative node pairs in a Ren-
ren snapshot.
found when comparing the inactive nodes’ idle times, with a
20-day idle threshold.
Furthermore, active nodes in positive node pairs tend to
create more edges in a recent time. Using the same Renren
snapshot, Figure 14 shows the CDF of new edges in the past
week for both positive and negative sets. For more than 60%
of positive node pairs, the active node creates more than 3
edges while only 20% of negative node pairs do so. This
“3-edge in past 7 days” can also be used to help identify
potential new links.
We show in §4 that
Arrival of Common Neighbor.
most similarity metrics focus on predicting edge formation
between 2-hop neighbors. For these, the recent arrivals of
common neighbors can often trigger the completion of a
triad [46] and thus be critical in predicting edges. We test
this hypothesis by measuring, for each node pair, the gap
between the most recent time when they connect to a com-
mon neighbor and the current snapshot time, referred to as
the CN time gap. Our results show that the CN time gap of
positive set is much smaller than that of negative set. Fig-
ure 15 shows the result for the same Renren snapshot, where
more than 60% of positive pairs create their last common
neighbors in the last 10 days, while 20% of negative pairs
do so.
6.2 Temporal Filtering
We propose to use these observations, which are consis-
tent across networks, to develop “temporal ﬁlters” to dras-
tically reduce the search space of new links by ﬁltering out
node pairs that are unlikely to create edges. Speciﬁcally, we
remove any potential node pair from the candidate list if it
fails to meet any of the following four criteria:
• Idle time of active nodes < dact days.
• Idle time of inactive nodes < dinact days.
• d-day new edges ≥ Enew.
• CN time gap < dCN . 5
Our threshold values are listed in Table 7 , which hold
across different snapshots for each corresponding network.
While each parameter is network speciﬁc, the methodology
to discover them is general.
5For node pairs beyond 2 hops, we do not apply this crite-
rion.
Graph
Facebook
YouTube
Renren
dinact
Node Idle Time
dact
15
3
3
40
30
20
Enew
d-day New Edges
d
21
7
7
2
3
3
dCN
40
20
10
Table 7: Parameters of the temporal ﬁlters.
We now present
Prediction Accuracy after Filtering.
the improvement in link prediction accuracy (in terms of ac-
curacy ratio) after adding temporal ﬁltering. We experiment
with the same data instances used to evaluate classiﬁcation-
based algorithms (see Table 6) and present the result for the
large instance. Results from the smaller instance show even
more signiﬁcant beneﬁts and are omitted for brevity.
Table 8 lists the normalized improvement from applying
the ﬁlter, i.e. the accuracy ratio of prediction with ﬁltering
divided by the accuracy ratio of prediction without ﬁlters.
The improvement is quite signiﬁcant for many cases, and
somewhat incremental for others. For classiﬁcation-based
algorithms, our ﬁltering raises the accuracy by 10%∼120%.
For metric-based algorithms, the gain can be as much as a
factor of 15.7.
We observe that ﬁltering affects certain algorithms more
than others. For metric-based algorithms, applying temporal
ﬁlters changes the “best” prediction algorithm. For example
in Facebook, JC was the weakest metric before the ﬁlters,
but becomes the best metric after ﬁltering. This is because
temporal ﬁlters effectively identify and remove the unlikely-
to-connect node pairs, i.e.
inactive, low-degree nodes that
JC is unable to identify.
6.3 Comparing to Other Temporal Meth-
ods
Recent works have exploited temporal information to im-
prove prediction accuracy [8, 10, 40]. We compare our ﬁl-
tering design with the time series based prediction [10], a
popular method that can also scale to our network datasets.
For each potential node pair, this method computes its sim-
ilarity metrics at multiple past time points, and aggregates
these scores to produce a ﬁnal score of the pair. We imple-
ment two aggregation approaches, Moving Average (MA)
and Linear Regression (LR), shown by [10] as the two best
approaches, and perform aggregation on equally spaced past
time points (the space equals to the number of days between
Network
Renren
Facebook
YouTube
JC
2.2
5.7
-
BCN BAA BRA LP
9.7
5.8
1.2
1.3
1.2
1.2
4.1
1.2
1.2
2.3
1.4
1.2
LRW PPR
1.7
3.2
1.3
5.3
3.1
1.1
SP
14.9
4.4
15.7
Katz Rescal
1.5
1.3
1.5
2.4
1.2
1.1
PA
-
2.1
1.2
1:1
1.9
1.3
2.2
1:10
1.9
1.4
2.2
1:100
1.8
1.5
2
1:1000
1:10000
1.8
1.3
1.2
1.8*
1.2
1.1
Table 8: Ratio of accuracy values after ﬁltering vs. before ﬁltering for all metric-based and classiﬁcation methods. Bold
value in each row is the maximum improvement for that network; “-” means the accuracy before ﬁltering is “0”. *Ratio
in Renren is 1:5000.
Renren
Time Model w/ filter
Basic w/ filter
Time Model w/o filter
Basic w/o filter
o
i
t
a
R
y
c