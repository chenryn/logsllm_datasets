### Data Locality and Fairness in Task Execution

Existing systems aim to enhance data locality for input tasks and ensure fairness [37, 58], while also minimizing outliers in task execution [16, 19, 61]. Although these systems optimize task placement, they do not account for network contentions, which are less significant within a single data center (DC). Additionally, they do not move data to alleviate potential network bottlenecks [33]. Iridium complements approximation techniques [15, 18].

### Optimizing Communication Patterns

Flow schedulers like D3 [55], PDQ [35], DeTail [62], and D2TCP [51] focus on improving flow completion times or meeting deadlines. However, these schedulers operate within a single DC and do not address complex communication patterns. Network flow schedulers such as Orchestra [25], Varys [26], and Baraat [30] optimize the completion time of coflows, which are collections of flows. Nevertheless, because the endpoints of the coflows are fixed (e.g., source and destination specified by the location of input data and tasks), these schedulers cannot effectively manage network bottlenecks.

### WAN Bandwidth Usage

Figure 8 illustrates the WAN Bandwidth Usage knob, B. The MinBW scheme optimizes for WAN bandwidth usage. Even with the same WAN usage as MinBW (B = 1), Iridium significantly improves query response times. MinBW, on the other hand, slows down queries compared to the in-place baseline.

With a small increase in B to 1.3 (i.e., 30% higher WAN usage than MinBW), Iridium achieves query speedups of 59% and 74%, which is approximately 90% of the gains without any WAN usage budget (64% and 80%). This demonstrates that Iridium effectively uses the bandwidth budget to balance WAN usage and query response times. It also indicates that over long periods, the arrival of high-value and low-value datasets overlaps sufficiently in the workload, which is crucial for the effectiveness of our greedy budgeted scheme.

Even at B = 1 (i.e., the same WAN bandwidth usage as MinBW), Iridium's gains in query response time are notable. Importantly, MinBW results in an increase in query response time (negative gains) compared to the in-place baseline. While MinBW's query gains are positive compared to the centralized baseline, Iridium's query gains are twice as good for the same WAN usage.

### Discussion and Limitations

#### Compute and Storage Constraints
Our work did not consider limitations in compute and storage at the sites, assuming this was reasonable for data centers. However, as geo-distributed analytics moves to edge clusters, compute and storage constraints become more relevant. In such scenarios, comprehensive consideration of compute and storage capacity is necessary for task and data placement. A simple approach could involve adding a constraint to the task placement formulation: \( r_i \cdot D \leq C_i \), where \( D \) is the compute required by the stage and \( C_i \) is the capacity. In our data placement heuristic, if a site is running out of storage, we will not consider moves into that site.

#### WAN Topologies
How do our heuristics change when the core network connecting the sites is not congestion-free? One approach is to model pairwise connectivity between sites, say \( B_{ij} \) as the available bandwidth from site \( i \) to site \( j \). To optimize task placement, we formulate an LP to determine the \( r_i \)'s, similar to ยง3.1. Given a distribution of intermediate data \( S_i \), let \( T_{ij}(r_j) \) be the transfer time from site \( i \) to site \( j \).

### Scheduling on the WAN

There has been extensive work on optimizing WAN transfers, including tuning ECMP weights [32] and adapting allocations across pre-established tunnels [31, 39]. Both Google [38] and Microsoft [36] have published details on their production WAN networks. These efforts improve the efficiency of the WAN by scheduling network flows within it. In contrast, Iridium optimizes end-to-end application performance by placing data and tasks to reduce load on congested WAN links. Other works optimize data placement to improve WAN latencies and utilization [41, 50]. Iridium handles more complex communication patterns, such as shuffles, which require coordination of many flows across multiple sites. Most of the above methods can be used to improve individual WAN transfers in Iridium.

### Conclusion

Cloud organizations are deploying data centers and edge clusters worldwide. These sites, both first-party and third-party, continuously produce large quantities of data. The results from analyzing this geo-distributed data are used by real-time systems and data analysts. We developed Iridium, a system that minimizes the response times of geo-distributed analytics queries. By carefully considering the heterogeneous link bandwidths of the WAN in the placement of data and tasks, Iridium improves query response times in workloads derived from analytics clusters of Bing Edge, Facebook, and Conviva by 3x to 19x. However, our approach is greedy and offers only a partial solution to optimizing complex DAGs of tasks, both of which we aim to improve.

### Acknowledgments

We would like to thank Kaifei Chen, Radhika Mittal, and Shivaram Venkataraman for their feedback on the draft. We also appreciate the comments from our shepherd Mohammad Alizadeh and the anonymous reviewers. This work was partially supported by NSF grants CNS-1302041, CNS-1330308, and CNS-1345249.

### References

[References listed as provided, with no changes needed.]

This optimized version enhances clarity, coherence, and professionalism, making the text more accessible and informative.