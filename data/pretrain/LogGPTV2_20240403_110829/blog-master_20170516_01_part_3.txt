```          
写入性能基本上取决于tsvector字段的元素个数，散列程度，本例每条记录约40个元素。如果元素个数下降一半，性能将提升一倍左右。          
```        
postgres=# select array_length(tsvector_to_array(content),1) from bptest1 limit 10;        
 array_length         
--------------        
           40        
           37        
           40        
           45        
           35        
           42        
           38        
           46        
           30        
           40        
(10 rows)        
```        
#### 评估每秒构建了多少个索引条目        
1\. 全文检索索引条目        
每条记录约40个元素，当插入的tps=6.5万时，构建的全文检索条目数约 260万/s。        
```        
65000*40 = 2600000        
```        
2\. uid索引条目，较小，忽略不计。        
3\. ts索引条目，使用BRIN块级索引，忽略不计。        
性能影响最大，资源消耗最多的就是全文检索索引条目的构建。        
## 查询性能      
举例      
```      
postgres=# \dt+ bptest1      
                      List of relations      
 Schema |  Name   | Type  |  Owner   |  Size   | Description       
--------+---------+-------+----------+---------+-------------      
 public | bptest1 | table | postgres | 1689 MB |       
(1 row)      
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from bptest1 where ts between 1494999617 and 1495999617 and content @@ to_tsquery ('english','abc');      
                                                              QUERY PLAN                                                                    
--------------------------------------------------------------------------------------------------------------------------------------      
 Bitmap Heap Scan on public.bptest1  (cost=175.95..23691.41 rows=20015 width=811) (actual time=7.017..23.376 rows=19755 loops=1)      
   Output: uid, ts, content      
   Recheck Cond: (bptest1.content @@ '''abc'''::tsquery)      
   Filter: ((bptest1.ts >= 1494999617) AND (bptest1.ts   Bitmap Index Scan on bptest1_content_idx  (cost=0.00..170.94 rows=20019 width=0) (actual time=3.811..3.811 rows=19755 loops=1)      
         Index Cond: (bptest1.content @@ '''abc'''::tsquery)      
         Buffers: shared hit=15      
 Planning time: 0.097 ms      
 Execution time: 24.517 ms      
(11 rows)       
postgres=# explain (analyze,verbose,timing,costs,buffers) select * from bptest1 where ts between 1494999617 and 1495999617 and content @@ to_tsquery ('english','abc & bc');      
                                                            QUERY PLAN                                                                   
-----------------------------------------------------------------------------------------------------------------------------------      
 Bitmap Heap Scan on public.bptest1  (cost=36.27..2598.42 rows=1996 width=811) (actual time=4.577..6.711 rows=2125 loops=1)      
   Output: uid, ts, content      
   Recheck Cond: (bptest1.content @@ '''abc'' & ''bc'''::tsquery)      
   Filter: ((bptest1.ts >= 1494999617) AND (bptest1.ts   Bitmap Index Scan on bptest1_content_idx  (cost=0.00..35.77 rows=1997 width=0) (actual time=4.291..4.291 rows=2125 loops=1)      
         Index Cond: (bptest1.content @@ '''abc'' & ''bc'''::tsquery)      
         Buffers: shared hit=123      
 Planning time: 0.125 ms      
 Execution time: 6.849 ms      
(11 rows)      
```      
## 纯SSD fsync=on 写入性能      
1\. 写入TPS      
7万/s ，构建的全文检索条目数约 280万/s。        
性能比较平稳。      
## 纯SATA+SSD bcache fsync=off 写入性能      
1\. 写入TPS      
7.5万/s ，构建的全文检索条目数约 300万/s。        
性能比较平稳。      
## 小结          
1\. 查询聚合          
由于日志数据打散分布在多个集群，多个表内，建议使用plproxy进行查询的聚合。          
参考          
[《A Smart PostgreSQL extension plproxy 2.2 practices》](../201110/20111025_01.md)            
[《阿里云ApsaraDB RDS for PostgreSQL 最佳实践 - 4 水平分库 之 节点扩展》](../201512/20151220_04.md)            
[《阿里云ApsaraDB RDS for PostgreSQL 最佳实践 - 3 水平分库 vs 单机 性能》](../201512/20151220_03.md)            
[《阿里云ApsaraDB RDS for PostgreSQL 最佳实践 - 2 教你RDS PG的水平分库》](../201512/20151220_02.md)            
2\. 写入分片          
写入分片，可以在业务层完成，随机打散写入。          
实际应用时，可以根据需要，切分成更多的分区。          
3\. 主要的开销是postgres的开销，如果需要详细的分析，建议重新编译postgres          
4\. gin索引的优化          
https://www.postgresql.org/docs/9.6/static/sql-createindex.html          
```          
GIN indexes accept different parameters:          
1. fastupdate          
This setting controls usage of the fast update technique described in Section 63.4.1.           
It is a Boolean parameter: ON enables fast update, OFF disables it.           
(Alternative spellings of ON and OFF are allowed as described in Section 19.1.) The default is ON.          
Note: Turning fastupdate off via ALTER INDEX prevents future insertions from going into the list of pending index entries,           
but does not in itself flush previous entries.           
You might want to VACUUM the table or call gin_clean_pending_list function afterward to ensure the pending list is emptied.          
2. gin_pending_list_limit          
Custom gin_pending_list_limit parameter.           
This value is specified in kilobytes.          
```          
gin_pending_list_limit的目的是延迟合并，因为一条记录中可能涉及较多的GIN KEY，如果实时更新，GIN索引的写入量会非常大，性能受到影响。          
本例gin_pending_list_limit设置为2MB，tps比较平缓，如果设置过大，当CPU资源不足时，抖动会比较严重。          
用户可以根据实际测试，设置合理的gin_pending_list_limit值。          
5\. 如果把PostgreSQL完全当成索引库使用，并且允许数据丢失，那么可以使用fsync=off的开关，（检查点fsync对IO的影响比较大，本例使用的是SATA盘，将会导致较大的性能抖动）。        
```      
postgresql.auto.conf      
fsync = off      
zero_damaged_pages = on        
```      
如果有ha的话，丢失的风险又会更小。（但是服务器CRASH后，需要重建备库，这么大的量，还是挺恐怖的。）        
建议用更多的数据库实例，每个实例的大小可控（例如 < 2TB），重建的时间也相对可控。       
6\. 为了达到更好的响应速度（RT），建议明细和索引分开存放，明细要求写入RT低，索引可以存在一定的延迟。 并且索引与明细数据的可靠性要求也不一样。      
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")