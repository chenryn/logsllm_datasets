prevents the document from reading or modifying the content of
the loaded object.
2.3 Secure Sockets Layer (SSL) and X.509
certiﬁcates
The Secure Sockets Layer (SSL) and its successor, Transport
Layer Security (TLS), are cryptographic protocols for establishing
end-to-end secure channels for Internet trafﬁc [13, 71]. HTTP over
SSL is also known as HTTPS.
SSL uses X.509 certiﬁcates [26] to identify the server partici-
pating in the SSL connection. An X.509 certiﬁcate contains the
server’s public key, the domain name of the web site (speciﬁed in
the CN subﬁeld of the certiﬁcate), the public key of the issuer of the
certiﬁcate, the time period for which the certiﬁcate is valid, and the
issuer’s signature over these ﬁelds. The private key corresponding
to a X.509 certiﬁcate can be used to sign another certiﬁcate, and so
on, creating a chain of trust. The root of this trust chain is typically
a certiﬁcate authority (CA); web browsers ship with the certiﬁcates
of some CAs which are deemed to be trusted.
When the client’s web browser makes a connection to an SSL en-
abled web server over HTTPS, the browser must verify the server’s
certiﬁcate is valid. This involves numerous checks, but at a high
level the browser must:
• Verify that every certiﬁcate in the chain has a valid signature
from its predecessor, using the public key of the predecessor,
and that the last certiﬁcate in the chain is from a trusted CA.
• Verify that the CN ﬁeld of the ﬁrst certiﬁcate in the chain
matches the domain name of the web site the browser in-
tended to visit.
• Verify every certiﬁcate has not expired.
If any of these checks fail, the browser warns the user and asks
the user if it is safe to continue. If the user chooses, the user may
permit the SSL connection to continue even though any or all of
these checks have failed. The reason is to ensure compatibility with
misconﬁgured certiﬁcates and SSL servers; a periodic survey by
Security Space shows that approximately 63% of SSL certiﬁcates
have such problems [65]. Also, this behavior by browsers allows
web sites to use self-signed certiﬁcates if they choose, instead of
paying a CA for a certiﬁcate. Unfortunately, asking users whether
to continue anyway in such cases is a serious security vulnerability.
Researchers have shown that users routinely ignore such security
warnings and just click “OK” [5, 10, 77]. In fact, users have be-
come so ambivalent to security warnings, one vendor has developed
“mouse auto-clicker” software, aptly titled “Press the Freakin But-
ton” [58], to automatically click through dialogs like these. Instead
of a dialog box, IE 7.0 uses a full page warning within the browser
window offering similar options (i.e., ignore and continue, or can-
cel connection). Unfortunately, studies suggest that users will ig-
nore a full page warning as well [64]. Accordingly, we consider a
certiﬁcate that does not generate any warnings as valid. Otherwise,
we consider it invalid.
After the browser validates the server’s certiﬁcate, it participates
in a cryptographic protocol with the server where: 1) the server
proves knowledge of the private key corresponding to the public
key in the certiﬁcate, and 2) they negotiate a session key to encrypt
and authenticate subsequent trafﬁc between them. Unlike the cer-
tiﬁcate validation step, if there are any errors in this protocol, the
browser closes the connection with no chance of user override.
Client-side SSL. The most common usage of SSL is for server au-
thentication, but in the SSL speciﬁcation, a server can also request
client-side authentication, where the client also presents an X.509
certiﬁcate and proves knowledge of the corresponding private key.
Using client-side SSL, servers can identify a user with her SSL
public key and authenticate her using the SSL protocol.
2.4 Assumptions
We assume that attackers do not have access to the target site’s
server machines or any secrets, such as private keys, contained
thereon. We also assume that many users will ignore certiﬁcate
warnings, as researchers have shown that users routinely ignore and
dismiss such warnings [5, 10, 64, 77].
3. DYNAMIC PHARMING ATTACKS
In this section, we show a new attack against web authentication
we call dynamic pharming.
In a simple, static pharming attack,
the adversary arranges for the victim’s DNS queries for the target
domain to always return the adversary’s IP address. In contrast, in
a dynamic pharming attack, the adversary causes DNS queries to
return either the legitimate server’s IP or its own IP, depending on
the situation.
We show how an adversary can use dynamic pharming to in-
fect the victim’s browser with malicious Javascript and use this
Javascript to hijack the victim’s session with the target domain’s
legitimate server. Dynamic pharming enables an adversary to com-
promise all known authentication schemes for existing browsers,
including passwords, authentication cookies, and client-side SSL.
In addition, the adversary can eavesdrop on sensitive content, forge
transactions, sniff secondary passwords, and so on.
We now describe how dynamic pharming works.
Suppose
the pharmer can control the results of DNS queries for www.
vanguard.com, and users authenticate themselves to www.
vanguard.com using a strong authentication mechanism, say
client-side SSL. We assume users’ machines have been initial-
ized with client-side SSL certiﬁcates, and www.vanguard.com
knows the public keys of its users’ certiﬁcates.
First, the pharmer initializes the DNS entry for www.vanguard.
com to the pharmer’s IP address, say 6.6.6.6. The pharmer also
indicates in the DNS record that requesters should not cache this
result, i.e., it sets the TTL=0. Now suppose a user Alice visits
https://www.vanguard.com/index.html with the inten-
tion of authenticating herself. The user’s browser will attempt to
establish an SSL connection, requiring the pharmer to present an
X.509 certiﬁcate. If the server certiﬁcate is not signed by one of the
trusted CAs in the browser or the certiﬁcate’s CN does not match
the server’s domain (i.e., www.vanguard.com), the browser will
warn the user and ask her if it is safe to proceed.
If the user
heeds the warning and answers “no”, the browser will cancel the
connection and the attack fails. If the user accepts the pharmer’s
certiﬁcate—and there is substantial evidence that the user would
(see Section 2.3)—Alice’s browser will establish an SSL connec-
tion to the pharmer at 6.6.6.6 and request index.html.
In response, the pharmer returns a “trojan” index.html doc-
ument. The purpose of this trojan document is to monitor and in-
ﬂuence Alice’s subsequent interactions with the legitimate www.
vanguard.com. The trojan document has the following general
structure:
After the pharmer returns the trojan document to Alice, it up-
dates the DNS entry for www.vanguard.com to the IP address
of the legitimate server for www.vanguard.com, say 1.2.3.4.
This forces the browser to load the legitimate https://www.
vanguard.com/index.html document into the 
and display it to the user. 1 Since this request is over SSL, the
legitimate server for www.vanguard.com will request client au-
thentication, and the user’s browser will authenticate her using her
private key and certiﬁcate.2
After authentication completes, the malicious Javascript in the
outer document takes control and monitors the user’s interactions in
the  with the legitimate server for www.vanguard.
com. Since the outer document and the  both have the
same domain (www.vanguard.com) and same protocol (https),
the SOP will allow the malicious Javascript running in the outer
document to access the content in the . The trojan ef-
fectively hijacks control of Alice’s session – it can eavesdrop on
sensitive content, forge transactions, sniff secondary passwords,
etc. We show an example of a dynamic pharming attack in Fig-
ure 1.
3.1 Defeating DNS pinning
One complication to mounting this attack is web browsers’ use of
DNS pinning. With DNS pinning, a web browser caches the result
of a DNS query for a ﬁxed period of time, regardless of the DNS
entry’s speciﬁed lifetime. Browsers implement DNS pinning to de-
fend against variants of the “Princeton attack” [22], also known as
DNS rebinding attacks. In the “Princeton attack”, a malicious web
server ﬁrst lures a victim who resides within a ﬁrewalled network
containing privileged web servers. We assume these servers are ac-
cessible only to machines behind the ﬁrewall. After the victim con-
nects to the malicious server, the adversary changes its DNS entry
to the IP address of a sensitive web server located on the victim’s
internal network. The SOP restricts malicious code from accessing
other domains, but since the adversary’s domain now resolves to
an internal IP address, this attack enables Javascript served by the
adversary to access internal web servers.
DNS pinning poses a problem for dynamic pharming attacks be-
cause once a browser resolves a domain name using DNS, it will
continue to use the IP address and ignore any subsequent changes
the pharmer makes in the DNS system. However, since DNS pin-
ning “breaks the web” in certain scenarios, e.g., dual homed IPv6-
IPv4 servers, dynamic DNS, and automatic failover, browsers im-
plementors have recently relaxed their DNS pinning policies.
As a result, Martin Johns discovered a technique for circumvent-
ing DNS pinning [32]. Johns discovered that a pharmer can force
a victim to renew its DNS entry for a given domain on demand by
rejecting connections from the victim, e.g., by sending an ICMP
“host not reachable” message in response to subsequent attempts
to connect to the server. The browser reacts by refreshing its DNS
entry for the domain.
In the basic dynamic pharming attack, we exploit Johns’s tech-
nique. After the pharmer delivers the trojan document to the user,
1Iframes are HTML elements which enable embedded documents.
To prevent inﬁnite recursion, most browsers disallow nesting where
the URL of the framed document is the same as an ancestor. To
address this issue, the attack could redirect the victim’s ﬁrst re-
quest to https://www.vanguard.com/index2.html or
arrange so that the legitimate home page from www.vanguard.
com loads in a separate window.
2The authentication process could be more complicated, say with a
supplementary password or explicit login button, but the presence
of any additional login mechanisms does not affect our attack.
*+#
*+#(cid:27)(cid:4)(cid:7)(cid:12)(cid:21)(cid:4)(cid:19)(cid:8)(cid:27)(cid:13)(cid:11)(cid:5)(cid:4)(cid:6)(cid:7)(cid:4)0(cid:8) (cid:31)’(cid:27)
(cid:16)(cid:16)(cid:16)(cid:17)(cid:18)(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)(cid:17)(cid:9)(cid:23)(cid:6)
)(cid:17))(cid:17))(cid:17))
*+#(cid:27)(cid:4)(cid:7)(cid:12)(cid:21)(cid:4)(cid:19)(cid:8)(cid:27)%(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)0(cid:8)(cid:27)(cid:31)’(cid:27)
(cid:16)(cid:16)(cid:16)(cid:17)(cid:18)(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)(cid:17)(cid:9)(cid:23)(cid:6)
,(cid:17)-(cid:17).(cid:17)/
1
4
(cid:11)(cid:12)(cid:12)(cid:13)(cid:8)(cid:14)(cid:15)(cid:15)(cid:16)(cid:16)(cid:16)(cid:17)(cid:18)(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)(cid:17)(cid:9)(cid:23)(cid:6)(cid:15)(cid:2)(cid:19)(cid:22)(cid:7)(cid:24)(cid:17)(cid:11)(cid:12)(cid:6)(cid:25)
(cid:1)(cid:8)(cid:9)(cid:4)(cid:2)(cid:13)(cid:12)(cid:26)(cid:27)(cid:28)(cid:29)(cid:30)(cid:31) (cid:31)!"#(cid:27)$(cid:29)%(cid:29)# &(cid:31)’((cid:27)(cid:1)(cid:15)(cid:8)(cid:9)(cid:4)(cid:2)(cid:13)(cid:12)(cid:26)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7) (cid:8)(cid:4)(cid:9)(cid:10)(cid:11)(cid:12)(cid:12)(cid:13)(cid:8)(cid:14)(cid:15)(cid:15)(cid:16)(cid:16)(cid:16)(cid:17)(cid:18)(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)(cid:17)(cid:9)(cid:23)(cid:6)(cid:15)(cid:2)(cid:19)(cid:22)(cid:7)(cid:24)(cid:17)(cid:11)(cid:12)(cid:6)(cid:25)(cid:26)
3
’(cid:11)(cid:5)(cid:4)(cid:6)(cid:7)(cid:4) (cid:21)(cid:13)(cid:22)(cid:5)(cid:12)(cid:7)(cid:8)(cid:27)*+#
(cid:7)(cid:19)(cid:12)(cid:4)6(cid:27)(cid:3)(cid:23)(cid:4)(cid:27)%(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)
(cid:16)(cid:16)(cid:16)(cid:17)(cid:18)(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)(cid:17)(cid:9)(cid:23)(cid:6)
,(cid:17)-(cid:17).(cid:17)/
)(cid:17))(cid:17))(cid:17))
,(cid:17)-(cid:17).(cid:17)/
%(cid:5)(cid:19)(cid:20)(cid:21)(cid:5)(cid:4)(cid:22)0(cid:8)
(cid:4)(cid:7)(cid:5)(cid:25)(cid:27)(cid:8)(cid:7)(cid:4)(cid:18)(cid:7)(cid:4)
(cid:23) 2 (cid:5)
(cid:4) (cid:27)(cid:12) (cid:4)
(cid:7)
(cid:16) (cid:8)
2
(cid:23)
(cid:4)
(cid:4) (cid:8) (cid:27) 1
(cid:7)
(cid:7) (cid:25)(cid:2) (cid:18)
(cid:22)
(cid:4)
(cid:4) (cid:6) (cid:7)
(cid:5)
(cid:11)
’
(cid:4)(cid:2) (cid:13) (cid:12)
(cid:9)
(cid:8)
(cid:5)
(cid:18)
(cid:19) $ (cid:5)
6
((cid:4)(cid:23)2(cid:5)(cid:19)(cid:27)$(cid:5)(cid:18)(cid:5)(cid:8)(cid:9)(cid:4)(cid:2)(cid:13)(cid:12)
(cid:11)(cid:2)2(cid:5)(cid:9)5(cid:8)(cid:27)(cid:8)(cid:7)(cid:8)(cid:8)(cid:2)(cid:23)(cid:19)
(cid:16)(cid:2)(cid:12)(cid:11)(cid:27)(cid:4)(cid:7)(cid:5)(cid:25)(cid:27)(cid:8)(cid:7)(cid:4)(cid:18)(cid:7)(cid:4)
(cid:23) (cid:6)
(cid:5) (cid:12) (cid:7)
(cid:8)
(cid:7) (cid:27)(cid:3) (cid:4)
(cid:12)(cid:2) (cid:9)
(cid:19)
(cid:20)
(cid:7)
(cid:5)
(cid:11)
(cid:20) (cid:2) (cid:19) (cid:27) (cid:13)
(cid:21)
(cid:4) (cid:27) (cid:5)
(cid:12)
5
(cid:8) (cid:12) (cid:8) (cid:27)(cid:25) (cid:23)
(cid:8)
(cid:22) (cid:27) (cid:21)
(cid:7)
(cid:7)
(cid:19)
(cid:21)
4
(cid:4) (cid:27) (cid:5)
(cid:7)
(cid:7)
(cid:4) (cid:27) (cid:4)
(cid:18)
(cid:4)
(cid:7)
(cid:7)
(cid:16) (cid:8)
(cid:5) (cid:25)(cid:27) (cid:8)
3
(cid:23)
(cid:7)
(cid:4)
(cid:4)
(1) Initially, the pharmer arranges for the
Figure 1: An example of a dynamic pharming attack against www.vanguard.com.
victim’s DNS queries for www.vanguard.com to resolve to the pharmer’s IP address, 6.6.6.6.
(2) Then, when the victim vis-
its www.vanguard.com, the pharmer returns a trojan document containing malicious Javascript and a iframe referencing Van-
guard’s home page. (3) The pharmer then updates the DNS entry for www.vanguard.com to the IP address of Vanguard’s legiti-
mate server and denies subsequent connections from the victim. (4) This causes the victim’s browser to renew its DNS entry for