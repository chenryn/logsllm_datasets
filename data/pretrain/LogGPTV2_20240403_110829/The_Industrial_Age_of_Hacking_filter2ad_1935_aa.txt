# The Industrial Age of Hacking

## Authors
- Timothy Nosco, United States Army
- Jared Ziegler, National Security Agency
- Zechariah Clark, United States Navy
- Davy Marrero, United States Navy
- Todd Finkler, United States Air Force
- Andrew Barbarello, United States Navy
- W. Michael Petullo, United States Army

### Abstract
The hacker community often exhibits a cognitive bias towards selecting a specific piece of software and investing significant human resources into finding bugs, even without prior indications of success. We term this approach "depth-first search" and propose an alternative: "breadth-first search." In the breadth-first strategy, minimal human effort is used to enable automated analysis on a wide range of targets before committing additional time and resources to any particular one. This paper presents a repeatable human study that leverages teams with varying skill levels while maximizing the use of automation. Our goal is to develop a process that effectively finds bugs, has a clear plan for team growth, coaching, and efficient resource use, and supports measurable, incremental progress. We derive an assembly-line process that improves upon what was once intricate, manual work. Our findings suggest that the breadth-first approach enhances the effectiveness of teams.

### 1. Introduction
Can we build a better vulnerability discovery process? Many researchers have proposed tools that aim to aid human work, including symbolic execution, fuzzing, taint tracing, and emulation. These techniques automate bug finding by conducting a search over software states with minimal human intervention. However, finding vulnerabilities at scale remains challenging, partly due to the human effort required to set up and manage these automated tools.

Our work focuses on human processes that build on a foundation of automation. We emphasize autonomous technologies because they hold great promise for scalability. We propose a minor modification to Votipka’s process [40] by introducing a deliberate software selection step called "targeting." We encourage novice hackers to perform a breadth-first search of potential software targets, accomplishing only essential preliminary tasks that allow for automated analysis. More experienced hackers then conduct a deeper, more costly analysis of select software only after novices have tried and failed with automation. This approach ensures that the most experienced practitioners focus on hard problems, while less experienced hackers generate useful artifacts for advanced analysis. Due to the volume of targets, all hackers can select software suitable for their skill level, and team members have a clear path for knowledge growth and coaching.

This paper describes our vulnerability-discovery process and the repeatable experiment we used to assess it. We found substantial evidence that a breadth-first search makes a superior targeting strategy in the presence of automation. We also measured significant improvements in the confidence of subjects who applied our process to a vulnerability-discovery campaign.

### 2. Related Work
Votipka et al. studied the interplay between testers, who investigate software before release, and hackers, who investigate software after release. They derived a common vulnerability discovery process, which we build upon here [40, §V]. Manès et al. provide a survey of many techniques found in fuzzing tools [21], such as Mayhem [5] and Driller [36], which address the path explosion problem in symbolic execution. Klees et al. survey the fuzzing literature to comment on the required procedures for good scientific and evidence-based research [20].

Avgerinos et al. mention the challenges of scaling analysis to thousands of software artifacts, making per-program manual labor impractical [1, §6.4]. Babic et al. discuss a method to harness library code automatically and at scale [2]. Sawilla and Ou proposed ASSETRANK, an algorithm that reveals the importance of vulnerabilities in a system [31]. Our strategy builds on OSS-Fuzz’s idea of passing indicators of vulnerability to human experts for remediation [32].

In this study, we extend Votipka’s vulnerability discovery process, use modern tools referenced by Manès, accept some manual labor to make finding bugs in real software artifacts tractable, and use statistical tests to extrapolate our observations to the broader hacker community.

### 3. Vulnerability Discovery Process
Our goal is to increase the effectiveness of teams built on a foundation of automation (e.g., fuzzing) whose aim is to find security-critical bugs in software. We consider both published and novel bugs, focusing on employed software where vulnerabilities—published (n-day) or not (0-day)—are the main concern. We describe our vulnerability discovery process, based on Votipka’s work, and introduce two distinct strategies that our experiment compared.

We categorize bug finders into three groups: apprentices, journeymen, and masters (Figure 1). An apprentice has a general computing background and basic understanding of automated software analysis tools, primarily fuzzers. Journeymen can modify source code or use binary patching to overcome obstacles like checksums, encryption, or non-deterministic functionality. Masters can manipulate or create tools to better investigate target programs.

**Targeting**: Targeting selects software for investigation. The goal is to divide complex systems into individual targets that can be studied in later phases. Only cursory information, such as the pervasiveness of existing security research, availability of source code, and impact of finding a vulnerability, should be collected during this phase. The predicted profit of a vulnerability-finding effort is proportional to the likelihood and value of success and inversely proportional to the projected time investment and required skill level.

\[ P = (L \times V) - (T \times S) \]

This model guides targeting and subsequent decisions to maximize return on investment. Not all hackers are created equal, and building expertise in software security can take years. A targeting strategy should boost overall productivity across all skill levels. We aimed to derive a sufficient number of software targets to allow hackers to select work aligned with their ability and interest.

Ultimately, we developed a strategy that coupled the freedom of target choice with a "fail fast" culture and an incentive for rapid results. This allows teams to self-organize and enables more effective use of journeyman- and master-level hackers’ scarce time.

**Information Gathering**: Hackers and analysts collect additional information about the target, including general details about development, prevalence, and known defects, along with any completed security research.

**Program Understanding**: Hackers focus on gaining knowledge of the target’s operation and design, including how it is used, advanced use cases, and configuration options. Information can come from documentation, source code, online forums, users, and developers.

**Attack Surface Analysis**: This involves devising ways to provide input to portions of the target program, often through a fuzzing harness. Apprentices apply known tools until an obstacle prevents further progress, document their work, and move on. Journeymen consume the documentation produced by apprentices, allowing them to immediately apply higher-order analysis. Masters enter the cycle with extensive documentation and other products generated by apprentices and journeymen, focusing on tasks only they can perform.

### 4. Experiment Design and Execution
We designed a repeatable experiment to assess our vulnerability discovery process. Two teams of hackers applied two strategies (depth-first and breadth-first) over two successive weeks. We describe the results in Section 5 and conclude in Section 6.

### 5. Results
Our results provide substantial evidence that a breadth-first search makes a superior targeting strategy in the presence of automation. We also measured significant improvements in the confidence of subjects who applied our process to a vulnerability-discovery campaign.

### 6. Conclusion
Our work demonstrates that a breadth-first approach, combined with a structured process and the use of automation, can significantly enhance the effectiveness of vulnerability discovery teams. By leveraging the strengths of hackers at different skill levels, we can achieve measurable, incremental progress and improve the overall efficiency of the process.