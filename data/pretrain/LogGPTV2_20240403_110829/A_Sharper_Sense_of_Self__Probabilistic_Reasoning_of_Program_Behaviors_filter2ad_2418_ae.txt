# Number of Useful [SYSCALL...RET] Gadgets

| Program | # of Useful [SYSCALL...RET] Gadgets |
|---------|--------------------------------------|
| sed     | 5                                    |
| gzip    | 5                                    |
| grep    | 5                                    |
| flex    | 5                                    |
| bash    | 9                                    |
| vim     | 6                                    |
| proftpd | 8                                    |
| nginx   | 8                                    |
| libc.so | 8                                    |

## E. Detection of Real-World Exploits

With the enforcement of caller information, our context-sensitive models successfully detect all the reproduced attacks. For most of the syscall traces, a high percentage (30% to 90%) of system calls were found with abnormal caller context information (e.g., either missing or incorrect).

### CMarkov Successfully Detects Abnormal-A Segments from Real-World Exploits

**Table IV: Real-World Exploits**

| Vulnerability          | Payload                         |
|------------------------|---------------------------------|
| Buffer Overflow (gzip) |                                 |
| Backdoor (proftpd)     | OSVDB-69562                     |
| Buffer Overflow (proftpd) | CVE-2010-4221                  |
| ROP                    | ROP syscall chain               |
| bind perl              |                                 |
| bind perl ipv6         |                                 |
| generic cmd execution  |                                 |
| double reverse TCP     |                                 |
| reverse perl           |                                 |
| reverse perl ssl       |                                 |
| reverse ssl double telnet |                               |
| guess memory address   |                                 |

The attacks evaluated are shown in Table IV and are briefly described next. This experimental setup follows the evaluation in STILO [4]. The ROP setup is similar to that in Section V-D. We reproduced a backdoor Trojan (OSVDB-69562) and a buffer overflow (CVE-2010-4221) exploit on a proftpd server and analyzed the server-side traces. We provided typical attack payloads in the backdoor exploit, which are for establishing various types of communication channels (including telnet, IPv6, TCP, or SSL) between the victim machine and the remote attacker.

## F. Summary of Experimental Findings

We summarize our experimental findings below.

**Table V: Analysis Runtime for CMarkov Model in Seconds**

| Program | Time (lib) | Time (sys) | CFG | Prob. Est. | Aggr. |
|---------|------------|------------|-----|------------|-------|
| flex    | 0.06       | 0.51       | 0.46 | 1.06       | 0.65  |
| grep    | 0.07       | 0.51       | 1.21 | 0.39       | 2.45  |
| gzip    | 0.04       | 0.49       | 1.01 | 0.24       | 2.67  |
| sed     | 0.08       | 0.54       | 3.01 | 0.39       | 2.76  |
| bash    | 0.08       | 2.41       | 0.15 | 2.56       | 1.11  |
| vim     | 0.75       | 3.66       | 2.48 | 4.99       | 0.75  |
| nginx   | 8.29       | 1.87       | 9.39 | 0.75       | 10.94 |
| proftpd | 0.56       | 10.56      | 0.65 | 10.66      | 1.97  |
| Total   | 134.93     | 75.94      | 1435.73 | 736.79    | 12.55 |

1. **High Classification Accuracy**: The average classification accuracy of our context-sensitive CMarkov models is orders of magnitude higher than that of the regular hidden Markov models used by existing anomaly detection systems. This improvement is consistently observed for all tested utility and server programs on both library and system calls. The high classification accuracy in the CMarkov model suggests the effectiveness of our static program analysis-guided HMM initialization in boosting its performance for anomaly detection.

   - **Detection Precision**: Detection with library calls yields more precise results than with system calls on synthetic abnormal call sequences. This trend is generally observed for all four compared detection models, with a few exceptions. Both types of call sequences reflect the control flow of program execution. We partially attribute the higher accuracy of using library calls to the larger set of distinct calls as compared to system calls, which results in a finer-grained representation of the program control-flow patterns.

2. **ROP Gadget Limitation**: We demonstrate that the available numbers of ROP gadgets in gzip that are compatible with 1-level calling context are low, limiting the success of ROP attacks. The results under various gadget lengths (2, 6, 10) are shown in Table III.

   - **Anomaly Detection**: The CMarkov model detects all the code-injection and subtle code-reuse attacks evaluated. It also identifies carefully prepared ROP-based anomalous system call sequences by identifying their incorrect caller context, whereas the regular HMM model cannot.

3. **Efficient Runtime**: Most CMarkov operations can be completed in seconds for the programs evaluated. The runtime information of CMarkov’s analysis operations for library calls and system calls is shown in Table V, including STATIC CFG CONSTRUCTION, PROBABILITY ESTIMATION, and AGGREGATION OF CALL-TRANSITION MATRIX.

   - **Training Time Reduction**: K-means clustering on library call models reduces the training time by 75% to 89% without compromising detection accuracy.

## VI. Related Work

Our discussion focuses on related control-flow anomaly-detection techniques. We divide them based on the context-sensitive property (i.e., the ability to distinguish calling context at run-time) or the flow-sensitive property (i.e., the ability to analyze the order of statement executions). For a complete and thorough discussion on program anomaly detection literature, we refer readers to [20].

### Context-Sensitive Models

- **FSA Model [5]** and **VtPath Model [6]**: Both are constructed dynamically from program executions. They identify the program counter and return addresses on the stack, respectively, as the context for each observed system call, which helps improve the precision of their program behavior models.
- **Execution-Graph Model [21]**: Built through learning runtime program execution patterns (return addresses on the call stack associated with system calls) and leveraging the inductive property in call sequences. However, they share the same issue as other dynamically constructed models where incomplete testing or training data may impair the quality of the learned detection model.
- **Context-Sensitive Push-Down Automaton (PDA) [22]**: Achieves context-sensitivity but may have prohibitive run-time costs.
- **Dyck Model [23]**: Code is inserted to link the entry and exit of a target function with its call sites for context sensitivity.
- **VPStatic [24]**: Captures a list of un-returned call site addresses on the stack at the time of each system call.
- **IAM (Inlined Automaton Model) [14]**: Achieves context-sensitivity by inlining every callee function’s automata into the caller, trading more space cost for lower time overhead.

In comparison, CMarkov performs static analysis on program binaries without any instrumentation. The context information in our model is the caller function of each system or library call, which can be obtained both at static analysis and runtime monitoring. Our empirical results show that this fine-grained context does not provide additional detection capability in code reuse attacks.

### Consistency in Control Transfer

- **e-NexSh [25]**: A runtime validation system that provides call-stack validation ensuring consistency in the call site and target site memory addresses for library and system call invocations. It operates mostly in the kernel space and does not require any modification to application code.
- **Control-Flow Integrity (CFI) Techniques [26-30]**: Various methods to achieve CFI, including binary transformation, static analysis, and software emulators. These systems assume limited dynamic code behaviors, which is not necessary in CMarkov due to our trace-based learning phase.

### Flow-Sensitive Models

- **N-Gram Models [1, 32, 33]**: Construct a set of all allowable call sequences from the execution traces of a program. They are simple but suffer from scalability and efficiency issues.
- **HMM (Hidden Markov Model) [2, 34, 35]**: First presented by Warrender et al. [2], it classifies program system call sequences for anomaly detection. STILO [4] correlates HMM states with control-flow properties but is context-insensitive. In comparison, CMarkov supports context-sensitive behavioral modeling and addresses the challenge of state explosion in HMM.

### Others

- **Machine-Learning Based Detection [35, 36]**: Recent research proposes using machine learning to detect anomalous correlation patterns in execution. LEAPS [36] uses program analysis to detect camouflaged attacks, but differs from CMarkov in preprocessing and machine learning techniques.
- **Specialized HMM [34]**: Designed for measuring the behavioral distances of two different programs that share similar functionality. Applying context-sensitive HMM to N-variant settings is an interesting open problem.
- **Abstract Anomaly Detection Frameworks [38, 20]**: Help define anomalies and understand detection capabilities and limitations.

## VII. Conclusions and Future Work

In this paper, we presented a HMM-based probabilistic program anomaly detection technique that supports 1-level calling context sensitivity. The solution is useful for detecting new and unknown exploits, as well as stealth attacks that alter runtime control flow properties of a program. Our hidden Markov model is specialized with initial probability values extracted through static analysis of control flows. We designed and demonstrated a clustering-based method for hidden state reduction. Extensive experimental evaluation with library call and system call sequences of Linux server and utility programs showed 1-3 orders of magnitude improvement over context-insensitive counterparts. Our ongoing work is focused on applying our solutions to improve the reliability and dependability of programs on embedded systems in the Internet of Things (IoT).

## Acknowledgements

The authors would like to thank the anonymous reviewers for their insightful comments on the work. This work has been supported by ONR grant N00014-13-1-0016.

## References

[1] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff, “A sense of self for Unix processes,” in Proc. of S&P, 1996.

[2] C. Warrender, S. Forrest, and B. A. Pearlmutter, “Detecting intrusions using system calls: Alternative data models,” in Proc. of S&P, 1999.

[3] D.-Y. Yeung and Y. Ding, “Host-based intrusion detection using dynamic and static behavioral models,” Pattern Recognition, 2003.

[4] K. Xu, D. Yao, B. Ryder, and K. Tian, “Probabilistic program modeling for high-precision anomaly classification,” in Proc. of CSF, 2015.

[5] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni, “A fast automaton-based method for detecting anomalous program behaviors,” in Proc. of S&P, 2001.

[6] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong, “Anomaly detection using call stack information,” in Proc. of S&P, 2003.

[7] H. Shacham, “The geometry of innocent flesh on the bone: Return-into-libc without function calls (on the x86),” in Proc. of CCS, 2007.

[8] D. Wagner and P. Soto, “Mimicry attacks on host-based intrusion detection systems,” in Proc. of CCS, 2002.

[9] L. Rabiner, “A tutorial on hidden Markov models and selected applications in speech recognition,” Proceedings of the IEEE, vol. 77, no. 2, pp. 257–286, Feb 1989.

[10] T. Ball and J. R. Larus, “Branch prediction for free,” in Proc. of PLDI, 1993.

[11] B. Calder, D. Grunwald, M. P. Jones, D. C. Lindsay, J. H. Martin, M. Mozer, and B. G. Zorn, “Evidence-based static branch prediction using machine learning,” ACM Trans. Prog. Lang. Syst., vol. 19, no. 1, 1997.

[12] Y. Wu and J. R. Larus, “Static branch frequency and program profile analysis,” in Proc. of MICRO, 1994.

[13] R. P. L. Buse and W. Weimer, “The road not taken: Estimating path execution frequency statically,” in Proc. of ICSE, 2009.

[14] R. Gopalakrishna, E. H. Spafford, and J. Vitek, “Efficient intrusion detection using automaton inlining,” in Proc. of S&P, 2005.

[15] DYNINST binary instrumentation. http://www.dyninst.org.

[16] Audit framework. https://wiki.archlinux.org/index.php/Audit_framework.

[17] Cost of Security. http://institute.lanl.gov/isti/summer-school/cluster_network/projects-2011/2011%20Yellow%20Team Lopez%20Mortensen%20Chambers.pdf.

[18] J.-M. Francois, “jahmm,” http://jahmm.googlecode.com/, 2009.

[19] Software-artifact Infrastructure Repository. http://sir.unl.edu/portal/index.php.

[20] X. Shu, D. Yao, and B. Ryder, “A formal framework for program anomaly detection,” in Proc. of RAID, 2015.

[21] D. Gao, M. K. Reiter, and D. Song, “Gray-box extraction of execution graphs for anomaly detection,” in Proc. of CCS, 2004.

[22] D. Wagner and D. Dean, “Intrusion detection via static analysis,” in Proc. of S&P, 2001.

[23] J. T. Giffin, S. Jha, and B. P. Miller, “Efficient context-sensitive intrusion detection,” in Proc. of NDSS, 2004.

[24] H. H. Feng, J. T. Giffin, Y. Huang, S. Jha, W. Lee, and B. P. Miller, “Formalizing sensitivity in static analysis for intrusion detection,” in Proc. of S&P, 2004.

[25] G. S. Kc and A. D. Keromytis, “e-NeXSh: Achieving an effectively non-executable stack and heap via system-call policing,” in Proc. of ACSAC, 2005.

[26] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-flow integrity: Principles, implementations, and applications,” in Proc. of CCS, 2005.

[27] B. Zeng, G. Tan, and G. Morrisett, “Combining control-flow integrity and static analysis for efficient and validated data sandboxing,” in Proc. of CCS, 2011.

[28] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant, D. Song, and W. Zou, “Practical control flow integrity and randomization for binary executables,” in Proc. of S&P, 2013.

[29] M. Zhang and R. Sekar, “Control flow integrity for COTS binaries,” in Proc. of USENIX Security, 2013.

[30] A. Prakash, H. Yin, and Z. Liang, “Enforcing system-wide control flow integrity for exploit detection and diagnosis,” in Proc. of AsiaCCS, 2013.

[31] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi, and T. Holz, “Counterfeit object-oriented programming: On the difficulty of preventing code reuse attacks in C++ applications,” in Proc. of S&P, 2015.

[32] S. A. Hofmeyr, S. Forrest, and A. Somayaji, “Intrusion detection using sequences of system calls,” Journal of Computer Security, 1998.

[33] C. Wressnegger, G. Schwenk, D. Arp, and K. Rieck, “A close look on N-grams in intrusion detection: Anomaly detection vs. classification,” in Proc. of AISec, 2013.

[34] D. Gao, M. K. Reiter, and D. X. Song, “Beyond output voting: Detecting compromised replicas using HMM-based behavioral distance,” IEEE TDSC, 2009.

[35] X. Shu, D. Yao, and N. Ramakrishnan, “Unearthing stealthy program attacks buried in extremely long execution paths,” in Proc. of CCS, 2015.

[36] Z. Gu, K. Pei, Q. Wang, L. Si, X. Zhang, and D. Xu, “LEAPS: Detecting camouflaged attacks with statistical learning guided by program analysis,” in Proc. of DSN, 2015.

[37] B. Cox, D. Evans, A. Filipi, J. Rowanhill, W. Hu, J. Davidson, J. Knight, A. Nguyen-Tuong, and J. Hiser, “N-variant systems: A secretless framework for security through diversity,” in Proc. of USENIX Security, 2006.

[38] E. Anceaume, Y. Busnel, E. L. Merrer, R. Ludinard, J. L. Marchand, and B. Sericola, “Anomaly characterization in large scale networks,” in Proc. of DSN, 2014.

[39] Q. Huang and P. P. C. Lee, “Ld-sketch: A distributed sketching design for accurate and scalable anomaly detection in network data streams,” in Proc. of INFOCOM, 2014.

[40] A. Ceccarelli, T. Zoppi, A. Bondavalli, F. Duchi, and G. Vella, “A testbed for evaluating anomaly detection monitors through fault injection,” in Proc. of ISORC, 2014.

[41] H. Zhang, D. D. Yao, and N. Ramakrishnan, “Detection of stealthy malware activities with traffic causality and scalable triggering relation discovery,” in Proc. of AsiaCCS, 2014.

[42] S. Jero, H. Lee, and C. Nita-Rotaru, “Leveraging state information for automated attack discovery in transport protocol implementations,” in Proc. of DSN, 2015.

[43] P. Buchholz and J. Kriege, “Markov modeling of availability and unavailability data,” in Proc. of EDCC, 2014.