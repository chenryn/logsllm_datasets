10
2
# of Useful [SYSCALL...RET] Gadgets
5
5
5
5
9
6
8
8
8
6
6
6
6
12
7
13
11
14
7
7
7
7
15
8
17
16
19
Program
sed
gzip
grep
ﬂex
bash
vim
proftpd
nginx
libc.so
E. Detection of Real-World Exploits
With the enforcement of caller information, our context-
sensitive models successfully detect all the reproduced attacks.
For most of the syscall traces, a high percentage of system
calls ([30%, 90%]) were found with abnormal caller context
information (e.g., either missing or incorrect).
CMARKOV SUCCESSFULLY DETECTS Abnormal-A SEGMENTS FROM
TABLE IV
REAL-WORLD EXPLOITS.
Vulnerability
Payload
Buffer Overﬂow
(gzip)
Backdoor
(proftpd)
Buffer Overﬂow
(proftpd)
ROP
ROP syscall chain
bind perl
bind perl ipv6
generic cmd execution
double reverse TCP
reverse perl
reverse perl ssl
reverse ssl double telnet
guess memory address
The attacks evaluated are shown in Table IV and are brieﬂy
described next. This experimental setup follows the evaluation
in STILO [4]. ROP setup is similar to that in Section V-D. We
reproduced a backdoor Trojan (OSVDB-69562) and a buffer
overﬂow (CVE-2010-4221) exploit on a proftpd server
and analyzed the server-side traces. We gave typical attack
payloads in the backdoor exploit, which are for establishing
various types of communication channels (including telnet,
IPv6, TCP, or SSL) between the victim machine and the
remote attacker.
F. Summary of Experimental Findings
We summarize our experimental ﬁndings below.
475
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
ANALYSIS RUNTIME FOR CMARKOV MODEL IN SECONDS. CFG IS FOR
CFG CONSTRUCTIONS. PROB. EST. IS FOR PROBABILITY ESTIMATION IN
FUNCTIONS. AGGR. IS FOR THE AGGREGATION OF CALL-TRANSITION
TABLE V
MATRICES.
Prog.
Time (lib)
Time (sys)
ﬂex
grep
gzip
sed
bash
vim
nginx
proftpd
CFG
Prob. Est.
Aggr.
0.06
0.51
0.07
0.51
0.04
0.49
0.08
0.54
0.46
1.06
0.65
1.21
0.39
2.45
1.01
3.01
0.24
2.67
0.39
2.76
0.08
2.41
0.15
2.56
1.11
3.66
2.48
4.99
0.75
8.29
1.87
9.39
0.75
10.94
0.56
10.56
0.65
10.66
1.97
12.55
134.93
75.94
1435.73
736.79
1.60
55.94
17.22
57.45
1) The average classiﬁcation accuracy of our context-
sensitive CMarkov models is orders of magnitudes
higher than that of the regular hidden Markov models
used by existing anomaly detection systems. This
improvement is consistently observed for all the tested
utility and server programs on both library and system
calls. The high classiﬁcation accuracy in CMarkov model
suggests the effectiveness of our static program analysis
guided HMM initialization in boosting its performance
for anomaly detection.
Detection with library calls yields more precise results
than that with system calls on synthetic abnormal call
sequences. This trend is generally observed for all four
compared detection models with a few exceptions. Both
types of call sequences reﬂect the control ﬂow of program
execution. We partially attribute the higher accuracy of
using libcalls to the larger set of distinct calls as compared
to syscalls, which results in a ﬁner-grained representation
of the program control-ﬂow patterns.
2) We demonstrate that the available numbers of ROP
gadgets in gzip that are compatible with 1-level calling
context are low, limiting the success of ROP attacks.
The results under various gadget lengths (2, 6, 10) are
shown in Table III.
CMarkov model detects all the code-injection and sub-
tle code-reuse attacks evaluated. CMarkov also detects
carefully prepared ROP-based anomalous system call
sequences by identifying their incorrect caller context,
whereas the regular HMM model cannot.
3) Most CMarkov operations can be ﬁnished in seconds
for the programs evaluated. The runtime information
of CMarkov’s analysis operations for library calls and
system calls is shown in Table V, including for STATIC
CFG CONSTRUCTION, PROBABILITY ESTIMATION, and
AGGREGATION OF CALL-TRANSITION MATRIX.
K-means clustering on library call models reduces the
training time by 75% to 89% without compromising
detection accuracy.
VI. RELATED WORK
Our discussion is focused on the related control-ﬂow
anomaly-detection techniques. We divide them based on the
context-sensitive property (i.e., the ability to distinguish calling
context at run-time) or the ﬂow-sensitive property (i.e., the
ability to analyze the order of statement executions). We refer
readers to [20] for a complete and thorough discussion on
program anomaly detection literature.
Context-Sensitive Models. The FSA model [5] and VtPath
model [6] are both constructed dynamically from program
executions. They identify the program counter and return
addresses on the stack respectively as the context for each
observed system call, which helps improve the precision of
their program behavior models. The execution-graph model
in [21] was built through learning runtime program execution
patterns (namely return addresses on the call stack associated
with system calls) and leveraging the inductive property in
call sequences. However, they share the same issue as other
dynamically constructed models where the testing or training
data may be incomplete and would thus impair the quality of
the learned detection model. Instead of dynamically learning
the automaton model from program traces as in [5], one
can build a similar ﬂow-sensitive and also context-sensitive
automaton by statically analyzing the programs themselves,
as shown in the seminal paper by Wagner [22]. The context-
sensitive push-down automaton (PDA) (in their abstract stack
model) in [22], however, may have prohibitive run-time costs.
Gifﬁn et al. proposed Dyck model [23] where code is
inserted to link the entry and exit of a target function with
its call sites for context sensitivity. As a static version of the
VtPath, the VPStatic [24] model captures a list of un-returned
call site addresses on the stack at the time of each system
call. Despite having more accurate program behavior models,
the requirement of program instrumentation is still a concern
for practical deployment. The IAM (inlined automaton model)
in [14] achieves context-sensitivity by inlining every callee
function’s automata into the caller, which trades more space
cost for lower time overhead.
In comparison, CMarkov performs static analysis on the
program binaries without any instrumentation. The context
information in our model is the caller function of each system
or library call, which can be obtained both at static analysis
and runtime monitoring. CMarkov has a manageable size
controlled at the time of model initialization with statically
extracted call transition information. Our model uses the caller
function as the context information for each system and libc
call, and does not distinguish same calls in a function. The use
of program counters as in [5] can further differentiate same
system calls made within the same function. Our empirical
results show that this ﬁne-grained context does not provide
additional detection capability in code reuse attacks.
Consistency in Control Transfer. e-NexSh is a runtime valida-
tion system that provides call-stack validation that ensures the
consistency in the call site and target site memory addresses
for libc call and system call invocations [25]. e-NexSh has
476
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
high compatibility, as it operates mostly in the kernel space
and does not require any modiﬁcation to application code.
A binary transformation technique was proposed by Abadi
et al. to achieve control-ﬂow integrity (CFI) [26]. Through
modifying source and destination instructions associated with
control-ﬂow transfers, it embeds control-ﬂow policies within
the binary to be enforced at runtime. Static analysis was used
to reduce CFI’s overhead in [27]. [28] improved the method by
allocating a memory region dedicated to enforcing the targets
of indirect control transfers. It brings 2- to 5-fold improvement
in the run-time performance. Zhang and Sekar presented static
analysis based methods and instrumentation to enforce the CFI
property on commercial off-the-shelf binaries [29]. Total-CFI
is a framework for system-wide run-time control-ﬂow integrity
enforcement [30] built on a software emulator.
In comparison to CFI techniques, our monitoring system
is focused on the call-making portion of the control ﬂow
instead of all the execution transfer instructions. We do not
require any binary transformation or software emulator. Most
CFI systems assume limited dynamic code behaviors 3; this
assumption is not necessary in CMarkov because of our trace-
based learning phase. Unlike ours, CFI is not designed to offer
any probabilistic behavior analysis.
New attacks against CFI techniques are constantly be-
ing reported, e.g., counterfeit object-oriented programming
(COOP) has been recently shown to bypass nearly all CFI
solutions [31]. Therefore, research efforts on probabilistic
program anomaly detection are important, as they can provide
complementary security protection to critical systems.
Flow-Sensitive Models. The n-gram models [1, 32, 33] con-
struct a set of all allowable call sequences from the execution
traces of a program. It is the simplest ﬂow-sensitive solution.
Because the model enumerates all possible call sequences,
scalability and efﬁciency are low.
As a probabilistic learning model, HMM (hidden Markov
model) was ﬁrst presented by Warrender et al. [2], and was
used to classify program system call sequences for anomaly
detection. This is also the model we extensively compare with
throughout the paper. By comparing two parallel executions
of a same program, Gao et al. [34] proposed a HMM-based
model that is resilient to their best-estimated mimicry attacks.
Different parameters of HMM were systematically studied
by the authors in [3] for the impact on model accuracy.
These existing HMM-based solutions initialize their models
randomly or arbitrarily.
STILO is a HMM model that correlates HMM states with
control-ﬂow properties [4]. The model
is initialized with
the data extracted from static program analysis. STILO is
context insensitive. In comparison, CMarkov supports context-
sensitive behavioral modeling. Our work addresses the new
challenge of state explosion in HMM, speciﬁcally, how to
support context sensitivity in probabilistic program anomaly
detection without incurring heavy computation costs.
3E.g., self-modifying code, runtime code generation, and the unanticipated
dynamic loading of code [26].
Recently, researchers proposed a machine-learning based
detection solution to detect anomalous correlation patterns in
execution [35]. Context-insensitive call information is rep-
resented in matrices, which are analyzed through clustering
and 1-class SVM. Gu et al. proposed LEAPS [36] to detect
camouﬂaged attacks with program analysis. This paper is
related to our work because it also adopts a preprocess to
reﬁne the training data and then deploys statistical learning
models to identify benign/malicious call patterns. However,
because our goal is to detect code reuse attacks, our approach
substantially differs from LEAPS in the following aspects.
1) The preprocess in our approach is used to capture more
precise hidden Markov models by statically estimating
likelihoods of call sequences. In comparison, the pre-
process in LEAPS is used to reduce the noise data and
acquire better labeled training dataset.
2) Because of the different detection goals, CMarkov and
LEAPS adopt different machine learning techniques. Our
approach is based on the hidden Markov model for the
purpose of anomaly detection. LEAPS is based on a
modiﬁed support vector machine for binary classiﬁcation.
Others. A specialized HMM has been designed for measuring
the behavioral distances of two different programs that share
similar functionality [34]. This behavior-comparison approach
is generally known in the literature as N-variant [37]. How to
apply the context-sensitive HMM to N-variant settings is an
interesting open problem. Recently, theoretical and abstract
anomaly detection frameworks have been proposed to help
the security community better deﬁne anomalies and understand
detection capabilities and limitations. For example, Anceaume
et al. deﬁned network anomalies with respect to their neigh-
boring environments, and showed that there exist scenarios
where isolated and massive anomalies are indistinguishable
from a global observer’s perspective [38]. Another group of
researchers recently proposed a new formal language based
framework for comparing the detection capabilities of various
anomaly detection techniques [20]. The work also provides
abstractions for reasoning the limit of detection accuracy.
anomaly detection methods,
Our program anomaly detection solution complements
network-centric
e.g., LD-
Sketch [39], fault-injection based anomaly detection for Ser-
vice Oriented Architecture (SOA) [40] and trigger-relation
based stealthy trafﬁc detection [41]. Jero et al. utilizes protocol
state machine to detect attacks against transport layer network
protocols such as TCP [42]. Buchholz et al. showed the
use of Markov model for representing and analyzing system
availability and dependability [43].
VII. CONCLUSIONS AND FUTURE WORK
In this paper, we presented a HMM-based probabilistic
program anomaly detection technique that supports 1-level
calling context sensitivity. The solution is useful for detecting
new and unknown exploits, as well as stealth attacks that alter
runtime control ﬂow properties of a program. Our hidden
Markov model is specialized with initial probability values
extracted through statically analyzing control ﬂows of the
477
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
program. We designed and demonstrated a clustering-based
method for hidden state reduction. Extensive experimental
evaluation with library call and system call sequences of
Linux server and utility programs showed 1-3 orders of
magnitude improvement over context-insensitive counterparts.
Our ongoing work is focused on applying our solutions in
order to improve the reliability and dependability of programs
on embedded systems in Internet of Things (IoT).
ACKNOWLEDGEMENTS
The authors would like to thank the anonymous reviewers
for their insightful comments on the work. This work has been
supported by ONR grant N00014-13-1-0016.
REFERENCES
[1] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff,
“A sense of self for Unix processes,” in Proc. of S&P, 1996.
[2] C. Warrender, S. Forrest, and B. A. Pearlmutter, “Detecting
intrusions using system calls: Alternative data models,” in Proc.
of S&P, 1999.
[3] D.-Y. Yeung and Y. Ding, “Host-based intrusion detection using
dynamic and static behavioral models,” Pattern Recognition,
2003.
[4] K. Xu, D. Yao, B. Ryder, and K. Tian, “Probabilistic program
modeling for high-precision anomaly classiﬁcation,” in Proc. of
CSF, 2015.
[5] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni, “A fast
automaton-based method for detecting anomalous program be-
haviors,” in Proc. of S&P, 2001.
[6] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong,
“Anomaly detection using call stack information,” in Proc. of
S&P, 2003.
[7] H. Shacham, “The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86),” in Proc.
of CCS, 2007.
[8] D. Wagner and P. Soto, “Mimicry attacks on host-based intru-
sion detection systems,” in Proc. of CCS, 2002.
[9] L. Rabiner, “A tutorial on hidden Markov models and selected
applications in speech recognition,” Proceedings of the IEEE,
vol. 77, no. 2, pp. 257–286, Feb 1989.
[10] T. Ball and J. R. Larus, “Branch prediction for free,” in Proc.
of PLDI, 1993.
[11] B. Calder, D. Grunwald, M. P. Jones, D. C. Lindsay, J. H.
Martin, M. Mozer, and B. G. Zorn, “Evidence-based static
branch prediction using machine learning,” ACM Trans. Pro-
gram. Lang. Syst., vol. 19, no. 1, 1997.
[12] Y. Wu and J. R. Larus, “Static branch frequency and program
proﬁle analysis,” in Proc. of MICRO, 1994.
[13] R. P. L. Buse and W. Weimer, “The road not taken: Estimating
path execution frequency statically,” in Proc. of ICSE, 2009.
[14] R. Gopalakrishna, E. H. Spafford, and J. Vitek, “Efﬁcient
intrusion detection using automaton inlining,” in Proc. of S&P,
2005.
[15] DYNINST binary instrumentation. http://www.dyninst.org.
[16] Audit
framework. https://wiki.archlinux.org/index.php/Audit
framework.
[17] Cost of Security. http://institute.lanl.gov/isti/summer-school/
cluster network/projects-2011/2011%20Yellow%20Team
Lopez%20Mortensen%20Chambers.pdf.
[18] J.-M. Francois, “jahmm,” http://jahmm.googlecode.com/, 2009.
Infrastructure Repository. http://sir.unl.edu/
[19] Software-artifact
portal/index.php.
[20] X. Shu, D. Yao, and B. Ryder, “A formal framework for program
anomaly detection,” in Proc. of RAID, 2015.
[21] D. Gao, M. K. Reiter, and D. Song, “Gray-box extraction of
execution graphs for anomaly detection,” in Proc. of CCS, 2004.
[22] D. Wagner and D. Dean, “Intrusion detection via static analy-
sis,” in Proc. of S&P, 2001.
[23] J. T. Gifﬁn, S. Jha, and B. P. Miller, “Efﬁcient context-sensitive
intrusion detection,” in Proc. of NDSS, 2004.
[24] H. H. Feng, J. T. Gifﬁn, Y. Huang, S. Jha, W. Lee, and B. P.
Miller, “Formalizing sensitivity in static analysis for intrusion
detection,” in Proc. of S&P, 2004.
[25] G. S. Kc and A. D. Keromytis, “e-NeXSh: Achieving an effec-
tively non-executable stack and heap via system-call policing,”
in Proc. of ACSAC, 2005.
[26] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-
ﬂow integrity: Principles, implementations, and applications,”
in Proc. of CCS, 2005.
[27] B. Zeng, G. Tan, and G. Morrisett, “Combining control-ﬂow
integrity and static analysis for efﬁcient and validated data
sandboxing,” in Proc. of CCS, 2011.
[28] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical control ﬂow integrity and
randomization for binary executables,” in Proc. of S&P, 2013.
[29] M. Zhang and R. Sekar, “Control ﬂow integrity for COTS
binaries,” in Proc. of USENIX Security, 2013.
[30] A. Prakash, H. Yin, and Z. Liang, “Enforcing system-wide
control ﬂow integrity for exploit detection and diagnosis,” in
Proc. of AsiaCCS, 2013.
[31] F. Schuster, T. Tendyck, C. Liebchen, L. Davi, A.-R. Sadeghi,
and T. Holz, “Counterfeit object-oriented programming: On the
difﬁculty of preventing code reuse attacks in C++ applications,”
in Proc. of S&P, 2015.
[32] S. A. Hofmeyr, S. Forrest, and A. Somayaji, “Intrusion detection
using sequences of system calls,” Journal of Computer Security,
1998.
[33] C. Wressnegger, G. Schwenk, D. Arp, and K. Rieck, “A close
look on N-grams in intrusion detection: Anomaly detection vs.
classiﬁcation,” in Proc. of AISec, 2013.
[34] D. Gao, M. K. Reiter, and D. X. Song, “Beyond output voting:
Detecting compromised replicas using HMM-based behavioral
distance,” IEEE TDSC, 2009.
[35] X. Shu, D. Yao, and N. Ramakrishnan, “Unearthing stealthy
program attacks buried in extremely long execution paths,” in
Proc. of CCS, 2015.
[36] Z. Gu, K. Pei, Q. Wang, L. Si, X. Zhang, and D. Xu, “LEAPS:
Detecting camouﬂaged attacks with statistical learning guided
by program analysis,” in Proc. of DSN, 2015.
[37] B. Cox, D. Evans, A. Filipi, J. Rowanhill, W. Hu, J. Davidson,
J. Knight, A. Nguyen-Tuong, and J. Hiser, “N-variant systems:
A secretless framework for security through diversity,” in Proc.
of USENIX Security, 2006.
[38] E. Anceaume, Y. Busnel, E. L. Merrer, R. Ludinard, J. L.
Marchand, and B. Sericola, “Anomaly characterization in large
scale networks,” in Proc. of DSN, 2014.
[39] Q. Huang and P. P. C. Lee, “Ld-sketch: A distributed sketching
design for accurate and scalable anomaly detection in network
data streams,” in Proc. of INFOCOM, 2014.
[40] A. Ceccarelli, T. Zoppi, A. Bondavalli, F. Duchi, and G. Vella,
“A testbed for evaluating anomaly detection monitors through
fault injection,” in Proc. of ISORC, 2014.
[41] H. Zhang, D. D. Yao, and N. Ramakrishnan, “Detection of
stealthy malware activities with trafﬁc causality and scalable
triggering relation discovery,” in Proc. of AsiaCCS, 2014.
[42] S. Jero, H. Lee, and C. Nita-Rotaru, “Leveraging state infor-
mation for automated attack discovery in transport protocol
implementations,” in Proc. of DSN, 2015.
[43] P. Buchholz and J. Kriege, “Markov modeling of availability
and unavailability data,” in Proc. of EDCC, 2014.
478
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply.