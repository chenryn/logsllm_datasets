# References

1. Dimitris Stripelis, José Luis Ambite, Pradeep Lam, and Paul Thompson. "Scaling Neuroscience Research using Federated Learning." In *IEEE International Symposium on Biomedical Imaging (ISBI)*, 2021.
2. Stacey Truex, Ling Liu, Mehmet Emre Gursoy, Lei Yu, and Wenqi Wei. "Towards Demystifying Membership Inference Attacks." *arXiv preprint arXiv:1807.09173*, 2018.
3. Didac Vidal-Pineiro, Yunpeng Wang, Stine K Krogsrud, Inge K Amlien, William FC Baare, David Bartres-Faz, Lars Bertram, Andreas M Brandmaier, Christian A Drevon, Sandra Düzel, et al. "‘Brain age’ relates to early life factors but not to accelerated brain aging." *bioRxiv*, 2021.
4. Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. "Federated Machine Learning: Concept and Applications." *ACM Transactions on Intelligent Systems and Technology (TIST)*, 10(2):1–19, 2019.
5. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. "Understanding deep learning requires rethinking generalization." In *International Conference on Learning Representations*, 2017.

# Appendix A: Brain Age Model, Training, and Dataset Details

In both federated and centralized setups, we used MRIs from the UK Biobank dataset (Miller et al., 2016) for brain age prediction. All scans were preprocessed using the same technique, resulting in final images with dimensions of 91 × 109 × 91. For full details, refer to Gupta et al. (2021) and Stripelis et al. (2021).

## A.1 Centralized Training Setup

To simulate attacks on centrally trained deep neural network models, we adopted the pre-trained models from Gupta et al. (2021). The authors selected a subset of 10,446 healthy subjects from 16,356 subjects in the UK Biobank dataset (Miller et al., 2016) to create training, validation, and test sets of sizes 7,312, 2,194, and 940, respectively, with a mean chronological age of 62.6 years and a standard deviation of 7.4 years. They proposed novel 2D-slice-based architectures to improve brain age prediction, using 2D convolutions to encode slices along the sagittal axis and aggregating the derived embeddings through permutation-invariant operations. In our work, we use the 2D-slice-mean model, which demonstrated the best performance in their study, and a conventional 3D-CNN model, commonly used for processing MRI scans (Peng et al., 2021; Cole et al., 2017). The architecture diagrams of each model are shown in Figure 6 and discussed in Section A.3.

Performance is measured as the mean absolute error (MAE) between the predicted and true ages on the held-out test set. The centralized models were trained for 100 epochs, and the best model was selected based on the validation set performance. The membership inference attacks we investigate are evaluated over the models produced at the end of the 100th epoch. Table 6 shows the MAE on the train, test, and validation sets.

## A.2 Federated Training Setup

To simulate membership inference attacks on models trained in a federated learning environment, we used the pre-trained models, dataset, and training setup from Stripelis et al. (2021). The federated learning environment consists of 8 learners with homogeneous computational capabilities (8 GeForce GTX 1080 Ti graphics cards with 10 GB RAM each) and heterogeneous local data distributions. The 10,446 subject records were split into 8,356 training and 2,090 test samples. The authors generated three representative federated learning environments with diverse amounts of records (Uniform and Skewed) and subject age range distribution across learners (IID and non-IID), as shown in Figure 4.

For our attacks, we used the community models received by each learner in all federation rounds. Specifically, we used the pre-trained 3D-CNN community models from Stripelis et al. (2021), which were trained for 25 federation rounds, with each learner training the community model locally for 4 epochs. To train the 2D-slice-mean federation model, we emulated a similar training setup for 40 federation rounds. For both federated models, the solver for the local objective was SGD, the batch size was 1, the learning rate was 5e−5, and every learner used all its local data during training without reserving any samples for validation. At every federation round, all local models were aggregated using the Federated Average (FedAvg) aggregation scheme (McMahan et al., 2017). The convergence of the 2D-slice-mean federated model for the three federated learning environments is shown in Figure 5, and the performance of the final community models for each learning environment is summarized in Table 7.

## A.3 3D-CNN and 2D-slice-mean Model Architecture

### 3D-CNN
Figure 6(a) describes the architecture for the 3D-CNN model. It uses 5 convolutional blocks consisting of 3D-convolution layers with 32, 64, 128, 256, and 256 filters. Each convolutional layer is followed by 3D max-pooling, 3D instance normalization, and ReLU non-linearity operations. The resulting activations are passed through a 64-filter convolutional layer of kernel size 1, average pooled, and passed through another 3D-convolutional layer of kernel size 1 to produce the 1-dimensional brain age output.

### 2D-slice-mean
Figure 6(b) describes the architecture of the 2D-slice-mean model. This architecture encodes each slice along the sagittal dimension using a slice encoder. The slice encoder is similar to the 3D-CNN model but uses 2D versions of all the operations. Ultimately, all slices are projected to a 32-dimensional embedding. The slice-mean operation aggregates these 32-dimensional embeddings via a mean operation, which are then passed through feed-forward layers to output the brain age.

# Appendix B: Detailed Results of Membership Inference Attacks on Federated Learning

In Section 4.2, we discussed summary results of attacks on models trained via federated learning. Here, we provide a more detailed analysis of the attack results. Table 3 compares the attack performance of different feature sets. We observe that in federated environments with similar data sizes and homogeneous data distribution (Uniform & IID), all attacks succeeded. However, when the local data size and/or the data distribution across learners is heterogeneous, the total number of successful attacks decreases. Therefore, these particular attacks are sensitive to data distribution. Interestingly, even though using only magnitudes as a feature resulted in poor average attack performance, these features may be more robust to distribution shift and have more successful attacks in some cases. Investigating and designing more robust features for membership inference attacks may lead to even more adverse attacks.

Tables 4 and 5 visualize the attack results on a per-learner basis. Each row indicates the attacker, and the column indicates the results of the attack on the attacked learner. We observe that the attack performance is correlated with the distribution similarity. For example, for the Uniform & non-IID distribution, learners L1 and L5 have a similar distribution, and hence the attack from L1 on L5 or vice versa has higher accuracies. However, the attack vulnerabilities are not symmetric; for example, the accuracy of the attack from L3 to L8 or L7 to L4 is higher than vice versa, even though both learners have trained on the same number of samples. Such differences may be due to the neural network's tendency to overfit differently over diverse local data distributions, such as age ranges. An adversary with more privileged information, like knowledge of the distribution of labels or outputs, may design more sophisticated attacks.

# Appendix C: Attack Architecture and Training Details

## C.1 Attack Classifier Parametrization

We evaluate the importance of different features derived from a sample and the trained model for membership inference attacks. In the case of a black-box attack, the attacker can only use the model’s output. In contrast, in the case of white-box attacks, the attacker may also exploit the knowledge of the model’s internal workings. We have used gradient and activation information to simulate the attacks. We train deep binary classifiers that take these features as input and output the probability of the sample being in the model’s training set or not.

We repurpose the model’s architecture to create a binary classifier for preliminary experiments on using activations for attacks. For example, in Figure 6(a), when simulating an attack that uses activations from the second hidden layer (i.e., after the conv 2 layer), we used a classifier that had layers from conv 3 to output. However, as discussed in Section 4.1, the activations are not very useful features for membership attacks. Thus, we did not conduct further experiments with activations.