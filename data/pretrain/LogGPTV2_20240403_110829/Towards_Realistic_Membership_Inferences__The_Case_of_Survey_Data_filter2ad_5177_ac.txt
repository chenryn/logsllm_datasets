Dimitris Stripelis, Jos´e Luis Ambite, Pradeep Lam, and Paul Thompson. Scaling Neu-
In IEEE International Symposium on
roscience Research using Federated Learning.
Biomedical Imaging (ISBI), 2021.
Stacey Truex, Ling Liu, Mehmet Emre Gursoy, Lei Yu, and Wenqi Wei. Towards Demysti-
fying Membership Inference Attacks. arXiv preprint arXiv:1807.09173, 2018.
Didac Vidal-Pineiro, Yunpeng Wang, Stine K Krogsrud, Inge K Amlien, William FC Baare,
David Bartres-Faz, Lars Bertram, Andreas M Brandmaier, Christian A Drevon, Sandra
Duzel, et al. “Brain age” relates to early life factors but not to accelerated brain aging.
bioRxiv, 2021.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated Machine Learning:
Concept and Applications. ACM Transactions on Intelligent Systems and Technology
(TIST), 10(2):1–19, 2019.
12
Membership Inference Attacks on Deep Regression Models for Neuroimaging
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Under-
standing deep learning requires rethinking generalization. In International Conference on
Learning Representations, 2017.
Appendix A. Brain Age Model, Training and Dataset Details
In both federated and centralized setups, we used MRIs from the UK Biobank dataset (Miller
et al., 2016) for brain age prediction. All the scans were preprocessed with the same tech-
nique resulting in the ﬁnal images with dimensions 91 × 109 × 91. Here we brieﬂy describe
the details. We refer the reader to Gupta et al. (2021) and Stripelis et al. (2021) for full
details.
A.1. Centralized Training Setup
To simulate attacks on centrally trained deep neural network models, we adopted the pre-
trained models from Gupta et al. (2021). The authors selected a subset of healthy 10,446
subjects from 16,356 subjects in the UK Biobank dataset (Miller et al., 2016) to create a
training, validation, and test set of size 7,312, 2,194, and 940, respectively, and with a mean
chronological age of 62.6 and standard deviation of 7.4 years. The authors proposed novel
2D-slice-based architectures to improve brain age prediction. Their architectures used 2D
convolutions to encode the slices along the sagittal axis and aggregated the derived embed-
dings through permutation invariant operations. In our work, we use the 2D-slice-mean
model, which demonstrated the best performance in their study, and a conventional 3D-CNN
model, which is often used to process MRI scans (Peng et al., 2021; Cole et al., 2017). The
architecture diagram of each model is shown in Figure 6, and discussed in Section A.3.
For the brain age problem, the performance is measured as the mean absolute error
between the predicted and true age on the held-out test set. In Gupta et al. (2021), the
centralized models were trained for 100 epochs, and the best model was selected based on
the performance on the validation set. The membership inference attacks we investigate in
this work are evaluated over the models produced at the end of the 100th epoch. Table 6
shows performance of these models, i.e., MAE on train, test and validation sets.
A.2. Federated Training Setup
To simulate membership inference attacks on models trained on a federated learning en-
vironment, we used the pretrained models, dataset, and training setup of Stripelis et al.
(2021). In particular, the investigating learning environment consists of 8 learners with ho-
mogeneous computational capabilities (8 GeForce GTX 1080 Ti graphics cards with 10 GB
RAM each) and heterogeneous local data distributions. With respect to the UK Biobank
dataset, the 10,446 subject records were split into 8356 train and 2090 test samples. In
particular, the authors generate three representative federated learning environments with
diverse amounts of records (i.e., Uniform and Skewed) and subject age range distribution
across learners (i.e., IID and non-IID). All these environments are presented in Figure 4.
To perform our attacks, we used the community models received by each learner in all
federation rounds. Speciﬁcally, we used the pretrained 3D-CNN community models from
13
Membership Inference Attacks on Deep Regression Models for Neuroimaging
(a) Uniform & IID
(b) Uniform & non-IID
(c) Skewed & non-IID
(d ) Uniform & IID
(e) Uniform & non-IID
(f ) Skewed & non-IID
Figure 4: The UK Biobank data distribution across 8 learners for the three federated
learning environments. Figures (a), (b) and (c) present the amount of data per age range
[39 − 50), [50 − 60), [60 − 70), [70 − 80)) per learner. Figures (d ), (e) and (f )
bucket (i.e.
present the age range distribution (mean µ and standard deviation σ) per learner. Figures
are reproduced from Stripelis et al. (2021).
Figure 5: Federation rounds learning curves (test performance) for the BrainAge
2D-slice-mean model across all federated learning environments. The more non-IID and
unbalanced the data distribution is, the harder it is for the federation model to converge.
14
0510152025303540Federation Rounds2.53.03.54.04.55.05.56.06.5MAEBrainAgeCNN Federation Rounds ConvergenceUniform & IIDUniform & Non-IIDSkewed & Non-IIDMembership Inference Attacks on Deep Regression Models for Neuroimaging
Stripelis et al. (2021), which were trained for 25 federation rounds, and where every learner
trained the community model locally for 4 epochs. To train the 2D-slice-mean federation
model, we emulate a similar training setup for 40 federation rounds. For both federated
models, the solver of the local objective is SGD, the batch size is equal to 1, the learning
rate is equal to 5e−5 and every learner used all its local data during training, without
reserving any samples for validation. Finally, at every federation round all local models are
aggregated using the Federated Average (FedAvg) aggregation scheme (McMahan et al.,
2017). The convergence of the 2D-slice-mean federated model for the three federated
learning environments is shown in Figure 5 and the performance of the ﬁnal community
models for each learning environment is summarized in Table 7.
A.3. 3D-CNN and 2D-slice-mean model architecture
3D-CNN: Figure 6(a) describes the architecture for the 3D-CNN model. 3D-CNN uses 5
convolutional blocks consisting of 3D-convolution layers with 32, 64, 128, 256 and 256
ﬁlters. Each convolutional layer is followed by 3D max-pooling, 3D instance norm and
ReLU non-linearity operations. The resulting activations from these are passed through a
64 ﬁlter convolutional layer of kernel size 1, average pooled and passed through another
3D-convolutional layer of kernel size 1 to produce the 1 dimensional brain age output.
2D-slice-mean: Figure 6(b) describes the architecture of the 2d-slice-mean models.
This architecture encodes each slice along the sagittal dimensional using a slice encoder. The
slice encoder is similar to the 3D-CNN model but uses the 2D version of all the operations.
Ultimately, all the slices are projected to a 32-dimensional embedding. The slice-mean
operation aggregates these 32-dimensional embeddings via mean operation, which are then
passed through feed-forward layers to output the brain age.
Appendix B. Detailed results of membership inference attacks on
federated learning
In Section 4.2, we discussed summary results of attacks on models trained via federated
learning. Here, we provide a more detailed analysis on the attack results. Table 3 compares
the attack performance of diﬀerent feature sets. We observe that in federated environments
with similar data sizes and homogeneous data distribution, i.e., Uniform & IID, all attacks
succeeded. However, when the local data size and/or the data distribution across learners is
heterogeneous, the total number of successful attacks decreases. Therefore, these particular
attacks are sensitive to data distribution. It is interesting to note that even though using
only magnitudes as a feature resulted in poor average attack performance, these features
may be more robust to distribution shift and have more successful attacks in some cases.
Investigating and designing more robust features for membership inference attack may lead
to even more adverse attacks.
Tables 4 and 5 visualize the attack results on a per learner basis. Each row indicates
the attacker, and the column indicates the results of the attack on the attacked learner.
We observe that the attack performance is correlated with the distribution similarity. For
example, for the Uniform & non-IID distribution, learners L1 and L5 have a similar distri-
bution and hence the attack from L1 on L5 or vice-versa has higher accuracies. However,
15
Membership Inference Attacks on Deep Regression Models for Neuroimaging
(a) 3D-CNN
(b) 2D-slice-mean
Figure 6: Brain Age Prediction Model architectures. Gray blocks indicate trainable modules
and they are labelled for ease of reference in Section 4.1, non parametric operations are
indicated on the arrows.
16
MRI Scan(1x91x109x91)3x3x3 conv, 323x3x3 conv, 643x3x3 conv, 1283x3x3 conv, 2563x3x3 conv, 256instance-norm, max-pool/2, reluinstance-norm, max-pool/2, reluinstance-norm, max-pool/2, reluinstance-norm, max-pool/2, relu1x1x1 conv, 64instance-norm, max-pool/2, reluinstance-norm, relu2x3x2, 3D-average-pooldropout (0.5)1x1x1 conv, 1Output (Brain Age)conv 1conv 2conv 4outputconv 3conv 6conv 5MRI Scan(1x91x109x91)3x3 conv, 32instance-norm, max-pool/2, reluOutput (Brain Age)conv 1conv 2conv 33x3 conv, 643x3 conv, 128instance-norm, max-pool/2, reluinstance-norm, max-pool/2, reluconv 4conv 53x3 conv, 2563x3 conv, 256instance-norm, max-pool/2, reluinstance-norm, max-pool/2, reluconv 6conv 71x1 conv, 641x1 conv, 32instance-norm, relu,3x22D-averagepool,dropout(0.5)91x, slice encoderSagittal Slice (1x109x91) embeddings, 91x32slice-mean-operationDense(64), relu, Dense(1)mean embedding, 1x32outputMembership Inference Attacks on Deep Regression Models for Neuroimaging
Features
D1
3D-CNN
D2
2D-slice-mean
D3
D1
D2
D3
Set 1
Set 2
Set 3
60.08 ± 0.06 (56) 57.75 ± 0.15 (30) 59.01 ± 0.34 (29) 58.15 ± 0.07 (56) 55.27 ± 0.03 (37) 58.55 ± 0.38 (24)
60.09 ± 0.06 (56) 59.97 ± 0.29 (30) 63.59 ± 0.35 (26) 58.04 ± 0.23 (56) 60.41 ± 0.22 (29) 63.73 ± 0.27 (25)
60.06 ± 0.04 (56) 61.00 ± 0.47 (28) 64.12 ± 0.52 (25) 58.11 ± 0.22 (56) 60.28 ± 0.73 (29) 63.81 ± 0.55 (24)
Table 3: Average membership inference attack accuracies on models trained using federated
learning for diﬀerent feature sets and distributions. The standard deviations are reported
over 5 runs. Number in parentheses indicate the median total number of successful attacks
over 5 runs.
Table Legend:
D1: Uniform & IID data distribution
D2: Uniform & non-IID data distribution
D3: Skewed & non-IID data distribution
Set 1: Gradient magnitude
Set 2: Gradient magnitude + prediction + label
Set 3: Gradient magnitude + prediction + label + gradient (conv 6 + output)
the attack vulnerabilities are not symmetric; for example, the accuracy of the attack from
L3 to L8, or L7 to L4 is higher than vice-versa, even though both learners have trained on
the same number of samples. Such diﬀerences may be due to the neural network’s tendency
to overﬁt diﬀerently over diverse local data distributions, in this case age ranges. An ad-
versary with some more privileged information like knowledge of the distribution of labels
or outputs may design more sophisticated attacks.
Appendix C. Attack Architecture and Training Details
C.1. Attack classiﬁer parametrization
We evaluate the importance of diﬀerent features derived from a sample and the trained
model for membership inference attacks. In the case of a black-box attack, the attacker
can only use the model’s output. In contrast, in the case of white-box attacks, the attacker
may also exploit the knowledge of the model’s internal working. We have used gradient and
activation information to simulate the attacks. We train deep binary classiﬁers that take
these features as input and output the probability of the sample being in the model’s train
set or not.
We repurpose the model’s architecture to create a binary classiﬁer for preliminary ex-
periments on using activations for attacks. For example, in Figure 6(a), when simulating
an attack that use activations from second hidden layer, i.e, after conv 2 layer, we used a
classiﬁer that had layers from conv 3 to output. However, as discussed in Section 4.1, the
activations are not very useful features for membership attacks. Thus we did not do further
experiments with activations.
17
Membership Inference Attacks on Deep Regression Models for Neuroimaging
Environment
3D-CNN
Uniform & IID
Uniform & non-IID
Skewed & non-IID
L1
L1
L2 59.68±0.20
L3 59.78±0.15
L4 59.92±0.26
L5 59.86±0.33
L6 59.98±0.30
L7 60.08±0.45
L8 59.09±0.30
L1
L1
L2 56.36±2.20
L3 32.76± 0.95
L4 32.05± 0.29
L5 72.28±0.19
L6 59.79±1.22
L7 31.96± 0.76
L8 32.88± 0.26
L1
L1
L2 67.90±0.60
L3 40.26± 0.50
L4 36.86± 0.08
L5 58.36±0.65
L6 67.88±2.40
L7 35.89± 0.54
L8 39.64± 0.19
L2
60.62±0.66
60.59±0.41
60.29±0.40
60.22±0.25
59.98±0.35
60.05±0.38
59.13±0.24
L2
56.20±1.44
49.15± 0.83
41.50± 0.10
54.02±0.15
62.71±0.56
49.26± 0.57
42.03± 0.79
L2
66.85±0.38
50.31±0.63
40.38± 0.20
51.96±1.05
60.44±4.63
42.13± 0.64
40.89± 0.12
L3
60.71±0.61
60.57±0.69
60.89±0.25
60.85±0.13
60.56±0.41
60.81±0.37
60.15±0.32
L3
38.34± 0.51
52.80±1.09
59.98±0.14
37.46± 0.34
51.31±0.95
64.98±0.20
59.64±1.24
L3
40.96± 0.26
50.38±0.50
60.66±0.76
36.82± 1.82
35.74± 2.27
64.86±0.43
53.93±0.43
L4
59.85±0.69
60.02±0.67
60.18±0.46
59.94±0.36
59.56±0.47