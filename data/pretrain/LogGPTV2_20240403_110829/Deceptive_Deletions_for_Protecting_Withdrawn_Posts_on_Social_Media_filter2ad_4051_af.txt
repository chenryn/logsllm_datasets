### Generating Decoy Posts on Twitter

Twitter posts are associated with persistent, non-anonymous user identities [31]. Uploading fake posts from real user accounts raises significant ethical concerns. Therefore, one approach is to create multiple bot accounts to upload machine-generated fake posts that can later be deleted. However, the detection of bot accounts is a well-studied problem [26], [30], [37], [40], [82], [86]. When an adversary detects a bot, any decoy post from that account will also be unmasked. Consequently, in non-anonymous platforms like Twitter, selecting decoy posts from the posts of actual users is a more practical approach.

### Acknowledgment

We would like to thank Z. Berkay Celik for his insightful suggestions on an early draft. We also extend our gratitude to Bo Lou and his team for providing part of the dataset used in our experimental section. This work was partially funded by the National Science Foundation (NSF) Awards CAREER IIS1943364, CCF-1918483, CNS-1719196, and by the ARO under the U.S. Army Research Laboratory contract number W911NF-09-2-0053. Additional support was provided by the Purdue Integrative Data Science Initiative, the Purdue Research Foundation, and the Wabash Heartland Innovation Network. The opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors.

### Conclusion and Future Work

In this paper, we demonstrate the necessity for deletion privacy by presenting an attack where an adversary can increase its performance (F-score) in identifying damaging posts by 56% compared to random guessing. Such an attack enables systems like Fallait Pas Supprimer to perform large-scale automated damaging deletion detection, leaving users in a "damned if I do, damned if I don't" dilemma.

To counter this attack, we introduce Deceptive Deletions (also denoted as the challenger), a new deletion mechanism that selects a set of non-damaging posts (decoy posts) to be deleted along with the damaging ones, thereby confusing the adversary. This creates a minmax game between the adversary and the challenger, which we formally describe as the Deceptive Learning Game. We also outline conditions for two extreme scenarios: one where the adversary always wins, and another where the challenger always wins. 

We show the practical effectiveness of the challenger over a real task on Twitter, where the bar is significantly raised against a strong adaptive adversary in automatically detecting damaging posts. Specifically, even when only two decoy posts are considered for each damaging deletion, the adversarial performance (F-score) drops to 65%, 42%, and 38% when the challenger has no access, restricted black-box access, and full black-box access, respectively. This indicates a significant improvement over the same adversary's performance (75% F-score) when no privacy-preserving deletion mechanism is in effect.

Our work paves a new research path for privacy-preserving deletions aimed at protecting against practical, resourceful adversaries. Additionally, our deceptive learning game can be adapted for current and future works in the domain of Private Information Retrieval [38], [47], [66], [69], which have a similar setting for injecting decoy queries to protect users' privacy. Furthermore, the challenger introduced in this work is considered honest and does not misuse the damaging deletions against users. Future work could explore distributed or federated protocols with multiple challengers and private multi-party computation [33], [76]–[78] to mitigate the complete trust in the challenger.

### References

1. “Snapchat,” https://www.snapchat.com/.
2. “Social book post manager,” https://chrome.google.com/webstore/detail/social-book-post-manager/ljfidlkcmdmmibngdfikhffffdmphjae.
3. “Twittereraser deletion service,” https://www.tweeteraser.com/statistics.
4. “Dust,” https://www.usedust.com/, 2016.
5. “SNL’s first Latina cast member is caught out deleting thousands of tweets, some of which were 'racist and offensive’,” http://www.dailymail.co.uk/news/article-3805356/SNL-s-Latina-cast-member-caught-deleting-thousands-tweets-racist-offensive.html, 2016.
6. “24 tweets Ed Sheeran will probably delete soon,” https://www.buzzfeed.com/mjs538/we-r-who-we-r-is-a-good-song-tho, 2017.
7. “The streaming APIs,” https://dev.twitter.com/streaming/overview, 2017.
8. “Streaming message types,” https://developer.twitter.com/en/docs/tweets/filter-realtime/guides/streaming-message-types, 2017.
9. “TrackMeNot,” https://cs.nyu.edu/trackmenot/, 2017.
10. “Tweetdelete,” https://www.tweetdelete.net/, 2017.
11. “TweetDeleter: Delete many tweets with one click!” https://www.tweetdeleter.com, 2017.
12. “Twitwipe,” http://twitwipe.com/, 2017.
13. “Collection of deleted tweets & annoying content,” https://twitter.com/fallaitpassuppr?lang=en, 2019.
14. “Cleaner for Instagram,” https://play.google.com/store/apps/details?id=ro.novasoft.cleanerig, 2020.
15. “Nuke Reddit history,” https://chrome.google.com/webstore/detail/nuke-reddit-history/aclagjkmidmkcdhkhlicmgkgmpgccaod, 2020.
16. “Pushshift,” https://pushshift.io/, 2020.
17. “Rate-limiting strategies and techniques,” https://cloud.google.com/solutions/rate-limiting-strategies-techniques, 2020.
18. “Removeddit,” http://removeddit.com/, 2020.
19. “What is rate limiting? — Rate limiting and bots,” https://www.cloudflare.com/learning/bots/what-is-rate-limiting/, 2020.

[Additional references follow the same format and are listed accordingly.]

This revised version aims to enhance clarity, coherence, and professionalism, ensuring that the text is well-structured and easy to follow.