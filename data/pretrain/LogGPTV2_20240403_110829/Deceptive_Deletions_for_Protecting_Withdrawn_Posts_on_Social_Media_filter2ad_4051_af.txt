Let us consider the case of generating decoy posts on
Twitter. Twitter posts are attached with a persistent non-
anonymous user identities [31]. Since, uploading fake posts
from real user accounts raises serious ethical concerns, one
should create multiple bot accounts that will upload machine-
generated fake posts to be used as decoy posts (by deleting
them later). However, unfortunately, detection of bot accounts
is a well studied problem [26], [30], [37], [40], [82], [86].
Moreover, when an adversary detects a bot, any decoy post
from that bot account will be similarly unmasked. Therefore,
in non-anonymous platforms like Twitter, selecting the decoy
posts from the posts of actual users is arguably a more practical
approach.
ACKNOWLEDGMENT
We would like to thank Z. Berkay Celik for insightful sug-
gestions on an early draft. We would also like to thank Bo
Lou and his team for providing part of the dataset used in
our experiment section. This work was funded in part by
the National Science Foundation (NSF) Awards CAREER
IIS1943364, CCF-1918483, CNS-1719196, and by the ARO,
under the U.S. Army Research Laboratory contract num-
ber W911NF-09-2-0053, the Purdue Integrative Data Science
Initiative, the Purdue Research Foundation, and the Wabash
Heartland Innovation Network. Any opinions, ﬁndings and
conclusions or recommendations expressed in this material are
those of the authors and do not necessarily reﬂect the views
of the sponsors.
VII. CONCLUSION AND FUTURE WORK
REFERENCES
latina cast member
“Snapchat,” https://www.snapchat.com/.
“Social book post manager,” https://chrome.google.com/webstore/
detail/social-book-post-manager/ljﬁdlkcmdmmibngdﬁkhffffdmphjae.
“Twittereraser deletion service,” https://www.tweeteraser.com/statistics.
“Dust,” https://www.usedust.com/, 2016.
“SNL’s ﬁrst
is caught out deleting thou-
sands of tweets, some of which were ’racist and offensive’,” http:
/ / www.dailymail.co.uk / news / article - 3805356 / SNL - s - Latina - cast -
member-caught-deleting-thousands-tweets-racist-offensive.html, 2016.
“24 tweets Ed Sheeran will probably delete
soon,” https : / /
www.buzzfeed.com/mjs538/we-r-who-we-r-is-a-good-song-tho, 2017.
“The streaming apis,” https://dev.twitter.com/streaming/overview, 2017.
“Streaming message types,” https : / / developer.twitter.com / en / docs /
tweets/ﬁlter-realtime/guides/streaming-message-types, 2017.
“Trackmenot,” https://cs.nyu.edu/trackmenot/, 2017.
“Tweetdelete,” https://www.tweetdelete.net/, 2017.
“Tweetdeleter: Delete many tweets with one
www.tweetdeleter.com, 2017.
“Twitwipe,” http://twitwipe.com/, 2017.
“Collection of deleted tweets & annoying content,” https://twitter.com/
fallaitpassuppr?lang=en, 2019.
“Cleaner for instagram,” https://play.google.com/store/apps/details?id=
ro.novasoft.cleanerig, 2020.
“Nuke reddit history,” https://chrome.google.com/webstore/detail/nuke-
reddit-history/aclagjkmidmkcdhkhlicmgkgmpgccaod, 2020.
“Pushshift,” https://pushshift.io/, 2020.
“Rate-limiting strategies and techniques,” https://cloud.google.com/
solutions/rate-limiting-strategies-techniques, 2020.
“Removeddit,” http://removeddit.com/, 2020.
“What
www.cloudﬂare.com/learning/bots/what-is-rate-limiting/, 2020.
rate limiting? — rate limiting and bots,” https : / /
click!” https : / /
is
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
In this paper, we show the necessity for deletion privacy by
presenting an attack where an adversary is able to increase
its performance (F-score) in identifying damaging posts by
56% compared to random guessing. Such an attack enables
the system like Fallait Pas Supprimer to perform large-scale
automated damaging deletion detection, and leaves users with
“damned if I do, damned if I don’t” dilemma.
To overcome the attack, we introduce Deceptive Deletions
(which we also denote as challenger), a new deletion mech-
anism that selects a set of non-damaging posts (decoy posts)
to be deleted along with the damaging ones to confuse the
adversary in identifying the damaging posts. These conﬂicting
goals create a minmax game between the adversary and the
challenger where we formally describe the Deceptive Learning
Game between the two parties. We further describe conditions
for two extreme scenarios: one where the adversary always
wins, and another where the challenger always wins. We also
show practical effectiveness of challenger over a real task
on Twitter, where the bar is signiﬁcantly raised against a
strong adaptive adversary in automatically detecting damaging
posts. Speciﬁcally, we show that even when we consider only
two decoy posts for each damaging deletion the adversarial
performance (F-score) drops to 65%, 42% and 38% where
the challenger has no-access, restricted black-box access and
black-box access respectively. This performance indicates a
signiﬁcant improvement over the performance of the same
adversary (75% F-score) when no privacy preserving deletion
mechanism is in effect. As a result, we signiﬁcantly raise the
bar for the adversary going after damaging deletions over the
social platform.
Our work paves a new research path for the privacy-
preserving deletions which aim to protect against a practical,
resourceful adversary. In addition, our deceptive learning game
can be adapted for current/future works in the domain of
Private Information Retrieval [38], [47], [66], [69] that have
a similar setting for injecting decoy queries to protect the
users’ privacy. Further, the challenger introduced in this work
is considered to be honest and to not misuse the damaging
deletions against the users. Considering distributed or federated
protocols with multiple challengers as well as private multi-
party computation [33], [76]–[78] can be a promising future
work to mitigate the complete trust of the challenger.
14
[20] H. Almuhimedi, S. Wilson, B. Liu, N. Sadeh, and A. Acquisti, “Tweets
are forever: A large-scale quantitative analysis of deleted tweets,” in
CSCW’13.
[21] Amazon, “Mechanical Turk,” https://www.mturk.com/mturk/welcome.
[22] P. Andr´e, M. Bernstein, and K. Luther, “Who gives a tweet?: Evaluating
microblog content value,” in CSCW ’12, 2012.
[23] E. Balsa, C. Troncoso, and C. Diaz, “Ob-pws: Obfuscation-based private
web search,” in Security and Privacy (SP), 2012.
[24] L. Bauer, L. F. Cranor, S. Komanduri, M. L. Mazurek, M. K. Reiter,
M. Sleeper, and B. Ur, “The post anachronism: The temporal dimension
of facebook privacy,” in ACM WPES ’13.
J. Baumgartner, S. Zannettou, B. Keegan, M. Squire, and J. Blackburn,
“The pushshift reddit dataset,” arXiv preprint arXiv:2001.08435, 2020.
[26] A. Bessi and E. Ferrara, “Social bots distort the 2016 us presidential
[25]
election online discussion,” 2016.
[27]
J. A. Biega, K. P. Gummadi, I. Mele, D. Milchevski, C. Tryfonopoulos,
and G. Weikum, “R-Susceptibility: An IR-Centric Approach to Assess-
ing Privacy Risks for Users in Online Communities,” in Proceedings of
the 39th International ACM SIGIR Conference, 2016.
[28] C. Castelluccia, E. De Cristofaro, A. Francillon, and M.-A. Kaafar,
“Ephpub: Toward robust ephemeral publishing,” in ICNP’11.
[29] M. D. Choudhury, S. Counts, E. Horvitz, and M. Gamon, “Predicting
depression via social media,” in Proceedings of AAAI Conference on
Weblogs and Social Media (ICWSM’2013), ser. ICWSM, 2013.
[30] Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia, “Detecting automation
of twitter accounts: Are you a human, bot, or cyborg?” IEEE Transac-
tions on Dependable and Secure Computing, vol. 9, no. 6, 2012.
[31] D. Correa, L. A. Silva, M. Mondal, F. Benevenuto, and K. P. Gum-
madi, “The Many Shades of Anonymity: Characterizing Anonymous
Social Media Content,” in Proceedings of The 9th International AAAI
Conference on Weblogs and Social Media, Oxford, UK, 2015.
[32] N. Dalvi, P. Domingos, S. Sanghai, D. Verma et al., “Adversarial
classiﬁcation,” in Proceedings of the tenth ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM, 2004.
J. Darivandpour and M. J. Atallah, “Efﬁcient and secure pattern
matching with wildcards using lightweight cryptography,” Computers
& Security, vol. 77, pp. 666–674, 2018.
[33]
[34] D. Dean and A. Stubbleﬁeld, “Using client puzzles to protect tls.” in
USENIX Security Symposium, vol. 42, 2001.
[36]
[35] E. L. Denton, S. Chintala, R. Fergus et al., “Deep generative image
models using a laplacian pyramid of adversarial networks,” in Advances
in neural information processing systems, 2015, pp. 1486–1494.
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv:1810.04805, 2018.
J. P. Dickerson, V. Kagan, and V. Subrahmanian, “Using sentiment
to detect bots on twitter: Are humans more opinionated than bots?”
in Proceedings of the 2014 IEEE/ACM International Conference on
Advances in Social Networks Analysis and Mining.
IEEE Press, 2014.
J. Domingo-Ferrer, A. Solanas, and J. Castell`a-Roca, “h (k)-private
information retrieval from privacy-uncooperative queryable databases,”
Online Information Review, vol. 33, no. 4, pp. 720–744, 2009.
[37]
[38]
[39] C. Dwork and M. Naor, “Pricing via processing or combatting junk
mail,” in Annual International Cryptology Conference. Springer, 1992.
[40] E. Ferrara, O. Varol, C. Davis, F. Menczer, and A. Flammini, “The rise
of social bots,” Communications of the ACM, vol. 59, no. 7, 2016.
[41] S. Garg, S. Goldwasser, and P. N. Vasudevan, “Formalizing data deletion
in the context of the right to be forgotten,” in EUROCRYPT, 2020.
[42] R. Geambasu, T. Kohno, A. Krishnamurthy, A. Levy, H. M. Levy,
P. Gardner, and V. Moscaritolo, “New directions for self-destructing
data,” University of Washington, Tech. Rep. UW-CSE-11-08-01, 2011.
[43] R. Geambasu, T. Kohno, A. A. Levy, and H. M. Levy, “Vanish:
Increasing data privacy with self-destructing data,” in USENIX, 2009.
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in neural information processing systems, 2014.
[44]
[45] M. Gutmann and A. Hyv¨arinen, “Noise-contrastive estimation: A new
estimation principle for unnormalized statistical models,” in AISTATS,
2010, pp. 297–304.
[46] K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward
networks are universal approximators,” Neural networks, 1989.
[47] D. C. Howe and H. Nissenbaum, “Trackmenot: Resisting surveillance
in web search,” Lessons from the Identity trail: Anonymity, privacy, and
identity in a networked society, vol. 23, pp. 417–436, 2009.
[48] B. A. Huberman, D. M. Romero, and F. Wu, “Social networks that
matter: Twitter under the microscope,” First Monday, vol. 14, no. 1,
2009, http://ﬁrstmonday.org/article/view/2317/2063.
[49] A. Java, X. Song, T. Finin, and B. Tseng, “Why we twitter: Understand-
ing microblogging usage and communities,” in WebKDD/SNA-KDD,
2007, http://dl.acm.org/citation.cfm?id=1348556.
J. Jia and N. Z. Gong, “Attriguard: A practical defense against attribute
inference attacks via adversarial machine learning,” in USENIX, 2018.
[50]
15
[51] C. Jin, P. Netrapalli, and M. I. Jordan, “Minmax optimization: Stable
limit points of gradient descent ascent are locally optimal,” arXiv
preprint arXiv:1902.00618, 2019.
[52] A. Juels, “Client puzzles: A cryptographic countermeasure against
connection depletion attacks,” in Proceedings of NDSS, 1999.
I. A. Kash, J. K. Lai, H. Zhang, and A. Zohar, “Economics of bittorrent
communities,” in Proceedings of the 21st international conference on
World Wide Web, 2012, pp. 221–230.
[53]
[54] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples in the
physical world,” arXiv preprint arXiv:1607.02533, 2016.
[55] C. Ledig, L. Theis, F. Husz´ar, J. Caballero, A. Cunningham, A. Acosta,
A. P. Aitken, A. Tejani, J. Totz, Z. Wang et al., “Photo-realistic
single image super-resolution using a generative adversarial network.”
in CVPR, vol. 2, no. 3, 2017, p. 4.
J. Maddock, K. Starbird, and R. M. Mason, “Using historical twitter
data for research: Ethical challenges of tweet deletions,” in CSCW 2015
Workshop on Ethics for Studying Sociotechnical Systems in a Big Data
World. ACM, 2015.
[56]
[57] E. V. Mangipudi, K. Rao, J. Clark, and A. Kate, “Towards automatically
penalizing multimedia breaches,” in IEEE European Symposium on
Security and Privacy Workshops (EuroS&PW), 2019.
[58] S. Mei and X. Zhu, “Using machine teaching to identify optimal
training-set attacks on machine learners.” in AAAI, 2015.
[59] A. Miller, A. Kosba, J. Katz, and E. Shi, “Nonoutsourceable scratch-off
puzzles to discourage bitcoin mining coalitions,” in Proceedings of the
22nd Conference on Computer and Communications Security, 2015.
[60] M. Minaei, M. Mondal, and A. Kate, “”my friend wanted to talk about
it and i didn’t”: Understanding perceptions of deletion privacy in social
platforms,” 2020.
[61] M. Minaei, M. Mondal, P. Loiseau, K. Gummadi, and A. Kate,
“Forgetting the forgotten with letheia, concealing content deletion from
persistent observers,” arXiv preprint arXiv:1710.11271, 2017.
[62] ——, “Lethe: Conceal content deletion from persistent observers,” vol.
2019, no. 1. Sciendo, 2019, pp. 206–226.
J. Mirkovic, G. Prier, and P. Reiher, “Attacking ddos at the source,”
in 10th IEEE International Conference on Network Protocols, 2002.
Proceedings.
IEEE, 2002, pp. 312–321.
[63]
[64] ——, “Source-end ddos defense,” in Second IEEE International Sym-
posium on Network Computing and Application.
IEEE, 2003.
[65] M. Mondal, J. Messias, S. Ghosh, K. P. Gummadi, and A. Kate,
“Forgetting in social media: Understanding and controlling longitudinal
exposure of socially shared data,” in USENIX SOUPS ’16.
[66] M. Murugesan and C. Clifton, “Providing privacy through plausibly
deniable search,” in International Conference on Data Mining, 2009.
[67] P. Papadopoulos, A. Papadogiannakis, M. Polychronakis, A. Zarras,
T. Holz, and E. P. Markatos, “K-subscription: Privacy-preserving mi-
croblogging browsing through obfuscation,” in Proceedings of the 29th
Annual Computer Security Applications Conference. ACM, 2013.
[68] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and
A. Swami, “Practical black-box attacks against machine learning,” in
Proceedings of Asia CCS, 2017.
[69] S. T. Peddinti and N. Saxena, “On the privacy of web search based
on query obfuscation: a case study of trackmenot,” in International
Symposium on Privacy Enhancing Technologies Symposium, 2010.
[70] ——, “On the effectiveness of anonymizing networks for web search
privacy,” in Proceedings of the 6th ACM Symposium on Information,
Computer and Communications Security. ACM, 2011, pp. 483–489.
[71] T. Pedersen, “Screening twitter users for depression and ptsd with
lexical decision lists,” in Proceedings of the 2nd Workshop on Com-
putational Linguistics and Clinical Psychology: From Linguistic Signal
to Clinical Reality, 2015, http://www.aclweb.org/anthology/W15-1206.
[72] A. Petit, T. Cerqueus, S. B. Mokhtar, L. Brunie, and H. Kosch,
in Trust-
IEEE, 2015, pp. 571–580.
[73] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,
“Language models are unsupervised multitask learners,” preprint, 2019.
[74] V. Raynauld, “The perfect political storm? the tea party movement, the
redeﬁnition of the digital political mediascape, and the birth of online
politicking 3.0,” Ph.D. dissertation, Carleton University, 2013.
“Peas: Private,
com/BigDataSE/ISPA, 2015 IEEE, vol. 1.