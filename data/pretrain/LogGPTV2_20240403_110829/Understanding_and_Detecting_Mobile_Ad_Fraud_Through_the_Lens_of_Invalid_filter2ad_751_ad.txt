IPs and device IDs.
The aforementioned discussion also largely demonstrates the
vast IP resources available to the click farm operators. Furthermore,
we note that it is unreliable to verify the invalid trac exclusively
based on IP distributions as recommended by the recent work [29].
Finding 4: The Android IDs have a common prex.
As discussed before, changing Android IDs is also a strategy
widely adopted by the click farm. This is because: (i) any Android
ID with too many ad bid logs is generally believed to be suspicious;
(ii) changing Android IDs can make the blocking list based invalid
trac ltering approach fail to work. This strategy has also been
applied to the identied click farm cluster, which involves 100, 001
Android IDs in ⇡2018.
                                                                                                                                                ANDROID_VER_CODE=["4.4.2","5.0.1","5.1.1","6.0","7.0","7.1.1"]DEV_BRAND=["OPPO","MST","CUI","SAMSUNG","YUS","ZTE","HTC","UMESI","DAXIAN","XIAOMI","VIVO","YTSP","MEIZHU","HUAWEI"]DEV_TYPE=["M56","PLUS5","Y11","L1","M7","N9","325p","MS16","PLUS6","F10","N11","NOTE3","8US","TUIP95","MTS6","S672","P8"]BUILD_CODE=["KTU84P","JOP40D","LMY47X","LMY48B","JZO54K","JDQ39","KOT49H","LRX21V","JLS36C"]UA=f"Mozilla/5.0(Linux;Android{ANDROID_VER_CODE[randint()%6]};"\f"{DEV_BRAND[randint()%14]}{DEV_TYPE[randint()%17]}"\f"Build/{BUILD_CODE[randint()%9]})"\f"AppleWebKit/537.36(KHTML,likeGecko)Version/4.0Chrome/30.0.0.0"\f"MobileSafari/537.36"Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea295Figure 10: An example of the UA generated by this click farm.
Surprisingly, we nd that in 2018, 100,000 out of 100,001 Android
IDs show a common pattern: they are the MD5 values of a determi-
nate string B = B1kB2, where B1 = “ad4b0d3f5fd” and B2 =“00000”,. . . ,
“99999”; the only exception is IDx = “ad4b0d3f5fdacd9b”. It is de-
rived that IDx is the Android ID of a real device, and all other
Android IDs were created by changing the last 5 digits of it and
computing the MD5 values. We conrmed this by looking into the
locations recorded in the logs, which showed that these devices
were in close proximity to each other. After discussing with Com-
pany A, one possible explanation is that the attackers intentionally
used this unique Android ID prex in 2018 as a piece of evidence to
request payment from the fraudulent publisher who endorses them
to launch the ad fraud campaign. However, in 2019, the Android
IDs did not exhibit such a pattern, indicating that the strategies
adopted by the attackers have evolved.
7.3 Cheating Strategy 3: Forging User Agents
User-Agent also includes much critical end-device system informa-
tion (e.g., Android version, device brand, build code, browser kernel
version), which can be exploited to ngerprint the fraudulent de-
vices. This observation drives the click farm devices to generate fake
UA elds to conceal their real system information through modi-
fying system conguration les, “/system/build.prop” [43], and
thus bypass the detection. As the rst step towards understanding
how to generate the fake UAs, we try to simulate fake User-Agent
generation in Python to enumerate all possible combinations of
UAs, as shown in Fig. 9. The attackers select items from predened
small sets for the 4 elds (Android version, device brand, device
type, and build code [2]) to conceal their critical system information
and avoid being blocked.
Finding 5: 3 types of UA fraud are identied.
We then perform a comprehensive analysis of the UA elds of
fraudulent devices in ⇡2018 and ⇡2019. We have detected the follow-
ing three UA frauds due to inconsistencies of the elds, which can
help us combat fraudulent devices in the future. In the following,
we use a real-world UA as an example, which was generated at
2:22:50 AM on March 23, 2018. As shown in Fig. 10, the Android
version is 7.1.1, the device brand is “SAMSUNG”, the device type is
“8US”, and the build code is “LRX21V”.
1) Chrome WebView vs. Android version. Chrome WebView is an
embedded edition of Chrome browser as a non-degradable system
component in each version of the Android system. The version
(30.0.0.0) was born with Android 4.4 [1] and the updated WebView
shipped with Android 4.4.3 has version number 33.0.0.0. It is indi-
cated in [1] that WebView will auto-update for mobile devices with
Android L (Android 5.0) and above. In other words, a new Android
version with an old Chrome WebView version is highly suspicious.
This serves as a strong indicator to identify the fraudulent devices
by checking the inconsistency of UA and Android versions. In the
example of click farm UA, Android 7.1.1 corresponds to WebView
(a) 2018
(b) 2019
Figure 11: Log number proportions of the apps in 2018 and
2019. For each day, the height of the dashed lines separated
by dierent colors represents the log numbers belonging to
dierent apps. There are no overlapping apps between two
years.
version 52.0.2743.100, which is inconsistent with the old WebView
version 30.0.0.0 (Fig. 10).
2) Device brand vs. device type. The second observation is that the
device brand and type elds in the click farm UAs are randomly
generated, which leads to non-existent device brand/type pairs,
such as “SAMSUNG 8US” in the example click farm UA showed in
Fig. 10. Importantly, we ascertain that, in the identied click farms,
most of the UA elds are evidenced to be forged, such as “HTC
M56”, “DAXIAN Y11”, “UMESI 325p”.
3) Android version vs. build code. Android version and build code
are in a one-to-many relationship, which can be used to check
the forged UAs. In the UA example above, “LRX21V” is the build
code for “android-5.0.0_r7” according to the list [2], which falsely
combines with the Android version of 7.1.1.
In summary, UA provides a plethora of useful information to
determine the nature of a device to be either benign or fraudulent.
7.4 Cheating Strategy 4: Rotating Apps
To avoid massive ad bid requests targeting only one app and being
banned by the ad platform, the fraudsters have developed dozens
of apps and dynamically changed the apps to run the ad campaign,
which will provide economic incentives for the fraudsters.
Finding 6: The apps are uniformly rotated after 3⇠4 days.
We investigate the proportion of log numbers for 18 apps in-
volved (9 selected apps in 2018 and all the 9 apps in 2019) and plot
their transition ows, which are shown in Fig. 11a and Fig. 11b.
It is observed that click farms do not generate invalid trac for
a xed app. Instead, ad spam campaigns have been intentionally
launched on dierent apps from one to another. It regularly takes a
certain period to run the ad spam campaign (or rotating period) for
each app. Averagely, the length of the period is about 3⇠5 days. For
example, 2 apps were activated on March 21, 2018, and deactivated
3 days later, meanwhile, 3 new apps were activated on March 23,
2018. The remaining 13 apps in 2018 and all the 9 apps in 2019
show the same characteristics. We checked the Android app market
Mozilla/5.0 (Linux; Android 7.1.1; SAMSUNG 8US Build/LRX21V) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/30.0.0.0 Mobile Safari/537.36*******Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea296and, interestingly, all of these apps were developed by the common
developer. After our manual check, all of these apps do not have
any special or practical functionality. It is reasonable to assume that
the only purpose of these apps is to run the ad spam campaign. This
is also supported by another fact that these apps have not received
any updates since being published on the market.
We also apply EH to the full datasets containing ⇡2018,
to investigate how invalid trac impacts top 50 apps in the 10-day
dataset of 2018 (Appendix C).
8 REAL-WORLD DEPLOYMENT
In this section, we will discuss how to implement EH in
real-world applications. As we mentioned in the introduction, in
the industry, the major challenge comes from how to address the
massive data (e.g., over 50M devices and 100M logs per day) in a
reasonable period (e.g., less than 1 day for daily clearance). We pro-
pose several techniques to speed up the execution of EH,
in order to support the verication of billions of ad bid requests in
an industrial environment. After applying optimization, we apply
EH to an in-the-wild dataset ⇡2021 and compare the result
with state-of-the-art industry methods. The acknowledgments from
our industrial collaborator show that EH can complement
existing industry methods, and is practical to be used in real-world
scenarios.
8.1 System Optimization
In the trac verication industry, it is required to process and detect
invalid trac on a daily basis. Thus, the time cost of processing
daily data should be within several hours. In the implementation of
Stage 2, a naive method is to compute similarities between each pair
of devices and then construct a complete graph. However, such a
pair-wise comparison suers from the scalability issue. Considering
hundreds of millions of active devices in the advertising system
every day, if we are going to apply the naive method, we need to
perform $(1015) computation to construct the whole graph, which
is unacceptable in practice.
8.1.1 Optimization techniques. In the following, we propose
three optimization techniques corresponding to the three steps in
stage 2 to address the computation challenges.
1) Merging devices. In Module 2.1 Top-App Extractor, since all devices
are represented by their top-app features, we can naturally put the
focus on distinct features instead of distinct devices. It is observed
that in ⇡2020, only a very small proportion of devices (0.25%) have
dierent labels but share the same top-app features. Meanwhile,
the number of distinct features is much smaller than the number
of devices (62=), which is not ecient
enough for large-scale applications. Therefore, we need tond
ways to speed up the computation. The input of Community Detector
is all the vertices and edges. It is observed that in a large graph,
the results of disconnected sub-graphs do not inuence each other.
We make use of this and divide the problem into sub-problems,
and solve them in parallel to increase eciency. After pruning in
similarity computation, the result is a collection of graphs. First, we
separate the graphs into groups that have the same top-1 app: each
group contains multiple graphs, and all the nodes in graphs of the
same group have the same top-1 app. Then, we process the groups
in parallel, since there is no dependency among them. Finally, we
collect the community detection results from all the groups. This
helps us to reduce the processing time from over 48 hours to 40
minutes in daily data processing.
8.1.2 Evaluation after optimization. We study how the opti-
mization improves the performance of EH, and how it
impacts the correctness of EH.
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2971) Performance improvement. We evaluate the performance of E
H prior to and post-optimization using ⇡2021, which con-
tains 1-day data (53M devices and 117M logs) in 2021. Stage 1 takes
roughly 10 minutes; Stage 3 takes 30 seconds. For Stage 2, Module
2.1 Top-App Extractor takes 4 minutes. For Module 2.2 Device Graph
Constructor and Module 2.3 Community Detector, before optimiza-
tion, each of them cannot terminate within 48 hours, respectively;
after optimization, they are able to produce results after 48 minutes
and 40 minutes, respectively. Therefore, EH can process
1-day’s data within 2 hours after optimization, which meets the
practical requirement for daily execution. The performance speedup
is more than 28x.
2) Correctness. We also evaluate the potential impact of the optimiza-
tion with regard to correctness. We randomly select 1,000 vertices
(including 21,191 devices) from ⇡2021 and apply EH prior
to and post-optimization. The nal detection results show that
there are only 48 devices (0.22%) with dierent labels. Therefore,
the optimization steps increase the system eciency by more than
28x, while incurring little loss (0.22%) on the potential correctness,
which is acceptable.
8.2 Result Validation
By following the IVT Detection and Filtration Standard [24], indus-
try leaders develop their own detection systems to detect several
known types of invalid trac. The dierent types of invalid trac
are labeled by dierent fraud reason codes. To date, there is no spe-
cic fraud reason code for detecting click farms, which is the major
advantage of EH. We deploy EH on 1-day’s real-
world ad trac data in order to test the practicality of EH.
Dataset. We use the ad bid logs in one day (Jan 13, 2021) collected
from the real world as our dataset ⇡2021. This dataset contains 53M
devices and 117M logs in total.
Results. EH detects around 8 million (15%) fraudulent
devices out of totally 53 million active devices in ⇡2021. These
devices generate 37 million (31%) fake bid requests. After Stage 3,
there are 23,604 clusters, wherein 5,164 clusters have more than 50
devices, and 491 of them are fraudulent clusters.
Comparison with the detection results of Company A. Since
there is no existing industrial system targeting click farm detec-
tion, here we use the detection result of the industrial system of
Company A, to compare and analyze our result. We nd that 93%
of the detected invalid trac by EH is not detected by
Company A’s existing detection system. This undetected invalid
trac is originated from click farms. We have manually checked
the top 30 click farms containing 5,941,433 devices in total, which
contribute to more than 74% of the detected fraudulent devices.
We nd similar cheating strategies from them as revealed in Sec. 7.
Among the 30 click farms, there are 9 click farms that only use IPs
from small centralized areas, which contain 329,287 devices (5.5%)
in total; there are 14 click farms (3,434,208 devices, 57.8%) rotating
IPs and device IDs to evade IP/ID ltering. Note that there are 4 click
farms (299,186 devices, 5.0%) that use both two strategies. These
19 click farms are conrmed by Company A, who has adopted our
proposed algorithm as a new fraud reason code in their platform.
We also investigate the other 11 detected fraudulent device clus-
ters. Among them, there are potentially 5 falsely detected clusters:
1) 4 of them contain only Android TV devices, which exhibit dier-
ent behaviors from Android phones; 2) another cluster has dierent
UA elds compared to the normal ones. These UAs are from true
Android devices but start with specic values (e.g., bundle ID) in-
stead of Mozilla or Dalvik. So they are agged by EH.
There remain 6 detected device clusters whose cheating patterns
are not so obvious. They are expected to be double-checked by
Company A using auxiliary information.
Consensus with other companies. In addition, we have reported
the device IDs and IPs of the detected click farms to the blockchain-
based consensus system. They are expected to be cross-checked by
other companies in the future.
9 DISCUSSION
EH update. To deploy EH and ensure that it
captures state-of-the-art ad fraud, we need to periodically collect
new ground truth data and retrain the Stage 1 classier of E
H. This can be achieved by integrating EH with an
active learning approach. For example, we can periodically collect
the prediction results of new devices and reuse them with two op-
tions: 1) For the devices with high prediction condence, we can
directly use them as the training dataset to retrain the classica-
tion model. 2) For the other devices with low condence, we can
manually label the devices using auxiliary information or other
existing tools. We show a simplied update process using ⇡2020
in Appendix B to demonstrate the practicality and eectiveness of
updating EH per week.
Impact of privacy regulations. To enhance privacy and adhere
to General Data Protection Regulation (GDPR), more elds of the
ad transaction data are expected to be encrypted or removed, ren-
dering the trac verication to be more challenging due to a lack
of necessary data. However, we argue that completely removing
all elds of the ad data is less likely to happen in the near future
because it challenges the current user prole based Internet ad
ecosystem. Therefore, it is desirable to have a more strict data au-
thorization and access control and limit the data to a small number
of highly qualied trac verication companies and their trusted
research partners. We also attempt to investigate dierentially pri-
vate programmatic ad auctions and this deserves separate research.
Open-source datasets. We are in the process of negotiation with
our industrial collaborator to release the datasets used in the paper.
Once approved, we will release the ad bid logs of fraudulent devices
to facilitate future research.
Limitations. EH shows a good performance in detect-
ing fraudulent devices generating invalid trac, but EH
mainly focuses on performing the trac analysis towards the ad
bid network; there might exist approaches that can perfectly mimic
the trac originating from the benign devices, which can be used
to evade our detection. However, in order to create such “perfect”
invalid trac, the attackers need to invest a signicant amount of
resources to make all features undetectable, which makes it hard
to make a prot. It is important to note that the eectiveness of
EH can be further improved if we combine it with other
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea298ad fraud mitigation techniques, such as trac authentication, hon-
eypots, and dynamic fraud testing.
Additionally, EH can only be used to detect fraudulent
Android devices. Detecting fraudulent devices running iOS is hard
for two reasons: 1) Apple has restricted the IDFA permission since
iOS 14, which makes it harder to uniquely trace an iOS device in
the ad ecosystem; 2) the invalid trac samples originated from iOS
devices are relatively small, due to the diculty of jail-breaking
and hijacking iOS devices. We leave a thorough study of invalid
trac from iOS devices as our future work.
10 RELATED WORK