website, and Dropbox which stores a piece of data to later be
fetched.
Approach Typical solutions to this problem would have Alice
alter her traffic patterns while visiting the website, in the hopes
of confusing the adversary’s attempts at fingerprinting. Instead,
in Bento, Alice can offload processing that would have typically
happened on her own machine to another node in the Tor network.
Figure 1 depicts this; we next describe each step at a high level.
Writing a Function First, Alice writes (or, more likely, downloads)
what we call a function: a (typically small) piece of code in a high-
level, powerful language that is intended to be run on other Tor
nodes. These functions can be powerful, but they are constrained
to a limited API. Also, critically, they run outside of unmodified
Tor—in essence, they are like small servlets running on Tor routers.
In our example, Alice’s function, Browser, is a program that takes
as input a URL to download. Upon being invoked with its input, the
function starts a web client, autonomously downloads her chosen
URL, saves it to a single digest file (e.g., a tarball), and returns the
file, padded to the nearest 1MB.
Deploying a Function In Bento, some Tor nodes opt into acting as
middlebox nodes, who are willing to run (some) functions on behalf
of other users. Much like exit nodes, middlebox nodes publicly
specify a policy of what function properties they are and are not
willing to support. Alice chooses a middlebox node who would
be willing to run her function, opens a circuit to it, and, with its
permission, installs the function on it.
Executing a Function Once the function is deployed, Alice sends
a message over the Tor circuit to the middlebox node to invoke
the function on the URL of the site she wishes to visit. Upon re-
ceiving this message, the middlebox node executes the function:
it downloads the website, packages it into a padded archive, and
sends that back to Alice, over the circuit. The attacker observing
Alice’s communication sees two small uploads from Alice (when
she installs the function and when she invokes it), followed by a
large download (the padded website). Thus, because Alice is not
actively involved during the download of the website, the attacker
cannot gain any of the informative traffic dynamics that prior fin-
gerprinting techniques require in order to work.
Composing Functions To further thwart the attacker, Alice de-
cides to go offline completely during the website download. To
achieve this, she composes two functions together, as shown in
Figure 2. In addition to Browser, she also instructs the Browser
function to deploy, on a separate node, a simple Dropbox function
ClientInternetBrowse2Run function1Upload and invoke function3Deliver websiteClientInternetBrowse2Run Browse1Install Browse+DropboxInstall Dropbox; Put data4Fetch3DropboxTor circuitsPoster CCS '20, November 9–13, 2020, Virtual Event, USA2110Function
Browser
Cover
LoadBalancer
Dropbox
Shard
Description
Runs an application-layer web proxy at the exit node, and delivers padded contents to the client.
Instruct desired relay to create a number of circuits; send cover traffic through each new circuit.
Balance incoming connections among hidden service hosts.
Allows a node to deposit data; only the node with a matching token can retrieve the data.
Takes in a file, breaks it into shards, and encrypts each shard.
Problem Solved
Website fingerprinting
Circuit fingerprinting
Increased capacity, reliability
Traffic correlation
Anonymity, low storage
Table 1: Example middlebox functions.
that supports two invocations: a “put” of a data file and a subse-
quent “get” to retrieve it. Alice then instructs the Browser function
to deliver the (padded) file to Dropbox rather than directly to her.
Some time later, she visits the Dropbox node to fetch the data. From
the perspective of an attacker who can sniff Alice’s link, not only
would she not provide activity that could be fingerprinted: she need
not be online at all while the website was being downloaded!
Why This Helps These motivating use cases show that, with just
simple programs, a user could significantly extend the capabilities
of the Tor anonymity network. We give examples in Table 1 of
a wider variety of functions, which make hidden services more
robust, provide cover traffic when needed, and more. However, to
responsibly achieve this vision, we must adhere to a set of safety
and reliability goals, which we outline next.
3 BENTO GOALS
We have four main goals and one non-goal when designing Bento to
ensure safe and secure deployment of our programmable functions:
Expressiveness We wish to empower users to write (or use) so-
phisticated, composable functions. We make use of a high-level
programming language with no inherent limitations.
Protect functions from middlebox nodes We must protect users’
functions against confidentiality and integrity attacks on untrusted
third-party middleboxes. This is similar to the large body of work
on making safe use of untrusted third-party compute resources like
cloud computing [3] or even Tor itself [7]. To achieve these, we
employ recent advances in deploying legacy software in trusted
secure enclaves [5].
Protect middlebox nodes from functions We must also protect
the users who run the middlebox nodes. Much like how Tor relays
can express the destinations for which they wish to serve as exit
nodes, middlebox nodes should be able to express policies over the
actions they do and do not wish to perform on behalf of other users.
Our solution is middlebox node policies, which allow middlebox
operators to specify which system calls to permit, and how many
resources to provide to functions. We aim to enforce these policies
by mediating access to all resources.
No Harm to Underlying Tor Deploying Bento should cause no
degradation to the existing anonymity properties of Tor. Our func-
tions run on top of Tor, and interface with it via the Stem library.
No Extensions to Tor We aim to sit on top of Tor, and to require no
additional user privileges, so as to support more robust applications.
4 CONCLUSIONS
In this work, we have argued that programmable anonymity net-
works are useful, possible, and challenging, yet attainable. We have
sketched an example application and various challenges, as well as
some possible avenues to achieve them. Our proposed applications
suggest that even a small amount of programmability would signifi-
cantly improve the speed at which new techniques can be rolled out
into the Tor network; for instance, load balancing at introduction
points has been a proposal for years, but would be a trivial snippet
of code in a more programmable Tor network.
There remain many interesting and important problems that
must be solved in order to achieve programmable anonymity net-
works. We view this work as merely the first step, and we hope that
it engenders a lively discussion among the anonymity community
as well as application developers who wish to expand the offerings
possible on anonymity networks.
ACKNOWLEDGMENTS
This work was supported in part by NSF grants CNS-1816422, CNS-
1816802, and CNS-1943240.
[5] Stephen Herwig, Christina Garman, and Dave Levin. 2020. Achieving Keyless
REFERENCES
[1] Masoud Akhoondi, Curtis Yu, and Harsha V. Madhyastha. 2013. LASTor: A
Low-Latency AS-Aware Tor Client. In IEEE Symposium on Security and Privacy.
[2] Xiang Cai, Rishab Nithyanand, Tao Wang, Rob Johnson, and Ian Goldberg. 2014.
A Systematic Approach to Developing and Evaluating Website Fingerprinting
Defenses. In ACM Conference on Computer and Communications Security (CCS).
[3] Michael Coughlin, Eric Keller, and Eric Wustrow. 2017. Trusted Click: Over-
coming Security issues of NFV in the Cloud. In ACM International Workshop on
Security in Software Defined Networks & Network Function Virtualization (SDN-
NFVSec).
[4] Roger Dingledine, Nick Mathewson, and Paul Syverson. 2004. Tor: The Second-
Generation Onion Router. In USENIX Security Symposium.
CDNs with Conclaves. In USENIX Security Symposium.
[6] Aaron Johnson, Chris Wacek, Rob Jansen, Micah Sherr, and Paul Syverson. 2013.
Users get routed: Traffic correlation on Tor by realistic adversaries. In ACM
Conference on Computer and Communications Security (CCS).
[7] Seong Min Kim, Juhyeng Han, Jaehyeong Ha, Taesoo Kim, and Dongsu Han. 2017.
Enhancing Security and Privacy of Tor’s Ecosystem by Using Trusted Execution
Environments. In Symposium on Networked Systems Design and Implementation
(NSDI).
[8] Albert Kwon, Mashael AlSabah, David Lazar, Marc Dacier, and Srinivas Devadas.
2015. Circuit Fingerprinting Attacks: Passive Deanonymization of Tor Hidden
Services. In USENIX Annual Technical Conference.
trouble-with-tor/.
[9] Matthew Prince. [n.d.]. The Trouble with Tor. https://blog.cloudflare.com/the-
[10] Reporters Without Borders. 2013.
Enemies of the Internet 2013, Re-
port. http://surveillance.rsf.org/en/wp-content/uploads/sites/2/2013/03/enemies-
of-the-internet_2013.pdf.
[11] Max Schuchard, John Geddes, Christopher Thompson, and Nicholas Hopper. 2012.
Routing Around Decoys. In ACM Conference on Computer and Communications
Security (CCS).
[12] R. Soule, S. Basu, P. J. Marandi, F. Pedone, R. Kleinberg, E. G.Sirer, and N. Foster.
2014. Merlin:A Language for Provisioning Network Resources. In ACM Conference
on emerging Networking EXperiments and Technologies (CoNEXT).
https:
//www.torproject.org/docs/hidden-services.html.en.
[13] Tor: Hidden Service Protocol [n.d.]. Tor: Hidden Service Protocol.
Poster CCS '20, November 9–13, 2020, Virtual Event, USA2111