the industrial setting and the need for strong security and privacy
challenge the establishment of a widely-accepted exchange platform.
3 DESIGN GOALS
Based on the description of our considered scenario, we now derive
a set of five distinct design goals, which must be considered by any
concept that proposes an exchange of process parameters. These
goals summarize the needs of the individual participants (G1 and
G2) as well as universal conceptual requirements (G3, G4, and G5).
G1: Provider Privacy. Companies offering their process param-
eters to other companies still have a strong desire to maintain their
privacy and data secrecy as the combined information of offered
data can reveal internal information. For example, in our injection
molding use case, knowledge about the data provider correlated
with shared geometry parameters could result in the identification
of specific parts and, thereby, reveal highly sensitive information
about the implemented production processes and the company’s
customers. Thus, data providers mandate that access to their data is
only granted in parts and only to authorized parties. Furthermore,
as long as data providers do not share provider-identifying infor-
mation voluntarily, they must remain anonymous for all clients.
G2: Client Privacy. Protecting the client’s requests is just as
important for the success of a process parameter exchange. First,
data providers must not be able to attribute the requested data items
to the client. Otherwise, information on new developments might
Figure 1: An exchange of process parameters between com-
panies illustrated based on the use case of injection molding.
how companies can profit. Thereby, (1) clients query parameters of
similar processes from (external) data providers, (2) data providers
curate matching parameters from their own production and (3)
send these results back to the client which can enhance both their
(4) modeling, e.g., integrating more real-world process data, as well
as (5) production, e.g., utilizing well-fitting configurations.
Need for a Suitable Approach. Today, companies already col-
lect much process information [44], i.e., they own data that is po-
tentially also relevant for other companies. However, the lack of
suitable data security mechanisms, missing opportunities to gain
benefits from sharing data, and the fear of leaking sensitive business
secrets, i.e., information leaking know-how of a company, manifests
the existing silo mentality [33, 72]. Simply making all information
freely accessible is no option in competitive environments.
Contrary to work in the medical domain [41, 78, 93, 95], where
usually a single stakeholder offloads data to an untrusted cloud
(with 𝑚 stakeholders querying information), we consider a setting
where multiple stakeholders offload their data and multiple (other)
stakeholders query information. To retain the utility of information,
opposed to best practices when handling sensitive user data [81],
we cannot anonymize data records when serving them in the cloud.
Hence, companies need suitable ways to ease the exchange of
process parameters without leaking confidential data and to intro-
duce a quid pro quo for data providers for motivation to share their
data even with potential competitors. Instead of simply retaining
their process information in local data silos, companies could sell
their data, which is collected anyway, to third parties which them-
selves want to reduce their costs by utilizing this information, e.g.,
by performing process optimization using this shared information.
2.3 Scenario Challenges
Based on the need for a privacy-preserving exchange of production
data, we now highlight scenario-specific challenges. While the most
crucial aspects concern privacy and information security, further
challenges are related to the operation of such a data exchange.
Crucial Properties. The most crucial properties directly fol-
low from the competitive environment. As companies are notori-
ously cautious [72], they intend to only share specifically requested
datasets [33] while preserving long-term security [13], i.e., data
requests must be specified precisely. Consequentially, a global cata-
log of existing data or a way to browse available data items must
not exist. Thereby, data providers do not to lose control of their
offered data while monetizing its usage. Furthermore, requesting
companies, i.e., clients, want to utilize external information for their
benefits, e.g., to improve their production processes, and do not
Similar ParametersTransfer LearningInjection MoldingClientInjection MoldingData Provider(s)ModelingProductionEmpiricalTestingParameter(s)Measured ParametersQuery SimilarProcess Parameters13245IntersectionACSAC 2020, December 7–11, 2020, Austin, USA
Pennekamp et al.
efficient possibility to extract a list of all inserted elements [7]. Apart
from insertions, Bloom filters support membership tests that check
whether a specific element was inserted. Due to its probabilistic
property, such queries can return false positives with a tunable
false positive (FP) rate 𝜀. However, false negatives cannot occur.
𝑛)𝑘𝑚)𝑘.
A Bloom filter 𝐵 consist of an array with fixed length 𝑛 and uses 𝑘
hash functions (ℎ1, . . . , ℎ𝑘) to map elements to the individual fields
of the array. Inserting an element 𝑥 works by setting 𝐵[ℎ𝑖(𝑥)] =
1∀𝑖 ∈ {1, . . . , 𝑘}. Consequently, querying an element 𝑦 equals a
bitwise comparison of ℎ𝑖(𝑦) ∀𝑖 ∈ {1, . . . , 𝑘} with 𝐵. Taking the FP
rate into account, 𝑦 was inserted in 𝐵 if all set values in ℎ𝑖(𝑦) ∀𝑖 ∈
{1, . . . , 𝑘} are set in 𝐵 as well. The FP rate 𝜀 can be computed based
on the number of stored elements 𝑚, the length 𝑛, and the number
of hash functions 𝑘 [70]: 𝜀 = (1 − (1 − 1
Adjusting the individual parameters (e.g., to reduce 𝜀) influences
the storage size as well as the processing of insertion and querying.
Oblivious Transfer (OT). OTs allow a client (receiver) to re-
trieve one of two items from a server (sender) without the server
knowing which of the items has been transferred [29, 60]. After the
OT, the receiver has access to a single item only and is unaware
of the other. This basic form is also called 1-out-of-2 OT. Several
additions enable more sophisticated scenarios: 1-out-of-𝑛 OTs or
𝑘-out-𝑛 OTs [18]. For improved performance, a few expensive base
OTs can seed a large number of less expensive OT extensions [3].
To achieve the required security, i.e., hiding the contents of the
data transfer, significant computational overhead and communica-
tion are introduced [51]. While the trade-off between computations
and communication is adaptable, OTs are still costly, and, thus,
cannot be used to efficiently transfer large amounts of data.
Private Set Intersection (PSI). PSI is a cryptographic building
block that allows two parties to calculate the intersection of two
confidential sets without revealing included elements [25]. Depend-
ing on the concrete implementation, only one or both parties learn
the content or the size of the intersection [22]. To realize PSIs, dif-
ferent cryptographic concepts have been utilized. For improved
security, many efficient designs utilize OTs [42, 67]. Similar to OTs,
PSIs also suffer from overhead with increasing set sizes.
5 BPE: A BLOOM FILTER-BASED EXCHANGE
In this section, we propose BPE, a novel privacy-preserving Bloom
filter-based production process Parameter Exchange for companies.
5.1 Notation for the Exchange of Parameters
To provide a more formal understanding, we first introduce the un-
derlying foundations of any offloaded record and potential queries.
A parameter record 𝑝 = 𝑥 ∥ 𝑦 = 𝑥1, . . . , 𝑥𝑛, 𝑦1, . . . 𝑦𝑚 consists of
a payload 𝑦 and a number of (identifying) parameters 𝑥𝑖. Here, 𝑥
can correspond to a part that should be manufactured at a specific
machine while 𝑦, for example, represents used machine settings.
The respective indexing is defined by 𝑋 → 𝐻 : ℎ𝑘(𝑥′
, ..., 𝑥′
𝑛) = 𝑖𝑑𝑥′
with a use case-specific rounding function 𝑟(𝑥𝑖) = 𝑥′
𝑖 (cf. Appen-
dix A.1) to derive its input, i.e., we apply a binning to match related
records to the same index. Both ℎ and 𝑟 are globally defined by the
exchange platform. We derive 𝑖𝑑𝑘𝑥′ ∈ 𝐾 as truncation of 𝑖𝑑𝑥′ ∈ 𝐻,
for the indexing of AES encryption keys 𝑘𝑥′, i.e., the encryption key
can be derived using the identifying parameters 𝑥𝑖 only. Records
1
Figure 2: Apart from design-specific goals, any suitable ex-
change platform has to especially consider G1 and G2.
be identifiable and directly linked to a company. Second, the request
generation, i.e., the metric identifying meaningful data items, must
remain private. In a production landscape with ubiquitous data
exchanges, such knowledge constitutes the competitive advantage
as the individual parameters can be considered a common good.
G3: Deployability. In terms of realizing a real-wold exchange,
two main aspects are crucial. On the one hand, requests must allow
for a flexible matching, i.e., clients can use any metric they like to
identify meaningful data items and must be able to request these
identified data items. Hence, this metric can neither be part of the
exchange, nor should it be public during the exchange (cf. G2). On
the other hand, to incentivize data providers to offer their valuable
data, a billing mechanism is required to enable new business models.
Finally, providers must not be required to remain online all the time,
i.e., client requests can be handled without their active involvement.
G4: Performance. As privacy-preserving designs usually in-
cur a performance overhead, the overall performance should still
be reasonable and appropriate for the respective use case, i.e., it
should not outweigh the potential benefits. However, specifying
concrete constraints is counterproductive since performance limits
can always depend on the importance of exchanged data, i.e., very
valuable data can justify significant resource needs. Similarly, intro-
duced hardware and network requirements should be reasonable
as well, i.e., ideally, commodity devices are sufficient to participate.
G5: Adaptability. Along with the previous goals of privacy (G1
and G2) and performance (G4), adapting the trade-off between
security and performance must be considered. Some data is more
sensitive than others and should be treated accordingly, i.e., a con-
cept to deal with these situations should be offered to optimally
address the trade-off while minimizing the number of changes.
These design goals are critical to realize a parameter exchange. We
provide an overview of our use case-independent scenario in Figure 2
along with the design goals and the exchanged messages. Any proposed
design must provide a concept of how to connect clients with relevant
data providers. In particular, it must realize the functionality, which
we illustrate with a cloud, while addressing the presented design goals.
4 PRELIMINARIES
To establish a common background of our utilized building blocks,
we briefly introduce their concepts in this section. Namely, we rely
on Bloom filters and oblivious transfers (OTs) as components of
our design and optionally on private set intersections (PSIs) for a
variation that offers improved security guarantees (cf. Section 8.2).
Bloom Filter. A Bloom filter is a probabilistic and space-efficient
data structure that allows for efficient membership tests without an
ClientData Provider 1Data Provider nExchangePlatformG1: Provider PrivacyG1: Provider PrivacyG2: Client PrivacyG3: DeployabilityG4: PerformanceG5: AdaptabilityRelevant ItemsAvailable ItemsLocally Compute Similarity MetricKnown ParametersPayment for Items Known ParametersPayment for Items Obliviously MatchParameters with QueriesPrivacy-Preserving Production Process Parameter Exchange
ACSAC 2020, December 7–11, 2020, Austin, USA
After these three phases, the client is oblivious of data-sharing
providers (cf. G1), and assuming a proper billing mechanism, the
selling provider cannot identify the purchaser either (cf. G2). Fur-
ther, the client’s valuable similarity metric is kept private as the
client locally computes the matching (cf. G2). As all items are en-
crypted, the storage server is unaware of the mediated records (cf.
G1 and G2). Moreover, the key server is oblivious of requested and
transferred keys given that the respective communication places
via OTs (cf. G1 and G2). Finally, computationally expensive tasks
are mostly run at the client or data providers keeping the total
utilization of our platform providers comparatively low (cf. G4).
5.3 Entities and Trust Assumptions
Next, we detail all four involved entities to clearly understand their
individual responsibilities, interactions, and trust relationships as
well as how our platform incorporates their individual interests.
Data Provider(s). Given that potential providers invest resources
when collecting parameter records [1, 30, 38] and possibly share
their know-how with business partners or competitors, they are
only willing to contribute against compensation [94], e.g., pay-
ments, and despite a required participation overhead. Furthermore,
the data provider’s identity and valuable provided data must be
protected, i.e., no third party may get access to all records. To this
end, in our platform, we separate key material and ciphertexts by
relying on two non-colluding operators. To reward the provider, our
platform bills clients, i.e., data providers receive payments for their
records if clients retrieved them. Finally, to ease the participation,
our platform allows providers to offload data once, which is not
time-critical, and supports adding additional records at a later time.
Client(s). The privacy interests of clients are twofold. First, sim-
ilarity metrics are potentially valuable as they originate from on-
going research [38, 82] and, thus, must be protected accordingly.
Second, the initial input for the metric (i.e., a known record) is
sensitive as well since it might reveal internal information [16], e.g.,
production plans. Apart from privacy interests, clients should only
have to pay for retrieved data records to compensate providers.
While our design requires the client to reveal certain parts of her
candidate set 𝑆, i.e., the matched (requested) indices to the storage
operator (e.g., to realize the billing), it completely relies on a local
matching, i.e., the metric as well as the initial input remain at the
client. Further, as the storage server is unable to decrypt or identify
the requested records, it cannot draw conclusions about this sensi-
tive information from the transmitted indices. Moreover, client and
key server only interact via OTs for potentially leaking requests,
i.e., the key server never learns anything about the client’s query.
Although, depending on the number of input parameters and the
used similarity metric, the matching can become time-consuming, it
is usually not very time-critical. For instance, injection molding pro-
ductions are planned weeks in advance [23] and, thus, a processing
of multiple days for the matching and retrieval is feasible.
Key Server. The interests of the key server operator are limited
to an ideally low computational and storage overhead. While the
generation of the key material for every possible index in a prelim-
inary phase temporarily generates a high workload and forces the
server to store all generated keys, the number of keys is limited by
the used OT set size. Thus, the key generation neither produces
Figure 3: Our exchange platform is split into two compo-
nents to separate key material from shared ciphertexts.
can share an encryption key if 𝐾 ⊊ 𝐻, i.e., fewer indices are avail-
able at the key server, which also handles the mapping (𝑖𝑑𝑘𝑥′, 𝑘𝑥′).
To reduce the computational overhead, a smaller set size 𝐾 is desir-
able (cf. Section 7.3). An encrypted parameter record 𝑐𝑥′ is further
defined as 𝑐 = 𝐸𝑘𝑥′ (𝑝). The storage server maintains the respective
pairs (𝑖𝑑𝑥′, 𝑐𝑥′). A single index 𝑖𝑑𝑥′ can refer to the ciphertexts of
multiple records due to the rounding with 𝑟(𝑥) (to put records into
bins). By design, these ciphertexts also share their encryption key.
A similarity metric 𝑠(𝑞) (cf. Appendix A.2), which should be
considered sensitive (G2), computes a candidate set 𝑆 from a client-