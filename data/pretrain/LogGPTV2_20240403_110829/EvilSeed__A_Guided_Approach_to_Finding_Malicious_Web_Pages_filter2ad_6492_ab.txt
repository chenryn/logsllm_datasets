generate queries to search engines. The results returned by the
search engines are then forwarded to an (existing) analysis
infrastructure.
The key idea of our approach is that we can leverage the
infrastructure of search engines and the data that they have
collected. To this end, we query search engines in such a
way that the URLs that they return have a higher probability
of being malicious than a random page on the web (or the
probability that can be achieved by directly crawling the web).
Of course, the main challenge is to formulate the search queries
such that the results indeed have a high probability of pointing
to malicious pages. We assume that we have at our disposal an
oracle (and optionally, a preﬁlter) that can be used to analyze
a web page and determine whether it is malicious or not. Of
course, the type of oracle depends on the precise notion of
maliciousness that is used. We discuss possible oracles below;
an example of an oracle that can detect drive-by download
exploits would be a cluster of honeyclients.
In the following paragraphs, we discuss the components of
our system in more detail:
Seed. The (evil) seed is a set of pages that have been previously
found to be malicious. These pages form the input to gadgets.
Of course, whenever gadgets discover new pages that the
oracle conﬁrms to be malicious, they can be added to the set
of seed pages. One can distinguish two main types of pages
in the seed. First, there are pages that were directly set up by
cybercriminals. Typically, these are pages that directly contain
scripting (mostly JavaScript) code that launches exploits, or
links to malware binaries, such as fake AV programs. A
previous paper refers to such pages as malware distribution
pages [2]. The second type of pages is not malicious per se.
Instead, they are legitimate pages that have been compromised.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:16 UTC from IEEE Xplore.  Restrictions apply. 
Figure 1. EVILSEED overview.
In most cases, such legitimate pages do not host any malicious
code themselves. Instead, they only include a small piece
of HTML or JavaScript that redirects the user to malware
distribution sites. Such compromised, legitimate pages are
called landing pages in [2].
Gadgets. Gadgets form the heart of EVILSEED. The purpose
of a gadget is to ﬁnd candidate pages (URLs) that are likely
malicious based on the pages contained in the seed.
While different gadgets implement different techniques to
achieve this goal, they all follow a common approach. More
precisely, each gadget extracts certain information from the
pages in the seed ( in Figure 1), such as content that is
shared among these pages and links that are related to them.
In the next step, the information extracted from the seed
pages is distilled into queries that are sent to search engines
(). These queries can be simple searches for words or terms
that appear on pages indexed by a search engine. Queries can
also leverage advanced features of search engines, such as link
information or restricted searches. Of course, gadgets need
to consider the parts of a page that are indexed by a search
engine. While it might be desirable to search for fragments
of scripts that appear on malicious pages, such content is
typically not indexed (or, at least, not made available through
the public interfaces).
Once a query is issued, the gadgets simply collect the list
of URLs that the search engines return (), and they forward
them to the oracle (or, possibly, a preﬁlter) for further analysis.
The gadgets that we use in EVILSEED are presented in detail
in Section III.
Oracle. In the current implementation of EVILSEED, the
oracle consists of three components: Google’s Safe Browsing
blacklist [16], Wepawet [6], and a custom-built tool to detect
sites that host fake AV tools. We do not use a preﬁlter to
analyze the URLs that EVILSEED produces, but this is certainly
a possibility (as depicted in Figure 1). While a preﬁlter would
reduce the number of pages that the oracle needs to inspect,
it has no inﬂuence on the “toxicity” (fraction of malicious
pages) of the URLs that the gadgets produce.
Google creates and makes available a “constantly updated
blacklist of suspected phishing and malware pages.” This
blacklist, publicly accessible through the Safe Browsing API,
is compiled by using a multi-stage process that analyzes more
than one billion pages daily. At the core of the analysis
infrastructure is a farm of (high interaction) honeyclients,
which are particularly suitable to identify drive-by download
attacks with a very low false positive rate.
Wepawet is a client honeypot that uses an instrumented
browser to capture the execution of JavaScript code on web
pages. Based on the recorded execution traces, the system
uses anomaly-based techniques to detect drive-by download
attacks. Wepawet is able to achieve high detection rates with
almost no false positives [6].
As the third component, we use a custom-built detector
for pages that host fake anti-virus software. This detector is
a classiﬁer that uses simple content analysis techniques (a
combination of signatures and term frequency analysis) to
determine if a web page misinforms users about the security
of their computers and deceives them into downloading rogue
security software.
III. Gadgets
The goal of a gadget is to leverage a set of known, malicious
web pages to guide the search for additional, malicious content
on the web. All gadgets perform the same processing steps.
First, they analyze the input seed to identify similarities, that
is, shared characteristics or properties that can be found among
seed pages. Second, they expand the initial seed by querying
one or more external search engines to identify other pages
that share similar characteristics.
The assumption underlying all our gadgets is that malicious
web pages often share a set of common characteristics, which
are determined by the modus operandi and tools available to
431
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:16 UTC from IEEE Xplore.  Restrictions apply. 
!"#$%&'('Search engines !"#$%&')'!"#$%&'*'Crawler Prefilter Oracle Web EVILSEED Malicious Benign Web pages: Seeds Crawler Web pages source: EvilSeed queries . . . (cid:18047) (cid:18048) (cid:18049) Gadget
Links
Expansion
Link topology
Content dorks
Content similarity
SEO
Link topology,
Content similarity
Domain registrations Bulk registrations
DNS queries
Link topology
Inputs
Seed URLs,
Search Engines
Seed pages source,
Search Engines
Seed URLs,
Search Engines
Seed URLs,
Domain registrations
Seed URLs,
DNS trace,
Search Engine
Table I
GADGETS USED BY EVILSEED.
cybercriminals, the side-effects of the attacks they run, or the
tell-tale signs of the vulnerabilities that enable their attacks.
We have implemented ﬁve gadgets (see Table I): The links
gadget leverages the web topology (web graph) to ﬁnd pages
that link to malicious resources; the content dorks gadget aims
at identifying vulnerable and exploited web applications; the
SEO gadget analyzes seed pages that belong to blackhat Search
Engine Optimization campaigns; the domain registrations
gadget identiﬁes suspicious sequences of domain registrations;
and the DNS queries gadget analyzes traces of DNS requests
to locate pages that lead to a malicious domain. We will now
describe each gadget in detail.
A. Links Gadget
This gadget is designed to locate “malware hubs” on the
web. Malware hubs are pages that contain links to several
malicious URLs.1 In our experience, hubs can be grouped
in two categories: vulnerable sites that have been infected
multiple times (this is typical, for example, of unmaintained
web applications), and pages that catalog (and link to) web
malware (this is the case of certain malware discussion forums,
such as malwareurl.com).
This gadget leverages the observation that links contained
on malware hubs are likely to be malicious and, thus, represent
valuable candidate URLs.
Seed. The seed analyzed by the links gadget consists of all
the URLs of known malicious pages.
Expansion. The gadget searches for malware hubs that link
to pages in the input seed. More precisely, the gadget issues
queries using the link operator, e.g., link:. We sent these queries to three different search engines:
Google, Bing, and Yacy. We used multiple search engines
to distribute the load of our queries over multiple sites, and
to increase the diversity of returned result sets. The gadget
retrieves the URLs returned for the search engine queries and
visits the corresponding page. For each visited page, the gadget
1We observe that links to known-malicious pages was a feature used in [2]
and [17]. Our gadget reconstructs the linking structure from search engine
results, rather than directly building the web graph by having access to the
raw crawling data of the search engine.
432
extracts the URLs of all outgoing links. These URLs are then
submitted to our oracle.
B. Content Dorks Gadget
An effective technique to ﬁnd vulnerable web sites is to
query a popular search engine with a Google dork. This term
delineates a set of carefully chosen keywords and operators
tailored to retrieve links to vulnerable web pages. For example,
the query “index of /etc/” will cause the search engine
to locate web sites that share their conﬁguration and list of
users through their Apache web server. Likewise, a query for
“powered by PhpBB 2.0.15” will return web sites that are
using an older version of a popular bulletin board software
with known vulnerabilities. The term Google dork was coined
by Johnny Long, originally indicating “inept or foolish people
as revealed by Google.” A number of such dorks have been
manually identiﬁed, and they are available in books [18],
online databases [19], and penetration testing tools [20]. Recent
research [12] has also found evidence of the large-scale use
of Google dorks in the wild.
Painstakingly-assembled lists of manually identiﬁed Google
dorks may be useful to ﬁnd malicious web sites. However,
many of the dorks lose their value over time. The reason is
that application vulnerabilities are patched and the targeted
applications are replaced. Thus, we propose a gadget that can
automate the generation of relevant Google dorks.
While the underlying idea of the content dork gadget is
known (and used by cybercriminals to ﬁnd vulnerable sites),
the novelty of this gadget is the ability to identify suitable
dorks automatically. This has two advantages. First, our system
produces a broad range of dorks that cover the long tail of
less-popular but vulnerable web applications. Second, the
system can quickly react to a wave of attacks that exploit a
previously-unknown vulnerability. As soon as some malicious
pages that exploit this vulnerability are included into the seed,
our system can automatically extract content dorks to ﬁnd
other, similar sites that fell victim to the same exploit.
Seed. As discussed in Section II-B, our initial dataset of
malicious pages can be divided into malware distribution pages
and landing pages. As a starting point for this gadget, we are
interested in landing pages only, which are originally benign but
vulnerable pages that have been compromised by an attacker,
as opposed to pages directly created by an attacker (e.g., pages
generated with an exploit kit). The reason for focusing on
landing pages is that they contain much more indexable content
than malware distribution pages, and they remain online longer.
Moreover, we expect that legitimate sites that were exploited
because of vulnerabilities in a common, underlying content
management system share characteristic strings that can be
identiﬁed (similar in spirit to the “original” Google dorks). To
distinguish between compromised landing pages and malware
distribution pages, we use a simple, two step classiﬁcation
process: First, we discard pages that are no longer active.
The assumption is that compromised pages, whether they
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:16 UTC from IEEE Xplore.  Restrictions apply. 
are cleaned or remain infected, will usually remain available
over longer periods of time. Malware distribution pages, on
the other hand, typically have a short lifetime. Likewise, we
discard pages that, although apparently still active, are in fact
parking pages, that is, pages set up by hosting providers in
lieu of the removed malicious page. In the second step, we
evaluate a number of HTML features that are indicative of
compromised pages. For these features, we leverage previous
work on static web page ﬁlters [21], [22]. Examples of the
features that we use to identify a compromised page are the
occurrence of script code after an HTML closing tag, the
number of hidden iframes, and the presence of links to known
advertising domains (as malware distribution pages typically
don’t have advertising).
Expansion. The queries generated by this gadget consist of
n-grams of words that are extracted from the indexable content
of landing pages in our seed. To generate these n-grams, we use
two different techniques: term extraction and n-gram selection.
The term extraction process derives, from the content of
a page, those terms that best summarize the topics of this
page. This analysis typically leverages techniques from the
information retrieval and natural language processing ﬁelds.
We extract signiﬁcant terms from a landing page in our seed by
using Yahoo’s Term Extraction API [23]. As an example, using
it on CNN.com at the time of writing, term extraction yields
Eurozone recession, gay wedding, Facebook attack, graphic
content.
Cybercriminals are known to leverage popular topics to lure
victims into visiting pages under their control. For example,
they place popular terms onto pages, hoping to drive search
engine trafﬁc to the corresponding URLs. Term extraction
allows us to identify and extract these topics automatically, as
new trends are observed: In our experiments, we have seen
terms that reﬂect topics such as smartphones, e-book readers,
TV series, pharmaceutical products, and adult content. We
use as content dorks all terms that are returned by the Term
Extraction API.
The n-gram selection process extracts all sequences (of
length n) of words from a landing page. Then, it ranks all n-
grams according to their likelihood of occurring in a malicious
page compared to their likelihood of appearing in a benign
page. The intuition is that n-grams that appear much more
frequently in malicious pages than in benign ones are a good
indication for the maliciousness of the page. Therefore, in
addition to the seed of compromised pages, we built a dataset
of benign web pages by crawling the top 16,000 most popular
domains, according to their Alexa ranking (we assume that
these pages are legitimate). To select the most promising n-
grams from a compromised page, we examine all n-grams
that appear on the malicious seed pages. We discard all n-
grams that are present more often in benign pages than in the
malicious ones (based on relative frequencies). In the next
step, we assign a score to each of the remaining n-grams. This
score is equal to the difference between the relative frequency
of an n-gram in the malicious dataset and its relative frequency
in the benign dataset. We consider n-grams that vary from
length n = 2 to n = 5. Once we have computed the score for
each n-gram, we select as content dorks the top 10 n-grams.
All content dorks (those extracted by the n-gram selection
and the term extraction processes) are submitted as queries to
three search engines (Google, Bing, Yacy). We then retrieve
the URLs (links) from the results and submit them to the
oracle.
C. Search Engine Optimization Gadget