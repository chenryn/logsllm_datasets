was collected by analyzing the access logs of the web-server
serving the challenges. The extracted information was stored
415Number of Companies
Open Relays
Users protected by CR
Total incoming emails
Messages in the Gray spool
Messages in the Black spool
Messages in the White Spool
Total Messages Dropped at MTA
General Statistics
47
13
19,426
Challenge Sent
Emails Whitelisted from digest
Solved CAPTCHAs
90,368,573 Messages Dropped because of:
11,590,532
349,697
2,737,978
75,690,366
reverse DNS ﬁlter
RBL ﬁlter
Antivirus ﬁlter
Total Messages Dropped by ﬁlters
Emails (per day)
Messages in the White spool (per day)
Daily Statistics
797,679
31,920
Challenges sent (per day)
Total number of days
Table 1: Statistics of the collected data
4,299,610
55,850
150,809
3,526,506
4,973,755
267,630
7,290,922
53,764
5,249
in a Postgres database and later analyzed and correlated by
a number of Python scripts.
Table 1 shows some general statistics about the dataset we
collected. Each company’s server was conﬁgured to protect
certain users with the challenge-response system, while pro-
tecting other accounts by traditional anti-spam techniques.
In this paper we limit our analysis to the 19,426 users pro-
tected by the CR solution (this number includes normal
users as well as administrative accounts and other rarely
used email addresses). The table also shows the total num-
ber of the messages that we analyzed, the breakdown in the
diﬀerent spools (white, black, and gray), and some statistics
about the eﬀectiveness of the other spam ﬁlters included in
the system (discussed in more details in Section 5).
Finally, since the number of days in which we were able to
collect data varies between companies (for a total of 5,249
analyzed days), the table also report some daily statistics.
3. PART I: THE INTERNET POINT OF VIEW
In this section we focus on the consequences of adopting
CR spam ﬁlters from a global point of view. In particular, we
present an evaluation of the amount of challenge emails sent
out by a challenge-response system during normal operation.
These backscattered messages are often criticized for two
main reasons: the fact that misdirected challenges can be de-
livered to innocent users, and the fact that a large amount
of useless messages are poured into the Internet, thus in-
creasing the global traﬃc and overloading third parties email
servers.
In the rest of the section we provide real-world measure-
ments to estimate the impact of these two phenomena.
3.1 Email Backscattering
From an external point of view, a challenge response sys-
tem can be approximated by a black box that receives emails
from the Internet and separates them in three categories:
some (the white set) are delivered to the users Inbox, while
others (the black set) are immediately ﬂagged as spam and
discarded. The remaining messages (the gray set) are the
ones for which the system is unable to take a decision. There-
fore, for each email in this set, the system sends back to the
sender another email containing a challenge to be solved.
In this simpliﬁed model, a challenge-response system can be
seen as a software that receives a certain amount of emails,
and “reﬂects” a fraction of them back to the senders. This
fraction, that we call Reﬂection Ratio R, is an important
parameter of a CR system.
By using the numbers in Figure 1, it is easy to compute
the average reﬂection ratio: R = 48/249 = 19.3% for the
emails reaching the CR ﬁlter (or, R = 48/1000 = 4.8% if we
consider all the emails reaching companies’ MTA-INs).
Understanding the Reﬂection Ratio
Is 19.3% a good value for R? If not, what would be a rea-
sonable value?
Unfortunately, it is very hard to answer these questions since
it is not clear how to estimate which is an acceptable range
for the reﬂection ratio.
To explain why, let us consider two extreme cases. In the
ﬁrst case, the CR system does not contain any other spam
detector or blacklist mechanism. Therefore, the amount
of challenges it sends is roughly the same as the amount
of spam it receives, currently estimated between 80 and
90% [35] of the total email traﬃc. Values of R close to this
range are obviously unacceptable, since, from a global point
of view, the system would just act as a spam multiplier.
In the second scenario, the CR system has been carefully
conﬁgured and it has been associated with another perfect
spam detector. In this case, the system never replies to spam
and only sends back challenges to legitimate messages whose
senders are not already in the recipients whitelist. In this
case (represented by very low values of R) the system does
not generate any backscattered emails. Therefore, it may
seem to be the ﬁnal goal to reach in a perfect CR system.
Unfortunately, a very low value of R also corresponds to a
completely useless system. In fact, if the internal spam ﬁlter
can already distinguish good messages from spam, there is
no need to add a challenge response system on top of it. In
other words, in order to be useful a CR system has to be able
to “substantially” reduce the amount of spam received by the
users. However, this can only happen if the system sends
back an equivalent “substantial” number of backscattered
messages.
To conclude, the reﬂection ratio is a good indicator of the
amount of challenges generated by a CR system. At the
same time, it is important to be extremely careful to use
this value alone to draw conclusions about the quality of
such systems.
3.2 Misdirected Challenges
So far, we focused on the amount of challenges generated
by a CR system. However, this value only measures the
amount and not the real impact of the generated emails.
In fact, not all the challenges are the same. Some of them
reach the real senders and, despite being a little nuisance,
could be tolerated as an acceptable price to pay for ﬁght-
416delivered but never solved, i.e. somewhere between 0 and
45 %.
By combining the percentage of backscattered spam with
the reﬂection ratio we presented before, we obtain the Backscat-
tered Ratio β, i.e., the ratio of incoming emails for which
the CR system sends back a misdirected challenge to the
wrong user.
In our experiments, we obtain, in the worst
case, β = 8.7% (at the CR ﬁlter) or 2.1% (at the MTA-IN).
However useful, these ﬁgures must be considered only ap-
proximate upper bounds. For example, it is possible that
challenge messages get dropped by some spam ﬁlter after be-
ing successfully delivered, or that real users ignore or inten-
tionally decide to not solve a particular challenge. Finally,
there are automatically generated emails (notiﬁcations from
websites, mailing lists, receipts of purchase, . . . )
to take
into account. When a user expects to receive such mes-
sages, he should either use an email address not protected
by the CR system (functionality provided by the commercial
product we have evaluated), or manually add the address to
the whitelist.
Unfortunately, this is not always the case.
In fact, we
measured that around 2% of the message addresses in the
gray spool have been whitelisted manually by the users from
the daily digest. In other words, the challenge was not de-
livered or it was not solved, but the user recognized that the
message was not spam and he manually added the sender to
his whitelist to allow future communications.
3.3 Trafﬁc Pollution
The reﬂection ratio only measures the number of mes-
sages, without taking into account their size. Therefore, it
is not a very accurate indicator to estimate the amount of
traﬃc generated by a challenge response system. For that
purpose, we need to extend the previous deﬁnition by intro-
ducing the ReﬂecteD Traﬃc ratio RT , that represents the
ratio between the amount of traﬃc received by the system
and the amount of email traﬃc generated for the challenges.
To measure this new value, we deployed to all the servers
a new sensor that extracts from the email headers the total
size of the incoming messages and the total size of the out-
going challenges. Over a month period, the average ratio we
measured at the CR ﬁlter was RT = 2.5%. Unfortunately,
we could not get a similar measure at the entrance of the
MTA-IN servers. However, since the number of messages
at MTA-IN is in average four times bigger than at the CR
ﬁlter (see Figure 1), we can estimate that a large scale de-
ployment of challenge-response spam ﬁlters would increase
the email traﬃc on the Internet of around 0.62%.
3.4 Data Variability
In previous sections we reported aggregated ﬁgures for a
number of diﬀerent factors that can be used to estimate the
“external” impact of a CR system.
In order to preserve the companies’ privacy, each value
was obtained by combining together the data collected from
all the monitored installations. However, it is interesting
to investigate what the variance of those values is, and if
the size of the company aﬀects in some way the presented
indicators. For instance, it could be the case that CR ﬁlters
work better for small companies, but fail to scale well to
larger installations.
Figure 5 shows a scatter plot of ﬁve variables: the num-
ber of protected accounts (users), the amount of emails re-
(a) Challenge delivery status
distribution
(b) Tries required to solve
CAPTCHA
Figure 4: Challenge statistics
ing spam. We refer to them aslegitimate challenges . A
second class of them is directed to non-existing addresses,
and, thus, constitutes garbage traﬃc on the network. Fi-
nally, some misdirected challenges are delivered to existing
spoofed email addresses, therefore reaching other innocent
users. This category is much more harmful, and it is of-
ten referred to as backscatter spam (note that not all the
backscattered messages are spam).
In order to distinguish the three categories of challenges,
we analyzed the status of the challenge delivery in the servers’
logs. In the systems under analysis, we found that only 49%
of the challenges were successfully delivered to the destina-
tion servers. The remaining 51% were either bounced, or
expired after many unsuccessful attempts (see Figure 4(a)).
In the bounced set, a small portion has been stopped be-
cause the server that sent the challenges has been temporar-
ily blacklisted (the problem will be discussed in more details
in Section 5), while the large majority (71.7%) has been
bounced due to the fact that the recipient address did not
exist. This value provide a reasonable estimation of the
amount of challenges that belong to the second category.
Another piece of the puzzle can be found by measuring
the number of challenges that were actually solved. Previ-
ous work [21], conducted in a controlled environment, esti-
mated that about 50% of the challenges were never solved.
Unfortunately, our study shows a completely diﬀerent pic-
ture. According to the web servers’ logs of the companies we
analyzed, on average 94% of the CAPTCHA URLs included
in the delivered challenges were never even opened. The re-
maining were either solved (4%) or were visited by the user
but not solved (0.25%). Figure 4(b) also shows the average
number of attempts required to solve the CAPTCHAs. The
fact that we never observed more than ﬁve attempts support
the fact that probably there are still no real cases of attack
against CR systems based on trying to automatically solve
the challenges.
So far, we estimated the legitimate challenges to be at
least 4% and the ones sent to non-existing recipients to be
around 36.6% (71.7% of the 51% of undelivered messages).
The third category, i.e., the backscattered spam, can instead
be approximated with the number of challenges correctly
417Figure 5: Histograms and correlations between diﬀerent dimensions. Graphs on the diagonal represent
the data histogram. Below the diagonal are the plots of the correlation between every pair of variables,
summarized by the correlation values reported above the diagonals.
ceived daily (emails), the percentage of emails delivered in
the white spool (white), the reﬂection ratio at the CR ﬁl-
ter (reflection), and the percentage of challenges solved
(captcha).
This graph represents a very eﬃcient way to convey a large
amount of information about the ﬁve variables. On the diag-
onal, it shows the histograms of the values of each variable.
For example, the ﬁrst element on the diagonal shows that
most of the companies have less than 500 users, with few
exceptions that have more than 2,000 users. Some values
have a very high variability, such as the percentage of white
emails that varies from less than 10% to over 70%. However,
the two main coeﬃcients we have measured in this Section,
i.e. the reﬂection ratio and the percentage of solved chal-
lenges, seem to stay constant between diﬀerent installations.
The percentage of solved challenges only varies between 2%
and 12%, and the reﬂection ratio stays in the range of 10%
to 25%.
In Figure 5, the plots below the diagonals show the cor-
relation between every pair of variables, while the upper
part of the graph reports the corresponding correlation val-
ues (the font size allows to immediately focus on the higher
values). Notably, the percentage of challenges sent by a
CR system (reflection) is not correlated to the size of the
companies (users) or to the amount of emails received. Not
surprisingly, a small inverse correlation exists instead with
the percentage of white emails. In other words, servers that
receive a large amount of white emails (and therefore a lower
amount of spam), tend to send less challenges and vice versa.
The rate of solved challenges (captcha) shows more corre-
lations with other values, and in particular it is also strongly
correlated with the white percentage. However, as the his-