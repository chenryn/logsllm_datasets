own. When running the CAT path simulation, each relay’s proﬁle
is queried whenever a congestion value would have been measured
for that relay.
7.3 Analysis
Figure 5 shows the results of our CAT simulations with the relay
adversary compared to Tor, under the typical user model. Figure 5a
indicates that CAT reduces the time to ﬁrst compromise, but that
the difference is quite minor. This is expected: while congestion
awareness affects which circuits get used, it does not affect selec-
tion of entry guards (recall that guards provide the largest inﬂuence
on time to ﬁrst compromise). However, congestion awareness does
affect which circuits get used over time, which in turn directly af-
fects the total fraction of streams that get compromised. Figure 5b
indeed shows a more drastic increase in the total amount of streams
that are compromised. This is likely caused by less congested ad-
versarial relays biasing the client’s circuit choices to those the ad-
versary compromised. This behavior presents a new vector for at-
tack: an adversary can bias the circuits that get used by the client
to those it has compromised by increasing circuit response time for
those circuits of which it is a member but has not compromised.
This is an active attack similar to selective denial of service (but
much harder to detect), and therefore it falls outside the scope of
our adversary model. Note that we came to similar conclusions
with the results from the BitTorrent and IRC user models.
3468. CONCLUSION
We present in this paper a realistic and comprehensive analy-
sis of the security of Tor against trafﬁc correlation. Our approach
carefully deﬁnes adversaries and uses them to deﬁne security met-
rics that capture user security over time. We propose adversaries
that control one or more ﬁxed ASes or IXPs. We present new, prac-
tical security metrics that show for the ﬁrst time how long a user
can stay anonymous and how often an adversary can deanonymize.
We developed several tools and techniques to allow us to evaluate
our security metrics on the live Tor network. These include models
of user activity online, an up-to-date and comprehensive Internet
map with BGP routes, and a model of relay congestion based on
full-network simulations with Shadow.
The results show that Tor faces even greater risks from traf-
ﬁc correlation than previous studies suggested. An adversary that
provides no more bandwidth than some volunteers do today can
deanonymize any given user within three months of regular Tor use
with over 50% probability and within six months with over 80%
probability. We observe that use of BitTorrent is particularly un-
safe, and we show that long-lived ports bear a large security cost
for their performance needs. We also observe that the Congestion-
Aware Tor proposal exacerbates these vulnerabilities.
Some of our results against an adversary controlling ASs or IXPs
are similarly alarming. Some users experience over 95% chance of
compromise within three months against a single AS or IXP. We see
that users’ security varies signiﬁcantly with their location. How-
ever, an adversary with additional ASes or IXPs has much higher
compromise speed, notably against even those users in “safer” lo-
cations. Such an adversary is highly relevant in today’s setting
in which many large organizations control multiple ASes or IXPs.
Surprisingly, we observe that high diversity in destinations may ac-
tually result in improved security against a network adversary.
These results are somewhat gloomy for the current security of the
Tor network. However, they do suggest several ways in which se-
curity could be signiﬁcantly improved. The results against the relay
adversary show that choosing multiple guards ampliﬁes the prob-
ability that the adversary’s guard is chosen. Reducing the default
number of guards by some factor would immediately cut compro-
mise rates by the same factor. Those same results show that guard
expiration, which starts after 30 days, noticeably speeds up the time
to ﬁrst compromise. Increasing the time to expiration would signiﬁ-
cantly increase the time to compromise (in fact, the minimum guard
expiration time was increased to 60 days in Tor version 0.2.4.12-
alpha for exactly this reason). Elahi et al. [16] report some results
on how making such changes in guard selection improves security.
It seems more difﬁcult to improve security against the network ad-
versary, but several proposals have been given [15, 19, 28]. We
suggest evaluating these defenses using the methodology we have
presented as well as designing new solutions with our adversary
models and security metrics in mind.
Our results do suggest that current users of Tor should carefully
consider if it meets their security needs. In particular, users fac-
ing persistant adversaries who might run relays or monitor network
trafﬁc should be aware of the threat of trafﬁc correlation. While
improved defenses are still being developed, such users may be
able to take defensive measures on their own. For example, they
can choose to limit which relays their client will select using man-
ual conﬁguration options (EntryNodes, ExitNodes, ExcludeNodes,
etc.). While this does break the uniformity of path selection among
clients, that may be a worthwhile risk tradeoff for these users. John-
son et al. [27] suggest an approach along these lines that balances
choosing relays using per-client trust with blending in with other
clients.
A goal of our analysis is that it inform safer use of Tor and in-
spire more secure designs. Despite our pessimistic results, Tor has
provided real and valuable privacy to thousands of users. We are
optimistic that it can continue and improve this service.
Acknowledgments
We thank Leiah Stevermer for assistance with the user models.
Work by Jansen, Johnson, and Syverson supported by ONR and
DARPA. For work by Sherr and Wacek: This material is based
upon work supported by the Defense Advanced Research Project
Agency (DARPA) and Space and Naval Warfare Systems Center
Paciﬁc under Contract No. N66001-11-C-4020. Any opinions, ﬁnd-
ings and conclusions or recommendations expressed in this ma-
terial are those of the author(s) and do not necessarily reﬂect the
views of the Defense Advanced Research Project Agency and Space
and Naval Warfare Systems Center Paciﬁc. This work is partially
supported by NSF CAREER CNS-1149832 and NSF grants CNS-
1064986, CNS-1204347, and CNS-1223825.
References
[1] 0x539 Dev Group. Gobby: A Collaborative Text Editor.
http://gobby.0x539.de, 2013.
[2] T. G. Abbott, K. J. Lai, M. R. Lieberman, and E. C. Price.
Browser-Based Attacks on Tor. In Privacy Enhancing Tech-
nologies Symposium (PETS), 2007.
[3] M. Akhoondi, C. Yu, and H. V. Madhyastha. LASTor: A
Low-Latency AS-Aware Tor Client. In IEEE Symposium on
Security and Privacy (Oakland), 2012.
[4] B. Augustin, B. Krishnamurthy, and W. Willinger.
IXPs:
Mapped? In ACM SIGCOMM Conference on Internet Mea-
surement (IMC), November 2009.
[5] S. L. Blond, P. Manils, A. Chaabane, M. A. Kaafar, A. Legout,
C. Castellucia, and W. Dabbous. De-anonymizing BitTorrent
Users on Tor (poster). In USENIX Symposium on Networked
Systems Design and Implementation (NSDI), 2010.
[6] N. Borisov, G. Danezis, P. Mittal, and P. Tabriz. Denial of
Service or Denial of Security? How Attacks on Reliability
can Compromise Anonymity. In ACM Conference on Com-
puter and Communications Security (CCS), 2007.
[7] X. Cai, J. Heidemann, B. Krishnamurthy, and W. Willinger.
In Internet Measure-
Towards an AS-to-organization Map.
ment Conference, 2010.
[8] X. Cai, X. C. Zhang, B. Joshi, and R. Johnson. Touching from
a Distance: Website Fingerprinting Attacks and Defenses. In
ACM Conference on Computer and Communications Security
(CCS), 2012.
[9] CAIDA.
IPv4 Routed
/24 Topology Dataset.
http://www.caida.org/data/active/ipv4_
routed_24_topology_dataset.xml,
2012.
December
[10] CAIDA.
The CAIDA AS Relationships Dataset.
http://www.caida.org/data/active/
as-relationships/, June 2012.
[11] D. L. Chaum. Untraceable Electronic Mail, Return Ad-
dresses, and Digital Pseudonyms. Communications of the
ACM, 24(2):84–90, 1981.
[12] C. Díaz, S. Seys, J. Claessens, and B. Preneel. Towards
Measuring Anonymity. In Privacy Enhancing Technologies
(PET), 2003.
347[13] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
Second-Generation Onion Router. In USENIX Security Sym-
posium (USENIX), 2004.
[14] P. Eckersley. How Unique is Your Browser? In Privacy En-
hancing Technologies Symposium (PETS), 2010.
[15] M. Edman and P. Syverson. AS-Awareness in Tor Path Selec-
tion. In ACM Conference on Computer and Communications
Security (CCS), 2009.
[16] T. Elahi, K. Bauer, M. AlSabah, R. Dingledine, and I. Gold-
berg. Changing of the Guards: A Framework for Understand-
In ACM
ing and Improving Entry Guard Selection in Tor.
Workshop on Privacy in the Electronic Society (WPES), 2012.
Equinix Internet Exchange Enables Ef-
of Net-
http://www.equinix.com/solutions/
ﬁcient
works.
by-services/interconnection/exchanges/
equinix-internet-exchange/.
between Hundreds
Interconnection
[17] Equinix.
[18] N. S. Evans, R. Dingledine, and C. Grothoff. A Practical Con-
gestion Attack on Tor using Long Paths. In USENIX Security
Symposium (USENIX), 2009.
[19] N. Feamster and R. Dingledine.
Location Diversity in
Anonymity Networks. In ACM Workshop on Privacy in the
Electronic Society (WPES), 2004.
[20] J. Feigenbaum, A. Johnson, and P. Syverson. Probabilis-
tic Analysis of Onion Routing in a Black-box Model. ACM
Transactions on Information and System Security (TISSEC),
15(3):14:1–14:28, 2012.
[21] L. Gao. On Inferring Autonomous System Relationships in
the Internet. In IEEE/ACM Transactions on Networking, vol-
ume 9, pages 733–745, December 2001.
[22] S. Hahn and K. Loesing.
Privacy-preserving Ways to
Estimate the Number of Tor Users, November 2010.
Available at https://metrics.torproject.org/
papers/countingusers-2010-11-30.pdf.
[23] A. Hamel, J.-C. Grégoire, and I. Goldberg.
The Mis-
entropists: New Approaches to Measures in Tor. Technical
Report 2011-18, Cheriton School of Computer Science, Uni-
versity of Waterloo, 2011.
[24] N. Hopper, E. Y. Vasserman, and E. Chan-Tin. How Much
Anonymity Does Network Latency Leak? ACM Transac-
tions on Information and System Security (TISSEC), 13(2):
13, 2010.
[25] R. Jansen and N. Hopper. Shadow: Running Tor in a Box
for Accurate and Efﬁcient Experimentation. In Network and
Distributed System Security Symposium (NDSS), 2012.
[26] R. Jansen, K. Bauer, N. Hopper, and R. Dingledine. Methodi-
cally modeling the tor network. In USENIX Workshop on Cy-
ber Security Experimentation and Test (CSET), August 2012.
[27] A. Johnson, P. Syverson, R. Dingledine, and N. Mathewson.
Trust-based anonymous communication: Adversary models
In Proceedings of the 18th ACM
and routing algorithms.
Conference on Computer and Communications Security (CCS
2011), pages 175–186. ACM, 2011.
[28] J. P. J. Juen. Protecting Anonymity in the Presence of Au-
tonomous System and Internet Exchange Level Adversaries.
Master’s thesis, University of Illinois, 2012.
[29] S. J. Murdoch and G. Danezis. Low-Cost Trafﬁc Analysis of
Tor. In IEEE Symposium on Security and Privacy (Oakland),
2005.
[30] S. J. Murdoch and P. Zieli´nski. Sampled Trafﬁc Analysis by
Internet-Exchange-Level Adversaries. In Privacy Enhancing
Technologies (PET), 2007.
[31] Ofﬁce of Engineering and Technology and Consumer and
Governmental Affairs Bureau. A Report on Consumer Wire-
line Broadband Performance in the U.S. Technical report,
Federal Communications Commission, February 2013.
[32] L. Øverlier and P. Syverson. Locating Hidden Servers.
In
IEEE Symposium on Security and Privacy (Oakland), 2006.
[33] J. Qiu and L. Gao. AS Path Inference by Exploiting Known
AS Paths. In Global Telecommunications Conference, 2006.
[34] A. Serjantov and G. Danezis. Towards an Information Theo-
retic Metric for Anonymity. In Privacy Enhancing Technolo-
gies (PET), 2003.
[35] M. Sherr, M. Blaze, and B. T. Loo. Scalable Link-Based Re-
lay Selection for Anonymous Routing. In Privacy Enhancing
Technologies Symposium (PETS), August 2009.
[36] R. Smits, D. Jain, S. Pidcock, I. Goldberg, and U. Hengartner.
BridgeSPA: Improving Tor Bridges with Single Packet Au-
thorization. In ACM Workshop on Privacy in the Electronic
Society (WPES), 2011.
[37] P. Syverson. Why I’m not an Entropist. In International Work-
shop on Security Protocols, 2009.
[38] P. Syverson, G. Tsudik, M. Reed, and C. Landwehr. Towards
an Analysis of Onion Routing Security. In Designing Privacy
Enhancing Technologies, 2000.
[39] The Tor Project.
Changelog Tor
0.2.4.12-alpha.
https://gitweb.torproject.org/tor.git?
a=blob_plain;hb=HEAD;f=ChangeLog.
[40] Tor Project, Inc. Tor Metrics Portal. https://metrics.
torproject.org/, 2013.
[41] Tor Project,
Inc.
The Tor Project.
torproject.org/, 2013.
https://www.
[42] TorPS. TorPS: The Tor Path Simulator. http://torps.
github.io, 2013.
[43] University of Oregon. RouteViews Project. http://www.
routeviews.org/, 2013.
[44] C. Wacek, H. Tan, K. Bauer, and M. Sherr. An Empirical
In Network and Dis-
Evaluation of Relay Selection in Tor.
tributed System Security Symposium (NDSS), 2013.
[45] T. Wang, K. Bauer, C. Forero, and I. Goldberg. Congestion-
aware Path Selection for Tor. In Financial Cryptography and
Data Security (FC), 2012.
[46] L. Wasserman. All of Nonparametric Statistics (Springer
Texts in Statistics). Springer-Verlag New York, Inc., Secau-
cus, NJ, USA, 2006.
[47] M. Wright, M. Adler, B. N. Levine, and C. Shields. The
Predecessor Attack: An Analysis of a Threat to Anonymous
Communications Systems. ACM Transactions on Informa-
tion and System Security (TISSEC), 4(7):489–522, November
2004.
348