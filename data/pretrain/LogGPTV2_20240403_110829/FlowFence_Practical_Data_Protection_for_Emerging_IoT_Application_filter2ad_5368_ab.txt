servers and may use a minimal hub that only serves
as a proxy for relaying commands to physical devices.
The hub model is less prone to reliability issues, such
as functionality degradation due to network connectivity
losses that plague cloud architectures [58]. Furthermore,
we observe a general trend toward adoption of the hub
model by industry in systems such as Android Auto [1]
and Wear [2], Samsung SmartThings [55]3, and Logitech
Harmony [3]. Our work targets the popular hub model,
making it widely applicable to these hub-based IoT sys-
tems.
Threat Model. IoT apps are exposed to a slew of sensi-
tive data from sensors, devices connected to the hub, and
other hub-based apps. This opens up the possibility of
sensitive data leaks leading to privacy invasion. For in-
stance, Denning et al. outlined emergent threats to smart
homes, including misuse of sensitive data for extortion
and for blackmail [17]. Fernandes et al. recently demon-
strated that such threats exist in real apps on an existing
IoT platform [26] where they were able to steal and mis-
use door lock pincodes.
We assume that the adversary controls IoT apps run-
ning on a hub whose platform software is trusted. The
adversary can program the apps to attempt to leak sen-
sitive data. Our security goal is to force apps to declare
their intended data use patterns, and then enforce those
flows, while preventing all other flows. This enables the
design of more privacy-respecting apps. For instance, if
an app on FlowFence declares it will sink camera data
to a door lock, then the system will ensure that the app
cannot leak that data to the Internet. We assume that side
channels and covert channels are outside the scope of this
work. We discuss implications of side channels, and pos-
sible defense strategies in §6.
3 Opacified Computation Model
Consider the example smart home app from §1, where it
unlocks the front door based on people’s faces. It uses
the bitmap to extract features, checks the current state of
the door, unlocks the door, and sends a notification to the
home owner using the Internet. This app uses sensitive
camera data, and accesses the Internet for the notification
(in addition to ads and crash reporting). An end user
wishes to reap the benefits of such a scenario but also
wants to ensure that the door control app does not leak
camera data to the Internet.
FlowFence supports such scenarios through the use
of Opacified Computation, which consists of two main
components:
(1) Quarantined Modules (“functions”),
and (2) opaque handles. A Quarantined Module (QM) is
a developer-written code module that computes on sen-
sitive data (which is assigned a taint label at the data
source), and runs in a system-provided sandbox. A de-
veloper is free to write many such Quarantined Modules.
Therefore, each app on FlowFence is split into two parts:
(1) some non-sensitive code that does not compute on
sensitive data, and (2) a set of QMs that compute on sen-
sitive data. Developers can chain multiple QMs together
3Recent v2 hubs have local processing.
534  25th USENIX Security Symposium 
USENIX Association
to achieve useful work, with the unit of transfer between
QMs being opaque handles—immutable, labeled opaque
references to data that can only be dereferenced by QMs
when running inside a sandbox. QMs and opaque han-
dles are associated with a taint set, i.e., a set of taint la-
bels that indicates the provenance of data and helps track
information flows (we explain label design later in this
section).
An opaque handle does not reveal any information
about the data value, data type, data size,
taint set,
or exceptions that may have occurred to non-sensitive
code. Although such opaqueness can make debugging
potentially difficult, our implementation does support a
development-time debugging flag that lifts these opaque-
ness restrictions (§4).
Listings 1 and 2 shows pseudo-code of example smart
home apps. The CamPub app defines QM bmp that pub-
lishes the bitmap data. FlowFence ensures that whenever
a QM returns to the caller, its results are converted to an
opaque handle.
Line 10 of Listing 1 shows the publisher app calling
the QM (a blocking call), supplying the function name
and a taint label. FlowFence allocates a clean sandbox,
and runs the QM. The result of QM bmp running is the
opaque handle hCam, which refers to the return data, and
is associated with the taint label Taint CAMERA. hCam is
immutable—it will always refer to the data that was used
while creating it (immutability helps us reduce overtaint-
ing; we discuss it later in this section). Line 11 shows
CamPub sending the resultant handle to a consumer.
We also have a second publisher of data QM status
that publishes the door state (Line 16 of Listing 1), along
with a door identifier, and provides an IPC function for
consumers to call (Line 20).
The DoorCon app defines QM recog, which expects a
bitmap, and door state (Lines 6-9 of Listing 2). It com-
putes feature vectors from the bitmap, checks if the face
is authorized, checks the door state, and unlocks the door.
Lines 18, 19 of Listing 2 show this consumer app receiv-
ing opaque handles from the publishers. As discussed,
non-sensitive code only sees opaque handles.
In this
case, hCam refers to camera-tainted data, and hStatus
refers to door-state-tainted data, but the consumer app
cannot read the data unless it passes the data to a QM.
Moreover, for this same reason, non-sensitive code can-
not test the value of a handle to create an implicit flow.
Line 20 calls a QM, passing the handles as parameters.
FlowFence automatically and transparently dereferences
opaque handle arguments into raw data before invoking a
QM. Transparent dereferencing of opaque handles offers
developers the ability to write QMs normally with stan-
dard types even though some parameters may be passed
as opaque handles. During this process, FlowFence allo-
cates a clean sandbox for the QM to run, and propagates
the taint labels of the opaque handles to that sandbox.
Finally, QM recog receives the raw data and opens the
door.
The consumer app uses QM report to send out the
state of the door to a remote monitoring website. It also
attempts to use QM mal to leak the bitmap data. Flow-
Fence prevents such a leak by enforcing flow policies,
which we discuss next.
Flow Policy. A publisher app, which is associated with
a sensor (or sensors), can add taint labels to its data that
are tuples of the form (appID,name), where appID is
the identifier of the publisher app and name is the name
of the taint label. This name denotes a standardized type
that publishers and consumers can agree upon, for ex-
ample, Taint CAMERA. We require labels to be statically
declared in the app’s manifest. appID is unique to an
app and is used to avoid name collisions across apps.4
Additionally, in its manifest, the publisher can specify
a set of flow rules for each of its taint labels, with the
set of flow rules constituting the publisher policy. The
publisher policy defines the permissible flows that gov-
ern the publisher’s data. A flow rule is of the form
TaintLabel → Sink, where a sink can be a user in-
terface, actuators, Internet, etc. CamPub’s flow policy is
described on Line 3 of Listing 1. The policy states that
consumer apps can sink camera data to the sink labeled
UI (which is a standard label corresponding to a user’s
display at the hub).
Since other possible sinks for camera data are not nec-
essarily known to the publisher, new flow policies are
added as follows. A consumer app must request approval
for flow policies if it wants to access sensitive data. Con-
sumer flow policies can be more restrictive than pub-
lisher policies, supporting the least privilege principle.
They can also request new flows, in which case the hub
user must approve them. DoorCon’s policy requests are
described in Lines 2-4 of Listing 2. It requests the flows:
Taint CAMERA → Door.Open, Taint DOORSTATE →
Door.Open, Taint DOORSTATE → Internet. At app
install time, a consumer app will be bound to a publisher
that provides data sources with labels Taint CAMERA,
Taint DOORSTATE.
To compute the final policy for a given consumer app
FlowFence performs two steps. First, it computes the in-
tersection between the publisher policy and the consumer
policy flow rules. In our example, the intersection is the
null set. If it were not null, FlowFence would authorize
the intersecting flows for the consumer app in question.
Second, it computes the set difference between the con-
sumer policy and publisher policy. This difference re-
flects the flows the consumer has requested but the pub-
lisher policy has not covered. At this point, FlowFence
4An app cannot forge its ID since our implementation uses Android
package name as the ID. See §4 for details.
USENIX Association  
25th USENIX Security Symposium  535
delegates approval to the IoT hub owner to make the fi-
nal decision about whether to approve the flows or not. If
the hub owner decides to approve a flow that a publisher
policy does not cover, that exception is added for subse-
quent runs of that consumer app. Such a approval does
not apply to other apps that may also use the data.
If a QM were to attempt to declassify the camera data
to the Internet (e.g., QM mal) directly without requesting
a flow policy, the attempt would be denied as none of
the flow policies allow it. An exception is thrown to
the calling QM whenever it tries to perform an unautho-
rized declassification. Similar to exception processing
in languages like Java, if a QM does not catch an ex-
ception, any output handle of this QM is moved into the
exception state. Non-QM code cannot view this excep-
tion state. If an app uses such a handle in a subsequent
QM as a parameter, then that QM will silently fail, with
all of its output handles also in the exception state. App
developers can avoid this by ensuring that a QM handles
all possible exceptions before returning and, if necessary,
encodes any errors into the return object, which can then
be examined in a subsequent QM that receives the re-
turned handle.
FlowFence is in a position to make security decisions
because the publisher assigns taint labels while creating
the handles, and when DoorCon reads in the handles, it
results in the taint labels propagating to the sandbox run-
ning QM mal. FlowFence simply reads the taint labels of
the sandbox at the time of declassification.
All declassification of sensitive data can only occur
through well-known trusted APIs that FlowFence de-
fines. Although our prototype provides a fixed set of
trusted APIs that execute in a separate trusted process,
we envision a plug-in architecture that supports commu-
nity built and vetted APIs (§4). FlowFence sets up sand-
box isolation such that attempts at declassifying data us-
ing non-trusted APIs, such as arbitrary OS system calls,
are denied.
Table 1 summarizes the taint logic. When a clean
sandbox loads a QM, it has no taint. A taint label, be-
longing to the app, may be added to a handle at creation,
or to a sandbox at any time, allowing data providers to la-
bel themselves as needed. A call from QM executing in
S0 to another QM that is launched in sandbox S1 results
in the taint labels of S0 being copied to S1. When a called
QM returns, FlowFence copies the taint of the sandbox
into the automatically created opaque handle. At that
point, the QM no longer exists. The caller is not tainted
by the returned handle, unless the caller (which must be
a QM) dereferences the handle. These taint arithmetic
rules, combined with QMs, opaque handles, and sand-
boxes conceptually correspond to a directed data flow
graph from sources to sinks, as we illustrate with the ex-
ample below.
1 a p p l i c a t i o n CamPub
2 t a i n t _ l a b e l T a i n t _ C A M E R A ;
3 a l l o w { T a i n t _ C A M E R A -> UI }
4
5 Bitmap QM_bmp () :
6
Bitmap face = c a m D e v i c e . s n a p s h o t () ;
r e t u r n face ;
7
8
9
10
i f ( motion at F r o n t D o o r )
hCam = QM. c a l l ( QM_bmp , T a i n t _ C A M E R A ) ;
send hCam t o DoorCon ;
11
12 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
13 a p p l i c a t i o n D o o r S t a t e P u b
14 t a i n t _ l a b e l T a i n t _ D O O R S T A T E ;
15
16 Status Q M _ s t a t u s () :
17
r e t u r n ( door [0]. state () , 0) ; // state , idx
18
19 /* IPC */ Handle g e t D o o r S t a t e () :
20
r e t u r n QM. c a l l ( QM_status ,
T a i n t _ D O O R S T A T E ) ;
Listing 1: Pseudocode for two publishers—camera data,
and door state. Quarantined Modules are shown in light
gray.
1 a p p l i c a t i o n DoorCon
2 r e q u e s t { T a i n t _ C A M E R A -> Door . Open ,
3
T a i n t _ D O O R S T A T E -> Door . Open ,
T a i n t _ D O O R S T A T E -> I n t e r n e t }
4
5
6 v o i d Q M _ r e c o g ( faceBmp , status ) :
7
F e a t u r e s f = e x t r a c t F e a t u r e s ( f a ce B m p ) ;
i f ( status != u n l o c k e d AND isAuth ( f ) )
T r u s t e d A P I . door [0]. open () ;
8
9
10
11 v o i d Q M _ r e p o r t ( status ) :
12
T r u s t e d A P I . network . send ( status ) ;
13
14 v o i d QM_mal ( faceBmp ) :
/* this is d e n i e d */
15
T r u s t e d A P I . network . send ( faceBmp ) ;
16
17
18 r e c e i v e hCam from CamPub ;
19 Handle h S ta t u s =
D o o r S t a t e P u b . g e t D o o r S t a t e () ;
20 QM. c a l l ( QM_recog , hCam , h S t a t u s ) ;
21 QM. c a l l ( QM_mal , hCam ) ;
22 QM. c a l l ( QM_report , h S t at u s ) ;
Listing 2: Consumer app pseudocode that reads camera
and door state data, and controls a door. Quarantined
Modules are shown in light gray.
FlowFence Data Flow Graph. We now discuss the taint
flow logic of FlowFence in more detail, and show how it
creates and tracks, at runtime, a directed data flow graph
that enables it to make security decisions on flows. Fig-
ure 1 shows two publishers of sensitive data that gener-
ate OHT1(d1)—an opaque handle that refers to camera
bitmap data d1, and OHT2(d2)—an opaque handle that
refers to door state data d2, using QMbmp and QMstatus
536  25th USENIX Security Symposium 
USENIX Association
Operation
Sandbox S loads a QM
QM inside S reads opaque handle d =
OH−1(h)
QM inside S returns h = OH(d)
QM manually adds taints {t} to its sandbox
QM0 inside S0 calls QM1 inside S1
Taint Action
T [S] := ∅
T [S] += T [h]
T [h] := T [S]
T [S] += {t}
T [S1] = T [S0]
Table 1: Taint Arithmetic in FlowFence. T [S] denotes
taint labels of a sandbox running a QM. T [h] denotes
taint label of a handle h.
Camera
(d1,T1)
Sandbox
QMbmp
T1
OHT1(d1)
Door
Status
(d2,T2)
T2
Sandbox
QMstatus
OHT2(d2)
CamPub
OHT1(d1)
DoorStatePub
OHT2(d2)
OHT2(d2)
T2
Sandbox
QMreport
H(d2) , {T2}
DoorCon
OHT1(d1)
T1
Sandbox
QMmal
G(d1) , {T1}
Trusted API
OHT1(d1),OHT2(d2)
T1 U T2
Sandbox
QMrecog
F(d1,d2) , {T1 U T2}
H(d2)
Internet
Policy Violation
Internet
F(d1,d2)
DoorLock
Figure 1: Data flow graph for our face recognition ex-
ample. FlowFence tracks taint labels as they propagate
from sources, to handles, to QMs, to sinks. The dot-
ted lines represent a declassification attempt. The trusted
API uses labels on the sandboxes to match a flow policy.
respectively. T1 and T2 are taint labels for data d1 and d2.