paradigms (e.g., using an array element to decide whether to
trigger anti-adblock reaction). To tackle this issue, our system
needs to trace value difference [36] as well.
Second, several websites seem to be impacted by different
sources of randomness that can bypass our current implemen-
tation. These include (1) behavioral randomization and (2)
content randomization. In behavioral randomization, a website
randomly activates its anti-adblocking module which results
in inconsistent positive/negative traces. Our system rules out
such inconsistencies as noise. In content randomization, a
website may change various page elements (e.g., DOM/vari-
able/bait names) across multiple runs, thereby breaking our
trace alignment (e.g., our current implementation requires the
same variable name). As mentioned earlier in §IV-B, this is not
a fundamental limitation of differential trace analysis as we can
force the same exact page to be loaded across multiple runs.
However, it is much more challenging to deal with behavioral
randomization, which we discuss in §VII.
Third, we also note a few special cases. For instance,
one interesting case is that an anti-adblock warning message
(initially invisible) is placed behind the real ad, and becomes
visible when the ad in the front is blocked. In this case, no
extra code is executed to conduct anti-adblocking but its effect
is still preserved (it’s arguable whether it should be considered
an anti-adblocker). The best solution is probably to let the
adblocker block the warning message as well.
We mentioned earlier that there are 428 out of 686 websites
that have visible anti-adblockers. We are curious about the
remaining 258 websites — could it be that they are simply
performing anti-adblocking with no visible reactions? After
running our system on these websites, it turns out that most of
them are actually ﬂagged as positive (with branch divergences
under A/B testing). To understand if our results are correct,
we conduct small-scale manual veriﬁcation. Speciﬁcally, we
look at the branch divergence and the triggered logic when
an adblocker is detected. Interestingly, we indeed ﬁnd many
websites that perform adblocker detection with minimal or
no visible reactions. We illustrate two interesting types of
them from two websites memeburn.com and englishforum.ch
in Figure 3.
1. Switching ad sources: As
shown in Figure 3(a),
memeburn.com uses a ﬁrst-party anti-adblock script. Upon
detecting an adblocker,
immediately replaces one of its
banner ads with a gif image (see Figure 4 for the visual
differences). Interestingly, instead of switching to external ads,
in this case the website has chosen to advertise its own services
(about its tech news podcasts).
it
adblocker
usage
statistics: We
ﬁnd
2. Collecting
englishforum.ch has a ﬁrst-party script
that detects
adblockers yet does not exhibit any visible reaction. As shown
in Figure 3(b),
the variable blockStatus indicates the
presence of adblockers, which is set to true as soon as an
ad frame is found missing. The ga() function is of Google
Analytics API that reports events back to the website owner.
As we can see in this case, there are no additional reactions
besides the silent recording of adblocker usage.
1 if( window.advertsAvailable === undefined ){
2
3
//adblocker detected, show fallback
jQuery(’.replace-me’).html(’’);
jQuery(’#testreplace’).css(’display’,’block’);
4
5 }
clientHeight === 0) blockStatus = ’Blocked’;
4 ga(’send’, ’event’, ’Ad block JavaScript’,
blockStatus, ’Desktop’, {nonInteraction: true});
5 ga(’theLocalNetwork.send’, ’event’, ’Ad block
JavaScript’, blockStatus, ’Desktop’, {
nonInteraction: true});
(a) Switching ad sources upon detecting any adblocker
(b) Reporting adblocker usage through Google Analytics
Fig. 3: Silent anti-adblocker (Left: memeburn.com. Right: englishforum.ch)
(a) Original banner ads (shown when there is no adblockers)
(b) Replaced banner ads (shown when the original is blocked)
Fig. 4: Ad switching behavior on memeburn.com
B. Large-Scale Analysis of Alexa Top-10K Websites
We now conduct a large-scale in the wild evaluation of
our system. Surprisingly, we are able to detect anti-adblockers
on 30.5% on the Alexa top-10K websites. Our results point
out that roughly one-third of the most popular websites are
equipped with anti-adblockers. Our investigation shows that
1238 websites use only if/else type of branch divergences, 473
use only ternary-type divergences, and the remaining 1344 are
detected to contain both divergences. This ﬁnding highlights
that anti-adblockers implement their detection logic in several
different ways. Thus, as we expand support for other types of
branch statements in our implementation in future, our anti-
adblock detection rate may further increase.
It is noteworthy that our results show that anti-adblockers
are much more pervasive than previously reported in prior
work [42, 45]. An earlier study [45] published in May 2016 re-
ported that 6.7% of Alexa top-5K websites use anti-adblockers.
Our anti-adblock detection results are approximately 5× more
than theirs. Another study [42] conducted in February 2017
reported that 0.7% of Alexa top-100K websites use anti-
adblockers. Our anti-adblock detection results are approxi-
mately 52× more than theirs. To better understand the dis-
crepancy, we should reiterate that an anti-adblocker has at least
two components: (1) adblocker detection and (2) subsequent
reaction. The solution in [42] also leverages A/B testing but
it aims to detect HTML changes caused by anti-adblockers. It
makes the assumption that there will be a signiﬁcant reaction
(visible at the HTML level) after an adblocker is detected.
However, as we have shown earlier, this assumption may not
hold as many websites can have subtle or no visible changes
at all while still having the ability to detect adblockers. The
authors in [45] relied on manual analysis and may miss some
anti-adblockers that do not have obvious keyword in the scripts
(e.g., obfuscated). Moreover, the anti-adblock prevalence has
likely increased [35] since more than a year ago [45] when the
study was conducted. In contrast to prior work, our approach
is oblivious to the reactions by anti-adblockers; instead, it
essentially relies on catching the adblocker detection logic that
Fig. 5: Popularity of anti-adblockers by website ranking
is evident by the discovered branch divergence. Later we will
sample a number of popular websites and scripts with manual
inspection to validate our results.
In summary, our hypothesis is that a much larger fraction
of websites than previously reported are “worried” about
adblockers but many are not employing retaliatory actions
against adblocking users yet. To verify the hypothesis, we
manually inspected 1000 websites out of the 3000+ detected
websites. Following the same inspection methodology de-
scribed in §V-A, we ﬁnd that there are only 66 (10 of them
simply switch sources of the ads) websites that do have visible
reactions and 934 that do not, which indeed represents a huge
disparity. While it may be useful to conduct automated analysis
of subsequent reactions (e.g., whether they invoke APIs that
have visual impact, or whether they send data over to network
to log adblocker usage), we leave this as future work.
We now attempt to categorize the websites that use anti-
adblockers in the following aspects. First, we are curious to
see whether there’s any correlation between their popularity
and the likelihood of them deploying anti-adblockers. Figure 5
shows that the higher ranked websites are more likely to use
anti-adblockers. This is somewhat counter-intuitive as most top
websites do not actually have any visible reactions to adblocker
users, leaving users the impression that they are not doing
7
Rank
Script Source
Reaction
Count2
Google Analytics
Google DoubleClick
YouTube
Taboola
PageFair
Chartbeat
Mail.ru
Addthis
Yandex
Cloudﬂare
Twitter
Criteo
Detection
Trigger1
unknown
real ads
real ads
baits
mixed baits +
extension
probing
unknown
baits
unknown
baits
baits
unknown
baits
1
2
3
4
5
6
7
8
9
10
11
12
13
reporting +
local storage
unknown
unknown
silent
reporting
silent
reporting
silent
reporting
silent
silent
reporting
unknown
silent
reporting
silent
reporting
unknown
silent
reporting +
ads switching
silent
reporting +
local storage
614
403
311
144
95
82
72
61
57
51
45
32
32
Outbrain
baits
1 All scripts check attributes of DOM elements as opposed to others.
2 The number of websites that contain the script.
See cases for checks against other types of variables in §VI-B
TABLE I: Top origins of anti-adblocker scripts based on
different sources
anything about adblockers. We ﬁnd that many popular websites
are passively collecting statistics (to evaluate what they should
do). Second, our analysis of website categorization corroborate
results reported in prior work [42, 45] that “news and media”
websites are much more likely to use anti-adblockers. This is
expected because online advertising is a key source of income
for news and media websites.
We investigate the source of anti-adblocking scripts used by
websites. More speciﬁcally, are they ﬁrst-party vs. third-party
scripts? Are there a small number of third-party scripts that
are widely deployed by many websites? Our results show that
there are 422 websites that use only ﬁrst-party anti-adblocking
scripts while 2219 websites use only third-party scripts (414
websites use both). This discrepancy shows that most websites
choose to outsource anti-adblocking to dedicated third-party
anti-adblocking service providers such as PageFair [24]. To
better understand the small set of third-party anti-adblocking
scripts, we aggregate their sources using the domain and URL
information. Table I reports the third-party sources of the most
popular anti-adblocking scripts. We note that analytics and
ads scripts by Google are the most popular source of anti-
adblocking scripts. As expected, we also note several other
online advertising services such as Taboola and Outbrain using
anti-adblockers.
To better understand popular third-party anti-adblocking
scripts, we next investigate them using several different anal-
ysis approaches such as code base, network trafﬁc, cookie
content, probing etc. For instance, if silent reporting exists,
the network trafﬁc would contain at least some difference in
the payload during A/B testing. Similarly, a different cookie
value set during A/B testing can also support silent reporting.
These anti-adblocking scripts are fairly challenging to analyze
because they are large, complex, and often use obfuscation.
It is also challenging to analyze some of them because they
do not have visible reactions to adblocker detection. For
example, 9 out of 13 most popular anti-adblocking scripts,
which account for almost one-third of the Alexa top-10K
websites that use anti-adblockers, detect adblockers silently.
Table I reports the detection mechanism and subsequent
reactions of popular anti-adblockers. They all check attributes
of DOM elements in certain way (as opposed to alternatives
which are more common in less popular scripts. See §VI-B
for details). Most of the checked DOM elements are baits and
a number of them are real ads. Speciﬁcally, we are able to
conﬁrm DoubleClick detects adblockers by checking the
height and length of ad-related objects and sends view-status
ad requests to the back-end server. Scripts from PageFair
and Taboola are also performing anti-adblocking, which is
expected since both are known to provide anti-adblocking
services [10, 14]. In particular, PageFair [42] attempts to craft a
diverse set of baits and even probes into the extension folder 1.
The probing methodology is deprecated in newer browsers but
still effective against older versions of Chrome [9] to detect
adblockers. Both scripts from PageFair and Taboola silently
report adblocking statistics. It is noteworthy that PageFair has
two types of scripts: one is analytics which only collects
adblocker usage; the other one has the ability to switch ad
sources [1]. In our study, the analytics script is the one that
showed up as top scripts, likely because it is a free service
while the other is not [1].
Being the biggest adblock-analytics-tech player in the
market, PageFair meticulously crafts a diverse set of baits
to maximize its chances of detecting adblockers. Its analytics
script measure.min.js creates six different baits in total,
with two of them being the  elements and the rest as
images/scripts. Then the blocking status of these six baits will
be monitored and stored independently. Finally the script saves
the status into a local cookie for future use, and also sends it
to back-end server with multiple ﬁelds indicating the state of
each bait and other statistics.
1 TRC.blocker.blockedState = TRC.blocker.
getBlockedState(this.global["abp-detection-class
-names"] || ["banner_ad", "sponsored_ad"])
2
3 getBlockedState: function(a) {