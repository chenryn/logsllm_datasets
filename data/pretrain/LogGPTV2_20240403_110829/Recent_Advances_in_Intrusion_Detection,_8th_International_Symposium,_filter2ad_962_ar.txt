512 MB memory). In both tests, we utilize the static test suite shipped with
WebBench 5.0 [34] to test the throughput and latency of the server when the
server is fully utilized. In the ﬁrst test, the machine simply runs the Abyss X1
webserver. In the second test, the machine runs the same webserver and also
extracts and sends out the system call information to another machine for the
behavioral distance calculation (though this calculation is not on the critical
path of the response). We compared the diﬀerence in throughput and latency
between the two tests. Our experiment results show that the second test has a
6.6% overhead in throughput and 6.4% overhead in latency compared to the ﬁrst
test. This shows that intercepting and sending out system call information causes
very low performance overhead on a single server in terms of both throughput
and latency.
Performance Overhead Compared to Output Voting. We perform three
tests to measure the performance overhead of our implementation of the behav-
ioral distance on a replicated system with Abyss X1 webservers. The experi-
mental setup is the same as shown in Section 4.1, except that we use another
machine T (with a 2.0 GHz Pentium IV processor and 512 MB memory) to
generate client requests, and in one of the tests we also have yet another ma-
chine C to perform the behavioral distance calculation. We use the benchmark
program WebBench 5.0 [34] in all the three tests. All tests utilize the static test
suite shipped with WebBench 5.0, except that we simulate 10 concurrent clients
throughout the tests. Each test was run for 80 minutes with statistics calculated
at 5-minute intervals. Results are shown in Figure 5.
In the ﬁrst test, replicas L and W only serve as webservers, without the
kernel patch (on Linux) or kernel driver (on Windows) to capture the system
call sequences. Proxy P does output voting, which means that responses from L
and W are compared before being sent to the client T. This test is used as the
reference in our evaluation.
In the second test, besides output voting on P, replicas L and W capture the
system calls made by the webservers and send them to machine C, which does
2.5
2
1.5
1
0.5
)
s
/
e
t
y
b
M
(
t
u
p
h
g
u
o
r
h
T
0
0
Behavioral Distance for Intrusion Detection
79
P:        output voting
L&W: serve requests
P:        output voting
L&W: serve requests + send syscall sequences to C
P:        output voting + behavioral distance calculation
L&W: serve requests + send syscall sequences to P
12
)
c
e
s
m
(
y
c
n
e
t
a
L
8
4
P:        output voting
L&W: serve requests
P:        output voting
L&W: serve requests + send syscall sequences to C
P:        output voting + behavioral distance calculation
L&W: serve requests + send syscall sequences to P
20
40
Test time (min)
(a) Throughput
60
80
0
0
20
40
Test time (min)
(b) Latency
60
80
Fig. 5. Performance overhead
the behavioral distance calculation. Note that in this test the behavioral distance
calculation is not on the critical path of responding to the client. The purpose of
this test is to show the overhead for capturing the system call information (and
analyzing it oﬀ-line). As seen from Figure 5, this results in very small overhead:
3.58% in throughput and 0.089 millisecond in latency on average.
In the last test, output voting and the behavioral distance calculation are both
performed on the proxy P on the critical path of responding to the client, i.e.,
the response is sent to the client only after the behavioral distance calculation
and output comparison complete. To improve performance, P caches behavioral
distance calculations, so that identical calculations are not performed repeatedly.
Figure 5 shows that the proxy needs about 50 minutes to reach its optimal
performance level. After that, clients experience about a 24.3% reduction in
throughput and 0.848 millisecond overhead in latency, when compared to results
from the ﬁrst test.
The results suggest that we need to use a slightly more powerful machine for
the proxy, if we want to do behavioral distance calculation on the critical path
of server responses, for servers to remain working at peak throughput. However,
even in our tests the overhead in latency is less than a millisecond.
5 Conclusion
In this paper, we introduce behavioral distance for evaluating the extent to which
two processes behave similarly in response to a common input. Behavioral dis-
tance can be used to detect a software fault or attack on a replica, particularly
one that does not immediately yield evidence in the output of the replica. We
propose a measure of behavioral distance and a realization of this measure us-
ing the system calls emitted by processes. Through an empirical evaluation of
this measure using three web servers on two diﬀerent platforms (Linux and Win-
dows), we demonstrate that this approach is able to detect sophisticated mimicry
attacks with low false positive rate and moderate overhead.
80
D. Gao, M.K. Reiter, and D. Song
References
1. Myserver. http://www.myserverproject.net.
2. L. Alvisi, D. Malkhi, E. Pierce, and M. K. Reiter. Fault detection for Byzan-
tine quorum systems. IEEE Transactions on Parallel Distributed Systems, 12(9),
September 2001.
3. R. W. Buskens and Jr. R. P. Bianchini. Distributed on-line diagnosis in the presence
of arbitrary faults. In Proceedings of the 23rd International Symposium on Fault-
Tolerant Computing, pages 470–479, June 1993.
4. M. Castro, R. Rodrigues, and B. Liskov. Base: Using abstraction to improve fault
tolerance. ACM Transactions on Computer Systems (TOCS), 21(3):236–269, 2003.
5. L. Chen and A. Avizienes. n-version programming: A fault-tolerance approach to
reliability of software operation. In Proceedings of the 8th International Symposium
on Fault-Tolerant Computing, pages 3–9, 1978.
6. S. Cheung, R. Crawford, M. Dilger, J. Frank, J. Hoagland, K. Levitt, J. Rowe,
S. Staniford-Chen, R. Yip, and D. Zerkle. The design of GrIDS: A graph-based
intrusion detection system. Technical Report CSE-99-2, Computer Science Depart-
ment, U.C. Davis, 1999.
7. C. Collberg, C. Thomborson, and D. Low. Manufacturing cheap, resilient, and
stealthy opaque constructs. In Proceedings of the ACM Symposium on Principles
of Programming Languages, January 1998.
8. H. H. Feng, J. T. Giﬃn, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing
In Proceedings of the 2004
sensitivity in static analysis for intrusion detection.
IEEE Symposium on Security and Privacy, 2004.
9. H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection
In Proceedings of the 2003 IEEE Symposium on
using call stack information.
Security and Privacy, 2003.
10. S. Forrest and T. A. Langstaﬀ. A sense of self for unix processes. In Proceedings
of the 1996 IEEE Symposium on Security and Privacy, 1996.
11. The Apache Software Foundation. Apache http server. http://httpd.apache.org.
12. D. Gao, M. K. Reiter, and D. Song. Gray-box extraction of execution graph for
anomaly detection. In Proceedings of the 11th ACM Conference on Computer &
Communication Security, 2004.
13. D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly
detection. In Proceedings of the 13th USENIX Security Symposium, 2004.
14. J. T. Giﬃn, S. Jha, and B. P. Miller. Detecting manipulated remote call streams.
In Proceedings of the 11th USENIX Security Symposium, 2002.
15. J. T. Giﬃn, S. Jha, and B. P. Miller. Eﬃcient context-sensitive intrusion detection.
In Proceedings of Symposium on Network and Distributed System Security, 2004.
16. C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous
system call arguments. In Proceedings of the 8th European Symposium on Research
in Computer Security (ESORICS 2003), 2003.
17. L. Lamport. The implementation of reliable distributed multiprocess systems. In
Computer Networks 2, 1978.
18. X. Lu. A Linux executable editing library. Master’s thesis, Computer and Infor-
mation Science Department, National Unviersity of Singpaore, 1999.
19. G. Nebbett. Windows NT/2000 Native API Reference. Sams Publishing, 2000.
20. M. Nei and S. Kumar. Molecular Evolution and Phylogenetics. Oxford University
Press, 2000.
Behavioral Distance for Intrusion Detection
81
21. P. Ning, Y. Cui, and D. S. Reeves. Analyzing intensive intrusion alerts via cor-
relation. In Recent Advances in Intrusion Detection (Lecture Notes in Computer
Science vol. 2516), 2002.
22. M. Prasad and T. Chiueh. A binary rewriting defense against stack based buﬀer
In Proceedings of the USENIX Annual Technical Conference,
overﬂow attacks.
June 2003.
23. I. Rigoutsos and A. Floratos. Combinatorial pattern discovery in biological se-
quences. Bioinformatics, 14(1):55–67, 1998.
24. T. Romer, G. Voelker, D. Lee, A. Wolman, W.Wong, H. Levy, B. Bershad, and
B. Chen. Instrumentation and optimization of win32/intel executables using etch.
In Proceeding of the USENIX Windows NT Workshop, August 1997.
25. F. B. Schneider.
Implementing fault-tolerant services using the state machine
approach: A tutorial. ACM Computing Surveys, 22(4):299–319, December 1990.
26. B. Schwarz, S. Debray, and G. Andrews. Disassembly of executable code revisited.
In Proceeding of the Working Conference on Reverse Engineering, pages 45–54,
2002.
27. R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast automaton-based
method for detecting anomalous program behaviors. In Proceedings of the 2001
IEEE Symposium on Security and Privacy, 2001.
28. P. H. Sellers. On the theory and computation of evolutionary distances. SIAM J.
Appl. Math., 26:787–793.
29. K. Shin and P. Ramanathan. Diagnosis of processors with Byzantine faults in a
distributed computing system. In Proceedings of the 17th International Symposium
on Fault-Tolerant Computing, pages 55–60, 1987.
30. S. R. Snapp, S. E. Smaha, D. M. Teal, and T. Grance. The DIDS (Distributed
Intrusion Detection System) prototype. In Proceedings of the Summer USENIX
Conference, pages 227–233, 1992.
31. K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal
to the normal and beyond. In Proceedings of the 5th International Workshop on
Information Hiding, October 2002.
32. Aprelium Technologies. Abyss web server. http://www.aprelium.com.
33. A. Valdes and K. Skinner. Probabilistic alert correlation. In Recent Advances in
Intrusion Detection (Lecture Notes in Computer Science vol. 2212), 2001.
34. VeriTest.
Webbench.
http://www.veritest.com/benchmarks/webbench/
default.asp
35. D. Wagner and D. Dean. Intrusion detection via static analysis. In Proceedings of
the 2001 IEEE Symposium on Security and Privacy, 2001.
36. D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems.
In Proceedings of the 9th ACM Conference on Computer and Communications
Security, 2002.
37. A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit
trail patterns. In Proceedings of the 2000 Recent Advances in Intrusion Detection,
2000.
38. Y. Xie, H. Kim, D. O’Hallaron, M. K. Reiter, and H. Zhang. Seurat: A pointillist
approach to anomaly detection. In Recent Advances in Intrusion Detection (Lecture
Notes in Computer Science 3224), pages 238–257, September 2004.
39. J. Yin, J.-P. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin. Separating
agreement from execution for Byzantine fault tolerant services. In Proceedings of
the 19th ACM Symposium on Operating System Principles, 2003.
FLIPS: Hybrid Adaptive Intrusion Prevention
Michael E. Locasto, Ke Wang, Angelos D. Keromytis, and Salvatore J. Stolfo
Department of Computer Science, Columbia University,
1214 Amsterdam Avenue, Mailcode 0401,
New York, NY 10027
+1 212 939 7177
{locasto, kewang, angelos, sal}@cs.columbia.edu
Abstract. Intrusion detection systems are fundamentally passive and
fail–open. Because their primary task is classiﬁcation, they do noth-
ing to prevent an attack from succeeding. An intrusion prevention sys-
tem (IPS) adds protection mechanisms that provide fail–safe semantics,
automatic response capabilities, and adaptive enforcement. We present
FLIPS (Feedback Learning IPS), a hybrid approach to host security that
prevents binary code injection attacks. It incorporates three major com-
ponents: an anomaly-based classiﬁer, a signature-based ﬁltering scheme,
and a supervision framework that employs Instruction Set Randomiza-
tion (ISR). Since ISR prevents code injection attacks and can also pre-
cisely identify the injected code, we can tune the classiﬁer and the ﬁlter
via a learning mechanism based on this feedback. Capturing the injected
code allows FLIPS to construct signatures for zero-day exploits. The
ﬁlter can discard input that is anomalous or matches known malicious
input, eﬀectively protecting the application from additional instances of
an attack – even zero-day attacks or attacks that are metamorphic in
nature. FLIPS does not require a known user base and can be deployed
transparently to clients and with minimal impact on servers. We describe
a prototype that protects HTTP servers, but FLIPS can be applied to a
variety of server and client applications.
Keywords: Adaptive Response,
Tolerance.
Intrusion Prevention,
Intrusion
1 Introduction
One key problem for network defense systems is the inability to automatically
mount a reliable, targeted, and adaptive response [21]. This problem is magniﬁed
when exploits are delivered via previously unseen inputs. Network defense sys-
tems are usually composed of network-based IDS’s and packet ﬁltering ﬁrewalls.
These systems have shortcomings that make it diﬃcult for them to identify and
characterize new attacks and respond intelligently to them.
Since IDS’s passively classify information, they can enable but not enact a
response. Both signature-based and anomaly-based approaches to classiﬁcation
merely warn that an attack may have occurred. Attack prevention is a task often
A. Valdes and D. Zamboni (Eds.): RAID 2005, LNCS 3858, pp. 82–101, 2006.
c(cid:2) Springer-Verlag Berlin Heidelberg 2006
FLIPS: Hybrid Adaptive Intrusion Prevention
83
left to a ﬁrewall, and it is usually accomplished by string matching signatures of
known malicious content or dropping packets according to site policy. Of course,
successfully blocking the correct traﬃc requires a ﬂexible and well deﬁned policy.
Furthermore, signature matching large amounts of network traﬃc often requires
specialized hardware and presumes the existence of accurate signatures. In addi-
tion, encrypted and tunneled network traﬃc poses problems for both ﬁrewalls and
IDS’s. To compound these problems, since neither IDS’s or ﬁrewalls know for sure
how a packet is processed at an end host, they may make an incorrect decision [10].
These obstacles motivate the argument for placing protection mechanisms
closer to the end host (e.g., distributed ﬁrewalls [11]). This approach to system
security can beneﬁt not only enterprise-level networks, but home users as well.
The principle of “defense-in-depth” suggests that traditional perimeter defenses
like ﬁrewalls be augmented with host-based protection mechanisms. This pa-
per advocates one such system that employs a hybrid anomaly and signature
detection scheme to adaptively react to new exploits.
1.1 Hybrid Detection
In general, detection systems that rely solely on signatures cannot enable a de-
fense against previously unseen attacks. On the other hand, anomaly-based clas-
siﬁers can recognize new behavior, but are often unable to distinguish between
previously unseen “good” behavior and previously unseen “bad” behavior. This
blind spot usually results in a high false positive rate and requires that these
classiﬁers be extensively trained.
A hybrid approach to detection can provide the basis for an Intrusion Preven-
tion System (IPS): an automated response system capable of stopping an attack
from succeeding. The core of our hybrid system is an anomaly-based classiﬁer
that incorporates feedback to both tune its models and automatically gener-
ate signatures of known malicious behavior. Our anomaly detector is based on
PayL [38], but other classiﬁers can be used [17].