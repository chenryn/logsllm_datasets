code in time to analyze and instrument it before it executes. This approach is
similar to BIRD’s [34], but monitors a smaller set of control transfers.
Code Overwrite Monitoring. Code overwrites invalidate portions of an ex-
isting code analysis and introduce new code that has not yet been analyzed. We
adapt DIOTA’s [29] mechanism for detecting code overwrites by write-protecting
memory pages that contain code and handling the signals that result from write
attempts. Accurately detecting when overwriting ends is important, as it allows
us to update our analysis only once when large code regions are overwritten in
small increments. We detect the end of code overwriting in a novel way by using
our structural analysis of the overwrite code to detect any loops that enclose the
write operations, allowing us to delay the analysis update until the loop exits.
Signal- and Exception-Handler Analysis. We use dynamic analysis to re-
solve signal- and exception-based control transfer obfuscations [18,38]. We detect
signal- and exception-raising instructions and ﬁnd their dynamically registered
handlers through standard techniques, and then add the handlers to our analysis
and instrument them to control their execution.
Figure 1 illustrates how we combine the above techniques into an iterative
algorithm that allows us to provide analysis-guided dynamic instrumentation
of analysis-resistant program binaries. The key feature of this algorithm is that
it allows all of the program’s code to be analyzed and instrumented before it
executes. Our algorithm’s incremental instrumentation of the code is similar
to Mirgorodskiy and Miller’s use of “self-propelled instrumentation” to trace a
program’s execution [31], but we also analyze and instrument analysis-resistant
code, whereas they can instrument only statically analyzable code.
4 Parsing
The purpose of our parsing algorithm is to accurately identify binary code and
analyze the program’s structure, producing an interprocedural control ﬂow graph
of the program. Existing parsing techniques for arbitrarily obfuscated code have
attempted to identify code with good accuracy and coverage, and have come up
short on both counts [24]. Instead, we prioritize accurate code identiﬁcation, as
an incorrect parse can cause incorrect program behavior by leading to the instru-
mentation of non-code bytes, and is ultimately not very useful. The competing
324
K.A. Roundy and B.P. Miller
goal of good coverage is relatively less important, because our dynamic tech-
niques compensate for lapses in coverage by capturing statically un-analyzable
code at run-time and triggering additional parsing.
Control-ﬂow traversal parsing [47] is the basis for most accurate parsing tech-
niques, but it makes three unsafe assumptions about control ﬂow that can re-
duce its accuracy. First, it assumes that function-call sites are always followed by
valid code sequences. Compilers violate this assumption when generating calls to
functions that they know to be non-returning, while obfuscated programs (e.g.,
Storm Worm [39]) often contain functions that return to unexpected locations
by tampering with the call stack [25]. Second, the algorithm assumes that con-
trol ﬂow is only redirected by control transfer instructions. Obfuscated programs
often use an apparently normal instruction to raise a signal or exception, thereby
transferring control to code that is hidden in a signal or exception handler [18].
The handler can further obfuscate control ﬂow by telling the operating system to
resume execution away from the signal- or exception-raising instruction, poten-
tially causing non-code bytes to be parsed following the instruction [38]. Third,
the algorithm assumes that both targets of conditional branch instructions can
be taken and therefore contain valid code. Program obfuscators can exploit this
assumption by creating branches with targets that are never taken, thereby di-
luting the analysis with junk code that never executes [14].
In our experience with analysis-resistant binaries, we have found that by far
the most targeted vulnerability is the assumption that code follows each call
instruction, and we have addressed this vulnerability in our current parsing
algorithm. We detect and resolve signal- and exception-based obfuscations at
run-time (see Section 7), when we analyze and instrument any hidden code
and correct our analysis to include the obfuscated control transfer. The use of
branches with targets that are never taken dilutes the analysis with junk code
but has thus far not been a problem for our hybrid analysis and instrumentation
techniques. Our ongoing work will improve upon our parser’s accuracy by adding
static detection of some fault-based control transfers and never-taken branch
targets, thereby making our instrumentation of the program safer and more
eﬃcient. In the meantime, our current parsing algorithm achieves signiﬁcant
accuracy improvements relative to existing techniques for parsing obfuscated
code, allowing us to analyze and instrument most analysis-resistant programs.
Non-returning Calls. When a called function either never returns or returns
to an unexpected location by tampering with the call stack [25], one or more junk
bytes may follow the function call site. The simplest approach to this problem
would be to adopt the assumption made by BIRD [34] and Kruegel et al.’s
obfuscated code parser [24], that function calls never return, and then rely on
run-time monitoring of return instructions to discover code that follows call sites.
This runtime-discovery approach is taken by BIRD, and while it is our technique
of last resort, our data-ﬂow analysis of called functions can often tell us whether
the function will return, and to where, thereby increasing the code coverage
attained through parsing and avoiding unnecessary instrumentation.
Hybrid Analysis and Control of Malware
325
push ADDR
...
retn
(a)
ebp
pop
inc
ebp
push ebp
retn
(b)
Fig. 2. Code sequences that tamper with return addresses on the call stack
We take advantage of the depth-ﬁrst nature of our parsing algorithm to use
the analysis of called functions in deciding whether or not to continue parsing
after call instructions. We do not resume parsing after the call site if our analysis
of the called function contains no return instructions, or if our static call stack
analysis [26] of the function detects that it tampers with the stack. Our call-stack
analysis emulates the function’s stack operations to detect whether the function
alters its return address, either by overwriting the address or by imbalancing the
call stack. Figure 2 illustrates two call-stack tampering tricks used by the ASPack
packer that are easily detected by our analysis. Figure 2a shows an instruction
sequence that transfers control to ADDR upon executing the return instruction,
while Figure 2b shows a sequence that increments the return address of a function
by a single byte. In both cases, our call-stack analysis informs the parser of the
actual return address of the called function, and the byte immediately following
the call site is not parsed as code.
5 Dynamic Capture
Having found and analyzed as much of the code as possible by traversing the
program’s statically analyzable control ﬂow, we turn to dynamic capture tech-
niques to ﬁnd code that is not statically analyzable. Statically un-analyzable
code includes code that is present in the binary but is reachable only through
pointer-based address calculations, and code that is not initially present because
it is dynamically unpacked. Our approach to both problems lies in monitoring
those control transfers whose targets are either unknown or invalid when we
originally parse them. More precisely, we use dynamic capture instrumentation
to monitor the execution of instructions that meet one of the following criteria:
– Control transfer instructions that use registers or memory values to deter-
mine their targets. Obfuscated programs often used indirect jump and call
instructions to hide code from static analysis. For example, the FSG packer
has an indirect function call for every 16 bytes of bootstrap code. We deter-
mine whether indirect control transfers leave analyzed code by resolving their
targets at run-time with dynamic instrumentation. In the case of indirect call
instructions, when our parser cannot determine the call’s target address, it
also cannot know if the call will return, so it conservatively assumes that it
does not; our instrumentation allows us to trigger parsing both at call target
and after the call site, if we can determine that the called function returns.
326
K.A. Roundy and B.P. Miller
– Return instructions of possibly non-returning functions. Return instructions
are designed to transfer execution from a called function to the caller at the
instruction immediately following the call site; unfortunately they can be
misused by tampering with the call stack. As detailed in Section 4, during
parsing we attempt to determine whether called functions return normally
so that we can continue parsing after call sites to those functions. If our
analysis is inconclusive we instrument the function’s return instructions.
– Control transfer instructions into invalid or uninitialized memory regions.
Control transfers to dynamically unpacked code can appear this way, as code
is often unpacked into uninitialized (e.g., UPX) or dynamically allocated
memory regions (e.g., NSPack). Our instrumentation of these control transfer
instructions executes immediately prior to the transfer into the region, when
it must contain valid code, allowing us to analyze it before it executes.
– Instructions that terminate a code sequence by reaching the end of initialized
memory. Some packer tools (e.g., UPack) and custom-packed malware (e.g.,
Rustock [12]) transition to dynamically unpacked code without executing a
control transfer instruction. These programs map code into a larger memory
region so that a code sequence runs to the end of initialized memory without
a terminating control transfer instruction. The program then unrolls the re-
mainder of the sequence into the region’s uninitialized memory so that when
it is invoked, control ﬂow falls through into the unpacked code. We trigger
analysis of the unpacked instructions by instrumenting the last instruction
of any code sequence that ends without a ﬁnal control transfer instruction.
Our dynamic capture instrumentation supplies our parser with entry points into
un-analyzed code. Before extending our analysis by parsing from these new entry
points, we determine whether the entry points represent un-analyzed functions
or if they are extensions to the body of previously analyzed functions. We treat
call targets as new functions, and treat branch targets as extensions to existing
functions (unless the branch instruction and its target are in diﬀerent memory
regions). The target of a non-obfuscated return instruction is always immediately
preceded by an analyzed call instruction, in which case we parse the return
instruction’s target as an extension of the calling function. When a return target
is not immediately preceded by a call instruction, we conclude that the call stack
has been tampered with and parse the target as a new function.
Cost issues arise from our use of the Dyninst instrumentation library [22]
because it monitors programs from a separate process that contains the analy-
sis and instrumentation engine. The problem is that our code-discovery instru-
mentation requires context switching between the two processes to determine
whether monitored control transfers lead to new or analyzed code. We reduce
this overhead by caching the targets of these instructions in the address space of
the monitored program, and context switching to Dyninst only for cache misses.
6 Response to Overwritten Code
Code overwrites cause signiﬁcant problems for binary analysis. Most analysis tools
cannot analyze overwritten code because they rely on static CFG representations
Hybrid Analysis and Control of Malware
327
(a) The monitored program over-
writes an instruction. We have
removed write permissions from
code pages to cause code over-
writes to raise access rights vio-
lations.
(b) A correct but ineﬃcient ap-
proach that updates the CFG in
response to each code write, trig-
gering major processing.
(c) Our optimized handler in-
struments the loop’s exit points
with callbacks to our CFG up-
dater and restores write permis-
sions to the overwritten page.
(d) When writing completes, the
instrumentation at a loop exit
triggers a callback to our CFG
updater.
Fig. 3. Our approach to detecting code writes is shown in Figure 3a, alternative meth-
ods for responding to code writes are shown in Figures 3b and 3c-3d.
of the code. Code overwrites cause problems for CFGs by simultaneously invali-
dating portions of the CFG and introducing new code that has yet to be analyzed.
We have developed techniques to address this problem by updating the program’s
CFG and analyzing overwritten code before it executes.
To analyze overwritten code before it executes, we can either detect the mod-
iﬁed instructions immediately prior to their execution, by checking whether the
bytes of each executed instruction have changed [44], or detect writes to code
as soon as they occur, by monitoring write operations to analyzed code re-
gions. Monitoring each instruction for changes is expensive because it requires
single-step execution of the program. Fortunately, we can eﬃciently detect write
operations that modify code by adapting DIOTA’s techniques for intercepting
writes to executable code regions [29]. DIOTA monitors writes to all memory
328
K.A. Roundy and B.P. Miller
pages that are writable and executable by removing write permissions from those
pages, thereby causing writes that might modify code to raise an access-rights
violation that DIOTA intercepts. As illustrated in Figure 3a, we have adapted
this mechanism for packed binaries, which typically mark most of their memory
as writable and executable, by removing write permissions only from memory
pages that contain analyzed code.
A na¨ıve approach based on monitoring writes to code pages might respond to
write attempts by emulating each write and immediately updating the analysis,
as shown in Figure 3b. Doing so is undesirable for eﬃciency reasons. Large code
regions are often overwritten in small increments, and updating the CFG in
response to every code write is unnecessarily expensive, as the analysis does not
need to be updated until the overwritten code is about to execute. Instead, we
catch the ﬁrst write to a code page but allow subsequent writes, delaying the
update to the window between the end of code overwriting and the beginning of
modiﬁed code execution. This delayed-update approach divides our response to
code overwrites into two components that we now describe in detail: a handler
for the access-rights violation resulting from the ﬁrst write attempt, and a CFG
update routine that we trigger before the modiﬁed code executes.
6.1 Response to the Initial Access-Rights Violation
When a write to a code page results in an access-rights violation, our ﬁrst task is
to handle the exception. We disambiguate between real access-rights violations
and protected-code violations by looking at the write’s target address. Protected-
code violations are artiﬁcially introduced by our code-protection mechanism and
we handle them ourselves to hide them from the monitored program. For real
access-rights violations we apply the techniques of Section 7 to analyze the reg-
istered handler and pass the signal or exception back to the program.
Our handler also decides when to update the CFG, attempting to trigger
the update after the program has stopped overwriting its code, but before the
modiﬁed code executes. A straightforward approach would be to restore write
permissions for the overwritten page and remove execute permissions from the
page, thereby causing a signal to be raised when the program attempts to execute
code from the overwritten page (similar to the approach taken by OmniUnpack
[30], Justin [20], and Saﬀron [41]). Unfortunately, this approach fails in the com-
mon case that the write instruction writes repeatedly to its own page, when this
approach eﬀectively devolves into single-step execution. Instead, we apply the
techniques shown in Figures 3c and 3d to detect the end of overwriting, and delay
updating the CFG until then. We perform inter-procedural loop analysis on the
execution context of the faulting write instruction to see if the write is contained
in a loop, in which case we instrument the loop’s exit edges with callbacks to
our CFG update routine. We allow subsequent writes to the write-target’s code
page to proceed unimpeded, by restoring the page’s write permissions. When the
write loop terminates, one of the loop’s instrumented exit edges causes the CFG
update routine to be invoked. We take extra precautions if the write loop’s code
pages intersect with the overwritten pages to ensure that the write loop does not
Hybrid Analysis and Control of Malware
329
modify its own code. We safeguard against this case by adding bounds-check in-
strumentation to all of the loop’s write operations so that any modiﬁcation of
the loop’s code will immediately trigger our CFG update routine.
Our handler’s ﬁnal task is to save a pre-write copy of the overwritten memory
page, so that when writing completes, the CFG update routine can identify the
page’s modiﬁed instructions by comparing the overwritten page to the pre-write
copy of the page. If the loop writes to multiple code pages, the ﬁrst write to each
code page results in a separate invocation of our protected-code handler, which
triggers the generation of a pre-write copy of the page, and associates it with
the write loop by detecting that the write instruction lies within it. Our handler
then restores write permissions to the new write-target page and resumes the
program’s execution. When the write loop ﬁnally exits, instrumentation at one
of its exit edges triggers a callback to our CFG update routine.
6.2 Updating the Control Flow Graph
We begin updating our analysis by determining the extent to which the code has
been overwritten. We identify overwritten bytes by comparing the overwritten
code pages with our saved pre-write copies of those pages, and then detemine
which of the overwritten bytes belong to analyzed instructions. If code was over-
written, we clean up the CFG by purging it of overwritten basic blocks and of
blocks that are only reachable from overwritten blocks. We analyze the modiﬁed
code by seeding our parser with entry points into the modiﬁed code regions. We
then inform the analyst of the changes to the program’s CFG so that the new
and modiﬁed functions can be instrumented. After adding our own dynamic cap-
ture instrumentation to the new code, we again remove write permissions from
the overwritten pages and resume the monitored program’s execution.