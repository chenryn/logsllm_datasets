而缩容怎么来做呢，我们需要考虑得更细致一些，所以我就截取了物理分片1的一
在这个基础上，我们需要保证的就是将原本隔离的节点数据统一为 Master 端 active
扩容前，分片节点上的4个逻辑分片都是 active 状态，都可以写入数据，从库是
chan
Master1-2
Masterl-1
图10-12
图10-11
Master1-2
Master1-1
---
## Page 407
过程中也被淘汰掉了，比如 falcon，还有些存储引擎的使用场景实在是有限，
出历史舞台，memory 存储引擎也在规划中会逐步被替代，还有些存储引擎，自身发展的
擎会随着 MySQL 官方的大力投入越来越火。
10.2.1
火花，在充分验证成熟度的基础上，引入开源方案是一种更为理性而且可落地的思路。
解决方案的功能边界，最好的方式就是看看行业里大家都在怎么用，有没有一些共鸣的
的解决方案。
错；简单来说，单纯基于 MySQL 的方案是明显有限的，我们可以基于业务场景考虑更好
速变化，为了快速响应，我们会随时考虑新的解决方案，充分利用开源红利进行创新试
10.2·基于业务场景的新架构方案
操作性。
从技术可控角度，我们需要的是一整套可逆的自动化操作来保证整个流程的完整性和可
对于数据分片节点来说，接入上是透明的，而在架构复杂度上，扩容是2*N的规模扩容：
同时留给其他存储引擎的挑战和压力也很大，比如 MyISAM会在MySQL 8.0版本退
而开源的发展也不是一帆风顺，虽然可以试错，但是我们很多时候更需要知道一个
MySQL 中的存储引擎是插件式的，当然主流默认的是 InnoDB，而且 InnoDB 存储引
我们接下来就来对行业里的数据库选型方案进行分析，试图给大家一些借鉴的思路。
现在的业务发展非常快，很多公司都在跨界，尤其在互联网环境中，因为需求的快
在正常情况下，切换的过程在业务低峰期，
在整个扩缩容的过程中，对于中间件来说，可以通过配置的方式平滑的进行切换，
密集型写入的场景选型：TokuDB
图10-13
Master1-2
Master1-1
一级扩容基本可以保证在秒级完成。
第10章基于业务的数据库架构设计”385
，不温不火，
---
## Page 408
386丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
是重点内容，在这个步骤该脚本也会自动修复。
不后期很容易失败。
插件式的安装角度来说，你也可以拷贝 so 的文件在其他版本中安装。
中还是很受欢迎的，或者是日志型/纯流水历史的数据也不错。
何。TokuDB 尤其适合密集型插入场景，压缩比很高，在一些应用中，比如监控数据存储
就是一个！
目录中就默认存在了,所以有的同学问MySQL社区版和Percona有什么差别，喏,TukuDB
比如 blackhole、csv、archive 等等。
TokuDB 这个存储引擎还蛮有意思，被 Percona 收购之后，在 Percona Server 的安装
这个步骤会完成所有的检查，如果正常的话，基本日志就是下面的样子，注意5.7版
（6）使用命令 ps_tokudb_admin 来激活 TokuDB，指定 socket 路径，端口等等。
update mysql.user set authentication_string=password('xxxx') where user='root';
（5）配置数据库的密码，在TokuDB 的配置中，还是需要设置下指定用户的密码，要
tokudb_cache_size = 700M 
（3）赋予指定的权限，比如 mysql组。
创建目录 toku_data、toku_log和 tmp 分别存储数据、日志和临时文件。
（1）配置TokuDB，如果已经有了Percona的软件则不需要做额外的工作了，否则从
我们来看一下 TokuDB 的部署和配置，有以下几个步骤：
选择测试TokuDB是因为本身已有业务在使用，自然是想看看在5.7版本中的表现如
thp-setting=never
tokudb
tokudbpk
tokudb_directio
tokudb
tokudb_commit_sync =1
需添加额外的几个参数：
（4）修改参数文件 my.cnf。
（2）我们给TokuDB 创建几个指定的目录，比如：
lock_timeout_debug = 3
tmp
insert
xa
-enable
mode=
/data/mycat_test/s1/toku_log
/data/mycat_test/s1/toku_data
tokudb_zlib
row
format
-user=root--password-s/data/mycat_test/
test/s1/tmp
---
## Page 409
能上 MySQL 也不支持一些高级的统计特性。
做统计分析就容易出现瓶颈了，一来是优化器在 OLAP 的场景支持力度有限；二来从功
10.2.2
较大，snappy 压缩比较小；压缩比最大的是 lzma。
线程数情况下，TokuDB的 TPS 指标相对 InnoDB要高15%~30%，如下表10-3所示。
MySQL 方向支撑OLTP 的业务是不成问题的，但随着数据量的增大，使用 MySQL
而从存储压缩比来看，TokuDB 的优势更为明显，兰
接下来就是使用了，使用TokuDB作为中间件节点做压力测试，在不同的分片节点数、
整个过程其实会安装很多 TokuDB 的插件，可以使用 show plugins 查看。
SELECT @@tokudb_version;
这时候就需要仔细看一下error log文件，看看到底是哪个环节出了问题。
或者是使用如下的SQL来看看TokuDB的版本信息。
安装完成后，
如果不顺利，
Checking
INFO: Option thp-setting=never is set in the config
Checking if
NFO:
INFO:
Checking if Percona Server
INFO:
基于OLAP 的场景选型：Infobright 
线程数
128
3
16
8
查看 show engines 就可以看到存储引擎是没有问题了。
很可能报出下面的错误：
thp-sett
status..
ng=never
分片节点数
plugin
6
9
6
6
is running with jemalloc enabled...
status
option
表10-3
with
currently disabled
is
already set
19892.61
19795.11
18231.94
18253.82
14077.49
13768.96
10670.2
10319.81
InnoDB
当然不同的压缩算法的压缩比差异
第10章基于业务的数据库架构设计”387
file.
5
config file...
30453.59
28238.48
27905.3
24510.4
18018.56
17848.35
12275.74
12359.15
TokuDB
---
## Page 410
388丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
原来的90%以上降到了不到10%。I0的压力也从原来的近100%降到了25%左右。
化，整体的负载情况就相对乐观了。
转移到从库端。
是辅助需求，所以在这种场景下和业务方沟通，快速的响应方式就是把主库的统计需求
结果原本简单的 Insert 也成为了慢日志 SQL；相比而言，写入需求是硬需求，而统计需求
力来自于全表扫描，对于 CPU和IO 压力都很大。
的压力。写入的压力来自于业务的并发写入，而读的压
的架构很简单（如图10-14），是一个主从，外加 MHA 高
计场景，基本都是全表扫描级别的查询语句。当前数据库
写入，会有明确地统计需求。
留言等。所以这类场景不存在事务，会有数据的密集型
比你发送了一条微博，想看看有多少人已读，有多少人
沟通了解，这个业务是记录回执数据的，简单来说就好
写入量剧增，产生了严重的性能阻塞。
100%，现在不是翻了几倍或者指数级增长，而是突然翻了100倍，导致业务后端的数据
具有较高的数据压缩比，对于统计计算的性能表现很不错。
Infobright更加轻量一些。
如Greenplum的 MPP方案。
引擎；还有clickhouse，这些年来相对比较热门：除此之外还有其他大型的解决方案，比
可用。
目前的统计频率是每7分钟做一次统计，会有几类统
转移了读请求的负载，写入压力得到了极大缓解，后来也经过业务方应用层面的优
这两个问题的解决还是存在优先级的，首先统计的 SQL 导致了系统资源成为瓶颈，
问题的改进方向是减少主库的压力，也就是读和写
Infobright 是面向数据仓库方向的解决方案，它最大的特点是引入了列式存储方案，
ColumnStore 的方案有点类似于 MPP 方案，需要的是分布式节点，在资源和架构上
主库的监控负载如下图10-15 所示，可以看到有一个明显降低的趋势，CPU负载从
1．引入读写分离，优化初见成效
MySQL 原生虽不支持数据库仓库，但是有第三方的解决方案：一类是ColumStore,
这个问题引起了我的兴趣和好奇心，
最近有一个业务库的负载比往常高了很多，最直观的印象就是原来的负载最高是
案例10-1：业务库百倍负载的优化方案
我们接下来引入一个案例，通过迭代的优化来分析适合业务场景的数据库方案。
，经过和业务方
图10-14
Slave
Master
---
## Page 411
对于系统整体的负载改进却很有限，所以我们需要对已有的架构做一些改进和优化。
效果很有限。因为从库端的是统计需求，添加的索引只能从全表扫描降级为全索引扫描，
现不够明显，主要的压力在于IO层面，即全表数据的扫描代价极高。
这个算是优化的第一步改进，在这个基础上，也做了索引优化，但是通过对比发现
从库的监控负载如下图10-16 所示，可以看到压力有了明显地提升。CPU 层面的体
N
图10-16
图10-15
11717
网络吞吐量
CPU使用率
LAALN
第10章基于业务的数据库架构设计|389
---
## Page 412
390丨MySQLDBA工作笔记：数据库管理、架构优化与运维开发
改进能够初见成效，后续的架构改进就会更加轻松。
射数据源，相对可控，更容易扩展，所以架构方式改为了下图10-18这种方式。
业务2在第一个节点，业务3、业务5在第二个节点等等；按照这种路由的配置方式来映
目前的中间件方案中很难以落实。而且对于业务来说，统计需求变得更加不透明了。
资源瓶颈除了磁盘空间外就是IO压力，目前通过空间扩容解决不了这个硬伤。
旦出现性能问题，对于中间件的压力极大，很可能导致原本的统计任务阻塞。同时从库端的
的压力就可以完全支撑住了。
为了节省成本，就对原来的服务器做了资源扩容，即单机多实例的模式，这样一来写入
加两个数据节点，然后打算启用中间件的方式来做分布式的架构设计。对于从库，暂时
而整个的改进中，最关键的一环是对于统计 SQL 性能的改进，如果 SQL 统计性能的
在和业务同学进一步沟通后，发现他们对于这一类表的创建是动态配置的方式，
一种行之有效的改进方式就是从应用层面来做数据路由，比如有10个业务：业务1、
但是这种方式有一个潜在的隐患，那就是从库的中间件层面充当了数据统计的角色，一
考虑到资源的成本和使用场景，所以我们暂时把架构调整为下图10-17的方式：即添
方案2
方案1
Master
中间件
Slave
中间件
图10-17
在
---
## Page 413
力就能够平滑地对接了，目前来看写压力不大，完全可以支撑指数级的压力。
的爆发式增长就很容易扩展了。有了这一层保障之后，业务的统计需求迁移到从库，写压
的逻辑不同，这是基于应用层面的分片，由应用端来做这个数据路由。这样分片对于业务
算是心有余而力不足。
个系统的延迟就会变大，
字段有5个，索引就有3个，而且不太可控的是一旦某个表的数据量太大导致延迟，整
统计需求涉及5个 SQL，要对每个场景做优化都需要取舍，最后达到的一个初步效果是
系型的 MySQL。
其实这个业务场景是蛮适合 Redis 之类的方案来解决的，但是介于成本和性价比选择了关
大的时候延迟有3个小时，按照这种情况，统计的意义其实已经不大了。
个，这样一来统计压力变大，导致系统响应降低，从而导致从库的延迟也开始增加。最
着业务的扩展，统计查询的需求越来越多。比如原来是有10个查询，现在可能变成了30
（1）首先是和业务方进行了细致地沟通，对于业务的场景有了一个比较清晰地认识,
（3）对于写压力，后续可以通过分片的策略来解决，这里的分片策略和我们传统认为
结论：索引优化效果有限，需要寻求其他可行解决方案。
（2）对于读压力，目前不仅支撑不了指数级压力，连现状都让人担忧。业务的每个
结论：暂时保持现状。
对此我做了几个方面的改进：
原来的主库读写压力都很大，通过读写分离，使得读节点的压力开始激增，而且随
由于后续又开始有了业务的爆发式增长，使得统计需求的优化成为本次优化的关键所在。
2．引入列式存储，优化统计性能
Master
，从而造成统计需求整体垮掉，所以添加索引来解决硬统计需求
Slave
应用路由
图10-18
第10章基于业务的数据库架构设计”
391
---
## Page 414
392丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
的需求来说还是游刃有余的。
社区版，将专注于 IEE 的开发，所以后续的支持力度其实就很有限了。但对于我们目前
'/data/dump_data/${tab_name}.csv'
需要继续扩容。
影响。
队内部也有大量的实践经验。
粒度和团队经验综合考虑下，我们选择了 Infobright。
询效率，同时保证系统的压力在可控范围内。
技术实现来说是肯定存在的，我们的改进方法是提高统计的查
条统计 SQL，做完统计大约需要17~18分钟左右，平均每个表需要大约2 分钟。
但是延迟还是存在，查询依旧是慢，很难想象在指数级压力的情况下，这个延迟会有多大。
Infobright 社区版是不支持 DDL 和 DML 的，后期 Infobright 官方宣布：不再发布 ICE
select *from $(tab_name) where create_time between xxx and xxxx into outfile
需要在此基础上扩展一个数据仓库节点，数据量可以根据
我们的表结构很简单，字段类型也是基本类型，而且在团
在做了大量的对比测试之后，按照单表3500万条的数据量，8张同样数据量的表，5
1 row in set (6.20 sec)
>select count( id) from testxxx where id>2000;
CREATE TABLE
 改进之后的整体架构如图10-19，原生的主从架构不受
一种行之有效的方式就是借助于数据仓库方案，
来简单感受下 Infobright 的实力。
因为没有事务关联，所以这个场景的延迟根据业务场景和
1138266841
>sel
导出的语句类似于：
表结构如下：
为了快速改进现状，我写了一个脚本自动采集和管理，会定时杀掉超时查询的会话。
结论：业务数据路由在统计压力减缓后再开始改进。
7276862051
count(id)
create_time`
readtimes
action
userid`
int(11)
int
int(11） NOT DEFAULT
(11)
NOT
receipt 12149 428