# 优化后的文本

## 表3：使用微调方法和我们的方法在源数据集上训练的NID模型性能对比

我们比较了我们的方法与基于微调的迁移学习方法。结果显示，我们的方法在F-score方面分别提高了9.83%和6.93%。对于其他攻击类别（如侦察和shellcode），当样本数量小于500-1000时，我们的方法在分类准确率和F-score方面均优于其他两种比较方法。

### 小样本量导致的过拟合问题

其他方法在小样本量下表现不佳的主要原因是深度学习模型在这种情况下容易发生严重的过拟合现象。小样本量使得模型能够很好地拟合训练数据，但在未见过的数据上泛化能力较差。我们的对抗性域适应方法通过将源数据集样本用于扩充目标数据集，并将其投影到一个共同的潜在子空间中，从而缓解了由于训练数据量过少而导致的过拟合问题。

### 源数据集上的性能测试

我们还测试了使用微调方法和我们的对抗性域适应方法训练的分类模型在源数据集上的准确性。这代表了模型在旧源数据集（包含8个攻击类别）上的性能。我们没有包括仅用目标数据集训练的基础模型，因为它在分类源数据集攻击类别时表现非常差。表3展示了我们在源数据集上的分类模型准确度结果。观察到，我们的对抗性域适应方法在源数据上保持了91-94%的准确率，而微调方法创建的模型则极不稳定。这表明我们的方法不仅在目标数据集上表现良好，在源数据集上也具有很高的准确性，能够同时检测到目标数据集中的新攻击和源数据集中的旧攻击。

### 结合源数据集和目标数据集

一种简单的结合源数据集和目标数据集来训练NID模型的方法是直接合并两个数据集并用其进行训练。为了评估这种方法，我们进行了额外的实验。结果显示，尽管使用这种简单方法训练的NID模型在源数据集上达到了高准确率和F-score，但在目标数据集样本量极少的情况下，它们的表现不如我们的对抗性域适应方法。例如，在利用100个样本进行exploits、侦察和shellcode攻击训练时，对抗性域适应方法在目标数据集上的准确率分别高出6.03%、8.26%和3.45%。

### 不同特征空间下的性能

该类场景表示目标数据集与源数据集具有不同的特征空间。

**数据集**：为此评估，我们使用NSL-KDD [46]作为源数据集，UNSW-NB15 [34]作为目标数据集。移除了特定攻击类别并将问题建模为二分类问题，即预测当前记录是否属于攻击或良性类别。源NSL-KDD数据集包含62,986个标记训练样本，我们改变了用于训练的目标UNSW-NB15数据集样本数，分别进行100、200、500、1000、5000、10,000和20,000个标记训练样本的实验。

**预处理**：由于微调方法要求源数据集和目标数据集具有相同的特征空间，因此我们在使用微调方法之前对两个数据集进行了预处理，使其都具有30个特征。同样地，我们也对数据进行了预处理以适应对抗性域适应方法的要求。

**实验结果**：图7展示了此场景的结果。从实验中观察到，当目标数据集样本为100时，我们的对抗性域适应方法在准确率上比基础案例和微调方法分别高出17.9%和5.78%，在F-score上分别高出20.94%和10.26%。虽然微调方法相比基础案例有所改进，但仍然不及我们的方法。这些结果与相同特征空间下的实验结果相似，表明我们的对抗性域适应方法在不同特征空间下也能表现出色。

### 结论与未来工作

本文提出了一种对抗性域适应方法，用于在仅有少量标记训练数据的情况下训练深度学习分类模型进行网络入侵检测。这使组织能够利用现有数据集（如公开可用的数据集或过去使用的数据集）以及针对新攻击家族捕获的一小部分标记数据来训练NID模型。实验表明，使用我们的对抗性域适应方法训练的NID模型在源数据集和目标数据集具有类似特征（同质域适应）和不同特征（异质域适应）的情况下均优于其他方法。

未来工作计划考虑半监督域适应（目标数据集中有一些标记样本和大量未标记样本）和无监督域适应（目标数据集中只有未标记样本）的情况。此外，我们还将评估更复杂的GAN架构，如Wasserstein GANs [3]。本文将NID问题建模为二分类问题，但探索多分类问题（即识别目标数据集中的具体攻击类别）也将是一个有趣的方向。此外，可以使用仅包含特定网络（如物联网网络或移动网络）标记数据的目标数据集来评估对抗性域适应方法的有效性。另外，使用多个源域进行对抗性域适应可能产生更通用的模型，能够识别多种网络类型的攻击。最后，考虑到隐私保护的需求，需要开发隐私保护的域适应技术，以便在不泄露源数据集的情况下实现域适应功能。

### 致谢

本研究由美国陆军研究实验室和英国国防部赞助，协议编号W911NF-16-3-0001。本文的观点和结论仅代表作者个人观点，不代表美国陆军研究实验室、美国政府、英国国防部或英国政府的官方政策。

### 参考文献

[略]

---

以上是对原文的优化版本，希望能够帮助你更好地表达内容。如果还有进一步的需求，请随时告知！