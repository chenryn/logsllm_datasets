to report dishonest logging whenever they see it. There are two
problems with this: firstly, government agencies and companies
might be forgetful, and cannot be trusted to post information reg-
ularly to a public ledger. Secondly, companies might be loath to
report possibly dishonest logging by law enforcement agencies
when they see it, fearing retribution.1
We remove this requirement by introducing an independent
auditor, called Enforcer (E), who can keep both, the company and
the law enforcement agency in check. 2) In [24], ZKPs created by
an agency and/or company are basically a proof that they are aware
of the court’s surveillance order. A ZKP is a proof of knowledge,
not compliance; merely proving knowledge of the contents of a
court’s orders does not guarantee that the agency/company are
complying with the court’s orders. In our system, the Enforcer
explicitly verifies that the data requested by the law enforcement
agency, and given by the company are within the ambit of the
court’s surveillance order. This is done in a privacy-preserving
manner such that the Enforcer does not actually get to know the
user’s data (e.g., emails), but is able to verify that the agency is not
over-requesting data, and the company is not over-sharing data.
3 SYSTEM MODEL
Parties: In our system, there are six parties: the individual being
surveilled I, company C that I has an account (e.g., e-mail) with, law
enforcement/intelligence gathering agency L requesting the surveil-
lance, Judge J who can potentially issue the surveillance order on I,
and an Enforcer E, who enforces accountability of L and C’s opera-
tions, by ensuring that L does not request more information about I
than what is authorized by J, and C does not over-share information
about I, more than what is authorized by J. Finally our system has a
set of interested users, U, made up of civil-rights and/or non-profit
organizations (e.g., American Civil Liberties Union (ACLU)) whose
mission is to protect and preserve individuals’ privacy as defined
by laws. We assume that all communication between J, L, C, E, I,
and U takes place via secure and authenticated channels. They use
each other’s public and verification keys, respectively to encrypt
and authenticate all communication between them.
We note that I ⊂ I, where I is a set of individuals who have an
account with C. Our table of notations is given in Table 1.
Identities of an individual I: In our system, an individual I has
three identities associated with her:
A real identity, RI which may correspond to I’s e-mail address
that is being surveilled. RI is established between I and C when I
signs up for service with C. In our system RI is represented by a
verification/signing key-pair: RI = (V KRI, SKRI). The company C
stores V KRI and V KRI is known only to J, L, and C. In particular,
RI will not be known to E. We assume that RI is stored safely by
I, does not get compromised, and acts as the root-of-trust for all
other keys involving I.
An anonymized identity, AI, which corresponds to a nickname
associated with RI. When a user signs up for service with a com-
pany, they are asked to create the anonymized identity AI which is
linked by C to their real identity RI. The user can create only one
anonymous identity with a service provider (e.g., one nickname per
1A report issued by the US Department of Justice’s OIG [2] says that they found
company employees provided telephone records to the FBI in response to just verbal
and e-mail requests, without legal process or even exigent letters, since they (company
employees) believed the requests related to major FBI counterterrorism investigations.
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2251e-mail address). We represent AI by a keypair: AI = (V KAI, SKAI).
We use anonymized identities to avoid having the enforcer know
RI. The company C stores V KAI which is known and revealed to
E, J, L, and C during the surveillance period.
A pseudonymous identity, PIi; i ∈ [1..m], represented by PI =
(V KPIi , SKPIi) which corresponds to I’s pseudonym associated with
AI. The pseudonymous identity can be chosen from a set of m
identities, with the restriction that only one pseudonymous identity
can be active at any given point of time, and a pseudonymous
identity cannot be reused. Pseudonymous identities, as opposed
to real and anonymized identities, are transient key-pairs. V KPI
is known and revealed to E, J, L, and C. The company stores all
historical V KPIs for future verification.
An individual storing data on company servers: Although
SAMPL enables the auditing of a broad range of data and application
types, for illustration in this paper we use user emails. In Section 9,
we generalize this requirement. When an individual I signs up for
service with a company C, it interactively creates a symmetric key
KCI to be shared between C and I. I uses KCI to encrypt sensitive
information, but keeps the date and time as plaintext and signs
the whole message. KCI can be updated periodically. C and I agree
on two parameters, bSize and bNum, which denote batch size and
batch number.
The batch size represents the intervals at which the user’s mes-
sages are batched. The batch number indicates the batch a given
message originates from. Let I’s total data records, e.g., emails be
denoted by T . Then bNum = T/bSize, bSize can be a static or dy-
namic parameter. In the static case, I sets up bSize at the time of
service initiation with C, and doesn’t change it; in the dynamic case,
bSize can be changed by I as needed. SAMPL supports both these
implementation choices.
I creates and encrypts each email with KCI before sending it to
C. At the end of each batch, C creates a Merkle tree with the hashes
of all messages in the batch at the leaves. C sends the root hash
of the Merkle tree to I. I verifies the root hash calculation, signs
it if accepts, and sends it to C. All signatures contain a timestamp
which has sign date and time. C then discards the Merkle tree and
archives just the signed root hash, since C can create the Merkle
tree on demand from the stored ciphertexts as needed.
Role of Enforcer, E: Each communication between L and C in-
volves them independently passing the message to E for verification.
Once E verifies that the message is not over-requesting or over-
sharing data with respect to an approved court order, the message
is passed on to the intended recipient (C or L). When surveillance
data from C is approved by E and received by L, C sends the shared
key, KCI directly to L, who can can then decrypt the information
and carry out the investigation.
We envision the enforcer to be a government watchdog or or-
ganization that oversees adherence to laws and rights by private
companies and law enforcement agencies. Federal agencies have
their own oversight entities, e.g., FBI is audited by the Department
of Justice’s Office of the Inspector General (OIG). Other federal
agencies also have their corresponding auditing entities. These en-
tities currently do auditing when needed, and hence the auditing
always happens after the event. We propose that the OIG plays a
proactive role in auditing such process, and enforce accountability
from the beginning, rather than play a reactive role and issue review
and audit reports after-the-fact, as it currently does.
Blockchain and its operations: The blockchain, BC, is used as an
official record for verification of actions performed, we use it as an
off-the-shelf enabling technology. When forwarding a request, each
entity posts a signed hash of the request/response to the blockchain–
a transaction–all messages posted on the BC are signed. The BC
also serves as a platform to announce new cases to the public
watch dogs and the general public without divulging investigation
details. The miners ensure that only valid entities involved in an
investigation can post transactions to the BC. We envision the
implementation of SAMPL using a permissioned blockchain with
read-only access given to public. For efficiency and fast convergence,
proof-of-stake may be used as the distributed consensus mechanism.
The infrastructure required for the BC may be maintained and
managed by the judicial system to engender greater trust.
4 THREAT MODEL
We list trust assumptions on the parties in the system:
Judge J: The judge J is assumed to be honest, but forgetful, i.e.,
J might forget to unseal records at the right time. J is trusted to
correctly generate an Surveillance Order (SO) and place it on the BC.
Whenever SO’s seal expires, members of U can choose to contact
J to make public the contents of SO. U can then verify details of
case, including contacting I as needed.
Law enforcement agency L: L is assumed to be malicious, in that
L will try to over-request data beyond what is authorized by the
SO issued by J (we discuss some overreaches in the real world in
Section 6.2). Once the SO is posted by J on the blockchain, L will
contact E with a surveillance request (SR). SR will be checked and
ratified by E based on the SO and prevalent policies.
Company C: C is assumed to be malicious, in that C can over-share
data beyond what is sought by the SR, and authorized by J’s SO.
If C fails to respond to an SR with a surveillance request response
(SRR), then there are policy measures that can be exercised by J to
enforce compliance.
Enforcer E: E verifies each SR generated by L and also verifies
each SRR generated by C, respectively. We assume E is honest. The
enforcer only knows I’s anonymized identity, AI and pseudonymous
identity, PI. In particular, E is not privy to I’s real identity RI. E
also does not have access to the plaintext version of I’s records
stored with C (e.g., emails). When a certain threshold of failures on
the part of L, C is reached (which can be a implementation specific
system parameter), E can choose to contact J and post a message
to BC exposing identity of the faulty party. The enforcer does not
store information linking AI and PI after evaluating an SRR.
No collusion assumption: In our system, we assume L and C
do not directly communicate with each other, and go through E for
information exchanges. We believe if L and C break this protocol
and interact directly, auditable data structures [26] may be used to
verify the operations of C. However, out of band, unbridled data
exchange is difficult to prevent when both parties are complicit.
Nevertheless, for accountability, it is in L’s and C’s interest to act
according to due process, and go through E, and not collude.
4.1 Privacy and security properties
SAMPL provides the following privacy and security properties:
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2252Accountability for L and C: We ensure that a malicious L and/or
C cannot over-request, or over-share data, respectively, beyond
that authorized by the SO, as long as they do not bypass the en-
tire system, and collude via side-channels. This applies to both:
over-requesting/over-sharing of the surveilled user’s data, or data
belonging to users not listed in the SO (not under surveillance).
Forgetful J: Our system enables an independent set of users, U (e.g.,
non-profit organizations such as ACLU) who keep track of court-
order unsealing dates, to contact the courts to unseal non-sensitive
information, contact the individuals who were being surveilled, and
help them with further courses of action.
Security against malicious I and C: We ensure that a malicious
I cannot make C fail E’s queries by creating fake ZKP for their
real, anonymous and pseudonymous identities. Also, a malicious C
cannot create fake data for I and frame I.
We now give the computational assumption for our system.
Definition 4.1. (DDH Problem [10]) We say that the DDH prob-
lem is hard relative to G if for all PPT algorithms A, there is a
negligible function negl such that
|Pr[A(G, q, д, дx , дy, дz) = 1]
−Pr[A(G, q, д, дx , дy, дxy) = 1]| ≤ negl(λ)
where in each case the probabilities are taken over the experiment
in which G(1λ) outputs (G, q, д), and then uniform x, y, z ∈ Zq are
chosen.
5 DESCRIPTION OF SAMPL
As a pre-requisite to using SAMPL for surveillance, I and C interact
to setup keys, associated ZKPs, and other operations as outlined
in Section 5.1. Surveillance on user I’s data is carried out with in-
teractions between J, L, C, and E as described in Section 5.2. We
note that SAMPL has 7 protocols and 4 algorithms. We adopt the
convention that communication protocols are run between two
or more entities, and algorithms are computations done by a sin-
gle entity. We recall that per our system model we assume that
all communication between entities takes place over secure and
authenticated channels.
5.1 Pre-Requisite for SAMPL
Protocols 1 and 2 bootstrap the communication between C and I,
and the corresponding data exchange. These protocols are required
so that in case of surveillance request by L for I’s data, E can verify
the user data without gaining any knowledge about identity of I.
Protocol 1: This is run by an individual I the first time she
sets up an email account with company C. In Line 1, I does two
3-round ZKPs with C to prove that: 1) V KAI was produced by
someone who has knowledge of SKRI, and 2) V KPIi
was gener-
ated by someone who has knowledge of SKAI (if C accepts V KAI
as valid). At the end, C will receive from I a copy of V KAI, V KPIi
and their associated ZKPs, πAI, πPIi
, and signed copies of the ZKPs:
(πPIi), along with some public
σAI = SignSKRI
= SignSKAI
verification metadata, zkpVerf , which will be used by the Enforcer
for verifying the ZKPs. The proofs are Chaum-Pedersen-style in-
teractive ZKPs [16], which can be made non-interactive using the
Fiat-Shamir transform [20]. Since the ZKPs are essentially used as
(πAI), σPIi
Protocol 1: Setup run between C and I.
:Public parameters: Group G, q = |G|, д, h ∈ G.
Input
Output: I establishes RI, AI, PIi , bSize and KCI with C.
Parties :C and I.
1 User I sets up (V KAI, SKAI) and (V KPIi , SKPIi), and sends
the ZKPs, their verification metadata, and signatures on
the ZKPs: (πAI, πPIi), zkpVerf , and (σAI, σPIi), respectively,
to C.
2 User I sets up a shared key with C, KCI , used to encrypt I’s
3 C and I agree upon and setup a batch-size, bSize ∈ Z+.
data stored on C’s servers.
black-boxes, in order not to distract the reader with their details, we
give the ZKPs and their description in Appendix A.
Next, I and C setup a shared key KCI using which I’s emails
stored on C’s servers are encrypted. I and C also agree upon a
batch-size bSize, which denotes the message-intervals at which I’s
emails will be batched, e.g., after every 100 emails. C will batch all
of I’s emails at bSize intervals and create a Merkle hash tree for the
batch with the hashes of the emails at the leaves; I will verify and
sign the root of the tree.
Protocol 2: Exchange of data between C and I for a given
batch.
:Public parameters: bSize, bNum ∈ [1..maxbNum].
Input
Output:C stores I’s emails along with verification hashes.
Parties :C and I.
1 Let MbNum represent the set of all e-mail messages in bNum.
2 for each Mx ∈ MbNum, x ∈ [1..bSize] do
I encrypts Mx : Cx ← KCI(Mx), sends Cx to C.
C stores Cx .
3
4
end
5 /* At the end of batch bNum of bSize messages: */
Let CbNum represent the set of all ciphertexts in bNum.
6 begin
7
C generates hashes, Hx = H(Cx), for all the Cx received
from I.
C forms a Merkle tree MbNum, with the Hx s at the
leaves, and RbNum as root of the Merkle tree.
C sends MbNum and RbNum to I.
I verifies that the root hash (RbNum) of MbNum is
correctly computed:
10.1 If verification fails, I notifies C to retry.
10.2 Else, I signs RbNum: σRbNum ← SignSKPIi
sends σRbNum
C stores σRbNum
batch bNum.
(RbNum),
to C and deletes all local copies of Mx .
along with previously stored Cx ’s for
8
9
10
11
end
Protocol 2: Protocol 2 depicts I’s emails being stored on C’s
servers. Before I and C execute this algorithm, they would have
already run Protocol 1 to setup the symmetric key KCI . I creates an
email message Mx and encrypts it with KCI , generating Cx , before
forwarding it to C (Lines 2,3,4). This already happens in OpenSSL,
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2253Session 9E: Web Censorship and Auditing
CCS ’19, November 11–15, 2019, London, United Kingdom
where the connections (and data transmitted) between two commu-
nicating entities are encrypted using pairwise symmetric session
keys.
4 J validates C’s response, checks if
Protocol 3: J issuing SO and posting SO on BC.
:V KAI, V KPI of user I, G, д, h ∈ G, q = |G|.
Input
Output: J issues SO, sets up keys KJ LC , KEJ LC and