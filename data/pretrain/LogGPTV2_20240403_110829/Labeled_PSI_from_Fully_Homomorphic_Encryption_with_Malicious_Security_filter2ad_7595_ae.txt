know the plaintext value OPRFk(y) to be able to compute an encryption of H(OPRFk(y)) with
non-negligible probability. As such, the sender is restricted to choosing a set X(cid:48) of polynomial
size, possibly larger than Nx, and using this in the PSI protocol. In particular, the simulator can
extract X(cid:48) as all x such that the sender has queried H(OPRFk(x)). We note that the sender is not
committed to its set X(cid:48), and can use an arbitrary subset of it in each protocol invocation.
On the other hand, the sender is still able to make the intersection indirectly depend on the set
Y \ X. In particular, the sender can choose a circuit leakage(·) and the ideal functionality is deﬁned
to be
X ∩ Y ∩ leakage(Y ) ,
This leakage function models the fact that the sender can perform some malicious computation
with the receiver’s encrypted hash table. This allows the sender to conditionally remove items from
the intersection based on items which are in Y \ X. See Appendix A for the full security proof.
While such an attack can be serious in some settings, this leakage is signiﬁcantly less than in [12],
where the sender can force the intersection to be Y .
Now we turn our attention to the setting where the sender reuses the pre-processing phase
with multiple receivers. Here the hashing parameters have to be ﬁxed and reused. In particular,
the cuckoo hash function and the hash function H used to hash to σ bit strings are picked by the
sender. This deviates from Step 1 and 2 of Figure 2, where the parties jointly sample random hash
functions. This has the implication that the sender can select hash functions which conditionally
fail based on the receiver’s set Y . For example, if y, y(cid:48) ∈ Y both hash to cuckoo position i under
all three hash function, cuckoo hashing will fail. This class of failures would be observable by the
sender, and leak that the receiver’s set is a member of all the sets which fail to cuckoo hash under
these parameters—a single bit of information.
While such attacks can be serious, we argue that many applications can tolerate leaking a
single bit. One countermeasure which can be employed is to sample the hash functions from a
public reference string. This could signiﬁcantly restrict the eﬀectiveness of such selective failure
attacks, as the hash functions are then ﬁxed.
8 Experiments
We implemented our protocols (unbalanced PSI for arbitrary length items, and Labeled PSI)
and benchmarked against previous methods. For unbalanced PSI with both long and short items our
points of comparison are [47,5] and [12] respectively. For labeled PSI, we compare with multi-PIR
by keyword from the multi-query SealPIR solution of [2].
Our implementation is built from scratch on top of the homomorphic encryption library SEAL
v2.3.0-4, which is based on the BFV scheme [22]. We give a detailed report of the end-to-end and
online running times along with the communication overhead of our protocol in Figure 4, both in
single and multi-threaded settings. We restrict the receiver to at most 4 threads to model a low
power device, while the sender utilizes up to 32 threads as denoted in the table. Figure 5 shows a
comparison with the unbalanced PSI protocols of [47,5,12].
We benchmark the protocols on a 32-core Intel Xeon CPU with 256 GB of RAM. We note that
this machine is similar to that utilized by [12], and that the numbers reported for their protocol
are obtained directly from their paper. All protocols are ran in the LAN setting with a 10 Gbps
throughput, and sub-millisecond latency.
8.1
Improved Communication from Symmetric-Key BFV
We further improve our communication cost by modifying SEAL a little bit to use a symmetric-key
variant of the BFV scheme instead of the more common public-key variant. The beneﬁt of this is
that the second polynomial in a freshly encrypted BFV ciphertext (see [22]) does not have to depend
on a public key and can thus be generated from a random seed. As a result, the size of every freshly
encrypted ciphertext is nearly halved, signiﬁcantly reducing our R → S communication. Once the
sender receives the half-size ciphertexts it can expand the seeds to obtain the full ciphertexts.
Unfortunately, after homomorphic multiplications there is really no way to go back to the half-size
representation, so this technique cannot improve the R ← S communication. We can also employ
the various trade-oﬀs in the protocol to put more communication in the R → S step which then is
halved, resulting in a signiﬁcant (20 − 40%) improvement in total communication with negligible
computational overhead.
8.2 Unbalanced PSI
Figure 4 contains our main set of performance numbers and demonstrate a wide ﬂexibility in set
sizes. For the sender, we consider set sizes of 220, 224 and 228, while the receiver’s set sizes range
between 128 and 4096. We note that for each of the receiver’s set sizes, approximately 1.33 times
more items could be added with no diﬀerence in performance due to extra space in the cuckoo
table. However, to give a fair comparison with other protocols without parameter restrictions we
round down to the nearest power of two.
We begin with our performance numbers for the smallest set sizes of |X| = 220 and |Y | = 128.
For such a small intersection our protocol is extremely eﬃcient, requiring an online time of less
than a second on a single thread, and only 3.9 MB of communication. When the receiver’s set is
increased to 512 items we observe only a minimal increase in running time and communication.
Moving to our largest receiver set size of 4096, we observe roughly a 4.7× increase in online running
time and a 3× increase in communication. This sublinear growth in overhead with respect to the
receiver’s set size is attributed to the ability to use more eﬃcient FHE parameters. With respect
to the sender’s oﬄine running time, we observe that in almost all cases with |X| = 220 the running
time is roughly 40 seconds on a single thread. The one exception is for |Y | = 256, which has double
the running time. This is attributed to the FHE parameters used that allowed an eﬃcient online
time at the expense of increased computation during the oﬄine phase.
Increasing the sender’s set size to |X| = 224 we observe a similar trend, where a smallest set
sizes for the receiver all obtain the same performance. Indeed, for |Y | = 128, 256, 512 the same FHE
parameters were utilized, which yield a single thread online running time of 9.1 seconds, and 8.2 MB
of communication. The choice to use oversized parameters for the smaller set sizes stems from the
highly complex interplay between the parameters that can be optimized, while also maintaining a
computational security level of 128 bits. We refer to Section 3.1 for a more detailed explanation. For
a receiver’s set size of 4096 we observe an online running time of 22 seconds in the single threaded
setting, and 15.9 MB of communication. The sender’s oﬄine time required 806 seconds on a single
thread, or 32 seconds on 32 threads. Interestingly, this oﬄine running time is faster as the sender’s
set size increases. Among other things, this is the result of the sender’s database having fewer items
per bin as |Y | increases, which in turn decreases the degree of the polynomials the sender needs to
compute in pre-processing, resulting in improved performance.
In addition, we consider the case of |X| = 228 which, as far as we are aware of, is the largest
PSI set size to have ever been considered in the two-party setting, and is only surpassed in a
weaker model where an untrusted third party assists in the computation [32]. For this case we
consider a receiver’s set size of 1024, and observe that the online phase can be performed in just
12 seconds when the sender and receiver respectively use 32 and 4 threads. At the same time, the
online phase utilizes only 18.4 MB of communication. The primary impact of such a large set size
is on the sender’s oﬄine running time. However, in cases where such a large set is used, it is highly
likely that the set is held by a powerful server and is relatively static, in which case the sender
can amortize the cost of the pre-processing across several protocol executions. We also note that
our protocol allows fast additions and deletions from the pre-processed set by updating only small
targeted locations when necessary. Moreover, the current implementation of the oﬄine phase is far
from optimal in that there exists more eﬃcient algorithms for computing coeﬃcients of the sender’s
polynomials, which is the primary bottleneck.
8.3 Comparison
We now move on to the comparison with the OPRF-based protocols of [47,5] and the FHE-based
protocol of [12]. First we recall the protocol paradigm of [47,5,31]. These protocols utilize the same
Sender oﬄine
8
32 T=1
Online
8
4
|X|
|Y |
228 2048
1024
T=1
–
–
4
–
–
– 4,628
– 4,628
–
–
–
–
– 28.5
– 12.1
Comm.
32 R → S R ← S
10.2
10.2
11.8
8.2
224
220
806 206 111
4096
2048
747 483 58
1024 1430 418 155
512 1368 267 146
256 1368 267 146
128 1368 267 146
4096
2048
1024
512
256
128
43 6.1 3.3
39 4.9 2.7
40 5.1 2.9
36 5.5 2.6
87 18.4 9.5
46 6.7 3.8
32 22.0 5.9 3.5 2.2
18 12.6 3.4 2.0 1.4
51 17.7 5.2 2.9 1.1
9.1 2.6 1.5 0.7
45
9.1 2.6 1.5 0.7
45
45
9.1 2.6 1.5 0.7
1.2
1.1
1.1
0.5
3.3
1.2
4.2 1.3 1.3 1.2
2.1 0.7 0.6 0.6
2.0 0.7 0.5 0.5
1.0 0.4 0.3 0.3
2.4 0.8 0.6 0.3
0.9 0.4 0.3 0.2
8.7
8.2
3.1
3.1
3.1
3.1
4.2
2.9
2.5
1.5
2.1
0.9
7.2
8.1
5.1
5.1
5.1
5.1
7.2
3.6
2.5
2.5
1.0
3.0
Fig. 4. Performance metrics of our protocol in the LAN setting for various set sizes. “Sender oﬄine” reports the
running time in seconds required to initialize the sender’s set. This is non-interactive and can be reused with multiple
receivers. “Online” reports the end-to-end running time in seconds required to perform the intersection, where the
“Comm.” columns report the directional communication requirements in MB. T is the number of threads used by
the sender. The receiver uses max{T, 4} threads.
Diﬃe-Hellman based OPRF as our protocol, where the sender holds the key k and applies the
OPRF to its set X to obtain X(cid:48) = {Fk(x) : x ∈ X}. The receiver then interactively computes