proach may work, it sacriﬁces performance and efﬁciency by leav-
ing resources idle.
A second approach is to apply smarter scheduling. Based on the
contention results in Section 4, the hypervisor can monitor the VMs
between processes and attempt to schedule those workloads that do
not conﬂict. This approach, often applied to multicore and multi-
threaded scheduling [6, 10, 29], detects workloads with conﬂicting
resource usages via statistics and processor performance counters,
and attempts to schedule them at different times, so they do not
concurrently share the contended resource, or on separate cores or
packages to reduce contention, as in the case of the LLC.
289No-RFA
512
Baseline
E5507-1 E5507-2 E5507-3 E5507-4 E5507-5 E5507-6 E5507-7 E5507-8 E5507-9
(a) LLCProbe
No-RFA
512
Baseline
E5507-1 E5507-2 E5507-3 E5507-4 E5507-5 E5507-6 E5507-7 E5507-8 E5507-9
(b) bzip2
No-RFA
512
Baseline
E5507-1 E5507-2 E5507-3 E5507-4 E5507-5 E5507-6 E5507-7 E5507-8 E5507-9
(c) mcf
No-RFA
512
Baseline
)
s
u
(
e
m
i
t
n
u
R
.
g
v
A
)
s
u
(
e
m
i
t
n
u
R
.
g
v
A
)
s
u
(
e
m
i
t
n
u
R
.
g
v
A
)
s
u
(
e
m
i
t
n
u
R
.
g
v
A
22000
20000
18000
16000
14000
12000
10000
8000
172
170
168
166
164
162
160
158
156
154
152
56
55
54
53
52
51
50
49
48
41.5
41
40.5
40
39.5
39
38.5
38
37.5
37
E5507-1 E5507-2 E5507-3 E5507-4 E5507-5 E5507-6 E5507-7 E5507-8 E5507-9
(d) sphinx
Figure 11: Average runtimes of LLCProbe, bzip2, mcf, and sphinx benchmarks across all 9 machines. Baseline has no trafﬁc to
victim, while No-RFA and 512 RFA have foreground request rate of 2000 rps.
290A ﬁnal idea would be to prevent RFAs by detecting and blocking
them. We suspect that this would be very difﬁcult in most settings.
RFAs need not abuse vulnerabilities on a system, rather they can
simply take advantage of legitimate functionality (e.g., CGI scripts
on a web server). Moreover they are stealthy in the sense that it
may only require a few requests per second to drive the victim up
against a resource bottleneck. A provider or the victim itself would
be hard pressed to detect and block RFA requests without prevent-
ing legitimate access to the resource.
7. RELATED WORK
Our work builds on past work surveying the performance interfer-
ence of virtual machines, hardware and software techniques for im-
proving performance isolation, side-channel attacks, and scheduler
vulnerabilities.
Performance interference. Numerous works have found severe
performance interference in cloud computing platforms [15, 22, 26,
34]. Our study of performance interference focuses more on the
worst-case interference in a controlled setting than on the actual
interference in cloud platforms. In addition, we measure the inter-
ference from pairs of different workloads rather than two instances
of the same workload. Finally, our work looks at the impact of
multicore scheduling by pinning VMs to a speciﬁc core.
Performance isolation. Contention for cache and processor re-
sources is a major cause of performance loss, and many projects
have studied resource-aware CPU schedulers that avoid contention [6,
18, 38]. In cache/network contention, these schedulers may place
the cache and network workloads on different packages to avoid af-
fecting the cache. Similar work has been done at the cluster level
to place jobs [30, 27, 16]. These systems attempt to place work-
loads that use non-interfering resources together or even to leave a
processor idle if interference is bad. These systems would reduce
the effect of performance isolation and thus reduce the need for and
ability of RFAs to improve performance.
Beyond scheduling, software mechanisms can ensure performance
isolation for many hardware resources, including cache [24], disk [11],
memory bandwidth [32] and network [28]. Similar to the sched-
ulers described above, these techniques all reduce the performance
interference from contention, and if used in a non-work-conserving
fashion, can remove the need/beneﬁt of RFAs.
In addition to software techniques, changes to low-level hard-
ware have been proposed to better share memory bandwidth and
processor caches [20, 23]. Similar to the software isolation tech-
niques, such mechanisms would reduce the amount of contention
and hence the need for RFAs.
Gaming schedulers and allocators. The network/cache RFA works
by forcing the scheduler to context switch at much coarser granu-
larities than normal. Similar techniques have been used in the past
to game schedulers in Linux [31] and Xen [37] in order to extend
the timeslice of a thread. These techniques exploit the difference
between the granularity of CPU allocation (cycles) and the granu-
larity of accounting (timer ticks). RFAs are different in that they
convert an interactive workload into a CPU-bound workload, and
thus affect the priority with which a process is scheduled.
Side-channel attacks. RFAs exploit the lack of isolation to boost
performance. Several projects demonstrated side-channel attacks
through the shared LLC that can be used to extract information
about co-resident virtual machines [25, 36, 35].
8. CONCLUSIONS
Performance isolation proves an elusive goal in cloud computing
environments. Despite years of research on how to reduce con-
tention, current cloud providers do not provide strong isolation for
reasons of cost and efﬁciency. We have outlined a new threat that
arises at the intersection of imperfect isolation and public clouds:
resource-freeing attacks. These are incentivized by the fact that
contention can lead to signiﬁcant efﬁciency loss, and that translates
directly into increased customer costs.
While obviously motivated, we sought to also understand whether
they are possible to mount. We therefore performed extensive ex-
periments both on a local Xen testbed and on Amazon EC2. The
results show that, for a certain class of benchmarks, a greedy cus-
tomer can use RFAs to signiﬁcantly reduce contention for a re-
source by manipulating a co-resident victim’s workload. Having
observed gains of up to 13% on live EC2 instances suggests that
RFAs are likely to offer improvements for real applications as well.
This is a problem, both for the direct victims of an RFA (that
incur increased cost due to spurious requests) and for the cloud
provider, which will loose overall efﬁciency because of the load
caused by the extraneous (malicious) gaming of resource alloca-
tions. We leave as an open question a detailed exploration of im-
proved resource allocation mechanisms that de-incentivize or com-
pletely prevent RFAs.
Acknowledgments
We thank Ari Juels for the initial observations about how cloud re-
sources might be adversarially gamed, which motivated this work,
and thank Kevin Bowers and Ari Juels for many helpful discussions
about resource-freeing attacks. This work was supported in part by
NSF grant 1065134 and by a gift from EMC. Swift has a signiﬁcant
ﬁnancial interest in Microsoft.
9. REFERENCES
[1] Specjbb2005. http://www.spec.org/jbb2005/.
[2] Graph 500. Graph 500 benchmark 1.
http://www.graph500.org/.
[3] Amazon Ltd. Amazon elastic compute cloud (EC2).
http://aws.amazon.com/ec2/.
[4] Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim
Harris, Alex Ho, Rolf Neugebauer, Ian Pratt, and Andrew
Warﬁeld. Xen and the art of virtualization. In SOSP, 2003.
[5] Sean K. Barker and Prashant Shenoy. Empirical evaluation of
latency-sensitive application performance in the cloud. In
MMSys, 2010.
[6] M. Bhadauria and S. A. McKee. An approach to
resource-aware co-scheduling for cmps. In ICS, 2010.
[7] L. Cherkasova, D.Gupta, and A. Vahdat. Comparison of the
three cpu schedulers in xen. SIGMETERICS Performance
Evaluation Review, 25(2), September 2007.
[8] Scott A. Crosby and Dan S. Wallach. Denial of service via
algorithmic complexity attacks. In Usenix Security, 2003.
[9] Jake Edge. Denial of service via hash collisions.
http://lwn.net/Articles/474912/, January
2012.
[10] Alexandra Fedorova, Margo Seltzer, and Michael D. Smith.
Improving performance isolation on chip multiprocessors via
an operating system scheduler. In PACT, 2007.
[11] Ajay Gulati, Arif Merchant, and Peter J. Varma. mclock:
Handling throughput variability for hypervisor io scheduling.
In OSDI, 2010.
291[12] Diwaker Gupta, Ludmila Cherkasova, Rob Gardner, and
[26] J. Schad, J. Dittrich, and J. Quiane-Ruiz. Runtime
Amin Vahdat. Enforcing performance isolation across virtual
machines in xen. In Middleware, 2006.
measurements in the cloud: Observing, analyzing, and
reducing variance. In PVLDB, 2010.
[13] J. L. Henning. Spec cpu2006 benchmark descriptions. In
[27] B. Sharma, R. Prabhakar, S. Lim, M. T. Kandemir, and C. R.
SIGARCH Computer Architecture News, 2006.
[14] R. E. Kessler and Mark D. Hill. Page placement algorithms
for large real-indexed caches. ACM TOCS, 10(4):338–359,
November 1992.
[15] A. Li, X. Yang, S. Kandula, and M. Zhang. Cloudcmp:
Comparing public cloud providers. In IMC, 2010.
[16] J. Li, M. Qiu, J. Niu, W. Gao, Z. Zong, and X. Qin. Feedback
dynamic algorithms for preemptable job scheduling in cloud
systems. In WI-IAT, 2010.
[17] Linux man page. xentrace(8).
http://linux.die.net/man/8/xentrace.
[18] Andreas Merkel, Jan Stoess, and Frank Bellosa.
Resource-conscious scheduling for energy efﬁciency on
multicore processors. In EuroSys, 2010.
[19] Thomas Moscibroda and Onur Mutlu. Memory performance
attacks: Denial of memory service in multi-core systems. In
Usenix Security Symposium, 2007.
[20] K. J. Nesbit, J. Laudon, and J. E. Smith. Virtual private
caches. In ISCA, 2007.
[21] Netcraft Ltd. August 2011 web server survey. http:
//news.netcraft.com/archives/2011/08/05/
august-2011-web-server-sur%vey-3.html,
August 2011.
[22] X. Pu, L. Liu, Y. Mei, S. Sivathanu, Y. Koh, and C. Pu.
Understanding performance interference of i/o workload in
virtualized cloud environments. In CLOUD, 2010.
[23] Nauman Raﬁque, Won-Taek Lim, and Mithuna Thottethodi.
Effective management of DRAM bandwidth in multicore
processors. In PACT, 2007.
[24] H. Raj, R. Nathuji, A. Singh, and P. England. Resource
management for isolation enhanced cloud services. In CCSW,
2009.
[25] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage. Hey,
you, get off my cloud: exploring information leakage in third
party compute clouds. In CCS, 2009.
Das. Mrorchestrator: A ﬁne-grained resource orchestration
framework for hadoop mapreduce. Technical Report
CSE-12-001, Pennsylvania State University, January 2012.
[28] Alan Shieh, Srikanth Kandula, Albert Greenberg, and
Changhoon Kim. Seawall: Performance isolation for cloud
datacenter networks. In HotCloud, 2010.
[29] Allan Snavely, Dean M. Tullsen, and Geoff Voelker.
Symbiotic job scheduling with priorities for a simultaneous
multithreading processor. In SIGMETRICS, 2002.
[30] S. Srikantaiah, A. Kansal, and F. Zhao. Energy aware
consolidation for cloud computing. In Proc.
HotPowerWorkshop Power Aware Comput. Syst, 2008.
[31] D. Tsafrir, Y. Etsion, and D. G. Feitelson. Secretly
monopolizing the CPU without superuser privileges. In
Usenix Security, 2007.
[32] Ben Verghese, Anoop Gupta, and Mendel Rosenblum.
Performance isolation: sharing and isolation in
shared-memory multiprocessors. In ASPLOS, pages
181–192, 1998.
[33] C. A. Waldspurger. Memory resource management in
vmware esx server. In OSDI, 2002.
[34] Guohui Wang and T. S. Eugene Ng. The impact of
virtualization on network performance of amazon EC2 data
center. In IEEE INFOCOM, 2010.
[35] Yunjing Xu, Michael Bailey, Farnam Jahanian, Kaustubh
Joshi, Matti Hiltunen, and Richard Schlichting. An
exploration of l2 cache covert channels in virtualized
environments. In CCSW, pages 29–40, 2011.
[36] Y. Zhang, A. Juels, A. Oprea, and M. K. Reiter. Homealone:
Co-residency detection in the cloud via side-channel
analysis. In Security and Privacy IEEE Symposium, 2011.
[37] F. Zhou, M. Goel, P. Desnoyers, and R. Sundaram. Scheduler
vulnerabilities and attacks in cloud computing.
arXiv:1103.0759v1 [cs.DC], March 2011.
[38] Sergey Zhuravlev, Sergey Blagodurov, and Alexandra
Fedorova. Addressing shared resource contention in
multicore processors via scheduling. In ASPLOS, 2010.
292