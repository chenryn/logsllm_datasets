ing DAC is necessary to obtain accurate analysis results.
Third, our goal, which is to compute the vulnerability
surface under different attack scenarios, is different from
that of existing tools. In particular we need to be con-
cerned with more than just providing a policy analysis
tool; we need to also come up with appropriate ways of
querying the tool and analyzing the result.
Comparing the QoP offered by different systems is
challenging because different policy models are used.
For example, SELinux uses Type Enforcement (TE), and
AppArmor conﬁnes security-critical programs with pro-
ﬁles. Currently there exists no tool to compare the secu-
rity of systems protected using different technologies.
There is an ongoing debate about which of SELinux
and AppArmor is a better system, but such debate often
centers on the mechanism and lacks actual comparison
of the security offered by the standard policies shipped
with these protection systems. As a result, such com-
parison tends to become rhetoric wars. In [15] Cowan
from Novell and Riek from Red Hat debated about us-
ability, simplicity, and policy implementation (labels vs.
pathnames) between AppArmor and SELinux. QoP is
not discussed in details. We believe that comparisons
involving actual deployed policies are necessary. It may
be theoretically possible to conﬁgure a MAC system to
offer very strong protection, but it is the shipped stan-
dard policy that determines the QoP in reality, since very
few people change the shipped policy. In our approach,
we perform a concrete measurement of QoP for both
mechanisms using shipped policies.
Attack surface is proposed as a metric to measure the
attackability of a system [11, 12]: “The attack surface of
an app is the union of code, interfaces, services, proto-
cols, and practices available to all users, with a strong fo-
cus on what is accessible to unauthenticated users.” The
heuristic is that a larger attack surface indicates a less
secure system. Reducing the attack surface is part of the
Microsoft Security Development Lifecycle (SDL) [11].
In [17], Manadhata et al. propose to measure a system’s
attack surface in terms of three kinds of resources used
in attacks on the system: methods, channels and data.
Figure 1. Solution Overview
Two IMAP and two FTP programs are evaluated using
this method.
Attack graph is used to analyze the security of net-
works in existing works [22, 20]. Our approach also
computes a graph similar to an attack graph. However,
our problem space is different, as we consider control
of processes under different access control restrictions,
rather than control of network-connected hosts. Also,
we perform additional analysis on the resulted graph to
generate all minimal attack paths for analysis and com-
parison purposes.
3 Overview of Our Approach
To analyze and compare the QoP of MAC systems,
we need a way to deﬁne the QoP ﬁrst. Lacking such a
deﬁnition prevents debates about the virtues of different
systems to go beyond subjective and rhetoric arguments.
In this paper, we present a ﬁrst attempt at coming up
with a pragmatic deﬁnition.
The MAC systems are motivated by the threats and
attacks facing today’s operating systems,
thus they
should be evaluated by their ability to defend against
these attacks. Our approach generates all possible at-
tack paths that can lead an attacker to control of the sys-
tem. We analyze the QoP under multiple attack scenar-
ios. Each attack scenario has two aspects. One is the
objective of the attacker (e.g., load a kernel module or
plant a trojan horse). The other is the initial resources
the attacker has (e.g., can connect to the machine from
network, or has a local account). Based on the scenario,
VulSAN gives all possible attack paths.
Our approach consists of following steps:
1. Establish a running server as the analysis target.
2. Translate policy rules and system state information
into Prolog facts. We write parsers for SELinux
and AppArmor policies. We write scripts to collect
information of the ﬁle system and running services.
3. Encode what the attacker can do to break into a sys-
tem and escalate privileges in one or more steps.
For each security-enhanced mechanism, we deﬁne
the notion of attack states to describe the attacker’s
current privileges. For each MAC system we write
a library of system rules that describe how an at-
tacker exploits a program to cause state transition
under the MAC system.
4. Encode an attack scenario into a query, and use the
query to generate the host attack graph. A host at-
tack graph is a directed graph. The graph nodes are
attack states, and graph edges correspond to state
transitions. Edges are marked by programs, and by
compromising marked programs the attacker can
cause state transitions. We call the nodes of the
graph that represent the attacker’s initial resources
initial attack states, and we call the nodes of the
graph that represent the attack objective goal attack
states.
5. Analyze the host attack graph. What we care about
are the paths from initial attack states to goal attack
states. The most interesting paths are the ones that
are “minimal”. VulSAN generates all the minimal
attack paths.
Figure 1 shows the overview of our approach.
The interesting result from the host attack graph is the
attack paths. An attack path is a path that starts from an
initial attack state and ends with a goal attack state. Sup-
pose there are two attack paths p1 and p2, and we have
V (p1) ⊂ V (p2) (V (p) represents the set of edge labels
along the path). Then we are not interested in p2 since it
is easier to realize p1 than to realize p2. An attack path p
is desirable when there does not exist another attack path
Security PolicyFact CollectorMachine ConfigurationMachine StateSystem FactsHost Attack  Graph GeneratorSystem RulesQuery:Initial ResourcesAttack ObjectiveHost Attack GraphAttack Path AnalyzerMinimal Attack Pathsp(cid:48) such that V (p(cid:48)) ⊂ V (p). We call such paths minimal
paths.
We deﬁne the vulnerability surface of a protection
system as the set of all minimal attack paths. Each path
includes the programs that must be exploited to realize
the attack objective.
When we compare two protection systems A and B
under the same attack scenario, we ﬁrst generate the sets
of all minimal attack paths of the two protection sys-
tems, called PA and PB. For any path p ∈ PA, we say:
• p is a strong path if there exists a path p(cid:48) ∈ PB such
that V (p) ⊂ V (p(cid:48)).
• p is a weak path if there exists a path p(cid:48) ∈ PB such
that V (p) ⊃ V (p(cid:48)).
• p is a common path if there exists a path p(cid:48) ∈ PB
such that V (p) = V (p(cid:48)).
• p is a unique path otherwise.
When comparing A and B, a common path shows a
common way to exploit both systems. A strong path p
of system A suggests that, if the attacker compromises
the same programs in p under system B, she will need to
compromise more programs to achieve the attack objec-
tive in B. A weak path p of A suggests that, compromis-
ing a subset of the programs in p under B already helps
the attacker to achieve the objective in B. A unique path
p of A suggests that A is more vulnerable than B be-
cause by realizing p, an attacker can compromise A but
not B. By examining the strong, weak, common, and
unique attack paths in details, we can better understand
the differences of QoP between two systems.
There are two approaches to use the sets of minimal
attack paths to compare the QoP of two systems. In one
approach, one makes no assumption about whether one
program is easier to compromise than another program.
In this approach, one could only partially order the QoP
as measured by the host vulnerability surfaces of dif-
ferent systems. PA has higher QoP than PB when all
minimal attack paths for PA are either common paths or
weak paths. That is, for every minimal attack path p for
PA, either PB has the same path, or there exists a path
p(cid:48) for PB that contains a strict subset of the programs in
p, which means that p(cid:48) is easier to exploit than p. The
strength of this approach is that the comparison result re-
mains valid even when some programs are signiﬁcantly
easier to exploit than other programs. The drawback is
that often times two protection systems are not directly
comparable. Most of the analysis in this paper use this
approach.
In the second approach, one views each program
as one unit, implicitly assuming that all programs are
equal. By making this assumption, it is possible to
come up with a total order among all protection sys-
tems. However, the drawback is that the validity of the
assumption is questionable. In a few head-to-head com-
parisons in this paper, we use this approach. Whenever
we do so, we will explicitly state the assumption that all
programs are considered equal.
The ideal solution is to be able to quantify the efforts
needed to exploit different programs. However, this is
a challenging open problem that appears unlikely to be
solved anytime soon.
4 Our Tool
VulSAN consists of the following components: the
Fact Collector, the Host Attack Graph Generator, and
the Attack Path Analyzer.
4.1 Fact Collector
Fact Collector retrieves information about the system
state and security policy, and encodes the information as
facts in Prolog.
The information about ﬁle system consists of facts of
all relevant ﬁles, system users, system groups and run-
ning processes. Several sample Prolog facts are depicted
in Figure 2. We only consider system facts that are rel-
evant to our security analysis.
Irrelevant information,
like CPU/memory consumption of a process, is not con-
sidered. Whether a piece of system information is rele-
vant to our analysis depends on the system rules (which
will be discussed later), and the MAC system to be ana-
lyzed. Some facts are security-relevant under all protec-
tion mechanisms, like uid/gid of a process; while some
facts are unique to a particular mechanism, like security
contexts in SELinux and process proﬁles in AppArmor.
The encoding of Prolog facts for security policies
vary for different security mechanisms. For example, in
SELinux policies, there are several kinds of statements,
e.g., Type Enforcement Access Vector Rules and Type
Enforcement Transition Rules. We also deﬁne all the
domains and types. Figure 3 gives several sample Pro-
log facts which are generated based on a SELinux pol-
icy. Our parser for SELinux policy is based on the tool
checkpolicy.
In AppArmor, a proﬁle deﬁnes the privileges of a
certain program. A privilege can be a capability, or a
set of permissions over a ﬁle or ﬁle pattern. Figure 4
(1) file_info(path(’/usr/bin/passwd’),
type(regular), owner(0), group(0),
uper(1,1,1), gper(1,0,1), oper(1,0,1),
setuid(1), setgid(0), sticky(0),
se_user(’system_u’), se_role(’object_r’),
se_type(’bin_t’)).
(2) user_info(’root’, 0, 0).
(3) group_info(’mail’, 8, [dovecot]).
(4) process_running(4412, 0, 0,
’/usr/lib/postfix/master’,
system_u, system_r, initrc_t).
(5) process_networking(4412).
The fact encodes the
(1) is the fact for ﬁle /usr/bin/passwd.
ﬁle name,
type, owner, group, user/group/world permissions, se-
tuid/setguid/sticky bit, and security context of the ﬁle. (2) is the fact
for root user, which includes the user name, user id and group id. (3)
is the fact for mail group, which includes the group name, group id
and group members. (4) is the fact for the postﬁx master process. The
fact contains the process id(pid), user id(uid), group id(gid), executed
program, and the security context of the process. (5) is the fact for the
same process as (4), denoting that the process is open to network.
Figure 2. Sample Facts of System State
(1) dom_priv(’user_ssh_t’, ’bin_t’, ’file’,
[’ioctl’, ’read’, ’getattr’, ’lock’,
’execute’, ’execute_no_trans’]).
(2) se_typetrans(old_dom(’user_ssh_t’),
new_dom(’user_xauth_t’),
type(’xauth_exec_t’)).
(3) se_domain(’user_ssh_t’).
(4) se_type(’bin_t’).
(1) says a process running under domain ‘user ssh t’ has the following
permissions over a ﬁle with type ‘bin t’: ioctl, read, getattr, etc. The
fact is derived from a TE Access Vector Rule. (2) says if a process run-
ning under domain ‘user ssh t’ executes an executable ﬁle with type
‘xauth exec t’, the domain of the process should transition to domain