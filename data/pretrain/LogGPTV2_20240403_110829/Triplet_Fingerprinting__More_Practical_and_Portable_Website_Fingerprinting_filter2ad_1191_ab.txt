to get 31 instances per site with a sufficiently large unmonitored set.
Our attack uses as little as five traces in total given a pre-trained
model. To address data freshness, they propose a technique to
update a trained k-NN classifier. This technique needs to be run
continuously, however, to maintain the freshness of data. If the
3.3 Flexibility & Transferability
A WF attack is a traditional classification problem in which the
attacker uses a fixed number of labels for training the classifier.
During the training process, the classifier is trained by learning to
locally map the input data to the given website. These following
steps briefly describe the training and prediction process:
• The attacker first determines the set of k monitored sites and
labels them as s1, s2, ... sk .
• He then gathers T training instances for each monitored site
and another U training instances for the unmonitored set.
• The attacker trains his classifier with the k × T + U collected
training traces with their corresponding labels.
• He eavesdrops on the victim to capture an unlabeled trace.
• In the prediction phase, the attacker uses the trained classifier
to predict the label of the victim’s trace.
Note that the possible predicted class is then limited to one of the
k websites that were previously used for training or to the unmoni-
tored set. Thus, the attacker is subject to an additional constraint.
Whenever the attacker wishes to add or remove a website from his
monitored set, he must re-train his classifier. This is yet another
issue which increases the time and resource requirements necessary
to perform the attack. In this work, we study how techniques such
as N-shot learning and transfer learning can be used to improve
WF attacks. It is important to note that resolving the flexibility and
transferability issues can directly ameliorate the bootstrap time
and generalizability issues since the time required to collect data is
reduced and more varied data set may be collected.
3.4 Goals for Improvement
We have described three areas of improvements of WF attacks,
including generalizability, bootstrap time, and flexibility and trans-
ferability issues. To improve the performance of WF attacks, we
have established the following key goals to address each issue.
Generalizability. The WF classifier should be robust to the data
mismatch issues that occur as a result of 1) staleness of training
data and 2) heterogeneous distributions of training and testing data.
Bootstrap time. The WF classifier that is trained on one dataset
should remain effective against traces collected later. If it needs to
be re-trained, the amount of training data required should be small
to reduce the effort needed for data collection.
Flexibility & Transferability. The WF classifier should enable
the attacker to flexibly add new sites to the monitored set or use
a completely new monitored set with only modest effort in data
collection and training.
Attack Performance. After achieving the aforementioned goals, a
robust classifier must of course still achieve a high level of accuracy.
A classifier that is able to achieve these goals is much more
dangerous to the privacy of Tor users than one that requires the
attacker to have significant computing resources for frequently
gathering fresh training data specifically targeting each victim’s
circumstances. In the next section, we describe a technique that
leverages N-shot learning to meet these requirements.
4 N-SHOT LEARNING
DL has shown to be effective in many domains of applications
such as image recognition, speech recognition, and WF attacks [7,
11, 15, 17, 26, 27, 29]. However, traditional supervised DL algo-
rithms normally require 1) a large number of labeled examples used
for training the classifier, 2) distributions of training and testing
datasets that are matched or at least similar. Moreover, the models
can only make predictions for the set of classes on which it was
trained.
This style of learning contrasts with what we normally think of
as true intelligence. For example, a person can recognize the face
of someone by only seeing them a few times, and this ability scales
to thousands of different faces. The DL models currently in use for
WF are unable to do this. This is a key challenge in DL: How can
we build a model that can rapidly learn from very little data? This
challenge has motivated the development of the N-shot Learning
(NSL) technique [8, 32].
4.1 NSL Implementation
NSL is a recently developed ML procedure that allows a model to
accurately classify samples based on only a few training examples.
More precisely, NSL requires only a small number N of examples
for every given class. So, when N=5 (called 5-Shot Learning), the
classifier learns from a training dataset that contains only five
samples for every class. NSL has been broadly implemented in
face recognition [22, 25], where it is a compelling approach due to
constraints inherent in the task:
Limited training data. The classifier used to perform the face recog-
nition task cannot expect a rich dataset of training data. For example,
if we want to design a face recognition system for use at a company,
the system cannot require hundreds of photos from each employee
as that would be impractical to implement.
Ability to update class’ labels.
In most uses of these classifiers, it is
expected that class labels will need to be added or removed from
the system frequently. For example, if there are new employees, the
classifier should be still effectively running without downtime for
re-training the classifier.
NSL is able to address both of these constraints by modifying
the learning process. We summarize the key differences between
the NSL and traditional supervised learning as the following:
Learning goal. Traditional supervised learning mainly focuses on
training the classifier to learn and locally map the input to its
corresponding class. In contast, NSL models are trained to learn how
to distinguish between different objects regardless of the previously
trained classes.
Prediction output. Traditional supervised learning aims to simply
predict a certain class within the set of training examples. By con-
trast, the model in NSL is treated as a feature extractor to generate
the embedded vectors of inputs from the learned model. These
embedded vectors are used to measure similarity and the expected
prediction output is to decide whether or not these inputs are in
the same class.
Transferability and flexibility. The transferability of the model
enables the practitioner to use models pre-trained by others and
make small changes to it. It is important to note that a rich dataset
is still necessary to initially train the NSL model. However, the NSL
model is used as a feature extractor without being locally bounded
to a set of classes. Thus, it can more readily generalize to new
classes. Moreover, NSL allows the practitioner to flexibly adopt a
pre-trained model from others who have more computing resources
and larger training datasets.
Number of learning examples. After the underlying model used by
NSL is trained, only a small number of examples are required for
each class to generate an embedded vector. The class embedded
vectors are used to train the final classifier to classify the given
inputs into their corresponding classes.
An early implementation of NSF used k-Nearest Neighbours
(k-NN) to directly measure the similarity between two different
samples, but this showed poor results due to being overly sensitive
to minor variations in raw data. To mitigate this problem, the model
needs to be capable of effectively extracting representative features
that are robust to variation before distance between samples is
measured. Koch et al. demonstrated that using deep learning for
feature extraction is an effective solution to this problem [16]. There
are two deep embedded networks that have seen use in NSL: Siamese
Networks [30] and Triplet Networks [25]. Siamese networks are
conceptually based on similarity learning in which we measure
how similar two comparable objects are. Triplet networks have
been shown to be more effective than Siamese networks [22, 25],
and we confirmed this for the WF problem in a preliminary study.
In the next section, we provide further details as to how an NSL
model can be constructed by using triplet networks.
5 TRIPLET NETWORKS
Triplet networks [22, 25] contain parallel and identical sub-networks
sharing the same weights and hyperparamenters as shown in Fig-
ure 2. Three different inputs called triplets are used to train the
networks. The triplets are randomly sampled from the training data
to create an array containing the vectors of three different input
examples: Anchor (A), Positive (P), and Negative (N). Each input is
individually fed to their corresponding sub-network during the
training phase. To explain the differences between A, P, and N,
let us craft a toy example. Let us say we have a dataset that con-
tains traffic examples from three different websitesÐwikipedia.org,
gmail.com and amazon.comÐand each website has three examples.
Then sampling and generating the triplets used to train the network
proceeds as:
• Anchor Input (A): The anchor input is the example used as
the main referenceÐe.g. the first example from wikipedia.org.
• Positive Input (P): The positive input is chosen from the
remaining examples of the anchor’s classÐe.g. the second
example from wikipedia.org.
• Negative Input (N): The negative input is sampled from any
class that is not the anchorÐe.g. any of network traffic’s ex-
amples from gmail.com, or amazon.com.
Table 4: The performance of prior attacks for NSL (Accuracy)
Type of
Number of N Example(s)
Experiment
CUMUL [21] 42.1 ± 5.5 72.2 ± 1.7 79.7 ± 1.4 83.3 ± 2.0 85.9 ± 0.6
36.3 ± 1.6 79.3 ± 1.0 83.9 ± 1.0 85.9 ± 0.6 87.5 ± 0.8
10
k-FP [10]
15
20
1
5
• AWF775: The set of the other 775 monitored websites, where
each website has 2,500 examples .
• AWF9000: The set of 9,000 unmonitored websites, where each
website has 1 example.
DF dataset [27]. The dataset consists of both monitored and un-
monitored websites crawled from the Alexa Top sites. As with the
AWF dataset, this dataset was collected using TBB version 6.X. in
2016. We categorize the DF dataset into two sets:
• DF95: The set of 95 monitored websites, where each website
has 1,000 examples.
• DF9000: The set of 9,000 unmonitored websites, where each
website has 1 example.
We choose these three datasets to support the different purposes
of our experiments. The intuitive explanation behind the selection
of each dataset will be later described in each experimental setup.
Data Representation: We follow the data representation used by
recent work in WF using DL [24, 27, 33]. The data used for training
and testing the model consists of network traffic examples from
various sources of dataset as mentioned above. All examples are
converted to fixed-length sequences with the size of 5000 length
feature vector as the input to the model. Thus, the dimension of
the input is 1D array of [n x 5000]; where n is the total number of
network’s sequences fed to the model. In each sequence, we ignored
packet size and timestamps and only take the traffic direction of
each packet in which +1 and -1 represent outgoing and incoming
packets, and 0 is used for padding
7.2 Statistical soundness
We run the experimental testing 10 times and find the mean and
standard deviation to report the final performance of the attack.
Furthermore, the network traffic examples used for N -training the
classifier and for testing the classifier are randomly shuffled and
sampled at every round of the evaluation to ensure that the results
are not evaluated from only specific data points.
7.3 Prior work baseline
To begin, we have reevaluated prior attacks CUMUL and k-FP under
the training sample restrictions of NSL.4 For these experiments, we
split the AWF100 dataset into testing and training portions. The
number of samples used in the training portion is varied throughout
the experiments. The results for N=[1, 5, 10, 15, 20] training samples
per class can be seen in Table 4.
4We were unable to accurately reproduce the results of [36] and consequently we do
not include the wfin attack in our baseline experiments.
Table 5: The performance of WF attacks: Similar but mutu-
ally exclusive datasets (Accuracy)
Type of
Embedded
Number of N Example(s)
Experiment
Disjointed Websites
Vectors
N-ALL
N-MEV
1
5
10
15
20
79.4 ± 1.6
90.9 ± 0.7 93.1 ± 0.2 93.3 ± 0.3 93.9 ± 0.2
92.2 ± 0.6 93.9 ± 0.2 94.4 ± 0.3 94.5 ± 0.2
7.4 Similar but mutually exclusive datasets
The first experiment evaluates the attack scenario in which the
attacker pre-trains the feature extractor on one dataset and tests
on a different dataset with different classes (Disjointed websites).
More precisely, the websites’ URLs used during the pre-training
phase and the attack phase are mutually exclusive. In this scenario,
the training and testing datasets have a similar distribution in that
they are both collected with from the same period of time (2016)
using the same version of TBB (6.X).
Experimental setting: We train the triplet networks by using the
AWF775 dataset and test on AWF100. During the training phase,
we randomly sampled 25 examples for each website in the AWF775
dataset using the semi-hard-negative mining strategy to formulate
232,500 triplets to train the triplet networks.
During the testing phase, we use 90 randomly-sampled examples
for each website from the AWF100 dataset. We separate each site’s
examples into two different chunks, with 20 examples for the first
chunk and 70 examples for the second chunks. The examples in the
first chunk are reserved to evaluate the classification performance
on the N = 1, 5, 10, 15, 20 examples that are collected by the attacker
to N -train the k-NN classifier. The other 70 examples are used as
the testing data to evaluate the performance of the attack from
the trained k-NN classifier. Note that, we will apply these basic
experimental settings for the rest of the following experiments.
N-ALL vs N-MEV: The original implementation of N -shot learn-
ing classification is to use N embedded examples to N -train the
k-NN classifiers as mentioned in Section 6.2. We call this represen-
tation N-ALL. We propose a new approach to improve the perfor-
mance of the k-NN classifier by modifying the input representation.
Instead of using N examples for each website, we calculate the mean
of all N examples to generate a Mean Embedded Vector (MEV) used
to train the classifier.
We evaluate the classification performance that results from
using 1) N-ALL representation in which all of N embedded examples
for each website are fed to train the model, and 2) our proposed
N-MEV representation, in which the embedded vector is generated
from the mean of N embedded examples for each websites.
Results: Table 5 shows the performance of WF attacks on mutu-
ally exclusive training and testing datasets with different values
of N . Overall, the N-MEV vectors consistently provide better per-
formance than N-ALL in term of the accuracy of the attack. We
believe that the average of vectors in N-MEV helps reduce the noise
between embedded vectors of the same class. Therefore, we will
mainly use N-MEV representation to evaluate the next following
experimental evaluations.
The results also show that the accuracy of the attack could reach
to almost 80% of accuracy with only one example (1-shot learning).
Table 6: The impact of including different portions of the
websites during the training phase (Accuracy)
Type of
Experiment
Disjointed Websites
25% Inclusion
50% Inclusion
75% Inclusion
100% Inclusion
Number of N Example(s)
1
5
10
15
20