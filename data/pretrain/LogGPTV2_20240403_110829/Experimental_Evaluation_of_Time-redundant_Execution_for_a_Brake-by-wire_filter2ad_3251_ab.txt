application.  We  used  the  Real-Time  Workshop  Ada 
Coder, which is an extension of Simulink to generate the 
Ada  software  code  used  in  the  experiments.  Figure  3 
shows the top-level view of the model. 
InitialVehicleSpeed 
VehicleSpeed 
BrakePedalAngle 
Vehicle 
model 
Wheel 
node 
WheelSpeed 
BrakeForce 
BrakeSignal 
Figure 3. Brake-by-wire model 
The model consists of two parts, one part modeling the 
vehicle  and  the  other  part  modeling  a  wheel  node.  The 
input to the vehicle model is an initial speed value and the 
brake  pedal  angle.  In  this  study,  the  vehicle  model  is 
initiated  with  a  speed  of  15  km/h  and  the  brake  pedal  is 
activated  after  15  ms.  The  vehicle  model  uses  the  brake 
pedal angle to calculate a brake force, which is delivered 
to the wheel node. The wheel node calculates the force to 
be applied on the brake discs. Here, the calculated force is 
returned to  the  vehicle  model  (BrakeSignal).  The  vehicle 
model  calculates  the  speed  reduction  caused  by  the 
friction  force  obtained  when  the  brake  pad  is  pressed 
against  the  brake  disc  and  then  sends  new  information 
about the vehicle speed and the speed of the wheel to the 
wheel node (VehicleSpeed, WheelSpeed). The wheel node 
uses the speed of the vehicle and the speed of the wheel to 
calculate the wheel slip, i.e. the speed difference between 
the  vehicle  and  the  wheel,  reducing  the  brake  force  if  a 
specified  slip  level  is  exceeded.  The  brake  force  is 
otherwise  increased.  This  allows  the  brake  force  to  be 
adjusted for optimized braking performance.  
Figure 2. Brake-by-wire system 
5. Experimental set-up 
Some  advantages  of  brake-by-wire  are  simplified 
assembling and service of the brake system. There are also 
environmental advantages as no hydraulics system is used. 
In  addition, 
the  brake-by-wire  approach  simplifies 
adaptation  of  assistance  systems,  such  as ESP  (electronic 
stability  program).  A  distributed  architecture  for  such  a 
Figure  4  shows  the  experimental  set-up  used  to 
evaluate  the  time  redundant  execution  of  the  brake-by-
wire application.  
A  Unix  workstation  is  hosting  a  Thor  microprocessor 
board  [17]  used  as  the  target  system  for  our  experiments 
as  well  as  the  GOOFI  fault  injection  tool  [8].  Our  real-
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:15:17 UTC from IEEE Xplore.  Restrictions apply. 
time  kernel  is  running  on  the  microprocessor  board, 
handling  the  execution  of  a  task  containing  the  code 
generated for the wheel node.  The code generated for the 
vehicle model is executed on the Unix workstation and is 
not a target for fault injection. The GOOFI tool performs 
the 
the 
communication  data  between  the  vehicle  model  and  the 
wheel node. 125 loop iterations (corresponding to 125 ms) 
of  the  brake-by-wire  model  are  executed  and  data  is 
exchanged between the vehicle model and the wheel node 
every fifth loop. 
injection  experiments  and 
forward 
fault 
Unix workstation  
Vehicle 
model 
GOOFI 
fault injection 
tool 
  Thor 
microprocessor 
board 
Kernel  
and tasks 
Figure 4. Experimental set-up 
5.1. The Thor microprocessor board 
The 
target 
system 
for  our  experiments 
is  a 
microprocessor  board  featuring  a  32-bit  Thor  RISC 
microprocessor, developed by SAAB Ericsson Space AB, 
and  512  KB  RAM.  The  CPU  includes  a  direct  mapped 
write-back  data  cache  of  128  bytes  as  well  as  several 
internal  EDMs.  The  EDMs  can  be  divided  into  run-time 
checks,  control  flow  checking  and  main  memory  error 
checking. Only the run-time checks were activated in this 
study.  The 
include  mechanisms 
commonly found in other microprocessors as well as other 
checks  such as  constraint  checks  of  array  indices  or  loop 
variables. 
run-time  checks 
5.2. The real-time kernel 
A  small  real-time  kernel  supporting  time-redundant 
execution  of  tasks  was  developed  to  perform  the 
experimental evaluation of the time redundancy technique. 
Tasks  are  executed  in  a  periodic  receive-compute-send 
loop.  The  input  data are received  in the  beginning  of  the 
loop from input devices or other tasks. The input data are 
then  processed  and  the  results  are  sent  to  actuators  or  to 
other tasks in the system in the end of the loop. 
Figure  5  shows  how  the  execution  of  tasks  is  handled 
by the kernel. Task A in Figure 5 uses code generated for 
the wheel node (see Section 4) to calculate the brake force 
and  is  considered  critical.  The  brake  force  calculation 
returns  the  output  of  the  computation  and  a  checksum 
calculated on all output values and all state variables. The 
checksum  produced  by  each  copy  is  compared  to  detect 
errors,  see  Section  3.  Task  B  (not  included  in  the  brake-
by-wire  model)  is non-critical  and  calculates  a  slip  value 
to  be  used,  e.g.  for  icy  road  warning  systems.  The  two 
tasks are not connected and they do not use any common 
variables.  
Dispatch 
Task A 
Save registers 
Dispatch 
Task B 
Read data  Calc. brake force  Compare checksums  Write output 
Re-execute 
Re-execute 
if mismatch 
Figure 5. Execution of a critical task 
5.3. Fault injection environment 
The  GOOFI  fault injection  tool  was  configured  to  use 
Scan-Chain Implemented Fault Injection (SCIFI) to inject 
faults in the Thor microprocessor. Faults were injected via 
the internal scan chains into the internal state elements of 
Thor.  The  scan  chains  were  also  used  for  observing  the 
internal state of the microprocessor before and after a fault 
was injected. 
Fault  model:  Transients  are  modeled  by  single  bit-
flips.  The  single-bit-flip  model  has  become  a  de-facto 
standard  for  modeling  the  effects  of  transient  faults  in 
fault  injection  experiments,  although  it  is  not  a  perfect 
representation of all transient faults.  
Fault injection locations: Faults were injected into the 
registers  and  data  cache  of  the  Thor  microprocessor  via 
scan-chains. The scan-chains cover 2250 fault locations of 
a total of 4400 state elements in Thor. The fault injection 
locations were selected randomly using uniform sampling 
among the 2250 state elements. 
Points 
injection:  The 
in  time  for  fault 
time 
redundancy  technique  is  evaluated  with  respect  to  errors 
affecting  the  application  tasks.  Thus,  faults  were  only 
injected  during 
force 
calculation,  see  Figure  5.  The  points  in  time  at  which 
faults are injected were selected randomly in this interval 
using uniform sampling. 
the  execution  of 
the  brake 
5.4. Definitions 
The  results  of  each  fault  is  classified  according  to  the 
consequences  with  respect 
failure 
semantics, see Figure 6. The requirement is fulfilled if the 
computer in spite of the fault delivers a correct result, or if 
a  fail-stop  or  omission  failure  occurs.  The requirement  is 
violated if a value failure or a timing failure occurs. 
the  required 
to 
A value failure occurs when the computer produces an 
erroneous output value, i.e. an error is not detected  or an 
error is detected but the recovery action fails. 
A  timing  failure  occurs  when  the  output  from  the 
computer  arrives  after  the  deadline.  An  omission  failure 
occurs when an error is detected but there was not enough 
time to  produce  two  identical results  before  the  deadline. 
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:15:17 UTC from IEEE Xplore.  Restrictions apply. 
Timing  failures  and  omission  failures  are  not  considered 
in this evaluation of the kernel (no deadline is defined and 
tasks  are  not  pre-empted).  Instead,  the  fault  tolerance 
latency [18], i.e. the total time for error detection and error 
recovery, is measured. 
A correct result is produced if the fault leads to a latent 
or  overwritten  error.  A  correct  result  is  also  produced 
when an error is detected and recovery is successful. Fail-
stop  failures  occur  when  an  error  is  detected  but  no 
recovery could be made, e.g. for CPU exceptions triggered 
during execution of the kernel code. 
Overwritten or 
latent errors 
Error 
detected 
 Recovery 
 successful 
 Recovery 
 available but 
 not possible 
Correct 
result 
Omission 
failure 
 No recovery 
 available 
Fail stop 
failure 
Fault 
Error 
 Recovery 
 failed 
Error not 
detected 
Value 
failure 
Timing 
failure 
Figure 6. Error propagation and effects 
e
r
u
l
i
a
f
e
h
t
g
n
i
l
l
i
f
l
u
F
e
r
u
l
i
a
f
e
h
t
g
n
i
t
a
l
o
i
V
s
c
i
t
n
a
m
e
s
s
c
i
t
n
a
m
e