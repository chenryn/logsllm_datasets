        this.b = b;
        this.sum = sum;
        this.createdAt = createdAt;
    }
    public String getSum() {
        return sum;
    }
}
```
此操作后，我们不再使用代码中的`result`列。请注意，直到第 2 步，此操作都是向后兼容的。如果我们需要回滚到步骤 1，那么我们可能会丢失该步骤后存储的数据。
# 从数据库中删除旧列
最后一步是从数据库中删除旧列。当我们确定不需要在步骤 4 之前回滚时，应该在回滚期之后执行此迁移。
The rollback period can be very long since we aren't using the column from the database anymore. This task can be treated as a cleanup task, so even though it's non-backwards-compatible, there is no associated risk.
让我们添加最终迁移，`V5__Drop_result_column.sql`:
```
alter table CALCULATION
drop column RESULT;
```
经过这一步，我们最终完成了列重命名过程。请注意，我们所做的只是将操作稍微复杂化一点，以便及时扩展。这降低了向后不兼容的数据库更改的风险，并允许零宕机部署。
# 将数据库更新与代码更改分开
到目前为止，在所有的图中，我们展示了数据库迁移是与服务版本一起运行的。换句话说，每次提交(这意味着每次发布)都会进行数据库更改和代码更改。但是，推荐的方法是明确区分对存储库的提交是数据库更新还是代码更改。下图显示了该方法:
![](img/af3ebd96-a96f-4565-84b6-f75ecd859d95.png)
数据库服务变更分离的好处是我们可以免费获得向后兼容性检查。假设更改 v11 和 v1.2.7 涉及一个逻辑更改，例如，向数据库添加一个新列。然后，我们首先提交数据库 v11，因此持续交付管道中的测试检查数据库 v11 是否与服务 v.1.2.6 正确工作。换句话说，它们检查数据库更新 v11 是否向后兼容。然后，我们提交 v1.2.7 更改，因此管道会检查数据库 v11 是否可以正常使用服务 v1.2.7。
The database-code separation does not mean that we must have two separate Jenkins pipelines. The pipeline can always execute both, but we should keep it as a good practice that a commit is either a database update or a code change.
总而言之，数据库模式的更改永远不应该手动完成。相反，我们应该始终使用迁移工具来自动化它们，作为持续交付管道的一部分来执行。我们还应该避免不向后兼容的数据库更新，确保这一点的最好方法是将数据库和代码更改分别提交到存储库中。
# 避免共享数据库
在许多系统中，我们可以发现数据库成为多个服务之间共享的中心点。在这种情况下，对数据库的任何更新都变得更具挑战性，因为我们需要在所有服务之间进行协调。
例如，假设我们开发了一个在线商店，我们有一个 Customers 表，该表包含以下列:名字、姓氏、用户名、密码、电子邮件和折扣。有三种服务对客户的数据感兴趣:
*   **档案管理器**:可以编辑用户数据
*   **结账处理器**:处理结账(读取用户名和邮件)
*   **折扣经理**:分析客户的订单，设置合适的折扣
让我们看看下面这张呈现这种情况的图片:
![](img/794aa472-8c58-4b68-b172-8b85d838d1b8.png)
它们依赖于相同的数据库模式。这种方法至少有两个问题:
*   当我们想要更新模式时，它必须与所有三个服务兼容。虽然所有向后兼容的更改都没问题，但是任何不向后兼容的更新都变得更加困难甚至不可能。
*   每项服务都有单独的交付周期和持续交付管道。那么，我们应该使用哪条管道进行数据库模式迁移呢？不幸的是，这个问题没有好的答案。
由于前面提到的原因，每个服务都应该有自己的数据库，并且服务应该通过它们的 API 进行通信。按照我们的示例，我们可以应用以下重构:
*   结账处理器应该与配置文件管理器的应用编程接口通信，以获取客户的数据
*   折扣列应该提取到一个单独的数据库(或模式)中，折扣管理器应该获得所有权
重构版本如下图所示:
![](img/58088d1d-5613-45b4-9ef1-978ac0372a8f.png)
这种方法符合微服务架构的原则，并且应该始终应用。通过 API 的通信比直接数据库访问更加灵活。
In the case of monolithic systems, a database is usually the integration point. Since such an approach causes a lot of issues, it's considered as an anti-pattern.
# 准备测试数据
我们已经介绍了数据库迁移，作为副作用，它可以保持环境之间的数据库模式一致。这是因为，如果我们在开发机器上、在临时环境中或在生产环境中运行相同的迁移脚本，那么我们将总是在相同的模式中得到结果。但是，表内的数据值不同。我们如何准备测试数据，以便有效地测试我们的系统？这是本节的主题。
这个问题的答案取决于测试的类型，对于单元测试、集成/验收测试和性能测试是不同的。让我们检查每个案例。
# 单元测试
在单元测试的情况下，我们不使用真实的数据库。我们要么在持久性机制(存储库、数据访问对象)的层次上模拟测试数据，要么用内存中的数据库(例如，H2 数据库)模拟真实的数据库。由于单元测试是由开发人员创建的，确切的数据值通常是由开发人员发明的，它们并不重要。
# 集成/验收测试
集成和验收测试通常使用测试/试运行数据库，该数据库应该尽可能类似于产品。许多公司采用的一种方法是将生产数据快照到分段中，以保证数据完全相同。但是，这种方法被视为反模式，原因如下:
*   **测试隔离**:每个测试都在同一个数据库上运行，所以一个测试的结果可能会影响其他测试的输入
*   **数据安全**:生产实例通常存储敏感信息，因此安全性更高
*   **再现性**:每次抓拍后，测试数据都不一样，可能会出现片状测试
由于上述原因，首选的方法是通过选择生产数据的子集，与客户或业务分析师一起手动准备测试数据。当生产数据库增长时，值得重新审视其内容，看看是否有任何合理的案例需要添加。
向临时数据库添加数据的最佳方式是使用服务的公共应用编程接口。这种方法与验收测试是一致的，验收测试通常是黑盒测试。此外，使用应用编程接口保证了数据本身的一致性，并通过限制直接数据库操作简化了数据库重构。
# 性能试验
性能测试的测试数据通常类似于验收测试。一个显著的区别是数据量。为了正确测试性能，我们需要提供足够的输入数据量，至少与生产中可用的数据量一样大(在高峰时间)。为此，我们可以创建数据生成器，这些生成器通常在验收测试和性能测试之间共享。
# 管道模式
我们已经知道启动一个项目和与 Jenkins 和 Docker 建立持续交付管道所必需的一切。本节旨在通过一些推荐的常规 Jenkins 管道实践来扩展这一知识。
# 并行化管道
在本书中，我们总是按顺序、一步一步地执行管道。这种方法很容易推理出状态和构建的结果。如果首先是验收测试阶段，然后是发布阶段，这意味着在验收测试成功之前，发布永远不会发生。顺序管道很容易理解，通常不会引起任何意外。这就是为什么解决任何问题的第一个方法是按顺序做。
然而，在某些情况下，这些阶段非常耗时，值得并行运行。一个很好的例子是性能测试。它们通常需要很多时间，所以假设它们是独立的和孤立的，并行运行它们是有意义的。在 Jenkins 中，我们可以在两个不同的级别上并行化管道:
*   **并行步骤**:在一个阶段内，并行进程在同一个代理上运行。这种方法很简单，因为所有与 Jenkins 工作区相关的文件都位于一台物理机器上，但是，与垂直扩展一样，资源仅限于该台机器。
*   **并行阶段**:每个阶段可以在单独的代理机器上并行运行，代理机器提供资源的水平扩展。如果另一台物理机上需要前一阶段创建的文件，我们需要注意环境之间的文件传输(使用`stash` Jenkinsfile 关键字)。
By the time of writing this book, parallel stages are not available in the declarative pipeline. The feature is supposed to be added in Jenkins Blue Ocean v1.3\. In the meantime, the only possibility is to use the deprecated feature in the Groovy-based scripting pipeline, as described here at [https://jenkins.io/doc/book/pipeline/jenkinsfile/#executing-in-parallel](https://jenkins.io/doc/book/pipeline/jenkinsfile/#executing-in-parallel).
让我们看看它在实践中的样子。如果我们想并行运行两个步骤，那么 Jenkinsfile 脚本应该如下所示:
```
pipeline {
   agent any
   stages {
       stage('Stage 1') {
           steps {
               parallel (
                       one: { echo "parallel step 1" },
                       two: { echo "parallel step 2" }
               )
           }
       }
       stage('Stage 2') {
           steps {
               echo "run after both parallel steps are completed"   
           }
       }
   }
}
```
在`Stage 1`中，使用`parallel`关键字，我们执行两个并行的步骤，`one`和`two`。请注意，`Stage 2`只有在两个并行步骤完成后才会执行。这就是为什么这样的解决方案并行运行测试是完全安全的；我们始终可以确保只有在所有并行测试都通过之后，部署阶段才会运行。
There is a very useful plugin called `Parallel Test Executor` that helps to automatically split tests and run them in parallel. Read more at [https://jenkins.io/doc/pipeline/steps/parallel-test-executor/](https://jenkins.io/doc/pipeline/steps/parallel-test-executor/).
前面的描述涉及并行步骤级别。另一种解决方案是使用并行阶段，因此在单独的代理机器上运行每个阶段。决定使用哪种类型的并行通常取决于两个因素:
*   代理机器有多强大
*   给定的阶段需要多少时间
作为一般建议，单元测试可以并行运行，但是性能测试通常最好在不同的机器上运行。
# 重用管道组件
当 Jenkinsfile 脚本变得越来越大，越来越复杂时，我们可能希望在类似的管道之间重用它的部分。
例如，我们可能希望为不同的环境(开发、质量保证、生产)提供独立但相似的管道。微服务领域的另一个常见例子是，每个服务都有一个非常相似的 Jenkins 文件。那么，我们如何编写 Jenkinsfile 脚本，使我们不会再次重复相同的代码呢？为此，有两种很好的模式，参数化构建和共享库。让我们一个一个地描述它们。
# 构建参数
我们已经在[第四章](04.html)、*持续集成管道*中提到，管道可以有输入参数。我们可以使用它们为不同的用例提供相同的管道代码。例如，让我们创建一个用环境类型参数化的管道:
```
pipeline {
   agent any
   parameters {
       string(name: 'Environment', defaultValue: 'dev', description: 'Which 
         environment (dev, qa, prod)?')
   }
   stages {
       stage('Environment check') {
           steps {
               echo "Current environment: ${params.Environment}"   
           }
       }
   }
}
```
构建采用一个输入参数`Environment`。然后，我们在这一步所做的就是打印参数。我们还可以添加一个条件，为不同的环境执行不同的代码。
使用这种配置，当我们开始构建时，我们将看到输入参数的提示，如下所示: