the following processes. Each node in the constructed path traversing the most
importantfeaturenodearemappedtoabstractservices.Theseabstractservices
constitute one of the abstract composition scheme, in the Service Composition
layer.Inordertoinstantiatetheseservices,withintheServicelayer,theFeatures
Matching Module, maps each abstract service representing a feature node, with
its suitable service description from the service registry. Thus, all the abstract
composition schema in the Service Composition layer are mapped to schema
412 H. Taktak et al.
compositionwithconcreteservices.Infact,theserviceregistryencompassesser-
vices descriptions expressed semantically as detailed in our previous work [6].
Thus, all the invoked services from the service registry, in the Service layer, are
enhanced with EO linked-data. The orchestration of these services execution
follows the ordered set of decision nodes traversed from the root until the leaf-
node,andpassingbythemostimportantfeaturenode.Otherwise,eachvalueof
afeaturenodeisdeterminedbytheexecutionofthesuitableenvironmentalWeb
serviceaccessingtoitsrelatedenvironmentaldatasourcewithinthePREDICAT
project.
Fig.1. The prediction system architecture.
4 The Wildfire Prediction Flow
Figure2 presents the proposed prediction flow related to wildfire alerts along
withitsdifferentphases.Infact,thenoveltyofourproposedflowisthatitallows
totriggeralertstoscientists,transparentlyandwithoutanyhumanintervention
norauserrequest.ThefirstphaseinthisflowistocollecttheEOdatastoredin
the knowledge-base. 1-EO data-acquisition phase is realized by the IoT devices
that belong among others to the OSS system. The second phase consists in 2-
Data Preparation, which takes as input the data from the knowledge-base and
splits it into two sets: the training data-set and the testing data-set. The Model
Input Data consists of the set of features of interest, to which is applied the ML
algorithm. The third phase is 3-Prediction Model Building one, which consists
of performing the ML algorithm and produces the prediction model, which is
the decision tree (DT). This phase relates to the Learning Module, detailed in
the previous section. A DT is a tree structure that consists of multiple internal-
nodes and leaf-nodes [15]. Each internal node represents a single category; each
branch of a node represents one possible value or a set of possible values of the
Knowledge-Driven Automatic Service Composition for Wildfire Prediction 413
category, and each leaf-node represents a class label. DT uses a tree structure
to represent the rules between independent and dependent variables. Each node
has a threshold compared with (i.e.: ).
TheRandomForest(RF)MLclassifierisanensemblelearningmethoddevel-
opedbyconstructingmultipleDTs[16].Inthetrainingprocess,anRFappliesa
baggingtechniquetobootstrapinstancesandselectsarandomsubsetoffeatures.
A set of DTs is then constructed based on each set of bootstrap instances with
a subset of features. Once the set of trees is constructed, a prediction regarding
unseen samples can be generated by selecting the majority class of individual
trees. Once the prediction model is generated, all the needed features of interest
defined in the decision nodes are ready to be extracted. In the fourth phase 4-
Prediction Model Deployment, each extracted feature of interest represents an
abstractservicethatwillbepartoftheabstractcompositionschema.Thedesign
oftheabstractservicecompositionschemaishandledbytheAwarenessModule
whichisdetailedinSect.5.1.Furthermore,itisworthytonotethatwecanhave
multipledesignedabstractcompositionschemaasfarastherearemultiplenodes
representingthemostimportantfeatureofinterestintheDT,determinedbythe
Awareness Module, and guiding the EO data collection in the model prediction
generateduponthePredictionModelBuildingPhase.SeeSect.5.1foradditional
detailsgiveninthepresentedalgorithms.AFeaturematchingprocessisapplied
toeachextractedfeature,andwhichismappedtoanabstractservice.Thelistof
services along with their related descriptions are stored in a service registry. In
the fifth 5-Service Composition phase, each abstract service is instantiated and
executed. This execution is handled by the Composition Execution Engine. The
orchestration of the execution of these services follows the order of traversing
the decision nodes defined by the traversal algorithm, in the Awareness Module.
Otherwise, each executed decision node, based on its value, determines which
nextdecisionnodeanditsserviceinstancetobeexecuted.Furthermore,theexe-
cution of multiple instantiated composition schema is realized in parallel. Upon
the execution of the schema composition, an alert is then, transmitted to the
scientist.
5 Implementation and Evaluation
In this section, we present the feasibility of our fire model prediction in the
guidance of the building of the service composition scheme. In particular, we
demonstratetheeffectivenessofourmodel.First,weprovideanimplementation
exampleofourmodelwiththeRandomForest(RF)algorithmtoperformthefire
prediction.Then,weprovidesomealgorithmsshowingdetailsoftheDTtraversal
from the most important feature of interest in the model prediction, which will
guide the search for the rest of the features, in the tree. Thus, the generated
paths across the DT are mapped to service composition schemas. Second, we
focus on the evaluation of our built-model, by comparing it with other classifier
algorithms, through the examination of the different performance indicators’.
414 H. Taktak et al.
Fig.2. The prediction flow.
5.1 Implementation
As aforementioned, we focus the implementation details on the two supervised
classifiers: The Random Forest (RF) and the Decision Tree (DT). We used the
built-inimplementationoftheRFandtheDTalgorithms,fromthefreesoftware
ML library “sklearn”. Furthermore, we used Python programming language for
the implementation and the “export graphviz” module for the visualization of
thegeneratedDTinbothclassifiers.EachgeneratedDTrepresentsthefiremodel
prediction. We, then, provide an evaluation based on performance indicators to
choose the relevant classifier. In the following, we first introduce the used data-
sets, then, present the implementation results.
Data-Sets. We used data4 related to weather recorded by the OSS as a set
of inputs and stored in the knowledge-base. In particular, we used hourly data
recorded between 1st November 2017 and 31st March 2019. This period of time
includes a wide range of temperature (◦C), relative humidity (%), wind speed
(km/h), wind direction (◦) and, drought factor values relevant to fire weather
considerations. Furthermore, we used the McArthur Forest Fire Danger Index
(FFDI) and its rating namely, the fire danger rating scale for forest (FFDR) as
outputusedbyourMLalgorithm.Thefiredangerindexisdeterminedbythecal-
culation of the FFDI according to the equation defined in [17]. FFDR is defined
by the following classes: catastrophic (>100), extreme (75–99), severe (50–75),
very high (25–49), high (12–24), and low-moderate (0–11). All these classes are
considered as output to the ML algorithm and stored in the knowledge-base.
We considered about 1500 tuples in our knowledge-base when performing the
ML algorithm. We split the data-set into 70% for training and 30% for testing.
Furthermore,inordertoavoidoverfittinganddeterminetheoptimalmodelper-
formances, we used the “GridSearchCV” function from the “sklearn” library, to
4 https://docs.google.com/spreadsheets/d/1v-46-KMHtErt3IGigFsusk7Fnp61DKvct
Ms9KMH a-E/edit?usp=sharing.
Knowledge-Driven Automatic Service Composition for Wildfire Prediction 415
tune the model hyperparameters for both RF and DT classifiers. It consists in
using a subset of the training collection as a validation dataset. We considered
the following hyperparameters. For cv=5 in the DT classifier: max depth=10,
criterion=‘entropy’and,min samples split=2.Forcv=3intheRFclassifier:cri-
terion=‘gini’, max depth=10 and, n estimators=90. Furthermore, we used the
Amicus fire knowledge-base5, which is a free suite of tools to simulate the cal-
culation of the FFDI index.
Learning Module. Asaforementioned,themainobjectiveofthismoduleisto
learn from the EO data itself and the historical EO data collected by the IoT
devices.Thismodulegeneratesthefiremodelprediction.Fortheconstructionof
the latter, we chose two decision tree algorithms: the Random Forest (RF) [16]
and the Decision Tree (DT) [15]. This choice is explained by the fact that the
decision tree algorithms are effective in that they provide human-readable rules
of classification. We performed tests on both classifiers to choose the relevant
one. Section5.2 provides evaluation details. After performing an ML classifier
algorithm, an extraction of the produced fire model prediction decision tree is
depictedinFig.3.Eachclassifierproducesafiremodelprediction,eachofwhich
represents a decision tree (DT).
Fig.3. Extraction from the decision tree.
Awareness Module. TheAwarenessModuleencompassestwoalgorithms:the
firstonedeterminesthemostimportantfeaturewhichindicatesitsimpactonthe
model compared to the rest of the features, and the second one determines the
path to traverse in the DT, from the most important feature node till the leaf-
node containing the fire danger class. Figure4 depicts the relative important
features, taking into consideration the set of the used features. We observed
5 https://research.csiro.au/amicus/.
416 H. Taktak et al.
that the drought factor feature (DF) has the highest importance value. This
value is determined by at first, applying the RF feature selection method [7],
which produces a list of scored features within the prediction model. This list is
denoted“L”inttheAlgorithm1.Second,byapplyingthemaximumequationon
these values to determine the most important feature in our model prediction.
Algorithm 16 is a pseudo-code presenting details about determining the most
importantfeature,whichisthefeatureDFinourmodelprediction.Furthermore,
once the most important feature is determined, the idea is to map the feature
tagtoitssuitableservice.ThisserviceisexecutedinordertohavetheDFvalue.
According to the returned value by the DF service, the DF node will guide the
tree traversal to search for the other features in the DT.
Algorithm 1. CMIF+ES.
Begin
LetL←Searchforfeaturesimportance//Listoftheimportantfeatures
DF←max{importance(i)}//Themostimportantfeatureinourmodelprediction
i∈L
Val←ExecutetheServiceHavingDFasatag//ExecoftheimportantFeatureservice
End.
Fig.4. The set of the important features in the fire model prediction.
Then comes the generation of the tree traversing the DF node which is com-
posedontheonehand,ofthepathdepartingfromtheDFnodetotheroot,and
on the other hand, of the sub-tree of the DF node. To do so, Algorithm 2 reuses
from Algorithm 1 the most important feature (e.g.: DF) and its related value
‘Val’.Asafirststep,inordertosearchfortheDFnodeintheDT,thealgorithm
determines the nearest node to the root whose feature is DF. Furthermore, it
generatesthepathfromtheDFnodetotheroot.Asasecondstep,accordingto
thereturnedvalue‘Val’,thislatteriscomparedtothe‘DF Threshold’indicated
in the chosen DF node in the DT. Thus, the algorithm decides which sub-tree
toextract(i.e.:theleftsub-treeortherightsub-tree).Afterwards,thepathand
thesub-treearemergedtogeneratethetreethattraversestheDFnode.Infact,
the DF node, according to its value, guides the ordered connections to the root
6 Computing the most important feature and executing its service.
Knowledge-Driven Automatic Service Composition for Wildfire Prediction 417
Algorithm 2. Construction of the tree: path departing from the important
feature to the root and, the sub-tree of the important feature.
Input:Tree//Thegenerateddecisiontreeofthemodelprediction
Output: Tree //Concatenation of the path departed from the important feature to the root and
itsextractedsub-binarytree
Begin
Node←NearestNodetotherootwhosefeatureisDF
Path←PathfromDFtotheroot
if(DFThreshold≤Val)then SubTree←LeftSubTreeofDF
elseSubTree←RightSubTreeofDF
endif
Tree←Path+SubTree//Fusionofthepathandthesub-tree
returnTree
End.
and to the leaf-nodes. Thus, the DF node impacts on the dynamic generation of
theservicecompositionscheme.IncaseifwehavemultipleDFnodesintheDT,
thenwehavemultiplepathstraversingeachofthesenodes.Therefore,wepresent
Algorithm 3, which defines a pseudo-code managing the generation of multiple
paths traversing the multiple DF nodes in the DT. This algorithm reuses the
generatedbinarydecisiontreeofthemodelpredictionandtheextractedsub-tree
determined according to the DF value in Algorithm 2. The idea, when having
multiple DF nodes in the DT, is to only prune the extracted sub-tree from the
binary tree and return the new tree. This way, the other non extracted sub-tree
willbeused,oranotherpathtraversinganotherDFnodewillbeused.Thesub-
tree pruning is realized ‘i’ times until reaching a ‘Stop Condition’. The value
of the ‘Stop Condition’ (e.g.: 10) is to be fixed at the beginning of the experi-
mentation by the experimental user of the PREDICAT platform, to define the
maximum number of service composition schemas supported to be run in paral-
leldependingonthecapacityofthePREDICATplatform.Thegeneratedpaths
constitute the possible constructed abstract service composition schemas. The
executionofthesecompositionschemaisrealizedinparallelbyinstantiatingthe
services at run-time. An alert is, then, triggered. Inthe next section, we provide
the evaluation of the fire prediction model based on comparative performance
measures computed from both previously detailed classifiers.
Algorithm 3. Generating multiple paths traversing multiple DF nodes.
Input:BinaryTree//ThegeneratedDTofthemodelpredictionfromAlgorithm2
StopCondition←10//10supportedgeneratedpathstobeexecutedinparallelintheplatform
Output:Tree//Thegeneratedtree
Begin
Repeat
Tree ← Binary Tree \{SubTree(i)} //Generate a new tree by eliminating the subTree of the
importantfeatureextractedinAlgorithm2
Until (i > StopCondition) //StopCondition is to be fixed limiting the number of the generated
//pathstraversingtheimportantfeatureDF.
returnTree
End.
418 H. Taktak et al.
5.2 Evaluation Metrics
Several metrics for the evaluation of the performance of the classifier from the
literature can be used. In our experiments, we considered four commonly used
metrics,whichareaccuracy,precision,recall,andf1-score.Theselatterareindi-
cators to measure the performance of our prediction models.
Table 1. System performance measures
ML classifier Accuracy % Precision Recall
Random Forest 86 0.862 0.862
Decision Tree 84.06 0.840 0.840
Fig.5. Classes of fire danger chart.
To assess the evaluation of our fire prediction model, we used the most
two popular ML classifiers which allow evaluating the RF classifier against the
Decision Tree classifier. Moreover, we used performance measures computed for
bothMLclassifiermodels.Furthermore,weconsideredtheclasses:Catastrophic,
Extreme, and Severe as the most important classes of fire danger triggering
alerts, and we measured the f1-score related to these classes, for each of the
classifiers. According to results in Fig.5, we noticed that f1-score values in the
RFclassifier, all the danger classes advance thosein theDecision Treeclassifier.
These results related to the most important danger classes show relevant values
for prediction. Moreover, according to our experiments on our fire prediction
model generated by the RF classifier, in Table1, showed a high accuracy value,
which is in advance to the one in the Decision Tree classifier.
6 Conclusion
Inthispaper,weproposedanapproachthatcombinesMLandknowledge-driven
engineering to dynamically compose services from sensor data for wildfire pre-
dictions. The predicted alerts help scientists to anticipate and to manage fire
in threatened areas. We evaluated our wildfire model prediction through several
experiments, which showed relevant values with respect to the most important
Knowledge-Driven Automatic Service Composition for Wildfire Prediction 419
classes of fire danger. Future work includes exploring optimal services compo-
sition along with optimal services selection based on the quality of data and
quality of services.
References
1. Mitchell, T.: Machine Learning. Publisher McGraw-Hill, New York (1997). ISBN
0070428077ISBN 0070428077
2. Boustil,A.,Maamri,R.,Sahnoun,Z.:Asemanticselectionapproachforcomposite
web services using OWL-DL and rules. Serv. Oriented Comput. Appl. 8, 221–238
(2014)