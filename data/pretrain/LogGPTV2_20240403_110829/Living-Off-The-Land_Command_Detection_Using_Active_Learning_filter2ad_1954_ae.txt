from each class.
• Random Sampling: gradient boosting classifier and pick-
ing samples for labeling uniformly at random.
The comparison of these variants is shown in Figure 6. The plots
show the average F1 scores and False Positive Rate metrics averaged
over different classes. Sampling using only anomalous or uncertain
samples does not provide significantly better performance than
random sampling. The classifier choice is clearly important, as the
malicious and benign samples in our dataset are not linearly separa-
ble in feature space, which leads to logistic regression performing
poorly compared to gradient boosting. The boosting classifiers
have higher capacity and can learn non-linear decision boundaries.
Table 6 shows the progress comparison of the variants at three
RAID’21,October6–8,2021,SanSebastian,SpainOngun,etal.01020304050Iteration0.00.20.40.60.81.0ValueMetrics for BitsadminLolbinPrecisionFraction of TP Found01020304050Iteration0.00.20.40.60.81.0ValueMetrics for CertutilLolbinPrecisionFraction of TP Found0510152025303540Iteration0.00.20.40.60.81.0ValueMetrics for MsbuildLolbinPrecisionFraction of TP Found01020304050Iteration0.00.20.40.60.81.0ValueMetrics for MsiexecLolbinPrecisionFraction of TP Found01020304050Iteration0.00.20.40.60.81.0ValueMetrics for Regsvr32LolbinPrecisionFraction of TP FoundFigure5:LOLALframeworkresultsfordifferentLOLBINclasses.ThePercentageofTruePositiveMetricandPrecisionincreaseswiththenumberofiterations.1987labeledsamplesfromTable2.Westartwithaverysmallnumberof10labeledsamplesandselectateachiteration5testsamplesforlabelingandinclusioninthetrainingdataforthenextiteration.Oursetupassumesthatananalystwouldcorrectlylabeltheselectedsamplesinthepresentedorder.WeshowinFigure5thePrecisionandPercentageofTruePositivesfoundasseveraliterationsofactivelearningareperformedwiththeboostingclassifier.Theplotsaregeneratedbyaveraging5runsasthestartingsetoflabelsarepickedrandomly.Werunthealgorithmsfor50iterationsandobservethatconvergenceisreachedfasterthan30iterationsinallcases.Mostimportantly,theprecisionreachesabove0.97inalmostallcases(withtheexceptionoftheMsiexecclass).Similarly,therecall(PercentageofTruePositives)foundateachiterationreachesabove0.97inallcases,asshowninTable5.Theseexperimentsshowthatouractivelearningframeworkisabletotrainaneffectiveclassifierusingaverysmallnumberoflabeledsamples,whichisaverychallengingsetting.Notethatweuseasetof1987samplesinthislabeleddataset.Startingwith10labelsandlabelingonesampleforeachofthefiveclassesfor30iterations,30·5=150additionalsamplesarelabeled,whereastheremaining1827samplesrepresenttheunlabeled,portionofthetestset.Thisdemonstratesthatouractivelearningframeworkisabletolearnaneffectiveclassifierusing160labels.Weobservesomeoscillationsovertime,whichindicatetheclassifiercorrectingitselfafterlearningfromnewsamples,andthenconvergingafteronly30iterations.Wealsoobservethatsomeclassesconvergelaterthanothers.Initially,theclassifierhasdifficultywiththeMsbuildclasssincethemaliciousintentofmsbuild.exeissometimesnotclearfromlookingonlyatthecommandline,evenforhumanexperts.Thedifficultyofdetectionis,bynature,classdependent.Nonetheless,theclassifiergetsalmostperfectprecisionandrecallasmorerelevantsamplesarelabeledandaddedtothetrainingset.Overall,thisexperimentshowshowouractivelearningframeworkisabletolearnaneffectiveclassifierovertime,withhighprecisionandrecall.Wenowcompareoursampleselectionstrategyforactivelearn-ingwithotherlabelingstrategiestodemonstratetheadvantagesTable5:ComparisonoftheLOLALclassifierevaluationfordifferentclassesafter5and30iterations.ClassIter5Iter30Prec%TPPrec%TPBitsadmin0.610.830.970.97Certutil0.920.930.980.98Msbuild0.620.781.01.0Msiexec0.680.520.881.0Regsvr320.940.820.970.99ofthesampleselectionstrategyusedbyLOLAL.Wedefinethefollowingvariantsofouractivelearningtool:•LOLAL:gradientboostingclassifierandnaïvebayesanom-alydetection;pickinguncertainandanomaloussamplesinaround-robinfashion.•LOLAL-LR:logisticregressionclassifierandnaïvebayesanomalydetection;pickinguncertainandanomaloussam-plesinaround-robinfashion.•UncertaintySampling:gradientboostingclassifier;pick-inguncertainsamplesfromeachclass.•AnomalySampling:gradientboostingclassifierandnaïvebayesanomalydetection;pickinganomaloussamplesfromeachclass.•RandomSampling:gradientboostingclassifierandpick-ingsamplesforlabelinguniformlyatrandom.ThecomparisonofthesevariantsisshowninFigure6.TheplotsshowtheaverageF1scoresandFalsePositiveRatemetricsaveragedoverdifferentclasses.Samplingusingonlyanomalousoruncertainsamplesdoesnotprovidesignificantlybetterperformancethanrandomsampling.Theclassifierchoiceisclearlyimportant,asthemaliciousandbenignsamplesinourdatasetarenotlinearlysepara-bleinfeaturespace,whichleadstologisticregressionperformingpoorlycomparedtogradientboosting.Theboostingclassifiershavehighercapacityandcanlearnnon-lineardecisionboundaries.Table6showstheprogresscomparisonofthevariantsatthree451Living-Off-The-Land Command Detection
Using Active Learning
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Table 6: Comparison of different active learning variants
showing the progress over iterations in terms of mean F1
scores and standard deviation values.
Sampling
Variant
LOLAL
LOLAL-LR
Uncertainty
Anomaly
Random
Iter 10
SD
F1
0.06
0.85
0.30
0.36
0.76
0.34
0.21
0.78
0.80
0.12
Iter 15
SD
F1
0.06
0.90
0.33
0.30
0.77
0.34
0.22
0.80
0.78
0.20
Iter 20
SD
F1
0.04
0.91
0.29
0.57
0.88
0.13
0.07
0.89
0.87
0.08
iterations showing F1 scores and standard deviation (SD) values.
LOLAL consistently gives higher F1 score and lower variance than
the other variants. Our system is designed to prioritize alerts for
labeling considering a fixed budget of expert time (the parameter
is the number of samples the analyst labels per iteration). Figure 6
demonstrates how our system LOLAL achieves better accuracy
at detection compared with other sampling strategies when the
number of samples is fixed per iteration. That translates to fewer
labeled samples needed to achieve a fixed accuracy level. For exam-
ple, to achieve an F1-score of 0.8, LOLAL needs to run 6 iterations
(30 labeled samples), while the Anomaly Scoring method needs
11 iterations (55 labeled samples). Our active learning algorithm
LOLAL with a boosting classifier, using both uncertain and anoma-
lous instances for sample selection, performs best across all these
variants.
4.4 Active Learning with Expert Feedback
Finally, we investigate how our active learning platform works
in a realistic setting, in which we run the system with a security
expert to investigate and label the samples identified by active
learning. First, we use the set of 1987 labeled samples to train the
multi-class classifier. The classifier is used to evaluate the 10522
command lines in the selected samples dataset, and some of the
samples are predicted to be malicious. Then, the algorithm ranks
the 25 most uncertain and the 25 most anomalous samples (among
the unlabeled samples) for labeling by the human analyst. After
each iteration, a total of 50 samples identified by the framework are
labeled by the human expert investigating the alert. In Table 7, we
show the accuracy of the identified samples in three iterations. This
measures the percentage of samples that are classified as malicious
by the classifier being confirmed as malicious by the human. A
first observation is that the identified samples have generally lower
accuracy compared to our classification results on labeled data.
This is expected, as the algorithm selects samples that are uncertain
or anomalous. Another observation is that the accuracy of the
identified samples increases over three iterations, meaning that the
accuracy for the samples that are anomalous or close to the decision
boundary is getting better. These results reinforce our strategy that
those samples should be investigated to correct the classifier. Note
that this labeling is done manually by a security analyst, and it is
time consuming. Therefore, for the duration of this work, we only
ran a limited number of iterations for this experiment. Nonetheless,
it shows valuable insights on how our framework may perform in
Table 7: The accuracy of the samples identified by active
learning. At each iteration, 50 samples have been identified
and labeled by the security expert.
Anomalous Samples
Uncertain Samples
Accuracy of selected samples
Iter 1
0.56
0.60
0.58
Iter 2
0.50
0.77
0.63
Iter 3
0.65
0.82
0.73
a realistic setting. This system can be deployed in production over
multiple iterations, but the initial results are promising.
5 DISCUSSION AND FUTURE WORK
Living-Off-The-Land attacks have increasingly been used by adver-
saries to evade detection, as traditional endpoint security solutions
cannot address this problem effectively.
In this problem setting, ML models need to be trained with lim-
ited labeled data. Systems designed to solve this problem need to
consider reducing the human expert’s time spent on alert investi-
gation. We have detailed the design and evaluation of our LOLAL
active learning framework to address these challenges. Several
directions and challenges for future work include:
Context information for detecting advanced attacks. As the
labeled dataset grows, the performance of the classifiers will in-
crease, but some attack types might still not be detected. The ad-
versary could be operating remotely and might have shell access to
the victim’s computers. The malicious LOLBIN activity is usually
part of these multi-stage attack campaigns, such as those used by
Advanced Persistent Threats (APTs), where the adversary tries to
perform lateral movement in the target organization’s network,
and hopes to remain undetected for extended periods of time. More
contextual information may sometimes be needed to differentiate
the benign use cases as system administrators or developers may be
using these tools in different ways. The dataset could be expanded
to include more host information such as process trees or network
activity to help detect adversarial activity. Our system could be
enriched with more detectors and features to investigate other data
sources from the target hosts or networks in order to provide a
more holistic, global perspective that could enhance detection of
advanced adversaries such as APTs. The main challenges are collect-
ing context information on client devices, generating appropriate
feature representations, and obtaining representative traces of APT
attacks.
Comparison with traditional anti-virus tools. Our proposed
framework has several advantages over traditional anti-virus (AV)
solutions. AV solutions mostly rely on pattern matching and rules
to detect known malicious behaviors. OS-level protection, such as
AppArmor [4] on Linux, could be used to restrict programs’ capabil-
ities with a set of rules. These policies can be constructed once the
pattern of the malicious commands is known, but they will not help
finding new variations of malicious behavior. We can enhance these
detections with our machine learning-based approach. The advan-
tages of LOLAL is that it could detect novel attacks not matching
existing signatures, due to the anomaly detector component, which
selects samples for labeling in active learning. Moreover, LOLAL
trains a classifier iteratively to distinguish malicious and benign
452RAID ’21, October 6–8, 2021, San Sebastian, Spain
Ongun, et al.
Figure 6: Comparison of different active learning variants.
LOLAL outperforms methods that use different sample selection algorithms.
commands, based on novel embedding representations, and will
perform much better than static detection rules.
In terms of latency and run-time performance, our method has
some overhead compared to regular expression matching. Although
word2vec training is expensive, it is done off-line, and could occa-
sionally be re-trained to adapt to dynamic process behavior. Simi-
larly, score generation can periodically be updated with new data.
The cost at runtime is small: a look-up to generate embedded fea-
tures, and fast inference using a gradient boosting classifier that is
widely used in production.
Deploying the system in production. To deploy our system in
production, the ML classifier should be run on client devices and
generate scores for the monitored command lines. As soon as sus-
picious activity is detected, the client reports it to a central server.
Alerts should be prioritized at the server, and the anomalous and
uncertain samples should be periodically analyzed by domain ex-
perts. The feedback from expert analysis needs to be integrated into
the model, as the ML classifiers are continuously retrained with the
newly-labeled samples. The challenges for integrating our system
into an existing endpoint protection product include reducing the
number of samples sent by clients to the server, lowering false pos-
itives while maximizing recall, as well as obtaining and integrating
feedback from domain experts on a regular basis.
LOLAL was designed to be used based on telemetry received
from the Microsoft Defender for Endpoint product which inter-
cepts the command lines generated on the host. This product is
designed for post-breach detection and allows for a higher false
positive rate compared to a standard anti-virus product. Microsoft
Defender for Endpoint warns customers of potential attacks in a
portal and does not currently block LOL commands. Windows De-
fender Antivirus can automatically block these commands based
on confirmed detections from Microsoft Defender for Endpoint.
The resulting classifier of LOLAL could be used to report potential
attacks to the customer’s interface. In addition, Microsoft also of-
fers the Microsoft Threat Experts service, which allows Microsoft
analysts to investigate anonymized telemetry to look for possible
attacks within the organization. In the future, LOLAL might be
helpful to allow analysts to improve the classifier or discover new
LOL attacks.
Resilience to adversarial manipulation. Adversaries might use
the sample selection algorithm of the active learning framework
to their advantage. Since anomalous samples are selected for in-
vestigation, constructing a number of unusual commands on the
target host before the attack may lower the chance of the real
malicious command being investigated. Nonetheless, the security
analysts will still investigate the hosts generating these anomalous
commands, and are likely to uncover the malicious behavior. Poi-
soning attacks have been studied in a variety of machine learning
applications [8, 21]. In our setting, the endpoint security product
employs enhanced kernel-level protections to prevent tampering
with the data it collects. An adversary might still attempt to gen-
erate activity labeled as Benign to poison the models. It would
be interesting to determine what fraction of clients an adversary
needs to compromise in order to impact the command embedding
representations. Typically, in poisoning attacks a large fraction
of training data is under the control of the adversary (10-20% for
poisoning availability attacks [21], and 1% for backdoor poisoning
attacks [20]). We believe it is infeasible for attackers to poison such
a large percentage of samples in our setting, as the adversary will
not be able to get a footprint on many client devices. Adversaries
might attempt to evade our system at run time by adding more
benign-looking tokens in the command. Note that token scores
are only a subset of the features we use. We also use command
embeddings and the parent-child process information, which we
believe will provide more resilience to evasion attacks. Evading
the command embeddings will involve significant changes to the
command itself, as well as the parent process, and can be captured
as an anomaly in our system. We believe that attackers would be
very limited if restricted to use these commands in their legitimate
context, only with benign scores, to avoid triggering an anomaly.
We leave a detailed investigation of potential adversarial attacks
against our system for future work.
6 RELATED WORK
Several AV vendors published reports about the emerging threat of
attackers leveraging Living-Off-The-Land methods to evade detec-
tion [13, 14, 28, 32, 49, 52, 57]. To the best of our knowledge, our
RAID’21,October6–8,2021,SanSebastian,SpainOngun,etal.1234567891011121314151617181920Iteration0.00.20.40.60.81.0F1 ScoreF1 Score over variantsLOLALLOLAL-LRUncertainty SamplingAnomaly SamplingRandom Sampling1234567891011121314151617181920Iteration0.00.10.20.30.40.5False Positive RateFPR over variantsFigure6:Comparisonofdifferentactivelearningvariants.LOLALoutperformsmethodsthatusedifferentsampleselectionalgorithms.commands,basedonnovelembeddingrepresentations,andwillperformmuchbetterthanstaticdetectionrules.Intermsoflatencyandrun-timeperformance,ourmethodhassomeoverheadcomparedtoregularexpressionmatching.Althoughword2vectrainingisexpensive,itisdoneoff-line,andcouldocca-sionallybere-trainedtoadapttodynamicprocessbehavior.Simi-larly,scoregenerationcanperiodicallybeupdatedwithnewdata.Thecostatruntimeissmall:alook-uptogenerateembeddedfea-tures,andfastinferenceusingagradientboostingclassifierthatiswidelyusedinproduction.Deployingthesysteminproduction.Todeployoursysteminproduction,theMLclassifiershouldberunonclientdevicesandgeneratescoresforthemonitoredcommandlines.Assoonassus-piciousactivityisdetected,theclientreportsittoacentralserver.Alertsshouldbeprioritizedattheserver,andtheanomalousanduncertainsamplesshouldbeperiodicallyanalyzedbydomainex-perts.Thefeedbackfromexpertanalysisneedstobeintegratedintothemodel,astheMLclassifiersarecontinuouslyretrainedwiththenewly-labeledsamples.Thechallengesforintegratingoursystemintoanexistingendpointprotectionproductincludereducingthenumberofsamplessentbyclientstotheserver,loweringfalsepos-itiveswhilemaximizingrecall,aswellasobtainingandintegratingfeedbackfromdomainexpertsonaregularbasis.LOLALwasdesignedtobeusedbasedontelemetryreceivedfromtheMicrosoftDefenderforEndpointproductwhichinter-ceptsthecommandlinesgeneratedonthehost.Thisproductisdesignedforpost-breachdetectionandallowsforahigherfalsepositiveratecomparedtoastandardanti-virusproduct.MicrosoftDefenderforEndpointwarnscustomersofpotentialattacksinaportalanddoesnotcurrentlyblockLOLcommands.WindowsDe-fenderAntiviruscanautomaticallyblockthesecommandsbasedonconfirmeddetectionsfromMicrosoftDefenderforEndpoint.TheresultingclassifierofLOLALcouldbeusedtoreportpotentialattackstothecustomer’sinterface.Inaddition,Microsoftalsoof-ferstheMicrosoftThreatExpertsservice,whichallowsMicrosoftanalyststoinvestigateanonymizedtelemetrytolookforpossibleattackswithintheorganization.Inthefuture,LOLALmightbehelpfultoallowanalyststoimprovetheclassifierordiscovernewLOLattacks.Resiliencetoadversarialmanipulation.Adversariesmightusethesampleselectionalgorithmoftheactivelearningframeworktotheiradvantage.Sinceanomaloussamplesareselectedforin-vestigation,constructinganumberofunusualcommandsonthetargethostbeforetheattackmaylowerthechanceoftherealmaliciouscommandbeinginvestigated.Nonetheless,thesecurityanalystswillstillinvestigatethehostsgeneratingtheseanomalouscommands,andarelikelytouncoverthemaliciousbehavior.Poi-soningattackshavebeenstudiedinavarietyofmachinelearningapplications[8,21].Inoursetting,theendpointsecurityproductemploysenhancedkernel-levelprotectionstopreventtamperingwiththedataitcollects.Anadversarymightstillattempttogen-erateactivitylabeledasBenigntopoisonthemodels.Itwouldbeinterestingtodeterminewhatfractionofclientsanadversaryneedstocompromiseinordertoimpactthecommandembeddingrepresentations.Typically,inpoisoningattacksalargefractionoftrainingdataisunderthecontroloftheadversary(10-20%forpoisoningavailabilityattacks[21],and1%forbackdoorpoisoningattacks[20]).Webelieveitisinfeasibleforattackerstopoisonsuchalargepercentageofsamplesinoursetting,astheadversarywillnotbeabletogetafootprintonmanyclientdevices.Adversariesmightattempttoevadeoursystematruntimebyaddingmorebenign-lookingtokensinthecommand.Notethattokenscoresareonlyasubsetofthefeaturesweuse.Wealsousecommandembeddingsandtheparent-childprocessinformation,whichwebelievewillprovidemoreresiliencetoevasionattacks.Evadingthecommandembeddingswillinvolvesignificantchangestothecommanditself,aswellastheparentprocess,andcanbecapturedasananomalyinoursystem.Webelievethatattackerswouldbeverylimitedifrestrictedtousethesecommandsintheirlegitimatecontext,onlywithbenignscores,toavoidtriggeringananomaly.Weleaveadetailedinvestigationofpotentialadversarialattacksagainstoursystemforfuturework.453Living-Off-The-Land Command Detection
Using Active Learning
work is the first study focusing on Living-Off-The-Land malicious
command line detection. Malicious command line detection, and
active learning for security has been studied extensively in recent
years.
Malicious command line and script Detection. Most of the
work in this area focuses on malicious PowerShell script/command
detection, as attackers increasingly use this powerful tool. Mali-
cious Powershell script detection has been studied by [9, 40, 41].
Yamin et. al. [60] proposed using NLP techniques to detect malicious
Windows commands. Rubin et. al [40] proposed using contextual
embeddings to represent tokenized PowerShell scripts to train neu-
ral networks for detecting malicious scripts. Wang et. al. [58] study
provenance-based methods for detecting stealthy malware that
could use Living-Off-The-Land techniques. Their method models
the whole attack graph to identify anomalies. Debar et. al. [16]