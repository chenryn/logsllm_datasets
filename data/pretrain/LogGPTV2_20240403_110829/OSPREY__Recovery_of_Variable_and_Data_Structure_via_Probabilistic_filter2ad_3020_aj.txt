I. Impact of Aggressive Optimization
To understand the impact of aggressive optimizations, we
evaluate OSPREY on the two benchmark sets compiled with
-O3, the most aggressive builtin optimization ﬂag of GCC.
The results are shown in Table IV. We calculate the F1
score [46] for each tool, and summarize CoreUtils’ results.
Table IVa presents the overall F1 scores including both scalar
and complex variables. The average F1 scores (with -O3)
for OSPREY, Ghidra, IDA Pro, and Angr are 0.70, 0.48,
0.27, and 0.16, respectively; and the degradation from the
default optimization (-O0) are 22.48%, 27.18%, 45.47%, and
42.64%, respectively. Although recovering accurate types from
aggressively optimized code is very challenging, OSPREY
substantially outperforms other state-of-the-art techniques. Be-
sides, OSPREY is the most robust tool among all the evaluated
ones. Manual inspection discloses that some aggressive opti-
mizations disrupt OSPREY’s hints (e.g., loop unrolling [79]
Program
s
d
r
a
w
o
H
wget
lighttpd
grep
gzip
fortune
CoreUtils
Avg.
(b) F1 scores for complex variable recovery
Osprey
Def. O3
0.55
0.78
0.44
0.85
0.68
0.50
0.55
1.00
0.76
1.00
0.62
0.80
0.85
0.57
Ghidra
Def. O3
0.45
0.36
0.38
0.09
0.16
0.35
0.35
0.70
0.71
0.57
0.43
0.38
0.38
0.45
IDA
Def. O3
0.14
0.32
0.33
0.12
0.18
0.20
0.33
0.67
0.52
0.13
0.35
0.39
0.30
0.31
# CVars
Def. O3
127
239
43
318
120
38
41
45
13
16
11
23
127
45
(c) Tree difference
Osprey
Ghidra
IDA
Program
s
d
r
a
w
o
H
Def. O3 Degra. Def. O3 Degra. Def. O3 Degra.
wget
28.92 57.24 49.47% 70.99 72.88 02.48% 62.84 75.14 16.37%
lighttpd 12.37 21.42 42.25% 80.18 55.10 -45.53% 64.87 62.81 -03.28%
30.09 26.96 -11.63% 78.41 72.62 -07.97% 60.93 89.68 32.06%
grep
gzip
00.00 41.67 100.0% 42.50 62.50 32.00% 00.00 50.00 100.0%
fortune 00.00 08.00 100.0% 100.0 50.00 -100.0% 00.00 50.00 100.0%
CoreUtils 29.32 63.26 53.65% 73.31 78.69 06.83% 64.04 78.61 18.54%
16.78 36.42 55.63% 74.23 65.28 -18.70% 42.11 67.71 43.95%
Avg.
and partial function inlining [80]), resulting in the degraded
accuracy. For example, loop unrolling can generate multiple
copies of a single memory access instruction such that we
lose the hint that detects an array by observing consecutive
memory locations being accessed by the same instruction.
Table IVb shows the F1 scores for complex variable recov-
ery. Observe that OSPREY still achieves substantially better F1
of 0.57 (compared to 0.45 for Ghidra and 0.31 for IDA Pro).
One may notice that Ghidra and IDA Pro get better results
with the -O3 ﬂag. Although it seems counter-intuitive, further
inspection shows that it is not because they are having better
performance but rather the number of complex variables in
memory becomes smaller. Recall that we consider a structure
being pointed to by a pointer in memory a complex variable.
With -O3, these pointers are largely allocated to registers. We
do not collect results for these cases as Howard does not
consider variables in registers. While Ghidra and IDA Pro tend
to have trouble with complex variables in memory, the number
of such cases are reduced.
We additionally count the number of complex variables,
shown in Table IVb. The results show that the number of
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
831
0.00%50.00%100.00%Tree Edit Distance for Structural DataProgramsOSPREYGhidraIDA Pro 7.229.32%64.04%73.31%TABLE V: Effects of BDA and probabilistic inference. Origi-
nal, w/o BDA, and w/o Prob. stand for the original OSPREY,
OSPREY with a dynamic-execution component
instead of
BDA, and OSPREY with deterministic inference instead of
probabilistic inference, respectively. Cov. denotes the fraction
of functions that the dynamic approach exercised.
Program
wget
lighttpd
grep
gzip
fortune
Avg.
Original
Reca.| Prec.
85.32 | 86.14
87.67 | 86.35
82.10 | 84.07
100.0 | 100.0
100.0 | 100.0
91.02 | 91.32
w/o BDA
Reca. | Prec.
29.46 | 86.31
73.75 | 97.16
44.48 | 89.78
43.48 | 100.0
75.61 | 100.0
53.36 | 94.65
w/o Prob.
Reca.| Prec.
Cov.
51% 45.43 | 47.21
55% 40.24 | 40.74
50% 44.76 | 46.04
74% 64.37 | 64.37
76% 78.57 | 78.57
61% 54.67 | 55.39
upon Pintools [83]. Following the same setup as Howard,
we use the provided test suite and also KLEE to increase
code coverage. To study the effect of probabilistic inference,
in the second variation, we turn the probabilistic inference
to deterministic inference. The deterministic inference rules
are largely derived from the probabilistic rules but have the
probabilities removed. As such, when multiple contradictory
inference results are encountered (e.g., conﬂicting types for a
variable), which are inevitable due to the inherent uncertainty,
the algorithm randomly picks one to proceed.
The results are shown in Table V. We report the precision
and recall of the ﬁrst variation for overall variables in the
fourth and ﬁfth columns. We also report the dynamic code
coverage in the sixth column. Due to page limits, we elide
other metrics as they are less interesting. Compared with the
original OSPREY, the dynamic-execution-based OSPREY has
slightly higher precision but lower recall. As dynamic execu-
tion strictly follows feasible paths, there are fewer conﬂicts,
beneﬁting the precision. However,
the conﬂicts introduced
by BDA’s incapabilities of determining infeasible paths are
decentralized and cumulatively resolved by the large number
of hints, making the improvement limited. On the other hand,
the dynamic-execution-based OSPREY cannot get hints from
the non-executed functions, leading to the low recall. Hence,
we argue that BDA is essential to OSPREY.
The results of the second variation are shown in the last
two columns of Table V. Note that the deterministic version
of OSPREY has nearly 40% decrease in terms of both recall
and precision. Such results indicate the probabilistic parts of
OSPREY are critical. We also study the reason behind the
degradation. On one hand, due to the infeasible paths, BDA
may generate many invalid accesses. When these accesses
conﬂict with the valid ones, the deterministic algorithm may
choose the wrong one. On the other hand, many inference rules
/ hints have inherent uncertainty. For example, rule CB02 says
when an instruction accesses multiple addresses in the same
region, likely, there is an array in that region. Note that it
is likely but not certain, as the situation could also be that
a pointer points to multiple individual objects. Deterministic
approaches are by their nature not suitable for handling such
inherent uncertainty.
(a) Default optimization
(b) O3 optimization
Fig. 21: OSPREY’s F1 scores for overall variable recovery on
the two benchmark sets compiled by GCC and Clang. The
results of CoreUtils are averaged over all programs.
complex variables decreases a lot from the default setting (127
v/s 45), supporting our hypothesis.
Table IVc presents the tree difference. Although OSPREY
has the smallest tree difference of 36.42 (compared to 65.28
for Ghidra and 67.71 for IDA Pro), the aggressive optimiza-
tions have larger impact on OSPREY. This is however reason-
able because OSPREY’s structure recovery mainly depends on
hints from program behaviors which can be greatly changed
by optimizations, while Ghidra and IDA Pro mainly depend on
predeﬁned function prototypes of external library calls which
are rarely inﬂuenced by optimizations. Ghidra’s register-based
data-ﬂow analysis also beneﬁts from optimizations. We foresee
that a set of rules particularly designed for optimized programs
can be developed for OSPREY. We will leave that to our future
work.
Finally, we want to point out that fortune is an outlier which
always achieves better results under aggressive optimizations.
This is because fortune is a very simple program (randomly
outputting predeﬁned sentences [81]) and O3 optimizations put
most of its variables in registers, reducing aliasing and greatly
beneﬁting the register-based data-ﬂow analysis.
J. Impact of Different Compilers
To study the robustness over different compilers, we ad-
ditionally examine OSPREY on benchmarks compiled by
Clang [82], another mainstream compiler. We use Clang 6.0
to compile the two benchmark sets with the default and -O3
optimization ﬂags, and summarize the results in Figure 21. The
results show that OSPREY has good robustness with different
compilers under the default compilation setting (less than
6% difference for each program). Although there is a larger
difference between GCC and Clang under the -O3 setting, we
speculate that it is because the -O3 optimizations of GCC and
Clang behave differently (e.g., they have different thresholds
for loop unrolling). The results of complex variable recovery
and tree difference reveal similar trends and are hence elided.
K. Contribution Breakdown of Different Components
To better understand the effect of different components,
including BDA and probabilistic inference, we further eval-
uate OSPREY with two variations. Speciﬁcally, to study the
contributions of BDA, in the ﬁrst variation, we replace the
BDA component with a dynamic-execution component built
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
832
0.860.870.831.001.000.890.920.840.870.940.940.89wgetlighttpdgrepgzipfortuneCoreUtilsGCCClang0.660.650.740.740.820.620.830.790.760.730.940.63wgetlighttpdgrepgzipfortuneCoreUtilsGCCClang