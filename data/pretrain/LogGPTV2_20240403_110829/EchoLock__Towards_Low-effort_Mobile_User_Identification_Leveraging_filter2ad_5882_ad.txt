a one-time configuration process by estimating time-of-flight of a
sample ultrasonic signal for all speaker-microphone combinations.
7.2 Posture Stabilization Detection
The design of EchoLock allows for the identification process to be
initiated by many types of actions. For seamless and low-effort us-
age, this process can be triggered by automatically detecting actions
such as the user picking or grabbing the intended device. Motions
such as picking the device are common triggers in existing API for
iOS and Android, enabling easy integration with our system. How-
ever, triggering acoustic sensing immediately after these actions
may risk recording unnecessary audio, such as shuffling of items
or accidental collisions while the user is moving their hand. To
circumvent this, we ensure our system initiates sensing only when
movement of the device has stabilized. When movement is not
yet stable, the user may still be adjusting their grip on the device,
leading us to obtain external sensor readings in order to monitor
this behavior. For smartphones and tablets in particular, we can
leverage motion sensors such as gyroscopes, accelerometers, and
magnetometers to obtain a trace of the motion path. We can then
compute variance of this trace across a sliding interval (e.g. every
0.1 seconds) and compare it with a pre-determined threshold to
pinpoint when major hand or arm movements have subsided. This
ensures minimal disturbances from non-acoustic sources.
7.3 Environmental Noise Removal
We capture our transmitted ùëõ-chirp sequence as an audio recording
using on-board microphones, which may also contain interference
in the form of ambient noise and high frequency distortions. Gener-
ally speaking, naturally occurring sound from daily activity such as
movement or light conversation is unlikely to reach the inaudible
frequency range used by EchoLock, however noise may still be in-
troduced as a result of speaker imperfections, loud public spaces, or
malicious actions by attackers. As a countermeasure, we filter our
obtained recording prior to detailed signal processing. In particular,
we design a band-pass filter with the pass band through 18kHz to
22kHz, which is the expected frequency range of the transmitted
chirp signal. We apply a Butterworth low-pass and high-pass filter
at the specified frequencies to achieve this. We use a third-order
filter in order to minimize passband ripple in our signal amplitude
and avoid distorting the biometric information embedded within.
(a) Top microphone
(b) Bottom microphone
Figure 8: Classification accuracy for two available mi-
crophones based on signal transmission from a bottom-
positioned speaker.
Machines (SVM) and find SVM to be the most effective among all
the classifiers. The SVM architecture is thoroughly studied and well
suited for lightweight and mobile platforms such as Android, which
helps ensure our system is deployable on many devices. SVM relies
on a hyperplane to divide the input acoustic sensing feature space
into the categories with each representing a user. The hyperplane
is determined during the training phase with the acoustic sensing
data from the registered users. We use LIBSVM with a cubic kernel
to build the SVM classifier [11].
6.4 User Profile Construction
EchoLock requires the user to provide the training data for user
profile construction during registration. Our ùëõ-chirp sequence is
transmitted and, based on the optimal chirp selection, a subset of
the chirp signals are processed for features to represent the user.
These features are shaped not only by hand geometry, but the device
structure itself. As structure-borne sound propagation is specific
to material, dimensions, and external forces (i.e. a firm grip by the
user), we construct a secure credential that is specific to a particular
user and device pair. This also prevents an isolated security breach
from compromising other devices and services of a given user as
structure-borne properties will differ from model to model. An
existing data set of anonymized user profiles is included to serve
as negative labels when classifying the user during identification
attempts. Registering multiple users to the same device also serves
to expand this data set. To ensure robustness and low false negative
rates, the user is advised to vary holding behavior multiple times
rather than remain still to train the data. This can be verified using
motion sensors to detect change in device holding posture.
7 IMPLEMENTATION
7.1 Sensing Microphone Selection
Contemporary mobile devices are often built with multiple on-
board microphones, particularly smartphones which employ them
for noise cancellation during phone calls. These devices also usu-
ally contain multiple speakers, which are typically located at the
extremities to reserve central space for screens or buttons. We find
that for devices with more than a single on-board microphone, re-
ception of acoustic signals from the speakers can vary considerably.
For example, speakers and microphones positioned adjacently gen-
erally gather less structural information as the propagation path
is extremely short. When positioned at opposite ends, however,
Accuracy: 96.00%100.0%200.0%00.0%00.0%00.0%00.0%0100.0%200.0%00.0%00.0%00.0%00.0%095.0%195.0%10.0%00.0%00.0%015.0%385.0%170.0%00.0%00.0%00.0%00.0%0100.0%2012345Target Class12345Output ClassAccuracy: 61.00%60.0%125.0%120.0%410.0%25.0%120.0%450.0%105.0%125.0%50.0%00.0%00.0%0100.0%200.0%00.0%035.0%710.0%215.0%325.0%515.0%35.0%120.0%40.0%05.0%170.0%1412345Target Class12345Output ClassSession 14: CPS Security ASIA CCS ‚Äô20, October 5‚Äì9, 2020, Taipei, Taiwan779(a) Nexus 5
(b) Galaxy Note 5
(c) Galaxy Tab A
(d) Example attack model setup.
Figure 9: Experimental setup for evaluating EchoLock. (a)
through (c) show example holding styles and devices spec-
ifications, (d) depicts evaluation of the adversary model.
8 PERFORMANCE EVALUATION
We study the performance of EchoLock in a variety of common use
case scenarios as well as on several mobile devices. Our experiments
test the capability of our system to lock or unlock access to mobile
devices as an example application, approved by our institute IRB.
We present our findings and detailed analysis below.
8.1 Experimental Setup
Devices and Scenarios. A prototype application for EchoLock was
developed for use on Android. Three smartphones, the Nexus 5,
Nexus 6, Galaxy Note 5, and two tablet devices, the Galaxy Tab
A and Lenovo Tab 4 , were selected for their varied designs (e.g.,
speaker and microphone positions) and dimensions, pictured in
Figure 9. The smartphone devices include two onboard microphones
whereas the tablets are equipped with one. We evaluate our system
in typical office and public scenarios. The office scenarios consist
of quiet, enclosed spaces with minimal disturbances whereas the
public scenarios are locations with large volumes of people and
traffic. We maintain an average noise level of approximately 30dB
and 60dB for the two environments, respectively. Sources of noise
for the public environment include nearby conversations, walking,
and dining. We gauge the ability of our system to accurately identify
the user in face of these obstacles. We also investigate the impact of
accessories that may transform the properties of the user‚Äôs hand or
device structure, such as gloves or smartphone cases. Additionally,
we assess the viability for adversaries to compromise our system
using various strategies. From these identified factors, we devised
several scenarios to study.
Data Collection. 10 use case experiments were conducted in
total, divided into 3 general categories. The first category examines
the ability of our prototype to successfully identify the current
user holding the device. The second category studies performance
Figure 10: Overall performance for different mobile devices.
differences when used in a public environment. The third category
considers usage via indirect physical contact, which includes when
the user has equipped a protective case to their device and when
the user is wearing a glove while holding their device. To reduce
the number of factors at play, we confine our study to office en-
vironments unless otherwise noted. Mobile devices are provided
on a table for the participants to pick up, hold, and place down.
Although our system can support automatic data collection as de-
scribed in Section 7.2, we initiate collection manually through the
press of a button to eliminate the possibility of lost data due to
undetected triggers. No specific instruction was provided on how
to hold the device to encourage more natural interactions. However,
we find that almost all participants favored holding postures similar
to those shown in Figure 9. This is both beneficial and challenging
as this adds consistency to our data set while also making it less
simple to differentiate usage behaviors.
We recruit 20 volunteers, 14 males and 6 females ranging from
ages 18-35, to participate in our study. We collect 40 ùëõ-chirp se-
quences, where ùëõ=10, for each test case based on the procedure in
Section 6.4 for a total of 80,000 hand geometry samples. The pro-
files of all volunteers collectively act as the negative label during
classification, with the exception of the target user undergoing iden-
tification. While this data is used for user identification purposes,
we do not consider it to be personally identifiable information (as
mentioned in Table 1). Nonetheless, we are currently maintain-
ing this data privately and do not plan to release it publicly as a
precaution.
8.2 Evaluation Metrics
We describe the accuracy of our system by evaluating the rela-
tion between precision and recall as well as usage of standard ROC
curves. Precision is defined as the percentage of True Positive (TP)
classifications out of all positive classifications recorded, notated
as ùëÉ = ùëá ùëÉ
ùëá ùëÉ+ùêπ ùëÉ where FP is the false positive rate. Recall is defined
ùëá ùëÉ
as ùëÖ =
ùëá ùëÉ+ùêπ ùëÅ or the percentage of true positive classifications
out of all target class instances. For our purposes, higher precision
describes lower probability for different people to be mistaken for
the legitimate user while higher recall describes the lower proba-
bility that the legitimate user is misidentified as someone else. The
receiver operating characteristic (ROC) curve graphs the TP rate
over the FP rate. The ideal system has a simultaneous 100% TP rate
and 0% FP rate, i.e. all legitimate users are correctly identified while
all attackers are denied access.
00.10.20.30.4FPR0.60.70.80.91TPRGalaxy Note 5Nexus 5Galaxy Tab ANexus 6Lenovo Tab 4Session 14: CPS Security ASIA CCS ‚Äô20, October 5‚Äì9, 2020, Taipei, Taiwan780(a) ROC curve.
(b) Precision-Recall curve.
(a) ROC curve.
(b) Precision-Recall curve.
Figure 11: Performance under impersonation attacks.
Figure 12: Eavesdropping and replay attack performance.
8.3 User Identification Performance
From our signal processing procedures, we obtain several features
used to identify the user and present them to a machine learning
classifier for identification. To evaluate the performance of our
implementation, we consider Bagged Decision Trees (BDT), Lin-
ear Discriminant Analysis (LDA), K-Nearest Neighbor (KNN), and
Support Vector Machines (SVM) as our candidate classifiers. From
our initial comparisons of each classifier‚Äôs ability to distinguish
between 5 different users on a Nexus 5, we observe SVM utilizing a
cubic kernel function to demonstrate the strongest performance.
As a result, we present our findings for the SVM in our extended
evaluations. We choose 10-fold cross-validation during the training
process to best utilize our data set and minimize selective bias, allo-
cating 50% for training and the remaining 50% for testing. Figure
10 illustrates the capability of our system to correctly identify the
legitimate user, showing average TP rate of 94% for a 5% FP rate
across a variety of different mobile devices. We detail the effects
of adverse conditions and multiple impact factors in the following
subsections.
8.4 Attacks on User Credentials
Impersonation Attacks. We evaluate the possibility of potential
attackers to impersonate hand profiles of other users as a means
of gaining unauthorized access to devices and information. For
our assessment, we consider the worst case scenario; a limited (i.e.
5) training sample size for the victim user and multiple informed
attackers. Our system is trained on user samples from 10 of our 20
participants, with one user acting as our victim and the remainder
serving as negative labels. The 10 participants not involved in the
training process act as attackers in our study. Attackers are allowed
30 seconds to observe the designated victim using our hardware
platforms and given 10 attempts to imitate their hold. We conduct
this process for 2 of our smartphones and 1 of our tablet devices.
Observation of the victim is conducted from behind (i.e. shoulder
surfing) and directly across (i.e. sitting in front).
Our results suggest that visual observation alone is insufficient
to prepare an attacker for impersonation of another hand profile.
We measure the TPR and FPR, plotted as the ROC curve in Figure
11(a), showing FPR as low as 6% for a 90% TP rate for devices such
as the Nexus 5. Shoulder surfing in particular was found to be
unhelpful for the attackers as the victim hand is mostly obscured
by the device. This would suggest that successful impersonation is
dependent on physical similarity between the attacker and victim,
which the attacker cannot control.
(a) Public environments.
(b) Different physical contact.
Figure 13: Performance in successfully identifying the legit-
imate user under various common circumstances.
Eavesdropping and Replay Attacks. We assessed the viabil-
ity of eavesdropping information during our studies on standard
usage behavior. Figure 9(d) shows an example hardware config-
uration during these experiments. The victim is seated at a desk
and uses our system on a mobile device. A separate mobile device
positioned 0.2m from the victim acts as a malicious sensor, listen-
ing for the validating signal. Many smartphones and tablets are
able to activate their microphones without any obvious indicators
onscreen, making this attack strategy highly plausible. We recruit
10 of our participants to act as 9 victims and 1 attacker. The profiles
of the remaining 10 participants are used as negative labels dur-
ing identification. We train our system on data from the 9 victims,
though purposely exclude the attacker to simulate an attack by
an unknown user. Each victim first authenticates themselves to
generate a signal for the attacker to eavesdrop. The attacker then
uses this signal to attempt to falsify their identity to our system.
Our experiments show EchoLock is able to correctly recognize
each victim while also blocking the attacker when attempting to
use an eavesdropped ùëõ-chirp sequence. Filtered signals recovered
from these simulated attacks in an office setting showed recogniz-
able chirp patterns, however clarity is lost due to the multipath
effect. This is reflected in Figure 12, resulting in 0% false positive
readings and perfect precision and recall. Recorded signals must
travel through two airborne paths, once from the victim device
to the eavesdropper and vice versa, causing significant attenua-
tion and loss of genuine structure-borne properties. This level of
attenuation is too severe for an attacker to compensate without
intimate knowledge of the victim‚Äôs authentic signal. We note that
an attacker may attempt to deceive a na√Øve user into installing a
malicious app in the mobile device, compromising the security of
user identification techniques, including EchoLock. Protecting users
from deception by attackers is a larger security problem to study,
but beyond the scope of this paper.
00.20.40.60.81FPR00.20.40.60.81TPRNexus 5Galaxy Note 5Galaxy Tab A00.20.40.60.81Recall00.20.40.60.81PrecisionNexus 5Galaxy Note 5Galaxy Tab A00.20.40.60.81FPR00.20.40.60.81TPRNexus 5Galaxy Note 5Galaxy Tab A00.20.40.60.81Recall00.20.40.60.81PrecisionNexus 5Galaxy Note 5Galaxy Tab A00.10.20.30.4FPR0.60.70.80.91TPRGalaxy Note 5Nexus 5Galaxy Tab A00.10.20.30.4FPR0.60.70.80.91TPRGalaxy Note 5CaseGloveSession 14: CPS Security ASIA CCS ‚Äô20, October 5‚Äì9, 2020, Taipei, Taiwan7818.5 Impact Factor Study