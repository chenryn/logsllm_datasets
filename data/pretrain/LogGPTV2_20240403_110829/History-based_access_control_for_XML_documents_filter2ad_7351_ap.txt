of the edited data. The user interface of this prototype is not optimized for
speciﬁc types of data and is mainly designed to illustrate the concepts of this
thesis. Therefore, the current User Interface only oﬀers a textual represen-
tation of the XML documents and the corresponding editing command are
independent of the semantics of the processed XML documents. Figure 7.3
shows a screenshot of the User Interface of the prototype. We will describe
the functions oﬀered by this User Interface.
Figure 7.3: Screenshot of the User Interface
This User Interface displays an opened XML document in its textual
representation in the middle area of the window. Multiple documents can
be opened simultaneously, but only one document is displayed at any time.
A currently not displayed document can be displayed by clicking in the top
area of the window, where the name of the document is displayed. In the
screenshot in Figure 7.3, only one document with the name Report.xml is
opened.
Buttons that can be used to edit the document are on the upper left
side of the User Interface window, where each such button corresponds to
one operation of the model. Three check boxes that activate diﬀerent view
options are located below the button for editing. These check boxes can
be used to illustrate the internal operations of the User Interface. The ﬁrst
of these buttons allows to view the histories, which are stored within the
108
CHAPTER 7.
IMPLEMENTATION
document. The second button allows to view deleted elements. Finally,
the third button hides all tags and shows the text content of the opened
document.
The button XPath Evaluator, which is located below the document area
on the left side, allows to manually enter an XPath expression that makes
use of the extended functions deﬁned in this thesis. The entered XPath
expression is evaluated for the currently active document the the resulting list
of nodes is displayed. This function is designed for demonstration purposes,
too.
Finally, four buttons that are used to create a new document, to load
an existing document, to save a changed document and to close an opened
document, are located on the right side of the XPath Evaluator. The loading
of a document performs the check-out, as it is described in Section 5.2.1 of
Chapter 5. In similar fashion, the storing of a document triggers the check-in
mechanism. Both mechanisms are used to eﬃciently reduce the number of
required view recalculations.
7.2.2 Copy DB
In this implementation, we store the rules in an XML document, which
is loaded when the server components of the system are started. We use
Is-Copy-Of elements to represent individual is-copy-of relations. Within
such an element, the source of a copy operation is captured by a Source
element, whereas the destination is described by a Destination element.
These element denote a source or destination by a sequence of document ID,
element ID and block ID. In case of elements, the block ID is set to “-1”.
(0:3:-1)
(0:4:-1)
(1:1:0)
(4:3:0)
Figure 7.4: Example of the XML representation of the copy database
Figure 7.4 shows an example of such an XML representation. This exam-
ple features two is-copy-of relations. The ﬁrst relation reﬂects the transfer of
7.2. COMPONENTS
109
an element within a document with the document ID 0, whereas the second
relation describes the transfer of a text block from the document with the
ID 1 to the document with the ID 4.
7.2.3 Rule DB
The Rule DB stores the rules in an XML document, which is loaded when
the server components are started. Such a policy ﬁle, must specify a default
policy which is applied when no other rule is matching. Moreover, it support
two types of rules, namely unary rules and transfer rules.
Deny
1
Change Attribute
//@funded-by
Allow
3
/Report[@funded-by="Company A"]
/Report[@funded-by="Company B"]
Allow
Figure 7.5: Example of a policy dcoument
Figure 7.5 shows an example of such a policy document. In this example,
the default policy is “deny”. Moreover, this example shows a unary rule as
well as a copy rule.
7.2.4 Policy Enforcement Point
The Policy Enforcement Point intercepts each performed operation and sends
a request to the Policy Decision Point to ask whether the operation in ques-
tion is allowed. For that purpose, the Policy Enforcement Point oﬀers a
method for every operation deﬁned by the model. The Policy Enforcement
Point can be conﬁgured to communicate with diﬀerent PDPs. However, one
110
CHAPTER 7.
IMPLEMENTATION
speciﬁc PDP must be chosen. This conﬁguration is made with the Server
Configurator, which we describe in Section 7.3.
7.2.5 Policy Decision Point
The Policy Decision Point loads the access control rules when the component
is initialized. A path must be speciﬁed where the XML ﬁle containing the
access control rules can be found. After initialization, the Policy Decision
Point can create a view of a document for a speciﬁed user and evaluate the
access control rules to check whether a speciﬁc operation is allowed.
7.3 Conﬁguration
The server components can be conﬁgured by a dedicated Server Config-
urator program. This program allows to deﬁne which classes are used for
speciﬁc functions. For example, this allows to switch between a local or
remote Copy DB. Moreover, the implementation of speciﬁc components, e.g.,
the Copy DB, can be replaced by a diﬀerent implementation that support the
deﬁned interface. This allows to easily exchange components of the current
prototype without the need to modify the existing source code. In addition
to this, the Server Configurator allows to deﬁne where the Copy DB is
stored, where documents are stored and where the policy document is stored.
Figure 7.6 shows a screenshot of the Server Configurator. In this ex-
ample, the prototype is executed locally and the paths to all required ﬁles are
set to a HiBac directory within the home directory of the user proeder. The
server uses a directory where all XML documents are stored, which is referred
to as “document folder” in the Server Configurator. In addition to the
directory, the server uses a text ﬁle to store the names of all XML documents
together with their document IDs. In the screenshot, the corresponding ﬁle
is named docNames.txt.
7.4 Performance Evaluation
In this section, we summarize the results of the performance evaluation, that
is described in detail in [Mel07]. As the performance of XPath queries has
already been discussed, e.g., in [GK02, GKP03, GKP05], we only evaluate
the performance of the functions that we have added to XPath. Moreover,
we measure the time to calculate a view to determine the impact of our
extension functions on the overall execution time of an XPath query.
7.4. PERFORMANCE EVALUATION
111
Figure 7.6: Screenshot of the Server Conﬁgurator
To determine the runtime behavior of an XPath function, we have tested
several diﬀerent factors to check whether the runtime depends on one or more
of these factors. We learned from our tests, that the runtime of each function
depends on only one speciﬁc factor, e.g., the number of nodes of the current
document. Moreover, we see that groups of functions have identical runtime
behavior and depend on the same factor. These groups of similar runtime
behavior do not exactly match the categories that we have deﬁned in Section
4.7. After we have identiﬁed the factor on which the runtime of a speciﬁc
function depends, we made a series of measurements where we increased
that factor from measurement to measurement. Each individual test was
repeated ﬁve time to reduce random sources of errors. With this method, we
determined how the runtime depends on the factor. For example, some tests
showed that functions have a constant runtime, whereas other functions have
a runtime that increases linearly with a speciﬁc factor. The speciﬁcation of
our test system is listed in Table 7.2.
112
CHAPTER 7.
IMPLEMENTATION
Processor
Memory
Operating System
Java Version
XPath 2.0 Implementation Saxon-B 8.8 (http://saxon.sourceforge.net)
Development Environment Eclipse SDK 3.2.2 (http://www.eclipse.org)
AMD Sempron 3100+
480 MB
Microsoft Windows XP Home Edition SP2
JRE 1.5.0 (http://java.sun.com)
Table 7.2: Speciﬁcation of the test system
7.4.1 Performance of Individual Functions
The ﬁrst group of functions of similar runtime behavior, is the group of func-
tions that return exactly one speciﬁc node or one atomic value, e.g., a string.
These functions of this group are selfAt, parentAt, rootAt, getCrea-
tionContext, currentNode, srcNode, destNode, currentSubject, cur-
rentRole and isDeleted. These functions show a constant runtime inde-
pendent of the tested documents, e.g., independent of the number of nodes
in the document or the size of the tested documents. The runtime of each
of this functions is around 5 milliseconds on the system that was used to
perform the tests. These tests show that the performance of these functions
is acceptable to be used in practice.
The next group of functions of similar runtime behavior is the group that
depends on the number of copies of the tested node. These functions are
copies, predecessors and successors. Our tests show, that the runtime
of these functions depends in a linear fashion on the number of copies of the
tested node. For example, with 25 copies such a function takes 100 millisec-
onds and with 100 copies it takes about one second to compute. These tests
show, that the implementation is suﬃciently fast for documents where single
elements are copied less than 100 times. We believe that the performance of
this group of functions is still acceptable for practical usage.
The runtime of the next group of functions is determined by the number
of nodes that are in a speciﬁc relation to the node used in the test. For
example, the runtime of the function childrenAt depends on the number
of child nodes of the tested node, whereas the runtime of the functions de-
scendantAt depends on the number of descendants of the tested node. In
all cases, the runtime depends in a linear way on the number of nodes that
are in a speciﬁc relation to the node used in the test. The functions of
this group are childrenAt, followingAt, precedingAt, descendantAt,
precedingSiblingAt and followingSiblingAt. The call of a function of
this group that returns 25 nodes takes about 100 milliseconds, whereas a call
that returns 100 nodes takes about 500 milliseconds. Whether the perfor-
7.4. PERFORMANCE EVALUATION
113
mance is suﬃciently fast for practical usage, depends both on the documents
that are used and how rules are expressed. Im some cases, the performance
can be to slow, to use the current implementation in practice.
The functions of the next group of similar runtime behavior are used to
retrieve the context of speciﬁc actions, e.g., the changing of attribute values.
The functions of this group are geAttrChangeContexts, getDeletionCon-
texts and getViewContexts. The runtime of these functions depends on
the number of contexts that are retrieved by the corresponding function
and increases linearly with the number of contexts.
In absolute numbers,
retrieving 100 contexts takes about 10 milliseconds, whereas retrieving 400
contexts takes about 30 milliseconds. For practical usage, this performance
is absolutely suﬃcient.
Group of Functions
parentAt,
rootAt,
selfAt,
getCreationContext,
currentNode,
srcNode, destNode, currentSubject,
currentRole, isDeleted
copies, predecessors, successors
childrenAt,
precedingAt,
descendantAt,
followingSiblingAt
getAttrChangeContexts,
getDeletionContexts,
getViewContexts
created, viewed, changedAttribute,
deleted, accessed, modified
precedingSiblingAt,
followingAt,
Runtime
behavior
constant
Usability
highly usable
linear
linear
acceptable
limited
linear
highly usable
linear
needs
improvement
Table 7.3: Summary of the performance of diﬀerent groups
The functions of the last group with similar runtime behavior, are used to
retrieve accessed nodes. These functions are created, viewed, changed-
Attribute, deleted, accessed and modified. The runtime of this func-
tions increases linearly with the number of accessed nodes. For example, a
function call which retrieves 100 nodes takes about 500 milliseconds, whereas
a call returning 650 nodes takes about 5 seconds. The functions of this group
need further improvement to be used in a real life scenario. As the current
prototype is not optimized towards performance, we see large potential to
increase the performance of the implementation. Finally, in Table 7.3 we
114
CHAPTER 7.
IMPLEMENTATION
summarize the performance of the diﬀerent groups of functions of similar
runtime behavior.
7.4.2 Performance of the Creation of Views
We ﬁnally present the results of the performance evaluation for creating a
view. For this test, we used a set of ﬁve rules, where three of the rules used
extension functions that access history information. The time to create a view
increases linearly with the number of nodes of the document in question. In
our test case, it took 2 seconds to create a view of a document with 4000
nodes, whereas it took about 7 seconds for a document containing 12000
nodes. We think that this performance is still acceptable for being used
in practice. Nevertheless, the performance can be increased with further
optimizations. In addition to this, there are much faster machines than the
machine that we have used for our tests.
Chapter 8
Related Work
In this chapter, we describe work that that is related to this thesis. We divide
the related work in three areas, which we describe in the following. Access
control can be performed on the server only, which we refer to as Server-side
Access Control . This is also the ﬁrst area of related work that we discuss in
Section 8.1. Server-side access control controls access only when information
is released to the client. As a consequence, there is no access control after
the releasing of information.
The counterpart of server-side access control is Client-Side Access Con-
In client-side access control, access
trol , which we discuss in Section 8.2.
control is only performed on the client. This type of access control is also re-
ferred to as Digital Rights Management or simply Rights Management. The
client can be manipulated easily, since it is under the control of the user, who