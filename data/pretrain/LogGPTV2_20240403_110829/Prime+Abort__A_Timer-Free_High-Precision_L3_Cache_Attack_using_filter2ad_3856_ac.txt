dence to render it impractical for most real applications,
and for the rest of the paper we focus on the other two
attacks we will present.
second
present,
attack we will
3.2 PRIME+ABORT–L1
called
The
PRIME+ABORT–L1,
is based on Abort Cause #7.
Abort Cause #7 provides us with a way to monitor
evictions from the L1 cache in a way that is precise and
presents us with, effectively, an immediate hardware
callback in the form of a transactional abort. This allows
us to build an attack in the PRIME+PROBE family, as the
key component of PRIME+PROBE involves detecting
cacheline evictions. This attack, like all attacks in the
PRIME+PROBE family, does not depend in any way on
shared memory; but unlike other attacks, it will also not
depend on timers.
Like other PRIME+PROBE variants, our attack re-
quires a one-time setup phase where we determine an
eviction set for the cache set we wish to target; but
like early PRIME+PROBE attacks [35, 34], we ﬁnd this
task trivial because the entire L1 cache index lies within
the page offset (as explained earlier). Unlike other
PRIME+PROBE variants, for PRIME+ABORT this is the
sole component of the setup phase; we do not need to
ﬁnd a timing threshold, as we do not rely on timing.
The main part of PRIME+ABORT–L1 involves the
same “prime” phase as a typical PRIME+PROBE attack,
except that it opens a TSX transaction ﬁrst. Once the
“prime” phase is completed, the attack simply waits for
an abort (with the proper abort status code). Upon receiv-
ing an abort, the attacker can conclude that some other
program has accessed an address in the target cache set.
This is similar to the information gleaned by ordinary
PRIME+PROBE.
The reason this works is that, since we will hold an en-
tire cache set in the write set of our transaction, any ac-
USENIX Association
26th USENIX Security Symposium    57
cess to a different cache line in that set by another process
will necessarily evict one of our cachelines and cause our
transaction to abort due to Cause #7. This gives us an
immediate hardware callback, obviating the need for any
“measurement” step as in traditional cache attacks. This
is why we call our method PRIME+ABORT—the abort
replaces the “probe” step of traditional PRIME+PROBE.
3.3 PRIME+ABORT–L3
PRIME+ABORT–L1 is fast and powerful, but because it
targets the (core-private) L1 cache, it can only spy on
threads which share its core; and since it must execute
simultaneously with its victim, this means it and its vic-
tim must be in separate hyperthreads on the same core.
In this section we present PRIME+ABORT–L3, an attack
which overcomes these restrictions by targeting the L3
cache. The development of PRIME+ABORT–L3 from
PRIME+ABORT–L1 mirrors the development of L3-
targeting PRIME+PROBE [29, 21, 25] from L1-targeting
PRIME+PROBE [35, 34], except
that we use TSX.
PRIME+ABORT–L3 retains all of the TSX-provided ad-
vantages of PRIME+ABORT–L1, while also (like L3
PRIME+PROBE) working across cores, easily detecting
accesses to either instructions or data, and even working
across virtual machines.
PRIME+ABORT–L3 uses Abort Cause #8 to moni-
tor evictions from the L3 cache. The only meaningful
change this entails to the active portion of the attack is
performing reads rather than writes during the “prime”
phase, in order to hold the primed cachelines in the read
set of the transaction rather than the write set. For the
pre-attack portion, PRIME+ABORT–L3, like other L3
PRIME+PROBE attacks, requires a much more sophis-
ticated setup phase in which it determines eviction sets
for the L3 cache. This is described in detail in the next
section.
3.4 Finding eviction sets
The goal of the pre-attack phase for PRIME+ABORT is to
determine an eviction set for a speciﬁed target address.
For PRIME+ABORT–L1, this is straightforward, as de-
scribed in Section 2.2.2. However, for PRIME+ABORT–
L3, we must deal with both physical indexing and cache
slicing in order to ﬁnd L3 eviction sets. Like [29] and
[21], we use large (2 MB) pages in this process as a con-
venience. With large pages, it becomes trivial to choose
virtual addresses that have the same physical set index
(i.e. agree in bits 6 to N, for some processor-dependent
N, perhaps 15), again as explained in Section 2.2.2. We
will refer to addresses which agree in physical set in-
dex (and in line offset, i.e. bits 0 to 5) as set-aligned ad-
dresses.
Algorithm 1: Dynamically generating a prototype
eviction set for each cache slice, as implemented
in [42]
Input: a set of potentially conﬂicting cachelines lines, all
set-aligned
Output: a set of prototype eviction sets, one eviction set for each
cache slice; that is, a “prototype group”
group ← {};
workingSet ← {};
while lines is not empty do
repeat forever :
line ← random member of lines;
remove line from lines;
if workingSet evicts line then // Algorithm 2 or 3
c ← line;
break;
end
add line to workingSet;
end
foreach member in workingSet do
remove member from workingSet;
if workingSet evicts c then
add member back to lines;
add member back to workingSet;
// Algorithm 2 or 3
else
end
end
end
foreach line in lines do
if workingSet evicts line then // Algorithm 2 or 3
remove line from lines;
end
add workingSet to group;
workingSet ← {};
end
return group;
We generate eviction sets dynamically using the algo-
rithm from Mastik [42] (inspired by that in [29]), which
is shown as Algorithm 1. However, for the subroutine
where Mastik uses timing methods to evaluate potential
eviction sets (Algorithm 2), we use TSX methods instead
(Algorithm 3).
Algorithm 3, a subroutine of Algorithm 1, demon-
strates how Intel TSX is used to determine whether a can-
didate eviction set can be expected to consistently evict
a given target cacheline.
If “priming” the eviction set
(accessing all its lines) inside a transaction followed by
accessing the target cacheline consistently results in an
immediate abort, we can conclude that a transaction can-
not hold both the eviction set and the target cacheline in
its read set at once, which means that together they con-
tain at least (associativity + 1, or 17 in our case) lines
which map to the same cache slice and cache set.
Conceptually, the algorithm for dynamically generat-
ing an eviction set for any given address has two phases:
ﬁrst, creating a “prototype group”, and second, special-
izing it to form an eviction set for the desired target ad-
58    26th USENIX Security Symposium
USENIX Association
PRIME+PROBE
Algorithm 2:
(timing-based)
method for determining whether an eviction set
evicts a given cacheline, as implemented in [42]
Input: a candidate eviction set es and a cacheline line
Output: true if es can be expected to consistently evict line
times ← {};
repeat 16 times :
access line;
repeat 20 times :
foreach member in es do
access member;
end
end
timed access to line;
times ← times + {elapsed time};
end
if median of times > predetermined threshold then return true;
else return false;
Algorithm 3: PRIME+ABORT (TSX-based) method
for determining whether an eviction set evicts a given
cacheline
Input: a candidate eviction set es and a cacheline line
Output: true if es can be expected to consistently evict line
aborts ← 0;
commits ← 0;
while aborts = 16 then return true;
else return false;
dress. The algorithms shown (Algorithms 1, 2, and 3) to-
gether constitute the ﬁrst phase of this larger algorithm.
In this ﬁrst phase, we use only set-aligned addresses, not-
ing that all such addresses, after being mapped to an L3
cache slice, necessarily map to the same cache set inside
that slice. This phase creates one eviction set for each
cache slice, targeting the cache set inside that slice with
the given set index. We call these “prototype” eviction
sets, and we call the resulting group of one “prototype”
eviction set per cache slice a “prototype group”.
Once we have a prototype group generated by Algo-
rithm 1, we can obtain an eviction set for any cache set
in any cache slice by simply adjusting the set index of
each address in one of the prototype eviction sets. Not
knowing the speciﬁc cache-slice-selection hash function,
it will be necessary to iterate over all prototype eviction
sets (one per slice) in order to ﬁnd the one which collides
If we do not
with the target on the same cache slice.
know the (physical) set index of our target, we can also
iterate through all possible set indices (with each pro-
totype eviction set) to ﬁnd the appropriate eviction set,
again following the procedure from Liu et al. [29].
4 Results
4.1 Characteristics of the Intel
Skylake Architecture
Our test machine has an Intel Skylake i7-6600U pro-
cessor, which has two physical cores and four virtual
cores. It is widely reported (e.g., in all of [16, 22, 25,
29, 32, 44]) that Intel processors have one cache slice per
physical core, based on experiments conducted on Sandy
Bridge, Ivy Bridge, and Haswell processors. However,
our testing on the Skylake dual-core i7-6600U leads us
to believe that it has four cache slices, contrary to pre-
vious trends which would predict it has only two. We
validate this claim by using Algorithm 1 to produce four
distinct eviction sets for large-page-aligned addresses.
Then we test our four distinct eviction sets on many ad-
ditional large-page-aligned addresses not used in Algo-
rithm 1. We ﬁnd that each large-page-aligned address
conﬂicts with exactly one of the four eviction sets (by
Algorithm 3), and further, that the conﬂicts are spread
relatively evenly over the four sets. This convinces us
that each of our four eviction sets represents set index 0
on a different cache slice, and thus that there are indeed
four cache slices in the i7-6600U.
Having determined the number of cache slices, we can
now calculate the number of low-order bits in an address
that must be ﬁxed to create groups of set-aligned ad-
dresses. For our i7-6600U, this is 16. Henceforth we can
use set-aligned addresses instead of large-page-aligned
addresses, which is an efﬁciency gain.
4.2 Dynamically Generating Eviction Sets
In the remainder of
the Results section we com-
pare PRIME+ABORT–L3 to L3 PRIME+PROBE as im-
plemented in [42]. We begin by comparing the
PRIME+ABORT and PRIME+PROBE versions of Algo-
rithm 1 for dynamically generating prototype eviction
sets.
Table 4 compares the runtimes of the PRIME+ABORT
and PRIME+PROBE versions of Algorithm 1.
The
PRIME+ABORT-based method is over 5× faster than the
PRIME+PROBE-based method in the median case, over
15× faster in the best case, and over 40% faster in the
worst case.
Next, we compare the “coverage” of prototype groups
(sets of four prototype eviction sets) derived and tested
USENIX Association
26th USENIX Security Symposium    59
Table 4: Runtimes of PRIME+ABORT- and
PRIME+PROBE-based versions of Algorithm 1
to generate a “prototype group” of eviction sets
(data based on 1000 runs of each version of Al-
gorithm 1)
PRIME+ABORT
4.5 ms
10.1 ms
15.0 ms
21.3 ms
64.7 ms
PRIME+PROBE
68.3 ms
76.6 ms
79.3 ms
82.0 ms
91.0 ms
Min
1Q
Median
3Q
Max
with the two methods. We derive 10 prototype groups
with each version of Algorithm 1; then, for each pro-
totype group, we use either timing-based or TSX-based
methods to test 1000 additional set-aligned addresses not
used for Algorithm 1 (a total of 10,000 additional set-
aligned addresses for PRIME+ABORT and 10,000 for
PRIME+PROBE). The testing procedure is akin to a sin-
gle iteration of the outer loop in Algorithm 2 or 3 re-
spectively. Using this procedure, each of the 10,000 set-
aligned addresses is tested 10,000 times against each of
the four prototype eviction sets in the prototype group.
This produces four “detection rates” for each set-aligned
address (one per prototype eviction set). We assume that
the highest of these four detection rates corresponds to
the prototype eviction set from the same cache slice as
the tested address, and we call this detection rate the
“max detection rate” for the set-aligned address. Both
PRIME+ABORT and PRIME+PROBE methods result in
“max detection rates” which are consistently indistin-
guishable from 100%. However, we note that out of
the 100 million trials in total, 13 times we observed the
PRIME+PROBE-based method fail to detect the access
(resulting in a “max detection rate” of 99.99% in 13
cases), whereas with the PRIME+ABORT-based method,
all 100 million trials were detected, for perfect max de-
tection rates of 100.0%. This result is due to the struc-
tural nature of transactional conﬂicts—it is impossible
for a transaction with a read set of size (1 +associativity)
to ever successfully commit; it must always abort.
Since each address maps to exactly one cache slice,
and ideally each eviction set contains lines from only
one cache slice, we expect that any given set-aligned
address conﬂicts with only one out of the four proto-
type eviction sets in a prototype group. That is, we ex-
pect that out of the four detection rates computed for
each line (one per prototype eviction set), one will be
very high (the “max detection rate”), and the other three
will be very low. Figure 2 shows the “second-highest
detection rate” for each line—that is, the maximum of
the remaining three detection rates for that line, which
is a measure of false positives. For any given detec-
tion rate on the x-axis, the ﬁgure shows what percent-
age of the 10,000 set-aligned addresses had a false-
positive detection rate at or above that level. Whenever
the “second-highest detection rate” is greater than zero,
it indicates that the line appeared to be detected by a pro-
totype eviction set meant for an entirely different cache
slice (i.e. a false positive detection).
In Figure 2, we
see that with the PRIME+PROBE-based method, around
22% of lines have “second-highest detection rates” over
5%, around 18% of lines have “second-highest detec-
Figure 2: “Double coverage” of prototype groups generated by PRIME+ABORT- and PRIME+PROBE-based versions
of Algorithm 1. With PRIME+PROBE, some tested cachelines are reliably detected by more than one prototype eviction
set. In contrast, with PRIME+ABORT each tested cacheline is reliably detected by only one prototype eviction set.
60    26th USENIX Security Symposium
USENIX Association
0%20%40%60%80%100%DetectionRate0%50%100%%oflineshavingasecondhighestdetectionrateatleastthathighPrime+AbortPrime+Probetion rates” over 10%, and around 7.5% of lines even
have “second-highest detection rates” of 100%, mean-
ing that more than one of the “prototype eviction sets”
each detected that line in 100% of the 10,000 trials. In
contrast, with the PRIME+ABORT-based method, none
of the 10,000 lines tested had “second-highest detection
rates” over 1%. PRIME+ABORT produces very few false
positives and cleanly monitors exactly one cache set in
exactly one cache slice.
4.3 Detecting Memory Accesses
Figures 3, 4, and 5 show the success of PRIME+ABORT
and two variants of PRIME+PROBE in detecting the
memory accesses of an artiﬁcial victim thread running
on a different physical core from the attacker. The vic-
tim thread repeatedly accesses a single memory loca-
tion for the duration of the experiment—in the “treat-
ment” condition, it accesses the target (monitored) lo-