Step-by-step instruction address checking: The instruction checks are easy
but highly speciﬁc. The analysis should therefore been done for each NIC model
and each ﬁrmware version.
The ﬁrst heuristic checks the program counter against code bounds. The
recorded model deﬁnes some areas where code is expected to be located, and
code execution outside these areas by the CPU is indicative of an attack. This
veriﬁcation is more complex to implement than the next one because it was not
possible to ﬁnd a unique code area on this speciﬁc card model and ﬁrmware
version combination. Thus, multiple checks must be done because there are one
main area and several sub-areas. An incomplete model (i.e, one which does not
cover the whole ranges of operations for the analysed ﬁrmware) may lead to false
positives and false negatives.
Step-by-step instruction comparison: The second heuristic compares the
content of the memory area pointed to by the program counter (which is the
 1 10 100 1000 10000 100000 1e+06 1e+07 1e+080x00x20000countaddressR/W/X memory mappingEXT WCPU XCPU RCPU WRCBTXringRXringTXMBUFRXMBUFscratchpadcpustackaddress of the next instruction to be executed) and compares it to the recorded
golden model. A mismatch between the two indicates that the code has been
overwritten and that an attack is ongoing (since we assume that the code is not
self-modifying). In this case, the monitor halts the embedded CPU.
Implementation of the shadow stack Maintaining a shadow stack on the
host is complex because we need to identify function CALLs and RETs. Unfortu-
nately, the ﬁrmware runs on a MIPS architecture, and there are no such instruc-
tions in MIPS assembly language.
On MIPS architecture with 32 internal general purpose registers, r29 is usu-
ally used as a stack pointer and r31 to hold a return value while r0 is always
zero. Other registers are used for general operations.
MIPS CPU only have jump and branch instructions. For instance, BEQ is
branch on equal, JAL is jump and link (jump to immediate address and store
return address in r31), and JR r is jump register (jump to address stored in
register r).
Fortunately, the ﬁrmware that we are monitoring is pretty simple :
– function calls are done through the JAL instructions,
– there are no function pointers. JAL are always performed on absolute values,
– returns from functions are done through JR 31.
In theory, locating function CALLs and RETs is not diﬃcult. However, we have
to manage interrupts, which can be triggered in the network adapters asyn-
chronously. Some of them can be predicted (by looking at the MIPS CPU status
registers), but it is diﬃcult to predict the exact CPU cycle when the interrupt
will be triggered. Interrupts cause unexpected changes in the control ﬂow of the
network adapter and can cancel instructions (because of the MIPS delay slot).
Therefore, we need to take interrupts into account to implement our shadow
stack.
In the ﬁrmware we are looking at, there is only one interrupt handler starting
at a ﬁxed address (interrupt vector), and return from the handler is done through
JR r27. As a result, identifying interrupts is possible : we need to detect unex-
pected jumps to the interrupt vector and check that the program will go back
using JR r27. However, interrupts sometimes cause errors on the shadow stack:
the MIPS delay slot is ignored on interrupt, so we need to take that into account.
Indeed, if an interrupt is taken when a CALL instruction (or a RET) instruction
is in the delay slot, the CPU will indeed perform as if running this instruction
(causing a modiﬁcation of the shadow stack) when in fact this instruction is
ignored (as if replaced by a NOP in the CPU pipeline). As a consequence, each
time our framework detects an interrupt, we check whether the last instruction
that was supposed to be run was a CALL or a RET instruction. If it is the case,
that means that our shadow stack is incorrect and we have to correct it.
6 Experimental results
6.1 Eﬀectiveness of the detection
Needless to say that the kinds of attacks we are trying to detect are extremely
speciﬁc. Therefore, it would not make sense to check the eﬀectiveness of our tool
against, e.g. the DARPA evaluation dataset.
Also, our intrusion detection system basically consists in ﬁnding evidences
of code injection and control ﬂow redirects in the memory of the network card
using simple heuristics, so our detector cannot actually be tuned. Therefore,
using ROC curves (receiver operating characteristic curves) to test it would
not be relevant either [16] (plotting the true-positive rate of detection against
the corresponding false-positive rate of error implies a degree of freedom in the
settings of the detector).
One way to evaluate the eﬀectiveness of our intrusion detection system ex-
perimentally may consist in testing it against a set of various attacks (e.g., stack
overﬂow, return-oriented programming) and/or vulnerabilities of the same type.
However, implementing variants of arbitrary code execution attacks is time-
consuming, especially on exotic and undocumented architectures. Moreover, as
our detection approach only relies on the measurable eﬀects of the attacks on the
monitored system (not on attack signatures), merely applying code obfuscation
techniques do not seem to be relevant.
As a summary, we can essentially speculate on the detection eﬀectiveness
from a theoretical point of view.
6.2 Experimental Settings
As a consequence, we chose a very simple experimental setting.
For our experiment, we used a Dell D530 laptop using a 5755M Broadcom
NetXtreme adapter running a ﬁrmware vulnerable to the diﬀerent kinds of at-
tacks we presented in [8]. The laptop is running Debian Squeeze with our NAVIS
detection framework.
In one setting of the experiment, the target PC is directly connected to
the internet through the adapter we are monitoring and we manually simulate
standard user actions (FTP downloads, web browsing etc.). At the same time,
we allowed automatic processes to access resources on the web several days in
a row. In a second setting we directly connect the adapter to a PC emulating
an attacker sending attack packets that will try to exploit vulnerabilities in the
adapter. Three diﬀerent types of payload are used for the experiments.
In our ﬁrst experiment, none of the packets associated with regular traﬃc
did trigger any alert from NAVIS. On the contrary, all three diﬀerent kind of
attacks using ASF traﬃc were successfully detected by NAVIS.
6.3 Performance
We were expecting that our detection framework would drastically decrease the
performances of the machine we are monitoring. Indeed, we run the MIPS CPU
in step-by-step mode, at each MIPS cycle we do various tests (bounds, call
stack...), so each MIPS cycle leads to a lot of host CPU cycles. As a result,
NAVIS uses 100% CPU for one core even when the adapter is not processing
traﬃc. Indeed, when the MIPS processor is idle (because there is no ASF traﬃc
at all) it loops on an waiting procedure which means the host CPU still analyses
the various steps.
The network adapter speed itself is not impaired by the detection technique.
Even after activating NAVIS, we still achieve gigabit speed. This comes from
the fact that the ﬁrmware we are monitoring only processes special kind of UDP
packets (ASF packets) so the fact that this ﬁrmware is running in step by step
mode does not have any kind of impact on regular traﬃc.
The testbed is composed of the Dell D530 laptop (IP 192.0.2.1), a gigabit
switch and a second machine with a gigabit ethernet card (IP 192.0.2.2). The
test is run using pktgen (a packet generator included in the Linux kernel), while
dstat (a statistics collecting tool) is run on the receiving machine (the D530
one) to monitor CPU usage along with network statistics (mainly packet rate).
The test is done in two parts, ﬁrst on a standard installation (Fig. 4a) then with
(Fig. 4b) NAVIS running. Generated traﬃc is sent and received on UDP port 9
and packet size is 256 and the source machine sends traﬃc at rates from 1000
to 250 000 packets per second.
(a) NAVIS stopped
(b) NAVIS running
Fig. 4: CPU usage and packet rate (UDP port 9)
It’s pretty clear that NAVIS does not really prevent the network to reach full
speed on this test, as both packet rate curves have the same shape when send
rate augments and they both reach 250 000 packets per second. At low packet
rates, the 100% CPU usage is mostly the active loop of the debugger. When
packet rate rises, software interrupts from system calls are starting to become
signiﬁcant. The packet generator isn’t able to generate more traﬃc but it seems
likely that NAVIS could handle more packets before slowing down the traﬃc.
-2 0 2 4 6 8 10 12 14 0 50000 100000 150000 200000 250000%ppsCPUInterrupt#recv-20 0 20 40 60 80 100 120 0 50000 100000 150000 200000 250000%ppsPerformances might not be that good with ﬁrmware needing to process every
network packets. A good test for that case is to send UDP packets on port 623
(ASF/RMCP port) to the D530. In that case the PHY will detect the packet needs
to be handled by the ﬁrmware, which needs to check if the datagram is ASF
traﬃc or not before relaying it to the host.
So we run the same test, this time sending datagrams to UDP port 623.
(a) NAVIS stopped
(b) NAVIS running
Fig. 5: CPU usage and packet rate (UDP port 623)
Even when NAVIS is not running (Fig. 5a), we have issues sending datagrams
to the network card. Processing done by the ﬁrmware to check if the packet
is ASF or not is slowing down the whole packet processing, meaning the PHY
queues are full and ethernet frames are dropped when packet rate is above 11000.
When running the same tests with NAVIS, we can achieve speeds around
24Mb/s, but packet rate drops dramatically and barely exceeds 250 packets per
second (Fig. 5b). The speed issues aren’t related to all the context switches from
the system calls (since interrupts are mostly at 0%) but are due to the time
spent in processing the various memory accesses to the card.
It might be worth implementing the veriﬁcation part of NAVIS inside the
kernel and optimize all the PCI accesses in order to improve the packet processing
rate of the whole installation.
7 Limitations of the approach
The solution is speciﬁc to the adapter. The kind of live veriﬁcations that we
are able to carry out will depend on the architecture of the controller we are
considering.
This approach allows to detect any unexpected change in the control ﬂow
when a return value is modiﬁed on the stack, but data on the stack, heap and
scratchpad can still be modiﬁed by the attacker. One could imagine that an
attacker would be able to craft an attack only by being able to modify data
areas. These kind of attacks would not be detected by NAVIS.
-1 0 1 2 3 4 5 6 7 8 9 0 2000 4000 6000 8000 10000 12000%ppsCPUInterrupt#recv-20 0 20 40 60 80 100 120 0 50 100 150 200 250 300%ppsMoreover, the fact that the ﬁrmware we are considering is quite simple makes
it easier for us to verify its integrity. For instance, the following characteristics
simplify the analysis:
– the ﬁrmware is not using any kind of indirection for CALL operations (there
are no function pointers). Function adresses are hardcoded and can be easily
identiﬁed by disassembling CALL instructions;
– no paging mechanism is involved. Addresses in the ﬁrmware are physical
addresses and therefore our framework does not need to perform any kind
of address translation;
– the ﬁrmware is running on the embedded CPU as a single thread.
8 Conclusion and Future work
In this paper we studied the diﬃcult problem of ﬁrmware integrity attestation
or veriﬁcation. We looked at the problem from a theoretical point of view and
showed that depending on the interface of the device we are considering and
the nature of the ﬁrmware, monitoring was possible. In our setting, the host
operating system acts as an external veriﬁer running a framework called NAVIS
that constantly analyses the behaviour of the embedded ﬁrmware and stops the
device whenever an unexpected behaviour is detected. We developed a proof of
concept for a popular model of network adapter and showed that our proof-
of-concept was indeed eﬃcient against attacks (even 0-day ones). The proof-
of-concept is highly speciﬁc to the adapter but shows that ﬁrmware integrity
veriﬁcation can be achieved in practice.
Future work on this topic involves studying alternate detection mechanisms
such as on the ﬂy virtualisation and control by an hypervisor of embedded
ﬁrmware.
References
1. Mart´ın Abadi, Mihai Budiu, ´Ulfar Erlingsson, and Jay Ligatti. Control-ﬂow in-
tegrity principles, implementations, and applications. ACM Transactions on In-
formation and System Security, 13, November 2009.
2. Yuriy Bulygin and David Samyde. Chipset based approach to detect virtualization
malware. BlackHat, 2008.
3. Claude Castelluccia, Aur´elien Francillon, Daniele Perito, and Claudio Soriente. On
the diﬃculty of software-based attestation of embedded devices. In Proceedings
of 16th ACM Conference on Computer and Communications Security, November
2009.
4. Hoi Chang and Mikhail J. Atallah. Protecting software code by guards. In ACM
Workshop on Security and Privacy in Digital Rights Management, 2001. ACM
Workshop on Security and Privacy in Digital Rights Management, Philadelphia,
Pennsylvania, November 2001.
5. Stephen Checkoway, Lucas Davi, Alexandra Dmitrienko, Ahmad-Reza Sadeghi,
Hovav Shacham, and Marcel Winandy. Return-oriented programming without
returns. In Proceedings of the 17th ACM conference on Computer and communi-
cations security, CCS ’10, pages 559–572. ACM, 2010.
6. K. Chen. Reversing and exploiting an apple ﬁrmware update. BlackHat, 2009.
7. Guillaume Delugr´e. Closer to metal : Reverse ingineering the broadcom netex-
treme’s ﬁrmware. Hack.lu, 2010.
8. Lo¨ıc Duﬂot and Yves-Alexis Perez. Can you still trust your network card?
CanSecWest, 2010.
9. Lo¨ıc Duﬂot, Yves-Alexis Perez, and Benjamin Morin. Run-time ﬁrmware integrity
veriﬁcation : what if you can’t trust your network card? CanSecWest, 2011.
10. `Ulfar Erlingsson, Mart`ın Abadi, Michael Vrable, Mihai Budiu, and George C. Nec-
ula. Xﬁ: Software guards for system address spaces. In Symposium on Operating
System Design and Implementation (OSDI), volume 4637, pages 75–88, 2006.
11. Aur´elien Francillon. Attacking an Protecting Constrained Embedded Systems from
Control Flow Attacks. PhD thesis, Institut Polytechnique de Grenoble, 2009.
12. Aur´elien Francillon, Claude Castelluccia, Daniele Perito, and Claudio Soriente.
Comments on “refutation of on the diﬃculty of software based attestation of em-
bedded devices”. -, 2010.
13. Mike Frantzen and Mike Shuey. Stackghost: Hardware facilitated stack protection.
In Proceedings of the 10th conference on USENIX Security Symposium - Volume
10, SSYM’01, pages 5–5. USENIX Association, 2001.
14. Trusted Computing Group. The trusted platform module.
15. Yanlin Li, Jonathan M. McCune, and Adrian Perrig. SBAP: Software-Based At-
testation for Peripherals. In Proceedings of the 3rd International Conference on
Trust and Trustworthy Computing (Trust 2010), June 2010.
16. R. A. Maxion and R. R. Roberts. Proper use of roc curves in intrusion/anomaly
detection. Technical report, School of Computing Science, University of Newcastle
upon Tyne, 2004.
17. Adrian Perrig and Leendert Van Doorn. Refutation of “on the diﬃculty of software
based attestation of embedded devices”. -, 2010.
18. Nick L. Petroni, Jr. Timothy, Fraser Jesus, Molina William, and A. Arbaugh.
Copilot - a coprocessor-based kernel runtime integrity monitor. In Proceedings of
the 13th USENIX Security Symposium, pages 179–194, 2004.
19. Joanna Rutkowska. Remotely attacking network cards (or why do we need vt-d
and txt), 2010.
20. Joanna Rutkowska and Rafal Wojtczuk. Preventing and detecting xen hypervisor
subversions. BlackHat, 2008.
21. Fernand L. Sang, Eric Lacombe, Vincent Nicomette, and Yves Deswarte. Exploit-
ing an I/OMMU vulnerability. In MALWARE ’10: 5th International Conference
on Malicious and Unwanted Software, pages 7–14, 2010.
22. Hovav Shacham, Matthew Page, Ben Pfaﬀ, Eu-Jin Goh, Nagendra Modadugu, and
Dan Boneh. On the eﬀectiveness of address-space randomization. In Proceedings
of the 11th ACM conference on Computer and communications security, CCS ’04,
pages 298–307. ACM, 2004.
23. Saravanan Sinnadurai, Qin Zhao, and Weng fai Wong. Transparent runtime shadow
stack: Protection against malicious return address modiﬁcations.
24. Alexander Tereshkin and Rafal Wojtczuk. Introducing ring -3 rootkits. BlackHat,
2009.
25. Arrigo Triulzi. Taking NIC backdoors to the next level. CanSecWest, 2010.
26. Jiang Wang, Angelos Stavrou, and Anup Ghosh. Hypercheck: a hardware-assisted
integrity monitor. In Proceedings of the 13th international conference on Recent
advances in intrusion detection, RAID’10, pages 158–177. Springer-Verlag, 2010.
27. Ralf-Philipp Weinmann. All Your Baseband Are Belong To Us. CCC, 2010.