title:"I am uncomfortable sharing what I can't see": Privacy Concerns
of the Visually Impaired with Camera Based Assistive Applications
author:Taslima Akter and
Bryan Dosono and
Tousif Ahmed and
Apu Kapadia and
Bryan C. Semaan
“I am uncomfortable sharing what I can’t see”: 
Privacy Concerns of the Visually Impaired with 
Camera Based Assistive Applications
Taslima Akter, Indiana University Bloomington; Bryan Dosono, Syracuse University; 
Tousif Ahmed and Apu Kapadia, Indiana University Bloomington; Bryan Semaan, 
Syracuse University
https://www.usenix.org/conference/usenixsecurity20/presentation/akter
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.“I am uncomfortable sharing what I can’t see”: Privacy Concerns of the
Visually Impaired with Camera Based Assistive Applications
Taslima Akter
Indiana University Bloomington
Bryan Dosono
Syracuse University
Tousif Ahmed
Indiana University Bloomington
Apu Kapadia
Indiana University Bloomington
Bryan Semaan
Syracuse University
Abstract
The emergence of camera-based assistive technologies has
empowered people with visual impairments (VIP) to obtain
independence in their daily lives. Popular services feature
volunteers who answer questions about photos or videos (e.g.,
to identify a medical prescription). However, people with
VIPs can (inadvertently) reveal sensitive information to these
volunteers. To better understand the privacy concerns regard-
ing the disclosure of background objects to different types of
human assistants (friends, family, and others), we conducted
an online survey with 155 visually impaired participants. In
general, our participants had varying concerns depending on
the type of assistants and the kind of information. We found
that our participants were more concerned about the privacy
of bystanders than their own when capturing people in im-
ages. We also found that participants were concerned about
self-presentation and were more comfortable sharing embar-
rassing information with family than with their friends. Our
ﬁndings suggest directions for future work in the development
of human-assisted question-answering systems. Speciﬁcally,
we discuss how humanizing these systems can give people a
greater sense of personal security.
1 Introduction
Sighted people can often take for granted the ease with which
they can engage in routine activities, such as driving to the
grocery store, paying bills, taking medications, using mobile
devices and computers, and more. For people with impair-
ments, these activities can be a challenge. In this paper, we
focus on people with visual impairments (VIPs), i.e., peo-
ple who live with impairments ranging from complete blind-
ness to an inability to read a book when wearing corrective
lenses [60]. Today, it is estimated that four percent of the
global population lives with visual impairments (about 285
million people) [73], and depending on the severity of their
visual impairments, engaging in routine and mundane activi-
ties may require the assistance of others. For example, people
with VIPs often rely on friends and family to help them ac-
complish daily practices, such as traveling to the market and
paying bills, such that they can maintain the practices of daily
life [6, 38].
However, there may be cases where people with VIPs do
not have access to people who provide this kind of support,
or they may have intermittent access to people who can assist
them. As a means of addressing this issue, technological
advances are leading to the rapid development of assistive
technologies for people with visual impairments. With the rise
of mobile cameras and advances in computer vision, ‘visually
aware’ assistive applications are now becoming a reality for
people with visual impairments. These camera-based assistive
technologies simplify a wide range of everyday tasks such
as navigating social spaces,1 identifying objects or color,2
recognizing familiar faces or facial expressions,3 and reading
documents.4 In contrast to automated systems, which use com-
puter vision and machine learning,3 human-powered systems
leverage human assistants (volunteers, professional agents,
or friends and family members) to answer questions about
photos (or live video) taken by people with VIPs [1, 2, 16].5
Since automated systems are not yet reliable [9] — e.g., the
user may want to know the number of calories in a can of
food, but the system might simply identify the food as a “tuna
can,” or the system may not be able to assess whether a pair
of shoes matches one’s clothing — people with VIPs still ﬁnd
human-assisted systems more accurate and trustworthy [9].
Indeed, more than 100,000 users with VIPs are currently using
human-powered assistive systems such as ‘Be My Eyes’ [2]
and ‘Aira’ [1].
Despite their advantages, human-powered, camera-based
assistive applications can pose serious privacy risks. For ex-
ample, people with VIPs may inadvertently share sensitive
1Orcam: www.orcam.com/en/
2Color teller: www.brytech.com/colorteller
3Seeing AI: www.microsoft.com/en-us/seeing-ai
4KNFB Reader: https://knfbreader.com
5A typical use case is for a visually impaired person to compose a photo
or video and deliberately share it with a human assistant.
USENIX Association
29th USENIX Security Symposium    1929
information with a human assistant both intentionally (e.g.,
asking to read a credit card number) or unintentionally (e.g., a
credit card may be present in the background). Such sharing
can sometimes have serious consequences, e.g., sharing a
credit card may lead to identity theft. Although these risks
have been acknowledged in prior work [8, 18, 21, 34], they
have focused mostly on identifying the kinds of sensitive con-
tent shared with volunteers. The privacy concerns of people
with VIPs in the context of revealing sensitive information
with different kinds of human agents, which can vary with
context, is not yet well understood. A deeper understanding
of these concerns can provide insight into how AI and human
assistance can be leveraged to provide both trustworthy and
privacy aware visual assistance to people with VIPs.
In this paper, we report on the privacy concerns of peo-
ple with VIPs when using human-powered, camera-based
assistive systems. We considered the privacy risks of ob-
jects both in the foreground (the objects people ask questions
about) and background (other objects present in the image
not directly associated with the question), and explored pri-
vacy concerns when sharing photos or video with three types
of human assistants: friends, family members, and crowd-
workers (professional agents, mechanical turk workers, and
volunteers). We also explored the concerns of people with
visual impairments in three common contexts: in the ofﬁce,
in a restaurant, and at home. Speciﬁcally, we focus on the
following research questions:
R1: What are the privacy concerns of people with visual
impairments in the context of background objects that are
inadvertently captured and included in photos sent to human
assistants?
R2: While using such technologies, how do their privacy
concerns vary for different classes of background objects and
the type of human assistants (friends, family, volunteers or
crowd-workers)?
To answer these research questions, we conducted an on-
line survey with 155 visually impaired participants examin-
ing three everyday scenarios in the context of three different
types of human assistants. Participants were assigned to a
between-subjects survey instrument based on the type of assis-
tant (friend, family member, and crowd-worker). The scenar-
ios were studied within subjects (home, ofﬁce, and restaurant).
We conduct a quantitative analysis of their privacy preferences
as well as a qualitative analysis of the reasons participants
provided for their preferences.
Our participants reported signiﬁcant privacy and security
concerns for information captured in the background. Their
information-disclosing behaviors depended on the nature of
the background objects present in the image as well as the
types of human assistants. For example, participants were
more concerned about maintaining a good impression with
their friends compared to family. Participants, however, also
reported being more concerned about sharing personally iden-
tiﬁable information with crowd workers compared to their
friends or family members. Interestingly, participants were
also more concerned about the privacy of other people com-
pared to their own. Our ﬁndings have important implications
for the design of camera based assistive devices. Despite their
potential for ‘good’, such technologies can also violate the
security and privacy of the very people being assisted. We
discuss how such systems need to be ‘humanized’ so as to
assist, and not harm, their users.
2 Related Work
In this section, we present related work on camera-based
assistive solutions and their privacy issues.
2.1 Camera-based assistive applications
We focus on two primary design paradigms for camera-
based assistive technologies: automated assistive systems
and human-powered assistive systems.
2.1.1 Automated assistive systems
Various kinds of camera-based assistive technologies have
been developed to assist people with VIPs in their daily tasks.
Such technologies include object identiﬁers6 [45] and barcode
readers,7 [52] text readers,4 color readers,2 money readers,8
and crowd-sourced visual question-answering systems [1, 2]
for multiple purposes such as identifying objects, reading
prescriptions, and answering subjective questions. Camera-
based assistive solutions also assist people with VIPs in their
social interactions by recognizing faces and facial attributes
of people in the vicinity [25, 43, 50]. Since the hands-free
nature of wearable cameras offers improved accessibility [75],
researchers have also developed various camera-assisted pro-
totypes [23, 51, 62] for people with VIPs on wearable and
augmented reality devices. Although people with VIPs are
quickly adopting automated systems, most applications work
best with high-quality photos and ample lighting, rightly an-
gled compositions, and fully captured subjects [45]. Cap-
turing such photos, however, is particularly challenging for
people with VIPs. Therefore, several camera-based applica-
tions have been proposed to assist people with VIPs in taking
photos. To capture a high-quality picture, these applications
automatically guide users to improve the focus, lighting, or
composition [5, 44, 72].
Unfortunately, automated systems have their limitations;
systems sometimes provide inaccurate answers and may lack
detailed descriptions when expected [9]. For example, the
user may want to know the temperature on a thermostat
6Aipoly: www.aipoly.com
7i.d. mate: www.envisionamerica.com
8LookTell: www.looktel.com
1930    29th USENIX Security Symposium
USENIX Association
whereas the automated application may just respond “thermo-
stat.” Because of the limited capabilities of automatic systems,
users ﬁnd communicating with a human more reliable [12].
2.1.2 Human-powered visual question answering sys-
tems
To address issues with automated assistive technologies,
crowd based systems are becoming more popular among peo-
ple with VIPs. Visual Question Answering (VQA) seeks to
automatically answer visual questions from a given image
and the user’s question using computer vision and natural
language processing [11, 32]. Currently, most models are
trained on images taken by sighted people that are not repre-
sentative of those taken in assistive systems for people with
VIPs. Hence, no such VQA systems have been developed
yet to assist people with VIPs. As an alternative, people with
VIPs get nearly real-time visual assistance with their visual
questions with the help of a human assistant [1, 2, 16]. Such
applications allow visually impaired users to send pictures or
make video calls for getting answers to their visual questions
from a sighted crowd-worker or volunteer. Currently, among
the two popular human-sourced services, Be My Eyes [2]
connects blind persons with untrained volunteers through a
free service. In contrast, Aira [1] connects visually impaired
users with paid, trained professional agents.
To provide greater support to visually impaired users,
VizWiz Social [20] expands the initial VizWiz application by
including friend-sourced answers (using Twitter, Facebook, or
email from their known contacts) along with crowd-sourced
answers (Mechanical Turk, IQ Engines). Friendsourcing re-
moves the ﬁnancial cost of the crowd-sourced service and
helps to improve the quality and trustworthiness of the an-
swers received [59]. Friends and family may be able to answer
questions better because they know the question asker. How-
ever, ‘friendsourcing’ has a social cost as the users might feel
they appear less independent or may want to avoid feeling
like a burden on their friends and family. To address this
problem, Brady et al. [18] introduce the idea of social micro-
volunteering, a type of intermediate friendsourcing in which
a volunteer who participates ask his networks of friends to an-
swer a visual question on behalf of a visually impaired person.
It also provides faster responses than friendsourcing. In our
work, we consider three different types of human assistants
(friends, family members, and volunteers or crowd-workers)
and focus on better understanding the preferences of people
with VIPs while seeking help from various types of human
assistants.
2.2 Privacy concerns
We now discuss related work on privacy in the context of
assistive technologies in general, camera based assistive tech-
nologies, and human assistant based assistive technologies.
2.2.1 Privacy concerns with assistive technologies
As people with VIPs continue to leverage assistive technolo-
gies in their routine lives, this leads to the question of what pri-
vacy issues emerge and how we, as designers, can best design
for the privacy of this particularly vulnerable population. Sev-
eral studies report that people with VIPs have concerns about
aural and visual eavesdropping when using screen readers and
screen magniﬁers [6, 13, 46]. They often use headphones and
screen occlusion software to protect themselves from other
people eavesdropping on their devices [8, 13]. Prior work
also discussed how simply possessing assistive devices may
invite privacy-invading questions (e.g., “how did you lose
your sight?”) or unwanted attention [68]. Ahmed et al. ex-
plored the privacy and security concerns of people with VIPs
that are not solved by current technology and suggested new
directions for improving camera-based assistive systems [6].
Other works also investigated the physical safety concerns
of individuals with VIPs [8, 21]. Researchers also focused
on the privacy challenges people with VIPs face while using
digital ﬁnance technologies such as ATMs [24, 69].
2.2.2 Privacy issues with cameras
More speciﬁc to video based assistive technology, camera-
based assistive devices can collect rich visual information
and create additional privacy risks for both the device user
and bystanders. Such risks might have a much higher impact
on visually impaired people because they cannot review the
content of photos before sharing [6] or they might be less
aware of when such situations might occur [8, 21]. Mali-
cious parties can use malware to record photos or video of
private spaces and blackmail the device owner [71]. Com-
puter vision-based technologies for assistive purposes may
also impose serious privacy risks for the bystanders while rec-
ognizing faces for people with VIPs. Face recognition may
lead to identity theft [4] and issues of bias related to race [26]
and age [10]. Ahmed et al.
investigated the concerns of
bystanders while information about them is shared through
camera-based assistive technologies to a visually impaired
person [7]. We address the concerns people with VIPs have
while sharing information about themselves and bystanders
through camera-based assistive technologies. We are also
interested in learning how concerned people with VIPs are
about the privacy of others (i.e., the bystanders).
Privacy issues with human-assisted solutions.
In real
time crowd-sourced assistive systems, users are limited in
the amount of time to review the content they are sharing
and might capture and share sensitive information mistak-
enly [15,53]. Such incidents potentially put the user at risk of
identity theft, blackmail, and other information-based attacks.
Lasecki et al. have demonstrated the risks of trusting crowd
workers with sensitive information [54]. They showed that
USENIX Association
29th USENIX Security Symposium    1931
workers can be engaged in potentially malicious tasks for per-
sonal gain, such as copying a credit card number from another
task. Branham et al. described an incident when a visually
impaired user was threatened by the volunteer who asked for
her location [21]. Several works reported situations when a
visually impaired user inadvertently shared images containing
private information with a crowd-worker, sometimes without
understanding either the risk or that sensitive information is
being captured [8, 33, 34].
Our work addresses the latter risk when the visually im-
paired person unintentionally captures sensitive information
and shares it with a human assistant. The images must con-
tain the foreground objects for the human assistant to answer
the question and are deliberately chosen while understanding
some of the privacy risks. However, background objects (or
people) can pose a much greater privacy risk since they were
not intended to be shared with the volunteer. Moreover, our
work provides insight into what should be shared (or not) as
background objects depending on the human-sourced assis-
tive technologies with the goal of better understanding their
privacy concerns and, therefore, providing design recommen-
dations to develop assistive devices for avoiding inadvertent