title:A Formal Framework for Program Anomaly Detection
author:Xiaokui Shu and
Danfeng (Daphne) Yao and
Barbara G. Ryder
A Formal Framework for Program
Anomaly Detection
Xiaokui Shu(B), Danfeng (Daphne) Yao, and Barbara G. Ryder
Department of Computer Science, Virginia Tech, Blacksburg, VA 24060, USA
{subx,danfeng,ryder}@cs.vt.edu
Abstract. Program anomaly detection analyzes normal program
behaviors and discovers aberrant executions caused by attacks, miscon-
ﬁgurations, program bugs, and unusual usage patterns. The merit of
program anomaly detection is its independence from attack signatures,
which enables proactive defense against new and unknown attacks. In
this paper, we formalize the general program anomaly detection prob-
lem and point out two of its key properties. We present a uniﬁed frame-
work to present any program anomaly detection method in terms of its
detection capability. We prove the theoretical accuracy limit for pro-
gram anomaly detection with an abstract detection machine. We show
how existing solutions are positioned in our framework and illustrate the
gap between state-of-the-art methods and the theoretical accuracy limit.
We also point out some potential modeling features for future program
anomaly detection evolution.
Keywords: Program anomaly detection · Uniﬁed framework ·
Automata theory · Detection accuracy · Theoretical accuracy limit
1 Introduction
Security problems in program executions – caused by program bugs, inappro-
priate program logic, or insecure system designs – were ﬁrst recognized by the
Air Force, the Advanced Research Projects Agency (ARPA), and IBM in early
1970s. In 1972, Anderson pointed out the threat of subverting or exploiting a
piece of software by a malicious user [2]. This threat was developed to a multi-
tude of real-world attacks in the late 1980s and 1990s including buﬀer overﬂow,
return-into-libc, denial of service (DoS), etc.
Defenses have been proposed against categories of attacks from the perspec-
tives of hardware (e.g., NX bit), operating system (e.g., address space layout
randomization), compiler (e.g., canaries) and software architecture (e.g., sand-
box) [56]. Although these defenses create barriers to exploiting a program, they
can be circumvented. For example, new program attacks are developed leveraging
unattended/uninspected execution elements, such as return-oriented program-
ming [51], jump-oriented programming [5,10], and non-control data attacks [11].
Denning proposed an intrusion detection expert system (IDES) in 1987 [15],
which learns how a system should behave (normal proﬁles) instead of how it
c(cid:2) Springer International Publishing Switzerland 2015
H. Bos et al. (Eds.): RAID 2015, LNCS 9404, pp. 270–292, 2015.
DOI: 10.1007/978-3-319-26362-5 13
A Formal Framework for Program Anomaly Detection
271
should not (e.g., an attack). In this paper, we formalize one area of intru-
sion detection, namely program anomaly detection or host-based intrusion detec-
tion [52]. The area focuses on intrusion detection in the context of program
executions. It was pioneered by Forrest et al., whose work was inspired by the
analogy between intrusion detection for programs and the immune mechanism
in biology [22].
Two major program anomaly detection approaches have been established
and advanced: n-gram-based dynamic normal program behavior modeling and
automaton-based normal program behavior analysis. The former was pioneered
by Forrest [23], and the latter was formally introduced by Sekar et al. [50] and
Wagner and Dean [59]. Other notable approaches include probabilistic modeling
methods pioneered by Lee and Stolfo [40] and dynamically built state machine
ﬁrst proposed by Kosoresow and Hofmeyr [36]. Later work explored more ﬁne-
grained models [4,28,30] and combined static and dynamic analysis [24].
Evaluating the detection capability of program anomaly detection methods
is always challenging [59]. Individual attacks do not cover all anomalous cases
that a program anomaly detection system detects. Control-ﬂow based metrics,
such as average branching factor, are developed for evaluating speciﬁc groups of
program anomaly detection methods [59]. However, none of the existing metrics
is general for evaluating an arbitrary program anomaly detection system.
Several surveys summarized program anomaly detection methods from dif-
ferent perspectives and pointed out relations among several methods. Forrest
et al. summarized existing methods from the perspective of system call moni-
toring [21]. Feng et al. formalized automaton based methods in [19]. Chandola
et al. described program anomaly detection as a sequence analysis problem [8].
Chandola et al. provided a survey of machine learning approaches in [9]. The
connection between an n-gram method and its automaton representation is ﬁrst
stated by Wagner [60]. Sharif et al. proved that any system call sequence based
method can be simulated by a control-ﬂow based method [52].
However, several critical questions about program anomaly detection have
not been answered by existing studies and summaries.
1. How to formalize the detection capability of any detection method?
2. What is the theoretical accuracy limit of program anomaly detection?
3. How far are existing methods from the limit?
4. How can existing methods be improved towards the limit?
We answer all these questions in this paper. We unify any existing or future
program anomaly detection method through its detection capability in a formal
framework. We prove the theoretical accuracy limit of program anomaly detec-
tion methods and illustrate it in our framework. Instead of presenting every pro-
posed method in the literature, we select and explain existing milestone detection
methods that indicate the evolution of program anomaly detection. Our analy-
sis helps understand the most critical steps in the evolution and points out the
unsolved challenges and research problems.
272
X. Shu et al.
The contributions of this paper are summarized as follows.
1. We formalize the general security model for program anomaly detection. We
prove that the detection capability of a method is determined by the expres-
siveness of its corresponding language (Sect. 2).
2. We point out two independent properties of program anomaly detection: pre-
cision and the scope of the norm. We explain the relation between precision
and deterministic/probabilistic detection methods (Sect. 2).
3. We present the theoretical accuracy limit of program anomaly detection with
an abstract machine ˜M. We prove that ˜M can characterize traces as precise
as the executing program (Sect. 3).
4. We develop a hierarchal framework unifying any program anomaly detec-
tion method according to its detection capability. We mark the positions of
existing methods in our framework and point out the gap between the state-
of-the-art methods and the theoretical accuracy limit (Sect. 5).
5. We explain the evolution of program anomaly detection solutions. We envision
future program anomaly detection systems with features such as full path
sensitivity and higher-order relation description (Sect. 6).
6. We compare program anomaly detection with control-ﬂow enforcement. We
point our their similarities in techniques/results and explain their diﬀerent
perspectives approaching program/process security (Sect. 7).
2 Formal Deﬁnitions for Program Anomaly Detection
We formally deﬁne the problem of program anomaly detection and present the
security model for detection systems. Then we discuss the two independent prop-
erties of a program anomaly detection method: the detection capability and the
scope of the norm. Last, we give an overview of our uniﬁed framework.
2.1 Security Model
Considering both transactional (terminating after a transaction/computation)
and continuous (constantly running) program executions, we deﬁne a precise
program trace based on an autonomous portion of a program execution, which
is a consistent and relatively independent execution segment that can be isolated
from the remaining execution, e.g., an routine, an event handling procedure (for
event-driven programs), a complete execution of a program, etc.
Deﬁnition 1. A precise program trace T is the sequence of all instructions exe-
cuted in an autonomous execution portion of a program.
T is usually recorded as the sequence of all executed instruction addresses 1
and instruction arguments. In real-world executions, addresses of basic blocks
can be used to record T without loss of generality since instructions within a
basic block are executed in a sequence.
We formalize the problem of program anomaly detection in Deﬁnition 2.
1 Instruction addresses are unique identiﬁers of speciﬁc instructions.
A Formal Framework for Program Anomaly Detection
273
Deﬁnition 2. Program anomaly detection is a decision problem whether a pre-
cise program trace T is accepted by a language L. L presents the set of all normal
precise program traces in either a deterministic means (L = {T | T is normal})
or a probabilistic means (L = {T | P (T) > η}).
In Deﬁnition 2, η is a probabilistic threshold for selecting normal traces from
arbitrary traces that consist of instruction addresses. Either parametric and non-
parametric probabilistic methods can construct probabilistic detection models.
In reality, no program anomaly detection system uses T to describe pro-
gram executions due to the signiﬁcant tracing overhead. Instead, a practical
program trace is commonly used in real-world systems.
Deﬁnition 3. A practical program trace ¨T is a subsequence of a precise program
trace T. The subsequence is formed based on alphabet Σ, a selected/traced subset
of all instructions, e.g., system calls.
We list three categories of commonly used practical traces in real-world pro-
gram anomaly detection systems. The traces result in black-box, gray-box, and
white-box detection approaches with an increasing level of modeling granularity.
– Black-box level traces: only the communications between the process and the
operating system kernel, i.e., system calls, are monitored. This level of practi-
cal traces has the smallest size of Σ among the three. It is the coarsest trace
level while obtaining the trace incurs the smallest tracing overhead.
– White-box level traces: all (or a part of) kernel-space and user-space activities
of a process are monitored. An extremely precise white-box level trace ¨T is
exactly a precise trace T where all instructions are monitored. However, real-
world white-box level traces usually deﬁne Σ as the set of function calls to
expose the call stack activity.
– Gray-box level traces: a limited white-box level without the complete static
program analysis information [24], e.g., all control-ﬂow graphs. Σ of a gray-
box level trace only contains symbols (function calls, system calls, etc.) that
appear in dynamic traces.
We describe the general security model of a real-world program anomaly
detection system in Deﬁnition 4. The security model derives from Deﬁnition 2
but measures program executions using ¨T instead of T.
Deﬁnition 4. A real-world program anomaly detection system Λ deﬁnes a lan-
guage LΛ (a deterministic or probabilistic set of normal practical program traces)
and establishes an attestation procedure GΛ to test whether a practical program
trace ¨T is accepted by LΛ.
A program anomaly detection system Λ usually consist of two phases: training
and detection. Training is the procedure forming LΛ and building GΛ from known
normal traces {¨T | ¨T is normal}. Detection is the runtime procedure testing
incoming traces against LΛ using GΛ. Traces that cannot be accepted by LΛ in
the detection phase are logged or aggregated for alarm generation.
274
X. Shu et al.
2.2 Detection Capability
The detection capability of a program anomaly detection method Λ is its ability
to detect attacks or anomalous program behaviors. Detection capability of a
detection system Λ is characterized by the precision of Λ. We deﬁne precision of Λ
as the ability of Λ to distinguish diﬀerent precise program traces in Deﬁnition 5.
This concept is independent of whether the scope of the norm is deterministically
or probabilistically established (discussed in Sect. 2.3).
Deﬁnition 5. Given a program anomaly detection method Λ and any practical
program trace ¨T that Λ accepts, the precision of Λ is the average number of
precise program traces T that share an identical subsequence ¨T.
Our deﬁnition of program anomaly detection system precision is a gener-
alization of average branching factor (using regular grammar to approximate
the description of precise program traces) [59] and average reachability measure
(using context-free grammar to approximate the description of precise program
traces) [28]. The generation is achieved through the using of T, the most precise
description of a program execution. average in Deﬁnition 5 can be replaced by
other aggregation function for customized evaluation.
We formalize the relation between the expressive power of LΛ (deﬁned by
detection method Λ) and the detection capability of Λ in Theorem 1.
Theorem 1. The detection capability of a program anomaly detection method
Λ is determined by the expressive power of the language LΛ corresponding to Λ.
Proof. Consider two detection methods Λ1 (LΛ1) and Λ2 (LΛ2) where Λ1 is more
precise than Λ2, one can always ﬁnd two precise program traces T1/T2, so that
T1/T2 are expressed by LΛ1 in two diﬀerent practical traces ¨T1Λ1/¨T2Λ1, but
they can only be expressed by LΛ2 as an identical ¨TΛ2. Because the deﬁnition
of the norm is subjective to the need of a detection system, in theory, one can
set T1/T2 to be normal/anomalous, respectively. In summary, Λ1 with a more
expressive LΛ1 can detect the attack T2 via practical trace ¨T2Λ1, but Λ2 cannot.
Theorem 1 enables the comparison between detection capabilities of diﬀerent
detection systems through their corresponding languages. It lays the foundation
of our uniﬁed framework. The more expressive LΛ describes a normal precise
trace T through a practical trace ¨T, the less likely an attacker can construct an
attack trace T(cid:3) mimicking T without being detected by Λ.
2.3 Scope of the Norm
Not all anomaly detection systems agree on whether a speciﬁc program behavior
(a precise program trace T) is normal or not. Even given the set of all practical
program traces Σ∗ with respect to a speciﬁc alphabet Σ (e.g., all system calls),
two detection systems Λ1 and Λ2 may disagree on whether a speciﬁc ¨T ∈ Σ∗ is
normal or not. Σ∗ denotes the set of all possible strings/traces over Σ.
A Formal Framework for Program Anomaly Detection
275
Deﬁnition 6. The scope of the norm SΛ (of a program anomaly detection sys-
tem Λ) is the selection of practical traces to be accepted by LΛ.
While LΛ is the set of all normal practical traces, SΛ emphasizes on the
selection process to build LΛ, but not the expressive power (detection capability)
of LΛ. SΛ does not inﬂuence the detection capability of Λ.
For instance, VPStatic [19] (denoted as Λs) utilizes a pushdown automaton
(PDA) to describe practical program traces. Therefore, its precision is deter-
mined by the expressiveness of context-free languages2. SΛs is all legal con-
trol ﬂows speciﬁed in the binary of the program. VtPath [18] (denoted as Λv)
is another PDA approach, but SΛv is deﬁned based on dynamic traces. Since
dynamic traces commonly forms a subset of all feasible execution paths, there
exists ¨T not in the training set of Λ2. Thus, ¨T will be recognized as anomalous
by Λ2 yet normal by Λ1. Because the precisions of Λ1 and Λ2 are the same, Λ2
can be made to detect ¨T as normal by including ¨T in its training set (changing
SΛv).
There are two types of scopes of the norm:
– Deterministic scope of the norm is achieved through a deterministic lan-
guage LΛ = {¨T | ¨T is normal}. Program anomaly detection systems based on
ﬁnite state automata (FSA), PDA, etc. belong to this category.
– Probabilistic scope of the norm is achieved through a stochastic language
LΛ = {¨T | P (¨T) > η}. Diﬀerent probability threshold η results in diﬀerent
SΛ and diﬀerent LΛ/Λ. Program anomaly detection systems based on hidden
Markov model, one-class SVM, etc. belong to this category.
2.4 Overview of Our Uniﬁed Framework
We develop a uniﬁed framework presenting any program anomaly detection
method Λ. Our framework uniﬁes Λ by the expressive power of LΛ.