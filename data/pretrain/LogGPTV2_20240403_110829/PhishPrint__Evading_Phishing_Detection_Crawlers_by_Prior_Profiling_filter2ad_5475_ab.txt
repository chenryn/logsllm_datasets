browsers used (or pretending to be used) by the crawlers. We
categorize these into 3 different anomaly vectors and discuss
them here.
JS Execution Anomaly Vector. The ﬁrst anomaly we
discovered was the inability of a few crawlers to execute
some simple JavaScript code. For this, we checked whether
or not a crawler is capable of executing a test function that
is passed to Window.setInterval() method. This is very
similar to the onload event-based cloaking vector used
in [37] (see Appendix C for details). However, it is to be
noted that many crawlers are good at executing such simple
JS code and hence this serves as a baseline against which can
measure the efﬁcacy of more sophisticated cloaking vectors.
Real Browser Anomaly Vector. We designed our proﬁling
website to ship out ﬁngerprints (speciﬁcally: Font, Canvas
and WebGL ﬁngerprints; code in Appendix D) to the database
without requiring any user interaction. We veriﬁed that this
website is cross-platform compatible by manually testing it
with most used web browsers such as Chrome 79, Firefox 71,
Safari 11, Edge 44 and IE 11 on Windows (Vista, 7 and 10),
macOS, Linux (Ubuntu), iOS and Android platforms. During
this process, as and when required, polyﬁll Javascript libraries
were used to maintain compatibility with older web browsers
(such as IE) that do not fully support some APIs such as
Canvas. Thus, our thorough testing ensured that the most
commonly used web browsers will all ship us ﬁngerprints
as soon as they visit our website. However, we observed that
many crawlers were unable to ship out their ﬁngerprints as the
ﬁngerprinting code fails to run in their “browsers” although
many of them do successfully execute the simpler JS code
mentioned previously. This is highly likely due to the failure
of crawler vendors in setting up robust JS-execution environ-
ments to support all advanced web APIs such as Canvas [20]
and WebGL [21]. We refer to this as a Real Browser anomaly.
To our knowledge, no other previous research has
attempted to do such analysis against security crawlers3.
Crawler Artifacts Anomaly Vector. We discovered a few
anomalies when manually analyzing the HTTP requests head-
ers and navigator objects we collected from the crawlers.
For some crawlers, we saw that the navigator.useragent
value does not match the User-Agent header. Similarly,
navigator.platform does not always match the platform
indicated in the User-Agent header. For example, it was
common to see cases where the User-Agent header indicates
a Windows platform, but the navigator.platform indicates
a Linux platform. Similarly, we saw a number of cases where
the User-Agent bears indicators of automation such as curl,
phantomjs, headless etc. Further, we also found discrep-
ancies in the values of navigator.webdriver. This is a
Boolean ﬁeld that indicates whether a web browser is being
driven by browser automation software such as Selenium.
While for most web browsers the default value of this ﬁeld in
3The “Real Browser" vector described in [37] is synonymous with the JS
Execution Anomaly we discussed.
3778    30th USENIX Security Symposium
USENIX Association
a non-automated browser is set to false, in Chrome it is set to
undefined. In this regard, we noticed that in some crawlers,
navigator.webdriver was being set to false even though
the User-Agent indicated a Chrome browser. This is a clear
anomaly and shows that the property had been tampered with.
We note that previous works have used similar techniques
in a more elaborate fashion to defeat privacy-protecting
browsers and extensions [46] and ad network block-
ages [45]. [26] also found several such artifacts by studying
in-the-wild bot detection scripts. However, in our study, we
measure these anomalies as weaknesses of security crawlers
and apply them for cloaking.
3.1.2 Network Data
For this part of the analysis, we focused on the IP addresses
used by the crawlers for initiating web requests to PhishPrint.
We collected these addresses during our deployment period
and crafted IP Blocklist Vectors. Thus, we were able to mine
a blocklist cloaking vector from PhishPrint’s data. Note that
real-world attackers tend to use massive blocklists made of
IP addresses for building phishing sites [38]. Hence, it is
very important to measure how well crawlers are doing (both
speciﬁcally as well as cumulatively) in defending against this
vector. The performance of crawlers against in-the-wild IP
blocklists has been studied before [37]. However, the highly
scalable nature of PhishPrint now allows us to directly collect
a large amount of network infrastructure data and then analyze
and compare this across an extensive set of security crawlers.
In addition, we also mapped the collected IP addresses to
their associated countries in order to measure the geolocation
variety of the network infrastructure setup by the crawlers.
AS Blocklist Vector. Upon analyzing the Autonomous
System (AS) names of the collected IP addresses, we also
discovered that many crawlers are housing their crawlers
in IP address spaces that can be mapped to web or cloud
hosting companies (such as Amazon, DigitalOcean) or the
organizations related to the crawlers themselves (such as
Google, Microsoft, BitDefender, Cisco). We were able to
make a list of 66 such AS names. We refer to this as an AS
Blocklist. As it is unlikely for a potential victim to be visiting
an attacker’s website from such IP addresses, an attacker can
easily use as AS Blocklist to evade crawlers.
AS Blocklist is a hybrid between anomaly and blocklist
cloaking vectors. Similar to anomaly vectors, it is based on an
anomaly and is relatively static as it is unlikely for offending
crawlers to frequently change their network infrastructure
between different cloud networks. On the other hand, similar
to other blocklist vectors, it takes extensive data collection
efforts to construct lists like this as there a myriad number
of web hosting entities. Further, if the blocklist is poorly
constructed and includes AS names of victim IP spaces,
then there could be speciﬁcity issues as with other blocklist
vectors. We empirically demonstrate that this is not the case
with AS Blocklist with a large-scale user study later (§4.2).
Prior works have utilized AS level features to escape
malware sandboxes [51]. In this study, we applied similar
techniques to study security crawler evasion.
3.1.3 Advanced Browser Fingerprints
Recent privacy-oriented studies such as [17, 22] have
shown Canvas, WebGL and Font list (obtained via JS)
ﬁngerprinting to be among the most discriminatory identiﬁers.
As a further testament to this, these browser ﬁngerprints have
also been used to develop authentication schemes [13, 27].
At the same time, privacy researchers have also shown
that such ﬁngerprints are not easy to defend against and
require elaborate measures [24, 31, 41, 50]. Given this, there
is a high potential for developing an effective cloaking
vector if crawlers do not take adequate measures to defend
against these ﬁngerprinting techniques. Hence, we wanted
to analyze these ﬁngerprints after we collected them from
crawlers. Snippets of the ﬁngerprinting code we use are listed
in Appendix D. For both Canvas and WebGL ﬁngerprints
(both ﬁrst introduced in [34] and later used in [22]), the code
draws a hidden image on the webpage and a cryptographic
hash of that image is produced to be used as a ﬁngerprint. For
font ﬁngerprinting, a simple trick ﬁrst proposed in [36] and
later used in [22] is used to detect the list of 1043 fonts that
are installed in the client using JavaScript. A cryptographic
hash of the font list serves as the font ﬁngerprint for the client.
Our analysis showed that the entire crawler ecosystem
exhibits very little dynamism across these three ﬁngerprints.
To capitalize on this, we propose a blocklist cloaking vector.
For this, we follow the approaches of prior studies [22, 29]
and use a tuple of the three ﬁngerprints:  (or ) in order to effectively combine their
individual ﬁngerprinting capabilities. In the rest of this paper,
we refer to this compound ﬁngerprint as “ﬁngerprint” for
brevity. Our proposed  Fingerprint Blocklist Vec-
tor for this simply stores all s seen from crawlers in
the past to aid future evasion. As this is a blocklist vector, we
will perform multiple measurements to verify its speciﬁcity.
3.2 Proﬁling Analysis Results
In this section, along with an overview of the proﬁling
data we collected during the 10-week study, we will present
measurements indicating the performance of the crawlers
against the six cloaking vectors we introduced previously. All
these results are presented in Table 1 where the 1st column
lists all the crawlers we studied.
VT Sharing. During analysis and investigation, we found
that 8 crawlers have shared their token URLs with VirusTo-
tal [11] (VT). This sharing has taken place at varying degrees.
Malwares and Quttera have shared more than 99.5% of their
URLs with VT, while Bitdefender and PhishTank have shared
about 10 and 30% of their URLs with VT. VT hosts more than
80 crawlers that begin scanning the uploaded URLs almost
immediately. As a result, all such VT-shared URLs need to be
considered separately. For this, we created a “virtual crawler"
named “VT Ecosystem" and consider all VT-shared URLs
USENIX Association
30th USENIX Security Symposium    3779
exclusively here. We treat this virtual crawler as equivalent to
other crawlers in the rest of this paper. Since Malwares and
Quttera shared most of their URLs with VT, no meaningful
speciﬁc analysis can be made for these crawlers. Hence, we
avoid their individual rows in the table and just show them
as part of the VT ecosystem. It is to be noted that due to the
large number (80) of crawlers hosted on VT (including 18
of our 23 crawlers), the VT ecosystem can be considered as
a cumulative representative of the entire crawler ecosystem.
The 2nd column shows the number of URLs submitted
(discussed in §3.1), the number of URLs scanned by the
crawlers and the number of URLs shared with VT by each
crawler. Overall, in the 10 week period, we submitted about
18,532 token URLs (with distinct domain names) to all the 23
crawlers. In terms of crawl back rates, most of the crawlers
did well with many of them visiting more than 90% of the
submitted URLs. A notable exception is Norton which visited
only 53 of the submitted URLs. The total number of URLs
submitted to VT by other crawlers was 803. The 3rd column
describes the number of URLs remaining to be analyzed after
we excluded the VT URLs. It also lists the number of sessions
established for the analyzed URLs indicating the total number
of visits made. While crawlers from PhishTank and Scumware
establish 50 to 100 sessions for each analyzed URL, some oth-
ers such as GSB, SmartScreen and Forcepoint visit each URL
only once or twice. Overall, as many as 348,516 sessions were
established for scanning 18,532 distinct URLs we submitted.
The 4th column shows the median of time deltas between
the ﬁrst crawl time and the URL submission time for URLs
submitted to each crawler. Some crawlers such as Fortinet
and SmartScreen have a slow average response time whereas
many others including GSB, Outlook take only a few seconds.
CVD Scores. In order to compare the performance of
all the crawlers across the six cloaking vectors, we need an
intuitive performance metric. For this, we devised a simple
metric called Cloaking Vector Defense Score (CVD score).
The CVD score can be computed for any given crawler (say,
W ) and a cloaking vector (say, V ). Assume that we reported x
URLs to W and it scanned y of them (ignoring the VT-shared
URLs) during our entire study. We conduct an a posteriori
analysis of all the y URLs to determine how many of them
were visited at least once by a crawler that does not exhibit
the weakness associated with V . If such a number is z, we
report the CVD score of the pair (W,V ) as z
y ×100.
Doing this a posteriori analysis for an anomaly vector is
straightforward as we simply need to determine if at least
one of the many requests a URL might receive does not
exhibit the anomaly being considered. However, in the case
of blocklist vectors, we will need the respective blocklists
in order to make this determination for a given request. We
build this blocklist dynamically using all the historic data
collected from the crawler prior to the current request. For
example, in order to determine if a request r at time t can be
blocked by a blocklist vector V , we use all prior requests to
the crawler before t to build a blocklist and see if the current
request can be blocked by such as blocklist. If it does, we
determine this to be a weak request and do not consider it.
From the above, we can see that the CVD score, by
deﬁnition, reﬂects the chance (as a %) of a given crawler
to successfully defend against a given cloaking vector.
Columns 5 to 10 show the CVD scores of the crawlers
over the six vectors we described previously. We use red,
yellow and green colors in the table to show the bad (66) scores respectively.
Anomalies. Column 5 shows that the CVD scores for JS
Execution Anomaly vector are good all across the spectrum
of crawlers. This demonstrates a positive evolution from the
situation in [37] which showed that only 1 of the 5 studied
crawlers had good score. More such evolutionary changes
in crawlers have been described in Appendix C. On the other
hand, many crawlers seem to be failing in handling the Real
Browser Anomaly vector that we developed (Column 6). The
only notable exceptions to this are APWG and the VT ecosys-
tem. We noticed that GSB, for example, completely fails to
support the WebGL API in many of its crawlers. Some other
notable failures are Outlook, Avira and Forcepoint that did not
visit even a single submitted URL with a Real Browser. The
overall combined CVD score of all crawlers in this respect is
thus only 35.2 which shows a lot of scope for improvement.
A positive result is that most vendors seem to have some
crawlers that do not carry Crawler Artifacts Anomalies
(Column 7). However, all crawlers from AlienVault and Avira
have an anomalous navigator.webdriver property which
was causing all their visits to be easily evadable.
IP-Blocklist. The CVD scores for IP-Blocklist vector
along with the number of distinct IP addresses of source
requests and the countries they are associated (# CCs) with is
in Column 8. We note that as many as 11 crawlers make their
visits from less than 20 distinct IP addresses even though
they visit hundreds of domains forming thousands of sessions
across time. Crawlers from AlienVault and OpenPhish visit
only from 1 or 2 IP addresses. A control experiment reported
that this situation persists even when doing repeated reports
from diverse sources (§3.2.2). On the other hand, URLs sub-
mitted to some crawlers including GSB, Outlook, PhishTank
and APWG are scanned by a large number of distinct IP
addresses. For PhishTank, this number is as high as 4096 IP
addresses (spread over 51 countries) for the 579 URLs we
analyzed. Figure 2 charts the growth of the distinct number of
IP addresses we have seen across the days of our experiment.
The graphs shows a near-linear growth for APWG and GSB
indicating the greatest diversity in IP addresses. SmartScreen
shows an interesting IP infrastructure growth. The number
of IP addresses was 1 for the ﬁrst 50 days of the experiment
but has risen to 50 in the last 20 days. This indicates an
infrastructure change during the last 20 days which was
referred to during our vulnerability disclosure process as well.
One more interesting point to note is the number of countries
3780    30th USENIX Security Symposium
USENIX Association
1
Crawlers
AlienVault
APWG
Avira
Badware
Bitdefender
Dr.Web
ESET
Forcepoint
FortiGuard
Fortinet
GSB
SmartScreen
Norton
Notmining
OpenPhish
Outlook
PhishTank
Scumware
Sophos
Sucuri
ZeroCERT
VT Ecosystem
All
Best Score
2
# URLs
Submitted
/ Scanned
/ VT Shared
840 / 837 / 0
840 / 839 / 0
840 / 837 / 0
840 / 837 / 0
840 / 542 / 67
840 / 836 / 0
840 / 764 / 0
350 / 295 / 0
777 / 764 / 8
840 / 772 / 5
612 / 591 / 0
840 / 822 / 0
840 / 53 / 0
840 / 838 / 0
840 / 835 / 0
840 / 672 / 0
840 / 838 / 259
840 / 633 / 2
840 / 793 / 0
840 / 830 / 0
840 / 840 / 462
2483 / 2465 / -
18532 / 16730 / 803
-
3
# URLs
Analyzed
/ # Sessions
4
Reply
Time
h:m:s
Browser Anomalies
Network Data
Advanced BFPs
5
6
7
8
9
10
JSE-A
Score
RB-A
Score
CA-A
Score
# IPs
/ # CCs
IP-B