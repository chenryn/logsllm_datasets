all correspond to end-to-end paths,
in the network, deﬁne vec-
if link is an incoming
if link is an outgoing link for
is nonzero iff the path
is an internal node and the rows
,
.
such that
Any identiﬁable link sequence in the network can be repre-
sented by a vector
for some ; for such a
link sequence,
cannot cor-
respond to a link sequence with an endpoint at
. Thus, no iden-
tiﬁable link sequence may have an endpoint at an interior net-
work node. This means that the only identiﬁable link sequences
are loops and end-to-end paths.
; therefore,
Routing loops are rare in the Internet; thus, Theorem 1 says
that each path is a MILS and there are no others. This means that
there are no individual links or subpaths whose loss rates can be
exactly determined from end-to-end measurements. Next, we
will discuss some practical methods to get ﬁner level unbiased
inference on directed graphs, such as the Internet.
2) Practical Inference Methods for Directed Graphs: Con-
sidering the simple directed graph in Fig. 5, the problem of de-
termining link loss rates is similar to the problem of breaking a
deadlock: If any of the individual links can be somehow mea-
sured, then loss rates of all other links can be determined through
end-to-end measurements. Since link loss rates cannot be nega-
tive, for a path with zero loss rate, all the links on that path must
Fig. 7. Examples showing all the matrices in the ﬂowchart.
also have zero loss rates. This can break the deadlock and help
solve the link loss rate of other paths. We call this inference ap-
proach the good path algorithm. Note that this is a fact instead
of an extra assumption. Our PlanetLab experiments a as well as
[20], show that more than 50% of paths in the Internet have no
loss.
In addition, we can relax the deﬁnition of “good path” and
, which
allow a negligible loss rate of at most
is the threshold for “no loss” in [20]). Then, we again have a
tradeoff between accuracy and diagnosis granularity, as depicted
in our framework. Note that although the strict good path algo-
rithm cannot be applied to other metrics such as latency, such
bounded inference is generally applicable.
(e.g.,
As illustrated in the second stage of Fig. 6, we identify MILSs
in directed graphs in two steps. First, we ﬁnd all the good paths
in
and thus establish some good links. We remove these good
links and good paths from to get a submatrix
. Then, we
apply Algorithm 1 to
to ﬁnd all lossy MILSs and their loss
. For the good links that are in the middle of lossy
rates in
MILSs identiﬁed, we add them back so that MILSs are con-
secutive. In addition, we apply the following optimization pro-
cedures to get
quickly for the identiﬁability test (step 10 of
Algorithm 1).
than
to do
. Since
. By necessity,
contains a basis of
We remove all the good links from and get a smaller sub-
. We
matrix
decomposition and
can then use the small matrix
thus get
from
a reasonably large overlay network, this optimization approach
makes LEND very efﬁcient for online diagnosis. In Fig. 7, we
use a simple topology to show the matrices computed in the
whole process. The path from to
is a good path, and thus
links 2 and 6 are good links.
is usually quite small even for
1730
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 17, NO. 6, DECEMBER 2009
D. Dynamic Update for Topology and Link Property Changes
During monitoring, good links may become lossy and vice-
versa, routing paths between end-hosts may change, and hosts
may enter or exit the overlay network. These changes may result
, forcing us to recompute
in changes to the reduced matrix
the MILSs and their loss rates. We perform this recomputation
in two steps: We ﬁrst incrementally update the decomposition
of the
matrix, and then we compute the MILSs and their
properties using the algorithm described in Section IV-B.
and
We express changes to
in terms of four kinds of
primitive updates: adding a bad path, deleting a bad path, adding
a good path, and deleting a good path. Any more complicated
change can be expressed in terms of these four operations. For
example, if the routing tables changes so that some bad paths
are rerouted, we would delete the original bad paths from the
system and add the routes for the new good paths. When a bad
path is added or deleted, there may be one row that is added
to or removed from ; similarly, when a good path is added
or deleted, the set of links identiﬁed as good by the good path
algorithm may change, so that a few columns are added to or
removed from . To update a QR decomposition of
after
one column or row update costs time proportional to the size
of the matrix, or
time (see the discussion in [21,
rows or columns are affected
Section 4.3]), and since at most
by one of our primitive updates, the total cost of such updates
is at most
. This cost is much less expensive than
the initial QR factorization of
.
In Section VII-B4, we show that it takes only a few seconds to
complete an incremental update to
and reidentify the
MILSs. Given that end-to-end Internet paths tend to be stable
on the time scale of a day [22] and link loss rates remain oper-
ationally stable on the time scale of an hour [20], our algorithm
should sufﬁce for online updates and diagnosis.
, which costs
and
E. Combining With Statistical Diagnosis
As discussed before, the linear system is underconstrained,
and so there exist some unidentiﬁable links. With MILSs, we
attempt to discover the smallest path segments for which proper-
ties can be uniquely identiﬁed. However, there are various statis-
tical methods that produce estimates of properties at a ﬁner gran-
ularity, e.g., at the virtual link level (see Section II-A for deﬁni-
tion). Essentially, these methods use statistical assumptions to
resolve the likely behavior in the unmeasured space discussed
in Section III-A and therefore provide only possible estimates
as shown in Fig. 2 [5].
Because of this, our LEND approach and other statistical
methods can complement each other nicely. For example, we
can discover some links or link segments that are lossy by the
least-unbiased approach. If the user wants to make predictions
at a ﬁner level of granularity with potential degradation of ac-
curacy, we can further apply the statistical algorithms on the
lossy MILSs. In comparison with the traditional statistical to-
mography that has to consider the whole path, our scheme can
help signiﬁcantly reduce complexity without losing inference
accuracy by considering a subset of the links. Our MILSs are
vectors in
.
Thus, inference with MILSs is equivalent to inference with the
whole end-to-end paths.
, and the MILS set contains a basis of
Take the linear optimization and Bayesian inference using
Gibbs sampling introduced in [5], for example; these algorithms
Fig. 8.
IP spooﬁng example.
can be used without modiﬁcation on our MILS set rather than
on the original end-to-end paths. Section VI-C6 shows that
Gibbs sampling inference combined with our least-unbiased
approach improves its accuracy. In addition, the computational
complexity of Gibbs sampling inference based on the MILS
set is dramatically reduced because the input “paths” are much
shorter than the whole end-to-end paths.
V. DIAGNOSIS VALIDATION THROUGH IP SPOOFING
Internet diagnosis systems are difﬁcult to evaluate because
of the general lack of ground truth—it is very hard, if not
virtually impossible, to obtain the link level performance from
the ISPs. We will ﬁrst evaluate the system through simulations
in Section VI. Then, we test LEND on the real Internet in
Section VII. For validation on the real Internet, in addition
to the classical cross validation, we need a more powerful
approach. As shown in Section II, existing router-based diag-
nosis tools like Tulip are neither very accurate nor scalable
and, therefore, do not suit our needs. In this section, we pro-
pose an IP-spooﬁng-based mechanism for link-level diagnosis
validation.
Though IP spooﬁng is usually used by malicious hackers to
hide their identities, it also is a useful tool to cope with the rigid
routers. For example, IP spooﬁng is used to help measure ICMP
generation time in routers [23]. We use IP spooﬁng to obtain
a limited source routing, which helps validate the accuracy of
MILSs. With this technique, we can measure the properties of
new paths that we could not normally probe. These additional
measurements are then used to validate the inferred loss rates of
MILSs.
Fig. 8 shows an example of how to use IP spooﬁng to “create”
a new path. Each line in the ﬁgure can be a single link or a se-
quence of links. For simplicity, we just call it a link in this sec-
to node
tion. Assume router
. To create a new
is on the path from the node
, and the path from to
does not go via
path
with spoofed source IP as
sends an ICMP ECHO request packet to
. When the packet reaches router
will generate an ICMP ECHO reply packet and send it to
,
,
.
is the
. Since
. Assume
via router
Thus, we get a path from to
logarithm of the success rate of link as deﬁned before and
is the logarithm of the success rate of path
we have
, i.e.,
. Thus,
, we get a lower bound of
. For validation, we use the source routing ca-
pability we have created to measure some new paths and check
whether they are consistent with the MILSs and their inferred
loss rates obtained from normal non-IP-spoofed measurements.
For example, normal measurements on path
reveal that
there is a single lossy MILS on
, then the logarithm of
’s success rate should be bounded by
as discussed before.
See details in Section VII-B2, where the consistency checking
idea is also used in cross validation.
The principle of IP-spooﬁng-based source routing is simple.
However, many practical problems need to be addressed.
ZHAO et al.: TOWARDS UNBIASED END-TO-END NETWORK DIAGNOSIS
1731
(cid:129) First, most edge routers check outgoing packets and dis-
able IP spooﬁng from the internal networks. In addition,
all PlanetLab hosts are disabled from IP spooﬁng. How-
ever, we were able to get one host, our institution, exempted
from such ﬁltering.
(cid:129) Second, as with other router-based diagnosis approaches
[12], our scheme is subject to ICMP rate-limiting on
routers for measuring the loss rates. We ﬁlter those routers
with strict ICMP rate-limiting.
VI. EVALUATION WITH SIMULATION
In this section, we present our evaluation metrics, simulation
methodology, and simulation results.
A. Metrics
The metrics we have used to evaluate our algorithms include
the granularity of diagnosis, MILS loss rate estimation accuracy,
and the speed of setup and online diagnosis.
Of these metrics, the ﬁrst one, diagnosis granularity, is par-
ticularly important. For diagnosis, we focus on the lossy paths
and examine how many links we suspect could be the cause of
the network congestion/failures. We deﬁne the diagnosis gran-
ularity of a path as the average of the lengths of all the lossy
MILSs contained in the path. The diagnosis granularity of an
overlay network is deﬁned as the average diagnosis granularity
of all the lossy paths in the overlay. For example, suppose an
overlay network has only two lossy paths: one path has two
lossy MILSs of length 2 and 4 separately, and the other lossy
path consists of only one lossy MILS of length 3. Then, the di-
.
agnosis granularity for the overlay is
We measure lengths in terms of physical links, except when we
compare to other approaches for which the natural unit of length
is a virtual link.4
We call a MILS as lossy (or bad) if its loss rate exceeds 3%,
which is the threshold between “minor loss” and “perceivable
loss” (like “tolerable loss” and “serious loss”) as deﬁned in [20].
As we mentioned in Section VI-B, we call a path “good” if it has
less than 0.5% loss, which is the threshold for “no loss” in [20].
Because we allow “good” paths to have nonzero loss, the good
path algorithm introduces some error. The question is whether
this error will accumulate in a serious way when we compute the
loss rates for MILSs. If the error does not accumulate, we can
simply adjust the threshold of what we consider to be a “good”
path in order to trade higher accuracy for better granularity and
faster computations.
For each MILS, we evaluate the error of the inferred loss rate
compared to the real loss rate by analyzing both the absolute
, which is deﬁned in
and the error factor
error
[4] to be
(4)
and
and
where
are treated as no less than , and the error factor is the maximum
ratio, upward or downward, by which they differ. We use the
, which is consistent with the link loss
default value
rate distribution selected in simulation (see Section VI-B). If the
estimate is perfect, the error factor is one.
. Thus,
4As deﬁned before, a network is composed of virtual links after merging con-
secutive links without a branching point.
The LEND system operates in two stages: setup and moni-
paths to mon-
toring. In the ﬁrst phase, we select
itor, while in the second phase, we monitor these paths and use
our measurements to diagnose any congestion/failure locations
among all
paths in the system. The setup phase takes
only a few minutes even for a reasonably large overlay network