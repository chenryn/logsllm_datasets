### All Correspond to End-to-End Paths

In the network, vectors are defined for end-to-end paths. If a link is an incoming or outgoing link for a path, it is represented in the vector. The vector is nonzero if and only if the path includes that specific link. For internal nodes, the rows of the matrix correspond to these links. Any identifiable link sequence in the network can be represented by a vector for some set of paths. For such a link sequence, the vector cannot correspond to a sequence with an endpoint at an internal node. Therefore, the only identifiable link sequences are loops and end-to-end paths.

### Theorem 1: Identifiable Link Sequences

Routing loops are rare in the Internet. According to Theorem 1, each path is a Minimal Identifiable Link Sequence (MILS), and there are no others. This means that individual links or subpaths cannot have their loss rates exactly determined from end-to-end measurements. Next, we will discuss practical methods to achieve finer, unbiased inference on directed graphs, such as the Internet.

### Practical Inference Methods for Directed Graphs

Consider the simple directed graph in Figure 5. The problem of determining link loss rates is similar to breaking a deadlock. If any individual link can be measured, the loss rates of all other links can be determined through end-to-end measurements. Since link loss rates cannot be negative, for a path with zero loss rate, all the links on that path must also have zero loss rates. This breaks the deadlock and helps solve the link loss rates of other paths. We call this inference approach the "good path algorithm." Note that this is a fact rather than an extra assumption. Our PlanetLab experiments, as well as [20], show that more than 50% of paths in the Internet have no loss.

Additionally, we can relax the definition of a "good path" to allow a negligible loss rate of at most \(\epsilon\), which is the threshold for "no loss" in [20]. This relaxation introduces a tradeoff between accuracy and diagnosis granularity, as depicted in our framework. Although the strict good path algorithm cannot be applied to other metrics such as latency, bounded inference is generally applicable.

### Identifying MILSs in Directed Graphs

As illustrated in the second stage of Figure 6, we identify MILSs in directed graphs in two steps:
1. **Finding Good Paths**: First, we find all the good paths in the network and establish some good links. We remove these good links and good paths from the original matrix to get a submatrix.
2. **Applying Algorithm 1**: Then, we apply Algorithm 1 to the submatrix to find all lossy MILSs and their loss rates. For the good links that are in the middle of identified lossy MILSs, we add them back to ensure MILSs are consecutive. We also apply optimization procedures to quickly compute the identifiability test (step 10 of Algorithm 1).

Since the submatrix is usually quite small even for a reasonably large overlay network, this optimization approach makes LEND very efficient for online diagnosis. In Figure 7, we use a simple topology to show the matrices computed in the whole process. The path from \(A\) to \(B\) is a good path, and thus links 2 and 6 are good links.

### Dynamic Update for Topology and Link Property Changes

During monitoring, good links may become lossy and vice versa, routing paths between end-hosts may change, and hosts may enter or exit the overlay network. These changes may result in changes to the reduced matrix, forcing us to recompute the MILSs and their loss rates. We perform this recomputation in two steps:
1. **Incremental Update**: We first incrementally update the decomposition of the matrix.
2. **Recompute MILSs**: Then, we compute the MILSs and their properties using the algorithm described in Section IV-B.

We express changes to the matrix in terms of four kinds of primitive updates: adding a bad path, deleting a bad path, adding a good path, and deleting a good path. Any more complicated change can be expressed in terms of these four operations. For example, if the routing tables change so that some bad paths are rerouted, we would delete the original bad paths from the system and add the routes for the new good paths. When a bad path is added or deleted, one row may be added to or removed from the matrix; similarly, when a good path is added or deleted, the set of links identified as good by the good path algorithm may change, so a few columns are added to or removed from the matrix. To update a QR decomposition after one column or row update costs time proportional to the size of the matrix, or \(O(n^2)\) time. Since at most \(k\) rows or columns are affected by one of our primitive updates, the total cost of such updates is at most \(O(kn)\). This cost is much less expensive than the initial QR factorization of the matrix.

In Section VII-B4, we show that it takes only a few seconds to complete an incremental update and reidentify the MILSs. Given that end-to-end Internet paths tend to be stable on the time scale of a day [22] and link loss rates remain operationally stable on the time scale of an hour [20], our algorithm should suffice for online updates and diagnosis.

### Combining with Statistical Diagnosis

As discussed before, the linear system is underconstrained, and there exist some unidentifiable links. With MILSs, we attempt to discover the smallest path segments for which properties can be uniquely identified. However, various statistical methods produce estimates of properties at a finer granularity, e.g., at the virtual link level. These methods use statistical assumptions to resolve the likely behavior in the unmeasured space and provide possible estimates.

Our LEND approach and other statistical methods can complement each other. For example, we can discover some links or link segments that are lossy by the least-unbiased approach. If the user wants to make predictions at a finer level of granularity with potential degradation of accuracy, we can further apply statistical algorithms on the lossy MILSs. Compared to traditional statistical tomography, our scheme can significantly reduce complexity without losing inference accuracy by considering a subset of the links. Our MILSs are vectors in the space of end-to-end paths, and the MILS set contains a basis of the space.

Take the linear optimization and Bayesian inference using Gibbs sampling introduced in [5], for example. These algorithms can be used without modification on our MILS set rather than on the original end-to-end paths. Section VI-C6 shows that Gibbs sampling inference combined with our least-unbiased approach improves its accuracy. Additionally, the computational complexity of Gibbs sampling inference based on the MILS set is dramatically reduced because the input "paths" are much shorter than the whole end-to-end paths.

### Diagnosis Validation Through IP Spoofing

Internet diagnosis systems are difficult to evaluate due to the general lack of ground truth. It is very hard, if not virtually impossible, to obtain the link-level performance from ISPs. We will first evaluate the system through simulations in Section VI. Then, we test LEND on the real Internet in Section VII. For validation on the real Internet, in addition to classical cross-validation, we need a more powerful approach. As shown in Section II, existing router-based diagnosis tools like Tulip are neither very accurate nor scalable and, therefore, do not suit our needs. In this section, we propose an IP-spoofing-based mechanism for link-level diagnosis validation.

Though IP spoofing is usually used by malicious hackers to hide their identities, it is also a useful tool to cope with rigid routers. For example, IP spoofing is used to help measure ICMP generation time in routers [23]. We use IP spoofing to obtain limited source routing, which helps validate the accuracy of MILSs. With this technique, we can measure the properties of new paths that we could not normally probe. These additional measurements are then used to validate the inferred loss rates of MILSs.

Figure 8 shows an example of how to use IP spoofing to "create" a new path. Each line in the figure can be a single link or a sequence of links. For simplicity, we call it a link in this section. Assume router \(R_1\) is on the path from node \(A\) to node \(B\), and the path from \(A\) to \(B\) does not go via \(R_1\). To create a new path, \(A\) sends an ICMP ECHO request packet to \(B\) with a spoofed source IP as \(C\). When the packet reaches router \(R_1\), it generates an ICMP ECHO reply packet and sends it to \(C\) via router \(R_2\). Thus, we get a path from \(A\) to \(C\) via \(R_1\) and \(R_2\). Let \(\log P_{AC}\) be the logarithm of the success rate of the path \(A \to C\), and \(\log P_{A \to R_1 \to R_2 \to C}\) be the logarithm of the success rate of the new path. We have \(\log P_{AC} = \log P_{A \to R_1 \to R_2 \to C}\). For validation, we use the source routing capability we have created to measure some new paths and check whether they are consistent with the MILSs and their inferred loss rates obtained from normal non-IP-spoofed measurements.

For example, normal measurements on path \(P\) reveal that there is a single lossy MILS on \(P\). Then, the logarithm of \(P\)'s success rate should be bounded by the sum of the logarithms of the success rates of the individual links in the MILS. See details in Section VII-B2, where the consistency checking idea is also used in cross-validation.

The principle of IP-spoofing-based source routing is simple, but many practical problems need to be addressed:
- **First**, most edge routers check outgoing packets and disable IP spoofing from the internal networks. All PlanetLab hosts are disabled from IP spoofing. However, we were able to get one host, our institution, exempted from such filtering.
- **Second**, as with other router-based diagnosis approaches [12], our scheme is subject to ICMP rate-limiting on routers for measuring the loss rates. We filter those routers with strict ICMP rate-limiting.

### Evaluation with Simulation

In this section, we present our evaluation metrics, simulation methodology, and simulation results.

#### Metrics

The metrics we have used to evaluate our algorithms include:
- **Diagnosis Granularity**: The average length of all the lossy MILSs contained in the path.
- **MILS Loss Rate Estimation Accuracy**: The error of the inferred loss rate compared to the real loss rate.
- **Speed of Setup and Online Diagnosis**: The time taken for setup and online diagnosis.

Of these metrics, diagnosis granularity is particularly important. For diagnosis, we focus on lossy paths and examine how many links we suspect could be the cause of network congestion or failures. We define the diagnosis granularity of a path as the average of the lengths of all the lossy MILSs contained in the path. The diagnosis granularity of an overlay network is defined as the average diagnosis granularity of all the lossy paths in the overlay.

For example, suppose an overlay network has only two lossy paths: one path has two lossy MILSs of length 2 and 4, and the other lossy path consists of only one lossy MILS of length 3. The diagnosis granularity for the overlay is \((2 + 4)/2 + 3/1 = 4.5\).

We measure lengths in terms of physical links, except when we compare to other approaches for which the natural unit of length is a virtual link. A MILS is considered lossy (or bad) if its loss rate exceeds 3%, which is the threshold between "minor loss" and "perceivable loss" as defined in [20]. A path is "good" if it has less than 0.5% loss, which is the threshold for "no loss" in [20].

For each MILS, we evaluate the error of the inferred loss rate compared to the real loss rate by analyzing both the absolute error and the error factor, defined as:

\[
\text{Error Factor} = \max\left(\frac{\hat{L}}{L}, \frac{L}{\hat{L}}\right)
\]

where \(\hat{L}\) and \(L\) are the inferred and real loss rates, respectively. If the estimate is perfect, the error factor is one.

### LEND System Operation

The LEND system operates in two stages: setup and monitoring. In the first phase, we select paths to monitor, and in the second phase, we monitor these paths and use our measurements to diagnose any congestion or failure locations among all paths in the system. The setup phase takes only a few minutes even for a reasonably large overlay network.