title:Enabling Ciphertext Deduplication for Secure Cloud Storage and Access
Control
author:Heyi Tang and
Yong Cui and
Chaowen Guan and
Jianping Wu and
Jian Weng and
Kui Ren
ClouDedup: Secure Deduplication with Encrypted
Data for Cloud Storage
Pasquale Puzio
SecludIT and EURECOM
Sophia-Antipolis, France
PI:EMAIL
Reﬁk Molva
EURECOM
Melek ¨Onen
EURECOM
Sergio Loureiro
SecludIT
Sophia-Antipolis, France
ReﬁPI:EMAIL
Sophia-Antipolis, France
PI:EMAIL
Sophia-Antipolis, France
PI:EMAIL
Abstract—With the continuous and exponential increase of the
number of users and the size of their data, data deduplication be-
comes more and more a necessity for cloud storage providers. By
storing a unique copy of duplicate data, cloud providers greatly
reduce their storage and data transfer costs. The advantages of
deduplication unfortunately come with a high cost in terms of
new security and privacy challenges. We propose ClouDedup,
a secure and efﬁcient storage service which assures block-level
deduplication and data conﬁdentiality at the same time. Although
based on convergent encryption, ClouDedup remains secure
thanks to the deﬁnition of a component that implements an
additional encryption operation and an access control mechanism.
Furthermore, as the requirement for deduplication at block-level
raises an issue with respect to key management, we suggest
to include a new component in order to implement the key
management for each block together with the actual deduplication
operation. We show that the overhead introduced by these new
components is minimal and does not impact the overall storage
and computational costs.
I.
INTRODUCTION
With the potentially inﬁnite storage space offered by cloud
providers, users tend to use as much space as they can and
vendors constantly look for techniques aimed to minimize
redundant data and maximize space savings. A technique
which has been widely adopted is cross-user deduplication.
The simple idea behind deduplication is to store duplicate
data (either ﬁles or blocks) only once. Therefore, if a user
wants to upload a ﬁle (block) which is already stored, the
cloud provider will add the user to the owner list of that ﬁle
(block). Deduplication has proved to achieve high space and
cost savings and many cloud storage providers are currently
adopting it. Deduplication can reduce storage needs by up to
90-95% for backup applications [11] and up to 68% in standard
ﬁle systems [23].
Along with low ownership costs and ﬂexibility, users re-
quire the protection of their data and conﬁdentiality guarantees
through encryption. Unfortunately, deduplication and encryp-
tion are two conﬂicting technologies. While the aim of dedu-
plication is to detect identical data segments and store them
only once, the result of encryption is to make two identical data
segments indistinguishable after being encrypted. This means
that if data are encrypted by users in a standard way, the cloud
storage provider cannot apply deduplication since two identical
1Partially funded by the Cloud Accountability project A4Cloud (grant EC
317550) and the Secure Virtual Cloud (SVC) project, supported by the French
Government within the ”Investissements d’Avenir” Program.
data segments will be different after encryption. On the other
hand, if data are not encrypted by users, conﬁdentiality cannot
be guaranteed and data are not protected against curious cloud
storage providers.
A technique which has been proposed to meet these two
conﬂicting requirements is convergent encryption [18], [25],
[26] whereby the encryption key is usually the result of the
hash of the data segment. Although convergent encryption
seems to be a good candidate to achieve conﬁdentiality and
deduplication at the same time, it unfortunately suffers from
various well-known weaknesses [15], [24] including dictionary
attacks: an attacker who is able to guess or predict a ﬁle can
easily derive the potential encryption key and verify whether
the ﬁle is already stored at the cloud storage provider or not.
In this paper, we cope with the inherent security ex-
posures of convergent encryption and propose ClouDedup,
which preserves the combined advantages of deduplication and
convergent encryption. The security of ClouDedup relies on
its new architecture whereby in addition to the basic storage
provider, a metadata manager and an additional server are de-
ﬁned: the server adds an additional encryption layer to prevent
well-known attacks against convergent encryption and thus
protect the conﬁdentiality of the data; on the other hand, the
metadata manager is responsible of the key management task
since block-level deduplication requires the memorization of a
huge number of keys. Therefore, the underlying deduplication
is performed at block-level and we deﬁne an efﬁcient key
management mechanism to avoid users to store one key per
block. To summarize our contributions:
•
•
•
•
•
ClouDedup assures block-level deduplication and
data conﬁdentiality while coping with weaknesses
raised by convergent encryption. Block-level dedupli-
cation renders the system more ﬂexible and efﬁcient;
ClouDedup preserves conﬁdentiality and privacy
even against potentially malicious cloud storage
providers thanks to an additional layer of encryption;
ClouDedup offers an efﬁcient key management solu-
tion through the metadata manager;
The new architecture deﬁnes several different compo-
nents and a single component cannot compromise
the whole system without colluding with other com-
ponents;
ClouDedup works transparently with existing cloud
storage providers. As a consequence, ClouDedup is
fully compatible with standard storage APIs and any
cloud storage provider can be easily integrated in our
architecture.
Section II explains what deduplication and convergent encryp-
tion are and why convergent encryption is not a secure solution
for cloud storage. Section III provides an overview on the
related work. Sections IV, V and VI describe ClouDedup’s
architecture and the role of each component. Section VII
analyzes the computational and storage overhead introduced
by ClouDedup and evaluates its resilience against potential
attacks. Finally, Section VIII presents our conclusions and
planned future work.
II. BACKGROUND
A. Deduplication
According to the data granularity, deduplication strategies
can be categorized into two main categories: ﬁle-level dedupli-
cation [29] and block-level deduplication [17], which is nowa-
days the most common strategy. In block-based deduplication,
the block size can either be ﬁxed or variable [27]. Another
categorization criteria is the location at which deduplication
is performed: if data are deduplicated at the client, then it is
called source-based deduplication, otherwise target-based. In
source-based deduplication, the client ﬁrst hashes each data
segment he wishes to upload and sends these results to the
storage provider to check whether such data are already stored:
thus only ”undeduplicated” data segments will be actually
uploaded by the user. While deduplication at the client side
can achieve bandwidth savings,
it unfortunately can make
the system vulnerable to side-channel attacks [19] whereby
attackers can immediately discover whether a certain data is
stored or not. On the other hand, by deduplicating data at the
storage provider, the system is protected against side-channel
attacks but such solution does not decrease the communication
overhead.
B. Convergent Encryption
The basic idea of convergent encryption (CE) is to derive
the encryption key from the hash of the plaintext. The simplest
implementation of convergent encryption can be deﬁned as
follows: Alice derives the encryption key from her message
M such that K = H(M ), where H is a cryptographic hash
function; she can encrypt the message with this key, hence:
C = E(K, M ) = E(H(M ), M ), where E is a block cipher.
By applying this technique, two users with two identical plain-
texts will obtain two identical ciphertexts since the encryption
key is the same; hence the cloud storage provider will be able
to perform deduplication on such ciphertexts. Furthermore,
encryption keys are generated, retained and protected by users.
As the encryption key is deterministically generated from
the plaintext, users do not have to interact with each other
for establishing an agreement on the key to encrypt a given
plaintext. Therefore, convergent encryption seems to be a good
candidate for the adoption of encryption and deduplication in
the cloud storage domain.
C. Weaknesses of Convergent Encryption
Convergent encryption suffers from some weaknesses
which have been widely discussed in the literature [9], [15],
[24]. As the encryption key depends on the value of the
plaintext, an attacker who has gained access to the storage
can perpetrate the so called ”dictionary attacks” by comparing
the ciphertexts resulting from the encryption of well-known
plaintext values from a dictionary with the stored ciphertexts.
Indeed, even if encryption keys are encrypted with users’ pri-
vate keys and stored somewhere else, the potentially malicious
cloud provider, who has no access to the encryption key but
has access to the encrypted chunks (blocks), can easily perform
ofﬂine dictionary attacks and discover predictable ﬁles. This
issue arises in [28] where chunks are stored at the storage
provider after being encrypted with convergent encryption.
As shown in [24], the two following attacks are possible
against convergent encryption: conﬁrmation of a ﬁle (COF)
and learn-the-remaining-information (LRI). These attacks ex-
ploit the deterministic relationship between the plaintext and
the encryption key in order to check if a given plaintext has
already been stored or not. In COF, an attacker who already
knows the full plaintext of a ﬁle, can check if a copy of
that ﬁle has already been stored. If the attacker is the cloud
provider or an insider, he might also learn which users are the
owners of that ﬁle. Depending on the content of the ﬁle, this
type of information leakage can be dangerous. For instance,
while some users could not be worried about leaking such
information, it is worth pointing out that by performing this
attack, it is possible to ﬁnd out if a user has illegally stored a
movie or a song.
While COF might be considered as a non-critical problem,
LRI can disclose highly sensitive information: in LRI, the
attacker already knows a big part of a ﬁle and tries to guess
the unknown parts by checking if the result of the encryption
matches the observed ciphertext. This is the case of those
documents that have a predeﬁned template and a small part
of variable content. For instance, if users store letters from
a bank, which contain bank account numbers and passwords,
then an attacker who knows the template might be able to learn
the account number and password of selected users. The same
mechanism can be used to guess passwords and other sensitive
information contained in ﬁles such as conﬁguration ﬁles, web
browser cookies, etc. In general, the more the attacker knows
about the victim’s data, the more the attack can be effective
and dangerous. Hence, a strategy is needed to achieve a higher
security degree while preserving combined advantages of both
convergent encryption and deduplication.
III. RELATED WORK
Many systems have been developed to provide secure stor-
age but traditional encryption techniques are not suitable for
deduplication purposes. Deterministic encryption, in particular
convergent encryption, is a good candidate to achieve both
conﬁdentiality and deduplication [22], [30] but it suffers from
well-known weaknesses which do not ensure protection of
predictable ﬁles against dictionary attacks [12], [18]. In order
to overcome this issue, Warner and Pertula [24] have proposed
to add a secret value S to the encryption key. Deduplication
will
thus be applied only to the ﬁles of those users that
share the secret. The new deﬁnition of the encryption key
is K = H(S|M ) where | denotes an operation between S
and M. However, this solution overcomes the weaknesses
of convergent encryption at the cost of dramatically limiting
deduplication effectiveness. Most
learning the
secret compromises the security of the system. Our approach
provides data conﬁdentiality without impacting deduplication
effectiveness. Indeed, ClouDedup is totally independent from
the underlying deduplication technique.
importantly,
An alternative approach [21], which makes use of proxy
re-encryption, has been proposed but
information on per-
formance and overhead were not provided. To the best of
our knowledge, the most recent work on this topic is [14],
which provides an algorithm to deterministically generate
a key without disclosing any information on the plaintext.
Keys are generated through a key server which retains a
secret. If an attacker learns the secret, the whole system is
compromised and the conﬁdentiality of unpredictable ﬁles is
no longer guaranteed. Also, this technique is limited to ﬁle-
level deduplication and is not scalable in the case of block-
level deduplication, which achieves higher space savings [23].
Moreover, it does not address either side-channel attacks [19]
or attacks based on the observation of access patterns, which
can leak conﬁdential information and compromise users’ pri-
vacy. We propose ClouDedup, which does not rely on the
security of one single component and manages block-level
deduplication in an efﬁcient manner. Furthermore, thanks to
its architecture, ClouDedup can address side-channel attacks
and preserve users’ privacy.
IV. CLOUDEDUP
The scheme proposed in this paper aims at deduplication
at the level of blocks of encrypted ﬁles while coping with
the inherent security exposures of convergent encryption. The
scheme consists of two basic components: a server that is in
charge of access control and that achieves the main protection
against COF and LRI attacks; another component, named as
metadata manager (MM), is in charge of the actual deduplica-
tion and key management operations.
Fig. 1. High-level view of ClouDedup
A. The Server
A simple solution to prevent the attacks against convergent
encryption (CE) consists of encrypting the ciphertexts resulting
from CE with another encryption algorithm using the same
keying material for all
input. This solution is compatible
with the deduplication requirement since identical ciphertexts
resulting from CE would yield identical outputs even after
the additional encryption operation. Yet, this solution will not
suffer anymore from the attacks targeting CE such as COF and
LRI.
We suggest to combine the access control function with the
mechanism that achieves the protection against CE through
an additional encryption operation. Indeed, access control is
an inherent function of any storage system with reasonable
security assurance. Enhancing the trusted component of the
storage system, that implements access control, with the new
mechanism against COF and LRI attacks, seems to be the most
straightforward approach. The core component of ClouDedup
is thus a server that implements the additional encryption
operation to cope with the weaknesses of CE, together with
a user authentication and an access control mechanism em-
bedded in the data protection mechanism. Each data segment
is thus encrypted by the server in addition to the convergent
encryption operation performed by the user. As to the data
access control, each encrypted data segment is linked with
a signature generated by its owner and veriﬁed upon data
retrieval requests. The server relies on the signature of each
segment to properly identify the recipient.
B. Block-level Deduplication and Key Management
Even though the mechanisms of the server cope with the
security weaknesses of CE, the requirement for deduplication
at block-level further raises an issue with respect to key man-
agement. As an inherent feature of CE, the fact that encryption
keys are derived from the data itself does not eliminate the
need for the user to memorize the value of the key for each
encrypted data segment. Unlike ﬁle-level deduplication, in case