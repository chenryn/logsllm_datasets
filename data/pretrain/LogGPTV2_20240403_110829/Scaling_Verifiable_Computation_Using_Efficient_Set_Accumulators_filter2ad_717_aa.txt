title:Scaling Verifiable Computation Using Efficient Set Accumulators
author:Alex Ozdemir and
Riad S. Wahby and
Barry Whitehat and
Dan Boneh
Scaling Verifiable Computation Using 
Efficient Set Accumulators
Alex Ozdemir and Riad Wahby, Stanford University; Barry Whitehat, 
Unaffiliated; Dan Boneh, Stanford University
https://www.usenix.org/conference/usenixsecurity20/presentation/ozdemir
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Scaling Veriﬁable Computation
Using Efﬁcient Set Accumulators
Alex Ozdemir
Stanford
Riad S. Wahby
Stanford
Barry Whitehat
No Afﬁliation
Dan Boneh
Stanford
{aozdemir,rsw,dabo}@cs.stanford.edu
PI:EMAIL
Abstract
Veriﬁable outsourcing systems ofﬂoad a large computation to
a remote server, but require that the remote server provide a
succinct proof, called a SNARK, that proves that the server
carried out the computation correctly. Real-world applications
of this approach can be found in several blockchain systems
that employ veriﬁable outsourcing to process a large number
of transactions off-chain. This reduces the on-chain work to
simply verifying a succinct proof that transaction process-
ing was done correctly. In practice, veriﬁable outsourcing of
state updates is done by updating the leaves of a Merkle tree,
recomputing the resulting Merkle root, and proving using a
SNARK that the state update was done correctly.
In this work, we use a combination of existing and novel
techniques to implement an RSA accumulator inside of a
SNARK, and use it as a replacement for a Merkle tree. We
speciﬁcally optimize the accumulator for compatibility with
SNARKs. Our experiments show that the resulting system re-
duces costs compared to existing approaches that use Merkle
trees for committing to the current state. These results apply
broadly to any system that needs to ofﬂoad batches of state
updates to an untrusted server.
1 Introduction
Veriﬁable outsourcing [4, 13, 15, 16, 21, 32, 45, 47, 49, 52,
56, 61, 78, 79, 96, 106–108, 111–115, 121, 123, 124] is a
technique that enables a weak client to outsource a compu-
tation to a powerful server. The server returns the result of
the computation along with a proof that the computation was
done correctly. The proof must be succinct, which means that
it must be short and cheap to verify. Veriﬁable outsourcing is
relevant in a number of scenarios, including weak IoT devices,
wearables, and low-power devices.
More recently, veriﬁable outsourcing has been deployed
in blockchain environments, because on-chain work is
expensive—literally. Here, a batch of k transactions, say
k = 1000, is outsourced to an untrusted server, called an ag-
gregator, for processing. The aggregator (1) veriﬁes that the
transactions are valid (e.g., properly signed), (2) computes
the updated global state resulting from these transactions, and
(3) generates a succinct proof that the aggregator correctly
executed steps (1) and (2). The updated state and the succinct
proof are then sent to the blockchain. In this approach, the
(expensive) on-chain work is reduced to only verifying the
proof—which is fast, taking time independent of the num-
ber of transactions k—and then recording the updated state.
Example systems that operate this way include Rollup [7],
Coda [89], Matter [86], and Zexe [29].
The process described above is called veriﬁable outsourc-
ing of state update [32]. In more detail, the state is a set
of elements S = {x1, . . . ,xM} from some universe X . The
blockchain (or a low-power device) stores only a succinct
digest of S, e.g., the root of a Merkle tree whose leaves com-
prise the elements of S. The untrusted but powerful aggregator
stores the full set S, in the clear. (Note that we treat S as public
data—privacy is orthogonal to our goal, which is scalability).
When processing a batch of transactions as described above,
the aggregator updates S to produce a new set S(cid:48), then com-
putes a new Merkle digest for S(cid:48) that it sends to the blockchain
to be veriﬁed and recorded. The aggregator’s proof establishes
that its starting state S is consistent with the current digest,
that correctly applying transactions yields the ending state S(cid:48),
and that the new digest is consistent with S(cid:48).
The succinct proof needed here is called a SNARK [19],
which we deﬁne in more detail in the next section. Construct-
ing efﬁcient SNARKs and optimizing their implementation is
a very active area of research [13, 15, 16, 49, 64, 70, 96], with
several new systems just in the last year [11, 37, 43, 44, 62, 63,
85, 122]. A common thread in all of these systems is that the
proving costs are enormous. In particular, proving imposes
multiple-orders-of-magnitude slowdown compared to native
execution [96, 106, 116]; this can be defrayed via parallel
execution, e.g., in clusters [45, 121] or on GPUs [108, 112].
Perhaps more importantly, for widely deployed SNARKs,
proving correctness of large computations requires an amount
of RAM proportional to the computation’s execution time [16,
96]. The result is that, even when proving is distributed across
hundreds of workers, the largest reachable computation sizes
are relatively small: only about 2 billion steps [121]. This
imposes a strict upper bound on the number of transactions k
that can be processed in a single batch.
USENIX Association
29th USENIX Security Symposium    2075
This state of affairs has motivated a large body of work on
computational primitives that yield efﬁcient proofs. Examples
include arithmetic [79, 96, 108], control ﬂow [96, 108, 116],
persistent state [4, 32, 49, 56, 105], and random-access mem-
ory [12, 13, 16, 32, 79, 116]. Our work continues in this
vein, with a focus on reducing proving costs for computations
involving persistent state or random-access memory.
Our work. A Merkle tree [90] is an example of an accu-
mulator [17], a cryptographic primitive that lets one commit
to a set S, and later prove that an element x is a member
of S. Although Merkle trees are used pervasively in today’s
general-purpose veriﬁable state update applications, in this
work we show that a Merkle tree is not the best choice for large
batches of state updates when S is moderately to very large,
say |S| ≥ 210. In particular, we show that replacing Merkle
trees with RSA-based accumulators [24, 40, 81] signiﬁcantly
improves proving time and/or reachable computation size.
Our contributions are:
• We deﬁne a new operation for RSA accumulators, which
we call MultiSwap, that provides a precise sequential se-
mantics for batched veriﬁable state updates (§3).
• We synthesize existing and novel techniques for efﬁciently
implementing MultiSwap (and, more generally, RSA accu-
mulators) in the context of SNARKs (§4). These techniques
include a hash function that outputs provable prime num-
bers, and a new division-intractable hash function. Our
approach makes use of very recent advances in manipulat-
ing RSA accumulators [24].
• We apply our techniques in two contexts (§5). The ﬁrst,
called Rollup [7, 65, 94], is a technique for batching cryp-
tocurrency transactions off-chain in order to save on-chain
work. The second is a general-purpose RAM abstraction
with long-lived state (i.e., over many proofs), which builds
upon and improves prior work [12, 13, 16, 32, 116].
• We implement and evaluate (§6, §7). In particular, we com-
pare our RSA accumulator implementation to Merkle trees
in two benchmarks: one that measures only set operations,
and one that implements a Rollup-style distributed payment
application. We also compare our RAM abstraction with
existing work via a cost model analysis.
In the set operations benchmark, we ﬁnd that RSA accu-
mulators surpass 220-element Merkle trees for batches of
≈1,300 operations, and allow for 3.3× more operations to
be performed in the largest proof sizes we consider. In the
Rollup application, RSA accumulators surpass 220-element
Merkle trees for ≈600 transactions, and allow 1.9× more
transactions in the largest proofs. For RAM, we ﬁnd that
for a RAM of size 220, RSA accumulators surpass Merkle
trees for ≈1000–4000 accesses, depending on write load.
2 Background and deﬁnitions
Multisets. A multiset is an unordered collection that may
contain multiple copies of any element. S1 (cid:93) S2 denotes the
union of multisets S1 and S2, i.e., the multiset S3 where each
element x ∈ S3 has multiplicity equal to the sum of the multi-
plicities of x in S1 and S2. S1 (cid:12) S2 denotes the strict difference
of multisets S1 and S2, i.e., the multiset S3 where each element
x ∈ S3 has multiplicity equal to the difference of multiplicities
of x in S1 and S2. Note that S1 (cid:12) S2 is only deﬁned if S2 ⊆ S1.
RSA groups. An RSA group is the group Z×
N , i.e., the mul-
tiplicative group of invertible integers modulo N, where N
is the product of two secret primes. We deﬁne the RSA quo-
tient group for N as the group Z×
N /{±1}. In this group, the
elements x and N − x are the same, meaning that all elements
can be represented by integers in the interval [1,(cid:98)N/2(cid:99)]. It is
believed that this group has no element of known order, other
than the identity.
Proofs and arguments.
Informally, a proof is a protocol
between a prover P and a PPT veriﬁer V by which P con-
vinces V that ∃υ : R(ι,υ) = 1, for a relation R, ι an input
from V , and υ a (possibly empty) witness from P . A proof
satisﬁes the following properties:
• Completeness: If ∃υ : R(ι,υ) = 1, then an honest P con-
vinces V except with probability at most εc (cid:28) 1/2.
If (cid:54)∃υ : R(ι,υ) = 1, no cheating prover P (cid:63)
• Soundness:
convinces V except with probability at most εs (cid:28) 1/2.
If soundness holds only against PPT P (cid:63), this protocol is in-
stead called an argument. When the witness υ exists, one may
also require the proof system to provide knowledge sound-
ness. Informally this means that whenever P convinces V that
∃υ : R(ι,υ) = 1, υ exists and P “knows” a witness υ (slightly
more formally, there exists a PPT algorithm, an extractor, that
can produce a witness via oracle access to P ).
Proof of exponentiation. Let G be a ﬁnite group of un-
known order. Wesolowski [120] describes a protocol that al-
lows P to convince V that y = xn in G, namely a protocol for
the relation R given by R(cid:0)(n,x,y),·(cid:1) = 1 ⇐⇒ y = xn ∈ G.
The protocol is: on input (n,x,y), V sends to P a random (cid:96)
chosen from the ﬁrst 2λ primes.1 P sends back Q = x(cid:98)n/(cid:96)(cid:99) ∈ G,
and V accepts only if Q(cid:96) · xn mod (cid:96) = y ∈ G holds.
This protocol is complete by inspection. Wesolowski shows
that it is sound if the group G satisﬁes the adaptive root
assumption, roughly, it is infeasible for an adversary to ﬁnd a
random root of an element of G chosen by the adversary. The
RSA quotient group Z×
N /{±1} is conjectured to satisfy this
assumption when P cannot factor N [23].
Division-intractable hashing. Recall that a hash function
H : X → D is collision resistant if it is infeasible for a PPT
1When this protocol is made non-interactive via the Fiat-Shamir heuristic,
the challenge must instead be drawn from the ﬁrst 22λ primes [120; 23, §3.3].
2076    29th USENIX Security Symposium
USENIX Association
adversary to ﬁnd distinct x0,x1 such that H(x0) = H(x1). In-
formally, H is division intractable if the range of H is Z, and
it is infeasible for a PPT adversary to ﬁnd ˆx and a set {xi} in
X such that ˆx (cid:54)∈ {xi} and H( ˆx) divides ∏i H(xi). A collision-
resistant hash function that outputs prime numbers is division
intractable. We construct a different division intractable hash
function in Section 4.2.
Pocklington primality certiﬁcates. Let p be a prime, and
r < p and a be positive integers. Deﬁne p(cid:48) = p· r + 1. Pock-
lington’s criterion [34] states that if ap·r ≡ 1 mod p(cid:48) and
gcd(ar − 1, p(cid:48)) = 1, then p(cid:48) is prime. In this case, we say that
(p,r,a) is a Pocklington witness for p(cid:48).
Pocklington’s criterion is useful for constructing primality
certiﬁcates. For a prime pn, this certiﬁcate comprises
(cid:0)p0,{(ri,ai)}0<i≤n
(cid:1)
where pi = pi−1 · ri + 1. To check this certiﬁcate, ﬁrst ver-
ify the primality of the small prime p0 (e.g., using a deter-
ministic primality test), then verify the Pocklington witness
(pi−1,ri,ai) for pi, 0 < i ≤ n. If each ri is nearly as large as
pi, the bit lengths double at each step, meaning that the total
veriﬁcation cost is dominated by the cost of the ﬁnal step.
2.1 Accumulators
A cryptographic accumulator [17] commits to a collection of
values (e.g., a vector, set, or multiset) as a succinct digest. This
digest is binding, meaning informally that it is computation-
ally infeasible to equivocate about the collection represented
by the digest. In addition, accumulators admit succinct proofs
of membership and, in some cases, non-membership.
Merkle trees. The best-known vector accumulator is the