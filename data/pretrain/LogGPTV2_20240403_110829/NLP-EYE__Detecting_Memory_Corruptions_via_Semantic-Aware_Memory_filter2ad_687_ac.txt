tance of each library and program by using the adaptive
Figure 4: Segmentation results of function names by using
NLP-EYE and GWTWC
corpus of NLP-EYE and GWTWC. NLP-EYE segments
function names of Vim, ImageMagick, CPython, Git, Graphics-
Magick,GnuTLS and LibTIFF accurately with the Levenshtein-
inspired distance as 0.96, 0.16, 0.3, 0.3, 0.42, 0.63 and 0.86
respectively. The results for LibTIFF and Vim are worse than the
others, because lots of function names involve single letters,
and NLP-EYE cannot distinguish those letters from a word.
Except for GraphicsMagick and ImageMagick, the adap-
tive corpus-based segmentation performs better than the
GWTWC-based segmentation. According to our manual in-
spection, we found that GWTWC is not a programming
language-based corpus and it cannot proceed programming ab-
breviations. Thus, most of its segmentation results are worse
than the results of the adaptive corpus-based segmentation.
However, this conclusion is not satisﬁed on GraphicsMagick,
because some function names are incorrectly divided into
abbreviations by the adaptive corpus. Taken a function name
preview as an example, it is divided into [“pre”, “view”]
instead of “preview”, because the frequencies of those two
abbreviations are higher in comments. For the ImageMagick,
most function names are declared in normalized words, which
are easy for GWTWC and the adaptive corpus to distinguish
each word.
4.3 Ex2: Memory Operation Function Identi-
ﬁcation
We counted the number of memory operation functions that
are correctly detected by NLP-EYE and computed the preci-
sion, recall, and F-measure on the entire dataset. To conduct
this experiment, we separately set the thresholds (fn-similarity
and arg-similarity) as (0.3, 0.4, 0.5) for function names and
argument names, and found that NLP-EYE performs the
best when fn-similarity and arg-similarity are 0.4 and 0.5,
respectively.
10.160.660.460.321.21.130.960.160.30.30.420.630.86VimImageMagickCPythonGitGraphicsMagickGnuTLSLibTIFF0.00.51.01.5AverageDistancesGWTWC-based Adaptive Corpus-basedUSENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 315# of
identiﬁed functions
# of correctly
identiﬁed functions
Precision Recall
F-measure
Vim
ImageMagick
CPython
Git
GraphicsMagick
GnuTLS
LibTIFF
Total
304
137
131
46
69
74
8
769
42
44
48
8
16
4
0
162
13%
32%
36%
17%
23%
5%
0
21%
57%
55%
72%
25%
55%
36%
0
55%
21%
40%
48%
20%
32%
8%
0
30%
Table 2: Memory operation function identiﬁcation results of NLP-EYE
NPD
DF
UAF
Detected Conﬁrmed Detected Conﬁrmed Detected Conﬁrmed
Vim
CPython
Git
GraphicsMagick
Total
17
10
1
6
34
17
4
1
5
27
2
1
0
0
3
1
1
0
0
2
8
8
0
0
16
2
1
0
0
3
Table 3: Detection results of null pointer de-reference (NPD), double-free (DF) and use-after-free (UAF). Note that this result
only shows the vulnerabilities caused by customized memory operation functions.
Function Identiﬁcation Results. We applied the StackOver-
ﬂow corpus for NLP-based comparison. All the posts from
the StackOverﬂow forum [16] are included in the Stack-
Overﬂow corpus. Table 2 shows the best identiﬁcation re-
sult with the number of identiﬁed functions and the number
of memory operation functions that are correctly identiﬁed.
We also computed precision, recall, and F-measure of NLP-
EYE. NLP-EYE correctly identiﬁes 162 memory operation
functions out of the 769 identiﬁed functions, with precision,
recall, F-measure value of 21%, 55%, and 30%, respectively.
For LibTIFF, NLP-EYE cannot detect any memory operation
functions because many single letters are used to name a
function argument. For example, “s” is commonly used to ex-
press “size” that causes the recognition of memory operation
functions even harder if the thresholds are too high. We then
determine a balance between the thresholds (i.e., fn-similarity
and arg-similarity) and the identiﬁcation accuracy.
Within millions of functions, NLP-EYE narrows down
the number of functions that need to be analyzed, and the
total number of functions for manual analysis is acceptable.
Furthermore, the false positive and the false negative are rea-
sonable.
Context Corpus Selection. We further applied NLP-based
comparison on two extra context corpuses (i.e., Wikipedia
corpus, and customized corpus) to assess the identiﬁcation per-
formance. The Wikipedia corpus contains all webpages from
Wikipedia [19]. Alternatively, the customized corpus consists
of: 1) Linux man pages [12]; 2) Part of GNU Manuals [5];
and 3) two programming tutorials, i.e., C++ Primer [31] and
C Primer Plus [36].
Based on the Wikipedia corpus, NLP-EYE only identi-
ﬁes no more than ten memory operation functions in each
library and program with a precision value of 7%, and a worse
recall value. While using customized corpus as the context
corpus, the precision and recall of NLP-EYE are 42% and
19%, respectively. Although its precision is acceptable, it still
causes too many false negatives. By manually analyzing the
results, we found that Wikipedia corpus is insensitive to the
programming language, and most identiﬁed functions are un-
related to memory operation. For the customized corpus, it
fails to identify functions that use abbreviations, which cause
exceptions if words are not found in the corpus.
4.4 Ex3: Vulnerability Detection
We tested NLP-EYE on the seven libraries and programs to
examine whether there is any unknown memory corruption
vulnerability. Note that the seven collected libraries and pro-
grams are the latest versions (collected in December 2018).
Vulnerabilities Detected by NLP-EYE. NLP-EYE detects
49 vulnerabilities from these libraries and programs in total.
While only considering vulnerabilities caused by customized
memory operation functions, four libraries and programs are
involved. The detection result is shown in Table 3. By manu-
ally verifying these results, NLP-EYE successfully detects
32 vulnerabilities, including 27 null pointer de-reference, two
double-free, and three use-after-free, existed in customized
memory operation functions. To further verify the correctness
of our results, we reported the manual-conﬁrmed vulnerabili-
ties to developers, and they have conﬁrmed and patched ten
316          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationNLP-EYE MallocChecker Cppcheck
Vim
ImageMagick
Cpython
Git
GraphicsMagick
GntTLS
LibTIFF
Total
3.82
6.16
8.31
3.11
2.08
2.75
0.91
27.14
2.77
5.00
7.70
2.80
1.45
2.33
0.87
22.92
18.90
28.00
1.47
0.88
11.83
9.65
0.93
71.66
Infer
51.28
64.25
23.43
13.52
8.75
11.13
3.55
175.91
SVF
50.92
0.25
0.26
2.36
0.15
0.11
0.04
54.09
Table 4: Runtime performance comparison (minutes)
null pointer de-reference and all the double-free, use-after-free
vulnerabilities. Each customized memory operation function
may cause vulnerabilities, since NLP-EYE failed to identify a
part of them, this may lead to a false negative of vulnerability
detection result. Besides the successfully detected vulnerabil-
ities, NLP-EYE made false positive as well listed in Table 3.
However, after we manually inspected the false positive, we
found that none of them are caused by the wrong identiﬁcation
result.
There are two reasons that cause the false positive: 1) sym-
bolic execution engine proceeds the expression with indexes
in a loop as a static expression. For instance, the engine may
report a double free on an array with different index in a
loop since the engine regard the array element with different
index as the same value; 2) While processing a conditional
statement with a complex logic, the symbolic execution en-
gine executes every path without considering the constraints
deﬁned in the conditional statements.
Detection Effectiveness Assessment. To assess the detection
effectiveness of NLP-EYE, we applied four detection tools,
MallocChecker, Cppcheck, Infer and SVF, to the entire dataset for
comparison. MallocChecker and Infer claim to detect all three
kinds of vulnerabilities. Cppcheck and SVF are designed to
detect vulnerabilities of use-after-free and double-free. For
the null pointer de-reference vulnerability, MallocChecker and
Infer correctly reported 11 and 30 vulnerabilities, respectively.
However, they can only report those misuses caused by stan-
dard memory allocation functions, while NLP-EYE can de-
tect both standard and customized memory allocation func-
tions. Even worse, none of these tools can detect vulnerabili-
ties of use-after-free and double-free correctly.
We analyzed false positives caused by these tools. Similar
to NLP-EYE, the symbolic execution engine of MallocChecker
cannot identify the index of an array in a loop. Although
Cppcheck can detect use-after-free vulnerabilities, it became
inaccurate when lots of variables are declared to operate dy-
namic memories. Infer checks all returned pointers, which
cause many false positives. It even reported a use-after-free
vulnerability existed in an integer statement. SVF performed
the worst by reporting hundreds of double-free vulnerabilities,
which causes lots of errors.
4.5 Ex4: Runtime Performance
We evaluated the time cost of each phase (i.e., preprocessing,
semantics extraction, and vulnerability detection) of NLP-
EYE. Additionally, we tested the runtime of the other detec-
tion tools to assess the efﬁciency of NLP-EYE.
Before vulnerability detection, we collected all the posts
on StackOverﬂow forum with the size of 17GB to create the
context corpus, and it costs 56 hours to generate the model
ﬁle. This step processes only once because we can repeatedly
use the context corpus in further analysis.
Table 4 shows the total runtime cost of NLP-EYE and
the other tools while analyzing our dataset. NLP-EYE pre-
processes each library and program, and constructs the cor-
responding adaptive corpus within one seconds. It further
spends 36.601s on average to identify memory operation func-
tions in each library and program. NLP-EYE spends 70.917s
on ImageMagick, but no more than 6s on LibTIFF, because Im-
ageMagick has 14,636 functions and LibTIFF only includes
1,326 functions.
By comparing with the other tools, the runtime performance
of NLP-EYE and MallocChecker are similar, since they use
the same symbolic execution engine. SVF sacriﬁces the de-
tection accuracy to achieve a higher runtime performance.
Unfortunately, it is unhelpful for programmers to pinpoint
vulnerabilities. Cppcheck and Infer analyze the entire source
code to ensure a complete coverage, which costs much time.
4.6 Limitations
NLP-EYE successfully detects some memory corruption
vulnerabilities other tools cannot detect. The results of func-
tion identiﬁcation and vulnerability detection indicate that
NLP-EYE understands the function semantics well with only
limited information. However, we still have the following lim-
itations that cause detection failures.
1. When a function implementation is complex, the sym-
bolic execution engine in NLP-EYE cannot correctly
analyze the data ﬂow and control ﬂow.
2. NLP-EYE cannot handle single letters involved in the
function prototypes which may causes false positive and
false negative.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 317Figure 5: A null pointer de-reference vulnerability in Graphic-