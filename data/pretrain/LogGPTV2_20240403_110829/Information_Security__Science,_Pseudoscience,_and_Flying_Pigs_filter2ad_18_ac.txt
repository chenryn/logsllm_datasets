### 3.2 Penetrate and Patch

In the late 1960s, general-purpose Automated Data Processing (ADP) systems often involved aerospace companies that needed to run both classified and unclassified processes on the same system. During this period, there were repeated attempts to achieve the necessary security through a method known as "penetrate and patch." This approach posited that a system could be secured by having experts identify and fix each flaw through penetration testing. However, the defender had to find and patch all flaws, while an attacker only needed to find one. The use of trap doors demonstrated the futility of this approach.

It is noteworthy that in many of today's ADP environments, "penetrate and patch" has evolved into "patch and pray," partly because modern penetrators are often hostile hackers rather than friendly Tiger Teams. A failure by a Tiger Team to penetrate a commercial system with add-on security was seen as extremely damaging to the nation's computer systems. This was because managers might falsely conclude that the exercise demonstrated a lack of flaws or trap doors, rather than recognizing that the Tiger Team simply failed to find existing vulnerabilities.

### 3.3 Deliberate Design for Evaluation

What was needed was a scientific basis for evaluating the protections offered by a system. The challenge lies in the fact that verifying software and hardware behavior, including security, is often non-computable. In the case of computer security, one must prove a negative, such as demonstrating that the system does not leak sensitive data. To succeed, the system must be specifically designed from the start to be evaluated, with security controls built into the design in a structured manner.

Even the earliest SAGE system recognized the need for independent evaluation, driven by the requirement for nuclear safety. In later systems, evaluation requirements were driven by the threat of subversion. It was also recognized that black-box testing for security was ineffective because it could demonstrate the existence but not the absence of flaws. For example, a system with a trap door triggered by a deliberately designed character sequence that would not occur during testing could remain undetected. If this triggering sequence were a 128-bit key, it would be impractical to test every possibility within a reasonable timeframe.

The failure of the "penetrate and patch" approach in the late 1960s led to the Ware Report [14], which codified the state of understanding and highlighted the difficulty of the problem. This was a pivotal moment where the understanding of concepts came together, allowing for significant progress. The Ware Report identified the problem but left it unresolved, leading to the Anderson Panel [15], which defined the reference monitor concept and conceived a program for evaluating and developing kernels. SCOMP [16] was the first commercial result of this effort, and another result was security enhancements to Multics [17]. Both systems had security built into them but responded to different levels of threat.

### 3.4 Discretionary and Mandatory Policies

A key scientific underpinning identified during this first epoch is the distinction between discretionary and mandatory security policies. Glimpses of this distinction appeared in the Ware Report [14] of 1969 and in the ADEPT-50 [18] system around the same time. The distinction first appeared in general literature in the mid-1970s [19].

By the time of WWMCCS and Multics, clear distinctions were made between mandatory access control policies (MAC), discretionary access control policies (DAC), and application policies. It became clear that only MAC offered verifiable statements about information flow, requiring that information be assigned global and persistent access classes in the form of a mathematical lattice [20]. This "labeling" of information supports both hierarchical and non-hierarchical relationships between access classes.

### 3.5 Formal Security Policy Models

As independent parallel efforts, Case Western and MITRE developed formal security policy models. The latter became more generally accepted because its elements more directly mapped to physical computing components, such as memory descriptors. While the mandatory access controls of the Multics system were built to the Case Western model, an after-the-fact interpretation of the Bell and LaPadula model was generated [21]. This was possible because both models encompassed common security policies. These formal models could be applied to problems of information integrity as well as maintaining the secrecy of information [22]. It was later shown that implementations of these models could bring verified protection to security policies suitable for commercial and other data processing requirements [23].

It became evident that achieving verified protection required sound mathematics. However, two key issues led to some failed attempts to apply formal models to trusted systems. First, the security model must be a valid representation of the system's behavior with respect to information protection. Second, the model must include a proven security theorem, establishing that the model’s behavior always complies with the security requirements for the policy of interest, rather than being a mere formalization of mechanism [24].

### 3.6 Key Hardware Platform Properties

Several different hardware platforms were the target of kernel prototyping efforts. They shared common properties, including memory segmentation and at least three hardware states for implementing protection rings: one for the security kernel, one for the operating system, and one for applications. The primary hardware modification that enabled SCOMP was the addition of support for four hardware rings and segmentation.

Mandatory access control policies are enforced by the security kernel in the most protected ring. Discretionary access control policies can also be enforced by the security kernel or by the OS, depending on assurance requirements. Application policies are generally enforced by the applications themselves or by the operating system. The separation of the operating system from the application programs is itself an application policy enforced by the operating system.

### 3.7 Advances in the State of the Science

This epoch, culminating in the prototyping and fielding of security kernels, contributed the following key advances to the science of computer and network security:
- Reference Monitor Concept
- A Simple Security Kernel
- Formal Security Policy Models
- Discretionary vs. Mandatory Access Control Policies
- Hardware Rings and Segmentation

### 4. Available Commercial Evaluations

The next epoch culminated in the ability to procure a commercial system demonstrably secure with respect to a given security policy. The key to a "demonstrably secure" system is a scientifically based evaluation. The need to independently evaluate a system's ability to enforce a given security policy was recognized even during the previous epoch when security-critical systems were largely built in controlled environments by cleared programmers. The need for evaluation becomes more acute when standard commercial products are used, as there is no assurance that they do not contain elements obtained from a potentially hostile third party.

### 4.1 How to Trust What You Don’t Build

Multics was influential in generating interest in commercial evaluations because it was a commercial product. Before that, attempts to field secure systems built on commercial security products were characterized by rounds of "penetrate and patch," with vendors often using emphatic assertions to explain the security basis of their systems.

Amid the increased interest in evaluating commercial products during the mid-1970s, the Air Force and ARPA sponsored MIT to develop auditable systems [25]. This effort concluded that building auditable systems required certain forms of hardware support. There were few construction techniques for building systems whose security could be assessed after-the-fact. There were ad-hoc techniques and design standards, but little in the way of reproducible theory on how to architect such a system.

The MIT project recognized this as a hard problem and identified several solution components. This effort articulated the notion of layering software modules, previously identified by Parnas [26]. It also solved challenges related to process management, resulting in the definition of a two-level scheduler. Issues of inter-process communication were a serious challenge, with contemporary strategies like message passing and P&V semaphores not suitable for the task. This led to the invention of eventcounts and sequencers [27] for secure inter-process communication.

The MIT project succeeded in offering solutions to all the hard problems that stood in the way of building auditable operating systems.

### 4.2 Formal Methods and Verification

A major step enabling independent evaluation of products was the development of formal methods [28]. At one point, there were three tools approved for use by the NCSC: FDM, HDM, and Gypsy. One of the most significant developments was the Fiertag flow tool [29].