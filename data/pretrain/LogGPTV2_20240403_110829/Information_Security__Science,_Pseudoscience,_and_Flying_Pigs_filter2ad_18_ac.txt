3.2.  Penetrate and Patch 
this 
During 
time,  general  purpose  ADP  often 
involved  aerospace  companies  wanting  to  run  classified 
and unclassified processing on the same system.  The late 
sixties  saw  repeated  attempts  to  achieve  the  needed 
security  through  what  became  known  as  “penetrate  and 
patch”, which posited that a system could be secured by 
having  experts  locate  each  flaw  through  penetration 
testing.  Note however that the defender had to find all of 
the  flaws,  while  the  attacker  only  had  to  find  one. 
Ultimately the use of a trap door artifice demonstrated the 
futility of that approach.  It is instructive to observe that 
in  many  of  today’s  ADP  environments,  “penetrate  and 
patch”  has  become  “patch  and  pray”,  in  part  because 
instead  of  friendly  Tiger  Teams,  many  of  today’s 
penetrators are hostile hackers. 
It was later observed that a failure by a Tiger Team to 
penetrate  a  commercial  system  with  add-on  security 
would  be  extremely  damaging  to  the  security  of  the 
nation’s computer systems [13]. The damage would result 
from  managers  falsely  concluding  that  the  exercise 
demonstrated a lack of flaws or trap doors, rather than the 
proper  conclusion  that  the  Tiger  Team  simply  failed  to 
find vulnerabilities that could well have existed. 
3.3.  Deliberate Design for Evaluation 
What  was  needed  was  a  scientific  basis  for 
evaluating  the  protections  offered  by  a  system.    The 
challenge is that you can’t evaluate just any software and 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
  In  the  general  case,  verifying  software 
hardware. 
behavior, including security, is often non-computable.  In 
the case of computer security, you must prove a negative, 
e.g.,  that  the  system  does  not  leak  sensitive  data.  To 
succeed,  the  system  must  be  specifically  designed  to  be 
evaluated with the security controls built into the design 
from  the  start  is  a  structured  manner.  Even  the  earliest 
SAGE  system  recognized  the  need  for  independent 
evaluation; in that system, it was driven by the need for 
nuclear safety.  In latter systems, evaluation requirements 
were  driven  by  the  threat  of  subversion.    And,  it  was 
recognized that black-box testing for security was useless 
because  it  could  demonstrate  the  existence  but  not  the 
absence of flaws.  For example, consider a system having 
a trap door triggered by a character sequence deliberately 
designed  to  not  occur  in  testing.    If  this  triggering 
sequence were simply a 128-bit key, the universe would 
die before you finish testing each possibility. 
The  failure  of  penetrate  and  patch  to  secure  ADP 
systems  in  the  late  sixties  helped  stimulate  the  Ware 
Report [14], which represented a codification of the state 
of  understanding,  which  primarily  was  a  realization  of 
how  difficult  the  problem  was.    This  was  one  of  those 
points  where  understanding  of  concepts  came  together 
enough to allow a significant step forward. 
The Ware Report [14] clearly identified the problem, 
but  left  it  unresolved.    That  led  to  the  Anderson  Panel 
[15],  which  defined  the  reference  monitor  concepts  and 
conceived  a  program  for  evaluating  and  developing 
kernels.  SCOMP [16] was the first commercial result of 
that  immediate  effort.    Another  result  was  security 
enhancements to Multics [17].  Both of these had security 
built into them, but it was recognized that they responded 
to two different levels of threat. 
to  support  security. 
At  about  this  same  time  frame,  the  WWMCCS 
system was built upon a commercial operating system as 
an  attempt  to  add  security  onto  a  system  that  was  not 
structurally  designed 
  While 
WWMCCS  had  substantial  security  requirements,  it  had 
no fundamental design requirement  for the  system to be 
designed  from  the  start  to  be  secure,  let  alone  be 
evaluatable.  It was built by layering applications upon a 
commercial operating system, and depending on the weak 
commercial  OS  security  controls. 
  This  doomed 
WWMCCS to a long series of security problems. 
AUTODIN, which was the government computerized 
messaging  system  for  several  decades,  had  definitive 
design  requirements  to  address  security.    Even  though 
AUTODIN  was  built  on  a  commercial  machine 
executive,  the  executive  itself  was  quite  small  and 
primitive.    The  remainder  of  the  system  was  built  by 
cleared  programmers 
to  a  set  of  security-driven 
specifications.  
The  NSA  Southeast  Asia  sanitization  system 
identified above was built substantially around the crypto 
therefore  had  development 
development  model  and 
criteria  intended  to  control  insertion  of  trap  doors  and 
ensure that the result could to some degree be evaluated.   
And  while  not  a  true  security  kernel,  Multics 
incorporated many of the requisite protection mechanisms 
and  separated  secret  from  top-secret  information  for 
fifteen  years  in  a  critical  Pentagon  facility  without  an 
operational compromise.   
3.4. Discretionary and Mandatory Policies 
A  key  scientific  underpinning  identified  during  this 
first  epoch  is  the  distinction  between  discretionary  and 
mandatory security policies.  Glimpses of this distinction 
appeared  in  the  Ware  Report  [14]  of  1969  and  in  the 
ADEPT-50  [18]  system  of  around  the  same  time  frame.  
The distinction  first appeared in  general literature in the 
mid seventies [19]. 
By  the  time  of  WWMCCS  and  Multics,  there  were 
clear distinctions being  made between  mandatory access 
control  policies  (MAC),  discretionary  access  control 
policies  (DAC)  and  application  policies.  And  it  became 
clear  that  only  MAC  offered  verifiable  statements  about 
information flow, which requires that the information be 
assigned global and persistent access classes in the form 
of  a  mathematical  lattice  [20].  This  “labeling”  of 
information 
supports  both  hierarchical  and  non-
hierarchical relationships between access classes. 
3.5.  Formal Security Policy Models 
As  independent  parallel  efforts,  Case  Western  and 
MITRE  developed  formal  security  policy  models.    The 
latter became more generally accepted primarily because 
its elements more directly mapped to physical computing 
components  (e.g.,  memory  descriptors).    So,  while  the 
mandatory  access  controls  of  the  Multics  system  were 
built  to  the  Case  Western  model,  an  after-the-fact 
interpretation  of  the  Bell  and  LaPadula  model  was 
generated [[21]].  This was possible because both models 
were  sound  math  encompassing  common  security 
policies.  It was found that these formal models could be 
applied to problems of information integrity as well as to 
maintaining the secrecy of information [22].  It was later 
shown that implementations of these models could bring 
verified  protection  to  security  policies  thought  to  be 
suitable  for  commercial  and  other  data  processing 
requirements [23]. 
It became evident that successfully achieving verified 
protection would require sound math.  However, two key 
security  model 
of 
misunderstanding  to  this  day,  leading  to  some  failed 
attempts to apply formal models to trusted systems.  First, 
the  security  model  must be a valid representation of the 
behavior  with  respect  to  information  protection  of  the 
remain 
source 
issues 
a 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
entire system.  Second, the model must include a proven 
security  theorem,  which  establishes  that  the  model’s 
behavior always complies with the security requirements 
for  the  policy  of  interest  rather  than  being  a  mere 
formalization of mechanism [24]. 
3.6.  Key Hardware Platform Properties 
Several different hardware platforms were the target 
of  kernel  prototyping  efforts.    They  each  had  common 
properties, however, including memory segmentation and 
at  least  three  hardware  states  for  use  in  implementing 
protection  rings  (as  illustrated  in  Figure  4):  One  for  the 
security kernel; one for the operating system; and one for 
applications.    The  primary  hardware  modification  that 
enabled  SCOMP  was  the  addition  of  support  for  four 
hardware rings and segmentation.   
Applications
Operating System 
Security 
Kernel 
Mandatory 
Policies 
Policies 
Discretionary 
Application 
Policies 
Figure 4: Hardware Protection Rings 
in 
the  most  protected 
Mandatory  access  control  policies  are  enforced  by 
the  security  kernel 
ring.  
Discretionary access control policies can also be enforced 
by  the  security  kernel,  or  can  be  enforced  by  the  OS 
depending  on  assurance  requirements. 
  Application 
policies  are  generally  enforced  by  the  applications 
themselves  or  by  the  operating  system.    In  fact,  the 
separation  of  the  operating  system  from  the  application 
programs  is  itself  an  application  policy  enforced  by  the 
operating system. 
3.7. Advances in the State of the Science 
This  epoch  culminating  in  the  prototyping  and 
fielding of security kernels contributed the following key 
advances  to  the  state  of  the  science  of  computer  and 
network security: 
•  Reference Monitor Concept 
•  A Simple Security Kernel  
•  Formal Security Policy Models 
•  Discretionary vs. Mandatory Access Control Policies 
•  Hardware Rings and Segmentation  
4.  Available Commercial Evaluations 
to  some  security  policy.  The  key 
The next epoch culminated in an ability to procure a 
commercial  system  that  is  demonstrably  secure  with 
respect 
to  a 
“demonstrably  secure”  system  is  a  scientifically  based 
evaluation.    The  need  to  independently  evaluate  the 
ability of a system to enforce a given security policy was 
a  recognized  problem,  even  during  the  previous  epoch 
when  security-critical  systems  were  largely  built  in 
controlled  environments  by  cleared  programmers.    The 
need  to  evaluate  systems  becomes  more  acute  when 
standard commercial products are  used, because there is 
no assurance that they do not contain elements obtained 
from an outside party who may in fact be hostile. 
Note  that  the  focus  of  this  epoch  was  the  ability  to 
obtain  evaluated  systems.  An  ability  to  obtain  evaluated 
subsystems  is  not  in  and  of  itself  sufficient  unless  the 
attacker is willing to agree to attack only the subsystems 
of your choosing – obviously an unreasonable constraint. 
4.1. How to Trust What You Don’t Build 
evaluations  because  Multics  was 
Multics  was  influential  in  generating  interest  in 
commercial 
a 
commercial product.   Before that, attempts to field secure 
systems  built  on  commercial  security  products  were 
characterized  by  rounds  of  penetrate  and  patch,  with 
emphatic assertion being the vendor’s argument of choice 
to explain a systems basis for security. 
  Previously, 
Amid the increased interest in an ability to evaluate 
commercial  products  during  the  mid  seventies,  the  Air 
Force  and  ARPA  sponsored  MIT  to  develop  auditable 
systems  [25]. 
  This  effort  concluded  that  building 
auditable  systems  required  certain  forms  of  hardware 
support. 
there  did  not  exist  many 
construction  techniques  for  building  systems  whose 
security could be assessed after-the-fact.  There were ad-
hoc techniques and design standards, but little in the way 
of reproducible theory on how to architect such a system. 
The  MIT  project  recognized  this  as  a  hard  problem 
and  identified  a  number  of  solutions  components.    This 
effort articulated the notion of layering software modules 
previously  identified  by  Parnas  [26].  This  effort  also 
solved  challenges 
to  process  management, 
resulting in the definition of a two-level scheduler.  Issues 
of 
inter-process 
communication  were  a  serious  challenge,  with 
the 
contemporary  strategies  of  message  passing  and  P&V 
semaphores not suitable for the task.  This resulted in the 
invention  of  eventcounts  and  sequencers  [27]  for  secure 
inter-process communication.  
flow  associated  with 
information 
related 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:10:17 UTC from IEEE Xplore.  Restrictions apply. 
The  MIT  project  succeeded  in  offering  solutions  to 
all of the hard problems that stood in the way of building 
auditable operating systems.  
4.2. Formal Methods and Verification 
A major step that enables a independent evaluation of 
products  was  the  development  of  formal  methods  [28].  
At one point, there were three tools approved for use by 
the  NCSC:  FDM,  HDM,  Gypsy.    One  of  the  most 
significant developments  was the Fiertag  flow tool [29]. 