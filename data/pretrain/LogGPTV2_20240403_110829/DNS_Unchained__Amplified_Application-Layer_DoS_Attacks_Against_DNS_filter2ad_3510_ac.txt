point of our packet capturing. Below them are the number of IP addresses we
found.
4 170 710 resolvers responded to our scan query, of which 3097203 answers
had a TTL of zero. For the same day (2017-08-02), Shadowserver’s DNS scan [45]
reports 4 198 025 resolvers found, i.e., a deviation of just 0.7. The scan shows
that 74.3% of all resolvers honor TTL=0 and they could be used for attacks.
Of those resolvers that enforce a minimal non-zero TTL in the response, most
enforce large TTLs, making them unsuitable for DNS Unchained attacks. The
ten most common TTL values we found are multiples of ten or 60. In decreasing
order of occurrence they are 300, 600, 3600, 1, 30, 900, 60, 150, 14400, and 20,
which taken together account for 24.8% (1033419) of all responses.
150
J. Bushart and C. Rossow
Fig. 2. Connections between diﬀerent resolver types. Our scanner (S) ﬁnds open for-
warder (OF) and open recursive resolver (ORR). A forwarder forwards the query to
one or multiple recursive resolver (RR). Recursive resolver (RR and ORR) query the
authoritative name server (ANS). Dashed arrows mark optional connections, like query-
ing multiple recursive resolver or sending a response to our scanner. An empty arrow
head marks a query response.
4.2 Ampliﬁcation
After seeing that the vast majority of resolvers does not cache TTL=0 RRs, we
now measure how much ampliﬁcation in-the-wild resolvers would enable. The
ampliﬁcation factor is determined by the maximum number of elements of the
chain that will be requested by each resolver. We thus conﬁgured a chain of 100
RRs and requested the ﬁrst element from each resolver. The last chain element
is an A record and all RRs carry TTL = 0.
Bind follows the chain 17 times, whereas PowerDNS and Unbound only per-
form 12 and 9 lookup steps, respectively. Knot Resolver performs 33 lookups.
Bind is the only implementation that consistently responds with a “no error”
status code. The other three reply with a SERVFAIL status code if the end of the
chain could not be reached.
Via our scans, we discovered 10054077 open resolvers and 178508 recursive
resolvers. Figure 2 gives an overview of the connections between scanner and
resolvers. Open resolvers are open to the Internet and can be used by anyone.
They can be recursive resolvers or simple forwarders, which forward the query to
a recursive resolver. Recursive resolvers perform the recursive lookup procedure
which we can detect at our ANS. We can count and distinguish the two types of
resolvers based on the traﬃc captured at our ANS. If the encoded IP address of
the scan target and the source IP address of the resolver querying our ANS are
identical, then the resolver is an open recursive resolver, otherwise the encoded
IP address belongs to an open forwarding resolver. We expect a much higher
number of open resolvers than recursive resolver, because as K¨uhrer et al. [24]
found, most open resolvers are routers or other embedded devices. There is little
reason for them to host a recursive resolver, because they require more resources.
DNS Unchained: Ampliﬁed Application-Layer DoS Attacks
151
Figure 3 shows how many resolvers support a given chain length. There are
clear spikes for common values like nine, used by Unbound and Microsoft DNS,
or 17 as used by Bind. Another spike is at length 21, yet we are not aware which
software causes it. The quick drop-oﬀ at the beginning is caused by resolvers,
which query the same domain from diﬀerent IP addresses often in the same
subnet. In these cases only one of the resolvers performs the full recursion, the
others stop early leading to the drop. This could be caused by open resolvers
querying multiple recursive resolvers in a short amount of time. Alternatively, it
might result from an attempt to pre-fetch data for multiple resolvers as soon as
one recursive resolver in the pool sees a new domain name.
Fig. 3. Supported chain length conﬁgurations for 178 508 recursive resolvers discovered
with a full Internet scan. The spike at nine corresponds to Unbound and Microsoft DNS
version; Bind shows up as the spike at 17. The cause of the 21-spike is unknown to us.
From the data we can conclude that resolvers do oﬀer a considerable ampliﬁ-
cation potential. Intuitively, the ampliﬁcation factor is the number of queries seen
by the target ANS in relation to the number of queries sent by the attacker. Fac-
tors larger than one mean the impact on the target is larger than the attacker’s
resources used for the attack. We can calculate the expected ampliﬁcation ratio
for all recursive resolvers by
(cid:2)∞
(cid:3)
i
i=1(
(cid:2)∞
2
i=1
(cid:4) × ni)
ni
where ni is the number of resolvers that support chains of length i. The formula
assumes that the ﬁrst element in the chain is hosted on the target ANS, which
is the more beneﬁcial setup for an attacker.
152
J. Bushart and C. Rossow
All resolvers together (178508) provide an ampliﬁcation factor of 7.59. Focus-
ing only on resolvers, which provide an ampliﬁcation factor >1 (chains of length
three or longer) results in an ampliﬁcation factor of 8.51 with 156481 available
resolvers. These numbers are lower bounds, because the early drop-oﬀ in Fig. 3 is
caused by resolvers that query the same domain name from diﬀerent IP addresses
(which we then conservatively count as individual resolvers).
We already mentioned in Sect. 3.2 that some ANSs do not follow CNAME
chains, even if they are authoritative for all domains. This is a performance
optimization reducing the work required to answer a query. For ANSs, which
do not follow chains, all elements of the chain can be hosted on the target ANS
thus an ampliﬁcation factor of 14.34 can be achieved resulting in 89% stronger
attacks. Eﬀectively, this removes the intermediary ANSs from the chain and all
resource records need to have a zero TTL value.
4.3 Overall Impact
Based on these observations, we conclude that CNAME chains enable for attacks
that are an order of magnitude larger (measured in queries per second) than
na¨ıve water torture attacks. In practice, ANSs can handle 400 000 qps to 2 500
000 qps (queries per second) [3,20,34,42]. An attacker only needs a fraction—
determined by the ampliﬁcation factor—of queries compared to that number.
Often even lower query rates are suﬃcient to overload the ANS, because the
ANS also receives (and has to process) benign queries.
A single chain, which is resolved by all non-caching resolvers, causes more
than a million queries to the target ANS (7.59 × 178508 × 75% (cid:2) 1016157).
Each resolver can be queried roughly every second per chain (assuming a low
RT TRT ). Using as few as two or three chains is enough to overload all commonly
deployed ANS. For three chains the attacker has to send 535 524 pps (packets
per second). A DNS query packet with a 20 character long domain name requires
104 B (including Ethernet preamble and inter-packet gap) for transmission over
the wire. The attacker needs 445.6 Mbit/s to overload even the fastest ANS.
In case the target ANS does not follow the CNAME chain, the stronger attack
can be used where all elements are hosted on the target ANS. A single chain
causes over 1.9 million queries (14.34 × 178508 × 75% (cid:2) 1919854) reducing the
required bandwidth for the attacker accordingly.
5 Countermeasures
We will now discuss countermeasures to reduce the impact of DNS application-
level attacks. First, we cover the authoritative view, how zones could be managed
and the eﬀect of response rate limiting. Then we look at the behavior of recursive
resolvers and how they could reduce the impact on ANSs.
DNS Unchained: Ampliﬁed Application-Layer DoS Attacks
153
5.1 Identiﬁcation and Remedy by ANSs
A hard requirement for the proposed attack is that the attacker can create CNAME
RRs on the target ANS. This gives the target ANS the power to inspect and
deny problematic or malicious conﬁgurations or completely remove zones from
the ANS.
Detection of CNAME Chains. Zone ﬁles for the DNS Unchained require
several CNAME records pointing to external domains. If the attacker chooses
random or pseudo-random domain names, ANSs can use this as an indicator
for an attack. The target ANS operator could additionally check the target of
CNAMEs and discourage (or even forbid) CNAMEs that point to CNAME RRs in other
domains (which is already discourage according to the speciﬁcation). Exceptions
are likely required for content delivery networks and cloud provider. Especially
CNAME chains, i.e., several entries that eventually lead back to the same zone are
not useful, because both records are controlled by the same entity.
The ANS operator needs to implement periodic checks of all zones with
CNAME entries. Only checking RRs during creation is insuﬃcient, as the attacker
can build the chain such that no CNAME points to another CNAME during cre-
ation. Given the same domains as in Listing 1, the attacker would ﬁrst cre-
ate “a.target-ans.com.” while the target domain (“b.intermediary.org.”)
either does not exist or only contains other types, e.g., of type A. Checking the
RR for “a.target-ans.com.” will not show any suspicious behavior. Now the
same steps are repeated with “b.intermediary.org.”. This forces a non-trivial
amount of work on the ANS. A too long periodicity in the checking would allow
the attacker to use the time between checks for the attack, thus the checks have
to be somewhat frequent.
Lower Limit for Time-to-Live (TTL) Values. In contrast to water torture
attacks, chaining attacks fall apart if the chain’s RRs are cached. Using a random
preﬁx to circumvent caching is only possible for the speciﬁc combination of using
DNAME RRs and abusing only those resolvers that do not support DNAME. Thus,
forcing a minimal TTL of only a few seconds will have considerable impact, as it
1s+RT TRT .
limits the per-resolver query frequency to
Thus, a 10 s TTL will reduce the impact by roughly a factor of ten. However,
an attacker can use more chains if a minimal TTL is enforced, which makes
the setup more complicated. On the one hand, CNAME RRs with short (or zero)
TTLs are used also for benign reasons, e.g., to implement DNS-based failover.
On the other hand, in light of chaining attacks, we consider serving A and AAAA
records with short TTLs as the better solution, which also closer resembles the
desired semantics. Note, that a CNAME RR oﬀers an additional canonical name
for an already existing record, which is a relationship that rarely changes (and
thus allows for non-zero TTLs).
TTL+RT TRT compared to #chains
#chains
154
J. Bushart and C. Rossow
5.2 Response Rate Limiting (RRL)
Response Rate Limiting (RRL) is an eﬀective technique to counter standard
DNS-based ampliﬁcation attacks. If DNS servers are abused for reﬂective ampli-
ﬁcation attacks [24,44], the attacker sets the request’s source to the IP address of
the victim. In turn, resolvers unknowingly ﬂood the victim with DNS responses.
To prevent such abuse, resolvers can implement IP address-based access control,
which eﬀectively turns them into closed resolvers.
Yet this is not an option for intended open resolvers (e.g., Google DNS,
Quad9, etc.) and especially not for ANSs, as they have to be reachable by the
entire Internet. Here, RRL plays an important role. RRL limits the frequency
of how fast a client IP address can receive responses. The beneﬁt for reﬂection
attacks is clear, where a single source (the victim) seemingly requests millions
of requests and now only faces a fraction of the actual responses due to RRL.
In principle, RRL also seems to mitigate chaining attacks. Yet enabling RRL
has its downsides, especially if resolvers hit a rate limit conﬁgured at an ANS.
Resolvers will then retry queries, lacking an answer, which again increases the
load on the ANS. Filtering all resolver traﬃc can even increase the incoming
traﬃc ten-fold as observed by Verisign during a water torture attack [51, p. 24].
Additionally, RRL is implemented with a slip rate, which speciﬁes how often
the ANS will answer with a truncated response instead of dropping the packet.
For example, a slip rate of two results in a truncated answer for every second
query, the other times the query is dropped. Truncated responses then cause the
resolver to retry the connection using TCP instead of UDP, which drastically
increases the overall processing overhead for the ANS.
An ideal RRL conﬁguration would thus never limit resolvers, as this may
actually increase the required resources for the ANS in case of application-layer
attacks. Filtering or rate limiting needs to be performed closer to the source.
Na¨ıvely, one could deploy RRL at resolvers to rate limit the initial attack requests
(“chain starts”) sent to them. However, then again the per-resolver request fre-
quency is as low as one request per second, which would only be blocked by an
overly aggressive RRL conﬁguration. Even worse, if attacks are carried out via
botnets, even those RRL conﬁgurations would not slow down the attacks.
5.3 Back-Oﬀ Strategies
In case of packet loss at the target ANS, resolvers resend queries and thereby
cause additional attack traﬃc. It is thus important to rate limit outgoing queries
of resolvers and to implement suitable back-oﬀ strategies in order to give over-
loaded ANSs the chance to recover.
To assess how resolvers act in such situations, we have measured how four
resolver implementations behave when querying a zone with two ANSs of which
both are not reachable. Bind sends a total of ﬁve packets with a delay of 800 ms
in between packets. The ANS is chosen at random. After the third failed packet,
Bind has an exponential back-oﬀ with factor two. PowerDNS only sends out two
packets in total with a delay of 1500 ms in between. Unbound sends in total the
DNS Unchained: Ampliﬁed Application-Layer DoS Attacks
155
most queries with range2730. Worse, Unbound always sends two queries as a
pair, which might go to the same or a diﬀerent ANS. There is a delay of 375 ms
between the pairs, which is doubled every two to four pairs. Knot has the most
complicated retry strategy. Knot starts with sending UDP queries alternating to
both servers, with a delay of 250 ms in between. After a total of two seconds, two
TCP queries are sent to the ﬁrst ANS, with a delay of 1000 ms between them.
Six seconds after the start the same pattern of UDP and TCP queries is sent to
the second ANS.
Bind’s and PowerDNS’s behavior are not problematic, as the number of
retries is small and retry delay high. Especially problematic for Unbound is that
it sends two identical queries to the same ANS without a delay between. Delaying
retries is a good balance between providing fast answers (in case of packet loss)
and not sending duplicate queries (in case of high round trip times). A delay of
250 ms between retries will cause unnecessary retries for many users. With our
Internet scan we found that 9045 recursive resolvers (14.9%) have RTTs larger
than 250 ms to both our ANSs and additional 19 773 resolvers (32.6%) have such
a high RTT to one of our ANSs.
An additional strategy is serving stale cache records [26]. Stale cache records
are records in the resolver’s cache of which the TTL has expired. A resolver
can use them based on the assumption that normally records contain working
data, even if the TTL has expired (e.g., IP addresses change less often than the
TTL of records expires). This technique is not new and already implemented
in Bind 9.12 [29] and used by OpenDNS [35] and Akamai [27]. The usabil-
ity improves as client will receive an answer, which likely is usable, instead of
receiving an error and failing to connect.
5.4 Recursion Depth Limit