which a principal could transfer its control to another principal. Entry points
are speciﬁed by the developer on a per-principal basis, yet some of them can
also be declared as global shared. For the global shared data objects and entry
points, SILVER virtually organizes them in to a global low-integrity protection
domain denoted as S−. We deﬁne the set of rules that govern protection domain
activities as follows:
Data creation. A principal p can create data objects of either integrity level
in its own protection domain. p can also degrade any high integrity data object
d ∈ Dp
Integrity protection. A data object can only be possessed by only one princi-
pal at any time. A principal p can write to a data object d iﬀ d ∈ Dp. p can read
− directly, p has the capability
from d iﬀ d ∈ Dp
to increase the integrity level of d via an endorsement API provided by SILVER.
Data communication. In SILVER, data communications are achieved by mov-
ing data objects from one protection domain to another. In order to send data
to another principal q, p can move its data object d ∈ Dp to low integrity part
−. However, to ensure that d is safe in regard to
of domain Sq so that d ∈ Dq
the integrity of q, d is kept to be in low integrity and cannot be read by q until
+).
q sanitizes and endorses the input data and render d high integrity (d ∈ Dq
Cross-domain calls. Another important method for inter-domain communica-
tion is through calling remote functions exported by other principals. Exporting
functions to a principal q is achieved by creating entry point objects in q’s do-
main. To prevent the abuse of code of a protection domain principal, SILVER
guarantees that calling through entry points granted by p is the only way to
transfer control to principal p. Data transfers through cross-domain calls must
obey the previous data communication rules.
Protection domain hierarchy. Besides mutually untrusted principals, SIL-
VER introduces protection domain hierarchy to accurately express one-way trust
+ to low integrity level so that d ∈ Dp
−.
+. While p cannot read d ∈ Dp
in practice (e.g., OS kernel and untrusted extensions). In such case, parent prin-
cipal has full privilege of its child protection domain in terms of object access
and creation.
7
3 System Design and Implementation
3.1 Overall Design
Fig. 1. The architecture of the SILVER framework.
To design a run-time system which enforces our model stated in Section 2.4,
SILVER exploits several architectural (hardware and virtualization) features to
achieve strong isolation and a coarse-grained, OS-agnostic access control mecha-
nism based on page permissions. On top of these facilities, we design a subsystem
for Linux kernel to achieve accountability and ﬁne-grained security control. The
kernel subsystem includes a speciﬁcally designed kernel memory allocator imple-
menting the core functionality of protection domain primitives, a kernel object
registry for accounting kernel objects and supporting reference check, and a set
of kernel APIs exported to principals for controlling security properties of their
data, performing secure communication and granting capability to other princi-
pals. Figure 1 illustrates the overall design of SILVER’s architecture, with the
components of SILVER in gray. The entire framework is divided into two layers:
the VMM layer and OS subsystem layer, respectively. The reference monitor
and architectural-related mechanisms are placed in the VMM layer to achieve
transparency and tamper-proof.
3.2 The VMM Layer Design
The VMM layer components consist the bottom-half of the SILVER architecture.
These components are responsible for enforcing hardware protection to establish
protection domain boundaries, as well as providing architectural-level primitives
8
(e.g., page permission control, control transfer monitoring) for upper-layer com-
ponents in the OS-subsystem.
In SILVER, each principal is conﬁned within a dedi-
Principal isolation.
cated, hardware-enforced virtual protection domain realized by the hypervisor.
The protection domain separation is achieved by creating multiple sets of HAP
(hardware-assisted paging) tables for memory virtualization, one table dedicated
for each virtual protection domain. Upon a protection domain transfer, instead
of modifying HAP table entries of the current domain, the hypervisor switches to
a diﬀerent HAP table with preset permissions. Using such layer of indirection,
each principal could have its own restricted view of the entire kernel address
space, while the shared address space paradigm is still preserved. Furthermore,
by leveraging IOMMU tables, the VMM enables a principal to control DMA
activities within its protection domain by explicitly exporting DMA-write per-
mission to other principals and designating DMA-writable pages in its address
space. The VMM prohibits any other DMA writes to the protection domain.
Finally, to prevent untrusted code tampering with the architectural state (e.g.,
control registers, segment selectors, and page table pointer) of other protection
domains or the OS kernel, the hypervisor saves all the corresponding hardware
state of one protection domain before the control transfers to another subject,
and restores the saved invariant values once the control is switching back.
Mapping security labels to page permissions. The hypervisor in SILVER
also provides a page-based access control mechanism using hardware virtualiza-
tion. In speciﬁc, it exports a small hypercall interface to the OS subsystem of
SILVER, allowing it to associate security labels to kernel physical pages. The
low-level access control primitives are implemented by mapping security labels to
page permissions (i.e., read, write, execute) in each principal’s HAP table, which
deﬁnes whether certain pages can be accessed by the principal via which per-
missions. In section 3.3, we further describe how SILVER achieves ﬁne-grained
data access control on top of these page-based mechanisms.
Securing control ﬂow transfer. By setting up NX (execution disable) bits on
corresponding HAP table entries representing pages owned by other principals,
the hypervisor is able to intercept all control transfers from/to a protection
domain through execution exceptions. Therefore, the reference monitor is fully
aware which principal is currently being executed by the processor and uses
this information to authenticate principals for the OS subsystem. The reference
monitor then validates the  against the
control transfer capability and the set of entry points designated by the owner
principal of the protection domain, and denies all the illegal control transfers. To
ensure the stack isolation and data safety during cross-domain calls, whenever
a call is made by the protected code to an untrusted principal, the hypervisor
forks a private kernel stack from the current kernel stack for untrusted execution,
and it changes the untrusted principal’s HAP table mapping of the stack pages
to point to the new machine frames of the private stack. Since both virtual
address and (guest) physical address of the stack are kept the same, untrusted
9
code will have the illusion that it operates on the real kernel stack so that
the original kernel stack semantics are preserved. After the call ﬁnishes, the
hypervisor joins the two stacks by propagating legit changes from the private
stack to the real kernel stack frames, guaranteeing that only modiﬁcations to its
own stack frames are committed. In this way, SILVER enforces that all principals
have read permission to the entire kernel stack, but only have write permission
to their own stack frames.
3.3 OS Subsystem Design
The OS subsystem is responsible for achieving ﬁne-grained protection domain
mechanism and providing APIs to kernel programs. It leverages the architectural
primitives provided by the VMM layer by issuing hypercalls to the VMM.
Kernel memory allocator The kernel memory allocator in SILVER is re-
sponsible for managing dynamic kernel objects according to the rules deﬁned
in Section 2.4, as well as providing primitives to kernel principals for control-
ling security properties of their data objects. It leverages the hypercall interface
provided by the VMM layer for labeling physical page frames and manipulat-
ing page permissions for diﬀerent principals. Based on these mechanisms, the
allocator achieves the following key functionality: (1) it allows principals to dy-
namically create objects within speciﬁed protection domain and integrity levels.
(2) It enables a principal to endorse or decrease the integrity level of its objects
at run time; (3) It allows a principal to transfer its data objects to be a low-
integrity data object in a contracted protection domain for passing data; (4) It
restricts principals from accessing the global name space (i.e., kernel virtual ad-
dress) to refer objects outside of its domain and provide access control according
to the rules.
Our design is an extension to the SLUB allocator [4] of Linux, which manages
the dynamic allocation and deallocation of kernel objects. The SLUB allocator
maintains a number of cached objects, distinguished by size for allocation eﬃ-
ciency. Physical pages for cache are named slabs, which are initialized to have
multiple instances of a speciﬁc type of objects. Each slab has a freelist pointer
for maintaining a list of available objects. A slab can have four allocation states:
cpu slab (the current active slab for a given cpu), partial slab (portion of the
objects are used), full slab (slab objects fully used) and new slab (all objects
are available).
Organization. SILVER enhanced the Linux SLUB allocator by introducing
heterogeneity to slabs for SLUB caches. In SILVER, each slab is associated with
an extra label , and according to the label, it is restricted
to contain kernel objects of the speciﬁed integrity level owned by the principal.
The memory allocator achieves the slab access control by issuing hypercalls to
the VMM layer, labeling and setting up page permissions. Figure 2 illustrates the
organization of two partial slabs from the same SLUB cache but with diﬀerent
owner principal and integrity levels. Their heterogeneous labels will eventually
10
freelist
metadata
Label:
Free
Object
Used
Object
Free
Object
Used
Object
partial_list
...
1
fork
freelist
metadata
join
3
slab perm.
principal p: rw-
principal q: ---
Label:
Free
Object
Free
Object
2
Used
Object
Free
Object
...
slab perm.
principal p: ---  
(can create object)
principal q: rw- 
(read by endorsement func.)
Fig. 2. The layout of two slabs of the same slub cache involved in a service-based
communication.
result in diﬀerent page permissions in principals’ HAP table, preventing princi-
pals from accessing objects that are disallowed by the access control rules.
Allocation and Deallocation. The kernel memory allocator in SILVER pro-
vides a family of secure allocation APIs (e.g., kmalloc pd()) for protection do-
main principals. These APIs follow the similar semantics of kmalloc family
functions in Linux, except for having two extra parameters to designate the
principal ID and integrity level of the object allocation. The work ﬂow of the
allocation procedure is described in Algorithm 1. During slab selection, SILVER
must guarantee to pick the slab that matches the security model rather than
to choose the ﬁrst available objects from cpu slab or partial slabs. Once a
new slab is created, SILVER must register the label to the VMM to establish
principal access control before using it. The deallocation procedure is similar as
the SLUB allocator, with extra permission checks on the requested slab. The
memory allocator also provides APIs to principals for changing the integrity
level of their objects as building blocks for data communication.
Support for secure communication As a major task, the OS subsystem in
SILVER is responsible for oﬀering secure primitives to principals for exchanging
data, with the strong guarantee of integrity. The data communication is governed
by the rules deﬁned in Section 2.4. According to the model, using direct memory
sharing to pass high-integrity data is prohibited in SILVER. Instead, SILVER
provides primitives for two primary types of data communication: transfer-based
communication and service-based communication. In transfer-based communi-
cation, a principal p sends one of its own data object d to another principal q.
After that, d will become a (low-integrity) data object of Sq, and can no longer
be accessed by p.
In SILVER’s implementation, The data object transfer is conducted by the
memory allocator by moving data object from one slab to another. In this case,
principal p will invoke the API call pd transfer object, providing its object and
q’s principal id as input. The memory allocator locates the particular slab (label:
) that contains d, removing d from that slab, and copying d to a
Algorithm 1 The procedure for handling allocation requests from a protection
domain principal
1: if
cpu slab matches  of the requested object and freelist is
not empty then
label  of
current
11
return the ﬁrst available object in the freelist
2:
3: end if
4: Try to ﬁnd a partial slab with the matching label
5: if partial slab found then