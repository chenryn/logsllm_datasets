is needed, and the cost of evaluating an XOR gate is re-
duced from a decryption operation to a bitwise XOR.
This technique is only secure when the encryption
scheme satisﬁes certain security properties. The solution
provided by the authors is
Enc(X||Y,K) = H(X||Y )⊕ Z,
where H : {0,1}2k (cid:55)→ {0,1}k is a random oracle. Re-
cently, Choi et al. [6] have further shown that it is
to instantiate H(·) with a weaker crypto-
sufﬁcient
graphic primitive, 2-circular correlation robust func-
tions.
Our system instantiates this primitive with
H(X||Y ) = SHA-256(X||Y ). However, when AES-NI
instructions are available, our system instantiates it with
Hk(X||Y ) = AES-256(X||Y,k), where k is the gate index.
4.3 Garbled Row Reduction
The GRR (Garbled Row Reduction) technique suggested
by Pinkas et al. [30] is used to reduce the communication
overhead for non-XOR gates. In particular, it reduces the
size of the garbled truth table for 2-fan-in gates by 25%.
Recall that in the baseline Yao’s garbled circuit, both
the 0-key and 1-key for each wire are randomly chosen.
After the free-XOR technique is integrated, the 0-key and
1-key for an XOR gate’s output wire depend on input key
and R, but the 0-key for a non-XOR gate’s output wire is
still free. The GRR technique is to make a smart choice
for this degree of freedom, and thus, reduce one entry in
the garbled truth table to be communicated over network.
In particular, the generator picks (Z0,Z1,πz) by letting
Zg(0⊕πx,0⊕πy) = H(X0⊕πx||Y0⊕πy), that is, either Z0 or Z1
is assigned to the encryption mask for the 0-th entry of
the GT Tg, and the other one is computed by the equa-
tion Zb = Z1⊕b ⊕ R. Therefore, when the evaluator gets
(X0⊕πx ,Y0⊕πy), both X0⊕πx and Y0⊕πy have rightmost bit
0, indicating that the 0-th entry needs to be decrypted.
However, with GRR technique, she is able to retrieve
Zg(0⊕πx,0⊕πy) by running H(·) without inquiring GT Tg.
Pinkas et al. claimed that this technique is compatible
with the free-XOR technique [30]. For rigorousness pur-
poses, we carefully went through the details and came
up with a security proof for our protocol that conﬁrms
this compatibility. The proof will be included in the full
version of this paper.
4.4 Random Seed Checking
Recall that the cut-and-choose approach requires the
generator to construct multiple copies of the garbled cir-
cuit, and more than half of these garbled circuits will
be fully revealed, including the randomness used to con-
struct the circuit. Goyal, Mohassel, and Smith [11] there-
fore pointed out an insight that the evaluator could exam-
ine the correctness of those check circuits by receiving
a hash of the garbled circuit ﬁrst, acquiring the random
seed, and reconstructing the circuit and hash by herself.
This technique results in the communication overhead
for check circuits independent of the circuit size. This
technique has two phases that straddle the coin-ﬂipping
protocol. Before the coin ﬂipping, the generator con-
structs multiple copies of the circuit as instructed by the
cut-and-choose procedure. Then the generator sends to
the evaluator the hash of each garbled circuit, rather than
the circuit itself. After the coin ﬂipping, when the eval-
uation circuits and the check circuits are determined, the
generator sends to the evaluator the full description of
the evaluation circuits and the random seed for the check
circuits. The evaluator then computes the evaluation cir-
cuits and tests the check circuits by reconstructing the
circuit and comparing its hash with the one received ear-
lier. As a result, even for large circuits, the communi-
cation cost for each check circuit is simply a hash value
plus the random seed. Our system provides that 60% of
the garbled circuits are check circuits. Thus, this opti-
mization signiﬁcantly reduces communication overhead.
4.5 Working with Large Circuits
A circuit for a reasonably complicated function can eas-
ily consist of billions of gates. For example, a 4095-bit
edit distance circuit has 5.9 billion gates. When circuits
grow to such a size, the task of achieving high perfor-
mance secure computation becomes challenging.
An (I + 2C)-time solution Our solution for handling
large circuits is based on Huang et al.’s work [13], which
is the only prior work capable of handling large circuits
(of up to 1.2 billion non-XOR gates) in the semi-honest
setting.
Intuitively, the generator could work with the
evaluator in a pipeline manner so that small chunks of
gates are being processed at a time. The generator could
start to work on the next chunk while the evaluator is still
processing the current one. However, this technique does
not work directly with the random seed checking tech-
nique described above in Section 4.4 because the genera-
tor has to ﬁnish circuit construction and hash calculation
before the coin ﬂipping, but the evaluator could start the
evaluation only after the coin ﬂipping. As a result, the
generator needs a way to construct the circuit ﬁrst, wait
for the coin ﬂipping, and send the evaluation circuits to
the evaluator without keeping them in memory the whole
time. We therefore propose that the generator constructs
the evaluation circuits all over again after the coin ﬂip-
ping, with the same random seed used before and the
same keys for input wires gotten from OT.
We stress that when fully parallelized, the second con-
struction of an evaluation circuit does not incur overhead
to the overall execution time. Although we suggest to
construct an evaluation circuit twice, the fact is that ac-
cording to the random seed checking, a check circuit is
already being constructed twice—once before the coin
ﬂipping by the generator for hash computation and once
after by the evaluator for correctness veriﬁcation. As a
result, when each generator-evaluator pair is working on
a single copy of the garbled circuit, the constructing time
for a evaluation circuit totally overlaps with that for a
check circuit. We therefore achieve the overall computa-
tion time I +2C mentioned earlier, where the ﬁrst C is for
the generator to calculate the circuit hash, and the other
C is either for the evaluator to reconstruct a check circuit
or for both parties to work on an evaluation circuit in a
pipeline manner as suggested by Huang et al. [13].
Achieving an (I + C)-time solution We observe that
there is a way to achieve I +C computation time, which
exactly matches the running time of Yao in the semi-
honest setting. This idea, however, is not compatible
with the random-seed technique, and therefore repre-
sents a trade-off between communication and computa-
tion. Recall that the generator has to ﬁnish circuit con-
struction and hash evaluation before beginning coin ﬂip-
ping, whereas the evaluator can start evaluating only af-
ter receiving the coin ﬂipping results. The idea is to run
the coin ﬂipping in the way that only the evaluator gets
the result and does not reveal it to the generator until the
circuit construction is completed. Since the generator
is oblivious to the coin ﬂipping result, she sends every
garbled circuit to the evaluator, who could then either
evaluate or check the received circuit. In order for the
evaluator to get the generator’s input keys for evaluation
circuits and the random seed for the check circuits, they
run an OT, where the evaluator uses the coin ﬂipping re-
sult as input and the generator provides either the ran-
dom seed (for the check circuit) or his input keys (for the
evaluation circuit). After the generator completes circuit
construction and reveals the circuit hash, the evaluator
compares the hash with her own calculation, if the hashes
match, she proceeds with the rest of the original protocol.
Note that this approach comes at the cost of sacriﬁcing
the random seed checking technique and its 60% savings
in communication.
Working Set Optimization Another problem encoun-
tered while dealing with large circuits is the working
set minimization problem. Note that the circuit value
problem is log-space complete for P. It is suspected that
L(cid:54)=P, that is, there exist some circuits that can be evalu-
ated in polynomial time but require more than logarith-
mic space. This open problem captures the difﬁculty of
handling large circuits during both the construction and
evaluation, where at any moment there is a set of wires,
called the working set, that are available and will be ref-
erenced in the future. For some circuits, the working set
is inherently super-logarithmic. A naive approach is to
keep the most recent D wires in the working set, where
D is the upper bound of the input-output distance of all
gates. However, there may be wires which are used as
inputs to gates throughout the entire circuit, and so this
technique could easily result in adding almost the whole
circuit to the working set, which is especially problem-
atic when there are hundreds of copies of a circuit of
billions of gates. While reordering the circuit or adding
identity gates to minimize D would mitigate this prob-
lem, doing so while maintaining the topological order of
the circuit is known to be an NP-complete problem, the
graph bandwidth problem [9].
Our solution to this difﬁculty is to pre-process the cir-
cuit so that each gate comes with a usage count. Our
system has a compiler that converts a program in high-
level language into a boolean circuit. Since the compiler
is already using global optimization in order to reduce
the circuit size, it is easy for the global optimizer to an-
alyze the circuit and calculate the usage count for each
gate. With this information, it is easy for the genera-
tor and evaluator to decrement the counter for each gate
whenever it is being referenced and to toss away the gate
whenever its counter becomes zero. In other words, we
keep track of merely useful information and heuristically
minimize the size of the working set, which is small com-
pared with the original circuit size as shown in Table 1.
circuit size
wrk set size
AES
49,912
323
Dot64
4
460,018
711
RSA-32
1,750,787
235
EDT-255
15,540,196
2,829
Table 1: The size of the working set for various circuits
(sizes include input gates)
5 Boolean Circuit Compiler
Although the Fairplay circuit compiler can generate cir-
cuits, it requires a very large amount of computational
resources to generate even relatively small circuits. Even
on a machine with 48 gigabytes of RAM, Fairplay ter-
minates with an out-of-memory error after spending 20
minutes attempting to compile an AES circuit. This
makes Fairplay impractical for even relatively small cir-
cuits, and infeasible for some of the circuits tested in this
project. One goal of this project was to have a general
purpose system for secure computation, and so writing
application speciﬁc programs to generate circuits, a tech-
nique used by others [13], was not an option.
To address this problem, we have implemented a new
compiler that generates a more efﬁcient output format
than Fairplay, and which requires far lower computa-
tional resources to compile circuits. We were able to
generate the AES circuit in only a few seconds on a typi-
cal desktop computer with only 8GB of RAM, and were
able to generate and test much larger non-trivial circuits.
We used the well-known ﬂex and bison tools to generate
our compiler, and implemented an optimizer as a sepa-
rate tool. We also use the results from [30] to reduce 3
arity gates to 2 arity gates.
As a design decision, we created an imperative, un-
typed language with static scoping. We allow code, vari-
ables, and input/output statements to exist in the global
scope; this allows very simple programs to be written
without too much extra syntax. Functions may be de-
clared, but may not be recursive. Variables do not need to
be declared before being used in an unconditional assign-
ment; variables assigned within a function’s body that are
not declared in the global scope are considered to be lo-
cal. Arrays are a language feature, but array indices must
be constants or must be determined at compile time. If
run-time determined indices are required for a function,
a loop that selects the correct index may be used; this is
necessary for oblivious evaluation. Variables may be ar-
bitrarily concatenated, and bits or groups of bits may be
selected from any variable and bits or ranges of bits may
be assigned to; as with arrays, the index of a bit must be
determined at compile time, or else a loop must be used.
Note that loop variables may be used as such an index,
since loops are always completely unrolled, and there-
fore the loop index can always be resolved at compile
time. Additional language features are planned as future
work.
We use some techniques from the Fairplay compiler
in our own compiler. In particular we use the single as-
signment algorithm from Fairplay, which is required to
deal with assignments that occur inside of if statements.
Otherwise, our compiler has several distinguishing char-
acteristics that make it more resource efﬁcient than Fair-
play. The front end of our compiler attempts to gener-
ate circuits as quickly as possible, using as little memory
as possible and performing only rudimentary optimiza-
tions before emitting its output. This can be done with
very modest computational resources, and the intermedi-
ate output can easily be translated into a circuit for evalu-
ation. The main optimizations are performed by the back
end of the compiler, which identiﬁes gates that can be
removed without affecting the output of the circuit as a
whole.
Unlike the Fairplay compiler, we avoided the use of
hash tables in our compiler, using more memory-efﬁcient
storage. Our system can use one of three storage strate-
gies: memory-mapped ﬁles, ﬂat ﬁles without any map-
ping, and Berkeley DB. In our tests, we found that mem-
ory mapped ﬁles always resulted in the highest perfor-
mance, but that Berkeley DB is only sometimes better
than direct access without any mapping.
In the following sections, we describe these contribu-
tions in more detail, and provide experimental results.
5.1 Circuit Optimizations
The front-end of our compiler tends to generate inefﬁ-
cient circuits, with large numbers of unnecessary gates.
As an example, for some operations the compiler gener-
ates large numbers of identity gates i.e. gates whose out-
puts follow one of their inputs. It is therefore essential
to optimize the circuits emitted by the front end, particu-
larly to meet our system’s overall goal of practicality.
Our compiler uses several stages of optimization, most
of which are global. As a ﬁrst step, a local optimization
removes redundant gates, i.e. gates that have the same
truth table and input wires. This ﬁrst step operates on
a ﬁxed-size chunk of the circuit, but we have found that
there are diminishing improvements as the size of this
window is increased. We also remove constant gates,
identity gates, and inverters, which are generated by the
compiler and which may be inadvertently generated dur-
ing the optimization process. Finally, we remove gates