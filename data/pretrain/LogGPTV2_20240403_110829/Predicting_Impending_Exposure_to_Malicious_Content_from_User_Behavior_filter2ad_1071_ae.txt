### Exposed: Model Training and Evaluation

We empirically determined that models trained using data collected over a 15-day period perform well when used for predictions in the subsequent five days. Therefore, we selected different 20-day periods (with the first 15 days used for training and the last five for testing) to evaluate our approach. Specifically, we used five different 20-day periods, uniformly spread over three months of our data collection, starting from April 5th, 2017. We chose not to start from April 1st to allow the first few days of April to observe user behavior and initialize the Past-Behavior Features to a meaningful state.

### Malicious Page Classification

Similar to Section 4.3, we classified a page as malicious if it was listed in the Google Safe Browsing (GSB) database or appeared in GSB within two days of being accessed by a user (i.e., we set τ = 2). This required careful handling during DNN training. Specifically, when training a DNN at time \( t \), one cannot determine if accesses in the interval \( t - \tau + 1, \ldots, t \) appeared in GSB within the interval \( t + 1, \ldots, t + \tau \). To avoid mislabeled data, we excluded HTTP requests made in the interval \( t - \tau + 1, \ldots, t \) from training (in our case, we excluded HTTP requests made in \( t - 1 \) and \( t \)).

### Data Sampling and Training

To speed up the training process and minimize the use of private information, we uniformly sampled 5% of the HTTP requests from unexposed sessions during training. We did not sample exposed sessions due to their relatively small number. Overall, for each evaluation period, we used approximately 3,200,000 requests from unexposed sessions and 43,000 requests from exposed sessions for training. For testing, we had an average of 412,005 benign sessions (containing approximately 21,620,410 requests) and 277 exposed sessions (containing approximately 19,457 requests).

### Experiment Results

#### Prediction Accuracy
We first evaluated how accurately the DNNs predict exposure in advance. We measured the true-positive rate (TPR; the rate at which exposed sessions were correctly classified as exposed) and the false-positive rate (FPR; the rate at which unexposed sessions were incorrectly classified as exposed) at different times before exposure. In these experiments, we used all features: Contextual, Past-Behavior, and Self-Reported.

Figures 8(a) and 8(b) summarize the results, showing that the DNNs can predict exposure with good accuracy. For example, if the aim is to predict exposure at any time before it happens, it is possible to achieve an 87% TPR with only a 20% FPR. If a lower FPR is desired, it is possible to achieve a 75% TPR with a 10% FPR, or even a 32% TPR with a 1% FPR. Similar accuracy can be achieved even when predicting exposure far in advance. For instance, we can obtain a 74% TPR with a 20% FPR balance even when predicting exposure 30 seconds before it actually happens. This early detection opens a window of opportunity for various interventions to prevent exposure to malicious content.

#### Feature Influence
Next, we evaluated the influence of different types of features on the performance of the DNNs. We tested the DNNs' performance when combining Contextual Features with both Past-Behavior Features and Self-Reported Features, only Past-Behavior Features, only Self-Reported Features, or none. The results are shown in Figure 8(c). The accuracy of predictions is roughly similar in all cases—Contextual Features slightly benefit from Past-Behavior Features, but the interaction with Self-Reported Features is slightly detrimental. In summary, Contextual Features alone are sufficient to accurately predict exposure in the short term. Thus, accurate within-session predictive engines can be developed without the need to collect and store historical behavior information or self-reported user input, but rather by using available contextual information describing users' browsing activity.

### False Alarms and Baseline Rate

There is a significant imbalance between exposed and unexposed sessions. For example, at the operating point TPR=56% and FPR=3% in Figure 8(a), the system would make 56 true detections (out of 100) and approximately 3,000 false detections for every 100,000 sessions. This could impede the deployment of active defenses, such as terminating risky sessions or issuing warnings, which could lead to network unavailability or user habituation.

However, many of the suspected false positives are actually true positives. Checking services like VirusTotal one year after our field measurements, we found that approximately 71% of the 3,000 "false" positives observed at the TPR=56%, FPR=3% operating point were eventually flagged as malicious. This suggests that the system may actually achieve roughly 2,186 true positives and 870 false positives for every 100,000 sessions, corresponding to a TPR of 93% and an FPR of 1% with a ratio of roughly 2.4:97.6 between exposed and unexposed sessions.

### Performance and Scalability

On a machine equipped with a Xeon X5875 CPU (3.07GHz) and 128GB of memory, our system can classify approximately 1,300 feature vectors per second. Assuming that one webpage visit usually accounts for five HTTP requests on average, our system can handle about 260 page visits per second. We believe this can be further optimized, for example, through GPU computation.

### Discussion

#### Implications and Interventions
Our findings have several implications for possible interventions. Our short-term prediction approach may enable human-centered defenses, such as alerting users about potential risks before exposure. In certain networks, exposure to malicious content may be intolerable, and operators may terminate browsing sessions of users about to visit malicious pages. Additionally, our session-based prediction system can help prioritize traffic for expensive inspection, enabling elastic defenses and preventing the installation of third-party apps in risky contexts.

#### Reproducibility
Reproducibility is a challenge due to user-privacy concerns. We hope to help others reimplement our system and reproduce our results by open-sourcing the code used for computing features, training the neural networks, and evaluating them.

#### Future Enhancements
Future enhancements could include using additional, computationally more expensive features, such as domain-name reputation or redirection-graph features. Other machine-learning algorithms, such as recurrent neural networks, may also improve performance. Our approach could be extended to other networks, though new challenges may arise. Privacy concerns mandate minimizing the amount of user data required for training, and recent techniques might reduce user data collection even further.

### Conclusion

We developed a system to predict whether users will be exposed to malicious pages while browsing the web, and evaluated it using three months of HTTP traffic generated by over 20,000 users of a Japanese cellular provider in 2017. Our system can accurately predict exposure seconds before it occurs, potentially enabling proactive defenses. We also collected self-reported demographic and security-related data from the same users, finding that models solely relying on self-reported data are less accurate than those including behavioral data.

### Acknowledgments

We thank our anonymous reviewers and our shepherd, Tudor Dumitraş, for feedback that greatly improved the manuscript. Mahmood Sharif was partially supported through MURI grant W911NF-17-1-0370, and by CyLab at Carnegie Mellon University via a CyLab Presidential Fellowship.

### References

[References remain unchanged]