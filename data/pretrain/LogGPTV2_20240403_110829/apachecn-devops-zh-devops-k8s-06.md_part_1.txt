# 六、监控和记录
监控和记录是站点可靠性的关键部分。我们已经学习了如何利用各种控制器来处理我们的应用，以及如何利用服务和入口来服务我们的网络应用。接下来，在本章中，我们将学习如何通过以下主题跟踪我们的应用:
*   获取容器的状态快照
*   Kubernetes 的监测
*   普罗米修斯从 Kubernetes 收集指标
*   Kubernetes 的伐木概念
*   具有流动性和弹性研究的测井
# 检查容器
每当我们的应用行为异常时，我们肯定会想知道发生了什么，使用一切手段，如检查日志、资源使用情况、进程看门狗，甚至直接进入运行的主机来挖掘问题。在 Kubernetes 中，我们有`kubectl get`和`kubectl describe`可以查询部署状态，这将有助于我们确定应用是否已经崩溃或按照预期工作。
此外，如果我们想从应用的输出中知道发生了什么，我们还有`kubectl logs`，它将容器的`stdout`重定向到我们的终端。对于 CPU 和内存使用统计，我们还可以使用类似 top 的命令`kubectl top`。`kubectl top node`，概述节点的资源使用情况，`kubectl top pod `显示每个 pod 的使用情况:
```
# kubectl top node
NAME        CPU(cores)   CPU%      MEMORY(bytes)  MEMORY% 
node-1      42m          4%        273Mi           12% 
node-2      152m         15%       1283Mi          75% 
# kubectl top pod mypod-name-2587489005-xq72v
NAME                         CPU(cores)   MEMORY(bytes) 
mypod-name-2587489005-xq72v   0m           0Mi            
```
To use `kubectl top`, you'll need Heapster deployed in your cluster. We'll discuss this later in the chapter.
如果我们把原木之类的东西放在一个容器里，却没有送到任何地方，会怎么样？我们知道在一个正在运行的容器中有一个`docker exec` execute 命令，但是我们不可能每次都能访问节点。幸运的是，`kubectl`允许我们用`kubectl exec`命令做同样的事情。它的用法类似于 Docker。例如，我们可以在这样一个容器中运行一个外壳:
```
$ kubectl exec -it mypod-name-2587489005-xq72v /bin/sh
/ # 
/ # hostname
mypod-name-2587489005-xq72v  
```
这与通过 SSH 登录主机非常相似，它使我们能够使用我们熟悉的工具进行故障排除，就像我们在非容器世界中所做的那样。
# 忽必烈的控制板
除了命令行实用程序之外，还有一个仪表板，它聚合了我们刚刚在一个体面的网络用户界面上讨论的几乎所有信息:
![](img/00094.jpeg)
它实际上是 Kubernetes 集群的通用图形用户界面，因为它还允许我们创建、编辑和删除资源。部署它相当容易；我们只需要应用一个模板:
```
$ kubectl create -f \ https://raw.githubusercontent.com/kubernetes/dashboard/v1.6.3/src/deploy/kubernetes-dashboard.yaml  
```
该模板适用于启用了 **RBAC** ( **基于角色的访问控制**)的 Kubernetes 集群。如果您需要其他部署选项，请查看仪表板的项目存储库([https://github.com/kubernetes/dashboard](https://github.com/kubernetes/dashboard))。关于 RBAC，我们将在[第 8 章](08.html#5J99O0-6c8359cae3d4492eb9973d94ec3e4f1e)、*集群管理*中讨论。许多托管的 Kubernetes 服务，比如 Google Container Engine，在集群中预先部署了仪表板，这样我们就不需要自己安装了。要确定仪表板是否存在于我们的集群中，请使用`kubectl cluster-info`。
我们将看到 kubernetes-dashboard 正在运行...如果安装了的话。使用默认模板部署或由云提供商提供的仪表板服务通常是集群 IP。为了访问它，我们需要用`kubectl proxy.`在我们的终端和 Kubernetes 的 API 服务器之间建立一个代理，一旦代理启动，我们就可以在`http://localhost:8001/ui`访问仪表板。港口`8001`是`kubectl proxy`的默认港口。
As with `kubectl top`, you'll need Heapster deployed in your cluster to see the CPU and memory stats.
# Kubernetes 的监测
因为我们现在知道如何在 Kubernetes 中检查我们的应用，所以我们应该有一个机制来不断地这样做，以便在第一次发生时检测到任何事件，这是非常自然的。换句话说，我们需要一个监控系统。监控系统从各种来源收集指标，存储和分析收到的数据，然后对异常做出响应。在传统的应用监控设置中，我们至少会从基础架构的三个不同层收集指标，以确保服务的可用性和质量。
# 应用
我们在这个级别上关心的数据涉及应用的内部状态，这可以帮助我们确定服务内部发生了什么。例如，以下截图来自 Elasticsearch 漫威([https://www . elastic . co/guide/en/marvel/current/introduction . html](https://www.elastic.co/guide/en/marvel/current/introduction.html)，从第 5 版开始称为 **Monitoring** ，这是一个针对 Elasticsearch 集群的监控解决方案。它汇集了关于我们集群的信息，尤其是弹性搜索特定指标:
![](img/00095.jpeg)
此外，我们将利用分析工具和跟踪工具来检测我们的程序，这增加了维度，使我们能够以更精细的粒度检查我们的服务。尤其是现在，一个应用可能由几十个分布式服务组成。如果不使用跟踪工具，例如 OpenTracing([http://OpenTracing . io](http://opentracing.io))实现，识别性能问题可能会非常困难。
# 主持
主机级别的收集任务通常由监控框架提供的代理执行。代理提取并发送有关主机的综合指标，如负载、磁盘、连接或进程统计数据，以帮助确定主机的运行状况。
# 外部资源
除了前面提到的两个组件，我们还需要检查相关组件的状态。例如，假设我们有一个应用消耗一个队列并执行相应的任务；我们还应该关注度量标准，比如队列长度和消耗率。如果消耗率低，队列长度不断增长，我们的应用可能会遇到麻烦。
这些原则也适用于 Kubernetes 上的容器，因为在主机上运行容器几乎等同于运行进程。尽管如此，由于 Kubernetes 上的容器和传统主机上的容器利用资源的方式之间存在微妙的区别，我们在使用监控策略时仍然需要考虑这些差异。例如，Kubernetes 上的一个应用的容器会分布在多个主机上，也不会总是在同一个主机上。如果我们仍然采用以主机为中心的监控方法，那么为一个应用制作一个一致的记录将是非常辛苦的。因此，我们不应该只观察主机级别的资源使用情况，而是应该在监控栈中堆积一个容器层。此外，由于 Kubernetes 实际上是我们应用的基础设施，我们绝对也应该考虑它。
# 容器
如上所述，在容器级别收集的指标和我们在主机级别获得的指标几乎是一样的，尤其是系统资源的使用。尽管看似冗余，但这是帮助我们解决监控移动容器困难的关键。这个想法很简单:我们需要做的是将逻辑信息附加到指标上，比如 pod 标签或它们的控制器名称。通过这种方式，来自不同主机的容器的度量可以被有意义地分组。考虑下图；假设我们想知道在 **App 2** 上传输了多少字节( **tx** ，我们可以对 **App 2** 标签上的 **tx** 度量进行求和，得出 **20 MB:**
![](img/00096.jpeg)
另一个不同之处是，关于 CPU 限制的指标仅在容器级别报告。如果某个应用遇到性能问题，但主机上的 CPU 资源是空闲的，我们可以检查它是否受到相关指标的限制。
# 忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈
Kubernetes 负责管理、调度和编排我们的应用。因此，一旦某个应用崩溃，Kubernetes 肯定是我们首先要关注的地方之一。特别是，当新部署推出后发生崩溃时，相关对象的状态会立即反映在 Kubernetes 上。
总的来说，下图说明了应该监控的组件:
![](img/00097.jpeg)
# 获取 Kubernetes 的监控要点
对于监控栈的每一层，我们总能找到对应的收集器。例如，在应用级别，我们可以手动转储指标；在主机级别，我们会在每个盒子上安装一个度量收集器；至于 Kubernetes，有用于导出我们感兴趣的指标的 API，至少我们手头有`kubectl`。
说到容器级收集器，我们有哪些选择？也许在应用的映像中安装主机度量收集器可以完成这项工作，但是我们很快就会意识到，这可能会使我们的容器在大小和资源利用率方面过于笨拙。幸运的是，对于这样的需求已经有了一个解决方案，即 cAdvisor([https://github.com/google/cadvisor](https://github.com/google/cadvisor))，容器级度量收集器的答案。简而言之，cAdvisor 聚合了机器上每个运行容器的资源使用情况和性能统计。请注意，cAdvisor 的部署是每个主机一个，而不是每个容器一个，这对于容器化的应用来说更合理。在 Kubernetes 中，我们甚至不关心 cAdvisor 的部署，因为它已经嵌入到了 kubelet 中。
cAdvisor 可通过每个节点上的端口`4194`访问。在 Kubernetes 1.7 之前，cAdvisor 收集的数据也可以通过 kubelet 端口(`10250` / `10255`)收集。要访问 cAdvisor，我们可以在`http://localhost:8001/api/v1/nodes/:4194/proxy/`访问实例端口`4194`或通过`kubectl proxy`访问，或者直接访问`http://:4194/`。
以下截图来自 cAdvisor 网络用户界面。连接后，您将看到类似的页面。要查看 cAdvisor 获取的指标，请访问端点`/metrics`。
>![](img/00098.jpeg)
监控管线中的另一个重要组件是 Heapster([https://github.com/kubernetes/heapster](https://github.com/kubernetes/heapster))。它从每个节点检索监控统计数据，特别是在节点处理上的 kubelet，然后写入外部接收器。它还通过 REST 应用编程接口公开聚合度量。对于 cAdvisor 来说，Heapster 的功能听起来相当多余，但实际上它们在监控管道中扮演着不同的角色。Heapster 收集集群范围的统计数据；cAdvisor 是一个主机范围的组件。也就是说，Heapster 赋予了 Kubernetes 集群基本的监控能力。下图说明了它如何与集群中的其他组件交互:
![](img/00099.jpeg)
事实上，如果您的监控框架提供了一个类似的工具，也可以从 kubelet 中抓取指标，那么就没有必要安装 Heapster 了。然而，由于它是 Kubernetes 生态系统中的默认监控组件，许多工具都依赖于它，例如`kubectl top`和前面提到的 Kubernetes 仪表板。