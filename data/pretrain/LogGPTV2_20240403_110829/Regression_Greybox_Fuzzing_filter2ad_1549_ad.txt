AFL as a baseline allows us to conduct a fair evaluation with minimal
risk to construct validity.
AFLGo [6]. In order to compare regression greybox fuzzing
to directed greybox fuzzing, we chose a state-of-the-art directed
greybox fuzzer, called AFLGo. While many papers have since been
published on the topic of directed greybox fuzzing, none of the im-
plementations are publicly available for our comparison. We spent
several weeks to set up AFLGo for all 15 subjects (and more), but
failed, except for three subjects (see Section 5.3)Ðdespite the kind
help of the AFLGo authors. We succeeded for libgit2, libhtp, and ht-
slib. However, for five of fifteen subjects we failed to compile them.
These subjects either require a newer compiler version,7 or their
build process does not allow additional compiler flags. We failed
for the remaining seven subjects to compute the distance informa-
tion for the given commits, e.g., because the compiler-generated
call graph or control flow graphs are incomplete [9]. We make our
integration of AFLGo into Fuzzbench publicly available.
7AFLGo supports up to Clang version 4.0.
Session 7B: Fuzzing CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea21754.4 Setup and Infrastructure
The experiments are fully reproducible and where conducted with
the kind and generous assistance of the Fuzzbench team. According
to the default setup, each fuzzing campaign runs for 20 trials of 23
hours. Repeating each experiment 20 times reduces the impact of
randomness [16]. There is one fuzzing campaign for each subject-
fuzzer-trial combination. We run 4 fuzzers on 15 subjects 20 times.
We conduct over 3 CPU-years worth of fuzzing campaigns.
Each fuzzing campaign runs on its own machine, called run-
ner. A runner instance is a Google Cloud Platform (GCP) instance
(e2-standard-2), which has 2 virtual CPUs, 8GB of memory, and
30GB of disk space. The dispatch of all runner machines, and col-
lection of various fuzzer performance metrics is conducted on a
separate machine, called dispatcher. A dispatcher instance is a much
bigger GCP instance (n1-highmem-96) with 96 virtual CPUs, 624
GB of main memory, and 4TB of fast SSD disk storage. This virtual
setup is fully specified in our fork of Fuzzbench, which facilitates
to apply the repository and versioning concept to our experiments.
The entire network of dispatcher and runners is deployed and
teared down fully automatically. The generated corpus, the crash-
ing inputs, and the fuzzer logs are copied onto cloud storage (GCP
buckets). We collect all our performance metrics from there.
4.5 Reproducibility
We believe that reproducibility is a fundamental building block
of open science and hope that other researchers and practitioners
can reproduce and build on our work. For this reason, we make all
our tools, data, scripts, and even the experimental infrastructure
publicly available.
• https://github.com/aflchurn/aflchurnbench (infrastructure)
• https://github.com/aflchurn/aflchurn (tools)
• https://kaggle.com/marcelbhme/aflchurn-ccs21 (data+scripts)
4.6 Threats to Validity
Like for any empirical investigation there are threats to the validity
of the claims that we derive from these results. The first concern is
external validity and notably generality. First, our results may not
hold for subjects outside of this study. However, we conduct exper-
iments on a large variety of open-source C projects that are critical
enough that they were added to OSSFuzz. Our random sample of
subjects is representative of such open-source C projects. In order
to mitigate selection bias, we explicitly specify selection criteria
and follow a concrete protocol (Section 4.2). To further support
independent tests of generality, we make our entire experimental
infrastructure publicly available.
The second concern is internal validity, i.e., the degree to which
a study minimizes systematic error. Like for implementations of
other techniques, we cannot guarantee that our implementation
of regression greybox fuzzing into AFLChurn is without bugs.
However, we make the code publicly available for everyone to
scrutinize our code. To minimize errors during experimentation,
we use and extend an existing tool [1] and infrastructure [20]. In
order to account for the impact of randomness, we repeat each
experiment 20 times.
Table 2: Effectiveness of Regression Greybox Fuzzing
Mean TTE
#Crashing Trials
Mean #Crashes
Subject
libgit2
file
yara
libxml2
aspell
libhtp
openssl
grok
unbound
zstd
systemd
usrsctp
neomutt
openvswitch
picotls
AFL
00h 00m
00h 05m
00h 10m
00h 43m
02h 03m
03h 38m
05h 29m
01h 37m
10h 22m
16h 44m
-
-
-
-
-
AFLChurn Factor AFL AFLChurn Factor AFL AFLChurn Factor
1.5
1.1
0.8
0.9
1.0
2.8
0.8
0.4
1.6
2.5
-
-
-
-
-
00h 00m 0.5
00h 10m 2.0
00h 13m 1.3
00h 44m 1.0
01h 44m 0.8
02h 01m 0.6
03h 01m 0.6
01h 37m 1.0
06h 15m 0.6
09h 25m 0.6
21h 18m
∞
12h 46m
∞
-
-
-
-
-
-
71.50
5.25
20.45
704.20
7.65
156.50
6.60
4.20
9.25
0.25
0.05
2.05
0
0
0
20
20
20
20
20
20
20
18
17
2
0
0
-
-
-
20
20
20
20
20
20
20
19
18
4
1
8
-
-
-
48.05
1.0
4.70
1.0
25.70
1.0
1.0 777.95
7.60
1.0
55.95
1.0
8.70
1.0
9.85
1.1
5.90
1.1
2.0
0.10
∞ 0.00
∞ 0.00
0
0
0
-
-
-
1○
2○
3○
The third concern is construct validity, i.e., the degree to which an
evaluation measures what it claims, or purports, to be measuring. To
minimize the impact of irrelevant factors onto the evaluation of our
main hypothesis, we implement our technique into an existing tool
and use the existing tool as a baseline. Thus, the difference in results
can be attributed fully to these changes. To prevent AFLChurn
from gaining an unfair advantage, we maximize the number of
unrelated changes since the bug was introduced. For each subject,
instead of choosing the version right after the bug was introduced,
we choose the version right before the bug was fixed.
5 EXPERIMENT RESULTS
5.1 Presentation
For each of the first two research questions RQ.1 and RQ.2, we
summarize our main results in a table and a graph.
Tables 2 and 3 show the mean time-to-error, the number of crash-
ing trials, and the average number of unique crashes. The mean
time-to-error (Mean TTE) measures how long it took to find the first
crash in the given subject across all successful campaigns. However,
not all campaigns may be successful. Hence, the number of crash-
ing trials (#Crashing Trials) measures the number of successful
campaigns. In addition, in related work, we found it is common to
report the number of unique crashes. AFL clusters crashing inputs
according to the program branches they exercise. The mean number
of unique crashes (Mean #Crashes) reports this number.
Figures 5 and 6 show the results of our deduplication. For each
crashing input, we found the corresponding bug report in OSSFuzz.
For each deduplicated bug, fuzzer, and fuzzing campaign, we mea-
sure the time to discover the first crashing input that witnesses
the bug. The box plot summarizes the time-to-error across all cam-
paigns. For usrsctp, we were unable to reproduce the crashes during
deduplication (and it is not counted among the 20 regression bugs
we found). This is a well-known problem in OSSFuzz and relates
to the statefulness of a subject. In a stateful subject, the outcome
of the execution of an input depends on the current program state
which can be changed during the execution of previous inputs.
RQ1. Efficiency of Regression Greybox Fuzzing
Our main hypothesis is that a fuzzer that is guided towards code
that has changed more recently or more often is also more effi-
cient in finding regression bugs. We evaluated this hypothesis by
implementing AFLChurn and measuring various bug finding per-
formance variables on 15 different open-source C projects that are
available at OSSFuzz.
Session 7B: Fuzzing CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2176aspell_17187
●
●
●
●
●
●
●
●
●
●
●
●●●
●●
●
●●
●
●
●
●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
libgit2_11382*
●
●
●
●●
●
●
●
●
●
●
●
●
●
●●●●
●●●●●●●
●
●
●●●
●
●
●
●●●●●
●
●
●
●●●
systemd_14708*
●
0.5
0.4
0.3
0.2
0.1
0.0
20
15
10
5
0
20
15
10
5
0
)
s
r
u
o
h
n
i
(
h
s
a
r
c
t
s
r
i
f
o
t
e
m
T
i
4
2
0
0.009
0.006
0.003
0.000
20
15
10
5
0
file_13222*
●
●
●
●
●
●
●
●
●●
●
●
●●
●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
libhtp_17198*
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●
●
●
●
●
●
●
●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●●
●
●
●
●
● ●● ●
●
●
●
●●
●
●●
●
●
unbound_20308*
●
●
●
●
●
●●
●
●
●
●
●
●
● ●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
grok_24427
●
●
10.0
15
10
5
0
20
15
10
5
0
2.0
1.5
1.0
0.5
0.0
●
●
●
●
libxml2_17737*
●
●
●
●
●
●
●
●●
●
●
●
●
●●
●●●
●●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●●
●
yara_11945
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●