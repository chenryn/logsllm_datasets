intrusive, a decryption is not necessary. Based on the observable encrypted
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 505–507, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
506
R. Koch and G.D. Rodosek
network traﬃc, the user input is identiﬁed and weighted. Concurrently, the user
generating the network traﬃc is identiﬁed by keystroke dynamics. The therefor
necessary features are recovered by the timing of the network packets. The sys-
tem architecture consists of the following modules:
Traﬃc Clustering: The system records the timestamps of the network packets,
the payload sizes and the transmission directions. The gathered data is grouped
into clusters, whereas a cluster consists of an user input and the corresponding
answer of the server.
Command Evaluation: This is done by analysing the consecutive payload sizes
of the network packets. Timestamps are taken into consideration as well, e.g. for
the detection of server delays (for example, the delay when requesting the listing
of a directory is all the longer with the number of ﬁles in the directory). In the
ﬁrst step, probabilities for single command-answer-combinations are calculated.
Best values for each cluster are selected. After that, the probabilities for diﬀerent
sequences are generated. So, the ranking of the identiﬁed commands can change
based on the whole sequence of commands.
Strategy Analysis: Based on the identiﬁed commands, the strategy of the user
is being analysed: Diﬀerent sub-goals are deﬁned in an attack-tree by multiple
steps. E.g., the sub-goal root privileges can be achieved by exploitation, miscon-
ﬁgured programs, etc. Series of logically related but not necessarily complete
intrusion steps are being searched. If a number of subgoals can lead to an intru-
sion attempt, an alarm is raised.
User Identiﬁcation: Users of an encrypted connection are identiﬁed based on
their keystroke dynamics recovered from the encrypted network packets.
Policy Conformation: Based on the used sources, commands and the identiﬁed
user, the accounting and allowed resource usage is veriﬁed.
3 Results and Further Work
The modules Command Evaluation and User Identiﬁcation had been imple-
mented in a ﬁrst prototype. Our experiments have shown that both command
evaluation and user identiﬁcation are possible with our proposed method. For
the command evaluation, only a limited set is implemented at the moment.
This will be advanced especially to the system- and therefore attack-relevant
commands. For the strategy analysis, multiple attack-trees will be deﬁned and
integrated. After that, a summarizing evaluation will be implemented. The
completed prototype will be put into a broad test in the data center of the
University.
Security System for Encrypted Environments (S2E2)
507
References
1. Lippmann, R., Webster, S., Stetson, D.: The Eﬀect of Identifying Vulnerabilities
and Patching Software on the Utility of Network Intrusion Detection. In: Wespi, A.,
Vigna, G., Deri, L. (eds.) RAID 2002. LNCS, vol. 2516, p. 307. Springer, Heidelberg
(2002)
2. Goh, V.T., Zimmermann, J., Looi, M.: Experimenting with an Intrusion Detection
System for Encrypted Networks. Int. J. Business Intelligence and Data Mining 5(2),
172–191 (2010)
Towards Automatic Deduction and Event
Reconstruction Using Forensic Lucid and Probabilities
to Encode the IDS Evidence
Serguei A. Mokhov, Joey Paquet, and Mourad Debbabi
Concordia University, Montr´eal, Qu´ebec, Canada,
{mokhov,paquet,debbabi}@encs.concordia.ca
Introduction. We apply the theoretical framework and formal model of the observation
tuple with the credibility weight for forensic analysis of the IDS data and the corre-
sponding event reconstruction. Forensic Lucid – a forensic case modeling and speciﬁca-
tion language is used for the task. In the ongoing theoretical and practical work, Forensic
Lucid is augmented with the Dempster-Shafer theory of mathematical evidence to in-
clude the credibility factors of the evidential IDS observations. Forensic Lucid’s toolset
is practically being implemented within the General Intensional Programming System
(GIPSY) and the probabilistic model-checking tool PRISM as a backend to compile the
Forensic Lucid model into the PRISM’s code and model-check it. This work may also
help with further generalization of the testing methodology of IDSs [10].
Overview. Encoding and modeling large volumes of network and other data related to
intrusion detection with Forensic Lucid for the purpose of event correlation and recon-
struction along with trustworthiness factors (e.g. the likelihood of logs being altered by
an intruder) in a common speciﬁcation of the evidential statement context and a digital
crime scene is an important step in the incident analysis and response. One goal is to
able to collect the intrusion-related evidence as the Forensic Lucid’s evidential state-
ment from diverse sources like Snort, netﬂows, pcap’s data, etc. to do the follow up
investigation and event reconstruction. Another goal is to either be interactive with an
investigator present, or fully automated in an autonomous IDS with self-forensics [9].
Background. In the ﬁrst formal approach about automated cyberforensic case reason-
ing and event reconstruction, Gladyshev et al. created a ﬁnite-state automata (FSA)
model [3] to encode the evidence and witness accounts of an incident in order to com-
bine them into an evidential statement. Then, they modeled the FSA of a particular case,
and, veriﬁed if certain claim agrees with the evidential statement, and if it does, list pos-
sible event sequences that explain that claim [3]. This was followed by the formal log
analysis approach by Arasteh et al [1]. Another earlier work suggested a mathematical
theory of evidence by Dempster, Shafer and others [4,12], where factors like credi-
bility play a role in the evaluation, which Gladyshev lacked. Thirdly, another earlier
work on intensional logics and programming provided a formal model that through-
out its evolution placed the context as a ﬁrst-class value in language expressions in the
system, called Lucid that has produced various Lucid dialects and context-aware sys-
tems, such as GIPSY [2,13,11]. Thus, we blended the three together – we augmented the
Gladyshev’s formalization with the credibility weights and we encode the IDS evidence
as a higher-order context (HOC) in the Forensic Lucid language. We then translate a
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 508–509, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
Analysis and Credibility in IDS Evidence Modeling with Forensic Lucid
509
(1)
(cid:3)
o = (P, min, max, w, t)
Forensic Lucid speciﬁcation into the PRISM speciﬁcation, which is a probabilistic au-
tomata evaluation and model-checking system and building a PoC expert system bound
to it in CLIPS. Some own work done includes [7,5,8,9].
Computing credibility weights. The notion of an observation is formalized in Equa-
tion 1 where w is the credibility weight of that observation, and t is an optional wall-
(2)
clock timestamp. With w = 1 the o would be equivalent to the original model proposed
by Gladyshev. We then deﬁne the total credibility of an observation sequence as an
average of all the weights in this observation sequence. The IDS evidence with higher
scores of W have higher credibility.
Higher-order context. HOCs represent nested contexts, e.g. as shown in Equation 3 by
modeling the evidential statement es containing observation sequences os containing
observations o for forensic speciﬁcation evaluation. In Forensic Lucid it is expressed
following the traditional Lucid syntax with modiﬁcations adapted from MARFL [6].
Wnaive =
(wi)
n
es os1 o1 (P, min, max, w, t)
o2
o3
. . .
os2
os3
. . .
(3)
References
1. Arasteh, A.R., Debbabi, M., Sakha, A., Saleh, M.: Analyzing multiple logs for forensic evi-
dence. Digital Investigation Journal 4(1), 82–91 (2007)
2. Ashcroft, E.A., Faustini, A., Jagannathan, R., Wadge, W.W.: Multidimensional, Declarative
Programming. Oxford University Press, London (1995)
3. Gladyshev, P., Patel, A.: Finite state machine approach to digital event reconstruction. Digital
Investigation Journal 2(1) (2004)
4. Haenni, R., Kohlas, J., Lehmann, N.: Probabilistic argumentation systems. Tech. rep., Insti-
tute of Informatics, University of Fribourg, Fribourg, Switzerland (October 1999)
5. Mokhov, S.A.: Encoding forensic multimedia evidence from MARF applications as Forensic
Lucid expressions. In: CISSE 2008, pp. 413–416. Springer, Heidelberg (December 2008)
6. Mokhov, S.A.: Towards syntax and semantics of hierarchical contexts in multimedia process-
ing applications using MARFL. In: COMPSAC, pp. 1288–1294. IEEE CS, Los Alamitos
(2008)
7. Mokhov, S.A., Paquet, J., Debbabi, M.: Formally specifying operational semantics and lan-
guage constructs of Forensic Lucid. In: IMF 2008, pp. 197–216. GI (September 2008)
8. Mokhov, S.A., Paquet, J., Debbabi, M.: Reasoning about a simulated printer case investiga-
tion with Forensic Lucid. In: HSC 2009. SCS (October 2009) (to appear)
9. Mokhov, S.A., Vassev, E.: Self-forensics through case studies of small to medium software
systems. In: IMF 2009, pp. 128–141. IEEE CS, Los Alamitos (2009)
10. Otrok, H., Paquet, J., Debbabi, M., Bhattacharya, P.: Testing intrusion detection systems in
MANET: A comprehensive study. In: CNSR 2007, pp. 364–371. IEEE CS, Los Alamitos
(2007)
11. Paquet, J., Mokhov, S.A., Tong, X.: Design and implementation of context calculus in the
GIPSY environment. In: COMPSAC 2008, pp. 1278–1283. IEEE CS, Los Alamitos (2008)
12. Shafer, G.: The Mathematical Theory of Evidence. Princeton University Press, Princeton
(1976)
13. Wan, K.: Lucx: Lucid Enriched with Context. Ph.D. thesis, Department of Computer Science
and Software Engineering, Concordia University, Montreal, Canada (2006)
Toward Speciﬁcation-Based Intrusion Detection
for Web Applications
Salman Niksefat, Mohammad Mahdi Ahaniha, Babak Sadeghiyan,
and Mehdi Shajari
{niksefat,mm.ahaniha,basadegh,mshajari}@aut.ac.ir
Amirkabir University of Technology
1 Introduction
In speciﬁcation-based detection the correct behavior of a system is modeled for-
mally and would be later veriﬁed during system operation for detecting anoma-
lies. In this paper we argue that comparing to anomaly and signature-based
approaches, speciﬁcation-based approach is an appropriate and precise way to
build IDSes for web applications. This is due to standardized nature of web archi-
tecture including protocols (HTTP, SOAP) and data formats (HTML, XHTML,
XML), which makes the challenging task of formal speciﬁcation feasible. In this
paper we propose a novel architecture based on ICAP protocol for a speciﬁcation-
based web application IDS, in which input parameters as well as the output
content of a web application are speciﬁed formally by regular expressions and
the IDS veriﬁes the speciﬁcation when users have interactions with the
application.
A more precise and comprehensive speciﬁcation makes the IDS engine more
powerful and increase the detection rate while decrease the false alarms. A cor-
rect speciﬁcation that exactly matches the real behavior of the system is very
important. If the speciﬁcation is so strict then some normal behavior of the sys-
tem may be detected as malicious activity and false positives arise. On the other
hand, If the speciﬁcation is so loose or general, then some abnormal behavior of
the system may be considered as normal activity and it causes false negatives.
Because of the variety of systems and normal behaviors, designing a general
speciﬁcation-based IDS with formal speciﬁcations of all normal activities is gen-
erally so complicated and imprecise. So researchers mainly focus on a speciﬁc
system or network protocol and try to formalize the speciﬁcations in order to
build a speciﬁcation-based IDS[1].
2 Formal Speciﬁcation of Web Applications
The standardized nature of web application protocols and data formats makes
the challenging work of speciﬁcation feasible. For building a speciﬁcation-based
IDS for a web application we propose to create the formal speciﬁcation in the
following areas:
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 510–511, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
Toward Speciﬁcation-Based Intrusion Detection for Web Applications
511
– Input Parameters and Values: Each web application has a number of
input parameters. These input parameters and their associated valid values
can be identiﬁed from design or implementation documents or can be possi-
bly extracted by code analysis tool. To formally specify the input parameters
we can utilize various computation models used in computability theory such
as regular expressions, ﬁnite state machines or push-down automata.
– Output Content: By formal speciﬁcation of the output content and enforcing
this speciﬁcation on our IDS it is possible to detect and prevent attacks such as
cross-site scripting (XSS), SQL Injection and information leakages(directory
traversal, error pages, etc). Similar to speciﬁcation of input parameters, the
output content can be speciﬁed using various computation models.
3 Proposed Architecture
Our idea for building a speciﬁcation-based IDS is using the Internet Content
Adaptation Protocol (ICAP) as well as a middle proxy system such as Squid to
deliver the requests and responses to the IDS analysis engine. This idea maximize
the interoperability and minimize the implementation overhead of our proposed
architecture. This architecture allows the detection ans also prevention of attacks
on web applications (Fig.1). When a web client sends a request, the middle proxy
machine receives this request, encapsulates it in an ICAP request and sends it
the IDS analysis engine. The IDS analysis engine veriﬁes the correctness of the
request and either rejects it or forward it to the target web server. The correctness
of the responses is veriﬁed in the same way.
Request (Mod)
Response (Orig)
Request (Orig)
Response (Mod)
Web Server +
Web Application
SQUID+
ICAP Client
Web Application
User
Response(Mod) Request(Orig)
Analysis Engine
Alerts
Specifications
DB
Fig. 1. Proposed Architecture
SSO
Reference
1. Orset, J., Alcalde, B., Cavalli, A.: An EFSM-based intrusion detection system for ad
hoc networks. In: Automated Technology for Veriﬁcation and Analysis, pp. 400–413
(2005)
Toward Whole-System Dynamic Analysis for
ARM-Based Mobile Devices
Ryan Whelan and David Kaeli
Department of Electrical and Computer Engineering
Northeastern University
Boston, MA, USA
PI:EMAIL, PI:EMAIL
Abstract. The ARM architecture is presently the chipset of choice for
today’s smartphones - this demand has spurred new advances in func-
tionality and services, and as the number of smartphones increases, so
has the number of applications being migrated to them. As a result, the
amount of malware targeting them will also increase. We present our pre-
liminary work on an ARM-based dynamic proﬁling platform that allows
analysts to study malware that targets ARM-based smartphone systems.
Mobile malware exploits have only begun to appear recently, but analysts expect
this trend to accelerate in future years as smartphones begin to dominate the
mobile communications market. Smartphones introduce additional attack vec-
tors unavailable on PCs, including Short Messaging Service (SMS), Multimedia
Messaging Service (MMS), and Bluetooth. While security experts (especially
white hat hackers) have begun to exploit and disclose these vulnerabilities so
they can be patched, a new group of embedded systems black hat hackers will
soon emerge given the personal and ﬁnancial data being managed from these
systems. As new mobile malware culture continues to mature, security analysts
will need a platform that will allow them to study exploits and intrusions. At
the moment, a complete ARM-based security analysis platform does not exist
that is appropriate for studying mobile malware.
In this paper we report on our implementation of such a platform that is
based on QEMU [1]. QEMU provides a whole-system emulator for many guest
architectures, including ARM. Since the open source development emulator for
the Android smartphone operating system is based on QEMU with an ARM
guest, we have chosen this environment to develop deep introspection and anal-
ysis capabilities for Android. The design of our environment leverages TEMU, an
open source dynamic analysis platform based on QEMU for x86 guests [3]. Us-
ing QEMU for instrumentation is ideal since it uses dynamic binary translation,
which translates execution on the guest architecture to the host architecture at
runtime (e.g., ARM on x86). This level of implementation granularity presents
an opportunity for ﬁne-grained instrumentation, proﬁling, and information ﬂow
tracking where custom analysis code can be executed along with each guest in-
struction. Dynamic information ﬂow tracking (i.e., taint tracking) can provide
insight into speciﬁc events on a system given that data in memory, disk, and
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 512–513, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
Toward Whole-System Dynamic Analysis for ARM-Based Mobile Devices
513
registers are instrumented. Any input to the system can then be tracked accord-
ing to the implemented policy. Given the fact that Android is one of the most
popular operating systems on smartphones today, we anticipate that our fully
instrumented Android system will be adopted by the mobile security community
to study new classes of malware and assist with making tomorrow’s smartphones
more secure.
On our platform, we have implemented the necessary extensions to dynam-
ically inspect the internal state of an Android guest, and we have begun to
evaluate a number of potential threats on ARM-based mobile devices such as
alphanumeric ARM shellcode [5], and a kernel module (similar to a rootkit) that
hides processes [4]. With our trusted view into the system, we can identify the
shell spawned by the shellcode, list processes we’ve hidden, and generate a rich
instruction trace. We obtain our trusted view into the system by analyzing the
memory image of the guest and reconstructing the relevant kernel data struc-
tures. Our current focus is to address SMS workloads as a portal for additional
attack vectors. Recent work has shown that certain SMS messages can render
phones inoperable [2], and that worm propagation over Bluetooth is a serious
problem that needs to be addressed.
Since the Android emulator provides a mechanism to send SMS messages
to the guest, we are approaching the SMS problem by implementing an SMS
fuzzing utility, along with a tainting scheme that keeps track of the SMS data
propagation through the system. Our preliminary SMS fuzzing can repeatedly
and reliably crash the Android process that handles SMS and MMS messages.
Once our tainting scheme is fully implemented, it will mark all data derived
from SMS input as untrusted and carefully inspect the guest for execution of
instructions possessing tainted operands. We will then be provided with a rich
proﬁle that will allow the analyst to identify the root cause of this attack (and
the associated software bug or vulnerability). We feel it is critical to have the
ability to carefully inspect mobile malware before it becomes widespread and
disables large segments in this market. Our implementation is the ﬁrst whole-
system platform that allows for dynamic analysis of malware and the potential
for discovery of new vulnerabilities on popular mobile devices.
References
1. Bellard, F.: Qemu, a fast and portable dynamic translator. In: USENIX 2005 (April
2005)
2. Mulliner, C., Miller, C.: Fuzzing the phone in your phone. In: Black Hat (June 2009)
3. Song, D., Brumley, D., Yin, H., Caballero, J., Jager, I., Kang, M.G., Liang, Z.,
Newsome, J., Poosankam, P., Saxena, P.: BitBlaze: A new approach to computer
security via binary analysis. In: Proceedings of the 4th International Conference on
Information Systems Security, Hyderabad, India (December 2008)
4. ubra: Process hiding and the linux scheduler. In: Phrack, vol. 63 (January 2005)
5. Younan, Y., Philippaerts, P.: Alphanumeric risc arm shellcode. In: Phrack, vol. 66
(November 2009)
Using IRP for Malware Detection
FuYong Zhang, DeYu Qi, and JingLin Hu
Research Institute of Computer Systems at South China University of Technology,
510640 GuangZhou, GuangDong, China
{z.fuyong,qideyu,h.jinglin}@mail.scut.edu.cn
Abstract. Run-time malware detection strategies are eﬃcient and ro-
bust, which get more and more attention. In this paper, we use I/O
Request Package (IRP) sequences for malware detection. N-gram will be
used to analyze IRP sequences for feature extraction. Integrated use of
Negative Selection Algorithm (NSA) and Positive Selection Algorithm
(PSA), we get more than 96% true positive rate and 0% false positive
rate, by a selection of n-gram sequences which only exist in malware IRP
sequences.
1 Introduction