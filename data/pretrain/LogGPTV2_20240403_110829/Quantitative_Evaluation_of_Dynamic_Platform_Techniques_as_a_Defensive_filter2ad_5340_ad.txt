M
420
H. Okhravi, J. Riordan, and K. Carter
manner that a person ﬂipping a coin will eventually observe a sequence of ten, or ninety-
two, heads in a row. Here metrics might reasonably be based in the mean time until
attacker victory. These can be analyzed in a fashion similar to the steady state model:
I{1···∞}
1−P rv
P rn−1
vv
start
P rvP rn−1
vv
V n
1
1−P rn−1
vv
V {1···n−1}I{1···∞}
vv
P r∗
1−P rn−1
(PPPPPPPPPPPP
vmmmmmmmmmmmmm
P r(n−1)
vv
(cid:4)
1 − P rn−1
(cid:5)
end
. We can use this to evaluate the expected time L(cid:6)(n)
where P r∗ = P rv
to attack compromise as the probabilistically weighted sum of all path lengths
vv
+
1 − P rv
L(cid:6)(n) =n +
(cid:4)
(cid:5)·
1 − P rii
vv − 1
P r1−n
(cid:14)
(cid:4)
(cid:5) · (1 − P rvv)
1 − n · P rn−1
vv + (n − 1) · P rn
1 − P rn−1
vv
vv
(cid:15).
(1)
+
1
1 − P rii
Hence, in scenarios such as ‘crash the satellite’, Eq. (1) computes the expected time
before the adversary is able to take down the service.
7 Simulation Results
In order to verify that we have captured the major effects in our analysis and that our
generalized model of dynamic platforms is valid, we simulate the Markov chain that
corresponds to our testbed experiments. Our testbed experiments assumed migration
with no immediate repeat, continuous control, and fractional payoff which is modeled
using the Markov chain in section 6.3. We run a Monte Carlo simulation on that model
with the same parameters as our testbed experiments: 40 − 60 second time of each
platform, three vulnerable platforms out of ﬁve total, exploits launched at random times
during each trial, and each trial runs for 15 minutes. The results are presented in Fig. 8.
In the ﬁgure, the testbed measurements are also overlaid on the simulated results using
dotted lines for comparison.
As can be observed, the simulation results match the testbed measurements very
closely. This validates the fact that we have indeed captured at least the major ef-
fects that contribute to the effectiveness of dynamic platform techniques. Note that the
smoothing effects (e.g. random duration on a platform and random exploit launch times)
are captured in the simulation results since we have captured them in the model. How-
ever, various jitters and delays (e.g. networking, OS scheduling, etc.) are not in the
(
*
*
/
/


O
O
v




s
d
e
e
c
c
u
S
r
e
k
c
a
t
t
i
A
e
h
t
e
m
T
f
o
n
o
i
t
r
o
P
0.35 
0.3 
0.25 
0.2 
0.15 
0.1 
0.05 
0 
0 
Quantitative Evaluation of Dynamic Platform Techniques
421
Testbed 
Measurements 
2 Platforms 
Simulation 
3 Platforms 
Simulation 
4 Platforms 
Simulation 
5 Platforms 
Simulation 
50 
100 
150 
200 
250 
300 
Attacker's Goal T (time to disrupt service in seconds) 
Fig. 8. Simulation results from the generalized model. The testbed measurements are also shown
in dotted lines.
model which can explain the small amount of discrepancy between the simulated and
measured results. Table 4 shows the mean squared error (MSE) of the simulation results
compared to the testbed measurements.
7.1 Discussion
One important observation to be made for both the simulated and measured results is
that for small attacker goals (T ), fewer platforms actually perform better. This is due
to the fact that in situations where the attacker wins quickly, more platforms present a
larger attack surface. As a result, the attacker wins if she can compromise any of the
platforms. In other words,
T
d → 0 : Attacker wins iff any platform is vulnerable
The value of dynamic platforms can only be observed for attacker goals that are large
with respect to the duration of each platform (T (cid:4) d). This is an important parameter
when deploying dynamic platform systems; the duration of each platform must be se-
lected short enough based on the service requirements of the system. For example, if
the system has to survive and provide service within 5 minutes (i.e. the attacker goal is
disrupting service longer than T = 5 minutes), the platform duration must be d << 5
min. In other words,
T
d → ∞ : Attacker wins iff all platforms are vulnerable
Note that there may be practical considerations when choosing small platform dura-
tion. If the platform changes too rapidly (i.e. very small d), it can disrupt the normal
mission of the system.
422
H. Okhravi, J. Riordan, and K. Carter
Table 4. Mean squared error of the simulated model compared to the testbed measurements
Number of Platforms Mean Squared Error
2 Platforms
3 Platforms
4 Platforms
5 Platforms
8 Lessons Learned
634 × 10−6
329 × 10−6
322 × 10−6
257 × 10−6
Our work in analyzing dynamic platform techniques has provided ﬁve main lessons.
The ﬁrst is that many effects contribute to a dynamic platform system. Although
these systems have been proposed in many different forms in the literature, little work
has been done to identify and quantify these effects which can be very counter-intuitive.
On the other hand, when these effects are studied and understood, even ﬁrst-order mod-
els can closely estimate the system behavior.
The second is that experiments such as ours using real-world technologies on a
testbed can shed light on some of the complex dynamics of active systems and can be
used as a way to identify and quantify the major contributing effects of such systems.
The third is that threat models are crucial in understanding the protection provided by
a defensive technique and they are also instrumental in quantitatively measuring such
protections. As can be observed in our results, while a technique can provide signiﬁcant
protection against one type of threat (e.g. long-duration attacks that can have fractional
gain for the attacker such as slow data exﬁltration), it may actually degrade the secu-
rity of the system for another one (e.g. short duration attacks causing an irreversible
impact). In fact, threat models should be an integral part of metrics and measurements
of effectiveness [22].
The fourth is that testbed experiments, abstract analysis, and modeling and simula-
tion can be used together to perform quantitative evaluation of defensive techniques in
general. These different approaches can identify subtle effects and dynamics. Moreover,
they can provide the veriﬁcation and validation necessary to ensure that the results are
indeed correct.
The ﬁnal lesson is that some features of the proposed techniques, such as cleanup,
can signiﬁcantly reduce the likelihood of success for attacks. When designing new tech-
niques, quantitative evaluations such as what we have done in this paper can be used to
decide the important features to support in order to provide the most protection with the
least performance overhead.
9 Related Work
Various dynamic platform techniques have been proposed in the literature. As men-
tioned earlier, The Self-Cleansing Intrusion Tolerance (SCIT) project rotates virtual
machines to reduce the exposure time. SCIT-web server [23] and SCIT-DNS [24] pre-
serve the session information and DNS master ﬁle and keys, respectively, but not the
internal state of the application. The Resilient Web Service (RWS) Project [25] uses a
Quantitative Evaluation of Dynamic Platform Techniques
423
virtualization-based web server system that detects intrusions and periodically restores
them to a pristine state. Certain forms of server rotation have been proposed by Black-
mon and Nguyen [26] and by Rabbat et al. [27] in an attempt to achieve high availability
servers.
High-level forms of temporal platform changes have been proposed by Petkac and
Badger [28] and Min and Choic [19] to build intrusion tolerant systems although the
diversiﬁcation strategy is not as detailed in these efforts. Compiler-based multivariant
[3–5, 15, 29] and N-variant systems [16] propose another way of achieving platform
diversity. Holland et al. propose diversifying machine descriptions using a virtualiza-
tion layer [6]. A similar approach with more speciﬁc diversiﬁcation strategy based on
instruction sets and calling sequences has been proposed by Williams et al. [2]. Wong
and Lee [30] use randomization in the processor to combat side-channel attacks on
caches.
On the evaluation side, Manadhata and Wind [31] propose a formal model for mea-
suring a system’s attack surface that can be used to compare different platforms. Evans
et al. [32] develop models to measure the effectiveness of diversity-based moving tar-
get technique. They evaluate the probability of attack success given the time duration
of attack probing, construction, and launch cycles and the entropy of randomness in the
target system. They evaluate the impact of various attacks on moving target systems in-
cluding circumvention, deputy, brute force, entropy reduction, probing, and incremental
attacks.
There has been numerous modeling attempts in the literature for diversity systems
or N-version programming such as those done by Popov and Mladenov [33], or Arlat
et al. [34]. However, they focus on accidental faults, not malicious attacks.
10 Conclusion
In this paper, we have quantitatively studied cyber defenses based on dynamic platform
techniques. We used testbed experiments to collect results from an actual technique. The
unexpected and complex results motivated us to perform an abstract analysis to explain
the various effects that contribute to the protection. We extended our analyses to the
main features provided by the dynamic platforms proposed in the literature. Based on
these effects, we then developed a generalized model of dynamic platforms. In order to
ensure that we have captured the major effects, and to verify the model and validate our
testbed results, we simulated the same sets of experiments using the generalized model.
The closely matching results enhance the conﬁdence in the results and validate the fact
that we have at least captured the main effects.
Our results suggest that while dynamic platforms are useful for mitigating some
attacks, it is of critical importance to understand the threat model one aims to defend
against. While dynamic platforms can be effective against long-period attacks with grad-
ual gains (e.g. data exﬁltration), they can be detrimental for short-period attacks with
instantaneous gains (e.g. a malware causing an irreversible impact in a control system).
The future work in this domain will focus on performing more experiments with
such systems, extending the analysis to other dynamic platform techniques and other
randomization and diversity approaches, and analyzing the second order behavior such
as adaptive adversaries who change tactics based on the deployed defenses.
424
H. Okhravi, J. Riordan, and K. Carter
Acknowledgement. We would like to thank Charles Wright, Mark Rabe, Paula Dono-
van, and William Streilein for their insights and contributions to this work.
References
[1] Networking, F., Research, I.T., (NITRD), D.: Federal Cybersecurity Game-change R&D
Themes (2012),
http://cybersecurity.nitrd.gov/page/federal-cybersecurity-1
[2] Williams, D., Hu, W., Davidson, J.W., Hiser, J.D., Knight, J.C., Nguyen-Tuong, A.: Security
through diversity: Leveraging virtual machine technology. IEEE Security and Privacy 7(1),
26–33 (2009)
[3] Salamat, B., Jackson, T., Wagner, G., Wimmer, C., Franz, M.: Runtime defense against code
injection attacks using replicated execution. IEEE Transactions on Dependable and Secure
Computing 8(4), 588–601 (2011)
[4] Salamat, B., Gal, A., Jackson, T., Manivannan, K., Wagner, G., Franz, M.: Multi-variant
program execution: Using multi-core systems to defuse buffer-overﬂow vulnerabilities. In:
International Conference on Complex, Intelligent and Software Intensive Systems (2008)
[5] Jackson, T., Salamat, B., Wagner, G., Wimmer, C., Franz, M.: On the effectiveness of multi-
variant program execution for vulnerability detection and prevention. In: Proceedings of
the 6th International Workshop on Security Measurements and Metrics, vol. 7, pp. 7:1–7:8
(2010)
[6] Holland, D.A., Lim, A.T., Seltzer, M.I.: An architecture a day keeps the hacker away.
SIGARCH Comput. Archit. News 33(1), 34–41 (2005)
[7] Okhravi, H., Comella, A., Robinson, E., Haines, J.: Creating a cyber moving target for
critical infrastructure applications using platform diversity. International Journal of Critical
Infrastructure Protection 5(1), 30–39 (2012)
[8] Saidane, A., Nicomette, V., Deswarte, Y.: The design of a generic intrusion-tolerant architec-
ture for web servers. IEEE Transactions on Dependable and Secure Computing 6(1), 45–58
(2009)
[9] Bangalore, A., Sood, A.: Securing web servers using self cleansing intrusion tolerance (scit).
In: Second International Conference on Dependability, pp. 60 –65 (2009)
[10] Huang, Y., Arsenault, D., Sood, A.: Incorruptible system self-cleansing for intrusion toler-
ance. In: 25th IEEE International on Performance, Computing, and Communications Con-
ference, IPCCC 2006, vol. 4, p. 496 (April 2006)
[11] Arsenault, D., Sood, A., Huang, Y.: Secure, resilient computing clusters: Self-cleansing in-
trusion tolerance with hardware enforced security (scit/hes). In: Proceedings of the Second
International Conference on Availability, Reliability and Security, ARES 2007, pp. 343–350.
IEEE Computer Society, Washington, DC (2007)
[12] Okhravi, H., Hobson, T., Bigelow, D., Streilein, W.: Finding Focus in the Blur of Moving-
Target Techniques. IEEE Security & Privacy (March/April 2014)
[13] Scott, K., Davidson, J.: Strata: A Software Dynamic Translation Infrastructure. Technical
Report CS-2001-17 (2001)
[14] Nethercote, N., Seward, J.: Valgrind: A framework for heavyweight dynamic binary in-
strumentation. In: Proceedings of the 2007 ACM SIGPLAN Conference on Programming
Language Design and Implementation, PLDI 2007, pp. 89–100. ACM, New York (2007)
[15] Salamat, B., Gal, A., Franz, M.: Reverse stack execution in a multi-variant execution envi-
ronment. In: Workshop on Compiler and Architectural Techniques for Application Reliabil-
ity and Security (2008)
Quantitative Evaluation of Dynamic Platform Techniques
425
[16] Cox, B., Evans, D., Filipi, A., Rowanhill, J., Hu, W., Davidson, J., Knight, J., Nguyen-
Tuong, A., Hiser, J.: N-variant systems: A secretless framework for security through diver-
sity. In: Proceedings of the 15th Conference on USENIX Security Symposium (2006)
[17] Crouse, M., Fulp, E.: A moving target environment for computer conﬁgurations using ge-
netic algorithms. In: 2011 4th Symposium on Conﬁguration Analytics and Automation
(SAFECONFIG), pp. 1–7 (October 2011)
[18] Huang, Y., Ghosh, A.K.: Introducing diversity and uncertainty to create moving attack sur-
faces for web services. In: Moving Target Defense, pp. 131–151 (2011)
[19] Min, B.J., Choi, J.S.: An approach to intrusion tolerance for mission-critical services using
adaptability and diverse replication. Future Gener. Comput. Syst, 303–313 (2004)
[20] Kolyshkin, K.: Virtualization in linux. White paper, OpenVZ (September 2006)
[21] Rodríguez, G., Martín, M.J., González, P., Touriño, J., Doallo, R.: Cppc: A compiler-
assisted tool for portable checkpointing of message-passing applications. Concurr. Comput.:
Pract. Exper. 22(6), 749–766 (2010)
[22] Lippmann, R.P., Riordan, J.F., Yu, T.H., Watson, K.K.: Continuous Security Metrics for
Prevalent Network Threats: Introduction and First Four Metrics. Technical report. MIT Lin-
coln Laboratory (May 2012)
[23] Bangalore, A.K., Sood, A.K.: Securing web servers using self cleansing intrusion tolerance
(scit). In: Proceedings of the 2009 Second International Conference on Dependability, pp.
60–65 (2009)
[24] Huang, Y., Arsenault, D., Arun, S.: Incorruptible self-cleansing intrusion tolerance and its
application to dns security. A Journal of Networks 1(5), 21–30 (2006)
[25] Huang, Y., Ghosh, A.: Automating intrusion response via virtualization for realizing unin-
terruptible web services. In: Eighth IEEE International Symposium on Network Computing
and Applications, NCA 2009, pp. 114–117 (July 2009)
[26] Blackmon, S., Nguyen, J.: High-availability ﬁle server with heartbeat. System Admin. The
Journal for UNIX and Linux Systems Administration 10(9) (2001)
[27] Rabbat, R., McNeal, T., Burke, T.: A high-availability clustering architecture with data in-
tegrity guarantees. In: IEEE International Conference on Cluster Computing (2001)
[28] Petkac, M., Badger, L.: Security agility in response to intrusion detection. In: 16th Annual
Computer Security Applications Conference (ACSAC), vol. 11 (2000)
[29] Jackson, T., Salamat, B., Homescu, A., Manivannan, K., Wagner, G., Gal, A., Brunthaler, S.,
Wimmer, C., Franz, M.: Compiler-generated software diversity. In: Moving Target Defense,
pp. 77–98 (2011)
[30] Wang, Z., Lee, R.B.: New cache designs for thwarting software cache-based side channel
attacks. In: Proceedings of the 34th Annual International Symposium on Computer Archi-
tecture, ISCA 2007, pp. 494–505. ACM, New York (2007)
[31] Manadhata, P.K., Wing, J.M.: A formal model for a system’s attack surface. In: Moving
Target Defense, pp. 1–28 (2011)
[32] Evans, D., Nguyen-Tuong, A., Knight, J.C.: Effectiveness of moving target defenses. In:
Moving Target Defense, pp. 29–48 (2011)
[33] Popov, G., Mladenov, V.: Modeling diversity in recovery computer systems. In: Mastorakis,
N., Mladenov, V., Kontargyri, V.T. (eds.) Proceedings of the European Computing Confer-
ence. LNEE, vol. 27, pp. 223–233. Springer, US (2009)
[34] Arlat, J., Kanoun, K., Laprie, J.C.: Dependability modeling and evaluation of software fault-
tolerant systems. IEEE Trans. Comput. 39(4), 504–513 (1990)